[
    {
        "question": {
            "question": "查找关于大模型Agent应用的最新发表论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "98891",
                "标题": "RecMind: Large Language Model Powered Agent For Recommendation",
                "作者": " Yancheng Wang,  Ziyan Jiang,  Zheng Chen,  Fan Yang,  Yingxue Zhou,  Eunah Cho,  Xing Fan,  Xiaojiang Huang,  Yanbin Lu,  Yingzhen Yang",
                "发布日期": "2023-08-29",
                "摘要": "  Recent advancements in instructing Large Language Models (LLMs) to utilize\nexternal tools and execute multi-step plans have significantly enhanced their\nability to solve intricate tasks, ranging from mathematical problems to\ncreative writing. Yet, there remains a notable gap in studying the capacity of\nLLMs in responding to personalized queries such as a recommendation request. To\nbridge this gap, we have designed an LLM-powered autonomous recommender agent,\nRecMind, which is capable of providing precise personalized recommendations\nthrough careful planning, utilizing tools for obtaining external knowledge, and\nleveraging individual data. We propose a novel algorithm, Self-Inspiring, to\nimprove the planning ability of the LLM agent. At each intermediate planning\nstep, the LLM 'self-inspires' to consider all previously explored states to\nplan for next step. This mechanism greatly improves the model's ability to\ncomprehend and utilize historical planning information for recommendation. We\nevaluate RecMind's performance in various recommendation scenarios, including\nrating prediction, sequential recommendation, direct recommendation,\nexplanation generation, and review summarization. Our experiment shows that\nRecMind outperforms existing zero/few-shot LLM-based recommendation methods in\ndifferent recommendation tasks and achieves competitive performance to a recent\nmodel P5, which requires fully pre-train for the recommendation tasks.\n",
                "链接": "https://arxiv.org/abs/2308.14296"
            },
            {
                "文章ID": "122182",
                "标题": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications",
                "作者": " Feibo Jiang,  Li Dong,  Yubo Peng,  Kezhi Wang,  Kun Yang,  Cunhua Pan,  Dusit Niyato,  Octavia A. Dobre",
                "发布日期": "2023-12-14",
                "摘要": "  The rapid development of the Large Language Model (LLM) presents huge\nopportunities for 6G communications, e.g., network optimization and management\nby allowing users to input task requirements to LLMs by nature language.\nHowever, directly applying native LLMs in 6G encounters various challenges,\nsuch as a lack of private communication data and knowledge, limited logical\nreasoning, evaluation, and refinement abilities. Integrating LLMs with the\ncapabilities of retrieval, planning, memory, evaluation and reflection in\nagents can greatly enhance the potential of LLMs for 6G communications. To this\nend, we propose a multi-agent system with customized communication knowledge\nand tools for solving communication related tasks using natural language,\ncomprising three components: (1) Multi-agent Data Retrieval (MDR), which\nemploys the condensate and inference agents to refine and summarize\ncommunication knowledge from the knowledge base, expanding the knowledge\nboundaries of LLMs in 6G communications; (2) Multi-agent Collaborative Planning\n(MCP), which utilizes multiple planning agents to generate feasible solutions\nfor the communication related task from different perspectives based on the\nretrieved knowledge; (3) Multi-agent Evaluation and Reflecxion (MER), which\nutilizes the evaluation agent to assess the solutions, and applies the\nreflexion agent and refinement agent to provide improvement suggestions for\ncurrent solutions. Finally, we validate the effectiveness of the proposed\nmulti-agent system by designing a semantic communication system, as a case\nstudy of 6G communications.\n",
                "链接": "https://arxiv.org/abs/2312.07850"
            },
            {
                "文章ID": "112741",
                "标题": "Multi-Agent Consensus Seeking via Large Language Models",
                "作者": " Huaben Chen,  Wenkang Ji,  Lufeng Xu,  Shiyu Zhao",
                "发布日期": "2023-11-01",
                "摘要": "  Multi-agent systems driven by large language models (LLMs) have shown\npromising abilities for solving complex tasks in a collaborative manner. This\nwork considers a fundamental problem in multi-agent collaboration: consensus\nseeking. When multiple agents work together, we are interested in how they can\nreach a consensus through inter-agent negotiation. To that end, this work\nstudies a consensus-seeking task where the state of each agent is a numerical\nvalue and they negotiate with each other to reach a consensus value. It is\nrevealed that when not explicitly directed on which strategy should be adopted,\nthe LLM-driven agents primarily use the average strategy for consensus seeking\nalthough they may occasionally use some other strategies. Moreover, this work\nanalyzes the impact of the agent number, agent personality, and network\ntopology on the negotiation process. The findings reported in this work can\npotentially lay the foundations for understanding the behaviors of LLM-driven\nmulti-agent systems for solving more complex tasks. Furthermore, LLM-driven\nconsensus seeking is applied to a multi-robot aggregation task. This\napplication demonstrates the potential of LLM-driven agents to achieve\nzero-shot autonomous planning for multi-robot collaboration tasks. Project\nwebsite: westlakeintelligentrobotics.github.io/ConsensusLLM/.\n",
                "链接": "https://arxiv.org/abs/2310.20151"
            },
            {
                "文章ID": "97404",
                "标题": "ChatEDA: A Large Language Model Powered Autonomous Agent for EDA",
                "作者": " Zhuolun He,  Haoyuan Wu,  Xinyun Zhang,  Xufeng Yao,  Su Zheng,  Haisheng Zheng,  Bei Yu",
                "发布日期": "2023-08-22",
                "摘要": "  The integration of a complex set of Electronic Design Automation (EDA) tools\nto enhance interoperability is a critical concern for circuit designers. Recent\nadvancements in large language models (LLMs) have showcased their exceptional\ncapabilities in natural language processing and comprehension, offering a novel\napproach to interfacing with EDA tools. This research paper introduces ChatEDA,\nan autonomous agent for EDA empowered by a large language model, AutoMage,\ncomplemented by EDA tools serving as executors. ChatEDA streamlines the design\nflow from the Register-Transfer Level (RTL) to the Graphic Data System Version\nII (GDSII) by effectively managing task planning, script generation, and task\nexecution. Through comprehensive experimental evaluations, ChatEDA has\ndemonstrated its proficiency in handling diverse requirements, and our\nfine-tuned AutoMage model has exhibited superior performance compared to GPT-4\nand other similar LLMs.\n",
                "链接": "https://arxiv.org/abs/2308.10204"
            },
            {
                "文章ID": "99980",
                "标题": "ModelScope-Agent: Building Your Customizable Agent System with\n  Open-source Large Language Models",
                "作者": " Chenliang Li,  Hehong Chen,  Ming Yan,  Weizhou Shen,  Haiyang Xu,  Zhikai Wu,  Zhicheng Zhang,  Wenmeng Zhou,  Yingda Chen,  Chen Cheng,  Hongzhu Shi,  Ji Zhang,  Fei Huang,  Jingren Zhou",
                "发布日期": "2023-09-06",
                "摘要": "  Large language models (LLMs) have recently demonstrated remarkable\ncapabilities to comprehend human intentions, engage in reasoning, and design\nplanning-like behavior. To further unleash the power of LLMs to accomplish\ncomplex tasks, there is a growing trend to build agent framework that equips\nLLMs, such as ChatGPT, with tool-use abilities to connect with massive external\nAPIs. In this work, we introduce ModelScope-Agent, a general and customizable\nagent framework for real-world applications, based on open-source LLMs as\ncontrollers. It provides a user-friendly system library, with customizable\nengine design to support model training on multiple open-source LLMs, while\nalso enabling seamless integration with both model APIs and common APIs in a\nunified way. To equip the LLMs with tool-use abilities, a comprehensive\nframework has been proposed spanning over tool-use data collection, tool\nretrieval, tool registration, memory control, customized model training, and\nevaluation for practical real-world applications. Finally, we showcase\nModelScopeGPT, a real-world intelligent assistant of ModelScope Community based\non the ModelScope-Agent framework, which is able to connect open-source LLMs\nwith more than 1000 public AI models and localized community knowledge in\nModelScope. The ModelScope-Agent\nlibrary\\footnote{https://github.com/modelscope/modelscope-agent} and online\ndemo\\footnote{https://modelscope.cn/studios/damo/ModelScopeGPT/summary} are now\npublicly available.\n",
                "链接": "https://arxiv.org/abs/2309.00986"
            },
            {
                "文章ID": "107938",
                "标题": "MatChat: A Large Language Model and Application Service Platform for\n  Materials Science",
                "作者": " Ziyi Chen,  Fankai Xie,  Meng Wan,  Yang Yuan,  Miao Liu,  Zongguo Wang,  Sheng Meng,  Yangang Wang",
                "发布日期": "2023-11-03",
                "摘要": "  The prediction of chemical synthesis pathways plays a pivotal role in\nmaterials science research. Challenges, such as the complexity of synthesis\npathways and the lack of comprehensive datasets, currently hinder our ability\nto predict these chemical processes accurately. However, recent advancements in\ngenerative artificial intelligence (GAI), including automated text generation\nand question-answering systems, coupled with fine-tuning techniques, have\nfacilitated the deployment of large-scale AI models tailored to specific\ndomains. In this study, we harness the power of the LLaMA2-7B model and enhance\nit through a learning process that incorporates 13,878 pieces of structured\nmaterial knowledge data. This specialized AI model, named MatChat, focuses on\npredicting inorganic material synthesis pathways. MatChat exhibits remarkable\nproficiency in generating and reasoning with knowledge in materials science.\nAlthough MatChat requires further refinement to meet the diverse material\ndesign needs, this research undeniably highlights its impressive reasoning\ncapabilities and innovative potential in the field of materials science.\nMatChat is now accessible online and open for use, with both the model and its\napplication framework available as open source. This study establishes a robust\nfoundation for collaborative innovation in the integration of generative AI in\nmaterials science.\n",
                "链接": "https://arxiv.org/abs/2310.07197"
            },
            {
                "文章ID": "119760",
                "标题": "Self Generated Wargame AI: Double Layer Agent Task Planning Based on\n  Large Language Model",
                "作者": " Y. Sun,  J. Zhao,  C. Yu,  W. Wang,  X. Zhou",
                "发布日期": "2023-12-19",
                "摘要": "  The large language models represented by ChatGPT have a disruptive impact on\nthe field of artificial intelligence. But it mainly focuses on natural language\nprocessing, speech recognition, machine learning and natural language\nunderstanding. This paper innovatively applies the large language model to the\nfield of intelligent decision-making, places the large language model in the\ndecision-making center, and constructs an agent architecture with the large\nlanguage model as the core. Based on this, it further proposes a two-layer\nagent task planning, issues and executes decision commands through the\ninteraction of natural language, and carries out simulation verification\nthrough the wargame simulation environment. Through the game confrontation\nsimulation experiment, it is found that the intelligent decision-making ability\nof the large language model is significantly stronger than the commonly used\nreinforcement learning AI and rule AI, and the intelligence, understandability\nand generalization are all better. And through experiments, it was found that\nthe intelligence of the large language model is closely related to prompt. This\nwork also extends the large language model from previous human-computer\ninteraction to the field of intelligent decision-making, which has important\nreference value and significance for the development of intelligent\ndecision-making.\n",
                "链接": "https://arxiv.org/abs/2312.01090"
            },
            {
                "文章ID": "121129",
                "标题": "KwaiAgents: Generalized Information-seeking Agent System with Large\n  Language Models",
                "作者": " Haojie Pan,  Zepeng Zhai,  Hao Yuan,  Yaojia Lv,  Ruiji Fu,  Ming Liu,  Zhongyuan Wang,  Bing Qin",
                "发布日期": "2023-12-11",
                "摘要": "  Driven by curiosity, humans have continually sought to explore and understand\nthe world around them, leading to the invention of various tools to satiate\nthis inquisitiveness. Despite not having the capacity to process and memorize\nvast amounts of information in their brains, humans excel in critical thinking,\nplanning, reflection, and harnessing available tools to interact with and\ninterpret the world, enabling them to find answers efficiently. The recent\nadvancements in large language models (LLMs) suggest that machines might also\npossess the aforementioned human-like capabilities, allowing them to exhibit\npowerful abilities even with a constrained parameter count. In this paper, we\nintroduce KwaiAgents, a generalized information-seeking agent system based on\nLLMs. Within KwaiAgents, we propose an agent system that employs LLMs as its\ncognitive core, which is capable of understanding a user's query, behavior\nguidelines, and referencing external documents. The agent can also update and\nretrieve information from its internal memory, plan and execute actions using a\ntime-aware search-browse toolkit, and ultimately provide a comprehensive\nresponse. We further investigate the system's performance when powered by LLMs\nless advanced than GPT-4, and introduce the Meta-Agent Tuning (MAT) framework,\ndesigned to ensure even an open-sourced 7B or 13B model performs well among\nmany agent systems. We exploit both benchmark and human evaluations to\nsystematically validate these capabilities. Extensive experiments show the\nsuperiority of our agent system compared to other autonomous agents and\nhighlight the enhanced generalized agent-abilities of our fine-tuned LLMs.\n",
                "链接": "https://arxiv.org/abs/2312.04889"
            },
            {
                "文章ID": "85679",
                "标题": "AVIS: Autonomous Visual Information Seeking with Large Language Model\n  Agent",
                "作者": " Ziniu Hu,  Ahmet Iscen,  Chen Sun,  Kai-Wei Chang,  Yizhou Sun,  David A Ross,  Cordelia Schmid,  Alireza Fathi",
                "发布日期": "2023-11-03",
                "摘要": "  In this paper, we propose an autonomous information seeking visual question\nanswering framework, AVIS. Our method leverages a Large Language Model (LLM) to\ndynamically strategize the utilization of external tools and to investigate\ntheir outputs, thereby acquiring the indispensable knowledge needed to provide\nanswers to the posed questions. Responding to visual questions that necessitate\nexternal knowledge, such as \"What event is commemorated by the building\ndepicted in this image?\", is a complex task. This task presents a combinatorial\nsearch space that demands a sequence of actions, including invoking APIs,\nanalyzing their responses, and making informed decisions. We conduct a user\nstudy to collect a variety of instances of human decision-making when faced\nwith this task. This data is then used to design a system comprised of three\ncomponents: an LLM-powered planner that dynamically determines which tool to\nuse next, an LLM-powered reasoner that analyzes and extracts key information\nfrom the tool outputs, and a working memory component that retains the acquired\ninformation throughout the process. The collected user behavior serves as a\nguide for our system in two key ways. First, we create a transition graph by\nanalyzing the sequence of decisions made by users. This graph delineates\ndistinct states and confines the set of actions available at each state.\nSecond, we use examples of user decision-making to provide our LLM-powered\nplanner and reasoner with relevant contextual instances, enhancing their\ncapacity to make informed decisions. We show that AVIS achieves\nstate-of-the-art results on knowledge-intensive visual question answering\nbenchmarks such as Infoseek and OK-VQA.\n",
                "链接": "https://arxiv.org/abs/2306.08129"
            },
            {
                "文章ID": "119492",
                "标题": "Agent-OM: Leveraging Large Language Models for Ontology Matching",
                "作者": " Zhangcheng Qiang,  Weiqing Wang,  Kerry Taylor",
                "发布日期": "2023-12-04",
                "摘要": "  Ontology matching (OM) enables semantic interoperability between different\nontologies and resolves their conceptual heterogeneity by aligning related\nentities. OM systems currently have two prevailing design paradigms:\nconventional knowledge-based expert systems and newer machine learning-based\npredictive systems. While large language models (LLMs) and LLM-based agents\nhave become revolutionary in data engineering and have been applied creatively\nin various domains, their potential for OM remains underexplored. This study\nintroduces a novel agent-powered LLM-based design paradigm for OM systems. With\nthoughtful consideration of several specific challenges to leverage LLMs for\nOM, we propose a generic framework, namely Agent-OM, consisting of two Siamese\nagents for retrieval and matching, with a set of simple prompt-based OM tools.\nOur framework is implemented in a proof-of-concept system. Evaluations of three\nOntology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM\nsystems show that our system can achieve very close results to the best\nlong-standing performance on simple OM tasks and significantly improve the\nperformance on complex and few-shot OM tasks.\n",
                "链接": "https://arxiv.org/abs/2312.00326"
            }
        ]
    },
    {
        "question": {
            "question": "查询近一年模型推理加速相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "94780",
                "标题": "Radiation reaction on an accelerating point charge",
                "作者": " Jerrold Franklin",
                "发布日期": "2023-08-08",
                "摘要": "  A point charge accelerating under the influence of an external force emits\nelectromagnetic radiation that reduces the increase in its mechanical energy.\nThis causes a reduction in the particle's acceleration. We derive the decrease\nin acceleration due to radiation reaction for a particle accelerating parallel\nto its velocity, and show that it has a negligible effect.\n",
                "链接": "https://arxiv.org/abs/2308.02628"
            },
            {
                "文章ID": "114776",
                "标题": "LCM-LoRA: A Universal Stable-Diffusion Acceleration Module",
                "作者": " Simian Luo,  Yiqin Tan,  Suraj Patil,  Daniel Gu,  Patrick von Platen,  Apolinário Passos,  Longbo Huang,  Jian Li,  Hang Zhao",
                "发布日期": "2023-11-10",
                "摘要": "  Latent Consistency Models (LCMs) have achieved impressive performance in\naccelerating text-to-image generative tasks, producing high-quality images with\nminimal inference steps. LCMs are distilled from pre-trained latent diffusion\nmodels (LDMs), requiring only ~32 A100 GPU training hours. This report further\nextends LCMs' potential in two aspects: First, by applying LoRA distillation to\nStable-Diffusion models including SD-V1.5, SSD-1B, and SDXL, we have expanded\nLCM's scope to larger models with significantly less memory consumption,\nachieving superior image generation quality. Second, we identify the LoRA\nparameters obtained through LCM distillation as a universal Stable-Diffusion\nacceleration module, named LCM-LoRA. LCM-LoRA can be directly plugged into\nvarious Stable-Diffusion fine-tuned models or LoRAs without training, thus\nrepresenting a universally applicable accelerator for diverse image generation\ntasks. Compared with previous numerical PF-ODE solvers such as DDIM,\nDPM-Solver, LCM-LoRA can be viewed as a plug-in neural PF-ODE solver that\npossesses strong generalization abilities. Project page:\nhttps://github.com/luosiallen/latent-consistency-model.\n",
                "链接": "https://arxiv.org/abs/2311.05556"
            },
            {
                "文章ID": "108944",
                "标题": "Chameleon: a heterogeneous and disaggregated accelerator system for\n  retrieval-augmented language models",
                "作者": " Wenqi Jiang,  Marco Zeller,  Roger Waleffe,  Torsten Hoefler,  Gustavo Alonso",
                "发布日期": "2023-11-30",
                "摘要": "  A Retrieval-Augmented Language Model (RALM) augments a generative language\nmodel by retrieving context-specific knowledge from an external database. This\nstrategy facilitates impressive text generation quality even with smaller\nmodels, thus reducing orders of magnitude of computational demands. However,\nRALMs introduce unique system design challenges due to (a) the diverse workload\ncharacteristics between LM inference and retrieval and (b) the various system\nrequirements and bottlenecks for different RALM configurations such as model\nsizes, database sizes, and retrieval frequencies. We propose Chameleon, a\nheterogeneous accelerator system that integrates both LM and retrieval\naccelerators in a disaggregated architecture. The heterogeneity ensures\nefficient acceleration of both LM inference and retrieval, while the\naccelerator disaggregation enables the system to independently scale both types\nof accelerators to fulfill diverse RALM requirements. Our Chameleon prototype\nimplements retrieval accelerators on FPGAs and assigns LM inference to GPUs,\nwith a CPU server orchestrating these accelerators over the network. Compared\nto CPU-based and CPU-GPU vector search systems, Chameleon achieves up to 23.72x\nspeedup and 26.2x energy efficiency. Evaluated on various RALMs, Chameleon\nexhibits up to 2.16x reduction in latency and 3.18x speedup in throughput\ncompared to the hybrid CPU-GPU architecture. These promising results pave the\nway for bringing accelerator heterogeneity and disaggregation into future RALM\nsystems.\n",
                "链接": "https://arxiv.org/abs/2310.09949"
            },
            {
                "文章ID": "124055",
                "标题": "Accelerator-driven Data Arrangement to Minimize Transformers Run-time on\n  Multi-core Architectures",
                "作者": " Alireza Amirshahi,  Giovanni Ansaloni,  David Atienza",
                "发布日期": "2023-12-21",
                "摘要": "  The increasing complexity of transformer models in artificial intelligence\nexpands their computational costs, memory usage, and energy consumption.\nHardware acceleration tackles the ensuing challenges by designing processors\nand accelerators tailored for transformer models, supporting their computation\nhotspots with high efficiency. However, memory bandwidth can hinder\nimprovements in hardware accelerators. Against this backdrop, in this paper we\npropose a novel memory arrangement strategy, governed by the hardware\naccelerator's kernel size, which effectively minimizes off-chip data access.\nThis arrangement is particularly beneficial for end-to-end transformer model\ninference, where most of the computation is based on general matrix\nmultiplication (GEMM) operations. Additionally, we address the overhead of\nnon-GEMM operations in transformer models within the scope of this memory data\narrangement. Our study explores the implementation and effectiveness of the\nproposed accelerator-driven data arrangement approach in both single- and\nmulti-core systems. Our evaluation demonstrates that our approach can achieve\nup to a 2.8x speed increase when executing inferences employing\nstate-of-the-art transformers.\n",
                "链接": "https://arxiv.org/abs/2312.13000"
            },
            {
                "文章ID": "102164",
                "标题": "Draft & Verify: Lossless Large Language Model Acceleration via\n  Self-Speculative Decoding",
                "作者": " Jun Zhang,  Jue Wang,  Huan Li,  Lidan Shou,  Ke Chen,  Gang Chen,  Sharad Mehrotra",
                "发布日期": "2023-09-18",
                "摘要": "  We present a novel inference scheme, self-speculative decoding, for\naccelerating Large Language Models (LLMs) without the need for an auxiliary\nmodel. This approach is characterized by a two-stage process: drafting and\nverification. The drafting stage generates draft tokens at a slightly lower\nquality but more quickly, which is achieved by selectively skipping certain\nintermediate layers during drafting Subsequently, the verification stage\nemploys the original LLM to validate those draft output tokens in one forward\npass. This process ensures the final output remains identical to that produced\nby the unaltered LLM, thereby maintaining output quality. The proposed method\nrequires no additional neural network training and no extra memory footprint,\nmaking it a plug-and-play and cost-effective solution for inference\nacceleration. Benchmarks with LLaMA-2 and its fine-tuned models demonstrated a\nspeedup up to 1.73$\\times$.\n",
                "链接": "https://arxiv.org/abs/2309.08168"
            },
            {
                "文章ID": "100868",
                "标题": "Training Acceleration of Low-Rank Decomposed Networks using Sequential\n  Freezing and Rank Quantization",
                "作者": " Habib Hajimolahoseini,  Walid Ahmed,  Yang Liu",
                "发布日期": "2023-09-08",
                "摘要": "  Low Rank Decomposition (LRD) is a model compression technique applied to the\nweight tensors of deep learning models in order to reduce the number of\ntrainable parameters and computational complexity. However, due to high number\nof new layers added to the architecture after applying LRD, it may not lead to\na high training/inference acceleration if the decomposition ranks are not small\nenough. The issue is that using small ranks increases the risk of significant\naccuracy drop after decomposition. In this paper, we propose two techniques for\naccelerating low rank decomposed models without requiring to use small ranks\nfor decomposition. These methods include rank optimization and sequential\nfreezing of decomposed layers. We perform experiments on both convolutional and\ntransformer-based models. Experiments show that these techniques can improve\nthe model throughput up to 60% during training and 37% during inference when\ncombined together while preserving the accuracy close to that of the original\nmodels\n",
                "链接": "https://arxiv.org/abs/2309.03824"
            },
            {
                "文章ID": "124676",
                "标题": "Understanding the Potential of FPGA-Based Spatial Acceleration for Large\n  Language Model Inference",
                "作者": " Hongzheng Chen,  Jiahao Zhang,  Yixiao Du,  Shaojie Xiang,  Zichao Yue,  Niansong Zhang,  Yaohui Cai,  Zhiru Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Recent advancements in large language models (LLMs) boasting billions of\nparameters have generated a significant demand for efficient deployment in\ninference workloads. The majority of existing approaches rely on temporal\narchitectures that reuse hardware units for different network layers and\noperators. However, these methods often encounter challenges in achieving low\nlatency due to considerable memory access overhead. This paper investigates the\nfeasibility and potential of model-specific spatial acceleration for LLM\ninference on FPGAs. Our approach involves the specialization of distinct\nhardware units for specific operators or layers, facilitating direct\ncommunication between them through a dataflow architecture while minimizing\noff-chip memory accesses. We introduce a comprehensive analytical model for\nestimating the performance of a spatial LLM accelerator, taking into account\nthe on-chip compute and memory resources available on an FPGA. Through our\nanalysis, we can determine the scenarios in which FPGA-based spatial\nacceleration can outperform its GPU-based counterpart. To enable more\nproductive implementations of an LLM model on FPGAs, we further provide a\nlibrary of high-level synthesis (HLS) kernels that are composable and reusable.\nThis library will be made available as open-source. To validate the\neffectiveness of both our analytical model and HLS library, we have implemented\nBERT and GPT2 on an AMD Alveo U280 FPGA device. Experimental results\ndemonstrate our approach can achieve up to 16.1x speedup when compared to\nprevious FPGA-based accelerators for the BERT model. For GPT generative\ninference, we attain a 2.2x speedup compared to DFX, an FPGA overlay, in the\nprefill stage, while achieving a 1.9x speedup and a 5.7x improvement in energy\nefficiency compared to the NVIDIA A100 GPU in the decode stage.\n",
                "链接": "https://arxiv.org/abs/2312.15159"
            },
            {
                "文章ID": "116519",
                "标题": "Exponentially Faster Language Modelling",
                "作者": " Peter Belcak,  Roger Wattenhofer",
                "发布日期": "2023-11-22",
                "摘要": "  Language models only really need to use an exponential fraction of their\nneurons for individual inferences. As proof, we present UltraFastBERT, a BERT\nvariant that uses 0.3% of its neurons during inference while performing on par\nwith similar BERT models. UltraFastBERT selectively engages just 12 out of 4095\nneurons for each layer inference. This is achieved by replacing feedforward\nnetworks with fast feedforward networks (FFFs). While no truly efficient\nimplementation currently exists to unlock the full acceleration potential of\nconditional neural execution, we provide high-level CPU code achieving 78x\nspeedup over the optimized baseline feedforward implementation, and a PyTorch\nimplementation delivering 40x speedup over the equivalent batched feedforward\ninference. We publish our training code, benchmarking setup, and model weights.\n",
                "链接": "https://arxiv.org/abs/2311.10770"
            },
            {
                "文章ID": "89860",
                "标题": "ITA: An Energy-Efficient Attention and Softmax Accelerator for Quantized\n  Transformers",
                "作者": " Gamze İslamoğlu,  Moritz Scherer,  Gianna Paulin,  Tim Fischer,  Victor J. B. Jung,  Angelo Garofalo,  Luca Benini",
                "发布日期": "2023-07-11",
                "摘要": "  Transformer networks have emerged as the state-of-the-art approach for\nnatural language processing tasks and are gaining popularity in other domains\nsuch as computer vision and audio processing. However, the efficient hardware\nacceleration of transformer models poses new challenges due to their high\narithmetic intensities, large memory requirements, and complex dataflow\ndependencies. In this work, we propose ITA, a novel accelerator architecture\nfor transformers and related models that targets efficient inference on\nembedded systems by exploiting 8-bit quantization and an innovative softmax\nimplementation that operates exclusively on integer values. By computing\non-the-fly in streaming mode, our softmax implementation minimizes data\nmovement and energy consumption. ITA achieves competitive energy efficiency\nwith respect to state-of-the-art transformer accelerators with 16.9 TOPS/W,\nwhile outperforming them in area efficiency with 5.93 TOPS/mm$^2$ in 22 nm\nfully-depleted silicon-on-insulator technology at 0.8 V.\n",
                "链接": "https://arxiv.org/abs/2307.03493"
            },
            {
                "文章ID": "120589",
                "标题": "F3-Pruning: A Training-Free and Generalized Pruning Strategy towards\n  Faster and Finer Text-to-Video Synthesis",
                "作者": " Sitong Su,  Jianzhi Liu,  Lianli Gao,  Jingkuan Song",
                "发布日期": "2023-12-07",
                "摘要": "  Recently Text-to-Video (T2V) synthesis has undergone a breakthrough by\ntraining transformers or diffusion models on large-scale datasets.\nNevertheless, inferring such large models incurs huge costs.Previous inference\nacceleration works either require costly retraining or are model-specific.To\naddress this issue, instead of retraining we explore the inference process of\ntwo mainstream T2V models using transformers and diffusion models.The\nexploration reveals the redundancy in temporal attention modules of both\nmodels, which are commonly utilized to establish temporal relations among\nframes.Consequently, we propose a training-free and generalized pruning\nstrategy called F3-Pruning to prune redundant temporal attention\nweights.Specifically, when aggregate temporal attention values are ranked below\na certain ratio, corresponding weights will be pruned.Extensive experiments on\nthree datasets using a classic transformer-based model CogVideo and a typical\ndiffusion-based model Tune-A-Video verify the effectiveness of F3-Pruning in\ninference acceleration, quality assurance and broad applicability.\n",
                "链接": "https://arxiv.org/abs/2312.03459"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本检测最新进展",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "123651",
                "标题": "Advancements and Challenges in Arabic Optical Character Recognition: A\n  Comprehensive Survey",
                "作者": " Mahmoud SalahEldin Kasem,  Mohamed Mahmoud,  Hyun-Soo Kang",
                "发布日期": "2023-12-20",
                "摘要": "  Optical character recognition (OCR) is a vital process that involves the\nextraction of handwritten or printed text from scanned or printed images,\nconverting it into a format that can be understood and processed by machines.\nThis enables further data processing activities such as searching and editing.\nThe automatic extraction of text through OCR plays a crucial role in digitizing\ndocuments, enhancing productivity, improving accessibility, and preserving\nhistorical records. This paper seeks to offer an exhaustive review of\ncontemporary applications, methodologies, and challenges associated with Arabic\nOptical Character Recognition (OCR). A thorough analysis is conducted on\nprevailing techniques utilized throughout the OCR process, with a dedicated\neffort to discern the most efficacious approaches that demonstrate enhanced\noutcomes. To ensure a thorough evaluation, a meticulous keyword-search\nmethodology is adopted, encompassing a comprehensive analysis of articles\nrelevant to Arabic OCR, including both backward and forward citation reviews.\nIn addition to presenting cutting-edge techniques and methods, this paper\ncritically identifies research gaps within the realm of Arabic OCR. By\nhighlighting these gaps, we shed light on potential areas for future\nexploration and development, thereby guiding researchers toward promising\navenues in the field of Arabic OCR. The outcomes of this study provide valuable\ninsights for researchers, practitioners, and stakeholders involved in Arabic\nOCR, ultimately fostering advancements in the field and facilitating the\ncreation of more accurate and efficient OCR systems for the Arabic language.\n",
                "链接": "https://arxiv.org/abs/2312.11812"
            },
            {
                "文章ID": "100439",
                "标题": "STEP -- Towards Structured Scene-Text Spotting",
                "作者": " Sergi Garcia-Bordils,  Dimosthenis Karatzas,  Marçal Rusiñol",
                "发布日期": "2023-12-12",
                "摘要": "  We introduce the structured scene-text spotting task, which requires a\nscene-text OCR system to spot text in the wild according to a query regular\nexpression. Contrary to generic scene text OCR, structured scene-text spotting\nseeks to dynamically condition both scene text detection and recognition on\nuser-provided regular expressions. To tackle this task, we propose the\nStructured TExt sPotter (STEP), a model that exploits the provided text\nstructure to guide the OCR process. STEP is able to deal with regular\nexpressions that contain spaces and it is not bound to detection at the\nword-level granularity. Our approach enables accurate zero-shot structured text\nspotting in a wide variety of real-world reading scenarios and is solely\ntrained on publicly available data. To demonstrate the effectiveness of our\napproach, we introduce a new challenging test dataset that contains several\ntypes of out-of-vocabulary structured text, reflecting important reading\napplications of fields such as prices, dates, serial numbers, license plates\netc. We demonstrate that STEP can provide specialised OCR performance on demand\nin all tested scenarios.\n",
                "链接": "https://arxiv.org/abs/2309.02356"
            },
            {
                "文章ID": "118306",
                "标题": "Data Generation for Post-OCR correction of Cyrillic handwriting",
                "作者": " Evgenii Davydkin,  Aleksandr Markelov,  Egor Iuldashev,  Anton Dudkin,  Ivan Krivorotov",
                "发布日期": "2023-11-28",
                "摘要": "  This paper introduces a novel approach to post-Optical Character Recognition\nCorrection (POC) for handwritten Cyrillic text, addressing a significant gap in\ncurrent research methodologies. This gap is due to the lack of large text\ncorporas that provide OCR errors for further training of language-based POC\nmodels, which are demanding in terms of corpora size. Our study primarily\nfocuses on the development and application of a synthetic handwriting\ngeneration engine based on B\\'ezier curves. Such an engine generates highly\nrealistic handwritten text in any amounts, which we utilize to create a\nsubstantial dataset by transforming Russian text corpora sourced from the\ninternet. We apply a Handwritten Text Recognition (HTR) model to this dataset\nto identify OCR errors, forming the basis for our POC model training. The\ncorrection model is trained on a 90-symbol input context, utilizing a\npre-trained T5 architecture with a seq2seq correction task. We evaluate our\napproach on HWR200 and School_notebooks_RU datasets as they provide significant\nchallenges in the HTR domain. Furthermore, POC can be used to highlight errors\nfor teachers, evaluating student performance. This can be done simply by\ncomparing sentences before and after correction, displaying differences in\ntext. Our primary contribution lies in the innovative use of B\\'ezier curves\nfor Cyrillic text generation and subsequent error correction using a\nspecialized POC model. We validate our approach by presenting Word Accuracy\nRate (WAR) and Character Accuracy Rate (CAR) results, both with and without\npost-OCR correction, using real open corporas of handwritten Cyrillic text.\nThese results, coupled with our methodology, are designed to be reproducible,\npaving the way for further advancements in the field of OCR and handwritten\ntext analysis. Paper contributions can be found in\nhttps://github.com/dbrainio/CyrillicHandwritingPOC\n",
                "链接": "https://arxiv.org/abs/2311.15896"
            },
            {
                "文章ID": "53136",
                "标题": "Extending TrOCR for Text Localization-Free OCR of Full-Page Scanned\n  Receipt Images",
                "作者": " Hongkuan Zhang,  Edward Whittaker,  Ikuo Kitagishi",
                "发布日期": "2023-10-17",
                "摘要": "  Digitization of scanned receipts aims to extract text from receipt images and\nsave it into structured documents. This is usually split into two sub-tasks:\ntext localization and optical character recognition (OCR). Most existing OCR\nmodels only focus on the cropped text instance images, which require the\nbounding box information provided by a text region detection model. Introducing\nan additional detector to identify the text instance images in advance adds\ncomplexity, however instance-level OCR models have very low accuracy when\nprocessing the whole image for the document-level OCR, such as receipt images\ncontaining multiple text lines arranged in various layouts. To this end, we\npropose a localization-free document-level OCR model for transcribing all the\ncharacters in a receipt image into an ordered sequence end-to-end.\nSpecifically, we finetune the pretrained instance-level model TrOCR with\nrandomly cropped image chunks, and gradually increase the image chunk size to\ngeneralize the recognition ability from instance images to full-page images. In\nour experiments on the SROIE receipt OCR dataset, the model finetuned with our\nstrategy achieved 64.4 F1-score and a 22.8% character error rate (CER),\nrespectively, which outperforms the baseline results with 48.5 F1-score and\n50.6% CER. The best model, which splits the full image into 15 equally sized\nchunks, gives 87.8 F1-score and 4.98% CER with minimal additional pre or\npost-processing of the output. Moreover, the characters in the generated\ndocument-level sequences are arranged in the reading order, which is practical\nfor real-world applications.\n",
                "链接": "https://arxiv.org/abs/2212.05525"
            },
            {
                "文章ID": "55598",
                "标题": "A Comprehensive Gold Standard and Benchmark for Comics Text Detection\n  and Recognition",
                "作者": " Gürkan Soykan,  Deniz Yuret,  Tevfik Metin Sezgin",
                "发布日期": "2023-01-02",
                "摘要": "  This study focuses on improving the optical character recognition (OCR) data\nfor panels in the COMICS dataset, the largest dataset containing text and\nimages from comic books. To do this, we developed a pipeline for OCR processing\nand labeling of comic books and created the first text detection and\nrecognition datasets for western comics, called \"COMICS Text+: Detection\" and\n\"COMICS Text+: Recognition\". We evaluated the performance of state-of-the-art\ntext detection and recognition models on these datasets and found significant\nimprovement in word accuracy and normalized edit distance compared to the text\nin COMICS. We also created a new dataset called \"COMICS Text+\", which contains\nthe extracted text from the textboxes in the COMICS dataset. Using the improved\ntext data of COMICS Text+ in the comics processing model from resulted in\nstate-of-the-art performance on cloze-style tasks without changing the model\narchitecture. The COMICS Text+ dataset can be a valuable resource for\nresearchers working on tasks including text detection, recognition, and\nhigh-level processing of comics, such as narrative understanding, character\nrelations, and story generation. All the data and inference instructions can be\naccessed in https://github.com/gsoykan/comics_text_plus.\n",
                "链接": "https://arxiv.org/abs/2212.14674"
            },
            {
                "文章ID": "23281",
                "标题": "PP-OCRv3: More Attempts for the Improvement of Ultra Lightweight OCR\n  System",
                "作者": " Chenxia Li,  Weiwei Liu,  Ruoyu Guo,  Xiaoting Yin,  Kaitao Jiang,  Yongkun Du,  Yuning Du,  Lingfeng Zhu,  Baohua Lai,  Xiaoguang Hu,  Dianhai Yu,  Yanjun Ma",
                "发布日期": "2022-06-15",
                "摘要": "  Optical character recognition (OCR) technology has been widely used in\nvarious scenes, as shown in Figure 1. Designing a practical OCR system is still\na meaningful but challenging task. In previous work, considering the efficiency\nand accuracy, we proposed a practical ultra lightweight OCR system (PP-OCR),\nand an optimized version PP-OCRv2. In order to further improve the performance\nof PP-OCRv2, a more robust OCR system PP-OCRv3 is proposed in this paper.\nPP-OCRv3 upgrades the text detection model and text recognition model in 9\naspects based on PP-OCRv2. For text detector, we introduce a PAN module with\nlarge receptive field named LK-PAN, a FPN module with residual attention\nmechanism named RSE-FPN, and DML distillation strategy. For text recognizer,\nthe base model is replaced from CRNN to SVTR, and we introduce lightweight text\nrecognition network SVTR LCNet, guided training of CTC by attention, data\naugmentation strategy TextConAug, better pre-trained model by self-supervised\nTextRotNet, UDML, and UIM to accelerate the model and improve the effect.\nExperiments on real data show that the hmean of PP-OCRv3 is 5% higher than\nPP-OCRv2 under comparable inference speed. All the above mentioned models are\nopen-sourced and the code is available in the GitHub repository PaddleOCR which\nis powered by PaddlePaddle.\n",
                "链接": "https://arxiv.org/abs/2206.03001"
            },
            {
                "文章ID": "107228",
                "标题": "Federated Learning: A Cutting-Edge Survey of the Latest Advancements and\n  Applications",
                "作者": " Azim Akhtarshenas,  Mohammad Ali Vahedifar,  Navid Ayoobi,  Behrouz Maham,  Tohid Alizadeh,  Sina Ebrahimi",
                "发布日期": "2023-10-17",
                "摘要": "  In the realm of machine learning (ML) systems featuring client-host\nconnections, the enhancement of privacy security can be effectively achieved\nthrough federated learning (FL) as a secure distributed ML methodology. FL\neffectively integrates cloud infrastructure to transfer ML models onto edge\nservers using blockchain technology. Through this mechanism, it guarantees the\nstreamlined processing and data storage requirements of both centralized and\ndecentralized systems, with an emphasis on scalability, privacy considerations,\nand cost-effective communication. In current FL implementations, data owners\nlocally train their models, and subsequently upload the outcomes in the form of\nweights, gradients, and parameters to the cloud for overall model aggregation.\nThis innovation obviates the necessity of engaging Internet of Things (IoT)\nclients and participants to communicate raw and potentially confidential data\ndirectly with a cloud center. This not only reduces the costs associated with\ncommunication networks but also enhances the protection of private data. This\nsurvey conducts an analysis and comparison of recent FL applications, aiming to\nassess their efficiency, accuracy, and privacy protection. However, in light of\nthe complex and evolving nature of FL, it becomes evident that additional\nresearch is imperative to address lingering knowledge gaps and effectively\nconfront the forthcoming challenges in this field. In this study, we categorize\nrecent literature into the following clusters: privacy protection, resource\nallocation, case study analysis, and applications. Furthermore, at the end of\neach section, we tabulate the open areas and future directions presented in the\nreferenced literature, affording researchers and scholars an insightful view of\nthe evolution of the field.\n",
                "链接": "https://arxiv.org/abs/2310.05269"
            },
            {
                "文章ID": "120332",
                "标题": "UPOCR: Towards Unified Pixel-Level OCR Interface",
                "作者": " Dezhi Peng,  Zhenhua Yang,  Jiaxin Zhang,  Chongyu Liu,  Yongxin Shi,  Kai Ding,  Fengjun Guo,  Lianwen Jin",
                "发布日期": "2023-12-06",
                "摘要": "  In recent years, the optical character recognition (OCR) field has been\nproliferating with plentiful cutting-edge approaches for a wide spectrum of\ntasks. However, these approaches are task-specifically designed with divergent\nparadigms, architectures, and training strategies, which significantly\nincreases the complexity of research and maintenance and hinders the fast\ndeployment in applications. To this end, we propose UPOCR, a\nsimple-yet-effective generalist model for Unified Pixel-level OCR interface.\nSpecifically, the UPOCR unifies the paradigm of diverse OCR tasks as\nimage-to-image transformation and the architecture as a vision Transformer\n(ViT)-based encoder-decoder. Learnable task prompts are introduced to push the\ngeneral feature representations extracted by the encoder toward task-specific\nspaces, endowing the decoder with task awareness. Moreover, the model training\nis uniformly aimed at minimizing the discrepancy between the generated and\nground-truth images regardless of the inhomogeneity among tasks. Experiments\nare conducted on three pixel-level OCR tasks including text removal, text\nsegmentation, and tampered text detection. Without bells and whistles, the\nexperimental results showcase that the proposed method can simultaneously\nachieve state-of-the-art performance on three tasks with a unified single\nmodel, which provides valuable strategies and insights for future research on\ngeneralist OCR models. Code will be publicly available.\n",
                "链接": "https://arxiv.org/abs/2312.02694"
            },
            {
                "文章ID": "8287",
                "标题": "DiT: Self-supervised Pre-training for Document Image Transformer",
                "作者": " Junlong Li,  Yiheng Xu,  Tengchao Lv,  Lei Cui,  Cha Zhang,  Furu Wei",
                "发布日期": "2022-07-20",
                "摘要": "  Image Transformer has recently achieved significant progress for natural\nimage understanding, either using supervised (ViT, DeiT, etc.) or\nself-supervised (BEiT, MAE, etc.) pre-training techniques. In this paper, we\npropose \\textbf{DiT}, a self-supervised pre-trained \\textbf{D}ocument\n\\textbf{I}mage \\textbf{T}ransformer model using large-scale unlabeled text\nimages for Document AI tasks, which is essential since no supervised\ncounterparts ever exist due to the lack of human-labeled document images. We\nleverage DiT as the backbone network in a variety of vision-based Document AI\ntasks, including document image classification, document layout analysis, table\ndetection as well as text detection for OCR. Experiment results have\nillustrated that the self-supervised pre-trained DiT model achieves new\nstate-of-the-art results on these downstream tasks, e.g. document image\nclassification (91.11 $\\rightarrow$ 92.69), document layout analysis (91.0\n$\\rightarrow$ 94.9), table detection (94.23 $\\rightarrow$ 96.55) and text\ndetection for OCR (93.07 $\\rightarrow$ 94.29). The code and pre-trained models\nare publicly available at \\url{https://aka.ms/msdit}.\n",
                "链接": "https://arxiv.org/abs/2203.02378"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本识别最新进展。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "97589",
                "标题": "bbOCR: An Open-source Multi-domain OCR Pipeline for Bengali Documents",
                "作者": " Imam Mohammad Zulkarnain,  Shayekh Bin Islam,  Md. Zami Al Zunaed Farabe,  Md. Mehedi Hasan Shawon,  Jawaril Munshad Abedin,  Beig Rajibul Hasan,  Marsia Haque,  Istiak Shihab,  Syed Mobassir,  MD. Nazmuddoha Ansary,  Asif Sushmit,  Farig Sadeque",
                "发布日期": "2023-08-23",
                "摘要": "  Despite the existence of numerous Optical Character Recognition (OCR) tools,\nthe lack of comprehensive open-source systems hampers the progress of document\ndigitization in various low-resource languages, including Bengali. Low-resource\nlanguages, especially those with an alphasyllabary writing system, suffer from\nthe lack of large-scale datasets for various document OCR components such as\nword-level OCR, document layout extraction, and distortion correction; which\nare available as individual modules in high-resource languages. In this paper,\nwe introduce Bengali$.$AI-BRACU-OCR (bbOCR): an open-source scalable document\nOCR system that can reconstruct Bengali documents into a structured searchable\ndigitized format that leverages a novel Bengali text recognition model and two\nnovel synthetic datasets. We present extensive component-level and system-level\nevaluation: both use a novel diversified evaluation dataset and comprehensive\nevaluation metrics. Our extensive evaluation suggests that our proposed\nsolution is preferable over the current state-of-the-art Bengali OCR systems.\nThe source codes and datasets are available here:\nhttps://bengaliai.github.io/bbocr.\n",
                "链接": "https://arxiv.org/abs/2308.10647"
            },
            {
                "文章ID": "98478",
                "标题": "DISGO: Automatic End-to-End Evaluation for Scene Text OCR",
                "作者": " Mei-Yuh Hwang,  Yangyang Shi,  Ankit Ramchandani,  Guan Pang,  Praveen Krishnan,  Lucas Kabela,  Frank Seide,  Samyak Datta,  Jun Liu",
                "发布日期": "2023-08-28",
                "摘要": "  This paper discusses the challenges of optical character recognition (OCR) on\nnatural scenes, which is harder than OCR on documents due to the wild content\nand various image backgrounds. We propose to uniformly use word error rates\n(WER) as a new measurement for evaluating scene-text OCR, both end-to-end (e2e)\nperformance and individual system component performances. Particularly for the\ne2e metric, we name it DISGO WER as it considers Deletion, Insertion,\nSubstitution, and Grouping/Ordering errors. Finally we propose to utilize the\nconcept of super blocks to automatically compute BLEU scores for e2e OCR\nmachine translation. The small SCUT public test set is used to demonstrate WER\nperformance by a modularized OCR system.\n",
                "链接": "https://arxiv.org/abs/2308.13173"
            },
            {
                "文章ID": "53136",
                "标题": "Extending TrOCR for Text Localization-Free OCR of Full-Page Scanned\n  Receipt Images",
                "作者": " Hongkuan Zhang,  Edward Whittaker,  Ikuo Kitagishi",
                "发布日期": "2023-10-17",
                "摘要": "  Digitization of scanned receipts aims to extract text from receipt images and\nsave it into structured documents. This is usually split into two sub-tasks:\ntext localization and optical character recognition (OCR). Most existing OCR\nmodels only focus on the cropped text instance images, which require the\nbounding box information provided by a text region detection model. Introducing\nan additional detector to identify the text instance images in advance adds\ncomplexity, however instance-level OCR models have very low accuracy when\nprocessing the whole image for the document-level OCR, such as receipt images\ncontaining multiple text lines arranged in various layouts. To this end, we\npropose a localization-free document-level OCR model for transcribing all the\ncharacters in a receipt image into an ordered sequence end-to-end.\nSpecifically, we finetune the pretrained instance-level model TrOCR with\nrandomly cropped image chunks, and gradually increase the image chunk size to\ngeneralize the recognition ability from instance images to full-page images. In\nour experiments on the SROIE receipt OCR dataset, the model finetuned with our\nstrategy achieved 64.4 F1-score and a 22.8% character error rate (CER),\nrespectively, which outperforms the baseline results with 48.5 F1-score and\n50.6% CER. The best model, which splits the full image into 15 equally sized\nchunks, gives 87.8 F1-score and 4.98% CER with minimal additional pre or\npost-processing of the output. Moreover, the characters in the generated\ndocument-level sequences are arranged in the reading order, which is practical\nfor real-world applications.\n",
                "链接": "https://arxiv.org/abs/2212.05525"
            },
            {
                "文章ID": "54214",
                "标题": "Transferring General Multimodal Pretrained Models to Text Recognition",
                "作者": " Junyang Lin,  Xuancheng Ren,  Yichang Zhang,  Gao Liu,  Peng Wang,  An Yang,  Chang Zhou",
                "发布日期": "2022-12-20",
                "摘要": "  This paper proposes a new method, OFA-OCR, to transfer multimodal pretrained\nmodels to text recognition. Specifically, we recast text recognition as image\ncaptioning and directly transfer a unified vision-language pretrained model to\nthe end task. Without pretraining on large-scale annotated or synthetic text\nrecognition data, OFA-OCR outperforms the baselines and achieves\nstate-of-the-art performance in the Chinese text recognition benchmark.\nAdditionally, we construct an OCR pipeline with OFA-OCR, and we demonstrate\nthat it can achieve competitive performance with the product-level API. The\ncode (https://github.com/OFA-Sys/OFA) and demo\n(https://modelscope.cn/studios/damo/ofa_ocr_pipeline/summary) are publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2212.09297"
            },
            {
                "文章ID": "111490",
                "标题": "Exploring OCR Capabilities of GPT-4V(ision) : A Quantitative and\n  In-depth Evaluation",
                "作者": " Yongxin Shi,  Dezhi Peng,  Wenhui Liao,  Zening Lin,  Xinhong Chen,  Chongyu Liu,  Yuyi Zhang,  Lianwen Jin",
                "发布日期": "2023-10-31",
                "摘要": "  This paper presents a comprehensive evaluation of the Optical Character\nRecognition (OCR) capabilities of the recently released GPT-4V(ision), a Large\nMultimodal Model (LMM). We assess the model's performance across a range of OCR\ntasks, including scene text recognition, handwritten text recognition,\nhandwritten mathematical expression recognition, table structure recognition,\nand information extraction from visually-rich document. The evaluation reveals\nthat GPT-4V performs well in recognizing and understanding Latin contents, but\nstruggles with multilingual scenarios and complex tasks. Specifically, it\nshowed limitations when dealing with non-Latin languages and complex tasks such\nas handwriting mathematical expression recognition, table structure\nrecognition, and end-to-end semantic entity recognition and pair extraction\nfrom document image. Based on these observations, we affirm the necessity and\ncontinued research value of specialized OCR models. In general, despite its\nversatility in handling diverse OCR tasks, GPT-4V does not outperform existing\nstate-of-the-art OCR models. How to fully utilize pre-trained general-purpose\nLMMs such as GPT-4V for OCR downstream tasks remains an open problem. The study\noffers a critical reference for future research in OCR with LMMs. Evaluation\npipeline and results are available at\nhttps://github.com/SCUT-DLVCLab/GPT-4V_OCR.\n",
                "链接": "https://arxiv.org/abs/2310.16809"
            },
            {
                "文章ID": "43946",
                "标题": "OCR-VQGAN: Taming Text-within-Image Generation",
                "作者": " Juan A. Rodriguez,  David Vazquez,  Issam Laradji,  Marco Pedersoli,  Pau Rodriguez",
                "发布日期": "2022-10-26",
                "摘要": "  Synthetic image generation has recently experienced significant improvements\nin domains such as natural image or art generation. However, the problem of\nfigure and diagram generation remains unexplored. A challenging aspect of\ngenerating figures and diagrams is effectively rendering readable texts within\nthe images. To alleviate this problem, we present OCR-VQGAN, an image encoder,\nand decoder that leverages OCR pre-trained features to optimize a text\nperceptual loss, encouraging the architecture to preserve high-fidelity text\nand diagram structure. To explore our approach, we introduce the Paper2Fig100k\ndataset, with over 100k images of figures and texts from research papers. The\nfigures show architecture diagrams and methodologies of articles available at\narXiv.org from fields like artificial intelligence and computer vision. Figures\nusually include text and discrete objects, e.g., boxes in a diagram, with lines\nand arrows that connect them. We demonstrate the effectiveness of OCR-VQGAN by\nconducting several experiments on the task of figure reconstruction.\nAdditionally, we explore the qualitative and quantitative impact of weighting\ndifferent perceptual metrics in the overall loss function. We release code,\nmodels, and dataset at https://github.com/joanrod/ocr-vqgan.\n",
                "链接": "https://arxiv.org/abs/2210.11248"
            },
            {
                "文章ID": "36484",
                "标题": "Levenshtein OCR",
                "作者": " Cheng Da,  Peng Wang,  Cong Yao",
                "发布日期": "2022-11-15",
                "摘要": "  A novel scene text recognizer based on Vision-Language Transformer (VLT) is\npresented. Inspired by Levenshtein Transformer in the area of NLP, the proposed\nmethod (named Levenshtein OCR, and LevOCR for short) explores an alternative\nway for automatically transcribing textual content from cropped natural images.\nSpecifically, we cast the problem of scene text recognition as an iterative\nsequence refinement process. The initial prediction sequence produced by a pure\nvision model is encoded and fed into a cross-modal transformer to interact and\nfuse with the visual features, to progressively approximate the ground truth.\nThe refinement process is accomplished via two basic character-level\noperations: deletion and insertion, which are learned with imitation learning\nand allow for parallel decoding, dynamic length change and good\ninterpretability. The quantitative experiments clearly demonstrate that LevOCR\nachieves state-of-the-art performances on standard benchmarks and the\nqualitative analyses verify the effectiveness and advantage of the proposed\nLevOCR algorithm. Code is available at\nhttps://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/LevOCR.\n",
                "链接": "https://arxiv.org/abs/2209.03594"
            },
            {
                "文章ID": "90438",
                "标题": "Handwritten Text Recognition Using Convolutional Neural Network",
                "作者": " Atman Mishra,  A. Sharath Ram,  Kavyashree C",
                "发布日期": "2023-07-12",
                "摘要": "  OCR (Optical Character Recognition) is a technology that offers comprehensive\nalphanumeric recognition of handwritten and printed characters at electronic\nspeed by merely scanning the document. Recently, the understanding of visual\ndata has been termed Intelligent Character Recognition (ICR). Intelligent\nCharacter Recognition (ICR) is the OCR module that can convert scans of\nhandwritten or printed characters into ASCII text. ASCII data is the standard\nformat for data encoding in electronic communication. ASCII assigns standard\nnumeric values to letters, numeral, symbols, white-spaces and other characters.\nIn more technical terms, OCR is the process of using an electronic device to\ntransform 2-Dimensional textual information into machine-encoded text. Anything\nthat contains text both machine written or handwritten can be scanned either\nthrough a scanner or just simply a picture of the text is enough for the\nrecognition system to distinguish the text. The goal of this papers is to show\nthe results of a Convolutional Neural Network model which has been trained on\nNational Institute of Science and Technology (NIST) dataset containing over a\n100,000 images. The network learns from the features extracted from the images\nand use it to generate the probability of each class to which the picture\nbelongs to. We have achieved an accuracy of 90.54% with a loss of 2.53%.\n",
                "链接": "https://arxiv.org/abs/2307.05396"
            },
            {
                "文章ID": "23281",
                "标题": "PP-OCRv3: More Attempts for the Improvement of Ultra Lightweight OCR\n  System",
                "作者": " Chenxia Li,  Weiwei Liu,  Ruoyu Guo,  Xiaoting Yin,  Kaitao Jiang,  Yongkun Du,  Yuning Du,  Lingfeng Zhu,  Baohua Lai,  Xiaoguang Hu,  Dianhai Yu,  Yanjun Ma",
                "发布日期": "2022-06-15",
                "摘要": "  Optical character recognition (OCR) technology has been widely used in\nvarious scenes, as shown in Figure 1. Designing a practical OCR system is still\na meaningful but challenging task. In previous work, considering the efficiency\nand accuracy, we proposed a practical ultra lightweight OCR system (PP-OCR),\nand an optimized version PP-OCRv2. In order to further improve the performance\nof PP-OCRv2, a more robust OCR system PP-OCRv3 is proposed in this paper.\nPP-OCRv3 upgrades the text detection model and text recognition model in 9\naspects based on PP-OCRv2. For text detector, we introduce a PAN module with\nlarge receptive field named LK-PAN, a FPN module with residual attention\nmechanism named RSE-FPN, and DML distillation strategy. For text recognizer,\nthe base model is replaced from CRNN to SVTR, and we introduce lightweight text\nrecognition network SVTR LCNet, guided training of CTC by attention, data\naugmentation strategy TextConAug, better pre-trained model by self-supervised\nTextRotNet, UDML, and UIM to accelerate the model and improve the effect.\nExperiments on real data show that the hmean of PP-OCRv3 is 5% higher than\nPP-OCRv2 under comparable inference speed. All the above mentioned models are\nopen-sourced and the code is available in the GitHub repository PaddleOCR which\nis powered by PaddlePaddle.\n",
                "链接": "https://arxiv.org/abs/2206.03001"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月agent系列决策文章。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "与大模型安全相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "104308",
                "标题": "People's Perceptions Toward Bias and Related Concepts in Large Language\n  Models: A Systematic Review",
                "作者": " Lu Wang,  Max Song,  Rezvaneh Rezapour,  Bum Chul Kwon,  Jina Huh-Yoo",
                "发布日期": "2023-09-27",
                "摘要": "  Large language models (LLMs) have brought breakthroughs in tasks including\ntranslation, summarization, information retrieval, and language generation,\ngaining growing interest in the CHI community. Meanwhile, the literature shows\nresearchers' controversial perceptions about the efficacy, ethics, and\nintellectual abilities of LLMs. However, we do not know how lay people perceive\nLLMs that are pervasive in everyday tools, specifically regarding their\nexperience with LLMs around bias, stereotypes, social norms, or safety. In this\nstudy, we conducted a systematic review to understand what empirical insights\npapers have gathered about people's perceptions toward LLMs. From a total of\n231 retrieved papers, we full-text reviewed 15 papers that recruited human\nevaluators to assess their experiences with LLMs. We report different biases\nand related concepts investigated by these studies, four broader LLM\napplication areas, the evaluators' perceptions toward LLMs' performances\nincluding advantages, biases, and conflicting perceptions, factors influencing\nthese perceptions, and concerns about LLM applications.\n",
                "链接": "https://arxiv.org/abs/2309.14504"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "95587",
                "标题": "NLLG Quarterly arXiv Report 06/23: What are the most influential current\n  AI Papers?",
                "作者": " Steffen Eger,  Christoph Leiter,  Jonas Belouadi,  Ran Zhang,  Aida Kostikova,  Daniil Larionov,  Yanran Chen,  Vivian Fresen",
                "发布日期": "2023-08-15",
                "摘要": "  The rapid growth of information in the field of Generative Artificial\nIntelligence (AI), particularly in the subfields of Natural Language Processing\n(NLP) and Machine Learning (ML), presents a significant challenge for\nresearchers and practitioners to keep pace with the latest developments. To\naddress the problem of information overload, this report by the Natural\nLanguage Learning Group at Bielefeld University focuses on identifying the most\npopular papers on arXiv, with a specific emphasis on NLP and ML. The objective\nis to offer a quick guide to the most relevant and widely discussed research,\naiding both newcomers and established researchers in staying abreast of current\ntrends. In particular, we compile a list of the 40 most popular papers based on\nnormalized citation counts from the first half of 2023. We observe the\ndominance of papers related to Large Language Models (LLMs) and specifically\nChatGPT during the first half of 2023, with the latter showing signs of\ndeclining popularity more recently, however. Further, NLP related papers are\nthe most influential (around 60\\% of top papers) even though there are twice as\nmany ML related papers in our data. Core issues investigated in the most\nheavily cited papers are: LLM efficiency, evaluation techniques, ethical\nconsiderations, embodied agents, and problem-solving with LLMs. Additionally,\nwe examine the characteristics of top papers in comparison to others outside\nthe top-40 list (noticing the top paper's focus on LLM related issues and\nhigher number of co-authors) and analyze the citation distributions in our\ndataset, among others.\n",
                "链接": "https://arxiv.org/abs/2308.04889"
            },
            {
                "文章ID": "112586",
                "标题": "Evaluating Large Language Models: A Comprehensive Survey",
                "作者": " Zishan Guo,  Renren Jin,  Chuang Liu,  Yufei Huang,  Dan Shi,   Supryadi,  Linhao Yu,  Yan Liu,  Jiaxuan Li,  Bojian Xiong,  Deyi Xiong",
                "发布日期": "2023-11-28",
                "摘要": "  Large language models (LLMs) have demonstrated remarkable capabilities across\na broad spectrum of tasks. They have attracted significant attention and been\ndeployed in numerous downstream applications. Nevertheless, akin to a\ndouble-edged sword, LLMs also present potential risks. They could suffer from\nprivate data leaks or yield inappropriate, harmful, or misleading content.\nAdditionally, the rapid progress of LLMs raises concerns about the potential\nemergence of superintelligent systems without adequate safeguards. To\neffectively capitalize on LLM capacities as well as ensure their safe and\nbeneficial development, it is critical to conduct a rigorous and comprehensive\nevaluation of LLMs.\n  This survey endeavors to offer a panoramic perspective on the evaluation of\nLLMs. We categorize the evaluation of LLMs into three major groups: knowledge\nand capability evaluation, alignment evaluation and safety evaluation. In\naddition to the comprehensive review on the evaluation methodologies and\nbenchmarks on these three aspects, we collate a compendium of evaluations\npertaining to LLMs' performance in specialized domains, and discuss the\nconstruction of comprehensive evaluation platforms that cover LLM evaluations\non capabilities, alignment, safety, and applicability.\n  We hope that this comprehensive overview will stimulate further research\ninterests in the evaluation of LLMs, with the ultimate goal of making\nevaluation serve as a cornerstone in guiding the responsible development of\nLLMs. We envision that this will channel their evolution into a direction that\nmaximizes societal benefit while minimizing potential risks. A curated list of\nrelated papers has been publicly available at\nhttps://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers.\n",
                "链接": "https://arxiv.org/abs/2310.19736"
            },
            {
                "文章ID": "43261",
                "标题": "A Systematic Review of Machine Learning Techniques for Cattle\n  Identification: Datasets, Methods and Future Directions",
                "作者": " Md Ekramul Hossain,  Muhammad Ashad Kabir,  Lihong Zheng,  Dave L. Swain,  Shawn McGrath,  Jonathan Medway",
                "发布日期": "2022-10-18",
                "摘要": "  Increased biosecurity and food safety requirements may increase demand for\nefficient traceability and identification systems of livestock in the supply\nchain. The advanced technologies of machine learning and computer vision have\nbeen applied in precision livestock management, including critical disease\ndetection, vaccination, production management, tracking, and health monitoring.\nThis paper offers a systematic literature review (SLR) of vision-based cattle\nidentification. More specifically, this SLR is to identify and analyse the\nresearch related to cattle identification using Machine Learning (ML) and Deep\nLearning (DL). For the two main applications of cattle detection and cattle\nidentification, all the ML based papers only solve cattle identification\nproblems. However, both detection and identification problems were studied in\nthe DL based papers. Based on our survey report, the most used ML models for\ncattle identification were support vector machine (SVM), k-nearest neighbour\n(KNN), and artificial neural network (ANN). Convolutional neural network (CNN),\nresidual network (ResNet), Inception, You Only Look Once (YOLO), and Faster\nR-CNN were popular DL models in the selected papers. Among these papers, the\nmost distinguishing features were the muzzle prints and coat patterns of\ncattle. Local binary pattern (LBP), speeded up robust features (SURF),\nscale-invariant feature transform (SIFT), and Inception or CNN were identified\nas the most used feature extraction methods.\n",
                "链接": "https://arxiv.org/abs/2210.09215"
            },
            {
                "文章ID": "42172",
                "标题": "Predicting the clinical citation count of biomedical papers using\n  multilayer perceptron neural network",
                "作者": " Xin Li,  Xuli Tang,  Qikai Cheng",
                "发布日期": "2022-10-24",
                "摘要": "  The number of clinical citations received from clinical guidelines or\nclinical trials has been considered as one of the most appropriate indicators\nfor quantifying the clinical impact of biomedical papers. Therefore, the early\nprediction of the clinical citation count of biomedical papers is critical to\nscientific activities in biomedicine, such as research evaluation, resource\nallocation, and clinical translation. In this study, we designed a four-layer\nmultilayer perceptron neural network (MPNN) model to predict the clinical\ncitation count of biomedical papers in the future by using 9,822,620 biomedical\npapers published from 1985 to 2005. We extracted ninety-one paper features from\nthree dimensions as the input of the model, including twenty-one features in\nthe paper dimension, thirty-five in the reference dimension, and thirty-five in\nthe citing paper dimension. In each dimension, the features can be classified\ninto three categories, i.e., the citation-related features, the clinical\ntranslation-related features, and the topic-related features. Besides, in the\npaper dimension, we also considered the features that have previously been\ndemonstrated to be related to the citation counts of research papers. The\nresults showed that the proposed MPNN model outperformed the other five\nbaseline models, and the features in the reference dimension were the most\nimportant.\n",
                "链接": "https://arxiv.org/abs/2210.06346"
            },
            {
                "文章ID": "7420",
                "标题": "Did AI get more negative recently?",
                "作者": " Dominik Beese,  Begüm Altunbaş,  Görkem Güzeler,  Steffen Eger",
                "发布日期": "2023-06-30",
                "摘要": "  In this paper, we classify scientific articles in the domain of natural\nlanguage processing (NLP) and machine learning (ML), as core subfields of\nartificial intelligence (AI), into whether (i) they extend the current\nstate-of-the-art by the introduction of novel techniques which beat existing\nmodels or whether (ii) they mainly criticize the existing state-of-the-art,\ni.e. that it is deficient with respect to some property (e.g. wrong evaluation,\nwrong datasets, misleading task specification). We refer to contributions under\n(i) as having a 'positive stance' and contributions under (ii) as having a\n'negative stance' (to related work). We annotate over 1.5 k papers from NLP and\nML to train a SciBERT-based model to automatically predict the stance of a\npaper based on its title and abstract. We then analyse large-scale trends on\nover 41 k papers from the last approximately 35 years in NLP and ML, finding\nthat papers have become substantially more positive over time, but negative\npapers also got more negative and we observe considerably more negative papers\nin recent years. Negative papers are also more influential in terms of\ncitations they receive.\n",
                "链接": "https://arxiv.org/abs/2202.13610"
            },
            {
                "文章ID": "102959",
                "标题": "OpenMSD: Towards Multilingual Scientific Documents Similarity\n  Measurement",
                "作者": " Yang Gao,  Ji Ma,  Ivan Korotkov,  Keith Hall,  Dana Alon,  Don Metzler",
                "发布日期": "2023-09-20",
                "摘要": "  We develop and evaluate multilingual scientific documents similarity\nmeasurement models in this work. Such models can be used to find related works\nin different languages, which can help multilingual researchers find and\nexplore papers more efficiently. We propose the first multilingual scientific\ndocuments dataset, Open-access Multilingual Scientific Documents (OpenMSD),\nwhich has 74M papers in 103 languages and 778M citation pairs. With OpenMSD, we\npretrain science-specialized language models, and explore different strategies\nto derive \"related\" paper pairs to fine-tune the models, including using a\nmixture of citation, co-citation, and bibliographic-coupling pairs. To further\nimprove the models' performance for non-English papers, we explore the use of\ngenerative language models to enrich the non-English papers with English\nsummaries. This allows us to leverage the models' English capabilities to\ncreate better representations for non-English papers. Our best model\nsignificantly outperforms strong baselines by 7-16% (in mean average\nprecision).\n",
                "链接": "https://arxiv.org/abs/2309.10539"
            },
            {
                "文章ID": "105505",
                "标题": "A Survey of Robustness and Safety of 2D and 3D Deep Learning Models\n  Against Adversarial Attacks",
                "作者": " Yanjie Li,  Bin Xie,  Songtao Guo,  Yuanyuan Yang,  Bin Xiao",
                "发布日期": "2023-10-03",
                "摘要": "  Benefiting from the rapid development of deep learning, 2D and 3D computer\nvision applications are deployed in many safe-critical systems, such as\nautopilot and identity authentication. However, deep learning models are not\ntrustworthy enough because of their limited robustness against adversarial\nattacks. The physically realizable adversarial attacks further pose fatal\nthreats to the application and human safety. Lots of papers have emerged to\ninvestigate the robustness and safety of deep learning models against\nadversarial attacks. To lead to trustworthy AI, we first construct a general\nthreat model from different perspectives and then comprehensively review the\nlatest progress of both 2D and 3D adversarial attacks. We extend the concept of\nadversarial examples beyond imperceptive perturbations and collate over 170\npapers to give an overview of deep learning model robustness against various\nadversarial attacks. To the best of our knowledge, we are the first to\nsystematically investigate adversarial attacks for 3D models, a flourishing\nfield applied to many real-world applications. In addition, we examine physical\nadversarial attacks that lead to safety violations. Last but not least, we\nsummarize present popular topics, give insights on challenges, and shed light\non future research on trustworthy AI.\n",
                "链接": "https://arxiv.org/abs/2310.00633"
            },
            {
                "文章ID": "111067",
                "标题": "Improving Biomedical Abstractive Summarisation with Knowledge\n  Aggregation from Citation Papers",
                "作者": " Chen Tang,  Shun Wang,  Tomas Goldsack,  Chenghua Lin",
                "发布日期": "2023-10-25",
                "摘要": "  Abstracts derived from biomedical literature possess distinct domain-specific\ncharacteristics, including specialised writing styles and biomedical\nterminologies, which necessitate a deep understanding of the related\nliterature. As a result, existing language models struggle to generate\ntechnical summaries that are on par with those produced by biomedical experts,\ngiven the absence of domain-specific background knowledge. This paper aims to\nenhance the performance of language models in biomedical abstractive\nsummarisation by aggregating knowledge from external papers cited within the\nsource article. We propose a novel attention-based citation aggregation model\nthat integrates domain-specific knowledge from citation papers, allowing neural\nnetworks to generate summaries by leveraging both the paper content and\nrelevant knowledge from citation papers. Furthermore, we construct and release\na large-scale biomedical summarisation dataset that serves as a foundation for\nour research. Extensive experiments demonstrate that our model outperforms\nstate-of-the-art approaches and achieves substantial improvements in\nabstractive biomedical text summarisation.\n",
                "链接": "https://arxiv.org/abs/2310.15684"
            }
        ]
    },
    {
        "question": {
            "question": "查找大模型推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "83366",
                "标题": "On Optimal Caching and Model Multiplexing for Large Model Inference",
                "作者": " Banghua Zhu,  Ying Sheng,  Lianmin Zheng,  Clark Barrett,  Michael I. Jordan,  Jiantao Jiao",
                "发布日期": "2023-08-30",
                "摘要": "  Large Language Models (LLMs) and other large foundation models have achieved\nnoteworthy success, but their size exacerbates existing resource consumption\nand latency challenges. In particular, the large-scale deployment of these\nmodels is hindered by the significant resource requirements during inference.\nIn this paper, we study two approaches for mitigating these challenges:\nemploying a cache to store previous queries and learning a model multiplexer to\nchoose from an ensemble of models for query processing.\n  Theoretically, we provide an optimal algorithm for jointly optimizing both\napproaches to reduce the inference cost in both offline and online tabular\nsettings. By combining a caching algorithm, namely Greedy Dual Size with\nFrequency (GDSF) or Least Expected Cost (LEC), with a model multiplexer, we\nachieve optimal rates in both offline and online settings. Empirically,\nsimulations show that the combination of our caching and model multiplexing\nalgorithms greatly improves over the baselines, with up to $50\\times$\nimprovement over the baseline when the ratio between the maximum cost and\nminimum cost is $100$. Experiments on real datasets show a $4.3\\times$\nimprovement in FLOPs over the baseline when the ratio for FLOPs is $10$, and a\n$1.8\\times$ improvement in latency when the ratio for average latency is\n$1.85$.\n",
                "链接": "https://arxiv.org/abs/2306.02003"
            },
            {
                "文章ID": "116170",
                "标题": "Large Language Model Inference with Lexical Shortlisting",
                "作者": " Nikolay Bogoychev,  Pinzhen Chen,  Barry Haddow,  Alexandra Birch",
                "发布日期": "2023-11-17",
                "摘要": "  Large language model (LLM) inference is computation and memory intensive, so\nwe adapt lexical shortlisting to it hoping to improve both. While lexical\nshortlisting is well-explored in tasks like machine translation, it requires\nmodifications before being suitable for LLMs as the intended applications vary\nsignificantly. Our work studies two heuristics to shortlist sub-vocabulary at\nLLM inference time: Unicode-based script filtering and corpus-based selection.\nWe explore different LLM families and sizes, and we find that lexical\nshortlisting can reduce the memory usage of some models by nearly 50\\% and has\nan upper bound of 25\\% improvement in generation speed. In this pilot study, we\nalso identify the drawbacks of such vocabulary selection methods and propose\navenues for future research.\n",
                "链接": "https://arxiv.org/abs/2311.09709"
            },
            {
                "文章ID": "120482",
                "标题": "A Hardware Evaluation Framework for Large Language Model Inference",
                "作者": " Hengrui Zhang,  August Ning,  Rohan Prabhakar,  David Wentzlaff",
                "发布日期": "2023-12-07",
                "摘要": "  The past year has witnessed the increasing popularity of Large Language\nModels (LLMs). Their unprecedented scale and associated high hardware cost have\nimpeded their broader adoption, calling for efficient hardware designs. With\nthe large hardware needed to simply run LLM inference, evaluating different\nhardware designs becomes a new bottleneck.\n  This work introduces LLMCompass, a hardware evaluation framework for LLM\ninference workloads. LLMCompass is fast, accurate, versatile, and able to\ndescribe and evaluate different hardware designs. LLMCompass includes a mapper\nto automatically find performance-optimal mapping and scheduling. It also\nincorporates an area-based cost model to help architects reason about their\ndesign choices. Compared to real-world hardware, LLMCompass' estimated latency\nachieves an average 10.4% error rate across various operators with various\ninput sizes and an average 4.1% error rate for LLM inference. With LLMCompass,\nsimulating a 4-NVIDIA A100 GPU node running GPT-3 175B inference can be done\nwithin 16 minutes on commodity hardware, including 26,400 rounds of the\nmapper's parameter search.\n  With the aid of LLMCompass, this work draws architectural implications and\nexplores new cost-effective hardware designs. By reducing the compute\ncapability or replacing High Bandwidth Memory (HBM) with traditional DRAM,\nthese new designs can achieve as much as 3.41x improvement in performance/cost\ncompared to an NVIDIA A100, making them promising choices for democratizing\nLLMs.\n  LLMCompass is planned to be fully open-source.\n",
                "链接": "https://arxiv.org/abs/2312.03134"
            },
            {
                "文章ID": "113368",
                "标题": "FlashDecoding++: Faster Large Language Model Inference on GPUs",
                "作者": " Ke Hong,  Guohao Dai,  Jiaming Xu,  Qiuli Mao,  Xiuhong Li,  Jun Liu,  Kangdi Chen,  Yuhan Dong,  Yu Wang",
                "发布日期": "2023-11-13",
                "摘要": "  As the Large Language Model (LLM) becomes increasingly important in various\ndomains. However, the following challenges still remain unsolved in\naccelerating LLM inference: (1) Synchronized partial softmax update. The\nsoftmax operation requires a synchronized update operation among each partial\nsoftmax result, leading to ~20% overheads for the attention computation in\nLLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices\nperforming GEMM in LLM inference is flat, leading to under-utilized computation\nand >50% performance loss after padding zeros in previous designs. (3)\nPerformance loss due to static dataflow. Kernel performance in LLM depends on\nvaried input data features, hardware configurations, etc. A single and static\ndataflow may lead to a 50.25% performance loss for GEMMs of different shapes in\nLLM inference.\n  We present FlashDecoding++, a fast LLM inference engine supporting mainstream\nLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++\ncreatively proposes: (1) Asynchronized softmax with unified max value.\nFlashDecoding++ introduces a unified max value technique for different partial\nsoftmax computations to avoid synchronization. (2) Flat GEMM optimization with\ndouble buffering. FlashDecoding++ points out that flat GEMMs with different\nshapes face varied bottlenecks. Then, techniques like double buffering are\nintroduced. (3) Heuristic dataflow with hardware resource adaptation.\nFlashDecoding++ heuristically optimizes dataflow using different hardware\nresource considering input dynamics. Due to the versatility of optimizations in\nFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on\nboth NVIDIA and AMD GPUs compared to Hugging Face implementations.\nFlashDecoding++ also achieves an average speedup of 1.37x compared to\nstate-of-the-art LLM inference engines on mainstream LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.01282"
            },
            {
                "文章ID": "119522",
                "标题": "LinguaLinked: A Distributed Large Language Model Inference System for\n  Mobile Devices",
                "作者": " Junchen Zhao,  Yurun Song,  Simeng Liu,  Ian G. Harris,  Sangeetha Abdu Jyothi",
                "发布日期": "2023-12-04",
                "摘要": "  Deploying Large Language Models (LLMs) locally on mobile devices presents a\nsignificant challenge due to their extensive memory requirements. In this\npaper, we introduce LinguaLinked, a system for decentralized, distributed LLM\ninference on mobile devices. LinguaLinked enables collaborative execution of\nthe inference task across multiple trusted devices. LinguaLinked ensures data\nprivacy by processing information locally. LinguaLinked uses three key\nstrategies. First, an optimized model assignment technique segments LLMs and\nuses linear optimization to align segments with each device's capabilities.\nSecond, an optimized data transmission mechanism ensures efficient and\nstructured data flow between model segments while also maintaining the\nintegrity of the original model structure. Finally, LinguaLinked incorporates a\nruntime load balancer that actively monitors and redistributes tasks among\nmobile devices to prevent bottlenecks, enhancing the system's overall\nefficiency and responsiveness. We demonstrate that LinguaLinked facilitates\nefficient LLM inference while maintaining consistent throughput and minimal\nlatency through extensive testing across various mobile devices, from high-end\nto low-end Android devices. In our evaluations, compared to the baseline,\nLinguaLinked achieves an inference performance acceleration of $1.11\\times$ to\n$1.61\\times$ in single-threaded settings, $1.73\\times$ to $2.65\\times$ with\nmulti-threading. Additionally, runtime load balancing yields an overall\ninference acceleration of $1.29\\times$ to $1.32\\times$.\n",
                "链接": "https://arxiv.org/abs/2312.00388"
            },
            {
                "文章ID": "57741",
                "标题": "Batch Prompting: Efficient Inference with Large Language Model APIs",
                "作者": " Zhoujun Cheng,  Jungo Kasai,  Tao Yu",
                "发布日期": "2023-10-25",
                "摘要": "  Performing inference on large volumes of samples with large language models\n(LLMs) can be computationally and financially costly in industry and real-world\nuse. We propose batch prompting, a simple yet effective prompting approach that\nenables the LLM to run inference in batches, instead of one sample at a time.\nOur method reduces both token and time costs while retaining downstream\nperformance. We theoretically demonstrate that under a few-shot in-context\nlearning setting, the inference costs decrease almost inverse linearly with the\nnumber of samples in each batch. We extensively validate the effectiveness of\nbatch prompting on ten datasets across commonsense QA, arithmetic reasoning,\nand NLI/NLU: batch prompting significantly~(up to 5x with six samples in batch)\nreduces the LLM (Codex) inference token and time costs while achieving better\nor comparable performance. For state-of-the-art Chat-based LLMs, e.g., GPT-3.5\nand GPT-4, we show the benefits of batch prompting also hold. Further analysis\nshows that the number of samples in each batch and the complexity of tasks\naffect its performance. Moreover, batch prompting can be applied across\ndifferent reasoning methods using LLMs. Our code can be found at the site\nhttps://github.com/xlang-ai/batch-prompting.\n",
                "链接": "https://arxiv.org/abs/2301.08721"
            },
            {
                "文章ID": "106372",
                "标题": "From Words to Watts: Benchmarking the Energy Costs of Large Language\n  Model Inference",
                "作者": " Siddharth Samsi,  Dan Zhao,  Joseph McDonald,  Baolin Li,  Adam Michaleas,  Michael Jones,  William Bergeron,  Jeremy Kepner,  Devesh Tiwari,  Vijay Gadepally",
                "发布日期": "2023-10-05",
                "摘要": "  Large language models (LLMs) have exploded in popularity due to their new\ngenerative capabilities that go far beyond prior state-of-the-art. These\ntechnologies are increasingly being leveraged in various domains such as law,\nfinance, and medicine. However, these models carry significant computational\nchallenges, especially the compute and energy costs required for inference.\nInference energy costs already receive less attention than the energy costs of\ntraining LLMs -- despite how often these large models are called on to conduct\ninference in reality (e.g., ChatGPT). As these state-of-the-art LLMs see\nincreasing usage and deployment in various domains, a better understanding of\ntheir resource utilization is crucial for cost-savings, scaling performance,\nefficient hardware usage, and optimal inference strategies.\n  In this paper, we describe experiments conducted to study the computational\nand energy utilization of inference with LLMs. We benchmark and conduct a\npreliminary analysis of the inference performance and inference energy costs of\ndifferent sizes of LLaMA -- a recent state-of-the-art LLM -- developed by Meta\nAI on two generations of popular GPUs (NVIDIA V100 \\& A100) and two datasets\n(Alpaca and GSM8K) to reflect the diverse set of tasks/benchmarks for LLMs in\nresearch and practice. We present the results of multi-node, multi-GPU\ninference using model sharding across up to 32 GPUs. To our knowledge, our work\nis the one of the first to study LLM inference performance from the perspective\nof computational and energy resources at this scale.\n",
                "链接": "https://arxiv.org/abs/2310.03003"
            },
            {
                "文章ID": "42266",
                "标题": "Developing a general-purpose clinical language inference model from a\n  large corpus of clinical notes",
                "作者": " Madhumita Sushil,  Dana Ludwig,  Atul J. Butte,  Vivek A. Rudrapatna",
                "发布日期": "2022-10-14",
                "摘要": "  Several biomedical language models have already been developed for clinical\nlanguage inference. However, these models typically utilize general\nvocabularies and are trained on relatively small clinical corpora. We sought to\nevaluate the impact of using a domain-specific vocabulary and a large clinical\ntraining corpus on the performance of these language models in clinical\nlanguage inference. We trained a Bidirectional Encoder Decoder from\nTransformers (BERT) model using a diverse, deidentified corpus of 75 million\ndeidentified clinical notes authored at the University of California, San\nFrancisco (UCSF). We evaluated this model on several clinical language\ninference benchmark tasks: clinical and temporal concept recognition, relation\nextraction and medical language inference. We also evaluated our model on two\ntasks using discharge summaries from UCSF: diagnostic code assignment and\ntherapeutic class inference. Our model performs at par with the best publicly\navailable biomedical language models of comparable sizes on the public\nbenchmark tasks, and is significantly better than these models in a\nwithin-system evaluation on the two tasks using UCSF data. The use of in-domain\nvocabulary appears to improve the encoding of longer documents. The use of\nlarge clinical corpora appears to enhance document encoding and inferential\naccuracy. However, further research is needed to improve abbreviation\nresolution, and numerical, temporal, and implicitly causal inference.\n",
                "链接": "https://arxiv.org/abs/2210.06566"
            },
            {
                "文章ID": "65490",
                "标题": "Cost-Effective Hyperparameter Optimization for Large Language Model\n  Generation Inference",
                "作者": " Chi Wang,  Susan Xueqing Liu,  Ahmed H. Awadallah",
                "发布日期": "2023-08-10",
                "摘要": "  Large Language Models (LLMs) have sparked significant interest in their\ngenerative capabilities, leading to the development of various commercial\napplications. The high cost of using the models drives application builders to\nmaximize the value of generation under a limited inference budget. This paper\npresents a study of optimizing inference hyperparameters such as the number of\nresponses, temperature and max tokens, which significantly affects the\nutility/cost of text generation. We design a framework named EcoOptiGen which\nleverages economical hyperparameter optimization and cost-based pruning.\nExperiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its\neffectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAML\nlibrary: \\url{https://aka.ms/autogen}.\n",
                "链接": "https://arxiv.org/abs/2303.04673"
            },
            {
                "文章ID": "123538",
                "标题": "LLM in a flash: Efficient Large Language Model Inference with Limited\n  Memory",
                "作者": " Keivan Alizadeh,  Iman Mirzadeh,  Dmitry Belenko,  Karen Khatamifard,  Minsik Cho,  Carlo C Del Mundo,  Mohammad Rastegari,  Mehrdad Farajtabar",
                "发布日期": "2023-12-20",
                "摘要": "  Large language models (LLMs) are central to modern natural language\nprocessing, delivering exceptional performance in various tasks. However, their\nintensive computational and memory requirements present challenges, especially\nfor devices with limited DRAM capacity. This paper tackles the challenge of\nefficiently running LLMs that exceed the available DRAM capacity by storing the\nmodel parameters on flash memory but bringing them on demand to DRAM. Our\nmethod involves constructing an inference cost model that harmonizes with the\nflash memory behavior, guiding us to optimize in two critical areas: reducing\nthe volume of data transferred from flash and reading data in larger, more\ncontiguous chunks. Within this flash memory-informed framework, we introduce\ntwo principal techniques. First, \"windowing'\" strategically reduces data\ntransfer by reusing previously activated neurons, and second, \"row-column\nbundling\", tailored to the sequential data access strengths of flash memory,\nincreases the size of data chunks read from flash memory. These methods\ncollectively enable running models up to twice the size of the available DRAM,\nwith a 4-5x and 20-25x increase in inference speed compared to naive loading\napproaches in CPU and GPU, respectively. Our integration of sparsity awareness,\ncontext-adaptive loading, and a hardware-oriented design paves the way for\neffective inference of LLMs on devices with limited memory.\n",
                "链接": "https://arxiv.org/abs/2312.11514"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月自然语言处理相关的文章。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找多语言情感分析的最新论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "82977",
                "标题": "UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of\n  Multilingual BERT for Low-resource Sentiment Analysis",
                "作者": " Dou Hu,  Lingwei Wei,  Yaxin Liu,  Wei Zhou,  Songlin Hu",
                "发布日期": "2023-06-05",
                "摘要": "  This paper describes our system designed for SemEval-2023 Task 12: Sentiment\nanalysis for African languages. The challenge faced by this task is the\nscarcity of labeled data and linguistic resources in low-resource settings. To\nalleviate these, we propose a generalized multilingual system SACL-XLMR for\nsentiment analysis on low-resource languages. Specifically, we design a\nlexicon-based multilingual BERT to facilitate language adaptation and\nsentiment-aware representation learning. Besides, we apply a supervised\nadversarial contrastive learning technique to learn sentiment-spread structured\nrepresentations and enhance model generalization. Our system achieved\ncompetitive results, largely outperforming baselines on both multilingual and\nzero-shot sentiment classification subtasks. Notably, the system obtained the\n1st rank on the zero-shot classification subtask in the official ranking.\nExtensive experiments demonstrate the effectiveness of our system.\n",
                "链接": "https://arxiv.org/abs/2306.01093"
            },
            {
                "文章ID": "95996",
                "标题": "Covid-19 Public Sentiment Analysis for Indian Tweets Classification",
                "作者": " Mohammad Maksood Akhter,  Devpriya Kanojia",
                "发布日期": "2023-08-14",
                "摘要": "  When any extraordinary event takes place in the world wide area, it is the\nsocial media that acts as the fastest carrier of the news along with the\nconsequences dealt with that event. One can gather much information through\nsocial networks regarding the sentiments, behavior, and opinions of the people.\nIn this paper, we focus mainly on sentiment analysis of twitter data of India\nwhich comprises of COVID-19 tweets. We show how Twitter data has been extracted\nand then run sentimental analysis queries on it. This is helpful to analyze the\ninformation in the tweets where opinions are highly unstructured,\nheterogeneous, and are either positive or negative or neutral in some cases.\n",
                "链接": "https://arxiv.org/abs/2308.06241"
            },
            {
                "文章ID": "85580",
                "标题": "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted\n  Sentiment Classification Benchmark",
                "作者": " Łukasz Augustyniak,  Szymon Woźniak,  Marcin Gruza,  Piotr Gramacki,  Krzysztof Rajda,  Mikołaj Morzy,  Tomasz Kajdanowicz",
                "发布日期": "2023-06-14",
                "摘要": "  Despite impressive advancements in multilingual corpora collection and model\ntraining, developing large-scale deployments of multilingual models still\npresents a significant challenge. This is particularly true for language tasks\nthat are culture-dependent. One such example is the area of multilingual\nsentiment analysis, where affective markers can be subtle and deeply ensconced\nin culture. This work presents the most extensive open massively multilingual\ncorpus of datasets for training sentiment models. The corpus consists of 79\nmanually selected datasets from over 350 datasets reported in the scientific\nliterature based on strict quality criteria. The corpus covers 27 languages\nrepresenting 6 language families. Datasets can be queried using several\nlinguistic and functional features. In addition, we present a multi-faceted\nsentiment classification benchmark summarizing hundreds of experiments\nconducted on different base models, training objectives, dataset collections,\nand fine-tuning strategies.\n",
                "链接": "https://arxiv.org/abs/2306.07902"
            },
            {
                "文章ID": "102692",
                "标题": "The ParlaSent multilingual training dataset for sentiment identification\n  in parliamentary proceedings",
                "作者": " Michal Mochtak,  Peter Rupnik,  Nikola Ljubešić",
                "发布日期": "2023-09-19",
                "摘要": "  Sentiments inherently drive politics. How we receive and process information\nplays an essential role in political decision-making, shaping our judgment with\nstrategic consequences both on the level of legislators and the masses. If\nsentiment plays such an important role in politics, how can we study and\nmeasure it systematically? The paper presents a new dataset of\nsentiment-annotated sentences, which are used in a series of experiments\nfocused on training a robust sentiment classifier for parliamentary\nproceedings. The paper also introduces the first domain-specific LLM for\npolitical science applications additionally pre-trained on 1.72 billion\ndomain-specific words from proceedings of 27 European parliaments. We present\nexperiments demonstrating how the additional pre-training of LLM on\nparliamentary data can significantly improve the model downstream performance\non the domain-specific tasks, in our case, sentiment detection in parliamentary\nproceedings. We further show that multilingual models perform very well on\nunseen languages and that additional data from other languages significantly\nimproves the target parliament's results. The paper makes an important\ncontribution to multiple domains of social sciences and bridges them with\ncomputer science and computational linguistics. Lastly, it sets up a more\nrobust approach to sentiment analysis of political texts in general, which\nallows scholars to study political sentiment from a comparative perspective\nusing standardized tools and techniques.\n",
                "链接": "https://arxiv.org/abs/2309.09783"
            },
            {
                "文章ID": "87606",
                "标题": "L3Cube-MahaSent-MD: A Multi-domain Marathi Sentiment Analysis Dataset\n  and Transformer Models",
                "作者": " Aabha Pingle,  Aditya Vyawahare,  Isha Joshi,  Rahul Tangsali,  Raviraj Joshi",
                "发布日期": "2023-06-27",
                "摘要": "  The exploration of sentiment analysis in low-resource languages, such as\nMarathi, has been limited due to the availability of suitable datasets. In this\nwork, we present L3Cube-MahaSent-MD, a multi-domain Marathi sentiment analysis\ndataset, with four different domains - movie reviews, general tweets, TV show\nsubtitles, and political tweets. The dataset consists of around 60,000 manually\ntagged samples covering 3 distinct sentiments - positive, negative, and\nneutral. We create a sub-dataset for each domain comprising 15k samples. The\nMahaSent-MD is the first comprehensive multi-domain sentiment analysis dataset\nwithin the Indic sentiment landscape. We fine-tune different monolingual and\nmultilingual BERT models on these datasets and report the best accuracy with\nthe MahaBERT model. We also present an extensive in-domain and cross-domain\nanalysis thus highlighting the need for low-resource multi-domain datasets. The\ndata and models are available at https://github.com/l3cube-pune/MarathiNLP .\n",
                "链接": "https://arxiv.org/abs/2306.13888"
            },
            {
                "文章ID": "87574",
                "标题": "An analysis of vaccine-related sentiments from development to deployment\n  of COVID-19 vaccines",
                "作者": " Rohitash Chandra,  Jayesh Sonawane,  Janhavi Lande,  Cathy Yu",
                "发布日期": "2023-06-27",
                "摘要": "  Anti-vaccine sentiments have been well-known and reported throughout the\nhistory of viral outbreaks and vaccination programmes. The COVID-19 pandemic\nhad fear and uncertainty about vaccines which has been well expressed on social\nmedia platforms such as Twitter. We analyse Twitter sentiments from the\nbeginning of the COVID-19 pandemic and study the public behaviour during the\nplanning, development and deployment of vaccines expressed in tweets worldwide\nusing a sentiment analysis framework via deep learning models. In this way, we\nprovide visualisation and analysis of anti-vaccine sentiments over the course\nof the COVID-19 pandemic. Our results show a link between the number of tweets,\nthe number of cases, and the change in sentiment polarity scores during major\nwaves of COVID-19 cases. We also found that the first half of the pandemic had\ndrastic changes in the sentiment polarity scores that later stabilised which\nimplies that the vaccine rollout had an impact on the nature of discussions on\nsocial media.\n",
                "链接": "https://arxiv.org/abs/2306.13797"
            },
            {
                "文章ID": "121053",
                "标题": "Deep Emotions Across Languages: A Novel Approach for Sentiment\n  Propagation in Multilingual WordNets",
                "作者": " Jan Kocoń",
                "发布日期": "2023-12-11",
                "摘要": "  Sentiment analysis involves using WordNets enriched with emotional metadata,\nwhich are valuable resources. However, manual annotation is time-consuming and\nexpensive, resulting in only a few WordNet Lexical Units being annotated. This\npaper introduces two new techniques for automatically propagating sentiment\nannotations from a partially annotated WordNet to its entirety and to a WordNet\nin a different language: Multilingual Structured Synset Embeddings (MSSE) and\nCross-Lingual Deep Neural Sentiment Propagation (CLDNS). We evaluated the\nproposed MSSE+CLDNS method extensively using Princeton WordNet and Polish\nWordNet, which have many inter-lingual relations. Our results show that the\nMSSE+CLDNS method outperforms existing propagation methods, indicating its\neffectiveness in enriching WordNets with emotional metadata across multiple\nlanguages. This work provides a solid foundation for large-scale, multilingual\nsentiment analysis and is valuable for academic research and practical\napplications.\n",
                "链接": "https://arxiv.org/abs/2312.04715"
            },
            {
                "文章ID": "99734",
                "标题": "Will Sentiment Analysis Need Subculture? A New Data Augmentation\n  Approach",
                "作者": " Zhenhua Wang,  Simin He,  Guang Xu,  Ming Ren",
                "发布日期": "2023-09-04",
                "摘要": "  The renowned proverb that \"The pen is mightier than the sword\" underscores\nthe formidable influence wielded by text expressions in shaping sentiments.\nIndeed, well-crafted written can deeply resonate within cultures, conveying\nprofound sentiments. Nowadays, the omnipresence of the Internet has fostered a\nsubculture that congregates around the contemporary milieu. The subculture\nartfully articulates the intricacies of human feelings by ardently pursuing the\nallure of novelty, a fact that cannot be disregarded in the sentiment analysis.\nThis paper strives to enrich data through the lens of subculture, to address\nthe insufficient training data faced by sentiment analysis. To this end, a new\napproach of subculture-based data augmentation (SCDA) is proposed, which\nengenders six enhanced texts for each training text by leveraging the creation\nof six diverse subculture expression generators. The extensive experiments\nattest to the effectiveness and potential of SCDA. The results also shed light\non the phenomenon that disparate subculture expressions elicit varying degrees\nof sentiment stimulation. Moreover, an intriguing conjecture arises, suggesting\nthe linear reversibility of certain subculture expressions. It is our fervent\naspiration that this study serves as a catalyst in fostering heightened\nperceptiveness towards the tapestry of information, sentiment and culture,\nthereby enriching our collective understanding.\n",
                "链接": "https://arxiv.org/abs/2309.00178"
            },
            {
                "文章ID": "116726",
                "标题": "A Comprehensive Review on Sentiment Analysis: Tasks, Approaches and\n  Applications",
                "作者": " Sudhanshu Kumar,  Partha Pratim Roy,  Debi Prosad Dogra,  Byung-Gyu Kim",
                "发布日期": "2023-11-21",
                "摘要": "  Sentiment analysis (SA) is an emerging field in text mining. It is the\nprocess of computationally identifying and categorizing opinions expressed in a\npiece of text over different social media platforms. Social media plays an\nessential role in knowing the customer mindset towards a product, services, and\nthe latest market trends. Most organizations depend on the customer's response\nand feedback to upgrade their offered products and services. SA or opinion\nmining seems to be a promising research area for various domains. It plays a\nvital role in analyzing big data generated daily in structured and unstructured\nformats over the internet. This survey paper defines sentiment and its recent\nresearch and development in different domains, including voice, images, videos,\nand text. The challenges and opportunities of sentiment analysis are also\ndiscussed in the paper.\n  \\keywords{Sentiment Analysis, Machine Learning, Lexicon-based approach, Deep\nLearning, Natural Language Processing}\n",
                "链接": "https://arxiv.org/abs/2311.11250"
            },
            {
                "文章ID": "122981",
                "标题": "Aspect-Level Sentiment Analysis Based on Knowledge Graph and Recurrent\n  Attention Network",
                "作者": " Kavita Sharma,  Ritu Patel,  Sunita Iyer",
                "发布日期": "2023-12-19",
                "摘要": "  In this paper, we propose a novel method to enhance sentiment analysis by\naddressing the challenge of context-specific word meanings. It combines the\nadvantages of a bidirectional long short-term memory network (Bi-LSTM) with a\nknowledge graph's synonym data. This synergy leverages a dynamic attention\nmechanism to develop a knowledge-driven state vector. For classifying\nsentiments linked to specific aspects, the approach constructs a memory bank\nintegrating positional data. This data is then analyzed using a multi-layer\ngated recurrent unit (GRU) to pinpoint sentiment characteristics related to\nspecific aspect terms. Tests on three widely available datasets demonstrate\nthis method's superior performance in sentiment classification.\n",
                "链接": "https://arxiv.org/abs/2312.10048"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于NLP领域的持续性学习论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "108574",
                "标题": "PerturbScore: Connecting Discrete and Continuous Perturbations in NLP",
                "作者": " Linyang Li,  Ke Ren,  Yunfan Shao,  Pengyu Wang,  Xipeng Qiu",
                "发布日期": "2023-10-16",
                "摘要": "  With the rapid development of neural network applications in NLP, model\nrobustness problem is gaining more attention. Different from computer vision,\nthe discrete nature of texts makes it more challenging to explore robustness in\nNLP. Therefore, in this paper, we aim to connect discrete perturbations with\ncontinuous perturbations, therefore we can use such connections as a bridge to\nhelp understand discrete perturbations in NLP models. Specifically, we first\nexplore how to connect and measure the correlation between discrete\nperturbations and continuous perturbations. Then we design a regression task as\na PerturbScore to learn the correlation automatically. Through experimental\nresults, we find that we can build a connection between discrete and continuous\nperturbations and use the proposed PerturbScore to learn such correlation,\nsurpassing previous methods used in discrete perturbation measuring. Further,\nthe proposed PerturbScore can be well generalized to different datasets,\nperturbation methods, indicating that we can use it as a powerful tool to study\nmodel robustness in NLP.\n",
                "链接": "https://arxiv.org/abs/2310.08889"
            },
            {
                "文章ID": "59134",
                "标题": "Continuous Spatiotemporal Transformers",
                "作者": " Antonio H. de O. Fonseca,  Emanuele Zappala,  Josue Ortega Caro,  David van Dijk",
                "发布日期": "2023-08-01",
                "摘要": "  Modeling spatiotemporal dynamical systems is a fundamental challenge in\nmachine learning. Transformer models have been very successful in NLP and\ncomputer vision where they provide interpretable representations of data.\nHowever, a limitation of transformers in modeling continuous dynamical systems\nis that they are fundamentally discrete time and space models and thus have no\nguarantees regarding continuous sampling. To address this challenge, we present\nthe Continuous Spatiotemporal Transformer (CST), a new transformer architecture\nthat is designed for the modeling of continuous systems. This new framework\nguarantees a continuous and smooth output via optimization in Sobolev space. We\nbenchmark CST against traditional transformers as well as other spatiotemporal\ndynamics modeling methods and achieve superior performance in a number of tasks\non synthetic and real systems, including learning brain dynamics from calcium\nimaging data.\n",
                "链接": "https://arxiv.org/abs/2301.13338"
            },
            {
                "文章ID": "99470",
                "标题": "Deep Inductive Logic Programming meets Reinforcement Learning",
                "作者": "University of Edinburgh  Andreas Bueff, University of\n  Edinburgh  Vaishak Belle",
                "发布日期": "2023-09-01",
                "摘要": "  One approach to explaining the hierarchical levels of understanding within a\nmachine learning model is the symbolic method of inductive logic programming\n(ILP), which is data efficient and capable of learning first-order logic rules\nthat can entail data behaviour. A differentiable extension to ILP, so-called\ndifferentiable Neural Logic (dNL) networks, are able to learn Boolean functions\nas their neural architecture includes symbolic reasoning. We propose an\napplication of dNL in the field of Relational Reinforcement Learning (RRL) to\naddress dynamic continuous environments. This represents an extension of\nprevious work in applying dNL-based ILP in RRL settings, as our proposed model\nupdates the architecture to enable it to solve problems in continuous RL\nenvironments. The goal of this research is to improve upon current ILP methods\nfor use in RRL by incorporating non-linear continuous predicates, allowing RRL\nagents to reason and make decisions in dynamic and continuous environments.\n",
                "链接": "https://arxiv.org/abs/2308.16210"
            },
            {
                "文章ID": "54041",
                "标题": "Multi-Scales Data Augmentation Approach In Natural Language Inference\n  For Artifacts Mitigation And Pre-Trained Model Optimization",
                "作者": " Zhenyuan Lu",
                "发布日期": "2023-03-20",
                "摘要": "  Machine learning models can reach high performance on benchmark natural\nlanguage processing (NLP) datasets but fail in more challenging settings. We\nstudy this issue when a pre-trained model learns dataset artifacts in natural\nlanguage inference (NLI), the topic of studying the logical relationship\nbetween a pair of text sequences. We provide a variety of techniques for\nanalyzing and locating dataset artifacts inside the crowdsourced Stanford\nNatural Language Inference (SNLI) corpus. We study the stylistic pattern of\ndataset artifacts in the SNLI. To mitigate dataset artifacts, we employ a\nunique multi-scale data augmentation technique with two distinct frameworks: a\nbehavioral testing checklist at the sentence level and lexical synonym criteria\nat the word level. Specifically, our combination method enhances our model's\nresistance to perturbation testing, enabling it to continuously outperform the\npre-trained baseline.\n",
                "链接": "https://arxiv.org/abs/2212.08756"
            },
            {
                "文章ID": "82147",
                "标题": "A generalized framework to predict continuous scores from medical\n  ordinal labels",
                "作者": " Katharina V. Hoebel,  Andreanne Lemay,  John Peter Campbell,  Susan Ostmo,  Michael F. Chiang,  Christopher P. Bridge,  Matthew D. Li,  Praveer Singh,  Aaron S. Coyner,  Jayashree Kalpathy-Cramer",
                "发布日期": "2023-05-31",
                "摘要": "  Many variables of interest in clinical medicine, like disease severity, are\nrecorded using discrete ordinal categories such as normal/mild/moderate/severe.\nThese labels are used to train and evaluate disease severity prediction models.\nHowever, ordinal categories represent a simplification of an underlying\ncontinuous severity spectrum. Using continuous scores instead of ordinal\ncategories is more sensitive to detecting small changes in disease severity\nover time. Here, we present a generalized framework that accurately predicts\ncontinuously valued variables using only discrete ordinal labels during model\ndevelopment. We found that for three clinical prediction tasks, models that\ntake the ordinal relationship of the training labels into account outperformed\nconventional multi-class classification models. Particularly the continuous\nscores generated by ordinal classification and regression models showed a\nsignificantly higher correlation with expert rankings of disease severity and\nlower mean squared errors compared to the multi-class classification models.\nFurthermore, the use of MC dropout significantly improved the ability of all\nevaluated deep learning approaches to predict continuously valued scores that\ntruthfully reflect the underlying continuous target variable. We showed that\naccurate continuously valued predictions can be generated even if the model\ndevelopment only involves discrete ordinal labels. The novel framework has been\nvalidated on three different clinical prediction tasks and has proven to bridge\nthe gap between discrete ordinal labels and the underlying continuously valued\nvariables.\n",
                "链接": "https://arxiv.org/abs/2305.19097"
            },
            {
                "文章ID": "60991",
                "标题": "Step by Step Loss Goes Very Far: Multi-Step Quantization for Adversarial\n  Text Attacks",
                "作者": " Piotr Gaiński,  Klaudia Bałazy",
                "发布日期": "2023-02-13",
                "摘要": "  We propose a novel gradient-based attack against transformer-based language\nmodels that searches for an adversarial example in a continuous space of token\nprobabilities. Our algorithm mitigates the gap between adversarial loss for\ncontinuous and discrete text representations by performing multi-step\nquantization in a quantization-compensation loop. Experiments show that our\nmethod significantly outperforms other approaches on various natural language\nprocessing (NLP) tasks.\n",
                "链接": "https://arxiv.org/abs/2302.05120"
            },
            {
                "文章ID": "74807",
                "标题": "Prompt Engineering for Healthcare: Methodologies and Applications",
                "作者": " Jiaqi Wang,  Enze Shi,  Sigang Yu,  Zihao Wu,  Chong Ma,  Haixing Dai,  Qiushi Yang,  Yanqing Kang,  Jinru Wu,  Huawen Hu,  Chenxi Yue,  Haiyang Zhang,  Yiheng Liu,  Xiang Li,  Bao Ge,  Dajiang Zhu,  Yixuan Yuan,  Dinggang Shen,  Tianming Liu,  Shu Zhang",
                "发布日期": "2023-05-01",
                "摘要": "  This review will introduce the latest advances in prompt engineering in the\nfield of natural language processing (NLP) for the medical domain. First, we\nwill provide a brief overview of the development of prompt engineering and\nemphasize its significant contributions to healthcare NLP applications such as\nquestion-answering systems, text summarization, and machine translation. With\nthe continuous improvement of general large language models, the importance of\nprompt engineering in the healthcare domain is becoming increasingly prominent.\nThe aim of this article is to provide useful resources and bridges for\nhealthcare NLP researchers to better explore the application of prompt\nengineering in this field. We hope that this review can provide new ideas and\ninspire ample possibilities for research and application in medical NLP.\n",
                "链接": "https://arxiv.org/abs/2304.14670"
            },
            {
                "文章ID": "94486",
                "标题": "XNLP: An Interactive Demonstration System for Universal Structured NLP",
                "作者": " Hao Fei,  Meishan Zhang,  Min Zhang,  Tat-Seng Chua",
                "发布日期": "2023-08-04",
                "摘要": "  Structured Natural Language Processing (XNLP) is an important subset of NLP\nthat entails understanding the underlying semantic or syntactic structure of\ntexts, which serves as a foundational component for many downstream\napplications. Despite certain recent efforts to explore universal solutions for\nspecific categories of XNLP tasks, a comprehensive and effective approach for\nunifying all XNLP tasks long remains underdeveloped. In the meanwhile, while\nXNLP demonstration systems are vital for researchers exploring various XNLP\ntasks, existing platforms can be limited to, e.g., supporting few XNLP tasks,\nlacking interactivity and universalness. To this end, we propose an advanced\nXNLP demonstration platform, where we propose leveraging LLM to achieve\nuniversal XNLP, with one model for all with high generalizability. Overall, our\nsystem advances in multiple aspects, including universal XNLP modeling, high\nperformance, interpretability, scalability, and interactivity, providing a\nunified platform for exploring diverse XNLP tasks in the community. XNLP is\nonline: https://xnlp.haofei.vip\n",
                "链接": "https://arxiv.org/abs/2308.01846"
            },
            {
                "文章ID": "107263",
                "标题": "Continuous Invariance Learning",
                "作者": " Yong Lin,  Fan Zhou,  Lu Tan,  Lintao Ma,  Jiameng Liu,  Yansu He,  Yuan Yuan,  Yu Liu,  James Zhang,  Yujiu Yang,  Hao Wang",
                "发布日期": "2023-10-10",
                "摘要": "  Invariance learning methods aim to learn invariant features in the hope that\nthey generalize under distributional shifts. Although many tasks are naturally\ncharacterized by continuous domains, current invariance learning techniques\ngenerally assume categorically indexed domains. For example, auto-scaling in\ncloud computing often needs a CPU utilization prediction model that generalizes\nacross different times (e.g., time of a day and date of a year), where `time'\nis a continuous domain index. In this paper, we start by theoretically showing\nthat existing invariance learning methods can fail for continuous domain\nproblems. Specifically, the naive solution of splitting continuous domains into\ndiscrete ones ignores the underlying relationship among domains, and therefore\npotentially leads to suboptimal performance. To address this challenge, we then\npropose Continuous Invariance Learning (CIL), which extracts invariant features\nacross continuously indexed domains. CIL is a novel adversarial procedure that\nmeasures and controls the conditional independence between the labels and\ncontinuous domain indices given the extracted features. Our theoretical\nanalysis demonstrates the superiority of CIL over existing invariance learning\nmethods. Empirical results on both synthetic and real-world datasets (including\ndata collected from production systems) show that CIL consistently outperforms\nstrong baselines among all the tasks.\n",
                "链接": "https://arxiv.org/abs/2310.05348"
            },
            {
                "文章ID": "105892",
                "标题": "Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across\n  Language Models",
                "作者": " Zijun Wu,  Yongkang Wu,  Lili Mou",
                "发布日期": "2023-10-04",
                "摘要": "  Prompt tuning in natural language processing (NLP) has become an increasingly\npopular method for adapting large language models to specific tasks. However,\nthe transferability of these prompts, especially continuous prompts, between\ndifferent models remains a challenge. In this work, we propose a zero-shot\ncontinuous prompt transfer method, where source prompts are encoded into\nrelative space and the corresponding target prompts are searched for\ntransferring to target models. Experimental results confirm the effectiveness\nof our method, showing that 'task semantics' in continuous prompts can be\ngeneralized across various language models. Moreover, we find that combining\n'task semantics' from multiple source models can further enhance the\ngeneralizability of transfer.\n",
                "链接": "https://arxiv.org/abs/2310.01691"
            }
        ]
    },
    {
        "question": {
            "question": "找一下最近关于大模型评测的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "110865",
                "标题": "Branch-Solve-Merge Improves Large Language Model Evaluation and\n  Generation",
                "作者": " Swarnadeep Saha,  Omer Levy,  Asli Celikyilmaz,  Mohit Bansal,  Jason Weston,  Xian Li",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) are frequently used for multi-faceted language\ngeneration and evaluation tasks that involve satisfying intricate user\nconstraints or taking into account multiple aspects and criteria. However,\ntheir performance can fall short, due to the model's lack of coherence and\ninability to plan and decompose the problem. We propose Branch-Solve-Merge\n(BSM), a Large Language Model program (Schlag et al., 2023) for tackling such\nchallenging natural language tasks. It consists of branch, solve, and merge\nmodules that are parameterized with specific prompts to the base LLM. These\nthree modules plan a decomposition of the task into multiple parallel\nsub-tasks, independently solve them, and fuse the solutions to the sub-tasks.\nWe apply our method to the tasks of LLM response evaluation and constrained\ntext generation and evaluate its effectiveness with multiple LLMs, including\nVicuna, LLaMA-2-chat, and GPT-4. BSM improves the evaluation correctness and\nconsistency for each LLM by enhancing human-LLM agreement by up to 26%,\nreducing length and pairwise position biases by up to 50%, and allowing\nLLaMA-2-chat to match or outperform GPT-4 on most domains. On the constraint\nstory generation task, BSM improves the coherence of the stories while also\nimproving constraint satisfaction by 12%.\n",
                "链接": "https://arxiv.org/abs/2310.15123"
            },
            {
                "文章ID": "95277",
                "标题": "AgentSims: An Open-Source Sandbox for Large Language Model Evaluation",
                "作者": " Jiaju Lin,  Haoran Zhao,  Aochi Zhang,  Yiting Wu,  Huqiuyue Ping,  Qin Chen",
                "发布日期": "2023-08-09",
                "摘要": "  With ChatGPT-like large language models (LLM) prevailing in the community,\nhow to evaluate the ability of LLMs is an open question. Existing evaluation\nmethods suffer from following shortcomings: (1) constrained evaluation\nabilities, (2) vulnerable benchmarks, (3) unobjective metrics. We suggest that\ntask-based evaluation, where LLM agents complete tasks in a simulated\nenvironment, is a one-for-all solution to solve above problems. We present\nAgentSims, an easy-to-use infrastructure for researchers from all disciplines\nto test the specific capacities they are interested in. Researchers can build\ntheir evaluation tasks by adding agents and buildings on an interactive GUI or\ndeploy and test new support mechanisms, i.e. memory, planning and tool-use\nsystems, by a few lines of codes. Our demo is available at\nhttps://agentsims.com .\n",
                "链接": "https://arxiv.org/abs/2308.04026"
            },
            {
                "文章ID": "84705",
                "标题": "PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark\n  for Finance",
                "作者": " Qianqian Xie,  Weiguang Han,  Xiao Zhang,  Yanzhao Lai,  Min Peng,  Alejandro Lopez-Lira,  Jimin Huang",
                "发布日期": "2023-06-12",
                "摘要": "  Although large language models (LLMs) has shown great performance on natural\nlanguage processing (NLP) in the financial domain, there are no publicly\navailable financial tailtored LLMs, instruction tuning datasets, and evaluation\nbenchmarks, which is critical for continually pushing forward the open-source\ndevelopment of financial artificial intelligence (AI). This paper introduces\nPIXIU, a comprehensive framework including the first financial LLM based on\nfine-tuning LLaMA with instruction data, the first instruction data with 136K\ndata samples to support the fine-tuning, and an evaluation benchmark with 5\ntasks and 9 datasets. We first construct the large-scale multi-task instruction\ndata considering a variety of financial tasks, financial document types, and\nfinancial data modalities. We then propose a financial LLM called FinMA by\nfine-tuning LLaMA with the constructed dataset to be able to follow\ninstructions for various financial tasks. To support the evaluation of\nfinancial LLMs, we propose a standardized benchmark that covers a set of\ncritical financial tasks, including five financial NLP tasks and one financial\nprediction task. With this benchmark, we conduct a detailed analysis of FinMA\nand several existing LLMs, uncovering their strengths and weaknesses in\nhandling critical financial tasks. The model, datasets, benchmark, and\nexperimental results are open-sourced to facilitate future research in\nfinancial AI.\n",
                "链接": "https://arxiv.org/abs/2306.05443"
            },
            {
                "文章ID": "120482",
                "标题": "A Hardware Evaluation Framework for Large Language Model Inference",
                "作者": " Hengrui Zhang,  August Ning,  Rohan Prabhakar,  David Wentzlaff",
                "发布日期": "2023-12-07",
                "摘要": "  The past year has witnessed the increasing popularity of Large Language\nModels (LLMs). Their unprecedented scale and associated high hardware cost have\nimpeded their broader adoption, calling for efficient hardware designs. With\nthe large hardware needed to simply run LLM inference, evaluating different\nhardware designs becomes a new bottleneck.\n  This work introduces LLMCompass, a hardware evaluation framework for LLM\ninference workloads. LLMCompass is fast, accurate, versatile, and able to\ndescribe and evaluate different hardware designs. LLMCompass includes a mapper\nto automatically find performance-optimal mapping and scheduling. It also\nincorporates an area-based cost model to help architects reason about their\ndesign choices. Compared to real-world hardware, LLMCompass' estimated latency\nachieves an average 10.4% error rate across various operators with various\ninput sizes and an average 4.1% error rate for LLM inference. With LLMCompass,\nsimulating a 4-NVIDIA A100 GPU node running GPT-3 175B inference can be done\nwithin 16 minutes on commodity hardware, including 26,400 rounds of the\nmapper's parameter search.\n  With the aid of LLMCompass, this work draws architectural implications and\nexplores new cost-effective hardware designs. By reducing the compute\ncapability or replacing High Bandwidth Memory (HBM) with traditional DRAM,\nthese new designs can achieve as much as 3.41x improvement in performance/cost\ncompared to an NVIDIA A100, making them promising choices for democratizing\nLLMs.\n  LLMCompass is planned to be fully open-source.\n",
                "链接": "https://arxiv.org/abs/2312.03134"
            },
            {
                "文章ID": "104015",
                "标题": "EvalLM: Interactive Evaluation of Large Language Model Prompts on\n  User-Defined Criteria",
                "作者": " Tae Soo Kim,  Yoonjoo Lee,  Jamin Shin,  Young-Ho Kim,  Juho Kim",
                "发布日期": "2023-09-26",
                "摘要": "  By simply composing prompts, developers can prototype novel generative\napplications with Large Language Models (LLMs). To refine prototypes into\nproducts, however, developers must iteratively revise prompts by evaluating\noutputs to diagnose weaknesses. Formative interviews (N=8) revealed that\ndevelopers invest significant effort in manually evaluating outputs as they\nassess context-specific and subjective criteria. We present EvalLM, an\ninteractive system for iteratively refining prompts by evaluating multiple\noutputs on user-defined criteria. By describing criteria in natural language,\nusers can employ the system's LLM-based evaluator to get an overview of where\nprompts excel or fail, and improve these based on the evaluator's feedback. A\ncomparative study (N=12) showed that EvalLM, when compared to manual\nevaluation, helped participants compose more diverse criteria, examine twice as\nmany outputs, and reach satisfactory prompts with 59% fewer revisions. Beyond\nprompts, our work can be extended to augment model evaluation and alignment in\nspecific application contexts.\n",
                "链接": "https://arxiv.org/abs/2309.13633"
            },
            {
                "文章ID": "119288",
                "标题": "CritiqueLLM: Scaling LLM-as-Critic for Effective and Explainable\n  Evaluation of Large Language Model Generation",
                "作者": " Pei Ke,  Bosi Wen,  Zhuoer Feng,  Xiao Liu,  Xuanyu Lei,  Jiale Cheng,  Shengyuan Wang,  Aohan Zeng,  Yuxiao Dong,  Hongning Wang,  Jie Tang,  Minlie Huang",
                "发布日期": "2023-12-01",
                "摘要": "  Since the natural language processing (NLP) community started to make large\nlanguage models (LLMs), such as GPT-4, act as a critic to evaluate the quality\nof generated texts, most of them only train a critique generation model of a\nspecific scale on specific datasets. We argue that a comprehensive\ninvestigation on the key factor of LLM-based evaluation models, such as scaling\nproperties, is lacking, so that it is still inconclusive whether these models\nhave potential to replace GPT-4's evaluation in practical scenarios. In this\npaper, we propose a new critique generation model called CritiqueLLM, which\nincludes a dialogue-based prompting method for high-quality referenced /\nreference-free evaluation data. Experimental results show that our model can\nachieve comparable evaluation performance to GPT-4 especially in system-level\ncorrelations, and even outperform GPT-4 in 3 out of 8 tasks in a challenging\nreference-free setting. We conduct detailed analysis to show promising scaling\nproperties of our model in the quality of generated critiques. We also\ndemonstrate that our generated critiques can act as scalable feedback to\ndirectly improve the generation quality of LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.18702"
            },
            {
                "文章ID": "98470",
                "标题": "SciEval: A Multi-Level Large Language Model Evaluation Benchmark for\n  Scientific Research",
                "作者": " Liangtai Sun,  Yang Han,  Zihan Zhao,  Da Ma,  Zhennan Shen,  Baocai Chen,  Lu Chen,  Kai Yu",
                "发布日期": "2023-08-28",
                "摘要": "  Recently, there has been growing interest in using Large Language Models\n(LLMs) for scientific research. Numerous benchmarks have been proposed to\nevaluate the ability of LLMs for scientific research. However, current\nbenchmarks are mostly based on pre-collected objective questions. This design\nsuffers from data leakage problem and lacks the evaluation of subjective Q/A\nability. In this paper, we propose SciEval, a comprehensive and\nmulti-disciplinary evaluation benchmark to address these issues. Based on\nBloom's taxonomy, SciEval covers four dimensions to systematically evaluate\nscientific research ability. In particular, we design a \"dynamic\" subset based\non scientific principles to prevent evaluation from potential data leakage.\nBoth objective and subjective questions are included in SciEval. These\ncharacteristics make SciEval a more effective benchmark for scientific research\nability evaluation of LLMs. Comprehensive experiments on most advanced LLMs\nshow that, although GPT-4 achieves SOTA performance compared to other LLMs,\nthere is still substantial room for improvement, especially for dynamic\nquestions. The data and codes are now publicly available.\n",
                "链接": "https://arxiv.org/abs/2308.13149"
            },
            {
                "文章ID": "109754",
                "标题": "Pseudointelligence: A Unifying Framework for Language Model Evaluation",
                "作者": " Shikhar Murty,  Orr Paradise,  Pratyusha Sharma",
                "发布日期": "2023-10-19",
                "摘要": "  With large language models surpassing human performance on an increasing\nnumber of benchmarks, we must take a principled approach for targeted\nevaluation of model capabilities. Inspired by pseudorandomness, we propose\npseudointelligence, which captures the maxim that \"(perceived) intelligence\nlies in the eye of the beholder\". That is, that claims of intelligence are\nmeaningful only when their evaluator is taken into account. Concretely, we\npropose a complexity-theoretic framework of model evaluation cast as a dynamic\ninteraction between a model and a learned evaluator. We demonstrate that this\nframework can be used to reason about two case studies in language model\nevaluation, as well as analyze existing evaluation methods.\n",
                "链接": "https://arxiv.org/abs/2310.12135"
            },
            {
                "文章ID": "113897",
                "标题": "QualEval: Qualitative Evaluation for Model Improvement",
                "作者": " Vishvak Murahari,  Ameet Deshpande,  Peter Clark,  Tanmay Rajpurohit,  Ashish Sabharwal,  Karthik Narasimhan,  Ashwin Kalyan",
                "发布日期": "2023-11-07",
                "摘要": "  Quantitative evaluation metrics have traditionally been pivotal in gauging\nthe advancements of artificial intelligence systems, including large language\nmodels (LLMs). However, these metrics have inherent limitations. Given the\nintricate nature of real-world tasks, a single scalar to quantify and compare\nis insufficient to capture the fine-grained nuances of model behavior. Metrics\nserve only as a way to compare and benchmark models, and do not yield\nactionable diagnostics, thus making the model improvement process challenging.\nModel developers find themselves amid extensive manual efforts involving\nsifting through vast datasets and attempting hit-or-miss adjustments to\ntraining data or setups. In this work, we address the shortcomings of\nquantitative metrics by proposing QualEval, which augments quantitative scalar\nmetrics with automated qualitative evaluation as a vehicle for model\nimprovement. QualEval uses a powerful LLM reasoner and our novel flexible\nlinear programming solver to generate human-readable insights that when\napplied, accelerate model improvement. The insights are backed by a\ncomprehensive dashboard with fine-grained visualizations and\nhuman-interpretable analyses. We corroborate the faithfulness of QualEval by\ndemonstrating that leveraging its insights, for example, improves the absolute\nperformance of the Llama 2 model by up to 15% points relative on a challenging\ndialogue task (DialogSum) when compared to baselines. QualEval successfully\nincreases the pace of model development, thus in essence serving as a\ndata-scientist-in-a-box. Given the focus on critiquing and improving current\nevaluation metrics, our method serves as a refreshingly new technique for both\nmodel evaluation and improvement.\n",
                "链接": "https://arxiv.org/abs/2311.02807"
            },
            {
                "文章ID": "107304",
                "标题": "Establishing Trustworthiness: Rethinking Tasks and Model Evaluation",
                "作者": " Robert Litschko,  Max Müller-Eberstein,  Rob van der Goot,  Leon Weber,  Barbara Plank",
                "发布日期": "2023-10-24",
                "摘要": "  Language understanding is a multi-faceted cognitive capability, which the\nNatural Language Processing (NLP) community has striven to model\ncomputationally for decades. Traditionally, facets of linguistic intelligence\nhave been compartmentalized into tasks with specialized model architectures and\ncorresponding evaluation protocols. With the advent of large language models\n(LLMs) the community has witnessed a dramatic shift towards general purpose,\ntask-agnostic approaches powered by generative models. As a consequence, the\ntraditional compartmentalized notion of language tasks is breaking down,\nfollowed by an increasing challenge for evaluation and analysis. At the same\ntime, LLMs are being deployed in more real-world scenarios, including\npreviously unforeseen zero-shot setups, increasing the need for trustworthy and\nreliable systems. Therefore, we argue that it is time to rethink what\nconstitutes tasks and model evaluation in NLP, and pursue a more holistic view\non language, placing trustworthiness at the center. Towards this goal, we\nreview existing compartmentalized approaches for understanding the origins of a\nmodel's functional capacity, and provide recommendations for more multi-faceted\nevaluation protocols.\n",
                "链接": "https://arxiv.org/abs/2310.05442"
            }
        ]
    },
    {
        "question": {
            "question": "近一个月与多模态大模型相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找近六个月工具学习评测数据集的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "108993",
                "标题": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
                "作者": " Alon Jacovi,  Avi Caciularu,  Jonathan Herzig,  Roee Aharoni,  Bernd Bohnet,  Mor Geva",
                "发布日期": "2023-12-29",
                "摘要": "  A growing area of research investigates augmenting language models with tools\n(e.g., search engines, calculators) to overcome their shortcomings (e.g.,\nmissing or incorrect knowledge, incorrect logical inferences). Various few-shot\ntool-usage strategies have been proposed. However, there is no systematic and\nfair comparison across different strategies, or between these strategies and\nstrong baselines that do not leverage tools. We conduct an extensive empirical\nanalysis, finding that (1) across various datasets, example difficulty levels,\nand models, strong no-tool baselines are competitive to tool-assisted\nstrategies, implying that effectively using tools with in-context\ndemonstrations is a difficult unsolved problem; (2) for knowledge-retrieval\ntasks, strategies that *refine* incorrect outputs with tools outperform\nstrategies that retrieve relevant information *ahead of* or *during\ngeneration*; (3) tool-assisted strategies are expensive in the number of tokens\nthey require to work -- incurring additional costs by orders of magnitude --\nwhich does not translate into significant improvement in performance. Overall,\nour findings suggest that few-shot tool integration is still an open challenge,\nemphasizing the need for comprehensive evaluations of future strategies to\naccurately assess their *benefits* and *costs*.\n",
                "链接": "https://arxiv.org/abs/2310.10062"
            },
            {
                "文章ID": "122009",
                "标题": "CholecTrack20: A Dataset for Multi-Class Multiple Tool Tracking in\n  Laparoscopic Surgery",
                "作者": " Chinedu Innocent Nwoye,  Kareem Elgohary,  Anvita Srinivas,  Fauzan Zaid,  Joël L. Lavanchy,  Nicolas Padoy",
                "发布日期": "2023-12-13",
                "摘要": "  Tool tracking in surgical videos is vital in computer-assisted intervention\nfor tasks like surgeon skill assessment, safety zone estimation, and\nhuman-machine collaboration during minimally invasive procedures. The lack of\nlarge-scale datasets hampers Artificial Intelligence implementation in this\ndomain. Current datasets exhibit overly generic tracking formalization, often\nlacking surgical context: a deficiency that becomes evident when tools move out\nof the camera's scope, resulting in rigid trajectories that hinder realistic\nsurgical representation. This paper addresses the need for a more precise and\nadaptable tracking formalization tailored to the intricacies of endoscopic\nprocedures by introducing CholecTrack20, an extensive dataset meticulously\nannotated for multi-class multi-tool tracking across three perspectives\nrepresenting the various ways of considering the temporal duration of a tool\ntrajectory: (1) intraoperative, (2) intracorporeal, and (3) visibility within\nthe camera's scope. The dataset comprises 20 laparoscopic videos with over\n35,000 frames and 65,000 annotated tool instances with details on spatial\nlocation, category, identity, operator, phase, and surgical visual conditions.\nThis detailed dataset caters to the evolving assistive requirements within a\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2312.07352"
            },
            {
                "文章ID": "98794",
                "标题": "Confucius: Iterative Tool Learning from Introspection Feedback by\n  Easy-to-Difficult Curriculum",
                "作者": " Shen Gao,  Zhengliang Shi,  Minghang Zhu,  Bowen Fang,  Xin Xin,  Pengjie Ren,  Zhumin Chen,  Jun Ma,  Zhaochun Ren",
                "发布日期": "2023-12-22",
                "摘要": "  Augmenting large language models (LLMs) with external tools has emerged as a\npromising approach to extending the capability of LLMs. Although some works\nemploy open-source LLMs for the tool learning task, most of them are trained in\na controlled environment in which LLMs only learn to execute the human-provided\ntools. However, selecting proper tools from the large toolset is also a crucial\nability for the tool learning model to be applied in real-world applications.\nExisting methods usually directly employ self-instruction methods to train the\nmodel, which ignores differences in tool complexity. In this paper, we propose\nthe Confucius, a novel tool learning framework to train LLM to use complicated\ntools in real-world scenarios, which contains two main phases: (1) We first\npropose a multi-stage learning method to teach the LLM to use various tools\nfrom an easy-to-difficult curriculum; (2) thenceforth, we propose the Iterative\nSelf-instruct from Introspective Feedback (ISIF) to dynamically construct the\ndataset to improve the ability to use the complicated tool. Extensive\nexperiments conducted on both controlled and real-world settings demonstrate\nthe superiority of our tool learning framework in the real-world application\nscenarios compared to both tuning-free (e.g. ChatGPT, Claude) and tuning-based\nbaselines (e.g. GPT4Tools).\n",
                "链接": "https://arxiv.org/abs/2308.14034"
            },
            {
                "文章ID": "124318",
                "标题": "T-Eval: Evaluating the Tool Utilization Capability Step by Step",
                "作者": " Zehui Chen,  Weihua Du,  Wenwei Zhang,  Kuikun Liu,  Jiangning Liu,  Miao Zheng,  Jingming Zhuo,  Songyang Zhang,  Dahua Lin,  Kai Chen,  Feng Zhao",
                "发布日期": "2023-12-22",
                "摘要": "  Large language models (LLM) have achieved remarkable performance on various\nNLP tasks and are augmented by tools for broader applications. Yet, how to\nevaluate and analyze the tool-utilization capability of LLMs is still\nunder-explored. In contrast to previous works that evaluate models\nholistically, we comprehensively decompose the tool utilization into multiple\nsub-processes, including instruction following, planning, reasoning, retrieval,\nunderstanding, and review. Based on that, we further introduce \\shortname~to\nevaluate the tool utilization capability step by step. \\shortname~disentangles\nthe tool utilization evaluation into several sub-domains along model\ncapabilities, facilitating the inner understanding of both holistic and\nisolated competency of LLMs. We conduct extensive experiments on \\shortname~and\nin-depth analysis of various LLMs. \\shortname~ not only exhibits consistency\nwith the outcome-oriented evaluation but also provides a more fine-grained\nanalysis of the capabilities of LLMs, providing a new perspective in LLM\nevaluation on tool-utilization ability. The benchmark will be available at\n\\href{https://github.com/open-compass/T-Eval}{https://github.com/open-compass/T-Eval}.\n",
                "链接": "https://arxiv.org/abs/2312.14033"
            },
            {
                "文章ID": "119263",
                "标题": "Data-driven prediction of tool wear using Bayesian-regularized\n  artificial neural networks",
                "作者": " Tam T. Truong,  Jay Airao,  Panagiotis Karras,  Faramarz Hojati,  Bahman Azarhoushang,  Ramin Aghababaei",
                "发布日期": "2023-12-01",
                "摘要": "  The prediction of tool wear helps minimize costs and enhance product quality\nin manufacturing. While existing data-driven models using machine learning and\ndeep learning have contributed to the accurate prediction of tool wear, they\noften lack generality and require substantial training data for high accuracy.\nIn this paper, we propose a new data-driven model that uses Bayesian\nRegularized Artificial Neural Networks (BRANNs) to precisely predict milling\ntool wear. BRANNs combine the strengths and leverage the benefits of artificial\nneural networks (ANNs) and Bayesian regularization, whereby ANNs learn complex\npatterns and Bayesian regularization handles uncertainty and prevents\noverfitting, resulting in a more generalized model. We treat both process\nparameters and monitoring sensor signals as BRANN input parameters. We\nconducted an extensive experimental study featuring four different experimental\ndata sets, including the NASA Ames milling dataset, the 2010 PHM Data Challenge\ndataset, the NUAA Ideahouse tool wear dataset, and an in-house performed\nend-milling of the Ti6Al4V dataset. We inspect the impact of input features,\ntraining data size, hidden units, training algorithms, and transfer functions\non the performance of the proposed BRANN model and demonstrate that it\noutperforms existing state-of-the-art models in terms of accuracy and\nreliability.\n",
                "链接": "https://arxiv.org/abs/2311.18620"
            },
            {
                "文章ID": "118185",
                "标题": "SVRDA: A Web-based Dataset Annotation Tool for Slice-to-Volume\n  Registration",
                "作者": " Weixun Luo,  Alexandre Triay Bagur,  Paul Aljabar,  George Ralli,  Sir Michael Brady",
                "发布日期": "2023-11-28",
                "摘要": "  Background and Objective: The lack of benchmark datasets has impeded the\ndevelopment of slice-to-volume registration algorithms. Such datasets are\ndifficult to annotate, primarily due to the dimensional difference within data\nand the dearth of task-specific software. We aim to develop a user-friendly\ntool to streamline dataset annotation for slice-to-volume registration.\n  Methods: The proposed tool, named SVRDA, is an installation-free web\napplication for platform-agnostic collaborative dataset annotation. It enables\nefficient transformation manipulation via keyboard shortcuts and smooth case\ntransitions with auto-saving. SVRDA supports configuration-based data loading\nand adheres to the separation of concerns, offering great flexibility and\nextensibility for future research. Various supplementary features have been\nimplemented to facilitate slice-to-volume registration.\n  Results: We validated the effectiveness of SVRDA by indirectly evaluating the\npost-registration segmentation quality on UK Biobank data, observing a dramatic\noverall improvement (24.02% in the Dice Similarity Coefficient and 48.93% in\nthe 95th percentile Hausdorff distance, respectively) supported by highly\nstatistically significant evidence ($p<0.001$).We further showcased the\nclinical usage of SVRDA by integrating it into test-retest T1 quantification on\nin-house magnetic resonance images, leading to more consistent results after\nregistration.\n  Conclusions: SVRDA can facilitate collaborative annotation of benchmark\ndatasets while being potentially applicable to other pipelines incorporating\nslice-to-volume registration. Full source code and documentation are available\nat https://github.com/Roldbach/SVRDA\n",
                "链接": "https://arxiv.org/abs/2311.15536"
            },
            {
                "文章ID": "123110",
                "标题": "ProTIP: Progressive Tool Retrieval Improves Planning",
                "作者": " Raviteja Anantha,  Bortik Bandyopadhyay,  Anirudh Kashi,  Sayantan Mahinder,  Andrew W Hill,  Srinivas Chappidi",
                "发布日期": "2023-12-19",
                "摘要": "  Large language models (LLMs) are increasingly employed for complex multi-step\nplanning tasks, where the tool retrieval (TR) step is crucial for achieving\nsuccessful outcomes. Two prevalent approaches for TR are single-step retrieval,\nwhich utilizes the complete query, and sequential retrieval using task\ndecomposition (TD), where a full query is segmented into discrete atomic\nsubtasks. While single-step retrieval lacks the flexibility to handle\n\"inter-tool dependency,\" the TD approach necessitates maintaining \"subtask-tool\natomicity alignment,\" as the toolbox can evolve dynamically. To address these\nlimitations, we introduce the Progressive Tool retrieval to Improve Planning\n(ProTIP) framework. ProTIP is a lightweight, contrastive learning-based\nframework that implicitly performs TD without the explicit requirement of\nsubtask labels, while simultaneously maintaining subtask-tool atomicity. On the\nToolBench dataset, ProTIP outperforms the ChatGPT task decomposition-based\napproach by a remarkable margin, achieving a 24% improvement in Recall@K=10 for\nTR and a 41% enhancement in tool accuracy for plan generation.\n",
                "链接": "https://arxiv.org/abs/2312.10332"
            },
            {
                "文章ID": "79415",
                "标题": "SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization\n  Evaluation",
                "作者": " Elizabeth Clark,  Shruti Rijhwani,  Sebastian Gehrmann,  Joshua Maynez,  Roee Aharoni,  Vitaly Nikolaev,  Thibault Sellam,  Aditya Siddhant,  Dipanjan Das,  Ankur P. Parikh",
                "发布日期": "2023-11-03",
                "摘要": "  Reliable automatic evaluation of summarization systems is challenging due to\nthe multifaceted and subjective nature of the task. This is especially the case\nfor languages other than English, where human evaluations are scarce. In this\nwork, we introduce SEAHORSE, a dataset for multilingual, multifaceted\nsummarization evaluation. SEAHORSE consists of 96K summaries with human ratings\nalong 6 dimensions of text quality: comprehensibility, repetition, grammar,\nattribution, main ideas, and conciseness, covering 6 languages, 9 systems and 4\ndatasets. As a result of its size and scope, SEAHORSE can serve both as a\nbenchmark to evaluate learnt metrics, as well as a large-scale resource for\ntraining such metrics. We show that metrics trained with SEAHORSE achieve\nstrong performance on the out-of-domain meta-evaluation benchmarks TRUE\n(Honovich et al., 2022) and mFACE (Aharoni et al., 2022). We make the SEAHORSE\ndataset and metrics publicly available for future research on multilingual and\nmultifaceted summarization evaluation.\n",
                "链接": "https://arxiv.org/abs/2305.13194"
            },
            {
                "文章ID": "124873",
                "标题": "Design and Implementation of a Tool for Extracting Uzbek Syllables",
                "作者": " Ulugbek Salaev,  Elmurod Kuriyozov,  Gayrat Matlatipov",
                "发布日期": "2023-12-27",
                "摘要": "  The accurate syllabification of words plays a vital role in various Natural\nLanguage Processing applications. Syllabification is a versatile linguistic\ntool with applications in linguistic research, language technology, education,\nand various fields where understanding and processing language is essential. In\nthis paper, we present a comprehensive approach to syllabification for the\nUzbek language, including rule-based techniques and machine learning\nalgorithms. Our rule-based approach utilizes advanced methods for dividing\nwords into syllables, generating hyphenations for line breaks and count of\nsyllables. Additionally, we collected a dataset for evaluating and training\nusing machine learning algorithms comprising word-syllable mappings,\nhyphenations, and syllable counts to predict syllable counts as well as for the\nevaluation of the proposed model. Our results demonstrate the effectiveness and\nefficiency of both approaches in achieving accurate syllabification. The\nresults of our experiments show that both approaches achieved a high level of\naccuracy, exceeding 99%. This study provides valuable insights and\nrecommendations for future research on syllabification and related areas in not\nonly the Uzbek language itself, but also in other closely-related Turkic\nlanguages with low-resource factor.\n",
                "链接": "https://arxiv.org/abs/2312.15779"
            },
            {
                "文章ID": "36360",
                "标题": "Benchmarking Multimodal Variational Autoencoders: CdSprites+ Dataset and\n  Toolkit",
                "作者": " Gabriela Sejnova,  Michal Vavrecka,  Karla Stepanova",
                "发布日期": "2023-11-27",
                "摘要": "  Multimodal Variational Autoencoders (VAEs) have been the subject of intense\nresearch in the past years as they can integrate multiple modalities into a\njoint representation and can thus serve as a promising tool for both data\nclassification and generation. Several approaches toward multimodal VAE\nlearning have been proposed so far, their comparison and evaluation have\nhowever been rather inconsistent. One reason is that the models differ at the\nimplementation level, another problem is that the datasets commonly used in\nthese cases were not initially designed to evaluate multimodal generative\nmodels. This paper addresses both mentioned issues. First, we propose a toolkit\nfor systematic multimodal VAE training and comparison. The toolkit currently\ncomprises 4 existing multimodal VAEs and 6 commonly used benchmark datasets\nalong with instructions on how to easily add a new model or a dataset. Second,\nwe present a disentangled bimodal dataset designed to comprehensively evaluate\nthe joint generation and cross-generation capabilities across multiple\ndifficulty levels. We demonstrate the utility of our dataset by comparing the\nimplemented state-of-the-art models.\n",
                "链接": "https://arxiv.org/abs/2209.03048"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下工具评测相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "90192",
                "标题": "A Semi-Automated Solution Approach Selection Tool for Any Use Case via\n  Scopus and OpenAI: a Case Study for AI/ML in Oncology",
                "作者": " Deniz Kenan Kılıç,  Alex Elkjær Vasegaard,  Aurélien Desoeuvres,  Peter Nielsen",
                "发布日期": "2023-07-11",
                "摘要": "  In today's vast literature landscape, a manual review is very time-consuming.\nTo address this challenge, this paper proposes a semi-automated tool for\nsolution method review and selection. It caters to researchers, practitioners,\nand decision-makers while serving as a benchmark for future work. The tool\ncomprises three modules: (1) paper selection and scoring, using a keyword\nselection scheme to query Scopus API and compute relevancy; (2) solution method\nextraction in papers utilizing OpenAI API; (3) sensitivity analysis and\npost-analyzes. It reveals trends, relevant papers, and methods. AI in the\noncology case study and several use cases are presented with promising results,\ncomparing the tool to manual ground truth.\n",
                "链接": "https://arxiv.org/abs/2307.04573"
            },
            {
                "文章ID": "103034",
                "标题": "Interactive Distillation of Large Single-Topic Corpora of Scientific\n  Papers",
                "作者": " Nicholas Solovyev,  Ryan Barron,  Manish Bhattarai,  Maksim E. Eren,  Kim O. Rasmussen,  Boian S. Alexandrov",
                "发布日期": "2023-09-20",
                "摘要": "  Highly specific datasets of scientific literature are important for both\nresearch and education. However, it is difficult to build such datasets at\nscale. A common approach is to build these datasets reductively by applying\ntopic modeling on an established corpus and selecting specific topics. A more\nrobust but time-consuming approach is to build the dataset constructively in\nwhich a subject matter expert (SME) handpicks documents. This method does not\nscale and is prone to error as the dataset grows. Here we showcase a new tool,\nbased on machine learning, for constructively generating targeted datasets of\nscientific literature. Given a small initial \"core\" corpus of papers, we build\na citation network of documents. At each step of the citation network, we\ngenerate text embeddings and visualize the embeddings through dimensionality\nreduction. Papers are kept in the dataset if they are \"similar\" to the core or\nare otherwise pruned through human-in-the-loop selection. Additional insight\ninto the papers is gained through sub-topic modeling using SeNMFk. We\ndemonstrate our new tool for literature review by applying it to two different\nfields in machine learning.\n",
                "链接": "https://arxiv.org/abs/2309.10772"
            },
            {
                "文章ID": "111569",
                "标题": "math-PVS: A Large Language Model Framework to Map Scientific\n  Publications to PVS Theories",
                "作者": " Hassen Saidi,  Susmit Jha,  Tuhin Sahai",
                "发布日期": "2023-10-27",
                "摘要": "  As artificial intelligence (AI) gains greater adoption in a wide variety of\napplications, it has immense potential to contribute to mathematical discovery,\nby guiding conjecture generation, constructing counterexamples, assisting in\nformalizing mathematics, and discovering connections between different\nmathematical areas, to name a few.\n  While prior work has leveraged computers for exhaustive mathematical proof\nsearch, recent efforts based on large language models (LLMs) aspire to position\ncomputing platforms as co-contributors in the mathematical research process.\nDespite their current limitations in logic and mathematical tasks, there is\ngrowing interest in melding theorem proving systems with foundation models.\nThis work investigates the applicability of LLMs in formalizing advanced\nmathematical concepts and proposes a framework that can critically review and\ncheck mathematical reasoning in research papers. Given the noted reasoning\nshortcomings of LLMs, our approach synergizes the capabilities of proof\nassistants, specifically PVS, with LLMs, enabling a bridge between textual\ndescriptions in academic papers and formal specifications in PVS. By harnessing\nthe PVS environment, coupled with data ingestion and conversion mechanisms, we\nenvision an automated process, called \\emph{math-PVS}, to extract and formalize\nmathematical theorems from research papers, offering an innovative tool for\nacademic review and discovery.\n",
                "链接": "https://arxiv.org/abs/2310.17064"
            },
            {
                "文章ID": "86386",
                "标题": "TOBY: A Tool for Exploring Data in Academic Survey Papers",
                "作者": " Tathagata Chakraborti,  Jungkoo Kang,  Christian Muise,  Sarath Sreedharan,  Michael Walker,  Daniel Szafir,  Tom Williams",
                "发布日期": "2023-06-21",
                "摘要": "  This paper describes TOBY, a visualization tool that helps a user explore the\ncontents of an academic survey paper. The visualization consists of four\ncomponents: a hierarchical view of taxonomic data in the survey, a document\nsimilarity view in the space of taxonomic classes, a network view of citations,\nand a new paper recommendation tool. In this paper, we will discuss these\nfeatures in the context of three separate deployments of the tool.\n",
                "链接": "https://arxiv.org/abs/2306.10051"
            },
            {
                "文章ID": "48672",
                "标题": "H2-Golden-Retriever: Methodology and Tool for an Evidence-Based Hydrogen\n  Research Grantsmanship",
                "作者": " Paul Seurin,  Olusola Olabanjo,  Joseph Wiggins,  Lorien Pratt,  Loveneesh Rana,  Rozhin Yasaei,  Gregory Renard",
                "发布日期": "2022-11-17",
                "摘要": "  Hydrogen is poised to play a major role in decarbonizing the economy. The\nneed to discover, develop, and understand low-cost, high-performance, durable\nmaterials that can help maximize the cost of electrolysis as well as the need\nfor an intelligent tool to make evidence-based Hydrogen research funding\ndecisions relatively easier warranted this study.In this work, we developed H2\nGolden Retriever (H2GR) system for Hydrogen knowledge discovery and\nrepresentation using Natural Language Processing (NLP), Knowledge Graph and\nDecision Intelligence. This system represents a novel methodology encapsulating\nstate-of-the-art technique for evidence-based research grantmanship. Relevant\nHydrogen papers were scraped and indexed from the web and preprocessing was\ndone using noise and stop-words removal, language and spell check, stemming and\nlemmatization. The NLP tasks included Named Entity Recognition using Stanford\nand Spacy NER, topic modeling using Latent Dirichlet Allocation and TF-IDF. The\nKnowledge Graph module was used for the generation of meaningful entities and\ntheir relationships, trends and patterns in relevant H2 papers, thanks to an\nontology of the hydrogen production domain. The Decision Intelligence component\nprovides stakeholders with a simulation environment for cost and quantity\ndependencies. PageRank algorithm was used to rank papers of interest. Random\nsearches were made on the proposed H2GR and the results included a list of\npapers ranked by relevancy score, entities, graphs of relationships between the\nentities, ontology of H2 production and Causal Decision Diagrams showing\ncomponent interactivity. Qualitative assessment was done by the experts and\nH2GR is deemed to function to a satisfactory level.\n",
                "链接": "https://arxiv.org/abs/2211.08614"
            },
            {
                "文章ID": "50847",
                "标题": "Bayesian Network Models of Causal Interventions in Healthcare Decision\n  Making: Literature Review and Software Evaluation",
                "作者": " Artem Velikzhanin,  Benjie Wang,  Marta Kwiatkowska",
                "发布日期": "2022-11-29",
                "摘要": "  This report summarises the outcomes of a systematic literature search to\nidentify Bayesian network models used to support decision making in healthcare.\nAfter describing the search methodology, the selected research papers are\nbriefly reviewed, with the view to identify publicly available models and\ndatasets that are well suited to analysis using the causal interventional\nanalysis software tool developed in Wang B, Lyle C, Kwiatkowska M (2021).\nFinally, an experimental evaluation of applying the software on a selection of\nmodels is carried out and preliminary results are reported.\n",
                "链接": "https://arxiv.org/abs/2211.15258"
            },
            {
                "文章ID": "112854",
                "标题": "ACL Anthology Helper: A Tool to Retrieve and Manage Literature from ACL\n  Anthology",
                "作者": " Chen Tang,  Frank Guerin,  Chenghua Lin",
                "发布日期": "2023-11-01",
                "摘要": "  The ACL Anthology is an online repository that serves as a comprehensive\ncollection of publications in the field of natural language processing (NLP)\nand computational linguistics (CL). This paper presents a tool called ``ACL\nAnthology Helper''. It automates the process of parsing and downloading papers\nalong with their meta-information, which are then stored in a local MySQL\ndatabase. This allows for efficient management of the local papers using a wide\nrange of operations, including \"where,\" \"group,\" \"order,\" and more. By\nproviding over 20 operations, this tool significantly enhances the retrieval of\nliterature based on specific conditions. Notably, this tool has been\nsuccessfully utilised in writing a survey paper (Tang et al.,2022a). By\nintroducing the ACL Anthology Helper, we aim to enhance researchers' ability to\neffectively access and organise literature from the ACL Anthology. This tool\noffers a convenient solution for researchers seeking to explore the ACL\nAnthology's vast collection of publications while allowing for more targeted\nand efficient literature retrieval.\n",
                "链接": "https://arxiv.org/abs/2310.20467"
            },
            {
                "文章ID": "58376",
                "标题": "A Systematic Review of Green AI",
                "作者": " Roberto Verdecchia,  June Sallou,  Luís Cruz",
                "发布日期": "2023-05-08",
                "摘要": "  With the ever-growing adoption of AI-based systems, the carbon footprint of\nAI is no longer negligible. AI researchers and practitioners are therefore\nurged to hold themselves accountable for the carbon emissions of the AI models\nthey design and use. This led in recent years to the appearance of researches\ntackling AI environmental sustainability, a field referred to as Green AI.\nDespite the rapid growth of interest in the topic, a comprehensive overview of\nGreen AI research is to date still missing. To address this gap, in this paper,\nwe present a systematic review of the Green AI literature. From the analysis of\n98 primary studies, different patterns emerge. The topic experienced a\nconsiderable growth from 2020 onward. Most studies consider monitoring AI model\nfootprint, tuning hyperparameters to improve model sustainability, or\nbenchmarking models. A mix of position papers, observational studies, and\nsolution papers are present. Most papers focus on the training phase, are\nalgorithm-agnostic or study neural networks, and use image data. Laboratory\nexperiments are the most common research strategy. Reported Green AI energy\nsavings go up to 115%, with savings over 50% being rather common. Industrial\nparties are involved in Green AI studies, albeit most target academic readers.\nGreen AI tool provisioning is scarce. As a conclusion, the Green AI research\nfield results to have reached a considerable level of maturity. Therefore, from\nthis review emerges that the time is suitable to adopt other Green AI research\nstrategies, and port the numerous promising academic results to industrial\npractice.\n",
                "链接": "https://arxiv.org/abs/2301.11047"
            },
            {
                "文章ID": "108599",
                "标题": "Textual Analysis of ICALEPCS and IPAC Conference Proceedings: Revealing\n  Research Trends, Topics, and Collaborations for Future Insights and Advanced\n  Search",
                "作者": " Antonin Sulc,  Annika Eichler,  Tim Wilksen",
                "发布日期": "2023-10-16",
                "摘要": "  In this paper, we show a textual analysis of past ICALEPCS and IPAC\nconference proceedings to gain insights into the research trends and topics\ndiscussed in the field. We use natural language processing techniques to\nextract meaningful information from the abstracts and papers of past conference\nproceedings. We extract topics to visualize and identify trends, analyze their\nevolution to identify emerging research directions, and highlight interesting\npublications based solely on their content with an analysis of their network.\nAdditionally, we will provide an advanced search tool to better search the\nexisting papers to prevent duplication and easier reference findings. Our\nanalysis provides a comprehensive overview of the research landscape in the\nfield and helps researchers and practitioners to better understand the\nstate-of-the-art and identify areas for future research.\n",
                "链接": "https://arxiv.org/abs/2310.08954"
            },
            {
                "文章ID": "98421",
                "标题": "An approach based on Open Research Knowledge Graph for Knowledge\n  Acquisition from scientific papers",
                "作者": " Azanzi Jiomekong,  Sanju Tiwari",
                "发布日期": "2023-08-28",
                "摘要": "  A scientific paper can be divided into two major constructs which are\nMetadata and Full-body text. Metadata provides a brief overview of the paper\nwhile the Full-body text contains key-insights that can be valuable to fellow\nresearchers. To retrieve metadata and key-insights from scientific papers,\nknowledge acquisition is a central activity. It consists of gathering,\nanalyzing and organizing knowledge embedded in scientific papers in such a way\nthat it can be used and reused whenever needed. Given the wealth of scientific\nliterature, manual knowledge acquisition is a cumbersome task. Thus,\ncomputer-assisted and (semi-)automatic strategies are generally adopted. Our\npurpose in this research was two fold: curate Open Research Knowledge Graph\n(ORKG) with papers related to ontology learning and define an approach using\nORKG as a computer-assisted tool to organize key-insights extracted from\nresearch papers. This approach was used to document the \"epidemiological\nsurveillance systems design and implementation\" research problem and to prepare\nthe related work of this paper. It is currently used to document \"food\ninformation engineering\", \"Tabular data to Knowledge Graph Matching\" and\n\"Question Answering\" research problems and \"Neuro-symbolic AI\" domain.\n",
                "链接": "https://arxiv.org/abs/2308.12981"
            }
        ]
    },
    {
        "question": {
            "question": "大模型在游戏方面的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "40769",
                "标题": "Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors",
                "作者": " Mohammad Reza Taesiri,  Finlay Macklon,  Yihe Wang,  Hengshuo Shen,  Cor-Paul Bezemer",
                "发布日期": "2022-10-07",
                "摘要": "  Video game testing requires game-specific knowledge as well as common sense\nreasoning about the events in the game. While AI-driven agents can satisfy the\nfirst requirement, it is not yet possible to meet the second requirement\nautomatically. Therefore, video game testing often still relies on manual\ntesting, and human testers are required to play the game thoroughly to detect\nbugs. As a result, it is challenging to fully automate game testing. In this\nstudy, we explore the possibility of leveraging the zero-shot capabilities of\nlarge language models for video game bug detection. By formulating the bug\ndetection problem as a question-answering task, we show that large language\nmodels can identify which event is buggy in a sequence of textual descriptions\nof events from a game. To this end, we introduce the GameBugDescriptions\nbenchmark dataset, which consists of 167 buggy gameplay videos and a total of\n334 question-answer pairs across 8 games. We extensively evaluate the\nperformance of six models across the OPT and InstructGPT large language model\nfamilies on our benchmark dataset. Our results show promising results for\nemploying language models to detect video game bugs. With the proper prompting\ntechnique, we could achieve an accuracy of 70.66%, and on some video games, up\nto 78.94%. Our code, evaluation data and the benchmark can be found on\nhttps://asgaardlab.github.io/LLMxBugs\n",
                "链接": "https://arxiv.org/abs/2210.02506"
            },
            {
                "文章ID": "74364",
                "标题": "Game-based Platforms for Artificial Intelligence Research",
                "作者": " Chengpeng Hu,  Yunlong Zhao,  Ziqi Wang,  Haocheng Du,  Jialin Liu",
                "发布日期": "2023-05-26",
                "摘要": "  Games have been the perfect test-beds for artificial intelligence research\nfor the characteristics that widely exist in real-world scenarios. Learning and\noptimisation, decision making in dynamic and uncertain environments, game\ntheory, planning and scheduling, design and education are common research areas\nshared between games and real-world problems. Numerous open-source games or\ngame-based environments have been implemented for studying artificial\nintelligence. In addition to single- or multi-player, collaborative or\nadversarial games, there has also been growing interest in implementing\nplatforms for creative design in recent years. Those platforms provide ideal\nbenchmarks for exploring and comparing artificial intelligence ideas and\ntechniques. This paper reviews the game-based platforms for artificial\nintelligence research, discusses the research trend induced by the evolution of\nthose platforms, and gives an outlook.\n",
                "链接": "https://arxiv.org/abs/2304.13269"
            },
            {
                "文章ID": "27135",
                "标题": "Mastering the Game of Stratego with Model-Free Multiagent Reinforcement\n  Learning",
                "作者": " Julien Perolat,  Bart de Vylder,  Daniel Hennes,  Eugene Tarassov,  Florian Strub,  Vincent de Boer,  Paul Muller,  Jerome T. Connor,  Neil Burch,  Thomas Anthony,  Stephen McAleer,  Romuald Elie,  Sarah H. Cen,  Zhe Wang,  Audrunas Gruslys,  Aleksandra Malysheva,  Mina Khan,  Sherjil Ozair,  Finbarr Timbers,  Toby Pohlen,  Tom Eccles,  Mark Rowland,  Marc Lanctot,  Jean-Baptiste Lespiau,  Bilal Piot,  Shayegan Omidshafiei,  Edward Lockhart,  Laurent Sifre,  Nathalie Beauguerlange,  Remi Munos,  David Silver,  Satinder Singh,  Demis Hassabis,  Karl Tuyls",
                "发布日期": "2023-01-11",
                "摘要": "  We introduce DeepNash, an autonomous agent capable of learning to play the\nimperfect information game Stratego from scratch, up to a human expert level.\nStratego is one of the few iconic board games that Artificial Intelligence (AI)\nhas not yet mastered. This popular game has an enormous game tree on the order\nof $10^{535}$ nodes, i.e., $10^{175}$ times larger than that of Go. It has the\nadditional complexity of requiring decision-making under imperfect information,\nsimilar to Texas hold'em poker, which has a significantly smaller game tree (on\nthe order of $10^{164}$ nodes). Decisions in Stratego are made over a large\nnumber of discrete actions with no obvious link between action and outcome.\nEpisodes are long, with often hundreds of moves before a player wins, and\nsituations in Stratego can not easily be broken down into manageably-sized\nsub-problems as in poker. For these reasons, Stratego has been a grand\nchallenge for the field of AI for decades, and existing AI methods barely reach\nan amateur level of play. DeepNash uses a game-theoretic, model-free deep\nreinforcement learning method, without search, that learns to master Stratego\nvia self-play. The Regularised Nash Dynamics (R-NaD) algorithm, a key component\nof DeepNash, converges to an approximate Nash equilibrium, instead of 'cycling'\naround it, by directly modifying the underlying multi-agent learning dynamics.\nDeepNash beats existing state-of-the-art AI methods in Stratego and achieved a\nyearly (2022) and all-time top-3 rank on the Gravon games platform, competing\nwith human expert players.\n",
                "链接": "https://arxiv.org/abs/2206.15378"
            },
            {
                "文章ID": "77182",
                "标题": "The Ethics of AI in Games",
                "作者": " David Melhart,  Julian Togelius,  Benedikte Mikkelsen,  Christoffer Holmgård,  Georgios N. Yannakakis",
                "发布日期": "2023-05-15",
                "摘要": "  Video games are one of the richest and most popular forms of human-computer\ninteraction and, hence, their role is critical for our understanding of human\nbehaviour and affect at a large scale. As artificial intelligence (AI) tools\nare gradually adopted by the game industry a series of ethical concerns arise.\nSuch concerns, however, have so far not been extensively discussed in a video\ngame context. Motivated by the lack of a comprehensive review of the ethics of\nAI as applied to games, we survey the current state of the art in this area and\ndiscuss ethical considerations of these systems from the holistic perspective\nof the affective loop. Through the components of this loop, we study the\nethical challenges that AI faces in video game development. Elicitation\nhighlights the ethical boundaries of artificially induced emotions; sensing\nshowcases the trade-off between privacy and safe gaming spaces; and detection,\nas utilised during in-game adaptation, poses challenges to transparency and\nownership. This paper calls for an open dialogue and action for the games of\ntoday and the virtual spaces of the future. By setting an appropriate framework\nwe aim to protect users and to guide developers towards safer and better\nexperiences for their customers.\n",
                "链接": "https://arxiv.org/abs/2305.07392"
            },
            {
                "文章ID": "106983",
                "标题": "Kawaii Game Vocalics: A Preliminary Model",
                "作者": " Katie Seaborn,  Katja Rogers,  Somang Name,  Miu Kojima",
                "发布日期": "2023-10-10",
                "摘要": "  Kawaii is the Japanese concept of cute++, a global export with local\ncharacteristics. Recent work has explored kawaii as a feature of user\nexperience (UX) with social robots, virtual characters, and voice assistants,\ni.e., kawaii vocalics. Games have a long history of incorporating characters\nthat use voice as a means of expressing kawaii. Nevertheless, no work to date\nhas evaluated kawaii game voices or mapped out a model of kawaii game vocalics.\nIn this work, we explored whether and how a model of kawaii vocalics maps onto\ngame character voices. We conducted an online perceptions study (N=157) using\n18 voices from kawaii characters in Japanese games. We replicated the results\nfor computer voice and discovered nuanced relationships between gender and age,\nespecially youthfulness, agelessness, gender ambiguity, and gender neutrality.\nWe provide our initial model and advocate for future work on character visuals\nand within play contexts.\n",
                "链接": "https://arxiv.org/abs/2310.04731"
            },
            {
                "文章ID": "92288",
                "标题": "Towards General Game Representations: Decomposing Games Pixels into\n  Content and Style",
                "作者": " Chintan Trivedi,  Konstantinos Makantasis,  Antonios Liapis,  Georgios N. Yannakakis",
                "发布日期": "2023-07-24",
                "摘要": "  On-screen game footage contains rich contextual information that players\nprocess when playing and experiencing a game. Learning pixel representations of\ngames can benefit artificial intelligence across several downstream tasks\nincluding game-playing agents, procedural content generation, and player\nmodelling. The generalizability of these methods, however, remains a challenge,\nas learned representations should ideally be shared across games with similar\ngame mechanics. This could allow, for instance, game-playing agents trained on\none game to perform well in similar games with no re-training. This paper\nexplores how generalizable pre-trained computer vision encoders can be for such\ntasks, by decomposing the latent space into content embeddings and style\nembeddings. The goal is to minimize the domain gap between games of the same\ngenre when it comes to game content critical for downstream tasks, and ignore\ndifferences in graphical style. We employ a pre-trained Vision Transformer\nencoder and a decomposition technique based on game genres to obtain separate\ncontent and style embeddings. Our findings show that the decomposed embeddings\nachieve style invariance across multiple games while still maintaining strong\ncontent extraction capabilities. We argue that the proposed decomposition of\ncontent and style offers better generalization capacities across game\nenvironments independently of the downstream task.\n",
                "链接": "https://arxiv.org/abs/2307.11141"
            },
            {
                "文章ID": "104167",
                "标题": "Affective Game Computing: A Survey",
                "作者": " Georgios N. Yannakakis,  David Melhart",
                "发布日期": "2023-09-26",
                "摘要": "  This paper surveys the current state of the art in affective computing\nprinciples, methods and tools as applied to games. We review this emerging\nfield, namely affective game computing, through the lens of the four core\nphases of the affective loop: game affect elicitation, game affect sensing,\ngame affect detection and game affect adaptation. In addition, we provide a\ntaxonomy of terms, methods and approaches used across the four phases of the\naffective game loop and situate the field within this taxonomy. We continue\nwith a comprehensive review of available affect data collection methods with\nregards to gaming interfaces, sensors, annotation protocols, and available\ncorpora. The paper concludes with a discussion on the current limitations of\naffective game computing and our vision for the most promising future research\ndirections in the field.\n",
                "链接": "https://arxiv.org/abs/2309.14104"
            },
            {
                "文章ID": "8026",
                "标题": "DareFightingICE Competition: A Fighting Game Sound Design and AI\n  Competition",
                "作者": " Ibrahim Khan,  Thai Van Nguyen,  Xincheng Dai,  Ruck Thawonmas",
                "发布日期": "2022-06-16",
                "摘要": "  This paper presents a new competition -- at the 2022 IEEE Conference on Games\n(CoG) -- called DareFightingICE Competition. The competition has two tracks: a\nsound design track and an AI track. The game platform for this competition is\nalso called DareFightingICE, a fighting game platform. DareFightingICE is a\nsound-design-enhanced version of FightingICE, used earlier in a competition at\nCoG until 2021 to promote artificial intelligence (AI) research in fighting\ngames. In the sound design track, participants compete for the best sound\ndesign, given the default sound design of DareFightingICE as a sample, where we\ndefine a sound design as a set of sound effects combined with the source code\nthat implements their timing-control algorithm. Participants of the AI track\nare asked to develop their AI algorithm that controls a character given only\nsound as the input (blind AI) to fight against their opponent; a sample\ndeep-learning blind AI will be provided by us. Our means to maximize the\nsynergy between the two tracks are also described. This competition serves to\ncome up with effective sound designs for visually impaired players, a group in\nthe gaming community which has been mostly ignored. To the best of our\nknowledge, DareFightingICE Competition is the first of its kind within and\noutside of CoG.\n",
                "链接": "https://arxiv.org/abs/2203.01556"
            },
            {
                "文章ID": "12922",
                "标题": "Perceptual Quality Assessment of UGC Gaming Videos",
                "作者": " Xiangxu Yu,  Zhengzhong Tu,  Neil Birkbeck,  Yilin Wang,  Balu Adsumilli,  Alan C. Bovik",
                "发布日期": "2022-04-15",
                "摘要": "  In recent years, with the vigorous development of the video game industry,\nthe proportion of gaming videos on major video websites like YouTube has\ndramatically increased. However, relatively little research has been done on\nthe automatic quality prediction of gaming videos, especially on those that\nfall in the category of \"User-Generated-Content\" (UGC). Since current leading\ngeneral-purpose Video Quality Assessment (VQA) models do not perform well on\nthis type of gaming videos, we have created a new VQA model specifically\ndesigned to succeed on UGC gaming videos, which we call the Gaming Video\nQuality Predictor (GAME-VQP). GAME-VQP successfully predicts the unique\nstatistical characteristics of gaming videos by drawing upon features designed\nunder modified natural scene statistics models, combined with gaming specific\nfeatures learned by a Convolution Neural Network. We study the performance of\nGAME-VQP on a very recent large UGC gaming video database called\nLIVE-YT-Gaming, and find that it both outperforms other mainstream general VQA\nmodels as well as VQA models specifically designed for gaming videos. The new\nmodel will be made public after paper being accepted.\n",
                "链接": "https://arxiv.org/abs/2204.00128"
            },
            {
                "文章ID": "40685",
                "标题": "Game Theoretic Rating in N-player general-sum games with Equilibria",
                "作者": " Luke Marris,  Marc Lanctot,  Ian Gemp,  Shayegan Omidshafiei,  Stephen McAleer,  Jerome Connor,  Karl Tuyls,  Thore Graepel",
                "发布日期": "2022-10-06",
                "摘要": "  Rating strategies in a game is an important area of research in game theory\nand artificial intelligence, and can be applied to any real-world competitive\nor cooperative setting. Traditionally, only transitive dependencies between\nstrategies have been used to rate strategies (e.g. Elo), however recent work\nhas expanded ratings to utilize game theoretic solutions to better rate\nstrategies in non-transitive games. This work generalizes these ideas and\nproposes novel algorithms suitable for N-player, general-sum rating of\nstrategies in normal-form games according to the payoff rating system. This\nenables well-established solution concepts, such as equilibria, to be leveraged\nto efficiently rate strategies in games with complex strategic interactions,\nwhich arise in multiagent training and real-world interactions between many\nagents. We empirically validate our methods on real world normal-form data\n(Premier League) and multiagent reinforcement learning agent evaluation.\n",
                "链接": "https://arxiv.org/abs/2210.02205"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "95587",
                "标题": "NLLG Quarterly arXiv Report 06/23: What are the most influential current\n  AI Papers?",
                "作者": " Steffen Eger,  Christoph Leiter,  Jonas Belouadi,  Ran Zhang,  Aida Kostikova,  Daniil Larionov,  Yanran Chen,  Vivian Fresen",
                "发布日期": "2023-08-15",
                "摘要": "  The rapid growth of information in the field of Generative Artificial\nIntelligence (AI), particularly in the subfields of Natural Language Processing\n(NLP) and Machine Learning (ML), presents a significant challenge for\nresearchers and practitioners to keep pace with the latest developments. To\naddress the problem of information overload, this report by the Natural\nLanguage Learning Group at Bielefeld University focuses on identifying the most\npopular papers on arXiv, with a specific emphasis on NLP and ML. The objective\nis to offer a quick guide to the most relevant and widely discussed research,\naiding both newcomers and established researchers in staying abreast of current\ntrends. In particular, we compile a list of the 40 most popular papers based on\nnormalized citation counts from the first half of 2023. We observe the\ndominance of papers related to Large Language Models (LLMs) and specifically\nChatGPT during the first half of 2023, with the latter showing signs of\ndeclining popularity more recently, however. Further, NLP related papers are\nthe most influential (around 60\\% of top papers) even though there are twice as\nmany ML related papers in our data. Core issues investigated in the most\nheavily cited papers are: LLM efficiency, evaluation techniques, ethical\nconsiderations, embodied agents, and problem-solving with LLMs. Additionally,\nwe examine the characteristics of top papers in comparison to others outside\nthe top-40 list (noticing the top paper's focus on LLM related issues and\nhigher number of co-authors) and analyze the citation distributions in our\ndataset, among others.\n",
                "链接": "https://arxiv.org/abs/2308.04889"
            },
            {
                "文章ID": "21348",
                "标题": "Target-aware Abstractive Related Work Generation with Contrastive\n  Learning",
                "作者": " Xiuying Chen,  Hind Alamro,  Mingzhe Li,  Shen Gao,  Rui Yan,  Xin Gao,  Xiangliang Zhang",
                "发布日期": "2022-05-27",
                "摘要": "  The related work section is an important component of a scientific paper,\nwhich highlights the contribution of the target paper in the context of the\nreference papers. Authors can save their time and effort by using the\nautomatically generated related work section as a draft to complete the final\nrelated work. Most of the existing related work section generation methods rely\non extracting off-the-shelf sentences to make a comparative discussion about\nthe target work and the reference papers. However, such sentences need to be\nwritten in advance and are hard to obtain in practice. Hence, in this paper, we\npropose an abstractive target-aware related work generator (TAG), which can\ngenerate related work sections consisting of new sentences. Concretely, we\nfirst propose a target-aware graph encoder, which models the relationships\nbetween reference papers and the target paper with target-centered attention\nmechanisms. In the decoding process, we propose a hierarchical decoder that\nattends to the nodes of different levels in the graph with keyphrases as\nsemantic indicators. Finally, to generate a more informative related work, we\npropose multi-level contrastive optimization objectives, which aim to maximize\nthe mutual information between the generated related work with the references\nand minimize that with non-references. Extensive experiments on two public\nscholar datasets show that the proposed model brings substantial improvements\nover several strong baselines in terms of automatic and tailored human\nevaluations.\n",
                "链接": "https://arxiv.org/abs/2205.13339"
            },
            {
                "文章ID": "42172",
                "标题": "Predicting the clinical citation count of biomedical papers using\n  multilayer perceptron neural network",
                "作者": " Xin Li,  Xuli Tang,  Qikai Cheng",
                "发布日期": "2022-10-24",
                "摘要": "  The number of clinical citations received from clinical guidelines or\nclinical trials has been considered as one of the most appropriate indicators\nfor quantifying the clinical impact of biomedical papers. Therefore, the early\nprediction of the clinical citation count of biomedical papers is critical to\nscientific activities in biomedicine, such as research evaluation, resource\nallocation, and clinical translation. In this study, we designed a four-layer\nmultilayer perceptron neural network (MPNN) model to predict the clinical\ncitation count of biomedical papers in the future by using 9,822,620 biomedical\npapers published from 1985 to 2005. We extracted ninety-one paper features from\nthree dimensions as the input of the model, including twenty-one features in\nthe paper dimension, thirty-five in the reference dimension, and thirty-five in\nthe citing paper dimension. In each dimension, the features can be classified\ninto three categories, i.e., the citation-related features, the clinical\ntranslation-related features, and the topic-related features. Besides, in the\npaper dimension, we also considered the features that have previously been\ndemonstrated to be related to the citation counts of research papers. The\nresults showed that the proposed MPNN model outperformed the other five\nbaseline models, and the features in the reference dimension were the most\nimportant.\n",
                "链接": "https://arxiv.org/abs/2210.06346"
            },
            {
                "文章ID": "42554",
                "标题": "Machine Learning vs. Deep Learning in 5G Networks -- A Comparison of\n  Scientific Impact",
                "作者": " Ilker Turker,  Serhat Orkun Tan",
                "发布日期": "2022-10-17",
                "摘要": "  Introduction of fifth generation (5G) wireless network technology has matched\nthe crucial need for high capacity and speed needs of the new generation mobile\napplications. Recent advances in Artificial Intelligence (AI) also empowered 5G\ncellular networks with two mainstreams as machine learning (ML) and deep\nlearning (DL) techniques. Our study aims to uncover the differences in\nscientific impact for these two techniques by the means of statistical\nbibliometrics. The performed analysis includes citation performance with\nrespect to indexing types, funding availability, journal or conference\npublishing options together with distributions of these metrics along years to\nevaluate the popularity trends in a detailed manner. Web of Science (WoS)\ndatabase host 2245 papers for ML and 1407 papers for DL-related studies. DL\nstudies, starting with 9% rate in 2013, has reached to 45% rate in 2022 among\nall DL and ML-related studies. Results related to scientific impact indicate\nthat DL studies get slightly more average normalized citation (2.256) compared\nto ML studies (2.118) in 5G, while SCI-Expanded indexed papers in both sides\ntend to have similar citation performance (3.165 and 3.162 respectively).\nML-related studies those are indexed in ESCI show twice citation performance\ncompared to DL. Conference papers in DL domain and journal papers in ML domain\nare superior in scientific interest to their counterparts with minor\ndifferences. Highest citation performance for ML studies is achieved for year\n2014, while this peak is observed for 2017 for DL studies. We can conclude that\nboth publication and citation rate for DL-related papers tend to increase and\noutperform ML-based studies in 5G domain by the means of citation metrics.\n",
                "链接": "https://arxiv.org/abs/2210.07327"
            },
            {
                "文章ID": "63515",
                "标题": "HADES: Homologous Automated Document Exploration and Summarization",
                "作者": " Piotr Wilczyński,  Artur Żółkowski,  Mateusz Krzyziński,  Emilia Wiśnios,  Bartosz Pieliński,  Stanisław Giziński,  Julian Sienkiewicz,  Przemysław Biecek",
                "发布日期": "2023-02-28",
                "摘要": "  This paper introduces HADES, a novel tool for automatic comparative documents\nwith similar structures. HADES is designed to streamline the work of\nprofessionals dealing with large volumes of documents, such as policy\ndocuments, legal acts, and scientific papers. The tool employs a multi-step\npipeline that begins with processing PDF documents using topic modeling,\nsummarization, and analysis of the most important words for each topic. The\nprocess concludes with an interactive web app with visualizations that\nfacilitate the comparison of the documents. HADES has the potential to\nsignificantly improve the productivity of professionals dealing with high\nvolumes of documents, reducing the time and effort required to complete tasks\nrelated to comparative document analysis. Our package is publically available\non GitHub.\n",
                "链接": "https://arxiv.org/abs/2302.13099"
            },
            {
                "文章ID": "102959",
                "标题": "OpenMSD: Towards Multilingual Scientific Documents Similarity\n  Measurement",
                "作者": " Yang Gao,  Ji Ma,  Ivan Korotkov,  Keith Hall,  Dana Alon,  Don Metzler",
                "发布日期": "2023-09-20",
                "摘要": "  We develop and evaluate multilingual scientific documents similarity\nmeasurement models in this work. Such models can be used to find related works\nin different languages, which can help multilingual researchers find and\nexplore papers more efficiently. We propose the first multilingual scientific\ndocuments dataset, Open-access Multilingual Scientific Documents (OpenMSD),\nwhich has 74M papers in 103 languages and 778M citation pairs. With OpenMSD, we\npretrain science-specialized language models, and explore different strategies\nto derive \"related\" paper pairs to fine-tune the models, including using a\nmixture of citation, co-citation, and bibliographic-coupling pairs. To further\nimprove the models' performance for non-English papers, we explore the use of\ngenerative language models to enrich the non-English papers with English\nsummaries. This allows us to leverage the models' English capabilities to\ncreate better representations for non-English papers. Our best model\nsignificantly outperforms strong baselines by 7-16% (in mean average\nprecision).\n",
                "链接": "https://arxiv.org/abs/2309.10539"
            },
            {
                "文章ID": "23276",
                "标题": "Review on Multiple Plagiarism: A Performance Comparison Study",
                "作者": " Jabir Al Nahian,  Abu Kaisar Mohammad Masum",
                "发布日期": "2022-07-01",
                "摘要": "  Plagiarism is the practice of claiming to be someone else content, thoughts\nor ideas as one own without any proper credit and citations. This paper is a\nsurvey paper that, represent the some of the great research paper and its\ncomparison that is work done on plagiarism. Now a days, plagiarism became one\nof the most interesting and crucial research points in Natural Language\nProcessing area. We review some old research paper based on different types of\nplagiarism detection and their models and algorithm, and comparison of the\naccuracy of those papers. There are many several ways which are available for\nplagiarism detection in different language. There are a few algorithms to\ndetecting plagiarism. Like, corpus, CL-CNG, LSI, Levenshtein Distance etc. We\nanalysis those papers, and learn that they used different types of algorithms\nfor detecting plagiarism. After experiment those papers, we got that some of\nthe algorithms give a better output and accuracy for detecting plagiarism. We\nare going to give a review on some papers about Plagiarism and will discuss\nabout the pros and cons of their models. And we also show a propose method for\nplagiarism detection method which based on sentience separation, word\nseparation and make sentence based on synonym and compare with any sources.\n",
                "链接": "https://arxiv.org/abs/2206.02983"
            },
            {
                "文章ID": "95351",
                "标题": "Auditory Attention Decoding with Task-Related Multi-View Contrastive\n  Learning",
                "作者": " Xiaoyu Chen,  Changde Du,  Qiongyi Zhou,  Huiguang He",
                "发布日期": "2023-08-09",
                "摘要": "  The human brain can easily focus on one speaker and suppress others in\nscenarios such as a cocktail party. Recently, researchers found that auditory\nattention can be decoded from the electroencephalogram (EEG) data. However,\nmost existing deep learning methods are difficult to use prior knowledge of\ndifferent views (that is attended speech and EEG are task-related views) and\nextract an unsatisfactory representation. Inspired by Broadbent's filter model,\nwe decode auditory attention in a multi-view paradigm and extract the most\nrelevant and important information utilizing the missing view. Specifically, we\npropose an auditory attention decoding (AAD) method based on multi-view VAE\nwith task-related multi-view contrastive (TMC) learning. Employing TMC learning\nin multi-view VAE can utilize the missing view to accumulate prior knowledge of\ndifferent views into the fusion of representation, and extract the approximate\ntask-related representation. We examine our method on two popular AAD datasets,\nand demonstrate the superiority of our method by comparing it to the\nstate-of-the-art method.\n",
                "链接": "https://arxiv.org/abs/2308.04244"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "17492",
                "标题": "Quality-Aware Decoding for Neural Machine Translation",
                "作者": " Patrick Fernandes,  António Farinhas,  Ricardo Rei,  José G. C. de Souza,  Perez Ogayo,  Graham Neubig,  André F. T. Martins",
                "发布日期": "2022-05-03",
                "摘要": "  Despite the progress in machine translation quality estimation and evaluation\nin the last years, decoding in neural machine translation (NMT) is mostly\noblivious to this and centers around finding the most probable translation\naccording to the model (MAP decoding), approximated with beam search. In this\npaper, we bring together these two lines of research and propose quality-aware\ndecoding for NMT, by leveraging recent breakthroughs in reference-free and\nreference-based MT evaluation through various inference methods like $N$-best\nreranking and minimum Bayes risk decoding. We perform an extensive comparison\nof various possible candidate generation and ranking methods across four\ndatasets and two model classes and find that quality-aware decoding\nconsistently outperforms MAP-based decoding according both to state-of-the-art\nautomatic metrics (COMET and BLEURT) and to human assessments. Our code is\navailable at https://github.com/deep-spin/qaware-decode.\n",
                "链接": "https://arxiv.org/abs/2205.00978"
            }
        ]
    },
    {
        "question": {
            "question": "请找到缓和噪声标签影响的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "94423",
                "标题": "Feature Noise Boosts DNN Generalization under Label Noise",
                "作者": " Lu Zeng,  Xuan Chen,  Xiaoshuang Shi,  Heng Tao Shen",
                "发布日期": "2023-08-04",
                "摘要": "  The presence of label noise in the training data has a profound impact on the\ngeneralization of deep neural networks (DNNs). In this study, we introduce and\ntheoretically demonstrate a simple feature noise method, which directly adds\nnoise to the features of training data, can enhance the generalization of DNNs\nunder label noise. Specifically, we conduct theoretical analyses to reveal that\nlabel noise leads to weakened DNN generalization by loosening the PAC-Bayes\ngeneralization bound, and feature noise results in better DNN generalization by\nimposing an upper bound on the mutual information between the model weights and\nthe features, which constrains the PAC-Bayes generalization bound. Furthermore,\nto ensure effective generalization of DNNs in the presence of label noise, we\nconduct application analyses to identify the optimal types and levels of\nfeature noise to add for obtaining desirable label noise generalization.\nFinally, extensive experimental results on several popular datasets demonstrate\nthe feature noise method can significantly enhance the label noise\ngeneralization of the state-of-the-art label noise method.\n",
                "链接": "https://arxiv.org/abs/2308.01609"
            },
            {
                "文章ID": "111388",
                "标题": "Label Propagation for Graph Label Noise",
                "作者": " Yao Cheng,  Caihua Shan,  Yifei Shen,  Xiang Li,  Siqiang Luo,  Dongsheng Li",
                "发布日期": "2023-10-26",
                "摘要": "  Label noise is a common challenge in large datasets, as it can significantly\ndegrade the generalization ability of deep neural networks. Most existing\nstudies focus on noisy labels in computer vision; however, graph models\nencompass both node features and graph topology as input, and become more\nsusceptible to label noise through message-passing mechanisms. Recently, only a\nfew works have been proposed to tackle the label noise on graphs. One major\nlimitation is that they assume the graph is homophilous and the labels are\nsmoothly distributed. Nevertheless, real-world graphs may contain varying\ndegrees of heterophily or even be heterophily-dominated, leading to the\ninadequacy of current methods. In this paper, we study graph label noise in the\ncontext of arbitrary heterophily, with the aim of rectifying noisy labels and\nassigning labels to previously unlabeled nodes. We begin by conducting two\nempirical analyses to explore the impact of graph homophily on graph label\nnoise. Following observations, we propose a simple yet efficient algorithm,\ndenoted as LP4GLN. Specifically, LP4GLN is an iterative algorithm with three\nsteps: (1) reconstruct the graph to recover the homophily property, (2) utilize\nlabel propagation to rectify the noisy labels, (3) select high-confidence\nlabels to retain for the next iteration. By iterating these steps, we obtain a\nset of correct labels, ultimately achieving high accuracy in the node\nclassification task. The theoretical analysis is also provided to demonstrate\nits remarkable denoising \"effect\". Finally, we conduct experiments on 10\nbenchmark datasets under varying graph heterophily levels and noise types,\ncomparing the performance of LP4GLN with 7 typical baselines. Our results\nillustrate the superior performance of the proposed LP4GLN.\n",
                "链接": "https://arxiv.org/abs/2310.16560"
            },
            {
                "文章ID": "67806",
                "标题": "Dynamics-Aware Loss for Learning with Label Noise",
                "作者": " Xiu-Chuan Li,  Xiaobo Xia,  Fei Zhu,  Tongliang Liu,  Xu-Yao Zhang,  Cheng-Lin Liu",
                "发布日期": "2023-08-08",
                "摘要": "  Label noise poses a serious threat to deep neural networks (DNNs). Employing\nrobust loss functions which reconcile fitting ability with robustness is a\nsimple but effective strategy to handle this problem. However, the widely-used\nstatic trade-off between these two factors contradicts the dynamics of DNNs\nlearning with label noise, leading to inferior performance. Therefore, we\npropose a dynamics-aware loss (DAL) to solve this problem. Considering that\nDNNs tend to first learn beneficial patterns, then gradually overfit harmful\nlabel noise, DAL strengthens the fitting ability initially, then gradually\nimproves robustness. Moreover, at the later stage, to further reduce the\nnegative impact of label noise and combat underfitting simultaneously, we let\nDNNs put more emphasis on easy examples than hard ones and introduce a\nbootstrapping term. Both the detailed theoretical analyses and extensive\nexperimental results demonstrate the superiority of our method. Our source code\ncan be found in https://github.com/XiuchuanLi/DAL.\n",
                "链接": "https://arxiv.org/abs/2303.11562"
            },
            {
                "文章ID": "48397",
                "标题": "Quantifying the Impact of Label Noise on Federated Learning",
                "作者": " Shuqi Ke,  Chao Huang,  Xin Liu",
                "发布日期": "2023-04-04",
                "摘要": "  Federated Learning (FL) is a distributed machine learning paradigm where\nclients collaboratively train a model using their local (human-generated)\ndatasets. While existing studies focus on FL algorithm development to tackle\ndata heterogeneity across clients, the important issue of data quality (e.g.,\nlabel noise) in FL is overlooked. This paper aims to fill this gap by providing\na quantitative study on the impact of label noise on FL. We derive an upper\nbound for the generalization error that is linear in the clients' label noise\nlevel. Then we conduct experiments on MNIST and CIFAR-10 datasets using various\nFL algorithms. Our empirical results show that the global model accuracy\nlinearly decreases as the noise level increases, which is consistent with our\ntheoretical analysis. We further find that label noise slows down the\nconvergence of FL training, and the global model tends to overfit when the\nnoise level is high.\n",
                "链接": "https://arxiv.org/abs/2211.07816"
            },
            {
                "文章ID": "80913",
                "标题": "Handling Realistic Label Noise in BERT Text Classification",
                "作者": " Maha Tufail Agro,  Hanan Aldarmaki",
                "发布日期": "2023-10-23",
                "摘要": "  Labels noise refers to errors in training labels caused by cheap data\nannotation methods, such as web scraping or crowd-sourcing, which can be\ndetrimental to the performance of supervised classifiers. Several methods have\nbeen proposed to counteract the effect of random label noise in supervised\nclassification, and some studies have shown that BERT is already robust against\nhigh rates of randomly injected label noise. However, real label noise is not\nrandom; rather, it is often correlated with input features or other\nannotator-specific factors. In this paper, we evaluate BERT in the presence of\ntwo types of realistic label noise: feature-dependent label noise, and\nsynthetic label noise from annotator disagreements. We show that the presence\nof these types of noise significantly degrades BERT classification performance.\nTo improve robustness, we evaluate different types of ensembles and\nnoise-cleaning methods and compare their effectiveness against label noise\nacross different datasets.\n",
                "链接": "https://arxiv.org/abs/2305.16337"
            },
            {
                "文章ID": "22618",
                "标题": "Robustness to Label Noise Depends on the Shape of the Noise Distribution\n  in Feature Space",
                "作者": " Diane Oyen,  Michal Kucer,  Nick Hengartner,  Har Simrat Singh",
                "发布日期": "2022-06-03",
                "摘要": "  Machine learning classifiers have been demonstrated, both empirically and\ntheoretically, to be robust to label noise under certain conditions -- notably\nthe typical assumption is that label noise is independent of the features given\nthe class label. We provide a theoretical framework that generalizes beyond\nthis typical assumption by modeling label noise as a distribution over feature\nspace. We show that both the scale and the shape of the noise distribution\ninfluence the posterior likelihood; and the shape of the noise distribution has\na stronger impact on classification performance if the noise is concentrated in\nfeature space where the decision boundary can be moved. For the special case of\nuniform label noise (independent of features and the class label), we show that\nthe Bayes optimal classifier for $c$ classes is robust to label noise until the\nratio of noisy samples goes above $\\frac{c-1}{c}$ (e.g. 90% for 10 classes),\nwhich we call the tipping point. However, for the special case of\nclass-dependent label noise (independent of features given the class label),\nthe tipping point can be as low as 50%. Most importantly, we show that when the\nnoise distribution targets decision boundaries (label noise is directly\ndependent on feature space), classification robustness can drop off even at a\nsmall scale of noise. Even when evaluating recent label-noise mitigation\nmethods we see reduced accuracy when label noise is dependent on features.\nThese findings explain why machine learning often handles label noise well if\nthe noise distribution is uniform in feature-space; yet it also points to the\ndifficulty of overcoming label noise when it is concentrated in a region of\nfeature space where a decision boundary can move.\n",
                "链接": "https://arxiv.org/abs/2206.01106"
            },
            {
                "文章ID": "92847",
                "标题": "Label Noise: Correcting a Correction",
                "作者": " William Toner,  Amos Storkey",
                "发布日期": "2023-07-26",
                "摘要": "  Training neural network classifiers on datasets with label noise poses a risk\nof overfitting them to the noisy labels. To address this issue, researchers\nhave explored alternative loss functions that aim to be more robust. However,\nmany of these alternatives are heuristic in nature and still vulnerable to\noverfitting or underfitting. In this work, we propose a more direct approach to\ntackling overfitting caused by label noise. We observe that the presence of\nlabel noise implies a lower bound on the noisy generalised risk. Building upon\nthis observation, we propose imposing a lower bound on the empirical risk\nduring training to mitigate overfitting. Our main contribution is providing\ntheoretical results that yield explicit, easily computable bounds on the\nminimum achievable noisy risk for different loss functions. We empirically\ndemonstrate that using these bounds significantly enhances robustness in\nvarious settings, with virtually no additional computational cost.\n",
                "链接": "https://arxiv.org/abs/2307.13100"
            },
            {
                "文章ID": "28377",
                "标题": "A law of adversarial risk, interpolation, and label noise",
                "作者": " Daniel Paleka,  Amartya Sanyal",
                "发布日期": "2023-03-15",
                "摘要": "  In supervised learning, it has been shown that label noise in the data can be\ninterpolated without penalties on test accuracy. We show that interpolating\nlabel noise induces adversarial vulnerability, and prove the first theorem\nshowing the relationship between label noise and adversarial risk for any data\ndistribution. Our results are almost tight if we do not make any assumptions on\nthe inductive bias of the learning algorithm. We then investigate how different\ncomponents of this problem affect this result, including properties of the\ndistribution. We also discuss non-uniform label noise distributions; and prove\na new theorem showing uniform label noise induces nearly as large an\nadversarial risk as the worst poisoning with the same noise rate. Then, we\nprovide theoretical and empirical evidence that uniform label noise is more\nharmful than typical real-world label noise. Finally, we show how inductive\nbiases amplify the effect of label noise and argue the need for future work in\nthis direction.\n",
                "链接": "https://arxiv.org/abs/2207.03933"
            },
            {
                "文章ID": "101526",
                "标题": "BatMan-CLR: Making Few-shots Meta-Learners Resilient Against Label Noise",
                "作者": " Jeroen M. Galjaard,  Robert Birke,  Juan Perez,  Lydia Y. Chen",
                "发布日期": "2023-09-13",
                "摘要": "  The negative impact of label noise is well studied in classical supervised\nlearning yet remains an open research question in meta-learning. Meta-learners\naim to adapt to unseen learning tasks by learning a good initial model in\nmeta-training and consecutively fine-tuning it according to new tasks during\nmeta-testing. In this paper, we present the first extensive analysis of the\nimpact of varying levels of label noise on the performance of state-of-the-art\nmeta-learners, specifically gradient-based $N$-way $K$-shot learners. We show\nthat the accuracy of Reptile, iMAML, and foMAML drops by up to 42% on the\nOmniglot and CifarFS datasets when meta-training is affected by label noise. To\nstrengthen the resilience against label noise, we propose two sampling\ntechniques, namely manifold (Man) and batch manifold (BatMan), which transform\nthe noisy supervised learners into semi-supervised ones to increase the utility\nof noisy labels. We first construct manifold samples of $N$-way\n$2$-contrastive-shot tasks through augmentation, learning the embedding via a\ncontrastive loss in meta-training, and then perform classification through\nzeroing on the embedding in meta-testing. We show that our approach can\neffectively mitigate the impact of meta-training label noise. Even with 60%\nwrong labels \\batman and \\man can limit the meta-testing accuracy drop to\n${2.5}$, ${9.4}$, ${1.1}$ percent points, respectively, with existing\nmeta-learners across the Omniglot, CifarFS, and MiniImagenet datasets.\n",
                "链接": "https://arxiv.org/abs/2309.06046"
            },
            {
                "文章ID": "121624",
                "标题": "Regroup Median Loss for Combating Label Noise",
                "作者": " Fengpeng Li,  Kemou Li,  Jinyu Tian,  Jiantao Zhou",
                "发布日期": "2023-12-12",
                "摘要": "  The deep model training procedure requires large-scale datasets of annotated\ndata. Due to the difficulty of annotating a large number of samples, label\nnoise caused by incorrect annotations is inevitable, resulting in low model\nperformance and poor model generalization. To combat label noise, current\nmethods usually select clean samples based on the small-loss criterion and use\nthese samples for training. Due to some noisy samples similar to clean ones,\nthese small-loss criterion-based methods are still affected by label noise. To\naddress this issue, in this work, we propose Regroup Median Loss (RML) to\nreduce the probability of selecting noisy samples and correct losses of noisy\nsamples. RML randomly selects samples with the same label as the training\nsamples based on a new loss processing method. Then, we combine the stable mean\nloss and the robust median loss through a proposed regrouping strategy to\nobtain robust loss estimation for noisy samples. To further improve the model\nperformance against label noise, we propose a new sample selection strategy and\nbuild a semi-supervised method based on RML. Compared to state-of-the-art\nmethods, for both the traditionally trained and semi-supervised models, RML\nachieves a significant improvement on synthetic and complex real-world\ndatasets. The source code of the paper has been released.\n",
                "链接": "https://arxiv.org/abs/2312.06273"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下文本检索任务上，是否有关于大模型在语义坍缩问题上的研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "12359",
                "标题": "Cross-Media Scientific Research Achievements Retrieval Based on Deep\n  Language Model",
                "作者": " Benzhi Wang,  Meiyu Liang,  Feifei Kou,  Mingying Xu",
                "发布日期": "2022-03-30",
                "摘要": "  Science and technology big data contain a lot of cross-media\ninformation.There are images and texts in the scientific paper.The s ingle\nmodal search method cannot well meet the needs of scientific researchers.This\npaper proposes a cross-media scientific research achievements retrieval method\nbased on deep language model (CARDL).It achieves a unified cross-media semantic\nrepresentation by learning the semantic association between different modal\ndata, and is applied to the generation of text semantic vector of scientific\nresearch achievements, and then cross-media retrieval is realized through\nsemantic similarity matching between different modal data.Experimental results\nshow that the proposed CARDL method achieves better cross-modal retrieval\nperformance than existing methods. Key words science and technology big data ;\ncross-media retrieval; cross-media semantic association learning; deep language\nmodel; semantic similarity\n",
                "链接": "https://arxiv.org/abs/2203.15595"
            },
            {
                "文章ID": "65811",
                "标题": "Semantic-Preserving Augmentation for Robust Image-Text Retrieval",
                "作者": " Sunwoo Kim,  Kyuhong Shim,  Luong Trung Nguyen,  Byonghyo Shim",
                "发布日期": "2023-03-13",
                "摘要": "  Image text retrieval is a task to search for the proper textual descriptions\nof the visual world and vice versa. One challenge of this task is the\nvulnerability to input image and text corruptions. Such corruptions are often\nunobserved during the training, and degrade the retrieval model decision\nquality substantially. In this paper, we propose a novel image text retrieval\ntechnique, referred to as robust visual semantic embedding (RVSE), which\nconsists of novel image-based and text-based augmentation techniques called\nsemantic preserving augmentation for image (SPAugI) and text (SPAugT). Since\nSPAugI and SPAugT change the original data in a way that its semantic\ninformation is preserved, we enforce the feature extractors to generate\nsemantic aware embedding vectors regardless of the corruption, improving the\nmodel robustness significantly. From extensive experiments using benchmark\ndatasets, we show that RVSE outperforms conventional retrieval schemes in terms\nof image-text retrieval performance.\n",
                "链接": "https://arxiv.org/abs/2303.05692"
            },
            {
                "文章ID": "122014",
                "标题": "Collapse-Oriented Adversarial Training with Triplet Decoupling for\n  Robust Image Retrieval",
                "作者": " Qiwei Tian,  Chenhao Lin,  Qian Li,  Zhengyu Zhao,  Chao Shen",
                "发布日期": "2023-12-13",
                "摘要": "  Adversarial training has achieved substantial performance in defending image\nretrieval systems against adversarial examples. However, existing studies still\nsuffer from two major limitations: model collapse and weak adversary. This\npaper addresses these two limitations by proposing collapse-oriented (COLO)\nadversarial training with triplet decoupling (TRIDE). Specifically, COLO\nprevents model collapse by temporally orienting the perturbation update\ndirection with a new collapse metric, while TRIDE yields a strong adversary by\nspatially decoupling the update targets of perturbation into the anchor and the\ntwo candidates of a triplet. Experimental results demonstrate that our\nCOLO-TRIDE outperforms the current state of the art by 7% on average over 10\nrobustness metrics and across 3 popular datasets. In addition, we identify the\nfairness limitations of commonly used robustness metrics in image retrieval and\npropose a new metric for more meaningful robustness evaluation. Codes will be\nmade publicly available on GitHub.\n",
                "链接": "https://arxiv.org/abs/2312.07364"
            },
            {
                "文章ID": "73561",
                "标题": "Rethinking Benchmarks for Cross-modal Image-text Retrieval",
                "作者": " Weijing Chen,  Linli Yao,  Qin Jin",
                "发布日期": "2023-04-24",
                "摘要": "  Image-text retrieval, as a fundamental and important branch of information\nretrieval, has attracted extensive research attentions. The main challenge of\nthis task is cross-modal semantic understanding and matching. Some recent works\nfocus more on fine-grained cross-modal semantic matching. With the prevalence\nof large scale multimodal pretraining models, several state-of-the-art models\n(e.g. X-VLM) have achieved near-perfect performance on widely-used image-text\nretrieval benchmarks, i.e. MSCOCO-Test-5K and Flickr30K-Test-1K. In this paper,\nwe review the two common benchmarks and observe that they are insufficient to\nassess the true capability of models on fine-grained cross-modal semantic\nmatching. The reason is that a large amount of images and texts in the\nbenchmarks are coarse-grained. Based on the observation, we renovate the\ncoarse-grained images and texts in the old benchmarks and establish the\nimproved benchmarks called MSCOCO-FG and Flickr30K-FG. Specifically, on the\nimage side, we enlarge the original image pool by adopting more similar images.\nOn the text side, we propose a novel semi-automatic renovation approach to\nrefine coarse-grained sentences into finer-grained ones with little human\neffort. Furthermore, we evaluate representative image-text retrieval models on\nour new benchmarks to demonstrate the effectiveness of our method. We also\nanalyze the capability of models on fine-grained semantic comprehension through\nextensive experiments. The results show that even the state-of-the-art models\nhave much room for improvement in fine-grained semantic understanding,\nespecially in distinguishing attributes of close objects in images. Our code\nand improved benchmark datasets are publicly available at:\nhttps://github.com/cwj1412/MSCOCO-Flikcr30K_FG, which we hope will inspire\nfurther in-depth research on cross-modal retrieval.\n",
                "链接": "https://arxiv.org/abs/2304.10824"
            },
            {
                "文章ID": "108354",
                "标题": "Direction-Oriented Visual-semantic Embedding Model for Remote Sensing\n  Image-text Retrieval",
                "作者": " Qing Ma,  Jiancheng Pan,  Cong Bai",
                "发布日期": "2023-10-13",
                "摘要": "  Image-text retrieval has developed rapidly in recent years. However, it is\nstill a challenge in remote sensing due to visual-semantic imbalance, which\nleads to incorrect matching of non-semantic visual and textual features. To\nsolve this problem, we propose a novel Direction-Oriented Visual-semantic\nEmbedding Model (DOVE) to mine the relationship between vision and language.\nConcretely, a Regional-Oriented Attention Module (ROAM) adaptively adjusts the\ndistance between the final visual and textual embeddings in the latent semantic\nspace, oriented by regional visual features. Meanwhile, a lightweight Digging\nText Genome Assistant (DTGA) is designed to expand the range of tractable\ntextual representation and enhance global word-level semantic connections using\nless attention operations. Ultimately, we exploit a global visual-semantic\nconstraint to reduce single visual dependency and serve as an external\nconstraint for the final visual and textual representations. The effectiveness\nand superiority of our method are verified by extensive experiments including\nparameter evaluation, quantitative comparison, ablation studies and visual\nanalysis, on two benchmark datasets, RSICD and RSITMD.\n",
                "链接": "https://arxiv.org/abs/2310.08276"
            },
            {
                "文章ID": "55962",
                "标题": "Understanding Imbalanced Semantic Segmentation Through Neural Collapse",
                "作者": " Zhisheng Zhong,  Jiequan Cui,  Yibo Yang,  Xiaoyang Wu,  Xiaojuan Qi,  Xiangyu Zhang,  Jiaya Jia",
                "发布日期": "2023-01-04",
                "摘要": "  A recent study has shown a phenomenon called neural collapse in that the\nwithin-class means of features and the classifier weight vectors converge to\nthe vertices of a simplex equiangular tight frame at the terminal phase of\ntraining for classification. In this paper, we explore the corresponding\nstructures of the last-layer feature centers and classifiers in semantic\nsegmentation. Based on our empirical and theoretical analysis, we point out\nthat semantic segmentation naturally brings contextual correlation and\nimbalanced distribution among classes, which breaks the equiangular and\nmaximally separated structure of neural collapse for both feature centers and\nclassifiers. However, such a symmetric structure is beneficial to\ndiscrimination for the minor classes. To preserve these advantages, we\nintroduce a regularizer on feature centers to encourage the network to learn\nfeatures closer to the appealing structure in imbalanced semantic segmentation.\nExperimental results show that our method can bring significant improvements on\nboth 2D and 3D semantic segmentation benchmarks. Moreover, our method ranks 1st\nand sets a new record (+6.8% mIoU) on the ScanNet200 test leaderboard. Code\nwill be available at https://github.com/dvlab-research/Imbalanced-Learning.\n",
                "链接": "https://arxiv.org/abs/2301.01100"
            },
            {
                "文章ID": "53193",
                "标题": "Scale-Semantic Joint Decoupling Network for Image-text Retrieval in\n  Remote Sensing",
                "作者": "corresponding author  Chengyu Zheng, corresponding author  Ning song, corresponding author  Ruoyu Zhang, corresponding author  Lei Huang, corresponding author  Zhiqiang Wei, corresponding author  Jie Nie",
                "发布日期": "2022-12-13",
                "摘要": "  Image-text retrieval in remote sensing aims to provide flexible information\nfor data analysis and application. In recent years, state-of-the-art methods\nare dedicated to ``scale decoupling'' and ``semantic decoupling'' strategies to\nfurther enhance the capability of representation. However, these previous\napproaches focus on either the disentangling scale or semantics but ignore\nmerging these two ideas in a union model, which extremely limits the\nperformance of cross-modal retrieval models. To address these issues, we\npropose a novel Scale-Semantic Joint Decoupling Network (SSJDN) for remote\nsensing image-text retrieval. Specifically, we design the Bidirectional Scale\nDecoupling (BSD) module, which exploits Salience Feature Extraction (SFE) and\nSalience-Guided Suppression (SGS) units to adaptively extract potential\nfeatures and suppress cumbersome features at other scales in a bidirectional\npattern to yield different scale clues. Besides, we design the Label-supervised\nSemantic Decoupling (LSD) module by leveraging the category semantic labels as\nprior knowledge to supervise images and texts probing significant\nsemantic-related information. Finally, we design a Semantic-guided Triple Loss\n(STL), which adaptively generates a constant to adjust the loss function to\nimprove the probability of matching the same semantic image and text and\nshorten the convergence time of the retrieval model. Our proposed SSJDN\noutperforms state-of-the-art approaches in numerical experiments conducted on\nfour benchmark remote sensing datasets.\n",
                "链接": "https://arxiv.org/abs/2212.05752"
            },
            {
                "文章ID": "75906",
                "标题": "A Large Cross-Modal Video Retrieval Dataset with Reading Comprehension",
                "作者": " Weijia Wu,  Yuzhong Zhao,  Zhuang Li,  Jiahong Li,  Hong Zhou,  Mike Zheng Shou,  Xiang Bai",
                "发布日期": "2023-05-08",
                "摘要": "  Most existing cross-modal language-to-video retrieval (VR) research focuses\non single-modal input from video, i.e., visual representation, while the text\nis omnipresent in human environments and frequently critical to understand\nvideo. To study how to retrieve video with both modal inputs, i.e., visual and\ntext semantic representations, we first introduce a large-scale and cross-modal\nVideo Retrieval dataset with text reading comprehension, TextVR, which contains\n42.2k sentence queries for 10.5k videos of 8 scenario domains, i.e., Street\nView (indoor), Street View (outdoor), Games, Sports, Driving, Activity, TV\nShow, and Cooking. The proposed TextVR requires one unified cross-modal model\nto recognize and comprehend texts, relate them to the visual context, and\ndecide what text semantic information is vital for the video retrieval task.\nBesides, we present a detailed analysis of TextVR compared to the existing\ndatasets and design a novel multimodal video retrieval baseline for the\ntext-based video retrieval task. The dataset analysis and extensive experiments\nshow that our TextVR benchmark provides many new technical challenges and\ninsights from previous datasets for the video-and-language community. The\nproject website and GitHub repo can be found at\nhttps://sites.google.com/view/loveucvpr23/guest-track and\nhttps://github.com/callsys/TextVR, respectively.\n",
                "链接": "https://arxiv.org/abs/2305.03347"
            },
            {
                "文章ID": "107265",
                "标题": "Generalized Neural Collapse for a Large Number of Classes",
                "作者": " Jiachen Jiang,  Jinxin Zhou,  Peng Wang,  Qing Qu,  Dustin Mixon,  Chong You,  Zhihui Zhu",
                "发布日期": "2023-10-30",
                "摘要": "  Neural collapse provides an elegant mathematical characterization of learned\nlast layer representations (a.k.a. features) and classifier weights in deep\nclassification models. Such results not only provide insights but also motivate\nnew techniques for improving practical deep models. However, most of the\nexisting empirical and theoretical studies in neural collapse focus on the case\nthat the number of classes is small relative to the dimension of the feature\nspace. This paper extends neural collapse to cases where the number of classes\nare much larger than the dimension of feature space, which broadly occur for\nlanguage models, retrieval systems, and face recognition applications. We show\nthat the features and classifier exhibit a generalized neural collapse\nphenomenon, where the minimum one-vs-rest margins is maximized.We provide\nempirical study to verify the occurrence of generalized neural collapse in\npractical deep neural networks. Moreover, we provide theoretical study to show\nthat the generalized neural collapse provably occurs under unconstrained\nfeature model with spherical constraint, under certain technical conditions on\nfeature dimension and number of classes.\n",
                "链接": "https://arxiv.org/abs/2310.05351"
            },
            {
                "文章ID": "113497",
                "标题": "Plot Retrieval as an Assessment of Abstract Semantic Association",
                "作者": " Shicheng Xu,  Liang Pang,  Jiangnan Li,  Mo Yu,  Fandong Meng,  Huawei Shen,  Xueqi Cheng,  Jie Zhou",
                "发布日期": "2023-11-06",
                "摘要": "  Retrieving relevant plots from the book for a query is a critical task, which\ncan improve the reading experience and efficiency of readers. Readers usually\nonly give an abstract and vague description as the query based on their own\nunderstanding, summaries, or speculations of the plot, which requires the\nretrieval model to have a strong ability to estimate the abstract semantic\nassociations between the query and candidate plots. However, existing\ninformation retrieval (IR) datasets cannot reflect this ability well. In this\npaper, we propose Plot Retrieval, a labeled dataset to train and evaluate the\nperformance of IR models on the novel task Plot Retrieval. Text pairs in Plot\nRetrieval have less word overlap and more abstract semantic association, which\ncan reflect the ability of the IR models to estimate the abstract semantic\nassociation, rather than just traditional lexical or semantic matching.\nExtensive experiments across various lexical retrieval, sparse retrieval, dense\nretrieval, and cross-encoder methods compared with human studies on Plot\nRetrieval show current IR models still struggle in capturing abstract semantic\nassociation between texts. Plot Retrieval can be the benchmark for further\nresearch on the semantic association modeling ability of IR models.\n",
                "链接": "https://arxiv.org/abs/2311.01666"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找对机器翻译数据集质量进行评估的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "19633",
                "标题": "Consistent Human Evaluation of Machine Translation across Language Pairs",
                "作者": " Daniel Licht,  Cynthia Gao,  Janice Lam,  Francisco Guzman,  Mona Diab,  Philipp Koehn",
                "发布日期": "2022-05-18",
                "摘要": "  Obtaining meaningful quality scores for machine translation systems through\nhuman evaluation remains a challenge given the high variability between human\nevaluators, partly due to subjective expectations for translation quality for\ndifferent language pairs. We propose a new metric called XSTS that is more\nfocused on semantic equivalence and a cross-lingual calibration method that\nenables more consistent assessment. We demonstrate the effectiveness of these\nnovel contributions in large scale evaluation studies across up to 14 language\npairs, with translation both into and out of English.\n",
                "链接": "https://arxiv.org/abs/2205.08533"
            },
            {
                "文章ID": "37434",
                "标题": "Rethinking Round-Trip Translation for Machine Translation Evaluation",
                "作者": " Terry Yue Zhuo,  Qiongkai Xu,  Xuanli He,  Trevor Cohn",
                "发布日期": "2023-05-16",
                "摘要": "  Automatic evaluation on low-resource language translation suffers from a\ndeficiency of parallel corpora. Round-trip translation could be served as a\nclever and straightforward technique to alleviate the requirement of the\nparallel evaluation corpus. However, there was an observation of obscure\ncorrelations between the evaluation scores by forward and round-trip\ntranslations in the era of statistical machine translation (SMT). In this\npaper, we report the surprising finding that round-trip translation can be used\nfor automatic evaluation without the references. Firstly, our revisit on the\nround-trip translation in SMT evaluation unveils that its long-standing\nmisunderstanding is essentially caused by copying mechanism. After removing\ncopying mechanism in SMT, round-trip translation scores can appropriately\nreflect the forward translation performance. Then, we demonstrate the\nrectification is overdue as round-trip translation could benefit multiple\nmachine translation evaluation tasks. To be more specific, round-trip\ntranslation could be used i) to predict corresponding forward translation\nscores; ii) to improve the performance of the recently advanced quality\nestimation model; and iii) to identify adversarial competitors in shared tasks\nvia cross-system verification.\n",
                "链接": "https://arxiv.org/abs/2209.07351"
            },
            {
                "文章ID": "6641",
                "标题": "An Overview on Machine Translation Evaluation",
                "作者": " Lifeng Han",
                "发布日期": "2022-02-23",
                "摘要": "  Since the 1950s, machine translation (MT) has become one of the important\ntasks of AI and development, and has experienced several different periods and\nstages of development, including rule-based methods, statistical methods, and\nrecently proposed neural network-based learning methods. Accompanying these\nstaged leaps is the evaluation research and development of MT, especially the\nimportant role of evaluation methods in statistical translation and neural\ntranslation research. The evaluation task of MT is not only to evaluate the\nquality of machine translation, but also to give timely feedback to machine\ntranslation researchers on the problems existing in machine translation itself,\nhow to improve and how to optimise. In some practical application fields, such\nas in the absence of reference translations, the quality estimation of machine\ntranslation plays an important role as an indicator to reveal the credibility\nof automatically translated target languages. This report mainly includes the\nfollowing contents: a brief history of machine translation evaluation (MTE),\nthe classification of research methods on MTE, and the the cutting-edge\nprogress, including human evaluation, automatic evaluation, and evaluation of\nevaluation methods (meta-evaluation). Manual evaluation and automatic\nevaluation include reference-translation based and reference-translation\nindependent participation; automatic evaluation methods include traditional\nn-gram string matching, models applying syntax and semantics, and deep learning\nmodels; evaluation of evaluation methods includes estimating the credibility of\nhuman evaluations, the reliability of the automatic evaluation, the reliability\nof the test set, etc. Advances in cutting-edge evaluation methods include\ntask-based evaluation, using pre-trained language models based on big data, and\nlightweight optimisation models using distillation techniques.\n",
                "链接": "https://arxiv.org/abs/2202.11027"
            },
            {
                "文章ID": "87010",
                "标题": "Evaluation of Chinese-English Machine Translation of Emotion-Loaded\n  Microblog Texts: A Human Annotated Dataset for the Quality Assessment of\n  Emotion Translation",
                "作者": " Shenbin Qian,  Constantin Orasan,  Felix do Carmo,  Qiuliang Li,  Diptesh Kanojia",
                "发布日期": "2023-06-22",
                "摘要": "  In this paper, we focus on how current Machine Translation (MT) tools perform\non the translation of emotion-loaded texts by evaluating outputs from Google\nTranslate according to a framework proposed in this paper. We propose this\nevaluation framework based on the Multidimensional Quality Metrics (MQM) and\nperform a detailed error analysis of the MT outputs. From our analysis, we\nobserve that about 50% of the MT outputs fail to preserve the original emotion.\nAfter further analysis of the errors, we find that emotion carrying words and\nlinguistic phenomena such as polysemous words, negation, abbreviation etc., are\ncommon causes for these translation errors.\n",
                "链接": "https://arxiv.org/abs/2306.11900"
            },
            {
                "文章ID": "59415",
                "标题": "An Evaluation of Persian-English Machine Translation Datasets with\n  Transformers",
                "作者": " Amir Sartipi,  Meghdad Dehghan,  Afsaneh Fatemi",
                "发布日期": "2023-02-02",
                "摘要": "  Nowadays, many researchers are focusing their attention on the subject of\nmachine translation (MT). However, Persian machine translation has remained\nunexplored despite a vast amount of research being conducted in languages with\nhigh resources, such as English. Moreover, while a substantial amount of\nresearch has been undertaken in statistical machine translation for some\ndatasets in Persian, there is currently no standard baseline for\ntransformer-based text2text models on each corpus. This study collected and\nanalysed the most popular and valuable parallel corpora, which were used for\nPersian-English translation. Furthermore, we fine-tuned and evaluated two\nstate-of-the-art attention-based seq2seq models on each dataset separately (48\nresults). We hope this paper will assist researchers in comparing their Persian\nto English and vice versa machine translation results to a standard baseline.\n",
                "链接": "https://arxiv.org/abs/2302.00321"
            },
            {
                "文章ID": "17492",
                "标题": "Quality-Aware Decoding for Neural Machine Translation",
                "作者": " Patrick Fernandes,  António Farinhas,  Ricardo Rei,  José G. C. de Souza,  Perez Ogayo,  Graham Neubig,  André F. T. Martins",
                "发布日期": "2022-05-03",
                "摘要": "  Despite the progress in machine translation quality estimation and evaluation\nin the last years, decoding in neural machine translation (NMT) is mostly\noblivious to this and centers around finding the most probable translation\naccording to the model (MAP decoding), approximated with beam search. In this\npaper, we bring together these two lines of research and propose quality-aware\ndecoding for NMT, by leveraging recent breakthroughs in reference-free and\nreference-based MT evaluation through various inference methods like $N$-best\nreranking and minimum Bayes risk decoding. We perform an extensive comparison\nof various possible candidate generation and ranking methods across four\ndatasets and two model classes and find that quality-aware decoding\nconsistently outperforms MAP-based decoding according both to state-of-the-art\nautomatic metrics (COMET and BLEURT) and to human assessments. Our code is\navailable at https://github.com/deep-spin/qaware-decode.\n",
                "链接": "https://arxiv.org/abs/2205.00978"
            },
            {
                "文章ID": "38541",
                "标题": "Approaching English-Polish Machine Translation Quality Assessment with\n  Neural-based Methods",
                "作者": " Artur Nowakowski",
                "发布日期": "2022-09-23",
                "摘要": "  This paper presents our contribution to the PolEval 2021 Task 2: Evaluation\nof translation quality assessment metrics. We describe experiments with\npre-trained language models and state-of-the-art frameworks for translation\nquality assessment in both nonblind and blind versions of the task. Our\nsolutions ranked second in the nonblind version and third in the blind version.\n",
                "链接": "https://arxiv.org/abs/2209.11016"
            },
            {
                "文章ID": "54518",
                "标题": "Extrinsic Evaluation of Machine Translation Metrics",
                "作者": " Nikita Moghe,  Tom Sherborne,  Mark Steedman,  Alexandra Birch",
                "发布日期": "2023-06-21",
                "摘要": "  Automatic machine translation (MT) metrics are widely used to distinguish the\ntranslation qualities of machine translation systems across relatively large\ntest sets (system-level evaluation). However, it is unclear if automatic\nmetrics are reliable at distinguishing good translations from bad translations\nat the sentence level (segment-level evaluation). In this paper, we investigate\nhow useful MT metrics are at detecting the success of a machine translation\ncomponent when placed in a larger platform with a downstream task. We evaluate\nthe segment-level performance of the most widely used MT metrics (chrF, COMET,\nBERTScore, etc.) on three downstream cross-lingual tasks (dialogue state\ntracking, question answering, and semantic parsing). For each task, we only\nhave access to a monolingual task-specific model. We calculate the correlation\nbetween the metric's ability to predict a good/bad translation with the\nsuccess/failure on the final task for the Translate-Test setup. Our experiments\ndemonstrate that all metrics exhibit negligible correlation with the extrinsic\nevaluation of the downstream outcomes. We also find that the scores provided by\nneural metrics are not interpretable mostly because of undefined ranges. We\nsynthesise our analysis into recommendations for future MT metrics to produce\nlabels rather than scores for more informative interaction between machine\ntranslation and multilingual language understanding.\n",
                "链接": "https://arxiv.org/abs/2212.10297"
            },
            {
                "文章ID": "109147",
                "标题": "xCOMET: Transparent Machine Translation Evaluation through Fine-grained\n  Error Detection",
                "作者": " Nuno M. Guerreiro,  Ricardo Rei,  Daan van Stigt,  Luisa Coheur,  Pierre Colombo,  André F. T. Martins",
                "发布日期": "2023-10-17",
                "摘要": "  Widely used learned metrics for machine translation evaluation, such as COMET\nand BLEURT, estimate the quality of a translation hypothesis by providing a\nsingle sentence-level score. As such, they offer little insight into\ntranslation errors (e.g., what are the errors and what is their severity). On\nthe other hand, generative large language models (LLMs) are amplifying the\nadoption of more granular strategies to evaluation, attempting to detail and\ncategorize translation errors. In this work, we introduce xCOMET, an\nopen-source learned metric designed to bridge the gap between these approaches.\nxCOMET integrates both sentence-level evaluation and error span detection\ncapabilities, exhibiting state-of-the-art performance across all types of\nevaluation (sentence-level, system-level, and error span detection). Moreover,\nit does so while highlighting and categorizing error spans, thus enriching the\nquality assessment. We also provide a robustness analysis with stress tests,\nand show that xCOMET is largely capable of identifying localized critical\nerrors and hallucinations.\n",
                "链接": "https://arxiv.org/abs/2310.10482"
            },
            {
                "文章ID": "87351",
                "标题": "Towards Explainable Evaluation Metrics for Machine Translation",
                "作者": " Christoph Leiter,  Piyawat Lertvittayakumjorn,  Marina Fomicheva,  Wei Zhao,  Yang Gao,  Steffen Eger",
                "发布日期": "2023-06-23",
                "摘要": "  Unlike classical lexical overlap metrics such as BLEU, most current\nevaluation metrics for machine translation (for example, COMET or BERTScore)\nare based on black-box large language models. They often achieve strong\ncorrelations with human judgments, but recent research indicates that the\nlower-quality classical metrics remain dominant, one of the potential reasons\nbeing that their decision processes are more transparent. To foster more\nwidespread acceptance of novel high-quality metrics, explainability thus\nbecomes crucial. In this concept paper, we identify key properties as well as\nkey goals of explainable machine translation metrics and provide a\ncomprehensive synthesis of recent techniques, relating them to our established\ngoals and properties. In this context, we also discuss the latest\nstate-of-the-art approaches to explainable metrics based on generative models\nsuch as ChatGPT and GPT4. Finally, we contribute a vision of next-generation\napproaches, including natural language explanations. We hope that our work can\nhelp catalyze and guide future research on explainable evaluation metrics and,\nmediately, also contribute to better and more transparent machine translation\nsystems.\n",
                "链接": "https://arxiv.org/abs/2306.13041"
            }
        ]
    },
    {
        "question": {
            "question": "查找大语言模型相关的分析类型的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "70928",
                "标题": "Revolutionizing Single Cell Analysis: The Power of Large Language Models\n  for Cell Type Annotation",
                "作者": " Zehua Zeng,  Hongwu Du",
                "发布日期": "2023-04-07",
                "摘要": "  In recent years, single cell RNA sequencing has become a widely used\ntechnique to study cellular diversity and function. However, accurately\nannotating cell types from single cell data has been a challenging task, as it\nrequires extensive knowledge of cell biology and gene function. The emergence\nof large language models such as ChatGPT and New Bing in 2023 has\nrevolutionized this process by integrating the scientific literature and\nproviding accurate annotations of cell types. This breakthrough enables\nresearchers to conduct literature reviews more efficiently and accurately, and\ncan potentially uncover new insights into cell type annotation. By using\nChatGPT to annotate single cell data, we can relate rare cell type to their\nfunction and reveal specific differentiation trajectories of cell subtypes that\nwere previously overlooked. This can have important applications in\nunderstanding cancer progression, mammalian development, and stem cell\ndifferentiation, and can potentially lead to the discovery of key cells that\ninterrupt the differentiation pathway and solve key problems in the life\nsciences. Overall, the future of cell type annotation in single cell data looks\npromising and the Large Language model will be an important milestone in the\nhistory of single cell analysis.\n",
                "链接": "https://arxiv.org/abs/2304.02697"
            },
            {
                "文章ID": "101120",
                "标题": "Analysis of Disinformation and Fake News Detection Using Fine-Tuned\n  Large Language Model",
                "作者": " Bohdan M. Pavlyshenko",
                "发布日期": "2023-09-12",
                "摘要": "  The paper considers the possibility of fine-tuning Llama 2 large language\nmodel (LLM) for the disinformation analysis and fake news detection. For\nfine-tuning, the PEFT/LoRA based approach was used. In the study, the model was\nfine-tuned for the following tasks: analysing a text on revealing\ndisinformation and propaganda narratives, fact checking, fake news detection,\nmanipulation analytics, extracting named entities with their sentiments. The\nobtained results show that the fine-tuned Llama 2 model can perform a deep\nanalysis of texts and reveal complex styles and narratives. Extracted\nsentiments for named entities can be considered as predictive features in\nsupervised machine learning models.\n",
                "链接": "https://arxiv.org/abs/2309.04704"
            },
            {
                "文章ID": "94373",
                "标题": "FinVis-GPT: A Multimodal Large Language Model for Financial Chart\n  Analysis",
                "作者": " Ziao Wang,  Yuhang Li,  Junda Wu,  Jaehyeon Soon,  Xiaofeng Zhang",
                "发布日期": "2023-08-04",
                "摘要": "  In this paper, we propose FinVis-GPT, a novel multimodal large language model\n(LLM) specifically designed for financial chart analysis. By leveraging the\npower of LLMs and incorporating instruction tuning and multimodal capabilities,\nFinVis-GPT is capable of interpreting financial charts and providing valuable\nanalysis. To train FinVis-GPT, a financial task oriented dataset was generated\nfor pre-training alignment and instruction tuning, comprising various types of\nfinancial charts and their corresponding descriptions. We evaluate the model\nperformance via several case studies due to the time limit, and the promising\nresults demonstrated that FinVis-GPT is superior in various financial chart\nrelated tasks, including generating descriptions, answering questions and\npredicting future market trends, surpassing existing state-of-the-art\nmultimodal LLMs. The proposed FinVis-GPT serves as a pioneering effort in\nutilizing multimodal LLMs in the finance domain and our generated dataset will\nbe release for public use in the near future to speedup related research.\n",
                "链接": "https://arxiv.org/abs/2308.01430"
            },
            {
                "文章ID": "12949",
                "标题": "Effect and Analysis of Large-scale Language Model Rescoring on\n  Competitive ASR Systems",
                "作者": " Takuma Udagawa,  Masayuki Suzuki,  Gakuto Kurata,  Nobuyasu Itoh,  George Saon",
                "发布日期": "2022-08-19",
                "摘要": "  Large-scale language models (LLMs) such as GPT-2, BERT and RoBERTa have been\nsuccessfully applied to ASR N-best rescoring. However, whether or how they can\nbenefit competitive, near state-of-the-art ASR systems remains unexplored. In\nthis study, we incorporate LLM rescoring into one of the most competitive ASR\nbaselines: the Conformer-Transducer model. We demonstrate that consistent\nimprovement is achieved by the LLM's bidirectionality, pretraining, in-domain\nfinetuning and context augmentation. Furthermore, our lexical analysis sheds\nlight on how each of these components may be contributing to the ASR\nperformance.\n",
                "链接": "https://arxiv.org/abs/2204.00212"
            },
            {
                "文章ID": "110493",
                "标题": "LUNA: A Model-Based Universal Analysis Framework for Large Language\n  Models",
                "作者": " Da Song,  Xuan Xie,  Jiayang Song,  Derui Zhu,  Yuheng Huang,  Felix Juefei-Xu,  Lei Ma",
                "发布日期": "2023-10-24",
                "摘要": "  Over the past decade, Artificial Intelligence (AI) has had great success\nrecently and is being used in a wide range of academic and industrial fields.\nMore recently, LLMs have made rapid advancements that have propelled AI to a\nnew level, enabling even more diverse applications and industrial domains with\nintelligence, particularly in areas like software engineering and natural\nlanguage processing. Nevertheless, a number of emerging trustworthiness\nconcerns and issues exhibited in LLMs have already recently received much\nattention, without properly solving which the widespread adoption of LLMs could\nbe greatly hindered in practice. The distinctive characteristics of LLMs, such\nas the self-attention mechanism, extremely large model scale, and\nautoregressive generation schema, differ from classic AI software based on CNNs\nand RNNs and present new challenges for quality analysis. Up to the present, it\nstill lacks universal and systematic analysis techniques for LLMs despite the\nurgent industrial demand. Towards bridging this gap, we initiate an early\nexploratory study and propose a universal analysis framework for LLMs, LUNA,\ndesigned to be general and extensible, to enable versatile analysis of LLMs\nfrom multiple quality perspectives in a human-interpretable manner. In\nparticular, we first leverage the data from desired trustworthiness\nperspectives to construct an abstract model as an auxiliary analysis asset,\nwhich is empowered by various abstract model construction methods. To assess\nthe quality of the abstract model, we collect and define a number of evaluation\nmetrics, aiming at both abstract model level and the semantics level. Then, the\nsemantics, which is the degree of satisfaction of the LLM w.r.t. the\ntrustworthiness perspective, is bound to and enriches the abstract model with\nsemantics, which enables more detailed analysis applications for diverse\npurposes.\n",
                "链接": "https://arxiv.org/abs/2310.14211"
            },
            {
                "文章ID": "105266",
                "标题": "A Large Language Model Approach to Educational Survey Feedback Analysis",
                "作者": " Michael J. Parker,  Caitlin Anderson,  Claire Stone,  YeaRim Oh",
                "发布日期": "2023-10-02",
                "摘要": "  This paper assesses the potential for the large language models (LLMs) GPT-4\nand GPT-3.5 to aid in deriving insight from education feedback surveys.\nExploration of LLM use cases in education has focused on teaching and learning,\nwith less exploration of capabilities in education feedback analysis. Survey\nanalysis in education involves goals such as finding gaps in curricula or\nevaluating teachers, often requiring time-consuming manual processing of\ntextual responses. LLMs have the potential to provide a flexible means of\nachieving these goals without specialized machine learning models or\nfine-tuning. We demonstrate a versatile approach to such goals by treating them\nas sequences of natural language processing (NLP) tasks including\nclassification (multi-label, multi-class, and binary), extraction, thematic\nanalysis, and sentiment analysis, each performed by LLM. We apply these\nworkflows to a real-world dataset of 2500 end-of-course survey comments from\nbiomedical science courses, and evaluate a zero-shot approach (i.e., requiring\nno examples or labeled training data) across all tasks, reflecting education\nsettings, where labeled data is often scarce. By applying effective prompting\npractices, we achieve human-level performance on multiple tasks with GPT-4,\nenabling workflows necessary to achieve typical goals. We also show the\npotential of inspecting LLMs' chain-of-thought (CoT) reasoning for providing\ninsight that may foster confidence in practice. Moreover, this study features\ndevelopment of a versatile set of classification categories, suitable for\nvarious course types (online, hybrid, or in-person) and amenable to\ncustomization. Our results suggest that LLMs can be used to derive a range of\ninsights from survey text.\n",
                "链接": "https://arxiv.org/abs/2309.17447"
            },
            {
                "文章ID": "119149",
                "标题": "mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large\n  Language Model",
                "作者": " Anwen Hu,  Yaya Shi,  Haiyang Xu,  Jiabo Ye,  Qinghao Ye,  Ming Yan,  Chenliang Li,  Qi Qian,  Ji Zhang,  Fei Huang",
                "发布日期": "2023-12-01",
                "摘要": "  Recently, the strong text creation ability of Large Language Models(LLMs) has\ngiven rise to many tools for assisting paper reading or even writing. However,\nthe weak diagram analysis abilities of LLMs or Multimodal LLMs greatly limit\ntheir application scenarios, especially for scientific academic paper writing.\nIn this work, towards a more versatile copilot for academic paper writing, we\nmainly focus on strengthening the multi-modal diagram analysis ability of\nMultimodal LLMs. By parsing Latex source files of high-quality papers, we\ncarefully build a multi-modal diagram understanding dataset M-Paper. By\naligning diagrams in the paper with related paragraphs, we construct\nprofessional diagram analysis samples for training and evaluation. M-Paper is\nthe first dataset to support joint comprehension of multiple scientific\ndiagrams, including figures and tables in the format of images or Latex codes.\nBesides, to better align the copilot with the user's intention, we introduce\nthe `outline' as the control signal, which could be directly given by the user\nor revised based on auto-generated ones. Comprehensive experiments with a\nstate-of-the-art Mumtimodal LLM demonstrate that training on our dataset shows\nstronger scientific diagram understanding performance, including diagram\ncaptioning, diagram analysis, and outline recommendation. The dataset, code,\nand model are available at\nhttps://github.com/X-PLUG/mPLUG-DocOwl/tree/main/PaperOwl.\n",
                "链接": "https://arxiv.org/abs/2311.18248"
            },
            {
                "文章ID": "118071",
                "标题": "Benchmarking Large Language Model Volatility",
                "作者": " Boyang Yu",
                "发布日期": "2023-11-28",
                "摘要": "  The impact of non-deterministic outputs from Large Language Models (LLMs) is\nnot well examined for financial text understanding tasks. Through a compelling\ncase study on investing in the US equity market via news sentiment analysis, we\nuncover substantial variability in sentence-level sentiment classification\nresults, underscoring the innate volatility of LLM outputs. These uncertainties\ncascade downstream, leading to more significant variations in portfolio\nconstruction and return. While tweaking the temperature parameter in the\nlanguage model decoder presents a potential remedy, it comes at the expense of\nstifled creativity. Similarly, while ensembling multiple outputs mitigates the\neffect of volatile outputs, it demands a notable computational investment. This\nwork furnishes practitioners with invaluable insights for adeptly navigating\nuncertainty in the integration of LLMs into financial decision-making,\nparticularly in scenarios dictated by non-deterministic information.\n",
                "链接": "https://arxiv.org/abs/2311.15180"
            },
            {
                "文章ID": "110853",
                "标题": "LLM-in-the-loop: Leveraging Large Language Model for Thematic Analysis",
                "作者": " Shih-Chieh Dai,  Aiping Xiong,  Lun-Wei Ku",
                "发布日期": "2023-10-24",
                "摘要": "  Thematic analysis (TA) has been widely used for analyzing qualitative data in\nmany disciplines and fields. To ensure reliable analysis, the same piece of\ndata is typically assigned to at least two human coders. Moreover, to produce\nmeaningful and useful analysis, human coders develop and deepen their data\ninterpretation and coding over multiple iterations, making TA labor-intensive\nand time-consuming. Recently the emerging field of large language models (LLMs)\nresearch has shown that LLMs have the potential replicate human-like behavior\nin various tasks: in particular, LLMs outperform crowd workers on\ntext-annotation tasks, suggesting an opportunity to leverage LLMs on TA. We\npropose a human-LLM collaboration framework (i.e., LLM-in-the-loop) to conduct\nTA with in-context learning (ICL). This framework provides the prompt to frame\ndiscussions with a LLM (e.g., GPT-3.5) to generate the final codebook for TA.\nWe demonstrate the utility of this framework using survey datasets on the\naspects of the music listening experience and the usage of a password manager.\nResults of the two case studies show that the proposed framework yields similar\ncoding quality to that of human coders but reduces TA's labor and time demands.\n",
                "链接": "https://arxiv.org/abs/2310.15100"
            },
            {
                "文章ID": "124538",
                "标题": "Large Language Model (LLM) Bias Index -- LLMBI",
                "作者": " Abiodun Finbarrs Oketunji,  Muhammad Anas,  Deepthi Saina",
                "发布日期": "2023-12-27",
                "摘要": "  The Large Language Model Bias Index (LLMBI) is a pioneering approach designed\nto quantify and address biases inherent in large language models (LLMs), such\nas GPT-4. We recognise the increasing prevalence and impact of LLMs across\ndiverse sectors. This research introduces a novel metric, LLMBI, to\nsystematically measure and mitigate biases potentially skewing model responses.\nWe formulated LLMBI using a composite scoring system incorporating multiple\ndimensions of bias, including but not limited to age, gender, and racial\nbiases.\n  To operationalise this metric, we engaged in a multi-step process involving\ncollecting and annotating LLM responses, applying sophisticated Natural\nLanguage Processing (NLP) techniques for bias detection, and computing the\nLLMBI score through a specially crafted mathematical formula. The formula\nintegrates weighted averages of various bias dimensions, a penalty for dataset\ndiversity deficiencies, and a correction for sentiment biases. Our empirical\nanalysis, conducted using responses from OpenAI's API, employs advanced\nsentiment analysis as a representative method for bias detection.\n  The research reveals LLMs, whilst demonstrating impressive capabilities in\ntext generation, exhibit varying degrees of bias across different dimensions.\nLLMBI provides a quantifiable measure to compare biases across models and over\ntime, offering a vital tool for systems engineers, researchers and regulators\nin enhancing the fairness and reliability of LLMs. It highlights the potential\nof LLMs in mimicking unbiased human-like responses. Additionally, it\nunderscores the necessity of continuously monitoring and recalibrating such\nmodels to align with evolving societal norms and ethical standards.\n",
                "链接": "https://arxiv.org/abs/2312.14769"
            }
        ]
    },
    {
        "question": {
            "question": "查询2022年以来指令遵循数据集构建相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "119138",
                "标题": "Automatic Construction of a Korean Toxic Instruction Dataset for Ethical\n  Tuning of Large Language Models",
                "作者": " Sungjoo Byun,  Dongjun Jang,  Hyemi Jo,  Hyopil Shin",
                "发布日期": "2023-12-01",
                "摘要": "  Caution: this paper may include material that could be offensive or\ndistressing.\n  The advent of Large Language Models (LLMs) necessitates the development of\ntraining approaches that mitigate the generation of unethical language and\naptly manage toxic user queries. Given the challenges related to human labor\nand the scarcity of data, we present KoTox, comprising 39K unethical\ninstruction-output pairs. This collection of automatically generated toxic\ninstructions refines the training of LLMs and establishes a foundational\nframework for improving LLMs' ethical awareness and response to various toxic\ninputs, promoting more secure and responsible interactions in Natural Language\nProcessing (NLP) applications.\n",
                "链接": "https://arxiv.org/abs/2311.18215"
            },
            {
                "文章ID": "78681",
                "标题": "InstructIE: A Chinese Instruction-based Information Extraction Dataset",
                "作者": " Honghao Gui,  Jintian Zhang,  Hongbin Ye,  Ningyu Zhang",
                "发布日期": "2023-05-22",
                "摘要": "  We introduce a new Information Extraction (IE) task dubbed Instruction-based\nIE, which aims to ask the system to follow specific instructions or guidelines\nto extract information. To facilitate research in this area, we construct a\ndataset called InstructIE, consisting of 270,000 weakly supervised data from\nChinese Wikipedia and 1,000 high-quality crowdsourced annotated instances. We\nfurther evaluate the performance of various baseline models on the InstructIE\ndataset. The results reveal that although current models exhibit promising\nperformance, there is still room for improvement. Furthermore, we conduct a\ncomprehensive case study analysis, underlining the challenges inherent in the\nInstruction-based IE task. Code and dataset are available at\nhttps://github.com/zjunlp/DeepKE/tree/main/example/llm.\n",
                "链接": "https://arxiv.org/abs/2305.11527"
            },
            {
                "文章ID": "85650",
                "标题": "Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for\n  Large Language Models",
                "作者": " Yin Fang,  Xiaozhuan Liang,  Ningyu Zhang,  Kangwei Liu,  Rui Huang,  Zhuo Chen,  Xiaohui Fan,  Huajun Chen",
                "发布日期": "2023-12-01",
                "摘要": "  Large Language Models (LLMs), with their remarkable task-handling\ncapabilities and innovative outputs, have catalyzed significant advancements\nacross a spectrum of fields. However, their proficiency within specialized\ndomains such as biomolecular studies remains limited. To address this\nchallenge, we introduce Mol-Instructions, a comprehensive instruction dataset\ndesigned for the biomolecular domain. Mol-Instructions encompasses three key\ncomponents: molecule-oriented instructions, protein-oriented instructions, and\nbiomolecular text instructions. Each component aims to improve the\nunderstanding and prediction capabilities of LLMs concerning biomolecular\nfeatures and behaviors. Through extensive instruction tuning experiments on\nLLMs, we demonstrate the effectiveness of Mol-Instructions in enhancing large\nmodels' performance in the intricate realm of biomolecular studies, thus\nfostering progress in the biomolecular research community. Mol-Instructions is\npublicly available for ongoing research and will undergo regular updates to\nenhance its applicability.\n",
                "链接": "https://arxiv.org/abs/2306.08018"
            },
            {
                "文章ID": "113182",
                "标题": "Construction Artifacts in Metaphor Identification Datasets",
                "作者": " Joanne Boisson,  Luis Espinosa-Anke,  Jose Camacho-Collados",
                "发布日期": "2023-11-17",
                "摘要": "  Metaphor identification aims at understanding whether a given expression is\nused figuratively in context. However, in this paper we show how existing\nmetaphor identification datasets can be gamed by fully ignoring the potential\nmetaphorical expression or the context in which it occurs. We test this\nhypothesis in a variety of datasets and settings, and show that metaphor\nidentification systems based on language models without complete information\ncan be competitive with those using the full context. This is due to the\nconstruction procedures to build such datasets, which introduce unwanted biases\nfor positive and negative classes. Finally, we test the same hypothesis on\ndatasets that are carefully sampled from natural corpora and where this bias is\nnot present, making these datasets more challenging and reliable.\n",
                "链接": "https://arxiv.org/abs/2311.00790"
            },
            {
                "文章ID": "50993",
                "标题": "Beyond Counting Datasets: A Survey of Multilingual Dataset Construction\n  and Necessary Resources",
                "作者": " Xinyan Velocity Yu,  Akari Asai,  Trina Chatterjee,  Junjie Hu,  Eunsol Choi",
                "发布日期": "2022-11-29",
                "摘要": "  While the NLP community is generally aware of resource disparities among\nlanguages, we lack research that quantifies the extent and types of such\ndisparity. Prior surveys estimating the availability of resources based on the\nnumber of datasets can be misleading as dataset quality varies: many datasets\nare automatically induced or translated from English data. To provide a more\ncomprehensive picture of language resources, we examine the characteristics of\n156 publicly available NLP datasets. We manually annotate how they are created,\nincluding input text and label sources and tools used to build them, and what\nthey study, tasks they address and motivations for their creation. After\nquantifying the qualitative NLP resource gap across languages, we discuss how\nto improve data collection in low-resource languages. We survey\nlanguage-proficient NLP researchers and crowd workers per language, finding\nthat their estimated availability correlates with dataset availability. Through\ncrowdsourcing experiments, we identify strategies for collecting high-quality\nmultilingual data on the Mechanical Turk platform. We conclude by making macro\nand micro-level suggestions to the NLP community and individual researchers for\nfuture multilingual data development.\n",
                "链接": "https://arxiv.org/abs/2211.15649"
            },
            {
                "文章ID": "120242",
                "标题": "MUFFIN: Curating Multi-Faceted Instructions for Improving\n  Instruction-Following",
                "作者": " Renze Lou,  Kai Zhang,  Jian Xie,  Yuxuan Sun,  Janice Ahn,  Hanzi Xu,  Yu Su,  Wenpeng Yin",
                "发布日期": "2023-12-06",
                "摘要": "  In the realm of large language models (LLMs), enhancing instruction-following\ncapability often involves curating expansive training data. This is achieved\nthrough two primary schemes: i) Scaling-Inputs: Amplifying (input, output)\npairs per task instruction, aiming for better instruction adherence. ii)\nScaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction,\noutput) pair (without requiring a separate input anymore). However, LLMs under\nScaling-Inputs tend to be overly sensitive to inputs, leading to\nmisinterpretation or non-compliance with instructions. Conversely, Scaling\nInput-Free Tasks demands a substantial number of tasks but is less effective in\ninstruction following when dealing with instances in Scaling-Inputs. This work\nintroduces MUFFIN, a new scheme of instruction-following dataset curation.\nSpecifically, we automatically Scale Tasks per Input by diversifying these\ntasks with various input facets. Experimental results across four zero-shot\nbenchmarks, spanning both Scaling-Inputs and Scaling Input-Free Tasks schemes,\nreveal that LLMs, at various scales, trained on MUFFIN generally demonstrate\nsuperior instruction-following capabilities compared to those trained on the\ntwo aforementioned schemes.\n",
                "链接": "https://arxiv.org/abs/2312.02436"
            },
            {
                "文章ID": "97640",
                "标题": "Instruction Tuning for Large Language Models: A Survey",
                "作者": " Shengyu Zhang,  Linfeng Dong,  Xiaoya Li,  Sen Zhang,  Xiaofei Sun,  Shuhe Wang,  Jiwei Li,  Runyi Hu,  Tianwei Zhang,  Fei Wu,  Guoyin Wang",
                "发布日期": "2023-10-10",
                "摘要": "  This paper surveys research works in the quickly advancing field of\ninstruction tuning (IT), a crucial technique to enhance the capabilities and\ncontrollability of large language models (LLMs). Instruction tuning refers to\nthe process of further training LLMs on a dataset consisting of\n\\textsc{(instruction, output)} pairs in a supervised fashion, which bridges the\ngap between the next-word prediction objective of LLMs and the users' objective\nof having LLMs adhere to human instructions. In this work, we make a systematic\nreview of the literature, including the general methodology of IT, the\nconstruction of IT datasets, the training of IT models, and applications to\ndifferent modalities, domains and applications, along with an analysis on\naspects that influence the outcome of IT (e.g., generation of instruction\noutputs, size of the instruction dataset, etc). We also review the potential\npitfalls of IT along with criticism against it, along with efforts pointing out\ncurrent deficiencies of existing strategies and suggest some avenues for\nfruitful research. Project page: github.com/xiaoya-li/Instruction-Tuning-Survey\n",
                "链接": "https://arxiv.org/abs/2308.10792"
            },
            {
                "文章ID": "21007",
                "标题": "Learning Action Conditions from Instructional Manuals for Instruction\n  Understanding",
                "作者": " Te-Lin Wu,  Caiqi Zhang,  Qingyuan Hu,  Alex Spangher,  Nanyun Peng",
                "发布日期": "2022-05-26",
                "摘要": "  The ability to infer pre- and postconditions of an action is vital for\ncomprehending complex instructions, and is essential for applications such as\nautonomous instruction-guided agents and assistive AI that supports humans to\nperform physical tasks. In this work, we propose a task dubbed action condition\ninference, and collecting a high-quality, human annotated dataset of\npreconditions and postconditions of actions in instructional manuals. We\npropose a weakly supervised approach to automatically construct large-scale\ntraining instances from online instructional manuals, and curate a densely\nhuman-annotated and validated dataset to study how well the current NLP models\ncan infer action-condition dependencies in the instruction texts. We design two\ntypes of models differ by whether contextualized and global information is\nleveraged, as well as various combinations of heuristics to construct the weak\nsupervisions. Our experimental results show a >20% F1-score improvement with\nconsidering the entire instruction contexts and a >6% F1-score benefit with the\nproposed heuristics.\n",
                "链接": "https://arxiv.org/abs/2205.12420"
            },
            {
                "文章ID": "93939",
                "标题": "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world\n  APIs",
                "作者": " Yujia Qin,  Shihao Liang,  Yining Ye,  Kunlun Zhu,  Lan Yan,  Yaxi Lu,  Yankai Lin,  Xin Cong,  Xiangru Tang,  Bill Qian,  Sihan Zhao,  Lauren Hong,  Runchu Tian,  Ruobing Xie,  Jie Zhou,  Mark Gerstein,  Dahai Li,  Zhiyuan Liu,  Maosong Sun",
                "发布日期": "2023-10-04",
                "摘要": "  Despite the advancements of open-source large language models (LLMs), e.g.,\nLLaMA, they remain significantly limited in tool-use capabilities, i.e., using\nexternal tools (APIs) to fulfill human instructions. The reason is that current\ninstruction tuning largely focuses on basic language tasks but ignores the\ntool-use domain. This is in contrast to the excellent tool-use capabilities of\nstate-of-the-art (SOTA) closed-source LLMs, e.g., ChatGPT. To bridge this gap,\nwe introduce ToolLLM, a general tool-use framework encompassing data\nconstruction, model training, and evaluation. We first present ToolBench, an\ninstruction-tuning dataset for tool use, which is constructed automatically\nusing ChatGPT. Specifically, the construction can be divided into three stages:\n(i) API collection: we collect 16,464 real-world RESTful APIs spanning 49\ncategories from RapidAPI Hub; (ii) instruction generation: we prompt ChatGPT to\ngenerate diverse instructions involving these APIs, covering both single-tool\nand multi-tool scenarios; (iii) solution path annotation: we use ChatGPT to\nsearch for a valid solution path (chain of API calls) for each instruction. To\nenhance the reasoning capabilities of LLMs, we develop a novel depth-first\nsearch-based decision tree algorithm. It enables LLMs to evaluate multiple\nreasoning traces and expand the search space. Moreover, to evaluate the\ntool-use capabilities of LLMs, we develop an automatic evaluator: ToolEval.\nBased on ToolBench, we fine-tune LLaMA to obtain an LLM ToolLLaMA, and equip it\nwith a neural API retriever to recommend appropriate APIs for each instruction.\nExperiments show that ToolLLaMA demonstrates a remarkable ability to execute\ncomplex instructions and generalize to unseen APIs, and exhibits comparable\nperformance to ChatGPT. Our ToolLLaMA also demonstrates strong zero-shot\ngeneralization ability in an out-of-distribution tool-use dataset: APIBench.\n",
                "链接": "https://arxiv.org/abs/2307.16789"
            },
            {
                "文章ID": "113444",
                "标题": "What Makes for Good Visual Instructions? Synthesizing Complex Visual\n  Reasoning Instructions for Visual Instruction Tuning",
                "作者": " Yifan Du,  Hangyu Guo,  Kun Zhou,  Wayne Xin Zhao,  Jinpeng Wang,  Chuyuan Wang,  Mingchen Cai,  Ruihua Song,  Ji-Rong Wen",
                "发布日期": "2023-11-06",
                "摘要": "  Visual instruction tuning is an essential approach to improving the zero-shot\ngeneralization capability of Multi-modal Large Language Models (MLLMs). A surge\nof visual instruction datasets with various focuses and characteristics have\nbeen proposed recently, enabling MLLMs to achieve surprising results on\nevaluation benchmarks. To develop more capable MLLMs, in this paper, we aim to\ninvestigate a more fundamental question: ``what makes for good visual\ninstructions?''. By conducting a comprehensive empirical study, we find that\ninstructions focused on complex visual reasoning tasks are particularly\neffective in improving the performance of MLLMs on evaluation benchmarks.\nBuilding upon this finding, we design a systematic approach to automatically\ncreating high-quality complex visual reasoning instructions. Our approach\nemploys a synthesis-complication-reformulation paradigm, leveraging multiple\nstages to gradually increase the complexity of the instructions while\nguaranteeing quality. Based on this approach, we create the synthetic visual\nreasoning instruction dataset consisting of 32K examples, namely ComVint, and\nfine-tune four MLLMs on it. Experimental results demonstrate that our dataset\nconsistently enhances the performance of all the compared MLLMs, e.g.,\nimproving the performance of MiniGPT-4 and BLIP-2 on MME-Cognition by 32.6% and\n28.8%, respectively. Our code and data are publicly available at the link:\nhttps://github.com/RUCAIBox/ComVint.\n",
                "链接": "https://arxiv.org/abs/2311.01487"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于gpt4自动生成prompt的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "68829",
                "标题": "Analyzing the Performance of GPT-3.5 and GPT-4 in Grammatical Error\n  Correction",
                "作者": " Steven Coyne,  Keisuke Sakaguchi,  Diana Galvan-Sosa,  Michael Zock,  Kentaro Inui",
                "发布日期": "2023-05-31",
                "摘要": "  GPT-3 and GPT-4 models are powerful, achieving high performance on a variety\nof Natural Language Processing tasks. However, there is a relative lack of\ndetailed published analysis of their performance on the task of grammatical\nerror correction (GEC). To address this, we perform experiments testing the\ncapabilities of a GPT-3.5 model (text-davinci-003) and a GPT-4 model\n(gpt-4-0314) on major GEC benchmarks. We compare the performance of different\nprompts in both zero-shot and few-shot settings, analyzing intriguing or\nproblematic outputs encountered with different prompt formats. We report the\nperformance of our best prompt on the BEA-2019 and JFLEG datasets, finding that\nthe GPT models can perform well in a sentence-level revision setting, with\nGPT-4 achieving a new high score on the JFLEG benchmark. Through human\nevaluation experiments, we compare the GPT models' corrections to source, human\nreference, and baseline GEC system sentences and observe differences in editing\nstrategies and how they are scored by human raters.\n",
                "链接": "https://arxiv.org/abs/2303.14342"
            },
            {
                "文章ID": "124195",
                "标题": "Using GPT-4 Prompts to Determine Whether Articles Contain Functional\n  Evidence Supporting or Refuting Variant Pathogenicity",
                "作者": " Samuel J. Aronson,  Kalotina Machini,  Pranav Sriraman,  Jiyeon Shin,  Emma R. Henricks,  Charlotte Mailly,  Angie J. Nottage,  Michael Oates,  Matthew S. Lebo",
                "发布日期": "2023-12-22",
                "摘要": "  Purpose: To assess Generative Pre-trained Transformer version 4's (GPT-4)\nability to classify articles containing functional evidence relevant to\nassessments of variant pathogenicity.\n  Results: GPT-4 settings and prompts were trained on a set of 45 articles and\ngenetic variants. A final test set of 72 manually classified articles and\ngenetic variants were then processed using two prompts. The prompts asked GPT-4\nto supply all functional evidence present in an article for a variant or\nindicate that no functional evidence is present. For articles with having\nfunctional evidence, a second prompt asked GPT-4 to classify the evidence into\npathogenic, benign, intermediate, and inconclusive categories. The first prompt\nidentified articles with variant-level functional evidence with 87% sensitivity\nand 89% positive predictive value (PPV). Five of 26 articles with no functional\ndata were indicated as having functional evidence by GPT-4. For variants with\nfunctional assays present as determined by both manual review and GPT-4, the\nsensitivity and PPV of GPT-4 prompt concordance was: Pathogenic (92% sensitive\nand 73% PPV), Intermediate or Inconclusive (67% sensitive and 93% PPV), Benign\n(100% sensitive and 73% PPV).\n  Conclusion: The GPT-4 prompts detected the presence or absence of a\nfunctional assay with high sensitivity and PPV, and articles with unambiguous\nevidence supporting a benign or pathogenic classification with high sensitivity\nand reasonable PPV. Our prompts detected papers with intermediate or\ninconclusive evidence with lower sensitivity but high PPV. Our results support\nthat GPT-4 may be useful in variant classification workflows by enabling\nprioritization of articles for review that are likely to have functional\nevidence supporting or refuting pathogenicity, but not that GPT-4 is capable of\nfully automating the genetics literature review component of variant\nclassification.\n",
                "链接": "https://arxiv.org/abs/2312.13521"
            },
            {
                "文章ID": "92427",
                "标题": "Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts",
                "作者": " Mayug Maniparambil,  Chris Vorster,  Derek Molloy,  Noel Murphy,  Kevin McGuinness,  Noel E. O'Connor",
                "发布日期": "2023-08-09",
                "摘要": "  Contrastive pretrained large Vision-Language Models (VLMs) like CLIP have\nrevolutionized visual representation learning by providing good performance on\ndownstream datasets. VLMs are 0-shot adapted to a downstream dataset by\ndesigning prompts that are relevant to the dataset. Such prompt engineering\nmakes use of domain expertise and a validation dataset. Meanwhile, recent\ndevelopments in generative pretrained models like GPT-4 mean they can be used\nas advanced internet search tools. They can also be manipulated to provide\nvisual information in any structure. In this work, we show that GPT-4 can be\nused to generate text that is visually descriptive and how this can be used to\nadapt CLIP to downstream tasks. We show considerable improvements in 0-shot\ntransfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD\n(~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP's default prompt.\nWe also design a simple few-shot adapter that learns to choose the best\npossible sentences to construct generalizable classifiers that outperform the\nrecently proposed CoCoOP by ~2% on average and by over 4% on 4 specialized\nfine-grained datasets. The code, prompts, and auxiliary text dataset is\navailable at https://github.com/mayug/VDT-Adapter.\n",
                "链接": "https://arxiv.org/abs/2307.11661"
            },
            {
                "文章ID": "68454",
                "标题": "Capabilities of GPT-4 on Medical Challenge Problems",
                "作者": " Harsha Nori,  Nicholas King,  Scott Mayer McKinney,  Dean Carignan,  Eric Horvitz",
                "发布日期": "2023-04-13",
                "摘要": "  Large language models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding and generation across various domains, including\nmedicine. We present a comprehensive evaluation of GPT-4, a state-of-the-art\nLLM, on medical competency examinations and benchmark datasets. GPT-4 is a\ngeneral-purpose model that is not specialized for medical problems through\ntraining or engineered to solve clinical tasks. Our analysis covers two sets of\nofficial practice materials for the USMLE, a three-step examination program\nused to assess clinical competency and grant licensure in the United States. We\nalso evaluate performance on the MultiMedQA suite of benchmark datasets. Beyond\nmeasuring model performance, experiments were conducted to investigate the\ninfluence of test questions containing both text and images on model\nperformance, probe for memorization of content during training, and study\nprobability calibration, which is of critical importance in high-stakes\napplications like medicine. Our results show that GPT-4, without any\nspecialized prompt crafting, exceeds the passing score on USMLE by over 20\npoints and outperforms earlier general-purpose models (GPT-3.5) as well as\nmodels specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned\nversion of Flan-PaLM 540B). In addition, GPT-4 is significantly better\ncalibrated than GPT-3.5, demonstrating a much-improved ability to predict the\nlikelihood that its answers are correct. We also explore the behavior of the\nmodel qualitatively through a case study that shows the ability of GPT-4 to\nexplain medical reasoning, personalize explanations to students, and\ninteractively craft new counterfactual scenarios around a medical case.\nImplications of the findings are discussed for potential uses of GPT-4 in\nmedical education, assessment, and clinical practice, with appropriate\nattention to challenges of accuracy and safety.\n",
                "链接": "https://arxiv.org/abs/2303.13375"
            },
            {
                "文章ID": "112047",
                "标题": "Using GPT-4 to Augment Unbalanced Data for Automatic Scoring",
                "作者": " Luyang Fang,  Gyeong-Geon Lee,  Xiaoming Zhai",
                "发布日期": "2023-11-21",
                "摘要": "  Machine learning-based automatic scoring can be challenging if students'\nresponses are unbalanced across scoring categories, as it introduces\nuncertainty in the machine training process. To meet this challenge, we\nintroduce a novel text data augmentation framework using GPT-4, a generative\nlarge language model, specifically tailored for unbalanced datasets in\nautomatic scoring. Our experimental dataset comprised student-written responses\nto two science items. We crafted prompts for GPT-4 to generate responses\nresembling student-written answers, particularly for the minority scoring\nclasses, to augment the data. We then finetuned DistillBERT for automatic\nscoring based on the augmented and original datasets. Model performance was\nassessed using accuracy, precision, recall, and F1 score. We incorporate varied\namounts of augmented data to examine scoring performance, and our findings\nrevealed remarkedly improved model performance. The average maximum increase\nobserved across two items is: 3.5% for accuracy, 30.6% for precision, 21.1% for\nrecall, and 24.2% for F1 score. Notably, using just 5% of the augmented data\nled to substantial improvements: 2.6%, 29.2%, 15.1%, and 19.6%. Interestingly,\nthe extent of improvement varied depending on specific datasets. Moreover, we\nfound that a varying amount of augmented data (5%-40%) was needed to obtain a\nstable improvement. We also compare models trained with GPT-4 augmented data\nand those trained with additional student-written responses. The findings\nindicate that former ones match or even exceed the performance of the latter.\nSpecifically, there is an average difference of 1.7%, 1.9%, 11.0%, and 7.8% for\nfour metrics separately. This research underscores the potential and\neffectiveness of data augmentation techniques utilizing GPT-4 in addressing\nunbalanced datasets within automated assessment.\n",
                "链接": "https://arxiv.org/abs/2310.18365"
            },
            {
                "文章ID": "69729",
                "标题": "Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission\n  Exams",
                "作者": " Desnes Nunes,  Ricardo Primi,  Ramon Pires,  Roberto Lotufo,  Rodrigo Nogueira",
                "发布日期": "2023-03-31",
                "摘要": "  The present study aims to explore the capabilities of Language Models (LMs)\nin tackling high-stakes multiple-choice tests, represented here by the Exame\nNacional do Ensino M\\'edio (ENEM), a multidisciplinary entrance examination\nwidely adopted by Brazilian universities. This exam poses challenging tasks for\nLMs, since its questions may span into multiple fields of knowledge, requiring\nunderstanding of information from diverse domains. For instance, a question may\nrequire comprehension of both statistics and biology to be solved. This work\nanalyzed responses generated by GPT-3.5 and GPT-4 models for questions\npresented in the 2009-2017 exams, as well as for questions of the 2022 exam,\nwhich were made public after the training of the models was completed.\nFurthermore, different prompt strategies were tested, including the use of\nChain-of-Thought (CoT) prompts to generate explanations for answers. On the\n2022 edition, the best-performing model, GPT-4 with CoT, achieved an accuracy\nof 87%, largely surpassing GPT-3.5 by 11 points. The code and data used on\nexperiments are available at https://github.com/piresramon/gpt-4-enem.\n",
                "链接": "https://arxiv.org/abs/2303.17003"
            },
            {
                "文章ID": "81941",
                "标题": "Controllable Text-to-Image Generation with GPT-4",
                "作者": " Tianjun Zhang,  Yi Zhang,  Vibhav Vineet,  Neel Joshi,  Xin Wang",
                "发布日期": "2023-05-31",
                "摘要": "  Current text-to-image generation models often struggle to follow textual\ninstructions, especially the ones requiring spatial reasoning. On the other\nhand, Large Language Models (LLMs), such as GPT-4, have shown remarkable\nprecision in generating code snippets for sketching out text inputs\ngraphically, e.g., via TikZ. In this work, we introduce Control-GPT to guide\nthe diffusion-based text-to-image pipelines with programmatic sketches\ngenerated by GPT-4, enhancing their abilities for instruction following.\nControl-GPT works by querying GPT-4 to write TikZ code, and the generated\nsketches are used as references alongside the text instructions for diffusion\nmodels (e.g., ControlNet) to generate photo-realistic images. One major\nchallenge to training our pipeline is the lack of a dataset containing aligned\ntext, images, and sketches. We address the issue by converting instance masks\nin existing datasets into polygons to mimic the sketches used at test time. As\na result, Control-GPT greatly boosts the controllability of image generation.\nIt establishes a new state-of-art on the spatial arrangement and object\npositioning generation and enhances users' control of object positions, sizes,\netc., nearly doubling the accuracy of prior models. Our work, as a first\nattempt, shows the potential for employing LLMs to enhance the performance in\ncomputer vision tasks.\n",
                "链接": "https://arxiv.org/abs/2305.18583"
            },
            {
                "文章ID": "111491",
                "标题": "Can GPT models Follow Human Summarization Guidelines? Evaluating ChatGPT\n  and GPT-4 for Dialogue Summarization",
                "作者": " Yongxin Zhou,  Fabien Ringeval,  François Portet",
                "发布日期": "2023-10-26",
                "摘要": "  This study explores the capabilities of prompt-driven Large Language Models\n(LLMs) like ChatGPT and GPT-4 in adhering to human guidelines for dialogue\nsummarization. Experiments employed DialogSum (English social conversations)\nand DECODA (French call center interactions), testing various prompts:\nincluding prompts from existing literature and those from human summarization\nguidelines, as well as a two-step prompt approach. Our findings indicate that\nGPT models often produce lengthy summaries and deviate from human summarization\nguidelines. However, using human guidelines as an intermediate step shows\npromise, outperforming direct word-length constraint prompts in some cases. The\nresults reveal that GPT models exhibit unique stylistic tendencies in their\nsummaries. While BERTScores did not dramatically decrease for GPT outputs\nsuggesting semantic similarity to human references and specialised pre-trained\nmodels, ROUGE scores reveal grammatical and lexical disparities between\nGPT-generated and human-written summaries. These findings shed light on the\ncapabilities and limitations of GPT models in following human instructions for\ndialogue summarization.\n",
                "链接": "https://arxiv.org/abs/2310.16810"
            },
            {
                "文章ID": "94757",
                "标题": "Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings",
                "作者": " Veronika Hackl,  Alexandra Elena Müller,  Michael Granitzer,  Maximilian Sailer",
                "发布日期": "2023-08-08",
                "摘要": "  This study investigates the consistency of feedback ratings generated by\nOpenAI's GPT-4, a state-of-the-art artificial intelligence language model,\nacross multiple iterations, time spans and stylistic variations. The model\nrated responses to tasks within the Higher Education (HE) subject domain of\nmacroeconomics in terms of their content and style. Statistical analysis was\nconducted in order to learn more about the interrater reliability, consistency\nof the ratings across iterations and the correlation between ratings in terms\nof content and style. The results revealed a high interrater reliability with\nICC scores ranging between 0.94 and 0.99 for different timespans, suggesting\nthat GPT-4 is capable of generating consistent ratings across repetitions with\na clear prompt. Style and content ratings show a high correlation of 0.87. When\napplying a non-adequate style the average content ratings remained constant,\nwhile style ratings decreased, which indicates that the large language model\n(LLM) effectively distinguishes between these two criteria during evaluation.\nThe prompt used in this study is furthermore presented and explained. Further\nresearch is necessary to assess the robustness and reliability of AI models in\nvarious use cases.\n",
                "链接": "https://arxiv.org/abs/2308.02575"
            },
            {
                "文章ID": "122336",
                "标题": "Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4",
                "作者": " Pei Yan,  Shunquan Tan,  Miaohui Wang,  Jiwu Huang",
                "发布日期": "2023-12-14",
                "摘要": "  Dynamic analysis methods effectively identify shelled, wrapped, or obfuscated\nmalware, thereby preventing them from invading computers. As a significant\nrepresentation of dynamic malware behavior, the API (Application Programming\nInterface) sequence, comprised of consecutive API calls, has progressively\nbecome the dominant feature of dynamic analysis methods. Though there have been\nnumerous deep learning models for malware detection based on API sequences, the\nquality of API call representations produced by those models is limited. These\nmodels cannot generate representations for unknown API calls, which weakens\nboth the detection performance and the generalization. Further, the concept\ndrift phenomenon of API calls is prominent. To tackle these issues, we\nintroduce a prompt engineering-assisted malware dynamic analysis using GPT-4.\nIn this method, GPT-4 is employed to create explanatory text for each API call\nwithin the API sequence. Afterward, the pre-trained language model BERT is used\nto obtain the representation of the text, from which we derive the\nrepresentation of the API sequence. Theoretically, this proposed method is\ncapable of generating representations for all API calls, excluding the\nnecessity for dataset training during the generation process. Utilizing the\nrepresentation, a CNN-based detection model is designed to extract the feature.\nWe adopt five benchmark datasets to validate the performance of the proposed\nmodel. The experimental results reveal that the proposed detection algorithm\nperforms better than the state-of-the-art method (TextCNN). Specifically, in\ncross-database experiments and few-shot learning experiments, the proposed\nmodel achieves excellent detection performance and almost a 100% recall rate\nfor malware, verifying its superior generalization performance. The code is\navailable at: github.com/yan-scnu/Prompted_Dynamic_Detection.\n",
                "链接": "https://arxiv.org/abs/2312.08317"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态agent, 具身智能的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "114225",
                "标题": "Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI",
                "作者": " Song Yaoxian,  Sun Penglei,  Liu Haoyu,  Li Zhixu,  Song Wei,  Xiao Yanghua,  Zhou Xiaofang",
                "发布日期": "2023-11-08",
                "摘要": "  Embodied AI is one of the most popular studies in artificial intelligence and\nrobotics, which can effectively improve the intelligence of real-world agents\n(i.e. robots) serving human beings. Scene knowledge is important for an agent\nto understand the surroundings and make correct decisions in the varied open\nworld. Currently, knowledge base for embodied tasks is missing and most\nexisting work use general knowledge base or pre-trained models to enhance the\nintelligence of an agent. For conventional knowledge base, it is sparse,\ninsufficient in capacity and cost in data collection. For pre-trained models,\nthey face the uncertainty of knowledge and hard maintenance. To overcome the\nchallenges of scene knowledge, we propose a scene-driven multimodal knowledge\ngraph (Scene-MMKG) construction method combining conventional knowledge\nengineering and large language models. A unified scene knowledge injection\nframework is introduced for knowledge representation. To evaluate the\nadvantages of our proposed method, we instantiate Scene-MMKG considering\ntypical indoor robotic functionalities (Manipulation and Mobility), named\nManipMob-MMKG. Comparisons in characteristics indicate our instantiated\nManipMob-MMKG has broad superiority in data-collection efficiency and knowledge\nquality. Experimental results on typical embodied tasks show that\nknowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the\nperformance obviously without re-designing model structures complexly. Our\nproject can be found at https://sites.google.com/view/manipmob-mmkg\n",
                "链接": "https://arxiv.org/abs/2311.03783"
            },
            {
                "文章ID": "117303",
                "标题": "An Embodied Generalist Agent in 3D World",
                "作者": " Jiangyong Huang,  Silong Yong,  Xiaojian Ma,  Xiongkun Linghu,  Puhao Li,  Yan Wang,  Qing Li,  Song-Chun Zhu,  Baoxiong Jia,  Siyuan Huang",
                "发布日期": "2023-11-23",
                "摘要": "  Leveraging massive knowledge and learning schemes from large language models\n(LLMs), recent machine learning models show notable successes in building\ngeneralist agents that exhibit the capability of general-purpose task solving\nin diverse domains, including natural language processing, computer vision, and\nrobotics. However, a significant challenge remains as these models exhibit\nlimited ability in understanding and interacting with the 3D world. We argue\nthis limitation significantly hinders the current models from performing\nreal-world tasks and further achieving general intelligence. To this end, we\nintroduce an embodied multi-modal and multi-task generalist agent that excels\nin perceiving, grounding, reasoning, planning, and acting in the 3D world. Our\nproposed agent, referred to as LEO, is trained with shared LLM-based model\narchitectures, objectives, and weights in two stages: (i) 3D vision-language\nalignment and (ii) 3D vision-language-action instruction tuning. To facilitate\nthe training, we meticulously curate and generate an extensive dataset\ncomprising object-level and scene-level multi-modal tasks with exceeding scale\nand complexity, necessitating a deep understanding of and interaction with the\n3D world. Through rigorous experiments, we demonstrate LEO's remarkable\nproficiency across a wide spectrum of tasks, including 3D captioning, question\nanswering, embodied reasoning, embodied navigation, and robotic manipulation.\nOur ablation results further provide valuable insights for the development of\nfuture embodied generalist agents.\n",
                "链接": "https://arxiv.org/abs/2311.12871"
            },
            {
                "文章ID": "61287",
                "标题": "Universal Agent Mixtures and the Geometry of Intelligence",
                "作者": " Samuel Allen Alexander,  David Quarel,  Len Du,  Marcus Hutter",
                "发布日期": "2023-02-14",
                "摘要": "  Inspired by recent progress in multi-agent Reinforcement Learning (RL), in\nthis work we examine the collective intelligent behaviour of theoretical\nuniversal agents by introducing a weighted mixture operation. Given a weighted\nset of agents, their weighted mixture is a new agent whose expected total\nreward in any environment is the corresponding weighted average of the original\nagents' expected total rewards in that environment. Thus, if RL agent\nintelligence is quantified in terms of performance across environments, the\nweighted mixture's intelligence is the weighted average of the original agents'\nintelligences. This operation enables various interesting new theorems that\nshed light on the geometry of RL agent intelligence, namely: results about\nsymmetries, convex agent-sets, and local extrema. We also show that any RL\nagent intelligence measure based on average performance across environments,\nsubject to certain weak technical conditions, is identical (up to a constant\nfactor) to performance within a single environment dependent on said\nintelligence measure.\n",
                "链接": "https://arxiv.org/abs/2302.06083"
            },
            {
                "文章ID": "89644",
                "标题": "Wireless Multi-Agent Generative AI: From Connected Intelligence to\n  Collective Intelligence",
                "作者": " Hang Zou,  Qiyang Zhao,  Lina Bariah,  Mehdi Bennis,  Merouane Debbah",
                "发布日期": "2023-07-07",
                "摘要": "  The convergence of generative large language models (LLMs), edge networks,\nand multi-agent systems represents a groundbreaking synergy that holds immense\npromise for future wireless generations, harnessing the power of collective\nintelligence and paving the way for self-governed networks where intelligent\ndecision-making happens right at the edge. This article puts the stepping-stone\nfor incorporating multi-agent generative artificial intelligence (AI) in\nwireless networks, and sets the scene for realizing on-device LLMs, where\nmulti-agent LLMs are collaboratively planning and solving tasks to achieve a\nnumber of network goals. We further investigate the profound limitations of\ncloud-based LLMs, and explore multi-agent LLMs from a game theoretic\nperspective, where agents collaboratively solve tasks in competitive\nenvironments. Moreover, we establish the underpinnings for the architecture\ndesign of wireless multi-agent generative AI systems at the network level and\nthe agent level, and we identify the wireless technologies that are envisioned\nto play a key role in enabling on-device LLM. To demonstrate the promising\npotentials of wireless multi-agent generative AI networks, we highlight the\nbenefits that can be achieved when implementing wireless generative agents in\nintent-based networking, and we provide a case study to showcase how on-device\nLLMs can contribute to solving network intents in a collaborative fashion. We\nfinally shed lights on potential challenges and sketch a research roadmap\ntowards realizing the vision of wireless collective intelligence.\n",
                "链接": "https://arxiv.org/abs/2307.02757"
            },
            {
                "文章ID": "118026",
                "标题": "Agent as Cerebrum, Controller as Cerebellum: Implementing an Embodied\n  LMM-based Agent on Drones",
                "作者": " Haoran Zhao,  Fengxing Pan,  Huqiuyue Ping,  Yaoming Zhou",
                "发布日期": "2023-11-28",
                "摘要": "  In this study, we present a novel paradigm for industrial robotic embodied\nagents, encapsulating an 'agent as cerebrum, controller as cerebellum'\narchitecture. Our approach harnesses the power of Large Multimodal Models\n(LMMs) within an agent framework known as AeroAgent, tailored for drone\ntechnology in industrial settings. To facilitate seamless integration with\nrobotic systems, we introduce ROSchain, a bespoke linkage framework connecting\nLMM-based agents to the Robot Operating System (ROS). We report findings from\nextensive empirical research, including simulated experiments on the Airgen and\nreal-world case study, particularly in individual search and rescue operations.\nThe results demonstrate AeroAgent's superior performance in comparison to\nexisting Deep Reinforcement Learning (DRL)-based agents, highlighting the\nadvantages of the embodied LMM in complex, real-world scenarios.\n",
                "链接": "https://arxiv.org/abs/2311.15033"
            },
            {
                "文章ID": "56083",
                "标题": "Emergent collective intelligence from massive-agent cooperation and\n  competition",
                "作者": " Hanmo Chen,  Stone Tao,  Jiaxin Chen,  Weihan Shen,  Xihui Li,  Chenghui Yu,  Sikai Cheng,  Xiaolong Zhu,  Xiu Li",
                "发布日期": "2023-01-06",
                "摘要": "  Inspired by organisms evolving through cooperation and competition between\ndifferent populations on Earth, we study the emergence of artificial collective\nintelligence through massive-agent reinforcement learning. To this end, We\npropose a new massive-agent reinforcement learning environment, Lux, where\ndynamic and massive agents in two teams scramble for limited resources and\nfight off the darkness. In Lux, we build our agents through the standard\nreinforcement learning algorithm in curriculum learning phases and leverage\ncentralized control via a pixel-to-pixel policy network. As agents co-evolve\nthrough self-play, we observe several stages of intelligence, from the\nacquisition of atomic skills to the development of group strategies. Since\nthese learned group strategies arise from individual decisions without an\nexplicit coordination mechanism, we claim that artificial collective\nintelligence emerges from massive-agent cooperation and competition. We further\nanalyze the emergence of various learned strategies through metrics and\nablation studies, aiming to provide insights for reinforcement learning\nimplementations in massive-agent environments.\n",
                "链接": "https://arxiv.org/abs/2301.01609"
            },
            {
                "文章ID": "63780",
                "标题": "Multimodal Speech Recognition for Language-Guided Embodied Agents",
                "作者": " Allen Chang,  Xiaoyuan Zhu,  Aarav Monga,  Seoho Ahn,  Tejas Srinivasan,  Jesse Thomason",
                "发布日期": "2023-10-11",
                "摘要": "  Benchmarks for language-guided embodied agents typically assume text-based\ninstructions, but deployed agents will encounter spoken instructions. While\nAutomatic Speech Recognition (ASR) models can bridge the input gap, erroneous\nASR transcripts can hurt the agents' ability to complete tasks. In this work,\nwe propose training a multimodal ASR model to reduce errors in transcribing\nspoken instructions by considering the accompanying visual context. We train\nour model on a dataset of spoken instructions, synthesized from the ALFRED task\ncompletion dataset, where we simulate acoustic noise by systematically masking\nspoken words. We find that utilizing visual observations facilitates masked\nword recovery, with multimodal ASR models recovering up to 30% more masked\nwords than unimodal baselines. We also find that a text-trained embodied agent\nsuccessfully completes tasks more often by following transcribed instructions\nfrom multimodal ASR models. github.com/Cylumn/embodied-multimodal-asr\n",
                "链接": "https://arxiv.org/abs/2302.14030"
            },
            {
                "文章ID": "123652",
                "标题": "Urban Generative Intelligence (UGI): A Foundational Platform for Agents\n  in Embodied City Environment",
                "作者": " Fengli Xu,  Jun Zhang,  Chen Gao,  Jie Feng,  Yong Li",
                "发布日期": "2023-12-20",
                "摘要": "  Urban environments, characterized by their complex, multi-layered networks\nencompassing physical, social, economic, and environmental dimensions, face\nsignificant challenges in the face of rapid urbanization. These challenges,\nranging from traffic congestion and pollution to social inequality, call for\nadvanced technological interventions. Recent developments in big data,\nartificial intelligence, urban computing, and digital twins have laid the\ngroundwork for sophisticated city modeling and simulation. However, a gap\npersists between these technological capabilities and their practical\nimplementation in addressing urban challenges in an systemic-intelligent way.\nThis paper proposes Urban Generative Intelligence (UGI), a novel foundational\nplatform integrating Large Language Models (LLMs) into urban systems to foster\na new paradigm of urban intelligence. UGI leverages CityGPT, a foundation model\ntrained on city-specific multi-source data, to create embodied agents for\nvarious urban tasks. These agents, operating within a textual urban environment\nemulated by city simulator and urban knowledge graph, interact through a\nnatural language interface, offering an open platform for diverse intelligent\nand embodied agent development. This platform not only addresses specific urban\nissues but also simulates complex urban systems, providing a multidisciplinary\napproach to understand and manage urban complexity. This work signifies a\ntransformative step in city science and urban intelligence, harnessing the\npower of LLMs to unravel and address the intricate dynamics of urban systems.\nThe code repository with demonstrations will soon be released here\nhttps://github.com/tsinghua-fib-lab/UGI.\n",
                "链接": "https://arxiv.org/abs/2312.11813"
            },
            {
                "文章ID": "44810",
                "标题": "Embodied, Situated, and Grounded Intelligence: Implications for AI",
                "作者": " Tyler Millhouse,  Melanie Moses,  Melanie Mitchell",
                "发布日期": "2022-10-26",
                "摘要": "  In April of 2022, the Santa Fe Institute hosted a workshop on embodied,\nsituated, and grounded intelligence as part of the Institute's Foundations of\nIntelligence project. The workshop brought together computer scientists,\npsychologists, philosophers, social scientists, and others to discuss the\nscience of embodiment and related issues in human intelligence, and its\nimplications for building robust, human-level AI. In this report, we summarize\neach of the talks and the subsequent discussions. We also draw out a number of\nkey themes and identify important frontiers for future research.\n",
                "链接": "https://arxiv.org/abs/2210.13589"
            },
            {
                "文章ID": "93106",
                "标题": "Heterogeneous Embodied Multi-Agent Collaboration",
                "作者": " Xinzhu Liu,  Di Guo,  Huaping Liu",
                "发布日期": "2023-07-28",
                "摘要": "  Multi-agent embodied tasks have recently been studied in complex indoor\nvisual environments. Collaboration among multiple agents can improve work\nefficiency and has significant practical value. However, most of the existing\nresearch focuses on homogeneous multi-agent tasks. Compared with homogeneous\nagents, heterogeneous agents can leverage their different capabilities to\nallocate corresponding sub-tasks and cooperate to complete complex tasks.\nHeterogeneous multi-agent tasks are common in real-world scenarios, and the\ncollaboration strategy among heterogeneous agents is a challenging and\nimportant problem to be solved. To study collaboration among heterogeneous\nagents, we propose the heterogeneous multi-agent tidying-up task, in which\nmultiple heterogeneous agents with different capabilities collaborate with each\nother to detect misplaced objects and place them in reasonable locations. This\nis a demanding task since it requires agents to make the best use of their\ndifferent capabilities to conduct reasonable task planning and complete the\nwhole task. To solve this task, we build a heterogeneous multi-agent tidying-up\nbenchmark dataset in a large number of houses with multiple rooms based on\nProcTHOR-10K. We propose the hierarchical decision model based on misplaced\nobject detection, reasonable receptacle prediction, as well as the\nhandshake-based group communication mechanism. Extensive experiments are\nconducted to demonstrate the effectiveness of the proposed model. The project's\nwebsite and videos of experiments can be found at https://hetercol.github.io/.\n",
                "链接": "https://arxiv.org/abs/2307.13957"
            }
        ]
    },
    {
        "question": {
            "question": "多模态细粒度图片编辑和生成相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "13260",
                "标题": "Flexible Portrait Image Editing with Fine-Grained Control",
                "作者": " Linlin Liu,  Qian Fu,  Fei Hou,  Ying He",
                "发布日期": "2022-04-05",
                "摘要": "  We develop a new method for portrait image editing, which supports\nfine-grained editing of geometries, colors, lights and shadows using a single\nneural network model. We adopt a novel asymmetric conditional GAN architecture:\nthe generators take the transformed conditional inputs, such as edge maps,\ncolor palette, sliders and masks, that can be directly edited by the user; the\ndiscriminators take the conditional inputs in the way that can guide\ncontrollable image generation more effectively. Taking color editing as an\nexample, we feed color palettes (which can be edited easily) into the\ngenerator, and color maps (which contain positional information of colors) into\nthe discriminator. We also design a region-weighted discriminator so that\nhigher weights are assigned to more important regions, like eyes and skin.\nUsing a color palette, the user can directly specify the desired colors of\nhair, skin, eyes, lip and background. Color sliders allow the user to blend\ncolors in an intuitive manner. The user can also edit lights and shadows by\nmodifying the corresponding masks. We demonstrate the effectiveness of our\nmethod by evaluating it on the CelebAMask-HQ dataset with a wide range of\ntasks, including geometry/color/shadow/light editing, hand-drawn sketch to\nimage translation, and color transfer. We also present ablation studies to\njustify our design.\n",
                "链接": "https://arxiv.org/abs/2204.01318"
            },
            {
                "文章ID": "124621",
                "标题": "FineMoGen: Fine-Grained Spatio-Temporal Motion Generation and Editing",
                "作者": " Mingyuan Zhang,  Huirong Li,  Zhongang Cai,  Jiawei Ren,  Lei Yang,  Ziwei Liu",
                "发布日期": "2023-12-27",
                "摘要": "  Text-driven motion generation has achieved substantial progress with the\nemergence of diffusion models. However, existing methods still struggle to\ngenerate complex motion sequences that correspond to fine-grained descriptions,\ndepicting detailed and accurate spatio-temporal actions. This lack of fine\ncontrollability limits the usage of motion generation to a larger audience. To\ntackle these challenges, we present FineMoGen, a diffusion-based motion\ngeneration and editing framework that can synthesize fine-grained motions, with\nspatial-temporal composition to the user instructions. Specifically, FineMoGen\nbuilds upon diffusion model with a novel transformer architecture dubbed\nSpatio-Temporal Mixture Attention (SAMI). SAMI optimizes the generation of the\nglobal attention template from two perspectives: 1) explicitly modeling the\nconstraints of spatio-temporal composition; and 2) utilizing sparsely-activated\nmixture-of-experts to adaptively extract fine-grained features. To facilitate a\nlarge-scale study on this new fine-grained motion generation task, we\ncontribute the HuMMan-MoGen dataset, which consists of 2,968 videos and 102,336\nfine-grained spatio-temporal descriptions. Extensive experiments validate that\nFineMoGen exhibits superior motion generation quality over state-of-the-art\nmethods. Notably, FineMoGen further enables zero-shot motion editing\ncapabilities with the aid of modern large language models (LLM), which\nfaithfully manipulates motion sequences with fine-grained instructions. Project\nPage: https://mingyuan-zhang.github.io/projects/FineMoGen.html\n",
                "链接": "https://arxiv.org/abs/2312.15004"
            },
            {
                "文章ID": "52126",
                "标题": "Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models",
                "作者": " Naoki Matsunaga,  Masato Ishii,  Akio Hayakawa,  Kenji Suzuki,  Takuya Narihira",
                "发布日期": "2023-06-01",
                "摘要": "  Our goal is to develop fine-grained real-image editing methods suitable for\nreal-world applications. In this paper, we first summarize four requirements\nfor these methods and propose a novel diffusion-based image editing framework\nwith pixel-wise guidance that satisfies these requirements. Specifically, we\ntrain pixel-classifiers with a few annotated data and then infer the\nsegmentation map of a target image. Users then manipulate the map to instruct\nhow the image will be edited. We utilize a pre-trained diffusion model to\ngenerate edited images aligned with the user's intention with pixel-wise\nguidance. The effective combination of proposed guidance and other techniques\nenables highly controllable editing with preserving the outside of the edited\narea, which results in meeting our requirements. The experimental results\ndemonstrate that our proposal outperforms the GAN-based method for editing\nquality and speed.\n",
                "链接": "https://arxiv.org/abs/2212.02024"
            },
            {
                "文章ID": "109759",
                "标题": "Object-aware Inversion and Reassembly for Image Editing",
                "作者": " Zhen Yang,  Dinggang Gui,  Wen Wang,  Hao Chen,  Bohan Zhuang,  Chunhua Shen",
                "发布日期": "2023-10-19",
                "摘要": "  By comparing the original and target prompts in editing task, we can obtain\nnumerous editing pairs, each comprising an object and its corresponding editing\ntarget. To allow editability while maintaining fidelity to the input image,\nexisting editing methods typically involve a fixed number of inversion steps\nthat project the whole input image to its noisier latent representation,\nfollowed by a denoising process guided by the target prompt. However, we find\nthat the optimal number of inversion steps for achieving ideal editing results\nvaries significantly among different editing pairs, owing to varying editing\ndifficulties. Therefore, the current literature, which relies on a fixed number\nof inversion steps, produces sub-optimal generation quality, especially when\nhandling multiple editing pairs in a natural image. To this end, we propose a\nnew image editing paradigm, dubbed Object-aware Inversion and Reassembly (OIR),\nto enable object-level fine-grained editing. Specifically, we design a new\nsearch metric, which determines the optimal inversion steps for each editing\npair, by jointly considering the editability of the target and the fidelity of\nthe non-editing region. We use our search metric to find the optimal inversion\nstep for each editing pair when editing an image. We then edit these editing\npairs separately to avoid concept mismatch. Subsequently, we propose an\nadditional reassembly step to seamlessly integrate the respective editing\nresults and the non-editing region to obtain the final edited image. To\nsystematically evaluate the effectiveness of our method, we collect two\ndatasets for benchmarking single- and multi-object editing, respectively.\nExperiments demonstrate that our method achieves superior performance in\nediting object shapes, colors, materials, categories, etc., especially in\nmulti-object editing scenarios.\n",
                "链接": "https://arxiv.org/abs/2310.12149"
            },
            {
                "文章ID": "105138",
                "标题": "Guiding Instruction-based Image Editing via Multimodal Large Language\n  Models",
                "作者": " Tsu-Jui Fu,  Wenze Hu,  Xianzhi Du,  William Yang Wang,  Yinfei Yang,  Zhe Gan",
                "发布日期": "2023-10-02",
                "摘要": "  Instruction-based image editing improves the controllability and flexibility\nof image manipulation via natural commands without elaborate descriptions or\nregional masks. However, human instructions are sometimes too brief for current\nmethods to capture and follow. Multimodal large language models (MLLMs) show\npromising capabilities in cross-modal understanding and visual-aware response\ngeneration via LMs. We investigate how MLLMs facilitate edit instructions and\npresent MLLM-Guided Image Editing (MGIE). MGIE learns to derive expressive\ninstructions and provides explicit guidance. The editing model jointly captures\nthis visual imagination and performs manipulation through end-to-end training.\nWe evaluate various aspects of Photoshop-style modification, global photo\noptimization, and local editing. Extensive experimental results demonstrate\nthat expressive instructions are crucial to instruction-based image editing,\nand our MGIE can lead to a notable improvement in automatic metrics and human\nevaluation while maintaining competitive inference efficiency.\n",
                "链接": "https://arxiv.org/abs/2309.17102"
            },
            {
                "文章ID": "68421",
                "标题": "SINE: Semantic-driven Image-based NeRF Editing with Prior-guided Editing\n  Field",
                "作者": " Chong Bao,  Yinda Zhang,  Bangbang Yang,  Tianxing Fan,  Zesong Yang,  Hujun Bao,  Guofeng Zhang,  Zhaopeng Cui",
                "发布日期": "2023-03-28",
                "摘要": "  Despite the great success in 2D editing using user-friendly tools, such as\nPhotoshop, semantic strokes, or even text prompts, similar capabilities in 3D\nareas are still limited, either relying on 3D modeling skills or allowing\nediting within only a few categories. In this paper, we present a novel\nsemantic-driven NeRF editing approach, which enables users to edit a neural\nradiance field with a single image, and faithfully delivers edited novel views\nwith high fidelity and multi-view consistency. To achieve this goal, we propose\na prior-guided editing field to encode fine-grained geometric and texture\nediting in 3D space, and develop a series of techniques to aid the editing\nprocess, including cyclic constraints with a proxy mesh to facilitate geometric\nsupervision, a color compositing mechanism to stabilize semantic-driven texture\nediting, and a feature-cluster-based regularization to preserve the irrelevant\ncontent unchanged. Extensive experiments and editing examples on both\nreal-world and synthetic data demonstrate that our method achieves\nphoto-realistic 3D editing using only a single edited image, pushing the bound\nof semantic-driven editing in 3D real-world scenes. Our project webpage:\nhttps://zju3dv.github.io/sine/.\n",
                "链接": "https://arxiv.org/abs/2303.13277"
            },
            {
                "文章ID": "43345",
                "标题": "UniTune: Text-Driven Image Editing by Fine Tuning a Diffusion Model on a\n  Single Image",
                "作者": " Dani Valevski,  Matan Kalman,  Eyal Molad,  Eyal Segalis,  Yossi Matias,  Yaniv Leviathan",
                "发布日期": "2023-07-06",
                "摘要": "  Text-driven image generation methods have shown impressive results recently,\nallowing casual users to generate high quality images by providing textual\ndescriptions. However, similar capabilities for editing existing images are\nstill out of reach. Text-driven image editing methods usually need edit masks,\nstruggle with edits that require significant visual changes and cannot easily\nkeep specific details of the edited portion. In this paper we make the\nobservation that image-generation models can be converted to image-editing\nmodels simply by fine-tuning them on a single image. We also show that\ninitializing the stochastic sampler with a noised version of the base image\nbefore the sampling and interpolating relevant details from the base image\nafter sampling further increase the quality of the edit operation. Combining\nthese observations, we propose UniTune, a novel image editing method. UniTune\ngets as input an arbitrary image and a textual edit description, and carries\nout the edit while maintaining high fidelity to the input image. UniTune does\nnot require additional inputs, like masks or sketches, and can perform multiple\nedits on the same image without retraining. We test our method using the Imagen\nmodel in a range of different use cases. We demonstrate that it is broadly\napplicable and can perform a surprisingly wide range of expressive editing\noperations, including those requiring significant visual changes that were\npreviously impossible.\n",
                "链接": "https://arxiv.org/abs/2210.09477"
            },
            {
                "文章ID": "116307",
                "标题": "Emu Edit: Precise Image Editing via Recognition and Generation Tasks",
                "作者": " Shelly Sheynin,  Adam Polyak,  Uriel Singer,  Yuval Kirstain,  Amit Zohar,  Oron Ashual,  Devi Parikh,  Yaniv Taigman",
                "发布日期": "2023-11-17",
                "摘要": "  Instruction-based image editing holds immense potential for a variety of\napplications, as it enables users to perform any editing operation using a\nnatural language instruction. However, current models in this domain often\nstruggle with accurately executing user instructions. We present Emu Edit, a\nmulti-task image editing model which sets state-of-the-art results in\ninstruction-based image editing. To develop Emu Edit we train it to multi-task\nacross an unprecedented range of tasks, such as region-based editing, free-form\nediting, and Computer Vision tasks, all of which are formulated as generative\ntasks. Additionally, to enhance Emu Edit's multi-task learning abilities, we\nprovide it with learned task embeddings which guide the generation process\ntowards the correct edit type. Both these elements are essential for Emu Edit's\noutstanding performance. Furthermore, we show that Emu Edit can generalize to\nnew tasks, such as image inpainting, super-resolution, and compositions of\nediting tasks, with just a few labeled examples. This capability offers a\nsignificant advantage in scenarios where high-quality samples are scarce.\nLastly, to facilitate a more rigorous and informed assessment of instructable\nimage editing models, we release a new challenging and versatile benchmark that\nincludes seven different image editing tasks.\n",
                "链接": "https://arxiv.org/abs/2311.10089"
            },
            {
                "文章ID": "124901",
                "标题": "SERF: Fine-Grained Interactive 3D Segmentation and Editing with Radiance\n  Fields",
                "作者": " Kaichen Zhou,  Lanqing Hong,  Enze Xie,  Yongxin Yang,  Zhenguo Li,  Wei Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Although significant progress has been made in the field of 2D-based\ninteractive editing, fine-grained 3D-based interactive editing remains\nrelatively unexplored. This limitation can be attributed to two main\nchallenges: the lack of an efficient 3D representation robust to different\nmodifications and the absence of an effective 3D interactive segmentation\nmethod. In this paper, we introduce a novel fine-grained interactive 3D\nsegmentation and editing algorithm with radiance fields, which we refer to as\nSERF. Our method entails creating a neural mesh representation by integrating\nmulti-view algorithms with pre-trained 2D models. Building upon this\nrepresentation, we introduce a novel surface rendering technique that preserves\nlocal information and is robust to deformation. Moreover, this representation\nforms the basis for achieving accurate and interactive 3D segmentation without\nrequiring 3D supervision. Harnessing this representation facilitates a range of\ninteractive 3D editing operations, encompassing tasks such as interactive\ngeometry editing and texture painting. Extensive experiments and visualization\nexamples of editing on both real and synthetic data demonstrate the superiority\nof our method on representation quality and editing ability.\n",
                "链接": "https://arxiv.org/abs/2312.15856"
            },
            {
                "文章ID": "122249",
                "标题": "AdapEdit: Spatio-Temporal Guided Adaptive Editing Algorithm for\n  Text-Based Continuity-Sensitive Image Editing",
                "作者": " Zhiyuan Ma,  Guoli Jia,  Bowen Zhou",
                "发布日期": "2023-12-27",
                "摘要": "  With the great success of text-conditioned diffusion models in creative\ntext-to-image generation, various text-driven image editing approaches have\nattracted the attentions of many researchers. However, previous works mainly\nfocus on discreteness-sensitive instructions such as adding, removing or\nreplacing specific objects, background elements or global styles (i.e., hard\nediting), while generally ignoring subject-binding but semantically\nfine-changing continuity-sensitive instructions such as actions, poses or\nadjectives, and so on (i.e., soft editing), which hampers generative AI from\ngenerating user-customized visual contents. To mitigate this predicament, we\npropose a spatio-temporal guided adaptive editing algorithm AdapEdit, which\nrealizes adaptive image editing by introducing a soft-attention strategy to\ndynamically vary the guiding degree from the editing conditions to visual\npixels from both temporal and spatial perspectives. Note our approach has a\nsignificant advantage in preserving model priors and does not require model\ntraining, fine-tuning, extra data, or optimization. We present our results over\na wide variety of raw images and editing instructions, demonstrating\ncompetitive performance and showing it significantly outperforms the previous\napproaches.\n",
                "链接": "https://arxiv.org/abs/2312.08019"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找风格化机器翻译相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "75252",
                "标题": "New Trends in Machine Translation using Large Language Models: Case\n  Examples with ChatGPT",
                "作者": " Chenyang Lyu,  Jitao Xu,  Longyue Wang",
                "发布日期": "2023-05-03",
                "摘要": "  Machine Translation (MT) has made significant progress in recent years using\ndeep learning, especially after the emergence of large language models (LLMs)\nsuch as GPT-3 and ChatGPT. This brings new challenges and opportunities for MT\nusing LLMs. In this paper, we brainstorm some interesting directions for MT\nusing LLMs, including stylized MT, interactive MT, and Translation Memory-based\nMT, as well as a new evaluation paradigm using LLMs. We also discuss the\nprivacy concerns in MT using LLMs and a basic privacy-preserving method to\nmitigate such risks. To illustrate the potential of our proposed directions, we\npresent several examples for the new directions mentioned above, demonstrating\nthe feasibility of the proposed directions and highlight the opportunities and\nchallenges for future research in MT using LLMs.\n",
                "链接": "https://arxiv.org/abs/2305.01181"
            },
            {
                "文章ID": "54621",
                "标题": "Lego-MT: Learning Detachable Models for Massively Multilingual Machine\n  Translation",
                "作者": " Fei Yuan,  Yinquan Lu,  WenHao Zhu,  Lingpeng Kong,  Lei Li,  Yu Qiao,  Jingjing Xu",
                "发布日期": "2023-07-20",
                "摘要": "  Multilingual neural machine translation (MNMT) aims to build a unified model\nfor many language directions. Existing monolithic models for MNMT encounter two\nchallenges: parameter interference among languages and inefficient inference\nfor large models. In this paper, we revisit the classic multi-way structures\nand develop a detachable model by assigning each language (or group of\nlanguages) to an individual branch that supports plug-and-play training and\ninference. To address the needs of learning representations for all languages\nin a unified space, we propose a novel efficient training recipe, upon which we\nbuild an effective detachable model, Lego-MT. For a fair comparison, we collect\ndata from OPUS and build a translation benchmark covering 433 languages and\n1.3B parallel data. Experiments show that Lego-MT with 1.2B parameters brings\nan average gain of 3.2 spBLEU. It even outperforms M2M-100 with 12B parameters.\nThe proposed training recipe brings a 28.2$\\times$ speedup over the\nconventional multi-way training method.\\footnote{\n\\url{https://github.com/CONE-MT/Lego-MT}.}\n",
                "链接": "https://arxiv.org/abs/2212.10551"
            },
            {
                "文章ID": "54085",
                "标题": "Controlling Styles in Neural Machine Translation with Activation Prompt",
                "作者": " Yifan Wang,  Zewei Sun,  Shanbo Cheng,  Weiguo Zheng,  Mingxuan Wang",
                "发布日期": "2023-05-30",
                "摘要": "  Controlling styles in neural machine translation (NMT) has attracted wide\nattention, as it is crucial for enhancing user experience. Earlier studies on\nthis topic typically concentrate on regulating the level of formality and\nachieve some progress in this area. However, they still encounter two major\nchallenges. The first is the difficulty in style evaluation. The style\ncomprises various aspects such as lexis, syntax, and others that provide\nabundant information. Nevertheless, only formality has been thoroughly\ninvestigated. The second challenge involves excessive dependence on incremental\nadjustments, particularly when new styles are necessary. To address both\nchallenges, this paper presents a new benchmark and approach. A multiway\nstylized machine translation (MSMT) benchmark is introduced, incorporating\ndiverse categories of styles across four linguistic domains. Then, we propose a\nmethod named style activation prompt (StyleAP) by retrieving prompts from\nstylized monolingual corpus, which does not require extra fine-tuning.\nExperiments show that StyleAP could effectively control the style of\ntranslation and achieve remarkable performance.\n",
                "链接": "https://arxiv.org/abs/2212.08909"
            },
            {
                "文章ID": "46544",
                "标题": "MT-GenEval: A Counterfactual and Contextual Dataset for Evaluating\n  Gender Accuracy in Machine Translation",
                "作者": " Anna Currey,  Maria Nădejde,  Raghavendra Pappagari,  Mia Mayer,  Stanislas Lauly,  Xing Niu,  Benjamin Hsu,  Georgiana Dinu",
                "发布日期": "2022-11-03",
                "摘要": "  As generic machine translation (MT) quality has improved, the need for\ntargeted benchmarks that explore fine-grained aspects of quality has increased.\nIn particular, gender accuracy in translation can have implications in terms of\noutput fluency, translation accuracy, and ethics. In this paper, we introduce\nMT-GenEval, a benchmark for evaluating gender accuracy in translation from\nEnglish into eight widely-spoken languages. MT-GenEval complements existing\nbenchmarks by providing realistic, gender-balanced, counterfactual data in\neight language pairs where the gender of individuals is unambiguous in the\ninput segment, including multi-sentence segments requiring inter-sentential\ngender agreement. Our data and code is publicly available under a CC BY SA 3.0\nlicense.\n",
                "链接": "https://arxiv.org/abs/2211.01355"
            },
            {
                "文章ID": "119493",
                "标题": "StyleCrafter: Enhancing Stylized Text-to-Video Generation with Style\n  Adapter",
                "作者": " Gongye Liu,  Menghan Xia,  Yong Zhang,  Haoxin Chen,  Jinbo Xing,  Xintao Wang,  Yujiu Yang,  Ying Shan",
                "发布日期": "2023-12-04",
                "摘要": "  Text-to-video (T2V) models have shown remarkable capabilities in generating\ndiverse videos. However, they struggle to produce user-desired stylized videos\ndue to (i) text's inherent clumsiness in expressing specific styles and (ii)\nthe generally degraded style fidelity. To address these challenges, we\nintroduce StyleCrafter, a generic method that enhances pre-trained T2V models\nwith a style control adapter, enabling video generation in any style by\nproviding a reference image. Considering the scarcity of stylized video\ndatasets, we propose to first train a style control adapter using style-rich\nimage datasets, then transfer the learned stylization ability to video\ngeneration through a tailor-made finetuning paradigm. To promote content-style\ndisentanglement, we remove style descriptions from the text prompt and extract\nstyle information solely from the reference image using a decoupling learning\nstrategy. Additionally, we design a scale-adaptive fusion module to balance the\ninfluences of text-based content features and image-based style features, which\nhelps generalization across various text and style combinations. StyleCrafter\nefficiently generates high-quality stylized videos that align with the content\nof the texts and resemble the style of the reference images. Experiments\ndemonstrate that our approach is more flexible and efficient than existing\ncompetitors.\n",
                "链接": "https://arxiv.org/abs/2312.00330"
            },
            {
                "文章ID": "118029",
                "标题": "InstaStyle: Inversion Noise of a Stylized Image is Secretly a Style\n  Adviser",
                "作者": " Xing Cui,  Zekun Li,  Pei Pei Li,  Huaibo Huang,  Zhaofeng He",
                "发布日期": "2023-11-28",
                "摘要": "  Stylized text-to-image generation focuses on creating images from textual\ndescriptions while adhering to a style specified by a few reference images.\nHowever, subtle style variations within different reference images can hinder\nthe model from accurately learning the target style. In this paper, we propose\nInstaStyle, a novel approach that excels in generating high-fidelity stylized\nimages with only a single reference image. Our approach is based on the finding\nthat the inversion noise from a stylized reference image inherently carries the\nstyle signal, as evidenced by their non-zero signal-to-noise ratio. We employ\nDDIM inversion to extract this noise from the reference image and leverage a\ndiffusion model to generate new stylized images from the ``style\" noise.\nAdditionally, the inherent ambiguity and bias of textual prompts impede the\nprecise conveying of style. To address this, we introduce a learnable style\ntoken via prompt refinement, which enhances the accuracy of the style\ndescription for the reference image. Qualitative and quantitative experimental\nresults demonstrate that InstaStyle achieves superior performance compared to\ncurrent benchmarks. Furthermore, our approach also showcases its capability in\nthe creative task of style combination with mixed inversion noise.\n",
                "链接": "https://arxiv.org/abs/2311.15040"
            },
            {
                "文章ID": "20942",
                "标题": "Chunk-based Nearest Neighbor Machine Translation",
                "作者": " Pedro Henrique Martins,  Zita Marinho,  André F. T. Martins",
                "发布日期": "2022-11-08",
                "摘要": "  Semi-parametric models, which augment generation with retrieval, have led to\nimpressive results in language modeling and machine translation, due to their\nability to retrieve fine-grained information from a datastore of examples. One\nof the most prominent approaches, $k$NN-MT, exhibits strong domain adaptation\ncapabilities by retrieving tokens from domain-specific datastores\n\\citep{khandelwal2020nearest}. However, $k$NN-MT requires an expensive\nretrieval operation for every single generated token, leading to a very low\ndecoding speed (around 8 times slower than a parametric model). In this paper,\nwe introduce a \\textit{chunk-based} $k$NN-MT model which retrieves chunks of\ntokens from the datastore, instead of a single token. We propose several\nstrategies for incorporating the retrieved chunks into the generation process,\nand for selecting the steps at which the model needs to search for neighbors in\nthe datastore. Experiments on machine translation in two settings, static and\n``on-the-fly'' domain adaptation, show that the chunk-based $k$NN-MT model\nleads to significant speed-ups (up to 4 times) with only a small drop in\ntranslation quality.\n",
                "链接": "https://arxiv.org/abs/2205.12230"
            },
            {
                "文章ID": "28662",
                "标题": "HLT-MT: High-resource Language-specific Training for Multilingual Neural\n  Machine Translation",
                "作者": " Jian Yang,  Yuwei Yin,  Shuming Ma,  Dongdong Zhang,  Zhoujun Li,  Furu Wei",
                "发布日期": "2022-07-21",
                "摘要": "  Multilingual neural machine translation (MNMT) trained in multiple language\npairs has attracted considerable attention due to fewer model parameters and\nlower training costs by sharing knowledge among multiple languages.\nNonetheless, multilingual training is plagued by language interference\ndegeneration in shared parameters because of the negative interference among\ndifferent translation directions, especially on high-resource languages. In\nthis paper, we propose the multilingual translation model with the\nhigh-resource language-specific training (HLT-MT) to alleviate the negative\ninterference, which adopts the two-stage training with the language-specific\nselection mechanism. Specifically, we first train the multilingual model only\nwith the high-resource pairs and select the language-specific modules at the\ntop of the decoder to enhance the translation quality of high-resource\ndirections. Next, the model is further trained on all available corpora to\ntransfer knowledge from high-resource languages (HRLs) to low-resource\nlanguages (LRLs). Experimental results show that HLT-MT outperforms various\nstrong baselines on WMT-10 and OPUS-100 benchmarks. Furthermore, the analytic\nexperiments validate the effectiveness of our method in mitigating the negative\ninterference in multilingual training.\n",
                "链接": "https://arxiv.org/abs/2207.04906"
            },
            {
                "文章ID": "92370",
                "标题": "Incorporating Human Translator Style into English-Turkish Literary\n  Machine Translation",
                "作者": " Zeynep Yirmibeşoğlu,  Olgun Dursun,  Harun Dallı,  Mehmet Şahin,  Ena Hodzik,  Sabri Gürses,  Tunga Güngör",
                "发布日期": "2023-07-24",
                "摘要": "  Although machine translation systems are mostly designed to serve in the\ngeneral domain, there is a growing tendency to adapt these systems to other\ndomains like literary translation. In this paper, we focus on English-Turkish\nliterary translation and develop machine translation models that take into\naccount the stylistic features of translators. We fine-tune a pre-trained\nmachine translation model by the manually-aligned works of a particular\ntranslator. We make a detailed analysis of the effects of manual and automatic\nalignments, data augmentation methods, and corpus size on the translations. We\npropose an approach based on stylistic features to evaluate the style of a\ntranslator in the output translations. We show that the human translator style\ncan be highly recreated in the target machine translations by adapting the\nmodels to the style of the translator.\n",
                "链接": "https://arxiv.org/abs/2307.11457"
            },
            {
                "文章ID": "14719",
                "标题": "Efficient Cluster-Based k-Nearest-Neighbor Machine Translation",
                "作者": " Dexin Wang,  Kai Fan,  Boxing Chen,  Deyi Xiong",
                "发布日期": "2022-05-04",
                "摘要": "  k-Nearest-Neighbor Machine Translation (kNN-MT) has been recently proposed as\na non-parametric solution for domain adaptation in neural machine translation\n(NMT). It aims to alleviate the performance degradation of advanced MT systems\nin translating out-of-domain sentences by coordinating with an additional\ntoken-level feature-based retrieval module constructed from in-domain data.\nPrevious studies have already demonstrated that non-parametric NMT is even\nsuperior to models fine-tuned on out-of-domain data. In spite of this success,\nkNN retrieval is at the expense of high latency, in particular for large\ndatastores. To make it practical, in this paper, we explore a more efficient\nkNN-MT and propose to use clustering to improve the retrieval efficiency.\nConcretely, we first propose a cluster-based Compact Network for feature\nreduction in a contrastive learning manner to compress context features into\n90+% lower dimensional vectors. We then suggest a cluster-based pruning\nsolution to filter out 10%-40% redundant nodes in large datastores while\nretaining translation quality. Our proposed methods achieve better or\ncomparable performance while reducing up to 57% inference latency against the\nadvanced non-parametric MT model on several machine translation benchmarks.\nExperimental results indicate that the proposed methods maintain the most\nuseful information of the original datastore and the Compact Network shows good\ngeneralization on unseen domains.\n",
                "链接": "https://arxiv.org/abs/2204.06175"
            }
        ]
    },
    {
        "question": {
            "question": "查找中文ner常用的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "5948",
                "标题": "AISHELL-NER: Named Entity Recognition from Chinese Speech",
                "作者": " Boli Chen,  Guangwei Xu,  Xiaobin Wang,  Pengjun Xie,  Meishan Zhang,  Fei Huang",
                "发布日期": "2022-02-18",
                "摘要": "  Named Entity Recognition (NER) from speech is among Spoken Language\nUnderstanding (SLU) tasks, aiming to extract semantic information from the\nspeech signal. NER from speech is usually made through a two-step pipeline that\nconsists of (1) processing the audio using an Automatic Speech Recognition\n(ASR) system and (2) applying an NER tagger to the ASR outputs. Recent works\nhave shown the capability of the End-to-End (E2E) approach for NER from English\nand French speech, which is essentially entity-aware ASR. However, due to the\nmany homophones and polyphones that exist in Chinese, NER from Chinese speech\nis effectively a more challenging task. In this paper, we introduce a new\ndataset AISEHLL-NER for NER from Chinese speech. Extensive experiments are\nconducted to explore the performance of several state-of-the-art methods. The\nresults demonstrate that the performance could be improved by combining\nentity-aware ASR and pretrained NER tagger, which can be easily applied to the\nmodern SLU pipeline. The dataset is publicly available at\ngithub.com/Alibaba-NLP/AISHELL-NER.\n",
                "链接": "https://arxiv.org/abs/2202.08533"
            },
            {
                "文章ID": "6079",
                "标题": "TURNER: The Uncertainty-based Retrieval Framework for Chinese NER",
                "作者": " Zhichao Geng,  Hang Yan,  Zhangyue Yin,  Chenxin An,  Xipeng Qiu",
                "发布日期": "2022-02-21",
                "摘要": "  Chinese NER is a difficult undertaking due to the ambiguity of Chinese\ncharacters and the absence of word boundaries. Previous work on Chinese NER\nfocus on lexicon-based methods to introduce boundary information and reduce\nout-of-vocabulary (OOV) cases during prediction. However, it is expensive to\nobtain and dynamically maintain high-quality lexicons in specific domains,\nwhich motivates us to utilize more general knowledge resources, e.g., search\nengines. In this paper, we propose TURNER: The Uncertainty-based Retrieval\nframework for Chinese NER. The idea behind TURNER is to imitate human behavior:\nwe frequently retrieve auxiliary knowledge as assistance when encountering an\nunknown or uncertain entity. To improve the efficiency and effectiveness of\nretrieval, we first propose two types of uncertainty sampling methods for\nselecting the most ambiguous entity-level uncertain components of the input\ntext. Then, the Knowledge Fusion Model re-predict the uncertain samples by\ncombining retrieved knowledge. Experiments on four benchmark datasets\ndemonstrate TURNER's effectiveness. TURNER outperforms existing lexicon-based\napproaches and achieves the new SOTA.\n",
                "链接": "https://arxiv.org/abs/2202.09022"
            },
            {
                "文章ID": "15120",
                "标题": "Qtrade AI at SemEval-2022 Task 11: An Unified Framework for Multilingual\n  NER Task",
                "作者": " Weichao Gan,  Yuanping Lin,  Guangbo Yu,  Guimin Chen,  Qian Ye",
                "发布日期": "2022-04-18",
                "摘要": "  This paper describes our system, which placed third in the Multilingual Track\n(subtask 11), fourth in the Code-Mixed Track (subtask 12), and seventh in the\nChinese Track (subtask 9) in the SemEval 2022 Task 11: MultiCoNER Multilingual\nComplex Named Entity Recognition. Our system's key contributions are as\nfollows: 1) For multilingual NER tasks, we offer an unified framework with\nwhich one can easily execute single-language or multilingual NER tasks, 2) for\nlow-resource code-mixed NER task, one can easily enhance his or her dataset\nthrough implementing several simple data augmentation methods and 3) for\nChinese tasks, we propose a model that can capture Chinese lexical semantic,\nlexical border, and lexical graph structural information. Finally, our system\nachieves macro-f1 scores of 77.66, 84.35, and 74.00 on subtasks 11, 12, and 9,\nrespectively, during the testing phase.\n",
                "链接": "https://arxiv.org/abs/2204.07459"
            },
            {
                "文章ID": "12836",
                "标题": "$k$NN-NER: Named Entity Recognition with Nearest Neighbor Search",
                "作者": " Shuhe Wang,  Xiaoya Li,  Yuxian Meng,  Tianwei Zhang,  Rongbin Ouyang,  Jiwei Li,  Guoyin Wang",
                "发布日期": "2022-04-01",
                "摘要": "  Inspired by recent advances in retrieval augmented methods in\nNLP~\\citep{khandelwal2019generalization,khandelwal2020nearest,meng2021gnn}, in\nthis paper, we introduce a $k$ nearest neighbor NER ($k$NN-NER) framework,\nwhich augments the distribution of entity labels by assigning $k$ nearest\nneighbors retrieved from the training set. This strategy makes the model more\ncapable of handling long-tail cases, along with better few-shot learning\nabilities. $k$NN-NER requires no additional operation during the training\nphase, and by interpolating $k$ nearest neighbors search into the vanilla NER\nmodel, $k$NN-NER consistently outperforms its vanilla counterparts: we achieve\na new state-of-the-art F1-score of 72.03 (+1.25) on the Chinese Weibo dataset\nand improved results on a variety of widely used NER benchmarks. Additionally,\nwe show that $k$NN-NER can achieve comparable results to the vanilla NER model\nwith 40\\% less amount of training data. Code available at\n\\url{https://github.com/ShannonAI/KNN-NER}.\n",
                "链接": "https://arxiv.org/abs/2203.17103"
            },
            {
                "文章ID": "44485",
                "标题": "Improving Chinese Named Entity Recognition by Search Engine Augmentation",
                "作者": " Qinghua Mao,  Jiatong Li,  Kui Meng",
                "发布日期": "2022-10-25",
                "摘要": "  Compared with English, Chinese suffers from more grammatical ambiguities,\nlike fuzzy word boundaries and polysemous words. In this case, contextual\ninformation is not sufficient to support Chinese named entity recognition\n(NER), especially for rare and emerging named entities. Semantic augmentation\nusing external knowledge is a potential way to alleviate this problem, while\nhow to obtain and leverage external knowledge for the NER task remains a\nchallenge. In this paper, we propose a neural-based approach to perform\nsemantic augmentation using external knowledge from search engine for Chinese\nNER. In particular, a multi-channel semantic fusion model is adopted to\ngenerate the augmented input representations, which aggregates external related\ntexts retrieved from the search engine. Experiments have shown the superiority\nof our model across 4 NER datasets, including formal and social media language\ncontexts, which further prove the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2210.12662"
            },
            {
                "文章ID": "14564",
                "标题": "Delving Deep into Regularity: A Simple but Effective Method for Chinese\n  Named Entity Recognition",
                "作者": " Yingjie Gu,  Xiaoye Qu,  Zhefeng Wang,  Yi Zheng,  Baoxing Huai,  Nicholas Jing Yuan",
                "发布日期": "2022-04-19",
                "摘要": "  Recent years have witnessed the improving performance of Chinese Named Entity\nRecognition (NER) from proposing new frameworks or incorporating word lexicons.\nHowever, the inner composition of entity mentions in character-level Chinese\nNER has been rarely studied. Actually, most mentions of regular types have\nstrong name regularity. For example, entities end with indicator words such as\n\"company\" or \"bank\" usually belong to organization. In this paper, we propose a\nsimple but effective method for investigating the regularity of entity spans in\nChinese NER, dubbed as Regularity-Inspired reCOgnition Network (RICON).\nSpecifically, the proposed model consists of two branches: a regularity-aware\nmodule and a regularityagnostic module. The regularity-aware module captures\nthe internal regularity of each span for better entity type prediction, while\nthe regularity-agnostic module is employed to locate the boundary of entities\nand relieve the excessive attention to span regularity. An orthogonality space\nis further constructed to encourage two modules to extract different aspects of\nregularity features. To verify the effectiveness of our method, we conduct\nextensive experiments on three benchmark datasets and a practical medical\ndataset. The experimental results show that our RICON significantly outperforms\nprevious state-of-the-art methods, including various lexicon-based methods.\n",
                "链接": "https://arxiv.org/abs/2204.05544"
            },
            {
                "文章ID": "125250",
                "标题": "Unified Lattice Graph Fusion for Chinese Named Entity Recognition",
                "作者": " Dixiang Zhang,  Junyu Lu,  Pingjian Zhang",
                "发布日期": "2023-12-29",
                "摘要": "  Integrating lexicon into character-level sequence has been proven effective\nto leverage word boundary and semantic information in Chinese named entity\nrecognition (NER). However, prior approaches usually utilize feature weighting\nand position coupling to integrate word information, but ignore the semantic\nand contextual correspondence between the fine-grained semantic units in the\ncharacter-word space. To solve this issue, we propose a Unified Lattice Graph\nFusion (ULGF) approach for Chinese NER. ULGF can explicitly capture various\nsemantic and boundary relations across different semantic units with the\nadjacency matrix by converting the lattice structure into a unified graph. We\nstack multiple graph-based intra-source self-attention and inter-source\ncross-gating fusion layers that iteratively carry out semantic interactions to\nlearn node representations. To alleviate the over-reliance on word information,\nwe further propose to leverage lexicon entity classification as an auxiliary\ntask. Experiments on four Chinese NER benchmark datasets demonstrate the\nsuperiority of our ULGF approach.\n",
                "链接": "https://arxiv.org/abs/2312.16917"
            },
            {
                "文章ID": "75893",
                "标题": "LLM-RM at SemEval-2023 Task 2: Multilingual Complex NER using\n  XLM-RoBERTa",
                "作者": " Rahul Mehta,  Vasudeva Varma",
                "发布日期": "2023-05-08",
                "摘要": "  Named Entity Recognition(NER) is a task of recognizing entities at a token\nlevel in a sentence. This paper focuses on solving NER tasks in a multilingual\nsetting for complex named entities. Our team, LLM-RM participated in the\nrecently organized SemEval 2023 task, Task 2: MultiCoNER II,Multilingual\nComplex Named Entity Recognition. We approach the problem by leveraging\ncross-lingual representation provided by fine-tuning XLM-Roberta base model on\ndatasets of all of the 12 languages provided -- Bangla, Chinese, English,\nFarsi, French, German, Hindi, Italian, Portuguese, Spanish, Swedish and\nUkrainian\n",
                "链接": "https://arxiv.org/abs/2305.03300"
            },
            {
                "文章ID": "108977",
                "标题": "Empirical Study of Zero-Shot NER with ChatGPT",
                "作者": " Tingyu Xie,  Qi Li,  Jian Zhang,  Yan Zhang,  Zuozhu Liu,  Hongwei Wang",
                "发布日期": "2023-10-17",
                "摘要": "  Large language models (LLMs) exhibited powerful capability in various natural\nlanguage processing tasks. This work focuses on exploring LLM performance on\nzero-shot information extraction, with a focus on the ChatGPT and named entity\nrecognition (NER) task. Inspired by the remarkable reasoning capability of LLM\non symbolic and arithmetic reasoning, we adapt the prevalent reasoning methods\nto NER and propose reasoning strategies tailored for NER. First, we explore a\ndecomposed question-answering paradigm by breaking down the NER task into\nsimpler subproblems by labels. Second, we propose syntactic augmentation to\nstimulate the model's intermediate thinking in two ways: syntactic prompting,\nwhich encourages the model to analyze the syntactic structure itself, and tool\naugmentation, which provides the model with the syntactic information generated\nby a parsing tool. Besides, we adapt self-consistency to NER by proposing a\ntwo-stage majority voting strategy, which first votes for the most consistent\nmentions, then the most consistent types. The proposed methods achieve\nremarkable improvements for zero-shot NER across seven benchmarks, including\nChinese and English datasets, and on both domain-specific and general-domain\nscenarios. In addition, we present a comprehensive analysis of the error types\nwith suggestions for optimization directions. We also verify the effectiveness\nof the proposed methods on the few-shot setting and other LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.10035"
            },
            {
                "文章ID": "28049",
                "标题": "Rethinking the Value of Gazetteer in Chinese Named Entity Recognition",
                "作者": " Qianglong Chen,  Xiangji Zeng,  Jiangang Zhu,  Yin Zhang,  Bojia Lin,  Yang Yang,  Daxin Jiang",
                "发布日期": "2022-07-19",
                "摘要": "  Gazetteer is widely used in Chinese named entity recognition (NER) to enhance\nspan boundary detection and type classification. However, to further understand\nthe generalizability and effectiveness of gazetteers, the NLP community still\nlacks a systematic analysis of the gazetteer-enhanced NER model. In this paper,\nwe first re-examine the effectiveness several common practices of the\ngazetteer-enhanced NER models and carry out a series of detailed analysis to\nevaluate the relationship between the model performance and the gazetteer\ncharacteristics, which can guide us to build a more suitable gazetteer. The\nfindings of this paper are as follows: (1) the gazetteer improves most of the\nsituations that the traditional NER model datasets are difficult to learn. (2)\nthe performance of model greatly benefits from the high-quality pre-trained\nlexeme embeddings. (3) a good gazetteer should cover more entities that can be\nmatched in both the training set and testing set.\n",
                "链接": "https://arxiv.org/abs/2207.02802"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下最近用反事实做数据增强的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "81687",
                "标题": "On Counterfactual Data Augmentation Under Confounding",
                "作者": " Abbavaram Gowtham Reddy,  Saketh Bachu,  Saloni Dash,  Charchit Sharma,  Amit Sharma,  Vineeth N Balasubramanian",
                "发布日期": "2023-11-22",
                "摘要": "  Counterfactual data augmentation has recently emerged as a method to mitigate\nconfounding biases in the training data. These biases, such as spurious\ncorrelations, arise due to various observed and unobserved confounding\nvariables in the data generation process. In this paper, we formally analyze\nhow confounding biases impact downstream classifiers and present a causal\nviewpoint to the solutions based on counterfactual data augmentation. We\nexplore how removing confounding biases serves as a means to learn invariant\nfeatures, ultimately aiding in generalization beyond the observed data\ndistribution. Additionally, we present a straightforward yet powerful algorithm\nfor generating counterfactual images, which effectively mitigates the influence\nof confounding effects on downstream classifiers. Through experiments on MNIST\nvariants and the CelebA datasets, we demonstrate how our simple augmentation\nmethod helps existing state-of-the-art methods achieve good results.\n",
                "链接": "https://arxiv.org/abs/2305.18183"
            },
            {
                "文章ID": "114161",
                "标题": "Counterfactual Data Augmentation with Contrastive Learning",
                "作者": " Ahmed Aloui,  Juncheng Dong,  Cat P. Le,  Vahid Tarokh",
                "发布日期": "2023-11-08",
                "摘要": "  Statistical disparity between distinct treatment groups is one of the most\nsignificant challenges for estimating Conditional Average Treatment Effects\n(CATE). To address this, we introduce a model-agnostic data augmentation method\nthat imputes the counterfactual outcomes for a selected subset of individuals.\nSpecifically, we utilize contrastive learning to learn a representation space\nand a similarity measure such that in the learned representation space close\nindividuals identified by the learned similarity measure have similar potential\noutcomes. This property ensures reliable imputation of counterfactual outcomes\nfor the individuals with close neighbors from the alternative treatment group.\nBy augmenting the original dataset with these reliable imputations, we can\neffectively reduce the discrepancy between different treatment groups, while\ninducing minimal imputation error. The augmented dataset is subsequently\nemployed to train CATE estimation models. Theoretical analysis and experimental\nstudies on synthetic and semi-synthetic benchmarks demonstrate that our method\nachieves significant improvements in both performance and robustness to\noverfitting across state-of-the-art models.\n",
                "链接": "https://arxiv.org/abs/2311.03630"
            },
            {
                "文章ID": "86799",
                "标题": "A Novel Counterfactual Data Augmentation Method for Aspect-Based\n  Sentiment Analysis",
                "作者": " Dongming Wu,  Lulu Wen,  Chao Chen,  Zhaoshu Shi",
                "发布日期": "2023-10-10",
                "摘要": "  Aspect-based-sentiment-analysis (ABSA) is a fine-grained sentiment evaluation\ntask, which analyzes the emotional polarity of the evaluation aspects.\nGenerally, the emotional polarity of an aspect exists in the corresponding\nopinion expression, whose diversity has great impact on model's performance. To\nmitigate this problem, we propose a novel and simple counterfactual data\naugmentation method to generate opinion expressions with reversed sentiment\npolarity. In particular, the integrated gradients are calculated to locate and\nmask the opinion expression. Then, a prompt combined with the reverse\nexpression polarity is added to the original text, and a Pre-trained language\nmodel (PLM), T5, is finally was employed to predict the masks. The experimental\nresults shows the proposed counterfactual data augmentation method performs\nbetter than current augmentation methods on three ABSA datasets, i.e. Laptop,\nRestaurant, and MAMS.\n",
                "链接": "https://arxiv.org/abs/2306.11260"
            },
            {
                "文章ID": "110605",
                "标题": "EXPLAIN, EDIT, GENERATE: Rationale-Sensitive Counterfactual Data\n  Augmentation for Multi-hop Fact Verification",
                "作者": " Yingjie Zhu,  Jiasheng Si,  Yibo Zhao,  Haiyang Zhu,  Deyu Zhou,  Yulan He",
                "发布日期": "2023-10-24",
                "摘要": "  Automatic multi-hop fact verification task has gained significant attention\nin recent years. Despite impressive results, these well-designed models perform\npoorly on out-of-domain data. One possible solution is to augment the training\ndata with counterfactuals, which are generated by minimally altering the causal\nfeatures of the original data. However, current counterfactual data\naugmentation techniques fail to handle multi-hop fact verification due to their\nincapability to preserve the complex logical relationships within multiple\ncorrelated texts. In this paper, we overcome this limitation by developing a\nrationale-sensitive method to generate linguistically diverse and\nlabel-flipping counterfactuals while preserving logical relationships. In\nspecific, the diverse and fluent counterfactuals are generated via an\nExplain-Edit-Generate architecture. Moreover, the checking and filtering\nmodules are proposed to regularize the counterfactual data with logical\nrelations and flipped labels. Experimental results show that the proposed\napproach outperforms the SOTA baselines and can generate linguistically diverse\ncounterfactual data without disrupting their logical relationships.\n",
                "链接": "https://arxiv.org/abs/2310.14508"
            },
            {
                "文章ID": "88864",
                "标题": "Counterfactual Collaborative Reasoning",
                "作者": " Jianchao Ji,  Zelong Li,  Shuyuan Xu,  Max Xiong,  Juntao Tan,  Yingqiang Ge,  Hao Wang,  Yongfeng Zhang",
                "发布日期": "2023-07-06",
                "摘要": "  Causal reasoning and logical reasoning are two important types of reasoning\nabilities for human intelligence. However, their relationship has not been\nextensively explored under machine intelligence context. In this paper, we\nexplore how the two reasoning abilities can be jointly modeled to enhance both\naccuracy and explainability of machine learning models. More specifically, by\nintegrating two important types of reasoning ability -- counterfactual\nreasoning and (neural) logical reasoning -- we propose Counterfactual\nCollaborative Reasoning (CCR), which conducts counterfactual logic reasoning to\nimprove the performance. In particular, we use recommender system as an example\nto show how CCR alleviate data scarcity, improve accuracy and enhance\ntransparency. Technically, we leverage counterfactual reasoning to generate\n\"difficult\" counterfactual training examples for data augmentation, which --\ntogether with the original training examples -- can enhance the model\nperformance. Since the augmented data is model irrelevant, they can be used to\nenhance any model, enabling the wide applicability of the technique. Besides,\nmost of the existing data augmentation methods focus on \"implicit data\naugmentation\" over users' implicit feedback, while our framework conducts\n\"explicit data augmentation\" over users explicit feedback based on\ncounterfactual logic reasoning. Experiments on three real-world datasets show\nthat CCR achieves better performance than non-augmented models and implicitly\naugmented models, and also improves model transparency by generating\ncounterfactual explanations.\n",
                "链接": "https://arxiv.org/abs/2307.00165"
            },
            {
                "文章ID": "82682",
                "标题": "CAISA at SemEval-2023 Task 8: Counterfactual Data Augmentation for\n  Mitigating Class Imbalance in Causal Claim Identification",
                "作者": " Akbar Karimi,  Lucie Flek",
                "发布日期": "2023-06-02",
                "摘要": "  The class imbalance problem can cause machine learning models to produce an\nundesirable performance on the minority class as well as the whole dataset.\nUsing data augmentation techniques to increase the number of samples is one way\nto tackle this problem. We introduce a novel counterfactual data augmentation\nby verb replacement for the identification of medical claims. In addition, we\ninvestigate the impact of this method and compare it with 3 other data\naugmentation techniques, showing that the proposed method can result in a\nsignificant (relative) improvement in the minority class.\n",
                "链接": "https://arxiv.org/abs/2306.00346"
            },
            {
                "文章ID": "80211",
                "标题": "Large Language Models as Counterfactual Generator: Strengths and\n  Weaknesses",
                "作者": " Yongqi Li,  Mayi Xu,  Xin Miao,  Shen Zhou,  Tieyun Qian",
                "发布日期": "2023-05-25",
                "摘要": "  Large language models (LLMs) have demonstrated remarkable performance in a\nrange of natural language understanding and generation tasks. Yet, their\nability to generate counterfactuals, which can be used for areas like data\naugmentation, remains under-explored. This study aims to investigate the\ncounterfactual generation capabilities of LLMs and analysis factors that\ninfluence this ability. First, we evaluate how effective are LLMs in\ncounterfactual generation through data augmentation experiments for small\nlanguage models (SLMs) across four tasks: sentiment analysis, natural language\ninference, named entity recognition, and relation extraction. While LLMs show\npromising enhancements in various settings, they struggle in complex tasks due\nto their self-limitations and the lack of logical guidance to produce\ncounterfactuals that align with commonsense. Second, our analysis reveals the\npivotal role of providing accurate task definitions and detailed step-by-step\ninstructions to LLMs in generating counterfactuals. Interestingly, we also find\nthat LLMs can generate reasonable counterfactuals even with unreasonable\ndemonstrations, which illustrates that demonstrations are primarily to regulate\nthe output format.This study provides the first comprehensive insight into\ncounterfactual generation abilities of LLMs, and offers a novel perspective on\nutilizing LLMs for data augmentation to enhance SLMs.\n",
                "链接": "https://arxiv.org/abs/2305.14791"
            },
            {
                "文章ID": "91298",
                "标题": "Learning for Counterfactual Fairness from Observational Data",
                "作者": " Jing Ma,  Ruocheng Guo,  Aidong Zhang,  Jundong Li",
                "发布日期": "2023-07-18",
                "摘要": "  Fairness-aware machine learning has attracted a surge of attention in many\ndomains, such as online advertising, personalized recommendation, and social\nmedia analysis in web applications. Fairness-aware machine learning aims to\neliminate biases of learning models against certain subgroups described by\ncertain protected (sensitive) attributes such as race, gender, and age. Among\nmany existing fairness notions, counterfactual fairness is a popular notion\ndefined from a causal perspective. It measures the fairness of a predictor by\ncomparing the prediction of each individual in the original world and that in\nthe counterfactual worlds in which the value of the sensitive attribute is\nmodified. A prerequisite for existing methods to achieve counterfactual\nfairness is the prior human knowledge of the causal model for the data.\nHowever, in real-world scenarios, the underlying causal model is often unknown,\nand acquiring such human knowledge could be very difficult. In these scenarios,\nit is risky to directly trust the causal models obtained from information\nsources with unknown reliability and even causal discovery methods, as\nincorrect causal models can consequently bring biases to the predictor and lead\nto unfair predictions. In this work, we address the problem of counterfactually\nfair prediction from observational data without given causal models by\nproposing a novel framework CLAIRE. Specifically, under certain general\nassumptions, CLAIRE effectively mitigates the biases from the sensitive\nattribute with a representation learning framework based on counterfactual data\naugmentation and an invariant penalty. Experiments conducted on both synthetic\nand real-world datasets validate the superiority of CLAIRE in both\ncounterfactual fairness and prediction performance.\n",
                "链接": "https://arxiv.org/abs/2307.08232"
            },
            {
                "文章ID": "83688",
                "标题": "Improving Conversational Recommendation Systems via Counterfactual Data\n  Simulation",
                "作者": " Xiaolei Wang,  Kun Zhou,  Xinyu Tang,  Wayne Xin Zhao,  Fan Pan,  Zhao Cao,  Ji-Rong Wen",
                "发布日期": "2023-06-09",
                "摘要": "  Conversational recommender systems (CRSs) aim to provide recommendation\nservices via natural language conversations. Although a number of approaches\nhave been proposed for developing capable CRSs, they typically rely on\nsufficient training data for training. Since it is difficult to annotate\nrecommendation-oriented dialogue datasets, existing CRS approaches often suffer\nfrom the issue of insufficient training due to the scarcity of training data.\nTo address this issue, in this paper, we propose a CounterFactual data\nsimulation approach for CRS, named CFCRS, to alleviate the issue of data\nscarcity in CRSs. Our approach is developed based on the framework of\ncounterfactual data augmentation, which gradually incorporates the rewriting to\nthe user preference from a real dialogue without interfering with the entire\nconversation flow. To develop our approach, we characterize user preference and\norganize the conversation flow by the entities involved in the dialogue, and\ndesign a multi-stage recommendation dialogue simulator based on a conversation\nflow language model. Under the guidance of the learned user preference and\ndialogue schema, the flow language model can produce reasonable, coherent\nconversation flows, which can be further realized into complete dialogues.\nBased on the simulator, we perform the intervention at the representations of\nthe interacted entities of target users, and design an adversarial training\nmethod with a curriculum schedule that can gradually optimize the data\naugmentation strategy. Extensive experiments show that our approach can\nconsistently boost the performance of several competitive CRSs, and outperform\nother data augmentation methods, especially when the training data is limited.\nOur code is publicly available at https://github.com/RUCAIBox/CFCRS.\n",
                "链接": "https://arxiv.org/abs/2306.02842"
            },
            {
                "文章ID": "97852",
                "标题": "Targeted Data Augmentation for bias mitigation",
                "作者": " Agnieszka Mikołajczyk-Bareła,  Maria Ferlin,  Michał Grochowski",
                "发布日期": "2023-08-23",
                "摘要": "  The development of fair and ethical AI systems requires careful consideration\nof bias mitigation, an area often overlooked or ignored. In this study, we\nintroduce a novel and efficient approach for addressing biases called Targeted\nData Augmentation (TDA), which leverages classical data augmentation techniques\nto tackle the pressing issue of bias in data and models. Unlike the laborious\ntask of removing biases, our method proposes to insert biases instead,\nresulting in improved performance. To identify biases, we annotated two diverse\ndatasets: a dataset of clinical skin lesions and a dataset of male and female\nfaces. These bias annotations are published for the first time in this study,\nproviding a valuable resource for future research. Through Counterfactual Bias\nInsertion, we discovered that biases associated with the frame, ruler, and\nglasses had a significant impact on models. By randomly introducing biases\nduring training, we mitigated these biases and achieved a substantial decrease\nin bias measures, ranging from two-fold to more than 50-fold, while maintaining\na negligible increase in the error rate.\n",
                "链接": "https://arxiv.org/abs/2308.11386"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用蒙特卡罗树搜索解决序列决策问题的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "50093",
                "标题": "Monte Carlo Tree Search Algorithms for Risk-Aware and Multi-Objective\n  Reinforcement Learning",
                "作者": " Conor F. Hayes,  Mathieu Reymond,  Diederik M. Roijers,  Enda Howley,  Patrick Mannion",
                "发布日期": "2022-12-07",
                "摘要": "  In many risk-aware and multi-objective reinforcement learning settings, the\nutility of the user is derived from a single execution of a policy. In these\nsettings, making decisions based on the average future returns is not suitable.\nFor example, in a medical setting a patient may only have one opportunity to\ntreat their illness. Making decisions using just the expected future returns --\nknown in reinforcement learning as the value -- cannot account for the\npotential range of adverse or positive outcomes a decision may have. Therefore,\nwe should use the distribution over expected future returns differently to\nrepresent the critical information that the agent requires at decision time by\ntaking both the future and accrued returns into consideration. In this paper,\nwe propose two novel Monte Carlo tree search algorithms. Firstly, we present a\nMonte Carlo tree search algorithm that can compute policies for nonlinear\nutility functions (NLU-MCTS) by optimising the utility of the different\npossible returns attainable from individual policy executions, resulting in\ngood policies for both risk-aware and multi-objective settings. Secondly, we\npropose a distributional Monte Carlo tree search algorithm (DMCTS) which\nextends NLU-MCTS. DMCTS computes an approximate posterior distribution over the\nutility of the returns, and utilises Thompson sampling during planning to\ncompute policies in risk-aware and multi-objective settings. Both algorithms\noutperform the state-of-the-art in multi-objective reinforcement learning for\nthe expected utility of the returns.\n",
                "链接": "https://arxiv.org/abs/2211.13032"
            },
            {
                "文章ID": "102301",
                "标题": "Maneuver Decision-Making Through Proximal Policy Optimization And Monte\n  Carlo Tree Search",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-09-19",
                "摘要": "  Maneuver decision-making can be regarded as a Markov decision process and can\nbe address by reinforcement learning. However, original reinforcement learning\nalgorithms can hardly solve the maneuvering decision-making problem. One reason\nis that agents use random actions in the early stages of training, which makes\nit difficult to get rewards and learn how to make effective decisions. To\naddress this issue, a method based on proximal policy optimization and Monte\nCarlo tree search is proposed. The method uses proximal policy optimization to\ntrain the agent, and regards the results of air combat as targets to train the\nvalue network. Then, based on the value network and the visit count of each\nnode, Monte Carlo tree search is used to find the actions with more expected\nreturns than random actions, which can improve the training performance. The\nablation studies and simulation experiments indicate that agents trained by the\nproposed method can make different decisions according to different states,\nwhich demonstrates that the method can solve the maneuvering decision problem\nthat the original reinforcement learning algorithm cannot solve.\n",
                "链接": "https://arxiv.org/abs/2309.08611"
            },
            {
                "文章ID": "106127",
                "标题": "Rollout Heuristics for Online Stochastic Contingent Planning",
                "作者": " Oded Blumenthal,  Guy Shani",
                "发布日期": "2023-10-05",
                "摘要": "  Partially observable Markov decision processes (POMDP) are a useful model for\ndecision-making under partial observability and stochastic actions. Partially\nObservable Monte-Carlo Planning is an online algorithm for deciding on the next\naction to perform, using a Monte-Carlo tree search approach, based on the UCT\n(UCB applied to trees) algorithm for fully observable Markov-decision\nprocesses. POMCP develops an action-observation tree, and at the leaves, uses a\nrollout policy to provide a value estimate for the leaf. As such, POMCP is\nhighly dependent on the rollout policy to compute good estimates, and hence\nidentify good actions. Thus, many practitioners who use POMCP are required to\ncreate strong, domain-specific heuristics.\n  In this paper, we model POMDPs as stochastic contingent planning problems.\nThis allows us to leverage domain-independent heuristics that were developed in\nthe planning community. We suggest two heuristics, the first is based on the\nwell-known h_add heuristic from classical planning, and the second is computed\nin belief space, taking the value of information into account.\n",
                "链接": "https://arxiv.org/abs/2310.02345"
            },
            {
                "文章ID": "40416",
                "标题": "Continuous Monte Carlo Graph Search",
                "作者": " Kalle Kujanpää,  Amin Babadi,  Yi Zhao,  Juho Kannala,  Alexander Ilin,  Joni Pajarinen",
                "发布日期": "2023-07-19",
                "摘要": "  In many complex sequential decision-making tasks, online planning is crucial\nfor high performance. For efficient online planning, Monte Carlo Tree Search\n(MCTS) employs a principled mechanism for trading off exploration for\nexploitation. MCTS outperforms comparison methods in many discrete\ndecision-making domains such as Go, Chess, and Shogi. Following, extensions of\nMCTS to continuous domains have been proposed. However, the inherent high\nbranching factor and the resulting explosion of search tree size are limiting\nexisting methods. To address this problem, we propose Continuous Monte Carlo\nGraph Search (CMCGS), a novel extension of MCTS to online planning in\nenvironments with continuous state and action spaces. CMCGS takes advantage of\nthe insight that, during planning, sharing the same action policy between\nseveral states can yield high performance. To implement this idea, at each time\nstep, CMCGS clusters similar states into a limited number of stochastic action\nbandit nodes, which produce a layered directed graph instead of an MCTS search\ntree. Experimental evaluation shows that CMCGS outperforms comparable planning\nmethods in several complex continuous DeepMind Control Suite benchmarks and a\n2D navigation task with limited sample budgets. Furthermore, CMCGS can be\nparallelized to scale up and it outperforms the Cross-Entropy Method (CEM) in\ncontinuous control with learned dynamics models.\n",
                "链接": "https://arxiv.org/abs/2210.01426"
            },
            {
                "文章ID": "40701",
                "标题": "Cost Aware Asynchronous Multi-Agent Active Search",
                "作者": " Arundhati Banerjee,  Ramina Ghods,  Jeff Schneider",
                "发布日期": "2022-10-06",
                "摘要": "  Multi-agent active search requires autonomous agents to choose sensing\nactions that efficiently locate targets. In a realistic setting, agents also\nmust consider the costs that their decisions incur. Previously proposed active\nsearch algorithms simplify the problem by ignoring uncertainty in the agent's\nenvironment, using myopic decision making, and/or overlooking costs. In this\npaper, we introduce an online active search algorithm to detect targets in an\nunknown environment by making adaptive cost-aware decisions regarding the\nagent's actions. Our algorithm combines principles from Thompson Sampling (for\nsearch space exploration and decentralized multi-agent decision making), Monte\nCarlo Tree Search (for long horizon planning) and pareto-optimal confidence\nbounds (for multi-objective optimization in an unknown environment) to propose\nan online lookahead planner that removes all the simplifications. We analyze\nthe algorithm's performance in simulation to show its efficacy in cost aware\nactive search.\n",
                "链接": "https://arxiv.org/abs/2210.02259"
            },
            {
                "文章ID": "7216",
                "标题": "Decision Making in Non-Stationary Environments with Policy-Augmented\n  Monte Carlo Tree Search",
                "作者": " Geoffrey Pettet,  Ayan Mukhopadhyay,  Abhishek Dubey",
                "发布日期": "2022-03-01",
                "摘要": "  Decision-making under uncertainty (DMU) is present in many important\nproblems. An open challenge is DMU in non-stationary environments, where the\ndynamics of the environment can change over time. Reinforcement Learning (RL),\na popular approach for DMU problems, learns a policy by interacting with a\nmodel of the environment offline. Unfortunately, if the environment changes the\npolicy can become stale and take sub-optimal actions, and relearning the policy\nfor the updated environment takes time and computational effort. An alternative\nis online planning approaches such as Monte Carlo Tree Search (MCTS), which\nperform their computation at decision time. Given the current environment, MCTS\nplans using high-fidelity models to determine promising action trajectories.\nThese models can be updated as soon as environmental changes are detected to\nimmediately incorporate them into decision making. However, MCTS's convergence\ncan be slow for domains with large state-action spaces. In this paper, we\npresent a novel hybrid decision-making approach that combines the strengths of\nRL and planning while mitigating their weaknesses. Our approach, called Policy\nAugmented MCTS (PA-MCTS), integrates a policy's actin-value estimates into\nMCTS, using the estimates to seed the action trajectories favored by the\nsearch. We hypothesize that PA-MCTS will converge more quickly than standard\nMCTS while making better decisions than the policy can make on its own when\nfaced with nonstationary environments. We test our hypothesis by comparing\nPA-MCTS with pure MCTS and an RL agent applied to the classical CartPole\nenvironment. We find that PC-MCTS can achieve higher cumulative rewards than\nthe policy in isolation under several environmental shifts while converging in\nsignificantly fewer iterations than pure MCTS.\n",
                "链接": "https://arxiv.org/abs/2202.13003"
            },
            {
                "文章ID": "108378",
                "标题": "LightZero: A Unified Benchmark for Monte Carlo Tree Search in General\n  Sequential Decision Scenarios",
                "作者": " Yazhe Niu,  Yuan Pu,  Zhenjie Yang,  Xueyan Li,  Tong Zhou,  Jiyuan Ren,  Shuai Hu,  Hongsheng Li,  Yu Liu",
                "发布日期": "2023-10-13",
                "摘要": "  Building agents based on tree-search planning capabilities with learned\nmodels has achieved remarkable success in classic decision-making problems,\nsuch as Go and Atari. However, it has been deemed challenging or even\ninfeasible to extend Monte Carlo Tree Search (MCTS) based algorithms to diverse\nreal-world applications, especially when these environments involve complex\naction spaces and significant simulation costs, or inherent stochasticity. In\nthis work, we introduce LightZero, the first unified benchmark for deploying\nMCTS/MuZero in general sequential decision scenarios. Specificially, we\nsummarize the most critical challenges in designing a general MCTS-style\ndecision-making solver, then decompose the tightly-coupled algorithm and system\ndesign of tree-search RL methods into distinct sub-modules. By incorporating\nmore appropriate exploration and optimization strategies, we can significantly\nenhance these sub-modules and construct powerful LightZero agents to tackle\ntasks across a wide range of domains, such as board games, Atari, MuJoCo,\nMiniGrid and GoBigger. Detailed benchmark results reveal the significant\npotential of such methods in building scalable and efficient decision\nintelligence. The code is available as part of OpenDILab at\nhttps://github.com/opendilab/LightZero.\n",
                "链接": "https://arxiv.org/abs/2310.08348"
            },
            {
                "文章ID": "23592",
                "标题": "Combining Monte-Carlo Tree Search with Proof-Number Search",
                "作者": " Elliot Doe,  Mark H. M. Winands,  Dennis J. N. J. Soemers,  Cameron Browne",
                "发布日期": "2022-06-09",
                "摘要": "  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
                "链接": "https://arxiv.org/abs/2206.03965"
            },
            {
                "文章ID": "82026",
                "标题": "Bayesian Decision Trees Inspired from Evolutionary Algorithms",
                "作者": " Efthyvoulos Drousiotis,  Alexander M. Phillips,  Paul G. Spirakis,  Simon Maskell",
                "发布日期": "2023-05-31",
                "摘要": "  Bayesian Decision Trees (DTs) are generally considered a more advanced and\naccurate model than a regular Decision Tree (DT) because they can handle\ncomplex and uncertain data. Existing work on Bayesian DTs uses Markov Chain\nMonte Carlo (MCMC) with an accept-reject mechanism and sample using naive\nproposals to proceed to the next iteration, which can be slow because of the\nburn-in time needed. We can reduce the burn-in period by proposing a more\nsophisticated way of sampling or by designing a different numerical Bayesian\napproach. In this paper, we propose a replacement of the MCMC with an\ninherently parallel algorithm, the Sequential Monte Carlo (SMC), and a more\neffective sampling strategy inspired by the Evolutionary Algorithms (EA).\nExperiments show that SMC combined with the EA can produce more accurate\nresults compared to MCMC in 100 times fewer iterations.\n",
                "链接": "https://arxiv.org/abs/2305.18774"
            },
            {
                "文章ID": "98469",
                "标题": "Diverse, Top-k, and Top-Quality Planning Over Simulators",
                "作者": " Lyndon Benke,  Tim Miller,  Michael Papasimeon,  Nir Lipovetzky",
                "发布日期": "2023-08-28",
                "摘要": "  Diverse, top-k, and top-quality planning are concerned with the generation of\nsets of solutions to sequential decision problems. Previously this area has\nbeen the domain of classical planners that require a symbolic model of the\nproblem instance. This paper proposes a novel alternative approach that uses\nMonte Carlo Tree Search (MCTS), enabling application to problems for which only\na black-box simulation model is available. We present a procedure for\nextracting bounded sets of plans from pre-generated search trees in best-first\norder, and a metric for evaluating the relative quality of paths through a\nsearch tree. We demonstrate this approach on a path-planning problem with\nhidden information, and suggest adaptations to the MCTS algorithm to increase\nthe diversity of generated plans. Our results show that our method can generate\ndiverse and high-quality plan sets in domains where classical planners are not\napplicable.\n",
                "链接": "https://arxiv.org/abs/2308.13147"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用gpt4做评测指标优缺点的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "116110",
                "标题": "Enhancing Medical Text Evaluation with GPT-4",
                "作者": " Yiqing Xie,  Sheng Zhang,  Hao Cheng,  Zelalem Gero,  Cliff Wong,  Tristan Naumann,  Hoifung Poon",
                "发布日期": "2023-11-17",
                "摘要": "  In the evaluation of medical text generation, it is essential to scrutinize\neach piece of information and ensure the utmost accuracy of the evaluation.\nExisting evaluation metrics either focus on coarse-level evaluation that\nassigns one score for the whole generated output or rely on evaluation models\ntrained on general domain, resulting in inaccuracies when adapted to the\nmedical domain. To address these issues, we propose a set of factuality-centric\nevaluation aspects and design corresponding GPT-4-based metrics for medical\ntext generation. We systematically compare these metrics with existing ones on\nclinical note generation and medical report summarization tasks, revealing low\ninter-metric correlation. A comprehensive human evaluation confirms that the\nproposed GPT-4-based metrics exhibit substantially higher agreement with human\njudgments than existing evaluation metrics. Our study contributes to the\nunderstanding of medical text generation evaluation and offers a more reliable\nalternative to existing metrics.\n",
                "链接": "https://arxiv.org/abs/2311.09581"
            },
            {
                "文章ID": "95177",
                "标题": "GPT-4 Can't Reason",
                "作者": " Konstantine Arkoudas",
                "发布日期": "2023-08-11",
                "摘要": "  GPT-4 was released in March 2023 to wide acclaim, marking a very substantial\nimprovement across the board over GPT-3.5 (OpenAI's previously best model,\nwhich had powered the initial release of ChatGPT). However, despite the\ngenuinely impressive improvement, there are good reasons to be highly skeptical\nof GPT-4's ability to reason. This position paper discusses the nature of\nreasoning; criticizes the current formulation of reasoning problems in the NLP\ncommunity, as well as the way in which LLM reasoning performance is currently\nevaluated; introduces a small collection of 21 diverse reasoning problems; and\nperforms a detailed qualitative evaluation of GPT-4's performance on those\nproblems. Based on this analysis, the paper concludes that, despite its\noccasional flashes of analytical brilliance, GPT-4 at present is utterly\nincapable of reasoning.\n",
                "链接": "https://arxiv.org/abs/2308.03762"
            },
            {
                "文章ID": "80356",
                "标题": "Is GPT-4 a Good Data Analyst?",
                "作者": " Liying Cheng,  Xingxuan Li,  Lidong Bing",
                "发布日期": "2023-10-24",
                "摘要": "  As large language models (LLMs) have demonstrated their powerful capabilities\nin plenty of domains and tasks, including context understanding, code\ngeneration, language generation, data storytelling, etc., many data analysts\nmay raise concerns if their jobs will be replaced by artificial intelligence\n(AI). This controversial topic has drawn great attention in public. However, we\nare still at a stage of divergent opinions without any definitive conclusion.\nMotivated by this, we raise the research question of \"is GPT-4 a good data\nanalyst?\" in this work and aim to answer it by conducting head-to-head\ncomparative studies. In detail, we regard GPT-4 as a data analyst to perform\nend-to-end data analysis with databases from a wide range of domains. We\npropose a framework to tackle the problems by carefully designing the prompts\nfor GPT-4 to conduct experiments. We also design several task-specific\nevaluation metrics to systematically compare the performance between several\nprofessional human data analysts and GPT-4. Experimental results show that\nGPT-4 can achieve comparable performance to humans. We also provide in-depth\ndiscussions about our results to shed light on further studies before reaching\nthe conclusion that GPT-4 can replace data analysts.\n",
                "链接": "https://arxiv.org/abs/2305.15038"
            },
            {
                "文章ID": "71129",
                "标题": "Instruction Tuning with GPT-4",
                "作者": " Baolin Peng,  Chunyuan Li,  Pengcheng He,  Michel Galley,  Jianfeng Gao",
                "发布日期": "2023-04-07",
                "摘要": "  Prior work has shown that finetuning large language models (LLMs) using\nmachine-generated instruction-following data enables such models to achieve\nremarkable zero-shot capabilities on new tasks, and no human-written\ninstructions are needed. In this paper, we present the first attempt to use\nGPT-4 to generate instruction-following data for LLM finetuning. Our early\nexperiments on instruction-tuned LLaMA models show that the 52K English and\nChinese instruction-following data generated by GPT-4 leads to superior\nzero-shot performance on new tasks to the instruction-following data generated\nby previous state-of-the-art models. We also collect feedback and comparison\ndata from GPT-4 to enable a comprehensive evaluation and reward model training.\nWe make our data generated using GPT-4 as well as our codebase publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2304.03277"
            },
            {
                "文章ID": "66852",
                "标题": "GPT-4 Technical Report",
                "作者": "Rai   OpenAI, Rai   :, Rai  Josh Achiam, Rai  Steven Adler, Rai  Sandhini Agarwal, Rai  Lama Ahmad, Rai  Ilge Akkaya, Rai  Florencia Leoni Aleman, Rai  Diogo Almeida, Rai  Janko Altenschmidt, Rai  Sam Altman, Rai  Shyamal Anadkat, Rai  Red Avila, Rai  Igor Babuschkin, Rai  Suchir Balaji, Rai  Valerie Balcom, Rai  Paul Baltescu, Rai  Haiming Bao, Rai  Mo Bavarian, Rai  Jeff Belgum, Rai  Irwan Bello, Rai  Jake Berdine, Rai  Gabriel Bernadett-Shapiro, Rai  Christopher Berner, Rai  Lenny Bogdonoff, Rai  Oleg Boiko, Rai  Madelaine Boyd, Rai  Anna-Luisa Brakman, Rai  Greg Brockman, Rai  Tim Brooks, Rai  Miles Brundage, Rai  Kevin Button, Rai  Trevor Cai, Rai  Rosie Campbell, Rai  Andrew Cann, Rai  Brittany Carey, Rai  Chelsea Carlson, Rai  Rory Carmichael, Rai  Brooke Chan, Rai  Che Chang, Rai  Fotis Chantzis, Rai  Derek Chen, Rai  Sully Chen, Rai  Ruby Chen, Rai  Jason Chen, Rai  Mark Chen, Rai  Ben Chess, Rai  Chester Cho, Rai  Casey Chu, Rai  Hyung Won Chung, Rai  Dave Cummings, Rai  Jeremiah Currier, Rai  Yunxing Dai, Rai  Cory Decareaux, Rai  Thomas Degry, Rai  Noah Deutsch, Rai  Damien Deville, Rai  Arka Dhar, Rai  David Dohan, Rai  Steve Dowling, Rai  Sheila Dunning, Rai  Adrien Ecoffet, Rai  Atty Eleti, Rai  Tyna Eloundou, Rai  David Farhi, Rai  Liam Fedus, Rai  Niko Felix, Rai  Simón Posada Fishman, Rai  Juston Forte, Rai  Isabella Fulford, Rai  Leo Gao, Rai  Elie Georges, Rai  Christian Gibson, Rai  Vik Goel, Rai  Tarun Gogineni, Rai  Gabriel Goh, Rai  Rapha Gontijo-Lopes, Rai  Jonathan Gordon, Rai  Morgan Grafstein, Rai  Scott Gray, Rai  Ryan Greene, Rai  Joshua Gross, Rai  Shixiang Shane Gu, Rai  Yufei Guo, Rai  Chris Hallacy, Rai  Jesse Han, Rai  Jeff Harris, Rai  Yuchen He, Rai  Mike Heaton, Rai  Johannes Heidecke, Rai  Chris Hesse, Rai  Alan Hickey, Rai  Wade Hickey, Rai  Peter Hoeschele, Rai  Brandon Houghton, Rai  Kenny Hsu, Rai  Shengli Hu, Rai  Xin Hu, Rai  Joost Huizinga, Rai  Shantanu Jain, Rai  Shawn Jain, Rai  Joanne Jang, Rai  Angela Jiang, Rai  Roger Jiang, Rai  Haozhun Jin, Rai  Denny Jin, Rai  Shino Jomoto, Rai  Billie Jonn, Rai  Heewoo Jun, Rai  Tomer Kaftan, Rai  Łukasz Kaiser, Rai  Ali Kamali, Rai  Ingmar Kanitscheider, Rai  Nitish Shirish Keskar, Rai  Tabarak Khan, Rai  Logan Kilpatrick, Rai  Jong Wook Kim, Rai  Christina Kim, Rai  Yongjik Kim, Rai  Hendrik Kirchner, Rai  Jamie Kiros, Rai  Matt Knight, Rai  Daniel Kokotajlo, Rai  Łukasz Kondraciuk, Rai  Andrew Kondrich, Rai  Aris Konstantinidis, Rai  Kyle Kosic, Rai  Gretchen Krueger, Rai  Vishal Kuo, Rai  Michael Lampe, Rai  Ikai Lan, Rai  Teddy Lee, Rai  Jan Leike, Rai  Jade Leung, Rai  Daniel Levy, Rai  Chak Ming Li, Rai  Rachel Lim, Rai  Molly Lin, Rai  Stephanie Lin, Rai  Mateusz Litwin, Rai  Theresa Lopez, Rai  Ryan Lowe, Rai  Patricia Lue, Rai  Anna Makanju, Rai  Kim Malfacini, Rai  Sam Manning, Rai  Todor Markov, Rai  Yaniv Markovski, Rai  Bianca Martin, Rai  Katie Mayer, Rai  Andrew Mayne, Rai  Bob McGrew, Rai  Scott Mayer McKinney, Rai  Christine McLeavey, Rai  Paul McMillan, Rai  Jake McNeil, Rai  David Medina, Rai  Aalok Mehta, Rai  Jacob Menick, Rai  Luke Metz, Rai  Andrey Mishchenko, Rai  Pamela Mishkin, Rai  Vinnie Monaco, Rai  Evan Morikawa, Rai  Daniel Mossing, Rai  Tong Mu, Rai  Mira Murati, Rai  Oleg Murk, Rai  David Mély, Rai  Ashvin Nair, Rai  Reiichiro Nakano, Rai  Rajeev Nayak, Rai  Arvind Neelakantan, Rai  Richard Ngo, Rai  Hyeonwoo Noh, Rai  Long Ouyang, Rai  Cullen O'Keefe, Rai  Jakub Pachocki, Rai  Alex Paino, Rai  Joe Palermo, Rai  Ashley Pantuliano, Rai  Giambattista Parascandolo, Rai  Joel Parish, Rai  Emy Parparita, Rai  Alex Passos, Rai  Mikhail Pavlov, Rai  Andrew Peng, Rai  Adam Perelman, Rai  Filipe de Avila Belbute Peres, Rai  Michael Petrov, Rai  Henrique Ponde de Oliveira Pinto, Rai   Michael,   Pokorny,  Michelle Pokrass,  Vitchyr Pong,  Tolly Powell,  Alethea Power,  Boris Power,  Elizabeth Proehl,  Raul Puri,  Alec Radford,  Jack Rae,  Aditya Ramesh,  Cameron Raymond,  Francis Real,  Kendra Rimbach,  Carl Ross,  Bob Rotsted,  Henri Roussez,  Nick Ryder,  Mario Saltarelli,  Ted Sanders,  Shibani Santurkar,  Girish Sastry,  Heather Schmidt,  David Schnurr,  John Schulman,  Daniel Selsam,  Kyla Sheppard,  Toki Sherbakov,  Jessica Shieh,  Sarah Shoker,  Pranav Shyam,  Szymon Sidor,  Eric Sigler,  Maddie Simens,  Jordan Sitkin,  Katarina Slama,  Ian Sohl,  Benjamin Sokolowsky,  Yang Song,  Natalie Staudacher,  Felipe Petroski Such,  Natalie Summers,  Ilya Sutskever,  Jie Tang,  Nikolas Tezak,  Madeleine Thompson,  Phil Tillet,  Amin Tootoonchian,  Elizabeth Tseng,  Preston Tuggle,  Nick Turley,  Jerry Tworek,  Juan Felipe Cerón Uribe,  Andrea Vallone,  Arun Vijayvergiya,  Chelsea Voss,  Carroll Wainwright,  Justin Jay Wang,  Alvin Wang,  Ben Wang,  Jonathan Ward,  Jason Wei,  CJ Weinmann,  Akila Welihinda,  Peter Welinder,  Jiayi Weng,  Lilian Weng,  Matt Wiethoff,  Dave Willner,  Clemens Winter,  Samuel Wolrich,  Hannah Wong,  Lauren Workman,  Sherwin Wu,  Jeff Wu,  Michael Wu,  Kai Xiao,  Tao Xu,  Sarah Yoo,  Kevin Yu,  Qiming Yuan,  Wojciech Zaremba,  Rowan Zellers,  Chong Zhang,  Marvin Zhang,  Shengjia Zhao,  Tianhao Zheng,  Juntang Zhuang,  William Zhuk,  Barret Zoph",
                "发布日期": "2023-12-20",
                "摘要": "  We report the development of GPT-4, a large-scale, multimodal model which can\naccept image and text inputs and produce text outputs. While less capable than\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance on\nvarious professional and academic benchmarks, including passing a simulated bar\nexam with a score around the top 10% of test takers. GPT-4 is a\nTransformer-based model pre-trained to predict the next token in a document.\nThe post-training alignment process results in improved performance on measures\nof factuality and adherence to desired behavior. A core component of this\nproject was developing infrastructure and optimization methods that behave\npredictably across a wide range of scales. This allowed us to accurately\npredict some aspects of GPT-4's performance based on models trained with no\nmore than 1/1,000th the compute of GPT-4.\n",
                "链接": "https://arxiv.org/abs/2303.08774"
            },
            {
                "文章ID": "74335",
                "标题": "AI-assisted coding: Experiments with GPT-4",
                "作者": " Russell A Poldrack,  Thomas Lu,  Gašper Beguš",
                "发布日期": "2023-04-27",
                "摘要": "  Artificial intelligence (AI) tools based on large language models have\nacheived human-level performance on some computer programming tasks. We report\nseveral experiments using GPT-4 to generate computer code. These experiments\ndemonstrate that AI code generation using the current generation of tools,\nwhile powerful, requires substantial human validation to ensure accurate\nperformance. We also demonstrate that GPT-4 refactoring of existing code can\nsignificantly improve that code along several established metrics for code\nquality, and we show that GPT-4 can generate tests with substantial coverage,\nbut that many of the tests fail when applied to the associated code. These\nfindings suggest that while AI coding tools are very powerful, they still\nrequire humans in the loop to ensure validity and accuracy of the results.\n",
                "链接": "https://arxiv.org/abs/2304.13187"
            },
            {
                "文章ID": "105803",
                "标题": "Graph Neural Architecture Search with GPT-4",
                "作者": " Haishuai Wang,  Yang Gao,  Xin Zheng,  Peng Zhang,  Hongyang Chen,  Jiajun Bu",
                "发布日期": "2023-10-04",
                "摘要": "  Graph Neural Architecture Search (GNAS) has shown promising results in\nautomatically designing graph neural networks. However, GNAS still requires\nintensive human labor with rich domain knowledge to design the search space and\nsearch strategy. In this paper, we integrate GPT-4 into GNAS and propose a new\nGPT-4 based Graph Neural Architecture Search method (GPT4GNAS for short). The\nbasic idea of our method is to design a new class of prompts for GPT-4 to guide\nGPT-4 toward the generative task of graph neural architectures. The prompts\nconsist of descriptions of the search space, search strategy, and search\nfeedback of GNAS. By iteratively running GPT-4 with the prompts, GPT4GNAS\ngenerates more accurate graph neural networks with fast convergence.\nExperimental results show that embedding GPT-4 into GNAS outperforms the\nstate-of-the-art GNAS methods.\n",
                "链接": "https://arxiv.org/abs/2310.01436"
            },
            {
                "文章ID": "80256",
                "标题": "Leveraging GPT-4 for Automatic Translation Post-Editing",
                "作者": " Vikas Raunak,  Amr Sharaf,  Yiren Wang,  Hany Hassan Awadallah,  Arul Menezes",
                "发布日期": "2023-10-25",
                "摘要": "  While Neural Machine Translation (NMT) represents the leading approach to\nMachine Translation (MT), the outputs of NMT models still require translation\npost-editing to rectify errors and enhance quality under critical settings. In\nthis work, we formalize the task of direct translation post-editing with Large\nLanguage Models (LLMs) and explore the use of GPT-4 to automatically post-edit\nNMT outputs across several language pairs. Our results demonstrate that GPT-4\nis adept at translation post-editing, producing meaningful and trustworthy\nedits to translations that help improve its general quality as well as remove\ndifferent classes of major errors in translations. In particular, human\nevaluations on assessing edit trustworthiness show that GPT-4 exhibits a large\nimprovement over the prior state-of-the-art LLM. Notably, we improve upon\nstate-of-the-art performance on WMT-22 English-Chinese, English-German,\nChinese-English and German-English language pairs using GPT-4 based\npost-editing, as evaluated by state-of-the-art MT quality metrics. However, we\nalso show that GPT-4 could produce hallucinated edits, thereby urging caution\nin its use as an expert translation post-editor.\n",
                "链接": "https://arxiv.org/abs/2305.14878"
            },
            {
                "文章ID": "68829",
                "标题": "Analyzing the Performance of GPT-3.5 and GPT-4 in Grammatical Error\n  Correction",
                "作者": " Steven Coyne,  Keisuke Sakaguchi,  Diana Galvan-Sosa,  Michael Zock,  Kentaro Inui",
                "发布日期": "2023-05-31",
                "摘要": "  GPT-3 and GPT-4 models are powerful, achieving high performance on a variety\nof Natural Language Processing tasks. However, there is a relative lack of\ndetailed published analysis of their performance on the task of grammatical\nerror correction (GEC). To address this, we perform experiments testing the\ncapabilities of a GPT-3.5 model (text-davinci-003) and a GPT-4 model\n(gpt-4-0314) on major GEC benchmarks. We compare the performance of different\nprompts in both zero-shot and few-shot settings, analyzing intriguing or\nproblematic outputs encountered with different prompt formats. We report the\nperformance of our best prompt on the BEA-2019 and JFLEG datasets, finding that\nthe GPT models can perform well in a sentence-level revision setting, with\nGPT-4 achieving a new high score on the JFLEG benchmark. Through human\nevaluation experiments, we compare the GPT models' corrections to source, human\nreference, and baseline GEC system sentences and observe differences in editing\nstrategies and how they are scored by human raters.\n",
                "链接": "https://arxiv.org/abs/2303.14342"
            },
            {
                "文章ID": "110350",
                "标题": "Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large\n  Language Models on Sequence to Sequence Tasks",
                "作者": " Andrea Sottana,  Bin Liang,  Kai Zou,  Zheng Yuan",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) evaluation is a patchy and inconsistent\nlandscape, and it is becoming clear that the quality of automatic evaluation\nmetrics is not keeping up with the pace of development of generative models. We\naim to improve the understanding of current models' performance by providing a\npreliminary and hybrid evaluation on a range of open and closed-source\ngenerative LLMs on three NLP benchmarks: text summarisation, text\nsimplification and grammatical error correction (GEC), using both automatic and\nhuman evaluation. We also explore the potential of the recently released GPT-4\nto act as an evaluator. We find that ChatGPT consistently outperforms many\nother popular models according to human reviewers on the majority of metrics,\nwhile scoring much more poorly when using classic automatic evaluation metrics.\nWe also find that human reviewers rate the gold reference as much worse than\nthe best models' outputs, indicating the poor quality of many popular\nbenchmarks. Finally, we find that GPT-4 is capable of ranking models' outputs\nin a way which aligns reasonably closely to human judgement despite\ntask-specific variations, with a lower alignment in the GEC task.\n",
                "链接": "https://arxiv.org/abs/2310.13800"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用GPT4v完成多模态智能体的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "120902",
                "标题": "GPT-4V with Emotion: A Zero-shot Benchmark for Multimodal Emotion\n  Understanding",
                "作者": " Zheng Lian,  Licai Sun,  Haiyang Sun,  Kang Chen,  Zhuofan Wen,  Hao Gu,  Shun Chen,  Bin Liu,  Jianhua Tao",
                "发布日期": "2023-12-08",
                "摘要": "  Recently, GPT-4 with Vision (GPT-4V) has shown remarkable performance across\nvarious multimodal tasks. However, its efficacy in emotion recognition remains\na question. This paper quantitatively evaluates GPT-4V's capabilities in\nmultimodal emotion understanding, encompassing tasks such as facial emotion\nrecognition, visual sentiment analysis, micro-expression recognition, dynamic\nfacial emotion recognition, and multimodal emotion recognition. Our experiments\nshow that GPT-4V exhibits impressive multimodal and temporal understanding\ncapabilities, even surpassing supervised systems in some tasks. Despite these\nachievements, GPT-4V is currently tailored for general domains. It performs\npoorly in micro-expression recognition that requires specialized expertise. The\nmain purpose of this paper is to present quantitative results of GPT-4V on\nemotion understanding and establish a zero-shot benchmark for future research.\nCode and evaluation results are available at:\nhttps://github.com/zeroQiaoba/gpt4v-emotion.\n",
                "链接": "https://arxiv.org/abs/2312.04293"
            },
            {
                "文章ID": "105257",
                "标题": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
                "作者": " Zhengyuan Yang,  Linjie Li,  Kevin Lin,  Jianfeng Wang,  Chung-Ching Lin,  Zicheng Liu,  Lijuan Wang",
                "发布日期": "2023-10-12",
                "摘要": "  Large multimodal models (LMMs) extend large language models (LLMs) with\nmulti-sensory skills, such as visual understanding, to achieve stronger generic\nintelligence. In this paper, we analyze the latest model, GPT-4V(ision), to\ndeepen the understanding of LMMs. The analysis focuses on the intriguing tasks\nthat GPT-4V can perform, containing test samples to probe the quality and\ngenericity of GPT-4V's capabilities, its supported inputs and working modes,\nand the effective ways to prompt the model. In our approach to exploring\nGPT-4V, we curate and organize a collection of carefully designed qualitative\nsamples spanning a variety of domains and tasks. Observations from these\nsamples demonstrate that GPT-4V's unprecedented ability in processing\narbitrarily interleaved multimodal inputs and the genericity of its\ncapabilities together make GPT-4V a powerful multimodal generalist system.\nFurthermore, GPT-4V's unique capability of understanding visual markers drawn\non input images can give rise to new human-computer interaction methods such as\nvisual referring prompting. We conclude the report with in-depth discussions on\nthe emerging application scenarios and the future research directions for\nGPT-4V-based systems. We hope that this preliminary exploration will inspire\nfuture research on the next-generation multimodal task formulation, new ways to\nexploit and enhance LMMs to solve real-world problems, and gaining better\nunderstanding of multimodal foundation models. Finally, we acknowledge that the\nmodel under our study is solely the product of OpenAI's innovative work, and\nthey should be fully credited for its development. Please see the GPT-4V\ncontributions paper for the authorship and credit attribution:\nhttps://cdn.openai.com/contributions/gpt-4v.pdf\n",
                "链接": "https://arxiv.org/abs/2309.17421"
            },
            {
                "文章ID": "115400",
                "标题": "GPT-4V(ision) as A Social Media Analysis Engine",
                "作者": " Hanjia Lyu,  Jinfa Huang,  Daoan Zhang,  Yongsheng Yu,  Xinyi Mou,  Jinsheng Pan,  Zhengyuan Yang,  Zhongyu Wei,  Jiebo Luo",
                "发布日期": "2023-11-14",
                "摘要": "  Recent research has offered insights into the extraordinary capabilities of\nLarge Multimodal Models (LMMs) in various general vision and language tasks.\nThere is growing interest in how LMMs perform in more specialized domains.\nSocial media content, inherently multimodal, blends text, images, videos, and\nsometimes audio. Understanding social multimedia content remains a challenging\nproblem for contemporary machine learning frameworks. In this paper, we explore\nGPT-4V(ision)'s capabilities for social multimedia analysis. We select five\nrepresentative tasks, including sentiment analysis, hate speech detection, fake\nnews identification, demographic inference, and political ideology detection,\nto evaluate GPT-4V. Our investigation begins with a preliminary quantitative\nanalysis for each task using existing benchmark datasets, followed by a careful\nreview of the results and a selection of qualitative samples that illustrate\nGPT-4V's potential in understanding multimodal social media content. GPT-4V\ndemonstrates remarkable efficacy in these tasks, showcasing strengths such as\njoint understanding of image-text pairs, contextual and cultural awareness, and\nextensive commonsense knowledge. Despite the overall impressive capacity of\nGPT-4V in the social media domain, there remain notable challenges. GPT-4V\nstruggles with tasks involving multilingual social multimedia comprehension and\nhas difficulties in generalizing to the latest trends in social media.\nAdditionally, it exhibits a tendency to generate erroneous information in the\ncontext of evolving celebrity and politician knowledge, reflecting the known\nhallucination problem. The insights gleaned from our findings underscore a\npromising future for LMMs in enhancing our comprehension of social media\ncontent and its users through the analysis of multimodal information.\n",
                "链接": "https://arxiv.org/abs/2311.07547"
            },
            {
                "文章ID": "121231",
                "标题": "Holistic Evaluation of GPT-4V for Biomedical Imaging",
                "作者": " Zhengliang Liu,  Hanqi Jiang,  Tianyang Zhong,  Zihao Wu,  Chong Ma,  Yiwei Li,  Xiaowei Yu,  Yutong Zhang,  Yi Pan,  Peng Shu,  Yanjun Lyu,  Lu Zhang,  Junjie Yao,  Peixin Dong,  Chao Cao,  Zhenxiang Xiao,  Jiaqi Wang,  Huan Zhao,  Shaochen Xu,  Yaonai Wei,  Jingyuan Chen,  Haixing Dai,  Peilong Wang,  Hao He,  Zewei Wang,  Xinyu Wang,  Xu Zhang,  Lin Zhao,  Yiheng Liu,  Kai Zhang,  Liheng Yan,  Lichao Sun,  Jun Liu,  Ning Qiang,  Bao Ge,  Xiaoyan Cai,  Shijie Zhao,  Xintao Hu,  Yixuan Yuan,  Gang Li,  Shu Zhang,  Xin Zhang,  Xi Jiang,  Tuo Zhang,  Dinggang Shen,  Quanzheng Li,  Wei Liu,  Xiang Li,  Dajiang Zhu,  Tianming Liu",
                "发布日期": "2023-12-12",
                "摘要": "  In this paper, we present a large-scale evaluation probing GPT-4V's\ncapabilities and limitations for biomedical image analysis. GPT-4V represents a\nbreakthrough in artificial general intelligence (AGI) for computer vision, with\napplications in the biomedical domain. We assess GPT-4V's performance across 16\nmedical imaging categories, including radiology, oncology, ophthalmology,\npathology, and more. Tasks include modality recognition, anatomy localization,\ndisease diagnosis, report generation, and lesion detection. The extensive\nexperiments provide insights into GPT-4V's strengths and weaknesses. Results\nshow GPT-4V's proficiency in modality and anatomy recognition but difficulty\nwith disease diagnosis and localization. GPT-4V excels at diagnostic report\ngeneration, indicating strong image captioning skills. While promising for\nbiomedical imaging AI, GPT-4V requires further enhancement and validation\nbefore clinical deployment. We emphasize responsible development and testing\nfor trustworthy integration of biomedical AGI. This rigorous evaluation of\nGPT-4V on diverse medical images advances understanding of multimodal large\nlanguage models (LLMs) and guides future work toward impactful healthcare\napplications.\n",
                "链接": "https://arxiv.org/abs/2312.05256"
            },
            {
                "文章ID": "106097",
                "标题": "MathVista: Evaluating Math Reasoning in Visual Contexts with GPT-4V,\n  Bard, and Other Large Multimodal Models",
                "作者": " Pan Lu,  Hritik Bansal,  Tony Xia,  Jiacheng Liu,  Chunyuan Li,  Hannaneh Hajishirzi,  Hao Cheng,  Kai-Wei Chang,  Michel Galley,  Jianfeng Gao",
                "发布日期": "2023-10-27",
                "摘要": "  Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit\nimpressive problem-solving skills in many tasks and domains, but their ability\nin mathematical reasoning in visual contexts has not been systematically\nstudied. To bridge this gap, we present MathVista, a benchmark designed to\ncombine challenges from diverse mathematical and visual tasks. It consists of\n6,141 examples, derived from 28 existing multimodal datasets involving\nmathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and\nPaperQA). Completing these tasks requires fine-grained, deep visual\nunderstanding and compositional reasoning, which all state-of-the-art\nfoundation models find challenging. With MathVista, we have conducted a\ncomprehensive, quantitative evaluation of 12 prominent foundation models. The\nbest-performing GPT-4V model achieves an overall accuracy of 49.9%,\nsubstantially outperforming Bard, the second-best performer, by 15.1%. Our\nin-depth analysis reveals that the superiority of GPT-4V is mainly attributed\nto its enhanced visual perception and mathematical reasoning. However, GPT-4V\nstill falls short of human performance by 10.4%, as it often struggles to\nunderstand complex figures and perform rigorous reasoning. This significant gap\nunderscores the critical role that MathVista will play in the development of\ngeneral-purpose AI agents capable of tackling mathematically intensive and\nvisually rich real-world tasks. We further explore the new ability of\nself-verification, the application of self-consistency, and the interactive\nchatbot capabilities of GPT-4V, highlighting its promising potential for future\nresearch. The project is available at https://mathvista.github.io/.\n",
                "链接": "https://arxiv.org/abs/2310.02255"
            },
            {
                "文章ID": "113829",
                "标题": "Exploring Grounding Potential of VQA-oriented GPT-4V for Zero-shot\n  Anomaly Detection",
                "作者": " Jiangning Zhang,  Xuhai Chen,  Zhucun Xue,  Yabiao Wang,  Chengjie Wang,  Yong Liu",
                "发布日期": "2023-11-07",
                "摘要": "  Large Multimodal Model (LMM) GPT-4V(ision) endows GPT-4 with visual grounding\ncapabilities, making it possible to handle certain tasks through the Visual\nQuestion Answering (VQA) paradigm. This paper explores the potential of\nVQA-oriented GPT-4V in the recently popular visual Anomaly Detection (AD) and\nis the first to conduct qualitative and quantitative evaluations on the popular\nMVTec AD and VisA datasets. Considering that this task requires both\nimage-/pixel-level evaluations, the proposed GPT-4V-AD framework contains three\ncomponents: 1) Granular Region Division, 2) Prompt Designing, 3)\nText2Segmentation for easy quantitative evaluation, and have made some\ndifferent attempts for comparative analysis. The results show that GPT-4V can\nachieve certain results in the zero-shot AD task through a VQA paradigm, such\nas achieving image-level 77.1/88.0 and pixel-level 68.0/76.6 AU-ROCs on MVTec\nAD and VisA datasets, respectively. However, its performance still has a\ncertain gap compared to the state-of-the-art zero-shot method, e.g., WinCLIP\nann CLIP-AD, and further research is needed. This study provides a baseline\nreference for the research of VQA-oriented LMM in the zero-shot AD task, and we\nalso post several possible future works. Code is available at\n\\url{https://github.com/zhangzjn/GPT-4V-AD}.\n",
                "链接": "https://arxiv.org/abs/2311.02612"
            },
            {
                "文章ID": "114344",
                "标题": "Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary\n  Case Study",
                "作者": " Peilin Zhou,  Meng Cao,  You-Liang Huang,  Qichen Ye,  Peiyan Zhang,  Junling Liu,  Yueqi Xie,  Yining Hua,  Jaeboum Kim",
                "发布日期": "2023-11-08",
                "摘要": "  Large Multimodal Models (LMMs) have demonstrated impressive performance\nacross various vision and language tasks, yet their potential applications in\nrecommendation tasks with visual assistance remain unexplored. To bridge this\ngap, we present a preliminary case study investigating the recommendation\ncapabilities of GPT-4V(ison), a recently released LMM by OpenAI. We construct a\nseries of qualitative test samples spanning multiple domains and employ these\nsamples to assess the quality of GPT-4V's responses within recommendation\nscenarios. Evaluation results on these test samples prove that GPT-4V has\nremarkable zero-shot recommendation abilities across diverse domains, thanks to\nits robust visual-text comprehension capabilities and extensive general\nknowledge. However, we have also identified some limitations in using GPT-4V\nfor recommendations, including a tendency to provide similar responses when\ngiven similar inputs. This report concludes with an in-depth discussion of the\nchallenges and research opportunities associated with utilizing GPT-4V in\nrecommendation scenarios. Our objective is to explore the potential of\nextending LMMs from vision and language tasks to recommendation tasks. We hope\nto inspire further research into next-generation multimodal generative\nrecommendation models, which can enhance user experiences by offering greater\ndiversity and interactivity. All images and prompts used in this report will be\naccessible at https://github.com/PALIN2018/Evaluate_GPT-4V_Rec.\n",
                "链接": "https://arxiv.org/abs/2311.04199"
            },
            {
                "文章ID": "111490",
                "标题": "Exploring OCR Capabilities of GPT-4V(ision) : A Quantitative and\n  In-depth Evaluation",
                "作者": " Yongxin Shi,  Dezhi Peng,  Wenhui Liao,  Zening Lin,  Xinhong Chen,  Chongyu Liu,  Yuyi Zhang,  Lianwen Jin",
                "发布日期": "2023-10-31",
                "摘要": "  This paper presents a comprehensive evaluation of the Optical Character\nRecognition (OCR) capabilities of the recently released GPT-4V(ision), a Large\nMultimodal Model (LMM). We assess the model's performance across a range of OCR\ntasks, including scene text recognition, handwritten text recognition,\nhandwritten mathematical expression recognition, table structure recognition,\nand information extraction from visually-rich document. The evaluation reveals\nthat GPT-4V performs well in recognizing and understanding Latin contents, but\nstruggles with multilingual scenarios and complex tasks. Specifically, it\nshowed limitations when dealing with non-Latin languages and complex tasks such\nas handwriting mathematical expression recognition, table structure\nrecognition, and end-to-end semantic entity recognition and pair extraction\nfrom document image. Based on these observations, we affirm the necessity and\ncontinued research value of specialized OCR models. In general, despite its\nversatility in handling diverse OCR tasks, GPT-4V does not outperform existing\nstate-of-the-art OCR models. How to fully utilize pre-trained general-purpose\nLMMs such as GPT-4V for OCR downstream tasks remains an open problem. The study\noffers a critical reference for future research in OCR with LMMs. Evaluation\npipeline and results are available at\nhttps://github.com/SCUT-DLVCLab/GPT-4V_OCR.\n",
                "链接": "https://arxiv.org/abs/2310.16809"
            },
            {
                "文章ID": "109499",
                "标题": "Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V",
                "作者": " Jianwei Yang,  Hao Zhang,  Feng Li,  Xueyan Zou,  Chunyuan Li,  Jianfeng Gao",
                "发布日期": "2023-11-07",
                "摘要": "  We present Set-of-Mark (SoM), a new visual prompting method, to unleash the\nvisual grounding abilities of large multimodal models (LMMs), such as GPT-4V.\nAs illustrated in Fig. 1 (right), we employ off-the-shelf interactive\nsegmentation models, such as SEEM/SAM, to partition an image into regions at\ndifferent levels of granularity, and overlay these regions with a set of marks\ne.g., alphanumerics, masks, boxes. Using the marked image as input, GPT-4V can\nanswer the questions that require visual grounding. We perform a comprehensive\nempirical study to validate the effectiveness of SoM on a wide range of\nfine-grained vision and multimodal tasks. For example, our experiments show\nthat GPT-4V with SoM in zero-shot setting outperforms the state-of-the-art\nfully-finetuned referring expression comprehension and segmentation model on\nRefCOCOg. Code for SoM prompting is made public at:\nhttps://github.com/microsoft/SoM.\n",
                "链接": "https://arxiv.org/abs/2310.11441"
            },
            {
                "文章ID": "112337",
                "标题": "Multimodal ChatGPT for Medical Applications: an Experimental Study of\n  GPT-4V",
                "作者": " Zhiling Yan,  Kai Zhang,  Rong Zhou,  Lifang He,  Xiang Li,  Lichao Sun",
                "发布日期": "2023-10-31",
                "摘要": "  In this paper, we critically evaluate the capabilities of the\nstate-of-the-art multimodal large language model, i.e., GPT-4 with Vision\n(GPT-4V), on Visual Question Answering (VQA) task. Our experiments thoroughly\nassess GPT-4V's proficiency in answering questions paired with images using\nboth pathology and radiology datasets from 11 modalities (e.g. Microscopy,\nDermoscopy, X-ray, CT, etc.) and fifteen objects of interests (brain, liver,\nlung, etc.). Our datasets encompass a comprehensive range of medical inquiries,\nincluding sixteen distinct question types. Throughout our evaluations, we\ndevised textual prompts for GPT-4V, directing it to synergize visual and\ntextual information. The experiments with accuracy score conclude that the\ncurrent version of GPT-4V is not recommended for real-world diagnostics due to\nits unreliable and suboptimal accuracy in responding to diagnostic medical\nquestions. In addition, we delineate seven unique facets of GPT-4V's behavior\nin medical VQA, highlighting its constraints within this complex arena. The\ncomplete details of our evaluation cases are accessible at\nhttps://github.com/ZhilingYan/GPT4V-Medical-Report.\n",
                "链接": "https://arxiv.org/abs/2310.19061"
            }
        ]
    },
    {
        "question": {
            "question": "使用LLM进行蛋白质结构/功能/性质预测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "106475",
                "标题": "InstructProtein: Aligning Human and Protein Language via Knowledge\n  Instruction",
                "作者": " Zeyuan Wang,  Qiang Zhang,  Keyan Ding,  Ming Qin,  Xiang Zhuang,  Xiaotong Li,  Huajun Chen",
                "发布日期": "2023-10-06",
                "摘要": "  Large Language Models (LLMs) have revolutionized the field of natural\nlanguage processing, but they fall short in comprehending biological sequences\nsuch as proteins. To address this challenge, we propose InstructProtein, an\ninnovative LLM that possesses bidirectional generation capabilities in both\nhuman and protein languages: (i) taking a protein sequence as input to predict\nits textual function description and (ii) using natural language to prompt\nprotein sequence generation. To achieve this, we first pre-train an LLM on both\nprotein and natural language corpora, enabling it to comprehend individual\nlanguages. Then supervised instruction tuning is employed to facilitate the\nalignment of these two distinct languages. Herein, we introduce a knowledge\ngraph-based instruction generation framework to construct a high-quality\ninstruction dataset, addressing annotation imbalance and instruction deficits\nin existing protein-text corpus. In particular, the instructions inherit the\nstructural relations between proteins and function annotations in knowledge\ngraphs, which empowers our model to engage in the causal modeling of protein\nfunctions, akin to the chain-of-thought processes in natural languages.\nExtensive experiments on bidirectional protein-text generation tasks show that\nInstructProtein outperforms state-of-the-art LLMs by large margins. Moreover,\nInstructProtein serves as a pioneering step towards text-based protein function\nprediction and sequence design, effectively bridging the gap between protein\nand human language understanding.\n",
                "链接": "https://arxiv.org/abs/2310.03269"
            },
            {
                "文章ID": "93224",
                "标题": "Prot2Text: Multimodal Protein's Function Generation with GNNs and\n  Transformers",
                "作者": " Hadi Abdine,  Michail Chatzianastasis,  Costas Bouyioukos,  Michalis Vazirgiannis",
                "发布日期": "2023-12-22",
                "摘要": "  The complex nature of big biological systems pushed some scientists to\nclassify its understanding under the inconceivable missions. Different leveled\nchallenges complicated this task, one of is the prediction of a protein's\nfunction. In recent years, significant progress has been made in this field\nthrough the development of various machine learning approaches. However, most\nexisting methods formulate the task as a multi-classification problem, i.e\nassigning predefined labels to proteins. In this work, we propose a novel\napproach, \\textbf{Prot2Text}, which predicts a protein function's in a free\ntext style, moving beyond the conventional binary or categorical\nclassifications. By combining Graph Neural Networks(GNNs) and Large Language\nModels(LLMs), in an encoder-decoder framework, our model effectively integrates\ndiverse data types including proteins' sequences, structures, and textual\nannotations. This multimodal approach allows for a holistic representation of\nproteins' functions, enabling the generation of detailed and accurate\ndescriptions. To evaluate our model, we extracted a multimodal protein dataset\nfrom SwissProt, and demonstrate empirically the effectiveness of Prot2Text.\nThese results highlight the transformative impact of multimodal models,\nspecifically the fusion of GNNs and LLMs, empowering researchers with powerful\ntools for more accurate prediction of proteins' functions. The code, the models\nand a demo will be publicly released.\n",
                "链接": "https://arxiv.org/abs/2307.14367"
            },
            {
                "文章ID": "84482",
                "标题": "Multi-level Protein Representation Learning for Blind Mutational Effect\n  Prediction",
                "作者": " Yang Tan,  Bingxin Zhou,  Yuanhong Jiang,  Yu Guang Wang,  Liang Hong",
                "发布日期": "2023-06-09",
                "摘要": "  Directed evolution plays an indispensable role in protein engineering that\nrevises existing protein sequences to attain new or enhanced functions.\nAccurately predicting the effects of protein variants necessitates an in-depth\nunderstanding of protein structure and function. Although large self-supervised\nlanguage models have demonstrated remarkable performance in zero-shot inference\nusing only protein sequences, these models inherently do not interpret the\nspatial characteristics of protein structures, which are crucial for\ncomprehending protein folding stability and internal molecular interactions.\nThis paper introduces a novel pre-training framework that cascades sequential\nand geometric analyzers for protein primary and tertiary structures. It guides\nmutational directions toward desired traits by simulating natural selection on\nwild-type proteins and evaluates the effects of variants based on their fitness\nto perform the function. We assess the proposed approach using a public\ndatabase and two new databases for a variety of variant effect prediction\ntasks, which encompass a diverse set of proteins and assays from different\ntaxa. The prediction results achieve state-of-the-art performance over other\nzero-shot learning methods for both single-site mutations and deep mutations.\n",
                "链接": "https://arxiv.org/abs/2306.04899"
            },
            {
                "文章ID": "120437",
                "标题": "Protein Language Model-Powered 3D Ligand Binding Site Prediction from\n  Protein Sequence",
                "作者": " Shuo Zhang,  Lei Xie",
                "发布日期": "2023-12-07",
                "摘要": "  Prediction of ligand binding sites of proteins is a fundamental and important\ntask for understanding the function of proteins and screening potential drugs.\nMost existing methods require experimentally determined protein holo-structures\nas input. However, such structures can be unavailable on novel or less-studied\nproteins. To tackle this limitation, we propose LaMPSite, which only takes\nprotein sequences and ligand molecular graphs as input for ligand binding site\npredictions. The protein sequences are used to retrieve residue-level\nembeddings and contact maps from the pre-trained ESM-2 protein language model.\nThe ligand molecular graphs are fed into a graph neural network to compute\natom-level embeddings. Then we compute and update the protein-ligand\ninteraction embedding based on the protein residue-level embeddings and ligand\natom-level embeddings, and the geometric constraints in the inferred protein\ncontact map and ligand distance map. A final pooling on protein-ligand\ninteraction embedding would indicate which residues belong to the binding\nsites. Without any 3D coordinate information of proteins, our proposed model\nachieves competitive performance compared to baseline methods that require 3D\nprotein structures when predicting binding sites. Given that less than 50% of\nproteins have reliable structure information in the current stage, LaMPSite\nwill provide new opportunities for drug discovery.\n",
                "链接": "https://arxiv.org/abs/2312.03016"
            },
            {
                "文章ID": "60833",
                "标题": "A Text-guided Protein Design Framework",
                "作者": " Shengchao Liu,  Yanjing Li,  Zhuoxinran Li,  Anthony Gitter,  Yutao Zhu,  Jiarui Lu,  Zhao Xu,  Weili Nie,  Arvind Ramanathan,  Chaowei Xiao,  Jian Tang,  Hongyu Guo,  Anima Anandkumar",
                "发布日期": "2023-12-05",
                "摘要": "  Current AI-assisted protein design mainly utilizes protein sequential and\nstructural information. Meanwhile, there exists tremendous knowledge curated by\nhumans in the text format describing proteins' high-level functionalities. Yet,\nwhether the incorporation of such text data can help protein design tasks has\nnot been explored. To bridge this gap, we propose ProteinDT, a multi-modal\nframework that leverages textual descriptions for protein design. ProteinDT\nconsists of three subsequent steps: ProteinCLAP which aligns the representation\nof two modalities, a facilitator that generates the protein representation from\nthe text modality, and a decoder that creates the protein sequences from the\nrepresentation. To train ProteinDT, we construct a large dataset,\nSwissProtCLAP, with 441K text and protein pairs. We quantitatively verify the\neffectiveness of ProteinDT on three challenging tasks: (1) over 90\\% accuracy\nfor text-guided protein generation; (2) best hit ratio on 10 zero-shot\ntext-guided protein editing tasks; (3) superior performance on four out of six\nprotein property prediction benchmarks.\n",
                "链接": "https://arxiv.org/abs/2302.04611"
            },
            {
                "文章ID": "58852",
                "标题": "Generating Novel, Designable, and Diverse Protein Structures by\n  Equivariantly Diffusing Oriented Residue Clouds",
                "作者": " Yeqing Lin,  Mohammed AlQuraishi",
                "发布日期": "2023-06-08",
                "摘要": "  Proteins power a vast array of functional processes in living cells. The\ncapability to create new proteins with designed structures and functions would\nthus enable the engineering of cellular behavior and development of\nprotein-based therapeutics and materials. Structure-based protein design aims\nto find structures that are designable (can be realized by a protein sequence),\nnovel (have dissimilar geometry from natural proteins), and diverse (span a\nwide range of geometries). While advances in protein structure prediction have\nmade it possible to predict structures of novel protein sequences, the\ncombinatorially large space of sequences and structures limits the practicality\nof search-based methods. Generative models provide a compelling alternative, by\nimplicitly learning the low-dimensional structure of complex data\ndistributions. Here, we leverage recent advances in denoising diffusion\nprobabilistic models and equivariant neural networks to develop Genie, a\ngenerative model of protein structures that performs discrete-time diffusion\nusing a cloud of oriented reference frames in 3D space. Through in silico\nevaluations, we demonstrate that Genie generates protein backbones that are\nmore designable, novel, and diverse than existing models. This indicates that\nGenie is capturing key aspects of the distribution of protein structure space\nand facilitates protein design with high success rates. Code for generating new\nproteins and training new versions of Genie is available at\nhttps://github.com/aqlaboratory/genie.\n",
                "链接": "https://arxiv.org/abs/2301.12485"
            },
            {
                "文章ID": "63348",
                "标题": "Retrieved Sequence Augmentation for Protein Representation Learning",
                "作者": " Chang Ma,  Haiteng Zhao,  Lin Zheng,  Jiayi Xin,  Qintong Li,  Lijun Wu,  Zhihong Deng,  Yang Lu,  Qi Liu,  Lingpeng Kong",
                "发布日期": "2023-02-27",
                "摘要": "  Protein language models have excelled in a variety of tasks, ranging from\nstructure prediction to protein engineering. However, proteins are highly\ndiverse in functions and structures, and current state-of-the-art models\nincluding the latest version of AlphaFold rely on Multiple Sequence Alignments\n(MSA) to feed in the evolutionary knowledge. Despite their success, heavy\ncomputational overheads, as well as the de novo and orphan proteins remain\ngreat challenges in protein representation learning. In this work, we show that\nMSAaugmented models inherently belong to retrievalaugmented methods. Motivated\nby this finding, we introduce Retrieved Sequence Augmentation(RSA) for protein\nrepresentation learning without additional alignment or pre-processing. RSA\nlinks query protein sequences to a set of sequences with similar structures or\nproperties in the database and combines these sequences for downstream\nprediction. We show that protein language models benefit from the retrieval\nenhancement on both structure prediction and property prediction tasks, with a\n5% improvement on MSA Transformer on average while being 373 times faster. In\naddition, we show that our model can transfer to new protein domains better and\noutperforms MSA Transformer on de novo protein prediction. Our study fills a\nmuch-encountered gap in protein prediction and brings us a step closer to\ndemystifying the domain knowledge needed to understand protein sequences. Code\nis available on https://github.com/HKUNLP/RSA.\n",
                "链接": "https://arxiv.org/abs/2302.12563"
            },
            {
                "文章ID": "106818",
                "标题": "Functional Geometry Guided Protein Sequence and Backbone Structure\n  Co-Design",
                "作者": " Zhenqiao Song,  Yunlong Zhao,  Wenxian Shi,  Yang Yang,  Lei Li",
                "发布日期": "2023-10-10",
                "摘要": "  Proteins are macromolecules responsible for essential functions in almost all\nliving organisms. Designing reasonable proteins with desired functions is\ncrucial. A protein's sequence and structure are strongly correlated and they\ntogether determine its function. In this paper, we propose NAEPro, a model to\njointly design Protein sequence and structure based on automatically detected\nfunctional sites. NAEPro is powered by an interleaving network of attention and\nequivariant layers, which can capture global correlation in a whole sequence\nand local influence from nearest amino acids in three dimensional (3D) space.\nSuch an architecture facilitates effective yet economic message passing at two\nlevels. We evaluate our model and several strong baselines on two protein\ndatasets, $\\beta$-lactamase and myoglobin. Experimental results show that our\nmodel consistently achieves the highest amino acid recovery rate, TM-score, and\nthe lowest RMSD among all competitors. These findings prove the capability of\nour model to design protein sequences and structures that closely resemble\ntheir natural counterparts. Furthermore, in-depth analysis further confirms our\nmodel's ability to generate highly effective proteins capable of binding to\ntheir target metallocofactors. We provide code, data and models in Github.\n",
                "链接": "https://arxiv.org/abs/2310.04343"
            },
            {
                "文章ID": "106701",
                "标题": "CrysFormer: Protein Structure Prediction via 3d Patterson Maps and\n  Partial Structure Attention",
                "作者": " Chen Dun,  Qiutai Pan,  Shikai Jin,  Ria Stevens,  Mitchell D. Miller, Jr. George N. Phillips,,  Anastasios Kyrillidis",
                "发布日期": "2023-10-09",
                "摘要": "  Determining the structure of a protein has been a decades-long open question.\nA protein's three-dimensional structure often poses nontrivial computation\ncosts, when classical simulation algorithms are utilized. Advances in the\ntransformer neural network architecture -- such as AlphaFold2 -- achieve\nsignificant improvements for this problem, by learning from a large dataset of\nsequence information and corresponding protein structures. Yet, such methods\nonly focus on sequence information; other available prior knowledge, such as\nprotein crystallography and partial structure of amino acids, could be\npotentially utilized. To the best of our knowledge, we propose the first\ntransformer-based model that directly utilizes protein crystallography and\npartial structure information to predict the electron density maps of proteins.\nVia two new datasets of peptide fragments (2-residue and 15-residue) , we\ndemonstrate our method, dubbed \\texttt{CrysFormer}, can achieve accurate\npredictions, based on a much smaller dataset size and with reduced computation\ncosts.\n",
                "链接": "https://arxiv.org/abs/2310.03899"
            },
            {
                "文章ID": "47032",
                "标题": "Learning the shape of protein micro-environments with a holographic\n  convolutional neural network",
                "作者": " Michael N. Pun,  Andrew Ivanov,  Quinn Bellamy,  Zachary Montague,  Colin LaMont,  Philip Bradley,  Jakub Otwinowski,  Armita Nourmohammad",
                "发布日期": "2022-11-08",
                "摘要": "  Proteins play a central role in biology from immune recognition to brain\nactivity. While major advances in machine learning have improved our ability to\npredict protein structure from sequence, determining protein function from\nstructure remains a major challenge. Here, we introduce Holographic\nConvolutional Neural Network (H-CNN) for proteins, which is a physically\nmotivated machine learning approach to model amino acid preferences in protein\nstructures. H-CNN reflects physical interactions in a protein structure and\nrecapitulates the functional information stored in evolutionary data. H-CNN\naccurately predicts the impact of mutations on protein function, including\nstability and binding of protein complexes. Our interpretable computational\nmodel for protein structure-function maps could guide design of novel proteins\nwith desired function.\n",
                "链接": "https://arxiv.org/abs/2211.02936"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用BERT和RoBERTa进行多语言情感分析的最新论文，要求涵盖2022年以来的研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "52169",
                "标题": "Video Games as a Corpus: Sentiment Analysis using Fallout New Vegas\n  Dialog",
                "作者": " Mika Hämäläinen,  Khalid Alnajjar,  Thierry Poibeau",
                "发布日期": "2022-12-06",
                "摘要": "  We present a method for extracting a multilingual sentiment annotated dialog\ndata set from Fallout New Vegas. The game developers have preannotated every\nline of dialog in the game in one of the 8 different sentiments: \\textit{anger,\ndisgust, fear, happy, neutral, pained, sad } and \\textit{surprised}. The game\nhas been translated into English, Spanish, German, French and Italian. We\nconduct experiments on multilingual, multilabel sentiment analysis on the\nextracted data set using multilingual BERT, XLMRoBERTa and language specific\nBERT models. In our experiments, multilingual BERT outperformed XLMRoBERTa for\nmost of the languages, also language specific models were slightly better than\nmultilingual BERT for most of the languages. The best overall accuracy was 54\\%\nand it was achieved by using multilingual BERT on Spanish data. The extracted\ndata set presents a challenging task for sentiment analysis. We have released\nthe data, including the testing and training splits, openly on Zenodo. The data\nset has been shuffled for copyright reasons.\n",
                "链接": "https://arxiv.org/abs/2212.02168"
            },
            {
                "文章ID": "15513",
                "标题": "Mono vs Multilingual BERT for Hate Speech Detection and Text\n  Classification: A Case Study in Marathi",
                "作者": " Abhishek Velankar,  Hrushikesh Patil,  Raviraj Joshi",
                "发布日期": "2022-11-15",
                "摘要": "  Transformers are the most eminent architectures used for a vast range of\nNatural Language Processing tasks. These models are pre-trained over a large\ntext corpus and are meant to serve state-of-the-art results over tasks like\ntext classification. In this work, we conduct a comparative study between\nmonolingual and multilingual BERT models. We focus on the Marathi language and\nevaluate the models on the datasets for hate speech detection, sentiment\nanalysis and simple text classification in Marathi. We use standard\nmultilingual models such as mBERT, indicBERT and xlm-RoBERTa and compare with\nMahaBERT, MahaALBERT and MahaRoBERTa, the monolingual models for Marathi. We\nfurther show that Marathi monolingual models outperform the multilingual BERT\nvariants on five different downstream fine-tuning experiments. We also evaluate\nsentence embeddings from these models by freezing the BERT encoder layers. We\nshow that monolingual MahaBERT based models provide rich representations as\ncompared to sentence embeddings from multi-lingual counterparts. However, we\nobserve that these embeddings are not generic enough and do not work well on\nout of domain social media datasets. We consider two Marathi hate speech\ndatasets L3Cube-MahaHate, HASOC-2021, a Marathi sentiment classification\ndataset L3Cube-MahaSent, and Marathi Headline, Articles classification\ndatasets.\n",
                "链接": "https://arxiv.org/abs/2204.08669"
            },
            {
                "文章ID": "31048",
                "标题": "Enhancing Collaborative Filtering Recommender with Prompt-Based\n  Sentiment Analysis",
                "作者": " Elliot Dang,  Zheyuan Hu,  Tong Li",
                "发布日期": "2022-07-27",
                "摘要": "  Collaborative Filtering(CF) recommender is a crucial application in the\nonline market and ecommerce. However, CF recommender has been proven to suffer\nfrom persistent problems related to sparsity of the user rating that will\nfurther lead to a cold-start issue. Existing methods address the data sparsity\nissue by applying token-level sentiment analysis that translate text review\ninto sentiment scores as a complement of the user rating. In this paper, we\nattempt to optimize the sentiment analysis with advanced NLP models including\nBERT and RoBERTa, and experiment on whether the CF recommender has been further\nenhanced. We build the recommenders on the Amazon US Reviews dataset, and tune\nthe pretrained BERT and RoBERTa with the traditional fine-tuned paradigm as\nwell as the new prompt-based learning paradigm. Experimental result shows that\nthe recommender enhanced with the sentiment ratings predicted by the fine-tuned\nRoBERTa has the best performance, and achieved 30.7% overall gain by comparing\nMAP, NDCG and precision at K to the baseline recommender. Prompt-based learning\nparadigm, although superior to traditional fine-tune paradigm in pure sentiment\nanalysis, fail to further improve the CF recommender.\n",
                "链接": "https://arxiv.org/abs/2207.12883"
            },
            {
                "文章ID": "114320",
                "标题": "Modelling Sentiment Analysis: LLMs and data augmentation techniques",
                "作者": " Guillem Senabre Prades",
                "发布日期": "2023-11-08",
                "摘要": "  This paper provides different approaches for a binary sentiment\nclassification on a small training dataset. LLMs that provided state-of-the-art\nresults in sentiment analysis and similar domains are being used, such as BERT,\nRoBERTa and XLNet.\n",
                "链接": "https://arxiv.org/abs/2311.04139"
            },
            {
                "文章ID": "82977",
                "标题": "UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of\n  Multilingual BERT for Low-resource Sentiment Analysis",
                "作者": " Dou Hu,  Lingwei Wei,  Yaxin Liu,  Wei Zhou,  Songlin Hu",
                "发布日期": "2023-06-05",
                "摘要": "  This paper describes our system designed for SemEval-2023 Task 12: Sentiment\nanalysis for African languages. The challenge faced by this task is the\nscarcity of labeled data and linguistic resources in low-resource settings. To\nalleviate these, we propose a generalized multilingual system SACL-XLMR for\nsentiment analysis on low-resource languages. Specifically, we design a\nlexicon-based multilingual BERT to facilitate language adaptation and\nsentiment-aware representation learning. Besides, we apply a supervised\nadversarial contrastive learning technique to learn sentiment-spread structured\nrepresentations and enhance model generalization. Our system achieved\ncompetitive results, largely outperforming baselines on both multilingual and\nzero-shot sentiment classification subtasks. Notably, the system obtained the\n1st rank on the zero-shot classification subtask in the official ranking.\nExtensive experiments demonstrate the effectiveness of our system.\n",
                "链接": "https://arxiv.org/abs/2306.01093"
            },
            {
                "文章ID": "74465",
                "标题": "HausaNLP at SemEval-2023 Task 12: Leveraging African Low Resource\n  TweetData for Sentiment Analysis",
                "作者": " Saheed Abdullahi Salahudeen,  Falalu Ibrahim Lawan,  Ahmad Mustapha Wali,  Amina Abubakar Imam,  Aliyu Rabiu Shuaibu,  Aliyu Yusuf,  Nur Bala Rabiu,  Musa Bello,  Shamsuddeen Umaru Adamu,  Saminu Mohammad Aliyu,  Murja Sani Gadanya,  Sanah Abdullahi Muaz,  Mahmoud Said Ahmad,  Abdulkadir Abdullahi,  Abdulmalik Yusuf Jamoh",
                "发布日期": "2023-04-27",
                "摘要": "  We present the findings of SemEval-2023 Task 12, a shared task on sentiment\nanalysis for low-resource African languages using Twitter dataset. The task\nfeatured three subtasks; subtask A is monolingual sentiment classification with\n12 tracks which are all monolingual languages, subtask B is multilingual\nsentiment classification using the tracks in subtask A and subtask C is a\nzero-shot sentiment classification. We present the results and findings of\nsubtask A, subtask B and subtask C. We also release the code on github. Our\ngoal is to leverage low-resource tweet data using pre-trained Afro-xlmr-large,\nAfriBERTa-Large, Bert-base-arabic-camelbert-da-sentiment (Arabic-camelbert),\nMultilingual-BERT (mBERT) and BERT models for sentiment analysis of 14 African\nlanguages. The datasets for these subtasks consists of a gold standard\nmulti-class labeled Twitter datasets from these languages. Our results\ndemonstrate that Afro-xlmr-large model performed better compared to the other\nmodels in most of the languages datasets. Similarly, Nigerian languages: Hausa,\nIgbo, and Yoruba achieved better performance compared to other languages and\nthis can be attributed to the higher volume of data present in the languages.\n",
                "链接": "https://arxiv.org/abs/2304.13634"
            },
            {
                "文章ID": "87606",
                "标题": "L3Cube-MahaSent-MD: A Multi-domain Marathi Sentiment Analysis Dataset\n  and Transformer Models",
                "作者": " Aabha Pingle,  Aditya Vyawahare,  Isha Joshi,  Rahul Tangsali,  Raviraj Joshi",
                "发布日期": "2023-06-27",
                "摘要": "  The exploration of sentiment analysis in low-resource languages, such as\nMarathi, has been limited due to the availability of suitable datasets. In this\nwork, we present L3Cube-MahaSent-MD, a multi-domain Marathi sentiment analysis\ndataset, with four different domains - movie reviews, general tweets, TV show\nsubtitles, and political tweets. The dataset consists of around 60,000 manually\ntagged samples covering 3 distinct sentiments - positive, negative, and\nneutral. We create a sub-dataset for each domain comprising 15k samples. The\nMahaSent-MD is the first comprehensive multi-domain sentiment analysis dataset\nwithin the Indic sentiment landscape. We fine-tune different monolingual and\nmultilingual BERT models on these datasets and report the best accuracy with\nthe MahaBERT model. We also present an extensive in-domain and cross-domain\nanalysis thus highlighting the need for low-resource multi-domain datasets. The\ndata and models are available at https://github.com/l3cube-pune/MarathiNLP .\n",
                "链接": "https://arxiv.org/abs/2306.13888"
            },
            {
                "文章ID": "78993",
                "标题": "SEntFiN 1.0: Entity-Aware Sentiment Analysis for Financial News",
                "作者": " Ankur Sinha,  Satishwar Kedas,  Rishu Kumar,  Pekka Malo",
                "发布日期": "2023-05-23",
                "摘要": "  Fine-grained financial sentiment analysis on news headlines is a challenging\ntask requiring human-annotated datasets to achieve high performance. Limited\nstudies have tried to address the sentiment extraction task in a setting where\nmultiple entities are present in a news headline. In an effort to further\nresearch in this area, we make publicly available SEntFiN 1.0, a\nhuman-annotated dataset of 10,753 news headlines with entity-sentiment\nannotations, of which 2,847 headlines contain multiple entities, often with\nconflicting sentiments. We augment our dataset with a database of over 1,000\nfinancial entities and their various representations in news media amounting to\nover 5,000 phrases. We propose a framework that enables the extraction of\nentity-relevant sentiments using a feature-based approach rather than an\nexpression-based approach. For sentiment extraction, we utilize 12 different\nlearning schemes utilizing lexicon-based and pre-trained sentence\nrepresentations and five classification approaches. Our experiments indicate\nthat lexicon-based n-gram ensembles are above par with pre-trained word\nembedding schemes such as GloVe. Overall, RoBERTa and finBERT (domain-specific\nBERT) achieve the highest average accuracy of 94.29% and F1-score of 93.27%.\nFurther, using over 210,000 entity-sentiment predictions, we validate the\neconomic effect of sentiments on aggregate market movements over a long\nduration.\n",
                "链接": "https://arxiv.org/abs/2305.12257"
            },
            {
                "文章ID": "93437",
                "标题": "Detecting the Presence of COVID-19 Vaccination Hesitancy from South\n  African Twitter Data Using Machine Learning",
                "作者": " Nicholas Perikli,  Srimoy Bhattacharya,  Blessing Ogbuokiri,  Zahra Movahedi Nia,  Benjamin Lieberman,  Nidhi Tripathi,  Salah-Eddine Dahbi,  Finn Stevenson,  Nicola Bragazzi,  Jude Kong,  Bruce Mellado",
                "发布日期": "2023-07-31",
                "摘要": "  Very few social media studies have been done on South African user-generated\ncontent during the COVID-19 pandemic and even fewer using hand-labelling over\nautomated methods. Vaccination is a major tool in the fight against the\npandemic, but vaccine hesitancy jeopardizes any public health effort. In this\nstudy, sentiment analysis on South African tweets related to vaccine hesitancy\nwas performed, with the aim of training AI-mediated classification models and\nassessing their reliability in categorizing UGC. A dataset of 30000 tweets from\nSouth Africa were extracted and hand-labelled into one of three sentiment\nclasses: positive, negative, neutral. The machine learning models used were\nLSTM, bi-LSTM, SVM, BERT-base-cased and the RoBERTa-base models, whereby their\nhyperparameters were carefully chosen and tuned using the WandB platform. We\nused two different approaches when we pre-processed our data for comparison:\none was semantics-based, while the other was corpus-based. The pre-processing\nof the tweets in our dataset was performed using both methods, respectively.\nAll models were found to have low F1-scores within a range of 45$\\%$-55$\\%$,\nexcept for BERT and RoBERTa which both achieved significantly better measures\nwith overall F1-scores of 60$\\%$ and 61$\\%$, respectively. Topic modelling\nusing an LDA was performed on the miss-classified tweets of the RoBERTa model\nto gain insight on how to further improve model accuracy.\n",
                "链接": "https://arxiv.org/abs/2307.15072"
            },
            {
                "文章ID": "11461",
                "标题": "Mono vs Multilingual BERT: A Case Study in Hindi and Marathi Named\n  Entity Recognition",
                "作者": " Onkar Litake,  Maithili Sabane,  Parth Patil,  Aparna Ranade,  Raviraj Joshi",
                "发布日期": "2023-02-28",
                "摘要": "  Named entity recognition (NER) is the process of recognising and classifying\nimportant information (entities) in text. Proper nouns, such as a person's\nname, an organization's name, or a location's name, are examples of entities.\nThe NER is one of the important modules in applications like human resources,\ncustomer support, search engines, content classification, and academia. In this\nwork, we consider NER for low-resource Indian languages like Hindi and Marathi.\nThe transformer-based models have been widely used for NER tasks. We consider\ndifferent variations of BERT like base-BERT, RoBERTa, and AlBERT and benchmark\nthem on publicly available Hindi and Marathi NER datasets. We provide an\nexhaustive comparison of different monolingual and multilingual\ntransformer-based models and establish simple baselines currently missing in\nthe literature. We show that the monolingual MahaRoBERTa model performs the\nbest for Marathi NER whereas the multilingual XLM-RoBERTa performs the best for\nHindi NER. We also perform cross-language evaluation and present mixed\nobservations.\n",
                "链接": "https://arxiv.org/abs/2203.12907"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找一下2018年以后使用强化学习做机器翻译任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "96953",
                "标题": "Reinforced Self-Training (ReST) for Language Modeling",
                "作者": " Caglar Gulcehre,  Tom Le Paine,  Srivatsan Srinivasan,  Ksenia Konyushkova,  Lotte Weerts,  Abhishek Sharma,  Aditya Siddhant,  Alex Ahern,  Miaosen Wang,  Chenjie Gu,  Wolfgang Macherey,  Arnaud Doucet,  Orhan Firat,  Nando de Freitas",
                "发布日期": "2023-08-22",
                "摘要": "  Reinforcement learning from human feedback (RLHF) can improve the quality of\nlarge language model's (LLM) outputs by aligning them with human preferences.\nWe propose a simple algorithm for aligning LLMs with human preferences inspired\nby growing batch reinforcement learning (RL), which we call Reinforced\nSelf-Training (ReST). Given an initial LLM policy, ReST produces a dataset by\ngenerating samples from the policy, which are then used to improve the LLM\npolicy using offline RL algorithms. ReST is more efficient than typical online\nRLHF methods because the training dataset is produced offline, which allows\ndata reuse. While ReST is a general approach applicable to all generative\nlearning settings, we focus on its application to machine translation. Our\nresults show that ReST can substantially improve translation quality, as\nmeasured by automated metrics and human evaluation on machine translation\nbenchmarks in a compute and sample-efficient manner.\n",
                "链接": "https://arxiv.org/abs/2308.08998"
            },
            {
                "文章ID": "29736",
                "标题": "MAD for Robust Reinforcement Learning in Machine Translation",
                "作者": " Domenic Donato,  Lei Yu,  Wang Ling,  Chris Dyer",
                "发布日期": "2022-07-19",
                "摘要": "  We introduce a new distributed policy gradient algorithm and show that it\noutperforms existing reward-aware training procedures such as REINFORCE,\nminimum risk training (MRT) and proximal policy optimization (PPO) in terms of\ntraining stability and generalization performance when optimizing machine\ntranslation models. Our algorithm, which we call MAD (on account of using the\nmean absolute deviation in the importance weighting calculation), has\ndistributed data generators sampling multiple candidates per source sentence on\nworker nodes, while a central learner updates the policy. MAD depends crucially\non two variance reduction strategies: (1) a conditional reward normalization\nmethod that ensures each source sentence has both positive and negative reward\ntranslation examples and (2) a new robust importance weighting scheme that acts\nas a conditional entropy regularizer. Experiments on a variety of translation\ntasks show that policies learned using the MAD algorithm perform very well when\nusing both greedy decoding and beam search, and that the learned policies are\nsensitive to the specific reward used during training.\n",
                "链接": "https://arxiv.org/abs/2207.08583"
            },
            {
                "文章ID": "79608",
                "标题": "Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine\n  Translation",
                "作者": " Jiayi Wang,  Ke Wang,  Yuqi Zhang,  Yu Zhao,  Pontus Stenetorp",
                "发布日期": "2023-05-24",
                "摘要": "  Non-parametric, k-nearest-neighbor algorithms have recently made inroads to\nassist generative models such as language models and machine translation\ndecoders. We explore whether such non-parametric models can improve machine\ntranslation models at the fine-tuning stage by incorporating statistics from\nthe kNN predictions to inform the gradient updates for a baseline translation\nmodel. There are multiple methods which could be used to incorporate kNN\nstatistics and we investigate gradient scaling by a gating mechanism, the kNN's\nground truth probability, and reinforcement learning. For four standard\nin-domain machine translation datasets, compared with classic fine-tuning, we\nreport consistent improvements of all of the three methods by as much as 1.45\nBLEU and 1.28 BLEU for German-English and English-German translations\nrespectively. Through qualitative analysis, we found particular improvements\nwhen it comes to translating grammatical relations or function words, which\nresults in increased fluency of our model.\n",
                "链接": "https://arxiv.org/abs/2305.13648"
            },
            {
                "文章ID": "112036",
                "标题": "A Review of Reinforcement Learning for Natural Language Processing, and\n  Applications in Healthcare",
                "作者": " Ying Liu,  Haozhu Wang,  Huixue Zhou,  Mingchen Li,  Yu Hou,  Sicheng Zhou,  Fang Wang,  Rama Hoetzlein,  Rui Zhang",
                "发布日期": "2023-10-31",
                "摘要": "  Reinforcement learning (RL) has emerged as a powerful approach for tackling\ncomplex medical decision-making problems such as treatment planning,\npersonalized medicine, and optimizing the scheduling of surgeries and\nappointments. It has gained significant attention in the field of Natural\nLanguage Processing (NLP) due to its ability to learn optimal strategies for\ntasks such as dialogue systems, machine translation, and question-answering.\nThis paper presents a review of the RL techniques in NLP, highlighting key\nadvancements, challenges, and applications in healthcare. The review begins by\nvisualizing a roadmap of machine learning and its applications in healthcare.\nAnd then it explores the integration of RL with NLP tasks. We examined dialogue\nsystems where RL enables the learning of conversational strategies, RL-based\nmachine translation models, question-answering systems, text summarization, and\ninformation extraction. Additionally, ethical considerations and biases in\nRL-NLP systems are addressed.\n",
                "链接": "https://arxiv.org/abs/2310.18354"
            },
            {
                "文章ID": "40957",
                "标题": "Reinforcement Learning with Large Action Spaces for Neural Machine\n  Translation",
                "作者": " Asaf Yehudai,  Leshem Choshen,  Lior Fox,  Omri Abend",
                "发布日期": "2022-10-07",
                "摘要": "  Applying Reinforcement learning (RL) following maximum likelihood estimation\n(MLE) pre-training is a versatile method for enhancing neural machine\ntranslation (NMT) performance. However, recent work has argued that the gains\nproduced by RL for NMT are mostly due to promoting tokens that have already\nreceived a fairly high probability in pre-training. We hypothesize that the\nlarge action space is a main obstacle to RL's effectiveness in MT, and conduct\ntwo sets of experiments that lend support to our hypothesis. First, we find\nthat reducing the size of the vocabulary improves RL's effectiveness. Second,\nwe find that effectively reducing the dimension of the action space without\nchanging the vocabulary also yields notable improvement as evaluated by BLEU,\nsemantic similarity, and human evaluation. Indeed, by initializing the\nnetwork's final fully connected layer (that maps the network's internal\ndimension to the vocabulary dimension), with a layer that generalizes over\nsimilar actions, we obtain a substantial improvement in RL performance: 1.5\nBLEU points on average.\n",
                "链接": "https://arxiv.org/abs/2210.03053"
            },
            {
                "文章ID": "94624",
                "标题": "ESRL: Efficient Sampling-based Reinforcement Learning for Sequence\n  Generation",
                "作者": " Chenglong Wang,  Hang Zhou,  Yimin Hu,  Yifu Huo,  Bei Li,  Tongran Liu,  Tong Xiao,  Jingbo Zhu",
                "发布日期": "2023-08-07",
                "摘要": "  Applying Reinforcement Learning (RL) to sequence generation models enables\nthe direct optimization of long-term rewards (\\textit{e.g.,} BLEU and human\nfeedback), but typically requires large-scale sampling over a space of action\nsequences. This is a computational challenge as presented by the practice of\nsequence generation problems, such as machine translation, where we often deal\nwith a large action space (\\textit{e.g.,} a vocabulary) and a long action\nsequence (\\textit{e.g.,} a translation). In this work, we introduce two-stage\nsampling and dynamic sampling approaches to improve the sampling efficiency\nduring training sequence generation models via RL. We experiment with our\napproaches on the traditional sequence generation tasks, including machine\ntranslation and abstractive summarization. Furthermore, we evaluate our\napproaches in RL from human feedback (RLHF) through training a large language\nmodel using the reward model. Experimental results show that the efficient\nsampling-based RL, referred to as ESRL, can outperform all baselines in terms\nof both training efficiency and memory consumption. Notably, ESRL yields\nconsistent performance gains over the strong REINFORCE, minimum risk training,\nand proximal policy optimization methods.\n",
                "链接": "https://arxiv.org/abs/2308.02223"
            },
            {
                "文章ID": "80020",
                "标题": "Language Model Self-improvement by Reinforcement Learning Contemplation",
                "作者": " Jing-Cheng Pang,  Pengyuan Wang,  Kaiyuan Li,  Xiong-Hui Chen,  Jiacheng Xu,  Zongzhang Zhang,  Yang Yu",
                "发布日期": "2023-05-25",
                "摘要": "  Large Language Models (LLMs) have exhibited remarkable performance across\nvarious natural language processing (NLP) tasks. However, fine-tuning these\nmodels often necessitates substantial supervision, which can be expensive and\ntime-consuming to obtain. This paper introduces a novel unsupervised method\ncalled LanguageModel Self-Improvement by Reinforcement Learning Contemplation\n(SIRLC) that improves LLMs without reliance on external labels. Our approach is\ngrounded in the observation that it is simpler for language models to assess\ntext quality than to generate text. Building on this insight, SIRLC assigns\nLLMs dual roles as both student and teacher. As a student, the LLM generates\nanswers to unlabeled questions, while as a teacher, it evaluates the generated\ntext and assigns scores accordingly. The model parameters are updated using\nreinforcement learning to maximize the evaluation score. We demonstrate that\nSIRLC can be applied to various NLP tasks, such as reasoning problems, text\ngeneration, and machine translation. Our experiments show that SIRLC\neffectively improves LLM performance without external supervision, resulting in\na 5.6% increase in answering accuracy for reasoning tasks and a rise in\nBERTScore from 0.82 to 0.86 for translation tasks. Furthermore, SIRLC can be\napplied to models of different sizes, showcasing its broad applicability.\n",
                "链接": "https://arxiv.org/abs/2305.14483"
            },
            {
                "文章ID": "115935",
                "标题": "Aligning Neural Machine Translation Models: Human Feedback in Training\n  and Inference",
                "作者": " Miguel Moura Ramos,  Patrick Fernandes,  António Farinhas,  André F. T. Martins",
                "发布日期": "2023-11-16",
                "摘要": "  Reinforcement learning from human feedback (RLHF) is a recent technique to\nimprove the quality of the text generated by a language model, making it closer\nto what humans would generate. A core ingredient in RLHF's success in aligning\nand improving large language models (LLMs) is its reward model, trained using\nhuman feedback on model outputs. In machine translation (MT), where metrics\ntrained from human annotations can readily be used as reward models, recent\nmethods using minimum Bayes risk decoding and reranking have succeeded in\nimproving the final quality of translation. In this study, we comprehensively\nexplore and compare techniques for integrating quality metrics as reward models\ninto the MT pipeline. This includes using the reward model for data filtering,\nduring the training phase through RL, and at inference time by employing\nreranking techniques, and we assess the effects of combining these in a unified\napproach. Our experimental results, conducted across multiple translation\ntasks, underscore the crucial role of effective data filtering, based on\nestimated quality, in harnessing the full potential of RL in enhancing MT\nquality. Furthermore, our findings demonstrate the effectiveness of combining\nRL training with reranking techniques, showcasing substantial improvements in\ntranslation quality.\n",
                "链接": "https://arxiv.org/abs/2311.09132"
            },
            {
                "文章ID": "10776",
                "标题": "Mitigating Gender Bias in Machine Translation through Adversarial\n  Learning",
                "作者": " Eve Fleisig,  Christiane Fellbaum",
                "发布日期": "2022-03-22",
                "摘要": "  Machine translation and other NLP systems often contain significant biases\nregarding sensitive attributes, such as gender or race, that worsen system\nperformance and perpetuate harmful stereotypes. Recent preliminary research\nsuggests that adversarial learning can be used as part of a model-agnostic bias\nmitigation method that requires no data modifications. However, adapting this\nstrategy for machine translation and other modern NLP domains requires (1)\nrestructuring training objectives in the context of fine-tuning pretrained\nlarge language models and (2) developing measures for gender or other protected\nvariables for tasks in which these attributes must be deduced from the data\nitself.\n  We present an adversarial learning framework that addresses these challenges\nto mitigate gender bias in seq2seq machine translation. Our framework improves\nthe disparity in translation quality for sentences with male vs. female\nentities by 86% for English-German translation and 91% for English-French\ntranslation, with minimal effect on translation quality. The results suggest\nthat adversarial learning is a promising technique for mitigating gender bias\nin machine translation.\n",
                "链接": "https://arxiv.org/abs/2203.10675"
            },
            {
                "文章ID": "110267",
                "标题": "Simultaneous Machine Translation with Tailored Reference",
                "作者": " Shoutao Guo,  Shaolei Zhang,  Yang Feng",
                "发布日期": "2023-10-27",
                "摘要": "  Simultaneous machine translation (SiMT) generates translation while reading\nthe whole source sentence. However, existing SiMT models are typically trained\nusing the same reference disregarding the varying amounts of available source\ninformation at different latency. Training the model with ground-truth at low\nlatency may introduce forced anticipations, whereas utilizing reference\nconsistent with the source word order at high latency results in performance\ndegradation. Consequently, it is crucial to train the SiMT model with\nappropriate reference that avoids forced anticipations during training while\nmaintaining high quality. In this paper, we propose a novel method that\nprovides tailored reference for the SiMT models trained at different latency by\nrephrasing the ground-truth. Specifically, we introduce the tailor, induced by\nreinforcement learning, to modify ground-truth to the tailored reference. The\nSiMT model is trained with the tailored reference and jointly optimized with\nthe tailor to enhance performance. Importantly, our method is applicable to a\nwide range of current SiMT approaches. Experiments on three translation tasks\ndemonstrate that our method achieves state-of-the-art performance in both fixed\nand adaptive policies.\n",
                "链接": "https://arxiv.org/abs/2310.13588"
            }
        ]
    },
    {
        "question": {
            "question": "请找出使用Transformer模型并在大规模数据集上进行预训练的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "42528",
                "标题": "How to Train Vision Transformer on Small-scale Datasets?",
                "作者": " Hanan Gani,  Muzammal Naseer,  Mohammad Yaqub",
                "发布日期": "2022-10-14",
                "摘要": "  Vision Transformer (ViT), a radically different architecture than\nconvolutional neural networks offers multiple advantages including design\nsimplicity, robustness and state-of-the-art performance on many vision tasks.\nHowever, in contrast to convolutional neural networks, Vision Transformer lacks\ninherent inductive biases. Therefore, successful training of such models is\nmainly attributed to pre-training on large-scale datasets such as ImageNet with\n1.2M or JFT with 300M images. This hinders the direct adaption of Vision\nTransformer for small-scale datasets. In this work, we show that\nself-supervised inductive biases can be learned directly from small-scale\ndatasets and serve as an effective weight initialization scheme for\nfine-tuning. This allows to train these models without large-scale\npre-training, changes to model architecture or loss functions. We present\nthorough experiments to successfully train monolithic and non-monolithic Vision\nTransformers on five small datasets including CIFAR10/100, CINIC10, SVHN,\nTiny-ImageNet and two fine-grained datasets: Aircraft and Cars. Our approach\nconsistently improves the performance of Vision Transformers while retaining\ntheir properties such as attention to salient regions and higher robustness.\nOur codes and pre-trained models are available at:\nhttps://github.com/hananshafi/vits-for-small-scale-datasets.\n",
                "链接": "https://arxiv.org/abs/2210.07240"
            },
            {
                "文章ID": "104233",
                "标题": "Small-scale proxies for large-scale Transformer training instabilities",
                "作者": " Mitchell Wortsman,  Peter J. Liu,  Lechao Xiao,  Katie Everett,  Alex Alemi,  Ben Adlam,  John D. Co-Reyes,  Izzeddin Gur,  Abhishek Kumar,  Roman Novak,  Jeffrey Pennington,  Jascha Sohl-dickstein,  Kelvin Xu,  Jaehoon Lee,  Justin Gilmer,  Simon Kornblith",
                "发布日期": "2023-10-18",
                "摘要": "  Teams that have trained large Transformer-based models have reported training\ninstabilities at large scale that did not appear when training with the same\nhyperparameters at smaller scales. Although the causes of such instabilities\nare of scientific interest, the amount of resources required to reproduce them\nhas made investigation difficult. In this work, we seek ways to reproduce and\nstudy training stability and instability at smaller scales. First, we focus on\ntwo sources of training instability described in previous work: the growth of\nlogits in attention layers (Dehghani et al., 2023) and divergence of the output\nlogits from the log probabilities (Chowdhery et al., 2022). By measuring the\nrelationship between learning rate and loss across scales, we show that these\ninstabilities also appear in small models when training at high learning rates,\nand that mitigations previously employed at large scales are equally effective\nin this regime. This prompts us to investigate the extent to which other known\noptimizer and model interventions influence the sensitivity of the final loss\nto changes in the learning rate. To this end, we study methods such as warm-up,\nweight decay, and the $\\mu$Param (Yang et al., 2022), and combine techniques to\ntrain small models that achieve similar losses across orders of magnitude of\nlearning rate variation. Finally, to conclude our exploration we study two\ncases where instabilities can be predicted before they emerge by examining the\nscaling behavior of model activation and gradient norms.\n",
                "链接": "https://arxiv.org/abs/2309.14322"
            },
            {
                "文章ID": "4580",
                "标题": "Particle Transformer for Jet Tagging",
                "作者": " Huilin Qu,  Congqiao Li,  Sitian Qian",
                "发布日期": "2022-12-16",
                "摘要": "  Jet tagging is a critical yet challenging classification task in particle\nphysics. While deep learning has transformed jet tagging and significantly\nimproved performance, the lack of a large-scale public dataset impedes further\nenhancement. In this work, we present JetClass, a new comprehensive dataset for\njet tagging. The JetClass dataset consists of 100 M jets, about two orders of\nmagnitude larger than existing public datasets. A total of 10 types of jets are\nsimulated, including several types unexplored for tagging so far. Based on the\nlarge dataset, we propose a new Transformer-based architecture for jet tagging,\ncalled Particle Transformer (ParT). By incorporating pairwise particle\ninteractions in the attention mechanism, ParT achieves higher tagging\nperformance than a plain Transformer and surpasses the previous\nstate-of-the-art, ParticleNet, by a large margin. The pre-trained ParT models,\nonce fine-tuned, also substantially enhance the performance on two widely\nadopted jet tagging benchmarks. The dataset, code and models are publicly\navailable at https://github.com/jet-universe/particle_transformer.\n",
                "链接": "https://arxiv.org/abs/2202.03772"
            },
            {
                "文章ID": "19946",
                "标题": "Integrally Migrating Pre-trained Transformer Encoder-decoders for Visual\n  Object Detection",
                "作者": " Feng Liu,  Xiaosong Zhang,  Zhiliang Peng,  Zonghao Guo,  Fang Wan,  Xiangyang Ji,  Qixiang Ye",
                "发布日期": "2023-12-22",
                "摘要": "  Modern object detectors have taken the advantages of backbone networks\npre-trained on large scale datasets. Except for the backbone networks, however,\nother components such as the detector head and the feature pyramid network\n(FPN) remain trained from scratch, which hinders fully tapping the potential of\nrepresentation models. In this study, we propose to integrally migrate\npre-trained transformer encoder-decoders (imTED) to a detector, constructing a\nfeature extraction path which is ``fully pre-trained\" so that detectors'\ngeneralization capacity is maximized. The essential differences between imTED\nwith the baseline detector are twofold: (1) migrating the pre-trained\ntransformer decoder to the detector head while removing the randomly\ninitialized FPN from the feature extraction path; and (2) defining a\nmulti-scale feature modulator (MFM) to enhance scale adaptability. Such designs\nnot only reduce randomly initialized parameters significantly but also unify\ndetector training with representation learning intendedly. Experiments on the\nMS COCO object detection dataset show that imTED consistently outperforms its\ncounterparts by $\\sim$2.4 AP. Without bells and whistles, imTED improves the\nstate-of-the-art of few-shot object detection by up to 7.6 AP. Code is\navailable at https://github.com/LiewFeng/imTED.\n",
                "链接": "https://arxiv.org/abs/2205.09613"
            },
            {
                "文章ID": "11046",
                "标题": "WuDaoMM: A large-scale Multi-Modal Dataset for Pre-training models",
                "作者": " Sha Yuan,  Shuai Zhao,  Jiahong Leng,  Zhao Xue,  Hanyu Zhao,  Peiyu Liu,  Zheng Gong,  Wayne Xin Zhao,  Junyi Li,  Jie Tang",
                "发布日期": "2022-05-03",
                "摘要": "  Compared with the domain-specific model, the vision-language pre-training\nmodels (VLPMs) have shown superior performance on downstream tasks with fast\nfine-tuning process. For example, ERNIE-ViL, Oscar and UNIMO trained VLPMs with\na uniform transformers stack architecture and large amounts of image-text\npaired data, achieving remarkable results on downstream tasks such as\nimage-text reference(IR and TR), vision question answering (VQA) and image\ncaptioning (IC) etc. During the training phase, VLPMs are always fed with a\ncombination of multiple public datasets to meet the demand of large-scare\ntraining data. However, due to the unevenness of data distribution including\nsize, task type and quality, using the mixture of multiple datasets for model\ntraining can be problematic. In this work, we introduce a large-scale\nmulti-modal corpora named WuDaoMM, totally containing more than 650M image-text\npairs. Specifically, about 600 million pairs of data are collected from\nmultiple webpages in which image and caption present weak correlation, and the\nother 50 million strong-related image-text pairs are collected from some\nhigh-quality graphic websites. We also release a base version of WuDaoMM with 5\nmillion strong-correlated image-text pairs, which is sufficient to support the\ncommon cross-modal model pre-training. Besides, we trained both an\nunderstanding and a generation vision-language (VL) model to test the dataset\neffectiveness. The results show that WuDaoMM can be applied as an efficient\ndataset for VLPMs, especially for the model in text-to-image generation task.\nThe data is released at https://data.wudaoai.cn\n",
                "链接": "https://arxiv.org/abs/2203.11480"
            },
            {
                "文章ID": "41603",
                "标题": "Transformer-based Localization from Embodied Dialog with Large-scale\n  Pre-training",
                "作者": " Meera Hahn,  James M. Rehg",
                "发布日期": "2022-10-11",
                "摘要": "  We address the challenging task of Localization via Embodied Dialog (LED).\nGiven a dialog from two agents, an Observer navigating through an unknown\nenvironment and a Locator who is attempting to identify the Observer's\nlocation, the goal is to predict the Observer's final location in a map. We\ndevelop a novel LED-Bert architecture and present an effective pretraining\nstrategy. We show that a graph-based scene representation is more effective\nthan the top-down 2D maps used in prior works. Our approach outperforms\nprevious baselines.\n",
                "链接": "https://arxiv.org/abs/2210.04864"
            },
            {
                "文章ID": "66204",
                "标题": "Transformer-based Planning for Symbolic Regression",
                "作者": " Parshin Shojaee,  Kazem Meidani,  Amir Barati Farimani,  Chandan K. Reddy",
                "发布日期": "2023-10-31",
                "摘要": "  Symbolic regression (SR) is a challenging task in machine learning that\ninvolves finding a mathematical expression for a function based on its values.\nRecent advancements in SR have demonstrated the effectiveness of pre-trained\ntransformer-based models in generating equations as sequences, leveraging\nlarge-scale pre-training on synthetic datasets and offering notable advantages\nin terms of inference time over classical Genetic Programming (GP) methods.\nHowever, these models primarily rely on supervised pre-training goals borrowed\nfrom text generation and overlook equation discovery objectives like accuracy\nand complexity. To address this, we propose TPSR, a Transformer-based Planning\nstrategy for Symbolic Regression that incorporates Monte Carlo Tree Search into\nthe transformer decoding process. Unlike conventional decoding strategies, TPSR\nenables the integration of non-differentiable feedback, such as fitting\naccuracy and complexity, as external sources of knowledge into the\ntransformer-based equation generation process. Extensive experiments on various\ndatasets show that our approach outperforms state-of-the-art methods, enhancing\nthe model's fitting-complexity trade-off, extrapolation abilities, and\nrobustness to noise.\n",
                "链接": "https://arxiv.org/abs/2303.06833"
            },
            {
                "文章ID": "82786",
                "标题": "AD-PT: Autonomous Driving Pre-Training with Large-scale Point Cloud\n  Dataset",
                "作者": " Jiakang Yuan,  Bo Zhang,  Xiangchao Yan,  Tao Chen,  Botian Shi,  Yikang Li,  Yu Qiao",
                "发布日期": "2023-10-27",
                "摘要": "  It is a long-term vision for Autonomous Driving (AD) community that the\nperception models can learn from a large-scale point cloud dataset, to obtain\nunified representations that can achieve promising results on different tasks\nor benchmarks. Previous works mainly focus on the self-supervised pre-training\npipeline, meaning that they perform the pre-training and fine-tuning on the\nsame benchmark, which is difficult to attain the performance scalability and\ncross-dataset application for the pre-training checkpoint. In this paper, for\nthe first time, we are committed to building a large-scale pre-training\npoint-cloud dataset with diverse data distribution, and meanwhile learning\ngeneralizable representations from such a diverse pre-training dataset. We\nformulate the point-cloud pre-training task as a semi-supervised problem, which\nleverages the few-shot labeled and massive unlabeled point-cloud data to\ngenerate the unified backbone representations that can be directly applied to\nmany baseline models and benchmarks, decoupling the AD-related pre-training\nprocess and downstream fine-tuning task. During the period of backbone\npre-training, by enhancing the scene- and instance-level distribution diversity\nand exploiting the backbone's ability to learn from unknown instances, we\nachieve significant performance gains on a series of downstream perception\nbenchmarks including Waymo, nuScenes, and KITTI, under different baseline\nmodels like PV-RCNN++, SECOND, CenterPoint.\n",
                "链接": "https://arxiv.org/abs/2306.00612"
            },
            {
                "文章ID": "77855",
                "标题": "NightHazeFormer: Single Nighttime Haze Removal Using Prior Query\n  Transformer",
                "作者": " Yun Liu,  Zhongsheng Yan,  Sixiang Chen,  Tian Ye,  Wenqi Ren,  Erkang Chen",
                "发布日期": "2023-08-15",
                "摘要": "  Nighttime image dehazing is a challenging task due to the presence of\nmultiple types of adverse degrading effects including glow, haze, blurry,\nnoise, color distortion, and so on. However, most previous studies mainly focus\non daytime image dehazing or partial degradations presented in nighttime hazy\nscenes, which may lead to unsatisfactory restoration results. In this paper, we\npropose an end-to-end transformer-based framework for nighttime haze removal,\ncalled NightHazeFormer. Our proposed approach consists of two stages:\nsupervised pre-training and semi-supervised fine-tuning. During the\npre-training stage, we introduce two powerful priors into the transformer\ndecoder to generate the non-learnable prior queries, which guide the model to\nextract specific degradations. For the fine-tuning, we combine the generated\npseudo ground truths with input real-world nighttime hazy images as paired\nimages and feed into the synthetic domain to fine-tune the pre-trained model.\nThis semi-supervised fine-tuning paradigm helps improve the generalization to\nreal domain. In addition, we also propose a large-scale synthetic dataset\ncalled UNREAL-NH, to simulate the real-world nighttime haze scenarios\ncomprehensively. Extensive experiments on several synthetic and real-world\ndatasets demonstrate the superiority of our NightHazeFormer over\nstate-of-the-art nighttime haze removal methods in terms of both visually and\nquantitatively.\n",
                "链接": "https://arxiv.org/abs/2305.09533"
            },
            {
                "文章ID": "20054",
                "标题": "Transformer with Memory Replay",
                "作者": " Rui Liu,  Barzan Mozafari",
                "发布日期": "2022-05-23",
                "摘要": "  Transformers achieve state-of-the-art performance for natural language\nprocessing tasks by pre-training on large-scale text corpora. They are\nextremely compute-intensive and have very high sample complexity. Memory replay\nis a mechanism that remembers and reuses past examples by saving to and\nreplaying from a memory buffer. It has been successfully used in reinforcement\nlearning and GANs due to better sample efficiency. In this paper, we propose\n\\emph{Transformer with Memory Replay} (TMR), which integrates memory replay\nwith transformer, making transformer more sample-efficient. Experiments on GLUE\nand SQuAD benchmark datasets show that Transformer with Memory Replay achieves\nat least $1\\%$ point increase compared to the baseline transformer model when\npretrained with the same number of examples. Further, by adopting a careful\ndesign that reduces the wall-clock time overhead of memory replay, we also\nempirically achieve a better runtime efficiency.\n",
                "链接": "https://arxiv.org/abs/2205.09869"
            }
        ]
    },
    {
        "question": {
            "question": "找一下使用强化学习做代码生成的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "59289",
                "标题": "Execution-based Code Generation using Deep Reinforcement Learning",
                "作者": " Parshin Shojaee,  Aneesh Jain,  Sindhu Tipirneni,  Chandan K. Reddy",
                "发布日期": "2023-07-21",
                "摘要": "  The utilization of programming language (PL) models, pre-trained on\nlarge-scale code corpora, as a means of automating software engineering\nprocesses has demonstrated considerable potential in streamlining various code\ngeneration tasks such as code completion, code translation, and program\nsynthesis. However, current approaches mainly rely on supervised fine-tuning\nobjectives borrowed from text generation, neglecting unique sequence-level\ncharacteristics of code, including but not limited to compilability as well as\nsyntactic and functional correctness. To address this limitation, we propose\nPPOCoder, a new framework for code generation that synergistically combines\npre-trained PL models with Proximal Policy Optimization (PPO) which is a widely\nused deep reinforcement learning technique. By utilizing non-differentiable\nfeedback from code execution and structure alignment, PPOCoder seamlessly\nintegrates external code-specific knowledge into the model optimization\nprocess. It's important to note that PPOCoder is a task-agnostic and\nmodel-agnostic framework that can be used across different code generation\ntasks and PLs. Extensive experiments on three code generation tasks demonstrate\nthe effectiveness of our proposed approach compared to SOTA methods, achieving\nsignificant improvements in compilation success rates and functional\ncorrectness across different PLs.\n",
                "链接": "https://arxiv.org/abs/2301.13816"
            },
            {
                "文章ID": "27761",
                "标题": "CodeRL: Mastering Code Generation through Pretrained Models and Deep\n  Reinforcement Learning",
                "作者": " Hung Le,  Yue Wang,  Akhilesh Deepak Gotmare,  Silvio Savarese,  Steven C. H. Hoi",
                "发布日期": "2022-11-04",
                "摘要": "  Program synthesis or code generation aims to generate a program that\nsatisfies a problem specification. Recent approaches using large-scale\npretrained language models (LMs) have shown promising results, yet they have\nsome critical limitations. In particular, they often follow a standard\nsupervised fine-tuning procedure to train a code generation model only from the\npairs of natural-language problem descriptions and ground-truth programs. Such\nparadigm largely ignores some important but potentially useful signals in the\nproblem specification such as unit tests, which thus often results in poor\nperformance when solving complex unseen coding tasks. To address the\nlimitations, we propose \"CodeRL\", a new framework for program synthesis tasks\nthrough pretrained LMs and deep reinforcement learning (RL). Specifically,\nduring training, we treat the code-generating LM as an actor network, and\nintroduce a critic network that is trained to predict the functional\ncorrectness of generated programs and provide dense feedback signals to the\nactor. During inference, we introduce a new generation procedure with a\ncritical sampling strategy that allows a model to automatically regenerate\nprograms based on feedback from example unit tests and critic scores. For the\nmodel backbones, we extended the encoder-decoder architecture of CodeT5 with\nenhanced learning objectives, larger model sizes, and better pretraining data.\nOur method not only achieves new SOTA results on the challenging APPS\nbenchmark, but also shows strong zero-shot transfer capability with new SOTA\nresults on the simpler MBPP benchmark.\n",
                "链接": "https://arxiv.org/abs/2207.01780"
            },
            {
                "文章ID": "9115",
                "标题": "Compilable Neural Code Generation with Compiler Feedback",
                "作者": " Xin Wang,  Yasheng Wang,  Yao Wan,  Fei Mi,  Yitong Li,  Pingyi Zhou,  Jin Liu,  Hao Wu,  Xin Jiang,  Qun Liu",
                "发布日期": "2022-03-11",
                "摘要": "  Automatically generating compilable programs with (or without) natural\nlanguage descriptions has always been a touchstone problem for computational\nlinguistics and automated software engineering. Existing deep-learning\napproaches model code generation as text generation, either constrained by\ngrammar structures in decoder, or driven by pre-trained language models on\nlarge-scale code corpus (e.g., CodeGPT, PLBART, and CodeT5). However, few of\nthem account for compilability of the generated programs. To improve\ncompilability of the generated programs, this paper proposes COMPCODER, a\nthree-stage pipeline utilizing compiler feedback for compilable code\ngeneration, including language model fine-tuning, compilability reinforcement,\nand compilability discrimination. Comprehensive experiments on two code\ngeneration tasks demonstrate the effectiveness of our proposed approach,\nimproving the success rate of compilation from 44.18 to 89.18 in code\ncompletion on average and from 70.3 to 96.2 in text-to-code generation,\nrespectively, when comparing with the state-of-the-art CodeGPT.\n",
                "链接": "https://arxiv.org/abs/2203.05132"
            },
            {
                "文章ID": "72734",
                "标题": "Stochastic Code Generation",
                "作者": " Swapnil Sharma,  Nikita Anand, V Kranthi Kiran G.",
                "发布日期": "2023-04-18",
                "摘要": "  Large language models pre-trained for code generation can generate\nhigh-quality short code but often struggle with generating coherent long code\nand understanding higher-level or system-level specifications. This issue is\nalso observed in language modeling for long text generation, and one proposed\nsolution is the use of a latent stochastic process. This approach involves\ngenerating a document plan and then producing text that is consistent with it.\n  In this study, we investigate whether this technique can be applied to code\ngeneration to improve coherence. We base our proposed encoder and decoder on\nthe pre-trained GPT-2 based CodeParrot model and utilize the APPS dataset for\ntraining. We evaluate our results using the HumanEval benchmark and observe\nthat the modified Time Control model performs similarly to CodeParrot on this\nevaluation.\n",
                "链接": "https://arxiv.org/abs/2304.08243"
            },
            {
                "文章ID": "51256",
                "标题": "Coder Reviewer Reranking for Code Generation",
                "作者": " Tianyi Zhang,  Tao Yu,  Tatsunori B. Hashimoto,  Mike Lewis,  Wen-tau Yih,  Daniel Fried,  Sida I. Wang",
                "发布日期": "2022-11-30",
                "摘要": "  Sampling diverse programs from a code language model and reranking with model\nlikelihood is a popular method for code generation but it is prone to\npreferring degenerate solutions. Inspired by collaborative programming, we\npropose Coder-Reviewer reranking. We augment Coder language models from past\nwork, which generate programs given language instructions, with Reviewer\nmodels, which evaluate the likelihood of the instruction given the generated\nprograms. We perform an extensive study across six datasets with eight models\nfrom three model families. Experimental results show that Coder-Reviewer\nreranking leads to consistent and significant improvement (up to 17% absolute\naccuracy gain) over reranking with the Coder model only. When combined with\nexecutability filtering, Coder-Reviewer reranking can often outperform the\nminimum Bayes risk method. Coder-Reviewer reranking is easy to implement by\nprompting, can generalize to different programming languages, and works well\nwith off-the-shelf hyperparameters.\n",
                "链接": "https://arxiv.org/abs/2211.16490"
            },
            {
                "文章ID": "122586",
                "标题": "Entity-Augmented Code Generation",
                "作者": " Anton Shapkin,  Denis Litvinov,  Timofey Bryksin",
                "发布日期": "2023-12-15",
                "摘要": "  The current state-of-the-art large language models (LLMs) are effective in\ngenerating high-quality text and encapsulating a broad spectrum of world\nknowledge. However, these models often hallucinate during generation and are\nnot designed to utilize external information sources. To enable requests to the\nexternal knowledge bases, also called knowledge grounding, retrieval-augmented\nLLMs were introduced. For now, their applications have largely involved Open\nDomain Question Answering, Abstractive Question Answering, and such. In this\npaper, we broaden the scope of retrieval-augmented LLMs by venturing into a new\ntask - code generation using external entities. For this task, we collect and\npublish a new dataset for project-level code generation, where the model should\nreuse functions defined in the project during generation. As we show, existing\nretrieval-augmented LLMs fail to assign relevance scores between similar entity\nnames, and to mitigate it, they expand entity names with description context\nand append it to the input. In practice, due to the limited context size they\ncan not accommodate the indefinitely large context of the whole project. To\nsolve this issue, we propose a novel end-to-end trainable architecture with an\nscalable entity retriever injected directly into the LLM decoder. We\ndemonstrate that our model can outperform common baselines in several\nscenarios, including project-level code generation, as well as Bash and SQL\nscripting.\n",
                "链接": "https://arxiv.org/abs/2312.08976"
            },
            {
                "文章ID": "119060",
                "标题": "Self-Infilling Code Generation",
                "作者": " Lin Zheng,  Jianbo Yuan,  Zhi Zhang,  Hongxia Yang,  Lingpeng Kong",
                "发布日期": "2023-12-01",
                "摘要": "  This work introduces a general code generation framework that incorporates\ninfilling operations into auto-regressive decoding. Our approach capitalizes on\nthe observation that recent code language models with infilling capabilities\ncan perform \\emph{self-infilling}: whereas infilling operations aim to fill in\nthe middle based on a predefined prefix and suffix, self-infilling sequentially\ngenerates both such surrounding context and the infilled content. We utilize\nthis feature to develop an infilling-augmented decoding process that\nfacilitates non-monotonic generation. This approach allows for postponing the\ngeneration of uncertain code snippets until a definitive suffix is established,\nleading to improved control over the generation sequence. In addition, it\nfacilitates a looping mechanism, which can iteratively update and synchronize\neach piece of generation in a cyclic manner. Extensive experiments are\nconducted to demonstrate that our proposed decoding process is effective in\nenhancing regularity and quality across several code generation benchmarks.\n",
                "链接": "https://arxiv.org/abs/2311.17972"
            },
            {
                "文章ID": "24006",
                "标题": "StructCoder: Structure-Aware Transformer for Code Generation",
                "作者": " Sindhu Tipirneni,  Ming Zhu,  Chandan K. Reddy",
                "发布日期": "2023-06-02",
                "摘要": "  There has been a recent surge of interest in automating software engineering\ntasks using deep learning. This paper addresses the problem of code generation\nwhere the goal is to generate target code given source code in a different\nlanguage or a natural language description. Most of the state-of-the-art deep\nlearning models for code generation use training strategies primarily designed\nfor natural language. However, understanding and generating code requires a\nmore rigorous comprehension of the code syntax and semantics. With this\nmotivation, we develop an encoder-decoder Transformer model where both the\nencoder and decoder are explicitly trained to recognize the syntax and data\nflow in the source and target codes, respectively. We not only make the encoder\nstructure-aware by leveraging the source code's syntax tree and data flow\ngraph, but we also support the decoder in preserving the syntax and data flow\nof the target code by introducing two novel auxiliary tasks: AST (Abstract\nSyntax Tree) paths prediction and data flow prediction. To the best of our\nknowledge, this is the first work to introduce a structure-aware Transformer\ndecoder that models both syntax and data flow to enhance the quality of\ngenerated code. The proposed StructCoder model achieves state-of-the-art\nperformance on code translation and text-to-code generation tasks in the\nCodeXGLUE benchmark, and improves over baselines of similar size on the APPS\ncode generation benchmark. Our code is publicly available at\nhttps://github.com/reddy-lab-code-research/StructCoder/.\n",
                "链接": "https://arxiv.org/abs/2206.05239"
            },
            {
                "文章ID": "69960",
                "标题": "AceCoder: Utilizing Existing Code to Enhance Code Generation",
                "作者": " Jia Li,  Yunfei Zhao,  Yongmin Li,  Ge Li,  Zhi Jin",
                "发布日期": "2023-09-08",
                "摘要": "  Large Language Models (LLMs) have shown great success in code generation.\nLLMs take as the input a prompt and output the code. A key question is how to\nmake prompts (i.e., Prompting Techniques). Existing prompting techniques are\ndesigned for natural language generation and have low accuracy in code\ngeneration.\n  In this paper, we propose a new prompting technique named AceCoder. Our\nmotivation is that code generation meets two unique challenges (i.e.,\nrequirement understanding and code implementation). AceCoder contains two novel\nmechanisms (i.e., guided code generation and example retrieval) to solve these\nchallenges. (1) Guided code generation asks LLMs first to analyze requirements\nand output an intermediate preliminary (e.g., test cases). The preliminary is\nused to clarify requirements and tell LLMs \"what to write\". (2) Example\nretrieval selects similar programs as examples in prompts, which provide lots\nof relevant content (e.g., algorithms, APIs) and teach LLMs \"how to write\". We\napply AceCoder to three LLMs (e.g., Codex) and evaluate it on three public\nbenchmarks using the Pass@k. Results show that AceCoder can significantly\nimprove the performance of LLMs on code generation. (1) In terms of Pass@1,\nAceCoder outperforms the state-of-the-art baseline by up to 56.4% in MBPP,\n70.7% in MBJP, and 88.4% in MBJSP. (2) AceCoder is effective in LLMs with\ndifferent sizes (i.e., 6B to 13B) and different languages (i.e., Python, Java,\nand JavaScript). (3) Human evaluation shows human developers prefer programs\nfrom AceCoder.\n",
                "链接": "https://arxiv.org/abs/2303.17780"
            },
            {
                "文章ID": "91293",
                "标题": "A Lightweight Framework for High-Quality Code Generation",
                "作者": " Mohammed Latif Siddiq,  Beatrice Casey,  Joanna C. S. Santos",
                "发布日期": "2023-07-18",
                "摘要": "  In recent years, the use of automated source code generation utilizing\ntransformer-based generative models has expanded, and these models can generate\nfunctional code according to the requirements of the developers. However,\nrecent research revealed that these automatically generated source codes can\ncontain vulnerabilities and other quality issues. Despite researchers' and\npractitioners' attempts to enhance code generation models, retraining and\nfine-tuning large language models is time-consuming and resource-intensive.\nThus, we describe FRANC, a lightweight framework for recommending more secure\nand high-quality source code derived from transformer-based code generation\nmodels. FRANC includes a static filter to make the generated code compilable\nwith heuristics and a quality-aware ranker to sort the code snippets based on a\nquality score. Moreover, the framework uses prompt engineering to fix\npersistent quality issues. We evaluated the framework with five Python and Java\ncode generation models and six prompt datasets, including a newly created one\nin this work (SOEval). The static filter improves 9% to 46% Java suggestions\nand 10% to 43% Python suggestions regarding compilability. The average\nimprovement over the NDCG@10 score for the ranking system is 0.0763, and the\nrepairing techniques repair the highest 80% of prompts. FRANC takes, on\naverage, 1.98 seconds for Java; for Python, it takes 0.08 seconds.\n",
                "链接": "https://arxiv.org/abs/2307.08220"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下关于大模型使用工具的安全性的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "73408",
                "标题": "Safety Assessment of Chinese Large Language Models",
                "作者": " Hao Sun,  Zhexin Zhang,  Jiawen Deng,  Jiale Cheng,  Minlie Huang",
                "发布日期": "2023-04-21",
                "摘要": "  With the rapid popularity of large language models such as ChatGPT and GPT-4,\na growing amount of attention is paid to their safety concerns. These models\nmay generate insulting and discriminatory content, reflect incorrect social\nvalues, and may be used for malicious purposes such as fraud and dissemination\nof misleading information. Evaluating and enhancing their safety is\nparticularly essential for the wide application of large language models\n(LLMs). To further promote the safe deployment of LLMs, we develop a Chinese\nLLM safety assessment benchmark. Our benchmark explores the comprehensive\nsafety performance of LLMs from two perspectives: 8 kinds of typical safety\nscenarios and 6 types of more challenging instruction attacks. Our benchmark is\nbased on a straightforward process in which it provides the test prompts and\nevaluates the safety of the generated responses from the evaluated model. In\nevaluation, we utilize the LLM's strong evaluation ability and develop it as a\nsafety evaluator by prompting. On top of this benchmark, we conduct safety\nassessments and analyze 15 LLMs including the OpenAI GPT series and other\nwell-known Chinese LLMs, where we observe some interesting findings. For\nexample, we find that instruction attacks are more likely to expose safety\nissues of all LLMs. Moreover, to promote the development and deployment of\nsafe, responsible, and ethical AI, we publicly release SafetyPrompts including\n100k augmented prompts and responses by LLMs.\n",
                "链接": "https://arxiv.org/abs/2304.10436"
            },
            {
                "文章ID": "102063",
                "标题": "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language\n  Models that Follow Instructions",
                "作者": " Federico Bianchi,  Mirac Suzgun,  Giuseppe Attanasio,  Paul Röttger,  Dan Jurafsky,  Tatsunori Hashimoto,  James Zou",
                "发布日期": "2023-09-26",
                "摘要": "  Training large language models to follow instructions makes them perform\nbetter on a wide range of tasks, generally becoming more helpful. However, a\nperfectly helpful model will follow even the most malicious instructions and\nreadily generate harmful content. In this paper, we raise concerns over the\nsafety of models that only emphasize helpfulness, not safety, in their\ninstruction-tuning. We show that several popular instruction-tuned models are\nhighly unsafe. Moreover, we show that adding just 3% safety examples (a few\nhundred demonstrations) in the training set when fine-tuning a model like LLaMA\ncan substantially improve their safety. Our safety-tuning does not make models\nsignificantly less capable or helpful as measured by standard benchmarks.\nHowever, we do find a behavior of exaggerated safety, where too much\nsafety-tuning makes models refuse to respond to reasonable prompts that\nsuperficially resemble unsafe ones. Our study sheds light on trade-offs in\ntraining LLMs to follow instructions and exhibit safe behavior.\n",
                "链接": "https://arxiv.org/abs/2309.07875"
            },
            {
                "文章ID": "107434",
                "标题": "SC-Safety: A Multi-round Open-ended Question Adversarial Safety\n  Benchmark for Large Language Models in Chinese",
                "作者": " Liang Xu,  Kangkang Zhao,  Lei Zhu,  Hang Xue",
                "发布日期": "2023-10-10",
                "摘要": "  Large language models (LLMs), like ChatGPT and GPT-4, have demonstrated\nremarkable abilities in natural language understanding and generation. However,\nalongside their positive impact on our daily tasks, they can also produce\nharmful content that negatively affects societal perceptions. To systematically\nassess the safety of Chinese LLMs, we introduce SuperCLUE-Safety (SC-Safety) -\na multi-round adversarial benchmark with 4912 open-ended questions covering\nmore than 20 safety sub-dimensions. Adversarial human-model interactions and\nconversations significantly increase the challenges compared to existing\nmethods. Experiments on 13 major LLMs supporting Chinese yield the following\ninsights: 1) Closed-source models outperform open-sourced ones in terms of\nsafety; 2) Models released from China demonstrate comparable safety levels to\nLLMs like GPT-3.5-turbo; 3) Some smaller models with 6B-13B parameters can\ncompete effectively in terms of safety. By introducing SC-Safety, we aim to\npromote collaborative efforts to create safer and more trustworthy LLMs. The\nbenchmark and findings provide guidance on model selection. Our benchmark can\nbe found at https://www.CLUEbenchmarks.com\n",
                "链接": "https://arxiv.org/abs/2310.05818"
            },
            {
                "文章ID": "105613",
                "标题": "All Languages Matter: On the Multilingual Safety of Large Language\n  Models",
                "作者": " Wenxuan Wang,  Zhaopeng Tu,  Chang Chen,  Youliang Yuan,  Jen-tse Huang,  Wenxiang Jiao,  Michael R. Lyu",
                "发布日期": "2023-10-03",
                "摘要": "  Safety lies at the core of developing and deploying large language models\n(LLMs). However, previous safety benchmarks only concern the safety in one\nlanguage, e.g. the majority language in the pretraining data such as English.\nIn this work, we build the first multilingual safety benchmark for LLMs,\nXSafety, in response to the global deployment of LLMs in practice. XSafety\ncovers 14 kinds of commonly used safety issues across 10 languages that span\nseveral language families. We utilize XSafety to empirically study the\nmultilingual safety for 4 widely-used LLMs, including both close-API and\nopen-source models. Experimental results show that all LLMs produce\nsignificantly more unsafe responses for non-English queries than English ones,\nindicating the necessity of developing safety alignment for non-English\nlanguages. In addition, we propose several simple and effective prompting\nmethods to improve the multilingual safety of ChatGPT by evoking safety\nknowledge and improving cross-lingual generalization of safety alignment. Our\nprompting method can significantly reduce the ratio of unsafe responses from\n19.1% to 9.7% for non-English queries. We release our data at\nhttps://github.com/Jarviswang94/Multilingual_safety_benchmark.\n",
                "链接": "https://arxiv.org/abs/2310.00905"
            },
            {
                "文章ID": "30420",
                "标题": "Security and Safety Aspects of AI in Industry Applications",
                "作者": " Hans Dermot Doran",
                "发布日期": "2022-07-25",
                "摘要": "  In this relatively informal discussion-paper we summarise issues in the\ndomains of safety and security in machine learning that will affect industry\nsectors in the next five to ten years. Various products using neural network\nclassification, most often in vision related applications but also in\npredictive maintenance, have been researched and applied in real-world\napplications in recent years. Nevertheless, reports of underlying problems in\nboth safety and security related domains, for instance adversarial attacks have\nunsettled early adopters and are threatening to hinder wider scale adoption of\nthis technology. The problem for real-world applicability lies in being able to\nassess the risk of applying these technologies. In this discussion-paper we\ndescribe the process of arriving at a machine-learnt neural network classifier\npointing out safety and security vulnerabilities in that workflow, citing\nrelevant research where appropriate.\n",
                "链接": "https://arxiv.org/abs/2207.10809"
            },
            {
                "文章ID": "112959",
                "标题": "Robust Safety Classifier for Large Language Models: Adversarial Prompt\n  Shield",
                "作者": " Jinhwa Kim,  Ali Derakhshan,  Ian G. Harris",
                "发布日期": "2023-11-02",
                "摘要": "  Large Language Models' safety remains a critical concern due to their\nvulnerability to adversarial attacks, which can prompt these systems to produce\nharmful responses. In the heart of these systems lies a safety classifier, a\ncomputational model trained to discern and mitigate potentially harmful,\noffensive, or unethical outputs. However, contemporary safety classifiers,\ndespite their potential, often fail when exposed to inputs infused with\nadversarial noise. In response, our study introduces the Adversarial Prompt\nShield (APS), a lightweight model that excels in detection accuracy and\ndemonstrates resilience against adversarial prompts. Additionally, we propose\nnovel strategies for autonomously generating adversarial training datasets,\nnamed Bot Adversarial Noisy Dialogue (BAND) datasets. These datasets are\ndesigned to fortify the safety classifier's robustness, and we investigate the\nconsequences of incorporating adversarial examples into the training process.\nThrough evaluations involving Large Language Models, we demonstrate that our\nclassifier has the potential to decrease the attack success rate resulting from\nadversarial attacks by up to 60%. This advancement paves the way for the next\ngeneration of more reliable and resilient conversational agents.\n",
                "链接": "https://arxiv.org/abs/2311.00172"
            },
            {
                "文章ID": "114317",
                "标题": "Unveiling Safety Vulnerabilities of Large Language Models",
                "作者": " George Kour,  Marcel Zalmanovici,  Naama Zwerdling,  Esther Goldbraich,  Ora Nova Fandina,  Ateret Anaby-Tavor,  Orna Raz,  Eitan Farchi",
                "发布日期": "2023-11-08",
                "摘要": "  As large language models become more prevalent, their possible harmful or\ninappropriate responses are a cause for concern. This paper introduces a unique\ndataset containing adversarial examples in the form of questions, which we call\nAttaQ, designed to provoke such harmful or inappropriate responses. We assess\nthe efficacy of our dataset by analyzing the vulnerabilities of various models\nwhen subjected to it. Additionally, we introduce a novel automatic approach for\nidentifying and naming vulnerable semantic regions - input semantic areas for\nwhich the model is likely to produce harmful outputs. This is achieved through\nthe application of specialized clustering techniques that consider both the\nsemantic similarity of the input attacks and the harmfulness of the model's\nresponses. Automatically identifying vulnerable semantic regions enhances the\nevaluation of model weaknesses, facilitating targeted improvements to its\nsafety mechanisms and overall reliability.\n",
                "链接": "https://arxiv.org/abs/2311.04124"
            },
            {
                "文章ID": "101815",
                "标题": "SafetyBench: Evaluating the Safety of Large Language Models with\n  Multiple Choice Questions",
                "作者": " Zhexin Zhang,  Leqi Lei,  Lindong Wu,  Rui Sun,  Yongkang Huang,  Chong Long,  Xiao Liu,  Xuanyu Lei,  Jie Tang,  Minlie Huang",
                "发布日期": "2023-09-14",
                "摘要": "  With the rapid development of Large Language Models (LLMs), increasing\nattention has been paid to their safety concerns. Consequently, evaluating the\nsafety of LLMs has become an essential task for facilitating the broad\napplications of LLMs. Nevertheless, the absence of comprehensive safety\nevaluation benchmarks poses a significant impediment to effectively assess and\nenhance the safety of LLMs. In this work, we present SafetyBench, a\ncomprehensive benchmark for evaluating the safety of LLMs, which comprises\n11,435 diverse multiple choice questions spanning across 7 distinct categories\nof safety concerns. Notably, SafetyBench also incorporates both Chinese and\nEnglish data, facilitating the evaluation in both languages. Our extensive\ntests over 25 popular Chinese and English LLMs in both zero-shot and few-shot\nsettings reveal a substantial performance advantage for GPT-4 over its\ncounterparts, and there is still significant room for improving the safety of\ncurrent LLMs. We believe SafetyBench will enable fast and comprehensive\nevaluation of LLMs' safety, and foster the development of safer LLMs. Data and\nevaluation guidelines are available at https://github.com/thu-coai/SafetyBench.\nSubmission entrance and leaderboard are available at\nhttps://llmbench.ai/safety.\n",
                "链接": "https://arxiv.org/abs/2309.07045"
            },
            {
                "文章ID": "119662",
                "标题": "Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective",
                "作者": " Yixuan Wang,  Ruochen Jiao,  Chengtian Lang,  Sinong Simon Zhan,  Chao Huang,  Zhaoran Wang,  Zhuoran Yang,  Qi Zhu",
                "发布日期": "2023-12-20",
                "摘要": "  Autonomous Driving (AD) faces crucial hurdles for commercial launch, notably\nin the form of diminished public trust and safety concerns from long-tail\nunforeseen driving scenarios. This predicament is due to the limitation of deep\nneural networks in AD software, which struggle with interpretability and\nexhibit poor generalization capabilities in out-of-distribution and uncertain\nscenarios. To this end, this paper advocates for the integration of Large\nLanguage Models (LLMs) into the AD system, leveraging their robust common-sense\nknowledge, reasoning abilities, and human-interaction capabilities. The\nproposed approach deploys the LLM as an intelligent decision-maker in planning,\nincorporating safety verifiers for contextual safety learning to enhance\noverall AD performance and safety. We present results from two case studies\nthat affirm the efficacy of our approach. We further discuss the potential\nintegration of LLM for other AD software components including perception,\nprediction, and simulation. Despite the observed challenges in the case\nstudies, the integration of LLMs is promising and beneficial for reinforcing\nboth safety and performance in AD.\n",
                "链接": "https://arxiv.org/abs/2312.00812"
            },
            {
                "文章ID": "108817",
                "标题": "ASSERT: Automated Safety Scenario Red Teaming for Evaluating the\n  Robustness of Large Language Models",
                "作者": " Alex Mei,  Sharon Levy,  William Yang Wang",
                "发布日期": "2023-11-14",
                "摘要": "  As large language models are integrated into society, robustness toward a\nsuite of prompts is increasingly important to maintain reliability in a\nhigh-variance environment.Robustness evaluations must comprehensively\nencapsulate the various settings in which a user may invoke an intelligent\nsystem. This paper proposes ASSERT, Automated Safety Scenario Red Teaming,\nconsisting of three methods -- semantically aligned augmentation, target\nbootstrapping, and adversarial knowledge injection. For robust safety\nevaluation, we apply these methods in the critical domain of AI safety to\nalgorithmically generate a test suite of prompts covering diverse robustness\nsettings -- semantic equivalence, related scenarios, and adversarial. We\npartition our prompts into four safety domains for a fine-grained analysis of\nhow the domain affects model performance. Despite dedicated safeguards in\nexisting state-of-the-art models, we find statistically significant performance\ndifferences of up to 11% in absolute classification accuracy among semantically\nrelated scenarios and error rates of up to 19% absolute error in zero-shot\nadversarial settings, raising concerns for users' physical safety.\n",
                "链接": "https://arxiv.org/abs/2310.09624"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下对使用GPT生成数据集的训练步骤进行改进的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "81391",
                "标题": "DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of\n  GPT-Generated Text",
                "作者": " Xianjun Yang,  Wei Cheng,  Yue Wu,  Linda Petzold,  William Yang Wang,  Haifeng Chen",
                "发布日期": "2023-10-05",
                "摘要": "  Large language models (LLMs) have notably enhanced the fluency and diversity\nof machine-generated text. However, this progress also presents a significant\nchallenge in detecting the origin of a given text, and current research on\ndetection methods lags behind the rapid evolution of LLMs. Conventional\ntraining-based methods have limitations in flexibility, particularly when\nadapting to new domains, and they often lack explanatory power. To address this\ngap, we propose a novel training-free detection strategy called Divergent\nN-Gram Analysis (DNA-GPT). Given a text, we first truncate it in the middle and\nthen use only the preceding portion as input to the LLMs to regenerate the new\nremaining parts. By analyzing the differences between the original and new\nremaining parts through N-gram analysis in black-box or probability divergence\nin white-box, we unveil significant discrepancies between the distribution of\nmachine-generated text and the distribution of human-written text. We conducted\nextensive experiments on the most advanced LLMs from OpenAI, including\ntext-davinci-003, GPT-3.5-turbo, and GPT-4, as well as open-source models such\nas GPT-NeoX-20B and LLaMa-13B. Results show that our zero-shot approach\nexhibits state-of-the-art performance in distinguishing between human and\nGPT-generated text on four English and one German dataset, outperforming\nOpenAI's own classifier, which is trained on millions of text. Additionally,\nour methods provide reasonable explanations and evidence to support our claim,\nwhich is a unique feature of explainable detection. Our method is also robust\nunder the revised text attack and can additionally solve model sourcing. Codes\nare available at https://github.com/Xianjun-Yang/DNA-GPT.\n",
                "链接": "https://arxiv.org/abs/2305.17359"
            },
            {
                "文章ID": "79102",
                "标题": "GPT Paternity Test: GPT Generated Text Detection with GPT Genetic\n  Inheritance",
                "作者": " Xiao Yu,  Yuang Qi,  Kejiang Chen,  Guoqiang Chen,  Xi Yang,  Pengyuan Zhu,  Weiming Zhang,  Nenghai Yu",
                "发布日期": "2023-05-23",
                "摘要": "  Large Language Models (LLMs) can generate texts that carry the risk of\nvarious misuses, including plagiarism, planting fake reviews on e-commerce\nplatforms, or creating fake social media postings that can sway election\nresults. Detecting whether a text is machine-generated has thus become\nincreasingly important. While machine-learning-based detection strategies\nexhibit superior performance, they often lack generalizability, limiting their\npracticality. In this work, we introduce GPT Paternity Test (GPT-Pat), which\nreliably detects machine-generated text across varied datasets. Given a text\nunder scrutiny, we leverage ChatGPT to generate a corresponding question and\nprovide a re-answer to the question. By comparing the similarity between the\noriginal text and the generated re-answered text, it can be determined whether\nthe text is machine-generated. GPT-Pat consists of a Siamese network to compute\nthe similarity between the original text and the generated re-answered text and\na binary classifier. Our method achieved an average accuracy of 94.57% on four\ngeneralization test sets, surpassing the state-of-the-art RoBERTa-based method\nby 12.34%. The accuracy drop of our method is only about half of that of the\nRoBERTa-based method when it is attacked by re-translation and polishing.\n",
                "链接": "https://arxiv.org/abs/2305.12519"
            },
            {
                "文章ID": "107579",
                "标题": "GPT-who: An Information Density-based Machine-Generated Text Detector",
                "作者": " Saranya Venkatraman,  Adaku Uchendu,  Dongwon Lee",
                "发布日期": "2023-10-11",
                "摘要": "  The Uniform Information Density principle posits that humans prefer to spread\ninformation evenly during language production. In this work, we examine if the\nUID principle can help capture differences between Large Language Models (LLMs)\nand human-generated text. We propose GPT-who, the first\npsycholinguistically-aware multi-class domain-agnostic statistical-based\ndetector. This detector employs UID-based features to model the unique\nstatistical signature of each LLM and human author for accurate authorship\nattribution. We evaluate our method using 4 large-scale benchmark datasets and\nfind that GPT-who outperforms state-of-the-art detectors (both statistical- &\nnon-statistical-based) such as GLTR, GPTZero, OpenAI detector, and ZeroGPT by\nover $20$% across domains. In addition to superior performance, it is\ncomputationally inexpensive and utilizes an interpretable representation of\ntext articles. We present the largest analysis of the UID-based representations\nof human and machine-generated texts (over 400k articles) to demonstrate how\nauthors distribute information differently, and in ways that enable their\ndetection using an off-the-shelf LM without any fine-tuning. We find that\nGPT-who can distinguish texts generated by very sophisticated LLMs, even when\nthe overlying text is indiscernible.\n",
                "链接": "https://arxiv.org/abs/2310.06202"
            },
            {
                "文章ID": "81655",
                "标题": "Game of Tones: Faculty detection of GPT-4 generated content in\n  university assessments",
                "作者": " Mike Perkins,  Jasper Roe,  Darius Postma,  James McGaughran,  Don Hickerson",
                "发布日期": "2023-11-02",
                "摘要": "  This study explores the robustness of university assessments against the use\nof Open AI's Generative Pre-Trained Transformer 4 (GPT-4) generated content and\nevaluates the ability of academic staff to detect its use when supported by the\nTurnitin Artificial Intelligence (AI) detection tool. The research involved\ntwenty-two GPT-4 generated submissions being created and included in the\nassessment process to be marked by fifteen different faculty members. The study\nreveals that although the detection tool identified 91% of the experimental\nsubmissions as containing some AI-generated content, the total detected content\nwas only 54.8%. This suggests that the use of adversarial techniques regarding\nprompt engineering is an effective method in evading AI detection tools and\nhighlights that improvements to AI detection software are needed. Using the\nTurnitin AI detect tool, faculty reported 54.5% of the experimental submissions\nto the academic misconduct process, suggesting the need for increased awareness\nand training into these tools. Genuine submissions received a mean score of\n54.4, whereas AI-generated content scored 52.3, indicating the comparable\nperformance of GPT-4 in real-life situations. Recommendations include adjusting\nassessment strategies to make them more resistant to the use of AI tools, using\nAI-inclusive assessment where possible, and providing comprehensive training\nprograms for faculty and students. This research contributes to understanding\nthe relationship between AI-generated content and academic assessment, urging\nfurther investigation to preserve academic integrity.\n",
                "链接": "https://arxiv.org/abs/2305.18081"
            },
            {
                "文章ID": "68065",
                "标题": "Generate labeled training data using Prompt Programming and GPT-3. An\n  example of Big Five Personality Classification",
                "作者": " Eason Chen",
                "发布日期": "2023-03-23",
                "摘要": "  We generated 25000 conversations labeled with Big Five Personality traits\nusing prompt programming at GPT-3. Then we train Big Five classification models\nwith these data and evaluate them with 2500 data from generated dialogues and\nreal conversational datasets labeled in Big Five by human annotators. The\nresults indicated that this approach is promising for creating effective\ntraining data. We then compare the performance by different training approaches\nand models. Our results suggest that using Adapter-Transformers and transfer\nlearning from pre-trained RoBERTa sentiment analysis model will perform best\nwith the generated data. Our best model obtained an accuracy of 0.71 in\ngenerated data and 0.65 in real datasets. Finally, we discuss this approach's\npotential limitations and confidence metric.\n",
                "链接": "https://arxiv.org/abs/2303.12279"
            },
            {
                "文章ID": "4574",
                "标题": "Semantic features of object concepts generated with GPT-3",
                "作者": " Hannes Hansen,  Martin N. Hebart",
                "发布日期": "2022-05-11",
                "摘要": "  Semantic features have been playing a central role in investigating the\nnature of our conceptual representations. Yet the enormous time and effort\nrequired to empirically sample and norm features from human raters has\nrestricted their use to a limited set of manually curated concepts. Given\nrecent promising developments with transformer-based language models, here we\nasked whether it was possible to use such models to automatically generate\nmeaningful lists of properties for arbitrary object concepts and whether these\nmodels would produce features similar to those found in humans. To this end, we\nprobed a GPT-3 model to generate semantic features for 1,854 objects and\ncompared automatically-generated features to existing human feature norms.\nGPT-3 generated many more features than humans, yet showed a similar\ndistribution in the types of generated features. Generated feature norms\nrivaled human norms in predicting similarity, relatedness, and category\nmembership, while variance partitioning demonstrated that these predictions\nwere driven by similar variance in humans and GPT-3. Together, these results\nhighlight the potential of large language models to capture important facets of\nhuman knowledge and yield a new approach for automatically generating\ninterpretable feature sets, thus drastically expanding the potential use of\nsemantic features in psychological and linguistic studies.\n",
                "链接": "https://arxiv.org/abs/2202.03753"
            },
            {
                "文章ID": "81531",
                "标题": "Evaluating GPT-3 Generated Explanations for Hateful Content Moderation",
                "作者": " Han Wang,  Ming Shan Hee,  Md Rabiul Awal,  Kenny Tsu Wei Choo,  Roy Ka-Wei Lee",
                "发布日期": "2023-08-31",
                "摘要": "  Recent research has focused on using large language models (LLMs) to generate\nexplanations for hate speech through fine-tuning or prompting. Despite the\ngrowing interest in this area, these generated explanations' effectiveness and\npotential limitations remain poorly understood. A key concern is that these\nexplanations, generated by LLMs, may lead to erroneous judgments about the\nnature of flagged content by both users and content moderators. For instance,\nan LLM-generated explanation might inaccurately convince a content moderator\nthat a benign piece of content is hateful. In light of this, we propose an\nanalytical framework for examining hate speech explanations and conducted an\nextensive survey on evaluating such explanations. Specifically, we prompted\nGPT-3 to generate explanations for both hateful and non-hateful content, and a\nsurvey was conducted with 2,400 unique respondents to evaluate the generated\nexplanations. Our findings reveal that (1) human evaluators rated the\nGPT-generated explanations as high quality in terms of linguistic fluency,\ninformativeness, persuasiveness, and logical soundness, (2) the persuasive\nnature of these explanations, however, varied depending on the prompting\nstrategy employed, and (3) this persuasiveness may result in incorrect\njudgments about the hatefulness of the content. Our study underscores the need\nfor caution in applying LLM-generated explanations for content moderation. Code\nand results are available at https://github.com/Social-AI-Studio/GPT3-HateEval.\n",
                "链接": "https://arxiv.org/abs/2305.17680"
            },
            {
                "文章ID": "20498",
                "标题": "Improving Short Text Classification With Augmented Data Using GPT-3",
                "作者": " Salvador Balkus,  Donghui Yan",
                "发布日期": "2023-08-29",
                "摘要": "  GPT-3 is a large-scale natural language model developed by OpenAI that can\nperform many different tasks, including topic classification. Although\nresearchers claim that it requires only a small number of in-context examples\nto learn a task, in practice GPT-3 requires these training examples to be\neither of exceptional quality or a higher quantity than easily created by hand.\nTo address this issue, this study teaches GPT-3 to classify whether a question\nis related to data science by augmenting a small training set with additional\nexamples generated by GPT-3 itself. This study compares two classifiers: the\nGPT-3 Classification Endpoint with augmented examples, and the GPT-3 Completion\nEndpoint with an optimal training set chosen using a genetic algorithm. We find\nthat while the augmented Completion Endpoint achieves upwards of 80 percent\nvalidation accuracy, using the augmented Classification Endpoint yields more\nconsistent accuracy on unseen examples. In this way, giving large-scale machine\nlearning models like GPT-3 the ability to propose their own additional training\nexamples can result in improved classification performance.\n",
                "链接": "https://arxiv.org/abs/2205.10981"
            },
            {
                "文章ID": "121374",
                "标题": "Sim-GPT: Text Similarity via GPT Annotated Data",
                "作者": " Shuhe Wang,  Beiming Cao,  Shengyu Zhang,  Xiaoya Li,  Jiwei Li,  Fei Wu,  Guoyin Wang,  Eduard Hovy",
                "发布日期": "2023-12-13",
                "摘要": "  Due to the lack of a large collection of high-quality labeled sentence pairs\nwith textual similarity scores, existing approaches for Semantic Textual\nSimilarity (STS) mostly rely on unsupervised techniques or training signals\nthat are only partially correlated with textual similarity, e.g., NLI-based\ndatasets. To tackle this issue, in this paper, we propose the strategy of\nmeasuring text similarity via GPT annotated data (Sim-GPT for short). The core\nidea of Sim-GPT is to generate data with STS labels using GPT-4, based on which\nan STS model is trained. Sim-GPT framework utilizes LLMs to provide a\nsubstantial amount of reliable annotated data filling the gap of the lack of\ntraining signals for STS. Sim-GPT is trained on a one-time generated dataset\nusing BERT or RoBERTa as the backbone, which offers long-term savings in cost\nand speed compared to repeatedly invoking LLMs for each sentence pair. Trained\non the examples from GPT-4 (371K), Sim-GPT yields SOTA performances on the\nwidely-used seven STS benchmarks: +0.99 over supervised-SimCSE, and +0.42 over\nthe current SOTA PromCSE model. To encourage further advancements of the field,\nwe release both models and the 371K annotated examples from GPT-4. Code, models\nand annotated data are available at: https://github.com/ShuheWang1998/Sim-GPT.\n",
                "链接": "https://arxiv.org/abs/2312.05603"
            },
            {
                "文章ID": "79177",
                "标题": "G3Detector: General GPT-Generated Text Detector",
                "作者": " Haolan Zhan,  Xuanli He,  Qiongkai Xu,  Yuxiang Wu,  Pontus Stenetorp",
                "发布日期": "2023-08-07",
                "摘要": "  The burgeoning progress in the field of Large Language Models (LLMs) heralds\nsignificant benefits due to their unparalleled capacities. However, it is\ncritical to acknowledge the potential misuse of these models, which could give\nrise to a spectrum of social and ethical dilemmas. Despite numerous preceding\nefforts centered around distinguishing synthetic text, most existing detection\nsystems fail to identify data synthesized by the latest LLMs, such as ChatGPT\nand GPT-4. In response to this challenge, we introduce an unpretentious yet\npotent detection approach proficient in identifying synthetic text across a\nwide array of fields. Moreover, our detector demonstrates outstanding\nperformance uniformly across various model architectures and decoding\nstrategies. It also possesses the capability to identify text generated\nutilizing a potent detection-evasion technique. Our comprehensive research\nunderlines our commitment to boosting the robustness and efficiency of\nmachine-generated text detection mechanisms, particularly in the context of\nswiftly progressing and increasingly adaptive AI technologies.\n",
                "链接": "https://arxiv.org/abs/2305.12680"
            }
        ]
    },
    {
        "question": {
            "question": "请找到利用clip做开放词汇检测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "121784",
                "标题": "OpenSD: Unified Open-Vocabulary Segmentation and Detection",
                "作者": " Shuai Li,  Minghan Li,  Pengfei Wang,  Lei Zhang",
                "发布日期": "2023-12-13",
                "摘要": "  Recently, a few open-vocabulary methods have been proposed by employing a\nunified architecture to tackle generic segmentation and detection tasks.\nHowever, their performance still lags behind the task-specific models due to\nthe conflict between different tasks, and their open-vocabulary capability is\nlimited due to the inadequate use of CLIP. To address these challenges, we\npresent a universal transformer-based framework, abbreviated as OpenSD, which\nutilizes the same architecture and network parameters to handle open-vocabulary\nsegmentation and detection tasks. First, we introduce a decoder decoupled\nlearning strategy to alleviate the semantic conflict between thing and staff\ncategories so that each individual task can be learned more effectively under\nthe same framework. Second, to better leverage CLIP for end-to-end segmentation\nand detection, we propose dual classifiers to handle the in-vocabulary domain\nand out-of-vocabulary domain, respectively. The text encoder is further trained\nto be region-aware for both thing and stuff categories through decoupled prompt\nlearning, enabling them to filter out duplicated and low-quality predictions,\nwhich is important to end-to-end segmentation and detection. Extensive\nexperiments are conducted on multiple datasets under various circumstances. The\nresults demonstrate that OpenSD outperforms state-of-the-art open-vocabulary\nsegmentation and detection methods in both closed- and open-vocabulary\nsettings. Code is available at https://github.com/strongwolf/OpenSD\n",
                "链接": "https://arxiv.org/abs/2312.06703"
            },
            {
                "文章ID": "116861",
                "标题": "CastDet: Toward Open Vocabulary Aerial Object Detection with\n  CLIP-Activated Student-Teacher Learning",
                "作者": " Yan Li,  Weiwei Guo,  Dunyun He,  Jiaqi Zhou,  Yuze Gao,  Wenxian Yu",
                "发布日期": "2023-11-21",
                "摘要": "  Object detection in aerial images is a pivotal task for various earth\nobservation applications, whereas current algorithms learn to detect only a\npre-defined set of object categories demanding sufficient bounding-box\nannotated training samples and fail to detect novel object categories. In this\npaper, we consider open-vocabulary object detection (OVD) in aerial images that\nenables the characterization of new objects beyond training categories on the\nearth surface without annotating training images for these new categories. The\nperformance of OVD depends on the quality of class-agnostic region proposals\nand pseudo-labels that can generalize well to novel object categories. To\nsimultaneously generate high-quality proposals and pseudo-labels, we propose\nCastDet, a CLIP-activated student-teacher open-vocabulary object Detection\nframework. Our end-to-end framework within the student-teacher mechanism\nemploys the CLIP model as an extra omniscient teacher of rich knowledge into\nthe student-teacher self-learning process. By doing so, our approach boosts\nnovel object proposals and classification. Furthermore, we design a dynamic\nlabel queue technique to maintain high-quality pseudo labels during batch\ntraining and mitigate label imbalance. We conduct extensive experiments on\nmultiple existing aerial object detection datasets, which are set up for the\nOVD task. Experimental results demonstrate our CastDet achieving superior\nopen-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean),\nwhich outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD\ndataset.\n",
                "链接": "https://arxiv.org/abs/2311.11646"
            },
            {
                "文章ID": "94707",
                "标题": "Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen\n  Convolutional CLIP",
                "作者": " Qihang Yu,  Ju He,  Xueqing Deng,  Xiaohui Shen,  Liang-Chieh Chen",
                "发布日期": "2023-11-16",
                "摘要": "  Open-vocabulary segmentation is a challenging task requiring segmenting and\nrecognizing objects from an open set of categories. One way to address this\nchallenge is to leverage multi-modal models, such as CLIP, to provide image and\ntext features in a shared embedding space, which bridges the gap between\nclosed-vocabulary and open-vocabulary recognition. Hence, existing methods\noften adopt a two-stage framework to tackle the problem, where the inputs first\ngo through a mask generator and then through the CLIP model along with the\npredicted masks. This process involves extracting features from images multiple\ntimes, which can be ineffective and inefficient. By contrast, we propose to\nbuild everything into a single-stage framework using a shared Frozen\nConvolutional CLIP backbone, which not only significantly simplifies the\ncurrent two-stage pipeline, but also remarkably yields a better accuracy-cost\ntrade-off. The proposed FC-CLIP, benefits from the following observations: the\nfrozen CLIP backbone maintains the ability of open-vocabulary classification\nand can also serve as a strong mask generator, and the convolutional CLIP\ngeneralizes well to a larger input resolution than the one used during\ncontrastive image-text pretraining. When training on COCO panoptic data only\nand testing in a zero-shot manner, FC-CLIP achieve 26.8 PQ, 16.8 AP, and 34.1\nmIoU on ADE20K, 18.2 PQ, 27.9 mIoU on Mapillary Vistas, 44.0 PQ, 26.8 AP, 56.2\nmIoU on Cityscapes, outperforming the prior art by +4.2 PQ, +2.4 AP, +4.2 mIoU\non ADE20K, +4.0 PQ on Mapillary Vistas and +20.1 PQ on Cityscapes,\nrespectively. Additionally, the training and testing time of FC-CLIP is 7.5x\nand 6.6x significantly faster than the same prior art, while using 5.9x fewer\nparameters. FC-CLIP also sets a new state-of-the-art performance across various\nopen-vocabulary semantic segmentation datasets. Code at\nhttps://github.com/bytedance/fc-clip\n",
                "链接": "https://arxiv.org/abs/2308.02487"
            },
            {
                "文章ID": "68353",
                "标题": "CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting\n  and Anchor Pre-Matching",
                "作者": " Xiaoshi Wu,  Feng Zhu,  Rui Zhao,  Hongsheng Li",
                "发布日期": "2023-03-24",
                "摘要": "  Open-vocabulary detection (OVD) is an object detection task aiming at\ndetecting objects from novel categories beyond the base categories on which the\ndetector is trained. Recent OVD methods rely on large-scale visual-language\npre-trained models, such as CLIP, for recognizing novel objects. We identify\nthe two core obstacles that need to be tackled when incorporating these models\ninto detector training: (1) the distribution mismatch that happens when\napplying a VL-model trained on whole images to region recognition tasks; (2)\nthe difficulty of localizing objects of unseen classes. To overcome these\nobstacles, we propose CORA, a DETR-style framework that adapts CLIP for\nOpen-vocabulary detection by Region prompting and Anchor pre-matching. Region\nprompting mitigates the whole-to-region distribution gap by prompting the\nregion features of the CLIP-based region classifier. Anchor pre-matching helps\nlearning generalizable object localization by a class-aware matching mechanism.\nWe evaluate CORA on the COCO OVD benchmark, where we achieve 41.7 AP50 on novel\nclasses, which outperforms the previous SOTA by 2.4 AP50 even without resorting\nto extra training data. When extra training data is available, we train\nCORA$^+$ on both ground-truth base-category annotations and additional pseudo\nbounding box labels computed by CORA. CORA$^+$ achieves 43.1 AP50 on the COCO\nOVD benchmark and 28.1 box APr on the LVIS OVD benchmark.\n",
                "链接": "https://arxiv.org/abs/2303.13076"
            },
            {
                "文章ID": "119030",
                "标题": "Active Open-Vocabulary Recognition: Let Intelligent Moving Mitigate CLIP\n  Limitations",
                "作者": " Lei Fan,  Jianxiong Zhou,  Xiaoying Xing,  Ying Wu",
                "发布日期": "2023-12-01",
                "摘要": "  Active recognition, which allows intelligent agents to explore observations\nfor better recognition performance, serves as a prerequisite for various\nembodied AI tasks, such as grasping, navigation and room arrangements. Given\nthe evolving environment and the multitude of object classes, it is impractical\nto include all possible classes during the training stage. In this paper, we\naim at advancing active open-vocabulary recognition, empowering embodied agents\nto actively perceive and classify arbitrary objects. However, directly adopting\nrecent open-vocabulary classification models, like Contrastive Language Image\nPretraining (CLIP), poses its unique challenges. Specifically, we observe that\nCLIP's performance is heavily affected by the viewpoint and occlusions,\ncompromising its reliability in unconstrained embodied perception scenarios.\nFurther, the sequential nature of observations in agent-environment\ninteractions necessitates an effective method for integrating features that\nmaintains discriminative strength for open-vocabulary classification. To\naddress these issues, we introduce a novel agent for active open-vocabulary\nrecognition. The proposed method leverages inter-frame and inter-concept\nsimilarities to navigate agent movements and to fuse features, without relying\non class-specific knowledge. Compared to baseline CLIP model with 29.6%\naccuracy on ShapeNet dataset, the proposed agent could achieve 53.3% accuracy\nfor open-vocabulary recognition, without any fine-tuning to the equipped CLIP\nmodel. Additional experiments conducted with the Habitat simulator further\naffirm the efficacy of our method.\n",
                "链接": "https://arxiv.org/abs/2311.17938"
            },
            {
                "文章ID": "41351",
                "标题": "Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP",
                "作者": " Feng Liang,  Bichen Wu,  Xiaoliang Dai,  Kunpeng Li,  Yinan Zhao,  Hang Zhang,  Peizhao Zhang,  Peter Vajda,  Diana Marculescu",
                "发布日期": "2023-04-04",
                "摘要": "  Open-vocabulary semantic segmentation aims to segment an image into semantic\nregions according to text descriptions, which may not have been seen during\ntraining. Recent two-stage methods first generate class-agnostic mask proposals\nand then leverage pre-trained vision-language models, e.g., CLIP, to classify\nmasked regions. We identify the performance bottleneck of this paradigm to be\nthe pre-trained CLIP model, since it does not perform well on masked images. To\naddress this, we propose to finetune CLIP on a collection of masked image\nregions and their corresponding text descriptions. We collect training data by\nmining an existing image-caption dataset (e.g., COCO Captions), using CLIP to\nmatch masked image regions to nouns in the image captions. Compared with the\nmore precise and manually annotated segmentation labels with fixed classes\n(e.g., COCO-Stuff), we find our noisy but diverse dataset can better retain\nCLIP's generalization ability. Along with finetuning the entire model, we\nutilize the \"blank\" areas in masked images using a method we dub mask prompt\ntuning. Experiments demonstrate mask prompt tuning brings significant\nimprovement without modifying any weights of CLIP, and it can further improve a\nfully finetuned model. In particular, when trained on COCO and evaluated on\nADE20K-150, our best model achieves 29.6% mIoU, which is +8.5% higher than the\nprevious state-of-the-art. For the first time, open-vocabulary generalist\nmodels match the performance of supervised specialist models in 2017 without\ndataset-specific adaptations.\n",
                "链接": "https://arxiv.org/abs/2210.04150"
            },
            {
                "文章ID": "50058",
                "标题": "Open-vocabulary Attribute Detection",
                "作者": " María A. Bravo,  Sudhanshu Mittal,  Simon Ging,  Thomas Brox",
                "发布日期": "2023-03-10",
                "摘要": "  Vision-language modeling has enabled open-vocabulary tasks where predictions\ncan be queried using any text prompt in a zero-shot manner. Existing\nopen-vocabulary tasks focus on object classes, whereas research on object\nattributes is limited due to the lack of a reliable attribute-focused\nevaluation benchmark. This paper introduces the Open-Vocabulary Attribute\nDetection (OVAD) task and the corresponding OVAD benchmark. The objective of\nthe novel task and benchmark is to probe object-level attribute information\nlearned by vision-language models. To this end, we created a clean and densely\nannotated test set covering 117 attribute classes on the 80 object classes of\nMS COCO. It includes positive and negative annotations, which enables\nopen-vocabulary evaluation. Overall, the benchmark consists of 1.4 million\nannotations. For reference, we provide a first baseline method for\nopen-vocabulary attribute detection. Moreover, we demonstrate the benchmark's\nvalue by studying the attribute detection performance of several foundation\nmodels. Project page https://ovad-benchmark.github.io\n",
                "链接": "https://arxiv.org/abs/2211.12914"
            },
            {
                "文章ID": "104220",
                "标题": "CLIP-DIY: CLIP Dense Inference Yields Open-Vocabulary Semantic\n  Segmentation For-Free",
                "作者": " Monika Wysoczańska,  Michaël Ramamonjisoa,  Tomasz Trzciński,  Oriane Siméoni",
                "发布日期": "2023-11-29",
                "摘要": "  The emergence of CLIP has opened the way for open-world image perception. The\nzero-shot classification capabilities of the model are impressive but are\nharder to use for dense tasks such as image segmentation. Several methods have\nproposed different modifications and learning schemes to produce dense output.\nInstead, we propose in this work an open-vocabulary semantic segmentation\nmethod, dubbed CLIP-DIY, which does not require any additional training or\nannotations, but instead leverages existing unsupervised object localization\napproaches. In particular, CLIP-DIY is a multi-scale approach that directly\nexploits CLIP classification abilities on patches of different sizes and\naggregates the decision in a single map. We further guide the segmentation\nusing foreground/background scores obtained using unsupervised object\nlocalization methods. With our method, we obtain state-of-the-art zero-shot\nsemantic segmentation results on PASCAL VOC and perform on par with the best\nmethods on COCO. The code is available at\nhttp://github.com/wysoczanska/clip-diy\n",
                "链接": "https://arxiv.org/abs/2309.14289"
            },
            {
                "文章ID": "68854",
                "标题": "Prompt-Guided Transformers for End-to-End Open-Vocabulary Object\n  Detection",
                "作者": " Hwanjun Song,  Jihwan Bang",
                "发布日期": "2023-03-28",
                "摘要": "  Prompt-OVD is an efficient and effective framework for open-vocabulary object\ndetection that utilizes class embeddings from CLIP as prompts, guiding the\nTransformer decoder to detect objects in both base and novel classes.\nAdditionally, our novel RoI-based masked attention and RoI pruning techniques\nhelp leverage the zero-shot classification ability of the Vision\nTransformer-based CLIP, resulting in improved detection performance at minimal\ncomputational cost. Our experiments on the OV-COCO and OVLVIS datasets\ndemonstrate that Prompt-OVD achieves an impressive 21.2 times faster inference\nspeed than the first end-to-end open-vocabulary detection method (OV-DETR),\nwhile also achieving higher APs than four two-stage-based methods operating\nwithin similar inference time ranges. Code will be made available soon.\n",
                "链接": "https://arxiv.org/abs/2303.14386"
            },
            {
                "文章ID": "71939",
                "标题": "CLIP Surgery for Better Explainability with Enhancement in\n  Open-Vocabulary Tasks",
                "作者": " Yi Li,  Hualiang Wang,  Yiqun Duan,  Xiaomeng Li",
                "发布日期": "2023-04-13",
                "摘要": "  Contrastive Language-Image Pre-training (CLIP) is a powerful multimodal large\nvision model that has demonstrated significant benefits for downstream tasks,\nincluding many zero-shot learning and text-guided vision tasks. However, we\nnotice some severe problems regarding the model's explainability, which\nundermines its credibility and impedes related tasks. Specifically, we find\nCLIP prefers the background regions than the foregrounds according to the\npredicted similarity map, which contradicts human understanding. Besides, there\nare obvious noisy activations on the visualization results at irrelevant\npositions. To address these two issues, we conduct in-depth analyses and reveal\nthe reasons with new findings and evidences. Based on these insights, we\npropose the CLIP Surgery, a method that enables surgery-like modifications for\nthe inference architecture and features, for better explainability and\nenhancement in multiple open-vocabulary tasks. The proposed method has\nsignificantly improved the explainability of CLIP for both convolutional\nnetworks and vision transformers, surpassing existing methods by large margins.\nBesides, our approach also demonstrates remarkable improvements in\nopen-vocabulary segmentation and multi-label recognition tasks. For examples,\nthe mAP improvement on NUS-Wide multi-label recognition is 4.41% without any\nadditional training, and our CLIP Surgery surpasses the state-of-the-art method\nby 8.74% at mIoU on Cityscapes open-vocabulary semantic segmentation.\nFurthermore, our method benefits other tasks including multimodal visualization\nand interactive segmentation like Segment Anything Model (SAM). The code is\navailable at https://github.com/xmed-lab/CLIP_Surgery\n",
                "链接": "https://arxiv.org/abs/2304.05653"
            }
        ]
    },
    {
        "question": {
            "question": "请找到使用自蒸馏加强目标检测性能的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "65588",
                "标题": "Smooth and Stepwise Self-Distillation for Object Detection",
                "作者": " Jieren Deng,  Xin Zhou,  Hao Tian,  Zhihong Pan,  Derek Aguiar",
                "发布日期": "2023-03-10",
                "摘要": "  Distilling the structured information captured in feature maps has\ncontributed to improved results for object detection tasks, but requires\ncareful selection of baseline architectures and substantial pre-training.\nSelf-distillation addresses these limitations and has recently achieved\nstate-of-the-art performance for object detection despite making several\nsimplifying architectural assumptions. Building on this work, we propose Smooth\nand Stepwise Self-Distillation (SSSD) for object detection. Our SSSD\narchitecture forms an implicit teacher from object labels and a feature pyramid\nnetwork backbone to distill label-annotated feature maps using Jensen-Shannon\ndistance, which is smoother than distillation losses used in prior work. We\nadditionally add a distillation coefficient that is adaptively configured based\non the learning rate. We extensively benchmark SSSD against a baseline and two\nstate-of-the-art object detector architectures on the COCO dataset by varying\nthe coefficients and backbone and detector networks. We demonstrate that SSSD\nachieves higher average precision in most experimental settings, is robust to a\nwide range of coefficients, and benefits from our stepwise distillation\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2303.05015"
            },
            {
                "文章ID": "92560",
                "标题": "Spatial Self-Distillation for Object Detection with Inaccurate Bounding\n  Boxes",
                "作者": " Di Wu,  Pengfei Chen,  Xuehui Yu,  Guorong Li,  Zhenjun Han,  Jianbin Jiao",
                "发布日期": "2023-08-16",
                "摘要": "  Object detection via inaccurate bounding boxes supervision has boosted a\nbroad interest due to the expensive high-quality annotation data or the\noccasional inevitability of low annotation quality (\\eg tiny objects). The\nprevious works usually utilize multiple instance learning (MIL), which highly\ndepends on category information, to select and refine a low-quality box. Those\nmethods suffer from object drift, group prediction and part domination problems\nwithout exploring spatial information. In this paper, we heuristically propose\na \\textbf{Spatial Self-Distillation based Object Detector (SSD-Det)} to mine\nspatial information to refine the inaccurate box in a self-distillation\nfashion. SSD-Det utilizes a Spatial Position Self-Distillation \\textbf{(SPSD)}\nmodule to exploit spatial information and an interactive structure to combine\nspatial information and category information, thus constructing a high-quality\nproposal bag. To further improve the selection procedure, a Spatial Identity\nSelf-Distillation \\textbf{(SISD)} module is introduced in SSD-Det to obtain\nspatial confidence to help select the best proposals. Experiments on MS-COCO\nand VOC datasets with noisy box annotation verify our method's effectiveness\nand achieve state-of-the-art performance. The code is available at\nhttps://github.com/ucas-vg/PointTinyBenchmark/tree/SSD-Det.\n",
                "链接": "https://arxiv.org/abs/2307.12101"
            },
            {
                "文章ID": "17577",
                "标题": "Cross Domain Object Detection by Target-Perceived Dual Branch\n  Distillation",
                "作者": " Mengzhe He,  Yali Wang,  Jiaxi Wu,  Yiru Wang,  Hanqing Li,  Bo Li,  Weihao Gan,  Wei Wu,  Yu Qiao",
                "发布日期": "2022-05-04",
                "摘要": "  Cross domain object detection is a realistic and challenging task in the\nwild. It suffers from performance degradation due to large shift of data\ndistributions and lack of instance-level annotations in the target domain.\nExisting approaches mainly focus on either of these two difficulties, even\nthough they are closely coupled in cross domain object detection. To solve this\nproblem, we propose a novel Target-perceived Dual-branch Distillation (TDD)\nframework. By integrating detection branches of both source and target domains\nin a unified teacher-student learning scheme, it can reduce domain shift and\ngenerate reliable supervision effectively. In particular, we first introduce a\ndistinct Target Proposal Perceiver between two domains. It can adaptively\nenhance source detector to perceive objects in a target image, by leveraging\ntarget proposal contexts from iterative cross-attention. Afterwards, we design\na concise Dual Branch Self Distillation strategy for model training, which can\nprogressively integrate complementary object knowledge from different domains\nvia self-distillation in two branches. Finally, we conduct extensive\nexperiments on a number of widely-used scenarios in cross domain object\ndetection. The results show that our TDD significantly outperforms the\nstate-of-the-art methods on all the benchmarks. Our code and model will be\navailable at https://github.com/Feobi1999/TDD.\n",
                "链接": "https://arxiv.org/abs/2205.01291"
            },
            {
                "文章ID": "114760",
                "标题": "Object-centric Cross-modal Feature Distillation for Event-based Object\n  Detection",
                "作者": " Lei Li,  Alexander Liniger,  Mario Millhaeusler,  Vagia Tsiminaki,  Yuanyou Li,  Dengxin Dai",
                "发布日期": "2023-11-10",
                "摘要": "  Event cameras are gaining popularity due to their unique properties, such as\ntheir low latency and high dynamic range. One task where these benefits can be\ncrucial is real-time object detection. However, RGB detectors still outperform\nevent-based detectors due to the sparsity of the event data and missing visual\ndetails. In this paper, we develop a novel knowledge distillation approach to\nshrink the performance gap between these two modalities. To this end, we\npropose a cross-modality object detection distillation method that by design\ncan focus on regions where the knowledge distillation works best. We achieve\nthis by using an object-centric slot attention mechanism that can iteratively\ndecouple features maps into object-centric features and corresponding\npixel-features used for distillation. We evaluate our novel distillation\napproach on a synthetic and a real event dataset with aligned grayscale images\nas a teacher modality. We show that object-centric distillation allows to\nsignificantly improve the performance of the event-based student object\ndetector, nearly halving the performance gap with respect to the teacher.\n",
                "链接": "https://arxiv.org/abs/2311.05494"
            },
            {
                "文章ID": "59214",
                "标题": "AMD: Adaptive Masked Distillation for Object Detection",
                "作者": " Guang Yang,  Yin Tang,  Jun Li,  Jianhua Xu,  Xili Wan",
                "发布日期": "2023-02-13",
                "摘要": "  As a general model compression paradigm, feature-based knowledge distillation\nallows the student model to learn expressive features from the teacher\ncounterpart. In this paper, we mainly focus on designing an effective\nfeature-distillation framework and propose a spatial-channel adaptive masked\ndistillation (AMD) network for object detection. More specifically, in order to\naccurately reconstruct important feature regions, we first perform\nattention-guided feature masking on the feature map of the student network,\nsuch that we can identify the important features via spatially adaptive feature\nmasking instead of random masking in the previous methods. In addition, we\nemploy a simple and efficient module to allow the student network channel to be\nadaptive, improving its model capability in object perception and detection. In\ncontrast to the previous methods, more crucial object-aware features can be\nreconstructed and learned from the proposed network, which is conducive to\naccurate object detection. The empirical experiments demonstrate the\nsuperiority of our method: with the help of our proposed distillation method,\nthe student networks report 41.3%, 42.4%, and 42.7% mAP scores when RetinaNet,\nCascade Mask-RCNN and RepPoints are respectively used as the teacher framework\nfor object detection, which outperforms the previous state-of-the-art\ndistillation methods including FGD and MGD.\n",
                "链接": "https://arxiv.org/abs/2301.13538"
            },
            {
                "文章ID": "65873",
                "标题": "Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection",
                "作者": " Luting Wang,  Yi Liu,  Penghui Du,  Zihan Ding,  Yue Liao,  Qiaosong Qi,  Biaolong Chen,  Si Liu",
                "发布日期": "2023-03-13",
                "摘要": "  Open-vocabulary object detection aims to provide object detectors trained on\na fixed set of object categories with the generalizability to detect objects\ndescribed by arbitrary text queries. Previous methods adopt knowledge\ndistillation to extract knowledge from Pretrained Vision-and-Language Models\n(PVLMs) and transfer it to detectors. However, due to the non-adaptive proposal\ncropping and single-level feature mimicking processes, they suffer from\ninformation destruction during knowledge extraction and inefficient knowledge\ntransfer. To remedy these limitations, we propose an Object-Aware Distillation\nPyramid (OADP) framework, including an Object-Aware Knowledge Extraction (OAKE)\nmodule and a Distillation Pyramid (DP) mechanism. When extracting object\nknowledge from PVLMs, the former adaptively transforms object proposals and\nadopts object-aware mask attention to obtain precise and complete knowledge of\nobjects. The latter introduces global and block distillation for more\ncomprehensive knowledge transfer to compensate for the missing relation\ninformation in object distillation. Extensive experiments show that our method\nachieves significant improvement compared to current methods. Especially on the\nMS-COCO dataset, our OADP framework reaches $35.6$ mAP$^{\\text{N}}_{50}$,\nsurpassing the current state-of-the-art method by $3.3$ mAP$^{\\text{N}}_{50}$.\nCode is released at https://github.com/LutingWang/OADP.\n",
                "链接": "https://arxiv.org/abs/2303.05892"
            },
            {
                "文章ID": "68022",
                "标题": "Efficient Feature Distillation for Zero-shot Annotation Object Detection",
                "作者": " Zhuoming Liu,  Xuefeng Hu,  Ram Nevatia",
                "发布日期": "2023-11-03",
                "摘要": "  We propose a new setting for detecting unseen objects called Zero-shot\nAnnotation object Detection (ZAD). It expands the zero-shot object detection\nsetting by allowing the novel objects to exist in the training images and\nrestricts the additional information the detector uses to novel category names.\nRecently, to detect unseen objects, large-scale vision-language models (e.g.,\nCLIP) are leveraged by different methods. The distillation-based methods have\ngood overall performance but suffer from a long training schedule caused by two\nfactors. First, existing work creates distillation regions biased to the base\ncategories, which limits the distillation of novel category information.\nSecond, directly using the raw feature from CLIP for distillation neglects the\ndomain gap between the training data of CLIP and the detection datasets, which\nmakes it difficult to learn the mapping from the image region to the\nvision-language feature space. To solve these problems, we propose Efficient\nfeature distillation for Zero-shot Annotation object Detection (EZAD). Firstly,\nEZAD adapts the CLIP's feature space to the target detection domain by\nre-normalizing CLIP; Secondly, EZAD uses CLIP to generate distillation\nproposals with potential novel category names to avoid the distillation being\noverly biased toward the base categories. Finally, EZAD takes advantage of\nsemantic meaning for regression to further improve the model performance. As a\nresult, EZAD outperforms the previous distillation-based methods in COCO by 4%\nwith a much shorter training schedule and achieves a 3% improvement on the LVIS\ndataset. Our code is available at https://github.com/dragonlzm/EZAD\n",
                "链接": "https://arxiv.org/abs/2303.12145"
            },
            {
                "文章ID": "49404",
                "标题": "Distinctive Self-Similar Object Detection",
                "作者": " Zeyu Shangguan,  Bocheng Hu,  Guohua Dai,  Yuyu Liu,  Darun Tang,  Xingqun Jiang",
                "发布日期": "2023-08-28",
                "摘要": "  Deep learning-based object detection has demonstrated a significant presence\nin the practical applications of artificial intelligence. However, objects such\nas fire and smoke, pose challenges to object detection because of their\nnon-solid and various shapes, and consequently difficult to truly meet\nrequirements in practical fire prevention and control. In this paper, we\npropose that the distinctive fractal feature of self-similar in fire and smoke\ncan relieve us from struggling with their various shapes. To our best\nknowledge, we are the first to discuss this problem. In order to evaluate the\nself-similarity of the fire and smoke and improve the precision of object\ndetection, we design a semi-supervised method that use Hausdorff distance to\ndescribe the resemblance between instances. Besides, based on the concept of\nself-similar, we have devised a novel methodology for evaluating this\nparticular task in a more equitable manner. We have meticulously designed our\nnetwork architecture based on well-established and representative baseline\nnetworks such as YOLO and Faster R-CNN. Our experiments have been conducted on\npublicly available fire and smoke detection datasets, which we have thoroughly\nverified to ensure the validity of our approach. As a result, we have observed\nsignificant improvements in the detection accuracy.\n",
                "链接": "https://arxiv.org/abs/2211.10995"
            },
            {
                "文章ID": "65349",
                "标题": "Gradient-Guided Knowledge Distillation for Object Detectors",
                "作者": " Qizhen Lan,  Qing Tian",
                "发布日期": "2023-03-09",
                "摘要": "  Deep learning models have demonstrated remarkable success in object\ndetection, yet their complexity and computational intensity pose a barrier to\ndeploying them in real-world applications (e.g., self-driving perception).\nKnowledge Distillation (KD) is an effective way to derive efficient models.\nHowever, only a small number of KD methods tackle object detection. Also, most\nof them focus on mimicking the plain features of the teacher model but rarely\nconsider how the features contribute to the final detection. In this paper, we\npropose a novel approach for knowledge distillation in object detection, named\nGradient-guided Knowledge Distillation (GKD). Our GKD uses gradient information\nto identify and assign more weights to features that significantly impact the\ndetection loss, allowing the student to learn the most relevant features from\nthe teacher. Furthermore, we present bounding-box-aware multi-grained feature\nimitation (BMFI) to further improve the KD performance. Experiments on the\nKITTI and COCO-Traffic datasets demonstrate our method's efficacy in knowledge\ndistillation for object detection. On one-stage and two-stage detectors, our\nGKD-BMFI leads to an average of 5.1% and 3.8% mAP improvement, respectively,\nbeating various state-of-the-art KD methods.\n",
                "链接": "https://arxiv.org/abs/2303.04240"
            },
            {
                "文章ID": "86837",
                "标题": "CrossKD: Cross-Head Knowledge Distillation for Dense Object Detection",
                "作者": " Jiabao Wang,  Yuming Chen,  Zhaohui Zheng,  Xiang Li,  Ming-Ming Cheng,  Qibin Hou",
                "发布日期": "2023-06-21",
                "摘要": "  Knowledge Distillation (KD) has been validated as an effective model\ncompression technique for learning compact object detectors. Existing\nstate-of-the-art KD methods for object detection are mostly based on feature\nimitation, which is generally observed to be better than prediction mimicking.\nIn this paper, we show that the inconsistency of the optimization objectives\nbetween the ground-truth signals and distillation targets is the key reason for\nthe inefficiency of prediction mimicking. To alleviate this issue, we present a\nsimple yet effective distillation scheme, termed CrossKD, which delivers the\nintermediate features of the student's detection head to the teacher's\ndetection head. The resulting cross-head predictions are then forced to mimic\nthe teacher's predictions. Such a distillation manner relieves the student's\nhead from receiving contradictory supervision signals from the ground-truth\nannotations and the teacher's predictions, greatly improving the student's\ndetection performance. On MS COCO, with only prediction mimicking losses\napplied, our CrossKD boosts the average precision of GFL ResNet-50 with 1x\ntraining schedule from 40.2 to 43.7, outperforming all existing KD methods for\nobject detection. Code is available at https://github.com/jbwang1997/CrossKD.\n",
                "链接": "https://arxiv.org/abs/2306.11369"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用2020年以后CONLL 2004数据集进行NER评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "46217",
                "标题": "Recognizing Nested Entities from Flat Supervision: A New NER Subtask,\n  Feasibility and Challenges",
                "作者": " Enwei Zhu,  Yiyang Liu,  Ming Jin,  Jinpeng Li",
                "发布日期": "2022-11-02",
                "摘要": "  Many recent named entity recognition (NER) studies criticize flat NER for its\nnon-overlapping assumption, and switch to investigating nested NER. However,\nexisting nested NER models heavily rely on training data annotated with nested\nentities, while labeling such data is costly. This study proposes a new\nsubtask, nested-from-flat NER, which corresponds to a realistic application\nscenario: given data annotated with flat entities only, one may still desire\nthe trained model capable of recognizing nested entities. To address this task,\nwe train span-based models and deliberately ignore the spans nested inside\nlabeled entities, since these spans are possibly unlabeled entities. With\nnested entities removed from the training data, our model achieves 54.8%, 54.2%\nand 41.1% F1 scores on the subset of spans within entities on ACE 2004, ACE\n2005 and GENIA, respectively. This suggests the effectiveness of our approach\nand the feasibility of the task. In addition, the model's performance on flat\nentities is entirely unaffected. We further manually annotate the nested\nentities in the test set of CoNLL 2003, creating a nested-from-flat NER\nbenchmark. Analysis results show that the main challenges stem from the data\nand annotation inconsistencies between the flat and nested entities.\n",
                "链接": "https://arxiv.org/abs/2211.00301"
            },
            {
                "文章ID": "12159",
                "标题": "Federated Named Entity Recognition",
                "作者": " Joel Mathew,  Dimitris Stripelis,  José Luis Ambite",
                "发布日期": "2022-03-30",
                "摘要": "  We present an analysis of the performance of Federated Learning in a\nparadigmatic natural-language processing task: Named-Entity Recognition (NER).\nFor our evaluation, we use the language-independent CoNLL-2003 dataset as our\nbenchmark dataset and a Bi-LSTM-CRF model as our benchmark NER model. We show\nthat federated training reaches almost the same performance as the centralized\nmodel, though with some performance degradation as the learning environments\nbecome more heterogeneous. We also show the convergence rate of federated\nmodels for NER. Finally, we discuss existing challenges of Federated Learning\nfor NLP applications that can foster future research directions.\n",
                "链接": "https://arxiv.org/abs/2203.15101"
            },
            {
                "文章ID": "111254",
                "标题": "CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset",
                "作者": " Susanna Rücker,  Alan Akbik",
                "发布日期": "2023-10-26",
                "摘要": "  The CoNLL-03 corpus is arguably the most well-known and utilized benchmark\ndataset for named entity recognition (NER). However, prior works found\nsignificant numbers of annotation errors, incompleteness, and inconsistencies\nin the data. This poses challenges to objectively comparing NER approaches and\nanalyzing their errors, as current state-of-the-art models achieve F1-scores\nthat are comparable to or even exceed the estimated noise level in CoNLL-03. To\naddress this issue, we present a comprehensive relabeling effort assisted by\nautomatic consistency checking that corrects 7.0% of all labels in the English\nCoNLL-03. Our effort adds a layer of entity linking annotation both for better\nexplainability of NER labels and as additional safeguard of annotation quality.\nOur experimental evaluation finds not only that state-of-the-art approaches\nreach significantly higher F1-scores (97.1%) on our data, but crucially that\nthe share of correct predictions falsely counted as errors due to annotation\nnoise drops from 47% to 6%. This indicates that our resource is well suited to\nanalyze the remaining errors made by state-of-the-art models, and that the\ntheoretical upper bound even on high resource, coarse-grained NER is not yet\nreached. To facilitate such analysis, we make CleanCoNLL publicly available to\nthe research community.\n",
                "链接": "https://arxiv.org/abs/2310.16225"
            },
            {
                "文章ID": "54351",
                "标题": "Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?",
                "作者": " Shuheng Liu,  Alan Ritter",
                "发布日期": "2023-07-13",
                "摘要": "  The CoNLL-2003 English named entity recognition (NER) dataset has been widely\nused to train and evaluate NER models for almost 20 years. However, it is\nunclear how well models that are trained on this 20-year-old data and developed\nover a period of decades using the same test set will perform when applied on\nmodern data. In this paper, we evaluate the generalization of over 20 different\nmodels trained on CoNLL-2003, and show that NER models have very different\ngeneralization. Surprisingly, we find no evidence of performance degradation in\npre-trained Transformers, such as RoBERTa and T5, even when fine-tuned using\ndecades-old data. We investigate why some models generalize well to new data\nwhile others do not, and attempt to disentangle the effects of temporal drift\nand overfitting due to test reuse. Our analysis suggests that most\ndeterioration is due to temporal mismatch between the pre-training corpora and\nthe downstream test sets. We found that four factors are important for good\ngeneralization: model architecture, number of parameters, time period of the\npre-training corpus, in addition to the amount of fine-tuning data. We suggest\ncurrent evaluation methods have, in some sense, underestimated progress on NER\nover the past 20 years, as NER models have not only improved on the original\nCoNLL-2003 test set, but improved even more on modern data. Our datasets can be\nfound at https://github.com/ShuhengL/acl2023_conllpp.\n",
                "链接": "https://arxiv.org/abs/2212.09747"
            },
            {
                "文章ID": "10782",
                "标题": "Leveraging Expert Guided Adversarial Augmentation For Improving\n  Generalization in Named Entity Recognition",
                "作者": " Aaron Reich,  Jiaao Chen,  Aastha Agrawal,  Yanzhe Zhang,  Diyi Yang",
                "发布日期": "2022-03-22",
                "摘要": "  Named Entity Recognition (NER) systems often demonstrate great performance on\nin-distribution data, but perform poorly on examples drawn from a shifted\ndistribution. One way to evaluate the generalization ability of NER models is\nto use adversarial examples, on which the specific variations associated with\nnamed entities are rarely considered. To this end, we propose leveraging\nexpert-guided heuristics to change the entity tokens and their surrounding\ncontexts thereby altering their entity types as adversarial attacks. Using\nexpert-guided heuristics, we augmented the CoNLL 2003 test set and manually\nannotated it to construct a high-quality challenging set. We found that\nstate-of-the-art NER systems trained on CoNLL 2003 training data drop\nperformance dramatically on our challenging set. By training on adversarial\naugmented training examples and using mixup for regularization, we were able to\nsignificantly improve the performance on the challenging set as well as improve\nout-of-domain generalization which we evaluated by using OntoNotes data. We\nhave publicly released our dataset and code at\nhttps://github.com/GT-SALT/Guided-Adversarial-Augmentation.\n",
                "链接": "https://arxiv.org/abs/2203.10693"
            },
            {
                "文章ID": "50504",
                "标题": "Finetuning BERT on Partially Annotated NER Corpora",
                "作者": " Viktor Scherbakov,  Vladimir Mayorov",
                "发布日期": "2022-11-29",
                "摘要": "  Most Named Entity Recognition (NER) models operate under the assumption that\ntraining datasets are fully labelled. While it is valid for established\ndatasets like CoNLL 2003 and OntoNotes, sometimes it is not feasible to obtain\nthe complete dataset annotation. These situations may occur, for instance,\nafter selective annotation of entities for cost reduction. This work presents\nan approach to finetuning BERT on such partially labelled datasets using\nself-supervision and label preprocessing. Our approach outperforms the previous\nLSTM-based label preprocessing baseline, significantly improving the\nperformance on poorly labelled datasets. We demonstrate that following our\napproach while finetuning RoBERTa on CoNLL 2003 dataset with only 10% of total\nentities labelled is enough to reach the performance of the baseline trained on\nthe same dataset with 50% of the entities labelled.\n",
                "链接": "https://arxiv.org/abs/2211.14360"
            },
            {
                "文章ID": "80545",
                "标题": "PromptNER: Prompting For Named Entity Recognition",
                "作者": " Dhananjay Ashok,  Zachary C. Lipton",
                "发布日期": "2023-06-21",
                "摘要": "  In a surprising turn, Large Language Models (LLMs) together with a growing\narsenal of prompt-based heuristics now offer powerful off-the-shelf approaches\nproviding few-shot solutions to myriad classic NLP problems. However, despite\npromising early results, these LLM-based few-shot methods remain far from the\nstate of the art in Named Entity Recognition (NER), where prevailing methods\ninclude learning representations via end-to-end structural understanding and\nfine-tuning on standard labeled corpora. In this paper, we introduce PromptNER,\na new state-of-the-art algorithm for few-Shot and cross-domain NER. To adapt to\nany new NER task PromptNER requires a set of entity definitions in addition to\nthe standard few-shot examples. Given a sentence, PromptNER prompts an LLM to\nproduce a list of potential entities along with corresponding explanations\njustifying their compatibility with the provided entity type definitions.\nRemarkably, PromptNER achieves state-of-the-art performance on few-shot NER,\nachieving a 4% (absolute) improvement in F1 score on the ConLL dataset, a 9%\n(absolute) improvement on the GENIA dataset, and a 4% (absolute) improvement on\nthe FewNERD dataset. PromptNER also moves the state of the art on Cross Domain\nNER, outperforming prior methods (including those not limited to the few-shot\nsetting), setting a new mark on 3/5 CrossNER target domains, with an average F1\ngain of 3%, despite using less than 2% of the available data.\n",
                "链接": "https://arxiv.org/abs/2305.15444"
            },
            {
                "文章ID": "54218",
                "标题": "E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text",
                "作者": " Ting Wai Terence Au,  Ingemar J. Cox,  Vasileios Lampos",
                "发布日期": "2022-12-20",
                "摘要": "  Identifying named entities such as a person, location or organization, in\ndocuments can highlight key information to readers. Training Named Entity\nRecognition (NER) models requires an annotated data set, which can be a\ntime-consuming labour-intensive task. Nevertheless, there are publicly\navailable NER data sets for general English. Recently there has been interest\nin developing NER for legal text. However, prior work and experimental results\nreported here indicate that there is a significant degradation in performance\nwhen NER methods trained on a general English data set are applied to legal\ntext. We describe a publicly available legal NER data set, called E-NER, based\non legal company filings available from the US Securities and Exchange\nCommission's EDGAR data set. Training a number of different NER algorithms on\nthe general English CoNLL-2003 corpus but testing on our test collection\nconfirmed significant degradations in accuracy, as measured by the F1-score, of\nbetween 29.4\\% and 60.4\\%, compared to training and testing on the E-NER\ncollection.\n",
                "链接": "https://arxiv.org/abs/2212.09306"
            },
            {
                "文章ID": "67040",
                "标题": "BanglaCoNER: Towards Robust Bangla Complex Named Entity Recognition",
                "作者": " HAZ Sameen Shahgir,  Ramisa Alam,  Md. Zarif Ul Alam",
                "发布日期": "2023-03-20",
                "摘要": "  Named Entity Recognition (NER) is a fundamental task in natural language\nprocessing that involves identifying and classifying named entities in text.\nBut much work hasn't been done for complex named entity recognition in Bangla,\ndespite being the seventh most spoken language globally. CNER is a more\nchallenging task than traditional NER as it involves identifying and\nclassifying complex and compound entities, which are not common in Bangla\nlanguage. In this paper, we present the winning solution of Bangla Complex\nNamed Entity Recognition Challenge - addressing the CNER task on BanglaCoNER\ndataset using two different approaches, namely Conditional Random Fields (CRF)\nand finetuning transformer based Deep Learning models such as BanglaBERT.\n  The dataset consisted of 15300 sentences for training and 800 sentences for\nvalidation, in the .conll format. Exploratory Data Analysis (EDA) on the\ndataset revealed that the dataset had 7 different NER tags, with notable\npresence of English words, suggesting that the dataset is synthetic and likely\na product of translation.\n  We experimented with a variety of feature combinations including Part of\nSpeech (POS) tags, word suffixes, Gazetteers, and cluster information from\nembeddings, while also finetuning the BanglaBERT (large) model for NER. We\nfound that not all linguistic patterns are immediately apparent or even\nintuitive to humans, which is why Deep Learning based models has proved to be\nthe more effective model in NLP, including CNER task. Our fine tuned BanglaBERT\n(large) model achieves an F1 Score of 0.79 on the validation set. Overall, our\nstudy highlights the importance of Bangla Complex Named Entity Recognition,\nparticularly in the context of synthetic datasets. Our findings also\ndemonstrate the efficacy of Deep Learning models such as BanglaBERT for NER in\nBangla language.\n",
                "链接": "https://arxiv.org/abs/2303.09306"
            },
            {
                "文章ID": "76988",
                "标题": "Cost-efficient Crowdsourcing for Span-based Sequence Labeling: Worker\n  Selection and Data Augmentation",
                "作者": " Yujie Wang,  Chao Huang,  Liner Yang,  Zhixuan Fang,  Yaping Huang,  Yang Liu,  Erhong Yang",
                "发布日期": "2023-05-12",
                "摘要": "  This paper introduces a novel worker selection algorithm, enhancing\nannotation quality and reducing costs in challenging span-based sequence\nlabeling tasks in Natural Language Processing (NLP). Unlike previous studies\ntargeting simpler tasks, this study contends with the complexities of label\ninterdependencies in sequence labeling tasks. The proposed algorithm utilizes a\nCombinatorial Multi-Armed Bandit (CMAB) approach for worker selection. The\nchallenge of dealing with imbalanced and small-scale datasets, which hinders\noffline simulation of worker selection, is tackled using an innovative data\naugmentation method termed shifting, expanding, and shrinking (SES). The SES\nmethod is designed specifically for sequence labeling tasks. Rigorous testing\non CoNLL 2003 NER and Chinese OEI datasets showcased the algorithm's\nefficiency, with an increase in F1 score up to 100.04% of the expert-only\nbaseline, alongside cost savings up to 65.97%. The paper also encompasses a\ndataset-independent test emulating annotation evaluation through a Bernoulli\ndistribution, which still led to an impressive 97.56% F1 score of the expert\nbaseline and 59.88% cost savings. This research addresses and overcomes\nnumerous obstacles in worker selection for complex NLP tasks.\n",
                "链接": "https://arxiv.org/abs/2305.06683"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用CrossWoz或MultiWoz数据集进行DST评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "8498",
                "标题": "Mismatch between Multi-turn Dialogue and its Evaluation Metric in\n  Dialogue State Tracking",
                "作者": " Takyoung Kim,  Hoonsang Yoon,  Yukyung Lee,  Pilsung Kang,  Misuk Kim",
                "发布日期": "2022-04-01",
                "摘要": "  Dialogue state tracking (DST) aims to extract essential information from\nmulti-turn dialogue situations and take appropriate actions. A belief state,\none of the core pieces of information, refers to the subject and its specific\ncontent, and appears in the form of domain-slot-value. The trained model\npredicts \"accumulated\" belief states in every turn, and joint goal accuracy and\nslot accuracy are mainly used to evaluate the prediction; however, we specify\nthat the current evaluation metrics have a critical limitation when evaluating\nbelief states accumulated as the dialogue proceeds, especially in the most used\nMultiWOZ dataset. Additionally, we propose relative slot accuracy to complement\nexisting metrics. Relative slot accuracy does not depend on the number of\npredefined slots, and allows intuitive evaluation by assigning relative scores\naccording to the turn of each dialogue. This study also encourages not solely\nthe reporting of joint goal accuracy, but also various complementary metrics in\nDST tasks for the sake of a realistic evaluation.\n",
                "链接": "https://arxiv.org/abs/2203.03123"
            },
            {
                "文章ID": "7222",
                "标题": "ASSIST: Towards Label Noise-Robust Dialogue State Tracking",
                "作者": " Fanghua Ye,  Yue Feng,  Emine Yilmaz",
                "发布日期": "2022-03-15",
                "摘要": "  The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state\ntracking (DST). However, substantial noise has been discovered in its state\nannotations. Such noise brings about huge challenges for training DST models\nrobustly. Although several refined versions, including MultiWOZ 2.1-2.4, have\nbeen published recently, there are still lots of noisy labels, especially in\nthe training set. Besides, it is costly to rectify all the problematic\nannotations. In this paper, instead of improving the annotation quality\nfurther, we propose a general framework, named ASSIST (lAbel noiSe-robuSt\ndIalogue State Tracking), to train DST models robustly from noisy labels.\nASSIST first generates pseudo labels for each sample in the training set by\nusing an auxiliary model trained on a small clean dataset, then puts the\ngenerated pseudo labels and vanilla noisy labels together to train the primary\nmodel. We show the validity of ASSIST theoretically. Experimental results also\ndemonstrate that ASSIST improves the joint goal accuracy of DST by up to\n$28.16\\%$ on MultiWOZ 2.0 and $8.41\\%$ on MultiWOZ 2.4, compared to using only\nthe vanilla noisy labels.\n",
                "链接": "https://arxiv.org/abs/2202.13024"
            },
            {
                "文章ID": "8024",
                "标题": "Dialogue Summaries as Dialogue States (DS2), Template-Guided\n  Summarization for Few-shot Dialogue State Tracking",
                "作者": " Jamin Shin,  Hangyeol Yu,  Hyeongdon Moon,  Andrea Madotto,  Juneyoung Park",
                "发布日期": "2022-03-04",
                "摘要": "  Annotating task-oriented dialogues is notorious for the expensive and\ndifficult data collection process. Few-shot dialogue state tracking (DST) is a\nrealistic solution to this problem. In this paper, we hypothesize that dialogue\nsummaries are essentially unstructured dialogue states; hence, we propose to\nreformulate dialogue state tracking as a dialogue summarization problem. To\nelaborate, we train a text-to-text language model with synthetic template-based\ndialogue summaries, generated by a set of rules from the dialogue states. Then,\nthe dialogue states can be recovered by inversely applying the summary\ngeneration rules. We empirically show that our method DS2 outperforms previous\nworks on few-shot DST in MultiWoZ 2.0 and 2.1, in both cross-domain and\nmulti-domain settings. Our method also exhibits vast speedup during both\ntraining and inference as it can generate all states at once. Finally, based on\nour analysis, we discover that the naturalness of the summary templates plays a\nkey role for successful training.\n",
                "链接": "https://arxiv.org/abs/2203.01552"
            },
            {
                "文章ID": "61900",
                "标题": "Dialogue State Distillation Network with Inter-slot Contrastive Learning\n  for Dialogue State Tracking",
                "作者": " Jing Xu,  Dandan Song,  Chong Liu,  Siu Cheung Hui,  Fei Li,  Qiang Ju,  Xiaonan He,  Jian Xie",
                "发布日期": "2023-03-08",
                "摘要": "  In task-oriented dialogue systems, Dialogue State Tracking (DST) aims to\nextract users' intentions from the dialogue history. Currently, most existing\napproaches suffer from error propagation and are unable to dynamically select\nrelevant information when utilizing previous dialogue states. Moreover, the\nrelations between the updates of different slots provide vital clues for DST.\nHowever, the existing approaches rely only on predefined graphs to indirectly\ncapture the relations. In this paper, we propose a Dialogue State Distillation\nNetwork (DSDN) to utilize relevant information of previous dialogue states and\nmigrate the gap of utilization between training and testing. Thus, it can\ndynamically exploit previous dialogue states and avoid introducing error\npropagation simultaneously. Further, we propose an inter-slot contrastive\nlearning loss to effectively capture the slot co-update relations from dialogue\ncontext. Experiments are conducted on the widely used MultiWOZ 2.0 and MultiWOZ\n2.1 datasets. The experimental results show that our proposed model achieves\nthe state-of-the-art performance for DST.\n",
                "链接": "https://arxiv.org/abs/2302.08220"
            },
            {
                "文章ID": "48889",
                "标题": "Self-Training with Purpose Preserving Augmentation Improves Few-shot\n  Generative Dialogue State Tracking",
                "作者": " Jihyun Lee,  Chaebin Lee,  Yunsu Kim,  Gary Geunbae Lee",
                "发布日期": "2022-11-18",
                "摘要": "  In dialogue state tracking (DST), labeling the dataset involves considerable\nhuman labor. We propose a new self-training framework for few-shot generative\nDST that utilize unlabeled data. Our self-training method iteratively improves\nthe model by pseudo labeling and employs Purpose Preserving Augmentation\n(PPAug) to prevent overfitting. We increaese the few-shot 10% performance by\napproximately 4% on MultiWOZ 2.1 and enhances the slot-recall 8.34% for unseen\nvalues compared to baseline.\n",
                "链接": "https://arxiv.org/abs/2211.09379"
            },
            {
                "文章ID": "41702",
                "标题": "CSS: Combining Self-training and Self-supervised Learning for Few-shot\n  Dialogue State Tracking",
                "作者": " Haoning Zhang,  Junwei Bao,  Haipeng Sun,  Huaishao Luo,  Wenye Li,  Shuguang Cui",
                "发布日期": "2022-10-12",
                "摘要": "  Few-shot dialogue state tracking (DST) is a realistic problem that trains the\nDST model with limited labeled data. Existing few-shot methods mainly transfer\nknowledge learned from external labeled dialogue data (e.g., from question\nanswering, dialogue summarization, machine reading comprehension tasks, etc.)\ninto DST, whereas collecting a large amount of external labeled data is\nlaborious, and the external data may not effectively contribute to the\nDST-specific task. In this paper, we propose a few-shot DST framework called\nCSS, which Combines Self-training and Self-supervised learning methods. The\nunlabeled data of the DST task is incorporated into the self-training\niterations, where the pseudo labels are predicted by a DST model trained on\nlimited labeled data in advance. Besides, a contrastive self-supervised method\nis used to learn better representations, where the data is augmented by the\ndropout operation to train the model. Experimental results on the MultiWOZ\ndataset show that our proposed CSS achieves competitive performance in several\nfew-shot scenarios.\n",
                "链接": "https://arxiv.org/abs/2210.05146"
            },
            {
                "文章ID": "109152",
                "标题": "UNO-DST: Leveraging Unlabelled Data in Zero-Shot Dialogue State Tracking",
                "作者": " Chuang Li,  Yan Zhang,  Min-Yen Kan,  Haizhou Li",
                "发布日期": "2023-10-17",
                "摘要": "  Previous zero-shot dialogue state tracking (DST) methods only apply transfer\nlearning, but ignore unlabelled data in the target domain. We transform\nzero-shot DST into few-shot DST by utilising such unlabelled data via joint and\nself-training methods. Our method incorporates auxiliary tasks that generate\nslot types as inverse prompts for main tasks, creating slot values during joint\ntraining. Cycle consistency between these two tasks enables the generation and\nselection of quality samples in unknown target domains for subsequent\nfine-tuning. This approach also facilitates automatic label creation, thereby\noptimizing the training and fine-tuning of DST models. We demonstrate this\nmethod's effectiveness on large language models in zero-shot scenarios,\nimproving average joint goal accuracy by $8\\%$ across all domains in MultiWOZ.\n",
                "链接": "https://arxiv.org/abs/2310.10492"
            },
            {
                "文章ID": "40726",
                "标题": "Schema Encoding for Transferable Dialogue State Tracking",
                "作者": " Hyunmin Jeon,  Gary Geunbae Lee",
                "发布日期": "2022-10-06",
                "摘要": "  Dialogue state tracking (DST) is an essential sub-task for task-oriented\ndialogue systems. Recent work has focused on deep neural models for DST.\nHowever, the neural models require a large dataset for training. Furthermore,\napplying them to another domain needs a new dataset because the neural models\nare generally trained to imitate the given dataset. In this paper, we propose\nSchema Encoding for Transferable Dialogue State Tracking (SETDST), which is a\nneural DST method for effective transfer to new domains. Transferable DST could\nassist developments of dialogue systems even with few dataset on target\ndomains. We use a schema encoder not just to imitate the dataset but to\ncomprehend the schema of the dataset. We aim to transfer the model to new\ndomains by encoding new schemas and using them for DST on multi-domain\nsettings. As a result, SET-DST improved the joint accuracy by 1.46 points on\nMultiWOZ 2.1.\n",
                "链接": "https://arxiv.org/abs/2210.02351"
            },
            {
                "文章ID": "109162",
                "标题": "Semantic Parsing by Large Language Models for Intricate Updating\n  Strategies of Zero-Shot Dialogue State Tracking",
                "作者": " Yuxiang Wu,  Guanting Dong,  Weiran Xu",
                "发布日期": "2023-11-28",
                "摘要": "  Zero-shot Dialogue State Tracking (DST) addresses the challenge of acquiring\nand annotating task-oriented dialogues, which can be time-consuming and costly.\nHowever, DST extends beyond simple slot-filling and requires effective updating\nstrategies for tracking dialogue state as conversations progress. In this\npaper, we propose ParsingDST, a new In-Context Learning (ICL) method, to\nintroduce additional intricate updating strategies in zero-shot DST. Our\napproach reformulates the DST task by leveraging powerful Large Language Models\n(LLMs) and translating the original dialogue text to JSON through semantic\nparsing as an intermediate state. We also design a novel framework that\nincludes more modules to ensure the effectiveness of updating strategies in the\ntext-to-JSON process. Experimental results demonstrate that our approach\noutperforms existing zero-shot DST methods on MultiWOZ, exhibiting significant\nimprovements in Joint Goal Accuracy (JGA) and slot accuracy compared to\nexisting ICL methods. Our code has been released.\n",
                "链接": "https://arxiv.org/abs/2310.10520"
            },
            {
                "文章ID": "10087",
                "标题": "In-Context Learning for Few-Shot Dialogue State Tracking",
                "作者": " Yushi Hu,  Chia-Hsuan Lee,  Tianbao Xie,  Tao Yu,  Noah A. Smith,  Mari Ostendorf",
                "发布日期": "2022-10-27",
                "摘要": "  Collecting and annotating task-oriented dialogues is time-consuming and\ncostly; thus, zero and few shot learning could greatly benefit dialogue state\ntracking (DST). In this work, we propose an in-context learning (ICL) framework\nfor zero-shot and few-shot learning DST, where a large pre-trained language\nmodel (LM) takes a test instance and a few exemplars as input, and directly\ndecodes the dialogue state without any parameter updates. To better leverage a\ntabular domain description in the LM prompt, we reformulate DST into a\ntext-to-SQL problem. We also propose a novel approach to retrieve annotated\ndialogues as exemplars. Empirical results on MultiWOZ show that our method\nIC-DST substantially outperforms previous fine-tuned state-of-the-art models in\nfew-shot settings. In addition, we test IC-DST in zero-shot settings, in which\nthe model only takes a fixed task instruction as input, finding that it\noutperforms previous zero-shot methods by a large margin.\n",
                "链接": "https://arxiv.org/abs/2203.08568"
            }
        ]
    },
    {
        "question": {
            "question": "2023年后利用hotpotqa数据集做问题生成任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "58619",
                "标题": "Graph Attention with Hierarchies for Multi-hop Question Answering",
                "作者": " Yunjie He,  Philip John Gorinski,  Ieva Staliunaite,  Pontus Stenetorp",
                "发布日期": "2023-01-30",
                "摘要": "  Multi-hop QA (Question Answering) is the task of finding the answer to a\nquestion across multiple documents. In recent years, a number of Deep\nLearning-based approaches have been proposed to tackle this complex task, as\nwell as a few standard benchmarks to assess models Multi-hop QA capabilities.\nIn this paper, we focus on the well-established HotpotQA benchmark dataset,\nwhich requires models to perform answer span extraction as well as support\nsentence prediction. We present two extensions to the SOTA Graph Neural Network\n(GNN) based model for HotpotQA, Hierarchical Graph Network (HGN): (i) we\ncomplete the original hierarchical structure by introducing new edges between\nthe query and context sentence nodes; (ii) in the graph propagation step, we\npropose a novel extension to Hierarchical Graph Attention Network GATH (Graph\nATtention with Hierarchies) that makes use of the graph hierarchy to update the\nnode representations in a sequential fashion. Experiments on HotpotQA\ndemonstrate the efficiency of the proposed modifications and support our\nassumptions about the effects of model related variables.\n",
                "链接": "https://arxiv.org/abs/2301.11792"
            },
            {
                "文章ID": "115380",
                "标题": "A Step Closer to Comprehensive Answers: Constrained Multi-Stage Question\n  Decomposition with Large Language Models",
                "作者": " Hejing Cao,  Zhenwei An,  Jiazhan Feng,  Kun Xu,  Liwei Chen,  Dongyan Zhao",
                "发布日期": "2023-11-14",
                "摘要": "  While large language models exhibit remarkable performance in the Question\nAnswering task, they are susceptible to hallucinations. Challenges arise when\nthese models grapple with understanding multi-hop relations in complex\nquestions or lack the necessary knowledge for a comprehensive response. To\naddress this issue, we introduce the \"Decompose-and-Query\" framework (D&Q).\nThis framework guides the model to think and utilize external knowledge similar\nto ReAct, while also restricting its thinking to reliable information,\neffectively mitigating the risk of hallucinations. Experiments confirm the\neffectiveness of D&Q: On our ChitChatQA dataset, D&Q does not lose to ChatGPT\nin 67% of cases; on the HotPotQA question-only setting, D&Q achieved an F1\nscore of 59.6%. Our code is available at\nhttps://github.com/alkaidpku/DQ-ToolQA.\n",
                "链接": "https://arxiv.org/abs/2311.07491"
            },
            {
                "文章ID": "73844",
                "标题": "IslamicPCQA: A Dataset for Persian Multi-hop Complex Question Answering\n  in Islamic Text Resources",
                "作者": " Arash Ghafouri,  Hasan Naderi,  Mohammad Aghajani asl,  Mahdi Firouzmandi",
                "发布日期": "2023-04-25",
                "摘要": "  Nowadays, one of the main challenges for Question Answering Systems is to\nanswer complex questions using various sources of information. Multi-hop\nquestions are a type of complex questions that require multi-step reasoning to\nanswer. In this article, the IslamicPCQA dataset is introduced. This is the\nfirst Persian dataset for answering complex questions based on non-structured\ninformation sources and consists of 12,282 question-answer pairs extracted from\n9 Islamic encyclopedias. This dataset has been created inspired by the HotpotQA\nEnglish dataset approach, which was customized to suit the complexities of the\nPersian language. Answering questions in this dataset requires more than one\nparagraph and reasoning. The questions are not limited to any prior knowledge\nbase or ontology, and to provide robust reasoning ability, the dataset also\nincludes supporting facts and key sentences. The prepared dataset covers a wide\nrange of Islamic topics and aims to facilitate answering complex Persian\nquestions within this subject matter\n",
                "链接": "https://arxiv.org/abs/2304.11664"
            },
            {
                "文章ID": "54277",
                "标题": "Rethinking Label Smoothing on Multi-hop Question Answering",
                "作者": " Zhangyue Yin,  Yuxin Wang,  Xiannian Hu,  Yiguang Wu,  Hang Yan,  Xinyu Zhang,  Zhao Cao,  Xuanjing Huang,  Xipeng Qiu",
                "发布日期": "2023-12-14",
                "摘要": "  Multi-Hop Question Answering (MHQA) is a significant area in question\nanswering, requiring multiple reasoning components, including document\nretrieval, supporting sentence prediction, and answer span extraction. In this\nwork, we analyze the primary factors limiting the performance of multi-hop\nreasoning and introduce label smoothing into the MHQA task. This is aimed at\nenhancing the generalization capabilities of MHQA systems and mitigating\noverfitting of answer spans and reasoning paths in training set. We propose a\nnovel label smoothing technique, F1 Smoothing, which incorporates uncertainty\ninto the learning process and is specifically tailored for Machine Reading\nComprehension (MRC) tasks. Inspired by the principles of curriculum learning,\nwe introduce the Linear Decay Label Smoothing Algorithm (LDLA), which\nprogressively reduces uncertainty throughout the training process. Experiment\non the HotpotQA dataset demonstrates the effectiveness of our methods in\nenhancing performance and generalizability in multi-hop reasoning, achieving\nnew state-of-the-art results on the leaderboard.\n",
                "链接": "https://arxiv.org/abs/2212.09512"
            },
            {
                "文章ID": "109543",
                "标题": "What is a good question? Task-oriented asking with fact-level masking",
                "作者": " Matthew Toles,  Yukun Huang,  Zhou Yu,  Luis Gravano",
                "发布日期": "2023-10-19",
                "摘要": "  Asking questions is an important element of real-life collaboration on\nreasoning tasks like question answering. For example, a legal assistant chatbot\nmay be unable to make accurate recommendations without specific information on\nthe user's circumstances. However, large language models are usually deployed\nto solve reasoning tasks directly without asking follow-up questions to the\nuser or third parties. We term this problem task-oriented asking (TOA).\nZero-shot chat models can perform TOA, but their training is primarily based on\nnext-token prediction rather than whether questions contribute to successful\ncollaboration. To enable the training and evaluation of TOA models, we present\na definition and framework for natural language task-oriented asking, the\nproblem of generating questions that result in answers useful for a reasoning\ntask. We also present fact-level masking (FLM), a procedure for converting\nnatural language datasets into self-supervised TOA datasets by omitting\nparticular critical facts. Finally, we generate a TOA dataset from the HotpotQA\ndataset using FLM and evaluate several zero-shot language models on it. Our\nexperiments show that current zero-shot models struggle to ask questions that\nretrieve useful information, as compared to human annotators. These results\ndemonstrate an opportunity to use FLM datasets and the TOA framework to train\nand evaluate better TOA models.\n",
                "链接": "https://arxiv.org/abs/2310.11571"
            },
            {
                "文章ID": "42469",
                "标题": "Few-Shot Visual Question Generation: A Novel Task and Benchmark Datasets",
                "作者": " Anurag Roy,  David Johnson Ekka,  Saptarshi Ghosh,  Abir Das",
                "发布日期": "2023-01-09",
                "摘要": "  Generating natural language questions from visual scenes, known as Visual\nQuestion Generation (VQG), has been explored in the recent past where large\namounts of meticulously labeled data provide the training corpus. However, in\npractice, it is not uncommon to have only a few images with question\nannotations corresponding to a few types of answers. In this paper, we propose\na new and challenging Few-Shot Visual Question Generation (FS-VQG) task and\nprovide a comprehensive benchmark to it. Specifically, we evaluate various\nexisting VQG approaches as well as popular few-shot solutions based on\nmeta-learning and self-supervised strategies for the FS-VQG task. We conduct\nexperiments on two popular existing datasets VQG and Visual7w. In addition, we\nhave also cleaned and extended the VQG dataset for use in a few-shot scenario,\nwith additional image-question pairs as well as additional answer categories.\nWe call this new dataset VQG-23. Several important findings emerge from our\nexperiments, that shed light on the limits of current models in few-shot vision\nand language generation tasks. We find that trivially extending existing VQG\napproaches with transfer learning or meta-learning may not be enough to tackle\nthe inherent challenges in few-shot VQG. We believe that this work will\ncontribute to accelerating the progress in few-shot learning research.\n",
                "链接": "https://arxiv.org/abs/2210.07076"
            },
            {
                "文章ID": "61248",
                "标题": "Analyzing the Effectiveness of the Underlying Reasoning Tasks in\n  Multi-hop Question Answering",
                "作者": " Xanh Ho,  Anh-Khoa Duong Nguyen,  Saku Sugawara,  Akiko Aizawa",
                "发布日期": "2023-02-14",
                "摘要": "  To explain the predicted answers and evaluate the reasoning abilities of\nmodels, several studies have utilized underlying reasoning (UR) tasks in\nmulti-hop question answering (QA) datasets. However, it remains an open\nquestion as to how effective UR tasks are for the QA task when training models\non both tasks in an end-to-end manner. In this study, we address this question\nby analyzing the effectiveness of UR tasks (including both sentence-level and\nentity-level tasks) in three aspects: (1) QA performance, (2) reasoning\nshortcuts, and (3) robustness. While the previous models have not been\nexplicitly trained on an entity-level reasoning prediction task, we build a\nmulti-task model that performs three tasks together: sentence-level supporting\nfacts prediction, entity-level reasoning prediction, and answer prediction.\nExperimental results on 2WikiMultiHopQA and HotpotQA-small datasets reveal that\n(1) UR tasks can improve QA performance. Using four debiased datasets that are\nnewly created, we demonstrate that (2) UR tasks are helpful in preventing\nreasoning shortcuts in the multi-hop QA task. However, we find that (3) UR\ntasks do not contribute to improving the robustness of the model on adversarial\nquestions, such as sub-questions and inverted questions. We encourage future\nstudies to investigate the effectiveness of entity-level reasoning in the form\nof natural language questions (e.g., sub-question forms).\n",
                "链接": "https://arxiv.org/abs/2302.05963"
            },
            {
                "文章ID": "85143",
                "标题": "Weakly Supervised Visual Question Answer Generation",
                "作者": " Charani Alampalle,  Shamanthak Hegde,  Soumya Jahagirdar,  Shankar Gangisetty",
                "发布日期": "2023-09-12",
                "摘要": "  Growing interest in conversational agents promote twoway human-computer\ncommunications involving asking and answering visual questions have become an\nactive area of research in AI. Thus, generation of visual questionanswer\npair(s) becomes an important and challenging task. To address this issue, we\npropose a weakly-supervised visual question answer generation method that\ngenerates a relevant question-answer pairs for a given input image and\nassociated caption. Most of the prior works are supervised and depend on the\nannotated question-answer datasets. In our work, we present a weakly supervised\nmethod that synthetically generates question-answer pairs procedurally from\nvisual information and captions. The proposed method initially extracts list of\nanswer words, then does nearest question generation that uses the caption and\nanswer word to generate synthetic question. Next, the relevant question\ngenerator converts the nearest question to relevant language question by\ndependency parsing and in-order tree traversal, finally, fine-tune a ViLBERT\nmodel with the question-answer pair(s) generated at end. We perform an\nexhaustive experimental analysis on VQA dataset and see that our model\nsignificantly outperform SOTA methods on BLEU scores. We also show the results\nwrt baseline models and ablation study.\n",
                "链接": "https://arxiv.org/abs/2306.06622"
            },
            {
                "文章ID": "75838",
                "标题": "Chain-of-Skills: A Configurable Model for Open-domain Question Answering",
                "作者": " Kaixin Ma,  Hao Cheng,  Yu Zhang,  Xiaodong Liu,  Eric Nyberg,  Jianfeng Gao",
                "发布日期": "2023-05-29",
                "摘要": "  The retrieval model is an indispensable component for real-world\nknowledge-intensive tasks, e.g., open-domain question answering (ODQA). As\nseparate retrieval skills are annotated for different datasets, recent work\nfocuses on customized methods, limiting the model transferability and\nscalability. In this work, we propose a modular retriever where individual\nmodules correspond to key skills that can be reused across datasets. Our\napproach supports flexible skill configurations based on the target domain to\nboost performance. To mitigate task interference, we design a novel\nmodularization parameterization inspired by sparse Transformer. We demonstrate\nthat our model can benefit from self-supervised pretraining on Wikipedia and\nfine-tuning using multiple ODQA datasets, both in a multi-task fashion. Our\napproach outperforms recent self-supervised retrievers in zero-shot evaluations\nand achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA\nand OTT-QA.\n",
                "链接": "https://arxiv.org/abs/2305.03130"
            },
            {
                "文章ID": "101245",
                "标题": "AGent: A Novel Pipeline for Automatically Creating Unanswerable\n  Questions",
                "作者": " Son Quoc Tran,  Gia-Huy Do,  Phong Nguyen-Thuan Do,  Matt Kretchmar,  Xinya Du",
                "发布日期": "2023-09-12",
                "摘要": "  The development of large high-quality datasets and high-performing models\nhave led to significant advancements in the domain of Extractive Question\nAnswering (EQA). This progress has sparked considerable interest in exploring\nunanswerable questions within the EQA domain. Training EQA models with\nunanswerable questions helps them avoid extracting misleading or incorrect\nanswers for queries that lack valid responses. However, manually annotating\nunanswerable questions is labor-intensive. To address this, we propose AGent, a\nnovel pipeline that automatically creates new unanswerable questions by\nre-matching a question with a context that lacks the necessary information for\na correct answer. In this paper, we demonstrate the usefulness of this AGent\npipeline by creating two sets of unanswerable questions from answerable\nquestions in SQuAD and HotpotQA. These created question sets exhibit low error\nrates. Additionally, models fine-tuned on these questions show comparable\nperformance with those fine-tuned on the SQuAD 2.0 dataset on multiple EQA\nbenchmarks.\n",
                "链接": "https://arxiv.org/abs/2309.05103"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用机器学习方法进行心理健康疾病研究的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "98633",
                "标题": "Discovering Mental Health Research Topics with Topic Modeling",
                "作者": " Xin Gao,  Cem Sazara",
                "发布日期": "2023-08-29",
                "摘要": "  Mental health significantly influences various aspects of our daily lives,\nand its importance has been increasingly recognized by the research community\nand the general public, particularly in the wake of the COVID-19 pandemic. This\nheightened interest is evident in the growing number of publications dedicated\nto mental health in the past decade. In this study, our goal is to identify\ngeneral trends in the field and pinpoint high-impact research topics by\nanalyzing a large dataset of mental health research papers. To accomplish this,\nwe collected abstracts from various databases and trained a customized\nSentence-BERT based embedding model leveraging the BERTopic framework. Our\ndataset comprises 96,676 research papers pertaining to mental health, enabling\nus to examine the relationships between different topics using their abstracts.\nTo evaluate the effectiveness of the model, we compared it against two other\nstate-of-the-art methods: Top2Vec model and LDA-BERT model. The model\ndemonstrated superior performance in metrics that measure topic diversity and\ncoherence. To enhance our analysis, we also generated word clouds to provide a\ncomprehensive overview of the machine learning models applied in mental health\nresearch, shedding light on commonly utilized techniques and emerging trends.\nFurthermore, we provide a GitHub link* to the dataset used in this paper,\nensuring its accessibility for further research endeavors.\n",
                "链接": "https://arxiv.org/abs/2308.13569"
            },
            {
                "文章ID": "104767",
                "标题": "Identifying Risk Factors for Post-COVID-19 Mental Health Disorders: A\n  Machine Learning Perspective",
                "作者": " Maitham G. Yousif,  Fadhil G. Al-Amran,  Hector J. Castro",
                "发布日期": "2023-09-29",
                "摘要": "  In this study, we leveraged machine learning techniques to identify risk\nfactors associated with post-COVID-19 mental health disorders. Our analysis,\nbased on data collected from 669 patients across various provinces in Iraq,\nyielded valuable insights. We found that age, gender, and geographical region\nof residence were significant demographic factors influencing the likelihood of\ndeveloping mental health disorders in post-COVID-19 patients. Additionally,\ncomorbidities and the severity of COVID-19 illness were important clinical\npredictors. Psychosocial factors, such as social support, coping strategies,\nand perceived stress levels, also played a substantial role. Our findings\nemphasize the complex interplay of multiple factors in the development of\nmental health disorders following COVID-19 recovery. Healthcare providers and\npolicymakers should consider these risk factors when designing targeted\ninterventions and support systems for individuals at risk. Machine\nlearning-based approaches can provide a valuable tool for predicting and\npreventing adverse mental health outcomes in post-COVID-19 patients. Further\nresearch and prospective studies are needed to validate these findings and\nenhance our understanding of the long-term psychological impact of the COVID-19\npandemic. This study contributes to the growing body of knowledge regarding the\nmental health consequences of the COVID-19 pandemic and underscores the\nimportance of a multidisciplinary approach to address the diverse needs of\nindividuals on the path to recovery. Keywords: COVID-19, mental health, risk\nfactors, machine learning, Iraq\n",
                "链接": "https://arxiv.org/abs/2309.16055"
            },
            {
                "文章ID": "32474",
                "标题": "Bias Reducing Multitask Learning on Mental Health Prediction",
                "作者": " Khadija Zanna,  Kusha Sridhar,  Han Yu,  Akane Sano",
                "发布日期": "2022-08-09",
                "摘要": "  There has been an increase in research in developing machine learning models\nfor mental health detection or prediction in recent years due to increased\nmental health issues in society. Effective use of mental health prediction or\ndetection models can help mental health practitioners re-define mental\nillnesses more objectively than currently done, and identify illnesses at an\nearlier stage when interventions may be more effective. However, there is still\na lack of standard in evaluating bias in such machine learning models in the\nfield, which leads to challenges in providing reliable predictions and in\naddressing disparities. This lack of standards persists due to factors such as\ntechnical difficulties, complexities of high dimensional clinical health data,\netc., which are especially true for physiological signals. This along with\nprior evidence of relations between some physiological signals with certain\ndemographic identities restates the importance of exploring bias in mental\nhealth prediction models that utilize physiological signals. In this work, we\naim to perform a fairness analysis and implement a multi-task learning based\nbias mitigation method on anxiety prediction models using ECG data. Our method\nis based on the idea of epistemic uncertainty and its relationship with model\nweights and feature space representation. Our analysis showed that our anxiety\nprediction base model introduced some bias with regards to age, income,\nethnicity, and whether a participant is born in the U.S. or not, and our bias\nmitigation method performed better at reducing the bias in the model, when\ncompared to the reweighting mitigation technique. Our analysis on feature\nimportance also helped identify relationships between heart rate variability\nand multiple demographic groupings.\n",
                "链接": "https://arxiv.org/abs/2208.03621"
            },
            {
                "文章ID": "92064",
                "标题": "Technology in Association With Mental Health: Meta-ethnography",
                "作者": " Hamza Mohammed",
                "发布日期": "2023-07-28",
                "摘要": "  This research paper presents a meta-analysis of the multifaceted role of\ntechnology in mental health. The pervasive influence of technology on daily\nlives necessitates a deep understanding of its impact on mental health\nservices. This study synthesizes literature covering Behavioral Intervention\nTechnologies (BITs), digital mental health interventions during COVID-19, young\nmen's attitudes toward mental health technologies, technology-based\ninterventions for university students, and the applicability of mobile health\ntechnologies for individuals with serious mental illnesses. BITs are recognized\nfor their potential to provide evidence-based interventions for mental health\nconditions, especially anxiety disorders. The COVID-19 pandemic acted as a\ncatalyst for the adoption of digital mental health services, underscoring their\ncrucial role in providing accessible and quality care; however, their efficacy\nneeds to be reinforced by workforce training, high-quality evidence, and\ndigital equity. A nuanced understanding of young men's attitudes toward mental\nhealth is imperative for devising effective online services. Technology-based\ninterventions for university students are promising, although variable in\neffectiveness; their deployment must be evidence-based and tailored to\nindividual needs. Mobile health technologies, particularly activity tracking,\nhold promise for individuals with serious mental illnesses. Collectively,\ntechnology has immense potential to revolutionize mental health care. However,\nthe implementation must be evidence-based, ethical, and equitable, with\ncontinued research focusing on experiences across diverse populations, ensuring\naccessibility and efficacy for all.\n",
                "链接": "https://arxiv.org/abs/2307.10513"
            },
            {
                "文章ID": "78820",
                "标题": "Amity -- A Hybrid Mental Health Application",
                "作者": " Srija Santhanam,  Kavipriya P,  Balamurugan MS,  Manoj Kumar Rajagopal",
                "发布日期": "2023-05-23",
                "摘要": "  Wellness in trivial terms combines physical, social, and mental wellbeing.\nWhile mental health is neglected, long-term success in a person life is mostly\ndetermined by his psychological health and contentment. For a person in\ndistress, professional mental health services are quite expensive, unpopular,\nand invite a lot of hesitation. Hence, it would be effective to use an Android\napplication that can offer day to day therapeutic assistance, meditation\nsessions, and guidance since it can cater to a massive community instantly. In\nthis paper, we propose a mobile and web application AMITY with a chat group and\nchatbot created using a machine learning approach. We have also built a dataset\nto train the chatbot model that we propose in this paper. We briefly introduce\nthe dataset and the machine learning model in section 3. In section 4, we\ninclude the architecture and the development details of the Hybrid application.\nNext, we present our results on usability and the efficiency of the idea we\npropose.\n",
                "链接": "https://arxiv.org/abs/2305.11871"
            },
            {
                "文章ID": "70494",
                "标题": "Identifying Mentions of Pain in Mental Health Records Text: A Natural\n  Language Processing Approach",
                "作者": " Jaya Chaturvedi,  Sumithra Velupillai,  Robert Stewart,  Angus Roberts",
                "发布日期": "2023-04-06",
                "摘要": "  Pain is a common reason for accessing healthcare resources and is a growing\narea of research, especially in its overlap with mental health. Mental health\nelectronic health records are a good data source to study this overlap.\nHowever, much information on pain is held in the free text of these records,\nwhere mentions of pain present a unique natural language processing problem due\nto its ambiguous nature. This project uses data from an anonymised mental\nhealth electronic health records database. The data are used to train a machine\nlearning based classification algorithm to classify sentences as discussing\npatient pain or not. This will facilitate the extraction of relevant pain\ninformation from large databases, and the use of such outputs for further\nstudies on pain and mental health. 1,985 documents were manually\ntriple-annotated for creation of gold standard training data, which was used to\ntrain three commonly used classification algorithms. The best performing model\nachieved an F1-score of 0.98 (95% CI 0.98-0.99).\n",
                "链接": "https://arxiv.org/abs/2304.01240"
            },
            {
                "文章ID": "72482",
                "标题": "Understanding and Mitigating Mental Health Misinformation on Video\n  Sharing Platforms",
                "作者": " Viet Cuong Nguyen,  Michael Birnbaum,  Munmun De Choudhury",
                "发布日期": "2023-04-18",
                "摘要": "  Despite the ever-strong demand for mental health care globally, access to\ntraditional mental health services remains severely limited expensive, and\nstifled by stigma and systemic barriers. Thus, over the last few years, young\npeople are increasingly turning to content on video-sharing platforms (VSPs)\nlike TikTok and YouTube to help them navigate their mental health journey.\nHowever, navigating towards trustworthy information relating to mental health\non these platforms is challenging, given the uncontrollable and unregulated\ngrowth of dedicated mental health content and content creators catering to a\nwide array of mental health conditions on these platforms. In this paper, we\nattempt to define what constitutes as \"mental health misinformation\" through\nexamples. In addition, we also suggest some open questions to answer and\nchallenges to tackle regarding this important and timely research topic\n",
                "链接": "https://arxiv.org/abs/2304.07417"
            },
            {
                "文章ID": "93837",
                "标题": "A Benchmark for Understanding Dialogue Safety in Mental Health Support",
                "作者": " Huachuan Qiu,  Tong Zhao,  Anqi Li,  Shuai Zhang,  Hongliang He,  Zhenzhong Lan",
                "发布日期": "2023-08-01",
                "摘要": "  Dialogue safety remains a pervasive challenge in open-domain human-machine\ninteraction. Existing approaches propose distinctive dialogue safety taxonomies\nand datasets for detecting explicitly harmful responses. However, these\ntaxonomies may not be suitable for analyzing response safety in mental health\nsupport. In real-world interactions, a model response deemed acceptable in\ncasual conversations might have a negligible positive impact on users seeking\nmental health support. To address these limitations, this paper aims to develop\na theoretically and factually grounded taxonomy that prioritizes the positive\nimpact on help-seekers. Additionally, we create a benchmark corpus with\nfine-grained labels for each dialogue session to facilitate further research.\nWe analyze the dataset using popular language models, including BERT-base,\nRoBERTa-large, and ChatGPT, to detect and understand unsafe responses within\nthe context of mental health support. Our study reveals that ChatGPT struggles\nto detect safety categories with detailed safety definitions in a zero- and\nfew-shot paradigm, whereas the fine-tuned model proves to be more suitable. The\ndeveloped dataset and findings serve as valuable benchmarks for advancing\nresearch on dialogue safety in mental health support, with significant\nimplications for improving the design and deployment of conversation agents in\nreal-world applications. We release our code and data here:\nhttps://github.com/qiuhuachuan/DialogueSafety.\n",
                "链接": "https://arxiv.org/abs/2307.16457"
            },
            {
                "文章ID": "45343",
                "标题": "Gendered Mental Health Stigma in Masked Language Models",
                "作者": " Inna Wanyin Lin,  Lucille Njoo,  Anjalie Field,  Ashish Sharma,  Katharina Reinecke,  Tim Althoff,  Yulia Tsvetkov",
                "发布日期": "2023-04-13",
                "摘要": "  Mental health stigma prevents many individuals from receiving the appropriate\ncare, and social psychology studies have shown that mental health tends to be\noverlooked in men. In this work, we investigate gendered mental health stigma\nin masked language models. In doing so, we operationalize mental health stigma\nby developing a framework grounded in psychology research: we use clinical\npsychology literature to curate prompts, then evaluate the models' propensity\nto generate gendered words. We find that masked language models capture\nsocietal stigma about gender in mental health: models are consistently more\nlikely to predict female subjects than male in sentences about having a mental\nhealth condition (32% vs. 19%), and this disparity is exacerbated for sentences\nthat indicate treatment-seeking behavior. Furthermore, we find that different\nmodels capture dimensions of stigma differently for men and women, associating\nstereotypes like anger, blame, and pity more with women with mental health\nconditions than with men. In showing the complex nuances of models' gendered\nmental health stigma, we demonstrate that context and overlapping dimensions of\nidentity are important considerations when assessing computational models'\nsocial biases.\n",
                "链接": "https://arxiv.org/abs/2210.15144"
            },
            {
                "文章ID": "22551",
                "标题": "MentSum: A Resource for Exploring Summarization of Mental Health Online\n  Posts",
                "作者": " Sajad Sotudeh,  Nazli Goharian,  Zachary Young",
                "发布日期": "2022-06-03",
                "摘要": "  Mental health remains a significant challenge of public health worldwide.\nWith increasing popularity of online platforms, many use the platforms to share\ntheir mental health conditions, express their feelings, and seek help from the\ncommunity and counselors. Some of these platforms, such as Reachout, are\ndedicated forums where the users register to seek help. Others such as Reddit\nprovide subreddits where the users publicly but anonymously post their mental\nhealth distress. Although posts are of varying length, it is beneficial to\nprovide a short, but informative summary for fast processing by the counselors.\nTo facilitate research in summarization of mental health online posts, we\nintroduce Mental Health Summarization dataset, MentSum, containing over 24k\ncarefully selected user posts from Reddit, along with their short user-written\nsummary (called TLDR) in English from 43 mental health subreddits. This\ndomain-specific dataset could be of interest not only for generating short\nsummaries on Reddit, but also for generating summaries of posts on the\ndedicated mental health forums such as Reachout. We further evaluate both\nextractive and abstractive state-of-the-art summarization baselines in terms of\nRouge scores, and finally conduct an in-depth human evaluation study of both\nuser-written and system-generated summaries, highlighting challenges in this\nresearch.\n",
                "链接": "https://arxiv.org/abs/2206.00856"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "73470",
                "标题": "Invariant Scattering Transform for Medical Imaging",
                "作者": " Md Manjurul Ahsan,  Shivakumar Raman,  Zahed Siddique",
                "发布日期": "2023-06-01",
                "摘要": "  Over the years, the Invariant Scattering Transform (IST) technique has become\npopular for medical image analysis, including using wavelet transform\ncomputation using Convolutional Neural Networks (CNN) to capture patterns'\nscale and orientation in the input signal. IST aims to be invariant to\ntransformations that are common in medical images, such as translation,\nrotation, scaling, and deformation, used to improve the performance in medical\nimaging applications such as segmentation, classification, and registration,\nwhich can be integrated into machine learning algorithms for disease detection,\ndiagnosis, and treatment planning. Additionally, combining IST with deep\nlearning approaches has the potential to leverage their strengths and enhance\nmedical image analysis outcomes. This study provides an overview of IST in\nmedical imaging by considering the types of IST, their application,\nlimitations, and potential scopes for future researchers and practitioners.\n",
                "链接": "https://arxiv.org/abs/2304.10582"
            },
            {
                "文章ID": "92854",
                "标题": "Deep Learning Approaches for Data Augmentation in Medical Imaging: A\n  Review",
                "作者": " Aghiles Kebaili,  Jérôme Lapuyade-Lahorgue,  Su Ruan",
                "发布日期": "2023-07-26",
                "摘要": "  Deep learning has become a popular tool for medical image analysis, but the\nlimited availability of training data remains a major challenge, particularly\nin the medical field where data acquisition can be costly and subject to\nprivacy regulations. Data augmentation techniques offer a solution by\nartificially increasing the number of training samples, but these techniques\noften produce limited and unconvincing results. To address this issue, a\ngrowing number of studies have proposed the use of deep generative models to\ngenerate more realistic and diverse data that conform to the true distribution\nof the data. In this review, we focus on three types of deep generative models\nfor medical image augmentation: variational autoencoders, generative\nadversarial networks, and diffusion models. We provide an overview of the\ncurrent state of the art in each of these models and discuss their potential\nfor use in different downstream tasks in medical imaging, including\nclassification, segmentation, and cross-modal translation. We also evaluate the\nstrengths and limitations of each model and suggest directions for future\nresearch in this field. Our goal is to provide a comprehensive review about the\nuse of deep generative models for medical image augmentation and to highlight\nthe potential of these models for improving the performance of deep learning\nalgorithms in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2307.13125"
            },
            {
                "文章ID": "90244",
                "标题": "Invariant Scattering Transform for Medical Imaging",
                "作者": " Nafisa Labiba Ishrat Huda,  Angona Biswas,  MD Abdullah Al Nasim,  Md. Fahim Rahman,  Shoaib Ahmed",
                "发布日期": "2023-07-12",
                "摘要": "  Invariant scattering transform introduces new area of research that merges\nthe signal processing with deep learning for computer vision. Nowadays, Deep\nLearning algorithms are able to solve a variety of problems in medical sector.\nMedical images are used to detect diseases brain cancer or tumor, Alzheimer's\ndisease, breast cancer, Parkinson's disease and many others. During pandemic\nback in 2020, machine learning and deep learning has played a critical role to\ndetect COVID-19 which included mutation analysis, prediction, diagnosis and\ndecision making. Medical images like X-ray, MRI known as magnetic resonance\nimaging, CT scans are used for detecting diseases. There is another method in\ndeep learning for medical imaging which is scattering transform. It builds\nuseful signal representation for image classification. It is a wavelet\ntechnique; which is impactful for medical image classification problems. This\nresearch article discusses scattering transform as the efficient system for\nmedical image analysis where it's figured by scattering the signal information\nimplemented in a deep convolutional network. A step by step case study is\nmanifested at this research work.\n",
                "链接": "https://arxiv.org/abs/2307.04771"
            },
            {
                "文章ID": "82718",
                "标题": "Introduction to Medical Imaging Informatics",
                "作者": " Md. Zihad Bin Jahangir,  Ruksat Hossain,  Riadul Islam,  MD Abdullah Al Nasim,  Md. Mahim Anjum Haque,  Md Jahangir Alam,  Sajedul Talukder",
                "发布日期": "2023-06-21",
                "摘要": "  Medical imaging informatics is a rapidly growing field that combines the\nprinciples of medical imaging and informatics to improve the acquisition,\nmanagement, and interpretation of medical images. This chapter introduces the\nbasic concepts of medical imaging informatics, including image processing,\nfeature engineering, and machine learning. It also discusses the recent\nadvancements in computer vision and deep learning technologies and how they are\nused to develop new quantitative image markers and prediction models for\ndisease detection, diagnosis, and prognosis prediction. By covering the basic\nknowledge of medical imaging informatics, this chapter provides a foundation\nfor understanding the role of informatics in medicine and its potential impact\non patient care.\n",
                "链接": "https://arxiv.org/abs/2306.00421"
            },
            {
                "文章ID": "84417",
                "标题": "AutoML Systems For Medical Imaging",
                "作者": " Tasmia Tahmida Jidney,  Angona Biswas,  MD Abdullah Al Nasim,  Ismail Hossain,  Md Jahangir Alam,  Sajedul Talukder,  Mofazzal Hossain,  Dr. Md Azim Ullah",
                "发布日期": "2023-06-21",
                "摘要": "  The integration of machine learning in medical image analysis can greatly\nenhance the quality of healthcare provided by physicians. The combination of\nhuman expertise and computerized systems can result in improved diagnostic\naccuracy. An automated machine learning approach simplifies the creation of\ncustom image recognition models by utilizing neural architecture search and\ntransfer learning techniques. Medical imaging techniques are used to\nnon-invasively create images of internal organs and body parts for diagnostic\nand procedural purposes. This article aims to highlight the potential\napplications, strategies, and techniques of AutoML in medical imaging through\ntheoretical and empirical evidence.\n",
                "链接": "https://arxiv.org/abs/2306.04750"
            },
            {
                "文章ID": "103258",
                "标题": "A Systematic Review of Few-Shot Learning in Medical Imaging",
                "作者": " Eva Pachetti,  Sara Colantonio",
                "发布日期": "2023-09-21",
                "摘要": "  The lack of annotated medical images limits the performance of deep learning\nmodels, which usually need large-scale labelled datasets. Few-shot learning\ntechniques can reduce data scarcity issues and enhance medical image analysis,\nespecially with meta-learning. This systematic review gives a comprehensive\noverview of few-shot learning in medical imaging. We searched the literature\nsystematically and selected 80 relevant articles published from 2018 to 2023.\nWe clustered the articles based on medical outcomes, such as tumour\nsegmentation, disease classification, and image registration; anatomical\nstructure investigated (i.e. heart, lung, etc.); and the meta-learning method\nused. For each cluster, we examined the papers' distributions and the results\nprovided by the state-of-the-art. In addition, we identified a generic pipeline\nshared among all the studies. The review shows that few-shot learning can\novercome data scarcity in most outcomes and that meta-learning is a popular\nchoice to perform few-shot learning because it can adapt to new tasks with few\nlabelled samples. In addition, following meta-learning, supervised learning and\nsemi-supervised learning stand out as the predominant techniques employed to\ntackle few-shot learning challenges in medical imaging and also best\nperforming. Lastly, we observed that the primary application areas\npredominantly encompass cardiac, pulmonary, and abdominal domains. This\nsystematic review aims to inspire further research to improve medical image\nanalysis and patient care.\n",
                "链接": "https://arxiv.org/abs/2309.11433"
            },
            {
                "文章ID": "76251",
                "标题": "Few Shot Learning for Medical Imaging: A Comparative Analysis of\n  Methodologies and Formal Mathematical Framework",
                "作者": " Jannatul Nayem,  Sayed Sahriar Hasan,  Noshin Amina,  Bristy Das,  Md Shahin Ali,  Md Manjurul Ahsan,  Shivakumar Raman",
                "发布日期": "2023-06-01",
                "摘要": "  Deep learning becomes an elevated context regarding disposing of many machine\nlearning tasks and has shown a breakthrough upliftment to extract features from\nunstructured data. Though this flourishing context is developing in the medical\nimage processing sector, scarcity of problem-dependent training data has become\na larger issue in the way of easy application of deep learning in the medical\nsector. To unravel the confined data source, researchers have developed a model\nthat can solve machine learning problems with fewer data called ``Few shot\nlearning\". Few hot learning algorithms determine to solve the data limitation\nproblems by extracting the characteristics from a small dataset through\nclassification and segmentation methods. In the medical sector, there is\nfrequently a shortage of available datasets in respect of some confidential\ndiseases. Therefore, Few shot learning gets the limelight in this data scarcity\nsector. In this chapter, the background and basic overview of a few shots of\nlearning is represented. Henceforth, the classification of few-shot learning is\ndescribed also. Even the paper shows a comparison of methodological approaches\nthat are applied in medical image analysis over time. The current advancement\nin the implementation of few-shot learning concerning medical imaging is\nillustrated. The future scope of this domain in the medical imaging sector is\nfurther described.\n",
                "链接": "https://arxiv.org/abs/2305.04401"
            },
            {
                "文章ID": "94331",
                "标题": "Deep learning for unsupervised domain adaptation in medical imaging:\n  Recent advancements and future perspectives",
                "作者": " Suruchi Kumari,  Pravendra Singh",
                "发布日期": "2023-08-03",
                "摘要": "  Deep learning has demonstrated remarkable performance across various tasks in\nmedical imaging. However, these approaches primarily focus on supervised\nlearning, assuming that the training and testing data are drawn from the same\ndistribution. Unfortunately, this assumption may not always hold true in\npractice. To address these issues, unsupervised domain adaptation (UDA)\ntechniques have been developed to transfer knowledge from a labeled domain to a\nrelated but unlabeled domain. In recent years, significant advancements have\nbeen made in UDA, resulting in a wide range of methodologies, including feature\nalignment, image translation, self-supervision, and disentangled representation\nmethods, among others. In this paper, we provide a comprehensive literature\nreview of recent deep UDA approaches in medical imaging from a technical\nperspective. Specifically, we categorize current UDA research in medical\nimaging into six groups and further divide them into finer subcategories based\non the different tasks they perform. We also discuss the respective datasets\nused in the studies to assess the divergence between the different domains.\nFinally, we discuss emerging areas and provide insights and discussions on\nfuture research directions to conclude this survey.\n",
                "链接": "https://arxiv.org/abs/2308.01265"
            },
            {
                "文章ID": "122010",
                "标题": "CLIP in Medical Imaging: A Comprehensive Survey",
                "作者": " Zihao Zhao,  Yuxiao Liu,  Han Wu,  Yonghao Li,  Sheng Wang,  Lin Teng,  Disheng Liu,  Zhiming Cui,  Qian Wang,  Dinggang Shen",
                "发布日期": "2023-12-27",
                "摘要": "  Contrastive Language-Image Pre-training (CLIP), a simple yet effective\npre-training paradigm, successfully introduces text supervision to vision\nmodels. It has shown promising results across various tasks, attributable to\nits generalizability and interpretability. The use of CLIP has recently gained\nincreasing interest in the medical imaging domain, serving both as a\npre-training paradigm for aligning medical vision and language, and as a\ncritical component in diverse clinical tasks. With the aim of facilitating a\ndeeper understanding of this promising direction, this survey offers an\nin-depth exploration of the CLIP paradigm within the domain of medical imaging,\nregarding both refined CLIP pre-training and CLIP-driven applications. In this\nstudy, We (1) start with a brief introduction to the fundamentals of CLIP\nmethodology. (2) Then, we investigate the adaptation of CLIP pre-training in\nthe medical domain, focusing on how to optimize CLIP given characteristics of\nmedical images and reports. (3) Furthermore, we explore the practical\nutilization of CLIP pre-trained models in various tasks, including\nclassification, dense prediction, and cross-modal tasks. (4) Finally, we\ndiscuss existing limitations of CLIP in the context of medical imaging and\npropose forward-looking directions to address the demands of medical imaging\ndomain. We expect that this comprehensive survey will provide researchers in\nthe field of medical image analysis with a holistic understanding of the CLIP\nparadigm and its potential implications. The project page can be found on\nhttps://github.com/zhaozh10/Awesome-CLIP-in-Medical-Imaging.\n",
                "链接": "https://arxiv.org/abs/2312.07353"
            },
            {
                "文章ID": "82624",
                "标题": "Multi-environment lifelong deep reinforcement learning for medical\n  imaging",
                "作者": " Guangyao Zheng,  Shuhao Lai,  Vladimir Braverman,  Michael A. Jacobs,  Vishwa S. Parekh",
                "发布日期": "2023-06-02",
                "摘要": "  Deep reinforcement learning(DRL) is increasingly being explored in medical\nimaging. However, the environments for medical imaging tasks are constantly\nevolving in terms of imaging orientations, imaging sequences, and pathologies.\nTo that end, we developed a Lifelong DRL framework, SERIL to continually learn\nnew tasks in changing imaging environments without catastrophic forgetting.\nSERIL was developed using selective experience replay based lifelong learning\ntechnique for the localization of five anatomical landmarks in brain MRI on a\nsequence of twenty-four different imaging environments. The performance of\nSERIL, when compared to two baseline setups: MERT(multi-environment-best-case)\nand SERT(single-environment-worst-case) demonstrated excellent performance with\nan average distance of $9.90\\pm7.35$ pixels from the desired landmark across\nall 120 tasks, compared to $10.29\\pm9.07$ for MERT and $36.37\\pm22.41$ for\nSERT($p<0.05$), demonstrating the excellent potential for continuously learning\nmultiple tasks across dynamically changing imaging environments.\n",
                "链接": "https://arxiv.org/abs/2306.00188"
            }
        ]
    },
    {
        "question": {
            "question": "查找基于优化实现模型越狱的文献",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "114015",
                "标题": "DeepInception: Hypnotize Large Language Model to Be Jailbreaker",
                "作者": " Xuan Li,  Zhanke Zhou,  Jianing Zhu,  Jiangchao Yao,  Tongliang Liu,  Bo Han",
                "发布日期": "2023-12-06",
                "摘要": "  Despite remarkable success in various applications, large language models\n(LLMs) are vulnerable to adversarial jailbreaks that make the safety guardrails\nvoid. However, previous studies for jailbreaks usually resort to brute-force\noptimization or extrapolations of a high computation cost, which might not be\npractical or effective. In this paper, inspired by the Milgram experiment that\nindividuals can harm another person if they are told to do so by an\nauthoritative figure, we disclose a lightweight method, termed as\nDeepInception, which can easily hypnotize LLM to be a jailbreaker and unlock\nits misusing risks. Specifically, DeepInception leverages the personification\nability of LLM to construct a novel nested scene to behave, which realizes an\nadaptive way to escape the usage control in a normal scenario and provides the\npossibility for further direct jailbreaks. Empirically, we conduct\ncomprehensive experiments to show its efficacy. Our DeepInception can achieve\ncompetitive jailbreak success rates with previous counterparts and realize a\ncontinuous jailbreak in subsequent interactions, which reveals the critical\nweakness of self-losing on both open/closed-source LLMs like Falcon, Vicuna,\nLlama-2, and GPT-3.5/4/4V. Our investigation appeals that people should pay\nmore attention to the safety aspects of LLMs and a stronger defense against\ntheir misuse risks. The code is publicly available at:\nhttps://github.com/tmlr-group/DeepInception.\n",
                "链接": "https://arxiv.org/abs/2311.03191"
            },
            {
                "文章ID": "118933",
                "标题": "Query-Relevant Images Jailbreak Large Multi-Modal Models",
                "作者": " Xin Liu,  Yichen Zhu,  Yunshi Lan,  Chao Yang,  Yu Qiao",
                "发布日期": "2023-11-30",
                "摘要": "  Warning: This paper contains examples of harmful language and images, and\nreader discretion is recommended. The security concerns surrounding Large\nLanguage Models (LLMs) have been extensively explored, yet the safety of Large\nMulti-Modal Models (LMMs) remains understudied. In our study, we present a\nnovel visual prompt attack that exploits query-relevant images to jailbreak the\nopen-source LMMs. Our method creates a composite image from one image generated\nby diffusion models and another that displays the text as typography, based on\nkeywords extracted from a malicious query. We show LLMs can be easily attacked\nby our approach, even if the employed Large Language Models are safely aligned.\nTo evaluate the extent of this vulnerability in open-source LMMs, we have\ncompiled a substantial dataset encompassing 13 scenarios with a total of 5,040\ntext-image pairs, using our presented attack technique. Our evaluation of 12\ncutting-edge LMMs using this dataset shows the vulnerability of existing\nmulti-modal models on adversarial attacks. This finding underscores the need\nfor a concerted effort to strengthen and enhance the safety measures of\nopen-source LMMs against potential malicious exploits. The resource is\navailable at \\href{this https URL}{https://github.com/isXinLiu/MM-SafetyBench}.\n",
                "链接": "https://arxiv.org/abs/2311.17600"
            },
            {
                "文章ID": "93279",
                "标题": "Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal\n  Language Models",
                "作者": " Erfan Shayegani,  Yue Dong,  Nael Abu-Ghazaleh",
                "发布日期": "2023-10-12",
                "摘要": "  We introduce new jailbreak attacks on vision language models (VLMs), which\nuse aligned LLMs and are resilient to text-only jailbreak attacks.\nSpecifically, we develop cross-modality attacks on alignment where we pair\nadversarial images going through the vision encoder with textual prompts to\nbreak the alignment of the language model. Our attacks employ a novel\ncompositional strategy that combines an image, adversarially targeted towards\ntoxic embeddings, with generic prompts to accomplish the jailbreak. Thus, the\nLLM draws the context to answer the generic prompt from the adversarial image.\nThe generation of benign-appearing adversarial images leverages a novel\nembedding-space-based methodology, operating with no access to the LLM model.\nInstead, the attacks require access only to the vision encoder and utilize one\nof our four embedding space targeting strategies. By not requiring access to\nthe LLM, the attacks lower the entry barrier for attackers, particularly when\nvision encoders such as CLIP are embedded in closed-source LLMs. The attacks\nachieve a high success rate across different VLMs, highlighting the risk of\ncross-modality alignment vulnerabilities, and the need for new alignment\napproaches for multi-modal models.\n",
                "链接": "https://arxiv.org/abs/2307.14539"
            },
            {
                "文章ID": "107692",
                "标题": "Multilingual Jailbreak Challenges in Large Language Models",
                "作者": " Yue Deng,  Wenxuan Zhang,  Sinno Jialin Pan,  Lidong Bing",
                "发布日期": "2023-10-11",
                "摘要": "  While large language models (LLMs) exhibit remarkable capabilities across a\nwide range of tasks, they pose potential safety concerns, such as the\n``jailbreak'' problem, wherein malicious instructions can manipulate LLMs to\nexhibit undesirable behavior. Although several preventive measures have been\ndeveloped to mitigate the potential risks associated with LLMs, they have\nprimarily focused on English data. In this study, we reveal the presence of\nmultilingual jailbreak challenges within LLMs and consider two potential risk\nscenarios: unintentional and intentional. The unintentional scenario involves\nusers querying LLMs using non-English prompts and inadvertently bypassing the\nsafety mechanisms, while the intentional scenario concerns malicious users\ncombining malicious instructions with multilingual prompts to deliberately\nattack LLMs. The experimental results reveal that in the unintentional\nscenario, the rate of unsafe content increases as the availability of languages\ndecreases. Specifically, low-resource languages exhibit three times the\nlikelihood of encountering harmful content compared to high-resource languages,\nwith both ChatGPT and GPT-4. In the intentional scenario, multilingual prompts\ncan exacerbate the negative impact of malicious instructions, with\nastonishingly high rates of unsafe output: 80.92\\% for ChatGPT and 40.71\\% for\nGPT-4. To handle such a challenge in the multilingual context, we propose a\nnovel \\textsc{Self-Defense} framework that automatically generates multilingual\ntraining data for safety fine-tuning. Experimental results show that ChatGPT\nfine-tuned with such data can achieve a substantial reduction in unsafe content\ngeneration. Data is available at\nhttps://github.com/DAMO-NLP-SG/multilingual-safety-for-LLMs. Warning: This\npaper contains examples with potentially harmful content.\n",
                "链接": "https://arxiv.org/abs/2310.06474"
            },
            {
                "文章ID": "115646",
                "标题": "A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can\n  Fool Large Language Models Easily",
                "作者": " Peng Ding,  Jun Kuang,  Dan Ma,  Xuezhi Cao,  Yunsen Xian,  Jiajun Chen,  Shujian Huang",
                "发布日期": "2023-11-15",
                "摘要": "  Large Language Models (LLMs), such as ChatGPT and GPT-4, are designed to\nprovide useful and safe responses. However, adversarial prompts known as\n'jailbreaks' can circumvent safeguards, leading LLMs to generate harmful\ncontent. Exploring jailbreak prompts can help to better reveal the weaknesses\nof LLMs and further steer us to secure them. Unfortunately, existing jailbreak\nmethods either suffer from intricate manual design or require optimization on\nanother white-box model, compromising generalization or jailbreak efficiency.\nIn this paper, we generalize jailbreak prompt attacks into two aspects: (1)\nPrompt Rewriting and (2) Scenario Nesting. Based on this, we propose ReNeLLM,\nan automatic framework that leverages LLMs themselves to generate effective\njailbreak prompts. Extensive experiments demonstrate that ReNeLLM significantly\nimproves the attack success rate while greatly reducing the time cost compared\nto existing baselines. Our study also reveals the inadequacy of current defense\nmethods in safeguarding LLMs. Finally, we offer detailed analysis and\ndiscussion from the perspective of prompt execution priority on the failure of\nLLMs' defense. We hope that our research can catalyze both the academic\ncommunity and LLMs vendors towards the provision of safer and more regulated\nLarge Language Models.\n",
                "链接": "https://arxiv.org/abs/2311.08268"
            },
            {
                "文章ID": "87400",
                "标题": "Visual Adversarial Examples Jailbreak Aligned Large Language Models",
                "作者": " Xiangyu Qi,  Kaixuan Huang,  Ashwinee Panda,  Peter Henderson,  Mengdi Wang,  Prateek Mittal",
                "发布日期": "2023-08-21",
                "摘要": "  Recently, there has been a surge of interest in integrating vision into Large\nLanguage Models (LLMs), exemplified by Visual Language Models (VLMs) such as\nFlamingo and GPT-4. This paper sheds light on the security and safety\nimplications of this trend. First, we underscore that the continuous and\nhigh-dimensional nature of the visual input makes it a weak link against\nadversarial attacks, representing an expanded attack surface of\nvision-integrated LLMs. Second, we highlight that the versatility of LLMs also\npresents visual attackers with a wider array of achievable adversarial\nobjectives, extending the implications of security failures beyond mere\nmisclassification. As an illustration, we present a case study in which we\nexploit visual adversarial examples to circumvent the safety guardrail of\naligned LLMs with integrated vision. Intriguingly, we discover that a single\nvisual adversarial example can universally jailbreak an aligned LLM, compelling\nit to heed a wide range of harmful instructions that it otherwise would not)\nand generate harmful content that transcends the narrow scope of a `few-shot'\nderogatory corpus initially employed to optimize the adversarial example. Our\nstudy underscores the escalating adversarial risks associated with the pursuit\nof multimodality. Our findings also connect the long-studied adversarial\nvulnerabilities of neural networks to the nascent field of AI alignment. The\npresented attack suggests a fundamental adversarial challenge for AI alignment,\nespecially in light of the emerging trend toward multimodality in frontier\nfoundation models.\n",
                "链接": "https://arxiv.org/abs/2306.13213"
            },
            {
                "文章ID": "108400",
                "标题": "Jailbreaking Black Box Large Language Models in Twenty Queries",
                "作者": " Patrick Chao,  Alexander Robey,  Edgar Dobriban,  Hamed Hassani,  George J. Pappas,  Eric Wong",
                "发布日期": "2023-10-17",
                "摘要": "  There is growing interest in ensuring that large language models (LLMs) align\nwith human values. However, the alignment of such models is vulnerable to\nadversarial jailbreaks, which coax LLMs into overriding their safety\nguardrails. The identification of these vulnerabilities is therefore\ninstrumental in understanding inherent weaknesses and preventing future misuse.\nTo this end, we propose Prompt Automatic Iterative Refinement (PAIR), an\nalgorithm that generates semantic jailbreaks with only black-box access to an\nLLM. PAIR -- which is inspired by social engineering attacks -- uses an\nattacker LLM to automatically generate jailbreaks for a separate targeted LLM\nwithout human intervention. In this way, the attacker LLM iteratively queries\nthe target LLM to update and refine a candidate jailbreak. Empirically, PAIR\noften requires fewer than twenty queries to produce a jailbreak, which is\norders of magnitude more efficient than existing algorithms. PAIR also achieves\ncompetitive jailbreaking success rates and transferability on open and\nclosed-source LLMs, including GPT-3.5/4, Vicuna, and PaLM-2.\n",
                "链接": "https://arxiv.org/abs/2310.08419"
            },
            {
                "文章ID": "106864",
                "标题": "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language\n  Models",
                "作者": " Xiaogeng Liu,  Nan Xu,  Muhao Chen,  Chaowei Xiao",
                "发布日期": "2023-10-10",
                "摘要": "  The aligned Large Language Models (LLMs) are powerful language understanding\nand decision-making tools that are created through extensive alignment with\nhuman feedback. However, these large models remain susceptible to jailbreak\nattacks, where adversaries manipulate prompts to elicit malicious outputs that\nshould not be given by aligned LLMs. Investigating jailbreak prompts can lead\nus to delve into the limitations of LLMs and further guide us to secure them.\nUnfortunately, existing jailbreak techniques suffer from either (1) scalability\nissues, where attacks heavily rely on manual crafting of prompts, or (2)\nstealthiness problems, as attacks depend on token-based algorithms to generate\nprompts that are often semantically meaningless, making them susceptible to\ndetection through basic perplexity testing. In light of these challenges, we\nintend to answer this question: Can we develop an approach that can\nautomatically generate stealthy jailbreak prompts? In this paper, we introduce\nAutoDAN, a novel jailbreak attack against aligned LLMs. AutoDAN can\nautomatically generate stealthy jailbreak prompts by the carefully designed\nhierarchical genetic algorithm. Extensive evaluations demonstrate that AutoDAN\nnot only automates the process while preserving semantic meaningfulness, but\nalso demonstrates superior attack strength in cross-model transferability, and\ncross-sample universality compared with the baseline. Moreover, we also compare\nAutoDAN with perplexity-based defense methods and show that AutoDAN can bypass\nthem effectively.\n",
                "链接": "https://arxiv.org/abs/2310.04451"
            },
            {
                "文章ID": "115932",
                "标题": "Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts",
                "作者": " Yuanwei Wu,  Xiang Li,  Yixin Liu,  Pan Zhou,  Lichao Sun",
                "发布日期": "2023-11-16",
                "摘要": "  Existing work on jailbreak Multimodal Large Language Models (MLLMs) has\nfocused primarily on adversarial examples in model inputs, with less attention\nto vulnerabilities in model APIs. To fill the research gap, we carry out the\nfollowing work: 1) We discover a system prompt leakage vulnerability in GPT-4V.\nThrough carefully designed dialogue, we successfully steal the internal system\nprompts of GPT-4V. This finding indicates potential exploitable security risks\nin MLLMs; 2)Based on the acquired system prompts, we propose a novel MLLM\njailbreaking attack method termed SASP (Self-Adversarial Attack via System\nPrompt). By employing GPT-4 as a red teaming tool against itself, we aim to\nsearch for potential jailbreak prompts leveraging stolen system prompts.\nFurthermore, in pursuit of better performance, we also add human modification\nbased on GPT-4's analysis, which further improves the attack success rate to\n98.7\\%; 3) We evaluated the effect of modifying system prompts to defend\nagainst jailbreaking attacks. Results show that appropriately designed system\nprompts can significantly reduce jailbreak success rates. Overall, our work\nprovides new insights into enhancing MLLM security, demonstrating the important\nrole of system prompts in jailbreaking, which could be leveraged to greatly\nfacilitate jailbreak success rates while also holding the potential for\ndefending against jailbreaks.\n",
                "链接": "https://arxiv.org/abs/2311.09127"
            },
            {
                "文章ID": "106172",
                "标题": "Low-Resource Languages Jailbreak GPT-4",
                "作者": " Zheng-Xin Yong,  Cristina Menghini,  Stephen H. Bach",
                "发布日期": "2023-10-05",
                "摘要": "  AI safety training and red-teaming of large language models (LLMs) are\nmeasures to mitigate the generation of unsafe content. Our work exposes the\ninherent cross-lingual vulnerability of these safety mechanisms, resulting from\nthe linguistic inequality of safety training data, by successfully\ncircumventing GPT-4's safeguard through translating unsafe English inputs into\nlow-resource languages. On the AdvBenchmark, GPT-4 engages with the unsafe\ntranslated inputs and provides actionable items that can get the users towards\ntheir harmful goals 79% of the time, which is on par with or even surpassing\nstate-of-the-art jailbreaking attacks. Other high-/mid-resource languages have\nsignificantly lower attack success rate, which suggests that the cross-lingual\nvulnerability mainly applies to low-resource languages. Previously, limited\ntraining on low-resource languages primarily affects speakers of those\nlanguages, causing technological disparities. However, our work highlights a\ncrucial shift: this deficiency now poses a risk to all LLMs users. Publicly\navailable translation APIs enable anyone to exploit LLMs' safety\nvulnerabilities. Therefore, our work calls for a more holistic red-teaming\nefforts to develop robust multilingual safeguards with wide language coverage.\n",
                "链接": "https://arxiv.org/abs/2310.02446"
            }
        ]
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "110744",
                "标题": "ALCUNA: Large Language Models Meet New Knowledge",
                "作者": " Xunjian Yin,  Baizhou Huang,  Xiaojun Wan",
                "发布日期": "2023-10-24",
                "摘要": "  With the rapid development of NLP, large-scale language models (LLMs) excel\nin various tasks across multiple domains now. However, existing benchmarks may\nnot adequately measure these models' capabilities, especially when faced with\nnew knowledge. In this paper, we address the lack of benchmarks to evaluate\nLLMs' ability to handle new knowledge, an important and challenging aspect in\nthe rapidly evolving world. We propose an approach called KnowGen that\ngenerates new knowledge by altering existing entity attributes and\nrelationships, resulting in artificial entities that are distinct from\nreal-world entities. With KnowGen, we introduce a benchmark named ALCUNA to\nassess LLMs' abilities in knowledge understanding, differentiation, and\nassociation. We benchmark several LLMs, reveals that their performance in face\nof new knowledge is not satisfactory, particularly in reasoning between new and\ninternal knowledge. We also explore the impact of entity similarity on the\nmodel's understanding of entity knowledge and the influence of contextual\nentities. We appeal to the need for caution when using LLMs in new scenarios or\nwith new knowledge, and hope that our benchmarks can help drive the development\nof LLMs in face of new knowledge.\n",
                "链接": "https://arxiv.org/abs/2310.14820"
            },
            {
                "文章ID": "66370",
                "标题": "Algorithmic Ghost in the Research Shell: Large Language Models and\n  Academic Knowledge Creation in Management Research",
                "作者": " Nigel Williams,  Stanislav Ivanov,  Dimitrios Buhalis",
                "发布日期": "2023-03-14",
                "摘要": "  The paper looks at the role of large language models in academic knowledge\ncreation based on a scoping review (2018 to January 2023) of how researchers\nhave previously used the language model GPT to assist in the performance of\nacademic knowledge creation tasks beyond data analysis. These tasks include\nwriting, editing, reviewing, dataset creation and curation, which have been\ndifficult to perform using earlier ML tools. Based on a synthesis of these\npapers, this study identifies pathways for a future academic research landscape\nthat incorporates wider usage of large language models based on the current\nmodes of adoption in published articles as a Co-Writer, Research Assistant and\nRespondent.\n",
                "链接": "https://arxiv.org/abs/2303.07304"
            },
            {
                "文章ID": "114645",
                "标题": "Characterizing Large Language Models as Rationalizers of\n  Knowledge-intensive Tasks",
                "作者": " Aditi Mishra,  Sajjadur Rahman,  Hannah Kim,  Kushan Mitra,  Estevam Hruschka",
                "发布日期": "2023-11-10",
                "摘要": "  Large language models (LLMs) are proficient at generating fluent text with\nminimal task-specific supervision. Yet, their ability to provide well-grounded\nrationalizations for knowledge-intensive tasks remains under-explored. Such\ntasks, like commonsense multiple-choice questions, require rationales based on\nworld knowledge to support predictions and refute alternate options. We\nconsider the task of generating knowledge-guided rationalization in natural\nlanguage by using expert-written examples in a few-shot manner. Surprisingly,\ncrowd-workers preferred knowledge-grounded rationales over crowdsourced\nrationalizations, citing their factuality, sufficiency, and comprehensive\nrefutations. Although LLMs-generated rationales were preferable, further\nimprovements in conciseness and novelty are required. In another study, we show\nhow rationalization of incorrect model predictions erodes humans' trust in\nLLM-generated rationales. Motivated by these observations, we create a\ntwo-stage pipeline to review task predictions and eliminate potential incorrect\ndecisions before rationalization, enabling trustworthy rationale generation.\n",
                "链接": "https://arxiv.org/abs/2311.05085"
            },
            {
                "文章ID": "48526",
                "标题": "When to Use What: An In-Depth Comparative Empirical Analysis of OpenIE\n  Systems for Downstream Applications",
                "作者": "Grainger College of Engineering, University of Illinois at\n  Urbana-Champaign  Kevin Pei, IBM Research  Ishan Jindal, Grainger College of Engineering, University of Illinois at\n  Urbana-Champaign  Kevin Chen-Chuan Chang, Grainger College of Engineering,\n  University of Illinois at Urbana-Champaign  Chengxiang Zhai, Apple Knowledge\n  Platform  Yunyao Li",
                "发布日期": "2022-11-16",
                "摘要": "  Open Information Extraction (OpenIE) has been used in the pipelines of\nvarious NLP tasks. Unfortunately, there is no clear consensus on which models\nto use in which tasks. Muddying things further is the lack of comparisons that\ntake differing training sets into account. In this paper, we present an\napplication-focused empirical survey of neural OpenIE models, training sets,\nand benchmarks in an effort to help users choose the most suitable OpenIE\nsystems for their applications. We find that the different assumptions made by\ndifferent models and datasets have a statistically significant effect on\nperformance, making it important to choose the most appropriate model for one's\napplications. We demonstrate the applicability of our recommendations on a\ndownstream Complex QA application.\n",
                "链接": "https://arxiv.org/abs/2211.08228"
            },
            {
                "文章ID": "111213",
                "标题": "Alquist 5.0: Dialogue Trees Meet Generative Models. A Novel Approach for\n  Enhancing SocialBot Conversations",
                "作者": "Faculty of Electrical Engineering, CTU in Prague  Ondřej Kobza, Faculty of Electrical Engineering, CTU in Prague  Jan Čuhel, Faculty of Electrical Engineering, CTU in Prague  Tommaso Gargiani, Faculty of Electrical Engineering, CTU in Prague  David Herel, Faculty of Electrical Engineering, CTU in Prague  Petr Marek",
                "发布日期": "2023-10-26",
                "摘要": "  We present our SocialBot -- Alquist~5.0 -- developed for the Alexa Prize\nSocialBot Grand Challenge~5. Building upon previous versions of our system, we\nintroduce the NRG Barista and outline several innovative approaches for\nintegrating Barista into our SocialBot, improving the overall conversational\nexperience. Additionally, we extend our SocialBot to support multimodal\ndevices. This paper offers insights into the development of Alquist~5.0, which\nmeets evolving user expectations while maintaining empathetic and knowledgeable\nconversational abilities across diverse topics.\n",
                "链接": "https://arxiv.org/abs/2310.16119"
            },
            {
                "文章ID": "32789",
                "标题": "Areas of Strategic Visibility: Disability Bias in Biometrics",
                "作者": "representing the Center for Research and Education\n  on Accessible Technology and Experiences, U. Washington  Jennifer Mankoff, City University of New York  Devva Kasnitz, City University of New York  Disability Studies, Indiana U.  L Jean Camp, U. of Maryland, HCIL, Trace Center  Jonathan Lazar, U. of\n  Pittsburgh  Harry Hochheiser",
                "发布日期": "2022-08-24",
                "摘要": "  This response to the RFI considers the potential for biometrics to help or\nharm disabled people2. Biometrics are already integrated into many aspects of\ndaily life, from airport travel to mobile phone use. Yet many of these systems\nare not accessible to people who experience different kinds of disability\nexclusion . Different personal characteristics may impact any or all of the\nphysical (DNA, fingerprints, face or retina) and behavioral (gesture, gait,\nvoice) characteristics listed in the RFI as examples of biometric signals.\n",
                "链接": "https://arxiv.org/abs/2208.04712"
            },
            {
                "文章ID": "119143",
                "标题": "Label-efficient Training of Small Task-specific Models by Leveraging\n  Vision Foundation Models",
                "作者": " Raviteja Vemulapalli,  Hadi Pouransari,  Fartash Faghri,  Sachin Mehta,  Mehrdad Farajtabar,  Mohammad Rastegari,  Oncel Tuzel",
                "发布日期": "2023-12-01",
                "摘要": "  Large Vision Foundation Models (VFMs) pretrained on massive datasets exhibit\nimpressive performance on various downstream tasks, especially with limited\nlabeled target data. However, due to their high memory and compute\nrequirements, these models cannot be deployed in resource constrained settings.\nThis raises an important question: How can we utilize the knowledge from a\nlarge VFM to train a small task-specific model for a new target task with\nlimited labeled training data? In this work, we answer this question by\nproposing a simple and highly effective task-oriented knowledge transfer\napproach to leverage pretrained VFMs for effective training of small\ntask-specific models. Our experimental results on four target tasks under\nlimited labeled data settings show that the proposed knowledge transfer\napproach outperforms task-agnostic VFM distillation, web-scale CLIP pretraining\nand supervised ImageNet pretraining by 1-10.5%, 2-22% and 2-14%, respectively.\nWe also show that the dataset used for transferring knowledge has a significant\neffect on the final target task performance, and propose an image\nretrieval-based approach for curating effective transfer sets.\n",
                "链接": "https://arxiv.org/abs/2311.18237"
            },
            {
                "文章ID": "26664",
                "标题": "ST-Adapter: Parameter-Efficient Image-to-Video Transfer Learning",
                "作者": " Junting Pan,  Ziyi Lin,  Xiatian Zhu,  Jing Shao,  Hongsheng Li",
                "发布日期": "2022-10-14",
                "摘要": "  Capitalizing on large pre-trained models for various downstream tasks of\ninterest have recently emerged with promising performance. Due to the\never-growing model size, the standard full fine-tuning based task adaptation\nstrategy becomes prohibitively costly in terms of model training and storage.\nThis has led to a new research direction in parameter-efficient transfer\nlearning. However, existing attempts typically focus on downstream tasks from\nthe same modality (e.g., image understanding) of the pre-trained model. This\ncreates a limit because in some specific modalities, (e.g., video\nunderstanding) such a strong pre-trained model with sufficient knowledge is\nless or not available. In this work, we investigate such a novel cross-modality\ntransfer learning setting, namely parameter-efficient image-to-video transfer\nlearning. To solve this problem, we propose a new Spatio-Temporal Adapter\n(ST-Adapter) for parameter-efficient fine-tuning per video task. With a\nbuilt-in spatio-temporal reasoning capability in a compact design, ST-Adapter\nenables a pre-trained image model without temporal knowledge to reason about\ndynamic video content at a small (~8%) per-task parameter cost, requiring\napproximately 20 times fewer updated parameters compared to previous work.\nExtensive experiments on video action recognition tasks show that our\nST-Adapter can match or even outperform the strong full fine-tuning strategy\nand state-of-the-art video models, whilst enjoying the advantage of parameter\nefficiency. The code and model are available at\nhttps://github.com/linziyi96/st-adapter\n",
                "链接": "https://arxiv.org/abs/2206.13559"
            },
            {
                "文章ID": "16746",
                "标题": "Heterogeneous Ensemble Knowledge Transfer for Training Large Models in\n  Federated Learning",
                "作者": " Yae Jee Cho,  Andre Manoel,  Gauri Joshi,  Robert Sim,  Dimitrios Dimitriadis",
                "发布日期": "2022-04-28",
                "摘要": "  Federated learning (FL) enables edge-devices to collaboratively learn a model\nwithout disclosing their private data to a central aggregating server. Most\nexisting FL algorithms require models of identical architecture to be deployed\nacross the clients and server, making it infeasible to train large models due\nto clients' limited system resources. In this work, we propose a novel ensemble\nknowledge transfer method named Fed-ET in which small models (different in\narchitecture) are trained on clients, and used to train a larger model at the\nserver. Unlike in conventional ensemble learning, in FL the ensemble can be\ntrained on clients' highly heterogeneous data. Cognizant of this property,\nFed-ET uses a weighted consensus distillation scheme with diversity\nregularization that efficiently extracts reliable consensus from the ensemble\nwhile improving generalization by exploiting the diversity within the ensemble.\nWe show the generalization bound for the ensemble of weighted models trained on\nheterogeneous datasets that supports the intuition of Fed-ET. Our experiments\non image and language tasks show that Fed-ET significantly outperforms other\nstate-of-the-art FL algorithms with fewer communicated parameters, and is also\nrobust against high data-heterogeneity.\n",
                "链接": "https://arxiv.org/abs/2204.12703"
            },
            {
                "文章ID": "65848",
                "标题": "Knowledge Transfer via Multi-Head Feature Adaptation for Whole Slide\n  Image Classification",
                "作者": " Conghao Xiong,  Yi Lin,  Hao Chen,  Joseph Sung,  Irwin King",
                "发布日期": "2023-03-13",
                "摘要": "  Transferring prior knowledge from a source domain to the same or similar\ntarget domain can greatly enhance the performance of models on the target\ndomain. However, it is challenging to directly leverage the knowledge from the\nsource domain due to task discrepancy and domain shift. To bridge the gaps\nbetween different tasks and domains, we propose a Multi-Head Feature Adaptation\nmodule, which projects features in the source feature space to a new space that\nis more similar to the target space. Knowledge transfer is particularly\nimportant in Whole Slide Image (WSI) classification since the number of WSIs in\none dataset might be too small to achieve satisfactory performance. Therefore,\nWSI classification is an ideal testbed for our method, and we adapt multiple\nknowledge transfer methods for WSI classification. The experimental results\nshow that models with knowledge transfer outperform models that are trained\nfrom scratch by a large margin regardless of the number of WSIs in the\ndatasets, and our method achieves state-of-the-art performances among other\nknowledge transfer methods on multiple datasets, including TCGA-RCC,\nTCGA-NSCLC, and Camelyon16 datasets.\n",
                "链接": "https://arxiv.org/abs/2303.05780"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和人文学科交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "112477",
                "标题": "Artificial intelligence and the limits of the humanities",
                "作者": " Włodzisław Duch",
                "发布日期": "2023-10-31",
                "摘要": "  The complexity of cultures in the modern world is now beyond human\ncomprehension. Cognitive sciences cast doubts on the traditional explanations\nbased on mental models. The core subjects in humanities may lose their\nimportance. Humanities have to adapt to the digital age. New, interdisciplinary\nbranches of humanities emerge. Instant access to information will be replaced\nby instant access to knowledge. Understanding the cognitive limitations of\nhumans and the opportunities opened by the development of artificial\nintelligence and interdisciplinary research necessary to address global\nchallenges is the key to the revitalization of humanities. Artificial\nintelligence will radically change humanities, from art to political sciences\nand philosophy, making these disciplines attractive to students and enabling\nthem to go beyond current limitations.\n",
                "链接": "https://arxiv.org/abs/2310.19425"
            },
            {
                "文章ID": "39270",
                "标题": "Hierarchical Interdisciplinary Topic Detection Model for Research\n  Proposal Classification",
                "作者": " Meng Xiao,  Ziyue Qiao,  Yanjie Fu,  Hao Dong,  Yi Du,  Pengyang Wang,  Hui Xiong,  Yuanchun Zhou",
                "发布日期": "2023-02-23",
                "摘要": "  The peer merit review of research proposals has been the major mechanism for\ndeciding grant awards. However, research proposals have become increasingly\ninterdisciplinary. It has been a longstanding challenge to assign\ninterdisciplinary proposals to appropriate reviewers, so proposals are fairly\nevaluated. One of the critical steps in reviewer assignment is to generate\naccurate interdisciplinary topic labels for proposal-reviewer matching.\nExisting systems mainly collect topic labels manually generated by principal\ninvestigators. However, such human-reported labels can be non-accurate,\nincomplete, labor intensive, and time costly. What role can AI play in\ndeveloping a fair and precise proposal reviewer assignment system? In this\nstudy, we collaborate with the National Science Foundation of China to address\nthe task of automated interdisciplinary topic path detection. For this purpose,\nwe develop a deep Hierarchical Interdisciplinary Research Proposal\nClassification Network (HIRPCN). Specifically, we first propose a hierarchical\ntransformer to extract the textual semantic information of proposals. We then\ndesign an interdisciplinary graph and leverage GNNs for learning\nrepresentations of each discipline in order to extract interdisciplinary\nknowledge. After extracting the semantic and interdisciplinary knowledge, we\ndesign a level-wise prediction component to fuse the two types of knowledge\nrepresentations and detect interdisciplinary topic paths for each proposal. We\nconduct extensive experiments and expert evaluations on three real-world\ndatasets to demonstrate the effectiveness of our proposed model.\n",
                "链接": "https://arxiv.org/abs/2209.13519"
            },
            {
                "文章ID": "93762",
                "标题": "Text Analysis Using Deep Neural Networks in Digital Humanities and\n  Information Science",
                "作者": " Omri Suissa,  Avshalom Elmalech,  Maayan Zhitomirsky-Geffet",
                "发布日期": "2023-08-01",
                "摘要": "  Combining computational technologies and humanities is an ongoing effort\naimed at making resources such as texts, images, audio, video, and other\nartifacts digitally available, searchable, and analyzable. In recent years,\ndeep neural networks (DNN) dominate the field of automatic text analysis and\nnatural language processing (NLP), in some cases presenting a super-human\nperformance. DNNs are the state-of-the-art machine learning algorithms solving\nmany NLP tasks that are relevant for Digital Humanities (DH) research, such as\nspell checking, language detection, entity extraction, author detection,\nquestion answering, and other tasks. These supervised algorithms learn patterns\nfrom a large number of \"right\" and \"wrong\" examples and apply them to new\nexamples. However, using DNNs for analyzing the text resources in DH research\npresents two main challenges: (un)availability of training data and a need for\ndomain adaptation. This paper explores these challenges by analyzing multiple\nuse-cases of DH studies in recent literature and their possible solutions and\nlays out a practical decision model for DH experts for when and how to choose\nthe appropriate deep learning approaches for their research. Moreover, in this\npaper, we aim to raise awareness of the benefits of utilizing deep learning\nmodels in the DH community.\n",
                "链接": "https://arxiv.org/abs/2307.16217"
            },
            {
                "文章ID": "112547",
                "标题": "Transformation vs Tradition: Artificial General Intelligence (AGI) for\n  Arts and Humanities",
                "作者": " Zhengliang Liu,  Yiwei Li,  Qian Cao,  Junwen Chen,  Tianze Yang,  Zihao Wu,  John Hale,  John Gibbs,  Khaled Rasheed,  Ninghao Liu,  Gengchen Mai,  Tianming Liu",
                "发布日期": "2023-10-31",
                "摘要": "  Recent advances in artificial general intelligence (AGI), particularly large\nlanguage models and creative image generation systems have demonstrated\nimpressive capabilities on diverse tasks spanning the arts and humanities.\nHowever, the swift evolution of AGI has also raised critical questions about\nits responsible deployment in these culturally significant domains\ntraditionally seen as profoundly human. This paper provides a comprehensive\nanalysis of the applications and implications of AGI for text, graphics, audio,\nand video pertaining to arts and the humanities. We survey cutting-edge systems\nand their usage in areas ranging from poetry to history, marketing to film, and\ncommunication to classical art. We outline substantial concerns pertaining to\nfactuality, toxicity, biases, and public safety in AGI systems, and propose\nmitigation strategies. The paper argues for multi-stakeholder collaboration to\nensure AGI promotes creativity, knowledge, and cultural values without\nundermining truth or human dignity. Our timely contribution summarizes a\nrapidly developing field, highlighting promising directions while advocating\nfor responsible progress centering on human flourishing. The analysis lays the\ngroundwork for further research on aligning AGI's technological capacities with\nenduring social goods.\n",
                "链接": "https://arxiv.org/abs/2310.19626"
            },
            {
                "文章ID": "72600",
                "标题": "SikuGPT: A Generative Pre-trained Model for Intelligent Information\n  Processing of Ancient Texts from the Perspective of Digital Humanities",
                "作者": " Liu Chang,  Wang Dongbo,  Zhao Zhixiao,  Hu Die,  Wu Mengcheng,  Lin Litao,  Shen Si,  Li Bin,  Liu Jiangfeng,  Zhang Hai,  Zhao Lianzheng",
                "发布日期": "2023-04-18",
                "摘要": "  The rapid advance in artificial intelligence technology has facilitated the\nprosperity of digital humanities research. Against such backdrop, research\nmethods need to be transformed in the intelligent processing of ancient texts,\nwhich is a crucial component of digital humanities research, so as to adapt to\nnew development trends in the wave of AIGC. In this study, we propose a GPT\nmodel called SikuGPT based on the corpus of Siku Quanshu. The model's\nperformance in tasks such as intralingual translation and text classification\nexceeds that of other GPT-type models aimed at processing ancient texts.\nSikuGPT's ability to process traditional Chinese ancient texts can help promote\nthe organization of ancient information and knowledge services, as well as the\ninternational dissemination of Chinese ancient culture.\n",
                "链接": "https://arxiv.org/abs/2304.07778"
            },
            {
                "文章ID": "39387",
                "标题": "Hierarchical MixUp Multi-label Classification with Imbalanced\n  Interdisciplinary Research Proposals",
                "作者": " Meng Xiao,  Min Wu,  Ziyue Qiao,  Zhiyuan Ning,  Yi Du,  Yanjie Fu,  Yuanchun Zhou",
                "发布日期": "2023-06-29",
                "摘要": "  Funding agencies are largely relied on a topic matching between domain\nexperts and research proposals to assign proposal reviewers. As proposals are\nincreasingly interdisciplinary, it is challenging to profile the\ninterdisciplinary nature of a proposal, and, thereafter, find expert reviewers\nwith an appropriate set of expertise. An essential step in solving this\nchallenge is to accurately model and classify the interdisciplinary labels of a\nproposal. Existing methodological and application-related literature, such as\ntextual classification and proposal classification, are insufficient in jointly\naddressing the three key unique issues introduced by interdisciplinary proposal\ndata: 1) the hierarchical structure of discipline labels of a proposal from\ncoarse-grain to fine-grain, e.g., from information science to AI to\nfundamentals of AI. 2) the heterogeneous semantics of various main textual\nparts that play different roles in a proposal; 3) the number of proposals is\nimbalanced between non-interdisciplinary and interdisciplinary research. Can we\nsimultaneously address the three issues in understanding the proposal's\ninterdisciplinary nature? In response to this question, we propose a\nhierarchical mixup multiple-label classification framework, which we called\nH-MixUp. H-MixUp leverages a transformer-based semantic information extractor\nand a GCN-based interdisciplinary knowledge extractor for the first and second\nissues. H-MixUp develops a fused training method of Wold-level MixUp,\nWord-level CutMix, Manifold MixUp, and Document-level MixUp to address the\nthird issue.\n",
                "链接": "https://arxiv.org/abs/2209.13912"
            },
            {
                "文章ID": "72431",
                "标题": "Covidia: COVID-19 Interdisciplinary Academic Knowledge Graph",
                "作者": " Cheng Deng,  Jiaxin Ding,  Luoyi Fu,  Weinan Zhang,  Xinbing Wang,  Chenghu Zhou",
                "发布日期": "2023-04-17",
                "摘要": "  The pandemic of COVID-19 has inspired extensive works across different\nresearch fields. Existing literature and knowledge platforms on COVID-19 only\nfocus on collecting papers on biology and medicine, neglecting the\ninterdisciplinary efforts, which hurdles knowledge sharing and research\ncollaborations between fields to address the problem. Studying\ninterdisciplinary researches requires effective paper category classification\nand efficient cross-domain knowledge extraction and integration. In this work,\nwe propose Covidia, COVID-19 interdisciplinary academic knowledge graph to\nbridge the gap between knowledge of COVID-19 on different domains. We design\nframeworks based on contrastive learning for disciplinary classification, and\npropose a new academic knowledge graph scheme for entity extraction, relation\nclassification and ontology management in accordance with interdisciplinary\nresearches. Based on Covidia, we also establish knowledge discovery benchmarks\nfor finding COVID-19 research communities and predicting potential links.\n",
                "链接": "https://arxiv.org/abs/2304.07242"
            },
            {
                "文章ID": "117074",
                "标题": "ATLANTIC: Structure-Aware Retrieval-Augmented Language Model for\n  Interdisciplinary Science",
                "作者": " Sai Munikoti,  Anurag Acharya,  Sridevi Wagle,  Sameera Horawalavithana",
                "发布日期": "2023-11-22",
                "摘要": "  Large language models record impressive performance on many natural language\nprocessing tasks. However, their knowledge capacity is limited to the\npretraining corpus. Retrieval augmentation offers an effective solution by\nretrieving context from external knowledge sources to complement the language\nmodel. However, existing retrieval augmentation techniques ignore the\nstructural relationships between these documents. Furthermore, retrieval models\nare not explored much in scientific tasks, especially in regard to the\nfaithfulness of retrieved documents. In this paper, we propose a novel\nstructure-aware retrieval augmented language model that accommodates document\nstructure during retrieval augmentation. We create a heterogeneous document\ngraph capturing multiple types of relationships (e.g., citation, co-authorship,\netc.) that connect documents from more than 15 scientific disciplines (e.g.,\nPhysics, Medicine, Chemistry, etc.). We train a graph neural network on the\ncurated document graph to act as a structural encoder for the corresponding\npassages retrieved during the model pretraining. Particularly, along with text\nembeddings of the retrieved passages, we obtain structural embeddings of the\ndocuments (passages) and fuse them together before feeding them to the language\nmodel. We evaluate our model extensively on various scientific benchmarks that\ninclude science question-answering and scientific document classification\ntasks. Experimental results demonstrate that structure-aware retrieval improves\nretrieving more coherent, faithful and contextually relevant passages, while\nshowing a comparable performance in the overall accuracy.\n",
                "链接": "https://arxiv.org/abs/2311.12289"
            },
            {
                "文章ID": "114592",
                "标题": "An Interdisciplinary Outlook on Large Language Models for Scientific\n  Research",
                "作者": " James Boyko,  Joseph Cohen,  Nathan Fox,  Maria Han Veiga,  Jennifer I-Hsiu Li,  Jing Liu,  Bernardo Modenesi,  Andreas H. Rauch,  Kenneth N. Reid,  Soumi Tribedi,  Anastasia Visheratina,  Xin Xie",
                "发布日期": "2023-11-10",
                "摘要": "  In this paper, we describe the capabilities and constraints of Large Language\nModels (LLMs) within disparate academic disciplines, aiming to delineate their\nstrengths and limitations with precision. We examine how LLMs augment\nscientific inquiry, offering concrete examples such as accelerating literature\nreview by summarizing vast numbers of publications, enhancing code development\nthrough automated syntax correction, and refining the scientific writing\nprocess. Simultaneously, we articulate the challenges LLMs face, including\ntheir reliance on extensive and sometimes biased datasets, and the potential\nethical dilemmas stemming from their use. Our critical discussion extends to\nthe varying impacts of LLMs across fields, from the natural sciences, where\nthey help model complex biological sequences, to the social sciences, where\nthey can parse large-scale qualitative data. We conclude by offering a nuanced\nperspective on how LLMs can be both a boon and a boundary to scientific\nprogress.\n",
                "链接": "https://arxiv.org/abs/2311.04929"
            },
            {
                "文章ID": "95564",
                "标题": "Evaluating the Generation Capabilities of Large Chinese Language Models",
                "作者": " Hui Zeng,  Jingyuan Xue,  Meng Hao,  Chen Sun,  Bin Ning,  Na Zhang",
                "发布日期": "2023-11-21",
                "摘要": "  This paper presents CG-Eval, the first comprehensive evaluation of the\ngeneration capabilities of large Chinese language models across a wide range of\nacademic disciplines. The models' performance was assessed based on their\nability to generate accurate and relevant responses to different types of\nquestions in six disciplines, namely, Science and Engineering, Humanities and\nSocial Sciences, Mathematical Calculations, Medical Practitioner Qualification\nExamination, Judicial Examination, and Certified Public Accountant Examination.\nThis paper also presents Gscore, a composite index derived from the weighted\nsum of multiple metrics to measure the quality of model's generation against a\nreference. The test data and test results can be found at\nhttp://cgeval.besteasy.com/.\n",
                "链接": "https://arxiv.org/abs/2308.04823"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和脑科学交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "112056",
                "标题": "Large-scale Foundation Models and Generative AI for BigData Neuroscience",
                "作者": " Ran Wang,  Zhe Sage Chen",
                "发布日期": "2023-10-31",
                "摘要": "  Recent advances in machine learning have made revolutionary breakthroughs in\ncomputer games, image and natural language understanding, and scientific\ndiscovery. Foundation models and large-scale language models (LLMs) have\nrecently achieved human-like intelligence thanks to BigData. With the help of\nself-supervised learning (SSL) and transfer learning, these models may\npotentially reshape the landscapes of neuroscience research and make a\nsignificant impact on the future. Here we present a mini-review on recent\nadvances in foundation models and generative AI models as well as their\napplications in neuroscience, including natural language and speech, semantic\nmemory, brain-machine interfaces (BMIs), and data augmentation. We argue that\nthis paradigm-shift framework will open new avenues for many neuroscience\nresearch directions and discuss the accompanying challenges and opportunities.\n",
                "链接": "https://arxiv.org/abs/2310.18377"
            },
            {
                "文章ID": "105384",
                "标题": "In-Context Learning in Large Language Models: A Neuroscience-inspired\n  Analysis of Representations",
                "作者": " Safoora Yousefi,  Leo Betthauser,  Hosein Hasanbeig,  Akanksha Saran,  Raphaël Millière,  Ida Momennejad",
                "发布日期": "2023-10-19",
                "摘要": "  Large language models (LLMs) exhibit remarkable performance improvement\nthrough in-context learning (ICL) by leveraging task-specific examples in the\ninput. However, the mechanisms behind this improvement remain elusive. In this\nwork, we investigate embeddings and attention representations in Llama-2 70B\nand Vicuna 13B. Specifically, we study how embeddings and attention change\nafter in-context-learning, and how these changes mediate improvement in\nbehavior. We employ neuroscience-inspired techniques, such as representational\nsimilarity analysis (RSA), and propose novel methods for parameterized probing\nand attention ratio analysis (ARA, measuring the ratio of attention to relevant\nvs. irrelevant information). We designed three tasks with a priori\nrelationships among their conditions: reading comprehension, linear regression,\nand adversarial prompt injection. We formed hypotheses about expected\nsimilarities in task representations to investigate latent changes in\nembeddings and attention. Our analyses revealed a meaningful correlation\nbetween changes in both embeddings and attention representations with\nimprovements in behavioral performance after ICL. This empirical framework\nempowers a nuanced understanding of how latent representations affect LLM\nbehavior with and without ICL, offering valuable tools and insights for future\nresearch and practical applications.\n",
                "链接": "https://arxiv.org/abs/2310.00313"
            },
            {
                "文章ID": "106494",
                "标题": "Benchmarking Large Language Models As AI Research Agents",
                "作者": " Qian Huang,  Jian Vora,  Percy Liang,  Jure Leskovec",
                "发布日期": "2023-10-06",
                "摘要": "  Scientific experimentation involves an iterative process of creating\nhypotheses, designing experiments, running experiments, and analyzing the\nresults. Can we build AI research agents to perform these long-horizon tasks?\nTo take a step towards building and evaluating research agents on such\nopen-ended decision-making tasks, we focus on the problem of machine learning\nengineering: given a task description and a dataset, build a high-performing\nmodel. In this paper, we propose MLAgentBench, a suite of ML tasks for\nbenchmarking AI research agents. Agents can perform actions like\nreading/writing files, executing code, and inspecting outputs. With these\nactions, agents could run experiments, analyze the results, and modify the code\nof entire machine learning pipelines, such as data processing, architecture,\ntraining processes, etc. The benchmark then automatically evaluates the agent's\nperformance objectively over various metrics related to performance and\nefficiency. We also design an LLM-based research agent to automatically perform\nexperimentation loops in such an environment. Empirically, we find that a\nGPT-4-based research agent can feasibly build compelling ML models over many\ntasks in MLAgentBench, displaying highly interpretable plans and actions.\nHowever, the success rates vary considerably; they span from almost 90\\% on\nwell-established older datasets to as low as 10\\% on recent Kaggle Challenges\n-- unavailable during the LLM model's pretraining -- and even 0\\% on newer\nresearch challenges like BabyLM. Finally, we identify several key challenges\nfor LLM-based research agents such as long-term planning and hallucination. Our\ncode is released at https://github.com/snap-stanford/MLAgentBench.\n",
                "链接": "https://arxiv.org/abs/2310.03302"
            },
            {
                "文章ID": "71835",
                "标题": "Emergent autonomous scientific research capabilities of large language\n  models",
                "作者": " Daniil A. Boiko,  Robert MacKnight,  Gabe Gomes",
                "发布日期": "2023-04-12",
                "摘要": "  Transformer-based large language models are rapidly advancing in the field of\nmachine learning research, with applications spanning natural language,\nbiology, chemistry, and computer programming. Extreme scaling and reinforcement\nlearning from human feedback have significantly improved the quality of\ngenerated text, enabling these models to perform various tasks and reason about\ntheir choices. In this paper, we present an Intelligent Agent system that\ncombines multiple large language models for autonomous design, planning, and\nexecution of scientific experiments. We showcase the Agent's scientific\nresearch capabilities with three distinct examples, with the most complex being\nthe successful performance of catalyzed cross-coupling reactions. Finally, we\ndiscuss the safety implications of such systems and propose measures to prevent\ntheir misuse.\n",
                "链接": "https://arxiv.org/abs/2304.05332"
            },
            {
                "文章ID": "101124",
                "标题": "Toward Reproducing Network Research Results Using Large Language Models",
                "作者": " Qiao Xiang,  Yuling Lin,  Mingjun Fang,  Bang Huang,  Siyong Huang,  Ridi Wen,  Franck Le,  Linghe Kong,  Jiwu Shu",
                "发布日期": "2023-09-12",
                "摘要": "  Reproducing research results in the networking community is important for\nboth academia and industry. The current best practice typically resorts to\nthree approaches: (1) looking for publicly available prototypes; (2) contacting\nthe authors to get a private prototype; and (3) manually implementing a\nprototype following the description of the publication. However, most published\nnetwork research does not have public prototypes and private prototypes are\nhard to get. As such, most reproducing efforts are spent on manual\nimplementation based on the publications, which is both time and labor\nconsuming and error-prone. In this paper, we boldly propose reproducing network\nresearch results using the emerging large language models (LLMs). In\nparticular, we first prove its feasibility with a small-scale experiment, in\nwhich four students with essential networking knowledge each reproduces a\ndifferent networking system published in prominent conferences and journals by\nprompt engineering ChatGPT. We report the experiment's observations and lessons\nand discuss future open research questions of this proposal. This work raises\nno ethical issue.\n",
                "链接": "https://arxiv.org/abs/2309.04716"
            },
            {
                "文章ID": "66370",
                "标题": "Algorithmic Ghost in the Research Shell: Large Language Models and\n  Academic Knowledge Creation in Management Research",
                "作者": " Nigel Williams,  Stanislav Ivanov,  Dimitrios Buhalis",
                "发布日期": "2023-03-14",
                "摘要": "  The paper looks at the role of large language models in academic knowledge\ncreation based on a scoping review (2018 to January 2023) of how researchers\nhave previously used the language model GPT to assist in the performance of\nacademic knowledge creation tasks beyond data analysis. These tasks include\nwriting, editing, reviewing, dataset creation and curation, which have been\ndifficult to perform using earlier ML tools. Based on a synthesis of these\npapers, this study identifies pathways for a future academic research landscape\nthat incorporates wider usage of large language models based on the current\nmodes of adoption in published articles as a Co-Writer, Research Assistant and\nRespondent.\n",
                "链接": "https://arxiv.org/abs/2303.07304"
            },
            {
                "文章ID": "81668",
                "标题": "The Utility of Large Language Models and Generative AI for Education\n  Research",
                "作者": " Andrew Katz,  Umair Shakir,  Ben Chambers",
                "发布日期": "2023-05-30",
                "摘要": "  The use of natural language processing (NLP) techniques in engineering\neducation can provide valuable insights into the underlying processes involved\nin generating text. While accessing these insights can be labor-intensive if\ndone manually, recent advances in NLP and large language models have made it a\nrealistic option for individuals. This study explores and evaluates a\ncombination of clustering, summarization, and prompting techniques to analyze\nover 1,000 student essays in which students discussed their career interests.\nThe specific assignment prompted students to define and explain their career\ngoals as engineers. Using text embedding representations of student responses,\nwe clustered the responses together to identify thematically similar statements\nfrom students. The clustered responses were then summarized to quickly identify\ncareer interest themes. We also used a set of a priori codes about career\nsatisfaction and sectors to demonstrate an alternative approach to using these\ngenerative text models to analyze student writing. The results of this study\ndemonstrate the feasibility and usefulness of NLP techniques in engineering\neducation research. By automating the initial analysis of student essays,\nresearchers and educators can more efficiently and accurately identify key\nthemes and patterns in student writing. The methods presented in this paper\nhave broader applications for engineering education and research purposes\nbeyond analyzing student essays. By explaining these methods to the engineering\neducation community, readers can utilize them in their own contexts.\n",
                "链接": "https://arxiv.org/abs/2305.18125"
            },
            {
                "文章ID": "114592",
                "标题": "An Interdisciplinary Outlook on Large Language Models for Scientific\n  Research",
                "作者": " James Boyko,  Joseph Cohen,  Nathan Fox,  Maria Han Veiga,  Jennifer I-Hsiu Li,  Jing Liu,  Bernardo Modenesi,  Andreas H. Rauch,  Kenneth N. Reid,  Soumi Tribedi,  Anastasia Visheratina,  Xin Xie",
                "发布日期": "2023-11-10",
                "摘要": "  In this paper, we describe the capabilities and constraints of Large Language\nModels (LLMs) within disparate academic disciplines, aiming to delineate their\nstrengths and limitations with precision. We examine how LLMs augment\nscientific inquiry, offering concrete examples such as accelerating literature\nreview by summarizing vast numbers of publications, enhancing code development\nthrough automated syntax correction, and refining the scientific writing\nprocess. Simultaneously, we articulate the challenges LLMs face, including\ntheir reliance on extensive and sometimes biased datasets, and the potential\nethical dilemmas stemming from their use. Our critical discussion extends to\nthe varying impacts of LLMs across fields, from the natural sciences, where\nthey help model complex biological sequences, to the social sciences, where\nthey can parse large-scale qualitative data. We conclude by offering a nuanced\nperspective on how LLMs can be both a boon and a boundary to scientific\nprogress.\n",
                "链接": "https://arxiv.org/abs/2311.04929"
            },
            {
                "文章ID": "70693",
                "标题": "Summary of ChatGPT-Related Research and Perspective Towards the Future\n  of Large Language Models",
                "作者": " Yiheng Liu,  Tianle Han,  Siyuan Ma,  Jiayue Zhang,  Yuanyuan Yang,  Jiaming Tian,  Hao He,  Antong Li,  Mengshen He,  Zhengliang Liu,  Zihao Wu,  Lin Zhao,  Dajiang Zhu,  Xiang Li,  Ning Qiang,  Dingang Shen,  Tianming Liu,  Bao Ge",
                "发布日期": "2023-08-25",
                "摘要": "  This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and\nGPT-4) research, state-of-the-art large language models (LLM) from the GPT\nseries, and their prospective applications across diverse domains. Indeed, key\ninnovations such as large-scale pre-training that captures knowledge across the\nentire world wide web, instruction fine-tuning and Reinforcement Learning from\nHuman Feedback (RLHF) have played significant roles in enhancing LLMs'\nadaptability and performance. We performed an in-depth analysis of 194 relevant\npapers on arXiv, encompassing trend analysis, word cloud representation, and\ndistribution analysis across various application domains. The findings reveal a\nsignificant and increasing interest in ChatGPT-related research, predominantly\ncentered on direct natural language processing applications, while also\ndemonstrating considerable potential in areas ranging from education and\nhistory to mathematics, medicine, and physics. This study endeavors to furnish\ninsights into ChatGPT's capabilities, potential implications, ethical concerns,\nand offer direction for future advancements in this field.\n",
                "链接": "https://arxiv.org/abs/2304.01852"
            },
            {
                "文章ID": "87578",
                "标题": "Potential Benefits of Employing Large Language Models in Research in\n  Moral Education and Development",
                "作者": " Hyemin Han",
                "发布日期": "2023-08-22",
                "摘要": "  Recently, computer scientists have developed large language models (LLMs) by\ntraining prediction models with large-scale language corpora and human\nreinforcements. The LLMs have become one promising way to implement artificial\nintelligence with accuracy in various fields. Interestingly, recent LLMs\npossess emergent functional features that emulate sophisticated human\ncognition, especially in-context learning and the chain of thought, which were\nunavailable in previous prediction models. In this paper, I will examine how\nLLMs might contribute to moral education and development research. To achieve\nthis goal, I will review the most recently published conference papers and\nArXiv preprints to overview the novel functional features implemented in LLMs.\nI also intend to conduct brief experiments with ChatGPT to investigate how LLMs\nbehave while addressing ethical dilemmas and external feedback. The results\nsuggest that LLMs might be capable of solving dilemmas based on reasoning and\nrevising their reasoning process with external input. Furthermore, a\npreliminary experimental result from the moral exemplar test may demonstrate\nthat exemplary stories can elicit moral elevation in LLMs as do they among\nhuman participants. I will discuss the potential implications of LLMs on\nresearch on moral education and development with the results.\n",
                "链接": "https://arxiv.org/abs/2306.13805"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下2023年关于LLM-based Agent的综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "106067",
                "标题": "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with\n  Agent Team Optimization",
                "作者": " Zijun Liu,  Yanzhe Zhang,  Peng Li,  Yang Liu,  Diyi Yang",
                "发布日期": "2023-10-04",
                "摘要": "  Large language model (LLM) agents have been shown effective on a wide range\nof tasks, and by ensembling multiple LLM agents, their performances could be\nfurther improved. Existing approaches employ a fixed set of agents to interact\nwith each other in a static architecture, which limits their generalizability\nto various tasks and requires strong human prior in designing these agents. In\nthis work, we propose to construct a strategic team of agents communicating in\na dynamic interaction architecture based on the task query. Specifically, we\nbuild a framework named Dynamic LLM-Agent Network ($\\textbf{DyLAN}$) for\nLLM-agent collaboration on complicated tasks like reasoning and code\ngeneration. DyLAN enables agents to interact for multiple rounds in a dynamic\narchitecture with inference-time agent selection and an early-stopping\nmechanism to improve performance and efficiency. We further design an automatic\nagent team optimization algorithm based on an unsupervised metric termed\n$\\textit{Agent Importance Score}$, enabling the selection of best agents based\non the contribution each agent makes. Empirically, we demonstrate that DyLAN\nperforms well in both reasoning and code generation tasks with reasonable\ncomputational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and\nHumanEval, respectively, compared to a single execution on GPT-35-turbo. On\nspecific subjects of MMLU, agent team optimization in DyLAN increases accuracy\nby up to 25.0%.\n",
                "链接": "https://arxiv.org/abs/2310.02170"
            },
            {
                "文章ID": "110807",
                "标题": "LLM-Based Agent Society Investigation: Collaboration and Confrontation\n  in Avalon Gameplay",
                "作者": " Yihuai Lan,  Zhiqiang Hu,  Lei Wang,  Yang Wang,  Deheng Ye,  Peilin Zhao,  Ee-Peng Lim,  Hui Xiong,  Hao Wang",
                "发布日期": "2023-10-24",
                "摘要": "  This paper aims to investigate the open research problem of uncovering the\nsocial behaviors of LLM-based agents. To achieve this goal, we adopt Avalon, a\nrepresentative communication game, as the environment and use system prompts to\nguide LLM agents to play the game. While previous studies have conducted\npreliminary investigations into gameplay with LLM agents, there lacks research\non their social behaviors. In this paper, we present a novel framework designed\nto seamlessly adapt to Avalon gameplay. The core of our proposed framework is a\nmulti-agent system that enables efficient communication and interaction among\nagents. We evaluate the performance of our framework based on metrics from two\nperspectives: winning the game and analyzing the social behaviors of LLM\nagents. Our results demonstrate the effectiveness of our framework in\ngenerating adaptive and intelligent agents and highlight the potential of\nLLM-based agents in addressing the challenges associated with dynamic social\nenvironment interaction. By analyzing the social behaviors of LLM agents from\nthe aspects of both collaboration and confrontation, we provide insights into\nthe research and applications of this domain.\n",
                "链接": "https://arxiv.org/abs/2310.14985"
            },
            {
                "文章ID": "120758",
                "标题": "LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent\n  Ecosystem",
                "作者": " Yingqiang Ge,  Yujie Ren,  Wenyue Hua,  Shuyuan Xu,  Juntao Tan,  Yongfeng Zhang",
                "发布日期": "2023-12-12",
                "摘要": "  This paper envisions a revolutionary AIOS-Agent ecosystem, where Large\nLanguage Model (LLM) serves as the (Artificial) Intelligent Operating System\n(IOS, or AIOS)--an operating system \"with soul\". Upon this foundation, a\ndiverse range of LLM-based AI Agent Applications (Agents, or AAPs) are\ndeveloped, enriching the AIOS-Agent ecosystem and signaling a paradigm shift\nfrom the traditional OS-APP ecosystem. We envision that LLM's impact will not\nbe limited to the AI application level, instead, it will in turn revolutionize\nthe design and implementation of computer system, architecture, software, and\nprogramming language, featured by several main concepts: LLM as OS\n(system-level), Agents as Applications (application-level), Natural Language as\nProgramming Interface (user-level), and Tools as Devices/Libraries\n(hardware/middleware-level). We begin by introducing the architecture of\ntraditional OS. Then we formalize a conceptual framework for AIOS through \"LLM\nas OS (LLMOS)\", drawing analogies between AIOS and traditional OS: LLM is\nlikened to OS kernel, context window to memory, external storage to file\nsystem, hardware tools to peripheral devices, software tools to programming\nlibraries, and user prompts to user commands. Subsequently, we introduce the\nnew AIOS-Agent Ecosystem, where users can easily program Agent Applications\n(AAPs) using natural language, democratizing the development of software, which\nis different from the traditional OS-APP ecosystem. Following this, we explore\nthe diverse scope of Agent Applications. We delve into both single-agent and\nmulti-agent systems, as well as human-agent interaction. Lastly, drawing on the\ninsights from traditional OS-APP ecosystem, we propose a roadmap for the\nevolution of the AIOS-Agent ecosystem. This roadmap is designed to guide the\nfuture research and development, suggesting systematic progresses of AIOS and\nits Agent applications.\n",
                "链接": "https://arxiv.org/abs/2312.03815"
            },
            {
                "文章ID": "118628",
                "标题": "Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld",
                "作者": " Yijun Yang,  Tianyi Zhou,  Kanxue Li,  Dapeng Tao,  Lusong Li,  Li Shen,  Xiaodong He,  Jing Jiang,  Yuhui Shi",
                "发布日期": "2023-11-29",
                "摘要": "  While large language models (LLMs) excel in a simulated world of texts, they\nstruggle to interact with the more realistic world without perceptions of other\nmodalities such as visual or audio signals. Although vision-language models\n(VLMs) integrate LLM modules (1) aligned with static image features, and (2)\nmay possess prior knowledge of world dynamics (as demonstrated in the text\nworld), they have not been trained in an embodied visual world and thus cannot\nalign with its dynamics. On the other hand, training an embodied agent in a\nnoisy visual world without expert guidance is often challenging and\ninefficient. In this paper, we train a VLM agent living in a visual world using\nan LLM agent excelling in a parallel text world (but inapplicable to the visual\nworld). Specifically, we distill LLM's reflection outcomes (improved actions by\nanalyzing mistakes) in a text world's tasks to finetune the VLM on the same\ntasks of the visual world, resulting in an Embodied Multi-Modal Agent (EMMA)\nquickly adapting to the visual world dynamics. Such cross-modality imitation\nlearning between the two parallel worlds enables EMMA to generalize to a broad\nscope of new tasks without any further guidance from the LLM expert. Extensive\nevaluations on the ALFWorld benchmark highlight EMMA's superior performance to\nSOTA VLM-based agents across diverse tasks, e.g., 20%-70% improvement in the\nsuccess rate.\n",
                "链接": "https://arxiv.org/abs/2311.16714"
            },
            {
                "文章ID": "102166",
                "标题": "LASER: LLM Agent with State-Space Exploration for Web Navigation",
                "作者": " Kaixin Ma,  Hongming Zhang,  Hongwei Wang,  Xiaoman Pan,  Dong Yu",
                "发布日期": "2023-09-18",
                "摘要": "  Large language models (LLMs) have been successfully adapted for interactive\ndecision-making tasks like web navigation. While achieving decent performance,\nprevious methods implicitly assume a forward-only execution mode for the model,\nwhere they only provide oracle trajectories as in-context examples to teach the\nmodel how to reason in the interactive environment. Consequently, the model\ncould not handle more challenging scenarios not covered in the in-context\nexamples, e.g., mistakes, leading to sub-optimal performance. To address this\nissue, we propose to model the interactive task as state space exploration,\nwhere the LLM agent transitions among a pre-defined set of states by performing\nactions to complete the task. This formulation enables flexible back-tracking,\nallowing the model to easily recover from errors. We evaluate our proposed LLM\nAgent with State-Space ExploRation (LASER) on the WebShop task. Experimental\nresults show that our LASER agent significantly outperforms previous methods\nand closes the gap with human performance on the web navigation task.\n",
                "链接": "https://arxiv.org/abs/2309.08172"
            },
            {
                "文章ID": "117600",
                "标题": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and\n  Character Design",
                "作者": " Yangyang Yu,  Haohang Li,  Zhi Chen,  Yuechen Jiang,  Yang Li,  Denghui Zhang,  Rong Liu,  Jordan W. Suchow,  Khaldoun Khashanah",
                "发布日期": "2023-12-05",
                "摘要": "  Recent advancements in Large Language Models (LLMs) have exhibited notable\nefficacy in question-answering (QA) tasks across diverse domains. Their prowess\nin integrating extensive web knowledge has fueled interest in developing\nLLM-based autonomous agents. While LLMs are efficient in decoding human\ninstructions and deriving solutions by holistically processing historical\ninputs, transitioning to purpose-driven agents requires a supplementary\nrational architecture to process multi-source information, establish reasoning\nchains, and prioritize critical tasks. Addressing this, we introduce\n\\textsc{FinMem}, a novel LLM-based agent framework devised for financial\ndecision-making. It encompasses three core modules: Profiling, to customize the\nagent's characteristics; Memory, with layered message processing, to aid the\nagent in assimilating hierarchical financial data; and Decision-making, to\nconvert insights gained from memories into investment decisions. Notably,\n\\textsc{FinMem}'s memory module aligns closely with the cognitive structure of\nhuman traders, offering robust interpretability and real-time tuning. Its\nadjustable cognitive span allows for the retention of critical information\nbeyond human perceptual limits, thereby enhancing trading outcomes. This\nframework enables the agent to self-evolve its professional knowledge, react\nagilely to new investment cues, and continuously refine trading decisions in\nthe volatile financial environment. We first compare \\textsc{FinMem} with\nvarious algorithmic agents on a scalable real-world financial dataset,\nunderscoring its leading trading performance in stocks. We then fine-tuned the\nagent's perceptual span and character setting to achieve a significantly\nenhanced trading performance. Collectively, \\textsc{FinMem} presents a\ncutting-edge LLM agent framework for automated trading, boosting cumulative\ninvestment returns.\n",
                "链接": "https://arxiv.org/abs/2311.13743"
            },
            {
                "文章ID": "108435",
                "标题": "Formally Specifying the High-Level Behavior of LLM-Based Agents",
                "作者": " Maxwell Crouse,  Ibrahim Abdelaziz,  Kinjal Basu,  Soham Dan,  Sadhana Kumaravel,  Achille Fokoue,  Pavan Kapanipathi,  Luis Lastras",
                "发布日期": "2023-10-13",
                "摘要": "  LLM-based agents have recently emerged as promising tools for solving\nchallenging problems without the need for task-specific finetuned models that\ncan be expensive to procure. Currently, the design and implementation of such\nagents is ad hoc, as the wide variety of tasks that LLM-based agents may be\napplied to naturally means there can be no one-size-fits-all approach to agent\ndesign. In this work we aim to alleviate the difficulty of designing and\nimplementing new agents by proposing a minimalistic, high-level generation\nframework that simplifies the process of building agents. The framework we\nintroduce allows the user to specify desired agent behaviors in Linear Temporal\nLogic (LTL). The declarative LTL specification is then used to construct a\nconstrained decoder that guarantees the LLM will produce an output exhibiting\nthe desired behavior. By designing our framework in this way, we obtain several\nbenefits, including the ability to enforce complex agent behavior, the ability\nto formally validate prompt examples, and the ability to seamlessly incorporate\ncontent-focused logical constraints into generation. In particular, our\ndeclarative approach, in which the desired behavior is simply described without\nconcern for how it should be implemented or enforced, enables rapid design,\nimplementation and experimentation with different LLM-based agents. We\ndemonstrate how the proposed framework can be used to implement recent\nLLM-based agents, and show how the guardrails our approach provides can lead to\nimprovements in agent performance. In addition, we release our code for general\nuse.\n",
                "链接": "https://arxiv.org/abs/2310.08535"
            },
            {
                "文章ID": "83996",
                "标题": "Enabling Intelligent Interactions between an Agent and an LLM: A\n  Reinforcement Learning Approach",
                "作者": " Bin Hu,  Chenyang Zhao,  Pu Zhang,  Zihao Zhou,  Yuanhang Yang,  Zenglin Xu,  Bin Liu",
                "发布日期": "2023-09-01",
                "摘要": "  Large language models (LLMs) encode a vast amount of world knowledge acquired\nfrom massive text datasets. Recent studies have demonstrated that LLMs can\nassist an embodied agent in solving complex sequential decision making tasks by\nproviding high-level instructions. However, interactions with LLMs can be\ntime-consuming. In many practical scenarios, they require a significant amount\nof storage space that can only be deployed on remote cloud server nodes.\nAdditionally, using commercial LLMs can be costly since they may charge based\non usage frequency. In this paper, we explore how to enable intelligent\ncost-effective interactions between the agent and an LLM. We propose When2Ask,\na reinforcement learning based approach that learns when it is necessary to\nquery LLMs for high-level instructions to accomplish a target task. Experiments\non MiniGrid and Habitat environments that entail planning sub-goals demonstrate\nthat When2Ask learns to solve target tasks with only a few necessary\ninteractions with an LLM, and significantly reduces interaction costs in\ntesting environments compared with baseline methods. Experiment results also\nsuggest that by learning a mediator model to interact with the LLM, the agent's\nperformance becomes more robust against partial observability of the\nenvironment. Our code is available at https://github.com/ZJLAB-AMMI/LLM4RL.\n",
                "链接": "https://arxiv.org/abs/2306.03604"
            },
            {
                "文章ID": "122965",
                "标题": "ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent",
                "作者": " Renat Aksitov,  Sobhan Miryoosefi,  Zonglin Li,  Daliang Li,  Sheila Babayan,  Kavya Kopparapu,  Zachary Fisher,  Ruiqi Guo,  Sushant Prakash,  Pranesh Srinivasan,  Manzil Zaheer,  Felix Yu,  Sanjiv Kumar",
                "发布日期": "2023-12-18",
                "摘要": "  Answering complex natural language questions often necessitates multi-step\nreasoning and integrating external information. Several systems have combined\nknowledge retrieval with a large language model (LLM) to answer such questions.\nThese systems, however, suffer from various failure cases, and we cannot\ndirectly train them end-to-end to fix such failures, as interaction with\nexternal knowledge is non-differentiable. To address these deficiencies, we\ndefine a ReAct-style LLM agent with the ability to reason and act upon external\nknowledge. We further refine the agent through a ReST-like method that\niteratively trains on previous trajectories, employing growing-batch\nreinforcement learning with AI feedback for continuous self-improvement and\nself-distillation. Starting from a prompted large model and after just two\niterations of the algorithm, we can produce a fine-tuned small model that\nachieves comparable performance on challenging compositional question-answering\nbenchmarks with two orders of magnitude fewer parameters.\n",
                "链接": "https://arxiv.org/abs/2312.10003"
            },
            {
                "文章ID": "106611",
                "标题": "Balancing Autonomy and Alignment: A Multi-Dimensional Taxonomy for\n  Autonomous LLM-powered Multi-Agent Architectures",
                "作者": " Thorsten Händler",
                "发布日期": "2023-10-06",
                "摘要": "  Large language models (LLMs) have revolutionized the field of artificial\nintelligence, endowing it with sophisticated language understanding and\ngeneration capabilities. However, when faced with more complex and\ninterconnected tasks that demand a profound and iterative thought process, LLMs\nreveal their inherent limitations. Autonomous LLM-powered multi-agent systems\nrepresent a strategic response to these challenges. Such systems strive for\nautonomously tackling user-prompted goals by decomposing them into manageable\ntasks and orchestrating their execution and result synthesis through a\ncollective of specialized intelligent agents. Equipped with LLM-powered\nreasoning capabilities, these agents harness the cognitive synergy of\ncollaborating with their peers, enhanced by leveraging contextual resources\nsuch as tools and datasets. While these architectures hold promising potential\nin amplifying AI capabilities, striking the right balance between different\nlevels of autonomy and alignment remains the crucial challenge for their\neffective operation. This paper proposes a comprehensive multi-dimensional\ntaxonomy, engineered to analyze how autonomous LLM-powered multi-agent systems\nbalance the dynamic interplay between autonomy and alignment across various\naspects inherent to architectural viewpoints such as goal-driven task\nmanagement, agent composition, multi-agent collaboration, and context\ninteraction. It also includes a domain-ontology model specifying fundamental\narchitectural concepts. Our taxonomy aims to empower researchers, engineers,\nand AI practitioners to systematically analyze the architectural dynamics and\nbalancing strategies employed by these increasingly prevalent AI systems. The\nexploratory taxonomic classification of selected representative LLM-powered\nmulti-agent systems illustrates its practical utility and reveals potential for\nfuture research and development.\n",
                "链接": "https://arxiv.org/abs/2310.03659"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "115879",
                "标题": "Speculative Contrastive Decoding",
                "作者": " Hongyi Yuan,  Keming Lu,  Fei Huang,  Zheng Yuan,  Chang Zhou",
                "发布日期": "2023-11-16",
                "摘要": "  Large language models (LLMs) have shown extraordinary performance in various\nlanguage tasks, but high computational requirements hinder their widespread\ndeployment. Speculative decoding, which uses amateur models to predict the\ngeneration of expert models, has been proposed as a way to accelerate LLM\ninference. However, speculative decoding focuses on acceleration instead of\nmaking the best use of the token distribution from amateur models. We proposed\nSpeculative Contrastive Decoding (SCD), an accelerated decoding method\nleveraging the natural contrast between expert and amateur models in\nspeculative decoding. Comprehensive evaluations on four benchmarks show that\nSCD can achieve similar acceleration factors as speculative decoding while\nfurther improving the generation quality as the contrastive decoding. The\nanalysis of token probabilities further demonstrates the compatibility between\nspeculative and contrastive decoding. Overall, SCD provides an effective\napproach to enhance the decoding quality of LLMs while saving computational\nresources.\n",
                "链接": "https://arxiv.org/abs/2311.08981"
            },
            {
                "文章ID": "90598",
                "标题": "Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM\n  Decoding",
                "作者": " Seongjun Yang,  Gibbeum Lee,  Jaewoong Cho,  Dimitris Papailiopoulos,  Kangwook Lee",
                "发布日期": "2023-07-13",
                "摘要": "  This paper presents \"Predictive Pipelined Decoding (PPD),\" an approach that\nspeeds up greedy decoding in Large Language Models (LLMs) while maintaining the\nexact same output as the original decoding. Unlike conventional strategies, PPD\nemploys additional compute resources to parallelize the initiation of\nsubsequent token decoding during the current token decoding. This innovative\nmethod reduces decoding latency and reshapes the understanding of trade-offs in\nLLM decoding strategies. We have developed a theoretical framework that allows\nus to analyze the trade-off between computation and latency. Using this\nframework, we can analytically estimate the potential reduction in latency\nassociated with our proposed method, achieved through the assessment of the\nmatch rate, represented as p_correct. The results demonstrate that the use of\nextra computational resources has the potential to accelerate LLM greedy\ndecoding.\n",
                "链接": "https://arxiv.org/abs/2307.05908"
            },
            {
                "文章ID": "17492",
                "标题": "Quality-Aware Decoding for Neural Machine Translation",
                "作者": " Patrick Fernandes,  António Farinhas,  Ricardo Rei,  José G. C. de Souza,  Perez Ogayo,  Graham Neubig,  André F. T. Martins",
                "发布日期": "2022-05-03",
                "摘要": "  Despite the progress in machine translation quality estimation and evaluation\nin the last years, decoding in neural machine translation (NMT) is mostly\noblivious to this and centers around finding the most probable translation\naccording to the model (MAP decoding), approximated with beam search. In this\npaper, we bring together these two lines of research and propose quality-aware\ndecoding for NMT, by leveraging recent breakthroughs in reference-free and\nreference-based MT evaluation through various inference methods like $N$-best\nreranking and minimum Bayes risk decoding. We perform an extensive comparison\nof various possible candidate generation and ranking methods across four\ndatasets and two model classes and find that quality-aware decoding\nconsistently outperforms MAP-based decoding according both to state-of-the-art\nautomatic metrics (COMET and BLEURT) and to human assessments. Our code is\navailable at https://github.com/deep-spin/qaware-decode.\n",
                "链接": "https://arxiv.org/abs/2205.00978"
            },
            {
                "文章ID": "42520",
                "标题": "Language Model Decoding as Likelihood-Utility Alignment",
                "作者": " Martin Josifoski,  Maxime Peyrard,  Frano Rajic,  Jiheng Wei,  Debjit Paul,  Valentin Hartmann,  Barun Patra,  Vishrav Chaudhary,  Emre Kıcıman,  Boi Faltings,  Robert West",
                "发布日期": "2023-03-17",
                "摘要": "  A critical component of a successful language generation pipeline is the\ndecoding algorithm. However, the general principles that should guide the\nchoice of a decoding algorithm remain unclear. Previous works only compare\ndecoding algorithms in narrow scenarios, and their findings do not generalize\nacross tasks. We argue that the misalignment between the model's likelihood and\nthe task-specific notion of utility is the key factor to understanding the\neffectiveness of decoding algorithms. To structure the discussion, we introduce\na taxonomy of misalignment mitigation strategies (MMSs), providing a unifying\nview of decoding as a tool for alignment. The MMS taxonomy groups decoding\nalgorithms based on their implicit assumptions about likelihood--utility\nmisalignment, yielding general statements about their applicability across\ntasks. Specifically, by analyzing the correlation between the likelihood and\nthe utility of predictions across a diverse set of tasks, we provide empirical\nevidence supporting the proposed taxonomy and a set of principles to structure\nreasoning when choosing a decoding algorithm. Crucially, our analysis is the\nfirst to relate likelihood-based decoding algorithms with algorithms that rely\non external information, such as value-guided methods and prompting, and covers\nthe most diverse set of tasks to date. Code, data, and models are available at\nhttps://github.com/epfl-dlab/understanding-decoding.\n",
                "链接": "https://arxiv.org/abs/2210.07228"
            },
            {
                "文章ID": "12396",
                "标题": "On Decoding Strategies for Neural Text Generators",
                "作者": " Gian Wiher,  Clara Meister,  Ryan Cotterell",
                "发布日期": "2022-03-30",
                "摘要": "  When generating text from probabilistic models, the chosen decoding strategy\nhas a profound effect on the resulting text. Yet the properties elicited by\nvarious decoding strategies do not always transfer across natural language\ngeneration tasks. For example, while mode-seeking methods like beam search\nperform remarkably well for machine translation, they have been observed to\nlead to incoherent and repetitive text in story generation. Despite such\nobservations, the effectiveness of decoding strategies is often assessed with\nrespect to only a single task. This work -- in contrast -- provides a\ncomprehensive analysis of the interaction between language generation tasks and\ndecoding strategies. Specifically, we measure changes in attributes of\ngenerated text as a function of both decoding strategy and task using human and\nautomatic evaluation. Our results reveal both previously-observed and\nsurprising findings. For example, the nature of the diversity-quality trade-off\nin language generation is very task-specific; the length bias often attributed\nto beam search is not constant across tasks.\n",
                "链接": "https://arxiv.org/abs/2203.15721"
            },
            {
                "文章ID": "91982",
                "标题": "Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding\n  (Survey)",
                "作者": " Subba Reddy Oota,  Manish Gupta,  Raju S. Bapi,  Gael Jobard,  Frederic Alexandre,  Xavier Hinaut",
                "发布日期": "2023-07-21",
                "摘要": "  How does the brain represent different modes of information? Can we design a\nsystem that automatically understands what the user is thinking? Such questions\ncan be answered by studying brain recordings like functional magnetic resonance\nimaging (fMRI). As a first step, the neuroscience community has contributed\nseveral large cognitive neuroscience datasets related to passive\nreading/listening/viewing of concept words, narratives, pictures and movies.\nEncoding and decoding models using these datasets have also been proposed in\nthe past two decades. These models serve as additional tools for basic research\nin cognitive science and neuroscience. Encoding models aim at generating fMRI\nbrain representations given a stimulus automatically. They have several\npractical applications in evaluating and diagnosing neurological conditions and\nthus also help design therapies for brain damage. Decoding models solve the\ninverse problem of reconstructing the stimuli given the fMRI. They are useful\nfor designing brain-machine or brain-computer interfaces. Inspired by the\neffectiveness of deep learning models for natural language processing, computer\nvision, and speech, recently several neural encoding and decoding models have\nbeen proposed. In this survey, we will first discuss popular representations of\nlanguage, vision and speech stimuli, and present a summary of neuroscience\ndatasets. Further, we will review popular deep learning based encoding and\ndecoding architectures and note their benefits and limitations. Finally, we\nwill conclude with a brief summary and discussion about future trends. Given\nthe large amount of recently published work in the `computational cognitive\nneuroscience' community, we believe that this survey nicely organizes the\nplethora of work and presents it as a coherent story.\n",
                "链接": "https://arxiv.org/abs/2307.10246"
            },
            {
                "文章ID": "81153",
                "标题": "Efficient Decoding of Compositional Structure in Holistic\n  Representations",
                "作者": " Denis Kleyko,  Connor Bybee,  Ping-Chen Huang,  Christopher J. Kymn,  Bruno A. Olshausen,  E. Paxon Frady,  Friedrich T. Sommer",
                "发布日期": "2023-05-29",
                "摘要": "  We investigate the task of retrieving information from compositional\ndistributed representations formed by Hyperdimensional Computing/Vector\nSymbolic Architectures and present novel techniques which achieve new\ninformation rate bounds. First, we provide an overview of the decoding\ntechniques that can be used to approach the retrieval task. The techniques are\ncategorized into four groups. We then evaluate the considered techniques in\nseveral settings that involve, e.g., inclusion of external noise and storage\nelements with reduced precision. In particular, we find that the decoding\ntechniques from the sparse coding and compressed sensing literature (rarely\nused for Hyperdimensional Computing/Vector Symbolic Architectures) are also\nwell-suited for decoding information from the compositional distributed\nrepresentations. Combining these decoding techniques with interference\ncancellation ideas from communications improves previously reported bounds\n(Hersche et al., 2021) of the information rate of the distributed\nrepresentations from 1.20 to 1.40 bits per dimension for smaller codebooks and\nfrom 0.60 to 1.26 bits per dimension for larger codebooks.\n",
                "链接": "https://arxiv.org/abs/2305.16873"
            },
            {
                "文章ID": "40637",
                "标题": "Nonparametric Decoding for Generative Retrieval",
                "作者": " Hyunji Lee,  Jaeyoung Kim,  Hoyeon Chang,  Hanseok Oh,  Sohee Yang,  Vlad Karpukhin,  Yi Lu,  Minjoon Seo",
                "发布日期": "2023-05-30",
                "摘要": "  The generative retrieval model depends solely on the information encoded in\nits model parameters without external memory, its information capacity is\nlimited and fixed. To overcome the limitation, we propose Nonparametric\nDecoding (Np Decoding) which can be applied to existing generative retrieval\nmodels. Np Decoding uses nonparametric contextualized vocab embeddings\n(external memory) rather than vanilla vocab embeddings as decoder vocab\nembeddings. By leveraging the contextualized vocab embeddings, the generative\nretrieval model is able to utilize both the parametric and nonparametric space.\nEvaluation over 9 datasets (8 single-hop and 1 multi-hop) in the document\nretrieval task shows that applying Np Decoding to generative retrieval models\nsignificantly improves the performance. We also show that Np Decoding is data-\nand parameter-efficient, and shows high performance in the zero-shot setting.\n",
                "链接": "https://arxiv.org/abs/2210.02068"
            },
            {
                "文章ID": "110770",
                "标题": "Air-Decoding: Attribute Distribution Reconstruction for Decoding-Time\n  Controllable Text Generation",
                "作者": " Tianqi Zhong,  Quan Wang,  Jingxuan Han,  Yongdong Zhang,  Zhendong Mao",
                "发布日期": "2023-11-03",
                "摘要": "  Controllable text generation (CTG) aims to generate text with desired\nattributes, and decoding-time-based methods have shown promising performance on\nthis task. However, in this paper, we identify the phenomenon of Attribute\nCollapse for the first time. It causes the fluency of generated text to rapidly\ndecrease when the control strength exceeds a critical value, rendering the text\ncompletely unusable. This limitation hinders the effectiveness of decoding\nmethods in achieving high levels of controllability. To address this problem,\nwe propose a novel lightweight decoding framework named Air-Decoding. Its main\nidea is reconstructing the attribute distributions to balance the weights\nbetween attribute words and non-attribute words to generate more fluent text.\nSpecifically, we train prefixes by prefix-tuning to obtain attribute\ndistributions. Then we design a novel attribute distribution reconstruction\nmethod to balance the obtained distributions and use the reconstructed\ndistributions to guide language models for generation, effectively avoiding the\nissue of Attribute Collapse. Experiments on multiple CTG tasks prove that our\nmethod achieves a new state-of-the-art control performance.\n",
                "链接": "https://arxiv.org/abs/2310.14892"
            },
            {
                "文章ID": "124417",
                "标题": "Context-aware Decoding Reduces Hallucination in Query-focused\n  Summarization",
                "作者": " Zhichao Xu",
                "发布日期": "2023-12-25",
                "摘要": "  Query-focused summarization (QFS) aims to provide a summary of a single\ndocument/multi documents that can satisfy the information needs of a given\nquery. It is useful for various real-world applications, such as abstractive\nsnippet generation or more recent retrieval augmented generation (RAG). A\nprototypical QFS pipeline consists of a retriever (sparse or dense retrieval)\nand a generator (usually a large language model). However, applying large\nlanguage models (LLM) potentially leads to hallucinations, especially when the\nevidence contradicts the prior belief of LLMs. There has been growing interest\nin developing new decoding methods to improve generation quality and reduce\nhallucination. In this work, we conduct a large-scale reproducibility on one\nrecently proposed decoding method -- Context-aware Decoding (CAD). In addition\nto replicating CAD's experiments on news summarization datasets, we include\nexperiments on QFS datasets, and conduct more rigorous analysis on\ncomputational complexity and hyperparameter sensitivity. Experiments with eight\ndifferent language models show that performance-wise, CAD improves QFS quality\nby (1) reducing factuality errors/hallucinations while (2) mostly retaining the\nmatch of lexical patterns, measured by ROUGE scores, while also at a cost of\nincreased inference-time FLOPs and reduced decoding speed. The code\nimplementation based on Huggingface Library is made available\nhttps://github.com/zhichaoxu-shufe/context-aware-decoding-qfs\n",
                "链接": "https://arxiv.org/abs/2312.14335"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近三个月有关语言模型rlhf的arxiv上的全部文章。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大模型结合树搜索方法进行推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105172",
                "标题": "Alphazero-like Tree-Search can Guide Large Language Model Decoding and\n  Training",
                "作者": " Xidong Feng,  Ziyu Wan,  Muning Wen,  Ying Wen,  Weinan Zhang,  Jun Wang",
                "发布日期": "2023-10-02",
                "摘要": "  Large language models (LLMs) typically employ sampling or beam search,\naccompanied by prompts such as Chain-of-Thought (CoT), to boost reasoning and\ndecoding ability. Recent work like Tree-of-Thought (ToT) and Reasoning via\nPlanning (RAP) aim to augment the reasoning capabilities of LLMs by utilizing\ntree-search algorithms to guide multi-step reasoning. These methods mainly\nfocus on LLMs' reasoning ability during inference and heavily rely on\nhuman-designed prompts to activate LLM as a value function, which lacks general\napplicability and scalability. To address these limitations, we present an\nAlphaZero-like tree-search framework for LLMs (termed TS-LLM), systematically\nillustrating how tree-search with a learned value function can guide LLMs'\ndecoding ability. TS-LLM distinguishes itself in two key ways: (1) Leveraging a\nlearned value function, our approach can be generally applied to different\ntasks beyond reasoning (such as RLHF alignment), and LLMs of any size, without\nprompting advanced, large-scale models. (2) It can guide LLM's decoding during\nboth inference and training. Empirical evaluations across reasoning, planning,\nand RLHF alignment tasks validate the effectiveness of TS-LLM, even on trees\nwith a depth of 64.\n",
                "链接": "https://arxiv.org/abs/2309.17179"
            },
            {
                "文章ID": "109239",
                "标题": "Autonomous Tree-search Ability of Large Language Models",
                "作者": " Zheyu Zhang,  Zhuorui Ye,  Yikang Shen,  Chuang Gan",
                "发布日期": "2023-10-18",
                "摘要": "  Large Language Models have excelled in remarkable reasoning capabilities with\nadvanced prompting techniques, but they fall short on tasks that require\nexploration, strategic foresight, and sequential decision-making. Recent works\npropose to utilize external programs to define search logic, such that LLMs can\nperform passive tree search to solve more challenging reasoning tasks. Though\nimpressive results have been achieved, there are several fundamental\nlimitations of these approaches. First, passive tree searches are not efficient\nas they usually require multiple rounds of LLM API calls to solve one single\nproblem. Moreover, passive search methods are not flexible since they need\ntask-specific program designs. Then a natural question arises: can we maintain\nthe tree-search capability of LLMs without the aid of external programs, and\ncan still generate responses that clearly demonstrate the process of a\ntree-structure search? To this end, we propose a new concept called autonomous\ntree-search ability of LLM, which can automatically generate a response\ncontaining search trajectories for the correct answer. Concretely, we perform\nsearch trajectories using capable LLM API via a fixed system prompt, allowing\nthem to perform autonomous tree-search (ATS) right out of the box. Experiments\non 4 puzzle games demonstrate our method can achieve huge improvements. The\nATS-BFS method outperforms the Chain of Thought approach by achieving an\naverage accuracy improvement of 33%. Compared to Tree of Thoughts, it requires\n65.6% or 47.7% less GPT-api cost to attain a comparable level of accuracy.\nMoreover, we have collected data using the ATS prompt method and fine-tuned\nLLaMA. This approach yield a greater improvement compared to the ones\nfine-tuned on CoT data. Specifically, it outperforms CoT-tuned LLaMAs by an\naverage of 40.6% and 38.5% for LLaMA2-7B and LLaMA2-13B, respectively.\n",
                "链接": "https://arxiv.org/abs/2310.10686"
            },
            {
                "文章ID": "106837",
                "标题": "Language Agent Tree Search Unifies Reasoning Acting and Planning in\n  Language Models",
                "作者": " Andy Zhou,  Kai Yan,  Michal Shlapentokh-Rothman,  Haohan Wang,  Yu-Xiong Wang",
                "发布日期": "2023-12-06",
                "摘要": "  While large language models (LLMs) have demonstrated impressive performance\non a range of decision-making tasks, they rely on simple acting processes and\nfall short of broad deployment as autonomous agents. We introduce LATS\n(Language Agent Tree Search), a general framework that synergizes the\ncapabilities of LLMs in planning, acting, and reasoning. Drawing inspiration\nfrom Monte Carlo tree search in model-based reinforcement learning, LATS\nemploys LLMs as agents, value functions, and optimizers, repurposing their\nlatent strengths for enhanced decision-making. What is crucial in this method\nis the use of an environment for external feedback, which offers a more\ndeliberate and adaptive problem-solving mechanism that moves beyond the\nlimitations of existing techniques. Our experimental evaluation across diverse\ndomains, such as programming, HotPotQA, and WebShop, illustrates the\napplicability of LATS for both reasoning and acting. In particular, LATS\nachieves 94.4% for programming on HumanEval with GPT-4 and an average score of\n75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness\nand generality of our method.\n",
                "链接": "https://arxiv.org/abs/2310.04406"
            },
            {
                "文章ID": "110564",
                "标题": "Monte Carlo Thought Search: Large Language Model Querying for Complex\n  Scientific Reasoning in Catalyst Design",
                "作者": " Henry W. Sprueill,  Carl Edwards,  Mariefel V. Olarte,  Udishnu Sanyal,  Heng Ji,  Sutanay Choudhury",
                "发布日期": "2023-11-07",
                "摘要": "  Discovering novel catalysts requires complex reasoning involving multiple\nchemical properties and resultant trade-offs, leading to a combinatorial growth\nin the search space. While large language models (LLM) have demonstrated novel\ncapabilities for chemistry through complex instruction following capabilities\nand high quality reasoning, a goal-driven combinatorial search using LLMs has\nnot been explored in detail. In this work, we present a Monte Carlo Tree\nSearch-based approach that improves beyond state-of-the-art chain-of-thought\nprompting variants to augment scientific reasoning. We introduce two new\nreasoning datasets: 1) a curation of computational chemistry simulations, and\n2) diverse questions written by catalysis researchers for reasoning about novel\nchemical conversion processes. We improve over the best baseline by 25.8\\% and\nfind that our approach can augment scientist's reasoning and discovery process\nwith novel insights.\n",
                "链接": "https://arxiv.org/abs/2310.14420"
            },
            {
                "文章ID": "100689",
                "标题": "No Train Still Gain. Unleash Mathematical Reasoning of Large Language\n  Models with Monte Carlo Tree Search Guided by Energy Function",
                "作者": " Haotian Xu",
                "发布日期": "2023-09-13",
                "摘要": "  Large language models (LLMs) demonstrate impressive language understanding\nand contextual learning abilities, making them suitable for natural language\nprocessing (NLP) tasks and complex mathematical reasoning. However, when\napplied to mathematical reasoning tasks, LLMs often struggle to generate\ncorrect reasoning steps and answers despite having high probabilities for the\nsolutions. To overcome this limitation and enhance the mathematical reasoning\ncapabilities of fine-tuned LLMs without additional fine-tuning steps, we\npropose a method that incorporates Monte Carlo Tree Search (MCTS) and a\nlightweight energy function to rank decision steps and enable immediate\nreaction and precise reasoning. Specifically, we re-formulate the fine-tuned\nLLMs into a Residual-based Energy Model (Residual-EBM) and employ noise\ncontrastive estimation to estimate the energy function's parameters. We then\nutilize MCTS with the energy function as a path verifier to search the output\nspace and evaluate the reasoning path. Through extensive experiments on two\nmathematical reasoning benchmarks, GSM8k and AQUA-RAT, we demonstrate the\nexceptional capabilities of our method, which significantly improves the pass@1\nmetric of the fine-tuned model without requiring additional fine-tuning or\nreinforcement learning with human feedback alignment.\n",
                "链接": "https://arxiv.org/abs/2309.03224"
            },
            {
                "文章ID": "121204",
                "标题": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "作者": " Olga Golovneva,  Sean O'Brien,  Ramakanth Pasunuru,  Tianlu Wang,  Luke Zettlemoyer,  Maryam Fazel-Zarandi,  Asli Celikyilmaz",
                "发布日期": "2023-12-13",
                "摘要": "  With recent advancements in large language models, methods like\nchain-of-thought prompting to elicit reasoning chains have been shown to\nimprove results on reasoning tasks. However, tasks that require multiple steps\nof reasoning still pose significant challenges to state-of-the-art models.\nDrawing inspiration from the beam search algorithm, we propose PathFinder, a\ntree-search-based reasoning path generation approach. It enhances diverse\nbranching and multi-hop reasoning through the integration of dynamic decoding,\nenabled by varying sampling methods and parameters. Using constrained\nreasoning, PathFinder integrates novel quality constraints, pruning, and\nexploration methods to enhance the efficiency and the quality of generation.\nMoreover, it includes scoring and ranking features to improve candidate\nselection. Our approach outperforms competitive baselines on three complex\narithmetic and commonsense reasoning tasks by 6% on average. Our model\ngeneralizes well to longer, unseen reasoning chains, reflecting similar\ncomplexities to beam search with large branching factors.\n",
                "链接": "https://arxiv.org/abs/2312.05180"
            },
            {
                "文章ID": "102013",
                "标题": "Tree of Uncertain Thoughts Reasoning for Large Language Models",
                "作者": " Shentong Mo,  Miao Xin",
                "发布日期": "2023-09-15",
                "摘要": "  While the recently introduced Tree of Thoughts (ToT) has heralded\nadvancements in allowing Large Language Models (LLMs) to reason through\nforesight and backtracking for global decision-making, it has overlooked the\ninherent local uncertainties in intermediate decision points or \"thoughts\".\nThese local uncertainties, intrinsic to LLMs given their potential for diverse\nresponses, remain a significant concern in the reasoning process. Addressing\nthis pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) - a\nreasoning framework tailored for LLMs. Our TouT effectively leverages Monte\nCarlo Dropout to quantify uncertainty scores associated with LLMs' diverse\nlocal responses at these intermediate steps. By marrying this local uncertainty\nquantification with global search algorithms, TouT enhances the model's\nprecision in response generation. We substantiate our approach with rigorous\nexperiments on two demanding planning tasks: Game of 24 and Mini Crosswords.\nThe empirical evidence underscores TouT's superiority over both ToT and\nchain-of-thought prompting methods.\n",
                "链接": "https://arxiv.org/abs/2309.07694"
            },
            {
                "文章ID": "80368",
                "标题": "Reasoning over Hierarchical Question Decomposition Tree for Explainable\n  Question Answering",
                "作者": " Jiajie Zhang,  Shulin Cao,  Tingjia Zhang,  Xin Lv,  Jiaxin Shi,  Qi Tian,  Juanzi Li,  Lei Hou",
                "发布日期": "2023-05-25",
                "摘要": "  Explainable question answering (XQA) aims to answer a given question and\nprovide an explanation why the answer is selected. Existing XQA methods focus\non reasoning on a single knowledge source, e.g., structured knowledge bases,\nunstructured corpora, etc. However, integrating information from heterogeneous\nknowledge sources is essential to answer complex questions. In this paper, we\npropose to leverage question decomposing for heterogeneous knowledge\nintegration, by breaking down a complex question into simpler ones, and\nselecting the appropriate knowledge source for each sub-question. To facilitate\nreasoning, we propose a novel two-stage XQA framework, Reasoning over\nHierarchical Question Decomposition Tree (RoHT). First, we build the\nHierarchical Question Decomposition Tree (HQDT) to understand the semantics of\na complex question; then, we conduct probabilistic reasoning over HQDT from\nroot to leaves recursively, to aggregate heterogeneous knowledge at different\ntree levels and search for a best solution considering the decomposing and\nanswering probabilities. The experiments on complex QA datasets KQA Pro and\nMusique show that our framework outperforms SOTA methods significantly,\ndemonstrating the effectiveness of leveraging question decomposing for\nknowledge integration and our RoHT framework.\n",
                "链接": "https://arxiv.org/abs/2305.15056"
            },
            {
                "文章ID": "39406",
                "标题": "SoftTreeMax: Policy Gradient with Tree Search",
                "作者": " Gal Dalal,  Assaf Hallak,  Shie Mannor,  Gal Chechik",
                "发布日期": "2022-09-29",
                "摘要": "  Policy-gradient methods are widely used for learning control policies. They\ncan be easily distributed to multiple workers and reach state-of-the-art\nresults in many domains. Unfortunately, they exhibit large variance and\nsubsequently suffer from high-sample complexity since they aggregate gradients\nover entire trajectories. At the other extreme, planning methods, like tree\nsearch, optimize the policy using single-step transitions that consider future\nlookahead. These approaches have been mainly considered for value-based\nalgorithms. Planning-based algorithms require a forward model and are\ncomputationally intensive at each step, but are more sample efficient. In this\nwork, we introduce SoftTreeMax, the first approach that integrates tree-search\ninto policy gradient. Traditionally, gradients are computed for single\nstate-action pairs. Instead, our tree-based policy structure leverages all\ngradients at the tree leaves in each environment step. This allows us to reduce\nthe variance of gradients by three orders of magnitude and to benefit from\nbetter sample complexity compared with standard policy gradient. On Atari,\nSoftTreeMax demonstrates up to 5x better performance in faster run-time\ncompared with distributed PPO.\n",
                "链接": "https://arxiv.org/abs/2209.13966"
            },
            {
                "文章ID": "80322",
                "标题": "Reasoning with Language Model is Planning with World Model",
                "作者": " Shibo Hao,  Yi Gu,  Haodi Ma,  Joshua Jiahua Hong,  Zhen Wang,  Daisy Zhe Wang,  Zhiting Hu",
                "发布日期": "2023-10-24",
                "摘要": "  Large language models (LLMs) have shown remarkable reasoning capabilities,\nespecially when prompted to generate intermediate reasoning steps (e.g.,\nChain-of-Thought, CoT). However, LLMs can still struggle with problems that are\neasy for humans, such as generating action plans for executing tasks in a given\nenvironment, or performing complex math, logical, and commonsense reasoning.\nThe deficiency stems from the key fact that LLMs lack an internal\n$\\textit{world model}$ to predict the world $\\textit{state}$ (e.g., environment\nstatus, intermediate variable values) and simulate long-term outcomes of\nactions. This prevents LLMs from performing deliberate planning akin to human\nbrains, which involves exploring alternative reasoning paths, anticipating\nfuture states and rewards, and iteratively refining existing reasoning steps.\nTo overcome the limitations, we propose a new LLM reasoning framework,\n$\\underline{R}$easoning vi$\\underline{a}$ $\\underline{P}$lanning\n$\\textbf{(RAP)}$. RAP repurposes the LLM as both a world model and a reasoning\nagent, and incorporates a principled planning algorithm (based on Monto Carlo\nTree Search) for strategic exploration in the vast reasoning space. During\nreasoning, the LLM (as agent) incrementally builds a reasoning tree under the\nguidance of the LLM (as world model) and task-specific rewards, and obtains a\nhigh-reward reasoning path efficiently with a proper balance between\nexploration $\\textit{vs.}$ exploitation. We apply RAP to a variety of\nchallenging reasoning problems including plan generation, math reasoning, and\nlogical inference. Empirical results on these tasks demonstrate the superiority\nof RAP over various strong baselines, including CoT and least-to-most prompting\nwith self-consistency. RAP on LLAMA-33B surpasses CoT on GPT-4 with 33%\nrelative improvement in a plan generation setting.\n",
                "链接": "https://arxiv.org/abs/2305.14992"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于通过prompt经验性研究大语言模型行为的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "112194",
                "标题": "Using Large Language Models to Support Thematic Analysis in Empirical\n  Legal Studies",
                "作者": " Jakub Drápal,  Hannes Westermann,  Jaromir Savelka",
                "发布日期": "2023-10-31",
                "摘要": "  Thematic analysis and other variants of inductive coding are widely used\nqualitative analytic methods within empirical legal studies (ELS). We propose a\nnovel framework facilitating effective collaboration of a legal expert with a\nlarge language model (LLM) for generating initial codes (phase 2 of thematic\nanalysis), searching for themes (phase 3), and classifying the data in terms of\nthe themes (to kick-start phase 4). We employed the framework for an analysis\nof a dataset (n=785) of facts descriptions from criminal court opinions\nregarding thefts. The goal of the analysis was to discover classes of typical\nthefts. Our results show that the LLM, namely OpenAI's GPT-4, generated\nreasonable initial codes, and it was capable of improving the quality of the\ncodes based on expert feedback. They also suggest that the model performed well\nin zero-shot classification of facts descriptions in terms of the themes.\nFinally, the themes autonomously discovered by the LLM appear to map fairly\nwell to the themes arrived at by legal experts. These findings can be leveraged\nby legal researchers to guide their decisions in integrating LLMs into their\nthematic analyses, as well as other inductive coding projects.\n",
                "链接": "https://arxiv.org/abs/2310.18729"
            },
            {
                "文章ID": "84328",
                "标题": "PromptBench: Towards Evaluating the Robustness of Large Language Models\n  on Adversarial Prompts",
                "作者": " Kaijie Zhu,  Jindong Wang,  Jiaheng Zhou,  Zichen Wang,  Hao Chen,  Yidong Wang,  Linyi Yang,  Wei Ye,  Yue Zhang,  Neil Zhenqiang Gong,  Xing Xie",
                "发布日期": "2023-10-19",
                "摘要": "  The increasing reliance on Large Language Models (LLMs) across academia and\nindustry necessitates a comprehensive understanding of their robustness to\nprompts. In response to this vital need, we introduce PromptBench, a robustness\nbenchmark designed to measure LLMs' resilience to adversarial prompts. This\nstudy uses a plethora of adversarial textual attacks targeting prompts across\nmultiple levels: character, word, sentence, and semantic. The adversarial\nprompts, crafted to mimic plausible user errors like typos or synonyms, aim to\nevaluate how slight deviations can affect LLM outcomes while maintaining\nsemantic integrity. These prompts are then employed in diverse tasks, such as\nsentiment analysis, natural language inference, reading comprehension, machine\ntranslation, and math problem-solving. Our study generates 4788 adversarial\nprompts, meticulously evaluated over 8 tasks and 13 datasets. Our findings\ndemonstrate that contemporary LLMs are not robust to adversarial prompts.\nFurthermore, we present comprehensive analysis to understand the mystery behind\nprompt robustness and its transferability. We then offer insightful robustness\nanalysis and pragmatic recommendations for prompt composition, beneficial to\nboth researchers and everyday users. Code is available at:\nhttps://github.com/microsoft/promptbench.\n",
                "链接": "https://arxiv.org/abs/2306.04528"
            },
            {
                "文章ID": "106864",
                "标题": "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language\n  Models",
                "作者": " Xiaogeng Liu,  Nan Xu,  Muhao Chen,  Chaowei Xiao",
                "发布日期": "2023-10-10",
                "摘要": "  The aligned Large Language Models (LLMs) are powerful language understanding\nand decision-making tools that are created through extensive alignment with\nhuman feedback. However, these large models remain susceptible to jailbreak\nattacks, where adversaries manipulate prompts to elicit malicious outputs that\nshould not be given by aligned LLMs. Investigating jailbreak prompts can lead\nus to delve into the limitations of LLMs and further guide us to secure them.\nUnfortunately, existing jailbreak techniques suffer from either (1) scalability\nissues, where attacks heavily rely on manual crafting of prompts, or (2)\nstealthiness problems, as attacks depend on token-based algorithms to generate\nprompts that are often semantically meaningless, making them susceptible to\ndetection through basic perplexity testing. In light of these challenges, we\nintend to answer this question: Can we develop an approach that can\nautomatically generate stealthy jailbreak prompts? In this paper, we introduce\nAutoDAN, a novel jailbreak attack against aligned LLMs. AutoDAN can\nautomatically generate stealthy jailbreak prompts by the carefully designed\nhierarchical genetic algorithm. Extensive evaluations demonstrate that AutoDAN\nnot only automates the process while preserving semantic meaningfulness, but\nalso demonstrates superior attack strength in cross-model transferability, and\ncross-sample universality compared with the baseline. Moreover, we also compare\nAutoDAN with perplexity-based defense methods and show that AutoDAN can bypass\nthem effectively.\n",
                "链接": "https://arxiv.org/abs/2310.04451"
            },
            {
                "文章ID": "75044",
                "标题": "An Empirical Study of Using Large Language Models for Unit Test\n  Generation",
                "作者": " Mohammed Latif Siddiq,  Joanna C. S. Santos,  Ridwanul Hasan Tanvir,  Noshin Ulfat,  Fahmid Al Rifat,  Vinicius Carvalho Lopes",
                "发布日期": "2023-10-31",
                "摘要": "  A code generation model generates code by taking a prompt from a code\ncomment, existing code, or a combination of both. Although code generation\nmodels (e.g. GitHub Copilot) are increasingly being adopted in practice, it is\nunclear whether they can successfully be used for unit test generation without\nfine-tuning. We investigated how well three generative models (Codex,\nGPT-3.5-Turbo, and StarCoder) can generate test cases to fill this gap. We used\ntwo benchmarks (HumanEval and Evosuite SF110) to investigate the context\ngeneration's effect in the unit test generation process. We evaluated the\nmodels based on compilation rates, test correctness, coverage, and test smells.\nWe found that the Codex model achieved above 80% coverage for the HumanEval\ndataset, but no model had more than 2% coverage for the EvoSuite SF110\nbenchmark. The generated tests also suffered from test smells, such as\nDuplicated Asserts and Empty Tests.\n",
                "链接": "https://arxiv.org/abs/2305.00418"
            },
            {
                "文章ID": "115250",
                "标题": "On the Discussion of Large Language Models: Symmetry of Agents and\n  Interplay with Prompts",
                "作者": " Qineng Wang,  Zihao Wang,  Ying Su,  Yangqiu Song",
                "发布日期": "2023-11-14",
                "摘要": "  Two ways has been discussed to unlock the reasoning capability of a large\nlanguage model. The first one is prompt engineering and the second one is to\ncombine the multiple inferences of large language models, or the multi-agent\ndiscussion. Theoretically, this paper justifies the multi-agent discussion\nmechanisms from the symmetry of agents. Empirically, this paper reports the\nempirical results of the interplay of prompts and discussion mechanisms,\nrevealing the empirical state-of-the-art performance of complex multi-agent\nmechanisms can be approached by carefully developed prompt engineering. This\npaper also proposes a scalable discussion mechanism based on conquer and merge,\nproviding a simple multi-agent discussion solution with simple prompts but\nstate-of-the-art performance.\n",
                "链接": "https://arxiv.org/abs/2311.07076"
            },
            {
                "文章ID": "107406",
                "标题": "LLMLingua: Compressing Prompts for Accelerated Inference of Large\n  Language Models",
                "作者": " Huiqiang Jiang,  Qianhui Wu,  Chin-Yew Lin,  Yuqing Yang,  Lili Qiu",
                "发布日期": "2023-12-07",
                "摘要": "  Large language models (LLMs) have been applied in various applications due to\ntheir astonishing capabilities. With advancements in technologies such as\nchain-of-thought (CoT) prompting and in-context learning (ICL), the prompts fed\nto LLMs are becoming increasingly lengthy, even exceeding tens of thousands of\ntokens. To accelerate model inference and reduce cost, this paper presents\nLLMLingua, a coarse-to-fine prompt compression method that involves a budget\ncontroller to maintain semantic integrity under high compression ratios, a\ntoken-level iterative compression algorithm to better model the interdependence\nbetween compressed contents, and an instruction tuning based method for\ndistribution alignment between language models. We conduct experiments and\nanalysis over four datasets from different scenarios, i.e., GSM8K, BBH,\nShareGPT, and Arxiv-March23; showing that the proposed approach yields\nstate-of-the-art performance and allows for up to 20x compression with little\nperformance loss. Our code is available at https://aka.ms/LLMLingua.\n",
                "链接": "https://arxiv.org/abs/2310.05736"
            },
            {
                "文章ID": "61414",
                "标题": "An Empirical Evaluation of Using Large Language Models for Automated\n  Unit Test Generation",
                "作者": " Max Schäfer,  Sarah Nadi,  Aryaz Eghbali,  Frank Tip",
                "发布日期": "2023-12-12",
                "摘要": "  Unit tests play a key role in ensuring the correctness of software. However,\nmanually creating unit tests is a laborious task, motivating the need for\nautomation. Large Language Models (LLMs) have recently been applied to this\nproblem, utilizing additional training or few-shot learning on examples of\nexisting tests. This paper presents a large-scale empirical evaluation on the\neffectiveness of LLMs for automated unit test generation without additional\ntraining or manual effort, providing the LLM with the signature and\nimplementation of the function under test, along with usage examples extracted\nfrom documentation. We also attempt to repair failed generated tests by\nre-prompting the model with the failing test and error message. We implement\nour approach in TestPilot, a test generation tool for JavaScript that\nautomatically generates unit tests for all API functions in an npm package. We\nevaluate TestPilot using OpenAI's gpt3.5-turbo LLM on 25 npm packages with a\ntotal of 1,684 API functions. The generated tests achieve a median statement\ncoverage of 70.2% and branch coverage of 52.8%, significantly improving on\nNessie, a recent feedback-directed JavaScript test generation technique, which\nachieves only 51.3% statement coverage and 25.6% branch coverage. We also find\nthat 92.8% of TestPilot's generated tests have no more than 50% similarity with\nexisting tests (as measured by normalized edit distance), with none of them\nbeing exact copies. Finally, we run TestPilot with two additional LLMs,\nOpenAI's older code-cushman-002 LLM and the open LLM StarCoder. Overall, we\nobserved similar results with the former (68.2% median statement coverage), and\nsomewhat worse results with the latter (54.0% median statement coverage),\nsuggesting that the effectiveness of the approach is influenced by the size and\ntraining set of the LLM, but does not fundamentally depend on the specific\nmodel.\n",
                "链接": "https://arxiv.org/abs/2302.06527"
            },
            {
                "文章ID": "34329",
                "标题": "Using Large Language Models to Simulate Multiple Humans and Replicate\n  Human Subject Studies",
                "作者": " Gati Aher,  Rosa I. Arriaga,  Adam Tauman Kalai",
                "发布日期": "2023-07-11",
                "摘要": "  We introduce a new type of test, called a Turing Experiment (TE), for\nevaluating to what extent a given language model, such as GPT models, can\nsimulate different aspects of human behavior. A TE can also reveal consistent\ndistortions in a language model's simulation of a specific human behavior.\nUnlike the Turing Test, which involves simulating a single arbitrary\nindividual, a TE requires simulating a representative sample of participants in\nhuman subject research. We carry out TEs that attempt to replicate\nwell-established findings from prior studies. We design a methodology for\nsimulating TEs and illustrate its use to compare how well different language\nmodels are able to reproduce classic economic, psycholinguistic, and social\npsychology experiments: Ultimatum Game, Garden Path Sentences, Milgram Shock\nExperiment, and Wisdom of Crowds. In the first three TEs, the existing findings\nwere replicated using recent models, while the last TE reveals a\n\"hyper-accuracy distortion\" present in some language models (including ChatGPT\nand GPT-4), which could affect downstream applications in education and the\narts.\n",
                "链接": "https://arxiv.org/abs/2208.10264"
            },
            {
                "文章ID": "102889",
                "标题": "Explaining Agent Behavior with Large Language Models",
                "作者": " Xijia Zhang,  Yue Guo,  Simon Stepputtis,  Katia Sycara,  Joseph Campbell",
                "发布日期": "2023-09-20",
                "摘要": "  Intelligent agents such as robots are increasingly deployed in real-world,\nsafety-critical settings. It is vital that these agents are able to explain the\nreasoning behind their decisions to human counterparts, however, their behavior\nis often produced by uninterpretable models such as deep neural networks. We\npropose an approach to generate natural language explanations for an agent's\nbehavior based only on observations of states and actions, agnostic to the\nunderlying model representation. We show how a compact representation of the\nagent's behavior can be learned and used to produce plausible explanations with\nminimal hallucination while affording user interaction with a pre-trained large\nlanguage model. Through user studies and empirical experiments, we show that\nour approach generates explanations as helpful as those generated by a human\ndomain expert while enabling beneficial interactions such as clarification and\ncounterfactual queries.\n",
                "链接": "https://arxiv.org/abs/2309.10346"
            },
            {
                "文章ID": "119665",
                "标题": "Large Language Models for Travel Behavior Prediction",
                "作者": " Baichuan Mo,  Hanyong Xu,  Dingyi Zhuang,  Ruoyun Ma,  Xiaotong Guo,  Jinhua Zhao",
                "发布日期": "2023-12-05",
                "摘要": "  Travel behavior prediction is a fundamental task in transportation demand\nmanagement. The conventional methods for travel behavior prediction rely on\nnumerical data to construct mathematical models and calibrate model parameters\nto represent human preferences. Recent advancement in large language models\n(LLMs) has shown great reasoning abilities to solve complex problems. In this\nstudy, we propose to use LLMs to predict travel behavior with prompt\nengineering without data-based parameter learning. Specifically, we carefully\ndesign our prompts that include 1) task description, 2) travel characteristics,\n3) individual attributes, and 4) guides of thinking with domain knowledge, and\nask the LLMs to predict an individual's travel behavior and explain the\nresults. We select the travel mode choice task as a case study. Results show\nthat, though no training samples are provided, LLM-based predictions have\ncompetitive accuracy and F1-score as canonical supervised learning methods such\nas multinomial logit, random forest, and neural networks. LLMs can also output\nreasons that support their prediction. However, though in most of the cases,\nthe output explanations are reasonable, we still observe cases that violate\nlogic or with hallucinations.\n",
                "链接": "https://arxiv.org/abs/2312.00819"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近两年关于语言模型奖励建模评估的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "55457",
                "标题": "Improving a sequence-to-sequence nlp model using a reinforcement\n  learning policy algorithm",
                "作者": " Jabri Ismail,  Aboulbichr Ahmed,  El ouaazizi Aziza",
                "发布日期": "2023-01-19",
                "摘要": "  Nowadays, the current neural network models of dialogue generation(chatbots)\nshow great promise for generating answers for chatty agents. But they are\nshort-sighted in that they predict utterances one at a time while disregarding\ntheir impact on future outcomes. Modelling a dialogue's future direction is\ncritical for generating coherent, interesting dialogues, a need that has led\ntraditional NLP dialogue models that rely on reinforcement learning. In this\narticle, we explain how to combine these objectives by using deep reinforcement\nlearning to predict future rewards in chatbot dialogue. The model simulates\nconversations between two virtual agents, with policy gradient methods used to\nreward sequences that exhibit three useful conversational characteristics: the\nflow of informality, coherence, and simplicity of response (related to\nforward-looking function). We assess our model based on its diversity, length,\nand complexity with regard to humans. In dialogue simulation, evaluations\ndemonstrated that the proposed model generates more interactive responses and\nencourages a more sustained successful conversation. This work commemorates a\npreliminary step toward developing a neural conversational model based on the\nlong-term success of dialogues.\n",
                "链接": "https://arxiv.org/abs/2212.14117"
            },
            {
                "文章ID": "49630",
                "标题": "Improving Multimodal Interactive Agents with Reinforcement Learning from\n  Human Feedback",
                "作者": " Josh Abramson,  Arun Ahuja,  Federico Carnevale,  Petko Georgiev,  Alex Goldin,  Alden Hung,  Jessica Landon,  Jirka Lhotka,  Timothy Lillicrap,  Alistair Muldal,  George Powell,  Adam Santoro,  Guy Scully,  Sanjana Srivastava,  Tamara von Glehn,  Greg Wayne,  Nathaniel Wong,  Chen Yan,  Rui Zhu",
                "发布日期": "2022-11-22",
                "摘要": "  An important goal in artificial intelligence is to create agents that can\nboth interact naturally with humans and learn from their feedback. Here we\ndemonstrate how to use reinforcement learning from human feedback (RLHF) to\nimprove upon simulated, embodied agents trained to a base level of competency\nwith imitation learning. First, we collected data of humans interacting with\nagents in a simulated 3D world. We then asked annotators to record moments\nwhere they believed that agents either progressed toward or regressed from\ntheir human-instructed goal. Using this annotation data we leveraged a novel\nmethod - which we call \"Inter-temporal Bradley-Terry\" (IBT) modelling - to\nbuild a reward model that captures human judgments. Agents trained to optimise\nrewards delivered from IBT reward models improved with respect to all of our\nmetrics, including subsequent human judgment during live interactions with\nagents. Altogether our results demonstrate how one can successfully leverage\nhuman judgments to improve agent behaviour, allowing us to use reinforcement\nlearning in complex, embodied domains without programmatic reward functions.\nVideos of agent behaviour may be found at https://youtu.be/v_Z9F2_eKk4.\n",
                "链接": "https://arxiv.org/abs/2211.11602"
            },
            {
                "文章ID": "111470",
                "标题": "SuperHF: Supervised Iterative Learning from Human Feedback",
                "作者": " Gabriel Mukobi,  Peter Chatain,  Su Fong,  Robert Windesheim,  Gitta Kutyniok,  Kush Bhatia,  Silas Alberti",
                "发布日期": "2023-10-26",
                "摘要": "  While large language models demonstrate remarkable capabilities, they often\npresent challenges in terms of safety, alignment with human values, and\nstability during training. Here, we focus on two prevalent methods used to\nalign these models, Supervised Fine-Tuning (SFT) and Reinforcement Learning\nfrom Human Feedback (RLHF). SFT is simple and robust, powering a host of\nopen-source models, while RLHF is a more sophisticated method used in top-tier\nmodels like ChatGPT but also suffers from instability and susceptibility to\nreward hacking. We propose a novel approach, Supervised Iterative Learning from\nHuman Feedback (SuperHF), which seeks to leverage the strengths of both\nmethods. Our hypothesis is two-fold: that the reward model used in RLHF is\ncritical for efficient data use and model generalization and that the use of\nProximal Policy Optimization (PPO) in RLHF may not be necessary and could\ncontribute to instability issues. SuperHF replaces PPO with a simple supervised\nloss and a Kullback-Leibler (KL) divergence prior. It creates its own training\ndata by repeatedly sampling a batch of model outputs and filtering them through\nthe reward model in an online learning regime. We then break down the reward\noptimization problem into three components: robustly optimizing the training\nrewards themselves, preventing reward hacking-exploitation of the reward model\nthat degrades model performance-as measured by a novel METEOR similarity\nmetric, and maintaining good performance on downstream evaluations. Our\nexperimental results show SuperHF exceeds PPO-based RLHF on the training\nobjective, easily and favorably trades off high reward with low reward hacking,\nimproves downstream calibration, and performs the same on our GPT-4 based\nqualitative evaluation scheme all the while being significantly simpler to\nimplement, highlighting SuperHF's potential as a competitive language model\nalignment technique.\n",
                "链接": "https://arxiv.org/abs/2310.16763"
            },
            {
                "文章ID": "103890",
                "标题": "Calibrating LLM-Based Evaluator",
                "作者": " Yuxuan Liu,  Tianchi Yang,  Shaohan Huang,  Zihan Zhang,  Haizhen Huang,  Furu Wei,  Weiwei Deng,  Feng Sun,  Qi Zhang",
                "发布日期": "2023-09-26",
                "摘要": "  Recent advancements in large language models (LLMs) on language modeling and\nemergent capabilities make them a promising reference-free evaluator of natural\nlanguage generation quality, and a competent alternative to human evaluation.\nHowever, hindered by the closed-source or high computational demand to host and\ntune, there is a lack of practice to further calibrate an off-the-shelf\nLLM-based evaluator towards better human alignment. In this work, we propose\nAutoCalibrate, a multi-stage, gradient-free approach to automatically calibrate\nand align an LLM-based evaluator toward human preference. Instead of explicitly\nmodeling human preferences, we first implicitly encompass them within a set of\nhuman labels. Then, an initial set of scoring criteria is drafted by the\nlanguage model itself, leveraging in-context learning on different few-shot\nexamples. To further calibrate this set of criteria, we select the best\nperformers and re-draft them with self-refinement. Our experiments on multiple\ntext quality evaluation datasets illustrate a significant improvement in\ncorrelation with expert evaluation through calibration. Our comprehensive\nqualitative analysis conveys insightful intuitions and observations on the\nessence of effective scoring criteria.\n",
                "链接": "https://arxiv.org/abs/2309.13308"
            },
            {
                "文章ID": "98183",
                "标题": "Language Reward Modulation for Pretraining Reinforcement Learning",
                "作者": " Ademi Adeniji,  Amber Xie,  Carmelo Sferrazza,  Younggyo Seo,  Stephen James,  Pieter Abbeel",
                "发布日期": "2023-08-24",
                "摘要": "  Using learned reward functions (LRFs) as a means to solve sparse-reward\nreinforcement learning (RL) tasks has yielded some steady progress in\ntask-complexity through the years. In this work, we question whether today's\nLRFs are best-suited as a direct replacement for task rewards. Instead, we\npropose leveraging the capabilities of LRFs as a pretraining signal for RL.\nConcretely, we propose $\\textbf{LA}$nguage Reward $\\textbf{M}$odulated\n$\\textbf{P}$retraining (LAMP) which leverages the zero-shot capabilities of\nVision-Language Models (VLMs) as a $\\textit{pretraining}$ utility for RL as\nopposed to a downstream task reward. LAMP uses a frozen, pretrained VLM to\nscalably generate noisy, albeit shaped exploration rewards by computing the\ncontrastive alignment between a highly diverse collection of language\ninstructions and the image observations of an agent in its pretraining\nenvironment. LAMP optimizes these rewards in conjunction with standard\nnovelty-seeking exploration rewards with reinforcement learning to acquire a\nlanguage-conditioned, pretrained policy. Our VLM pretraining approach, which is\na departure from previous attempts to use LRFs, can warmstart sample-efficient\nlearning on robot manipulation tasks in RLBench.\n",
                "链接": "https://arxiv.org/abs/2308.12270"
            },
            {
                "文章ID": "39955",
                "标题": "Improving Policy Learning via Language Dynamics Distillation",
                "作者": " Victor Zhong,  Jesse Mu,  Luke Zettlemoyer,  Edward Grefenstette,  Tim Rocktäschel",
                "发布日期": "2022-10-04",
                "摘要": "  Recent work has shown that augmenting environments with language descriptions\nimproves policy learning. However, for environments with complex language\nabstractions, learning how to ground language to observations is difficult due\nto sparse, delayed rewards. We propose Language Dynamics Distillation (LDD),\nwhich pretrains a model to predict environment dynamics given demonstrations\nwith language descriptions, and then fine-tunes these language-aware pretrained\nrepresentations via reinforcement learning (RL). In this way, the model is\ntrained to both maximize expected reward and retain knowledge about how\nlanguage relates to environment dynamics. On SILG, a benchmark of five tasks\nwith language descriptions that evaluate distinct generalization challenges on\nunseen environments (NetHack, ALFWorld, RTFM, Messenger, and Touchdown), LDD\noutperforms tabula-rasa RL, VAE pretraining, and methods that learn from\nunlabeled demonstrations in inverse RL and reward shaping with pretrained\nexperts. In our analyses, we show that language descriptions in demonstrations\nimprove sample-efficiency and generalization across environments, and that\ndynamics modelling with expert demonstrations is more effective than with\nnon-experts.\n",
                "链接": "https://arxiv.org/abs/2210.00066"
            },
            {
                "文章ID": "105659",
                "标题": "Tool-Augmented Reward Modeling",
                "作者": " Lei Li,  Yekun Chai,  Shuohuan Wang,  Yu Sun,  Hao Tian,  Ningyu Zhang,  Hua Wu",
                "发布日期": "2023-10-03",
                "摘要": "  Reward modeling (a.k.a., preference modeling) is instrumental for aligning\nlarge language models with human preferences, particularly within the context\nof reinforcement learning from human feedback (RLHF). While conventional reward\nmodels (RMs) have exhibited remarkable scalability, they oft struggle with\nfundamental functionality such as arithmetic computation, code execution, and\nfactual lookup. In this paper, we propose a tool-augmented preference modeling\napproach, named \\name, to address these limitations by empowering RMs with\naccess to external environments, including calculators and search engines. This\napproach not only fosters synergy between tool utilization and reward grading\nbut also enhances interpretive capacity and scoring reliability. Our study\ndelves into the integration of external tools into RMs, enabling them to\ninteract with diverse external sources and construct task-specific tool\nengagement and reasoning traces in an autoregressive manner. We validate our\napproach across a wide range of domains, incorporating seven distinct external\ntools. Our experimental results demonstrate a noteworthy overall improvement of\n17.7% across eight tasks in preference ranking. Furthermore, our approach\noutperforms Gopher 280B by 7.3% on TruthfulQA task in zero-shot evaluation. In\nhuman evaluations, RLHF trained with Themis attains an average win rate of 32%\nwhen compared to baselines across four distinct tasks. Additionally, we provide\na comprehensive collection of tool-related RM datasets, incorporating data from\nseven distinct tool APIs, totaling 15,000 instances. We anticipate that this\npublicly available dataset will facilitate and inspire further research\nadvancements in the field.\n",
                "链接": "https://arxiv.org/abs/2310.01045"
            },
            {
                "文章ID": "79955",
                "标题": "Video Prediction Models as Rewards for Reinforcement Learning",
                "作者": " Alejandro Escontrela,  Ademi Adeniji,  Wilson Yan,  Ajay Jain,  Xue Bin Peng,  Ken Goldberg,  Youngwoon Lee,  Danijar Hafner,  Pieter Abbeel",
                "发布日期": "2023-05-31",
                "摘要": "  Specifying reward signals that allow agents to learn complex behaviors is a\nlong-standing challenge in reinforcement learning. A promising approach is to\nextract preferences for behaviors from unlabeled videos, which are widely\navailable on the internet. We present Video Prediction Rewards (VIPER), an\nalgorithm that leverages pretrained video prediction models as action-free\nreward signals for reinforcement learning. Specifically, we first train an\nautoregressive transformer on expert videos and then use the video prediction\nlikelihoods as reward signals for a reinforcement learning agent. VIPER enables\nexpert-level control without programmatic task rewards across a wide range of\nDMC, Atari, and RLBench tasks. Moreover, generalization of the video prediction\nmodel allows us to derive rewards for an out-of-distribution environment where\nno expert data is available, enabling cross-embodiment generalization for\ntabletop manipulation. We see our work as starting point for scalable reward\nspecification from unlabeled videos that will benefit from the rapid advances\nin generative modeling. Source code and datasets are available on the project\nwebsite: https://escontrela.me/viper\n",
                "链接": "https://arxiv.org/abs/2305.14343"
            },
            {
                "文章ID": "122681",
                "标题": "Helping or Herding? Reward Model Ensembles Mitigate but do not Eliminate\n  Reward Hacking",
                "作者": " Jacob Eisenstein,  Chirag Nagpal,  Alekh Agarwal,  Ahmad Beirami,  Alex D'Amour,  DJ Dvijotham,  Adam Fisch,  Katherine Heller,  Stephen Pfohl,  Deepak Ramachandran,  Peter Shaw,  Jonathan Berant",
                "发布日期": "2023-12-22",
                "摘要": "  Reward models play a key role in aligning language model applications towards\nhuman preferences. However, this setup creates an incentive for the language\nmodel to exploit errors in the reward model to achieve high estimated reward, a\nphenomenon often termed \\emph{reward hacking}. A natural mitigation is to train\nan ensemble of reward models, aggregating over model outputs to obtain a more\nrobust reward estimate. We explore the application of reward ensembles to\nalignment at both training time (through reinforcement learning) and inference\ntime (through reranking). First, we show that reward models are\n\\emph{underspecified}: reward models that perform similarly in-distribution can\nyield very different rewards when used in alignment, due to distribution shift.\nSecond, underspecification results in overoptimization, where alignment to one\nreward model does not improve reward as measured by another reward model\ntrained on the same data. Third, overoptimization is mitigated by the use of\nreward ensembles, and ensembles that vary by their \\emph{pretraining} seeds\nlead to better generalization than ensembles that differ only by their\n\\emph{fine-tuning} seeds, with both outperforming individual reward models.\nHowever, even pretrain reward ensembles do not eliminate reward hacking: we\nshow several qualitative reward hacking phenomena that are not mitigated by\nensembling because all reward models in the ensemble exhibit similar error\npatterns.\n",
                "链接": "https://arxiv.org/abs/2312.09244"
            },
            {
                "文章ID": "21453",
                "标题": "Quark: Controllable Text Generation with Reinforced Unlearning",
                "作者": " Ximing Lu,  Sean Welleck,  Jack Hessel,  Liwei Jiang,  Lianhui Qin,  Peter West,  Prithviraj Ammanabrolu,  Yejin Choi",
                "发布日期": "2022-11-18",
                "摘要": "  Large-scale language models often learn behaviors that are misaligned with\nuser expectations. Generated text may contain offensive or toxic language,\ncontain significant repetition, or be of a different sentiment than desired by\nthe user. We consider the task of unlearning these misalignments by fine-tuning\nthe language model on signals of what not to do. We introduce Quantized Reward\nKonditioning (Quark), an algorithm for optimizing a reward function that\nquantifies an (un)wanted property, while not straying too far from the original\nmodel. Quark alternates between (i) collecting samples with the current\nlanguage model, (ii) sorting them into quantiles based on reward, with each\nquantile identified by a reward token prepended to the language model's input,\nand (iii) using a standard language modeling loss on samples from each quantile\nconditioned on its reward token, while remaining nearby the original language\nmodel via a KL-divergence penalty. By conditioning on a high-reward token at\ngeneration time, the model generates text that exhibits less of the unwanted\nproperty. For unlearning toxicity, negative sentiment, and repetition, our\nexperiments show that Quark outperforms both strong baselines and\nstate-of-the-art reinforcement learning methods like PPO (Schulman et al.\n2017), while relying only on standard language modeling primitives.\n",
                "链接": "https://arxiv.org/abs/2205.13636"
            }
        ]
    },
    {
        "question": {
            "question": "利用大模型做数学题生成的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "84264",
                "标题": "World Models for Math Story Problems",
                "作者": " Andreas Opedal,  Niklas Stoehr,  Abulhair Saparov,  Mrinmaya Sachan",
                "发布日期": "2023-06-08",
                "摘要": "  Solving math story problems is a complex task for students and NLP models\nalike, requiring them to understand the world as described in the story and\nreason over it to compute an answer. Recent years have seen impressive\nperformance on automatically solving these problems with large pre-trained\nlanguage models and innovative techniques to prompt them. However, it remains\nunclear if these models possess accurate representations of mathematical\nconcepts. This leads to lack of interpretability and trustworthiness which\nimpedes their usefulness in various applications. In this paper, we consolidate\nprevious work on categorizing and representing math story problems and develop\nMathWorld, which is a graph-based semantic formalism specific for the domain of\nmath story problems. With MathWorld, we can assign world models to math story\nproblems which represent the situations and actions introduced in the text and\ntheir mathematical relationships. We combine math story problems from several\nexisting datasets and annotate a corpus of 1,019 problems and 3,204 logical\nforms with MathWorld. Using this data, we demonstrate the following use cases\nof MathWorld: (1) prompting language models with synthetically generated\nquestion-answer pairs to probe their reasoning and world modeling abilities,\nand (2) generating new problems by using the world models as a design space.\n",
                "链接": "https://arxiv.org/abs/2306.04347"
            },
            {
                "文章ID": "108984",
                "标题": "Improving Large Language Model Fine-tuning for Solving Math Problems",
                "作者": " Yixin Liu,  Avi Singh,  C. Daniel Freeman,  John D. Co-Reyes,  Peter J. Liu",
                "发布日期": "2023-10-17",
                "摘要": "  Despite their success in many natural language tasks, solving math problems\nremains a significant challenge for large language models (LLMs). A large gap\nexists between LLMs' pass-at-one and pass-at-N performance in solving math\nproblems, suggesting LLMs might be close to finding correct solutions,\nmotivating our exploration of fine-tuning methods to unlock LLMs' performance.\nUsing the challenging MATH dataset, we investigate three fine-tuning\nstrategies: (1) solution fine-tuning, where we fine-tune to generate a detailed\nsolution for a given math problem; (2) solution-cluster re-ranking, where the\nLLM is fine-tuned as a solution verifier/evaluator to choose among generated\ncandidate solution clusters; (3) multi-task sequential fine-tuning, which\nintegrates both solution generation and evaluation tasks together efficiently\nto enhance the LLM performance. With these methods, we present a thorough\nempirical study on a series of PaLM 2 models and find: (1) The quality and\nstyle of the step-by-step solutions used for fine-tuning can make a significant\nimpact on the model performance; (2) While solution re-ranking and majority\nvoting are both effective for improving the model performance when used\nseparately, they can also be used together for an even greater performance\nboost; (3) Multi-task fine-tuning that sequentially separates the solution\ngeneration and evaluation tasks can offer improved performance compared with\nthe solution fine-tuning baseline. Guided by these insights, we design a\nfine-tuning recipe that yields approximately 58.8% accuracy on the MATH dataset\nwith fine-tuned PaLM 2-L models, an 11.2% accuracy improvement over the\nfew-shot performance of pre-trained PaLM 2-L model with majority voting.\n",
                "链接": "https://arxiv.org/abs/2310.10047"
            },
            {
                "文章ID": "72994",
                "标题": "Solving Math Word Problems by Combining Language Models With Symbolic\n  Solvers",
                "作者": " Joy He-Yueya,  Gabriel Poesia,  Rose E. Wang,  Noah D. Goodman",
                "发布日期": "2023-04-19",
                "摘要": "  Automatically generating high-quality step-by-step solutions to math word\nproblems has many applications in education. Recently, combining large language\nmodels (LLMs) with external tools to perform complex reasoning and calculation\nhas emerged as a promising direction for solving math word problems, but prior\napproaches such as Program-Aided Language model (PAL) are biased towards simple\nprocedural problems and less effective for problems that require declarative\nreasoning. We propose an approach that combines an LLM that can incrementally\nformalize word problems as a set of variables and equations with an external\nsymbolic solver that can solve the equations. Our approach achieves comparable\naccuracy to the original PAL on the GSM8K benchmark of math word problems and\noutperforms PAL by an absolute 20% on ALGEBRA, a new dataset of more\nchallenging word problems extracted from Algebra textbooks. Our work highlights\nthe benefits of using declarative and incremental representations when\ninterfacing with an external tool for solving complex math word problems. Our\ndata and prompts are publicly available at\nhttps://github.com/joyheyueya/declarative-math-word-problem.\n",
                "链接": "https://arxiv.org/abs/2304.09102"
            },
            {
                "文章ID": "94507",
                "标题": "Reasoning in Large Language Models Through Symbolic Math Word Problems",
                "作者": " Vedant Gaur,  Nikunj Saunshi",
                "发布日期": "2023-08-04",
                "摘要": "  Large language models (LLMs) have revolutionized NLP by solving downstream\ntasks with little to no labeled data. Despite their versatile abilities, the\nlarger question of their ability to reason remains ill-understood. This paper\naddresses reasoning in math word problems (MWPs) by studying symbolic versions\nof the numeric problems, since a symbolic expression is a \"concise explanation\"\nof the numeric answer. We create and use a symbolic version of the SVAMP\ndataset and find that GPT-3's davinci-002 model also has good zero-shot\naccuracy on symbolic MWPs. To evaluate the faithfulness of the model's\nreasoning, we go beyond accuracy and additionally evaluate the alignment\nbetween the final answer and the outputted reasoning, which correspond to\nnumeric and symbolic answers respectively for MWPs. We explore a self-prompting\napproach to encourage the symbolic reasoning to align with the numeric answer,\nthus equipping the LLM with the ability to provide a concise and verifiable\nreasoning and making it more interpretable. Surprisingly, self-prompting also\nimproves the symbolic accuracy to be higher than both the numeric and symbolic\naccuracies, thus providing an ensembling effect. The SVAMP_Sym dataset will be\nreleased for future research on symbolic math problems.\n",
                "链接": "https://arxiv.org/abs/2308.01906"
            },
            {
                "文章ID": "50031",
                "标题": "Automatic Generation of Socratic Subquestions for Teaching Math Word\n  Problems",
                "作者": " Kumar Shridhar,  Jakub Macina,  Mennatallah El-Assady,  Tanmay Sinha,  Manu Kapur,  Mrinmaya Sachan",
                "发布日期": "2022-11-24",
                "摘要": "  Socratic questioning is an educational method that allows students to\ndiscover answers to complex problems by asking them a series of thoughtful\nquestions. Generation of didactically sound questions is challenging, requiring\nunderstanding of the reasoning process involved in the problem. We hypothesize\nthat such questioning strategy can not only enhance the human performance, but\nalso assist the math word problem (MWP) solvers. In this work, we explore the\nability of large language models (LMs) in generating sequential questions for\nguiding math word problem-solving. We propose various guided question\ngeneration schemes based on input conditioning and reinforcement learning. On\nboth automatic and human quality evaluations, we find that LMs constrained with\ndesirable question properties generate superior questions and improve the\noverall performance of a math word problem solver. We conduct a preliminary\nuser study to examine the potential value of such question generation models in\nthe education domain. Results suggest that the difficulty level of problems\nplays an important role in determining whether questioning improves or hinders\nhuman performance. We discuss the future of using such questioning strategies\nin education.\n",
                "链接": "https://arxiv.org/abs/2211.12835"
            },
            {
                "文章ID": "91485",
                "标题": "A mixed policy to improve performance of language models on math\n  problems",
                "作者": " Gang Chen",
                "发布日期": "2023-07-19",
                "摘要": "  When to solve math problems, most language models take a sampling strategy to\npredict next word according conditional probabilities. In the math reasoning\nstep, it may generate wrong answer. Considering math problems are\ndeterministic, we propose a mixed policy exploration approach to solve math\nproblems with reinforcement learning. In peculiar, we propose a two level token\nexploration policy: the abstract level explores next token with probability and\nthe second level is deterministic. Specifically, the abstract level policy will\ndecide whether the token is operator or operand with probability sampling,\nwhile the second level is deterministic to select next token with the highest\nscore in a greedy way. We test our method on GSM8K dataset with GPT-2 model,\nand demonstrate more than $2\\%$ performance gain. Our implementation is\navailable at https://github.com/vividitytech/math_lm_rl.\n",
                "链接": "https://arxiv.org/abs/2307.08767"
            },
            {
                "文章ID": "100220",
                "标题": "MathAttack: Attacking Large Language Models Towards Math Solving Ability",
                "作者": " Zihao Zhou,  Qiufeng Wang,  Mingyu Jin,  Jie Yao,  Jianan Ye,  Wei Liu,  Wei Wang,  Xiaowei Huang,  Kaizhu Huang",
                "发布日期": "2023-09-06",
                "摘要": "  With the boom of Large Language Models (LLMs), the research of solving Math\nWord Problem (MWP) has recently made great progress. However, there are few\nstudies to examine the security of LLMs in math solving ability. Instead of\nattacking prompts in the use of LLMs, we propose a MathAttack model to attack\nMWP samples which are closer to the essence of security in solving math\nproblems. Compared to traditional text adversarial attack, it is essential to\npreserve the mathematical logic of original MWPs during the attacking. To this\nend, we propose logical entity recognition to identify logical entries which\nare then frozen. Subsequently, the remaining text are attacked by adopting a\nword-level attacker. Furthermore, we propose a new dataset RobustMath to\nevaluate the robustness of LLMs in math solving ability. Extensive experiments\non our RobustMath and two another math benchmark datasets GSM8K and MultiAirth\nshow that MathAttack could effectively attack the math solving ability of LLMs.\nIn the experiments, we observe that (1) Our adversarial samples from\nhigher-accuracy LLMs are also effective for attacking LLMs with lower accuracy\n(e.g., transfer from larger to smaller-size LLMs, or from few-shot to zero-shot\nprompts); (2) Complex MWPs (such as more solving steps, longer text, more\nnumbers) are more vulnerable to attack; (3) We can improve the robustness of\nLLMs by using our adversarial samples in few-shot prompts. Finally, we hope our\npractice and observation can serve as an important attempt towards enhancing\nthe robustness of LLMs in math solving ability. We will release our code and\ndataset.\n",
                "链接": "https://arxiv.org/abs/2309.01686"
            },
            {
                "文章ID": "109235",
                "标题": "LLMs as Potential Brainstorming Partners for Math and Science Problems",
                "作者": " Sophia Gu",
                "发布日期": "2023-10-18",
                "摘要": "  With the recent rise of widely successful deep learning models, there is\nemerging interest among professionals in various math and science communities\nto see and evaluate the state-of-the-art models' abilities to collaborate on\nfinding or solving problems that often require creativity and thus\nbrainstorming. While a significant chasm still exists between current\nhuman-machine intellectual collaborations and the resolution of complex math\nand science problems, such as the six unsolved Millennium Prize Problems, our\ninitial investigation into this matter reveals a promising step towards\nbridging the divide. This is due to the recent advancements in Large Language\nModels (LLMs). More specifically, we conduct comprehensive case studies to\nexplore both the capabilities and limitations of the current state-of-the-art\nLLM, notably GPT-4, in collective brainstorming with humans.\n",
                "链接": "https://arxiv.org/abs/2310.10677"
            },
            {
                "文章ID": "34215",
                "标题": "Automatic tagging of knowledge points for K12 math problems",
                "作者": " Xiaolu Wang,  Ziqi Ding,  Liangyu Chen",
                "发布日期": "2022-08-23",
                "摘要": "  Automatic tagging of knowledge points for practice problems is the basis for\nmanaging question bases and improving the automation and intelligence of\neducation. Therefore, it is of great practical significance to study the\nautomatic tagging technology for practice problems. However, there are few\nstudies on the automatic tagging of knowledge points for math problems. Math\ntexts have more complex structures and semantics compared with general texts\nbecause they contain unique elements such as symbols and formulas. Therefore,\nit is difficult to meet the accuracy requirement of knowledge point prediction\nby directly applying the text classification techniques in general domains. In\nthis paper, K12 math problems taken as the research object, the LABS model\nbased on label-semantic attention and multi-label smoothing combining textual\nfeatures is proposed to improve the automatic tagging of knowledge points for\nmath problems. The model combines the text classification techniques in general\ndomains and the unique features of math texts. The results show that the models\nusing label-semantic attention or multi-label smoothing perform better on\nprecision, recall, and F1-score metrics than the traditional BiLSTM model,\nwhile the LABS model using both performs best. It can be seen that label\ninformation can guide the neural networks to extract meaningful information\nfrom the problem text, which improves the text classification performance of\nthe model. Moreover, multi-label smoothing combining textual features can fully\nexplore the relationship between text and labels, improve the model's\nprediction ability for new data and improve the model's classification\naccuracy.\n",
                "链接": "https://arxiv.org/abs/2208.09867"
            },
            {
                "文章ID": "45426",
                "标题": "Self-consistent Reasoning For Solving Math Word Problems",
                "作者": " Jing Xiong,  Zhongwei Wan,  Xiping Hu,  Min Yang,  Chengming Li",
                "发布日期": "2022-10-28",
                "摘要": "  Math word problems (MWPs) is a task that automatically derives solution\nexpression from a giving math problems in text. The previous studies suffer\nfrom spurious correlations between input text and output expression. To\nmitigate this issue, we propose a self-consistent reasoning framework called\nSCR, which attempts to adopt a pruning strategy to correct the output\ndistribution shift so as to implicitly fix those spurious correlative samples.\nSpecifically, we firstly obtain a sub-network by pruning a roberta2tree model,\nfor the sake to use the gap on output distribution between the original\nroberta2tree model and the pruned sub-network to expose spurious correlative\nsamples. Then, we calibrate the output distribution shift by applying symmetric\nKullback-Leibler divergence to alleviate spurious correlations. In addition,\nSCR generates equivalent expressions, thereby, capturing the original text's\nlogic rather than relying on hints from original text. Extensive experiments on\ntwo large-scale benchmarks demonstrate that our model substantially outperforms\nthe strong baseline methods.\n",
                "链接": "https://arxiv.org/abs/2210.15373"
            }
        ]
    },
    {
        "question": {
            "question": "帮我找一下用大模型进行论文查找的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "79916",
                "标题": "Query Rewriting for Retrieval-Augmented Large Language Models",
                "作者": " Xinbei Ma,  Yeyun Gong,  Pengcheng He,  Hai Zhao,  Nan Duan",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) play powerful, black-box readers in the\nretrieve-then-read pipeline, making remarkable progress in knowledge-intensive\ntasks. This work introduces a new framework, Rewrite-Retrieve-Read instead of\nthe previous retrieve-then-read for the retrieval-augmented LLMs from the\nperspective of the query rewriting. Unlike prior studies focusing on adapting\neither the retriever or the reader, our approach pays attention to the\nadaptation of the search query itself, for there is inevitably a gap between\nthe input text and the needed knowledge in retrieval. We first prompt an LLM to\ngenerate the query, then use a web search engine to retrieve contexts.\nFurthermore, to better align the query to the frozen modules, we propose a\ntrainable scheme for our pipeline. A small language model is adopted as a\ntrainable rewriter to cater to the black-box LLM reader. The rewriter is\ntrained using the feedback of the LLM reader by reinforcement learning.\nEvaluation is conducted on downstream tasks, open-domain QA and multiple-choice\nQA. Experiments results show consistent performance improvement, indicating\nthat our framework is proven effective and scalable, and brings a new framework\nfor retrieval-augmented LLM.\n",
                "链接": "https://arxiv.org/abs/2305.14283"
            },
            {
                "文章ID": "370",
                "标题": "PARM: A Paragraph Aggregation Retrieval Model for Dense\n  Document-to-Document Retrieval",
                "作者": " Sophia Althammer,  Sebastian Hofstätter,  Mete Sertkan,  Suzan Verberne,  Allan Hanbury",
                "发布日期": "2022-08-16",
                "摘要": "  Dense passage retrieval (DPR) models show great effectiveness gains in first\nstage retrieval for the web domain. However in the web domain we are in a\nsetting with large amounts of training data and a query-to-passage or a\nquery-to-document retrieval task. We investigate in this paper dense\ndocument-to-document retrieval with limited labelled target data for training,\nin particular legal case retrieval. In order to use DPR models for\ndocument-to-document retrieval, we propose a Paragraph Aggregation Retrieval\nModel (PARM) which liberates DPR models from their limited input length. PARM\nretrieves documents on the paragraph-level: for each query paragraph, relevant\ndocuments are retrieved based on their paragraphs. Then the relevant results\nper query paragraph are aggregated into one ranked list for the whole query\ndocument. For the aggregation we propose vector-based aggregation with\nreciprocal rank fusion (VRRF) weighting, which combines the advantages of\nrank-based aggregation and topical aggregation based on the dense embeddings.\nExperimental results show that VRRF outperforms rank-based aggregation\nstrategies for dense document-to-document retrieval with PARM. We compare PARM\nto document-level retrieval and demonstrate higher retrieval effectiveness of\nPARM for lexical and dense first-stage retrieval on two different legal case\nretrieval collections. We investigate how to train the dense retrieval model\nfor PARM on limited target data with labels on the paragraph or the\ndocument-level. In addition, we analyze the differences of the retrieved\nresults of lexical and dense retrieval with PARM.\n",
                "链接": "https://arxiv.org/abs/2201.01614"
            },
            {
                "文章ID": "78767",
                "标题": "Inference-time Re-ranker Relevance Feedback for Neural Information\n  Retrieval",
                "作者": " Revanth Gangi Reddy,  Pradeep Dasigi,  Md Arafat Sultan,  Arman Cohan,  Avirup Sil,  Heng Ji,  Hannaneh Hajishirzi",
                "发布日期": "2023-05-22",
                "摘要": "  Neural information retrieval often adopts a retrieve-and-rerank framework: a\nbi-encoder network first retrieves K (e.g., 100) candidates that are then\nre-ranked using a more powerful cross-encoder model to rank the better\ncandidates higher. The re-ranker generally produces better candidate scores\nthan the retriever, but is limited to seeing only the top K retrieved\ncandidates, thus providing no improvements in retrieval performance as measured\nby Recall@K. In this work, we leverage the re-ranker to also improve retrieval\nby providing inference-time relevance feedback to the retriever. Concretely, we\nupdate the retriever's query representation for a test instance using a\nlightweight inference-time distillation of the re-ranker's prediction for that\ninstance. The distillation loss is designed to bring the retriever's candidate\nscores closer to those of the re-ranker. A second retrieval step is then\nperformed with the updated query vector. We empirically show that our approach,\nwhich can serve arbitrary retrieve-and-rerank pipelines, significantly improves\nretrieval recall in multiple domains, languages, and modalities.\n",
                "链接": "https://arxiv.org/abs/2305.11744"
            },
            {
                "文章ID": "43577",
                "标题": "Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual\n  Question Answering",
                "作者": " Jialin Wu,  Raymond J. Mooney",
                "发布日期": "2022-10-24",
                "摘要": "  Most Outside-Knowledge Visual Question Answering (OK-VQA) systems employ a\ntwo-stage framework that first retrieves external knowledge given the visual\nquestion and then predicts the answer based on the retrieved content. However,\nthe retrieved knowledge is often inadequate. Retrievals are frequently too\ngeneral and fail to cover specific knowledge needed to answer the question.\nAlso, the naturally available supervision (whether the passage contains the\ncorrect answer) is weak and does not guarantee question relevancy. To address\nthese issues, we propose an Entity-Focused Retrieval (EnFoRe) model that\nprovides stronger supervision during training and recognizes question-relevant\nentities to help retrieve more specific knowledge. Experiments show that our\nEnFoRe model achieves superior retrieval performance on OK-VQA, the currently\nlargest outside-knowledge VQA dataset. We also combine the retrieved knowledge\nwith state-of-the-art VQA models, and achieve a new state-of-the-art\nperformance on OK-VQA.\n",
                "链接": "https://arxiv.org/abs/2210.10176"
            },
            {
                "文章ID": "80481",
                "标题": "Enhancing Retrieval-Augmented Large Language Models with Iterative\n  Retrieval-Generation Synergy",
                "作者": " Zhihong Shao,  Yeyun Gong,  Yelong Shen,  Minlie Huang,  Nan Duan,  Weizhu Chen",
                "发布日期": "2023-10-24",
                "摘要": "  Large language models are powerful text processors and reasoners, but are\nstill subject to limitations including outdated knowledge and hallucinations,\nwhich necessitates connecting them to the world. Retrieval-augmented large\nlanguage models have raised extensive attention for grounding model generation\non external knowledge. However, retrievers struggle to capture relevance,\nespecially for queries with complex information needs. Recent work has proposed\nto improve relevance modeling by having large language models actively involved\nin retrieval, i.e., to improve retrieval with generation. In this paper, we\nshow that strong performance can be achieved by a method we call Iter-RetGen,\nwhich synergizes retrieval and generation in an iterative manner. A model\noutput shows what might be needed to finish a task, and thus provides an\ninformative context for retrieving more relevant knowledge which in turn helps\ngenerate a better output in the next iteration. Compared with recent work which\ninterleaves retrieval with generation when producing an output, Iter-RetGen\nprocesses all retrieved knowledge as a whole and largely preserves the\nflexibility in generation without structural constraints. We evaluate\nIter-RetGen on multi-hop question answering, fact verification, and commonsense\nreasoning, and show that it can flexibly leverage parametric knowledge and\nnon-parametric knowledge, and is superior to or competitive with\nstate-of-the-art retrieval-augmented baselines while causing fewer overheads of\nretrieval and generation. We can further improve performance via\ngeneration-augmented retrieval adaptation.\n",
                "链接": "https://arxiv.org/abs/2305.15294"
            },
            {
                "文章ID": "111390",
                "标题": "1-PAGER: One Pass Answer Generation and Evidence Retrieval",
                "作者": " Palak Jain,  Livio Baldini Soares,  Tom Kwiatkowski",
                "发布日期": "2023-10-26",
                "摘要": "  We present 1-Pager the first system that answers a question and retrieves\nevidence using a single Transformer-based model and decoding process. 1-Pager\nincrementally partitions the retrieval corpus using constrained decoding to\nselect a document and answer string, and we show that this is competitive with\ncomparable retrieve-and-read alternatives according to both retrieval and\nanswer accuracy metrics. 1-Pager also outperforms the equivalent closed-book\nquestion answering model, by grounding predictions in an evidence corpus. While\n1-Pager is not yet on-par with more expensive systems that read many more\ndocuments before generating an answer, we argue that it provides an important\nstep toward attributed generation by folding retrieval into the\nsequence-to-sequence paradigm that is currently dominant in NLP. We also show\nthat the search paths used to partition the corpus are easy to read and\nunderstand, paving a way forward for interpretable neural retrieval.\n",
                "链接": "https://arxiv.org/abs/2310.16568"
            },
            {
                "文章ID": "35286",
                "标题": "LED: Lexicon-Enlightened Dense Retriever for Large-Scale Retrieval",
                "作者": " Kai Zhang,  Chongyang Tao,  Tao Shen,  Can Xu,  Xiubo Geng,  Binxing Jiao,  Daxin Jiang",
                "发布日期": "2023-03-06",
                "摘要": "  Retrieval models based on dense representations in semantic space have become\nan indispensable branch for first-stage retrieval. These retrievers benefit\nfrom surging advances in representation learning towards compressive global\nsequence-level embeddings. However, they are prone to overlook local salient\nphrases and entity mentions in texts, which usually play pivot roles in\nfirst-stage retrieval. To mitigate this weakness, we propose to make a dense\nretriever align a well-performing lexicon-aware representation model. The\nalignment is achieved by weakened knowledge distillations to enlighten the\nretriever via two aspects -- 1) a lexicon-augmented contrastive objective to\nchallenge the dense encoder and 2) a pair-wise rank-consistent regularization\nto make dense model's behavior incline to the other. We evaluate our model on\nthree public benchmarks, which shows that with a comparable lexicon-aware\nretriever as the teacher, our proposed dense one can bring consistent and\nsignificant improvements, and even outdo its teacher. In addition, we found our\nimprovement on the dense retriever is complementary to the standard ranker\ndistillation, which can further lift state-of-the-art performance.\n",
                "链接": "https://arxiv.org/abs/2208.13661"
            },
            {
                "文章ID": "105149",
                "标题": "Fine-grained Late-interaction Multi-modal Retrieval for Retrieval\n  Augmented Visual Question Answering",
                "作者": " Weizhe Lin,  Jinghong Chen,  Jingbiao Mei,  Alexandru Coca,  Bill Byrne",
                "发布日期": "2023-10-31",
                "摘要": "  Knowledge-based Visual Question Answering (KB-VQA) requires VQA systems to\nutilize knowledge from external knowledge bases to answer visually-grounded\nquestions. Retrieval-Augmented Visual Question Answering (RA-VQA), a strong\nframework to tackle KB-VQA, first retrieves related documents with Dense\nPassage Retrieval (DPR) and then uses them to answer questions. This paper\nproposes Fine-grained Late-interaction Multi-modal Retrieval (FLMR) which\nsignificantly improves knowledge retrieval in RA-VQA. FLMR addresses two major\nlimitations in RA-VQA's retriever: (1) the image representations obtained via\nimage-to-text transforms can be incomplete and inaccurate and (2) relevance\nscores between queries and documents are computed with one-dimensional\nembeddings, which can be insensitive to finer-grained relevance. FLMR overcomes\nthese limitations by obtaining image representations that complement those from\nthe image-to-text transforms using a vision model aligned with an existing\ntext-based retriever through a simple alignment network. FLMR also encodes\nimages and questions using multi-dimensional embeddings to capture\nfiner-grained relevance between queries and documents. FLMR significantly\nimproves the original RA-VQA retriever's PRRecall@5 by approximately 8\\%.\nFinally, we equipped RA-VQA with two state-of-the-art large\nmulti-modal/language models to achieve $\\sim61\\%$ VQA score in the OK-VQA\ndataset.\n",
                "链接": "https://arxiv.org/abs/2309.17133"
            },
            {
                "文章ID": "61114",
                "标题": "Characterizing Attribution and Fluency Tradeoffs for Retrieval-Augmented\n  Large Language Models",
                "作者": " Renat Aksitov,  Chung-Ching Chang,  David Reitter,  Siamak Shakeri,  Yunhsuan Sung",
                "发布日期": "2023-02-16",
                "摘要": "  Despite recent progress, it has been difficult to prevent semantic\nhallucinations in generative Large Language Models. One common solution to this\nis augmenting LLMs with a retrieval system and making sure that the generated\noutput is attributable to the retrieved information. Given this new added\nconstraint, it is plausible to expect that the overall quality of the output\nwill be affected, for example, in terms of fluency. Can scaling language models\nhelp?\n  Here we examine the relationship between fluency and attribution in LLMs\nprompted with retrieved evidence in knowledge-heavy dialog settings. Our\nexperiments were implemented with a set of auto-metrics that are aligned with\nhuman preferences. They were used to evaluate a large set of generations,\nproduced under varying parameters of LLMs and supplied context.\n  We show that larger models tend to do much better in both fluency and\nattribution, and that (naively) using top-k retrieval versus top-1 retrieval\nimproves attribution but hurts fluency. We next propose a recipe that could\nallow smaller models to both close the gap with larger models and preserve the\nbenefits of top-k retrieval while avoiding its drawbacks.\n",
                "链接": "https://arxiv.org/abs/2302.05578"
            },
            {
                "文章ID": "115504",
                "标题": "LLatrieval: LLM-Verified Retrieval for Verifiable Generation",
                "作者": " Xiaonan Li,  Changtai Zhu,  Linyang Li,  Zhangyue Yin,  Tianxiang Sun,  Xipeng Qiu",
                "发布日期": "2023-11-15",
                "摘要": "  Verifiable generation aims to let the large language model (LLM) generate\ntext with corresponding supporting documents, which enables the user to\nflexibly verify the answer and makes it more trustworthy. Its evaluation not\nonly measures the correctness of the answer, but also the answer's\nverifiability, i.e., how well the answer is supported by the corresponding\ndocuments. In typical, verifiable generation adopts the retrieval-read\npipeline, which is divided into two stages: 1) retrieve relevant documents of\nthe question. 2) according to the documents, generate the corresponding answer.\nSince the retrieved documents can supplement knowledge for the LLM to generate\nthe answer and serve as evidence, the retrieval stage is essential for the\ncorrectness and verifiability of the answer. However, the widely used\nretrievers become the bottleneck of the entire pipeline and limit the overall\nperformance. They often have fewer parameters than the large language model and\nhave not been proven to scale well to the size of LLMs. Since the LLM passively\nreceives the retrieval result, if the retriever does not correctly find the\nsupporting documents, the LLM can not generate the correct and verifiable\nanswer, which overshadows the LLM's remarkable abilities. In this paper, we\npropose LLatrieval (Large Language Model Verified Retrieval), where the LLM\nupdates the retrieval result until it verifies that the retrieved documents can\nsupport answering the question. Thus, the LLM can iteratively provide feedback\nto retrieval and facilitate the retrieval result to sufficiently support\nverifiable generation. Experimental results show that our method significantly\noutperforms extensive baselines and achieves new state-of-the-art results.\n",
                "链接": "https://arxiv.org/abs/2311.07838"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到，最早提出分布式词表示的论文是哪一篇？",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "16842",
                "标题": "Extremal GloVe: Theoretically Accurate Distributed Word Embedding by\n  Tail Inference",
                "作者": " Hao Wang",
                "发布日期": "2022-04-28",
                "摘要": "  Distributed word embeddings such as Word2Vec and GloVe have been widely\nadopted in industrial context settings. Major technical applications of GloVe\ninclude recommender systems and natural language processing. The fundamental\ntheory behind GloVe relies on the selection of a weighting function in the\nweighted least squres formulation that computes the powered ratio of word\noccurrence count and the maximum word count in the corpus. However, the initial\nformulation of GloVe is not theoretically sound in two aspects, namely the\nselection of the weighting function and its power exponent is ad-hoc. In this\npaper, we utilize the theory of extreme value analysis and propose a\ntheoretically accurate version of GloVe. By reformulating the weighted least\nsquares loss function as the expected loss function and accurately choosing the\npower exponent, we create a theoretically accurate version of GloVe. We\ndemonstrate the competitiveness of our algorithm and show that the initial\nformulation of GloVe with the suggested optimal parameter can be viewed as a\nspecial case of our paradigm.\n",
                "链接": "https://arxiv.org/abs/2204.13009"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下nips 2023 paper list",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "121476",
                "标题": "Proceedings of the 2023 XCSP3 Competition",
                "作者": " Gilles Audemard,  Christophe Lecoutre,  Emmanuel Lonca",
                "发布日期": "2023-12-12",
                "摘要": "  This document represents the proceedings of the 2023 XCSP3 Competition. The\nresults of this competition of constraint solvers were presented at CP'23 (the\n29th International Conference on Principles and Practice of Constraint\nProgramming, held in Toronto, Canada from 27th to 31th August, 2023).\n",
                "链接": "https://arxiv.org/abs/2312.05877"
            },
            {
                "文章ID": "113325",
                "标题": "ACES: Translation Accuracy Challenge Sets at WMT 2023",
                "作者": " Chantal Amrhein,  Nikita Moghe,  Liane Guillou",
                "发布日期": "2023-11-03",
                "摘要": "  We benchmark the performance of segmentlevel metrics submitted to WMT 2023\nusing the ACES Challenge Set (Amrhein et al., 2022). The challenge set consists\nof 36K examples representing challenges from 68 phenomena and covering 146\nlanguage pairs. The phenomena range from simple perturbations at the\nword/character level to more complex errors based on discourse and real-world\nknowledge. For each metric, we provide a detailed profile of performance over a\nrange of error categories as well as an overall ACES-Score for quick\ncomparison. We also measure the incremental performance of the metrics\nsubmitted to both WMT 2023 and 2022. We find that 1) there is no clear winner\namong the metrics submitted to WMT 2023, and 2) performance change between the\n2023 and 2022 versions of the metrics is highly variable. Our recommendations\nare similar to those from WMT 2022. Metric developers should focus on: building\nensembles of metrics from different design families, developing metrics that\npay more attention to the source and rely less on surface-level overlap, and\ncarefully determining the influence of multilingual embeddings on MT\nevaluation.\n",
                "链接": "https://arxiv.org/abs/2311.01153"
            },
            {
                "文章ID": "98264",
                "标题": "UNISOUND System for VoxCeleb Speaker Recognition Challenge 2023",
                "作者": " Yu Zheng,  Yajun Zhang,  Chuanying Niu,  Yibin Zhan,  Yanhua Long,  Dongxing Xu",
                "发布日期": "2023-08-25",
                "摘要": "  This report describes the UNISOUND submission for Track1 and Track2 of\nVoxCeleb Speaker Recognition Challenge 2023 (VoxSRC 2023). We submit the same\nsystem on Track 1 and Track 2, which is trained with only VoxCeleb2-dev.\nLarge-scale ResNet and RepVGG architectures are developed for the challenge. We\npropose a consistency-aware score calibration method, which leverages the\nstability of audio voiceprints in similarity score by a Consistency Measure\nFactor (CMF). CMF brings a huge performance boost in this challenge. Our final\nsystem is a fusion of six models and achieves the first place in Track 1 and\nsecond place in Track 2 of VoxSRC 2023. The minDCF of our submission is 0.0855\nand the EER is 1.5880%.\n",
                "链接": "https://arxiv.org/abs/2308.12526"
            },
            {
                "文章ID": "40312",
                "标题": "SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis",
                "作者": " Jiaxin Pei,  Vítor Silva,  Maarten Bos,  Yozon Liu,  Leonardo Neves,  David Jurgens,  Francesco Barbieri",
                "发布日期": "2023-02-06",
                "摘要": "  We propose MINT, a new Multilingual INTimacy analysis dataset covering 13,372\ntweets in 10 languages including English, French, Spanish, Italian, Portuguese,\nKorean, Dutch, Chinese, Hindi, and Arabic. We benchmarked a list of popular\nmultilingual pre-trained language models. The dataset is released along with\nthe SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis\n(https://sites.google.com/umich.edu/semeval-2023-tweet-intimacy).\n",
                "链接": "https://arxiv.org/abs/2210.01108"
            },
            {
                "文章ID": "82537",
                "标题": "Findings of the VarDial Evaluation Campaign 2023",
                "作者": " Noëmi Aepli,  Çağrı Çöltekin,  Rob Van Der Goot,  Tommi Jauhiainen,  Mourhaf Kazzaz,  Nikola Ljubešić,  Kai North,  Barbara Plank,  Yves Scherrer,  Marcos Zampieri",
                "发布日期": "2023-06-01",
                "摘要": "  This report presents the results of the shared tasks organized as part of the\nVarDial Evaluation Campaign 2023. The campaign is part of the tenth workshop on\nNatural Language Processing (NLP) for Similar Languages, Varieties and Dialects\n(VarDial), co-located with EACL 2023. Three separate shared tasks were included\nthis year: Slot and intent detection for low-resource language varieties\n(SID4LR), Discriminating Between Similar Languages -- True Labels (DSL-TL), and\nDiscriminating Between Similar Languages -- Speech (DSL-S). All three tasks\nwere organized for the first time this year.\n",
                "链接": "https://arxiv.org/abs/2305.20080"
            },
            {
                "文章ID": "111594",
                "标题": "Core Challenge 2023: Solver and Graph Descriptions",
                "作者": " Takehide Soh,  Tomoya Tanjo,  Yoshio Okamoto,  Takehiro Ito",
                "发布日期": "2023-10-30",
                "摘要": "  This paper collects all descriptions of solvers and ISR instances submitted\nto CoRe Challenge 2023.\n",
                "链接": "https://arxiv.org/abs/2310.17136"
            },
            {
                "文章ID": "119609",
                "标题": "Machine Learning for Health symposium 2023 -- Findings track",
                "作者": " Stefan Hegselmann,  Antonio Parziale,  Divya Shanmugam,  Shengpu Tang,  Mercy Nyamewaa Asiedu,  Serina Chang,  Thomas Hartvigsen,  Harvineet Singh",
                "发布日期": "2023-12-18",
                "摘要": "  A collection of the accepted Findings papers that were presented at the 3rd\nMachine Learning for Health symposium (ML4H 2023), which was held on December\n10, 2023, in New Orleans, Louisiana, USA. ML4H 2023 invited high-quality\nsubmissions on relevant problems in a variety of health-related disciplines\nincluding healthcare, biomedicine, and public health. Two submission tracks\nwere offered: the archival Proceedings track, and the non-archival Findings\ntrack. Proceedings were targeted at mature work with strong technical\nsophistication and a high impact to health. The Findings track looked for new\nideas that could spark insightful discussion, serve as valuable resources for\nthe community, or could enable new collaborations. Submissions to the\nProceedings track, if not accepted, were automatically considered for the\nFindings track. All the manuscripts submitted to ML4H Symposium underwent a\ndouble-blind peer-review process.\n",
                "链接": "https://arxiv.org/abs/2312.00655"
            },
            {
                "文章ID": "111229",
                "标题": "WojoodNER 2023: The First Arabic Named Entity Recognition Shared Task",
                "作者": " Mustafa Jarrar,  Muhammad Abdul-Mageed,  Mohammed Khalilia,  Bashar Talafha,  AbdelRahim Elmadany,  Nagham Hamad,  Alaa' Omar",
                "发布日期": "2023-10-26",
                "摘要": "  We present WojoodNER-2023, the first Arabic Named Entity Recognition (NER)\nShared Task. The primary focus of WojoodNER-2023 is on Arabic NER, offering\nnovel NER datasets (i.e., Wojood) and the definition of subtasks designed to\nfacilitate meaningful comparisons between different NER approaches.\nWojoodNER-2023 encompassed two Subtasks: FlatNER and NestedNER. A total of 45\nunique teams registered for this shared task, with 11 of them actively\nparticipating in the test phase. Specifically, 11 teams participated in\nFlatNER, while $8$ teams tackled NestedNER. The winning teams achieved F1\nscores of 91.96 and 93.73 in FlatNER and NestedNER, respectively.\n",
                "链接": "https://arxiv.org/abs/2310.16153"
            },
            {
                "文章ID": "88267",
                "标题": "The 2nd Place Solution for 2023 Waymo Open Sim Agents Challenge",
                "作者": " Cheng Qian,  Di Xiu,  Minghao Tian",
                "发布日期": "2023-06-29",
                "摘要": "  In this technical report, we present the 2nd place solution of 2023 Waymo\nOpen Sim Agents Challenge (WOSAC)[4]. We propose a simple yet effective\nautoregressive method for simulating multi-agent behaviors, which is built upon\na well-known multimodal motion forecasting framework called Motion Transformer\n(MTR)[5] with postprocessing algorithms applied. Our submission named MTR+++\nachieves 0.4697 on the Realism Meta metric in 2023 WOSAC. Besides, a modified\nmodel based on MTR named MTR_E is proposed after the challenge, which has a\nbetter score 0.4911 and is ranked the 3rd on the leaderboard of WOSAC as of\nJune 25, 2023.\n",
                "链接": "https://arxiv.org/abs/2306.15914"
            },
            {
                "文章ID": "95325",
                "标题": "EFaR 2023: Efficient Face Recognition Competition",
                "作者": " Jan Niklas Kolf,  Fadi Boutros,  Jurek Elliesen,  Markus Theuerkauf,  Naser Damer,  Mohamad Alansari,  Oussama Abdul Hay,  Sara Alansari,  Sajid Javed,  Naoufel Werghi,  Klemen Grm,  Vitomir Štruc,  Fernando Alonso-Fernandez,  Kevin Hernandez Diaz,  Josef Bigun,  Anjith George,  Christophe Ecabert,  Hatef Otroshi Shahreza,  Ketan Kotwal,  Sébastien Marcel,  Iurii Medvedev,  Bo Jin,  Diogo Nunes,  Ahmad Hassanpour,  Pankaj Khatiwada,  Aafan Ahmad Toor,  Bian Yang",
                "发布日期": "2023-08-09",
                "摘要": "  This paper presents the summary of the Efficient Face Recognition Competition\n(EFaR) held at the 2023 International Joint Conference on Biometrics (IJCB\n2023). The competition received 17 submissions from 6 different teams. To drive\nfurther development of efficient face recognition models, the submitted\nsolutions are ranked based on a weighted score of the achieved verification\naccuracies on a diverse set of benchmarks, as well as the deployability given\nby the number of floating-point operations and model size. The evaluation of\nsubmissions is extended to bias, cross-quality, and large-scale recognition\nbenchmarks. Overall, the paper gives an overview of the achieved performance\nvalues of the submitted solutions as well as a diverse set of baselines. The\nsubmitted solutions use small, efficient network architectures to reduce the\ncomputational cost, some solutions apply model quantization. An outlook on\npossible techniques that are underrepresented in current solutions is given as\nwell.\n",
                "链接": "https://arxiv.org/abs/2308.04168"
            }
        ]
    },
    {
        "question": {
            "question": "请列出近一年来工业界发表的搜广推工作落地实践的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "闭源大模型用户数据隐私保护研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "52013",
                "标题": "AI-driven Mobile Apps: an Explorative Study",
                "作者": " Yinghua Li,  Xueqi Dang,  Haoye Tian,  Tiezhu Sun,  Zhijie Wang,  Lei Ma,  Jacques Klein,  Tegawende F. Bissyande",
                "发布日期": "2022-12-06",
                "摘要": "  Recent years have witnessed an astonishing explosion in the evolution of\nmobile applications powered by AI technologies. The rapid growth of AI\nframeworks enables the transition of AI technologies to mobile devices,\nsignificantly prompting the adoption of AI apps (i.e., apps that integrate AI\ninto their functions) among smartphone devices. In this paper, we conduct the\nmost extensive empirical study on 56,682 published AI apps from three\nperspectives: dataset characteristics, development issues, and user feedback\nand privacy. To this end, we build an automated AI app identification tool, AI\nDiscriminator, that detects eligible AI apps from 7,259,232 mobile apps. First,\nwe carry out a dataset analysis, where we explore the AndroZoo large repository\nto identify AI apps and their core characteristics. Subsequently, we pinpoint\nkey issues in AI app development (e.g., model protection). Finally, we focus on\nuser reviews and user privacy protection. Our paper provides several notable\nfindings. Some essential ones involve revealing the issue of insufficient model\nprotection by presenting the lack of model encryption, and demonstrating the\nrisk of user privacy data being leaked. We published our large-scale AI app\ndatasets to inspire more future research.\n",
                "链接": "https://arxiv.org/abs/2212.01635"
            },
            {
                "文章ID": "85712",
                "标题": "Protecting User Privacy in Remote Conversational Systems: A\n  Privacy-Preserving framework based on text sanitization",
                "作者": " Zhigang Kan,  Linbo Qiao,  Hao Yu,  Liwen Peng,  Yifu Gao,  Dongsheng Li",
                "发布日期": "2023-06-16",
                "摘要": "  Large Language Models (LLMs) are gaining increasing attention due to their\nexceptional performance across numerous tasks. As a result, the general public\nutilize them as an influential tool for boosting their productivity while\nnatural language processing researchers endeavor to employ them in solving\nexisting or new research problems. Unfortunately, individuals can only access\nsuch powerful AIs through APIs, which ultimately leads to the transmission of\nraw data to the models' providers and increases the possibility of privacy data\nleakage. Current privacy-preserving methods for cloud-deployed language models\naim to protect privacy information in the pre-training dataset or during the\nmodel training phase. However, they do not meet the specific challenges\npresented by the remote access approach of new large-scale language models.\n  This paper introduces a novel task, \"User Privacy Protection for Dialogue\nModels,\" which aims to safeguard sensitive user information from any possible\ndisclosure while conversing with chatbots. We also present an evaluation scheme\nfor this task, which covers evaluation metrics for privacy protection, data\navailability, and resistance to simulation attacks. Moreover, we propose the\nfirst framework for this task, namely privacy protection through text\nsanitization. Before sending the input to remote large models, it filters out\nthe sensitive information, using several rounds of text sanitization based on\nprivacy types that users define. Upon receiving responses from the larger\nmodel, our framework automatically restores privacy to ensure that the\nconversation goes smoothly, without intervention from the privacy filter.\nExperiments based on real-world datasets demonstrate the efficacy of our\nprivacy-preserving approach against eavesdropping from potential attackers.\n",
                "链接": "https://arxiv.org/abs/2306.08223"
            },
            {
                "文章ID": "119126",
                "标题": "Toward the Tradeoffs between Privacy, Fairness and Utility in Federated\n  Learning",
                "作者": " Kangkang Sun,  Xiaojin Zhang,  Xi Lin,  Gaolei Li,  Jing Wang,  Jianhua Li",
                "发布日期": "2023-12-01",
                "摘要": "  Federated Learning (FL) is a novel privacy-protection distributed machine\nlearning paradigm that guarantees user privacy and prevents the risk of data\nleakage due to the advantage of the client's local training. Researchers have\nstruggled to design fair FL systems that ensure fairness of results. However,\nthe interplay between fairness and privacy has been less studied. Increasing\nthe fairness of FL systems can have an impact on user privacy, while an\nincrease in user privacy can affect fairness. In this work, on the client side,\nwe use fairness metrics, such as Demographic Parity (DemP), Equalized Odds\n(EOs), and Disparate Impact (DI), to construct the local fair model. To protect\nthe privacy of the client model, we propose a privacy-protection fairness FL\nmethod. The results show that the accuracy of the fair model with privacy\nincreases because privacy breaks the constraints of the fairness metrics. In\nour experiments, we conclude the relationship between privacy, fairness and\nutility, and there is a tradeoff between these.\n",
                "链接": "https://arxiv.org/abs/2311.18190"
            },
            {
                "文章ID": "36560",
                "标题": "A Framework for Evaluating Privacy-Utility Trade-off in Vertical\n  Federated Learning",
                "作者": " Yan Kang,  Jiahuan Luo,  Yuanqin He,  Xiaojin Zhang,  Lixin Fan,  Qiang Yang",
                "发布日期": "2022-09-12",
                "摘要": "  Federated learning (FL) has emerged as a practical solution to tackle data\nsilo issues without compromising user privacy. One of its variants, vertical\nfederated learning (VFL), has recently gained increasing attention as the VFL\nmatches the enterprises' demands of leveraging more valuable features to build\nbetter machine learning models while preserving user privacy. Current works in\nVFL concentrate on developing a specific protection or attack mechanism for a\nparticular VFL algorithm. In this work, we propose an evaluation framework that\nformulates the privacy-utility evaluation problem. We then use this framework\nas a guide to comprehensively evaluate a broad range of protection mechanisms\nagainst most of the state-of-the-art privacy attacks for three widely-deployed\nVFL algorithms. These evaluations may help FL practitioners select appropriate\nprotection mechanisms given specific requirements. Our evaluation results\ndemonstrate that: the model inversion and most of the label inference attacks\ncan be thwarted by existing protection mechanisms; the model completion (MC)\nattack is difficult to be prevented, which calls for more advanced MC-targeted\nprotection mechanisms. Based on our evaluation results, we offer concrete\nadvice on improving the privacy-preserving capability of VFL systems.\n",
                "链接": "https://arxiv.org/abs/2209.03885"
            },
            {
                "文章ID": "112402",
                "标题": "Building Real-World Meeting Summarization Systems using Large Language\n  Models: A Practical Perspective",
                "作者": " Md Tahmid Rahman Laskar,  Xue-Yong Fu,  Cheng Chen,  Shashi Bhushan TN",
                "发布日期": "2023-11-09",
                "摘要": "  This paper studies how to effectively build meeting summarization systems for\nreal-world usage using large language models (LLMs). For this purpose, we\nconduct an extensive evaluation and comparison of various closed-source and\nopen-source LLMs, namely, GPT-4, GPT- 3.5, PaLM-2, and LLaMA-2. Our findings\nreveal that most closed-source LLMs are generally better in terms of\nperformance. However, much smaller open-source models like LLaMA- 2 (7B and\n13B) could still achieve performance comparable to the large closed-source\nmodels even in zero-shot scenarios. Considering the privacy concerns of\nclosed-source models for only being accessible via API, alongside the high cost\nassociated with using fine-tuned versions of the closed-source models, the\nopensource models that can achieve competitive performance are more\nadvantageous for industrial use. Balancing performance with associated costs\nand privacy concerns, the LLaMA-2-7B model looks more promising for industrial\nusage. In sum, this paper offers practical insights on using LLMs for\nreal-world business meeting summarization, shedding light on the trade-offs\nbetween performance and cost.\n",
                "链接": "https://arxiv.org/abs/2310.19233"
            },
            {
                "文章ID": "84894",
                "标题": "SoK: Analysis of User-Centered Studies Focusing on Healthcare Privacy &\n  Security",
                "作者": " Faiza Tazi,  Archana Nandakumar,  Josiah Dykstra,  Prashanth Rajivan,  Sanchari Das",
                "发布日期": "2023-06-27",
                "摘要": "  Sensitive information is intrinsically tied to interactions in healthcare,\nand its protection is of paramount importance for achieving high-quality\npatient outcomes. Research in healthcare privacy and security is predominantly\nfocused on understanding the factors that increase the susceptibility of users\nto privacy and security breaches. To understand further, we systematically\nreview 26 research papers in this domain to explore the existing user studies\nin healthcare privacy and security. Following the review, we conducted a\ncard-sorting exercise, allowing us to identify 12 themes integral to this\nsubject such as \"Data Sharing,\" \"Risk Awareness,\" and \"Privacy.\" Further to the\nidentification of these themes, we performed an in-depth analysis of the 26\nresearch papers report on the insights into the discourse within the research\ncommunity about healthcare privacy and security, particularly from the user\nperspective.\n",
                "链接": "https://arxiv.org/abs/2306.06033"
            },
            {
                "文章ID": "16263",
                "标题": "MLP-Hash: Protecting Face Templates via Hashing of Randomized\n  Multi-Layer Perceptron",
                "作者": " Hatef Otroshi Shahreza,  Vedrana Krivokuća Hahn,  Sébastien Marcel",
                "发布日期": "2023-09-06",
                "摘要": "  Applications of face recognition systems for authentication purposes are\ngrowing rapidly. Although state-of-the-art (SOTA) face recognition systems have\nhigh recognition accuracy, the features which are extracted for each user and\nare stored in the system's database contain privacy-sensitive information.\nAccordingly, compromising this data would jeopardize users' privacy. In this\npaper, we propose a new cancelable template protection method, dubbed MLP-hash,\nwhich generates protected templates by passing the extracted features through a\nuser-specific randomly-weighted multi-layer perceptron (MLP) and binarizing the\nMLP output. We evaluated the unlinkability, irreversibility, and recognition\naccuracy of our proposed biometric template protection method to fulfill the\nISO/IEC 30136 standard requirements. Our experiments with SOTA face recognition\nsystems on the MOBIO and LFW datasets show that our method has competitive\nperformance with the BioHashing and IoM Hashing (IoM-GRP and IoM-URP) template\nprotection algorithms. We provide an open-source implementation of all the\nexperiments presented in this paper so that other researchers can verify our\nfindings and build upon our work.\n",
                "链接": "https://arxiv.org/abs/2204.11054"
            },
            {
                "文章ID": "76087",
                "标题": "An Overview of AI and Blockchain Integration for Privacy-Preserving",
                "作者": " Zongwei Li,  Dechao Kong,  Yuanzheng Niu,  Hongli Peng,  Xiaoqi Li,  Wenkai Li",
                "发布日期": "2023-05-09",
                "摘要": "  With the widespread attention and application of artificial intelligence (AI)\nand blockchain technologies, privacy protection techniques arising from their\nintegration are of notable significance. In addition to protecting privacy of\nindividuals, these techniques also guarantee security and dependability of\ndata. This paper initially presents an overview of AI and blockchain,\nsummarizing their combination along with derived privacy protection\ntechnologies. It then explores specific application scenarios in data\nencryption, de-identification, multi-tier distributed ledgers, and k-anonymity\nmethods. Moreover, the paper evaluates five critical aspects of\nAI-blockchain-integration privacy protection systems, including authorization\nmanagement, access control, data protection, network security, and scalability.\nFurthermore, it analyzes the deficiencies and their actual cause, offering\ncorresponding suggestions. This research also classifies and summarizes privacy\nprotection techniques based on AI-blockchain application scenarios and\ntechnical schemes. In conclusion, this paper outlines the future directions of\nprivacy protection technologies emerging from AI and blockchain integration,\nincluding enhancing efficiency and security to achieve a more comprehensive\nprivacy protection of privacy.\n",
                "链接": "https://arxiv.org/abs/2305.03928"
            },
            {
                "文章ID": "36093",
                "标题": "How Much User Context Do We Need? Privacy by Design in Mental Health NLP\n  Application",
                "作者": " Ramit Sawhney,  Atula Tejaswi Neerkaje,  Ivan Habernal,  Lucie Flek",
                "发布日期": "2022-09-07",
                "摘要": "  Clinical NLP tasks such as mental health assessment from text, must take\nsocial constraints into account - the performance maximization must be\nconstrained by the utmost importance of guaranteeing privacy of user data.\nConsumer protection regulations, such as GDPR, generally handle privacy by\nrestricting data availability, such as requiring to limit user data to 'what is\nnecessary' for a given purpose. In this work, we reason that providing stricter\nformal privacy guarantees, while increasing the volume of user data in the\nmodel, in most cases increases benefit for all parties involved, especially for\nthe user. We demonstrate our arguments on two existing suicide risk assessment\ndatasets of Twitter and Reddit posts. We present the first analysis juxtaposing\nuser history length and differential privacy budgets and elaborate how modeling\nadditional user context enables utility preservation while maintaining\nacceptable user privacy guarantees.\n",
                "链接": "https://arxiv.org/abs/2209.02022"
            },
            {
                "文章ID": "37431",
                "标题": "Does CLIP Know My Face?",
                "作者": " Dominik Hintersdorf,  Lukas Struppek,  Manuel Brack,  Felix Friedrich,  Patrick Schramowski,  Kristian Kersting",
                "发布日期": "2023-05-31",
                "摘要": "  With the rise of deep learning in various applications, privacy concerns\naround the protection of training data has become a critical area of research.\nWhereas prior studies have focused on privacy risks in single-modal models, we\nintroduce a novel method to assess privacy for multi-modal models, specifically\nvision-language models like CLIP. The proposed Identity Inference Attack (IDIA)\nreveals whether an individual was included in the training data by querying the\nmodel with images of the same person. Letting the model choose from a wide\nvariety of possible text labels, the model reveals whether it recognizes the\nperson and, therefore, was used for training. Our large-scale experiments on\nCLIP demonstrate that individuals used for training can be identified with very\nhigh accuracy. We confirm that the model has learned to associate names with\ndepicted individuals, implying the existence of sensitive information that can\nbe extracted by adversaries. Our results highlight the need for stronger\nprivacy protection in large-scale models and suggest that IDIAs can be used to\nprove the unauthorized use of data for training and to enforce privacy laws.\n",
                "链接": "https://arxiv.org/abs/2209.07341"
            }
        ]
    },
    {
        "question": {
            "question": "推荐与AutoGPT相似的10篇文献",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "86417",
                "标题": "AD-AutoGPT: An Autonomous GPT for Alzheimer's Disease Infodemiology",
                "作者": " Haixing Dai,  Yiwei Li,  Zhengliang Liu,  Lin Zhao,  Zihao Wu,  Suhang Song,  Ye Shen,  Dajiang Zhu,  Xiang Li,  Sheng Li,  Xiaobai Yao,  Lu Shi,  Quanzheng Li,  Zhuo Chen,  Donglan Zhang,  Gengchen Mai,  Tianming Liu",
                "发布日期": "2023-06-21",
                "摘要": "  In this pioneering study, inspired by AutoGPT, the state-of-the-art\nopen-source application based on the GPT-4 large language model, we develop a\nnovel tool called AD-AutoGPT which can conduct data collection, processing, and\nanalysis about complex health narratives of Alzheimer's Disease in an\nautonomous manner via users' textual prompts. We collated comprehensive data\nfrom a variety of news sources, including the Alzheimer's Association, BBC,\nMayo Clinic, and the National Institute on Aging since June 2022, leading to\nthe autonomous execution of robust trend analyses, intertopic distance maps\nvisualization, and identification of salient terms pertinent to Alzheimer's\nDisease. This approach has yielded not only a quantifiable metric of relevant\ndiscourse but also valuable insights into public focus on Alzheimer's Disease.\nThis application of AD-AutoGPT in public health signifies the transformative\npotential of AI in facilitating a data-rich understanding of complex health\nnarratives like Alzheimer's Disease in an autonomous manner, setting the\ngroundwork for future AI-driven investigations in global health landscapes.\n",
                "链接": "https://arxiv.org/abs/2306.10095"
            },
            {
                "文章ID": "96648",
                "标题": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
                "作者": " Qingyun Wu,  Gagan Bansal,  Jieyu Zhang,  Yiran Wu,  Beibin Li,  Erkang Zhu,  Li Jiang,  Xiaoyun Zhang,  Shaokun Zhang,  Jiale Liu,  Ahmed Hassan Awadallah,  Ryen W White,  Doug Burger,  Chi Wang",
                "发布日期": "2023-10-05",
                "摘要": "  AutoGen is an open-source framework that allows developers to build LLM\napplications via multiple agents that can converse with each other to\naccomplish tasks. AutoGen agents are customizable, conversable, and can operate\nin various modes that employ combinations of LLMs, human inputs, and tools.\nUsing AutoGen, developers can also flexibly define agent interaction behaviors.\nBoth natural language and computer code can be used to program flexible\nconversation patterns for different applications. AutoGen serves as a generic\ninfrastructure to build diverse applications of various complexities and LLM\ncapacities. Empirical studies demonstrate the effectiveness of the framework in\nmany example applications, with domains ranging from mathematics, coding,\nquestion answering, operations research, online decision-making, entertainment,\netc.\n",
                "链接": "https://arxiv.org/abs/2308.08155"
            },
            {
                "文章ID": "74264",
                "标题": "AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking\n  Head",
                "作者": " Rongjie Huang,  Mingze Li,  Dongchao Yang,  Jiatong Shi,  Xuankai Chang,  Zhenhui Ye,  Yuning Wu,  Zhiqing Hong,  Jiawei Huang,  Jinglin Liu,  Yi Ren,  Zhou Zhao,  Shinji Watanabe",
                "发布日期": "2023-04-26",
                "摘要": "  Large language models (LLMs) have exhibited remarkable capabilities across a\nvariety of domains and tasks, challenging our understanding of learning and\ncognition. Despite the recent success, current LLMs are not capable of\nprocessing complex audio information or conducting spoken conversations (like\nSiri or Alexa). In this work, we propose a multi-modal AI system named\nAudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to\nprocess complex audio information and solve numerous understanding and\ngeneration tasks; and 2) the input/output interface (ASR, TTS) to support\nspoken dialogue. With an increasing demand to evaluate multi-modal LLMs of\nhuman intention understanding and cooperation with foundation models, we\noutline the principles and processes and test AudioGPT in terms of consistency,\ncapability, and robustness. Experimental results demonstrate the capabilities\nof AudioGPT in solving AI tasks with speech, music, sound, and talking head\nunderstanding and generation in multi-round dialogues, which empower humans to\ncreate rich and diverse audio content with unprecedented ease. Our system is\npublicly available at \\url{https://github.com/AIGC-Audio/AudioGPT}.\n",
                "链接": "https://arxiv.org/abs/2304.12995"
            },
            {
                "文章ID": "122994",
                "标题": "Assessing the Usability of GutGPT: A Simulation Study of an AI Clinical\n  Decision Support System for Gastrointestinal Bleeding Risk",
                "作者": " Colleen Chan,  Kisung You,  Sunny Chung,  Mauro Giuffrè,  Theo Saarinen,  Niroop Rajashekar,  Yuan Pu,  Yeo Eun Shin,  Loren Laine,  Ambrose Wong,  René Kizilcec,  Jasjeet Sekhon,  Dennis Shung",
                "发布日期": "2023-12-19",
                "摘要": "  Applications of large language models (LLMs) like ChatGPT have potential to\nenhance clinical decision support through conversational interfaces. However,\nchallenges of human-algorithmic interaction and clinician trust are poorly\nunderstood. GutGPT, a LLM for gastrointestinal (GI) bleeding risk prediction\nand management guidance, was deployed in clinical simulation scenarios\nalongside the electronic health record (EHR) with emergency medicine\nphysicians, internal medicine physicians, and medical students to evaluate its\neffect on physician acceptance and trust in AI clinical decision support\nsystems (AI-CDSS). GutGPT provides risk predictions from a validated machine\nlearning model and evidence-based answers by querying extracted clinical\nguidelines. Participants were randomized to GutGPT and an interactive\ndashboard, or the interactive dashboard and a search engine. Surveys and\neducational assessments taken before and after measured technology acceptance\nand content mastery. Preliminary results showed mixed effects on acceptance\nafter using GutGPT compared to the dashboard or search engine but appeared to\nimprove content mastery based on simulation performance. Overall, this study\ndemonstrates LLMs like GutGPT could enhance effective AI-CDSS if implemented\noptimally and paired with interactive interfaces.\n",
                "链接": "https://arxiv.org/abs/2312.10072"
            },
            {
                "文章ID": "13182",
                "标题": "AutoOpt: A General Framework for Automatically Designing Metaheuristic\n  Optimization Algorithms with Diverse Structures",
                "作者": " Qi Zhao,  Bai Yan,  Xianglong Chen,  Taiwei Hu,  Shi Cheng,  Yuhui Shi",
                "发布日期": "2023-05-05",
                "摘要": "  Metaheuristics are widely recognized gradient-free solvers to hard problems\nthat do not meet the rigorous mathematical assumptions of conventional solvers.\nThe automated design of metaheuristic algorithms provides an attractive path to\nrelieve manual design effort and gain enhanced performance beyond human-made\nalgorithms. However, the specific algorithm prototype and linear algorithm\nrepresentation in the current automated design pipeline restrict the design\nwithin a fixed algorithm structure, which hinders discovering novelties and\ndiversity across the metaheuristic family. To address this challenge, this\npaper proposes a general framework, AutoOpt, for automatically designing\nmetaheuristic algorithms with diverse structures. AutoOpt contains three\ninnovations: (i) A general algorithm prototype dedicated to covering the\nmetaheuristic family as widely as possible. It promotes high-quality automated\ndesign on different problems by fully discovering potentials and novelties\nacross the family. (ii) A directed acyclic graph algorithm representation to\nfit the proposed prototype. Its flexibility and evolvability enable discovering\nvarious algorithm structures in a single run of design, thus boosting the\npossibility of finding high-performance algorithms. (iii) A graph\nrepresentation embedding method offering an alternative compact form of the\ngraph to be manipulated, which ensures AutoOpt's generality. Experiments on\nnumeral functions and real applications validate AutoOpt's efficiency and\npracticability.\n",
                "链接": "https://arxiv.org/abs/2204.00998"
            },
            {
                "文章ID": "53479",
                "标题": "AutoPV: Automated photovoltaic forecasts with limited information using\n  an ensemble of pre-trained models",
                "作者": " Stefan Meisenbacher,  Benedikt Heidrich,  Tim Martin,  Ralf Mikut,  Veit Hagenmeyer",
                "发布日期": "2023-06-21",
                "摘要": "  Accurate PhotoVoltaic (PV) power generation forecasting is vital for the\nefficient operation of Smart Grids. The automated design of such accurate\nforecasting models for individual PV plants includes two challenges: First,\ninformation about the PV mounting configuration (i.e. inclination and azimuth\nangles) is often missing. Second, for new PV plants, the amount of historical\ndata available to train a forecasting model is limited (cold-start problem). We\naddress these two challenges by proposing a new method for day-ahead PV power\ngeneration forecasts called AutoPV. AutoPV is a weighted ensemble of\nforecasting models that represent different PV mounting configurations. This\nrepresentation is achieved by pre-training each forecasting model on a separate\nPV plant and by scaling the model's output with the peak power rating of the\ncorresponding PV plant. To tackle the cold-start problem, we initially weight\neach forecasting model in the ensemble equally. To tackle the problem of\nmissing information about the PV mounting configuration, we use new data that\nbecome available during operation to adapt the ensemble weights to minimize the\nforecasting error. AutoPV is advantageous as the unknown PV mounting\nconfiguration is implicitly reflected in the ensemble weights, and only the PV\nplant's peak power rating is required to re-scale the ensemble's output. AutoPV\nalso allows to represent PV plants with panels distributed on different roofs\nwith varying alignments, as these mounting configurations can be reflected\nproportionally in the weighting. Additionally, the required computing memory is\ndecoupled when scaling AutoPV to hundreds of PV plants, which is beneficial in\nSmart Grids with limited computing capabilities. For a real-world data set with\n11 PV plants, the accuracy of AutoPV is comparable to a model trained on two\nyears of data and outperforms an incrementally trained model.\n",
                "链接": "https://arxiv.org/abs/2212.06797"
            },
            {
                "文章ID": "9495",
                "标题": "AutoGPart: Intermediate Supervision Search for Generalizable 3D Part\n  Segmentation",
                "作者": " Xueyi Liu,  Xiaomeng Xu,  Anyi Rao,  Chuang Gan,  Li Yi",
                "发布日期": "2022-04-18",
                "摘要": "  Training a generalizable 3D part segmentation network is quite challenging\nbut of great importance in real-world applications. To tackle this problem,\nsome works design task-specific solutions by translating human understanding of\nthe task to machine's learning process, which faces the risk of missing the\noptimal strategy since machines do not necessarily understand in the exact\nhuman way. Others try to use conventional task-agnostic approaches designed for\ndomain generalization problems with no task prior knowledge considered. To\nsolve the above issues, we propose AutoGPart, a generic method enabling\ntraining generalizable 3D part segmentation networks with the task prior\nconsidered. AutoGPart builds a supervision space with geometric prior knowledge\nencoded, and lets the machine to search for the optimal supervisions from the\nspace for a specific segmentation task automatically. Extensive experiments on\nthree generalizable 3D part segmentation tasks are conducted to demonstrate the\neffectiveness and versatility of AutoGPart. We demonstrate that the performance\nof segmentation networks using simple backbones can be significantly improved\nwhen trained with supervisions searched by our method.\n",
                "链接": "https://arxiv.org/abs/2203.06558"
            },
            {
                "文章ID": "73364",
                "标题": "OptoGPT: A Foundation Model for Inverse Design in Optical Multilayer\n  Thin Film Structures",
                "作者": " Taigao Ma,  Haozhu Wang,  L. Jay Guo",
                "发布日期": "2023-04-21",
                "摘要": "  Foundation models are large machine learning models that can tackle various\ndownstream tasks once trained on diverse and large-scale data, leading research\ntrends in natural language processing, computer vision, and reinforcement\nlearning. However, no foundation model exists for optical multilayer thin film\nstructure inverse design. Current inverse design algorithms either fail to\nexplore the global design space or suffer from low computational efficiency. To\nbridge this gap, we propose the Opto Generative Pretrained Transformer\n(OptoGPT). OptoGPT is a decoder-only transformer that auto-regressively\ngenerates designs based on specific spectrum targets. Trained on a large\ndataset of 10 million designs, our model demonstrates remarkable capabilities:\n1) autonomous global design exploration by determining the number of layers (up\nto 20) while selecting the material (up to 18 distinct types) and thickness at\neach layer, 2) efficient designs for structural color, absorbers, filters,\ndistributed brag reflectors, and Fabry-Perot resonators within 0.1 seconds\n(comparable to simulation speeds), 3) the ability to output diverse designs,\nand 4) seamless integration of user-defined constraints. By overcoming design\nbarriers regarding optical targets, material selections, and design\nconstraints, OptoGPT can serve as a foundation model for optical multilayer\nthin film structure inverse design.\n",
                "链接": "https://arxiv.org/abs/2304.10294"
            },
            {
                "文章ID": "108389",
                "标题": "AutoVP: An Automated Visual Prompting Framework and Benchmark",
                "作者": " Hsi-Ai Tsao,  Lei Hsiung,  Pin-Yu Chen,  Sijia Liu,  Tsung-Yi Ho",
                "发布日期": "2023-10-13",
                "摘要": "  Visual prompting (VP) is an emerging parameter-efficient fine-tuning approach\nto adapting pre-trained vision models to solve various downstream\nimage-classification tasks. However, there has hitherto been little systematic\nstudy of the design space of VP and no clear benchmark for evaluating its\nperformance. To bridge this gap, we propose AutoVP, an end-to-end expandable\nframework for automating VP design choices, along with 12 downstream\nimage-classification tasks that can serve as a holistic VP-performance\nbenchmark. Our design space covers 1) the joint optimization of the prompts; 2)\nthe selection of pre-trained models, including image classifiers and text-image\nencoders; and 3) model output mapping strategies, including nonparametric and\ntrainable label mapping. Our extensive experimental results show that AutoVP\noutperforms the best-known current VP methods by a substantial margin, having\nup to 6.7% improvement in accuracy; and attains a maximum performance increase\nof 27.5% compared to linear-probing (LP) baseline. AutoVP thus makes a two-fold\ncontribution: serving both as an efficient tool for hyperparameter tuning on VP\ndesign choices, and as a comprehensive benchmark that can reasonably be\nexpected to accelerate VP's development. The source code is available at\nhttps://github.com/IBM/AutoVP.\n",
                "链接": "https://arxiv.org/abs/2310.08381"
            },
            {
                "文章ID": "65490",
                "标题": "Cost-Effective Hyperparameter Optimization for Large Language Model\n  Generation Inference",
                "作者": " Chi Wang,  Susan Xueqing Liu,  Ahmed H. Awadallah",
                "发布日期": "2023-08-10",
                "摘要": "  Large Language Models (LLMs) have sparked significant interest in their\ngenerative capabilities, leading to the development of various commercial\napplications. The high cost of using the models drives application builders to\nmaximize the value of generation under a limited inference budget. This paper\npresents a study of optimizing inference hyperparameters such as the number of\nresponses, temperature and max tokens, which significantly affects the\nutility/cost of text generation. We design a framework named EcoOptiGen which\nleverages economical hyperparameter optimization and cost-based pruning.\nExperiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its\neffectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAML\nlibrary: \\url{https://aka.ms/autogen}.\n",
                "链接": "https://arxiv.org/abs/2303.04673"
            }
        ]
    },
    {
        "question": {
            "question": "请搜索近一年发表的有关多模态大模型与产业相结合、与具体应用场景相结合的论文",
            "type": "2"
        },
        "results": [
            {
                "文章ID": "97795",
                "标题": "Federated Learning in Big Model Era: Domain-Specific Multimodal Large\n  Models",
                "作者": " Zengxiang Li,  Zhaoxiang Hou,  Hui Liu,  Ying Wang,  Tongzhi Li,  Longfei Xie,  Chao Shi,  Chengyi Yang,  Weishan Zhang,  Zelei Liu,  Liang Xu",
                "发布日期": "2023-08-25",
                "摘要": "  Multimodal data, which can comprehensively perceive and recognize the\nphysical world, has become an essential path towards general artificial\nintelligence. However, multimodal large models trained on public datasets often\nunderperform in specific industrial domains. This paper proposes a multimodal\nfederated learning framework that enables multiple enterprises to utilize\nprivate domain data to collaboratively train large models for vertical domains,\nachieving intelligent services across scenarios. The authors discuss in-depth\nthe strategic transformation of federated learning in terms of intelligence\nfoundation and objectives in the era of big model, as well as the new\nchallenges faced in heterogeneous data, model aggregation, performance and cost\ntrade-off, data privacy, and incentive mechanism. The paper elaborates a case\nstudy of leading enterprises contributing multimodal data and expert knowledge\nto city safety operation management , including distributed deployment and\nefficient coordination of the federated learning platform, technical\ninnovations on data quality improvement based on large model capabilities and\nefficient joint fine-tuning approaches. Preliminary experiments show that\nenterprises can enhance and accumulate intelligent capabilities through\nmultimodal model federated learning, thereby jointly creating an smart city\nmodel that provides high-quality intelligent services covering energy\ninfrastructure safety, residential community security, and urban operation\nmanagement. The established federated learning cooperation ecosystem is\nexpected to further aggregate industry, academia, and research resources,\nrealize large models in multiple vertical domains, and promote the large-scale\nindustrial application of artificial intelligence and cutting-edge research on\nmultimodal federated learning.\n",
                "链接": "https://arxiv.org/abs/2308.11217"
            },
            {
                "文章ID": "86687",
                "标题": "MotionGPT: Finetuned LLMs are General-Purpose Motion Generators",
                "作者": " Yaqi Zhang,  Di Huang,  Bin Liu,  Shixiang Tang,  Yan Lu,  Lu Chen,  Lei Bai,  Qi Chu,  Nenghai Yu,  Wanli Ouyang",
                "发布日期": "2023-06-21",
                "摘要": "  Generating realistic human motion from given action descriptions has\nexperienced significant advancements because of the emerging requirement of\ndigital humans. While recent works have achieved impressive results in\ngenerating motion directly from textual action descriptions, they often support\nonly a single modality of the control signal, which limits their application in\nthe real digital human industry. This paper presents a Motion General-Purpose\ngeneraTor (MotionGPT) that can use multimodal control signals, e.g., text and\nsingle-frame poses, for generating consecutive human motions by treating\nmultimodal signals as special input tokens in large language models (LLMs).\nSpecifically, we first quantize multimodal control signals into discrete codes\nand then formulate them in a unified prompt instruction to ask the LLMs to\ngenerate the motion answer. Our MotionGPT demonstrates a unified human motion\ngeneration model with multimodal control signals by tuning a mere 0.4% of LLM\nparameters. To the best of our knowledge, MotionGPT is the first method to\ngenerate human motion by multimodal control signals, which we hope can shed\nlight on this new direction. Codes shall be released upon acceptance.\n",
                "链接": "https://arxiv.org/abs/2306.10900"
            },
            {
                "文章ID": "115070",
                "标题": "Knowledgeable Preference Alignment for LLMs in Domain-specific Question\n  Answering",
                "作者": " Yichi Zhang,  Zhuo Chen,  Yin Fang,  Lei Cheng,  Yanxi Lu,  Fangming Li,  Wen Zhang,  Huajun Chen",
                "发布日期": "2023-11-14",
                "摘要": "  Recently, the development of large language models (LLMs) has attracted wide\nattention in academia and industry. Deploying LLMs to real scenarios is one of\nthe key directions in the current Internet industry. In this paper, we present\na novel pipeline to apply LLMs for domain-specific question answering (QA) that\nincorporates domain knowledge graphs (KGs), addressing an important direction\nof LLM application. As a real-world application, the content generated by LLMs\nshould be user-friendly to serve the customers. Additionally, the model needs\nto utilize domain knowledge properly to generate reliable answers. These two\nissues are the two major difficulties in the LLM application as vanilla\nfine-tuning can not adequately address them. We think both requirements can be\nunified as the model preference problem that needs to align with humans to\nachieve practical application. Thus, we introduce Knowledgeable Preference\nAlignmenT (KnowPAT), which constructs two kinds of preference set called style\npreference set and knowledge preference set respectively to tackle the two\nissues. Besides, we design a new alignment objective to align the LLM\npreference with human preference, aiming to train a better LLM for\nreal-scenario domain-specific QA to generate reliable and user-friendly\nanswers. Adequate experiments and comprehensive with 15 baseline methods\ndemonstrate that our KnowPAT is an outperforming pipeline for real-scenario\ndomain-specific QA with LLMs. Our code is open-source at\nhttps://github.com/zjukg/KnowPAT.\n",
                "链接": "https://arxiv.org/abs/2311.06503"
            },
            {
                "文章ID": "123840",
                "标题": "Future-proofing geotechnics workflows: accelerating problem-solving with\n  large language models",
                "作者": " Stephen Wu,  Yu Otake,  Daijiro Mizutani,  Chang Liu,  Kotaro Asano,  Nana Sato,  Hidetoshi Baba,  Yusuke Fukunaga,  Yosuke Higo,  Akiyoshi Kamura,  Shinnosuke Kodama,  Masataka Metoki,  Tomoka Nakamura,  Yuto Nakazato,  Taiga Saito,  Akihiro Shioi,  Masahiro Takenobu,  Keigo Tsukioka,  Ryo Yoshikawa",
                "发布日期": "2023-12-20",
                "摘要": "  The integration of Large Language Models (LLMs) like ChatGPT into the\nworkflows of geotechnical engineering has a high potential to transform how the\ndiscipline approaches problem-solving and decision-making. This paper delves\ninto the innovative application of LLMs in geotechnical engineering, as\nexplored in a hands-on workshop held in Tokyo, Japan. The event brought\ntogether a diverse group of 20 participants, including students, researchers,\nand professionals from academia, industry, and government sectors, to\ninvestigate practical uses of LLMs in addressing specific geotechnical\nchallenges. The workshop facilitated the creation of solutions for four\ndifferent practical geotechnical problems as illustrative examples, culminating\nin the development of an academic paper. The paper discusses the potential of\nLLMs to transform geotechnical engineering practices, highlighting their\nproficiency in handling a range of tasks from basic data analysis to complex,\nmultimodal problem-solving. It also addresses the challenges in implementing\nLLMs, particularly in achieving high precision and accuracy in specialized\ntasks, and underscores the need for expert oversight. The findings demonstrate\nLLMs' effectiveness in enhancing efficiency, data processing, and\ndecision-making in geotechnical engineering, suggesting a paradigm shift\ntowards more integrated, data-driven approaches in this field. This study not\nonly showcases the potential of LLMs in a specific engineering domain, but also\nsets a precedent for their broader application in interdisciplinary research\nand practice, where the synergy of human expertise and artificial intelligence\nredefines the boundaries of problem-solving.\n",
                "链接": "https://arxiv.org/abs/2312.12411"
            },
            {
                "文章ID": "108706",
                "标题": "Topological Data Analysis in smart manufacturing processes -- A survey\n  on the state of the art",
                "作者": " Martin Uray,  Barbara Giunti,  Michael Kerber,  Stefan Huber",
                "发布日期": "2023-10-17",
                "摘要": "  Topological Data Analysis (TDA) is a mathematical method using techniques\nfrom topology for the analysis of complex, multi-dimensional data that has been\nwidely and successfully applied in several fields such as medicine, material\nscience, biology, and others. This survey summarizes the state of the art of\nTDA in yet another application area: industrial manufacturing and production in\nthe context of Industry 4.0. We perform a rigorous and reproducible literature\nsearch of applications of TDA on the setting of industrial production and\nmanufacturing. The resulting works are clustered and analyzed based on their\napplication area within the manufacturing process and their input data type. We\nhighlight the key benefits of TDA and their tools in this area and describe its\nchallenges, as well as future potential. Finally, we discuss which TDA methods\nare underutilized in (the specific area of) industry and the identified types\nof application, with the goal of prompting more research in this profitable\narea of application.\n",
                "链接": "https://arxiv.org/abs/2310.09319"
            },
            {
                "文章ID": "124123",
                "标题": "Generative Multimodal Models are In-Context Learners",
                "作者": " Quan Sun,  Yufeng Cui,  Xiaosong Zhang,  Fan Zhang,  Qiying Yu,  Zhengxiong Luo,  Yueze Wang,  Yongming Rao,  Jingjing Liu,  Tiejun Huang,  Xinlong Wang",
                "发布日期": "2023-12-21",
                "摘要": "  The human ability to easily solve multimodal tasks in context (i.e., with\nonly a few demonstrations or simple instructions), is what current multimodal\nsystems have largely struggled to imitate. In this work, we demonstrate that\nthe task-agnostic in-context learning capabilities of large multimodal models\ncan be significantly enhanced by effective scaling-up. We introduce Emu2, a\ngenerative multimodal model with 37 billion parameters, trained on large-scale\nmultimodal sequences with a unified autoregressive objective. Emu2 exhibits\nstrong multimodal in-context learning abilities, even emerging to solve tasks\nthat require on-the-fly reasoning, such as visual prompting and object-grounded\ngeneration. The model sets a new record on multiple multimodal understanding\ntasks in few-shot settings. When instruction-tuned to follow specific\ninstructions, Emu2 further achieves new state-of-the-art on challenging tasks\nsuch as question answering benchmarks for large multimodal models and\nopen-ended subject-driven generation. These achievements demonstrate that Emu2\ncan serve as a base model and general-purpose interface for a wide range of\nmultimodal tasks. Code and models are publicly available to facilitate future\nresearch.\n",
                "链接": "https://arxiv.org/abs/2312.13286"
            },
            {
                "文章ID": "81949",
                "标题": "Improving Generalization for Multimodal Fake News Detection",
                "作者": " Sahar Tahmasebi,  Sherzod Hakimov,  Ralph Ewerth,  Eric Müller-Budack",
                "发布日期": "2023-05-31",
                "摘要": "  The increasing proliferation of misinformation and its alarming impact have\nmotivated both industry and academia to develop approaches for fake news\ndetection. However, state-of-the-art approaches are usually trained on datasets\nof smaller size or with a limited set of specific topics. As a consequence,\nthese models lack generalization capabilities and are not applicable to\nreal-world data. In this paper, we propose three models that adopt and\nfine-tune state-of-the-art multimodal transformers for multimodal fake news\ndetection. We conduct an in-depth analysis by manipulating the input data aimed\nto explore models performance in realistic use cases on social media. Our study\nacross multiple models demonstrates that these systems suffer significant\nperformance drops against manipulated data. To reduce the bias and improve\nmodel generalization, we suggest training data augmentation to conduct more\nmeaningful experiments for fake news detection on social media. The proposed\ndata augmentation techniques enable models to generalize better and yield\nimproved state-of-the-art results.\n",
                "链接": "https://arxiv.org/abs/2305.18599"
            },
            {
                "文章ID": "124447",
                "标题": "A Unified Industrial Large Knowledge Model Framework in Smart\n  Manufacturing",
                "作者": " Jay Lee,  Hanqi Su",
                "发布日期": "2023-12-25",
                "摘要": "  The recent emergence of large language models (LLMs) shows the potential for\nartificial general intelligence, revealing new opportunities in industry 4.0\nand smart manufacturing. However, a notable gap exists in applying these LLMs\nin industry, primarily due to their training on general knowledge rather than\ndomain-specific knowledge. Such specialized domain knowledge is vital for\neffectively addressing the complex needs of industrial applications. To bridge\nthis gap, this paper proposes an Industrial Large Knowledge Model (ILKM)\nframework emphasizing their potential to revolutionize the industry in smart\nmanufacturing. In addition, ILKMs and LLMs are compared from eight\nperspectives. Finally, \"6S Principle\" is proposed as the guideline for the\ndevelopment of ILKMs in smart manufacturing.\n",
                "链接": "https://arxiv.org/abs/2312.14428"
            },
            {
                "文章ID": "92421",
                "标题": "Integration of Domain Expert-Centric Ontology Design into the CRISP-DM\n  for Cyber-Physical Production Systems",
                "作者": " Milapji Singh Gill,  Tom Westermann,  Marvin Schieseck,  Alexander Fay",
                "发布日期": "2023-07-24",
                "摘要": "  In the age of Industry 4.0 and Cyber-Physical Production Systems (CPPSs) vast\namounts of potentially valuable data are being generated. Methods from Machine\nLearning (ML) and Data Mining (DM) have proven to be promising in extracting\ncomplex and hidden patterns from the data collected. The knowledge obtained can\nin turn be used to improve tasks like diagnostics or maintenance planning.\nHowever, such data-driven projects, usually performed with the Cross-Industry\nStandard Process for Data Mining (CRISP-DM), often fail due to the\ndisproportionate amount of time needed for understanding and preparing the\ndata. The application of domain-specific ontologies has demonstrated its\nadvantageousness in a wide variety of Industry 4.0 application scenarios\nregarding the aforementioned challenges. However, workflows and artifacts from\nontology design for CPPSs have not yet been systematically integrated into the\nCRISP-DM. Accordingly, this contribution intends to present an integrated\napproach so that data scientists are able to more quickly and reliably gain\ninsights into the CPPS. The result is exemplarily applied to an anomaly\ndetection use case.\n",
                "链接": "https://arxiv.org/abs/2307.11637"
            },
            {
                "文章ID": "91047",
                "标题": "CephGPT-4: An Interactive Multimodal Cephalometric Measurement and\n  Diagnostic System with Visual Large Language Model",
                "作者": " Lei Ma,  Jincong Han,  Zhaoxin Wang,  Dian Zhang",
                "发布日期": "2023-07-18",
                "摘要": "  Large-scale multimodal language models (LMMs) have achieved remarkable\nsuccess in general domains. However, the exploration of diagnostic language\nmodels based on multimodal cephalometric medical data remains limited. In this\npaper, we propose a novel multimodal cephalometric analysis and diagnostic\ndialogue model. Firstly, a multimodal orthodontic medical dataset is\nconstructed, comprising cephalometric images and doctor-patient dialogue data,\nwith automatic analysis of cephalometric landmarks using U-net and generation\nof diagnostic reports. Then, the cephalometric dataset and generated diagnostic\nreports are separately fine-tuned on Minigpt-4 and VisualGLM. Results\ndemonstrate that the CephGPT-4 model exhibits excellent performance and has the\npotential to revolutionize orthodontic measurement and diagnostic applications.\nThese innovations hold revolutionary application potential in the field of\northodontics.\n",
                "链接": "https://arxiv.org/abs/2307.07518"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究，特别关注使用自动标注和迁移学习方法的论文，时间跨度覆盖2019年至今。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "110503",
                "标题": "A comprehensive survey on deep active learning and its applications in\n  medical image analysis",
                "作者": " Haoran Wang,  Qiuye Jin,  Shiman Li,  Siyu Liu,  Manning Wang,  Zhijian Song",
                "发布日期": "2023-10-25",
                "摘要": "  Deep learning has achieved widespread success in medical image analysis,\nleading to an increasing demand for large-scale expert-annotated medical image\ndatasets. Yet, the high cost of annotating medical images severely hampers the\ndevelopment of deep learning in this field. To reduce annotation costs, active\nlearning aims to select the most informative samples for annotation and train\nhigh-performance models with as few labeled samples as possible. In this\nsurvey, we review the core methods of active learning, including the evaluation\nof informativeness and sampling strategy. For the first time, we provide a\ndetailed summary of the integration of active learning with other\nlabel-efficient techniques, such as semi-supervised, self-supervised learning,\nand so on. Additionally, we also highlight active learning works that are\nspecifically tailored to medical image analysis. In the end, we offer our\nperspectives on the future trends and challenges of active learning and its\napplications in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2310.14230"
            },
            {
                "文章ID": "100407",
                "标题": "Augmenting Chest X-ray Datasets with Non-Expert Annotations",
                "作者": " Cathrine Damgaard,  Trine Naja Eriksen,  Dovile Juodelyte,  Veronika Cheplygina,  Amelia Jiménez-Sánchez",
                "发布日期": "2023-09-06",
                "摘要": "  The advancement of machine learning algorithms in medical image analysis\nrequires the expansion of training datasets. A popular and cost-effective\napproach is automated annotation extraction from free-text medical reports,\nprimarily due to the high costs associated with expert clinicians annotating\nchest X-ray images. However, it has been shown that the resulting datasets are\nsusceptible to biases and shortcuts. Another strategy to increase the size of a\ndataset is crowdsourcing, a widely adopted practice in general computer vision\nwith some success in medical image analysis. In a similar vein to\ncrowdsourcing, we enhance two publicly available chest X-ray datasets by\nincorporating non-expert annotations. However, instead of using diagnostic\nlabels, we annotate shortcuts in the form of tubes. We collect 3.5k chest drain\nannotations for CXR14, and 1k annotations for 4 different tube types in\nPadChest. We train a chest drain detector with the non-expert annotations that\ngeneralizes well to expert labels. Moreover, we compare our annotations to\nthose provided by experts and show \"moderate\" to \"almost perfect\" agreement.\nFinally, we present a pathology agreement study to raise awareness about ground\ntruth annotations. We make our annotations and code available.\n",
                "链接": "https://arxiv.org/abs/2309.02244"
            },
            {
                "文章ID": "92533",
                "标题": "COLosSAL: A Benchmark for Cold-start Active Learning for 3D Medical\n  Image Segmentation",
                "作者": " Han Liu,  Hao Li,  Xing Yao,  Yubo Fan,  Dewei Hu,  Benoit Dawant,  Vishwesh Nath,  Zhoubing Xu,  Ipek Oguz",
                "发布日期": "2023-07-25",
                "摘要": "  Medical image segmentation is a critical task in medical image analysis. In\nrecent years, deep learning based approaches have shown exceptional performance\nwhen trained on a fully-annotated dataset. However, data annotation is often a\nsignificant bottleneck, especially for 3D medical images. Active learning (AL)\nis a promising solution for efficient annotation but requires an initial set of\nlabeled samples to start active selection. When the entire data pool is\nunlabeled, how do we select the samples to annotate as our initial set? This is\nalso known as the cold-start AL, which permits only one chance to request\nannotations from experts without access to previously annotated data.\nCold-start AL is highly relevant in many practical scenarios but has been\nunder-explored, especially for 3D medical segmentation tasks requiring\nsubstantial annotation effort. In this paper, we present a benchmark named\nCOLosSAL by evaluating six cold-start AL strategies on five 3D medical image\nsegmentation tasks from the public Medical Segmentation Decathlon collection.\nWe perform a thorough performance analysis and explore important open questions\nfor cold-start AL, such as the impact of budget on different strategies. Our\nresults show that cold-start AL is still an unsolved problem for 3D\nsegmentation tasks but some important trends have been observed. The code\nrepository, data partitions, and baseline results for the complete benchmark\nare publicly available at https://github.com/MedICL-VU/COLosSAL.\n",
                "链接": "https://arxiv.org/abs/2307.12004"
            },
            {
                "文章ID": "34051",
                "标题": "PyMIC: A deep learning toolkit for annotation-efficient medical image\n  segmentation",
                "作者": " Guotai Wang,  Xiangde Luo,  Ran Gu,  Shuojue Yang,  Yijie Qu,  Shuwei Zhai,  Qianfei Zhao,  Kang Li,  Shaoting Zhang",
                "发布日期": "2023-02-14",
                "摘要": "  Background and Objective: Open-source deep learning toolkits are one of the\ndriving forces for developing medical image segmentation models. Existing\ntoolkits mainly focus on fully supervised segmentation and require full and\naccurate pixel-level annotations that are time-consuming and difficult to\nacquire for segmentation tasks, which makes learning from imperfect labels\nhighly desired for reducing the annotation cost. We aim to develop a new deep\nlearning toolkit to support annotation-efficient learning for medical image\nsegmentation.\n  Methods: Our proposed toolkit named PyMIC is a modular deep learning library\nfor medical image segmentation tasks. In addition to basic components that\nsupport development of high-performance models for fully supervised\nsegmentation, it contains several advanced components tailored for learning\nfrom imperfect annotations, such as loading annotated and unannounced images,\nloss functions for unannotated, partially or inaccurately annotated images, and\ntraining procedures for co-learning between multiple networks, etc. PyMIC\nsupports development of semi-supervised, weakly supervised and noise-robust\nlearning methods for medical image segmentation.\n  Results: We present several illustrative medical image segmentation tasks\nbased on PyMIC: (1) Achieving competitive performance on fully supervised\nlearning; (2) Semi-supervised cardiac structure segmentation with only 10%\ntraining images annotated; (3) Weakly supervised segmentation using scribble\nannotations; and (4) Learning from noisy labels for chest radiograph\nsegmentation.\n  Conclusions: The PyMIC toolkit is easy to use and facilitates efficient\ndevelopment of medical image segmentation models with imperfect annotations. It\nis modular and flexible, which enables researchers to develop high-performance\nmodels with low annotation cost. The source code is available at:\nhttps://github.com/HiLab-git/PyMIC.\n",
                "链接": "https://arxiv.org/abs/2208.09350"
            },
            {
                "文章ID": "14738",
                "标题": "Rapid model transfer for medical image segmentation via iterative\n  human-in-the-loop update: from labelled public to unlabelled clinical\n  datasets for multi-organ segmentation in CT",
                "作者": " Wenao Ma,  Shuang Zheng,  Lei Zhang,  Huimao Zhang,  Qi Dou",
                "发布日期": "2022-04-14",
                "摘要": "  Despite the remarkable success on medical image analysis with deep learning,\nit is still under exploration regarding how to rapidly transfer AI models from\none dataset to another for clinical applications. This paper presents a novel\nand generic human-in-the-loop scheme for efficiently transferring a\nsegmentation model from a small-scale labelled dataset to a larger-scale\nunlabelled dataset for multi-organ segmentation in CT. To achieve this, we\npropose to use an igniter network which can learn from a small-scale labelled\ndataset and generate coarse annotations to start the process of human-machine\ninteraction. Then, we use a sustainer network for our larger-scale dataset, and\niteratively updated it on the new annotated data. Moreover, we propose a\nflexible labelling strategy for the annotator to reduce the initial annotation\nworkload. The model performance and the time cost of annotation in each subject\nevaluated on our private dataset are reported and analysed. The results show\nthat our scheme can not only improve the performance by 19.7% on Dice, but also\nexpedite the cost time of manual labelling from 13.87 min to 1.51 min per CT\nvolume during the model transfer, demonstrating the clinical usefulness with\npromising potentials.\n",
                "链接": "https://arxiv.org/abs/2204.06243"
            },
            {
                "文章ID": "20042",
                "标题": "Generation of Artificial CT Images using Patch-based Conditional\n  Generative Adversarial Networks",
                "作者": " Marija Habijan,  Irena Galic",
                "发布日期": "2022-05-23",
                "摘要": "  Deep learning has a great potential to alleviate diagnosis and prognosis for\nvarious clinical procedures. However, the lack of a sufficient number of\nmedical images is the most common obstacle in conducting image-based analysis\nusing deep learning. Due to the annotations scarcity, semi-supervised\ntechniques in the automatic medical analysis are getting high attention.\nArtificial data augmentation and generation techniques such as generative\nadversarial networks (GANs) may help overcome this obstacle. In this work, we\npresent an image generation approach that uses generative adversarial networks\nwith a conditional discriminator where segmentation masks are used as\nconditions for image generation. We validate the feasibility of GAN-enhanced\nmedical image generation on whole heart computed tomography (CT) images and its\nseven substructures, namely: left ventricle, right ventricle, left atrium,\nright atrium, myocardium, pulmonary arteries, and aorta. Obtained results\ndemonstrate the suitability of the proposed adversarial approach for the\naccurate generation of high-quality CT images. The presented method shows great\npotential to facilitate further research in the domain of artificial medical\nimage generation.\n",
                "链接": "https://arxiv.org/abs/2205.09842"
            },
            {
                "文章ID": "95871",
                "标题": "Unleashing the Strengths of Unlabeled Data in Pan-cancer Abdominal Organ\n  Quantification: the FLARE22 Challenge",
                "作者": " Jun Ma,  Yao Zhang,  Song Gu,  Cheng Ge,  Shihao Ma,  Adamo Young,  Cheng Zhu,  Kangkang Meng,  Xin Yang,  Ziyan Huang,  Fan Zhang,  Wentao Liu,  YuanKe Pan,  Shoujin Huang,  Jiacheng Wang,  Mingze Sun,  Weixin Xu,  Dengqiang Jia,  Jae Won Choi,  Natália Alves,  Bram de Wilde,  Gregor Koehler,  Yajun Wu,  Manuel Wiesenfarth,  Qiongjie Zhu,  Guoqiang Dong,  Jian He,  the FLARE Challenge Consortium,  Bo Wang",
                "发布日期": "2023-08-14",
                "摘要": "  Quantitative organ assessment is an essential step in automated abdominal\ndisease diagnosis and treatment planning. Artificial intelligence (AI) has\nshown great potential to automatize this process. However, most existing AI\nalgorithms rely on many expert annotations and lack a comprehensive evaluation\nof accuracy and efficiency in real-world multinational settings. To overcome\nthese limitations, we organized the FLARE 2022 Challenge, the largest abdominal\norgan analysis challenge to date, to benchmark fast, low-resource, accurate,\nannotation-efficient, and generalized AI algorithms. We constructed an\nintercontinental and multinational dataset from more than 50 medical groups,\nincluding Computed Tomography (CT) scans with different races, diseases,\nphases, and manufacturers. We independently validated that a set of AI\nalgorithms achieved a median Dice Similarity Coefficient (DSC) of 90.0\\% by\nusing 50 labeled scans and 2000 unlabeled scans, which can significantly reduce\nannotation requirements. The best-performing algorithms successfully\ngeneralized to holdout external validation sets, achieving a median DSC of\n89.5\\%, 90.9\\%, and 88.3\\% on North American, European, and Asian cohorts,\nrespectively. They also enabled automatic extraction of key organ biology\nfeatures, which was labor-intensive with traditional manual measurements. This\nopens the potential to use unlabeled data to boost performance and alleviate\nannotation shortages for modern AI models.\n",
                "链接": "https://arxiv.org/abs/2308.05862"
            },
            {
                "文章ID": "78299",
                "标题": "DeepEdit: Deep Editable Learning for Interactive Segmentation of 3D\n  Medical Images",
                "作者": " Andres Diaz-Pinto,  Pritesh Mehta,  Sachidanand Alle,  Muhammad Asad,  Richard Brown,  Vishwesh Nath,  Alvin Ihsani,  Michela Antonelli,  Daniel Palkovics,  Csaba Pinter,  Ron Alkalay,  Steve Pieper,  Holger R. Roth,  Daguang Xu,  Prerna Dogra,  Tom Vercauteren,  Andrew Feng,  Abood Quraini,  Sebastien Ourselin,  M. Jorge Cardoso",
                "发布日期": "2023-11-22",
                "摘要": "  Automatic segmentation of medical images is a key step for diagnostic and\ninterventional tasks. However, achieving this requires large amounts of\nannotated volumes, which can be tedious and time-consuming task for expert\nannotators. In this paper, we introduce DeepEdit, a deep learning-based method\nfor volumetric medical image annotation, that allows automatic and\nsemi-automatic segmentation, and click-based refinement. DeepEdit combines the\npower of two methods: a non-interactive (i.e. automatic segmentation using\nnnU-Net, UNET or UNETR) and an interactive segmentation method (i.e. DeepGrow),\ninto a single deep learning model. It allows easy integration of\nuncertainty-based ranking strategies (i.e. aleatoric and epistemic uncertainty\ncomputation) and active learning. We propose and implement a method for\ntraining DeepEdit by using standard training combined with user interaction\nsimulation. Once trained, DeepEdit allows clinicians to quickly segment their\ndatasets by using the algorithm in auto segmentation mode or by providing\nclicks via a user interface (i.e. 3D Slicer, OHIF). We show the value of\nDeepEdit through evaluation on the PROSTATEx dataset for prostate/prostatic\nlesions and the Multi-Atlas Labeling Beyond the Cranial Vault (BTCV) dataset\nfor abdominal CT segmentation, using state-of-the-art network architectures as\nbaseline for comparison. DeepEdit could reduce the time and effort annotating\n3D medical images compared to DeepGrow alone. Source code is available at\nhttps://github.com/Project-MONAI/MONAILabel\n",
                "链接": "https://arxiv.org/abs/2305.10655"
            },
            {
                "文章ID": "42675",
                "标题": "Mention Annotations Alone Enable Efficient Domain Adaptation for\n  Coreference Resolution",
                "作者": " Nupoor Gandhi,  Anjalie Field,  Emma Strubell",
                "发布日期": "2023-06-01",
                "摘要": "  Although recent neural models for coreference resolution have led to\nsubstantial improvements on benchmark datasets, transferring these models to\nnew target domains containing out-of-vocabulary spans and requiring differing\nannotation schemes remains challenging. Typical approaches involve continued\ntraining on annotated target-domain data, but obtaining annotations is costly\nand time-consuming. We show that annotating mentions alone is nearly twice as\nfast as annotating full coreference chains. Accordingly, we propose a method\nfor efficiently adapting coreference models, which includes a high-precision\nmention detection objective and requires annotating only mentions in the target\ndomain. Extensive evaluation across three English coreference datasets:\nCoNLL-2012 (news/conversation), i2b2/VA (medical notes), and previously\nunstudied child welfare notes, reveals that our approach facilitates\nannotation-efficient transfer and results in a 7-14% improvement in average F1\nwithout increasing annotator time.\n",
                "链接": "https://arxiv.org/abs/2210.07602"
            },
            {
                "文章ID": "37698",
                "标题": "Weakly Supervised Medical Image Segmentation With Soft Labels and Noise\n  Robust Loss",
                "作者": " Banafshe Felfeliyan,  Abhilash Hareendranathan,  Gregor Kuntze,  Stephanie Wichuk,  Nils D. Forkert,  Jacob L. Jaremko,  Janet L. Ronsky",
                "发布日期": "2023-09-19",
                "摘要": "  Recent advances in deep learning algorithms have led to significant benefits\nfor solving many medical image analysis problems. Training deep learning models\ncommonly requires large datasets with expert-labeled annotations. However,\nacquiring expert-labeled annotation is not only expensive but also is\nsubjective, error-prone, and inter-/intra- observer variability introduces\nnoise to labels. This is particularly a problem when using deep learning models\nfor segmenting medical images due to the ambiguous anatomical boundaries.\nImage-based medical diagnosis tools using deep learning models trained with\nincorrect segmentation labels can lead to false diagnoses and treatment\nsuggestions. Multi-rater annotations might be better suited to train deep\nlearning models with small training sets compared to single-rater annotations.\nThe aim of this paper was to develop and evaluate a method to generate\nprobabilistic labels based on multi-rater annotations and anatomical knowledge\nof the lesion features in MRI and a method to train segmentation models using\nprobabilistic labels using normalized active-passive loss as a \"noise-tolerant\nloss\" function. The model was evaluated by comparing it to binary ground truth\nfor 17 knees MRI scans for clinical segmentation and detection of bone marrow\nlesions (BML). The proposed method successfully improved precision 14, recall\n22, and Dice score 8 percent compared to a binary cross-entropy loss function.\nOverall, the results of this work suggest that the proposed normalized\nactive-passive loss using soft labels successfully mitigated the effects of\nnoisy labels.\n",
                "链接": "https://arxiv.org/abs/2209.08172"
            }
        ]
    },
    {
        "question": {
            "question": "请找出最近一年内发表的关于自然语言处理领域中，使用Transformer模型并在大规模数据集上进行预训练的论文。特别关注模型结构和性能指标。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "107878",
                "标题": "Computational Pathology at Health System Scale -- Self-Supervised\n  Foundation Models from Three Billion Images",
                "作者": " Gabriele Campanella,  Ricky Kwan,  Eugene Fluder,  Jennifer Zeng,  Aryeh Stock,  Brandon Veremis,  Alexandros D. Polydorides,  Cyrus Hedvat,  Adam Schoenfeld,  Chad Vanderbilt,  Patricia Kovatch,  Carlos Cordon-Cardo,  Thomas J. Fuchs",
                "发布日期": "2023-10-12",
                "摘要": "  Recent breakthroughs in self-supervised learning have enabled the use of\nlarge unlabeled datasets to train visual foundation models that can generalize\nto a variety of downstream tasks. While this training paradigm is well suited\nfor the medical domain where annotations are scarce, large-scale pre-training\nin the medical domain, and in particular pathology, has not been extensively\nstudied. Previous work in self-supervised learning in pathology has leveraged\nsmaller datasets for both pre-training and evaluating downstream performance.\nThe aim of this project is to train the largest academic foundation model and\nbenchmark the most prominent self-supervised learning algorithms by\npre-training and evaluating downstream performance on large clinical pathology\ndatasets. We collected the largest pathology dataset to date, consisting of\nover 3 billion images from over 423 thousand microscopy slides. We compared\npre-training of visual transformer models using the masked autoencoder (MAE)\nand DINO algorithms. We evaluated performance on six clinically relevant tasks\nfrom three anatomic sites and two institutions: breast cancer detection,\ninflammatory bowel disease detection, breast cancer estrogen receptor\nprediction, lung adenocarcinoma EGFR mutation prediction, and lung cancer\nimmunotherapy response prediction. Our results demonstrate that pre-training on\npathology data is beneficial for downstream performance compared to\npre-training on natural images. Additionally, the DINO algorithm achieved\nbetter generalization performance across all tasks tested. The presented\nresults signify a phase change in computational pathology research, paving the\nway into a new era of more performant models based on large-scale, parallel\npre-training at the billion-image scale.\n",
                "链接": "https://arxiv.org/abs/2310.07033"
            },
            {
                "文章ID": "122302",
                "标题": "PAD: Self-Supervised Pre-Training with Patchwise-Scale Adapter for\n  Infrared Images",
                "作者": " Tao Zhang,  Kun Ding,  Jinyong Wen,  Yu Xiong,  Zeyu Zhang,  Shiming Xiang,  Chunhong Pan",
                "发布日期": "2023-12-14",
                "摘要": "  Self-supervised learning (SSL) for RGB images has achieved significant\nsuccess, yet there is still limited research on SSL for infrared images,\nprimarily due to three prominent challenges: 1) the lack of a suitable\nlarge-scale infrared pre-training dataset, 2) the distinctiveness of non-iconic\ninfrared images rendering common pre-training tasks like masked image modeling\n(MIM) less effective, and 3) the scarcity of fine-grained textures making it\nparticularly challenging to learn general image features. To address these\nissues, we construct a Multi-Scene Infrared Pre-training (MSIP) dataset\ncomprising 178,756 images, and introduce object-sensitive random RoI cropping,\nan image preprocessing method, to tackle the challenge posed by non-iconic\nimages. To alleviate the impact of weak textures on feature learning, we\npropose a pre-training paradigm called Pre-training with ADapter (PAD), which\nuses adapters to learn domain-specific features while freezing parameters\npre-trained on ImageNet to retain the general feature extraction capability.\nThis new paradigm is applicable to any transformer-based SSL method.\nFurthermore, to achieve more flexible coordination between pre-trained and\nnewly-learned features in different layers and patches, a patchwise-scale\nadapter with dynamically learnable scale factors is introduced. Extensive\nexperiments on three downstream tasks show that PAD, with only 1.23M\npre-trainable parameters, outperforms other baseline paradigms including\ncontinual full pre-training on MSIP. Our code and dataset are available at\nhttps://github.com/casiatao/PAD.\n",
                "链接": "https://arxiv.org/abs/2312.08192"
            },
            {
                "文章ID": "118333",
                "标题": "Efficient Pre-training for Localized Instruction Generation of Videos",
                "作者": " Anil Batra,  Davide Moltisanti,  Laura Sevilla-Lara,  Marcus Rohrbach,  Frank Keller",
                "发布日期": "2023-11-28",
                "摘要": "  Procedural videos show step-by-step demonstrations of tasks like recipe\npreparation. Understanding such videos is challenging, involving the precise\nlocalization of steps and the generation of textual instructions. Manually\nannotating steps and writing instructions is costly, which limits the size of\ncurrent datasets and hinders effective learning. Leveraging large but noisy\nvideo-transcript datasets for pre-training can boost performance, but demands\nsignificant computational resources. Furthermore, transcripts contain\nirrelevant content and exhibit style variation compared to instructions written\nby human annotators. To mitigate both issues, we propose a technique,\nSieve-&-Swap, to automatically curate a smaller dataset: (i) Sieve filters\nirrelevant transcripts and (ii) Swap enhances the quality of the text\ninstruction by automatically replacing the transcripts with human-written\ninstructions from a text-only recipe dataset. The curated dataset, three orders\nof magnitude smaller than current web-scale datasets, enables efficient\ntraining of large-scale models with competitive performance. We complement our\nSieve-\\&-Swap approach with a Procedure Transformer (ProcX) for end-to-end step\nlocalization and instruction generation for procedural videos. When this model\nis pre-trained on our curated dataset, it achieves state-of-the-art performance\nin zero-shot and finetuning settings on YouCook2 and Tasty, while using a\nfraction of the computational resources.\n",
                "链接": "https://arxiv.org/abs/2311.15964"
            },
            {
                "文章ID": "124090",
                "标题": "Unleashing Large-Scale Video Generative Pre-training for Visual Robot\n  Manipulation",
                "作者": " Hongtao Wu,  Ya Jing,  Chilam Cheang,  Guangzeng Chen,  Jiafeng Xu,  Xinghang Li,  Minghuan Liu,  Hang Li,  Tao Kong",
                "发布日期": "2023-12-22",
                "摘要": "  Generative pre-trained models have demonstrated remarkable effectiveness in\nlanguage and vision domains by learning useful representations. In this paper,\nwe extend the scope of this effectiveness by showing that visual robot\nmanipulation can significantly benefit from large-scale video generative\npre-training. We introduce GR-1, a straightforward GPT-style model designed for\nmulti-task language-conditioned visual robot manipulation. GR-1 takes as inputs\na language instruction, a sequence of observation images, and a sequence of\nrobot states. It predicts robot actions as well as future images in an\nend-to-end manner. Thanks to a flexible design, GR-1 can be seamlessly\nfinetuned on robot data after pre-trained on a large-scale video dataset. We\nperform extensive experiments on the challenging CALVIN benchmark and a real\nrobot. On CALVIN benchmark, our method outperforms state-of-the-art baseline\nmethods and improves the success rate from 88.9% to 94.9%. In the setting of\nzero-shot unseen scene generalization, GR-1 improves the success rate from\n53.3% to 85.4%. In real robot experiments, GR-1 also outperforms baseline\nmethods and shows strong potentials in generalization to unseen scenes and\nobjects. We provide inaugural evidence that a unified GPT-style transformer,\naugmented with large-scale video generative pre-training, exhibits remarkable\ngeneralization to multi-task visual robot manipulation. Project page:\nhttps://GR1-Manipulation.github.io\n",
                "链接": "https://arxiv.org/abs/2312.13139"
            },
            {
                "文章ID": "19946",
                "标题": "Integrally Migrating Pre-trained Transformer Encoder-decoders for Visual\n  Object Detection",
                "作者": " Feng Liu,  Xiaosong Zhang,  Zhiliang Peng,  Zonghao Guo,  Fang Wan,  Xiangyang Ji,  Qixiang Ye",
                "发布日期": "2023-12-22",
                "摘要": "  Modern object detectors have taken the advantages of backbone networks\npre-trained on large scale datasets. Except for the backbone networks, however,\nother components such as the detector head and the feature pyramid network\n(FPN) remain trained from scratch, which hinders fully tapping the potential of\nrepresentation models. In this study, we propose to integrally migrate\npre-trained transformer encoder-decoders (imTED) to a detector, constructing a\nfeature extraction path which is ``fully pre-trained\" so that detectors'\ngeneralization capacity is maximized. The essential differences between imTED\nwith the baseline detector are twofold: (1) migrating the pre-trained\ntransformer decoder to the detector head while removing the randomly\ninitialized FPN from the feature extraction path; and (2) defining a\nmulti-scale feature modulator (MFM) to enhance scale adaptability. Such designs\nnot only reduce randomly initialized parameters significantly but also unify\ndetector training with representation learning intendedly. Experiments on the\nMS COCO object detection dataset show that imTED consistently outperforms its\ncounterparts by $\\sim$2.4 AP. Without bells and whistles, imTED improves the\nstate-of-the-art of few-shot object detection by up to 7.6 AP. Code is\navailable at https://github.com/LiewFeng/imTED.\n",
                "链接": "https://arxiv.org/abs/2205.09613"
            },
            {
                "文章ID": "114004",
                "标题": "Asymmetric Masked Distillation for Pre-Training Small Foundation Models",
                "作者": " Zhiyu Zhao,  Bingkun Huang,  Sen Xing,  Gangshan Wu,  Yu Qiao,  Limin Wang",
                "发布日期": "2023-11-07",
                "摘要": "  Self-supervised foundation models have shown great potential in computer\nvision thanks to the pre-training paradigm of masked autoencoding. Scale is a\nprimary factor influencing the performance of these foundation models. However,\nthese large foundation models often result in high computational cost that\nmight limit their deployment. This paper focuses on pre-training relatively\nsmall vision transformer models that could be efficiently adapted to downstream\ntasks. Specifically, taking inspiration from knowledge distillation in model\ncompression, we propose a new asymmetric masked distillation(AMD) framework for\npre-training relatively small models with autoencoding. The core of AMD is to\ndevise an asymmetric masking strategy, where the teacher model is enabled to\nsee more context information with a lower masking ratio, while the student\nmodel still with high masking ratio to the original masked pre-training. We\ndesign customized multi-layer feature alignment between the teacher encoder and\nstudent encoder to regularize the pre-training of student MAE. To demonstrate\nthe effectiveness and versatility of AMD, we apply it to both ImageMAE and\nVideoMAE for pre-training relatively small ViT models. AMD achieved 84.6%\nclassification accuracy on IN1K using the ViT-B model. And AMD achieves 73.3%\nclassification accuracy using the ViT-B model on the Something-in-Something V2\ndataset, a 3.7% improvement over the original ViT-B model from VideoMAE. We\nalso transfer AMD pre-trained models to downstream tasks and obtain consistent\nperformance improvement over the standard pre-training.\n",
                "链接": "https://arxiv.org/abs/2311.03149"
            },
            {
                "文章ID": "117788",
                "标题": "Comparative Analysis of Transformers for Modeling Tabular Data: A\n  Casestudy using Industry Scale Dataset",
                "作者": " Usneek Singh,  Piyush Arora,  Shamika Ganesan,  Mohit Kumar,  Siddhant Kulkarni,  Salil R. Joshi",
                "发布日期": "2023-11-27",
                "摘要": "  We perform a comparative analysis of transformer-based models designed for\nmodeling tabular data, specifically on an industry-scale dataset. While earlier\nstudies demonstrated promising outcomes on smaller public or synthetic\ndatasets, the effectiveness did not extend to larger industry-scale datasets.\nThe challenges identified include handling high-dimensional data, the necessity\nfor efficient pre-processing of categorical and numerical features, and\naddressing substantial computational requirements.\n  To overcome the identified challenges, the study conducts an extensive\nexamination of various transformer-based models using both synthetic datasets\nand the default prediction Kaggle dataset (2022) from American Express. The\npaper presents crucial insights into optimal data pre-processing, compares\npre-training and direct supervised learning methods, discusses strategies for\nmanaging categorical and numerical features, and highlights trade-offs between\ncomputational resources and performance. Focusing on temporal financial data\nmodeling, the research aims to facilitate the systematic development and\ndeployment of transformer-based models in real-world scenarios, emphasizing\nscalability.\n",
                "链接": "https://arxiv.org/abs/2311.14335"
            },
            {
                "文章ID": "85092",
                "标题": "Multi-modal Pre-training for Medical Vision-language Understanding and\n  Generation: An Empirical Study with A New Benchmark",
                "作者": " Li Xu,  Bo Liu,  Ameer Hamza Khan,  Lu Fan,  Xiao-Ming Wu",
                "发布日期": "2023-08-25",
                "摘要": "  With the availability of large-scale, comprehensive, and general-purpose\nvision-language (VL) datasets such as MSCOCO, vision-language pre-training\n(VLP) has become an active area of research and proven to be effective for\nvarious VL tasks such as visual-question answering. However, studies on VLP in\nthe medical domain have so far been scanty. To provide a comprehensive\nperspective on VLP for medical VL tasks, we conduct a thorough experimental\nanalysis to study key factors that may affect the performance of VLP with a\nunified vision-language Transformer. To allow making sound and quick\npre-training decisions, we propose RadioGraphy Captions (RGC), a high-quality,\nmulti-modality radiographic dataset containing 18,434 image-caption pairs\ncollected from an open-access online database MedPix. RGC can be used as a\npre-training dataset or a new benchmark for medical report generation and\nmedical image-text retrieval. By utilizing RGC and other available datasets for\npre-training, we develop several key insights that can guide future medical VLP\nresearch and new strong baselines for various medical VL tasks.\n",
                "链接": "https://arxiv.org/abs/2306.06494"
            },
            {
                "文章ID": "77855",
                "标题": "NightHazeFormer: Single Nighttime Haze Removal Using Prior Query\n  Transformer",
                "作者": " Yun Liu,  Zhongsheng Yan,  Sixiang Chen,  Tian Ye,  Wenqi Ren,  Erkang Chen",
                "发布日期": "2023-08-15",
                "摘要": "  Nighttime image dehazing is a challenging task due to the presence of\nmultiple types of adverse degrading effects including glow, haze, blurry,\nnoise, color distortion, and so on. However, most previous studies mainly focus\non daytime image dehazing or partial degradations presented in nighttime hazy\nscenes, which may lead to unsatisfactory restoration results. In this paper, we\npropose an end-to-end transformer-based framework for nighttime haze removal,\ncalled NightHazeFormer. Our proposed approach consists of two stages:\nsupervised pre-training and semi-supervised fine-tuning. During the\npre-training stage, we introduce two powerful priors into the transformer\ndecoder to generate the non-learnable prior queries, which guide the model to\nextract specific degradations. For the fine-tuning, we combine the generated\npseudo ground truths with input real-world nighttime hazy images as paired\nimages and feed into the synthetic domain to fine-tune the pre-trained model.\nThis semi-supervised fine-tuning paradigm helps improve the generalization to\nreal domain. In addition, we also propose a large-scale synthetic dataset\ncalled UNREAL-NH, to simulate the real-world nighttime haze scenarios\ncomprehensively. Extensive experiments on several synthetic and real-world\ndatasets demonstrate the superiority of our NightHazeFormer over\nstate-of-the-art nighttime haze removal methods in terms of both visually and\nquantitatively.\n",
                "链接": "https://arxiv.org/abs/2305.09533"
            },
            {
                "文章ID": "58902",
                "标题": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image\n  Encoders and Large Language Models",
                "作者": " Junnan Li,  Dongxu Li,  Silvio Savarese,  Steven Hoi",
                "发布日期": "2023-06-16",
                "摘要": "  The cost of vision-and-language pre-training has become increasingly\nprohibitive due to end-to-end training of large-scale models. This paper\nproposes BLIP-2, a generic and efficient pre-training strategy that bootstraps\nvision-language pre-training from off-the-shelf frozen pre-trained image\nencoders and frozen large language models. BLIP-2 bridges the modality gap with\na lightweight Querying Transformer, which is pre-trained in two stages. The\nfirst stage bootstraps vision-language representation learning from a frozen\nimage encoder. The second stage bootstraps vision-to-language generative\nlearning from a frozen language model. BLIP-2 achieves state-of-the-art\nperformance on various vision-language tasks, despite having significantly\nfewer trainable parameters than existing methods. For example, our model\noutperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable\nparameters. We also demonstrate the model's emerging capabilities of zero-shot\nimage-to-text generation that can follow natural language instructions.\n",
                "链接": "https://arxiv.org/abs/2301.12597"
            }
        ]
    },
    {
        "question": {
            "question": "请查找关于智能体的研究进展的综述或调查论文。重点关注不同领域中智能体的方法和应用，以及相关的挑战和未来方向。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "68556",
                "标题": "TinyML: Tools, Applications, Challenges, and Future Research Directions",
                "作者": " Rakhee Kallimani,  Krishna Pai,  Prasoon Raghuwanshi,  Sridhar Iyer,  Onel L. A. López",
                "发布日期": "2023-09-08",
                "摘要": "  In recent years, Artificial Intelligence (AI) and Machine learning (ML) have\ngained significant interest from both, industry and academia. Notably,\nconventional ML techniques require enormous amounts of power to meet the\ndesired accuracy, which has limited their use mainly to high-capability devices\nsuch as network nodes. However, with many advancements in technologies such as\nthe Internet of Things (IoT) and edge computing, it is desirable to incorporate\nML techniques into resource-constrained embedded devices for distributed and\nubiquitous intelligence. This has motivated the emergence of the TinyML\nparadigm which is an embedded ML technique that enables ML applications on\nmultiple cheap, resource- and power-constrained devices. However, during this\ntransition towards appropriate implementation of the TinyML technology,\nmultiple challenges such as processing capacity optimization, improved\nreliability, and maintenance of learning models' accuracy require timely\nsolutions. In this article, various avenues available for TinyML implementation\nare reviewed. Firstly, a background of TinyML is provided, followed by detailed\ndiscussions on various tools supporting TinyML. Then, state-of-art applications\nof TinyML using advanced technologies are detailed. Lastly, various research\nchallenges and future directions are identified.\n",
                "链接": "https://arxiv.org/abs/2303.13569"
            },
            {
                "文章ID": "119748",
                "标题": "A Survey of Progress on Cooperative Multi-agent Reinforcement Learning\n  in Open Environment",
                "作者": " Lei Yuan,  Ziqian Zhang,  Lihe Li,  Cong Guan,  Yang Yu",
                "发布日期": "2023-12-05",
                "摘要": "  Multi-agent Reinforcement Learning (MARL) has gained wide attention in recent\nyears and has made progress in various fields. Specifically, cooperative MARL\nfocuses on training a team of agents to cooperatively achieve tasks that are\ndifficult for a single agent to handle. It has shown great potential in\napplications such as path planning, autonomous driving, active voltage control,\nand dynamic algorithm configuration. One of the research focuses in the field\nof cooperative MARL is how to improve the coordination efficiency of the\nsystem, while research work has mainly been conducted in simple, static, and\nclosed environment settings. To promote the application of artificial\nintelligence in real-world, some research has begun to explore multi-agent\ncoordination in open environments. These works have made progress in exploring\nand researching the environments where important factors might change. However,\nthe mainstream work still lacks a comprehensive review of the research\ndirection. In this paper, starting from the concept of reinforcement learning,\nwe subsequently introduce multi-agent systems (MAS), cooperative MARL, typical\nmethods, and test environments. Then, we summarize the research work of\ncooperative MARL from closed to open environments, extract multiple research\ndirections, and introduce typical works. Finally, we summarize the strengths\nand weaknesses of the current research, and look forward to the future\ndevelopment direction and research problems in cooperative MARL in open\nenvironments.\n",
                "链接": "https://arxiv.org/abs/2312.01058"
            },
            {
                "文章ID": "115918",
                "标题": "Applications of Computer Vision in Autonomous Vehicles: Methods,\n  Challenges and Future Directions",
                "作者": " Xingshuai Dong,  Massimiliano L. Cappuccio",
                "发布日期": "2023-11-17",
                "摘要": "  Autonomous vehicle refers to a vehicle capable of perceiving its surrounding\nenvironment and driving with little or no human driver input. The perception\nsystem is a fundamental component which enables the autonomous vehicle to\ncollect data and extract relevant information from the environment to drive\nsafely. Benefit from the recent advances in computer vision, the perception\ntask can be achieved by using sensors, such as camera, LiDAR, radar, and\nultrasonic sensor. This paper reviews publications on computer vision and\nautonomous driving that are published during the last ten years. In particular,\nwe first investigate the development of autonomous driving systems and\nsummarize these systems that are developed by the major automotive\nmanufacturers from different countries. Second, we investigate the sensors and\nbenchmark data sets that are commonly utilized for autonomous driving. Then, a\ncomprehensive overview of computer vision applications for autonomous driving\nsuch as depth estimation, object detection, lane detection, and traffic sign\nrecognition are discussed. Additionally, we review public opinions and concerns\non autonomous vehicles. Based on the discussion, we analyze the current\ntechnological challenges that autonomous vehicles meet with. Finally, we\npresent our insights and point out some promising directions for future\nresearch. This paper will help the reader to understand autonomous vehicles\nfrom the perspectives of academia and industry.\n",
                "链接": "https://arxiv.org/abs/2311.09093"
            },
            {
                "文章ID": "117114",
                "标题": "A Survey of Graph Meets Large Language Model: Progress and Future\n  Directions",
                "作者": " Yuhan Li,  Zhixun Li,  Peisong Wang,  Jia Li,  Xiangguo Sun,  Hong Cheng,  Jeffrey Xu Yu",
                "发布日期": "2023-11-29",
                "摘要": "  Graph plays a significant role in representing and analyzing complex\nrelationships in real-world applications such as citation networks, social\nnetworks, and biological data. Recently, Large Language Models (LLMs), which\nhave achieved tremendous success in various domains, have also been leveraged\nin graph-related tasks to surpass traditional Graph Neural Networks (GNNs)\nbased methods and yield state-of-the-art performance. In this survey, we first\npresent a comprehensive review and analysis of existing methods that integrate\nLLMs with graphs. First of all, we propose a new taxonomy, which organizes\nexisting methods into three categories based on the role (i.e., enhancer,\npredictor, and alignment component) played by LLMs in graph-related tasks. Then\nwe systematically survey the representative methods along the three categories\nof the taxonomy. Finally, we discuss the remaining limitations of existing\nstudies and highlight promising avenues for future research. The relevant\npapers are summarized and will be consistently updated at:\nhttps://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.\n",
                "链接": "https://arxiv.org/abs/2311.12399"
            },
            {
                "文章ID": "123433",
                "标题": "A review of federated learning in renewable energy applications:\n  Potential, challenges, and future directions",
                "作者": " Albin Grataloup,  Stefan Jonas,  Angela Meyer",
                "发布日期": "2023-12-19",
                "摘要": "  Federated learning has recently emerged as a privacy-preserving distributed\nmachine learning approach. Federated learning enables collaborative training of\nmultiple clients and entire fleets without sharing the involved training\ndatasets. By preserving data privacy, federated learning has the potential to\novercome the lack of data sharing in the renewable energy sector which is\ninhibiting innovation, research and development. Our paper provides an overview\nof federated learning in renewable energy applications. We discuss federated\nlearning algorithms and survey their applications and case studies in renewable\nenergy generation and consumption. We also evaluate the potential and the\nchallenges associated with federated learning applied in power and energy\ncontexts. Finally, we outline promising future research directions in federated\nlearning for applications in renewable energy.\n",
                "链接": "https://arxiv.org/abs/2312.11220"
            },
            {
                "文章ID": "86534",
                "标题": "Advancing Biomedicine with Graph Representation Learning: Recent\n  Progress, Challenges, and Future Directions",
                "作者": " Fang Li,  Yi Nian,  Zenan Sun,  Cui Tao",
                "发布日期": "2023-06-22",
                "摘要": "  Graph representation learning (GRL) has emerged as a pivotal field that has\ncontributed significantly to breakthroughs in various fields, including\nbiomedicine. The objective of this survey is to review the latest advancements\nin GRL methods and their applications in the biomedical field. We also\nhighlight key challenges currently faced by GRL and outline potential\ndirections for future research.\n",
                "链接": "https://arxiv.org/abs/2306.10456"
            },
            {
                "文章ID": "87697",
                "标题": "Semi-supervised Object Detection: A Survey on Recent Research and\n  Progress",
                "作者": " Yanyang Wang,  Zhaoxiang Liu,  Shiguo Lian",
                "发布日期": "2023-06-27",
                "摘要": "  In recent years, deep learning technology has been maturely applied in the\nfield of object detection, and most algorithms tend to be supervised learning.\nHowever, a large amount of labeled data requires high costs of human resources,\nwhich brings about low efficiency and limitations. Semi-supervised object\ndetection (SSOD) has been paid more and more attentions due to its high\nresearch value and practicability. It is designed to learn information by using\nsmall amounts of labeled data and large amounts of unlabeled data. In this\npaper, we present a comprehensive and up-to-date survey on the SSOD approaches\nfrom five aspects. We first briefly introduce several ways of data\naugmentation. Then, we dive the mainstream semi-supervised strategies into\npseudo labels, consistent regularization, graph based and transfer learning\nbased methods, and introduce some methods in challenging settings. We further\npresent widely-used loss functions, and then we outline the common benchmark\ndatasets and compare the accuracy among different representative approaches.\nFinally, we conclude this paper and present some promising research directions\nfor the future. Our survey aims to provide researchers and practitioners new to\nthe field as well as more advanced readers with a solid understanding of the\nmain approaches developed over the past few years.\n",
                "链接": "https://arxiv.org/abs/2306.14106"
            },
            {
                "文章ID": "19909",
                "标题": "Federated learning: Applications, challenges and future directions",
                "作者": " Subrato Bharati,  M. Rubaiyat Hossain Mondal,  Prajoy Podder,  V. B. Surya Prasath",
                "发布日期": "2022-06-27",
                "摘要": "  Federated learning (FL) is a system in which a central aggregator coordinates\nthe efforts of multiple clients to solve machine learning problems. This\nsetting allows training data to be dispersed in order to protect privacy. The\npurpose of this paper is to provide an overview of FL systems with a focus on\nhealthcare. FL is evaluated here based on its frameworks, architectures, and\napplications. It is shown here that FL solves the preceding issues with a\nshared global deep learning (DL) model via a central aggregator server. This\npaper examines recent developments and provides a comprehensive list of\nunresolved issues, inspired by the rapid growth of FL research. In the context\nof FL, several privacy methods are described, including secure multiparty\ncomputation, homomorphic encryption, differential privacy, and stochastic\ngradient descent. Furthermore, a review of various FL classes, such as\nhorizontal and vertical FL and federated transfer learning, is provided. FL has\napplications in wireless communication, service recommendation, intelligent\nmedical diagnosis systems, and healthcare, all of which are discussed in this\npaper. We also present a thorough review of existing FL challenges, such as\nprivacy protection, communication cost, system heterogeneity, and unreliable\nmodel upload, followed by future research directions.\n",
                "链接": "https://arxiv.org/abs/2205.09513"
            },
            {
                "文章ID": "54318",
                "标题": "The Decades Progress on Code-Switching Research in NLP: A Systematic\n  Survey on Trends and Challenges",
                "作者": " Genta Indra Winata,  Alham Fikri Aji,  Zheng-Xin Yong,  Thamar Solorio",
                "发布日期": "2023-05-26",
                "摘要": "  Code-Switching, a common phenomenon in written text and conversation, has\nbeen studied over decades by the natural language processing (NLP) research\ncommunity. Initially, code-switching is intensively explored by leveraging\nlinguistic theories and, currently, more machine-learning oriented approaches\nto develop models. We introduce a comprehensive systematic survey on\ncode-switching research in natural language processing to understand the\nprogress of the past decades and conceptualize the challenges and tasks on the\ncode-switching topic. Finally, we summarize the trends and findings and\nconclude with a discussion for future direction and open questions for further\ninvestigation.\n",
                "链接": "https://arxiv.org/abs/2212.09660"
            },
            {
                "文章ID": "64747",
                "标题": "Backdoor Attacks and Defenses in Federated Learning: Survey, Challenges\n  and Future Research Directions",
                "作者": " Thuy Dung Nguyen,  Tuan Nguyen,  Phi Le Nguyen,  Hieu H. Pham,  Khoa Doan,  Kok-Seng Wong",
                "发布日期": "2023-03-07",
                "摘要": "  Federated learning (FL) is a machine learning (ML) approach that allows the\nuse of distributed data without compromising personal privacy. However, the\nheterogeneous distribution of data among clients in FL can make it difficult\nfor the orchestration server to validate the integrity of local model updates,\nmaking FL vulnerable to various threats, including backdoor attacks. Backdoor\nattacks involve the insertion of malicious functionality into a targeted model\nthrough poisoned updates from malicious clients. These attacks can cause the\nglobal model to misbehave on specific inputs while appearing normal in other\ncases. Backdoor attacks have received significant attention in the literature\ndue to their potential to impact real-world deep learning applications.\nHowever, they have not been thoroughly studied in the context of FL. In this\nsurvey, we provide a comprehensive survey of current backdoor attack strategies\nand defenses in FL, including a comprehensive analysis of different approaches.\nWe also discuss the challenges and potential future directions for attacks and\ndefenses in the context of FL.\n",
                "链接": "https://arxiv.org/abs/2303.02213"
            }
        ]
    }
]