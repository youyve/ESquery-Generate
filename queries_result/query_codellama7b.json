[
    {
        "question": {
            "question": "与大模型工具学习相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "和大模型可解释相关的最新论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找关于大模型Agent应用的最新发表论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找论文中包含指令微调细节描述的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找OCR文本检测最新进展",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找OCR文本识别最新进展。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "近几个月agent系列决策文章。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "与大模型安全相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大模型推理的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "近几个月自然语言处理相关的文章。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找多语言情感分析的最新论文。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "找一下最近关于大模型评测的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "近一个月与多模态大模型相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找近六个月工具学习评测数据集的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下工具评测相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "大模型在游戏方面的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "请找到缓和噪声标签影响的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "64530",
                "标题": "MiShape: 3D Shape Modelling of Mitochondria in Microscopy",
                "作者": " Abhinanda R. Punnakkal,  Suyog S Jadhav,  Alexander Horsch,  Krishna Agarwal,  Dilip K. Prasad",
                "发布日期": "2023-03-06",
                "摘要": "  Fluorescence microscopy is a quintessential tool for observing cells and\nunderstanding the underlying mechanisms of life-sustaining processes of all\nliving organisms. The problem of extracting 3D shape of mitochondria from\nfluorescence microscopy images remains unsolved due to the complex and varied\nshapes expressed by mitochondria and the poor resolving capacity of these\nmicroscopes. We propose an approach to bridge this gap by learning a shape\nprior for mitochondria termed as MiShape, by leveraging high-resolution\nelectron microscopy data. MiShape is a generative model learned using implicit\nrepresentations of mitochondrial shapes. It provides a shape distribution that\ncan be used to generate infinite realistic mitochondrial shapes. We demonstrate\nthe representation power of MiShape and its utility for 3D shape reconstruction\ngiven a single 2D fluorescence image or a small 3D stack of 2D slices. We also\nshowcase applications of our method by deriving simulated fluorescence\nmicroscope datasets that have realistic 3D ground truths for the problem of 2D\nsegmentation and microscope-to-microscope transformation.\n",
                "链接": "https://arxiv.org/abs/2303.01546"
            },
            {
                "文章ID": "23072",
                "标题": "Semi-Supervised Segmentation of Mitochondria from Electron Microscopy\n  Images Using Spatial Continuity",
                "作者": " Yunpeng Xiao,  Youpeng Zhao,  Ge Yang",
                "发布日期": "2022-06-16",
                "摘要": "  Morphology of mitochondria plays critical roles in mediating their\nphysiological functions. Accurate segmentation of mitochondria from 3D electron\nmicroscopy (EM) images is essential to quantitative characterization of their\nmorphology at the nanometer scale. Fully supervised deep learning models\ndeveloped for this task achieve excellent performance but require substantial\namounts of annotated data for training. However, manual annotation of EM images\nis laborious and time-consuming because of their large volumes, limited\ncontrast, and low signal-to-noise ratios (SNRs). To overcome this challenge, we\npropose a semi-supervised deep learning model that segments mitochondria by\nleveraging the spatial continuity of their structural, morphological, and\ncontextual information in both labeled and unlabeled images. We use random\npiecewise affine transformation to synthesize comprehensive and realistic\nmitochondrial morphology for augmentation of training data. Experiments on the\nEPFL dataset show that our model achieves performance similar as that of\nstate-of-the-art fully supervised models but requires only ~20% of their\nannotated training data. Our semi-supervised model is versatile and can also\naccurately segment other spatially continuous structures from EM images. Data\nand code of this study are openly accessible at\nhttps://github.com/cbmi-group/MPP.\n",
                "链接": "https://arxiv.org/abs/2206.02392"
            },
            {
                "文章ID": "66371",
                "标题": "Transformer Models for Acute Brain Dysfunction Prediction",
                "作者": " Brandon Silva,  Miguel Contreras,  Tezcan Ozrazgat Baslanti,  Yuanfang Ren,  Guan Ziyuan,  Kia Khezeli,  Azra Bihorac,  Parisa Rashidi",
                "发布日期": "2023-03-14",
                "摘要": "  Acute brain dysfunctions (ABD), which include coma and delirium, are\nprevalent in the ICU, especially among older patients. The current approach in\nmanual assessment of ABD by care providers may be sporadic and subjective.\nHence, there exists a need for a data-driven robust system automating the\nassessment and prediction of ABD. In this work, we develop a machine learning\nsystem for real-time prediction of ADB using Electronic Health Record (HER)\ndata. Our data processing pipeline enables integration of static and temporal\ndata, and extraction of features relevant to ABD. We train several\nstate-of-the-art transformer models and baseline machine learning models\nincluding CatBoost and XGB on the data that was collected from patients\nadmitted to the ICU at UF Shands Hospital. We demonstrate the efficacy of our\nsystem for tasks related to acute brain dysfunction including binary\nclassification of brain acuity and multi-class classification (i.e., coma,\ndelirium, death, or normal), achieving a mean AUROC of 0.953 on our Long-former\nimplementation. Our system can then be deployed for real-time prediction of ADB\nin ICUs to reduce the number of incidents caused by ABD. Moreover, the\nreal-time system has the potential to reduce costs, duration of patients stays\nin the ICU, and mortality among those afflicted.\n",
                "链接": "https://arxiv.org/abs/2303.07305"
            },
            {
                "文章ID": "46070",
                "标题": "Explainable Deep Learning to Profile Mitochondrial Disease Using High\n  Dimensional Protein Expression Data",
                "作者": " Atif Khan,  Conor Lawless,  Amy E Vincent,  Satish Pilla,  Sushanth Ramesh,  A. Stephen McGough",
                "发布日期": "2022-11-01",
                "摘要": "  Mitochondrial diseases are currently untreatable due to our limited\nunderstanding of their pathology. We study the expression of various\nmitochondrial proteins in skeletal myofibres (SM) in order to discover\nprocesses involved in mitochondrial pathology using Imaging Mass Cytometry\n(IMC). IMC produces high dimensional multichannel pseudo-images representing\nspatial variation in the expression of a panel of proteins within a tissue,\nincluding subcellular variation. Statistical analysis of these images requires\nsemi-automated annotation of thousands of SMs in IMC images of patient muscle\nbiopsies. In this paper we investigate the use of deep learning (DL) on raw IMC\ndata to analyse it without any manual pre-processing steps, statistical\nsummaries or statistical models. For this we first train state-of-art computer\nvision DL models on all available image channels, both combined and\nindividually. We observed better than expected accuracy for many of these\nmodels. We then apply state-of-the-art explainable techniques relevant to\ncomputer vision DL to find the basis of the predictions of these models. Some\nof the resulting visual explainable maps highlight features in the images that\nappear consistent with the latest hypotheses about mitochondrial disease\nprogression within myofibres.\n",
                "链接": "https://arxiv.org/abs/2210.17360"
            },
            {
                "文章ID": "101413",
                "标题": "Maxwell's Current in Mitochondria and Nerve",
                "作者": " Robert S. Eisenberg",
                "发布日期": "2023-09-29",
                "摘要": "  Maxwell defined true current in a way not widely used today. He said that\n\"... true electric current ... is not the same thing as the current of\nconduction but that the time-variation of the electric displacement must be\ntaken into account in estimating the total movement of electricity\". We show\nthat true current is a universal property independent of properties of matter,\nshown using mathematics without approximate dielectric constants. The resulting\nMaxwell Current Law is a generalization of the Kirchhoff Law of Current of\ncircuits, that also includes displacement current. Engineers introduce\ndisplacement current through supplementary 'stray capacitances'. The Maxwell\nCurrent Law does not require currents to be confined to circuits. It can be\napplied to three dimensional systems like mitochondria and nerve cells. The\nMaxwell Current Law clarifies the flow of electrons, protons, and ions in\nmitochondria that generate ATP, the molecule used to store chemical energy\nthroughout life. The currents are globally coupled because mitochondria are\nshort. The Maxwell Current Law approach reinterprets the classical chemiosmotic\nhypothesis of ATP production. The conduction current of protons in mitochondria\nis driven by the protonmotive force including its component electrical\npotential, just as in the classical chemiosmotic hypothesis. Conduction current\nis, however, just a part of the true current analyzed by Maxwell. Maxwell's\ncurrent does not accumulate, in contrast to the conduction current of protons\nwhich does accumulate. Details of accumulation do not appear in the true\ncurrent.\n  The treatment here allows the chemiosmotic hypothesis to take advantage of\nknowledge of current flow in physical and engineering sciences, particularly\nKirchhoff and Maxwell Current Laws. Knowing the current means knowing an\nimportant part of the mechanism of ATP synthesis.\n",
                "链接": "https://arxiv.org/abs/2309.05667"
            },
            {
                "文章ID": "65758",
                "标题": "Computable Phenotypes to Characterize Changing Patient Brain Dysfunction\n  in the Intensive Care Unit",
                "作者": "1 and 2  Yuanfang Ren, 1 and 3  Tyler J. Loftus, 1 and\n  2  Ziyuan Guan, 1 and 2  Rayon Uddin, 1 and 2  Benjamin Shickel, 1 and 5  Carolina B. Maciel, 1 and 5  Katharina Busl, 1 and 5  Parisa Rashidi, 1 and 2  Azra Bihorac, 1 and 2  Tezcan Ozrazgat-Baslanti",
                "发布日期": "2023-03-10",
                "摘要": "  In the United States, more than 5 million patients are admitted annually to\nICUs, with ICU mortality of 10%-29% and costs over $82 billion. Acute brain\ndysfunction status, delirium, is often underdiagnosed or undervalued. This\nstudy's objective was to develop automated computable phenotypes for acute\nbrain dysfunction states and describe transitions among brain dysfunction\nstates to illustrate the clinical trajectories of ICU patients. We created two\nsingle-center, longitudinal EHR datasets for 48,817 adult patients admitted to\nan ICU at UFH Gainesville (GNV) and Jacksonville (JAX). We developed algorithms\nto quantify acute brain dysfunction status including coma, delirium, normal, or\ndeath at 12-hour intervals of each ICU admission and to identify acute brain\ndysfunction phenotypes using continuous acute brain dysfunction status and\nk-means clustering approach. There were 49,770 admissions for 37,835 patients\nin UFH GNV dataset and 18,472 admissions for 10,982 patients in UFH JAX\ndataset. In total, 18% of patients had coma as the worst brain dysfunction\nstatus; every 12 hours, around 4%-7% would transit to delirium, 22%-25% would\nrecover, 3%-4% would expire, and 67%-68% would remain in a coma in the ICU.\nAdditionally, 7% of patients had delirium as the worst brain dysfunction\nstatus; around 6%-7% would transit to coma, 40%-42% would be no delirium, 1%\nwould expire, and 51%-52% would remain delirium in the ICU. There were three\nphenotypes: persistent coma/delirium, persistently normal, and transition from\ncoma/delirium to normal almost exclusively in first 48 hours after ICU\nadmission. We developed phenotyping scoring algorithms that determined acute\nbrain dysfunction status every 12 hours while admitted to the ICU. This\napproach may be useful in developing prognostic and decision-support tools to\naid patients and clinicians in decision-making on resource use and escalation\nof care.\n",
                "链接": "https://arxiv.org/abs/2303.05504"
            },
            {
                "文章ID": "67999",
                "标题": "3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers",
                "作者": " Omkar Thawakar,  Rao Muhammad Anwer,  Jorma Laaksonen,  Orly Reiner,  Mubarak Shah,  Fahad Shahbaz Khan",
                "发布日期": "2023-03-22",
                "摘要": "  Accurate 3D mitochondria instance segmentation in electron microscopy (EM) is\na challenging problem and serves as a prerequisite to empirically analyze their\ndistributions and morphology. Most existing approaches employ 3D convolutions\nto obtain representative features. However, these convolution-based approaches\nstruggle to effectively capture long-range dependencies in the volume\nmitochondria data, due to their limited local receptive field. To address this,\nwe propose a hybrid encoder-decoder framework based on a split spatio-temporal\nattention module that efficiently computes spatial and temporal self-attentions\nin parallel, which are later fused through a deformable convolution. Further,\nwe introduce a semantic foreground-background adversarial loss during training\nthat aids in delineating the region of mitochondria instances from the\nbackground clutter. Our extensive experiments on three benchmarks, Lucchi,\nMitoEM-R and MitoEM-H, reveal the benefits of the proposed contributions\nachieving state-of-the-art results on all three datasets. Our code and models\nare available at https://github.com/OmkarThawakar/STT-UNET.\n",
                "链接": "https://arxiv.org/abs/2303.12073"
            },
            {
                "文章ID": "6566",
                "标题": "Deep learning based domain adaptation for mitochondria segmentation on\n  EM volumes",
                "作者": " Daniel Franco-Barranco,  Julio Pastor-Tronch,  Aitor Gonzalez-Marfil,  Arrate Muñoz-Barrutia,  Ignacio Arganda-Carreras",
                "发布日期": "2022-07-06",
                "摘要": "  Accurate segmentation of electron microscopy (EM) volumes of the brain is\nessential to characterize neuronal structures at a cell or organelle level.\nWhile supervised deep learning methods have led to major breakthroughs in that\ndirection during the past years, they usually require large amounts of\nannotated data to be trained, and perform poorly on other data acquired under\nsimilar experimental and imaging conditions. This is a problem known as domain\nadaptation, since models that learned from a sample distribution (or source\ndomain) struggle to maintain their performance on samples extracted from a\ndifferent distribution or target domain. In this work, we address the complex\ncase of deep learning based domain adaptation for mitochondria segmentation\nacross EM datasets from different tissues and species. We present three\nunsupervised domain adaptation strategies to improve mitochondria segmentation\nin the target domain based on (1) state-of-the-art style transfer between\nimages of both domains; (2) self-supervised learning to pre-train a model using\nunlabeled source and target images, and then fine-tune it only with the source\nlabels; and (3) multi-task neural network architectures trained end-to-end with\nboth labeled and unlabeled images. Additionally, we propose a new training\nstopping criterion based on morphological priors obtained exclusively in the\nsource domain. We carried out all possible cross-dataset experiments using\nthree publicly available EM datasets. We evaluated our proposed strategies on\nthe mitochondria semantic labels predicted on the target datasets. The methods\nintroduced here outperform the baseline methods and compare favorably to the\nstate of the art. In the absence of validation labels, monitoring our proposed\nmorphology-based metric is an intuitive and effective way to stop the training\nprocess and select in average optimal models.\n",
                "链接": "https://arxiv.org/abs/2202.10773"
            },
            {
                "文章ID": "105009",
                "标题": "Cognizance of Post-COVID-19 Multi-Organ Dysfunction through Machine\n  Learning Analysis",
                "作者": " Hector J. Castro,  Maitham G. Yousif",
                "发布日期": "2023-10-02",
                "摘要": "  In the year 2022, a total of 466 patients from various cities across Iraq\nwere included in this study. This research paper focuses on the application of\nmachine learning techniques to analyse and predict multi-organ dysfunction in\nindividuals experiencing Post-COVID-19 Syndrome, commonly known as Long COVID.\nPost-COVID-19 Syndrome presents a wide array of persistent symptoms affecting\nvarious organ systems, posing a significant challenge to healthcare. Leveraging\nthe power of artificial intelligence, this study aims to enhance early\ndetection and management of this complex condition. The paper outlines the\nimportance of data collection and preprocessing, feature selection and\nengineering, model development and validation, and ethical considerations in\nconducting research in this field. By improving our understanding of\nPost-COVID-19 Syndrome through machine learning, healthcare providers can\nidentify at-risk individuals and offer timely interventions, potentially\nimproving patient outcomes and quality of life. Further research is essential\nto refine models, validate their clinical utility, and explore treatment\noptions for Long COVID. Keywords: Post-COVID-19 Syndrome, Machine Learning,\nMulti-Organ Dysfunction, Healthcare, Artificial Intelligence.\n",
                "链接": "https://arxiv.org/abs/2309.16736"
            },
            {
                "文章ID": "48784",
                "标题": "Normative Modeling via Conditional Variational Autoencoder and\n  Adversarial Learning to Identify Brain Dysfunction in Alzheimer's Disease",
                "作者": " Xuetong Wang,  Kanhao Zhao,  Rong Zhou,  Alex Leow,  Ricardo Osorio,  Yu Zhang,  Lifang He",
                "发布日期": "2022-11-17",
                "摘要": "  Normative modeling is an emerging and promising approach to effectively study\ndisorder heterogeneity in individual participants. In this study, we propose a\nnovel normative modeling method by combining conditional variational\nautoencoder with adversarial learning (ACVAE) to identify brain dysfunction in\nAlzheimer's Disease (AD). Specifically, we first train a conditional VAE on the\nhealthy control (HC) group to create a normative model conditioned on\ncovariates like age, gender and intracranial volume. Then we incorporate an\nadversarial training process to construct a discriminative feature space that\ncan better generalize to unseen data. Finally, we compute deviations from the\nnormal criterion at the patient level to determine which brain regions were\nassociated with AD. Our experiments on OASIS-3 database show that the deviation\nmaps generated by our model exhibit higher sensitivity to AD compared to other\ndeep normative models, and are able to better identify differences between the\nAD and HC groups.\n",
                "链接": "https://arxiv.org/abs/2211.08982"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下文本检索任务上，是否有关于大模型在语义坍缩问题上的研究",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "帮我查找对机器翻译数据集质量进行评估的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "20269",
                "标题": "Prototyping three key properties of specific curiosity in computational\n  reinforcement learning",
                "作者": "University of Alberta Department of Computing Science and Alberta\n  Machine Intelligence Institute  Nadia M. Ady, University of Alberta Department of Computing Science and Alberta\n  Machine Intelligence Institute  Roshan Shariff, University of Alberta Department of Computing Science and Alberta\n  Machine Intelligence Institute  Johannes Günther, University of Alberta Department of Computing Science and Alberta\n  Machine Intelligence Institute  Patrick M. Pilarski",
                "发布日期": "2022-05-24",
                "摘要": "  Curiosity for machine agents has been a focus of intense research. The study\nof human and animal curiosity, particularly specific curiosity, has unearthed\nseveral properties that would offer important benefits for machine learners,\nbut that have not yet been well-explored in machine intelligence. In this work,\nwe introduce three of the most immediate of these properties -- directedness,\ncessation when satisfied, and voluntary exposure -- and show how they may be\nimplemented together in a proof-of-concept reinforcement learning agent;\nfurther, we demonstrate how the properties manifest in the behaviour of this\nagent in a simple non-episodic grid-world environment that includes\ncuriosity-inducing locations and induced targets of curiosity. As we would\nhope, the agent exhibits short-term directed behaviour while updating long-term\npreferences to adaptively seek out curiosity-inducing situations. This work\ntherefore presents a novel view into how specific curiosity operates and in the\nfuture might be integrated into the behaviour of goal-seeking, decision-making\nagents in complex environments.\n",
                "链接": "https://arxiv.org/abs/2205.10407"
            }
        ]
    },
    {
        "question": {
            "question": "查找大语言模型相关的分析类型的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找关于gpt4自动生成prompt的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "118879",
                "标题": "TARGET: Template-Transferable Backdoor Attack Against Prompt-based NLP\n  Models via GPT4",
                "作者": " Zihao Tan,  Qingliang Chen,  Yongjian Huang,  Chen Liang",
                "发布日期": "2023-11-30",
                "摘要": "  Prompt-based learning has been widely applied in many low-resource NLP tasks\nsuch as few-shot scenarios. However, this paradigm has been shown to be\nvulnerable to backdoor attacks. Most of the existing attack methods focus on\ninserting manually predefined templates as triggers in the pre-training phase\nto train the victim model and utilize the same triggers in the downstream task\nto perform inference, which tends to ignore the transferability and\nstealthiness of the templates. In this work, we propose a novel approach of\nTARGET (Template-trAnsfeRable backdoor attack aGainst prompt-basEd NLP models\nvia GPT4), which is a data-independent attack method. Specifically, we first\nutilize GPT4 to reformulate manual templates to generate tone-strong and normal\ntemplates, and the former are injected into the model as a backdoor trigger in\nthe pre-training phase. Then, we not only directly employ the above templates\nin the downstream task, but also use GPT4 to generate templates with similar\ntone to the above templates to carry out transferable attacks. Finally we have\nconducted extensive experiments on five NLP datasets and three BERT series\nmodels, with experimental results justifying that our TARGET method has better\nattack performance and stealthiness compared to the two-external baseline\nmethods on direct attacks, and in addition achieves satisfactory attack\ncapability in the unseen tone-similar templates.\n",
                "链接": "https://arxiv.org/abs/2311.17429"
            },
            {
                "文章ID": "103106",
                "标题": "Is GPT4 a Good Trader?",
                "作者": " Bingzhe Wu",
                "发布日期": "2023-09-21",
                "摘要": "  Recently, large language models (LLMs), particularly GPT-4, have demonstrated\nsignificant capabilities in various planning and reasoning tasks\n\\cite{cheng2023gpt4,bubeck2023sparks}. Motivated by these advancements, there\nhas been a surge of interest among researchers to harness the capabilities of\nGPT-4 for the automated design of quantitative factors that do not overlap with\nexisting factor libraries, with an aspiration to achieve alpha returns\n\\cite{webpagequant}. In contrast to these work, this study aims to examine the\nfidelity of GPT-4's comprehension of classic trading theories and its\nproficiency in applying its code interpreter abilities to real-world trading\ndata analysis. Such an exploration is instrumental in discerning whether the\nunderlying logic GPT-4 employs for trading is intrinsically reliable.\nFurthermore, given the acknowledged interpretative latitude inherent in most\ntrading theories, we seek to distill more precise methodologies of deploying\nthese theories from GPT-4's analytical process, potentially offering invaluable\ninsights to human traders.\n  To achieve this objective, we selected daily candlestick (K-line) data from\nspecific periods for certain assets, such as the Shanghai Stock Index. Through\nmeticulous prompt engineering, we guided GPT-4 to analyze the technical\nstructures embedded within this data, based on specific theories like the\nElliott Wave Theory. We then subjected its analytical output to manual\nevaluation, assessing its interpretative depth and accuracy vis-\\`a-vis these\ntrading theories from multiple dimensions. The results and findings from this\nstudy could pave the way for a synergistic amalgamation of human expertise and\nAI-driven insights in the realm of trading.\n",
                "链接": "https://arxiv.org/abs/2309.10982"
            },
            {
                "文章ID": "103691",
                "标题": "OpenAi's GPT4 as coding assistant",
                "作者": " Lefteris Moussiades,  George Zografos",
                "发布日期": "2023-09-25",
                "摘要": "  Lately, Large Language Models have been widely used in code generation. GPT4\nis considered the most potent Large Language Model from Openai. In this paper,\nwe examine GPT3.5 and GPT4 as coding assistants. More specifically, we have\nconstructed appropriate tests to check whether the two systems can a) answer\ntypical questions that can arise during the code development, b) produce\nreliable code, and c) contribute to code debugging. The test results are\nimpressive. The performance of GPT4 is outstanding and signals an increase in\nthe productivity of programmers and the reorganization of software development\nprocedures based on these new tools.\n",
                "链接": "https://arxiv.org/abs/2309.12732"
            },
            {
                "文章ID": "94380",
                "标题": "Reverse Stable Diffusion: What prompt was used to generate this image?",
                "作者": " Florinel-Alin Croitoru,  Vlad Hondru,  Radu Tudor Ionescu,  Mubarak Shah",
                "发布日期": "2023-08-04",
                "摘要": "  Text-to-image diffusion models such as Stable Diffusion have recently\nattracted the interest of many researchers, and inverting the diffusion process\ncan play an important role in better understanding the generative process and\nhow to engineer prompts in order to obtain the desired images. To this end, we\nintroduce the new task of predicting the text prompt given an image generated\nby a generative diffusion model. We combine a series of white-box and black-box\nmodels (with and without access to the weights of the diffusion network) to\ndeal with the proposed task. We propose a novel learning framework comprising\nof a joint prompt regression and multi-label vocabulary classification\nobjective that generates improved prompts. To further improve our method, we\nemploy a curriculum learning procedure that promotes the learning of\nimage-prompt pairs with lower labeling noise (i.e. that are better aligned),\nand an unsupervised domain-adaptive kernel learning method that uses the\nsimilarities between samples in the source and target domains as extra\nfeatures. We conduct experiments on the DiffusionDB data set, predicting text\nprompts from images generated by Stable Diffusion. Our novel learning framework\nproduces excellent results on the aforementioned task, yielding the highest\ngains when applied on the white-box model. In addition, we make an interesting\ndiscovery: training a diffusion model on the prompt generation task can make\nthe model generate images that are much better aligned with the input prompts,\nwhen the model is directly reused for text-to-image generation.\n",
                "链接": "https://arxiv.org/abs/2308.01472"
            },
            {
                "文章ID": "123546",
                "标题": "Assessing GPT4-V on Structured Reasoning Tasks",
                "作者": " Mukul Singh,  José Cambronero,  Sumit Gulwani,  Vu Le,  Gust Verbruggen",
                "发布日期": "2023-12-20",
                "摘要": "  Multi-modality promises to unlock further uses for large language models.\nRecently, the state-of-the-art language model GPT-4 was enhanced with vision\ncapabilities. We carry out a prompting evaluation of GPT-4V and five other\nbaselines on structured reasoning tasks, such as mathematical reasoning, visual\ndata analysis, and code generation. We show that visual Chain-of-Thought, an\nextension of Chain-of-Thought to multi-modal LLMs, yields significant\nimprovements over the vanilla model. We also present a categorized analysis of\nscenarios where these models perform well and where they struggle, highlighting\nchallenges associated with coherent multimodal reasoning.\n",
                "链接": "https://arxiv.org/abs/2312.11524"
            },
            {
                "文章ID": "102893",
                "标题": "Prompt, Condition, and Generate: Classification of Unsupported Claims\n  with In-Context Learning",
                "作者": " Peter Ebert Christensen,  Srishti Yadav,  Serge Belongie",
                "发布日期": "2023-09-20",
                "摘要": "  Unsupported and unfalsifiable claims we encounter in our daily lives can\ninfluence our view of the world. Characterizing, summarizing, and -- more\ngenerally -- making sense of such claims, however, can be challenging. In this\nwork, we focus on fine-grained debate topics and formulate a new task of\ndistilling, from such claims, a countable set of narratives. We present a\ncrowdsourced dataset of 12 controversial topics, comprising more than 120k\narguments, claims, and comments from heterogeneous sources, each annotated with\na narrative label. We further investigate how large language models (LLMs) can\nbe used to synthesise claims using In-Context Learning. We find that generated\nclaims with supported evidence can be used to improve the performance of\nnarrative classification models and, additionally, that the same model can\ninfer the stance and aspect using a few training examples. Such a model can be\nuseful in applications which rely on narratives , e.g. fact-checking.\n",
                "链接": "https://arxiv.org/abs/2309.10359"
            },
            {
                "文章ID": "64729",
                "标题": "Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong\n  Few-shot Learners",
                "作者": " Renrui Zhang,  Xiangfei Hu,  Bohao Li,  Siyuan Huang,  Hanqiu Deng,  Hongsheng Li,  Yu Qiao,  Peng Gao",
                "发布日期": "2023-03-06",
                "摘要": "  Visual recognition in low-data regimes requires deep neural networks to learn\ngeneralized representations from limited training samples. Recently, CLIP-based\nmethods have shown promising few-shot performance benefited from the\ncontrastive language-image pre-training. We then question, if the more diverse\npre-training knowledge can be cascaded to further assist few-shot\nrepresentation learning. In this paper, we propose CaFo, a Cascade of\nFoundation models that incorporates diverse prior knowledge of various\npre-training paradigms for better few-shot learning. Our CaFo incorporates\nCLIP's language-contrastive knowledge, DINO's vision-contrastive knowledge,\nDALL-E's vision-generative knowledge, and GPT-3's language-generative\nknowledge. Specifically, CaFo works by 'Prompt, Generate, then Cache'. Firstly,\nwe leverage GPT-3 to produce textual inputs for prompting CLIP with rich\ndownstream linguistic semantics. Then, we generate synthetic images via DALL-E\nto expand the few-shot training data without any manpower. At last, we\nintroduce a learnable cache model to adaptively blend the predictions from CLIP\nand DINO. By such collaboration, CaFo can fully unleash the potential of\ndifferent pre-training methods and unify them to perform state-of-the-art for\nfew-shot classification. Code is available at\nhttps://github.com/ZrrSkywalker/CaFo.\n",
                "链接": "https://arxiv.org/abs/2303.02151"
            },
            {
                "文章ID": "34967",
                "标题": "AutoQGS: Auto-Prompt for Low-Resource Knowledge-based Question\n  Generation from SPARQL",
                "作者": " Guanming Xiong,  Junwei Bao,  Wen Zhao,  Youzheng Wu,  Xiaodong He",
                "发布日期": "2022-08-29",
                "摘要": "  This study investigates the task of knowledge-based question generation\n(KBQG). Conventional KBQG works generated questions from fact triples in the\nknowledge graph, which could not express complex operations like aggregation\nand comparison in SPARQL. Moreover, due to the costly annotation of large-scale\nSPARQL-question pairs, KBQG from SPARQL under low-resource scenarios urgently\nneeds to be explored. Recently, since the generative pre-trained language\nmodels (PLMs) typically trained in natural language (NL)-to-NL paradigm have\nbeen proven effective for low-resource generation, e.g., T5 and BART, how to\neffectively utilize them to generate NL-question from non-NL SPARQL is\nchallenging. To address these challenges, AutoQGS, an auto-prompt approach for\nlow-resource KBQG from SPARQL, is proposed. Firstly, we put forward to generate\nquestions directly from SPARQL for the KBQG task to handle complex operations.\nSecondly, we propose an auto-prompter trained on large-scale unsupervised data\nto rephrase SPARQL into NL description, smoothing the low-resource\ntransformation from non-NL SPARQL to NL question with PLMs. Experimental\nresults on the WebQuestionsSP, ComlexWebQuestions 1.1, and PathQuestions show\nthat our model achieves state-of-the-art performance, especially in\nlow-resource settings. Furthermore, a corpus of 330k factoid complex\nquestion-SPARQL pairs is generated for further KBQG research.\n",
                "链接": "https://arxiv.org/abs/2208.12461"
            },
            {
                "文章ID": "83977",
                "标题": "An Approach to Solving the Abstraction and Reasoning Corpus (ARC)\n  Challenge",
                "作者": " Tan John Chong Min",
                "发布日期": "2023-06-07",
                "摘要": "  We utilise the power of Large Language Models (LLMs), in particular GPT4, to\nbe prompt engineered into performing an arbitrary task. Here, we give the model\nsome human priors via text, along with some typical procedures for solving the\nARC tasks, and ask it to generate the i) broad description of the input-output\nrelation, ii) detailed steps of the input-output mapping, iii) use the detailed\nsteps to perform manipulation on the test input and derive the test output. The\ncurrent GPT3.5/GPT4 prompt solves 2 out of 4 tested small ARC challenges (those\nwith small grids of 8x8 and below). With tweaks to the prompt to make it more\nspecific for the use case, it can solve more. We posit that when scaled to a\nmulti-agent system with usage of past memory and equipped with an image\ninterpretation tool via Visual Question Answering, we may actually be able to\nsolve the majority of the ARC challenge\n",
                "链接": "https://arxiv.org/abs/2306.03553"
            },
            {
                "文章ID": "116159",
                "标题": "Do Physicians Know How to Prompt? The Need for Automatic Prompt\n  Optimization Help in Clinical Note Generation",
                "作者": " Zonghai Yao,  Ahmed Jaafar,  Beining Wang,  Yue Zhu,  Zhichao Yang,  Hong Yu",
                "发布日期": "2023-11-17",
                "摘要": "  This study examines the effect of prompt engineering on the performance of\nLarge Language Models (LLMs) in clinical note generation. We introduce an\nAutomatic Prompt Optimization (APO) framework to refine initial prompts and\ncompare the outputs of medical experts, non-medical experts, and APO-enhanced\nGPT3.5 and GPT4. Results highlight GPT4 APO's superior performance in\nstandardizing prompt quality across clinical note sections. A human-in-the-loop\napproach shows that experts maintain content quality post-APO, with a\npreference for their own modifications, suggesting the value of expert\ncustomization. We recommend a two-phase optimization process, leveraging\nAPO-GPT4 for consistency and expert input for personalization.\n",
                "链接": "https://arxiv.org/abs/2311.09684"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态agent, 具身智能的相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "新的大模型结构相关探索的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "多模态细粒度图片编辑和生成相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "124621",
                "标题": "FineMoGen: Fine-Grained Spatio-Temporal Motion Generation and Editing",
                "作者": " Mingyuan Zhang,  Huirong Li,  Zhongang Cai,  Jiawei Ren,  Lei Yang,  Ziwei Liu",
                "发布日期": "2023-12-27",
                "摘要": "  Text-driven motion generation has achieved substantial progress with the\nemergence of diffusion models. However, existing methods still struggle to\ngenerate complex motion sequences that correspond to fine-grained descriptions,\ndepicting detailed and accurate spatio-temporal actions. This lack of fine\ncontrollability limits the usage of motion generation to a larger audience. To\ntackle these challenges, we present FineMoGen, a diffusion-based motion\ngeneration and editing framework that can synthesize fine-grained motions, with\nspatial-temporal composition to the user instructions. Specifically, FineMoGen\nbuilds upon diffusion model with a novel transformer architecture dubbed\nSpatio-Temporal Mixture Attention (SAMI). SAMI optimizes the generation of the\nglobal attention template from two perspectives: 1) explicitly modeling the\nconstraints of spatio-temporal composition; and 2) utilizing sparsely-activated\nmixture-of-experts to adaptively extract fine-grained features. To facilitate a\nlarge-scale study on this new fine-grained motion generation task, we\ncontribute the HuMMan-MoGen dataset, which consists of 2,968 videos and 102,336\nfine-grained spatio-temporal descriptions. Extensive experiments validate that\nFineMoGen exhibits superior motion generation quality over state-of-the-art\nmethods. Notably, FineMoGen further enables zero-shot motion editing\ncapabilities with the aid of modern large language models (LLM), which\nfaithfully manipulates motion sequences with fine-grained instructions. Project\nPage: https://mingyuan-zhang.github.io/projects/FineMoGen.html\n",
                "链接": "https://arxiv.org/abs/2312.15004"
            },
            {
                "文章ID": "13260",
                "标题": "Flexible Portrait Image Editing with Fine-Grained Control",
                "作者": " Linlin Liu,  Qian Fu,  Fei Hou,  Ying He",
                "发布日期": "2022-04-05",
                "摘要": "  We develop a new method for portrait image editing, which supports\nfine-grained editing of geometries, colors, lights and shadows using a single\nneural network model. We adopt a novel asymmetric conditional GAN architecture:\nthe generators take the transformed conditional inputs, such as edge maps,\ncolor palette, sliders and masks, that can be directly edited by the user; the\ndiscriminators take the conditional inputs in the way that can guide\ncontrollable image generation more effectively. Taking color editing as an\nexample, we feed color palettes (which can be edited easily) into the\ngenerator, and color maps (which contain positional information of colors) into\nthe discriminator. We also design a region-weighted discriminator so that\nhigher weights are assigned to more important regions, like eyes and skin.\nUsing a color palette, the user can directly specify the desired colors of\nhair, skin, eyes, lip and background. Color sliders allow the user to blend\ncolors in an intuitive manner. The user can also edit lights and shadows by\nmodifying the corresponding masks. We demonstrate the effectiveness of our\nmethod by evaluating it on the CelebAMask-HQ dataset with a wide range of\ntasks, including geometry/color/shadow/light editing, hand-drawn sketch to\nimage translation, and color transfer. We also present ablation studies to\njustify our design.\n",
                "链接": "https://arxiv.org/abs/2204.01318"
            },
            {
                "文章ID": "52126",
                "标题": "Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models",
                "作者": " Naoki Matsunaga,  Masato Ishii,  Akio Hayakawa,  Kenji Suzuki,  Takuya Narihira",
                "发布日期": "2023-06-01",
                "摘要": "  Our goal is to develop fine-grained real-image editing methods suitable for\nreal-world applications. In this paper, we first summarize four requirements\nfor these methods and propose a novel diffusion-based image editing framework\nwith pixel-wise guidance that satisfies these requirements. Specifically, we\ntrain pixel-classifiers with a few annotated data and then infer the\nsegmentation map of a target image. Users then manipulate the map to instruct\nhow the image will be edited. We utilize a pre-trained diffusion model to\ngenerate edited images aligned with the user's intention with pixel-wise\nguidance. The effective combination of proposed guidance and other techniques\nenables highly controllable editing with preserving the outside of the edited\narea, which results in meeting our requirements. The experimental results\ndemonstrate that our proposal outperforms the GAN-based method for editing\nquality and speed.\n",
                "链接": "https://arxiv.org/abs/2212.02024"
            },
            {
                "文章ID": "26773",
                "标题": "MACSA: A Multimodal Aspect-Category Sentiment Analysis Dataset with\n  Multimodal Fine-grained Aligned Annotations",
                "作者": " Hao Yang,  Yanyan Zhao,  Jianwei Liu,  Yang Wu,  Bing Qin",
                "发布日期": "2022-06-29",
                "摘要": "  Multimodal fine-grained sentiment analysis has recently attracted increasing\nattention due to its broad applications. However, the existing multimodal\nfine-grained sentiment datasets most focus on annotating the fine-grained\nelements in text but ignore those in images, which leads to the fine-grained\nelements in visual content not receiving the full attention they deserve. In\nthis paper, we propose a new dataset, the Multimodal Aspect-Category Sentiment\nAnalysis (MACSA) dataset, which contains more than 21K text-image pairs. The\ndataset provides fine-grained annotations for both textual and visual content\nand firstly uses the aspect category as the pivot to align the fine-grained\nelements between the two modalities. Based on our dataset, we propose the\nMultimodal ACSA task and a multimodal graph-based aligned model (MGAM), which\nadopts a fine-grained cross-modal fusion method. Experimental results show that\nour method can facilitate the baseline comparison for future research on this\ncorpus. We will make the dataset and code publicly available.\n",
                "链接": "https://arxiv.org/abs/2206.13969"
            },
            {
                "文章ID": "124901",
                "标题": "SERF: Fine-Grained Interactive 3D Segmentation and Editing with Radiance\n  Fields",
                "作者": " Kaichen Zhou,  Lanqing Hong,  Enze Xie,  Yongxin Yang,  Zhenguo Li,  Wei Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Although significant progress has been made in the field of 2D-based\ninteractive editing, fine-grained 3D-based interactive editing remains\nrelatively unexplored. This limitation can be attributed to two main\nchallenges: the lack of an efficient 3D representation robust to different\nmodifications and the absence of an effective 3D interactive segmentation\nmethod. In this paper, we introduce a novel fine-grained interactive 3D\nsegmentation and editing algorithm with radiance fields, which we refer to as\nSERF. Our method entails creating a neural mesh representation by integrating\nmulti-view algorithms with pre-trained 2D models. Building upon this\nrepresentation, we introduce a novel surface rendering technique that preserves\nlocal information and is robust to deformation. Moreover, this representation\nforms the basis for achieving accurate and interactive 3D segmentation without\nrequiring 3D supervision. Harnessing this representation facilitates a range of\ninteractive 3D editing operations, encompassing tasks such as interactive\ngeometry editing and texture painting. Extensive experiments and visualization\nexamples of editing on both real and synthetic data demonstrate the superiority\nof our method on representation quality and editing ability.\n",
                "链接": "https://arxiv.org/abs/2312.15856"
            },
            {
                "文章ID": "41367",
                "标题": "MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language\n  Representation Learning",
                "作者": " Zijia Zhao,  Longteng Guo,  Xingjian He,  Shuai Shao,  Zehuan Yuan,  Jing Liu",
                "发布日期": "2023-06-16",
                "摘要": "  Multimodal representation learning has shown promising improvements on\nvarious vision-language tasks. Most existing methods excel at building\nglobal-level alignment between vision and language while lacking effective\nfine-grained image-text interaction. In this paper, we propose a jointly masked\nmultimodal modeling method to learn fine-grained multimodal representations.\nOur method performs joint masking on image-text input and integrates both\nimplicit and explicit targets for the masked signals to recover. The implicit\ntarget provides a unified and debiased objective for vision and language, where\nthe model predicts latent multimodal representations of the unmasked input. The\nexplicit target further enriches the multimodal representations by recovering\nhigh-level and semantically meaningful information: momentum visual features of\nimage patches and concepts of word tokens. Through such a masked modeling\nprocess, our model not only learns fine-grained multimodal interaction, but\nalso avoids the semantic gap between high-level representations and low- or\nmid-level prediction targets (e.g. image pixels), thus producing semantically\nrich multimodal representations that perform well on both zero-shot and\nfine-tuned settings. Our pre-trained model (named MAMO) achieves\nstate-of-the-art performance on various downstream vision-language tasks,\nincluding image-text retrieval, visual question answering, visual reasoning,\nand weakly-supervised visual grounding.\n",
                "链接": "https://arxiv.org/abs/2210.04183"
            },
            {
                "文章ID": "69760",
                "标题": "Hierarchical Fine-Grained Image Forgery Detection and Localization",
                "作者": " Xiao Guo,  Xiaohong Liu,  Zhiyuan Ren,  Steven Grosz,  Iacopo Masi,  Xiaoming Liu",
                "发布日期": "2023-03-31",
                "摘要": "  Differences in forgery attributes of images generated in CNN-synthesized and\nimage-editing domains are large, and such differences make a unified image\nforgery detection and localization (IFDL) challenging. To this end, we present\na hierarchical fine-grained formulation for IFDL representation learning.\nSpecifically, we first represent forgery attributes of a manipulated image with\nmultiple labels at different levels. Then we perform fine-grained\nclassification at these levels using the hierarchical dependency between them.\nAs a result, the algorithm is encouraged to learn both comprehensive features\nand inherent hierarchical nature of different forgery attributes, thereby\nimproving the IFDL representation. Our proposed IFDL framework contains three\ncomponents: multi-branch feature extractor, localization and classification\nmodules. Each branch of the feature extractor learns to classify forgery\nattributes at one level, while localization and classification modules segment\nthe pixel-level forgery region and detect image-level forgery, respectively.\nLastly, we construct a hierarchical fine-grained dataset to facilitate our\nstudy. We demonstrate the effectiveness of our method on $7$ different\nbenchmarks, for both tasks of IFDL and forgery attribute classification. Our\nsource code and dataset can be found:\n\\href{https://github.com/CHELSEA234/HiFi_IFDL}{github.com/CHELSEA234/HiFi-IFDL}.\n",
                "链接": "https://arxiv.org/abs/2303.17111"
            },
            {
                "文章ID": "73032",
                "标题": "Text-guided Image-and-Shape Editing and Generation: A Short Survey",
                "作者": " Cheng-Kang Ted Chao,  Yotam Gingold",
                "发布日期": "2023-04-20",
                "摘要": "  Image and shape editing are ubiquitous among digital artworks. Graphics\nalgorithms facilitate artists and designers to achieve desired editing intents\nwithout going through manually tedious retouching. In the recent advance of\nmachine learning, artists' editing intents can even be driven by text, using a\nvariety of well-trained neural networks. They have seen to be receiving an\nextensive success on such as generating photorealistic images, artworks and\nhuman poses, stylizing meshes from text, or auto-completion given image and\nshape priors. In this short survey, we provide an overview over 50 papers on\nstate-of-the-art (text-guided) image-and-shape generation techniques. We start\nwith an overview on recent editing algorithms in the introduction. Then, we\nprovide a comprehensive review on text-guided editing techniques for 2D and 3D\nindependently, where each of its sub-section begins with a brief background\nintroduction. We also contextualize editing algorithms under recent implicit\nneural representations. Finally, we conclude the survey with the discussion\nover existing methods and potential research ideas.\n",
                "链接": "https://arxiv.org/abs/2304.09244"
            },
            {
                "文章ID": "76015",
                "标题": "Fine-Grained Product Classification on Leaflet Advertisements",
                "作者": "1 and 2  Daniel Ladwig, 1 and 2  Bianca Lamm,  Janis Keuper",
                "发布日期": "2023-05-08",
                "摘要": "  In this paper, we describe a first publicly available fine-grained product\nrecognition dataset based on leaflet images. Using advertisement leaflets,\ncollected over several years from different European retailers, we provide a\ntotal of 41.6k manually annotated product images in 832 classes. Further, we\ninvestigate three different approaches for this fine-grained product\nclassification task, Classification by Image, by Text, as well as by Image and\nText. The approach \"Classification by Text\" uses the text extracted directly\nfrom the leaflet product images. We show, that the combination of image and\ntext as input improves the classification of visual difficult to distinguish\nproducts. The final model leads to an accuracy of 96.4% with a Top-3 score of\n99.2%. We release our code at\nhttps://github.com/ladwigd/Leaflet-Product-Classification.\n",
                "链接": "https://arxiv.org/abs/2305.03706"
            },
            {
                "文章ID": "80167",
                "标题": "BLIP-Diffusion: Pre-trained Subject Representation for Controllable\n  Text-to-Image Generation and Editing",
                "作者": " Dongxu Li,  Junnan Li,  Steven C. H. Hoi",
                "发布日期": "2023-06-23",
                "摘要": "  Subject-driven text-to-image generation models create novel renditions of an\ninput subject based on text prompts. Existing models suffer from lengthy\nfine-tuning and difficulties preserving the subject fidelity. To overcome these\nlimitations, we introduce BLIP-Diffusion, a new subject-driven image generation\nmodel that supports multimodal control which consumes inputs of subject images\nand text prompts. Unlike other subject-driven generation models, BLIP-Diffusion\nintroduces a new multimodal encoder which is pre-trained to provide subject\nrepresentation. We first pre-train the multimodal encoder following BLIP-2 to\nproduce visual representation aligned with the text. Then we design a subject\nrepresentation learning task which enables a diffusion model to leverage such\nvisual representation and generates new subject renditions. Compared with\nprevious methods such as DreamBooth, our model enables zero-shot subject-driven\ngeneration, and efficient fine-tuning for customized subject with up to 20x\nspeedup. We also demonstrate that BLIP-Diffusion can be flexibly combined with\nexisting techniques such as ControlNet and prompt-to-prompt to enable novel\nsubject-driven generation and editing applications. Code and models will be\nreleased at\nhttps://github.com/salesforce/LAVIS/tree/main/projects/blip-diffusion. Project\npage at https://dxli94.github.io/BLIP-Diffusion-website/.\n",
                "链接": "https://arxiv.org/abs/2305.14720"
            }
        ]
    },
    {
        "question": {
            "question": "查找中文ner常用的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "5948",
                "标题": "AISHELL-NER: Named Entity Recognition from Chinese Speech",
                "作者": " Boli Chen,  Guangwei Xu,  Xiaobin Wang,  Pengjun Xie,  Meishan Zhang,  Fei Huang",
                "发布日期": "2022-02-18",
                "摘要": "  Named Entity Recognition (NER) from speech is among Spoken Language\nUnderstanding (SLU) tasks, aiming to extract semantic information from the\nspeech signal. NER from speech is usually made through a two-step pipeline that\nconsists of (1) processing the audio using an Automatic Speech Recognition\n(ASR) system and (2) applying an NER tagger to the ASR outputs. Recent works\nhave shown the capability of the End-to-End (E2E) approach for NER from English\nand French speech, which is essentially entity-aware ASR. However, due to the\nmany homophones and polyphones that exist in Chinese, NER from Chinese speech\nis effectively a more challenging task. In this paper, we introduce a new\ndataset AISEHLL-NER for NER from Chinese speech. Extensive experiments are\nconducted to explore the performance of several state-of-the-art methods. The\nresults demonstrate that the performance could be improved by combining\nentity-aware ASR and pretrained NER tagger, which can be easily applied to the\nmodern SLU pipeline. The dataset is publicly available at\ngithub.com/Alibaba-NLP/AISHELL-NER.\n",
                "链接": "https://arxiv.org/abs/2202.08533"
            },
            {
                "文章ID": "12836",
                "标题": "$k$NN-NER: Named Entity Recognition with Nearest Neighbor Search",
                "作者": " Shuhe Wang,  Xiaoya Li,  Yuxian Meng,  Tianwei Zhang,  Rongbin Ouyang,  Jiwei Li,  Guoyin Wang",
                "发布日期": "2022-04-01",
                "摘要": "  Inspired by recent advances in retrieval augmented methods in\nNLP~\\citep{khandelwal2019generalization,khandelwal2020nearest,meng2021gnn}, in\nthis paper, we introduce a $k$ nearest neighbor NER ($k$NN-NER) framework,\nwhich augments the distribution of entity labels by assigning $k$ nearest\nneighbors retrieved from the training set. This strategy makes the model more\ncapable of handling long-tail cases, along with better few-shot learning\nabilities. $k$NN-NER requires no additional operation during the training\nphase, and by interpolating $k$ nearest neighbors search into the vanilla NER\nmodel, $k$NN-NER consistently outperforms its vanilla counterparts: we achieve\na new state-of-the-art F1-score of 72.03 (+1.25) on the Chinese Weibo dataset\nand improved results on a variety of widely used NER benchmarks. Additionally,\nwe show that $k$NN-NER can achieve comparable results to the vanilla NER model\nwith 40\\% less amount of training data. Code available at\n\\url{https://github.com/ShannonAI/KNN-NER}.\n",
                "链接": "https://arxiv.org/abs/2203.17103"
            },
            {
                "文章ID": "73406",
                "标题": "GPT-NER: Named Entity Recognition via Large Language Models",
                "作者": " Shuhe Wang,  Xiaofei Sun,  Xiaoya Li,  Rongbin Ouyang,  Fei Wu,  Tianwei Zhang,  Jiwei Li,  Guoyin Wang",
                "发布日期": "2023-10-10",
                "摘要": "  Despite the fact that large-scale Language Models (LLM) have achieved SOTA\nperformances on a variety of NLP tasks, its performance on NER is still\nsignificantly below supervised baselines. This is due to the gap between the\ntwo tasks the NER and LLMs: the former is a sequence labeling task in nature\nwhile the latter is a text-generation model.\n  In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges the\ngap by transforming the sequence labeling task to a generation task that can be\neasily adapted by LLMs e.g., the task of finding location entities in the input\ntext \"Columbus is a city\" is transformed to generate the text sequence\n\"@@Columbus## is a city\", where special tokens @@## marks the entity to\nextract. To efficiently address the \"hallucination\" issue of LLMs, where LLMs\nhave a strong inclination to over-confidently label NULL inputs as entities, we\npropose a self-verification strategy by prompting LLMs to ask itself whether\nthe extracted entities belong to a labeled entity tag.\n  We conduct experiments on five widely adopted NER datasets, and GPT-NER\nachieves comparable performances to fully supervised baselines, which is the\nfirst time as far as we are concerned. More importantly, we find that GPT-NER\nexhibits a greater ability in the low-resource and few-shot setups, when the\namount of training data is extremely scarce, GPT-NER performs significantly\nbetter than supervised models. This demonstrates the capabilities of GPT-NER in\nreal-world NER applications where the number of labeled examples is limited.\n",
                "链接": "https://arxiv.org/abs/2304.10428"
            },
            {
                "文章ID": "81587",
                "标题": "E-NER: Evidential Deep Learning for Trustworthy Named Entity Recognition",
                "作者": " Zhen Zhang,  Mengting Hu,  Shiwan Zhao,  Minlie Huang,  Haotian Wang,  Lemao Liu,  Zhirui Zhang,  Zhe Liu,  Bingzhe Wu",
                "发布日期": "2023-05-30",
                "摘要": "  Most named entity recognition (NER) systems focus on improving model\nperformance, ignoring the need to quantify model uncertainty, which is critical\nto the reliability of NER systems in open environments. Evidential deep\nlearning (EDL) has recently been proposed as a promising solution to explicitly\nmodel predictive uncertainty for classification tasks. However, directly\napplying EDL to NER applications faces two challenges, i.e., the problems of\nsparse entities and OOV/OOD entities in NER tasks. To address these challenges,\nwe propose a trustworthy NER framework named E-NER by introducing two\nuncertainty-guided loss terms to the conventional EDL, along with a series of\nuncertainty-guided training strategies. Experiments show that E-NER can be\napplied to multiple NER paradigms to obtain accurate uncertainty estimation.\nFurthermore, compared to state-of-the-art baselines, the proposed method\nachieves a better OOV/OOD detection performance and better generalization\nability on OOV entities.\n",
                "链接": "https://arxiv.org/abs/2305.17854"
            },
            {
                "文章ID": "108977",
                "标题": "Empirical Study of Zero-Shot NER with ChatGPT",
                "作者": " Tingyu Xie,  Qi Li,  Jian Zhang,  Yan Zhang,  Zuozhu Liu,  Hongwei Wang",
                "发布日期": "2023-10-17",
                "摘要": "  Large language models (LLMs) exhibited powerful capability in various natural\nlanguage processing tasks. This work focuses on exploring LLM performance on\nzero-shot information extraction, with a focus on the ChatGPT and named entity\nrecognition (NER) task. Inspired by the remarkable reasoning capability of LLM\non symbolic and arithmetic reasoning, we adapt the prevalent reasoning methods\nto NER and propose reasoning strategies tailored for NER. First, we explore a\ndecomposed question-answering paradigm by breaking down the NER task into\nsimpler subproblems by labels. Second, we propose syntactic augmentation to\nstimulate the model's intermediate thinking in two ways: syntactic prompting,\nwhich encourages the model to analyze the syntactic structure itself, and tool\naugmentation, which provides the model with the syntactic information generated\nby a parsing tool. Besides, we adapt self-consistency to NER by proposing a\ntwo-stage majority voting strategy, which first votes for the most consistent\nmentions, then the most consistent types. The proposed methods achieve\nremarkable improvements for zero-shot NER across seven benchmarks, including\nChinese and English datasets, and on both domain-specific and general-domain\nscenarios. In addition, we present a comprehensive analysis of the error types\nwith suggestions for optimization directions. We also verify the effectiveness\nof the proposed methods on the few-shot setting and other LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.10035"
            },
            {
                "文章ID": "81674",
                "标题": "Extrinsic Factors Affecting the Accuracy of Biomedical NER",
                "作者": " Zhiyi Li,  Shengjie Zhang,  Yujie Song,  Jungyeul Park",
                "发布日期": "2023-05-30",
                "摘要": "  Biomedical named entity recognition (NER) is a critial task that aims to\nidentify structured information in clinical text, which is often replete with\ncomplex, technical terms and a high degree of variability. Accurate and\nreliable NER can facilitate the extraction and analysis of important biomedical\ninformation, which can be used to improve downstream applications including the\nhealthcare system. However, NER in the biomedical domain is challenging due to\nlimited data availability, as the high expertise, time, and expenses are\nrequired to annotate its data. In this paper, by using the limited data, we\nexplore various extrinsic factors including the corpus annotation scheme, data\naugmentation techniques, semi-supervised learning and Brill transformation, to\nimprove the performance of a NER model on a clinical text dataset (i2b2 2012,\n\\citet{sun-rumshisky-uzuner:2013}). Our experiments demonstrate that these\napproaches can significantly improve the model's F1 score from original 73.74\nto 77.55. Our findings suggest that considering different extrinsic factors and\ncombining these techniques is a promising approach for improving NER\nperformance in the biomedical domain where the size of data is limited.\n",
                "链接": "https://arxiv.org/abs/2305.18152"
            },
            {
                "文章ID": "81620",
                "标题": "ContrastNER: Contrastive-based Prompt Tuning for Few-shot NER",
                "作者": " Amirhossein Layegh,  Amir H. Payberah,  Ahmet Soylu,  Dumitru Roman,  Mihhail Matskin",
                "发布日期": "2023-08-08",
                "摘要": "  Prompt-based language models have produced encouraging results in numerous\napplications, including Named Entity Recognition (NER) tasks. NER aims to\nidentify entities in a sentence and provide their types. However, the strong\nperformance of most available NER approaches is heavily dependent on the design\nof discrete prompts and a verbalizer to map the model-predicted outputs to\nentity categories, which are complicated undertakings. To address these\nchallenges, we present ContrastNER, a prompt-based NER framework that employs\nboth discrete and continuous tokens in prompts and uses a contrastive learning\napproach to learn the continuous prompts and forecast entity types. The\nexperimental results demonstrate that ContrastNER obtains competitive\nperformance to the state-of-the-art NER methods in high-resource settings and\noutperforms the state-of-the-art models in low-resource circumstances without\nrequiring extensive manual prompt engineering and verbalizer design.\n",
                "链接": "https://arxiv.org/abs/2305.17951"
            },
            {
                "文章ID": "54218",
                "标题": "E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text",
                "作者": " Ting Wai Terence Au,  Ingemar J. Cox,  Vasileios Lampos",
                "发布日期": "2022-12-20",
                "摘要": "  Identifying named entities such as a person, location or organization, in\ndocuments can highlight key information to readers. Training Named Entity\nRecognition (NER) models requires an annotated data set, which can be a\ntime-consuming labour-intensive task. Nevertheless, there are publicly\navailable NER data sets for general English. Recently there has been interest\nin developing NER for legal text. However, prior work and experimental results\nreported here indicate that there is a significant degradation in performance\nwhen NER methods trained on a general English data set are applied to legal\ntext. We describe a publicly available legal NER data set, called E-NER, based\non legal company filings available from the US Securities and Exchange\nCommission's EDGAR data set. Training a number of different NER algorithms on\nthe general English CoNLL-2003 corpus but testing on our test collection\nconfirmed significant degradations in accuracy, as measured by the F1-score, of\nbetween 29.4\\% and 60.4\\%, compared to training and testing on the E-NER\ncollection.\n",
                "链接": "https://arxiv.org/abs/2212.09306"
            },
            {
                "文章ID": "82089",
                "标题": "A Multilingual Evaluation of NER Robustness to Adversarial Inputs",
                "作者": " Akshay Srinivasan,  Sowmya Vajjala",
                "发布日期": "2023-05-31",
                "摘要": "  Adversarial evaluations of language models typically focus on English alone.\nIn this paper, we performed a multilingual evaluation of Named Entity\nRecognition (NER) in terms of its robustness to small perturbations in the\ninput. Our results showed the NER models we explored across three languages\n(English, German and Hindi) are not very robust to such changes, as indicated\nby the fluctuations in the overall F1 score as well as in a more fine-grained\nevaluation. With that knowledge, we further explored whether it is possible to\nimprove the existing NER models using a part of the generated adversarial data\nsets as augmented training data to train a new NER model or as fine-tuning data\nto adapt an existing NER model. Our results showed that both these approaches\nimprove performance on the original as well as adversarial test sets. While\nthere is no significant difference between the two approaches for English,\nre-training is significantly better than fine-tuning for German and Hindi.\n",
                "链接": "https://arxiv.org/abs/2305.18933"
            },
            {
                "文章ID": "78785",
                "标题": "Enhancing Few-shot NER with Prompt Ordering based Data Augmentation",
                "作者": " Huiming Wang,  Liying Cheng,  Wenxuan Zhang,  De Wen Soh,  Lidong Bing",
                "发布日期": "2023-05-22",
                "摘要": "  Recently, data augmentation (DA) methods have been proven to be effective for\npre-trained language models (PLMs) in low-resource settings, including few-shot\nnamed entity recognition (NER). However, conventional NER DA methods are mostly\naimed at sequence labeling models, i.e., token-level classification, and few\nare compatible with unified autoregressive generation frameworks, which can\nhandle a wider range of NER tasks, such as nested NER. Furthermore, these\ngeneration frameworks have a strong assumption that the entities will appear in\nthe target sequence with the same left-to-right order as the source sequence.\nIn this paper, we claim that there is no need to keep this strict order, and\nmore diversified but reasonable target entity sequences can be provided during\nthe training stage as a novel DA method. Nevertheless, a naive mixture of\naugmented data can confuse the model since one source sequence will then be\npaired with different target sequences. Therefore, we propose a simple but\neffective Prompt Ordering based Data Augmentation (PODA) method to improve the\ntraining of unified autoregressive generation frameworks under few-shot NER\nscenarios. Experimental results on three public NER datasets and further\nanalyses demonstrate the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2305.11791"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下最近用反事实做数据增强的文章",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下利用蒙特卡罗树搜索解决序列决策问题的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "54835",
                "标题": "Feature Acquisition using Monte Carlo Tree Search",
                "作者": " Sungsoo Lim,  Diego Klabjan,  Mark Shapiro",
                "发布日期": "2022-12-23",
                "摘要": "  Feature acquisition algorithms address the problem of acquiring informative\nfeatures while balancing the costs of acquisition to improve the learning\nperformances of ML models. Previous approaches have focused on calculating the\nexpected utility values of features to determine the acquisition sequences.\nOther approaches formulated the problem as a Markov Decision Process (MDP) and\napplied reinforcement learning based algorithms. In comparison to previous\napproaches, we focus on 1) formulating the feature acquisition problem as a MDP\nand applying Monte Carlo Tree Search, 2) calculating the intermediary rewards\nfor each acquisition step based on model improvements and acquisition costs and\n3) simultaneously optimizing model improvement and acquisition costs with\nmulti-objective Monte Carlo Tree Search. With Proximal Policy Optimization and\nDeep Q-Network algorithms as benchmark, we show the effectiveness of our\nproposed approach with experimental study.\n",
                "链接": "https://arxiv.org/abs/2212.11360"
            },
            {
                "文章ID": "102301",
                "标题": "Maneuver Decision-Making Through Proximal Policy Optimization And Monte\n  Carlo Tree Search",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-09-19",
                "摘要": "  Maneuver decision-making can be regarded as a Markov decision process and can\nbe address by reinforcement learning. However, original reinforcement learning\nalgorithms can hardly solve the maneuvering decision-making problem. One reason\nis that agents use random actions in the early stages of training, which makes\nit difficult to get rewards and learn how to make effective decisions. To\naddress this issue, a method based on proximal policy optimization and Monte\nCarlo tree search is proposed. The method uses proximal policy optimization to\ntrain the agent, and regards the results of air combat as targets to train the\nvalue network. Then, based on the value network and the visit count of each\nnode, Monte Carlo tree search is used to find the actions with more expected\nreturns than random actions, which can improve the training performance. The\nablation studies and simulation experiments indicate that agents trained by the\nproposed method can make different decisions according to different states,\nwhich demonstrates that the method can solve the maneuvering decision problem\nthat the original reinforcement learning algorithm cannot solve.\n",
                "链接": "https://arxiv.org/abs/2309.08611"
            },
            {
                "文章ID": "59436",
                "标题": "Alphazzle: Jigsaw Puzzle Solver with Deep Monte-Carlo Tree Search",
                "作者": " Marie-Morgane Paumard,  Hedi Tabia,  David Picard",
                "发布日期": "2023-02-02",
                "摘要": "  Solving jigsaw puzzles requires to grasp the visual features of a sequence of\npatches and to explore efficiently a solution space that grows exponentially\nwith the sequence length. Therefore, visual deep reinforcement learning (DRL)\nshould answer this problem more efficiently than optimization solvers coupled\nwith neural networks. Based on this assumption, we introduce Alphazzle, a\nreassembly algorithm based on single-player Monte Carlo Tree Search (MCTS). A\nmajor difference with DRL algorithms lies in the unavailability of game reward\nfor MCTS, and we show how to estimate it from the visual input with neural\nnetworks. This constraint is induced by the puzzle-solving task and\ndramatically adds to the task complexity (and interest!). We perform an in-deep\nablation study that shows the importance of MCTS and the neural networks\nworking together. We achieve excellent results and get exciting insights into\nthe combination of DRL and visual feature learning.\n",
                "链接": "https://arxiv.org/abs/2302.00384"
            },
            {
                "文章ID": "23592",
                "标题": "Combining Monte-Carlo Tree Search with Proof-Number Search",
                "作者": " Elliot Doe,  Mark H. M. Winands,  Dennis J. N. J. Soemers,  Cameron Browne",
                "发布日期": "2022-06-09",
                "摘要": "  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
                "链接": "https://arxiv.org/abs/2206.03965"
            },
            {
                "文章ID": "53055",
                "标题": "Lookahead Pathology in Monte-Carlo Tree Search",
                "作者": " Khoi P. N. Nguyen,  Raghuram Ramanujan",
                "发布日期": "2022-12-13",
                "摘要": "  Monte-Carlo Tree Search (MCTS) is an adversarial search paradigm that first\nfound prominence with its success in the domain of computer Go. Early\ntheoretical work established the game-theoretic soundness and convergence\nbounds for Upper Confidence bounds applied to Trees (UCT), the most popular\ninstantiation of MCTS; however, there remain notable gaps in our understanding\nof how UCT behaves in practice. In this work, we address one such gap by\nconsidering the question of whether UCT can exhibit lookahead pathology -- a\nparadoxical phenomenon first observed in Minimax search where greater search\neffort leads to worse decision-making. We introduce a novel family of synthetic\ngames that offer rich modeling possibilities while remaining amenable to\nmathematical analysis. Our theoretical and experimental results suggest that\nUCT is indeed susceptible to pathological behavior in a range of games drawn\nfrom this family.\n",
                "链接": "https://arxiv.org/abs/2212.05208"
            },
            {
                "文章ID": "67092",
                "标题": "Proof Number Based Monte-Carlo Tree Search",
                "作者": " Jakub Kowalski,  Elliot Doe,  Mark H. M. Winands,  Daniel Górski,  Dennis J. N. J. Soemers",
                "发布日期": "2023-12-22",
                "摘要": "  This paper proposes a new game-search algorithm, PN-MCTS, which combines\nMonte-Carlo Tree Search (MCTS) and Proof-Number Search (PNS). These two\nalgorithms have been successfully applied for decision making in a range of\ndomains. We define three areas where the additional knowledge provided by the\nproof and disproof numbers gathered in MCTS trees might be used: final move\nselection, solving subtrees, and the UCB1 selection mechanism. We test all\npossible combinations on different time settings, playing against vanilla UCT\non several games: Lines of Action ($7$$\\times$$7$ and $8$$\\times$$8$ board\nsizes), MiniShogi, Knightthrough, and Awari. Furthermore, we extend this new\nalgorithm to properly address games with draws, like Awari, by adding an\nadditional layer of PNS on top of the MCTS tree. The experiments show that\nPN-MCTS confidently outperforms MCTS in all tested game domains, achieving win\nrates up to 96.2\\% for Lines of Action.\n",
                "链接": "https://arxiv.org/abs/2303.09449"
            },
            {
                "文章ID": "107193",
                "标题": "Evolutionary Retrosynthetic Route Planning",
                "作者": " Yan Zhang,  Hao Hao,  Xiao He,  Shuanhu Gao,  Aimin Zhou",
                "发布日期": "2023-10-10",
                "摘要": "  Molecular retrosynthesis is a significant and complex problem in the field of\nchemistry, however, traditional manual synthesis methods not only need\nwell-trained experts but also are time-consuming. With the development of big\ndata and machine learning, artificial intelligence (AI) based retrosynthesis is\nattracting more attention and is becoming a valuable tool for molecular\nretrosynthesis. At present, Monte Carlo tree search is a mainstream search\nframework employed to address this problem. Nevertheless, its search efficiency\nis compromised by its large search space. Therefore, we propose a novel\napproach for retrosynthetic route planning based on evolutionary optimization,\nmarking the first use of Evolutionary Algorithm (EA) in the field of multi-step\nretrosynthesis. The proposed method involves modeling the retrosynthetic\nproblem into an optimization problem, defining the search space and operators.\nAdditionally, to improve the search efficiency, a parallel strategy is\nimplemented. The new approach is applied to four case products, and is compared\nwith Monte Carlo tree search. The experimental results show that, in comparison\nto the Monte Carlo tree search algorithm, EA significantly reduces the number\nof calling single-step model by an average of 53.9%. The time required to\nsearch three solutions decreased by an average of 83.9%, and the number of\nfeasible search routes increases by 5 times.\n",
                "链接": "https://arxiv.org/abs/2310.05186"
            },
            {
                "文章ID": "40416",
                "标题": "Continuous Monte Carlo Graph Search",
                "作者": " Kalle Kujanpää,  Amin Babadi,  Yi Zhao,  Juho Kannala,  Alexander Ilin,  Joni Pajarinen",
                "发布日期": "2023-07-19",
                "摘要": "  In many complex sequential decision-making tasks, online planning is crucial\nfor high performance. For efficient online planning, Monte Carlo Tree Search\n(MCTS) employs a principled mechanism for trading off exploration for\nexploitation. MCTS outperforms comparison methods in many discrete\ndecision-making domains such as Go, Chess, and Shogi. Following, extensions of\nMCTS to continuous domains have been proposed. However, the inherent high\nbranching factor and the resulting explosion of search tree size are limiting\nexisting methods. To address this problem, we propose Continuous Monte Carlo\nGraph Search (CMCGS), a novel extension of MCTS to online planning in\nenvironments with continuous state and action spaces. CMCGS takes advantage of\nthe insight that, during planning, sharing the same action policy between\nseveral states can yield high performance. To implement this idea, at each time\nstep, CMCGS clusters similar states into a limited number of stochastic action\nbandit nodes, which produce a layered directed graph instead of an MCTS search\ntree. Experimental evaluation shows that CMCGS outperforms comparable planning\nmethods in several complex continuous DeepMind Control Suite benchmarks and a\n2D navigation task with limited sample budgets. Furthermore, CMCGS can be\nparallelized to scale up and it outperforms the Cross-Entropy Method (CEM) in\ncontinuous control with learned dynamics models.\n",
                "链接": "https://arxiv.org/abs/2210.01426"
            },
            {
                "文章ID": "16547",
                "标题": "An Efficient Dynamic Sampling Policy For Monte Carlo Tree Search",
                "作者": " Gongbo Zhang,  Yijie Peng,  Yilong Xu",
                "发布日期": "2023-05-09",
                "摘要": "  We consider the popular tree-based search strategy within the framework of\nreinforcement learning, the Monte Carlo Tree Search (MCTS), in the context of\nfinite-horizon Markov decision process. We propose a dynamic sampling tree\npolicy that efficiently allocates limited computational budget to maximize the\nprobability of correct selection of the best action at the root node of the\ntree. Experimental results on Tic-Tac-Toe and Gomoku show that the proposed\ntree policy is more efficient than other competing methods.\n",
                "链接": "https://arxiv.org/abs/2204.12043"
            },
            {
                "文章ID": "75072",
                "标题": "Nearly Optimal Steiner Trees using Graph Neural Network Assisted Monte\n  Carlo Tree Search",
                "作者": " Reyan Ahmed,  Mithun Ghosh,  Kwang-Sung Jun,  Stephen Kobourov",
                "发布日期": "2023-05-02",
                "摘要": "  Graph neural networks are useful for learning problems, as well as for\ncombinatorial and graph problems such as the Subgraph Isomorphism Problem and\nthe Traveling Salesman Problem. We describe an approach for computing Steiner\nTrees by combining a graph neural network and Monte Carlo Tree Search. We first\ntrain a graph neural network that takes as input a partial solution and\nproposes a new node to be added as output. This neural network is then used in\na Monte Carlo search to compute a Steiner tree. The proposed method\nconsistently outperforms the standard 2-approximation algorithm on many\ndifferent types of graphs and often finds the optimal solution.\n",
                "链接": "https://arxiv.org/abs/2305.00535"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用gpt4做评测指标优缺点的文章",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找使用GPT4v完成多模态智能体的论文",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "使用LLM进行蛋白质结构/功能/性质预测的论文",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "帮我查找一下2018年以后使用强化学习做机器翻译任务的论文",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "请找出使用Transformer模型并在大规模数据集上进行预训练的论文。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "找一下使用强化学习做代码生成的论文",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下关于大模型使用工具的安全性的论文。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下对使用GPT生成数据集的训练步骤进行改进的论文。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "请找到利用clip做开放词汇检测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "116861",
                "标题": "CastDet: Toward Open Vocabulary Aerial Object Detection with\n  CLIP-Activated Student-Teacher Learning",
                "作者": " Yan Li,  Weiwei Guo,  Dunyun He,  Jiaqi Zhou,  Yuze Gao,  Wenxian Yu",
                "发布日期": "2023-11-21",
                "摘要": "  Object detection in aerial images is a pivotal task for various earth\nobservation applications, whereas current algorithms learn to detect only a\npre-defined set of object categories demanding sufficient bounding-box\nannotated training samples and fail to detect novel object categories. In this\npaper, we consider open-vocabulary object detection (OVD) in aerial images that\nenables the characterization of new objects beyond training categories on the\nearth surface without annotating training images for these new categories. The\nperformance of OVD depends on the quality of class-agnostic region proposals\nand pseudo-labels that can generalize well to novel object categories. To\nsimultaneously generate high-quality proposals and pseudo-labels, we propose\nCastDet, a CLIP-activated student-teacher open-vocabulary object Detection\nframework. Our end-to-end framework within the student-teacher mechanism\nemploys the CLIP model as an extra omniscient teacher of rich knowledge into\nthe student-teacher self-learning process. By doing so, our approach boosts\nnovel object proposals and classification. Furthermore, we design a dynamic\nlabel queue technique to maintain high-quality pseudo labels during batch\ntraining and mitigate label imbalance. We conduct extensive experiments on\nmultiple existing aerial object detection datasets, which are set up for the\nOVD task. Experimental results demonstrate our CastDet achieving superior\nopen-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean),\nwhich outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD\ndataset.\n",
                "链接": "https://arxiv.org/abs/2311.11646"
            },
            {
                "文章ID": "68353",
                "标题": "CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting\n  and Anchor Pre-Matching",
                "作者": " Xiaoshi Wu,  Feng Zhu,  Rui Zhao,  Hongsheng Li",
                "发布日期": "2023-03-24",
                "摘要": "  Open-vocabulary detection (OVD) is an object detection task aiming at\ndetecting objects from novel categories beyond the base categories on which the\ndetector is trained. Recent OVD methods rely on large-scale visual-language\npre-trained models, such as CLIP, for recognizing novel objects. We identify\nthe two core obstacles that need to be tackled when incorporating these models\ninto detector training: (1) the distribution mismatch that happens when\napplying a VL-model trained on whole images to region recognition tasks; (2)\nthe difficulty of localizing objects of unseen classes. To overcome these\nobstacles, we propose CORA, a DETR-style framework that adapts CLIP for\nOpen-vocabulary detection by Region prompting and Anchor pre-matching. Region\nprompting mitigates the whole-to-region distribution gap by prompting the\nregion features of the CLIP-based region classifier. Anchor pre-matching helps\nlearning generalizable object localization by a class-aware matching mechanism.\nWe evaluate CORA on the COCO OVD benchmark, where we achieve 41.7 AP50 on novel\nclasses, which outperforms the previous SOTA by 2.4 AP50 even without resorting\nto extra training data. When extra training data is available, we train\nCORA$^+$ on both ground-truth base-category annotations and additional pseudo\nbounding box labels computed by CORA. CORA$^+$ achieves 43.1 AP50 on the COCO\nOVD benchmark and 28.1 box APr on the LVIS OVD benchmark.\n",
                "链接": "https://arxiv.org/abs/2303.13076"
            },
            {
                "文章ID": "72044",
                "标题": "RECLIP: Resource-efficient CLIP by Training with Small Images",
                "作者": " Runze Li,  Dahun Kim,  Bir Bhanu,  Weicheng Kuo",
                "发布日期": "2023-09-01",
                "摘要": "  We present RECLIP (Resource-efficient CLIP), a simple method that minimizes\ncomputational resource footprint for CLIP (Contrastive Language Image\nPretraining). Inspired by the notion of coarse-to-fine in computer vision, we\nleverage small images to learn from large-scale language supervision\nefficiently, and finetune the model with high-resolution data in the end. Since\nthe complexity of the vision transformer heavily depends on input image size,\nour approach significantly reduces the training resource requirements both in\ntheory and in practice. Using the same batch size and training epoch, RECLIP\nachieves highly competitive zero-shot classification and image-text retrieval\naccuracy with 6 to 8x less computational resources and 7 to 9x fewer FLOPs than\nthe baseline. Compared to the state-of-the-art contrastive learning methods,\nRECLIP demonstrates 5 to 59x training resource savings while maintaining highly\ncompetitive zero-shot classification and retrieval performance. Finally, RECLIP\nmatches the state of the art in transfer learning to open-vocabulary detection\ntasks, achieving 32 APr on LVIS. We hope this work will pave the path for the\nbroader research community to explore language supervised pretraining in\nresource-friendly settings.\n",
                "链接": "https://arxiv.org/abs/2304.06028"
            },
            {
                "文章ID": "77149",
                "标题": "CLIP-Count: Towards Text-Guided Zero-Shot Object Counting",
                "作者": " Ruixiang Jiang,  Lingbo Liu,  Changwen Chen",
                "发布日期": "2023-08-11",
                "摘要": "  Recent advances in visual-language models have shown remarkable zero-shot\ntext-image matching ability that is transferable to downstream tasks such as\nobject detection and segmentation. Adapting these models for object counting,\nhowever, remains a formidable challenge. In this study, we first investigate\ntransferring vision-language models (VLMs) for class-agnostic object counting.\nSpecifically, we propose CLIP-Count, the first end-to-end pipeline that\nestimates density maps for open-vocabulary objects with text guidance in a\nzero-shot manner. To align the text embedding with dense visual features, we\nintroduce a patch-text contrastive loss that guides the model to learn\ninformative patch-level visual representations for dense prediction. Moreover,\nwe design a hierarchical patch-text interaction module to propagate semantic\ninformation across different resolution levels of visual features. Benefiting\nfrom the full exploitation of the rich image-text alignment knowledge of\npretrained VLMs, our method effectively generates high-quality density maps for\nobjects-of-interest. Extensive experiments on FSC-147, CARPK, and ShanghaiTech\ncrowd counting datasets demonstrate state-of-the-art accuracy and\ngeneralizability of the proposed method. Code is available:\nhttps://github.com/songrise/CLIP-Count.\n",
                "链接": "https://arxiv.org/abs/2305.07304"
            }
        ]
    },
    {
        "question": {
            "question": "请找到使用自蒸馏加强目标检测性能的论文",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下使用CrossWoz或MultiWoz数据集进行DST评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "46848",
                "标题": "MultiWOZ-DF -- A Dataflow implementation of the MultiWOZ dataset",
                "作者": " Joram Meron,  Victor Guimarães",
                "发布日期": "2022-11-07",
                "摘要": "  Semantic Machines (SM) have introduced the use of the dataflow (DF) paradigm\nto dialogue modelling, using computational graphs to hierarchically represent\nuser requests, data, and the dialogue history [Semantic Machines et al. 2020].\nAlthough the main focus of that paper was the SMCalFlow dataset (to date, the\nonly dataset with \"native\" DF annotations), they also reported some results of\nan experiment using a transformed version of the commonly used MultiWOZ dataset\n[Budzianowski et al. 2018] into a DF format. In this paper, we expand the\nexperiments using DF for the MultiWOZ dataset, exploring some additional\nexperimental set-ups. The code and instructions to reproduce the experiments\nreported here have been released. The contributions of this paper are: 1.) A DF\nimplementation capable of executing MultiWOZ dialogues; 2.) Several versions of\nconversion of MultiWOZ into a DF format are presented; 3.) Experimental results\non state match and translation accuracy.\n",
                "链接": "https://arxiv.org/abs/2211.02303"
            },
            {
                "文章ID": "112862",
                "标题": "Multi-User MultiWOZ: Task-Oriented Dialogues among Multiple Users",
                "作者": " Yohan Jo,  Xinyan Zhao,  Arijit Biswas,  Nikoletta Basiou,  Vincent Auvray,  Nikolaos Malandrakis,  Angeliki Metallinou,  Alexandros Potamianos",
                "发布日期": "2023-11-01",
                "摘要": "  While most task-oriented dialogues assume conversations between the agent and\none user at a time, dialogue systems are increasingly expected to communicate\nwith multiple users simultaneously who make decisions collaboratively. To\nfacilitate development of such systems, we release the Multi-User MultiWOZ\ndataset: task-oriented dialogues among two users and one agent. To collect this\ndataset, each user utterance from MultiWOZ 2.2 was replaced with a small chat\nbetween two users that is semantically and pragmatically consistent with the\noriginal user utterance, thus resulting in the same dialogue state and system\nresponse. These dialogues reflect interesting dynamics of collaborative\ndecision-making in task-oriented scenarios, e.g., social chatter and\ndeliberation. Supported by this data, we propose the novel task of multi-user\ncontextual query rewriting: to rewrite a task-oriented chat between two users\nas a concise task-oriented query that retains only task-relevant information\nand that is directly consumable by the dialogue system. We demonstrate that in\nmulti-user dialogues, using predicted rewrites substantially improves dialogue\nstate tracking without modifying existing dialogue systems that are trained for\nsingle-user dialogues. Further, this method surpasses training a medium-sized\nmodel directly on multi-user dialogues and generalizes to unseen domains.\n",
                "链接": "https://arxiv.org/abs/2310.20479"
            },
            {
                "文章ID": "45137",
                "标题": "Is MultiWOZ a Solved Task? An Interactive TOD Evaluation Framework with\n  User Simulator",
                "作者": " Qinyuan Cheng,  Linyang Li,  Guofeng Quan,  Feng Gao,  Xiaofeng Mou,  Xipeng Qiu",
                "发布日期": "2022-10-27",
                "摘要": "  Task-Oriented Dialogue (TOD) systems are drawing more and more attention in\nrecent studies. Current methods focus on constructing pre-trained models or\nfine-tuning strategies while the evaluation of TOD is limited by a policy\nmismatch problem. That is, during evaluation, the user utterances are from the\nannotated dataset while these utterances should interact with previous\nresponses which can have many alternatives besides annotated texts. Therefore,\nin this work, we propose an interactive evaluation framework for TOD. We first\nbuild a goal-oriented user simulator based on pre-trained models and then use\nthe user simulator to interact with the dialogue system to generate dialogues.\nBesides, we introduce a sentence-level and a session-level score to measure the\nsentence fluency and session coherence in the interactive evaluation.\nExperimental results show that RL-based TOD systems trained by our proposed\nuser simulator can achieve nearly 98% inform and success rates in the\ninteractive evaluation of MultiWOZ dataset and the proposed scores measure the\nresponse quality besides the inform and success rates. We are hoping that our\nwork will encourage simulator-based interactive evaluations in the TOD task.\n",
                "链接": "https://arxiv.org/abs/2210.14529"
            },
            {
                "文章ID": "7222",
                "标题": "ASSIST: Towards Label Noise-Robust Dialogue State Tracking",
                "作者": " Fanghua Ye,  Yue Feng,  Emine Yilmaz",
                "发布日期": "2022-03-15",
                "摘要": "  The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state\ntracking (DST). However, substantial noise has been discovered in its state\nannotations. Such noise brings about huge challenges for training DST models\nrobustly. Although several refined versions, including MultiWOZ 2.1-2.4, have\nbeen published recently, there are still lots of noisy labels, especially in\nthe training set. Besides, it is costly to rectify all the problematic\nannotations. In this paper, instead of improving the annotation quality\nfurther, we propose a general framework, named ASSIST (lAbel noiSe-robuSt\ndIalogue State Tracking), to train DST models robustly from noisy labels.\nASSIST first generates pseudo labels for each sample in the training set by\nusing an auxiliary model trained on a small clean dataset, then puts the\ngenerated pseudo labels and vanilla noisy labels together to train the primary\nmodel. We show the validity of ASSIST theoretically. Experimental results also\ndemonstrate that ASSIST improves the joint goal accuracy of DST by up to\n$28.16\\%$ on MultiWOZ 2.0 and $8.41\\%$ on MultiWOZ 2.4, compared to using only\nthe vanilla noisy labels.\n",
                "链接": "https://arxiv.org/abs/2202.13024"
            },
            {
                "文章ID": "17975",
                "标题": "LUNA: Learning Slot-Turn Alignment for Dialogue State Tracking",
                "作者": " Yifan Wang,  Jing Zhao,  Junwei Bao,  Chaoqun Duan,  Youzheng Wu,  Xiaodong He",
                "发布日期": "2022-05-06",
                "摘要": "  Dialogue state tracking (DST) aims to predict the current dialogue state\ngiven the dialogue history. Existing methods generally exploit the utterances\nof all dialogue turns to assign value for each slot. This could lead to\nsuboptimal results due to the information introduced from irrelevant utterances\nin the dialogue history, which may be useless and can even cause confusion. To\naddress this problem, we propose LUNA, a sLot-tUrN Alignment enhanced approach.\nIt first explicitly aligns each slot with its most relevant utterance, then\nfurther predicts the corresponding value based on this aligned utterance\ninstead of all dialogue utterances. Furthermore, we design a slot ranking\nauxiliary task to learn the temporal correlation among slots which could\nfacilitate the alignment. Comprehensive experiments are conducted on\nmulti-domain task-oriented dialogue datasets, i.e., MultiWOZ 2.0, MultiWOZ 2.1,\nand MultiWOZ 2.2. The results show that LUNA achieves new state-of-the-art\nresults on these datasets.\n",
                "链接": "https://arxiv.org/abs/2205.02550"
            },
            {
                "文章ID": "79647",
                "标题": "Using Textual Interface to Align External Knowledge for End-to-End\n  Task-Oriented Dialogue Systems",
                "作者": " Qingyang Wu,  Deema Alnuhait,  Derek Chen,  Zhou Yu",
                "发布日期": "2023-05-24",
                "摘要": "  Traditional end-to-end task-oriented dialogue systems have been built with a\nmodularized design. However, such design often causes misalignment between the\nagent response and external knowledge, due to inadequate representation of\ninformation. Furthermore, its evaluation metrics emphasize assessing the\nagent's pre-lexicalization response, neglecting the quality of the completed\nresponse. In this work, we propose a novel paradigm that uses a textual\ninterface to align external knowledge and eliminate redundant processes. We\ndemonstrate our paradigm in practice through MultiWOZ-Remake, including an\ninteractive textual interface built for the MultiWOZ database and a\ncorrespondingly re-processed dataset. We train an end-to-end dialogue system to\nevaluate this new dataset. The experimental results show that our approach\ngenerates more natural final responses and achieves a greater task success rate\ncompared to the previous models.\n",
                "链接": "https://arxiv.org/abs/2305.13710"
            },
            {
                "文章ID": "68448",
                "标题": "Reevaluating Data Partitioning for Emotion Detection in EmoWOZ",
                "作者": " Moeen Mostafavi,  Michael D. Porter",
                "发布日期": "2023-03-24",
                "摘要": "  This paper focuses on the EmoWoz dataset, an extension of MultiWOZ that\nprovides emotion labels for the dialogues. MultiWOZ was partitioned initially\nfor another purpose, resulting in a distributional shift when considering the\nnew purpose of emotion recognition. The emotion tags in EmoWoz are highly\nimbalanced and unevenly distributed across the partitions, which causes\nsub-optimal performance and poor comparison of models. We propose a stratified\nsampling scheme based on emotion tags to address this issue, improve the\ndataset's distribution, and reduce dataset shift. We also introduce a special\ntechnique to handle conversation (sequential) data with many emotional tags.\nUsing our proposed sampling method, models built upon EmoWoz can perform\nbetter, making it a more reliable resource for training conversational agents\nwith emotional intelligence. We recommend that future researchers use this new\npartitioning to ensure consistent and accurate performance evaluations.\n",
                "链接": "https://arxiv.org/abs/2303.13364"
            },
            {
                "文章ID": "61900",
                "标题": "Dialogue State Distillation Network with Inter-slot Contrastive Learning\n  for Dialogue State Tracking",
                "作者": " Jing Xu,  Dandan Song,  Chong Liu,  Siu Cheung Hui,  Fei Li,  Qiang Ju,  Xiaonan He,  Jian Xie",
                "发布日期": "2023-03-08",
                "摘要": "  In task-oriented dialogue systems, Dialogue State Tracking (DST) aims to\nextract users' intentions from the dialogue history. Currently, most existing\napproaches suffer from error propagation and are unable to dynamically select\nrelevant information when utilizing previous dialogue states. Moreover, the\nrelations between the updates of different slots provide vital clues for DST.\nHowever, the existing approaches rely only on predefined graphs to indirectly\ncapture the relations. In this paper, we propose a Dialogue State Distillation\nNetwork (DSDN) to utilize relevant information of previous dialogue states and\nmigrate the gap of utilization between training and testing. Thus, it can\ndynamically exploit previous dialogue states and avoid introducing error\npropagation simultaneously. Further, we propose an inter-slot contrastive\nlearning loss to effectively capture the slot co-update relations from dialogue\ncontext. Experiments are conducted on the widely used MultiWOZ 2.0 and MultiWOZ\n2.1 datasets. The experimental results show that our proposed model achieves\nthe state-of-the-art performance for DST.\n",
                "链接": "https://arxiv.org/abs/2302.08220"
            },
            {
                "文章ID": "94649",
                "标题": "Dataflow Dialogue Generation",
                "作者": " Joram Meron,  Victor Guimarães",
                "发布日期": "2023-08-07",
                "摘要": "  We demonstrate task-oriented dialogue generation within the dataflow dialogue\nparadigm. We show an example of agenda driven dialogue generation for the\nMultiWOZ domain, and an example of generation without an agenda for the\nSMCalFlow domain, where we show an improvement in the accuracy of the\ntranslation of user requests to dataflow expressions when the generated\ndialogues are used to augment the translation training dataset.\n",
                "链接": "https://arxiv.org/abs/2308.02323"
            },
            {
                "文章ID": "20132",
                "标题": "Beyond the Granularity: Multi-Perspective Dialogue Collaborative\n  Selection for Dialogue State Tracking",
                "作者": " Jinyu Guo,  Kai Shuang,  Jijie Li,  Zihan Wang,  Yixuan Liu",
                "发布日期": "2022-05-23",
                "摘要": "  In dialogue state tracking, dialogue history is a crucial material, and its\nutilization varies between different models. However, no matter how the\ndialogue history is used, each existing model uses its own consistent dialogue\nhistory during the entire state tracking process, regardless of which slot is\nupdated. Apparently, it requires different dialogue history to update different\nslots in different turns. Therefore, using consistent dialogue contents may\nlead to insufficient or redundant information for different slots, which\naffects the overall performance. To address this problem, we devise DiCoS-DST\nto dynamically select the relevant dialogue contents corresponding to each slot\nfor state updating. Specifically, it first retrieves turn-level utterances of\ndialogue history and evaluates their relevance to the slot from a combination\nof three perspectives: (1) its explicit connection to the slot name; (2) its\nrelevance to the current turn dialogue; (3) Implicit Mention Oriented\nReasoning. Then these perspectives are combined to yield a decision, and only\nthe selected dialogue contents are fed into State Generator, which explicitly\nminimizes the distracting information passed to the downstream state\nprediction. Experimental results show that our approach achieves new\nstate-of-the-art performance on MultiWOZ 2.1 and MultiWOZ 2.2, and achieves\nsuperior performance on multiple mainstream benchmark datasets (including\nSim-M, Sim-R, and DSTC2).\n",
                "链接": "https://arxiv.org/abs/2205.10059"
            }
        ]
    },
    {
        "question": {
            "question": "2023年后利用hotpotqa数据集做问题生成任务的论文",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下使用机器学习方法进行心理健康疾病研究的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "29046",
                "标题": "Machine Learning Application in Health",
                "作者": " Ghadah Alshabana,  Marjn Sadati,  Thao Tran,  Michael Thompson,  Ashritha Chitimalla",
                "发布日期": "2022-07-14",
                "摘要": "  Coronavirus can be transmitted through the air by close proximity to infected\npersons. Commercial aircraft are a likely way to both transmit the virus among\npassengers and move the virus between locations. The importance of learning\nabout where and how coronavirus has entered the United States will help further\nour understanding of the disease. Air travelers can come from countries or\nareas with a high rate of infection and may very well be at risk of being\nexposed to the virus. Therefore, as they reach the United States, the virus\ncould easily spread. On our analysis, we utilized machine learning to determine\nif the number of flights into the Washington DC Metro Area had an effect on the\nnumber of cases and deaths reported in the city and surrounding area.\n",
                "链接": "https://arxiv.org/abs/2207.06228"
            },
            {
                "文章ID": "14307",
                "标题": "Multimodal Machine Learning in Precision Health",
                "作者": " Adrienne Kline,  Hanyin Wang,  Yikuan Li,  Saya Dennis,  Meghan Hutch,  Zhenxing Xu,  Fei Wang,  Feixiong Cheng,  Yuan Luo",
                "发布日期": "2022-04-12",
                "摘要": "  As machine learning and artificial intelligence are more frequently being\nleveraged to tackle problems in the health sector, there has been increased\ninterest in utilizing them in clinical decision-support. This has historically\nbeen the case in single modal data such as electronic health record data.\nAttempts to improve prediction and resemble the multimodal nature of clinical\nexpert decision-making this has been met in the computational field of machine\nlearning by a fusion of disparate data. This review was conducted to summarize\nthis field and identify topics ripe for future research. We conducted this\nreview in accordance with the PRISMA (Preferred Reporting Items for Systematic\nreviews and Meta-Analyses) extension for Scoping Reviews to characterize\nmulti-modal data fusion in health. We used a combination of content analysis\nand literature searches to establish search strings and databases of PubMed,\nGoogle Scholar, and IEEEXplore from 2011 to 2021. A final set of 125 articles\nwere included in the analysis. The most common health areas utilizing\nmulti-modal methods were neurology and oncology. However, there exist a wide\nbreadth of current applications. The most common form of information fusion was\nearly fusion. Notably, there was an improvement in predictive performance\nperforming heterogeneous data fusion. Lacking from the papers were clear\nclinical deployment strategies and pursuit of FDA-approved tools. These\nfindings provide a map of the current literature on multimodal data fusion as\napplied to health diagnosis/prognosis problems. Multi-modal machine learning,\nwhile more robust in its estimations over unimodal methods, has drawbacks in\nits scalability and the time-consuming nature of information concatenation.\n",
                "链接": "https://arxiv.org/abs/2204.04777"
            },
            {
                "文章ID": "92012",
                "标题": "Reproducibility in Machine Learning-Driven Research",
                "作者": " Harald Semmelrock,  Simone Kopeinik,  Dieter Theiler,  Tony Ross-Hellauer,  Dominik Kowald",
                "发布日期": "2023-07-21",
                "摘要": "  Research is facing a reproducibility crisis, in which the results and\nfindings of many studies are difficult or even impossible to reproduce. This is\nalso the case in machine learning (ML) and artificial intelligence (AI)\nresearch. Often, this is the case due to unpublished data and/or source-code,\nand due to sensitivity to ML training conditions. Although different solutions\nto address this issue are discussed in the research community such as using ML\nplatforms, the level of reproducibility in ML-driven research is not increasing\nsubstantially. Therefore, in this mini survey, we review the literature on\nreproducibility in ML-driven research with three main aims: (i) reflect on the\ncurrent situation of ML reproducibility in various research fields, (ii)\nidentify reproducibility issues and barriers that exist in these research\nfields applying ML, and (iii) identify potential drivers such as tools,\npractices, and interventions that support ML reproducibility. With this, we\nhope to contribute to decisions on the viability of different solutions for\nsupporting ML reproducibility.\n",
                "链接": "https://arxiv.org/abs/2307.10320"
            },
            {
                "文章ID": "98633",
                "标题": "Discovering Mental Health Research Topics with Topic Modeling",
                "作者": " Xin Gao,  Cem Sazara",
                "发布日期": "2023-08-29",
                "摘要": "  Mental health significantly influences various aspects of our daily lives,\nand its importance has been increasingly recognized by the research community\nand the general public, particularly in the wake of the COVID-19 pandemic. This\nheightened interest is evident in the growing number of publications dedicated\nto mental health in the past decade. In this study, our goal is to identify\ngeneral trends in the field and pinpoint high-impact research topics by\nanalyzing a large dataset of mental health research papers. To accomplish this,\nwe collected abstracts from various databases and trained a customized\nSentence-BERT based embedding model leveraging the BERTopic framework. Our\ndataset comprises 96,676 research papers pertaining to mental health, enabling\nus to examine the relationships between different topics using their abstracts.\nTo evaluate the effectiveness of the model, we compared it against two other\nstate-of-the-art methods: Top2Vec model and LDA-BERT model. The model\ndemonstrated superior performance in metrics that measure topic diversity and\ncoherence. To enhance our analysis, we also generated word clouds to provide a\ncomprehensive overview of the machine learning models applied in mental health\nresearch, shedding light on commonly utilized techniques and emerging trends.\nFurthermore, we provide a GitHub link* to the dataset used in this paper,\nensuring its accessibility for further research endeavors.\n",
                "链接": "https://arxiv.org/abs/2308.13569"
            },
            {
                "文章ID": "32886",
                "标题": "Research on restaurant recommendation using machine learning",
                "作者": " Junan Pan,  Zhihao Zhao",
                "发布日期": "2022-08-11",
                "摘要": "  A recommender system is a system that helps users filter irrelevant\ninformation and create user interest models based on their historical records.\nWith the continuous development of Internet information, recommendation systems\nhave received widespread attention in the industry. In this era of ubiquitous\ndata and information, how to obtain and analyze these data has become the\nresearch topic of many people. In view of this situation, this paper makes some\nbrief overviews of machine learning-related recommendation systems. By\nanalyzing some technologies and ideas used by machine learning in recommender\nsystems, let more people understand what is Big data and what is machine\nlearning. The most important point is to let everyone understand the profound\nimpact of machine learning on our daily life.\n",
                "链接": "https://arxiv.org/abs/2208.05113"
            },
            {
                "文章ID": "60653",
                "标题": "Towards Inferential Reproducibility of Machine Learning Research",
                "作者": " Michael Hagmann,  Philipp Meier,  Stefan Riezler",
                "发布日期": "2023-10-10",
                "摘要": "  Reliability of machine learning evaluation -- the consistency of observed\nevaluation scores across replicated model training runs -- is affected by\nseveral sources of nondeterminism which can be regarded as measurement noise.\nCurrent tendencies to remove noise in order to enforce reproducibility of\nresearch results neglect inherent nondeterminism at the implementation level\nand disregard crucial interaction effects between algorithmic noise factors and\ndata properties. This limits the scope of conclusions that can be drawn from\nsuch experiments. Instead of removing noise, we propose to incorporate several\nsources of variance, including their interaction with data properties, into an\nanalysis of significance and reliability of machine learning evaluation, with\nthe aim to draw inferences beyond particular instances of trained models. We\nshow how to use linear mixed effects models (LMEMs) to analyze performance\nevaluation scores, and to conduct statistical inference with a generalized\nlikelihood ratio test (GLRT). This allows us to incorporate arbitrary sources\nof noise like meta-parameter variations into statistical significance testing,\nand to assess performance differences conditional on data properties.\nFurthermore, a variance component analysis (VCA) enables the analysis of the\ncontribution of noise sources to overall variance and the computation of a\nreliability coefficient by the ratio of substantial to total variance.\n",
                "链接": "https://arxiv.org/abs/2302.04054"
            },
            {
                "文章ID": "88301",
                "标题": "Streamlining Social Media Information Retrieval for Public Health\n  Research with Deep Learning",
                "作者": " Yining Hua,  Shixu Lin,  Minghui Li,  Yujie Zhang,  Peilin Zhou,  Ying-Chih Lo,  Li Zhou,  Jie Yang",
                "发布日期": "2023-06-29",
                "摘要": "  The utilization of social media in epidemic surveillance has been well\nestablished. Nonetheless, bias is often introduced when pre-defined lexicons\nare used to retrieve relevant corpus. This study introduces a framework aimed\nat curating extensive dictionaries of medical colloquialisms and Unified\nMedical Language System (UMLS) concepts. The framework comprises three modules:\na BERT-based Named Entity Recognition (NER) model that identifies medical\nentities from social media content, a deep-learning powered normalization\nmodule that standardizes the extracted entities, and a semi-supervised\nclustering module that assigns the most probable UMLS concept to each\nstandardized entity. We applied this framework to COVID-19-related tweets from\nFebruary 1, 2020, to April 30, 2022, generating a symptom dictionary (available\nat https://github.com/ningkko/UMLS_colloquialism/) composed of 9,249\nstandardized entities mapped to 876 UMLS concepts and 38,175 colloquial\nexpressions. This framework demonstrates encouraging potential in addressing\nthe constraints of keyword matching information retrieval in social media-based\npublic health research.\n",
                "链接": "https://arxiv.org/abs/2306.16001"
            },
            {
                "文章ID": "27119",
                "标题": "Physics-informed machine learning for Structural Health Monitoring",
                "作者": " Elizabeth J Cross,  Samuel J Gibson,  Matthew R Jones,  Daniel J Pitchforth,  Sikai Zhang,  Timothy J Rogers",
                "发布日期": "2022-07-01",
                "摘要": "  The use of machine learning in Structural Health Monitoring is becoming more\ncommon, as many of the inherent tasks (such as regression and classification)\nin developing condition-based assessment fall naturally into its remit. This\nchapter introduces the concept of physics-informed machine learning, where one\nadapts ML algorithms to account for the physical insight an engineer will often\nhave of the structure they are attempting to model or assess. The chapter will\ndemonstrate how grey-box models, that combine simple physics-based models with\ndata-driven ones, can improve predictive capability in an SHM setting. A\nparticular strength of the approach demonstrated here is the capacity of the\nmodels to generalise, with enhanced predictive capability in different regimes.\nThis is a key issue when life-time assessment is a requirement, or when\nmonitoring data do not span the operational conditions a structure will\nundergo.\n  The chapter will provide an overview of physics-informed ML, introducing a\nnumber of new approaches for grey-box modelling in a Bayesian setting. The main\nML tool discussed will be Gaussian process regression, we will demonstrate how\nphysical assumptions/models can be incorporated through constraints, through\nthe mean function and kernel design, and finally in a state-space setting. A\nrange of SHM applications will be demonstrated, from loads monitoring tasks for\noff-shore and aerospace structures, through to performance monitoring for\nlong-span bridges.\n",
                "链接": "https://arxiv.org/abs/2206.15303"
            },
            {
                "文章ID": "119609",
                "标题": "Machine Learning for Health symposium 2023 -- Findings track",
                "作者": " Stefan Hegselmann,  Antonio Parziale,  Divya Shanmugam,  Shengpu Tang,  Mercy Nyamewaa Asiedu,  Serina Chang,  Thomas Hartvigsen,  Harvineet Singh",
                "发布日期": "2023-12-18",
                "摘要": "  A collection of the accepted Findings papers that were presented at the 3rd\nMachine Learning for Health symposium (ML4H 2023), which was held on December\n10, 2023, in New Orleans, Louisiana, USA. ML4H 2023 invited high-quality\nsubmissions on relevant problems in a variety of health-related disciplines\nincluding healthcare, biomedicine, and public health. Two submission tracks\nwere offered: the archival Proceedings track, and the non-archival Findings\ntrack. Proceedings were targeted at mature work with strong technical\nsophistication and a high impact to health. The Findings track looked for new\nideas that could spark insightful discussion, serve as valuable resources for\nthe community, or could enable new collaborations. Submissions to the\nProceedings track, if not accepted, were automatically considered for the\nFindings track. All the manuscripts submitted to ML4H Symposium underwent a\ndouble-blind peer-review process.\n",
                "链接": "https://arxiv.org/abs/2312.00655"
            },
            {
                "文章ID": "92530",
                "标题": "Psy-LLM: Scaling up Global Mental Health Psychological Services with\n  AI-based Large Language Models",
                "作者": " Tin Lai,  Yukun Shi,  Zicong Du,  Jiajie Wu,  Ken Fu,  Yichao Dou,  Ziqi Wang",
                "发布日期": "2023-09-04",
                "摘要": "  The demand for psychological counselling has grown significantly in recent\nyears, particularly with the global outbreak of COVID-19, which has heightened\nthe need for timely and professional mental health support. Online\npsychological counselling has emerged as the predominant mode of providing\nservices in response to this demand. In this study, we propose the Psy-LLM\nframework, an AI-based assistive tool leveraging Large Language Models (LLMs)\nfor question-answering in psychological consultation settings to ease the\ndemand for mental health professions. Our framework combines pre-trained LLMs\nwith real-world professional Q\\&A from psychologists and extensively crawled\npsychological articles. The Psy-LLM framework serves as a front-end tool for\nhealthcare professionals, allowing them to provide immediate responses and\nmindfulness activities to alleviate patient stress. Additionally, it functions\nas a screening tool to identify urgent cases requiring further assistance. We\nevaluated the framework using intrinsic metrics, such as perplexity, and\nextrinsic evaluation metrics, with human participant assessments of response\nhelpfulness, fluency, relevance, and logic. The results demonstrate the\neffectiveness of the Psy-LLM framework in generating coherent and relevant\nanswers to psychological questions. This article discusses the potential and\nlimitations of using large language models to enhance mental health support\nthrough AI technologies.\n",
                "链接": "https://arxiv.org/abs/2307.11991"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找基于优化实现模型越狱的文献",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "强化学习在大语言模型领域中应用的相关论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "115961",
                "标题": "Never Lost in the Middle: Improving Large Language Models via Attention\n  Strengthening Question Answering",
                "作者": " Junqing He,  Kunhao Pan,  Xiaoqun Dong,  Zhuoyang Song,  Yibo Liu,  Yuxin Liang,  Hao Wang,  Qianguo Sun,  Songxin Zhang,  Zejian Xie,  Jiaxing Zhang",
                "发布日期": "2023-11-16",
                "摘要": "  While large language models (LLMs) are equipped with longer text input\ncapabilities than before, they are struggling to seek correct information in\nlong contexts. The \"lost in the middle\" problem challenges most LLMs, referring\nto the dramatic decline in accuracy when correct information is located in the\nmiddle. To overcome this crucial issue, this paper proposes to enhance the\ninformation searching and reflection ability of LLMs in long contexts via\nspecially designed tasks called Attention Strengthening Multi-doc QA (ASM QA).\nFollowing these tasks, our model excels in focusing more precisely on the\ndesired information. Experimental results show substantial improvement in\nMulti-doc QA and other benchmarks, superior to state-of-the-art models by 13.7%\nabsolute gain in shuffled settings, by 21.5% in passage retrieval task. We\nrelease our model, Ziya-Reader to promote related research in the community.\n",
                "链接": "https://arxiv.org/abs/2311.09198"
            },
            {
                "文章ID": "96562",
                "标题": "Link-Context Learning for Multimodal LLMs",
                "作者": " Yan Tai,  Weichen Fan,  Zhao Zhang,  Feng Zhu,  Rui Zhao,  Ziwei Liu",
                "发布日期": "2023-08-16",
                "摘要": "  The ability to learn from context with novel concepts, and deliver\nappropriate responses are essential in human conversations. Despite current\nMultimodal Large Language Models (MLLMs) and Large Language Models (LLMs) being\ntrained on mega-scale datasets, recognizing unseen images or understanding\nnovel concepts in a training-free manner remains a challenge. In-Context\nLearning (ICL) explores training-free few-shot learning, where models are\nencouraged to ``learn to learn\" from limited tasks and generalize to unseen\ntasks. In this work, we propose link-context learning (LCL), which emphasizes\n\"reasoning from cause and effect\" to augment the learning capabilities of\nMLLMs. LCL goes beyond traditional ICL by explicitly strengthening the causal\nrelationship between the support set and the query set. By providing\ndemonstrations with causal links, LCL guides the model to discern not only the\nanalogy but also the underlying causal associations between data points, which\nempowers MLLMs to recognize unseen images and understand novel concepts more\neffectively. To facilitate the evaluation of this novel approach, we introduce\nthe ISEKAI dataset, comprising exclusively of unseen generated image-label\npairs designed for link-context learning. Extensive experiments show that our\nLCL-MLLM exhibits strong link-context learning capabilities to novel concepts\nover vanilla MLLMs. Code and data will be released at\nhttps://github.com/isekai-portal/Link-Context-Learning.\n",
                "链接": "https://arxiv.org/abs/2308.07891"
            },
            {
                "文章ID": "21899",
                "标题": "E2S2: Encoding-Enhanced Sequence-to-Sequence Pretraining for Language\n  Understanding and Generation",
                "作者": " Qihuang Zhong,  Liang Ding,  Juhua Liu,  Bo Du,  Dacheng Tao",
                "发布日期": "2022-12-06",
                "摘要": "  Sequence-to-sequence (seq2seq) learning is a popular fashion for large-scale\npretraining language models. However, the prior seq2seq pretraining models\ngenerally focus on reconstructive objectives on the decoder side and neglect\nthe effect of encoder-side supervision, which we argue may lead to sub-optimal\nperformance. To verify our hypothesis, we first empirically study the\nfunctionalities of the encoder and decoder in seq2seq pretrained language\nmodels, and find that the encoder takes an important but under-exploitation\nrole than the decoder regarding the downstream performance and neuron\nactivation. Therefore, we propose an encoding-enhanced seq2seq pretraining\nstrategy, namely E2S2, which improves the seq2seq models via integrating more\nefficient self-supervised information into the encoders. Specifically, E2S2\nadopts two self-supervised objectives on the encoder side from two aspects: 1)\nlocally denoising the corrupted sentence (denoising objective); and 2) globally\nlearning better sentence representations (contrastive objective). With the help\nof both objectives, the encoder can effectively distinguish the noise tokens\nand capture high-level (i.e. syntactic and semantic) knowledge, thus\nstrengthening the ability of seq2seq model to accurately achieve the\nconditional generation. On a large diversity of downstream natural language\nunderstanding and generation tasks, E2S2 dominantly improves the performance of\nits powerful backbone models, e.g. BART and T5. For example, upon BART\nbackbone, we achieve +1.1% averaged gain on the general language understanding\nevaluation (GLUE) benchmark and +1.75% F_0.5 score improvement on CoNLL2014\ndataset. We also provide in-depth analyses to show the improvement stems from\nbetter linguistic representation. We hope that our work will foster future\nself-supervision research on seq2seq language model pretraining.\n",
                "链接": "https://arxiv.org/abs/2205.14912"
            },
            {
                "文章ID": "72480",
                "标题": "Fairness in Visual Clustering: A Novel Transformer Clustering Approach",
                "作者": " Xuan-Bac Nguyen,  Chi Nhan Duong,  Marios Savvides,  Kaushik Roy,  Hugh Churchill,  Khoa Luu",
                "发布日期": "2023-09-19",
                "摘要": "  Promoting fairness for deep clustering models in unsupervised clustering\nsettings to reduce demographic bias is a challenging goal. This is because of\nthe limitation of large-scale balanced data with well-annotated labels for\nsensitive or protected attributes. In this paper, we first evaluate demographic\nbias in deep clustering models from the perspective of cluster purity, which is\nmeasured by the ratio of positive samples within a cluster to their correlation\ndegree. This measurement is adopted as an indication of demographic bias. Then,\na novel loss function is introduced to encourage a purity consistency for all\nclusters to maintain the fairness aspect of the learned clustering model.\nMoreover, we present a novel attention mechanism, Cross-attention, to measure\ncorrelations between multiple clusters, strengthening faraway positive samples\nand improving the purity of clusters during the learning process. Experimental\nresults on a large-scale dataset with numerous attribute settings have\ndemonstrated the effectiveness of the proposed approach on both clustering\naccuracy and fairness enhancement on several sensitive attributes.\n",
                "链接": "https://arxiv.org/abs/2304.07408"
            },
            {
                "文章ID": "83477",
                "标题": "Exposing Bias in Online Communities through Large-Scale Language Models",
                "作者": " Celine Wald,  Lukas Pfahler",
                "发布日期": "2023-06-06",
                "摘要": "  Progress in natural language generation research has been shaped by the\never-growing size of language models. While large language models pre-trained\non web data can generate human-sounding text, they also reproduce social biases\nand contribute to the propagation of harmful stereotypes. This work utilises\nthe flaw of bias in language models to explore the biases of six different\nonline communities. In order to get an insight into the communities'\nviewpoints, we fine-tune GPT-Neo 1.3B with six social media datasets. The bias\nof the resulting models is evaluated by prompting the models with different\ndemographics and comparing the sentiment and toxicity values of these\ngenerations. Together, these methods reveal that bias differs in type and\nintensity for the various models. This work not only affirms how easily bias is\nabsorbed from training data but also presents a scalable method to identify and\ncompare the bias of different datasets or communities. Additionally, the\nexamples generated for this work demonstrate the limitations of using automated\nsentiment and toxicity classifiers in bias research.\n",
                "链接": "https://arxiv.org/abs/2306.02294"
            },
            {
                "文章ID": "102874",
                "标题": "Baichuan 2: Open Large-scale Language Models",
                "作者": " Aiyuan Yang,  Bin Xiao,  Bingning Wang,  Borong Zhang,  Ce Bian,  Chao Yin,  Chenxu Lv,  Da Pan,  Dian Wang,  Dong Yan,  Fan Yang,  Fei Deng,  Feng Wang,  Feng Liu,  Guangwei Ai,  Guosheng Dong,  Haizhou Zhao,  Hang Xu,  Haoze Sun,  Hongda Zhang,  Hui Liu,  Jiaming Ji,  Jian Xie,  JunTao Dai,  Kun Fang,  Lei Su,  Liang Song,  Lifeng Liu,  Liyun Ru,  Luyao Ma,  Mang Wang,  Mickel Liu,  MingAn Lin,  Nuolan Nie,  Peidong Guo,  Ruiyang Sun,  Tao Zhang,  Tianpeng Li,  Tianyu Li,  Wei Cheng,  Weipeng Chen,  Xiangrong Zeng,  Xiaochuan Wang,  Xiaoxi Chen,  Xin Men,  Xin Yu,  Xuehai Pan,  Yanjun Shen,  Yiding Wang,  Yiyu Li,  Youxin Jiang,  Yuchen Gao,  Yupeng Zhang,  Zenan Zhou,  Zhiying Wu",
                "发布日期": "2023-09-21",
                "摘要": "  Large language models (LLMs) have demonstrated remarkable performance on a\nvariety of natural language tasks based on just a few examples of natural\nlanguage instructions, reducing the need for extensive feature engineering.\nHowever, most powerful LLMs are closed-source or limited in their capability\nfor languages other than English. In this technical report, we present Baichuan\n2, a series of large-scale multilingual language models containing 7 billion\nand 13 billion parameters, trained from scratch, on 2.6 trillion tokens.\nBaichuan 2 matches or outperforms other open-source models of similar size on\npublic benchmarks like MMLU, CMMLU, GSM8K, and HumanEval. Furthermore, Baichuan\n2 excels in vertical domains such as medicine and law. We will release all\npre-training model checkpoints to benefit the research community in better\nunderstanding the training dynamics of Baichuan 2.\n",
                "链接": "https://arxiv.org/abs/2309.10305"
            },
            {
                "文章ID": "58357",
                "标题": "Learning Large Scale Sparse Models",
                "作者": " Atul Dhingra,  Jie Shen,  Nicholas Kleene",
                "发布日期": "2023-01-31",
                "摘要": "  In this work, we consider learning sparse models in large scale settings,\nwhere the number of samples and the feature dimension can grow as large as\nmillions or billions. Two immediate issues occur under such challenging\nscenario: (i) computational cost; (ii) memory overhead. In particular, the\nmemory issue precludes a large volume of prior algorithms that are based on\nbatch optimization technique. To remedy the problem, we propose to learn sparse\nmodels such as Lasso in an online manner where in each iteration, only one\nrandomly chosen sample is revealed to update a sparse iterate. Thereby, the\nmemory cost is independent of the sample size and gradient evaluation for one\nsample is efficient. Perhaps amazingly, we find that with the same parameter,\nsparsity promoted by batch methods is not preserved in online fashion. We\nanalyze such interesting phenomenon and illustrate some effective variants\nincluding mini-batch methods and a hard thresholding based stochastic gradient\nalgorithm. Extensive experiments are carried out on a public dataset which\nsupports our findings and algorithms.\n",
                "链接": "https://arxiv.org/abs/2301.10958"
            },
            {
                "文章ID": "72952",
                "标题": "In ChatGPT We Trust? Measuring and Characterizing the Reliability of\n  ChatGPT",
                "作者": " Xinyue Shen,  Zeyuan Chen,  Michael Backes,  Yang Zhang",
                "发布日期": "2023-10-06",
                "摘要": "  The way users acquire information is undergoing a paradigm shift with the\nadvent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves\nknowledge from the model itself and generates answers for users. ChatGPT's\nimpressive question-answering (QA) capability has attracted more than 100\nmillion users within a short period of time but has also raised concerns\nregarding its reliability. In this paper, we perform the first large-scale\nmeasurement of ChatGPT's reliability in the generic QA scenario with a\ncarefully curated set of 5,695 questions across ten datasets and eight domains.\nWe find that ChatGPT's reliability varies across different domains, especially\nunderperforming in law and science questions. We also demonstrate that system\nroles, originally designed by OpenAI to allow users to steer ChatGPT's\nbehavior, can impact ChatGPT's reliability in an imperceptible way. We further\nshow that ChatGPT is vulnerable to adversarial examples, and even a single\ncharacter change can negatively affect its reliability in certain cases. We\nbelieve that our study provides valuable insights into ChatGPT's reliability\nand underscores the need for strengthening the reliability and security of\nlarge language models (LLMs).\n",
                "链接": "https://arxiv.org/abs/2304.08979"
            },
            {
                "文章ID": "55833",
                "标题": "Targeted Phishing Campaigns using Large Scale Language Models",
                "作者": " Rabimba Karanjai",
                "发布日期": "2023-01-03",
                "摘要": "  In this research, we aim to explore the potential of natural language models\n(NLMs) such as GPT-3 and GPT-2 to generate effective phishing emails. Phishing\nemails are fraudulent messages that aim to trick individuals into revealing\nsensitive information or taking actions that benefit the attackers. We propose\na framework for evaluating the performance of NLMs in generating these types of\nemails based on various criteria, including the quality of the generated text,\nthe ability to bypass spam filters, and the success rate of tricking\nindividuals. Our evaluations show that NLMs are capable of generating phishing\nemails that are difficult to detect and that have a high success rate in\ntricking individuals, but their effectiveness varies based on the specific NLM\nand training data used. Our research indicates that NLMs could have a\nsignificant impact on the prevalence of phishing attacks and emphasizes the\nneed for further study on the ethical and security implications of using NLMs\nfor malicious purposes.\n",
                "链接": "https://arxiv.org/abs/2301.00665"
            },
            {
                "文章ID": "79284",
                "标题": "Meta-in-context learning in large language models",
                "作者": " Julian Coda-Forno,  Marcel Binz,  Zeynep Akata,  Matthew Botvinick,  Jane X. Wang,  Eric Schulz",
                "发布日期": "2023-05-23",
                "摘要": "  Large language models have shown tremendous performance in a variety of\ntasks. In-context learning -- the ability to improve at a task after being\nprovided with a number of demonstrations -- is seen as one of the main\ncontributors to their success. In the present paper, we demonstrate that the\nin-context learning abilities of large language models can be recursively\nimproved via in-context learning itself. We coin this phenomenon\nmeta-in-context learning. Looking at two idealized domains, a one-dimensional\nregression task and a two-armed bandit task, we show that meta-in-context\nlearning adaptively reshapes a large language model's priors over expected\ntasks. Furthermore, we find that meta-in-context learning modifies the\nin-context learning strategies of such models. Finally, we extend our approach\nto a benchmark of real-world regression problems where we observe competitive\nperformance to traditional learning algorithms. Taken together, our work\nimproves our understanding of in-context learning and paves the way toward\nadapting large language models to the environment they are applied purely\nthrough meta-in-context learning rather than traditional finetuning.\n",
                "链接": "https://arxiv.org/abs/2305.12907"
            }
        ]
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和脑科学交叉的研究",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "2022年后与AI for Science相关的综述论文",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "33431",
                "标题": "Where is VALDO? VAscular Lesions Detection and segmentatiOn challenge at\n  MICCAI 2021",
                "作者": "for the ALFA study  Carole H. Sudre, for the ALFA study  Kimberlin Van Wijnen, for the ALFA study  Florian Dubost, for the ALFA study  Hieab Adams, for the ALFA study  David Atkinson, for the ALFA study  Frederik Barkhof, for the ALFA study  Mahlet A. Birhanu, for the ALFA study  Esther E. Bron, for the ALFA study  Robin Camarasa, for the ALFA study  Nish Chaturvedi, for the ALFA study  Yuan Chen, for the ALFA study  Zihao Chen, for the ALFA study  Shuai Chen, for the ALFA study  Qi Dou, for the ALFA study  Tavia Evans, for the ALFA study  Ivan Ezhov, for the ALFA study  Haojun Gao, for the ALFA study  Marta Girones Sanguesa, for the ALFA study  Juan Domingo Gispert, for the ALFA study  Beatriz Gomez Anson, for the ALFA study  Alun D. Hughes, for the ALFA study  M. Arfan Ikram, for the ALFA study  Silvia Ingala, for the ALFA study  H. Rolf Jaeger, for the ALFA study  Florian Kofler, for the ALFA study  Hugo J. Kuijf, for the ALFA study  Denis Kutnar, for the ALFA study  Minho Lee, for the ALFA study  Bo Li, for the ALFA study  Luigi Lorenzini, for the ALFA study  Bjoern Menze, for the ALFA study  Jose Luis Molinuevo, for the ALFA study  Yiwei Pan, for the ALFA study  Elodie Puybareau, for the ALFA study  Rafael Rehwald, for the ALFA study  Ruisheng Su, for the ALFA study  Pengcheng Shi, for the ALFA study  Lorna Smith, for the ALFA study  Therese Tillin, for the ALFA study  Guillaume Tochon, for the ALFA study  Helene Urien, for the ALFA study  Bas H. M. van der Velden, for the ALFA study  Isabelle F. van der Velpen, for the ALFA study  Benedikt Wiestler, for the ALFA study  Frank J. Wolters, for the ALFA study  Pinar Yilmaz, for the ALFA study  Marius de Groot, for the ALFA study  Meike W. Vernooij, for the ALFA study  Marleen de Bruijne",
                "发布日期": "2022-08-16",
                "摘要": "  Imaging markers of cerebral small vessel disease provide valuable information\non brain health, but their manual assessment is time-consuming and hampered by\nsubstantial intra- and interrater variability. Automated rating may benefit\nbiomedical research, as well as clinical assessment, but diagnostic reliability\nof existing algorithms is unknown. Here, we present the results of the\n\\textit{VAscular Lesions DetectiOn and Segmentation} (\\textit{Where is VALDO?})\nchallenge that was run as a satellite event at the international conference on\nMedical Image Computing and Computer Aided Intervention (MICCAI) 2021. This\nchallenge aimed to promote the development of methods for automated detection\nand segmentation of small and sparse imaging markers of cerebral small vessel\ndisease, namely enlarged perivascular spaces (EPVS) (Task 1), cerebral\nmicrobleeds (Task 2) and lacunes of presumed vascular origin (Task 3) while\nleveraging weak and noisy labels. Overall, 12 teams participated in the\nchallenge proposing solutions for one or more tasks (4 for Task 1 - EPVS, 9 for\nTask 2 - Microbleeds and 6 for Task 3 - Lacunes). Multi-cohort data was used in\nboth training and evaluation. Results showed a large variability in performance\nboth across teams and across tasks, with promising results notably for Task 1 -\nEPVS and Task 2 - Microbleeds and not practically useful results yet for Task 3\n- Lacunes. It also highlighted the performance inconsistency across cases that\nmay deter use at an individual level, while still proving useful at a\npopulation level.\n",
                "链接": "https://arxiv.org/abs/2208.07167"
            },
            {
                "文章ID": "103843",
                "标题": "The LHCb ultra-fast simulation option, Lamarr: design and validation",
                "作者": "for the LHCb Simulation\n  Project  Lucio Anderlini, for the LHCb Simulation\n  Project  Matteo Barbetti, for the LHCb Simulation\n  Project  Simone Capelli, for the LHCb Simulation\n  Project  Gloria Corti, for the LHCb Simulation\n  Project  Adam Davis, for the LHCb Simulation\n  Project  Denis Derkach, for the LHCb Simulation\n  Project  Nikita Kazeev, for the LHCb Simulation\n  Project  Artem Maevskiy, for the LHCb Simulation\n  Project  Maurizio Martinelli, for the LHCb Simulation\n  Project  Sergei Mokonenko, for the LHCb Simulation\n  Project  Benedetto Gianluca Siddi, for the LHCb Simulation\n  Project  Zehua Xu",
                "发布日期": "2023-09-26",
                "摘要": "  Detailed detector simulation is the major consumer of CPU resources at LHCb,\nhaving used more than 90% of the total computing budget during Run 2 of the\nLarge Hadron Collider at CERN. As data is collected by the upgraded LHCb\ndetector during Run 3 of the LHC, larger requests for simulated data samples\nare necessary, and will far exceed the pledged resources of the experiment,\neven with existing fast simulation options. An evolution of technologies and\ntechniques to produce simulated samples is mandatory to meet the upcoming needs\nof analysis to interpret signal versus background and measure efficiencies. In\nthis context, we propose Lamarr, a Gaudi-based framework designed to offer the\nfastest solution for the simulation of the LHCb detector. Lamarr consists of a\npipeline of modules parameterizing both the detector response and the\nreconstruction algorithms of the LHCb experiment. Most of the parameterizations\nare made of Deep Generative Models and Gradient Boosted Decision Trees trained\non simulated samples or alternatively, where possible, on real data. Embedding\nLamarr in the general LHCb Gauss Simulation framework allows combining its\nexecution with any of the available generators in a seamless way. Lamarr has\nbeen validated by comparing key reconstructed quantities with Detailed\nSimulation. Good agreement of the simulated distributions is obtained with\ntwo-order-of-magnitude speed-up of the simulation phase.\n",
                "链接": "https://arxiv.org/abs/2309.13213"
            },
            {
                "文章ID": "93644",
                "标题": "Recent neutrino oscillation result with the IceCube experiment",
                "作者": "for the IceCube Collaboration  Shiqi Yu, for the IceCube Collaboration  Jessie Micallef",
                "发布日期": "2023-08-01",
                "摘要": "  The IceCube South Pole Neutrino Observatory is a Cherenkov detector\ninstrumented in a cubic kilometer of ice at the South Pole. IceCube's primary\nscientific goal is the detection of TeV neutrino emissions from astrophysical\nsources. At the lower center of the IceCube array, there is a subdetector\ncalled DeepCore, which has a denser configuration that makes it possible to\nlower the energy threshold of IceCube and observe GeV-scale neutrinos, opening\nthe window to atmospheric neutrino oscillations studies. Advances in physics\nsensitivity have recently been achieved by employing Convolutional Neural\nNetworks to reconstruct neutrino interactions in the DeepCore detector. In this\ncontribution, the recent IceCube result from the atmospheric muon neutrino\ndisappearance analysis using the CNN-reconstructed neutrino sample is presented\nand compared to the existing worldwide measurements.\n",
                "链接": "https://arxiv.org/abs/2307.15855"
            },
            {
                "文章ID": "51533",
                "标题": "FIESTA: Autoencoders for accurate fiber segmentation in tractography",
                "作者": "for the Alzheimer's Disease Neuroimaging\n  Initiative  Félix Dumais, for the Alzheimer's Disease Neuroimaging\n  Initiative  Jon Haitz Legarreta, for the Alzheimer's Disease Neuroimaging\n  Initiative  Carl Lemaire, for the Alzheimer's Disease Neuroimaging\n  Initiative  Philippe Poulin, for the Alzheimer's Disease Neuroimaging\n  Initiative  François Rheault, for the Alzheimer's Disease Neuroimaging\n  Initiative  Laurent Petit, for the Alzheimer's Disease Neuroimaging\n  Initiative  Muhamed Barakovic, for the Alzheimer's Disease Neuroimaging\n  Initiative  Stefano Magon, for the Alzheimer's Disease Neuroimaging\n  Initiative  Maxime Descoteaux, for the Alzheimer's Disease Neuroimaging\n  Initiative  Pierre-Marc Jodoin",
                "发布日期": "2023-08-25",
                "摘要": "  White matter bundle segmentation is a cornerstone of modern tractography to\nstudy the brain's structural connectivity in domains such as neurological\ndisorders, neurosurgery, and aging. In this study, we present FIESTA (FIbEr\nSegmentation in Tractography using Autoencoders), a reliable and robust, fully\nautomated, and easily semi-automatically calibrated pipeline based on deep\nautoencoders that can dissect and fully populate white matter bundles. This\npipeline is built upon previous works that demonstrated how autoencoders can be\nused successfully for streamline filtering, bundle segmentation, and streamline\ngeneration in tractography. Our proposed method improves bundle segmentation\ncoverage by recovering hard-to-track bundles with generative sampling through\nthe latent space seeding of the subject bundle and the atlas bundle. A latent\nspace of streamlines is learned using autoencoder-based modeling combined with\ncontrastive learning. Using an atlas of bundles in standard space (MNI), our\nproposed method segments new tractograms using the autoencoder latent distance\nbetween each tractogram streamline and its closest neighbor bundle in the atlas\nof bundles. Intra-subject bundle reliability is improved by recovering\nhard-to-track streamlines, using the autoencoder to generate new streamlines\nthat increase the spatial coverage of each bundle while remaining anatomically\ncorrect. Results show that our method is more reliable than state-of-the-art\nautomated virtual dissection methods such as RecoBundles, RecoBundlesX,\nTractSeg, White Matter Analysis and XTRACT. Our framework allows for the\ntransition from one anatomical bundle definition to another with marginal\ncalibration efforts. Overall, these results show that our framework improves\nthe practicality and usability of current state-of-the-art bundle segmentation\nframework.\n",
                "链接": "https://arxiv.org/abs/2212.00143"
            },
            {
                "文章ID": "70152",
                "标题": "A Surface-Based Federated Chow Test Model for Integrating APOE Status,\n  Tau Deposition Measure, and Hippocampal Surface Morphometry",
                "作者": "for the\n  Alzheimer's Disease Neuroimaging Initiative  Jianfeng Wu, for the\n  Alzheimer's Disease Neuroimaging Initiative  Yi Su, for the\n  Alzheimer's Disease Neuroimaging Initiative  Yanxi Chen, for the\n  Alzheimer's Disease Neuroimaging Initiative  Wenhui Zhu, for the\n  Alzheimer's Disease Neuroimaging Initiative  Eric M. Reiman, for the\n  Alzheimer's Disease Neuroimaging Initiative  Richard J. Caselli, for the\n  Alzheimer's Disease Neuroimaging Initiative  Kewei Chen, for the\n  Alzheimer's Disease Neuroimaging Initiative  Paul M. Thompson, for the\n  Alzheimer's Disease Neuroimaging Initiative  Junwen Wang, for the\n  Alzheimer's Disease Neuroimaging Initiative  Yalin Wang",
                "发布日期": "2023-04-04",
                "摘要": "  Background: Alzheimer's Disease (AD) is the most common type of age-related\ndementia, affecting 6.2 million people aged 65 or older according to CDC data.\nIt is commonly agreed that discovering an effective AD diagnosis biomarker\ncould have enormous public health benefits, potentially preventing or delaying\nup to 40% of dementia cases. Tau neurofibrillary tangles are the primary driver\nof downstream neurodegeneration and subsequent cognitive impairment in AD,\nresulting in structural deformations such as hippocampal atrophy that can be\nobserved in magnetic resonance imaging (MRI) scans. Objective: To build a\nsurface-based model to 1) detect differences between APOE subgroups in patterns\nof tau deposition and hippocampal atrophy, and 2) use the extracted\nsurface-based features to predict cognitive decline. Methods: Using data\nobtained from different institutions, we develop a surface-based federated Chow\ntest model to study the synergistic effects of APOE, a previously reported\nsignificant risk factor of AD, and tau on hippocampal surface morphometry.\nResults: We illustrate that the APOE-specific morphometry features correlate\nwith AD progression and better predict future AD conversion than other MRI\nbiomarkers. For example, a strong association between atrophy and abnormal tau\nwas identified in hippocampal subregion cornu ammonis 1 (CA1 subfield) and\nsubiculum in e4 homozygote cohort. Conclusion: Our model allows for identifying\nMRI biomarkers for AD and cognitive decline prediction and may uncover a corner\nof the neural mechanism of the influence of APOE and tau deposition on\nhippocampal morphology.\n",
                "链接": "https://arxiv.org/abs/2304.00134"
            },
            {
                "文章ID": "109886",
                "标题": "Julearn: an easy-to-use library for leakage-free evaluation and\n  inspection of ML models",
                "作者": "for the Alzheimer's Disease Neuroimaging\n  Initiative  Sami Hamdan, for the Alzheimer's Disease Neuroimaging\n  Initiative  Shammi More, for the Alzheimer's Disease Neuroimaging\n  Initiative  Leonard Sasse, for the Alzheimer's Disease Neuroimaging\n  Initiative  Vera Komeyer, for the Alzheimer's Disease Neuroimaging\n  Initiative  Kaustubh R. Patil, for the Alzheimer's Disease Neuroimaging\n  Initiative  Federico Raimondo",
                "发布日期": "2023-10-20",
                "摘要": "  The fast-paced development of machine learning (ML) methods coupled with its\nincreasing adoption in research poses challenges for researchers without\nextensive training in ML. In neuroscience, for example, ML can help understand\nbrain-behavior relationships, diagnose diseases, and develop biomarkers using\nvarious data sources like magnetic resonance imaging and\nelectroencephalography. The primary objective of ML is to build models that can\nmake accurate predictions on unseen data. Researchers aim to prove the\nexistence of such generalizable models by evaluating performance using\ntechniques such as cross-validation (CV), which uses systematic subsampling to\nestimate the generalization performance. Choosing a CV scheme and evaluating an\nML pipeline can be challenging and, if used improperly, can lead to\noverestimated results and incorrect interpretations.\n  We created julearn, an open-source Python library, that allow researchers to\ndesign and evaluate complex ML pipelines without encountering in common\npitfalls. In this manuscript, we present the rationale behind julearn's design,\nits core features, and showcase three examples of previously-published research\nprojects that can be easily implemented using this novel library. Julearn aims\nto simplify the entry into the ML world by providing an easy-to-use environment\nwith built in guards against some of the most common ML pitfalls. With its\ndesign, unique features and simple interface, it poses as a useful Python-based\nlibrary for research projects.\n",
                "链接": "https://arxiv.org/abs/2310.12568"
            },
            {
                "文章ID": "52633",
                "标题": "A Neural Network Approach for Selecting Track-like Events in\n  Fluorescence Telescope Data",
                "作者": "for the JEM-EUSO collaboration  Mikhail Zotov, for the JEM-EUSO collaboration  Denis Sokolinskii",
                "发布日期": "2023-04-06",
                "摘要": "  In 2016-2017, TUS, the world's first experiment for testing the possibility\nof registering ultra-high energy cosmic rays (UHECRs) by their fluorescent\nradiation in the night atmosphere of Earth was carried out. Since 2019, the\nRussian-Italian fluorescence telescope (FT) Mini-EUSO (\"UV Atmosphere\") has\nbeen operating on the ISS. The stratospheric experiment EUSO-SPB2, which will\nemploy an FT for registering UHECRs, is planned for 2023. We show how a simple\nconvolutional neural network can be effectively used to find track-like events\nin the variety of data obtained with such instruments.\n",
                "链接": "https://arxiv.org/abs/2212.03787"
            },
            {
                "文章ID": "10429",
                "标题": "Deep Multi-Modal Structural Equations For Causal Effect Estimation With\n  Unstructured Proxies",
                "作者": "Department of Computer Science, Cornell Tech  Shachi Deshpande, Department of Computer Science, Cornell Tech  Kaiwen Wang, Department of Computer Science, Cornell Tech  Dhruv Sreenivas, Department of Computer Science, Cornell Tech  Zheng Li, Department of Computer Science, Cornell Tech  Volodymyr Kuleshov",
                "发布日期": "2022-12-13",
                "摘要": "  Estimating the effect of intervention from observational data while\naccounting for confounding variables is a key task in causal inference.\nOftentimes, the confounders are unobserved, but we have access to large amounts\nof additional unstructured data (images, text) that contain valuable proxy\nsignal about the missing confounders. This paper argues that leveraging this\nunstructured data can greatly improve the accuracy of causal effect estimation.\nSpecifically, we introduce deep multi-modal structural equations, a generative\nmodel for causal effect estimation in which confounders are latent variables\nand unstructured data are proxy variables. This model supports multiple\nmulti-modal proxies (images, text) as well as missing data. We empirically\ndemonstrate that our approach outperforms existing methods based on propensity\nscores and corrects for confounding using unstructured inputs on tasks in\ngenomics and healthcare. Our methods can potentially support the use of large\namounts of data that were previously not used in causal inference\n",
                "链接": "https://arxiv.org/abs/2203.09672"
            },
            {
                "文章ID": "71613",
                "标题": "Regional Deep Atrophy: a Self-Supervised Learning Method to\n  Automatically Identify Regions Associated With Alzheimer's Disease\n  Progression From Longitudinal MRI",
                "作者": "for the Alzheimer's\n  Disease Neuroimaging Initiative  Mengjin Dong, for the Alzheimer's\n  Disease Neuroimaging Initiative  Long Xie, for the Alzheimer's\n  Disease Neuroimaging Initiative  Sandhitsu R. Das, for the Alzheimer's\n  Disease Neuroimaging Initiative  Jiancong Wang, for the Alzheimer's\n  Disease Neuroimaging Initiative  Laura E. M. Wisse, for the Alzheimer's\n  Disease Neuroimaging Initiative  Robin deFlores, for the Alzheimer's\n  Disease Neuroimaging Initiative  David A. Wolk, for the Alzheimer's\n  Disease Neuroimaging Initiative  Paul A. Yushkevich",
                "发布日期": "2023-04-11",
                "摘要": "  Longitudinal assessment of brain atrophy, particularly in the hippocampus, is\na well-studied biomarker for neurodegenerative diseases, such as Alzheimer's\ndisease (AD). In clinical trials, estimation of brain progressive rates can be\napplied to track therapeutic efficacy of disease modifying treatments. However,\nmost state-of-the-art measurements calculate changes directly by segmentation\nand/or deformable registration of MRI images, and may misreport head motion or\nMRI artifacts as neurodegeneration, impacting their accuracy. In our previous\nstudy, we developed a deep learning method DeepAtrophy that uses a\nconvolutional neural network to quantify differences between longitudinal MRI\nscan pairs that are associated with time. DeepAtrophy has high accuracy in\ninferring temporal information from longitudinal MRI scans, such as temporal\norder or relative inter-scan interval. DeepAtrophy also provides an overall\natrophy score that was shown to perform well as a potential biomarker of\ndisease progression and treatment efficacy. However, DeepAtrophy is not\ninterpretable, and it is unclear what changes in the MRI contribute to\nprogression measurements. In this paper, we propose Regional Deep Atrophy\n(RDA), which combines the temporal inference approach from DeepAtrophy with a\ndeformable registration neural network and attention mechanism that highlights\nregions in the MRI image where longitudinal changes are contributing to\ntemporal inference. RDA has similar prediction accuracy as DeepAtrophy, but its\nadditional interpretability makes it more acceptable for use in clinical\nsettings, and may lead to more sensitive biomarkers for disease monitoring in\nclinical trials of early AD.\n",
                "链接": "https://arxiv.org/abs/2304.04673"
            },
            {
                "文章ID": "86593",
                "标题": "Prior-knowledge-informed deep learning for lacune detection and\n  quantification using multi-site brain MRI",
                "作者": "for the\n  Heart-Brain Connection Consortium  Bo Li, for the\n  Heart-Brain Connection Consortium  Jeroen de Bresser, for the\n  Heart-Brain Connection Consortium  Wiro Niessen, for the\n  Heart-Brain Connection Consortium  Matthias van Osch, for the\n  Heart-Brain Connection Consortium  Wiesje M. van der Flier, for the\n  Heart-Brain Connection Consortium  Geert Jan Biessels, for the\n  Heart-Brain Connection Consortium  Meike W. Vernooij, for the\n  Heart-Brain Connection Consortium  Esther Bron",
                "发布日期": "2023-06-21",
                "摘要": "  Lacunes of presumed vascular origin, also referred to as lacunar infarcts,\nare important to assess cerebral small vessel disease and cognitive diseases\nsuch as dementia. However, visual rating of lacunes from imaging data is\nchallenging, time-consuming, and rater-dependent, owing to their small size,\nsparsity, and mimics. Whereas recent developments in automatic algorithms have\nshown to make the detection of lacunes faster while preserving sensitivity,\nthey also showed a large number of false positives, which makes them\nimpractical for use in clinical practice or large-scale studies. Here, we\ndevelop a novel framework that, in addition to lacune detection, outputs a\ncategorical burden score. This score could provide a more practical estimate of\nlacune presence that simplifies and effectively accelerates the imaging\nassessment of lacunes. We hypothesize that the combination of detection and the\ncategorical score makes the procedure less sensitive to noisy labels.\n",
                "链接": "https://arxiv.org/abs/2306.10622"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下2023年关于LLM-based Agent的综述",
            "type": "6"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下近三个月有关语言模型rlhf的arxiv上的全部文章。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大模型结合树搜索方法进行推理的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下近两年关于语言模型奖励建模评估的文章。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "请帮我找到从位置编码角度改善模型长序列建模能力的相关论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "60632",
                "标题": "Convolutional Neural Networks Trained to Identify Words Provide a\n  Surprisingly Good Account of Visual Form Priming Effects",
                "作者": " Dong Yin,  Valerio Biscione,  Jeffrey Bowers",
                "发布日期": "2023-03-15",
                "摘要": "  A wide variety of orthographic coding schemes and models of visual word\nidentification have been developed to account for masked priming data that\nprovide a measure of orthographic similarity between letter strings. These\nmodels tend to include hand-coded orthographic representations with single unit\ncoding for specific forms of knowledge (e.g., units coding for a letter in a\ngiven position). Here we assess how well a range of these coding schemes and\nmodels account for the pattern of form priming effects taken from the Form\nPriming Project and compare these findings to results observed with 11 standard\ndeep neural network models (DNNs) developed in computer science. We find that\ndeep convolutional networks (CNNs) perform as well or better than the coding\nschemes and word recognition models, whereas transformer networks did less\nwell. The success of CNNs is remarkable as their architectures were not\ndeveloped to support word recognition (they were designed to perform well on\nobject recognition), they classify pixel images of words (rather than\nartificial encodings of letter strings), and their training was highly\nsimplified (not respecting many key aspects of human experience). In addition\nto these form priming effects, we find that the DNNs can account for visual\nsimilarity effects on priming that are beyond all current psychological models\nof priming. The findings add to the recent work of (Hannagan et al., 2021) and\nsuggest that CNNs should be given more attention in psychology as models of\nhuman visual word recognition.\n",
                "链接": "https://arxiv.org/abs/2302.03992"
            },
            {
                "文章ID": "63378",
                "标题": "Modelling Temporal Document Sequences for Clinical ICD Coding",
                "作者": " Clarence Boon Liang Ng,  Diogo Santos,  Marek Rei",
                "发布日期": "2023-02-27",
                "摘要": "  Past studies on the ICD coding problem focus on predicting clinical codes\nprimarily based on the discharge summary. This covers only a small fraction of\nthe notes generated during each hospital stay and leaves potential for\nimproving performance by analysing all the available clinical notes. We propose\na hierarchical transformer architecture that uses text across the entire\nsequence of clinical notes in each hospital stay for ICD coding, and\nincorporates embeddings for text metadata such as their position, time, and\ntype of note. While using all clinical notes increases the quantity of data\nsubstantially, superconvergence can be used to reduce training costs. We\nevaluate the model on the MIMIC-III dataset. Our model exceeds the prior\nstate-of-the-art when using only discharge summaries as input, and achieves\nfurther performance improvements when all clinical notes are used as input.\n",
                "链接": "https://arxiv.org/abs/2302.12666"
            },
            {
                "文章ID": "97346",
                "标题": "MeDM: Mediating Image Diffusion Models for Video-to-Video Translation\n  with Temporal Correspondence Guidance",
                "作者": " Ernie Chu,  Tzuhsuan Huang,  Shuo-Yen Lin,  Jun-Cheng Chen",
                "发布日期": "2023-12-21",
                "摘要": "  This study introduces an efficient and effective method, MeDM, that utilizes\npre-trained image Diffusion Models for video-to-video translation with\nconsistent temporal flow. The proposed framework can render videos from scene\nposition information, such as a normal G-buffer, or perform text-guided editing\non videos captured in real-world scenarios. We employ explicit optical flows to\nconstruct a practical coding that enforces physical constraints on generated\nframes and mediates independent frame-wise scores. By leveraging this coding,\nmaintaining temporal consistency in the generated videos can be framed as an\noptimization problem with a closed-form solution. To ensure compatibility with\nStable Diffusion, we also suggest a workaround for modifying observation-space\nscores in latent Diffusion Models. Notably, MeDM does not require fine-tuning\nor test-time optimization of the Diffusion Models. Through extensive\nqualitative, quantitative, and subjective experiments on various benchmarks,\nthe study demonstrates the effectiveness and superiority of the proposed\napproach. Our project page can be found at https://medm2023.github.io\n",
                "链接": "https://arxiv.org/abs/2308.10079"
            },
            {
                "文章ID": "33671",
                "标题": "Efficient dynamic point cloud coding using Slice-Wise Segmentation",
                "作者": " Faranak Tohidi,  Manoranjan Paul,  Anwaar Ulhaq",
                "发布日期": "2022-08-18",
                "摘要": "  With the fast growth of immersive video sequences, achieving seamless and\nhigh-quality compressed 3D content is even more critical. MPEG recently\ndeveloped a video-based point cloud compression (V-PCC) standard for dynamic\npoint cloud coding. However, reconstructed point clouds using V-PCC suffer from\ndifferent artifacts, including losing data during pre-processing before\napplying existing video coding techniques, e.g., High-Efficiency Video Coding\n(HEVC). Patch generations and self-occluded points in the 3D to the 2D\nprojection are the main reasons for missing data using V-PCC. This paper\nproposes a new method that introduces overlapping slicing as an alternative to\npatch generation to decrease the number of patches generated and the amount of\ndata lost. In the proposed method, the entire point cloud has been\ncross-sectioned into variable-sized slices based on the number of self-occluded\npoints so that data loss can be minimized in the patch generation process and\nprojection. For this, a variable number of layers are considered, partially\noverlapped to retain the self-occluded points. The proposed method's added\nadvantage is to reduce the bits requirement and to encode geometric data using\nthe slicing base position. The experimental results show that the proposed\nmethod is much more flexible than the standard V-PCC method, improves the\nrate-distortion performance, and decreases the data loss significantly compared\nto the standard V-PCC method.\n",
                "链接": "https://arxiv.org/abs/2208.08061"
            },
            {
                "文章ID": "78756",
                "标题": "Towards Accurate Image Coding: Improved Autoregressive Image Generation\n  with Dynamic Vector Quantization",
                "作者": " Mengqi Huang,  Zhendong Mao,  Zhuowei Chen,  Yongdong Zhang",
                "发布日期": "2023-05-22",
                "摘要": "  Existing vector quantization (VQ) based autoregressive models follow a\ntwo-stage generation paradigm that first learns a codebook to encode images as\ndiscrete codes, and then completes generation based on the learned codebook.\nHowever, they encode fixed-size image regions into fixed-length codes and\nignore their naturally different information densities, which results in\ninsufficiency in important regions and redundancy in unimportant ones, and\nfinally degrades the generation quality and speed. Moreover, the fixed-length\ncoding leads to an unnatural raster-scan autoregressive generation. To address\nthe problem, we propose a novel two-stage framework: (1) Dynamic-Quantization\nVAE (DQ-VAE) which encodes image regions into variable-length codes based on\ntheir information densities for an accurate and compact code representation.\n(2) DQ-Transformer which thereby generates images autoregressively from\ncoarse-grained (smooth regions with fewer codes) to fine-grained (details\nregions with more codes) by modeling the position and content of codes in each\ngranularity alternately, through a novel stacked-transformer architecture and\nshared-content, non-shared position input layers designs. Comprehensive\nexperiments on various generation tasks validate our superiorities in both\neffectiveness and efficiency. Code will be released at\nhttps://github.com/CrossmodalGroup/DynamicVectorQuantization.\n",
                "链接": "https://arxiv.org/abs/2305.11718"
            },
            {
                "文章ID": "55480",
                "标题": "Learned Hierarchical B-frame Coding with Adaptive Feature Modulation for\n  YUV 4:2:0 Content",
                "作者": " Mu-Jung Chen,  Hong-Sheng Xie,  Cheng Chien,  Wen-Hsiao Peng,  Hsueh-Ming Hang",
                "发布日期": "2023-01-02",
                "摘要": "  This paper introduces a learned hierarchical B-frame coding scheme in\nresponse to the Grand Challenge on Neural Network-based Video Coding at ISCAS\n2023. We address specifically three issues, including (1) B-frame coding, (2)\nYUV 4:2:0 coding, and (3) content-adaptive variable-rate coding with only one\nsingle model. Most learned video codecs operate internally in the RGB domain\nfor P-frame coding. B-frame coding for YUV 4:2:0 content is largely\nunder-explored. In addition, while there have been prior works on variable-rate\ncoding with conditional convolution, most of them fail to consider the content\ninformation. We build our scheme on conditional augmented normalized flows\n(CANF). It features conditional motion and inter-frame codecs for efficient\nB-frame coding. To cope with YUV 4:2:0 content, two conditional inter-frame\ncodecs are used to process the Y and UV components separately, with the coding\nof the UV components conditioned additionally on the Y component. Moreover, we\nintroduce adaptive feature modulation in every convolutional layer, taking into\naccount both the content information and the coding levels of B-frames to\nachieve content-adaptive variable-rate coding. Experimental results show that\nour model outperforms x265 and the winner of last year's challenge on commonly\nused datasets in terms of PSNR-YUV.\n",
                "链接": "https://arxiv.org/abs/2212.14187"
            },
            {
                "文章ID": "4370",
                "标题": "Rate Coding or Direct Coding: Which One is Better for Accurate, Robust,\n  and Energy-efficient Spiking Neural Networks?",
                "作者": " Youngeun Kim,  Hyoungseob Park,  Abhishek Moitra,  Abhiroop Bhattacharjee,  Yeshwanth Venkatesha,  Priyadarshini Panda",
                "发布日期": "2022-04-13",
                "摘要": "  Recent Spiking Neural Networks (SNNs) works focus on an image classification\ntask, therefore various coding techniques have been proposed to convert an\nimage into temporal binary spikes. Among them, rate coding and direct coding\nare regarded as prospective candidates for building a practical SNN system as\nthey show state-of-the-art performance on large-scale datasets. Despite their\nusage, there is little attention to comparing these two coding schemes in a\nfair manner. In this paper, we conduct a comprehensive analysis of the two\ncodings from three perspectives: accuracy, adversarial robustness, and\nenergy-efficiency. First, we compare the performance of two coding techniques\nwith various architectures and datasets. Then, we measure the robustness of the\ncoding techniques on two adversarial attack methods. Finally, we compare the\nenergy-efficiency of two coding schemes on a digital hardware platform. Our\nresults show that direct coding can achieve better accuracy especially for a\nsmall number of timesteps. In contrast, rate coding shows better robustness to\nadversarial attacks owing to the non-differentiable spike generation process.\nRate coding also yields higher energy-efficiency than direct coding which\nrequires multi-bit precision for the first layer. Our study explores the\ncharacteristics of two codings, which is an important design consideration for\nbuilding SNNs. The code is made available at\nhttps://github.com/Intelligent-Computing-Lab-Yale/Rate-vs-Direct.\n",
                "链接": "https://arxiv.org/abs/2202.03133"
            },
            {
                "文章ID": "70925",
                "标题": "Hierarchical B-frame Video Coding Using Two-Layer CANF without Motion\n  Coding",
                "作者": " David Alexandre,  Hsueh-Ming Hang,  Wen-Hsiao Peng",
                "发布日期": "2023-04-07",
                "摘要": "  Typical video compression systems consist of two main modules: motion coding\nand residual coding. This general architecture is adopted by classical coding\nschemes (such as international standards H.265 and H.266) and deep\nlearning-based coding schemes. We propose a novel B-frame coding architecture\nbased on two-layer Conditional Augmented Normalization Flows (CANF). It has the\nstriking feature of not transmitting any motion information. Our proposed idea\nof video compression without motion coding offers a new direction for learned\nvideo coding. Our base layer is a low-resolution image compressor that replaces\nthe full-resolution motion compressor. The low-resolution coded image is merged\nwith the warped high-resolution images to generate a high-quality image as a\nconditioning signal for the enhancement-layer image coding in full resolution.\nOne advantage of this architecture is significantly reduced computational\ncomplexity due to eliminating the motion information compressor. In addition,\nwe adopt a skip-mode coding technique to reduce the transmitted latent samples.\nThe rate-distortion performance of our scheme is slightly lower than that of\nthe state-of-the-art learned B-frame coding scheme, B-CANF, but outperforms\nother learned B-frame coding schemes. However, compared to B-CANF, our scheme\nsaves 45% of multiply-accumulate operations (MACs) for encoding and 27% of MACs\nfor decoding. The code is available at https://nycu-clab.github.io.\n",
                "链接": "https://arxiv.org/abs/2304.02690"
            },
            {
                "文章ID": "28778",
                "标题": "CANF-VC: Conditional Augmented Normalizing Flows for Video Compression",
                "作者": " Yung-Han Ho,  Chih-Peng Chang,  Peng-Yu Chen,  Alessandro Gnutti,  Wen-Hsiao Peng",
                "发布日期": "2022-08-16",
                "摘要": "  This paper presents an end-to-end learning-based video compression system,\ntermed CANF-VC, based on conditional augmented normalizing flows (CANF). Most\nlearned video compression systems adopt the same hybrid-based coding\narchitecture as the traditional codecs. Recent research on conditional coding\nhas shown the sub-optimality of the hybrid-based coding and opens up\nopportunities for deep generative models to take a key role in creating new\ncoding frameworks. CANF-VC represents a new attempt that leverages the\nconditional ANF to learn a video generative model for conditional inter-frame\ncoding. We choose ANF because it is a special type of generative model, which\nincludes variational autoencoder as a special case and is able to achieve\nbetter expressiveness. CANF-VC also extends the idea of conditional coding to\nmotion coding, forming a purely conditional coding framework. Extensive\nexperimental results on commonly used datasets confirm the superiority of\nCANF-VC to the state-of-the-art methods. The source code of CANF-VC is\navailable at https://github.com/NYCU-MAPL/CANF-VC.\n",
                "链接": "https://arxiv.org/abs/2207.05315"
            },
            {
                "文章ID": "116567",
                "标题": "Exploring the Consistency, Quality and Challenges in Manual and\n  Automated Coding of Free-text Diagnoses from Hospital Outpatient Letters",
                "作者": " Warren Del-Pinto,  George Demetriou,  Meghna Jani,  Rikesh Patel,  Leanne Gray,  Alex Bulcock,  Niels Peek,  Andrew S. Kanter,  William G Dixon,  Goran Nenadic",
                "发布日期": "2023-11-21",
                "摘要": "  Coding of unstructured clinical free-text to produce interoperable structured\ndata is essential to improve direct care, support clinical communication and to\nenable clinical research.However, manual clinical coding is difficult and time\nconsuming, which motivates the development and use of natural language\nprocessing for automated coding. This work evaluates the quality and\nconsistency of both manual and automated clinical coding of diagnoses from\nhospital outpatient letters. Using 100 randomly selected letters, two human\nclinicians performed coding of diagnosis lists to SNOMED CT. Automated coding\nwas also performed using IMO's Concept Tagger. A gold standard was constructed\nby a panel of clinicians from a subset of the annotated diagnoses. This was\nused to evaluate the quality and consistency of both manual and automated\ncoding via (1) a distance-based metric, treating SNOMED CT as a graph, and (2)\na qualitative metric agreed upon by the panel of clinicians. Correlation\nbetween the two metrics was also evaluated. Comparing human and\ncomputer-generated codes to the gold standard, the results indicate that humans\nslightly out-performed automated coding, while both performed notably better\nwhen there was only a single diagnosis contained in the free-text description.\nAutomated coding was considered acceptable by the panel of clinicians in\napproximately 90% of cases.\n",
                "链接": "https://arxiv.org/abs/2311.10856"
            }
        ]
    },
    {
        "question": {
            "question": "利用大模型做数学题生成的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找可以用于验证模型推理能力的数据集论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "帮我找一下用大模型进行论文查找的论文",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "请帮我找到，最早提出分布式词表示的论文是哪一篇？",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下nips 2023 paper list",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "84628",
                "标题": "Overview of the Problem List Summarization (ProbSum) 2023 Shared Task on\n  Summarizing Patients' Active Diagnoses and Problems from Electronic Health\n  Record Progress Notes",
                "作者": " Yanjun Gao,  Dmitriy Dligach,  Timothy Miller,  Matthew M. Churpek,  Majid Afshar",
                "发布日期": "2023-06-09",
                "摘要": "  The BioNLP Workshop 2023 initiated the launch of a shared task on Problem\nList Summarization (ProbSum) in January 2023. The aim of this shared task is to\nattract future research efforts in building NLP models for real-world\ndiagnostic decision support applications, where a system generating relevant\nand accurate diagnoses will augment the healthcare providers decision-making\nprocess and improve the quality of care for patients. The goal for participants\nis to develop models that generated a list of diagnoses and problems using\ninput from the daily care notes collected from the hospitalization of\ncritically ill patients. Eight teams submitted their final systems to the\nshared task leaderboard. In this paper, we describe the tasks, datasets,\nevaluation metrics, and baseline systems. Additionally, the techniques and\nresults of the evaluation of the different approaches tried by the\nparticipating teams are summarized.\n",
                "链接": "https://arxiv.org/abs/2306.05270"
            },
            {
                "文章ID": "40312",
                "标题": "SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis",
                "作者": " Jiaxin Pei,  Vítor Silva,  Maarten Bos,  Yozon Liu,  Leonardo Neves,  David Jurgens,  Francesco Barbieri",
                "发布日期": "2023-02-06",
                "摘要": "  We propose MINT, a new Multilingual INTimacy analysis dataset covering 13,372\ntweets in 10 languages including English, French, Spanish, Italian, Portuguese,\nKorean, Dutch, Chinese, Hindi, and Arabic. We benchmarked a list of popular\nmultilingual pre-trained language models. The dataset is released along with\nthe SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis\n(https://sites.google.com/umich.edu/semeval-2023-tweet-intimacy).\n",
                "链接": "https://arxiv.org/abs/2210.01108"
            },
            {
                "文章ID": "47574",
                "标题": "A Characterization of List Learnability",
                "作者": " Moses Charikar,  Chirag Pabbaraju",
                "发布日期": "2023-03-28",
                "摘要": "  A classical result in learning theory shows the equivalence of PAC\nlearnability of binary hypothesis classes and the finiteness of VC dimension.\nExtending this to the multiclass setting was an open problem, which was settled\nin a recent breakthrough result characterizing multiclass PAC learnability via\nthe DS dimension introduced earlier by Daniely and Shalev-Shwartz. In this work\nwe consider list PAC learning where the goal is to output a list of $k$\npredictions. List learning algorithms have been developed in several settings\nbefore and indeed, list learning played an important role in the recent\ncharacterization of multiclass learnability. In this work we ask: when is it\npossible to $k$-list learn a hypothesis class? We completely characterize\n$k$-list learnability in terms of a generalization of DS dimension that we call\nthe $k$-DS dimension. Generalizing the recent characterization of multiclass\nlearnability, we show that a hypothesis class is $k$-list learnable if and only\nif the $k$-DS dimension is finite.\n",
                "链接": "https://arxiv.org/abs/2211.04956"
            },
            {
                "文章ID": "69199",
                "标题": "List Online Classification",
                "作者": " Shay Moran,  Ohad Sharon,  Iska Tsubari,  Sivan Yosebashvili",
                "发布日期": "2023-05-19",
                "摘要": "  We study multiclass online prediction where the learner can predict using a\nlist of multiple labels (as opposed to just one label in the traditional\nsetting). We characterize learnability in this model using the $b$-ary\nLittlestone dimension. This dimension is a variation of the classical\nLittlestone dimension with the difference that binary mistake trees are\nreplaced with $(k+1)$-ary mistake trees, where $k$ is the number of labels in\nthe list. In the agnostic setting, we explore different scenarios depending on\nwhether the comparator class consists of single-labeled or multi-labeled\nfunctions and its tradeoff with the size of the lists the algorithm uses. We\nfind that it is possible to achieve negative regret in some cases and provide a\ncomplete characterization of when this is possible. As part of our work, we\nadapt classical algorithms such as Littlestone's SOA and Rosenblatt's\nPerceptron to predict using lists of labels. We also establish combinatorial\nresults for list-learnable classes, including an list online version of the\nSauer-Shelah-Perles Lemma. We state our results within the framework of pattern\nclasses -- a generalization of hypothesis classes which can represent adaptive\nhypotheses (i.e. functions with memory), and model data-dependent assumptions\nsuch as linear classification with margin.\n",
                "链接": "https://arxiv.org/abs/2303.15383"
            },
            {
                "文章ID": "101771",
                "标题": "OWL Reasoners still useable in 2023",
                "作者": " Konrad Abicht",
                "发布日期": "2023-09-14",
                "摘要": "  In a systematic literature and software review over 100 OWL reasoners/systems\nwere analyzed to see if they would still be usable in 2023. This has never been\ndone in this capacity. OWL reasoners still play an important role in knowledge\norganisation and management, but the last comprehensive surveys/studies are\nmore than 8 years old. The result of this work is a comprehensive list of 95\nstandalone OWL reasoners and systems using an OWL reasoner. For each item,\ninformation on project pages, source code repositories and related\ndocumentation was gathered. The raw research data is provided in a Github\nrepository for anyone to use.\n",
                "链接": "https://arxiv.org/abs/2309.06888"
            },
            {
                "文章ID": "91898",
                "标题": "Rob\\^oCIn Small Size League Extended Team Description Paper for RoboCup\n  2023",
                "作者": " Aline Lima de Oliveira,  Cauê Addae da Silva Gomes,  Cecília Virginia Santos da Silva,  Charles Matheus de Sousa Alves,  Danilo Andrade Martins de Souza,  Driele Pires Ferreira Araújo Xavier,  Edgleyson Pereira da Silva,  Felipe Bezerra Martins,  Lucas Henrique Cavalcanti Santos,  Lucas Dias Maciel,  Matheus Paixão Gumercindo dos Santos,  Matheus Lafayette Vasconcelos,  Matheus Vinícius Teotonio do Nascimento Andrade,  João Guilherme Oliveira Carvalho de Melo,  João Pedro Souza Pereira de Moura,  José Ronald da Silva,  José Victor Silva Cruz,  Pedro Henrique Santana de Morais,  Pedro Paulo Salman de Oliveira,  Riei Joaquim Matos Rodrigues,  Roberto Costa Fernandes,  Ryan Vinicius Santos Morais,  Tamara Mayara Ramos Teobaldo,  Washington Igor dos Santos Silva,  Edna Natividade Silva Barros",
                "发布日期": "2023-07-20",
                "摘要": "  Rob\\^oCIn has participated in RoboCup Small Size League since 2019, won its\nfirst world title in 2022 (Division B), and is currently a three-times\nLatin-American champion. This paper presents our improvements to defend the\nSmall Size League (SSL) division B title in RoboCup 2023 in Bordeaux, France.\nThis paper aims to share some of the academic research that our team developed\nover the past year. Our team has successfully published 2 articles related to\nSSL at two high-impact conferences: the 25th RoboCup International Symposium\nand the 19th IEEE Latin American Robotics Symposium (LARS 2022). Over the last\nyear, we have been continuously migrating from our past codebase to\nUnification. We will describe the new architecture implemented and some points\nof software and AI refactoring. In addition, we discuss the process of\nintegrating machined components into the mechanical system, our development for\nparticipating in the vision blackout challenge last year and what we are\npreparing for this year.\n",
                "链接": "https://arxiv.org/abs/2307.10018"
            },
            {
                "文章ID": "25879",
                "标题": "List-Decodable Covariance Estimation",
                "作者": " Misha Ivkov,  Pravesh K. Kothari",
                "发布日期": "2022-06-23",
                "摘要": "  We give the first polynomial time algorithm for \\emph{list-decodable\ncovariance estimation}. For any $\\alpha > 0$, our algorithm takes input a\nsample $Y \\subseteq \\mathbb{R}^d$ of size $n\\geq d^{\\mathsf{poly}(1/\\alpha)}$\nobtained by adversarially corrupting an $(1-\\alpha)n$ points in an i.i.d.\nsample $X$ of size $n$ from the Gaussian distribution with unknown mean $\\mu_*$\nand covariance $\\Sigma_*$. In $n^{\\mathsf{poly}(1/\\alpha)}$ time, it outputs a\nconstant-size list of $k = k(\\alpha)= (1/\\alpha)^{\\mathsf{poly}(1/\\alpha)}$\ncandidate parameters that, with high probability, contains a\n$(\\hat{\\mu},\\hat{\\Sigma})$ such that the total variation distance\n$TV(\\mathcal{N}(\\mu_*,\\Sigma_*),\\mathcal{N}(\\hat{\\mu},\\hat{\\Sigma}))<1-O_{\\alpha}(1)$.\nThis is the statistically strongest notion of distance and implies\nmultiplicative spectral and relative Frobenius distance approximation for\nparameters with dimension independent error. Our algorithm works more generally\nfor $(1-\\alpha)$-corruptions of any distribution $D$ that possesses low-degree\nsum-of-squares certificates of two natural analytic properties: 1)\nanti-concentration of one-dimensional marginals and 2) hypercontractivity of\ndegree 2 polynomials.\n  Prior to our work, the only known results for estimating covariance in the\nlist-decodable setting were for the special cases of list-decodable linear\nregression and subspace recovery due to Karmarkar, Klivans, and Kothari (2019),\nRaghavendra and Yau (2019 and 2020) and Bakshi and Kothari (2020). These\nresults need superpolynomial time for obtaining any subconstant error in the\nunderlying dimension. Our result implies the first polynomial-time \\emph{exact}\nalgorithm for list-decodable linear regression and subspace recovery that\nallows, in particular, to obtain $2^{-\\mathsf{poly}(d)}$ error in\npolynomial-time. Our result also implies an improved algorithm for clustering\nnon-spherical mixtures.\n",
                "链接": "https://arxiv.org/abs/2206.10942"
            },
            {
                "文章ID": "84651",
                "标题": "CUED at ProbSum 2023: Hierarchical Ensemble of Summarization Models",
                "作者": " Potsawee Manakul,  Yassir Fathullah,  Adian Liusie,  Vyas Raina,  Vatsal Raina,  Mark Gales",
                "发布日期": "2023-06-09",
                "摘要": "  In this paper, we consider the challenge of summarizing patients' medical\nprogress notes in a limited data setting. For the Problem List Summarization\n(shared task 1A) at the BioNLP Workshop 2023, we demonstrate that Clinical-T5\nfine-tuned to 765 medical clinic notes outperforms other extractive,\nabstractive and zero-shot baselines, yielding reasonable baseline systems for\nmedical note summarization. Further, we introduce Hierarchical Ensemble of\nSummarization Models (HESM), consisting of token-level ensembles of diverse\nfine-tuned Clinical-T5 models, followed by Minimum Bayes Risk (MBR) decoding.\nOur HESM approach lead to a considerable summarization performance boost, and\nwhen evaluated on held-out challenge data achieved a ROUGE-L of 32.77, which\nwas the best-performing system at the top of the shared task leaderboard.\n",
                "链接": "https://arxiv.org/abs/2306.05317"
            },
            {
                "文章ID": "49997",
                "标题": "Efficient List-Decodable Regression using Batches",
                "作者": " Abhimanyu Das,  Ayush Jain,  Weihao Kong,  Rajat Sen",
                "发布日期": "2022-11-24",
                "摘要": "  We begin the study of list-decodable linear regression using batches. In this\nsetting only an $\\alpha \\in (0,1]$ fraction of the batches are genuine. Each\ngenuine batch contains $\\ge n$ i.i.d. samples from a common unknown\ndistribution and the remaining batches may contain arbitrary or even\nadversarial samples. We derive a polynomial time algorithm that for any $n\\ge\n\\tilde \\Omega(1/\\alpha)$ returns a list of size $\\mathcal O(1/\\alpha^2)$ such\nthat one of the items in the list is close to the true regression parameter.\nThe algorithm requires only $\\tilde{\\mathcal{O}}(d/\\alpha^2)$ genuine batches\nand works under fairly general assumptions on the distribution.\n  The results demonstrate the utility of batch structure, which allows for the\nfirst polynomial time algorithm for list-decodable regression, which may be\nimpossible for the non-batch setting, as suggested by a recent SQ lower bound\n\\cite{diakonikolas2021statistical} for the non-batch setting.\n",
                "链接": "https://arxiv.org/abs/2211.12743"
            },
            {
                "文章ID": "16951",
                "标题": "List-Mode PET Image Reconstruction Using Deep Image Prior",
                "作者": " Kibo Ote,  Fumio Hashimoto,  Yuya Onishi,  Takashi Isobe,  Yasuomi Ouchi",
                "发布日期": "2023-02-10",
                "摘要": "  List-mode positron emission tomography (PET) image reconstruction is an\nimportant tool for PET scanners with many lines-of-response and additional\ninformation such as time-of-flight and depth-of-interaction. Deep learning is\none possible solution to enhance the quality of PET image reconstruction.\nHowever, the application of deep learning techniques to list-mode PET image\nreconstruction has not been progressed because list data is a sequence of bit\ncodes and unsuitable for processing by convolutional neural networks (CNN). In\nthis study, we propose a novel list-mode PET image reconstruction method using\nan unsupervised CNN called deep image prior (DIP) which is the first trial to\nintegrate list-mode PET image reconstruction and CNN. The proposed list-mode\nDIP reconstruction (LM-DIPRecon) method alternatively iterates the regularized\nlist-mode dynamic row action maximum likelihood algorithm (LM-DRAMA) and\nmagnetic resonance imaging conditioned DIP (MR-DIP) using an alternating\ndirection method of multipliers. We evaluated LM-DIPRecon using both simulation\nand clinical data, and it achieved sharper images and better tradeoff curves\nbetween contrast and noise than the LM-DRAMA, MR-DIP and sinogram-based\nDIPRecon methods. These results indicated that the LM-DIPRecon is useful for\nquantitative PET imaging with limited events while keeping accurate raw data\ninformation. In addition, as list data has finer temporal information than\ndynamic sinograms, list-mode deep image prior reconstruction is expected to be\nuseful for 4D PET imaging and motion correction.\n",
                "链接": "https://arxiv.org/abs/2204.13404"
            }
        ]
    },
    {
        "question": {
            "question": "请列出近一年来工业界发表的搜广推工作落地实践的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "闭源大模型用户数据隐私保护研究",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "请搜索近一年发表的有关多模态大模型与产业相结合、与具体应用场景相结合的论文",
            "type": "2"
        },
        "results": []
    },
    {
        "question": {
            "question": "请找出最近一年内发表的关于自然语言处理领域中，使用Transformer模型并在大规模数据集上进行预训练的论文。特别关注模型结构和性能指标。",
            "type": "5"
        },
        "results": []
    }
]