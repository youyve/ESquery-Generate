[
    {
        "question": {
            "question": "查找OCR文本检测最新进展",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "43946",
                "标题": "OCR-VQGAN: Taming Text-within-Image Generation",
                "作者": " Juan A. Rodriguez,  David Vazquez,  Issam Laradji,  Marco Pedersoli,  Pau Rodriguez",
                "发布日期": "2022-10-26",
                "摘要": "  Synthetic image generation has recently experienced significant improvements\nin domains such as natural image or art generation. However, the problem of\nfigure and diagram generation remains unexplored. A challenging aspect of\ngenerating figures and diagrams is effectively rendering readable texts within\nthe images. To alleviate this problem, we present OCR-VQGAN, an image encoder,\nand decoder that leverages OCR pre-trained features to optimize a text\nperceptual loss, encouraging the architecture to preserve high-fidelity text\nand diagram structure. To explore our approach, we introduce the Paper2Fig100k\ndataset, with over 100k images of figures and texts from research papers. The\nfigures show architecture diagrams and methodologies of articles available at\narXiv.org from fields like artificial intelligence and computer vision. Figures\nusually include text and discrete objects, e.g., boxes in a diagram, with lines\nand arrows that connect them. We demonstrate the effectiveness of OCR-VQGAN by\nconducting several experiments on the task of figure reconstruction.\nAdditionally, we explore the qualitative and quantitative impact of weighting\ndifferent perceptual metrics in the overall loss function. We release code,\nmodels, and dataset at https://github.com/joanrod/ocr-vqgan.\n",
                "链接": "https://arxiv.org/abs/2210.11248"
            },
            {
                "文章ID": "53136",
                "标题": "Extending TrOCR for Text Localization-Free OCR of Full-Page Scanned\n  Receipt Images",
                "作者": " Hongkuan Zhang,  Edward Whittaker,  Ikuo Kitagishi",
                "发布日期": "2023-10-17",
                "摘要": "  Digitization of scanned receipts aims to extract text from receipt images and\nsave it into structured documents. This is usually split into two sub-tasks:\ntext localization and optical character recognition (OCR). Most existing OCR\nmodels only focus on the cropped text instance images, which require the\nbounding box information provided by a text region detection model. Introducing\nan additional detector to identify the text instance images in advance adds\ncomplexity, however instance-level OCR models have very low accuracy when\nprocessing the whole image for the document-level OCR, such as receipt images\ncontaining multiple text lines arranged in various layouts. To this end, we\npropose a localization-free document-level OCR model for transcribing all the\ncharacters in a receipt image into an ordered sequence end-to-end.\nSpecifically, we finetune the pretrained instance-level model TrOCR with\nrandomly cropped image chunks, and gradually increase the image chunk size to\ngeneralize the recognition ability from instance images to full-page images. In\nour experiments on the SROIE receipt OCR dataset, the model finetuned with our\nstrategy achieved 64.4 F1-score and a 22.8% character error rate (CER),\nrespectively, which outperforms the baseline results with 48.5 F1-score and\n50.6% CER. The best model, which splits the full image into 15 equally sized\nchunks, gives 87.8 F1-score and 4.98% CER with minimal additional pre or\npost-processing of the output. Moreover, the characters in the generated\ndocument-level sequences are arranged in the reading order, which is practical\nfor real-world applications.\n",
                "链接": "https://arxiv.org/abs/2212.05525"
            },
            {
                "文章ID": "19555",
                "标题": "Detection Masking for Improved OCR on Noisy Documents",
                "作者": " Daniel Rotman,  Ophir Azulai,  Inbar Shapira,  Yevgeny Burshtein,  Udi Barzelay",
                "发布日期": "2022-05-18",
                "摘要": "  Optical Character Recognition (OCR), the task of extracting textual\ninformation from scanned documents is a vital and broadly used technology for\ndigitizing and indexing physical documents. Existing technologies perform well\nfor clean documents, but when the document is visually degraded, or when there\nare non-textual elements, OCR quality can be greatly impacted, specifically due\nto erroneous detections. In this paper we present an improved detection network\nwith a masking system to improve the quality of OCR performed on documents. By\nfiltering non-textual elements from the image we can utilize document-level OCR\nto incorporate contextual information to improve OCR results. We perform a\nunified evaluation on a publicly available dataset demonstrating the usefulness\nand broad applicability of our method. Additionally, we present and make\npublicly available our synthetic dataset with a unique hard-negative component\nspecifically tuned to improve detection results, and evaluate the benefits that\ncan be gained from its usage\n",
                "链接": "https://arxiv.org/abs/2205.08257"
            },
            {
                "文章ID": "98478",
                "标题": "DISGO: Automatic End-to-End Evaluation for Scene Text OCR",
                "作者": " Mei-Yuh Hwang,  Yangyang Shi,  Ankit Ramchandani,  Guan Pang,  Praveen Krishnan,  Lucas Kabela,  Frank Seide,  Samyak Datta,  Jun Liu",
                "发布日期": "2023-08-28",
                "摘要": "  This paper discusses the challenges of optical character recognition (OCR) on\nnatural scenes, which is harder than OCR on documents due to the wild content\nand various image backgrounds. We propose to uniformly use word error rates\n(WER) as a new measurement for evaluating scene-text OCR, both end-to-end (e2e)\nperformance and individual system component performances. Particularly for the\ne2e metric, we name it DISGO WER as it considers Deletion, Insertion,\nSubstitution, and Grouping/Ordering errors. Finally we propose to utilize the\nconcept of super blocks to automatically compute BLEU scores for e2e OCR\nmachine translation. The small SCUT public test set is used to demonstrate WER\nperformance by a modularized OCR system.\n",
                "链接": "https://arxiv.org/abs/2308.13173"
            },
            {
                "文章ID": "120332",
                "标题": "UPOCR: Towards Unified Pixel-Level OCR Interface",
                "作者": " Dezhi Peng,  Zhenhua Yang,  Jiaxin Zhang,  Chongyu Liu,  Yongxin Shi,  Kai Ding,  Fengjun Guo,  Lianwen Jin",
                "发布日期": "2023-12-06",
                "摘要": "  In recent years, the optical character recognition (OCR) field has been\nproliferating with plentiful cutting-edge approaches for a wide spectrum of\ntasks. However, these approaches are task-specifically designed with divergent\nparadigms, architectures, and training strategies, which significantly\nincreases the complexity of research and maintenance and hinders the fast\ndeployment in applications. To this end, we propose UPOCR, a\nsimple-yet-effective generalist model for Unified Pixel-level OCR interface.\nSpecifically, the UPOCR unifies the paradigm of diverse OCR tasks as\nimage-to-image transformation and the architecture as a vision Transformer\n(ViT)-based encoder-decoder. Learnable task prompts are introduced to push the\ngeneral feature representations extracted by the encoder toward task-specific\nspaces, endowing the decoder with task awareness. Moreover, the model training\nis uniformly aimed at minimizing the discrepancy between the generated and\nground-truth images regardless of the inhomogeneity among tasks. Experiments\nare conducted on three pixel-level OCR tasks including text removal, text\nsegmentation, and tampered text detection. Without bells and whistles, the\nexperimental results showcase that the proposed method can simultaneously\nachieve state-of-the-art performance on three tasks with a unified single\nmodel, which provides valuable strategies and insights for future research on\ngeneralist OCR models. Code will be publicly available.\n",
                "链接": "https://arxiv.org/abs/2312.02694"
            },
            {
                "文章ID": "97589",
                "标题": "bbOCR: An Open-source Multi-domain OCR Pipeline for Bengali Documents",
                "作者": " Imam Mohammad Zulkarnain,  Shayekh Bin Islam,  Md. Zami Al Zunaed Farabe,  Md. Mehedi Hasan Shawon,  Jawaril Munshad Abedin,  Beig Rajibul Hasan,  Marsia Haque,  Istiak Shihab,  Syed Mobassir,  MD. Nazmuddoha Ansary,  Asif Sushmit,  Farig Sadeque",
                "发布日期": "2023-08-23",
                "摘要": "  Despite the existence of numerous Optical Character Recognition (OCR) tools,\nthe lack of comprehensive open-source systems hampers the progress of document\ndigitization in various low-resource languages, including Bengali. Low-resource\nlanguages, especially those with an alphasyllabary writing system, suffer from\nthe lack of large-scale datasets for various document OCR components such as\nword-level OCR, document layout extraction, and distortion correction; which\nare available as individual modules in high-resource languages. In this paper,\nwe introduce Bengali$.$AI-BRACU-OCR (bbOCR): an open-source scalable document\nOCR system that can reconstruct Bengali documents into a structured searchable\ndigitized format that leverages a novel Bengali text recognition model and two\nnovel synthetic datasets. We present extensive component-level and system-level\nevaluation: both use a novel diversified evaluation dataset and comprehensive\nevaluation metrics. Our extensive evaluation suggests that our proposed\nsolution is preferable over the current state-of-the-art Bengali OCR systems.\nThe source codes and datasets are available here:\nhttps://bengaliai.github.io/bbocr.\n",
                "链接": "https://arxiv.org/abs/2308.10647"
            },
            {
                "文章ID": "25669",
                "标题": "Towards Optimizing OCR for Accessibility",
                "作者": " Peya Mowar,  Tanuja Ganu,  Saikat Guha",
                "发布日期": "2022-06-27",
                "摘要": "  Visual cues such as structure, emphasis, and icons play an important role in\nefficient information foraging by sighted individuals and make for a\npleasurable reading experience. Blind, low-vision and other print-disabled\nindividuals miss out on these cues since current OCR and text-to-speech\nsoftware ignore them, resulting in a tedious reading experience. We identify\nfour semantic goals for an enjoyable listening experience, and identify\nsyntactic visual cues that help make progress towards these goals. Empirically,\nwe find that preserving even one or two visual cues in aural form significantly\nenhances the experience for listening to print content.\n",
                "链接": "https://arxiv.org/abs/2206.10254"
            },
            {
                "文章ID": "24093",
                "标题": "An Evaluation of OCR on Egocentric Data",
                "作者": " Valentin Popescu,  Dima Damen,  Toby Perrett",
                "发布日期": "2022-06-14",
                "摘要": "  In this paper, we evaluate state-of-the-art OCR methods on Egocentric data.\nWe annotate text in EPIC-KITCHENS images, and demonstrate that existing OCR\nmethods struggle with rotated text, which is frequently observed on objects\nbeing handled. We introduce a simple rotate-and-merge procedure which can be\napplied to pre-trained OCR models that halves the normalized edit distance\nerror. This suggests that future OCR attempts should incorporate rotation into\nmodel design and training procedures.\n",
                "链接": "https://arxiv.org/abs/2206.05496"
            },
            {
                "文章ID": "23281",
                "标题": "PP-OCRv3: More Attempts for the Improvement of Ultra Lightweight OCR\n  System",
                "作者": " Chenxia Li,  Weiwei Liu,  Ruoyu Guo,  Xiaoting Yin,  Kaitao Jiang,  Yongkun Du,  Yuning Du,  Lingfeng Zhu,  Baohua Lai,  Xiaoguang Hu,  Dianhai Yu,  Yanjun Ma",
                "发布日期": "2022-06-15",
                "摘要": "  Optical character recognition (OCR) technology has been widely used in\nvarious scenes, as shown in Figure 1. Designing a practical OCR system is still\na meaningful but challenging task. In previous work, considering the efficiency\nand accuracy, we proposed a practical ultra lightweight OCR system (PP-OCR),\nand an optimized version PP-OCRv2. In order to further improve the performance\nof PP-OCRv2, a more robust OCR system PP-OCRv3 is proposed in this paper.\nPP-OCRv3 upgrades the text detection model and text recognition model in 9\naspects based on PP-OCRv2. For text detector, we introduce a PAN module with\nlarge receptive field named LK-PAN, a FPN module with residual attention\nmechanism named RSE-FPN, and DML distillation strategy. For text recognizer,\nthe base model is replaced from CRNN to SVTR, and we introduce lightweight text\nrecognition network SVTR LCNet, guided training of CTC by attention, data\naugmentation strategy TextConAug, better pre-trained model by self-supervised\nTextRotNet, UDML, and UIM to accelerate the model and improve the effect.\nExperiments on real data show that the hmean of PP-OCRv3 is 5% higher than\nPP-OCRv2 under comparable inference speed. All the above mentioned models are\nopen-sourced and the code is available in the GitHub repository PaddleOCR which\nis powered by PaddlePaddle.\n",
                "链接": "https://arxiv.org/abs/2206.03001"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态优化训练方式的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "64750",
                "标题": "NSGA-PINN: A Multi-Objective Optimization Method for Physics-Informed\n  Neural Network Training",
                "作者": " Binghang Lu,  Christian B. Moya,  Guang Lin",
                "发布日期": "2023-03-08",
                "摘要": "  This paper presents NSGA-PINN, a multi-objective optimization framework for\neffective training of Physics-Informed Neural Networks (PINNs). The proposed\nframework uses the Non-dominated Sorting Genetic Algorithm (NSGA-II) to enable\ntraditional stochastic gradient optimization algorithms (e.g., ADAM) to escape\nlocal minima effectively. Additionally, the NSGA-II algorithm enables\nsatisfying the initial and boundary conditions encoded into the loss function\nduring physics-informed training precisely. We demonstrate the effectiveness of\nour framework by applying NSGA-PINN to several ordinary and partial\ndifferential equation problems. In particular, we show that the proposed\nframework can handle challenging inverse problems with noisy data.\n",
                "链接": "https://arxiv.org/abs/2303.02219"
            },
            {
                "文章ID": "73374",
                "标题": "Adaptive Consensus Optimization Method for GANs",
                "作者": " Sachin Kumar Danisetty,  Santhosh Reddy Mylaram,  Pawan Kumar",
                "发布日期": "2023-04-21",
                "摘要": "  We propose a second order gradient based method with ADAM and RMSprop for the\ntraining of generative adversarial networks. The proposed method is fastest to\nobtain similar accuracy when compared to prominent second order methods. Unlike\nstate-of-the-art recent methods, it does not require solving a linear system,\nor it does not require additional mixed second derivative terms. We derive the\nfixed point iteration corresponding to proposed method, and show that the\nproposed method is convergent. The proposed method produces better or\ncomparable inception scores, and comparable quality of images compared to other\nrecently proposed state-of-the-art second order methods. Compared to first\norder methods such as ADAM, it produces significantly better inception scores.\nThe proposed method is compared and validated on popular datasets such as FFHQ,\nLSUN, CIFAR10, MNIST, and Fashion MNIST for image generation\ntasks\\footnote{Accepted in IJCNN 2023}. Codes:\n\\url{https://github.com/misterpawan/acom}\n",
                "链接": "https://arxiv.org/abs/2304.10317"
            },
            {
                "文章ID": "114718",
                "标题": "Beyond the training set: an intuitive method for detecting distribution\n  shift in model-based optimization",
                "作者": " Farhan Damani,  David H Brookes,  Theodore Sternlieb,  Cameron Webster,  Stephen Malina,  Rishi Jajoo,  Kathy Lin,  Sam Sinai",
                "发布日期": "2023-11-10",
                "摘要": "  Model-based optimization (MBO) is increasingly applied to design problems in\nscience and engineering. A common scenario involves using a fixed training set\nto train models, with the goal of designing new samples that outperform those\npresent in the training data. A major challenge in this setting is distribution\nshift, where the distributions of training and design samples are different.\nWhile some shift is expected, as the goal is to create better designs, this\nchange can negatively affect model accuracy and subsequently, design quality.\nDespite the widespread nature of this problem, addressing it demands deep\ndomain knowledge and artful application. To tackle this issue, we propose a\nstraightforward method for design practitioners that detects distribution\nshifts. This method trains a binary classifier using knowledge of the unlabeled\ndesign distribution to separate the training data from the design data. The\nclassifier's logit scores are then used as a proxy measure of distribution\nshift. We validate our method in a real-world application by running offline\nMBO and evaluate the effect of distribution shift on design quality. We find\nthat the intensity of the shift in the design distribution varies based on the\nnumber of steps taken by the optimization algorithm, and our simple approach\ncan identify these shifts. This enables users to constrain their search to\nregions where the model's predictions are reliable, thereby increasing the\nquality of designs.\n",
                "链接": "https://arxiv.org/abs/2311.05363"
            },
            {
                "文章ID": "88563",
                "标题": "Alternative Telescopic Displacement: An Efficient Multimodal Alignment\n  Method",
                "作者": " Jiahao Qin,  Yitao Xu,  Zihong Luo Chengzhi Liu,  Zong Lu,  Xiaojun Zhang",
                "发布日期": "2023-06-30",
                "摘要": "  Feature alignment is the primary means of fusing multimodal data. We propose\na feature alignment method that fully fuses multimodal information, which\nalternately shifts and expands feature information from different modalities to\nhave a consistent representation in a feature space. The proposed method can\nrobustly capture high-level interactions between features of different\nmodalities, thus significantly improving the performance of multimodal\nlearning. We also show that the proposed method outperforms other popular\nmultimodal schemes on multiple tasks. Experimental evaluation of ETT and\nMIT-BIH-Arrhythmia, datasets shows that the proposed method achieves state of\nthe art performance.\n",
                "链接": "https://arxiv.org/abs/2306.16950"
            },
            {
                "文章ID": "60584",
                "标题": "Two-step hyperparameter optimization method: Accelerating hyperparameter\n  search by using a fraction of a training dataset",
                "作者": " Sungduk Yu,  Mike Pritchard,  Po-Lun Ma,  Balwinder Singh,  Sam Silva",
                "发布日期": "2023-11-15",
                "摘要": "  Hyperparameter optimization (HPO) is an important step in machine learning\n(ML) model development, but common practices are archaic -- primarily relying\non manual or grid searches. This is partly because adopting advanced HPO\nalgorithms introduces added complexity to the workflow, leading to longer\ncomputation times. This poses a notable challenge to ML applications, as\nsuboptimal hyperparameter selections curtail the potential of ML model\nperformance, ultimately obstructing the full exploitation of ML techniques. In\nthis article, we present a two-step HPO method as a strategic solution to\ncurbing computational demands and wait times, gleaned from practical\nexperiences in applied ML parameterization work. The initial phase involves a\npreliminary evaluation of hyperparameters on a small subset of the training\ndataset, followed by a re-evaluation of the top-performing candidate models\npost-retraining with the entire training dataset. This two-step HPO method is\nuniversally applicable across HPO search algorithms, and we argue it has\nattractive efficiency gains.\n  As a case study, we present our recent application of the two-step HPO method\nto the development of neural network emulators for aerosol activation. Although\nour primary use case is a data-rich limit with many millions of samples, we\nalso find that using up to 0.0025% of the data (a few thousand samples) in the\ninitial step is sufficient to find optimal hyperparameter configurations from\nmuch more extensive sampling, achieving up to 135-times speedup. The benefits\nof this method materialize through an assessment of hyperparameters and model\nperformance, revealing the minimal model complexity required to achieve the\nbest performance. The assortment of top-performing models harvested from the\nHPO process allows us to choose a high-performing model with a low inference\ncost for efficient use in global climate models (GCMs).\n",
                "链接": "https://arxiv.org/abs/2302.03845"
            },
            {
                "文章ID": "65940",
                "标题": "Single-branch Network for Multimodal Training",
                "作者": " Muhammad Saad Saeed,  Shah Nawaz,  Muhammad Haris Khan,  Muhammad Zaigham Zaheer,  Karthik Nandakumar,  Muhammad Haroon Yousaf,  Arif Mahmood",
                "发布日期": "2023-03-13",
                "摘要": "  With the rapid growth of social media platforms, users are sharing billions\nof multimedia posts containing audio, images, and text. Researchers have\nfocused on building autonomous systems capable of processing such multimedia\ndata to solve challenging multimodal tasks including cross-modal retrieval,\nmatching, and verification. Existing works use separate networks to extract\nembeddings of each modality to bridge the gap between them. The modular\nstructure of their branched networks is fundamental in creating numerous\nmultimodal applications and has become a defacto standard to handle multiple\nmodalities. In contrast, we propose a novel single-branch network capable of\nlearning discriminative representation of unimodal as well as multimodal tasks\nwithout changing the network. An important feature of our single-branch network\nis that it can be trained either using single or multiple modalities without\nsacrificing performance. We evaluated our proposed single-branch network on the\nchallenging multimodal problem (face-voice association) for cross-modal\nverification and matching tasks with various loss formulations. Experimental\nresults demonstrate the superiority of our proposed single-branch network over\nthe existing methods in a wide range of experiments. Code:\nhttps://github.com/msaadsaeed/SBNet\n",
                "链接": "https://arxiv.org/abs/2303.06129"
            },
            {
                "文章ID": "104627",
                "标题": "Jointly Training Large Autoregressive Multimodal Models",
                "作者": " Emanuele Aiello,  Lili Yu,  Yixin Nie,  Armen Aghajanyan,  Barlas Oguz",
                "发布日期": "2023-09-29",
                "摘要": "  In recent years, advances in the large-scale pretraining of language and\ntext-to-image models have revolutionized the field of machine learning. Yet,\nintegrating these two modalities into a single, robust model capable of\ngenerating seamless multimodal outputs remains a significant challenge. To\naddress this gap, we present the Joint Autoregressive Mixture (JAM) framework,\na modular approach that systematically fuses existing text and image generation\nmodels. We also introduce a specialized, data-efficient instruction-tuning\nstrategy, tailored for mixed-modal generation tasks. Our final instruct-tuned\nmodel demonstrates unparalleled performance in generating high-quality\nmultimodal outputs and represents the first model explicitly designed for this\npurpose.\n",
                "链接": "https://arxiv.org/abs/2309.15564"
            },
            {
                "文章ID": "94636",
                "标题": "Adaptive Proximal Gradient Method for Convex Optimization",
                "作者": " Yura Malitsky,  Konstantin Mishchenko",
                "发布日期": "2023-08-07",
                "摘要": "  In this paper, we explore two fundamental first-order algorithms in convex\noptimization, namely, gradient descent (GD) and proximal gradient method\n(ProxGD). Our focus is on making these algorithms entirely adaptive by\nleveraging local curvature information of smooth functions. We propose adaptive\nversions of GD and ProxGD that are based on observed gradient differences and,\nthus, have no added computational costs. Moreover, we prove convergence of our\nmethods assuming only local Lipschitzness of the gradient. In addition, the\nproposed versions allow for even larger stepsizes than those initially\nsuggested in [MM20].\n",
                "链接": "https://arxiv.org/abs/2308.02261"
            },
            {
                "文章ID": "95032",
                "标题": "HomOpt: A Homotopy-Based Hyperparameter Optimization Method",
                "作者": " Sophia J. Abraham,  Kehelwala D. G. Maduranga,  Jeffery Kinnison,  Zachariah Carmichael,  Jonathan D. Hauenstein,  Walter J. Scheirer",
                "发布日期": "2023-08-08",
                "摘要": "  Machine learning has achieved remarkable success over the past couple of\ndecades, often attributed to a combination of algorithmic innovations and the\navailability of high-quality data available at scale. However, a third critical\ncomponent is the fine-tuning of hyperparameters, which plays a pivotal role in\nachieving optimal model performance. Despite its significance, hyperparameter\noptimization (HPO) remains a challenging task for several reasons. Many HPO\ntechniques rely on naive search methods or assume that the loss function is\nsmooth and continuous, which may not always be the case. Traditional methods,\nlike grid search and Bayesian optimization, often struggle to quickly adapt and\nefficiently search the loss landscape. Grid search is computationally\nexpensive, while Bayesian optimization can be slow to prime. Since the search\nspace for HPO is frequently high-dimensional and non-convex, it is often\nchallenging to efficiently find a global minimum. Moreover, optimal\nhyperparameters can be sensitive to the specific dataset or task, further\ncomplicating the search process. To address these issues, we propose a new\nhyperparameter optimization method, HomOpt, using a data-driven approach based\non a generalized additive model (GAM) surrogate combined with homotopy\noptimization. This strategy augments established optimization methodologies to\nboost the performance and effectiveness of any given method with faster\nconvergence to the optimum on continuous, discrete, and categorical domain\nspaces. We compare the effectiveness of HomOpt applied to multiple optimization\ntechniques (e.g., Random Search, TPE, Bayes, and SMAC) showing improved\nobjective performance on many standardized machine learning benchmarks and\nchallenging open-set recognition tasks.\n",
                "链接": "https://arxiv.org/abs/2308.03317"
            },
            {
                "文章ID": "92143",
                "标题": "Reparameterized Policy Learning for Multimodal Trajectory Optimization",
                "作者": " Zhiao Huang,  Litian Liang,  Zhan Ling,  Xuanlin Li,  Chuang Gan,  Hao Su",
                "发布日期": "2023-07-21",
                "摘要": "  We investigate the challenge of parametrizing policies for reinforcement\nlearning (RL) in high-dimensional continuous action spaces. Our objective is to\ndevelop a multimodal policy that overcomes limitations inherent in the\ncommonly-used Gaussian parameterization. To achieve this, we propose a\nprincipled framework that models the continuous RL policy as a generative model\nof optimal trajectories. By conditioning the policy on a latent variable, we\nderive a novel variational bound as the optimization objective, which promotes\nexploration of the environment. We then present a practical model-based RL\nmethod, called Reparameterized Policy Gradient (RPG), which leverages the\nmultimodal policy parameterization and learned world model to achieve strong\nexploration capabilities and high data efficiency. Empirical results\ndemonstrate that our method can help agents evade local optima in tasks with\ndense rewards and solve challenging sparse-reward environments by incorporating\nan object-centric intrinsic reward. Our method consistently outperforms\nprevious approaches across a range of tasks. Code and supplementary materials\nare available on the project page https://haosulab.github.io/RPG/\n",
                "链接": "https://arxiv.org/abs/2307.10710"
            }
        ]
    },
    {
        "question": {
            "question": "与大模型安全相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大模型推理的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "近几个月自然语言处理相关的文章。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "近一个月与多模态大模型相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下工具评测相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "34033",
                "标题": "SimLDA: A tool for topic model evaluation",
                "作者": " Rebecca M. C. Taylor,  Johan A. du Preez",
                "发布日期": "2022-08-22",
                "摘要": "  Variational Bayes (VB) applied to latent Dirichlet allocation (LDA) has\nbecome the most popular algorithm for aspect modeling. While sufficiently\nsuccessful in text topic extraction from large corpora, VB is less successful\nin identifying aspects in the presence of limited data. We present a novel\nvariational message passing algorithm as applied to Latent Dirichlet Allocation\n(LDA) and compare it with the gold standard VB and collapsed Gibbs sampling. In\nsituations where marginalisation leads to non-conjugate messages, we use ideas\nfrom sampling to derive approximate update equations. In cases where conjugacy\nholds, Loopy Belief update (LBU) (also known as Lauritzen-Spiegelhalter) is\nused. Our algorithm, ALBU (approximate LBU), has strong similarities with\nVariational Message Passing (VMP) (which is the message passing variant of VB).\nTo compare the performance of the algorithms in the presence of limited data,\nwe use data sets consisting of tweets and news groups. Using coherence measures\nwe show that ALBU learns latent distributions more accurately than does VB,\nespecially for smaller data sets.\n",
                "链接": "https://arxiv.org/abs/2208.09299"
            },
            {
                "文章ID": "25887",
                "标题": "Diagnostic Tool for Out-of-Sample Model Evaluation",
                "作者": " Ludvig Hult,  Dave Zachariah,  Petre Stoica",
                "发布日期": "2023-10-17",
                "摘要": "  Assessment of model fitness is a key part of machine learning. The standard\nparadigm is to learn models by minimizing a chosen loss function averaged over\ntraining data, with the aim of achieving small losses on future data. In this\npaper, we consider the use of a finite calibration data set to characterize the\nfuture, out-of-sample losses of a model. We propose a simple model diagnostic\ntool that provides finite-sample guarantees under weak assumptions. The tool is\nsimple to compute and to interpret. Several numerical experiments are presented\nto show how the proposed method quantifies the impact of distribution shifts,\naids the analysis of regression, and enables model selection as well as\nhyper-parameter tuning.\n",
                "链接": "https://arxiv.org/abs/2206.10982"
            },
            {
                "文章ID": "108993",
                "标题": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
                "作者": " Alon Jacovi,  Avi Caciularu,  Jonathan Herzig,  Roee Aharoni,  Bernd Bohnet,  Mor Geva",
                "发布日期": "2023-12-29",
                "摘要": "  A growing area of research investigates augmenting language models with tools\n(e.g., search engines, calculators) to overcome their shortcomings (e.g.,\nmissing or incorrect knowledge, incorrect logical inferences). Various few-shot\ntool-usage strategies have been proposed. However, there is no systematic and\nfair comparison across different strategies, or between these strategies and\nstrong baselines that do not leverage tools. We conduct an extensive empirical\nanalysis, finding that (1) across various datasets, example difficulty levels,\nand models, strong no-tool baselines are competitive to tool-assisted\nstrategies, implying that effectively using tools with in-context\ndemonstrations is a difficult unsolved problem; (2) for knowledge-retrieval\ntasks, strategies that *refine* incorrect outputs with tools outperform\nstrategies that retrieve relevant information *ahead of* or *during\ngeneration*; (3) tool-assisted strategies are expensive in the number of tokens\nthey require to work -- incurring additional costs by orders of magnitude --\nwhich does not translate into significant improvement in performance. Overall,\nour findings suggest that few-shot tool integration is still an open challenge,\nemphasizing the need for comprehensive evaluations of future strategies to\naccurately assess their *benefits* and *costs*.\n",
                "链接": "https://arxiv.org/abs/2310.10062"
            },
            {
                "文章ID": "86296",
                "标题": "INDCOR white paper 4: Evaluation of Interactive Narrative Design For\n  Complexity Representations",
                "作者": " Christian Roth,  Breanne Pitt,  Lāsma Šķestere,  Jonathan Barbara,  Agnes Karolina Bakk,  Kirsty Dunlop,  Maria del Mar Grandio,  Miguel Barreda,  Despoina Sampatakou,  Michael Schlauch",
                "发布日期": "2023-07-07",
                "摘要": "  While a strength of Interactive Digital Narratives (IDN) is its support for\nmultiperspectivity, this also poses a substantial challenge to its evaluation.\nMoreover, evaluation has to assess the system's ability to represent a complex\nreality as well as the user's understanding of that complex reality as a result\nof the experience of interacting with the system. This is needed to measure an\nIDN's efficiency and effectiveness in representing the chosen complex\nphenomenon. We here present some empirical methods employed by INDCOR members\nin their research including UX toolkits and scales. Particularly, we consider\nthe impact of IDN on transformative learning and its evaluation through\nself-reporting and other alternatives.\n",
                "链接": "https://arxiv.org/abs/2306.09817"
            },
            {
                "文章ID": "43389",
                "标题": "Summary Workbench: Unifying Application and Evaluation of Text\n  Summarization Models",
                "作者": " Shahbaz Syed,  Dominik Schwabe,  Martin Potthast",
                "发布日期": "2022-10-19",
                "摘要": "  This paper presents Summary Workbench, a new tool for developing and\nevaluating text summarization models. New models and evaluation measures can be\neasily integrated as Docker-based plugins, allowing to examine the quality of\ntheir summaries against any input and to evaluate them using various evaluation\nmeasures. Visual analyses combining multiple measures provide insights into the\nmodels' strengths and weaknesses. The tool is hosted at\n\\url{https://tldr.demo.webis.de} and also supports local deployment for private\nresources.\n",
                "链接": "https://arxiv.org/abs/2210.09587"
            },
            {
                "文章ID": "18767",
                "标题": "ALIGNMEET: A Comprehensive Tool for Meeting Annotation, Alignment, and\n  Evaluation",
                "作者": " Peter Polák,  Muskaan Singh,  Anna Nedoluzhko,  Ondřej Bojar",
                "发布日期": "2022-05-12",
                "摘要": "  Summarization is a challenging problem, and even more challenging is to\nmanually create, correct, and evaluate the summaries. The severity of the\nproblem grows when the inputs are multi-party dialogues in a meeting setup. To\nfacilitate the research in this area, we present ALIGNMEET, a comprehensive\ntool for meeting annotation, alignment, and evaluation. The tool aims to\nprovide an efficient and clear interface for fast annotation while mitigating\nthe risk of introducing errors. Moreover, we add an evaluation mode that\nenables a comprehensive quality evaluation of meeting minutes. To the best of\nour knowledge, there is no such tool available. We release the tool as open\nsource. It is also directly installable from PyPI.\n",
                "链接": "https://arxiv.org/abs/2205.05433"
            },
            {
                "文章ID": "38679",
                "标题": "An Interdisciplinary Perspective on Evaluation and Experimental Design\n  for Visual Text Analytics: Position Paper",
                "作者": " Kostiantyn Kucher,  Nicole Sultanum,  Angel Daza,  Vasiliki Simaki,  Maria Skeppstedt,  Barbara Plank,  Jean-Daniel Fekete,  Narges Mahyar",
                "发布日期": "2022-12-21",
                "摘要": "  Appropriate evaluation and experimental design are fundamental for empirical\nsciences, particularly in data-driven fields. Due to the successes in\ncomputational modeling of languages, for instance, research outcomes are having\nan increasingly immediate impact on end users. As the gap in adoption by end\nusers decreases, the need increases to ensure that tools and models developed\nby the research communities and practitioners are reliable, trustworthy, and\nsupportive of the users in their goals. In this position paper, we focus on the\nissues of evaluating visual text analytics approaches. We take an\ninterdisciplinary perspective from the visualization and natural language\nprocessing communities, as we argue that the design and validation of visual\ntext analytics include concerns beyond computational or visual/interactive\nmethods on their own. We identify four key groups of challenges for evaluating\nvisual text analytics approaches (data ambiguity, experimental design, user\ntrust, and \"big picture\" concerns) and provide suggestions for research\nopportunities from an interdisciplinary perspective.\n",
                "链接": "https://arxiv.org/abs/2209.11534"
            },
            {
                "文章ID": "46198",
                "标题": "Evaluation Metrics for Symbolic Knowledge Extracted from Machine\n  Learning Black Boxes: A Discussion Paper",
                "作者": " Federico Sabbatini,  Roberta Calegari",
                "发布日期": "2022-11-02",
                "摘要": "  As opaque decision systems are being increasingly adopted in almost any\napplication field, issues about their lack of transparency and human\nreadability are a concrete concern for end-users. Amongst existing proposals to\nassociate human-interpretable knowledge with accurate predictions provided by\nopaque models, there are rule extraction techniques, capable of extracting\nsymbolic knowledge out of an opaque model. However, how to assess the level of\nreadability of the extracted knowledge quantitatively is still an open issue.\nFinding such a metric would be the key, for instance, to enable automatic\ncomparison between a set of different knowledge representations, paving the way\nfor the development of parameter autotuning algorithms for knowledge\nextractors. In this paper we discuss the need for such a metric as well as the\ncriticalities of readability assessment and evaluation, taking into account the\nmost common knowledge representations while highlighting the most puzzling\nissues.\n",
                "链接": "https://arxiv.org/abs/2211.00238"
            },
            {
                "文章ID": "79556",
                "标题": "The Grammar and Syntax Based Corpus Analysis Tool For The Ukrainian\n  Language",
                "作者": " Daria Stetsenko,  Inez Okulska",
                "发布日期": "2023-05-24",
                "摘要": "  This paper provides an overview of a text mining tool the StyloMetrix\ndeveloped initially for the Polish language and further extended for English\nand recently for Ukrainian. The StyloMetrix is built upon various metrics\ncrafted manually by computational linguists and researchers from literary\nstudies to analyze grammatical, stylistic, and syntactic patterns. The idea of\nconstructing the statistical evaluation of syntactic and grammar features is\nstraightforward and familiar for the languages like English, Spanish, German,\nand others; it is yet to be developed for low-resource languages like\nUkrainian. We describe the StyloMetrix pipeline and provide some experiments\nwith this tool for the text classification task. We also describe our package's\nmain limitations and the metrics' evaluation procedure.\n",
                "链接": "https://arxiv.org/abs/2305.13530"
            },
            {
                "文章ID": "35158",
                "标题": "Textwash -- automated open-source text anonymisation",
                "作者": " Bennett Kleinberg,  Toby Davies,  Maximilian Mozes",
                "发布日期": "2022-08-30",
                "摘要": "  The increased use of text data in social science research has benefited from\neasy-to-access data (e.g., Twitter). That trend comes at the cost of research\nrequiring sensitive but hard-to-share data (e.g., interview data, police\nreports, electronic health records). We introduce a solution to that stalemate\nwith the open-source text anonymisation software_Textwash_. This paper presents\nthe empirical evaluation of the tool using the TILD criteria: a technical\nevaluation (how accurate is the tool?), an information loss evaluation (how\nmuch information is lost in the anonymisation process?) and a de-anonymisation\ntest (can humans identify individuals from anonymised text data?). The findings\nsuggest that Textwash performs similar to state-of-the-art entity recognition\nmodels and introduces a negligible information loss of 0.84%. For the\nde-anonymisation test, we tasked humans to identify individuals by name from a\ndataset of crowdsourced person descriptions of very famous, semi-famous and\nnon-existing individuals. The de-anonymisation rate ranged from 1.01-2.01% for\nthe realistic use cases of the tool. We replicated the findings in a second\nstudy and concluded that Textwash succeeds in removing potentially sensitive\ninformation that renders detailed person descriptions practically anonymous.\n",
                "链接": "https://arxiv.org/abs/2208.13081"
            }
        ]
    },
    {
        "question": {
            "question": "大模型在游戏方面的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "12922",
                "标题": "Perceptual Quality Assessment of UGC Gaming Videos",
                "作者": " Xiangxu Yu,  Zhengzhong Tu,  Neil Birkbeck,  Yilin Wang,  Balu Adsumilli,  Alan C. Bovik",
                "发布日期": "2022-04-15",
                "摘要": "  In recent years, with the vigorous development of the video game industry,\nthe proportion of gaming videos on major video websites like YouTube has\ndramatically increased. However, relatively little research has been done on\nthe automatic quality prediction of gaming videos, especially on those that\nfall in the category of \"User-Generated-Content\" (UGC). Since current leading\ngeneral-purpose Video Quality Assessment (VQA) models do not perform well on\nthis type of gaming videos, we have created a new VQA model specifically\ndesigned to succeed on UGC gaming videos, which we call the Gaming Video\nQuality Predictor (GAME-VQP). GAME-VQP successfully predicts the unique\nstatistical characteristics of gaming videos by drawing upon features designed\nunder modified natural scene statistics models, combined with gaming specific\nfeatures learned by a Convolution Neural Network. We study the performance of\nGAME-VQP on a very recent large UGC gaming video database called\nLIVE-YT-Gaming, and find that it both outperforms other mainstream general VQA\nmodels as well as VQA models specifically designed for gaming videos. The new\nmodel will be made public after paper being accepted.\n",
                "链接": "https://arxiv.org/abs/2204.00128"
            },
            {
                "文章ID": "81335",
                "标题": "Study of Subjective and Objective Quality Assessment of Mobile Cloud\n  Gaming Videos",
                "作者": " Avinab Saha,  Yu-Chih Chen,  Chase Davis,  Bo Qiu,  Xiaoming Wang,  Rahul Gowda,  Ioannis Katsavounidis,  Alan C. Bovik",
                "发布日期": "2023-06-28",
                "摘要": "  We present the outcomes of a recent large-scale subjective study of Mobile\nCloud Gaming Video Quality Assessment (MCG-VQA) on a diverse set of gaming\nvideos. Rapid advancements in cloud services, faster video encoding\ntechnologies, and increased access to high-speed, low-latency wireless internet\nhave all contributed to the exponential growth of the Mobile Cloud Gaming\nindustry. Consequently, the development of methods to assess the quality of\nreal-time video feeds to end-users of cloud gaming platforms has become\nincreasingly important. However, due to the lack of a large-scale public Mobile\nCloud Gaming Video dataset containing a diverse set of distorted videos with\ncorresponding subjective scores, there has been limited work on the development\nof MCG-VQA models. Towards accelerating progress towards these goals, we\ncreated a new dataset, named the LIVE-Meta Mobile Cloud Gaming (LIVE-Meta-MCG)\nvideo quality database, composed of 600 landscape and portrait gaming videos,\non which we collected 14,400 subjective quality ratings from an in-lab\nsubjective study. Additionally, to demonstrate the usefulness of the new\nresource, we benchmarked multiple state-of-the-art VQA algorithms on the\ndatabase. The new database will be made publicly available on our website:\n\\url{https://live.ece.utexas.edu/research/LIVE-Meta-Mobile-Cloud-Gaming/index.html}\n",
                "链接": "https://arxiv.org/abs/2305.17260"
            },
            {
                "文章ID": "75621",
                "标题": "GAMIVAL: Video Quality Prediction on Mobile Cloud Gaming Content",
                "作者": " Yu-Chih Chen,  Avinab Saha,  Chase Davis,  Bo Qiu,  Xiaoming Wang,  Rahul Gowda,  Ioannis Katsavounidis,  Alan C. Bovik",
                "发布日期": "2023-08-31",
                "摘要": "  The mobile cloud gaming industry has been rapidly growing over the last\ndecade. When streaming gaming videos are transmitted to customers' client\ndevices from cloud servers, algorithms that can monitor distorted video quality\nwithout having any reference video available are desirable tools. However,\ncreating No-Reference Video Quality Assessment (NR VQA) models that can\naccurately predict the quality of streaming gaming videos rendered by computer\ngraphics engines is a challenging problem, since gaming content generally\ndiffers statistically from naturalistic videos, often lacks detail, and\ncontains many smooth regions. Until recently, the problem has been further\ncomplicated by the lack of adequate subjective quality databases of mobile\ngaming content. We have created a new gaming-specific NR VQA model called the\nGaming Video Quality Evaluator (GAMIVAL), which combines and leverages the\nadvantages of spatial and temporal gaming distorted scene statistics models, a\nneural noise model, and deep semantic features. Using a support vector\nregression (SVR) as a regressor, GAMIVAL achieves superior performance on the\nnew LIVE-Meta Mobile Cloud Gaming (LIVE-Meta MCG) video quality database.\n",
                "链接": "https://arxiv.org/abs/2305.02422"
            },
            {
                "文章ID": "11430",
                "标题": "Subjective and Objective Analysis of Streamed Gaming Videos",
                "作者": " Xiangxu Yu,  Zhenqiang Ying,  Neil Birkbeck,  Yilin Wang,  Balu Adsumilli,  Alan C. Bovik",
                "发布日期": "2022-03-25",
                "摘要": "  The rising popularity of online User-Generated-Content (UGC) in the form of\nstreamed and shared videos, has hastened the development of perceptual Video\nQuality Assessment (VQA) models, which can be used to help optimize their\ndelivery. Gaming videos, which are a relatively new type of UGC videos, are\ncreated when skilled gamers post videos of their gameplay. These kinds of\nscreenshots of UGC gameplay videos have become extremely popular on major\nstreaming platforms like YouTube and Twitch. Synthetically-generated gaming\ncontent presents challenges to existing VQA algorithms, including those based\non natural scene/video statistics models. Synthetically generated gaming\ncontent presents different statistical behavior than naturalistic videos. A\nnumber of studies have been directed towards understanding the perceptual\ncharacteristics of professionally generated gaming videos arising in gaming\nvideo streaming, online gaming, and cloud gaming. However, little work has been\ndone on understanding the quality of UGC gaming videos, and how it can be\ncharacterized and predicted. Towards boosting the progress of gaming video VQA\nmodel development, we conducted a comprehensive study of subjective and\nobjective VQA models on UGC gaming videos. To do this, we created a novel UGC\ngaming video resource, called the LIVE-YouTube Gaming video quality\n(LIVE-YT-Gaming) database, comprised of 600 real UGC gaming videos. We\nconducted a subjective human study on this data, yielding 18,600 human quality\nratings recorded by 61 human subjects. We also evaluated a number of\nstate-of-the-art (SOTA) VQA models on the new database, including a new one,\ncalled GAME-VQP, based on both natural video statistics and CNN-learned\nfeatures. To help support work in this field, we are making the new\nLIVE-YT-Gaming Database, publicly available through the link:\nhttps://live.ece.utexas.edu/research/LIVE-YT-Gaming/index.html .\n",
                "链接": "https://arxiv.org/abs/2203.12824"
            },
            {
                "文章ID": "102747",
                "标题": "MindAgent: Emergent Gaming Interaction",
                "作者": " Ran Gong,  Qiuyuan Huang,  Xiaojian Ma,  Hoi Vo,  Zane Durante,  Yusuke Noda,  Zilong Zheng,  Song-Chun Zhu,  Demetri Terzopoulos,  Li Fei-Fei,  Jianfeng Gao",
                "发布日期": "2023-09-20",
                "摘要": "  Large Language Models (LLMs) have the capacity of performing complex\nscheduling in a multi-agent system and can coordinate these agents into\ncompleting sophisticated tasks that require extensive collaboration. However,\ndespite the introduction of numerous gaming frameworks, the community has\ninsufficient benchmarks towards building general multi-agents collaboration\ninfrastructure that encompass both LLM and human-NPCs collaborations. In this\nwork, we propose a novel infrastructure - MindAgent - to evaluate planning and\ncoordination emergent capabilities for gaming interaction. In particular, our\ninfrastructure leverages existing gaming framework, to i) require understanding\nof the coordinator for a multi-agent system, ii) collaborate with human players\nvia un-finetuned proper instructions, and iii) establish an in-context learning\non few-shot prompt with feedback. Furthermore, we introduce CUISINEWORLD, a new\ngaming scenario and related benchmark that dispatch a multi-agent collaboration\nefficiency and supervise multiple agents playing the game simultaneously. We\nconduct comprehensive evaluations with new auto-metric CoS for calculating the\ncollaboration efficiency. Finally, our infrastructure can be deployed into\nreal-world gaming scenarios in a customized VR version of CUISINEWORLD and\nadapted in existing broader Minecraft gaming domain. We hope our findings on\nLLMs and the new infrastructure for general-purpose scheduling and coordination\ncan help shed light on how such skills can be obtained by learning from large\nlanguage corpora.\n",
                "链接": "https://arxiv.org/abs/2309.09971"
            },
            {
                "文章ID": "89981",
                "标题": "ScriptWorld: Text Based Environment For Learning Procedural Knowledge",
                "作者": " Abhinav Joshi,  Areeb Ahmad,  Umang Pandey,  Ashutosh Modi",
                "发布日期": "2023-07-11",
                "摘要": "  Text-based games provide a framework for developing natural language\nunderstanding and commonsense knowledge about the world in reinforcement\nlearning based agents. Existing text-based environments often rely on fictional\nsituations and characters to create a gaming framework and are far from\nreal-world scenarios. In this paper, we introduce ScriptWorld: a text-based\nenvironment for teaching agents about real-world daily chores and hence\nimparting commonsense knowledge. To the best of our knowledge, it is the first\ninteractive text-based gaming framework that consists of daily real-world human\nactivities designed using scripts dataset. We provide gaming environments for\n10 daily activities and perform a detailed analysis of the proposed\nenvironment. We develop RL-based baseline models/agents to play the games in\nScriptworld. To understand the role of language models in such environments, we\nleverage features obtained from pre-trained language models in the RL agents.\nOur experiments show that prior knowledge obtained from a pre-trained language\nmodel helps to solve real-world text-based gaming environments. We release the\nenvironment via Github: https://github.com/Exploration-Lab/ScriptWorld\n",
                "链接": "https://arxiv.org/abs/2307.03906"
            },
            {
                "文章ID": "6704",
                "标题": "Margin-distancing for safe model explanation",
                "作者": " Tom Yan,  Chicheng Zhang",
                "发布日期": "2022-02-24",
                "摘要": "  The growing use of machine learning models in consequential settings has\nhighlighted an important and seemingly irreconcilable tension between\ntransparency and vulnerability to gaming. While this has sparked sizable debate\nin legal literature, there has been comparatively less technical study of this\ncontention. In this work, we propose a clean-cut formulation of this tension\nand a way to make the tradeoff between transparency and gaming. We identify the\nsource of gaming as being points close to the \\emph{decision boundary} of the\nmodel. And we initiate an investigation on how to provide example-based\nexplanations that are expansive and yet consistent with a version space that is\nsufficiently uncertain with respect to the boundary points' labels. Finally, we\nfurnish our theoretical results with empirical investigations of this tradeoff\non real-world datasets.\n",
                "链接": "https://arxiv.org/abs/2202.11266"
            },
            {
                "文章ID": "55440",
                "标题": "Measuring and Estimating Key Quality Indicators in Cloud Gaming services",
                "作者": " Carlos Baena,  O. S. Peñaherrera-Pulla,  Raquel Barco,  Sergio Fortes",
                "发布日期": "2023-05-11",
                "摘要": "  User equipment is one of the main bottlenecks facing the gaming industry\nnowadays. The extremely realistic games which are currently available trigger\nhigh computational requirements of the user devices to run games. As a\nconsequence, the game industry has proposed the concept of Cloud Gaming, a\nparadigm that improves gaming experience in reduced hardware devices. To this\nend, games are hosted on remote servers, relegating users' devices to play only\nthe role of a peripheral for interacting with the game. However, this paradigm\noverloads the communication links connecting the users with the cloud.\nTherefore, service experience becomes highly dependent on network connectivity.\nTo overcome this, Cloud Gaming will be boosted by the promised performance of\n5G and future 6G networks, together with the flexibility provided by mobility\nin multi-RAT scenarios, such as WiFi. In this scope, the present work proposes\na framework for measuring and estimating the main E2E metrics of the Cloud\nGaming service, namely KQIs. In addition, different machine learning techniques\nare assessed for predicting KQIs related to Cloud Gaming user's experience. To\nthis end, the main key quality indicators (KQIs) of the service such as input\nlag, freeze percent or perceived video frame rate are collected in a real\nenvironment. Based on these, results show that machine learning techniques\nprovide a good estimation of these indicators solely from network-based\nmetrics. This is considered a valuable asset to guide the delivery of Cloud\nGaming services through cellular communications networks even without access to\nthe user's device, as it is expected for telecom operators.\n",
                "链接": "https://arxiv.org/abs/2212.14073"
            },
            {
                "文章ID": "86256",
                "标题": "An Analysis of Physiological and Psychological Responses in Virtual\n  Reality and Flat Screen Gaming",
                "作者": " Ritik Vatsal,  Shrivatsa Mishra,  Rushil Thareja,  Mrinmoy Chakrabarty,  Ojaswa Sharma,  Jainendra Shukla",
                "发布日期": "2023-11-16",
                "摘要": "  Recent research has focused on the effectiveness of Virtual Reality (VR) in\ngames as a more immersive method of interaction. However, there is a lack of\nrobust analysis of the physiological effects between VR and flatscreen (FS)\ngaming. This paper introduces the first systematic comparison and analysis of\nemotional and physiological responses to commercially available games in VR and\nFS environments. To elicit these responses, we first selected four games\nthrough a pilot study of 6 participants to cover all four quadrants of the\nvalence-arousal space. Using these games, we recorded the physiological\nactivity, including Blood Volume Pulse and Electrodermal Activity, and\nself-reported emotions of 33 participants in a user study. Our data analysis\nrevealed that VR gaming elicited more pronounced emotions, higher arousal,\nincreased cognitive load and stress, and lower dominance than FS gaming. The\nVirtual Reality and Flat Screen (VRFS) dataset, containing over 15 hours of\nmultimodal data comparing FS and VR gaming across different games, is also made\npublicly available for research purposes. Our analysis provides valuable\ninsights for further investigations into the physiological and emotional\neffects of VR and FS gaming.\n",
                "链接": "https://arxiv.org/abs/2306.09690"
            },
            {
                "文章ID": "122132",
                "标题": "Scaling Culture in Blockchain Gaming: Generative AI and Pseudonymous\n  Engagement",
                "作者": " Henrik Axelsen,  Sebastian Axelsen,  Valdemar Licht,  Jason Potts",
                "发布日期": "2023-12-14",
                "摘要": "  Managing rapidly growing decentralized gaming communities brings unique\nchallenges at the nexus of cultural economics and technology. This paper\nintroduces a streamlined analytical framework that utilizes Large Language\nModels (LLMs), in this instance open-access generative pre-trained transformer\n(GPT) models, offering an efficient solution with deeper insights into\ncommunity dynamics. The framework aids moderators in identifying pseudonymous\nactor intent, moderating toxic behavior, rewarding desired actions to avoid\nunintended consequences of blockchain-based gaming, and gauging community\nsentiment as communities venture into metaverse platforms and plan for\nhypergrowth. This framework strengthens community controls, eases onboarding,\nand promotes a common moral mission across communities while reducing agency\ncosts by 95 pct. Highlighting the transformative role of generative AI, the\npaper emphasizes its potential to redefine the cost of cultural production. It\nshowcases the utility of GPTs in digital community management, expanding their\nimplications in cultural economics and transmedia storytelling.\n",
                "链接": "https://arxiv.org/abs/2312.07693"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "请找到缓和噪声标签影响的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下文本检索任务上，是否有关于大模型在语义坍缩问题上的研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "107413",
                "标题": "Unleashing the power of Neural Collapse for Transferability Estimation",
                "作者": " Yuhe Ding,  Bo Jiang,  Lijun Sheng,  Aihua Zheng,  Jian Liang",
                "发布日期": "2023-10-10",
                "摘要": "  Transferability estimation aims to provide heuristics for quantifying how\nsuitable a pre-trained model is for a specific downstream task, without\nfine-tuning them all. Prior studies have revealed that well-trained models\nexhibit the phenomenon of Neural Collapse. Based on a widely used neural\ncollapse metric in existing literature, we observe a strong correlation between\nthe neural collapse of pre-trained models and their corresponding fine-tuned\nmodels. Inspired by this observation, we propose a novel method termed Fair\nCollapse (FaCe) for transferability estimation by comprehensively measuring the\ndegree of neural collapse in the pre-trained model. Typically, FaCe comprises\ntwo different terms: the variance collapse term, which assesses the class\nseparation and within-class compactness, and the class fairness term, which\nquantifies the fairness of the pre-trained model towards each class. We\ninvestigate FaCe on a variety of pre-trained classification models across\ndifferent network architectures, source datasets, and training loss functions.\nResults show that FaCe yields state-of-the-art performance on different tasks\nincluding image classification, semantic segmentation, and text classification,\nwhich demonstrate the effectiveness and generalization of our method.\n",
                "链接": "https://arxiv.org/abs/2310.05754"
            },
            {
                "文章ID": "122223",
                "标题": "Semantic-aware Data Augmentation for Text-to-image Synthesis",
                "作者": " Zhaorui Tan,  Xi Yang,  Kaizhu Huang",
                "发布日期": "2023-12-14",
                "摘要": "  Data augmentation has been recently leveraged as an effective regularizer in\nvarious vision-language deep neural networks. However, in text-to-image\nsynthesis (T2Isyn), current augmentation wisdom still suffers from the semantic\nmismatch between augmented paired data. Even worse, semantic collapse may occur\nwhen generated images are less semantically constrained. In this paper, we\ndevelop a novel Semantic-aware Data Augmentation (SADA) framework dedicated to\nT2Isyn. In particular, we propose to augment texts in the semantic space via an\nImplicit Textual Semantic Preserving Augmentation ($ITA$), in conjunction with\na specifically designed Image Semantic Regularization Loss ($L_r$) as Generated\nImage Semantic Conservation, to cope well with semantic mismatch and collapse.\nAs one major contribution, we theoretically show that $ITA$ can certify better\ntext-image consistency while $L_r$ regularizing the semantics of generated\nimages would avoid semantic collapse and enhance image quality. Extensive\nexperiments validate that SADA enhances text-image consistency and improves\nimage quality significantly in T2Isyn models across various backbones.\nEspecially, incorporating SADA during the tuning process of Stable Diffusion\nmodels also yields performance improvements.\n",
                "链接": "https://arxiv.org/abs/2312.07951"
            },
            {
                "文章ID": "12573",
                "标题": "How Does SimSiam Avoid Collapse Without Negative Samples? A Unified\n  Understanding with Self-supervised Contrastive Learning",
                "作者": " Chaoning Zhang,  Kang Zhang,  Chenshuang Zhang,  Trung X. Pham,  Chang D. Yoo,  In So Kweon",
                "发布日期": "2022-03-31",
                "摘要": "  To avoid collapse in self-supervised learning (SSL), a contrastive loss is\nwidely used but often requires a large number of negative samples. Without\nnegative samples yet achieving competitive performance, a recent work has\nattracted significant attention for providing a minimalist simple Siamese\n(SimSiam) method to avoid collapse. However, the reason for how it avoids\ncollapse without negative samples remains not fully clear and our investigation\nstarts by revisiting the explanatory claims in the original SimSiam. After\nrefuting their claims, we introduce vector decomposition for analyzing the\ncollapse based on the gradient analysis of the $l_2$-normalized representation\nvector. This yields a unified perspective on how negative samples and SimSiam\nalleviate collapse. Such a unified perspective comes timely for understanding\nthe recent progress in SSL.\n",
                "链接": "https://arxiv.org/abs/2203.16262"
            },
            {
                "文章ID": "55962",
                "标题": "Understanding Imbalanced Semantic Segmentation Through Neural Collapse",
                "作者": " Zhisheng Zhong,  Jiequan Cui,  Yibo Yang,  Xiaoyang Wu,  Xiaojuan Qi,  Xiangyu Zhang,  Jiaya Jia",
                "发布日期": "2023-01-04",
                "摘要": "  A recent study has shown a phenomenon called neural collapse in that the\nwithin-class means of features and the classifier weight vectors converge to\nthe vertices of a simplex equiangular tight frame at the terminal phase of\ntraining for classification. In this paper, we explore the corresponding\nstructures of the last-layer feature centers and classifiers in semantic\nsegmentation. Based on our empirical and theoretical analysis, we point out\nthat semantic segmentation naturally brings contextual correlation and\nimbalanced distribution among classes, which breaks the equiangular and\nmaximally separated structure of neural collapse for both feature centers and\nclassifiers. However, such a symmetric structure is beneficial to\ndiscrimination for the minor classes. To preserve these advantages, we\nintroduce a regularizer on feature centers to encourage the network to learn\nfeatures closer to the appealing structure in imbalanced semantic segmentation.\nExperimental results show that our method can bring significant improvements on\nboth 2D and 3D semantic segmentation benchmarks. Moreover, our method ranks 1st\nand sets a new record (+6.8% mIoU) on the ScanNet200 test leaderboard. Code\nwill be available at https://github.com/dvlab-research/Imbalanced-Learning.\n",
                "链接": "https://arxiv.org/abs/2301.01100"
            },
            {
                "文章ID": "49203",
                "标题": "Sample-efficient Quantum Born Machine through Coding Rate Reduction",
                "作者": " Pengyuan Zhai",
                "发布日期": "2022-11-21",
                "摘要": "  The quantum circuit Born machine (QCBM) is a quantum physics inspired\nimplicit generative model naturally suitable for learning binary images, with a\npotential advantage of modeling discrete distributions that are hard to\nsimulate classically. As data samples are generated quantum-mechanically, QCBMs\nencompass a unique optimization landscape. However, pioneering works on QCBMs\ndo not consider the practical scenario where only small batch sizes are allowed\nduring training. QCBMs trained with a statistical two-sample test objective in\nthe image space require large amounts of projective measurements to approximate\nthe model distribution well, unpractical for large-scale quantum systems due to\nthe exponential scaling of the probability space. QCBMs trained adversarially\nagainst a deep neural network discriminator are proof-of-concept models that\nface mode collapse. In this work we investigate practical learning of QCBMs. We\nuse the information-theoretic \\textit{Maximal Coding Rate Reduction} (MCR$^2$)\nmetric as a second moment matching tool and study its effect on mode collapse\nin QCBMs. We compute the sampling based gradient of MCR$^2$ with respect to\nquantum circuit parameters with or without an explicit feature mapping. We\nexperimentally show that matching up to the second moment alone is not\nsufficient for training the quantum generator, but when combined with the class\nprobability estimation loss, MCR$^2$ is able to resist mode collapse. In\naddition, we show that adversarially trained neural network kernel for infinite\nmoment matching is also effective against mode collapse. On the Bars and\nStripes dataset, our proposed techniques alleviate mode collapse to a larger\ndegree than previous QCBM training schemes, moving one step closer towards\npracticality and scalability.\n",
                "链接": "https://arxiv.org/abs/2211.10418"
            },
            {
                "文章ID": "63677",
                "标题": "A Prototypical Semantic Decoupling Method via Joint Contrastive Learning\n  for Few-Shot Name Entity Recognition",
                "作者": " Guanting Dong,  Zechen Wang,  Liwen Wang,  Daichi Guo,  Dayuan Fu,  Yuxiang Wu,  Chen Zeng,  Xuefeng Li,  Tingfeng Hui,  Keqing He,  Xinyue Cui,  Qixiang Gao,  Weiran Xu",
                "发布日期": "2023-04-13",
                "摘要": "  Few-shot named entity recognition (NER) aims at identifying named entities\nbased on only few labeled instances. Most existing prototype-based sequence\nlabeling models tend to memorize entity mentions which would be easily confused\nby close prototypes. In this paper, we proposed a Prototypical Semantic\nDecoupling method via joint Contrastive learning (PSDC) for few-shot NER.\nSpecifically, we decouple class-specific prototypes and contextual semantic\nprototypes by two masking strategies to lead the model to focus on two\ndifferent semantic information for inference. Besides, we further introduce\njoint contrastive learning objectives to better integrate two kinds of\ndecoupling information and prevent semantic collapse. Experimental results on\ntwo few-shot NER benchmarks demonstrate that PSDC consistently outperforms the\nprevious SOTA methods in terms of overall performance. Extensive analysis\nfurther validates the effectiveness and generalization of PSDC.\n",
                "链接": "https://arxiv.org/abs/2302.13610"
            },
            {
                "文章ID": "80825",
                "标题": "Feature Collapse",
                "作者": " Thomas Laurent,  James H. von Brecht,  Xavier Bresson",
                "发布日期": "2023-05-26",
                "摘要": "  We formalize and study a phenomenon called feature collapse that makes\nprecise the intuitive idea that entities playing a similar role in a learning\ntask receive similar representations. As feature collapse requires a notion of\ntask, we leverage a simple but prototypical NLP task to study it. We start by\nshowing experimentally that feature collapse goes hand in hand with\ngeneralization. We then prove that, in the large sample limit, distinct words\nthat play identical roles in this NLP task receive identical local feature\nrepresentations in a neural network. This analysis reveals the crucial role\nthat normalization mechanisms, such as LayerNorm, play in feature collapse and\nin generalization.\n",
                "链接": "https://arxiv.org/abs/2305.16162"
            },
            {
                "文章ID": "18416",
                "标题": "Posterior Collapse of a Linear Latent Variable Model",
                "作者": " Zihao Wang,  Liu Ziyin",
                "发布日期": "2022-10-17",
                "摘要": "  This work identifies the existence and cause of a type of posterior collapse\nthat frequently occurs in the Bayesian deep learning practice. For a general\nlinear latent variable model that includes linear variational autoencoders as a\nspecial case, we precisely identify the nature of posterior collapse to be the\ncompetition between the likelihood and the regularization of the mean due to\nthe prior. Our result suggests that posterior collapse may be related to neural\ncollapse and dimensional collapse and could be a subclass of a general problem\nof learning for deeper architectures.\n",
                "链接": "https://arxiv.org/abs/2205.04009"
            },
            {
                "文章ID": "50574",
                "标题": "Rethinking Alignment and Uniformity in Unsupervised Image Semantic\n  Segmentation",
                "作者": " Daoan Zhang,  Chenming Li,  Haoquan Li,  Wenjian Huang,  Lingyun Huang,  Jianguo Zhang",
                "发布日期": "2023-04-04",
                "摘要": "  Unsupervised image semantic segmentation(UISS) aims to match low-level visual\nfeatures with semantic-level representations without outer supervision. In this\npaper, we address the critical properties from the view of feature alignments\nand feature uniformity for UISS models. We also make a comparison between UISS\nand image-wise representation learning. Based on the analysis, we argue that\nthe existing MI-based methods in UISS suffer from representation collapse. By\nthis, we proposed a robust network called Semantic Attention Network(SAN), in\nwhich a new module Semantic Attention(SEAT) is proposed to generate pixel-wise\nand semantic features dynamically. Experimental results on multiple semantic\nsegmentation benchmarks show that our unsupervised segmentation framework\nspecializes in catching semantic representations, which outperforms all the\nunpretrained and even several pretrained methods.\n",
                "链接": "https://arxiv.org/abs/2211.14513"
            },
            {
                "文章ID": "40678",
                "标题": "Are All Losses Created Equal: A Neural Collapse Perspective",
                "作者": " Jinxin Zhou,  Chong You,  Xiao Li,  Kangning Liu,  Sheng Liu,  Qing Qu,  Zhihui Zhu",
                "发布日期": "2022-10-11",
                "摘要": "  While cross entropy (CE) is the most commonly used loss to train deep neural\nnetworks for classification tasks, many alternative losses have been developed\nto obtain better empirical performance. Among them, which one is the best to\nuse is still a mystery, because there seem to be multiple factors affecting the\nanswer, such as properties of the dataset, the choice of network architecture,\nand so on. This paper studies the choice of loss function by examining the\nlast-layer features of deep networks, drawing inspiration from a recent line\nwork showing that the global optimal solution of CE and mean-square-error (MSE)\nlosses exhibits a Neural Collapse phenomenon. That is, for sufficiently large\nnetworks trained until convergence, (i) all features of the same class collapse\nto the corresponding class mean and (ii) the means associated with different\nclasses are in a configuration where their pairwise distances are all equal and\nmaximized. We extend such results and show through global solution and\nlandscape analyses that a broad family of loss functions including commonly\nused label smoothing (LS) and focal loss (FL) exhibits Neural Collapse. Hence,\nall relevant losses(i.e., CE, LS, FL, MSE) produce equivalent features on\ntraining data. Based on the unconstrained feature model assumption, we provide\neither the global landscape analysis for LS loss or the local landscape\nanalysis for FL loss and show that the (only!) global minimizers are neural\ncollapse solutions, while all other critical points are strict saddles whose\nHessian exhibit negative curvature directions either in the global scope for LS\nloss or in the local scope for FL loss near the optimal solution. The\nexperiments further show that Neural Collapse features obtained from all\nrelevant losses lead to largely identical performance on test data as well,\nprovided that the network is sufficiently large and trained until convergence.\n",
                "链接": "https://arxiv.org/abs/2210.02192"
            }
        ]
    },
    {
        "question": {
            "question": "查找大语言模型相关的分析类型的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找多模态agent, 具身智能的相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找中文ner常用的数据集论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下利用蒙特卡罗树搜索解决序列决策问题的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "54835",
                "标题": "Feature Acquisition using Monte Carlo Tree Search",
                "作者": " Sungsoo Lim,  Diego Klabjan,  Mark Shapiro",
                "发布日期": "2022-12-23",
                "摘要": "  Feature acquisition algorithms address the problem of acquiring informative\nfeatures while balancing the costs of acquisition to improve the learning\nperformances of ML models. Previous approaches have focused on calculating the\nexpected utility values of features to determine the acquisition sequences.\nOther approaches formulated the problem as a Markov Decision Process (MDP) and\napplied reinforcement learning based algorithms. In comparison to previous\napproaches, we focus on 1) formulating the feature acquisition problem as a MDP\nand applying Monte Carlo Tree Search, 2) calculating the intermediary rewards\nfor each acquisition step based on model improvements and acquisition costs and\n3) simultaneously optimizing model improvement and acquisition costs with\nmulti-objective Monte Carlo Tree Search. With Proximal Policy Optimization and\nDeep Q-Network algorithms as benchmark, we show the effectiveness of our\nproposed approach with experimental study.\n",
                "链接": "https://arxiv.org/abs/2212.11360"
            },
            {
                "文章ID": "107193",
                "标题": "Evolutionary Retrosynthetic Route Planning",
                "作者": " Yan Zhang,  Hao Hao,  Xiao He,  Shuanhu Gao,  Aimin Zhou",
                "发布日期": "2023-10-10",
                "摘要": "  Molecular retrosynthesis is a significant and complex problem in the field of\nchemistry, however, traditional manual synthesis methods not only need\nwell-trained experts but also are time-consuming. With the development of big\ndata and machine learning, artificial intelligence (AI) based retrosynthesis is\nattracting more attention and is becoming a valuable tool for molecular\nretrosynthesis. At present, Monte Carlo tree search is a mainstream search\nframework employed to address this problem. Nevertheless, its search efficiency\nis compromised by its large search space. Therefore, we propose a novel\napproach for retrosynthetic route planning based on evolutionary optimization,\nmarking the first use of Evolutionary Algorithm (EA) in the field of multi-step\nretrosynthesis. The proposed method involves modeling the retrosynthetic\nproblem into an optimization problem, defining the search space and operators.\nAdditionally, to improve the search efficiency, a parallel strategy is\nimplemented. The new approach is applied to four case products, and is compared\nwith Monte Carlo tree search. The experimental results show that, in comparison\nto the Monte Carlo tree search algorithm, EA significantly reduces the number\nof calling single-step model by an average of 53.9%. The time required to\nsearch three solutions decreased by an average of 83.9%, and the number of\nfeasible search routes increases by 5 times.\n",
                "链接": "https://arxiv.org/abs/2310.05186"
            },
            {
                "文章ID": "75072",
                "标题": "Nearly Optimal Steiner Trees using Graph Neural Network Assisted Monte\n  Carlo Tree Search",
                "作者": " Reyan Ahmed,  Mithun Ghosh,  Kwang-Sung Jun,  Stephen Kobourov",
                "发布日期": "2023-05-02",
                "摘要": "  Graph neural networks are useful for learning problems, as well as for\ncombinatorial and graph problems such as the Subgraph Isomorphism Problem and\nthe Traveling Salesman Problem. We describe an approach for computing Steiner\nTrees by combining a graph neural network and Monte Carlo Tree Search. We first\ntrain a graph neural network that takes as input a partial solution and\nproposes a new node to be added as output. This neural network is then used in\na Monte Carlo search to compute a Steiner tree. The proposed method\nconsistently outperforms the standard 2-approximation algorithm on many\ndifferent types of graphs and often finds the optimal solution.\n",
                "链接": "https://arxiv.org/abs/2305.00535"
            },
            {
                "文章ID": "66610",
                "标题": "Beyond Games: A Systematic Review of Neural Monte Carlo Tree Search\n  Applications",
                "作者": " Marco Kemmerling,  Daniel Lütticke,  Robert H. Schmitt",
                "发布日期": "2023-12-29",
                "摘要": "  The advent of AlphaGo and its successors marked the beginning of a new\nparadigm in playing games using artificial intelligence. This was achieved by\ncombining Monte Carlo tree search, a planning procedure, and deep learning.\nWhile the impact on the domain of games has been undeniable, it is less clear\nhow useful similar approaches are in applications beyond games and how they\nneed to be adapted from the original methodology. We review 129 peer-reviewed\narticles detailing the application of neural Monte Carlo tree search methods in\ndomains other than games. Our goal is to systematically assess how such methods\nare structured in practice and if their success can be extended to other\ndomains. We find applications in a variety of domains, many distinct ways of\nguiding the tree search using learned policy and value functions, and various\ntraining methods. Our review maps the current landscape of algorithms in the\nfamily of neural monte carlo tree search as they are applied to practical\nproblems, which is a first step towards a more principled way of designing such\nalgorithms for specific problems and their requirements.\n",
                "链接": "https://arxiv.org/abs/2303.08060"
            },
            {
                "文章ID": "16547",
                "标题": "An Efficient Dynamic Sampling Policy For Monte Carlo Tree Search",
                "作者": " Gongbo Zhang,  Yijie Peng,  Yilong Xu",
                "发布日期": "2023-05-09",
                "摘要": "  We consider the popular tree-based search strategy within the framework of\nreinforcement learning, the Monte Carlo Tree Search (MCTS), in the context of\nfinite-horizon Markov decision process. We propose a dynamic sampling tree\npolicy that efficiently allocates limited computational budget to maximize the\nprobability of correct selection of the best action at the root node of the\ntree. Experimental results on Tic-Tac-Toe and Gomoku show that the proposed\ntree policy is more efficient than other competing methods.\n",
                "链接": "https://arxiv.org/abs/2204.12043"
            },
            {
                "文章ID": "50093",
                "标题": "Monte Carlo Tree Search Algorithms for Risk-Aware and Multi-Objective\n  Reinforcement Learning",
                "作者": " Conor F. Hayes,  Mathieu Reymond,  Diederik M. Roijers,  Enda Howley,  Patrick Mannion",
                "发布日期": "2022-12-07",
                "摘要": "  In many risk-aware and multi-objective reinforcement learning settings, the\nutility of the user is derived from a single execution of a policy. In these\nsettings, making decisions based on the average future returns is not suitable.\nFor example, in a medical setting a patient may only have one opportunity to\ntreat their illness. Making decisions using just the expected future returns --\nknown in reinforcement learning as the value -- cannot account for the\npotential range of adverse or positive outcomes a decision may have. Therefore,\nwe should use the distribution over expected future returns differently to\nrepresent the critical information that the agent requires at decision time by\ntaking both the future and accrued returns into consideration. In this paper,\nwe propose two novel Monte Carlo tree search algorithms. Firstly, we present a\nMonte Carlo tree search algorithm that can compute policies for nonlinear\nutility functions (NLU-MCTS) by optimising the utility of the different\npossible returns attainable from individual policy executions, resulting in\ngood policies for both risk-aware and multi-objective settings. Secondly, we\npropose a distributional Monte Carlo tree search algorithm (DMCTS) which\nextends NLU-MCTS. DMCTS computes an approximate posterior distribution over the\nutility of the returns, and utilises Thompson sampling during planning to\ncompute policies in risk-aware and multi-objective settings. Both algorithms\noutperform the state-of-the-art in multi-objective reinforcement learning for\nthe expected utility of the returns.\n",
                "链接": "https://arxiv.org/abs/2211.13032"
            },
            {
                "文章ID": "102301",
                "标题": "Maneuver Decision-Making Through Proximal Policy Optimization And Monte\n  Carlo Tree Search",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-09-19",
                "摘要": "  Maneuver decision-making can be regarded as a Markov decision process and can\nbe address by reinforcement learning. However, original reinforcement learning\nalgorithms can hardly solve the maneuvering decision-making problem. One reason\nis that agents use random actions in the early stages of training, which makes\nit difficult to get rewards and learn how to make effective decisions. To\naddress this issue, a method based on proximal policy optimization and Monte\nCarlo tree search is proposed. The method uses proximal policy optimization to\ntrain the agent, and regards the results of air combat as targets to train the\nvalue network. Then, based on the value network and the visit count of each\nnode, Monte Carlo tree search is used to find the actions with more expected\nreturns than random actions, which can improve the training performance. The\nablation studies and simulation experiments indicate that agents trained by the\nproposed method can make different decisions according to different states,\nwhich demonstrates that the method can solve the maneuvering decision problem\nthat the original reinforcement learning algorithm cannot solve.\n",
                "链接": "https://arxiv.org/abs/2309.08611"
            },
            {
                "文章ID": "103683",
                "标题": "The Mathematical Game",
                "作者": " Marc Pierre,  Quentin Cohen-Solal,  Tristan Cazenave",
                "发布日期": "2023-09-25",
                "摘要": "  Monte Carlo Tree Search can be used for automated theorem proving. Holophrasm\nis a neural theorem prover using MCTS combined with neural networks for the\npolicy and the evaluation. In this paper we propose to improve the performance\nof the Holophrasm theorem prover using other game tree search algorithms.\n",
                "链接": "https://arxiv.org/abs/2309.12711"
            },
            {
                "文章ID": "40416",
                "标题": "Continuous Monte Carlo Graph Search",
                "作者": " Kalle Kujanpää,  Amin Babadi,  Yi Zhao,  Juho Kannala,  Alexander Ilin,  Joni Pajarinen",
                "发布日期": "2023-07-19",
                "摘要": "  In many complex sequential decision-making tasks, online planning is crucial\nfor high performance. For efficient online planning, Monte Carlo Tree Search\n(MCTS) employs a principled mechanism for trading off exploration for\nexploitation. MCTS outperforms comparison methods in many discrete\ndecision-making domains such as Go, Chess, and Shogi. Following, extensions of\nMCTS to continuous domains have been proposed. However, the inherent high\nbranching factor and the resulting explosion of search tree size are limiting\nexisting methods. To address this problem, we propose Continuous Monte Carlo\nGraph Search (CMCGS), a novel extension of MCTS to online planning in\nenvironments with continuous state and action spaces. CMCGS takes advantage of\nthe insight that, during planning, sharing the same action policy between\nseveral states can yield high performance. To implement this idea, at each time\nstep, CMCGS clusters similar states into a limited number of stochastic action\nbandit nodes, which produce a layered directed graph instead of an MCTS search\ntree. Experimental evaluation shows that CMCGS outperforms comparable planning\nmethods in several complex continuous DeepMind Control Suite benchmarks and a\n2D navigation task with limited sample budgets. Furthermore, CMCGS can be\nparallelized to scale up and it outperforms the Cross-Entropy Method (CEM) in\ncontinuous control with learned dynamics models.\n",
                "链接": "https://arxiv.org/abs/2210.01426"
            },
            {
                "文章ID": "23592",
                "标题": "Combining Monte-Carlo Tree Search with Proof-Number Search",
                "作者": " Elliot Doe,  Mark H. M. Winands,  Dennis J. N. J. Soemers,  Cameron Browne",
                "发布日期": "2022-06-09",
                "摘要": "  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
                "链接": "https://arxiv.org/abs/2206.03965"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用gpt4做评测指标优缺点的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "123333",
                "标题": "The Pros and Cons of Adversarial Robustness",
                "作者": " Yacine Izza,  Joao Marques-Silva",
                "发布日期": "2023-12-19",
                "摘要": "  Robustness is widely regarded as a fundamental problem in the analysis of\nmachine learning (ML) models. Most often robustness equates with deciding the\nnon-existence of adversarial examples, where adversarial examples denote\nsituations where small changes on some inputs cause a change in the prediction.\nThe perceived importance of ML model robustness explains the continued progress\nobserved for most of the last decade. Whereas robustness is often assessed\nlocally, i.e. given some target point in feature space, robustness can also be\ndefined globally, i.e. where any point in feature space can be considered. The\nimportance of ML model robustness is illustrated for example by the existence\nof competitions evaluating the progress of robustness tools, namely in the case\nof neural networks (NNs) but also by efforts towards robustness certification.\nMore recently, robustness tools have also been used for computing rigorous\nexplanations of ML models. In contrast with the observed successes of\nrobustness, this paper uncovers some limitations with existing definitions of\nrobustness, both global and local, but also with efforts towards robustness\ncertification. The paper also investigates uses of adversarial examples besides\nthose related with robustness.\n",
                "链接": "https://arxiv.org/abs/2312.10911"
            },
            {
                "文章ID": "72141",
                "标题": "Computational modeling of semantic change",
                "作者": " Nina Tahmasebi,  Haim Dubossarsky",
                "发布日期": "2023-04-14",
                "摘要": "  In this chapter we provide an overview of computational modeling for semantic\nchange using large and semi-large textual corpora. We aim to provide a key for\nthe interpretation of relevant methods and evaluation techniques, and also\nprovide insights into important aspects of the computational study of semantic\nchange. We discuss the pros and cons of different classes of models with\nrespect to the properties of the data from which one wishes to model semantic\nchange, and which avenues are available to evaluate the results.\n",
                "链接": "https://arxiv.org/abs/2304.06337"
            },
            {
                "文章ID": "1688",
                "标题": "Digital Twin: From Concept to Practice",
                "作者": " Ashwin Agrawal,  Martin Fischer,  Vishal Singh",
                "发布日期": "2022-01-19",
                "摘要": "  Recent technological developments and advances in Artificial Intelligence\n(AI) have enabled sophisticated capabilities to be a part of Digital Twin (DT),\nvirtually making it possible to introduce automation into all aspects of work\nprocesses. Given these possibilities that DT can offer, practitioners are\nfacing increasingly difficult decisions regarding what capabilities to select\nwhile deploying a DT in practice. The lack of research in this field has not\nhelped either. It has resulted in the rebranding and reuse of emerging\ntechnological capabilities like prediction, simulation, AI, and Machine\nLearning (ML) as necessary constituents of DT. Inappropriate selection of\ncapabilities in a DT can result in missed opportunities, strategic\nmisalignments, inflated expectations, and risk of it being rejected as just\nhype by the practitioners. To alleviate this challenge, this paper proposes the\ndigitalization framework, designed and developed by following a Design Science\nResearch (DSR) methodology over a period of 18 months. The framework can help\npractitioners select an appropriate level of sophistication in a DT by weighing\nthe pros and cons for each level, deciding evaluation criteria for the digital\ntwin system, and assessing the implications of the selected DT on the\norganizational processes and strategies, and value creation. Three real-life\ncase studies illustrate the application and usefulness of the framework.\n",
                "链接": "https://arxiv.org/abs/2201.06912"
            },
            {
                "文章ID": "44092",
                "标题": "Video Summarization Overview",
                "作者": " Mayu Otani,  Yale Song,  Yang Wang",
                "发布日期": "2022-10-24",
                "摘要": "  With the broad growth of video capturing devices and applications on the web,\nit is more demanding to provide desired video content for users efficiently.\nVideo summarization facilitates quickly grasping video content by creating a\ncompact summary of videos. Much effort has been devoted to automatic video\nsummarization, and various problem settings and approaches have been proposed.\nOur goal is to provide an overview of this field. This survey covers early\nstudies as well as recent approaches which take advantage of deep learning\ntechniques. We describe video summarization approaches and their underlying\nconcepts. We also discuss benchmarks and evaluations. We overview how prior\nwork addressed evaluation and detail the pros and cons of the evaluation\nprotocols. Last but not least, we discuss open challenges in this field.\n",
                "链接": "https://arxiv.org/abs/2210.11707"
            },
            {
                "文章ID": "110224",
                "标题": "Benchmarking Sequential Visual Input Reasoning and Prediction in\n  Multimodal Large Language Models",
                "作者": " Mingwei Zhu,  Leigang Sha,  Yu Shu,  Kangjia Zhao,  Tiancheng Zhao,  Jianwei Yin",
                "发布日期": "2023-10-23",
                "摘要": "  Multimodal large language models (MLLMs) have shown great potential in\nperception and interpretation tasks, but their capabilities in predictive\nreasoning remain under-explored. To address this gap, we introduce a novel\nbenchmark that assesses the predictive reasoning capabilities of MLLMs across\ndiverse scenarios. Our benchmark targets three important domains: abstract\npattern reasoning, human activity prediction, and physical interaction\nprediction. We further develop three evaluation methods powered by large\nlanguage model to robustly quantify a model's performance in predicting and\nreasoning the future based on multi-visual context. Empirical experiments\nconfirm the soundness of the proposed benchmark and evaluation methods via\nrigorous testing and reveal pros and cons of current popular MLLMs in the task\nof predictive reasoning. Lastly, our proposed benchmark provides a standardized\nevaluation framework for MLLMs and can facilitate the development of more\nadvanced models that can reason and predict over complex long sequence of\nmultimodal input.\n",
                "链接": "https://arxiv.org/abs/2310.13473"
            },
            {
                "文章ID": "33038",
                "标题": "On the Pros and Cons of Momentum Encoder in Self-Supervised Visual\n  Representation Learning",
                "作者": " Trung Pham,  Chaoning Zhang,  Axi Niu,  Kang Zhang,  Chang D. Yoo",
                "发布日期": "2022-08-12",
                "摘要": "  Exponential Moving Average (EMA or momentum) is widely used in modern\nself-supervised learning (SSL) approaches, such as MoCo, for enhancing\nperformance. We demonstrate that such momentum can also be plugged into\nmomentum-free SSL frameworks, such as SimCLR, for a performance boost. Despite\nits wide use as a fundamental component in modern SSL frameworks, the benefit\ncaused by momentum is not well understood. We find that its success can be at\nleast partly attributed to the stability effect. In the first attempt, we\nanalyze how EMA affects each part of the encoder and reveal that the portion\nnear the encoder's input plays an insignificant role while the latter parts\nhave much more influence. By monitoring the gradient of the overall loss with\nrespect to the output of each block in the encoder, we observe that the final\nlayers tend to fluctuate much more than other layers during backpropagation,\ni.e. less stability. Interestingly, we show that using EMA to the final part of\nthe SSL encoder, i.e. projector, instead of the whole deep network encoder can\ngive comparable or preferable performance. Our proposed projector-only momentum\nhelps maintain the benefit of EMA but avoids the double forward computation.\n",
                "链接": "https://arxiv.org/abs/2208.05744"
            },
            {
                "文章ID": "54746",
                "标题": "Critic-Guided Decoding for Controlled Text Generation",
                "作者": " Minbeom Kim,  Hwanhee Lee,  Kang Min Yoo,  Joonsuk Park,  Hwaran Lee,  Kyomin Jung",
                "发布日期": "2022-12-22",
                "摘要": "  Steering language generation towards objectives or away from undesired\ncontent has been a long-standing goal in utilizing language models (LM). Recent\nwork has demonstrated reinforcement learning and weighted decoding as effective\napproaches to achieve a higher level of language control and quality with pros\nand cons. In this work, we propose a novel critic decoding method for\ncontrolled language generation (CriticControl) that combines the strengths of\nreinforcement learning and weighted decoding. Specifically, we adopt the\nactor-critic framework to train an LM-steering critic from non-differentiable\nreward models. And similar to weighted decoding, our method freezes the\nlanguage model and manipulates the output token distribution using called\ncritic, improving training efficiency and stability. Evaluation of our method\non three controlled generation tasks, namely topic control, sentiment control,\nand detoxification, shows that our approach generates more coherent and\nwell-controlled texts than previous methods. In addition, CriticControl\ndemonstrates superior generalization ability in zero-shot settings. Human\nevaluation studies also corroborate our findings.\n",
                "链接": "https://arxiv.org/abs/2212.10938"
            },
            {
                "文章ID": "61858",
                "标题": "Product Question Answering in E-Commerce: A Survey",
                "作者": " Yang Deng,  Wenxuan Zhang,  Qian Yu,  Wai Lam",
                "发布日期": "2023-05-04",
                "摘要": "  Product question answering (PQA), aiming to automatically provide instant\nresponses to customer's questions in E-Commerce platforms, has drawn increasing\nattention in recent years. Compared with typical QA problems, PQA exhibits\nunique challenges such as the subjectivity and reliability of user-generated\ncontents in E-commerce platforms. Therefore, various problem settings and novel\nmethods have been proposed to capture these special characteristics. In this\npaper, we aim to systematically review existing research efforts on PQA.\nSpecifically, we categorize PQA studies into four problem settings in terms of\nthe form of provided answers. We analyze the pros and cons, as well as present\nexisting datasets and evaluation protocols for each setting. We further\nsummarize the most significant challenges that characterize PQA from general QA\napplications and discuss their corresponding solutions. Finally, we conclude\nthis paper by providing the prospect on several future directions.\n",
                "链接": "https://arxiv.org/abs/2302.08092"
            },
            {
                "文章ID": "42181",
                "标题": "A Comparative Study on 1.5T-3T MRI Conversion through Deep Neural\n  Network Models",
                "作者": " Binhua Liao,  Yani Chen,  Zhewei Wang,  Charles D. Smith,  Jundong Liu",
                "发布日期": "2022-10-13",
                "摘要": "  In this paper, we explore the capabilities of a number of deep neural network\nmodels in generating whole-brain 3T-like MR images from clinical 1.5T MRIs. The\nmodels include a fully convolutional network (FCN) method and three\nstate-of-the-art super-resolution solutions, ESPCN [26], SRGAN [17] and PRSR\n[7]. The FCN solution, U-Convert-Net, carries out mapping of 1.5T-to-3T slices\nthrough a U-Net-like architecture, with 3D neighborhood information integrated\nthrough a multi-view ensemble. The pros and cons of the models, as well the\nassociated evaluation metrics, are measured with experiments and discussed in\ndepth. To the best of our knowledge, this study is the first work to evaluate\nmultiple deep learning solutions for whole-brain MRI conversion, as well as the\nfirst attempt to utilize FCN/U-Net-like structure for this purpose.\n",
                "链接": "https://arxiv.org/abs/2210.06362"
            },
            {
                "文章ID": "101596",
                "标题": "OTAS: Unsupervised Boundary Detection for Object-Centric Temporal Action\n  Segmentation",
                "作者": " Yuerong Li,  Zhengrong Xue,  Huazhe Xu",
                "发布日期": "2023-09-13",
                "摘要": "  Temporal action segmentation is typically achieved by discovering the\ndramatic variances in global visual descriptors. In this paper, we explore the\nmerits of local features by proposing the unsupervised framework of\nObject-centric Temporal Action Segmentation (OTAS). Broadly speaking, OTAS\nconsists of self-supervised global and local feature extraction modules as well\nas a boundary selection module that fuses the features and detects salient\nboundaries for action segmentation. As a second contribution, we discuss the\npros and cons of existing frame-level and boundary-level evaluation metrics.\nThrough extensive experiments, we find OTAS is superior to the previous\nstate-of-the-art method by $41\\%$ on average in terms of our recommended F1\nscore. Surprisingly, OTAS even outperforms the ground-truth human annotations\nin the user study. Moreover, OTAS is efficient enough to allow real-time\ninference.\n",
                "链接": "https://arxiv.org/abs/2309.06276"
            }
        ]
    },
    {
        "question": {
            "question": "使用LLM进行蛋白质结构/功能/性质预测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "109510",
                "标题": "Protein 3D Graph Structure Learning for Robust Structure-based Protein\n  Property Prediction",
                "作者": " Yufei Huang,  Siyuan Li,  Jin Su,  Lirong Wu,  Odin Zhang,  Haitao Lin,  Jingqi Qi,  Zihan Liu,  Zhangyang Gao,  Yuyang Liu,  Jiangbin Zheng,  Stan. ZQ. Li",
                "发布日期": "2023-10-20",
                "摘要": "  Protein structure-based property prediction has emerged as a promising\napproach for various biological tasks, such as protein function prediction and\nsub-cellular location estimation. The existing methods highly rely on\nexperimental protein structure data and fail in scenarios where these data are\nunavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were\nutilized as alternatives. However, we observed that current practices, which\nsimply employ accurately predicted structures during inference, suffer from\nnotable degradation in prediction accuracy. While similar phenomena have been\nextensively studied in general fields (e.g., Computer Vision) as model\nrobustness, their impact on protein property prediction remains unexplored. In\nthis paper, we first investigate the reason behind the performance decrease\nwhen utilizing predicted structures, attributing it to the structure embedding\nbias from the perspective of structure representation learning. To study this\nproblem, we identify a Protein 3D Graph Structure Learning Problem for Robust\nProtein Property Prediction (PGSL-RP3), collect benchmark datasets, and present\na protein Structure embedding Alignment Optimization framework (SAO) to\nmitigate the problem of structure embedding bias between the predicted and\nexperimental protein structures. Extensive experiments have shown that our\nframework is model-agnostic and effective in improving the property prediction\nof both predicted structures and experimental structures. The benchmark\ndatasets and codes will be released to benefit the community.\n",
                "链接": "https://arxiv.org/abs/2310.11466"
            },
            {
                "文章ID": "106475",
                "标题": "InstructProtein: Aligning Human and Protein Language via Knowledge\n  Instruction",
                "作者": " Zeyuan Wang,  Qiang Zhang,  Keyan Ding,  Ming Qin,  Xiang Zhuang,  Xiaotong Li,  Huajun Chen",
                "发布日期": "2023-10-06",
                "摘要": "  Large Language Models (LLMs) have revolutionized the field of natural\nlanguage processing, but they fall short in comprehending biological sequences\nsuch as proteins. To address this challenge, we propose InstructProtein, an\ninnovative LLM that possesses bidirectional generation capabilities in both\nhuman and protein languages: (i) taking a protein sequence as input to predict\nits textual function description and (ii) using natural language to prompt\nprotein sequence generation. To achieve this, we first pre-train an LLM on both\nprotein and natural language corpora, enabling it to comprehend individual\nlanguages. Then supervised instruction tuning is employed to facilitate the\nalignment of these two distinct languages. Herein, we introduce a knowledge\ngraph-based instruction generation framework to construct a high-quality\ninstruction dataset, addressing annotation imbalance and instruction deficits\nin existing protein-text corpus. In particular, the instructions inherit the\nstructural relations between proteins and function annotations in knowledge\ngraphs, which empowers our model to engage in the causal modeling of protein\nfunctions, akin to the chain-of-thought processes in natural languages.\nExtensive experiments on bidirectional protein-text generation tasks show that\nInstructProtein outperforms state-of-the-art LLMs by large margins. Moreover,\nInstructProtein serves as a pioneering step towards text-based protein function\nprediction and sequence design, effectively bridging the gap between protein\nand human language understanding.\n",
                "链接": "https://arxiv.org/abs/2310.03269"
            },
            {
                "文章ID": "9383",
                "标题": "Protein Representation Learning by Geometric Structure Pretraining",
                "作者": " Zuobai Zhang,  Minghao Xu,  Arian Jamasb,  Vijil Chenthamarakshan,  Aurelie Lozano,  Payel Das,  Jian Tang",
                "发布日期": "2023-01-31",
                "摘要": "  Learning effective protein representations is critical in a variety of tasks\nin biology such as predicting protein function or structure. Existing\napproaches usually pretrain protein language models on a large number of\nunlabeled amino acid sequences and then finetune the models with some labeled\ndata in downstream tasks. Despite the effectiveness of sequence-based\napproaches, the power of pretraining on known protein structures, which are\navailable in smaller numbers only, has not been explored for protein property\nprediction, though protein structures are known to be determinants of protein\nfunction. In this paper, we propose to pretrain protein representations\naccording to their 3D structures. We first present a simple yet effective\nencoder to learn the geometric features of a protein. We pretrain the protein\ngraph encoder by leveraging multiview contrastive learning and different\nself-prediction tasks. Experimental results on both function prediction and\nfold classification tasks show that our proposed pretraining methods outperform\nor are on par with the state-of-the-art sequence-based methods, while using\nmuch less pretraining data. Our implementation is available at\nhttps://github.com/DeepGraphLearning/GearNet.\n",
                "链接": "https://arxiv.org/abs/2203.06125"
            },
            {
                "文章ID": "63348",
                "标题": "Retrieved Sequence Augmentation for Protein Representation Learning",
                "作者": " Chang Ma,  Haiteng Zhao,  Lin Zheng,  Jiayi Xin,  Qintong Li,  Lijun Wu,  Zhihong Deng,  Yang Lu,  Qi Liu,  Lingpeng Kong",
                "发布日期": "2023-02-27",
                "摘要": "  Protein language models have excelled in a variety of tasks, ranging from\nstructure prediction to protein engineering. However, proteins are highly\ndiverse in functions and structures, and current state-of-the-art models\nincluding the latest version of AlphaFold rely on Multiple Sequence Alignments\n(MSA) to feed in the evolutionary knowledge. Despite their success, heavy\ncomputational overheads, as well as the de novo and orphan proteins remain\ngreat challenges in protein representation learning. In this work, we show that\nMSAaugmented models inherently belong to retrievalaugmented methods. Motivated\nby this finding, we introduce Retrieved Sequence Augmentation(RSA) for protein\nrepresentation learning without additional alignment or pre-processing. RSA\nlinks query protein sequences to a set of sequences with similar structures or\nproperties in the database and combines these sequences for downstream\nprediction. We show that protein language models benefit from the retrieval\nenhancement on both structure prediction and property prediction tasks, with a\n5% improvement on MSA Transformer on average while being 373 times faster. In\naddition, we show that our model can transfer to new protein domains better and\noutperforms MSA Transformer on de novo protein prediction. Our study fills a\nmuch-encountered gap in protein prediction and brings us a step closer to\ndemystifying the domain knowledge needed to understand protein sequences. Code\nis available on https://github.com/HKUNLP/RSA.\n",
                "链接": "https://arxiv.org/abs/2302.12563"
            },
            {
                "文章ID": "26245",
                "标题": "PSP: Million-level Protein Sequence Dataset for Protein Structure\n  Prediction",
                "作者": " Sirui Liu,  Jun Zhang,  Haotian Chu,  Min Wang,  Boxin Xue,  Ningxi Ni,  Jialiang Yu,  Yuhao Xie,  Zhenyu Chen,  Mengyun Chen,  Yuan Liu,  Piya Patra,  Fan Xu,  Jie Chen,  Zidong Wang,  Lijiang Yang,  Fan Yu,  Lei Chen,  Yi Qin Gao",
                "发布日期": "2022-06-27",
                "摘要": "  Proteins are essential component of human life and their structures are\nimportant for function and mechanism analysis. Recent work has shown the\npotential of AI-driven methods for protein structure prediction. However, the\ndevelopment of new models is restricted by the lack of dataset and benchmark\ntraining procedure. To the best of our knowledge, the existing open source\ndatasets are far less to satisfy the needs of modern protein sequence-structure\nrelated research. To solve this problem, we present the first million-level\nprotein structure prediction dataset with high coverage and diversity, named as\nPSP. This dataset consists of 570k true structure sequences (10TB) and 745k\ncomplementary distillation sequences (15TB). We provide in addition the\nbenchmark training procedure for SOTA protein structure prediction model on\nthis dataset. We validate the utility of this dataset for training by\nparticipating CAMEO contest in which our model won the first place. We hope our\nPSP dataset together with the training benchmark can enable a broader community\nof AI/biology researchers for AI-driven protein related research.\n",
                "链接": "https://arxiv.org/abs/2206.12240"
            },
            {
                "文章ID": "16136",
                "标题": "Generative De Novo Protein Design with Global Context",
                "作者": " Cheng Tan,  Zhangyang Gao,  Jun Xia,  Bozhen Hu,  Stan Z. Li",
                "发布日期": "2023-02-22",
                "摘要": "  The linear sequence of amino acids determines protein structure and function.\nProtein design, known as the inverse of protein structure prediction, aims to\nobtain a novel protein sequence that will fold into the defined structure.\nRecent works on computational protein design have studied designing sequences\nfor the desired backbone structure with local positional information and\nachieved competitive performance. However, similar local environments in\ndifferent backbone structures may result in different amino acids, indicating\nthat protein structure's global context matters. Thus, we propose the\nGlobal-Context Aware generative de novo protein design method (GCA), consisting\nof local and global modules. While local modules focus on relationships between\nneighbor amino acids, global modules explicitly capture non-local contexts.\nExperimental results demonstrate that the proposed GCA method outperforms\nstate-of-the-arts on de novo protein design. Our code and pretrained model will\nbe released.\n",
                "链接": "https://arxiv.org/abs/2204.10673"
            },
            {
                "文章ID": "24433",
                "标题": "Exploring evolution-aware & -free protein language models as protein\n  function predictors",
                "作者": " Mingyang Hu,  Fajie Yuan,  Kevin K. Yang,  Fusong Ju,  Jin Su,  Hui Wang,  Fei Yang,  Qiuyang Ding",
                "发布日期": "2022-10-18",
                "摘要": "  Large-scale Protein Language Models (PLMs) have improved performance in\nprotein prediction tasks, ranging from 3D structure prediction to various\nfunction predictions. In particular, AlphaFold, a ground-breaking AI system,\ncould potentially reshape structural biology. However, the utility of the PLM\nmodule in AlphaFold, Evoformer, has not been explored beyond structure\nprediction. In this paper, we investigate the representation ability of three\npopular PLMs: ESM-1b (single sequence), MSA-Transformer (multiple sequence\nalignment) and Evoformer (structural), with a special focus on Evoformer.\nSpecifically, we aim to answer the following key questions: (i) Does the\nEvoformer trained as part of AlphaFold produce representations amenable to\npredicting protein function? (ii) If yes, can Evoformer replace ESM-1b and\nMSA-Transformer? (ii) How much do these PLMs rely on evolution-related protein\ndata? In this regard, are they complementary to each other? We compare these\nmodels by empirical study along with new insights and conclusions. All code and\ndatasets for reproducibility are available at\nhttps://github.com/elttaes/Revisiting-PLMs.\n",
                "链接": "https://arxiv.org/abs/2206.06583"
            },
            {
                "文章ID": "65999",
                "标题": "A Systematic Study of Joint Representation Learning on Protein Sequences\n  and Structures",
                "作者": " Zuobai Zhang,  Chuanrui Wang,  Minghao Xu,  Vijil Chenthamarakshan,  Aurélie Lozano,  Payel Das,  Jian Tang",
                "发布日期": "2023-10-19",
                "摘要": "  Learning effective protein representations is critical in a variety of tasks\nin biology such as predicting protein functions. Recent sequence representation\nlearning methods based on Protein Language Models (PLMs) excel in\nsequence-based tasks, but their direct adaptation to tasks involving protein\nstructures remains a challenge. In contrast, structure-based methods leverage\n3D structural information with graph neural networks and geometric pre-training\nmethods show potential in function prediction tasks, but still suffers from the\nlimited number of available structures. To bridge this gap, our study\nundertakes a comprehensive exploration of joint protein representation learning\nby integrating a state-of-the-art PLM (ESM-2) with distinct structure encoders\n(GVP, GearNet, CDConv). We introduce three representation fusion strategies and\nexplore different pre-training techniques. Our method achieves significant\nimprovements over existing sequence- and structure-based methods, setting new\nstate-of-the-art for function annotation. This study underscores several\nimportant design choices for fusing protein sequence and structure information.\nOur implementation is available at\nhttps://github.com/DeepGraphLearning/ESM-GearNet.\n",
                "链接": "https://arxiv.org/abs/2303.06275"
            },
            {
                "文章ID": "25918",
                "标题": "Transformer Neural Networks Attending to Both Sequence and Structure for\n  Protein Prediction Tasks",
                "作者": " Anowarul Kabir,  Amarda Shehu",
                "发布日期": "2022-06-23",
                "摘要": "  The increasing number of protein sequences decoded from genomes is opening up\nnew avenues of research on linking protein sequence to function with\ntransformer neural networks. Recent research has shown that the number of known\nprotein sequences supports learning useful, task-agnostic sequence\nrepresentations via transformers. In this paper, we posit that learning joint\nsequence-structure representations yields better representations for\nfunction-related prediction tasks. We propose a transformer neural network that\nattends to both sequence and tertiary structure. We show that such joint\nrepresentations are more powerful than sequence-based representations only, and\nthey yield better performance on superfamily membership across various metrics.\n",
                "链接": "https://arxiv.org/abs/2206.11057"
            },
            {
                "文章ID": "22961",
                "标题": "PEER: A Comprehensive and Multi-Task Benchmark for Protein Sequence\n  Understanding",
                "作者": " Minghao Xu,  Zuobai Zhang,  Jiarui Lu,  Zhaocheng Zhu,  Yangtian Zhang,  Chang Ma,  Runcheng Liu,  Jian Tang",
                "发布日期": "2022-09-20",
                "摘要": "  We are now witnessing significant progress of deep learning methods in a\nvariety of tasks (or datasets) of proteins. However, there is a lack of a\nstandard benchmark to evaluate the performance of different methods, which\nhinders the progress of deep learning in this field. In this paper, we propose\nsuch a benchmark called PEER, a comprehensive and multi-task benchmark for\nProtein sEquence undERstanding. PEER provides a set of diverse protein\nunderstanding tasks including protein function prediction, protein localization\nprediction, protein structure prediction, protein-protein interaction\nprediction, and protein-ligand interaction prediction. We evaluate different\ntypes of sequence-based methods for each task including traditional feature\nengineering approaches, different sequence encoding methods as well as\nlarge-scale pre-trained protein language models. In addition, we also\ninvestigate the performance of these methods under the multi-task learning\nsetting. Experimental results show that large-scale pre-trained protein\nlanguage models achieve the best performance for most individual tasks, and\njointly training multiple tasks further boosts the performance. The datasets\nand source codes of this benchmark are all available at\nhttps://github.com/DeepGraphLearning/PEER_Benchmark\n",
                "链接": "https://arxiv.org/abs/2206.02096"
            }
        ]
    },
    {
        "question": {
            "question": "请找出使用Transformer模型并在大规模数据集上进行预训练的论文。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下关于大模型使用工具的安全性的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "94169",
                "标题": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language\n  Models",
                "作者": " Cheng-Yu Hsieh,  Si-An Chen,  Chun-Liang Li,  Yasuhisa Fujii,  Alexander Ratner,  Chen-Yu Lee,  Ranjay Krishna,  Tomas Pfister",
                "发布日期": "2023-08-02",
                "摘要": "  Today, large language models (LLMs) are taught to use new tools by providing\na few demonstrations of the tool's usage. Unfortunately, demonstrations are\nhard to acquire, and can result in undesirable biased usage if the wrong\ndemonstration is chosen. Even in the rare scenario that demonstrations are\nreadily available, there is no principled selection protocol to determine how\nmany and which ones to provide. As tasks grow more complex, the selection\nsearch grows combinatorially and invariably becomes intractable. Our work\nprovides an alternative to demonstrations: tool documentation. We advocate the\nuse of tool documentation, descriptions for the individual tool usage, over\ndemonstrations. We substantiate our claim through three main empirical findings\non 6 tasks across both vision and language modalities. First, on existing\nbenchmarks, zero-shot prompts with only tool documentation are sufficient for\neliciting proper tool usage, achieving performance on par with few-shot\nprompts. Second, on a newly collected realistic tool-use dataset with hundreds\nof available tool APIs, we show that tool documentation is significantly more\nvaluable than demonstrations, with zero-shot documentation significantly\noutperforming few-shot without documentation. Third, we highlight the benefits\nof tool documentations by tackling image generation and video tracking using\njust-released unseen state-of-the-art models as tools. Finally, we highlight\nthe possibility of using tool documentation to automatically enable new\napplications: by using nothing more than the documentation of GroundingDino,\nStable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the\njust-released Grounded-SAM and Track Anything models.\n",
                "链接": "https://arxiv.org/abs/2308.00675"
            },
            {
                "文章ID": "95072",
                "标题": "TPTU: Large Language Model-based AI Agents for Task Planning and Tool\n  Usage",
                "作者": " Jingqing Ruan,  Yihong Chen,  Bin Zhang,  Zhiwei Xu,  Tianpeng Bao,  Guoqing Du,  Shiwei Shi,  Hangyu Mao,  Ziyue Li,  Xingyu Zeng,  Rui Zhao",
                "发布日期": "2023-11-08",
                "摘要": "  With recent advancements in natural language processing, Large Language\nModels (LLMs) have emerged as powerful tools for various real-world\napplications. Despite their prowess, the intrinsic generative abilities of LLMs\nmay prove insufficient for handling complex tasks which necessitate a\ncombination of task planning and the usage of external tools. In this paper, we\nfirst propose a structured framework tailored for LLM-based AI Agents and\ndiscuss the crucial capabilities necessary for tackling intricate problems.\nWithin this framework, we design two distinct types of agents (i.e., one-step\nagent and sequential agent) to execute the inference process. Subsequently, we\ninstantiate the framework using various LLMs and evaluate their Task Planning\nand Tool Usage (TPTU) abilities on typical tasks. By highlighting key findings\nand challenges, our goal is to provide a helpful resource for researchers and\npractitioners to leverage the power of LLMs in their AI applications. Our study\nemphasizes the substantial potential of these models, while also identifying\nareas that need more investigation and improvement.\n",
                "链接": "https://arxiv.org/abs/2308.03427"
            },
            {
                "文章ID": "116754",
                "标题": "TPTU-v2: Boosting Task Planning and Tool Usage of Large Language\n  Model-based Agents in Real-world Systems",
                "作者": " Yilun Kong,  Jingqing Ruan,  Yihong Chen,  Bin Zhang,  Tianpeng Bao,  Shiwei Shi,  Guoqing Du,  Xiaoru Hu,  Hangyu Mao,  Ziyue Li,  Xingyu Zeng,  Rui Zhao",
                "发布日期": "2023-11-21",
                "摘要": "  Large Language Models (LLMs) have demonstrated proficiency in addressing\ntasks that necessitate a combination of task planning and the usage of external\ntools that require a blend of task planning and the utilization of external\ntools, such as APIs. However, real-world complex systems present three\nprevalent challenges concerning task planning and tool usage: (1) The real\nsystem usually has a vast array of APIs, so it is impossible to feed the\ndescriptions of all APIs to the prompt of LLMs as the token length is limited;\n(2) the real system is designed for handling complex tasks, and the base LLMs\ncan hardly plan a correct sub-task order and API-calling order for such tasks;\n(3) Similar semantics and functionalities among APIs in real systems create\nchallenges for both LLMs and even humans in distinguishing between them. In\nresponse, this paper introduces a comprehensive framework aimed at enhancing\nthe Task Planning and Tool Usage (TPTU) abilities of LLM-based agents operating\nwithin real-world systems. Our framework comprises three key components\ndesigned to address these challenges: (1) the API Retriever selects the most\npertinent APIs for the user task among the extensive array available; (2) LLM\nFinetuner tunes a base LLM so that the finetuned LLM can be more capable for\ntask planning and API calling; (3) the Demo Selector adaptively retrieves\ndifferent demonstrations related to hard-to-distinguish APIs, which is further\nused for in-context learning to boost the final performance. We validate our\nmethods using a real-world commercial system as well as an open-sourced\nacademic dataset, and the outcomes clearly showcase the efficacy of each\nindividual component as well as the integrated framework.\n",
                "链接": "https://arxiv.org/abs/2311.11315"
            },
            {
                "文章ID": "116523",
                "标题": "ToolTalk: Evaluating Tool-Usage in a Conversational Setting",
                "作者": " Nicholas Farn,  Richard Shin",
                "发布日期": "2023-11-21",
                "摘要": "  Large language models (LLMs) have displayed massive improvements in reasoning\nand decision-making skills and can hold natural conversations with users. Many\nrecent works seek to augment LLM-based assistants with external tools so they\ncan access private or up-to-date information and carry out actions on behalf of\nusers. To better measure the performance of these assistants, this paper\nintroduces ToolTalk, a benchmark consisting of complex user intents requiring\nmulti-step tool usage specified through dialogue. ToolTalk contains 28 tools\ngrouped into 7 plugins, and includes a complete simulated implementation of\neach tool, allowing for fully automated evaluation of assistants that rely on\nexecution feedback. ToolTalk also emphasizes tools that externally affect the\nworld rather than only tools for referencing or searching information. We\nevaluate GPT-3.5 and GPT-4 on ToolTalk resulting in success rates of 26% and\n50% respectively. Our analysis of the errors reveals three major categories and\nsuggests some future directions for improvement. We release ToolTalk at\nhttps://github.com/microsoft/ToolTalk.\n",
                "链接": "https://arxiv.org/abs/2311.10775"
            },
            {
                "文章ID": "123332",
                "标题": "CLOVA: A Closed-Loop Visual Assistant with Tool Usage and Update",
                "作者": " Zhi Gao,  Yuntao Du,  Xintong Zhang,  Xiaojian Ma,  Wenjuan Han,  Song-Chun Zhu,  Qing Li",
                "发布日期": "2023-12-19",
                "摘要": "  Leveraging large language models (LLMs) to integrate off-the-shelf tools\n(e.g., visual models and image processing functions) is a promising research\ndirection to build powerful visual assistants for solving diverse visual tasks.\nHowever, the learning capability is rarely explored in existing methods, as\nthey freeze the used tools after deployment, thereby limiting the\ngeneralization to new environments requiring specific knowledge. In this paper,\nwe propose CLOVA, a Closed-LOop Visual Assistant to address this limitation,\nwhich encompasses inference, reflection, and learning phases in a closed-loop\nframework. During inference, LLMs generate programs and execute corresponding\ntools to accomplish given tasks. The reflection phase introduces a multimodal\nglobal-local reflection scheme to analyze whether and which tool needs to be\nupdated based on environmental feedback. Lastly, the learning phase uses three\nflexible manners to collect training data in real-time and introduces a novel\nprompt tuning scheme to update the tools, enabling CLOVA to efficiently learn\nspecific knowledge for new environments without human involvement. Experiments\nshow that CLOVA outperforms tool-usage methods by 5% in visual question\nanswering and multiple-image reasoning tasks, by 10% in knowledge tagging\ntasks, and by 20% in image editing tasks, highlighting the significance of the\nlearning capability for general visual assistants.\n",
                "链接": "https://arxiv.org/abs/2312.10908"
            },
            {
                "文章ID": "73408",
                "标题": "Safety Assessment of Chinese Large Language Models",
                "作者": " Hao Sun,  Zhexin Zhang,  Jiawen Deng,  Jiale Cheng,  Minlie Huang",
                "发布日期": "2023-04-21",
                "摘要": "  With the rapid popularity of large language models such as ChatGPT and GPT-4,\na growing amount of attention is paid to their safety concerns. These models\nmay generate insulting and discriminatory content, reflect incorrect social\nvalues, and may be used for malicious purposes such as fraud and dissemination\nof misleading information. Evaluating and enhancing their safety is\nparticularly essential for the wide application of large language models\n(LLMs). To further promote the safe deployment of LLMs, we develop a Chinese\nLLM safety assessment benchmark. Our benchmark explores the comprehensive\nsafety performance of LLMs from two perspectives: 8 kinds of typical safety\nscenarios and 6 types of more challenging instruction attacks. Our benchmark is\nbased on a straightforward process in which it provides the test prompts and\nevaluates the safety of the generated responses from the evaluated model. In\nevaluation, we utilize the LLM's strong evaluation ability and develop it as a\nsafety evaluator by prompting. On top of this benchmark, we conduct safety\nassessments and analyze 15 LLMs including the OpenAI GPT series and other\nwell-known Chinese LLMs, where we observe some interesting findings. For\nexample, we find that instruction attacks are more likely to expose safety\nissues of all LLMs. Moreover, to promote the development and deployment of\nsafe, responsible, and ethical AI, we publicly release SafetyPrompts including\n100k augmented prompts and responses by LLMs.\n",
                "链接": "https://arxiv.org/abs/2304.10436"
            },
            {
                "文章ID": "80992",
                "标题": "On the Tool Manipulation Capability of Open-source Large Language Models",
                "作者": " Qiantong Xu,  Fenglu Hong,  Bo Li,  Changran Hu,  Zhengyu Chen,  Jian Zhang",
                "发布日期": "2023-05-29",
                "摘要": "  Recent studies on software tool manipulation with large language models\n(LLMs) mostly rely on closed model APIs. The industrial adoption of these\nmodels is substantially constrained due to the security and robustness risks in\nexposing information to closed LLM API services. In this paper, we ask can we\nenhance open-source LLMs to be competitive to leading closed LLM APIs in tool\nmanipulation, with practical amount of human supervision. By analyzing common\ntool manipulation failures, we first demonstrate that open-source LLMs may\nrequire training with usage examples, in-context demonstration and generation\nstyle regulation to resolve failures. These insights motivate us to revisit\nclassical methods in LLM literature, and demonstrate that we can adapt them as\nmodel alignment with programmatic data generation, system prompts and\nin-context demonstration retrievers to enhance open-source LLMs for tool\nmanipulation. To evaluate these techniques, we create the ToolBench, a tool\nmanipulation benchmark consisting of diverse software tools for real-world\ntasks. We demonstrate that our techniques can boost leading open-source LLMs by\nup to 90% success rate, showing capabilities competitive to OpenAI GPT-4 in 4\nout of 8 ToolBench tasks. We show that such enhancement typically requires\nabout one developer day to curate data for each tool, rendering a recipe with\npractical amount of human supervision.\n",
                "链接": "https://arxiv.org/abs/2305.16504"
            },
            {
                "文章ID": "81272",
                "标题": "Large Language Models as Tool Makers",
                "作者": " Tianle Cai,  Xuezhi Wang,  Tengyu Ma,  Xinyun Chen,  Denny Zhou",
                "发布日期": "2023-05-29",
                "摘要": "  Recent research shows the potential of enhancing the problem-solving ability\nof large language models (LLMs) through the use of external tools. However,\nprior work along this line depends on the availability of existing tools. In\nthis work, we take an initial step towards removing this dependency by\nproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),\nwhere LLMs create their own reusable tools for problem-solving. Our approach\nconsists of two key phases: 1) tool making: an LLM acts as the tool maker that\ncrafts tools for given tasks, where a tool is implemented as a Python utility\nfunction. 2) tool using: an LLM acts as the tool user, which applies the tool\nbuilt by the tool maker for problem-solving. The tool user can be either the\nsame or a different LLM from the tool maker. Tool-making enables an LLM to\ncontinually generate tools that can be applied to different requests so that\nfuture requests can call the corresponding APIs when beneficial for solving the\ntasks. Furthermore, the division of labor among LLMs for tool-making and\ntool-using phases introduces the opportunity to achieve cost effectiveness\nwithout degrading the quality of generated tools and problem solutions. For\nexample, recognizing that tool-making demands more sophisticated capabilities\nthan tool-using, we can apply a powerful yet resource-intensive model as the\ntool maker, and a lightweight while cost-effective model as the tool user. We\nvalidate the effectiveness of our approach across a variety of complex\nreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and\nGPT-3.5 as the tool user, LATM can achieve performance that is on par with\nusing GPT-4 for both tool making and tool using, while the inference cost is\nsignificantly reduced.\n",
                "链接": "https://arxiv.org/abs/2305.17126"
            },
            {
                "文章ID": "42954",
                "标题": "HUDD: A tool to debug DNNs for safety analysis",
                "作者": " Hazem Fahmy,  Fabrizio Pastore,  Lionel Briand",
                "发布日期": "2022-10-18",
                "摘要": "  We present HUDD, a tool that supports safety analysis practices for systems\nenabled by Deep Neural Networks (DNNs) by automatically identifying the root\ncauses for DNN errors and retraining the DNN. HUDD stands for Heatmap-based\nUnsupervised Debugging of DNNs, it automatically clusters error-inducing images\nwhose results are due to common subsets of DNN neurons. The intent is for the\ngenerated clusters to group error-inducing images having common\ncharacteristics, that is, having a common root cause. HUDD identifies root\ncauses by applying a clustering algorithm to matrices (i.e., heatmaps)\ncapturing the relevance of every DNN neuron on the DNN outcome. Also, HUDD\nretrains DNNs with images that are automatically selected based on their\nrelatedness to the identified image clusters. Our empirical evaluation with\nDNNs from the automotive domain have shown that HUDD automatically identifies\nall the distinct root causes of DNN errors, thus supporting safety analysis.\nAlso, our retraining approach has shown to be more effective at improving DNN\naccuracy than existing approaches. A demo video of HUDD is available at\nhttps://youtu.be/drjVakP7jdU.\n",
                "链接": "https://arxiv.org/abs/2210.08356"
            },
            {
                "文章ID": "102063",
                "标题": "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language\n  Models that Follow Instructions",
                "作者": " Federico Bianchi,  Mirac Suzgun,  Giuseppe Attanasio,  Paul Röttger,  Dan Jurafsky,  Tatsunori Hashimoto,  James Zou",
                "发布日期": "2023-09-26",
                "摘要": "  Training large language models to follow instructions makes them perform\nbetter on a wide range of tasks, generally becoming more helpful. However, a\nperfectly helpful model will follow even the most malicious instructions and\nreadily generate harmful content. In this paper, we raise concerns over the\nsafety of models that only emphasize helpfulness, not safety, in their\ninstruction-tuning. We show that several popular instruction-tuned models are\nhighly unsafe. Moreover, we show that adding just 3% safety examples (a few\nhundred demonstrations) in the training set when fine-tuning a model like LLaMA\ncan substantially improve their safety. Our safety-tuning does not make models\nsignificantly less capable or helpful as measured by standard benchmarks.\nHowever, we do find a behavior of exaggerated safety, where too much\nsafety-tuning makes models refuse to respond to reasonable prompts that\nsuperficially resemble unsafe ones. Our study sheds light on trade-offs in\ntraining LLMs to follow instructions and exhibit safe behavior.\n",
                "链接": "https://arxiv.org/abs/2309.07875"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下对使用GPT生成数据集的训练步骤进行改进的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "121374",
                "标题": "Sim-GPT: Text Similarity via GPT Annotated Data",
                "作者": " Shuhe Wang,  Beiming Cao,  Shengyu Zhang,  Xiaoya Li,  Jiwei Li,  Fei Wu,  Guoyin Wang,  Eduard Hovy",
                "发布日期": "2023-12-13",
                "摘要": "  Due to the lack of a large collection of high-quality labeled sentence pairs\nwith textual similarity scores, existing approaches for Semantic Textual\nSimilarity (STS) mostly rely on unsupervised techniques or training signals\nthat are only partially correlated with textual similarity, e.g., NLI-based\ndatasets. To tackle this issue, in this paper, we propose the strategy of\nmeasuring text similarity via GPT annotated data (Sim-GPT for short). The core\nidea of Sim-GPT is to generate data with STS labels using GPT-4, based on which\nan STS model is trained. Sim-GPT framework utilizes LLMs to provide a\nsubstantial amount of reliable annotated data filling the gap of the lack of\ntraining signals for STS. Sim-GPT is trained on a one-time generated dataset\nusing BERT or RoBERTa as the backbone, which offers long-term savings in cost\nand speed compared to repeatedly invoking LLMs for each sentence pair. Trained\non the examples from GPT-4 (371K), Sim-GPT yields SOTA performances on the\nwidely-used seven STS benchmarks: +0.99 over supervised-SimCSE, and +0.42 over\nthe current SOTA PromCSE model. To encourage further advancements of the field,\nwe release both models and the 371K annotated examples from GPT-4. Code, models\nand annotated data are available at: https://github.com/ShuheWang1998/Sim-GPT.\n",
                "链接": "https://arxiv.org/abs/2312.05603"
            },
            {
                "文章ID": "73923",
                "标题": "Generation-driven Contrastive Self-training for Zero-shot Text\n  Classification with Instruction-tuned GPT",
                "作者": " Ruohong Zhang,  Yau-Shian Wang,  Yiming Yang",
                "发布日期": "2023-04-25",
                "摘要": "  Moreover, GPT-based zero-shot classification models tend to make independent\npredictions over test instances, which can be sub-optimal as the instance\ncorrelations and the decision boundaries in the target space are ignored. To\naddress these difficulties and limitations, we propose a new approach to\nzero-shot text classification, namely \\ourmodelshort, which leverages the\nstrong generative power of GPT to assist in training a smaller, more adaptable,\nand efficient sentence encoder classifier with contrastive self-training.\nSpecifically, GenCo applies GPT in two ways: firstly, it generates multiple\naugmented texts for each input instance to enhance the semantic embedding of\nthe instance and improve the mapping to relevant labels; secondly, it generates\naugmented texts conditioned on the predicted label during self-training, which\nmakes the generative process tailored to the decision boundaries in the target\nspace. In our experiments, GenCo outperforms previous state-of-the-art methods\non multiple benchmark datasets, even when only limited in-domain text data is\navailable.\n",
                "链接": "https://arxiv.org/abs/2304.11872"
            },
            {
                "文章ID": "80324",
                "标题": "RefGPT: Dialogue Generation of GPT, by GPT, and for GPT",
                "作者": " Dongjie Yang,  Ruifeng Yuan,  Yuantao Fan,  Yifei Yang,  Zili Wang,  Shusen Wang,  Hai Zhao",
                "发布日期": "2023-10-20",
                "摘要": "  Large Language Models (LLMs) have attained the impressive capability to\nresolve a wide range of NLP tasks by fine-tuning high-quality instruction data.\nHowever, collecting human-written data of high quality, especially multi-turn\ndialogues, is expensive and unattainable for most people. Though previous\nstudies have used powerful LLMs to generate the dialogues automatically, they\nall suffer from generating untruthful dialogues because of the model\nhallucination. Therefore, we propose a method called RefGPT to generate\nenormous truthful and customized dialogues without worrying about factual\nerrors caused by the model hallucination. RefGPT solves the model hallucination\nin dialogue generation by restricting the LLMs to leverage the given reference\ninstead of reciting their own knowledge to generate dialogues. Additionally,\nRefGPT adds detailed controls on every utterance to enable high customization\ncapability, which previous studies have ignored. On the basis of RefGPT, we\nalso propose two high-quality dialogue datasets generated by GPT-4, namely\nRefGPT-Fact and RefGPT-Code. RefGPT-Fact is a dataset with 100k multi-turn\ndialogues based on factual knowledge and RefGPT-Code has 76k multi-turn\ndialogues covering a wide range of coding scenarios. Our code and datasets are\nreleased in https://github.com/mutonix/RefGPT.\n",
                "链接": "https://arxiv.org/abs/2305.14994"
            },
            {
                "文章ID": "66852",
                "标题": "GPT-4 Technical Report",
                "作者": "Rai   OpenAI, Rai   :, Rai  Josh Achiam, Rai  Steven Adler, Rai  Sandhini Agarwal, Rai  Lama Ahmad, Rai  Ilge Akkaya, Rai  Florencia Leoni Aleman, Rai  Diogo Almeida, Rai  Janko Altenschmidt, Rai  Sam Altman, Rai  Shyamal Anadkat, Rai  Red Avila, Rai  Igor Babuschkin, Rai  Suchir Balaji, Rai  Valerie Balcom, Rai  Paul Baltescu, Rai  Haiming Bao, Rai  Mo Bavarian, Rai  Jeff Belgum, Rai  Irwan Bello, Rai  Jake Berdine, Rai  Gabriel Bernadett-Shapiro, Rai  Christopher Berner, Rai  Lenny Bogdonoff, Rai  Oleg Boiko, Rai  Madelaine Boyd, Rai  Anna-Luisa Brakman, Rai  Greg Brockman, Rai  Tim Brooks, Rai  Miles Brundage, Rai  Kevin Button, Rai  Trevor Cai, Rai  Rosie Campbell, Rai  Andrew Cann, Rai  Brittany Carey, Rai  Chelsea Carlson, Rai  Rory Carmichael, Rai  Brooke Chan, Rai  Che Chang, Rai  Fotis Chantzis, Rai  Derek Chen, Rai  Sully Chen, Rai  Ruby Chen, Rai  Jason Chen, Rai  Mark Chen, Rai  Ben Chess, Rai  Chester Cho, Rai  Casey Chu, Rai  Hyung Won Chung, Rai  Dave Cummings, Rai  Jeremiah Currier, Rai  Yunxing Dai, Rai  Cory Decareaux, Rai  Thomas Degry, Rai  Noah Deutsch, Rai  Damien Deville, Rai  Arka Dhar, Rai  David Dohan, Rai  Steve Dowling, Rai  Sheila Dunning, Rai  Adrien Ecoffet, Rai  Atty Eleti, Rai  Tyna Eloundou, Rai  David Farhi, Rai  Liam Fedus, Rai  Niko Felix, Rai  Simón Posada Fishman, Rai  Juston Forte, Rai  Isabella Fulford, Rai  Leo Gao, Rai  Elie Georges, Rai  Christian Gibson, Rai  Vik Goel, Rai  Tarun Gogineni, Rai  Gabriel Goh, Rai  Rapha Gontijo-Lopes, Rai  Jonathan Gordon, Rai  Morgan Grafstein, Rai  Scott Gray, Rai  Ryan Greene, Rai  Joshua Gross, Rai  Shixiang Shane Gu, Rai  Yufei Guo, Rai  Chris Hallacy, Rai  Jesse Han, Rai  Jeff Harris, Rai  Yuchen He, Rai  Mike Heaton, Rai  Johannes Heidecke, Rai  Chris Hesse, Rai  Alan Hickey, Rai  Wade Hickey, Rai  Peter Hoeschele, Rai  Brandon Houghton, Rai  Kenny Hsu, Rai  Shengli Hu, Rai  Xin Hu, Rai  Joost Huizinga, Rai  Shantanu Jain, Rai  Shawn Jain, Rai  Joanne Jang, Rai  Angela Jiang, Rai  Roger Jiang, Rai  Haozhun Jin, Rai  Denny Jin, Rai  Shino Jomoto, Rai  Billie Jonn, Rai  Heewoo Jun, Rai  Tomer Kaftan, Rai  Łukasz Kaiser, Rai  Ali Kamali, Rai  Ingmar Kanitscheider, Rai  Nitish Shirish Keskar, Rai  Tabarak Khan, Rai  Logan Kilpatrick, Rai  Jong Wook Kim, Rai  Christina Kim, Rai  Yongjik Kim, Rai  Hendrik Kirchner, Rai  Jamie Kiros, Rai  Matt Knight, Rai  Daniel Kokotajlo, Rai  Łukasz Kondraciuk, Rai  Andrew Kondrich, Rai  Aris Konstantinidis, Rai  Kyle Kosic, Rai  Gretchen Krueger, Rai  Vishal Kuo, Rai  Michael Lampe, Rai  Ikai Lan, Rai  Teddy Lee, Rai  Jan Leike, Rai  Jade Leung, Rai  Daniel Levy, Rai  Chak Ming Li, Rai  Rachel Lim, Rai  Molly Lin, Rai  Stephanie Lin, Rai  Mateusz Litwin, Rai  Theresa Lopez, Rai  Ryan Lowe, Rai  Patricia Lue, Rai  Anna Makanju, Rai  Kim Malfacini, Rai  Sam Manning, Rai  Todor Markov, Rai  Yaniv Markovski, Rai  Bianca Martin, Rai  Katie Mayer, Rai  Andrew Mayne, Rai  Bob McGrew, Rai  Scott Mayer McKinney, Rai  Christine McLeavey, Rai  Paul McMillan, Rai  Jake McNeil, Rai  David Medina, Rai  Aalok Mehta, Rai  Jacob Menick, Rai  Luke Metz, Rai  Andrey Mishchenko, Rai  Pamela Mishkin, Rai  Vinnie Monaco, Rai  Evan Morikawa, Rai  Daniel Mossing, Rai  Tong Mu, Rai  Mira Murati, Rai  Oleg Murk, Rai  David Mély, Rai  Ashvin Nair, Rai  Reiichiro Nakano, Rai  Rajeev Nayak, Rai  Arvind Neelakantan, Rai  Richard Ngo, Rai  Hyeonwoo Noh, Rai  Long Ouyang, Rai  Cullen O'Keefe, Rai  Jakub Pachocki, Rai  Alex Paino, Rai  Joe Palermo, Rai  Ashley Pantuliano, Rai  Giambattista Parascandolo, Rai  Joel Parish, Rai  Emy Parparita, Rai  Alex Passos, Rai  Mikhail Pavlov, Rai  Andrew Peng, Rai  Adam Perelman, Rai  Filipe de Avila Belbute Peres, Rai  Michael Petrov, Rai  Henrique Ponde de Oliveira Pinto, Rai   Michael,   Pokorny,  Michelle Pokrass,  Vitchyr Pong,  Tolly Powell,  Alethea Power,  Boris Power,  Elizabeth Proehl,  Raul Puri,  Alec Radford,  Jack Rae,  Aditya Ramesh,  Cameron Raymond,  Francis Real,  Kendra Rimbach,  Carl Ross,  Bob Rotsted,  Henri Roussez,  Nick Ryder,  Mario Saltarelli,  Ted Sanders,  Shibani Santurkar,  Girish Sastry,  Heather Schmidt,  David Schnurr,  John Schulman,  Daniel Selsam,  Kyla Sheppard,  Toki Sherbakov,  Jessica Shieh,  Sarah Shoker,  Pranav Shyam,  Szymon Sidor,  Eric Sigler,  Maddie Simens,  Jordan Sitkin,  Katarina Slama,  Ian Sohl,  Benjamin Sokolowsky,  Yang Song,  Natalie Staudacher,  Felipe Petroski Such,  Natalie Summers,  Ilya Sutskever,  Jie Tang,  Nikolas Tezak,  Madeleine Thompson,  Phil Tillet,  Amin Tootoonchian,  Elizabeth Tseng,  Preston Tuggle,  Nick Turley,  Jerry Tworek,  Juan Felipe Cerón Uribe,  Andrea Vallone,  Arun Vijayvergiya,  Chelsea Voss,  Carroll Wainwright,  Justin Jay Wang,  Alvin Wang,  Ben Wang,  Jonathan Ward,  Jason Wei,  CJ Weinmann,  Akila Welihinda,  Peter Welinder,  Jiayi Weng,  Lilian Weng,  Matt Wiethoff,  Dave Willner,  Clemens Winter,  Samuel Wolrich,  Hannah Wong,  Lauren Workman,  Sherwin Wu,  Jeff Wu,  Michael Wu,  Kai Xiao,  Tao Xu,  Sarah Yoo,  Kevin Yu,  Qiming Yuan,  Wojciech Zaremba,  Rowan Zellers,  Chong Zhang,  Marvin Zhang,  Shengjia Zhao,  Tianhao Zheng,  Juntang Zhuang,  William Zhuk,  Barret Zoph",
                "发布日期": "2023-12-20",
                "摘要": "  We report the development of GPT-4, a large-scale, multimodal model which can\naccept image and text inputs and produce text outputs. While less capable than\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance on\nvarious professional and academic benchmarks, including passing a simulated bar\nexam with a score around the top 10% of test takers. GPT-4 is a\nTransformer-based model pre-trained to predict the next token in a document.\nThe post-training alignment process results in improved performance on measures\nof factuality and adherence to desired behavior. A core component of this\nproject was developing infrastructure and optimization methods that behave\npredictably across a wide range of scales. This allowed us to accurately\npredict some aspects of GPT-4's performance based on models trained with no\nmore than 1/1,000th the compute of GPT-4.\n",
                "链接": "https://arxiv.org/abs/2303.08774"
            },
            {
                "文章ID": "81391",
                "标题": "DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of\n  GPT-Generated Text",
                "作者": " Xianjun Yang,  Wei Cheng,  Yue Wu,  Linda Petzold,  William Yang Wang,  Haifeng Chen",
                "发布日期": "2023-10-05",
                "摘要": "  Large language models (LLMs) have notably enhanced the fluency and diversity\nof machine-generated text. However, this progress also presents a significant\nchallenge in detecting the origin of a given text, and current research on\ndetection methods lags behind the rapid evolution of LLMs. Conventional\ntraining-based methods have limitations in flexibility, particularly when\nadapting to new domains, and they often lack explanatory power. To address this\ngap, we propose a novel training-free detection strategy called Divergent\nN-Gram Analysis (DNA-GPT). Given a text, we first truncate it in the middle and\nthen use only the preceding portion as input to the LLMs to regenerate the new\nremaining parts. By analyzing the differences between the original and new\nremaining parts through N-gram analysis in black-box or probability divergence\nin white-box, we unveil significant discrepancies between the distribution of\nmachine-generated text and the distribution of human-written text. We conducted\nextensive experiments on the most advanced LLMs from OpenAI, including\ntext-davinci-003, GPT-3.5-turbo, and GPT-4, as well as open-source models such\nas GPT-NeoX-20B and LLaMa-13B. Results show that our zero-shot approach\nexhibits state-of-the-art performance in distinguishing between human and\nGPT-generated text on four English and one German dataset, outperforming\nOpenAI's own classifier, which is trained on millions of text. Additionally,\nour methods provide reasonable explanations and evidence to support our claim,\nwhich is a unique feature of explainable detection. Our method is also robust\nunder the revised text attack and can additionally solve model sourcing. Codes\nare available at https://github.com/Xianjun-Yang/DNA-GPT.\n",
                "链接": "https://arxiv.org/abs/2305.17359"
            },
            {
                "文章ID": "105003",
                "标题": "GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven\n  Robotic Lab",
                "作者": " Xiaokai Qin,  Mingda Song,  Yangguan Chen,  Zhehong Ai,  Jing Jiang",
                "发布日期": "2023-10-02",
                "摘要": "  The integration of robots in chemical experiments has enhanced experimental\nefficiency, but lacking the human intelligence to comprehend literature, they\nseldom provide assistance in experimental design. Therefore, achieving\nfull-process autonomy from experiment design to validation in self-driven\nlaboratories (SDL) remains a challenge. The introduction of Generative\nPre-trained Transformers (GPT), particularly GPT-4, into robotic\nexperimentation offers a solution. We introduce GPT-Lab, a paradigm that\nemploys GPT models to give robots human-like intelligence. With our robotic\nexperimentation platform, GPT-Lab mines literature for materials and methods\nand validates findings through high-throughput synthesis. As a demonstration,\nGPT-Lab analyzed 500 articles, identified 18 potential reagents, and\nsuccessfully produced an accurate humidity colorimetric sensor with a root mean\nsquare error (RMSE) of 2.68%. This showcases the rapid materials discovery and\nvalidation potential of our system.\n",
                "链接": "https://arxiv.org/abs/2309.16721"
            },
            {
                "文章ID": "81941",
                "标题": "Controllable Text-to-Image Generation with GPT-4",
                "作者": " Tianjun Zhang,  Yi Zhang,  Vibhav Vineet,  Neel Joshi,  Xin Wang",
                "发布日期": "2023-05-31",
                "摘要": "  Current text-to-image generation models often struggle to follow textual\ninstructions, especially the ones requiring spatial reasoning. On the other\nhand, Large Language Models (LLMs), such as GPT-4, have shown remarkable\nprecision in generating code snippets for sketching out text inputs\ngraphically, e.g., via TikZ. In this work, we introduce Control-GPT to guide\nthe diffusion-based text-to-image pipelines with programmatic sketches\ngenerated by GPT-4, enhancing their abilities for instruction following.\nControl-GPT works by querying GPT-4 to write TikZ code, and the generated\nsketches are used as references alongside the text instructions for diffusion\nmodels (e.g., ControlNet) to generate photo-realistic images. One major\nchallenge to training our pipeline is the lack of a dataset containing aligned\ntext, images, and sketches. We address the issue by converting instance masks\nin existing datasets into polygons to mimic the sketches used at test time. As\na result, Control-GPT greatly boosts the controllability of image generation.\nIt establishes a new state-of-art on the spatial arrangement and object\npositioning generation and enhances users' control of object positions, sizes,\netc., nearly doubling the accuracy of prior models. Our work, as a first\nattempt, shows the potential for employing LLMs to enhance the performance in\ncomputer vision tasks.\n",
                "链接": "https://arxiv.org/abs/2305.18583"
            },
            {
                "文章ID": "100040",
                "标题": "AutoML-GPT: Large Language Model for AutoML",
                "作者": " Yun-Da Tsai,  Yu-Che Tsai,  Bo-Wei Huang,  Chun-Pai Yang,  Shou-De Lin",
                "发布日期": "2023-09-06",
                "摘要": "  With the emerging trend of GPT models, we have established a framework called\nAutoML-GPT that integrates a comprehensive set of tools and libraries. This\nframework grants users access to a wide range of data preprocessing techniques,\nfeature engineering methods, and model selection algorithms. Through a\nconversational interface, users can specify their requirements, constraints,\nand evaluation metrics. Throughout the process, AutoML-GPT employs advanced\ntechniques for hyperparameter optimization and model selection, ensuring that\nthe resulting model achieves optimal performance. The system effectively\nmanages the complexity of the machine learning pipeline, guiding users towards\nthe best choices without requiring deep domain knowledge. Through our\nexperimental results on diverse datasets, we have demonstrated that AutoML-GPT\nsignificantly reduces the time and effort required for machine learning tasks.\nIts ability to leverage the vast knowledge encoded in large language models\nenables it to provide valuable insights, identify potential pitfalls, and\nsuggest effective solutions to common challenges faced during model training.\n",
                "链接": "https://arxiv.org/abs/2309.01125"
            },
            {
                "文章ID": "75650",
                "标题": "AutoML-GPT: Automatic Machine Learning with GPT",
                "作者": " Shujian Zhang,  Chengyue Gong,  Lemeng Wu,  Xingchao Liu,  Mingyuan Zhou",
                "发布日期": "2023-05-05",
                "摘要": "  AI tasks encompass a wide range of domains and fields. While numerous AI\nmodels have been designed for specific tasks and applications, they often\nrequire considerable human efforts in finding the right model architecture,\noptimization algorithm, and hyperparameters. Recent advances in large language\nmodels (LLMs) like ChatGPT show remarkable capabilities in various aspects of\nreasoning, comprehension, and interaction. Consequently, we propose developing\ntask-oriented prompts and automatically utilizing LLMs to automate the training\npipeline. To implement this concept, we present the AutoML-GPT, which employs\nGPT as the bridge to diverse AI models and dynamically trains models with\noptimized hyperparameters. AutoML-GPT dynamically takes user requests from the\nmodel and data cards and composes the corresponding prompt paragraph.\nUltimately, with this prompt paragraph, AutoML-GPT will automatically conduct\nthe experiments from data processing to model architecture, hyperparameter\ntuning, and predicted training log. By leveraging {\\ours}'s robust language\ncapabilities and the available AI models, AutoML-GPT can tackle numerous\nintricate AI tasks across various tasks and datasets. This approach achieves\nremarkable results in computer vision, natural language processing, and other\nchallenging areas. Extensive experiments and ablation studies demonstrate that\nour method can be general, effective, and beneficial for many AI tasks.\n",
                "链接": "https://arxiv.org/abs/2305.02499"
            },
            {
                "文章ID": "116515",
                "标题": "Enhancing Machine Translation through Advanced In-Context Learning: A\n  Methodological Strategy for GPT-4 Improvement",
                "作者": " Yufeng Chen",
                "发布日期": "2023-11-21",
                "摘要": "  The challenge of improving translation accuracy in GPT-4 is being addressed\nby harnessing a method known as in-context learning. This paper introduces a\nstrategic approach to utilize in-context learning specifically for machine\ntranslation, aiming to significantly boost accuracy. The crux of this method\nlies in the judicious selection of demonstrations that are most effective for\nin-context learning. By selecting these examples carefully, GPT-4 can utilize\nthem to achieve remarkably accurate machine translations, eliminating the need\nfor task-specific fine-tuning. This technique is anchored in the semantic\nsimilarities between the user's prompt and the chosen dataset. Sentences from\nthis dataset, carefully picked for their relevance and clarity, serve as potent\ndemonstrations for in-context learning. This approach not only enhances\ntranslation accuracy but also enriches the understanding of nuanced linguistic\nstructures. It represents a significant step forward in machine learning,\nleveraging the inherent capabilities of GPT-4 to provide translations that are\nnot only accurate but also contextually rich and linguistically sophisticated.\nThis method demonstrates the potential of in-context learning in overcoming\nlanguage barriers, opening new avenues for cross-cultural communication and\nglobal collaboration.\n",
                "链接": "https://arxiv.org/abs/2311.10765"
            }
        ]
    },
    {
        "question": {
            "question": "请找到利用clip做开放词汇检测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "105778",
                "标题": "CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense\n  Prediction",
                "作者": " Size Wu,  Wenwei Zhang,  Lumin Xu,  Sheng Jin,  Xiangtai Li,  Wentao Liu,  Chen Change Loy",
                "发布日期": "2023-10-03",
                "摘要": "  Open-vocabulary dense prediction tasks including object detection and image\nsegmentation have been advanced by the success of Contrastive Language-Image\nPre-training (CLIP). CLIP models, particularly those incorporating vision\ntransformers (ViTs), have exhibited remarkable generalization ability in\nzero-shot image classification. However, when transferring the vision-language\nalignment of CLIP from global image representation to local region\nrepresentation for the open-vocabulary dense prediction tasks, CLIP ViTs suffer\nfrom the domain shift from full images to local image regions. In this paper,\nwe embark on an in-depth analysis of the region-language alignment in CLIP\nmodels, which is essential for downstream open-vocabulary dense prediction\ntasks. Subsequently, we propose an approach named CLIPSelf, which adapts the\nimage-level recognition ability of CLIP ViT to local image regions without\nneeding any region-text pairs. CLIPSelf empowers ViTs to distill itself by\naligning a region representation extracted from its dense feature map with the\nimage-level representation of the corresponding image crop. With the enhanced\nCLIP ViTs, we achieve new state-of-the-art performance on open-vocabulary\nobject detection, semantic segmentation, and panoptic segmentation across\nvarious benchmarks. Models and code will be available at\nhttps://github.com/wusize/CLIPSelf.\n",
                "链接": "https://arxiv.org/abs/2310.01403"
            },
            {
                "文章ID": "121784",
                "标题": "OpenSD: Unified Open-Vocabulary Segmentation and Detection",
                "作者": " Shuai Li,  Minghan Li,  Pengfei Wang,  Lei Zhang",
                "发布日期": "2023-12-13",
                "摘要": "  Recently, a few open-vocabulary methods have been proposed by employing a\nunified architecture to tackle generic segmentation and detection tasks.\nHowever, their performance still lags behind the task-specific models due to\nthe conflict between different tasks, and their open-vocabulary capability is\nlimited due to the inadequate use of CLIP. To address these challenges, we\npresent a universal transformer-based framework, abbreviated as OpenSD, which\nutilizes the same architecture and network parameters to handle open-vocabulary\nsegmentation and detection tasks. First, we introduce a decoder decoupled\nlearning strategy to alleviate the semantic conflict between thing and staff\ncategories so that each individual task can be learned more effectively under\nthe same framework. Second, to better leverage CLIP for end-to-end segmentation\nand detection, we propose dual classifiers to handle the in-vocabulary domain\nand out-of-vocabulary domain, respectively. The text encoder is further trained\nto be region-aware for both thing and stuff categories through decoupled prompt\nlearning, enabling them to filter out duplicated and low-quality predictions,\nwhich is important to end-to-end segmentation and detection. Extensive\nexperiments are conducted on multiple datasets under various circumstances. The\nresults demonstrate that OpenSD outperforms state-of-the-art open-vocabulary\nsegmentation and detection methods in both closed- and open-vocabulary\nsettings. Code is available at https://github.com/strongwolf/OpenSD\n",
                "链接": "https://arxiv.org/abs/2312.06703"
            },
            {
                "文章ID": "124461",
                "标题": "FM-OV3D: Foundation Model-based Cross-modal Knowledge Blending for\n  Open-Vocabulary 3D Detection",
                "作者": " Dongmei Zhang,  Chang Li,  Ray Zhang,  Shenghao Xie,  Wei Xue,  Xiaodong Xie,  Shanghang Zhang",
                "发布日期": "2023-12-25",
                "摘要": "  The superior performances of pre-trained foundation models in various visual\ntasks underscore their potential to enhance the 2D models' open-vocabulary\nability. Existing methods explore analogous applications in the 3D space.\nHowever, most of them only center around knowledge extraction from singular\nfoundation models, which limits the open-vocabulary ability of 3D models. We\nhypothesize that leveraging complementary pre-trained knowledge from various\nfoundation models can improve knowledge transfer from 2D pre-trained visual\nlanguage models to the 3D space. In this work, we propose FM-OV3D, a method of\nFoundation Model-based Cross-modal Knowledge Blending for Open-Vocabulary 3D\nDetection, which improves the open-vocabulary localization and recognition\nabilities of 3D model by blending knowledge from multiple pre-trained\nfoundation models, achieving true open-vocabulary without facing constraints\nfrom original 3D datasets. Specifically, to learn the open-vocabulary 3D\nlocalization ability, we adopt the open-vocabulary localization knowledge of\nthe Grounded-Segment-Anything model. For open-vocabulary 3D recognition\nability, We leverage the knowledge of generative foundation models, including\nGPT-3 and Stable Diffusion models, and cross-modal discriminative models like\nCLIP. The experimental results on two popular benchmarks for open-vocabulary 3D\nobject detection show that our model efficiently learns knowledge from multiple\nfoundation models to enhance the open-vocabulary ability of the 3D model and\nsuccessfully achieves state-of-the-art performance in open-vocabulary 3D object\ndetection tasks. Code is released at\nhttps://github.com/dmzhang0425/FM-OV3D.git.\n",
                "链接": "https://arxiv.org/abs/2312.14465"
            },
            {
                "文章ID": "68854",
                "标题": "Prompt-Guided Transformers for End-to-End Open-Vocabulary Object\n  Detection",
                "作者": " Hwanjun Song,  Jihwan Bang",
                "发布日期": "2023-03-28",
                "摘要": "  Prompt-OVD is an efficient and effective framework for open-vocabulary object\ndetection that utilizes class embeddings from CLIP as prompts, guiding the\nTransformer decoder to detect objects in both base and novel classes.\nAdditionally, our novel RoI-based masked attention and RoI pruning techniques\nhelp leverage the zero-shot classification ability of the Vision\nTransformer-based CLIP, resulting in improved detection performance at minimal\ncomputational cost. Our experiments on the OV-COCO and OVLVIS datasets\ndemonstrate that Prompt-OVD achieves an impressive 21.2 times faster inference\nspeed than the first end-to-end open-vocabulary detection method (OV-DETR),\nwhile also achieving higher APs than four two-stage-based methods operating\nwithin similar inference time ranges. Code will be made available soon.\n",
                "链接": "https://arxiv.org/abs/2303.14386"
            },
            {
                "文章ID": "110181",
                "标题": "SILC: Improving Vision Language Pretraining with Self-Distillation",
                "作者": " Muhammad Ferjad Naeem,  Yongqin Xian,  Xiaohua Zhai,  Lukas Hoyer,  Luc Van Gool,  Federico Tombari",
                "发布日期": "2023-12-08",
                "摘要": "  Image-Text pretraining on web-scale image caption datasets has become the\ndefault recipe for open vocabulary classification and retrieval models thanks\nto the success of CLIP and its variants. Several works have also used CLIP\nfeatures for dense prediction tasks and have shown the emergence of open-set\nabilities. However, the contrastive objective used by these models only focuses\non image-text alignment and does not incentivise image feature learning for\ndense prediction tasks. In this work, we introduce SILC, a novel framework for\nvision language pretraining. SILC improves image-text contrastive learning with\nthe simple addition of local-to-global correspondence learning by\nself-distillation. We show that distilling local image features from an\nexponential moving average (EMA) teacher model significantly improves model\nperformance on dense predictions tasks like detection and segmentation, while\nalso providing improvements on image-level tasks such as classification and\nretrieval. SILC models sets a new state of the art for zero-shot\nclassification, few shot classification, image and text retrieval, zero-shot\nsegmentation, and open vocabulary segmentation. We further show that SILC\nfeatures greatly benefit open vocabulary detection, captioning and visual\nquestion answering.\n",
                "链接": "https://arxiv.org/abs/2310.13355"
            },
            {
                "文章ID": "22912",
                "标题": "Delving into the Openness of CLIP",
                "作者": " Shuhuai Ren,  Lei Li,  Xuancheng Ren,  Guangxiang Zhao,  Xu Sun",
                "发布日期": "2023-05-09",
                "摘要": "  Contrastive Language-Image Pre-training (CLIP) formulates image\nclassification as an image-to-text matching task, i.e., matching images to the\ncorresponding natural language descriptions instead of discrete category IDs.\nThis allows for open-vocabulary visual recognition, where the model can\nrecognize images from an open class set (also known as an open vocabulary) in a\nzero-shot manner. However, evaluating the openness of CLIP-like models is\nchallenging, as the models are open to arbitrary vocabulary in theory, but\ntheir accuracy varies in practice. To address this, we resort to an incremental\nperspective to assess the openness through vocabulary expansions, and define\nextensibility to measure a model's ability to handle novel classes. Our\nevaluation shows that CLIP-like models are not truly open, and their\nperformance deteriorates as the vocabulary expands. We further dissect the\nfeature space of CLIP from the perspectives of representation alignment and\nuniformity. Our investigation reveals that the overestimation of openness is\ndue to confusion among competing text features, rather than a failure to\ncapture the similarity between image features and text features of novel\nclasses. We hope that our investigation and analysis will facilitate future\nresearch on the CLIP openness issue.\n",
                "链接": "https://arxiv.org/abs/2206.01986"
            },
            {
                "文章ID": "94707",
                "标题": "Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen\n  Convolutional CLIP",
                "作者": " Qihang Yu,  Ju He,  Xueqing Deng,  Xiaohui Shen,  Liang-Chieh Chen",
                "发布日期": "2023-11-16",
                "摘要": "  Open-vocabulary segmentation is a challenging task requiring segmenting and\nrecognizing objects from an open set of categories. One way to address this\nchallenge is to leverage multi-modal models, such as CLIP, to provide image and\ntext features in a shared embedding space, which bridges the gap between\nclosed-vocabulary and open-vocabulary recognition. Hence, existing methods\noften adopt a two-stage framework to tackle the problem, where the inputs first\ngo through a mask generator and then through the CLIP model along with the\npredicted masks. This process involves extracting features from images multiple\ntimes, which can be ineffective and inefficient. By contrast, we propose to\nbuild everything into a single-stage framework using a shared Frozen\nConvolutional CLIP backbone, which not only significantly simplifies the\ncurrent two-stage pipeline, but also remarkably yields a better accuracy-cost\ntrade-off. The proposed FC-CLIP, benefits from the following observations: the\nfrozen CLIP backbone maintains the ability of open-vocabulary classification\nand can also serve as a strong mask generator, and the convolutional CLIP\ngeneralizes well to a larger input resolution than the one used during\ncontrastive image-text pretraining. When training on COCO panoptic data only\nand testing in a zero-shot manner, FC-CLIP achieve 26.8 PQ, 16.8 AP, and 34.1\nmIoU on ADE20K, 18.2 PQ, 27.9 mIoU on Mapillary Vistas, 44.0 PQ, 26.8 AP, 56.2\nmIoU on Cityscapes, outperforming the prior art by +4.2 PQ, +2.4 AP, +4.2 mIoU\non ADE20K, +4.0 PQ on Mapillary Vistas and +20.1 PQ on Cityscapes,\nrespectively. Additionally, the training and testing time of FC-CLIP is 7.5x\nand 6.6x significantly faster than the same prior art, while using 5.9x fewer\nparameters. FC-CLIP also sets a new state-of-the-art performance across various\nopen-vocabulary semantic segmentation datasets. Code at\nhttps://github.com/bytedance/fc-clip\n",
                "链接": "https://arxiv.org/abs/2308.02487"
            },
            {
                "文章ID": "28246",
                "标题": "Bridging the Gap between Object and Image-level Representations for\n  Open-Vocabulary Detection",
                "作者": " Hanoona Rasheed,  Muhammad Maaz,  Muhammad Uzair Khattak,  Salman Khan,  Fahad Shahbaz Khan",
                "发布日期": "2022-11-30",
                "摘要": "  Existing open-vocabulary object detectors typically enlarge their vocabulary\nsizes by leveraging different forms of weak supervision. This helps generalize\nto novel objects at inference. Two popular forms of weak-supervision used in\nopen-vocabulary detection (OVD) include pretrained CLIP model and image-level\nsupervision. We note that both these modes of supervision are not optimally\naligned for the detection task: CLIP is trained with image-text pairs and lacks\nprecise localization of objects while the image-level supervision has been used\nwith heuristics that do not accurately specify local object regions. In this\nwork, we propose to address this problem by performing object-centric alignment\nof the language embeddings from the CLIP model. Furthermore, we visually ground\nthe objects with only image-level supervision using a pseudo-labeling process\nthat provides high-quality object proposals and helps expand the vocabulary\nduring training. We establish a bridge between the above two object-alignment\nstrategies via a novel weight transfer function that aggregates their\ncomplimentary strengths. In essence, the proposed model seeks to minimize the\ngap between object and image-centric representations in the OVD setting. On the\nCOCO benchmark, our proposed approach achieves 36.6 AP50 on novel classes, an\nabsolute 8.2 gain over the previous best performance. For LVIS, we surpass the\nstate-of-the-art ViLD model by 5.0 mask AP for rare categories and 3.4 overall.\nCode: https://github.com/hanoonaR/object-centric-ovd.\n",
                "链接": "https://arxiv.org/abs/2207.03482"
            },
            {
                "文章ID": "120843",
                "标题": "Open-Vocabulary Segmentation with Semantic-Assisted Calibration",
                "作者": " Yong Liu,  Sule Bai,  Guanbin Li,  Yitong Wang,  Yansong Tang",
                "发布日期": "2023-12-08",
                "摘要": "  This paper studies open-vocabulary segmentation (OVS) through calibrating\nin-vocabulary and domain-biased embedding space with generalized contextual\nprior of CLIP. As the core of open-vocabulary understanding, alignment of\nvisual content with the semantics of unbounded text has become the bottleneck\nof this field. To address this challenge, recent works propose to utilize CLIP\nas an additional classifier and aggregate model predictions with CLIP\nclassification results. Despite their remarkable progress, performance of OVS\nmethods in relevant scenarios is still unsatisfactory compared with supervised\ncounterparts. We attribute this to the in-vocabulary embedding and\ndomain-biased CLIP prediction. To this end, we present a Semantic-assisted\nCAlibration Network (SCAN). In SCAN, we incorporate generalized semantic prior\nof CLIP into proposal embedding to avoid collapsing on known categories.\nBesides, a contextual shift strategy is applied to mitigate the lack of global\ncontext and unnatural background noise. With above designs, SCAN achieves\nstate-of-the-art performance on all popular open-vocabulary segmentation\nbenchmarks. Furthermore, we also focus on the problem of existing evaluation\nsystem that ignores semantic duplication across categories, and propose a new\nmetric called Semantic-Guided IoU (SG-IoU).\n",
                "链接": "https://arxiv.org/abs/2312.04089"
            },
            {
                "文章ID": "116861",
                "标题": "CastDet: Toward Open Vocabulary Aerial Object Detection with\n  CLIP-Activated Student-Teacher Learning",
                "作者": " Yan Li,  Weiwei Guo,  Dunyun He,  Jiaqi Zhou,  Yuze Gao,  Wenxian Yu",
                "发布日期": "2023-11-21",
                "摘要": "  Object detection in aerial images is a pivotal task for various earth\nobservation applications, whereas current algorithms learn to detect only a\npre-defined set of object categories demanding sufficient bounding-box\nannotated training samples and fail to detect novel object categories. In this\npaper, we consider open-vocabulary object detection (OVD) in aerial images that\nenables the characterization of new objects beyond training categories on the\nearth surface without annotating training images for these new categories. The\nperformance of OVD depends on the quality of class-agnostic region proposals\nand pseudo-labels that can generalize well to novel object categories. To\nsimultaneously generate high-quality proposals and pseudo-labels, we propose\nCastDet, a CLIP-activated student-teacher open-vocabulary object Detection\nframework. Our end-to-end framework within the student-teacher mechanism\nemploys the CLIP model as an extra omniscient teacher of rich knowledge into\nthe student-teacher self-learning process. By doing so, our approach boosts\nnovel object proposals and classification. Furthermore, we design a dynamic\nlabel queue technique to maintain high-quality pseudo labels during batch\ntraining and mitigate label imbalance. We conduct extensive experiments on\nmultiple existing aerial object detection datasets, which are set up for the\nOVD task. Experimental results demonstrate our CastDet achieving superior\nopen-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean),\nwhich outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD\ndataset.\n",
                "链接": "https://arxiv.org/abs/2311.11646"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用CrossWoz或MultiWoz数据集进行DST评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "43163",
                "标题": "Mars: Modeling Context & State Representations with Contrastive Learning\n  for End-to-End Task-Oriented Dialog",
                "作者": " Haipeng Sun,  Junwei Bao,  Youzheng Wu,  Xiaodong He",
                "发布日期": "2023-07-11",
                "摘要": "  Traditional end-to-end task-oriented dialog systems first convert dialog\ncontext into belief state and action state before generating the system\nresponse. The system response performance is significantly affected by the\nquality of the belief state and action state. We first explore what dialog\ncontext representation is beneficial to improving the quality of the belief\nstate and action state, which further enhances the generated response quality.\nTo tackle our exploration, we propose Mars, an end-to-end task-oriented dialog\nsystem with two contrastive learning strategies to model the relationship\nbetween dialog context and belief/action state representations. Empirical\nresults show dialog context representations, which are more different from\nsemantic state representations, are more conducive to multi-turn task-oriented\ndialog. Moreover, our proposed Mars achieves state-of-the-art performance on\nthe MultiWOZ 2.0, CamRest676, and CrossWOZ.\n",
                "链接": "https://arxiv.org/abs/2210.08917"
            },
            {
                "文章ID": "46848",
                "标题": "MultiWOZ-DF -- A Dataflow implementation of the MultiWOZ dataset",
                "作者": " Joram Meron,  Victor Guimarães",
                "发布日期": "2022-11-07",
                "摘要": "  Semantic Machines (SM) have introduced the use of the dataflow (DF) paradigm\nto dialogue modelling, using computational graphs to hierarchically represent\nuser requests, data, and the dialogue history [Semantic Machines et al. 2020].\nAlthough the main focus of that paper was the SMCalFlow dataset (to date, the\nonly dataset with \"native\" DF annotations), they also reported some results of\nan experiment using a transformed version of the commonly used MultiWOZ dataset\n[Budzianowski et al. 2018] into a DF format. In this paper, we expand the\nexperiments using DF for the MultiWOZ dataset, exploring some additional\nexperimental set-ups. The code and instructions to reproduce the experiments\nreported here have been released. The contributions of this paper are: 1.) A DF\nimplementation capable of executing MultiWOZ dialogues; 2.) Several versions of\nconversion of MultiWOZ into a DF format are presented; 3.) Experimental results\non state match and translation accuracy.\n",
                "链接": "https://arxiv.org/abs/2211.02303"
            },
            {
                "文章ID": "7222",
                "标题": "ASSIST: Towards Label Noise-Robust Dialogue State Tracking",
                "作者": " Fanghua Ye,  Yue Feng,  Emine Yilmaz",
                "发布日期": "2022-03-15",
                "摘要": "  The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state\ntracking (DST). However, substantial noise has been discovered in its state\nannotations. Such noise brings about huge challenges for training DST models\nrobustly. Although several refined versions, including MultiWOZ 2.1-2.4, have\nbeen published recently, there are still lots of noisy labels, especially in\nthe training set. Besides, it is costly to rectify all the problematic\nannotations. In this paper, instead of improving the annotation quality\nfurther, we propose a general framework, named ASSIST (lAbel noiSe-robuSt\ndIalogue State Tracking), to train DST models robustly from noisy labels.\nASSIST first generates pseudo labels for each sample in the training set by\nusing an auxiliary model trained on a small clean dataset, then puts the\ngenerated pseudo labels and vanilla noisy labels together to train the primary\nmodel. We show the validity of ASSIST theoretically. Experimental results also\ndemonstrate that ASSIST improves the joint goal accuracy of DST by up to\n$28.16\\%$ on MultiWOZ 2.0 and $8.41\\%$ on MultiWOZ 2.4, compared to using only\nthe vanilla noisy labels.\n",
                "链接": "https://arxiv.org/abs/2202.13024"
            },
            {
                "文章ID": "17975",
                "标题": "LUNA: Learning Slot-Turn Alignment for Dialogue State Tracking",
                "作者": " Yifan Wang,  Jing Zhao,  Junwei Bao,  Chaoqun Duan,  Youzheng Wu,  Xiaodong He",
                "发布日期": "2022-05-06",
                "摘要": "  Dialogue state tracking (DST) aims to predict the current dialogue state\ngiven the dialogue history. Existing methods generally exploit the utterances\nof all dialogue turns to assign value for each slot. This could lead to\nsuboptimal results due to the information introduced from irrelevant utterances\nin the dialogue history, which may be useless and can even cause confusion. To\naddress this problem, we propose LUNA, a sLot-tUrN Alignment enhanced approach.\nIt first explicitly aligns each slot with its most relevant utterance, then\nfurther predicts the corresponding value based on this aligned utterance\ninstead of all dialogue utterances. Furthermore, we design a slot ranking\nauxiliary task to learn the temporal correlation among slots which could\nfacilitate the alignment. Comprehensive experiments are conducted on\nmulti-domain task-oriented dialogue datasets, i.e., MultiWOZ 2.0, MultiWOZ 2.1,\nand MultiWOZ 2.2. The results show that LUNA achieves new state-of-the-art\nresults on these datasets.\n",
                "链接": "https://arxiv.org/abs/2205.02550"
            },
            {
                "文章ID": "112862",
                "标题": "Multi-User MultiWOZ: Task-Oriented Dialogues among Multiple Users",
                "作者": " Yohan Jo,  Xinyan Zhao,  Arijit Biswas,  Nikoletta Basiou,  Vincent Auvray,  Nikolaos Malandrakis,  Angeliki Metallinou,  Alexandros Potamianos",
                "发布日期": "2023-11-01",
                "摘要": "  While most task-oriented dialogues assume conversations between the agent and\none user at a time, dialogue systems are increasingly expected to communicate\nwith multiple users simultaneously who make decisions collaboratively. To\nfacilitate development of such systems, we release the Multi-User MultiWOZ\ndataset: task-oriented dialogues among two users and one agent. To collect this\ndataset, each user utterance from MultiWOZ 2.2 was replaced with a small chat\nbetween two users that is semantically and pragmatically consistent with the\noriginal user utterance, thus resulting in the same dialogue state and system\nresponse. These dialogues reflect interesting dynamics of collaborative\ndecision-making in task-oriented scenarios, e.g., social chatter and\ndeliberation. Supported by this data, we propose the novel task of multi-user\ncontextual query rewriting: to rewrite a task-oriented chat between two users\nas a concise task-oriented query that retains only task-relevant information\nand that is directly consumable by the dialogue system. We demonstrate that in\nmulti-user dialogues, using predicted rewrites substantially improves dialogue\nstate tracking without modifying existing dialogue systems that are trained for\nsingle-user dialogues. Further, this method surpasses training a medium-sized\nmodel directly on multi-user dialogues and generalizes to unseen domains.\n",
                "链接": "https://arxiv.org/abs/2310.20479"
            },
            {
                "文章ID": "20132",
                "标题": "Beyond the Granularity: Multi-Perspective Dialogue Collaborative\n  Selection for Dialogue State Tracking",
                "作者": " Jinyu Guo,  Kai Shuang,  Jijie Li,  Zihan Wang,  Yixuan Liu",
                "发布日期": "2022-05-23",
                "摘要": "  In dialogue state tracking, dialogue history is a crucial material, and its\nutilization varies between different models. However, no matter how the\ndialogue history is used, each existing model uses its own consistent dialogue\nhistory during the entire state tracking process, regardless of which slot is\nupdated. Apparently, it requires different dialogue history to update different\nslots in different turns. Therefore, using consistent dialogue contents may\nlead to insufficient or redundant information for different slots, which\naffects the overall performance. To address this problem, we devise DiCoS-DST\nto dynamically select the relevant dialogue contents corresponding to each slot\nfor state updating. Specifically, it first retrieves turn-level utterances of\ndialogue history and evaluates their relevance to the slot from a combination\nof three perspectives: (1) its explicit connection to the slot name; (2) its\nrelevance to the current turn dialogue; (3) Implicit Mention Oriented\nReasoning. Then these perspectives are combined to yield a decision, and only\nthe selected dialogue contents are fed into State Generator, which explicitly\nminimizes the distracting information passed to the downstream state\nprediction. Experimental results show that our approach achieves new\nstate-of-the-art performance on MultiWOZ 2.1 and MultiWOZ 2.2, and achieves\nsuperior performance on multiple mainstream benchmark datasets (including\nSim-M, Sim-R, and DSTC2).\n",
                "链接": "https://arxiv.org/abs/2205.10059"
            },
            {
                "文章ID": "90756",
                "标题": "Agreement Tracking for Multi-Issue Negotiation Dialogues",
                "作者": " Amogh Mannekote,  Bonnie J. Dorr,  Kristy Elizabeth Boyer",
                "发布日期": "2023-07-14",
                "摘要": "  Automated negotiation support systems aim to help human negotiators reach\nmore favorable outcomes in multi-issue negotiations (e.g., an employer and a\ncandidate negotiating over issues such as salary, hours, and promotions before\na job offer). To be successful, these systems must accurately track agreements\nreached by participants in real-time. Existing approaches either focus on\ntask-oriented dialogues or produce unstructured outputs, rendering them\nunsuitable for this objective. Our work introduces the novel task of agreement\ntracking for two-party multi-issue negotiations, which requires continuous\nmonitoring of agreements within a structured state space. To address the\nscarcity of annotated corpora with realistic multi-issue negotiation dialogues,\nwe use GPT-3 to build GPT-Negochat, a synthesized dataset that we make publicly\navailable. We present a strong initial baseline for our task by\ntransfer-learning a T5 model trained on the MultiWOZ 2.4 corpus. Pre-training\nT5-small and T5-base on MultiWOZ 2.4's DST task enhances results by 21% and 9%\nrespectively over training solely on GPT-Negochat. We validate our method's\nsample-efficiency via smaller training subset experiments. By releasing\nGPT-Negochat and our baseline models, we aim to encourage further research in\nmulti-issue negotiation dialogue agreement tracking.\n",
                "链接": "https://arxiv.org/abs/2307.06524"
            },
            {
                "文章ID": "79647",
                "标题": "Using Textual Interface to Align External Knowledge for End-to-End\n  Task-Oriented Dialogue Systems",
                "作者": " Qingyang Wu,  Deema Alnuhait,  Derek Chen,  Zhou Yu",
                "发布日期": "2023-05-24",
                "摘要": "  Traditional end-to-end task-oriented dialogue systems have been built with a\nmodularized design. However, such design often causes misalignment between the\nagent response and external knowledge, due to inadequate representation of\ninformation. Furthermore, its evaluation metrics emphasize assessing the\nagent's pre-lexicalization response, neglecting the quality of the completed\nresponse. In this work, we propose a novel paradigm that uses a textual\ninterface to align external knowledge and eliminate redundant processes. We\ndemonstrate our paradigm in practice through MultiWOZ-Remake, including an\ninteractive textual interface built for the MultiWOZ database and a\ncorrespondingly re-processed dataset. We train an end-to-end dialogue system to\nevaluate this new dataset. The experimental results show that our approach\ngenerates more natural final responses and achieves a greater task success rate\ncompared to the previous models.\n",
                "链接": "https://arxiv.org/abs/2305.13710"
            },
            {
                "文章ID": "68448",
                "标题": "Reevaluating Data Partitioning for Emotion Detection in EmoWOZ",
                "作者": " Moeen Mostafavi,  Michael D. Porter",
                "发布日期": "2023-03-24",
                "摘要": "  This paper focuses on the EmoWoz dataset, an extension of MultiWOZ that\nprovides emotion labels for the dialogues. MultiWOZ was partitioned initially\nfor another purpose, resulting in a distributional shift when considering the\nnew purpose of emotion recognition. The emotion tags in EmoWoz are highly\nimbalanced and unevenly distributed across the partitions, which causes\nsub-optimal performance and poor comparison of models. We propose a stratified\nsampling scheme based on emotion tags to address this issue, improve the\ndataset's distribution, and reduce dataset shift. We also introduce a special\ntechnique to handle conversation (sequential) data with many emotional tags.\nUsing our proposed sampling method, models built upon EmoWoz can perform\nbetter, making it a more reliable resource for training conversational agents\nwith emotional intelligence. We recommend that future researchers use this new\npartitioning to ensure consistent and accurate performance evaluations.\n",
                "链接": "https://arxiv.org/abs/2303.13364"
            },
            {
                "文章ID": "61900",
                "标题": "Dialogue State Distillation Network with Inter-slot Contrastive Learning\n  for Dialogue State Tracking",
                "作者": " Jing Xu,  Dandan Song,  Chong Liu,  Siu Cheung Hui,  Fei Li,  Qiang Ju,  Xiaonan He,  Jian Xie",
                "发布日期": "2023-03-08",
                "摘要": "  In task-oriented dialogue systems, Dialogue State Tracking (DST) aims to\nextract users' intentions from the dialogue history. Currently, most existing\napproaches suffer from error propagation and are unable to dynamically select\nrelevant information when utilizing previous dialogue states. Moreover, the\nrelations between the updates of different slots provide vital clues for DST.\nHowever, the existing approaches rely only on predefined graphs to indirectly\ncapture the relations. In this paper, we propose a Dialogue State Distillation\nNetwork (DSDN) to utilize relevant information of previous dialogue states and\nmigrate the gap of utilization between training and testing. Thus, it can\ndynamically exploit previous dialogue states and avoid introducing error\npropagation simultaneously. Further, we propose an inter-slot contrastive\nlearning loss to effectively capture the slot co-update relations from dialogue\ncontext. Experiments are conducted on the widely used MultiWOZ 2.0 and MultiWOZ\n2.1 datasets. The experimental results show that our proposed model achieves\nthe state-of-the-art performance for DST.\n",
                "链接": "https://arxiv.org/abs/2302.08220"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "强化学习在大语言模型领域中应用的相关论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "61474",
                "标题": "Guiding Pretraining in Reinforcement Learning with Large Language Models",
                "作者": " Yuqing Du,  Olivia Watkins,  Zihan Wang,  Cédric Colas,  Trevor Darrell,  Pieter Abbeel,  Abhishek Gupta,  Jacob Andreas",
                "发布日期": "2023-09-18",
                "摘要": "  Reinforcement learning algorithms typically struggle in the absence of a\ndense, well-shaped reward function. Intrinsically motivated exploration methods\naddress this limitation by rewarding agents for visiting novel states or\ntransitions, but these methods offer limited benefits in large environments\nwhere most discovered novelty is irrelevant for downstream tasks. We describe a\nmethod that uses background knowledge from text corpora to shape exploration.\nThis method, called ELLM (Exploring with LLMs) rewards an agent for achieving\ngoals suggested by a language model prompted with a description of the agent's\ncurrent state. By leveraging large-scale language model pretraining, ELLM\nguides agents toward human-meaningful and plausibly useful behaviors without\nrequiring a human in the loop. We evaluate ELLM in the Crafter game environment\nand the Housekeep robotic simulator, showing that ELLM-trained agents have\nbetter coverage of common-sense behaviors during pretraining and usually match\nor improve performance on a range of downstream tasks. Code available at\nhttps://github.com/yuqingd/ellm.\n",
                "链接": "https://arxiv.org/abs/2302.06692"
            },
            {
                "文章ID": "4689",
                "标题": "Exploring the Limits of Domain-Adaptive Training for Detoxifying\n  Large-Scale Language Models",
                "作者": " Boxin Wang,  Wei Ping,  Chaowei Xiao,  Peng Xu,  Mostofa Patwary,  Mohammad Shoeybi,  Bo Li,  Anima Anandkumar,  Bryan Catanzaro",
                "发布日期": "2022-10-25",
                "摘要": "  Pre-trained language models (LMs) are shown to easily generate toxic\nlanguage. In this work, we systematically explore domain-adaptive training to\nreduce the toxicity of language models. We conduct this study on three\ndimensions: training corpus, model size, and parameter efficiency. For the\ntraining corpus, we propose to leverage the generative power of LMs and\ngenerate nontoxic datasets for domain-adaptive training, which mitigates the\nexposure bias and is shown to be more data-efficient than using a curated\npre-training corpus. We demonstrate that the self-generation method\nconsistently outperforms the existing baselines across various model sizes on\nboth automatic and human evaluations, even when it uses a 1/3 smaller training\ncorpus. We then comprehensively study detoxifying LMs with parameter sizes\nranging from 126M up to 530B (3x larger than GPT-3), a scale that has never\nbeen studied before. We find that i) large LMs have similar toxicity levels as\nsmaller ones given the same pre-training corpus, and ii) large LMs require more\nendeavor to detoxify. We also explore parameter-efficient training methods for\ndetoxification. We demonstrate that adding and training adapter-only layers in\nLMs not only saves a lot of parameters but also achieves a better trade-off\nbetween toxicity and perplexity than whole model adaptation for the large-scale\nmodels.\n",
                "链接": "https://arxiv.org/abs/2202.04173"
            },
            {
                "文章ID": "97002",
                "标题": "The Unreasonable Effectiveness of Large Language-Vision Models for\n  Source-free Video Domain Adaptation",
                "作者": " Giacomo Zara,  Alessandro Conti,  Subhankar Roy,  Stéphane Lathuilière,  Paolo Rota,  Elisa Ricci",
                "发布日期": "2023-08-23",
                "摘要": "  Source-Free Video Unsupervised Domain Adaptation (SFVUDA) task consists in\nadapting an action recognition model, trained on a labelled source dataset, to\nan unlabelled target dataset, without accessing the actual source data. The\nprevious approaches have attempted to address SFVUDA by leveraging\nself-supervision (e.g., enforcing temporal consistency) derived from the target\ndata itself. In this work, we take an orthogonal approach by exploiting\n\"web-supervision\" from Large Language-Vision Models (LLVMs), driven by the\nrationale that LLVMs contain a rich world prior surprisingly robust to\ndomain-shift. We showcase the unreasonable effectiveness of integrating LLVMs\nfor SFVUDA by devising an intuitive and parameter-efficient method, which we\nname Domain Adaptation with Large Language-Vision models (DALL-V), that\ndistills the world prior and complementary source model information into a\nstudent network tailored for the target. Despite the simplicity, DALL-V\nachieves significant improvement over state-of-the-art SFVUDA methods.\n",
                "链接": "https://arxiv.org/abs/2308.09139"
            },
            {
                "文章ID": "123602",
                "标题": "Traces of Memorisation in Large Language Models for Code",
                "作者": " Ali Al-Kaswan,  Maliheh Izadi,  Arie van Deursen",
                "发布日期": "2023-12-20",
                "摘要": "  Large language models have gained significant popularity because of their\nability to generate human-like text and potential applications in various\nfields, such as Software Engineering. Large language models for code are\ncommonly trained on large unsanitised corpora of source code scraped from the\ninternet. The content of these datasets is memorised and can be extracted by\nattackers with data extraction attacks. In this work, we explore memorisation\nin large language models for code and compare the rate of memorisation with\nlarge language models trained on natural language. We adopt an existing\nbenchmark for natural language and construct a benchmark for code by\nidentifying samples that are vulnerable to attack. We run both benchmarks\nagainst a variety of models, and perform a data extraction attack. We find that\nlarge language models for code are vulnerable to data extraction attacks, like\ntheir natural language counterparts. From the training data that was identified\nto be potentially extractable we were able to extract 47% from a\nCodeGen-Mono-16B code completion model. We also observe that models memorise\nmore, as their parameter count grows, and that their pre-training data are also\nvulnerable to attack. We also find that data carriers are memorised at a higher\nrate than regular code or documentation and that different model architectures\nmemorise different samples. Data leakage has severe outcomes, so we urge the\nresearch community to further investigate the extent of this phenomenon using a\nwider range of models and extraction techniques in order to build safeguards to\nmitigate this issue.\n",
                "链接": "https://arxiv.org/abs/2312.11658"
            },
            {
                "文章ID": "79083",
                "标题": "Evaluating the Performance of Large Language Models on GAOKAO Benchmark",
                "作者": " Xiaotian Zhang,  Chunyang Li,  Yi Zong,  Zhengyu Ying,  Liang He,  Xipeng Qiu",
                "发布日期": "2023-05-24",
                "摘要": "  Large language models have demonstrated remarkable performance across various\nnatural language processing tasks; however, their efficacy in more challenging\nand domain-specific tasks remains less explored. This paper introduces the\nGAOKAO-Benchmark (GAOKAO-Bench), an intuitive benchmark that employs questions\nfrom the Chinese Gaokao examination as test samples for evaluating large\nlanguage models.In order to align the evaluation results with humans as much as\npossible, we designed a method based on zero-shot prompts to analyze the\naccuracy and scoring rate of the model by dividing the questions into\nsubjective and objective types. We evaluated the ChatGPT model on\nGAOKAO-Benchmark performance.Our findings reveal that the ChatGPT model excels\nin tackling objective questions, while also shedding light on its shortcomings\nand areas for improvement. To further scrutinize the model's responses, we\nincorporate human evaluations.In conclusion, this research contributes a robust\nevaluation benchmark for future large-scale language models and offers valuable\ninsights into the limitations of such models.\n",
                "链接": "https://arxiv.org/abs/2305.12474"
            },
            {
                "文章ID": "83697",
                "标题": "Leveraging Large Language Models for Topic Classification in the Domain\n  of Public Affairs",
                "作者": " Alejandro Peña,  Aythami Morales,  Julian Fierrez,  Ignacio Serna,  Javier Ortega-Garcia,  Iñigo Puente,  Jorge Cordova,  Gonzalo Cordova",
                "发布日期": "2023-09-06",
                "摘要": "  The analysis of public affairs documents is crucial for citizens as it\npromotes transparency, accountability, and informed decision-making. It allows\ncitizens to understand government policies, participate in public discourse,\nand hold representatives accountable. This is crucial, and sometimes a matter\nof life or death, for companies whose operation depend on certain regulations.\nLarge Language Models (LLMs) have the potential to greatly enhance the analysis\nof public affairs documents by effectively processing and understanding the\ncomplex language used in such documents. In this work, we analyze the\nperformance of LLMs in classifying public affairs documents. As a natural\nmulti-label task, the classification of these documents presents important\nchallenges. In this work, we use a regex-powered tool to collect a database of\npublic affairs documents with more than 33K samples and 22.5M tokens. Our\nexperiments assess the performance of 4 different Spanish LLMs to classify up\nto 30 different topics in the data in different configurations. The results\nshows that LLMs can be of great use to process domain-specific documents, such\nas those in the domain of public affairs.\n",
                "链接": "https://arxiv.org/abs/2306.02864"
            },
            {
                "文章ID": "100283",
                "标题": "On the Planning, Search, and Memorization Capabilities of Large Language\n  Models",
                "作者": " Yunhao Yang,  Anshul Tomar",
                "发布日期": "2023-09-06",
                "摘要": "  The rapid advancement of large language models, such as the Generative\nPre-trained Transformer (GPT) series, has had significant implications across\nvarious disciplines. In this study, we investigate the potential of the\nstate-of-the-art large language model (GPT-4) for planning tasks. We explore\nits effectiveness in multiple planning subfields, highlighting both its\nstrengths and limitations. Through a comprehensive examination, we identify\nareas where large language models excel in solving planning problems and reveal\nthe constraints that limit their applicability. Our empirical analysis focuses\non GPT-4's performance in planning domain extraction, graph search path\nplanning, and adversarial planning. We then propose a way of fine-tuning a\ndomain-specific large language model to improve its Chain of Thought (CoT)\ncapabilities for the above-mentioned tasks. The results provide valuable\ninsights into the potential applications of large language models in the\nplanning domain and pave the way for future research to overcome their\nlimitations and expand their capabilities.\n",
                "链接": "https://arxiv.org/abs/2309.01868"
            },
            {
                "文章ID": "79680",
                "标题": "Images in Language Space: Exploring the Suitability of Large Language\n  Models for Vision & Language Tasks",
                "作者": " Sherzod Hakimov,  David Schlangen",
                "发布日期": "2023-05-24",
                "摘要": "  Large language models have demonstrated robust performance on various\nlanguage tasks using zero-shot or few-shot learning paradigms. While being\nactively researched, multimodal models that can additionally handle images as\ninput have yet to catch up in size and generality with language-only models. In\nthis work, we ask whether language-only models can be utilised for tasks that\nrequire visual input -- but also, as we argue, often require a strong reasoning\ncomponent. Similar to some recent related work, we make visual information\naccessible to the language model using separate verbalisation models.\nSpecifically, we investigate the performance of open-source, open-access\nlanguage models against GPT-3 on five vision-language tasks when given\ntextually-encoded visual information. Our results suggest that language models\nare effective for solving vision-language tasks even with limited samples. This\napproach also enhances the interpretability of a model's output by providing a\nmeans of tracing the output back through the verbalised image content.\n",
                "链接": "https://arxiv.org/abs/2305.13782"
            },
            {
                "文章ID": "77064",
                "标题": "Evaluating Open-Domain Question Answering in the Era of Large Language\n  Models",
                "作者": " Ehsan Kamalloo,  Nouha Dziri,  Charles L. A. Clarke,  Davood Rafiei",
                "发布日期": "2023-07-10",
                "摘要": "  Lexical matching remains the de facto evaluation method for open-domain\nquestion answering (QA). Unfortunately, lexical matching fails completely when\na plausible candidate answer does not appear in the list of gold answers, which\nis increasingly the case as we shift from extractive to generative models. The\nrecent success of large language models (LLMs) for QA aggravates lexical\nmatching failures since candidate answers become longer, thereby making\nmatching with the gold answers even more challenging. Without accurate\nevaluation, the true progress in open-domain QA remains unknown. In this paper,\nwe conduct a thorough analysis of various open-domain QA models, including\nLLMs, by manually evaluating their answers on a subset of NQ-open, a popular\nbenchmark. Our assessments reveal that while the true performance of all models\nis significantly underestimated, the performance of the InstructGPT (zero-shot)\nLLM increases by nearly +60%, making it on par with existing top models, and\nthe InstructGPT (few-shot) model actually achieves a new state-of-the-art on\nNQ-open. We also find that more than 50% of lexical matching failures are\nattributed to semantically equivalent answers. We further demonstrate that\nregex matching ranks QA models consistent with human judgments, although still\nsuffering from unnecessary strictness. Finally, we demonstrate that automated\nevaluation models are a reasonable surrogate for lexical matching in some\ncircumstances, but not for long-form answers generated by LLMs. The automated\nmodels struggle in detecting hallucinations in LLM answers and are thus unable\nto evaluate LLMs. At this time, there appears to be no substitute for human\nevaluation.\n",
                "链接": "https://arxiv.org/abs/2305.06984"
            },
            {
                "文章ID": "102386",
                "标题": "Rethinking Learning Rate Tuning in the Era of Large Language Models",
                "作者": " Hongpeng Jin,  Wenqi Wei,  Xuyu Wang,  Wenbin Zhang,  Yanzhao Wu",
                "发布日期": "2023-09-19",
                "摘要": "  Large Language Models (LLMs) represent the recent success of deep learning in\nachieving remarkable human-like predictive performance. It has become a\nmainstream strategy to leverage fine-tuning to adapt LLMs for various\nreal-world applications due to the prohibitive expenses associated with LLM\ntraining. The learning rate is one of the most important hyperparameters in LLM\nfine-tuning with direct impacts on both fine-tuning efficiency and fine-tuned\nLLM quality. Existing learning rate policies are primarily designed for\ntraining traditional deep neural networks (DNNs), which may not work well for\nLLM fine-tuning. We reassess the research challenges and opportunities of\nlearning rate tuning in the coming era of Large Language Models. This paper\nmakes three original contributions. First, we revisit existing learning rate\npolicies to analyze the critical challenges of learning rate tuning in the era\nof LLMs. Second, we present LRBench++ to benchmark learning rate policies and\nfacilitate learning rate tuning for both traditional DNNs and LLMs. Third, our\nexperimental analysis with LRBench++ demonstrates the key differences between\nLLM fine-tuning and traditional DNN training and validates our analysis.\n",
                "链接": "https://arxiv.org/abs/2309.08859"
            }
        ]
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "854",
                "标题": "Investigating internal migration with network analysis and latent space\n  representations: An application to Turkey",
                "作者": " Furkan Gürsoy,  Bertan Badur",
                "发布日期": "2022-01-11",
                "摘要": "  Human migration patterns influence the redistribution of population\ncharacteristics over the geography and since such distributions are closely\nrelated to social and economic outcomes, investigating the structure and\ndynamics of internal migration plays a crucial role in understanding and\ndesigning policies for such systems. We provide an in-depth investigation into\nthe structure and dynamics of the internal migration in Turkey from 2008 to\n2020. We identify a set of classical migration laws and examine them via\nvarious methods for signed network analysis, ego network analysis,\nrepresentation learning, temporal stability analysis, community detection, and\nnetwork visualization. The findings show that, in line with the classical\nmigration laws, most migration links are geographically bounded with several\nexceptions involving cities with large economic activity, major migration flows\nare countered with migration flows in the opposite direction, there are\nwell-defined migration routes, and the migration system is generally stable\nover the investigated period. Apart from these general results, we also provide\nunique and specific insights into Turkey. Overall, the novel toolset we employ\nfor the first time in the literature allows the investigation of selected\nmigration laws from a complex networks perspective and sheds light on future\nmigration research on different geographies.\n",
                "链接": "https://arxiv.org/abs/2201.03543"
            },
            {
                "文章ID": "82137",
                "标题": "Multi-source adversarial transfer learning for ultrasound image\n  segmentation with limited similarity",
                "作者": " Yifu Zhang,  Hongru Li,  Tao Yang,  Rui Tao,  Zhengyuan Liu,  Shimeng Shi,  Jiansong Zhang,  Ning Ma,  Wujin Feng,  Zhanhu Zhang,  Xinyu Zhang",
                "发布日期": "2023-08-11",
                "摘要": "  Lesion segmentation of ultrasound medical images based on deep learning\ntechniques is a widely used method for diagnosing diseases. Although there is a\nlarge amount of ultrasound image data in medical centers and other places,\nlabeled ultrasound datasets are a scarce resource, and it is likely that no\ndatasets are available for new tissues/organs. Transfer learning provides the\npossibility to solve this problem, but there are too many features in natural\nimages that are not related to the target domain. As a source domain, redundant\nfeatures that are not conducive to the task will be extracted. Migration\nbetween ultrasound images can avoid this problem, but there are few types of\npublic datasets, and it is difficult to find sufficiently similar source\ndomains. Compared with natural images, ultrasound images have less information,\nand there are fewer transferable features between different ultrasound images,\nwhich may cause negative transfer. To this end, a multi-source adversarial\ntransfer learning network for ultrasound image segmentation is proposed.\nSpecifically, to address the lack of annotations, the idea of adversarial\ntransfer learning is used to adaptively extract common features between a\ncertain pair of source and target domains, which provides the possibility to\nutilize unlabeled ultrasound data. To alleviate the lack of knowledge in a\nsingle source domain, multi-source transfer learning is adopted to fuse\nknowledge from multiple source domains. In order to ensure the effectiveness of\nthe fusion and maximize the use of precious data, a multi-source domain\nindependent strategy is also proposed to improve the estimation of the target\ndomain data distribution, which further increases the learning ability of the\nmulti-source adversarial migration learning network in multiple domains.\n",
                "链接": "https://arxiv.org/abs/2305.19069"
            },
            {
                "文章ID": "28558",
                "标题": "Multi-task Envisioning Transformer-based Autoencoder for Corporate\n  Credit Rating Migration Early Prediction",
                "作者": " Han Yue,  Steve Xia,  Hongfu Liu",
                "发布日期": "2022-07-12",
                "摘要": "  Corporate credit ratings issued by third-party rating agencies are quantified\nassessments of a company's creditworthiness. Credit Ratings highly correlate to\nthe likelihood of a company defaulting on its debt obligations. These ratings\nplay critical roles in investment decision-making as one of the key risk\nfactors. They are also central to the regulatory framework such as BASEL II in\ncalculating necessary capital for financial institutions. Being able to predict\nrating changes will greatly benefit both investors and regulators alike. In\nthis paper, we consider the corporate credit rating migration early prediction\nproblem, which predicts the credit rating of an issuer will be upgraded,\nunchanged, or downgraded after 12 months based on its latest financial\nreporting information at the time. We investigate the effectiveness of\ndifferent standard machine learning algorithms and conclude these models\ndeliver inferior performance. As part of our contribution, we propose a new\nMulti-task Envisioning Transformer-based Autoencoder (META) model to tackle\nthis challenging problem. META consists of Positional Encoding,\nTransformer-based Autoencoder, and Multi-task Prediction to learn effective\nrepresentations for both migration prediction and rating prediction. This\nenables META to better explore the historical data in the training stage for\none-year later prediction. Experimental results show that META outperforms all\nbaseline models.\n",
                "链接": "https://arxiv.org/abs/2207.04539"
            },
            {
                "文章ID": "114993",
                "标题": "A Cognitive Agent Computing-Based Model For The Primary School Student\n  Migration Problem Using A Descriptive Agent-Based Approach",
                "作者": " Muhammad Tausif",
                "发布日期": "2023-11-14",
                "摘要": "  Students' migration from public to private schools, due to lack of school\nperformance of public schools, is one of the major issues faced by the\nGovernment of Punjab to provide compulsory and quality education at low cost.\nDue to complex adaptive nature of educational system, interdependencies with\nsociety, constant feedback loops conventional linear regression methods, for\nevaluation of effective performance, are ineffective or costly to solve the\nissue. Linear regression techniques present the static view of the system,\nwhich are not enough to understand the complex dynamic nature of educational\nparadigm. We have presented a Cognitive Agent Computing-Based Model for the\nSchool Student Migration Problem Using a Descriptive Agent-Based Modeling\napproach to understand the causes-effects relationship of student migration. We\nhave presented the primary school students' migration model using descriptive\nmodeling approach along with exploratory modeling. Our research, in the context\nof Software Engineering of Simulation & Modeling, and exploring the Complex\nAdaptive nature of school system, is two folds. Firstly, the cause-effect\nrelationship of students' migration is being investigated using Cognitive\nDescriptive Agent-Based Modeling. Secondly, the formalization extent of\nCognitive Agent-Based Computing framework is analyzed by performing its\ncomparative analysis with exploratory modeling protocol 'Overview, Design, and\nDetail'.\n",
                "链接": "https://arxiv.org/abs/2311.06272"
            },
            {
                "文章ID": "56761",
                "标题": "AdaPoinTr: Diverse Point Cloud Completion with Adaptive Geometry-Aware\n  Transformers",
                "作者": " Xumin Yu,  Yongming Rao,  Ziyi Wang,  Jiwen Lu,  Jie Zhou",
                "发布日期": "2023-01-12",
                "摘要": "  In this paper, we present a new method that reformulates point cloud\ncompletion as a set-to-set translation problem and design a new model, called\nPoinTr, which adopts a Transformer encoder-decoder architecture for point cloud\ncompletion. By representing the point cloud as a set of unordered groups of\npoints with position embeddings, we convert the input data to a sequence of\npoint proxies and employ the Transformers for generation. To facilitate\nTransformers to better leverage the inductive bias about 3D geometric\nstructures of point clouds, we further devise a geometry-aware block that\nmodels the local geometric relationships explicitly. The migration of\nTransformers enables our model to better learn structural knowledge and\npreserve detailed information for point cloud completion. Taking a step towards\nmore complicated and diverse situations, we further propose AdaPoinTr by\ndeveloping an adaptive query generation mechanism and designing a novel\ndenoising task during completing a point cloud. Coupling these two techniques\nenables us to train the model efficiently and effectively: we reduce training\ntime (by 15x or more) and improve completion performance (over 20%). We also\nshow our method can be extended to the scene-level point cloud completion\nscenario by designing a new geometry-enhanced semantic scene completion\nframework. Extensive experiments on the existing and newly-proposed datasets\ndemonstrate the effectiveness of our method, which attains 6.53 CD on PCN, 0.81\nCD on ShapeNet-55 and 0.392 MMD on real-world KITTI, surpassing other work by a\nlarge margin and establishing new state-of-the-arts on various benchmarks. Most\nnotably, AdaPoinTr can achieve such promising performance with higher\nthroughputs and fewer FLOPs compared with the previous best methods in\npractice. The code and datasets are available at\nhttps://github.com/yuxumin/PoinTr\n",
                "链接": "https://arxiv.org/abs/2301.04545"
            },
            {
                "文章ID": "41290",
                "标题": "Self-organizing nest migration dynamics synthesis for ant colony systems",
                "作者": " Matin Macktoobian",
                "发布日期": "2022-10-11",
                "摘要": "  In this study, we synthesize a novel dynamical approach for ant colonies\nenabling them to migrate to new nest sites in a self-organizing fashion. In\nother words, we realize ant colony migration as a self-organizing\nphenotype-level collective behavior. For this purpose, we first segment the\nedges of the graph of ants' pathways. Then, each segment, attributed to its own\npheromone profile, may host an ant. So, multiple ants may occupy an edge at the\nsame time. Thanks to this segment-wise edge formulation, ants have more\nselection options in the course of their pathway determination, thereby\nincreasing the diversity of their colony's emergent behaviors. In light of the\ncontinuous pheromone dynamics of segments, each edge owns a spatio-temporal\npiece-wise continuous pheromone profile in which both deposit and evaporation\nprocesses are unified. The passive dynamics of the proposed migration mechanism\nis sufficiently rich so that an ant colony can migrate to the vicinity of a new\nnest site in a self-organizing manner without any external supervision. In\nparticular, we perform extensive simulations to test our migration dynamics\napplied to a colony including 500 ants traversing a pathway graph comprising\n200 nodes and 4000 edges which are segmented based on various resolutions. The\nobtained results exhibit the effectiveness of our strategy.\n",
                "链接": "https://arxiv.org/abs/2210.03975"
            },
            {
                "文章ID": "51005",
                "标题": "PINNet: a deep neural network with pathway prior knowledge for\n  Alzheimer's disease",
                "作者": " Yeojin Kim,  Hyunju Lee",
                "发布日期": "2022-11-30",
                "摘要": "  Identification of Alzheimer's Disease (AD)-related transcriptomic signatures\nfrom blood is important for early diagnosis of the disease. Deep learning\ntechniques are potent classifiers for AD diagnosis, but most have been unable\nto identify biomarkers because of their lack of interpretability. To address\nthese challenges, we propose a pathway information-based neural network\n(PINNet) to predict AD patients and analyze blood and brain transcriptomic\nsignatures using an interpretable deep learning model. PINNet is a deep neural\nnetwork (DNN) model with pathway prior knowledge from either the Gene Ontology\nor Kyoto Encyclopedia of Genes and Genomes databases. Then, a\nbackpropagation-based model interpretation method was applied to reveal\nessential pathways and genes for predicting AD. We compared the performance of\nPINNet with a DNN model without a pathway. Performances of PINNet outperformed\nor were similar to those of DNN without a pathway using blood and brain gene\nexpressions, respectively. Moreover, PINNet considers more AD-related genes as\nessential features than DNN without a pathway in the learning process. Pathway\nanalysis of protein-protein interaction modules of highly contributed genes\nshowed that AD-related genes in blood were enriched with cell migration,\nPI3K-Akt, MAPK signaling, and apoptosis in blood. The pathways enriched in the\nbrain module included cell migration, PI3K-Akt, MAPK signaling, apoptosis,\nprotein ubiquitination, and t-cell activation. Collectively, with prior\nknowledge about pathways, PINNet reveals essential pathways related to AD.\n",
                "链接": "https://arxiv.org/abs/2211.15669"
            },
            {
                "文章ID": "32150",
                "标题": "Simplifying Sparse Expert Recommendation by Revisiting Graph Diffusion",
                "作者": " Vaibhav Krishna,  Nino Antulov-Fantulin",
                "发布日期": "2022-08-05",
                "摘要": "  Community Question Answering (CQA) websites have become valuable knowledge\nrepositories where individuals exchange information by asking and answering\nquestions. With an ever-increasing number of questions and high migration of\nusers in and out of communities, a key challenge is to design effective\nstrategies for recommending experts for new questions. In this paper, we\npropose a simple graph-diffusion expert recommendation model for CQA, that can\noutperform state-of-the art deep learning representatives and collaborative\nmodels. Our proposed method learns users' expertise in the context of both\nsemantic and temporal information to capture their changing interest and\nactivity levels with time. Experiments on five real-world datasets from the\nStack Exchange network demonstrate that our approach outperforms competitive\nbaseline methods. Further, experiments on cold-start users (users with a\nlimited historical record) show our model achieves an average of ~ 30%\nperformance gain compared to the best baseline method.\n",
                "链接": "https://arxiv.org/abs/2208.02438"
            },
            {
                "文章ID": "9304",
                "标题": "Towards Analyzing the Bias of News Recommender Systems Using Sentiment\n  and Stance Detection",
                "作者": " Mehwish Alam,  Andreea Iana,  Alexander Grote,  Katharina Ludwig,  Philipp Müller,  Heiko Paulheim",
                "发布日期": "2022-03-14",
                "摘要": "  News recommender systems are used by online news providers to alleviate\ninformation overload and to provide personalized content to users. However,\nalgorithmic news curation has been hypothesized to create filter bubbles and to\nintensify users' selective exposure, potentially increasing their vulnerability\nto polarized opinions and fake news. In this paper, we show how information on\nnews items' stance and sentiment can be utilized to analyze and quantify the\nextent to which recommender systems suffer from biases. To that end, we have\nannotated a German news corpus on the topic of migration using stance detection\nand sentiment analysis. In an experimental evaluation with four different\nrecommender systems, our results show a slight tendency of all four models for\nrecommending articles with negative sentiments and stances against the topic of\nrefugees and migration. Moreover, we observed a positive correlation between\nthe sentiment and stance bias of the text-based recommenders and the\npreexisting user bias, which indicates that these systems amplify users'\nopinions and decrease the diversity of recommended news. The knowledge-aware\nmodel appears to be the least prone to such biases, at the cost of predictive\naccuracy.\n",
                "链接": "https://arxiv.org/abs/2203.05824"
            },
            {
                "文章ID": "120418",
                "标题": "Advancing Web Accessibility -- A guide to transitioning Design Systems\n  from WCAG 2.0 to WCAG 2.1",
                "作者": " Hardik Shah",
                "发布日期": "2023-12-07",
                "摘要": "  This research focuses on the critical process of upgrading a Design System\nfrom Web Content Accessibility Guidelines (WCAG) 2.0 to WCAG 2.1, which is an\nessential step in enhancing web accessibility. It emphasizes the importance of\nstaying up to date on increasing accessibility requirements, as well as the\ncritical function of Design Systems in supporting inclusion in digital\nenvironments. The article lays out a complete strategy for meeting WCAG 2.1\ncompliance. Assessment, strategic planning, implementation, and testing are all\npart of this strategy. The need for collaboration and user involvement is\nemphasized as critical strategies and best practices for a successful migration\njourney. In addition, the article digs into migration barriers and discusses\nsignificant lessons acquired, offering a realistic view of the intricacies of\nthis transforming road. Finally, it is a practical guide and a necessary\nresource for organizations committed to accessible and user-centered design.\nThe document provides them with the knowledge and resources they need to\nnavigate the changing world of web accessibility properly.\n",
                "链接": "https://arxiv.org/abs/2312.02992"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和脑科学交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "105384",
                "标题": "In-Context Learning in Large Language Models: A Neuroscience-inspired\n  Analysis of Representations",
                "作者": " Safoora Yousefi,  Leo Betthauser,  Hosein Hasanbeig,  Akanksha Saran,  Raphaël Millière,  Ida Momennejad",
                "发布日期": "2023-10-19",
                "摘要": "  Large language models (LLMs) exhibit remarkable performance improvement\nthrough in-context learning (ICL) by leveraging task-specific examples in the\ninput. However, the mechanisms behind this improvement remain elusive. In this\nwork, we investigate embeddings and attention representations in Llama-2 70B\nand Vicuna 13B. Specifically, we study how embeddings and attention change\nafter in-context-learning, and how these changes mediate improvement in\nbehavior. We employ neuroscience-inspired techniques, such as representational\nsimilarity analysis (RSA), and propose novel methods for parameterized probing\nand attention ratio analysis (ARA, measuring the ratio of attention to relevant\nvs. irrelevant information). We designed three tasks with a priori\nrelationships among their conditions: reading comprehension, linear regression,\nand adversarial prompt injection. We formed hypotheses about expected\nsimilarities in task representations to investigate latent changes in\nembeddings and attention. Our analyses revealed a meaningful correlation\nbetween changes in both embeddings and attention representations with\nimprovements in behavioral performance after ICL. This empirical framework\nempowers a nuanced understanding of how latent representations affect LLM\nbehavior with and without ICL, offering valuable tools and insights for future\nresearch and practical applications.\n",
                "链接": "https://arxiv.org/abs/2310.00313"
            },
            {
                "文章ID": "11875",
                "标题": "mdx: A Cloud Platform for Supporting Data Science and Cross-Disciplinary\n  Research Collaborations",
                "作者": " Toyotaro Suzumura,  Akiyoshi Sugiki,  Hiroyuki Takizawa,  Akira Imakura,  Hiroshi Nakamura,  Kenjiro Taura,  Tomohiro Kudoh,  Toshihiro Hanawa,  Yuji Sekiya,  Hiroki Kobayashi,  Shin Matsushima,  Yohei Kuga,  Ryo Nakamura,  Renhe Jiang,  Junya Kawase,  Masatoshi Hanai,  Hiroshi Miyazaki,  Tsutomu Ishizaki,  Daisuke Shimotoku,  Daisuke Miyamoto,  Kento Aida,  Atsuko Takefusa,  Takashi Kurimoto,  Koji Sasayama,  Naoya Kitagawa,  Ikki Fujiwara,  Yusuke Tanimura,  Takayuki Aoki,  Toshio Endo,  Satoshi Ohshima,  Keiichiro Fukazawa,  Susumu Date,  Toshihiro Uchibayashi",
                "发布日期": "2022-03-29",
                "摘要": "  The growing amount of data and advances in data science have created a need\nfor a new kind of cloud platform that provides users with flexibility, strong\nsecurity, and the ability to couple with supercomputers and edge devices\nthrough high-performance networks. We have built such a nation-wide cloud\nplatform, called \"mdx\" to meet this need. The mdx platform's virtualization\nservice, jointly operated by 9 national universities and 2 national research\ninstitutes in Japan, launched in 2021, and more features are in development.\nCurrently mdx is used by researchers in a wide variety of domains, including\nmaterials informatics, geo-spatial information science, life science,\nastronomical science, economics, social science, and computer science. This\npaper provides an the overview of the mdx platform, details the motivation for\nits development, reports its current status, and outlines its future plans.\n",
                "链接": "https://arxiv.org/abs/2203.14188"
            },
            {
                "文章ID": "112056",
                "标题": "Large-scale Foundation Models and Generative AI for BigData Neuroscience",
                "作者": " Ran Wang,  Zhe Sage Chen",
                "发布日期": "2023-10-31",
                "摘要": "  Recent advances in machine learning have made revolutionary breakthroughs in\ncomputer games, image and natural language understanding, and scientific\ndiscovery. Foundation models and large-scale language models (LLMs) have\nrecently achieved human-like intelligence thanks to BigData. With the help of\nself-supervised learning (SSL) and transfer learning, these models may\npotentially reshape the landscapes of neuroscience research and make a\nsignificant impact on the future. Here we present a mini-review on recent\nadvances in foundation models and generative AI models as well as their\napplications in neuroscience, including natural language and speech, semantic\nmemory, brain-machine interfaces (BMIs), and data augmentation. We argue that\nthis paradigm-shift framework will open new avenues for many neuroscience\nresearch directions and discuss the accompanying challenges and opportunities.\n",
                "链接": "https://arxiv.org/abs/2310.18377"
            },
            {
                "文章ID": "115369",
                "标题": "MEGAVERSE: Benchmarking Large Language Models Across Languages,\n  Modalities, Models and Tasks",
                "作者": " Sanchit Ahuja,  Divyanshu Aggarwal,  Varun Gumma,  Ishaan Watts,  Ashutosh Sathe,  Millicent Ochieng,  Rishav Hada,  Prachi Jain,  Maxamed Axmed,  Kalika Bali,  Sunayana Sitaram",
                "发布日期": "2023-11-14",
                "摘要": "  Recently, there has been a rapid advancement in research on Large Language\nModels (LLMs), resulting in significant progress in several Natural Language\nProcessing (NLP) tasks. Consequently, there has been a surge in LLM evaluation\nresearch to comprehend the models' capabilities and limitations. However, much\nof this research has been confined to the English language, leaving LLM\nbuilding and evaluation for non-English languages relatively unexplored. There\nhas been an introduction of several new LLMs, necessitating their evaluation on\nnon-English languages. This study aims to expand our MEGA benchmarking suite by\nincluding six new datasets to form the MEGAVERSE benchmark. The benchmark\ncomprises 22 datasets covering 81 languages, including low-resource African\nlanguages. We evaluate several state-of-the-art LLMs like GPT-3.5-Turbo, GPT4,\nPaLM2, and Llama2 on the MEGAVERSE datasets. Additionally, we include two\nmultimodal datasets in the benchmark and assess the performance of the\nLLaVa-v1.5 model. Our experiments suggest that GPT4 and PaLM2 outperform the\nLlama models on various tasks, notably on low-resource languages, with GPT4\noutperforming PaLM2 on more datasets than vice versa. However, issues such as\ndata contamination must be addressed to obtain an accurate assessment of LLM\nperformance on non-English languages.\n",
                "链接": "https://arxiv.org/abs/2311.07463"
            },
            {
                "文章ID": "106494",
                "标题": "Benchmarking Large Language Models As AI Research Agents",
                "作者": " Qian Huang,  Jian Vora,  Percy Liang,  Jure Leskovec",
                "发布日期": "2023-10-06",
                "摘要": "  Scientific experimentation involves an iterative process of creating\nhypotheses, designing experiments, running experiments, and analyzing the\nresults. Can we build AI research agents to perform these long-horizon tasks?\nTo take a step towards building and evaluating research agents on such\nopen-ended decision-making tasks, we focus on the problem of machine learning\nengineering: given a task description and a dataset, build a high-performing\nmodel. In this paper, we propose MLAgentBench, a suite of ML tasks for\nbenchmarking AI research agents. Agents can perform actions like\nreading/writing files, executing code, and inspecting outputs. With these\nactions, agents could run experiments, analyze the results, and modify the code\nof entire machine learning pipelines, such as data processing, architecture,\ntraining processes, etc. The benchmark then automatically evaluates the agent's\nperformance objectively over various metrics related to performance and\nefficiency. We also design an LLM-based research agent to automatically perform\nexperimentation loops in such an environment. Empirically, we find that a\nGPT-4-based research agent can feasibly build compelling ML models over many\ntasks in MLAgentBench, displaying highly interpretable plans and actions.\nHowever, the success rates vary considerably; they span from almost 90\\% on\nwell-established older datasets to as low as 10\\% on recent Kaggle Challenges\n-- unavailable during the LLM model's pretraining -- and even 0\\% on newer\nresearch challenges like BabyLM. Finally, we identify several key challenges\nfor LLM-based research agents such as long-term planning and hallucination. Our\ncode is released at https://github.com/snap-stanford/MLAgentBench.\n",
                "链接": "https://arxiv.org/abs/2310.03302"
            },
            {
                "文章ID": "78446",
                "标题": "SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal\n  Conversational Abilities",
                "作者": " Dong Zhang,  Shimin Li,  Xin Zhang,  Jun Zhan,  Pengyu Wang,  Yaqian Zhou,  Xipeng Qiu",
                "发布日期": "2023-05-22",
                "摘要": "  Multi-modal large language models are regarded as a crucial step towards\nArtificial General Intelligence (AGI) and have garnered significant interest\nwith the emergence of ChatGPT. However, current speech-language models\ntypically adopt the cascade paradigm, preventing inter-modal knowledge\ntransfer. In this paper, we propose SpeechGPT, a large language model with\nintrinsic cross-modal conversational abilities, capable of perceiving and\ngenerating multi-model content. With discrete speech representations, we first\nconstruct SpeechInstruct, a large-scale cross-modal speech instruction dataset.\nAdditionally, we employ a three-stage training strategy that includes\nmodality-adaptation pre-training, cross-modal instruction fine-tuning, and\nchain-of-modality instruction fine-tuning. The experimental results demonstrate\nthat SpeechGPT has an impressive capacity to follow multi-modal human\ninstructions and highlight the potential of handling multiple modalities with\none model. Demos are shown in https://0nutation.github.io/SpeechGPT.github.io/.\n",
                "链接": "https://arxiv.org/abs/2305.11000"
            },
            {
                "文章ID": "102423",
                "标题": "Cross-Lingual Knowledge Editing in Large Language Models",
                "作者": " Jiaan Wang,  Yunlong Liang,  Zengkui Sun,  Yuxuan Cao,  Jiarong Xu",
                "发布日期": "2023-09-19",
                "摘要": "  Knowledge editing aims to change language models' performance on several\nspecial cases (i.e., editing scope) by infusing the corresponding expected\nknowledge into them. With the recent advancements in large language models\n(LLMs), knowledge editing has been shown as a promising technique to adapt LLMs\nto new knowledge without retraining from scratch. However, most of the previous\nstudies neglect the multi-lingual nature of some main-stream LLMs (e.g., LLaMA,\nChatGPT and GPT-4), and typically focus on monolingual scenarios, where LLMs\nare edited and evaluated in the same language. As a result, it is still unknown\nthe effect of source language editing on a different target language. In this\npaper, we aim to figure out this cross-lingual effect in knowledge editing.\nSpecifically, we first collect a large-scale cross-lingual synthetic dataset by\ntranslating ZsRE from English to Chinese. Then, we conduct English editing on\nvarious knowledge editing methods covering different paradigms, and evaluate\ntheir performance in Chinese, and vice versa. To give deeper analyses of the\ncross-lingual effect, the evaluation includes four aspects, i.e., reliability,\ngenerality, locality and portability. Furthermore, we analyze the inconsistent\nbehaviors of the edited models and discuss their specific challenges.\n",
                "链接": "https://arxiv.org/abs/2309.08952"
            },
            {
                "文章ID": "122222",
                "标题": "CBQ: Cross-Block Quantization for Large Language Models",
                "作者": " Xin Ding,  Xiaoyu Liu,  Yun Zhang,  Zhijun Tu,  Wei Li,  Jie Hu,  Hanting Chen,  Yehui Tang,  Zhiwei Xiong,  Baoqun Yin,  Yunhe Wang",
                "发布日期": "2023-12-14",
                "摘要": "  Post-training quantization (PTQ) has driven attention to producing efficient\nlarge language models (LLMs) with ultra-low costs. Since hand-craft\nquantization parameters lead to low performance in low-bit quantization, recent\nmethods optimize the quantization parameters through block-wise reconstruction\nbetween the floating-point and quantized models. However, these methods suffer\nfrom two challenges: accumulated errors from independent one-by-one block\nquantization and reconstruction difficulties from extreme weight and activation\noutliers. To address these two challenges, we propose CBQ, a cross-block\nreconstruction-based PTQ method for LLMs. To reduce error accumulation, we\nintroduce a cross-block dependency with the aid of a homologous reconstruction\nscheme to build the long-range dependency between adjacent multi-blocks with\noverlapping. To reduce reconstruction difficulty, we design a coarse-to-fine\npre-processing (CFP) to truncate weight outliers and dynamically scale\nactivation outliers before optimization, and an adaptive rounding scheme,\ncalled LoRA-Rounding, with two low-rank learnable matrixes to further rectify\nweight quantization errors. Extensive experiments demonstrate that: (1) CBQ\npushes both activation and weight quantization to low-bit settings W4A4, W4A8,\nand W2A16. (2) CBQ achieves better performance than the existing\nstate-of-the-art methods on various LLMs and benchmark datasets.\n",
                "链接": "https://arxiv.org/abs/2312.07950"
            },
            {
                "文章ID": "71835",
                "标题": "Emergent autonomous scientific research capabilities of large language\n  models",
                "作者": " Daniil A. Boiko,  Robert MacKnight,  Gabe Gomes",
                "发布日期": "2023-04-12",
                "摘要": "  Transformer-based large language models are rapidly advancing in the field of\nmachine learning research, with applications spanning natural language,\nbiology, chemistry, and computer programming. Extreme scaling and reinforcement\nlearning from human feedback have significantly improved the quality of\ngenerated text, enabling these models to perform various tasks and reason about\ntheir choices. In this paper, we present an Intelligent Agent system that\ncombines multiple large language models for autonomous design, planning, and\nexecution of scientific experiments. We showcase the Agent's scientific\nresearch capabilities with three distinct examples, with the most complex being\nthe successful performance of catalyzed cross-coupling reactions. Finally, we\ndiscuss the safety implications of such systems and propose measures to prevent\ntheir misuse.\n",
                "链接": "https://arxiv.org/abs/2304.05332"
            },
            {
                "文章ID": "101124",
                "标题": "Toward Reproducing Network Research Results Using Large Language Models",
                "作者": " Qiao Xiang,  Yuling Lin,  Mingjun Fang,  Bang Huang,  Siyong Huang,  Ridi Wen,  Franck Le,  Linghe Kong,  Jiwu Shu",
                "发布日期": "2023-09-12",
                "摘要": "  Reproducing research results in the networking community is important for\nboth academia and industry. The current best practice typically resorts to\nthree approaches: (1) looking for publicly available prototypes; (2) contacting\nthe authors to get a private prototype; and (3) manually implementing a\nprototype following the description of the publication. However, most published\nnetwork research does not have public prototypes and private prototypes are\nhard to get. As such, most reproducing efforts are spent on manual\nimplementation based on the publications, which is both time and labor\nconsuming and error-prone. In this paper, we boldly propose reproducing network\nresearch results using the emerging large language models (LLMs). In\nparticular, we first prove its feasibility with a small-scale experiment, in\nwhich four students with essential networking knowledge each reproduces a\ndifferent networking system published in prominent conferences and journals by\nprompt engineering ChatGPT. We report the experiment's observations and lessons\nand discuss future open research questions of this proposal. This work raises\nno ethical issue.\n",
                "链接": "https://arxiv.org/abs/2309.04716"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下2023年关于LLM-based Agent的综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "106067",
                "标题": "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with\n  Agent Team Optimization",
                "作者": " Zijun Liu,  Yanzhe Zhang,  Peng Li,  Yang Liu,  Diyi Yang",
                "发布日期": "2023-10-04",
                "摘要": "  Large language model (LLM) agents have been shown effective on a wide range\nof tasks, and by ensembling multiple LLM agents, their performances could be\nfurther improved. Existing approaches employ a fixed set of agents to interact\nwith each other in a static architecture, which limits their generalizability\nto various tasks and requires strong human prior in designing these agents. In\nthis work, we propose to construct a strategic team of agents communicating in\na dynamic interaction architecture based on the task query. Specifically, we\nbuild a framework named Dynamic LLM-Agent Network ($\\textbf{DyLAN}$) for\nLLM-agent collaboration on complicated tasks like reasoning and code\ngeneration. DyLAN enables agents to interact for multiple rounds in a dynamic\narchitecture with inference-time agent selection and an early-stopping\nmechanism to improve performance and efficiency. We further design an automatic\nagent team optimization algorithm based on an unsupervised metric termed\n$\\textit{Agent Importance Score}$, enabling the selection of best agents based\non the contribution each agent makes. Empirically, we demonstrate that DyLAN\nperforms well in both reasoning and code generation tasks with reasonable\ncomputational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and\nHumanEval, respectively, compared to a single execution on GPT-35-turbo. On\nspecific subjects of MMLU, agent team optimization in DyLAN increases accuracy\nby up to 25.0%.\n",
                "链接": "https://arxiv.org/abs/2310.02170"
            },
            {
                "文章ID": "96320",
                "标题": "ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate",
                "作者": " Chi-Min Chan,  Weize Chen,  Yusheng Su,  Jianxuan Yu,  Wei Xue,  Shanghang Zhang,  Jie Fu,  Zhiyuan Liu",
                "发布日期": "2023-08-15",
                "摘要": "  Text evaluation has historically posed significant challenges, often\ndemanding substantial labor and time cost. With the emergence of large language\nmodels (LLMs), researchers have explored LLMs' potential as alternatives for\nhuman evaluation. While these single-agent-based approaches show promise,\nexperimental results suggest that further advancements are needed to bridge the\ngap between their current effectiveness and human-level evaluation quality.\nRecognizing that best practices of human evaluation processes often involve\nmultiple human annotators collaborating in the evaluation, we resort to a\nmulti-agent debate framework, moving beyond single-agent prompting strategies.\nThe multi-agent-based approach enables a group of LLMs to synergize with an\narray of intelligent counterparts, harnessing their distinct capabilities and\nexpertise to enhance efficiency and effectiveness in handling intricate tasks.\nIn this paper, we construct a multi-agent referee team called ChatEval to\nautonomously discuss and evaluate the quality of generated responses from\ndifferent models on open-ended questions and traditional natural language\ngeneration (NLG) tasks. Our analysis shows that ChatEval transcends mere\ntextual scoring, offering a human-mimicking evaluation process for reliable\nassessments. Our code is available at https://github.com/chanchimin/ChatEval.\n",
                "链接": "https://arxiv.org/abs/2308.07201"
            },
            {
                "文章ID": "110807",
                "标题": "LLM-Based Agent Society Investigation: Collaboration and Confrontation\n  in Avalon Gameplay",
                "作者": " Yihuai Lan,  Zhiqiang Hu,  Lei Wang,  Yang Wang,  Deheng Ye,  Peilin Zhao,  Ee-Peng Lim,  Hui Xiong,  Hao Wang",
                "发布日期": "2023-10-24",
                "摘要": "  This paper aims to investigate the open research problem of uncovering the\nsocial behaviors of LLM-based agents. To achieve this goal, we adopt Avalon, a\nrepresentative communication game, as the environment and use system prompts to\nguide LLM agents to play the game. While previous studies have conducted\npreliminary investigations into gameplay with LLM agents, there lacks research\non their social behaviors. In this paper, we present a novel framework designed\nto seamlessly adapt to Avalon gameplay. The core of our proposed framework is a\nmulti-agent system that enables efficient communication and interaction among\nagents. We evaluate the performance of our framework based on metrics from two\nperspectives: winning the game and analyzing the social behaviors of LLM\nagents. Our results demonstrate the effectiveness of our framework in\ngenerating adaptive and intelligent agents and highlight the potential of\nLLM-based agents in addressing the challenges associated with dynamic social\nenvironment interaction. By analyzing the social behaviors of LLM agents from\nthe aspects of both collaboration and confrontation, we provide insights into\nthe research and applications of this domain.\n",
                "链接": "https://arxiv.org/abs/2310.14985"
            },
            {
                "文章ID": "109035",
                "标题": "Character-LLM: A Trainable Agent for Role-Playing",
                "作者": " Yunfan Shao,  Linyang Li,  Junqi Dai,  Xipeng Qiu",
                "发布日期": "2023-12-15",
                "摘要": "  Large language models (LLMs) can be used to serve as agents to simulate human\nbehaviors, given the powerful ability to understand human instructions and\nprovide high-quality generated texts. Such ability stimulates us to wonder\nwhether LLMs can simulate a person in a higher form than simple human\nbehaviors. Therefore, we aim to train an agent with the profile, experience,\nand emotional states of a specific person instead of using limited prompts to\ninstruct ChatGPT API. In this work, we introduce Character-LLM that teach LLMs\nto act as specific people such as Beethoven, Queen Cleopatra, Julius Caesar,\netc. Our method focuses on editing profiles as experiences of a certain\ncharacter and training models to be personal simulacra with these experiences.\nTo assess the effectiveness of our approach, we build a test playground that\ninterviews trained agents and evaluates whether the agents \\textit{memorize}\ntheir characters and experiences. Experimental results show interesting\nobservations that help build future simulacra of humankind.\n",
                "链接": "https://arxiv.org/abs/2310.10158"
            },
            {
                "文章ID": "106140",
                "标题": "Conversational Health Agents: A Personalized LLM-Powered Agent Framework",
                "作者": " Mahyar Abbasian,  Iman Azimi,  Amir M. Rahmani,  Ramesh Jain",
                "发布日期": "2023-12-11",
                "摘要": "  Conversational Health Agents (CHAs) are interactive systems that provide\nhealthcare services, such as assistance, self-awareness, and diagnosis. Current\nCHAs, especially those utilizing Large Language Models (LLMs), primarily focus\non conversation aspects. However, they offer limited agent capabilities\nspecifically lacking multi-step problem-solving, empathetic conversations, and\nmultimodal data analysis. Our aim is to overcome these limitations. In this\npaper, we propose an LLM-powered framework to empower CHAs to generate a\npersonalized response for users' healthcare queries. This framework provides\ncritical thinking, knowledge acquisition, and problem-solving abilities by\nintegrating healthcare data sources, enabling multilingual and multimodal\nconversations, and interacting with various user data analysis tools. We\nillustrate the framework's proficiency in handling complex healthcare tasks via\na case study on stress level estimation, showcasing the agent's cognitive and\noperational capabilities. Powered by our framework, the CHA can provide\nappropriate responses, when the user inquires about their stress level. To\nachieve this, it learns to collect photoplethysmogram signals, converts them\ninto heart rate variability, and interprets them as indicators of stress\nlevels.\n",
                "链接": "https://arxiv.org/abs/2310.02374"
            },
            {
                "文章ID": "103890",
                "标题": "Calibrating LLM-Based Evaluator",
                "作者": " Yuxuan Liu,  Tianchi Yang,  Shaohan Huang,  Zihan Zhang,  Haizhen Huang,  Furu Wei,  Weiwei Deng,  Feng Sun,  Qi Zhang",
                "发布日期": "2023-09-26",
                "摘要": "  Recent advancements in large language models (LLMs) on language modeling and\nemergent capabilities make them a promising reference-free evaluator of natural\nlanguage generation quality, and a competent alternative to human evaluation.\nHowever, hindered by the closed-source or high computational demand to host and\ntune, there is a lack of practice to further calibrate an off-the-shelf\nLLM-based evaluator towards better human alignment. In this work, we propose\nAutoCalibrate, a multi-stage, gradient-free approach to automatically calibrate\nand align an LLM-based evaluator toward human preference. Instead of explicitly\nmodeling human preferences, we first implicitly encompass them within a set of\nhuman labels. Then, an initial set of scoring criteria is drafted by the\nlanguage model itself, leveraging in-context learning on different few-shot\nexamples. To further calibrate this set of criteria, we select the best\nperformers and re-draft them with self-refinement. Our experiments on multiple\ntext quality evaluation datasets illustrate a significant improvement in\ncorrelation with expert evaluation through calibration. Our comprehensive\nqualitative analysis conveys insightful intuitions and observations on the\nessence of effective scoring criteria.\n",
                "链接": "https://arxiv.org/abs/2309.13308"
            },
            {
                "文章ID": "83868",
                "标题": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM\n  Agents",
                "作者": " Yashar Talebirad,  Amirhossein Nadiri",
                "发布日期": "2023-06-07",
                "摘要": "  In this paper, we present a novel framework for enhancing the capabilities of\nlarge language models (LLMs) by leveraging the power of multi-agent systems.\nOur framework introduces a collaborative environment where multiple intelligent\nagent components, each with distinctive attributes and roles, work together to\nhandle complex tasks more efficiently and effectively. We demonstrate the\npracticality and versatility of our framework through case studies in\nartificial general intelligence (AGI), specifically focusing on the Auto-GPT\nand BabyAGI models. We also examine the \"Gorilla\" model, which integrates\nexternal APIs into the LLM. Our framework addresses limitations and challenges\nsuch as looping issues, security risks, scalability, system evaluation, and\nethical considerations. By modeling various domains such as courtroom\nsimulations and software development scenarios, we showcase the potential\napplications and benefits of our proposed multi-agent system. Our framework\nprovides an avenue for advancing the capabilities and performance of LLMs\nthrough collaboration and knowledge exchange among intelligent agents.\n",
                "链接": "https://arxiv.org/abs/2306.03314"
            },
            {
                "文章ID": "96648",
                "标题": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
                "作者": " Qingyun Wu,  Gagan Bansal,  Jieyu Zhang,  Yiran Wu,  Beibin Li,  Erkang Zhu,  Li Jiang,  Xiaoyun Zhang,  Shaokun Zhang,  Jiale Liu,  Ahmed Hassan Awadallah,  Ryen W White,  Doug Burger,  Chi Wang",
                "发布日期": "2023-10-05",
                "摘要": "  AutoGen is an open-source framework that allows developers to build LLM\napplications via multiple agents that can converse with each other to\naccomplish tasks. AutoGen agents are customizable, conversable, and can operate\nin various modes that employ combinations of LLMs, human inputs, and tools.\nUsing AutoGen, developers can also flexibly define agent interaction behaviors.\nBoth natural language and computer code can be used to program flexible\nconversation patterns for different applications. AutoGen serves as a generic\ninfrastructure to build diverse applications of various complexities and LLM\ncapacities. Empirical studies demonstrate the effectiveness of the framework in\nmany example applications, with domains ranging from mathematics, coding,\nquestion answering, operations research, online decision-making, entertainment,\netc.\n",
                "链接": "https://arxiv.org/abs/2308.08155"
            },
            {
                "文章ID": "102166",
                "标题": "LASER: LLM Agent with State-Space Exploration for Web Navigation",
                "作者": " Kaixin Ma,  Hongming Zhang,  Hongwei Wang,  Xiaoman Pan,  Dong Yu",
                "发布日期": "2023-09-18",
                "摘要": "  Large language models (LLMs) have been successfully adapted for interactive\ndecision-making tasks like web navigation. While achieving decent performance,\nprevious methods implicitly assume a forward-only execution mode for the model,\nwhere they only provide oracle trajectories as in-context examples to teach the\nmodel how to reason in the interactive environment. Consequently, the model\ncould not handle more challenging scenarios not covered in the in-context\nexamples, e.g., mistakes, leading to sub-optimal performance. To address this\nissue, we propose to model the interactive task as state space exploration,\nwhere the LLM agent transitions among a pre-defined set of states by performing\nactions to complete the task. This formulation enables flexible back-tracking,\nallowing the model to easily recover from errors. We evaluate our proposed LLM\nAgent with State-Space ExploRation (LASER) on the WebShop task. Experimental\nresults show that our LASER agent significantly outperforms previous methods\nand closes the gap with human performance on the web navigation task.\n",
                "链接": "https://arxiv.org/abs/2309.08172"
            },
            {
                "文章ID": "105192",
                "标题": "LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent\n  Negotiation Games",
                "作者": " Sahar Abdelnabi,  Amr Gomaa,  Sarath Sivaprasad,  Lea Schönherr,  Mario Fritz",
                "发布日期": "2023-10-02",
                "摘要": "  There is a growing interest in using Large Language Models (LLMs) as agents\nto tackle real-world tasks that may require assessing complex situations. Yet,\nwe have a limited understanding of LLMs' reasoning and decision-making\ncapabilities, partly stemming from a lack of dedicated evaluation benchmarks.\nAs negotiating and compromising are key aspects of our everyday communication\nand collaboration, we propose using scorable negotiation games as a new\nevaluation framework for LLMs. We create a testbed of diverse text-based,\nmulti-agent, multi-issue, semantically rich negotiation games, with easily\ntunable difficulty. To solve the challenge, agents need to have strong\narithmetic, inference, exploration, and planning capabilities, while seamlessly\nintegrating them. Via a systematic zero-shot Chain-of-Thought prompting (CoT),\nwe show that agents can negotiate and consistently reach successful deals. We\nquantify the performance with multiple metrics and observe a large gap between\nGPT-4 and earlier models. Importantly, we test the generalization to new games\nand setups. Finally, we show that these games can help evaluate other critical\naspects, such as the interaction dynamics between agents in the presence of\ngreedy and adversarial players.\n",
                "链接": "https://arxiv.org/abs/2309.17234"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "39323",
                "标题": "An Overview of the Data-Loader Landscape: Comparative Performance\n  Analysis",
                "作者": " Iason Ofeidis,  Diego Kiedanski,  Leandros Tassiulas",
                "发布日期": "2022-09-29",
                "摘要": "  Dataloaders, in charge of moving data from storage into GPUs while training\nmachine learning models, might hold the key to drastically improving the\nperformance of training jobs. Recent advances have shown promise not only by\nconsiderably decreasing training time but also by offering new features such as\nloading data from remote storage like S3. In this paper, we are the first to\ndistinguish the dataloader as a separate component in the Deep Learning (DL)\nworkflow and to outline its structure and features. Finally, we offer a\ncomprehensive comparison of the different dataloading libraries available,\ntheir trade-offs in terms of functionality, usability, and performance and the\ninsights derived from them.\n",
                "链接": "https://arxiv.org/abs/2209.13705"
            },
            {
                "文章ID": "109426",
                "标题": "EEG motor imagery decoding: A framework for comparative analysis with\n  channel attention mechanisms",
                "作者": " Martin Wimpff,  Leonardo Gizzi,  Jan Zerfowski,  Bin Yang",
                "发布日期": "2023-10-18",
                "摘要": "  The objective of this study is to investigate the application of various\nchannel attention mechanisms within the domain of brain-computer interface\n(BCI) for motor imagery decoding. Channel attention mechanisms can be seen as a\npowerful evolution of spatial filters traditionally used for motor imagery\ndecoding. This study systematically compares such mechanisms by integrating\nthem into a lightweight architecture framework to evaluate their impact. We\ncarefully construct a straightforward and lightweight baseline architecture\ndesigned to seamlessly integrate different channel attention mechanisms. This\napproach is contrary to previous works which only investigate one attention\nmechanism and usually build a very complex, sometimes nested architecture. Our\nframework allows us to evaluate and compare the impact of different attention\nmechanisms under the same circumstances. The easy integration of different\nchannel attention mechanisms as well as the low computational complexity\nenables us to conduct a wide range of experiments on three datasets to\nthoroughly assess the effectiveness of the baseline model and the attention\nmechanisms. Our experiments demonstrate the strength and generalizability of\nour architecture framework as well as how channel attention mechanisms can\nimprove the performance while maintaining the small memory footprint and low\ncomputational complexity of our baseline architecture. Our architecture\nemphasizes simplicity, offering easy integration of channel attention\nmechanisms, while maintaining a high degree of generalizability across\ndatasets, making it a versatile and efficient solution for EEG motor imagery\ndecoding within brain-computer interfaces.\n",
                "链接": "https://arxiv.org/abs/2310.11198"
            },
            {
                "文章ID": "61256",
                "标题": "Multi-dimensional discrimination in Law and Machine Learning -- A\n  comparative overview",
                "作者": " Arjun Roy,  Jan Horstmann,  Eirini Ntoutsi",
                "发布日期": "2023-02-14",
                "摘要": "  AI-driven decision-making can lead to discrimination against certain\nindividuals or social groups based on protected characteristics/attributes such\nas race, gender, or age. The domain of fairness-aware machine learning focuses\non methods and algorithms for understanding, mitigating, and accounting for\nbias in AI/ML models. Still, thus far, the vast majority of the proposed\nmethods assess fairness based on a single protected attribute, e.g. only gender\nor race. In reality, though, human identities are multi-dimensional, and\ndiscrimination can occur based on more than one protected characteristic,\nleading to the so-called ``multi-dimensional discrimination'' or\n``multi-dimensional fairness'' problem. While well-elaborated in legal\nliterature, the multi-dimensionality of discrimination is less explored in the\nmachine learning community. Recent approaches in this direction mainly follow\nthe so-called intersectional fairness definition from the legal domain, whereas\nother notions like additive and sequential discrimination are less studied or\nnot considered thus far. In this work, we overview the different definitions of\nmulti-dimensional discrimination/fairness in the legal domain as well as how\nthey have been transferred/ operationalized (if) in the fairness-aware machine\nlearning domain. By juxtaposing these two domains, we draw the connections,\nidentify the limitations, and point out open research directions.\n",
                "链接": "https://arxiv.org/abs/2302.05995"
            },
            {
                "文章ID": "117885",
                "标题": "Decoding Social Sentiment in DAO: A Comparative Analysis of Blockchain\n  Governance Communities",
                "作者": " Yutong Quan,  Xintong Wu,  Wanlin Deng,  Luyao Zhang",
                "发布日期": "2023-11-30",
                "摘要": "  Blockchain technology is leading a revolutionary transformation across\ndiverse industries, with effective governance standing as a critical\ndeterminant for the success and sustainability of blockchain projects.\nCommunity forums, pivotal in engaging decentralized autonomous organizations\n(DAOs), wield a substantial impact on blockchain governance decisions.\nConcurrently, Natural Language Processing (NLP), particularly sentiment\nanalysis, provides powerful insights from textual data. While prior research\nhas explored the potential of NLP tools in social media sentiment analysis, a\ngap persists in understanding the sentiment landscape of blockchain governance\ncommunities. The evolving discourse and sentiment dynamics on the forums of top\nDAOs remain largely unknown. This paper delves deep into the evolving discourse\nand sentiment dynamics on the public forums of leading DeFi projects -- Aave,\nUniswap, Curve Dao, Aragon, Yearn.finance, Merit Circle, and Balancer --\nplacing a primary focus on discussions related to governance issues. Despite\ndiffering activity patterns, participants across these decentralized\ncommunities consistently express positive sentiments in their Discord\ndiscussions, indicating optimism towards governance decisions. Additionally,\nour research suggests a potential interplay between discussion intensity and\nsentiment dynamics, indicating that higher discussion volumes may contribute to\nmore stable and positive emotions. The insights gained from this study are\nvaluable for decision-makers in blockchain governance, underscoring the pivotal\nrole of sentiment analysis in interpreting community emotions and its evolving\nimpact on the landscape of blockchain governance. This research significantly\ncontributes to the interdisciplinary exploration of the intersection of\nblockchain and society, with a specific emphasis on the decentralized\nblockchain governance ecosystem.\n",
                "链接": "https://arxiv.org/abs/2311.14676"
            },
            {
                "文章ID": "81153",
                "标题": "Efficient Decoding of Compositional Structure in Holistic\n  Representations",
                "作者": " Denis Kleyko,  Connor Bybee,  Ping-Chen Huang,  Christopher J. Kymn,  Bruno A. Olshausen,  E. Paxon Frady,  Friedrich T. Sommer",
                "发布日期": "2023-05-29",
                "摘要": "  We investigate the task of retrieving information from compositional\ndistributed representations formed by Hyperdimensional Computing/Vector\nSymbolic Architectures and present novel techniques which achieve new\ninformation rate bounds. First, we provide an overview of the decoding\ntechniques that can be used to approach the retrieval task. The techniques are\ncategorized into four groups. We then evaluate the considered techniques in\nseveral settings that involve, e.g., inclusion of external noise and storage\nelements with reduced precision. In particular, we find that the decoding\ntechniques from the sparse coding and compressed sensing literature (rarely\nused for Hyperdimensional Computing/Vector Symbolic Architectures) are also\nwell-suited for decoding information from the compositional distributed\nrepresentations. Combining these decoding techniques with interference\ncancellation ideas from communications improves previously reported bounds\n(Hersche et al., 2021) of the information rate of the distributed\nrepresentations from 1.20 to 1.40 bits per dimension for smaller codebooks and\nfrom 0.60 to 1.26 bits per dimension for larger codebooks.\n",
                "链接": "https://arxiv.org/abs/2305.16873"
            },
            {
                "文章ID": "89910",
                "标题": "Comparing Apples to Apples: Generating Aspect-Aware Comparative\n  Sentences from User Reviews",
                "作者": " Jessica Echterhoff,  An Yan,  Julian McAuley",
                "发布日期": "2023-07-25",
                "摘要": "  It is time-consuming to find the best product among many similar\nalternatives. Comparative sentences can help to contrast one item from others\nin a way that highlights important features of an item that stand out. Given\nreviews of one or multiple items and relevant item features, we generate\ncomparative review sentences to aid users to find the best fit. Specifically,\nour model consists of three successive components in a transformer: (i) an item\nencoding module to encode an item for comparison, (ii) a comparison generation\nmodule that generates comparative sentences in an autoregressive manner, (iii)\na novel decoding method for user personalization. We show that our pipeline\ngenerates fluent and diverse comparative sentences. We run experiments on the\nrelevance and fidelity of our generated sentences in a human evaluation study\nand find that our algorithm creates comparative review sentences that are\nrelevant and truthful.\n",
                "链接": "https://arxiv.org/abs/2307.03691"
            },
            {
                "文章ID": "81448",
                "标题": "A Comprehensive Overview and Comparative Analysis on Deep Learning\n  Models: CNN, RNN, LSTM, GRU",
                "作者": " Farhad Mortezapour Shiri,  Thinagaran Perumal,  Norwati Mustapha,  Raihani Mohamed",
                "发布日期": "2023-06-02",
                "摘要": "  Deep learning (DL) has emerged as a powerful subset of machine learning (ML)\nand artificial intelligence (AI), outperforming traditional ML methods,\nespecially in handling unstructured and large datasets. Its impact spans across\nvarious domains, including speech recognition, healthcare, autonomous vehicles,\ncybersecurity, predictive analytics, and more. However, the complexity and\ndynamic nature of real-world problems present challenges in designing effective\ndeep learning models. Consequently, several deep learning models have been\ndeveloped to address different problems and applications. In this article, we\nconduct a comprehensive survey of various deep learning models, including\nConvolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs),\nGenerative Models, Deep Reinforcement Learning (DRL), and Deep Transfer\nLearning. We examine the structure, applications, benefits, and limitations of\neach model. Furthermore, we perform an analysis using three publicly available\ndatasets: IMDB, ARAS, and Fruit-360. We compare the performance of six renowned\ndeep learning models: CNN, Simple RNN, Long Short-Term Memory (LSTM),\nBidirectional LSTM, Gated Recurrent Unit (GRU), and Bidirectional GRU.\n",
                "链接": "https://arxiv.org/abs/2305.17473"
            },
            {
                "文章ID": "118350",
                "标题": "Decoding Logic Errors: A Comparative Study on Bug Detection by Students\n  and Large Language Models",
                "作者": " Stephen MacNeil,  Paul Denny,  Andrew Tran,  Juho Leinonen,  Seth Bernstein,  Arto Hellas,  Sami Sarsa,  Joanne Kim",
                "发布日期": "2023-11-28",
                "摘要": "  Identifying and resolving logic errors can be one of the most frustrating\nchallenges for novices programmers. Unlike syntax errors, for which a compiler\nor interpreter can issue a message, logic errors can be subtle. In certain\nconditions, buggy code may even exhibit correct behavior -- in other cases, the\nissue might be about how a problem statement has been interpreted. Such errors\ncan be hard to spot when reading the code, and they can also at times be missed\nby automated tests. There is great educational potential in automatically\ndetecting logic errors, especially when paired with suitable feedback for\nnovices. Large language models (LLMs) have recently demonstrated surprising\nperformance for a range of computing tasks, including generating and explaining\ncode. These capabilities are closely linked to code syntax, which aligns with\nthe next token prediction behavior of LLMs. On the other hand, logic errors\nrelate to the runtime performance of code and thus may not be as well suited to\nanalysis by LLMs. To explore this, we investigate the performance of two\npopular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly\nexplanation of logic errors. We compare LLM performance with a large cohort of\nintroductory computing students $(n=964)$ solving the same error detection\ntask. Through a mixed-methods analysis of student and model responses, we\nobserve significant improvement in logic error identification between the\nprevious and current generation of LLMs, and find that both LLM generations\nsignificantly outperform students. We outline how such models could be\nintegrated into computing education tools, and discuss their potential for\nsupporting students when learning programming.\n",
                "链接": "https://arxiv.org/abs/2311.16017"
            },
            {
                "文章ID": "115879",
                "标题": "Speculative Contrastive Decoding",
                "作者": " Hongyi Yuan,  Keming Lu,  Fei Huang,  Zheng Yuan,  Chang Zhou",
                "发布日期": "2023-11-16",
                "摘要": "  Large language models (LLMs) have shown extraordinary performance in various\nlanguage tasks, but high computational requirements hinder their widespread\ndeployment. Speculative decoding, which uses amateur models to predict the\ngeneration of expert models, has been proposed as a way to accelerate LLM\ninference. However, speculative decoding focuses on acceleration instead of\nmaking the best use of the token distribution from amateur models. We proposed\nSpeculative Contrastive Decoding (SCD), an accelerated decoding method\nleveraging the natural contrast between expert and amateur models in\nspeculative decoding. Comprehensive evaluations on four benchmarks show that\nSCD can achieve similar acceleration factors as speculative decoding while\nfurther improving the generation quality as the contrastive decoding. The\nanalysis of token probabilities further demonstrates the compatibility between\nspeculative and contrastive decoding. Overall, SCD provides an effective\napproach to enhance the decoding quality of LLMs while saving computational\nresources.\n",
                "链接": "https://arxiv.org/abs/2311.08981"
            },
            {
                "文章ID": "32709",
                "标题": "Comparative Evaluation of Bipartite, Node-Link, and Matrix-Based Network\n  Representations",
                "作者": " Moataz Abdelaal,  Nathan D. Schiele,  Katrin Angerbauer,  Kuno Kurzhals,  Michael Sedlmair,  Daniel Weiskopf",
                "发布日期": "2022-08-10",
                "摘要": "  This work investigates and compares the performance of node-link diagrams,\nadjacency matrices, and bipartite layouts for visualizing networks. In a\ncrowd-sourced user study (n = 150), we measure the task accuracy and completion\ntime of the three representations for different network classes and properties.\nIn contrast to the literature, which covers mostly topology-based tasks (e.g.,\npath finding) in small datasets, we mainly focus on overview tasks for large\nand directed networks. We consider three overview tasks on networks with 500\nnodes: (T1) network class identification, (T2) cluster detection, and (T3)\nnetwork density estimation, and two detailed tasks: (T4) node in-degree vs.\nout-degree and (T5) representation mapping, on networks with 50 and 20 nodes,\nrespectively. Our results show that bipartite layouts are beneficial for\nrevealing the overall network structure, while adjacency matrices are most\nreliable across the different tasks.\n",
                "链接": "https://arxiv.org/abs/2208.04458"
            }
        ]
    },
    {
        "question": {
            "question": "查找大模型结合树搜索方法进行推理的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "2023年以后关于通过prompt经验性研究大语言模型行为的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "108435",
                "标题": "Formally Specifying the High-Level Behavior of LLM-Based Agents",
                "作者": " Maxwell Crouse,  Ibrahim Abdelaziz,  Kinjal Basu,  Soham Dan,  Sadhana Kumaravel,  Achille Fokoue,  Pavan Kapanipathi,  Luis Lastras",
                "发布日期": "2023-10-13",
                "摘要": "  LLM-based agents have recently emerged as promising tools for solving\nchallenging problems without the need for task-specific finetuned models that\ncan be expensive to procure. Currently, the design and implementation of such\nagents is ad hoc, as the wide variety of tasks that LLM-based agents may be\napplied to naturally means there can be no one-size-fits-all approach to agent\ndesign. In this work we aim to alleviate the difficulty of designing and\nimplementing new agents by proposing a minimalistic, high-level generation\nframework that simplifies the process of building agents. The framework we\nintroduce allows the user to specify desired agent behaviors in Linear Temporal\nLogic (LTL). The declarative LTL specification is then used to construct a\nconstrained decoder that guarantees the LLM will produce an output exhibiting\nthe desired behavior. By designing our framework in this way, we obtain several\nbenefits, including the ability to enforce complex agent behavior, the ability\nto formally validate prompt examples, and the ability to seamlessly incorporate\ncontent-focused logical constraints into generation. In particular, our\ndeclarative approach, in which the desired behavior is simply described without\nconcern for how it should be implemented or enforced, enables rapid design,\nimplementation and experimentation with different LLM-based agents. We\ndemonstrate how the proposed framework can be used to implement recent\nLLM-based agents, and show how the guardrails our approach provides can lead to\nimprovements in agent performance. In addition, we release our code for general\nuse.\n",
                "链接": "https://arxiv.org/abs/2310.08535"
            },
            {
                "文章ID": "124695",
                "标题": "Do LLM Agents Exhibit Social Behavior?",
                "作者": " Yan Leng,  Yuan Yuan",
                "发布日期": "2023-12-27",
                "摘要": "  The advances of Large Language Models (LLMs) are expanding their utility in\nboth academic research and practical applications. Recent social science\nresearch has explored the use of these \"black-box\" LLM agents for simulating\ncomplex social systems and potentially substituting human subjects in\nexperiments. Our study delves into this emerging domain, investigating the\nextent to which LLMs exhibit key social interaction principles, such as social\nlearning, social preference, and cooperative behavior, in their interactions\nwith humans and other agents. We develop a novel framework for our study,\nwherein classical laboratory experiments involving human subjects are adapted\nto use LLM agents. This approach involves step-by-step reasoning that mirrors\nhuman cognitive processes and zero-shot learning to assess the innate\npreferences of LLMs. Our analysis of LLM agents' behavior includes both the\nprimary effects and an in-depth examination of the underlying mechanisms.\nFocusing on GPT-4, the state-of-the-art LLM, our analyses suggest that LLM\nagents appear to exhibit a range of human-like social behaviors such as\ndistributional and reciprocity preferences, responsiveness to group identity\ncues, engagement in indirect reciprocity, and social learning capabilities.\nHowever, our analysis also reveals notable differences: LLMs demonstrate a\npronounced fairness preference, weaker positive reciprocity, and a more\ncalculating approach in social learning compared to humans. These insights\nindicate that while LLMs hold great promise for applications in social science\nresearch, such as in laboratory experiments and agent-based modeling, the\nsubtle behavioral differences between LLM agents and humans warrant further\ninvestigation. Careful examination and development of protocols in evaluating\nthe social behaviors of LLMs are necessary before directly applying these\nmodels to emulate human behavior.\n",
                "链接": "https://arxiv.org/abs/2312.15198"
            },
            {
                "文章ID": "17880",
                "标题": "Reproducibility Beyond the Research Community: Experience from NLP\n  Beginners",
                "作者": " Shane Storks,  Keunwoo Peter Yu,  Joyce Chai",
                "发布日期": "2022-05-19",
                "摘要": "  As NLP research attracts public attention and excitement, it becomes\nincreasingly important for it to be accessible to a broad audience. As the\nresearch community works to democratize NLP, it remains unclear whether\nbeginners to the field can easily apply the latest developments. To understand\ntheir needs, we conducted a study with 93 students in an introductory NLP\ncourse, where students reproduced results of recent NLP papers. Surprisingly,\nour results suggest that their technical skill (i.e., programming experience)\nhas limited impact on their effort spent completing the exercise. Instead, we\nfind accessibility efforts by research authors to be key to a successful\nexperience, including thorough documentation and easy access to required models\nand datasets.\n",
                "链接": "https://arxiv.org/abs/2205.02182"
            },
            {
                "文章ID": "109419",
                "标题": "Analyzing Behavior and User Experience in Online Museum Virtual Tours",
                "作者": " Roman Shikhri,  Lev Poretski,  Joel Lanir",
                "发布日期": "2023-10-18",
                "摘要": "  The disruption to tourism and travel caused by the COVID-related health\ncrisis highlighted the potential of virtual tourism to provide a universally\naccessible way to engage in cultural experiences. 360-degree virtual tours,\nshowing a realistic representation of the physical location, enable virtual\ntourists to experience cultural heritage sites and engage with their\ncollections from the comfort and safety of their home. However, there is no\nclear standard for the design of such tours and the experience of visitors may\nvary widely from platform to platform. We first conducted a comprehensive\nanalysis of 40 existing virtual tours, constructing a descriptive framework for\nunderstanding the key components and characteristics of virtual tours. Next, we\nconducted a remote usability study to gain deeper insights into the actual\nexperiences and challenges faced by VT users. Our investigation revealed a\nsignificant disparity between users' mental models of virtual tours and the\nactual system behavior. We discuss these issues and provide concrete\nrecommendations for the creation of better, user-friendly 360-degree virtual\ntours.\n",
                "链接": "https://arxiv.org/abs/2310.11176"
            },
            {
                "文章ID": "105224",
                "标题": "Overview of the BioLaySumm 2023 Shared Task on Lay Summarization of\n  Biomedical Research Articles",
                "作者": " Tomas Goldsack,  Zheheng Luo,  Qianqian Xie,  Carolina Scarton,  Matthew Shardlow,  Sophia Ananiadou,  Chenghua Lin",
                "发布日期": "2023-10-26",
                "摘要": "  This paper presents the results of the shared task on Lay Summarisation of\nBiomedical Research Articles (BioLaySumm), hosted at the BioNLP Workshop at ACL\n2023. The goal of this shared task is to develop abstractive summarisation\nmodels capable of generating \"lay summaries\" (i.e., summaries that are\ncomprehensible to non-technical audiences) in both a controllable and\nnon-controllable setting. There are two subtasks: 1) Lay Summarisation, where\nthe goal is for participants to build models for lay summary generation only,\ngiven the full article text and the corresponding abstract as input; and 2)\nReadability-controlled Summarisation, where the goal is for participants to\ntrain models to generate both the technical abstract and the lay summary, given\nan article's main text as input. In addition to overall results, we report on\nthe setup and insights from the BioLaySumm shared task, which attracted a total\nof 20 participating teams across both subtasks.\n",
                "链接": "https://arxiv.org/abs/2309.17332"
            },
            {
                "文章ID": "94596",
                "标题": "Avatar Fusion Karaoke: Research and development on multi-user music play\n  VR experience in the metaverse",
                "作者": " Alexandre Berthault,  Takuma Kato,  Akihiko Shirai",
                "发布日期": "2023-08-07",
                "摘要": "  This paper contributes to building a standard process of research and\ndevelopment (R&D) for new user experiences (UX) in metaverse services. We\ntested this R&D process on a new UX proof of concept (PoC) for Meta Quest\nhead-mounted display (HMDs) consisting of a school-life karaoke experience with\nthe hypothesis that it is possible to design the avatars with only the\nnecessary functions and rendering costs. The school life metaverse is a\nrelevant subject for discovering issues and problems in this type of\nsimultaneous connection. To qualitatively evaluate the potential of a\nmulti-person metaverse experience, this study investigated subjects where each\navatar requires expressive skills. While avatar play experiences feature\nartistic expressions, such as dancing, playing musical instruments, and\ndrawing, and these can be used to evaluate their operability and expressive\ncapabilities qualitatively, the Quest's tracking capabilities are insufficient\nfor full-body performance and graphical art expression. Considering such\nhardware limitations, this study evaluated the Quest, focusing primarily on UX\nsimplicity using AI Fusion techniques and expressiveness in instrumental scenes\nplayed by approximately four avatars. This research reported methods for\nmultiuser metaverse communication and its supporting technologies, such as\nhead-mounted devices and their graphics performance, special interaction\ntechniques, and complementary tools and the importance of PoC development, its\nevaluation, and its iterations. The result is remarkable for further research;\nthese expressive technologies in a multi-user context are directly related to\nthe quality of communication within the metaverse and the value of the\nuser-generated content (UGC) produced there.\n",
                "链接": "https://arxiv.org/abs/2308.02139"
            },
            {
                "文章ID": "9283",
                "标题": "Research on Parallel SVM Algorithm Based on Cascade SVM",
                "作者": " Yi Cheng,   Liu,   XiaoYan,   Liu",
                "发布日期": "2022-03-14",
                "摘要": "  Cascade SVM (CSVM) can group datasets and train subsets in parallel, which\ngreatly reduces the training time and memory consumption. However, the model\naccuracy obtained by using this method has some errors compared with direct\ntraining. In order to reduce the error, we analyze the causes of error in\ngrouping training, and summarize the grouping without error under ideal\nconditions. A Balanced Cascade SVM (BCSVM) algorithm is proposed, which\nbalances the sample proportion in the subset after grouping to ensure that the\nsample proportion in the subset is the same as the original dataset. At the\nsame time, it proves that the accuracy of the model obtained by BCSVM algorithm\nis higher than that of CSVM. Finally, two common datasets are used for\nexperimental verification, and the results show that the accuracy error\nobtained by using BCSVM algorithm is reduced from 1% of CSVM to 0.1%, which is\nreduced by an order of magnitude.\n",
                "链接": "https://arxiv.org/abs/2203.05768"
            },
            {
                "文章ID": "105730",
                "标题": "SPELL: Semantic Prompt Evolution based on a LLM",
                "作者": " Yujian Betterest Li,  Kai Wu",
                "发布日期": "2023-10-03",
                "摘要": "  Prompt engineering is a new paradigm for enhancing the performance of trained\nneural network models. For optimizing text-style prompts, existing methods\nusually individually operate small portions of a text step by step, which\neither breaks the fluency or could not globally adjust a prompt. Since large\nlanguage models (LLMs) have powerful ability of generating coherent texts token\nby token, can we utilize LLMs for improving prompts? Based on this motivation,\nin this paper, considering a trained LLM as a text generator, we attempt to\ndesign a black-box evolution algorithm for automatically optimizing texts,\nnamely SPELL (Semantic Prompt Evolution based on a LLM). The proposed method is\nevaluated with different LLMs and evolution parameters in different text tasks.\nExperimental results show that SPELL could rapidly improve the prompts indeed.\nWe further explore the evolution process and discuss on the limitations,\npotential possibilities and future work.\n",
                "链接": "https://arxiv.org/abs/2310.01260"
            },
            {
                "文章ID": "75914",
                "标题": "Repairing Deep Neural Networks Based on Behavior Imitation",
                "作者": " Zhen Liang,  Taoran Wu,  Changyuan Zhao,  Wanwei Liu,  Bai Xue,  Wenjing Yang,  Ji Wang",
                "发布日期": "2023-05-09",
                "摘要": "  The increasing use of deep neural networks (DNNs) in safety-critical systems\nhas raised concerns about their potential for exhibiting ill-behaviors. While\nDNN verification and testing provide post hoc conclusions regarding unexpected\nbehaviors, they do not prevent the erroneous behaviors from occurring. To\naddress this issue, DNN repair/patch aims to eliminate unexpected predictions\ngenerated by defective DNNs. Two typical DNN repair paradigms are retraining\nand fine-tuning. However, existing methods focus on the high-level abstract\ninterpretation or inference of state spaces, ignoring the underlying neurons'\noutputs. This renders patch processes computationally prohibitive and limited\nto piecewise linear (PWL) activation functions to great extent. To address\nthese shortcomings, we propose a behavior-imitation based repair framework,\nBIRDNN, which integrates the two repair paradigms for the first time. BIRDNN\ncorrects incorrect predictions of negative samples by imitating the closest\nexpected behaviors of positive samples during the retraining repair procedure.\nFor the fine-tuning repair process, BIRDNN analyzes the behavior differences of\nneurons on positive and negative samples to identify the most responsible\nneurons for the erroneous behaviors. To tackle more challenging domain-wise\nrepair problems (DRPs), we synthesize BIRDNN with a domain behavior\ncharacterization technique to repair buggy DNNs in a probably approximated\ncorrect style. We also implement a prototype tool based on BIRDNN and evaluate\nit on ACAS Xu DNNs. Our experimental results show that BIRDNN can successfully\nrepair buggy DNNs with significantly higher efficiency than state-of-the-art\nrepair tools. Additionally, BIRDNN is highly compatible with different\nactivation functions.\n",
                "链接": "https://arxiv.org/abs/2305.03365"
            },
            {
                "文章ID": "83871",
                "标题": "Student Classroom Behavior Detection based on Improved YOLOv7",
                "作者": " Fan Yang",
                "发布日期": "2023-06-07",
                "摘要": "  Accurately detecting student behavior in classroom videos can aid in\nanalyzing their classroom performance and improving teaching effectiveness.\nHowever, the current accuracy rate in behavior detection is low. To address\nthis challenge, we propose the Student Classroom Behavior Detection method,\nbased on improved YOLOv7. First, we created the Student Classroom Behavior\ndataset (SCB-Dataset), which includes 18.4k labels and 4.2k images, covering\nthree behaviors: hand raising, reading, and writing. To improve detection\naccuracy in crowded scenes, we integrated the biformer attention module and\nWise-IoU into the YOLOv7 network. Finally, experiments were conducted on the\nSCB-Dataset, and the model achieved an mAP@0.5 of 79%, resulting in a 1.8%\nimprovement over previous results. The SCB-Dataset and code are available for\ndownload at: https://github.com/Whiffe/SCB-dataset.\n",
                "链接": "https://arxiv.org/abs/2306.03318"
            }
        ]
    },
    {
        "question": {
            "question": "利用大模型做数学题生成的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "122573",
                "标题": "Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human\n  Annotations",
                "作者": " Peiyi Wang,  Lei Li,  Zhihong Shao,  R. X. Xu,  Damai Dai,  Yifei Li,  Deli Chen,  Y. Wu,  Zhifang Sui",
                "发布日期": "2023-12-29",
                "摘要": "  In this paper, we present an innovative process-oriented math process reward\nmodel called \\textbf{Math-Shepherd}, which assigns a reward score to each step\nof math problem solutions. The training of Math-Shepherd is achieved using\nautomatically constructed process-wise supervision data, breaking the\nbottleneck of heavy reliance on manual annotation in existing work. We explore\nthe effectiveness of Math-Shepherd in two scenarios: 1) \\textit{Verification}:\nMath-Shepherd is utilized for reranking multiple outputs generated by Large\nLanguage Models (LLMs); 2) \\textit{Reinforcement Learning}: Math-Shepherd is\nemployed to reinforce LLMs with step-by-step Proximal Policy Optimization\n(PPO). With Math-Shepherd, a series of open-source LLMs demonstrates\nexceptional performance. For instance, the step-by-step PPO with Math-Shepherd\nsignificantly improves the accuracy of Mistral-7B (77.9\\%$\\to$84.1\\% on GSM8K\nand 28.6\\%$\\to$33.0\\% on MATH). The accuracy can be further enhanced to 89.1\\%\nand 43.5\\% on GSM8K and MATH with the verification of Math-Shepherd,\nrespectively. We believe that automatic process supervision holds significant\npotential for the future evolution of LLMs.\n",
                "链接": "https://arxiv.org/abs/2312.08935"
            },
            {
                "文章ID": "79980",
                "标题": "Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with\n  Customized Exercise Generation",
                "作者": " Zhenwen Liang,  Wenhao Yu,  Tanmay Rajpurohit,  Peter Clark,  Xiangliang Zhang,  Ashwin Kaylan",
                "发布日期": "2023-05-25",
                "摘要": "  In this paper, we present a novel approach for distilling math word problem\nsolving capabilities from large language models (LLMs) into smaller, more\nefficient student models. Our approach is designed to consider the student\nmodel's weaknesses and foster a tailored learning experience by generating\ntargeted exercises aligned with educational science principles, such as\nknowledge tracing and personalized learning. Concretely, we let GPT-3 be a math\ntutor and run two steps iteratively: 1) assessing the student model's current\nlearning status on a GPT-generated exercise book, and 2) improving the student\nmodel by training it with tailored exercise samples generated by GPT-3.\nExperimental results reveal that our approach outperforms LLMs (e.g., GPT-3 and\nPaLM) in accuracy across three distinct benchmarks while employing\nsignificantly fewer parameters. Furthermore, we provide a comprehensive\nanalysis of the various components within our methodology to substantiate their\nefficacy.\n",
                "链接": "https://arxiv.org/abs/2305.14386"
            },
            {
                "文章ID": "108984",
                "标题": "Improving Large Language Model Fine-tuning for Solving Math Problems",
                "作者": " Yixin Liu,  Avi Singh,  C. Daniel Freeman,  John D. Co-Reyes,  Peter J. Liu",
                "发布日期": "2023-10-17",
                "摘要": "  Despite their success in many natural language tasks, solving math problems\nremains a significant challenge for large language models (LLMs). A large gap\nexists between LLMs' pass-at-one and pass-at-N performance in solving math\nproblems, suggesting LLMs might be close to finding correct solutions,\nmotivating our exploration of fine-tuning methods to unlock LLMs' performance.\nUsing the challenging MATH dataset, we investigate three fine-tuning\nstrategies: (1) solution fine-tuning, where we fine-tune to generate a detailed\nsolution for a given math problem; (2) solution-cluster re-ranking, where the\nLLM is fine-tuned as a solution verifier/evaluator to choose among generated\ncandidate solution clusters; (3) multi-task sequential fine-tuning, which\nintegrates both solution generation and evaluation tasks together efficiently\nto enhance the LLM performance. With these methods, we present a thorough\nempirical study on a series of PaLM 2 models and find: (1) The quality and\nstyle of the step-by-step solutions used for fine-tuning can make a significant\nimpact on the model performance; (2) While solution re-ranking and majority\nvoting are both effective for improving the model performance when used\nseparately, they can also be used together for an even greater performance\nboost; (3) Multi-task fine-tuning that sequentially separates the solution\ngeneration and evaluation tasks can offer improved performance compared with\nthe solution fine-tuning baseline. Guided by these insights, we design a\nfine-tuning recipe that yields approximately 58.8% accuracy on the MATH dataset\nwith fine-tuned PaLM 2-L models, an 11.2% accuracy improvement over the\nfew-shot performance of pre-trained PaLM 2-L model with majority voting.\n",
                "链接": "https://arxiv.org/abs/2310.10047"
            },
            {
                "文章ID": "101406",
                "标题": "MAmmoTH: Building Math Generalist Models through Hybrid Instruction\n  Tuning",
                "作者": " Xiang Yue,  Xingwei Qu,  Ge Zhang,  Yao Fu,  Wenhao Huang,  Huan Sun,  Yu Su,  Wenhu Chen",
                "发布日期": "2023-10-04",
                "摘要": "  We introduce MAmmoTH, a series of open-source large language models (LLMs)\nspecifically tailored for general math problem-solving. The MAmmoTH models are\ntrained on MathInstruct, our meticulously curated instruction tuning dataset.\nMathInstruct is compiled from 13 math datasets with intermediate rationales,\nsix of which have rationales newly curated by us. It presents a unique hybrid\nof chain-of-thought (CoT) and program-of-thought (PoT) rationales, and also\nensures extensive coverage of diverse fields in math. The hybrid of CoT and PoT\nnot only unleashes the potential of tool use but also allows different thought\nprocesses for different math problems. As a result, the MAmmoTH series\nsubstantially outperform existing open-source models on nine mathematical\nreasoning datasets across all scales with an average accuracy gain between 16%\nand 32%. Remarkably, our MAmmoTH-7B model reaches 33% on MATH (a\ncompetition-level dataset), which exceeds the best open-source 7B model\n(WizardMath) by 23%, and the MAmmoTH-34B model achieves 44% accuracy on MATH,\neven surpassing GPT-4's CoT result. Our work underscores the importance of\ndiverse problem coverage and the use of hybrid rationales in developing\nsuperior math generalist models.\n",
                "链接": "https://arxiv.org/abs/2309.05653"
            },
            {
                "文章ID": "121729",
                "标题": "Beyond Human Data: Scaling Self-Training for Problem-Solving with\n  Language Models",
                "作者": " Avi Singh,  John D. Co-Reyes,  Rishabh Agarwal,  Ankesh Anand,  Piyush Patil,  Xavier Garcia,  Peter J. Liu,  James Harrison,  Jaehoon Lee,  Kelvin Xu,  Aaron Parisi,  Abhishek Kumar,  Alex Alemi,  Alex Rizkowsky,  Azade Nova,  Ben Adlam,  Bernd Bohnet,  Gamaleldin Elsayed,  Hanie Sedghi,  Igor Mordatch,  Isabelle Simpson,  Izzeddin Gur,  Jasper Snoek,  Jeffrey Pennington,  Jiri Hron,  Kathleen Kenealy,  Kevin Swersky,  Kshiteej Mahajan,  Laura Culp,  Lechao Xiao,  Maxwell L. Bileschi,  Noah Constant,  Roman Novak,  Rosanne Liu,  Tris Warkentin,  Yundi Qian,  Yamini Bansal,  Ethan Dyer,  Behnam Neyshabur,  Jascha Sohl-Dickstein,  Noah Fiedel",
                "发布日期": "2023-12-25",
                "摘要": "  Fine-tuning language models~(LMs) on human-generated data remains a prevalent\npractice. However, the performance of such models is often limited by the\nquantity and diversity of high-quality human data. In this paper, we explore\nwhether we can go beyond human data on tasks where we have access to scalar\nfeedback, for example, on math problems where one can verify correctness. To do\nso, we investigate a simple self-training method based on\nexpectation-maximization, which we call ReST$^{EM}$, where we (1) generate\nsamples from the model and filter them using binary feedback, (2) fine-tune the\nmodel on these samples, and (3) repeat this process a few times. Testing on\nadvanced MATH reasoning and APPS coding benchmarks using PaLM-2 models, we find\nthat ReST$^{EM}$ scales favorably with model size and significantly surpasses\nfine-tuning only on human data. Overall, our findings suggest self-training\nwith feedback can substantially reduce dependence on human-generated data.\n",
                "链接": "https://arxiv.org/abs/2312.06585"
            },
            {
                "文章ID": "105901",
                "标题": "Large Language Models as Analogical Reasoners",
                "作者": " Michihiro Yasunaga,  Xinyun Chen,  Yujia Li,  Panupong Pasupat,  Jure Leskovec,  Percy Liang,  Ed H. Chi,  Denny Zhou",
                "发布日期": "2023-10-10",
                "摘要": "  Chain-of-thought (CoT) prompting for language models demonstrates impressive\nperformance across reasoning tasks, but typically needs labeled exemplars of\nthe reasoning process. In this work, we introduce a new prompting approach,\nAnalogical Prompting, designed to automatically guide the reasoning process of\nlarge language models. Inspired by analogical reasoning, a cognitive process in\nwhich humans draw from relevant past experiences to tackle new problems, our\napproach prompts language models to self-generate relevant exemplars or\nknowledge in the context, before proceeding to solve the given problem. This\nmethod presents several advantages: it obviates the need for labeling or\nretrieving exemplars, offering generality and convenience; it can also tailor\nthe generated exemplars and knowledge to each problem, offering adaptability.\nExperimental results show that our approach outperforms 0-shot CoT and manual\nfew-shot CoT in a variety of reasoning tasks, including math problem solving in\nGSM8K and MATH, code generation in Codeforces, and other reasoning tasks in\nBIG-Bench.\n",
                "链接": "https://arxiv.org/abs/2310.01714"
            },
            {
                "文章ID": "84264",
                "标题": "World Models for Math Story Problems",
                "作者": " Andreas Opedal,  Niklas Stoehr,  Abulhair Saparov,  Mrinmaya Sachan",
                "发布日期": "2023-06-08",
                "摘要": "  Solving math story problems is a complex task for students and NLP models\nalike, requiring them to understand the world as described in the story and\nreason over it to compute an answer. Recent years have seen impressive\nperformance on automatically solving these problems with large pre-trained\nlanguage models and innovative techniques to prompt them. However, it remains\nunclear if these models possess accurate representations of mathematical\nconcepts. This leads to lack of interpretability and trustworthiness which\nimpedes their usefulness in various applications. In this paper, we consolidate\nprevious work on categorizing and representing math story problems and develop\nMathWorld, which is a graph-based semantic formalism specific for the domain of\nmath story problems. With MathWorld, we can assign world models to math story\nproblems which represent the situations and actions introduced in the text and\ntheir mathematical relationships. We combine math story problems from several\nexisting datasets and annotate a corpus of 1,019 problems and 3,204 logical\nforms with MathWorld. Using this data, we demonstrate the following use cases\nof MathWorld: (1) prompting language models with synthetically generated\nquestion-answer pairs to probe their reasoning and world modeling abilities,\nand (2) generating new problems by using the world models as a design space.\n",
                "链接": "https://arxiv.org/abs/2306.04347"
            },
            {
                "文章ID": "106447",
                "标题": "Retrieval-augmented Generation to Improve Math Question-Answering:\n  Trade-offs Between Groundedness and Human Preference",
                "作者": " Zachary Levonian,  Chenglu Li,  Wangda Zhu,  Anoushka Gade,  Owen Henkel,  Millie-Ellen Postle,  Wanli Xing",
                "发布日期": "2023-11-14",
                "摘要": "  For middle-school math students, interactive question-answering (QA) with\ntutors is an effective way to learn. The flexibility and emergent capabilities\nof generative large language models (LLMs) has led to a surge of interest in\nautomating portions of the tutoring process - including interactive QA to\nsupport conceptual discussion of mathematical concepts. However, LLM responses\nto math questions can be incorrect or mismatched to the educational context -\nsuch as being misaligned with a school's curriculum. One potential solution is\nretrieval-augmented generation (RAG), which involves incorporating a vetted\nexternal knowledge source in the LLM prompt to increase response quality. In\nthis paper, we designed prompts that retrieve and use content from a\nhigh-quality open-source math textbook to generate responses to real student\nquestions. We evaluate the efficacy of this RAG system for middle-school\nalgebra and geometry QA by administering a multi-condition survey, finding that\nhumans prefer responses generated using RAG, but not when responses are too\ngrounded in the textbook content. We argue that while RAG is able to improve\nresponse quality, designers of math QA systems must consider trade-offs between\ngenerating responses preferred by students and responses closely matched to\nspecific educational resources.\n",
                "链接": "https://arxiv.org/abs/2310.03184"
            },
            {
                "文章ID": "97157",
                "标题": "WizardMath: Empowering Mathematical Reasoning for Large Language Models\n  via Reinforced Evol-Instruct",
                "作者": " Haipeng Luo,  Qingfeng Sun,  Can Xu,  Pu Zhao,  Jianguang Lou,  Chongyang Tao,  Xiubo Geng,  Qingwei Lin,  Shifeng Chen,  Dongmei Zhang",
                "发布日期": "2023-08-21",
                "摘要": "  Large language models (LLMs), such as GPT-4, have shown remarkable\nperformance in natural language processing (NLP) tasks, including challenging\nmathematical reasoning. However, most existing open-source models are only\npre-trained on large-scale internet data and without math-related optimization.\nIn this paper, we present WizardMath, which enhances the mathematical reasoning\nabilities of Llama-2, by applying our proposed Reinforcement Learning from\nEvol-Instruct Feedback (RLEIF) method to the domain of math. Through extensive\nexperiments on two mathematical reasoning benchmarks, namely GSM8k and MATH, we\nreveal the extraordinary capabilities of our model. WizardMath surpasses all\nother open-source LLMs by a substantial margin. Furthermore, our model even\noutperforms ChatGPT-3.5, Claude Instant-1, PaLM-2 and Minerva on GSM8k,\nsimultaneously surpasses Text-davinci-002, PaLM-1 and GPT-3 on MATH. More\ndetails and model weights are public at https://github.com/nlpxucan/WizardLM\nand https://huggingface.co/WizardLM.\n",
                "链接": "https://arxiv.org/abs/2308.09583"
            },
            {
                "文章ID": "112914",
                "标题": "Learning From Mistakes Makes LLM Better Reasoner",
                "作者": " Shengnan An,  Zexiong Ma,  Zeqi Lin,  Nanning Zheng,  Jian-Guang Lou,  Weizhu Chen",
                "发布日期": "2023-11-15",
                "摘要": "  Large language models (LLMs) recently exhibited remarkable reasoning\ncapabilities on solving math problems. To further improve this capability, this\nwork proposes Learning from Mistakes (LeMa), akin to human learning processes.\nConsider a human student who failed to solve a math problem, he will learn from\nwhat mistake he has made and how to correct it. Mimicking this error-driven\nlearning process, LeMa fine-tunes LLMs on mistake-correction data pairs\ngenerated by GPT-4. Specifically, we first collect inaccurate reasoning paths\nfrom various LLMs and then employ GPT-4 as a \"corrector\" to (1) identify the\nmistake step, (2) explain the reason for the mistake, and (3) correct the\nmistake and generate the final answer. Experimental results demonstrate the\neffectiveness of LeMa: across five backbone LLMs and two mathematical reasoning\ntasks, LeMa consistently improves the performance compared with fine-tuning on\nCoT data alone. Impressively, LeMa can also benefit specialized LLMs such as\nWizardMath and MetaMath, achieving 85.4% pass@1 accuracy on GSM8K and 27.1% on\nMATH. This surpasses the SOTA performance achieved by non-execution open-source\nmodels on these challenging tasks. Our code, data and models will be publicly\navailable at https://github.com/microsoft/LEMA.\n",
                "链接": "https://arxiv.org/abs/2310.20689"
            }
        ]
    }
]