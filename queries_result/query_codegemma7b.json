[
    {
        "question": {
            "question": "与大模型工具学习相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "115852",
                "标题": "Enabling Large Language Models to Learn from Rules",
                "作者": " Wenkai Yang,  Yankai Lin,  Jie Zhou,  Jirong Wen",
                "发布日期": "2023-11-16",
                "摘要": "  Large language models (LLMs) have shown incredible performance in completing\nvarious real-world tasks. The current knowledge learning paradigm of LLMs is\nmainly based on learning from examples, in which LLMs learn the internal rule\nimplicitly from a certain number of supervised examples. However, the learning\nparadigm may not well learn those complicated rules, especially when the\ntraining examples are limited. We are inspired that humans can learn the new\ntasks or knowledge in another way by learning from rules. That is, humans can\ngrasp the new tasks or knowledge quickly and generalize well given only a\ndetailed rule and a few optional examples. Therefore, in this paper, we aim to\nexplore the feasibility of this new learning paradigm, which encodes the\nrule-based knowledge into LLMs. We propose rule distillation, which first uses\nthe strong in-context abilities of LLMs to extract the knowledge from the\ntextual rules and then explicitly encode the knowledge into LLMs' parameters by\nlearning from the above in-context signals produced inside the model. Our\nexperiments show that making LLMs learn from rules by our method is much more\nefficient than example-based learning in both the sample size and\ngeneralization ability.\n",
                "链接": "https://arxiv.org/abs/2311.08883"
            },
            {
                "文章ID": "44321",
                "标题": "What do Large Language Models Learn beyond Language?",
                "作者": " Avinash Madasu,  Shashank Srivastava",
                "发布日期": "2022-10-25",
                "摘要": "  Large language models (LMs) have rapidly become a mainstay in Natural\nLanguage Processing. These models are known to acquire rich linguistic\nknowledge from training on large amounts of text. In this paper, we investigate\nif pre-training on text also confers these models with helpful `inductive\nbiases' for non-linguistic reasoning. On a set of 19 diverse non-linguistic\ntasks involving quantitative computations, recognizing regular expressions and\nreasoning over strings. We find that pretrained models significantly outperform\ncomparable non-pretrained neural models. This remains true also in experiments\nwith training non-pretrained models with fewer parameters to account for model\nregularization effects. We further explore the effect of text domain on LMs by\npretraining models from text from different domains and provenances. Our\nexperiments surprisingly reveal that the positive effects of pre-training\npersist even when pretraining on multi-lingual text or computer code, and even\nfor text generated from synthetic languages. Our findings suggest a hitherto\nunexplored deep connection between pre-training and inductive learning\nabilities of language models.\n",
                "链接": "https://arxiv.org/abs/2210.12302"
            },
            {
                "文章ID": "107887",
                "标题": "Large Language Models can Learn Rules",
                "作者": " Zhaocheng Zhu,  Yuan Xue,  Xinyun Chen,  Denny Zhou,  Jian Tang,  Dale Schuurmans,  Hanjun Dai",
                "发布日期": "2023-10-12",
                "摘要": "  When prompted with a few examples and intermediate steps, large language\nmodels (LLMs) have demonstrated impressive performance in various reasoning\ntasks. However, prompting methods that rely on implicit knowledge in an LLM\noften hallucinate incorrect answers when the implicit knowledge is wrong or\ninconsistent with the task. To tackle this problem, we present\nHypotheses-to-Theories (HtT), a framework that learns a rule library for\nreasoning with LLMs. HtT contains two stages, an induction stage and a\ndeduction stage. In the induction stage, an LLM is first asked to generate and\nverify rules over a set of training examples. Rules that appear and lead to\ncorrect answers sufficiently often are collected to form a rule library. In the\ndeduction stage, the LLM is then prompted to employ the learned rule library to\nperform reasoning to answer test questions. Experiments on both numerical\nreasoning and relational reasoning problems show that HtT improves existing\nprompting methods, with an absolute gain of 11-27% in accuracy. The learned\nrules are also transferable to different models and to different forms of the\nsame problem.\n",
                "链接": "https://arxiv.org/abs/2310.07064"
            },
            {
                "文章ID": "42615",
                "标题": "Transparency Helps Reveal When Language Models Learn Meaning",
                "作者": " Zhaofeng Wu,  William Merrill,  Hao Peng,  Iz Beltagy,  Noah A. Smith",
                "发布日期": "2023-03-07",
                "摘要": "  Many current NLP systems are built from language models trained to optimize\nunsupervised objectives on large amounts of raw text. Under what conditions\nmight such a procedure acquire meaning? Our systematic experiments with\nsynthetic data reveal that, with languages where all expressions have\ncontext-independent denotations (i.e., languages with strong transparency),\nboth autoregressive and masked language models successfully learn to emulate\nsemantic relations between expressions. However, when denotations are changed\nto be context-dependent with the language otherwise unmodified, this ability\ndegrades. Turning to natural language, our experiments with a specific\nphenomenon -- referential opacity -- add to the growing body of evidence that\ncurrent language models do not represent natural language semantics well. We\nshow this failure relates to the context-dependent nature of natural language\nform-meaning mappings.\n",
                "链接": "https://arxiv.org/abs/2210.07468"
            },
            {
                "文章ID": "48600",
                "标题": "Large Language Models Struggle to Learn Long-Tail Knowledge",
                "作者": " Nikhil Kandpal,  Haikang Deng,  Adam Roberts,  Eric Wallace,  Colin Raffel",
                "发布日期": "2023-07-28",
                "摘要": "  The Internet contains a wealth of knowledge -- from the birthdays of\nhistorical figures to tutorials on how to code -- all of which may be learned\nby language models. However, while certain pieces of information are ubiquitous\non the web, others appear extremely rarely. In this paper, we study the\nrelationship between the knowledge memorized by large language models and the\ninformation in pre-training datasets scraped from the web. In particular, we\nshow that a language model's ability to answer a fact-based question relates to\nhow many documents associated with that question were seen during pre-training.\nWe identify these relevant documents by entity linking pre-training datasets\nand counting documents that contain the same entities as a given\nquestion-answer pair. Our results demonstrate strong correlational and causal\nrelationships between accuracy and relevant document count for numerous\nquestion answering datasets (e.g., TriviaQA), pre-training corpora (e.g.,\nROOTS), and model sizes (e.g., 176B parameters). Moreover, while larger models\nare better at learning long-tail knowledge, we estimate that today's models\nmust be scaled by many orders of magnitude to reach competitive QA performance\non questions with little support in the pre-training data. Finally, we show\nthat retrieval-augmentation can reduce the dependence on relevant pre-training\ninformation, presenting a promising approach for capturing the long-tail.\n",
                "链接": "https://arxiv.org/abs/2211.08411"
            },
            {
                "文章ID": "125056",
                "标题": "More than Correlation: Do Large Language Models Learn Causal\n  Representations of Space?",
                "作者": " Yida Chen,  Yixian Gan,  Sijia Li,  Li Yao,  Xiaohan Zhao",
                "发布日期": "2023-12-29",
                "摘要": "  Recent work found high mutual information between the learned representations\nof large language models (LLMs) and the geospatial property of its input,\nhinting an emergent internal model of space. However, whether this internal\nspace model has any causal effects on the LLMs' behaviors was not answered by\nthat work, led to criticism of these findings as mere statistical correlation.\nOur study focused on uncovering the causality of the spatial representations in\nLLMs. In particular, we discovered the potential spatial representations in\nDeBERTa, GPT-Neo using representational similarity analysis and linear and\nnon-linear probing. Our casual intervention experiments showed that the spatial\nrepresentations influenced the model's performance on next word prediction and\na downstream task that relies on geospatial information. Our experiments\nsuggested that the LLMs learn and use an internal model of space in solving\ngeospatial related tasks.\n",
                "链接": "https://arxiv.org/abs/2312.16257"
            },
            {
                "文章ID": "92072",
                "标题": "Dynamic Large Language Models on Blockchains",
                "作者": " Yuanhao Gong",
                "发布日期": "2023-07-21",
                "摘要": "  Training and deploying the large language models requires a large mount of\ncomputational resource because the language models contain billions of\nparameters and the text has thousands of tokens. Another problem is that the\nlarge language models are static. They are fixed after the training process. To\ntackle these issues, in this paper, we propose to train and deploy the dynamic\nlarge language model on blockchains, which have high computation performance\nand are distributed across a network of computers. A blockchain is a secure,\ndecentralized, and transparent system that allows for the creation of a\ntamper-proof ledger for transactions without the need for intermediaries. The\ndynamic large language models can continuously learn from the user input after\nthe training process. Our method provides a new way to develop the large\nlanguage models and also sheds a light on the next generation artificial\nintelligence systems.\n",
                "链接": "https://arxiv.org/abs/2307.10549"
            },
            {
                "文章ID": "18360",
                "标题": "Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text\n  Correspondence",
                "作者": " Myeongjun Jang,  Frank Mtumbuka,  Thomas Lukasiewicz",
                "发布日期": "2022-08-12",
                "摘要": "  The logical negation property (LNP), which implies generating different\npredictions for semantically opposite inputs, is an important property that a\ntrustworthy language model must satisfy. However, much recent evidence shows\nthat large-size pre-trained language models (PLMs) do not satisfy this\nproperty. In this paper, we perform experiments using probing tasks to assess\nPLM's LNP understanding. Unlike previous studies that only examined negation\nexpressions, we expand the boundary of the investigation to lexical semantics.\nThrough experiments, we observe that PLMs violate the LNP frequently. To\nalleviate the issue, we propose a novel intermediate training task, names\nmeaning-matching, designed to directly learn a meaning-text correspondence,\ninstead of relying on the distributional hypothesis. Through multiple\nexperiments, we find that the task enables PLMs to learn lexical semantic\ninformation. Also, through fine-tuning experiments on 7 GLUE tasks, we confirm\nthat it is a safe intermediate task that guarantees a similar or better\nperformance of downstream tasks. Finally, we observe that our proposed approach\noutperforms our previous counterparts despite its time and resource efficiency.\n",
                "链接": "https://arxiv.org/abs/2205.03815"
            },
            {
                "文章ID": "99139",
                "标题": "Large language models converge toward human-like concept organization",
                "作者": " Mathias Lykke Gammelgaard,  Jonathan Gabel Christiansen,  Anders Søgaard",
                "发布日期": "2023-08-30",
                "摘要": "  Large language models show human-like performance in knowledge extraction,\nreasoning and dialogue, but it remains controversial whether this performance\nis best explained by memorization and pattern matching, or whether it reflects\nhuman-like inferential semantics and world knowledge. Knowledge bases such as\nWikiData provide large-scale, high-quality representations of inferential\nsemantics and world knowledge. We show that large language models learn to\norganize concepts in ways that are strikingly similar to how concepts are\norganized in such knowledge bases. Knowledge bases model collective,\ninstitutional knowledge, and large language models seem to induce such\nknowledge from raw text. We show that bigger and better models exhibit more\nhuman-like concept organization, across four families of language models and\nthree knowledge graph embeddings.\n",
                "链接": "https://arxiv.org/abs/2308.15047"
            },
            {
                "文章ID": "85815",
                "标题": "Knowledge Distillation of Large Language Models",
                "作者": " Yuxian Gu,  Li Dong,  Furu Wei,  Minlie Huang",
                "发布日期": "2023-06-16",
                "摘要": "  Knowledge Distillation (KD) is a promising technique for reducing the high\ncomputational demand of large language models (LLMs). However, previous KD\nmethods are primarily applied to white-box classification models or training\nsmall models to imitate black-box model APIs like ChatGPT. How to effectively\ndistill the knowledge from white-box generative LLMs is still under-explored,\nwhich becomes more and more important with the prosperity of LLMs. In this\nwork, we propose MiniLLM that distills smaller language models from generative\nlarger language models. We first replace the forward Kullback-Leibler\ndivergence (KLD) objective in the standard KD approaches with reverse KLD,\nwhich is more suitable for KD on generative language models, to prevent the\nstudent model from overestimating the low-probability regions of the teacher\ndistribution. Then, we derive an effective optimization approach to learn this\nobjective. Extensive experiments in the instruction-following setting show that\nthe MiniLLM models generate more precise responses with the higher overall\nquality, lower exposure bias, better calibration, and higher long-text\ngeneration performance. Our method is also scalable for different model\nfamilies with 120M to 13B parameters. We will release our code and model\ncheckpoints at https://aka.ms/MiniLLM.\n",
                "链接": "https://arxiv.org/abs/2306.08543"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于大模型Agent应用的最新发表论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找论文中包含指令微调细节描述的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "99939",
                "标题": "Fearless Luminance Adaptation: A Macro-Micro-Hierarchical Transformer\n  for Exposure Correction",
                "作者": " Gehui Li,  Jinyuan Liu,  Long Ma,  Zhiying Jiang,  Xin Fan,  Risheng Liu",
                "发布日期": "2023-12-19",
                "摘要": "  Photographs taken with less-than-ideal exposure settings often display poor\nvisual quality. Since the correction procedures vary significantly, it is\ndifficult for a single neural network to handle all exposure problems.\nMoreover, the inherent limitations of convolutions, hinder the models ability\nto restore faithful color or details on extremely over-/under- exposed regions.\nTo overcome these limitations, we propose a Macro-Micro-Hierarchical\ntransformer, which consists of a macro attention to capture long-range\ndependencies, a micro attention to extract local features, and a hierarchical\nstructure for coarse-to-fine correction. In specific, the complementary\nmacro-micro attention designs enhance locality while allowing global\ninteractions. The hierarchical structure enables the network to correct\nexposure errors of different scales layer by layer. Furthermore, we propose a\ncontrast constraint and couple it seamlessly in the loss function, where the\ncorrected image is pulled towards the positive sample and pushed away from the\ndynamically generated negative samples. Thus the remaining color distortion and\nloss of detail can be removed. We also extend our method as an image enhancer\nfor low-light face recognition and low-light semantic segmentation. Experiments\ndemonstrate that our approach obtains more attractive results than\nstate-of-the-art methods quantitatively and qualitatively.\n",
                "链接": "https://arxiv.org/abs/2309.00872"
            },
            {
                "文章ID": "71101",
                "标题": "Micron-BERT: BERT-based Facial Micro-Expression Recognition",
                "作者": " Xuan-Bac Nguyen,  Chi Nhan Duong,  Xin Li,  Susan Gauch,  Han-Seok Seo,  Khoa Luu",
                "发布日期": "2023-04-07",
                "摘要": "  Micro-expression recognition is one of the most challenging topics in\naffective computing. It aims to recognize tiny facial movements difficult for\nhumans to perceive in a brief period, i.e., 0.25 to 0.5 seconds. Recent\nadvances in pre-training deep Bidirectional Transformers (BERT) have\nsignificantly improved self-supervised learning tasks in computer vision.\nHowever, the standard BERT in vision problems is designed to learn only from\nfull images or videos, and the architecture cannot accurately detect details of\nfacial micro-expressions. This paper presents Micron-BERT ($\\mu$-BERT), a novel\napproach to facial micro-expression recognition. The proposed method can\nautomatically capture these movements in an unsupervised manner based on two\nkey ideas. First, we employ Diagonal Micro-Attention (DMA) to detect tiny\ndifferences between two frames. Second, we introduce a new Patch of Interest\n(PoI) module to localize and highlight micro-expression interest regions and\nsimultaneously reduce noisy backgrounds and distractions. By incorporating\nthese components into an end-to-end deep network, the proposed $\\mu$-BERT\nsignificantly outperforms all previous work in various micro-expression tasks.\n$\\mu$-BERT can be trained on a large-scale unlabeled dataset, i.e., up to 8\nmillion images, and achieves high accuracy on new unseen facial\nmicro-expression datasets. Empirical experiments show $\\mu$-BERT consistently\noutperforms state-of-the-art performance on four micro-expression benchmarks,\nincluding SAMM, CASME II, SMIC, and CASME3, by significant margins. Code will\nbe available at \\url{https://github.com/uark-cviu/Micron-BERT}\n",
                "链接": "https://arxiv.org/abs/2304.03195"
            },
            {
                "文章ID": "115412",
                "标题": "To See is to Believe: Prompting GPT-4V for Better Visual Instruction\n  Tuning",
                "作者": " Junke Wang,  Lingchen Meng,  Zejia Weng,  Bo He,  Zuxuan Wu,  Yu-Gang Jiang",
                "发布日期": "2023-11-30",
                "摘要": "  Existing visual instruction tuning methods typically prompt large language\nmodels with textual descriptions to generate instruction-following data.\nDespite the promising performance achieved, these descriptions are derived from\nimage annotations, which are oftentimes coarse-grained. Furthermore, the\ninstructions might even contradict the visual content without observing the\nentire visual context. To address this challenge, we introduce a fine-grained\nvisual instruction dataset, LVIS-Instruct4V, which contains 220K visually\naligned and context-aware instructions produced by prompting the powerful\nGPT-4V with images from LVIS. Through experimental validation and case studies,\nwe demonstrate that high-quality visual instructional data could improve the\nperformance of LLaVA-1.5, a state-of-the-art large multimodal model, across a\nwide spectrum of benchmarks by clear margins. Notably, by simply replacing the\nLLaVA-Instruct with our LVIS-Instruct4V, we achieve better results than LLaVA\non most challenging LMM benchmarks, e.g., LLaVA$^w$ (76.7 vs. 70.7) and MM-Vet\n(40.2 vs. 35.4). We release our data and model at\nhttps://github.com/X2FD/LVIS-INSTRUCT4V.\n",
                "链接": "https://arxiv.org/abs/2311.07574"
            },
            {
                "文章ID": "120634",
                "标题": "Revisiting Micro and Macro Expressions in Computer Graphics Characters",
                "作者": " Rubens Montanha,  Giovana Raupp,  Vitoria Gonzalez,  Yanny Partichelli,  André Bins,  Marcos Ferreira,  Victor Araujo,  Soraia Musse",
                "发布日期": "2023-12-07",
                "摘要": "  This paper presents the reproduction of two studies focused on the perception\nof micro and macro expressions of Virtual Humans (VHs) generated by Computer\nGraphics (CG), first described in 2014 and replicated in 2021. The 2014 study\nreferred to a VH realistic, whereas, in 2021, it referred to a VH cartoon. In\nour work, we replicate the study by using a realistic CG character. Our main\ngoals are to compare the perceptions of micro and macro expressions between\nlevels of realism (2021 cartoon versus 2023 realistic) and between realistic\ncharacters in different periods (i.e., 2014 versus 2023). In one of our\nresults, people more easily recognized micro expressions in realistic VHs than\nin a cartoon VH. In another result, we show that the participants' perception\nwas similar for both micro and macro expressions in 2014 and 2023.\n",
                "链接": "https://arxiv.org/abs/2312.03590"
            },
            {
                "文章ID": "87849",
                "标题": "Mitigating Hallucination in Large Multi-Modal Models via Robust\n  Instruction Tuning",
                "作者": " Fuxiao Liu,  Kevin Lin,  Linjie Li,  Jianfeng Wang,  Yaser Yacoob,  Lijuan Wang",
                "发布日期": "2023-10-02",
                "摘要": "  Despite the promising progress in multi-modal tasks, current large\nmulti-modal models (LMMs) are prone to hallucinating inconsistent descriptions\nwith respect to the associated image and human instructions. This paper\naddresses this issue by introducing the first large and diverse visual\ninstruction tuning dataset, named Large-scale Robust Visual (LRV)-Instruction.\nOur dataset comprises 400k visual instructions generated by GPT4, covering 16\nvision-and-language tasks with open-ended instructions and answers. Unlike\nexisting studies that primarily focus on positive instruction samples, we\ndesign LRV-Instruction to include both positive and negative instructions for\nmore robust visual instruction tuning. Our negative instructions are designed\nat three semantic levels: (i) Nonexistent Object Manipulation, (ii) Existent\nObject Manipulation and (iii) Knowledge Manipulation. To efficiently measure\nthe hallucination generated by LMMs, we propose GPT4-Assisted Visual\nInstruction Evaluation (GAVIE), a stable approach to evaluate visual\ninstruction tuning like human experts. GAVIE does not require human-annotated\ngroundtruth answers and can adapt to diverse instruction formats. We conduct\ncomprehensive experiments to investigate the hallucination of LMMs. Our results\ndemonstrate existing LMMs exhibit significant hallucinations when presented\nwith our negative instructions, particularly Existent Object and Knowledge\nManipulation instructions. Moreover, we successfully mitigate hallucination by\nfinetuning MiniGPT4 and mPLUG-Owl on LRV-Instruction while improving\nperformance on several public datasets compared to state-of-the-art methods.\nAdditionally, we observed that a balanced ratio of positive and negative\ninstances in the training data leads to a more robust model.\n",
                "链接": "https://arxiv.org/abs/2306.14565"
            },
            {
                "文章ID": "54348",
                "标题": "One Embedder, Any Task: Instruction-Finetuned Text Embeddings",
                "作者": " Hongjin Su,  Weijia Shi,  Jungo Kasai,  Yizhong Wang,  Yushi Hu,  Mari Ostendorf,  Wen-tau Yih,  Noah A. Smith,  Luke Zettlemoyer,  Tao Yu",
                "发布日期": "2023-05-31",
                "摘要": "  We introduce INSTRUCTOR, a new method for computing text embeddings given\ntask instructions: every text input is embedded together with instructions\nexplaining the use case (e.g., task and domain descriptions). Unlike encoders\nfrom prior work that are more specialized, INSTRUCTOR is a single embedder that\ncan generate text embeddings tailored to different downstream tasks and\ndomains, without any further training. We first annotate instructions for 330\ndiverse tasks and train INSTRUCTOR on this multitask mixture with a contrastive\nloss. We evaluate INSTRUCTOR on 70 embedding evaluation tasks (66 of which are\nunseen during training), ranging from classification and information retrieval\nto semantic textual similarity and text generation evaluation. INSTRUCTOR,\nwhile having an order of magnitude fewer parameters than the previous best\nmodel, achieves state-of-the-art performance, with an average improvement of\n3.4% compared to the previous best results on the 70 diverse datasets. Our\nanalysis suggests that INSTRUCTOR is robust to changes in instructions, and\nthat instruction finetuning mitigates the challenge of training a single model\non diverse datasets. Our model, code, and data are available at\nhttps://instructor-embedding.github.io.\n",
                "链接": "https://arxiv.org/abs/2212.09741"
            },
            {
                "文章ID": "93561",
                "标题": "Exploring Format Consistency for Instruction Tuning",
                "作者": " Shihao Liang,  Kunlun Zhu,  Runchu Tian,  Yujia Qin,  Huadong Wang,  Xin Cong,  Zhiyuan Liu,  Xiaojiang Liu,  Maosong Sun",
                "发布日期": "2023-07-31",
                "摘要": "  Instruction tuning has emerged as a promising approach to enhancing large\nlanguage models in following human instructions. It is shown that increasing\nthe diversity and number of instructions in the training data can consistently\nenhance generalization performance, which facilitates a recent endeavor to\ncollect various instructions and integrate existing instruction tuning datasets\ninto larger collections. However, different users have their unique ways of\nexpressing instructions, and there often exist variations across different\ndatasets in the instruction styles and formats, i.e., format inconsistency. In\nthis work, we study how format inconsistency may impact the performance of\ninstruction tuning. We propose a framework called \"Unified Instruction Tuning\"\n(UIT), which calls OpenAI APIs for automatic format transfer among different\ninstruction tuning datasets. We show that UIT successfully improves the\ngeneralization performance on unseen instructions, which highlights the\nimportance of format consistency for instruction tuning. To make the UIT\nframework more practical, we further propose a novel perplexity-based denoising\nmethod to reduce the noise of automatic format transfer. We also train a\nsmaller offline model that achieves comparable format transfer capability than\nOpenAI APIs to reduce costs in practice.\n",
                "链接": "https://arxiv.org/abs/2307.15504"
            },
            {
                "文章ID": "20430",
                "标题": "Instruction Induction: From Few Examples to Natural Language Task\n  Descriptions",
                "作者": " Or Honovich,  Uri Shaham,  Samuel R. Bowman,  Omer Levy",
                "发布日期": "2022-05-24",
                "摘要": "  Large language models are able to perform a task by conditioning on a few\ninput-output demonstrations - a paradigm known as in-context learning. We show\nthat language models can explicitly infer an underlying task from a few\ndemonstrations by prompting them to generate a natural language instruction\nthat fits the examples. To explore this ability, we introduce the instruction\ninduction challenge, compile a dataset consisting of 24 tasks, and define a\nnovel evaluation metric based on executing the generated instruction. We\ndiscover that, to a large extent, the ability to generate instructions does\nindeed emerge when using a model that is both large enough and aligned to\nfollow instructions; InstructGPT achieves 65.7% of human performance in our\nexecution-based metric, while the original GPT-3 model reaches only 9.8% of\nhuman performance. This surprising result suggests that instruction induction\nmight be a viable learning paradigm in and of itself, where instead of fitting\na set of latent continuous parameters to the data, one searches for the best\ndescription in the natural language hypothesis space.\n",
                "链接": "https://arxiv.org/abs/2205.10782"
            },
            {
                "文章ID": "115229",
                "标题": "Context-dependent Instruction Tuning for Dialogue Response Generation",
                "作者": " Jin Myung Kwak,  Minseon Kim,  Sung Ju Hwang",
                "发布日期": "2023-11-14",
                "摘要": "  Recent language models have achieved impressive performance in natural\nlanguage tasks by incorporating instructions with task input during\nfine-tuning. Since all samples in the same natural language task can be\nexplained with the same task instructions, many instruction datasets only\nprovide a few instructions for the entire task, without considering the input\nof each example in the task. However, this approach becomes ineffective in\ncomplex multi-turn dialogue generation tasks, where the input varies highly\nwith each turn as the dialogue context changes, so that simple task\ninstructions cannot improve the generation performance. To address this\nlimitation, we introduce a context-based instruction fine-tuning framework for\neach multi-turn dialogue which generates both responses and instructions based\non the previous context as input. During the evaluation, the model generates\ninstructions based on the previous context to self-guide the response. The\nproposed framework produces comparable or even outstanding results compared to\nthe baselines by aligning instructions to the input during fine-tuning with the\ninstructions in quantitative evaluations on dialogue benchmark datasets with\nreduced computation budget.\n",
                "链接": "https://arxiv.org/abs/2311.07006"
            },
            {
                "文章ID": "66734",
                "标题": "Lana: A Language-Capable Navigator for Instruction Following and\n  Generation",
                "作者": " Xiaohan Wang,  Wenguan Wang,  Jiayi Shao,  Yi Yang",
                "发布日期": "2023-03-16",
                "摘要": "  Recently, visual-language navigation (VLN) -- entailing robot agents to\nfollow navigation instructions -- has shown great advance. However, existing\nliterature put most emphasis on interpreting instructions into actions, only\ndelivering \"dumb\" wayfinding agents. In this article, we devise LANA, a\nlanguage-capable navigation agent which is able to not only execute\nhuman-written navigation commands, but also provide route descriptions to\nhumans. This is achieved by simultaneously learning instruction following and\ngeneration with only one single model. More specifically, two encoders,\nrespectively for route and language encoding, are built and shared by two\ndecoders, respectively, for action prediction and instruction generation, so as\nto exploit cross-task knowledge and capture task-specific characteristics.\nThroughout pretraining and fine-tuning, both instruction following and\ngeneration are set as optimization objectives. We empirically verify that,\ncompared with recent advanced task-specific solutions, LANA attains better\nperformances on both instruction following and route description, with nearly\nhalf complexity. In addition, endowed with language generation capability, LANA\ncan explain to humans its behaviors and assist human's wayfinding. This work is\nexpected to foster future efforts towards building more trustworthy and\nsocially-intelligent navigation robots.\n",
                "链接": "https://arxiv.org/abs/2303.08409"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本检测最新进展",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "100439",
                "标题": "STEP -- Towards Structured Scene-Text Spotting",
                "作者": " Sergi Garcia-Bordils,  Dimosthenis Karatzas,  Marçal Rusiñol",
                "发布日期": "2023-12-12",
                "摘要": "  We introduce the structured scene-text spotting task, which requires a\nscene-text OCR system to spot text in the wild according to a query regular\nexpression. Contrary to generic scene text OCR, structured scene-text spotting\nseeks to dynamically condition both scene text detection and recognition on\nuser-provided regular expressions. To tackle this task, we propose the\nStructured TExt sPotter (STEP), a model that exploits the provided text\nstructure to guide the OCR process. STEP is able to deal with regular\nexpressions that contain spaces and it is not bound to detection at the\nword-level granularity. Our approach enables accurate zero-shot structured text\nspotting in a wide variety of real-world reading scenarios and is solely\ntrained on publicly available data. To demonstrate the effectiveness of our\napproach, we introduce a new challenging test dataset that contains several\ntypes of out-of-vocabulary structured text, reflecting important reading\napplications of fields such as prices, dates, serial numbers, license plates\netc. We demonstrate that STEP can provide specialised OCR performance on demand\nin all tested scenarios.\n",
                "链接": "https://arxiv.org/abs/2309.02356"
            },
            {
                "文章ID": "53136",
                "标题": "Extending TrOCR for Text Localization-Free OCR of Full-Page Scanned\n  Receipt Images",
                "作者": " Hongkuan Zhang,  Edward Whittaker,  Ikuo Kitagishi",
                "发布日期": "2023-10-17",
                "摘要": "  Digitization of scanned receipts aims to extract text from receipt images and\nsave it into structured documents. This is usually split into two sub-tasks:\ntext localization and optical character recognition (OCR). Most existing OCR\nmodels only focus on the cropped text instance images, which require the\nbounding box information provided by a text region detection model. Introducing\nan additional detector to identify the text instance images in advance adds\ncomplexity, however instance-level OCR models have very low accuracy when\nprocessing the whole image for the document-level OCR, such as receipt images\ncontaining multiple text lines arranged in various layouts. To this end, we\npropose a localization-free document-level OCR model for transcribing all the\ncharacters in a receipt image into an ordered sequence end-to-end.\nSpecifically, we finetune the pretrained instance-level model TrOCR with\nrandomly cropped image chunks, and gradually increase the image chunk size to\ngeneralize the recognition ability from instance images to full-page images. In\nour experiments on the SROIE receipt OCR dataset, the model finetuned with our\nstrategy achieved 64.4 F1-score and a 22.8% character error rate (CER),\nrespectively, which outperforms the baseline results with 48.5 F1-score and\n50.6% CER. The best model, which splits the full image into 15 equally sized\nchunks, gives 87.8 F1-score and 4.98% CER with minimal additional pre or\npost-processing of the output. Moreover, the characters in the generated\ndocument-level sequences are arranged in the reading order, which is practical\nfor real-world applications.\n",
                "链接": "https://arxiv.org/abs/2212.05525"
            },
            {
                "文章ID": "98478",
                "标题": "DISGO: Automatic End-to-End Evaluation for Scene Text OCR",
                "作者": " Mei-Yuh Hwang,  Yangyang Shi,  Ankit Ramchandani,  Guan Pang,  Praveen Krishnan,  Lucas Kabela,  Frank Seide,  Samyak Datta,  Jun Liu",
                "发布日期": "2023-08-28",
                "摘要": "  This paper discusses the challenges of optical character recognition (OCR) on\nnatural scenes, which is harder than OCR on documents due to the wild content\nand various image backgrounds. We propose to uniformly use word error rates\n(WER) as a new measurement for evaluating scene-text OCR, both end-to-end (e2e)\nperformance and individual system component performances. Particularly for the\ne2e metric, we name it DISGO WER as it considers Deletion, Insertion,\nSubstitution, and Grouping/Ordering errors. Finally we propose to utilize the\nconcept of super blocks to automatically compute BLEU scores for e2e OCR\nmachine translation. The small SCUT public test set is used to demonstrate WER\nperformance by a modularized OCR system.\n",
                "链接": "https://arxiv.org/abs/2308.13173"
            },
            {
                "文章ID": "45166",
                "标题": "A Late Multi-Modal Fusion Model for Detecting Hybrid Spam E-mail",
                "作者": " Zhibo Zhang,  Ernesto Damiani,  Hussam Al Hamadi,  Chan Yeob Yeun,  Fatma Taher",
                "发布日期": "2023-05-16",
                "摘要": "  In recent years, spammers are now trying to obfuscate their intents by\nintroducing hybrid spam e-mail combining both image and text parts, which is\nmore challenging to detect in comparison to e-mails containing text or image\nonly. The motivation behind this research is to design an effective approach\nfiltering out hybrid spam e-mails to avoid situations where traditional\ntext-based or image-baesd only filters fail to detect hybrid spam e-mails. To\nthe best of our knowledge, a few studies have been conducted with the goal of\ndetecting hybrid spam e-mails. Ordinarily, Optical Character Recognition (OCR)\ntechnology is used to eliminate the image parts of spam by transforming images\ninto text. However, the research questions are that although OCR scanning is a\nvery successful technique in processing text-and-image hybrid spam, it is not\nan effective solution for dealing with huge quantities due to the CPU power\nrequired and the execution time it takes to scan e-mail files. And the OCR\ntechniques are not always reliable in the transformation processes. To address\nsuch problems, we propose new late multi-modal fusion training frameworks for a\ntext-and-image hybrid spam e-mail filtering system compared to the classical\nearly fusion detection frameworks based on the OCR method. Convolutional Neural\nNetwork (CNN) and Continuous Bag of Words were implemented to extract features\nfrom image and text parts of hybrid spam respectively, whereas generated\nfeatures were fed to sigmoid layer and Machine Learning based classifiers\nincluding Random Forest (RF), Decision Tree (DT), Naive Bayes (NB) and Support\nVector Machine (SVM) to determine the e-mail ham or spam.\n",
                "链接": "https://arxiv.org/abs/2210.14616"
            },
            {
                "文章ID": "120332",
                "标题": "UPOCR: Towards Unified Pixel-Level OCR Interface",
                "作者": " Dezhi Peng,  Zhenhua Yang,  Jiaxin Zhang,  Chongyu Liu,  Yongxin Shi,  Kai Ding,  Fengjun Guo,  Lianwen Jin",
                "发布日期": "2023-12-06",
                "摘要": "  In recent years, the optical character recognition (OCR) field has been\nproliferating with plentiful cutting-edge approaches for a wide spectrum of\ntasks. However, these approaches are task-specifically designed with divergent\nparadigms, architectures, and training strategies, which significantly\nincreases the complexity of research and maintenance and hinders the fast\ndeployment in applications. To this end, we propose UPOCR, a\nsimple-yet-effective generalist model for Unified Pixel-level OCR interface.\nSpecifically, the UPOCR unifies the paradigm of diverse OCR tasks as\nimage-to-image transformation and the architecture as a vision Transformer\n(ViT)-based encoder-decoder. Learnable task prompts are introduced to push the\ngeneral feature representations extracted by the encoder toward task-specific\nspaces, endowing the decoder with task awareness. Moreover, the model training\nis uniformly aimed at minimizing the discrepancy between the generated and\nground-truth images regardless of the inhomogeneity among tasks. Experiments\nare conducted on three pixel-level OCR tasks including text removal, text\nsegmentation, and tampered text detection. Without bells and whistles, the\nexperimental results showcase that the proposed method can simultaneously\nachieve state-of-the-art performance on three tasks with a unified single\nmodel, which provides valuable strategies and insights for future research on\ngeneralist OCR models. Code will be publicly available.\n",
                "链接": "https://arxiv.org/abs/2312.02694"
            },
            {
                "文章ID": "77918",
                "标题": "Mobile User Interface Element Detection Via Adaptively Prompt Tuning",
                "作者": " Zhangxuan Gu,  Zhuoer Xu,  Haoxing Chen,  Jun Lan,  Changhua Meng,  Weiqiang Wang",
                "发布日期": "2023-05-18",
                "摘要": "  Recent object detection approaches rely on pretrained vision-language models\nfor image-text alignment. However, they fail to detect the Mobile User\nInterface (MUI) element since it contains additional OCR information, which\ndescribes its content and function but is often ignored. In this paper, we\ndevelop a new MUI element detection dataset named MUI-zh and propose an\nAdaptively Prompt Tuning (APT) module to take advantage of discriminating OCR\ninformation. APT is a lightweight and effective module to jointly optimize\ncategory prompts across different modalities. For every element, APT uniformly\nencodes its visual features and OCR descriptions to dynamically adjust the\nrepresentation of frozen category prompts. We evaluate the effectiveness of our\nplug-and-play APT upon several existing CLIP-based detectors for both standard\nand open-vocabulary MUI element detection. Extensive experiments show that our\nmethod achieves considerable improvements on two datasets. The datasets is\navailable at \\url{github.com/antmachineintelligence/MUI-zh}.\n",
                "链接": "https://arxiv.org/abs/2305.09699"
            },
            {
                "文章ID": "88218",
                "标题": "UTRNet: High-Resolution Urdu Text Recognition In Printed Documents",
                "作者": " Abdur Rahman,  Arjun Ghosh,  Chetan Arora",
                "发布日期": "2023-08-24",
                "摘要": "  In this paper, we propose a novel approach to address the challenges of\nprinted Urdu text recognition using high-resolution, multi-scale semantic\nfeature extraction. Our proposed UTRNet architecture, a hybrid CNN-RNN model,\ndemonstrates state-of-the-art performance on benchmark datasets. To address the\nlimitations of previous works, which struggle to generalize to the intricacies\nof the Urdu script and the lack of sufficient annotated real-world data, we\nhave introduced the UTRSet-Real, a large-scale annotated real-world dataset\ncomprising over 11,000 lines and UTRSet-Synth, a synthetic dataset with 20,000\nlines closely resembling real-world and made corrections to the ground truth of\nthe existing IIITH dataset, making it a more reliable resource for future\nresearch. We also provide UrduDoc, a benchmark dataset for Urdu text line\ndetection in scanned documents. Additionally, we have developed an online tool\nfor end-to-end Urdu OCR from printed documents by integrating UTRNet with a\ntext detection model. Our work not only addresses the current limitations of\nUrdu OCR but also paves the way for future research in this area and\nfacilitates the continued advancement of Urdu OCR technology. The project page\nwith source code, datasets, annotations, trained models, and online tool is\navailable at abdur75648.github.io/UTRNet.\n",
                "链接": "https://arxiv.org/abs/2306.15782"
            },
            {
                "文章ID": "73951",
                "标题": "ICDAR 2023 Competition on Reading the Seal Title",
                "作者": " Wenwen Yu,  Mingyu Liu,  Mingrui Chen,  Ning Lu,  Yinlong Wen,  Yuliang Liu,  Dimosthenis Karatzas,  Xiang Bai",
                "发布日期": "2023-06-07",
                "摘要": "  Reading seal title text is a challenging task due to the variable shapes of\nseals, curved text, background noise, and overlapped text. However, this\nimportant element is commonly found in official and financial scenarios, and\nhas not received the attention it deserves in the field of OCR technology. To\npromote research in this area, we organized ICDAR 2023 competition on reading\nthe seal title (ReST), which included two tasks: seal title text detection\n(Task 1) and end-to-end seal title recognition (Task 2). We constructed a\ndataset of 10,000 real seal data, covering the most common classes of seals,\nand labeled all seal title texts with text polygons and text contents. The\ncompetition opened on 30th December, 2022 and closed on 20th March, 2023. The\ncompetition attracted 53 participants from academia and industry including 28\nsubmissions for Task 1 and 25 submissions for Task 2, which demonstrated\nsignificant interest in this challenging task. In this report, we present an\noverview of the competition, including the organization, challenges, and\nresults. We describe the dataset and tasks, and summarize the submissions and\nevaluation results. The results show that significant progress has been made in\nthe field of seal title text reading, and we hope that this competition will\ninspire further research and development in this important area of OCR\ntechnology.\n",
                "链接": "https://arxiv.org/abs/2304.11966"
            },
            {
                "文章ID": "98244",
                "标题": "American Stories: A Large-Scale Structured Text Dataset of Historical\n  U.S. Newspapers",
                "作者": " Melissa Dell,  Jacob Carlson,  Tom Bryan,  Emily Silcock,  Abhishek Arora,  Zejiang Shen,  Luca D'Amico-Wong,  Quan Le,  Pablo Querubin,  Leander Heldring",
                "发布日期": "2023-08-25",
                "摘要": "  Existing full text datasets of U.S. public domain newspapers do not recognize\nthe often complex layouts of newspaper scans, and as a result the digitized\ncontent scrambles texts from articles, headlines, captions, advertisements, and\nother layout regions. OCR quality can also be low. This study develops a novel,\ndeep learning pipeline for extracting full article texts from newspaper images\nand applies it to the nearly 20 million scans in Library of Congress's public\ndomain Chronicling America collection. The pipeline includes layout detection,\nlegibility classification, custom OCR, and association of article texts\nspanning multiple bounding boxes. To achieve high scalability, it is built with\nefficient architectures designed for mobile phones. The resulting American\nStories dataset provides high quality data that could be used for pre-training\na large language model to achieve better understanding of historical English\nand historical world knowledge. The dataset could also be added to the external\ndatabase of a retrieval-augmented language model to make historical information\n- ranging from interpretations of political events to minutiae about the lives\nof people's ancestors - more widely accessible. Furthermore, structured article\ntexts facilitate using transformer-based methods for popular social science\napplications like topic classification, detection of reproduced content, and\nnews story clustering. Finally, American Stories provides a massive silver\nquality dataset for innovating multimodal layout analysis models and other\nmultimodal applications.\n",
                "链接": "https://arxiv.org/abs/2308.12477"
            },
            {
                "文章ID": "94203",
                "标题": "Artificial Eye for the Blind",
                "作者": " Abhinav Benagi,  Dhanyatha Narayan,  Charith Rage,  A Sushmitha",
                "发布日期": "2023-08-03",
                "摘要": "  The main backbone of our Artificial Eye model is the Raspberry pi3 which is\nconnected to the webcam ,ultrasonic proximity sensor, speaker and we also run\nall our software models i.e object detection, Optical Character recognition,\ngoogle text to speech conversion and the Mycroft voice assistance model. At\nfirst the ultrasonic proximity sensor will be measuring the distance between\nitself and any obstacle in front of it .When the Proximity sensor detects any\nobstacle in front within its specified range, the blind person will hear an\naudio prompt about an obstacle in his way at a certain distance. At this time\nthe Webcam will capture an image in front of it and the Object detection model\nand the Optical Character Recognition model will begin to run on the Raspberry\npi. The imat of the blind person. The text and the object detected are conveyed\nto the blind pege captured is first sent through the Tesseract OCR module to\ndetect any texts in the image and then through the Object detection model to\ndetect the objects in fronrson by converting the texts to speech by using the\ngTTS module. Along with the above mentioned process going on there will be an\nactive MYCROFT voice assistant model which can be used to interact with the\nblind person. The blind person can ask about the weather , daily news , any\ninformation on the internet ,etc\n",
                "链接": "https://arxiv.org/abs/2308.00801"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月agent系列决策文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "90666",
                "标题": "Maneuver Decision-Making Through Automatic Curriculum Reinforcement\n  Learning Without Handcrafted Reward functions",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-07-13",
                "摘要": "  Maneuver decision-making is the core of unmanned combat aerial vehicle for\nautonomous air combat. To solve this problem, we propose an automatic\ncurriculum reinforcement learning method, which enables agents to learn\neffective decisions in air combat from scratch. The range of initial states are\nused for distinguishing curricula of different difficulty levels, thereby\nmaneuver decision is divided into a series of sub-tasks from easy to difficult,\nand test results are used to change sub-tasks. As sub-tasks change, agents\ngradually learn to complete a series of sub-tasks from easy to difficult,\nenabling them to make effective maneuvering decisions to cope with various\nstates without the need to spend effort designing reward functions. The\nablation studied show that the automatic curriculum learning proposed in this\narticle is an essential component for training through reinforcement learning,\nnamely, agents cannot complete effective decisions without curriculum learning.\nSimulation experiments show that, after training, agents are able to make\neffective decisions given different states, including tracking, attacking and\nescaping, which are both rational and interpretable.\n",
                "链接": "https://arxiv.org/abs/2307.06152"
            },
            {
                "文章ID": "100061",
                "标题": "Cooperative Filtering with Range Measurements: A Distributed Constrained\n  Zonotopic Method",
                "作者": " Yu Ding,  Yirui Cong,  Xiangke Wang,  Long Cheng",
                "发布日期": "2023-09-06",
                "摘要": "  This article studies the distributed estimation problem of a multi-agent\nsystem with bounded absolute and relative range measurements. Parts of the\nagents are with high-accuracy absolute measurements, which are considered as\nanchors; the other agents utilize lowaccuracy absolute and relative range\nmeasurements, each derives an uncertain range that contains its true state in a\ndistributed manner. Different from previous studies, we design a distributed\nalgorithm to handle the range measurements based on extended constrained\nzonotopes, which has low computational complexity and high precision. With our\nproposed algorithm, agents can derive their uncertain range sequentially along\nthe chain topology, such that agents with low-accuracy sensors can benefit from\nthe high-accuracy absolute measurements of anchors and improve the estimation\nperformance. Simulation results corroborate the effectiveness of our proposed\nalgorithm and verify our method can significantly improve the estimation\naccuracy.\n",
                "链接": "https://arxiv.org/abs/2309.01185"
            },
            {
                "文章ID": "488",
                "标题": "Sales Time Series Analytics Using Deep Q-Learning",
                "作者": " Bohdan M. Pavlyshenko",
                "发布日期": "2022-01-07",
                "摘要": "  The article describes the use of deep Q-learning models in the problems of\nsales time series analytics. In contrast to supervised machine learning which\nis a kind of passive learning using historical data, Q-learning is a kind of\nactive learning with goal to maximize a reward by optimal sequence of actions.\nModel free Q-learning approach for optimal pricing strategies and supply-demand\nproblems was considered in the work. The main idea of the study is to show that\nusing deep Q-learning approach in time series analytics, the sequence of\nactions can be optimized by maximizing the reward function when the environment\nfor learning agent interaction can be modeled using the parametric model and in\nthe case of using the model which is based on the historical data. In the\npricing optimizing case study environment was modeled using sales dependence on\nextras price and randomly simulated demand. In the pricing optimizing case\nstudy, the environment was modeled using sales dependence on extra price and\nrandomly simulated demand. In the supply-demand case study, it was proposed to\nuse historical demand time series for environment modeling, agent states were\nrepresented by promo actions, previous demand values and weekly seasonality\nfeatures. Obtained results show that using deep Q-learning, we can optimize the\ndecision making process for price optimization and supply-demand problems.\nEnvironment modeling using parametric models and historical data can be used\nfor the cold start of learning agent. On the next steps, after the cold start,\nthe trained agent can be used in real business environment.\n",
                "链接": "https://arxiv.org/abs/2201.02058"
            },
            {
                "文章ID": "110249",
                "标题": "The Perils & Promises of Fact-checking with Large Language Models",
                "作者": " Dorian Quelle,  Alexandre Bovet",
                "发布日期": "2023-10-23",
                "摘要": "  Autonomous fact-checking, using machine learning to verify claims, has grown\nvital as misinformation spreads beyond human fact-checking capacity. Large\nLanguage Models (LLMs) like GPT-4 are increasingly trusted to verify\ninformation and write academic papers, lawsuits, and news articles, emphasizing\ntheir role in discerning truth from falsehood and the importance of being able\nto verify their outputs. Here, we evaluate the use of LLM agents in\nfact-checking by having them phrase queries, retrieve contextual data, and make\ndecisions. Importantly, in our framework, agents explain their reasoning and\ncite the relevant sources from the retrieved context. Our results show the\nenhanced prowess of LLMs when equipped with contextual information. GPT-4\noutperforms GPT-3, but accuracy varies based on query language and claim\nveracity. While LLMs show promise in fact-checking, caution is essential due to\ninconsistent accuracy. Our investigation calls for further research, fostering\na deeper comprehension of when agents succeed and when they fail.\n",
                "链接": "https://arxiv.org/abs/2310.13549"
            },
            {
                "文章ID": "107741",
                "标题": "V2X-AHD:Vehicle-to-Everything Cooperation Perception via Asymmetric\n  Heterogenous Distillation Network",
                "作者": " Caizhen He,  Hai Wang,  Long Chen,  Tong Luo,  Yingfeng Cai",
                "发布日期": "2023-10-11",
                "摘要": "  Object detection is the central issue of intelligent traffic systems, and\nrecent advancements in single-vehicle lidar-based 3D detection indicate that it\ncan provide accurate position information for intelligent agents to make\ndecisions and plan. Compared with single-vehicle perception, multi-view\nvehicle-road cooperation perception has fundamental advantages, such as the\nelimination of blind spots and a broader range of perception, and has become a\nresearch hotspot. However, the current perception of cooperation focuses on\nimproving the complexity of fusion while ignoring the fundamental problems\ncaused by the absence of single-view outlines. We propose a multi-view\nvehicle-road cooperation perception system, vehicle-to-everything cooperative\nperception (V2X-AHD), in order to enhance the identification capability,\nparticularly for predicting the vehicle's shape. At first, we propose an\nasymmetric heterogeneous distillation network fed with different training data\nto improve the accuracy of contour recognition, with multi-view teacher\nfeatures transferring to single-view student features. While the point cloud\ndata are sparse, we propose Spara Pillar, a spare convolutional-based plug-in\nfeature extraction backbone, to reduce the number of parameters and improve and\nenhance feature extraction capabilities. Moreover, we leverage the multi-head\nself-attention (MSA) to fuse the single-view feature, and the lightweight\ndesign makes the fusion feature a smooth expression. The results of applying\nour algorithm to the massive open dataset V2Xset demonstrate that our method\nachieves the state-of-the-art result. The V2X-AHD can effectively improve the\naccuracy of 3D object detection and reduce the number of network parameters,\naccording to this study, which serves as a benchmark for cooperative\nperception. The code for this article is available at\nhttps://github.com/feeling0414-lab/V2X-AHD.\n",
                "链接": "https://arxiv.org/abs/2310.06603"
            },
            {
                "文章ID": "105835",
                "标题": "RF-ULM: Deep Learning for Radio-Frequency Ultrasound Localization\n  Microscopy",
                "作者": " Christopher Hahne,  Georges Chabouh,  Arthur Chavignon,  Olivier Couture,  Raphael Sznitman",
                "发布日期": "2023-12-27",
                "摘要": "  In Ultrasound Localization Microscopy (ULM),achieving high-resolution images\nrelies on the precise localization of contrast agent particles across\nconsecutive beam-formed frames. However, our study uncovers an enormous\npotential: The process of delay-and-sum beamforming leads to an irreversible\nreduction of Radio-Frequency (RF) data, while its implications for localization\nremain largely unexplored. The rich contextual information embedded within RF\nwavefronts, including their hyperbolic shape and phase, offers great promise\nfor guiding Deep Neural Networks (DNNs) in challenging localization scenarios.\nTo fully exploit this data, we propose to directly localize scatterers in RF\nsignals. Our approach involves a custom super-resolution DNN using learned\nfeature channel shuffling and a novel semi-global convolutional sampling block\ntailored for reliable and accurate wavefront localization. Additionally, we\nintroduce a geometric point transformation that facilitates seamless mapping\nbetween RF and B-mode coordinate space. To understand the impact of beamforming\non ULM, we validate the effectiveness of our method by conducting an extensive\ncomparison with State-Of-The-Art (SOTA) techniques. We present the inaugural in\nvivo results from an RF-trained DNN, highlighting its real-world practicality.\nOur findings show that RF-ULM bridges the domain gap between synthetic and real\ndatasets, offering a considerable advantage in terms of precision and\ncomplexity. To enable the broader research community to benefit from our\nfindings, our code and the associated SOTA methods are made available at\nhttps://github.com/hahnec/rf-ulm.\n",
                "链接": "https://arxiv.org/abs/2310.01545"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态优化训练方式的相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "与大模型安全相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "近几个月自然语言处理相关的文章。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找多语言情感分析的最新论文。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "2023年以后关于NLP领域的持续性学习论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "33717",
                "标题": "Transformer Vs. MLP-Mixer: Exponential Expressive Gap For NLP Problems",
                "作者": " Dan Navon,  Alex M. Bronstein",
                "发布日期": "2022-11-18",
                "摘要": "  Vision-Transformers are widely used in various vision tasks. Meanwhile, there\nis another line of works starting with the MLP-mixer trying to achieve similar\nperformance using mlp-based architectures. Interestingly, until now those\nmlp-based architectures have not been adapted for NLP tasks. Additionally,\nuntil now, mlp-based architectures have failed to achieve state-of-the-art\nperformance in vision tasks. In this paper, we analyze the expressive power of\nmlp-based architectures in modeling dependencies between multiple different\ninputs simultaneously, and show an exponential gap between the attention and\nthe mlp-based mechanisms. Our results suggest a theoretical explanation for the\nmlp inability to compete with attention-based mechanisms in NLP problems, they\nalso suggest that the performance gap in vision tasks may be due to the mlp\nrelative weakness in modeling dependencies between multiple different\nlocations, and that combining smart input permutations with mlp architectures\nmay not be enough to close the performance gap alone.\n",
                "链接": "https://arxiv.org/abs/2208.08191"
            },
            {
                "文章ID": "4742",
                "标题": "pNLP-Mixer: an Efficient all-MLP Architecture for Language",
                "作者": " Francesco Fusco,  Damian Pascual,  Peter Staar,  Diego Antognini",
                "发布日期": "2023-05-26",
                "摘要": "  Large pre-trained language models based on transformer architecture have\ndrastically changed the natural language processing (NLP) landscape. However,\ndeploying those models for on-device applications in constrained devices such\nas smart watches is completely impractical due to their size and inference\ncost. As an alternative to transformer-based architectures, recent work on\nefficient NLP has shown that weight-efficient models can attain competitive\nperformance for simple tasks, such as slot filling and intent classification,\nwith model sizes in the order of the megabyte. This work introduces the\npNLP-Mixer architecture, an embedding-free MLP-Mixer model for on-device NLP\nthat achieves high weight-efficiency thanks to a novel projection layer. We\nevaluate a pNLP-Mixer model of only one megabyte in size on two multi-lingual\nsemantic parsing datasets, MTOP and multiATIS. Our quantized model achieves\n99.4% and 97.8% the performance of mBERT on MTOP and multi-ATIS, while using\n170x fewer parameters. Our model consistently beats the state-of-the-art of\ntiny models (pQRNN), which is twice as large, by a margin up to 7.8% on MTOP.\n",
                "链接": "https://arxiv.org/abs/2202.04350"
            },
            {
                "文章ID": "66376",
                "标题": "Model-tuning Via Prompts Makes NLP Models Adversarially Robust",
                "作者": " Mrigank Raman,  Pratyush Maini,  J. Zico Kolter,  Zachary C. Lipton,  Danish Pruthi",
                "发布日期": "2023-12-07",
                "摘要": "  In recent years, NLP practitioners have converged on the following practice:\n(i) import an off-the-shelf pretrained (masked) language model; (ii) append a\nmultilayer perceptron atop the CLS token's hidden representation (with randomly\ninitialized weights); and (iii) fine-tune the entire model on a downstream task\n(MLP-FT). This procedure has produced massive gains on standard NLP benchmarks,\nbut these models remain brittle, even to mild adversarial perturbations. In\nthis work, we demonstrate surprising gains in adversarial robustness enjoyed by\nModel-tuning Via Prompts (MVP), an alternative method of adapting to downstream\ntasks. Rather than appending an MLP head to make output prediction, MVP appends\na prompt template to the input, and makes prediction via text\ninfilling/completion. Across 5 NLP datasets, 4 adversarial attacks, and 3\ndifferent models, MVP improves performance against adversarial substitutions by\nan average of 8% over standard methods and even outperforms adversarial\ntraining-based state-of-art defenses by 3.5%. By combining MVP with adversarial\ntraining, we achieve further improvements in adversarial robustness while\nmaintaining performance on unperturbed examples. Finally, we conduct ablations\nto investigate the mechanism underlying these gains. Notably, we find that the\nmain causes of vulnerability of MLP-FT can be attributed to the misalignment\nbetween pre-training and fine-tuning tasks, and the randomly initialized MLP\nparameters.\n",
                "链接": "https://arxiv.org/abs/2303.07320"
            },
            {
                "文章ID": "110508",
                "标题": "RSM-NLP at BLP-2023 Task 2: Bangla Sentiment Analysis using Weighted and\n  Majority Voted Fine-Tuned Transformers",
                "作者": " Pratinav Seth,  Rashi Goel,  Komal Mathur,  Swetha Vemulapalli",
                "发布日期": "2023-10-24",
                "摘要": "  This paper describes our approach to submissions made at Shared Task 2 at BLP\nWorkshop - Sentiment Analysis of Bangla Social Media Posts. Sentiment Analysis\nis an action research area in the digital age. With the rapid and constant\ngrowth of online social media sites and services and the increasing amount of\ntextual data, the application of automatic Sentiment Analysis is on the rise.\nHowever, most of the research in this domain is based on the English language.\nDespite being the world's sixth most widely spoken language, little work has\nbeen done in Bangla. This task aims to promote work on Bangla Sentiment\nAnalysis while identifying the polarity of social media content by determining\nwhether the sentiment expressed in the text is Positive, Negative, or Neutral.\nOur approach consists of experimenting and finetuning various multilingual and\npre-trained BERT-based models on our downstream tasks and using a Majority\nVoting and Weighted ensemble model that outperforms individual baseline model\nscores. Our system scored 0.711 for the multiclass classification task and\nscored 10th place among the participants on the leaderboard for the shared\ntask. Our code is available at https://github.com/ptnv-s/RSM-NLP-BLP-Task2 .\n",
                "链接": "https://arxiv.org/abs/2310.14261"
            },
            {
                "文章ID": "60852",
                "标题": "Augmenting NLP data to counter Annotation Artifacts for NLI Tasks",
                "作者": " Armaan Singh Bhullar",
                "发布日期": "2023-02-10",
                "摘要": "  In this paper, we explore Annotation Artifacts - the phenomena wherein large\npre-trained NLP models achieve high performance on benchmark datasets but do\nnot actually \"solve\" the underlying task and instead rely on some dataset\nartifacts (same across train, validation, and test sets) to figure out the\nright answer. We explore this phenomenon on the well-known Natural Language\nInference task by first using contrast and adversarial examples to understand\nlimitations to the model's performance and show one of the biases arising from\nannotation artifacts (the way training data was constructed by the annotators).\nWe then propose a data augmentation technique to fix this bias and measure its\neffectiveness.\n",
                "链接": "https://arxiv.org/abs/2302.04700"
            },
            {
                "文章ID": "94486",
                "标题": "XNLP: An Interactive Demonstration System for Universal Structured NLP",
                "作者": " Hao Fei,  Meishan Zhang,  Min Zhang,  Tat-Seng Chua",
                "发布日期": "2023-08-04",
                "摘要": "  Structured Natural Language Processing (XNLP) is an important subset of NLP\nthat entails understanding the underlying semantic or syntactic structure of\ntexts, which serves as a foundational component for many downstream\napplications. Despite certain recent efforts to explore universal solutions for\nspecific categories of XNLP tasks, a comprehensive and effective approach for\nunifying all XNLP tasks long remains underdeveloped. In the meanwhile, while\nXNLP demonstration systems are vital for researchers exploring various XNLP\ntasks, existing platforms can be limited to, e.g., supporting few XNLP tasks,\nlacking interactivity and universalness. To this end, we propose an advanced\nXNLP demonstration platform, where we propose leveraging LLM to achieve\nuniversal XNLP, with one model for all with high generalizability. Overall, our\nsystem advances in multiple aspects, including universal XNLP modeling, high\nperformance, interpretability, scalability, and interactivity, providing a\nunified platform for exploring diverse XNLP tasks in the community. XNLP is\nonline: https://xnlp.haofei.vip\n",
                "链接": "https://arxiv.org/abs/2308.01846"
            },
            {
                "文章ID": "110535",
                "标题": "The Law and NLP: Bridging Disciplinary Disconnects",
                "作者": " Robert Mahari,  Dominik Stammbach,  Elliott Ash,  Alex 'Sandy' Pentland",
                "发布日期": "2023-10-24",
                "摘要": "  Legal practice is intrinsically rooted in the fabric of language, yet legal\npractitioners and scholars have been slow to adopt tools from natural language\nprocessing (NLP). At the same time, the legal system is experiencing an access\nto justice crisis, which could be partially alleviated with NLP. In this\nposition paper, we argue that the slow uptake of NLP in legal practice is\nexacerbated by a disconnect between the needs of the legal community and the\nfocus of NLP researchers. In a review of recent trends in the legal NLP\nliterature, we find limited overlap between the legal NLP community and legal\nacademia. Our interpretation is that some of the most popular legal NLP tasks\nfail to address the needs of legal practitioners. We discuss examples of legal\nNLP tasks that promise to bridge disciplinary disconnects and highlight\ninteresting areas for legal NLP research that remain underexplored.\n",
                "链接": "https://arxiv.org/abs/2310.14346"
            },
            {
                "文章ID": "115688",
                "标题": "A Material Lens on Coloniality in NLP",
                "作者": " William Held,  Camille Harris,  Michael Best,  Diyi Yang",
                "发布日期": "2023-11-15",
                "摘要": "  Coloniality, the continuation of colonial harms beyond \"official\"\ncolonization, has pervasive effects across society and scientific fields.\nNatural Language Processing (NLP) is no exception to this broad phenomenon. In\nthis work, we argue that coloniality is implicitly embedded in and amplified by\nNLP data, algorithms, and software. We formalize this analysis using\nActor-Network Theory (ANT): an approach to understanding social phenomena\nthrough the network of relationships between human stakeholders and technology.\nWe use our Actor-Network to guide a quantitative survey of the geography of\ndifferent phases of NLP research, providing evidence that inequality along\ncolonial boundaries increases as NLP builds on itself. Based on this, we argue\nthat combating coloniality in NLP requires not only changing current values but\nalso active work to remove the accumulation of colonial ideals in our\nfoundational data and algorithms.\n",
                "链接": "https://arxiv.org/abs/2311.08391"
            },
            {
                "文章ID": "70948",
                "标题": "Sejarah dan Perkembangan Teknik Natural Language Processing (NLP) Bahasa\n  Indonesia: Tinjauan tentang sejarah, perkembangan teknologi, dan aplikasi NLP\n  dalam bahasa Indonesia",
                "作者": " Mukhlis Amien",
                "发布日期": "2023-04-07",
                "摘要": "  This study provides an overview of the history of the development of Natural\nLanguage Processing (NLP) in the context of the Indonesian language, with a\nfocus on the basic technologies, methods, and practical applications that have\nbeen developed. This review covers developments in basic NLP technologies such\nas stemming, part-of-speech tagging, and related methods; practical\napplications in cross-language information retrieval systems, information\nextraction, and sentiment analysis; and methods and techniques used in\nIndonesian language NLP research, such as machine learning, statistics-based\nmachine translation, and conflict-based approaches. This study also explores\nthe application of NLP in Indonesian language industry and research and\nidentifies challenges and opportunities in Indonesian language NLP research and\ndevelopment. Recommendations for future Indonesian language NLP research and\ndevelopment include developing more efficient methods and technologies,\nexpanding NLP applications, increasing sustainability, further research into\nthe potential of NLP, and promoting interdisciplinary collaboration. It is\nhoped that this review will help researchers, practitioners, and the government\nto understand the development of Indonesian language NLP and identify\nopportunities for further research and development.\n",
                "链接": "https://arxiv.org/abs/2304.02746"
            },
            {
                "文章ID": "112899",
                "标题": "Defining a New NLP Playground",
                "作者": " Sha Li,  Chi Han,  Pengfei Yu,  Carl Edwards,  Manling Li,  Xingyao Wang,  Yi R. Fung,  Charles Yu,  Joel R. Tetreault,  Eduard H. Hovy,  Heng Ji",
                "发布日期": "2023-11-01",
                "摘要": "  The recent explosion of performance of large language models (LLMs) has\nchanged the field of Natural Language Processing (NLP) more abruptly and\nseismically than any other shift in the field's 80-year history. This has\nresulted in concerns that the field will become homogenized and\nresource-intensive. The new status quo has put many academic researchers,\nespecially PhD students, at a disadvantage. This paper aims to define a new NLP\nplayground by proposing 20+ PhD-dissertation-worthy research directions,\ncovering theoretical analysis, new and challenging problems, learning\nparadigms, and interdisciplinary applications.\n",
                "链接": "https://arxiv.org/abs/2310.20633"
            }
        ]
    },
    {
        "question": {
            "question": "找一下最近关于大模型评测的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "110865",
                "标题": "Branch-Solve-Merge Improves Large Language Model Evaluation and\n  Generation",
                "作者": " Swarnadeep Saha,  Omer Levy,  Asli Celikyilmaz,  Mohit Bansal,  Jason Weston,  Xian Li",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) are frequently used for multi-faceted language\ngeneration and evaluation tasks that involve satisfying intricate user\nconstraints or taking into account multiple aspects and criteria. However,\ntheir performance can fall short, due to the model's lack of coherence and\ninability to plan and decompose the problem. We propose Branch-Solve-Merge\n(BSM), a Large Language Model program (Schlag et al., 2023) for tackling such\nchallenging natural language tasks. It consists of branch, solve, and merge\nmodules that are parameterized with specific prompts to the base LLM. These\nthree modules plan a decomposition of the task into multiple parallel\nsub-tasks, independently solve them, and fuse the solutions to the sub-tasks.\nWe apply our method to the tasks of LLM response evaluation and constrained\ntext generation and evaluate its effectiveness with multiple LLMs, including\nVicuna, LLaMA-2-chat, and GPT-4. BSM improves the evaluation correctness and\nconsistency for each LLM by enhancing human-LLM agreement by up to 26%,\nreducing length and pairwise position biases by up to 50%, and allowing\nLLaMA-2-chat to match or outperform GPT-4 on most domains. On the constraint\nstory generation task, BSM improves the coherence of the stories while also\nimproving constraint satisfaction by 12%.\n",
                "链接": "https://arxiv.org/abs/2310.15123"
            },
            {
                "文章ID": "84705",
                "标题": "PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark\n  for Finance",
                "作者": " Qianqian Xie,  Weiguang Han,  Xiao Zhang,  Yanzhao Lai,  Min Peng,  Alejandro Lopez-Lira,  Jimin Huang",
                "发布日期": "2023-06-12",
                "摘要": "  Although large language models (LLMs) has shown great performance on natural\nlanguage processing (NLP) in the financial domain, there are no publicly\navailable financial tailtored LLMs, instruction tuning datasets, and evaluation\nbenchmarks, which is critical for continually pushing forward the open-source\ndevelopment of financial artificial intelligence (AI). This paper introduces\nPIXIU, a comprehensive framework including the first financial LLM based on\nfine-tuning LLaMA with instruction data, the first instruction data with 136K\ndata samples to support the fine-tuning, and an evaluation benchmark with 5\ntasks and 9 datasets. We first construct the large-scale multi-task instruction\ndata considering a variety of financial tasks, financial document types, and\nfinancial data modalities. We then propose a financial LLM called FinMA by\nfine-tuning LLaMA with the constructed dataset to be able to follow\ninstructions for various financial tasks. To support the evaluation of\nfinancial LLMs, we propose a standardized benchmark that covers a set of\ncritical financial tasks, including five financial NLP tasks and one financial\nprediction task. With this benchmark, we conduct a detailed analysis of FinMA\nand several existing LLMs, uncovering their strengths and weaknesses in\nhandling critical financial tasks. The model, datasets, benchmark, and\nexperimental results are open-sourced to facilitate future research in\nfinancial AI.\n",
                "链接": "https://arxiv.org/abs/2306.05443"
            },
            {
                "文章ID": "104015",
                "标题": "EvalLM: Interactive Evaluation of Large Language Model Prompts on\n  User-Defined Criteria",
                "作者": " Tae Soo Kim,  Yoonjoo Lee,  Jamin Shin,  Young-Ho Kim,  Juho Kim",
                "发布日期": "2023-09-26",
                "摘要": "  By simply composing prompts, developers can prototype novel generative\napplications with Large Language Models (LLMs). To refine prototypes into\nproducts, however, developers must iteratively revise prompts by evaluating\noutputs to diagnose weaknesses. Formative interviews (N=8) revealed that\ndevelopers invest significant effort in manually evaluating outputs as they\nassess context-specific and subjective criteria. We present EvalLM, an\ninteractive system for iteratively refining prompts by evaluating multiple\noutputs on user-defined criteria. By describing criteria in natural language,\nusers can employ the system's LLM-based evaluator to get an overview of where\nprompts excel or fail, and improve these based on the evaluator's feedback. A\ncomparative study (N=12) showed that EvalLM, when compared to manual\nevaluation, helped participants compose more diverse criteria, examine twice as\nmany outputs, and reach satisfactory prompts with 59% fewer revisions. Beyond\nprompts, our work can be extended to augment model evaluation and alignment in\nspecific application contexts.\n",
                "链接": "https://arxiv.org/abs/2309.13633"
            },
            {
                "文章ID": "120482",
                "标题": "A Hardware Evaluation Framework for Large Language Model Inference",
                "作者": " Hengrui Zhang,  August Ning,  Rohan Prabhakar,  David Wentzlaff",
                "发布日期": "2023-12-07",
                "摘要": "  The past year has witnessed the increasing popularity of Large Language\nModels (LLMs). Their unprecedented scale and associated high hardware cost have\nimpeded their broader adoption, calling for efficient hardware designs. With\nthe large hardware needed to simply run LLM inference, evaluating different\nhardware designs becomes a new bottleneck.\n  This work introduces LLMCompass, a hardware evaluation framework for LLM\ninference workloads. LLMCompass is fast, accurate, versatile, and able to\ndescribe and evaluate different hardware designs. LLMCompass includes a mapper\nto automatically find performance-optimal mapping and scheduling. It also\nincorporates an area-based cost model to help architects reason about their\ndesign choices. Compared to real-world hardware, LLMCompass' estimated latency\nachieves an average 10.4% error rate across various operators with various\ninput sizes and an average 4.1% error rate for LLM inference. With LLMCompass,\nsimulating a 4-NVIDIA A100 GPU node running GPT-3 175B inference can be done\nwithin 16 minutes on commodity hardware, including 26,400 rounds of the\nmapper's parameter search.\n  With the aid of LLMCompass, this work draws architectural implications and\nexplores new cost-effective hardware designs. By reducing the compute\ncapability or replacing High Bandwidth Memory (HBM) with traditional DRAM,\nthese new designs can achieve as much as 3.41x improvement in performance/cost\ncompared to an NVIDIA A100, making them promising choices for democratizing\nLLMs.\n  LLMCompass is planned to be fully open-source.\n",
                "链接": "https://arxiv.org/abs/2312.03134"
            },
            {
                "文章ID": "119288",
                "标题": "CritiqueLLM: Scaling LLM-as-Critic for Effective and Explainable\n  Evaluation of Large Language Model Generation",
                "作者": " Pei Ke,  Bosi Wen,  Zhuoer Feng,  Xiao Liu,  Xuanyu Lei,  Jiale Cheng,  Shengyuan Wang,  Aohan Zeng,  Yuxiao Dong,  Hongning Wang,  Jie Tang,  Minlie Huang",
                "发布日期": "2023-12-01",
                "摘要": "  Since the natural language processing (NLP) community started to make large\nlanguage models (LLMs), such as GPT-4, act as a critic to evaluate the quality\nof generated texts, most of them only train a critique generation model of a\nspecific scale on specific datasets. We argue that a comprehensive\ninvestigation on the key factor of LLM-based evaluation models, such as scaling\nproperties, is lacking, so that it is still inconclusive whether these models\nhave potential to replace GPT-4's evaluation in practical scenarios. In this\npaper, we propose a new critique generation model called CritiqueLLM, which\nincludes a dialogue-based prompting method for high-quality referenced /\nreference-free evaluation data. Experimental results show that our model can\nachieve comparable evaluation performance to GPT-4 especially in system-level\ncorrelations, and even outperform GPT-4 in 3 out of 8 tasks in a challenging\nreference-free setting. We conduct detailed analysis to show promising scaling\nproperties of our model in the quality of generated critiques. We also\ndemonstrate that our generated critiques can act as scalable feedback to\ndirectly improve the generation quality of LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.18702"
            },
            {
                "文章ID": "78952",
                "标题": "Revisiting Automated Topic Model Evaluation with Large Language Models",
                "作者": " Dominik Stammbach,  Vilém Zouhar,  Alexander Hoyle,  Mrinmaya Sachan,  Elliott Ash",
                "发布日期": "2023-10-24",
                "摘要": "  Topic models are used to make sense of large text collections. However,\nautomatically evaluating topic model output and determining the optimal number\nof topics both have been longstanding challenges, with no effective automated\nsolutions to date. This paper proposes using large language models to evaluate\nsuch output. We find that large language models appropriately assess the\nresulting topics, correlating more strongly with human judgments than existing\nautomated metrics. We then investigate whether we can use large language models\nto automatically determine the optimal number of topics. We automatically\nassign labels to documents and choosing configurations with the most pure\nlabels returns reasonable values for the optimal number of topics.\n",
                "链接": "https://arxiv.org/abs/2305.12152"
            },
            {
                "文章ID": "72848",
                "标题": "An Evaluation on Large Language Model Outputs: Discourse and\n  Memorization",
                "作者": " Adrian de Wynter,  Xun Wang,  Alex Sokolov,  Qilong Gu,  Si-Qing Chen",
                "发布日期": "2023-07-06",
                "摘要": "  We present an empirical evaluation of various outputs generated by nine of\nthe most widely-available large language models (LLMs). Our analysis is done\nwith off-the-shelf, readily-available tools. We find a correlation between\npercentage of memorized text, percentage of unique text, and overall output\nquality, when measured with respect to output pathologies such as\ncounterfactual and logically-flawed statements, and general failures like not\nstaying on topic. Overall, 80.0% of the outputs evaluated contained memorized\ndata, but outputs containing the most memorized content were also more likely\nto be considered of high quality. We discuss and evaluate mitigation\nstrategies, showing that, in the models evaluated, the rate of memorized text\nbeing output is reduced. We conclude with a discussion on potential\nimplications around what it means to learn, to memorize, and to evaluate\nquality text.\n",
                "链接": "https://arxiv.org/abs/2304.08637"
            },
            {
                "文章ID": "95277",
                "标题": "AgentSims: An Open-Source Sandbox for Large Language Model Evaluation",
                "作者": " Jiaju Lin,  Haoran Zhao,  Aochi Zhang,  Yiting Wu,  Huqiuyue Ping,  Qin Chen",
                "发布日期": "2023-08-09",
                "摘要": "  With ChatGPT-like large language models (LLM) prevailing in the community,\nhow to evaluate the ability of LLMs is an open question. Existing evaluation\nmethods suffer from following shortcomings: (1) constrained evaluation\nabilities, (2) vulnerable benchmarks, (3) unobjective metrics. We suggest that\ntask-based evaluation, where LLM agents complete tasks in a simulated\nenvironment, is a one-for-all solution to solve above problems. We present\nAgentSims, an easy-to-use infrastructure for researchers from all disciplines\nto test the specific capacities they are interested in. Researchers can build\ntheir evaluation tasks by adding agents and buildings on an interactive GUI or\ndeploy and test new support mechanisms, i.e. memory, planning and tool-use\nsystems, by a few lines of codes. Our demo is available at\nhttps://agentsims.com .\n",
                "链接": "https://arxiv.org/abs/2308.04026"
            },
            {
                "文章ID": "115954",
                "标题": "PsyEval: A Comprehensive Large Language Model Evaluation Benchmark for\n  Mental Health",
                "作者": " Haoan Jin,  Siyuan Chen,  Mengyue Wu,  Kenny Q. Zhu",
                "发布日期": "2023-11-16",
                "摘要": "  Recently, there has been a growing interest in utilizing large language\nmodels (LLMs) in mental health research, with studies showcasing their\nremarkable capabilities, such as disease detection. However, there is currently\na lack of a comprehensive benchmark for evaluating the capability of LLMs in\nthis domain. Therefore, we address this gap by introducing the first\ncomprehensive benchmark tailored to the unique characteristics of the mental\nhealth domain. This benchmark encompasses a total of six sub-tasks, covering\nthree dimensions, to systematically assess the capabilities of LLMs in the\nrealm of mental health. We have designed corresponding concise prompts for each\nsub-task. And we comprehensively evaluate a total of eight advanced LLMs using\nour benchmark. Experiment results not only demonstrate significant room for\nimprovement in current LLMs concerning mental health but also unveil potential\ndirections for future model optimization.\n",
                "链接": "https://arxiv.org/abs/2311.09189"
            },
            {
                "文章ID": "96477",
                "标题": "LLM-Mini-CEX: Automatic Evaluation of Large Language Model for\n  Diagnostic Conversation",
                "作者": " Xiaoming Shi,  Jie Xu,  Jinru Ding,  Jiali Pang,  Sichen Liu,  Shuqing Luo,  Xingwei Peng,  Lu Lu,  Haihong Yang,  Mingtao Hu,  Tong Ruan,  Shaoting Zhang",
                "发布日期": "2023-08-16",
                "摘要": "  There is an increasing interest in developing LLMs for medical diagnosis to\nimprove diagnosis efficiency. Despite their alluring technological potential,\nthere is no unified and comprehensive evaluation criterion, leading to the\ninability to evaluate the quality and potential risks of medical LLMs, further\nhindering the application of LLMs in medical treatment scenarios. Besides,\ncurrent evaluations heavily rely on labor-intensive interactions with LLMs to\nobtain diagnostic dialogues and human evaluation on the quality of diagnosis\ndialogue. To tackle the lack of unified and comprehensive evaluation criterion,\nwe first initially establish an evaluation criterion, termed LLM-specific\nMini-CEX to assess the diagnostic capabilities of LLMs effectively, based on\noriginal Mini-CEX. To address the labor-intensive interaction problem, we\ndevelop a patient simulator to engage in automatic conversations with LLMs, and\nutilize ChatGPT for evaluating diagnosis dialogues automatically. Experimental\nresults show that the LLM-specific Mini-CEX is adequate and necessary to\nevaluate medical diagnosis dialogue. Besides, ChatGPT can replace manual\nevaluation on the metrics of humanistic qualities and provides reproducible and\nautomated comparisons between different LLMs.\n",
                "链接": "https://arxiv.org/abs/2308.07635"
            }
        ]
    },
    {
        "question": {
            "question": "近一个月与多模态大模型相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找近六个月工具学习评测数据集的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "25887",
                "标题": "Diagnostic Tool for Out-of-Sample Model Evaluation",
                "作者": " Ludvig Hult,  Dave Zachariah,  Petre Stoica",
                "发布日期": "2023-10-17",
                "摘要": "  Assessment of model fitness is a key part of machine learning. The standard\nparadigm is to learn models by minimizing a chosen loss function averaged over\ntraining data, with the aim of achieving small losses on future data. In this\npaper, we consider the use of a finite calibration data set to characterize the\nfuture, out-of-sample losses of a model. We propose a simple model diagnostic\ntool that provides finite-sample guarantees under weak assumptions. The tool is\nsimple to compute and to interpret. Several numerical experiments are presented\nto show how the proposed method quantifies the impact of distribution shifts,\naids the analysis of regression, and enables model selection as well as\nhyper-parameter tuning.\n",
                "链接": "https://arxiv.org/abs/2206.10982"
            },
            {
                "文章ID": "108993",
                "标题": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
                "作者": " Alon Jacovi,  Avi Caciularu,  Jonathan Herzig,  Roee Aharoni,  Bernd Bohnet,  Mor Geva",
                "发布日期": "2023-12-29",
                "摘要": "  A growing area of research investigates augmenting language models with tools\n(e.g., search engines, calculators) to overcome their shortcomings (e.g.,\nmissing or incorrect knowledge, incorrect logical inferences). Various few-shot\ntool-usage strategies have been proposed. However, there is no systematic and\nfair comparison across different strategies, or between these strategies and\nstrong baselines that do not leverage tools. We conduct an extensive empirical\nanalysis, finding that (1) across various datasets, example difficulty levels,\nand models, strong no-tool baselines are competitive to tool-assisted\nstrategies, implying that effectively using tools with in-context\ndemonstrations is a difficult unsolved problem; (2) for knowledge-retrieval\ntasks, strategies that *refine* incorrect outputs with tools outperform\nstrategies that retrieve relevant information *ahead of* or *during\ngeneration*; (3) tool-assisted strategies are expensive in the number of tokens\nthey require to work -- incurring additional costs by orders of magnitude --\nwhich does not translate into significant improvement in performance. Overall,\nour findings suggest that few-shot tool integration is still an open challenge,\nemphasizing the need for comprehensive evaluations of future strategies to\naccurately assess their *benefits* and *costs*.\n",
                "链接": "https://arxiv.org/abs/2310.10062"
            },
            {
                "文章ID": "118185",
                "标题": "SVRDA: A Web-based Dataset Annotation Tool for Slice-to-Volume\n  Registration",
                "作者": " Weixun Luo,  Alexandre Triay Bagur,  Paul Aljabar,  George Ralli,  Sir Michael Brady",
                "发布日期": "2023-11-28",
                "摘要": "  Background and Objective: The lack of benchmark datasets has impeded the\ndevelopment of slice-to-volume registration algorithms. Such datasets are\ndifficult to annotate, primarily due to the dimensional difference within data\nand the dearth of task-specific software. We aim to develop a user-friendly\ntool to streamline dataset annotation for slice-to-volume registration.\n  Methods: The proposed tool, named SVRDA, is an installation-free web\napplication for platform-agnostic collaborative dataset annotation. It enables\nefficient transformation manipulation via keyboard shortcuts and smooth case\ntransitions with auto-saving. SVRDA supports configuration-based data loading\nand adheres to the separation of concerns, offering great flexibility and\nextensibility for future research. Various supplementary features have been\nimplemented to facilitate slice-to-volume registration.\n  Results: We validated the effectiveness of SVRDA by indirectly evaluating the\npost-registration segmentation quality on UK Biobank data, observing a dramatic\noverall improvement (24.02% in the Dice Similarity Coefficient and 48.93% in\nthe 95th percentile Hausdorff distance, respectively) supported by highly\nstatistically significant evidence ($p<0.001$).We further showcased the\nclinical usage of SVRDA by integrating it into test-retest T1 quantification on\nin-house magnetic resonance images, leading to more consistent results after\nregistration.\n  Conclusions: SVRDA can facilitate collaborative annotation of benchmark\ndatasets while being potentially applicable to other pipelines incorporating\nslice-to-volume registration. Full source code and documentation are available\nat https://github.com/Roldbach/SVRDA\n",
                "链接": "https://arxiv.org/abs/2311.15536"
            },
            {
                "文章ID": "122009",
                "标题": "CholecTrack20: A Dataset for Multi-Class Multiple Tool Tracking in\n  Laparoscopic Surgery",
                "作者": " Chinedu Innocent Nwoye,  Kareem Elgohary,  Anvita Srinivas,  Fauzan Zaid,  Joël L. Lavanchy,  Nicolas Padoy",
                "发布日期": "2023-12-13",
                "摘要": "  Tool tracking in surgical videos is vital in computer-assisted intervention\nfor tasks like surgeon skill assessment, safety zone estimation, and\nhuman-machine collaboration during minimally invasive procedures. The lack of\nlarge-scale datasets hampers Artificial Intelligence implementation in this\ndomain. Current datasets exhibit overly generic tracking formalization, often\nlacking surgical context: a deficiency that becomes evident when tools move out\nof the camera's scope, resulting in rigid trajectories that hinder realistic\nsurgical representation. This paper addresses the need for a more precise and\nadaptable tracking formalization tailored to the intricacies of endoscopic\nprocedures by introducing CholecTrack20, an extensive dataset meticulously\nannotated for multi-class multi-tool tracking across three perspectives\nrepresenting the various ways of considering the temporal duration of a tool\ntrajectory: (1) intraoperative, (2) intracorporeal, and (3) visibility within\nthe camera's scope. The dataset comprises 20 laparoscopic videos with over\n35,000 frames and 65,000 annotated tool instances with details on spatial\nlocation, category, identity, operator, phase, and surgical visual conditions.\nThis detailed dataset caters to the evolving assistive requirements within a\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2312.07352"
            },
            {
                "文章ID": "79415",
                "标题": "SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization\n  Evaluation",
                "作者": " Elizabeth Clark,  Shruti Rijhwani,  Sebastian Gehrmann,  Joshua Maynez,  Roee Aharoni,  Vitaly Nikolaev,  Thibault Sellam,  Aditya Siddhant,  Dipanjan Das,  Ankur P. Parikh",
                "发布日期": "2023-11-03",
                "摘要": "  Reliable automatic evaluation of summarization systems is challenging due to\nthe multifaceted and subjective nature of the task. This is especially the case\nfor languages other than English, where human evaluations are scarce. In this\nwork, we introduce SEAHORSE, a dataset for multilingual, multifaceted\nsummarization evaluation. SEAHORSE consists of 96K summaries with human ratings\nalong 6 dimensions of text quality: comprehensibility, repetition, grammar,\nattribution, main ideas, and conciseness, covering 6 languages, 9 systems and 4\ndatasets. As a result of its size and scope, SEAHORSE can serve both as a\nbenchmark to evaluate learnt metrics, as well as a large-scale resource for\ntraining such metrics. We show that metrics trained with SEAHORSE achieve\nstrong performance on the out-of-domain meta-evaluation benchmarks TRUE\n(Honovich et al., 2022) and mFACE (Aharoni et al., 2022). We make the SEAHORSE\ndataset and metrics publicly available for future research on multilingual and\nmultifaceted summarization evaluation.\n",
                "链接": "https://arxiv.org/abs/2305.13194"
            },
            {
                "文章ID": "92022",
                "标题": "POV-Surgery: A Dataset for Egocentric Hand and Tool Pose Estimation\n  During Surgical Activities",
                "作者": " Rui Wang,  Sophokles Ktistakis,  Siwei Zhang,  Mirko Meboldt,  Quentin Lohmeyer",
                "发布日期": "2023-10-05",
                "摘要": "  The surgical usage of Mixed Reality (MR) has received growing attention in\nareas such as surgical navigation systems, skill assessment, and robot-assisted\nsurgeries. For such applications, pose estimation for hand and surgical\ninstruments from an egocentric perspective is a fundamental task and has been\nstudied extensively in the computer vision field in recent years. However, the\ndevelopment of this field has been impeded by a lack of datasets, especially in\nthe surgical field, where bloody gloves and reflective metallic tools make it\nhard to obtain 3D pose annotations for hands and objects using conventional\nmethods. To address this issue, we propose POV-Surgery, a large-scale,\nsynthetic, egocentric dataset focusing on pose estimation for hands with\ndifferent surgical gloves and three orthopedic surgical instruments, namely\nscalpel, friem, and diskplacer. Our dataset consists of 53 sequences and 88,329\nframes, featuring high-resolution RGB-D video streams with activity\nannotations, accurate 3D and 2D annotations for hand-object pose, and 2D\nhand-object segmentation masks. We fine-tune the current SOTA methods on\nPOV-Surgery and further show the generalizability when applying to real-life\ncases with surgical gloves and tools by extensive evaluations. The code and the\ndataset are publicly available at batfacewayne.github.io/POV_Surgery_io/.\n",
                "链接": "https://arxiv.org/abs/2307.10387"
            },
            {
                "文章ID": "117713",
                "标题": "Brain MRI Screening Tool with Federated Learning",
                "作者": " Roman Stoklasa,  Ioannis Stathopoulos,  Efstratios Karavasilis,  Efstathios Efstathopoulos,  Marek Dostál,  Miloš Keřkovský,  Michal Kozubek,  Luigi Serio",
                "发布日期": "2023-11-27",
                "摘要": "  In clinical practice, we often see significant delays between MRI scans and\nthe diagnosis made by radiologists, even for severe cases. In some cases, this\nmay be caused by the lack of additional information and clues, so even the\nsevere cases need to wait in the queue for diagnosis. This can be avoided if\nthere is an automatic software tool, which would supplement additional\ninformation, alerting radiologists that the particular patient may be a severe\ncase.\n  We are presenting an automatic brain MRI Screening Tool and we are\ndemonstrating its capabilities for detecting tumor-like pathologies. It is the\nfirst version on the path toward a robust multi-pathology screening solution.\nThe tool supports Federated Learning, so multiple institutions may contribute\nto the model without disclosing their private data.\n",
                "链接": "https://arxiv.org/abs/2311.14086"
            },
            {
                "文章ID": "114252",
                "标题": "Understanding Tool Discovery and Tool Innovation Using Active Inference",
                "作者": " Poppy Collis,  Paul F Kinghorn,  Christopher L Buckley",
                "发布日期": "2023-11-08",
                "摘要": "  The ability to invent new tools has been identified as an important facet of\nour ability as a species to problem solve in dynamic and novel environments.\nWhile the use of tools by artificial agents presents a challenging task and has\nbeen widely identified as a key goal in the field of autonomous robotics, far\nless research has tackled the invention of new tools by agents. In this paper,\n(1) we articulate the distinction between tool discovery and tool innovation by\nproviding a minimal description of the two concepts under the formalism of\nactive inference. We then (2) apply this description to construct a toy model\nof tool innovation by introducing the notion of tool affordances into the\nhidden states of the agent's probabilistic generative model. This particular\nstate factorisation facilitates the ability to not just discover tools but\ninvent them through the offline induction of an appropriate tool property. We\ndiscuss the implications of these preliminary results and outline future\ndirections of research.\n",
                "链接": "https://arxiv.org/abs/2311.03893"
            },
            {
                "文章ID": "105321",
                "标题": "Learning Generalizable Tool-use Skills through Trajectory Generation",
                "作者": " Carl Qi,  Sarthak Shetty,  Xingyu Lin,  David Held",
                "发布日期": "2023-10-10",
                "摘要": "  Autonomous systems that efficiently utilize tools can assist humans in\ncompleting many common tasks such as cooking and cleaning. However, current\nsystems fall short of matching human-level of intelligence in terms of adapting\nto novel tools. Prior works based on affordance often make strong assumptions\nabout the environments and cannot scale to more complex, contact-rich tasks. In\nthis work, we tackle this challenge and explore how agents can learn to use\npreviously unseen tools to manipulate deformable objects. We propose to learn a\ngenerative model of the tool-use trajectories as a sequence of point clouds,\nwhich generalizes to different tool shapes. Given any novel tool, we first\ngenerate a tool-use trajectory and then optimize the sequence of tool poses to\nalign with the generated trajectory. We train a single model for four different\nchallenging deformable object manipulation tasks. Our model is trained with\ndemonstration data from just a single tool for each task and is able to\ngeneralize to various novel tools, significantly outperforming baselines.\nAdditional materials can be found on our project website:\nhttps://sites.google.com/view/toolgen.\n",
                "链接": "https://arxiv.org/abs/2310.00156"
            },
            {
                "文章ID": "106599",
                "标题": "CLASSify: A Web-Based Tool for Machine Learning",
                "作者": " Aaron D. Mullen,  Samuel E. Armstrong,  Jeff Talbert,  V. K. Cody Bumgardner",
                "发布日期": "2023-10-06",
                "摘要": "  Machine learning classification problems are widespread in bioinformatics,\nbut the technical knowledge required to perform model training, optimization,\nand inference can prevent researchers from utilizing this technology. This\narticle presents an automated tool for machine learning classification problems\nto simplify the process of training models and producing results while\nproviding informative visualizations and insights into the data. This tool\nsupports both binary and multiclass classification problems, and it provides\naccess to a variety of models and methods. Synthetic data can be generated\nwithin the interface to fill missing values, balance class labels, or generate\nentirely new datasets. It also provides support for feature evaluation and\ngenerates explainability scores to indicate which features influence the output\nthe most. We present CLASSify, an open-source tool for simplifying the user\nexperience of solving classification problems without the need for knowledge of\nmachine learning.\n",
                "链接": "https://arxiv.org/abs/2310.03618"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下工具评测相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "对比解码相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "21348",
                "标题": "Target-aware Abstractive Related Work Generation with Contrastive\n  Learning",
                "作者": " Xiuying Chen,  Hind Alamro,  Mingzhe Li,  Shen Gao,  Rui Yan,  Xin Gao,  Xiangliang Zhang",
                "发布日期": "2022-05-27",
                "摘要": "  The related work section is an important component of a scientific paper,\nwhich highlights the contribution of the target paper in the context of the\nreference papers. Authors can save their time and effort by using the\nautomatically generated related work section as a draft to complete the final\nrelated work. Most of the existing related work section generation methods rely\non extracting off-the-shelf sentences to make a comparative discussion about\nthe target work and the reference papers. However, such sentences need to be\nwritten in advance and are hard to obtain in practice. Hence, in this paper, we\npropose an abstractive target-aware related work generator (TAG), which can\ngenerate related work sections consisting of new sentences. Concretely, we\nfirst propose a target-aware graph encoder, which models the relationships\nbetween reference papers and the target paper with target-centered attention\nmechanisms. In the decoding process, we propose a hierarchical decoder that\nattends to the nodes of different levels in the graph with keyphrases as\nsemantic indicators. Finally, to generate a more informative related work, we\npropose multi-level contrastive optimization objectives, which aim to maximize\nthe mutual information between the generated related work with the references\nand minimize that with non-references. Extensive experiments on two public\nscholar datasets show that the proposed model brings substantial improvements\nover several strong baselines in terms of automatic and tailored human\nevaluations.\n",
                "链接": "https://arxiv.org/abs/2205.13339"
            },
            {
                "文章ID": "95351",
                "标题": "Auditory Attention Decoding with Task-Related Multi-View Contrastive\n  Learning",
                "作者": " Xiaoyu Chen,  Changde Du,  Qiongyi Zhou,  Huiguang He",
                "发布日期": "2023-08-09",
                "摘要": "  The human brain can easily focus on one speaker and suppress others in\nscenarios such as a cocktail party. Recently, researchers found that auditory\nattention can be decoded from the electroencephalogram (EEG) data. However,\nmost existing deep learning methods are difficult to use prior knowledge of\ndifferent views (that is attended speech and EEG are task-related views) and\nextract an unsatisfactory representation. Inspired by Broadbent's filter model,\nwe decode auditory attention in a multi-view paradigm and extract the most\nrelevant and important information utilizing the missing view. Specifically, we\npropose an auditory attention decoding (AAD) method based on multi-view VAE\nwith task-related multi-view contrastive (TMC) learning. Employing TMC learning\nin multi-view VAE can utilize the missing view to accumulate prior knowledge of\ndifferent views into the fusion of representation, and extract the approximate\ntask-related representation. We examine our method on two popular AAD datasets,\nand demonstrate the superiority of our method by comparing it to the\nstate-of-the-art method.\n",
                "链接": "https://arxiv.org/abs/2308.04244"
            },
            {
                "文章ID": "50069",
                "标题": "How do Authors' Perceptions of their Papers Compare with Co-authors'\n  Perceptions and Peer-review Decisions?",
                "作者": " Charvi Rastogi,  Ivan Stelmakh,  Alina Beygelzimer,  Yann N. Dauphin,  Percy Liang,  Jennifer Wortman Vaughan,  Zhenyu Xue, III Hal Daumé,  Emma Pierson,  Nihar B. Shah",
                "发布日期": "2022-11-24",
                "摘要": "  How do author perceptions match up to the outcomes of the peer-review process\nand perceptions of others? In a top-tier computer science conference (NeurIPS\n2021) with more than 23,000 submitting authors and 9,000 submitted papers, we\nsurvey the authors on three questions: (i) their predicted probability of\nacceptance for each of their papers, (ii) their perceived ranking of their own\npapers based on scientific contribution, and (iii) the change in their\nperception about their own papers after seeing the reviews. The salient results\nare: (1) Authors have roughly a three-fold overestimate of the acceptance\nprobability of their papers: The median prediction is 70% for an approximately\n25% acceptance rate. (2) Female authors exhibit a marginally higher\n(statistically significant) miscalibration than male authors; predictions of\nauthors invited to serve as meta-reviewers or reviewers are similarly\ncalibrated, but better than authors who were not invited to review. (3)\nAuthors' relative ranking of scientific contribution of two submissions they\nmade generally agree (93%) with their predicted acceptance probabilities, but\nthere is a notable 7% responses where authors think their better paper will\nface a worse outcome. (4) The author-provided rankings disagreed with the\npeer-review decisions about a third of the time; when co-authors ranked their\njointly authored papers, co-authors disagreed at a similar rate -- about a\nthird of the time. (5) At least 30% of respondents of both accepted and\nrejected papers said that their perception of their own paper improved after\nthe review process. The stakeholders in peer review should take these findings\ninto account in setting their expectations from peer review.\n",
                "链接": "https://arxiv.org/abs/2211.12966"
            },
            {
                "文章ID": "1976",
                "标题": "Why Did You Not Compare With That? Identifying Papers for Use as\n  Baselines",
                "作者": " Manjot Bedi,  Tanisha Pandey,  Sumit Bhatia,  Tanmoy Chakraborty",
                "发布日期": "2022-01-21",
                "摘要": "  We propose the task of automatically identifying papers used as baselines in\na scientific article. We frame the problem as a binary classification task\nwhere all the references in a paper are to be classified as either baselines or\nnon-baselines. This is a challenging problem due to the numerous ways in which\na baseline reference can appear in a paper. We develop a dataset of $2,075$\npapers from ACL anthology corpus with all their references manually annotated\nas one of the two classes. We develop a multi-module attention-based neural\nclassifier for the baseline classification task that outperforms four\nstate-of-the-art citation role classification methods when applied to the\nbaseline classification task. We also present an analysis of the errors made by\nthe proposed classifier, eliciting the challenges that make baseline\nidentification a challenging problem.\n",
                "链接": "https://arxiv.org/abs/2201.08089"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "44909",
                "标题": "Information Filter upon Diversity-Improved Decoding for\n  Diversity-Faithfulness Tradeoff in NLG",
                "作者": " Han Meng,  Xiaosong He,  Zexing Chen,  Feng Zhou",
                "发布日期": "2023-02-22",
                "摘要": "  Some Natural Language Generation (NLG) tasks require both faithfulness and\ndiversity. The decoding strategy is intensively related to the quality of the\ngenerated text. Strategies such as beam search, greedy search, etc., perform\nwith low diversity and high repetition. On the other hand, guided decoding, the\nsolution towards diversity, may generate unfaithful expressions. To this end,\nthis paper presents Information Filter upon Diversity-Improved Decoding (IFDID)\nto obtain the tradeoff between diversity and faithfulness. IFDID is a two-stage\ndecoding strategy leveraging the proposed Enhance-Filter framework, which\nachieves the tradeoff by increasing the probabilities of some typical tokens\nbeing selected and subsequently filtering them by their information amount. To\nverify the effectiveness, we compare our method with other baselines on related\nCommonGEN, RocStories and AdGen benchmarks, which cover Chinese and English\ndatasets. Our numerical experimental results and human evaluation outcomes\nverify the effectiveness of the proposed approach, as our approach achieves a\n1.24 higher ROUGE score describing faithfulness as well as higher diversity\nrepresented by 62.5% higher upon Dist-2 than traditional approaches,\ndemonstrating that IFDID is a novel SOTA decoding strategy for the tradeoff\nbetween diversity and faithfulness.\n",
                "链接": "https://arxiv.org/abs/2210.13829"
            },
            {
                "文章ID": "442",
                "标题": "Automatic Related Work Generation: A Meta Study",
                "作者": " Xiangci Li,  Jessica Ouyang",
                "发布日期": "2022-01-07",
                "摘要": "  Academic research is an exploration activity to solve problems that have\nnever been resolved before. By this nature, each academic research work is\nrequired to perform a literature review to distinguish its novelties that have\nnot been addressed by prior works. In natural language processing, this\nliterature review is usually conducted under the \"Related Work\" section. The\ntask of automatic related work generation aims to automatically generate the\n\"Related Work\" section given the rest of the research paper and a list of cited\npapers. Although this task was proposed over 10 years ago, it received little\nattention until very recently, when it was cast as a variant of the scientific\nmulti-document summarization problem. However, even today, the problems of\nautomatic related work and citation text generation are not yet standardized.\nIn this survey, we conduct a meta-study to compare the existing literature on\nrelated work generation from the perspectives of problem formulation, dataset\ncollection, methodological approach, performance evaluation, and future\nprospects to provide the reader insight into the progress of the\nstate-of-the-art studies, as well as and how future studies can be conducted.\nWe also survey relevant fields of study that we suggest future work to consider\nintegrating.\n",
                "链接": "https://arxiv.org/abs/2201.01880"
            },
            {
                "文章ID": "95587",
                "标题": "NLLG Quarterly arXiv Report 06/23: What are the most influential current\n  AI Papers?",
                "作者": " Steffen Eger,  Christoph Leiter,  Jonas Belouadi,  Ran Zhang,  Aida Kostikova,  Daniil Larionov,  Yanran Chen,  Vivian Fresen",
                "发布日期": "2023-08-15",
                "摘要": "  The rapid growth of information in the field of Generative Artificial\nIntelligence (AI), particularly in the subfields of Natural Language Processing\n(NLP) and Machine Learning (ML), presents a significant challenge for\nresearchers and practitioners to keep pace with the latest developments. To\naddress the problem of information overload, this report by the Natural\nLanguage Learning Group at Bielefeld University focuses on identifying the most\npopular papers on arXiv, with a specific emphasis on NLP and ML. The objective\nis to offer a quick guide to the most relevant and widely discussed research,\naiding both newcomers and established researchers in staying abreast of current\ntrends. In particular, we compile a list of the 40 most popular papers based on\nnormalized citation counts from the first half of 2023. We observe the\ndominance of papers related to Large Language Models (LLMs) and specifically\nChatGPT during the first half of 2023, with the latter showing signs of\ndeclining popularity more recently, however. Further, NLP related papers are\nthe most influential (around 60\\% of top papers) even though there are twice as\nmany ML related papers in our data. Core issues investigated in the most\nheavily cited papers are: LLM efficiency, evaluation techniques, ethical\nconsiderations, embodied agents, and problem-solving with LLMs. Additionally,\nwe examine the characteristics of top papers in comparison to others outside\nthe top-40 list (noticing the top paper's focus on LLM related issues and\nhigher number of co-authors) and analyze the citation distributions in our\ndataset, among others.\n",
                "链接": "https://arxiv.org/abs/2308.04889"
            },
            {
                "文章ID": "42172",
                "标题": "Predicting the clinical citation count of biomedical papers using\n  multilayer perceptron neural network",
                "作者": " Xin Li,  Xuli Tang,  Qikai Cheng",
                "发布日期": "2022-10-24",
                "摘要": "  The number of clinical citations received from clinical guidelines or\nclinical trials has been considered as one of the most appropriate indicators\nfor quantifying the clinical impact of biomedical papers. Therefore, the early\nprediction of the clinical citation count of biomedical papers is critical to\nscientific activities in biomedicine, such as research evaluation, resource\nallocation, and clinical translation. In this study, we designed a four-layer\nmultilayer perceptron neural network (MPNN) model to predict the clinical\ncitation count of biomedical papers in the future by using 9,822,620 biomedical\npapers published from 1985 to 2005. We extracted ninety-one paper features from\nthree dimensions as the input of the model, including twenty-one features in\nthe paper dimension, thirty-five in the reference dimension, and thirty-five in\nthe citing paper dimension. In each dimension, the features can be classified\ninto three categories, i.e., the citation-related features, the clinical\ntranslation-related features, and the topic-related features. Besides, in the\npaper dimension, we also considered the features that have previously been\ndemonstrated to be related to the citation counts of research papers. The\nresults showed that the proposed MPNN model outperformed the other five\nbaseline models, and the features in the reference dimension were the most\nimportant.\n",
                "链接": "https://arxiv.org/abs/2210.06346"
            },
            {
                "文章ID": "120092",
                "标题": "TPPoet: Transformer-Based Persian Poem Generation using Minimal Data and\n  Advanced Decoding Techniques",
                "作者": " Amir Panahandeh,  Hanie Asemi,  Esmaeil Nourani",
                "发布日期": "2023-12-07",
                "摘要": "  Recent advances in language models (LMs), have demonstrated significant\nefficacy in tasks related to the arts and humanities. While LMs have exhibited\nexceptional performance across a wide range of natural language processing\ntasks, there are notable challenges associated with their utilization on small\ndatasets and their ability to replicate more creative human capacities. In this\nstudy, we aim to address these challenges by training a Persian classical\npoetry generation model using a transformer architecture on a specialized\ndataset with no pretraining. Additionally, we propose a novel decoding method\nto enhance coherence and meaningfulness in the generated poetry, effectively\nmanaging the tradeoff between diversity and quality. Furthermore, the results\nof our training approach and the proposed decoding method are evaluated through\ncomprehensive set of automatic and human evaluations and showed its superior\ncapability to generate coherent and meaningful poetry in compare to other\ndecoding methods and an existing Persian large language model (LLM).\n",
                "链接": "https://arxiv.org/abs/2312.02125"
            }
        ]
    },
    {
        "question": {
            "question": "请找到缓和噪声标签影响的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "94423",
                "标题": "Feature Noise Boosts DNN Generalization under Label Noise",
                "作者": " Lu Zeng,  Xuan Chen,  Xiaoshuang Shi,  Heng Tao Shen",
                "发布日期": "2023-08-04",
                "摘要": "  The presence of label noise in the training data has a profound impact on the\ngeneralization of deep neural networks (DNNs). In this study, we introduce and\ntheoretically demonstrate a simple feature noise method, which directly adds\nnoise to the features of training data, can enhance the generalization of DNNs\nunder label noise. Specifically, we conduct theoretical analyses to reveal that\nlabel noise leads to weakened DNN generalization by loosening the PAC-Bayes\ngeneralization bound, and feature noise results in better DNN generalization by\nimposing an upper bound on the mutual information between the model weights and\nthe features, which constrains the PAC-Bayes generalization bound. Furthermore,\nto ensure effective generalization of DNNs in the presence of label noise, we\nconduct application analyses to identify the optimal types and levels of\nfeature noise to add for obtaining desirable label noise generalization.\nFinally, extensive experimental results on several popular datasets demonstrate\nthe feature noise method can significantly enhance the label noise\ngeneralization of the state-of-the-art label noise method.\n",
                "链接": "https://arxiv.org/abs/2308.01609"
            },
            {
                "文章ID": "111388",
                "标题": "Label Propagation for Graph Label Noise",
                "作者": " Yao Cheng,  Caihua Shan,  Yifei Shen,  Xiang Li,  Siqiang Luo,  Dongsheng Li",
                "发布日期": "2023-10-26",
                "摘要": "  Label noise is a common challenge in large datasets, as it can significantly\ndegrade the generalization ability of deep neural networks. Most existing\nstudies focus on noisy labels in computer vision; however, graph models\nencompass both node features and graph topology as input, and become more\nsusceptible to label noise through message-passing mechanisms. Recently, only a\nfew works have been proposed to tackle the label noise on graphs. One major\nlimitation is that they assume the graph is homophilous and the labels are\nsmoothly distributed. Nevertheless, real-world graphs may contain varying\ndegrees of heterophily or even be heterophily-dominated, leading to the\ninadequacy of current methods. In this paper, we study graph label noise in the\ncontext of arbitrary heterophily, with the aim of rectifying noisy labels and\nassigning labels to previously unlabeled nodes. We begin by conducting two\nempirical analyses to explore the impact of graph homophily on graph label\nnoise. Following observations, we propose a simple yet efficient algorithm,\ndenoted as LP4GLN. Specifically, LP4GLN is an iterative algorithm with three\nsteps: (1) reconstruct the graph to recover the homophily property, (2) utilize\nlabel propagation to rectify the noisy labels, (3) select high-confidence\nlabels to retain for the next iteration. By iterating these steps, we obtain a\nset of correct labels, ultimately achieving high accuracy in the node\nclassification task. The theoretical analysis is also provided to demonstrate\nits remarkable denoising \"effect\". Finally, we conduct experiments on 10\nbenchmark datasets under varying graph heterophily levels and noise types,\ncomparing the performance of LP4GLN with 7 typical baselines. Our results\nillustrate the superior performance of the proposed LP4GLN.\n",
                "链接": "https://arxiv.org/abs/2310.16560"
            },
            {
                "文章ID": "80913",
                "标题": "Handling Realistic Label Noise in BERT Text Classification",
                "作者": " Maha Tufail Agro,  Hanan Aldarmaki",
                "发布日期": "2023-10-23",
                "摘要": "  Labels noise refers to errors in training labels caused by cheap data\nannotation methods, such as web scraping or crowd-sourcing, which can be\ndetrimental to the performance of supervised classifiers. Several methods have\nbeen proposed to counteract the effect of random label noise in supervised\nclassification, and some studies have shown that BERT is already robust against\nhigh rates of randomly injected label noise. However, real label noise is not\nrandom; rather, it is often correlated with input features or other\nannotator-specific factors. In this paper, we evaluate BERT in the presence of\ntwo types of realistic label noise: feature-dependent label noise, and\nsynthetic label noise from annotator disagreements. We show that the presence\nof these types of noise significantly degrades BERT classification performance.\nTo improve robustness, we evaluate different types of ensembles and\nnoise-cleaning methods and compare their effectiveness against label noise\nacross different datasets.\n",
                "链接": "https://arxiv.org/abs/2305.16337"
            },
            {
                "文章ID": "83903",
                "标题": "Binary Classification with Instance and Label Dependent Label Noise",
                "作者": " Hyungki Im,  Paul Grigas",
                "发布日期": "2023-06-07",
                "摘要": "  Learning with label dependent label noise has been extensively explored in\nboth theory and practice; however, dealing with instance (i.e., feature) and\nlabel dependent label noise continues to be a challenging task. The difficulty\narises from the fact that the noise rate varies for each instance, making it\nchallenging to estimate accurately. The question of whether it is possible to\nlearn a reliable model using only noisy samples remains unresolved. We answer\nthis question with a theoretical analysis that provides matching upper and\nlower bounds. Surprisingly, our results show that, without any additional\nassumptions, empirical risk minimization achieves the optimal excess risk\nbound. Specifically, we derive a novel excess risk bound proportional to the\nnoise level, which holds in very general settings, by comparing the empirical\nrisk minimizers obtained from clean samples and noisy samples. Second, we show\nthat the minimax lower bound for the 0-1 loss is a constant proportional to the\naverage noise rate. Our findings suggest that learning solely with noisy\nsamples is impossible without access to clean samples or strong assumptions on\nthe distribution of the data.\n",
                "链接": "https://arxiv.org/abs/2306.03402"
            },
            {
                "文章ID": "32080",
                "标题": "Noise tolerance of learning to rank under class-conditional label noise",
                "作者": " Dany Haddad",
                "发布日期": "2022-08-18",
                "摘要": "  Often, the data used to train ranking models is subject to label noise. For\nexample, in web-search, labels created from clickstream data are noisy due to\nissues such as insufficient information in item descriptions on the SERP, query\nreformulation by the user, and erratic or unexpected user behavior. In\npractice, it is difficult to handle label noise without making strong\nassumptions about the label generation process. As a result, practitioners\ntypically train their learning-to-rank (LtR) models directly on this noisy data\nwithout additional consideration of the label noise. Surprisingly, we often see\nstrong performance from LtR models trained in this way. In this work, we\ndescribe a class of noise-tolerant LtR losses for which empirical risk\nminimization is a consistent procedure, even in the context of\nclass-conditional label noise. We also develop noise-tolerant analogs of\ncommonly used loss functions. The practical implications of our theoretical\nfindings are further supported by experimental results.\n",
                "链接": "https://arxiv.org/abs/2208.02126"
            },
            {
                "文章ID": "92847",
                "标题": "Label Noise: Correcting a Correction",
                "作者": " William Toner,  Amos Storkey",
                "发布日期": "2023-07-26",
                "摘要": "  Training neural network classifiers on datasets with label noise poses a risk\nof overfitting them to the noisy labels. To address this issue, researchers\nhave explored alternative loss functions that aim to be more robust. However,\nmany of these alternatives are heuristic in nature and still vulnerable to\noverfitting or underfitting. In this work, we propose a more direct approach to\ntackling overfitting caused by label noise. We observe that the presence of\nlabel noise implies a lower bound on the noisy generalised risk. Building upon\nthis observation, we propose imposing a lower bound on the empirical risk\nduring training to mitigate overfitting. Our main contribution is providing\ntheoretical results that yield explicit, easily computable bounds on the\nminimum achievable noisy risk for different loss functions. We empirically\ndemonstrate that using these bounds significantly enhances robustness in\nvarious settings, with virtually no additional computational cost.\n",
                "链接": "https://arxiv.org/abs/2307.13100"
            },
            {
                "文章ID": "22618",
                "标题": "Robustness to Label Noise Depends on the Shape of the Noise Distribution\n  in Feature Space",
                "作者": " Diane Oyen,  Michal Kucer,  Nick Hengartner,  Har Simrat Singh",
                "发布日期": "2022-06-03",
                "摘要": "  Machine learning classifiers have been demonstrated, both empirically and\ntheoretically, to be robust to label noise under certain conditions -- notably\nthe typical assumption is that label noise is independent of the features given\nthe class label. We provide a theoretical framework that generalizes beyond\nthis typical assumption by modeling label noise as a distribution over feature\nspace. We show that both the scale and the shape of the noise distribution\ninfluence the posterior likelihood; and the shape of the noise distribution has\na stronger impact on classification performance if the noise is concentrated in\nfeature space where the decision boundary can be moved. For the special case of\nuniform label noise (independent of features and the class label), we show that\nthe Bayes optimal classifier for $c$ classes is robust to label noise until the\nratio of noisy samples goes above $\\frac{c-1}{c}$ (e.g. 90% for 10 classes),\nwhich we call the tipping point. However, for the special case of\nclass-dependent label noise (independent of features given the class label),\nthe tipping point can be as low as 50%. Most importantly, we show that when the\nnoise distribution targets decision boundaries (label noise is directly\ndependent on feature space), classification robustness can drop off even at a\nsmall scale of noise. Even when evaluating recent label-noise mitigation\nmethods we see reduced accuracy when label noise is dependent on features.\nThese findings explain why machine learning often handles label noise well if\nthe noise distribution is uniform in feature-space; yet it also points to the\ndifficulty of overcoming label noise when it is concentrated in a region of\nfeature space where a decision boundary can move.\n",
                "链接": "https://arxiv.org/abs/2206.01106"
            },
            {
                "文章ID": "28377",
                "标题": "A law of adversarial risk, interpolation, and label noise",
                "作者": " Daniel Paleka,  Amartya Sanyal",
                "发布日期": "2023-03-15",
                "摘要": "  In supervised learning, it has been shown that label noise in the data can be\ninterpolated without penalties on test accuracy. We show that interpolating\nlabel noise induces adversarial vulnerability, and prove the first theorem\nshowing the relationship between label noise and adversarial risk for any data\ndistribution. Our results are almost tight if we do not make any assumptions on\nthe inductive bias of the learning algorithm. We then investigate how different\ncomponents of this problem affect this result, including properties of the\ndistribution. We also discuss non-uniform label noise distributions; and prove\na new theorem showing uniform label noise induces nearly as large an\nadversarial risk as the worst poisoning with the same noise rate. Then, we\nprovide theoretical and empirical evidence that uniform label noise is more\nharmful than typical real-world label noise. Finally, we show how inductive\nbiases amplify the effect of label noise and argue the need for future work in\nthis direction.\n",
                "链接": "https://arxiv.org/abs/2207.03933"
            },
            {
                "文章ID": "53932",
                "标题": "Instance-specific Label Distribution Regularization for Learning with\n  Label Noise",
                "作者": " Zehui Liao,  Shishuai Hu,  Yutong Xie,  Yong Xia",
                "发布日期": "2022-12-19",
                "摘要": "  Modeling noise transition matrix is a kind of promising method for learning\nwith label noise. Based on the estimated noise transition matrix and the noisy\nposterior probabilities, the clean posterior probabilities, which are jointly\ncalled Label Distribution (LD) in this paper, can be calculated as the\nsupervision. To reliably estimate the noise transition matrix, some methods\nassume that anchor points are available during training. Nonetheless, if anchor\npoints are invalid, the noise transition matrix might be poorly learned,\nresulting in poor performance. Consequently, other methods treat reliable data\npoints, extracted from training data, as pseudo anchor points. However, from a\nstatistical point of view, the noise transition matrix can be inferred from\ndata with noisy labels under the clean-label-domination assumption. Therefore,\nwe aim to estimate the noise transition matrix without (pseudo) anchor points.\nThere is evidence showing that samples are more likely to be mislabeled as\nother similar class labels, which means the mislabeling probability is highly\ncorrelated with the inter-class correlation. Inspired by this observation, we\npropose an instance-specific Label Distribution Regularization (LDR), in which\nthe instance-specific LD is estimated as the supervision, to prevent DCNNs from\nmemorizing noisy labels. Specifically, we estimate the noisy posterior under\nthe supervision of noisy labels, and approximate the batch-level noise\ntransition matrix by estimating the inter-class correlation matrix with neither\nanchor points nor pseudo anchor points. Experimental results on two synthetic\nnoisy datasets and two real-world noisy datasets demonstrate that our LDR\noutperforms existing methods.\n",
                "链接": "https://arxiv.org/abs/2212.08380"
            },
            {
                "文章ID": "45310",
                "标题": "Deep Learning is Provably Robust to Symmetric Label Noise",
                "作者": " Carey E. Priebe,  Ningyuan Huang,  Soledad Villar,  Cong Mu,  Li Chen",
                "发布日期": "2022-10-28",
                "摘要": "  Deep neural networks (DNNs) are capable of perfectly fitting the training\ndata, including memorizing noisy data. It is commonly believed that\nmemorization hurts generalization. Therefore, many recent works propose\nmitigation strategies to avoid noisy data or correct memorization. In this\nwork, we step back and ask the question: Can deep learning be robust against\nmassive label noise without any mitigation? We provide an affirmative answer\nfor the case of symmetric label noise: We find that certain DNNs, including\nunder-parameterized and over-parameterized models, can tolerate massive\nsymmetric label noise up to the information-theoretic threshold. By appealing\nto classical statistical theory and universal consistency of DNNs, we prove\nthat for multiclass classification, $L_1$-consistent DNN classifiers trained\nunder symmetric label noise can achieve Bayes optimality asymptotically if the\nlabel noise probability is less than $\\frac{K-1}{K}$, where $K \\ge 2$ is the\nnumber of classes. Our results show that for symmetric label noise, no\nmitigation is necessary for $L_1$-consistent estimators. We conjecture that for\ngeneral label noise, mitigation strategies that make use of the noisy data will\noutperform those that ignore the noisy data.\n",
                "链接": "https://arxiv.org/abs/2210.15083"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下文本检索任务上，是否有关于大模型在语义坍缩问题上的研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "55962",
                "标题": "Understanding Imbalanced Semantic Segmentation Through Neural Collapse",
                "作者": " Zhisheng Zhong,  Jiequan Cui,  Yibo Yang,  Xiaoyang Wu,  Xiaojuan Qi,  Xiangyu Zhang,  Jiaya Jia",
                "发布日期": "2023-01-04",
                "摘要": "  A recent study has shown a phenomenon called neural collapse in that the\nwithin-class means of features and the classifier weight vectors converge to\nthe vertices of a simplex equiangular tight frame at the terminal phase of\ntraining for classification. In this paper, we explore the corresponding\nstructures of the last-layer feature centers and classifiers in semantic\nsegmentation. Based on our empirical and theoretical analysis, we point out\nthat semantic segmentation naturally brings contextual correlation and\nimbalanced distribution among classes, which breaks the equiangular and\nmaximally separated structure of neural collapse for both feature centers and\nclassifiers. However, such a symmetric structure is beneficial to\ndiscrimination for the minor classes. To preserve these advantages, we\nintroduce a regularizer on feature centers to encourage the network to learn\nfeatures closer to the appealing structure in imbalanced semantic segmentation.\nExperimental results show that our method can bring significant improvements on\nboth 2D and 3D semantic segmentation benchmarks. Moreover, our method ranks 1st\nand sets a new record (+6.8% mIoU) on the ScanNet200 test leaderboard. Code\nwill be available at https://github.com/dvlab-research/Imbalanced-Learning.\n",
                "链接": "https://arxiv.org/abs/2301.01100"
            },
            {
                "文章ID": "45847",
                "标题": "Perturbation Analysis of Neural Collapse",
                "作者": " Tom Tirer,  Haoxiang Huang,  Jonathan Niles-Weed",
                "发布日期": "2023-05-30",
                "摘要": "  Training deep neural networks for classification often includes minimizing\nthe training loss beyond the zero training error point. In this phase of\ntraining, a \"neural collapse\" behavior has been observed: the variability of\nfeatures (outputs of the penultimate layer) of within-class samples decreases\nand the mean features of different classes approach a certain tight frame\nstructure. Recent works analyze this behavior via idealized unconstrained\nfeatures models where all the minimizers exhibit exact collapse. However, with\npractical networks and datasets, the features typically do not reach exact\ncollapse, e.g., because deep layers cannot arbitrarily modify intermediate\nfeatures that are far from being collapsed. In this paper, we propose a richer\nmodel that can capture this phenomenon by forcing the features to stay in the\nvicinity of a predefined features matrix (e.g., intermediate features). We\nexplore the model in the small vicinity case via perturbation analysis and\nestablish results that cannot be obtained by the previously studied models. For\nexample, we prove reduction in the within-class variability of the optimized\nfeatures compared to the predefined input features (via analyzing gradient flow\non the \"central-path\" with minimal assumptions), analyze the minimizers in the\nnear-collapse regime, and provide insights on the effect of regularization\nhyperparameters on the closeness to collapse. We support our theory with\nexperiments in practical deep learning settings.\n",
                "链接": "https://arxiv.org/abs/2210.16658"
            },
            {
                "文章ID": "55800",
                "标题": "Posterior Collapse and Latent Variable Non-identifiability",
                "作者": " Yixin Wang,  David M. Blei,  John P. Cunningham",
                "发布日期": "2023-01-03",
                "摘要": "  Variational autoencoders model high-dimensional data by positing\nlow-dimensional latent variables that are mapped through a flexible\ndistribution parametrized by a neural network. Unfortunately, variational\nautoencoders often suffer from posterior collapse: the posterior of the latent\nvariables is equal to its prior, rendering the variational autoencoder useless\nas a means to produce meaningful representations. Existing approaches to\nposterior collapse often attribute it to the use of neural networks or\noptimization issues due to variational approximation. In this paper, we\nconsider posterior collapse as a problem of latent variable\nnon-identifiability. We prove that the posterior collapses if and only if the\nlatent variables are non-identifiable in the generative model. This fact\nimplies that posterior collapse is not a phenomenon specific to the use of\nflexible distributions or approximate inference. Rather, it can occur in\nclassical probabilistic models even with exact inference, which we also\ndemonstrate. Based on these results, we propose a class of latent-identifiable\nvariational autoencoders, deep generative models which enforce identifiability\nwithout sacrificing flexibility. This model class resolves the problem of\nlatent variable non-identifiability by leveraging bijective Brenier maps and\nparameterizing them with input convex neural networks, without special\nvariational inference objectives or optimization tricks. Across synthetic and\nreal datasets, latent-identifiable variational autoencoders outperform existing\nmethods in mitigating posterior collapse and providing meaningful\nrepresentations of the data.\n",
                "链接": "https://arxiv.org/abs/2301.00537"
            },
            {
                "文章ID": "84537",
                "标题": "Posterior Collapse in Linear Conditional and Hierarchical Variational\n  Autoencoders",
                "作者": " Hien Dang,  Tho Tran,  Tan Nguyen,  Nhat Ho",
                "发布日期": "2023-06-09",
                "摘要": "  The posterior collapse phenomenon in variational autoencoders (VAEs), where\nthe variational posterior distribution closely matches the prior distribution,\ncan hinder the quality of the learned latent variables. As a consequence of\nposterior collapse, the latent variables extracted by the encoder in VAEs\npreserve less information from the input data and thus fail to produce\nmeaningful representations as input to the reconstruction process in the\ndecoder. While this phenomenon has been an actively addressed topic related to\nVAEs performance, the theory for posterior collapse remains underdeveloped,\nespecially beyond the standard VAEs. In this work, we advance the theoretical\nunderstanding of posterior collapse to two important and prevalent yet less\nstudied classes of VAEs: conditional VAEs and hierarchical VAEs. Specifically,\nvia a non-trivial theoretical analysis of linear conditional VAEs and\nhierarchical VAEs with two levels of latent, we prove that the cause of\nposterior collapses in these models includes the correlation between the input\nand output of the conditional VAEs and the effect of learnable encoder variance\nin the hierarchical VAEs. We empirically validate our theoretical findings for\nlinear conditional and hierarchical VAEs and demonstrate that these results are\nalso predictive for non-linear cases.\n",
                "链接": "https://arxiv.org/abs/2306.05023"
            },
            {
                "文章ID": "106836",
                "标题": "On the Embedding Collapse when Scaling up Recommendation Models",
                "作者": " Xingzhuo Guo,  Junwei Pan,  Ximei Wang,  Baixu Chen,  Jie Jiang,  Mingsheng Long",
                "发布日期": "2023-10-09",
                "摘要": "  Recent advances in deep foundation models have led to a promising trend of\ndeveloping large recommendation models to leverage vast amounts of available\ndata. However, we experiment to scale up existing recommendation models and\nobserve that the enlarged models do not improve satisfactorily. In this\ncontext, we investigate the embedding layers of enlarged models and identify a\nphenomenon of embedding collapse, which ultimately hinders scalability, wherein\nthe embedding matrix tends to reside in a low-dimensional subspace. Through\nempirical and theoretical analysis, we demonstrate that the feature interaction\nmodule specific to recommendation models has a two-sided effect. On the one\nhand, the interaction restricts embedding learning when interacting with\ncollapsed embeddings, exacerbating the collapse issue. On the other hand,\nfeature interaction is crucial in mitigating the fitting of spurious features,\nthereby improving scalability. Based on this analysis, we propose a simple yet\neffective multi-embedding design incorporating embedding-set-specific\ninteraction modules to capture diverse patterns and reduce collapse. Extensive\nexperiments demonstrate that this proposed design provides consistent\nscalability for various recommendation models.\n",
                "链接": "https://arxiv.org/abs/2310.04400"
            },
            {
                "文章ID": "104780",
                "标题": "Feature Normalization Prevents Collapse of Non-contrastive Learning\n  Dynamics",
                "作者": " Han Bao",
                "发布日期": "2023-09-29",
                "摘要": "  Contrastive learning is a self-supervised representation learning framework,\nwhere two positive views generated through data augmentation are made similar\nby an attraction force in a data representation space, while a repulsive force\nmakes them far from negative examples. Non-contrastive learning, represented by\nBYOL and SimSiam, further gets rid of negative examples and improves\ncomputational efficiency. While learned representations may collapse into a\nsingle point due to the lack of the repulsive force at first sight, Tian et al.\n(2021) revealed through the learning dynamics analysis that the representations\ncan avoid collapse if data augmentation is sufficiently stronger than\nregularization. However, their analysis does not take into account\ncommonly-used feature normalization, a normalizer before measuring the\nsimilarity of representations, and hence excessively strong regularization may\ncollapse the dynamics, which is an unnatural behavior under the presence of\nfeature normalization. Therefore, we extend the previous theory based on the L2\nloss by considering the cosine loss, which involves feature normalization. We\nshow that the cosine loss induces sixth-order dynamics (while the L2 loss\ninduces a third-order one), in which a stable equilibrium dynamically emerges\neven if there are only collapsed solutions with given initial parameters. Thus,\nwe offer a new understanding that feature normalization plays an important role\nin robustly preventing the dynamics collapse.\n",
                "链接": "https://arxiv.org/abs/2309.16109"
            },
            {
                "文章ID": "74201",
                "标题": "Controlling Posterior Collapse by an Inverse Lipschitz Constraint on the\n  Decoder Network",
                "作者": " Yuri Kinoshita,  Kenta Oono,  Kenji Fukumizu,  Yuichi Yoshida,  Shin-ichi Maeda",
                "发布日期": "2023-04-26",
                "摘要": "  Variational autoencoders (VAEs) are one of the deep generative models that\nhave experienced enormous success over the past decades. However, in practice,\nthey suffer from a problem called posterior collapse, which occurs when the\nencoder coincides, or collapses, with the prior taking no information from the\nlatent structure of the input data into consideration. In this work, we\nintroduce an inverse Lipschitz neural network into the decoder and, based on\nthis architecture, provide a new method that can control in a simple and clear\nmanner the degree of posterior collapse for a wide range of VAE models equipped\nwith a concrete theoretical guarantee. We also illustrate the effectiveness of\nour method through several numerical experiments.\n",
                "链接": "https://arxiv.org/abs/2304.12770"
            },
            {
                "文章ID": "80825",
                "标题": "Feature Collapse",
                "作者": " Thomas Laurent,  James H. von Brecht,  Xavier Bresson",
                "发布日期": "2023-05-26",
                "摘要": "  We formalize and study a phenomenon called feature collapse that makes\nprecise the intuitive idea that entities playing a similar role in a learning\ntask receive similar representations. As feature collapse requires a notion of\ntask, we leverage a simple but prototypical NLP task to study it. We start by\nshowing experimentally that feature collapse goes hand in hand with\ngeneralization. We then prove that, in the large sample limit, distinct words\nthat play identical roles in this NLP task receive identical local feature\nrepresentations in a neural network. This analysis reveals the crucial role\nthat normalization mechanisms, such as LayerNorm, play in feature collapse and\nin generalization.\n",
                "链接": "https://arxiv.org/abs/2305.16162"
            },
            {
                "文章ID": "28395",
                "标题": "Event Collapse in Contrast Maximization Frameworks",
                "作者": " Shintaro Shiba,  Yoshimitsu Aoki,  Guillermo Gallego",
                "发布日期": "2022-07-12",
                "摘要": "  Contrast maximization (CMax) is a framework that provides state-of-the-art\nresults on several event-based computer vision tasks, such as ego-motion or\noptical flow estimation. However, it may suffer from a problem called event\ncollapse, which is an undesired solution where events are warped into too few\npixels. As prior works have largely ignored the issue or proposed workarounds,\nit is imperative to analyze this phenomenon in detail. Our work demonstrates\nevent collapse in its simplest form and proposes collapse metrics by using\nfirst principles of space-time deformation based on differential geometry and\nphysics. We experimentally show on publicly available datasets that the\nproposed metrics mitigate event collapse and do not harm well-posed warps. To\nthe best of our knowledge, regularizers based on the proposed metrics are the\nonly effective solution against event collapse in the experimental settings\nconsidered, compared with other methods. We hope that this work inspires\nfurther research to tackle more complex warp models.\n",
                "链接": "https://arxiv.org/abs/2207.04007"
            },
            {
                "文章ID": "42805",
                "标题": "$\\Lambda$-DARTS: Mitigating Performance Collapse by Harmonizing\n  Operation Selection among Cells",
                "作者": " Sajad Movahedi,  Melika Adabinejad,  Ayyoob Imani,  Arezou Keshavarz,  Mostafa Dehghani,  Azadeh Shakery,  Babak N. Araabi",
                "发布日期": "2023-03-03",
                "摘要": "  Differentiable neural architecture search (DARTS) is a popular method for\nneural architecture search (NAS), which performs cell-search and utilizes\ncontinuous relaxation to improve the search efficiency via gradient-based\noptimization. The main shortcoming of DARTS is performance collapse, where the\ndiscovered architecture suffers from a pattern of declining quality during\nsearch. Performance collapse has become an important topic of research, with\nmany methods trying to solve the issue through either regularization or\nfundamental changes to DARTS. However, the weight-sharing framework used for\ncell-search in DARTS and the convergence of architecture parameters has not\nbeen analyzed yet. In this paper, we provide a thorough and novel theoretical\nand empirical analysis on DARTS and its point of convergence. We show that\nDARTS suffers from a specific structural flaw due to its weight-sharing\nframework that limits the convergence of DARTS to saturation points of the\nsoftmax function. This point of convergence gives an unfair advantage to layers\ncloser to the output in choosing the optimal architecture, causing performance\ncollapse. We then propose two new regularization terms that aim to prevent\nperformance collapse by harmonizing operation selection via aligning gradients\nof layers. Experimental results on six different search spaces and three\ndifferent datasets show that our method ($\\Lambda$-DARTS) does indeed prevent\nperformance collapse, providing justification for our theoretical analysis and\nthe proposed remedy.\n",
                "链接": "https://arxiv.org/abs/2210.07998"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找对机器翻译数据集质量进行评估的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "78515",
                "标题": "Discourse Centric Evaluation of Machine Translation with a Densely\n  Annotated Parallel Corpus",
                "作者": " Yuchen Eleanor Jiang,  Tianyu Liu,  Shuming Ma,  Dongdong Zhang,  Mrinmaya Sachan,  Ryan Cotterell",
                "发布日期": "2023-05-19",
                "摘要": "  Several recent papers claim human parity at sentence-level Machine\nTranslation (MT), especially in high-resource languages. Thus, in response, the\nMT community has, in part, shifted its focus to document-level translation.\nTranslating documents requires a deeper understanding of the structure and\nmeaning of text, which is often captured by various kinds of discourse\nphenomena such as consistency, coherence, and cohesion. However, this renders\nconventional sentence-level MT evaluation benchmarks inadequate for evaluating\nthe performance of context-aware MT systems. This paper presents a new dataset\nwith rich discourse annotations, built upon the large-scale parallel corpus BWB\nintroduced in Jiang et al. (2022). The new BWB annotation introduces four extra\nevaluation aspects, i.e., entity, terminology, coreference, and quotation,\ncovering 15,095 entity mentions in both languages. Using these annotations, we\nsystematically investigate the similarities and differences between the\ndiscourse structures of source and target languages, and the challenges they\npose to MT. We discover that MT outputs differ fundamentally from human\ntranslations in terms of their latent discourse structures. This gives us a new\nperspective on the challenges and opportunities in document-level MT. We make\nour resource publicly available to spur future research in document-level MT\nand the generalization to other language translation tasks.\n",
                "链接": "https://arxiv.org/abs/2305.11142"
            },
            {
                "文章ID": "32341",
                "标题": "Out of the BLEU: how should we assess quality of the Code Generation\n  models?",
                "作者": " Mikhail Evtikhiev,  Egor Bogomolov,  Yaroslav Sokolov,  Timofey Bryksin",
                "发布日期": "2023-05-11",
                "摘要": "  In recent years, researchers have created and introduced a significant number\nof various code generation models. As human evaluation of every new model\nversion is unfeasible, the community adopted automatic evaluation metrics such\nas BLEU to approximate the results of human judgement. These metrics originate\nfrom the machine translation domain and it is unclear whether they are\napplicable for the code generation tasks and how well they agree with the human\nevaluation on this task. There are also other metrics, CodeBLEU and RUBY,\ndeveloped to estimate the similarity of code, that take into account the\nproperties of source code. However, for these metrics there are hardly any\nstudies on their agreement with the human evaluation. Despite all that, minimal\ndifferences in the metric scores have been used in recent papers to claim\nsuperiority of some code generation models over the others.\n  In this paper, we present a study on the applicability of six metrics --\nBLEU, ROUGE-L, METEOR, ChrF, CodeBLEU, and RUBY -- for evaluation of code\ngeneration models. We conduct a study on two different code generation datasets\nand use human annotators to assess the quality of all models run on these\ndatasets. The results indicate that for the CoNaLa dataset of Python\none-liners, none of the metrics can correctly emulate human judgement on which\nmodel is better with >95% certainty if the difference in model scores is less\nthan 5 points. For the HearthStone dataset, which consists of classes of a\nparticular structure, a difference in model scores of at least 2 points is\nenough to claim the superiority of one model over the other. Our findings\nsuggest that the ChrF metric is a better fit for the evaluation of code\ngeneration models than the commonly used BLEU and CodeBLEU. Yet, finding a\nmetric for code generation that closely agrees with humans requires additional\nwork.\n",
                "链接": "https://arxiv.org/abs/2208.03133"
            }
        ]
    },
    {
        "question": {
            "question": "查找大语言模型相关的分析类型的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查询2022年以来指令遵循数据集构建相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "0",
                "标题": "A Literature Review on Length of Stay Prediction for Stroke Patients\n  using Machine Learning and Statistical Approaches",
                "作者": " Ola Alkhatib,  Ayman Alahmar",
                "发布日期": "2022-01-06",
                "摘要": "  Hospital length of stay (LOS) is one of the most essential healthcare metrics\nthat reflects the hospital quality of service and helps improve hospital\nscheduling and management. LOS prediction helps in cost management because\npatients who remain in hospitals usually do so in hospital units where\nresources are severely limited. In this study, we reviewed papers on LOS\nprediction using machine learning and statistical approaches. Our literature\nreview considers research studies that focus on LOS prediction for stroke\npatients. Some of the surveyed studies revealed that authors reached\ncontradicting conclusions. For example, the age of the patient was considered\nan important predictor of LOS for stroke patients in some studies, while other\nstudies concluded that age was not a significant factor. Therefore, additional\nresearch is required in this domain to further understand the predictors of LOS\nfor stroke patients.\n",
                "链接": "https://arxiv.org/abs/2201.00005"
            },
            {
                "文章ID": "1",
                "标题": "Leveraging Queue Length and Attention Mechanisms for Enhanced Traffic\n  Signal Control Optimization",
                "作者": " Liang Zhang,  Shubin Xie,  Jianming Deng",
                "发布日期": "2023-09-26",
                "摘要": "  Reinforcement learning (RL) techniques for traffic signal control (TSC) have\ngained increasing popularity in recent years. However, most existing RL-based\nTSC methods tend to focus primarily on the RL model structure while neglecting\nthe significance of proper traffic state representation. Furthermore, some\nRL-based methods heavily rely on expert-designed traffic signal phase\ncompetition. In this paper, we present a novel approach to TSC that utilizes\nqueue length as an efficient state representation. We propose two new methods:\n(1) Max Queue-Length (M-QL), an optimization-based traditional method designed\nbased on the property of queue length; and (2) AttentionLight, an RL model that\nemploys the self-attention mechanism to capture the signal phase correlation\nwithout requiring human knowledge of phase relationships. Comprehensive\nexperiments on multiple real-world datasets demonstrate the effectiveness of\nour approach: (1) the M-QL method outperforms the latest RL-based methods; (2)\nAttentionLight achieves a new state-of-the-art performance; and (3) our results\nhighlight the significance of proper state representation, which is as crucial\nas neural network design in TSC methods. Our findings have important\nimplications for advancing the development of more effective and efficient TSC\nmethods. Our code is released on Github (https://github.\ncom/LiangZhang1996/AttentionLight).\n",
                "链接": "https://arxiv.org/abs/2201.00006"
            },
            {
                "文章ID": "2",
                "标题": "Confidence-Aware Multi-Teacher Knowledge Distillation",
                "作者": " Hailin Zhang,  Defang Chen,  Can Wang",
                "发布日期": "2022-02-15",
                "摘要": "  Knowledge distillation is initially introduced to utilize additional\nsupervision from a single teacher model for the student model training. To\nboost the student performance, some recent variants attempt to exploit diverse\nknowledge sources from multiple teachers. However, existing studies mainly\nintegrate knowledge from diverse sources by averaging over multiple teacher\npredictions or combining them using other various label-free strategies, which\nmay mislead student in the presence of low-quality teacher predictions. To\ntackle this problem, we propose Confidence-Aware Multi-teacher Knowledge\nDistillation (CA-MKD), which adaptively assigns sample-wise reliability for\neach teacher prediction with the help of ground-truth labels, with those\nteacher predictions close to one-hot labels assigned large weights. Besides,\nCA-MKD incorporates intermediate layers to stable the knowledge transfer\nprocess. Extensive experiments show that our CA-MKD consistently outperforms\nall compared state-of-the-art methods across various teacher-student\narchitectures.\n",
                "链接": "https://arxiv.org/abs/2201.00007"
            },
            {
                "文章ID": "3",
                "标题": "A Lightweight and Accurate Spatial-Temporal Transformer for Traffic\n  Forecasting",
                "作者": " Guanyao Li,  Shuhan Zhong,  S. -H. Gary Chan,  Ruiyuan Li,  Chih-Chieh Hung,  Wen-Chih Peng",
                "发布日期": "2022-05-05",
                "摘要": "  We study the forecasting problem for traffic with dynamic, possibly\nperiodical, and joint spatial-temporal dependency between regions. Given the\naggregated inflow and outflow traffic of regions in a city from time slots 0 to\nt-1, we predict the traffic at time t at any region. Prior arts in the area\noften consider the spatial and temporal dependencies in a decoupled manner or\nare rather computationally intensive in training with a large number of\nhyper-parameters to tune. We propose ST-TIS, a novel, lightweight, and accurate\nSpatial-Temporal Transformer with information fusion and region sampling for\ntraffic forecasting. ST-TIS extends the canonical Transformer with information\nfusion and region sampling. The information fusion module captures the complex\nspatial-temporal dependency between regions. The region sampling module is to\nimprove the efficiency and prediction accuracy, cutting the computation\ncomplexity for dependency learning from $O(n^2)$ to $O(n\\sqrt{n})$, where n is\nthe number of regions. With far fewer parameters than state-of-the-art models,\nthe offline training of our model is significantly faster in terms of tuning\nand computation (with a reduction of up to $90\\%$ on training time and network\nparameters). Notwithstanding such training efficiency, extensive experiments\nshow that ST-TIS is substantially more accurate in online prediction than\nstate-of-the-art approaches (with an average improvement of up to $9.5\\%$ on\nRMSE, and $12.4\\%$ on MAPE).\n",
                "链接": "https://arxiv.org/abs/2201.00008"
            },
            {
                "文章ID": "4",
                "标题": "Improving Deep Neural Network Classification Confidence using\n  Heatmap-based eXplainable AI",
                "作者": " Erico Tjoa,  Hong Jing Khok,  Tushar Chouhan,  Guan Cuntai",
                "发布日期": "2023-01-24",
                "摘要": "  This paper quantifies the quality of heatmap-based eXplainable AI (XAI)\nmethods w.r.t image classification problem. Here, a heatmap is considered\ndesirable if it improves the probability of predicting the correct classes.\nDifferent XAI heatmap-based methods are empirically shown to improve\nclassification confidence to different extents depending on the datasets, e.g.\nSaliency works best on ImageNet and Deconvolution on Chest X-Ray Pneumonia\ndataset. The novelty includes a new gap distribution that shows a stark\ndifference between correct and wrong predictions. Finally, the generative\naugmentative explanation is introduced, a method to generate heatmaps capable\nof improving predictive confidence to a high level.\n",
                "链接": "https://arxiv.org/abs/2201.00009"
            },
            {
                "文章ID": "5",
                "标题": "An Efficient Federated Distillation Learning System for Multi-task Time\n  Series Classification",
                "作者": " Huanlai Xing,  Zhiwen Xiao,  Rong Qu,  Zonghai Zhu,  Bowen Zhao",
                "发布日期": "2022-01-04",
                "摘要": "  This paper proposes an efficient federated distillation learning system\n(EFDLS) for multi-task time series classification (TSC). EFDLS consists of a\ncentral server and multiple mobile users, where different users may run\ndifferent TSC tasks. EFDLS has two novel components, namely a feature-based\nstudent-teacher (FBST) framework and a distance-based weights matching (DBWM)\nscheme. Within each user, the FBST framework transfers knowledge from its\nteacher's hidden layers to its student's hidden layers via knowledge\ndistillation, with the teacher and student having identical network structure.\nFor each connected user, its student model's hidden layers' weights are\nuploaded to the EFDLS server periodically. The DBWM scheme is deployed on the\nserver, with the least square distance used to measure the similarity between\nthe weights of two given models. This scheme finds a partner for each connected\nuser such that the user's and its partner's weights are the closest among all\nthe weights uploaded. The server exchanges and sends back the user's and its\npartner's weights to these two users which then load the received weights to\ntheir teachers' hidden layers. Experimental results show that the proposed\nEFDLS achieves excellent performance on a set of selected UCR2018 datasets\nregarding top-1 accuracy.\n",
                "链接": "https://arxiv.org/abs/2201.00011"
            },
            {
                "文章ID": "6",
                "标题": "MORAL: Aligning AI with Human Norms through Multi-Objective Reinforced\n  Active Learning",
                "作者": " Markus Peschl,  Arkady Zgonnikov,  Frans A. Oliehoek,  Luciano C. Siebert",
                "发布日期": "2022-01-04",
                "摘要": "  Inferring reward functions from demonstrations and pairwise preferences are\nauspicious approaches for aligning Reinforcement Learning (RL) agents with\nhuman intentions. However, state-of-the art methods typically focus on learning\na single reward model, thus rendering it difficult to trade off different\nreward functions from multiple experts. We propose Multi-Objective Reinforced\nActive Learning (MORAL), a novel method for combining diverse demonstrations of\nsocial norms into a Pareto-optimal policy. Through maintaining a distribution\nover scalarization weights, our approach is able to interactively tune a deep\nRL agent towards a variety of preferences, while eliminating the need for\ncomputing multiple policies. We empirically demonstrate the effectiveness of\nMORAL in two scenarios, which model a delivery and an emergency task that\nrequire an agent to act in the presence of normative conflicts. Overall, we\nconsider our research a step towards multi-objective RL with learned rewards,\nbridging the gap between current reward learning and machine ethics literature.\n",
                "链接": "https://arxiv.org/abs/2201.00012"
            },
            {
                "文章ID": "7",
                "标题": "Exploiting Bi-directional Global Transition Patterns and Personal\n  Preferences for Missing POI Category Identification",
                "作者": " Dongbo Xi,  Fuzhen Zhuang,  Yanchi Liu,  Hengshu Zhu,  Pengpeng Zhao,  Chang Tan,  Qing He",
                "发布日期": "2022-01-04",
                "摘要": "  Recent years have witnessed the increasing popularity of Location-based\nSocial Network (LBSN) services, which provides unparalleled opportunities to\nbuild personalized Point-of-Interest (POI) recommender systems. Existing POI\nrecommendation and location prediction tasks utilize past information for\nfuture recommendation or prediction from a single direction perspective, while\nthe missing POI category identification task needs to utilize the check-in\ninformation both before and after the missing category. Therefore, a\nlong-standing challenge is how to effectively identify the missing POI\ncategories at any time in the real-world check-in data of mobile users. To this\nend, in this paper, we propose a novel neural network approach to identify the\nmissing POI categories by integrating both bi-directional global non-personal\ntransition patterns and personal preferences of users. Specifically, we\ndelicately design an attention matching cell to model how well the check-in\ncategory information matches their non-personal transition patterns and\npersonal preferences. Finally, we evaluate our model on two real-world\ndatasets, which clearly validate its effectiveness compared with the\nstate-of-the-art baselines. Furthermore, our model can be naturally extended to\naddress next POI category recommendation and prediction tasks with competitive\nperformance.\n",
                "链接": "https://arxiv.org/abs/2201.00014"
            },
            {
                "文章ID": "8",
                "标题": "TransLog: A Unified Transformer-based Framework for Log Anomaly\n  Detection",
                "作者": " Hongcheng Guo,  Xingyu Lin,  Jian Yang,  Yi Zhuang,  Jiaqi Bai,  Tieqiao Zheng,  Bo Zhang,  Zhoujun Li",
                "发布日期": "2022-01-19",
                "摘要": "  Log anomaly detection is a key component in the field of artificial\nintelligence for IT operations (AIOps). Considering log data of variant\ndomains, retraining the whole network for unknown domains is inefficient in\nreal industrial scenarios especially for low-resource domains. However,\nprevious deep models merely focused on extracting the semantics of log sequence\nin the same domain, leading to poor generalization on multi-domain logs.\nTherefore, we propose a unified Transformer-based framework for log anomaly\ndetection (\\ourmethod{}), which is comprised of the pretraining and\nadapter-based tuning stage. Our model is first pretrained on the source domain\nto obtain shared semantic knowledge of log data. Then, we transfer the\npretrained model to the target domain via the adapter-based tuning. The\nproposed method is evaluated on three public datasets including one source\ndomain and two target domains. The experimental results demonstrate that our\nsimple yet efficient approach, with fewer trainable parameters and lower\ntraining costs in the target domain, achieves state-of-the-art performance on\nthree benchmarks.\n",
                "链接": "https://arxiv.org/abs/2201.00016"
            },
            {
                "文章ID": "9",
                "标题": "Stochastic convex optimization for provably efficient apprenticeship\n  learning",
                "作者": " Angeliki Kamoutsi,  Goran Banjac,  John Lygeros",
                "发布日期": "2022-01-04",
                "摘要": "  We consider large-scale Markov decision processes (MDPs) with an unknown cost\nfunction and employ stochastic convex optimization tools to address the problem\nof imitation learning, which consists of learning a policy from a finite set of\nexpert demonstrations.\n  We adopt the apprenticeship learning formalism, which carries the assumption\nthat the true cost function can be represented as a linear combination of some\nknown features. Existing inverse reinforcement learning algorithms come with\nstrong theoretical guarantees, but are computationally expensive because they\nuse reinforcement learning or planning algorithms as a subroutine. On the other\nhand, state-of-the-art policy gradient based algorithms (like IM-REINFORCE,\nIM-TRPO, and GAIL), achieve significant empirical success in challenging\nbenchmark tasks, but are not well understood in terms of theory. With an\nemphasis on non-asymptotic guarantees of performance, we propose a method that\ndirectly learns a policy from expert demonstrations, bypassing the intermediate\nstep of learning the cost function, by formulating the problem as a single\nconvex optimization problem over occupancy measures. We develop a\ncomputationally efficient algorithm and derive high confidence regret bounds on\nthe quality of the extracted policy, utilizing results from stochastic convex\noptimization and recent works in approximate linear programming for solving\nforward MDPs.\n",
                "链接": "https://arxiv.org/abs/2201.00039"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于gpt4自动生成prompt的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "122793",
                "标题": "GPT-4 Surpassing Human Performance in Linguistic Pragmatics",
                "作者": " Ljubisa Bojic,  Predrag Kovacevic,  Milan Cabarkapa",
                "发布日期": "2023-12-18",
                "摘要": "  As Large Language Models (LLMs) become increasingly integrated into everyday\nlife, their capabilities to understand and emulate human cognition are under\nsteady examination. This study investigates the ability of LLMs to comprehend\nand interpret linguistic pragmatics, an aspect of communication that considers\ncontext and implied meanings. Using Grice's communication principles, LLMs and\nhuman subjects (N=76) were evaluated based on their responses to various\ndialogue-based tasks. The findings revealed the superior performance and speed\nof LLMs, particularly GPT4, over human subjects in interpreting pragmatics.\nGPT4 also demonstrated accuracy in the pre-testing of human-written samples,\nindicating its potential in text analysis. In a comparative analysis of LLMs\nusing human individual and average scores, the models exhibited significant\nchronological improvement. The models were ranked from lowest to highest score,\nwith GPT2 positioned at 78th place, GPT3 ranking at 23rd, Bard at 10th, GPT3.5\nplacing 5th, Best Human scoring 2nd, and GPT4 achieving the top spot. The\nfindings highlight the remarkable progress made in the development and\nperformance of these LLMs. Future studies should consider diverse subjects,\nmultiple languages, and other cognitive aspects to fully comprehend the\ncapabilities of LLMs. This research holds significant implications for the\ndevelopment and application of AI-based models in communication-centered\nsectors.\n",
                "链接": "https://arxiv.org/abs/2312.09545"
            },
            {
                "文章ID": "103691",
                "标题": "OpenAi's GPT4 as coding assistant",
                "作者": " Lefteris Moussiades,  George Zografos",
                "发布日期": "2023-09-25",
                "摘要": "  Lately, Large Language Models have been widely used in code generation. GPT4\nis considered the most potent Large Language Model from Openai. In this paper,\nwe examine GPT3.5 and GPT4 as coding assistants. More specifically, we have\nconstructed appropriate tests to check whether the two systems can a) answer\ntypical questions that can arise during the code development, b) produce\nreliable code, and c) contribute to code debugging. The test results are\nimpressive. The performance of GPT4 is outstanding and signals an increase in\nthe productivity of programmers and the reorganization of software development\nprocedures based on these new tools.\n",
                "链接": "https://arxiv.org/abs/2309.12732"
            },
            {
                "文章ID": "109795",
                "标题": "A Survey of GPT-3 Family Large Language Models Including ChatGPT and\n  GPT-4",
                "作者": " Katikapalli Subramanyam Kalyan",
                "发布日期": "2023-10-20",
                "摘要": "  Large language models (LLMs) are a special class of pretrained language\nmodels obtained by scaling model size, pretraining corpus and computation.\nLLMs, because of their large size and pretraining on large volumes of text\ndata, exhibit special abilities which allow them to achieve remarkable\nperformances without any task-specific training in many of the natural language\nprocessing tasks. The era of LLMs started with OpenAI GPT-3 model, and the\npopularity of LLMs is increasing exponentially after the introduction of models\nlike ChatGPT and GPT4. We refer to GPT-3 and its successor OpenAI models,\nincluding ChatGPT and GPT4, as GPT-3 family large language models (GLLMs). With\nthe ever-rising popularity of GLLMs, especially in the research community,\nthere is a strong need for a comprehensive survey which summarizes the recent\nresearch progress in multiple dimensions and can guide the research community\nwith insightful future research directions. We start the survey paper with\nfoundation concepts like transformers, transfer learning, self-supervised\nlearning, pretrained language models and large language models. We then present\na brief overview of GLLMs and discuss the performances of GLLMs in various\ndownstream tasks, specific domains and multiple languages. We also discuss the\ndata labelling and data augmentation abilities of GLLMs, the robustness of\nGLLMs, the effectiveness of GLLMs as evaluators, and finally, conclude with\nmultiple insightful future research directions. To summarize, this\ncomprehensive survey paper will serve as a good resource for both academic and\nindustry people to stay updated with the latest research related to GPT-3\nfamily large language models.\n",
                "链接": "https://arxiv.org/abs/2310.12321"
            },
            {
                "文章ID": "90467",
                "标题": "GPT4 is Slightly Helpful for Peer-Review Assistance: A Pilot Study",
                "作者": " Zachary Robertson",
                "发布日期": "2023-07-13",
                "摘要": "  In this pilot study, we investigate the use of GPT4 to assist in the\npeer-review process. Our key hypothesis was that GPT-generated reviews could\nachieve comparable helpfulness to human reviewers. By comparing reviews\ngenerated by both human reviewers and GPT models for academic papers submitted\nto a major machine learning conference, we provide initial evidence that\nartificial intelligence can contribute effectively to the peer-review process.\nWe also perform robustness experiments with inserted errors to understand which\nparts of the paper the model tends to focus on. Our findings open new avenues\nfor leveraging machine learning tools to address resource constraints in peer\nreview. The results also shed light on potential enhancements to the review\nprocess and lay the groundwork for further research on scaling oversight in a\ndomain where human-feedback is increasingly a scarce resource.\n",
                "链接": "https://arxiv.org/abs/2307.05492"
            },
            {
                "文章ID": "98842",
                "标题": "Examining User-Friendly and Open-Sourced Large GPT Models: A Survey on\n  Language, Multimodal, and Scientific GPT Models",
                "作者": " Kaiyuan Gao,  Sunan He,  Zhenyu He,  Jiacheng Lin,  QiZhi Pei,  Jie Shao,  Wei Zhang",
                "发布日期": "2023-08-29",
                "摘要": "  Generative pre-trained transformer (GPT) models have revolutionized the field\nof natural language processing (NLP) with remarkable performance in various\ntasks and also extend their power to multimodal domains. Despite their success,\nlarge GPT models like GPT-4 face inherent limitations such as considerable\nsize, high computational requirements, complex deployment processes, and closed\ndevelopment loops. These constraints restrict their widespread adoption and\nraise concerns regarding their responsible development and usage. The need for\nuser-friendly, relatively small, and open-sourced alternative GPT models arises\nfrom the desire to overcome these limitations while retaining high performance.\nIn this survey paper, we provide an examination of alternative open-sourced\nmodels of large GPTs, focusing on user-friendly and relatively small models\nthat facilitate easier deployment and accessibility. Through this extensive\nsurvey, we aim to equip researchers, practitioners, and enthusiasts with a\nthorough understanding of user-friendly and relatively small open-sourced\nmodels of large GPTs, their current state, challenges, and future research\ndirections, inspiring the development of more efficient, accessible, and\nversatile GPT models that cater to the broader scientific community and advance\nthe field of general artificial intelligence. The source contents are\ncontinuously updating in https://github.com/GPT-Alternatives/gpt_alternatives.\n",
                "链接": "https://arxiv.org/abs/2308.14149"
            },
            {
                "文章ID": "67618",
                "标题": "DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4",
                "作者": " Zhengliang Liu,  Yue Huang,  Xiaowei Yu,  Lu Zhang,  Zihao Wu,  Chao Cao,  Haixing Dai,  Lin Zhao,  Yiwei Li,  Peng Shu,  Fang Zeng,  Lichao Sun,  Wei Liu,  Dinggang Shen,  Quanzheng Li,  Tianming Liu,  Dajiang Zhu,  Xiang Li",
                "发布日期": "2023-12-22",
                "摘要": "  The digitization of healthcare has facilitated the sharing and re-using of\nmedical data but has also raised concerns about confidentiality and privacy.\nHIPAA (Health Insurance Portability and Accountability Act) mandates removing\nre-identifying information before the dissemination of medical records. Thus,\neffective and efficient solutions for de-identifying medical data, especially\nthose in free-text forms, are highly needed. While various computer-assisted\nde-identification methods, including both rule-based and learning-based, have\nbeen developed and used in prior practice, such solutions still lack\ngeneralizability or need to be fine-tuned according to different scenarios,\nsignificantly imposing restrictions in wider use. The advancement of large\nlanguage models (LLM), such as ChatGPT and GPT-4, have shown great potential in\nprocessing text data in the medical domain with zero-shot in-context learning,\nespecially in the task of privacy protection, as these models can identify\nconfidential information by their powerful named entity recognition (NER)\ncapability. In this work, we developed a novel GPT4-enabled de-identification\nframework (``DeID-GPT\") to automatically identify and remove the identifying\ninformation. Compared to existing commonly used medical text data\nde-identification methods, our developed DeID-GPT showed the highest accuracy\nand remarkable reliability in masking private information from the unstructured\nmedical text while preserving the original structure and meaning of the text.\nThis study is one of the earliest to utilize ChatGPT and GPT-4 for medical text\ndata processing and de-identification, which provides insights for further\nresearch and solution development on the use of LLMs such as ChatGPT/GPT-4 in\nhealthcare. Codes and benchmarking data information are available at\nhttps://github.com/yhydhx/ChatGPT-API.\n",
                "链接": "https://arxiv.org/abs/2303.11032"
            },
            {
                "文章ID": "46060",
                "标题": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained\n  Transformers",
                "作者": " Elias Frantar,  Saleh Ashkboos,  Torsten Hoefler,  Dan Alistarh",
                "发布日期": "2023-03-23",
                "摘要": "  Generative Pre-trained Transformer models, known as GPT or OPT, set\nthemselves apart through breakthrough performance across complex language\nmodelling tasks, but also by their extremely high computational and storage\ncosts. Specifically, due to their massive size, even inference for large,\nhighly-accurate GPT models may require multiple performant GPUs, which limits\nthe usability of such models. While there is emerging work on relieving this\npressure via model compression, the applicability and performance of existing\ncompression techniques is limited by the scale and complexity of GPT models. In\nthis paper, we address this challenge, and propose GPTQ, a new one-shot weight\nquantization method based on approximate second-order information, that is both\nhighly-accurate and highly-efficient. Specifically, GPTQ can quantize GPT\nmodels with 175 billion parameters in approximately four GPU hours, reducing\nthe bitwidth down to 3 or 4 bits per weight, with negligible accuracy\ndegradation relative to the uncompressed baseline. Our method more than doubles\nthe compression gains relative to previously-proposed one-shot quantization\nmethods, preserving accuracy, allowing us for the first time to execute an 175\nbillion-parameter model inside a single GPU for generative inference. Moreover,\nwe also show that our method can still provide reasonable accuracy in the\nextreme quantization regime, in which weights are quantized to 2-bit or even\nternary quantization levels. We show experimentally that these improvements can\nbe leveraged for end-to-end inference speedups over FP16, of around 3.25x when\nusing high-end GPUs (NVIDIA A100) and 4.5x when using more cost-effective ones\n(NVIDIA A6000). The implementation is available at\nhttps://github.com/IST-DASLab/gptq.\n",
                "链接": "https://arxiv.org/abs/2210.17323"
            },
            {
                "文章ID": "73599",
                "标题": "Can GPT-4 Perform Neural Architecture Search?",
                "作者": " Mingkai Zheng,  Xiu Su,  Shan You,  Fei Wang,  Chen Qian,  Chang Xu,  Samuel Albanie",
                "发布日期": "2023-08-03",
                "摘要": "  We investigate the potential of GPT-4~\\cite{gpt4} to perform Neural\nArchitecture Search (NAS) -- the task of designing effective neural\narchitectures. Our proposed approach, \\textbf{G}PT-4 \\textbf{E}nhanced\n\\textbf{N}eural arch\\textbf{I}tect\\textbf{U}re \\textbf{S}earch (GENIUS),\nleverages the generative capabilities of GPT-4 as a black-box optimiser to\nquickly navigate the architecture search space, pinpoint promising candidates,\nand iteratively refine these candidates to improve performance. We assess\nGENIUS across several benchmarks, comparing it with existing state-of-the-art\nNAS techniques to illustrate its effectiveness. Rather than targeting\nstate-of-the-art performance, our objective is to highlight GPT-4's potential\nto assist research on a challenging technical problem through a simple\nprompting scheme that requires relatively limited domain\nexpertise\\footnote{Code available at\n\\href{https://github.com/mingkai-zheng/GENIUS}{https://github.com/mingkai-zheng/GENIUS}.}.\nMore broadly, we believe our preliminary results point to future research that\nharnesses general purpose language models for diverse optimisation tasks. We\nalso highlight important limitations to our study, and note implications for AI\nsafety.\n",
                "链接": "https://arxiv.org/abs/2304.10970"
            },
            {
                "文章ID": "73250",
                "标题": "Catch Me If You Can: Identifying Fraudulent Physician Reviews with Large\n  Language Models Using Generative Pre-Trained Transformers",
                "作者": "JM  Aishwarya Deep Shukla, JM  Laksh Agarwal, JM  Jie Mein, Gordon   Goh, Gordon   Guodong,   Gao,  Ritu Agarwal",
                "发布日期": "2023-04-21",
                "摘要": "  The proliferation of fake reviews of doctors has potentially detrimental\nconsequences for patient well-being and has prompted concern among consumer\nprotection groups and regulatory bodies. Yet despite significant advancements\nin the fields of machine learning and natural language processing, there\nremains limited comprehension of the characteristics differentiating fraudulent\nfrom authentic reviews. This study utilizes a novel pre-labeled dataset of\n38048 physician reviews to establish the effectiveness of large language models\nin classifying reviews. Specifically, we compare the performance of traditional\nML models, such as logistic regression and support vector machines, to\ngenerative pre-trained transformer models. Furthermore, we use GPT4, the newest\nmodel in the GPT family, to uncover the key dimensions along which fake and\ngenuine physician reviews differ. Our findings reveal significantly superior\nperformance of GPT-3 over traditional ML models in this context. Additionally,\nour analysis suggests that GPT3 requires a smaller training sample than\ntraditional models, suggesting its appropriateness for tasks with scarce\ntraining data. Moreover, the superiority of GPT3 performance increases in the\ncold start context i.e., when there are no prior reviews of a doctor. Finally,\nwe employ GPT4 to reveal the crucial dimensions that distinguish fake physician\nreviews. In sharp contrast to previous findings in the literature that were\nobtained using simulated data, our findings from a real-world dataset show that\nfake reviews are generally more clinically detailed, more reserved in\nsentiment, and have better structure and grammar than authentic ones.\n",
                "链接": "https://arxiv.org/abs/2304.09948"
            },
            {
                "文章ID": "90219",
                "标题": "CORE-GPT: Combining Open Access research and large language models for\n  credible, trustworthy question answering",
                "作者": " David Pride,  Matteo Cancellieri,  Petr Knoth",
                "发布日期": "2023-07-11",
                "摘要": "  In this paper, we present CORE-GPT, a novel question-answering platform that\ncombines GPT-based language models and more than 32 million full-text open\naccess scientific articles from CORE. We first demonstrate that GPT3.5 and GPT4\ncannot be relied upon to provide references or citations for generated text. We\nthen introduce CORE-GPT which delivers evidence-based answers to questions,\nalong with citations and links to the cited papers, greatly increasing the\ntrustworthiness of the answers and reducing the risk of hallucinations.\nCORE-GPT's performance was evaluated on a dataset of 100 questions covering the\ntop 20 scientific domains in CORE, resulting in 100 answers and links to 500\nrelevant articles. The quality of the provided answers and and relevance of the\nlinks were assessed by two annotators. Our results demonstrate that CORE-GPT\ncan produce comprehensive and trustworthy answers across the majority of\nscientific domains, complete with links to genuine, relevant scientific\narticles.\n",
                "链接": "https://arxiv.org/abs/2307.04683"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态agent, 具身智能的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "61323",
                "标题": "Order Matters: Agent-by-agent Policy Optimization",
                "作者": " Xihuai Wang,  Zheng Tian,  Ziyu Wan,  Ying Wen,  Jun Wang,  Weinan Zhang",
                "发布日期": "2023-02-28",
                "摘要": "  While multi-agent trust region algorithms have achieved great success\nempirically in solving coordination tasks, most of them, however, suffer from a\nnon-stationarity problem since agents update their policies simultaneously. In\ncontrast, a sequential scheme that updates policies agent-by-agent provides\nanother perspective and shows strong performance. However, sample inefficiency\nand lack of monotonic improvement guarantees for each agent are still the two\nsignificant challenges for the sequential scheme. In this paper, we propose the\n\\textbf{A}gent-by-\\textbf{a}gent \\textbf{P}olicy \\textbf{O}ptimization (A2PO)\nalgorithm to improve the sample efficiency and retain the guarantees of\nmonotonic improvement for each agent during training. We justify the tightness\nof the monotonic improvement bound compared with other trust region algorithms.\nFrom the perspective of sequentially updating agents, we further consider the\neffect of agent updating order and extend the theory of non-stationarity into\nthe sequential update scheme. To evaluate A2PO, we conduct a comprehensive\nempirical study on four benchmarks: StarCraftII, Multi-agent MuJoCo,\nMulti-agent Particle Environment, and Google Research Football full game\nscenarios. A2PO consistently outperforms strong baselines.\n",
                "链接": "https://arxiv.org/abs/2302.06205"
            },
            {
                "文章ID": "111341",
                "标题": "Graph Agent: Explicit Reasoning Agent for Graphs",
                "作者": " Qinyong Wang,  Zhenxiang Gao,  Rong Xu",
                "发布日期": "2023-10-26",
                "摘要": "  Graph embedding methods such as Graph Neural Networks (GNNs) and Graph\nTransformers have contributed to the development of graph reasoning algorithms\nfor various tasks on knowledge graphs. However, the lack of interpretability\nand explainability of graph embedding methods has limited their applicability\nin scenarios requiring explicit reasoning. In this paper, we introduce the\nGraph Agent (GA), an intelligent agent methodology of leveraging large language\nmodels (LLMs), inductive-deductive reasoning modules, and long-term memory for\nknowledge graph reasoning tasks. GA integrates aspects of symbolic reasoning\nand existing graph embedding methods to provide an innovative approach for\ncomplex graph reasoning tasks. By converting graph structures into textual\ndata, GA enables LLMs to process, reason, and provide predictions alongside\nhuman-interpretable explanations. The effectiveness of the GA was evaluated on\nnode classification and link prediction tasks. Results showed that GA reached\nstate-of-the-art performance, demonstrating accuracy of 90.65%, 95.48%, and\n89.32% on Cora, PubMed, and PrimeKG datasets, respectively. Compared to\nexisting GNN and transformer models, GA offered advantages of explicit\nreasoning ability, free-of-training, easy adaption to various graph reasoning\ntasks\n",
                "链接": "https://arxiv.org/abs/2310.16421"
            },
            {
                "文章ID": "106067",
                "标题": "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with\n  Agent Team Optimization",
                "作者": " Zijun Liu,  Yanzhe Zhang,  Peng Li,  Yang Liu,  Diyi Yang",
                "发布日期": "2023-10-04",
                "摘要": "  Large language model (LLM) agents have been shown effective on a wide range\nof tasks, and by ensembling multiple LLM agents, their performances could be\nfurther improved. Existing approaches employ a fixed set of agents to interact\nwith each other in a static architecture, which limits their generalizability\nto various tasks and requires strong human prior in designing these agents. In\nthis work, we propose to construct a strategic team of agents communicating in\na dynamic interaction architecture based on the task query. Specifically, we\nbuild a framework named Dynamic LLM-Agent Network ($\\textbf{DyLAN}$) for\nLLM-agent collaboration on complicated tasks like reasoning and code\ngeneration. DyLAN enables agents to interact for multiple rounds in a dynamic\narchitecture with inference-time agent selection and an early-stopping\nmechanism to improve performance and efficiency. We further design an automatic\nagent team optimization algorithm based on an unsupervised metric termed\n$\\textit{Agent Importance Score}$, enabling the selection of best agents based\non the contribution each agent makes. Empirically, we demonstrate that DyLAN\nperforms well in both reasoning and code generation tasks with reasonable\ncomputational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and\nHumanEval, respectively, compared to a single execution on GPT-35-turbo. On\nspecific subjects of MMLU, agent team optimization in DyLAN increases accuracy\nby up to 25.0%.\n",
                "链接": "https://arxiv.org/abs/2310.02170"
            },
            {
                "文章ID": "56008",
                "标题": "Optimizing Agent Collaboration through Heuristic Multi-Agent Planning",
                "作者": " Nitsan Soffair",
                "发布日期": "2023-06-26",
                "摘要": "  The SOTA algorithms for addressing QDec-POMDP issues, QDec-FP and QDec-FPS,\nare unable to effectively tackle problems that involve different types of\nsensing agents. We propose a new algorithm that addresses this issue by\nrequiring agents to adopt the same plan if one agent is unable to take a\nsensing action but the other can. Our algorithm performs significantly better\nthan both QDec-FP and QDec-FPS in these types of situations.\n",
                "链接": "https://arxiv.org/abs/2301.01246"
            },
            {
                "文章ID": "93344",
                "标题": "Using Multi-Agent MicroServices (MAMS) for Agent Based Modelling",
                "作者": " Martynas Jagutis,  Sean Russell,  Rem Collier",
                "发布日期": "2023-07-28",
                "摘要": "  This paper demonstrates the use of the Multi-Agent MicroServices (MAMS)\narchitectural style through a case study based around the development of a\nprototype traffic simulation in which agents model a population of individuals\nwho travel from home to work and vice versa by car.\n",
                "链接": "https://arxiv.org/abs/2307.14745"
            },
            {
                "文章ID": "109786",
                "标题": "Fact-based Agent modeling for Multi-Agent Reinforcement Learning",
                "作者": " Baofu Fang,  Caiming Zheng,  Hao Wang",
                "发布日期": "2023-10-20",
                "摘要": "  In multi-agent systems, agents need to interact and collaborate with other\nagents in environments. Agent modeling is crucial to facilitate agent\ninteractions and make adaptive cooperation strategies. However, it is\nchallenging for agents to model the beliefs, behaviors, and intentions of other\nagents in non-stationary environment where all agent policies are learned\nsimultaneously. In addition, the existing methods realize agent modeling\nthrough behavior cloning which assume that the local information of other\nagents can be accessed during execution or training. However, this assumption\nis infeasible in unknown scenarios characterized by unknown agents, such as\ncompetition teams, unreliable communication and federated learning due to\nprivacy concerns. To eliminate this assumption and achieve agent modeling in\nunknown scenarios, Fact-based Agent modeling (FAM) method is proposed in which\nfact-based belief inference (FBI) network models other agents in partially\nobservable environment only based on its local information. The reward and\nobservation obtained by agents after taking actions are called facts, and FAM\nuses facts as reconstruction target to learn the policy representation of other\nagents through a variational autoencoder. We evaluate FAM on various Multiagent\nParticle Environment (MPE) and compare the results with several\nstate-of-the-art MARL algorithms. Experimental results show that compared with\nbaseline methods, FAM can effectively improve the efficiency of agent policy\nlearning by making adaptive cooperation strategies in multi-agent reinforcement\nlearning tasks, while achieving higher returns in complex\ncompetitive-cooperative mixed scenarios.\n",
                "链接": "https://arxiv.org/abs/2310.12290"
            },
            {
                "文章ID": "69009",
                "标题": "Learning Generative Models with Goal-conditioned Reinforcement Learning",
                "作者": " Mariana Vargas Vieyra,  Pierre Ménard",
                "发布日期": "2023-03-28",
                "摘要": "  We present a novel, alternative framework for learning generative models with\ngoal-conditioned reinforcement learning. We define two agents, a goal\nconditioned agent (GC-agent) and a supervised agent (S-agent). Given a\nuser-input initial state, the GC-agent learns to reconstruct the training set.\nIn this context, elements in the training set are the goals. During training,\nthe S-agent learns to imitate the GC-agent while remaining agnostic of the\ngoals. At inference we generate new samples with the S-agent. Following a\nsimilar route as in variational auto-encoders, we derive an upper bound on the\nnegative log-likelihood that consists of a reconstruction term and a divergence\nbetween the GC-agent policy and the (goal-agnostic) S-agent policy. We\nempirically demonstrate that our method is able to generate diverse and high\nquality samples in the task of image synthesis.\n",
                "链接": "https://arxiv.org/abs/2303.14811"
            },
            {
                "文章ID": "118652",
                "标题": "Agent-Aware Training for Agent-Agnostic Action Advising in Deep\n  Reinforcement Learning",
                "作者": " Yaoquan Wei,  Shunyu Liu,  Jie Song,  Tongya Zheng,  Kaixuan Chen,  Yong Wang,  Mingli Song",
                "发布日期": "2023-11-29",
                "摘要": "  Action advising endeavors to leverage supplementary guidance from expert\nteachers to alleviate the issue of sampling inefficiency in Deep Reinforcement\nLearning (DRL). Previous agent-specific action advising methods are hindered by\nimperfections in the agent itself, while agent-agnostic approaches exhibit\nlimited adaptability to the learning agent. In this study, we propose a novel\nframework called Agent-Aware trAining yet Agent-Agnostic Action Advising (A7)\nto strike a balance between the two. The underlying concept of A7 revolves\naround utilizing the similarity of state features as an indicator for\nsoliciting advice. However, unlike prior methodologies, the measurement of\nstate feature similarity is performed by neither the error-prone learning agent\nnor the agent-agnostic advisor. Instead, we employ a proxy model to extract\nstate features that are both discriminative (adaptive to the agent) and\ngenerally applicable (robust to agent noise). Furthermore, we utilize behavior\ncloning to train a model for reusing advice and introduce an intrinsic reward\nfor the advised samples to incentivize the utilization of expert guidance.\nExperiments are conducted on the GridWorld, LunarLander, and six prominent\nscenarios from Atari games. The results demonstrate that A7 significantly\naccelerates the learning process and surpasses existing methods (both\nagent-specific and agent-agnostic) by a substantial margin. Our code will be\nmade publicly available.\n",
                "链接": "https://arxiv.org/abs/2311.16807"
            },
            {
                "文章ID": "122537",
                "标题": "Agent Attention: On the Integration of Softmax and Linear Attention",
                "作者": " Dongchen Han,  Tianzhu Ye,  Yizeng Han,  Zhuofan Xia,  Shiji Song,  Gao Huang",
                "发布日期": "2023-12-27",
                "摘要": "  The attention module is the key component in Transformers. While the global\nattention mechanism offers high expressiveness, its excessive computational\ncost restricts its applicability in various scenarios. In this paper, we\npropose a novel attention paradigm, Agent Attention, to strike a favorable\nbalance between computational efficiency and representation power.\nSpecifically, the Agent Attention, denoted as a quadruple $(Q, A, K, V)$,\nintroduces an additional set of agent tokens $A$ into the conventional\nattention module. The agent tokens first act as the agent for the query tokens\n$Q$ to aggregate information from $K$ and $V$, and then broadcast the\ninformation back to $Q$. Given the number of agent tokens can be designed to be\nmuch smaller than the number of query tokens, the agent attention is\nsignificantly more efficient than the widely adopted Softmax attention, while\npreserving global context modelling capability. Interestingly, we show that the\nproposed agent attention is equivalent to a generalized form of linear\nattention. Therefore, agent attention seamlessly integrates the powerful\nSoftmax attention and the highly efficient linear attention. Extensive\nexperiments demonstrate the effectiveness of agent attention with various\nvision Transformers and across diverse vision tasks, including image\nclassification, object detection, semantic segmentation and image generation.\nNotably, agent attention has shown remarkable performance in high-resolution\nscenarios, owning to its linear attention nature. For instance, when applied to\nStable Diffusion, our agent attention accelerates generation and substantially\nenhances image generation quality without any additional training. Code is\navailable at https://github.com/LeapLabTHU/Agent-Attention.\n",
                "链接": "https://arxiv.org/abs/2312.08874"
            },
            {
                "文章ID": "70188",
                "标题": "Improving of Robotic Virtual Agent's errors that are accepted by\n  reaction and human's preference",
                "作者": " Takahiro Tsumura,  Seiji Yamada",
                "发布日期": "2023-08-22",
                "摘要": "  One way to improve the relationship between humans and anthropomorphic agents\nis to have humans empathize with the agents. In this study, we focused on a\ntask between an agent and a human in which the agent makes a mistake. To\ninvestigate significant factors for designing a robotic agent that can promote\nhumans empathy, we experimentally examined the hypothesis that agent reaction\nand human's preference affect human empathy and acceptance of the agent's\nmistakes. The experiment consisted of a four-condition, three-factor mixed\ndesign with agent reaction, selected agent's body color for human's preference,\nand pre- and post-task as factors. The results showed that agent reaction and\nhuman's preference did not affect empathy toward the agent but did allow the\nagent to make mistakes. It was also shown that empathy for the agent decreased\nwhen the agent made a mistake on the task. The results of this study provide a\nway to control impressions of the robotic virtual agent's behaviors, which are\nincreasingly used in society.\n",
                "链接": "https://arxiv.org/abs/2304.00247"
            }
        ]
    },
    {
        "question": {
            "question": "新的大模型结构相关探索的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "多模态细粒度图片编辑和生成相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "69866",
                "标题": "PAIR-Diffusion: A Comprehensive Multimodal Object-Level Image Editor",
                "作者": " Vidit Goel,  Elia Peruzzo,  Yifan Jiang,  Dejia Xu,  Xingqian Xu,  Nicu Sebe,  Trevor Darrell,  Zhangyang Wang,  Humphrey Shi",
                "发布日期": "2023-10-12",
                "摘要": "  Generative image editing has recently witnessed extremely fast-paced growth.\nSome works use high-level conditioning such as text, while others use low-level\nconditioning. Nevertheless, most of them lack fine-grained control over the\nproperties of the different objects present in the image, i.e.\\,object-level\nimage editing. In this work, we tackle the task by perceiving the images as an\namalgamation of various objects and aim to control the properties of each\nobject in a fine-grained manner. Out of these properties, we identify structure\nand appearance as the most intuitive to understand and useful for editing\npurposes. We propose \\textbf{PAIR} Diffusion, a generic framework that can\nenable a diffusion model to control the structure and appearance properties of\neach object in the image. We show that having control over the properties of\neach object in an image leads to comprehensive editing capabilities. Our\nframework allows for various object-level editing operations on real images\nsuch as reference image-based appearance editing, free-form shape editing,\nadding objects, and variations. Thanks to our design, we do not require any\ninversion step. Additionally, we propose multimodal classifier-free guidance\nwhich enables editing images using both reference images and text when using\nour approach with foundational diffusion models. We validate the above claims\nby extensively evaluating our framework on both unconditional and foundational\ndiffusion models. Please refer to\nhttps://vidit98.github.io/publication/conference-paper/pair_diff.html for code\nand model release.\n",
                "链接": "https://arxiv.org/abs/2303.17546"
            },
            {
                "文章ID": "124621",
                "标题": "FineMoGen: Fine-Grained Spatio-Temporal Motion Generation and Editing",
                "作者": " Mingyuan Zhang,  Huirong Li,  Zhongang Cai,  Jiawei Ren,  Lei Yang,  Ziwei Liu",
                "发布日期": "2023-12-27",
                "摘要": "  Text-driven motion generation has achieved substantial progress with the\nemergence of diffusion models. However, existing methods still struggle to\ngenerate complex motion sequences that correspond to fine-grained descriptions,\ndepicting detailed and accurate spatio-temporal actions. This lack of fine\ncontrollability limits the usage of motion generation to a larger audience. To\ntackle these challenges, we present FineMoGen, a diffusion-based motion\ngeneration and editing framework that can synthesize fine-grained motions, with\nspatial-temporal composition to the user instructions. Specifically, FineMoGen\nbuilds upon diffusion model with a novel transformer architecture dubbed\nSpatio-Temporal Mixture Attention (SAMI). SAMI optimizes the generation of the\nglobal attention template from two perspectives: 1) explicitly modeling the\nconstraints of spatio-temporal composition; and 2) utilizing sparsely-activated\nmixture-of-experts to adaptively extract fine-grained features. To facilitate a\nlarge-scale study on this new fine-grained motion generation task, we\ncontribute the HuMMan-MoGen dataset, which consists of 2,968 videos and 102,336\nfine-grained spatio-temporal descriptions. Extensive experiments validate that\nFineMoGen exhibits superior motion generation quality over state-of-the-art\nmethods. Notably, FineMoGen further enables zero-shot motion editing\ncapabilities with the aid of modern large language models (LLM), which\nfaithfully manipulates motion sequences with fine-grained instructions. Project\nPage: https://mingyuan-zhang.github.io/projects/FineMoGen.html\n",
                "链接": "https://arxiv.org/abs/2312.15004"
            },
            {
                "文章ID": "116878",
                "标题": "Cut-and-Paste: Subject-Driven Video Editing with Attention Control",
                "作者": " Zhichao Zuo,  Zhao Zhang,  Yan Luo,  Yang Zhao,  Haijun Zhang,  Yi Yang,  Meng Wang",
                "发布日期": "2023-11-21",
                "摘要": "  This paper presents a novel framework termed Cut-and-Paste for real-word\nsemantic video editing under the guidance of text prompt and additional\nreference image. While the text-driven video editing has demonstrated\nremarkable ability to generate highly diverse videos following given text\nprompts, the fine-grained semantic edits are hard to control by plain textual\nprompt only in terms of object details and edited region, and cumbersome long\ntext descriptions are usually needed for the task. We therefore investigate\nsubject-driven video editing for more precise control of both edited regions\nand background preservation, and fine-grained semantic generation. We achieve\nthis goal by introducing an reference image as supplementary input to the\ntext-driven video editing, which avoids racking your brain to come up with a\ncumbersome text prompt describing the detailed appearance of the object. To\nlimit the editing area, we refer to a method of cross attention control in\nimage editing and successfully extend it to video editing by fusing the\nattention map of adjacent frames, which strikes a balance between maintaining\nvideo background and spatio-temporal consistency. Compared with current\nmethods, the whole process of our method is like ``cut\" the source object to be\nedited and then ``paste\" the target object provided by reference image. We\ndemonstrate that our method performs favorably over prior arts for video\nediting under the guidance of text prompt and extra reference image, as\nmeasured by both quantitative and subjective evaluations.\n",
                "链接": "https://arxiv.org/abs/2311.11697"
            },
            {
                "文章ID": "118525",
                "标题": "Efficient Multimodal Diffusion Models Using Joint Data Infilling with\n  Partially Shared U-Net",
                "作者": " Zizhao Hu,  Shaochong Jia,  Mohammad Rostami",
                "发布日期": "2023-11-29",
                "摘要": "  Recently, diffusion models have been used successfully to fit distributions\nfor cross-modal data translation and multimodal data generation. However, these\nmethods rely on extensive scaling, overlooking the inefficiency and\ninterference between modalities. We develop Partially Shared U-Net (PS-U-Net)\narchitecture which is an efficient multimodal diffusion model that allows text\nand image inputs to pass through dedicated layers and skip-connections for\npreserving modality-specific fine-grained details. Inspired by image\ninpainting, we also propose a new efficient multimodal sampling method that\nintroduces new scenarios for conditional generation while only requiring a\nsimple joint distribution to be learned. Our empirical exploration of the\nMS-COCO dataset demonstrates that our method generates multimodal text and\nimage data with higher quality compared to existing multimodal diffusion models\nwhile having a comparable size, faster training, faster multimodal sampling,\nand more flexible generation.\n",
                "链接": "https://arxiv.org/abs/2311.16488"
            },
            {
                "文章ID": "105347",
                "标题": "Steered Diffusion: A Generalized Framework for Plug-and-Play Conditional\n  Image Synthesis",
                "作者": " Nithin Gopalakrishnan Nair,  Anoop Cherian,  Suhas Lohit,  Ye Wang,  Toshiaki Koike-Akino,  Vishal M. Patel,  Tim K. Marks",
                "发布日期": "2023-10-03",
                "摘要": "  Conditional generative models typically demand large annotated training sets\nto achieve high-quality synthesis. As a result, there has been significant\ninterest in designing models that perform plug-and-play generation, i.e., to\nuse a predefined or pretrained model, which is not explicitly trained on the\ngenerative task, to guide the generative process (e.g., using language).\nHowever, such guidance is typically useful only towards synthesizing high-level\nsemantics rather than editing fine-grained details as in image-to-image\ntranslation tasks. To this end, and capitalizing on the powerful fine-grained\ngenerative control offered by the recent diffusion-based generative models, we\nintroduce Steered Diffusion, a generalized framework for photorealistic\nzero-shot conditional image generation using a diffusion model trained for\nunconditional generation. The key idea is to steer the image generation of the\ndiffusion model at inference time via designing a loss using a pre-trained\ninverse model that characterizes the conditional task. This loss modulates the\nsampling trajectory of the diffusion process. Our framework allows for easy\nincorporation of multiple conditions during inference. We present experiments\nusing steered diffusion on several tasks including inpainting, colorization,\ntext-guided semantic editing, and image super-resolution. Our results\ndemonstrate clear qualitative and quantitative improvements over\nstate-of-the-art diffusion-based plug-and-play models while adding negligible\nadditional computational cost.\n",
                "链接": "https://arxiv.org/abs/2310.00224"
            },
            {
                "文章ID": "27520",
                "标题": "Chat-to-Design: AI Assisted Personalized Fashion Design",
                "作者": " Weiming Zhuang,  Chongjie Ye,  Ying Xu,  Pengzhi Mao,  Shuai Zhang",
                "发布日期": "2022-07-05",
                "摘要": "  In this demo, we present Chat-to-Design, a new multimodal interaction system\nfor personalized fashion design. Compared to classic systems that recommend\napparel based on keywords, Chat-to-Design enables users to design clothes in\ntwo steps: 1) coarse-grained selection via conversation and 2) fine-grained\nediting via an interactive interface. It encompasses three sub-systems to\ndeliver an immersive user experience: A conversation system empowered by\nnatural language understanding to accept users' requests and manages dialogs; A\nmultimodal fashion retrieval system empowered by a large-scale pretrained\nlanguage-image network to retrieve requested apparel; A fashion design system\nempowered by emerging generative techniques to edit attributes of retrieved\nclothes.\n",
                "链接": "https://arxiv.org/abs/2207.01058"
            },
            {
                "文章ID": "76015",
                "标题": "Fine-Grained Product Classification on Leaflet Advertisements",
                "作者": "1 and 2  Daniel Ladwig, 1 and 2  Bianca Lamm,  Janis Keuper",
                "发布日期": "2023-05-08",
                "摘要": "  In this paper, we describe a first publicly available fine-grained product\nrecognition dataset based on leaflet images. Using advertisement leaflets,\ncollected over several years from different European retailers, we provide a\ntotal of 41.6k manually annotated product images in 832 classes. Further, we\ninvestigate three different approaches for this fine-grained product\nclassification task, Classification by Image, by Text, as well as by Image and\nText. The approach \"Classification by Text\" uses the text extracted directly\nfrom the leaflet product images. We show, that the combination of image and\ntext as input improves the classification of visual difficult to distinguish\nproducts. The final model leads to an accuracy of 96.4% with a Top-3 score of\n99.2%. We release our code at\nhttps://github.com/ladwigd/Leaflet-Product-Classification.\n",
                "链接": "https://arxiv.org/abs/2305.03706"
            },
            {
                "文章ID": "80167",
                "标题": "BLIP-Diffusion: Pre-trained Subject Representation for Controllable\n  Text-to-Image Generation and Editing",
                "作者": " Dongxu Li,  Junnan Li,  Steven C. H. Hoi",
                "发布日期": "2023-06-23",
                "摘要": "  Subject-driven text-to-image generation models create novel renditions of an\ninput subject based on text prompts. Existing models suffer from lengthy\nfine-tuning and difficulties preserving the subject fidelity. To overcome these\nlimitations, we introduce BLIP-Diffusion, a new subject-driven image generation\nmodel that supports multimodal control which consumes inputs of subject images\nand text prompts. Unlike other subject-driven generation models, BLIP-Diffusion\nintroduces a new multimodal encoder which is pre-trained to provide subject\nrepresentation. We first pre-train the multimodal encoder following BLIP-2 to\nproduce visual representation aligned with the text. Then we design a subject\nrepresentation learning task which enables a diffusion model to leverage such\nvisual representation and generates new subject renditions. Compared with\nprevious methods such as DreamBooth, our model enables zero-shot subject-driven\ngeneration, and efficient fine-tuning for customized subject with up to 20x\nspeedup. We also demonstrate that BLIP-Diffusion can be flexibly combined with\nexisting techniques such as ControlNet and prompt-to-prompt to enable novel\nsubject-driven generation and editing applications. Code and models will be\nreleased at\nhttps://github.com/salesforce/LAVIS/tree/main/projects/blip-diffusion. Project\npage at https://dxli94.github.io/BLIP-Diffusion-website/.\n",
                "链接": "https://arxiv.org/abs/2305.14720"
            },
            {
                "文章ID": "81646",
                "标题": "InstructEdit: Improving Automatic Masks for Diffusion-based Image\n  Editing With User Instructions",
                "作者": " Qian Wang,  Biao Zhang,  Michael Birsak,  Peter Wonka",
                "发布日期": "2023-05-30",
                "摘要": "  Recent works have explored text-guided image editing using diffusion models\nand generated edited images based on text prompts. However, the models struggle\nto accurately locate the regions to be edited and faithfully perform precise\nedits. In this work, we propose a framework termed InstructEdit that can do\nfine-grained editing based on user instructions. Our proposed framework has\nthree components: language processor, segmenter, and image editor. The first\ncomponent, the language processor, processes the user instruction using a large\nlanguage model. The goal of this processing is to parse the user instruction\nand output prompts for the segmenter and captions for the image editor. We\nadopt ChatGPT and optionally BLIP2 for this step. The second component, the\nsegmenter, uses the segmentation prompt provided by the language processor. We\nemploy a state-of-the-art segmentation framework Grounded Segment Anything to\nautomatically generate a high-quality mask based on the segmentation prompt.\nThe third component, the image editor, uses the captions from the language\nprocessor and the masks from the segmenter to compute the edited image. We\nadopt Stable Diffusion and the mask-guided generation from DiffEdit for this\npurpose. Experiments show that our method outperforms previous editing methods\nin fine-grained editing applications where the input image contains a complex\nobject or multiple objects. We improve the mask quality over DiffEdit and thus\nimprove the quality of edited images. We also show that our framework can\naccept multiple forms of user instructions as input. We provide the code at\nhttps://github.com/QianWangX/InstructEdit.\n",
                "链接": "https://arxiv.org/abs/2305.18047"
            },
            {
                "文章ID": "81455",
                "标题": "Text-to-image Editing by Image Information Removal",
                "作者": " Zhongping Zhang,  Jian Zheng,  Jacob Zhiyuan Fang,  Bryan A. Plummer",
                "发布日期": "2023-11-09",
                "摘要": "  Diffusion models have demonstrated impressive performance in text-guided\nimage generation. Current methods that leverage the knowledge of these models\nfor image editing either fine-tune them using the input image (e.g., Imagic) or\nincorporate structure information as additional constraints (e.g., ControlNet).\nHowever, fine-tuning large-scale diffusion models on a single image can lead to\nsevere overfitting issues and lengthy inference time. Information leakage from\npretrained models also make it challenging to preserve image content not\nrelated to the text input. Additionally, methods that incorporate structural\nguidance (e.g., edge maps, semantic maps, keypoints) find retaining attributes\nlike colors and textures difficult. Using the input image as a control could\nmitigate these issues, but since these models are trained via reconstruction, a\nmodel can simply hide information about the original image when encoding it to\nperfectly reconstruct the image without learning the editing task. To address\nthese challenges, we propose a text-to-image editing model with an Image\nInformation Removal module (IIR) that selectively erases color-related and\ntexture-related information from the original image, allowing us to better\npreserve the text-irrelevant content and avoid issues arising from information\nhiding. Our experiments on CUB, Outdoor Scenes, and COCO reports our approach\nachieves the best editability-fidelity trade-off results. In addition, a user\nstudy on COCO shows that our edited images are preferred 35% more often than\nprior work.\n",
                "链接": "https://arxiv.org/abs/2305.17489"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找风格化机器翻译相关的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找中文ner常用的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "5948",
                "标题": "AISHELL-NER: Named Entity Recognition from Chinese Speech",
                "作者": " Boli Chen,  Guangwei Xu,  Xiaobin Wang,  Pengjun Xie,  Meishan Zhang,  Fei Huang",
                "发布日期": "2022-02-18",
                "摘要": "  Named Entity Recognition (NER) from speech is among Spoken Language\nUnderstanding (SLU) tasks, aiming to extract semantic information from the\nspeech signal. NER from speech is usually made through a two-step pipeline that\nconsists of (1) processing the audio using an Automatic Speech Recognition\n(ASR) system and (2) applying an NER tagger to the ASR outputs. Recent works\nhave shown the capability of the End-to-End (E2E) approach for NER from English\nand French speech, which is essentially entity-aware ASR. However, due to the\nmany homophones and polyphones that exist in Chinese, NER from Chinese speech\nis effectively a more challenging task. In this paper, we introduce a new\ndataset AISEHLL-NER for NER from Chinese speech. Extensive experiments are\nconducted to explore the performance of several state-of-the-art methods. The\nresults demonstrate that the performance could be improved by combining\nentity-aware ASR and pretrained NER tagger, which can be easily applied to the\nmodern SLU pipeline. The dataset is publicly available at\ngithub.com/Alibaba-NLP/AISHELL-NER.\n",
                "链接": "https://arxiv.org/abs/2202.08533"
            },
            {
                "文章ID": "12836",
                "标题": "$k$NN-NER: Named Entity Recognition with Nearest Neighbor Search",
                "作者": " Shuhe Wang,  Xiaoya Li,  Yuxian Meng,  Tianwei Zhang,  Rongbin Ouyang,  Jiwei Li,  Guoyin Wang",
                "发布日期": "2022-04-01",
                "摘要": "  Inspired by recent advances in retrieval augmented methods in\nNLP~\\citep{khandelwal2019generalization,khandelwal2020nearest,meng2021gnn}, in\nthis paper, we introduce a $k$ nearest neighbor NER ($k$NN-NER) framework,\nwhich augments the distribution of entity labels by assigning $k$ nearest\nneighbors retrieved from the training set. This strategy makes the model more\ncapable of handling long-tail cases, along with better few-shot learning\nabilities. $k$NN-NER requires no additional operation during the training\nphase, and by interpolating $k$ nearest neighbors search into the vanilla NER\nmodel, $k$NN-NER consistently outperforms its vanilla counterparts: we achieve\na new state-of-the-art F1-score of 72.03 (+1.25) on the Chinese Weibo dataset\nand improved results on a variety of widely used NER benchmarks. Additionally,\nwe show that $k$NN-NER can achieve comparable results to the vanilla NER model\nwith 40\\% less amount of training data. Code available at\n\\url{https://github.com/ShannonAI/KNN-NER}.\n",
                "链接": "https://arxiv.org/abs/2203.17103"
            },
            {
                "文章ID": "73406",
                "标题": "GPT-NER: Named Entity Recognition via Large Language Models",
                "作者": " Shuhe Wang,  Xiaofei Sun,  Xiaoya Li,  Rongbin Ouyang,  Fei Wu,  Tianwei Zhang,  Jiwei Li,  Guoyin Wang",
                "发布日期": "2023-10-10",
                "摘要": "  Despite the fact that large-scale Language Models (LLM) have achieved SOTA\nperformances on a variety of NLP tasks, its performance on NER is still\nsignificantly below supervised baselines. This is due to the gap between the\ntwo tasks the NER and LLMs: the former is a sequence labeling task in nature\nwhile the latter is a text-generation model.\n  In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges the\ngap by transforming the sequence labeling task to a generation task that can be\neasily adapted by LLMs e.g., the task of finding location entities in the input\ntext \"Columbus is a city\" is transformed to generate the text sequence\n\"@@Columbus## is a city\", where special tokens @@## marks the entity to\nextract. To efficiently address the \"hallucination\" issue of LLMs, where LLMs\nhave a strong inclination to over-confidently label NULL inputs as entities, we\npropose a self-verification strategy by prompting LLMs to ask itself whether\nthe extracted entities belong to a labeled entity tag.\n  We conduct experiments on five widely adopted NER datasets, and GPT-NER\nachieves comparable performances to fully supervised baselines, which is the\nfirst time as far as we are concerned. More importantly, we find that GPT-NER\nexhibits a greater ability in the low-resource and few-shot setups, when the\namount of training data is extremely scarce, GPT-NER performs significantly\nbetter than supervised models. This demonstrates the capabilities of GPT-NER in\nreal-world NER applications where the number of labeled examples is limited.\n",
                "链接": "https://arxiv.org/abs/2304.10428"
            },
            {
                "文章ID": "81587",
                "标题": "E-NER: Evidential Deep Learning for Trustworthy Named Entity Recognition",
                "作者": " Zhen Zhang,  Mengting Hu,  Shiwan Zhao,  Minlie Huang,  Haotian Wang,  Lemao Liu,  Zhirui Zhang,  Zhe Liu,  Bingzhe Wu",
                "发布日期": "2023-05-30",
                "摘要": "  Most named entity recognition (NER) systems focus on improving model\nperformance, ignoring the need to quantify model uncertainty, which is critical\nto the reliability of NER systems in open environments. Evidential deep\nlearning (EDL) has recently been proposed as a promising solution to explicitly\nmodel predictive uncertainty for classification tasks. However, directly\napplying EDL to NER applications faces two challenges, i.e., the problems of\nsparse entities and OOV/OOD entities in NER tasks. To address these challenges,\nwe propose a trustworthy NER framework named E-NER by introducing two\nuncertainty-guided loss terms to the conventional EDL, along with a series of\nuncertainty-guided training strategies. Experiments show that E-NER can be\napplied to multiple NER paradigms to obtain accurate uncertainty estimation.\nFurthermore, compared to state-of-the-art baselines, the proposed method\nachieves a better OOV/OOD detection performance and better generalization\nability on OOV entities.\n",
                "链接": "https://arxiv.org/abs/2305.17854"
            },
            {
                "文章ID": "108977",
                "标题": "Empirical Study of Zero-Shot NER with ChatGPT",
                "作者": " Tingyu Xie,  Qi Li,  Jian Zhang,  Yan Zhang,  Zuozhu Liu,  Hongwei Wang",
                "发布日期": "2023-10-17",
                "摘要": "  Large language models (LLMs) exhibited powerful capability in various natural\nlanguage processing tasks. This work focuses on exploring LLM performance on\nzero-shot information extraction, with a focus on the ChatGPT and named entity\nrecognition (NER) task. Inspired by the remarkable reasoning capability of LLM\non symbolic and arithmetic reasoning, we adapt the prevalent reasoning methods\nto NER and propose reasoning strategies tailored for NER. First, we explore a\ndecomposed question-answering paradigm by breaking down the NER task into\nsimpler subproblems by labels. Second, we propose syntactic augmentation to\nstimulate the model's intermediate thinking in two ways: syntactic prompting,\nwhich encourages the model to analyze the syntactic structure itself, and tool\naugmentation, which provides the model with the syntactic information generated\nby a parsing tool. Besides, we adapt self-consistency to NER by proposing a\ntwo-stage majority voting strategy, which first votes for the most consistent\nmentions, then the most consistent types. The proposed methods achieve\nremarkable improvements for zero-shot NER across seven benchmarks, including\nChinese and English datasets, and on both domain-specific and general-domain\nscenarios. In addition, we present a comprehensive analysis of the error types\nwith suggestions for optimization directions. We also verify the effectiveness\nof the proposed methods on the few-shot setting and other LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.10035"
            },
            {
                "文章ID": "81674",
                "标题": "Extrinsic Factors Affecting the Accuracy of Biomedical NER",
                "作者": " Zhiyi Li,  Shengjie Zhang,  Yujie Song,  Jungyeul Park",
                "发布日期": "2023-05-30",
                "摘要": "  Biomedical named entity recognition (NER) is a critial task that aims to\nidentify structured information in clinical text, which is often replete with\ncomplex, technical terms and a high degree of variability. Accurate and\nreliable NER can facilitate the extraction and analysis of important biomedical\ninformation, which can be used to improve downstream applications including the\nhealthcare system. However, NER in the biomedical domain is challenging due to\nlimited data availability, as the high expertise, time, and expenses are\nrequired to annotate its data. In this paper, by using the limited data, we\nexplore various extrinsic factors including the corpus annotation scheme, data\naugmentation techniques, semi-supervised learning and Brill transformation, to\nimprove the performance of a NER model on a clinical text dataset (i2b2 2012,\n\\citet{sun-rumshisky-uzuner:2013}). Our experiments demonstrate that these\napproaches can significantly improve the model's F1 score from original 73.74\nto 77.55. Our findings suggest that considering different extrinsic factors and\ncombining these techniques is a promising approach for improving NER\nperformance in the biomedical domain where the size of data is limited.\n",
                "链接": "https://arxiv.org/abs/2305.18152"
            },
            {
                "文章ID": "81620",
                "标题": "ContrastNER: Contrastive-based Prompt Tuning for Few-shot NER",
                "作者": " Amirhossein Layegh,  Amir H. Payberah,  Ahmet Soylu,  Dumitru Roman,  Mihhail Matskin",
                "发布日期": "2023-08-08",
                "摘要": "  Prompt-based language models have produced encouraging results in numerous\napplications, including Named Entity Recognition (NER) tasks. NER aims to\nidentify entities in a sentence and provide their types. However, the strong\nperformance of most available NER approaches is heavily dependent on the design\nof discrete prompts and a verbalizer to map the model-predicted outputs to\nentity categories, which are complicated undertakings. To address these\nchallenges, we present ContrastNER, a prompt-based NER framework that employs\nboth discrete and continuous tokens in prompts and uses a contrastive learning\napproach to learn the continuous prompts and forecast entity types. The\nexperimental results demonstrate that ContrastNER obtains competitive\nperformance to the state-of-the-art NER methods in high-resource settings and\noutperforms the state-of-the-art models in low-resource circumstances without\nrequiring extensive manual prompt engineering and verbalizer design.\n",
                "链接": "https://arxiv.org/abs/2305.17951"
            },
            {
                "文章ID": "54218",
                "标题": "E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text",
                "作者": " Ting Wai Terence Au,  Ingemar J. Cox,  Vasileios Lampos",
                "发布日期": "2022-12-20",
                "摘要": "  Identifying named entities such as a person, location or organization, in\ndocuments can highlight key information to readers. Training Named Entity\nRecognition (NER) models requires an annotated data set, which can be a\ntime-consuming labour-intensive task. Nevertheless, there are publicly\navailable NER data sets for general English. Recently there has been interest\nin developing NER for legal text. However, prior work and experimental results\nreported here indicate that there is a significant degradation in performance\nwhen NER methods trained on a general English data set are applied to legal\ntext. We describe a publicly available legal NER data set, called E-NER, based\non legal company filings available from the US Securities and Exchange\nCommission's EDGAR data set. Training a number of different NER algorithms on\nthe general English CoNLL-2003 corpus but testing on our test collection\nconfirmed significant degradations in accuracy, as measured by the F1-score, of\nbetween 29.4\\% and 60.4\\%, compared to training and testing on the E-NER\ncollection.\n",
                "链接": "https://arxiv.org/abs/2212.09306"
            },
            {
                "文章ID": "82089",
                "标题": "A Multilingual Evaluation of NER Robustness to Adversarial Inputs",
                "作者": " Akshay Srinivasan,  Sowmya Vajjala",
                "发布日期": "2023-05-31",
                "摘要": "  Adversarial evaluations of language models typically focus on English alone.\nIn this paper, we performed a multilingual evaluation of Named Entity\nRecognition (NER) in terms of its robustness to small perturbations in the\ninput. Our results showed the NER models we explored across three languages\n(English, German and Hindi) are not very robust to such changes, as indicated\nby the fluctuations in the overall F1 score as well as in a more fine-grained\nevaluation. With that knowledge, we further explored whether it is possible to\nimprove the existing NER models using a part of the generated adversarial data\nsets as augmented training data to train a new NER model or as fine-tuning data\nto adapt an existing NER model. Our results showed that both these approaches\nimprove performance on the original as well as adversarial test sets. While\nthere is no significant difference between the two approaches for English,\nre-training is significantly better than fine-tuning for German and Hindi.\n",
                "链接": "https://arxiv.org/abs/2305.18933"
            },
            {
                "文章ID": "78785",
                "标题": "Enhancing Few-shot NER with Prompt Ordering based Data Augmentation",
                "作者": " Huiming Wang,  Liying Cheng,  Wenxuan Zhang,  De Wen Soh,  Lidong Bing",
                "发布日期": "2023-05-22",
                "摘要": "  Recently, data augmentation (DA) methods have been proven to be effective for\npre-trained language models (PLMs) in low-resource settings, including few-shot\nnamed entity recognition (NER). However, conventional NER DA methods are mostly\naimed at sequence labeling models, i.e., token-level classification, and few\nare compatible with unified autoregressive generation frameworks, which can\nhandle a wider range of NER tasks, such as nested NER. Furthermore, these\ngeneration frameworks have a strong assumption that the entities will appear in\nthe target sequence with the same left-to-right order as the source sequence.\nIn this paper, we claim that there is no need to keep this strict order, and\nmore diversified but reasonable target entity sequences can be provided during\nthe training stage as a novel DA method. Nevertheless, a naive mixture of\naugmented data can confuse the model since one source sequence will then be\npaired with different target sequences. Therefore, we propose a simple but\neffective Prompt Ordering based Data Augmentation (PODA) method to improve the\ntraining of unified autoregressive generation frameworks under few-shot NER\nscenarios. Experimental results on three public NER datasets and further\nanalyses demonstrate the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2305.11791"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下最近用反事实做数据增强的文章",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下利用蒙特卡罗树搜索解决序列决策问题的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "63382",
                "标题": "Towards Computationally Efficient Responsibility Attribution in\n  Decentralized Partially Observable MDPs",
                "作者": " Stelios Triantafyllou,  Goran Radanovic",
                "发布日期": "2023-02-27",
                "摘要": "  Responsibility attribution is a key concept of accountable multi-agent\ndecision making. Given a sequence of actions, responsibility attribution\nmechanisms quantify the impact of each participating agent to the final\noutcome. One such popular mechanism is based on actual causality, and it\nassigns (causal) responsibility based on the actions that were found to be\npivotal for the considered outcome. However, the inherent problem of\npinpointing actual causes and consequently determining the exact responsibility\nassignment has shown to be computationally intractable. In this paper, we aim\nto provide a practical algorithmic solution to the problem of responsibility\nattribution under a computational budget. We first formalize the problem in the\nframework of Decentralized Partially Observable Markov Decision Processes\n(Dec-POMDPs) augmented by a specific class of Structural Causal Models (SCMs).\nUnder this framework, we introduce a Monte Carlo Tree Search (MCTS) type of\nmethod which efficiently approximates the agents' degrees of responsibility.\nThis method utilizes the structure of a novel search tree and a pruning\ntechnique, both tailored to the problem of responsibility attribution. Other\nnovel components of our method are (a) a child selection policy based on linear\nscalarization and (b) a backpropagation procedure that accounts for a\nminimality condition that is typically used to define actual causality. We\nexperimentally evaluate the efficacy of our algorithm through a\nsimulation-based test-bed, which includes three team-based card games.\n",
                "链接": "https://arxiv.org/abs/2302.12676"
            },
            {
                "文章ID": "21495",
                "标题": "Personalized Algorithmic Recourse with Preference Elicitation",
                "作者": " Giovanni De Toni,  Paolo Viappiani,  Stefano Teso,  Bruno Lepri,  Andrea Passerini",
                "发布日期": "2023-06-01",
                "摘要": "  Algorithmic Recourse (AR) is the problem of computing a sequence of actions\nthat -- once performed by a user -- overturns an undesirable machine decision.\nIt is paramount that the sequence of actions does not require too much effort\nfor users to implement. Yet, most approaches to AR assume that actions cost the\nsame for all users, and thus may recommend unfairly expensive recourse plans to\ncertain users. Prompted by this observation, we introduce PEAR, the first\nhuman-in-the-loop approach capable of providing personalized algorithmic\nrecourse tailored to the needs of any end-user. PEAR builds on insights from\nBayesian Preference Elicitation to iteratively refine an estimate of the costs\nof actions by asking choice set queries to the target user. The queries\nthemselves are computed by maximizing the Expected Utility of Selection, a\nprincipled measure of information gain accounting for uncertainty on both the\ncost estimate and the user's responses. PEAR integrates elicitation into a\nReinforcement Learning agent coupled with Monte Carlo Tree Search to quickly\nidentify promising recourse plans. Our empirical evaluation on real-world\ndatasets highlights how PEAR produces high-quality personalized recourse in\nonly a handful of iterations.\n",
                "链接": "https://arxiv.org/abs/2205.13743"
            },
            {
                "文章ID": "1749",
                "标题": "Synthesizing explainable counterfactual policies for algorithmic\n  recourse with program synthesis",
                "作者": " Giovanni De Toni,  Bruno Lepri,  Andrea Passerini",
                "发布日期": "2023-02-08",
                "摘要": "  Being able to provide counterfactual interventions - sequences of actions we\nwould have had to take for a desirable outcome to happen - is essential to\nexplain how to change an unfavourable decision by a black-box machine learning\nmodel (e.g., being denied a loan request). Existing solutions have mainly\nfocused on generating feasible interventions without providing explanations on\ntheir rationale. Moreover, they need to solve a separate optimization problem\nfor each user. In this paper, we take a different approach and learn a program\nthat outputs a sequence of explainable counterfactual actions given a user\ndescription and a causal graph. We leverage program synthesis techniques,\nreinforcement learning coupled with Monte Carlo Tree Search for efficient\nexploration, and rule learning to extract explanations for each recommended\naction. An experimental evaluation on synthetic and real-world datasets shows\nhow our approach generates effective interventions by making orders of\nmagnitude fewer queries to the black-box classifier with respect to existing\nsolutions, with the additional benefit of complementing them with interpretable\nexplanations.\n",
                "链接": "https://arxiv.org/abs/2201.07135"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用gpt4做评测指标优缺点的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "80263",
                "标题": "Evaluating Evaluation Metrics: A Framework for Analyzing NLG Evaluation\n  Metrics using Measurement Theory",
                "作者": " Ziang Xiao,  Susu Zhang,  Vivian Lai,  Q. Vera Liao",
                "发布日期": "2023-10-24",
                "摘要": "  We address a fundamental challenge in Natural Language Generation (NLG) model\nevaluation -- the design and evaluation of evaluation metrics. Recognizing the\nlimitations of existing automatic metrics and noises from how current human\nevaluation was conducted, we propose MetricEval, a framework informed by\nmeasurement theory, the foundation of educational test design, for\nconceptualizing and evaluating the reliability and validity of NLG evaluation\nmetrics. The framework formalizes the source of measurement error and offers\nstatistical tools for evaluating evaluation metrics based on empirical data.\nWith our framework, one can quantify the uncertainty of the metrics to better\ninterpret the result. To exemplify the use of our framework in practice, we\nanalyzed a set of evaluation metrics for summarization and identified issues\nrelated to conflated validity structure in human-eval and reliability in\nLLM-based metrics. Through MetricEval, we aim to promote the design,\nevaluation, and interpretation of valid and reliable metrics to advance robust\nand effective NLG models.\n",
                "链接": "https://arxiv.org/abs/2305.14889"
            },
            {
                "文章ID": "57762",
                "标题": "Robot Skill Learning Via Classical Robotics-Based Generated Datasets:\n  Advantages, Disadvantages, and Future Improvement",
                "作者": " Batu Kaan Oezen",
                "发布日期": "2023-01-24",
                "摘要": "  Why do we not profit from our long-existing classical robotics knowledge and\nlook for some alternative way for data collection? The situation ignoring all\nexisting methods might be such a waste. This article argues that a dataset\ncreated using a classical robotics algorithm is a crucial part of future\ndevelopment. This developed classic algorithm has a perfect domain adaptation\nand generalization property, and most importantly, collecting datasets based on\nthem is quite easy. It is well known that current robot skill-learning\napproaches perform exceptionally badly in the unseen domain, and their\nperformance against adversarial attacks is quite limited as long as they do not\nhave a very exclusive big dataset. Our experiment is the initial steps of using\na dataset created by classical robotics codes. Our experiment investigated\npossible trajectory collection based on classical robotics. It addressed some\nadvantages and disadvantages and pointed out other future development ideas.\n",
                "链接": "https://arxiv.org/abs/2301.08794"
            },
            {
                "文章ID": "98603",
                "标题": "Training and Meta-Evaluating Machine Translation Evaluation Metrics at\n  the Paragraph Level",
                "作者": " Daniel Deutsch,  Juraj Juraska,  Mara Finkelstein,  Markus Freitag",
                "发布日期": "2023-08-29",
                "摘要": "  As research on machine translation moves to translating text beyond the\nsentence level, it remains unclear how effective automatic evaluation metrics\nare at scoring longer translations. In this work, we first propose a method for\ncreating paragraph-level data for training and meta-evaluating metrics from\nexisting sentence-level data. Then, we use these new datasets to benchmark\nexisting sentence-level metrics as well as train learned metrics at the\nparagraph level. Interestingly, our experimental results demonstrate that using\nsentence-level metrics to score entire paragraphs is equally as effective as\nusing a metric designed to work at the paragraph level. We speculate this\nresult can be attributed to properties of the task of reference-based\nevaluation as well as limitations of our datasets with respect to capturing all\ntypes of phenomena that occur in paragraph-level translations.\n",
                "链接": "https://arxiv.org/abs/2308.13506"
            },
            {
                "文章ID": "110350",
                "标题": "Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large\n  Language Models on Sequence to Sequence Tasks",
                "作者": " Andrea Sottana,  Bin Liang,  Kai Zou,  Zheng Yuan",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) evaluation is a patchy and inconsistent\nlandscape, and it is becoming clear that the quality of automatic evaluation\nmetrics is not keeping up with the pace of development of generative models. We\naim to improve the understanding of current models' performance by providing a\npreliminary and hybrid evaluation on a range of open and closed-source\ngenerative LLMs on three NLP benchmarks: text summarisation, text\nsimplification and grammatical error correction (GEC), using both automatic and\nhuman evaluation. We also explore the potential of the recently released GPT-4\nto act as an evaluator. We find that ChatGPT consistently outperforms many\nother popular models according to human reviewers on the majority of metrics,\nwhile scoring much more poorly when using classic automatic evaluation metrics.\nWe also find that human reviewers rate the gold reference as much worse than\nthe best models' outputs, indicating the poor quality of many popular\nbenchmarks. Finally, we find that GPT-4 is capable of ranking models' outputs\nin a way which aligns reasonably closely to human judgement despite\ntask-specific variations, with a lower alignment in the GEC task.\n",
                "链接": "https://arxiv.org/abs/2310.13800"
            },
            {
                "文章ID": "77571",
                "标题": "NLG Evaluation Metrics Beyond Correlation Analysis: An Empirical Metric\n  Preference Checklist",
                "作者": " Iftitahu Ni'mah,  Meng Fang,  Vlado Menkovski,  Mykola Pechenizkiy",
                "发布日期": "2023-05-29",
                "摘要": "  In this study, we analyze automatic evaluation metrics for Natural Language\nGeneration (NLG), specifically task-agnostic metrics and human-aligned metrics.\nTask-agnostic metrics, such as Perplexity, BLEU, BERTScore, are cost-effective\nand highly adaptable to diverse NLG tasks, yet they have a weak correlation\nwith human. Human-aligned metrics (CTC, CtrlEval, UniEval) improves correlation\nlevel by incorporating desirable human-like qualities as training objective.\nHowever, their effectiveness at discerning system-level performance and quality\nof system outputs remain unclear.\n  We present metric preference checklist as a framework to assess the\neffectiveness of automatic metrics in three NLG tasks: Text Summarization,\nDialogue Response Generation, and Controlled Generation. Our proposed framework\nprovides access: (i) for verifying whether automatic metrics are faithful to\nhuman preference, regardless of their correlation level to human; and (ii) for\ninspecting the strengths and limitations of NLG systems via pairwise\nevaluation. We show that automatic metrics provide a better guidance than human\non discriminating system-level performance in Text Summarization and Controlled\nGeneration tasks. We also show that multi-aspect human-aligned metric (UniEval)\nis not necessarily dominant over single-aspect human-aligned metrics (CTC,\nCtrlEval) and task-agnostic metrics (BLEU, BERTScore), particularly in\nControlled Generation tasks.\n",
                "链接": "https://arxiv.org/abs/2305.08566"
            },
            {
                "文章ID": "25426",
                "标题": "MME-CRS: Multi-Metric Evaluation Based on Correlation Re-Scaling for\n  Evaluating Open-Domain Dialogue",
                "作者": " Pengfei Zhang,  Xiaohui Hu,  Kaidong Yu,  Jian Wang,  Song Han,  Cao Liu,  Chunyang Yuan",
                "发布日期": "2022-06-22",
                "摘要": "  Automatic open-domain dialogue evaluation is a crucial component of dialogue\nsystems. Recently, learning-based evaluation metrics have achieved\nstate-of-the-art performance in open-domain dialogue evaluation. However, these\nmetrics, which only focus on a few qualities, are hard to evaluate dialogue\ncomprehensively. Furthermore, these metrics lack an effective score composition\napproach for diverse evaluation qualities. To address the above problems, we\npropose a Multi-Metric Evaluation based on Correlation Re-Scaling (MME-CRS) for\nevaluating open-domain dialogue. Firstly, we build an evaluation metric\ncomposed of 5 groups of parallel sub-metrics called Multi-Metric Evaluation\n(MME) to evaluate the quality of dialogue comprehensively. Furthermore, we\npropose a novel score composition method called Correlation Re-Scaling (CRS) to\nmodel the relationship between sub-metrics and diverse qualities. Our approach\nMME-CRS ranks first on the final test data of DSTC10 track5 subtask1 Automatic\nOpen-domain Dialogue Evaluation Challenge with a large margin, which proved the\neffectiveness of our proposed approach.\n",
                "链接": "https://arxiv.org/abs/2206.09403"
            },
            {
                "文章ID": "120466",
                "标题": "Advantage of Quantum Machine Learning from General Computational\n  Advantages",
                "作者": " Hayata Yamasaki,  Natsuto Isogai,  Mio Murao",
                "发布日期": "2023-12-07",
                "摘要": "  An overarching milestone of quantum machine learning (QML) is to demonstrate\nthe advantage of QML over all possible classical learning methods in\naccelerating a common type of learning task as represented by supervised\nlearning with classical data. However, the provable advantages of QML in\nsupervised learning have been known so far only for the learning tasks designed\nfor using the advantage of specific quantum algorithms, i.e., Shor's\nalgorithms. Here we explicitly construct an unprecedentedly broader family of\nsupervised learning tasks with classical data to offer the provable advantage\nof QML based on general quantum computational advantages, progressing beyond\nShor's algorithms. Our learning task is feasibly achievable by executing a\ngeneral class of functions that can be computed efficiently in polynomial time\nfor a large fraction of inputs by arbitrary quantum algorithms but not by any\nclassical algorithm. We prove the hardness of achieving this learning task for\nany possible polynomial-time classical learning method. We also clarify\nprotocols for preparing the classical data to demonstrate this learning task in\nexperiments. These results open routes to exploit a variety of quantum\nadvantages in computing functions for the experimental demonstration of the\nadvantage of QML.\n",
                "链接": "https://arxiv.org/abs/2312.03057"
            },
            {
                "文章ID": "5926",
                "标题": "On the Evaluation Metrics for Paraphrase Generation",
                "作者": " Lingfeng Shen,  Lemao Liu,  Haiyun Jiang,  Shuming Shi",
                "发布日期": "2022-10-11",
                "摘要": "  In this paper we revisit automatic metrics for paraphrase evaluation and\nobtain two findings that disobey conventional wisdom: (1) Reference-free\nmetrics achieve better performance than their reference-based counterparts. (2)\nMost commonly used metrics do not align well with human annotation. Underlying\nreasons behind the above findings are explored through additional experiments\nand in-depth analyses. Based on the experiments and analyses, we propose\nParaScore, a new evaluation metric for paraphrase generation. It possesses the\nmerits of reference-based and reference-free metrics and explicitly models\nlexical divergence. Experimental results demonstrate that ParaScore\nsignificantly outperforms existing metrics.\n",
                "链接": "https://arxiv.org/abs/2202.08479"
            },
            {
                "文章ID": "116110",
                "标题": "Enhancing Medical Text Evaluation with GPT-4",
                "作者": " Yiqing Xie,  Sheng Zhang,  Hao Cheng,  Zelalem Gero,  Cliff Wong,  Tristan Naumann,  Hoifung Poon",
                "发布日期": "2023-11-17",
                "摘要": "  In the evaluation of medical text generation, it is essential to scrutinize\neach piece of information and ensure the utmost accuracy of the evaluation.\nExisting evaluation metrics either focus on coarse-level evaluation that\nassigns one score for the whole generated output or rely on evaluation models\ntrained on general domain, resulting in inaccuracies when adapted to the\nmedical domain. To address these issues, we propose a set of factuality-centric\nevaluation aspects and design corresponding GPT-4-based metrics for medical\ntext generation. We systematically compare these metrics with existing ones on\nclinical note generation and medical report summarization tasks, revealing low\ninter-metric correlation. A comprehensive human evaluation confirms that the\nproposed GPT-4-based metrics exhibit substantially higher agreement with human\njudgments than existing evaluation metrics. Our study contributes to the\nunderstanding of medical text generation evaluation and offers a more reliable\nalternative to existing metrics.\n",
                "链接": "https://arxiv.org/abs/2311.09581"
            },
            {
                "文章ID": "16357",
                "标题": "Offline Retrieval Evaluation Without Evaluation Metrics",
                "作者": " Fernando Diaz,  Andres Ferraro",
                "发布日期": "2022-04-26",
                "摘要": "  Offline evaluation of information retrieval and recommendation has\ntraditionally focused on distilling the quality of a ranking into a scalar\nmetric such as average precision or normalized discounted cumulative gain. We\ncan use this metric to compare the performance of multiple systems for the same\nrequest. Although evaluation metrics provide a convenient summary of system\nperformance, they also collapse subtle differences across users into a single\nnumber and can carry assumptions about user behavior and utility not supported\nacross retrieval scenarios. We propose recall-paired preference (RPP), a\nmetric-free evaluation method based on directly computing a preference between\nranked lists. RPP simulates multiple user subpopulations per query and compares\nsystems across these pseudo-populations. Our results across multiple search and\nrecommendation tasks demonstrate that RPP substantially improves discriminative\npower while correlating well with existing metrics and being equally robust to\nincomplete data.\n",
                "链接": "https://arxiv.org/abs/2204.11400"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用GPT4v完成多模态智能体的论文",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "使用LLM进行蛋白质结构/功能/性质预测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "106701",
                "标题": "CrysFormer: Protein Structure Prediction via 3d Patterson Maps and\n  Partial Structure Attention",
                "作者": " Chen Dun,  Qiutai Pan,  Shikai Jin,  Ria Stevens,  Mitchell D. Miller, Jr. George N. Phillips,,  Anastasios Kyrillidis",
                "发布日期": "2023-10-09",
                "摘要": "  Determining the structure of a protein has been a decades-long open question.\nA protein's three-dimensional structure often poses nontrivial computation\ncosts, when classical simulation algorithms are utilized. Advances in the\ntransformer neural network architecture -- such as AlphaFold2 -- achieve\nsignificant improvements for this problem, by learning from a large dataset of\nsequence information and corresponding protein structures. Yet, such methods\nonly focus on sequence information; other available prior knowledge, such as\nprotein crystallography and partial structure of amino acids, could be\npotentially utilized. To the best of our knowledge, we propose the first\ntransformer-based model that directly utilizes protein crystallography and\npartial structure information to predict the electron density maps of proteins.\nVia two new datasets of peptide fragments (2-residue and 15-residue) , we\ndemonstrate our method, dubbed \\texttt{CrysFormer}, can achieve accurate\npredictions, based on a much smaller dataset size and with reduced computation\ncosts.\n",
                "链接": "https://arxiv.org/abs/2310.03899"
            },
            {
                "文章ID": "26245",
                "标题": "PSP: Million-level Protein Sequence Dataset for Protein Structure\n  Prediction",
                "作者": " Sirui Liu,  Jun Zhang,  Haotian Chu,  Min Wang,  Boxin Xue,  Ningxi Ni,  Jialiang Yu,  Yuhao Xie,  Zhenyu Chen,  Mengyun Chen,  Yuan Liu,  Piya Patra,  Fan Xu,  Jie Chen,  Zidong Wang,  Lijiang Yang,  Fan Yu,  Lei Chen,  Yi Qin Gao",
                "发布日期": "2022-06-27",
                "摘要": "  Proteins are essential component of human life and their structures are\nimportant for function and mechanism analysis. Recent work has shown the\npotential of AI-driven methods for protein structure prediction. However, the\ndevelopment of new models is restricted by the lack of dataset and benchmark\ntraining procedure. To the best of our knowledge, the existing open source\ndatasets are far less to satisfy the needs of modern protein sequence-structure\nrelated research. To solve this problem, we present the first million-level\nprotein structure prediction dataset with high coverage and diversity, named as\nPSP. This dataset consists of 570k true structure sequences (10TB) and 745k\ncomplementary distillation sequences (15TB). We provide in addition the\nbenchmark training procedure for SOTA protein structure prediction model on\nthis dataset. We validate the utility of this dataset for training by\nparticipating CAMEO contest in which our model won the first place. We hope our\nPSP dataset together with the training benchmark can enable a broader community\nof AI/biology researchers for AI-driven protein related research.\n",
                "链接": "https://arxiv.org/abs/2206.12240"
            },
            {
                "文章ID": "109510",
                "标题": "Protein 3D Graph Structure Learning for Robust Structure-based Protein\n  Property Prediction",
                "作者": " Yufei Huang,  Siyuan Li,  Jin Su,  Lirong Wu,  Odin Zhang,  Haitao Lin,  Jingqi Qi,  Zihan Liu,  Zhangyang Gao,  Yuyang Liu,  Jiangbin Zheng,  Stan. ZQ. Li",
                "发布日期": "2023-10-20",
                "摘要": "  Protein structure-based property prediction has emerged as a promising\napproach for various biological tasks, such as protein function prediction and\nsub-cellular location estimation. The existing methods highly rely on\nexperimental protein structure data and fail in scenarios where these data are\nunavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were\nutilized as alternatives. However, we observed that current practices, which\nsimply employ accurately predicted structures during inference, suffer from\nnotable degradation in prediction accuracy. While similar phenomena have been\nextensively studied in general fields (e.g., Computer Vision) as model\nrobustness, their impact on protein property prediction remains unexplored. In\nthis paper, we first investigate the reason behind the performance decrease\nwhen utilizing predicted structures, attributing it to the structure embedding\nbias from the perspective of structure representation learning. To study this\nproblem, we identify a Protein 3D Graph Structure Learning Problem for Robust\nProtein Property Prediction (PGSL-RP3), collect benchmark datasets, and present\na protein Structure embedding Alignment Optimization framework (SAO) to\nmitigate the problem of structure embedding bias between the predicted and\nexperimental protein structures. Extensive experiments have shown that our\nframework is model-agnostic and effective in improving the property prediction\nof both predicted structures and experimental structures. The benchmark\ndatasets and codes will be released to benefit the community.\n",
                "链接": "https://arxiv.org/abs/2310.11466"
            },
            {
                "文章ID": "58713",
                "标题": "Pre-Training Protein Encoder via Siamese Sequence-Structure Diffusion\n  Trajectory Prediction",
                "作者": " Zuobai Zhang,  Minghao Xu,  Aurélie Lozano,  Vijil Chenthamarakshan,  Payel Das,  Jian Tang",
                "发布日期": "2023-07-11",
                "摘要": "  Self-supervised pre-training methods on proteins have recently gained\nattention, with most approaches focusing on either protein sequences or\nstructures, neglecting the exploration of their joint distribution, which is\ncrucial for a comprehensive understanding of protein functions by integrating\nco-evolutionary information and structural characteristics. In this work,\ninspired by the success of denoising diffusion models in generative tasks, we\npropose the DiffPreT approach to pre-train a protein encoder by\nsequence-structure joint diffusion modeling. DiffPreT guides the encoder to\nrecover the native protein sequences and structures from the perturbed ones\nalong the joint diffusion trajectory, which acquires the joint distribution of\nsequences and structures. Considering the essential protein conformational\nvariations, we enhance DiffPreT by a method called Siamese Diffusion Trajectory\nPrediction (SiamDiff) to capture the correlation between different conformers\nof a protein. SiamDiff attains this goal by maximizing the mutual information\nbetween representations of diffusion trajectories of structurally-correlated\nconformers. We study the effectiveness of DiffPreT and SiamDiff on both atom-\nand residue-level structure-based protein understanding tasks. Experimental\nresults show that the performance of DiffPreT is consistently competitive on\nall tasks, and SiamDiff achieves new state-of-the-art performance, considering\nthe mean ranks on all tasks. Our implementation is available at\nhttps://github.com/DeepGraphLearning/SiamDiff.\n",
                "链接": "https://arxiv.org/abs/2301.12068"
            },
            {
                "文章ID": "39761",
                "标题": "State-specific protein-ligand complex structure prediction with a\n  multi-scale deep generative model",
                "作者": " Zhuoran Qiao,  Weili Nie,  Arash Vahdat, III Thomas F. Miller,  Anima Anandkumar",
                "发布日期": "2023-04-21",
                "摘要": "  The binding complexes formed by proteins and small molecule ligands are\nubiquitous and critical to life. Despite recent advancements in protein\nstructure prediction, existing algorithms are so far unable to systematically\npredict the binding ligand structures along with their regulatory effects on\nprotein folding. To address this discrepancy, we present NeuralPLexer, a\ncomputational approach that can directly predict protein-ligand complex\nstructures solely using protein sequence and ligand molecular graph inputs.\nNeuralPLexer adopts a deep generative model to sample the 3D structures of the\nbinding complex and their conformational changes at an atomistic resolution.\nThe model is based on a diffusion process that incorporates essential\nbiophysical constraints and a multi-scale geometric deep learning system to\niteratively sample residue-level contact maps and all heavy-atom coordinates in\na hierarchical manner. NeuralPLexer achieves state-of-the-art performance\ncompared to all existing methods on benchmarks for both protein-ligand blind\ndocking and flexible binding site structure recovery. Moreover, owing to its\nspecificity in sampling both ligand-free-state and ligand-bound-state\nensembles, NeuralPLexer consistently outperforms AlphaFold2 in terms of global\nprotein structure accuracy on both representative structure pairs with large\nconformational changes (average TM-score=0.93) and recently determined\nligand-binding proteins (average TM-score=0.89). Case studies reveal that the\npredicted conformational variations are consistent with structure determination\nexperiments for important targets, including human KRAS$^\\textrm{G12C}$,\nketol-acid reductoisomerase, and purine GPCRs. Our study suggests that a\ndata-driven approach can capture the structural cooperativity between proteins\nand small molecules, showing promise in accelerating the design of enzymes,\ndrug molecules, and beyond.\n",
                "链接": "https://arxiv.org/abs/2209.15171"
            },
            {
                "文章ID": "70802",
                "标题": "EigenFold: Generative Protein Structure Prediction with Diffusion Models",
                "作者": " Bowen Jing,  Ezra Erives,  Peter Pao-Huang,  Gabriele Corso,  Bonnie Berger,  Tommi Jaakkola",
                "发布日期": "2023-04-06",
                "摘要": "  Protein structure prediction has reached revolutionary levels of accuracy on\nsingle structures, yet distributional modeling paradigms are needed to capture\nthe conformational ensembles and flexibility that underlie biological function.\nTowards this goal, we develop EigenFold, a diffusion generative modeling\nframework for sampling a distribution of structures from a given protein\nsequence. We define a diffusion process that models the structure as a system\nof harmonic oscillators and which naturally induces a cascading-resolution\ngenerative process along the eigenmodes of the system. On recent CAMEO targets,\nEigenFold achieves a median TMScore of 0.84, while providing a more\ncomprehensive picture of model uncertainty via the ensemble of sampled\nstructures relative to existing methods. We then assess EigenFold's ability to\nmodel and predict conformational heterogeneity for fold-switching proteins and\nligand-induced conformational change. Code is available at\nhttps://github.com/bjing2016/EigenFold.\n",
                "链接": "https://arxiv.org/abs/2304.02198"
            },
            {
                "文章ID": "57484",
                "标题": "Beating the Best: Improving on AlphaFold2 at Protein Structure\n  Prediction",
                "作者": " Abbi Abdel-Rehim,  Oghenejokpeme Orhobor,  Hang Lou,  Hao Ni,  Ross D. King",
                "发布日期": "2023-01-24",
                "摘要": "  The goal of Protein Structure Prediction (PSP) problem is to predict a\nprotein's 3D structure (confirmation) from its amino acid sequence. The problem\nhas been a 'holy grail' of science since the Noble prize-winning work of\nAnfinsen demonstrated that protein conformation was determined by sequence. A\nrecent and important step towards this goal was the development of AlphaFold2,\ncurrently the best PSP method. AlphaFold2 is probably the highest profile\napplication of AI to science. Both AlphaFold2 and RoseTTAFold (another\nimpressive PSP method) have been published and placed in the public domain\n(code & models). Stacking is a form of ensemble machine learning ML in which\nmultiple baseline models are first learnt, then a meta-model is learnt using\nthe outputs of the baseline level model to form a model that outperforms the\nbase models. Stacking has been successful in many applications. We developed\nthe ARStack PSP method by stacking AlphaFold2 and RoseTTAFold. ARStack\nsignificantly outperforms AlphaFold2. We rigorously demonstrate this using two\nsets of non-homologous proteins, and a test set of protein structures published\nafter that of AlphaFold2 and RoseTTAFold. As more high quality prediction\nmethods are published it is likely that ensemble methods will increasingly\noutperform any single method.\n",
                "链接": "https://arxiv.org/abs/2301.07568"
            },
            {
                "文章ID": "31301",
                "标题": "HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein\n  Language Model as an Alternative",
                "作者": " Xiaomin Fang,  Fan Wang,  Lihang Liu,  Jingzhou He,  Dayong Lin,  Yingfei Xiang,  Xiaonan Zhang,  Hua Wu,  Hui Li,  Le Song",
                "发布日期": "2023-10-19",
                "摘要": "  AI-based protein structure prediction pipelines, such as AlphaFold2, have\nachieved near-experimental accuracy. These advanced pipelines mainly rely on\nMultiple Sequence Alignments (MSAs) as inputs to learn the co-evolution\ninformation from the homologous sequences. Nonetheless, searching MSAs from\nprotein databases is time-consuming, usually taking dozens of minutes.\nConsequently, we attempt to explore the limits of fast protein structure\nprediction by using only primary sequences of proteins. HelixFold-Single is\nproposed to combine a large-scale protein language model with the superior\ngeometric learning capability of AlphaFold2. Our proposed method,\nHelixFold-Single, first pre-trains a large-scale protein language model (PLM)\nwith thousands of millions of primary sequences utilizing the self-supervised\nlearning paradigm, which will be used as an alternative to MSAs for learning\nthe co-evolution information. Then, by combining the pre-trained PLM and the\nessential components of AlphaFold2, we obtain an end-to-end differentiable\nmodel to predict the 3D coordinates of atoms from only the primary sequence.\nHelixFold-Single is validated in datasets CASP14 and CAMEO, achieving\ncompetitive accuracy with the MSA-based methods on the targets with large\nhomologous families. Furthermore, HelixFold-Single consumes much less time than\nthe mainstream pipelines for protein structure prediction, demonstrating its\npotential in tasks requiring many predictions. The code of HelixFold-Single is\navailable at\nhttps://github.com/PaddlePaddle/PaddleHelix/tree/dev/apps/protein_folding/helixfold-single,\nand we also provide stable web services on\nhttps://paddlehelix.baidu.com/app/drug/protein-single/forecast.\n",
                "链接": "https://arxiv.org/abs/2207.13921"
            },
            {
                "文章ID": "51324",
                "标题": "Protein Language Models and Structure Prediction: Connection and\n  Progression",
                "作者": " Bozhen Hu,  Jun Xia,  Jiangbin Zheng,  Cheng Tan,  Yufei Huang,  Yongjie Xu,  Stan Z. Li",
                "发布日期": "2022-12-01",
                "摘要": "  The prediction of protein structures from sequences is an important task for\nfunction prediction, drug design, and related biological processes\nunderstanding. Recent advances have proved the power of language models (LMs)\nin processing the protein sequence databases, which inherit the advantages of\nattention networks and capture useful information in learning representations\nfor proteins. The past two years have witnessed remarkable success in tertiary\nprotein structure prediction (PSP), including evolution-based and\nsingle-sequence-based PSP. It seems that instead of using energy-based models\nand sampling procedures, protein language model (pLM)-based pipelines have\nemerged as mainstream paradigms in PSP. Despite the fruitful progress, the PSP\ncommunity needs a systematic and up-to-date survey to help bridge the gap\nbetween LMs in the natural language processing (NLP) and PSP domains and\nintroduce their methodologies, advancements and practical applications. To this\nend, in this paper, we first introduce the similarities between protein and\nhuman languages that allow LMs extended to pLMs, and applied to protein\ndatabases. Then, we systematically review recent advances in LMs and pLMs from\nthe perspectives of network architectures, pre-training strategies,\napplications, and commonly-used protein databases. Next, different types of\nmethods for PSP are discussed, particularly how the pLM-based architectures\nfunction in the process of protein folding. Finally, we identify challenges\nfaced by the PSP community and foresee promising research directions along with\nthe advances of pLMs. This survey aims to be a hands-on guide for researchers\nto understand PSP methods, develop pLMs and tackle challenging problems in this\nfield for practical purposes.\n",
                "链接": "https://arxiv.org/abs/2211.16742"
            },
            {
                "文章ID": "83294",
                "标题": "Enhancing the Protein Tertiary Structure Prediction by Multiple Sequence\n  Alignment Generation",
                "作者": " Le Zhang,  Jiayang Chen,  Tao Shen,  Yu Li,  Siqi Sun",
                "发布日期": "2023-06-06",
                "摘要": "  The field of protein folding research has been greatly advanced by deep\nlearning methods, with AlphaFold2 (AF2) demonstrating exceptional performance\nand atomic-level precision. As co-evolution is integral to protein structure\nprediction, AF2's accuracy is significantly influenced by the depth of multiple\nsequence alignment (MSA), which requires extensive exploration of a large\nprotein database for similar sequences. However, not all protein sequences\npossess abundant homologous families, and consequently, AF2's performance can\ndegrade on such queries, at times failing to produce meaningful results. To\naddress this, we introduce a novel generative language model, MSA-Augmenter,\nwhich leverages protein-specific attention mechanisms and large-scale MSAs to\ngenerate useful, novel protein sequences not currently found in databases.\nThese sequences supplement shallow MSAs, enhancing the accuracy of structural\nproperty predictions. Our experiments on CASP14 demonstrate that MSA-Augmenter\ncan generate de novo sequences that retain co-evolutionary information from\ninferior MSAs, thereby improving protein structure prediction quality on top of\nstrong AF2.\n",
                "链接": "https://arxiv.org/abs/2306.01824"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用BERT和RoBERTa进行多语言情感分析的最新论文，要求涵盖2022年以来的研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "82977",
                "标题": "UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of\n  Multilingual BERT for Low-resource Sentiment Analysis",
                "作者": " Dou Hu,  Lingwei Wei,  Yaxin Liu,  Wei Zhou,  Songlin Hu",
                "发布日期": "2023-06-05",
                "摘要": "  This paper describes our system designed for SemEval-2023 Task 12: Sentiment\nanalysis for African languages. The challenge faced by this task is the\nscarcity of labeled data and linguistic resources in low-resource settings. To\nalleviate these, we propose a generalized multilingual system SACL-XLMR for\nsentiment analysis on low-resource languages. Specifically, we design a\nlexicon-based multilingual BERT to facilitate language adaptation and\nsentiment-aware representation learning. Besides, we apply a supervised\nadversarial contrastive learning technique to learn sentiment-spread structured\nrepresentations and enhance model generalization. Our system achieved\ncompetitive results, largely outperforming baselines on both multilingual and\nzero-shot sentiment classification subtasks. Notably, the system obtained the\n1st rank on the zero-shot classification subtask in the official ranking.\nExtensive experiments demonstrate the effectiveness of our system.\n",
                "链接": "https://arxiv.org/abs/2306.01093"
            },
            {
                "文章ID": "824",
                "标题": "BERT for Sentiment Analysis: Pre-trained and Fine-Tuned Alternatives",
                "作者": " Frederico Souza,  João Filho",
                "发布日期": "2022-01-11",
                "摘要": "  BERT has revolutionized the NLP field by enabling transfer learning with\nlarge language models that can capture complex textual patterns, reaching the\nstate-of-the-art for an expressive number of NLP applications. For text\nclassification tasks, BERT has already been extensively explored. However,\naspects like how to better cope with the different embeddings provided by the\nBERT output layer and the usage of language-specific instead of multilingual\nmodels are not well studied in the literature, especially for the Brazilian\nPortuguese language. The purpose of this article is to conduct an extensive\nexperimental study regarding different strategies for aggregating the features\nproduced in the BERT output layer, with a focus on the sentiment analysis task.\nThe experiments include BERT models trained with Brazilian Portuguese corpora\nand the multilingual version, contemplating multiple aggregation strategies and\nopen-source datasets with predefined training, validation, and test partitions\nto facilitate the reproducibility of the results. BERT achieved the highest\nROC-AUC values for the majority of cases as compared to TF-IDF. Nonetheless,\nTF-IDF represents a good trade-off between the predictive performance and\ncomputational cost.\n",
                "链接": "https://arxiv.org/abs/2201.03382"
            },
            {
                "文章ID": "15513",
                "标题": "Mono vs Multilingual BERT for Hate Speech Detection and Text\n  Classification: A Case Study in Marathi",
                "作者": " Abhishek Velankar,  Hrushikesh Patil,  Raviraj Joshi",
                "发布日期": "2022-11-15",
                "摘要": "  Transformers are the most eminent architectures used for a vast range of\nNatural Language Processing tasks. These models are pre-trained over a large\ntext corpus and are meant to serve state-of-the-art results over tasks like\ntext classification. In this work, we conduct a comparative study between\nmonolingual and multilingual BERT models. We focus on the Marathi language and\nevaluate the models on the datasets for hate speech detection, sentiment\nanalysis and simple text classification in Marathi. We use standard\nmultilingual models such as mBERT, indicBERT and xlm-RoBERTa and compare with\nMahaBERT, MahaALBERT and MahaRoBERTa, the monolingual models for Marathi. We\nfurther show that Marathi monolingual models outperform the multilingual BERT\nvariants on five different downstream fine-tuning experiments. We also evaluate\nsentence embeddings from these models by freezing the BERT encoder layers. We\nshow that monolingual MahaBERT based models provide rich representations as\ncompared to sentence embeddings from multi-lingual counterparts. However, we\nobserve that these embeddings are not generic enough and do not work well on\nout of domain social media datasets. We consider two Marathi hate speech\ndatasets L3Cube-MahaHate, HASOC-2021, a Marathi sentiment classification\ndataset L3Cube-MahaSent, and Marathi Headline, Articles classification\ndatasets.\n",
                "链接": "https://arxiv.org/abs/2204.08669"
            },
            {
                "文章ID": "114320",
                "标题": "Modelling Sentiment Analysis: LLMs and data augmentation techniques",
                "作者": " Guillem Senabre Prades",
                "发布日期": "2023-11-08",
                "摘要": "  This paper provides different approaches for a binary sentiment\nclassification on a small training dataset. LLMs that provided state-of-the-art\nresults in sentiment analysis and similar domains are being used, such as BERT,\nRoBERTa and XLNet.\n",
                "链接": "https://arxiv.org/abs/2311.04139"
            },
            {
                "文章ID": "31048",
                "标题": "Enhancing Collaborative Filtering Recommender with Prompt-Based\n  Sentiment Analysis",
                "作者": " Elliot Dang,  Zheyuan Hu,  Tong Li",
                "发布日期": "2022-07-27",
                "摘要": "  Collaborative Filtering(CF) recommender is a crucial application in the\nonline market and ecommerce. However, CF recommender has been proven to suffer\nfrom persistent problems related to sparsity of the user rating that will\nfurther lead to a cold-start issue. Existing methods address the data sparsity\nissue by applying token-level sentiment analysis that translate text review\ninto sentiment scores as a complement of the user rating. In this paper, we\nattempt to optimize the sentiment analysis with advanced NLP models including\nBERT and RoBERTa, and experiment on whether the CF recommender has been further\nenhanced. We build the recommenders on the Amazon US Reviews dataset, and tune\nthe pretrained BERT and RoBERTa with the traditional fine-tuned paradigm as\nwell as the new prompt-based learning paradigm. Experimental result shows that\nthe recommender enhanced with the sentiment ratings predicted by the fine-tuned\nRoBERTa has the best performance, and achieved 30.7% overall gain by comparing\nMAP, NDCG and precision at K to the baseline recommender. Prompt-based learning\nparadigm, although superior to traditional fine-tune paradigm in pure sentiment\nanalysis, fail to further improve the CF recommender.\n",
                "链接": "https://arxiv.org/abs/2207.12883"
            },
            {
                "文章ID": "52169",
                "标题": "Video Games as a Corpus: Sentiment Analysis using Fallout New Vegas\n  Dialog",
                "作者": " Mika Hämäläinen,  Khalid Alnajjar,  Thierry Poibeau",
                "发布日期": "2022-12-06",
                "摘要": "  We present a method for extracting a multilingual sentiment annotated dialog\ndata set from Fallout New Vegas. The game developers have preannotated every\nline of dialog in the game in one of the 8 different sentiments: \\textit{anger,\ndisgust, fear, happy, neutral, pained, sad } and \\textit{surprised}. The game\nhas been translated into English, Spanish, German, French and Italian. We\nconduct experiments on multilingual, multilabel sentiment analysis on the\nextracted data set using multilingual BERT, XLMRoBERTa and language specific\nBERT models. In our experiments, multilingual BERT outperformed XLMRoBERTa for\nmost of the languages, also language specific models were slightly better than\nmultilingual BERT for most of the languages. The best overall accuracy was 54\\%\nand it was achieved by using multilingual BERT on Spanish data. The extracted\ndata set presents a challenging task for sentiment analysis. We have released\nthe data, including the testing and training splits, openly on Zenodo. The data\nset has been shuffled for copyright reasons.\n",
                "链接": "https://arxiv.org/abs/2212.02168"
            },
            {
                "文章ID": "47660",
                "标题": "BERT-Based Combination of Convolutional and Recurrent Neural Network for\n  Indonesian Sentiment Analysis",
                "作者": " Hendri Murfi,   Syamsyuriani,  Theresia Gowandi,  Gianinna Ardaneswari,  Siti Nurrohmah",
                "发布日期": "2022-11-11",
                "摘要": "  Sentiment analysis is the computational study of opinions and emotions\nex-pressed in text. Deep learning is a model that is currently producing\nstate-of-the-art in various application domains, including sentiment analysis.\nMany researchers are using a hybrid approach that combines different deep\nlearning models and has been shown to improve model performance. In sentiment\nanalysis, input in text data is first converted into a numerical\nrepresentation. The standard method used to obtain a text representation is the\nfine-tuned embedding method. However, this method does not pay attention to\neach word's context in the sentence. Therefore, the Bidirectional Encoder\nRepresentation from Transformer (BERT) model is used to obtain text\nrepresentations based on the context and position of words in sentences. This\nresearch extends the previous hybrid deep learning using BERT representation\nfor Indonesian sentiment analysis. Our simulation shows that the BERT\nrepresentation improves the accuracies of all hybrid architectures. The\nBERT-based LSTM-CNN also reaches slightly better accuracies than other\nBERT-based hybrid architectures.\n",
                "链接": "https://arxiv.org/abs/2211.05273"
            },
            {
                "文章ID": "18471",
                "标题": "A Dataset and BERT-based Models for Targeted Sentiment Analysis on\n  Turkish Texts",
                "作者": " M. Melih Mutlu,  Arzucan Özgür",
                "发布日期": "2022-05-10",
                "摘要": "  Targeted Sentiment Analysis aims to extract sentiment towards a particular\ntarget from a given text. It is a field that is attracting attention due to the\nincreasing accessibility of the Internet, which leads people to generate an\nenormous amount of data. Sentiment analysis, which in general requires\nannotated data for training, is a well-researched area for widely studied\nlanguages such as English. For low-resource languages such as Turkish, there is\na lack of such annotated data. We present an annotated Turkish dataset suitable\nfor targeted sentiment analysis. We also propose BERT-based models with\ndifferent architectures to accomplish the task of targeted sentiment analysis.\nThe results demonstrate that the proposed models outperform the traditional\nsentiment analysis models for the targeted sentiment analysis task.\n",
                "链接": "https://arxiv.org/abs/2205.04185"
            },
            {
                "文章ID": "74465",
                "标题": "HausaNLP at SemEval-2023 Task 12: Leveraging African Low Resource\n  TweetData for Sentiment Analysis",
                "作者": " Saheed Abdullahi Salahudeen,  Falalu Ibrahim Lawan,  Ahmad Mustapha Wali,  Amina Abubakar Imam,  Aliyu Rabiu Shuaibu,  Aliyu Yusuf,  Nur Bala Rabiu,  Musa Bello,  Shamsuddeen Umaru Adamu,  Saminu Mohammad Aliyu,  Murja Sani Gadanya,  Sanah Abdullahi Muaz,  Mahmoud Said Ahmad,  Abdulkadir Abdullahi,  Abdulmalik Yusuf Jamoh",
                "发布日期": "2023-04-27",
                "摘要": "  We present the findings of SemEval-2023 Task 12, a shared task on sentiment\nanalysis for low-resource African languages using Twitter dataset. The task\nfeatured three subtasks; subtask A is monolingual sentiment classification with\n12 tracks which are all monolingual languages, subtask B is multilingual\nsentiment classification using the tracks in subtask A and subtask C is a\nzero-shot sentiment classification. We present the results and findings of\nsubtask A, subtask B and subtask C. We also release the code on github. Our\ngoal is to leverage low-resource tweet data using pre-trained Afro-xlmr-large,\nAfriBERTa-Large, Bert-base-arabic-camelbert-da-sentiment (Arabic-camelbert),\nMultilingual-BERT (mBERT) and BERT models for sentiment analysis of 14 African\nlanguages. The datasets for these subtasks consists of a gold standard\nmulti-class labeled Twitter datasets from these languages. Our results\ndemonstrate that Afro-xlmr-large model performed better compared to the other\nmodels in most of the languages datasets. Similarly, Nigerian languages: Hausa,\nIgbo, and Yoruba achieved better performance compared to other languages and\nthis can be attributed to the higher volume of data present in the languages.\n",
                "链接": "https://arxiv.org/abs/2304.13634"
            },
            {
                "文章ID": "11461",
                "标题": "Mono vs Multilingual BERT: A Case Study in Hindi and Marathi Named\n  Entity Recognition",
                "作者": " Onkar Litake,  Maithili Sabane,  Parth Patil,  Aparna Ranade,  Raviraj Joshi",
                "发布日期": "2023-02-28",
                "摘要": "  Named entity recognition (NER) is the process of recognising and classifying\nimportant information (entities) in text. Proper nouns, such as a person's\nname, an organization's name, or a location's name, are examples of entities.\nThe NER is one of the important modules in applications like human resources,\ncustomer support, search engines, content classification, and academia. In this\nwork, we consider NER for low-resource Indian languages like Hindi and Marathi.\nThe transformer-based models have been widely used for NER tasks. We consider\ndifferent variations of BERT like base-BERT, RoBERTa, and AlBERT and benchmark\nthem on publicly available Hindi and Marathi NER datasets. We provide an\nexhaustive comparison of different monolingual and multilingual\ntransformer-based models and establish simple baselines currently missing in\nthe literature. We show that the monolingual MahaRoBERTa model performs the\nbest for Marathi NER whereas the multilingual XLM-RoBERTa performs the best for\nHindi NER. We also perform cross-language evaluation and present mixed\nobservations.\n",
                "链接": "https://arxiv.org/abs/2203.12907"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找一下2018年以后使用强化学习做机器翻译任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "92370",
                "标题": "Incorporating Human Translator Style into English-Turkish Literary\n  Machine Translation",
                "作者": " Zeynep Yirmibeşoğlu,  Olgun Dursun,  Harun Dallı,  Mehmet Şahin,  Ena Hodzik,  Sabri Gürses,  Tunga Güngör",
                "发布日期": "2023-07-24",
                "摘要": "  Although machine translation systems are mostly designed to serve in the\ngeneral domain, there is a growing tendency to adapt these systems to other\ndomains like literary translation. In this paper, we focus on English-Turkish\nliterary translation and develop machine translation models that take into\naccount the stylistic features of translators. We fine-tune a pre-trained\nmachine translation model by the manually-aligned works of a particular\ntranslator. We make a detailed analysis of the effects of manual and automatic\nalignments, data augmentation methods, and corpus size on the translations. We\npropose an approach based on stylistic features to evaluate the style of a\ntranslator in the output translations. We show that the human translator style\ncan be highly recreated in the target machine translations by adapting the\nmodels to the style of the translator.\n",
                "链接": "https://arxiv.org/abs/2307.11457"
            },
            {
                "文章ID": "107113",
                "标题": "Synslator: An Interactive Machine Translation Tool with Online Learning",
                "作者": " Jiayi Wang,  Ke Wang,  Fengming Zhou,  Chengyu Wang,  Zhiyong Fu,  Zeyu Feng,  Yu Zhao,  Yuqi Zhang",
                "发布日期": "2023-10-10",
                "摘要": "  Interactive machine translation (IMT) has emerged as a progression of the\ncomputer-aided translation paradigm, where the machine translation system and\nthe human translator collaborate to produce high-quality translations. This\npaper introduces Synslator, a user-friendly computer-aided translation (CAT)\ntool that not only supports IMT, but is adept at online learning with real-time\ntranslation memories. To accommodate various deployment environments for CAT\nservices, Synslator integrates two different neural translation models to\nhandle translation memories for online learning. Additionally, the system\nemploys a language model to enhance the fluency of translations in an\ninteractive mode. In evaluation, we have confirmed the effectiveness of online\nlearning through the translation models, and have observed a 13% increase in\npost-editing efficiency with the interactive functionalities of Synslator. A\ntutorial video is available at:https://youtu.be/K0vRsb2lTt8.\n",
                "链接": "https://arxiv.org/abs/2310.05025"
            },
            {
                "文章ID": "79608",
                "标题": "Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine\n  Translation",
                "作者": " Jiayi Wang,  Ke Wang,  Yuqi Zhang,  Yu Zhao,  Pontus Stenetorp",
                "发布日期": "2023-05-24",
                "摘要": "  Non-parametric, k-nearest-neighbor algorithms have recently made inroads to\nassist generative models such as language models and machine translation\ndecoders. We explore whether such non-parametric models can improve machine\ntranslation models at the fine-tuning stage by incorporating statistics from\nthe kNN predictions to inform the gradient updates for a baseline translation\nmodel. There are multiple methods which could be used to incorporate kNN\nstatistics and we investigate gradient scaling by a gating mechanism, the kNN's\nground truth probability, and reinforcement learning. For four standard\nin-domain machine translation datasets, compared with classic fine-tuning, we\nreport consistent improvements of all of the three methods by as much as 1.45\nBLEU and 1.28 BLEU for German-English and English-German translations\nrespectively. Through qualitative analysis, we found particular improvements\nwhen it comes to translating grammatical relations or function words, which\nresults in increased fluency of our model.\n",
                "链接": "https://arxiv.org/abs/2305.13648"
            },
            {
                "文章ID": "73945",
                "标题": "UTSGAN: Unseen Transition Suss GAN for Transition-Aware Image-to-image\n  Translation",
                "作者": " Yaxin Shi,  Xiaowei Zhou,  Ping Liu,  Ivor W. Tsang",
                "发布日期": "2023-04-25",
                "摘要": "  In the field of Image-to-Image (I2I) translation, ensuring consistency\nbetween input images and their translated results is a key requirement for\nproducing high-quality and desirable outputs. Previous I2I methods have relied\non result consistency, which enforces consistency between the translated\nresults and the ground truth output, to achieve this goal. However, result\nconsistency is limited in its ability to handle complex and unseen attribute\nchanges in translation tasks. To address this issue, we introduce a\ntransition-aware approach to I2I translation, where the data translation\nmapping is explicitly parameterized with a transition variable, allowing for\nthe modelling of unobserved translations triggered by unseen transitions.\nFurthermore, we propose the use of transition consistency, defined on the\ntransition variable, to enable regularization of consistency on unobserved\ntranslations, which is omitted in previous works. Based on these insights, we\npresent Unseen Transition Suss GAN (UTSGAN), a generative framework that\nconstructs a manifold for the transition with a stochastic transition encoder\nand coherently regularizes and generalizes result consistency and transition\nconsistency on both training and unobserved translations with tailor-designed\nconstraints. Extensive experiments on four different I2I tasks performed on\nfive different datasets demonstrate the efficacy of our proposed UTSGAN in\nperforming consistent translations.\n",
                "链接": "https://arxiv.org/abs/2304.11955"
            },
            {
                "文章ID": "56448",
                "标题": "Applying Automated Machine Translation to Educational Video Courses",
                "作者": " Linden Wang",
                "发布日期": "2023-09-20",
                "摘要": "  We studied the capability of automated machine translation in the online\nvideo education space by automatically translating Khan Academy videos with\nstate-of-the-art translation models and applying text-to-speech synthesis and\naudio/video synchronization to build engaging videos in target languages. We\nalso analyzed and established two reliable translation confidence estimators\nbased on round-trip translations in order to efficiently manage translation\nquality and reduce human translation effort. Finally, we developed a deployable\nsystem to deliver translated videos to end users and collect user corrections\nfor iterative improvement.\n",
                "链接": "https://arxiv.org/abs/2301.03141"
            },
            {
                "文章ID": "48179",
                "标题": "Easy Guided Decoding in Providing Suggestions for Interactive Machine\n  Translation",
                "作者": " Ke Wang,  Xin Ge,  Jiayi Wang,  Yu Zhao,  Yuqi Zhang",
                "发布日期": "2023-06-05",
                "摘要": "  Machine translation technology has made great progress in recent years, but\nit cannot guarantee error free results. Human translators perform post editing\non machine translations to correct errors in the scene of computer aided\ntranslation. In favor of expediting the post editing process, many works have\ninvestigated machine translation in interactive modes, in which machines can\nautomatically refine the rest of translations constrained by human's edits.\nTranslation Suggestion (TS), as an interactive mode to assist human\ntranslators, requires machines to generate alternatives for specific incorrect\nwords or phrases selected by human translators. In this paper, we utilize the\nparameterized objective function of neural machine translation (NMT) and\npropose a novel constrained decoding algorithm, namely Prefix Suffix Guided\nDecoding (PSGD), to deal with the TS problem without additional training.\nCompared to the state of the art lexically constrained decoding method, PSGD\nimproves translation quality by an average of $10.87$ BLEU and $8.62$ BLEU on\nthe WeTS and the WMT 2022 Translation Suggestion datasets, respectively, and\nreduces decoding time overhead by an average of 63.4% tested on the WMT\ntranslation datasets. Furthermore, on both of the TS benchmark datasets, it is\nsuperior to other supervised learning systems trained with TS annotated data.\n",
                "链接": "https://arxiv.org/abs/2211.07093"
            },
            {
                "文章ID": "55838",
                "标题": "Active Learning for Neural Machine Translation",
                "作者": " Neeraj Vashistha,  Kriti Singh,  Ramakant Shakya",
                "发布日期": "2023-01-03",
                "摘要": "  The machine translation mechanism translates texts automatically between\ndifferent natural languages, and Neural Machine Translation (NMT) has gained\nattention for its rational context analysis and fluent translation accuracy.\nHowever, processing low-resource languages that lack relevant training\nattributes like supervised data is a current challenge for Natural Language\nProcessing (NLP). We incorporated a technique known Active Learning with the\nNMT toolkit Joey NMT to reach sufficient accuracy and robust predictions of\nlow-resource language translation. With active learning, a semi-supervised\nmachine learning strategy, the training algorithm determines which unlabeled\ndata would be the most beneficial for obtaining labels using selected query\ntechniques. We implemented two model-driven acquisition functions for selecting\nthe samples to be validated. This work uses transformer-based NMT systems;\nbaseline model (BM), fully trained model (FTM) , active learning least\nconfidence based model (ALLCM), and active learning margin sampling based model\n(ALMSM) when translating English to Hindi. The Bilingual Evaluation Understudy\n(BLEU) metric has been used to evaluate system results. The BLEU scores of BM,\nFTM, ALLCM and ALMSM systems are 16.26, 22.56 , 24.54, and 24.20, respectively.\nThe findings in this paper demonstrate that active learning techniques helps\nthe model to converge early and improve the overall quality of the translation\nsystem.\n",
                "链接": "https://arxiv.org/abs/2301.00688"
            },
            {
                "文章ID": "83454",
                "标题": "Extract and Attend: Improving Entity Translation in Neural Machine\n  Translation",
                "作者": " Zixin Zeng,  Rui Wang,  Yichong Leng,  Junliang Guo,  Xu Tan,  Tao Qin,  Tie-yan Liu",
                "发布日期": "2023-06-06",
                "摘要": "  While Neural Machine Translation(NMT) has achieved great progress in recent\nyears, it still suffers from inaccurate translation of entities (e.g.,\nperson/organization name, location), due to the lack of entity training\ninstances. When we humans encounter an unknown entity during translation, we\nusually first look up in a dictionary and then organize the entity translation\ntogether with the translations of other parts to form a smooth target sentence.\nInspired by this translation process, we propose an Extract-and-Attend approach\nto enhance entity translation in NMT, where the translation candidates of\nsource entities are first extracted from a dictionary and then attended to by\nthe NMT model to generate the target sentence. Specifically, the translation\ncandidates are extracted by first detecting the entities in a source sentence\nand then translating the entities through looking up in a dictionary. Then, the\nextracted candidates are added as a prefix of the decoder input to be attended\nto by the decoder when generating the target sentence through self-attention.\nExperiments conducted on En-Zh and En-Ru demonstrate that the proposed method\nis effective on improving both the translation accuracy of entities and the\noverall translation quality, with up to 35% reduction on entity error rate and\n0.85 gain on BLEU and 13.8 gain on COMET.\n",
                "链接": "https://arxiv.org/abs/2306.02242"
            },
            {
                "文章ID": "51365",
                "标题": "Rephrasing the Reference for Non-Autoregressive Machine Translation",
                "作者": " Chenze Shao,  Jinchao Zhang,  Jie Zhou,  Yang Feng",
                "发布日期": "2022-12-01",
                "摘要": "  Non-autoregressive neural machine translation (NAT) models suffer from the\nmulti-modality problem that there may exist multiple possible translations of a\nsource sentence, so the reference sentence may be inappropriate for the\ntraining when the NAT output is closer to other translations. In response to\nthis problem, we introduce a rephraser to provide a better training target for\nNAT by rephrasing the reference sentence according to the NAT output. As we\ntrain NAT based on the rephraser output rather than the reference sentence, the\nrephraser output should fit well with the NAT output and not deviate too far\nfrom the reference, which can be quantified as reward functions and optimized\nby reinforcement learning. Experiments on major WMT benchmarks and NAT\nbaselines show that our approach consistently improves the translation quality\nof NAT. Specifically, our best variant achieves comparable performance to the\nautoregressive Transformer, while being 14.7 times more efficient in inference.\n",
                "链接": "https://arxiv.org/abs/2211.16863"
            },
            {
                "文章ID": "6641",
                "标题": "An Overview on Machine Translation Evaluation",
                "作者": " Lifeng Han",
                "发布日期": "2022-02-23",
                "摘要": "  Since the 1950s, machine translation (MT) has become one of the important\ntasks of AI and development, and has experienced several different periods and\nstages of development, including rule-based methods, statistical methods, and\nrecently proposed neural network-based learning methods. Accompanying these\nstaged leaps is the evaluation research and development of MT, especially the\nimportant role of evaluation methods in statistical translation and neural\ntranslation research. The evaluation task of MT is not only to evaluate the\nquality of machine translation, but also to give timely feedback to machine\ntranslation researchers on the problems existing in machine translation itself,\nhow to improve and how to optimise. In some practical application fields, such\nas in the absence of reference translations, the quality estimation of machine\ntranslation plays an important role as an indicator to reveal the credibility\nof automatically translated target languages. This report mainly includes the\nfollowing contents: a brief history of machine translation evaluation (MTE),\nthe classification of research methods on MTE, and the the cutting-edge\nprogress, including human evaluation, automatic evaluation, and evaluation of\nevaluation methods (meta-evaluation). Manual evaluation and automatic\nevaluation include reference-translation based and reference-translation\nindependent participation; automatic evaluation methods include traditional\nn-gram string matching, models applying syntax and semantics, and deep learning\nmodels; evaluation of evaluation methods includes estimating the credibility of\nhuman evaluations, the reliability of the automatic evaluation, the reliability\nof the test set, etc. Advances in cutting-edge evaluation methods include\ntask-based evaluation, using pre-trained language models based on big data, and\nlightweight optimisation models using distillation techniques.\n",
                "链接": "https://arxiv.org/abs/2202.11027"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下关于大模型使用工具的安全性的论文。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下对使用GPT生成数据集的训练步骤进行改进的论文。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "请找到利用clip做开放词汇检测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "105778",
                "标题": "CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense\n  Prediction",
                "作者": " Size Wu,  Wenwei Zhang,  Lumin Xu,  Sheng Jin,  Xiangtai Li,  Wentao Liu,  Chen Change Loy",
                "发布日期": "2023-10-03",
                "摘要": "  Open-vocabulary dense prediction tasks including object detection and image\nsegmentation have been advanced by the success of Contrastive Language-Image\nPre-training (CLIP). CLIP models, particularly those incorporating vision\ntransformers (ViTs), have exhibited remarkable generalization ability in\nzero-shot image classification. However, when transferring the vision-language\nalignment of CLIP from global image representation to local region\nrepresentation for the open-vocabulary dense prediction tasks, CLIP ViTs suffer\nfrom the domain shift from full images to local image regions. In this paper,\nwe embark on an in-depth analysis of the region-language alignment in CLIP\nmodels, which is essential for downstream open-vocabulary dense prediction\ntasks. Subsequently, we propose an approach named CLIPSelf, which adapts the\nimage-level recognition ability of CLIP ViT to local image regions without\nneeding any region-text pairs. CLIPSelf empowers ViTs to distill itself by\naligning a region representation extracted from its dense feature map with the\nimage-level representation of the corresponding image crop. With the enhanced\nCLIP ViTs, we achieve new state-of-the-art performance on open-vocabulary\nobject detection, semantic segmentation, and panoptic segmentation across\nvarious benchmarks. Models and code will be available at\nhttps://github.com/wusize/CLIPSelf.\n",
                "链接": "https://arxiv.org/abs/2310.01403"
            },
            {
                "文章ID": "110181",
                "标题": "SILC: Improving Vision Language Pretraining with Self-Distillation",
                "作者": " Muhammad Ferjad Naeem,  Yongqin Xian,  Xiaohua Zhai,  Lukas Hoyer,  Luc Van Gool,  Federico Tombari",
                "发布日期": "2023-12-08",
                "摘要": "  Image-Text pretraining on web-scale image caption datasets has become the\ndefault recipe for open vocabulary classification and retrieval models thanks\nto the success of CLIP and its variants. Several works have also used CLIP\nfeatures for dense prediction tasks and have shown the emergence of open-set\nabilities. However, the contrastive objective used by these models only focuses\non image-text alignment and does not incentivise image feature learning for\ndense prediction tasks. In this work, we introduce SILC, a novel framework for\nvision language pretraining. SILC improves image-text contrastive learning with\nthe simple addition of local-to-global correspondence learning by\nself-distillation. We show that distilling local image features from an\nexponential moving average (EMA) teacher model significantly improves model\nperformance on dense predictions tasks like detection and segmentation, while\nalso providing improvements on image-level tasks such as classification and\nretrieval. SILC models sets a new state of the art for zero-shot\nclassification, few shot classification, image and text retrieval, zero-shot\nsegmentation, and open vocabulary segmentation. We further show that SILC\nfeatures greatly benefit open vocabulary detection, captioning and visual\nquestion answering.\n",
                "链接": "https://arxiv.org/abs/2310.13355"
            },
            {
                "文章ID": "28246",
                "标题": "Bridging the Gap between Object and Image-level Representations for\n  Open-Vocabulary Detection",
                "作者": " Hanoona Rasheed,  Muhammad Maaz,  Muhammad Uzair Khattak,  Salman Khan,  Fahad Shahbaz Khan",
                "发布日期": "2022-11-30",
                "摘要": "  Existing open-vocabulary object detectors typically enlarge their vocabulary\nsizes by leveraging different forms of weak supervision. This helps generalize\nto novel objects at inference. Two popular forms of weak-supervision used in\nopen-vocabulary detection (OVD) include pretrained CLIP model and image-level\nsupervision. We note that both these modes of supervision are not optimally\naligned for the detection task: CLIP is trained with image-text pairs and lacks\nprecise localization of objects while the image-level supervision has been used\nwith heuristics that do not accurately specify local object regions. In this\nwork, we propose to address this problem by performing object-centric alignment\nof the language embeddings from the CLIP model. Furthermore, we visually ground\nthe objects with only image-level supervision using a pseudo-labeling process\nthat provides high-quality object proposals and helps expand the vocabulary\nduring training. We establish a bridge between the above two object-alignment\nstrategies via a novel weight transfer function that aggregates their\ncomplimentary strengths. In essence, the proposed model seeks to minimize the\ngap between object and image-centric representations in the OVD setting. On the\nCOCO benchmark, our proposed approach achieves 36.6 AP50 on novel classes, an\nabsolute 8.2 gain over the previous best performance. For LVIS, we surpass the\nstate-of-the-art ViLD model by 5.0 mask AP for rare categories and 3.4 overall.\nCode: https://github.com/hanoonaR/object-centric-ovd.\n",
                "链接": "https://arxiv.org/abs/2207.03482"
            },
            {
                "文章ID": "99749",
                "标题": "What Makes Good Open-Vocabulary Detector: A Disassembling Perspective",
                "作者": " Jincheng Li,  Chunyu Xie,  Xiaoyu Wu,  Bin Wang,  Dawei Leng",
                "发布日期": "2023-09-04",
                "摘要": "  Open-vocabulary detection (OVD) is a new object detection paradigm, aiming to\nlocalize and recognize unseen objects defined by an unbounded vocabulary. This\nis challenging since traditional detectors can only learn from pre-defined\ncategories and thus fail to detect and localize objects out of pre-defined\nvocabulary. To handle the challenge, OVD leverages pre-trained cross-modal VLM,\nsuch as CLIP, ALIGN, etc. Previous works mainly focus on the open vocabulary\nclassification part, with less attention on the localization part. We argue\nthat for a good OVD detector, both classification and localization should be\nparallelly studied for the novel object categories. We show in this work that\nimproving localization as well as cross-modal classification complement each\nother, and compose a good OVD detector jointly. We analyze three families of\nOVD methods with different design emphases. We first propose a vanilla\nmethod,i.e., cropping a bounding box obtained by a localizer and resizing it\ninto the CLIP. We next introduce another approach, which combines a standard\ntwo-stage object detector with CLIP. A two-stage object detector includes a\nvisual backbone, a region proposal network (RPN), and a region of interest\n(RoI) head. We decouple RPN and ROI head (DRR) and use RoIAlign to extract\nmeaningful features. In this case, it avoids resizing objects. To further\naccelerate the training time and reduce the model parameters, we couple RPN and\nROI head (CRR) as the third approach. We conduct extensive experiments on these\nthree types of approaches in different settings. On the OVD-COCO benchmark, DRR\nobtains the best performance and achieves 35.8 Novel AP$_{50}$, an absolute 2.8\ngain over the previous state-of-the-art (SOTA). For OVD-LVIS, DRR surpasses the\nprevious SOTA by 1.9 AP$_{50}$ in rare categories. We also provide an object\ndetection dataset called PID and provide a baseline on PID.\n",
                "链接": "https://arxiv.org/abs/2309.00227"
            },
            {
                "文章ID": "104455",
                "标题": "Object-Centric Open-Vocabulary Image-Retrieval with Aggregated Features",
                "作者": " Hila Levi,  Guy Heller,  Dan Levi,  Ethan Fetaya",
                "发布日期": "2023-09-27",
                "摘要": "  The task of open-vocabulary object-centric image retrieval involves the\nretrieval of images containing a specified object of interest, delineated by an\nopen-set text query. As working on large image datasets becomes standard,\nsolving this task efficiently has gained significant practical importance.\nApplications include targeted performance analysis of retrieved images using\nad-hoc queries and hard example mining during training. Recent advancements in\ncontrastive-based open vocabulary systems have yielded remarkable\nbreakthroughs, facilitating large-scale open vocabulary image retrieval.\nHowever, these approaches use a single global embedding per image, thereby\nconstraining the system's ability to retrieve images containing relatively\nsmall object instances. Alternatively, incorporating local embeddings from\ndetection pipelines faces scalability challenges, making it unsuitable for\nretrieval from large databases.\n  In this work, we present a simple yet effective approach to object-centric\nopen-vocabulary image retrieval. Our approach aggregates dense embeddings\nextracted from CLIP into a compact representation, essentially combining the\nscalability of image retrieval pipelines with the object identification\ncapabilities of dense detection methods. We show the effectiveness of our\nscheme to the task by achieving significantly better results than global\nfeature approaches on three datasets, increasing accuracy by up to 15 mAP\npoints. We further integrate our scheme into a large scale retrieval framework\nand demonstrate our method's advantages in terms of scalability and\ninterpretability.\n",
                "链接": "https://arxiv.org/abs/2309.14999"
            },
            {
                "文章ID": "116861",
                "标题": "CastDet: Toward Open Vocabulary Aerial Object Detection with\n  CLIP-Activated Student-Teacher Learning",
                "作者": " Yan Li,  Weiwei Guo,  Dunyun He,  Jiaqi Zhou,  Yuze Gao,  Wenxian Yu",
                "发布日期": "2023-11-21",
                "摘要": "  Object detection in aerial images is a pivotal task for various earth\nobservation applications, whereas current algorithms learn to detect only a\npre-defined set of object categories demanding sufficient bounding-box\nannotated training samples and fail to detect novel object categories. In this\npaper, we consider open-vocabulary object detection (OVD) in aerial images that\nenables the characterization of new objects beyond training categories on the\nearth surface without annotating training images for these new categories. The\nperformance of OVD depends on the quality of class-agnostic region proposals\nand pseudo-labels that can generalize well to novel object categories. To\nsimultaneously generate high-quality proposals and pseudo-labels, we propose\nCastDet, a CLIP-activated student-teacher open-vocabulary object Detection\nframework. Our end-to-end framework within the student-teacher mechanism\nemploys the CLIP model as an extra omniscient teacher of rich knowledge into\nthe student-teacher self-learning process. By doing so, our approach boosts\nnovel object proposals and classification. Furthermore, we design a dynamic\nlabel queue technique to maintain high-quality pseudo labels during batch\ntraining and mitigate label imbalance. We conduct extensive experiments on\nmultiple existing aerial object detection datasets, which are set up for the\nOVD task. Experimental results demonstrate our CastDet achieving superior\nopen-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean),\nwhich outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD\ndataset.\n",
                "链接": "https://arxiv.org/abs/2311.11646"
            },
            {
                "文章ID": "11160",
                "标题": "Open-Vocabulary DETR with Conditional Matching",
                "作者": " Yuhang Zang,  Wei Li,  Kaiyang Zhou,  Chen Huang,  Chen Change Loy",
                "发布日期": "2022-12-01",
                "摘要": "  Open-vocabulary object detection, which is concerned with the problem of\ndetecting novel objects guided by natural language, has gained increasing\nattention from the community. Ideally, we would like to extend an\nopen-vocabulary detector such that it can produce bounding box predictions\nbased on user inputs in form of either natural language or exemplar image. This\noffers great flexibility and user experience for human-computer interaction. To\nthis end, we propose a novel open-vocabulary detector based on DETR -- hence\nthe name OV-DETR -- which, once trained, can detect any object given its class\nname or an exemplar image. The biggest challenge of turning DETR into an\nopen-vocabulary detector is that it is impossible to calculate the\nclassification cost matrix of novel classes without access to their labeled\nimages. To overcome this challenge, we formulate the learning objective as a\nbinary matching one between input queries (class name or exemplar image) and\nthe corresponding objects, which learns useful correspondence to generalize to\nunseen queries during testing. For training, we choose to condition the\nTransformer decoder on the input embeddings obtained from a pre-trained\nvision-language model like CLIP, in order to enable matching for both text and\nimage queries. With extensive experiments on LVIS and COCO datasets, we\ndemonstrate that our OV-DETR -- the first end-to-end Transformer-based\nopen-vocabulary detector -- achieves non-trivial improvements over current\nstate of the arts.\n",
                "链接": "https://arxiv.org/abs/2203.11876"
            },
            {
                "文章ID": "57961",
                "标题": "OvarNet: Towards Open-vocabulary Object Attribute Recognition",
                "作者": " Keyan Chen,  Xiaolong Jiang,  Yao Hu,  Xu Tang,  Yan Gao,  Jianqi Chen,  Weidi Xie",
                "发布日期": "2023-01-24",
                "摘要": "  In this paper, we consider the problem of simultaneously detecting objects\nand inferring their visual attributes in an image, even for those with no\nmanual annotations provided at the training stage, resembling an\nopen-vocabulary scenario. To achieve this goal, we make the following\ncontributions: (i) we start with a naive two-stage approach for open-vocabulary\nobject detection and attribute classification, termed CLIP-Attr. The candidate\nobjects are first proposed with an offline RPN and later classified for\nsemantic category and attributes; (ii) we combine all available datasets and\ntrain with a federated strategy to finetune the CLIP model, aligning the visual\nrepresentation with attributes, additionally, we investigate the efficacy of\nleveraging freely available online image-caption pairs under weakly supervised\nlearning; (iii) in pursuit of efficiency, we train a Faster-RCNN type model\nend-to-end with knowledge distillation, that performs class-agnostic object\nproposals and classification on semantic categories and attributes with\nclassifiers generated from a text encoder; Finally, (iv) we conduct extensive\nexperiments on VAW, MS-COCO, LSA, and OVAD datasets, and show that recognition\nof semantic category and attributes is complementary for visual scene\nunderstanding, i.e., jointly training object detection and attributes\nprediction largely outperform existing approaches that treat the two tasks\nindependently, demonstrating strong generalization ability to novel attributes\nand categories.\n",
                "链接": "https://arxiv.org/abs/2301.09506"
            },
            {
                "文章ID": "68353",
                "标题": "CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting\n  and Anchor Pre-Matching",
                "作者": " Xiaoshi Wu,  Feng Zhu,  Rui Zhao,  Hongsheng Li",
                "发布日期": "2023-03-24",
                "摘要": "  Open-vocabulary detection (OVD) is an object detection task aiming at\ndetecting objects from novel categories beyond the base categories on which the\ndetector is trained. Recent OVD methods rely on large-scale visual-language\npre-trained models, such as CLIP, for recognizing novel objects. We identify\nthe two core obstacles that need to be tackled when incorporating these models\ninto detector training: (1) the distribution mismatch that happens when\napplying a VL-model trained on whole images to region recognition tasks; (2)\nthe difficulty of localizing objects of unseen classes. To overcome these\nobstacles, we propose CORA, a DETR-style framework that adapts CLIP for\nOpen-vocabulary detection by Region prompting and Anchor pre-matching. Region\nprompting mitigates the whole-to-region distribution gap by prompting the\nregion features of the CLIP-based region classifier. Anchor pre-matching helps\nlearning generalizable object localization by a class-aware matching mechanism.\nWe evaluate CORA on the COCO OVD benchmark, where we achieve 41.7 AP50 on novel\nclasses, which outperforms the previous SOTA by 2.4 AP50 even without resorting\nto extra training data. When extra training data is available, we train\nCORA$^+$ on both ground-truth base-category annotations and additional pseudo\nbounding box labels computed by CORA. CORA$^+$ achieves 43.1 AP50 on the COCO\nOVD benchmark and 28.1 box APr on the LVIS OVD benchmark.\n",
                "链接": "https://arxiv.org/abs/2303.13076"
            },
            {
                "文章ID": "123157",
                "标题": "Simple Image-level Classification Improves Open-vocabulary Object\n  Detection",
                "作者": " Ruohuan Fang,  Guansong Pang,  Xiao Bai",
                "发布日期": "2023-12-20",
                "摘要": "  Open-Vocabulary Object Detection (OVOD) aims to detect novel objects beyond a\ngiven set of base categories on which the detection model is trained. Recent\nOVOD methods focus on adapting the image-level pre-trained vision-language\nmodels (VLMs), such as CLIP, to a region-level object detection task via, eg.,\nregion-level knowledge distillation, regional prompt learning, or region-text\npre-training, to expand the detection vocabulary. These methods have\ndemonstrated remarkable performance in recognizing regional visual concepts,\nbut they are weak in exploiting the VLMs' powerful global scene understanding\nability learned from the billion-scale image-level text descriptions. This\nlimits their capability in detecting hard objects of small, blurred, or\noccluded appearance from novel/base categories, whose detection heavily relies\non contextual information. To address this, we propose a novel approach, namely\nSimple Image-level Classification for Context-Aware Detection Scoring\n(SIC-CADS), to leverage the superior global knowledge yielded from CLIP for\ncomplementing the current OVOD models from a global perspective. The core of\nSIC-CADS is a multi-modal multi-label recognition (MLR) module that learns the\nobject co-occurrence-based contextual information from CLIP to recognize all\npossible object categories in the scene. These image-level MLR scores can then\nbe utilized to refine the instance-level detection scores of the current OVOD\nmodels in detecting those hard objects. This is verified by extensive empirical\nresults on two popular benchmarks, OV-LVIS and OV-COCO, which show that\nSIC-CADS achieves significant and consistent improvement when combined with\ndifferent types of OVOD models. Further, SIC-CADS also improves the\ncross-dataset generalization ability on Objects365 and OpenImages. The code is\navailable at https://github.com/mala-lab/SIC-CADS.\n",
                "链接": "https://arxiv.org/abs/2312.10439"
            }
        ]
    },
    {
        "question": {
            "question": "请找到使用自蒸馏加强目标检测性能的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "65588",
                "标题": "Smooth and Stepwise Self-Distillation for Object Detection",
                "作者": " Jieren Deng,  Xin Zhou,  Hao Tian,  Zhihong Pan,  Derek Aguiar",
                "发布日期": "2023-03-10",
                "摘要": "  Distilling the structured information captured in feature maps has\ncontributed to improved results for object detection tasks, but requires\ncareful selection of baseline architectures and substantial pre-training.\nSelf-distillation addresses these limitations and has recently achieved\nstate-of-the-art performance for object detection despite making several\nsimplifying architectural assumptions. Building on this work, we propose Smooth\nand Stepwise Self-Distillation (SSSD) for object detection. Our SSSD\narchitecture forms an implicit teacher from object labels and a feature pyramid\nnetwork backbone to distill label-annotated feature maps using Jensen-Shannon\ndistance, which is smoother than distillation losses used in prior work. We\nadditionally add a distillation coefficient that is adaptively configured based\non the learning rate. We extensively benchmark SSSD against a baseline and two\nstate-of-the-art object detector architectures on the COCO dataset by varying\nthe coefficients and backbone and detector networks. We demonstrate that SSSD\nachieves higher average precision in most experimental settings, is robust to a\nwide range of coefficients, and benefits from our stepwise distillation\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2303.05015"
            },
            {
                "文章ID": "92560",
                "标题": "Spatial Self-Distillation for Object Detection with Inaccurate Bounding\n  Boxes",
                "作者": " Di Wu,  Pengfei Chen,  Xuehui Yu,  Guorong Li,  Zhenjun Han,  Jianbin Jiao",
                "发布日期": "2023-08-16",
                "摘要": "  Object detection via inaccurate bounding boxes supervision has boosted a\nbroad interest due to the expensive high-quality annotation data or the\noccasional inevitability of low annotation quality (\\eg tiny objects). The\nprevious works usually utilize multiple instance learning (MIL), which highly\ndepends on category information, to select and refine a low-quality box. Those\nmethods suffer from object drift, group prediction and part domination problems\nwithout exploring spatial information. In this paper, we heuristically propose\na \\textbf{Spatial Self-Distillation based Object Detector (SSD-Det)} to mine\nspatial information to refine the inaccurate box in a self-distillation\nfashion. SSD-Det utilizes a Spatial Position Self-Distillation \\textbf{(SPSD)}\nmodule to exploit spatial information and an interactive structure to combine\nspatial information and category information, thus constructing a high-quality\nproposal bag. To further improve the selection procedure, a Spatial Identity\nSelf-Distillation \\textbf{(SISD)} module is introduced in SSD-Det to obtain\nspatial confidence to help select the best proposals. Experiments on MS-COCO\nand VOC datasets with noisy box annotation verify our method's effectiveness\nand achieve state-of-the-art performance. The code is available at\nhttps://github.com/ucas-vg/PointTinyBenchmark/tree/SSD-Det.\n",
                "链接": "https://arxiv.org/abs/2307.12101"
            },
            {
                "文章ID": "17577",
                "标题": "Cross Domain Object Detection by Target-Perceived Dual Branch\n  Distillation",
                "作者": " Mengzhe He,  Yali Wang,  Jiaxi Wu,  Yiru Wang,  Hanqing Li,  Bo Li,  Weihao Gan,  Wei Wu,  Yu Qiao",
                "发布日期": "2022-05-04",
                "摘要": "  Cross domain object detection is a realistic and challenging task in the\nwild. It suffers from performance degradation due to large shift of data\ndistributions and lack of instance-level annotations in the target domain.\nExisting approaches mainly focus on either of these two difficulties, even\nthough they are closely coupled in cross domain object detection. To solve this\nproblem, we propose a novel Target-perceived Dual-branch Distillation (TDD)\nframework. By integrating detection branches of both source and target domains\nin a unified teacher-student learning scheme, it can reduce domain shift and\ngenerate reliable supervision effectively. In particular, we first introduce a\ndistinct Target Proposal Perceiver between two domains. It can adaptively\nenhance source detector to perceive objects in a target image, by leveraging\ntarget proposal contexts from iterative cross-attention. Afterwards, we design\na concise Dual Branch Self Distillation strategy for model training, which can\nprogressively integrate complementary object knowledge from different domains\nvia self-distillation in two branches. Finally, we conduct extensive\nexperiments on a number of widely-used scenarios in cross domain object\ndetection. The results show that our TDD significantly outperforms the\nstate-of-the-art methods on all the benchmarks. Our code and model will be\navailable at https://github.com/Feobi1999/TDD.\n",
                "链接": "https://arxiv.org/abs/2205.01291"
            },
            {
                "文章ID": "114760",
                "标题": "Object-centric Cross-modal Feature Distillation for Event-based Object\n  Detection",
                "作者": " Lei Li,  Alexander Liniger,  Mario Millhaeusler,  Vagia Tsiminaki,  Yuanyou Li,  Dengxin Dai",
                "发布日期": "2023-11-10",
                "摘要": "  Event cameras are gaining popularity due to their unique properties, such as\ntheir low latency and high dynamic range. One task where these benefits can be\ncrucial is real-time object detection. However, RGB detectors still outperform\nevent-based detectors due to the sparsity of the event data and missing visual\ndetails. In this paper, we develop a novel knowledge distillation approach to\nshrink the performance gap between these two modalities. To this end, we\npropose a cross-modality object detection distillation method that by design\ncan focus on regions where the knowledge distillation works best. We achieve\nthis by using an object-centric slot attention mechanism that can iteratively\ndecouple features maps into object-centric features and corresponding\npixel-features used for distillation. We evaluate our novel distillation\napproach on a synthetic and a real event dataset with aligned grayscale images\nas a teacher modality. We show that object-centric distillation allows to\nsignificantly improve the performance of the event-based student object\ndetector, nearly halving the performance gap with respect to the teacher.\n",
                "链接": "https://arxiv.org/abs/2311.05494"
            },
            {
                "文章ID": "14912",
                "标题": "Spatial Likelihood Voting with Self-Knowledge Distillation for Weakly\n  Supervised Object Detection",
                "作者": " Ze Chen,  Zhihang Fu,  Jianqiang Huang,  Mingyuan Tao,  Rongxin Jiang,  Xiang Tian,  Yaowu Chen,  Xian-sheng Hua",
                "发布日期": "2022-04-15",
                "摘要": "  Weakly supervised object detection (WSOD), which is an effective way to train\nan object detection model using only image-level annotations, has attracted\nconsiderable attention from researchers. However, most of the existing methods,\nwhich are based on multiple instance learning (MIL), tend to localize instances\nto the discriminative parts of salient objects instead of the entire content of\nall objects. In this paper, we propose a WSOD framework called the Spatial\nLikelihood Voting with Self-knowledge Distillation Network (SLV-SD Net). In\nthis framework, we introduce a spatial likelihood voting (SLV) module to\nconverge region proposal localization without bounding box annotations.\nSpecifically, in every iteration during training, all the region proposals in a\ngiven image act as voters voting for the likelihood of each category in the\nspatial dimensions. After dilating the alignment on the area with large\nlikelihood values, the voting results are regularized as bounding boxes, which\nare then used for the final classification and localization. Based on SLV, we\nfurther propose a self-knowledge distillation (SD) module to refine the feature\nrepresentations of the given image. The likelihood maps generated by the SLV\nmodule are used to supervise the feature learning of the backbone network,\nencouraging the network to attend to wider and more diverse areas of the image.\nExtensive experiments on the PASCAL VOC 2007/2012 and MS-COCO datasets\ndemonstrate the excellent performance of SLV-SD Net. In addition, SLV-SD Net\nproduces new state-of-the-art results on these benchmarks.\n",
                "链接": "https://arxiv.org/abs/2204.06899"
            },
            {
                "文章ID": "33013",
                "标题": "Self-Knowledge Distillation via Dropout",
                "作者": " Hyoje Lee,  Yeachan Park,  Hyun Seo,  Myungjoo Kang",
                "发布日期": "2022-08-12",
                "摘要": "  To boost the performance, deep neural networks require deeper or wider\nnetwork structures that involve massive computational and memory costs. To\nalleviate this issue, the self-knowledge distillation method regularizes the\nmodel by distilling the internal knowledge of the model itself. Conventional\nself-knowledge distillation methods require additional trainable parameters or\nare dependent on the data. In this paper, we propose a simple and effective\nself-knowledge distillation method using a dropout (SD-Dropout). SD-Dropout\ndistills the posterior distributions of multiple models through a dropout\nsampling. Our method does not require any additional trainable modules, does\nnot rely on data, and requires only simple operations. Furthermore, this simple\nmethod can be easily combined with various self-knowledge distillation\napproaches. We provide a theoretical and experimental analysis of the effect of\nforward and reverse KL-divergences in our work. Extensive experiments on\nvarious vision tasks, i.e., image classification, object detection, and\ndistribution shift, demonstrate that the proposed method can effectively\nimprove the generalization of a single network. Further experiments show that\nthe proposed method also improves calibration performance, adversarial\nrobustness, and out-of-distribution detection ability.\n",
                "链接": "https://arxiv.org/abs/2208.05642"
            },
            {
                "文章ID": "6788",
                "标题": "Self-Supervised Transformers for Unsupervised Object Discovery using\n  Normalized Cut",
                "作者": "M-PSI  Yangtao Wang, LIGM  Xi Shen, MIT CSAIL  Shell Hu, MIT CSAIL  Yuan Yuan, M-PSI  James Crowley, M-PSI  Dominique Vaufreydaz",
                "发布日期": "2022-03-25",
                "摘要": "  Transformers trained with self-supervised learning using self-distillation\nloss (DINO) have been shown to produce attention maps that highlight salient\nforeground objects. In this paper, we demonstrate a graph-based approach that\nuses the self-supervised transformer features to discover an object from an\nimage. Visual tokens are viewed as nodes in a weighted graph with edges\nrepresenting a connectivity score based on the similarity of tokens. Foreground\nobjects can then be segmented using a normalized graph-cut to group\nself-similar regions. We solve the graph-cut problem using spectral clustering\nwith generalized eigen-decomposition and show that the second smallest\neigenvector provides a cutting solution since its absolute value indicates the\nlikelihood that a token belongs to a foreground object. Despite its simplicity,\nthis approach significantly boosts the performance of unsupervised object\ndiscovery: we improve over the recent state of the art LOST by a margin of\n6.9%, 8.1%, and 8.1% respectively on the VOC07, VOC12, and COCO20K. The\nperformance can be further improved by adding a second stage class-agnostic\ndetector (CAD). Our proposed method can be easily extended to unsupervised\nsaliency detection and weakly supervised object detection. For unsupervised\nsaliency detection, we improve IoU for 4.9%, 5.2%, 12.9% on ECSSD, DUTS,\nDUT-OMRON respectively compared to previous state of the art. For weakly\nsupervised object detection, we achieve competitive performance on CUB and\nImageNet.\n",
                "链接": "https://arxiv.org/abs/2202.11539"
            },
            {
                "文章ID": "68022",
                "标题": "Efficient Feature Distillation for Zero-shot Annotation Object Detection",
                "作者": " Zhuoming Liu,  Xuefeng Hu,  Ram Nevatia",
                "发布日期": "2023-11-03",
                "摘要": "  We propose a new setting for detecting unseen objects called Zero-shot\nAnnotation object Detection (ZAD). It expands the zero-shot object detection\nsetting by allowing the novel objects to exist in the training images and\nrestricts the additional information the detector uses to novel category names.\nRecently, to detect unseen objects, large-scale vision-language models (e.g.,\nCLIP) are leveraged by different methods. The distillation-based methods have\ngood overall performance but suffer from a long training schedule caused by two\nfactors. First, existing work creates distillation regions biased to the base\ncategories, which limits the distillation of novel category information.\nSecond, directly using the raw feature from CLIP for distillation neglects the\ndomain gap between the training data of CLIP and the detection datasets, which\nmakes it difficult to learn the mapping from the image region to the\nvision-language feature space. To solve these problems, we propose Efficient\nfeature distillation for Zero-shot Annotation object Detection (EZAD). Firstly,\nEZAD adapts the CLIP's feature space to the target detection domain by\nre-normalizing CLIP; Secondly, EZAD uses CLIP to generate distillation\nproposals with potential novel category names to avoid the distillation being\noverly biased toward the base categories. Finally, EZAD takes advantage of\nsemantic meaning for regression to further improve the model performance. As a\nresult, EZAD outperforms the previous distillation-based methods in COCO by 4%\nwith a much shorter training schedule and achieves a 3% improvement on the LVIS\ndataset. Our code is available at https://github.com/dragonlzm/EZAD\n",
                "链接": "https://arxiv.org/abs/2303.12145"
            },
            {
                "文章ID": "11255",
                "标题": "Scale-Equivalent Distillation for Semi-Supervised Object Detection",
                "作者": " Qiushan Guo,  Yao Mu,  Jianyu Chen,  Tianqi Wang,  Yizhou Yu,  Ping Luo",
                "发布日期": "2022-03-29",
                "摘要": "  Recent Semi-Supervised Object Detection (SS-OD) methods are mainly based on\nself-training, i.e., generating hard pseudo-labels by a teacher model on\nunlabeled data as supervisory signals. Although they achieved certain success,\nthe limited labeled data in semi-supervised learning scales up the challenges\nof object detection. We analyze the challenges these methods meet with the\nempirical experiment results. We find that the massive False Negative samples\nand inferior localization precision lack consideration. Besides, the large\nvariance of object sizes and class imbalance (i.e., the extreme ratio between\nbackground and object) hinder the performance of prior arts. Further, we\novercome these challenges by introducing a novel approach, Scale-Equivalent\nDistillation (SED), which is a simple yet effective end-to-end knowledge\ndistillation framework robust to large object size variance and class\nimbalance. SED has several appealing benefits compared to the previous works.\n(1) SED imposes a consistency regularization to handle the large scale variance\nproblem. (2) SED alleviates the noise problem from the False Negative samples\nand inferior localization precision. (3) A re-weighting strategy can implicitly\nscreen the potential foreground regions of the unlabeled data to reduce the\neffect of class imbalance. Extensive experiments show that SED consistently\noutperforms the recent state-of-the-art methods on different datasets with\nsignificant margins. For example, it surpasses the supervised counterpart by\nmore than 10 mAP when using 5% and 10% labeled data on MS-COCO.\n",
                "链接": "https://arxiv.org/abs/2203.12244"
            },
            {
                "文章ID": "9204",
                "标题": "Prediction-Guided Distillation for Dense Object Detection",
                "作者": " Chenhongyi Yang,  Mateusz Ochal,  Amos Storkey,  Elliot J. Crowley",
                "发布日期": "2022-07-19",
                "摘要": "  Real-world object detection models should be cheap and accurate. Knowledge\ndistillation (KD) can boost the accuracy of a small, cheap detection model by\nleveraging useful information from a larger teacher model. However, a key\nchallenge is identifying the most informative features produced by the teacher\nfor distillation. In this work, we show that only a very small fraction of\nfeatures within a ground-truth bounding box are responsible for a teacher's\nhigh detection performance. Based on this, we propose Prediction-Guided\nDistillation (PGD), which focuses distillation on these key predictive regions\nof the teacher and yields considerable gains in performance over many existing\nKD baselines. In addition, we propose an adaptive weighting scheme over the key\nregions to smooth out their influence and achieve even better performance. Our\nproposed approach outperforms current state-of-the-art KD baselines on a\nvariety of advanced one-stage detection architectures. Specifically, on the\nCOCO dataset, our method achieves between +3.1% and +4.6% AP improvement using\nResNet-101 and ResNet-50 as the teacher and student backbones, respectively. On\nthe CrowdHuman dataset, we achieve +3.2% and +2.0% improvements in MR and AP,\nalso using these backbones. Our code is available at\nhttps://github.com/ChenhongyiYang/PGD.\n",
                "链接": "https://arxiv.org/abs/2203.05469"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用2020年以后CONLL 2004数据集进行NER评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "54351",
                "标题": "Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?",
                "作者": " Shuheng Liu,  Alan Ritter",
                "发布日期": "2023-07-13",
                "摘要": "  The CoNLL-2003 English named entity recognition (NER) dataset has been widely\nused to train and evaluate NER models for almost 20 years. However, it is\nunclear how well models that are trained on this 20-year-old data and developed\nover a period of decades using the same test set will perform when applied on\nmodern data. In this paper, we evaluate the generalization of over 20 different\nmodels trained on CoNLL-2003, and show that NER models have very different\ngeneralization. Surprisingly, we find no evidence of performance degradation in\npre-trained Transformers, such as RoBERTa and T5, even when fine-tuned using\ndecades-old data. We investigate why some models generalize well to new data\nwhile others do not, and attempt to disentangle the effects of temporal drift\nand overfitting due to test reuse. Our analysis suggests that most\ndeterioration is due to temporal mismatch between the pre-training corpora and\nthe downstream test sets. We found that four factors are important for good\ngeneralization: model architecture, number of parameters, time period of the\npre-training corpus, in addition to the amount of fine-tuning data. We suggest\ncurrent evaluation methods have, in some sense, underestimated progress on NER\nover the past 20 years, as NER models have not only improved on the original\nCoNLL-2003 test set, but improved even more on modern data. Our datasets can be\nfound at https://github.com/ShuhengL/acl2023_conllpp.\n",
                "链接": "https://arxiv.org/abs/2212.09747"
            },
            {
                "文章ID": "46217",
                "标题": "Recognizing Nested Entities from Flat Supervision: A New NER Subtask,\n  Feasibility and Challenges",
                "作者": " Enwei Zhu,  Yiyang Liu,  Ming Jin,  Jinpeng Li",
                "发布日期": "2022-11-02",
                "摘要": "  Many recent named entity recognition (NER) studies criticize flat NER for its\nnon-overlapping assumption, and switch to investigating nested NER. However,\nexisting nested NER models heavily rely on training data annotated with nested\nentities, while labeling such data is costly. This study proposes a new\nsubtask, nested-from-flat NER, which corresponds to a realistic application\nscenario: given data annotated with flat entities only, one may still desire\nthe trained model capable of recognizing nested entities. To address this task,\nwe train span-based models and deliberately ignore the spans nested inside\nlabeled entities, since these spans are possibly unlabeled entities. With\nnested entities removed from the training data, our model achieves 54.8%, 54.2%\nand 41.1% F1 scores on the subset of spans within entities on ACE 2004, ACE\n2005 and GENIA, respectively. This suggests the effectiveness of our approach\nand the feasibility of the task. In addition, the model's performance on flat\nentities is entirely unaffected. We further manually annotate the nested\nentities in the test set of CoNLL 2003, creating a nested-from-flat NER\nbenchmark. Analysis results show that the main challenges stem from the data\nand annotation inconsistencies between the flat and nested entities.\n",
                "链接": "https://arxiv.org/abs/2211.00301"
            },
            {
                "文章ID": "50504",
                "标题": "Finetuning BERT on Partially Annotated NER Corpora",
                "作者": " Viktor Scherbakov,  Vladimir Mayorov",
                "发布日期": "2022-11-29",
                "摘要": "  Most Named Entity Recognition (NER) models operate under the assumption that\ntraining datasets are fully labelled. While it is valid for established\ndatasets like CoNLL 2003 and OntoNotes, sometimes it is not feasible to obtain\nthe complete dataset annotation. These situations may occur, for instance,\nafter selective annotation of entities for cost reduction. This work presents\nan approach to finetuning BERT on such partially labelled datasets using\nself-supervision and label preprocessing. Our approach outperforms the previous\nLSTM-based label preprocessing baseline, significantly improving the\nperformance on poorly labelled datasets. We demonstrate that following our\napproach while finetuning RoBERTa on CoNLL 2003 dataset with only 10% of total\nentities labelled is enough to reach the performance of the baseline trained on\nthe same dataset with 50% of the entities labelled.\n",
                "链接": "https://arxiv.org/abs/2211.14360"
            },
            {
                "文章ID": "10782",
                "标题": "Leveraging Expert Guided Adversarial Augmentation For Improving\n  Generalization in Named Entity Recognition",
                "作者": " Aaron Reich,  Jiaao Chen,  Aastha Agrawal,  Yanzhe Zhang,  Diyi Yang",
                "发布日期": "2022-03-22",
                "摘要": "  Named Entity Recognition (NER) systems often demonstrate great performance on\nin-distribution data, but perform poorly on examples drawn from a shifted\ndistribution. One way to evaluate the generalization ability of NER models is\nto use adversarial examples, on which the specific variations associated with\nnamed entities are rarely considered. To this end, we propose leveraging\nexpert-guided heuristics to change the entity tokens and their surrounding\ncontexts thereby altering their entity types as adversarial attacks. Using\nexpert-guided heuristics, we augmented the CoNLL 2003 test set and manually\nannotated it to construct a high-quality challenging set. We found that\nstate-of-the-art NER systems trained on CoNLL 2003 training data drop\nperformance dramatically on our challenging set. By training on adversarial\naugmented training examples and using mixup for regularization, we were able to\nsignificantly improve the performance on the challenging set as well as improve\nout-of-domain generalization which we evaluated by using OntoNotes data. We\nhave publicly released our dataset and code at\nhttps://github.com/GT-SALT/Guided-Adversarial-Augmentation.\n",
                "链接": "https://arxiv.org/abs/2203.10693"
            },
            {
                "文章ID": "29132",
                "标题": "A Simple Adaptive Procedure Converging to Forgiving Correlated\n  Equilibria",
                "作者": " Hugh Zhang",
                "发布日期": "2022-07-15",
                "摘要": "  Simple adaptive procedures that converge to correlated equilibria are known\nto exist for normal form games (Hart and Mas-Colell 2000), but no such analogue\nexists for extensive-form games. Leveraging inspiration from Zinkevich et al.\n(2008), we show that any internal regret minimization procedure designed for\nnormal-form games can be efficiently extended to finite extensive-form games of\nperfect recall. Our procedure converges to the set of forgiving correlated\nequilibria, a refinement of various other proposed extensions of the correlated\nequilibrium solution concept to extensive-form games (Forges 1986a; Forges\n1986b; von Stengel and Forges 2008). In a forgiving correlated equilibrium,\nplayers receive move recommendations only upon reaching the relevant\ninformation set instead of all at once at the beginning of the game. Assuming\nall other players follow their recommendations, each player is incentivized to\nfollow her recommendations regardless of whether she has done so at previous\ninfosets. The resulting procedure is completely decentralized: players need\nneither knowledge of their opponents' actions nor even a complete understanding\nof the game itself beyond their own payoffs and strategies.\n",
                "链接": "https://arxiv.org/abs/2207.06548"
            },
            {
                "文章ID": "12159",
                "标题": "Federated Named Entity Recognition",
                "作者": " Joel Mathew,  Dimitris Stripelis,  José Luis Ambite",
                "发布日期": "2022-03-30",
                "摘要": "  We present an analysis of the performance of Federated Learning in a\nparadigmatic natural-language processing task: Named-Entity Recognition (NER).\nFor our evaluation, we use the language-independent CoNLL-2003 dataset as our\nbenchmark dataset and a Bi-LSTM-CRF model as our benchmark NER model. We show\nthat federated training reaches almost the same performance as the centralized\nmodel, though with some performance degradation as the learning environments\nbecome more heterogeneous. We also show the convergence rate of federated\nmodels for NER. Finally, we discuss existing challenges of Federated Learning\nfor NLP applications that can foster future research directions.\n",
                "链接": "https://arxiv.org/abs/2203.15101"
            },
            {
                "文章ID": "41264",
                "标题": "Detecting Label Errors in Token Classification Data",
                "作者": " Wei-Chen Wang,  Jonas Mueller",
                "发布日期": "2022-10-24",
                "摘要": "  Mislabeled examples are a common issue in real-world data, particularly for\ntasks like token classification where many labels must be chosen on a\nfine-grained basis. Here we consider the task of finding sentences that contain\nlabel errors in token classification datasets. We study 11 different\nstraightforward methods that score tokens/sentences based on the predicted\nclass probabilities output by a (any) token classification model (trained via\nany procedure). In precision-recall evaluations based on real-world label\nerrors in entity recognition data from CoNLL-2003, we identify a simple and\neffective method that consistently detects those sentences containing label\nerrors when applied with different token classification models.\n",
                "链接": "https://arxiv.org/abs/2210.03920"
            },
            {
                "文章ID": "62353",
                "标题": "Exploring the Potential of Machine Translation for Generating Named\n  Entity Datasets: A Case Study between Persian and English",
                "作者": " Amir Sartipi,  Afsaneh Fatemi",
                "发布日期": "2023-06-07",
                "摘要": "  This study focuses on the generation of Persian named entity datasets through\nthe application of machine translation on English datasets. The generated\ndatasets were evaluated by experimenting with one monolingual and one\nmultilingual transformer model. Notably, the CoNLL 2003 dataset has achieved\nthe highest F1 score of 85.11%. In contrast, the WNUT 2017 dataset yielded the\nlowest F1 score of 40.02%. The results of this study highlight the potential of\nmachine translation in creating high-quality named entity recognition datasets\nfor low-resource languages like Persian. The study compares the performance of\nthese generated datasets with English named entity recognition systems and\nprovides insights into the effectiveness of machine translation for this task.\nAdditionally, this approach could be used to augment data in low-resource\nlanguage or create noisy data to make named entity systems more robust and\nimprove them.\n",
                "链接": "https://arxiv.org/abs/2302.09611"
            },
            {
                "文章ID": "73488",
                "标题": "IXA/Cogcomp at SemEval-2023 Task 2: Context-enriched Multilingual Named\n  Entity Recognition using Knowledge Bases",
                "作者": " Iker García-Ferrero,  Jon Ander Campos,  Oscar Sainz,  Ander Salaberria,  Dan Roth",
                "发布日期": "2023-05-01",
                "摘要": "  Named Entity Recognition (NER) is a core natural language processing task in\nwhich pre-trained language models have shown remarkable performance. However,\nstandard benchmarks like CoNLL 2003 do not address many of the challenges that\ndeployed NER systems face, such as having to classify emerging or complex\nentities in a fine-grained way. In this paper we present a novel NER cascade\napproach comprising three steps: first, identifying candidate entities in the\ninput sentence; second, linking the each candidate to an existing knowledge\nbase; third, predicting the fine-grained category for each entity candidate. We\nempirically demonstrate the significance of external knowledge bases in\naccurately classifying fine-grained and emerging entities. Our system exhibits\nrobust performance in the MultiCoNER2 shared task, even in the low-resource\nlanguage setting where we leverage knowledge bases of high-resource languages.\n",
                "链接": "https://arxiv.org/abs/2304.10637"
            },
            {
                "文章ID": "9599",
                "标题": "WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named\n  Entity Recognition",
                "作者": " Renjie Zhou,  Qiang Hu,  Jian Wan,  Jilin Zhang,  Qiang Liu,  Tianxiang Hu,  Jianjun Li",
                "发布日期": "2022-08-16",
                "摘要": "  Named Entity Recognition task is one of the core tasks of information\nextraction. Word ambiguity and word abbreviation are important reasons for the\nlow recognition rate of named entities. In this paper, we propose a novel named\nentity recognition model WCL-BBCD (Word Contrastive Learning with\nBERT-BiLSTM-CRF-DBpedia), which incorporates the idea of contrastive learning.\nThe model first trains the sentence pairs in the text, calculate similarity\nbetween sentence pairs, and fine-tunes BERT used for the named entity\nrecognition task according to the similarity, so as to alleviate word\nambiguity. Then, the fine-tuned BERT is combined with BiLSTM-CRF to perform the\nnamed entity recognition task. Finally, the recognition results are corrected\nin combination with prior knowledge such as knowledge graphs, so as to\nalleviate the low-recognition-rate problem caused by word abbreviations. The\nresults of experimentals conducted on the CoNLL-2003 English dataset and\nOntoNotes V5 English dataset show that our model outperforms other similar\nmodels on.\n",
                "链接": "https://arxiv.org/abs/2203.06925"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用机器学习方法进行心理健康疾病研究的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "92064",
                "标题": "Technology in Association With Mental Health: Meta-ethnography",
                "作者": " Hamza Mohammed",
                "发布日期": "2023-07-28",
                "摘要": "  This research paper presents a meta-analysis of the multifaceted role of\ntechnology in mental health. The pervasive influence of technology on daily\nlives necessitates a deep understanding of its impact on mental health\nservices. This study synthesizes literature covering Behavioral Intervention\nTechnologies (BITs), digital mental health interventions during COVID-19, young\nmen's attitudes toward mental health technologies, technology-based\ninterventions for university students, and the applicability of mobile health\ntechnologies for individuals with serious mental illnesses. BITs are recognized\nfor their potential to provide evidence-based interventions for mental health\nconditions, especially anxiety disorders. The COVID-19 pandemic acted as a\ncatalyst for the adoption of digital mental health services, underscoring their\ncrucial role in providing accessible and quality care; however, their efficacy\nneeds to be reinforced by workforce training, high-quality evidence, and\ndigital equity. A nuanced understanding of young men's attitudes toward mental\nhealth is imperative for devising effective online services. Technology-based\ninterventions for university students are promising, although variable in\neffectiveness; their deployment must be evidence-based and tailored to\nindividual needs. Mobile health technologies, particularly activity tracking,\nhold promise for individuals with serious mental illnesses. Collectively,\ntechnology has immense potential to revolutionize mental health care. However,\nthe implementation must be evidence-based, ethical, and equitable, with\ncontinued research focusing on experiences across diverse populations, ensuring\naccessibility and efficacy for all.\n",
                "链接": "https://arxiv.org/abs/2307.10513"
            },
            {
                "文章ID": "115954",
                "标题": "PsyEval: A Comprehensive Large Language Model Evaluation Benchmark for\n  Mental Health",
                "作者": " Haoan Jin,  Siyuan Chen,  Mengyue Wu,  Kenny Q. Zhu",
                "发布日期": "2023-11-16",
                "摘要": "  Recently, there has been a growing interest in utilizing large language\nmodels (LLMs) in mental health research, with studies showcasing their\nremarkable capabilities, such as disease detection. However, there is currently\na lack of a comprehensive benchmark for evaluating the capability of LLMs in\nthis domain. Therefore, we address this gap by introducing the first\ncomprehensive benchmark tailored to the unique characteristics of the mental\nhealth domain. This benchmark encompasses a total of six sub-tasks, covering\nthree dimensions, to systematically assess the capabilities of LLMs in the\nrealm of mental health. We have designed corresponding concise prompts for each\nsub-task. And we comprehensively evaluate a total of eight advanced LLMs using\nour benchmark. Experiment results not only demonstrate significant room for\nimprovement in current LLMs concerning mental health but also unveil potential\ndirections for future model optimization.\n",
                "链接": "https://arxiv.org/abs/2311.09189"
            },
            {
                "文章ID": "75054",
                "标题": "SMILE: Single-turn to Multi-turn Inclusive Language Expansion via\n  ChatGPT for Mental Health Support",
                "作者": " Huachuan Qiu,  Hongliang He,  Shuai Zhang,  Anqi Li,  Zhenzhong Lan",
                "发布日期": "2023-05-02",
                "摘要": "  There has been an increasing research interest in developing specialized\ndialogue systems that can offer mental health support. However, gathering\nlarge-scale and real-life multi-turn conversations for mental health support\nposes challenges due to the sensitivity of personal information, as well as the\ntime and cost involved. To address these issues, we introduce the SMILE\napproach, an inclusive language expansion technique that employs ChatGPT to\nextend public single-turn dialogues into multi-turn ones. Our research first\npresents a preliminary exploratory study that validates the effectiveness of\nthe SMILE approach. Furthermore, we conduct a comprehensive and systematic\ncontrastive analysis of datasets generated with and without the SMILE approach,\ndemonstrating that the SMILE method results in a large-scale, diverse, and\nclose-to-real-life multi-turn mental health support conversation corpus,\nincluding dialog topics, lexical and semantic features. Finally, we use the\ncollected corpus (SMILECHAT) to develop a more effective dialogue system that\noffers emotional support and constructive suggestions in multi-turn\nconversations for mental health support.\n",
                "链接": "https://arxiv.org/abs/2305.00450"
            },
            {
                "文章ID": "51957",
                "标题": "Topic Modeling on Clinical Social Work Notes for Exploring Social\n  Determinants of Health Factors",
                "作者": " Shenghuan Sun,  Travis Zack,  Madhumita Sushil,  Atul J. Butte",
                "发布日期": "2022-12-06",
                "摘要": "  Most research studying social determinants of health (SDoH) has focused on\nphysician notes or structured elements of the electronic medical record (EMR).\nWe hypothesize that clinical notes from social workers, whose role is to\nameliorate social and economic factors, might provide a richer source of data\non SDoH. We sought to perform topic modeling to identify robust topics of\ndiscussion within a large cohort of social work notes. We retrieved a diverse,\ndeidentified corpus of 0.95 million clinical social work notes from 181,644\npatients at the University of California, San Francisco. We used word frequency\nanalysis and Latent Dirichlet Allocation (LDA) topic modeling analysis to\ncharacterize this corpus and identify potential topics of discussion. Word\nfrequency analysis identified both medical and non-medical terms associated\nwith specific ICD10 chapters. The LDA topic modeling analysis extracted 11\ntopics related to social determinants of health risk factors including\nfinancial status, abuse history, social support, risk of death, and mental\nhealth. In addition, the topic modeling approach captured the variation between\ndifferent types of social work notes and across patients with different types\nof diseases or conditions. We demonstrated that social work notes contain rich,\nunique, and otherwise unobtainable information on an individual's SDoH.\n",
                "链接": "https://arxiv.org/abs/2212.01462"
            },
            {
                "文章ID": "87191",
                "标题": "Precision psychiatry: predicting predictability",
                "作者": " Edwin van Dellen",
                "发布日期": "2023-06-23",
                "摘要": "  Precision psychiatry is an ermerging field that aims to provide\nindividualized approaches to mental health care. Multivariate analysis and\nmachine learning are used to create outcome prediction models based on clinical\ndata such as demographics, symptom assessments, genetic information, and brain\nimaging. While much emphasis has been placed on technical innovation, the\ncomplex and varied nature of mental health presents significant challenges to\nthe successful implementation of these models. From this perspective, I review\nten challenges in the field of precision psychiatry, including the need for\nstudies on real-world populations and realistic clinical outcome definitions,\nconsideration of treatment-related factors such as placebo effects and\nnon-adherence to prescriptions. Fairness, prospective validation in comparison\nto current practice and implementation studies of prediction models are other\nkey issues that are currently understudied. A shift is proposed from\nretrospective studies based on linear and static concepts of disease towards\nprospective research that considers the importance of contextual factors and\nthe dynamic and complex nature of mental health.\n",
                "链接": "https://arxiv.org/abs/2306.12462"
            },
            {
                "文章ID": "104767",
                "标题": "Identifying Risk Factors for Post-COVID-19 Mental Health Disorders: A\n  Machine Learning Perspective",
                "作者": " Maitham G. Yousif,  Fadhil G. Al-Amran,  Hector J. Castro",
                "发布日期": "2023-09-29",
                "摘要": "  In this study, we leveraged machine learning techniques to identify risk\nfactors associated with post-COVID-19 mental health disorders. Our analysis,\nbased on data collected from 669 patients across various provinces in Iraq,\nyielded valuable insights. We found that age, gender, and geographical region\nof residence were significant demographic factors influencing the likelihood of\ndeveloping mental health disorders in post-COVID-19 patients. Additionally,\ncomorbidities and the severity of COVID-19 illness were important clinical\npredictors. Psychosocial factors, such as social support, coping strategies,\nand perceived stress levels, also played a substantial role. Our findings\nemphasize the complex interplay of multiple factors in the development of\nmental health disorders following COVID-19 recovery. Healthcare providers and\npolicymakers should consider these risk factors when designing targeted\ninterventions and support systems for individuals at risk. Machine\nlearning-based approaches can provide a valuable tool for predicting and\npreventing adverse mental health outcomes in post-COVID-19 patients. Further\nresearch and prospective studies are needed to validate these findings and\nenhance our understanding of the long-term psychological impact of the COVID-19\npandemic. This study contributes to the growing body of knowledge regarding the\nmental health consequences of the COVID-19 pandemic and underscores the\nimportance of a multidisciplinary approach to address the diverse needs of\nindividuals on the path to recovery. Keywords: COVID-19, mental health, risk\nfactors, machine learning, Iraq\n",
                "链接": "https://arxiv.org/abs/2309.16055"
            },
            {
                "文章ID": "54359",
                "标题": "Exploring Hybrid and Ensemble Models for Multiclass Prediction of Mental\n  Health Status on Social Media",
                "作者": " Sourabh Zanwar,  Daniel Wiechmann,  Yu Qiao,  Elma Kerz",
                "发布日期": "2022-12-21",
                "摘要": "  In recent years, there has been a surge of interest in research on automatic\nmental health detection (MHD) from social media data leveraging advances in\nnatural language processing and machine learning techniques. While significant\nprogress has been achieved in this interdisciplinary research area, the vast\nmajority of work has treated MHD as a binary classification task. The\nmulticlass classification setup is, however, essential if we are to uncover the\nsubtle differences among the statistical patterns of language use associated\nwith particular mental health conditions. Here, we report on experiments aimed\nat predicting six conditions (anxiety, attention deficit hyperactivity\ndisorder, bipolar disorder, post-traumatic stress disorder, depression, and\npsychological stress) from Reddit social media posts. We explore and compare\nthe performance of hybrid and ensemble models leveraging transformer-based\narchitectures (BERT and RoBERTa) and BiLSTM neural networks trained on\nwithin-text distributions of a diverse set of linguistic features. This set\nencompasses measures of syntactic complexity, lexical sophistication and\ndiversity, readability, and register-specific ngram frequencies, as well as\nsentiment and emotion lexicons. In addition, we conduct feature ablation\nexperiments to investigate which types of features are most indicative of\nparticular mental health conditions.\n",
                "链接": "https://arxiv.org/abs/2212.09839"
            },
            {
                "文章ID": "37090",
                "标题": "Acoustic-Linguistic Features for Modeling Neurological Task Score in\n  Alzheimer's",
                "作者": " Saurav K. Aryal,  Howard Prioleau,  Legand Burge",
                "发布日期": "2022-09-14",
                "摘要": "  The average life expectancy is increasing globally due to advancements in\nmedical technology, preventive health care, and a growing emphasis on\ngerontological health. Therefore, developing technologies that detect and track\naging-associated disease in cognitive function among older adult populations is\nimperative. In particular, research related to automatic detection and\nevaluation of Alzheimer's disease (AD) is critical given the disease's\nprevalence and the cost of current methods. As AD impacts the acoustics of\nspeech and vocabulary, natural language processing and machine learning provide\npromising techniques for reliably detecting AD. We compare and contrast the\nperformance of ten linear regression models for predicting Mini-Mental Status\nExam scores on the ADReSS challenge dataset. We extracted 13000+ handcrafted\nand learned features that capture linguistic and acoustic phenomena. Using a\nsubset of 54 top features selected by two methods: (1) recursive elimination\nand (2) correlation scores, we outperform a state-of-the-art baseline for the\nsame task. Upon scoring and evaluating the statistical significance of each of\nthe selected subset of features for each model, we find that, for the given\ntask, handcrafted linguistic features are more significant than acoustic and\nlearned features.\n",
                "链接": "https://arxiv.org/abs/2209.06085"
            },
            {
                "文章ID": "105887",
                "标题": "Designing User-Centric Behavioral Interventions to Prevent Dysglycemia\n  with Novel Counterfactual Explanations",
                "作者": " Asiful Arefeen,  Hassan Ghasemzadeh",
                "发布日期": "2023-10-04",
                "摘要": "  Maintaining normal blood glucose levels through lifestyle behaviors is\ncentral to maintaining health and preventing disease. Frequent exposure to\ndysglycemia (i.e., abnormal glucose events such as hyperlycemia and\nhypoglycemia) leads to chronic complications including diabetes, kidney disease\nand need for dialysis, myocardial infarction, stroke, amputation, and death.\nTherefore, a tool capable of predicting dysglycemia and offering users\nactionable feedback about how to make changes in their diet, exercise, and\nmedication to prevent abnormal glycemic events could have significant societal\nimpacts. Counterfactual explanations can provide insights into why a model made\na particular prediction by generating hypothetical instances that are similar\nto the original input but lead to a different prediction outcome. Therefore,\ncounterfactuals can be viewed as a means to design AI-driven health\ninterventions to prevent adverse health outcomes such as dysglycemia. In this\npaper, we design GlyCoach, a framework for generating counterfactual\nexplanations for glucose control. Leveraging insights from adversarial\nlearning, GlyCoach characterizes the decision boundary for high-dimensional\nhealth data and performs a grid search to generate actionable interventions.\nGlyCoach is unique in integrating prior knowledge about user preferences of\nplausible explanations into the process of counterfactual generation. We\nevaluate GlyCoach extensively using two real-world datasets and external\nsimulators from prior studies that predict glucose response. GlyCoach achieves\n87\\% sensitivity in the simulation-aided validation, surpassing the\nstate-of-the-art techniques for generating counterfactual explanations by at\nleast $10\\%$. Besides, counterfactuals from GlyCoach exhibit a $32\\%$ improved\nnormalized distance compared to previous research.\n",
                "链接": "https://arxiv.org/abs/2310.01684"
            },
            {
                "文章ID": "112016",
                "标题": "Using Adaptive Bandit Experiments to Increase and Investigate Engagement\n  in Mental Health",
                "作者": " Harsh Kumar,  Tong Li,  Jiakai Shi,  Ilya Musabirov,  Rachel Kornfield,  Jonah Meyerhoff,  Ananya Bhattacharjee,  Chris Karr,  Theresa Nguyen,  David Mohr,  Anna Rafferty,  Sofia Villar,  Nina Deliu,  Joseph Jay Williams",
                "发布日期": "2023-10-31",
                "摘要": "  Digital mental health (DMH) interventions, such as text-message-based lessons\nand activities, offer immense potential for accessible mental health support.\nWhile these interventions can be effective, real-world experimental testing can\nfurther enhance their design and impact. Adaptive experimentation, utilizing\nalgorithms like Thompson Sampling for (contextual) multi-armed bandit (MAB)\nproblems, can lead to continuous improvement and personalization. However, it\nremains unclear when these algorithms can simultaneously increase user\nexperience rewards and facilitate appropriate data collection for\nsocial-behavioral scientists to analyze with sufficient statistical confidence.\nAlthough a growing body of research addresses the practical and statistical\naspects of MAB and other adaptive algorithms, further exploration is needed to\nassess their impact across diverse real-world contexts. This paper presents a\nsoftware system developed over two years that allows text-messaging\nintervention components to be adapted using bandit and other algorithms while\ncollecting data for side-by-side comparison with traditional uniform random\nnon-adaptive experiments. We evaluate the system by deploying a\ntext-message-based DMH intervention to 1100 users, recruited through a large\nmental health non-profit organization, and share the path forward for deploying\nthis system at scale. This system not only enables applications in mental\nhealth but could also serve as a model testbed for adaptive experimentation\nalgorithms in other domains.\n",
                "链接": "https://arxiv.org/abs/2310.18326"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "60723",
                "标题": "Adapting Pre-trained Vision Transformers from 2D to 3D through Weight\n  Inflation Improves Medical Image Segmentation",
                "作者": " Yuhui Zhang,  Shih-Cheng Huang,  Zhengping Zhou,  Matthew P. Lungren,  Serena Yeung",
                "发布日期": "2023-02-10",
                "摘要": "  Given the prevalence of 3D medical imaging technologies such as MRI and CT\nthat are widely used in diagnosing and treating diverse diseases, 3D\nsegmentation is one of the fundamental tasks of medical image analysis.\nRecently, Transformer-based models have started to achieve state-of-the-art\nperformances across many vision tasks, through pre-training on large-scale\nnatural image benchmark datasets. While works on medical image analysis have\nalso begun to explore Transformer-based models, there is currently no optimal\nstrategy to effectively leverage pre-trained Transformers, primarily due to the\ndifference in dimensionality between 2D natural images and 3D medical images.\nExisting solutions either split 3D images into 2D slices and predict each slice\nindependently, thereby losing crucial depth-wise information, or modify the\nTransformer architecture to support 3D inputs without leveraging pre-trained\nweights. In this work, we use a simple yet effective weight inflation strategy\nto adapt pre-trained Transformers from 2D to 3D, retaining the benefit of both\ntransfer learning and depth information. We further investigate the\neffectiveness of transfer from different pre-training sources and objectives.\nOur approach achieves state-of-the-art performances across a broad range of 3D\nmedical image datasets, and can become a standard strategy easily utilized by\nall work on Transformer-based models for 3D medical images, to maximize\nperformance.\n",
                "链接": "https://arxiv.org/abs/2302.04303"
            },
            {
                "文章ID": "107833",
                "标题": "A review of uncertainty quantification in medical image analysis:\n  probabilistic and non-probabilistic methods",
                "作者": " Ling Huang,  Su Ruan,  Yucheng Xing,  Mengling Feng",
                "发布日期": "2023-10-12",
                "摘要": "  The comprehensive integration of machine learning healthcare models within\nclinical practice remains suboptimal, notwithstanding the proliferation of\nhigh-performing solutions reported in the literature. A predominant factor\nhindering widespread adoption pertains to an insufficiency of evidence\naffirming the reliability of the aforementioned models. Recently, uncertainty\nquantification methods have been proposed as a potential solution to quantify\nthe reliability of machine learning models and thus increase the\ninterpretability and acceptability of the result. In this review, we offer a\ncomprehensive overview of prevailing methods proposed to quantify uncertainty\ninherent in machine learning models developed for various medical image tasks.\nContrary to earlier reviews that exclusively focused on probabilistic methods,\nthis review also explores non-probabilistic approaches, thereby furnishing a\nmore holistic survey of research pertaining to uncertainty quantification for\nmachine learning models. Analysis of medical images with the summary and\ndiscussion on medical applications and the corresponding uncertainty evaluation\nprotocols are presented, which focus on the specific challenges of uncertainty\nin medical image analysis. We also highlight some potential future research\nwork at the end. Generally, this review aims to allow researchers from both\nclinical and technical backgrounds to gain a quick and yet in-depth\nunderstanding of the research in uncertainty quantification for medical image\nanalysis machine learning models.\n",
                "链接": "https://arxiv.org/abs/2310.06873"
            },
            {
                "文章ID": "117087",
                "标题": "Overcoming Pathology Image Data Deficiency: Generating Images from\n  Pathological Transformation Process",
                "作者": " Zeyu Liu,  Yufang He,  Yu Zhao,  Yunlu Feng,  Guanglei Zhang",
                "发布日期": "2023-11-22",
                "摘要": "  Histopathology serves as the gold standard for medical diagnosis but faces\napplication limitations due to the shortage of medical resources. Leveraging\ndeep learning, computer-aided diagnosis has the potential to alleviate the\npathologist scarcity and provide timely clinical analysis. However, developing\na reliable model generally necessitates substantial data for training, which is\nchallenging in pathological field. In response, we propose an adaptive\ndepth-controlled bidirectional diffusion (ADBD) network for image data\ngeneration. The domain migration approach can work with small trainset and\novercome the diffusion overfitting by source information guidance.\nSpecifically, we developed a hybrid attention strategy to blend global and\nlocal attention priorities, which guides the bidirectional diffusion and\nensures the migration success. In addition, we developed the adaptive\ndepth-controlled strategy to simulate physiological transformations, capable of\nyielding unlimited cross-domain intermediate images with corresponding soft\nlabels. ADBD is effective for overcoming pathological image data deficiency and\nsupportable for further pathology-related research.\n",
                "链接": "https://arxiv.org/abs/2311.12316"
            },
            {
                "文章ID": "13384",
                "标题": "Exemplar Learning for Medical Image Segmentation",
                "作者": " Qing En,  Yuhong Guo",
                "发布日期": "2022-10-11",
                "摘要": "  Medical image annotation typically requires expert knowledge and hence incurs\ntime-consuming and expensive data annotation costs. To alleviate this burden,\nwe propose a novel learning scenario, Exemplar Learning (EL), to explore\nautomated learning processes for medical image segmentation with a single\nannotated image example. This innovative learning task is particularly suitable\nfor medical image segmentation, where all categories of organs can be presented\nin one single image and annotated all at once. To address this challenging EL\ntask, we propose an Exemplar Learning-based Synthesis Net (ELSNet) framework\nfor medical image segmentation that enables innovative exemplar-based data\nsynthesis, pixel-prototype based contrastive embedding learning, and\npseudo-label based exploitation of the unlabeled data. Specifically, ELSNet\nintroduces two new modules for image segmentation: an exemplar-guided synthesis\nmodule, which enriches and diversifies the training set by synthesizing\nannotated samples from the given exemplar, and a pixel-prototype based\ncontrastive embedding module, which enhances the discriminative capacity of the\nbase segmentation model via contrastive representation learning. Moreover, we\ndeploy a two-stage process for segmentation model training, which exploits the\nunlabeled data with predicted pseudo segmentation labels. To evaluate this new\nlearning framework, we conduct extensive experiments on several organ\nsegmentation datasets and present an in-depth analysis. The empirical results\nshow that the proposed exemplar learning framework produces effective\nsegmentation results.\n",
                "链接": "https://arxiv.org/abs/2204.01713"
            },
            {
                "文章ID": "117675",
                "标题": "Deep Interactive Segmentation of Medical Images: A Systematic Review and\n  Taxonomy",
                "作者": " Zdravko Marinov,  Paul F. Jäger,  Jan Egger,  Jens Kleesiek,  Rainer Stiefelhagen",
                "发布日期": "2023-11-27",
                "摘要": "  Interactive segmentation is a crucial research area in medical image analysis\naiming to boost the efficiency of costly annotations by incorporating human\nfeedback. This feedback takes the form of clicks, scribbles, or masks and\nallows for iterative refinement of the model output so as to efficiently guide\nthe system towards the desired behavior. In recent years, deep learning-based\napproaches have propelled results to a new level causing a rapid growth in the\nfield with 121 methods proposed in the medical imaging domain alone. In this\nreview, we provide a structured overview of this emerging field featuring a\ncomprehensive taxonomy, a systematic review of existing methods, and an\nin-depth analysis of current practices. Based on these contributions, we\ndiscuss the challenges and opportunities in the field. For instance, we find\nthat there is a severe lack of comparison across methods which needs to be\ntackled by standardized baselines and benchmarks.\n",
                "链接": "https://arxiv.org/abs/2311.13964"
            },
            {
                "文章ID": "96027",
                "标题": "Classification of White Blood Cells Using Machine and Deep Learning\n  Models: A Systematic Review",
                "作者": " Rabia Asghar,  Sanjay Kumar,  Paul Hynds,  Arslan Shaukat",
                "发布日期": "2023-08-22",
                "摘要": "  Machine learning (ML) and deep learning (DL) models have been employed to\nsignificantly improve analyses of medical imagery, with these approaches used\nto enhance the accuracy of prediction and classification. Model predictions and\nclassifications assist diagnoses of various cancers and tumors. This review\npresents an in-depth analysis of modern techniques applied within the domain of\nmedical image analysis for white blood cell classification. The methodologies\nthat use blood smear images, magnetic resonance imaging (MRI), X-rays, and\nsimilar medical imaging domains are identified and discussed, with a detailed\nanalysis of ML/DL techniques applied to the classification of white blood cells\n(WBCs) representing the primary focus of the review. The data utilized in this\nresearch has been extracted from a collection of 136 primary papers that were\npublished between the years 2006 and 2023. The most widely used techniques and\nbest-performing white blood cell classification methods are identified. While\nthe use of ML and DL for white blood cell classification has concurrently\nincreased and improved in recent year, significant challenges remain - 1)\nAvailability of appropriate datasets remain the primary challenge, and may be\nresolved using data augmentation techniques. 2) Medical training of researchers\nis recommended to improve current understanding of white blood cell structure\nand subsequent selection of appropriate classification models. 3) Advanced DL\nnetworks including Generative Adversarial Networks, R-CNN, Fast R-CNN, and\nfaster R-CNN will likely be increasingly employed to supplement or replace\ncurrent techniques.\n",
                "链接": "https://arxiv.org/abs/2308.06296"
            },
            {
                "文章ID": "18063",
                "标题": "Super Images -- A New 2D Perspective on 3D Medical Imaging Analysis",
                "作者": " Ikboljon Sobirov,  Numan Saeed,  Mohammad Yaqub",
                "发布日期": "2023-05-18",
                "摘要": "  In medical imaging analysis, deep learning has shown promising results. We\nfrequently rely on volumetric data to segment medical images, necessitating the\nuse of 3D architectures, which are commended for their capacity to capture\ninterslice context. However, because of the 3D convolutions, max pooling,\nup-convolutions, and other operations utilized in these networks, these\narchitectures are often more inefficient in terms of time and computation than\ntheir 2D equivalents. Furthermore, there are few 3D pretrained model weights,\nand pretraining is often difficult. We present a simple yet effective 2D method\nto handle 3D data while efficiently embedding the 3D knowledge during training.\nWe propose transforming volumetric data into 2D super images and segmenting\nwith 2D networks to solve these challenges. Our method generates a\nsuper-resolution image by stitching slices side by side in the 3D image. We\nexpect deep neural networks to capture and learn these properties spatially\ndespite losing depth information. This work aims to present a novel perspective\nwhen dealing with volumetric data, and we test the hypothesis using CNN and ViT\nnetworks as well as self-supervised pretraining. While attaining equal, if not\nsuperior, results to 3D networks utilizing only 2D counterparts, the model\ncomplexity is reduced by around threefold. Because volumetric data is\nrelatively scarce, we anticipate that our approach will entice more studies,\nparticularly in medical imaging analysis.\n",
                "链接": "https://arxiv.org/abs/2205.02847"
            },
            {
                "文章ID": "115734",
                "标题": "JOSA: Joint surface-based registration and atlas construction of brain\n  geometry and function",
                "作者": " Jian Li,  Greta Tuckute,  Evelina Fedorenko,  Brian L. Edlow,  Adrian V. Dalca,  Bruce Fischl",
                "发布日期": "2023-11-16",
                "摘要": "  Surface-based cortical registration is an important topic in medical image\nanalysis and facilitates many downstream applications. Current approaches for\ncortical registration are mainly driven by geometric features, such as sulcal\ndepth and curvature, and often assume that registration of folding patterns\nleads to alignment of brain function. However, functional variability of\nanatomically corresponding areas across subjects has been widely reported,\nparticularly in higher-order cognitive areas. In this work, we present JOSA, a\nnovel cortical registration framework that jointly models the mismatch between\ngeometry and function while simultaneously learning an unbiased\npopulation-specific atlas. Using a semi-supervised training strategy, JOSA\nachieves superior registration performance in both geometry and function to the\nstate-of-the-art methods but without requiring functional data at inference.\nThis learning framework can be extended to any auxiliary data to guide\nspherical registration that is available during training but is difficult or\nimpossible to obtain during inference, such as parcellations, architectonic\nidentity, transcriptomic information, and molecular profiles. By recognizing\nthe mismatch between geometry and function, JOSA provides new insights into the\nfuture development of registration methods using joint analysis of the brain\nstructure and function.\n",
                "链接": "https://arxiv.org/abs/2311.08544"
            },
            {
                "文章ID": "776",
                "标题": "MyoPS: A Benchmark of Myocardial Pathology Segmentation Combining\n  Three-Sequence Cardiac Magnetic Resonance Images",
                "作者": " Lei Li,  Fuping Wu,  Sihan Wang,  Xinzhe Luo,  Carlos Martin-Isla,  Shuwei Zhai,  Jianpeng Zhang,  Yanfei Liu7,  Zhen Zhang,  Markus J. Ankenbrand,  Haochuan Jiang,  Xiaoran Zhang,  Linhong Wang,  Tewodros Weldebirhan Arega,  Elif Altunok,  Zhou Zhao,  Feiyan Li,  Jun Ma,  Xiaoping Yang,  Elodie Puybareau,  Ilkay Oksuz,  Stephanie Bricq,  Weisheng Li,  Kumaradevan Punithakumar,  Sotirios A. Tsaftaris,  Laura M. Schreiber,  Mingjing Yang,  Guocai Liu,  Yong Xia,  Guotai Wang,  Sergio Escalera,  Xiahai Zhuang",
                "发布日期": "2022-01-11",
                "摘要": "  Assessment of myocardial viability is essential in diagnosis and treatment\nmanagement of patients suffering from myocardial infarction, and classification\nof pathology on myocardium is the key to this assessment. This work defines a\nnew task of medical image analysis, i.e., to perform myocardial pathology\nsegmentation (MyoPS) combining three-sequence cardiac magnetic resonance (CMR)\nimages, which was first proposed in the MyoPS challenge, in conjunction with\nMICCAI 2020. The challenge provided 45 paired and pre-aligned CMR images,\nallowing algorithms to combine the complementary information from the three CMR\nsequences for pathology segmentation. In this article, we provide details of\nthe challenge, survey the works from fifteen participants and interpret their\nmethods according to five aspects, i.e., preprocessing, data augmentation,\nlearning strategy, model architecture and post-processing. In addition, we\nanalyze the results with respect to different factors, in order to examine the\nkey obstacles and explore potential of solutions, as well as to provide a\nbenchmark for future research. We conclude that while promising results have\nbeen reported, the research is still in the early stage, and more in-depth\nexploration is needed before a successful application to the clinics. Note that\nMyoPS data and evaluation tool continue to be publicly available upon\nregistration via its homepage\n(www.sdspeople.fudan.edu.cn/zhuangxiahai/0/myops20/).\n",
                "链接": "https://arxiv.org/abs/2201.03186"
            }
        ]
    },
    {
        "question": {
            "question": "强化学习在大语言模型领域中应用的相关论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "46797",
                "标题": "A Survey on Reinforcement Learning in Aviation Applications",
                "作者": " Pouria Razzaghi,  Amin Tabrizian,  Wei Guo,  Shulu Chen,  Abenezer Taye,  Ellis Thompson,  Alexis Bregeon,  Ali Baheri,  Peng Wei",
                "发布日期": "2022-11-24",
                "摘要": "  Compared with model-based control and optimization methods, reinforcement\nlearning (RL) provides a data-driven, learning-based framework to formulate and\nsolve sequential decision-making problems. The RL framework has become\npromising due to largely improved data availability and computing power in the\naviation industry. Many aviation-based applications can be formulated or\ntreated as sequential decision-making problems. Some of them are offline\nplanning problems, while others need to be solved online and are\nsafety-critical. In this survey paper, we first describe standard RL\nformulations and solutions. Then we survey the landscape of existing RL-based\napplications in aviation. Finally, we summarize the paper, identify the\ntechnical gaps, and suggest future directions of RL research in aviation.\n",
                "链接": "https://arxiv.org/abs/2211.02147"
            },
            {
                "文章ID": "2783",
                "标题": "Hyperparameter Tuning for Deep Reinforcement Learning Applications",
                "作者": " Mariam Kiran,  Melis Ozyildirim",
                "发布日期": "2022-01-28",
                "摘要": "  Reinforcement learning (RL) applications, where an agent can simply learn\noptimal behaviors by interacting with the environment, are quickly gaining\ntremendous success in a wide variety of applications from controlling simple\npendulums to complex data centers. However, setting the right hyperparameters\ncan have a huge impact on the deployed solution performance and reliability in\nthe inference models, produced via RL, used for decision-making. Hyperparameter\nsearch itself is a laborious process that requires many iterations and\ncomputationally expensive to find the best settings that produce the best\nneural network architectures. In comparison to other neural network\narchitectures, deep RL has not witnessed much hyperparameter tuning, due to its\nalgorithm complexity and simulation platforms needed. In this paper, we propose\na distributed variable-length genetic algorithm framework to systematically\ntune hyperparameters for various RL applications, improving training time and\nrobustness of the architecture, via evolution. We demonstrate the scalability\nof our approach on many RL problems (from simple gyms to complex applications)\nand compared with Bayesian approach. Our results show that with more\ngenerations, optimal solutions that require fewer training episodes and are\ncomputationally cheap while being more robust for deployment. Our results are\nimperative to advance deep reinforcement learning controllers for real-world\nproblems.\n",
                "链接": "https://arxiv.org/abs/2201.11182"
            },
            {
                "文章ID": "26857",
                "标题": "Reinforcement Learning in Medical Image Analysis: Concepts,\n  Applications, Challenges, and Future Directions",
                "作者": " Mingzhe Hu,  Jiahan Zhang,  Luke Matkovic,  Tian Liu,  Xiaofeng Yang",
                "发布日期": "2022-06-30",
                "摘要": "  Motivation: Medical image analysis involves tasks to assist physicians in\nqualitative and quantitative analysis of lesions or anatomical structures,\nsignificantly improving the accuracy and reliability of diagnosis and\nprognosis. Traditionally, these tasks are finished by physicians or medical\nphysicists and lead to two major problems: (i) low efficiency; (ii) biased by\npersonal experience. In the past decade, many machine learning methods have\nbeen applied to accelerate and automate the image analysis process. Compared to\nthe enormous deployments of supervised and unsupervised learning models,\nattempts to use reinforcement learning in medical image analysis are scarce.\nThis review article could serve as the stepping-stone for related research.\nSignificance: From our observation, though reinforcement learning has gradually\ngained momentum in recent years, many researchers in the medical analysis field\nfind it hard to understand and deploy in clinics. One cause is lacking\nwell-organized review articles targeting readers lacking professional computer\nscience backgrounds. Rather than providing a comprehensive list of all\nreinforcement learning models in medical image analysis, this paper may help\nthe readers to learn how to formulate and solve their medical image analysis\nresearch as reinforcement learning problems. Approach & Results: We selected\npublished articles from Google Scholar and PubMed. Considering the scarcity of\nrelated articles, we also included some outstanding newest preprints. The\npapers are carefully reviewed and categorized according to the type of image\nanalysis task. We first review the basic concepts and popular models of\nreinforcement learning. Then we explore the applications of reinforcement\nlearning models in landmark detection. Finally, we conclude the article by\ndiscussing the reviewed reinforcement learning approaches' limitations and\npossible improvements.\n",
                "链接": "https://arxiv.org/abs/2206.14302"
            },
            {
                "文章ID": "20475",
                "标题": "Power and accountability in reinforcement learning applications to\n  environmental policy",
                "作者": " Melissa Chapman,  Caleb Scoville,  Marcus Lapeyrolerie,  Carl Boettiger",
                "发布日期": "2022-07-01",
                "摘要": "  Machine learning (ML) methods already permeate environmental decision-making,\nfrom processing high-dimensional data on earth systems to monitoring compliance\nwith environmental regulations. Of the ML techniques available to address\npressing environmental problems (e.g., climate change, biodiversity loss),\nReinforcement Learning (RL) may both hold the greatest promise and present the\nmost pressing perils. This paper explores how RL-driven policy refracts\nexisting power relations in the environmental domain while also creating unique\nchallenges to ensuring equitable and accountable environmental decision\nprocesses. We leverage examples from RL applications to climate change\nmitigation and fisheries management to explore how RL technologies shift the\ndistribution of power between resource users, governing bodies, and private\nindustry.\n",
                "链接": "https://arxiv.org/abs/2205.10911"
            },
            {
                "文章ID": "25667",
                "标题": "Incorporating Voice Instructions in Model-Based Reinforcement Learning\n  for Self-Driving Cars",
                "作者": " Mingze Wang,  Ziyang Zhang,  Grace Hui Yang",
                "发布日期": "2022-06-22",
                "摘要": "  This paper presents a novel approach that supports natural language voice\ninstructions to guide deep reinforcement learning (DRL) algorithms when\ntraining self-driving cars. DRL methods are popular approaches for autonomous\nvehicle (AV) agents. However, most existing methods are sample- and\ntime-inefficient and lack a natural communication channel with the human\nexpert. In this paper, how new human drivers learn from human coaches motivates\nus to study new ways of human-in-the-loop learning and a more natural and\napproachable training interface for the agents. We propose incorporating\nnatural language voice instructions (NLI) in model-based deep reinforcement\nlearning to train self-driving cars. We evaluate the proposed method together\nwith a few state-of-the-art DRL methods in the CARLA simulator. The results\nshow that NLI can help ease the training process and significantly boost the\nagents' learning speed.\n",
                "链接": "https://arxiv.org/abs/2206.10249"
            },
            {
                "文章ID": "45486",
                "标题": "Meta-Reinforcement Learning Using Model Parameters",
                "作者": " Gabriel Hartmann,  Amos Azaria",
                "发布日期": "2022-10-28",
                "摘要": "  In meta-reinforcement learning, an agent is trained in multiple different\nenvironments and attempts to learn a meta-policy that can efficiently adapt to\na new environment. This paper presents RAMP, a Reinforcement learning Agent\nusing Model Parameters that utilizes the idea that a neural network trained to\npredict environment dynamics encapsulates the environment information. RAMP is\nconstructed in two phases: in the first phase, a multi-environment\nparameterized dynamic model is learned. In the second phase, the model\nparameters of the dynamic model are used as context for the multi-environment\npolicy of the model-free reinforcement learning agent.\n",
                "链接": "https://arxiv.org/abs/2210.15515"
            },
            {
                "文章ID": "33615",
                "标题": "A Walk in the Park: Learning to Walk in 20 Minutes With Model-Free\n  Reinforcement Learning",
                "作者": " Laura Smith,  Ilya Kostrikov,  Sergey Levine",
                "发布日期": "2022-08-17",
                "摘要": "  Deep reinforcement learning is a promising approach to learning policies in\nuncontrolled environments that do not require domain knowledge. Unfortunately,\ndue to sample inefficiency, deep RL applications have primarily focused on\nsimulated environments. In this work, we demonstrate that the recent\nadvancements in machine learning algorithms and libraries combined with a\ncarefully tuned robot controller lead to learning quadruped locomotion in only\n20 minutes in the real world. We evaluate our approach on several indoor and\noutdoor terrains which are known to be challenging for classical model-based\ncontrollers. We observe the robot to be able to learn walking gait consistently\non all of these terrains. Finally, we evaluate our design decisions in a\nsimulated environment.\n",
                "链接": "https://arxiv.org/abs/2208.07860"
            },
            {
                "文章ID": "25398",
                "标题": "A Survey on Model-based Reinforcement Learning",
                "作者": " Fan-Ming Luo,  Tian Xu,  Hang Lai,  Xiong-Hui Chen,  Weinan Zhang,  Yang Yu",
                "发布日期": "2022-06-22",
                "摘要": "  Reinforcement learning (RL) solves sequential decision-making problems via a\ntrial-and-error process interacting with the environment. While RL achieves\noutstanding success in playing complex video games that allow huge\ntrial-and-error, making errors is always undesired in the real world. To\nimprove the sample efficiency and thus reduce the errors, model-based\nreinforcement learning (MBRL) is believed to be a promising direction, which\nbuilds environment models in which the trial-and-errors can take place without\nreal costs. In this survey, we take a review of MBRL with a focus on the recent\nprogress in deep RL. For non-tabular environments, there is always a\ngeneralization error between the learned environment model and the real\nenvironment. As such, it is of great importance to analyze the discrepancy\nbetween policy training in the environment model and that in the real\nenvironment, which in turn guides the algorithm design for better model\nlearning, model usage, and policy training. Besides, we also discuss the recent\nadvances of model-based techniques in other forms of RL, including offline RL,\ngoal-conditioned RL, multi-agent RL, and meta-RL. Moreover, we discuss the\napplicability and advantages of MBRL in real-world tasks. Finally, we end this\nsurvey by discussing the promising prospects for the future development of\nMBRL. We think that MBRL has great potential and advantages in real-world\napplications that were overlooked, and we hope this survey could attract more\nresearch on MBRL.\n",
                "链接": "https://arxiv.org/abs/2206.09328"
            },
            {
                "文章ID": "454",
                "标题": "Machine Learning: Algorithms, Models, and Applications",
                "作者": " Jaydip Sen,  Sidra Mehtab,  Rajdeep Sen,  Abhishek Dutta,  Pooja Kherwa,  Saheel Ahmed,  Pranay Berry,  Sahil Khurana,  Sonali Singh,  David W. W Cadotte,  David W. Anderson,  Kalum J. Ost,  Racheal S. Akinbo,  Oladunni A. Daramola,  Bongs Lainjo",
                "发布日期": "2022-01-07",
                "摘要": "  Recent times are witnessing rapid development in machine learning algorithm\nsystems, especially in reinforcement learning, natural language processing,\ncomputer and robot vision, image processing, speech, and emotional processing\nand understanding. In tune with the increasing importance and relevance of\nmachine learning models, algorithms, and their applications, and with the\nemergence of more innovative uses cases of deep learning and artificial\nintelligence, the current volume presents a few innovative research works and\ntheir applications in real world, such as stock trading, medical and healthcare\nsystems, and software automation. The chapters in the book illustrate how\nmachine learning and deep learning algorithms and models are designed,\noptimized, and deployed. The volume will be useful for advanced graduate and\ndoctoral students, researchers, faculty members of universities, practicing\ndata scientists and data engineers, professionals, and consultants working on\nthe broad areas of machine learning, deep learning, and artificial\nintelligence.\n",
                "链接": "https://arxiv.org/abs/2201.01943"
            },
            {
                "文章ID": "49139",
                "标题": "Language-Conditioned Reinforcement Learning to Solve Misunderstandings\n  with Action Corrections",
                "作者": " Frank Röder,  Manfred Eppe",
                "发布日期": "2022-11-21",
                "摘要": "  Human-to-human conversation is not just talking and listening. It is an\nincremental process where participants continually establish a common\nunderstanding to rule out misunderstandings. Current language understanding\nmethods for intelligent robots do not consider this. There exist numerous\napproaches considering non-understandings, but they ignore the incremental\nprocess of resolving misunderstandings. In this article, we present a first\nformalization and experimental validation of incremental action-repair for\nrobotic instruction-following based on reinforcement learning. To evaluate our\napproach, we propose a collection of benchmark environments for action\ncorrection in language-conditioned reinforcement learning, utilizing a\nsynthetic instructor to generate language goals and their corresponding\ncorrections. We show that a reinforcement learning agent can successfully learn\nto understand incremental corrections of misunderstood instructions.\n",
                "链接": "https://arxiv.org/abs/2211.10168"
            }
        ]
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "119143",
                "标题": "Label-efficient Training of Small Task-specific Models by Leveraging\n  Vision Foundation Models",
                "作者": " Raviteja Vemulapalli,  Hadi Pouransari,  Fartash Faghri,  Sachin Mehta,  Mehrdad Farajtabar,  Mohammad Rastegari,  Oncel Tuzel",
                "发布日期": "2023-12-01",
                "摘要": "  Large Vision Foundation Models (VFMs) pretrained on massive datasets exhibit\nimpressive performance on various downstream tasks, especially with limited\nlabeled target data. However, due to their high memory and compute\nrequirements, these models cannot be deployed in resource constrained settings.\nThis raises an important question: How can we utilize the knowledge from a\nlarge VFM to train a small task-specific model for a new target task with\nlimited labeled training data? In this work, we answer this question by\nproposing a simple and highly effective task-oriented knowledge transfer\napproach to leverage pretrained VFMs for effective training of small\ntask-specific models. Our experimental results on four target tasks under\nlimited labeled data settings show that the proposed knowledge transfer\napproach outperforms task-agnostic VFM distillation, web-scale CLIP pretraining\nand supervised ImageNet pretraining by 1-10.5%, 2-22% and 2-14%, respectively.\nWe also show that the dataset used for transferring knowledge has a significant\neffect on the final target task performance, and propose an image\nretrieval-based approach for curating effective transfer sets.\n",
                "链接": "https://arxiv.org/abs/2311.18237"
            },
            {
                "文章ID": "65848",
                "标题": "Knowledge Transfer via Multi-Head Feature Adaptation for Whole Slide\n  Image Classification",
                "作者": " Conghao Xiong,  Yi Lin,  Hao Chen,  Joseph Sung,  Irwin King",
                "发布日期": "2023-03-13",
                "摘要": "  Transferring prior knowledge from a source domain to the same or similar\ntarget domain can greatly enhance the performance of models on the target\ndomain. However, it is challenging to directly leverage the knowledge from the\nsource domain due to task discrepancy and domain shift. To bridge the gaps\nbetween different tasks and domains, we propose a Multi-Head Feature Adaptation\nmodule, which projects features in the source feature space to a new space that\nis more similar to the target space. Knowledge transfer is particularly\nimportant in Whole Slide Image (WSI) classification since the number of WSIs in\none dataset might be too small to achieve satisfactory performance. Therefore,\nWSI classification is an ideal testbed for our method, and we adapt multiple\nknowledge transfer methods for WSI classification. The experimental results\nshow that models with knowledge transfer outperform models that are trained\nfrom scratch by a large margin regardless of the number of WSIs in the\ndatasets, and our method achieves state-of-the-art performances among other\nknowledge transfer methods on multiple datasets, including TCGA-RCC,\nTCGA-NSCLC, and Camelyon16 datasets.\n",
                "链接": "https://arxiv.org/abs/2303.05780"
            },
            {
                "文章ID": "30372",
                "标题": "TinyViT: Fast Pretraining Distillation for Small Vision Transformers",
                "作者": " Kan Wu,  Jinnian Zhang,  Houwen Peng,  Mengchen Liu,  Bin Xiao,  Jianlong Fu,  Lu Yuan",
                "发布日期": "2022-07-22",
                "摘要": "  Vision transformer (ViT) recently has drawn great attention in computer\nvision due to its remarkable model capability. However, most prevailing ViT\nmodels suffer from huge number of parameters, restricting their applicability\non devices with limited resources. To alleviate this issue, we propose TinyViT,\na new family of tiny and efficient small vision transformers pretrained on\nlarge-scale datasets with our proposed fast distillation framework. The central\nidea is to transfer knowledge from large pretrained models to small ones, while\nenabling small models to get the dividends of massive pretraining data. More\nspecifically, we apply distillation during pretraining for knowledge transfer.\nThe logits of large teacher models are sparsified and stored in disk in advance\nto save the memory cost and computation overheads. The tiny student\ntransformers are automatically scaled down from a large pretrained model with\ncomputation and parameter constraints. Comprehensive experiments demonstrate\nthe efficacy of TinyViT. It achieves a top-1 accuracy of 84.8% on ImageNet-1k\nwith only 21M parameters, being comparable to Swin-B pretrained on ImageNet-21k\nwhile using 4.2 times fewer parameters. Moreover, increasing image resolutions,\nTinyViT can reach 86.5% accuracy, being slightly better than Swin-L while using\nonly 11% parameters. Last but not the least, we demonstrate a good transfer\nability of TinyViT on various downstream tasks. Code and models are available\nat https://github.com/microsoft/Cream/tree/main/TinyViT.\n",
                "链接": "https://arxiv.org/abs/2207.10666"
            },
            {
                "文章ID": "20067",
                "标题": "Deep transfer learning for image classification: a survey",
                "作者": " Jo Plested,  Tom Gedeon",
                "发布日期": "2022-05-23",
                "摘要": "  Deep neural networks such as convolutional neural networks (CNNs) and\ntransformers have achieved many successes in image classification in recent\nyears. It has been consistently demonstrated that best practice for image\nclassification is when large deep models can be trained on abundant labelled\ndata. However there are many real world scenarios where the requirement for\nlarge amounts of training data to get the best performance cannot be met. In\nthese scenarios transfer learning can help improve performance. To date there\nhave been no surveys that comprehensively review deep transfer learning as it\nrelates to image classification overall. However, several recent general\nsurveys of deep transfer learning and ones that relate to particular\nspecialised target image classification tasks have been published. We believe\nit is important for the future progress in the field that all current knowledge\nis collated and the overarching patterns analysed and discussed. In this survey\nwe formally define deep transfer learning and the problem it attempts to solve\nin relation to image classification. We survey the current state of the field\nand identify where recent progress has been made. We show where the gaps in\ncurrent knowledge are and make suggestions for how to progress the field to\nfill in these knowledge gaps. We present a new taxonomy of the applications of\ntransfer learning for image classification. This taxonomy makes it easier to\nsee overarching patterns of where transfer learning has been effective and,\nwhere it has failed to fulfill its potential. This also allows us to suggest\nwhere the problems lie and how it could be used more effectively. We show that\nunder this new taxonomy, many of the applications where transfer learning has\nbeen shown to be ineffective or even hinder performance are to be expected when\ntaking into account the source and target datasets and the techniques used.\n",
                "链接": "https://arxiv.org/abs/2205.09904"
            },
            {
                "文章ID": "70105",
                "标题": "DIME-FM: DIstilling Multimodal and Efficient Foundation Models",
                "作者": " Ximeng Sun,  Pengchuan Zhang,  Peizhao Zhang,  Hardik Shah,  Kate Saenko,  Xide Xia",
                "发布日期": "2023-08-16",
                "摘要": "  Large Vision-Language Foundation Models (VLFM), such as CLIP, ALIGN and\nFlorence, are trained on large-scale datasets of image-caption pairs and\nachieve superior transferability and robustness on downstream tasks, but they\nare difficult to use in many practical applications due to their large size,\nhigh latency and fixed architectures. Unfortunately, recent work shows training\na small custom VLFM for resource-limited applications is currently very\ndifficult using public and smaller-scale data. In this paper, we introduce a\nnew distillation mechanism (DIME-FM) that allows us to transfer the knowledge\ncontained in large VLFMs to smaller, customized foundation models using a\nrelatively small amount of inexpensive, unpaired images and sentences. We\ntransfer the knowledge from the pre-trained CLIP-ViTL/14 model to a ViT-B/32\nmodel, with only 40M public images and 28.4M unpaired public sentences. The\nresulting model \"Distill-ViT-B/32\" rivals the CLIP-ViT-B/32 model pre-trained\non its private WiT dataset (400M image-text pairs): Distill-ViT-B/32 achieves\nsimilar results in terms of zero-shot and linear-probing performance on both\nImageNet and the ELEVATER (20 image classification tasks) benchmarks. It also\ndisplays comparable robustness when evaluated on five datasets with natural\ndistribution shifts from ImageNet.\n",
                "链接": "https://arxiv.org/abs/2303.18232"
            },
            {
                "文章ID": "26664",
                "标题": "ST-Adapter: Parameter-Efficient Image-to-Video Transfer Learning",
                "作者": " Junting Pan,  Ziyi Lin,  Xiatian Zhu,  Jing Shao,  Hongsheng Li",
                "发布日期": "2022-10-14",
                "摘要": "  Capitalizing on large pre-trained models for various downstream tasks of\ninterest have recently emerged with promising performance. Due to the\never-growing model size, the standard full fine-tuning based task adaptation\nstrategy becomes prohibitively costly in terms of model training and storage.\nThis has led to a new research direction in parameter-efficient transfer\nlearning. However, existing attempts typically focus on downstream tasks from\nthe same modality (e.g., image understanding) of the pre-trained model. This\ncreates a limit because in some specific modalities, (e.g., video\nunderstanding) such a strong pre-trained model with sufficient knowledge is\nless or not available. In this work, we investigate such a novel cross-modality\ntransfer learning setting, namely parameter-efficient image-to-video transfer\nlearning. To solve this problem, we propose a new Spatio-Temporal Adapter\n(ST-Adapter) for parameter-efficient fine-tuning per video task. With a\nbuilt-in spatio-temporal reasoning capability in a compact design, ST-Adapter\nenables a pre-trained image model without temporal knowledge to reason about\ndynamic video content at a small (~8%) per-task parameter cost, requiring\napproximately 20 times fewer updated parameters compared to previous work.\nExtensive experiments on video action recognition tasks show that our\nST-Adapter can match or even outperform the strong full fine-tuning strategy\nand state-of-the-art video models, whilst enjoying the advantage of parameter\nefficiency. The code and model are available at\nhttps://github.com/linziyi96/st-adapter\n",
                "链接": "https://arxiv.org/abs/2206.13559"
            },
            {
                "文章ID": "49217",
                "标题": "Building a Subspace of Policies for Scalable Continual Learning",
                "作者": " Jean-Baptiste Gaya,  Thang Doan,  Lucas Caccia,  Laure Soulier,  Ludovic Denoyer,  Roberta Raileanu",
                "发布日期": "2023-03-03",
                "摘要": "  The ability to continuously acquire new knowledge and skills is crucial for\nautonomous agents. Existing methods are typically based on either fixed-size\nmodels that struggle to learn a large number of diverse behaviors, or\ngrowing-size models that scale poorly with the number of tasks. In this work,\nwe aim to strike a better balance between an agent's size and performance by\ndesigning a method that grows adaptively depending on the task sequence. We\nintroduce Continual Subspace of Policies (CSP), a new approach that\nincrementally builds a subspace of policies for training a reinforcement\nlearning agent on a sequence of tasks. The subspace's high expressivity allows\nCSP to perform well for many different tasks while growing sublinearly with the\nnumber of tasks. Our method does not suffer from forgetting and displays\npositive transfer to new tasks. CSP outperforms a number of popular baselines\non a wide range of scenarios from two challenging domains, Brax (locomotion)\nand Continual World (manipulation).\n",
                "链接": "https://arxiv.org/abs/2211.10445"
            },
            {
                "文章ID": "89073",
                "标题": "Analysis of Task Transferability in Large Pre-trained Classifiers",
                "作者": " Akshay Mehra,  Yunbei Zhang,  Jihun Hamm",
                "发布日期": "2023-07-04",
                "摘要": "  Transfer learning transfers the knowledge acquired by a model from a source\ntask to multiple downstream target tasks with minimal fine-tuning. The success\nof transfer learning at improving performance, especially with the use of large\npre-trained models has made transfer learning an essential tool in the machine\nlearning toolbox. However, the conditions under which the performance is\ntransferable to downstream tasks are not understood very well. In this work, we\nanalyze the transfer of performance for classification tasks, when only the\nlast linear layer of the source model is fine-tuned on the target task. We\npropose a novel Task Transfer Analysis approach that transforms the source\ndistribution (and classifier) by changing the class prior distribution, label,\nand feature spaces to produce a new source distribution (and classifier) and\nallows us to relate the loss of the downstream task (i.e., transferability) to\nthat of the source task. Concretely, our bound explains transferability in\nterms of the Wasserstein distance between the transformed source and downstream\ntask's distribution, conditional entropy between the label distributions of the\ntwo tasks, and weighted loss of the source classifier on the source task.\nMoreover, we propose an optimization problem for learning the transforms of the\nsource task to minimize the upper bound on transferability. We perform a\nlarge-scale empirical study by using state-of-the-art pre-trained models and\ndemonstrate the effectiveness of our bound and optimization at predicting\ntransferability. The results of our experiments demonstrate how factors such as\ntask relatedness, pretraining method, and model architecture affect\ntransferability.\n",
                "链接": "https://arxiv.org/abs/2307.00823"
            },
            {
                "文章ID": "9133",
                "标题": "Knowledge Distillation as Efficient Pre-training: Faster Convergence,\n  Higher Data-efficiency, and Better Transferability",
                "作者": " Ruifei He,  Shuyang Sun,  Jihan Yang,  Song Bai,  Xiaojuan Qi",
                "发布日期": "2022-03-29",
                "摘要": "  Large-scale pre-training has been proven to be crucial for various computer\nvision tasks. However, with the increase of pre-training data amount, model\narchitecture amount, and the private/inaccessible data, it is not very\nefficient or possible to pre-train all the model architectures on large-scale\ndatasets. In this work, we investigate an alternative strategy for\npre-training, namely Knowledge Distillation as Efficient Pre-training (KDEP),\naiming to efficiently transfer the learned feature representation from existing\npre-trained models to new student models for future downstream tasks. We\nobserve that existing Knowledge Distillation (KD) methods are unsuitable\ntowards pre-training since they normally distill the logits that are going to\nbe discarded when transferred to downstream tasks. To resolve this problem, we\npropose a feature-based KD method with non-parametric feature dimension\naligning. Notably, our method performs comparably with supervised pre-training\ncounterparts in 3 downstream tasks and 9 downstream datasets requiring 10x less\ndata and 5x less pre-training time. Code is available at\nhttps://github.com/CVMI-Lab/KDEP.\n",
                "链接": "https://arxiv.org/abs/2203.05180"
            },
            {
                "文章ID": "15508",
                "标题": "On The Cross-Modal Transfer from Natural Language to Code through\n  Adapter Modules",
                "作者": " Divyam Goel,  Ramansh Grover,  Fatemeh H. Fard",
                "发布日期": "2022-04-20",
                "摘要": "  Pre-trained neural Language Models (PTLM), such as CodeBERT, are recently\nused in software engineering as models pre-trained on large source code\ncorpora. Their knowledge is transferred to downstream tasks (e.g. code clone\ndetection) via fine-tuning. In natural language processing (NLP), other\nalternatives for transferring the knowledge of PTLMs are explored through using\nadapters, compact, parameter efficient modules inserted in the layers of the\nPTLM. Although adapters are known to facilitate adapting to many downstream\ntasks compared to fine-tuning the model that require retraining all of the\nmodels' parameters -- which owes to the adapters' plug and play nature and\nbeing parameter efficient -- their usage in software engineering is not\nexplored.\n  Here, we explore the knowledge transfer using adapters and based on the\nNaturalness Hypothesis proposed by Hindle et. al \\cite{hindle2016naturalness}.\nThus, studying the bimodality of adapters for two tasks of cloze test and code\nclone detection, compared to their benchmarks from the CodeXGLUE platform.\nThese adapters are trained using programming languages and are inserted in a\nPTLM that is pre-trained on English corpora (N-PTLM). Three programming\nlanguages, C/C++, Python, and Java, are studied along with extensive\nexperiments on the best setup used for adapters. Improving the results of the\nN-PTLM confirms the success of the adapters in knowledge transfer to software\nengineering, which sometimes are in par with or exceed the results of a PTLM\ntrained on source code; while being more efficient in terms of the number of\nparameters, memory usage, and inference time. Our results can open new\ndirections to build smaller models for more software engineering tasks. We open\nsource all the scripts and the trained adapters.\n",
                "链接": "https://arxiv.org/abs/2204.08653"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和人文学科交叉的研究",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和脑科学交叉的研究",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "2022年后与AI for Science相关的综述论文",
            "type": "6"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下2023年关于LLM-based Agent的综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "110807",
                "标题": "LLM-Based Agent Society Investigation: Collaboration and Confrontation\n  in Avalon Gameplay",
                "作者": " Yihuai Lan,  Zhiqiang Hu,  Lei Wang,  Yang Wang,  Deheng Ye,  Peilin Zhao,  Ee-Peng Lim,  Hui Xiong,  Hao Wang",
                "发布日期": "2023-10-24",
                "摘要": "  This paper aims to investigate the open research problem of uncovering the\nsocial behaviors of LLM-based agents. To achieve this goal, we adopt Avalon, a\nrepresentative communication game, as the environment and use system prompts to\nguide LLM agents to play the game. While previous studies have conducted\npreliminary investigations into gameplay with LLM agents, there lacks research\non their social behaviors. In this paper, we present a novel framework designed\nto seamlessly adapt to Avalon gameplay. The core of our proposed framework is a\nmulti-agent system that enables efficient communication and interaction among\nagents. We evaluate the performance of our framework based on metrics from two\nperspectives: winning the game and analyzing the social behaviors of LLM\nagents. Our results demonstrate the effectiveness of our framework in\ngenerating adaptive and intelligent agents and highlight the potential of\nLLM-based agents in addressing the challenges associated with dynamic social\nenvironment interaction. By analyzing the social behaviors of LLM agents from\nthe aspects of both collaboration and confrontation, we provide insights into\nthe research and applications of this domain.\n",
                "链接": "https://arxiv.org/abs/2310.14985"
            },
            {
                "文章ID": "107562",
                "标题": "How AI Processing Delays Foster Creativity: Exploring Research Question\n  Co-Creation with an LLM-based Agent",
                "作者": " Yiren Liu,  Si Chen,  Haocong Cheng,  Mengxia Yu,  Xiao Ran,  Andrew Mo,  Yiliu Tang,  Yun Huang",
                "发布日期": "2023-10-17",
                "摘要": "  Developing novel research questions (RQs) often requires extensive literature\nreviews, especially for interdisciplinary fields. Leveraging Large Language\nModels (LLMs), we built an LLM-based agent system, called CoQuest, supporting\nRQ development through human-AI co-creation. We conducted an experimental\ndesign with 20 participants to examine the effect of two interaction designs:\nbreadth-first and depth-first RQ generation. The results showed that\nparticipants found the breadth-first approach more creative and trustworthy\nupon task completion. However, during the task, they rated the RQs generated\nthrough the depth-first approach as more creative. We also discovered that AI\nprocessing delays allowed users to contemplate multiple RQs simultaneously,\nresulting in more generated RQs and an increased sense of perceived control.\nOur work makes both theoretical and practical contributions by proposing and\nassessing a mental model for human-AI co-creation RQs.\n",
                "链接": "https://arxiv.org/abs/2310.06155"
            },
            {
                "文章ID": "109250",
                "标题": "Theory of Mind for Multi-Agent Collaboration via Large Language Models",
                "作者": " Huao Li,  Yu Quan Chong,  Simon Stepputtis,  Joseph Campbell,  Dana Hughes,  Michael Lewis,  Katia Sycara",
                "发布日期": "2023-10-24",
                "摘要": "  While Large Language Models (LLMs) have demonstrated impressive\naccomplishments in both reasoning and planning, their abilities in multi-agent\ncollaborations remains largely unexplored. This study evaluates LLM-based\nagents in a multi-agent cooperative text game with Theory of Mind (ToM)\ninference tasks, comparing their performance with Multi-Agent Reinforcement\nLearning (MARL) and planning-based baselines. We observed evidence of emergent\ncollaborative behaviors and high-order Theory of Mind capabilities among\nLLM-based agents. Our results reveal limitations in LLM-based agents' planning\noptimization due to systematic failures in managing long-horizon contexts and\nhallucination about the task state. We explore the use of explicit belief state\nrepresentations to mitigate these issues, finding that it enhances task\nperformance and the accuracy of ToM inferences for LLM-based agents.\n",
                "链接": "https://arxiv.org/abs/2310.10701"
            },
            {
                "文章ID": "106067",
                "标题": "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with\n  Agent Team Optimization",
                "作者": " Zijun Liu,  Yanzhe Zhang,  Peng Li,  Yang Liu,  Diyi Yang",
                "发布日期": "2023-10-04",
                "摘要": "  Large language model (LLM) agents have been shown effective on a wide range\nof tasks, and by ensembling multiple LLM agents, their performances could be\nfurther improved. Existing approaches employ a fixed set of agents to interact\nwith each other in a static architecture, which limits their generalizability\nto various tasks and requires strong human prior in designing these agents. In\nthis work, we propose to construct a strategic team of agents communicating in\na dynamic interaction architecture based on the task query. Specifically, we\nbuild a framework named Dynamic LLM-Agent Network ($\\textbf{DyLAN}$) for\nLLM-agent collaboration on complicated tasks like reasoning and code\ngeneration. DyLAN enables agents to interact for multiple rounds in a dynamic\narchitecture with inference-time agent selection and an early-stopping\nmechanism to improve performance and efficiency. We further design an automatic\nagent team optimization algorithm based on an unsupervised metric termed\n$\\textit{Agent Importance Score}$, enabling the selection of best agents based\non the contribution each agent makes. Empirically, we demonstrate that DyLAN\nperforms well in both reasoning and code generation tasks with reasonable\ncomputational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and\nHumanEval, respectively, compared to a single execution on GPT-35-turbo. On\nspecific subjects of MMLU, agent team optimization in DyLAN increases accuracy\nby up to 25.0%.\n",
                "链接": "https://arxiv.org/abs/2310.02170"
            },
            {
                "文章ID": "120758",
                "标题": "LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent\n  Ecosystem",
                "作者": " Yingqiang Ge,  Yujie Ren,  Wenyue Hua,  Shuyuan Xu,  Juntao Tan,  Yongfeng Zhang",
                "发布日期": "2023-12-12",
                "摘要": "  This paper envisions a revolutionary AIOS-Agent ecosystem, where Large\nLanguage Model (LLM) serves as the (Artificial) Intelligent Operating System\n(IOS, or AIOS)--an operating system \"with soul\". Upon this foundation, a\ndiverse range of LLM-based AI Agent Applications (Agents, or AAPs) are\ndeveloped, enriching the AIOS-Agent ecosystem and signaling a paradigm shift\nfrom the traditional OS-APP ecosystem. We envision that LLM's impact will not\nbe limited to the AI application level, instead, it will in turn revolutionize\nthe design and implementation of computer system, architecture, software, and\nprogramming language, featured by several main concepts: LLM as OS\n(system-level), Agents as Applications (application-level), Natural Language as\nProgramming Interface (user-level), and Tools as Devices/Libraries\n(hardware/middleware-level). We begin by introducing the architecture of\ntraditional OS. Then we formalize a conceptual framework for AIOS through \"LLM\nas OS (LLMOS)\", drawing analogies between AIOS and traditional OS: LLM is\nlikened to OS kernel, context window to memory, external storage to file\nsystem, hardware tools to peripheral devices, software tools to programming\nlibraries, and user prompts to user commands. Subsequently, we introduce the\nnew AIOS-Agent Ecosystem, where users can easily program Agent Applications\n(AAPs) using natural language, democratizing the development of software, which\nis different from the traditional OS-APP ecosystem. Following this, we explore\nthe diverse scope of Agent Applications. We delve into both single-agent and\nmulti-agent systems, as well as human-agent interaction. Lastly, drawing on the\ninsights from traditional OS-APP ecosystem, we propose a roadmap for the\nevolution of the AIOS-Agent ecosystem. This roadmap is designed to guide the\nfuture research and development, suggesting systematic progresses of AIOS and\nits Agent applications.\n",
                "链接": "https://arxiv.org/abs/2312.03815"
            },
            {
                "文章ID": "102059",
                "标题": "The Rise and Potential of Large Language Model Based Agents: A Survey",
                "作者": " Zhiheng Xi,  Wenxiang Chen,  Xin Guo,  Wei He,  Yiwen Ding,  Boyang Hong,  Ming Zhang,  Junzhe Wang,  Senjie Jin,  Enyu Zhou,  Rui Zheng,  Xiaoran Fan,  Xiao Wang,  Limao Xiong,  Yuhao Zhou,  Weiran Wang,  Changhao Jiang,  Yicheng Zou,  Xiangyang Liu,  Zhangyue Yin,  Shihan Dou,  Rongxiang Weng,  Wensen Cheng,  Qi Zhang,  Wenjuan Qin,  Yongyan Zheng,  Xipeng Qiu,  Xuanjing Huang,  Tao Gui",
                "发布日期": "2023-09-20",
                "摘要": "  For a long time, humanity has pursued artificial intelligence (AI) equivalent\nto or surpassing the human level, with AI agents considered a promising vehicle\nfor this pursuit. AI agents are artificial entities that sense their\nenvironment, make decisions, and take actions. Many efforts have been made to\ndevelop intelligent agents, but they mainly focus on advancement in algorithms\nor training strategies to enhance specific capabilities or performance on\nparticular tasks. Actually, what the community lacks is a general and powerful\nmodel to serve as a starting point for designing AI agents that can adapt to\ndiverse scenarios. Due to the versatile capabilities they demonstrate, large\nlanguage models (LLMs) are regarded as potential sparks for Artificial General\nIntelligence (AGI), offering hope for building general AI agents. Many\nresearchers have leveraged LLMs as the foundation to build AI agents and have\nachieved significant progress. In this paper, we perform a comprehensive survey\non LLM-based agents. We start by tracing the concept of agents from its\nphilosophical origins to its development in AI, and explain why LLMs are\nsuitable foundations for agents. Building upon this, we present a general\nframework for LLM-based agents, comprising three main components: brain,\nperception, and action, and the framework can be tailored for different\napplications. Subsequently, we explore the extensive applications of LLM-based\nagents in three aspects: single-agent scenarios, multi-agent scenarios, and\nhuman-agent cooperation. Following this, we delve into agent societies,\nexploring the behavior and personality of LLM-based agents, the social\nphenomena that emerge from an agent society, and the insights they offer for\nhuman society. Finally, we discuss several key topics and open problems within\nthe field. A repository for the related papers at\nhttps://github.com/WooooDyy/LLM-Agent-Paper-List.\n",
                "链接": "https://arxiv.org/abs/2309.07864"
            },
            {
                "文章ID": "117475",
                "标题": "Large Language Model is a Good Policy Teacher for Training Reinforcement\n  Learning Agents",
                "作者": " Zihao Zhou,  Bin Hu,  Pu Zhang,  Chenyang Zhao,  Bin Liu",
                "发布日期": "2023-11-30",
                "摘要": "  Recent studies have shown that Large Language Models (LLMs) can be utilized\nfor solving complex sequential decision-making tasks by providing high-level\ninstructions. However, LLM-based agents face limitations in real-time dynamic\nenvironments due to their lack of specialization in solving specific target\nproblems. Moreover, the deployment of such LLM-based agents is both costly and\ntime-consuming in practical scenarios. In this paper, we introduce a novel\nframework that addresses these challenges by training a smaller scale\nspecialized student agent using instructions from an LLM-based teacher agent.\nBy leveraging guided actions provided by the teachers, the prior knowledge of\nthe LLM is distilled into the local student model. Consequently, the student\nagent can be trained with significantly less data. Furthermore, subsequent\ntraining with environment feedback empowers the student agents to surpass the\ncapabilities of their teachers. We conducted experiments on three challenging\nMiniGrid environments to evaluate the effectiveness of our framework. The\nresults demonstrate that our approach enhances sample efficiency and achieves\nsuperior performance compared to baseline methods. Our code is available at\nhttps://github.com/ZJLAB-AMMI/LLM4Teach.\n",
                "链接": "https://arxiv.org/abs/2311.13373"
            },
            {
                "文章ID": "108435",
                "标题": "Formally Specifying the High-Level Behavior of LLM-Based Agents",
                "作者": " Maxwell Crouse,  Ibrahim Abdelaziz,  Kinjal Basu,  Soham Dan,  Sadhana Kumaravel,  Achille Fokoue,  Pavan Kapanipathi,  Luis Lastras",
                "发布日期": "2023-10-13",
                "摘要": "  LLM-based agents have recently emerged as promising tools for solving\nchallenging problems without the need for task-specific finetuned models that\ncan be expensive to procure. Currently, the design and implementation of such\nagents is ad hoc, as the wide variety of tasks that LLM-based agents may be\napplied to naturally means there can be no one-size-fits-all approach to agent\ndesign. In this work we aim to alleviate the difficulty of designing and\nimplementing new agents by proposing a minimalistic, high-level generation\nframework that simplifies the process of building agents. The framework we\nintroduce allows the user to specify desired agent behaviors in Linear Temporal\nLogic (LTL). The declarative LTL specification is then used to construct a\nconstrained decoder that guarantees the LLM will produce an output exhibiting\nthe desired behavior. By designing our framework in this way, we obtain several\nbenefits, including the ability to enforce complex agent behavior, the ability\nto formally validate prompt examples, and the ability to seamlessly incorporate\ncontent-focused logical constraints into generation. In particular, our\ndeclarative approach, in which the desired behavior is simply described without\nconcern for how it should be implemented or enforced, enables rapid design,\nimplementation and experimentation with different LLM-based agents. We\ndemonstrate how the proposed framework can be used to implement recent\nLLM-based agents, and show how the guardrails our approach provides can lead to\nimprovements in agent performance. In addition, we release our code for general\nuse.\n",
                "链接": "https://arxiv.org/abs/2310.08535"
            },
            {
                "文章ID": "112870",
                "标题": "Leveraging Word Guessing Games to Assess the Intelligence of Large\n  Language Models",
                "作者": " Tian Liang,  Zhiwei He,  Jen-tse Huang,  Wenxuan Wang,  Wenxiang Jiao,  Rui Wang,  Yujiu Yang,  Zhaopeng Tu,  Shuming Shi,  Xing Wang",
                "发布日期": "2023-11-07",
                "摘要": "  The automatic evaluation of LLM-based agent intelligence is critical in\ndeveloping advanced LLM-based agents. Although considerable effort has been\ndevoted to developing human-annotated evaluation datasets, such as AlpacaEval,\nexisting techniques are costly, time-consuming, and lack adaptability. In this\npaper, inspired by the popular language game ``Who is Spy'', we propose to use\nthe word guessing game to assess the intelligence performance of LLMs. Given a\nword, the LLM is asked to describe the word and determine its identity (spy or\nnot) based on its and other players' descriptions. Ideally, an advanced agent\nshould possess the ability to accurately describe a given word using an\naggressive description while concurrently maximizing confusion in the\nconservative description, enhancing its participation in the game. To this end,\nwe first develop DEEP to evaluate LLMs' expression and disguising abilities.\nDEEP requires LLM to describe a word in aggressive and conservative modes. We\nthen introduce SpyGame, an interactive multi-agent framework designed to assess\nLLMs' intelligence through participation in a competitive language-based board\ngame. Incorporating multi-agent interaction, SpyGame requires the target LLM to\npossess linguistic skills and strategic thinking, providing a more\ncomprehensive evaluation of LLMs' human-like cognitive abilities and\nadaptability in complex communication situations. The proposed evaluation\nframework is very easy to implement. We collected words from multiple sources,\ndomains, and languages and used the proposed evaluation framework to conduct\nexperiments. Extensive experiments demonstrate that the proposed DEEP and\nSpyGame effectively evaluate the capabilities of various LLMs, capturing their\nability to adapt to novel situations and engage in strategic communication.\n",
                "链接": "https://arxiv.org/abs/2310.20499"
            },
            {
                "文章ID": "85592",
                "标题": "Large Language Models Are Semi-Parametric Reinforcement Learning Agents",
                "作者": " Danyang Zhang,  Lu Chen,  Situo Zhang,  Hongshen Xu,  Zihan Zhao,  Kai Yu",
                "发布日期": "2023-10-31",
                "摘要": "  Inspired by the insights in cognitive science with respect to human memory\nand reasoning mechanism, a novel evolvable LLM-based (Large Language Model)\nagent framework is proposed as REMEMBERER. By equipping the LLM with a\nlong-term experience memory, REMEMBERER is capable of exploiting the\nexperiences from the past episodes even for different task goals, which excels\nan LLM-based agent with fixed exemplars or equipped with a transient working\nmemory. We further introduce Reinforcement Learning with Experience Memory\n(RLEM) to update the memory. Thus, the whole system can learn from the\nexperiences of both success and failure, and evolve its capability without\nfine-tuning the parameters of the LLM. In this way, the proposed REMEMBERER\nconstitutes a semi-parametric RL agent. Extensive experiments are conducted on\ntwo RL task sets to evaluate the proposed framework. The average results with\ndifferent initialization and training sets exceed the prior SOTA by 4% and 2%\nfor the success rate on two task sets and demonstrate the superiority and\nrobustness of REMEMBERER.\n",
                "链接": "https://arxiv.org/abs/2306.07929"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近三个月有关语言模型rlhf的arxiv上的全部文章。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大模型结合树搜索方法进行推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105172",
                "标题": "Alphazero-like Tree-Search can Guide Large Language Model Decoding and\n  Training",
                "作者": " Xidong Feng,  Ziyu Wan,  Muning Wen,  Ying Wen,  Weinan Zhang,  Jun Wang",
                "发布日期": "2023-10-02",
                "摘要": "  Large language models (LLMs) typically employ sampling or beam search,\naccompanied by prompts such as Chain-of-Thought (CoT), to boost reasoning and\ndecoding ability. Recent work like Tree-of-Thought (ToT) and Reasoning via\nPlanning (RAP) aim to augment the reasoning capabilities of LLMs by utilizing\ntree-search algorithms to guide multi-step reasoning. These methods mainly\nfocus on LLMs' reasoning ability during inference and heavily rely on\nhuman-designed prompts to activate LLM as a value function, which lacks general\napplicability and scalability. To address these limitations, we present an\nAlphaZero-like tree-search framework for LLMs (termed TS-LLM), systematically\nillustrating how tree-search with a learned value function can guide LLMs'\ndecoding ability. TS-LLM distinguishes itself in two key ways: (1) Leveraging a\nlearned value function, our approach can be generally applied to different\ntasks beyond reasoning (such as RLHF alignment), and LLMs of any size, without\nprompting advanced, large-scale models. (2) It can guide LLM's decoding during\nboth inference and training. Empirical evaluations across reasoning, planning,\nand RLHF alignment tasks validate the effectiveness of TS-LLM, even on trees\nwith a depth of 64.\n",
                "链接": "https://arxiv.org/abs/2309.17179"
            },
            {
                "文章ID": "109239",
                "标题": "Autonomous Tree-search Ability of Large Language Models",
                "作者": " Zheyu Zhang,  Zhuorui Ye,  Yikang Shen,  Chuang Gan",
                "发布日期": "2023-10-18",
                "摘要": "  Large Language Models have excelled in remarkable reasoning capabilities with\nadvanced prompting techniques, but they fall short on tasks that require\nexploration, strategic foresight, and sequential decision-making. Recent works\npropose to utilize external programs to define search logic, such that LLMs can\nperform passive tree search to solve more challenging reasoning tasks. Though\nimpressive results have been achieved, there are several fundamental\nlimitations of these approaches. First, passive tree searches are not efficient\nas they usually require multiple rounds of LLM API calls to solve one single\nproblem. Moreover, passive search methods are not flexible since they need\ntask-specific program designs. Then a natural question arises: can we maintain\nthe tree-search capability of LLMs without the aid of external programs, and\ncan still generate responses that clearly demonstrate the process of a\ntree-structure search? To this end, we propose a new concept called autonomous\ntree-search ability of LLM, which can automatically generate a response\ncontaining search trajectories for the correct answer. Concretely, we perform\nsearch trajectories using capable LLM API via a fixed system prompt, allowing\nthem to perform autonomous tree-search (ATS) right out of the box. Experiments\non 4 puzzle games demonstrate our method can achieve huge improvements. The\nATS-BFS method outperforms the Chain of Thought approach by achieving an\naverage accuracy improvement of 33%. Compared to Tree of Thoughts, it requires\n65.6% or 47.7% less GPT-api cost to attain a comparable level of accuracy.\nMoreover, we have collected data using the ATS prompt method and fine-tuned\nLLaMA. This approach yield a greater improvement compared to the ones\nfine-tuned on CoT data. Specifically, it outperforms CoT-tuned LLaMAs by an\naverage of 40.6% and 38.5% for LLaMA2-7B and LLaMA2-13B, respectively.\n",
                "链接": "https://arxiv.org/abs/2310.10686"
            },
            {
                "文章ID": "108241",
                "标题": "Large Language Models for Scientific Synthesis, Inference and\n  Explanation",
                "作者": " Yizhen Zheng,  Huan Yee Koh,  Jiaxin Ju,  Anh T. N. Nguyen,  Lauren T. May,  Geoffrey I. Webb,  Shirui Pan",
                "发布日期": "2023-10-13",
                "摘要": "  Large language models are a form of artificial intelligence systems whose\nprimary knowledge consists of the statistical patterns, semantic relationships,\nand syntactical structures of language1. Despite their limited forms of\n\"knowledge\", these systems are adept at numerous complex tasks including\ncreative writing, storytelling, translation, question-answering, summarization,\nand computer code generation. However, they have yet to demonstrate advanced\napplications in natural science. Here we show how large language models can\nperform scientific synthesis, inference, and explanation. We present a method\nfor using general-purpose large language models to make inferences from\nscientific datasets of the form usually associated with special-purpose machine\nlearning algorithms. We show that the large language model can augment this\n\"knowledge\" by synthesizing from the scientific literature. When a conventional\nmachine learning system is augmented with this synthesized and inferred\nknowledge it can outperform the current state of the art across a range of\nbenchmark tasks for predicting molecular properties. This approach has the\nfurther advantage that the large language model can explain the machine\nlearning system's predictions. We anticipate that our framework will open new\navenues for AI to accelerate the pace of scientific discovery.\n",
                "链接": "https://arxiv.org/abs/2310.07984"
            },
            {
                "文章ID": "77937",
                "标题": "SpecInfer: Accelerating Generative Large Language Model Serving with\n  Speculative Inference and Token Tree Verification",
                "作者": " Xupeng Miao,  Gabriele Oliaro,  Zhihao Zhang,  Xinhao Cheng,  Zeyu Wang,  Rae Ying Yee Wong,  Alan Zhu,  Lijie Yang,  Xiaoxiang Shi,  Chunan Shi,  Zhuoming Chen,  Daiyaan Arfeen,  Reyna Abhyankar,  Zhihao Jia",
                "发布日期": "2023-08-17",
                "摘要": "  The high computational and memory requirements of generative large language\nmodels (LLMs) make it challenging to serve them quickly and cheaply. This paper\nintroduces SpecInfer, an LLM serving system that accelerates generative LLM\ninference with speculative inference and token tree verification. A key insight\nbehind Specinfer is to combine various collectively boost-tuned small language\nmodels to jointly predict the LLM's outputs; the predictions are organized as a\ntoken tree, whose nodes each represent a candidate token sequence. The\ncorrectness of all candidate token sequences represented by a token tree is\nverified against the LLM in parallel using a novel tree-based parallel decoding\nmechanism. SpecInfer uses an LLM as a token tree verifier instead of an\nincremental decoder, which significantly reduces the end-to-end latency and\ncomputational requirement for serving generative LLMs while provably preserving\nmodel quality. Our evaluation shows that SpecInfer outperforms existing LLM\nserving systems by 1.3-2.4x for distributed LLM inference and by 2.6-3.5x for\noffloading-based LLM inference, while preserving the same generative\nperformance. SpecInfer is publicly available at\nhttps://github.com/flexflow/FlexFlow/tree/inference.\n",
                "链接": "https://arxiv.org/abs/2305.09781"
            },
            {
                "文章ID": "105289",
                "标题": "SocREval: Large Language Models with the Socratic Method for\n  Reference-Free Reasoning Evaluation",
                "作者": " Hangfeng He,  Hongming Zhang,  Dan Roth",
                "发布日期": "2023-10-03",
                "摘要": "  To comprehensively assess the capacity of current models for complex\nreasoning, it is crucial to assess their step-by-step reasoning in a scalable\nmanner. Established reference-based evaluation metrics rely on human-annotated\nreasoning chains to assess the model-derived chains. However, such\n``gold-standard'' human-written reasoning chains may not be unique and their\nacquisition is often labor-intensive. Existing reference-free reasoning metrics\neliminate the need for human-crafted reasoning chains as references, but they\ntypically require fine-tuning on datasets with human-derived reasoning chains,\nwhich complicates the process and raises concerns regarding generalizability\nacross diverse datasets. To address these challenges, we harness GPT-4 to\nautomatically evaluate reasoning chain quality, obviating the need for\nhuman-crafted references. Leveraging the Socratic method, we devise tailored\nprompts to enhance reference-free reasoning evaluation, which we term SocREval\n(Socratic method for Reasoning Evaluation). Empirical results from four human\nannotated datasets reveal that SocREval significantly improves GPT-4's\nperformance, surpassing existing reference-free and reference-based reasoning\nevaluation metrics. Beyond its demonstrated efficacy, our proposed framework,\nlarge language models (LLMs) with the Socratic method, proves to be both\ncost-efficient and robust to prompt writing and example selection, as\nsubstantiated by our in-depth analysis.\n",
                "链接": "https://arxiv.org/abs/2310.00074"
            },
            {
                "文章ID": "71550",
                "标题": "Inference with Reference: Lossless Acceleration of Large Language Models",
                "作者": " Nan Yang,  Tao Ge,  Liang Wang,  Binxing Jiao,  Daxin Jiang,  Linjun Yang,  Rangan Majumder,  Furu Wei",
                "发布日期": "2023-04-11",
                "摘要": "  We propose LLMA, an LLM accelerator to losslessly speed up Large Language\nModel (LLM) inference with references. LLMA is motivated by the observation\nthat there are abundant identical text spans between the decoding result by an\nLLM and the reference that is available in many real world scenarios (e.g.,\nretrieved documents). LLMA first selects a text span from the reference and\ncopies its tokens to the decoder and then efficiently checks the tokens'\nappropriateness as the decoding result in parallel within one decoding step.\nThe improved computational parallelism allows LLMA to achieve over 2x speed-up\nfor LLMs with identical generation results as greedy decoding in many practical\ngeneration scenarios where significant overlap between in-context reference and\noutputs exists (e.g., search engines and multi-turn conversations).\n",
                "链接": "https://arxiv.org/abs/2304.04487"
            },
            {
                "文章ID": "109443",
                "标题": "Revealing the Unwritten: Visual Investigation of Beam Search Trees to\n  Address Language Model Prompting Challenges",
                "作者": " Thilo Spinner,  Rebecca Kehlbeck,  Rita Sevastjanova,  Tobias Stähle,  Daniel A. Keim,  Oliver Deussen,  Andreas Spitz,  Mennatallah El-Assady",
                "发布日期": "2023-10-18",
                "摘要": "  The growing popularity of generative language models has amplified interest\nin interactive methods to guide model outputs. Prompt refinement is considered\none of the most effective means to influence output among these methods. We\nidentify several challenges associated with prompting large language models,\ncategorized into data- and model-specific, linguistic, and socio-linguistic\nchallenges. A comprehensive examination of model outputs, including runner-up\ncandidates and their corresponding probabilities, is needed to address these\nissues. The beam search tree, the prevalent algorithm to sample model outputs,\ncan inherently supply this information. Consequently, we introduce an\ninteractive visual method for investigating the beam search tree, facilitating\nanalysis of the decisions made by the model during generation. We\nquantitatively show the value of exposing the beam search tree and present five\ndetailed analysis scenarios addressing the identified challenges. Our\nmethodology validates existing results and offers additional insights.\n",
                "链接": "https://arxiv.org/abs/2310.11252"
            },
            {
                "文章ID": "100993",
                "标题": "LLMCad: Fast and Scalable On-device Large Language Model Inference",
                "作者": " Daliang Xu,  Wangsong Yin,  Xin Jin,  Ying Zhang,  Shiyun Wei,  Mengwei Xu,  Xuanzhe Liu",
                "发布日期": "2023-09-11",
                "摘要": "  Generative tasks, such as text generation and question answering, hold a\ncrucial position in the realm of mobile applications. Due to their sensitivity\nto privacy concerns, there is a growing demand for their execution directly on\nmobile devices. Currently, the execution of these generative tasks heavily\ndepends on Large Language Models (LLMs). Nevertheless, the limited memory\ncapacity of these devices presents a formidable challenge to the scalability of\nsuch models.\n  In our research, we introduce LLMCad, an innovative on-device inference\nengine specifically designed for efficient generative Natural Language\nProcessing (NLP) tasks. The core idea behind LLMCad revolves around model\ncollaboration: a compact LLM, residing in memory, takes charge of generating\nthe most straightforward tokens, while a high-precision LLM steps in to\nvalidate these tokens and rectify any identified errors. LLMCad incorporates\nthree novel techniques: (1) Instead of generating candidate tokens in a\nsequential manner, LLMCad employs the smaller LLM to construct a token tree,\nencompassing a wider range of plausible token pathways. Subsequently, the\nlarger LLM can efficiently validate all of these pathways simultaneously. (2)\nIt employs a self-adjusting fallback strategy, swiftly initiating the\nverification process whenever the smaller LLM generates an erroneous token. (3)\nTo ensure a continuous flow of token generation, LLMCad speculatively generates\ntokens during the verification process by implementing a compute-IO pipeline.\nThrough an extensive series of experiments, LLMCad showcases an impressive\ntoken generation speed, achieving rates up to 9.3x faster than existing\ninference engines.\n",
                "链接": "https://arxiv.org/abs/2309.04255"
            },
            {
                "文章ID": "78273",
                "标题": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
                "作者": " Shunyu Yao,  Dian Yu,  Jeffrey Zhao,  Izhak Shafran,  Thomas L. Griffiths,  Yuan Cao,  Karthik Narasimhan",
                "发布日期": "2023-12-05",
                "摘要": "  Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nhttps://github.com/princeton-nlp/tree-of-thought-llm.\n",
                "链接": "https://arxiv.org/abs/2305.10601"
            },
            {
                "文章ID": "106837",
                "标题": "Language Agent Tree Search Unifies Reasoning Acting and Planning in\n  Language Models",
                "作者": " Andy Zhou,  Kai Yan,  Michal Shlapentokh-Rothman,  Haohan Wang,  Yu-Xiong Wang",
                "发布日期": "2023-12-06",
                "摘要": "  While large language models (LLMs) have demonstrated impressive performance\non a range of decision-making tasks, they rely on simple acting processes and\nfall short of broad deployment as autonomous agents. We introduce LATS\n(Language Agent Tree Search), a general framework that synergizes the\ncapabilities of LLMs in planning, acting, and reasoning. Drawing inspiration\nfrom Monte Carlo tree search in model-based reinforcement learning, LATS\nemploys LLMs as agents, value functions, and optimizers, repurposing their\nlatent strengths for enhanced decision-making. What is crucial in this method\nis the use of an environment for external feedback, which offers a more\ndeliberate and adaptive problem-solving mechanism that moves beyond the\nlimitations of existing techniques. Our experimental evaluation across diverse\ndomains, such as programming, HotPotQA, and WebShop, illustrates the\napplicability of LATS for both reasoning and acting. In particular, LATS\nachieves 94.4% for programming on HumanEval with GPT-4 and an average score of\n75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness\nand generality of our method.\n",
                "链接": "https://arxiv.org/abs/2310.04406"
            },
            {
                "文章ID": "79447",
                "标题": "Enhance Reasoning Ability of Visual-Language Models via Large Language\n  Models",
                "作者": " Yueting Yang,  Xintong Zhang,  Wenjuan Han",
                "发布日期": "2023-05-23",
                "摘要": "  Pre-trained visual language models (VLM) have shown excellent performance in\nimage caption tasks. However, it sometimes shows insufficient reasoning\nability. In contrast, large language models (LLMs) emerge with powerful\nreasoning capabilities. Therefore, we propose a method called TReE, which\ntransfers the reasoning ability of a large language model to a visual language\nmodel in zero-shot scenarios. TReE contains three stages: observation,\nthinking, and re-thinking. Observation stage indicates that VLM obtains the\noverall information of the relative image. Thinking stage combines the image\ninformation and task description as the prompt of the LLM, inference with the\nrationals. Re-Thinking stage learns from rationale and then inference the final\nresult through VLM.\n",
                "链接": "https://arxiv.org/abs/2305.13267"
            },
            {
                "文章ID": "116170",
                "标题": "Large Language Model Inference with Lexical Shortlisting",
                "作者": " Nikolay Bogoychev,  Pinzhen Chen,  Barry Haddow,  Alexandra Birch",
                "发布日期": "2023-11-17",
                "摘要": "  Large language model (LLM) inference is computation and memory intensive, so\nwe adapt lexical shortlisting to it hoping to improve both. While lexical\nshortlisting is well-explored in tasks like machine translation, it requires\nmodifications before being suitable for LLMs as the intended applications vary\nsignificantly. Our work studies two heuristics to shortlist sub-vocabulary at\nLLM inference time: Unicode-based script filtering and corpus-based selection.\nWe explore different LLM families and sizes, and we find that lexical\nshortlisting can reduce the memory usage of some models by nearly 50\\% and has\nan upper bound of 25\\% improvement in generation speed. In this pilot study, we\nalso identify the drawbacks of such vocabulary selection methods and propose\navenues for future research.\n",
                "链接": "https://arxiv.org/abs/2311.09709"
            },
            {
                "文章ID": "70326",
                "标题": "Exploring the Use of Large Language Models for Reference-Free Text\n  Quality Evaluation: An Empirical Study",
                "作者": " Yi Chen,  Rui Wang,  Haiyun Jiang,  Shuming Shi,  Ruifeng Xu",
                "发布日期": "2023-09-19",
                "摘要": "  Evaluating the quality of generated text is a challenging task in NLP, due to\nthe inherent complexity and diversity of text. Recently, large language models\n(LLMs) have garnered significant attention due to their impressive performance\nin various tasks. Therefore, we present this paper to investigate the\neffectiveness of LLMs, especially ChatGPT, and explore ways to optimize their\nuse in assessing text quality. We compared three kinds of reference-free\nevaluation methods. The experimental results prove that ChatGPT is capable of\nevaluating text quality effectively from various perspectives without reference\nand demonstrates superior performance than most existing automatic metrics. In\nparticular, the Explicit Score, which utilizes ChatGPT to generate a numeric\nscore measuring text quality, is the most effective and reliable method among\nthe three exploited approaches. However, directly comparing the quality of two\ntexts may lead to suboptimal results. We believe this paper will provide\nvaluable insights for evaluating text quality with LLMs and have released the\nused data.\n",
                "链接": "https://arxiv.org/abs/2304.00723"
            },
            {
                "文章ID": "9690",
                "标题": "GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large\n  Language Models",
                "作者": " Archiki Prasad,  Peter Hase,  Xiang Zhou,  Mohit Bansal",
                "发布日期": "2023-04-28",
                "摘要": "  Providing natural language instructions in prompts is a useful new paradigm\nfor improving task performance of large language models in a zero-shot setting.\nRecent work has aimed to improve such prompts via manual rewriting or\ngradient-based tuning. However, manual rewriting is time-consuming and requires\nsubjective interpretation, while gradient-based tuning can be extremely\ncomputationally demanding for large models and may not be feasible for\nAPI-based models. In this work, we introduce Gradient-free Instructional Prompt\nSearch (GrIPS), a gradient-free, edit-based search approach for improving task\ninstructions for large language models. GrIPS takes in instructions designed\nfor humans and automatically returns an improved, edited prompt, while allowing\nfor API-based tuning. With InstructGPT models, GrIPS improves the average task\nperformance by up to 4.30 percentage points on eight classification tasks from\nthe Natural Instructions dataset (with similar improvements for OPT, BLOOM, and\nFLAN-T5). We see improvements for both instruction-only prompts and instruction\n+ k-shot examples prompts. Notably, GrIPS outperforms manual rewriting and\npurely example-based prompts while controlling for the available compute and\ndata budget. Further, performance of GrIPS is comparable to select\ngradient-based tuning approaches. Qualitatively, we show our edits can simplify\ninstructions and at times make them incoherent but nonetheless improve\naccuracy. Our code is available at: https://github.com/archiki/GrIPS\n",
                "链接": "https://arxiv.org/abs/2203.07281"
            },
            {
                "文章ID": "53273",
                "标题": "Reinforcement Learning and Tree Search Methods for the Unit Commitment\n  Problem",
                "作者": " Patrick de Mars",
                "发布日期": "2022-12-13",
                "摘要": "  The unit commitment (UC) problem, which determines operating schedules of\ngeneration units to meet demand, is a fundamental task in power systems\noperation. Existing UC methods using mixed-integer programming are not\nwell-suited to highly stochastic systems. Approaches which more rigorously\naccount for uncertainty could yield large reductions in operating costs by\nreducing spinning reserve requirements; operating power stations at higher\nefficiencies; and integrating greater volumes of variable renewables. A\npromising approach to solving the UC problem is reinforcement learning (RL), a\nmethodology for optimal decision-making which has been used to conquer\nlong-standing grand challenges in artificial intelligence. This thesis explores\nthe application of RL to the UC problem and addresses challenges including\nrobustness under uncertainty; generalisability across multiple problem\ninstances; and scaling to larger power systems than previously studied. To\ntackle these issues, we develop guided tree search, a novel methodology\ncombining model-free RL and model-based planning. The UC problem is formalised\nas a Markov decision process and we develop an open-source environment based on\nreal data from Great Britain's power system to train RL agents. In problems of\nup to 100 generators, guided tree search is shown to be competitive with\ndeterministic UC methods, reducing operating costs by up to 1.4\\%. An advantage\nof RL is that the framework can be easily extended to incorporate\nconsiderations important to power systems operators such as robustness to\ngenerator failure, wind curtailment or carbon prices. When generator outages\nare considered, guided tree search saves over 2\\% in operating costs as\ncompared with methods using conventional $N-x$ reserve criteria.\n",
                "链接": "https://arxiv.org/abs/2212.06001"
            },
            {
                "文章ID": "102988",
                "标题": "Large language models can accurately predict searcher preferences",
                "作者": " Paul Thomas,  Seth Spielman,  Nick Craswell,  Bhaskar Mitra",
                "发布日期": "2023-09-20",
                "摘要": "  Relevance labels, which indicate whether a search result is valuable to a\nsearcher, are key to evaluating and optimising search systems. The best way to\ncapture the true preferences of users is to ask them for their careful feedback\non which results would be useful, but this approach does not scale to produce a\nlarge number of labels. Getting relevance labels at scale is usually done with\nthird-party labellers, who judge on behalf of the user, but there is a risk of\nlow-quality data if the labeller doesn't understand user needs. To improve\nquality, one standard approach is to study real users through interviews, user\nstudies and direct feedback, find areas where labels are systematically\ndisagreeing with users, then educate labellers about user needs through judging\nguidelines, training and monitoring. This paper introduces an alternate\napproach for improving label quality. It takes careful feedback from real\nusers, which by definition is the highest-quality first-party gold data that\ncan be derived, and develops an large language model prompt that agrees with\nthat data.\n  We present ideas and observations from deploying language models for\nlarge-scale relevance labelling at Bing, and illustrate with data from TREC. We\nhave found large language models can be effective, with accuracy as good as\nhuman labellers and similar capability to pick the hardest queries, best runs,\nand best groups. Systematic changes to the prompts make a difference in\naccuracy, but so too do simple paraphrases. To measure agreement with real\nsearchers needs high-quality ``gold'' labels, but with these we find that\nmodels produce better labels than third-party workers, for a fraction of the\ncost, and these labels let us train notably better rankers.\n",
                "链接": "https://arxiv.org/abs/2309.10621"
            },
            {
                "文章ID": "114927",
                "标题": "Practical Membership Inference Attacks against Fine-tuned Large Language\n  Models via Self-prompt Calibration",
                "作者": " Wenjie Fu,  Huandong Wang,  Chen Gao,  Guanghua Liu,  Yong Li,  Tao Jiang",
                "发布日期": "2023-12-13",
                "摘要": "  Membership Inference Attacks (MIA) aim to infer whether a target data record\nhas been utilized for model training or not. Prior attempts have quantified the\nprivacy risks of language models (LMs) via MIAs, but there is still no\nconsensus on whether existing MIA algorithms can cause remarkable privacy\nleakage on practical Large Language Models (LLMs). Existing MIAs designed for\nLMs can be classified into two categories: reference-free and reference-based\nattacks. They are both based on the hypothesis that training records\nconsistently strike a higher probability of being sampled. Nevertheless, this\nhypothesis heavily relies on the overfitting of target models, which will be\nmitigated by multiple regularization methods and the generalization of LLMs.\nThe reference-based attack seems to achieve promising effectiveness in LLMs,\nwhich measures a more reliable membership signal by comparing the probability\ndiscrepancy between the target model and the reference model. However, the\nperformance of reference-based attack is highly dependent on a reference\ndataset that closely resembles the training dataset, which is usually\ninaccessible in the practical scenario. Overall, existing MIAs are unable to\neffectively unveil privacy leakage over practical fine-tuned LLMs that are\noverfitting-free and private. We propose a Membership Inference Attack based on\nSelf-calibrated Probabilistic Variation (SPV-MIA). Specifically, since\nmemorization in LLMs is inevitable during the training process and occurs\nbefore overfitting, we introduce a more reliable membership signal,\nprobabilistic variation, which is based on memorization rather than\noverfitting. Furthermore, we introduce a self-prompt approach, which constructs\nthe dataset to fine-tune the reference model by prompting the target LLM\nitself. In this manner, the adversary can collect a dataset with a similar\ndistribution from public APIs.\n",
                "链接": "https://arxiv.org/abs/2311.06062"
            },
            {
                "文章ID": "80195",
                "标题": "Allies: Prompting Large Language Model with Beam Search",
                "作者": " Hao Sun,  Xiao Liu,  Yeyun Gong,  Yan Zhang,  Daxin Jiang,  Linjun Yang,  Nan Duan",
                "发布日期": "2023-10-20",
                "摘要": "  With the advance of large language models (LLMs), the research field of LLM\napplications becomes more and more popular and the idea of constructing\npipelines to accomplish complex tasks by stacking LLM API calls come true.\nHowever, this kind of methods face two limitations: narrow information coverage\nand low fault tolerance. In this work, we propose a novel method called ALLIES.\nGiven an input query, ALLIES leverages LLMs to iteratively generate new queries\nrelated to the original query, enabling an iterative reasoning process. By\niteratively refining and expanding the scope of the original query, ALLIES\ncaptures and utilizes hidden knowledge that may not be directly obtainable\nthrough retrieval. We take zero-shot open-domain question answering (ODQA) as\nan application scene and evaluate ALLIES on the widely-used benchmarks, such as\nNQ, WebQ and TriviaQA. The experimental results demonstrate that ALLIES\nsignificantly outperforms other zero-shot baselines, indicating its\neffectiveness in tackling those challenges. Our code is available in\nhttps://github.com/microsoft/SimXNS/tree/main/ALLIES.\n",
                "链接": "https://arxiv.org/abs/2305.14766"
            },
            {
                "文章ID": "84807",
                "标题": "Leaping through tree space: continuous phylogenetic inference for rooted\n  and unrooted trees",
                "作者": " Matthew J Penn,  Neil Scheidwasser,  Joseph Penn,  Christl A Donnelly,  David A Duchêne,  Samir Bhatt",
                "发布日期": "2023-10-05",
                "摘要": "  Phylogenetics is now fundamental in life sciences, providing insights into\nthe earliest branches of life and the origins and spread of epidemics. However,\nfinding suitable phylogenies from the vast space of possible trees remains\nchallenging. To address this problem, for the first time, we perform both tree\nexploration and inference in a continuous space where the computation of\ngradients is possible. This continuous relaxation allows for major leaps across\ntree space in both rooted and unrooted trees, and is less susceptible to\nconvergence to local minima. Our approach outperforms the current best methods\nfor inference on unrooted trees and, in simulation, accurately infers the tree\nand root in ultrametric cases. The approach is effective in cases of empirical\ndata with negligible amounts of data, which we demonstrate on the phylogeny of\njawed vertebrates. Indeed, only a few genes with an ultrametric signal were\ngenerally sufficient for resolving the major lineages of vertebrate. With\ncubic-time complexity and efficient optimisation via automatic differentiation,\nour method presents an effective way forwards for exploring the most difficult,\ndata-deficient phylogenetic questions.\n",
                "链接": "https://arxiv.org/abs/2306.05739"
            },
            {
                "文章ID": "120482",
                "标题": "A Hardware Evaluation Framework for Large Language Model Inference",
                "作者": " Hengrui Zhang,  August Ning,  Rohan Prabhakar,  David Wentzlaff",
                "发布日期": "2023-12-07",
                "摘要": "  The past year has witnessed the increasing popularity of Large Language\nModels (LLMs). Their unprecedented scale and associated high hardware cost have\nimpeded their broader adoption, calling for efficient hardware designs. With\nthe large hardware needed to simply run LLM inference, evaluating different\nhardware designs becomes a new bottleneck.\n  This work introduces LLMCompass, a hardware evaluation framework for LLM\ninference workloads. LLMCompass is fast, accurate, versatile, and able to\ndescribe and evaluate different hardware designs. LLMCompass includes a mapper\nto automatically find performance-optimal mapping and scheduling. It also\nincorporates an area-based cost model to help architects reason about their\ndesign choices. Compared to real-world hardware, LLMCompass' estimated latency\nachieves an average 10.4% error rate across various operators with various\ninput sizes and an average 4.1% error rate for LLM inference. With LLMCompass,\nsimulating a 4-NVIDIA A100 GPU node running GPT-3 175B inference can be done\nwithin 16 minutes on commodity hardware, including 26,400 rounds of the\nmapper's parameter search.\n  With the aid of LLMCompass, this work draws architectural implications and\nexplores new cost-effective hardware designs. By reducing the compute\ncapability or replacing High Bandwidth Memory (HBM) with traditional DRAM,\nthese new designs can achieve as much as 3.41x improvement in performance/cost\ncompared to an NVIDIA A100, making them promising choices for democratizing\nLLMs.\n  LLMCompass is planned to be fully open-source.\n",
                "链接": "https://arxiv.org/abs/2312.03134"
            },
            {
                "文章ID": "100283",
                "标题": "On the Planning, Search, and Memorization Capabilities of Large Language\n  Models",
                "作者": " Yunhao Yang,  Anshul Tomar",
                "发布日期": "2023-09-06",
                "摘要": "  The rapid advancement of large language models, such as the Generative\nPre-trained Transformer (GPT) series, has had significant implications across\nvarious disciplines. In this study, we investigate the potential of the\nstate-of-the-art large language model (GPT-4) for planning tasks. We explore\nits effectiveness in multiple planning subfields, highlighting both its\nstrengths and limitations. Through a comprehensive examination, we identify\nareas where large language models excel in solving planning problems and reveal\nthe constraints that limit their applicability. Our empirical analysis focuses\non GPT-4's performance in planning domain extraction, graph search path\nplanning, and adversarial planning. We then propose a way of fine-tuning a\ndomain-specific large language model to improve its Chain of Thought (CoT)\ncapabilities for the above-mentioned tasks. The results provide valuable\ninsights into the potential applications of large language models in the\nplanning domain and pave the way for future research to overcome their\nlimitations and expand their capabilities.\n",
                "链接": "https://arxiv.org/abs/2309.01868"
            },
            {
                "文章ID": "99341",
                "标题": "Efficient and Explainable Graph Neural Architecture Search via\n  Monte-Carlo Tree Search",
                "作者": " Yuya Sasaki",
                "发布日期": "2023-09-04",
                "摘要": "  Graph neural networks (GNNs) are powerful tools for performing data science\ntasks in various domains. Although we use GNNs in wide application scenarios,\nit is a laborious task for researchers and practitioners to design/select\noptimal GNN architectures in diverse graphs. To save human efforts and\ncomputational costs, graph neural architecture search (Graph NAS) has been used\nto search for a sub-optimal GNN architecture that combines existing components.\nHowever, there are no existing Graph NAS methods that satisfy explainability,\nefficiency, and adaptability to various graphs. Therefore, we propose an\nefficient and explainable Graph NAS method, called ExGNAS, which consists of\n(i) a simple search space that can adapt to various graphs and (ii) a search\nalgorithm that makes the decision process explainable. The search space\nincludes only fundamental functions that can handle homophilic and heterophilic\ngraphs. The search algorithm efficiently searches for the best GNN architecture\nvia Monte-Carlo tree search without neural models. The combination of our\nsearch space and algorithm achieves finding accurate GNN models and the\nimportant functions within the search space. We comprehensively evaluate our\nmethod compared with twelve hand-crafted GNN architectures and three Graph NAS\nmethods in four graphs. Our experimental results show that ExGNAS increases AUC\nup to 3.6 and reduces run time up to 78\\% compared with the state-of-the-art\nGraph NAS methods. Furthermore, we show ExGNAS is effective in analyzing the\ndifference between GNN architectures in homophilic and heterophilic graphs.\n",
                "链接": "https://arxiv.org/abs/2308.15734"
            },
            {
                "文章ID": "21115",
                "标题": "TreEnhance: A Tree Search Method For Low-Light Image Enhancement",
                "作者": " Marco Cotogni,  Claudio Cusano",
                "发布日期": "2022-12-15",
                "摘要": "  In this paper we present TreEnhance, an automatic method for low-light image\nenhancement capable of improving the quality of digital images. The method\ncombines tree search theory, and in particular the Monte Carlo Tree Search\n(MCTS) algorithm, with deep reinforcement learning. Given as input a low-light\nimage, TreEnhance produces as output its enhanced version together with the\nsequence of image editing operations used to obtain it. During the training\nphase, the method repeatedly alternates two main phases: a generation phase,\nwhere a modified version of MCTS explores the space of image editing operations\nand selects the most promising sequence, and an optimization phase, where the\nparameters of a neural network, implementing the enhancement policy, are\nupdated.\n  Two different inference solutions are proposed for the enhancement of new\nimages: one is based on MCTS and is more accurate but more time and memory\nconsuming; the other directly applies the learned policy and is faster but\nslightly less precise. As a further contribution, we propose a guided search\nstrategy that \"reverses\" the enhancement procedure that a photo editor applied\nto a given input image. Unlike other methods from the state of the art,\nTreEnhance does not pose any constraint on the image resolution and can be used\nin a variety of scenarios with minimal tuning. We tested the method on two\ndatasets: the Low-Light dataset and the Adobe Five-K dataset obtaining good\nresults from both a qualitative and a quantitative point of view.\n",
                "链接": "https://arxiv.org/abs/2205.12639"
            },
            {
                "文章ID": "93547",
                "标题": "Cross-Modal Concept Learning and Inference for Vision-Language Models",
                "作者": " Yi Zhang,  Ce Zhang,  Yushun Tang,  Zhihai He",
                "发布日期": "2023-07-31",
                "摘要": "  Large-scale pre-trained Vision-Language Models (VLMs), such as CLIP,\nestablish the correlation between texts and images, achieving remarkable\nsuccess on various downstream tasks with fine-tuning. In existing fine-tuning\nmethods, the class-specific text description is matched against the whole\nimage. We recognize that this whole image matching is not effective since\nimages from the same class often contain a set of different semantic objects,\nand an object further consists of a set of semantic parts or concepts.\nIndividual semantic parts or concepts may appear in image samples from\ndifferent classes. To address this issue, in this paper, we develop a new\nmethod called cross-model concept learning and inference (CCLI). Using the\npowerful text-image correlation capability of CLIP, our method automatically\nlearns a large set of distinctive visual concepts from images using a set of\nsemantic text concepts. Based on these visual concepts, we construct a\ndiscriminative representation of images and learn a concept inference network\nto perform downstream image classification tasks, such as few-shot learning and\ndomain generalization. Extensive experimental results demonstrate that our CCLI\nmethod is able to improve the performance upon the current state-of-the-art\nmethods by large margins, for example, by up to 8.0% improvement on few-shot\nlearning and by up to 1.3% for domain generalization.\n",
                "链接": "https://arxiv.org/abs/2307.15460"
            },
            {
                "文章ID": "66115",
                "标题": "Large Language Models Know Your Contextual Search Intent: A Prompting\n  Framework for Conversational Search",
                "作者": " Kelong Mao,  Zhicheng Dou,  Fengran Mo,  Jiewen Hou,  Haonan Chen,  Hongjin Qian",
                "发布日期": "2023-10-23",
                "摘要": "  Precisely understanding users' contextual search intent has been an important\nchallenge for conversational search. As conversational search sessions are much\nmore diverse and long-tailed, existing methods trained on limited data still\nshow unsatisfactory effectiveness and robustness to handle real conversational\nsearch scenarios. Recently, large language models (LLMs) have demonstrated\namazing capabilities for text generation and conversation understanding. In\nthis work, we present a simple yet effective prompting framework, called\nLLM4CS, to leverage LLMs as a text-based search intent interpreter to help\nconversational search. Under this framework, we explore three prompting methods\nto generate multiple query rewrites and hypothetical responses, and propose to\naggregate them into an integrated representation that can robustly represent\nthe user's real contextual search intent. Extensive automatic evaluations and\nhuman evaluations on three widely used conversational search benchmarks,\nincluding CAsT-19, CAsT-20, and CAsT-21, demonstrate the remarkable performance\nof our simple LLM4CS framework compared with existing methods and even using\nhuman rewrites. Our findings provide important evidence to better understand\nand leverage LLMs for conversational search.\n",
                "链接": "https://arxiv.org/abs/2303.06573"
            },
            {
                "文章ID": "123538",
                "标题": "LLM in a flash: Efficient Large Language Model Inference with Limited\n  Memory",
                "作者": " Keivan Alizadeh,  Iman Mirzadeh,  Dmitry Belenko,  Karen Khatamifard,  Minsik Cho,  Carlo C Del Mundo,  Mohammad Rastegari,  Mehrdad Farajtabar",
                "发布日期": "2023-12-20",
                "摘要": "  Large language models (LLMs) are central to modern natural language\nprocessing, delivering exceptional performance in various tasks. However, their\nintensive computational and memory requirements present challenges, especially\nfor devices with limited DRAM capacity. This paper tackles the challenge of\nefficiently running LLMs that exceed the available DRAM capacity by storing the\nmodel parameters on flash memory but bringing them on demand to DRAM. Our\nmethod involves constructing an inference cost model that harmonizes with the\nflash memory behavior, guiding us to optimize in two critical areas: reducing\nthe volume of data transferred from flash and reading data in larger, more\ncontiguous chunks. Within this flash memory-informed framework, we introduce\ntwo principal techniques. First, \"windowing'\" strategically reduces data\ntransfer by reusing previously activated neurons, and second, \"row-column\nbundling\", tailored to the sequential data access strengths of flash memory,\nincreases the size of data chunks read from flash memory. These methods\ncollectively enable running models up to twice the size of the available DRAM,\nwith a 4-5x and 20-25x increase in inference speed compared to naive loading\napproaches in CPU and GPU, respectively. Our integration of sparsity awareness,\ncontext-adaptive loading, and a hardware-oriented design paves the way for\neffective inference of LLMs on devices with limited memory.\n",
                "链接": "https://arxiv.org/abs/2312.11514"
            },
            {
                "文章ID": "108690",
                "标题": "User Inference Attacks on Large Language Models",
                "作者": " Nikhil Kandpal,  Krishna Pillutla,  Alina Oprea,  Peter Kairouz,  Christopher A. Choquette-Choo,  Zheng Xu",
                "发布日期": "2023-10-16",
                "摘要": "  Fine-tuning is a common and effective method for tailoring large language\nmodels (LLMs) to specialized tasks and applications. In this paper, we study\nthe privacy implications of fine-tuning LLMs on user data. To this end, we\ndefine a realistic threat model, called user inference, wherein an attacker\ninfers whether or not a user's data was used for fine-tuning. We implement\nattacks for this threat model that require only a small set of samples from a\nuser (possibly different from the samples used for training) and black-box\naccess to the fine-tuned LLM. We find that LLMs are susceptible to user\ninference attacks across a variety of fine-tuning datasets, at times with near\nperfect attack success rates. Further, we investigate which properties make\nusers vulnerable to user inference, finding that outlier users (i.e. those with\ndata distributions sufficiently different from other users) and users who\ncontribute large quantities of data are most susceptible to attack. Finally, we\nexplore several heuristics for mitigating privacy attacks. We find that\ninterventions in the training algorithm, such as batch or per-example gradient\nclipping and early stopping fail to prevent user inference. However, limiting\nthe number of fine-tuning samples from a single user can reduce attack\neffectiveness, albeit at the cost of reducing the total amount of fine-tuning\ndata.\n",
                "链接": "https://arxiv.org/abs/2310.09266"
            },
            {
                "文章ID": "102013",
                "标题": "Tree of Uncertain Thoughts Reasoning for Large Language Models",
                "作者": " Shentong Mo,  Miao Xin",
                "发布日期": "2023-09-15",
                "摘要": "  While the recently introduced Tree of Thoughts (ToT) has heralded\nadvancements in allowing Large Language Models (LLMs) to reason through\nforesight and backtracking for global decision-making, it has overlooked the\ninherent local uncertainties in intermediate decision points or \"thoughts\".\nThese local uncertainties, intrinsic to LLMs given their potential for diverse\nresponses, remain a significant concern in the reasoning process. Addressing\nthis pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) - a\nreasoning framework tailored for LLMs. Our TouT effectively leverages Monte\nCarlo Dropout to quantify uncertainty scores associated with LLMs' diverse\nlocal responses at these intermediate steps. By marrying this local uncertainty\nquantification with global search algorithms, TouT enhances the model's\nprecision in response generation. We substantiate our approach with rigorous\nexperiments on two demanding planning tasks: Game of 24 and Mini Crosswords.\nThe empirical evidence underscores TouT's superiority over both ToT and\nchain-of-thought prompting methods.\n",
                "链接": "https://arxiv.org/abs/2309.07694"
            },
            {
                "文章ID": "35864",
                "标题": "Petals: Collaborative Inference and Fine-tuning of Large Models",
                "作者": " Alexander Borzunov,  Dmitry Baranchuk,  Tim Dettmers,  Max Ryabinin,  Younes Belkada,  Artem Chumachenko,  Pavel Samygin,  Colin Raffel",
                "发布日期": "2023-03-06",
                "摘要": "  Many NLP tasks benefit from using large language models (LLMs) that often\nhave more than 100 billion parameters. With the release of BLOOM-176B and\nOPT-175B, everyone can download pretrained models of this scale. Still, using\nthese models requires high-end hardware unavailable to many researchers. In\nsome cases, LLMs can be used more affordably via RAM offloading or hosted APIs.\nHowever, these techniques have innate limitations: offloading is too slow for\ninteractive inference, while APIs are not flexible enough for research that\nrequires access to weights, attention or logits. In this work, we propose\nPetals - a system for inference and fine-tuning of large models collaboratively\nby joining the resources of multiple parties. We demonstrate that this strategy\noutperforms offloading for very large models, running inference of BLOOM-176B\non consumer GPUs with $\\approx$ 1 step per second, which is enough for many\ninteractive LLM applications. Unlike most inference APIs, Petals also natively\nexposes hidden states of served models, allowing to train and share custom\nmodel extensions based on efficient fine-tuning methods.\n",
                "链接": "https://arxiv.org/abs/2209.01188"
            },
            {
                "文章ID": "95604",
                "标题": "Integrating large language models and active inference to understand eye\n  movements in reading and dyslexia",
                "作者": " Francesco Donnarumma,  Mirco Frosolone,  Giovanni Pezzulo",
                "发布日期": "2023-08-10",
                "摘要": "  We present a novel computational model employing hierarchical active\ninference to simulate reading and eye movements. The model characterizes\nlinguistic processing as inference over a hierarchical generative model,\nfacilitating predictions and inferences at various levels of granularity, from\nsyllables to sentences.\n  Our approach combines the strengths of large language models for realistic\ntextual predictions and active inference for guiding eye movements to\ninformative textual information, enabling the testing of predictions. The model\nexhibits proficiency in reading both known and unknown words and sentences,\nadhering to the distinction between lexical and nonlexical routes in dual-route\ntheories of reading. Notably, our model permits the exploration of maladaptive\ninference effects on eye movements during reading, such as in dyslexia. To\nsimulate this condition, we attenuate the contribution of priors during the\nreading process, leading to incorrect inferences and a more fragmented reading\nstyle, characterized by a greater number of shorter saccades. This alignment\nwith empirical findings regarding eye movements in dyslexic individuals\nhighlights the model's potential to aid in understanding the cognitive\nprocesses underlying reading and eye movements, as well as how reading deficits\nassociated with dyslexia may emerge from maladaptive predictive processing.\n  In summary, our model represents a significant advancement in comprehending\nthe intricate cognitive processes involved in reading and eye movements, with\npotential implications for understanding and addressing dyslexia through the\nsimulation of maladaptive inference. It may offer valuable insights into this\ncondition and contribute to the development of more effective interventions for\ntreatment.\n",
                "链接": "https://arxiv.org/abs/2308.04941"
            },
            {
                "文章ID": "78147",
                "标题": "Controllable Speaking Styles Using a Large Language Model",
                "作者": " Atli Thor Sigurgeirsson,  Simon King",
                "发布日期": "2023-09-20",
                "摘要": "  Reference-based Text-to-Speech (TTS) models can generate multiple,\nprosodically-different renditions of the same target text. Such models jointly\nlearn a latent acoustic space during training, which can be sampled from during\ninference. Controlling these models during inference typically requires finding\nan appropriate reference utterance, which is non-trivial.\n  Large generative language models (LLMs) have shown excellent performance in\nvarious language-related tasks. Given only a natural language query text (the\nprompt), such models can be used to solve specific, context-dependent tasks.\nRecent work in TTS has attempted similar prompt-based control of novel speaking\nstyle generation. Those methods do not require a reference utterance and can,\nunder ideal conditions, be controlled with only a prompt. But existing methods\ntypically require a prompt-labelled speech corpus for jointly training a\nprompt-conditioned encoder.\n  In contrast, we instead employ an LLM to directly suggest prosodic\nmodifications for a controllable TTS model, using contextual information\nprovided in the prompt. The prompt can be designed for a multitude of tasks.\nHere, we give two demonstrations: control of speaking style; prosody\nappropriate for a given dialogue context. The proposed method is rated most\nappropriate in 50% of cases vs. 31% for a baseline model.\n",
                "链接": "https://arxiv.org/abs/2305.10321"
            },
            {
                "文章ID": "100689",
                "标题": "No Train Still Gain. Unleash Mathematical Reasoning of Large Language\n  Models with Monte Carlo Tree Search Guided by Energy Function",
                "作者": " Haotian Xu",
                "发布日期": "2023-09-13",
                "摘要": "  Large language models (LLMs) demonstrate impressive language understanding\nand contextual learning abilities, making them suitable for natural language\nprocessing (NLP) tasks and complex mathematical reasoning. However, when\napplied to mathematical reasoning tasks, LLMs often struggle to generate\ncorrect reasoning steps and answers despite having high probabilities for the\nsolutions. To overcome this limitation and enhance the mathematical reasoning\ncapabilities of fine-tuned LLMs without additional fine-tuning steps, we\npropose a method that incorporates Monte Carlo Tree Search (MCTS) and a\nlightweight energy function to rank decision steps and enable immediate\nreaction and precise reasoning. Specifically, we re-formulate the fine-tuned\nLLMs into a Residual-based Energy Model (Residual-EBM) and employ noise\ncontrastive estimation to estimate the energy function's parameters. We then\nutilize MCTS with the energy function as a path verifier to search the output\nspace and evaluate the reasoning path. Through extensive experiments on two\nmathematical reasoning benchmarks, GSM8k and AQUA-RAT, we demonstrate the\nexceptional capabilities of our method, which significantly improves the pass@1\nmetric of the fine-tuned model without requiring additional fine-tuning or\nreinforcement learning with human feedback alignment.\n",
                "链接": "https://arxiv.org/abs/2309.03224"
            },
            {
                "文章ID": "9684",
                "标题": "The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for\n  Large Language Models",
                "作者": " Eldar Kurtic,  Daniel Campos,  Tuan Nguyen,  Elias Frantar,  Mark Kurtz,  Benjamin Fineran,  Michael Goin,  Dan Alistarh",
                "发布日期": "2022-10-19",
                "摘要": "  Transformer-based language models have become a key building block for\nnatural language processing. While these models are extremely accurate, they\ncan be too large and computationally intensive to run on standard deployments.\nA variety of compression methods, including distillation, quantization,\nstructured and unstructured pruning are known to decrease model size and\nincrease inference speed, with low accuracy loss. In this context, this paper's\ncontributions are two-fold. We perform an in-depth study of the\naccuracy-compression trade-off for unstructured weight pruning of BERT models.\nWe introduce Optimal BERT Surgeon (oBERT), an efficient and accurate weight\npruning method based on approximate second-order information, which we show to\nyield state-of-the-art results in both stages of language tasks: pre-training\nand fine-tuning. Specifically, oBERT extends existing work on unstructured\nsecond-order pruning by allowing for pruning blocks of weights, and by being\napplicable at the BERT scale. Second, we investigate the impact of this pruning\nmethod when compounding compression approaches to obtain highly compressed but\naccurate models for deployment on edge devices. These models significantly push\nboundaries of the current state-of-the-art sparse BERT models with respect to\nall metrics: model size, inference speed and task accuracy. For example,\nrelative to the dense BERT-base, we obtain 10x model size compression (in MB)\nwith < 1% accuracy drop, 10x CPU-inference speedup with < 2% accuracy drop, and\n29x CPU-inference speedup with < 7.5% accuracy drop. Our code, fully integrated\nwith Transformers and SparseML, is available at\nhttps://github.com/neuralmagic/sparseml/tree/main/research/optimal_BERT_surgeon_oBERT.\n",
                "链接": "https://arxiv.org/abs/2203.07259"
            },
            {
                "文章ID": "122343",
                "标题": "Distributed Inference and Fine-tuning of Large Language Models Over The\n  Internet",
                "作者": " Alexander Borzunov,  Max Ryabinin,  Artem Chumachenko,  Dmitry Baranchuk,  Tim Dettmers,  Younes Belkada,  Pavel Samygin,  Colin Raffel",
                "发布日期": "2023-12-14",
                "摘要": "  Large language models (LLMs) are useful in many NLP tasks and become more\ncapable with size, with the best open-source models having over 50 billion\nparameters. However, using these 50B+ models requires high-end hardware, making\nthem inaccessible to most researchers. In this work, we investigate methods for\ncost-efficient inference and fine-tuning of LLMs, comparing local and\ndistributed strategies. We observe that a large enough model (50B+) can run\nefficiently even on geodistributed devices in a consumer-grade network. This\ncould allow running LLM efficiently by pooling together idle compute resources\nof multiple research groups and volunteers. We address two open problems: (1)\nhow to perform inference and fine-tuning reliably if any device can disconnect\nabruptly and (2) how to partition LLMs between devices with uneven hardware,\njoining and leaving at will. In order to do that, we develop special\nfault-tolerant inference algorithms and load-balancing protocols that\nautomatically assign devices to maximize the total system throughput. We\nshowcase these algorithms in Petals - a decentralized system that runs Llama 2\n(70B) and BLOOM (176B) over the Internet up to 10x faster than offloading for\ninteractive generation. We evaluate the performance of our system in simulated\nconditions and a real-world setup spanning two continents.\n",
                "链接": "https://arxiv.org/abs/2312.08361"
            },
            {
                "文章ID": "108619",
                "标题": "KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level\n  Hallucination Detection",
                "作者": " Sehyun Choi,  Tianqing Fang,  Zhaowei Wang,  Yangqiu Song",
                "发布日期": "2023-10-16",
                "摘要": "  Large Language Models (LLMs) have demonstrated remarkable human-level natural\nlanguage generation capabilities. However, their potential to generate\nmisinformation, often called the hallucination problem, poses a significant\nrisk to their deployment. A common approach to address this issue is to\nretrieve relevant knowledge and fine-tune the LLM with the knowledge in its\ninput. Unfortunately, this method incurs high training costs and may cause\ncatastrophic forgetting for multi-tasking models. To overcome these\nlimitations, we propose a knowledge-constrained decoding method called KCTS\n(Knowledge-Constrained Tree Search), which guides a frozen LM to generate text\naligned with the reference knowledge at each decoding step using a knowledge\nclassifier score and MCTS (Monte-Carlo Tree Search). To adapt the\nsequence-level knowledge classifier to token-level guidance, we also propose a\nnovel token-level hallucination detection method called RIPA (Reward Inflection\nPoint Approximation). Our empirical results on knowledge-grounded dialogue and\nabstractive summarization demonstrate the strength of KCTS as a plug-and-play,\nmodel-agnostic decoding method that can effectively reduce hallucinations in\nnatural language generation.\n",
                "链接": "https://arxiv.org/abs/2310.09044"
            },
            {
                "文章ID": "42266",
                "标题": "Developing a general-purpose clinical language inference model from a\n  large corpus of clinical notes",
                "作者": " Madhumita Sushil,  Dana Ludwig,  Atul J. Butte,  Vivek A. Rudrapatna",
                "发布日期": "2022-10-14",
                "摘要": "  Several biomedical language models have already been developed for clinical\nlanguage inference. However, these models typically utilize general\nvocabularies and are trained on relatively small clinical corpora. We sought to\nevaluate the impact of using a domain-specific vocabulary and a large clinical\ntraining corpus on the performance of these language models in clinical\nlanguage inference. We trained a Bidirectional Encoder Decoder from\nTransformers (BERT) model using a diverse, deidentified corpus of 75 million\ndeidentified clinical notes authored at the University of California, San\nFrancisco (UCSF). We evaluated this model on several clinical language\ninference benchmark tasks: clinical and temporal concept recognition, relation\nextraction and medical language inference. We also evaluated our model on two\ntasks using discharge summaries from UCSF: diagnostic code assignment and\ntherapeutic class inference. Our model performs at par with the best publicly\navailable biomedical language models of comparable sizes on the public\nbenchmark tasks, and is significantly better than these models in a\nwithin-system evaluation on the two tasks using UCSF data. The use of in-domain\nvocabulary appears to improve the encoding of longer documents. The use of\nlarge clinical corpora appears to enhance document encoding and inferential\naccuracy. However, further research is needed to improve abbreviation\nresolution, and numerical, temporal, and implicitly causal inference.\n",
                "链接": "https://arxiv.org/abs/2210.06566"
            },
            {
                "文章ID": "119522",
                "标题": "LinguaLinked: A Distributed Large Language Model Inference System for\n  Mobile Devices",
                "作者": " Junchen Zhao,  Yurun Song,  Simeng Liu,  Ian G. Harris,  Sangeetha Abdu Jyothi",
                "发布日期": "2023-12-04",
                "摘要": "  Deploying Large Language Models (LLMs) locally on mobile devices presents a\nsignificant challenge due to their extensive memory requirements. In this\npaper, we introduce LinguaLinked, a system for decentralized, distributed LLM\ninference on mobile devices. LinguaLinked enables collaborative execution of\nthe inference task across multiple trusted devices. LinguaLinked ensures data\nprivacy by processing information locally. LinguaLinked uses three key\nstrategies. First, an optimized model assignment technique segments LLMs and\nuses linear optimization to align segments with each device's capabilities.\nSecond, an optimized data transmission mechanism ensures efficient and\nstructured data flow between model segments while also maintaining the\nintegrity of the original model structure. Finally, LinguaLinked incorporates a\nruntime load balancer that actively monitors and redistributes tasks among\nmobile devices to prevent bottlenecks, enhancing the system's overall\nefficiency and responsiveness. We demonstrate that LinguaLinked facilitates\nefficient LLM inference while maintaining consistent throughput and minimal\nlatency through extensive testing across various mobile devices, from high-end\nto low-end Android devices. In our evaluations, compared to the baseline,\nLinguaLinked achieves an inference performance acceleration of $1.11\\times$ to\n$1.61\\times$ in single-threaded settings, $1.73\\times$ to $2.65\\times$ with\nmulti-threading. Additionally, runtime load balancing yields an overall\ninference acceleration of $1.29\\times$ to $1.32\\times$.\n",
                "链接": "https://arxiv.org/abs/2312.00388"
            },
            {
                "文章ID": "123724",
                "标题": "Fluctuation-based Adaptive Structured Pruning for Large Language Models",
                "作者": " Yongqi An,  Xu Zhao,  Tao Yu,  Ming Tang,  Jinqiao Wang",
                "发布日期": "2023-12-20",
                "摘要": "  Network Pruning is a promising way to address the huge computing resource\ndemands of the deployment and inference of Large Language Models (LLMs).\nRetraining-free is important for LLMs' pruning methods. However, almost all of\nthe existing retraining-free pruning approaches for LLMs focus on unstructured\npruning, which requires specific hardware support for acceleration. In this\npaper, we propose a novel retraining-free structured pruning framework for\nLLMs, named FLAP (FLuctuation-based Adaptive Structured Pruning). It is\nhardware-friendly by effectively reducing storage and enhancing inference\nspeed. For effective structured pruning of LLMs, we highlight three critical\nelements that demand the utmost attention: formulating structured importance\nmetrics, adaptively searching the global compressed model, and implementing\ncompensation mechanisms to mitigate performance loss. First, FLAP determines\nwhether the output feature map is easily recoverable when a column of weight is\nremoved, based on the fluctuation pruning metric. Then it standardizes the\nimportance scores to adaptively determine the global compressed model\nstructure. At last, FLAP adds additional bias terms to recover the output\nfeature maps using the baseline values. We thoroughly evaluate our approach on\na variety of language benchmarks. Without any retraining, our method\nsignificantly outperforms the state-of-the-art methods, including LLM-Pruner\nand the extension of Wanda in structured pruning. The code is released at\nhttps://github.com/CASIA-IVA-Lab/FLAP.\n",
                "链接": "https://arxiv.org/abs/2312.11983"
            },
            {
                "文章ID": "121137",
                "标题": "EE-LLM: Large-Scale Training and Inference of Early-Exit Large Language\n  Models with 3D Parallelism",
                "作者": " Yanxi Chen,  Xuchen Pan,  Yaliang Li,  Bolin Ding,  Jingren Zhou",
                "发布日期": "2023-12-11",
                "摘要": "  We present EE-LLM, a framework for large-scale training and inference of\nearly-exit large language models (LLMs). While recent works have shown\npreliminary evidence for the efficacy of early exiting in accelerating LLM\ninference, EE-LLM makes a foundational step towards scaling up early-exit LLMs\nby supporting their training and inference with massive 3D parallelism. Built\nupon Megatron-LM, EE-LLM implements a variety of algorithmic innovations and\nperformance optimizations tailored to early exiting, including a lightweight\nmethod that facilitates backpropagation for the early-exit training objective\nwith pipeline parallelism, techniques of leveraging idle resources in the\noriginal pipeline schedule for computation related to early-exit layers, and\ntwo approaches of early-exit inference that are compatible with KV caching for\nautoregressive generation. Our analytical and empirical study shows that EE-LLM\nachieves great training efficiency with negligible computational overhead\ncompared to standard LLM training, as well as outstanding inference speedup\nwithout compromising output quality. To facilitate further research and\nadoption, we release EE-LLM at https://github.com/pan-x-c/EE-LLM.\n",
                "链接": "https://arxiv.org/abs/2312.04916"
            },
            {
                "文章ID": "19994",
                "标题": "Selection-Inference: Exploiting Large Language Models for Interpretable\n  Logical Reasoning",
                "作者": " Antonia Creswell,  Murray Shanahan,  Irina Higgins",
                "发布日期": "2022-05-20",
                "摘要": "  Large language models (LLMs) have been shown to be capable of impressive\nfew-shot generalisation to new tasks. However, they still tend to perform\npoorly on multi-step logical reasoning problems. Here we carry out a\ncomprehensive evaluation of LLMs on 50 tasks that probe different aspects of\nlogical reasoning. We show that language models tend to perform fairly well at\nsingle step inference or entailment tasks, but struggle to chain together\nmultiple reasoning steps to solve more complex problems. In light of this, we\npropose a Selection-Inference (SI) framework that exploits pre-trained LLMs as\ngeneral processing modules, and alternates between selection and inference to\ngenerate a series of interpretable, casual reasoning steps leading to the final\nanswer. We show that a 7B parameter LLM used within the SI framework in a\n5-shot generalisation setting, with no fine-tuning, yields a performance\nimprovement of over 100% compared to an equivalent vanilla baseline on a suite\nof 10 logical reasoning tasks. The same model in the same setting even\noutperforms a significantly larger 280B parameter baseline on the same suite of\ntasks. Moreover, answers produced by the SI framework are accompanied by a\ncausal natural-language-based reasoning trace, which has important implications\nfor the safety and trustworthiness of the system.\n",
                "链接": "https://arxiv.org/abs/2205.09712"
            },
            {
                "文章ID": "107406",
                "标题": "LLMLingua: Compressing Prompts for Accelerated Inference of Large\n  Language Models",
                "作者": " Huiqiang Jiang,  Qianhui Wu,  Chin-Yew Lin,  Yuqing Yang,  Lili Qiu",
                "发布日期": "2023-12-07",
                "摘要": "  Large language models (LLMs) have been applied in various applications due to\ntheir astonishing capabilities. With advancements in technologies such as\nchain-of-thought (CoT) prompting and in-context learning (ICL), the prompts fed\nto LLMs are becoming increasingly lengthy, even exceeding tens of thousands of\ntokens. To accelerate model inference and reduce cost, this paper presents\nLLMLingua, a coarse-to-fine prompt compression method that involves a budget\ncontroller to maintain semantic integrity under high compression ratios, a\ntoken-level iterative compression algorithm to better model the interdependence\nbetween compressed contents, and an instruction tuning based method for\ndistribution alignment between language models. We conduct experiments and\nanalysis over four datasets from different scenarios, i.e., GSM8K, BBH,\nShareGPT, and Arxiv-March23; showing that the proposed approach yields\nstate-of-the-art performance and allows for up to 20x compression with little\nperformance loss. Our code is available at https://aka.ms/LLMLingua.\n",
                "链接": "https://arxiv.org/abs/2310.05736"
            },
            {
                "文章ID": "77185",
                "标题": "Synergistic Interplay between Search and Large Language Models for\n  Information Retrieval",
                "作者": " Jiazhan Feng,  Chongyang Tao,  Xiubo Geng,  Tao Shen,  Can Xu,  Guodong Long,  Dongyan Zhao,  Daxin Jiang",
                "发布日期": "2023-12-13",
                "摘要": "  Information retrieval (IR) plays a crucial role in locating relevant\nresources from vast amounts of data, and its applications have evolved from\ntraditional knowledge bases to modern retrieval models (RMs). The emergence of\nlarge language models (LLMs) has further revolutionized the IR field by\nenabling users to interact with search systems in natural languages. In this\npaper, we explore the advantages and disadvantages of LLMs and RMs,\nhighlighting their respective strengths in understanding user-issued queries\nand retrieving up-to-date information. To leverage the benefits of both\nparadigms while circumventing their limitations, we propose InteR, a novel\nframework that facilitates information refinement through synergy between RMs\nand LLMs. InteR allows RMs to expand knowledge in queries using LLM-generated\nknowledge collections and enables LLMs to enhance prompt formulation using\nretrieved documents. This iterative refinement process augments the inputs of\nRMs and LLMs, leading to more accurate retrieval. Experiments on large-scale\nretrieval benchmarks involving web search and low-resource retrieval tasks\ndemonstrate that InteR achieves overall superior zero-shot retrieval\nperformance compared to state-of-the-art methods, even those using relevance\njudgment. Source code is available at https://github.com/Cyril-JZ/InteR\n",
                "链接": "https://arxiv.org/abs/2305.07402"
            },
            {
                "文章ID": "102815",
                "标题": "RadOnc-GPT: A Large Language Model for Radiation Oncology",
                "作者": " Zhengliang Liu,  Peilong Wang,  Yiwei Li,  Jason Holmes,  Peng Shu,  Lian Zhang,  Chenbin Liu,  Ninghao Liu,  Dajiang Zhu,  Xiang Li,  Quanzheng Li,  Samir H. Patel,  Terence T. Sio,  Tianming Liu,  Wei Liu",
                "发布日期": "2023-11-07",
                "摘要": "  This paper presents RadOnc-GPT, a large language model specialized for\nradiation oncology through advanced tuning methods. RadOnc-GPT was finetuned on\na large dataset of radiation oncology patient records from the Mayo Clinic in\nArizona. The model employs instruction tuning on three key tasks - generating\nradiotherapy treatment regimens, determining optimal radiation modalities, and\nproviding diagnostic descriptions/ICD codes based on patient diagnostic\ndetails. Evaluations conducted by comparing RadOnc-GPT outputs to general large\nlanguage model outputs showed higher ROUGE scores in these three tasks. The\nstudy demonstrated the potential of using large language models fine-tuned\nusing domain-specific knowledge like RadOnc-GPT to achieve transformational\ncapabilities in highly specialized healthcare fields such as radiation\noncology. However, our model's clinical relevance requires confirmation, and it\nspecializes in only the aforementioned three specific tasks and lacks broader\napplicability. Furthermore, its evaluation through ROUGE scores might not\nreflect the true semantic and clinical accuracy - challenges we intend to\naddress in future research.\n",
                "链接": "https://arxiv.org/abs/2309.10160"
            },
            {
                "文章ID": "57741",
                "标题": "Batch Prompting: Efficient Inference with Large Language Model APIs",
                "作者": " Zhoujun Cheng,  Jungo Kasai,  Tao Yu",
                "发布日期": "2023-10-25",
                "摘要": "  Performing inference on large volumes of samples with large language models\n(LLMs) can be computationally and financially costly in industry and real-world\nuse. We propose batch prompting, a simple yet effective prompting approach that\nenables the LLM to run inference in batches, instead of one sample at a time.\nOur method reduces both token and time costs while retaining downstream\nperformance. We theoretically demonstrate that under a few-shot in-context\nlearning setting, the inference costs decrease almost inverse linearly with the\nnumber of samples in each batch. We extensively validate the effectiveness of\nbatch prompting on ten datasets across commonsense QA, arithmetic reasoning,\nand NLI/NLU: batch prompting significantly~(up to 5x with six samples in batch)\nreduces the LLM (Codex) inference token and time costs while achieving better\nor comparable performance. For state-of-the-art Chat-based LLMs, e.g., GPT-3.5\nand GPT-4, we show the benefits of batch prompting also hold. Further analysis\nshows that the number of samples in each batch and the complexity of tasks\naffect its performance. Moreover, batch prompting can be applied across\ndifferent reasoning methods using LLMs. Our code can be found at the site\nhttps://github.com/xlang-ai/batch-prompting.\n",
                "链接": "https://arxiv.org/abs/2301.08721"
            },
            {
                "文章ID": "28252",
                "标题": "Meta-Learning the Difference: Preparing Large Language Models for\n  Efficient Adaptation",
                "作者": " Zejiang Hou,  Julian Salazar,  George Polovets",
                "发布日期": "2022-07-11",
                "摘要": "  Large pretrained language models (PLMs) are often domain- or task-adapted via\nfine-tuning or prompting. Finetuning requires modifying all of the parameters\nand having enough data to avoid overfitting while prompting requires no\ntraining and few examples but limits performance. Instead, we prepare PLMs for\ndata- and parameter-efficient adaptation by learning to learn the difference\nbetween general and adapted PLMs. This difference is expressed in terms of\nmodel weights and sublayer structure through our proposed dynamic low-rank\nreparameterization and learned architecture controller. Experiments on few-shot\ndialogue completion, low-resource abstractive summarization, and multi-domain\nlanguage modeling show improvements in adaptation time and performance over\ndirect finetuning or preparation via domain-adaptive pretraining. Ablations\nshow our task-adaptive reparameterization (TARP) and model search (TAMS)\ncomponents individually improve on other parameter-efficient transfer like\nadapters and structure-learning methods like learned sparsification.\n",
                "链接": "https://arxiv.org/abs/2207.03509"
            },
            {
                "文章ID": "63456",
                "标题": "Robot Behavior-Tree-Based Task Generation with Large Language Models",
                "作者": " Yue Cao,  C. S. George Lee",
                "发布日期": "2023-02-28",
                "摘要": "  Nowadays, the behavior tree is gaining popularity as a representation for\nrobot tasks due to its modularity and reusability. Designing behavior-tree\ntasks manually is time-consuming for robot end-users, thus there is a need for\ninvestigating automatic behavior-tree-based task generation. Prior\nbehavior-tree-based task generation approaches focus on fixed primitive tasks\nand lack generalizability to new task domains. To cope with this issue, we\npropose a novel behavior-tree-based task generation approach that utilizes\nstate-of-the-art large language models. We propose a Phase-Step prompt design\nthat enables a hierarchical-structured robot task generation and further\nintegrate it with behavior-tree-embedding-based search to set up the\nappropriate prompt. In this way, we enable an automatic and cross-domain\nbehavior-tree task generation. Our behavior-tree-based task generation approach\ndoes not require a set of pre-defined primitive tasks. End-users only need to\ndescribe an abstract desired task and our proposed approach can swiftly\ngenerate the corresponding behavior tree. A full-process case study is provided\nto demonstrate our proposed approach. An ablation study is conducted to\nevaluate the effectiveness of our Phase-Step prompts. Assessment on Phase-Step\nprompts and the limitation of large language models are presented and\ndiscussed.\n",
                "链接": "https://arxiv.org/abs/2302.12927"
            },
            {
                "文章ID": "75634",
                "标题": "Inference at Scale Significance Testing for Large Search and\n  Recommendation Experiments",
                "作者": " Ngozi Ihemelandu,  Michael D. Ekstrand",
                "发布日期": "2023-05-15",
                "摘要": "  A number of information retrieval studies have been done to assess which\nstatistical techniques are appropriate for comparing systems. However, these\nstudies are focused on TREC-style experiments, which typically have fewer than\n100 topics. There is no similar line of work for large search and\nrecommendation experiments; such studies typically have thousands of topics or\nusers and much sparser relevance judgements, so it is not clear if\nrecommendations for analyzing traditional TREC experiments apply to these\nsettings. In this paper, we empirically study the behavior of significance\ntests with large search and recommendation evaluation data. Our results show\nthat the Wilcoxon and Sign tests show significantly higher Type-1 error rates\nfor large sample sizes than the bootstrap, randomization and t-tests, which\nwere more consistent with the expected error rate. While the statistical tests\ndisplayed differences in their power for smaller sample sizes, they showed no\ndifference in their power for large sample sizes. We recommend the sign and\nWilcoxon tests should not be used to analyze large scale evaluation results.\nOur result demonstrate that with Top-N recommendation and large search\nevaluation data, most tests would have a 100% chance of finding statistically\nsignificant results. Therefore, the effect size should be used to determine\npractical or scientific significance.\n",
                "链接": "https://arxiv.org/abs/2305.02461"
            },
            {
                "文章ID": "121134",
                "标题": "Ophtha-LLaMA2: A Large Language Model for Ophthalmology",
                "作者": " Huan Zhao,  Qian Ling,  Yi Pan,  Tianyang Zhong,  Jin-Yu Hu,  Junjie Yao,  Fengqian Xiao,  Zhenxiang Xiao,  Yutong Zhang,  San-Hua Xu,  Shi-Nan Wu,  Min Kang,  Zihao Wu,  Zhengliang Liu,  Xi Jiang,  Tianming Liu,  Yi Shao",
                "发布日期": "2023-12-11",
                "摘要": "  In recent years, pre-trained large language models (LLMs) have achieved\ntremendous success in the field of Natural Language Processing (NLP). Prior\nstudies have primarily focused on general and generic domains, with relatively\nless research on specialized LLMs in the medical field. The specialization and\nhigh accuracy requirements for diagnosis in the medical field, as well as the\nchallenges in collecting large-scale data, have constrained the application and\ndevelopment of LLMs in medical scenarios. In the field of ophthalmology,\nclinical diagnosis mainly relies on doctors' interpretation of reports and\nmaking diagnostic decisions. In order to take advantage of LLMs to provide\ndecision support for doctors, we collected three modalities of ophthalmic\nreport data and fine-tuned the LLaMA2 model, successfully constructing an LLM\ntermed the \"Ophtha-LLaMA2\" specifically tailored for ophthalmic disease\ndiagnosis. Inference test results show that even with a smaller fine-tuning\ndataset, Ophtha-LLaMA2 performs significantly better in ophthalmic diagnosis\ncompared to other LLMs. It demonstrates that the Ophtha-LLaMA2 exhibits\nsatisfying accuracy and efficiency in ophthalmic disease diagnosis, making it a\nvaluable tool for ophthalmologists to provide improved diagnostic support for\npatients. This research provides a useful reference for the application of LLMs\nin the field of ophthalmology, while showcasing the immense potential and\nprospects in this domain.\n",
                "链接": "https://arxiv.org/abs/2312.04906"
            },
            {
                "文章ID": "114237",
                "标题": "Conversations in Galician: a Large Language Model for an\n  Underrepresented Language",
                "作者": " Eliseo Bao,  Anxo Pérez,  Javier Parapar",
                "发布日期": "2023-11-08",
                "摘要": "  The recent proliferation of Large Conversation Language Models has\nhighlighted the economic significance of widespread access to this type of AI\ntechnologies in the current information age. Nevertheless, prevailing models\nhave primarily been trained on corpora consisting of documents written in\npopular languages. The dearth of such cutting-edge tools for low-resource\nlanguages further exacerbates their underrepresentation in the current economic\nlandscape, thereby impacting their native speakers. This paper introduces two\nnovel resources designed to enhance Natural Language Processing (NLP) for the\nGalician language. We present a Galician adaptation of the Alpaca dataset,\ncomprising 52,000 instructions and demonstrations. This dataset proves\ninvaluable for enhancing language models by fine-tuning them to more accurately\nadhere to provided instructions. Additionally, as a demonstration of the\ndataset utility, we fine-tuned LLaMA-7B to comprehend and respond in Galician,\na language not originally supported by the model, by following the Alpaca\nformat. This work contributes to the research on multilingual models tailored\nfor low-resource settings, a crucial endeavor in ensuring the inclusion of all\nlinguistic communities in the development of Large Language Models. Another\nnoteworthy aspect of this research is the exploration of how knowledge of a\nclosely related language, in this case, Portuguese, can assist in generating\ncoherent text when training resources are scarce. Both the Galician Alpaca\ndataset and Cabuxa-7B are publicly accessible on our Huggingface Hub, and we\nhave made the source code available to facilitate replication of this\nexperiment and encourage further advancements for underrepresented languages.\n",
                "链接": "https://arxiv.org/abs/2311.03812"
            },
            {
                "文章ID": "76747",
                "标题": "Fast Distributed Inference Serving for Large Language Models",
                "作者": " Bingyang Wu,  Yinmin Zhong,  Zili Zhang,  Gang Huang,  Xuanzhe Liu,  Xin Jin",
                "发布日期": "2023-05-11",
                "摘要": "  Large language models (LLMs) power a new generation of interactive AI\napplications exemplified by ChatGPT. The interactive nature of these\napplications demand low job completion time (JCT) for model inference. Existing\nLLM serving systems use run-to-completion processing for inference jobs, which\nsuffers from head-of-line blocking and long JCT. We present FastServe, a\ndistributed inference serving system for LLMs. FastServe exploits the\nautoregressive pattern of LLM inference to enable preemption at the granularity\nof each output token. FastServe uses preemptive scheduling to minimize JCT with\na novel skip-join Multi-Level Feedback Queue scheduler. Based on the new semi\ninformation-agnostic setting of LLM inference, the scheduler leverages the\ninput length information to assign an appropriate initial queue for each\narrival job to join. The higher priority queues than the joined queue are\nskipped to reduce demotions. We design an efficient GPU memory management\nmechanism that proactively offloads and uploads intermediate states between GPU\nmemory and host memory for LLM inference. We build a system prototype of\nFastServe based on NVIDIA FasterTransformer. Experimental results show that\ncompared to the state-of-the-art solution Orca, FastServe improves the average\nand tail JCT by up to 5.1$\\times$ and 6.4$\\times$, respectively.\n",
                "链接": "https://arxiv.org/abs/2305.05920"
            },
            {
                "文章ID": "119089",
                "标题": "TurkishBERTweet: Fast and Reliable Large Language Model for Social Media\n  Analysis",
                "作者": " Ali Najafi,  Onur Varol",
                "发布日期": "2023-12-01",
                "摘要": "  Turkish is one of the most popular languages in the world. Wide us of this\nlanguage on social media platforms such as Twitter, Instagram, or Tiktok and\nstrategic position of the country in the world politics makes it appealing for\nthe social network researchers and industry. To address this need, we introduce\nTurkishBERTweet, the first large scale pre-trained language model for Turkish\nsocial media built using almost 900 million tweets. The model shares the same\narchitecture as base BERT model with smaller input length, making\nTurkishBERTweet lighter than BERTurk and can have significantly lower inference\ntime. We trained our model using the same approach for RoBERTa model and\nevaluated on two text classification tasks: Sentiment Classification and Hate\nSpeech Detection. We demonstrate that TurkishBERTweet outperforms the other\navailable alternatives on generalizability and its lower inference time gives\nsignificant advantage to process large-scale datasets. We also compared our\nmodels with the commercial OpenAI solutions in terms of cost and performance to\ndemonstrate TurkishBERTweet is scalable and cost-effective solution. As part of\nour research, we released TurkishBERTweet and fine-tuned LoRA adapters for the\nmentioned tasks under the MIT License to facilitate future research and\napplications on Turkish social media. Our TurkishBERTweet model is available\nat: https://github.com/ViralLab/TurkishBERTweet\n",
                "链接": "https://arxiv.org/abs/2311.18063"
            },
            {
                "文章ID": "62463",
                "标题": "Free-Form Variational Inference for Gaussian Process State-Space Models",
                "作者": " Xuhui Fan,  Edwin V. Bonilla,  Terence J. O'Kane,  Scott A. Sisson",
                "发布日期": "2023-07-18",
                "摘要": "  Gaussian process state-space models (GPSSMs) provide a principled and\nflexible approach to modeling the dynamics of a latent state, which is observed\nat discrete-time points via a likelihood model. However, inference in GPSSMs is\ncomputationally and statistically challenging due to the large number of latent\nvariables in the model and the strong temporal dependencies between them. In\nthis paper, we propose a new method for inference in Bayesian GPSSMs, which\novercomes the drawbacks of previous approaches, namely over-simplified\nassumptions, and high computational requirements. Our method is based on\nfree-form variational inference via stochastic gradient Hamiltonian Monte Carlo\nwithin the inducing-variable formalism. Furthermore, by exploiting our proposed\nvariational distribution, we provide a collapsed extension of our method where\nthe inducing variables are marginalized analytically. We also showcase results\nwhen combining our framework with particle MCMC methods. We show that, on six\nreal-world datasets, our approach can learn transition dynamics and latent\nstates more accurately than competing methods.\n",
                "链接": "https://arxiv.org/abs/2302.09921"
            },
            {
                "文章ID": "39406",
                "标题": "SoftTreeMax: Policy Gradient with Tree Search",
                "作者": " Gal Dalal,  Assaf Hallak,  Shie Mannor,  Gal Chechik",
                "发布日期": "2022-09-29",
                "摘要": "  Policy-gradient methods are widely used for learning control policies. They\ncan be easily distributed to multiple workers and reach state-of-the-art\nresults in many domains. Unfortunately, they exhibit large variance and\nsubsequently suffer from high-sample complexity since they aggregate gradients\nover entire trajectories. At the other extreme, planning methods, like tree\nsearch, optimize the policy using single-step transitions that consider future\nlookahead. These approaches have been mainly considered for value-based\nalgorithms. Planning-based algorithms require a forward model and are\ncomputationally intensive at each step, but are more sample efficient. In this\nwork, we introduce SoftTreeMax, the first approach that integrates tree-search\ninto policy gradient. Traditionally, gradients are computed for single\nstate-action pairs. Instead, our tree-based policy structure leverages all\ngradients at the tree leaves in each environment step. This allows us to reduce\nthe variance of gradients by three orders of magnitude and to benefit from\nbetter sample complexity compared with standard policy gradient. On Atari,\nSoftTreeMax demonstrates up to 5x better performance in faster run-time\ncompared with distributed PPO.\n",
                "链接": "https://arxiv.org/abs/2209.13966"
            },
            {
                "文章ID": "115499",
                "标题": "Leveraging Large Language Models to Detect Influence Campaigns in Social\n  Media",
                "作者": " Luca Luceri,  Eric Boniardi,  Emilio Ferrara",
                "发布日期": "2023-11-15",
                "摘要": "  Social media influence campaigns pose significant challenges to public\ndiscourse and democracy. Traditional detection methods fall short due to the\ncomplexity and dynamic nature of social media. Addressing this, we propose a\nnovel detection method using Large Language Models (LLMs) that incorporates\nboth user metadata and network structures. By converting these elements into a\ntext format, our approach effectively processes multilingual content and adapts\nto the shifting tactics of malicious campaign actors. We validate our model\nthrough rigorous testing on multiple datasets, showcasing its superior\nperformance in identifying influence efforts. This research not only offers a\npowerful tool for detecting campaigns, but also sets the stage for future\nenhancements to keep up with the fast-paced evolution of social media-based\ninfluence tactics.\n",
                "链接": "https://arxiv.org/abs/2311.07816"
            },
            {
                "文章ID": "34734",
                "标题": "A model-based approach to meta-Reinforcement Learning: Transformers and\n  tree search",
                "作者": " Brieuc Pinon,  Jean-Charles Delvenne,  Raphaël Jungers",
                "发布日期": "2022-08-25",
                "摘要": "  Meta-learning is a line of research that develops the ability to leverage\npast experiences to efficiently solve new learning problems. Meta-Reinforcement\nLearning (meta-RL) methods demonstrate a capability to learn behaviors that\nefficiently acquire and exploit information in several meta-RL problems.\n  In this context, the Alchemy benchmark has been proposed by Wang et al.\n[2021]. Alchemy features a rich structured latent space that is challenging for\nstate-of-the-art model-free RL methods. These methods fail to learn to properly\nexplore then exploit.\n  We develop a model-based algorithm. We train a model whose principal block is\na Transformer Encoder to fit the symbolic Alchemy environment dynamics. Then we\ndefine an online planner with the learned model using a tree search method.\nThis algorithm significantly outperforms previously applied model-free RL\nmethods on the symbolic Alchemy problem.\n  Our results reveal the relevance of model-based approaches with online\nplanning to perform exploration and exploitation successfully in meta-RL.\nMoreover, we show the efficiency of the Transformer architecture to learn\ncomplex dynamics that arise from latent spaces present in meta-RL problems.\n",
                "链接": "https://arxiv.org/abs/2208.11535"
            },
            {
                "文章ID": "8202",
                "标题": "LiteTransformerSearch: Training-free Neural Architecture Search for\n  Efficient Language Models",
                "作者": " Mojan Javaheripi,  Gustavo H. de Rosa,  Subhabrata Mukherjee,  Shital Shah,  Tomasz L. Religa,  Caio C. T. Mendes,  Sebastien Bubeck,  Farinaz Koushanfar,  Debadeepta Dey",
                "发布日期": "2022-10-19",
                "摘要": "  The Transformer architecture is ubiquitously used as the building block of\nlarge-scale autoregressive language models. However, finding architectures with\nthe optimal trade-off between task performance (perplexity) and hardware\nconstraints like peak memory utilization and latency is non-trivial. This is\nexacerbated by the proliferation of various hardware. We leverage the somewhat\nsurprising empirical observation that the number of decoder parameters in\nautoregressive Transformers has a high rank correlation with task performance,\nirrespective of the architecture topology. This observation organically induces\na simple Neural Architecture Search (NAS) algorithm that uses decoder\nparameters as a proxy for perplexity without need for any model training. The\nsearch phase of our training-free algorithm, dubbed Lightweight Transformer\nSearch (LTS), can be run directly on target devices since it does not require\nGPUs. Using on-target-device measurements, LTS extracts the Pareto-frontier of\nperplexity versus any hardware performance cost. We evaluate LTS on diverse\ndevices from ARM CPUs to NVIDIA GPUs and two popular autoregressive Transformer\nbackbones: GPT-2 and Transformer-XL. Results show that the perplexity of\n16-layer GPT-2 and Transformer-XL can be achieved with up to 1.5x, 2.5x faster\nruntime and 1.2x, 2.0x lower peak memory utilization. When evaluated in zero\nand one-shot settings, LTS Pareto-frontier models achieve higher average\naccuracy compared to the 350M parameter OPT across 14 tasks, with up to 1.6x\nlower latency. LTS extracts the Pareto-frontier in under 3 hours while running\non a commodity laptop. We effectively remove the carbon footprint of hundreds\nof GPU hours of training during search, offering a strong simple baseline for\nfuture NAS methods in autoregressive language modeling.\n",
                "链接": "https://arxiv.org/abs/2203.02094"
            },
            {
                "文章ID": "102661",
                "标题": "Evaluating Gender Bias of Pre-trained Language Models in Natural\n  Language Inference by Considering All Labels",
                "作者": " Panatchakorn Anantaprayoon,  Masahiro Kaneko,  Naoaki Okazaki",
                "发布日期": "2023-09-19",
                "摘要": "  Discriminatory social biases, including gender biases, have been found in\nPre-trained Language Models (PLMs). In Natural Language Inference (NLI), recent\nbias evaluation methods have observed biased inferences from the outputs of a\nparticular label such as neutral or entailment. However, since different biased\ninferences can be associated with different output labels, it is inaccurate for\na method to rely on one label. In this work, we propose an evaluation method\nthat considers all labels in the NLI task. We create evaluation data and assign\nthem into groups based on their expected biased output labels. Then, we define\na bias measure based on the corresponding label output of each data group. In\nthe experiment, we propose a meta-evaluation method for NLI bias measures, and\nthen use it to confirm that our measure can evaluate bias more accurately than\nthe baseline. Moreover, we show that our evaluation method is applicable to\nmultiple languages by conducting the meta-evaluation on PLMs in three different\nlanguages: English, Japanese, and Chinese. Finally, we evaluate PLMs of each\nlanguage to confirm their bias tendency. To our knowledge, we are the first to\nbuild evaluation datasets and measure the bias of PLMs from the NLI task in\nJapanese and Chinese.\n",
                "链接": "https://arxiv.org/abs/2309.09697"
            },
            {
                "文章ID": "81601",
                "标题": "LLM-QAT: Data-Free Quantization Aware Training for Large Language Models",
                "作者": " Zechun Liu,  Barlas Oguz,  Changsheng Zhao,  Ernie Chang,  Pierre Stock,  Yashar Mehdad,  Yangyang Shi,  Raghuraman Krishnamoorthi,  Vikas Chandra",
                "发布日期": "2023-05-30",
                "摘要": "  Several post-training quantization methods have been applied to large\nlanguage models (LLMs), and have been shown to perform well down to 8-bits. We\nfind that these methods break down at lower bit precision, and investigate\nquantization aware training for LLMs (LLM-QAT) to push quantization levels even\nfurther. We propose a data-free distillation method that leverages generations\nproduced by the pre-trained model, which better preserves the original output\ndistribution and allows quantizing any generative model independent of its\ntraining data, similar to post-training quantization methods. In addition to\nquantizing weights and activations, we also quantize the KV cache, which is\ncritical for increasing throughput and support long sequence dependencies at\ncurrent model sizes. We experiment with LLaMA models of sizes 7B, 13B, and 30B,\nat quantization levels down to 4-bits. We observe large improvements over\ntraining-free methods, especially in the low-bit settings.\n",
                "链接": "https://arxiv.org/abs/2305.17888"
            },
            {
                "文章ID": "83366",
                "标题": "On Optimal Caching and Model Multiplexing for Large Model Inference",
                "作者": " Banghua Zhu,  Ying Sheng,  Lianmin Zheng,  Clark Barrett,  Michael I. Jordan,  Jiantao Jiao",
                "发布日期": "2023-08-30",
                "摘要": "  Large Language Models (LLMs) and other large foundation models have achieved\nnoteworthy success, but their size exacerbates existing resource consumption\nand latency challenges. In particular, the large-scale deployment of these\nmodels is hindered by the significant resource requirements during inference.\nIn this paper, we study two approaches for mitigating these challenges:\nemploying a cache to store previous queries and learning a model multiplexer to\nchoose from an ensemble of models for query processing.\n  Theoretically, we provide an optimal algorithm for jointly optimizing both\napproaches to reduce the inference cost in both offline and online tabular\nsettings. By combining a caching algorithm, namely Greedy Dual Size with\nFrequency (GDSF) or Least Expected Cost (LEC), with a model multiplexer, we\nachieve optimal rates in both offline and online settings. Empirically,\nsimulations show that the combination of our caching and model multiplexing\nalgorithms greatly improves over the baselines, with up to $50\\times$\nimprovement over the baseline when the ratio between the maximum cost and\nminimum cost is $100$. Experiments on real datasets show a $4.3\\times$\nimprovement in FLOPs over the baseline when the ratio for FLOPs is $10$, and a\n$1.8\\times$ improvement in latency when the ratio for average latency is\n$1.85$.\n",
                "链接": "https://arxiv.org/abs/2306.02003"
            },
            {
                "文章ID": "110263",
                "标题": "Tree Search in DAG Space with Model-based Reinforcement Learning for\n  Causal Discovery",
                "作者": " Victor-Alexandru Darvariu,  Stephen Hailes,  Mirco Musolesi",
                "发布日期": "2023-10-23",
                "摘要": "  Identifying causal structure is central to many fields ranging from strategic\ndecision-making to biology and economics. In this work, we propose a\nmodel-based reinforcement learning method for causal discovery based on tree\nsearch, which builds directed acyclic graphs incrementally. We also formalize\nand prove the correctness of an efficient algorithm for excluding edges that\nwould introduce cycles, which enables deeper discrete search and sampling in\nDAG space. We evaluate our approach on two real-world tasks, achieving\nsubstantially better performance than the state-of-the-art model-free method\nand greedy search, constituting a promising advancement for combinatorial\nmethods.\n",
                "链接": "https://arxiv.org/abs/2310.13576"
            },
            {
                "文章ID": "26013",
                "标题": "FINGER: Fast Inference for Graph-based Approximate Nearest Neighbor\n  Search",
                "作者": " Patrick H. Chen,  Chang Wei-cheng,  Yu Hsiang-fu,  Inderjit S. Dhillon,  Hsieh Cho-jui",
                "发布日期": "2022-06-24",
                "摘要": "  Approximate K-Nearest Neighbor Search (AKNNS) has now become ubiquitous in\nmodern applications, for example, as a fast search procedure with two tower\ndeep learning models. Graph-based methods for AKNNS in particular have received\ngreat attention due to their superior performance. These methods rely on greedy\ngraph search to traverse the data points as embedding vectors in a database.\nUnder this greedy search scheme, we make a key observation: many distance\ncomputations do not influence search updates so these computations can be\napproximated without hurting performance. As a result, we propose FINGER, a\nfast inference method to achieve efficient graph search. FINGER approximates\nthe distance function by estimating angles between neighboring residual vectors\nwith low-rank bases and distribution matching. The approximated distance can be\nused to bypass unnecessary computations, which leads to faster searches.\nEmpirically, accelerating a popular graph-based method named HNSW by FINGER is\nshown to outperform existing graph-based methods by 20%-60% across different\nbenchmark datasets.\n",
                "链接": "https://arxiv.org/abs/2206.11408"
            },
            {
                "文章ID": "87212",
                "标题": "Evaluating Large Language Models with NeuBAROCO: Syllogistic Reasoning\n  Ability and Human-like Biases",
                "作者": " Risako Ando,  Takanobu Morishita,  Hirohiko Abe,  Koji Mineshima,  Mitsuhiro Okada",
                "发布日期": "2023-06-23",
                "摘要": "  This paper investigates whether current large language models exhibit biases\nin logical reasoning, similar to humans. Specifically, we focus on syllogistic\nreasoning, a well-studied form of inference in the cognitive science of human\ndeduction. To facilitate our analysis, we introduce a dataset called NeuBAROCO,\noriginally designed for psychological experiments that assess human logical\nabilities in syllogistic reasoning. The dataset consists of syllogistic\ninferences in both English and Japanese. We examine three types of biases\nobserved in human syllogistic reasoning: belief biases, conversion errors, and\natmosphere effects. Our findings demonstrate that current large language models\nstruggle more with problems involving these three types of biases.\n",
                "链接": "https://arxiv.org/abs/2306.12567"
            },
            {
                "文章ID": "75538",
                "标题": "Zero-Shot Listwise Document Reranking with a Large Language Model",
                "作者": " Xueguang Ma,  Xinyu Zhang,  Ronak Pradeep,  Jimmy Lin",
                "发布日期": "2023-05-04",
                "摘要": "  Supervised ranking methods based on bi-encoder or cross-encoder architectures\nhave shown success in multi-stage text ranking tasks, but they require large\namounts of relevance judgments as training data. In this work, we propose\nListwise Reranker with a Large Language Model (LRL), which achieves strong\nreranking effectiveness without using any task-specific training data.\nDifferent from the existing pointwise ranking methods, where documents are\nscored independently and ranked according to the scores, LRL directly generates\na reordered list of document identifiers given the candidate documents.\nExperiments on three TREC web search datasets demonstrate that LRL not only\noutperforms zero-shot pointwise methods when reranking first-stage retrieval\nresults, but can also act as a final-stage reranker to improve the top-ranked\nresults of a pointwise method for improved efficiency. Additionally, we apply\nour approach to subsets of MIRACL, a recent multilingual retrieval dataset,\nwith results showing its potential to generalize across different languages.\n",
                "链接": "https://arxiv.org/abs/2305.02156"
            },
            {
                "文章ID": "82111",
                "标题": "ConES: Concept Embedding Search for Parameter Efficient Tuning Large\n  Vision Language Models",
                "作者": " Huahui Yi,  Ziyuan Qin,  Wei Xu,  Miaotian Guo,  Kun Wang,  Shaoting Zhang,  Kang Li,  Qicheng Lao",
                "发布日期": "2023-05-31",
                "摘要": "  Large pre-trained vision-language models have shown great prominence in\ntransferring pre-acquired knowledge to various domains and downstream tasks\nwith appropriate prompting or tuning. Existing prevalent tuning methods can be\ngenerally categorized into three genres: 1) prompt engineering by creating\nsuitable prompt texts, which is time-consuming and requires domain expertise;\n2) or simply fine-tuning the whole model, which is extremely inefficient; 3)\nprompt tuning through parameterized prompt embeddings with the text encoder.\nNevertheless, all methods rely on the text encoder for bridging the modality\ngap between vision and language. In this work, we question the necessity of the\ncumbersome text encoder for a more lightweight and efficient tuning paradigm as\nwell as more representative prompt embeddings closer to the image\nrepresentations. To achieve this, we propose a Concept Embedding Search (ConES)\napproach by optimizing prompt embeddings -- without the need of the text\nencoder -- to capture the 'concept' of the image modality through a variety of\ntask objectives. By dropping the text encoder, we are able to significantly\nspeed up the learning process, \\eg, from about an hour to just ten minutes in\nour experiments for personalized text-to-image generation without impairing the\ngeneration quality. Moreover, our proposed approach is orthogonal to current\nexisting tuning methods since the searched concept embeddings can be further\nutilized in the next stage of fine-tuning the pre-trained large models for\nboosting performance. Extensive experiments show that our approach can beat the\nprompt tuning and textual inversion methods in a variety of downstream tasks\nincluding objection detection, instance segmentation, and image generation. Our\napproach also shows better generalization capability for unseen concepts in\nspecialized domains, such as the medical domain.\n",
                "链接": "https://arxiv.org/abs/2305.18993"
            },
            {
                "文章ID": "103741",
                "标题": "Trusta: Reasoning about Assurance Cases with Formal Methods and Large\n  Language Models",
                "作者": " Zezhong Chen,  Yuxin Deng,  Wenjie Du",
                "发布日期": "2023-09-25",
                "摘要": "  Assurance cases can be used to argue for the safety of products in safety\nengineering. In safety-critical areas, the construction of assurance cases is\nindispensable. Trustworthiness Derivation Trees (TDTs) enhance assurance cases\nby incorporating formal methods, rendering it possible for automatic reasoning\nabout assurance cases. We present Trustworthiness Derivation Tree Analyzer\n(Trusta), a desktop application designed to automatically construct and verify\nTDTs. The tool has a built-in Prolog interpreter in its backend, and is\nsupported by the constraint solvers Z3 and MONA. Therefore, it can solve\nconstraints about logical formulas involving arithmetic, sets, Horn clauses\netc. Trusta also utilizes large language models to make the creation and\nevaluation of assurance cases more convenient. It allows for interactive human\nexamination and modification. We evaluated top language models like\nChatGPT-3.5, ChatGPT-4, and PaLM 2 for generating assurance cases. Our tests\nshowed a 50%-80% similarity between machine-generated and human-created cases.\nIn addition, Trusta can extract formal constraints from text in natural\nlanguages, facilitating an easier interpretation and validation process. This\nextraction is subject to human review and correction, blending the best of\nautomated efficiency with human insight. To our knowledge, this marks the first\nintegration of large language models in automatic creating and reasoning about\nassurance cases, bringing a novel approach to a traditional challenge. Through\nseveral industrial case studies, Trusta has proven to quickly find some subtle\nissues that are typically missed in manual inspection, demonstrating its\npractical value in enhancing the assurance case development process.\n",
                "链接": "https://arxiv.org/abs/2309.12941"
            },
            {
                "文章ID": "17319",
                "标题": "Adapting and Evaluating Influence-Estimation Methods for\n  Gradient-Boosted Decision Trees",
                "作者": " Jonathan Brophy,  Zayd Hammoudeh,  Daniel Lowd",
                "发布日期": "2023-06-01",
                "摘要": "  Influence estimation analyzes how changes to the training data can lead to\ndifferent model predictions; this analysis can help us better understand these\npredictions, the models making those predictions, and the data sets they're\ntrained on. However, most influence-estimation techniques are designed for deep\nlearning models with continuous parameters. Gradient-boosted decision trees\n(GBDTs) are a powerful and widely-used class of models; however, these models\nare black boxes with opaque decision-making processes. In the pursuit of better\nunderstanding GBDT predictions and generally improving these models, we adapt\nrecent and popular influence-estimation methods designed for deep learning\nmodels to GBDTs. Specifically, we adapt representer-point methods and TracIn,\ndenoting our new methods TREX and BoostIn, respectively; source code is\navailable at https://github.com/jjbrophy47/tree_influence. We compare these\nmethods to LeafInfluence and other baselines using 5 different evaluation\nmeasures on 22 real-world data sets with 4 popular GBDT implementations. These\nexperiments give us a comprehensive overview of how different approaches to\ninfluence estimation work in GBDT models. We find BoostIn is an efficient\ninfluence-estimation method for GBDTs that performs equally well or better than\nexisting work while being four orders of magnitude faster. Our evaluation also\nsuggests the gold-standard approach of leave-one-out (LOO) retraining\nconsistently identifies the single-most influential training example but\nperforms poorly at finding the most influential set of training examples for a\ngiven target prediction.\n",
                "链接": "https://arxiv.org/abs/2205.00359"
            },
            {
                "文章ID": "66221",
                "标题": "FlexGen: High-Throughput Generative Inference of Large Language Models\n  with a Single GPU",
                "作者": " Ying Sheng,  Lianmin Zheng,  Binhang Yuan,  Zhuohan Li,  Max Ryabinin,  Daniel Y. Fu,  Zhiqiang Xie,  Beidi Chen,  Clark Barrett,  Joseph E. Gonzalez,  Percy Liang,  Christopher Ré,  Ion Stoica,  Ce Zhang",
                "发布日期": "2023-06-13",
                "摘要": "  The high computational and memory requirements of large language model (LLM)\ninference make it feasible only with multiple high-end accelerators. Motivated\nby the emerging demand for latency-insensitive tasks with batched processing,\nthis paper initiates the study of high-throughput LLM inference using limited\nresources, such as a single commodity GPU. We present FlexGen, a\nhigh-throughput generation engine for running LLMs with limited GPU memory.\nFlexGen can be flexibly configured under various hardware resource constraints\nby aggregating memory and computation from the GPU, CPU, and disk. By solving a\nlinear programming problem, it searches for efficient patterns to store and\naccess tensors. FlexGen further compresses the weights and the attention cache\nto 4 bits with negligible accuracy loss. These techniques enable FlexGen to\nhave a larger space of batch size choices and thus significantly increase\nmaximum throughput. As a result, when running OPT-175B on a single 16GB GPU,\nFlexGen achieves significantly higher throughput compared to state-of-the-art\noffloading systems, reaching a generation throughput of 1 token/s for the first\ntime with an effective batch size of 144. On the HELM benchmark, FlexGen can\nbenchmark a 30B model with a 16GB GPU on 7 representative sub-scenarios in 21\nhours. The code is available at https://github.com/FMInference/FlexGen\n",
                "链接": "https://arxiv.org/abs/2303.06865"
            },
            {
                "文章ID": "106967",
                "标题": "Tree-GPT: Modular Large Language Model Expert System for Forest Remote\n  Sensing Image Understanding and Interactive Analysis",
                "作者": " Siqi Du,  Shengjun Tang,  Weixi Wang,  Xiaoming Li,  Renzhong Guo",
                "发布日期": "2023-10-10",
                "摘要": "  This paper introduces a novel framework, Tree-GPT, which incorporates Large\nLanguage Models (LLMs) into the forestry remote sensing data workflow, thereby\nenhancing the efficiency of data analysis. Currently, LLMs are unable to\nextract or comprehend information from images and may generate inaccurate text\ndue to a lack of domain knowledge, limiting their use in forestry data\nanalysis. To address this issue, we propose a modular LLM expert system,\nTree-GPT, that integrates image understanding modules, domain knowledge bases,\nand toolchains. This empowers LLMs with the ability to comprehend images,\nacquire accurate knowledge, generate code, and perform data analysis in a local\nenvironment. Specifically, the image understanding module extracts structured\ninformation from forest remote sensing images by utilizing automatic or\ninteractive generation of prompts to guide the Segment Anything Model (SAM) in\ngenerating and selecting optimal tree segmentation results. The system then\ncalculates tree structural parameters based on these results and stores them in\na database. Upon receiving a specific natural language instruction, the LLM\ngenerates code based on a thought chain to accomplish the analysis task. The\ncode is then executed by an LLM agent in a local environment and . For\necological parameter calculations, the system retrieves the corresponding\nknowledge from the knowledge base and inputs it into the LLM to guide the\ngeneration of accurate code. We tested this system on several tasks, including\nSearch, Visualization, and Machine Learning Analysis. The prototype system\nperformed well, demonstrating the potential for dynamic usage of LLMs in\nforestry research and environmental sciences.\n",
                "链接": "https://arxiv.org/abs/2310.04698"
            },
            {
                "文章ID": "76055",
                "标题": "On Contrastive Learning of Semantic Similarity forCode to Code Search",
                "作者": " Anthony Saieva,  Saikat Chakraborty,  Gail Kaiser",
                "发布日期": "2023-05-09",
                "摘要": "  This paper introduces a novel code-to-code search technique that enhances the\nperformance of Large Language Models (LLMs) by including both static and\ndynamic features as well as utilizing both similar and dissimilar examples\nduring training. We present the first-ever code search method that encodes\ndynamic runtime information during training without the need to execute either\nthe corpus under search or the search query at inference time and the first\ncode search technique that trains on both positive and negative reference\nsamples. To validate the efficacy of our approach, we perform a set of studies\ndemonstrating the capability of enhanced LLMs to perform cross-language\ncode-to-code search.\n  Our evaluation demonstrates that the effectiveness of our approach is\nconsistent across various model architectures and programming languages. We\noutperform the state-of-the-art cross-language search tool by up to 44.7\\%.\nMoreover, our ablation studies reveal that even a single positive and negative\nreference sample in the training process results in substantial performance\nimprovements demonstrating both similar and dissimilar references are important\nparts of code search. Importantly, we show that enhanced well-crafted,\nfine-tuned models consistently outperform enhanced larger modern LLMs without\nfine tuning, even when enhancing the largest available LLMs highlighting the\nimportance for open-sourced models.\n  To ensure the reproducibility and extensibility of our research, we present\nan open-sourced implementation of our tool and training procedures called\nCosco.\n",
                "链接": "https://arxiv.org/abs/2305.03843"
            },
            {
                "文章ID": "115369",
                "标题": "MEGAVERSE: Benchmarking Large Language Models Across Languages,\n  Modalities, Models and Tasks",
                "作者": " Sanchit Ahuja,  Divyanshu Aggarwal,  Varun Gumma,  Ishaan Watts,  Ashutosh Sathe,  Millicent Ochieng,  Rishav Hada,  Prachi Jain,  Maxamed Axmed,  Kalika Bali,  Sunayana Sitaram",
                "发布日期": "2023-11-14",
                "摘要": "  Recently, there has been a rapid advancement in research on Large Language\nModels (LLMs), resulting in significant progress in several Natural Language\nProcessing (NLP) tasks. Consequently, there has been a surge in LLM evaluation\nresearch to comprehend the models' capabilities and limitations. However, much\nof this research has been confined to the English language, leaving LLM\nbuilding and evaluation for non-English languages relatively unexplored. There\nhas been an introduction of several new LLMs, necessitating their evaluation on\nnon-English languages. This study aims to expand our MEGA benchmarking suite by\nincluding six new datasets to form the MEGAVERSE benchmark. The benchmark\ncomprises 22 datasets covering 81 languages, including low-resource African\nlanguages. We evaluate several state-of-the-art LLMs like GPT-3.5-Turbo, GPT4,\nPaLM2, and Llama2 on the MEGAVERSE datasets. Additionally, we include two\nmultimodal datasets in the benchmark and assess the performance of the\nLLaVa-v1.5 model. Our experiments suggest that GPT4 and PaLM2 outperform the\nLlama models on various tasks, notably on low-resource languages, with GPT4\noutperforming PaLM2 on more datasets than vice versa. However, issues such as\ndata contamination must be addressed to obtain an accurate assessment of LLM\nperformance on non-English languages.\n",
                "链接": "https://arxiv.org/abs/2311.07463"
            },
            {
                "文章ID": "77883",
                "标题": "Large Language Models are Built-in Autoregressive Search Engines",
                "作者": " Noah Ziems,  Wenhao Yu,  Zhihan Zhang,  Meng Jiang",
                "发布日期": "2023-05-17",
                "摘要": "  Document retrieval is a key stage of standard Web search engines. Existing\ndual-encoder dense retrievers obtain representations for questions and\ndocuments independently, allowing for only shallow interactions between them.\nTo overcome this limitation, recent autoregressive search engines replace the\ndual-encoder architecture by directly generating identifiers for relevant\ndocuments in the candidate pool. However, the training cost of such\nautoregressive search engines rises sharply as the number of candidate\ndocuments increases. In this paper, we find that large language models (LLMs)\ncan follow human instructions to directly generate URLs for document retrieval.\n  Surprisingly, when providing a few {Query-URL} pairs as in-context\ndemonstrations, LLMs can generate Web URLs where nearly 90\\% of the\ncorresponding documents contain correct answers to open-domain questions. In\nthis way, LLMs can be thought of as built-in search engines, since they have\nnot been explicitly trained to map questions to document identifiers.\nExperiments demonstrate that our method can consistently achieve better\nretrieval performance than existing retrieval approaches by a significant\nmargin on three open-domain question answering benchmarks, under both zero and\nfew-shot settings. The code for this work can be found at\n\\url{https://github.com/Ziems/llm-url}.\n",
                "链接": "https://arxiv.org/abs/2305.09612"
            },
            {
                "文章ID": "106372",
                "标题": "From Words to Watts: Benchmarking the Energy Costs of Large Language\n  Model Inference",
                "作者": " Siddharth Samsi,  Dan Zhao,  Joseph McDonald,  Baolin Li,  Adam Michaleas,  Michael Jones,  William Bergeron,  Jeremy Kepner,  Devesh Tiwari,  Vijay Gadepally",
                "发布日期": "2023-10-05",
                "摘要": "  Large language models (LLMs) have exploded in popularity due to their new\ngenerative capabilities that go far beyond prior state-of-the-art. These\ntechnologies are increasingly being leveraged in various domains such as law,\nfinance, and medicine. However, these models carry significant computational\nchallenges, especially the compute and energy costs required for inference.\nInference energy costs already receive less attention than the energy costs of\ntraining LLMs -- despite how often these large models are called on to conduct\ninference in reality (e.g., ChatGPT). As these state-of-the-art LLMs see\nincreasing usage and deployment in various domains, a better understanding of\ntheir resource utilization is crucial for cost-savings, scaling performance,\nefficient hardware usage, and optimal inference strategies.\n  In this paper, we describe experiments conducted to study the computational\nand energy utilization of inference with LLMs. We benchmark and conduct a\npreliminary analysis of the inference performance and inference energy costs of\ndifferent sizes of LLaMA -- a recent state-of-the-art LLM -- developed by Meta\nAI on two generations of popular GPUs (NVIDIA V100 \\& A100) and two datasets\n(Alpaca and GSM8K) to reflect the diverse set of tasks/benchmarks for LLMs in\nresearch and practice. We present the results of multi-node, multi-GPU\ninference using model sharding across up to 32 GPUs. To our knowledge, our work\nis the one of the first to study LLM inference performance from the perspective\nof computational and energy resources at this scale.\n",
                "链接": "https://arxiv.org/abs/2310.03003"
            },
            {
                "文章ID": "108599",
                "标题": "Textual Analysis of ICALEPCS and IPAC Conference Proceedings: Revealing\n  Research Trends, Topics, and Collaborations for Future Insights and Advanced\n  Search",
                "作者": " Antonin Sulc,  Annika Eichler,  Tim Wilksen",
                "发布日期": "2023-10-16",
                "摘要": "  In this paper, we show a textual analysis of past ICALEPCS and IPAC\nconference proceedings to gain insights into the research trends and topics\ndiscussed in the field. We use natural language processing techniques to\nextract meaningful information from the abstracts and papers of past conference\nproceedings. We extract topics to visualize and identify trends, analyze their\nevolution to identify emerging research directions, and highlight interesting\npublications based solely on their content with an analysis of their network.\nAdditionally, we will provide an advanced search tool to better search the\nexisting papers to prevent duplication and easier reference findings. Our\nanalysis provides a comprehensive overview of the research landscape in the\nfield and helps researchers and practitioners to better understand the\nstate-of-the-art and identify areas for future research.\n",
                "链接": "https://arxiv.org/abs/2310.08954"
            },
            {
                "文章ID": "106544",
                "标题": "Variational Inference for GARCH-family Models",
                "作者": " Martin Magris,  Alexandros Iosifidis",
                "发布日期": "2023-10-06",
                "摘要": "  The Bayesian estimation of GARCH-family models has been typically addressed\nthrough Monte Carlo sampling. Variational Inference is gaining popularity and\nattention as a robust approach for Bayesian inference in complex machine\nlearning models; however, its adoption in econometrics and finance is limited.\nThis paper discusses the extent to which Variational Inference constitutes a\nreliable and feasible alternative to Monte Carlo sampling for Bayesian\ninference in GARCH-like models. Through a large-scale experiment involving the\nconstituents of the S&P 500 index, several Variational Inference optimizers, a\nvariety of volatility models, and a case study, we show that Variational\nInference is an attractive, remarkably well-calibrated, and competitive method\nfor Bayesian learning.\n",
                "链接": "https://arxiv.org/abs/2310.03435"
            },
            {
                "文章ID": "112559",
                "标题": "Explaining Tree Model Decisions in Natural Language for Network\n  Intrusion Detection",
                "作者": " Noah Ziems,  Gang Liu,  John Flanagan,  Meng Jiang",
                "发布日期": "2023-10-31",
                "摘要": "  Network intrusion detection (NID) systems which leverage machine learning\nhave been shown to have strong performance in practice when used to detect\nmalicious network traffic. Decision trees in particular offer a strong balance\nbetween performance and simplicity, but require users of NID systems to have\nbackground knowledge in machine learning to interpret. In addition, they are\nunable to provide additional outside information as to why certain features may\nbe important for classification.\n  In this work, we explore the use of large language models (LLMs) to provide\nexplanations and additional background knowledge for decision tree NID systems.\nFurther, we introduce a new human evaluation framework for decision tree\nexplanations, which leverages automatically generated quiz questions that\nmeasure human evaluators' understanding of decision tree inference. Finally, we\nshow LLM generated decision tree explanations correlate highly with human\nratings of readability, quality, and use of background knowledge while\nsimultaneously providing better understanding of decision boundaries.\n",
                "链接": "https://arxiv.org/abs/2310.19658"
            },
            {
                "文章ID": "54607",
                "标题": "DISCO: Distilling Counterfactuals with Large Language Models",
                "作者": " Zeming Chen,  Qiyue Gao,  Antoine Bosselut,  Ashish Sabharwal,  Kyle Richardson",
                "发布日期": "2023-06-07",
                "摘要": "  Models trained with counterfactually augmented data learn representations of\nthe causal structure of tasks, enabling robust generalization. However,\nhigh-quality counterfactual data is scarce for most tasks and not easily\ngenerated at scale. When crowdsourced, such data is typically limited in scale\nand diversity; when generated using supervised methods, it is computationally\nexpensive to extend to new counterfactual dimensions. In this work, we\nintroduce DISCO (DIStilled COunterfactual Data), a new method for automatically\ngenerating high quality counterfactual data at scale. DISCO engineers prompts\nto generate phrasal perturbations with a large general language model. Then, a\ntask-specific teacher model filters these generations to distill high-quality\ncounterfactual data. While task-agnostic, we apply our pipeline to the task of\nnatural language inference (NLI) and find that on challenging evaluations such\nas the NLI stress test, comparatively smaller student models trained with DISCO\ngenerated counterfactuals are more robust (6% absolute) and generalize better\nacross distributions (2%) compared to models trained without data augmentation.\nFurthermore, DISCO augmented models are 10% more consistent between\ncounterfactual pairs on three evaluation sets, demonstrating that DISCO\naugmentation enables models to more reliably learn causal representations. Our\nrepository is available at: https://github.com/eric11eca/disco\n",
                "链接": "https://arxiv.org/abs/2212.10534"
            },
            {
                "文章ID": "56812",
                "标题": "NarrowBERT: Accelerating Masked Language Model Pretraining and Inference",
                "作者": " Haoxin Li,  Phillip Keung,  Daniel Cheng,  Jungo Kasai,  Noah A. Smith",
                "发布日期": "2023-06-07",
                "摘要": "  Large-scale language model pretraining is a very successful form of\nself-supervised learning in natural language processing, but it is increasingly\nexpensive to perform as the models and pretraining corpora have become larger\nover time. We propose NarrowBERT, a modified transformer encoder that increases\nthe throughput for masked language model pretraining by more than $2\\times$.\nNarrowBERT sparsifies the transformer model such that the self-attention\nqueries and feedforward layers only operate on the masked tokens of each\nsentence during pretraining, rather than all of the tokens as with the usual\ntransformer encoder. We also show that NarrowBERT increases the throughput at\ninference time by as much as $3.5\\times$ with minimal (or no) performance\ndegradation on sentence encoding tasks like MNLI. Finally, we examine the\nperformance of NarrowBERT on the IMDB and Amazon reviews classification and\nCoNLL NER tasks and show that it is also comparable to standard BERT\nperformance.\n",
                "链接": "https://arxiv.org/abs/2301.04761"
            },
            {
                "文章ID": "123684",
                "标题": "ConsistentEE: A Consistent and Hardness-Guided Early Exiting Method for\n  Accelerating Language Models Inference",
                "作者": " Ziqian Zeng,  Yihuai Hong,  Hongliang Dai,  Huiping Zhuang,  Cen Chen",
                "发布日期": "2023-12-20",
                "摘要": "  Early Exiting is one of the most popular methods to achieve efficient\ninference. Current early exiting methods adopt the (weighted) sum of the cross\nentropy loss of all internal classifiers during training, imposing all these\nclassifiers to predict all instances correctly. However, during inference, as\nlong as one internal classifier predicts an instance correctly, it can\naccelerate without losing accuracy. Thus, there is a notable gap between\ntraining and inference. We propose ConsistentEE, an early exiting method that\nis consistent in training and inference. ConsistentEE formulates the early\nexiting process as a reinforcement learning problem. A policy network is added\nto decide whether an instance should exit or continue. The training objective\nof ConsistentEE only require each instance to be predicted correctly by one\ninternal classifier. Additionally, we introduce the concept Memorize Layer to\nmeasure the hardness of an instance. We incorporate memorized layer into reward\nfunction design, which allows ``easy'' instances to focus more on acceleration\nwhile ``hard'' instances to focus more on accuracy. Experimental results show\nthat our method outperforms other baselines on various natural language\nunderstanding and generation tasks.\n",
                "链接": "https://arxiv.org/abs/2312.11882"
            },
            {
                "文章ID": "81662",
                "标题": "BigTranslate: Augmenting Large Language Models with Multilingual\n  Translation Capability over 100 Languages",
                "作者": " Wen Yang,  Chong Li,  Jiajun Zhang,  Chengqing Zong",
                "发布日期": "2023-11-22",
                "摘要": "  Large language models (LLMs) demonstrate promising translation performance\namong various natural languages. However, many LLMs especially the open-sourced\nones, such as BLOOM and LLaMA, are English-dominant and support only dozens of\nnatural languages, making the potential of LLMs on language translation less\nexplored. In this work, we present BigTranslate which adapts LLaMA that covers\nonly 20 languages and enhances it with multilingual translation capability on\nmore than 100 languages. BigTranslate is built upon LLaMA-13B and it is\noptimized in three steps. First, we continue training LLaMA with massive\nChinese monolingual data. Second, we continue training the model with a\nlarge-scale parallel dataset that covers 102 natural languages. Third, we\ninstruct-tune the foundation model with multilingual translation instructions,\nleading to our BigTranslate model. The preliminary experiments on multilingual\ntranslation show that BigTranslate performs comparably with ChatGPT and Google\nTranslate in many languages and even outperforms ChatGPT in 8 language pairs.\nWe release the BigTranslate model and hope it can advance the research\nprogress.\n",
                "链接": "https://arxiv.org/abs/2305.18098"
            },
            {
                "文章ID": "115552",
                "标题": "How good are Large Language Models on African Languages?",
                "作者": " Jessica Ojo,  Kelechi Ogueji,  Pontus Stenetorp,  David I. Adelani",
                "发布日期": "2023-11-15",
                "摘要": "  Recent advancements in natural language processing have led to the\nproliferation of large language models (LLMs). These models have been shown to\nyield good performance, using in-context learning, even on unseen tasks and\nlanguages. Additionally, they have been widely adopted as\nlanguage-model-as-a-service commercial APIs like GPT-4 API. However, their\nperformance on African languages is largely unknown. We present an analysis of\nthree popular large language models (mT0, LLaMa 2, and GPT-4) on five tasks\n(news topic classification, sentiment classification, machine translation,\nquestion answering, and named entity recognition) across 30 African languages,\nspanning different language families and geographical regions. Our results\nsuggest that all LLMs produce below-par performance on African languages, and\nthere is a large gap in performance compared to high-resource languages like\nEnglish most tasks. We find that GPT-4 has an average or impressive performance\non classification tasks but very poor results on generative tasks like machine\ntranslation. Surprisingly, we find that mT0 had the best overall on\ncross-lingual QA, better than the state-of-the-art supervised model (i.e.\nfine-tuned mT5) and GPT-4 on African languages. Overall, LLaMa 2 records the\nworst performance due to its limited multilingual capabilities and\nEnglish-centric pre-training corpus. In general, our findings present a\ncall-to-action to ensure African languages are well represented in large\nlanguage models, given their growing popularity.\n",
                "链接": "https://arxiv.org/abs/2311.07978"
            },
            {
                "文章ID": "92678",
                "标题": "Model-free generalized fiducial inference",
                "作者": " Jonathan P Williams",
                "发布日期": "2023-07-25",
                "摘要": "  Motivated by the need for the development of safe and reliable methods for\nuncertainty quantification in machine learning, I propose and develop ideas for\na model-free statistical framework for imprecise probabilistic prediction\ninference. This framework facilitates uncertainty quantification in the form of\nprediction sets that offer finite sample control of type 1 errors, a property\nshared with conformal prediction sets, but this new approach also offers more\nversatile tools for imprecise probabilistic reasoning. Furthermore, I propose\nand consider the theoretical and empirical properties of a precise\nprobabilistic approximation to the model-free imprecise framework.\nApproximating a belief/plausibility measure pair by an [optimal in some sense]\nprobability measure in the credal set is a critical resolution needed for the\nbroader adoption of imprecise probabilistic approaches to inference in\nstatistical and machine learning communities. It is largely undetermined in the\nstatistical and machine learning literatures, more generally, how to properly\nquantify uncertainty in that there is no generally accepted standard of\naccountability of stated uncertainties. The research I present in this\nmanuscript is aimed at motivating a framework for statistical inference with\nreliability and accountability as the guiding principles.\n",
                "链接": "https://arxiv.org/abs/2307.12472"
            },
            {
                "文章ID": "114213",
                "标题": "Large Language Model based Long-tail Query Rewriting in Taobao Search",
                "作者": " Wenjun Peng,  Guiyang Li,  Yue Jiang,  Zilong Wang,  Dan Ou,  Xiaoyi Zeng,  Derong Xu,   Tongxu,  Enhong Chen",
                "发布日期": "2023-11-14",
                "摘要": "  In the realm of e-commerce search, the significance of semantic matching\ncannot be overstated, as it directly impacts both user experience and company\nrevenue. Along this line, query rewriting, serving as an important technique to\nbridge the semantic gaps inherent in the semantic matching process, has\nattached wide attention from the industry and academia. However, existing query\nrewriting methods often struggle to effectively optimize long-tail queries and\nalleviate the phenomenon of \"few-recall\" caused by semantic gap. In this paper,\nwe present BEQUE, a comprehensive framework that Bridges the sEmantic gap for\nlong-tail QUEries. In detail, BEQUE comprises three stages: multi-instruction\nsupervised fine tuning (SFT), offline feedback, and objective alignment. We\nfirst construct a rewriting dataset based on rejection sampling and auxiliary\ntasks mixing to fine-tune our large language model (LLM) in a supervised\nfashion. Subsequently, with the well-trained LLM, we employ beam search to\ngenerate multiple candidate rewrites, and feed them into Taobao offline system\nto obtain the partial order. Leveraging the partial order of rewrites, we\nintroduce a contrastive learning method to highlight the distinctions between\nrewrites, and align the model with the Taobao online objectives. Offline\nexperiments prove the effectiveness of our method in bridging semantic gap.\nOnline A/B tests reveal that our method can significantly boost gross\nmerchandise volume (GMV), number of transaction (#Trans) and unique visitor\n(UV) for long-tail queries. BEQUE has been deployed on Taobao, one of most\npopular online shopping platforms in China, since October 2023.\n",
                "链接": "https://arxiv.org/abs/2311.03758"
            },
            {
                "文章ID": "65490",
                "标题": "Cost-Effective Hyperparameter Optimization for Large Language Model\n  Generation Inference",
                "作者": " Chi Wang,  Susan Xueqing Liu,  Ahmed H. Awadallah",
                "发布日期": "2023-08-10",
                "摘要": "  Large Language Models (LLMs) have sparked significant interest in their\ngenerative capabilities, leading to the development of various commercial\napplications. The high cost of using the models drives application builders to\nmaximize the value of generation under a limited inference budget. This paper\npresents a study of optimizing inference hyperparameters such as the number of\nresponses, temperature and max tokens, which significantly affects the\nutility/cost of text generation. We design a framework named EcoOptiGen which\nleverages economical hyperparameter optimization and cost-based pruning.\nExperiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its\neffectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAML\nlibrary: \\url{https://aka.ms/autogen}.\n",
                "链接": "https://arxiv.org/abs/2303.04673"
            },
            {
                "文章ID": "105189",
                "标题": "Training and inference of large language models using 8-bit floating\n  point",
                "作者": " Sergio P. Perez,  Yan Zhang,  James Briggs,  Charlie Blake,  Josh Levy-Kramer,  Paul Balanca,  Carlo Luschi,  Stephen Barlow,  Andrew William Fitzgibbon",
                "发布日期": "2023-10-02",
                "摘要": "  FP8 formats are gaining popularity to boost the computational efficiency for\ntraining and inference of large deep learning models. Their main challenge is\nthat a careful choice of scaling is needed to prevent degradation due to the\nreduced dynamic range compared to higher-precision formats. Although there\nexists ample literature about selecting such scalings for INT formats, this\ncritical aspect has yet to be addressed for FP8. This paper presents a\nmethodology to select the scalings for FP8 linear layers, based on dynamically\nupdating per-tensor scales for the weights, gradients and activations. We apply\nthis methodology to train and validate large language models of the type of GPT\nand Llama 2 using FP8, for model sizes ranging from 111M to 70B. To facilitate\nthe understanding of the FP8 dynamics, our results are accompanied by plots of\nthe per-tensor scale distribution for weights, activations and gradients during\nboth training and inference.\n",
                "链接": "https://arxiv.org/abs/2309.17224"
            },
            {
                "文章ID": "66851",
                "标题": "Prompting Large Language Models With the Socratic Method",
                "作者": " Edward Y. Chang",
                "发布日期": "2023-03-17",
                "摘要": "  This paper presents a systematic approach to using the Socratic method in\ndeveloping prompt templates that effectively interact with large language\nmodels, including GPT-3. Various methods are examined, and those that yield\nprecise answers and justifications while fostering creativity and imagination\nto enhance creative writing are identified. Techniques such as {\\em\ndefinition}, {\\em elenchus}, {\\em dialectic}, {\\em maieutics}, {\\em\ngeneralization}, and {\\em counterfactual reasoning} are discussed for their\napplication in engineering prompt templates and their connections to inductive,\ndeductive, and abductive reasoning. Through examples, the effectiveness of\nthese dialogue and reasoning methods is demonstrated. An interesting\nobservation is made that when the task's goal and user intent are conveyed to\nGPT-3 via ChatGPT before the start of a dialogue, the large language model\nseems to connect to the external context expressed in the intent and perform\nmore effectively.\n",
                "链接": "https://arxiv.org/abs/2303.08769"
            },
            {
                "文章ID": "123966",
                "标题": "Lookahead: An Inference Acceleration Framework for Large Language Model\n  with Lossless Generation Accuracy",
                "作者": " Yao Zhao,  Zhitian Xie,  Chenyi Zhuang,  Jinjie Gu",
                "发布日期": "2023-12-21",
                "摘要": "  As Large Language Models (LLMs) have made significant advancements across\nvarious tasks, such as question answering, translation, text summarization, and\ndialogue systems, the need for accuracy in information becomes crucial,\nespecially for serious financial products serving billions of users like\nAlipay. To address this, Alipay has developed a Retrieval-Augmented Generation\n(RAG) system that grounds LLMs on the most accurate and up-to-date information.\nHowever, for a real-world product serving millions of users, the inference\nspeed of LLMs becomes a critical factor compared to a mere experimental model.\n  Hence, this paper presents a generic framework for accelerating the inference\nprocess, resulting in a substantial increase in speed and cost reduction for\nour RAG system, with lossless generation accuracy. In the traditional inference\nprocess, each token is generated sequentially by the LLM, leading to a time\nconsumption proportional to the number of generated tokens. To enhance this\nprocess, our framework, named \\textit{lookahead}, introduces a\n\\textit{multi-branch} strategy. Instead of generating a single token at a time,\nwe propose a \\textit{Trie-based Retrieval} (TR) process that enables the\ngeneration of multiple branches simultaneously, each of which is a sequence of\ntokens. Subsequently, for each branch, a \\textit{Verification and Accept} (VA)\nprocess is performed to identify the longest correct sub-sequence as the final\noutput. Our strategy offers two distinct advantages: (1) it guarantees absolute\ncorrectness of the output, avoiding any approximation algorithms, and (2) the\nworst-case performance of our approach is equivalent to the conventional\nprocess. We conduct extensive experiments to demonstrate the significant\nimprovements achieved by applying our inference acceleration framework.\n",
                "链接": "https://arxiv.org/abs/2312.12728"
            },
            {
                "文章ID": "116233",
                "标题": "SUQL: Conversational Search over Structured and Unstructured Data with\n  Large Language Models",
                "作者": " Shicheng Liu,  Jialiang Xu,  Wesley Tjangnaka,  Sina J. Semnani,  Chen Jie Yu,  Gui Dávid,  Monica S. Lam",
                "发布日期": "2023-11-17",
                "摘要": "  Many knowledge sources consist of both structured information such as\nrelational databases as well as unstructured free text. Building a\nconversational interface to such data sources is challenging.\n  This paper introduces SUQL, Structured and Unstructured Query Language, the\nfirst formal executable representation that naturally covers compositions of\nstructured and unstructured data queries. Specifically, it augments SQL with\nseveral free-text primitives to form a precise, succinct, and expressive\nrepresentation. This paper also presents a conversational search agent based on\nlarge language models, including a few-shot contextual semantic parser for\nSUQL.\n  To validate our approach, we introduce a dataset consisting of crowdsourced\nquestions and conversations about real restaurants. Over 51% of the questions\nin the dataset require both structured and unstructured data, suggesting that\nit is a common phenomenon. We show that our few-shot conversational agent based\non SUQL finds an entity satisfying all user requirements 89.3% of the time,\ncompared to just 65.0% for a strong and commonly used baseline.\n",
                "链接": "https://arxiv.org/abs/2311.09818"
            },
            {
                "文章ID": "11552",
                "标题": "Language Models that Seek for Knowledge: Modular Search & Generation for\n  Dialogue and Prompt Completion",
                "作者": " Kurt Shuster,  Mojtaba Komeili,  Leonard Adolphs,  Stephen Roller,  Arthur Szlam,  Jason Weston",
                "发布日期": "2022-03-31",
                "摘要": "  Language models (LMs) have recently been shown to generate more factual\nresponses by employing modularity (Zhou et al., 2021) in combination with\nretrieval (Adolphs et al., 2021). We extend the recent approach of Adolphs et\nal. (2021) to include internet search as a module. Our SeeKeR (Search\nengine->Knowledge->Response) method thus applies a single LM to three modular\ntasks in succession: search, generating knowledge, and generating a final\nresponse. We show that, when using SeeKeR as a dialogue model, it outperforms\nthe state-of-the-art model BlenderBot 2 (Chen et al., 2021) on open-domain\nknowledge-grounded conversations for the same number of parameters, in terms of\nconsistency, knowledge and per-turn engagingness. SeeKeR applied to topical\nprompt completions as a standard language model outperforms GPT2 (Radford et\nal., 2019) and GPT3 (Brown et al., 2020) in terms of factuality and topicality,\ndespite GPT3 being a vastly larger model. Our code and models are made publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2203.13224"
            },
            {
                "文章ID": "108455",
                "标题": "Tree-Planner: Efficient Close-loop Task Planning with Large Language\n  Models",
                "作者": " Mengkang Hu,  Yao Mu,  Xinmiao Yu,  Mingyu Ding,  Shiguang Wu,  Wenqi Shao,  Qiguang Chen,  Bin Wang,  Yu Qiao,  Ping Luo",
                "发布日期": "2023-10-13",
                "摘要": "  This paper studies close-loop task planning, which refers to the process of\ngenerating a sequence of skills (a plan) to accomplish a specific goal while\nadapting the plan based on real-time observations. Recently, prompting Large\nLanguage Models (LLMs) to generate actions iteratively has become a prevalent\nparadigm due to its superior performance and user-friendliness. However, this\nparadigm is plagued by two inefficiencies: high token consumption and redundant\nerror correction, both of which hinder its scalability for large-scale testing\nand applications. To address these issues, we propose Tree-Planner, which\nreframes task planning with LLMs into three distinct phases: plan sampling,\naction tree construction, and grounded deciding. Tree-Planner starts by using\nan LLM to sample a set of potential plans before execution, followed by the\naggregation of them to form an action tree. Finally, the LLM performs a\ntop-down decision-making process on the tree, taking into account real-time\nenvironmental information. Experiments show that Tree-Planner achieves\nstate-of-the-art performance while maintaining high efficiency. By decomposing\nLLM queries into a single plan-sampling call and multiple grounded-deciding\ncalls, a considerable part of the prompt are less likely to be repeatedly\nconsumed. As a result, token consumption is reduced by 92.2% compared to the\npreviously best-performing model. Additionally, by enabling backtracking on the\naction tree as needed, the correction process becomes more flexible, leading to\na 40.5% decrease in error corrections. Project page:\nhttps://tree-planner.github.io/\n",
                "链接": "https://arxiv.org/abs/2310.08582"
            },
            {
                "文章ID": "120237",
                "标题": "PEFA: Parameter-Free Adapters for Large-scale Embedding-based Retrieval\n  Models",
                "作者": " Wei-Cheng Chang,  Jyun-Yu Jiang,  Jiong Zhang,  Mutasem Al-Darabsah,  Choon Hui Teo,  Cho-Jui Hsieh,  Hsiang-Fu Yu,  S. V. N. Vishwanathan",
                "发布日期": "2023-12-07",
                "摘要": "  Embedding-based Retrieval Models (ERMs) have emerged as a promising framework\nfor large-scale text retrieval problems due to powerful large language models.\nNevertheless, fine-tuning ERMs to reach state-of-the-art results can be\nexpensive due to the extreme scale of data as well as the complexity of\nmulti-stages pipelines (e.g., pre-training, fine-tuning, distillation). In this\nwork, we propose the PEFA framework, namely ParamEter-Free Adapters, for fast\ntuning of ERMs without any backward pass in the optimization. At index building\nstage, PEFA equips the ERM with a non-parametric k-nearest neighbor (kNN)\ncomponent. At inference stage, PEFA performs a convex combination of two\nscoring functions, one from the ERM and the other from the kNN. Based on the\nneighborhood definition, PEFA framework induces two realizations, namely\nPEFA-XL (i.e., extra large) using double ANN indices and PEFA-XS (i.e., extra\nsmall) using a single ANN index. Empirically, PEFA achieves significant\nimprovement on two retrieval applications. For document retrieval, regarding\nRecall@100 metric, PEFA improves not only pre-trained ERMs on Trivia-QA by an\naverage of 13.2%, but also fine-tuned ERMs on NQ-320K by an average of 5.5%,\nrespectively. For product search, PEFA improves the Recall@100 of the\nfine-tuned ERMs by an average of 5.3% and 14.5%, for PEFA-XS and PEFA-XL,\nrespectively. Our code is available at\nhttps://github.com/amzn/pecos/tree/mainline/examples/pefa-wsdm24.\n",
                "链接": "https://arxiv.org/abs/2312.02429"
            },
            {
                "文章ID": "79244",
                "标题": "Farewell to Aimless Large-scale Pretraining: Influential Subset\n  Selection for Language Model",
                "作者": " Xiao Wang,  Weikang Zhou,  Qi Zhang,  Jie Zhou,  Songyang Gao,  Junzhe Wang,  Menghan Zhang,  Xiang Gao,  Yunwen Chen,  Tao Gui",
                "发布日期": "2023-05-23",
                "摘要": "  Pretrained language models have achieved remarkable success in various\nnatural language processing tasks. However, pretraining has recently shifted\ntoward larger models and larger data, and this has resulted in significant\ncomputational and energy costs. In this paper, we propose Influence Subset\nSelection (ISS) for language model, which explicitly utilizes end-task\nknowledge to select a tiny subset of the pretraining corpus. Specifically, the\nISS selects the samples that will provide the most positive influence on the\nperformance of the end-task. Furthermore, we design a gradient matching based\ninfluence estimation method, which can drastically reduce the computation time\nof influence. With only 0.45% of the data and a three-orders-of-magnitude lower\ncomputational cost, ISS outperformed pretrained models (e.g., RoBERTa) on eight\ndatasets covering four domains.\n",
                "链接": "https://arxiv.org/abs/2305.12816"
            },
            {
                "文章ID": "47768",
                "标题": "Generalization of generative model for neuronal ensemble inference\n  method",
                "作者": " Shun Kimura,  Koujin Takeda",
                "发布日期": "2023-06-29",
                "摘要": "  Various brain functions that are necessary to maintain life activities\nmaterialize through the interaction of countless neurons. Therefore, it is\nimportant to analyze functional neuronal network. To elucidate the mechanism of\nbrain function, many studies are being actively conducted on functional\nneuronal ensemble and hub, including all areas of neuroscience. In addition,\nrecent study suggests that the existence of functional neuronal ensembles and\nhubs contributes to the efficiency of information processing. For these\nreasons, there is a demand for methods to infer functional neuronal ensembles\nfrom neuronal activity data, and methods based on Bayesian inference have been\nproposed. However, there is a problem in modeling the activity in Bayesian\ninference. The features of each neuron's activity have non-stationarity\ndepending on physiological experimental conditions. As a result, the assumption\nof stationarity in Bayesian inference model impedes inference, which leads to\ndestabilization of inference results and degradation of inference accuracy. In\nthis study, we extend the range of the variable for expressing the neuronal\nstate, and generalize the likelihood of the model for extended variables. By\ncomparing with the previous study, our model can express the neuronal state in\nlarger space. This generalization without restriction of the binary input\nenables us to perform soft clustering and apply the method to non-stationary\nneuroactivity data. In addition, for the effectiveness of the method, we apply\nthe developed method to multiple synthetic fluorescence data generated from the\nelectrical potential data in leaky integrated-and-fire model.\n",
                "链接": "https://arxiv.org/abs/2211.05634"
            },
            {
                "文章ID": "79552",
                "标题": "A Study of Generative Large Language Model for Medical Research and\n  Healthcare",
                "作者": " Cheng Peng,  Xi Yang,  Aokun Chen,  Kaleb E Smith,  Nima PourNejatian,  Anthony B Costa,  Cheryl Martin,  Mona G Flores,  Ying Zhang,  Tanja Magoc,  Gloria Lipori,  Duane A Mitchell,  Naykky S Ospina,  Mustafa M Ahmed,  William R Hogan,  Elizabeth A Shenkman,  Yi Guo,  Jiang Bian,  Yonghui Wu",
                "发布日期": "2023-11-20",
                "摘要": "  There is enormous enthusiasm and concerns in using large language models\n(LLMs) in healthcare, yet current assumptions are all based on general-purpose\nLLMs such as ChatGPT. This study develops a clinical generative LLM,\nGatorTronGPT, using 277 billion words of mixed clinical and English text with a\nGPT-3 architecture of 20 billion parameters. GatorTronGPT improves biomedical\nnatural language processing for medical research. Synthetic NLP models trained\nusing GatorTronGPT generated text outperform NLP models trained using\nreal-world clinical text. Physicians Turing test using 1 (worst) to 9 (best)\nscale shows that there is no significant difference in linguistic readability\n(p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical\nrelevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that\nphysicians cannot differentiate them (p < 0.001). This study provides insights\non the opportunities and challenges of LLMs for medical research and\nhealthcare.\n",
                "链接": "https://arxiv.org/abs/2305.13523"
            },
            {
                "文章ID": "81190",
                "标题": "Levin Tree Search with Context Models",
                "作者": " Laurent Orseau,  Marcus Hutter,  Levi H. S. Lelis",
                "发布日期": "2023-06-28",
                "摘要": "  Levin Tree Search (LTS) is a search algorithm that makes use of a policy (a\nprobability distribution over actions) and comes with a theoretical guarantee\non the number of expansions before reaching a goal node, depending on the\nquality of the policy. This guarantee can be used as a loss function, which we\ncall the LTS loss, to optimize neural networks representing the policy\n(LTS+NN). In this work we show that the neural network can be substituted with\nparameterized context models originating from the online compression literature\n(LTS+CM). We show that the LTS loss is convex under this new model, which\nallows for using standard convex optimization tools, and obtain convergence\nguarantees to the optimal parameters in an online setting for a given set of\nsolution trajectories -- guarantees that cannot be provided for neural\nnetworks. The new LTS+CM algorithm compares favorably against LTS+NN on several\nbenchmarks: Sokoban (Boxoban), The Witness, and the 24-Sliding Tile puzzle\n(STP). The difference is particularly large on STP, where LTS+NN fails to solve\nmost of the test instances while LTS+CM solves each test instance in a fraction\nof a second. Furthermore, we show that LTS+CM is able to learn a policy that\nsolves the Rubik's cube in only a few hundred expansions, which considerably\nimproves upon previous machine learning techniques.\n",
                "链接": "https://arxiv.org/abs/2305.16945"
            },
            {
                "文章ID": "87317",
                "标题": "AudioPaLM: A Large Language Model That Can Speak and Listen",
                "作者": " Paul K. Rubenstein,  Chulayuth Asawaroengchai,  Duc Dung Nguyen,  Ankur Bapna,  Zalán Borsos,  Félix de Chaumont Quitry,  Peter Chen,  Dalia El Badawy,  Wei Han,  Eugene Kharitonov,  Hannah Muckenhirn,  Dirk Padfield,  James Qin,  Danny Rozenberg,  Tara Sainath,  Johan Schalkwyk,  Matt Sharifi,  Michelle Tadmor Ramanovich,  Marco Tagliasacchi,  Alexandru Tudor,  Mihajlo Velimirović,  Damien Vincent,  Jiahui Yu,  Yongqiang Wang,  Vicky Zayats,  Neil Zeghidour,  Yu Zhang,  Zhishuai Zhang,  Lukas Zilka,  Christian Frank",
                "发布日期": "2023-06-23",
                "摘要": "  We introduce AudioPaLM, a large language model for speech understanding and\ngeneration. AudioPaLM fuses text-based and speech-based language models, PaLM-2\n[Anil et al., 2023] and AudioLM [Borsos et al., 2022], into a unified\nmultimodal architecture that can process and generate text and speech with\napplications including speech recognition and speech-to-speech translation.\nAudioPaLM inherits the capability to preserve paralinguistic information such\nas speaker identity and intonation from AudioLM and the linguistic knowledge\npresent only in text large language models such as PaLM-2. We demonstrate that\ninitializing AudioPaLM with the weights of a text-only large language model\nimproves speech processing, successfully leveraging the larger quantity of text\ntraining data used in pretraining to assist with the speech tasks. The\nresulting model significantly outperforms existing systems for speech\ntranslation tasks and has the ability to perform zero-shot speech-to-text\ntranslation for many languages for which input/target language combinations\nwere not seen in training. AudioPaLM also demonstrates features of audio\nlanguage models, such as transferring a voice across languages based on a short\nspoken prompt. We release examples of our method at\nhttps://google-research.github.io/seanet/audiopalm/examples\n",
                "链接": "https://arxiv.org/abs/2306.12925"
            },
            {
                "文章ID": "121946",
                "标题": "Multilingual large language models leak human stereotypes across\n  language boundaries",
                "作者": " Yang Trista Cao,  Anna Sotnikova,  Jieyu Zhao,  Linda X. Zou,  Rachel Rudinger, III Hal Daume",
                "发布日期": "2023-12-13",
                "摘要": "  Multilingual large language models have been increasingly popular for their\nproficiency in comprehending and generating text across various languages.\nPrevious research has shown that the presence of stereotypes and biases in\nmonolingual large language models can be attributed to the nature of their\ntraining data, which is collected from humans and reflects societal biases.\nMultilingual language models undergo the same training procedure as monolingual\nones, albeit with training data sourced from various languages. This raises the\nquestion: do stereotypes present in one social context leak across languages\nwithin the model? In our work, we first define the term ``stereotype leakage''\nand propose a framework for its measurement. With this framework, we\ninvestigate how stereotypical associations leak across four languages: English,\nRussian, Chinese, and Hindi. To quantify the stereotype leakage, we employ an\napproach from social psychology, measuring stereotypes via group-trait\nassociations. We evaluate human stereotypes and stereotypical associations\nmanifested in multilingual large language models such as mBERT, mT5, and\nChatGPT. Our findings show a noticeable leakage of positive, negative, and\nnon-polar associations across all languages. Notably, Hindi within multilingual\nmodels appears to be the most susceptible to influence from other languages,\nwhile Chinese is the least. Additionally, ChatGPT exhibits a better alignment\nwith human scores than other models.\n",
                "链接": "https://arxiv.org/abs/2312.07141"
            },
            {
                "文章ID": "94006",
                "标题": "Three Bricks to Consolidate Watermarks for Large Language Models",
                "作者": " Pierre Fernandez,  Antoine Chaffin,  Karim Tit,  Vivien Chappelier,  Teddy Furon",
                "发布日期": "2023-11-09",
                "摘要": "  The task of discerning between generated and natural texts is increasingly\nchallenging. In this context, watermarking emerges as a promising technique for\nascribing generated text to a specific model. It alters the sampling generation\nprocess so as to leave an invisible trace in the generated output, facilitating\nlater detection. This research consolidates watermarks for large language\nmodels based on three theoretical and empirical considerations. First, we\nintroduce new statistical tests that offer robust theoretical guarantees which\nremain valid even at low false-positive rates (less than 10$^{\\text{-6}}$).\nSecond, we compare the effectiveness of watermarks using classical benchmarks\nin the field of natural language processing, gaining insights into their\nreal-world applicability. Third, we develop advanced detection schemes for\nscenarios where access to the LLM is available, as well as multi-bit\nwatermarking.\n",
                "链接": "https://arxiv.org/abs/2308.00113"
            },
            {
                "文章ID": "106719",
                "标题": "Chain of Natural Language Inference for Reducing Large Language Model\n  Ungrounded Hallucinations",
                "作者": " Deren Lei,  Yaxi Li,  Mengya Hu,  Mingyu Wang,  Vincent Yun,  Emily Ching,  Eslam Kamal",
                "发布日期": "2023-10-11",
                "摘要": "  Large language models (LLMs) can generate fluent natural language texts when\ngiven relevant documents as background context. This ability has attracted\nconsiderable interest in developing industry applications of LLMs. However,\nLLMs are prone to generate hallucinations that are not supported by the\nprovided sources. In this paper, we propose a hierarchical framework to detect\nand mitigate such ungrounded hallucination. Our framework uses Chain of Natural\nLanguage Inference (CoNLI) for hallucination detection and hallucination\nreduction via post-editing. Our approach achieves state-of-the-art performance\non hallucination detection and enhances text quality through rewrite, using\nLLMs without any fine-tuning or domain-specific prompt engineering. We show\nthat this simple plug-and-play framework can serve as an effective choice for\nhallucination detection and reduction, achieving competitive performance across\nvarious contexts.\n",
                "链接": "https://arxiv.org/abs/2310.03951"
            },
            {
                "文章ID": "120700",
                "标题": "Methods to Estimate Large Language Model Confidence",
                "作者": " Maia Kotelanski,  Robert Gallo,  Ashwin Nayak,  Thomas Savage",
                "发布日期": "2023-12-11",
                "摘要": "  Large Language Models have difficulty communicating uncertainty, which is a\nsignificant obstacle to applying LLMs to complex medical tasks. This study\nevaluates methods to measure LLM confidence when suggesting a diagnosis for\nchallenging clinical vignettes. GPT4 was asked a series of challenging case\nquestions using Chain of Thought and Self Consistency prompting. Multiple\nmethods were investigated to assess model confidence and evaluated on their\nability to predict the models observed accuracy. The methods evaluated were\nIntrinsic Confidence, SC Agreement Frequency and CoT Response Length. SC\nAgreement Frequency correlated with observed accuracy, yielding a higher Area\nunder the Receiver Operating Characteristic Curve compared to Intrinsic\nConfidence and CoT Length analysis. SC agreement is the most useful proxy for\nmodel confidence, especially for medical diagnosis. Model Intrinsic Confidence\nand CoT Response Length exhibit a weaker ability to differentiate between\ncorrect and incorrect answers, preventing them from being reliable and\ninterpretable markers for model confidence. We conclude GPT4 has a limited\nability to assess its own diagnostic accuracy. SC Agreement Frequency is the\nmost useful method to measure GPT4 confidence.\n",
                "链接": "https://arxiv.org/abs/2312.03733"
            },
            {
                "文章ID": "79750",
                "标题": "Generating Data for Symbolic Language with Large Language Models",
                "作者": " Jiacheng Ye,  Chengzu Li,  Lingpeng Kong,  Tao Yu",
                "发布日期": "2023-05-24",
                "摘要": "  While large language models (LLMs) bring not only performance but also\ncomplexity, recent work has started to turn LLMs into data generators rather\nthan task inferencers, where another affordable task model is trained for\nefficient deployment and inference. However, such an approach has primarily\nbeen applied to natural language tasks and has not yet been explored for\nsymbolic language tasks with complex structured outputs (e.g., semantic parsing\nand code generation). In this paper, we propose SymGen which utilizes LLMs for\ngenerating various annotation-expensive symbolic language data. SymGen consists\nof an informative prompt to steer generation and an agreement-based verifier to\nimprove data correctness. We conduct extensive experiments on six symbolic\nlanguage tasks across various settings. Compared with the LLMs, we demonstrate\nthe 1\\%-sized task model can achieve comparable or better performance, largely\ncutting inference and deployment costs. We also show that generated data with\nonly a few human demonstrations can be as effective as over 10 times the amount\nof human-annotated data when training the task model, saving a considerable\namount of annotation effort. SymGen sheds new light on data generation for\ncomplex tasks, and we release the code at\n\\href{https://github.com/HKUNLP/SymGen}{https://github.com/HKUNLP/SymGen}.\n",
                "链接": "https://arxiv.org/abs/2305.13917"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态大模型理解和生成统一建模、端到端训练相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "120673",
                "标题": "OneLLM: One Framework to Align All Modalities with Language",
                "作者": " Jiaming Han,  Kaixiong Gong,  Yiyuan Zhang,  Jiaqi Wang,  Kaipeng Zhang,  Dahua Lin,  Yu Qiao,  Peng Gao,  Xiangyu Yue",
                "发布日期": "2023-12-07",
                "摘要": "  Multimodal large language models (MLLMs) have gained significant attention\ndue to their strong multimodal understanding capability. However, existing\nworks rely heavily on modality-specific encoders, which usually differ in\narchitecture and are limited to common modalities. In this paper, we present\nOneLLM, an MLLM that aligns eight modalities to language using a unified\nframework. We achieve this through a unified multimodal encoder and a\nprogressive multimodal alignment pipeline. In detail, we first train an image\nprojection module to connect a vision encoder with LLM. Then, we build a\nuniversal projection module (UPM) by mixing multiple image projection modules\nand dynamic routing. Finally, we progressively align more modalities to LLM\nwith the UPM. To fully leverage the potential of OneLLM in following\ninstructions, we also curated a comprehensive multimodal instruction dataset,\nincluding 2M items from image, audio, video, point cloud, depth/normal map, IMU\nand fMRI brain activity. OneLLM is evaluated on 25 diverse benchmarks,\nencompassing tasks such as multimodal captioning, question answering and\nreasoning, where it delivers excellent performance. Code, data, model and\nonline demo are available at https://github.com/csuhan/OneLLM\n",
                "链接": "https://arxiv.org/abs/2312.03700"
            },
            {
                "文章ID": "125308",
                "标题": "Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision,\n  Language, Audio, and Action",
                "作者": " Jiasen Lu,  Christopher Clark,  Sangho Lee,  Zichen Zhang,  Savya Khosla,  Ryan Marten,  Derek Hoiem,  Aniruddha Kembhavi",
                "发布日期": "2023-12-29",
                "摘要": "  We present Unified-IO 2, the first autoregressive multimodal model that is\ncapable of understanding and generating image, text, audio, and action. To\nunify different modalities, we tokenize inputs and outputs -- images, text,\naudio, action, bounding boxes, etc., into a shared semantic space and then\nprocess them with a single encoder-decoder transformer model. Since training\nwith such diverse modalities is challenging, we propose various architectural\nimprovements to stabilize model training. We train our model from scratch on a\nlarge multimodal pre-training corpus from diverse sources with a multimodal\nmixture of denoisers objective. To learn an expansive set of skills, such as\nfollowing multimodal instructions, we construct and finetune on an ensemble of\n120 datasets with prompts and augmentations. With a single unified model,\nUnified-IO 2 achieves state-of-the-art performance on the GRIT benchmark and\nstrong results in more than 35 benchmarks, including image generation and\nunderstanding, natural language understanding, video and audio understanding,\nand robotic manipulation. We release all our models to the research community.\n",
                "链接": "https://arxiv.org/abs/2312.17172"
            },
            {
                "文章ID": "15417",
                "标题": "LayoutLMv3: Pre-training for Document AI with Unified Text and Image\n  Masking",
                "作者": " Yupan Huang,  Tengchao Lv,  Lei Cui,  Yutong Lu,  Furu Wei",
                "发布日期": "2022-07-20",
                "摘要": "  Self-supervised pre-training techniques have achieved remarkable progress in\nDocument AI. Most multimodal pre-trained models use a masked language modeling\nobjective to learn bidirectional representations on the text modality, but they\ndiffer in pre-training objectives for the image modality. This discrepancy adds\ndifficulty to multimodal representation learning. In this paper, we propose\n\\textbf{LayoutLMv3} to pre-train multimodal Transformers for Document AI with\nunified text and image masking. Additionally, LayoutLMv3 is pre-trained with a\nword-patch alignment objective to learn cross-modal alignment by predicting\nwhether the corresponding image patch of a text word is masked. The simple\nunified architecture and training objectives make LayoutLMv3 a general-purpose\npre-trained model for both text-centric and image-centric Document AI tasks.\nExperimental results show that LayoutLMv3 achieves state-of-the-art performance\nnot only in text-centric tasks, including form understanding, receipt\nunderstanding, and document visual question answering, but also in\nimage-centric tasks such as document image classification and document layout\nanalysis. The code and models are publicly available at\n\\url{https://aka.ms/layoutlmv3}.\n",
                "链接": "https://arxiv.org/abs/2204.08387"
            },
            {
                "文章ID": "119041",
                "标题": "C3Net: Compound Conditioned ControlNet for Multimodal Content Generation",
                "作者": " Juntao Zhang,  Yuehuai Liu,  Yu-Wing Tai,  Chi-Keung Tang",
                "发布日期": "2023-12-01",
                "摘要": "  We present Compound Conditioned ControlNet, C3Net, a novel generative neural\narchitecture taking conditions from multiple modalities and synthesizing\nmultimodal contents simultaneously (e.g., image, text, audio). C3Net adapts the\nControlNet architecture to jointly train and make inferences on a\nproduction-ready diffusion model and its trainable copies. Specifically, C3Net\nfirst aligns the conditions from multi-modalities to the same semantic latent\nspace using modality-specific encoders based on contrastive training. Then, it\ngenerates multimodal outputs based on the aligned latent space, whose semantic\ninformation is combined using a ControlNet-like architecture called Control\nC3-UNet. Correspondingly, with this system design, our model offers an improved\nsolution for joint-modality generation through learning and explaining\nmultimodal conditions instead of simply taking linear interpolations on the\nlatent space. Meanwhile, as we align conditions to a unified latent space,\nC3Net only requires one trainable Control C3-UNet to work on multimodal\nsemantic information. Furthermore, our model employs unimodal pretraining on\nthe condition alignment stage, outperforming the non-pretrained alignment even\non relatively scarce training data and thus demonstrating high-quality compound\ncondition generation. We contribute the first high-quality tri-modal validation\nset to validate quantitatively that C3Net outperforms or is on par with first\nand contemporary state-of-the-art multimodal generation. Our codes and\ntri-modal dataset will be released.\n",
                "链接": "https://arxiv.org/abs/2311.17951"
            },
            {
                "文章ID": "89570",
                "标题": "mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document\n  Understanding",
                "作者": " Jiabo Ye,  Anwen Hu,  Haiyang Xu,  Qinghao Ye,  Ming Yan,  Yuhao Dan,  Chenlin Zhao,  Guohai Xu,  Chenliang Li,  Junfeng Tian,  Qian Qi,  Ji Zhang,  Fei Huang",
                "发布日期": "2023-07-07",
                "摘要": "  Document understanding refers to automatically extract, analyze and\ncomprehend information from various types of digital documents, such as a web\npage. Existing Multi-model Large Language Models (MLLMs), including mPLUG-Owl,\nhave demonstrated promising zero-shot capabilities in shallow OCR-free text\nrecognition, indicating their potential for OCR-free document understanding.\nNevertheless, without in-domain training, these models tend to ignore\nfine-grained OCR features, such as sophisticated tables or large blocks of\ntext, which are essential for OCR-free document understanding. In this paper,\nwe propose mPLUG-DocOwl based on mPLUG-Owl for OCR-free document understanding.\nSpecifically, we first construct a instruction tuning dataset featuring a wide\nrange of visual-text understanding tasks. Then, we strengthen the OCR-free\ndocument understanding ability by jointly train the model on language-only,\ngeneral vision-and-language, and document instruction tuning dataset with our\nunified instruction tuning strategy. We also build an OCR-free document\ninstruction understanding evaluation set LLMDoc to better compare models'\ncapabilities on instruct compliance and document understanding. Experimental\nresults show that our model outperforms existing multi-modal models,\ndemonstrating its strong ability of document understanding. Besides, without\nspecific fine-tuning, mPLUG-DocOwl generalizes well on various downstream\ntasks. Our code, models, training data and evaluation set are available at\nhttps://github.com/X-PLUG/mPLUG-DocOwl.\n",
                "链接": "https://arxiv.org/abs/2307.02499"
            },
            {
                "文章ID": "21649",
                "标题": "Multimodal Masked Autoencoders Learn Transferable Representations",
                "作者": " Xinyang Geng,  Hao Liu,  Lisa Lee,  Dale Schuurmans,  Sergey Levine,  Pieter Abbeel",
                "发布日期": "2022-10-24",
                "摘要": "  Building scalable models to learn from diverse, multimodal data remains an\nopen challenge. For vision-language data, the dominant approaches are based on\ncontrastive learning objectives that train a separate encoder for each\nmodality. While effective, contrastive learning approaches introduce sampling\nbias depending on the data augmentations used, which can degrade performance on\ndownstream tasks. Moreover, these methods are limited to paired image-text\ndata, and cannot leverage widely-available unpaired data. In this paper, we\ninvestigate whether a large multimodal model trained purely via masked token\nprediction, without using modality-specific encoders or contrastive learning,\ncan learn transferable representations for downstream tasks. We propose a\nsimple and scalable network architecture, the Multimodal Masked Autoencoder\n(M3AE), which learns a unified encoder for both vision and language data via\nmasked token prediction. We provide an empirical study of M3AE trained on a\nlarge-scale image-text dataset, and find that M3AE is able to learn\ngeneralizable representations that transfer well to downstream tasks.\nSurprisingly, we find that M3AE benefits from a higher text mask ratio\n(50-90%), in contrast to BERT whose standard masking ratio is 15%, due to the\njoint training of two data modalities. We also provide qualitative analysis\nshowing that the learned representation incorporates meaningful information\nfrom both image and language. Lastly, we demonstrate the scalability of M3AE\nwith larger model size and training time, and its flexibility to train on both\npaired image-text data as well as unpaired data.\n",
                "链接": "https://arxiv.org/abs/2205.14204"
            },
            {
                "文章ID": "123045",
                "标题": "UniAR: Unifying Human Attention and Response Prediction on Visual\n  Content",
                "作者": " Peizhao Li,  Junfeng He,  Gang Li,  Rachit Bhargava,  Shaolei Shen,  Nachiappan Valliappan,  Youwei Liang,  Hongxiang Gu,  Venky Ramachandran,  Golnaz Farhadi,  Yang Li,  Kai J Kohlhoff,  Vidhya Navalpakkam",
                "发布日期": "2023-12-19",
                "摘要": "  Progress in human behavior modeling involves understanding both implicit,\nearly-stage perceptual behavior such as human attention and explicit,\nlater-stage behavior such as subjective ratings/preferences. Yet, most prior\nresearch has focused on modeling implicit and explicit human behavior in\nisolation. Can we build a unified model of human attention and preference\nbehavior that reliably works across diverse types of visual content? Such a\nmodel would enable predicting subjective feedback such as overall satisfaction\nor aesthetic quality ratings, along with the underlying human attention or\ninteraction heatmaps and viewing order, enabling designers and content-creation\nmodels to optimize their creation for human-centric improvements. In this\npaper, we propose UniAR -- a unified model that predicts both implicit and\nexplicit human behavior across different types of visual content. UniAR\nleverages a multimodal transformer, featuring distinct prediction heads for\neach facet, and predicts attention heatmap, scanpath or viewing order, and\nsubjective rating/preference. We train UniAR on diverse public datasets\nspanning natural images, web pages and graphic designs, and achieve leading\nperformance on multiple benchmarks across different image domains and various\nbehavior modeling tasks. Potential applications include providing instant\nfeedback on the effectiveness of UIs/digital designs/images, and serving as a\nreward model to further optimize design/image creation.\n",
                "链接": "https://arxiv.org/abs/2312.10175"
            },
            {
                "文章ID": "71145",
                "标题": "Vita-CLIP: Video and text adaptive CLIP via Multimodal Prompting",
                "作者": " Syed Talal Wasim,  Muzammal Naseer,  Salman Khan,  Fahad Shahbaz Khan,  Mubarak Shah",
                "发布日期": "2023-04-10",
                "摘要": "  Adopting contrastive image-text pretrained models like CLIP towards video\nclassification has gained attention due to its cost-effectiveness and\ncompetitive performance. However, recent works in this area face a trade-off.\nFinetuning the pretrained model to achieve strong supervised performance\nresults in low zero-shot generalization. Similarly, freezing the backbone to\nretain zero-shot capability causes significant drop in supervised accuracy.\nBecause of this, recent works in literature typically train separate models for\nsupervised and zero-shot action recognition. In this work, we propose a\nmultimodal prompt learning scheme that works to balance the supervised and\nzero-shot performance under a single unified training. Our prompting approach\non the vision side caters for three aspects: 1) Global video-level prompts to\nmodel the data distribution; 2) Local frame-level prompts to provide per-frame\ndiscriminative conditioning; and 3) a summary prompt to extract a condensed\nvideo representation. Additionally, we define a prompting scheme on the text\nside to augment the textual context. Through this prompting scheme, we can\nachieve state-of-the-art zero-shot performance on Kinetics-600, HMDB51 and\nUCF101 while remaining competitive in the supervised setting. By keeping the\npretrained backbone frozen, we optimize a much lower number of parameters and\nretain the existing general representation which helps achieve the strong\nzero-shot performance. Our codes/models are released at\nhttps://github.com/TalalWasim/Vita-CLIP.\n",
                "链接": "https://arxiv.org/abs/2304.03307"
            },
            {
                "文章ID": "113994",
                "标题": "Unified Multi-modal Unsupervised Representation Learning for\n  Skeleton-based Action Understanding",
                "作者": " Shengkai Sun,  Daizong Liu,  Jianfeng Dong,  Xiaoye Qu,  Junyu Gao,  Xun Yang,  Xun Wang,  Meng Wang",
                "发布日期": "2023-11-07",
                "摘要": "  Unsupervised pre-training has shown great success in skeleton-based action\nunderstanding recently. Existing works typically train separate\nmodality-specific models, then integrate the multi-modal information for action\nunderstanding by a late-fusion strategy. Although these approaches have\nachieved significant performance, they suffer from the complex yet redundant\nmulti-stream model designs, each of which is also limited to the fixed input\nskeleton modality. To alleviate these issues, in this paper, we propose a\nUnified Multimodal Unsupervised Representation Learning framework, called\nUmURL, which exploits an efficient early-fusion strategy to jointly encode the\nmulti-modal features in a single-stream manner. Specifically, instead of\ndesigning separate modality-specific optimization processes for uni-modal\nunsupervised learning, we feed different modality inputs into the same stream\nwith an early-fusion strategy to learn their multi-modal features for reducing\nmodel complexity. To ensure that the fused multi-modal features do not exhibit\nmodality bias, i.e., being dominated by a certain modality input, we further\npropose both intra- and inter-modal consistency learning to guarantee that the\nmulti-modal features contain the complete semantics of each modal via feature\ndecomposition and distinct alignment. In this manner, our framework is able to\nlearn the unified representations of uni-modal or multi-modal skeleton input,\nwhich is flexible to different kinds of modality input for robust action\nunderstanding in practical cases. Extensive experiments conducted on three\nlarge-scale datasets, i.e., NTU-60, NTU-120, and PKU-MMD II, demonstrate that\nUmURL is highly efficient, possessing the approximate complexity with the\nuni-modal methods, while achieving new state-of-the-art performance across\nvarious downstream task scenarios in skeleton-based action representation\nlearning.\n",
                "链接": "https://arxiv.org/abs/2311.03106"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到从位置编码角度改善模型长序列建模能力的相关论文。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找可以用于验证模型推理能力的数据集论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "请帮我找到，最早提出分布式词表示的论文是哪一篇？",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "54196",
                "标题": "Multi hash embeddings in spaCy",
                "作者": " Lester James Miranda,  Ákos Kádár,  Adriane Boyd,  Sofie Van Landeghem,  Anders Søgaard,  Matthew Honnibal",
                "发布日期": "2022-12-20",
                "摘要": "  The distributed representation of symbols is one of the key technologies in\nmachine learning systems today, playing a pivotal role in modern natural\nlanguage processing. Traditional word embeddings associate a separate vector\nwith each word. While this approach is simple and leads to good performance, it\nrequires a lot of memory for representing a large vocabulary. To reduce the\nmemory footprint, the default embedding layer in spaCy is a hash embeddings\nlayer. It is a stochastic approximation of traditional embeddings that provides\nunique vectors for a large number of words without explicitly storing a\nseparate vector for each of them. To be able to compute meaningful\nrepresentations for both known and unknown words, hash embeddings represent\neach word as a summary of the normalized word form, subword information and\nword shape. Together, these features produce a multi-embedding of a word. In\nthis technical report we lay out a bit of history and introduce the embedding\nmethods in spaCy in detail. Second, we critically evaluate the hash embedding\narchitecture with multi-embeddings on Named Entity Recognition datasets from a\nvariety of domains and languages. The experiments validate most key design\nchoices behind spaCy's embedders, but we also uncover a few surprising results.\n",
                "链接": "https://arxiv.org/abs/2212.09255"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下nips 2023 paper list",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "36791",
                "标题": "An Improved Algorithm For Online Min-Sum Set Cover",
                "作者": " Marcin Bienkowski,  Marcin Mucha",
                "发布日期": "2023-03-28",
                "摘要": "  We study a fundamental model of online preference aggregation, where an\nalgorithm maintains an ordered list of $n$ elements. An input is a stream of\npreferred sets $R_1, R_2, \\dots, R_t, \\dots$. Upon seeing $R_t$ and without\nknowledge of any future sets, an algorithm has to rerank elements (change the\nlist ordering), so that at least one element of $R_t$ is found near the list\nfront. The incurred cost is a sum of the list update costs (the number of swaps\nof neighboring list elements) and access costs (position of the first element\nof $R_t$ on the list). This scenario occurs naturally in applications such as\nordering items in an online shop using aggregated preferences of shop\ncustomers. The theoretical underpinning of this problem is known as Min-Sum Set\nCover.\n  Unlike previous work (Fotakis et al., ICALP 2020, NIPS 2020) that mostly\nstudied the performance of an online algorithm ALG against the static optimal\nsolution (a single optimal list ordering), in this paper, we study an arguably\nharder variant where the benchmark is the provably stronger optimal dynamic\nsolution OPT (that may also modify the list ordering). In terms of an online\nshop, this means that the aggregated preferences of its user base evolve with\ntime. We construct a computationally efficient randomized algorithm whose\ncompetitive ratio (ALG-to-OPT cost ratio) is $O(r^2)$ and prove the existence\nof a deterministic $O(r^4)$-competitive algorithm. Here, $r$ is the maximum\ncardinality of sets $R_t$. This is the first algorithm whose ratio does not\ndepend on $n$: the previously best algorithm for this problem was $O(r^{3/2}\n\\cdot \\sqrt{n})$-competitive and $\\Omega(r)$ is a lower bound on the\nperformance of any deterministic online algorithm.\n",
                "链接": "https://arxiv.org/abs/2209.04870"
            },
            {
                "文章ID": "84628",
                "标题": "Overview of the Problem List Summarization (ProbSum) 2023 Shared Task on\n  Summarizing Patients' Active Diagnoses and Problems from Electronic Health\n  Record Progress Notes",
                "作者": " Yanjun Gao,  Dmitriy Dligach,  Timothy Miller,  Matthew M. Churpek,  Majid Afshar",
                "发布日期": "2023-06-09",
                "摘要": "  The BioNLP Workshop 2023 initiated the launch of a shared task on Problem\nList Summarization (ProbSum) in January 2023. The aim of this shared task is to\nattract future research efforts in building NLP models for real-world\ndiagnostic decision support applications, where a system generating relevant\nand accurate diagnoses will augment the healthcare providers decision-making\nprocess and improve the quality of care for patients. The goal for participants\nis to develop models that generated a list of diagnoses and problems using\ninput from the daily care notes collected from the hospitalization of\ncritically ill patients. Eight teams submitted their final systems to the\nshared task leaderboard. In this paper, we describe the tasks, datasets,\nevaluation metrics, and baseline systems. Additionally, the techniques and\nresults of the evaluation of the different approaches tried by the\nparticipating teams are summarized.\n",
                "链接": "https://arxiv.org/abs/2306.05270"
            },
            {
                "文章ID": "40312",
                "标题": "SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis",
                "作者": " Jiaxin Pei,  Vítor Silva,  Maarten Bos,  Yozon Liu,  Leonardo Neves,  David Jurgens,  Francesco Barbieri",
                "发布日期": "2023-02-06",
                "摘要": "  We propose MINT, a new Multilingual INTimacy analysis dataset covering 13,372\ntweets in 10 languages including English, French, Spanish, Italian, Portuguese,\nKorean, Dutch, Chinese, Hindi, and Arabic. We benchmarked a list of popular\nmultilingual pre-trained language models. The dataset is released along with\nthe SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis\n(https://sites.google.com/umich.edu/semeval-2023-tweet-intimacy).\n",
                "链接": "https://arxiv.org/abs/2210.01108"
            },
            {
                "文章ID": "99282",
                "标题": "Chunked Lists versus Extensible Arrays for Text Inversion",
                "作者": " David Hawking,  Bodo Billerbeck",
                "发布日期": "2023-08-31",
                "摘要": "  In our 2017 work on in-memory list-based text inversion [Hawking and\nBillerbeck. Efficient In-Memory, List-Based Text Inversion. ADCS 2017] we\ncompared memory use and indexing speed of a considerable number of variants of\nchunked linked lists. In the present work we compare the best performing of\nthose variants (FBB - dynamic Fibonacci chunking) with the extensible SQ array\ntechnique (SQA) presented in [Moffat and Mackenzie. Immediate-Access Indexing\nUsing Space-Efficient Extensible Arrays. ADCS 2023].\n",
                "链接": "https://arxiv.org/abs/2308.15498"
            },
            {
                "文章ID": "83654",
                "标题": "PULSAR: Pre-training with Extracted Healthcare Terms for Summarising\n  Patients' Problems and Data Augmentation with Black-box Large Language Models",
                "作者": " Hao Li,  Yuping Wu,  Viktor Schlegel,  Riza Batista-Navarro,  Thanh-Tung Nguyen,  Abhinav Ramesh Kashyap,  Xiaojun Zeng,  Daniel Beck,  Stefan Winkler,  Goran Nenadic",
                "发布日期": "2023-06-06",
                "摘要": "  Medical progress notes play a crucial role in documenting a patient's\nhospital journey, including his or her condition, treatment plan, and any\nupdates for healthcare providers. Automatic summarisation of a patient's\nproblems in the form of a problem list can aid stakeholders in understanding a\npatient's condition, reducing workload and cognitive bias. BioNLP 2023 Shared\nTask 1A focuses on generating a list of diagnoses and problems from the\nprovider's progress notes during hospitalisation. In this paper, we introduce\nour proposed approach to this task, which integrates two complementary\ncomponents. One component employs large language models (LLMs) for data\naugmentation; the other is an abstractive summarisation LLM with a novel\npre-training objective for generating the patients' problems summarised as a\nlist. Our approach was ranked second among all submissions to the shared task.\nThe performance of our model on the development and test datasets shows that\nour approach is more robust on unknown data, with an improvement of up to 3.1\npoints over the same size of the larger model.\n",
                "链接": "https://arxiv.org/abs/2306.02754"
            },
            {
                "文章ID": "23301",
                "标题": "CAISAR: A platform for Characterizing Artificial Intelligence Safety and\n  Robustness",
                "作者": "CEA LIST  Julien Girard-Satabin, CEA LIST  Michele Alberti, CEA LIST  François Bobot, CEA LIST  Zakaria Chihani, CEA LIST  Augustin Lemesle",
                "发布日期": "2022-06-22",
                "摘要": "  We present CAISAR, an open-source platform under active development for the\ncharacterization of AI systems' robustness and safety. CAISAR provides a\nunified entry point for defining verification problems by using WhyML, the\nmature and expressive language of the Why3 verification platform. Moreover,\nCAISAR orchestrates and composes state-of-the-art machine learning verification\ntools which, individually, are not able to efficiently handle all problems but,\ncollectively, can cover a growing number of properties. Our aim is to assist,\non the one hand, the V\\&V process by reducing the burden of choosing the\nmethodology tailored to a given verification problem, and on the other hand the\ntools developers by factorizing useful features-visualization, report\ngeneration, property description-in one platform. CAISAR will soon be available\nat https://git.frama-c.com/pub/caisar.\n",
                "链接": "https://arxiv.org/abs/2206.03044"
            },
            {
                "文章ID": "59538",
                "标题": "Inference of Partial Colexifications from Multilingual Wordlists",
                "作者": " Johann-Mattis List",
                "发布日期": "2023-02-03",
                "摘要": "  The past years have seen a drastic rise in studies devoted to the\ninvestigation of colexification patterns in individual languages families in\nparticular and the languages of the world in specific. Specifically\ncomputational studies have profited from the fact that colexification as a\nscientific construct is easy to operationalize, enabling scholars to infer\ncolexification patterns for large collections of cross-linguistic data. Studies\ndevoted to partial colexifications -- colexification patterns that do not\ninvolve entire words, but rather various parts of words--, however, have been\nrarely conducted so far. This is not surprising, since partial colexifications\nare less easy to deal with in computational approaches and may easily suffer\nfrom all kinds of noise resulting from false positive matches. In order to\naddress this problem, this study proposes new approaches to the handling of\npartial colexifications by (1) proposing new models with which partial\ncolexification patterns can be represented, (2) developing new efficient\nmethods and workflows which help to infer various types of partial\ncolexification patterns from multilingual wordlists, and (3) illustrating how\ninferred patterns of partial colexifications can be computationally analyzed\nand interactively visualized.\n",
                "链接": "https://arxiv.org/abs/2302.00739"
            },
            {
                "文章ID": "6577",
                "标题": "Robust and Provable Guarantees for Sparse Random Embeddings",
                "作者": " Maciej Skorski,  Alessandro Temperoni,  Martin Theobald",
                "发布日期": "2022-02-23",
                "摘要": "  In this work, we improve upon the guarantees for sparse random embeddings, as\nthey were recently provided and analyzed by Freksen at al. (NIPS'18) and\nJagadeesan (NIPS'19). Specifically, we show that (a) our bounds are explicit as\nopposed to the asymptotic guarantees provided previously, and (b) our bounds\nare guaranteed to be sharper by practically significant constants across a wide\nrange of parameters, including the dimensionality, sparsity and dispersion of\nthe data. Moreover, we empirically demonstrate that our bounds significantly\noutperform prior works on a wide range of real-world datasets, such as\ncollections of images, text documents represented as bags-of-words, and text\nsequences vectorized by neural embeddings. Behind our numerical improvements\nare techniques of broader interest, which improve upon key steps of previous\nanalyses in terms of (c) tighter estimates for certain types of quadratic\nchaos, (d) establishing extreme properties of sparse linear forms, and (e)\nimprovements on bounds for the estimation of sums of independent random\nvariables.\n",
                "链接": "https://arxiv.org/abs/2202.10815"
            },
            {
                "文章ID": "84651",
                "标题": "CUED at ProbSum 2023: Hierarchical Ensemble of Summarization Models",
                "作者": " Potsawee Manakul,  Yassir Fathullah,  Adian Liusie,  Vyas Raina,  Vatsal Raina,  Mark Gales",
                "发布日期": "2023-06-09",
                "摘要": "  In this paper, we consider the challenge of summarizing patients' medical\nprogress notes in a limited data setting. For the Problem List Summarization\n(shared task 1A) at the BioNLP Workshop 2023, we demonstrate that Clinical-T5\nfine-tuned to 765 medical clinic notes outperforms other extractive,\nabstractive and zero-shot baselines, yielding reasonable baseline systems for\nmedical note summarization. Further, we introduce Hierarchical Ensemble of\nSummarization Models (HESM), consisting of token-level ensembles of diverse\nfine-tuned Clinical-T5 models, followed by Minimum Bayes Risk (MBR) decoding.\nOur HESM approach lead to a considerable summarization performance boost, and\nwhen evaluated on held-out challenge data achieved a ROUGE-L of 32.77, which\nwas the best-performing system at the top of the shared task leaderboard.\n",
                "链接": "https://arxiv.org/abs/2306.05317"
            },
            {
                "文章ID": "91898",
                "标题": "Rob\\^oCIn Small Size League Extended Team Description Paper for RoboCup\n  2023",
                "作者": " Aline Lima de Oliveira,  Cauê Addae da Silva Gomes,  Cecília Virginia Santos da Silva,  Charles Matheus de Sousa Alves,  Danilo Andrade Martins de Souza,  Driele Pires Ferreira Araújo Xavier,  Edgleyson Pereira da Silva,  Felipe Bezerra Martins,  Lucas Henrique Cavalcanti Santos,  Lucas Dias Maciel,  Matheus Paixão Gumercindo dos Santos,  Matheus Lafayette Vasconcelos,  Matheus Vinícius Teotonio do Nascimento Andrade,  João Guilherme Oliveira Carvalho de Melo,  João Pedro Souza Pereira de Moura,  José Ronald da Silva,  José Victor Silva Cruz,  Pedro Henrique Santana de Morais,  Pedro Paulo Salman de Oliveira,  Riei Joaquim Matos Rodrigues,  Roberto Costa Fernandes,  Ryan Vinicius Santos Morais,  Tamara Mayara Ramos Teobaldo,  Washington Igor dos Santos Silva,  Edna Natividade Silva Barros",
                "发布日期": "2023-07-20",
                "摘要": "  Rob\\^oCIn has participated in RoboCup Small Size League since 2019, won its\nfirst world title in 2022 (Division B), and is currently a three-times\nLatin-American champion. This paper presents our improvements to defend the\nSmall Size League (SSL) division B title in RoboCup 2023 in Bordeaux, France.\nThis paper aims to share some of the academic research that our team developed\nover the past year. Our team has successfully published 2 articles related to\nSSL at two high-impact conferences: the 25th RoboCup International Symposium\nand the 19th IEEE Latin American Robotics Symposium (LARS 2022). Over the last\nyear, we have been continuously migrating from our past codebase to\nUnification. We will describe the new architecture implemented and some points\nof software and AI refactoring. In addition, we discuss the process of\nintegrating machined components into the mechanical system, our development for\nparticipating in the vision blackout challenge last year and what we are\npreparing for this year.\n",
                "链接": "https://arxiv.org/abs/2307.10018"
            }
        ]
    },
    {
        "question": {
            "question": "请列出近一年来工业界发表的搜广推工作落地实践的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "1",
                "标题": "Leveraging Queue Length and Attention Mechanisms for Enhanced Traffic\n  Signal Control Optimization",
                "作者": " Liang Zhang,  Shubin Xie,  Jianming Deng",
                "发布日期": "2023-09-26",
                "摘要": "  Reinforcement learning (RL) techniques for traffic signal control (TSC) have\ngained increasing popularity in recent years. However, most existing RL-based\nTSC methods tend to focus primarily on the RL model structure while neglecting\nthe significance of proper traffic state representation. Furthermore, some\nRL-based methods heavily rely on expert-designed traffic signal phase\ncompetition. In this paper, we present a novel approach to TSC that utilizes\nqueue length as an efficient state representation. We propose two new methods:\n(1) Max Queue-Length (M-QL), an optimization-based traditional method designed\nbased on the property of queue length; and (2) AttentionLight, an RL model that\nemploys the self-attention mechanism to capture the signal phase correlation\nwithout requiring human knowledge of phase relationships. Comprehensive\nexperiments on multiple real-world datasets demonstrate the effectiveness of\nour approach: (1) the M-QL method outperforms the latest RL-based methods; (2)\nAttentionLight achieves a new state-of-the-art performance; and (3) our results\nhighlight the significance of proper state representation, which is as crucial\nas neural network design in TSC methods. Our findings have important\nimplications for advancing the development of more effective and efficient TSC\nmethods. Our code is released on Github (https://github.\ncom/LiangZhang1996/AttentionLight).\n",
                "链接": "https://arxiv.org/abs/2201.00006"
            },
            {
                "文章ID": "15",
                "标题": "Representation Topology Divergence: A Method for Comparing Neural\n  Network Representations",
                "作者": " Serguei Barannikov,  Ilya Trofimov,  Nikita Balabin,  Evgeny Burnaev",
                "发布日期": "2023-05-05",
                "摘要": "  Comparison of data representations is a complex multi-aspect problem that has\nnot enjoyed a complete solution yet. We propose a method for comparing two data\nrepresentations. We introduce the Representation Topology Divergence (RTD),\nmeasuring the dissimilarity in multi-scale topology between two point clouds of\nequal size with a one-to-one correspondence between points. The data point\nclouds are allowed to lie in different ambient spaces. The RTD is one of the\nfew TDA-based practical methods applicable to real machine learning datasets.\nExperiments show that the proposed RTD agrees with the intuitive assessment of\ndata representation similarity and is sensitive to its topological structure.\nWe apply RTD to gain insights on neural networks representations in computer\nvision and NLP domains for various problems: training dynamics analysis, data\ndistribution shift, transfer learning, ensemble learning, disentanglement\nassessment.\n",
                "链接": "https://arxiv.org/abs/2201.00058"
            },
            {
                "文章ID": "23",
                "标题": "Persistent Homological State-Space Estimation of Functional Human Brain\n  Networks at Rest",
                "作者": " Moo K. Chung,  Shih-Gu Huang,  Ian C. Carroll,  Vince D. Calhoun,  H. Hill Goldsmith",
                "发布日期": "2023-12-19",
                "摘要": "  We present a new data driven topological data analysis (TDA) approach for\nestimating state spaces in dynamically changing human functional brain networks\nof human. Our approach penalizes the topological distance between networks and\nclusters dynamically changing brain networks into topologically distinct\nstates. Our method takes into account the temporal dimension of the data\nthrough the Wasserstein distance between networks. Our method is shown to\noutperform the widely used k-means clustering often used in estimating the\nstate space in brain networks. The method is applied to more accurately\ndetermine the state spaces of dynamically changing functional brain networks.\nSubsequently, we address the question of whether the overall topology of brain\nnetworks is a heritable feature using the twin study design. MATLAB code for\nthe method is available at https://github.com/laplcebeltrami/PH-STAT.\n",
                "链接": "https://arxiv.org/abs/2201.00087"
            },
            {
                "文章ID": "38",
                "标题": "Matrix Decomposition and Applications",
                "作者": " Jun Lu",
                "发布日期": "2023-12-29",
                "摘要": "  In 1954, Alston S. Householder published Principles of Numerical Analysis,\none of the first modern treatments on matrix decomposition that favored a\n(block) LU decomposition-the factorization of a matrix into the product of\nlower and upper triangular matrices. And now, matrix decomposition has become a\ncore technology in machine learning, largely due to the development of the back\npropagation algorithm in fitting a neural network. The sole aim of this survey\nis to give a self-contained introduction to concepts and mathematical tools in\nnumerical linear algebra and matrix analysis in order to seamlessly introduce\nmatrix decomposition techniques and their applications in subsequent sections.\nHowever, we clearly realize our inability to cover all the useful and\ninteresting results concerning matrix decomposition and given the paucity of\nscope to present this discussion, e.g., the separated analysis of the Euclidean\nspace, Hermitian space, Hilbert space, and things in the complex domain. We\nrefer the reader to literature in the field of linear algebra for a more\ndetailed introduction to the related fields.\n",
                "链接": "https://arxiv.org/abs/2201.00145"
            },
            {
                "文章ID": "73",
                "标题": "Fair Data Representation for Machine Learning at the Pareto Frontier",
                "作者": " Shizhou Xu,  Thomas Strohmer",
                "发布日期": "2023-11-27",
                "摘要": "  As machine learning powered decision-making becomes increasingly important in\nour daily lives, it is imperative to strive for fairness in the underlying data\nprocessing. We propose a pre-processing algorithm for fair data representation\nvia which supervised learning results in estimations of the Pareto frontier\nbetween prediction error and statistical disparity. Particularly, the present\nwork applies the optimal affine transport to approach the post-processing\nWasserstein-2 barycenter characterization of the optimal fair $L^2$-objective\nsupervised learning via a pre-processing data deformation. Furthermore, we show\nthat the Wasserstein-2 geodesics from the conditional (on sensitive\ninformation) distributions of the learning outcome to their barycenter\ncharacterizes the Pareto frontier between $L^2$-loss and the average pairwise\nWasserstein-2 distance among sensitive groups on the learning outcome.\nNumerical simulations underscore the advantages: (1) the pre-processing step is\ncompositive with arbitrary conditional expectation estimation supervised\nlearning methods and unseen data; (2) the fair representation protects the\nsensitive information by limiting the inference capability of the remaining\ndata with respect to the sensitive data; (3) the optimal affine maps are\ncomputationally efficient even for high-dimensional data.\n",
                "链接": "https://arxiv.org/abs/2201.00292"
            },
            {
                "文章ID": "79",
                "标题": "Recurrent Feature Propagation and Edge Skip-Connections for Automatic\n  Abdominal Organ Segmentation",
                "作者": " Zefan Yang,  Di Lin,  Dong Ni,  Yi Wang",
                "发布日期": "2023-05-22",
                "摘要": "  Automatic segmentation of abdominal organs in computed tomography (CT) images\ncan support radiation therapy and image-guided surgery workflows. Developing of\nsuch automatic solutions remains challenging mainly owing to complex organ\ninteractions and blurry boundaries in CT images. To address these issues, we\nfocus on effective spatial context modeling and explicit edge segmentation\npriors. Accordingly, we propose a 3D network with four main components trained\nend-to-end including shared encoder, edge detector, decoder with edge\nskip-connections (ESCs) and recurrent feature propagation head (RFP-Head). To\ncapture wide-range spatial dependencies, the RFP-Head propagates and harvests\nlocal features through directed acyclic graphs (DAGs) formulated with recurrent\nconnections in an efficient slice-wise manner, with regard to spatial\narrangement of image units. To leverage edge information, the edge detector\nlearns edge prior knowledge specifically tuned for semantic segmentation by\nexploiting intermediate features from the encoder with the edge supervision.\nThe ESCs then aggregate the edge knowledge with multi-level decoder features to\nlearn a hierarchy of discriminative features explicitly modeling\ncomplementarity between organs' interiors and edges for segmentation. We\nconduct extensive experiments on two challenging abdominal CT datasets with\neight annotated organs. Experimental results show that the proposed network\noutperforms several state-of-the-art models, especially for the segmentation of\nsmall and complicated structures (gallbladder, esophagus, stomach, pancreas and\nduodenum). The code will be publicly available.\n",
                "链接": "https://arxiv.org/abs/2201.00317"
            },
            {
                "文章ID": "87",
                "标题": "The Interpretability of LSTM Models for Predicting Oil Company Stocks:\n  Impact of Correlated Features",
                "作者": " Javad T. Firouzjaee,  Pouriya Khaliliyan",
                "发布日期": "2023-12-21",
                "摘要": "  Oil companies are among the largest companies in the world whose economic\nindicators in the global stock market have a great impact on the world\neconomy\\cite{ec00} and market due to their relation to gold\\cite{ec01}, crude\noil\\cite{ec02}, and the dollar\\cite{ec03}. This study investigates the impact\nof correlated features on the interpretability of Long Short-Term\nMemory(LSTM)\\cite{ec04} models for predicting oil company stocks. To achieve\nthis, we designed a Standard Long Short-Term Memory (LSTM) network and trained\nit using various correlated datasets. Our approach aims to improve the accuracy\nof stock price prediction by considering the multiple factors affecting the\nmarket, such as crude oil prices, gold prices, and the US dollar. The results\ndemonstrate that adding a feature correlated with oil stocks does not improve\nthe interpretability of LSTM models. These findings suggest that while LSTM\nmodels may be effective in predicting stock prices, their interpretability may\nbe limited. Caution should be exercised when relying solely on LSTM models for\nstock price prediction as their lack of interpretability may make it difficult\nto fully understand the underlying factors driving stock price movements. We\nhave employed complexity analysis to support our argument, considering that\nfinancial markets encompass a form of physical complex system\\cite{ec05}. One\nof the fundamental challenges faced in utilizing LSTM models for financial\nmarkets lies in interpreting the unexpected feedback dynamics within them.\n",
                "链接": "https://arxiv.org/abs/2201.00350"
            },
            {
                "文章ID": "97",
                "标题": "On the effectiveness of Randomized Signatures as Reservoir for Learning\n  Rough Dynamics",
                "作者": " Enea Monzio Compagnoni,  Anna Scampicchio,  Luca Biggio,  Antonio Orvieto,  Thomas Hofmann,  Josef Teichmann",
                "发布日期": "2023-04-27",
                "摘要": "  Many finance, physics, and engineering phenomena are modeled by\ncontinuous-time dynamical systems driven by highly irregular (stochastic)\ninputs. A powerful tool to perform time series analysis in this context is\nrooted in rough path theory and leverages the so-called Signature Transform.\nThis algorithm enjoys strong theoretical guarantees but is hard to scale to\nhigh-dimensional data. In this paper, we study a recently derived random\nprojection variant called Randomized Signature, obtained using the\nJohnson-Lindenstrauss Lemma. We provide an in-depth experimental evaluation of\nthe effectiveness of the Randomized Signature approach, in an attempt to\nshowcase the advantages of this reservoir to the community. Specifically, we\nfind that this method is preferable to the truncated Signature approach and\nalternative deep learning techniques in terms of model complexity, training\ntime, accuracy, robustness, and data hungriness.\n",
                "链接": "https://arxiv.org/abs/2201.00384"
            },
            {
                "文章ID": "166",
                "标题": "Compression-Resistant Backdoor Attack against Deep Neural Networks",
                "作者": " Mingfu Xue,  Xin Wang,  Shichang Sun,  Yushu Zhang,  Jian Wang,  Weiqiang Liu",
                "发布日期": "2023-05-26",
                "摘要": "  In recent years, many backdoor attacks based on training data poisoning have\nbeen proposed. However, in practice, those backdoor attacks are vulnerable to\nimage compressions. When backdoor instances are compressed, the feature of\nspecific backdoor trigger will be destroyed, which could result in the backdoor\nattack performance deteriorating. In this paper, we propose a\ncompression-resistant backdoor attack based on feature consistency training. To\nthe best of our knowledge, this is the first backdoor attack that is robust to\nimage compressions. First, both backdoor images and their compressed versions\nare input into the deep neural network (DNN) for training. Then, the feature of\neach image is extracted by internal layers of the DNN. Next, the feature\ndifference between backdoor images and their compressed versions are minimized.\nAs a result, the DNN treats the feature of compressed images as the feature of\nbackdoor images in feature space. After training, the backdoor attack against\nDNN is robust to image compression. Furthermore, we consider three different\nimage compressions (i.e., JPEG, JPEG2000, WEBP) in feature consistency\ntraining, so that the backdoor attack is robust to multiple image compression\nalgorithms. Experimental results demonstrate the effectiveness and robustness\nof the proposed backdoor attack. When the backdoor instances are compressed,\nthe attack success rate of common backdoor attack is lower than 10%, while the\nattack success rate of our compression-resistant backdoor is greater than 97%.\nThe compression-resistant attack is still robust even when the backdoor images\nare compressed with low compression quality. In addition, extensive experiments\nhave demonstrated that, our compression-resistant backdoor attack has the\ngeneralization ability to resist image compression which is not used in the\ntraining process.\n",
                "链接": "https://arxiv.org/abs/2201.00672"
            },
            {
                "文章ID": "199",
                "标题": "Implicit Autoencoder for Point-Cloud Self-Supervised Representation\n  Learning",
                "作者": " Siming Yan,  Zhenpei Yang,  Haoxiang Li,  Chen Song,  Li Guan,  Hao Kang,  Gang Hua,  Qixing Huang",
                "发布日期": "2023-08-29",
                "摘要": "  This paper advocates the use of implicit surface representation in\nautoencoder-based self-supervised 3D representation learning. The most popular\nand accessible 3D representation, i.e., point clouds, involves discrete samples\nof the underlying continuous 3D surface. This discretization process introduces\nsampling variations on the 3D shape, making it challenging to develop\ntransferable knowledge of the true 3D geometry. In the standard autoencoding\nparadigm, the encoder is compelled to encode not only the 3D geometry but also\ninformation on the specific discrete sampling of the 3D shape into the latent\ncode. This is because the point cloud reconstructed by the decoder is\nconsidered unacceptable unless there is a perfect mapping between the original\nand the reconstructed point clouds. This paper introduces the Implicit\nAutoEncoder (IAE), a simple yet effective method that addresses the sampling\nvariation issue by replacing the commonly-used point-cloud decoder with an\nimplicit decoder. The implicit decoder reconstructs a continuous representation\nof the 3D shape, independent of the imperfections in the discrete samples.\nExtensive experiments demonstrate that the proposed IAE achieves\nstate-of-the-art performance across various self-supervised learning\nbenchmarks.\n",
                "链接": "https://arxiv.org/abs/2201.00785"
            }
        ]
    },
    {
        "question": {
            "question": "推荐与AutoGPT相似的10篇文献",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "请搜索近一年发表的有关多模态大模型与产业相结合、与具体应用场景相结合的论文",
            "type": "2"
        },
        "results": [
            {
                "文章ID": "76105",
                "标题": "Image to Multi-Modal Retrieval for Industrial Scenarios",
                "作者": " Zida Cheng,  Chen Ju,  Xu Chen,  Zhonghua Zhai,  Shuai Xiao,  Xiaoyi Zeng,  Weilin Huang",
                "发布日期": "2023-12-01",
                "摘要": "  We formally define a novel valuable information retrieval task:\nimage-to-multi-modal-retrieval (IMMR), where the query is an image and the doc\nis an entity with both image and textual description. IMMR task is valuable in\nvarious industrial application. We analyze three key challenges for IMMR: 1)\nskewed data and noisy label in metric learning, 2) multi-modality fusion, 3)\neffective and efficient training in large-scale industrial scenario. To tackle\nthe above challenges, we propose a novel framework for IMMR task. Our framework\nconsists of three components: 1) a novel data governance scheme coupled with a\nlarge-scale classification-based learning paradigm. 2) model architecture\nspecially designed for multimodal learning, where the proposed concept-aware\nmodality fusion module adaptively fuse image and text modality. 3. a hybrid\nparallel training approach for tackling large-scale training in industrial\nscenario. The proposed framework achieves SOTA performance on public datasets\nand has been deployed in a real-world industrial search system, leading to\nsignificant improvements in click-through rate and deal number. Code and data\nwill be made publicly available.\n",
                "链接": "https://arxiv.org/abs/2305.03972"
            },
            {
                "文章ID": "97795",
                "标题": "Federated Learning in Big Model Era: Domain-Specific Multimodal Large\n  Models",
                "作者": " Zengxiang Li,  Zhaoxiang Hou,  Hui Liu,  Ying Wang,  Tongzhi Li,  Longfei Xie,  Chao Shi,  Chengyi Yang,  Weishan Zhang,  Zelei Liu,  Liang Xu",
                "发布日期": "2023-08-25",
                "摘要": "  Multimodal data, which can comprehensively perceive and recognize the\nphysical world, has become an essential path towards general artificial\nintelligence. However, multimodal large models trained on public datasets often\nunderperform in specific industrial domains. This paper proposes a multimodal\nfederated learning framework that enables multiple enterprises to utilize\nprivate domain data to collaboratively train large models for vertical domains,\nachieving intelligent services across scenarios. The authors discuss in-depth\nthe strategic transformation of federated learning in terms of intelligence\nfoundation and objectives in the era of big model, as well as the new\nchallenges faced in heterogeneous data, model aggregation, performance and cost\ntrade-off, data privacy, and incentive mechanism. The paper elaborates a case\nstudy of leading enterprises contributing multimodal data and expert knowledge\nto city safety operation management , including distributed deployment and\nefficient coordination of the federated learning platform, technical\ninnovations on data quality improvement based on large model capabilities and\nefficient joint fine-tuning approaches. Preliminary experiments show that\nenterprises can enhance and accumulate intelligent capabilities through\nmultimodal model federated learning, thereby jointly creating an smart city\nmodel that provides high-quality intelligent services covering energy\ninfrastructure safety, residential community security, and urban operation\nmanagement. The established federated learning cooperation ecosystem is\nexpected to further aggregate industry, academia, and research resources,\nrealize large models in multiple vertical domains, and promote the large-scale\nindustrial application of artificial intelligence and cutting-edge research on\nmultimodal federated learning.\n",
                "链接": "https://arxiv.org/abs/2308.11217"
            },
            {
                "文章ID": "109442",
                "标题": "Leveraging Large Language Model for Automatic Evolving of Industrial\n  Data-Centric R&D Cycle",
                "作者": " Xu Yang,  Xiao Yang,  Weiqing Liu,  Jinhui Li,  Peng Yu,  Zeqi Ye,  Jiang Bian",
                "发布日期": "2023-10-18",
                "摘要": "  In the wake of relentless digital transformation, data-driven solutions are\nemerging as powerful tools to address multifarious industrial tasks such as\nforecasting, anomaly detection, planning, and even complex decision-making.\nAlthough data-centric R&D has been pivotal in harnessing these solutions, it\noften comes with significant costs in terms of human, computational, and time\nresources. This paper delves into the potential of large language models (LLMs)\nto expedite the evolution cycle of data-centric R&D. Assessing the foundational\nelements of data-centric R&D, including heterogeneous task-related data,\nmulti-facet domain knowledge, and diverse computing-functional tools, we\nexplore how well LLMs can understand domain-specific requirements, generate\nprofessional ideas, utilize domain-specific tools to conduct experiments,\ninterpret results, and incorporate knowledge from past endeavors to tackle new\nchallenges. We take quantitative investment research as a typical example of\nindustrial data-centric R&D scenario and verified our proposed framework upon\nour full-stack open-sourced quantitative research platform Qlib and obtained\npromising results which shed light on our vision of automatic evolving of\nindustrial data-centric R&D cycle.\n",
                "链接": "https://arxiv.org/abs/2310.11249"
            },
            {
                "文章ID": "80153",
                "标题": "Mixture-of-Experts Meets Instruction Tuning:A Winning Combination for\n  Large Language Models",
                "作者": " Sheng Shen,  Le Hou,  Yanqi Zhou,  Nan Du,  Shayne Longpre,  Jason Wei,  Hyung Won Chung,  Barret Zoph,  William Fedus,  Xinyun Chen,  Tu Vu,  Yuexin Wu,  Wuyang Chen,  Albert Webson,  Yunxuan Li,  Vincent Zhao,  Hongkun Yu,  Kurt Keutzer,  Trevor Darrell,  Denny Zhou",
                "发布日期": "2023-07-06",
                "摘要": "  Sparse Mixture-of-Experts (MoE) is a neural architecture design that can be\nutilized to add learnable parameters to Large Language Models (LLMs) without\nincreasing inference cost. Instruction tuning is a technique for training LLMs\nto follow instructions. We advocate combining these two approaches, as we find\nthat MoE models benefit more from instruction tuning than dense models. In\nparticular, we conduct empirical studies across three experimental setups: (i)\nDirect finetuning on individual downstream tasks devoid of instruction tuning;\n(ii) Instructiontuning followed by in-context few-shot or zero-shot\ngeneralization on downstream tasks; and (iii) Instruction tuning supplemented\nby further finetuning on individual downstream tasks. In the first scenario,\nMoE models overall underperform dense models of identical computational\ncapacity. This narrative, however, dramatically changes with the introduction\nof instruction tuning (second and third scenario), used independently or in\nconjunction with task-specific finetuning. Our most powerful model,\nFLAN-MOE-32B, surpasses the performance of FLAN-PALM-62B on four benchmark\ntasks, while using only a third of the FLOPs. The advancements embodied\nbyFLAN-MOE inspire a reevaluation of the design principles of large-scale,\nhigh-performance language models in the framework of task-agnostic learning.\n",
                "链接": "https://arxiv.org/abs/2305.14705"
            },
            {
                "文章ID": "78689",
                "标题": "Empower Large Language Model to Perform Better on Industrial\n  Domain-Specific Question Answering",
                "作者": " Fangkai Yang,  Pu Zhao,  Zezhong Wang,  Lu Wang,  Jue Zhang,  Mohit Garg,  Qingwei Lin,  Saravan Rajmohan,  Dongmei Zhang",
                "发布日期": "2023-10-17",
                "摘要": "  Large Language Model (LLM) has gained popularity and achieved remarkable\nresults in open-domain tasks, but its performance in real industrial\ndomain-specific scenarios is average due to its lack of specific domain\nknowledge. This issue has attracted widespread attention, but there are few\nrelevant benchmarks available. In this paper, we provide a benchmark Question\nAnswering (QA) dataset named MSQA, centered around Microsoft products and IT\ntechnical problems encountered by customers. This dataset contains industry\ncloud-specific QA knowledge, an area not extensively covered in general LLMs,\nmaking it well-suited for evaluating methods aiming to enhance LLMs'\ndomain-specific capabilities. In addition, we propose a new model interaction\nparadigm that can empower LLM to achieve better performance on domain-specific\ntasks where it is not proficient. Extensive experiments demonstrate that the\napproach following our method outperforms the commonly used LLM with retrieval\nmethods. We make our source code and sample data available at:\nhttps://aka.ms/Microsoft_QA.\n",
                "链接": "https://arxiv.org/abs/2305.11541"
            },
            {
                "文章ID": "81013",
                "标题": "LANISTR: Multimodal Learning from Structured and Unstructured Data",
                "作者": " Sayna Ebrahimi,  Sercan O. Arik,  Yihe Dong,  Tomas Pfister",
                "发布日期": "2023-08-25",
                "摘要": "  Multimodal large-scale pretraining has shown impressive performance for\nunstructured data including language, image, audio, and video. However, a\nprevalent real-world scenario involves the combination of structured data types\n(tabular, time-series) with unstructured data which has so far been\nunderstudied. To bridge this gap, we propose LANISTR, an attention-based\nframework to learn from LANguage, Image, and STRuctured data. The core of\nLANISTR's methodology is rooted in \\textit{masking-based} training applied\nacross both unimodal and multimodal levels. In particular, we introduce a new\nsimilarity-based multimodal masking loss that enables it to learn cross-modal\nrelations from large-scale multimodal data with missing modalities. On two\nreal-world datastes, MIMIC-IV (healthcare) and Amazon Product Review (retail),\nLANISTR demonstrates remarkable absolute improvements of 6.6\\% (AUROC) and up\nto 14\\% (accuracy) when fine-tuned on 0.1\\% and 0.01\\% of labeled data,\nrespectively, compared to the state-of-the-art alternatives. Notably, these\nimprovements are observed even in the presence of considerable missingness\nratios of 35.7\\% and 99.8\\%, in the respective datasets.\n",
                "链接": "https://arxiv.org/abs/2305.16556"
            },
            {
                "文章ID": "112345",
                "标题": "Myriad: Large Multimodal Model by Applying Vision Experts for Industrial\n  Anomaly Detection",
                "作者": " Yuanze Li,  Haolin Wang,  Shihao Yuan,  Ming Liu,  Debin Zhao,  Yiwen Guo,  Chen Xu,  Guangming Shi,  Wangmeng Zuo",
                "发布日期": "2023-11-02",
                "摘要": "  Existing industrial anomaly detection (IAD) methods predict anomaly scores\nfor both anomaly detection and localization. However, they struggle to perform\na multi-turn dialog and detailed descriptions for anomaly regions, e.g., color,\nshape, and categories of industrial anomalies. Recently, large multimodal\n(i.e., vision and language) models (LMMs) have shown eminent perception\nabilities on multiple vision tasks such as image captioning, visual\nunderstanding, visual reasoning, etc., making it a competitive potential choice\nfor more comprehensible anomaly detection. However, the knowledge about anomaly\ndetection is absent in existing general LMMs, while training a specific LMM for\nanomaly detection requires a tremendous amount of annotated data and massive\ncomputation resources. In this paper, we propose a novel large multi-modal\nmodel by applying vision experts for industrial anomaly detection (dubbed\nMyriad), which leads to definite anomaly detection and high-quality anomaly\ndescription. Specifically, we adopt MiniGPT-4 as the base LMM and design an\nExpert Perception module to embed the prior knowledge from vision experts as\ntokens which are intelligible to Large Language Models (LLMs). To compensate\nfor the errors and confusions of vision experts, we introduce a domain adapter\nto bridge the visual representation gaps between generic and industrial images.\nFurthermore, we propose a Vision Expert Instructor, which enables the Q-Former\nto generate IAD domain vision-language tokens according to vision expert prior.\nExtensive experiments on MVTec-AD and VisA benchmarks demonstrate that our\nproposed method not only performs favorably against state-of-the-art methods\nunder the 1-class and few-shot settings, but also provide definite anomaly\nprediction along with detailed descriptions in IAD domain.\n",
                "链接": "https://arxiv.org/abs/2310.19070"
            },
            {
                "文章ID": "87449",
                "标题": "OptMSM: Optimizing Multi-Scenario Modeling for Click-Through Rate\n  Prediction",
                "作者": " Xing Tang,  Yang Qiao,  Yuwen Fu,  Fuyuan Lyu,  Dugang Liu,  Xiuqiang He",
                "发布日期": "2023-06-26",
                "摘要": "  A large-scale industrial recommendation platform typically consists of\nmultiple associated scenarios, requiring a unified click-through rate (CTR)\nprediction model to serve them simultaneously. Existing approaches for\nmulti-scenario CTR prediction generally consist of two main modules: i) a\nscenario-aware learning module that learns a set of multi-functional\nrepresentations with scenario-shared and scenario-specific information from\ninput features, and ii) a scenario-specific prediction module that serves each\nscenario based on these representations. However, most of these approaches\nprimarily focus on improving the former module and neglect the latter module.\nThis can result in challenges such as increased model parameter size, training\ndifficulty, and performance bottlenecks for each scenario. To address these\nissues, we propose a novel framework called OptMSM (\\textbf{Opt}imizing\n\\textbf{M}ulti-\\textbf{S}cenario \\textbf{M}odeling). First, we introduce a\nsimplified yet effective scenario-enhanced learning module to alleviate the\naforementioned challenges. Specifically, we partition the input features into\nscenario-specific and scenario-shared features, which are mapped to specific\ninformation embedding encodings and a set of shared information embeddings,\nrespectively. By imposing an orthogonality constraint on the shared information\nembeddings to facilitate the disentanglement of shared information\ncorresponding to each scenario, we combine them with the specific information\nembeddings to obtain multi-functional representations. Second, we introduce a\nscenario-specific hypernetwork in the scenario-specific prediction module to\ncapture interactions within each scenario more effectively, thereby alleviating\nthe performance bottlenecks. Finally, we conduct extensive offline experiments\nand an online A/B test to demonstrate the effectiveness of OptMSM.\n",
                "链接": "https://arxiv.org/abs/2306.13382"
            },
            {
                "文章ID": "87099",
                "标题": "Exploiting Multimodal Synthetic Data for Egocentric Human-Object\n  Interaction Detection in an Industrial Scenario",
                "作者": " Rosario Leonardi,  Francesco Ragusa,  Antonino Furnari,  Giovanni Maria Farinella",
                "发布日期": "2023-06-22",
                "摘要": "  In this paper, we tackle the problem of Egocentric Human-Object Interaction\n(EHOI) detection in an industrial setting. To overcome the lack of public\ndatasets in this context, we propose a pipeline and a tool for generating\nsynthetic images of EHOIs paired with several annotations and data signals\n(e.g., depth maps or instance segmentation masks). Using the proposed pipeline,\nwe present EgoISM-HOI a new multimodal dataset composed of synthetic EHOI\nimages in an industrial environment with rich annotations of hands and objects.\nTo demonstrate the utility and effectiveness of synthetic EHOI data produced by\nthe proposed tool, we designed a new method that predicts and combines\ndifferent multimodal signals to detect EHOIs in RGB images. Our study shows\nthat exploiting synthetic data to pre-train the proposed method significantly\nimproves performance when tested on real-world data. Moreover, the proposed\napproach outperforms state-of-the-art class-agnostic methods. To support\nresearch in this field, we publicly release the datasets, source code, and\npre-trained models at https://iplab.dmi.unict.it/egoism-hoi.\n",
                "链接": "https://arxiv.org/abs/2306.12152"
            },
            {
                "文章ID": "116538",
                "标题": "Modality-invariant and Specific Prompting for Multimodal Human\n  Perception Understanding",
                "作者": " Hao Sun,  Ziwei Niu,  Xinyao Yu,  Jiaqing Liu,  Yen-Wei Chen,  Lanfen Lin",
                "发布日期": "2023-11-21",
                "摘要": "  Understanding human perceptions presents a formidable multimodal challenge\nfor computers, encompassing aspects such as sentiment tendencies and sense of\nhumor. While various methods have recently been introduced to extract\nmodality-invariant and specific information from diverse modalities, with the\ngoal of enhancing the efficacy of multimodal learning, few works emphasize this\naspect in large language models. In this paper, we introduce a novel multimodal\nprompt strategy tailored for tuning large language models. Our method assesses\nthe correlation among different modalities and isolates the modality-invariant\nand specific components, which are then utilized for prompt tuning. This\napproach enables large language models to efficiently and effectively\nassimilate information from various modalities. Furthermore, our strategy is\ndesigned with scalability in mind, allowing the integration of features from\nany modality into pretrained large language models. Experimental results on\npublic datasets demonstrate that our proposed method significantly improves\nperformance compared to previous methods.\n",
                "链接": "https://arxiv.org/abs/2311.10791"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究，特别关注使用自动标注和迁移学习方法的论文，时间跨度覆盖2019年至今。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "110503",
                "标题": "A comprehensive survey on deep active learning and its applications in\n  medical image analysis",
                "作者": " Haoran Wang,  Qiuye Jin,  Shiman Li,  Siyu Liu,  Manning Wang,  Zhijian Song",
                "发布日期": "2023-10-25",
                "摘要": "  Deep learning has achieved widespread success in medical image analysis,\nleading to an increasing demand for large-scale expert-annotated medical image\ndatasets. Yet, the high cost of annotating medical images severely hampers the\ndevelopment of deep learning in this field. To reduce annotation costs, active\nlearning aims to select the most informative samples for annotation and train\nhigh-performance models with as few labeled samples as possible. In this\nsurvey, we review the core methods of active learning, including the evaluation\nof informativeness and sampling strategy. For the first time, we provide a\ndetailed summary of the integration of active learning with other\nlabel-efficient techniques, such as semi-supervised, self-supervised learning,\nand so on. Additionally, we also highlight active learning works that are\nspecifically tailored to medical image analysis. In the end, we offer our\nperspectives on the future trends and challenges of active learning and its\napplications in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2310.14230"
            },
            {
                "文章ID": "68134",
                "标题": "Label-Efficient Deep Learning in Medical Image Analysis: Challenges and\n  Future Directions",
                "作者": " Cheng Jin,  Zhengrui Guo,  Yi Lin,  Luyang Luo,  Hao Chen",
                "发布日期": "2023-12-21",
                "摘要": "  Deep learning has seen rapid growth in recent years and achieved\nstate-of-the-art performance in a wide range of applications. However, training\nmodels typically requires expensive and time-consuming collection of large\nquantities of labeled data. This is particularly true within the scope of\nmedical imaging analysis (MIA), where data are limited and labels are expensive\nto be acquired. Thus, label-efficient deep learning methods are developed to\nmake comprehensive use of the labeled data as well as the abundance of\nunlabeled and weak-labeled data. In this survey, we extensively investigated\nover 300 recent papers to provide a comprehensive overview of recent progress\non label-efficient learning strategies in MIA. We first present the background\nof label-efficient learning and categorize the approaches into different\nschemes. Next, we examine the current state-of-the-art methods in detail\nthrough each scheme. Specifically, we provide an in-depth investigation,\ncovering not only canonical semi-supervised, self-supervised, and\nmulti-instance learning schemes, but also recently emerged active and\nannotation-efficient learning strategies. Moreover, as a comprehensive\ncontribution to the field, this survey not only elucidates the commonalities\nand unique features of the surveyed methods but also presents a detailed\nanalysis of the current challenges in the field and suggests potential avenues\nfor future research.\n",
                "链接": "https://arxiv.org/abs/2303.12484"
            },
            {
                "文章ID": "90511",
                "标题": "$\\mathrm{SAM^{Med}}$: A medical image annotation framework based on\n  large vision model",
                "作者": " Chenglong Wang,  Dexuan Li,  Sucheng Wang,  Chengxiu Zhang,  Yida Wang,  Yun Liu,  Guang Yang",
                "发布日期": "2023-09-20",
                "摘要": "  Recently, large vision model, Segment Anything Model (SAM), has\nrevolutionized the computer vision field, especially for image segmentation.\nSAM presented a new promptable segmentation paradigm that exhibit its\nremarkable zero-shot generalization ability. An extensive researches have\nexplore the potential and limits of SAM in various downstream tasks. In this\nstudy, we presents $\\mathrm{SAM^{Med}}$, an enhanced framework for medical\nimage annotation that leverages the capabilities of SAM. $\\mathrm{SAM^{Med}}$\nframework consisted of two submodules, namely $\\mathrm{SAM^{assist}}$ and\n$\\mathrm{SAM^{auto}}$. The $\\mathrm{SAM^{assist}}$ demonstrates the\ngeneralization ability of SAM to the downstream medical segmentation task using\nthe prompt-learning approach. Results show a significant improvement in\nsegmentation accuracy with only approximately 5 input points. The\n$\\mathrm{SAM^{auto}}$ model aims to accelerate the annotation process by\nautomatically generating input prompts. The proposed SAP-Net model achieves\nsuperior segmentation performance with only five annotated slices, achieving an\naverage Dice coefficient of 0.80 and 0.82 for kidney and liver segmentation,\nrespectively. Overall, $\\mathrm{SAM^{Med}}$ demonstrates promising results in\nmedical image annotation. These findings highlight the potential of leveraging\nlarge-scale vision models in medical image annotation tasks.\n",
                "链接": "https://arxiv.org/abs/2307.05617"
            },
            {
                "文章ID": "93650",
                "标题": "Cross-dimensional transfer learning in medical image segmentation with\n  deep learning",
                "作者": " Hicham Messaoudi,  Ahror Belaid,  Douraied Ben Salem,  Pierre-Henri Conze",
                "发布日期": "2023-08-01",
                "摘要": "  Over the last decade, convolutional neural networks have emerged and advanced\nthe state-of-the-art in various image analysis and computer vision\napplications. The performance of 2D image classification networks is constantly\nimproving and being trained on databases made of millions of natural images.\nHowever, progress in medical image analysis has been hindered by limited\nannotated data and acquisition constraints. These limitations are even more\npronounced given the volumetry of medical imaging data. In this paper, we\nintroduce an efficient way to transfer the efficiency of a 2D classification\nnetwork trained on natural images to 2D, 3D uni- and multi-modal medical image\nsegmentation applications. In this direction, we designed novel architectures\nbased on two key principles: weight transfer by embedding a 2D pre-trained\nencoder into a higher dimensional U-Net, and dimensional transfer by expanding\na 2D segmentation network into a higher dimension one. The proposed networks\nwere tested on benchmarks comprising different modalities: MR, CT, and\nultrasound images. Our 2D network ranked first on the CAMUS challenge dedicated\nto echo-cardiographic data segmentation and surpassed the state-of-the-art.\nRegarding 2D/3D MR and CT abdominal images from the CHAOS challenge, our\napproach largely outperformed the other 2D-based methods described in the\nchallenge paper on Dice, RAVD, ASSD, and MSSD scores and ranked third on the\nonline evaluation platform. Our 3D network applied to the BraTS 2022\ncompetition also achieved promising results, reaching an average Dice score of\n91.69% (91.22%) for the whole tumor, 83.23% (84.77%) for the tumor core, and\n81.75% (83.88%) for enhanced tumor using the approach based on weight\n(dimensional) transfer. Experimental and qualitative results illustrate the\neffectiveness of our methods for multi-dimensional medical image segmentation.\n",
                "链接": "https://arxiv.org/abs/2307.15872"
            },
            {
                "文章ID": "69437",
                "标题": "Medical Image Analysis using Deep Relational Learning",
                "作者": " Zhihua Liu",
                "发布日期": "2023-03-29",
                "摘要": "  In the past ten years, with the help of deep learning, especially the rapid\ndevelopment of deep neural networks, medical image analysis has made remarkable\nprogress. However, how to effectively use the relational information between\nvarious tissues or organs in medical images is still a very challenging\nproblem, and it has not been fully studied. In this thesis, we propose two\nnovel solutions to this problem based on deep relational learning. First, we\npropose a context-aware fully convolutional network that effectively models\nimplicit relation information between features to perform medical image\nsegmentation. The network achieves the state-of-the-art segmentation results on\nthe Multi Modal Brain Tumor Segmentation 2017 (BraTS2017) and Multi Modal Brain\nTumor Segmentation 2018 (BraTS2018) data sets. Subsequently, we propose a new\nhierarchical homography estimation network to achieve accurate medical image\nmosaicing by learning the explicit spatial relationship between adjacent\nframes. We use the UCL Fetoscopy Placenta dataset to conduct experiments and\nour hierarchical homography estimation network outperforms the other\nstate-of-the-art mosaicing methods while generating robust and meaningful\nmosaicing result on unseen frames.\n",
                "链接": "https://arxiv.org/abs/2303.16099"
            },
            {
                "文章ID": "34051",
                "标题": "PyMIC: A deep learning toolkit for annotation-efficient medical image\n  segmentation",
                "作者": " Guotai Wang,  Xiangde Luo,  Ran Gu,  Shuojue Yang,  Yijie Qu,  Shuwei Zhai,  Qianfei Zhao,  Kang Li,  Shaoting Zhang",
                "发布日期": "2023-02-14",
                "摘要": "  Background and Objective: Open-source deep learning toolkits are one of the\ndriving forces for developing medical image segmentation models. Existing\ntoolkits mainly focus on fully supervised segmentation and require full and\naccurate pixel-level annotations that are time-consuming and difficult to\nacquire for segmentation tasks, which makes learning from imperfect labels\nhighly desired for reducing the annotation cost. We aim to develop a new deep\nlearning toolkit to support annotation-efficient learning for medical image\nsegmentation.\n  Methods: Our proposed toolkit named PyMIC is a modular deep learning library\nfor medical image segmentation tasks. In addition to basic components that\nsupport development of high-performance models for fully supervised\nsegmentation, it contains several advanced components tailored for learning\nfrom imperfect annotations, such as loading annotated and unannounced images,\nloss functions for unannotated, partially or inaccurately annotated images, and\ntraining procedures for co-learning between multiple networks, etc. PyMIC\nsupports development of semi-supervised, weakly supervised and noise-robust\nlearning methods for medical image segmentation.\n  Results: We present several illustrative medical image segmentation tasks\nbased on PyMIC: (1) Achieving competitive performance on fully supervised\nlearning; (2) Semi-supervised cardiac structure segmentation with only 10%\ntraining images annotated; (3) Weakly supervised segmentation using scribble\nannotations; and (4) Learning from noisy labels for chest radiograph\nsegmentation.\n  Conclusions: The PyMIC toolkit is easy to use and facilitates efficient\ndevelopment of medical image segmentation models with imperfect annotations. It\nis modular and flexible, which enables researchers to develop high-performance\nmodels with low annotation cost. The source code is available at:\nhttps://github.com/HiLab-git/PyMIC.\n",
                "链接": "https://arxiv.org/abs/2208.09350"
            },
            {
                "文章ID": "16060",
                "标题": "DiRA: Discriminative, Restorative, and Adversarial Learning for\n  Self-supervised Medical Image Analysis",
                "作者": " Fatemeh Haghighi,  Mohammad Reza Hosseinzadeh Taher,  Michael B. Gotway,  Jianming Liang",
                "发布日期": "2022-04-25",
                "摘要": "  Discriminative learning, restorative learning, and adversarial learning have\nproven beneficial for self-supervised learning schemes in computer vision and\nmedical imaging. Existing efforts, however, omit their synergistic effects on\neach other in a ternary setup, which, we envision, can significantly benefit\ndeep semantic representation learning. To realize this vision, we have\ndeveloped DiRA, the first framework that unites discriminative, restorative,\nand adversarial learning in a unified manner to collaboratively glean\ncomplementary visual information from unlabeled medical images for fine-grained\nsemantic representation learning. Our extensive experiments demonstrate that\nDiRA (1) encourages collaborative learning among three learning ingredients,\nresulting in more generalizable representation across organs, diseases, and\nmodalities; (2) outperforms fully supervised ImageNet models and increases\nrobustness in small data regimes, reducing annotation cost across multiple\nmedical imaging applications; (3) learns fine-grained semantic representation,\nfacilitating accurate lesion localization with only image-level annotation; and\n(4) enhances state-of-the-art restorative approaches, revealing that DiRA is a\ngeneral mechanism for united representation learning. All code and pre-trained\nmodels are available at https: //github.com/JLiangLab/DiRA.\n",
                "链接": "https://arxiv.org/abs/2204.10437"
            },
            {
                "文章ID": "80236",
                "标题": "Deep Learning-based Bio-Medical Image Segmentation using UNet\n  Architecture and Transfer Learning",
                "作者": " Nima Hassanpour,  Abouzar Ghavami",
                "发布日期": "2023-05-25",
                "摘要": "  Image segmentation is a branch of computer vision that is widely used in real\nworld applications including biomedical image processing. With recent\nadvancement of deep learning, image segmentation has achieved at a very high\nlevel performance. Recently, UNet architecture is found as the core of novel\ndeep learning segmentation methods. In this paper we implement UNet\narchitecture from scratch with using basic blocks in Pytorch and evaluate its\nperformance on multiple biomedical image datasets. We also use transfer\nlearning to apply novel modified UNet segmentation packages on the biomedical\nimage datasets. We fine tune the pre-trained transferred model with each\nspecific dataset. We compare its performance with our fundamental UNet\nimplementation. We show that transferred learning model has better performance\nin image segmentation than UNet model that is implemented from scratch.\n",
                "链接": "https://arxiv.org/abs/2305.14841"
            },
            {
                "文章ID": "59136",
                "标题": "Few-Shot Image-to-Semantics Translation for Policy Transfer in\n  Reinforcement Learning",
                "作者": " Rei Sato,  Kazuto Fukuchi,  Jun Sakuma,  Youhei Akimoto",
                "发布日期": "2023-02-01",
                "摘要": "  We investigate policy transfer using image-to-semantics translation to\nmitigate learning difficulties in vision-based robotics control agents. This\nproblem assumes two environments: a simulator environment with semantics, that\nis, low-dimensional and essential information, as the state space, and a\nreal-world environment with images as the state space. By learning mapping from\nimages to semantics, we can transfer a policy, pre-trained in the simulator, to\nthe real world, thereby eliminating real-world on-policy agent interactions to\nlearn, which are costly and risky. In addition, using image-to-semantics\nmapping is advantageous in terms of the computational efficiency to train the\npolicy and the interpretability of the obtained policy over other types of\nsim-to-real transfer strategies. To tackle the main difficulty in learning\nimage-to-semantics mapping, namely the human annotation cost for producing a\ntraining dataset, we propose two techniques: pair augmentation with the\ntransition function in the simulator environment and active learning. We\nobserved a reduction in the annotation cost without a decline in the\nperformance of the transfer, and the proposed approach outperformed the\nexisting approach without annotation.\n",
                "链接": "https://arxiv.org/abs/2301.13343"
            },
            {
                "文章ID": "87162",
                "标题": "M-VAAL: Multimodal Variational Adversarial Active Learning for\n  Downstream Medical Image Analysis Tasks",
                "作者": " Bidur Khanal,  Binod Bhattarai,  Bishesh Khanal,  Danail Stoyanov,  Cristian A. Linte",
                "发布日期": "2023-06-22",
                "摘要": "  Acquiring properly annotated data is expensive in the medical field as it\nrequires experts, time-consuming protocols, and rigorous validation. Active\nlearning attempts to minimize the need for large annotated samples by actively\nsampling the most informative examples for annotation. These examples\ncontribute significantly to improving the performance of supervised machine\nlearning models, and thus, active learning can play an essential role in\nselecting the most appropriate information in deep learning-based diagnosis,\nclinical assessments, and treatment planning. Although some existing works have\nproposed methods for sampling the best examples for annotation in medical image\nanalysis, they are not task-agnostic and do not use multimodal auxiliary\ninformation in the sampler, which has the potential to increase robustness.\nTherefore, in this work, we propose a Multimodal Variational Adversarial Active\nLearning (M-VAAL) method that uses auxiliary information from additional\nmodalities to enhance the active sampling. We applied our method to two\ndatasets: i) brain tumor segmentation and multi-label classification using the\nBraTS2018 dataset, and ii) chest X-ray image classification using the\nCOVID-QU-Ex dataset. Our results show a promising direction toward\ndata-efficient learning under limited annotations.\n",
                "链接": "https://arxiv.org/abs/2306.12376"
            }
        ]
    },
    {
        "question": {
            "question": "请找出最近一年内发表的关于自然语言处理领域中，使用Transformer模型并在大规模数据集上进行预训练的论文。特别关注模型结构和性能指标。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "请查找关于智能体的研究进展的综述或调查论文。重点关注不同领域中智能体的方法和应用，以及相关的挑战和未来方向。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "96424",
                "标题": "DREAMWALKER: Mental Planning for Continuous Vision-Language Navigation",
                "作者": " Hanqing Wang,  Wei Liang,  Luc Van Gool,  Wenguan Wang",
                "发布日期": "2023-08-16",
                "摘要": "  VLN-CE is a recently released embodied task, where AI agents need to navigate\na freely traversable environment to reach a distant target location, given\nlanguage instructions. It poses great challenges due to the huge space of\npossible strategies. Driven by the belief that the ability to anticipate the\nconsequences of future actions is crucial for the emergence of intelligent and\ninterpretable planning behavior, we propose DREAMWALKER -- a world model based\nVLN-CE agent. The world model is built to summarize the visual, topological,\nand dynamic properties of the complicated continuous environment into a\ndiscrete, structured, and compact representation. DREAMWALKER can simulate and\nevaluate possible plans entirely in such internal abstract world, before\nexecuting costly actions. As opposed to existing model-free VLN-CE agents\nsimply making greedy decisions in the real world, which easily results in\nshortsighted behaviors, DREAMWALKER is able to make strategic planning through\nlarge amounts of ``mental experiments.'' Moreover, the imagined future\nscenarios reflect our agent's intention, making its decision-making process\nmore transparent. Extensive experiments and ablation studies on VLN-CE dataset\nconfirm the effectiveness of the proposed approach and outline fruitful\ndirections for future work.\n",
                "链接": "https://arxiv.org/abs/2308.07498"
            },
            {
                "文章ID": "57524",
                "标题": "Human-Machine Collaboration for Smart Decision Making: Current Trends\n  and Future Opportunities",
                "作者": " Baocheng Geng,  Pramod K. Varshney",
                "发布日期": "2023-01-20",
                "摘要": "  Recently, modeling of decision making and control systems that include\nheterogeneous smart sensing devices (machines) as well as human agents as\nparticipants is becoming an important research area due to the wide variety of\napplications including autonomous driving, smart manufacturing, internet of\nthings, national security, and healthcare. To accomplish complex missions under\nuncertainty, it is imperative that we build novel human machine collaboration\nstructures to integrate the cognitive strengths of humans with computational\ncapabilities of machines in an intelligent manner. In this paper, we present an\noverview of the existing works on human decision making and human machine\ncollaboration within the scope of signal processing and information fusion. We\nreview several application areas and research domains relevant to human machine\ncollaborative decision making. We also discuss current challenges and future\ndirections in this problem domain.\n",
                "链接": "https://arxiv.org/abs/2301.07766"
            }
        ]
    }
]