[
    {
        "question": {
            "question": "与大模型工具学习相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "78693",
                "标题": "ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via\n  Tool Embeddings",
                "作者": " Shibo Hao,  Tianyang Liu,  Zhen Wang,  Zhiting Hu",
                "发布日期": "2023-11-01",
                "摘要": "  Augmenting large language models (LLMs) with external tools has emerged as a\npromising approach to solving complex problems. However, traditional methods,\nwhich finetune LLMs with tool demonstration data, can be both costly and\nrestricted to a predefined set of tools. Recent in-context learning paradigm\nalleviates these issues, but the limited context length only allows for a few\nshots of demonstrations, leading to suboptimal understandings of the tools.\nMoreover, when there are numerous tools to choose from, in-context learning\ncould completely fail to work. In this paper, we propose an alternative\napproach, $\\textbf{ToolkenGPT}$, which combines the benefits of both sides. Our\napproach represents each $\\underline{tool}$ as a to$\\underline{ken}$\n($\\textit{toolken}$) and learns an embedding for it, enabling tool calls in the\nsame way as generating a regular word token. Once a toolken is triggered, the\nLLM is prompted to complete arguments for the tool to execute. ToolkenGPT\noffers the flexibility to plug in an arbitrary number of tools by expanding the\nset of toolkens on the fly. In addition, it improves tool use by allowing\nextensive demonstration data for learning the toolken embeddings. In diverse\ndomains, including numerical reasoning, knowledge-based question answering, and\nembodied plan generation, our approach effectively augments LLMs with tools and\nsubstantially outperforms various latest baselines. ToolkenGPT demonstrates the\npromising ability to use relevant tools from a large tool set in complex\nscenarios.\n",
                "链接": "https://arxiv.org/abs/2305.11554"
            },
            {
                "文章ID": "106425",
                "标题": "MetaTool Benchmark for Large Language Models: Deciding Whether to Use\n  Tools and Which to Use",
                "作者": " Yue Huang,  Jiawen Shi,  Yuan Li,  Chenrui Fan,  Siyuan Wu,  Qihui Zhang,  Yixin Liu,  Pan Zhou,  Yao Wan,  Neil Zhenqiang Gong,  Lichao Sun",
                "发布日期": "2023-10-25",
                "摘要": "  Large language models (LLMs) have garnered significant attention due to their\nimpressive natural language processing (NLP) capabilities. Recently, many\nstudies have focused on the tool utilization ability of LLMs. They primarily\ninvestigated how LLMs effectively collaborate with given specific tools.\nHowever, in scenarios where LLMs serve as intelligent agents, as seen in\napplications like AutoGPT and MetaGPT, LLMs are expected to engage in intricate\ndecision-making processes that involve deciding whether to employ a tool and\nselecting the most suitable tool(s) from a collection of available tools to\nfulfill user requests. Therefore, in this paper, we introduce MetaTool, a\nbenchmark designed to evaluate whether LLMs have tool usage awareness and can\ncorrectly choose tools. Specifically, we create a dataset called ToolE within\nthe benchmark. This dataset contains various types of user queries in the form\nof prompts that trigger LLMs to use tools, including both single-tool and\nmulti-tool scenarios. Subsequently, we set the tasks for both tool usage\nawareness and tool selection. We define four subtasks from different\nperspectives in tool selection, including tool selection with similar choices,\ntool selection in specific scenarios, tool selection with possible reliability\nissues, and multi-tool selection. We conduct experiments involving nine popular\nLLMs and find that the majority of them still struggle to effectively select\ntools, highlighting the existing gaps between LLMs and genuine intelligent\nagents. However, through the error analysis, we found there is still\nsignificant room for improvement. Finally, we conclude with insights for tool\ndevelopers that follow ChatGPT to provide detailed descriptions that can\nenhance the tool selection performance of LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.03128"
            },
            {
                "文章ID": "72776",
                "标题": "Tool Learning with Foundation Models",
                "作者": " Yujia Qin,  Shengding Hu,  Yankai Lin,  Weize Chen,  Ning Ding,  Ganqu Cui,  Zheni Zeng,  Yufei Huang,  Chaojun Xiao,  Chi Han,  Yi Ren Fung,  Yusheng Su,  Huadong Wang,  Cheng Qian,  Runchu Tian,  Kunlun Zhu,  Shihao Liang,  Xingyu Shen,  Bokai Xu,  Zhen Zhang,  Yining Ye,  Bowen Li,  Ziwei Tang,  Jing Yi,  Yuzhang Zhu,  Zhenning Dai,  Lan Yan,  Xin Cong,  Yaxi Lu,  Weilin Zhao,  Yuxiang Huang,  Junxi Yan,  Xu Han,  Xian Sun,  Dahai Li,  Jason Phang,  Cheng Yang,  Tongshuang Wu,  Heng Ji,  Zhiyuan Liu,  Maosong Sun",
                "发布日期": "2023-06-16",
                "摘要": "  Humans possess an extraordinary ability to create and utilize tools, allowing\nthem to overcome physical limitations and explore new frontiers. With the\nadvent of foundation models, AI systems have the potential to be equally adept\nin tool use as humans. This paradigm, i.e., tool learning with foundation\nmodels, combines the strengths of specialized tools and foundation models to\nachieve enhanced accuracy, efficiency, and automation in problem-solving.\nDespite its immense potential, there is still a lack of a comprehensive\nunderstanding of key challenges, opportunities, and future endeavors in this\nfield. To this end, we present a systematic investigation of tool learning in\nthis paper. We first introduce the background of tool learning, including its\ncognitive origins, the paradigm shift of foundation models, and the\ncomplementary roles of tools and models. Then we recapitulate existing tool\nlearning research into tool-augmented and tool-oriented learning. We formulate\na general tool learning framework: starting from understanding the user\ninstruction, models should learn to decompose a complex task into several\nsubtasks, dynamically adjust their plan through reasoning, and effectively\nconquer each sub-task by selecting appropriate tools. We also discuss how to\ntrain models for improved tool-use capabilities and facilitate the\ngeneralization in tool learning. Considering the lack of a systematic tool\nlearning evaluation in prior works, we experiment with 18 representative tools\nand show the potential of current foundation models in skillfully utilizing\ntools. Finally, we discuss several open problems that require further\ninvestigation for tool learning. Overall, we hope this paper could inspire\nfuture research in integrating tools with foundation models.\n",
                "链接": "https://arxiv.org/abs/2304.08354"
            },
            {
                "文章ID": "94169",
                "标题": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language\n  Models",
                "作者": " Cheng-Yu Hsieh,  Si-An Chen,  Chun-Liang Li,  Yasuhisa Fujii,  Alexander Ratner,  Chen-Yu Lee,  Ranjay Krishna,  Tomas Pfister",
                "发布日期": "2023-08-02",
                "摘要": "  Today, large language models (LLMs) are taught to use new tools by providing\na few demonstrations of the tool's usage. Unfortunately, demonstrations are\nhard to acquire, and can result in undesirable biased usage if the wrong\ndemonstration is chosen. Even in the rare scenario that demonstrations are\nreadily available, there is no principled selection protocol to determine how\nmany and which ones to provide. As tasks grow more complex, the selection\nsearch grows combinatorially and invariably becomes intractable. Our work\nprovides an alternative to demonstrations: tool documentation. We advocate the\nuse of tool documentation, descriptions for the individual tool usage, over\ndemonstrations. We substantiate our claim through three main empirical findings\non 6 tasks across both vision and language modalities. First, on existing\nbenchmarks, zero-shot prompts with only tool documentation are sufficient for\neliciting proper tool usage, achieving performance on par with few-shot\nprompts. Second, on a newly collected realistic tool-use dataset with hundreds\nof available tool APIs, we show that tool documentation is significantly more\nvaluable than demonstrations, with zero-shot documentation significantly\noutperforming few-shot without documentation. Third, we highlight the benefits\nof tool documentations by tackling image generation and video tracking using\njust-released unseen state-of-the-art models as tools. Finally, we highlight\nthe possibility of using tool documentation to automatically enable new\napplications: by using nothing more than the documentation of GroundingDino,\nStable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the\njust-released Grounded-SAM and Track Anything models.\n",
                "链接": "https://arxiv.org/abs/2308.00675"
            },
            {
                "文章ID": "94111",
                "标题": "Structural Embeddings of Tools for Large Language Models",
                "作者": " Eren Unlu",
                "发布日期": "2023-08-02",
                "摘要": "  It is evident that the current state of Large Language Models (LLMs)\nnecessitates the incorporation of external tools. The lack of straightforward\nalgebraic and logical reasoning is well documented and prompted researchers to\ndevelop frameworks which allow LLMs to operate via external tools. The\nontological nature of tool utilization for a specific task can be well\nformulated with a Directed Acyclic Graph (DAG). The central aim of the paper is\nto highlight the importance of graph based approaches to LLM-tool interaction\nin near future. We propose an exemplary framework to guide the orchestration of\nexponentially increasing numbers of external tools with LLMs,where objectives\nand functionalities of tools are graph encoded hierarchically. Assuming that\ntextual segments of a Chain-of-Thought (CoT) can be imagined as a tool as\ndefined here, the graph based framework can pave new avenues in that particular\ndirection as well.\n",
                "链接": "https://arxiv.org/abs/2308.00447"
            },
            {
                "文章ID": "110068",
                "标题": "Creative Robot Tool Use with Large Language Models",
                "作者": " Mengdi Xu,  Peide Huang,  Wenhao Yu,  Shiqi Liu,  Xilun Zhang,  Yaru Niu,  Tingnan Zhang,  Fei Xia,  Jie Tan,  Ding Zhao",
                "发布日期": "2023-10-23",
                "摘要": "  Tool use is a hallmark of advanced intelligence, exemplified in both animal\nbehavior and robotic capabilities. This paper investigates the feasibility of\nimbuing robots with the ability to creatively use tools in tasks that involve\nimplicit physical constraints and long-term planning. Leveraging Large Language\nModels (LLMs), we develop RoboTool, a system that accepts natural language\ninstructions and outputs executable code for controlling robots in both\nsimulated and real-world environments. RoboTool incorporates four pivotal\ncomponents: (i) an \"Analyzer\" that interprets natural language to discern key\ntask-related concepts, (ii) a \"Planner\" that generates comprehensive strategies\nbased on the language input and key concepts, (iii) a \"Calculator\" that\ncomputes parameters for each skill, and (iv) a \"Coder\" that translates these\nplans into executable Python code. Our results show that RoboTool can not only\ncomprehend explicit or implicit physical constraints and environmental factors\nbut also demonstrate creative tool use. Unlike traditional Task and Motion\nPlanning (TAMP) methods that rely on explicit optimization, our LLM-based\nsystem offers a more flexible, efficient, and user-friendly solution for\ncomplex robotics tasks. Through extensive experiments, we validate that\nRoboTool is proficient in handling tasks that would otherwise be infeasible\nwithout the creative use of tools, thereby expanding the capabilities of\nrobotic systems. Demos are available on our project page:\nhttps://creative-robotool.github.io/.\n",
                "链接": "https://arxiv.org/abs/2310.13065"
            },
            {
                "文章ID": "81272",
                "标题": "Large Language Models as Tool Makers",
                "作者": " Tianle Cai,  Xuezhi Wang,  Tengyu Ma,  Xinyun Chen,  Denny Zhou",
                "发布日期": "2023-05-29",
                "摘要": "  Recent research shows the potential of enhancing the problem-solving ability\nof large language models (LLMs) through the use of external tools. However,\nprior work along this line depends on the availability of existing tools. In\nthis work, we take an initial step towards removing this dependency by\nproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),\nwhere LLMs create their own reusable tools for problem-solving. Our approach\nconsists of two key phases: 1) tool making: an LLM acts as the tool maker that\ncrafts tools for given tasks, where a tool is implemented as a Python utility\nfunction. 2) tool using: an LLM acts as the tool user, which applies the tool\nbuilt by the tool maker for problem-solving. The tool user can be either the\nsame or a different LLM from the tool maker. Tool-making enables an LLM to\ncontinually generate tools that can be applied to different requests so that\nfuture requests can call the corresponding APIs when beneficial for solving the\ntasks. Furthermore, the division of labor among LLMs for tool-making and\ntool-using phases introduces the opportunity to achieve cost effectiveness\nwithout degrading the quality of generated tools and problem solutions. For\nexample, recognizing that tool-making demands more sophisticated capabilities\nthan tool-using, we can apply a powerful yet resource-intensive model as the\ntool maker, and a lightweight while cost-effective model as the tool user. We\nvalidate the effectiveness of our approach across a variety of complex\nreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and\nGPT-3.5 as the tool user, LATM can achieve performance that is on par with\nusing GPT-4 for both tool making and tool using, while the inference cost is\nsignificantly reduced.\n",
                "链接": "https://arxiv.org/abs/2305.17126"
            },
            {
                "文章ID": "56117",
                "标题": "Exploring Machine Learning Techniques to Identify Important Factors\n  Leading to Injury in Curve Related Crashes",
                "作者": " Mehdi Moeinaddini,  Mozhgan Pourmoradnasseri,  Amnir Hadachi,  Mario Cools",
                "发布日期": "2023-01-06",
                "摘要": "  Different factors have effects on traffic crashes and crash-related injuries.\nThese factors include segment characteristics, crash-level characteristics,\noccupant level characteristics, environment characteristics, and vehicle level\ncharacteristics. There are several studies regarding these factors' effects on\ncrash injuries. However, limited studies have examined the effects of pre-crash\nevents on injuries, especially for curve-related crashes. The majority of\nprevious studies for curve-related crashes focused on the impact of geometric\nfeatures or street design factors. The current study tries to eliminate the\naforementioned shortcomings by considering important pre-crash events related\nfactors as selected variables and the number of vehicles with or without injury\nas the predicted variable. This research used CRSS data from the National\nHighway Traffic Safety Administration (NHTSA), which includes traffic\ncrash-related data for different states in the USA. The relationships are\nexplored using different machine learning algorithms like the random forest,\nC5.0, CHAID, Bayesian Network, Neural Network, C\\&R Tree, Quest, etc. The\nrandom forest and SHAP values are used to identify the most effective\nvariables. The C5.0 algorithm, which has the highest accuracy rate among the\nother algorithms, is used to develop the final model. Analysis results revealed\nthat the extent of the damage, critical pre-crash event, pre-impact location,\nthe trafficway description, roadway surface condition, the month of the crash,\nthe first harmful event, number of motor vehicles, attempted avoidance\nmaneuver, and roadway grade affect the number of vehicles with or without\ninjury in curve-related crashes.\n",
                "链接": "https://arxiv.org/abs/2301.01771"
            },
            {
                "文章ID": "84645",
                "标题": "ToolAlpaca: Generalized Tool Learning for Language Models with 3000\n  Simulated Cases",
                "作者": " Qiaoyu Tang,  Ziliang Deng,  Hongyu Lin,  Xianpei Han,  Qiao Liang,  Boxi Cao,  Le Sun",
                "发布日期": "2023-09-08",
                "摘要": "  Enabling large language models to utilize real-world tools effectively is\ncrucial for achieving embodied intelligence. Existing approaches to tool\nlearning have either primarily relied on extremely large language models, such\nas GPT-4, to attain generalized tool-use abilities in a zero-shot manner, or\nutilized supervised learning to train limited scopes of tools on compact\nmodels. However, it remains uncertain whether smaller language models can\nachieve generalized tool-use abilities without tool-specific training. To\naddress this question, this paper introduces ToolAlpaca, a novel framework\ndesigned to automatically generate a diverse tool-use corpus and learn\ngeneralized tool-use abilities on compact language models with minimal human\nintervention. Specifically, ToolAlpaca first automatically creates a highly\ndiversified tool-use corpus by building a multi-agent simulation environment.\nThe corpus contains 3938 tool-use instances from more than 400 real-world tool\nAPIs spanning 50 distinct categories. Subsequently, the constructed corpus is\nemployed to fine-tune compact language models, resulting in two models, namely\nToolAlpaca-7B and ToolAlpaca-13B, respectively. Finally, we evaluate the\nability of these models to utilize previously unseen tools without specific\ntraining. Experimental results demonstrate that ToolAlpaca achieves effective\ngeneralized tool-use capabilities comparable to those of extremely large\nlanguage models like GPT-3.5, demonstrating that learning generalized tool-use\nability is feasible for compact language models.\n",
                "链接": "https://arxiv.org/abs/2306.05301"
            },
            {
                "文章ID": "82016",
                "标题": "GPT4Tools: Teaching Large Language Model to Use Tools via\n  Self-instruction",
                "作者": " Rui Yang,  Lin Song,  Yanwei Li,  Sijie Zhao,  Yixiao Ge,  Xiu Li,  Ying Shan",
                "发布日期": "2023-05-31",
                "摘要": "  This paper aims to efficiently enable Large Language Models (LLMs) to use\nmultimodal tools. Advanced proprietary LLMs, such as ChatGPT and GPT-4, have\nshown great potential for tool usage through sophisticated prompt engineering.\nNevertheless, these models typically rely on prohibitive computational costs\nand publicly inaccessible data. To address these challenges, we propose the\nGPT4Tools based on self-instruct to enable open-source LLMs, such as LLaMA and\nOPT, to use tools. It generates an instruction-following dataset by prompting\nan advanced teacher with various multi-modal contexts. By using the Low-Rank\nAdaptation (LoRA) optimization, our approach facilitates the open-source LLMs\nto solve a range of visual problems, including visual comprehension and image\ngeneration. Moreover, we provide a benchmark to evaluate the ability of LLMs to\nuse tools, which is performed in both zero-shot and fine-tuning ways. Extensive\nexperiments demonstrate the effectiveness of our method on various language\nmodels, which not only significantly improves the accuracy of invoking seen\ntools, but also enables the zero-shot capacity for unseen tools. The code and\ndemo are available at https://github.com/StevenGrove/GPT4Tools.\n",
                "链接": "https://arxiv.org/abs/2305.18752"
            }
        ]
    },
    {
        "question": {
            "question": "和大模型可解释相关的最新论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "39484",
                "标题": "Accuracy, Fairness, and Interpretability of Machine Learning Criminal\n  Recidivism Models",
                "作者": " Eric Ingram,  Furkan Gursoy,  Ioannis A. Kakadiaris",
                "发布日期": "2022-09-29",
                "摘要": "  Criminal recidivism models are tools that have gained widespread adoption by\nparole boards across the United States to assist with parole decisions. These\nmodels take in large amounts of data about an individual and then predict\nwhether an individual would commit a crime if released on parole. Although such\nmodels are not the only or primary factor in making the final parole decision,\nquestions have been raised about their accuracy, fairness, and\ninterpretability. In this paper, various machine learning-based criminal\nrecidivism models are created based on a real-world parole decision dataset\nfrom the state of Georgia in the United States. The recidivism models are\ncomparatively evaluated for their accuracy, fairness, and interpretability. It\nis found that there are noted differences and trade-offs between accuracy,\nfairness, and being inherently interpretable. Therefore, choosing the best\nmodel depends on the desired balance between accuracy, fairness, and\ninterpretability, as no model is perfect or consistently the best across\ndifferent criteria.\n",
                "链接": "https://arxiv.org/abs/2209.14237"
            },
            {
                "文章ID": "20302",
                "标题": "Scaling Laws and Interpretability of Learning from Repeated Data",
                "作者": " Danny Hernandez,  Tom Brown,  Tom Conerly,  Nova DasSarma,  Dawn Drain,  Sheer El-Showk,  Nelson Elhage,  Zac Hatfield-Dodds,  Tom Henighan,  Tristan Hume,  Scott Johnston,  Ben Mann,  Chris Olah,  Catherine Olsson,  Dario Amodei,  Nicholas Joseph,  Jared Kaplan,  Sam McCandlish",
                "发布日期": "2022-05-24",
                "摘要": "  Recent large language models have been trained on vast datasets, but also\noften on repeated data, either intentionally for the purpose of upweighting\nhigher quality data, or unintentionally because data deduplication is not\nperfect and the model is exposed to repeated data at the sentence, paragraph,\nor document level. Some works have reported substantial negative performance\neffects of this repeated data. In this paper we attempt to study repeated data\nsystematically and to understand its effects mechanistically. To do this, we\ntrain a family of models where most of the data is unique but a small fraction\nof it is repeated many times. We find a strong double descent phenomenon, in\nwhich repeated data can lead test loss to increase midway through training. A\npredictable range of repetition frequency leads to surprisingly severe\ndegradation in performance. For instance, performance of an 800M parameter\nmodel can be degraded to that of a 2x smaller model (400M params) by repeating\n0.1% of the data 100 times, despite the other 90% of the training tokens\nremaining unique. We suspect there is a range in the middle where the data can\nbe memorized and doing so consumes a large fraction of the model's capacity,\nand this may be where the peak of degradation occurs. Finally, we connect these\nobservations to recent mechanistic interpretability work - attempting to\nreverse engineer the detailed computations performed by the model - by showing\nthat data repetition disproportionately damages copying and internal structures\nassociated with generalization, such as induction heads, providing a possible\nmechanism for the shift from generalization to memorization. Taken together,\nthese results provide a hypothesis for why repeating a relatively small\nfraction of data in large language models could lead to disproportionately\nlarge harms to performance.\n",
                "链接": "https://arxiv.org/abs/2205.10487"
            },
            {
                "文章ID": "116604",
                "标题": "RecExplainer: Aligning Large Language Models for Recommendation Model\n  Interpretability",
                "作者": " Yuxuan Lei,  Jianxun Lian,  Jing Yao,  Xu Huang,  Defu Lian,  Xing Xie",
                "发布日期": "2023-11-21",
                "摘要": "  Recommender systems are widely used in various online services, with\nembedding-based models being particularly popular due to their expressiveness\nin representing complex signals. However, these models often lack\ninterpretability, making them less reliable and transparent for both users and\ndevelopers. With the emergence of large language models (LLMs), we find that\ntheir capabilities in language expression, knowledge-aware reasoning, and\ninstruction following are exceptionally powerful. Based on this, we propose a\nnew model interpretation approach for recommender systems, by using LLMs as\nsurrogate models and learn to mimic and comprehend target recommender models.\nSpecifically, we introduce three alignment methods: behavior alignment,\nintention alignment, and hybrid alignment. Behavior alignment operates in the\nlanguage space, representing user preferences and item information as text to\nlearn the recommendation model's behavior; intention alignment works in the\nlatent space of the recommendation model, using user and item representations\nto understand the model's behavior; hybrid alignment combines both language and\nlatent spaces for alignment training. To demonstrate the effectiveness of our\nmethods, we conduct evaluation from two perspectives: alignment effect, and\nexplanation generation ability on three public datasets. Experimental results\nindicate that our approach effectively enables LLMs to comprehend the patterns\nof recommendation models and generate highly credible recommendation\nexplanations.\n",
                "链接": "https://arxiv.org/abs/2311.10947"
            },
            {
                "文章ID": "61490",
                "标题": "Relatedly: Scaffolding Literature Reviews with Existing Related Work\n  Sections",
                "作者": " Srishti Palani,  Aakanksha Naik,  Doug Downey,  Amy X. Zhang,  Jonathan Bragg,  Joseph Chee Chang",
                "发布日期": "2023-02-15",
                "摘要": "  Scholars who want to research a scientific topic must take time to read,\nextract meaning, and identify connections across many papers. As scientific\nliterature grows, this becomes increasingly challenging. Meanwhile, authors\nsummarize prior research in papers' related work sections, though this is\nscoped to support a single paper. A formative study found that while reading\nmultiple related work paragraphs helps overview a topic, it is hard to navigate\noverlapping and diverging references and research foci. In this work, we design\na system, Relatedly, that scaffolds exploring and reading multiple related work\nparagraphs on a topic, with features including dynamic re-ranking and\nhighlighting to spotlight unexplored dissimilar information, auto-generated\ndescriptive paragraph headings, and low-lighting of redundant information. From\na within-subjects user study (n=15), we found that scholars generate more\ncoherent, insightful, and comprehensive topic outlines using Relatedly compared\nto a baseline paper list.\n",
                "链接": "https://arxiv.org/abs/2302.06754"
            },
            {
                "文章ID": "115222",
                "标题": "Assessing the Interpretability of Programmatic Policies with Large\n  Language Models",
                "作者": " Zahra Bashir,  Michael Bowling,  Levi H. S. Lelis",
                "发布日期": "2023-11-14",
                "摘要": "  Although the synthesis of programs encoding policies often carries the\npromise of interpretability, systematic evaluations to assess the\ninterpretability of these policies were never performed, likely because of the\ncomplexity of such an evaluation. In this paper, we introduce a novel metric\nthat uses large-language models (LLM) to assess the interpretability of\nprogrammatic policies. For our metric, an LLM is given both a program and a\ndescription of its associated programming language. The LLM then formulates a\nnatural language explanation of the program. This explanation is subsequently\nfed into a second LLM, which tries to reconstruct the program from the natural\nlanguage explanation. Our metric measures the behavioral similarity between the\nreconstructed program and the original. We validate our approach using\nobfuscated programs that are used to solve classic programming problems. We\nalso assess our metric with programmatic policies synthesized for playing a\nreal-time strategy game, comparing the interpretability scores of programmatic\npolicies synthesized by an existing system to lightly obfuscated versions of\nthe same programs. Our LLM-based interpretability score consistently ranks less\ninterpretable programs lower and more interpretable ones higher. These findings\nsuggest that our metric could serve as a reliable and inexpensive tool for\nevaluating the interpretability of programmatic policies.\n",
                "链接": "https://arxiv.org/abs/2311.06979"
            },
            {
                "文章ID": "30759",
                "标题": "Inter-model Interpretability: Self-supervised Models as a Case Study",
                "作者": " Ahmad Mustapha,  Wael Khreich,  Wes Masri",
                "发布日期": "2022-08-02",
                "摘要": "  Since early machine learning models, metrics such as accuracy and precision\nhave been the de facto way to evaluate and compare trained models. However, a\nsingle metric number doesn't fully capture the similarities and differences\nbetween models, especially in the computer vision domain. A model with high\naccuracy on a certain dataset might provide a lower accuracy on another\ndataset, without any further insights. To address this problem we build on a\nrecent interpretability technique called Dissect to introduce\n\\textit{inter-model interpretability}, which determines how models relate or\ncomplement each other based on the visual concepts they have learned (such as\nobjects and materials). Towards this goal, we project 13 top-performing\nself-supervised models into a Learned Concepts Embedding (LCE) space that\nreveals proximities among models from the perspective of learned concepts. We\nfurther crossed this information with the performance of these models on four\ncomputer vision tasks and 15 datasets. The experiment allowed us to categorize\nthe models into three categories and revealed for the first time the type of\nvisual concepts different tasks requires. This is a step forward for designing\ncross-task learning algorithms.\n",
                "链接": "https://arxiv.org/abs/2207.11837"
            },
            {
                "文章ID": "120483",
                "标题": "FlexModel: A Framework for Interpretability of Distributed Large\n  Language Models",
                "作者": " Matthew Choi,  Muhammad Adil Asif,  John Willes,  David Emerson",
                "发布日期": "2023-12-07",
                "摘要": "  With the growth of large language models, now incorporating billions of\nparameters, the hardware prerequisites for their training and deployment have\nseen a corresponding increase. Although existing tools facilitate model\nparallelization and distributed training, deeper model interactions, crucial\nfor interpretability and responsible AI techniques, still demand thorough\nknowledge of distributed computing. This often hinders contributions from\nresearchers with machine learning expertise but limited distributed computing\nbackground. Addressing this challenge, we present FlexModel, a software package\nproviding a streamlined interface for engaging with models distributed across\nmulti-GPU and multi-node configurations. The library is compatible with\nexisting model distribution libraries and encapsulates PyTorch models. It\nexposes user-registerable HookFunctions to facilitate straightforward\ninteraction with distributed model internals, bridging the gap between\ndistributed and single-device model paradigms. Primarily, FlexModel enhances\naccessibility by democratizing model interactions and promotes more inclusive\nresearch in the domain of large-scale neural networks. The package is found at\nhttps://github.com/VectorInstitute/flex_model.\n",
                "链接": "https://arxiv.org/abs/2312.03140"
            },
            {
                "文章ID": "90826",
                "标题": "Negated Complementary Commonsense using Large Language Models",
                "作者": " Navid Rezaei,  Marek Z. Reformat",
                "发布日期": "2023-07-14",
                "摘要": "  Larger language models, such as GPT-3, have shown to be excellent in many\ntasks. However, we demonstrate that out-of-ordinary questions can throw the\nmodel off guard. This work focuses on finding answers to negated complementary\nquestions in commonsense scenarios. We illustrate how such questions adversely\naffect the model responses. We propose a model-agnostic methodology to improve\nthe performance in negated complementary scenarios. Our method outperforms\nfew-shot generation from GPT-3 (by more than 11 points) and, more importantly,\nhighlights the significance of studying the response of large language models\nin negated complementary questions. The code, data, and experiments are\navailable under: https://github.com/navidre/negated_complementary_commonsense.\n",
                "链接": "https://arxiv.org/abs/2307.06794"
            },
            {
                "文章ID": "80657",
                "标题": "On the Impact of Knowledge Distillation for Model Interpretability",
                "作者": " Hyeongrok Han,  Siwon Kim,  Hyun-Soo Choi,  Sungroh Yoon",
                "发布日期": "2023-05-26",
                "摘要": "  Several recent studies have elucidated why knowledge distillation (KD)\nimproves model performance. However, few have researched the other advantages\nof KD in addition to its improving model performance. In this study, we have\nattempted to show that KD enhances the interpretability as well as the accuracy\nof models. We measured the number of concept detectors identified in network\ndissection for a quantitative comparison of model interpretability. We\nattributed the improvement in interpretability to the class-similarity\ninformation transferred from the teacher to student models. First, we confirmed\nthe transfer of class-similarity information from the teacher to student model\nvia logit distillation. Then, we analyzed how class-similarity information\naffects model interpretability in terms of its presence or absence and degree\nof similarity information. We conducted various quantitative and qualitative\nexperiments and examined the results on different datasets, different KD\nmethods, and according to different measures of interpretability. Our research\nshowed that KD models by large models could be used more reliably in various\nfields.\n",
                "链接": "https://arxiv.org/abs/2305.15734"
            },
            {
                "文章ID": "16113",
                "标题": "Sparsely-gated Mixture-of-Expert Layers for CNN Interpretability",
                "作者": " Svetlana Pavlitska,  Christian Hubschneider,  Lukas Struppek,  J. Marius Zöllner",
                "发布日期": "2023-04-28",
                "摘要": "  Sparsely-gated Mixture of Expert (MoE) layers have been recently successfully\napplied for scaling large transformers, especially for language modeling tasks.\nAn intriguing side effect of sparse MoE layers is that they convey inherent\ninterpretability to a model via natural expert specialization. In this work, we\napply sparse MoE layers to CNNs for computer vision tasks and analyze the\nresulting effect on model interpretability. To stabilize MoE training, we\npresent both soft and hard constraint-based approaches. With hard constraints,\nthe weights of certain experts are allowed to become zero, while soft\nconstraints balance the contribution of experts with an additional auxiliary\nloss. As a result, soft constraints handle expert utilization better and\nsupport the expert specialization process, while hard constraints maintain more\ngeneralized experts and increase overall model performance. Our findings\ndemonstrate that experts can implicitly focus on individual sub-domains of the\ninput space. For example, experts trained for CIFAR-100 image classification\nspecialize in recognizing different domains such as flowers or animals without\nprevious data clustering. Experiments with RetinaNet and the COCO dataset\nfurther indicate that object detection experts can also specialize in detecting\nobjects of distinct sizes.\n",
                "链接": "https://arxiv.org/abs/2204.10598"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于大模型Agent应用的最新发表论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "10750",
                "标题": "Model-based Multi-agent Reinforcement Learning: Recent Progress and\n  Prospects",
                "作者": " Xihuai Wang,  Zhicheng Zhang,  Weinan Zhang",
                "发布日期": "2022-03-22",
                "摘要": "  Significant advances have recently been achieved in Multi-Agent Reinforcement\nLearning (MARL) which tackles sequential decision-making problems involving\nmultiple participants. However, MARL requires a tremendous number of samples\nfor effective training. On the other hand, model-based methods have been shown\nto achieve provable advantages of sample efficiency. However, the attempts of\nmodel-based methods to MARL have just started very recently. This paper\npresents a review of the existing research on model-based MARL, including\ntheoretical analyses, algorithms, and applications, and analyzes the advantages\nand potential of model-based MARL. Specifically, we provide a detailed taxonomy\nof the algorithms and point out the pros and cons for each algorithm according\nto the challenges inherent to multi-agent scenarios. We also outline promising\ndirections for future development of this field.\n",
                "链接": "https://arxiv.org/abs/2203.10603"
            },
            {
                "文章ID": "69140",
                "标题": "CoCon: A Data Set on Combined Contextualized Research Artifact Use",
                "作者": " Tarek Saier,  Youxiang Dong,  Michael Färber",
                "发布日期": "2023-11-06",
                "摘要": "  In the wake of information overload in academia, methodologies and systems\nfor search, recommendation, and prediction to aid researchers in identifying\nrelevant research are actively studied and developed. Existing work, however,\nis limited in terms of granularity, focusing only on the level of papers or a\nsingle type of artifact, such as data sets. To enable more holistic analyses\nand systems dealing with academic publications and their content, we propose\nCoCon, a large scholarly data set reflecting the combined use of research\nartifacts, contextualized in academic publications' full-text. Our data set\ncomprises 35 k artifacts (data sets, methods, models, and tasks) and 340 k\npublications. We additionally formalize a link prediction task for \"combined\nresearch artifact use prediction\" and provide code to utilize analyses of and\nthe development of ML applications on our data. All data and code is publicly\navailable at https://github.com/IllDepence/contextgraph.\n",
                "链接": "https://arxiv.org/abs/2303.15193"
            },
            {
                "文章ID": "60063",
                "标题": "PubGraph: A Large-Scale Scientific Knowledge Graph",
                "作者": " Kian Ahrabian,  Xinwei Du,  Richard Delwin Myloth,  Arun Baalaaji Sankar Ananthan,  Jay Pujara",
                "发布日期": "2023-05-22",
                "摘要": "  Research publications are the primary vehicle for sharing scientific progress\nin the form of new discoveries, methods, techniques, and insights.\nUnfortunately, the lack of a large-scale, comprehensive, and easy-to-use\nresource capturing the myriad relationships between publications, their\nauthors, and venues presents a barrier to applications for gaining a deeper\nunderstanding of science. In this paper, we present PubGraph, a new resource\nfor studying scientific progress that takes the form of a large-scale knowledge\ngraph (KG) with more than 385M entities, 13B main edges, and 1.5B qualifier\nedges. PubGraph is comprehensive and unifies data from various sources,\nincluding Wikidata, OpenAlex, and Semantic Scholar, using the Wikidata\nontology. Beyond the metadata available from these sources, PubGraph includes\noutputs from auxiliary community detection algorithms and large language\nmodels. To further support studies on reasoning over scientific networks, we\ncreate several large-scale benchmarks extracted from PubGraph for the core task\nof knowledge graph completion (KGC). These benchmarks present many challenges\nfor knowledge graph embedding models, including an adversarial community-based\nKGC evaluation setting, zero-shot inductive learning, and large-scale learning.\nAll of the aforementioned resources are accessible at https://pubgraph.isi.edu/\nand released under the CC-BY-SA license. We plan to update PubGraph quarterly\nto accommodate the release of new publications.\n",
                "链接": "https://arxiv.org/abs/2302.02231"
            },
            {
                "文章ID": "16946",
                "标题": "D3: A Massive Dataset of Scholarly Metadata for Analyzing the State of\n  Computer Science Research",
                "作者": " Jan Philip Wahle,  Terry Ruas,  Saif M. Mohammad,  Bela Gipp",
                "发布日期": "2023-10-24",
                "摘要": "  DBLP is the largest open-access repository of scientific articles on computer\nscience and provides metadata associated with publications, authors, and\nvenues. We retrieved more than 6 million publications from DBLP and extracted\npertinent metadata (e.g., abstracts, author affiliations, citations) from the\npublication texts to create the DBLP Discovery Dataset (D3). D3 can be used to\nidentify trends in research activity, productivity, focus, bias, accessibility,\nand impact of computer science research. We present an initial analysis focused\non the volume of computer science research (e.g., number of papers, authors,\nresearch activity), trends in topics of interest, and citation patterns. Our\nfindings show that computer science is a growing research field (approx. 15%\nannually), with an active and collaborative researcher community. While papers\nin recent years present more bibliographical entries in comparison to previous\ndecades, the average number of citations has been declining. Investigating\npapers' abstracts reveals that recent topic trends are clearly reflected in D3.\nFinally, we list further applications of D3 and pose supplemental research\nquestions. The D3 dataset, our findings, and source code are publicly available\nfor research purposes.\n",
                "链接": "https://arxiv.org/abs/2204.13384"
            },
            {
                "文章ID": "111569",
                "标题": "math-PVS: A Large Language Model Framework to Map Scientific\n  Publications to PVS Theories",
                "作者": " Hassen Saidi,  Susmit Jha,  Tuhin Sahai",
                "发布日期": "2023-10-27",
                "摘要": "  As artificial intelligence (AI) gains greater adoption in a wide variety of\napplications, it has immense potential to contribute to mathematical discovery,\nby guiding conjecture generation, constructing counterexamples, assisting in\nformalizing mathematics, and discovering connections between different\nmathematical areas, to name a few.\n  While prior work has leveraged computers for exhaustive mathematical proof\nsearch, recent efforts based on large language models (LLMs) aspire to position\ncomputing platforms as co-contributors in the mathematical research process.\nDespite their current limitations in logic and mathematical tasks, there is\ngrowing interest in melding theorem proving systems with foundation models.\nThis work investigates the applicability of LLMs in formalizing advanced\nmathematical concepts and proposes a framework that can critically review and\ncheck mathematical reasoning in research papers. Given the noted reasoning\nshortcomings of LLMs, our approach synergizes the capabilities of proof\nassistants, specifically PVS, with LLMs, enabling a bridge between textual\ndescriptions in academic papers and formal specifications in PVS. By harnessing\nthe PVS environment, coupled with data ingestion and conversion mechanisms, we\nenvision an automated process, called \\emph{math-PVS}, to extract and formalize\nmathematical theorems from research papers, offering an innovative tool for\nacademic review and discovery.\n",
                "链接": "https://arxiv.org/abs/2310.17064"
            },
            {
                "文章ID": "66558",
                "标题": "Generalised Scale-Space Properties for Probabilistic Diffusion Models",
                "作者": " Pascal Peter",
                "发布日期": "2023-09-19",
                "摘要": "  Probabilistic diffusion models enjoy increasing popularity in the deep\nlearning community. They generate convincing samples from a learned\ndistribution of input images with a wide field of practical applications.\nOriginally, these approaches were motivated from drift-diffusion processes, but\nthese origins find less attention in recent, practice-oriented publications. We\ninvestigate probabilistic diffusion models from the viewpoint of scale-space\nresearch and show that they fulfil generalised scale-space properties on\nevolving probability distributions. Moreover, we discuss similarities and\ndifferences between interpretations of the physical core concept of\ndrift-diffusion in the deep learning and model-based world. To this end, we\nexamine relations of probabilistic diffusion to osmosis filters.\n",
                "链接": "https://arxiv.org/abs/2303.07900"
            },
            {
                "文章ID": "124256",
                "标题": "AppAgent: Multimodal Agents as Smartphone Users",
                "作者": " Chi Zhang,  Zhao Yang,  Jiaxuan Liu,  Yucheng Han,  Xin Chen,  Zebiao Huang,  Bin Fu,  Gang Yu",
                "发布日期": "2023-12-25",
                "摘要": "  Recent advancements in large language models (LLMs) have led to the creation\nof intelligent agents capable of performing complex tasks. This paper\nintroduces a novel LLM-based multimodal agent framework designed to operate\nsmartphone applications. Our framework enables the agent to operate smartphone\napplications through a simplified action space, mimicking human-like\ninteractions such as tapping and swiping. This novel approach bypasses the need\nfor system back-end access, thereby broadening its applicability across diverse\napps. Central to our agent's functionality is its innovative learning method.\nThe agent learns to navigate and use new apps either through autonomous\nexploration or by observing human demonstrations. This process generates a\nknowledge base that the agent refers to for executing complex tasks across\ndifferent applications. To demonstrate the practicality of our agent, we\nconducted extensive testing over 50 tasks in 10 different applications,\nincluding social media, email, maps, shopping, and sophisticated image editing\ntools. The results affirm our agent's proficiency in handling a diverse array\nof high-level tasks.\n",
                "链接": "https://arxiv.org/abs/2312.13771"
            },
            {
                "文章ID": "44656",
                "标题": "Full-Text Argumentation Mining on Scientific Publications",
                "作者": " Arne Binder,  Bhuvanesh Verma,  Leonhard Hennig",
                "发布日期": "2022-10-25",
                "摘要": "  Scholarly Argumentation Mining (SAM) has recently gained attention due to its\npotential to help scholars with the rapid growth of published scientific\nliterature. It comprises two subtasks: argumentative discourse unit recognition\n(ADUR) and argumentative relation extraction (ARE), both of which are\nchallenging since they require e.g. the integration of domain knowledge, the\ndetection of implicit statements, and the disambiguation of argument structure.\nWhile previous work focused on dataset construction and baseline methods for\nspecific document sections, such as abstract or results, full-text scholarly\nargumentation mining has seen little progress. In this work, we introduce a\nsequential pipeline model combining ADUR and ARE for full-text SAM, and provide\na first analysis of the performance of pretrained language models (PLMs) on\nboth subtasks. We establish a new SotA for ADUR on the Sci-Arg corpus,\noutperforming the previous best reported result by a large margin (+7% F1). We\nalso present the first results for ARE, and thus for the full AM pipeline, on\nthis benchmark dataset. Our detailed error analysis reveals that non-contiguous\nADUs as well as the interpretation of discourse connectors pose major\nchallenges and that data annotation needs to be more consistent.\n",
                "链接": "https://arxiv.org/abs/2210.13084"
            },
            {
                "文章ID": "77005",
                "标题": "Towards a Better Understanding of the Computer Vision Research Community\n  in Africa",
                "作者": " Abdul-Hakeem Omotayo,  Mai Gamal,  Eman Ehab,  Gbetondji Dovonon,  Zainab Akinjobi,  Ismaila Lukman,  Houcemeddine Turki,  Mahmod Abdien,  Idriss Tondji,  Abigail Oppong,  Yvan Pimi,  Karim Gamal,   Ro'ya-CV4Africa,  Mennatullah Siam",
                "发布日期": "2023-11-01",
                "摘要": "  Computer vision is a broad field of study that encompasses different tasks\n(e.g., object detection). Although computer vision is relevant to the African\ncommunities in various applications, yet computer vision research is\nunder-explored in the continent and constructs only 0.06% of top-tier\npublications in the last ten years. In this paper, our goal is to have a better\nunderstanding of the computer vision research conducted in Africa and provide\npointers on whether there is equity in research or not. We do this through an\nempirical analysis of the African computer vision publications that are Scopus\nindexed, where we collect around 63,000 publications over the period 2012-2022.\nWe first study the opportunities available for African institutions to publish\nin top-tier computer vision venues. We show that African publishing trends in\ntop-tier venues over the years do not exhibit consistent growth, unlike other\ncontinents such as North America or Asia. Moreover, we study all computer\nvision publications beyond top-tier venues in different African regions to find\nthat mainly Northern and Southern Africa are publishing in computer vision with\n68.5% and 15.9% of publications, resp. Nonetheless, we highlight that both\nEastern and Western Africa are exhibiting a promising increase with the last\ntwo years closing the gap with Southern Africa. Additionally, we study the\ncollaboration patterns in these publications to find that most of these exhibit\ninternational collaborations rather than African ones. We also show that most\nof these publications include an African author that is a key contributor as\nthe first or last author. Finally, we present the most recurring keywords in\ncomputer vision publications per African region.\n",
                "链接": "https://arxiv.org/abs/2305.06773"
            },
            {
                "文章ID": "33809",
                "标题": "On the evolution of research in hypersonics: application of natural\n  language processing and machine learning",
                "作者": " Ashkan Ebadi,  Alain Auger,  Yvan Gauthier",
                "发布日期": "2022-08-22",
                "摘要": "  Research and development in hypersonics have progressed significantly in\nrecent years, with various military and commercial applications being\ndemonstrated increasingly. Public and private organizations in several\ncountries have been investing in hypersonics, with the aim to overtake their\ncompetitors and secure/improve strategic advantage and deterrence. For these\norganizations, being able to identify emerging technologies in a timely and\nreliable manner is paramount. Recent advances in information technology have\nmade it possible to analyze large amounts of data, extract hidden patterns, and\nprovide decision-makers with new insights. In this study, we focus on\nscientific publications about hypersonics within the period of 2000-2020, and\nemploy natural language processing and machine learning to characterize the\nresearch landscape by identifying 12 key latent research themes and analyzing\ntheir temporal evolution. Our publication similarity analysis revealed patterns\nthat are indicative of cycles during two decades of research. The study offers\na comprehensive analysis of the research field and the fact that the research\nthemes are algorithmically extracted removes subjectivity from the exercise and\nenables consistent comparisons between topics and between time intervals.\n",
                "链接": "https://arxiv.org/abs/2208.08507"
            }
        ]
    },
    {
        "question": {
            "question": "查询近一年模型推理加速相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "111604",
                "标题": "Hierarchical Semi-Implicit Variational Inference with Application to\n  Diffusion Model Acceleration",
                "作者": " Longlin Yu,  Tianyu Xie,  Yu Zhu,  Tong Yang,  Xiangyu Zhang,  Cheng Zhang",
                "发布日期": "2023-10-27",
                "摘要": "  Semi-implicit variational inference (SIVI) has been introduced to expand the\nanalytical variational families by defining expressive semi-implicit\ndistributions in a hierarchical manner. However, the single-layer architecture\ncommonly used in current SIVI methods can be insufficient when the target\nposterior has complicated structures. In this paper, we propose hierarchical\nsemi-implicit variational inference, called HSIVI, which generalizes SIVI to\nallow more expressive multi-layer construction of semi-implicit distributions.\nBy introducing auxiliary distributions that interpolate between a simple base\ndistribution and the target distribution, the conditional layers can be trained\nby progressively matching these auxiliary distributions one layer after\nanother. Moreover, given pre-trained score networks, HSIVI can be used to\naccelerate the sampling process of diffusion models with the score matching\nobjective. We show that HSIVI significantly enhances the expressiveness of SIVI\non several Bayesian inference problems with complicated target distributions.\nWhen used for diffusion model acceleration, we show that HSIVI can produce high\nquality samples comparable to or better than the existing fast diffusion model\nbased samplers with a small number of function evaluations on various datasets.\n",
                "链接": "https://arxiv.org/abs/2310.17153"
            },
            {
                "文章ID": "124676",
                "标题": "Understanding the Potential of FPGA-Based Spatial Acceleration for Large\n  Language Model Inference",
                "作者": " Hongzheng Chen,  Jiahao Zhang,  Yixiao Du,  Shaojie Xiang,  Zichao Yue,  Niansong Zhang,  Yaohui Cai,  Zhiru Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Recent advancements in large language models (LLMs) boasting billions of\nparameters have generated a significant demand for efficient deployment in\ninference workloads. The majority of existing approaches rely on temporal\narchitectures that reuse hardware units for different network layers and\noperators. However, these methods often encounter challenges in achieving low\nlatency due to considerable memory access overhead. This paper investigates the\nfeasibility and potential of model-specific spatial acceleration for LLM\ninference on FPGAs. Our approach involves the specialization of distinct\nhardware units for specific operators or layers, facilitating direct\ncommunication between them through a dataflow architecture while minimizing\noff-chip memory accesses. We introduce a comprehensive analytical model for\nestimating the performance of a spatial LLM accelerator, taking into account\nthe on-chip compute and memory resources available on an FPGA. Through our\nanalysis, we can determine the scenarios in which FPGA-based spatial\nacceleration can outperform its GPU-based counterpart. To enable more\nproductive implementations of an LLM model on FPGAs, we further provide a\nlibrary of high-level synthesis (HLS) kernels that are composable and reusable.\nThis library will be made available as open-source. To validate the\neffectiveness of both our analytical model and HLS library, we have implemented\nBERT and GPT2 on an AMD Alveo U280 FPGA device. Experimental results\ndemonstrate our approach can achieve up to 16.1x speedup when compared to\nprevious FPGA-based accelerators for the BERT model. For GPT generative\ninference, we attain a 2.2x speedup compared to DFX, an FPGA overlay, in the\nprefill stage, while achieving a 1.9x speedup and a 5.7x improvement in energy\nefficiency compared to the NVIDIA A100 GPU in the decode stage.\n",
                "链接": "https://arxiv.org/abs/2312.15159"
            },
            {
                "文章ID": "123966",
                "标题": "Lookahead: An Inference Acceleration Framework for Large Language Model\n  with Lossless Generation Accuracy",
                "作者": " Yao Zhao,  Zhitian Xie,  Chenyi Zhuang,  Jinjie Gu",
                "发布日期": "2023-12-21",
                "摘要": "  As Large Language Models (LLMs) have made significant advancements across\nvarious tasks, such as question answering, translation, text summarization, and\ndialogue systems, the need for accuracy in information becomes crucial,\nespecially for serious financial products serving billions of users like\nAlipay. To address this, Alipay has developed a Retrieval-Augmented Generation\n(RAG) system that grounds LLMs on the most accurate and up-to-date information.\nHowever, for a real-world product serving millions of users, the inference\nspeed of LLMs becomes a critical factor compared to a mere experimental model.\n  Hence, this paper presents a generic framework for accelerating the inference\nprocess, resulting in a substantial increase in speed and cost reduction for\nour RAG system, with lossless generation accuracy. In the traditional inference\nprocess, each token is generated sequentially by the LLM, leading to a time\nconsumption proportional to the number of generated tokens. To enhance this\nprocess, our framework, named \\textit{lookahead}, introduces a\n\\textit{multi-branch} strategy. Instead of generating a single token at a time,\nwe propose a \\textit{Trie-based Retrieval} (TR) process that enables the\ngeneration of multiple branches simultaneously, each of which is a sequence of\ntokens. Subsequently, for each branch, a \\textit{Verification and Accept} (VA)\nprocess is performed to identify the longest correct sub-sequence as the final\noutput. Our strategy offers two distinct advantages: (1) it guarantees absolute\ncorrectness of the output, avoiding any approximation algorithms, and (2) the\nworst-case performance of our approach is equivalent to the conventional\nprocess. We conduct extensive experiments to demonstrate the significant\nimprovements achieved by applying our inference acceleration framework.\n",
                "链接": "https://arxiv.org/abs/2312.12728"
            },
            {
                "文章ID": "116519",
                "标题": "Exponentially Faster Language Modelling",
                "作者": " Peter Belcak,  Roger Wattenhofer",
                "发布日期": "2023-11-22",
                "摘要": "  Language models only really need to use an exponential fraction of their\nneurons for individual inferences. As proof, we present UltraFastBERT, a BERT\nvariant that uses 0.3% of its neurons during inference while performing on par\nwith similar BERT models. UltraFastBERT selectively engages just 12 out of 4095\nneurons for each layer inference. This is achieved by replacing feedforward\nnetworks with fast feedforward networks (FFFs). While no truly efficient\nimplementation currently exists to unlock the full acceleration potential of\nconditional neural execution, we provide high-level CPU code achieving 78x\nspeedup over the optimized baseline feedforward implementation, and a PyTorch\nimplementation delivering 40x speedup over the equivalent batched feedforward\ninference. We publish our training code, benchmarking setup, and model weights.\n",
                "链接": "https://arxiv.org/abs/2311.10770"
            },
            {
                "文章ID": "50323",
                "标题": "Design and Prototyping Distributed CNN Inference Acceleration in Edge\n  Computing",
                "作者": " Zhongtian Dong,  Nan Li,  Alexandros Iosifidis,  Qi Zhang",
                "发布日期": "2022-11-29",
                "摘要": "  For time-critical IoT applications using deep learning, inference\nacceleration through distributed computing is a promising approach to meet a\nstringent deadline. In this paper, we implement a working prototype of a new\ndistributed inference acceleration method HALP using three raspberry Pi 4. HALP\naccelerates inference by designing a seamless collaboration among edge devices\n(EDs) in Edge Computing. We maximize the parallelization between communication\nand computation among the collaborative EDs by optimizing the task partitioning\nratio based on the segment-based partitioning. Experimental results show that\nthe distributed inference HALP achieves 1.7x inference acceleration for VGG-16.\nThen, we combine distributed inference with conventional neural network model\ncompression by setting up different shrinking hyperparameters for MobileNet-V1.\nIn this way, we can further accelerate inference but at the cost of inference\naccuracy loss. To strike a balance between latency and accuracy, we propose\ndynamic model selection to select a model which provides the highest accuracy\nwithin the latency constraint. It is shown that the model selection with\ndistributed inference HALP can significantly improve service reliability\ncompared to the conventional stand-alone computation.\n",
                "链接": "https://arxiv.org/abs/2211.13778"
            },
            {
                "文章ID": "120589",
                "标题": "F3-Pruning: A Training-Free and Generalized Pruning Strategy towards\n  Faster and Finer Text-to-Video Synthesis",
                "作者": " Sitong Su,  Jianzhi Liu,  Lianli Gao,  Jingkuan Song",
                "发布日期": "2023-12-07",
                "摘要": "  Recently Text-to-Video (T2V) synthesis has undergone a breakthrough by\ntraining transformers or diffusion models on large-scale datasets.\nNevertheless, inferring such large models incurs huge costs.Previous inference\nacceleration works either require costly retraining or are model-specific.To\naddress this issue, instead of retraining we explore the inference process of\ntwo mainstream T2V models using transformers and diffusion models.The\nexploration reveals the redundancy in temporal attention modules of both\nmodels, which are commonly utilized to establish temporal relations among\nframes.Consequently, we propose a training-free and generalized pruning\nstrategy called F3-Pruning to prune redundant temporal attention\nweights.Specifically, when aggregate temporal attention values are ranked below\na certain ratio, corresponding weights will be pruned.Extensive experiments on\nthree datasets using a classic transformer-based model CogVideo and a typical\ndiffusion-based model Tune-A-Video verify the effectiveness of F3-Pruning in\ninference acceleration, quality assurance and broad applicability.\n",
                "链接": "https://arxiv.org/abs/2312.03459"
            },
            {
                "文章ID": "71550",
                "标题": "Inference with Reference: Lossless Acceleration of Large Language Models",
                "作者": " Nan Yang,  Tao Ge,  Liang Wang,  Binxing Jiao,  Daxin Jiang,  Linjun Yang,  Rangan Majumder,  Furu Wei",
                "发布日期": "2023-04-11",
                "摘要": "  We propose LLMA, an LLM accelerator to losslessly speed up Large Language\nModel (LLM) inference with references. LLMA is motivated by the observation\nthat there are abundant identical text spans between the decoding result by an\nLLM and the reference that is available in many real world scenarios (e.g.,\nretrieved documents). LLMA first selects a text span from the reference and\ncopies its tokens to the decoder and then efficiently checks the tokens'\nappropriateness as the decoding result in parallel within one decoding step.\nThe improved computational parallelism allows LLMA to achieve over 2x speed-up\nfor LLMs with identical generation results as greedy decoding in many practical\ngeneration scenarios where significant overlap between in-context reference and\noutputs exists (e.g., search engines and multi-turn conversations).\n",
                "链接": "https://arxiv.org/abs/2304.04487"
            },
            {
                "文章ID": "93406",
                "标题": "Scaling TransNormer to 175 Billion Parameters",
                "作者": " Zhen Qin,  Dong Li,  Weigao Sun,  Weixuan Sun,  Xuyang Shen,  Xiaodong Han,  Yunshen Wei,  Baohong Lv,  Fei Yuan,  Xiao Luo,  Yu Qiao,  Yiran Zhong",
                "发布日期": "2023-07-28",
                "摘要": "  We present TransNormerLLM, the first linear attention-based Large Language\nModel (LLM) that outperforms conventional softmax attention-based models in\nterms of both accuracy and efficiency. TransNormerLLM evolves from the previous\nlinear attention architecture TransNormer by making advanced modifications that\ninclude positional embedding, linear attention acceleration, gating mechanism,\ntensor normalization, inference acceleration and stabilization. Specifically,\nwe use LRPE together with an exponential decay to avoid attention dilution\nissues while allowing the model to retain global interactions between tokens.\nAdditionally, we propose Lightning Attention, a cutting-edge technique that\naccelerates linear attention by more than twice in runtime and reduces memory\nusage by a remarkable four times. To further enhance the performance of\nTransNormer, we leverage a gating mechanism to smooth training and a new tensor\nnormalization scheme to accelerate the model, resulting in an impressive\nacceleration of over 20%. Furthermore, we have developed a robust inference\nalgorithm that ensures numerical stability and consistent inference speed,\nregardless of the sequence length, showcasing superior efficiency during both\ntraining and inference stages. Scalability is at the heart of our model's\ndesign, enabling seamless deployment on large-scale clusters and facilitating\nexpansion to even more extensive models, all while maintaining outstanding\nperformance metrics. Rigorous validation of our model design is achieved\nthrough a series of comprehensive experiments on our self-collected corpus,\nboasting a size exceeding 6TB and containing over 2 trillion tokens. To ensure\ndata quality and relevance, we implement a new self-cleaning strategy to filter\nour collected data. Our pre-trained models will be released to foster community\nadvancements in efficient LLMs.\n",
                "链接": "https://arxiv.org/abs/2307.14995"
            },
            {
                "文章ID": "29562",
                "标题": "S4: a High-sparsity, High-performance AI Accelerator",
                "作者": " Ian En-Hsu Yen,  Zhibin Xiao,  Dongkuan Xu",
                "发布日期": "2022-07-19",
                "摘要": "  Exploiting sparsity underlying neural networks has become one of the most\npotential methodologies to reduce the memory footprint, I/O cost, and\ncomputation workloads during inference. And the degree of sparsity one can\nexploit has become higher as larger model sizes have been considered along with\nthe trend of pre-training giant models. On the other hand, compared with\nquantization that has been a widely supported option, acceleration through\nhigh-degree sparsity is not supported in most computing platforms. In this\nwork, we introduce the first commercial hardware platform supporting\nhigh-degree sparsity acceleration up to 32 times -- S4. Combined with\nstate-of-the-art sparse pruning techniques, we demonstrate several-times\npractical inference speedup on S4 over mainstream inference platforms such as\nNvidia T4. We also show that in practice a sparse model of larger size can\nachieve both higher accuracy and higher throughput on S4 than a dense model of\nsmaller size.\n",
                "链接": "https://arxiv.org/abs/2207.08006"
            },
            {
                "文章ID": "5530",
                "标题": "A Survey on Model Compression and Acceleration for Pretrained Language\n  Models",
                "作者": " Canwen Xu,  Julian McAuley",
                "发布日期": "2022-11-30",
                "摘要": "  Despite achieving state-of-the-art performance on many NLP tasks, the high\nenergy cost and long inference delay prevent Transformer-based pretrained\nlanguage models (PLMs) from seeing broader adoption including for edge and\nmobile computing. Efficient NLP research aims to comprehensively consider\ncomputation, time and carbon emission for the entire life-cycle of NLP,\nincluding data preparation, model training and inference. In this survey, we\nfocus on the inference stage and review the current state of model compression\nand acceleration for pretrained language models, including benchmarks, metrics\nand methodology.\n",
                "链接": "https://arxiv.org/abs/2202.07105"
            }
        ]
    },
    {
        "question": {
            "question": "查找论文中包含指令微调细节描述的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "4565",
                "标题": "Cyrus 2D Simulation Team Description Paper 2016",
                "作者": " Nader Zare,  Ashkan Keshavarzi,  Seyed Ehsan Beheshtian,  Hadi Mowla,  Aryan Akbarpour,  Hossein Jafari,  Keyvan Arab Baraghi,  Mohammad Amin Zarifi,  Reza Javidan",
                "发布日期": "2022-02-09",
                "摘要": "  This description includes some explanation about algorithms and also\nalgorithms that are being implemented by Cyrus team members. The objectives of\nthis description are to express a brief explanation about shoot, block, mark\nand defensive decision will be given. It also explained about the parts that\nhas been implemented. The base code that Cyrus used is agent 3.11.\n",
                "链接": "https://arxiv.org/abs/2202.03726"
            },
            {
                "文章ID": "95319",
                "标题": "Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative\n  Instructions",
                "作者": " Juncheng Li,  Kaihang Pan,  Zhiqi Ge,  Minghe Gao,  Hanwang Zhang,  Wei Ji,  Wenqiao Zhang,  Tat-Seng Chua,  Siliang Tang,  Yueting Zhuang",
                "发布日期": "2023-10-03",
                "摘要": "  Recent advancements in Multimodal Large Language Models (MLLMs) have been\nutilizing Visual Prompt Generators (VPGs) to convert visual features into\ntokens that LLMs can recognize. This is achieved by training the VPGs on\nmillions of image-caption pairs, where the VPG-generated tokens of images are\nfed into a frozen LLM to generate the corresponding captions. However, this\nimage-captioning based training objective inherently biases the VPG to\nconcentrate solely on the primary visual contents sufficient for caption\ngeneration, often neglecting other visual details. This shortcoming results in\nMLLMs' underperformance in comprehending demonstrative instructions consisting\nof multiple, interleaved, and multimodal instructions that demonstrate the\nrequired context to complete a task. To address this issue, we introduce a\ngeneric and lightweight Visual Prompt Generator Complete module (VPG-C), which\ncan infer and complete the missing details essential for comprehending\ndemonstrative instructions. Further, we propose a synthetic discriminative\ntraining strategy to fine-tune VPG-C, eliminating the need for supervised\ndemonstrative instructions. As for evaluation, we build DEMON, a comprehensive\nbenchmark for demonstrative instruction understanding. Synthetically trained\nwith the proposed strategy, VPG-C achieves significantly stronger zero-shot\nperformance across all tasks of DEMON. Further evaluation on the MME and\nOwlEval benchmarks also demonstrate the superiority of VPG-C. Our benchmark,\ncode, and pre-trained models are available at\nhttps://github.com/DCDmllm/Cheetah.\n",
                "链接": "https://arxiv.org/abs/2308.04152"
            },
            {
                "文章ID": "94225",
                "标题": "ImageBrush: Learning Visual In-Context Instructions for Exemplar-Based\n  Image Manipulation",
                "作者": " Yasheng Sun,  Yifan Yang,  Houwen Peng,  Yifei Shen,  Yuqing Yang,  Han Hu,  Lili Qiu,  Hideki Koike",
                "发布日期": "2023-08-03",
                "摘要": "  While language-guided image manipulation has made remarkable progress, the\nchallenge of how to instruct the manipulation process faithfully reflecting\nhuman intentions persists. An accurate and comprehensive description of a\nmanipulation task using natural language is laborious and sometimes even\nimpossible, primarily due to the inherent uncertainty and ambiguity present in\nlinguistic expressions. Is it feasible to accomplish image manipulation without\nresorting to external cross-modal language information? If this possibility\nexists, the inherent modality gap would be effortlessly eliminated. In this\npaper, we propose a novel manipulation methodology, dubbed ImageBrush, that\nlearns visual instructions for more accurate image editing. Our key idea is to\nemploy a pair of transformation images as visual instructions, which not only\nprecisely captures human intention but also facilitates accessibility in\nreal-world scenarios. Capturing visual instructions is particularly challenging\nbecause it involves extracting the underlying intentions solely from visual\ndemonstrations and then applying this operation to a new image. To address this\nchallenge, we formulate visual instruction learning as a diffusion-based\ninpainting problem, where the contextual information is fully exploited through\nan iterative process of generation. A visual prompting encoder is carefully\ndevised to enhance the model's capacity in uncovering human intent behind the\nvisual instructions. Extensive experiments show that our method generates\nengaging manipulation results conforming to the transformations entailed in\ndemonstrations. Moreover, our model exhibits robust generalization capabilities\non various downstream tasks such as pose transfer, image translation and video\ninpainting.\n",
                "链接": "https://arxiv.org/abs/2308.00906"
            },
            {
                "文章ID": "117252",
                "标题": "A Fine-Grained Image Description Generation Method Based on Joint\n  Objectives",
                "作者": " Yifan Zhang,  Chunzhen Lin,  Donglin Cao,  Dazhen Lin",
                "发布日期": "2023-11-23",
                "摘要": "  The goal of fine-grained image description generation techniques is to learn\ndetailed information from images and simulate human-like descriptions that\nprovide coherent and comprehensive textual details about the image content.\nCurrently, most of these methods face two main challenges: description\nrepetition and omission. Moreover, the existing evaluation metrics cannot\nclearly reflect the performance of models on these two issues. To address these\nchallenges, we propose an innovative Fine-grained Image Description Generation\nmodel based on Joint Objectives. Furthermore, we introduce new object-based\nevaluation metrics to more intuitively assess the model's performance in\nhandling description repetition and omission. This novel approach combines\nvisual features at both the image level and object level to maximize their\nadvantages and incorporates an object penalty mechanism to reduce description\nrepetition. Experimental results demonstrate that our proposed method\nsignificantly improves the CIDEr evaluation metric, indicating its excellent\nperformance in addressing description repetition and omission issues.\n",
                "链接": "https://arxiv.org/abs/2311.12799"
            },
            {
                "文章ID": "86664",
                "标题": "Instruct-NeuralTalker: Editing Audio-Driven Talking Radiance Fields with\n  Instructions",
                "作者": " Yuqi Sun,  Ruian He,  Weimin Tan,  Bo Yan",
                "发布日期": "2023-08-17",
                "摘要": "  Recent neural talking radiance field methods have shown great success in\nphotorealistic audio-driven talking face synthesis. In this paper, we propose a\nnovel interactive framework that utilizes human instructions to edit such\nimplicit neural representations to achieve real-time personalized talking face\ngeneration. Given a short speech video, we first build an efficient talking\nradiance field, and then apply the latest conditional diffusion model for image\nediting based on the given instructions and guiding implicit representation\noptimization towards the editing target. To ensure audio-lip synchronization\nduring the editing process, we propose an iterative dataset updating strategy\nand utilize a lip-edge loss to constrain changes in the lip region. We also\nintroduce a lightweight refinement network for complementing image details and\nachieving controllable detail generation in the final rendered image. Our\nmethod also enables real-time rendering at up to 30FPS on consumer hardware.\nMultiple metrics and user verification show that our approach provides a\nsignificant improvement in rendering quality compared to state-of-the-art\nmethods.\n",
                "链接": "https://arxiv.org/abs/2306.10813"
            },
            {
                "文章ID": "86358",
                "标题": "Rewriting the Script: Adapting Text Instructions for Voice Interaction",
                "作者": " Alyssa Hwang,  Natasha Oza,  Chris Callison-Burch,  Andrew Head",
                "发布日期": "2023-09-13",
                "摘要": "  Voice assistants have sharply risen in popularity in recent years, but their\nuse has been limited mostly to simple applications like music, hands-free\nsearch, or control of internet-of-things devices. What would it take for voice\nassistants to guide people through more complex tasks? In our work, we study\nthe limitations of the dominant approach voice assistants take to complex task\nguidance: reading aloud written instructions. Using recipes as an example, we\nobserve twelve participants cook at home with a state-of-the-art voice\nassistant. We learn that the current approach leads to nine challenges,\nincluding obscuring the bigger picture, overwhelming users with too much\ninformation, and failing to communicate affordances. Instructions delivered by\na voice assistant are especially difficult because they cannot be skimmed as\neasily as written instructions. Alexa in particular did not surface crucial\ndetails to the user or answer questions well. We draw on our observations to\npropose eight ways in which voice assistants can ``rewrite the script'' --\nsummarizing, signposting, splitting, elaborating, volunteering, reordering,\nredistributing, and visualizing -- to transform written sources into forms that\nare readily communicated through spoken conversation. We conclude with a vision\nof how modern advancements in natural language processing can be leveraged for\nintelligent agents to guide users effectively through complex tasks.\n",
                "链接": "https://arxiv.org/abs/2306.09992"
            },
            {
                "文章ID": "77521",
                "标题": "Edit As You Wish: Video Description Editing with Multi-grained Commands",
                "作者": " Linli Yao,  Yuanmeng Zhang,  Ziheng Wang,  Xinglin Hou,  Tiezheng Ge,  Yuning Jiang,  Qin Jin",
                "发布日期": "2023-05-16",
                "摘要": "  Automatically narrating a video with natural language can assist people in\ngrasping and managing massive videos on the Internet. From the perspective of\nvideo uploaders, they may have varied preferences for writing the desired video\ndescription to attract more potential followers, e.g. catching customers'\nattention for product videos. The Controllable Video Captioning task is\ntherefore proposed to generate a description conditioned on the user demand and\nvideo content. However, existing works suffer from two shortcomings: 1) the\ncontrol signal is fixed and can only express single-grained control; 2) the\nvideo description can not be further edited to meet dynamic user demands. In\nthis paper, we propose a novel Video Description Editing (VDEdit) task to\nautomatically revise an existing video description guided by flexible user\nrequests. Inspired by human writing-revision habits, we design the user command\nas a {operation, position, attribute} triplet to cover multi-grained use\nrequirements, which can express coarse-grained control (e.g. expand the\ndescription) as well as fine-grained control (e.g. add specified details in\nspecified position) in a unified format. To facilitate the VDEdit task, we\nfirst automatically construct a large-scale benchmark dataset namely VATEX-EDIT\nin the open domain describing diverse human activities. Considering the\nreal-life application scenario, we further manually collect an e-commerce\nbenchmark dataset called EMMAD-EDIT. We propose a unified framework to convert\nthe {operation, position, attribute} triplet into a textual control sequence to\nhandle multi-grained editing commands. For VDEdit evaluation, we adopt\ncomprehensive metrics to measure three aspects of model performance, including\ncaption quality, caption-command consistency, and caption-video alignment.\n",
                "链接": "https://arxiv.org/abs/2305.08389"
            },
            {
                "文章ID": "120991",
                "标题": "Generating Illustrated Instructions",
                "作者": " Sachit Menon,  Ishan Misra,  Rohit Girdhar",
                "发布日期": "2023-12-08",
                "摘要": "  We introduce the new task of generating Illustrated Instructions, i.e.,\nvisual instructions customized to a user's needs. We identify desiderata unique\nto this task, and formalize it through a suite of automatic and human\nevaluation metrics, designed to measure the validity, consistency, and efficacy\nof the generations. We combine the power of large language models (LLMs)\ntogether with strong text-to-image generation diffusion models to propose a\nsimple approach called StackedDiffusion, which generates such illustrated\ninstructions given text as input. The resulting model strongly outperforms\nbaseline approaches and state-of-the-art multimodal LLMs; and in 30% of cases,\nusers even prefer it to human-generated articles. Most notably, it enables\nvarious new and exciting applications far beyond what static articles on the\nweb can provide, such as personalized instructions complete with intermediate\nsteps and pictures in response to a user's individual situation.\n",
                "链接": "https://arxiv.org/abs/2312.04552"
            },
            {
                "文章ID": "18422",
                "标题": "Learning 6-DoF Object Poses to Grasp Category-level Objects by Language\n  Instructions",
                "作者": " Chilam Cheang,  Haitao Lin,  Yanwei Fu,  Xiangyang Xue",
                "发布日期": "2022-05-10",
                "摘要": "  This paper studies the task of any objects grasping from the known categories\nby free-form language instructions. This task demands the technique in computer\nvision, natural language processing, and robotics. We bring these disciplines\ntogether on this open challenge, which is essential to human-robot interaction.\nCritically, the key challenge lies in inferring the category of objects from\nlinguistic instructions and accurately estimating the 6-DoF information of\nunseen objects from the known classes. In contrast, previous works focus on\ninferring the pose of object candidates at the instance level. This\nsignificantly limits its applications in real-world scenarios.In this paper, we\npropose a language-guided 6-DoF category-level object localization model to\nachieve robotic grasping by comprehending human intention. To this end, we\npropose a novel two-stage method. Particularly, the first stage grounds the\ntarget in the RGB image through language description of names, attributes, and\nspatial relations of objects. The second stage extracts and segments point\nclouds from the cropped depth image and estimates the full 6-DoF object pose at\ncategory-level. Under such a manner, our approach can locate the specific\nobject by following human instructions, and estimate the full 6-DoF pose of a\ncategory-known but unseen instance which is not utilized for training the\nmodel. Extensive experimental results show that our method is competitive with\nthe state-of-the-art language-conditioned grasp method. Importantly, we deploy\nour approach on a physical robot to validate the usability of our framework in\nreal-world applications. Please refer to the supplementary for the demo videos\nof our robot experiments.\n",
                "链接": "https://arxiv.org/abs/2205.04028"
            },
            {
                "文章ID": "48856",
                "标题": "Task-aware Retrieval with Instructions",
                "作者": " Akari Asai,  Timo Schick,  Patrick Lewis,  Xilun Chen,  Gautier Izacard,  Sebastian Riedel,  Hannaneh Hajishirzi,  Wen-tau Yih",
                "发布日期": "2022-12-21",
                "摘要": "  We study the problem of retrieval with instructions, where users of a\nretrieval system explicitly describe their intent along with their queries. We\naim to develop a general-purpose task-aware retrieval system using multi-task\ninstruction tuning, which can follow human-written instructions to find the\nbest documents for a given query. We introduce the first large-scale collection\nof approximately 40 retrieval datasets with instructions, BERRI, and present\nTART, a multi-task retrieval system trained on BERRI with instructions. TART\nshows strong capabilities to adapt to a new retrieval task via instructions and\nadvances the state of the art on two zero-shot retrieval benchmarks, BEIR and\nLOTTE, outperforming models up to three times larger. We further introduce a\nnew evaluation setup, X^2-Retrieval to better reflect real-world scenarios,\nwhere diverse domains and tasks are pooled and a system needs to find documents\naligning users' intents. In this setup, TART significantly outperforms\ncompetitive baselines, further demonstrating the effectiveness of guiding\nretrieval with instructions.\n",
                "链接": "https://arxiv.org/abs/2211.09260"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本检测最新进展",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "100439",
                "标题": "STEP -- Towards Structured Scene-Text Spotting",
                "作者": " Sergi Garcia-Bordils,  Dimosthenis Karatzas,  Marçal Rusiñol",
                "发布日期": "2023-12-12",
                "摘要": "  We introduce the structured scene-text spotting task, which requires a\nscene-text OCR system to spot text in the wild according to a query regular\nexpression. Contrary to generic scene text OCR, structured scene-text spotting\nseeks to dynamically condition both scene text detection and recognition on\nuser-provided regular expressions. To tackle this task, we propose the\nStructured TExt sPotter (STEP), a model that exploits the provided text\nstructure to guide the OCR process. STEP is able to deal with regular\nexpressions that contain spaces and it is not bound to detection at the\nword-level granularity. Our approach enables accurate zero-shot structured text\nspotting in a wide variety of real-world reading scenarios and is solely\ntrained on publicly available data. To demonstrate the effectiveness of our\napproach, we introduce a new challenging test dataset that contains several\ntypes of out-of-vocabulary structured text, reflecting important reading\napplications of fields such as prices, dates, serial numbers, license plates\netc. We demonstrate that STEP can provide specialised OCR performance on demand\nin all tested scenarios.\n",
                "链接": "https://arxiv.org/abs/2309.02356"
            },
            {
                "文章ID": "49513",
                "标题": "Intelligent Computing: The Latest Advances, Challenges and Future",
                "作者": " Shiqiang Zhu,  Ting Yu,  Tao Xu,  Hongyang Chen,  Schahram Dustdar,  Sylvain Gigan,  Deniz Gunduz,  Ekram Hossain,  Yaochu Jin,  Feng Lin,  Bo Liu,  Zhiguo Wan,  Ji Zhang,  Zhifeng Zhao,  Wentao Zhu,  Zuoning Chen,  Tariq Durrani,  Huaimin Wang,  Jiangxing Wu,  Tongyi Zhang,  Yunhe Pan",
                "发布日期": "2022-11-22",
                "摘要": "  Computing is a critical driving force in the development of human\ncivilization. In recent years, we have witnessed the emergence of intelligent\ncomputing, a new computing paradigm that is reshaping traditional computing and\npromoting digital revolution in the era of big data, artificial intelligence\nand internet-of-things with new computing theories, architectures, methods,\nsystems, and applications. Intelligent computing has greatly broadened the\nscope of computing, extending it from traditional computing on data to\nincreasingly diverse computing paradigms such as perceptual intelligence,\ncognitive intelligence, autonomous intelligence, and human-computer fusion\nintelligence. Intelligence and computing have undergone paths of different\nevolution and development for a long time but have become increasingly\nintertwined in recent years: intelligent computing is not only\nintelligence-oriented but also intelligence-driven. Such cross-fertilization\nhas prompted the emergence and rapid advancement of intelligent computing.\nIntelligent computing is still in its infancy and an abundance of innovations\nin the theories, systems, and applications of intelligent computing are\nexpected to occur soon. We present the first comprehensive survey of literature\non intelligent computing, covering its theory fundamentals, the technological\nfusion of intelligence and computing, important applications, challenges, and\nfuture perspectives. We believe that this survey is highly timely and will\nprovide a comprehensive reference and cast valuable insights into intelligent\ncomputing for academic and industrial researchers and practitioners.\n",
                "链接": "https://arxiv.org/abs/2211.11281"
            },
            {
                "文章ID": "53136",
                "标题": "Extending TrOCR for Text Localization-Free OCR of Full-Page Scanned\n  Receipt Images",
                "作者": " Hongkuan Zhang,  Edward Whittaker,  Ikuo Kitagishi",
                "发布日期": "2023-10-17",
                "摘要": "  Digitization of scanned receipts aims to extract text from receipt images and\nsave it into structured documents. This is usually split into two sub-tasks:\ntext localization and optical character recognition (OCR). Most existing OCR\nmodels only focus on the cropped text instance images, which require the\nbounding box information provided by a text region detection model. Introducing\nan additional detector to identify the text instance images in advance adds\ncomplexity, however instance-level OCR models have very low accuracy when\nprocessing the whole image for the document-level OCR, such as receipt images\ncontaining multiple text lines arranged in various layouts. To this end, we\npropose a localization-free document-level OCR model for transcribing all the\ncharacters in a receipt image into an ordered sequence end-to-end.\nSpecifically, we finetune the pretrained instance-level model TrOCR with\nrandomly cropped image chunks, and gradually increase the image chunk size to\ngeneralize the recognition ability from instance images to full-page images. In\nour experiments on the SROIE receipt OCR dataset, the model finetuned with our\nstrategy achieved 64.4 F1-score and a 22.8% character error rate (CER),\nrespectively, which outperforms the baseline results with 48.5 F1-score and\n50.6% CER. The best model, which splits the full image into 15 equally sized\nchunks, gives 87.8 F1-score and 4.98% CER with minimal additional pre or\npost-processing of the output. Moreover, the characters in the generated\ndocument-level sequences are arranged in the reading order, which is practical\nfor real-world applications.\n",
                "链接": "https://arxiv.org/abs/2212.05525"
            },
            {
                "文章ID": "55598",
                "标题": "A Comprehensive Gold Standard and Benchmark for Comics Text Detection\n  and Recognition",
                "作者": " Gürkan Soykan,  Deniz Yuret,  Tevfik Metin Sezgin",
                "发布日期": "2023-01-02",
                "摘要": "  This study focuses on improving the optical character recognition (OCR) data\nfor panels in the COMICS dataset, the largest dataset containing text and\nimages from comic books. To do this, we developed a pipeline for OCR processing\nand labeling of comic books and created the first text detection and\nrecognition datasets for western comics, called \"COMICS Text+: Detection\" and\n\"COMICS Text+: Recognition\". We evaluated the performance of state-of-the-art\ntext detection and recognition models on these datasets and found significant\nimprovement in word accuracy and normalized edit distance compared to the text\nin COMICS. We also created a new dataset called \"COMICS Text+\", which contains\nthe extracted text from the textboxes in the COMICS dataset. Using the improved\ntext data of COMICS Text+ in the comics processing model from resulted in\nstate-of-the-art performance on cloze-style tasks without changing the model\narchitecture. The COMICS Text+ dataset can be a valuable resource for\nresearchers working on tasks including text detection, recognition, and\nhigh-level processing of comics, such as narrative understanding, character\nrelations, and story generation. All the data and inference instructions can be\naccessed in https://github.com/gsoykan/comics_text_plus.\n",
                "链接": "https://arxiv.org/abs/2212.14674"
            },
            {
                "文章ID": "23281",
                "标题": "PP-OCRv3: More Attempts for the Improvement of Ultra Lightweight OCR\n  System",
                "作者": " Chenxia Li,  Weiwei Liu,  Ruoyu Guo,  Xiaoting Yin,  Kaitao Jiang,  Yongkun Du,  Yuning Du,  Lingfeng Zhu,  Baohua Lai,  Xiaoguang Hu,  Dianhai Yu,  Yanjun Ma",
                "发布日期": "2022-06-15",
                "摘要": "  Optical character recognition (OCR) technology has been widely used in\nvarious scenes, as shown in Figure 1. Designing a practical OCR system is still\na meaningful but challenging task. In previous work, considering the efficiency\nand accuracy, we proposed a practical ultra lightweight OCR system (PP-OCR),\nand an optimized version PP-OCRv2. In order to further improve the performance\nof PP-OCRv2, a more robust OCR system PP-OCRv3 is proposed in this paper.\nPP-OCRv3 upgrades the text detection model and text recognition model in 9\naspects based on PP-OCRv2. For text detector, we introduce a PAN module with\nlarge receptive field named LK-PAN, a FPN module with residual attention\nmechanism named RSE-FPN, and DML distillation strategy. For text recognizer,\nthe base model is replaced from CRNN to SVTR, and we introduce lightweight text\nrecognition network SVTR LCNet, guided training of CTC by attention, data\naugmentation strategy TextConAug, better pre-trained model by self-supervised\nTextRotNet, UDML, and UIM to accelerate the model and improve the effect.\nExperiments on real data show that the hmean of PP-OCRv3 is 5% higher than\nPP-OCRv2 under comparable inference speed. All the above mentioned models are\nopen-sourced and the code is available in the GitHub repository PaddleOCR which\nis powered by PaddlePaddle.\n",
                "链接": "https://arxiv.org/abs/2206.03001"
            },
            {
                "文章ID": "120332",
                "标题": "UPOCR: Towards Unified Pixel-Level OCR Interface",
                "作者": " Dezhi Peng,  Zhenhua Yang,  Jiaxin Zhang,  Chongyu Liu,  Yongxin Shi,  Kai Ding,  Fengjun Guo,  Lianwen Jin",
                "发布日期": "2023-12-06",
                "摘要": "  In recent years, the optical character recognition (OCR) field has been\nproliferating with plentiful cutting-edge approaches for a wide spectrum of\ntasks. However, these approaches are task-specifically designed with divergent\nparadigms, architectures, and training strategies, which significantly\nincreases the complexity of research and maintenance and hinders the fast\ndeployment in applications. To this end, we propose UPOCR, a\nsimple-yet-effective generalist model for Unified Pixel-level OCR interface.\nSpecifically, the UPOCR unifies the paradigm of diverse OCR tasks as\nimage-to-image transformation and the architecture as a vision Transformer\n(ViT)-based encoder-decoder. Learnable task prompts are introduced to push the\ngeneral feature representations extracted by the encoder toward task-specific\nspaces, endowing the decoder with task awareness. Moreover, the model training\nis uniformly aimed at minimizing the discrepancy between the generated and\nground-truth images regardless of the inhomogeneity among tasks. Experiments\nare conducted on three pixel-level OCR tasks including text removal, text\nsegmentation, and tampered text detection. Without bells and whistles, the\nexperimental results showcase that the proposed method can simultaneously\nachieve state-of-the-art performance on three tasks with a unified single\nmodel, which provides valuable strategies and insights for future research on\ngeneralist OCR models. Code will be publicly available.\n",
                "链接": "https://arxiv.org/abs/2312.02694"
            },
            {
                "文章ID": "8287",
                "标题": "DiT: Self-supervised Pre-training for Document Image Transformer",
                "作者": " Junlong Li,  Yiheng Xu,  Tengchao Lv,  Lei Cui,  Cha Zhang,  Furu Wei",
                "发布日期": "2022-07-20",
                "摘要": "  Image Transformer has recently achieved significant progress for natural\nimage understanding, either using supervised (ViT, DeiT, etc.) or\nself-supervised (BEiT, MAE, etc.) pre-training techniques. In this paper, we\npropose \\textbf{DiT}, a self-supervised pre-trained \\textbf{D}ocument\n\\textbf{I}mage \\textbf{T}ransformer model using large-scale unlabeled text\nimages for Document AI tasks, which is essential since no supervised\ncounterparts ever exist due to the lack of human-labeled document images. We\nleverage DiT as the backbone network in a variety of vision-based Document AI\ntasks, including document image classification, document layout analysis, table\ndetection as well as text detection for OCR. Experiment results have\nillustrated that the self-supervised pre-trained DiT model achieves new\nstate-of-the-art results on these downstream tasks, e.g. document image\nclassification (91.11 $\\rightarrow$ 92.69), document layout analysis (91.0\n$\\rightarrow$ 94.9), table detection (94.23 $\\rightarrow$ 96.55) and text\ndetection for OCR (93.07 $\\rightarrow$ 94.29). The code and pre-trained models\nare publicly available at \\url{https://aka.ms/msdit}.\n",
                "链接": "https://arxiv.org/abs/2203.02378"
            },
            {
                "文章ID": "77918",
                "标题": "Mobile User Interface Element Detection Via Adaptively Prompt Tuning",
                "作者": " Zhangxuan Gu,  Zhuoer Xu,  Haoxing Chen,  Jun Lan,  Changhua Meng,  Weiqiang Wang",
                "发布日期": "2023-05-18",
                "摘要": "  Recent object detection approaches rely on pretrained vision-language models\nfor image-text alignment. However, they fail to detect the Mobile User\nInterface (MUI) element since it contains additional OCR information, which\ndescribes its content and function but is often ignored. In this paper, we\ndevelop a new MUI element detection dataset named MUI-zh and propose an\nAdaptively Prompt Tuning (APT) module to take advantage of discriminating OCR\ninformation. APT is a lightweight and effective module to jointly optimize\ncategory prompts across different modalities. For every element, APT uniformly\nencodes its visual features and OCR descriptions to dynamically adjust the\nrepresentation of frozen category prompts. We evaluate the effectiveness of our\nplug-and-play APT upon several existing CLIP-based detectors for both standard\nand open-vocabulary MUI element detection. Extensive experiments show that our\nmethod achieves considerable improvements on two datasets. The datasets is\navailable at \\url{github.com/antmachineintelligence/MUI-zh}.\n",
                "链接": "https://arxiv.org/abs/2305.09699"
            },
            {
                "文章ID": "30789",
                "标题": "Optimal Boxes: Boosting End-to-End Scene Text Recognition by Adjusting\n  Annotated Bounding Boxes via Reinforcement Learning",
                "作者": " Jingqun Tang,  Wenming Qian,  Luchuan Song,  Xiena Dong,  Lan Li,  Xiang Bai",
                "发布日期": "2022-07-27",
                "摘要": "  Text detection and recognition are essential components of a modern OCR\nsystem. Most OCR approaches attempt to obtain accurate bounding boxes of text\nat the detection stage, which is used as the input of the text recognition\nstage. We observe that when using tight text bounding boxes as input, a text\nrecognizer frequently fails to achieve optimal performance due to the\ninconsistency between bounding boxes and deep representations of text\nrecognition. In this paper, we propose Box Adjuster, a reinforcement\nlearning-based method for adjusting the shape of each text bounding box to make\nit more compatible with text recognition models. Additionally, when dealing\nwith cross-domain problems such as synthetic-to-real, the proposed method\nsignificantly reduces mismatches in domain distribution between the source and\ntarget domains. Experiments demonstrate that the performance of end-to-end text\nrecognition systems can be improved when using the adjusted bounding boxes as\nthe ground truths for training. Specifically, on several benchmark datasets for\nscene text understanding, the proposed method outperforms state-of-the-art text\nspotters by an average of 2.0% F-Score on end-to-end text recognition tasks and\n4.6% F-Score on domain adaptation tasks.\n",
                "链接": "https://arxiv.org/abs/2207.11934"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本识别最新进展。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "90438",
                "标题": "Handwritten Text Recognition Using Convolutional Neural Network",
                "作者": " Atman Mishra,  A. Sharath Ram,  Kavyashree C",
                "发布日期": "2023-07-12",
                "摘要": "  OCR (Optical Character Recognition) is a technology that offers comprehensive\nalphanumeric recognition of handwritten and printed characters at electronic\nspeed by merely scanning the document. Recently, the understanding of visual\ndata has been termed Intelligent Character Recognition (ICR). Intelligent\nCharacter Recognition (ICR) is the OCR module that can convert scans of\nhandwritten or printed characters into ASCII text. ASCII data is the standard\nformat for data encoding in electronic communication. ASCII assigns standard\nnumeric values to letters, numeral, symbols, white-spaces and other characters.\nIn more technical terms, OCR is the process of using an electronic device to\ntransform 2-Dimensional textual information into machine-encoded text. Anything\nthat contains text both machine written or handwritten can be scanned either\nthrough a scanner or just simply a picture of the text is enough for the\nrecognition system to distinguish the text. The goal of this papers is to show\nthe results of a Convolutional Neural Network model which has been trained on\nNational Institute of Science and Technology (NIST) dataset containing over a\n100,000 images. The network learns from the features extracted from the images\nand use it to generate the probability of each class to which the picture\nbelongs to. We have achieved an accuracy of 90.54% with a loss of 2.53%.\n",
                "链接": "https://arxiv.org/abs/2307.05396"
            },
            {
                "文章ID": "98478",
                "标题": "DISGO: Automatic End-to-End Evaluation for Scene Text OCR",
                "作者": " Mei-Yuh Hwang,  Yangyang Shi,  Ankit Ramchandani,  Guan Pang,  Praveen Krishnan,  Lucas Kabela,  Frank Seide,  Samyak Datta,  Jun Liu",
                "发布日期": "2023-08-28",
                "摘要": "  This paper discusses the challenges of optical character recognition (OCR) on\nnatural scenes, which is harder than OCR on documents due to the wild content\nand various image backgrounds. We propose to uniformly use word error rates\n(WER) as a new measurement for evaluating scene-text OCR, both end-to-end (e2e)\nperformance and individual system component performances. Particularly for the\ne2e metric, we name it DISGO WER as it considers Deletion, Insertion,\nSubstitution, and Grouping/Ordering errors. Finally we propose to utilize the\nconcept of super blocks to automatically compute BLEU scores for e2e OCR\nmachine translation. The small SCUT public test set is used to demonstrate WER\nperformance by a modularized OCR system.\n",
                "链接": "https://arxiv.org/abs/2308.13173"
            },
            {
                "文章ID": "43946",
                "标题": "OCR-VQGAN: Taming Text-within-Image Generation",
                "作者": " Juan A. Rodriguez,  David Vazquez,  Issam Laradji,  Marco Pedersoli,  Pau Rodriguez",
                "发布日期": "2022-10-26",
                "摘要": "  Synthetic image generation has recently experienced significant improvements\nin domains such as natural image or art generation. However, the problem of\nfigure and diagram generation remains unexplored. A challenging aspect of\ngenerating figures and diagrams is effectively rendering readable texts within\nthe images. To alleviate this problem, we present OCR-VQGAN, an image encoder,\nand decoder that leverages OCR pre-trained features to optimize a text\nperceptual loss, encouraging the architecture to preserve high-fidelity text\nand diagram structure. To explore our approach, we introduce the Paper2Fig100k\ndataset, with over 100k images of figures and texts from research papers. The\nfigures show architecture diagrams and methodologies of articles available at\narXiv.org from fields like artificial intelligence and computer vision. Figures\nusually include text and discrete objects, e.g., boxes in a diagram, with lines\nand arrows that connect them. We demonstrate the effectiveness of OCR-VQGAN by\nconducting several experiments on the task of figure reconstruction.\nAdditionally, we explore the qualitative and quantitative impact of weighting\ndifferent perceptual metrics in the overall loss function. We release code,\nmodels, and dataset at https://github.com/joanrod/ocr-vqgan.\n",
                "链接": "https://arxiv.org/abs/2210.11248"
            },
            {
                "文章ID": "54214",
                "标题": "Transferring General Multimodal Pretrained Models to Text Recognition",
                "作者": " Junyang Lin,  Xuancheng Ren,  Yichang Zhang,  Gao Liu,  Peng Wang,  An Yang,  Chang Zhou",
                "发布日期": "2022-12-20",
                "摘要": "  This paper proposes a new method, OFA-OCR, to transfer multimodal pretrained\nmodels to text recognition. Specifically, we recast text recognition as image\ncaptioning and directly transfer a unified vision-language pretrained model to\nthe end task. Without pretraining on large-scale annotated or synthetic text\nrecognition data, OFA-OCR outperforms the baselines and achieves\nstate-of-the-art performance in the Chinese text recognition benchmark.\nAdditionally, we construct an OCR pipeline with OFA-OCR, and we demonstrate\nthat it can achieve competitive performance with the product-level API. The\ncode (https://github.com/OFA-Sys/OFA) and demo\n(https://modelscope.cn/studios/damo/ofa_ocr_pipeline/summary) are publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2212.09297"
            },
            {
                "文章ID": "53136",
                "标题": "Extending TrOCR for Text Localization-Free OCR of Full-Page Scanned\n  Receipt Images",
                "作者": " Hongkuan Zhang,  Edward Whittaker,  Ikuo Kitagishi",
                "发布日期": "2023-10-17",
                "摘要": "  Digitization of scanned receipts aims to extract text from receipt images and\nsave it into structured documents. This is usually split into two sub-tasks:\ntext localization and optical character recognition (OCR). Most existing OCR\nmodels only focus on the cropped text instance images, which require the\nbounding box information provided by a text region detection model. Introducing\nan additional detector to identify the text instance images in advance adds\ncomplexity, however instance-level OCR models have very low accuracy when\nprocessing the whole image for the document-level OCR, such as receipt images\ncontaining multiple text lines arranged in various layouts. To this end, we\npropose a localization-free document-level OCR model for transcribing all the\ncharacters in a receipt image into an ordered sequence end-to-end.\nSpecifically, we finetune the pretrained instance-level model TrOCR with\nrandomly cropped image chunks, and gradually increase the image chunk size to\ngeneralize the recognition ability from instance images to full-page images. In\nour experiments on the SROIE receipt OCR dataset, the model finetuned with our\nstrategy achieved 64.4 F1-score and a 22.8% character error rate (CER),\nrespectively, which outperforms the baseline results with 48.5 F1-score and\n50.6% CER. The best model, which splits the full image into 15 equally sized\nchunks, gives 87.8 F1-score and 4.98% CER with minimal additional pre or\npost-processing of the output. Moreover, the characters in the generated\ndocument-level sequences are arranged in the reading order, which is practical\nfor real-world applications.\n",
                "链接": "https://arxiv.org/abs/2212.05525"
            },
            {
                "文章ID": "94665",
                "标题": "Universal Defensive Underpainting Patch: Making Your Text Invisible to\n  Optical Character Recognition",
                "作者": " JiaCheng Deng,  Li Dong,  Jiahao Chen,  Diqun Yan,  Rangding Wang,  Dengpan Ye,  Lingchen Zhao,  Jinyu Tian",
                "发布日期": "2023-08-07",
                "摘要": "  Optical Character Recognition (OCR) enables automatic text extraction from\nscanned or digitized text images, but it also makes it easy to pirate valuable\nor sensitive text from these images. Previous methods to prevent OCR piracy by\ndistorting characters in text images are impractical in real-world scenarios,\nas pirates can capture arbitrary portions of the text images, rendering the\ndefenses ineffective. In this work, we propose a novel and effective defense\nmechanism termed the Universal Defensive Underpainting Patch (UDUP) that\nmodifies the underpainting of text images instead of the characters. UDUP is\ncreated through an iterative optimization process to craft a small, fixed-size\ndefensive patch that can generate non-overlapping underpainting for text images\nof any size. Experimental results show that UDUP effectively defends against\nunauthorized OCR under the setting of any screenshot range or complex image\nbackground. It is agnostic to the content, size, colors, and languages of\ncharacters, and is robust to typical image operations such as scaling and\ncompressing. In addition, the transferability of UDUP is demonstrated by\nevading several off-the-shelf OCRs. The code is available at\nhttps://github.com/QRICKDD/UDUP.\n",
                "链接": "https://arxiv.org/abs/2308.02369"
            },
            {
                "文章ID": "89132",
                "标题": "Estimating Post-OCR Denoising Complexity on Numerical Texts",
                "作者": " Arthur Hemmer,  Jérôme Brachat,  Mickaël Coustaty,  Jean-Marc Ogier",
                "发布日期": "2023-07-04",
                "摘要": "  Post-OCR processing has significantly improved over the past few years.\nHowever, these have been primarily beneficial for texts consisting of natural,\nalphabetical words, as opposed to documents of numerical nature such as\ninvoices, payslips, medical certificates, etc. To evaluate the OCR\npost-processing difficulty of these datasets, we propose a method to estimate\nthe denoising complexity of a text and evaluate it on several datasets of\nvarying nature, and show that texts of numerical nature have a significant\ndisadvantage. We evaluate the estimated complexity ranking with respect to the\nerror rates of modern-day denoising approaches to show the validity of our\nestimator.\n",
                "链接": "https://arxiv.org/abs/2307.01020"
            },
            {
                "文章ID": "36483",
                "标题": "Multi-Granularity Prediction for Scene Text Recognition",
                "作者": " Peng Wang,  Cheng Da,  Cong Yao",
                "发布日期": "2022-10-18",
                "摘要": "  Scene text recognition (STR) has been an active research topic in computer\nvision for years. To tackle this challenging problem, numerous innovative\nmethods have been successively proposed and incorporating linguistic knowledge\ninto STR models has recently become a prominent trend. In this work, we first\ndraw inspiration from the recent progress in Vision Transformer (ViT) to\nconstruct a conceptually simple yet powerful vision STR model, which is built\nupon ViT and outperforms previous state-of-the-art models for scene text\nrecognition, including both pure vision models and language-augmented methods.\nTo integrate linguistic knowledge, we further propose a Multi-Granularity\nPrediction strategy to inject information from the language modality into the\nmodel in an implicit way, i.e. , subword representations (BPE and WordPiece)\nwidely-used in NLP are introduced into the output space, in addition to the\nconventional character level representation, while no independent language\nmodel (LM) is adopted. The resultant algorithm (termed MGP-STR) is able to push\nthe performance envelop of STR to an even higher level. Specifically, it\nachieves an average recognition accuracy of 93.35% on standard benchmarks. Code\nis available at\nhttps://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/MGP-STR.\n",
                "链接": "https://arxiv.org/abs/2209.03592"
            },
            {
                "文章ID": "11473",
                "标题": "Towards Escaping from Language Bias and OCR Error: Semantics-Centered\n  Text Visual Question Answering",
                "作者": " Chengyang Fang,  Gangyan Zeng,  Yu Zhou,  Daiqing Wu,  Can Ma,  Dayong Hu,  Weiping Wang",
                "发布日期": "2023-09-06",
                "摘要": "  Texts in scene images convey critical information for scene understanding and\nreasoning. The abilities of reading and reasoning matter for the model in the\ntext-based visual question answering (TextVQA) process. However, current\nTextVQA models do not center on the text and suffer from several limitations.\nThe model is easily dominated by language biases and optical character\nrecognition (OCR) errors due to the absence of semantic guidance in the answer\nprediction process. In this paper, we propose a novel Semantics-Centered\nNetwork (SC-Net) that consists of an instance-level contrastive semantic\nprediction module (ICSP) and a semantics-centered transformer module (SCT).\nEquipped with the two modules, the semantics-centered model can resist the\nlanguage biases and the accumulated errors from OCR. Extensive experiments on\nTextVQA and ST-VQA datasets show the effectiveness of our model. SC-Net\nsurpasses previous works with a noticeable margin and is more reasonable for\nthe TextVQA task.\n",
                "链接": "https://arxiv.org/abs/2203.12929"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态优化训练方式的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "30973",
                "标题": "Large-displacement 3D Object Tracking with Hybrid Non-local Optimization",
                "作者": " Xuhui Tian,  Xinran Lin,  Fan Zhong,  Xueying Qin",
                "发布日期": "2022-07-27",
                "摘要": "  Optimization-based 3D object tracking is known to be precise and fast, but\nsensitive to large inter-frame displacements. In this paper we propose a fast\nand effective non-local 3D tracking method. Based on the observation that\nerroneous local minimum are mostly due to the out-of-plane rotation, we propose\na hybrid approach combining non-local and local optimizations for different\nparameters, resulting in efficient non-local search in the 6D pose space. In\naddition, a precomputed robust contour-based tracking method is proposed for\nthe pose optimization. By using long search lines with multiple candidate\ncorrespondences, it can adapt to different frame displacements without the need\nof coarse-to-fine search. After the pre-computation, pose updates can be\nconducted very fast, enabling the non-local optimization to run in real time.\nOur method outperforms all previous methods for both small and large\ndisplacements. For large displacements, the accuracy is greatly improved\n($81.7\\% \\;\\text{v.s.}\\; 19.4\\%$). At the same time, real-time speed ($>$50fps)\ncan be achieved with only CPU. The source code is available at\n\\url{https://github.com/cvbubbles/nonlocal-3dtracking}.\n",
                "链接": "https://arxiv.org/abs/2207.12620"
            },
            {
                "文章ID": "28619",
                "标题": "A Late Fusion Framework with Multiple Optimization Methods for Media\n  Interestingness",
                "作者": " Maria Shoukat,  Khubaib Ahmad,  Naina Said,  Nasir Ahmad,  Mohammed Hassanuzaman,  Kashif Ahmad",
                "发布日期": "2022-07-12",
                "摘要": "  The recent advancement in Multimedia Analytical, Computer Vision (CV), and\nArtificial Intelligence (AI) algorithms resulted in several interesting tools\nallowing an automatic analysis and retrieval of multimedia content of users'\ninterests. However, retrieving the content of interest generally involves\nanalysis and extraction of semantic features, such as emotions and\ninterestingness-level. The extraction of such meaningful information is a\ncomplex task and generally, the performance of individual algorithms is very\nlow. One way to enhance the performance of the individual algorithms is to\ncombine the predictive capabilities of multiple algorithms using fusion\nschemes. This allows the individual algorithms to complement each other,\nleading to improved performance. This paper proposes several fusion methods for\nthe media interestingness score prediction task introduced in CLEF Fusion 2022.\nThe proposed methods include both a naive fusion scheme, where all the inducers\nare treated equally and a merit-based fusion scheme where multiple weight\noptimization methods are employed to assign weights to the individual inducers.\nIn total, we used six optimization methods including a Particle Swarm\nOptimization (PSO), a Genetic Algorithm (GA), Nelder Mead, Trust Region\nConstrained (TRC), and Limited-memory Broyden Fletcher Goldfarb Shanno\nAlgorithm (LBFGSA), and Truncated Newton Algorithm (TNA). Overall better\nresults are obtained with PSO and TNA achieving 0.109 mean average precision at\n10. The task is complex and generally, scores are low. We believe the presented\nanalysis will provide a baseline for future research in the domain.\n",
                "链接": "https://arxiv.org/abs/2207.04762"
            },
            {
                "文章ID": "61822",
                "标题": "Slapo: A Schedule Language for Progressive Optimization of Large Deep\n  Learning Model Training",
                "作者": " Hongzheng Chen,  Cody Hao Yu,  Shuai Zheng,  Zhen Zhang,  Zhiru Zhang,  Yida Wang",
                "发布日期": "2023-12-27",
                "摘要": "  Recent years have seen an increase in the development of large deep learning\n(DL) models, which makes training efficiency crucial. Common practice is\nstruggling with the trade-off between usability and performance. On one hand,\nDL frameworks such as PyTorch use dynamic graphs to facilitate model developers\nat a price of sub-optimal model training performance. On the other hand,\npractitioners propose various approaches to improving the training efficiency\nby sacrificing some of the flexibility, ranging from making the graph static\nfor more thorough optimization (e.g., XLA) to customizing optimization towards\nlarge-scale distributed training (e.g., DeepSpeed and Megatron-LM). In this\npaper, we aim to address the tension between usability and training efficiency\nthrough separation of concerns. Inspired by DL compilers that decouple the\nplatform-specific optimizations of a tensor-level operator from its arithmetic\ndefinition, this paper proposes a schedule language, Slapo, to decouple model\nexecution from definition. Specifically, Slapo works on a PyTorch model and\nuses a set of schedule primitives to convert the model for common model\ntraining optimizations such as high-performance kernels, effective 3D\nparallelism, and efficient activation checkpointing. Compared to existing\noptimization solutions, Slapo progressively optimizes the model \"as-needed\"\nthrough high-level primitives, and thus preserving programmability and\ndebuggability for users to a large extent. Our evaluation results show that by\nscheduling the existing hand-crafted optimizations in a systematic way using\nSlapo, we are able to improve training throughput by up to 2.92x on a single\nmachine with 8 NVIDIA V100 GPUs, and by up to 1.41x on multiple machines with\nup to 64 GPUs, when compared to the out-of-the-box performance of DeepSpeed and\nMegatron-LM.\n",
                "链接": "https://arxiv.org/abs/2302.08005"
            },
            {
                "文章ID": "81479",
                "标题": "Faster Margin Maximization Rates for Generic Optimization Methods",
                "作者": " Guanghui Wang,  Zihao Hu,  Vidya Muthukumar,  Jacob Abernethy",
                "发布日期": "2023-05-30",
                "摘要": "  First-order optimization methods tend to inherently favor certain solutions\nover others when minimizing a given training objective with multiple local\noptima. This phenomenon, known as implicit bias, plays a critical role in\nunderstanding the generalization capabilities of optimization algorithms.\nRecent research has revealed that gradient-descent-based methods exhibit an\nimplicit bias for the $\\ell_2$-maximal margin classifier in the context of\nseparable binary classification. In contrast, generic optimization methods,\nsuch as mirror descent and steepest descent, have been shown to converge to\nmaximal margin classifiers defined by alternative geometries. However, while\ngradient-descent-based algorithms demonstrate fast implicit bias rates, the\nimplicit bias rates of generic optimization methods have been relatively slow.\nTo address this limitation, in this paper, we present a series of\nstate-of-the-art implicit bias rates for mirror descent and steepest descent\nalgorithms. Our primary technique involves transforming a generic optimization\nalgorithm into an online learning dynamic that solves a regularized bilinear\ngame, providing a unified framework for analyzing the implicit bias of various\noptimization methods. The accelerated rates are derived leveraging the regret\nbounds of online learning algorithms within this game framework.\n",
                "链接": "https://arxiv.org/abs/2305.17544"
            },
            {
                "文章ID": "32464",
                "标题": "Transformer-based assignment decision network for multiple object\n  tracking",
                "作者": " Athena Psalta,  Vasileios Tsironis,  Konstantinos Karantzalos",
                "发布日期": "2022-11-24",
                "摘要": "  Data association is a crucial component for any multiple object tracking\n(MOT) method that follows the tracking-by-detection paradigm. To generate\ncomplete trajectories such methods employ a data association process to\nestablish assignments between detections and existing targets during each\ntimestep. Recent data association approaches try to solve a multi-dimensional\nlinear assignment task or a network flow minimization problem or either tackle\nit via multiple hypotheses tracking. However, during inference an optimization\nstep that computes optimal assignments is required for every sequence frame\nadding significant computational complexity in any given solution. To this end,\nin the context of this work we introduce Transformer-based Assignment Decision\nNetwork (TADN) that tackles data association without the need of any explicit\noptimization during inference. In particular, TADN can directly infer\nassignment pairs between detections and active targets in a single forward pass\nof the network. We have integrated TADN in a rather simple MOT framework, we\ndesigned a novel training strategy for efficient end-to-end training and\ndemonstrate the high potential of our approach for online visual\ntracking-by-detection MOT on two popular benchmarks, i.e. MOT17 and UA-DETRAC.\nOur proposed approach outperforms the state-of-the-art in most evaluation\nmetrics despite its simple nature as a tracker which lacks significant\nauxiliary components such as occlusion handling or re-identification. The\nimplementation of our method is publicly available at\nhttps://github.com/psaltaath/tadn-mot.\n",
                "链接": "https://arxiv.org/abs/2208.03571"
            },
            {
                "文章ID": "93841",
                "标题": "Tracking mulitple targets with multiple radars using Distributed\n  Auctions",
                "作者": "LABISEN-KLAIM  Pierre Larrenie, LABISEN-KLAIM  Cédric Buron,  Frédéric Barbaresco",
                "发布日期": "2023-08-01",
                "摘要": "  Coordination of radars can be performed in various ways. To be more resilient\nradar networks can be coordinated in a decentralized way. In this paper, we\nintroduce a highly resilient algorithm for radar coordination based on\ndecentralized and collaborative bundle auctions. We first formalize our problem\nas a constrained optimization problem and apply a market-based algorithm to\nprovide an approximate solution. Our approach allows to track simultaneously\nmultiple targets, and to use up to two radars tracking the same target to\nimprove accuracy. We show that our approach performs sensibly as well as a\ncentralized approach relying on a MIP solver, and depending on the situations,\nmay outperform it or be outperformed.\n",
                "链接": "https://arxiv.org/abs/2307.16477"
            },
            {
                "文章ID": "43592",
                "标题": "Non-iterative optimization of pseudo-labeling thresholds for training\n  object detection models from multiple datasets",
                "作者": " Yuki Tanaka,  Shuhei M. Yoshida,  Makoto Terao",
                "发布日期": "2022-10-21",
                "摘要": "  We propose a non-iterative method to optimize pseudo-labeling thresholds for\nlearning object detection from a collection of low-cost datasets, each of which\nis annotated for only a subset of all the object classes. A popular approach to\nthis problem is first to train teacher models and then to use their confident\npredictions as pseudo ground-truth labels when training a student model. To\nobtain the best result, however, thresholds for prediction confidence must be\nadjusted. This process typically involves iterative search and repeated\ntraining of student models and is time-consuming. Therefore, we develop a\nmethod to optimize the thresholds without iterative optimization by maximizing\nthe $F_\\beta$-score on a validation dataset, which measures the quality of\npseudo labels and can be measured without training a student model. We\nexperimentally demonstrate that our proposed method achieves an mAP comparable\nto that of grid search on the COCO and VOC datasets.\n",
                "链接": "https://arxiv.org/abs/2210.10221"
            },
            {
                "文章ID": "114718",
                "标题": "Beyond the training set: an intuitive method for detecting distribution\n  shift in model-based optimization",
                "作者": " Farhan Damani,  David H Brookes,  Theodore Sternlieb,  Cameron Webster,  Stephen Malina,  Rishi Jajoo,  Kathy Lin,  Sam Sinai",
                "发布日期": "2023-11-10",
                "摘要": "  Model-based optimization (MBO) is increasingly applied to design problems in\nscience and engineering. A common scenario involves using a fixed training set\nto train models, with the goal of designing new samples that outperform those\npresent in the training data. A major challenge in this setting is distribution\nshift, where the distributions of training and design samples are different.\nWhile some shift is expected, as the goal is to create better designs, this\nchange can negatively affect model accuracy and subsequently, design quality.\nDespite the widespread nature of this problem, addressing it demands deep\ndomain knowledge and artful application. To tackle this issue, we propose a\nstraightforward method for design practitioners that detects distribution\nshifts. This method trains a binary classifier using knowledge of the unlabeled\ndesign distribution to separate the training data from the design data. The\nclassifier's logit scores are then used as a proxy measure of distribution\nshift. We validate our method in a real-world application by running offline\nMBO and evaluate the effect of distribution shift on design quality. We find\nthat the intensity of the shift in the design distribution varies based on the\nnumber of steps taken by the optimization algorithm, and our simple approach\ncan identify these shifts. This enables users to constrain their search to\nregions where the model's predictions are reliable, thereby increasing the\nquality of designs.\n",
                "链接": "https://arxiv.org/abs/2311.05363"
            },
            {
                "文章ID": "80682",
                "标题": "AUC Optimization from Multiple Unlabeled Datasets",
                "作者": " Zheng Xie,  Yu Liu,  Ming Li",
                "发布日期": "2023-09-18",
                "摘要": "  Weakly supervised learning aims to empower machine learning when the perfect\nsupervision is unavailable, which has drawn great attention from researchers.\nAmong various types of weak supervision, one of the most challenging cases is\nto learn from multiple unlabeled (U) datasets with only a little knowledge of\nthe class priors, or U$^m$ learning for short. In this paper, we study the\nproblem of building an AUC (area under ROC curve) optimization model from\nmultiple unlabeled datasets, which maximizes the pairwise ranking ability of\nthe classifier. We propose U$^m$-AUC, an AUC optimization approach that\nconverts the U$^m$ data into a multi-label AUC optimization problem, and can be\ntrained efficiently. We show that the proposed U$^m$-AUC is effective\ntheoretically and empirically.\n",
                "链接": "https://arxiv.org/abs/2305.15776"
            },
            {
                "文章ID": "60360",
                "标题": "Optimization using Parallel Gradient Evaluations on Multiple Parameters",
                "作者": " Yash Chandak,  Shiv Shankar,  Venkata Gandikota,  Philip S. Thomas,  Arya Mazumdar",
                "发布日期": "2023-02-08",
                "摘要": "  We propose a first-order method for convex optimization, where instead of\nbeing restricted to the gradient from a single parameter, gradients from\nmultiple parameters can be used during each step of gradient descent. This\nsetup is particularly useful when a few processors are available that can be\nused in parallel for optimization. Our method uses gradients from multiple\nparameters in synergy to update these parameters together towards the optima.\nWhile doing so, it is ensured that the computational and memory complexity is\nof the same order as that of gradient descent. Empirical results demonstrate\nthat even using gradients from as low as \\textit{two} parameters, our method\ncan often obtain significant acceleration and provide robustness to\nhyper-parameter settings. We remark that the primary goal of this work is less\ntheoretical, and is instead aimed at exploring the understudied case of using\nmultiple gradients during each step of optimization.\n",
                "链接": "https://arxiv.org/abs/2302.03161"
            }
        ]
    },
    {
        "question": {
            "question": "查找大模型推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "83366",
                "标题": "On Optimal Caching and Model Multiplexing for Large Model Inference",
                "作者": " Banghua Zhu,  Ying Sheng,  Lianmin Zheng,  Clark Barrett,  Michael I. Jordan,  Jiantao Jiao",
                "发布日期": "2023-08-30",
                "摘要": "  Large Language Models (LLMs) and other large foundation models have achieved\nnoteworthy success, but their size exacerbates existing resource consumption\nand latency challenges. In particular, the large-scale deployment of these\nmodels is hindered by the significant resource requirements during inference.\nIn this paper, we study two approaches for mitigating these challenges:\nemploying a cache to store previous queries and learning a model multiplexer to\nchoose from an ensemble of models for query processing.\n  Theoretically, we provide an optimal algorithm for jointly optimizing both\napproaches to reduce the inference cost in both offline and online tabular\nsettings. By combining a caching algorithm, namely Greedy Dual Size with\nFrequency (GDSF) or Least Expected Cost (LEC), with a model multiplexer, we\nachieve optimal rates in both offline and online settings. Empirically,\nsimulations show that the combination of our caching and model multiplexing\nalgorithms greatly improves over the baselines, with up to $50\\times$\nimprovement over the baseline when the ratio between the maximum cost and\nminimum cost is $100$. Experiments on real datasets show a $4.3\\times$\nimprovement in FLOPs over the baseline when the ratio for FLOPs is $10$, and a\n$1.8\\times$ improvement in latency when the ratio for average latency is\n$1.85$.\n",
                "链接": "https://arxiv.org/abs/2306.02003"
            },
            {
                "文章ID": "116170",
                "标题": "Large Language Model Inference with Lexical Shortlisting",
                "作者": " Nikolay Bogoychev,  Pinzhen Chen,  Barry Haddow,  Alexandra Birch",
                "发布日期": "2023-11-17",
                "摘要": "  Large language model (LLM) inference is computation and memory intensive, so\nwe adapt lexical shortlisting to it hoping to improve both. While lexical\nshortlisting is well-explored in tasks like machine translation, it requires\nmodifications before being suitable for LLMs as the intended applications vary\nsignificantly. Our work studies two heuristics to shortlist sub-vocabulary at\nLLM inference time: Unicode-based script filtering and corpus-based selection.\nWe explore different LLM families and sizes, and we find that lexical\nshortlisting can reduce the memory usage of some models by nearly 50\\% and has\nan upper bound of 25\\% improvement in generation speed. In this pilot study, we\nalso identify the drawbacks of such vocabulary selection methods and propose\navenues for future research.\n",
                "链接": "https://arxiv.org/abs/2311.09709"
            },
            {
                "文章ID": "120482",
                "标题": "A Hardware Evaluation Framework for Large Language Model Inference",
                "作者": " Hengrui Zhang,  August Ning,  Rohan Prabhakar,  David Wentzlaff",
                "发布日期": "2023-12-07",
                "摘要": "  The past year has witnessed the increasing popularity of Large Language\nModels (LLMs). Their unprecedented scale and associated high hardware cost have\nimpeded their broader adoption, calling for efficient hardware designs. With\nthe large hardware needed to simply run LLM inference, evaluating different\nhardware designs becomes a new bottleneck.\n  This work introduces LLMCompass, a hardware evaluation framework for LLM\ninference workloads. LLMCompass is fast, accurate, versatile, and able to\ndescribe and evaluate different hardware designs. LLMCompass includes a mapper\nto automatically find performance-optimal mapping and scheduling. It also\nincorporates an area-based cost model to help architects reason about their\ndesign choices. Compared to real-world hardware, LLMCompass' estimated latency\nachieves an average 10.4% error rate across various operators with various\ninput sizes and an average 4.1% error rate for LLM inference. With LLMCompass,\nsimulating a 4-NVIDIA A100 GPU node running GPT-3 175B inference can be done\nwithin 16 minutes on commodity hardware, including 26,400 rounds of the\nmapper's parameter search.\n  With the aid of LLMCompass, this work draws architectural implications and\nexplores new cost-effective hardware designs. By reducing the compute\ncapability or replacing High Bandwidth Memory (HBM) with traditional DRAM,\nthese new designs can achieve as much as 3.41x improvement in performance/cost\ncompared to an NVIDIA A100, making them promising choices for democratizing\nLLMs.\n  LLMCompass is planned to be fully open-source.\n",
                "链接": "https://arxiv.org/abs/2312.03134"
            },
            {
                "文章ID": "113368",
                "标题": "FlashDecoding++: Faster Large Language Model Inference on GPUs",
                "作者": " Ke Hong,  Guohao Dai,  Jiaming Xu,  Qiuli Mao,  Xiuhong Li,  Jun Liu,  Kangdi Chen,  Yuhan Dong,  Yu Wang",
                "发布日期": "2023-11-13",
                "摘要": "  As the Large Language Model (LLM) becomes increasingly important in various\ndomains. However, the following challenges still remain unsolved in\naccelerating LLM inference: (1) Synchronized partial softmax update. The\nsoftmax operation requires a synchronized update operation among each partial\nsoftmax result, leading to ~20% overheads for the attention computation in\nLLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices\nperforming GEMM in LLM inference is flat, leading to under-utilized computation\nand >50% performance loss after padding zeros in previous designs. (3)\nPerformance loss due to static dataflow. Kernel performance in LLM depends on\nvaried input data features, hardware configurations, etc. A single and static\ndataflow may lead to a 50.25% performance loss for GEMMs of different shapes in\nLLM inference.\n  We present FlashDecoding++, a fast LLM inference engine supporting mainstream\nLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++\ncreatively proposes: (1) Asynchronized softmax with unified max value.\nFlashDecoding++ introduces a unified max value technique for different partial\nsoftmax computations to avoid synchronization. (2) Flat GEMM optimization with\ndouble buffering. FlashDecoding++ points out that flat GEMMs with different\nshapes face varied bottlenecks. Then, techniques like double buffering are\nintroduced. (3) Heuristic dataflow with hardware resource adaptation.\nFlashDecoding++ heuristically optimizes dataflow using different hardware\nresource considering input dynamics. Due to the versatility of optimizations in\nFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on\nboth NVIDIA and AMD GPUs compared to Hugging Face implementations.\nFlashDecoding++ also achieves an average speedup of 1.37x compared to\nstate-of-the-art LLM inference engines on mainstream LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.01282"
            },
            {
                "文章ID": "119522",
                "标题": "LinguaLinked: A Distributed Large Language Model Inference System for\n  Mobile Devices",
                "作者": " Junchen Zhao,  Yurun Song,  Simeng Liu,  Ian G. Harris,  Sangeetha Abdu Jyothi",
                "发布日期": "2023-12-04",
                "摘要": "  Deploying Large Language Models (LLMs) locally on mobile devices presents a\nsignificant challenge due to their extensive memory requirements. In this\npaper, we introduce LinguaLinked, a system for decentralized, distributed LLM\ninference on mobile devices. LinguaLinked enables collaborative execution of\nthe inference task across multiple trusted devices. LinguaLinked ensures data\nprivacy by processing information locally. LinguaLinked uses three key\nstrategies. First, an optimized model assignment technique segments LLMs and\nuses linear optimization to align segments with each device's capabilities.\nSecond, an optimized data transmission mechanism ensures efficient and\nstructured data flow between model segments while also maintaining the\nintegrity of the original model structure. Finally, LinguaLinked incorporates a\nruntime load balancer that actively monitors and redistributes tasks among\nmobile devices to prevent bottlenecks, enhancing the system's overall\nefficiency and responsiveness. We demonstrate that LinguaLinked facilitates\nefficient LLM inference while maintaining consistent throughput and minimal\nlatency through extensive testing across various mobile devices, from high-end\nto low-end Android devices. In our evaluations, compared to the baseline,\nLinguaLinked achieves an inference performance acceleration of $1.11\\times$ to\n$1.61\\times$ in single-threaded settings, $1.73\\times$ to $2.65\\times$ with\nmulti-threading. Additionally, runtime load balancing yields an overall\ninference acceleration of $1.29\\times$ to $1.32\\times$.\n",
                "链接": "https://arxiv.org/abs/2312.00388"
            },
            {
                "文章ID": "57741",
                "标题": "Batch Prompting: Efficient Inference with Large Language Model APIs",
                "作者": " Zhoujun Cheng,  Jungo Kasai,  Tao Yu",
                "发布日期": "2023-10-25",
                "摘要": "  Performing inference on large volumes of samples with large language models\n(LLMs) can be computationally and financially costly in industry and real-world\nuse. We propose batch prompting, a simple yet effective prompting approach that\nenables the LLM to run inference in batches, instead of one sample at a time.\nOur method reduces both token and time costs while retaining downstream\nperformance. We theoretically demonstrate that under a few-shot in-context\nlearning setting, the inference costs decrease almost inverse linearly with the\nnumber of samples in each batch. We extensively validate the effectiveness of\nbatch prompting on ten datasets across commonsense QA, arithmetic reasoning,\nand NLI/NLU: batch prompting significantly~(up to 5x with six samples in batch)\nreduces the LLM (Codex) inference token and time costs while achieving better\nor comparable performance. For state-of-the-art Chat-based LLMs, e.g., GPT-3.5\nand GPT-4, we show the benefits of batch prompting also hold. Further analysis\nshows that the number of samples in each batch and the complexity of tasks\naffect its performance. Moreover, batch prompting can be applied across\ndifferent reasoning methods using LLMs. Our code can be found at the site\nhttps://github.com/xlang-ai/batch-prompting.\n",
                "链接": "https://arxiv.org/abs/2301.08721"
            },
            {
                "文章ID": "106372",
                "标题": "From Words to Watts: Benchmarking the Energy Costs of Large Language\n  Model Inference",
                "作者": " Siddharth Samsi,  Dan Zhao,  Joseph McDonald,  Baolin Li,  Adam Michaleas,  Michael Jones,  William Bergeron,  Jeremy Kepner,  Devesh Tiwari,  Vijay Gadepally",
                "发布日期": "2023-10-05",
                "摘要": "  Large language models (LLMs) have exploded in popularity due to their new\ngenerative capabilities that go far beyond prior state-of-the-art. These\ntechnologies are increasingly being leveraged in various domains such as law,\nfinance, and medicine. However, these models carry significant computational\nchallenges, especially the compute and energy costs required for inference.\nInference energy costs already receive less attention than the energy costs of\ntraining LLMs -- despite how often these large models are called on to conduct\ninference in reality (e.g., ChatGPT). As these state-of-the-art LLMs see\nincreasing usage and deployment in various domains, a better understanding of\ntheir resource utilization is crucial for cost-savings, scaling performance,\nefficient hardware usage, and optimal inference strategies.\n  In this paper, we describe experiments conducted to study the computational\nand energy utilization of inference with LLMs. We benchmark and conduct a\npreliminary analysis of the inference performance and inference energy costs of\ndifferent sizes of LLaMA -- a recent state-of-the-art LLM -- developed by Meta\nAI on two generations of popular GPUs (NVIDIA V100 \\& A100) and two datasets\n(Alpaca and GSM8K) to reflect the diverse set of tasks/benchmarks for LLMs in\nresearch and practice. We present the results of multi-node, multi-GPU\ninference using model sharding across up to 32 GPUs. To our knowledge, our work\nis the one of the first to study LLM inference performance from the perspective\nof computational and energy resources at this scale.\n",
                "链接": "https://arxiv.org/abs/2310.03003"
            },
            {
                "文章ID": "42266",
                "标题": "Developing a general-purpose clinical language inference model from a\n  large corpus of clinical notes",
                "作者": " Madhumita Sushil,  Dana Ludwig,  Atul J. Butte,  Vivek A. Rudrapatna",
                "发布日期": "2022-10-14",
                "摘要": "  Several biomedical language models have already been developed for clinical\nlanguage inference. However, these models typically utilize general\nvocabularies and are trained on relatively small clinical corpora. We sought to\nevaluate the impact of using a domain-specific vocabulary and a large clinical\ntraining corpus on the performance of these language models in clinical\nlanguage inference. We trained a Bidirectional Encoder Decoder from\nTransformers (BERT) model using a diverse, deidentified corpus of 75 million\ndeidentified clinical notes authored at the University of California, San\nFrancisco (UCSF). We evaluated this model on several clinical language\ninference benchmark tasks: clinical and temporal concept recognition, relation\nextraction and medical language inference. We also evaluated our model on two\ntasks using discharge summaries from UCSF: diagnostic code assignment and\ntherapeutic class inference. Our model performs at par with the best publicly\navailable biomedical language models of comparable sizes on the public\nbenchmark tasks, and is significantly better than these models in a\nwithin-system evaluation on the two tasks using UCSF data. The use of in-domain\nvocabulary appears to improve the encoding of longer documents. The use of\nlarge clinical corpora appears to enhance document encoding and inferential\naccuracy. However, further research is needed to improve abbreviation\nresolution, and numerical, temporal, and implicitly causal inference.\n",
                "链接": "https://arxiv.org/abs/2210.06566"
            },
            {
                "文章ID": "65490",
                "标题": "Cost-Effective Hyperparameter Optimization for Large Language Model\n  Generation Inference",
                "作者": " Chi Wang,  Susan Xueqing Liu,  Ahmed H. Awadallah",
                "发布日期": "2023-08-10",
                "摘要": "  Large Language Models (LLMs) have sparked significant interest in their\ngenerative capabilities, leading to the development of various commercial\napplications. The high cost of using the models drives application builders to\nmaximize the value of generation under a limited inference budget. This paper\npresents a study of optimizing inference hyperparameters such as the number of\nresponses, temperature and max tokens, which significantly affects the\nutility/cost of text generation. We design a framework named EcoOptiGen which\nleverages economical hyperparameter optimization and cost-based pruning.\nExperiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its\neffectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAML\nlibrary: \\url{https://aka.ms/autogen}.\n",
                "链接": "https://arxiv.org/abs/2303.04673"
            },
            {
                "文章ID": "123538",
                "标题": "LLM in a flash: Efficient Large Language Model Inference with Limited\n  Memory",
                "作者": " Keivan Alizadeh,  Iman Mirzadeh,  Dmitry Belenko,  Karen Khatamifard,  Minsik Cho,  Carlo C Del Mundo,  Mohammad Rastegari,  Mehrdad Farajtabar",
                "发布日期": "2023-12-20",
                "摘要": "  Large language models (LLMs) are central to modern natural language\nprocessing, delivering exceptional performance in various tasks. However, their\nintensive computational and memory requirements present challenges, especially\nfor devices with limited DRAM capacity. This paper tackles the challenge of\nefficiently running LLMs that exceed the available DRAM capacity by storing the\nmodel parameters on flash memory but bringing them on demand to DRAM. Our\nmethod involves constructing an inference cost model that harmonizes with the\nflash memory behavior, guiding us to optimize in two critical areas: reducing\nthe volume of data transferred from flash and reading data in larger, more\ncontiguous chunks. Within this flash memory-informed framework, we introduce\ntwo principal techniques. First, \"windowing'\" strategically reduces data\ntransfer by reusing previously activated neurons, and second, \"row-column\nbundling\", tailored to the sequential data access strengths of flash memory,\nincreases the size of data chunks read from flash memory. These methods\ncollectively enable running models up to twice the size of the available DRAM,\nwith a 4-5x and 20-25x increase in inference speed compared to naive loading\napproaches in CPU and GPU, respectively. Our integration of sparsity awareness,\ncontext-adaptive loading, and a hardware-oriented design paves the way for\neffective inference of LLMs on devices with limited memory.\n",
                "链接": "https://arxiv.org/abs/2312.11514"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月自然语言处理相关的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "197",
                "标题": "Robust Natural Language Processing: Recent Advances, Challenges, and\n  Future Directions",
                "作者": " Marwan Omar,  Soohyeon Choi,  DaeHun Nyang,  David Mohaisen",
                "发布日期": "2022-10-24",
                "摘要": "  Recent natural language processing (NLP) techniques have accomplished high\nperformance on benchmark datasets, primarily due to the significant improvement\nin the performance of deep learning. The advances in the research community\nhave led to great enhancements in state-of-the-art production systems for NLP\ntasks, such as virtual assistants, speech recognition, and sentiment analysis.\nHowever, such NLP systems still often fail when tested with adversarial\nattacks. The initial lack of robustness exposed troubling gaps in current\nmodels' language understanding capabilities, creating problems when NLP systems\nare deployed in real life. In this paper, we present a structured overview of\nNLP robustness research by summarizing the literature in a systemic way across\nvarious dimensions. We then take a deep-dive into the various dimensions of\nrobustness, across techniques, metrics, embeddings, and benchmarks. Finally, we\nargue that robustness should be multi-dimensional, provide insights into\ncurrent research, identify gaps in the literature to suggest directions worth\npursuing to address these gaps.\n",
                "链接": "https://arxiv.org/abs/2201.00768"
            },
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "85699",
                "标题": "Operationalising Representation in Natural Language Processing",
                "作者": " Jacqueline Harding",
                "发布日期": "2023-11-21",
                "摘要": "  Despite its centrality in the philosophy of cognitive science, there has been\nlittle prior philosophical work engaging with the notion of representation in\ncontemporary NLP practice. This paper attempts to fill that lacuna: drawing on\nideas from cognitive science, I introduce a framework for evaluating the\nrepresentational claims made about components of neural NLP models, proposing\nthree criteria with which to evaluate whether a component of a model represents\na property and operationalising these criteria using probing classifiers, a\npopular analysis technique in NLP (and deep learning more broadly).\n  The project of operationalising a philosophically-informed notion of\nrepresentation should be of interest to both philosophers of science and NLP\npractitioners. It affords philosophers a novel testing-ground for claims about\nthe nature of representation, and helps NLPers organise the large literature on\nprobing experiments, suggesting novel avenues for empirical research.\n",
                "链接": "https://arxiv.org/abs/2306.08193"
            },
            {
                "文章ID": "120207",
                "标题": "Measuring Distributional Shifts in Text: The Advantage of Language\n  Model-Based Embeddings",
                "作者": " Gyandev Gupta,  Bashir Rastegarpanah,  Amalendu Iyer,  Joshua Rubin,  Krishnaram Kenthapadi",
                "发布日期": "2023-12-06",
                "摘要": "  An essential part of monitoring machine learning models in production is\nmeasuring input and output data drift. In this paper, we present a system for\nmeasuring distributional shifts in natural language data and highlight and\ninvestigate the potential advantage of using large language models (LLMs) for\nthis problem. Recent advancements in LLMs and their successful adoption in\ndifferent domains indicate their effectiveness in capturing semantic\nrelationships for solving various natural language processing problems. The\npower of LLMs comes largely from the encodings (embeddings) generated in the\nhidden layers of the corresponding neural network. First we propose a\nclustering-based algorithm for measuring distributional shifts in text data by\nexploiting such embeddings. Then we study the effectiveness of our approach\nwhen applied to text embeddings generated by both LLMs and classical embedding\nalgorithms. Our experiments show that general-purpose LLM-based embeddings\nprovide a high sensitivity to data drift compared to other embedding methods.\nWe propose drift sensitivity as an important evaluation metric to consider when\ncomparing language models. Finally, we present insights and lessons learned\nfrom deploying our framework as part of the Fiddler ML Monitoring platform over\na period of 18 months.\n",
                "链接": "https://arxiv.org/abs/2312.02337"
            },
            {
                "文章ID": "79436",
                "标题": "Interactive Natural Language Processing",
                "作者": " Zekun Wang,  Ge Zhang,  Kexin Yang,  Ning Shi,  Wangchunshu Zhou,  Shaochun Hao,  Guangzheng Xiong,  Yizhi Li,  Mong Yuan Sim,  Xiuying Chen,  Qingqing Zhu,  Zhenzhu Yang,  Adam Nik,  Qi Liu,  Chenghua Lin,  Shi Wang,  Ruibo Liu,  Wenhu Chen,  Ke Xu,  Dayiheng Liu,  Yike Guo,  Jie Fu",
                "发布日期": "2023-05-23",
                "摘要": "  Interactive Natural Language Processing (iNLP) has emerged as a novel\nparadigm within the field of NLP, aimed at addressing limitations in existing\nframeworks while aligning with the ultimate goals of artificial intelligence.\nThis paradigm considers language models as agents capable of observing, acting,\nand receiving feedback iteratively from external entities. Specifically,\nlanguage models in this context can: (1) interact with humans for better\nunderstanding and addressing user needs, personalizing responses, aligning with\nhuman values, and improving the overall user experience; (2) interact with\nknowledge bases for enriching language representations with factual knowledge,\nenhancing the contextual relevance of responses, and dynamically leveraging\nexternal information to generate more accurate and informed responses; (3)\ninteract with models and tools for effectively decomposing and addressing\ncomplex tasks, leveraging specialized expertise for specific subtasks, and\nfostering the simulation of social behaviors; and (4) interact with\nenvironments for learning grounded representations of language, and effectively\ntackling embodied tasks such as reasoning, planning, and decision-making in\nresponse to environmental observations. This paper offers a comprehensive\nsurvey of iNLP, starting by proposing a unified definition and framework of the\nconcept. We then provide a systematic classification of iNLP, dissecting its\nvarious components, including interactive objects, interaction interfaces, and\ninteraction methods. We proceed to delve into the evaluation methodologies used\nin the field, explore its diverse applications, scrutinize its ethical and\nsafety issues, and discuss prospective research directions. This survey serves\nas an entry point for researchers who are interested in this rapidly evolving\narea and offers a broad view of the current landscape and future trajectory of\niNLP.\n",
                "链接": "https://arxiv.org/abs/2305.13246"
            },
            {
                "文章ID": "34310",
                "标题": "Review of Natural Language Processing in Pharmacology",
                "作者": " Dimitar Trajanov,  Vangel Trajkovski,  Makedonka Dimitrieva,  Jovana Dobreva,  Milos Jovanovik,  Matej Klemen,  Aleš Žagar,  Marko Robnik-Šikonja",
                "发布日期": "2023-01-27",
                "摘要": "  Natural language processing (NLP) is an area of artificial intelligence that\napplies information technologies to process the human language, understand it\nto a certain degree, and use it in various applications. This area has rapidly\ndeveloped in the last few years and now employs modern variants of deep neural\nnetworks to extract relevant patterns from large text corpora. The main\nobjective of this work is to survey the recent use of NLP in the field of\npharmacology. As our work shows, NLP is a highly relevant information\nextraction and processing approach for pharmacology. It has been used\nextensively, from intelligent searches through thousands of medical documents\nto finding traces of adversarial drug interactions in social media. We split\nour coverage into five categories to survey modern NLP methodology, commonly\naddressed tasks, relevant textual data, knowledge bases, and useful programming\nlibraries. We split each of the five categories into appropriate subcategories,\ndescribe their main properties and ideas, and summarize them in a tabular form.\nThe resulting survey presents a comprehensive overview of the area, useful to\npractitioners and interested observers.\n",
                "链接": "https://arxiv.org/abs/2208.10228"
            },
            {
                "文章ID": "56677",
                "标题": "User-Centered Security in Natural Language Processing",
                "作者": " Chris Emmery",
                "发布日期": "2023-01-12",
                "摘要": "  This dissertation proposes a framework of user-centered security in Natural\nLanguage Processing (NLP), and demonstrates how it can improve the\naccessibility of related research. Accordingly, it focuses on two security\ndomains within NLP with great public interest. First, that of author profiling,\nwhich can be employed to compromise online privacy through invasive inferences.\nWithout access and detailed insight into these models' predictions, there is no\nreasonable heuristic by which Internet users might defend themselves from such\ninferences. Secondly, that of cyberbullying detection, which by default\npresupposes a centralized implementation; i.e., content moderation across\nsocial platforms. As access to appropriate data is restricted, and the nature\nof the task rapidly evolves (both through lexical variation, and cultural\nshifts), the effectiveness of its classifiers is greatly diminished and thereby\noften misrepresented.\n  Under the proposed framework, we predominantly investigate the use of\nadversarial attacks on language; i.e., changing a given input (generating\nadversarial samples) such that a given model does not function as intended.\nThese attacks form a common thread between our user-centered security problems;\nthey are highly relevant for privacy-preserving obfuscation methods against\nauthor profiling, and adversarial samples might also prove useful to assess the\ninfluence of lexical variation and augmentation on cyberbullying detection.\n",
                "链接": "https://arxiv.org/abs/2301.04230"
            },
            {
                "文章ID": "63180",
                "标题": "Natural Language Processing in the Legal Domain",
                "作者": " Daniel Martin Katz,  Dirk Hartung,  Lauritz Gerlach,  Abhik Jana, II Michael J. Bommarito",
                "发布日期": "2023-02-24",
                "摘要": "  In this paper, we summarize the current state of the field of NLP & Law with\na specific focus on recent technical and substantive developments. To support\nour analysis, we construct and analyze a nearly complete corpus of more than\nsix hundred NLP & Law related papers published over the past decade. Our\nanalysis highlights several major trends. Namely, we document an increasing\nnumber of papers written, tasks undertaken, and languages covered over the\ncourse of the past decade. We observe an increase in the sophistication of the\nmethods which researchers deployed in this applied context. Slowly but surely,\nLegal NLP is beginning to match not only the methodological sophistication of\ngeneral NLP but also the professional standards of data availability and code\nreproducibility observed within the broader scientific community. We believe\nall of these trends bode well for the future of the field, but many questions\nin both the academic and commercial sphere still remain open.\n",
                "链接": "https://arxiv.org/abs/2302.12039"
            },
            {
                "文章ID": "121029",
                "标题": "PyThaiNLP: Thai Natural Language Processing in Python",
                "作者": " Wannaphong Phatthiyaphaibun,  Korakot Chaovavanich,  Charin Polpanumas,  Arthit Suriyawongkul,  Lalita Lowphansirikul,  Pattarawat Chormai,  Peerat Limkonchotiwat,  Thanathip Suntorntip,  Can Udomcharoenchaikit",
                "发布日期": "2023-12-11",
                "摘要": "  We present PyThaiNLP, a free and open-source natural language processing\n(NLP) library for Thai language implemented in Python. It provides a wide range\nof software, models, and datasets for Thai language. We first provide a brief\nhistorical context of tools for Thai language prior to the development of\nPyThaiNLP. We then outline the functionalities it provided as well as datasets\nand pre-trained language models. We later summarize its development milestones\nand discuss our experience during its development. We conclude by demonstrating\nhow industrial and research communities utilize PyThaiNLP in their work. The\nlibrary is freely available at https://github.com/pythainlp/pythainlp.\n",
                "链接": "https://arxiv.org/abs/2312.04649"
            },
            {
                "文章ID": "1182",
                "标题": "Feature-rich multiplex lexical networks reveal mental strategies of\n  early language learning",
                "作者": " Salvatore Citraro,  Michael S. Vitevitch,  Massimo Stella,  Giulio Rossetti",
                "发布日期": "2022-01-14",
                "摘要": "  Knowledge in the human mind exhibits a dualistic vector/network nature.\nModelling words as vectors is key to natural language processing, whereas\nnetworks of word associations can map the nature of semantic memory. We\nreconcile these paradigms - fragmented across linguistics, psychology and\ncomputer science - by introducing FEature-Rich MUltiplex LEXical (FERMULEX)\nnetworks. This novel framework merges structural similarities in networks and\nvector features of words, which can be combined or explored independently.\nSimilarities model heterogenous word associations across\nsemantic/syntactic/phonological aspects of knowledge. Words are enriched with\nmulti-dimensional feature embeddings including frequency, age of acquisition,\nlength and polysemy. These aspects enable unprecedented explorations of\ncognitive knowledge. Through CHILDES data, we use FERMULEX networks to model\nnormative language acquisition by 1000 toddlers between 18 and 30 months.\nSimilarities and embeddings capture word homophily via conformity, which\nmeasures assortative mixing via distance and features. Conformity unearths a\nlanguage kernel of frequent/polysemous/short nouns and verbs key for basic\nsentence production, supporting recent evidence of children's syntactic\nconstructs emerging at 30 months. This kernel is invisible to network\ncore-detection and feature-only clustering: It emerges from the dual\nvector/network nature of words. Our quantitative analysis reveals two key\nstrategies in early word learning. Modelling word acquisition as random walks\non FERMULEX topology, we highlight non-uniform filling of communicative\ndevelopmental inventories (CDIs). Conformity-based walkers lead to accurate\n(75%), precise (55%) and partially well-recalled (34%) predictions of early\nword learning in CDIs, providing quantitative support to previous empirical\nfindings and developmental theories.\n",
                "链接": "https://arxiv.org/abs/2201.05061"
            }
        ]
    },
    {
        "question": {
            "question": "查找多语言情感分析的最新论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "82977",
                "标题": "UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of\n  Multilingual BERT for Low-resource Sentiment Analysis",
                "作者": " Dou Hu,  Lingwei Wei,  Yaxin Liu,  Wei Zhou,  Songlin Hu",
                "发布日期": "2023-06-05",
                "摘要": "  This paper describes our system designed for SemEval-2023 Task 12: Sentiment\nanalysis for African languages. The challenge faced by this task is the\nscarcity of labeled data and linguistic resources in low-resource settings. To\nalleviate these, we propose a generalized multilingual system SACL-XLMR for\nsentiment analysis on low-resource languages. Specifically, we design a\nlexicon-based multilingual BERT to facilitate language adaptation and\nsentiment-aware representation learning. Besides, we apply a supervised\nadversarial contrastive learning technique to learn sentiment-spread structured\nrepresentations and enhance model generalization. Our system achieved\ncompetitive results, largely outperforming baselines on both multilingual and\nzero-shot sentiment classification subtasks. Notably, the system obtained the\n1st rank on the zero-shot classification subtask in the official ranking.\nExtensive experiments demonstrate the effectiveness of our system.\n",
                "链接": "https://arxiv.org/abs/2306.01093"
            },
            {
                "文章ID": "85580",
                "标题": "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted\n  Sentiment Classification Benchmark",
                "作者": " Łukasz Augustyniak,  Szymon Woźniak,  Marcin Gruza,  Piotr Gramacki,  Krzysztof Rajda,  Mikołaj Morzy,  Tomasz Kajdanowicz",
                "发布日期": "2023-06-14",
                "摘要": "  Despite impressive advancements in multilingual corpora collection and model\ntraining, developing large-scale deployments of multilingual models still\npresents a significant challenge. This is particularly true for language tasks\nthat are culture-dependent. One such example is the area of multilingual\nsentiment analysis, where affective markers can be subtle and deeply ensconced\nin culture. This work presents the most extensive open massively multilingual\ncorpus of datasets for training sentiment models. The corpus consists of 79\nmanually selected datasets from over 350 datasets reported in the scientific\nliterature based on strict quality criteria. The corpus covers 27 languages\nrepresenting 6 language families. Datasets can be queried using several\nlinguistic and functional features. In addition, we present a multi-faceted\nsentiment classification benchmark summarizing hundreds of experiments\nconducted on different base models, training objectives, dataset collections,\nand fine-tuning strategies.\n",
                "链接": "https://arxiv.org/abs/2306.07902"
            },
            {
                "文章ID": "14369",
                "标题": "Assessment of Massively Multilingual Sentiment Classifiers",
                "作者": " Krzysztof Rajda,  Łukasz Augustyniak,  Piotr Gramacki,  Marcin Gruza,  Szymon Woźniak,  Tomasz Kajdanowicz",
                "发布日期": "2022-04-12",
                "摘要": "  Models are increasing in size and complexity in the hunt for SOTA. But what\nif those 2\\% increase in performance does not make a difference in a production\nuse case? Maybe benefits from a smaller, faster model outweigh those slight\nperformance gains. Also, equally good performance across languages in\nmultilingual tasks is more important than SOTA results on a single one. We\npresent the biggest, unified, multilingual collection of sentiment analysis\ndatasets. We use these to assess 11 models and 80 high-quality sentiment\ndatasets (out of 342 raw datasets collected) in 27 languages and included\nresults on the internally annotated datasets. We deeply evaluate multiple\nsetups, including fine-tuning transformer-based models for measuring\nperformance. We compare results in numerous dimensions addressing the imbalance\nin both languages coverage and dataset sizes. Finally, we present some best\npractices for working with such a massive collection of datasets and models\nfrom a multilingual perspective.\n",
                "链接": "https://arxiv.org/abs/2204.04937"
            },
            {
                "文章ID": "74935",
                "标题": "NLNDE at SemEval-2023 Task 12: Adaptive Pretraining and Source Language\n  Selection for Low-Resource Multilingual Sentiment Analysis",
                "作者": " Mingyang Wang,  Heike Adel,  Lukas Lange,  Jannik Strötgen,  Hinrich Schütze",
                "发布日期": "2023-05-02",
                "摘要": "  This paper describes our system developed for the SemEval-2023 Task 12\n\"Sentiment Analysis for Low-resource African Languages using Twitter Dataset\".\nSentiment analysis is one of the most widely studied applications in natural\nlanguage processing. However, most prior work still focuses on a small number\nof high-resource languages. Building reliable sentiment analysis systems for\nlow-resource languages remains challenging, due to the limited training data in\nthis task. In this work, we propose to leverage language-adaptive and\ntask-adaptive pretraining on African texts and study transfer learning with\nsource language selection on top of an African language-centric pretrained\nlanguage model. Our key findings are: (1) Adapting the pretrained model to the\ntarget language and task using a small yet relevant corpus improves performance\nremarkably by more than 10 F1 score points. (2) Selecting source languages with\npositive transfer gains during training can avoid harmful interference from\ndissimilar languages, leading to better results in multilingual and\ncross-lingual settings. In the shared task, our system wins 8 out of 15 tracks\nand, in particular, performs best in the multilingual evaluation.\n",
                "链接": "https://arxiv.org/abs/2305.00090"
            },
            {
                "文章ID": "2025",
                "标题": "NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual\n  Sentiment Analysis",
                "作者": " Shamsuddeen Hassan Muhammad,  David Ifeoluwa Adelani,  Sebastian Ruder,  Ibrahim Said Ahmad,  Idris Abdulmumin,  Bello Shehu Bello,  Monojit Choudhury,  Chris Chinenye Emezue,  Saheed Salahudeen Abdullahi,  Anuoluwapo Aremu,  Alipio Jeorge,  Pavel Brazdil",
                "发布日期": "2022-06-22",
                "摘要": "  Sentiment analysis is one of the most widely studied applications in NLP, but\nmost work focuses on languages with large amounts of data. We introduce the\nfirst large-scale human-annotated Twitter sentiment dataset for the four most\nwidely spoken languages in Nigeria (Hausa, Igbo, Nigerian-Pidgin, and\nYor\\`ub\\'a ) consisting of around 30,000 annotated tweets per language (and\n14,000 for Nigerian-Pidgin), including a significant fraction of code-mixed\ntweets. We propose text collection, filtering, processing and labeling methods\nthat enable us to create datasets for these low-resource languages. We evaluate\na rangeof pre-trained models and transfer strategies on the dataset. We find\nthat language-specific models and language-adaptivefine-tuning generally\nperform best. We release the datasets, trained models, sentiment lexicons, and\ncode to incentivizeresearch on sentiment analysis in under-represented\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2201.08277"
            },
            {
                "文章ID": "121053",
                "标题": "Deep Emotions Across Languages: A Novel Approach for Sentiment\n  Propagation in Multilingual WordNets",
                "作者": " Jan Kocoń",
                "发布日期": "2023-12-11",
                "摘要": "  Sentiment analysis involves using WordNets enriched with emotional metadata,\nwhich are valuable resources. However, manual annotation is time-consuming and\nexpensive, resulting in only a few WordNet Lexical Units being annotated. This\npaper introduces two new techniques for automatically propagating sentiment\nannotations from a partially annotated WordNet to its entirety and to a WordNet\nin a different language: Multilingual Structured Synset Embeddings (MSSE) and\nCross-Lingual Deep Neural Sentiment Propagation (CLDNS). We evaluated the\nproposed MSSE+CLDNS method extensively using Princeton WordNet and Polish\nWordNet, which have many inter-lingual relations. Our results show that the\nMSSE+CLDNS method outperforms existing propagation methods, indicating its\neffectiveness in enriching WordNets with emotional metadata across multiple\nlanguages. This work provides a solid foundation for large-scale, multilingual\nsentiment analysis and is valuable for academic research and practical\napplications.\n",
                "链接": "https://arxiv.org/abs/2312.04715"
            },
            {
                "文章ID": "52169",
                "标题": "Video Games as a Corpus: Sentiment Analysis using Fallout New Vegas\n  Dialog",
                "作者": " Mika Hämäläinen,  Khalid Alnajjar,  Thierry Poibeau",
                "发布日期": "2022-12-06",
                "摘要": "  We present a method for extracting a multilingual sentiment annotated dialog\ndata set from Fallout New Vegas. The game developers have preannotated every\nline of dialog in the game in one of the 8 different sentiments: \\textit{anger,\ndisgust, fear, happy, neutral, pained, sad } and \\textit{surprised}. The game\nhas been translated into English, Spanish, German, French and Italian. We\nconduct experiments on multilingual, multilabel sentiment analysis on the\nextracted data set using multilingual BERT, XLMRoBERTa and language specific\nBERT models. In our experiments, multilingual BERT outperformed XLMRoBERTa for\nmost of the languages, also language specific models were slightly better than\nmultilingual BERT for most of the languages. The best overall accuracy was 54\\%\nand it was achieved by using multilingual BERT on Spanish data. The extracted\ndata set presents a challenging task for sentiment analysis. We have released\nthe data, including the testing and training splits, openly on Zenodo. The data\nset has been shuffled for copyright reasons.\n",
                "链接": "https://arxiv.org/abs/2212.02168"
            },
            {
                "文章ID": "110460",
                "标题": "Sentiment Analysis Across Multiple African Languages: A Current\n  Benchmark",
                "作者": " Saurav K. Aryal,  Howard Prioleau,  Surakshya Aryal",
                "发布日期": "2023-10-24",
                "摘要": "  Sentiment analysis is a fundamental and valuable task in NLP. However, due to\nlimitations in data and technological availability, research into sentiment\nanalysis of African languages has been fragmented and lacking. With the recent\nrelease of the AfriSenti-SemEval Shared Task 12, hosted as a part of The 17th\nInternational Workshop on Semantic Evaluation, an annotated sentiment analysis\nof 14 African languages was made available. We benchmarked and compared current\nstate-of-art transformer models across 12 languages and compared the\nperformance of training one-model-per-language versus\nsingle-model-all-languages. We also evaluated the performance of standard\nmultilingual models and their ability to learn and transfer cross-lingual\nrepresentation from non-African to African languages. Our results show that\ndespite work in low resource modeling, more data still produces better models\non a per-language basis. Models explicitly developed for African languages\noutperform other models on all tasks. Additionally, no one-model-fits-all\nsolution exists for a per-language evaluation of the models evaluated.\nMoreover, for some languages with a smaller sample size, a larger multilingual\nmodel may perform better than a dedicated per-language model for sentiment\nclassification.\n",
                "链接": "https://arxiv.org/abs/2310.14120"
            },
            {
                "文章ID": "45781",
                "标题": "Sentiment Classification of Code-Switched Text using Pre-trained\n  Multilingual Embeddings and Segmentation",
                "作者": " Saurav K. Aryal,  Howard Prioleau,  Gloria Washington",
                "发布日期": "2022-11-01",
                "摘要": "  With increasing globalization and immigration, various studies have estimated\nthat about half of the world population is bilingual. Consequently, individuals\nconcurrently use two or more languages or dialects in casual conversational\nsettings. However, most research is natural language processing is focused on\nmonolingual text. To further the work in code-switched sentiment analysis, we\npropose a multi-step natural language processing algorithm utilizing points of\ncode-switching in mixed text and conduct sentiment analysis around those\nidentified points. The proposed sentiment analysis algorithm uses semantic\nsimilarity derived from large pre-trained multilingual models with a\nhandcrafted set of positive and negative words to determine the polarity of\ncode-switched text. The proposed approach outperforms a comparable baseline\nmodel by 11.2% for accuracy and 11.64% for F1-score on a Spanish-English\ndataset. Theoretically, the proposed algorithm can be expanded for sentiment\nanalysis of multiple languages with limited human expertise.\n",
                "链接": "https://arxiv.org/abs/2210.16461"
            },
            {
                "文章ID": "59246",
                "标题": "Automated Sentiment and Hate Speech Analysis of Facebook Data by\n  Employing Multilingual Transformer Models",
                "作者": " Ritumbra Manuvie,  Saikat Chatterjee",
                "发布日期": "2023-02-01",
                "摘要": "  In recent years, there has been a heightened consensus within academia and in\nthe public discourse that Social Media Platforms (SMPs), amplify the spread of\nhateful and negative sentiment content. Researchers have identified how hateful\ncontent, political propaganda, and targeted messaging contributed to real-world\nharms including insurrections against democratically elected governments,\ngenocide, and breakdown of social cohesion due to heightened negative discourse\ntowards certain communities in parts of the world. To counter these issues,\nSMPs have created semi-automated systems that can help identify toxic speech.\nIn this paper we analyse the statistical distribution of hateful and negative\nsentiment contents within a representative Facebook dataset (n= 604,703)\nscrapped through 648 public Facebook pages which identify themselves as\nproponents (and followers) of far-right Hindutva actors. These pages were\nidentified manually using keyword searches on Facebook and on CrowdTangleand\nclassified as far-right Hindutva pages based on page names, page descriptions,\nand discourses shared on these pages. We employ state-of-the-art, open-source\nXLM-T multilingual transformer-based language models to perform sentiment and\nhate speech analysis of the textual contents shared on these pages over a\nperiod of 5.5 years. The result shows the statistical distributions of the\npredicted sentiment and the hate speech labels; top actors, and top page\ncategories. We further discuss the benchmark performances and limitations of\nthese pre-trained language models.\n",
                "链接": "https://arxiv.org/abs/2301.13668"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于NLP领域的持续性学习论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找近六个月工具学习评测数据集的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "7232",
                "标题": "Automated Identification of Toxic Code Reviews Using ToxiCR",
                "作者": " Jaydeb Sarker,  Asif Kamal Turzo,  Ming Dong,  Amiangshu Bosu",
                "发布日期": "2023-02-09",
                "摘要": "  Toxic conversations during software development interactions may have serious\nrepercussions on a Free and Open Source Software (FOSS) development project.\nFor example, victims of toxic conversations may become afraid to express\nthemselves, therefore get demotivated, and may eventually leave the project.\nAutomated filtering of toxic conversations may help a FOSS community to\nmaintain healthy interactions among its members. However, off-the-shelf\ntoxicity detectors perform poorly on Software Engineering (SE) datasets, such\nas one curated from code review comments. To encounter this challenge, we\npresent ToxiCR, a supervised learning-based toxicity identification tool for\ncode review interactions. ToxiCR includes a choice to select one of the ten\nsupervised learning algorithms, an option to select text vectorization\ntechniques, eight preprocessing steps, and a large-scale labeled dataset of\n19,571 code review comments. Two out of those eight preprocessing steps are SE\ndomain specific. With our rigorous evaluation of the models with various\ncombinations of preprocessing steps and vectorization techniques, we have\nidentified the best combination for our dataset that boosts 95.8% accuracy and\n88.9% F1 score. ToxiCR significantly outperforms existing toxicity detectors on\nour dataset. We have released our dataset, pre-trained models, evaluation\nresults, and source code publicly available at:\nhttps://github.com/WSU-SEAL/ToxiCR\n",
                "链接": "https://arxiv.org/abs/2202.13056"
            },
            {
                "文章ID": "105659",
                "标题": "Tool-Augmented Reward Modeling",
                "作者": " Lei Li,  Yekun Chai,  Shuohuan Wang,  Yu Sun,  Hao Tian,  Ningyu Zhang,  Hua Wu",
                "发布日期": "2023-10-03",
                "摘要": "  Reward modeling (a.k.a., preference modeling) is instrumental for aligning\nlarge language models with human preferences, particularly within the context\nof reinforcement learning from human feedback (RLHF). While conventional reward\nmodels (RMs) have exhibited remarkable scalability, they oft struggle with\nfundamental functionality such as arithmetic computation, code execution, and\nfactual lookup. In this paper, we propose a tool-augmented preference modeling\napproach, named \\name, to address these limitations by empowering RMs with\naccess to external environments, including calculators and search engines. This\napproach not only fosters synergy between tool utilization and reward grading\nbut also enhances interpretive capacity and scoring reliability. Our study\ndelves into the integration of external tools into RMs, enabling them to\ninteract with diverse external sources and construct task-specific tool\nengagement and reasoning traces in an autoregressive manner. We validate our\napproach across a wide range of domains, incorporating seven distinct external\ntools. Our experimental results demonstrate a noteworthy overall improvement of\n17.7% across eight tasks in preference ranking. Furthermore, our approach\noutperforms Gopher 280B by 7.3% on TruthfulQA task in zero-shot evaluation. In\nhuman evaluations, RLHF trained with Themis attains an average win rate of 32%\nwhen compared to baselines across four distinct tasks. Additionally, we provide\na comprehensive collection of tool-related RM datasets, incorporating data from\nseven distinct tool APIs, totaling 15,000 instances. We anticipate that this\npublicly available dataset will facilitate and inspire further research\nadvancements in the field.\n",
                "链接": "https://arxiv.org/abs/2310.01045"
            },
            {
                "文章ID": "77407",
                "标题": "CREMP: Conformer-Rotamer Ensembles of Macrocyclic Peptides for Machine\n  Learning",
                "作者": " Colin A. Grambow,  Hayley Weir,  Christian N. Cunningham,  Tommaso Biancalani,  Kangway V. Chuang",
                "发布日期": "2023-05-16",
                "摘要": "  Computational and machine learning approaches to model the conformational\nlandscape of macrocyclic peptides have the potential to enable rational design\nand optimization. However, accurate, fast, and scalable methods for modeling\nmacrocycle geometries remain elusive. Recent deep learning approaches have\nsignificantly accelerated protein structure prediction and the generation of\nsmall-molecule conformational ensembles, yet similar progress has not been made\nfor macrocyclic peptides due to their unique properties. Here, we introduce\nCREMP, a resource generated for the rapid development and evaluation of machine\nlearning models for macrocyclic peptides. CREMP contains 36,198 unique\nmacrocyclic peptides and their high-quality structural ensembles generated\nusing the Conformer-Rotamer Ensemble Sampling Tool (CREST). Altogether, this\nnew dataset contains nearly 31.3 million unique macrocycle geometries, each\nannotated with energies derived from semi-empirical extended tight-binding\n(xTB) DFT calculations. We anticipate that this dataset will enable the\ndevelopment of machine learning models that can improve peptide design and\noptimization for novel therapeutics.\n",
                "链接": "https://arxiv.org/abs/2305.08057"
            },
            {
                "文章ID": "88537",
                "标题": "Surgical Phase and Instrument Recognition: How to identify appropriate\n  Dataset Splits",
                "作者": " Georgii Kostiuchik,  Lalith Sharan,  Benedikt Mayer,  Ivo Wolf,  Bernhard Preim,  Sandy Engelhardt",
                "发布日期": "2023-11-01",
                "摘要": "  Purpose: Machine learning models can only be reliably evaluated if training,\nvalidation, and test data splits are representative and not affected by the\nabsence of classes of interest. Surgical workflow and instrument recognition\ntasks are complicated in this manner, because of heavy data imbalances\nresulting from different lengths of phases and their erratic occurrences.\nFurthermore, the issue becomes difficult as sub-properties that help define\nphases, like instrument (co-)occurrence, are usually not considered when\ndefining the split. We argue that such sub-properties must be equally\nconsidered.\n  Methods: This work presents a publicly available data visualization tool that\nenables interactive exploration of dataset splits for surgical phase and\ninstrument recognition. It focuses on the visualization of the occurrence of\nphases, phase transitions, instruments, and instrument combinations across\nsets. Particularly, it facilitates the assessment and identification of\nsub-optimal dataset splits.\n  Results: We performed an analysis of common Cholec80 dataset splits using the\nproposed application and were able to uncover phase transitions and\ncombinations of instruments that were not represented in one of the sets.\nAdditionally, we outlined possible improvements to the splits. A user study\nwith ten participants demonstrated the ability of participants to solve a\nselection of data exploration tasks using the proposed application.\n  Conclusion: In highly unbalanced class distributions, special care should be\ntaken with respect to the selection of an appropriate dataset split. Our\ninteractive data visualization tool presents a promising approach for the\nassessment of dataset splits for surgical phase and instrument recognition.\nEvaluation results show that it can enhance the development of machine learning\nmodels. The application is available at https://cardio-ai.github.io/endovis-ml/ .\n",
                "链接": "https://arxiv.org/abs/2306.16879"
            },
            {
                "文章ID": "118037",
                "标题": "Introducing SSBD+ Dataset with a Convolutional Pipeline for detecting\n  Self-Stimulatory Behaviours in Children using raw videos",
                "作者": " Vaibhavi Lokegaonkar,  Vijay Jaisankar,  Pon Deepika,  Madhav Rao,  T K Srikanth,  Sarbani Mallick,  Manjit Sodhi",
                "发布日期": "2023-11-28",
                "摘要": "  Conventionally, evaluation for the diagnosis of Autism spectrum disorder is\ndone by a trained specialist through questionnaire-based formal assessments and\nby observation of behavioral cues under various settings to capture the early\nwarning signs of autism. These evaluation techniques are highly subjective and\ntheir accuracy relies on the experience of the specialist. In this regard,\nmachine learning-based methods for automated capturing of early signs of autism\nfrom the recorded videos of the children is a promising alternative. In this\npaper, the authors propose a novel pipelined deep learning architecture to\ndetect certain self-stimulatory behaviors that help in the diagnosis of autism\nspectrum disorder (ASD). The authors also supplement their tool with an\naugmented version of the Self Stimulatory Behavior Dataset (SSBD) and also\npropose a new label in SSBD Action detection: no-class. The deep learning model\nwith the new dataset is made freely available for easy adoption to the\nresearchers and developers community. An overall accuracy of around 81% was\nachieved from the proposed pipeline model that is targeted for real-time and\nhands-free automated diagnosis. All of the source code, data, licenses of use,\nand other relevant material is made freely available in\nhttps://github.com/sarl-iiitb/\n",
                "链接": "https://arxiv.org/abs/2311.15072"
            },
            {
                "文章ID": "99437",
                "标题": "Text-to-OverpassQL: A Natural Language Interface for Complex Geodata\n  Querying of OpenStreetMap",
                "作者": " Michael Staniek,  Raphael Schumann,  Maike Züfle,  Stefan Riezler",
                "发布日期": "2023-08-31",
                "摘要": "  We present Text-to-OverpassQL, a task designed to facilitate a natural\nlanguage interface for querying geodata from OpenStreetMap (OSM). The Overpass\nQuery Language (OverpassQL) allows users to formulate complex database queries\nand is widely adopted in the OSM ecosystem. Generating Overpass queries from\nnatural language input serves multiple use-cases. It enables novice users to\nutilize OverpassQL without prior knowledge, assists experienced users with\ncrafting advanced queries, and enables tool-augmented large language models to\naccess information stored in the OSM database. In order to assess the\nperformance of current sequence generation models on this task, we propose\nOverpassNL, a dataset of 8,352 queries with corresponding natural language\ninputs. We further introduce task specific evaluation metrics and ground the\nevaluation of the Text-to-OverpassQL task by executing the queries against the\nOSM database. We establish strong baselines by finetuning sequence-to-sequence\nmodels and adapting large language models with in-context examples. The\ndetailed evaluation reveals strengths and weaknesses of the considered learning\nstrategies, laying the foundations for further research into the\nText-to-OverpassQL task.\n",
                "链接": "https://arxiv.org/abs/2308.16060"
            },
            {
                "文章ID": "103061",
                "标题": "CMRxRecon: An open cardiac MRI dataset for the competition of\n  accelerated image reconstruction",
                "作者": " Chengyan Wang,  Jun Lyu,  Shuo Wang,  Chen Qin,  Kunyuan Guo,  Xinyu Zhang,  Xiaotong Yu,  Yan Li,  Fanwen Wang,  Jianhua Jin,  Zhang Shi,  Ziqiang Xu,  Yapeng Tian,  Sha Hua,  Zhensen Chen,  Meng Liu,  Mengting Sun,  Xutong Kuang,  Kang Wang,  Haoran Wang,  Hao Li,  Yinghua Chu,  Guang Yang,  Wenjia Bai,  Xiahai Zhuang,  He Wang,  Jing Qin,  Xiaobo Qu",
                "发布日期": "2023-09-21",
                "摘要": "  Cardiac magnetic resonance imaging (CMR) has emerged as a valuable diagnostic\ntool for cardiac diseases. However, a limitation of CMR is its slow imaging\nspeed, which causes patient discomfort and introduces artifacts in the images.\nThere has been growing interest in deep learning-based CMR imaging algorithms\nthat can reconstruct high-quality images from highly under-sampled k-space\ndata. However, the development of deep learning methods requires large training\ndatasets, which have not been publicly available for CMR. To address this gap,\nwe released a dataset that includes multi-contrast, multi-view, multi-slice and\nmulti-coil CMR imaging data from 300 subjects. Imaging studies include cardiac\ncine and mapping sequences. Manual segmentations of the myocardium and chambers\nof all the subjects are also provided within the dataset. Scripts of\nstate-of-the-art reconstruction algorithms were also provided as a point of\nreference. Our aim is to facilitate the advancement of state-of-the-art CMR\nimage reconstruction by introducing standardized evaluation criteria and making\nthe dataset freely accessible to the research community. Researchers can access\nthe dataset at https://www.synapse.org/#!Synapse:syn51471091/wiki/.\n",
                "链接": "https://arxiv.org/abs/2309.10836"
            },
            {
                "文章ID": "105091",
                "标题": "nnSAM: Plug-and-play Segment Anything Model Improves nnUNet Performance",
                "作者": " Yunxiang Li,  Bowen Jing,  Zihan Li,  Jing Wang,  You Zhang",
                "发布日期": "2023-10-04",
                "摘要": "  The recent developments of foundation models in computer vision, especially\nthe Segment Anything Model (SAM), allow scalable and domain-agnostic image\nsegmentation to serve as a general-purpose segmentation tool. In parallel, the\nfield of medical image segmentation has benefited significantly from\nspecialized neural networks like the nnUNet, which is trained on\ndomain-specific datasets and can automatically configure the network to tailor\nto specific segmentation challenges. To combine the advantages of foundation\nmodels and domain-specific models, we present nnSAM, which synergistically\nintegrates the SAM model with the nnUNet model to achieve more accurate and\nrobust medical image segmentation. The nnSAM model leverages the powerful and\nrobust feature extraction capabilities of SAM, while harnessing the automatic\nconfiguration capabilities of nnUNet to promote dataset-tailored learning. Our\ncomprehensive evaluation of nnSAM model on different sizes of training samples\nshows that it allows few-shot learning, which is highly relevant for medical\nimage segmentation where high-quality, annotated data can be scarce and costly\nto obtain. By melding the strengths of both its predecessors, nnSAM positions\nitself as a potential new benchmark in medical image segmentation, offering a\ntool that combines broad applicability with specialized efficiency. The code is\navailable at https://github.com/Kent0n-Li/Medical-Image-Segmentation.\n",
                "链接": "https://arxiv.org/abs/2309.16967"
            },
            {
                "文章ID": "36360",
                "标题": "Benchmarking Multimodal Variational Autoencoders: CdSprites+ Dataset and\n  Toolkit",
                "作者": " Gabriela Sejnova,  Michal Vavrecka,  Karla Stepanova",
                "发布日期": "2023-11-27",
                "摘要": "  Multimodal Variational Autoencoders (VAEs) have been the subject of intense\nresearch in the past years as they can integrate multiple modalities into a\njoint representation and can thus serve as a promising tool for both data\nclassification and generation. Several approaches toward multimodal VAE\nlearning have been proposed so far, their comparison and evaluation have\nhowever been rather inconsistent. One reason is that the models differ at the\nimplementation level, another problem is that the datasets commonly used in\nthese cases were not initially designed to evaluate multimodal generative\nmodels. This paper addresses both mentioned issues. First, we propose a toolkit\nfor systematic multimodal VAE training and comparison. The toolkit currently\ncomprises 4 existing multimodal VAEs and 6 commonly used benchmark datasets\nalong with instructions on how to easily add a new model or a dataset. Second,\nwe present a disentangled bimodal dataset designed to comprehensively evaluate\nthe joint generation and cross-generation capabilities across multiple\ndifficulty levels. We demonstrate the utility of our dataset by comparing the\nimplemented state-of-the-art models.\n",
                "链接": "https://arxiv.org/abs/2209.03048"
            },
            {
                "文章ID": "40384",
                "标题": "Automated Medical Device Display Reading Using Deep Learning Object\n  Detection",
                "作者": " Lucas P. Moreira",
                "发布日期": "2022-10-05",
                "摘要": "  Telemedicine and mobile health applications, especially during the quarantine\nimposed by the covid-19 pandemic, led to an increase on the need of\ntransferring health monitor readings from patients to specialists. Considering\nthat most home medical devices use seven-segment displays, an automatic display\nreading algorithm should provide a more reliable tool for remote health care.\nThis work proposes an end-to-end method for detection and reading seven-segment\ndisplays from medical devices based on deep learning object detection models.\nTwo state of the art model families, EfficientDet and EfficientDet-lite,\npreviously trained with the MS-COCO dataset, were fine-tuned on a dataset\ncomprised by medical devices photos taken with mobile digital cameras, to\nsimulate real case applications. Evaluation of the trained model show high\nefficiency, where all models achieved more than 98% of detection precision and\nmore than 98% classification accuracy, with model EfficientDet-lite1 showing\n100% detection precision and 100% correct digit classification for a test set\nof 104 images and 438 digits.\n",
                "链接": "https://arxiv.org/abs/2210.01325"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下工具评测相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "86386",
                "标题": "TOBY: A Tool for Exploring Data in Academic Survey Papers",
                "作者": " Tathagata Chakraborti,  Jungkoo Kang,  Christian Muise,  Sarath Sreedharan,  Michael Walker,  Daniel Szafir,  Tom Williams",
                "发布日期": "2023-06-21",
                "摘要": "  This paper describes TOBY, a visualization tool that helps a user explore the\ncontents of an academic survey paper. The visualization consists of four\ncomponents: a hierarchical view of taxonomic data in the survey, a document\nsimilarity view in the space of taxonomic classes, a network view of citations,\nand a new paper recommendation tool. In this paper, we will discuss these\nfeatures in the context of three separate deployments of the tool.\n",
                "链接": "https://arxiv.org/abs/2306.10051"
            },
            {
                "文章ID": "50847",
                "标题": "Bayesian Network Models of Causal Interventions in Healthcare Decision\n  Making: Literature Review and Software Evaluation",
                "作者": " Artem Velikzhanin,  Benjie Wang,  Marta Kwiatkowska",
                "发布日期": "2022-11-29",
                "摘要": "  This report summarises the outcomes of a systematic literature search to\nidentify Bayesian network models used to support decision making in healthcare.\nAfter describing the search methodology, the selected research papers are\nbriefly reviewed, with the view to identify publicly available models and\ndatasets that are well suited to analysis using the causal interventional\nanalysis software tool developed in Wang B, Lyle C, Kwiatkowska M (2021).\nFinally, an experimental evaluation of applying the software on a selection of\nmodels is carried out and preliminary results are reported.\n",
                "链接": "https://arxiv.org/abs/2211.15258"
            },
            {
                "文章ID": "90192",
                "标题": "A Semi-Automated Solution Approach Selection Tool for Any Use Case via\n  Scopus and OpenAI: a Case Study for AI/ML in Oncology",
                "作者": " Deniz Kenan Kılıç,  Alex Elkjær Vasegaard,  Aurélien Desoeuvres,  Peter Nielsen",
                "发布日期": "2023-07-11",
                "摘要": "  In today's vast literature landscape, a manual review is very time-consuming.\nTo address this challenge, this paper proposes a semi-automated tool for\nsolution method review and selection. It caters to researchers, practitioners,\nand decision-makers while serving as a benchmark for future work. The tool\ncomprises three modules: (1) paper selection and scoring, using a keyword\nselection scheme to query Scopus API and compute relevancy; (2) solution method\nextraction in papers utilizing OpenAI API; (3) sensitivity analysis and\npost-analyzes. It reveals trends, relevant papers, and methods. AI in the\noncology case study and several use cases are presented with promising results,\ncomparing the tool to manual ground truth.\n",
                "链接": "https://arxiv.org/abs/2307.04573"
            },
            {
                "文章ID": "112854",
                "标题": "ACL Anthology Helper: A Tool to Retrieve and Manage Literature from ACL\n  Anthology",
                "作者": " Chen Tang,  Frank Guerin,  Chenghua Lin",
                "发布日期": "2023-11-01",
                "摘要": "  The ACL Anthology is an online repository that serves as a comprehensive\ncollection of publications in the field of natural language processing (NLP)\nand computational linguistics (CL). This paper presents a tool called ``ACL\nAnthology Helper''. It automates the process of parsing and downloading papers\nalong with their meta-information, which are then stored in a local MySQL\ndatabase. This allows for efficient management of the local papers using a wide\nrange of operations, including \"where,\" \"group,\" \"order,\" and more. By\nproviding over 20 operations, this tool significantly enhances the retrieval of\nliterature based on specific conditions. Notably, this tool has been\nsuccessfully utilised in writing a survey paper (Tang et al.,2022a). By\nintroducing the ACL Anthology Helper, we aim to enhance researchers' ability to\neffectively access and organise literature from the ACL Anthology. This tool\noffers a convenient solution for researchers seeking to explore the ACL\nAnthology's vast collection of publications while allowing for more targeted\nand efficient literature retrieval.\n",
                "链接": "https://arxiv.org/abs/2310.20467"
            },
            {
                "文章ID": "83968",
                "标题": "SciLit: A Platform for Joint Scientific Literature Discovery,\n  Summarization and Citation Generation",
                "作者": " Nianlong Gu,  Richard H. R. Hahnloser",
                "发布日期": "2023-11-07",
                "摘要": "  Scientific writing involves retrieving, summarizing, and citing relevant\npapers, which can be time-consuming processes in large and rapidly evolving\nfields. By making these processes inter-operable, natural language processing\n(NLP) provides opportunities for creating end-to-end assistive writing tools.\nWe propose SciLit, a pipeline that automatically recommends relevant papers,\nextracts highlights, and suggests a reference sentence as a citation of a\npaper, taking into consideration the user-provided context and keywords. SciLit\nefficiently recommends papers from large databases of hundreds of millions of\npapers using a two-stage pre-fetching and re-ranking literature search system\nthat flexibly deals with addition and removal of a paper database. We provide a\nconvenient user interface that displays the recommended papers as extractive\nsummaries and that offers abstractively-generated citing sentences which are\naligned with the provided context and which mention the chosen keyword(s). Our\nassistive tool for literature discovery and scientific writing is available at\nhttps://scilit.vercel.app\n",
                "链接": "https://arxiv.org/abs/2306.03535"
            },
            {
                "文章ID": "103034",
                "标题": "Interactive Distillation of Large Single-Topic Corpora of Scientific\n  Papers",
                "作者": " Nicholas Solovyev,  Ryan Barron,  Manish Bhattarai,  Maksim E. Eren,  Kim O. Rasmussen,  Boian S. Alexandrov",
                "发布日期": "2023-09-20",
                "摘要": "  Highly specific datasets of scientific literature are important for both\nresearch and education. However, it is difficult to build such datasets at\nscale. A common approach is to build these datasets reductively by applying\ntopic modeling on an established corpus and selecting specific topics. A more\nrobust but time-consuming approach is to build the dataset constructively in\nwhich a subject matter expert (SME) handpicks documents. This method does not\nscale and is prone to error as the dataset grows. Here we showcase a new tool,\nbased on machine learning, for constructively generating targeted datasets of\nscientific literature. Given a small initial \"core\" corpus of papers, we build\na citation network of documents. At each step of the citation network, we\ngenerate text embeddings and visualize the embeddings through dimensionality\nreduction. Papers are kept in the dataset if they are \"similar\" to the core or\nare otherwise pruned through human-in-the-loop selection. Additional insight\ninto the papers is gained through sub-topic modeling using SeNMFk. We\ndemonstrate our new tool for literature review by applying it to two different\nfields in machine learning.\n",
                "链接": "https://arxiv.org/abs/2309.10772"
            },
            {
                "文章ID": "31915",
                "标题": "Deconstructing Self-Supervised Monocular Reconstruction: The Design\n  Decisions that Matter",
                "作者": " Jaime Spencer,  Chris Russell,  Simon Hadfield,  Richard Bowden",
                "发布日期": "2022-12-22",
                "摘要": "  This paper presents an open and comprehensive framework to systematically\nevaluate state-of-the-art contributions to self-supervised monocular depth\nestimation. This includes pretraining, backbone, architectural design choices\nand loss functions. Many papers in this field claim novelty in either\narchitecture design or loss formulation. However, simply updating the backbone\nof historical systems results in relative improvements of 25%, allowing them to\noutperform the majority of existing systems. A systematic evaluation of papers\nin this field was not straightforward. The need to compare like-with-like in\nprevious papers means that longstanding errors in the evaluation protocol are\nubiquitous in the field. It is likely that many papers were not only optimized\nfor particular datasets, but also for errors in the data and evaluation\ncriteria. To aid future research in this area, we release a modular codebase\n(https://github.com/jspenmar/monodepth_benchmark), allowing for easy evaluation\nof alternate design decisions against corrected data and evaluation criteria.\nWe re-implement, validate and re-evaluate 16 state-of-the-art contributions and\nintroduce a new dataset (SYNS-Patches) containing dense outdoor depth maps in a\nvariety of both natural and urban scenes. This allows for the computation of\ninformative metrics in complex regions such as depth boundaries.\n",
                "链接": "https://arxiv.org/abs/2208.01489"
            },
            {
                "文章ID": "74641",
                "标题": "The Intended Uses of Automated Fact-Checking Artefacts: Why, How and Who",
                "作者": " Michael Schlichtkrull,  Nedjma Ousidhoum,  Andreas Vlachos",
                "发布日期": "2023-11-09",
                "摘要": "  Automated fact-checking is often presented as an epistemic tool that\nfact-checkers, social media consumers, and other stakeholders can use to fight\nmisinformation. Nevertheless, few papers thoroughly discuss how. We document\nthis by analysing 100 highly-cited papers, and annotating epistemic elements\nrelated to intended use, i.e., means, ends, and stakeholders. We find that\nnarratives leaving out some of these aspects are common, that many papers\npropose inconsistent means and ends, and that the feasibility of suggested\nstrategies rarely has empirical backing. We argue that this vagueness actively\nhinders the technology from reaching its goals, as it encourages overclaiming,\nlimits criticism, and prevents stakeholder feedback. Accordingly, we provide\nseveral recommendations for thinking and writing about the use of fact-checking\nartefacts.\n",
                "链接": "https://arxiv.org/abs/2304.14238"
            },
            {
                "文章ID": "34033",
                "标题": "SimLDA: A tool for topic model evaluation",
                "作者": " Rebecca M. C. Taylor,  Johan A. du Preez",
                "发布日期": "2022-08-22",
                "摘要": "  Variational Bayes (VB) applied to latent Dirichlet allocation (LDA) has\nbecome the most popular algorithm for aspect modeling. While sufficiently\nsuccessful in text topic extraction from large corpora, VB is less successful\nin identifying aspects in the presence of limited data. We present a novel\nvariational message passing algorithm as applied to Latent Dirichlet Allocation\n(LDA) and compare it with the gold standard VB and collapsed Gibbs sampling. In\nsituations where marginalisation leads to non-conjugate messages, we use ideas\nfrom sampling to derive approximate update equations. In cases where conjugacy\nholds, Loopy Belief update (LBU) (also known as Lauritzen-Spiegelhalter) is\nused. Our algorithm, ALBU (approximate LBU), has strong similarities with\nVariational Message Passing (VMP) (which is the message passing variant of VB).\nTo compare the performance of the algorithms in the presence of limited data,\nwe use data sets consisting of tweets and news groups. Using coherence measures\nwe show that ALBU learns latent distributions more accurately than does VB,\nespecially for smaller data sets.\n",
                "链接": "https://arxiv.org/abs/2208.09299"
            },
            {
                "文章ID": "51717",
                "标题": "Improving astroBERT using Semantic Textual Similarity",
                "作者": " Felix Grezes,  Thomas Allen,  Sergi Blanco-Cuaresma,  Alberto Accomazzi,  Michael J. Kurtz,  Golnaz Shapurian,  Edwin Henneken,  Carolyn S. Grant,  Donna M. Thompson,  Timothy W. Hostetler,  Matthew R. Templeton,  Kelly E. Lockhart,  Shinyi Chen,  Jennifer Koch,  Taylor Jacovich,  Pavlos Protopapas",
                "发布日期": "2022-12-02",
                "摘要": "  The NASA Astrophysics Data System (ADS) is an essential tool for researchers\nthat allows them to explore the astronomy and astrophysics scientific\nliterature, but it has yet to exploit recent advances in natural language\nprocessing. At ADASS 2021, we introduced astroBERT, a machine learning language\nmodel tailored to the text used in astronomy papers in ADS. In this work we:\n  - announce the first public release of the astroBERT language model;\n  - show how astroBERT improves over existing public language models on\nastrophysics specific tasks;\n  - and detail how ADS plans to harness the unique structure of scientific\npapers, the citation graph and citation context, to further improve astroBERT.\n",
                "链接": "https://arxiv.org/abs/2212.00744"
            }
        ]
    },
    {
        "question": {
            "question": "大模型在游戏方面的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "102747",
                "标题": "MindAgent: Emergent Gaming Interaction",
                "作者": " Ran Gong,  Qiuyuan Huang,  Xiaojian Ma,  Hoi Vo,  Zane Durante,  Yusuke Noda,  Zilong Zheng,  Song-Chun Zhu,  Demetri Terzopoulos,  Li Fei-Fei,  Jianfeng Gao",
                "发布日期": "2023-09-20",
                "摘要": "  Large Language Models (LLMs) have the capacity of performing complex\nscheduling in a multi-agent system and can coordinate these agents into\ncompleting sophisticated tasks that require extensive collaboration. However,\ndespite the introduction of numerous gaming frameworks, the community has\ninsufficient benchmarks towards building general multi-agents collaboration\ninfrastructure that encompass both LLM and human-NPCs collaborations. In this\nwork, we propose a novel infrastructure - MindAgent - to evaluate planning and\ncoordination emergent capabilities for gaming interaction. In particular, our\ninfrastructure leverages existing gaming framework, to i) require understanding\nof the coordinator for a multi-agent system, ii) collaborate with human players\nvia un-finetuned proper instructions, and iii) establish an in-context learning\non few-shot prompt with feedback. Furthermore, we introduce CUISINEWORLD, a new\ngaming scenario and related benchmark that dispatch a multi-agent collaboration\nefficiency and supervise multiple agents playing the game simultaneously. We\nconduct comprehensive evaluations with new auto-metric CoS for calculating the\ncollaboration efficiency. Finally, our infrastructure can be deployed into\nreal-world gaming scenarios in a customized VR version of CUISINEWORLD and\nadapted in existing broader Minecraft gaming domain. We hope our findings on\nLLMs and the new infrastructure for general-purpose scheduling and coordination\ncan help shed light on how such skills can be obtained by learning from large\nlanguage corpora.\n",
                "链接": "https://arxiv.org/abs/2309.09971"
            },
            {
                "文章ID": "12922",
                "标题": "Perceptual Quality Assessment of UGC Gaming Videos",
                "作者": " Xiangxu Yu,  Zhengzhong Tu,  Neil Birkbeck,  Yilin Wang,  Balu Adsumilli,  Alan C. Bovik",
                "发布日期": "2022-04-15",
                "摘要": "  In recent years, with the vigorous development of the video game industry,\nthe proportion of gaming videos on major video websites like YouTube has\ndramatically increased. However, relatively little research has been done on\nthe automatic quality prediction of gaming videos, especially on those that\nfall in the category of \"User-Generated-Content\" (UGC). Since current leading\ngeneral-purpose Video Quality Assessment (VQA) models do not perform well on\nthis type of gaming videos, we have created a new VQA model specifically\ndesigned to succeed on UGC gaming videos, which we call the Gaming Video\nQuality Predictor (GAME-VQP). GAME-VQP successfully predicts the unique\nstatistical characteristics of gaming videos by drawing upon features designed\nunder modified natural scene statistics models, combined with gaming specific\nfeatures learned by a Convolution Neural Network. We study the performance of\nGAME-VQP on a very recent large UGC gaming video database called\nLIVE-YT-Gaming, and find that it both outperforms other mainstream general VQA\nmodels as well as VQA models specifically designed for gaming videos. The new\nmodel will be made public after paper being accepted.\n",
                "链接": "https://arxiv.org/abs/2204.00128"
            },
            {
                "文章ID": "11430",
                "标题": "Subjective and Objective Analysis of Streamed Gaming Videos",
                "作者": " Xiangxu Yu,  Zhenqiang Ying,  Neil Birkbeck,  Yilin Wang,  Balu Adsumilli,  Alan C. Bovik",
                "发布日期": "2022-03-25",
                "摘要": "  The rising popularity of online User-Generated-Content (UGC) in the form of\nstreamed and shared videos, has hastened the development of perceptual Video\nQuality Assessment (VQA) models, which can be used to help optimize their\ndelivery. Gaming videos, which are a relatively new type of UGC videos, are\ncreated when skilled gamers post videos of their gameplay. These kinds of\nscreenshots of UGC gameplay videos have become extremely popular on major\nstreaming platforms like YouTube and Twitch. Synthetically-generated gaming\ncontent presents challenges to existing VQA algorithms, including those based\non natural scene/video statistics models. Synthetically generated gaming\ncontent presents different statistical behavior than naturalistic videos. A\nnumber of studies have been directed towards understanding the perceptual\ncharacteristics of professionally generated gaming videos arising in gaming\nvideo streaming, online gaming, and cloud gaming. However, little work has been\ndone on understanding the quality of UGC gaming videos, and how it can be\ncharacterized and predicted. Towards boosting the progress of gaming video VQA\nmodel development, we conducted a comprehensive study of subjective and\nobjective VQA models on UGC gaming videos. To do this, we created a novel UGC\ngaming video resource, called the LIVE-YouTube Gaming video quality\n(LIVE-YT-Gaming) database, comprised of 600 real UGC gaming videos. We\nconducted a subjective human study on this data, yielding 18,600 human quality\nratings recorded by 61 human subjects. We also evaluated a number of\nstate-of-the-art (SOTA) VQA models on the new database, including a new one,\ncalled GAME-VQP, based on both natural video statistics and CNN-learned\nfeatures. To help support work in this field, we are making the new\nLIVE-YT-Gaming Database, publicly available through the link:\nhttps://live.ece.utexas.edu/research/LIVE-YT-Gaming/index.html .\n",
                "链接": "https://arxiv.org/abs/2203.12824"
            },
            {
                "文章ID": "81335",
                "标题": "Study of Subjective and Objective Quality Assessment of Mobile Cloud\n  Gaming Videos",
                "作者": " Avinab Saha,  Yu-Chih Chen,  Chase Davis,  Bo Qiu,  Xiaoming Wang,  Rahul Gowda,  Ioannis Katsavounidis,  Alan C. Bovik",
                "发布日期": "2023-06-28",
                "摘要": "  We present the outcomes of a recent large-scale subjective study of Mobile\nCloud Gaming Video Quality Assessment (MCG-VQA) on a diverse set of gaming\nvideos. Rapid advancements in cloud services, faster video encoding\ntechnologies, and increased access to high-speed, low-latency wireless internet\nhave all contributed to the exponential growth of the Mobile Cloud Gaming\nindustry. Consequently, the development of methods to assess the quality of\nreal-time video feeds to end-users of cloud gaming platforms has become\nincreasingly important. However, due to the lack of a large-scale public Mobile\nCloud Gaming Video dataset containing a diverse set of distorted videos with\ncorresponding subjective scores, there has been limited work on the development\nof MCG-VQA models. Towards accelerating progress towards these goals, we\ncreated a new dataset, named the LIVE-Meta Mobile Cloud Gaming (LIVE-Meta-MCG)\nvideo quality database, composed of 600 landscape and portrait gaming videos,\non which we collected 14,400 subjective quality ratings from an in-lab\nsubjective study. Additionally, to demonstrate the usefulness of the new\nresource, we benchmarked multiple state-of-the-art VQA algorithms on the\ndatabase. The new database will be made publicly available on our website:\n\\url{https://live.ece.utexas.edu/research/LIVE-Meta-Mobile-Cloud-Gaming/index.html}\n",
                "链接": "https://arxiv.org/abs/2305.17260"
            },
            {
                "文章ID": "75621",
                "标题": "GAMIVAL: Video Quality Prediction on Mobile Cloud Gaming Content",
                "作者": " Yu-Chih Chen,  Avinab Saha,  Chase Davis,  Bo Qiu,  Xiaoming Wang,  Rahul Gowda,  Ioannis Katsavounidis,  Alan C. Bovik",
                "发布日期": "2023-08-31",
                "摘要": "  The mobile cloud gaming industry has been rapidly growing over the last\ndecade. When streaming gaming videos are transmitted to customers' client\ndevices from cloud servers, algorithms that can monitor distorted video quality\nwithout having any reference video available are desirable tools. However,\ncreating No-Reference Video Quality Assessment (NR VQA) models that can\naccurately predict the quality of streaming gaming videos rendered by computer\ngraphics engines is a challenging problem, since gaming content generally\ndiffers statistically from naturalistic videos, often lacks detail, and\ncontains many smooth regions. Until recently, the problem has been further\ncomplicated by the lack of adequate subjective quality databases of mobile\ngaming content. We have created a new gaming-specific NR VQA model called the\nGaming Video Quality Evaluator (GAMIVAL), which combines and leverages the\nadvantages of spatial and temporal gaming distorted scene statistics models, a\nneural noise model, and deep semantic features. Using a support vector\nregression (SVR) as a regressor, GAMIVAL achieves superior performance on the\nnew LIVE-Meta Mobile Cloud Gaming (LIVE-Meta MCG) video quality database.\n",
                "链接": "https://arxiv.org/abs/2305.02422"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "122132",
                "标题": "Scaling Culture in Blockchain Gaming: Generative AI and Pseudonymous\n  Engagement",
                "作者": " Henrik Axelsen,  Sebastian Axelsen,  Valdemar Licht,  Jason Potts",
                "发布日期": "2023-12-14",
                "摘要": "  Managing rapidly growing decentralized gaming communities brings unique\nchallenges at the nexus of cultural economics and technology. This paper\nintroduces a streamlined analytical framework that utilizes Large Language\nModels (LLMs), in this instance open-access generative pre-trained transformer\n(GPT) models, offering an efficient solution with deeper insights into\ncommunity dynamics. The framework aids moderators in identifying pseudonymous\nactor intent, moderating toxic behavior, rewarding desired actions to avoid\nunintended consequences of blockchain-based gaming, and gauging community\nsentiment as communities venture into metaverse platforms and plan for\nhypergrowth. This framework strengthens community controls, eases onboarding,\nand promotes a common moral mission across communities while reducing agency\ncosts by 95 pct. Highlighting the transformative role of generative AI, the\npaper emphasizes its potential to redefine the cost of cultural production. It\nshowcases the utility of GPTs in digital community management, expanding their\nimplications in cultural economics and transmedia storytelling.\n",
                "链接": "https://arxiv.org/abs/2312.07693"
            },
            {
                "文章ID": "55440",
                "标题": "Measuring and Estimating Key Quality Indicators in Cloud Gaming services",
                "作者": " Carlos Baena,  O. S. Peñaherrera-Pulla,  Raquel Barco,  Sergio Fortes",
                "发布日期": "2023-05-11",
                "摘要": "  User equipment is one of the main bottlenecks facing the gaming industry\nnowadays. The extremely realistic games which are currently available trigger\nhigh computational requirements of the user devices to run games. As a\nconsequence, the game industry has proposed the concept of Cloud Gaming, a\nparadigm that improves gaming experience in reduced hardware devices. To this\nend, games are hosted on remote servers, relegating users' devices to play only\nthe role of a peripheral for interacting with the game. However, this paradigm\noverloads the communication links connecting the users with the cloud.\nTherefore, service experience becomes highly dependent on network connectivity.\nTo overcome this, Cloud Gaming will be boosted by the promised performance of\n5G and future 6G networks, together with the flexibility provided by mobility\nin multi-RAT scenarios, such as WiFi. In this scope, the present work proposes\na framework for measuring and estimating the main E2E metrics of the Cloud\nGaming service, namely KQIs. In addition, different machine learning techniques\nare assessed for predicting KQIs related to Cloud Gaming user's experience. To\nthis end, the main key quality indicators (KQIs) of the service such as input\nlag, freeze percent or perceived video frame rate are collected in a real\nenvironment. Based on these, results show that machine learning techniques\nprovide a good estimation of these indicators solely from network-based\nmetrics. This is considered a valuable asset to guide the delivery of Cloud\nGaming services through cellular communications networks even without access to\nthe user's device, as it is expected for telecom operators.\n",
                "链接": "https://arxiv.org/abs/2212.14073"
            },
            {
                "文章ID": "48707",
                "标题": "Reward Gaming in Conditional Text Generation",
                "作者": " Richard Yuanzhe Pang,  Vishakh Padmakumar,  Thibault Sellam,  Ankur P. Parikh,  He He",
                "发布日期": "2023-06-02",
                "摘要": "  To align conditional text generation model outputs with desired behaviors,\nthere has been an increasing focus on training the model using reinforcement\nlearning (RL) with reward functions learned from human annotations. Under this\nframework, we identify three common cases where high rewards are incorrectly\nassigned to undesirable patterns: noise-induced spurious correlation, naturally\noccurring spurious correlation, and covariate shift. We show that even though\nlearned metrics achieve high performance on the distribution of the data used\nto train the reward function, the undesirable patterns may be amplified during\nRL training of the text generation model. While there has been discussion about\nreward gaming in the RL or safety community, in this discussion piece, we would\nlike to highlight reward gaming in the natural language generation (NLG)\ncommunity using concrete conditional text generation examples and discuss\npotential fixes and areas for future work.\n",
                "链接": "https://arxiv.org/abs/2211.08714"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "请找到缓和噪声标签影响的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下文本检索任务上，是否有关于大模型在语义坍缩问题上的研究",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "帮我查找对机器翻译数据集质量进行评估的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大语言模型相关的分析类型的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "119149",
                "标题": "mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large\n  Language Model",
                "作者": " Anwen Hu,  Yaya Shi,  Haiyang Xu,  Jiabo Ye,  Qinghao Ye,  Ming Yan,  Chenliang Li,  Qi Qian,  Ji Zhang,  Fei Huang",
                "发布日期": "2023-12-01",
                "摘要": "  Recently, the strong text creation ability of Large Language Models(LLMs) has\ngiven rise to many tools for assisting paper reading or even writing. However,\nthe weak diagram analysis abilities of LLMs or Multimodal LLMs greatly limit\ntheir application scenarios, especially for scientific academic paper writing.\nIn this work, towards a more versatile copilot for academic paper writing, we\nmainly focus on strengthening the multi-modal diagram analysis ability of\nMultimodal LLMs. By parsing Latex source files of high-quality papers, we\ncarefully build a multi-modal diagram understanding dataset M-Paper. By\naligning diagrams in the paper with related paragraphs, we construct\nprofessional diagram analysis samples for training and evaluation. M-Paper is\nthe first dataset to support joint comprehension of multiple scientific\ndiagrams, including figures and tables in the format of images or Latex codes.\nBesides, to better align the copilot with the user's intention, we introduce\nthe `outline' as the control signal, which could be directly given by the user\nor revised based on auto-generated ones. Comprehensive experiments with a\nstate-of-the-art Mumtimodal LLM demonstrate that training on our dataset shows\nstronger scientific diagram understanding performance, including diagram\ncaptioning, diagram analysis, and outline recommendation. The dataset, code,\nand model are available at\nhttps://github.com/X-PLUG/mPLUG-DocOwl/tree/main/PaperOwl.\n",
                "链接": "https://arxiv.org/abs/2311.18248"
            },
            {
                "文章ID": "101120",
                "标题": "Analysis of Disinformation and Fake News Detection Using Fine-Tuned\n  Large Language Model",
                "作者": " Bohdan M. Pavlyshenko",
                "发布日期": "2023-09-12",
                "摘要": "  The paper considers the possibility of fine-tuning Llama 2 large language\nmodel (LLM) for the disinformation analysis and fake news detection. For\nfine-tuning, the PEFT/LoRA based approach was used. In the study, the model was\nfine-tuned for the following tasks: analysing a text on revealing\ndisinformation and propaganda narratives, fact checking, fake news detection,\nmanipulation analytics, extracting named entities with their sentiments. The\nobtained results show that the fine-tuned Llama 2 model can perform a deep\nanalysis of texts and reveal complex styles and narratives. Extracted\nsentiments for named entities can be considered as predictive features in\nsupervised machine learning models.\n",
                "链接": "https://arxiv.org/abs/2309.04704"
            },
            {
                "文章ID": "94373",
                "标题": "FinVis-GPT: A Multimodal Large Language Model for Financial Chart\n  Analysis",
                "作者": " Ziao Wang,  Yuhang Li,  Junda Wu,  Jaehyeon Soon,  Xiaofeng Zhang",
                "发布日期": "2023-08-04",
                "摘要": "  In this paper, we propose FinVis-GPT, a novel multimodal large language model\n(LLM) specifically designed for financial chart analysis. By leveraging the\npower of LLMs and incorporating instruction tuning and multimodal capabilities,\nFinVis-GPT is capable of interpreting financial charts and providing valuable\nanalysis. To train FinVis-GPT, a financial task oriented dataset was generated\nfor pre-training alignment and instruction tuning, comprising various types of\nfinancial charts and their corresponding descriptions. We evaluate the model\nperformance via several case studies due to the time limit, and the promising\nresults demonstrated that FinVis-GPT is superior in various financial chart\nrelated tasks, including generating descriptions, answering questions and\npredicting future market trends, surpassing existing state-of-the-art\nmultimodal LLMs. The proposed FinVis-GPT serves as a pioneering effort in\nutilizing multimodal LLMs in the finance domain and our generated dataset will\nbe release for public use in the near future to speedup related research.\n",
                "链接": "https://arxiv.org/abs/2308.01430"
            },
            {
                "文章ID": "105266",
                "标题": "A Large Language Model Approach to Educational Survey Feedback Analysis",
                "作者": " Michael J. Parker,  Caitlin Anderson,  Claire Stone,  YeaRim Oh",
                "发布日期": "2023-10-02",
                "摘要": "  This paper assesses the potential for the large language models (LLMs) GPT-4\nand GPT-3.5 to aid in deriving insight from education feedback surveys.\nExploration of LLM use cases in education has focused on teaching and learning,\nwith less exploration of capabilities in education feedback analysis. Survey\nanalysis in education involves goals such as finding gaps in curricula or\nevaluating teachers, often requiring time-consuming manual processing of\ntextual responses. LLMs have the potential to provide a flexible means of\nachieving these goals without specialized machine learning models or\nfine-tuning. We demonstrate a versatile approach to such goals by treating them\nas sequences of natural language processing (NLP) tasks including\nclassification (multi-label, multi-class, and binary), extraction, thematic\nanalysis, and sentiment analysis, each performed by LLM. We apply these\nworkflows to a real-world dataset of 2500 end-of-course survey comments from\nbiomedical science courses, and evaluate a zero-shot approach (i.e., requiring\nno examples or labeled training data) across all tasks, reflecting education\nsettings, where labeled data is often scarce. By applying effective prompting\npractices, we achieve human-level performance on multiple tasks with GPT-4,\nenabling workflows necessary to achieve typical goals. We also show the\npotential of inspecting LLMs' chain-of-thought (CoT) reasoning for providing\ninsight that may foster confidence in practice. Moreover, this study features\ndevelopment of a versatile set of classification categories, suitable for\nvarious course types (online, hybrid, or in-person) and amenable to\ncustomization. Our results suggest that LLMs can be used to derive a range of\ninsights from survey text.\n",
                "链接": "https://arxiv.org/abs/2309.17447"
            },
            {
                "文章ID": "110493",
                "标题": "LUNA: A Model-Based Universal Analysis Framework for Large Language\n  Models",
                "作者": " Da Song,  Xuan Xie,  Jiayang Song,  Derui Zhu,  Yuheng Huang,  Felix Juefei-Xu,  Lei Ma",
                "发布日期": "2023-10-24",
                "摘要": "  Over the past decade, Artificial Intelligence (AI) has had great success\nrecently and is being used in a wide range of academic and industrial fields.\nMore recently, LLMs have made rapid advancements that have propelled AI to a\nnew level, enabling even more diverse applications and industrial domains with\nintelligence, particularly in areas like software engineering and natural\nlanguage processing. Nevertheless, a number of emerging trustworthiness\nconcerns and issues exhibited in LLMs have already recently received much\nattention, without properly solving which the widespread adoption of LLMs could\nbe greatly hindered in practice. The distinctive characteristics of LLMs, such\nas the self-attention mechanism, extremely large model scale, and\nautoregressive generation schema, differ from classic AI software based on CNNs\nand RNNs and present new challenges for quality analysis. Up to the present, it\nstill lacks universal and systematic analysis techniques for LLMs despite the\nurgent industrial demand. Towards bridging this gap, we initiate an early\nexploratory study and propose a universal analysis framework for LLMs, LUNA,\ndesigned to be general and extensible, to enable versatile analysis of LLMs\nfrom multiple quality perspectives in a human-interpretable manner. In\nparticular, we first leverage the data from desired trustworthiness\nperspectives to construct an abstract model as an auxiliary analysis asset,\nwhich is empowered by various abstract model construction methods. To assess\nthe quality of the abstract model, we collect and define a number of evaluation\nmetrics, aiming at both abstract model level and the semantics level. Then, the\nsemantics, which is the degree of satisfaction of the LLM w.r.t. the\ntrustworthiness perspective, is bound to and enriches the abstract model with\nsemantics, which enables more detailed analysis applications for diverse\npurposes.\n",
                "链接": "https://arxiv.org/abs/2310.14211"
            },
            {
                "文章ID": "87693",
                "标题": "Chinese Fine-Grained Financial Sentiment Analysis with Large Language\n  Models",
                "作者": " Yinyu Lan,  Yanru Wu,  Wang Xu,  Weiqiang Feng,  Youhao Zhang",
                "发布日期": "2023-09-18",
                "摘要": "  Entity-level fine-grained sentiment analysis in the financial domain is a\ncrucial subtask of sentiment analysis and currently faces numerous challenges.\nThe primary challenge stems from the lack of high-quality and large-scale\nannotated corpora specifically designed for financial text sentiment analysis,\nwhich in turn limits the availability of data necessary for developing\neffective text processing techniques. Recent advancements in large language\nmodels (LLMs) have yielded remarkable performance in natural language\nprocessing tasks, primarily centered around language pattern matching. In this\npaper, we propose a novel and extensive Chinese fine-grained financial\nsentiment analysis dataset, FinChina SA, for enterprise early warning. We\nthoroughly evaluate and experiment with well-known existing open-source LLMs\nusing our dataset. We firmly believe that our dataset will serve as a valuable\nresource to advance the exploration of real-world financial sentiment analysis\ntasks, which should be the focus of future research. The FinChina SA dataset is\npublicly available at https://github.com/YerayL/FinChina-SA\n",
                "链接": "https://arxiv.org/abs/2306.14096"
            },
            {
                "文章ID": "69238",
                "标题": "Can Large Language Models assist in Hazard Analysis?",
                "作者": " Simon Diemert,  Jens H Weber",
                "发布日期": "2023-03-29",
                "摘要": "  Large Language Models (LLMs), such as GPT-3, have demonstrated remarkable\nnatural language processing and generation capabilities and have been applied\nto a variety tasks, such as source code generation. This paper explores the\npotential of integrating LLMs in the hazard analysis for safety-critical\nsystems, a process which we refer to as co-hazard analysis (CoHA). In CoHA, a\nhuman analyst interacts with an LLM via a context-aware chat session and uses\nthe responses to support elicitation of possible hazard causes. In this\nexperiment, we explore CoHA with three increasingly complex versions of a\nsimple system, using Open AI's ChatGPT service. The quality of ChatGPT's\nresponses were systematically assessed to determine the feasibility of CoHA\ngiven the current state of LLM technology. The results suggest that LLMs may be\nuseful for supporting human analysts performing hazard analysis.\n",
                "链接": "https://arxiv.org/abs/2303.15473"
            },
            {
                "文章ID": "39922",
                "标题": "Family-Based Fingerprint Analysis: A Position Paper",
                "作者": " Carlos Diego Nascimento Damasceno,  Daniel Strüber",
                "发布日期": "2022-10-03",
                "摘要": "  Thousands of vulnerabilities are reported on a monthly basis to security\nrepositories, such as the National Vulnerability Database. Among these\nvulnerabilities, software misconfiguration is one of the top 10 security risks\nfor web applications. With this large influx of vulnerability reports, software\nfingerprinting has become a highly desired capability to discover distinctive\nand efficient signatures and recognize reportedly vulnerable software\nimplementations. Due to the exponential worst-case complexity of fingerprint\nmatching, designing more efficient methods for fingerprinting becomes highly\ndesirable, especially for variability-intensive systems where optional features\nadd another exponential factor to its analysis. This position paper presents\nour vision of a framework that lifts model learning and family-based analysis\nprinciples to software fingerprinting. In this framework, we propose unifying\ndatabases of signatures into a featured finite state machine and using presence\nconditions to specify whether and in which circumstances a given input-output\ntrace is observed. We believe feature-based signatures can aid performance\nimprovements by reducing the size of fingerprints under analysis.\n",
                "链接": "https://arxiv.org/abs/2209.15620"
            },
            {
                "文章ID": "12949",
                "标题": "Effect and Analysis of Large-scale Language Model Rescoring on\n  Competitive ASR Systems",
                "作者": " Takuma Udagawa,  Masayuki Suzuki,  Gakuto Kurata,  Nobuyasu Itoh,  George Saon",
                "发布日期": "2022-08-19",
                "摘要": "  Large-scale language models (LLMs) such as GPT-2, BERT and RoBERTa have been\nsuccessfully applied to ASR N-best rescoring. However, whether or how they can\nbenefit competitive, near state-of-the-art ASR systems remains unexplored. In\nthis study, we incorporate LLM rescoring into one of the most competitive ASR\nbaselines: the Conformer-Transducer model. We demonstrate that consistent\nimprovement is achieved by the LLM's bidirectionality, pretraining, in-domain\nfinetuning and context augmentation. Furthermore, our lexical analysis sheds\nlight on how each of these components may be contributing to the ASR\nperformance.\n",
                "链接": "https://arxiv.org/abs/2204.00212"
            }
        ]
    },
    {
        "question": {
            "question": "查询2022年以来指令遵循数据集构建相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "908",
                "标题": "CI-AVSR: A Cantonese Audio-Visual Speech Dataset for In-car Command\n  Recognition",
                "作者": " Wenliang Dai,  Samuel Cahyawijaya,  Tiezheng Yu,  Elham J. Barezi,  Peng Xu,  Cheuk Tung Shadow Yiu,  Rita Frieske,  Holy Lovenia,  Genta Indra Winata,  Qifeng Chen,  Xiaojuan Ma,  Bertram E. Shi,  Pascale Fung",
                "发布日期": "2022-03-15",
                "摘要": "  With the rise of deep learning and intelligent vehicle, the smart assistant\nhas become an essential in-car component to facilitate driving and provide\nextra functionalities. In-car smart assistants should be able to process\ngeneral as well as car-related commands and perform corresponding actions,\nwhich eases driving and improves safety. However, there is a data scarcity\nissue for low resource languages, hindering the development of research and\napplications. In this paper, we introduce a new dataset, Cantonese In-car\nAudio-Visual Speech Recognition (CI-AVSR), for in-car command recognition in\nthe Cantonese language with both video and audio data. It consists of 4,984\nsamples (8.3 hours) of 200 in-car commands recorded by 30 native Cantonese\nspeakers. Furthermore, we augment our dataset using common in-car background\nnoises to simulate real environments, producing a dataset 10 times larger than\nthe collected one. We provide detailed statistics of both the clean and the\naugmented versions of our dataset. Moreover, we implement two multimodal\nbaselines to demonstrate the validity of CI-AVSR. Experiment results show that\nleveraging the visual signal improves the overall performance of the model.\nAlthough our best model can achieve a considerable quality on the clean test\nset, the speech recognition quality on the noisy data is still inferior and\nremains as an extremely challenging task for real in-car speech recognition\nsystems. The dataset and code will be released at\nhttps://github.com/HLTCHKUST/CI-AVSR.\n",
                "链接": "https://arxiv.org/abs/2201.03804"
            },
            {
                "文章ID": "4098",
                "标题": "A Dataset for Interactive Vision-Language Navigation with Unknown\n  Command Feasibility",
                "作者": " Andrea Burns,  Deniz Arsan,  Sanjna Agrawal,  Ranjitha Kumar,  Kate Saenko,  Bryan A. Plummer",
                "发布日期": "2022-08-16",
                "摘要": "  Vision-language navigation (VLN), in which an agent follows language\ninstruction in a visual environment, has been studied under the premise that\nthe input command is fully feasible in the environment. Yet in practice, a\nrequest may not be possible due to language ambiguity or environment changes.\nTo study VLN with unknown command feasibility, we introduce a new dataset\nMobile app Tasks with Iterative Feedback (MoTIF), where the goal is to complete\na natural language command in a mobile app. Mobile apps provide a scalable\ndomain to study real downstream uses of VLN methods. Moreover, mobile app\ncommands provide instruction for interactive navigation, as they result in\naction sequences with state changes via clicking, typing, or swiping. MoTIF is\nthe first to include feasibility annotations, containing both binary\nfeasibility labels and fine-grained labels for why tasks are unsatisfiable. We\nfurther collect follow-up questions for ambiguous queries to enable research on\ntask uncertainty resolution. Equipped with our dataset, we propose the new\nproblem of feasibility prediction, in which a natural language instruction and\nmultimodal app environment are used to predict command feasibility. MoTIF\nprovides a more realistic app dataset as it contains many diverse environments,\nhigh-level goals, and longer action sequences than prior work. We evaluate\ninteractive VLN methods using MoTIF, quantify the generalization ability of\ncurrent approaches to new app environments, and measure the effect of task\nfeasibility on navigation performance.\n",
                "链接": "https://arxiv.org/abs/2202.02312"
            },
            {
                "文章ID": "26793",
                "标题": "Bengali Common Voice Speech Dataset for Automatic Speech Recognition",
                "作者": " Samiul Alam,  Asif Sushmit,  Zaowad Abdullah,  Shahrin Nakkhatra,  MD. Nazmuddoha Ansary,  Syed Mobassir Hossen,  Sazia Morshed Mehnaz,  Tahsin Reasat,  Ahmed Imtiaz Humayun",
                "发布日期": "2022-06-30",
                "摘要": "  Bengali is one of the most spoken languages in the world with over 300\nmillion speakers globally. Despite its popularity, research into the\ndevelopment of Bengali speech recognition systems is hindered due to the lack\nof diverse open-source datasets. As a way forward, we have crowdsourced the\nBengali Common Voice Speech Dataset, which is a sentence-level automatic speech\nrecognition corpus. Collected on the Mozilla Common Voice platform, the dataset\nis part of an ongoing campaign that has led to the collection of over 400 hours\nof data in 2 months and is growing rapidly. Our analysis shows that this\ndataset has more speaker, phoneme, and environmental diversity compared to the\nOpenSLR Bengali ASR dataset, the largest existing open-source Bengali speech\ndataset. We present insights obtained from the dataset and discuss key\nlinguistic challenges that need to be addressed in future versions.\nAdditionally, we report the current performance of a few Automatic Speech\nRecognition (ASR) algorithms and set a benchmark for future research.\n",
                "链接": "https://arxiv.org/abs/2206.14053"
            },
            {
                "文章ID": "1409",
                "标题": "Common Phone: A Multilingual Dataset for Robust Acoustic Modelling",
                "作者": " Philipp Klumpp,  Tomás Arias-Vergara,  Paula Andrea Pérez-Toro,  Elmar Nöth,  Juan Rafael Orozco-Arroyave",
                "发布日期": "2022-02-01",
                "摘要": "  Current state of the art acoustic models can easily comprise more than 100\nmillion parameters. This growing complexity demands larger training datasets to\nmaintain a decent generalization of the final decision function. An ideal\ndataset is not necessarily large in size, but large with respect to the amount\nof unique speakers, utilized hardware and varying recording conditions. This\nenables a machine learning model to explore as much of the domain-specific\ninput space as possible during parameter estimation. This work introduces\nCommon Phone, a gender-balanced, multilingual corpus recorded from more than\n11.000 contributors via Mozilla's Common Voice project. It comprises around 116\nhours of speech enriched with automatically generated phonetic segmentation. A\nWav2Vec 2.0 acoustic model was trained with the Common Phone to perform\nphonetic symbol recognition and validate the quality of the generated phonetic\nannotation. The architecture achieved a PER of 18.1 % on the entire test set,\ncomputed with all 101 unique phonetic symbols, showing slight differences\nbetween the individual languages. We conclude that Common Phone provides\nsufficient variability and reliable phonetic annotation to help bridging the\ngap between research and application of acoustic models.\n",
                "链接": "https://arxiv.org/abs/2201.05912"
            },
            {
                "文章ID": "84049",
                "标题": "Some voices are too common: Building fair speech recognition systems\n  using the Common Voice dataset",
                "作者": " Lucas Maison,  Yannick Estève",
                "发布日期": "2023-06-07",
                "摘要": "  Automatic speech recognition (ASR) systems become increasingly efficient\nthanks to new advances in neural network training like self-supervised\nlearning. However, they are known to be unfair toward certain groups, for\ninstance, people speaking with an accent. In this work, we use the French\nCommon Voice dataset to quantify the biases of a pre-trained wav2vec~2.0 model\ntoward several demographic groups. By fine-tuning the pre-trained model on a\nvariety of fixed-size, carefully crafted training sets, we demonstrate the\nimportance of speaker diversity. We also run an in-depth analysis of the Common\nVoice corpus and identify important shortcomings that should be taken into\naccount by users of this dataset.\n",
                "链接": "https://arxiv.org/abs/2306.03773"
            },
            {
                "文章ID": "40081",
                "标题": "ReAct: A Review Comment Dataset for Actionability (and more)",
                "作者": " Gautam Choudhary,  Natwar Modani,  Nitish Maurya",
                "发布日期": "2022-10-04",
                "摘要": "  Review comments play an important role in the evolution of documents. For a\nlarge document, the number of review comments may become large, making it\ndifficult for the authors to quickly grasp what the comments are about. It is\nimportant to identify the nature of the comments to identify which comments\nrequire some action on the part of document authors, along with identifying the\ntypes of these comments. In this paper, we introduce an annotated review\ncomment dataset ReAct. The review comments are sourced from OpenReview site. We\ncrowd-source annotations for these reviews for actionability and type of\ncomments. We analyze the properties of the dataset and validate the quality of\nannotations. We release the dataset (https://github.com/gtmdotme/ReAct) to the\nresearch community as a major contribution. We also benchmark our data with\nstandard baselines for classification tasks and analyze their performance.\n",
                "链接": "https://arxiv.org/abs/2210.00443"
            },
            {
                "文章ID": "109710",
                "标题": "CORE: A Few-Shot Company Relation Classification Dataset for Robust\n  Domain Adaptation",
                "作者": " Philipp Borchert,  Jochen De Weerdt,  Kristof Coussement,  Arno De Caigny,  Marie-Francine Moens",
                "发布日期": "2023-10-19",
                "摘要": "  We introduce CORE, a dataset for few-shot relation classification (RC)\nfocused on company relations and business entities. CORE includes 4,708\ninstances of 12 relation types with corresponding textual evidence extracted\nfrom company Wikipedia pages. Company names and business entities pose a\nchallenge for few-shot RC models due to the rich and diverse information\nassociated with them. For example, a company name may represent the legal\nentity, products, people, or business divisions depending on the context.\nTherefore, deriving the relation type between entities is highly dependent on\ntextual context. To evaluate the performance of state-of-the-art RC models on\nthe CORE dataset, we conduct experiments in the few-shot domain adaptation\nsetting. Our results reveal substantial performance gaps, confirming that\nmodels trained on different domains struggle to adapt to CORE. Interestingly,\nwe find that models trained on CORE showcase improved out-of-domain\nperformance, which highlights the importance of high-quality data for robust\ndomain adaptation. Specifically, the information richness embedded in business\nentities allows models to focus on contextual nuances, reducing their reliance\non superficial clues such as relation-specific verbs. In addition to the\ndataset, we provide relevant code snippets to facilitate reproducibility and\nencourage further research in the field.\n",
                "链接": "https://arxiv.org/abs/2310.12024"
            },
            {
                "文章ID": "55504",
                "标题": "Error syntax aware augmentation of feedback comment generation dataset",
                "作者": " Nikolay Babakov,  Maria Lysyuk,  Alexander Shvets,  Lilya Kazakova,  Alexander Panchenko",
                "发布日期": "2023-01-02",
                "摘要": "  This paper presents a solution to the GenChal 2022 shared task dedicated to\nfeedback comment generation for writing learning. In terms of this task given a\ntext with an error and a span of the error, a system generates an explanatory\nnote that helps the writer (language learner) to improve their writing skills.\nOur solution is based on fine-tuning the T5 model on the initial dataset\naugmented according to syntactical dependencies of the words located within\nindicated error span. The solution of our team \"nigula\" obtained second place\naccording to manual evaluation by the organizers.\n",
                "链接": "https://arxiv.org/abs/2212.14293"
            },
            {
                "文章ID": "37221",
                "标题": "Applying wav2vec2 for Speech Recognition on Bengali Common Voices\n  Dataset",
                "作者": " H. A. Z. Sameen Shahgir,  Khondker Salman Sayeed,  Tanjeem Azwad Zaman",
                "发布日期": "2022-09-15",
                "摘要": "  Speech is inherently continuous, where discrete words, phonemes and other\nunits are not clearly segmented, and so speech recognition has been an active\nresearch problem for decades. In this work we have fine-tuned wav2vec 2.0 to\nrecognize and transcribe Bengali speech -- training it on the Bengali Common\nVoice Speech Dataset. After training for 71 epochs, on a training set\nconsisting of 36919 mp3 files, we achieved a training loss of 0.3172 and WER of\n0.2524 on a validation set of size 7,747. Using a 5-gram language model, the\nLevenshtein Distance was 2.6446 on a test set of size 7,747. Then the training\nset and validation set were combined, shuffled and split into 85-15 ratio.\nTraining for 7 more epochs on this combined dataset yielded an improved\nLevenshtein Distance of 2.60753 on the test set. Our model was the best\nperforming one, achieving a Levenshtein Distance of 6.234 on a hidden dataset,\nwhich was 1.1049 units lower than other competing submissions.\n",
                "链接": "https://arxiv.org/abs/2209.06581"
            },
            {
                "文章ID": "56556",
                "标题": "Safer Together: Machine Learning Models Trained on Shared Accident\n  Datasets Predict Construction Injuries Better than Company-Specific Models",
                "作者": " Antoine J. -P. Tixier,  Matthew R. Hallowell",
                "发布日期": "2023-01-10",
                "摘要": "  In this study, we capitalized on a collective dataset repository of 57k\naccidents from 9 companies belonging to 3 domains and tested whether models\ntrained on multiple datasets (generic models) predicted safety outcomes better\nthan the company-specific models. We experimented with full generic models\n(trained on all data), per-domain generic models (construction, electric T&D,\noil & gas), and with ensembles of generic and specific models. Results are very\npositive, with generic models outperforming the company-specific models in most\ncases while also generating finer-grained, hence more useful, forecasts.\nSuccessful generic models remove the needs for training company-specific\nmodels, saving a lot of time and resources, and give small companies, whose\naccident datasets are too limited to train their own models, access to safety\noutcome predictions. It may still however be advantageous to train specific\nmodels to get an extra boost in performance through ensembling with the generic\nmodels. Overall, by learning lessons from a pool of datasets whose accumulated\nexperience far exceeds that of any single company, and making these lessons\neasily accessible in the form of simple forecasts, generic models tackle the\nholy grail of safety cross-organizational learning and dissemination in the\nconstruction industry.\n",
                "链接": "https://arxiv.org/abs/2301.03567"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于gpt4自动生成prompt的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找多模态agent, 具身智能的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "114225",
                "标题": "Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI",
                "作者": " Song Yaoxian,  Sun Penglei,  Liu Haoyu,  Li Zhixu,  Song Wei,  Xiao Yanghua,  Zhou Xiaofang",
                "发布日期": "2023-11-08",
                "摘要": "  Embodied AI is one of the most popular studies in artificial intelligence and\nrobotics, which can effectively improve the intelligence of real-world agents\n(i.e. robots) serving human beings. Scene knowledge is important for an agent\nto understand the surroundings and make correct decisions in the varied open\nworld. Currently, knowledge base for embodied tasks is missing and most\nexisting work use general knowledge base or pre-trained models to enhance the\nintelligence of an agent. For conventional knowledge base, it is sparse,\ninsufficient in capacity and cost in data collection. For pre-trained models,\nthey face the uncertainty of knowledge and hard maintenance. To overcome the\nchallenges of scene knowledge, we propose a scene-driven multimodal knowledge\ngraph (Scene-MMKG) construction method combining conventional knowledge\nengineering and large language models. A unified scene knowledge injection\nframework is introduced for knowledge representation. To evaluate the\nadvantages of our proposed method, we instantiate Scene-MMKG considering\ntypical indoor robotic functionalities (Manipulation and Mobility), named\nManipMob-MMKG. Comparisons in characteristics indicate our instantiated\nManipMob-MMKG has broad superiority in data-collection efficiency and knowledge\nquality. Experimental results on typical embodied tasks show that\nknowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the\nperformance obviously without re-designing model structures complexly. Our\nproject can be found at https://sites.google.com/view/manipmob-mmkg\n",
                "链接": "https://arxiv.org/abs/2311.03783"
            },
            {
                "文章ID": "2448",
                "标题": "Learning to Act with Affordance-Aware Multimodal Neural SLAM",
                "作者": " Zhiwei Jia,  Kaixiang Lin,  Yizhou Zhao,  Qiaozi Gao,  Govind Thattai,  Gaurav Sukhatme",
                "发布日期": "2022-10-26",
                "摘要": "  Recent years have witnessed an emerging paradigm shift toward embodied\nartificial intelligence, in which an agent must learn to solve challenging\ntasks by interacting with its environment. There are several challenges in\nsolving embodied multimodal tasks, including long-horizon planning,\nvision-and-language grounding, and efficient exploration. We focus on a\ncritical bottleneck, namely the performance of planning and navigation. To\ntackle this challenge, we propose a Neural SLAM approach that, for the first\ntime, utilizes several modalities for exploration, predicts an affordance-aware\nsemantic map, and plans over it at the same time. This significantly improves\nexploration efficiency, leads to robust long-horizon planning, and enables\neffective vision-and-language grounding. With the proposed Affordance-aware\nMultimodal Neural SLAM (AMSLAM) approach, we obtain more than 40% improvement\nover prior published work on the ALFRED benchmark and set a new\nstate-of-the-art generalization performance at a success rate of 23.48% on the\ntest unseen scenes.\n",
                "链接": "https://arxiv.org/abs/2201.09862"
            },
            {
                "文章ID": "63780",
                "标题": "Multimodal Speech Recognition for Language-Guided Embodied Agents",
                "作者": " Allen Chang,  Xiaoyuan Zhu,  Aarav Monga,  Seoho Ahn,  Tejas Srinivasan,  Jesse Thomason",
                "发布日期": "2023-10-11",
                "摘要": "  Benchmarks for language-guided embodied agents typically assume text-based\ninstructions, but deployed agents will encounter spoken instructions. While\nAutomatic Speech Recognition (ASR) models can bridge the input gap, erroneous\nASR transcripts can hurt the agents' ability to complete tasks. In this work,\nwe propose training a multimodal ASR model to reduce errors in transcribing\nspoken instructions by considering the accompanying visual context. We train\nour model on a dataset of spoken instructions, synthesized from the ALFRED task\ncompletion dataset, where we simulate acoustic noise by systematically masking\nspoken words. We find that utilizing visual observations facilitates masked\nword recovery, with multimodal ASR models recovering up to 30% more masked\nwords than unimodal baselines. We also find that a text-trained embodied agent\nsuccessfully completes tasks more often by following transcribed instructions\nfrom multimodal ASR models. github.com/Cylumn/embodied-multimodal-asr\n",
                "链接": "https://arxiv.org/abs/2302.14030"
            },
            {
                "文章ID": "42792",
                "标题": "AVLEN: Audio-Visual-Language Embodied Navigation in 3D Environments",
                "作者": " Sudipta Paul,  Amit K. Roy-Chowdhury,  Anoop Cherian",
                "发布日期": "2022-10-17",
                "摘要": "  Recent years have seen embodied visual navigation advance in two distinct\ndirections: (i) in equipping the AI agent to follow natural language\ninstructions, and (ii) in making the navigable world multimodal, e.g.,\naudio-visual navigation. However, the real world is not only multimodal, but\nalso often complex, and thus in spite of these advances, agents still need to\nunderstand the uncertainty in their actions and seek instructions to navigate.\nTo this end, we present AVLEN~ -- an interactive agent for\nAudio-Visual-Language Embodied Navigation. Similar to audio-visual navigation\ntasks, the goal of our embodied agent is to localize an audio event via\nnavigating the 3D visual world; however, the agent may also seek help from a\nhuman (oracle), where the assistance is provided in free-form natural language.\nTo realize these abilities, AVLEN uses a multimodal hierarchical reinforcement\nlearning backbone that learns: (a) high-level policies to choose either\naudio-cues for navigation or to query the oracle, and (b) lower-level policies\nto select navigation actions based on its audio-visual and language inputs. The\npolicies are trained via rewarding for the success on the navigation task while\nminimizing the number of queries to the oracle. To empirically evaluate AVLEN,\nwe present experiments on the SoundSpaces framework for semantic audio-visual\nnavigation tasks. Our results show that equipping the agent to ask for help\nleads to a clear improvement in performance, especially in challenging cases,\ne.g., when the sound is unheard during training or in the presence of\ndistractor sounds.\n",
                "链接": "https://arxiv.org/abs/2210.07940"
            },
            {
                "文章ID": "106036",
                "标题": "Towards End-to-End Embodied Decision Making via Multi-modal Large\n  Language Model: Explorations with GPT4-Vision and Beyond",
                "作者": " Liang Chen,  Yichi Zhang,  Shuhuai Ren,  Haozhe Zhao,  Zefan Cai,  Yuchi Wang,  Peiyi Wang,  Tianyu Liu,  Baobao Chang",
                "发布日期": "2023-11-29",
                "摘要": "  In this study, we explore the potential of Multimodal Large Language Models\n(MLLMs) in improving embodied decision-making processes for agents. While Large\nLanguage Models (LLMs) have been widely used due to their advanced reasoning\nskills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual\nunderstanding and reasoning capabilities. We investigate whether\nstate-of-the-art MLLMs can handle embodied decision-making in an end-to-end\nmanner and whether collaborations between LLMs and MLLMs can enhance\ndecision-making. To address these questions, we introduce a new benchmark\ncalled PCA-EVAL, which evaluates embodied decision-making from the perspectives\nof Perception, Cognition, and Action. Additionally, we propose HOLMES, a\nmulti-agent cooperation framework that allows LLMs to leverage MLLMs and APIs\nto gather multimodal information for informed decision-making. We compare\nend-to-end embodied decision-making and HOLMES on our benchmark and find that\nthe GPT4-Vision model demonstrates strong end-to-end embodied decision-making\nabilities, outperforming GPT4-HOLMES in terms of average decision accuracy\n(+3%). However, this performance is exclusive to the latest GPT4-Vision model,\nsurpassing the open-source state-of-the-art MLLM by 26%. Our results indicate\nthat powerful MLLMs like GPT4-Vision hold promise for decision-making in\nembodied agents, offering new avenues for MLLM research. Code and data are open\nat https://github.com/pkunlp-icler/PCA-EVAL/.\n",
                "链接": "https://arxiv.org/abs/2310.02071"
            },
            {
                "文章ID": "104544",
                "标题": "The Importance of Multimodal Emotion Conditioning and Affect Consistency\n  for Embodied Conversational Agents",
                "作者": " Che-Jui Chang,  Samuel S. Sohn,  Sen Zhang,  Rajath Jayashankar,  Muhammad Usman,  Mubbasir Kapadia",
                "发布日期": "2023-12-08",
                "摘要": "  Previous studies regarding the perception of emotions for embodied virtual\nagents have shown the effectiveness of using virtual characters in conveying\nemotions through interactions with humans. However, creating an autonomous\nembodied conversational agent with expressive behaviors presents two major\nchallenges. The first challenge is the difficulty of synthesizing the\nconversational behaviors for each modality that are as expressive as real human\nbehaviors. The second challenge is that the affects are modeled independently,\nwhich makes it difficult to generate multimodal responses with consistent\nemotions across all modalities. In this work, we propose a conceptual\nframework, ACTOR (Affect-Consistent mulTimodal behaviOR generation), that aims\nto increase the perception of affects by generating multimodal behaviors\nconditioned on a consistent driving affect. We have conducted a user study with\n199 participants to assess how the average person judges the affects perceived\nfrom multimodal behaviors that are consistent and inconsistent with respect to\na driving affect. The result shows that among all model conditions, our\naffect-consistent framework receives the highest Likert scores for the\nperception of driving affects. Our statistical analysis suggests that making a\nmodality affect-inconsistent significantly decreases the perception of driving\naffects. We also observe that multimodal behaviors conditioned on consistent\naffects are more expressive compared to behaviors with inconsistent affects.\nTherefore, we conclude that multimodal emotion conditioning and affect\nconsistency are vital to enhancing the perception of affects for embodied\nconversational agents.\n",
                "链接": "https://arxiv.org/abs/2309.15311"
            },
            {
                "文章ID": "118026",
                "标题": "Agent as Cerebrum, Controller as Cerebellum: Implementing an Embodied\n  LMM-based Agent on Drones",
                "作者": " Haoran Zhao,  Fengxing Pan,  Huqiuyue Ping,  Yaoming Zhou",
                "发布日期": "2023-11-28",
                "摘要": "  In this study, we present a novel paradigm for industrial robotic embodied\nagents, encapsulating an 'agent as cerebrum, controller as cerebellum'\narchitecture. Our approach harnesses the power of Large Multimodal Models\n(LMMs) within an agent framework known as AeroAgent, tailored for drone\ntechnology in industrial settings. To facilitate seamless integration with\nrobotic systems, we introduce ROSchain, a bespoke linkage framework connecting\nLMM-based agents to the Robot Operating System (ROS). We report findings from\nextensive empirical research, including simulated experiments on the Airgen and\nreal-world case study, particularly in individual search and rescue operations.\nThe results demonstrate AeroAgent's superior performance in comparison to\nexisting Deep Reinforcement Learning (DRL)-based agents, highlighting the\nadvantages of the embodied LMM in complex, real-world scenarios.\n",
                "链接": "https://arxiv.org/abs/2311.15033"
            },
            {
                "文章ID": "114303",
                "标题": "Multitask Multimodal Prompted Training for Interactive Embodied Task\n  Completion",
                "作者": " Georgios Pantazopoulos,  Malvina Nikandrou,  Amit Parekh,  Bhathiya Hemanthage,  Arash Eshghi,  Ioannis Konstas,  Verena Rieser,  Oliver Lemon,  Alessandro Suglia",
                "发布日期": "2023-11-08",
                "摘要": "  Interactive and embodied tasks pose at least two fundamental challenges to\nexisting Vision & Language (VL) models, including 1) grounding language in\ntrajectories of actions and observations, and 2) referential disambiguation. To\ntackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a\nunified encoder-decoder model that reasons over images and trajectories, and\ncasts action prediction as multimodal text generation. By unifying all tasks as\ntext generation, EMMA learns a language of actions which facilitates transfer\nacross tasks. Different to previous modular approaches with independently\ntrained components, we use a single multitask model where each task contributes\nto goal completion. EMMA performs on par with similar models on several VL\nbenchmarks and sets a new state-of-the-art performance (36.81% success rate) on\nthe Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided\nagents in the Alexa Arena\n",
                "链接": "https://arxiv.org/abs/2311.04067"
            },
            {
                "文章ID": "90648",
                "标题": "VELMA: Verbalization Embodiment of LLM Agents for Vision and Language\n  Navigation in Street View",
                "作者": " Raphael Schumann,  Wanrong Zhu,  Weixi Feng,  Tsu-Jui Fu,  Stefan Riezler,  William Yang Wang",
                "发布日期": "2023-07-13",
                "摘要": "  Incremental decision making in real-world environments is one of the most\nchallenging tasks in embodied artificial intelligence. One particularly\ndemanding scenario is Vision and Language Navigation~(VLN) which requires\nvisual and natural language understanding as well as spatial and temporal\nreasoning capabilities. The embodied agent needs to ground its understanding of\nnavigation instructions in observations of a real-world environment like Street\nView. Despite the impressive results of LLMs in other research areas, it is an\nongoing problem of how to best connect them with an interactive visual\nenvironment. In this work, we propose VELMA, an embodied LLM agent that uses a\nverbalization of the trajectory and of visual environment observations as\ncontextual prompt for the next action. Visual information is verbalized by a\npipeline that extracts landmarks from the human written navigation instructions\nand uses CLIP to determine their visibility in the current panorama view. We\nshow that VELMA is able to successfully follow navigation instructions in\nStreet View with only two in-context examples. We further finetune the LLM\nagent on a few thousand examples and achieve 25%-30% relative improvement in\ntask completion over the previous state-of-the-art for two datasets.\n",
                "链接": "https://arxiv.org/abs/2307.06082"
            },
            {
                "文章ID": "89377",
                "标题": "Embodied Task Planning with Large Language Models",
                "作者": " Zhenyu Wu,  Ziwei Wang,  Xiuwei Xu,  Jiwen Lu,  Haibin Yan",
                "发布日期": "2023-07-07",
                "摘要": "  Equipping embodied agents with commonsense is important for robots to\nsuccessfully complete complex human instructions in general environments.\nRecent large language models (LLM) can embed rich semantic knowledge for agents\nin plan generation of complex tasks, while they lack the information about the\nrealistic world and usually yield infeasible action sequences. In this paper,\nwe propose a TAsk Planing Agent (TaPA) in embodied tasks for grounded planning\nwith physical scene constraint, where the agent generates executable plans\naccording to the existed objects in the scene by aligning LLMs with the visual\nperception models. Specifically, we first construct a multimodal dataset\ncontaining triplets of indoor scenes, instructions and action plans, where we\nprovide the designed prompts and the list of existing objects in the scene for\nGPT-3.5 to generate a large number of instructions and corresponding planned\nactions. The generated data is leveraged for grounded plan tuning of\npre-trained LLMs. During inference, we discover the objects in the scene by\nextending open-vocabulary object detectors to multi-view RGB images collected\nin different achievable locations. Experimental results show that the generated\nplan from our TaPA framework can achieve higher success rate than LLaVA and\nGPT-3.5 by a sizable margin, which indicates the practicality of embodied task\nplanning in general and complex environments.\n",
                "链接": "https://arxiv.org/abs/2307.01848"
            }
        ]
    },
    {
        "question": {
            "question": "新的大模型结构相关探索的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "帮我查找风格化机器翻译相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "92370",
                "标题": "Incorporating Human Translator Style into English-Turkish Literary\n  Machine Translation",
                "作者": " Zeynep Yirmibeşoğlu,  Olgun Dursun,  Harun Dallı,  Mehmet Şahin,  Ena Hodzik,  Sabri Gürses,  Tunga Güngör",
                "发布日期": "2023-07-24",
                "摘要": "  Although machine translation systems are mostly designed to serve in the\ngeneral domain, there is a growing tendency to adapt these systems to other\ndomains like literary translation. In this paper, we focus on English-Turkish\nliterary translation and develop machine translation models that take into\naccount the stylistic features of translators. We fine-tune a pre-trained\nmachine translation model by the manually-aligned works of a particular\ntranslator. We make a detailed analysis of the effects of manual and automatic\nalignments, data augmentation methods, and corpus size on the translations. We\npropose an approach based on stylistic features to evaluate the style of a\ntranslator in the output translations. We show that the human translator style\ncan be highly recreated in the target machine translations by adapting the\nmodels to the style of the translator.\n",
                "链接": "https://arxiv.org/abs/2307.11457"
            },
            {
                "文章ID": "113724",
                "标题": "Narrowing the Gap between Zero- and Few-shot Machine Translation by\n  Matching Styles",
                "作者": " Weiting Tan,  Haoran Xu,  Lingfeng Shen,  Shuyue Stella Li,  Kenton Murray,  Philipp Koehn,  Benjamin Van Durme,  Yunmo Chen",
                "发布日期": "2023-11-07",
                "摘要": "  Large language models trained primarily in a monolingual setting have\ndemonstrated their ability to generalize to machine translation using zero- and\nfew-shot examples with in-context learning. However, even though zero-shot\ntranslations are relatively good, there remains a discernible gap comparing\ntheir performance with the few-shot setting. In this paper, we investigate the\nfactors contributing to this gap and find that this gap can largely be closed\n(for about 70%) by matching the writing styles of the target corpus.\nAdditionally, we explore potential approaches to enhance zero-shot baselines\nwithout the need for parallel demonstration examples, providing valuable\ninsights into how these methods contribute to improving translation metrics.\n",
                "链接": "https://arxiv.org/abs/2311.02310"
            },
            {
                "文章ID": "54085",
                "标题": "Controlling Styles in Neural Machine Translation with Activation Prompt",
                "作者": " Yifan Wang,  Zewei Sun,  Shanbo Cheng,  Weiguo Zheng,  Mingxuan Wang",
                "发布日期": "2023-05-30",
                "摘要": "  Controlling styles in neural machine translation (NMT) has attracted wide\nattention, as it is crucial for enhancing user experience. Earlier studies on\nthis topic typically concentrate on regulating the level of formality and\nachieve some progress in this area. However, they still encounter two major\nchallenges. The first is the difficulty in style evaluation. The style\ncomprises various aspects such as lexis, syntax, and others that provide\nabundant information. Nevertheless, only formality has been thoroughly\ninvestigated. The second challenge involves excessive dependence on incremental\nadjustments, particularly when new styles are necessary. To address both\nchallenges, this paper presents a new benchmark and approach. A multiway\nstylized machine translation (MSMT) benchmark is introduced, incorporating\ndiverse categories of styles across four linguistic domains. Then, we propose a\nmethod named style activation prompt (StyleAP) by retrieving prompts from\nstylized monolingual corpus, which does not require extra fine-tuning.\nExperiments show that StyleAP could effectively control the style of\ntranslation and achieve remarkable performance.\n",
                "链接": "https://arxiv.org/abs/2212.08909"
            },
            {
                "文章ID": "107113",
                "标题": "Synslator: An Interactive Machine Translation Tool with Online Learning",
                "作者": " Jiayi Wang,  Ke Wang,  Fengming Zhou,  Chengyu Wang,  Zhiyong Fu,  Zeyu Feng,  Yu Zhao,  Yuqi Zhang",
                "发布日期": "2023-10-10",
                "摘要": "  Interactive machine translation (IMT) has emerged as a progression of the\ncomputer-aided translation paradigm, where the machine translation system and\nthe human translator collaborate to produce high-quality translations. This\npaper introduces Synslator, a user-friendly computer-aided translation (CAT)\ntool that not only supports IMT, but is adept at online learning with real-time\ntranslation memories. To accommodate various deployment environments for CAT\nservices, Synslator integrates two different neural translation models to\nhandle translation memories for online learning. Additionally, the system\nemploys a language model to enhance the fluency of translations in an\ninteractive mode. In evaluation, we have confirmed the effectiveness of online\nlearning through the translation models, and have observed a 13% increase in\npost-editing efficiency with the interactive functionalities of Synslator. A\ntutorial video is available at:https://youtu.be/K0vRsb2lTt8.\n",
                "链接": "https://arxiv.org/abs/2310.05025"
            },
            {
                "文章ID": "73945",
                "标题": "UTSGAN: Unseen Transition Suss GAN for Transition-Aware Image-to-image\n  Translation",
                "作者": " Yaxin Shi,  Xiaowei Zhou,  Ping Liu,  Ivor W. Tsang",
                "发布日期": "2023-04-25",
                "摘要": "  In the field of Image-to-Image (I2I) translation, ensuring consistency\nbetween input images and their translated results is a key requirement for\nproducing high-quality and desirable outputs. Previous I2I methods have relied\non result consistency, which enforces consistency between the translated\nresults and the ground truth output, to achieve this goal. However, result\nconsistency is limited in its ability to handle complex and unseen attribute\nchanges in translation tasks. To address this issue, we introduce a\ntransition-aware approach to I2I translation, where the data translation\nmapping is explicitly parameterized with a transition variable, allowing for\nthe modelling of unobserved translations triggered by unseen transitions.\nFurthermore, we propose the use of transition consistency, defined on the\ntransition variable, to enable regularization of consistency on unobserved\ntranslations, which is omitted in previous works. Based on these insights, we\npresent Unseen Transition Suss GAN (UTSGAN), a generative framework that\nconstructs a manifold for the transition with a stochastic transition encoder\nand coherently regularizes and generalizes result consistency and transition\nconsistency on both training and unobserved translations with tailor-designed\nconstraints. Extensive experiments on four different I2I tasks performed on\nfive different datasets demonstrate the efficacy of our proposed UTSGAN in\nperforming consistent translations.\n",
                "链接": "https://arxiv.org/abs/2304.11955"
            },
            {
                "文章ID": "56448",
                "标题": "Applying Automated Machine Translation to Educational Video Courses",
                "作者": " Linden Wang",
                "发布日期": "2023-09-20",
                "摘要": "  We studied the capability of automated machine translation in the online\nvideo education space by automatically translating Khan Academy videos with\nstate-of-the-art translation models and applying text-to-speech synthesis and\naudio/video synchronization to build engaging videos in target languages. We\nalso analyzed and established two reliable translation confidence estimators\nbased on round-trip translations in order to efficiently manage translation\nquality and reduce human translation effort. Finally, we developed a deployable\nsystem to deliver translated videos to end users and collect user corrections\nfor iterative improvement.\n",
                "链接": "https://arxiv.org/abs/2301.03141"
            },
            {
                "文章ID": "48179",
                "标题": "Easy Guided Decoding in Providing Suggestions for Interactive Machine\n  Translation",
                "作者": " Ke Wang,  Xin Ge,  Jiayi Wang,  Yu Zhao,  Yuqi Zhang",
                "发布日期": "2023-06-05",
                "摘要": "  Machine translation technology has made great progress in recent years, but\nit cannot guarantee error free results. Human translators perform post editing\non machine translations to correct errors in the scene of computer aided\ntranslation. In favor of expediting the post editing process, many works have\ninvestigated machine translation in interactive modes, in which machines can\nautomatically refine the rest of translations constrained by human's edits.\nTranslation Suggestion (TS), as an interactive mode to assist human\ntranslators, requires machines to generate alternatives for specific incorrect\nwords or phrases selected by human translators. In this paper, we utilize the\nparameterized objective function of neural machine translation (NMT) and\npropose a novel constrained decoding algorithm, namely Prefix Suffix Guided\nDecoding (PSGD), to deal with the TS problem without additional training.\nCompared to the state of the art lexically constrained decoding method, PSGD\nimproves translation quality by an average of $10.87$ BLEU and $8.62$ BLEU on\nthe WeTS and the WMT 2022 Translation Suggestion datasets, respectively, and\nreduces decoding time overhead by an average of 63.4% tested on the WMT\ntranslation datasets. Furthermore, on both of the TS benchmark datasets, it is\nsuperior to other supervised learning systems trained with TS annotated data.\n",
                "链接": "https://arxiv.org/abs/2211.07093"
            },
            {
                "文章ID": "83454",
                "标题": "Extract and Attend: Improving Entity Translation in Neural Machine\n  Translation",
                "作者": " Zixin Zeng,  Rui Wang,  Yichong Leng,  Junliang Guo,  Xu Tan,  Tao Qin,  Tie-yan Liu",
                "发布日期": "2023-06-06",
                "摘要": "  While Neural Machine Translation(NMT) has achieved great progress in recent\nyears, it still suffers from inaccurate translation of entities (e.g.,\nperson/organization name, location), due to the lack of entity training\ninstances. When we humans encounter an unknown entity during translation, we\nusually first look up in a dictionary and then organize the entity translation\ntogether with the translations of other parts to form a smooth target sentence.\nInspired by this translation process, we propose an Extract-and-Attend approach\nto enhance entity translation in NMT, where the translation candidates of\nsource entities are first extracted from a dictionary and then attended to by\nthe NMT model to generate the target sentence. Specifically, the translation\ncandidates are extracted by first detecting the entities in a source sentence\nand then translating the entities through looking up in a dictionary. Then, the\nextracted candidates are added as a prefix of the decoder input to be attended\nto by the decoder when generating the target sentence through self-attention.\nExperiments conducted on En-Zh and En-Ru demonstrate that the proposed method\nis effective on improving both the translation accuracy of entities and the\noverall translation quality, with up to 35% reduction on entity error rate and\n0.85 gain on BLEU and 13.8 gain on COMET.\n",
                "链接": "https://arxiv.org/abs/2306.02242"
            },
            {
                "文章ID": "97924",
                "标题": "SeamlessM4T: Massively Multilingual & Multimodal Machine Translation",
                "作者": " Seamless Communication,  Loïc Barrault,  Yu-An Chung,  Mariano Cora Meglioli,  David Dale,  Ning Dong,  Paul-Ambroise Duquenne,  Hady Elsahar,  Hongyu Gong,  Kevin Heffernan,  John Hoffman,  Christopher Klaiber,  Pengwei Li,  Daniel Licht,  Jean Maillard,  Alice Rakotoarison,  Kaushik Ram Sadagopan,  Guillaume Wenzek,  Ethan Ye,  Bapi Akula,  Peng-Jen Chen,  Naji El Hachem,  Brian Ellis,  Gabriel Mejia Gonzalez,  Justin Haaheim,  Prangthip Hansanti,  Russ Howes,  Bernie Huang,  Min-Jae Hwang,  Hirofumi Inaguma,  Somya Jain,  Elahe Kalbassi,  Amanda Kallet,  Ilia Kulikov,  Janice Lam,  Daniel Li,  Xutai Ma,  Ruslan Mavlyutov,  Benjamin Peloquin,  Mohamed Ramadan,  Abinesh Ramakrishnan,  Anna Sun,  Kevin Tran,  Tuan Tran,  Igor Tufanov,  Vish Vogeti,  Carleigh Wood,  Yilin Yang,  Bokai Yu,  Pierre Andrews,  Can Balioglu,  Marta R. Costa-jussà,  Onur Celebi,  Maha Elbayad,  Cynthia Gao,  Francisco Guzmán,  Justine Kao,  Ann Lee,  Alexandre Mourachko,  Juan Pino,  Sravya Popuri,  Christophe Ropers,  Safiyyah Saleem,  Holger Schwenk,  Paden Tomasello,  Changhan Wang,  Jeff Wang,  Skyler Wang",
                "发布日期": "2023-10-26",
                "摘要": "  What does it take to create the Babel Fish, a tool that can help individuals\ntranslate speech between any two languages? While recent breakthroughs in\ntext-based models have pushed machine translation coverage beyond 200\nlanguages, unified speech-to-speech translation models have yet to achieve\nsimilar strides. More specifically, conventional speech-to-speech translation\nsystems rely on cascaded systems that perform translation progressively,\nputting high-performing unified systems out of reach. To address these gaps, we\nintroduce SeamlessM4T, a single model that supports speech-to-speech\ntranslation, speech-to-text translation, text-to-speech translation,\ntext-to-text translation, and automatic speech recognition for up to 100\nlanguages. To build this, we used 1 million hours of open speech audio data to\nlearn self-supervised speech representations with w2v-BERT 2.0. Subsequently,\nwe created a multimodal corpus of automatically aligned speech translations.\nFiltered and combined with human-labeled and pseudo-labeled data, we developed\nthe first multilingual system capable of translating from and into English for\nboth speech and text. On FLEURS, SeamlessM4T sets a new standard for\ntranslations into multiple target languages, achieving an improvement of 20%\nBLEU over the previous SOTA in direct speech-to-text translation. Compared to\nstrong cascaded models, SeamlessM4T improves the quality of into-English\ntranslation by 1.3 BLEU points in speech-to-text and by 2.6 ASR-BLEU points in\nspeech-to-speech. Tested for robustness, our system performs better against\nbackground noises and speaker variations in speech-to-text tasks compared to\nthe current SOTA model. Critically, we evaluated SeamlessM4T on gender bias and\nadded toxicity to assess translation safety. Finally, all contributions in this\nwork are open-sourced and accessible at\nhttps://github.com/facebookresearch/seamless_communication\n",
                "链接": "https://arxiv.org/abs/2308.11596"
            },
            {
                "文章ID": "119702",
                "标题": "Quick Back-Translation for Unsupervised Machine Translation",
                "作者": " Benjamin Brimacombe,  Jiawei Zhou",
                "发布日期": "2023-12-05",
                "摘要": "  The field of unsupervised machine translation has seen significant\nadvancement from the marriage of the Transformer and the back-translation\nalgorithm. The Transformer is a powerful generative model, and back-translation\nleverages Transformer's high-quality translations for iterative\nself-improvement. However, the Transformer is encumbered by the run-time of\nautoregressive inference during back-translation, and back-translation is\nlimited by a lack of synthetic data efficiency. We propose a two-for-one\nimprovement to Transformer back-translation: Quick Back-Translation (QBT). QBT\nre-purposes the encoder as a generative model, and uses encoder-generated\nsequences to train the decoder in conjunction with the original autoregressive\nback-translation step, improving data throughput and utilization. Experiments\non various WMT benchmarks demonstrate that a relatively small number of\nrefining steps of QBT improve current unsupervised machine translation models,\nand that QBT dramatically outperforms standard back-translation only method in\nterms of training efficiency for comparable translation qualities.\n",
                "链接": "https://arxiv.org/abs/2312.00912"
            }
        ]
    },
    {
        "question": {
            "question": "查找中文ner常用的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "5948",
                "标题": "AISHELL-NER: Named Entity Recognition from Chinese Speech",
                "作者": " Boli Chen,  Guangwei Xu,  Xiaobin Wang,  Pengjun Xie,  Meishan Zhang,  Fei Huang",
                "发布日期": "2022-02-18",
                "摘要": "  Named Entity Recognition (NER) from speech is among Spoken Language\nUnderstanding (SLU) tasks, aiming to extract semantic information from the\nspeech signal. NER from speech is usually made through a two-step pipeline that\nconsists of (1) processing the audio using an Automatic Speech Recognition\n(ASR) system and (2) applying an NER tagger to the ASR outputs. Recent works\nhave shown the capability of the End-to-End (E2E) approach for NER from English\nand French speech, which is essentially entity-aware ASR. However, due to the\nmany homophones and polyphones that exist in Chinese, NER from Chinese speech\nis effectively a more challenging task. In this paper, we introduce a new\ndataset AISEHLL-NER for NER from Chinese speech. Extensive experiments are\nconducted to explore the performance of several state-of-the-art methods. The\nresults demonstrate that the performance could be improved by combining\nentity-aware ASR and pretrained NER tagger, which can be easily applied to the\nmodern SLU pipeline. The dataset is publicly available at\ngithub.com/Alibaba-NLP/AISHELL-NER.\n",
                "链接": "https://arxiv.org/abs/2202.08533"
            },
            {
                "文章ID": "12836",
                "标题": "$k$NN-NER: Named Entity Recognition with Nearest Neighbor Search",
                "作者": " Shuhe Wang,  Xiaoya Li,  Yuxian Meng,  Tianwei Zhang,  Rongbin Ouyang,  Jiwei Li,  Guoyin Wang",
                "发布日期": "2022-04-01",
                "摘要": "  Inspired by recent advances in retrieval augmented methods in\nNLP~\\citep{khandelwal2019generalization,khandelwal2020nearest,meng2021gnn}, in\nthis paper, we introduce a $k$ nearest neighbor NER ($k$NN-NER) framework,\nwhich augments the distribution of entity labels by assigning $k$ nearest\nneighbors retrieved from the training set. This strategy makes the model more\ncapable of handling long-tail cases, along with better few-shot learning\nabilities. $k$NN-NER requires no additional operation during the training\nphase, and by interpolating $k$ nearest neighbors search into the vanilla NER\nmodel, $k$NN-NER consistently outperforms its vanilla counterparts: we achieve\na new state-of-the-art F1-score of 72.03 (+1.25) on the Chinese Weibo dataset\nand improved results on a variety of widely used NER benchmarks. Additionally,\nwe show that $k$NN-NER can achieve comparable results to the vanilla NER model\nwith 40\\% less amount of training data. Code available at\n\\url{https://github.com/ShannonAI/KNN-NER}.\n",
                "链接": "https://arxiv.org/abs/2203.17103"
            },
            {
                "文章ID": "73406",
                "标题": "GPT-NER: Named Entity Recognition via Large Language Models",
                "作者": " Shuhe Wang,  Xiaofei Sun,  Xiaoya Li,  Rongbin Ouyang,  Fei Wu,  Tianwei Zhang,  Jiwei Li,  Guoyin Wang",
                "发布日期": "2023-10-10",
                "摘要": "  Despite the fact that large-scale Language Models (LLM) have achieved SOTA\nperformances on a variety of NLP tasks, its performance on NER is still\nsignificantly below supervised baselines. This is due to the gap between the\ntwo tasks the NER and LLMs: the former is a sequence labeling task in nature\nwhile the latter is a text-generation model.\n  In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges the\ngap by transforming the sequence labeling task to a generation task that can be\neasily adapted by LLMs e.g., the task of finding location entities in the input\ntext \"Columbus is a city\" is transformed to generate the text sequence\n\"@@Columbus## is a city\", where special tokens @@## marks the entity to\nextract. To efficiently address the \"hallucination\" issue of LLMs, where LLMs\nhave a strong inclination to over-confidently label NULL inputs as entities, we\npropose a self-verification strategy by prompting LLMs to ask itself whether\nthe extracted entities belong to a labeled entity tag.\n  We conduct experiments on five widely adopted NER datasets, and GPT-NER\nachieves comparable performances to fully supervised baselines, which is the\nfirst time as far as we are concerned. More importantly, we find that GPT-NER\nexhibits a greater ability in the low-resource and few-shot setups, when the\namount of training data is extremely scarce, GPT-NER performs significantly\nbetter than supervised models. This demonstrates the capabilities of GPT-NER in\nreal-world NER applications where the number of labeled examples is limited.\n",
                "链接": "https://arxiv.org/abs/2304.10428"
            },
            {
                "文章ID": "81587",
                "标题": "E-NER: Evidential Deep Learning for Trustworthy Named Entity Recognition",
                "作者": " Zhen Zhang,  Mengting Hu,  Shiwan Zhao,  Minlie Huang,  Haotian Wang,  Lemao Liu,  Zhirui Zhang,  Zhe Liu,  Bingzhe Wu",
                "发布日期": "2023-05-30",
                "摘要": "  Most named entity recognition (NER) systems focus on improving model\nperformance, ignoring the need to quantify model uncertainty, which is critical\nto the reliability of NER systems in open environments. Evidential deep\nlearning (EDL) has recently been proposed as a promising solution to explicitly\nmodel predictive uncertainty for classification tasks. However, directly\napplying EDL to NER applications faces two challenges, i.e., the problems of\nsparse entities and OOV/OOD entities in NER tasks. To address these challenges,\nwe propose a trustworthy NER framework named E-NER by introducing two\nuncertainty-guided loss terms to the conventional EDL, along with a series of\nuncertainty-guided training strategies. Experiments show that E-NER can be\napplied to multiple NER paradigms to obtain accurate uncertainty estimation.\nFurthermore, compared to state-of-the-art baselines, the proposed method\nachieves a better OOV/OOD detection performance and better generalization\nability on OOV entities.\n",
                "链接": "https://arxiv.org/abs/2305.17854"
            },
            {
                "文章ID": "108977",
                "标题": "Empirical Study of Zero-Shot NER with ChatGPT",
                "作者": " Tingyu Xie,  Qi Li,  Jian Zhang,  Yan Zhang,  Zuozhu Liu,  Hongwei Wang",
                "发布日期": "2023-10-17",
                "摘要": "  Large language models (LLMs) exhibited powerful capability in various natural\nlanguage processing tasks. This work focuses on exploring LLM performance on\nzero-shot information extraction, with a focus on the ChatGPT and named entity\nrecognition (NER) task. Inspired by the remarkable reasoning capability of LLM\non symbolic and arithmetic reasoning, we adapt the prevalent reasoning methods\nto NER and propose reasoning strategies tailored for NER. First, we explore a\ndecomposed question-answering paradigm by breaking down the NER task into\nsimpler subproblems by labels. Second, we propose syntactic augmentation to\nstimulate the model's intermediate thinking in two ways: syntactic prompting,\nwhich encourages the model to analyze the syntactic structure itself, and tool\naugmentation, which provides the model with the syntactic information generated\nby a parsing tool. Besides, we adapt self-consistency to NER by proposing a\ntwo-stage majority voting strategy, which first votes for the most consistent\nmentions, then the most consistent types. The proposed methods achieve\nremarkable improvements for zero-shot NER across seven benchmarks, including\nChinese and English datasets, and on both domain-specific and general-domain\nscenarios. In addition, we present a comprehensive analysis of the error types\nwith suggestions for optimization directions. We also verify the effectiveness\nof the proposed methods on the few-shot setting and other LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.10035"
            },
            {
                "文章ID": "81674",
                "标题": "Extrinsic Factors Affecting the Accuracy of Biomedical NER",
                "作者": " Zhiyi Li,  Shengjie Zhang,  Yujie Song,  Jungyeul Park",
                "发布日期": "2023-05-30",
                "摘要": "  Biomedical named entity recognition (NER) is a critial task that aims to\nidentify structured information in clinical text, which is often replete with\ncomplex, technical terms and a high degree of variability. Accurate and\nreliable NER can facilitate the extraction and analysis of important biomedical\ninformation, which can be used to improve downstream applications including the\nhealthcare system. However, NER in the biomedical domain is challenging due to\nlimited data availability, as the high expertise, time, and expenses are\nrequired to annotate its data. In this paper, by using the limited data, we\nexplore various extrinsic factors including the corpus annotation scheme, data\naugmentation techniques, semi-supervised learning and Brill transformation, to\nimprove the performance of a NER model on a clinical text dataset (i2b2 2012,\n\\citet{sun-rumshisky-uzuner:2013}). Our experiments demonstrate that these\napproaches can significantly improve the model's F1 score from original 73.74\nto 77.55. Our findings suggest that considering different extrinsic factors and\ncombining these techniques is a promising approach for improving NER\nperformance in the biomedical domain where the size of data is limited.\n",
                "链接": "https://arxiv.org/abs/2305.18152"
            },
            {
                "文章ID": "81620",
                "标题": "ContrastNER: Contrastive-based Prompt Tuning for Few-shot NER",
                "作者": " Amirhossein Layegh,  Amir H. Payberah,  Ahmet Soylu,  Dumitru Roman,  Mihhail Matskin",
                "发布日期": "2023-08-08",
                "摘要": "  Prompt-based language models have produced encouraging results in numerous\napplications, including Named Entity Recognition (NER) tasks. NER aims to\nidentify entities in a sentence and provide their types. However, the strong\nperformance of most available NER approaches is heavily dependent on the design\nof discrete prompts and a verbalizer to map the model-predicted outputs to\nentity categories, which are complicated undertakings. To address these\nchallenges, we present ContrastNER, a prompt-based NER framework that employs\nboth discrete and continuous tokens in prompts and uses a contrastive learning\napproach to learn the continuous prompts and forecast entity types. The\nexperimental results demonstrate that ContrastNER obtains competitive\nperformance to the state-of-the-art NER methods in high-resource settings and\noutperforms the state-of-the-art models in low-resource circumstances without\nrequiring extensive manual prompt engineering and verbalizer design.\n",
                "链接": "https://arxiv.org/abs/2305.17951"
            },
            {
                "文章ID": "54218",
                "标题": "E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text",
                "作者": " Ting Wai Terence Au,  Ingemar J. Cox,  Vasileios Lampos",
                "发布日期": "2022-12-20",
                "摘要": "  Identifying named entities such as a person, location or organization, in\ndocuments can highlight key information to readers. Training Named Entity\nRecognition (NER) models requires an annotated data set, which can be a\ntime-consuming labour-intensive task. Nevertheless, there are publicly\navailable NER data sets for general English. Recently there has been interest\nin developing NER for legal text. However, prior work and experimental results\nreported here indicate that there is a significant degradation in performance\nwhen NER methods trained on a general English data set are applied to legal\ntext. We describe a publicly available legal NER data set, called E-NER, based\non legal company filings available from the US Securities and Exchange\nCommission's EDGAR data set. Training a number of different NER algorithms on\nthe general English CoNLL-2003 corpus but testing on our test collection\nconfirmed significant degradations in accuracy, as measured by the F1-score, of\nbetween 29.4\\% and 60.4\\%, compared to training and testing on the E-NER\ncollection.\n",
                "链接": "https://arxiv.org/abs/2212.09306"
            },
            {
                "文章ID": "82089",
                "标题": "A Multilingual Evaluation of NER Robustness to Adversarial Inputs",
                "作者": " Akshay Srinivasan,  Sowmya Vajjala",
                "发布日期": "2023-05-31",
                "摘要": "  Adversarial evaluations of language models typically focus on English alone.\nIn this paper, we performed a multilingual evaluation of Named Entity\nRecognition (NER) in terms of its robustness to small perturbations in the\ninput. Our results showed the NER models we explored across three languages\n(English, German and Hindi) are not very robust to such changes, as indicated\nby the fluctuations in the overall F1 score as well as in a more fine-grained\nevaluation. With that knowledge, we further explored whether it is possible to\nimprove the existing NER models using a part of the generated adversarial data\nsets as augmented training data to train a new NER model or as fine-tuning data\nto adapt an existing NER model. Our results showed that both these approaches\nimprove performance on the original as well as adversarial test sets. While\nthere is no significant difference between the two approaches for English,\nre-training is significantly better than fine-tuning for German and Hindi.\n",
                "链接": "https://arxiv.org/abs/2305.18933"
            },
            {
                "文章ID": "78785",
                "标题": "Enhancing Few-shot NER with Prompt Ordering based Data Augmentation",
                "作者": " Huiming Wang,  Liying Cheng,  Wenxuan Zhang,  De Wen Soh,  Lidong Bing",
                "发布日期": "2023-05-22",
                "摘要": "  Recently, data augmentation (DA) methods have been proven to be effective for\npre-trained language models (PLMs) in low-resource settings, including few-shot\nnamed entity recognition (NER). However, conventional NER DA methods are mostly\naimed at sequence labeling models, i.e., token-level classification, and few\nare compatible with unified autoregressive generation frameworks, which can\nhandle a wider range of NER tasks, such as nested NER. Furthermore, these\ngeneration frameworks have a strong assumption that the entities will appear in\nthe target sequence with the same left-to-right order as the source sequence.\nIn this paper, we claim that there is no need to keep this strict order, and\nmore diversified but reasonable target entity sequences can be provided during\nthe training stage as a novel DA method. Nevertheless, a naive mixture of\naugmented data can confuse the model since one source sequence will then be\npaired with different target sequences. Therefore, we propose a simple but\neffective Prompt Ordering based Data Augmentation (PODA) method to improve the\ntraining of unified autoregressive generation frameworks under few-shot NER\nscenarios. Experimental results on three public NER datasets and further\nanalyses demonstrate the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2305.11791"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下最近用反事实做数据增强的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "10174",
                "标题": "Neural network processing of holographic images",
                "作者": " John S. Schreck,  Gabrielle Gantos,  Matthew Hayman,  Aaron Bansemer,  David John Gagne",
                "发布日期": "2022-03-21",
                "摘要": "  HOLODEC, an airborne cloud particle imager, captures holographic images of a\nfixed volume of cloud to characterize the types and sizes of cloud particles,\nsuch as water droplets and ice crystals. Cloud particle properties include\nposition, diameter, and shape. We present a hologram processing algorithm,\nHolodecML, that utilizes a neural segmentation model, GPUs, and computational\nparallelization. HolodecML is trained using synthetically generated holograms\nbased on a model of the instrument, and predicts masks around particles found\nwithin reconstructed images. From these masks, the position and size of the\ndetected particles can be characterized in three dimensions. In order to\nsuccessfully process real holograms, we find we must apply a series of image\ncorrupting transformations and noise to the synthetic images used in training.\n  In this evaluation, HolodecML had comparable position and size estimation\nperformance to the standard processing method, but improved particle detection\nby nearly 20\\% on several thousand manually labeled HOLODEC images. However,\nthe improvement only occurred when image corruption was performed on the\nsimulated images during training, thereby mimicking non-ideal conditions in the\nactual probe. The trained model also learned to differentiate artifacts and\nother impurities in the HOLODEC images from the particles, even though no such\nobjects were present in the training data set, while the standard processing\nmethod struggled to separate particles from artifacts. The novelty of the\ntraining approach, which leveraged noise as a means for parameterizing\nnon-ideal aspects of the HOLODEC detector, could be applied in other domains\nwhere the theoretical model is incapable of fully describing the real-world\noperation of the instrument and accurate truth data required for supervised\nlearning cannot be obtained from real-world observations.\n",
                "链接": "https://arxiv.org/abs/2203.08898"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用gpt4做评测指标优缺点的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "116110",
                "标题": "Enhancing Medical Text Evaluation with GPT-4",
                "作者": " Yiqing Xie,  Sheng Zhang,  Hao Cheng,  Zelalem Gero,  Cliff Wong,  Tristan Naumann,  Hoifung Poon",
                "发布日期": "2023-11-17",
                "摘要": "  In the evaluation of medical text generation, it is essential to scrutinize\neach piece of information and ensure the utmost accuracy of the evaluation.\nExisting evaluation metrics either focus on coarse-level evaluation that\nassigns one score for the whole generated output or rely on evaluation models\ntrained on general domain, resulting in inaccuracies when adapted to the\nmedical domain. To address these issues, we propose a set of factuality-centric\nevaluation aspects and design corresponding GPT-4-based metrics for medical\ntext generation. We systematically compare these metrics with existing ones on\nclinical note generation and medical report summarization tasks, revealing low\ninter-metric correlation. A comprehensive human evaluation confirms that the\nproposed GPT-4-based metrics exhibit substantially higher agreement with human\njudgments than existing evaluation metrics. Our study contributes to the\nunderstanding of medical text generation evaluation and offers a more reliable\nalternative to existing metrics.\n",
                "链接": "https://arxiv.org/abs/2311.09581"
            },
            {
                "文章ID": "110350",
                "标题": "Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large\n  Language Models on Sequence to Sequence Tasks",
                "作者": " Andrea Sottana,  Bin Liang,  Kai Zou,  Zheng Yuan",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) evaluation is a patchy and inconsistent\nlandscape, and it is becoming clear that the quality of automatic evaluation\nmetrics is not keeping up with the pace of development of generative models. We\naim to improve the understanding of current models' performance by providing a\npreliminary and hybrid evaluation on a range of open and closed-source\ngenerative LLMs on three NLP benchmarks: text summarisation, text\nsimplification and grammatical error correction (GEC), using both automatic and\nhuman evaluation. We also explore the potential of the recently released GPT-4\nto act as an evaluator. We find that ChatGPT consistently outperforms many\nother popular models according to human reviewers on the majority of metrics,\nwhile scoring much more poorly when using classic automatic evaluation metrics.\nWe also find that human reviewers rate the gold reference as much worse than\nthe best models' outputs, indicating the poor quality of many popular\nbenchmarks. Finally, we find that GPT-4 is capable of ranking models' outputs\nin a way which aligns reasonably closely to human judgement despite\ntask-specific variations, with a lower alignment in the GEC task.\n",
                "链接": "https://arxiv.org/abs/2310.13800"
            },
            {
                "文章ID": "81046",
                "标题": "Evaluation of Question Generation Needs More References",
                "作者": " Shinhyeok Oh,  Hyojun Go,  Hyeongdon Moon,  Yunsung Lee,  Myeongho Jeong,  Hyun Seung Lee,  Seungtaek Choi",
                "发布日期": "2023-05-29",
                "摘要": "  Question generation (QG) is the task of generating a valid and fluent\nquestion based on a given context and the target answer. According to various\npurposes, even given the same context, instructors can ask questions about\ndifferent concepts, and even the same concept can be written in different ways.\nHowever, the evaluation for QG usually depends on single reference-based\nsimilarity metrics, such as n-gram-based metric or learned metric, which is not\nsufficient to fully evaluate the potential of QG methods. To this end, we\npropose to paraphrase the reference question for a more robust QG evaluation.\nUsing large language models such as GPT-3, we created semantically and\nsyntactically diverse questions, then adopt the simple aggregation of the\npopular evaluation metrics as the final scores. Through our experiments, we\nfound that using multiple (pseudo) references is more effective for QG\nevaluation while showing a higher correlation with human evaluations than\nevaluation with a single reference.\n",
                "链接": "https://arxiv.org/abs/2305.16626"
            },
            {
                "文章ID": "54431",
                "标题": "On the Blind Spots of Model-Based Evaluation Metrics for Text Generation",
                "作者": " Tianxing He,  Jingyu Zhang,  Tianle Wang,  Sachin Kumar,  Kyunghyun Cho,  James Glass,  Yulia Tsvetkov",
                "发布日期": "2023-05-22",
                "摘要": "  In this work, we explore a useful but often neglected methodology for\nrobustness analysis of text generation evaluation metrics: stress tests with\nsynthetic data. Basically, we design and synthesize a wide range of potential\nerrors and check whether they result in a commensurate drop in the metric\nscores. We examine a range of recently proposed evaluation metrics based on\npretrained language models, for the tasks of open-ended generation,\ntranslation, and summarization. Our experiments reveal interesting\ninsensitivities, biases, or even loopholes in existing metrics. For example, we\nfind that BERTScore is confused by truncation errors in summarization, and\nMAUVE (built on top of GPT-2) is insensitive to errors at the beginning or\nmiddle of generations. Further, we investigate the reasons behind these blind\nspots and suggest practical workarounds for a more reliable evaluation of text\ngeneration. We have released our code and data at\nhttps://github.com/cloudygoose/blindspot_nlg.\n",
                "链接": "https://arxiv.org/abs/2212.10020"
            },
            {
                "文章ID": "77571",
                "标题": "NLG Evaluation Metrics Beyond Correlation Analysis: An Empirical Metric\n  Preference Checklist",
                "作者": " Iftitahu Ni'mah,  Meng Fang,  Vlado Menkovski,  Mykola Pechenizkiy",
                "发布日期": "2023-05-29",
                "摘要": "  In this study, we analyze automatic evaluation metrics for Natural Language\nGeneration (NLG), specifically task-agnostic metrics and human-aligned metrics.\nTask-agnostic metrics, such as Perplexity, BLEU, BERTScore, are cost-effective\nand highly adaptable to diverse NLG tasks, yet they have a weak correlation\nwith human. Human-aligned metrics (CTC, CtrlEval, UniEval) improves correlation\nlevel by incorporating desirable human-like qualities as training objective.\nHowever, their effectiveness at discerning system-level performance and quality\nof system outputs remain unclear.\n  We present metric preference checklist as a framework to assess the\neffectiveness of automatic metrics in three NLG tasks: Text Summarization,\nDialogue Response Generation, and Controlled Generation. Our proposed framework\nprovides access: (i) for verifying whether automatic metrics are faithful to\nhuman preference, regardless of their correlation level to human; and (ii) for\ninspecting the strengths and limitations of NLG systems via pairwise\nevaluation. We show that automatic metrics provide a better guidance than human\non discriminating system-level performance in Text Summarization and Controlled\nGeneration tasks. We also show that multi-aspect human-aligned metric (UniEval)\nis not necessarily dominant over single-aspect human-aligned metrics (CTC,\nCtrlEval) and task-agnostic metrics (BLEU, BERTScore), particularly in\nControlled Generation tasks.\n",
                "链接": "https://arxiv.org/abs/2305.08566"
            },
            {
                "文章ID": "64442",
                "标题": "Navigating the Metric Maze: A Taxonomy of Evaluation Metrics for Anomaly\n  Detection in Time Series",
                "作者": " Sondre Sørbø,  Massimiliano Ruocco",
                "发布日期": "2023-03-03",
                "摘要": "  The field of time series anomaly detection is constantly advancing, with\nseveral methods available, making it a challenge to determine the most\nappropriate method for a specific domain. The evaluation of these methods is\nfacilitated by the use of metrics, which vary widely in their properties.\nDespite the existence of new evaluation metrics, there is limited agreement on\nwhich metrics are best suited for specific scenarios and domain, and the most\ncommonly used metrics have faced criticism in the literature. This paper\nprovides a comprehensive overview of the metrics used for the evaluation of\ntime series anomaly detection methods, and also defines a taxonomy of these\nbased on how they are calculated. By defining a set of properties for\nevaluation metrics and a set of specific case studies and experiments, twenty\nmetrics are analyzed and discussed in detail, highlighting the unique\nsuitability of each for specific tasks. Through extensive experimentation and\nanalysis, this paper argues that the choice of evaluation metric must be made\nwith care, taking into account the specific requirements of the task at hand.\n",
                "链接": "https://arxiv.org/abs/2303.01272"
            },
            {
                "文章ID": "16357",
                "标题": "Offline Retrieval Evaluation Without Evaluation Metrics",
                "作者": " Fernando Diaz,  Andres Ferraro",
                "发布日期": "2022-04-26",
                "摘要": "  Offline evaluation of information retrieval and recommendation has\ntraditionally focused on distilling the quality of a ranking into a scalar\nmetric such as average precision or normalized discounted cumulative gain. We\ncan use this metric to compare the performance of multiple systems for the same\nrequest. Although evaluation metrics provide a convenient summary of system\nperformance, they also collapse subtle differences across users into a single\nnumber and can carry assumptions about user behavior and utility not supported\nacross retrieval scenarios. We propose recall-paired preference (RPP), a\nmetric-free evaluation method based on directly computing a preference between\nranked lists. RPP simulates multiple user subpopulations per query and compares\nsystems across these pseudo-populations. Our results across multiple search and\nrecommendation tasks demonstrate that RPP substantially improves discriminative\npower while correlating well with existing metrics and being equally robust to\nincomplete data.\n",
                "链接": "https://arxiv.org/abs/2204.11400"
            },
            {
                "文章ID": "54518",
                "标题": "Extrinsic Evaluation of Machine Translation Metrics",
                "作者": " Nikita Moghe,  Tom Sherborne,  Mark Steedman,  Alexandra Birch",
                "发布日期": "2023-06-21",
                "摘要": "  Automatic machine translation (MT) metrics are widely used to distinguish the\ntranslation qualities of machine translation systems across relatively large\ntest sets (system-level evaluation). However, it is unclear if automatic\nmetrics are reliable at distinguishing good translations from bad translations\nat the sentence level (segment-level evaluation). In this paper, we investigate\nhow useful MT metrics are at detecting the success of a machine translation\ncomponent when placed in a larger platform with a downstream task. We evaluate\nthe segment-level performance of the most widely used MT metrics (chrF, COMET,\nBERTScore, etc.) on three downstream cross-lingual tasks (dialogue state\ntracking, question answering, and semantic parsing). For each task, we only\nhave access to a monolingual task-specific model. We calculate the correlation\nbetween the metric's ability to predict a good/bad translation with the\nsuccess/failure on the final task for the Translate-Test setup. Our experiments\ndemonstrate that all metrics exhibit negligible correlation with the extrinsic\nevaluation of the downstream outcomes. We also find that the scores provided by\nneural metrics are not interpretable mostly because of undefined ranges. We\nsynthesise our analysis into recommendations for future MT metrics to produce\nlabels rather than scores for more informative interaction between machine\ntranslation and multilingual language understanding.\n",
                "链接": "https://arxiv.org/abs/2212.10297"
            },
            {
                "文章ID": "19675",
                "标题": "The Solvability of Interpretability Evaluation Metrics",
                "作者": " Yilun Zhou,  Julie Shah",
                "发布日期": "2023-02-06",
                "摘要": "  Feature attribution methods are popular for explaining neural network\npredictions, and they are often evaluated on metrics such as comprehensiveness\nand sufficiency. In this paper, we highlight an intriguing property of these\nmetrics: their solvability. Concretely, we can define the problem of optimizing\nan explanation for a metric, which can be solved by beam search. This\nobservation leads to the obvious yet unaddressed question: why do we use\nexplainers (e.g., LIME) not based on solving the target metric, if the metric\nvalue represents explanation quality? We present a series of investigations\nshowing strong performance of this beam search explainer and discuss its\nbroader implication: a definition-evaluation duality of interpretability\nconcepts. We implement the explainer and release the Python solvex package for\nmodels of text, image and tabular domains.\n",
                "链接": "https://arxiv.org/abs/2205.08696"
            },
            {
                "文章ID": "54347",
                "标题": "LENS: A Learnable Evaluation Metric for Text Simplification",
                "作者": " Mounica Maddela,  Yao Dou,  David Heineman,  Wei Xu",
                "发布日期": "2023-07-11",
                "摘要": "  Training learnable metrics using modern language models has recently emerged\nas a promising method for the automatic evaluation of machine translation.\nHowever, existing human evaluation datasets for text simplification have\nlimited annotations that are based on unitary or outdated models, making them\nunsuitable for this approach. To address these issues, we introduce the\nSimpEval corpus that contains: SimpEval_past, comprising 12K human ratings on\n2.4K simplifications of 24 past systems, and SimpEval_2022, a challenging\nsimplification benchmark consisting of over 1K human ratings of 360\nsimplifications including GPT-3.5 generated text. Training on SimpEval, we\npresent LENS, a Learnable Evaluation Metric for Text Simplification. Extensive\nempirical results show that LENS correlates much better with human judgment\nthan existing metrics, paving the way for future progress in the evaluation of\ntext simplification. We also introduce Rank and Rate, a human evaluation\nframework that rates simplifications from several models in a list-wise manner\nusing an interactive interface, which ensures both consistency and accuracy in\nthe evaluation process and is used to create the SimpEval datasets.\n",
                "链接": "https://arxiv.org/abs/2212.09739"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用GPT4v完成多模态智能体的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "63780",
                "标题": "Multimodal Speech Recognition for Language-Guided Embodied Agents",
                "作者": " Allen Chang,  Xiaoyuan Zhu,  Aarav Monga,  Seoho Ahn,  Tejas Srinivasan,  Jesse Thomason",
                "发布日期": "2023-10-11",
                "摘要": "  Benchmarks for language-guided embodied agents typically assume text-based\ninstructions, but deployed agents will encounter spoken instructions. While\nAutomatic Speech Recognition (ASR) models can bridge the input gap, erroneous\nASR transcripts can hurt the agents' ability to complete tasks. In this work,\nwe propose training a multimodal ASR model to reduce errors in transcribing\nspoken instructions by considering the accompanying visual context. We train\nour model on a dataset of spoken instructions, synthesized from the ALFRED task\ncompletion dataset, where we simulate acoustic noise by systematically masking\nspoken words. We find that utilizing visual observations facilitates masked\nword recovery, with multimodal ASR models recovering up to 30% more masked\nwords than unimodal baselines. We also find that a text-trained embodied agent\nsuccessfully completes tasks more often by following transcribed instructions\nfrom multimodal ASR models. github.com/Cylumn/embodied-multimodal-asr\n",
                "链接": "https://arxiv.org/abs/2302.14030"
            },
            {
                "文章ID": "83868",
                "标题": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM\n  Agents",
                "作者": " Yashar Talebirad,  Amirhossein Nadiri",
                "发布日期": "2023-06-07",
                "摘要": "  In this paper, we present a novel framework for enhancing the capabilities of\nlarge language models (LLMs) by leveraging the power of multi-agent systems.\nOur framework introduces a collaborative environment where multiple intelligent\nagent components, each with distinctive attributes and roles, work together to\nhandle complex tasks more efficiently and effectively. We demonstrate the\npracticality and versatility of our framework through case studies in\nartificial general intelligence (AGI), specifically focusing on the Auto-GPT\nand BabyAGI models. We also examine the \"Gorilla\" model, which integrates\nexternal APIs into the LLM. Our framework addresses limitations and challenges\nsuch as looping issues, security risks, scalability, system evaluation, and\nethical considerations. By modeling various domains such as courtroom\nsimulations and software development scenarios, we showcase the potential\napplications and benefits of our proposed multi-agent system. Our framework\nprovides an avenue for advancing the capabilities and performance of LLMs\nthrough collaboration and knowledge exchange among intelligent agents.\n",
                "链接": "https://arxiv.org/abs/2306.03314"
            },
            {
                "文章ID": "124256",
                "标题": "AppAgent: Multimodal Agents as Smartphone Users",
                "作者": " Chi Zhang,  Zhao Yang,  Jiaxuan Liu,  Yucheng Han,  Xin Chen,  Zebiao Huang,  Bin Fu,  Gang Yu",
                "发布日期": "2023-12-25",
                "摘要": "  Recent advancements in large language models (LLMs) have led to the creation\nof intelligent agents capable of performing complex tasks. This paper\nintroduces a novel LLM-based multimodal agent framework designed to operate\nsmartphone applications. Our framework enables the agent to operate smartphone\napplications through a simplified action space, mimicking human-like\ninteractions such as tapping and swiping. This novel approach bypasses the need\nfor system back-end access, thereby broadening its applicability across diverse\napps. Central to our agent's functionality is its innovative learning method.\nThe agent learns to navigate and use new apps either through autonomous\nexploration or by observing human demonstrations. This process generates a\nknowledge base that the agent refers to for executing complex tasks across\ndifferent applications. To demonstrate the practicality of our agent, we\nconducted extensive testing over 50 tasks in 10 different applications,\nincluding social media, email, maps, shopping, and sophisticated image editing\ntools. The results affirm our agent's proficiency in handling a diverse array\nof high-level tasks.\n",
                "链接": "https://arxiv.org/abs/2312.13771"
            },
            {
                "文章ID": "61287",
                "标题": "Universal Agent Mixtures and the Geometry of Intelligence",
                "作者": " Samuel Allen Alexander,  David Quarel,  Len Du,  Marcus Hutter",
                "发布日期": "2023-02-14",
                "摘要": "  Inspired by recent progress in multi-agent Reinforcement Learning (RL), in\nthis work we examine the collective intelligent behaviour of theoretical\nuniversal agents by introducing a weighted mixture operation. Given a weighted\nset of agents, their weighted mixture is a new agent whose expected total\nreward in any environment is the corresponding weighted average of the original\nagents' expected total rewards in that environment. Thus, if RL agent\nintelligence is quantified in terms of performance across environments, the\nweighted mixture's intelligence is the weighted average of the original agents'\nintelligences. This operation enables various interesting new theorems that\nshed light on the geometry of RL agent intelligence, namely: results about\nsymmetries, convex agent-sets, and local extrema. We also show that any RL\nagent intelligence measure based on average performance across environments,\nsubject to certain weak technical conditions, is identical (up to a constant\nfactor) to performance within a single environment dependent on said\nintelligence measure.\n",
                "链接": "https://arxiv.org/abs/2302.06083"
            },
            {
                "文章ID": "89644",
                "标题": "Wireless Multi-Agent Generative AI: From Connected Intelligence to\n  Collective Intelligence",
                "作者": " Hang Zou,  Qiyang Zhao,  Lina Bariah,  Mehdi Bennis,  Merouane Debbah",
                "发布日期": "2023-07-07",
                "摘要": "  The convergence of generative large language models (LLMs), edge networks,\nand multi-agent systems represents a groundbreaking synergy that holds immense\npromise for future wireless generations, harnessing the power of collective\nintelligence and paving the way for self-governed networks where intelligent\ndecision-making happens right at the edge. This article puts the stepping-stone\nfor incorporating multi-agent generative artificial intelligence (AI) in\nwireless networks, and sets the scene for realizing on-device LLMs, where\nmulti-agent LLMs are collaboratively planning and solving tasks to achieve a\nnumber of network goals. We further investigate the profound limitations of\ncloud-based LLMs, and explore multi-agent LLMs from a game theoretic\nperspective, where agents collaboratively solve tasks in competitive\nenvironments. Moreover, we establish the underpinnings for the architecture\ndesign of wireless multi-agent generative AI systems at the network level and\nthe agent level, and we identify the wireless technologies that are envisioned\nto play a key role in enabling on-device LLM. To demonstrate the promising\npotentials of wireless multi-agent generative AI networks, we highlight the\nbenefits that can be achieved when implementing wireless generative agents in\nintent-based networking, and we provide a case study to showcase how on-device\nLLMs can contribute to solving network intents in a collaborative fashion. We\nfinally shed lights on potential challenges and sketch a research roadmap\ntowards realizing the vision of wireless collective intelligence.\n",
                "链接": "https://arxiv.org/abs/2307.02757"
            },
            {
                "文章ID": "34904",
                "标题": "Towards A Complete Multi-Agent Pathfinding Algorithm For Large Agents",
                "作者": " Stepan Dergachev,  Konstantin Yakovlev",
                "发布日期": "2022-08-26",
                "摘要": "  Multi-agent pathfinding (MAPF) is a challenging problem which is hard to\nsolve optimally even when simplifying assumptions are adopted, e.g. planar\ngraphs (typically -- grids), discretized time, uniform duration of move and\nwait actions etc. On the other hand, MAPF under such restrictive assumptions\n(also known as the Classical MAPF) is equivalent to the so-called pebble motion\nproblem for which non-optimal polynomial time algorithms do exist. Recently, a\nbody of works emerged that investigated MAPF beyond the basic setting and, in\nparticular, considered agents of arbitrary size and shape. Still, to the best\nof our knowledge no complete algorithms for such MAPF variant exists. In this\nwork we attempt to narrow this gap by considering MAPF for large agents and\nsuggesting how this problem can be reduced to pebble motion on (general)\ngraphs. The crux of this reduction is the procedure that moves away the agents\naway from the edge which is needed to perform a move action of the current\nagent. We consider different variants of how this procedure can be implemented\nand present a variant of the pebble motion algorithm which incorporates this\nprocedure. Unfortunately, the algorithm is still incomplete, but empirically we\nshow that it is able to solve much more MAPF instances (under the strict time\nlimit) with large agents on arbitrary non-planar graphs (roadmaps) compared to\nthe state-of-the-art MAPF solver -- Continous Conflict-Based Search (CCBS).\n",
                "链接": "https://arxiv.org/abs/2208.12236"
            },
            {
                "文章ID": "21325",
                "标题": "Evaluating Multimodal Interactive Agents",
                "作者": " Josh Abramson,  Arun Ahuja,  Federico Carnevale,  Petko Georgiev,  Alex Goldin,  Alden Hung,  Jessica Landon,  Timothy Lillicrap,  Alistair Muldal,  Blake Richards,  Adam Santoro,  Tamara von Glehn,  Greg Wayne,  Nathaniel Wong,  Chen Yan",
                "发布日期": "2022-07-15",
                "摘要": "  Creating agents that can interact naturally with humans is a common goal in\nartificial intelligence (AI) research. However, evaluating these interactions\nis challenging: collecting online human-agent interactions is slow and\nexpensive, yet faster proxy metrics often do not correlate well with\ninteractive evaluation. In this paper, we assess the merits of these existing\nevaluation metrics and present a novel approach to evaluation called the\nStandardised Test Suite (STS). The STS uses behavioural scenarios mined from\nreal human interaction data. Agents see replayed scenario context, receive an\ninstruction, and are then given control to complete the interaction offline.\nThese agent continuations are recorded and sent to human annotators to mark as\nsuccess or failure, and agents are ranked according to the proportion of\ncontinuations in which they succeed. The resulting STS is fast, controlled,\ninterpretable, and representative of naturalistic interactions. Altogether, the\nSTS consolidates much of what is desirable across many of our standard\nevaluation metrics, allowing us to accelerate research progress towards\nproducing agents that can interact naturally with humans. A video may be found\nat https://youtu.be/YR1TngGORGQ.\n",
                "链接": "https://arxiv.org/abs/2205.13274"
            },
            {
                "文章ID": "81277",
                "标题": "Integrating Generative Artificial Intelligence in Intelligent Vehicle\n  Systems",
                "作者": " Lukas Stappen,  Jeremy Dillmann,  Serena Striegel,  Hans-Jörg Vögel,  Nicolas Flores-Herr,  Björn W. Schuller",
                "发布日期": "2023-05-30",
                "摘要": "  This paper aims to serve as a comprehensive guide for researchers and\npractitioners, offering insights into the current state, potential\napplications, and future research directions for generative artificial\nintelligence and foundation models within the context of intelligent vehicles.\nAs the automotive industry progressively integrates AI, generative artificial\nintelligence technologies hold the potential to revolutionize user\ninteractions, delivering more immersive, intuitive, and personalised in-car\nexperiences. We provide an overview of current applications of generative\nartificial intelligence in the automotive domain, emphasizing speech, audio,\nvision, and multimodal interactions. We subsequently outline critical future\nresearch areas, including domain adaptability, alignment, multimodal\nintegration and others, as well as, address the challenges and risks associated\nwith ethics. By fostering collaboration and addressing these research areas,\ngenerative artificial intelligence can unlock its full potential, transforming\nthe driving experience and shaping the future of intelligent vehicles.\n",
                "链接": "https://arxiv.org/abs/2305.17137"
            },
            {
                "文章ID": "22312",
                "标题": "CBS-Budget (CBSB): A Complete and Bounded Suboptimal Search for\n  Multi-Agent Path Finding",
                "作者": " Jaein Lim,  Panagiotis Tsiotras",
                "发布日期": "2022-06-02",
                "摘要": "  Multi-Agent Path Finding (MAPF) is the problem of finding a collection of\ncollision-free paths for a team of multiple agents while minimizing some global\ncost, such as the sum of the time travelled by all agents, or the time\ntravelled by the last agent. Conflict Based Search (CBS) is a leading complete\nand optimal MAPF solver which lazily explores the joint agent state space,\nusing an admissible heuristic joint plan. Such an admissible heuristic joint\nplan is computed by combining individual shortest paths found without\nconsidering inter-agent conflicts, and which becomes gradually more informed as\nconstraints are added to individual agents' path planning problems to avoid\ndiscovered conflicts. In this paper, we seek to speedup CBS by finding a more\ninformed heuristic joint plan which is bounded from above. We first propose the\nbudgeted Class-Ordered A* (bCOA*), a novel algorithm that finds the shortest\npath with minimal number of conflicts that is upper bounded in terms of length.\nThen, we propose a novel bounded-cost variant of CBS, called CBS-Budget (CBSB)\nby using a bCOA* search at the low-level search of the CBS and by using a\nmodified focal search at the high-level search of the CBS. We prove that CBSB\nis complete and bounded-suboptimal. In our numerical experiments, CBSB finds a\nnear optimal solution for hundreds of agents within a fraction of a second.\nCBSB shows state-of-the-art performance, comparable to Explicit Estimation CBS\n(EECBS), an enhanced recent version of CBS. On the other hand, CBSB is easier\nto implement than EECBS, since only two priority queues at the high-level\nsearch are needed as in Enhanced CBS (ECBS).\n",
                "链接": "https://arxiv.org/abs/2206.00130"
            },
            {
                "文章ID": "35279",
                "标题": "CH-MARL: A Multimodal Benchmark for Cooperative, Heterogeneous\n  Multi-Agent Reinforcement Learning",
                "作者": " Vasu Sharma,  Prasoon Goyal,  Kaixiang Lin,  Govind Thattai,  Qiaozi Gao,  Gaurav S. Sukhatme",
                "发布日期": "2022-08-30",
                "摘要": "  We propose a multimodal (vision-and-language) benchmark for cooperative and\nheterogeneous multi-agent learning. We introduce a benchmark multimodal dataset\nwith tasks involving collaboration between multiple simulated heterogeneous\nrobots in a rich multi-room home environment. We provide an integrated learning\nframework, multimodal implementations of state-of-the-art multi-agent\nreinforcement learning techniques, and a consistent evaluation protocol. Our\nexperiments investigate the impact of different modalities on multi-agent\nlearning performance. We also introduce a simple message passing method between\nagents. The results suggest that multimodality introduces unique challenges for\ncooperative multi-agent learning and there is significant room for advancing\nmulti-agent reinforcement learning methods in such settings.\n",
                "链接": "https://arxiv.org/abs/2208.13626"
            }
        ]
    },
    {
        "question": {
            "question": "使用LLM进行蛋白质结构/功能/性质预测的论文",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找使用BERT和RoBERTa进行多语言情感分析的最新论文，要求涵盖2022年以来的研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "53574",
                "标题": "Multi-task Learning for Cross-Lingual Sentiment Analysis",
                "作者": " Gaurish Thakkar,  Nives Mikelic Preradovic,  Marko Tadic",
                "发布日期": "2022-12-15",
                "摘要": "  This paper presents a cross-lingual sentiment analysis of news articles using\nzero-shot and few-shot learning. The study aims to classify the Croatian news\narticles with positive, negative, and neutral sentiments using the Slovene\ndataset. The system is based on a trilingual BERT-based model trained in three\nlanguages: English, Slovene, Croatian. The paper analyses different setups\nusing datasets in two languages and proposes a simple multi-task model to\nperform sentiment classification. The evaluation is performed using the\nfew-shot and zero-shot scenarios in single-task and multi-task experiments for\nCroatian and Slovene.\n",
                "链接": "https://arxiv.org/abs/2212.07160"
            },
            {
                "文章ID": "22103",
                "标题": "A Knowledge-Enhanced Adversarial Model for Cross-lingual Structured\n  Sentiment Analysis",
                "作者": " Qi Zhang,  Jie Zhou,  Qin Chen,  Qingchun Bai,  Jun Xiao,  Liang He",
                "发布日期": "2022-06-01",
                "摘要": "  Structured sentiment analysis, which aims to extract the complex semantic\nstructures such as holders, expressions, targets, and polarities, has obtained\nwidespread attention from both industry and academia. Unfortunately, the\nexisting structured sentiment analysis datasets refer to a few languages and\nare relatively small, limiting neural network models' performance. In this\npaper, we focus on the cross-lingual structured sentiment analysis task, which\naims to transfer the knowledge from the source language to the target one.\nNotably, we propose a Knowledge-Enhanced Adversarial Model (\\texttt{KEAM}) with\nboth implicit distributed and explicit structural knowledge to enhance the\ncross-lingual transfer. First, we design an adversarial embedding adapter for\nlearning an informative and robust representation by capturing implicit\nsemantic information from diverse multi-lingual embeddings adaptively. Then, we\npropose a syntax GCN encoder to transfer the explicit semantic information\n(e.g., universal dependency tree) among multiple languages. We conduct\nexperiments on five datasets and compare \\texttt{KEAM} with both the supervised\nand unsupervised methods. The extensive experimental results show that our\n\\texttt{KEAM} model outperforms all the unsupervised baselines in various\nmetrics.\n",
                "链接": "https://arxiv.org/abs/2205.15514"
            },
            {
                "文章ID": "45781",
                "标题": "Sentiment Classification of Code-Switched Text using Pre-trained\n  Multilingual Embeddings and Segmentation",
                "作者": " Saurav K. Aryal,  Howard Prioleau,  Gloria Washington",
                "发布日期": "2022-11-01",
                "摘要": "  With increasing globalization and immigration, various studies have estimated\nthat about half of the world population is bilingual. Consequently, individuals\nconcurrently use two or more languages or dialects in casual conversational\nsettings. However, most research is natural language processing is focused on\nmonolingual text. To further the work in code-switched sentiment analysis, we\npropose a multi-step natural language processing algorithm utilizing points of\ncode-switching in mixed text and conduct sentiment analysis around those\nidentified points. The proposed sentiment analysis algorithm uses semantic\nsimilarity derived from large pre-trained multilingual models with a\nhandcrafted set of positive and negative words to determine the polarity of\ncode-switched text. The proposed approach outperforms a comparable baseline\nmodel by 11.2% for accuracy and 11.64% for F1-score on a Spanish-English\ndataset. Theoretically, the proposed algorithm can be expanded for sentiment\nanalysis of multiple languages with limited human expertise.\n",
                "链接": "https://arxiv.org/abs/2210.16461"
            },
            {
                "文章ID": "15513",
                "标题": "Mono vs Multilingual BERT for Hate Speech Detection and Text\n  Classification: A Case Study in Marathi",
                "作者": " Abhishek Velankar,  Hrushikesh Patil,  Raviraj Joshi",
                "发布日期": "2022-11-15",
                "摘要": "  Transformers are the most eminent architectures used for a vast range of\nNatural Language Processing tasks. These models are pre-trained over a large\ntext corpus and are meant to serve state-of-the-art results over tasks like\ntext classification. In this work, we conduct a comparative study between\nmonolingual and multilingual BERT models. We focus on the Marathi language and\nevaluate the models on the datasets for hate speech detection, sentiment\nanalysis and simple text classification in Marathi. We use standard\nmultilingual models such as mBERT, indicBERT and xlm-RoBERTa and compare with\nMahaBERT, MahaALBERT and MahaRoBERTa, the monolingual models for Marathi. We\nfurther show that Marathi monolingual models outperform the multilingual BERT\nvariants on five different downstream fine-tuning experiments. We also evaluate\nsentence embeddings from these models by freezing the BERT encoder layers. We\nshow that monolingual MahaBERT based models provide rich representations as\ncompared to sentence embeddings from multi-lingual counterparts. However, we\nobserve that these embeddings are not generic enough and do not work well on\nout of domain social media datasets. We consider two Marathi hate speech\ndatasets L3Cube-MahaHate, HASOC-2021, a Marathi sentiment classification\ndataset L3Cube-MahaSent, and Marathi Headline, Articles classification\ndatasets.\n",
                "链接": "https://arxiv.org/abs/2204.08669"
            },
            {
                "文章ID": "15733",
                "标题": "You Are What You Write: Preserving Privacy in the Era of Large Language\n  Models",
                "作者": " Richard Plant,  Valerio Giuffrida,  Dimitra Gkatzia",
                "发布日期": "2022-04-21",
                "摘要": "  Large scale adoption of large language models has introduced a new era of\nconvenient knowledge transfer for a slew of natural language processing tasks.\nHowever, these models also run the risk of undermining user trust by exposing\nunwanted information about the data subjects, which may be extracted by a\nmalicious party, e.g. through adversarial attacks. We present an empirical\ninvestigation into the extent of the personal information encoded into\npre-trained representations by a range of popular models, and we show a\npositive correlation between the complexity of a model, the amount of data used\nin pre-training, and data leakage. In this paper, we present the first wide\ncoverage evaluation and comparison of some of the most popular\nprivacy-preserving algorithms, on a large, multi-lingual dataset on sentiment\nanalysis annotated with demographic information (location, age and gender). The\nresults show since larger and more complex models are more prone to leaking\nprivate information, use of privacy-preserving methods is highly desirable. We\nalso find that highly privacy-preserving technologies like differential privacy\n(DP) can have serious model utility effects, which can be ameliorated using\nhybrid or metric-DP techniques.\n",
                "链接": "https://arxiv.org/abs/2204.09391"
            },
            {
                "文章ID": "0",
                "标题": "A Literature Review on Length of Stay Prediction for Stroke Patients\n  using Machine Learning and Statistical Approaches",
                "作者": " Ola Alkhatib,  Ayman Alahmar",
                "发布日期": "2022-01-06",
                "摘要": "  Hospital length of stay (LOS) is one of the most essential healthcare metrics\nthat reflects the hospital quality of service and helps improve hospital\nscheduling and management. LOS prediction helps in cost management because\npatients who remain in hospitals usually do so in hospital units where\nresources are severely limited. In this study, we reviewed papers on LOS\nprediction using machine learning and statistical approaches. Our literature\nreview considers research studies that focus on LOS prediction for stroke\npatients. Some of the surveyed studies revealed that authors reached\ncontradicting conclusions. For example, the age of the patient was considered\nan important predictor of LOS for stroke patients in some studies, while other\nstudies concluded that age was not a significant factor. Therefore, additional\nresearch is required in this domain to further understand the predictors of LOS\nfor stroke patients.\n",
                "链接": "https://arxiv.org/abs/2201.00005"
            },
            {
                "文章ID": "2",
                "标题": "Confidence-Aware Multi-Teacher Knowledge Distillation",
                "作者": " Hailin Zhang,  Defang Chen,  Can Wang",
                "发布日期": "2022-02-15",
                "摘要": "  Knowledge distillation is initially introduced to utilize additional\nsupervision from a single teacher model for the student model training. To\nboost the student performance, some recent variants attempt to exploit diverse\nknowledge sources from multiple teachers. However, existing studies mainly\nintegrate knowledge from diverse sources by averaging over multiple teacher\npredictions or combining them using other various label-free strategies, which\nmay mislead student in the presence of low-quality teacher predictions. To\ntackle this problem, we propose Confidence-Aware Multi-teacher Knowledge\nDistillation (CA-MKD), which adaptively assigns sample-wise reliability for\neach teacher prediction with the help of ground-truth labels, with those\nteacher predictions close to one-hot labels assigned large weights. Besides,\nCA-MKD incorporates intermediate layers to stable the knowledge transfer\nprocess. Extensive experiments show that our CA-MKD consistently outperforms\nall compared state-of-the-art methods across various teacher-student\narchitectures.\n",
                "链接": "https://arxiv.org/abs/2201.00007"
            },
            {
                "文章ID": "3",
                "标题": "A Lightweight and Accurate Spatial-Temporal Transformer for Traffic\n  Forecasting",
                "作者": " Guanyao Li,  Shuhan Zhong,  S. -H. Gary Chan,  Ruiyuan Li,  Chih-Chieh Hung,  Wen-Chih Peng",
                "发布日期": "2022-05-05",
                "摘要": "  We study the forecasting problem for traffic with dynamic, possibly\nperiodical, and joint spatial-temporal dependency between regions. Given the\naggregated inflow and outflow traffic of regions in a city from time slots 0 to\nt-1, we predict the traffic at time t at any region. Prior arts in the area\noften consider the spatial and temporal dependencies in a decoupled manner or\nare rather computationally intensive in training with a large number of\nhyper-parameters to tune. We propose ST-TIS, a novel, lightweight, and accurate\nSpatial-Temporal Transformer with information fusion and region sampling for\ntraffic forecasting. ST-TIS extends the canonical Transformer with information\nfusion and region sampling. The information fusion module captures the complex\nspatial-temporal dependency between regions. The region sampling module is to\nimprove the efficiency and prediction accuracy, cutting the computation\ncomplexity for dependency learning from $O(n^2)$ to $O(n\\sqrt{n})$, where n is\nthe number of regions. With far fewer parameters than state-of-the-art models,\nthe offline training of our model is significantly faster in terms of tuning\nand computation (with a reduction of up to $90\\%$ on training time and network\nparameters). Notwithstanding such training efficiency, extensive experiments\nshow that ST-TIS is substantially more accurate in online prediction than\nstate-of-the-art approaches (with an average improvement of up to $9.5\\%$ on\nRMSE, and $12.4\\%$ on MAPE).\n",
                "链接": "https://arxiv.org/abs/2201.00008"
            },
            {
                "文章ID": "5",
                "标题": "An Efficient Federated Distillation Learning System for Multi-task Time\n  Series Classification",
                "作者": " Huanlai Xing,  Zhiwen Xiao,  Rong Qu,  Zonghai Zhu,  Bowen Zhao",
                "发布日期": "2022-01-04",
                "摘要": "  This paper proposes an efficient federated distillation learning system\n(EFDLS) for multi-task time series classification (TSC). EFDLS consists of a\ncentral server and multiple mobile users, where different users may run\ndifferent TSC tasks. EFDLS has two novel components, namely a feature-based\nstudent-teacher (FBST) framework and a distance-based weights matching (DBWM)\nscheme. Within each user, the FBST framework transfers knowledge from its\nteacher's hidden layers to its student's hidden layers via knowledge\ndistillation, with the teacher and student having identical network structure.\nFor each connected user, its student model's hidden layers' weights are\nuploaded to the EFDLS server periodically. The DBWM scheme is deployed on the\nserver, with the least square distance used to measure the similarity between\nthe weights of two given models. This scheme finds a partner for each connected\nuser such that the user's and its partner's weights are the closest among all\nthe weights uploaded. The server exchanges and sends back the user's and its\npartner's weights to these two users which then load the received weights to\ntheir teachers' hidden layers. Experimental results show that the proposed\nEFDLS achieves excellent performance on a set of selected UCR2018 datasets\nregarding top-1 accuracy.\n",
                "链接": "https://arxiv.org/abs/2201.00011"
            },
            {
                "文章ID": "6",
                "标题": "MORAL: Aligning AI with Human Norms through Multi-Objective Reinforced\n  Active Learning",
                "作者": " Markus Peschl,  Arkady Zgonnikov,  Frans A. Oliehoek,  Luciano C. Siebert",
                "发布日期": "2022-01-04",
                "摘要": "  Inferring reward functions from demonstrations and pairwise preferences are\nauspicious approaches for aligning Reinforcement Learning (RL) agents with\nhuman intentions. However, state-of-the art methods typically focus on learning\na single reward model, thus rendering it difficult to trade off different\nreward functions from multiple experts. We propose Multi-Objective Reinforced\nActive Learning (MORAL), a novel method for combining diverse demonstrations of\nsocial norms into a Pareto-optimal policy. Through maintaining a distribution\nover scalarization weights, our approach is able to interactively tune a deep\nRL agent towards a variety of preferences, while eliminating the need for\ncomputing multiple policies. We empirically demonstrate the effectiveness of\nMORAL in two scenarios, which model a delivery and an emergency task that\nrequire an agent to act in the presence of normative conflicts. Overall, we\nconsider our research a step towards multi-objective RL with learned rewards,\nbridging the gap between current reward learning and machine ethics literature.\n",
                "链接": "https://arxiv.org/abs/2201.00012"
            }
        ]
    },
    {
        "question": {
            "question": "请找出使用Transformer模型并在大规模数据集上进行预训练的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "83393",
                "标题": "A Conditional Generative Chatbot using Transformer Model",
                "作者": " Nura Esfandiari,  Kourosh Kiani,  Razieh Rastgoo",
                "发布日期": "2023-09-11",
                "摘要": "  A Chatbot serves as a communication tool between a human user and a machine\nto achieve an appropriate answer based on the human input. In more recent\napproaches, a combination of Natural Language Processing and sequential models\nare used to build a generative Chatbot. The main challenge of these models is\ntheir sequential nature, which leads to less accurate results. To tackle this\nchallenge, in this paper, a novel architecture is proposed using conditional\nWasserstein Generative Adversarial Networks and a transformer model for answer\ngeneration in Chatbots. While the generator of the proposed model consists of a\nfull transformer model to generate an answer, the discriminator includes only\nthe encoder part of a transformer model followed by a classifier. To the best\nof our knowledge, this is the first time that a generative Chatbot is proposed\nusing the embedded transformer in both generator and discriminator models.\nRelying on the parallel computing of the transformer model, the results of the\nproposed model on the Cornell Movie-Dialog corpus and the Chit-Chat datasets\nconfirm the superiority of the proposed model compared to state-of-the-art\nalternatives using different evaluation metrics.\n",
                "链接": "https://arxiv.org/abs/2306.02074"
            },
            {
                "文章ID": "61921",
                "标题": "Robust Human Motion Forecasting using Transformer-based Model",
                "作者": " Esteve Valls Mascaro,  Shuo Ma,  Hyemin Ahn,  Dongheui Lee",
                "发布日期": "2023-04-20",
                "摘要": "  Comprehending human motion is a fundamental challenge for developing\nHuman-Robot Collaborative applications. Computer vision researchers have\naddressed this field by only focusing on reducing error in predictions, but not\ntaking into account the requirements to facilitate its implementation in\nrobots. In this paper, we propose a new model based on Transformer that\nsimultaneously deals with the real time 3D human motion forecasting in the\nshort and long term. Our 2-Channel Transformer (2CH-TR) is able to efficiently\nexploit the spatio-temporal information of a shortly observed sequence (400ms)\nand generates a competitive accuracy against the current state-of-the-art.\n2CH-TR stands out for the efficient performance of the Transformer, being\nlighter and faster than its competitors. In addition, our model is tested in\nconditions where the human motion is severely occluded, demonstrating its\nrobustness in reconstructing and predicting 3D human motion in a highly noisy\nenvironment. Our experiment results show that the proposed 2CH-TR outperforms\nthe ST-Transformer, which is another state-of-the-art model based on the\nTransformer, in terms of reconstruction and prediction under the same\nconditions of input prefix. Our model reduces in 8.89% the mean squared error\nof ST-Transformer in short-term prediction, and 2.57% in long-term prediction\nin Human3.6M dataset with 400ms input prefix. Visit our website\n$\\href{https://sites.google.com/view/estevevallsmascaro/publications/iros2022}{here}$.\n",
                "链接": "https://arxiv.org/abs/2302.08274"
            },
            {
                "文章ID": "8441",
                "标题": "PanFormer: a Transformer Based Model for Pan-sharpening",
                "作者": " Huanyu Zhou,  Qingjie Liu,  Yunhong Wang",
                "发布日期": "2022-04-12",
                "摘要": "  Pan-sharpening aims at producing a high-resolution (HR) multi-spectral (MS)\nimage from a low-resolution (LR) multi-spectral (MS) image and its\ncorresponding panchromatic (PAN) image acquired by a same satellite. Inspired\nby a new fashion in recent deep learning community, we propose a novel\nTransformer based model for pan-sharpening. We explore the potential of\nTransformer in image feature extraction and fusion. Following the successful\ndevelopment of vision transformers, we design a two-stream network with the\nself-attention to extract the modality-specific features from the PAN and MS\nmodalities and apply a cross-attention module to merge the spectral and spatial\nfeatures. The pan-sharpened image is produced from the enhanced fused features.\nExtensive experiments on GaoFen-2 and WorldView-3 images demonstrate that our\nTransformer based model achieves impressive results and outperforms many\nexisting CNN based methods, which shows the great potential of introducing\nTransformer to the pan-sharpening task. Codes are available at\nhttps://github.com/zhysora/PanFormer.\n",
                "链接": "https://arxiv.org/abs/2203.02916"
            },
            {
                "文章ID": "75455",
                "标题": "A Lightweight CNN-Transformer Model for Learning Traveling Salesman\n  Problems",
                "作者": " Minseop Jung,  Jaeseung Lee,  Jibum Kim",
                "发布日期": "2023-05-04",
                "摘要": "  Transformer-based models show state-of-the-art performance even for\nlarge-scale Traveling Salesman Problems (TSPs). However, they are based on\nfully-connected attention models and suffer from large computational complexity\nand GPU memory usage. We propose a lightweight CNN-Transformer model based on a\nCNN embedding layer and partial self-attention. Our CNN-Transformer model is\nable to better learn spatial features from input data using a CNN embedding\nlayer compared with the standard Transformer models. It also removes\nconsiderable redundancy in fully connected attention models using the proposed\npartial self-attention. Experiments show that the proposed model outperforms\nother state-of-the-art Transformer-based models in terms of TSP solution\nquality, GPU memory usage, and inference time. Our model consumes approximately\n20% less GPU memory usage and has 45% faster inference time compared with other\nstate-of-the-art Transformer-based models. Our code is publicly available at\nhttps://github.com/cm8908/CNN_Transformer3\n",
                "链接": "https://arxiv.org/abs/2305.01883"
            },
            {
                "文章ID": "75677",
                "标题": "LayoutDM: Transformer-based Diffusion Model for Layout Generation",
                "作者": " Shang Chai,  Liansheng Zhuang,  Fengying Yan",
                "发布日期": "2023-05-05",
                "摘要": "  Automatic layout generation that can synthesize high-quality layouts is an\nimportant tool for graphic design in many applications. Though existing methods\nbased on generative models such as Generative Adversarial Networks (GANs) and\nVariational Auto-Encoders (VAEs) have progressed, they still leave much room\nfor improving the quality and diversity of the results. Inspired by the recent\nsuccess of diffusion models in generating high-quality images, this paper\nexplores their potential for conditional layout generation and proposes\nTransformer-based Layout Diffusion Model (LayoutDM) by instantiating the\nconditional denoising diffusion probabilistic model (DDPM) with a purely\ntransformer-based architecture. Instead of using convolutional neural networks,\na transformer-based conditional Layout Denoiser is proposed to learn the\nreverse diffusion process to generate samples from noised layout data.\nBenefitting from both transformer and DDPM, our LayoutDM is of desired\nproperties such as high-quality generation, strong sample diversity, faithful\ndistribution coverage, and stationary training in comparison to GANs and VAEs.\nQuantitative and qualitative experimental results show that our method\noutperforms state-of-the-art generative models in terms of quality and\ndiversity.\n",
                "链接": "https://arxiv.org/abs/2305.02567"
            },
            {
                "文章ID": "104363",
                "标题": "A Simple Text to Video Model via Transformer",
                "作者": " Gang Chen",
                "发布日期": "2023-09-27",
                "摘要": "  We present a general and simple text to video model based on Transformer.\nSince both text and video are sequential data, we encode both texts and images\ninto the same hidden space, which are further fed into Transformer to capture\nthe temporal consistency and then decoder to generate either text or images.\nConsidering the image signal may become weak in the long sequence, we introduce\nthe U-Net to reconstruct image from its noised version. Specifically, we\nincrease the noise level to the original image in the long sequence, then use\nthe $down$ module from U-Net to encode noised images, which are further input\nto transformer to predict next clear images. We also add a constraint to\npromote motion between any generated image pair in the video. We use GPT2 and\ntest our approach on UCF101 dataset and show it can generate promising videos.\n",
                "链接": "https://arxiv.org/abs/2309.14683"
            },
            {
                "文章ID": "80916",
                "标题": "Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model",
                "作者": " Yinghan Long,  Sayeed Shafayet Chowdhury,  Kaushik Roy",
                "发布日期": "2023-10-24",
                "摘要": "  Transformers have shown dominant performance across a range of domains\nincluding language and vision. However, their computational cost grows\nquadratically with the sequence length, making their usage prohibitive for\nresource-constrained applications. To counter this, our approach is to divide\nthe whole sequence into segments and apply attention to the individual\nsegments. We propose a segmented recurrent transformer (SRformer) that combines\nsegmented (local) attention with recurrent attention. The loss caused by\nreducing the attention window length is compensated by aggregating information\nacross segments with recurrent attention. SRformer leverages Recurrent\nAccumulate-and-Fire (RAF) neurons' inherent memory to update the cumulative\nproduct of keys and values. The segmented attention and lightweight RAF neurons\nensure the efficiency of the proposed transformer. Such an approach leads to\nmodels with sequential processing capability at a lower computation/memory\ncost. We apply the proposed method to T5 and BART transformers. The modified\nmodels are tested on summarization datasets including CNN-dailymail, XSUM,\nArXiv, and MediaSUM. Notably, using segmented inputs of varied sizes, the\nproposed model achieves $6-22\\%$ higher ROUGE1 scores than a segmented\ntransformer and outperforms other recurrent transformer approaches.\nFurthermore, compared to full attention, the proposed model reduces the\ncomputational complexity of cross attention by around $40\\%$.\n",
                "链接": "https://arxiv.org/abs/2305.16340"
            },
            {
                "文章ID": "10273",
                "标题": "ODE Transformer: An Ordinary Differential Equation-Inspired Model for\n  Sequence Generation",
                "作者": " Bei Li,  Quan Du,  Tao Zhou,  Yi Jing,  Shuhan Zhou,  Xin Zeng,  Tong Xiao,  JingBo Zhu,  Xuebo Liu,  Min Zhang",
                "发布日期": "2022-04-13",
                "摘要": "  Residual networks are an Euler discretization of solutions to Ordinary\nDifferential Equations (ODE). This paper explores a deeper relationship between\nTransformer and numerical ODE methods. We first show that a residual block of\nlayers in Transformer can be described as a higher-order solution to ODE.\nInspired by this, we design a new architecture, {\\it ODE Transformer}, which is\nanalogous to the Runge-Kutta method that is well motivated in ODE. As a natural\nextension to Transformer, ODE Transformer is easy to implement and efficient to\nuse. Experimental results on the large-scale machine translation, abstractive\nsummarization, and grammar error correction tasks demonstrate the high\ngenericity of ODE Transformer. It can gain large improvements in model\nperformance over strong baselines (e.g., 30.77 and 44.11 BLEU scores on the\nWMT'14 English-German and English-French benchmarks) at a slight cost in\ninference efficiency.\n",
                "链接": "https://arxiv.org/abs/2203.09176"
            },
            {
                "文章ID": "57547",
                "标题": "FE-TCM: Filter-Enhanced Transformer Click Model for Web Search",
                "作者": " Yingfei Wang,  Jianping Liu,  Jian Wang,  Xiaofeng Wang,  Meng Wang,  Xintao Chu",
                "发布日期": "2023-02-01",
                "摘要": "  Constructing click models and extracting implicit relevance feedback\ninformation from the interaction between users and search engines are very\nimportant to improve the ranking of search results. Using neural network to\nmodel users' click behaviors has become one of the effective methods to\nconstruct click models. In this paper, We use Transformer as the backbone\nnetwork of feature extraction, add filter layer innovatively, and propose a new\nFilter-Enhanced Transformer Click Model (FE-TCM) for web search. Firstly, in\norder to reduce the influence of noise on user behavior data, we use the\nlearnable filters to filter log noise. Secondly, following the examination\nhypothesis, we model the attraction estimator and examination predictor\nrespectively to output the attractiveness scores and examination probabilities.\nA novel transformer model is used to learn the deeper representation among\ndifferent features. Finally, we apply the combination functions to integrate\nattractiveness scores and examination probabilities into the click prediction.\nFrom our experiments on two real-world session datasets, it is proved that\nFE-TCM outperforms the existing click models for the click prediction.\n",
                "链接": "https://arxiv.org/abs/2301.07854"
            },
            {
                "文章ID": "53461",
                "标题": "CNN-transformer mixed model for object detection",
                "作者": " Wenshuo Li",
                "发布日期": "2022-12-14",
                "摘要": "  Object detection, one of the three main tasks of computer vision, has been\nused in various applications. The main process is to use deep neural networks\nto extract the features of an image and then use the features to identify the\nclass and location of an object. Therefore, the main direction to improve the\naccuracy of object detection tasks is to improve the neural network to extract\nfeatures better. In this paper, I propose a convolutional module with a\ntransformer[1], which aims to improve the recognition accuracy of the model by\nfusing the detailed features extracted by CNN[2] with the global features\nextracted by a transformer and significantly reduce the computational effort of\nthe transformer module by deflating the feature mAP. The main execution steps\nare convolutional downsampling to reduce the feature map size, then\nself-attention calculation and upsampling, and finally concatenation with the\ninitial input. In the experimental part, after splicing the block to the end of\nYOLOv5n[3] and training 300 epochs on the coco dataset, the mAP improved by\n1.7% compared with the previous YOLOv5n, and the mAP curve did not show any\nsaturation phenomenon, so there is still potential for improvement. After 100\nrounds of training on the Pascal VOC dataset, the accuracy of the results\nreached 81%, which is 4.6 better than the faster RCNN[4] using resnet101[5] as\nthe backbone, but the number of parameters is less than one-twentieth of it.\n",
                "链接": "https://arxiv.org/abs/2212.06714"
            },
            {
                "文章ID": "41362",
                "标题": "A Transformer-based deep neural network model for SSVEP classification",
                "作者": " Jianbo Chen,  Yangsong Zhang,  Yudong Pan,  Peng Xu,  Cuntai Guan",
                "发布日期": "2022-10-11",
                "摘要": "  Steady-state visual evoked potential (SSVEP) is one of the most commonly used\ncontrol signal in the brain-computer interface (BCI) systems. However, the\nconventional spatial filtering methods for SSVEP classification highly depend\non the subject-specific calibration data. The need for the methods that can\nalleviate the demand for the calibration data become urgent. In recent years,\ndeveloping the methods that can work in inter-subject classification scenario\nhas become a promising new direction. As the popular deep learning model\nnowadays, Transformer has excellent performance and has been used in EEG signal\nclassification tasks. Therefore, in this study, we propose a deep learning\nmodel for SSVEP classification based on Transformer structure in inter-subject\nclassification scenario, termed as SSVEPformer, which is the first application\nof the transformer to the classification of SSVEP. Inspired by previous\nstudies, the model adopts the frequency spectrum of SSVEP data as input, and\nexplores the spectral and spatial domain information for classification.\nFurthermore, to fully utilize the harmonic information, an extended SSVEPformer\nbased on the filter bank technology (FB-SSVEPformer) is proposed to further\nimprove the classification performance. Experiments were conducted using two\nopen datasets (Dataset 1: 10 subjects, 12-class task; Dataset 2: 35 subjects,\n40-class task) in the inter-subject classification scenario. The experimental\nresults show that the proposed models could achieve better results in terms of\nclassification accuracy and information transfer rate, compared with other\nbaseline methods. The proposed model validates the feasibility of deep learning\nmodels based on Transformer structure for SSVEP classification task, and could\nserve as a potential model to alleviate the calibration procedure in the\npractical application of SSVEP-based BCI systems.\n",
                "链接": "https://arxiv.org/abs/2210.04172"
            },
            {
                "文章ID": "96865",
                "标题": "PMET: Precise Model Editing in a Transformer",
                "作者": " Xiaopeng Li,  Shasha Li,  Shezheng Song,  Jing Yang,  Jun Ma,  Jie Yu",
                "发布日期": "2023-12-21",
                "摘要": "  Model editing techniques modify a minor proportion of knowledge in Large\nLanguage Models (LLMs) at a relatively low cost, which have demonstrated\nnotable success. Existing methods assume Transformer Layer (TL) hidden states\nare values of key-value memories of the Feed-Forward Network (FFN). They\nusually optimize the TL hidden states to memorize target knowledge and use it\nto update the weights of the FFN in LLMs. However, the information flow of TL\nhidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN,\nand residual connections. Existing methods neglect the fact that the TL hidden\nstates contains information not specifically required for FFN. Consequently,\nthe performance of model editing decreases. To achieve more precise model\nediting, we analyze hidden states of MHSA and FFN, finding that MHSA encodes\ncertain general knowledge extraction patterns. This implies that MHSA weights\ndo not require updating when new knowledge is introduced. Based on above\nfindings, we introduce PMET, which simultaneously optimizes Transformer\nComponent (TC, namely MHSA and FFN) hidden states, while only using the\noptimized TC hidden states of FFN to precisely update FFN weights. Our\nexperiments demonstrate that PMET exhibits state-of-the-art performance on both\nthe COUNTERFACT and zsRE datasets. Our ablation experiments substantiate the\neffectiveness of our enhancements, further reinforcing the finding that the\nMHSA encodes certain general knowledge extraction patterns and indicating its\nstorage of a small amount of factual knowledge. Our code is available at\nhttps://github.com/xpq-tech/PMET.\n",
                "链接": "https://arxiv.org/abs/2308.08742"
            },
            {
                "文章ID": "102081",
                "标题": "Large-Vocabulary 3D Diffusion Model with Transformer",
                "作者": " Ziang Cao,  Fangzhou Hong,  Tong Wu,  Liang Pan,  Ziwei Liu",
                "发布日期": "2023-09-18",
                "摘要": "  Creating diverse and high-quality 3D assets with an automatic generative\nmodel is highly desirable. Despite extensive efforts on 3D generation, most\nexisting works focus on the generation of a single category or a few\ncategories. In this paper, we introduce a diffusion-based feed-forward\nframework for synthesizing massive categories of real-world 3D objects with a\nsingle generative model. Notably, there are three major challenges for this\nlarge-vocabulary 3D generation: a) the need for expressive yet efficient 3D\nrepresentation; b) large diversity in geometry and texture across categories;\nc) complexity in the appearances of real-world objects. To this end, we propose\na novel triplane-based 3D-aware Diffusion model with TransFormer, DiffTF, for\nhandling challenges via three aspects. 1) Considering efficiency and\nrobustness, we adopt a revised triplane representation and improve the fitting\nspeed and accuracy. 2) To handle the drastic variations in geometry and\ntexture, we regard the features of all 3D objects as a combination of\ngeneralized 3D knowledge and specialized 3D features. To extract generalized 3D\nknowledge from diverse categories, we propose a novel 3D-aware transformer with\nshared cross-plane attention. It learns the cross-plane relations across\ndifferent planes and aggregates the generalized 3D knowledge with specialized\n3D features. 3) In addition, we devise the 3D-aware encoder/decoder to enhance\nthe generalized 3D knowledge in the encoded triplanes for handling categories\nwith complex appearances. Extensive experiments on ShapeNet and OmniObject3D\n(over 200 diverse real-world categories) convincingly demonstrate that a single\nDiffTF model achieves state-of-the-art large-vocabulary 3D object generation\nperformance with large diversity, rich semantics, and high quality.\n",
                "链接": "https://arxiv.org/abs/2309.07920"
            },
            {
                "文章ID": "12051",
                "标题": "Hierarchical Transformer Model for Scientific Named Entity Recognition",
                "作者": " Urchade Zaratiana,  Pierre Holat,  Nadi Tomeh,  Thierry Charnois",
                "发布日期": "2022-03-29",
                "摘要": "  The task of Named Entity Recognition (NER) is an important component of many\nnatural language processing systems, such as relation extraction and knowledge\ngraph construction. In this work, we present a simple and effective approach\nfor Named Entity Recognition. The main idea of our approach is to encode the\ninput subword sequence with a pre-trained transformer such as BERT, and then,\ninstead of directly classifying the word labels, another layer of transformer\nis added to the subword representation to better encode the word-level\ninteraction. We evaluate our approach on three benchmark datasets for\nscientific NER, particularly in the computer science and biomedical domains.\nExperimental results show that our model outperforms the current\nstate-of-the-art on SciERC and TDM datasets without requiring external\nresources or specific data augmentation. Code is available at\n\\url{https://github.com/urchade/HNER}.\n",
                "链接": "https://arxiv.org/abs/2203.14710"
            },
            {
                "文章ID": "94033",
                "标题": "Performance Evaluation of Swin Vision Transformer Model using Gradient\n  Accumulation Optimization Technique",
                "作者": " Sanad Aburass,  Osama Dorgham",
                "发布日期": "2023-08-02",
                "摘要": "  Vision Transformers (ViTs) have emerged as a promising approach for visual\nrecognition tasks, revolutionizing the field by leveraging the power of\ntransformer-based architectures. Among the various ViT models, Swin\nTransformers have gained considerable attention due to their hierarchical\ndesign and ability to capture both local and global visual features\neffectively. This paper evaluates the performance of Swin ViT model using\ngradient accumulation optimization (GAO) technique. We investigate the impact\nof gradient accumulation optimization technique on the model's accuracy and\ntraining time. Our experiments show that applying the GAO technique leads to a\nsignificant decrease in the accuracy of the Swin ViT model, compared to the\nstandard Swin Transformer model. Moreover, we detect a significant increase in\nthe training time of the Swin ViT model when GAO model is applied. These\nfindings suggest that applying the GAO technique may not be suitable for the\nSwin ViT model, and concern should be undertaken when using GAO technique for\nother transformer-based models.\n",
                "链接": "https://arxiv.org/abs/2308.00197"
            },
            {
                "文章ID": "16149",
                "标题": "Hierarchical Label-wise Attention Transformer Model for Explainable ICD\n  Coding",
                "作者": " Leibo Liu,  Oscar Perez-Concha,  Anthony Nguyen,  Vicki Bennett,  Louisa Jorm",
                "发布日期": "2022-10-04",
                "摘要": "  International Classification of Diseases (ICD) coding plays an important role\nin systematically classifying morbidity and mortality data. In this study, we\npropose a hierarchical label-wise attention Transformer model (HiLAT) for the\nexplainable prediction of ICD codes from clinical documents. HiLAT firstly\nfine-tunes a pretrained Transformer model to represent the tokens of clinical\ndocuments. We subsequently employ a two-level hierarchical label-wise attention\nmechanism that creates label-specific document representations. These\nrepresentations are in turn used by a feed-forward neural network to predict\nwhether a specific ICD code is assigned to the input clinical document of\ninterest. We evaluate HiLAT using hospital discharge summaries and their\ncorresponding ICD-9 codes from the MIMIC-III database. To investigate the\nperformance of different types of Transformer models, we develop\nClinicalplusXLNet, which conducts continual pretraining from XLNet-Base using\nall the MIMIC-III clinical notes. The experiment results show that the F1\nscores of the HiLAT+ClinicalplusXLNet outperform the previous state-of-the-art\nmodels for the top-50 most frequent ICD-9 codes from MIMIC-III. Visualisations\nof attention weights present a potential explainability tool for checking the\nface validity of ICD code predictions.\n",
                "链接": "https://arxiv.org/abs/2204.10716"
            },
            {
                "文章ID": "12262",
                "标题": "End-to-End Transformer Based Model for Image Captioning",
                "作者": " Yiyu Wang,  Jungang Xu,  Yingfei Sun",
                "发布日期": "2022-03-30",
                "摘要": "  CNN-LSTM based architectures have played an important role in image\ncaptioning, but limited by the training efficiency and expression ability,\nresearchers began to explore the CNN-Transformer based models and achieved\ngreat success. Meanwhile, almost all recent works adopt Faster R-CNN as the\nbackbone encoder to extract region-level features from given images. However,\nFaster R-CNN needs a pre-training on an additional dataset, which divides the\nimage captioning task into two stages and limits its potential applications. In\nthis paper, we build a pure Transformer-based model, which integrates image\ncaptioning into one stage and realizes end-to-end training. Firstly, we adopt\nSwinTransformer to replace Faster R-CNN as the backbone encoder to extract\ngrid-level features from given images; Then, referring to Transformer, we build\na refining encoder and a decoder. The refining encoder refines the grid\nfeatures by capturing the intra-relationship between them, and the decoder\ndecodes the refined features into captions word by word. Furthermore, in order\nto increase the interaction between multi-modal (vision and language) features\nto enhance the modeling capability, we calculate the mean pooling of grid\nfeatures as the global feature, then introduce it into refining encoder to\nrefine with grid features together, and add a pre-fusion process of refined\nglobal feature and generated words in decoder. To validate the effectiveness of\nour proposed model, we conduct experiments on MSCOCO dataset. The experimental\nresults compared to existing published works demonstrate that our model\nachieves new state-of-the-art performances of 138.2% (single model) and 141.0%\n(ensemble of 4 models) CIDEr scores on `Karpathy' offline test split and 136.0%\n(c5) and 138.3% (c40) CIDEr scores on the official online test server. Trained\nmodels and source code will be released.\n",
                "链接": "https://arxiv.org/abs/2203.15350"
            },
            {
                "文章ID": "84432",
                "标题": "Absformer: Transformer-based Model for Unsupervised Multi-Document\n  Abstractive Summarization",
                "作者": " Mohamed Trabelsi,  Huseyin Uzunalioglu",
                "发布日期": "2023-06-09",
                "摘要": "  Multi-document summarization (MDS) refers to the task of summarizing the text\nin multiple documents into a concise summary. The generated summary can save\nthe time of reading many documents by providing the important content in the\nform of a few sentences. Abstractive MDS aims to generate a coherent and fluent\nsummary for multiple documents using natural language generation techniques. In\nthis paper, we consider the unsupervised abstractive MDS setting where there\nare only documents with no groundtruh summaries provided, and we propose\nAbsformer, a new Transformer-based method for unsupervised abstractive summary\ngeneration. Our method consists of a first step where we pretrain a\nTransformer-based encoder using the masked language modeling (MLM) objective as\nthe pretraining task in order to cluster the documents into semantically\nsimilar groups; and a second step where we train a Transformer-based decoder to\ngenerate abstractive summaries for the clusters of documents. To our knowledge,\nwe are the first to successfully incorporate a Transformer-based model to solve\nthe unsupervised abstractive MDS task. We evaluate our approach using three\nreal-world datasets from different domains, and we demonstrate both substantial\nimprovements in terms of evaluation metrics over state-of-the-art\nabstractive-based methods, and generalization to datasets from different\ndomains.\n",
                "链接": "https://arxiv.org/abs/2306.04787"
            },
            {
                "文章ID": "67822",
                "标题": "How does Transformer model evolve to learn diverse chemical structures?",
                "作者": " Yasuhiro Yoshikai,  Tadahaya Mizuno,  Shumpei Nemoto,  Hiroyuki Kusuhara",
                "发布日期": "2023-10-10",
                "摘要": "  Recent years have seen rapid development of descriptor generation based on\nrepresentation learning of extremely diverse molecules, especially those that\napply natural language processing (NLP) models to SMILES, a literal\nrepresentation of molecular structure. However, little research has been done\non how these models understand chemical structure. To address this black box,\nwe investigated the relationship between the learning progress of SMILES and\nchemical structure using a representative NLP model, the Transformer. The\nresults suggest that while the Transformer learns partial structures of\nmolecules quickly, it requires extended training to understand overall\nstructures. Consistently, the accuracy of molecular property predictions using\ndescriptors generated from models at different learning steps was similar from\nthe beginning to the end of training. Furthermore, we found that the\nTransformer requires particularly long training to learn chirality and\nsometimes stagnates with low translation accuracy due to misunderstanding of\nenantiomers. These findings are expected to deepen the understanding of NLP\nmodels in chemistry.\n",
                "链接": "https://arxiv.org/abs/2303.11593"
            },
            {
                "文章ID": "37025",
                "标题": "A lightweight Transformer-based model for fish landmark detection",
                "作者": " Alzayat Saleh,  David Jones,  Dean Jerry,  Mostafa Rahimi Azghadi",
                "发布日期": "2022-09-14",
                "摘要": "  Transformer-based models, such as the Vision Transformer (ViT), can\noutperform onvolutional Neural Networks (CNNs) in some vision tasks when there\nis sufficient training data. However, (CNNs) have a strong and useful inductive\nbias for vision tasks (i.e. translation equivariance and locality). In this\nwork, we developed a novel model architecture that we call a Mobile fish\nlandmark detection network (MFLD-net). We have made this model using\nconvolution operations based on ViT (i.e. Patch embeddings, Multi-Layer\nPerceptrons). MFLD-net can achieve competitive or better results in low data\nregimes while being lightweight and therefore suitable for embedded and mobile\ndevices. Furthermore, we show that MFLD-net can achieve keypoint (landmark)\nestimation accuracies on-par or even better than some of the state-of-the-art\n(CNNs) on a fish image dataset. Additionally, unlike ViT, MFLD-net does not\nneed a pre-trained model and can generalise well when trained on a small\ndataset. We provide quantitative and qualitative results that demonstrate the\nmodel's generalisation capabilities. This work will provide a foundation for\nfuture efforts in developing mobile, but efficient fish monitoring systems and\ndevices.\n",
                "链接": "https://arxiv.org/abs/2209.05777"
            },
            {
                "文章ID": "108961",
                "标题": "SeUNet-Trans: A Simple yet Effective UNet-Transformer Model for Medical\n  Image Segmentation",
                "作者": " Tan-Hanh Pham,  Xianqi Li,  Kim-Doang Nguyen",
                "发布日期": "2023-11-13",
                "摘要": "  Automated medical image segmentation is becoming increasingly crucial to\nmodern clinical practice, driven by the growing demand for precise diagnosis,\nthe push towards personalized treatment plans, and the advancements in machine\nlearning algorithms, especially the incorporation of deep learning methods.\nWhile convolutional neural networks (CNN) have been prevalent among these\nmethods, the remarkable potential of Transformer-based models for computer\nvision tasks is gaining more acknowledgment. To harness the advantages of both\nCNN-based and Transformer-based models, we propose a simple yet effective\nUNet-Transformer (seUNet-Trans) model for medical image segmentation. In our\napproach, the UNet model is designed as a feature extractor to generate\nmultiple feature maps from the input images, then the maps are propagated into\na bridge layer, which is introduced to sequentially connect the UNet and the\nTransformer. In this stage, we approach the pixel-level embedding technique\nwithout position embedding vectors, aiming to make the model more efficient.\nMoreover, we apply spatial-reduction attention in the Transformer to reduce the\ncomputational/memory overhead. By leveraging the UNet architecture and the\nself-attention mechanism, our model not only retains the preservation of both\nlocal and global context information but also is capable of capturing\nlong-range dependencies between input elements. The proposed model is\nextensively experimented on seven medical image segmentation datasets including\npolyp segmentation to demonstrate its efficacy. Comparison with several\nstate-of-the-art segmentation models on these datasets shows the superior\nperformance of our proposed seUNet-Trans network.\n",
                "链接": "https://arxiv.org/abs/2310.09998"
            },
            {
                "文章ID": "35894",
                "标题": "TransPolymer: a Transformer-based language model for polymer property\n  predictions",
                "作者": " Changwen Xu,  Yuyang Wang,  Amir Barati Farimani",
                "发布日期": "2023-04-27",
                "摘要": "  Accurate and efficient prediction of polymer properties is of great\nsignificance in polymer design. Conventionally, expensive and time-consuming\nexperiments or simulations are required to evaluate polymer functions.\nRecently, Transformer models, equipped with self-attention mechanisms, have\nexhibited superior performance in natural language processing. However, such\nmethods have not been investigated in polymer sciences. Herein, we report\nTransPolymer, a Transformer-based language model for polymer property\nprediction. Our proposed polymer tokenizer with chemical awareness enables\nlearning representations from polymer sequences. Rigorous experiments on ten\npolymer property prediction benchmarks demonstrate the superior performance of\nTransPolymer. Moreover, we show that TransPolymer benefits from pretraining on\nlarge unlabeled dataset via Masked Language Modeling. Experimental results\nfurther manifest the important role of self-attention in modeling polymer\nsequences. We highlight this model as a promising computational tool for\npromoting rational polymer design and understanding structure-property\nrelationships from a data science view.\n",
                "链接": "https://arxiv.org/abs/2209.01307"
            },
            {
                "文章ID": "72623",
                "标题": "A Neural Network Transformer Model for Composite Microstructure\n  Homogenization",
                "作者": " Emil Pitz,  Kishore Pochiraju",
                "发布日期": "2023-04-18",
                "摘要": "  Heterogeneity and uncertainty in a composite microstructure lead to either\ncomputational bottlenecks if modeled rigorously, or to solution inaccuracies in\nthe stress field and failure predictions if approximated. Although methods\nsuitable for analyzing arbitrary and non-linear microstructures exist, their\ncomputational cost makes them impractical to use in large-scale structural\nanalysis. Surrogate models or Reduced Order Models (ROM), commonly enhance\nefficiencies, but they are typically calibrated with a single microstructure.\nHomogenization methods, such as the Mori-Tanaka method, offer rapid\nhomogenization for a wide range of constituent properties. However, simplifying\nassumptions, like stress and strain averaging in phases, render the\nconsideration of both deterministic and stochastic variations in microstructure\ninfeasible.\n  This paper illustrates a transformer neural network architecture that\ncaptures the knowledge of various microstructures and constituents, enabling it\nto function as a computationally efficient homogenization surrogate model.\nGiven an image or an abstraction of an arbitrary composite microstructure, the\ntransformer network predicts the homogenized stress-strain response. Two\nmethods were tested that encode features of the microstructure. The first\nmethod calculates two-point statistics of the microstructure and uses Principal\nComponent Analysis for dimensionality reduction. The second method uses an\nautoencoder with a Convolutional Neural Network. Both microstructure encoding\nmethods accurately predict the homogenized material response. The paper\ndescribes the network architecture, training and testing data generation and\nthe performance of the transformer network under cycling and random loadings.\n",
                "链接": "https://arxiv.org/abs/2304.07877"
            },
            {
                "文章ID": "116412",
                "标题": "Bias A-head? Analyzing Bias in Transformer-Based Language Model\n  Attention Heads",
                "作者": " Yi Yang,  Hanyu Duan,  Ahmed Abbasi,  John P. Lalor,  Kar Yan Tam",
                "发布日期": "2023-11-20",
                "摘要": "  Transformer-based pretrained large language models (PLM) such as BERT and GPT\nhave achieved remarkable success in NLP tasks. However, PLMs are prone to\nencoding stereotypical biases. Although a burgeoning literature has emerged on\nstereotypical bias mitigation in PLMs, such as work on debiasing gender and\nracial stereotyping, how such biases manifest and behave internally within PLMs\nremains largely unknown. Understanding the internal stereotyping mechanisms may\nallow better assessment of model fairness and guide the development of\neffective mitigation strategies. In this work, we focus on attention heads, a\nmajor component of the Transformer architecture, and propose a bias analysis\nframework to explore and identify a small set of biased heads that are found to\ncontribute to a PLM's stereotypical bias. We conduct extensive experiments to\nvalidate the existence of these biased heads and to better understand how they\nbehave. We investigate gender and racial bias in the English language in two\ntypes of Transformer-based PLMs: the encoder-based BERT model and the\ndecoder-based autoregressive GPT model. Overall, the results shed light on\nunderstanding the bias behavior in pretrained language models.\n",
                "链接": "https://arxiv.org/abs/2311.10395"
            },
            {
                "文章ID": "9549",
                "标题": "CMKD: CNN/Transformer-Based Cross-Model Knowledge Distillation for Audio\n  Classification",
                "作者": " Yuan Gong,  Sameer Khurana,  Andrew Rouditchenko,  James Glass",
                "发布日期": "2022-03-15",
                "摘要": "  Audio classification is an active research area with a wide range of\napplications. Over the past decade, convolutional neural networks (CNNs) have\nbeen the de-facto standard building block for end-to-end audio classification\nmodels. Recently, neural networks based solely on self-attention mechanisms\nsuch as the Audio Spectrogram Transformer (AST) have been shown to outperform\nCNNs. In this paper, we find an intriguing interaction between the two very\ndifferent models - CNN and AST models are good teachers for each other. When we\nuse either of them as the teacher and train the other model as the student via\nknowledge distillation (KD), the performance of the student model noticeably\nimproves, and in many cases, is better than the teacher model. In our\nexperiments with this CNN/Transformer Cross-Model Knowledge Distillation (CMKD)\nmethod we achieve new state-of-the-art performance on FSD50K, AudioSet, and\nESC-50.\n",
                "链接": "https://arxiv.org/abs/2203.06760"
            },
            {
                "文章ID": "6747",
                "标题": "A Differential Attention Fusion Model Based on Transformer for Time\n  Series Forecasting",
                "作者": " Benhan Li,  Shengdong Du,  Tianrui Li",
                "发布日期": "2022-02-24",
                "摘要": "  Time series forecasting is widely used in the fields of equipment life cycle\nforecasting, weather forecasting, traffic flow forecasting, and other fields.\nRecently, some scholars have tried to apply Transformer to time series\nforecasting because of its powerful parallel training ability. However, the\nexisting Transformer methods do not pay enough attention to the small time\nsegments that play a decisive role in prediction, making it insensitive to\nsmall changes that affect the trend of time series, and it is difficult to\neffectively learn continuous time-dependent features. To solve this problem, we\npropose a differential attention fusion model based on Transformer, which\ndesigns the differential layer, neighbor attention, sliding fusion mechanism,\nand residual layer on the basis of classical Transformer architecture.\nSpecifically, the differences of adjacent time points are extracted and focused\nby difference and neighbor attention. The sliding fusion mechanism fuses\nvarious features of each time point so that the data can participate in\nencoding and decoding without losing important information. The residual layer\nincluding convolution and LSTM further learns the dependence between time\npoints and enables our model to carry out deeper training. A large number of\nexperiments on three datasets show that the prediction results produced by our\nmethod are favorably comparable to the state-of-the-art.\n",
                "链接": "https://arxiv.org/abs/2202.11402"
            },
            {
                "文章ID": "68283",
                "标题": "A Small-Scale Switch Transformer and NLP-based Model for Clinical\n  Narratives Classification",
                "作者": " Thanh-Dung Le,  Philippe Jouvet,  Rita Noumeir",
                "发布日期": "2023-03-24",
                "摘要": "  In recent years, Transformer-based models such as the Switch Transformer have\nachieved remarkable results in natural language processing tasks. However,\nthese models are often too complex and require extensive pre-training, which\nlimits their effectiveness for small clinical text classification tasks with\nlimited data. In this study, we propose a simplified Switch Transformer\nframework and train it from scratch on a small French clinical text\nclassification dataset at CHU Sainte-Justine hospital. Our results demonstrate\nthat the simplified small-scale Transformer models outperform pre-trained\nBERT-based models, including DistillBERT, CamemBERT, FlauBERT, and FrALBERT.\nAdditionally, using a mixture of expert mechanisms from the Switch Transformer\nhelps capture diverse patterns; hence, the proposed approach achieves better\nresults than a conventional Transformer with the self-attention mechanism.\nFinally, our proposed framework achieves an accuracy of 87\\%, precision at\n87\\%, and recall at 85\\%, compared to the third-best pre-trained BERT-based\nmodel, FlauBERT, which achieved an accuracy of 84\\%, precision at 84\\%, and\nrecall at 84\\%. However, Switch Transformers have limitations, including a\ngeneralization gap and sharp minima. We compare it with a multi-layer\nperceptron neural network for small French clinical narratives classification\nand show that the latter outperforms all other models.\n",
                "链接": "https://arxiv.org/abs/2303.12892"
            },
            {
                "文章ID": "66077",
                "标题": "TransMatting: Tri-token Equipped Transformer Model for Image Matting",
                "作者": " Huanqia Cai,  Fanglei Xue,  Lele Xu,  Lili Guo",
                "发布日期": "2023-03-14",
                "摘要": "  Image matting aims to predict alpha values of elaborate uncertainty areas of\nnatural images, like hairs, smoke, and spider web. However, existing methods\nperform poorly when faced with highly transparent foreground objects due to the\nlarge area of uncertainty to predict and the small receptive field of\nconvolutional networks. To address this issue, we propose a Transformer-based\nnetwork (TransMatting) to model transparent objects with long-range features\nand collect a high-resolution matting dataset of transparent objects\n(Transparent-460) for performance evaluation. Specifically, to utilize semantic\ninformation in the trimap flexibly and effectively, we also redesign the trimap\nas three learnable tokens, named tri-token. Both Transformer and convolution\nmatting models could benefit from our proposed tri-token design. By replacing\nthe traditional trimap concatenation strategy with our tri-token, existing\nmatting methods could achieve about 10% improvement in SAD and 20% in MSE.\nEquipped with the new tri-token design, our proposed TransMatting outperforms\ncurrent state-of-the-art methods on several popular matting benchmarks and our\nnewly collected Transparent-460.\n",
                "链接": "https://arxiv.org/abs/2303.06476"
            },
            {
                "文章ID": "93498",
                "标题": "Differential Evolution Algorithm based Hyper-Parameters Selection of\n  Transformer Neural Network Model for Load Forecasting",
                "作者": " Anuvab Sen,  Arul Rhik Mazumder,  Udayon Sen",
                "发布日期": "2023-09-25",
                "摘要": "  Accurate load forecasting plays a vital role in numerous sectors, but\naccurately capturing the complex dynamics of dynamic power systems remains a\nchallenge for traditional statistical models. For these reasons, time-series\nmodels (ARIMA) and deep-learning models (ANN, LSTM, GRU, etc.) are commonly\ndeployed and often experience higher success. In this paper, we analyze the\nefficacy of the recently developed Transformer-based Neural Network model in\nLoad forecasting. Transformer models have the potential to improve Load\nforecasting because of their ability to learn long-range dependencies derived\nfrom their Attention Mechanism. We apply several metaheuristics namely\nDifferential Evolution to find the optimal hyperparameters of the\nTransformer-based Neural Network to produce accurate forecasts. Differential\nEvolution provides scalable, robust, global solutions to non-differentiable,\nmulti-objective, or constrained optimization problems. Our work compares the\nproposed Transformer based Neural Network model integrated with different\nmetaheuristic algorithms by their performance in Load forecasting based on\nnumerical metrics such as Mean Squared Error (MSE) and Mean Absolute Percentage\nError (MAPE). Our findings demonstrate the potential of metaheuristic-enhanced\nTransformer-based Neural Network models in Load forecasting accuracy and\nprovide optimal hyperparameters for each model.\n",
                "链接": "https://arxiv.org/abs/2307.15299"
            },
            {
                "文章ID": "24175",
                "标题": "SeATrans: Learning Segmentation-Assisted diagnosis model via Transformer",
                "作者": " Junde Wu,  Huihui Fang,  Fangxin Shang,  Dalu Yang,  Zhaowei Wang,  Jing Gao,  Yehui Yang,  Yanwu Xu",
                "发布日期": "2022-06-23",
                "摘要": "  Clinically, the accurate annotation of lesions/tissues can significantly\nfacilitate the disease diagnosis. For example, the segmentation of optic\ndisc/cup (OD/OC) on fundus image would facilitate the glaucoma diagnosis, the\nsegmentation of skin lesions on dermoscopic images is helpful to the melanoma\ndiagnosis, etc. With the advancement of deep learning techniques, a wide range\nof methods proved the lesions/tissues segmentation can also facilitate the\nautomated disease diagnosis models. However, existing methods are limited in\nthe sense that they can only capture static regional correlations in the\nimages. Inspired by the global and dynamic nature of Vision Transformer, in\nthis paper, we propose Segmentation-Assisted diagnosis Transformer (SeATrans)\nto transfer the segmentation knowledge to the disease diagnosis network.\nSpecifically, we first propose an asymmetric multi-scale interaction strategy\nto correlate each single low-level diagnosis feature with multi-scale\nsegmentation features. Then, an effective strategy called SeA-block is adopted\nto vitalize diagnosis feature via correlated segmentation features. To model\nthe segmentation-diagnosis interaction, SeA-block first embeds the diagnosis\nfeature based on the segmentation information via the encoder, and then\ntransfers the embedding back to the diagnosis feature space by a decoder.\nExperimental results demonstrate that SeATrans surpasses a wide range of\nstate-of-the-art (SOTA) segmentation-assisted diagnosis methods on several\ndisease diagnosis tasks.\n",
                "链接": "https://arxiv.org/abs/2206.05763"
            },
            {
                "文章ID": "67483",
                "标题": "Bangla Grammatical Error Detection Using T5 Transformer Model",
                "作者": " H. A. Z. Sameen Shahgir,  Khondker Salman Sayeed",
                "发布日期": "2023-03-21",
                "摘要": "  This paper presents a method for detecting grammatical errors in Bangla using\na Text-to-Text Transfer Transformer (T5) Language Model, using the small\nvariant of BanglaT5, fine-tuned on a corpus of 9385 sentences where errors were\nbracketed by the dedicated demarcation symbol. The T5 model was primarily\ndesigned for translation and is not specifically designed for this task, so\nextensive post-processing was necessary to adapt it to the task of error\ndetection. Our experiments show that the T5 model can achieve low Levenshtein\nDistance in detecting grammatical errors in Bangla, but post-processing is\nessential to achieve optimal performance. The final average Levenshtein\nDistance after post-processing the output of the fine-tuned model was 1.0394 on\na test set of 5000 sentences. This paper also presents a detailed analysis of\nthe errors detected by the model and discusses the challenges of adapting a\ntranslation model for grammar. Our approach can be extended to other languages,\ndemonstrating the potential of T5 models for detecting grammatical errors in a\nwide range of languages.\n",
                "链接": "https://arxiv.org/abs/2303.10612"
            },
            {
                "文章ID": "82297",
                "标题": "Synthetic CT Generation from MRI using 3D Transformer-based Denoising\n  Diffusion Model",
                "作者": " Shaoyan Pan,  Elham Abouei,  Jacob Wynne,  Tonghe Wang,  Richard L. J. Qiu,  Yuheng Li,  Chih-Wei Chang,  Junbo Peng,  Justin Roper,  Pretesh Patel,  David S. Yu,  Hui Mao,  Xiaofeng Yang",
                "发布日期": "2023-06-01",
                "摘要": "  Magnetic resonance imaging (MRI)-based synthetic computed tomography (sCT)\nsimplifies radiation therapy treatment planning by eliminating the need for CT\nsimulation and error-prone image registration, ultimately reducing patient\nradiation dose and setup uncertainty. We propose an MRI-to-CT transformer-based\ndenoising diffusion probabilistic model (MC-DDPM) to transform MRI into\nhigh-quality sCT to facilitate radiation treatment planning. MC-DDPM implements\ndiffusion processes with a shifted-window transformer network to generate sCT\nfrom MRI. The proposed model consists of two processes: a forward process which\nadds Gaussian noise to real CT scans, and a reverse process in which a\nshifted-window transformer V-net (Swin-Vnet) denoises the noisy CT scans\nconditioned on the MRI from the same patient to produce noise-free CT scans.\nWith an optimally trained Swin-Vnet, the reverse diffusion process was used to\ngenerate sCT scans matching MRI anatomy. We evaluated the proposed method by\ngenerating sCT from MRI on a brain dataset and a prostate dataset. Qualitative\nevaluation was performed using the mean absolute error (MAE) of Hounsfield unit\n(HU), peak signal to noise ratio (PSNR), multi-scale Structure Similarity index\n(MS-SSIM) and normalized cross correlation (NCC) indexes between ground truth\nCTs and sCTs. MC-DDPM generated brain sCTs with state-of-the-art quantitative\nresults with MAE 43.317 HU, PSNR 27.046 dB, SSIM 0.965, and NCC 0.983. For the\nprostate dataset, MC-DDPM achieved MAE 59.953 HU, PSNR 26.920 dB, SSIM 0.849,\nand NCC 0.948. In conclusion, we have developed and validated a novel approach\nfor generating CT images from routine MRIs using a transformer-based DDPM. This\nmodel effectively captures the complex relationship between CT and MRI images,\nallowing for robust and high-quality synthetic CT (sCT) images to be generated\nin minutes.\n",
                "链接": "https://arxiv.org/abs/2305.19467"
            },
            {
                "文章ID": "29084",
                "标题": "Deep Transformer Model with Pre-Layer Normalization for COVID-19 Growth\n  Prediction",
                "作者": " Rizki Ramadhan Fitra,  Novanto Yudistira,  Wayan Firdaus Mahmudy",
                "发布日期": "2022-07-14",
                "摘要": "  Coronavirus disease or COVID-19 is an infectious disease caused by the\nSARS-CoV-2 virus. The first confirmed case caused by this virus was found at\nthe end of December 2019 in Wuhan City, China. This case then spread throughout\nthe world, including Indonesia. Therefore, the COVID-19 case was designated as\na global pandemic by WHO. The growth of COVID-19 cases, especially in\nIndonesia, can be predicted using several approaches, such as the Deep Neural\nNetwork (DNN). One of the DNN models that can be used is Deep Transformer which\ncan predict time series. The model is trained with several test scenarios to\nget the best model. The evaluation is finding the best hyperparameters. Then,\nfurther evaluation was carried out using the best hyperparameters setting of\nthe number of prediction days, the optimizer, the number of features, and\ncomparison with the former models of the Long Short-Term Memory (LSTM) and\nRecurrent Neural Network (RNN). All evaluations used metric of the Mean\nAbsolute Percentage Error (MAPE). Based on the results of the evaluations, Deep\nTransformer produces the best results when using the Pre-Layer Normalization\nand predicting one day ahead with a MAPE value of 18.83. Furthermore, the model\ntrained with the Adamax optimizer obtains the best performance among other\ntested optimizers. The performance of the Deep Transformer also exceeds other\ntest models, which are LSTM and RNN.\n",
                "链接": "https://arxiv.org/abs/2207.06356"
            },
            {
                "文章ID": "66170",
                "标题": "Endoscopy Classification Model Using Swin Transformer and Saliency Map",
                "作者": " Zahra Sobhaninia,  Nasrin Abharian,  Nader Karimi,  Shahram Shirani,  Shadrokh Samavi",
                "发布日期": "2023-03-14",
                "摘要": "  Endoscopy is a valuable tool for the early diagnosis of colon cancer.\nHowever, it requires the expertise of endoscopists and is a time-consuming\nprocess. In this work, we propose a new multi-label classification method,\nwhich considers two aspects of learning approaches (local and global views) for\nendoscopic image classification. The model consists of a Swin transformer\nbranch and a modified VGG16 model as a CNN branch. To help the learning process\nof the CNN branch, the model employs saliency maps and endoscopy images and\nconcatenates them. The results demonstrate that this method performed well for\nendoscopic medical images by utilizing local and global features of the images.\nFurthermore, quantitative evaluations prove the proposed method's superiority\nover state-of-the-art works.\n",
                "链接": "https://arxiv.org/abs/2303.06736"
            },
            {
                "文章ID": "120835",
                "标题": "A Transformer Model for Symbolic Regression towards Scientific Discovery",
                "作者": " Florian Lalande,  Yoshitomo Matsubara,  Naoya Chiba,  Tatsunori Taniai,  Ryo Igarashi,  Yoshitaka Ushiku",
                "发布日期": "2023-12-15",
                "摘要": "  Symbolic Regression (SR) searches for mathematical expressions which best\ndescribe numerical datasets. This allows to circumvent interpretation issues\ninherent to artificial neural networks, but SR algorithms are often\ncomputationally expensive. This work proposes a new Transformer model aiming at\nSymbolic Regression particularly focused on its application for Scientific\nDiscovery. We propose three encoder architectures with increasing flexibility\nbut at the cost of column-permutation equivariance violation. Training results\nindicate that the most flexible architecture is required to prevent from\noverfitting. Once trained, we apply our best model to the SRSD datasets\n(Symbolic Regression for Scientific Discovery datasets) which yields\nstate-of-the-art results using the normalized tree-based edit distance, at no\nextra computational cost.\n",
                "链接": "https://arxiv.org/abs/2312.04070"
            },
            {
                "文章ID": "93981",
                "标题": "Monaural Multi-Speaker Speech Separation Using Efficient Transformer\n  Model",
                "作者": " S. Rijal,  R. Neupane,  S. P. Mainali,  S. K. Regmi,  S. Maharjan",
                "发布日期": "2023-08-02",
                "摘要": "  Cocktail party problem is the scenario where it is difficult to separate or\ndistinguish individual speaker from a mixed speech from several speakers. There\nhave been several researches going on in this field but the size and complexity\nof the model is being traded off with the accuracy and robustness of speech\nseparation. \"Monaural multi-speaker speech separation\" presents a\nspeech-separation model based on the Transformer architecture and its efficient\nforms. The model has been trained with the LibriMix dataset containing diverse\nspeakers' utterances. The model separates 2 distinct speaker sources from a\nmixed audio input. The developed model approaches the reduction in\ncomputational complexity of the speech separation model, with minimum tradeoff\nwith the performance of prevalent speech separation model and it has shown\nsignificant movement towards that goal. This project foresees, a rise in\ncontribution towards the ongoing research in the field of speech separation\nwith computational efficiency at its core.\n",
                "链接": "https://arxiv.org/abs/2308.00010"
            },
            {
                "文章ID": "63290",
                "标题": "TrafFormer: A Transformer Model for Predicting Long-term Traffic",
                "作者": " David Alexander Tedjopurnomo,  Farhana M. Choudhury,  A. K. Qin",
                "发布日期": "2023-03-06",
                "摘要": "  Traffic prediction is a flourishing research field due to its importance in\nhuman mobility in the urban space. Despite this, existing studies only focus on\nshort-term prediction of up to few hours in advance, with most being up to one\nhour only. Long-term traffic prediction can enable more comprehensive,\ninformed, and proactive measures against traffic congestion and is therefore an\nimportant task to explore. In this paper, we explore the task of long-term\ntraffic prediction; where we predict traffic up to 24 hours in advance. We note\nthe weaknesses of existing models--which are based on recurrent structures--for\nlong-term traffic prediction and propose a modified Transformer model\n\"TrafFormer\". Experiments comparing our model with existing hybrid neural\nnetwork models show the superiority of our model.\n",
                "链接": "https://arxiv.org/abs/2302.12388"
            },
            {
                "文章ID": "95145",
                "标题": "Improving FHB Screening in Wheat Breeding Using an Efficient Transformer\n  Model",
                "作者": " Babak Azad,  Ahmed Abdalla,  Kwanghee Won,  Ali Mirzakhani Nafchi",
                "发布日期": "2023-08-08",
                "摘要": "  Fusarium head blight is a devastating disease that causes significant\neconomic losses annually on small grains. Efficiency, accuracy, and timely\ndetection of FHB in the resistance screening are critical for wheat and barley\nbreeding programs. In recent years, various image processing techniques have\nbeen developed using supervised machine learning algorithms for the early\ndetection of FHB. The state-of-the-art convolutional neural network-based\nmethods, such as U-Net, employ a series of encoding blocks to create a local\nrepresentation and a series of decoding blocks to capture the semantic\nrelations. However, these methods are not often capable of long-range modeling\ndependencies inside the input data, and their ability to model multi-scale\nobjects with significant variations in texture and shape is limited. Vision\ntransformers as alternative architectures with innate global self-attention\nmechanisms for sequence-to-sequence prediction, due to insufficient low-level\ndetails, may also limit localization capabilities. To overcome these\nlimitations, a new Context Bridge is proposed to integrate the local\nrepresentation capability of the U-Net network in the transformer model. In\naddition, the standard attention mechanism of the original transformer is\nreplaced with Efficient Self-attention, which is less complicated than other\nstate-of-the-art methods. To train the proposed network, 12,000 wheat images\nfrom an FHB-inoculated wheat field at the SDSU research farm in Volga, SD, were\ncaptured. In addition to healthy and unhealthy plants, these images encompass\nvarious stages of the disease. A team of expert pathologists annotated the\nimages for training and evaluating the developed model. As a result, the\neffectiveness of the transformer-based method for FHB-disease detection,\nthrough extensive experiments across typical tasks for plant image\nsegmentation, is demonstrated.\n",
                "链接": "https://arxiv.org/abs/2308.03670"
            },
            {
                "文章ID": "33758",
                "标题": "Transformer-Based Deep Learning Model for Stock Price Prediction: A Case\n  Study on Bangladesh Stock Market",
                "作者": " Tashreef Muhammad,  Anika Bintee Aftab,  Md. Mainul Ahsan,  Maishameem Meherin Muhu,  Muhammad Ibrahim,  Shahidul Islam Khan,  Mohammad Shafiul Alam",
                "发布日期": "2023-04-11",
                "摘要": "  In modern capital market the price of a stock is often considered to be\nhighly volatile and unpredictable because of various social, financial,\npolitical and other dynamic factors. With calculated and thoughtful investment,\nstock market can ensure a handsome profit with minimal capital investment,\nwhile incorrect prediction can easily bring catastrophic financial loss to the\ninvestors. This paper introduces the application of a recently introduced\nmachine learning model - the Transformer model, to predict the future price of\nstocks of Dhaka Stock Exchange (DSE), the leading stock exchange in Bangladesh.\nThe transformer model has been widely leveraged for natural language processing\nand computer vision tasks, but, to the best of our knowledge, has never been\nused for stock price prediction task at DSE. Recently the introduction of\ntime2vec encoding to represent the time series features has made it possible to\nemploy the transformer model for the stock price prediction. This paper\nconcentrates on the application of transformer-based model to predict the price\nmovement of eight specific stocks listed in DSE based on their historical daily\nand weekly data. Our experiments demonstrate promising results and acceptable\nroot mean squared error on most of the stocks.\n",
                "链接": "https://arxiv.org/abs/2208.08300"
            },
            {
                "文章ID": "30223",
                "标题": "Hybrid CNN-Transformer Model For Facial Affect Recognition In the ABAW4\n  Challenge",
                "作者": " Lingfeng Wang,  Haocheng Li,  Chunyin Liu",
                "发布日期": "2022-07-22",
                "摘要": "  This paper describes our submission to the fourth Affective Behavior Analysis\n(ABAW) competition. We proposed a hybrid CNN-Transformer model for the\nMulti-Task-Learning (MTL) and Learning from Synthetic Data (LSD) task.\nExperimental results on validation dataset shows that our method achieves\nbetter performance than baseline model, which verifies that the effectiveness\nof proposed network.\n",
                "链接": "https://arxiv.org/abs/2207.10201"
            },
            {
                "文章ID": "19641",
                "标题": "The Power of Fragmentation: A Hierarchical Transformer Model for\n  Structural Segmentation in Symbolic Music Generation",
                "作者": " Guowei Wu,  Shipei Liu,  Xiaoya Fan",
                "发布日期": "2022-07-12",
                "摘要": "  Symbolic Music Generation relies on the contextual representation\ncapabilities of the generative model, where the most prevalent approach is the\nTransformer-based model. The learning of musical context is also related to the\nstructural elements in music, i.e. intro, verse, and chorus, which are\ncurrently overlooked by the research community. In this paper, we propose a\nhierarchical Transformer model to learn multi-scale contexts in music. In the\nencoding phase, we first designed a Fragment Scope Localization layer to\nsyncopate the music into chords and sections. Then, we use a multi-scale\nattention mechanism to learn note-, chord-, and section-level contexts. In the\ndecoding phase, we proposed a hierarchical Transformer model that uses\nfine-decoders to generate sections in parallel and a coarse-decoder to decode\nthe combined music. We also designed a Music Style Normalization layer to\nachieve a consistent music style between the generated sections. Our model is\nevaluated on two open MIDI datasets, and experiments show that our model\noutperforms the best contemporary music generative models. More excitingly, the\nvisual evaluation shows that our model is superior in melody reuse, resulting\nin more realistic music.\n",
                "链接": "https://arxiv.org/abs/2205.08579"
            },
            {
                "文章ID": "97806",
                "标题": "An Effective Transformer-based Contextual Model and Temporal Gate\n  Pooling for Speaker Identification",
                "作者": " Harunori Kawano,  Sota Shimizu",
                "发布日期": "2023-09-12",
                "摘要": "  Wav2vec2 has achieved success in applying Transformer architecture and\nself-supervised learning to speech recognition. Recently, these have come to be\nused not only for speech recognition but also for the entire speech processing.\nThis paper introduces an effective end-to-end speaker identification model\napplied Transformer-based contextual model. We explored the relationship\nbetween the hyper-parameters and the performance in order to discern the\nstructure of an effective model. Furthermore, we propose a pooling method,\nTemporal Gate Pooling, with powerful learning ability for speaker\nidentification. We applied Conformer as encoder and BEST-RQ for pre-training\nand conducted an evaluation utilizing the speaker identification of VoxCeleb1.\nThe proposed method has achieved an accuracy of 87.1% with 28.5M parameters,\ndemonstrating comparable precision to wav2vec2 with 317.7M parameters. Code is\navailable at https://github.com/HarunoriKawano/speaker-identification-with-tgp.\n",
                "链接": "https://arxiv.org/abs/2308.11241"
            },
            {
                "文章ID": "19224",
                "标题": "Multiformer: A Head-Configurable Transformer-Based Model for Direct\n  Speech Translation",
                "作者": " Gerard Sant,  Gerard I. Gállego,  Belen Alastruey,  Marta R. Costa-Jussà",
                "发布日期": "2022-05-17",
                "摘要": "  Transformer-based models have been achieving state-of-the-art results in\nseveral fields of Natural Language Processing. However, its direct application\nto speech tasks is not trivial. The nature of this sequences carries problems\nsuch as long sequence lengths and redundancy between adjacent tokens.\nTherefore, we believe that regular self-attention mechanism might not be well\nsuited for it.\n  Different approaches have been proposed to overcome these problems, such as\nthe use of efficient attention mechanisms. However, the use of these methods\nusually comes with a cost, which is a performance reduction caused by\ninformation loss. In this study, we present the Multiformer, a\nTransformer-based model which allows the use of different attention mechanisms\non each head. By doing this, the model is able to bias the self-attention\ntowards the extraction of more diverse token interactions, and the information\nloss is reduced. Finally, we perform an analysis of the head contributions, and\nwe observe that those architectures where all heads relevance is uniformly\ndistributed obtain better results. Our results show that mixing attention\npatterns along the different heads and layers outperforms our baseline by up to\n0.7 BLEU.\n",
                "链接": "https://arxiv.org/abs/2205.07100"
            },
            {
                "文章ID": "114747",
                "标题": "Transformer-based Model for Oral Epithelial Dysplasia Segmentation",
                "作者": " Adam J Shephard,  Hanya Mahmood,  Shan E Ahmed Raza,  Anna Luiza Damaceno Araujo,  Alan Roger Santos-Silva,  Marcio Ajudarte Lopes,  Pablo Agustin Vargas,  Kris McCombe,  Stephanie Craig,  Jacqueline James,  Jill Brooks,  Paul Nankivell,  Hisham Mehanna,  Syed Ali Khurram,  Nasir M Rajpoot",
                "发布日期": "2023-11-10",
                "摘要": "  Oral epithelial dysplasia (OED) is a premalignant histopathological diagnosis\ngiven to lesions of the oral cavity. OED grading is subject to large\ninter/intra-rater variability, resulting in the under/over-treatment of\npatients. We developed a new Transformer-based pipeline to improve detection\nand segmentation of OED in haematoxylin and eosin (H&E) stained whole slide\nimages (WSIs). Our model was trained on OED cases (n = 260) and controls (n =\n105) collected using three different scanners, and validated on test data from\nthree external centres in the United Kingdom and Brazil (n = 78). Our internal\nexperiments yield a mean F1-score of 0.81 for OED segmentation, which reduced\nslightly to 0.71 on external testing, showing good generalisability, and\ngaining state-of-the-art results. This is the first externally validated study\nto use Transformers for segmentation in precancerous histology images. Our\npublicly available model shows great promise to be the first step of a\nfully-integrated pipeline, allowing earlier and more efficient OED diagnosis,\nultimately benefiting patient outcomes.\n",
                "链接": "https://arxiv.org/abs/2311.05452"
            },
            {
                "文章ID": "112867",
                "标题": "A Transformer-Based Model With Self-Distillation for Multimodal Emotion\n  Recognition in Conversations",
                "作者": " Hui Ma,  Jian Wang,  Hongfei Lin,  Bo Zhang,  Yijia Zhang,  Bo Xu",
                "发布日期": "2023-11-01",
                "摘要": "  Emotion recognition in conversations (ERC), the task of recognizing the\nemotion of each utterance in a conversation, is crucial for building empathetic\nmachines. Existing studies focus mainly on capturing context- and\nspeaker-sensitive dependencies on the textual modality but ignore the\nsignificance of multimodal information. Different from emotion recognition in\ntextual conversations, capturing intra- and inter-modal interactions between\nutterances, learning weights between different modalities, and enhancing modal\nrepresentations play important roles in multimodal ERC. In this paper, we\npropose a transformer-based model with self-distillation (SDT) for the task.\nThe transformer-based model captures intra- and inter-modal interactions by\nutilizing intra- and inter-modal transformers, and learns weights between\nmodalities dynamically by designing a hierarchical gated fusion strategy.\nFurthermore, to learn more expressive modal representations, we treat soft\nlabels of the proposed model as extra training supervision. Specifically, we\nintroduce self-distillation to transfer knowledge of hard and soft labels from\nthe proposed model to each modality. Experiments on IEMOCAP and MELD datasets\ndemonstrate that SDT outperforms previous state-of-the-art baselines.\n",
                "链接": "https://arxiv.org/abs/2310.20494"
            },
            {
                "文章ID": "107899",
                "标题": "Jaeger: A Concatenation-Based Multi-Transformer VQA Model",
                "作者": " Jieting Long,  Zewei Shi,  Penghao Jiang,  Yidong Gan",
                "发布日期": "2023-10-20",
                "摘要": "  Document-based Visual Question Answering poses a challenging task between\nlinguistic sense disambiguation and fine-grained multimodal retrieval. Although\nthere has been encouraging progress in document-based question answering due to\nthe utilization of large language and open-world prior models\\cite{1}, several\nchallenges persist, including prolonged response times, extended inference\ndurations, and imprecision in matching. In order to overcome these challenges,\nwe propose Jaegar, a concatenation-based multi-transformer VQA model. To derive\nquestion features, we leverage the exceptional capabilities of RoBERTa\nlarge\\cite{2} and GPT2-xl\\cite{3} as feature extractors. Subsequently, we\nsubject the outputs from both models to a concatenation process. This operation\nallows the model to consider information from diverse sources concurrently,\nstrengthening its representational capability. By leveraging pre-trained models\nfor feature extraction, our approach has the potential to amplify the\nperformance of these models through concatenation. After concatenation, we\napply dimensionality reduction to the output features, reducing the model's\ncomputational effectiveness and inference time. Empirical results demonstrate\nthat our proposed model achieves competitive performance on Task C of the\nPDF-VQA Dataset. If the user adds any new data, they should make sure to style\nit as per the instructions provided in previous sections.\n",
                "链接": "https://arxiv.org/abs/2310.07091"
            },
            {
                "文章ID": "113210",
                "标题": "Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in\n  Transformer Models",
                "作者": " Steve Yadlowsky,  Lyric Doshi,  Nilesh Tripuraneni",
                "发布日期": "2023-11-03",
                "摘要": "  Transformer models, notably large language models (LLMs), have the remarkable\nability to perform in-context learning (ICL) -- to perform new tasks when\nprompted with unseen input-output examples without any explicit model training.\nIn this work, we study how effectively transformers can bridge between their\npretraining data mixture, comprised of multiple distinct task families, to\nidentify and learn new tasks in-context which are both inside and outside the\npretraining distribution. Building on previous work, we investigate this\nquestion in a controlled setting, where we study transformer models trained on\nsequences of $(x, f(x))$ pairs rather than natural language. Our empirical\nresults show transformers demonstrate near-optimal unsupervised model selection\ncapabilities, in their ability to first in-context identify different task\nfamilies and in-context learn within them when the task families are\nwell-represented in their pretraining data. However when presented with tasks\nor functions which are out-of-domain of their pretraining data, we demonstrate\nvarious failure modes of transformers and degradation of their generalization\nfor even simple extrapolation tasks. Together our results highlight that the\nimpressive ICL abilities of high-capacity sequence models may be more closely\ntied to the coverage of their pretraining data mixtures than inductive biases\nthat create fundamental generalization capabilities.\n",
                "链接": "https://arxiv.org/abs/2311.00871"
            },
            {
                "文章ID": "5058",
                "标题": "Entroformer: A Transformer-based Entropy Model for Learned Image\n  Compression",
                "作者": " Yichen Qian,  Ming Lin,  Xiuyu Sun,  Zhiyu Tan,  Rong Jin",
                "发布日期": "2023-03-16",
                "摘要": "  One critical component in lossy deep image compression is the entropy model,\nwhich predicts the probability distribution of the quantized latent\nrepresentation in the encoding and decoding modules. Previous works build\nentropy models upon convolutional neural networks which are inefficient in\ncapturing global dependencies. In this work, we propose a novel\ntransformer-based entropy model, termed Entroformer, to capture long-range\ndependencies in probability distribution estimation effectively and\nefficiently. Different from vision transformers in image classification, the\nEntroformer is highly optimized for image compression, including a top-k\nself-attention and a diamond relative position encoding. Meanwhile, we further\nexpand this architecture with a parallel bidirectional context model to speed\nup the decoding process. The experiments show that the Entroformer achieves\nstate-of-the-art performance on image compression while being time-efficient.\n",
                "链接": "https://arxiv.org/abs/2202.05492"
            },
            {
                "文章ID": "19145",
                "标题": "PathologyBERT -- Pre-trained Vs. A New Transformer Language Model for\n  Pathology Domain",
                "作者": " Thiago Santos,  Amara Tariq,  Susmita Das,  Kavyasree Vayalpati,  Geoffrey H. Smith,  Hari Trivedi,  Imon Banerjee",
                "发布日期": "2022-05-17",
                "摘要": "  Pathology text mining is a challenging task given the reporting variability\nand constant new findings in cancer sub-type definitions. However, successful\ntext mining of a large pathology database can play a critical role to advance\n'big data' cancer research like similarity-based treatment selection, case\nidentification, prognostication, surveillance, clinical trial screening, risk\nstratification, and many others. While there is a growing interest in\ndeveloping language models for more specific clinical domains, no\npathology-specific language space exist to support the rapid data-mining\ndevelopment in pathology space. In literature, a few approaches fine-tuned\ngeneral transformer models on specialized corpora while maintaining the\noriginal tokenizer, but in fields requiring specialized terminology, these\nmodels often fail to perform adequately. We propose PathologyBERT - a\npre-trained masked language model which was trained on 347,173 histopathology\nspecimen reports and publicly released in the Huggingface repository. Our\ncomprehensive experiments demonstrate that pre-training of transformer model on\npathology corpora yields performance improvements on Natural Language\nUnderstanding (NLU) and Breast Cancer Diagnose Classification when compared to\nnonspecific language models.\n",
                "链接": "https://arxiv.org/abs/2205.06885"
            },
            {
                "文章ID": "65229",
                "标题": "Environment Transformer and Policy Optimization for Model-Based Offline\n  Reinforcement Learning",
                "作者": " Pengqin Wang,  Meixin Zhu,  Shaojie Shen",
                "发布日期": "2023-10-17",
                "摘要": "  Interacting with the actual environment to acquire data is often costly and\ntime-consuming in robotic tasks. Model-based offline reinforcement learning\n(RL) provides a feasible solution. On the one hand, it eliminates the\nrequirements of interaction with the actual environment. On the other hand, it\nlearns the transition dynamics and reward function from the offline datasets\nand generates simulated rollouts to accelerate training. Previous model-based\noffline RL methods adopt probabilistic ensemble neural networks (NN) to model\naleatoric uncertainty and epistemic uncertainty. However, this results in an\nexponential increase in training time and computing resource requirements.\nFurthermore, these methods are easily disturbed by the accumulative errors of\nthe environment dynamics models when simulating long-term rollouts. To solve\nthe above problems, we propose an uncertainty-aware sequence modeling\narchitecture called Environment Transformer. It models the probability\ndistribution of the environment dynamics and reward function to capture\naleatoric uncertainty and treats epistemic uncertainty as a learnable noise\nparameter. Benefiting from the accurate modeling of the transition dynamics and\nreward function, Environment Transformer can be combined with arbitrary\nplanning, dynamics programming, or policy optimization algorithms for offline\nRL. In this case, we perform Conservative Q-Learning (CQL) to learn a\nconservative Q-function. Through simulation experiments, we demonstrate that\nour method achieves or exceeds state-of-the-art performance in widely studied\noffline RL benchmarks. Moreover, we show that Environment Transformer's\nsimulated rollout quality, sample efficiency, and long-term rollout simulation\ncapability are superior to those of previous model-based offline RL methods.\n",
                "链接": "https://arxiv.org/abs/2303.03811"
            },
            {
                "文章ID": "115727",
                "标题": "GLiNER: Generalist Model for Named Entity Recognition using\n  Bidirectional Transformer",
                "作者": " Urchade Zaratiana,  Nadi Tomeh,  Pierre Holat,  Thierry Charnois",
                "发布日期": "2023-11-16",
                "摘要": "  Named Entity Recognition (NER) is essential in various Natural Language\nProcessing (NLP) applications. Traditional NER models are effective but limited\nto a set of predefined entity types. In contrast, Large Language Models (LLMs)\ncan extract arbitrary entities through natural language instructions, offering\ngreater flexibility. However, their size and cost, particularly for those\naccessed via APIs like ChatGPT, make them impractical in resource-limited\nscenarios. In this paper, we introduce a compact NER model trained to identify\nany type of entity. Leveraging a bidirectional transformer encoder, our model,\nGLiNER, facilitates parallel entity extraction, an advantage over the slow\nsequential token generation of LLMs. Through comprehensive testing, GLiNER\ndemonstrate strong performance, outperforming both ChatGPT and fine-tuned LLMs\nin zero-shot evaluations on various NER benchmarks.\n",
                "链接": "https://arxiv.org/abs/2311.08526"
            },
            {
                "文章ID": "48703",
                "标题": "A Simple Transformer-Based Model for Ego4D Natural Language Queries\n  Challenge",
                "作者": " Sicheng Mo,  Fangzhou Mu,  Yin Li",
                "发布日期": "2022-11-17",
                "摘要": "  This report describes Badgers@UW-Madison, our submission to the Ego4D Natural\nLanguage Queries (NLQ) Challenge. Our solution inherits the point-based event\nrepresentation from our prior work on temporal action localization, and\ndevelops a Transformer-based model for video grounding. Further, our solution\nintegrates several strong video features including SlowFast, Omnivore and\nEgoVLP. Without bells and whistles, our submission based on a single model\nachieves 12.64% Mean R@1 and is ranked 2nd on the public leaderboard.\nMeanwhile, our method garners 28.45% (18.03%) R@5 at tIoU=0.3 (0.5), surpassing\nthe top-ranked solution by up to 5.5 absolute percentage points.\n",
                "链接": "https://arxiv.org/abs/2211.08704"
            },
            {
                "文章ID": "31770",
                "标题": "Learning from flowsheets: A generative transformer model for\n  autocompletion of flowsheets",
                "作者": " Gabriel Vogel,  Lukas Schulze Balhorn,  Artur M. Schweidtmann",
                "发布日期": "2022-08-02",
                "摘要": "  We propose a novel method enabling autocompletion of chemical flowsheets.\nThis idea is inspired by the autocompletion of text. We represent flowsheets as\nstrings using the text-based SFILES 2.0 notation and learn the grammatical\nstructure of the SFILES 2.0 language and common patterns in flowsheets using a\ntransformer-based language model. We pre-train our model on synthetically\ngenerated flowsheets to learn the flowsheet language grammar. Then, we\nfine-tune our model in a transfer learning step on real flowsheet topologies.\nFinally, we use the trained model for causal language modeling to autocomplete\nflowsheets. Eventually, the proposed method can provide chemical engineers with\nrecommendations during interactive flowsheet synthesis. The results demonstrate\na high potential of this approach for future AI-assisted process synthesis.\n",
                "链接": "https://arxiv.org/abs/2208.00859"
            },
            {
                "文章ID": "31188",
                "标题": "TransNorm: Transformer Provides a Strong Spatial Normalization Mechanism\n  for a Deep Segmentation Model",
                "作者": " Reza Azad,  Mohammad T. AL-Antary,  Moein Heidari,  Dorit Merhof",
                "发布日期": "2022-07-28",
                "摘要": "  In the past few years, convolutional neural networks (CNNs), particularly\nU-Net, have been the prevailing technique in the medical image processing era.\nSpecifically, the seminal U-Net, as well as its alternatives, have successfully\nmanaged to address a wide variety of medical image segmentation tasks. However,\nthese architectures are intrinsically imperfect as they fail to exhibit\nlong-range interactions and spatial dependencies leading to a severe\nperformance drop in the segmentation of medical images with variable shapes and\nstructures. Transformers, preliminary proposed for sequence-to-sequence\nprediction, have arisen as surrogate architectures to precisely model global\ninformation assisted by the self-attention mechanism. Despite being feasibly\ndesigned, utilizing a pure Transformer for image segmentation purposes can\nresult in limited localization capacity stemming from inadequate low-level\nfeatures. Thus, a line of research strives to design robust variants of\nTransformer-based U-Net. In this paper, we propose Trans-Norm, a novel deep\nsegmentation framework which concomitantly consolidates a Transformer module\ninto both encoder and skip-connections of the standard U-Net. We argue that the\nexpedient design of skip-connections can be crucial for accurate segmentation\nas it can assist in feature fusion between the expanding and contracting paths.\nIn this respect, we derive a Spatial Normalization mechanism from the\nTransformer module to adaptively recalibrate the skip connection path.\nExtensive experiments across three typical tasks for medical image segmentation\ndemonstrate the effectiveness of TransNorm. The codes and trained models are\npublicly available at https://github.com/rezazad68/transnorm.\n",
                "链接": "https://arxiv.org/abs/2207.13415"
            },
            {
                "文章ID": "106729",
                "标题": "Quantized Transformer Language Model Implementations on Edge Devices",
                "作者": " Mohammad Wali Ur Rahman,  Murad Mehrab Abrar,  Hunter Gibbons Copening,  Salim Hariri,  Sicong Shao,  Pratik Satam,  Soheil Salehi",
                "发布日期": "2023-10-09",
                "摘要": "  Large-scale transformer-based models like the Bidirectional Encoder\nRepresentations from Transformers (BERT) are widely used for Natural Language\nProcessing (NLP) applications, wherein these models are initially pre-trained\nwith a large corpus with millions of parameters and then fine-tuned for a\ndownstream NLP task. One of the major limitations of these large-scale models\nis that they cannot be deployed on resource-constrained devices due to their\nlarge model size and increased inference latency. In order to overcome these\nlimitations, such large-scale models can be converted to an optimized\nFlatBuffer format, tailored for deployment on resource-constrained edge\ndevices. Herein, we evaluate the performance of such FlatBuffer transformed\nMobileBERT models on three different edge devices, fine-tuned for Reputation\nanalysis of English language tweets in the RepLab 2013 dataset. In addition,\nthis study encompassed an evaluation of the deployed models, wherein their\nlatency, performance, and resource efficiency were meticulously assessed. Our\nexperiment results show that, compared to the original BERT large model, the\nconverted and quantized MobileBERT models have 160$\\times$ smaller footprints\nfor a 4.1% drop in accuracy while analyzing at least one tweet per second on\nedge devices. Furthermore, our study highlights the privacy-preserving aspect\nof TinyML systems as all data is processed locally within a serverless\nenvironment.\n",
                "链接": "https://arxiv.org/abs/2310.03971"
            },
            {
                "文章ID": "42915",
                "标题": "MenuAI: Restaurant Food Recommendation System via a Transformer-based\n  Deep Learning Model",
                "作者": " Xinwei Ju,  Frank Po Wen Lo,  Jianing Qiu,  Peilun Shi,  Jiachuan Peng,  Benny Lo",
                "发布日期": "2022-10-18",
                "摘要": "  Food recommendation system has proven as an effective technology to provide\nguidance on dietary choices, and this is especially important for patients\nsuffering from chronic diseases. Unlike other multimedia recommendations, such\nas books and movies, food recommendation task is highly relied on the context\nat the moment, since users' food preference can be highly dynamic over time.\nFor example, individuals tend to eat more calories earlier in the day and eat a\nlittle less at dinner. However, there are still limited research works trying\nto incorporate both current context and nutritional knowledge for food\nrecommendation. Thus, a novel restaurant food recommendation system is proposed\nin this paper to recommend food dishes to users according to their special\nnutritional needs. Our proposed system utilises Optical Character Recognition\n(OCR) technology and a transformer-based deep learning model, Learning to Rank\n(LTR) model, to conduct food recommendation. Given a single RGB image of the\nmenu, the system is then able to rank the food dishes in terms of the input\nsearch key (e.g., calorie, protein level). Due to the property of the\ntransformer, our system can also rank unseen food dishes. Comprehensive\nexperiments are conducted to validate our methods on a self-constructed menu\ndataset, known as MenuRank dataset. The promising results, with accuracy\nranging from 77.2% to 99.5%, have demonstrated the great potential of LTR model\nin addressing food recommendation problems.\n",
                "链接": "https://arxiv.org/abs/2210.08266"
            },
            {
                "文章ID": "99479",
                "标题": "Materials Informatics Transformer: A Language Model for Interpretable\n  Materials Properties Prediction",
                "作者": " Hongshuo Huang,  Rishikesh Magar,  Changwen Xu,  Amir Barati Farimani",
                "发布日期": "2023-09-04",
                "摘要": "  Recently, the remarkable capabilities of large language models (LLMs) have\nbeen illustrated across a variety of research domains such as natural language\nprocessing, computer vision, and molecular modeling. We extend this paradigm by\nutilizing LLMs for material property prediction by introducing our model\nMaterials Informatics Transformer (MatInFormer). Specifically, we introduce a\nnovel approach that involves learning the grammar of crystallography through\nthe tokenization of pertinent space group information. We further illustrate\nthe adaptability of MatInFormer by incorporating task-specific data pertaining\nto Metal-Organic Frameworks (MOFs). Through attention visualization, we uncover\nthe key features that the model prioritizes during property prediction. The\neffectiveness of our proposed model is empirically validated across 14 distinct\ndatasets, hereby underscoring its potential for high throughput screening\nthrough accurate material property prediction.\n",
                "链接": "https://arxiv.org/abs/2308.16259"
            },
            {
                "文章ID": "78380",
                "标题": "A Lexical-aware Non-autoregressive Transformer-based ASR Model",
                "作者": " Chong-En Lin,  Kuan-Yu Chen",
                "发布日期": "2023-05-19",
                "摘要": "  Non-autoregressive automatic speech recognition (ASR) has become a mainstream\nof ASR modeling because of its fast decoding speed and satisfactory result. To\nfurther boost the performance, relaxing the conditional independence assumption\nand cascading large-scaled pre-trained models are two active research\ndirections. In addition to these strategies, we propose a lexical-aware\nnon-autoregressive Transformer-based (LA-NAT) ASR framework, which consists of\nan acoustic encoder, a speech-text shared encoder, and a speech-text shared\ndecoder. The acoustic encoder is used to process the input speech features as\nusual, and the speech-text shared encoder and decoder are designed to train\nspeech and text data simultaneously. By doing so, LA-NAT aims to make the ASR\nmodel aware of lexical information, so the resulting model is expected to\nachieve better results by leveraging the learned linguistic knowledge. A series\nof experiments are conducted on the AISHELL-1, CSJ, and TEDLIUM 2 datasets.\nAccording to the experiments, the proposed LA-NAT can provide superior results\nthan other recently proposed non-autoregressive ASR models. In addition, LA-NAT\nis a relatively compact model than most non-autoregressive ASR models, and it\nis about 58 times faster than the classic autoregressive model.\n",
                "链接": "https://arxiv.org/abs/2305.10839"
            },
            {
                "文章ID": "40864",
                "标题": "Vision Transformer Based Model for Describing a Set of Images as a Story",
                "作者": " Zainy M. Malakan,  Ghulam Mubashar Hassan,  Ajmal Mian",
                "发布日期": "2023-07-17",
                "摘要": "  Visual Story-Telling is the process of forming a multi-sentence story from a\nset of images. Appropriately including visual variation and contextual\ninformation captured inside the input images is one of the most challenging\naspects of visual storytelling. Consequently, stories developed from a set of\nimages often lack cohesiveness, relevance, and semantic relationship. In this\npaper, we propose a novel Vision Transformer Based Model for describing a set\nof images as a story. The proposed method extracts the distinct features of the\ninput images using a Vision Transformer (ViT). Firstly, input images are\ndivided into 16X16 patches and bundled into a linear projection of flattened\npatches. The transformation from a single image to multiple image patches\ncaptures the visual variety of the input visual patterns. These features are\nused as input to a Bidirectional-LSTM which is part of the sequence encoder.\nThis captures the past and future image context of all image patches. Then, an\nattention mechanism is implemented and used to increase the discriminatory\ncapacity of the data fed into the language model, i.e. a Mogrifier-LSTM. The\nperformance of our proposed model is evaluated using the Visual Story-Telling\ndataset (VIST), and the results show that our model outperforms the current\nstate of the art models.\n",
                "链接": "https://arxiv.org/abs/2210.02762"
            },
            {
                "文章ID": "92028",
                "标题": "DP-TBART: A Transformer-based Autoregressive Model for Differentially\n  Private Tabular Data Generation",
                "作者": " Rodrigo Castellon,  Achintya Gopal,  Brian Bloniarz,  David Rosenberg",
                "发布日期": "2023-07-21",
                "摘要": "  The generation of synthetic tabular data that preserves differential privacy\nis a problem of growing importance. While traditional marginal-based methods\nhave achieved impressive results, recent work has shown that deep\nlearning-based approaches tend to lag behind. In this work, we present\nDifferentially-Private TaBular AutoRegressive Transformer (DP-TBART), a\ntransformer-based autoregressive model that maintains differential privacy and\nachieves performance competitive with marginal-based methods on a wide variety\nof datasets, capable of even outperforming state-of-the-art methods in certain\nsettings. We also provide a theoretical framework for understanding the\nlimitations of marginal-based approaches and where deep learning-based\napproaches stand to contribute most. These results suggest that deep\nlearning-based techniques should be considered as a viable alternative to\nmarginal-based methods in the generation of differentially private synthetic\ntabular data.\n",
                "链接": "https://arxiv.org/abs/2307.10430"
            },
            {
                "文章ID": "64406",
                "标题": "STDepthFormer: Predicting Spatio-temporal Depth from Video with a\n  Self-supervised Transformer Model",
                "作者": " Houssem Boulahbal,  Adrian Voicila,  Andrew Comport",
                "发布日期": "2023-03-03",
                "摘要": "  In this paper, a self-supervised model that simultaneously predicts a\nsequence of future frames from video-input with a novel spatial-temporal\nattention (ST) network is proposed. The ST transformer network allows\nconstraining both temporal consistency across future frames whilst constraining\nconsistency across spatial objects in the image at different scales. This was\nnot the case in prior works for depth prediction, which focused on predicting a\nsingle frame as output. The proposed model leverages prior scene knowledge such\nas object shape and texture similar to single-image depth inference methods,\nwhilst also constraining the motion and geometry from a sequence of input\nimages. Apart from the transformer architecture, one of the main contributions\nwith respect to prior works lies in the objective function that enforces\nspatio-temporal consistency across a sequence of output frames rather than a\nsingle output frame. As will be shown, this results in more accurate and robust\ndepth sequence forecasting. The model achieves highly accurate depth\nforecasting results that outperform existing baselines on the KITTI benchmark.\nExtensive ablation studies were performed to assess the effectiveness of the\nproposed techniques. One remarkable result of the proposed model is that it is\nimplicitly capable of forecasting the motion of objects in the scene, rather\nthan requiring complex models involving multi-object detection, segmentation\nand tracking.\n",
                "链接": "https://arxiv.org/abs/2303.01196"
            },
            {
                "文章ID": "79603",
                "标题": "AxomiyaBERTa: A Phonologically-aware Transformer Model for Assamese",
                "作者": " Abhijnan Nath,  Sheikh Mannan,  Nikhil Krishnaswamy",
                "发布日期": "2023-05-24",
                "摘要": "  Despite their successes in NLP, Transformer-based language models still\nrequire extensive computing resources and suffer in low-resource or low-compute\nsettings. In this paper, we present AxomiyaBERTa, a novel BERT model for\nAssamese, a morphologically-rich low-resource language (LRL) of Eastern India.\nAxomiyaBERTa is trained only on the masked language modeling (MLM) task,\nwithout the typical additional next sentence prediction (NSP) objective, and\nour results show that in resource-scarce settings for very low-resource\nlanguages like Assamese, MLM alone can be successfully leveraged for a range of\ntasks. AxomiyaBERTa achieves SOTA on token-level tasks like Named Entity\nRecognition and also performs well on \"longer-context\" tasks like Cloze-style\nQA and Wiki Title Prediction, with the assistance of a novel embedding\ndisperser and phonological signals respectively. Moreover, we show that\nAxomiyaBERTa can leverage phonological signals for even more challenging tasks,\nsuch as a novel cross-document coreference task on a translated version of the\nECB+ corpus, where we present a new SOTA result for an LRL. Our source code and\nevaluation scripts may be found at https://github.com/csu-signal/axomiyaberta.\n",
                "链接": "https://arxiv.org/abs/2305.13641"
            },
            {
                "文章ID": "115422",
                "标题": "NLQxform: A Language Model-based Question to SPARQL Transformer",
                "作者": " Ruijie Wang,  Zhiruo Zhang,  Luca Rossetto,  Florian Ruosch,  Abraham Bernstein",
                "发布日期": "2023-11-15",
                "摘要": "  In recent years, scholarly data has grown dramatically in terms of both scale\nand complexity. It becomes increasingly challenging to retrieve information\nfrom scholarly knowledge graphs that include large-scale heterogeneous\nrelationships, such as authorship, affiliation, and citation, between various\ntypes of entities, e.g., scholars, papers, and organizations. As part of the\nScholarly QALD Challenge, this paper presents a question-answering (QA) system\ncalled NLQxform, which provides an easy-to-use natural language interface to\nfacilitate accessing scholarly knowledge graphs. NLQxform allows users to\nexpress their complex query intentions in natural language questions. A\ntransformer-based language model, i.e., BART, is employed to translate\nquestions into standard SPARQL queries, which can be evaluated to retrieve the\nrequired information. According to the public leaderboard of the Scholarly QALD\nChallenge at ISWC 2023 (Task 1: DBLP-QUAD - Knowledge Graph Question Answering\nover DBLP), NLQxform achieved an F1 score of 0.85 and ranked first on the QA\ntask, demonstrating the competitiveness of the system.\n",
                "链接": "https://arxiv.org/abs/2311.07588"
            },
            {
                "文章ID": "82886",
                "标题": "A Transformer-based representation-learning model with unified\n  processing of multimodal input for clinical diagnostics",
                "作者": " Hong-Yu Zhou,  Yizhou Yu,  Chengdi Wang,  Shu Zhang,  Yuanxu Gao,  Jia Pan,  Jun Shao,  Guangming Lu,  Kang Zhang,  Weimin Li",
                "发布日期": "2023-06-02",
                "摘要": "  During the diagnostic process, clinicians leverage multimodal information,\nsuch as chief complaints, medical images, and laboratory-test results.\nDeep-learning models for aiding diagnosis have yet to meet this requirement.\nHere we report a Transformer-based representation-learning model as a clinical\ndiagnostic aid that processes multimodal input in a unified manner. Rather than\nlearning modality-specific features, the model uses embedding layers to convert\nimages and unstructured and structured text into visual tokens and text tokens,\nand bidirectional blocks with intramodal and intermodal attention to learn a\nholistic representation of radiographs, the unstructured chief complaint and\nclinical history, structured clinical information such as laboratory-test\nresults and patient demographic information. The unified model outperformed an\nimage-only model and non-unified multimodal diagnosis models in the\nidentification of pulmonary diseases (by 12% and 9%, respectively) and in the\nprediction of adverse clinical outcomes in patients with COVID-19 (by 29% and\n7%, respectively). Leveraging unified multimodal Transformer-based models may\nhelp streamline triage of patients and facilitate the clinical decision\nprocess.\n",
                "链接": "https://arxiv.org/abs/2306.00864"
            },
            {
                "文章ID": "76703",
                "标题": "Towards an Automatic Optimisation Model Generator Assisted with\n  Generative Pre-trained Transformer",
                "作者": " Boris Almonacid",
                "发布日期": "2023-05-11",
                "摘要": "  This article presents a framework for generating optimisation models using a\npre-trained generative transformer. The framework involves specifying the\nfeatures that the optimisation model should have and using a language model to\ngenerate an initial version of the model. The model is then tested and\nvalidated, and if it contains build errors, an automatic edition process is\ntriggered. An experiment was performed using MiniZinc as the target language\nand two GPT-3.5 language models for generation and debugging. The results show\nthat the use of language models for the generation of optimisation models is\nfeasible, with some models satisfying the requested specifications, while\nothers require further refinement. The study provides promising evidence for\nthe use of language models in the modelling of optimisation problems and\nsuggests avenues for future research.\n",
                "链接": "https://arxiv.org/abs/2305.05811"
            },
            {
                "文章ID": "28794",
                "标题": "Image and Model Transformation with Secret Key for Vision Transformer",
                "作者": " Hitoshi Kiya,  Ryota Iijima,  MaungMaung Aprilpyone,  Yuma Kinoshita",
                "发布日期": "2023-01-11",
                "摘要": "  In this paper, we propose a combined use of transformed images and vision\ntransformer (ViT) models transformed with a secret key. We show for the first\ntime that models trained with plain images can be directly transformed to\nmodels trained with encrypted images on the basis of the ViT architecture, and\nthe performance of the transformed models is the same as models trained with\nplain images when using test images encrypted with the key. In addition, the\nproposed scheme does not require any specially prepared data for training\nmodels or network modification, so it also allows us to easily update the\nsecret key. In an experiment, the effectiveness of the proposed scheme is\nevaluated in terms of performance degradation and model protection performance\nin an image classification task on the CIFAR-10 dataset.\n",
                "链接": "https://arxiv.org/abs/2207.05366"
            },
            {
                "文章ID": "92758",
                "标题": "Concept-based explainability for an EEG transformer model",
                "作者": " Anders Gjølbye Madsen,  William Theodor Lehn-Schiøler,  Áshildur Jónsdóttir,  Bergdís Arnardóttir,  Lars Kai Hansen",
                "发布日期": "2023-07-25",
                "摘要": "  Deep learning models are complex due to their size, structure, and inherent\nrandomness in training procedures. Additional complexity arises from the\nselection of datasets and inductive biases. Addressing these challenges for\nexplainability, Kim et al. (2018) introduced Concept Activation Vectors (CAVs),\nwhich aim to understand deep models' internal states in terms of human-aligned\nconcepts. These concepts correspond to directions in latent space, identified\nusing linear discriminants. Although this method was first applied to image\nclassification, it was later adapted to other domains, including natural\nlanguage processing. In this work, we attempt to apply the method to\nelectroencephalogram (EEG) data for explainability in Kostas et al.'s BENDR\n(2021), a large-scale transformer model. A crucial part of this endeavor\ninvolves defining the explanatory concepts and selecting relevant datasets to\nground concepts in the latent space. Our focus is on two mechanisms for EEG\nconcept formation: the use of externally labeled EEG datasets, and the\napplication of anatomically defined concepts. The former approach is a\nstraightforward generalization of methods used in image classification, while\nthe latter is novel and specific to EEG. We present evidence that both\napproaches to concept formation yield valuable insights into the\nrepresentations learned by deep EEG models.\n",
                "链接": "https://arxiv.org/abs/2307.12745"
            },
            {
                "文章ID": "118082",
                "标题": "Probabilistic Transformer: A Probabilistic Dependency Model for\n  Contextual Word Representation",
                "作者": " Haoyi Wu,  Kewei Tu",
                "发布日期": "2023-11-28",
                "摘要": "  Syntactic structures used to play a vital role in natural language processing\n(NLP), but since the deep learning revolution, NLP has been gradually dominated\nby neural models that do not consider syntactic structures in their design. One\nvastly successful class of neural models is transformers. When used as an\nencoder, a transformer produces contextual representation of words in the input\nsentence. In this work, we propose a new model of contextual word\nrepresentation, not from a neural perspective, but from a purely syntactic and\nprobabilistic perspective. Specifically, we design a conditional random field\nthat models discrete latent representations of all words in a sentence as well\nas dependency arcs between them; and we use mean field variational inference\nfor approximate inference. Strikingly, we find that the computation graph of\nour model resembles transformers, with correspondences between dependencies and\nself-attention and between distributions over latent representations and\ncontextual embeddings of words. Experiments show that our model performs\ncompetitively to transformers on small to medium sized datasets. We hope that\nour work could help bridge the gap between traditional syntactic and\nprobabilistic approaches and cutting-edge neural approaches to NLP, and inspire\nmore linguistically-principled neural approaches in the future.\n",
                "链接": "https://arxiv.org/abs/2311.15211"
            },
            {
                "文章ID": "43098",
                "标题": "A Transformer-based Generative Model for De Novo Molecular Design",
                "作者": " Wenlu Wang,  Ye Wang,  Honggang Zhao,  Simone Sciabola",
                "发布日期": "2022-10-25",
                "摘要": "  In the scope of drug discovery, the molecular design aims to identify novel\ncompounds from the chemical space where the potential drug-like molecules are\nestimated to be in the order of 10^60 - 10^100. Since this search task is\ncomputationally intractable due to the unbounded search space, deep learning\ndraws a lot of attention as a new way of generating unseen molecules. As we\nseek compounds with specific target proteins, we propose a Transformer-based\ndeep model for de novo target-specific molecular design. The proposed method is\ncapable of generating both drug-like compounds (without specified targets) and\ntarget-specific compounds. The latter are generated by enforcing different keys\nand values of the multi-head attention for each target. In this way, we allow\nthe generation of SMILES strings to be conditional on the specified target.\nExperimental results demonstrate that our method is capable of generating both\nvalid drug-like compounds and target-specific compounds. Moreover, the sampled\ncompounds from conditional model largely occupy the real target-specific\nmolecules' chemical space and also cover a significant fraction of novel\ncompounds.\n",
                "链接": "https://arxiv.org/abs/2210.08749"
            },
            {
                "文章ID": "73751",
                "标题": "Transformer-Based Language Model Surprisal Predicts Human Reading Times\n  Best with About Two Billion Training Tokens",
                "作者": " Byung-Doh Oh,  William Schuler",
                "发布日期": "2023-10-24",
                "摘要": "  Recent psycholinguistic studies have drawn conflicting conclusions about the\nrelationship between the quality of a language model and the ability of its\nsurprisal estimates to predict human reading times, which has been speculated\nto be due to the large gap in both the amount of training data and model\ncapacity across studies. The current work aims to consolidate these findings by\nevaluating surprisal estimates from Transformer-based language model variants\nthat vary systematically in the amount of training data and model capacity on\ntheir ability to predict human reading times. The results show that surprisal\nestimates from most variants with contemporary model capacities provide the\nbest fit after seeing about two billion training tokens, after which they begin\nto diverge from humanlike expectations. Additionally, newly-trained smaller\nmodel variants reveal a 'tipping point' at convergence, after which the\ndecrease in language model perplexity begins to result in poorer fits to human\nreading times. These results suggest that the massive amount of training data\nis mainly responsible for the poorer fit achieved by surprisal from larger\npre-trained language models, and that a certain degree of model capacity is\nnecessary for Transformer-based language models to capture humanlike\nexpectations.\n",
                "链接": "https://arxiv.org/abs/2304.11389"
            },
            {
                "文章ID": "67954",
                "标题": "Vision Transformer-based Model for Severity Quantification of Lung\n  Pneumonia Using Chest X-ray Images",
                "作者": " Bouthaina Slika,  Fadi Dornaika,  Hamid Merdji,  Karim Hammoudi",
                "发布日期": "2023-03-22",
                "摘要": "  To develop generic and reliable approaches for diagnosing and assessing the\nseverity of COVID-19 from chest X-rays (CXR), a large number of well-maintained\nCOVID-19 datasets are needed. Existing severity quantification architectures\nrequire expensive training calculations to achieve the best results. For\nhealthcare professionals to quickly and automatically identify COVID-19\npatients and predict associated severity indicators, computer utilities are\nneeded. In this work, we propose a Vision Transformer (ViT)-based neural\nnetwork model that relies on a small number of trainable parameters to quantify\nthe severity of COVID-19 and other lung diseases. We present a feasible\napproach to quantify the severity of CXR, called Vision Transformer Regressor\nInfection Prediction (ViTReg-IP), derived from a ViT and a regression head. We\ninvestigate the generalization potential of our model using a variety of\nadditional test chest radiograph datasets from different open sources. In this\ncontext, we performed a comparative study with several competing deep learning\nanalysis methods. The experimental results show that our model can provide peak\nperformance in quantifying severity with high generalizability at a relatively\nlow computational cost. The source codes used in our work are publicly\navailable at https://github.com/bouthainas/ViTReg-IP.\n",
                "链接": "https://arxiv.org/abs/2303.11935"
            },
            {
                "文章ID": "16523",
                "标题": "Crystal Transformer: Self-learning neural language model for Generative\n  and Tinkering Design of Materials",
                "作者": " Lai Wei,  Qinyang Li,  Yuqi Song,  Stanislav Stefanov,  Edirisuriya M. D. Siriwardane,  Fanglin Chen,  Jianjun Hu",
                "发布日期": "2022-04-27",
                "摘要": "  Self-supervised neural language models have recently achieved unprecedented\nsuccess, from natural language processing to learning the languages of\nbiological sequences and organic molecules. These models have demonstrated\nsuperior performance in the generation, structure classification, and\nfunctional predictions for proteins and molecules with learned representations.\nHowever, most of the masking-based pre-trained language models are not designed\nfor generative design, and their black-box nature makes it difficult to\ninterpret their design logic. Here we propose BLMM Crystal Transformer, a\nneural network based probabilistic generative model for generative and\ntinkering design of inorganic materials. Our model is built on the blank\nfilling language model for text generation and has demonstrated unique\nadvantages in learning the \"materials grammars\" together with high-quality\ngeneration, interpretability, and data efficiency. It can generate chemically\nvalid materials compositions with as high as 89.7\\% charge neutrality and\n84.8\\% balanced electronegativity, which are more than 4 and 8 times higher\ncompared to a pseudo random sampling baseline. The probabilistic generation\nprocess of BLMM allows it to recommend tinkering operations based on learned\nmaterials chemistry and makes it useful for materials doping. Combined with the\nTCSP crysal structure prediction algorithm, We have applied our model to\ndiscover a set of new materials as validated using DFT calculations. Our work\nthus brings the unsupervised transformer language models based generative\nartificial intelligence to inorganic materials. A user-friendly web app has\nbeen developed for computational materials doping and can be accessed freely at\n\\url{www.materialsatlas.org/blmtinker}.\n",
                "链接": "https://arxiv.org/abs/2204.11953"
            },
            {
                "文章ID": "97120",
                "标题": "Exploring Sampling Techniques for Generating Melodies with a Transformer\n  Language Model",
                "作者": " Mathias Rose Bjare,  Stefan Lattner,  Gerhard Widmer",
                "发布日期": "2023-08-21",
                "摘要": "  Research in natural language processing has demonstrated that the quality of\ngenerations from trained autoregressive language models is significantly\ninfluenced by the used sampling strategy. In this study, we investigate the\nimpact of different sampling techniques on musical qualities such as diversity\nand structure. To accomplish this, we train a high-capacity transformer model\non a vast collection of highly-structured Irish folk melodies and analyze the\nmusical qualities of the samples generated using distribution truncation\nsampling techniques. Specifically, we use nucleus sampling, the recently\nproposed \"typical sampling\", and conventional ancestral sampling. We evaluate\nthe effect of these sampling strategies in two scenarios: optimal circumstances\nwith a well-calibrated model and suboptimal circumstances where we\nsystematically degrade the model's performance. We assess the generated samples\nusing objective and subjective evaluations. We discover that probability\ntruncation techniques may restrict diversity and structural patterns in optimal\ncircumstances, but may also produce more musical samples in suboptimal\ncircumstances.\n",
                "链接": "https://arxiv.org/abs/2308.09454"
            },
            {
                "文章ID": "46896",
                "标题": "A Transformer-Based Substitute Recommendation Model Incorporating Weakly\n  Supervised Customer Behavior Data",
                "作者": " Wenting Ye,  Hongfei Yang,  Shuai Zhao,  Haoyang Fang,  Xingjian Shi,  Naveen Neppalli",
                "发布日期": "2023-04-11",
                "摘要": "  The substitute-based recommendation is widely used in E-commerce to provide\nbetter alternatives to customers. However, existing research typically uses the\ncustomer behavior signals like co-view and view-but-purchase-another to capture\nthe substitute relationship. Despite its intuitive soundness, we find that such\nan approach might ignore the functionality and characteristics of products. In\nthis paper, we adapt substitute recommendation into language matching problem\nby taking product title description as model input to consider product\nfunctionality. We design a new transformation method to de-noise the signals\nderived from production data. In addition, we consider multilingual support\nfrom the engineering point of view. Our proposed end-to-end transformer-based\nmodel achieves both successes from offline and online experiments. The proposed\nmodel has been deployed in a large-scale E-commerce website for 11 marketplaces\nin 6 languages. Our proposed model is demonstrated to increase revenue by 19%\nbased on an online A/B experiment.\n",
                "链接": "https://arxiv.org/abs/2211.02533"
            },
            {
                "文章ID": "57241",
                "标题": "TDSTF: Transformer-based Diffusion probabilistic model for Sparse Time\n  series Forecasting",
                "作者": " Ping Chang,  Huayu Li,  Stuart F. Quan,  Shuyang Lu,  Shu-Fen Wung,  Janet Roveda,  Ao Li",
                "发布日期": "2023-03-16",
                "摘要": "  Background and objective: In the intensive care unit (ICU), vital sign\nmonitoring is critical, and an accurate predictive system is required. This\nstudy will create a novel model to forecast Heart Rate (HR), Systolic Blood\nPressure (SBP), and Diastolic Blood Pressure (DBP) in ICU. These vital signs\nare crucial for prompt interventions for patients. We extracted $24,886$ ICU\nstays from the MIMIC-III database, which contains data from over $46$ thousand\npatients, to train and test the model. Methods: The model proposed in this\nstudy, areansformerin intensive careabilistic Model for Sparse Time Series\nForecasting (TDSTF), uses a deep learning technique called the Transformer. The\nTDSTF model showed state-of-the-art performance in predicting vital signs in\nthe ICU, outperforming other models' ability to predict distributions of vital\nsigns and being more computationally efficient. The code is available at\nhttps://github.com/PingChang818/TDSTF. Results: The results of the study showed\nthat TDSTF achieved a Normalized Average Continuous Ranked Probability Score\n(NACRPS) of $0.4438$ and a Mean Squared Error (MSE) of $0.4168$, an improvement\nof $18.9\\%$ and $34.3\\%$ over the best baseline model, respectively.\nConclusion: In conclusion, TDSTF is an effective and efficient solution for\nforecasting vital signs in the ICU, and it shows a significant improvement\ncompared to other models in the field.\n",
                "链接": "https://arxiv.org/abs/2301.06625"
            },
            {
                "文章ID": "11132",
                "标题": "Estimation of speaker age and height from speech signal using bi-encoder\n  transformer mixture model",
                "作者": " Tarun Gupta,  Duc-Tuan Truong,  Tran The Anh,  Chng Eng Siong",
                "发布日期": "2022-03-23",
                "摘要": "  The estimation of speaker characteristics such as age and height is a\nchallenging task, having numerous applications in voice forensic analysis. In\nthis work, we propose a bi-encoder transformer mixture model for speaker age\nand height estimation. Considering the wide differences in male and female\nvoice characteristics such as differences in formant and fundamental\nfrequencies, we propose the use of two separate transformer encoders for the\nextraction of specific voice features in the male and female gender, using\nwav2vec 2.0 as a common-level feature extractor. This architecture reduces the\ninterference effects during backpropagation and improves the generalizability\nof the model. We perform our experiments on the TIMIT dataset and significantly\noutperform the current state-of-the-art results on age estimation.\nSpecifically, we achieve root mean squared error (RMSE) of 5.54 years and 6.49\nyears for male and female age estimation, respectively. Further experiment to\nevaluate the relative importance of different phonetic types for our task\ndemonstrate that vowel sounds are the most distinguishing for age estimation.\n",
                "链接": "https://arxiv.org/abs/2203.11774"
            },
            {
                "文章ID": "84532",
                "标题": "Sequence-to-Sequence Model with Transformer-based Attention Mechanism\n  and Temporal Pooling for Non-Intrusive Load Monitoring",
                "作者": " Mohammad Irani Azad,  Roozbeh Rajabi,  Abouzar Estebsari",
                "发布日期": "2023-06-09",
                "摘要": "  This paper presents a novel Sequence-to-Sequence (Seq2Seq) model based on a\ntransformer-based attention mechanism and temporal pooling for Non-Intrusive\nLoad Monitoring (NILM) of smart buildings. The paper aims to improve the\naccuracy of NILM by using a deep learning-based method. The proposed method\nuses a Seq2Seq model with a transformer-based attention mechanism to capture\nthe long-term dependencies of NILM data. Additionally, temporal pooling is used\nto improve the model's accuracy by capturing both the steady-state and\ntransient behavior of appliances. The paper evaluates the proposed method on a\npublicly available dataset and compares the results with other state-of-the-art\nNILM techniques. The results demonstrate that the proposed method outperforms\nthe existing methods in terms of both accuracy and computational efficiency.\n",
                "链接": "https://arxiv.org/abs/2306.05012"
            },
            {
                "文章ID": "22749",
                "标题": "Anomaly detection in surveillance videos using transformer based\n  attention model",
                "作者": " Kapil Deshpande,  Narinder Singh Punn,  Sanjay Kumar Sonbhadra,  Sonali Agarwal",
                "发布日期": "2022-06-07",
                "摘要": "  Surveillance footage can catch a wide range of realistic anomalies. This\nresearch suggests using a weakly supervised strategy to avoid annotating\nanomalous segments in training videos, which is time consuming. In this\napproach only video level labels are used to obtain frame level anomaly scores.\nWeakly supervised video anomaly detection (WSVAD) suffers from the wrong\nidentification of abnormal and normal instances during the training process.\nTherefore it is important to extract better quality features from the available\nvideos. WIth this motivation, the present paper uses better quality\ntransformer-based features named Videoswin Features followed by the attention\nlayer based on dilated convolution and self attention to capture long and short\nrange dependencies in temporal domain. This gives us a better understanding of\navailable videos. The proposed framework is validated on real-world dataset\ni.e. ShanghaiTech Campus dataset which results in competitive performance than\ncurrent state-of-the-art methods. The model and the code are available at\nhttps://github.com/kapildeshpande/Anomaly-Detection-in-Surveillance-Videos\n",
                "链接": "https://arxiv.org/abs/2206.01524"
            },
            {
                "文章ID": "3395",
                "标题": "Correcting diacritics and typos with a ByT5 transformer model",
                "作者": " Lukas Stankevičius,  Mantas Lukoševičius,  Jurgita Kapočiūtė-Dzikienė,  Monika Briedienė,  Tomas Krilavičius",
                "发布日期": "2022-03-24",
                "摘要": "  Due to the fast pace of life and online communications and the prevalence of\nEnglish and the QWERTY keyboard, people tend to forgo using diacritics, make\ntypographical errors (typos) when typing in other languages. Restoring\ndiacritics and correcting spelling is important for proper language use and the\ndisambiguation of texts for both humans and downstream algorithms. However,\nboth of these problems are typically addressed separately: the state-of-the-art\ndiacritics restoration methods do not tolerate other typos, but classical\nspellcheckers also cannot deal adequately with all the diacritics missing. In\nthis work, we tackle both problems at once by employing the newly-developed\nuniversal ByT5 byte-level seq2seq transformer model that requires no\nlanguage-specific model structures. For a comparison, we perform diacritics\nrestoration on benchmark datasets of 12 languages, with the addition of\nLithuanian. The experimental investigation proves that our approach is able to\nachieve results (> 98%) comparable to the previous state-of-the-art, despite\nbeing trained less and on fewer data. Our approach is also able to restore\ndiacritics in words not seen during training with > 76% accuracy. Our\nsimultaneous diacritics restoration and typos correction approach reaches > 94%\nalpha-word accuracy on the 13 languages. It has no direct competitors and\nstrongly outperforms classical spell-checking or dictionary-based approaches.\nWe also demonstrate all the accuracies to further improve with more training.\nTaken together, this shows the great real-world application potential of our\nsuggested methods to more data, languages, and error classes.\n",
                "链接": "https://arxiv.org/abs/2201.13242"
            },
            {
                "文章ID": "30176",
                "标题": "Single Frame Atmospheric Turbulence Mitigation: A Benchmark Study and A\n  New Physics-Inspired Transformer Model",
                "作者": " Zhiyuan Mao,  Ajay Jaiswal,  Zhangyang Wang,  Stanley H. Chan",
                "发布日期": "2022-07-26",
                "摘要": "  Image restoration algorithms for atmospheric turbulence are known to be much\nmore challenging to design than traditional ones such as blur or noise because\nthe distortion caused by the turbulence is an entanglement of spatially varying\nblur, geometric distortion, and sensor noise. Existing CNN-based restoration\nmethods built upon convolutional kernels with static weights are insufficient\nto handle the spatially dynamical atmospheric turbulence effect. To address\nthis problem, in this paper, we propose a physics-inspired transformer model\nfor imaging through atmospheric turbulence. The proposed network utilizes the\npower of transformer blocks to jointly extract a dynamical turbulence\ndistortion map and restore a turbulence-free image. In addition, recognizing\nthe lack of a comprehensive dataset, we collect and present two new real-world\nturbulence datasets that allow for evaluation with both classical objective\nmetrics (e.g., PSNR and SSIM) and a new task-driven metric using text\nrecognition accuracy. Both real testing sets and all related code will be made\npublicly available.\n",
                "链接": "https://arxiv.org/abs/2207.10040"
            },
            {
                "文章ID": "87602",
                "标题": "Action Q-Transformer: Visual Explanation in Deep Reinforcement Learning\n  with Encoder-Decoder Model using Action Query",
                "作者": " Hidenori Itaya,  Tsubasa Hirakawa,  Takayoshi Yamashita,  Hironobu Fujiyoshi,  Komei Sugiura",
                "发布日期": "2023-06-27",
                "摘要": "  The excellent performance of Transformer in supervised learning has led to\ngrowing interest in its potential application to deep reinforcement learning\n(DRL) to achieve high performance on a wide variety of problems. However, the\ndecision making of a DRL agent is a black box, which greatly hinders the\napplication of the agent to real-world problems. To address this problem, we\npropose the Action Q-Transformer (AQT), which introduces a transformer\nencoder-decoder structure to Q-learning based DRL methods. In AQT, the encoder\ncalculates the state value function and the decoder calculates the advantage\nfunction to promote the acquisition of different attentions indicating the\nagent's decision-making. The decoder in AQT utilizes action queries, which\nrepresent the information of each action, as queries. This enables us to obtain\nthe attentions for the state value and for each action. By acquiring and\nvisualizing these attentions that detail the agent's decision-making, we\nachieve a DRL model with high interpretability. In this paper, we show that\nvisualization of attention in Atari 2600 games enables detailed analysis of\nagents' decision-making in various game tasks. Further, experimental results\ndemonstrate that our method can achieve higher performance than the baseline in\nsome games.\n",
                "链接": "https://arxiv.org/abs/2306.13879"
            },
            {
                "文章ID": "120454",
                "标题": "Transformer-Based Deep Learning Model for Bored Pile Load-Deformation\n  Prediction in Bangkok Subsoil",
                "作者": " Sompote Youwai,  Chissanupong Thongnoo",
                "发布日期": "2023-12-07",
                "摘要": "  This paper presents a novel deep learning model based on the transformer\narchitecture to predict the load-deformation behavior of large bored piles in\nBangkok subsoil. The model encodes the soil profile and pile features as\ntokenization input, and generates the load-deformation curve as output. The\nmodel also incorporates the previous sequential data of load-deformation curve\ninto the decoder to improve the prediction accuracy. The model also\nincorporates the previous sequential data of load-deformation curve into the\ndecoder. The model shows a satisfactory accuracy and generalization ability for\nthe load-deformation curve prediction, with a mean absolute error of 5.72% for\nthe test data. The model could also be used for parametric analysis and design\noptimization of piles under different soil and pile conditions, pile cross\nsection, pile length and type of pile.\n",
                "链接": "https://arxiv.org/abs/2312.03041"
            },
            {
                "文章ID": "50549",
                "标题": "Transformer-based Model for Word Level Language Identification in\n  Code-mixed Kannada-English Texts",
                "作者": " Atnafu Lambebo Tonja,  Mesay Gemeda Yigezu,  Olga Kolesnikova,  Moein Shahiki Tash,  Grigori Sidorov,  Alexander Gelbuk",
                "发布日期": "2022-11-29",
                "摘要": "  Using code-mixed data in natural language processing (NLP) research currently\ngets a lot of attention. Language identification of social media code-mixed\ntext has been an interesting problem of study in recent years due to the\nadvancement and influences of social media in communication. This paper\npresents the Instituto Polit\\'ecnico Nacional, Centro de Investigaci\\'on en\nComputaci\\'on (CIC) team's system description paper for the CoLI-Kanglish\nshared task at ICON2022. In this paper, we propose the use of a Transformer\nbased model for word-level language identification in code-mixed Kannada\nEnglish texts. The proposed model on the CoLI-Kenglish dataset achieves a\nweighted F1-score of 0.84 and a macro F1-score of 0.61.\n",
                "链接": "https://arxiv.org/abs/2211.14459"
            },
            {
                "文章ID": "74352",
                "标题": "UNADON: Transformer-based model to predict genome-wide chromosome\n  spatial position",
                "作者": " Muyu Yang,  Jian Ma",
                "发布日期": "2023-07-04",
                "摘要": "  The spatial positioning of chromosomes relative to functional nuclear bodies\nis intertwined with genome functions such as transcription. However, the\nsequence patterns and epigenomic features that collectively influence chromatin\nspatial positioning in a genome-wide manner are not well understood. Here, we\ndevelop a new transformer-based deep learning model called UNADON, which\npredicts the genome-wide cytological distance to a specific type of nuclear\nbody, as measured by TSA-seq, using both sequence features and epigenomic\nsignals. Evaluations of UNADON in four cell lines (K562, H1, HFFc6, HCT116)\nshow high accuracy in predicting chromatin spatial positioning to nuclear\nbodies when trained on a single cell line. UNADON also performed well in an\nunseen cell type. Importantly, we reveal potential sequence and epigenomic\nfactors that affect large-scale chromatin compartmentalization to nuclear\nbodies. Together, UNADON provides new insights into the principles between\nsequence features and large-scale chromatin spatial localization, which has\nimportant implications for understanding nuclear structure and function.\n",
                "链接": "https://arxiv.org/abs/2304.13230"
            },
            {
                "文章ID": "87914",
                "标题": "Automatic Assessment of Divergent Thinking in Chinese Language with\n  TransDis: A Transformer-Based Language Model Approach",
                "作者": " Tianchen Yang,  Qifan Zhang,  Zhaoyang Sun,  Yubo Hou",
                "发布日期": "2023-12-27",
                "摘要": "  Language models have been increasingly popular for automatic creativity\nassessment, generating semantic distances to objectively measure the quality of\ncreative ideas. However, there is currently a lack of an automatic assessment\nsystem for evaluating creative ideas in the Chinese language. To address this\ngap, we developed TransDis, a scoring system using transformer-based language\nmodels, capable of providing valid originality (quality) and flexibility\n(variety) scores for Alternative Uses Task (AUT) responses in Chinese. Study 1\ndemonstrated that the latent model-rated originality factor, comprised of three\ntransformer-based models, strongly predicted human originality ratings, and the\nmodel-rated flexibility strongly correlated with human flexibility ratings as\nwell. Criterion validity analyses indicated that model-rated originality and\nflexibility positively correlated to other creativity measures, demonstrating\nsimilar validity to human ratings. Study 2 & 3 showed that TransDis effectively\ndistinguished participants instructed to provide creative vs. common uses\n(Study 2) and participants instructed to generate ideas in a flexible vs.\npersistent way (Study 3). Our findings suggest that TransDis can be a reliable\nand low-cost tool for measuring idea originality and flexibility in Chinese\nlanguage, potentially paving the way for automatic creativity assessment in\nother languages. We offer an open platform to compute originality and\nflexibility for AUT responses in Chinese and over 50 other languages\n(https://osf.io/59jv2/).\n",
                "链接": "https://arxiv.org/abs/2306.14790"
            },
            {
                "文章ID": "13067",
                "标题": "UNetFormer: A Unified Vision Transformer Model and Pre-Training\n  Framework for 3D Medical Image Segmentation",
                "作者": " Ali Hatamizadeh,  Ziyue Xu,  Dong Yang,  Wenqi Li,  Holger Roth,  Daguang Xu",
                "发布日期": "2022-04-06",
                "摘要": "  Vision Transformers (ViT)s have recently become popular due to their\noutstanding modeling capabilities, in particular for capturing long-range\ninformation, and scalability to dataset and model sizes which has led to\nstate-of-the-art performance in various computer vision and medical image\nanalysis tasks. In this work, we introduce a unified framework consisting of\ntwo architectures, dubbed UNetFormer, with a 3D Swin Transformer-based encoder\nand Convolutional Neural Network (CNN) and transformer-based decoders. In the\nproposed model, the encoder is linked to the decoder via skip connections at\nfive different resolutions with deep supervision. The design of proposed\narchitecture allows for meeting a wide range of trade-off requirements between\naccuracy and computational cost. In addition, we present a methodology for\nself-supervised pre-training of the encoder backbone via learning to predict\nrandomly masked volumetric tokens using contextual information of visible\ntokens. We pre-train our framework on a cohort of $5050$ CT images, gathered\nfrom publicly available CT datasets, and present a systematic investigation of\nvarious components such as masking ratio and patch size that affect the\nrepresentation learning capability and performance of downstream tasks. We\nvalidate the effectiveness of our pre-training approach by fine-tuning and\ntesting our model on liver and liver tumor segmentation task using the Medical\nSegmentation Decathlon (MSD) dataset and achieve state-of-the-art performance\nin terms of various segmentation metrics. To demonstrate its generalizability,\nwe train and test the model on BraTS 21 dataset for brain tumor segmentation\nusing MRI images and outperform other methods in terms of Dice score. Code:\nhttps://github.com/Project-MONAI/research-contributions\n",
                "链接": "https://arxiv.org/abs/2204.00631"
            },
            {
                "文章ID": "57831",
                "标题": "REDAffectiveLM: Leveraging Affect Enriched Embedding and\n  Transformer-based Neural Language Model for Readers' Emotion Detection",
                "作者": " Anoop Kadan,  Deepak P.,  Manjary P. Gangan,  Savitha Sam Abraham,  Lajish V. L",
                "发布日期": "2023-01-24",
                "摘要": "  Technological advancements in web platforms allow people to express and share\nemotions towards textual write-ups written and shared by others. This brings\nabout different interesting domains for analysis; emotion expressed by the\nwriter and emotion elicited from the readers. In this paper, we propose a novel\napproach for Readers' Emotion Detection from short-text documents using a deep\nlearning model called REDAffectiveLM. Within state-of-the-art NLP tasks, it is\nwell understood that utilizing context-specific representations from\ntransformer-based pre-trained language models helps achieve improved\nperformance. Within this affective computing task, we explore how incorporating\naffective information can further enhance performance. Towards this, we\nleverage context-specific and affect enriched representations by using a\ntransformer-based pre-trained language model in tandem with affect enriched\nBi-LSTM+Attention. For empirical evaluation, we procure a new dataset REN-20k,\nbesides using RENh-4k and SemEval-2007. We evaluate the performance of our\nREDAffectiveLM rigorously across these datasets, against a vast set of\nstate-of-the-art baselines, where our model consistently outperforms baselines\nand obtains statistically significant results. Our results establish that\nutilizing affect enriched representation along with context-specific\nrepresentation within a neural architecture can considerably enhance readers'\nemotion detection. Since the impact of affect enrichment specifically in\nreaders' emotion detection isn't well explored, we conduct a detailed analysis\nover affect enriched Bi-LSTM+Attention using qualitative and quantitative model\nbehavior evaluation techniques. We observe that compared to conventional\nsemantic embedding, affect enriched embedding increases ability of the network\nto effectively identify and assign weightage to key terms responsible for\nreaders' emotion detection.\n",
                "链接": "https://arxiv.org/abs/2301.08995"
            },
            {
                "文章ID": "111908",
                "标题": "FaultSeg Swin-UNETR: Transformer-Based Self-Supervised Pretraining Model\n  for Fault Recognition",
                "作者": " Zeren Zhang,  Ran Chen,  Jinwen Ma",
                "发布日期": "2023-10-30",
                "摘要": "  This paper introduces an approach to enhance seismic fault recognition\nthrough self-supervised pretraining. Seismic fault interpretation holds great\nsignificance in the fields of geophysics and geology. However, conventional\nmethods for seismic fault recognition encounter various issues, including\ndependence on data quality and quantity, as well as susceptibility to\ninterpreter subjectivity. Currently, automated fault recognition methods\nproposed based on small synthetic datasets experience performance degradation\nwhen applied to actual seismic data. To address these challenges, we have\nintroduced the concept of self-supervised learning, utilizing a substantial\namount of relatively easily obtainable unlabeled seismic data for pretraining.\nSpecifically, we have employed the Swin Transformer model as the core network\nand employed the SimMIM pretraining task to capture unique features related to\ndiscontinuities in seismic data. During the fine-tuning phase, inspired by edge\ndetection techniques, we have also refined the structure of the Swin-UNETR\nmodel, enabling multiscale decoding and fusion for more effective fault\ndetection. Experimental results demonstrate that our proposed method attains\nstate-of-the-art performance on the Thebe dataset, as measured by the OIS and\nODS metrics.\n",
                "链接": "https://arxiv.org/abs/2310.17974"
            },
            {
                "文章ID": "53941",
                "标题": "Utilizing distilBert transformer model for sentiment classification of\n  COVID-19's Persian open-text responses",
                "作者": " Fatemeh Sadat Masoumi,  Mohammad Bahrani",
                "发布日期": "2022-12-19",
                "摘要": "  The COVID-19 pandemic has caused drastic alternations in human life in all\naspects. The government's laws in this regard affected the lifestyle of all\npeople. Due to this fact studying the sentiment of individuals is essential to\nbe aware of the future impacts of the coming pandemics. To contribute to this\naim, we proposed an NLP (Natural Language Processing) model to analyze\nopen-text answers in a survey in Persian and detect positive and negative\nfeelings of the people in Iran. In this study, a distilBert transformer model\nwas applied to take on this task. We deployed three approaches to perform the\ncomparison, and our best model could gain accuracy: 0.824, Precision: 0.824,\nRecall: 0.798, and F1 score: 0.804.\n",
                "链接": "https://arxiv.org/abs/2212.08407"
            },
            {
                "文章ID": "76805",
                "标题": "Transformer-based model for monocular visual odometry: a video\n  understanding approach",
                "作者": " André O. Françani,  Marcos R. O. A. Maximo",
                "发布日期": "2023-09-14",
                "摘要": "  Estimating the camera's pose given images of a single camera is a traditional\ntask in mobile robots and autonomous vehicles. This problem is called monocular\nvisual odometry and it often relies on geometric approaches that require\nconsiderable engineering effort for a specific scenario. Deep learning methods\nhave shown to be generalizable after proper training and a large amount of\navailable data. Transformer-based architectures have dominated the\nstate-of-the-art in natural language processing and computer vision tasks, such\nas image and video understanding. In this work, we deal with the monocular\nvisual odometry as a video understanding task to estimate the 6-DoF camera's\npose. We contribute by presenting the TSformer-VO model based on\nspatio-temporal self-attention mechanisms to extract features from clips and\nestimate the motions in an end-to-end manner. Our approach achieved competitive\nstate-of-the-art performance compared with geometry-based and deep\nlearning-based methods on the KITTI visual odometry dataset, outperforming the\nDeepVO implementation highly accepted in the visual odometry community.\n",
                "链接": "https://arxiv.org/abs/2305.06121"
            },
            {
                "文章ID": "55003",
                "标题": "HiTSKT: A Hierarchical Transformer Model for Session-Aware Knowledge\n  Tracing",
                "作者": " Fucai Ke,  Weiqing Wang,  Weicong Tan,  Lan Du,  Yuan Jin,  Yujin Huang,  Hongzhi Yin",
                "发布日期": "2023-06-07",
                "摘要": "  Knowledge tracing (KT) aims to leverage students' learning histories to\nestimate their mastery levels on a set of pre-defined skills, based on which\nthe corresponding future performance can be accurately predicted. As an\nimportant way of providing personalized experience for online education, KT has\ngained increased attention in recent years. In practice, a student's learning\nhistory comprises answers to sets of massed questions, each known as a session,\nrather than merely being a sequence of independent answers. Theoretically,\nwithin and across these sessions, students' learning dynamics can be very\ndifferent. Therefore, how to effectively model the dynamics of students'\nknowledge states within and across the sessions is crucial for handling the KT\nproblem. Most existing KT models treat student's learning records as a single\ncontinuing sequence, without capturing the sessional shift of students'\nknowledge state. To address the above issue, we propose a novel hierarchical\ntransformer model, named HiTSKT, comprises an interaction(-level) encoder to\ncapture the knowledge a student acquires within a session, and a\nsession(-level) encoder to summarise acquired knowledge across the past\nsessions. To predict an interaction in the current session, a knowledge\nretriever integrates the summarised past-session knowledge with the previous\ninteractions' information into proper knowledge representations. These\nrepresentations are then used to compute the student's current knowledge state.\nAdditionally, to model the student's long-term forgetting behaviour across the\nsessions, a power-law-decay attention mechanism is designed and deployed in the\nsession encoder, allowing it to emphasize more on the recent sessions.\nExtensive experiments on three public datasets demonstrate that HiTSKT achieves\nnew state-of-the-art performance on all the datasets compared with six\nstate-of-the-art KT models.\n",
                "链接": "https://arxiv.org/abs/2212.12139"
            },
            {
                "文章ID": "31764",
                "标题": "A Transformer-based Neural Language Model that Synthesizes Brain\n  Activation Maps from Free-Form Text Queries",
                "作者": " Gia H. Ngo,  Minh Nguyen,  Nancy F. Chen,  Mert R. Sabuncu",
                "发布日期": "2022-08-02",
                "摘要": "  Neuroimaging studies are often limited by the number of subjects and\ncognitive processes that can be feasibly interrogated. However, a rapidly\ngrowing number of neuroscientific studies have collectively accumulated an\nextensive wealth of results. Digesting this growing literature and obtaining\nnovel insights remains to be a major challenge, since existing meta-analytic\ntools are constrained to keyword queries. In this paper, we present Text2Brain,\nan easy to use tool for synthesizing brain activation maps from open-ended text\nqueries. Text2Brain was built on a transformer-based neural network language\nmodel and a coordinate-based meta-analysis of neuroimaging studies. Text2Brain\ncombines a transformer-based text encoder and a 3D image generator, and was\ntrained on variable-length text snippets and their corresponding activation\nmaps sampled from 13,000 published studies. In our experiments, we demonstrate\nthat Text2Brain can synthesize meaningful neural activation patterns from\nvarious free-form textual descriptions. Text2Brain is available at\nhttps://braininterpreter.com as a web-based tool for efficiently searching\nthrough the vast neuroimaging literature and generating new hypotheses.\n",
                "链接": "https://arxiv.org/abs/2208.00840"
            },
            {
                "文章ID": "113246",
                "标题": "Video2Music: Suitable Music Generation from Videos using an Affective\n  Multimodal Transformer model",
                "作者": " Jaeyong Kang,  Soujanya Poria,  Dorien Herremans",
                "发布日期": "2023-11-03",
                "摘要": "  Numerous studies in the field of music generation have demonstrated\nimpressive performance, yet virtually no models are able to directly generate\nmusic to match accompanying videos. In this work, we develop a generative music\nAI framework, Video2Music, that can match a provided video. We first curated a\nunique collection of music videos. Then, we analysed the music videos to obtain\nsemantic, scene offset, motion, and emotion features. These distinct features\nare then employed as guiding input to our music generation model. We transcribe\nthe audio files into MIDI and chords, and extract features such as note density\nand loudness. This results in a rich multimodal dataset, called MuVi-Sync, on\nwhich we train a novel Affective Multimodal Transformer (AMT) model to generate\nmusic given a video. This model includes a novel mechanism to enforce affective\nsimilarity between video and music. Finally, post-processing is performed based\non a biGRU-based regression model to estimate note density and loudness based\non the video features. This ensures a dynamic rendering of the generated chords\nwith varying rhythm and volume. In a thorough experiment, we show that our\nproposed framework can generate music that matches the video content in terms\nof emotion. The musical quality, along with the quality of music-video matching\nis confirmed in a user study. The proposed AMT model, along with the new\nMuVi-Sync dataset, presents a promising step for the new task of music\ngeneration for videos.\n",
                "链接": "https://arxiv.org/abs/2311.00968"
            },
            {
                "文章ID": "12797",
                "标题": "An End-to-end Chinese Text Normalization Model based on Rule-guided\n  Flat-Lattice Transformer",
                "作者": " Wenlin Dai,  Changhe Song,  Xiang Li,  Zhiyong Wu,  Huashan Pan,  Xiulin Li,  Helen Meng",
                "发布日期": "2022-04-01",
                "摘要": "  Text normalization, defined as a procedure transforming non standard words to\nspoken-form words, is crucial to the intelligibility of synthesized speech in\ntext-to-speech system. Rule-based methods without considering context can not\neliminate ambiguation, whereas sequence-to-sequence neural network based\nmethods suffer from the unexpected and uninterpretable errors problem. Recently\nproposed hybrid system treats rule-based model and neural model as two cascaded\nsub-modules, where limited interaction capability makes neural network model\ncannot fully utilize expert knowledge contained in the rules. Inspired by\nFlat-LAttice Transformer (FLAT), we propose an end-to-end Chinese text\nnormalization model, which accepts Chinese characters as direct input and\nintegrates expert knowledge contained in rules into the neural network, both\ncontribute to the superior performance of proposed model for the text\nnormalization task. We also release a first publicly accessible largescale\ndataset for Chinese text normalization. Our proposed model has achieved\nexcellent results on this dataset.\n",
                "链接": "https://arxiv.org/abs/2203.16954"
            },
            {
                "文章ID": "62058",
                "标题": "GPT4MIA: Utilizing Generative Pre-trained Transformer (GPT-3) as A\n  Plug-and-Play Transductive Model for Medical Image Analysis",
                "作者": " Yizhe Zhang,  Danny Z. Chen",
                "发布日期": "2023-03-22",
                "摘要": "  In this paper, we propose a novel approach (called GPT4MIA) that utilizes\nGenerative Pre-trained Transformer (GPT) as a plug-and-play transductive\ninference tool for medical image analysis (MIA). We provide theoretical\nanalysis on why a large pre-trained language model such as GPT-3 can be used as\na plug-and-play transductive inference model for MIA. At the methodological\nlevel, we develop several technical treatments to improve the efficiency and\neffectiveness of GPT4MIA, including better prompt structure design, sample\nselection, and prompt ordering of representative samples/features. We present\ntwo concrete use cases (with workflow) of GPT4MIA: (1) detecting prediction\nerrors and (2) improving prediction accuracy, working in conjecture with\nwell-established vision-based models for image classification (e.g., ResNet).\nExperiments validate that our proposed method is effective for these two tasks.\nWe further discuss the opportunities and challenges in utilizing\nTransformer-based large language models for broader MIA applications.\n",
                "链接": "https://arxiv.org/abs/2302.08722"
            },
            {
                "文章ID": "95663",
                "标题": "PTransIPs: Identification of phosphorylation sites based on protein\n  pretrained language model and Transformer",
                "作者": " Ziyang Xu,  Haitian Zhong",
                "发布日期": "2023-08-21",
                "摘要": "  Phosphorylation is central to numerous fundamental cellular processes,\ninfluencing the onset and progression of a variety of diseases. The correct\nidentification of these phosphorylation sites is of great importance to unravel\nthe intricate molecular mechanisms within cells and during viral infections,\npotentially leading to the discovery of new therapeutic targets. In this study,\nwe introduce PTransIPs, a novel deep learning model for the identification of\nphosphorylation sites. PTransIPs treat amino acids within protein sequences as\nwords, extracting unique encodings based on their type and sequential position.\nThe model also incorporates embeddings from large pretrained protein models as\nadditional data inputs. PTransIPS is further trained on a combination model of\nconvolutional neural network with residual connections and Transformer model\nequipped with multi-head attention mechanisms. At last, the model outputs\nclassification results through a fully connected layer. The results of\nindependent testing reveal that PTransIPs outperforms existing\nstate-of-the-art(SOTA) methods, achieving AUROCs of 0.9232 and 0.9660 for\nidentifying phosphorylated S/T and Y sites respectively. In addition, ablation\nstudies prove that pretrained model embeddings contribute to the performance of\nPTransIPs. Furthermore, PTransIPs has interpretable amino acid preference,\nvisible training process and shows generalizability on other bioactivity\nclassification tasks. To facilitate usage, our code and data are publicly\naccessible at \\url{https://github.com/StatXzy7/PTransIPs}.\n",
                "链接": "https://arxiv.org/abs/2308.05115"
            },
            {
                "文章ID": "17165",
                "标题": "Multimodal Transformer-based Model for Buchwald-Hartwig and\n  Suzuki-Miyaura Reaction Yield Prediction",
                "作者": " Shimaa Baraka,  Ahmed M. El Kerdawy",
                "发布日期": "2022-05-02",
                "摘要": "  Predicting the yield percentage of a chemical reaction is useful in many\naspects such as reducing wet-lab experimentation by giving the priority to the\nreactions with a high predicted yield. In this work we investigated the use of\nmultiple type inputs to predict chemical reaction yield. We used simplified\nmolecular-input line-entry system (SMILES) as well as calculated chemical\ndescriptors as model inputs. The model consists of a pre-trained bidirectional\ntransformer-based encoder (BERT) and a multi-layer perceptron (MLP) with a\nregression head to predict the yield. We experimented on two high throughput\nexperimentation (HTE) datasets for Buchwald-Hartwig and Suzuki-Miyaura\nreactions. The experiments show improvements in the prediction on both datasets\ncompared to systems using only SMILES or chemical descriptors as input. We also\ntested the model's performance on out-of-sample dataset splits of\nBuchwald-Hartwig and achieved comparable results with the state-of-the-art. In\naddition to predicting the yield, we demonstrated the model's ability to\nsuggest the optimum (highest yield) reaction conditions. The model was able to\nsuggest conditions that achieves 94% of the optimum reported yields. This\nproves the model to be useful in achieving the best results in the wet lab\nwithout expensive experimentation.\n",
                "链接": "https://arxiv.org/abs/2204.14062"
            },
            {
                "文章ID": "62231",
                "标题": "Transformer-Based Neural Marked Spatio Temporal Point Process Model for\n  Football Match Events Analysis",
                "作者": " Calvin C. K. Yeung,  Tony Sit,  Keisuke Fujii",
                "发布日期": "2023-02-21",
                "摘要": "  With recently available football match event data that record the details of\nfootball matches, analysts and researchers have a great opportunity to develop\nnew performance metrics, gain insight, and evaluate key performance. However,\nmost sports sequential events modeling methods and performance metrics\napproaches could be incomprehensive in dealing with such large-scale\nspatiotemporal data (in particular, temporal process), thereby necessitating a\nmore comprehensive spatiotemporal model and a holistic performance metric. To\nthis end, we proposed the Transformer-Based Neural Marked Spatio Temporal Point\nProcess (NMSTPP) model for football event data based on the neural temporal\npoint processes (NTPP) framework. In the experiments, our model outperformed\nthe prediction performance of the baseline models. Furthermore, we proposed the\nholistic possession utilization score (HPUS) metric for a more comprehensive\nfootball possession analysis. For verification, we examined the relationship\nwith football teams' final ranking, average goal score, and average xG over a\nseason. It was observed that the average HPUS showed significant correlations\nregardless of not using goal and details of shot information. Furthermore, we\nshow HPUS examples in analyzing possessions, matches, and between matches.\n",
                "链接": "https://arxiv.org/abs/2302.09276"
            },
            {
                "文章ID": "406",
                "标题": "NumHTML: Numeric-Oriented Hierarchical Transformer Model for Multi-task\n  Financial Forecasting",
                "作者": " Linyi Yang,  Jiazheng Li,  Ruihai Dong,  Yue Zhang,  Barry Smyth",
                "发布日期": "2022-01-07",
                "摘要": "  Financial forecasting has been an important and active area of machine\nlearning research because of the challenges it presents and the potential\nrewards that even minor improvements in prediction accuracy or forecasting may\nentail. Traditionally, financial forecasting has heavily relied on quantitative\nindicators and metrics derived from structured financial statements. Earnings\nconference call data, including text and audio, is an important source of\nunstructured data that has been used for various prediction tasks using deep\nearning and related approaches. However, current deep learning-based methods\nare limited in the way that they deal with numeric data; numbers are typically\ntreated as plain-text tokens without taking advantage of their underlying\nnumeric structure. This paper describes a numeric-oriented hierarchical\ntransformer model to predict stock returns, and financial risk using\nmulti-modal aligned earnings calls data by taking advantage of the different\ncategories of numbers (monetary, temporal, percentages etc.) and their\nmagnitude. We present the results of a comprehensive evaluation of NumHTML\nagainst several state-of-the-art baselines using a real-world publicly\navailable dataset. The results indicate that NumHTML significantly outperforms\nthe current state-of-the-art across a variety of evaluation metrics and that it\nhas the potential to offer significant financial gains in a practical trading\ncontext.\n",
                "链接": "https://arxiv.org/abs/2201.01770"
            },
            {
                "文章ID": "103670",
                "标题": "TrTr: A Versatile Pre-Trained Large Traffic Model based on Transformer\n  for Capturing Trajectory Diversity in Vehicle Population",
                "作者": " Ruyi Feng,  Zhibin Li,  Bowen Liu,  Yan Ding",
                "发布日期": "2023-12-04",
                "摘要": "  Understanding trajectory diversity is a fundamental aspect of addressing\npractical traffic tasks. However, capturing the diversity of trajectories\npresents challenges, particularly with traditional machine learning and\nrecurrent neural networks due to the requirement of large-scale parameters. The\nemerging Transformer technology, renowned for its parallel computation\ncapabilities enabling the utilization of models with hundreds of millions of\nparameters, offers a promising solution. In this study, we apply the\nTransformer architecture to traffic tasks, aiming to learn the diversity of\ntrajectories within vehicle populations. We analyze the Transformer's attention\nmechanism and its adaptability to the goals of traffic tasks, and subsequently,\ndesign specific pre-training tasks. To achieve this, we create a data structure\ntailored to the attention mechanism and introduce a set of noises that\ncorrespond to spatio-temporal demands, which are incorporated into the\nstructured data during the pre-training process. The designed pre-training\nmodel demonstrates excellent performance in capturing the spatial distribution\nof the vehicle population, with no instances of vehicle overlap and an RMSE of\n0.6059 when compared to the ground truth values. In the context of time series\nprediction, approximately 95% of the predicted trajectories' speeds closely\nalign with the true speeds, within a deviation of 7.5144m/s. Furthermore, in\nthe stability test, the model exhibits robustness by continuously predicting a\ntime series ten times longer than the input sequence, delivering smooth\ntrajectories and showcasing diverse driving behaviors. The pre-trained model\nalso provides a good basis for downstream fine-tuning tasks. The number of\nparameters of our model is over 50 million.\n",
                "链接": "https://arxiv.org/abs/2309.12677"
            }
        ]
    },
    {
        "question": {
            "question": "找一下使用强化学习做代码生成的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "59289",
                "标题": "Execution-based Code Generation using Deep Reinforcement Learning",
                "作者": " Parshin Shojaee,  Aneesh Jain,  Sindhu Tipirneni,  Chandan K. Reddy",
                "发布日期": "2023-07-21",
                "摘要": "  The utilization of programming language (PL) models, pre-trained on\nlarge-scale code corpora, as a means of automating software engineering\nprocesses has demonstrated considerable potential in streamlining various code\ngeneration tasks such as code completion, code translation, and program\nsynthesis. However, current approaches mainly rely on supervised fine-tuning\nobjectives borrowed from text generation, neglecting unique sequence-level\ncharacteristics of code, including but not limited to compilability as well as\nsyntactic and functional correctness. To address this limitation, we propose\nPPOCoder, a new framework for code generation that synergistically combines\npre-trained PL models with Proximal Policy Optimization (PPO) which is a widely\nused deep reinforcement learning technique. By utilizing non-differentiable\nfeedback from code execution and structure alignment, PPOCoder seamlessly\nintegrates external code-specific knowledge into the model optimization\nprocess. It's important to note that PPOCoder is a task-agnostic and\nmodel-agnostic framework that can be used across different code generation\ntasks and PLs. Extensive experiments on three code generation tasks demonstrate\nthe effectiveness of our proposed approach compared to SOTA methods, achieving\nsignificant improvements in compilation success rates and functional\ncorrectness across different PLs.\n",
                "链接": "https://arxiv.org/abs/2301.13816"
            },
            {
                "文章ID": "64359",
                "标题": "Reinforcement Learning Guided Multi-Objective Exam Paper Generation",
                "作者": " Yuhu Shang,  Xuexiong Luo,  Lihong Wang,  Hao Peng,  Xiankun Zhang,  Yimeng Ren,  Kun Liang",
                "发布日期": "2023-03-03",
                "摘要": "  To reduce the repetitive and complex work of instructors, exam paper\ngeneration (EPG) technique has become a salient topic in the intelligent\neducation field, which targets at generating high-quality exam paper\nautomatically according to instructor-specified assessment criteria. The\ncurrent advances utilize the ability of heuristic algorithms to optimize\nseveral well-known objective constraints, such as difficulty degree, number of\nquestions, etc., for producing optimal solutions. However, in real scenarios,\nconsidering other equally relevant objectives (e.g., distribution of exam\nscores, skill coverage) is extremely important. Besides, how to develop an\nautomatic multi-objective solution that finds an optimal subset of questions\nfrom a huge search space of large-sized question datasets and thus composes a\nhigh-quality exam paper is urgent but non-trivial. To this end, we skillfully\ndesign a reinforcement learning guided Multi-Objective Exam Paper Generation\nframework, termed MOEPG, to simultaneously optimize three exam domain-specific\nobjectives including difficulty degree, distribution of exam scores, and skill\ncoverage. Specifically, to accurately measure the skill proficiency of the\nexaminee group, we first employ deep knowledge tracing to model the interaction\ninformation between examinees and response logs. We then design the flexible\nExam Q-Network, a function approximator, which automatically selects the\nappropriate question to update the exam paper composition process. Later, MOEPG\ndivides the decision space into multiple subspaces to better guide the updated\ndirection of the exam paper. Through extensive experiments on two real-world\ndatasets, we demonstrate that MOEPG is feasible in addressing the multiple\ndilemmas of exam paper generation scenario.\n",
                "链接": "https://arxiv.org/abs/2303.01042"
            },
            {
                "文章ID": "9115",
                "标题": "Compilable Neural Code Generation with Compiler Feedback",
                "作者": " Xin Wang,  Yasheng Wang,  Yao Wan,  Fei Mi,  Yitong Li,  Pingyi Zhou,  Jin Liu,  Hao Wu,  Xin Jiang,  Qun Liu",
                "发布日期": "2022-03-11",
                "摘要": "  Automatically generating compilable programs with (or without) natural\nlanguage descriptions has always been a touchstone problem for computational\nlinguistics and automated software engineering. Existing deep-learning\napproaches model code generation as text generation, either constrained by\ngrammar structures in decoder, or driven by pre-trained language models on\nlarge-scale code corpus (e.g., CodeGPT, PLBART, and CodeT5). However, few of\nthem account for compilability of the generated programs. To improve\ncompilability of the generated programs, this paper proposes COMPCODER, a\nthree-stage pipeline utilizing compiler feedback for compilable code\ngeneration, including language model fine-tuning, compilability reinforcement,\nand compilability discrimination. Comprehensive experiments on two code\ngeneration tasks demonstrate the effectiveness of our proposed approach,\nimproving the success rate of compilation from 44.18 to 89.18 in code\ncompletion on average and from 70.3 to 96.2 in text-to-code generation,\nrespectively, when comparing with the state-of-the-art CodeGPT.\n",
                "链接": "https://arxiv.org/abs/2203.05132"
            },
            {
                "文章ID": "27761",
                "标题": "CodeRL: Mastering Code Generation through Pretrained Models and Deep\n  Reinforcement Learning",
                "作者": " Hung Le,  Yue Wang,  Akhilesh Deepak Gotmare,  Silvio Savarese,  Steven C. H. Hoi",
                "发布日期": "2022-11-04",
                "摘要": "  Program synthesis or code generation aims to generate a program that\nsatisfies a problem specification. Recent approaches using large-scale\npretrained language models (LMs) have shown promising results, yet they have\nsome critical limitations. In particular, they often follow a standard\nsupervised fine-tuning procedure to train a code generation model only from the\npairs of natural-language problem descriptions and ground-truth programs. Such\nparadigm largely ignores some important but potentially useful signals in the\nproblem specification such as unit tests, which thus often results in poor\nperformance when solving complex unseen coding tasks. To address the\nlimitations, we propose \"CodeRL\", a new framework for program synthesis tasks\nthrough pretrained LMs and deep reinforcement learning (RL). Specifically,\nduring training, we treat the code-generating LM as an actor network, and\nintroduce a critic network that is trained to predict the functional\ncorrectness of generated programs and provide dense feedback signals to the\nactor. During inference, we introduce a new generation procedure with a\ncritical sampling strategy that allows a model to automatically regenerate\nprograms based on feedback from example unit tests and critic scores. For the\nmodel backbones, we extended the encoder-decoder architecture of CodeT5 with\nenhanced learning objectives, larger model sizes, and better pretraining data.\nOur method not only achieves new SOTA results on the challenging APPS\nbenchmark, but also shows strong zero-shot transfer capability with new SOTA\nresults on the simpler MBPP benchmark.\n",
                "链接": "https://arxiv.org/abs/2207.01780"
            },
            {
                "文章ID": "30296",
                "标题": "CodeT: Code Generation with Generated Tests",
                "作者": " Bei Chen,  Fengji Zhang,  Anh Nguyen,  Daoguang Zan,  Zeqi Lin,  Jian-Guang Lou,  Weizhu Chen",
                "发布日期": "2022-11-24",
                "摘要": "  The task of generating code solutions for a given programming problem can\nbenefit from the use of pre-trained language models such as Codex, which can\nproduce multiple diverse samples. However, a major challenge for this task is\nto select the most appropriate solution from the multiple samples generated by\nthe pre-trained language models. A natural way to evaluate the quality and\ncorrectness of a code solution is to run it against a set of test cases, but\nthe manual creation of such test cases is often costly and time-consuming. In\nthis paper, we propose a novel method, CodeT, that leverages the same\npre-trained language models to automatically generate test cases for the code\nsamples, thus reducing the human effort and increasing the coverage of the test\nscenarios. CodeT then executes the code samples using the generated test cases,\nand performs a dual execution agreement, which considers both the consistency\nof the outputs against the generated test cases and the agreement of the\noutputs with other code samples. We conduct comprehensive experiments on four\nbenchmarks, HumanEval, MBPP, APPS and CodeContests, using five different\npre-trained language models with varying sizes and capabilities. Our results\nshow that CodeT can significantly improve the performance of code solution\nselection over previous methods, achieving remarkable and consistent gains\nacross different models and benchmarks. For instance, CodeT improves the pass@1\nmetric on HumanEval to 65.8%, which represents an absolute improvement of 18.8%\nover the code-davinci-002 model, and an absolute improvement of more than 20%\nover the previous state-of-the-art results.\n",
                "链接": "https://arxiv.org/abs/2207.10397"
            },
            {
                "文章ID": "78552",
                "标题": "Investigating and Designing for Trust in AI-powered Code Generation\n  Tools",
                "作者": " Ruotong Wang,  Ruijia Cheng,  Denae Ford,  Thomas Zimmermann",
                "发布日期": "2023-05-22",
                "摘要": "  As AI-powered code generation tools such as GitHub Copilot become popular, it\nis crucial to understand software developers' trust in AI tools -- a key factor\nfor tool adoption and responsible usage. However, we know little about how\ndevelopers build trust with AI, nor do we understand how to design the\ninterface of generative AI systems to facilitate their appropriate levels of\ntrust. In this paper, we describe findings from a two-stage qualitative\ninvestigation. We first interviewed 17 developers to contextualize their\nnotions of trust and understand their challenges in building appropriate trust\nin AI code generation tools. We surfaced three main challenges -- including\nbuilding appropriate expectations, configuring AI tools, and validating AI\nsuggestions. To address these challenges, we conducted a design probe study in\nthe second stage to explore design concepts that support developers'\ntrust-building process by 1) communicating AI performance to help users set\nproper expectations, 2) allowing users to configure AI by setting and adjusting\npreferences, and 3) offering indicators of model mechanism to support\nevaluation of AI suggestions. We gathered developers' feedback on how these\ndesign concepts can help them build appropriate trust in AI-powered code\ngeneration tools, as well as potential risks in design. These findings inform\nour proposed design recommendations on how to design for trust in AI-powered\ncode generation tools.\n",
                "链接": "https://arxiv.org/abs/2305.11248"
            },
            {
                "文章ID": "51256",
                "标题": "Coder Reviewer Reranking for Code Generation",
                "作者": " Tianyi Zhang,  Tao Yu,  Tatsunori B. Hashimoto,  Mike Lewis,  Wen-tau Yih,  Daniel Fried,  Sida I. Wang",
                "发布日期": "2022-11-30",
                "摘要": "  Sampling diverse programs from a code language model and reranking with model\nlikelihood is a popular method for code generation but it is prone to\npreferring degenerate solutions. Inspired by collaborative programming, we\npropose Coder-Reviewer reranking. We augment Coder language models from past\nwork, which generate programs given language instructions, with Reviewer\nmodels, which evaluate the likelihood of the instruction given the generated\nprograms. We perform an extensive study across six datasets with eight models\nfrom three model families. Experimental results show that Coder-Reviewer\nreranking leads to consistent and significant improvement (up to 17% absolute\naccuracy gain) over reranking with the Coder model only. When combined with\nexecutability filtering, Coder-Reviewer reranking can often outperform the\nminimum Bayes risk method. Coder-Reviewer reranking is easy to implement by\nprompting, can generalize to different programming languages, and works well\nwith off-the-shelf hyperparameters.\n",
                "链接": "https://arxiv.org/abs/2211.16490"
            },
            {
                "文章ID": "24006",
                "标题": "StructCoder: Structure-Aware Transformer for Code Generation",
                "作者": " Sindhu Tipirneni,  Ming Zhu,  Chandan K. Reddy",
                "发布日期": "2023-06-02",
                "摘要": "  There has been a recent surge of interest in automating software engineering\ntasks using deep learning. This paper addresses the problem of code generation\nwhere the goal is to generate target code given source code in a different\nlanguage or a natural language description. Most of the state-of-the-art deep\nlearning models for code generation use training strategies primarily designed\nfor natural language. However, understanding and generating code requires a\nmore rigorous comprehension of the code syntax and semantics. With this\nmotivation, we develop an encoder-decoder Transformer model where both the\nencoder and decoder are explicitly trained to recognize the syntax and data\nflow in the source and target codes, respectively. We not only make the encoder\nstructure-aware by leveraging the source code's syntax tree and data flow\ngraph, but we also support the decoder in preserving the syntax and data flow\nof the target code by introducing two novel auxiliary tasks: AST (Abstract\nSyntax Tree) paths prediction and data flow prediction. To the best of our\nknowledge, this is the first work to introduce a structure-aware Transformer\ndecoder that models both syntax and data flow to enhance the quality of\ngenerated code. The proposed StructCoder model achieves state-of-the-art\nperformance on code translation and text-to-code generation tasks in the\nCodeXGLUE benchmark, and improves over baselines of similar size on the APPS\ncode generation benchmark. Our code is publicly available at\nhttps://github.com/reddy-lab-code-research/StructCoder/.\n",
                "链接": "https://arxiv.org/abs/2206.05239"
            },
            {
                "文章ID": "22325",
                "标题": "PAGER: Progressive Attribute-Guided Extendable Robust Image Generation",
                "作者": " Zohreh Azizi,  C. -C. Jay Kuo",
                "发布日期": "2022-08-24",
                "摘要": "  This work presents a generative modeling approach based on successive\nsubspace learning (SSL). Unlike most generative models in the literature, our\nmethod does not utilize neural networks to analyze the underlying source\ndistribution and synthesize images. The resulting method, called the\nprogressive attribute-guided extendable robust image generative (PAGER) model,\nhas advantages in mathematical transparency, progressive content generation,\nlower training time, robust performance with fewer training samples, and\nextendibility to conditional image generation. PAGER consists of three modules:\ncore generator, resolution enhancer, and quality booster. The core generator\nlearns the distribution of low-resolution images and performs unconditional\nimage generation. The resolution enhancer increases image resolution via\nconditional generation. Finally, the quality booster adds finer details to\ngenerated images. Extensive experiments on MNIST, Fashion-MNIST, and CelebA\ndatasets are conducted to demonstrate generative performance of PAGER.\n",
                "链接": "https://arxiv.org/abs/2206.00162"
            },
            {
                "文章ID": "110290",
                "标题": "Automatic Unit Test Data Generation and Actor-Critic Reinforcement\n  Learning for Code Synthesis",
                "作者": " Philip John Gorinski,  Matthieu Zimmer,  Gerasimos Lampouras,  Derrick Goh Xin Deik,  Ignacio Iacobacci",
                "发布日期": "2023-10-23",
                "摘要": "  The advent of large pre-trained language models in the domain of Code\nSynthesis has shown remarkable performance on various benchmarks, treating the\nproblem of Code Generation in a fashion similar to Natural Language Generation,\ntrained with a Language Modelling (LM) objective. In addition, the property of\nprogramming language code being precisely evaluable with respect to its\nsemantics -- through the use of Unit Tests to check its functional correctness\n-- lends itself to using Reinforcement Learning (RL) as a further training\nparadigm. Previous work has shown that RL can be applied as such to improve\nmodels' coding capabilities; however, such RL-based methods rely on a reward\nsignal based on defined Unit Tests, which are much harder to obtain compared to\nthe huge crawled code datasets used in LM objectives. In this work, we present\na novel approach to automatically obtain data consisting of function signatures\nand associated Unit Tests, suitable for RL training of Code Synthesis models.\nWe also introduce a straightforward, simple yet effective Actor-Critic RL\ntraining scheme and show that it, in conjunction with automatically generated\ntraining data, leads to improvement of a pre-trained code language model's\nperformance by up to 9.9% improvement over the original underlying code\nsynthesis LM, and up to 4.3% over RL-based models trained with standard PPO or\nCodeRL.\n",
                "链接": "https://arxiv.org/abs/2310.13669"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下关于大模型使用工具的安全性的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "120057",
                "标题": "A Survey on Large Language Model (LLM) Security and Privacy: The Good,\n  the Bad, and the Ugly",
                "作者": " Yifan Yao,  Jinhao Duan,  Kaidi Xu,  Yuanfang Cai,  Eric Sun,  Yue Zhang",
                "发布日期": "2023-12-05",
                "摘要": "  Large Language Models (LLMs), such as GPT-3 and BERT, have revolutionized\nnatural language understanding and generation. They possess deep language\ncomprehension, human-like text generation capabilities, contextual awareness,\nand robust problem-solving skills, making them invaluable in various domains\n(e.g., search engines, customer support, translation). In the meantime, LLMs\nhave also gained traction in the security community, revealing security\nvulnerabilities and showcasing their potential in security-related tasks. This\npaper explores the intersection of LLMs with security and privacy.\nSpecifically, we investigate how LLMs positively impact security and privacy,\npotential risks and threats associated with their use, and inherent\nvulnerabilities within LLMs. Through a comprehensive literature review, the\npaper categorizes findings into \"The Good\" (beneficial LLM applications), \"The\nBad\" (offensive applications), and \"The Ugly\" (vulnerabilities and their\ndefenses). We have some interesting findings. For example, LLMs have proven to\nenhance code and data security, outperforming traditional methods. However,\nthey can also be harnessed for various attacks (particularly user-level\nattacks) due to their human-like reasoning abilities. We have identified areas\nthat require further research efforts. For example, research on model and\nparameter extraction attacks is limited and often theoretical, hindered by LLM\nparameter scale and confidentiality. Safe instruction tuning, a recent\ndevelopment, requires more exploration. We hope that our work can shed light on\nthe LLMs' potential to both bolster and jeopardize cybersecurity.\n",
                "链接": "https://arxiv.org/abs/2312.02003"
            },
            {
                "文章ID": "50442",
                "标题": "Inverse Solvability and Security with Applications to Federated Learning",
                "作者": " Tomasz Piotrowski,  Matthias Frey,  Renato L. G. Cavalcante,  Rafail Ismayilov",
                "发布日期": "2023-06-27",
                "摘要": "  We introduce the concepts of inverse solvability and security for a generic\nlinear forward model and demonstrate how they can be applied to models used in\nfederated learning. We provide examples of such models which differ in the\nresulting inverse solvability and security as defined in this paper. We also\nshow how the large number of users participating in a given iteration of\nfederated learning can be leveraged to increase both solvability and security.\nFinally, we discuss possible extensions of the presented concepts including the\nnonlinear case.\n",
                "链接": "https://arxiv.org/abs/2211.14115"
            },
            {
                "文章ID": "109486",
                "标题": "Last One Standing: A Comparative Analysis of Security and Privacy of\n  Soft Prompt Tuning, LoRA, and In-Context Learning",
                "作者": " Rui Wen,  Tianhao Wang,  Michael Backes,  Yang Zhang,  Ahmed Salem",
                "发布日期": "2023-10-18",
                "摘要": "  Large Language Models (LLMs) are powerful tools for natural language\nprocessing, enabling novel applications and user experiences. However, to\nachieve optimal performance, LLMs often require adaptation with private data,\nwhich poses privacy and security challenges. Several techniques have been\nproposed to adapt LLMs with private data, such as Low-Rank Adaptation (LoRA),\nSoft Prompt Tuning (SPT), and In-Context Learning (ICL), but their comparative\nprivacy and security properties have not been systematically investigated. In\nthis work, we fill this gap by evaluating the robustness of LoRA, SPT, and ICL\nagainst three types of well-established attacks: membership inference, which\nexposes data leakage (privacy); backdoor, which injects malicious behavior\n(security); and model stealing, which can violate intellectual property\n(privacy and security). Our results show that there is no silver bullet for\nprivacy and security in LLM adaptation and each technique has different\nstrengths and weaknesses.\n",
                "链接": "https://arxiv.org/abs/2310.11397"
            },
            {
                "文章ID": "92590",
                "标题": "Security and Privacy Issues of Federated Learning",
                "作者": " Jahid Hasan",
                "发布日期": "2023-07-25",
                "摘要": "  Federated Learning (FL) has emerged as a promising approach to address data\nprivacy and confidentiality concerns by allowing multiple participants to\nconstruct a shared model without centralizing sensitive data. However, this\ndecentralized paradigm introduces new security challenges, necessitating a\ncomprehensive identification and classification of potential risks to ensure\nFL's security guarantees. This paper presents a comprehensive taxonomy of\nsecurity and privacy challenges in Federated Learning (FL) across various\nmachine learning models, including large language models. We specifically\ncategorize attacks performed by the aggregator and participants, focusing on\npoisoning attacks, backdoor attacks, membership inference attacks, generative\nadversarial network (GAN) based attacks, and differential privacy attacks.\nAdditionally, we propose new directions for future research, seeking innovative\nsolutions to fortify FL systems against emerging security risks and uphold\nsensitive data confidentiality in distributed learning environments.\n",
                "链接": "https://arxiv.org/abs/2307.12181"
            },
            {
                "文章ID": "107644",
                "标题": "A Semantic Invariant Robust Watermark for Large Language Models",
                "作者": " Aiwei Liu,  Leyi Pan,  Xuming Hu,  Shiao Meng,  Lijie Wen",
                "发布日期": "2023-10-11",
                "摘要": "  Watermark algorithms for large language models (LLMs) have achieved extremely\nhigh accuracy in detecting text generated by LLMs. Such algorithms typically\ninvolve adding extra watermark logits to the LLM's logits at each generation\nstep. However, prior algorithms face a trade-off between attack robustness and\nsecurity robustness. This is because the watermark logits for a token are\ndetermined by a certain number of preceding tokens; a small number leads to low\nsecurity robustness, while a large number results in insufficient attack\nrobustness. In this work, we propose a semantic invariant watermarking method\nfor LLMs that provides both attack robustness and security robustness. The\nwatermark logits in our work are determined by the semantics of all preceding\ntokens. Specifically, we utilize another embedding LLM to generate semantic\nembeddings for all preceding tokens, and then these semantic embeddings are\ntransformed into the watermark logits through our trained watermark model.\nSubsequent analyses and experiments demonstrated the attack robustness of our\nmethod in semantically invariant settings: synonym substitution and text\nparaphrasing settings. Finally, we also show that our watermark possesses\nadequate security robustness. Our code and data are available at\nhttps://github.com/THU-BPM/Robust_Watermark.\n",
                "链接": "https://arxiv.org/abs/2310.06356"
            },
            {
                "文章ID": "56590",
                "标题": "Chatbots in a Honeypot World",
                "作者": " Forrest McKee,  David Noever",
                "发布日期": "2023-01-11",
                "摘要": "  Question-and-answer agents like ChatGPT offer a novel tool for use as a\npotential honeypot interface in cyber security. By imitating Linux, Mac, and\nWindows terminal commands and providing an interface for TeamViewer, nmap, and\nping, it is possible to create a dynamic environment that can adapt to the\nactions of attackers and provide insight into their tactics, techniques, and\nprocedures (TTPs). The paper illustrates ten diverse tasks that a\nconversational agent or large language model might answer appropriately to the\neffects of command-line attacker. The original result features feasibility\nstudies for ten model tasks meant for defensive teams to mimic expected\nhoneypot interfaces with minimal risks. Ultimately, the usefulness outside of\nforensic activities stems from whether the dynamic honeypot can extend the\ntime-to-conquer or otherwise delay attacker timelines short of reaching key\nnetwork assets like databases or confidential information. While ongoing\nmaintenance and monitoring may be required, ChatGPT's ability to detect and\ndeflect malicious activity makes it a valuable option for organizations seeking\nto enhance their cyber security posture. Future work will focus on\ncybersecurity layers, including perimeter security, host virus detection, and\ndata security.\n",
                "链接": "https://arxiv.org/abs/2301.03771"
            },
            {
                "文章ID": "110132",
                "标题": "Anomaly Detection of Command Shell Sessions based on DistilBERT:\n  Unsupervised and Supervised Approaches",
                "作者": " Zefang Liu,  John Buford",
                "发布日期": "2023-10-23",
                "摘要": "  Anomaly detection in command shell sessions is a critical aspect of computer\nsecurity. Recent advances in deep learning and natural language processing,\nparticularly transformer-based models, have shown great promise for addressing\ncomplex security challenges. In this paper, we implement a comprehensive\napproach to detect anomalies in Unix shell sessions using a pretrained\nDistilBERT model, leveraging both unsupervised and supervised learning\ntechniques to identify anomalous activity while minimizing data labeling. The\nunsupervised method captures the underlying structure and syntax of Unix shell\ncommands, enabling the detection of session deviations from normal behavior.\nExperiments on a large-scale enterprise dataset collected from production\nsystems demonstrate the effectiveness of our approach in detecting anomalous\nbehavior in Unix shell sessions. This work highlights the potential of\nleveraging recent advances in transformers to address important computer\nsecurity challenges.\n",
                "链接": "https://arxiv.org/abs/2310.13247"
            },
            {
                "文章ID": "83602",
                "标题": "Building Resilient SMEs: Harnessing Large Language Models for Cyber\n  Security in Australia",
                "作者": " Benjamin Kereopa-Yorke",
                "发布日期": "2023-06-06",
                "摘要": "  The escalating digitalisation of our lives and enterprises has led to a\nparallel growth in the complexity and frequency of cyber-attacks. Small and\nmedium-sized enterprises (SMEs), particularly in Australia, are experiencing\nincreased vulnerability to cyber threats, posing a significant challenge to the\nnation's cyber security landscape. Embracing transformative technologies such\nas Artificial Intelligence (AI), Machine Learning (ML) and Large Language\nModels (LLMs) can potentially strengthen cyber security policies for Australian\nSMEs. However, their practical application, advantages, and limitations remain\nunderexplored, with prior research mainly focusing on large corporations. This\nstudy aims to address this gap by providing a comprehensive understanding of\nthe potential role of LLMs in enhancing cyber security policies for Australian\nSMEs. Employing a mixed-methods study design, this research includes a\nliterature review, qualitative analysis of SME case studies, and a quantitative\nassessment of LLM performance metrics in cyber security applications. The\nfindings highlight the promising potential of LLMs across various performance\ncriteria, including relevance, accuracy, and applicability, though gaps remain\nin areas such as completeness and clarity. The study underlines the importance\nof integrating human expertise with LLM technology and refining model\ndevelopment to address these limitations. By proposing a robust conceptual\nframework guiding the effective adoption of LLMs, this research aims to\ncontribute to a safer and more resilient cyber environment for Australian SMEs,\nenabling sustainable growth and competitiveness in the digital era.\n",
                "链接": "https://arxiv.org/abs/2306.02612"
            },
            {
                "文章ID": "116782",
                "标题": "A Security Risk Taxonomy for Large Language Models",
                "作者": " Erik Derner,  Kristina Batistič,  Jan Zahálka,  Robert Babuška",
                "发布日期": "2023-11-21",
                "摘要": "  As large language models (LLMs) permeate more and more applications, an\nassessment of their associated security risks becomes increasingly necessary.\nThe potential for exploitation by malicious actors, ranging from disinformation\nto data breaches and reputation damage, is substantial. This paper addresses a\ngap in current research by focusing on the security risks posed by LLMs, which\nextends beyond the widely covered ethical and societal implications. Our work\nproposes a taxonomy of security risks along the user-model communication\npipeline, explicitly focusing on prompt-based attacks on LLMs. We categorize\nthe attacks by target and attack type within a prompt-based interaction scheme.\nThe taxonomy is reinforced with specific attack examples to showcase the\nreal-world impact of these risks. Through this taxonomy, we aim to inform the\ndevelopment of robust and secure LLM applications, enhancing their safety and\ntrustworthiness.\n",
                "链接": "https://arxiv.org/abs/2311.11415"
            },
            {
                "文章ID": "81769",
                "标题": "A Survey on ChatGPT: AI-Generated Contents, Challenges, and Solutions",
                "作者": " Yuntao Wang,  Yanghe Pan,  Miao Yan,  Zhou Su,  Tom H. Luan",
                "发布日期": "2023-08-24",
                "摘要": "  With the widespread use of large artificial intelligence (AI) models such as\nChatGPT, AI-generated content (AIGC) has garnered increasing attention and is\nleading a paradigm shift in content creation and knowledge representation. AIGC\nuses generative large AI algorithms to assist or replace humans in creating\nmassive, high-quality, and human-like content at a faster pace and lower cost,\nbased on user-provided prompts. Despite the recent significant progress in\nAIGC, security, privacy, ethical, and legal challenges still need to be\naddressed. This paper presents an in-depth survey of working principles,\nsecurity and privacy threats, state-of-the-art solutions, and future challenges\nof the AIGC paradigm. Specifically, we first explore the enabling technologies,\ngeneral architecture of AIGC, and discuss its working modes and key\ncharacteristics. Then, we investigate the taxonomy of security and privacy\nthreats to AIGC and highlight the ethical and societal implications of GPT and\nAIGC technologies. Furthermore, we review the state-of-the-art AIGC\nwatermarking approaches for regulatable AIGC paradigms regarding the AIGC model\nand its produced content. Finally, we identify future challenges and open\nresearch directions related to AIGC.\n",
                "链接": "https://arxiv.org/abs/2305.18339"
            }
        ]
    },
    {
        "question": {
            "question": "请找到利用clip做开放词汇检测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "68353",
                "标题": "CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting\n  and Anchor Pre-Matching",
                "作者": " Xiaoshi Wu,  Feng Zhu,  Rui Zhao,  Hongsheng Li",
                "发布日期": "2023-03-24",
                "摘要": "  Open-vocabulary detection (OVD) is an object detection task aiming at\ndetecting objects from novel categories beyond the base categories on which the\ndetector is trained. Recent OVD methods rely on large-scale visual-language\npre-trained models, such as CLIP, for recognizing novel objects. We identify\nthe two core obstacles that need to be tackled when incorporating these models\ninto detector training: (1) the distribution mismatch that happens when\napplying a VL-model trained on whole images to region recognition tasks; (2)\nthe difficulty of localizing objects of unseen classes. To overcome these\nobstacles, we propose CORA, a DETR-style framework that adapts CLIP for\nOpen-vocabulary detection by Region prompting and Anchor pre-matching. Region\nprompting mitigates the whole-to-region distribution gap by prompting the\nregion features of the CLIP-based region classifier. Anchor pre-matching helps\nlearning generalizable object localization by a class-aware matching mechanism.\nWe evaluate CORA on the COCO OVD benchmark, where we achieve 41.7 AP50 on novel\nclasses, which outperforms the previous SOTA by 2.4 AP50 even without resorting\nto extra training data. When extra training data is available, we train\nCORA$^+$ on both ground-truth base-category annotations and additional pseudo\nbounding box labels computed by CORA. CORA$^+$ achieves 43.1 AP50 on the COCO\nOVD benchmark and 28.1 box APr on the LVIS OVD benchmark.\n",
                "链接": "https://arxiv.org/abs/2303.13076"
            },
            {
                "文章ID": "105778",
                "标题": "CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense\n  Prediction",
                "作者": " Size Wu,  Wenwei Zhang,  Lumin Xu,  Sheng Jin,  Xiangtai Li,  Wentao Liu,  Chen Change Loy",
                "发布日期": "2023-10-03",
                "摘要": "  Open-vocabulary dense prediction tasks including object detection and image\nsegmentation have been advanced by the success of Contrastive Language-Image\nPre-training (CLIP). CLIP models, particularly those incorporating vision\ntransformers (ViTs), have exhibited remarkable generalization ability in\nzero-shot image classification. However, when transferring the vision-language\nalignment of CLIP from global image representation to local region\nrepresentation for the open-vocabulary dense prediction tasks, CLIP ViTs suffer\nfrom the domain shift from full images to local image regions. In this paper,\nwe embark on an in-depth analysis of the region-language alignment in CLIP\nmodels, which is essential for downstream open-vocabulary dense prediction\ntasks. Subsequently, we propose an approach named CLIPSelf, which adapts the\nimage-level recognition ability of CLIP ViT to local image regions without\nneeding any region-text pairs. CLIPSelf empowers ViTs to distill itself by\naligning a region representation extracted from its dense feature map with the\nimage-level representation of the corresponding image crop. With the enhanced\nCLIP ViTs, we achieve new state-of-the-art performance on open-vocabulary\nobject detection, semantic segmentation, and panoptic segmentation across\nvarious benchmarks. Models and code will be available at\nhttps://github.com/wusize/CLIPSelf.\n",
                "链接": "https://arxiv.org/abs/2310.01403"
            },
            {
                "文章ID": "121784",
                "标题": "OpenSD: Unified Open-Vocabulary Segmentation and Detection",
                "作者": " Shuai Li,  Minghan Li,  Pengfei Wang,  Lei Zhang",
                "发布日期": "2023-12-13",
                "摘要": "  Recently, a few open-vocabulary methods have been proposed by employing a\nunified architecture to tackle generic segmentation and detection tasks.\nHowever, their performance still lags behind the task-specific models due to\nthe conflict between different tasks, and their open-vocabulary capability is\nlimited due to the inadequate use of CLIP. To address these challenges, we\npresent a universal transformer-based framework, abbreviated as OpenSD, which\nutilizes the same architecture and network parameters to handle open-vocabulary\nsegmentation and detection tasks. First, we introduce a decoder decoupled\nlearning strategy to alleviate the semantic conflict between thing and staff\ncategories so that each individual task can be learned more effectively under\nthe same framework. Second, to better leverage CLIP for end-to-end segmentation\nand detection, we propose dual classifiers to handle the in-vocabulary domain\nand out-of-vocabulary domain, respectively. The text encoder is further trained\nto be region-aware for both thing and stuff categories through decoupled prompt\nlearning, enabling them to filter out duplicated and low-quality predictions,\nwhich is important to end-to-end segmentation and detection. Extensive\nexperiments are conducted on multiple datasets under various circumstances. The\nresults demonstrate that OpenSD outperforms state-of-the-art open-vocabulary\nsegmentation and detection methods in both closed- and open-vocabulary\nsettings. Code is available at https://github.com/strongwolf/OpenSD\n",
                "链接": "https://arxiv.org/abs/2312.06703"
            },
            {
                "文章ID": "11160",
                "标题": "Open-Vocabulary DETR with Conditional Matching",
                "作者": " Yuhang Zang,  Wei Li,  Kaiyang Zhou,  Chen Huang,  Chen Change Loy",
                "发布日期": "2022-12-01",
                "摘要": "  Open-vocabulary object detection, which is concerned with the problem of\ndetecting novel objects guided by natural language, has gained increasing\nattention from the community. Ideally, we would like to extend an\nopen-vocabulary detector such that it can produce bounding box predictions\nbased on user inputs in form of either natural language or exemplar image. This\noffers great flexibility and user experience for human-computer interaction. To\nthis end, we propose a novel open-vocabulary detector based on DETR -- hence\nthe name OV-DETR -- which, once trained, can detect any object given its class\nname or an exemplar image. The biggest challenge of turning DETR into an\nopen-vocabulary detector is that it is impossible to calculate the\nclassification cost matrix of novel classes without access to their labeled\nimages. To overcome this challenge, we formulate the learning objective as a\nbinary matching one between input queries (class name or exemplar image) and\nthe corresponding objects, which learns useful correspondence to generalize to\nunseen queries during testing. For training, we choose to condition the\nTransformer decoder on the input embeddings obtained from a pre-trained\nvision-language model like CLIP, in order to enable matching for both text and\nimage queries. With extensive experiments on LVIS and COCO datasets, we\ndemonstrate that our OV-DETR -- the first end-to-end Transformer-based\nopen-vocabulary detector -- achieves non-trivial improvements over current\nstate of the arts.\n",
                "链接": "https://arxiv.org/abs/2203.11876"
            },
            {
                "文章ID": "68854",
                "标题": "Prompt-Guided Transformers for End-to-End Open-Vocabulary Object\n  Detection",
                "作者": " Hwanjun Song,  Jihwan Bang",
                "发布日期": "2023-03-28",
                "摘要": "  Prompt-OVD is an efficient and effective framework for open-vocabulary object\ndetection that utilizes class embeddings from CLIP as prompts, guiding the\nTransformer decoder to detect objects in both base and novel classes.\nAdditionally, our novel RoI-based masked attention and RoI pruning techniques\nhelp leverage the zero-shot classification ability of the Vision\nTransformer-based CLIP, resulting in improved detection performance at minimal\ncomputational cost. Our experiments on the OV-COCO and OVLVIS datasets\ndemonstrate that Prompt-OVD achieves an impressive 21.2 times faster inference\nspeed than the first end-to-end open-vocabulary detection method (OV-DETR),\nwhile also achieving higher APs than four two-stage-based methods operating\nwithin similar inference time ranges. Code will be made available soon.\n",
                "链接": "https://arxiv.org/abs/2303.14386"
            },
            {
                "文章ID": "70348",
                "标题": "Open-Vocabulary Point-Cloud Object Detection without 3D Annotation",
                "作者": " Yuheng Lu,  Chenfeng Xu,  Xiaobao Wei,  Xiaodong Xie,  Masayoshi Tomizuka,  Kurt Keutzer,  Shanghang Zhang",
                "发布日期": "2023-05-18",
                "摘要": "  The goal of open-vocabulary detection is to identify novel objects based on\narbitrary textual descriptions. In this paper, we address open-vocabulary 3D\npoint-cloud detection by a dividing-and-conquering strategy, which involves: 1)\ndeveloping a point-cloud detector that can learn a general representation for\nlocalizing various objects, and 2) connecting textual and point-cloud\nrepresentations to enable the detector to classify novel object categories\nbased on text prompting. Specifically, we resort to rich image pre-trained\nmodels, by which the point-cloud detector learns localizing objects under the\nsupervision of predicted 2D bounding boxes from 2D pre-trained detectors.\nMoreover, we propose a novel de-biased triplet cross-modal contrastive learning\nto connect the modalities of image, point-cloud and text, thereby enabling the\npoint-cloud detector to benefit from vision-language pre-trained\nmodels,i.e.,CLIP. The novel use of image and vision-language pre-trained models\nfor point-cloud detectors allows for open-vocabulary 3D object detection\nwithout the need for 3D annotations. Experiments demonstrate that the proposed\nmethod improves at least 3.03 points and 7.47 points over a wide range of\nbaselines on the ScanNet and SUN RGB-D datasets, respectively. Furthermore, we\nprovide a comprehensive analysis to explain why our approach works.\n",
                "链接": "https://arxiv.org/abs/2304.00788"
            },
            {
                "文章ID": "99749",
                "标题": "What Makes Good Open-Vocabulary Detector: A Disassembling Perspective",
                "作者": " Jincheng Li,  Chunyu Xie,  Xiaoyu Wu,  Bin Wang,  Dawei Leng",
                "发布日期": "2023-09-04",
                "摘要": "  Open-vocabulary detection (OVD) is a new object detection paradigm, aiming to\nlocalize and recognize unseen objects defined by an unbounded vocabulary. This\nis challenging since traditional detectors can only learn from pre-defined\ncategories and thus fail to detect and localize objects out of pre-defined\nvocabulary. To handle the challenge, OVD leverages pre-trained cross-modal VLM,\nsuch as CLIP, ALIGN, etc. Previous works mainly focus on the open vocabulary\nclassification part, with less attention on the localization part. We argue\nthat for a good OVD detector, both classification and localization should be\nparallelly studied for the novel object categories. We show in this work that\nimproving localization as well as cross-modal classification complement each\nother, and compose a good OVD detector jointly. We analyze three families of\nOVD methods with different design emphases. We first propose a vanilla\nmethod,i.e., cropping a bounding box obtained by a localizer and resizing it\ninto the CLIP. We next introduce another approach, which combines a standard\ntwo-stage object detector with CLIP. A two-stage object detector includes a\nvisual backbone, a region proposal network (RPN), and a region of interest\n(RoI) head. We decouple RPN and ROI head (DRR) and use RoIAlign to extract\nmeaningful features. In this case, it avoids resizing objects. To further\naccelerate the training time and reduce the model parameters, we couple RPN and\nROI head (CRR) as the third approach. We conduct extensive experiments on these\nthree types of approaches in different settings. On the OVD-COCO benchmark, DRR\nobtains the best performance and achieves 35.8 Novel AP$_{50}$, an absolute 2.8\ngain over the previous state-of-the-art (SOTA). For OVD-LVIS, DRR surpasses the\nprevious SOTA by 1.9 AP$_{50}$ in rare categories. We also provide an object\ndetection dataset called PID and provide a baseline on PID.\n",
                "链接": "https://arxiv.org/abs/2309.00227"
            },
            {
                "文章ID": "123157",
                "标题": "Simple Image-level Classification Improves Open-vocabulary Object\n  Detection",
                "作者": " Ruohuan Fang,  Guansong Pang,  Xiao Bai",
                "发布日期": "2023-12-20",
                "摘要": "  Open-Vocabulary Object Detection (OVOD) aims to detect novel objects beyond a\ngiven set of base categories on which the detection model is trained. Recent\nOVOD methods focus on adapting the image-level pre-trained vision-language\nmodels (VLMs), such as CLIP, to a region-level object detection task via, eg.,\nregion-level knowledge distillation, regional prompt learning, or region-text\npre-training, to expand the detection vocabulary. These methods have\ndemonstrated remarkable performance in recognizing regional visual concepts,\nbut they are weak in exploiting the VLMs' powerful global scene understanding\nability learned from the billion-scale image-level text descriptions. This\nlimits their capability in detecting hard objects of small, blurred, or\noccluded appearance from novel/base categories, whose detection heavily relies\non contextual information. To address this, we propose a novel approach, namely\nSimple Image-level Classification for Context-Aware Detection Scoring\n(SIC-CADS), to leverage the superior global knowledge yielded from CLIP for\ncomplementing the current OVOD models from a global perspective. The core of\nSIC-CADS is a multi-modal multi-label recognition (MLR) module that learns the\nobject co-occurrence-based contextual information from CLIP to recognize all\npossible object categories in the scene. These image-level MLR scores can then\nbe utilized to refine the instance-level detection scores of the current OVOD\nmodels in detecting those hard objects. This is verified by extensive empirical\nresults on two popular benchmarks, OV-LVIS and OV-COCO, which show that\nSIC-CADS achieves significant and consistent improvement when combined with\ndifferent types of OVOD models. Further, SIC-CADS also improves the\ncross-dataset generalization ability on Objects365 and OpenImages. The code is\navailable at https://github.com/mala-lab/SIC-CADS.\n",
                "链接": "https://arxiv.org/abs/2312.10439"
            },
            {
                "文章ID": "124461",
                "标题": "FM-OV3D: Foundation Model-based Cross-modal Knowledge Blending for\n  Open-Vocabulary 3D Detection",
                "作者": " Dongmei Zhang,  Chang Li,  Ray Zhang,  Shenghao Xie,  Wei Xue,  Xiaodong Xie,  Shanghang Zhang",
                "发布日期": "2023-12-25",
                "摘要": "  The superior performances of pre-trained foundation models in various visual\ntasks underscore their potential to enhance the 2D models' open-vocabulary\nability. Existing methods explore analogous applications in the 3D space.\nHowever, most of them only center around knowledge extraction from singular\nfoundation models, which limits the open-vocabulary ability of 3D models. We\nhypothesize that leveraging complementary pre-trained knowledge from various\nfoundation models can improve knowledge transfer from 2D pre-trained visual\nlanguage models to the 3D space. In this work, we propose FM-OV3D, a method of\nFoundation Model-based Cross-modal Knowledge Blending for Open-Vocabulary 3D\nDetection, which improves the open-vocabulary localization and recognition\nabilities of 3D model by blending knowledge from multiple pre-trained\nfoundation models, achieving true open-vocabulary without facing constraints\nfrom original 3D datasets. Specifically, to learn the open-vocabulary 3D\nlocalization ability, we adopt the open-vocabulary localization knowledge of\nthe Grounded-Segment-Anything model. For open-vocabulary 3D recognition\nability, We leverage the knowledge of generative foundation models, including\nGPT-3 and Stable Diffusion models, and cross-modal discriminative models like\nCLIP. The experimental results on two popular benchmarks for open-vocabulary 3D\nobject detection show that our model efficiently learns knowledge from multiple\nfoundation models to enhance the open-vocabulary ability of the 3D model and\nsuccessfully achieves state-of-the-art performance in open-vocabulary 3D object\ndetection tasks. Code is released at\nhttps://github.com/dmzhang0425/FM-OV3D.git.\n",
                "链接": "https://arxiv.org/abs/2312.14465"
            },
            {
                "文章ID": "123481",
                "标题": "CLIM: Contrastive Language-Image Mosaic for Region Representation",
                "作者": " Size Wu,  Wenwei Zhang,  Lumin Xu,  Sheng Jin,  Wentao Liu,  Chen Change Loy",
                "发布日期": "2023-12-20",
                "摘要": "  Detecting objects accurately from a large or open vocabulary necessitates the\nvision-language alignment on region representations. However, learning such a\nregion-text alignment by obtaining high-quality box annotations with text\nlabels or descriptions is expensive and infeasible. In contrast, collecting\nimage-text pairs is simpler but lacks precise object location information to\nassociate regions with texts. In this paper, we propose a novel approach called\nContrastive Language-Image Mosaic (CLIM), which leverages large-scale\nimage-text pairs effectively for aligning region and text representations. CLIM\ncombines multiple images into a mosaicked image and treats each image as a\n`pseudo region'. The feature of each pseudo region is extracted and trained to\nbe similar to the corresponding text embedding while dissimilar from others by\na contrastive loss, enabling the model to learn the region-text alignment\nwithout costly box annotations. As a generally applicable approach, CLIM\nconsistently improves different open-vocabulary object detection methods that\nuse caption supervision. Furthermore, CLIM can effectively enhance the region\nrepresentation of vision-language models, thus providing stronger backbones for\nopen-vocabulary object detectors. Our experimental results demonstrate that\nCLIM improves different baseline open-vocabulary object detectors by a large\nmargin on both OV-COCO and OV-LVIS benchmarks. The code is available at\nhttps://github.com/wusize/CLIM.\n",
                "链接": "https://arxiv.org/abs/2312.11376"
            }
        ]
    },
    {
        "question": {
            "question": "请找到使用自蒸馏加强目标检测性能的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "65588",
                "标题": "Smooth and Stepwise Self-Distillation for Object Detection",
                "作者": " Jieren Deng,  Xin Zhou,  Hao Tian,  Zhihong Pan,  Derek Aguiar",
                "发布日期": "2023-03-10",
                "摘要": "  Distilling the structured information captured in feature maps has\ncontributed to improved results for object detection tasks, but requires\ncareful selection of baseline architectures and substantial pre-training.\nSelf-distillation addresses these limitations and has recently achieved\nstate-of-the-art performance for object detection despite making several\nsimplifying architectural assumptions. Building on this work, we propose Smooth\nand Stepwise Self-Distillation (SSSD) for object detection. Our SSSD\narchitecture forms an implicit teacher from object labels and a feature pyramid\nnetwork backbone to distill label-annotated feature maps using Jensen-Shannon\ndistance, which is smoother than distillation losses used in prior work. We\nadditionally add a distillation coefficient that is adaptively configured based\non the learning rate. We extensively benchmark SSSD against a baseline and two\nstate-of-the-art object detector architectures on the COCO dataset by varying\nthe coefficients and backbone and detector networks. We demonstrate that SSSD\nachieves higher average precision in most experimental settings, is robust to a\nwide range of coefficients, and benefits from our stepwise distillation\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2303.05015"
            },
            {
                "文章ID": "92560",
                "标题": "Spatial Self-Distillation for Object Detection with Inaccurate Bounding\n  Boxes",
                "作者": " Di Wu,  Pengfei Chen,  Xuehui Yu,  Guorong Li,  Zhenjun Han,  Jianbin Jiao",
                "发布日期": "2023-08-16",
                "摘要": "  Object detection via inaccurate bounding boxes supervision has boosted a\nbroad interest due to the expensive high-quality annotation data or the\noccasional inevitability of low annotation quality (\\eg tiny objects). The\nprevious works usually utilize multiple instance learning (MIL), which highly\ndepends on category information, to select and refine a low-quality box. Those\nmethods suffer from object drift, group prediction and part domination problems\nwithout exploring spatial information. In this paper, we heuristically propose\na \\textbf{Spatial Self-Distillation based Object Detector (SSD-Det)} to mine\nspatial information to refine the inaccurate box in a self-distillation\nfashion. SSD-Det utilizes a Spatial Position Self-Distillation \\textbf{(SPSD)}\nmodule to exploit spatial information and an interactive structure to combine\nspatial information and category information, thus constructing a high-quality\nproposal bag. To further improve the selection procedure, a Spatial Identity\nSelf-Distillation \\textbf{(SISD)} module is introduced in SSD-Det to obtain\nspatial confidence to help select the best proposals. Experiments on MS-COCO\nand VOC datasets with noisy box annotation verify our method's effectiveness\nand achieve state-of-the-art performance. The code is available at\nhttps://github.com/ucas-vg/PointTinyBenchmark/tree/SSD-Det.\n",
                "链接": "https://arxiv.org/abs/2307.12101"
            },
            {
                "文章ID": "62692",
                "标题": "Self-improving object detection via disagreement reconciliation",
                "作者": " Gianluca Scarpellini,  Stefano Rosa,  Pietro Morerio,  Lorenzo Natale,  Alessio Del Bue",
                "发布日期": "2023-02-22",
                "摘要": "  Object detectors often experience a drop in performance when new\nenvironmental conditions are insufficiently represented in the training data.\nThis paper studies how to automatically fine-tune a pre-existing object\ndetector while exploring and acquiring images in a new environment without\nrelying on human intervention, i.e., in a self-supervised fashion. In our\nsetting, an agent initially explores the environment using a pre-trained\noff-the-shelf detector to locate objects and associate pseudo-labels. By\nassuming that pseudo-labels for the same object must be consistent across\ndifferent views, we devise a novel mechanism for producing refined predictions\nfrom the consensus among observations. Our approach improves the off-the-shelf\nobject detector by 2.66% in terms of mAP and outperforms the current state of\nthe art without relying on ground-truth annotations.\n",
                "链接": "https://arxiv.org/abs/2302.10624"
            },
            {
                "文章ID": "68022",
                "标题": "Efficient Feature Distillation for Zero-shot Annotation Object Detection",
                "作者": " Zhuoming Liu,  Xuefeng Hu,  Ram Nevatia",
                "发布日期": "2023-11-03",
                "摘要": "  We propose a new setting for detecting unseen objects called Zero-shot\nAnnotation object Detection (ZAD). It expands the zero-shot object detection\nsetting by allowing the novel objects to exist in the training images and\nrestricts the additional information the detector uses to novel category names.\nRecently, to detect unseen objects, large-scale vision-language models (e.g.,\nCLIP) are leveraged by different methods. The distillation-based methods have\ngood overall performance but suffer from a long training schedule caused by two\nfactors. First, existing work creates distillation regions biased to the base\ncategories, which limits the distillation of novel category information.\nSecond, directly using the raw feature from CLIP for distillation neglects the\ndomain gap between the training data of CLIP and the detection datasets, which\nmakes it difficult to learn the mapping from the image region to the\nvision-language feature space. To solve these problems, we propose Efficient\nfeature distillation for Zero-shot Annotation object Detection (EZAD). Firstly,\nEZAD adapts the CLIP's feature space to the target detection domain by\nre-normalizing CLIP; Secondly, EZAD uses CLIP to generate distillation\nproposals with potential novel category names to avoid the distillation being\noverly biased toward the base categories. Finally, EZAD takes advantage of\nsemantic meaning for regression to further improve the model performance. As a\nresult, EZAD outperforms the previous distillation-based methods in COCO by 4%\nwith a much shorter training schedule and achieves a 3% improvement on the LVIS\ndataset. Our code is available at https://github.com/dragonlzm/EZAD\n",
                "链接": "https://arxiv.org/abs/2303.12145"
            },
            {
                "文章ID": "6788",
                "标题": "Self-Supervised Transformers for Unsupervised Object Discovery using\n  Normalized Cut",
                "作者": "M-PSI  Yangtao Wang, LIGM  Xi Shen, MIT CSAIL  Shell Hu, MIT CSAIL  Yuan Yuan, M-PSI  James Crowley, M-PSI  Dominique Vaufreydaz",
                "发布日期": "2022-03-25",
                "摘要": "  Transformers trained with self-supervised learning using self-distillation\nloss (DINO) have been shown to produce attention maps that highlight salient\nforeground objects. In this paper, we demonstrate a graph-based approach that\nuses the self-supervised transformer features to discover an object from an\nimage. Visual tokens are viewed as nodes in a weighted graph with edges\nrepresenting a connectivity score based on the similarity of tokens. Foreground\nobjects can then be segmented using a normalized graph-cut to group\nself-similar regions. We solve the graph-cut problem using spectral clustering\nwith generalized eigen-decomposition and show that the second smallest\neigenvector provides a cutting solution since its absolute value indicates the\nlikelihood that a token belongs to a foreground object. Despite its simplicity,\nthis approach significantly boosts the performance of unsupervised object\ndiscovery: we improve over the recent state of the art LOST by a margin of\n6.9%, 8.1%, and 8.1% respectively on the VOC07, VOC12, and COCO20K. The\nperformance can be further improved by adding a second stage class-agnostic\ndetector (CAD). Our proposed method can be easily extended to unsupervised\nsaliency detection and weakly supervised object detection. For unsupervised\nsaliency detection, we improve IoU for 4.9%, 5.2%, 12.9% on ECSSD, DUTS,\nDUT-OMRON respectively compared to previous state of the art. For weakly\nsupervised object detection, we achieve competitive performance on CUB and\nImageNet.\n",
                "链接": "https://arxiv.org/abs/2202.11539"
            },
            {
                "文章ID": "122446",
                "标题": "A Simple Knowledge Distillation Framework for Open-world Object\n  Detection",
                "作者": " Shuailei Ma,  Yuefeng Wang,  Ying Wei,  Jiaqi Fan,  Xinyu Sun,  Peihao Chen,  Enming Zhang",
                "发布日期": "2023-12-15",
                "摘要": "  Open World Object Detection (OWOD) is a novel computer vision task with a\nconsiderable challenge, bridging the gap between classic object detection (OD)\nbenchmarks and real-world object detection. In addition to detecting and\nclassifying seen/known objects, OWOD algorithms are expected to localize all\npotential unseen/unknown objects and incrementally learn them. The large\npre-trained vision-language grounding models (VLM,eg, GLIP) have rich knowledge\nabout the open world, but are limited by text prompts and cannot localize\nindescribable objects. However, there are many detection scenarios which\npre-defined language descriptions are unavailable during inference. In this\npaper, we attempt to specialize the VLM model for OWOD task by distilling its\nopen-world knowledge into a language-agnostic detector. Surprisingly, we\nobserve that the combination of a simple knowledge distillation approach and\nthe automatic pseudo-labeling mechanism in OWOD can achieve better performance\nfor unknown object detection, even with a small amount of data. Unfortunately,\nknowledge distillation for unknown objects severely affects the learning of\ndetectors with conventional structures for known objects, leading to\ncatastrophic forgetting. To alleviate these problems, we propose the\ndown-weight loss function for knowledge distillation from vision-language to\nsingle vision modality. Meanwhile, we decouple the learning of localization and\nrecognition to reduce the impact of category interactions of known and unknown\nobjects on the localization learning process. Comprehensive experiments\nperformed on MS-COCO and PASCAL VOC demonstrate the effectiveness of our\nmethods.\n",
                "链接": "https://arxiv.org/abs/2312.08653"
            },
            {
                "文章ID": "14912",
                "标题": "Spatial Likelihood Voting with Self-Knowledge Distillation for Weakly\n  Supervised Object Detection",
                "作者": " Ze Chen,  Zhihang Fu,  Jianqiang Huang,  Mingyuan Tao,  Rongxin Jiang,  Xiang Tian,  Yaowu Chen,  Xian-sheng Hua",
                "发布日期": "2022-04-15",
                "摘要": "  Weakly supervised object detection (WSOD), which is an effective way to train\nan object detection model using only image-level annotations, has attracted\nconsiderable attention from researchers. However, most of the existing methods,\nwhich are based on multiple instance learning (MIL), tend to localize instances\nto the discriminative parts of salient objects instead of the entire content of\nall objects. In this paper, we propose a WSOD framework called the Spatial\nLikelihood Voting with Self-knowledge Distillation Network (SLV-SD Net). In\nthis framework, we introduce a spatial likelihood voting (SLV) module to\nconverge region proposal localization without bounding box annotations.\nSpecifically, in every iteration during training, all the region proposals in a\ngiven image act as voters voting for the likelihood of each category in the\nspatial dimensions. After dilating the alignment on the area with large\nlikelihood values, the voting results are regularized as bounding boxes, which\nare then used for the final classification and localization. Based on SLV, we\nfurther propose a self-knowledge distillation (SD) module to refine the feature\nrepresentations of the given image. The likelihood maps generated by the SLV\nmodule are used to supervise the feature learning of the backbone network,\nencouraging the network to attend to wider and more diverse areas of the image.\nExtensive experiments on the PASCAL VOC 2007/2012 and MS-COCO datasets\ndemonstrate the excellent performance of SLV-SD Net. In addition, SLV-SD Net\nproduces new state-of-the-art results on these benchmarks.\n",
                "链接": "https://arxiv.org/abs/2204.06899"
            },
            {
                "文章ID": "25538",
                "标题": "Knowledge Distillation for Oriented Object Detection on Aerial Images",
                "作者": " Yicheng Xiao,  Junpeng Zhang",
                "发布日期": "2022-06-22",
                "摘要": "  Deep convolutional neural network with increased number of parameters has\nachieved improved precision in task of object detection on natural images,\nwhere objects of interests are annotated with horizontal boundary boxes. On\naerial images captured from the bird-view perspective, these improvements on\nmodel architecture and deeper convolutional layers can also boost the\nperformance on oriented object detection task. However, it is hard to directly\napply those state-of-the-art object detectors on the devices with limited\ncomputation resources, which necessitates lightweight models through model\ncompression. In order to address this issue, we present a model compression\nmethod for rotated object detection on aerial images by knowledge distillation,\nnamely KD-RNet. With a well-trained teacher oriented object detector with a\nlarge number of parameters, the obtained object category and location\ninformation are both transferred to a compact student network in KD-RNet by\ncollaborative training strategy. Transferring the category information is\nachieved by knowledge distillation on predicted probability distribution, and a\nsoft regression loss is adopted for handling displacement in location\ninformation transfer. The experimental result on a large-scale aerial object\ndetection dataset (DOTA) demonstrates that the proposed KD-RNet model can\nachieve improved mean-average precision (mAP) with reduced number of\nparameters, at the same time, KD-RNet boost the performance on providing high\nquality detections with higher overlap with groundtruth annotations.\n",
                "链接": "https://arxiv.org/abs/2206.09796"
            },
            {
                "文章ID": "17577",
                "标题": "Cross Domain Object Detection by Target-Perceived Dual Branch\n  Distillation",
                "作者": " Mengzhe He,  Yali Wang,  Jiaxi Wu,  Yiru Wang,  Hanqing Li,  Bo Li,  Weihao Gan,  Wei Wu,  Yu Qiao",
                "发布日期": "2022-05-04",
                "摘要": "  Cross domain object detection is a realistic and challenging task in the\nwild. It suffers from performance degradation due to large shift of data\ndistributions and lack of instance-level annotations in the target domain.\nExisting approaches mainly focus on either of these two difficulties, even\nthough they are closely coupled in cross domain object detection. To solve this\nproblem, we propose a novel Target-perceived Dual-branch Distillation (TDD)\nframework. By integrating detection branches of both source and target domains\nin a unified teacher-student learning scheme, it can reduce domain shift and\ngenerate reliable supervision effectively. In particular, we first introduce a\ndistinct Target Proposal Perceiver between two domains. It can adaptively\nenhance source detector to perceive objects in a target image, by leveraging\ntarget proposal contexts from iterative cross-attention. Afterwards, we design\na concise Dual Branch Self Distillation strategy for model training, which can\nprogressively integrate complementary object knowledge from different domains\nvia self-distillation in two branches. Finally, we conduct extensive\nexperiments on a number of widely-used scenarios in cross domain object\ndetection. The results show that our TDD significantly outperforms the\nstate-of-the-art methods on all the benchmarks. Our code and model will be\navailable at https://github.com/Feobi1999/TDD.\n",
                "链接": "https://arxiv.org/abs/2205.01291"
            },
            {
                "文章ID": "114760",
                "标题": "Object-centric Cross-modal Feature Distillation for Event-based Object\n  Detection",
                "作者": " Lei Li,  Alexander Liniger,  Mario Millhaeusler,  Vagia Tsiminaki,  Yuanyou Li,  Dengxin Dai",
                "发布日期": "2023-11-10",
                "摘要": "  Event cameras are gaining popularity due to their unique properties, such as\ntheir low latency and high dynamic range. One task where these benefits can be\ncrucial is real-time object detection. However, RGB detectors still outperform\nevent-based detectors due to the sparsity of the event data and missing visual\ndetails. In this paper, we develop a novel knowledge distillation approach to\nshrink the performance gap between these two modalities. To this end, we\npropose a cross-modality object detection distillation method that by design\ncan focus on regions where the knowledge distillation works best. We achieve\nthis by using an object-centric slot attention mechanism that can iteratively\ndecouple features maps into object-centric features and corresponding\npixel-features used for distillation. We evaluate our novel distillation\napproach on a synthetic and a real event dataset with aligned grayscale images\nas a teacher modality. We show that object-centric distillation allows to\nsignificantly improve the performance of the event-based student object\ndetector, nearly halving the performance gap with respect to the teacher.\n",
                "链接": "https://arxiv.org/abs/2311.05494"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用2020年以后CONLL 2004数据集进行NER评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "54351",
                "标题": "Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?",
                "作者": " Shuheng Liu,  Alan Ritter",
                "发布日期": "2023-07-13",
                "摘要": "  The CoNLL-2003 English named entity recognition (NER) dataset has been widely\nused to train and evaluate NER models for almost 20 years. However, it is\nunclear how well models that are trained on this 20-year-old data and developed\nover a period of decades using the same test set will perform when applied on\nmodern data. In this paper, we evaluate the generalization of over 20 different\nmodels trained on CoNLL-2003, and show that NER models have very different\ngeneralization. Surprisingly, we find no evidence of performance degradation in\npre-trained Transformers, such as RoBERTa and T5, even when fine-tuned using\ndecades-old data. We investigate why some models generalize well to new data\nwhile others do not, and attempt to disentangle the effects of temporal drift\nand overfitting due to test reuse. Our analysis suggests that most\ndeterioration is due to temporal mismatch between the pre-training corpora and\nthe downstream test sets. We found that four factors are important for good\ngeneralization: model architecture, number of parameters, time period of the\npre-training corpus, in addition to the amount of fine-tuning data. We suggest\ncurrent evaluation methods have, in some sense, underestimated progress on NER\nover the past 20 years, as NER models have not only improved on the original\nCoNLL-2003 test set, but improved even more on modern data. Our datasets can be\nfound at https://github.com/ShuhengL/acl2023_conllpp.\n",
                "链接": "https://arxiv.org/abs/2212.09747"
            },
            {
                "文章ID": "50504",
                "标题": "Finetuning BERT on Partially Annotated NER Corpora",
                "作者": " Viktor Scherbakov,  Vladimir Mayorov",
                "发布日期": "2022-11-29",
                "摘要": "  Most Named Entity Recognition (NER) models operate under the assumption that\ntraining datasets are fully labelled. While it is valid for established\ndatasets like CoNLL 2003 and OntoNotes, sometimes it is not feasible to obtain\nthe complete dataset annotation. These situations may occur, for instance,\nafter selective annotation of entities for cost reduction. This work presents\nan approach to finetuning BERT on such partially labelled datasets using\nself-supervision and label preprocessing. Our approach outperforms the previous\nLSTM-based label preprocessing baseline, significantly improving the\nperformance on poorly labelled datasets. We demonstrate that following our\napproach while finetuning RoBERTa on CoNLL 2003 dataset with only 10% of total\nentities labelled is enough to reach the performance of the baseline trained on\nthe same dataset with 50% of the entities labelled.\n",
                "链接": "https://arxiv.org/abs/2211.14360"
            },
            {
                "文章ID": "46217",
                "标题": "Recognizing Nested Entities from Flat Supervision: A New NER Subtask,\n  Feasibility and Challenges",
                "作者": " Enwei Zhu,  Yiyang Liu,  Ming Jin,  Jinpeng Li",
                "发布日期": "2022-11-02",
                "摘要": "  Many recent named entity recognition (NER) studies criticize flat NER for its\nnon-overlapping assumption, and switch to investigating nested NER. However,\nexisting nested NER models heavily rely on training data annotated with nested\nentities, while labeling such data is costly. This study proposes a new\nsubtask, nested-from-flat NER, which corresponds to a realistic application\nscenario: given data annotated with flat entities only, one may still desire\nthe trained model capable of recognizing nested entities. To address this task,\nwe train span-based models and deliberately ignore the spans nested inside\nlabeled entities, since these spans are possibly unlabeled entities. With\nnested entities removed from the training data, our model achieves 54.8%, 54.2%\nand 41.1% F1 scores on the subset of spans within entities on ACE 2004, ACE\n2005 and GENIA, respectively. This suggests the effectiveness of our approach\nand the feasibility of the task. In addition, the model's performance on flat\nentities is entirely unaffected. We further manually annotate the nested\nentities in the test set of CoNLL 2003, creating a nested-from-flat NER\nbenchmark. Analysis results show that the main challenges stem from the data\nand annotation inconsistencies between the flat and nested entities.\n",
                "链接": "https://arxiv.org/abs/2211.00301"
            },
            {
                "文章ID": "39331",
                "标题": "mRobust04: A Multilingual Version of the TREC Robust 2004 Benchmark",
                "作者": " Vitor Jeronymo,  Mauricio Nascimento,  Roberto Lotufo,  Rodrigo Nogueira",
                "发布日期": "2022-09-29",
                "摘要": "  Robust 2004 is an information retrieval benchmark whose large number of\njudgments per query make it a reliable evaluation dataset. In this paper, we\npresent mRobust04, a multilingual version of Robust04 that was translated to 8\nlanguages using Google Translate. We also provide results of three different\nmultilingual retrievers on this dataset. The dataset is available at\nhttps://huggingface.co/datasets/unicamp-dl/mrobust\n",
                "链接": "https://arxiv.org/abs/2209.13738"
            },
            {
                "文章ID": "111254",
                "标题": "CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset",
                "作者": " Susanna Rücker,  Alan Akbik",
                "发布日期": "2023-10-26",
                "摘要": "  The CoNLL-03 corpus is arguably the most well-known and utilized benchmark\ndataset for named entity recognition (NER). However, prior works found\nsignificant numbers of annotation errors, incompleteness, and inconsistencies\nin the data. This poses challenges to objectively comparing NER approaches and\nanalyzing their errors, as current state-of-the-art models achieve F1-scores\nthat are comparable to or even exceed the estimated noise level in CoNLL-03. To\naddress this issue, we present a comprehensive relabeling effort assisted by\nautomatic consistency checking that corrects 7.0% of all labels in the English\nCoNLL-03. Our effort adds a layer of entity linking annotation both for better\nexplainability of NER labels and as additional safeguard of annotation quality.\nOur experimental evaluation finds not only that state-of-the-art approaches\nreach significantly higher F1-scores (97.1%) on our data, but crucially that\nthe share of correct predictions falsely counted as errors due to annotation\nnoise drops from 47% to 6%. This indicates that our resource is well suited to\nanalyze the remaining errors made by state-of-the-art models, and that the\ntheoretical upper bound even on high resource, coarse-grained NER is not yet\nreached. To facilitate such analysis, we make CleanCoNLL publicly available to\nthe research community.\n",
                "链接": "https://arxiv.org/abs/2310.16225"
            },
            {
                "文章ID": "19232",
                "标题": "The VoicePrivacy 2020 Challenge Evaluation Plan",
                "作者": " Natalia Tomashenko,  Brij Mohan Lal Srivastava,  Xin Wang,  Emmanuel Vincent,  Andreas Nautsch,  Junichi Yamagishi,  Nicholas Evans,  Jose Patino,  Jean-François Bonastre,  Paul-Gauthier Noé,  Massimiliano Todisco",
                "发布日期": "2022-05-17",
                "摘要": "  The VoicePrivacy Challenge aims to promote the development of privacy\npreservation tools for speech technology by gathering a new community to define\nthe tasks of interest and the evaluation methodology, and benchmarking\nsolutions through a series of challenges. In this document, we formulate the\nvoice anonymization task selected for the VoicePrivacy 2020 Challenge and\ndescribe the datasets used for system development and evaluation. We also\npresent the attack models and the associated objective and subjective\nevaluation metrics. We introduce two anonymization baselines and report\nobjective evaluation results.\n",
                "链接": "https://arxiv.org/abs/2205.07123"
            },
            {
                "文章ID": "82089",
                "标题": "A Multilingual Evaluation of NER Robustness to Adversarial Inputs",
                "作者": " Akshay Srinivasan,  Sowmya Vajjala",
                "发布日期": "2023-05-31",
                "摘要": "  Adversarial evaluations of language models typically focus on English alone.\nIn this paper, we performed a multilingual evaluation of Named Entity\nRecognition (NER) in terms of its robustness to small perturbations in the\ninput. Our results showed the NER models we explored across three languages\n(English, German and Hindi) are not very robust to such changes, as indicated\nby the fluctuations in the overall F1 score as well as in a more fine-grained\nevaluation. With that knowledge, we further explored whether it is possible to\nimprove the existing NER models using a part of the generated adversarial data\nsets as augmented training data to train a new NER model or as fine-tuning data\nto adapt an existing NER model. Our results showed that both these approaches\nimprove performance on the original as well as adversarial test sets. While\nthere is no significant difference between the two approaches for English,\nre-training is significantly better than fine-tuning for German and Hindi.\n",
                "链接": "https://arxiv.org/abs/2305.18933"
            },
            {
                "文章ID": "17226",
                "标题": "What do we Really Know about State of the Art NER?",
                "作者": " Sowmya Vajjala,  Ramya Balasubramaniam",
                "发布日期": "2022-05-05",
                "摘要": "  Named Entity Recognition (NER) is a well researched NLP task and is widely\nused in real world NLP scenarios. NER research typically focuses on the\ncreation of new ways of training NER, with relatively less emphasis on\nresources and evaluation. Further, state of the art (SOTA) NER models, trained\non standard datasets, typically report only a single performance measure\n(F-score) and we don't really know how well they do for different entity types\nand genres of text, or how robust are they to new, unseen entities. In this\npaper, we perform a broad evaluation of NER using a popular dataset, that takes\ninto consideration various text genres and sources constituting the dataset at\nhand. Additionally, we generate six new adversarial test sets through small\nperturbations in the original test set, replacing select entities while\nretaining the context. We also train and test our models on randomly generated\ntrain/dev/test splits followed by an experiment where the models are trained on\na select set of genres but tested genres not seen in training. These\ncomprehensive evaluation strategies were performed using three SOTA NER models.\nBased on our results, we recommend some useful reporting practices for NER\nresearchers, that could help in providing a better understanding of a SOTA\nmodel's performance in future.\n",
                "链接": "https://arxiv.org/abs/2205.00034"
            },
            {
                "文章ID": "54218",
                "标题": "E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text",
                "作者": " Ting Wai Terence Au,  Ingemar J. Cox,  Vasileios Lampos",
                "发布日期": "2022-12-20",
                "摘要": "  Identifying named entities such as a person, location or organization, in\ndocuments can highlight key information to readers. Training Named Entity\nRecognition (NER) models requires an annotated data set, which can be a\ntime-consuming labour-intensive task. Nevertheless, there are publicly\navailable NER data sets for general English. Recently there has been interest\nin developing NER for legal text. However, prior work and experimental results\nreported here indicate that there is a significant degradation in performance\nwhen NER methods trained on a general English data set are applied to legal\ntext. We describe a publicly available legal NER data set, called E-NER, based\non legal company filings available from the US Securities and Exchange\nCommission's EDGAR data set. Training a number of different NER algorithms on\nthe general English CoNLL-2003 corpus but testing on our test collection\nconfirmed significant degradations in accuracy, as measured by the F1-score, of\nbetween 29.4\\% and 60.4\\%, compared to training and testing on the E-NER\ncollection.\n",
                "链接": "https://arxiv.org/abs/2212.09306"
            },
            {
                "文章ID": "18896",
                "标题": "NER-MQMRC: Formulating Named Entity Recognition as Multi Question\n  Machine Reading Comprehension",
                "作者": " Anubhav Shrimal,  Avi Jain,  Kartik Mehta,  Promod Yenigalla",
                "发布日期": "2022-05-13",
                "摘要": "  NER has been traditionally formulated as a sequence labeling task. However,\nthere has been recent trend in posing NER as a machine reading comprehension\ntask (Wang et al., 2020; Mengge et al., 2020), where entity name (or other\ninformation) is considered as a question, text as the context and entity value\nin text as answer snippet. These works consider MRC based on a single question\n(entity) at a time. We propose posing NER as a multi-question MRC task, where\nmultiple questions (one question per entity) are considered at the same time\nfor a single text. We propose a novel BERT-based multi-question MRC (NER-MQMRC)\narchitecture for this formulation. NER-MQMRC architecture considers all\nentities as input to BERT for learning token embeddings with self-attention and\nleverages BERT-based entity representation for further improving these token\nembeddings for NER task. Evaluation on three NER datasets show that our\nproposed architecture leads to average 2.5 times faster training and 2.3 times\nfaster inference as compared to NER-SQMRC framework based models by considering\nall entities together in a single pass. Further, we show that our model\nperformance does not degrade compared to single-question based MRC (NER-SQMRC)\n(Devlin et al., 2019) leading to F1 gain of +0.41%, +0.32% and +0.27% for\nAE-Pub, Ecommerce5PT and Twitter datasets respectively. We propose this\narchitecture primarily to solve large scale e-commerce attribute (or entity)\nextraction from unstructured text of a magnitude of 50k+ attributes to be\nextracted on a scalable production environment with high performance and\noptimised training and inference runtimes.\n",
                "链接": "https://arxiv.org/abs/2205.05904"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用CrossWoz或MultiWoz数据集进行DST评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "13878",
                "标题": "Towards Fair Evaluation of Dialogue State Tracking by Flexible\n  Incorporation of Turn-level Performances",
                "作者": " Suvodip Dey,  Ramamohan Kummara,  Maunendra Sankar Desarkar",
                "发布日期": "2022-04-08",
                "摘要": "  Dialogue State Tracking (DST) is primarily evaluated using Joint Goal\nAccuracy (JGA) defined as the fraction of turns where the ground-truth dialogue\nstate exactly matches the prediction. Generally in DST, the dialogue state or\nbelief state for a given turn contains all the intents shown by the user till\nthat turn. Due to this cumulative nature of the belief state, it is difficult\nto get a correct prediction once a misprediction has occurred. Thus, although\nbeing a useful metric, it can be harsh at times and underestimate the true\npotential of a DST model. Moreover, an improvement in JGA can sometimes\ndecrease the performance of turn-level or non-cumulative belief state\nprediction due to inconsistency in annotations. So, using JGA as the only\nmetric for model selection may not be ideal for all scenarios. In this work, we\ndiscuss various evaluation metrics used for DST along with their shortcomings.\nTo address the existing issues, we propose a new evaluation metric named\nFlexible Goal Accuracy (FGA). FGA is a generalized version of JGA. But unlike\nJGA, it tries to give penalized rewards to mispredictions that are locally\ncorrect i.e. the root cause of the error is an earlier turn. By doing so, FGA\nconsiders the performance of both cumulative and turn-level prediction flexibly\nand provides a better insight than the existing metrics. We also show that FGA\nis a better discriminator of DST model performance.\n",
                "链接": "https://arxiv.org/abs/2204.03375"
            },
            {
                "文章ID": "27448",
                "标题": "A Multi-Task BERT Model for Schema-Guided Dialogue State Tracking",
                "作者": " Eleftherios Kapelonis,  Efthymios Georgiou,  Alexandros Potamianos",
                "发布日期": "2022-07-05",
                "摘要": "  Task-oriented dialogue systems often employ a Dialogue State Tracker (DST) to\nsuccessfully complete conversations. Recent state-of-the-art DST\nimplementations rely on schemata of diverse services to improve model\nrobustness and handle zero-shot generalization to new domains [1], however such\nmethods [2, 3] typically require multiple large scale transformer models and\nlong input sequences to perform well. We propose a single multi-task BERT-based\nmodel that jointly solves the three DST tasks of intent prediction, requested\nslot prediction and slot filling. Moreover, we propose an efficient and\nparsimonious encoding of the dialogue history and service schemata that is\nshown to further improve performance. Evaluation on the SGD dataset shows that\nour approach outperforms the baseline SGP-DST by a large margin and performs\nwell compared to the state-of-the-art, while being significantly more\ncomputationally efficient. Extensive ablation studies are performed to examine\nthe contributing factors to the success of our model.\n",
                "链接": "https://arxiv.org/abs/2207.00828"
            },
            {
                "文章ID": "120022",
                "标题": "Exploring the Viability of Synthetic Audio Data for Audio-Based Dialogue\n  State Tracking",
                "作者": " Jihyun Lee,  Yejin Jeon,  Wonjun Lee,  Yunsu Kim,  Gary Geunbae Lee",
                "发布日期": "2023-12-05",
                "摘要": "  Dialogue state tracking plays a crucial role in extracting information in\ntask-oriented dialogue systems. However, preceding research are limited to\ntextual modalities, primarily due to the shortage of authentic human audio\ndatasets. We address this by investigating synthetic audio data for audio-based\nDST. To this end, we develop cascading and end-to-end models, train them with\nour synthetic audio dataset, and test them on actual human speech data. To\nfacilitate evaluation tailored to audio modalities, we introduce a novel\nPhonemeF1 to capture pronunciation similarity. Experimental results showed that\nmodels trained solely on synthetic datasets can generalize their performance to\nhuman voice data. By eliminating the dependency on human speech data\ncollection, these insights pave the way for significant practical advancements\nin audio-based DST. Data and code are available at\nhttps://github.com/JihyunLee1/E2E-DST.\n",
                "链接": "https://arxiv.org/abs/2312.01842"
            },
            {
                "文章ID": "8498",
                "标题": "Mismatch between Multi-turn Dialogue and its Evaluation Metric in\n  Dialogue State Tracking",
                "作者": " Takyoung Kim,  Hoonsang Yoon,  Yukyung Lee,  Pilsung Kang,  Misuk Kim",
                "发布日期": "2022-04-01",
                "摘要": "  Dialogue state tracking (DST) aims to extract essential information from\nmulti-turn dialogue situations and take appropriate actions. A belief state,\none of the core pieces of information, refers to the subject and its specific\ncontent, and appears in the form of domain-slot-value. The trained model\npredicts \"accumulated\" belief states in every turn, and joint goal accuracy and\nslot accuracy are mainly used to evaluate the prediction; however, we specify\nthat the current evaluation metrics have a critical limitation when evaluating\nbelief states accumulated as the dialogue proceeds, especially in the most used\nMultiWOZ dataset. Additionally, we propose relative slot accuracy to complement\nexisting metrics. Relative slot accuracy does not depend on the number of\npredefined slots, and allows intuitive evaluation by assigning relative scores\naccording to the turn of each dialogue. This study also encourages not solely\nthe reporting of joint goal accuracy, but also various complementary metrics in\nDST tasks for the sake of a realistic evaluation.\n",
                "链接": "https://arxiv.org/abs/2203.03123"
            },
            {
                "文章ID": "110799",
                "标题": "Towards LLM-driven Dialogue State Tracking",
                "作者": " Yujie Feng,  Zexin Lu,  Bo Liu,  Liming Zhan,  Xiao-Ming Wu",
                "发布日期": "2023-10-24",
                "摘要": "  Dialogue State Tracking (DST) is of paramount importance in ensuring accurate\ntracking of user goals and system actions within task-oriented dialogue\nsystems. The emergence of large language models (LLMs) such as GPT3 and ChatGPT\nhas sparked considerable interest in assessing their efficacy across diverse\napplications. In this study, we conduct an initial examination of ChatGPT's\ncapabilities in DST. Our evaluation uncovers the exceptional performance of\nChatGPT in this task, offering valuable insights to researchers regarding its\ncapabilities and providing useful directions for designing and enhancing\ndialogue systems. Despite its impressive performance, ChatGPT has significant\nlimitations including its closed-source nature, request restrictions, raising\ndata privacy concerns, and lacking local deployment capabilities. To address\nthese concerns, we present LDST, an LLM-driven DST framework based on smaller,\nopen-source foundation models. By utilizing a novel domain-slot instruction\ntuning method, LDST achieves performance on par with ChatGPT. Comprehensive\nevaluations across three distinct experimental settings, we find that LDST\nexhibits remarkable performance improvements in both zero-shot and few-shot\nsetting compared to previous SOTA methods. The source code is provided for\nreproducibility.\n",
                "链接": "https://arxiv.org/abs/2310.14970"
            },
            {
                "文章ID": "72719",
                "标题": "Human Pose Estimation in Monocular Omnidirectional Top-View Images",
                "作者": " Jingrui Yu,  Tobias Scheck,  Roman Seidel,  Yukti Adya,  Dipankar Nandi,  Gangolf Hirtz",
                "发布日期": "2023-04-18",
                "摘要": "  Human pose estimation (HPE) with convolutional neural networks (CNNs) for\nindoor monitoring is one of the major challenges in computer vision. In\ncontrast to HPE in perspective views, an indoor monitoring system can consist\nof an omnidirectional camera with a field of view of 180{\\deg} to detect the\npose of a person with only one sensor per room. To recognize human pose, the\ndetection of keypoints is an essential upstream step. In our work we propose a\nnew dataset for training and evaluation of CNNs for the task of keypoint\ndetection in omnidirectional images. The training dataset, THEODORE+, consists\nof 50,000 images and is created by a 3D rendering engine, where humans are\nrandomly walking through an indoor environment. In a dynamically created 3D\nscene, persons move randomly with simultaneously moving omnidirectional camera\nto generate synthetic RGB images and 2D and 3D ground truth. For evaluation\npurposes, the real-world PoseFES dataset with two scenarios and 701 frames with\nup to eight persons per scene was captured and annotated. We propose four\ntraining paradigms to finetune or re-train two top-down models in MMPose and\ntwo bottom-up models in CenterNet on THEODORE+. Beside a qualitative evaluation\nwe report quantitative results. Compared to a COCO pretrained baseline, we\nachieve significant improvements especially for top-view scenes on the PoseFES\ndataset. Our datasets can be found at\nhttps://www.tu-chemnitz.de/etit/dst/forschung/comp_vision/datasets/index.php.en.\n",
                "链接": "https://arxiv.org/abs/2304.08186"
            }
        ]
    },
    {
        "question": {
            "question": "2023年后利用hotpotqa数据集做问题生成任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "1",
                "标题": "Leveraging Queue Length and Attention Mechanisms for Enhanced Traffic\n  Signal Control Optimization",
                "作者": " Liang Zhang,  Shubin Xie,  Jianming Deng",
                "发布日期": "2023-09-26",
                "摘要": "  Reinforcement learning (RL) techniques for traffic signal control (TSC) have\ngained increasing popularity in recent years. However, most existing RL-based\nTSC methods tend to focus primarily on the RL model structure while neglecting\nthe significance of proper traffic state representation. Furthermore, some\nRL-based methods heavily rely on expert-designed traffic signal phase\ncompetition. In this paper, we present a novel approach to TSC that utilizes\nqueue length as an efficient state representation. We propose two new methods:\n(1) Max Queue-Length (M-QL), an optimization-based traditional method designed\nbased on the property of queue length; and (2) AttentionLight, an RL model that\nemploys the self-attention mechanism to capture the signal phase correlation\nwithout requiring human knowledge of phase relationships. Comprehensive\nexperiments on multiple real-world datasets demonstrate the effectiveness of\nour approach: (1) the M-QL method outperforms the latest RL-based methods; (2)\nAttentionLight achieves a new state-of-the-art performance; and (3) our results\nhighlight the significance of proper state representation, which is as crucial\nas neural network design in TSC methods. Our findings have important\nimplications for advancing the development of more effective and efficient TSC\nmethods. Our code is released on Github (https://github.\ncom/LiangZhang1996/AttentionLight).\n",
                "链接": "https://arxiv.org/abs/2201.00006"
            },
            {
                "文章ID": "4",
                "标题": "Improving Deep Neural Network Classification Confidence using\n  Heatmap-based eXplainable AI",
                "作者": " Erico Tjoa,  Hong Jing Khok,  Tushar Chouhan,  Guan Cuntai",
                "发布日期": "2023-01-24",
                "摘要": "  This paper quantifies the quality of heatmap-based eXplainable AI (XAI)\nmethods w.r.t image classification problem. Here, a heatmap is considered\ndesirable if it improves the probability of predicting the correct classes.\nDifferent XAI heatmap-based methods are empirically shown to improve\nclassification confidence to different extents depending on the datasets, e.g.\nSaliency works best on ImageNet and Deconvolution on Chest X-Ray Pneumonia\ndataset. The novelty includes a new gap distribution that shows a stark\ndifference between correct and wrong predictions. Finally, the generative\naugmentative explanation is introduced, a method to generate heatmaps capable\nof improving predictive confidence to a high level.\n",
                "链接": "https://arxiv.org/abs/2201.00009"
            },
            {
                "文章ID": "15",
                "标题": "Representation Topology Divergence: A Method for Comparing Neural\n  Network Representations",
                "作者": " Serguei Barannikov,  Ilya Trofimov,  Nikita Balabin,  Evgeny Burnaev",
                "发布日期": "2023-05-05",
                "摘要": "  Comparison of data representations is a complex multi-aspect problem that has\nnot enjoyed a complete solution yet. We propose a method for comparing two data\nrepresentations. We introduce the Representation Topology Divergence (RTD),\nmeasuring the dissimilarity in multi-scale topology between two point clouds of\nequal size with a one-to-one correspondence between points. The data point\nclouds are allowed to lie in different ambient spaces. The RTD is one of the\nfew TDA-based practical methods applicable to real machine learning datasets.\nExperiments show that the proposed RTD agrees with the intuitive assessment of\ndata representation similarity and is sensitive to its topological structure.\nWe apply RTD to gain insights on neural networks representations in computer\nvision and NLP domains for various problems: training dynamics analysis, data\ndistribution shift, transfer learning, ensemble learning, disentanglement\nassessment.\n",
                "链接": "https://arxiv.org/abs/2201.00058"
            },
            {
                "文章ID": "23",
                "标题": "Persistent Homological State-Space Estimation of Functional Human Brain\n  Networks at Rest",
                "作者": " Moo K. Chung,  Shih-Gu Huang,  Ian C. Carroll,  Vince D. Calhoun,  H. Hill Goldsmith",
                "发布日期": "2023-12-19",
                "摘要": "  We present a new data driven topological data analysis (TDA) approach for\nestimating state spaces in dynamically changing human functional brain networks\nof human. Our approach penalizes the topological distance between networks and\nclusters dynamically changing brain networks into topologically distinct\nstates. Our method takes into account the temporal dimension of the data\nthrough the Wasserstein distance between networks. Our method is shown to\noutperform the widely used k-means clustering often used in estimating the\nstate space in brain networks. The method is applied to more accurately\ndetermine the state spaces of dynamically changing functional brain networks.\nSubsequently, we address the question of whether the overall topology of brain\nnetworks is a heritable feature using the twin study design. MATLAB code for\nthe method is available at https://github.com/laplcebeltrami/PH-STAT.\n",
                "链接": "https://arxiv.org/abs/2201.00087"
            },
            {
                "文章ID": "38",
                "标题": "Matrix Decomposition and Applications",
                "作者": " Jun Lu",
                "发布日期": "2023-12-29",
                "摘要": "  In 1954, Alston S. Householder published Principles of Numerical Analysis,\none of the first modern treatments on matrix decomposition that favored a\n(block) LU decomposition-the factorization of a matrix into the product of\nlower and upper triangular matrices. And now, matrix decomposition has become a\ncore technology in machine learning, largely due to the development of the back\npropagation algorithm in fitting a neural network. The sole aim of this survey\nis to give a self-contained introduction to concepts and mathematical tools in\nnumerical linear algebra and matrix analysis in order to seamlessly introduce\nmatrix decomposition techniques and their applications in subsequent sections.\nHowever, we clearly realize our inability to cover all the useful and\ninteresting results concerning matrix decomposition and given the paucity of\nscope to present this discussion, e.g., the separated analysis of the Euclidean\nspace, Hermitian space, Hilbert space, and things in the complex domain. We\nrefer the reader to literature in the field of linear algebra for a more\ndetailed introduction to the related fields.\n",
                "链接": "https://arxiv.org/abs/2201.00145"
            },
            {
                "文章ID": "58",
                "标题": "The Complexity of Dynamic Least-Squares Regression",
                "作者": " Shunhua Jiang,  Binghui Peng,  Omri Weinstein",
                "发布日期": "2023-04-07",
                "摘要": "  We settle the complexity of dynamic least-squares regression (LSR), where\nrows and labels $(\\mathbf{A}^{(t)}, \\mathbf{b}^{(t)})$ can be adaptively\ninserted and/or deleted, and the goal is to efficiently maintain an\n$\\epsilon$-approximate solution to $\\min_{\\mathbf{x}^{(t)}} \\| \\mathbf{A}^{(t)}\n\\mathbf{x}^{(t)} - \\mathbf{b}^{(t)} \\|_2$ for all $t\\in [T]$. We prove sharp\nseparations ($d^{2-o(1)}$ vs. $\\sim d$) between the amortized update time of:\n(i) Fully vs. Partially dynamic $0.01$-LSR; (ii) High vs. low-accuracy LSR in\nthe partially-dynamic (insertion-only) setting.\n  Our lower bounds follow from a gap-amplification reduction -- reminiscent of\niterative refinement -- rom the exact version of the Online Matrix Vector\nConjecture (OMv) [HKNS15], to constant approximate OMv over the reals, where\nthe $i$-th online product $\\mathbf{H}\\mathbf{v}^{(i)}$ only needs to be\ncomputed to $0.1$-relative error. All previous fine-grained reductions from OMv\nto its approximate versions only show hardness for inverse polynomial\napproximation $\\epsilon = n^{-\\omega(1)}$ (additive or multiplicative) . This\nresult is of independent interest in fine-grained complexity and for the\ninvestigation of the OMv Conjecture, which is still widely open.\n",
                "链接": "https://arxiv.org/abs/2201.00228"
            },
            {
                "文章ID": "73",
                "标题": "Fair Data Representation for Machine Learning at the Pareto Frontier",
                "作者": " Shizhou Xu,  Thomas Strohmer",
                "发布日期": "2023-11-27",
                "摘要": "  As machine learning powered decision-making becomes increasingly important in\nour daily lives, it is imperative to strive for fairness in the underlying data\nprocessing. We propose a pre-processing algorithm for fair data representation\nvia which supervised learning results in estimations of the Pareto frontier\nbetween prediction error and statistical disparity. Particularly, the present\nwork applies the optimal affine transport to approach the post-processing\nWasserstein-2 barycenter characterization of the optimal fair $L^2$-objective\nsupervised learning via a pre-processing data deformation. Furthermore, we show\nthat the Wasserstein-2 geodesics from the conditional (on sensitive\ninformation) distributions of the learning outcome to their barycenter\ncharacterizes the Pareto frontier between $L^2$-loss and the average pairwise\nWasserstein-2 distance among sensitive groups on the learning outcome.\nNumerical simulations underscore the advantages: (1) the pre-processing step is\ncompositive with arbitrary conditional expectation estimation supervised\nlearning methods and unseen data; (2) the fair representation protects the\nsensitive information by limiting the inference capability of the remaining\ndata with respect to the sensitive data; (3) the optimal affine maps are\ncomputationally efficient even for high-dimensional data.\n",
                "链接": "https://arxiv.org/abs/2201.00292"
            },
            {
                "文章ID": "79",
                "标题": "Recurrent Feature Propagation and Edge Skip-Connections for Automatic\n  Abdominal Organ Segmentation",
                "作者": " Zefan Yang,  Di Lin,  Dong Ni,  Yi Wang",
                "发布日期": "2023-05-22",
                "摘要": "  Automatic segmentation of abdominal organs in computed tomography (CT) images\ncan support radiation therapy and image-guided surgery workflows. Developing of\nsuch automatic solutions remains challenging mainly owing to complex organ\ninteractions and blurry boundaries in CT images. To address these issues, we\nfocus on effective spatial context modeling and explicit edge segmentation\npriors. Accordingly, we propose a 3D network with four main components trained\nend-to-end including shared encoder, edge detector, decoder with edge\nskip-connections (ESCs) and recurrent feature propagation head (RFP-Head). To\ncapture wide-range spatial dependencies, the RFP-Head propagates and harvests\nlocal features through directed acyclic graphs (DAGs) formulated with recurrent\nconnections in an efficient slice-wise manner, with regard to spatial\narrangement of image units. To leverage edge information, the edge detector\nlearns edge prior knowledge specifically tuned for semantic segmentation by\nexploiting intermediate features from the encoder with the edge supervision.\nThe ESCs then aggregate the edge knowledge with multi-level decoder features to\nlearn a hierarchy of discriminative features explicitly modeling\ncomplementarity between organs' interiors and edges for segmentation. We\nconduct extensive experiments on two challenging abdominal CT datasets with\neight annotated organs. Experimental results show that the proposed network\noutperforms several state-of-the-art models, especially for the segmentation of\nsmall and complicated structures (gallbladder, esophagus, stomach, pancreas and\nduodenum). The code will be publicly available.\n",
                "链接": "https://arxiv.org/abs/2201.00317"
            },
            {
                "文章ID": "85",
                "标题": "Riemannian Nearest-Regularized Subspace Classification for Polarimetric\n  SAR images",
                "作者": " Junfei Shi,  Haiyan Jin",
                "发布日期": "2023-02-08",
                "摘要": "  As a representation learning method, nearest regularized subspace(NRS)\nalgorithm is an effective tool to obtain both accuracy and speed for PolSAR\nimage classification. However, existing NRS methods use the polarimetric\nfeature vector but the PolSAR original covariance matrix(known as Hermitian\npositive definite(HPD)matrix) as the input. Without considering the matrix\nstructure, existing NRS-based methods cannot learn correlation among channels.\nHow to utilize the original covariance matrix to NRS method is a key problem.\nTo address this limit, a Riemannian NRS method is proposed, which consider the\nHPD matrices endow in the Riemannian space. Firstly, to utilize the PolSAR\noriginal data, a Riemannian NRS method(RNRS) is proposed by constructing HPD\ndictionary and HPD distance metric. Secondly, a new Tikhonov regularization\nterm is designed to reduce the differences within the same class. Finally, the\noptimal method is developed and the first-order derivation is inferred. During\nthe experimental test, only T matrix is used in the proposed method, while\nmultiple of features are utilized for compared methods. Experimental results\ndemonstrate the proposed method can outperform the state-of-art algorithms even\nusing less features.\n",
                "链接": "https://arxiv.org/abs/2201.00337"
            },
            {
                "文章ID": "87",
                "标题": "The Interpretability of LSTM Models for Predicting Oil Company Stocks:\n  Impact of Correlated Features",
                "作者": " Javad T. Firouzjaee,  Pouriya Khaliliyan",
                "发布日期": "2023-12-21",
                "摘要": "  Oil companies are among the largest companies in the world whose economic\nindicators in the global stock market have a great impact on the world\neconomy\\cite{ec00} and market due to their relation to gold\\cite{ec01}, crude\noil\\cite{ec02}, and the dollar\\cite{ec03}. This study investigates the impact\nof correlated features on the interpretability of Long Short-Term\nMemory(LSTM)\\cite{ec04} models for predicting oil company stocks. To achieve\nthis, we designed a Standard Long Short-Term Memory (LSTM) network and trained\nit using various correlated datasets. Our approach aims to improve the accuracy\nof stock price prediction by considering the multiple factors affecting the\nmarket, such as crude oil prices, gold prices, and the US dollar. The results\ndemonstrate that adding a feature correlated with oil stocks does not improve\nthe interpretability of LSTM models. These findings suggest that while LSTM\nmodels may be effective in predicting stock prices, their interpretability may\nbe limited. Caution should be exercised when relying solely on LSTM models for\nstock price prediction as their lack of interpretability may make it difficult\nto fully understand the underlying factors driving stock price movements. We\nhave employed complexity analysis to support our argument, considering that\nfinancial markets encompass a form of physical complex system\\cite{ec05}. One\nof the fundamental challenges faced in utilizing LSTM models for financial\nmarkets lies in interpreting the unexpected feedback dynamics within them.\n",
                "链接": "https://arxiv.org/abs/2201.00350"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用机器学习方法进行心理健康疾病研究的论文",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找基于优化实现模型越狱的文献",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "72857",
                "标题": "Continuous Versatile Jumping Using Learned Action Residuals",
                "作者": " Yuxiang Yang,  Xiangyun Meng,  Wenhao Yu,  Tingnan Zhang,  Jie Tan,  Byron Boots",
                "发布日期": "2023-04-19",
                "摘要": "  Jumping is essential for legged robots to traverse through difficult\nterrains. In this work, we propose a hierarchical framework that combines\noptimal control and reinforcement learning to learn continuous jumping motions\nfor quadrupedal robots. The core of our framework is a stance controller, which\ncombines a manually designed acceleration controller with a learned residual\npolicy. As the acceleration controller warm starts policy for efficient\ntraining, the trained policy overcomes the limitation of the acceleration\ncontroller and improves the jumping stability. In addition, a low-level\nwhole-body controller converts the body pose command from the stance controller\nto motor commands. After training in simulation, our framework can be deployed\ndirectly to the real robot, and perform versatile, continuous jumping motions,\nincluding omni-directional jumps at up to 50cm high, 60cm forward, and\njump-turning at up to 90 degrees. Please visit our website for more results:\nhttps://sites.google.com/view/learning-to-jump.\n",
                "链接": "https://arxiv.org/abs/2304.08663"
            },
            {
                "文章ID": "116298",
                "标题": "Near-optimal Closed-loop Method via Lyapunov Damping for Convex\n  Optimization",
                "作者": " Severin Maier,  Camille Castera,  Peter Ochs",
                "发布日期": "2023-11-17",
                "摘要": "  We introduce an autonomous system with closed-loop damping for first-order\nconvex optimization. While, to this day, optimal rates of convergence are only\nachieved by non-autonomous methods via open-loop damping (e.g., Nesterov's\nalgorithm), we show that our system is the first one featuring a closed-loop\ndamping while exhibiting a rate arbitrarily close to the optimal one. We do so\nby coupling the damping and the speed of convergence of the system via a\nwell-chosen Lyapunov function. We then derive a practical first-order algorithm\ncalled LYDIA by discretizing our system, and present numerical experiments\nsupporting our theoretical findings.\n",
                "链接": "https://arxiv.org/abs/2311.10053"
            },
            {
                "文章ID": "1838",
                "标题": "Graph Neural Network-based Android Malware Classification with Jumping\n  Knowledge",
                "作者": " Wai Weng Lo,  Siamak Layeghy,  Mohanad Sarhan,  Marcus Gallagher,  Marius Portmann",
                "发布日期": "2022-06-14",
                "摘要": "  This paper presents a new Android malware detection method based on Graph\nNeural Networks (GNNs) with Jumping-Knowledge (JK). Android function call\ngraphs (FCGs) consist of a set of program functions and their inter-procedural\ncalls. Thus, this paper proposes a GNN-based method for Android malware\ndetection by capturing meaningful intra-procedural call path patterns. In\naddition, a Jumping-Knowledge technique is applied to minimize the effect of\nthe over-smoothing problem, which is common in GNNs. The proposed method has\nbeen extensively evaluated using two benchmark datasets. The results\ndemonstrate the superiority of our approach compared to state-of-the-art\napproaches in terms of key classification metrics, which demonstrates the\npotential of GNNs in Android malware detection and classification.\n",
                "链接": "https://arxiv.org/abs/2201.07537"
            },
            {
                "文章ID": "63962",
                "标题": "Analysis and experimental study on the Jumping Chain",
                "作者": " Wenyu Wang,  Wu-Long Xu,  Yang Xu,  Xu-Dong Yang",
                "发布日期": "2023-03-01",
                "摘要": "  A freely falling chain from a cup at certain height can jump. The process can\nbe divided into two parts: a stable suspension and an accelerating procedure.\nVariational principle and force analysis demonstrate that the shape of stable\nsuspension is an inverted catenary. The requirement of the jumping and the\nparameters to describe the jumping catenary have been studied in detail, and\nexperiments have been conducted to verify the theoretical analysis. The\nphysical picture of the falling chain could be useful in certain falling\nsystems, providing valuable insight into the dynamical system.\n",
                "链接": "https://arxiv.org/abs/2302.14528"
            },
            {
                "文章ID": "62296",
                "标题": "Robust and Versatile Bipedal Jumping Control through Reinforcement\n  Learning",
                "作者": " Zhongyu Li,  Xue Bin Peng,  Pieter Abbeel,  Sergey Levine,  Glen Berseth,  Koushil Sreenath",
                "发布日期": "2023-06-02",
                "摘要": "  This work aims to push the limits of agility for bipedal robots by enabling a\ntorque-controlled bipedal robot to perform robust and versatile dynamic jumps\nin the real world. We present a reinforcement learning framework for training a\nrobot to accomplish a large variety of jumping tasks, such as jumping to\ndifferent locations and directions. To improve performance on these challenging\ntasks, we develop a new policy structure that encodes the robot's long-term\ninput/output (I/O) history while also providing direct access to a short-term\nI/O history. In order to train a versatile jumping policy, we utilize a\nmulti-stage training scheme that includes different training stages for\ndifferent objectives. After multi-stage training, the policy can be directly\ntransferred to a real bipedal Cassie robot. Training on different tasks and\nexploring more diverse scenarios lead to highly robust policies that can\nexploit the diverse set of learned maneuvers to recover from perturbations or\npoor landings during real-world deployment. Such robustness in the proposed\npolicy enables Cassie to succeed in completing a variety of challenging jump\ntasks in the real world, such as standing long jumps, jumping onto elevated\nplatforms, and multi-axes jumps.\n",
                "链接": "https://arxiv.org/abs/2302.09450"
            },
            {
                "文章ID": "24779",
                "标题": "Flexible Raman Amplifier Optimization Based on Machine Learning-aided\n  Physical Stimulated Raman Scattering Model",
                "作者": " Metodi Plamenov Yankov,  Francesco Da Ros,  Uiara Celine de Moura,  Andrea Carena,  Darko Zibar",
                "发布日期": "2022-06-16",
                "摘要": "  The problem of Raman amplifier optimization is studied. A differentiable\ninterpolation function is obtained for the Raman gain coefficient using machine\nlearning (ML), which allows for the gradient descent optimization of\nforward-propagating Raman pumps. Both the frequency and power of an arbitrary\nnumber of pumps in a forward pumping configuration are then optimized for an\narbitrary data channel load and span length. The forward propagation model is\ncombined with an experimentally-trained ML model of a backward-pumping Raman\namplifier to jointly optimize the frequency and power of the forward\namplifier's pumps and the powers of the backward amplifier's pumps. The joint\nforward and backward amplifier optimization is demonstrated for an unrepeatered\ntransmission of 250 km. A gain flatness of $<$ 1~dB over 4 THz is achieved. The\noptimized amplifiers are validated using a numerical simulator.\n",
                "链接": "https://arxiv.org/abs/2206.07650"
            },
            {
                "文章ID": "119761",
                "标题": "A Semi-Supervised Deep Learning Approach to Dataset Collection for\n  Query-By-Humming Task",
                "作者": " Amantur Amatov,  Dmitry Lamanov,  Maksim Titov,  Ivan Vovk,  Ilya Makarov,  Mikhail Kudinov",
                "发布日期": "2023-12-05",
                "摘要": "  Query-by-Humming (QbH) is a task that involves finding the most relevant song\nbased on a hummed or sung fragment. Despite recent successful commercial\nsolutions, implementing QbH systems remains challenging due to the lack of\nhigh-quality datasets for training machine learning models. In this paper, we\npropose a deep learning data collection technique and introduce Covers and\nHummings Aligned Dataset (CHAD), a novel dataset that contains 18 hours of\nshort music fragments, paired with time-aligned hummed versions. To expand our\ndataset, we employ a semi-supervised model training pipeline that leverages the\nQbH task as a specialized case of cover song identification (CSI) task.\nStarting with a model trained on the initial dataset, we iteratively collect\ngroups of fragments of cover versions of the same song and retrain the model on\nthe extended data. Using this pipeline, we collect over 308 hours of additional\nmusic fragments, paired with time-aligned cover versions. The final model is\nsuccessfully applied to the QbH task and achieves competitive results on\nbenchmark datasets. Our study shows that the proposed dataset and training\npipeline can effectively facilitate the implementation of QbH systems.\n",
                "链接": "https://arxiv.org/abs/2312.01092"
            },
            {
                "文章ID": "34097",
                "标题": "Recurrent Neural Network-based Anti-jamming Framework for Defense\n  Against Multiple Jamming Policies",
                "作者": " Ali Pourranjbar,  Georges Kaddoum,  Walid Saad",
                "发布日期": "2022-12-26",
                "摘要": "  Conventional anti-jamming methods mainly focus on preventing single jammer\nattacks with an invariant jamming policy or jamming attacks from multiple\njammers with similar jamming policies. These anti-jamming methods are\nineffective against a single jammer following several different jamming\npolicies or multiple jammers with distinct policies. Therefore, this paper\nproposes an anti-jamming method that can adapt its policy to the current\njamming attack. Moreover, for the multiple jammers scenario, an anti-jamming\nmethod that estimates the future occupied channels using the jammers' occupied\nchannels in previous time slots is proposed. In both single and multiple\njammers scenarios, the interaction between the users and jammers is modeled\nusing recurrent neural networks (RNN)s. The performance of the proposed\nanti-jamming methods is evaluated by calculating the users' successful\ntransmission rate (STR) and ergodic rate (ER), and compared to a baseline based\non Q-learning (DQL). Simulation results show that for the single jammer\nscenario, all the considered jamming policies are perfectly detected and high\nSTR and ER are maintained. Moreover, when 70 % of the spectrum is under jamming\nattacks from multiple jammers, the proposed method achieves an STR and ER\ngreater than 75 % and 80 %, respectively. These values rise to 90 % when 30 %\nof the spectrum is under jamming attacks. In addition, the proposed\nanti-jamming methods significantly outperform the DQL method for all the\nconsidered cases and jamming scenarios.\n",
                "链接": "https://arxiv.org/abs/2208.09518"
            },
            {
                "文章ID": "104286",
                "标题": "Skilog: A Smart Sensor System for Performance Analysis and Biofeedback\n  in Ski Jumping",
                "作者": " Lukas Schulthess,  Thorir Mar Ingolfsson,  Marc Nölke,  Michele Magno,  Luca Benini,  Christoph Leitner",
                "发布日期": "2023-09-27",
                "摘要": "  In ski jumping, low repetition rates of jumps limit the effectiveness of\ntraining. Thus, increasing learning rate within every single jump is key to\nsuccess. A critical element of athlete training is motor learning, which has\nbeen shown to be accelerated by feedback methods. In particular, a fine-grained\ncontrol of the center of gravity in the in-run is essential. This is because\nthe actual takeoff occurs within a blink of an eye ($\\sim$300ms), thus any\nunbalanced body posture during the in-run will affect flight. This paper\npresents a smart, compact, and energy-efficient wireless sensor system for\nreal-time performance analysis and biofeedback during ski jumping. The system\noperates by gauging foot pressures at three distinct points on the insoles of\nthe ski boot at 100Hz. Foot pressure data can either be directly sent to\ncoaches to improve their feedback, or fed into a ML model to give athletes\ninstantaneous in-action feedback using a vibration motor in the ski boot. In\nthe biofeedback scenario, foot pressures act as input variables for an\noptimized XGBoost model. We achieve a high predictive accuracy of 92.7% for\ncenter of mass predictions (dorsal shift, neutral stand, ventral shift).\nSubsequently, we parallelized and fine-tuned our XGBoost model for a RISC-V\nbased low power parallel processor (GAP9), based on the PULP architecture. We\ndemonstrate real-time detection and feedback (0.0109ms/inference) using our\non-chip deployment. The proposed smart system is unobtrusive with a slim form\nfactor (13mm baseboard, 3.2mm antenna) and a lightweight build (26g). Power\nconsumption analysis reveals that the system's energy-efficient design enables\nsustained operation over multiple days (up to 300 hours) without requiring\nrecharge.\n",
                "链接": "https://arxiv.org/abs/2309.14455"
            },
            {
                "文章ID": "53958",
                "标题": "Implementation of general formal translators",
                "作者": " Iosif Iulian Petrila",
                "发布日期": "2022-12-23",
                "摘要": "  The general translator formalism and computing specific implementations are\nproposed. The implementation of specific elements necessary to process the\nsource and destination information within the translators are presented. Some\ncommon directives or instructions, such as classes and procedures, were unified\nand generalized in order to allow general translations implementations. In\norder to cover general cases, two levels of processing are required, related to\nthe source and destination information appropriate transformations, with the\nrelated control and processing instructions. The proposed general translator\nelements are useful for processing natural or artificial information described\nthrough any types of languages or systems.\n",
                "链接": "https://arxiv.org/abs/2212.08482"
            }
        ]
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "110744",
                "标题": "ALCUNA: Large Language Models Meet New Knowledge",
                "作者": " Xunjian Yin,  Baizhou Huang,  Xiaojun Wan",
                "发布日期": "2023-10-24",
                "摘要": "  With the rapid development of NLP, large-scale language models (LLMs) excel\nin various tasks across multiple domains now. However, existing benchmarks may\nnot adequately measure these models' capabilities, especially when faced with\nnew knowledge. In this paper, we address the lack of benchmarks to evaluate\nLLMs' ability to handle new knowledge, an important and challenging aspect in\nthe rapidly evolving world. We propose an approach called KnowGen that\ngenerates new knowledge by altering existing entity attributes and\nrelationships, resulting in artificial entities that are distinct from\nreal-world entities. With KnowGen, we introduce a benchmark named ALCUNA to\nassess LLMs' abilities in knowledge understanding, differentiation, and\nassociation. We benchmark several LLMs, reveals that their performance in face\nof new knowledge is not satisfactory, particularly in reasoning between new and\ninternal knowledge. We also explore the impact of entity similarity on the\nmodel's understanding of entity knowledge and the influence of contextual\nentities. We appeal to the need for caution when using LLMs in new scenarios or\nwith new knowledge, and hope that our benchmarks can help drive the development\nof LLMs in face of new knowledge.\n",
                "链接": "https://arxiv.org/abs/2310.14820"
            },
            {
                "文章ID": "14407",
                "标题": "Forecasting new diseases in low-data settings using transfer learning",
                "作者": " Kirstin Roster,  Colm Connaughton,  Francisco A. Rodrigues",
                "发布日期": "2022-08-16",
                "摘要": "  Recent infectious disease outbreaks, such as the COVID-19 pandemic and the\nZika epidemic in Brazil, have demonstrated both the importance and difficulty\nof accurately forecasting novel infectious diseases. When new diseases first\nemerge, we have little knowledge of the transmission process, the level and\nduration of immunity to reinfection, or other parameters required to build\nrealistic epidemiological models. Time series forecasts and machine learning,\nwhile less reliant on assumptions about the disease, require large amounts of\ndata that are also not available in early stages of an outbreak. In this study,\nwe examine how knowledge of related diseases can help make predictions of new\ndiseases in data-scarce environments using transfer learning. We implement both\nan empirical and a theoretical approach. Using empirical data from Brazil, we\ncompare how well different machine learning models transfer knowledge between\ntwo different disease pairs: (i) dengue and Zika, and (ii) influenza and\nCOVID-19. In the theoretical analysis, we generate data using different\ntransmission and recovery rates with an SIR compartmental model, and then\ncompare the effectiveness of different transfer learning methods. We find that\ntransfer learning offers the potential to improve predictions, even beyond a\nmodel based on data from the target disease, though the appropriate source\ndisease must be chosen carefully. While imperfect, these models offer an\nadditional input for decision makers during pandemic response.\n",
                "链接": "https://arxiv.org/abs/2204.05059"
            },
            {
                "文章ID": "9744",
                "标题": "Leveraging Visual Knowledge in Language Tasks: An Empirical Study on\n  Intermediate Pre-training for Cross-modal Knowledge Transfer",
                "作者": " Woojeong Jin,  Dong-Ho Lee,  Chenguang Zhu,  Jay Pujara,  Xiang Ren",
                "发布日期": "2022-03-18",
                "摘要": "  Pre-trained language models are still far from human performance in tasks\nthat need understanding of properties (e.g. appearance, measurable quantity)\nand affordances of everyday objects in the real world since the text lacks such\ninformation due to reporting bias. In this work, we study whether integrating\nvisual knowledge into a language model can fill the gap. We investigate two\ntypes of knowledge transfer: (1) text knowledge transfer using image captions\nthat may contain enriched visual knowledge and (2) cross-modal knowledge\ntransfer using both images and captions with vision-language training\nobjectives. On 5 downstream tasks that may need visual knowledge to solve the\nproblem, we perform extensive empirical comparisons over the presented\nobjectives. Our experiments show that visual knowledge transfer can improve\nperformance in both low-resource and fully supervised settings.\n",
                "链接": "https://arxiv.org/abs/2203.07519"
            },
            {
                "文章ID": "109505",
                "标题": "Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from\n  a Parametric Perspective",
                "作者": " Ming Zhong,  Chenxin An,  Weizhu Chen,  Jiawei Han,  Pengcheng He",
                "发布日期": "2023-10-18",
                "摘要": "  Large Language Models (LLMs) inherently encode a wealth of knowledge within\ntheir parameters through pre-training on extensive corpora. While prior\nresearch has delved into operations on these parameters to manipulate the\nunderlying implicit knowledge (encompassing detection, editing, and merging),\nthere remains an ambiguous understanding regarding their transferability across\nmodels with varying scales. In this paper, we seek to empirically investigate\nknowledge transfer from larger to smaller models through a parametric\nperspective. To achieve this, we employ sensitivity-based techniques to extract\nand align knowledge-specific parameters between different LLMs. Moreover, the\nLoRA module is used as the intermediary mechanism for injecting the extracted\nknowledge into smaller models. Evaluations across four benchmarks validate the\nefficacy of our proposed method. Our findings highlight the critical factors\ncontributing to the process of parametric knowledge transfer, underscoring the\ntransferability of model parameters across LLMs of different scales. We release\ncode and data at \\url{https://github.com/maszhongming/ParaKnowTransfer}.\n",
                "链接": "https://arxiv.org/abs/2310.11451"
            },
            {
                "文章ID": "37229",
                "标题": "Learning state correspondence of reinforcement learning tasks for\n  knowledge transfer",
                "作者": " Marko Ruman,  Tatiana V. Guy",
                "发布日期": "2022-09-15",
                "摘要": "  Deep reinforcement learning has shown an ability to achieve super-human\nperformance in solving complex reinforcement learning (RL) tasks only from\nraw-pixels. However, it fails to reuse knowledge from previously learnt tasks\nto solve new, unseen ones. Generalizing and reusing knowledge are the\nfundamental requirements for creating a truly intelligent agent. This work\nproposes a general method for one-to-one transfer learning based on generative\nadversarial network model tailored to RL task.\n",
                "链接": "https://arxiv.org/abs/2209.06604"
            },
            {
                "文章ID": "33357",
                "标题": "A Theory for Knowledge Transfer in Continual Learning",
                "作者": " Diana Benavides-Prado,  Patricia Riddle",
                "发布日期": "2022-08-16",
                "摘要": "  Continual learning of a stream of tasks is an active area in deep neural\nnetworks. The main challenge investigated has been the phenomenon of\ncatastrophic forgetting or interference of newly acquired knowledge with\nknowledge from previous tasks. Recent work has investigated forward knowledge\ntransfer to new tasks. Backward transfer for improving knowledge gained during\nprevious tasks has received much less attention. There is in general limited\nunderstanding of how knowledge transfer could aid tasks learned continually. We\npresent a theory for knowledge transfer in continual supervised learning, which\nconsiders both forward and backward transfer. We aim at understanding their\nimpact for increasingly knowledgeable learners. We derive error bounds for each\nof these transfer mechanisms. These bounds are agnostic to specific\nimplementations (e.g. deep neural networks). We demonstrate that, for a\ncontinual learner that observes related tasks, both forward and backward\ntransfer can contribute to an increasing performance as more tasks are\nobserved.\n",
                "链接": "https://arxiv.org/abs/2208.06931"
            },
            {
                "文章ID": "41595",
                "标题": "Knowledge Distillation Transfer Sets and their Impact on Downstream NLU\n  Tasks",
                "作者": " Charith Peris,  Lizhen Tan,  Thomas Gueudre,  Turan Gojayev,  Pan Wei,  Gokmen Oz",
                "发布日期": "2022-10-19",
                "摘要": "  Teacher-student knowledge distillation is a popular technique for compressing\ntoday's prevailing large language models into manageable sizes that fit\nlow-latency downstream applications. Both the teacher and the choice of\ntransfer set used for distillation are crucial ingredients in creating a high\nquality student. Yet, the generic corpora used to pretrain the teacher and the\ncorpora associated with the downstream target domain are often significantly\ndifferent, which raises a natural question: should the student be distilled\nover the generic corpora, so as to learn from high-quality teacher predictions,\nor over the downstream task corpora to align with finetuning? Our study\ninvestigates this trade-off using Domain Classification (DC) and Intent\nClassification/Named Entity Recognition (ICNER) as downstream tasks. We distill\nseveral multilingual students from a larger multilingual LM with varying\nproportions of generic and task-specific datasets, and report their performance\nafter finetuning on DC and ICNER. We observe significant improvements across\ntasks and test sets when only task-specific corpora is used. We also report on\nhow the impact of adding task-specific data to the transfer set correlates with\nthe similarity between generic and task-specific data. Our results clearly\nindicate that, while distillation from a generic LM benefits downstream tasks,\nstudents learn better using target domain data even if it comes at the price of\nnoisier teacher predictions. In other words, target domain data still trumps\nteacher knowledge.\n",
                "链接": "https://arxiv.org/abs/2210.04834"
            },
            {
                "文章ID": "16746",
                "标题": "Heterogeneous Ensemble Knowledge Transfer for Training Large Models in\n  Federated Learning",
                "作者": " Yae Jee Cho,  Andre Manoel,  Gauri Joshi,  Robert Sim,  Dimitrios Dimitriadis",
                "发布日期": "2022-04-28",
                "摘要": "  Federated learning (FL) enables edge-devices to collaboratively learn a model\nwithout disclosing their private data to a central aggregating server. Most\nexisting FL algorithms require models of identical architecture to be deployed\nacross the clients and server, making it infeasible to train large models due\nto clients' limited system resources. In this work, we propose a novel ensemble\nknowledge transfer method named Fed-ET in which small models (different in\narchitecture) are trained on clients, and used to train a larger model at the\nserver. Unlike in conventional ensemble learning, in FL the ensemble can be\ntrained on clients' highly heterogeneous data. Cognizant of this property,\nFed-ET uses a weighted consensus distillation scheme with diversity\nregularization that efficiently extracts reliable consensus from the ensemble\nwhile improving generalization by exploiting the diversity within the ensemble.\nWe show the generalization bound for the ensemble of weighted models trained on\nheterogeneous datasets that supports the intuition of Fed-ET. Our experiments\non image and language tasks show that Fed-ET significantly outperforms other\nstate-of-the-art FL algorithms with fewer communicated parameters, and is also\nrobust against high data-heterogeneity.\n",
                "链接": "https://arxiv.org/abs/2204.12703"
            },
            {
                "文章ID": "21024",
                "标题": "Sparse*BERT: Sparse Models Generalize To New tasks and Domains",
                "作者": " Daniel Campos,  Alexandre Marques,  Tuan Nguyen,  Mark Kurtz,  ChengXiang Zhai",
                "发布日期": "2023-04-07",
                "摘要": "  Large Language Models have become the core architecture upon which most\nmodern natural language processing (NLP) systems build. These models can\nconsistently deliver impressive accuracy and robustness across tasks and\ndomains, but their high computational overhead can make inference difficult and\nexpensive. To make using these models less costly, recent work has explored\nleveraging structured and unstructured pruning, quantization, and distillation\nto improve inference speed and decrease size. This paper studies how models\npruned using Gradual Unstructured Magnitude Pruning can transfer between\ndomains and tasks. Our experimentation shows that models that are pruned during\npretraining using general domain masked language models can transfer to novel\ndomains and tasks without extensive hyperparameter exploration or specialized\napproaches. We demonstrate that our general sparse model Sparse*BERT can become\nSparseBioBERT simply by pretraining the compressed architecture on unstructured\nbiomedical text. Moreover, we show that SparseBioBERT can match the quality of\nBioBERT with only 10\\% of the parameters.\n",
                "链接": "https://arxiv.org/abs/2205.12452"
            },
            {
                "文章ID": "107652",
                "标题": "Geometrically Aligned Transfer Encoder for Inductive Transfer in\n  Regression Tasks",
                "作者": " Sung Moon Ko,  Sumin Lee,  Dae-Woong Jeong,  Woohyung Lim,  Sehui Han",
                "发布日期": "2023-10-11",
                "摘要": "  Transfer learning is a crucial technique for handling a small amount of data\nthat is potentially related to other abundant data. However, most of the\nexisting methods are focused on classification tasks using images and language\ndatasets. Therefore, in order to expand the transfer learning scheme to\nregression tasks, we propose a novel transfer technique based on differential\ngeometry, namely the Geometrically Aligned Transfer Encoder (GATE). In this\nmethod, we interpret the latent vectors from the model to exist on a Riemannian\ncurved manifold. We find a proper diffeomorphism between pairs of tasks to\nensure that every arbitrary point maps to a locally flat coordinate in the\noverlapping region, allowing the transfer of knowledge from the source to the\ntarget data. This also serves as an effective regularizer for the model to\nbehave in extrapolation regions. In this article, we demonstrate that GATE\noutperforms conventional methods and exhibits stable behavior in both the\nlatent space and extrapolation regions for various molecular graph datasets.\n",
                "链接": "https://arxiv.org/abs/2310.06369"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和人文学科交叉的研究",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和脑科学交叉的研究",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "2022年后与AI for Science相关的综述论文",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "5628",
                "标题": "State of AI Ethics Report (Volume 6, February 2022)",
                "作者": " Abhishek Gupta,  Connor Wright,  Marianna Bergamaschi Ganapini,  Masa Sweidan,  Renjie Butalid",
                "发布日期": "2022-02-16",
                "摘要": "  This report from the Montreal AI Ethics Institute (MAIEI) covers the most\nsalient progress in research and reporting over the second half of 2021 in the\nfield of AI ethics. Particular emphasis is placed on an \"Analysis of the AI\nEcosystem\", \"Privacy\", \"Bias\", \"Social Media and Problematic Information\", \"AI\nDesign and Governance\", \"Laws and Regulations\", \"Trends\", and other areas\ncovered in the \"Outside the Boxes\" section. The two AI spotlights feature\napplication pieces on \"Constructing and Deconstructing Gender with AI-Generated\nArt\" as well as \"Will an Artificial Intellichef be Cooking Your Next Meal at a\nMichelin Star Restaurant?\". Given MAIEI's mission to democratize AI,\nsubmissions from external collaborators have featured, such as pieces on the\n\"Challenges of AI Development in Vietnam: Funding, Talent and Ethics\" and using\n\"Representation and Imagination for Preventing AI Harms\". The report is a\ncomprehensive overview of what the key issues in the field of AI ethics were in\n2021, what trends are emergent, what gaps exist, and a peek into what to expect\nfrom the field of AI ethics in 2022. It is a resource for researchers and\npractitioners alike in the field to set their research and development agendas\nto make contributions to the field of AI ethics.\n",
                "链接": "https://arxiv.org/abs/2202.07435"
            },
            {
                "文章ID": "95379",
                "标题": "Towards an AI to Win Ghana's National Science and Maths Quiz",
                "作者": " George Boateng,  Jonathan Abrefah Mensah,  Kevin Takyi Yeboah,  William Edor,  Andrew Kojo Mensah-Onumah,  Naafi Dasana Ibrahim,  Nana Sam Yeboah",
                "发布日期": "2023-08-09",
                "摘要": "  Can an AI win Ghana's National Science and Maths Quiz (NSMQ)? That is the\nquestion we seek to answer in the NSMQ AI project, an open-source project that\nis building AI to compete live in the NSMQ and win. The NSMQ is an annual live\nscience and mathematics competition for senior secondary school students in\nGhana in which 3 teams of 2 students compete by answering questions across\nbiology, chemistry, physics, and math in 5 rounds over 5 progressive stages\nuntil a winning team is crowned for that year. The NSMQ is an exciting live\nquiz competition with interesting technical challenges across speech-to-text,\ntext-to-speech, question-answering, and human-computer interaction. In this\nongoing work that began in January 2023, we give an overview of the project,\ndescribe each of the teams, progress made thus far, and the next steps toward\nour planned launch and debut of the AI in October for NSMQ 2023. An AI that\nconquers this grand challenge can have real-world impact on education such as\nenabling millions of students across Africa to have one-on-one learning support\nfrom this AI.\n",
                "链接": "https://arxiv.org/abs/2308.04333"
            },
            {
                "文章ID": "49542",
                "标题": "Extended Multilingual Protest News Detection -- Shared Task 1, CASE 2021\n  and 2022",
                "作者": " Ali Hürriyetoğlu,  Osman Mutlu,  Fırat Duruşan,  Onur Uca,  Alaeddin Selçuk Gürel,  Benjamin Radford,  Yaoyao Dai,  Hansi Hettiarachchi,  Niklas Stoehr,  Tadashi Nomoto,  Milena Slavcheva,  Francielle Vargas,  Aaqib Javid,  Fatih Beyhan,  Erdem Yörük",
                "发布日期": "2022-11-22",
                "摘要": "  We report results of the CASE 2022 Shared Task 1 on Multilingual Protest\nEvent Detection. This task is a continuation of CASE 2021 that consists of four\nsubtasks that are i) document classification, ii) sentence classification, iii)\nevent sentence coreference identification, and iv) event extraction. The CASE\n2022 extension consists of expanding the test data with more data in previously\navailable languages, namely, English, Hindi, Portuguese, and Spanish, and\nadding new test data in Mandarin, Turkish, and Urdu for Sub-task 1, document\nclassification. The training data from CASE 2021 in English, Portuguese and\nSpanish were utilized. Therefore, predicting document labels in Hindi,\nMandarin, Turkish, and Urdu occurs in a zero-shot setting. The CASE 2022\nworkshop accepts reports on systems developed for predicting test data of CASE\n2021 as well. We observe that the best systems submitted by CASE 2022\nparticipants achieve between 79.71 and 84.06 F1-macro for new languages in a\nzero-shot setting. The winning approaches are mainly ensembling models and\nmerging data in multiple languages. The best two submissions on CASE 2021 data\noutperform submissions from last year for Subtask 1 and Subtask 2 in all\nlanguages. Only the following scenarios were not outperformed by new\nsubmissions on CASE 2021: Subtask 3 Portuguese \\& Subtask 4 English.\n",
                "链接": "https://arxiv.org/abs/2211.11360"
            },
            {
                "文章ID": "102384",
                "标题": "Has Sentiment Returned to the Pre-pandemic Level? A Sentiment Analysis\n  Using U.S. College Subreddit Data from 2019 to 2022",
                "作者": " Tian Yan,  Fang Liu",
                "发布日期": "2023-09-19",
                "摘要": "  As impact of COVID-19 pandemic winds down, both individuals and society\ngradually return to pre-pandemic activities. This study aims to explore how\npeople's emotions have changed from the pre-pandemic during the pandemic to\npost-emergency period and whether it has returned to pre-pandemic level. We\ncollected Reddit data in 2019 (pre-pandemic), 2020 (peak pandemic), 2021, and\n2022 (late stages of pandemic, transitioning period to post-emergency period)\nfrom subreddits in 128 universities/colleges in the U.S., and a set of\nschool-level characteristics. We predicted two sets of sentiments from a\npre-trained Robustly Optimized BERT pre-training approach (RoBERTa) and graph\nattention network (GAT) that leverages both rich semantic and relational\ninformation among posted messages and then applied a logistic stacking method\nto obtain the final sentiment classification. After obtaining sentiment label\nfor each message, we used a generalized linear mixed-effects model to estimate\ntemporal trend in sentiment from 2019 to 2022 and how school-level factors may\naffect sentiment. Compared to the year 2019, the odds of negative sentiment in\nyears 2020, 2021, and 2022 are 24%, 4.3%, and 10.3% higher, respectively, which\nare all statistically significant(adjusted $p$<0.05). Our study findings\nsuggest a partial recovery in the sentiment composition in the\npost-pandemic-emergency era. The results align with common expectations and\nprovide a detailed quantification of how sentiments have evolved from 2019 to\n2022.\n",
                "链接": "https://arxiv.org/abs/2309.08845"
            },
            {
                "文章ID": "65341",
                "标题": "AI for Science: An Emerging Agenda",
                "作者": " Philipp Berens,  Kyle Cranmer,  Neil D. Lawrence,  Ulrike von Luxburg,  Jessica Montgomery",
                "发布日期": "2023-03-09",
                "摘要": "  This report documents the programme and the outcomes of Dagstuhl Seminar\n22382 \"Machine Learning for Science: Bridging Data-Driven and Mechanistic\nModelling\". Today's scientific challenges are characterised by complexity.\nInterconnected natural, technological, and human systems are influenced by\nforces acting across time- and spatial-scales, resulting in complex\ninteractions and emergent behaviours. Understanding these phenomena -- and\nleveraging scientific advances to deliver innovative solutions to improve\nsociety's health, wealth, and well-being -- requires new ways of analysing\ncomplex systems. The transformative potential of AI stems from its widespread\napplicability across disciplines, and will only be achieved through integration\nacross research domains. AI for science is a rendezvous point. It brings\ntogether expertise from $\\mathrm{AI}$ and application domains; combines\nmodelling knowledge with engineering know-how; and relies on collaboration\nacross disciplines and between humans and machines. Alongside technical\nadvances, the next wave of progress in the field will come from building a\ncommunity of machine learning researchers, domain experts, citizen scientists,\nand engineers working together to design and deploy effective AI tools. This\nreport summarises the discussions from the seminar and provides a roadmap to\nsuggest how different communities can collaborate to deliver a new wave of\nprogress in AI and its application for scientific discovery.\n",
                "链接": "https://arxiv.org/abs/2303.04217"
            },
            {
                "文章ID": "102298",
                "标题": "Monitoring Urban Changes in Mariupol/Ukraine in 2022/23",
                "作者": " Georg Zitzlsberger,  Michal Podhoranyi",
                "发布日期": "2023-09-19",
                "摘要": "  The ability to constantly monitor urban changes is of large socio-economic\ninterest. Previous works have already shown approaches in this field with the\nuse of Deep Neural Networks (DNNs) and transfer learning. However, they fell\nshort in demonstrating temporal scale outside of either the training or\ntransfer domain.\n  This work builds on existing research and proves that transfer learning with\nthe use of historic data is a feasible solution, which still allows the urban\nchange monitoring of later years. We considered a case with limited access to\npublic and free Very High Resolution (VHR) imagery to guide the transfer. To\nprovide a high temporal resolution, the core data of our monitoring method\ncomprised multi-modal Synthetic Aperture Radar (SAR) and optical multispectral\nobservations from Sentinel 1 and Sentinel 2, respectively.\n  We chose a practical application of our methods for monitoring urban-related\nchanges in the city of Mariupol in Ukraine during the beginning of the\nRusso-Ukrainian War in 2022/23. During this conflict, availability of VHR data\nwas limited and hence an inexpensive direct transfer to the years 2022/23 was\nrendered impossible. Instead, a transfer was made for the years 2017-2020 that\nprovided sufficient public and free VHR data with an application of the\ntransferred model in the years late 2021 to mid-2023. It was shown that\ntransferring for the years 2017-2020 with this inexpensive historical VHR data\nenabled monitoring during times of war in 2022/23.\n  An ablation study on the impact of the frequency of observations showed our\nmethod as resilient to even a large loss of observations. However, it also\nindicated that our method, despite the multi-modal input, was more dependent on\noptical observations than SAR observations. Neither the indirect transfer, nor\nthe malfunction of Sentinel 1B had a significant impact on the monitoring\ncapabilities of our method.\n",
                "链接": "https://arxiv.org/abs/2309.08607"
            },
            {
                "文章ID": "39503",
                "标题": "Proceedings of the AI-HRI Symposium at AAAI-FSS 2022",
                "作者": " Zhao Han,  Emmanuel Senft,  Muneeb I. Ahmad,  Shelly Bagchi,  Amir Yazdani,  Jason R. Wilson,  Boyoung Kim,  Ruchen Wen,  Justin W. Hart,  Daniel Hernández García,  Matteo Leonetti,  Ross Mead,  Reuth Mirsky,  Ahalya Prabhakar,  Megan L. Zimmerman",
                "发布日期": "2022-11-30",
                "摘要": "  The Artificial Intelligence (AI) for Human-Robot Interaction (HRI) Symposium\nhas been a successful venue of discussion and collaboration on AI theory and\nmethods aimed at HRI since 2014. This year, after a review of the achievements\nof the AI-HRI community over the last decade in 2021, we are focusing on a\nvisionary theme: exploring the future of AI-HRI. Accordingly, we added a Blue\nSky Ideas track to foster a forward-thinking discussion on future research at\nthe intersection of AI and HRI. As always, we appreciate all contributions\nrelated to any topic on AI/HRI and welcome new researchers who wish to take\npart in this growing community.\n  With the success of past symposia, AI-HRI impacts a variety of communities\nand problems, and has pioneered the discussions in recent trends and interests.\nThis year's AI-HRI Fall Symposium aims to bring together researchers and\npractitioners from around the globe, representing a number of university,\ngovernment, and industry laboratories. In doing so, we hope to accelerate\nresearch in the field, support technology transition and user adoption, and\ndetermine future directions for our group and our research.\n",
                "链接": "https://arxiv.org/abs/2209.14292"
            },
            {
                "文章ID": "59467",
                "标题": "Serious Games and AI: Challenges and Opportunities for Computational\n  Social Science",
                "作者": " Jaime Pérez,  Mario Castro,  Gregorio López",
                "发布日期": "2023-07-06",
                "摘要": "  The video game industry plays an essential role in the entertainment sphere\nof our society. However, from Monopoly to Flight Simulators, serious games have\nalso been appealing tools for learning a new language, conveying values, or\ntraining skills. Furthermore, the resurgence of Artificial Intelligence (AI)\nand data science in the last decade has created a unique opportunity since the\namount of data collected through a game is immense, as is the amount of data\nneeded to feed such AI algorithms. This paper aims to identify relevant\nresearch lines using Serious Games as a novel research tool, especially in\nComputational Social Sciences. To contextualize, we also conduct a\n(non-systematic) literature review of this field. We conclude that the synergy\nbetween games and data can foster the use of AI for good and open up new\nstrategies to empower humanity and support social research with novel\ncomputational tools. We also discuss the challenges and new opportunities that\narise from aspiring to such lofty goals.\n",
                "链接": "https://arxiv.org/abs/2302.00500"
            },
            {
                "文章ID": "119664",
                "标题": "The perpetual motion machine of AI-generated data and the distraction of\n  ChatGPT-as-scientist",
                "作者": " Jennifer Listgarten",
                "发布日期": "2023-12-05",
                "摘要": "  Since ChatGPT works so well, are we on the cusp of solving science with AI?\nIs not AlphaFold2 suggestive that the potential of LLMs in biology and the\nsciences more broadly is limitless? Can we use AI itself to bridge the lack of\ndata in the sciences in order to then train an AI? Herein we present a\ndiscussion of these topics.\n",
                "链接": "https://arxiv.org/abs/2312.00818"
            },
            {
                "文章ID": "108537",
                "标题": "Advancing Perception in Artificial Intelligence through Principles of\n  Cognitive Science",
                "作者": " Palaash Agrawal,  Cheston Tan,  Heena Rathore",
                "发布日期": "2023-10-16",
                "摘要": "  Although artificial intelligence (AI) has achieved many feats at a rapid\npace, there still exist open problems and fundamental shortcomings related to\nperformance and resource efficiency. Since AI researchers benchmark a\nsignificant proportion of performance standards through human intelligence,\ncognitive sciences-inspired AI is a promising domain of research. Studying\ncognitive science can provide a fresh perspective to building fundamental\nblocks in AI research, which can lead to improved performance and efficiency.\nIn this review paper, we focus on the cognitive functions of perception, which\nis the process of taking signals from one's surroundings as input, and\nprocessing them to understand the environment. Particularly, we study and\ncompare its various processes through the lens of both cognitive sciences and\nAI. Through this study, we review all current major theories from various\nsub-disciplines of cognitive science (specifically neuroscience, psychology and\nlinguistics), and draw parallels with theories and techniques from current\npractices in AI. We, hence, present a detailed collection of methods in AI for\nresearchers to build AI systems inspired by cognitive science. Further, through\nthe process of reviewing the state of cognitive-inspired AI, we point out many\ngaps in the current state of AI (with respect to the performance of the human\nbrain), and hence present potential directions for researchers to develop\nbetter perception systems in AI.\n",
                "链接": "https://arxiv.org/abs/2310.08803"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下2023年关于LLM-based Agent的综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "106067",
                "标题": "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with\n  Agent Team Optimization",
                "作者": " Zijun Liu,  Yanzhe Zhang,  Peng Li,  Yang Liu,  Diyi Yang",
                "发布日期": "2023-10-04",
                "摘要": "  Large language model (LLM) agents have been shown effective on a wide range\nof tasks, and by ensembling multiple LLM agents, their performances could be\nfurther improved. Existing approaches employ a fixed set of agents to interact\nwith each other in a static architecture, which limits their generalizability\nto various tasks and requires strong human prior in designing these agents. In\nthis work, we propose to construct a strategic team of agents communicating in\na dynamic interaction architecture based on the task query. Specifically, we\nbuild a framework named Dynamic LLM-Agent Network ($\\textbf{DyLAN}$) for\nLLM-agent collaboration on complicated tasks like reasoning and code\ngeneration. DyLAN enables agents to interact for multiple rounds in a dynamic\narchitecture with inference-time agent selection and an early-stopping\nmechanism to improve performance and efficiency. We further design an automatic\nagent team optimization algorithm based on an unsupervised metric termed\n$\\textit{Agent Importance Score}$, enabling the selection of best agents based\non the contribution each agent makes. Empirically, we demonstrate that DyLAN\nperforms well in both reasoning and code generation tasks with reasonable\ncomputational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and\nHumanEval, respectively, compared to a single execution on GPT-35-turbo. On\nspecific subjects of MMLU, agent team optimization in DyLAN increases accuracy\nby up to 25.0%.\n",
                "链接": "https://arxiv.org/abs/2310.02170"
            },
            {
                "文章ID": "110807",
                "标题": "LLM-Based Agent Society Investigation: Collaboration and Confrontation\n  in Avalon Gameplay",
                "作者": " Yihuai Lan,  Zhiqiang Hu,  Lei Wang,  Yang Wang,  Deheng Ye,  Peilin Zhao,  Ee-Peng Lim,  Hui Xiong,  Hao Wang",
                "发布日期": "2023-10-24",
                "摘要": "  This paper aims to investigate the open research problem of uncovering the\nsocial behaviors of LLM-based agents. To achieve this goal, we adopt Avalon, a\nrepresentative communication game, as the environment and use system prompts to\nguide LLM agents to play the game. While previous studies have conducted\npreliminary investigations into gameplay with LLM agents, there lacks research\non their social behaviors. In this paper, we present a novel framework designed\nto seamlessly adapt to Avalon gameplay. The core of our proposed framework is a\nmulti-agent system that enables efficient communication and interaction among\nagents. We evaluate the performance of our framework based on metrics from two\nperspectives: winning the game and analyzing the social behaviors of LLM\nagents. Our results demonstrate the effectiveness of our framework in\ngenerating adaptive and intelligent agents and highlight the potential of\nLLM-based agents in addressing the challenges associated with dynamic social\nenvironment interaction. By analyzing the social behaviors of LLM agents from\nthe aspects of both collaboration and confrontation, we provide insights into\nthe research and applications of this domain.\n",
                "链接": "https://arxiv.org/abs/2310.14985"
            },
            {
                "文章ID": "120758",
                "标题": "LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent\n  Ecosystem",
                "作者": " Yingqiang Ge,  Yujie Ren,  Wenyue Hua,  Shuyuan Xu,  Juntao Tan,  Yongfeng Zhang",
                "发布日期": "2023-12-12",
                "摘要": "  This paper envisions a revolutionary AIOS-Agent ecosystem, where Large\nLanguage Model (LLM) serves as the (Artificial) Intelligent Operating System\n(IOS, or AIOS)--an operating system \"with soul\". Upon this foundation, a\ndiverse range of LLM-based AI Agent Applications (Agents, or AAPs) are\ndeveloped, enriching the AIOS-Agent ecosystem and signaling a paradigm shift\nfrom the traditional OS-APP ecosystem. We envision that LLM's impact will not\nbe limited to the AI application level, instead, it will in turn revolutionize\nthe design and implementation of computer system, architecture, software, and\nprogramming language, featured by several main concepts: LLM as OS\n(system-level), Agents as Applications (application-level), Natural Language as\nProgramming Interface (user-level), and Tools as Devices/Libraries\n(hardware/middleware-level). We begin by introducing the architecture of\ntraditional OS. Then we formalize a conceptual framework for AIOS through \"LLM\nas OS (LLMOS)\", drawing analogies between AIOS and traditional OS: LLM is\nlikened to OS kernel, context window to memory, external storage to file\nsystem, hardware tools to peripheral devices, software tools to programming\nlibraries, and user prompts to user commands. Subsequently, we introduce the\nnew AIOS-Agent Ecosystem, where users can easily program Agent Applications\n(AAPs) using natural language, democratizing the development of software, which\nis different from the traditional OS-APP ecosystem. Following this, we explore\nthe diverse scope of Agent Applications. We delve into both single-agent and\nmulti-agent systems, as well as human-agent interaction. Lastly, drawing on the\ninsights from traditional OS-APP ecosystem, we propose a roadmap for the\nevolution of the AIOS-Agent ecosystem. This roadmap is designed to guide the\nfuture research and development, suggesting systematic progresses of AIOS and\nits Agent applications.\n",
                "链接": "https://arxiv.org/abs/2312.03815"
            },
            {
                "文章ID": "118628",
                "标题": "Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld",
                "作者": " Yijun Yang,  Tianyi Zhou,  Kanxue Li,  Dapeng Tao,  Lusong Li,  Li Shen,  Xiaodong He,  Jing Jiang,  Yuhui Shi",
                "发布日期": "2023-11-29",
                "摘要": "  While large language models (LLMs) excel in a simulated world of texts, they\nstruggle to interact with the more realistic world without perceptions of other\nmodalities such as visual or audio signals. Although vision-language models\n(VLMs) integrate LLM modules (1) aligned with static image features, and (2)\nmay possess prior knowledge of world dynamics (as demonstrated in the text\nworld), they have not been trained in an embodied visual world and thus cannot\nalign with its dynamics. On the other hand, training an embodied agent in a\nnoisy visual world without expert guidance is often challenging and\ninefficient. In this paper, we train a VLM agent living in a visual world using\nan LLM agent excelling in a parallel text world (but inapplicable to the visual\nworld). Specifically, we distill LLM's reflection outcomes (improved actions by\nanalyzing mistakes) in a text world's tasks to finetune the VLM on the same\ntasks of the visual world, resulting in an Embodied Multi-Modal Agent (EMMA)\nquickly adapting to the visual world dynamics. Such cross-modality imitation\nlearning between the two parallel worlds enables EMMA to generalize to a broad\nscope of new tasks without any further guidance from the LLM expert. Extensive\nevaluations on the ALFWorld benchmark highlight EMMA's superior performance to\nSOTA VLM-based agents across diverse tasks, e.g., 20%-70% improvement in the\nsuccess rate.\n",
                "链接": "https://arxiv.org/abs/2311.16714"
            },
            {
                "文章ID": "102166",
                "标题": "LASER: LLM Agent with State-Space Exploration for Web Navigation",
                "作者": " Kaixin Ma,  Hongming Zhang,  Hongwei Wang,  Xiaoman Pan,  Dong Yu",
                "发布日期": "2023-09-18",
                "摘要": "  Large language models (LLMs) have been successfully adapted for interactive\ndecision-making tasks like web navigation. While achieving decent performance,\nprevious methods implicitly assume a forward-only execution mode for the model,\nwhere they only provide oracle trajectories as in-context examples to teach the\nmodel how to reason in the interactive environment. Consequently, the model\ncould not handle more challenging scenarios not covered in the in-context\nexamples, e.g., mistakes, leading to sub-optimal performance. To address this\nissue, we propose to model the interactive task as state space exploration,\nwhere the LLM agent transitions among a pre-defined set of states by performing\nactions to complete the task. This formulation enables flexible back-tracking,\nallowing the model to easily recover from errors. We evaluate our proposed LLM\nAgent with State-Space ExploRation (LASER) on the WebShop task. Experimental\nresults show that our LASER agent significantly outperforms previous methods\nand closes the gap with human performance on the web navigation task.\n",
                "链接": "https://arxiv.org/abs/2309.08172"
            },
            {
                "文章ID": "117600",
                "标题": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and\n  Character Design",
                "作者": " Yangyang Yu,  Haohang Li,  Zhi Chen,  Yuechen Jiang,  Yang Li,  Denghui Zhang,  Rong Liu,  Jordan W. Suchow,  Khaldoun Khashanah",
                "发布日期": "2023-12-05",
                "摘要": "  Recent advancements in Large Language Models (LLMs) have exhibited notable\nefficacy in question-answering (QA) tasks across diverse domains. Their prowess\nin integrating extensive web knowledge has fueled interest in developing\nLLM-based autonomous agents. While LLMs are efficient in decoding human\ninstructions and deriving solutions by holistically processing historical\ninputs, transitioning to purpose-driven agents requires a supplementary\nrational architecture to process multi-source information, establish reasoning\nchains, and prioritize critical tasks. Addressing this, we introduce\n\\textsc{FinMem}, a novel LLM-based agent framework devised for financial\ndecision-making. It encompasses three core modules: Profiling, to customize the\nagent's characteristics; Memory, with layered message processing, to aid the\nagent in assimilating hierarchical financial data; and Decision-making, to\nconvert insights gained from memories into investment decisions. Notably,\n\\textsc{FinMem}'s memory module aligns closely with the cognitive structure of\nhuman traders, offering robust interpretability and real-time tuning. Its\nadjustable cognitive span allows for the retention of critical information\nbeyond human perceptual limits, thereby enhancing trading outcomes. This\nframework enables the agent to self-evolve its professional knowledge, react\nagilely to new investment cues, and continuously refine trading decisions in\nthe volatile financial environment. We first compare \\textsc{FinMem} with\nvarious algorithmic agents on a scalable real-world financial dataset,\nunderscoring its leading trading performance in stocks. We then fine-tuned the\nagent's perceptual span and character setting to achieve a significantly\nenhanced trading performance. Collectively, \\textsc{FinMem} presents a\ncutting-edge LLM agent framework for automated trading, boosting cumulative\ninvestment returns.\n",
                "链接": "https://arxiv.org/abs/2311.13743"
            },
            {
                "文章ID": "108435",
                "标题": "Formally Specifying the High-Level Behavior of LLM-Based Agents",
                "作者": " Maxwell Crouse,  Ibrahim Abdelaziz,  Kinjal Basu,  Soham Dan,  Sadhana Kumaravel,  Achille Fokoue,  Pavan Kapanipathi,  Luis Lastras",
                "发布日期": "2023-10-13",
                "摘要": "  LLM-based agents have recently emerged as promising tools for solving\nchallenging problems without the need for task-specific finetuned models that\ncan be expensive to procure. Currently, the design and implementation of such\nagents is ad hoc, as the wide variety of tasks that LLM-based agents may be\napplied to naturally means there can be no one-size-fits-all approach to agent\ndesign. In this work we aim to alleviate the difficulty of designing and\nimplementing new agents by proposing a minimalistic, high-level generation\nframework that simplifies the process of building agents. The framework we\nintroduce allows the user to specify desired agent behaviors in Linear Temporal\nLogic (LTL). The declarative LTL specification is then used to construct a\nconstrained decoder that guarantees the LLM will produce an output exhibiting\nthe desired behavior. By designing our framework in this way, we obtain several\nbenefits, including the ability to enforce complex agent behavior, the ability\nto formally validate prompt examples, and the ability to seamlessly incorporate\ncontent-focused logical constraints into generation. In particular, our\ndeclarative approach, in which the desired behavior is simply described without\nconcern for how it should be implemented or enforced, enables rapid design,\nimplementation and experimentation with different LLM-based agents. We\ndemonstrate how the proposed framework can be used to implement recent\nLLM-based agents, and show how the guardrails our approach provides can lead to\nimprovements in agent performance. In addition, we release our code for general\nuse.\n",
                "链接": "https://arxiv.org/abs/2310.08535"
            },
            {
                "文章ID": "83996",
                "标题": "Enabling Intelligent Interactions between an Agent and an LLM: A\n  Reinforcement Learning Approach",
                "作者": " Bin Hu,  Chenyang Zhao,  Pu Zhang,  Zihao Zhou,  Yuanhang Yang,  Zenglin Xu,  Bin Liu",
                "发布日期": "2023-09-01",
                "摘要": "  Large language models (LLMs) encode a vast amount of world knowledge acquired\nfrom massive text datasets. Recent studies have demonstrated that LLMs can\nassist an embodied agent in solving complex sequential decision making tasks by\nproviding high-level instructions. However, interactions with LLMs can be\ntime-consuming. In many practical scenarios, they require a significant amount\nof storage space that can only be deployed on remote cloud server nodes.\nAdditionally, using commercial LLMs can be costly since they may charge based\non usage frequency. In this paper, we explore how to enable intelligent\ncost-effective interactions between the agent and an LLM. We propose When2Ask,\na reinforcement learning based approach that learns when it is necessary to\nquery LLMs for high-level instructions to accomplish a target task. Experiments\non MiniGrid and Habitat environments that entail planning sub-goals demonstrate\nthat When2Ask learns to solve target tasks with only a few necessary\ninteractions with an LLM, and significantly reduces interaction costs in\ntesting environments compared with baseline methods. Experiment results also\nsuggest that by learning a mediator model to interact with the LLM, the agent's\nperformance becomes more robust against partial observability of the\nenvironment. Our code is available at https://github.com/ZJLAB-AMMI/LLM4RL.\n",
                "链接": "https://arxiv.org/abs/2306.03604"
            },
            {
                "文章ID": "122965",
                "标题": "ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent",
                "作者": " Renat Aksitov,  Sobhan Miryoosefi,  Zonglin Li,  Daliang Li,  Sheila Babayan,  Kavya Kopparapu,  Zachary Fisher,  Ruiqi Guo,  Sushant Prakash,  Pranesh Srinivasan,  Manzil Zaheer,  Felix Yu,  Sanjiv Kumar",
                "发布日期": "2023-12-18",
                "摘要": "  Answering complex natural language questions often necessitates multi-step\nreasoning and integrating external information. Several systems have combined\nknowledge retrieval with a large language model (LLM) to answer such questions.\nThese systems, however, suffer from various failure cases, and we cannot\ndirectly train them end-to-end to fix such failures, as interaction with\nexternal knowledge is non-differentiable. To address these deficiencies, we\ndefine a ReAct-style LLM agent with the ability to reason and act upon external\nknowledge. We further refine the agent through a ReST-like method that\niteratively trains on previous trajectories, employing growing-batch\nreinforcement learning with AI feedback for continuous self-improvement and\nself-distillation. Starting from a prompted large model and after just two\niterations of the algorithm, we can produce a fine-tuned small model that\nachieves comparable performance on challenging compositional question-answering\nbenchmarks with two orders of magnitude fewer parameters.\n",
                "链接": "https://arxiv.org/abs/2312.10003"
            },
            {
                "文章ID": "106611",
                "标题": "Balancing Autonomy and Alignment: A Multi-Dimensional Taxonomy for\n  Autonomous LLM-powered Multi-Agent Architectures",
                "作者": " Thorsten Händler",
                "发布日期": "2023-10-06",
                "摘要": "  Large language models (LLMs) have revolutionized the field of artificial\nintelligence, endowing it with sophisticated language understanding and\ngeneration capabilities. However, when faced with more complex and\ninterconnected tasks that demand a profound and iterative thought process, LLMs\nreveal their inherent limitations. Autonomous LLM-powered multi-agent systems\nrepresent a strategic response to these challenges. Such systems strive for\nautonomously tackling user-prompted goals by decomposing them into manageable\ntasks and orchestrating their execution and result synthesis through a\ncollective of specialized intelligent agents. Equipped with LLM-powered\nreasoning capabilities, these agents harness the cognitive synergy of\ncollaborating with their peers, enhanced by leveraging contextual resources\nsuch as tools and datasets. While these architectures hold promising potential\nin amplifying AI capabilities, striking the right balance between different\nlevels of autonomy and alignment remains the crucial challenge for their\neffective operation. This paper proposes a comprehensive multi-dimensional\ntaxonomy, engineered to analyze how autonomous LLM-powered multi-agent systems\nbalance the dynamic interplay between autonomy and alignment across various\naspects inherent to architectural viewpoints such as goal-driven task\nmanagement, agent composition, multi-agent collaboration, and context\ninteraction. It also includes a domain-ontology model specifying fundamental\narchitectural concepts. Our taxonomy aims to empower researchers, engineers,\nand AI practitioners to systematically analyze the architectural dynamics and\nbalancing strategies employed by these increasingly prevalent AI systems. The\nexploratory taxonomic classification of selected representative LLM-powered\nmulti-agent systems illustrates its practical utility and reveals potential for\nfuture research and development.\n",
                "链接": "https://arxiv.org/abs/2310.03659"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "81153",
                "标题": "Efficient Decoding of Compositional Structure in Holistic\n  Representations",
                "作者": " Denis Kleyko,  Connor Bybee,  Ping-Chen Huang,  Christopher J. Kymn,  Bruno A. Olshausen,  E. Paxon Frady,  Friedrich T. Sommer",
                "发布日期": "2023-05-29",
                "摘要": "  We investigate the task of retrieving information from compositional\ndistributed representations formed by Hyperdimensional Computing/Vector\nSymbolic Architectures and present novel techniques which achieve new\ninformation rate bounds. First, we provide an overview of the decoding\ntechniques that can be used to approach the retrieval task. The techniques are\ncategorized into four groups. We then evaluate the considered techniques in\nseveral settings that involve, e.g., inclusion of external noise and storage\nelements with reduced precision. In particular, we find that the decoding\ntechniques from the sparse coding and compressed sensing literature (rarely\nused for Hyperdimensional Computing/Vector Symbolic Architectures) are also\nwell-suited for decoding information from the compositional distributed\nrepresentations. Combining these decoding techniques with interference\ncancellation ideas from communications improves previously reported bounds\n(Hersche et al., 2021) of the information rate of the distributed\nrepresentations from 1.20 to 1.40 bits per dimension for smaller codebooks and\nfrom 0.60 to 1.26 bits per dimension for larger codebooks.\n",
                "链接": "https://arxiv.org/abs/2305.16873"
            },
            {
                "文章ID": "17492",
                "标题": "Quality-Aware Decoding for Neural Machine Translation",
                "作者": " Patrick Fernandes,  António Farinhas,  Ricardo Rei,  José G. C. de Souza,  Perez Ogayo,  Graham Neubig,  André F. T. Martins",
                "发布日期": "2022-05-03",
                "摘要": "  Despite the progress in machine translation quality estimation and evaluation\nin the last years, decoding in neural machine translation (NMT) is mostly\noblivious to this and centers around finding the most probable translation\naccording to the model (MAP decoding), approximated with beam search. In this\npaper, we bring together these two lines of research and propose quality-aware\ndecoding for NMT, by leveraging recent breakthroughs in reference-free and\nreference-based MT evaluation through various inference methods like $N$-best\nreranking and minimum Bayes risk decoding. We perform an extensive comparison\nof various possible candidate generation and ranking methods across four\ndatasets and two model classes and find that quality-aware decoding\nconsistently outperforms MAP-based decoding according both to state-of-the-art\nautomatic metrics (COMET and BLEURT) and to human assessments. Our code is\navailable at https://github.com/deep-spin/qaware-decode.\n",
                "链接": "https://arxiv.org/abs/2205.00978"
            },
            {
                "文章ID": "115879",
                "标题": "Speculative Contrastive Decoding",
                "作者": " Hongyi Yuan,  Keming Lu,  Fei Huang,  Zheng Yuan,  Chang Zhou",
                "发布日期": "2023-11-16",
                "摘要": "  Large language models (LLMs) have shown extraordinary performance in various\nlanguage tasks, but high computational requirements hinder their widespread\ndeployment. Speculative decoding, which uses amateur models to predict the\ngeneration of expert models, has been proposed as a way to accelerate LLM\ninference. However, speculative decoding focuses on acceleration instead of\nmaking the best use of the token distribution from amateur models. We proposed\nSpeculative Contrastive Decoding (SCD), an accelerated decoding method\nleveraging the natural contrast between expert and amateur models in\nspeculative decoding. Comprehensive evaluations on four benchmarks show that\nSCD can achieve similar acceleration factors as speculative decoding while\nfurther improving the generation quality as the contrastive decoding. The\nanalysis of token probabilities further demonstrates the compatibility between\nspeculative and contrastive decoding. Overall, SCD provides an effective\napproach to enhance the decoding quality of LLMs while saving computational\nresources.\n",
                "链接": "https://arxiv.org/abs/2311.08981"
            },
            {
                "文章ID": "90598",
                "标题": "Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM\n  Decoding",
                "作者": " Seongjun Yang,  Gibbeum Lee,  Jaewoong Cho,  Dimitris Papailiopoulos,  Kangwook Lee",
                "发布日期": "2023-07-13",
                "摘要": "  This paper presents \"Predictive Pipelined Decoding (PPD),\" an approach that\nspeeds up greedy decoding in Large Language Models (LLMs) while maintaining the\nexact same output as the original decoding. Unlike conventional strategies, PPD\nemploys additional compute resources to parallelize the initiation of\nsubsequent token decoding during the current token decoding. This innovative\nmethod reduces decoding latency and reshapes the understanding of trade-offs in\nLLM decoding strategies. We have developed a theoretical framework that allows\nus to analyze the trade-off between computation and latency. Using this\nframework, we can analytically estimate the potential reduction in latency\nassociated with our proposed method, achieved through the assessment of the\nmatch rate, represented as p_correct. The results demonstrate that the use of\nextra computational resources has the potential to accelerate LLM greedy\ndecoding.\n",
                "链接": "https://arxiv.org/abs/2307.05908"
            },
            {
                "文章ID": "65506",
                "标题": "Stealing the Decoding Algorithms of Language Models",
                "作者": " Ali Naseh,  Kalpesh Krishna,  Mohit Iyyer,  Amir Houmansadr",
                "发布日期": "2023-12-05",
                "摘要": "  A key component of generating text from modern language models (LM) is the\nselection and tuning of decoding algorithms. These algorithms determine how to\ngenerate text from the internal probability distribution generated by the LM.\nThe process of choosing a decoding algorithm and tuning its hyperparameters\ntakes significant time, manual effort, and computation, and it also requires\nextensive human evaluation. Therefore, the identity and hyperparameters of such\ndecoding algorithms are considered to be extremely valuable to their owners. In\nthis work, we show, for the first time, that an adversary with typical API\naccess to an LM can steal the type and hyperparameters of its decoding\nalgorithms at very low monetary costs. Our attack is effective against popular\nLMs used in text generation APIs, including GPT-2, GPT-3 and GPT-Neo. We\ndemonstrate the feasibility of stealing such information with only a few\ndollars, e.g., $\\$0.8$, $\\$1$, $\\$4$, and $\\$40$ for the four versions of\nGPT-3.\n",
                "链接": "https://arxiv.org/abs/2303.04729"
            },
            {
                "文章ID": "90734",
                "标题": "A Comprehensive Overview of Large Language Models",
                "作者": " Humza Naveed,  Asad Ullah Khan,  Shi Qiu,  Muhammad Saqib,  Saeed Anwar,  Muhammad Usman,  Naveed Akhtar,  Nick Barnes,  Ajmal Mian",
                "发布日期": "2023-12-29",
                "摘要": "  Large Language Models (LLMs) have recently demonstrated remarkable\ncapabilities in natural language processing tasks and beyond. This success of\nLLMs has led to a large influx of research contributions in this direction.\nThese works encompass diverse topics such as architectural innovations, better\ntraining strategies, context length improvements, fine-tuning, multi-modal\nLLMs, robotics, datasets, benchmarking, efficiency, and more. With the rapid\ndevelopment of techniques and regular breakthroughs in LLM research, it has\nbecome considerably challenging to perceive the bigger picture of the advances\nin this direction. Considering the rapidly emerging plethora of literature on\nLLMs, it is imperative that the research community is able to benefit from a\nconcise yet comprehensive overview of the recent developments in this field.\nThis article provides an overview of the existing literature on a broad range\nof LLM-related concepts. Our self-contained comprehensive overview of LLMs\ndiscusses relevant background concepts along with covering the advanced topics\nat the frontier of research in LLMs. This review article is intended to not\nonly provide a systematic survey but also a quick comprehensive reference for\nthe researchers and practitioners to draw insights from extensive informative\nsummaries of the existing works to advance the LLM research.\n",
                "链接": "https://arxiv.org/abs/2307.06435"
            },
            {
                "文章ID": "34916",
                "标题": "Decoding speech perception from non-invasive brain recordings",
                "作者": " Alexandre Défossez,  Charlotte Caucheteux,  Jérémy Rapin,  Ori Kabeli,  Jean-Rémi King",
                "发布日期": "2023-10-06",
                "摘要": "  Decoding speech from brain activity is a long-awaited goal in both healthcare\nand neuroscience. Invasive devices have recently led to major milestones in\nthat regard: deep learning algorithms trained on intracranial recordings now\nstart to decode elementary linguistic features (e.g. letters, words,\nspectrograms). However, extending this approach to natural speech and\nnon-invasive brain recordings remains a major challenge. Here, we introduce a\nmodel trained with contrastive-learning to decode self-supervised\nrepresentations of perceived speech from the non-invasive recordings of a large\ncohort of healthy individuals. To evaluate this approach, we curate and\nintegrate four public datasets, encompassing 175 volunteers recorded with\nmagneto- or electro-encephalography (M/EEG), while they listened to short\nstories and isolated sentences. The results show that our model can identify,\nfrom 3 seconds of MEG signals, the corresponding speech segment with up to 41%\naccuracy out of more than 1,000 distinct possibilities on average across\nparticipants, and more than 80% in the very best participants - a performance\nthat allows the decoding of words and phrases absent from the training set. The\ncomparison of our model to a variety of baselines highlights the importance of\n(i) a contrastive objective, (ii) pretrained representations of speech and\n(iii) a common convolutional architecture simultaneously trained across\nmultiple participants. Finally, the analysis of the decoder's predictions\nsuggests that they primarily depend on lexical and contextual semantic\nrepresentations. Overall, this effective decoding of perceived speech from\nnon-invasive recordings delineates a promising path to decode language from\nbrain activity, without putting patients at risk for brain surgery.\n",
                "链接": "https://arxiv.org/abs/2208.12266"
            },
            {
                "文章ID": "44092",
                "标题": "Video Summarization Overview",
                "作者": " Mayu Otani,  Yale Song,  Yang Wang",
                "发布日期": "2022-10-24",
                "摘要": "  With the broad growth of video capturing devices and applications on the web,\nit is more demanding to provide desired video content for users efficiently.\nVideo summarization facilitates quickly grasping video content by creating a\ncompact summary of videos. Much effort has been devoted to automatic video\nsummarization, and various problem settings and approaches have been proposed.\nOur goal is to provide an overview of this field. This survey covers early\nstudies as well as recent approaches which take advantage of deep learning\ntechniques. We describe video summarization approaches and their underlying\nconcepts. We also discuss benchmarks and evaluations. We overview how prior\nwork addressed evaluation and detail the pros and cons of the evaluation\nprotocols. Last but not least, we discuss open challenges in this field.\n",
                "链接": "https://arxiv.org/abs/2210.11707"
            },
            {
                "文章ID": "98789",
                "标题": "A Comparison of Neural Networks for Wireless Channel Prediction",
                "作者": " Oscar Stenhammar,  Gabor Fodor,  Carlo Fischione",
                "发布日期": "2023-08-29",
                "摘要": "  The performance of modern wireless communications systems depends critically\non the quality of the available channel state information (CSI) at the\ntransmitter and receiver. Several previous works have proposed concepts and\nalgorithms that help maintain high quality CSI even in the presence of high\nmobility and channel aging, such as temporal prediction schemes that employ\nneural networks. However, it is still unclear which neural network-based scheme\nprovides the best performance in terms of prediction quality, training\ncomplexity and practical feasibility. To investigate such a question, this\npaper first provides an overview of state-of-the-art neural networks applicable\nto channel prediction and compares their performance in terms of prediction\nquality. Next, a new comparative analysis is proposed for four promising neural\nnetworks with different prediction horizons. The well-known tapped delay\nchannel model recommended by the Third Generation Partnership Program is used\nfor a standardized comparison among the neural networks. Based on this\ncomparative evaluation, the advantages and disadvantages of each neural network\nare discussed and guidelines for selecting the best-suited neural network in\nchannel prediction applications are given.\n",
                "链接": "https://arxiv.org/abs/2308.14020"
            },
            {
                "文章ID": "31238",
                "标题": "AccuStripes: Adaptive Binning for the Visual Comparison of Univariate\n  Data Distributions",
                "作者": " Anja Heim,  Eduard Gröller,  Christoph Heinzl",
                "发布日期": "2022-09-07",
                "摘要": "  Understanding and comparing distributions of data (e.g., regarding their\nmodes, shapes, or outliers) is a common challenge in many scientific\ndisciplines. Typically, this challenge is addressed using side-by-side\ncomparisons of histograms or density plots. However, comparing multiple density\nplots is mentally demanding. Uniform histograms often represent distributions\nimprecisely since missing values, outliers, or modes are hidden by a grouping\nof equal size. In this paper, a novel type of overview visualization for the\ncomparison of univariate data distributions is presented: AccuStripes (i.e.,\naccumulated stripes) is a new visual metaphor encoding accumulations of data\ndistributions according to adaptive binning using color coded stripes of\nirregular width. We provide detailed insights about challenges of binning.\nSpecifically, we explore different adaptive binning concepts such as Bayesian\nBlocks binning and Jenks Natural Breaks binning for the computation of binning\nboundaries, in terms of their capabilities to represent the datasets as\naccurately as possible. In addition, we discuss issues arising with the\nrepresentation of designs for the comparative visualization of distributions:\nTo allow for a comparison of many distributions, their accumulated\nrepresentations are plotted below each other in a stacked mode. Based on our\nfindings, we propose three different layouts for comparative visualization of\nmultiple distributions. The usefulness of AccuStripes is investigated using a\nstatistical evaluation of the binning methods. Using a similarity metric from\ncluster analysis, it is shown, which binning method statistically yields the\nbest grouping results. Through a user study we evaluate, which binning strategy\nvisually represents the distribution in the most intuitive form and\ninvestigate, which layout allows the user the comparison of many distributions\nin the most effortless way.\n",
                "链接": "https://arxiv.org/abs/2207.13663"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近三个月有关语言模型rlhf的arxiv上的全部文章。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大模型结合树搜索方法进行推理的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "2023年以后关于通过prompt经验性研究大语言模型行为的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找多模态大模型理解和生成统一建模、端到端训练相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下近两年关于语言模型奖励建模评估的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105659",
                "标题": "Tool-Augmented Reward Modeling",
                "作者": " Lei Li,  Yekun Chai,  Shuohuan Wang,  Yu Sun,  Hao Tian,  Ningyu Zhang,  Hua Wu",
                "发布日期": "2023-10-03",
                "摘要": "  Reward modeling (a.k.a., preference modeling) is instrumental for aligning\nlarge language models with human preferences, particularly within the context\nof reinforcement learning from human feedback (RLHF). While conventional reward\nmodels (RMs) have exhibited remarkable scalability, they oft struggle with\nfundamental functionality such as arithmetic computation, code execution, and\nfactual lookup. In this paper, we propose a tool-augmented preference modeling\napproach, named \\name, to address these limitations by empowering RMs with\naccess to external environments, including calculators and search engines. This\napproach not only fosters synergy between tool utilization and reward grading\nbut also enhances interpretive capacity and scoring reliability. Our study\ndelves into the integration of external tools into RMs, enabling them to\ninteract with diverse external sources and construct task-specific tool\nengagement and reasoning traces in an autoregressive manner. We validate our\napproach across a wide range of domains, incorporating seven distinct external\ntools. Our experimental results demonstrate a noteworthy overall improvement of\n17.7% across eight tasks in preference ranking. Furthermore, our approach\noutperforms Gopher 280B by 7.3% on TruthfulQA task in zero-shot evaluation. In\nhuman evaluations, RLHF trained with Themis attains an average win rate of 32%\nwhen compared to baselines across four distinct tasks. Additionally, we provide\na comprehensive collection of tool-related RM datasets, incorporating data from\nseven distinct tool APIs, totaling 15,000 instances. We anticipate that this\npublicly available dataset will facilitate and inspire further research\nadvancements in the field.\n",
                "链接": "https://arxiv.org/abs/2310.01045"
            },
            {
                "文章ID": "6241",
                "标题": "Reward Modeling for Mitigating Toxicity in Transformer-based Language\n  Models",
                "作者": " Farshid Faal,  Ketra Schmitt,  Jia Yuan Yu",
                "发布日期": "2022-07-28",
                "摘要": "  Transformer-based language models are able to generate fluent text and be\nefficiently adapted across various natural language generation tasks. However,\nlanguage models that are pretrained on large unlabeled web text corpora have\nbeen shown to suffer from degenerating toxic content and social bias behaviors,\nconsequently hindering their safe deployment. Various detoxification methods\nwere proposed to mitigate the language model's toxicity; however, these methods\nstruggled to detoxify language models when conditioned on prompts that contain\nspecific social identities related to gender, race, or religion. In this study,\nwe propose Reinforce-Detoxify; A reinforcement learning-based method for\nmitigating toxicity in language models. We address the challenge of safety in\nlanguage models and propose a new reward model that is able to detect toxic\ncontent and mitigate unintended bias towards social identities in toxicity\nprediction. The experiments demonstrate that the Reinforce-Detoxify method for\nlanguage model detoxification outperforms existing detoxification approaches in\nautomatic evaluation metrics, indicating the ability of our approach in\nlanguage model detoxification and less prone to unintended bias toward social\nidentities in generated content.\n",
                "链接": "https://arxiv.org/abs/2202.09662"
            },
            {
                "文章ID": "58975",
                "标题": "Direct Preference-based Policy Optimization without Reward Modeling",
                "作者": " Gaon An,  Junhyeok Lee,  Xingdong Zuo,  Norio Kosaka,  Kyung-Min Kim,  Hyun Oh Song",
                "发布日期": "2023-10-30",
                "摘要": "  Preference-based reinforcement learning (PbRL) is an approach that enables RL\nagents to learn from preference, which is particularly useful when formulating\na reward function is challenging. Existing PbRL methods generally involve a\ntwo-step procedure: they first learn a reward model based on given preference\ndata and then employ off-the-shelf reinforcement learning algorithms using the\nlearned reward model. However, obtaining an accurate reward model solely from\npreference information, especially when the preference is from human teachers,\ncan be difficult. Instead, we propose a PbRL algorithm that directly learns\nfrom preference without requiring any reward modeling. To achieve this, we\nadopt a contrastive learning framework to design a novel policy scoring metric\nthat assigns a high score to policies that align with the given preferences. We\napply our algorithm to offline RL tasks with actual human preference labels and\nshow that our algorithm outperforms or is on par with the existing PbRL\nmethods. Notably, on high-dimensional control tasks, our algorithm surpasses\noffline RL methods that learn with ground-truth reward information. Finally, we\nshow that our algorithm can be successfully applied to fine-tune large language\nmodels.\n",
                "链接": "https://arxiv.org/abs/2301.12842"
            },
            {
                "文章ID": "108780",
                "标题": "Reward-Augmented Decoding: Efficient Controlled Text Generation With a\n  Unidirectional Reward Model",
                "作者": " Haikang Deng,  Colin Raffel",
                "发布日期": "2023-10-30",
                "摘要": "  While large language models have proven effective in a huge range of\ndownstream applications, they often generate text that is problematic or lacks\na desired attribute. In this paper, we introduce Reward-Augmented Decoding\n(RAD), a text generation procedure that uses a small unidirectional reward\nmodel to encourage a language model to generate text that has certain\nproperties. Specifically, RAD uses the reward model to score generations as\nthey are produced and rescales sampling probabilities to favor high-reward\ntokens. By using a unidirectional reward model, RAD can cache activations from\nprior generation steps to decrease computational overhead. Through experiments\non generating non-toxic and sentiment-controlled text, we demonstrate that RAD\nperforms best among methods that change only the generation procedure and\nmatches the performance of state-of-the-art methods that involve re-training\nthe language model. We further validate that RAD is effective on very large\nlanguage models while incurring a minimal computational overhead.\n",
                "链接": "https://arxiv.org/abs/2310.09520"
            },
            {
                "文章ID": "122681",
                "标题": "Helping or Herding? Reward Model Ensembles Mitigate but do not Eliminate\n  Reward Hacking",
                "作者": " Jacob Eisenstein,  Chirag Nagpal,  Alekh Agarwal,  Ahmad Beirami,  Alex D'Amour,  DJ Dvijotham,  Adam Fisch,  Katherine Heller,  Stephen Pfohl,  Deepak Ramachandran,  Peter Shaw,  Jonathan Berant",
                "发布日期": "2023-12-22",
                "摘要": "  Reward models play a key role in aligning language model applications towards\nhuman preferences. However, this setup creates an incentive for the language\nmodel to exploit errors in the reward model to achieve high estimated reward, a\nphenomenon often termed \\emph{reward hacking}. A natural mitigation is to train\nan ensemble of reward models, aggregating over model outputs to obtain a more\nrobust reward estimate. We explore the application of reward ensembles to\nalignment at both training time (through reinforcement learning) and inference\ntime (through reranking). First, we show that reward models are\n\\emph{underspecified}: reward models that perform similarly in-distribution can\nyield very different rewards when used in alignment, due to distribution shift.\nSecond, underspecification results in overoptimization, where alignment to one\nreward model does not improve reward as measured by another reward model\ntrained on the same data. Third, overoptimization is mitigated by the use of\nreward ensembles, and ensembles that vary by their \\emph{pretraining} seeds\nlead to better generalization than ensembles that differ only by their\n\\emph{fine-tuning} seeds, with both outperforming individual reward models.\nHowever, even pretrain reward ensembles do not eliminate reward hacking: we\nshow several qualitative reward hacking phenomena that are not mitigated by\nensembling because all reward models in the ensemble exhibit similar error\npatterns.\n",
                "链接": "https://arxiv.org/abs/2312.09244"
            },
            {
                "文章ID": "106830",
                "标题": "Confronting Reward Model Overoptimization with Constrained RLHF",
                "作者": " Ted Moskovitz,  Aaditya K. Singh,  DJ Strouse,  Tuomas Sandholm,  Ruslan Salakhutdinov,  Anca D. Dragan,  Stephen McAleer",
                "发布日期": "2023-10-11",
                "摘要": "  Large language models are typically aligned with human preferences by\noptimizing $\\textit{reward models}$ (RMs) fitted to human feedback. However,\nhuman preferences are multi-faceted, and it is increasingly common to derive\nreward from a composition of simpler reward models which each capture a\ndifferent aspect of language quality. This itself presents a challenge, as it\nis difficult to appropriately weight these component RMs when combining them.\nCompounding this difficulty, because any RM is only a proxy for human\nevaluation, this process is vulnerable to $\\textit{overoptimization}$, wherein\npast a certain point, accumulating higher reward is associated with worse human\nratings. In this paper, we perform, to our knowledge, the first study on\noveroptimization in composite RMs, showing that correlation between component\nRMs has a significant effect on the locations of these points. We then\nintroduce an approach to solve this issue using constrained reinforcement\nlearning as a means of preventing the agent from exceeding each RM's threshold\nof usefulness. Our method addresses the problem of weighting component RMs by\nlearning dynamic weights, naturally expressed by Lagrange multipliers. As a\nresult, each RM stays within the range at which it is an effective proxy,\nimproving evaluation performance. Finally, we introduce an adaptive method\nusing gradient-free optimization to identify and optimize towards these points\nduring a single run.\n",
                "链接": "https://arxiv.org/abs/2310.04373"
            },
            {
                "文章ID": "64063",
                "标题": "Reward Design with Language Models",
                "作者": " Minae Kwon,  Sang Michael Xie,  Kalesha Bullard,  Dorsa Sadigh",
                "发布日期": "2023-03-02",
                "摘要": "  Reward design in reinforcement learning (RL) is challenging since specifying\nhuman notions of desired behavior may be difficult via reward functions or\nrequire many expert demonstrations. Can we instead cheaply design rewards using\na natural language interface? This paper explores how to simplify reward design\nby prompting a large language model (LLM) such as GPT-3 as a proxy reward\nfunction, where the user provides a textual prompt containing a few examples\n(few-shot) or a description (zero-shot) of the desired behavior. Our approach\nleverages this proxy reward function in an RL framework. Specifically, users\nspecify a prompt once at the beginning of training. During training, the LLM\nevaluates an RL agent's behavior against the desired behavior described by the\nprompt and outputs a corresponding reward signal. The RL agent then uses this\nreward to update its behavior. We evaluate whether our approach can train\nagents aligned with user objectives in the Ultimatum Game, matrix games, and\nthe DealOrNoDeal negotiation task. In all three tasks, we show that RL agents\ntrained with our framework are well-aligned with the user's objectives and\noutperform RL agents trained with reward functions learned via supervised\nlearning\n",
                "链接": "https://arxiv.org/abs/2303.00001"
            },
            {
                "文章ID": "110451",
                "标题": "Learning Reward for Physical Skills using Large Language Model",
                "作者": " Yuwei Zeng,  Yiqing Xu",
                "发布日期": "2023-10-24",
                "摘要": "  Learning reward functions for physical skills are challenging due to the vast\nspectrum of skills, the high-dimensionality of state and action space, and\nnuanced sensory feedback. The complexity of these tasks makes acquiring expert\ndemonstration data both costly and time-consuming. Large Language Models (LLMs)\ncontain valuable task-related knowledge that can aid in learning these reward\nfunctions. However, the direct application of LLMs for proposing reward\nfunctions has its limitations such as numerical instability and inability to\nincorporate the environment feedback. We aim to extract task knowledge from\nLLMs using environment feedback to create efficient reward functions for\nphysical skills. Our approach consists of two components. We first use the LLM\nto propose features and parameterization of the reward function. Next, we\nupdate the parameters of this proposed reward function through an iterative\nself-alignment process. In particular, this process minimizes the ranking\ninconsistency between the LLM and our learned reward functions based on the new\nobservations. We validated our method by testing it on three simulated physical\nskill learning tasks, demonstrating effective support for our design choices.\n",
                "链接": "https://arxiv.org/abs/2310.14092"
            },
            {
                "文章ID": "81738",
                "标题": "Direct Preference Optimization: Your Language Model is Secretly a Reward\n  Model",
                "作者": " Rafael Rafailov,  Archit Sharma,  Eric Mitchell,  Stefano Ermon,  Christopher D. Manning,  Chelsea Finn",
                "发布日期": "2023-12-14",
                "摘要": "  While large-scale unsupervised language models (LMs) learn broad world\nknowledge and some reasoning skills, achieving precise control of their\nbehavior is difficult due to the completely unsupervised nature of their\ntraining. Existing methods for gaining such steerability collect human labels\nof the relative quality of model generations and fine-tune the unsupervised LM\nto align with these preferences, often with reinforcement learning from human\nfeedback (RLHF). However, RLHF is a complex and often unstable procedure, first\nfitting a reward model that reflects the human preferences, and then\nfine-tuning the large unsupervised LM using reinforcement learning to maximize\nthis estimated reward without drifting too far from the original model. In this\npaper we introduce a new parameterization of the reward model in RLHF that\nenables extraction of the corresponding optimal policy in closed form, allowing\nus to solve the standard RLHF problem with only a simple classification loss.\nThe resulting algorithm, which we call Direct Preference Optimization (DPO), is\nstable, performant, and computationally lightweight, eliminating the need for\nsampling from the LM during fine-tuning or performing significant\nhyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align\nwith human preferences as well as or better than existing methods. Notably,\nfine-tuning with DPO exceeds PPO-based RLHF in ability to control sentiment of\ngenerations, and matches or improves response quality in summarization and\nsingle-turn dialogue while being substantially simpler to implement and train.\n",
                "链接": "https://arxiv.org/abs/2305.18290"
            },
            {
                "文章ID": "106278",
                "标题": "Reward Model Ensembles Help Mitigate Overoptimization",
                "作者": " Thomas Coste,  Usman Anwar,  Robert Kirk,  David Krueger",
                "发布日期": "2023-10-05",
                "摘要": "  Reinforcement learning from human feedback (RLHF) is a standard approach for\nfine-tuning large language models to follow instructions. As part of this\nprocess, learned reward models are used to approximately model human\npreferences. However, as imperfect representations of the \"true\" reward, these\nlearned reward models are susceptible to \\textit{overoptimization}. Gao et al.\n(2023) studied this phenomenon in a synthetic human feedback setup with a\nsignificantly larger \"gold\" reward model acting as the true reward (instead of\nhumans) and showed that overoptimization remains a persistent problem\nregardless of the size of the proxy reward model and training data used. Using\na similar setup, we conduct a systematic study to evaluate the efficacy of\nusing ensemble-based conservative optimization objectives, specifically\nworst-case optimization (WCO) and uncertainty-weighted optimization (UWO), for\nmitigating reward model overoptimization when using two optimization methods:\n(a) best-of-n sampling (BoN) (b) proximal policy optimization (PPO). We\nadditionally extend the setup of Gao et al. (2023) to include 25% label noise\nto better mirror real-world conditions. Both with and without label noise, we\nfind that conservative optimization practically eliminates overoptimization and\nimproves performance by up to 70% for BoN sampling. For PPO, ensemble-based\nconservative optimization always reduces overoptimization and outperforms\nsingle reward model optimization. Moreover, combining it with a small KL\npenalty successfully prevents overoptimization at no performance cost. Overall,\nour results demonstrate that ensemble-based conservative optimization can\neffectively counter overoptimization.\n",
                "链接": "https://arxiv.org/abs/2310.02743"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到从位置编码角度改善模型长序列建模能力的相关论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "6738",
                "标题": "FastRPB: a Scalable Relative Positional Encoding for Long Sequence Tasks",
                "作者": " Maksim Zubkov,  Daniil Gavrilov",
                "发布日期": "2022-02-24",
                "摘要": "  Transformers achieve remarkable performance in various domains, including\nNLP, CV, audio processing, and graph analysis. However, they do not scale well\non long sequence tasks due to their quadratic complexity w.r.t. the inputs\nlength. Linear Transformers were proposed to address this limitation. However,\nthese models have shown weaker performance on the long sequence tasks comparing\nto the original one. In this paper, we explore Linear Transformer models,\nrethinking their two core components. Firstly, we improved Linear Transformer\nwith Shift-Invariant Kernel Function SIKF, which achieve higher accuracy\nwithout loss in speed. Secondly, we introduce FastRPB which stands for Fast\nRelative Positional Bias, which efficiently adds positional information to\nself-attention using Fast Fourier Transformation. FastRPB is independent of the\nself-attention mechanism and can be combined with an original self-attention\nand all its efficient variants. FastRPB has O(N log(N)) computational\ncomplexity, requiring O(N) memory w.r.t. input sequence length N.\n",
                "链接": "https://arxiv.org/abs/2202.11364"
            },
            {
                "文章ID": "91660",
                "标题": "Linearized Relative Positional Encoding",
                "作者": " Zhen Qin,  Weixuan Sun,  Kaiyue Lu,  Hui Deng,  Dongxu Li,  Xiaodong Han,  Yuchao Dai,  Lingpeng Kong,  Yiran Zhong",
                "发布日期": "2023-07-19",
                "摘要": "  Relative positional encoding is widely used in vanilla and linear\ntransformers to represent positional information. However, existing encoding\nmethods of a vanilla transformer are not always directly applicable to a linear\ntransformer, because the latter requires a decomposition of the query and key\nrepresentations into separate kernel functions. Nevertheless, principles for\ndesigning encoding methods suitable for linear transformers remain\nunderstudied. In this work, we put together a variety of existing linear\nrelative positional encoding approaches under a canonical form and further\npropose a family of linear relative positional encoding algorithms via unitary\ntransformation. Our formulation leads to a principled framework that can be\nused to develop new relative positional encoding methods that preserve linear\nspace-time complexity. Equipped with different models, the proposed linearized\nrelative positional encoding (LRPE) family derives effective encoding for\nvarious applications. Experiments show that compared with existing methods,\nLRPE achieves state-of-the-art performance in language modeling, text\nclassification, and image classification. Meanwhile, it emphasizes a general\nparadigm for designing broadly more relative positional encoding methods that\nare applicable to linear transformers. The code is available at\nhttps://github.com/OpenNLPLab/Lrpe.\n",
                "链接": "https://arxiv.org/abs/2307.09270"
            },
            {
                "文章ID": "50484",
                "标题": "PIP: Positional-encoding Image Prior",
                "作者": " Nimrod Shabtay,  Eli Schwartz,  Raja Giryes",
                "发布日期": "2023-04-04",
                "摘要": "  In Deep Image Prior (DIP), a Convolutional Neural Network (CNN) is fitted to\nmap a latent space to a degraded (e.g. noisy) image but in the process learns\nto reconstruct the clean image. This phenomenon is attributed to CNN's internal\nimage-prior. We revisit the DIP framework, examining it from the perspective of\na neural implicit representation. Motivated by this perspective, we replace the\nrandom or learned latent with Fourier-Features (Positional Encoding). We show\nthat thanks to the Fourier features properties, we can replace the convolution\nlayers with simple pixel-level MLPs. We name this scheme ``Positional Encoding\nImage Prior\" (PIP) and exhibit that it performs very similarly to DIP on\nvarious image-reconstruction tasks with much less parameters required.\nAdditionally, we demonstrate that PIP can be easily extended to videos, where\n3D-DIP struggles and suffers from instability. Code and additional examples for\nall tasks, including videos, are available on the project page\nhttps://nimrodshabtay.github.io/PIP/\n",
                "链接": "https://arxiv.org/abs/2211.14298"
            },
            {
                "文章ID": "61325",
                "标题": "A Unified View of Long-Sequence Models towards Modeling Million-Scale\n  Dependencies",
                "作者": " Hongyu Hè,  Marko Kabic",
                "发布日期": "2023-02-17",
                "摘要": "  Ever since their conception, Transformers have taken over traditional\nsequence models in many tasks, such as NLP, image classification, and\nvideo/audio processing, for their fast training and superior performance. Much\nof the merit is attributable to positional encoding and multi-head attention.\nHowever, Transformers fall short in learning long-range dependencies mainly due\nto the quadratic complexity scaled with context length, in terms of both time\nand space. Consequently, over the past five years, a myriad of methods has been\nproposed to make Transformers more efficient. In this work, we first take a\nstep back, study and compare existing solutions to long-sequence modeling in\nterms of their pure mathematical formulation. Specifically, we summarize them\nusing a unified template, given their shared nature of token mixing. Through\nbenchmarks, we then demonstrate that long context length does yield better\nperformance, albeit application-dependent, and traditional Transformer models\nfall short in taking advantage of long-range dependencies. Next, inspired by\nemerging sparse models of huge capacity, we propose a machine learning system\nfor handling million-scale dependencies. As a proof of concept, we evaluate the\nperformance of one essential component of this system, namely, the distributed\nmulti-head attention. We show that our algorithm can scale up attention\ncomputation by almost $40\\times$ using four GeForce RTX 4090 GPUs, compared to\nvanilla multi-head attention mechanism. We believe this study is an\ninstrumental step towards modeling million-scale dependencies.\n",
                "链接": "https://arxiv.org/abs/2302.06218"
            },
            {
                "文章ID": "9782",
                "标题": "Efficient Long Sequence Encoding via Synchronization",
                "作者": " Xiangyang Mou,  Mo Yu,  Bingsheng Yao,  Lifu Huang",
                "发布日期": "2022-03-16",
                "摘要": "  Pre-trained Transformer models have achieved successes in a wide range of NLP\ntasks, but are inefficient when dealing with long input sequences. Existing\nstudies try to overcome this challenge via segmenting the long sequence\nfollowed by hierarchical encoding or post-hoc aggregation. We propose a\nsynchronization mechanism for hierarchical encoding. Our approach first\nidentifies anchor tokens across segments and groups them by their roles in the\noriginal input sequence. Then inside Transformer layer, anchor embeddings are\nsynchronized within their group via a self-attention module. Our approach is a\ngeneral framework with sufficient flexibility -- when adapted to a new task, it\nis easy to be enhanced with the task-specific anchor definitions. Experiments\non two representative tasks with different types of long input texts,\nNarrativeQA summary setting and wild multi-hop reasoning from HotpotQA,\ndemonstrate that our approach is able to improve the global information\nexchange among segments while maintaining efficiency.\n",
                "链接": "https://arxiv.org/abs/2203.07644"
            },
            {
                "文章ID": "50009",
                "标题": "Learning Regularized Positional Encoding for Molecular Prediction",
                "作者": " Xiang Gao,  Weihao Gao,  Wenzhi Xiao,  Zhirui Wang,  Chong Wang,  Liang Xiang",
                "发布日期": "2022-11-24",
                "摘要": "  Machine learning has become a promising approach for molecular modeling.\nPositional quantities, such as interatomic distances and bond angles, play a\ncrucial role in molecule physics. The existing works rely on careful manual\ndesign of their representation. To model the complex nonlinearity in predicting\nmolecular properties in an more end-to-end approach, we propose to encode the\npositional quantities with a learnable embedding that is continuous and\ndifferentiable. A regularization technique is employed to encourage embedding\nsmoothness along the physical dimension. We experiment with a variety of\nmolecular property and force field prediction tasks. Improved performance is\nobserved for three different model architectures after plugging in the proposed\npositional encoding method. In addition, the learned positional encoding allows\neasier physics-based interpretation. We observe that tasks of similar physics\nhave the similar learned positional encoding.\n",
                "链接": "https://arxiv.org/abs/2211.12773"
            },
            {
                "文章ID": "3277",
                "标题": "GRPE: Relative Positional Encoding for Graph Transformer",
                "作者": " Wonpyo Park,  Woonggi Chang,  Donggeon Lee,  Juntae Kim,  Seung-won Hwang",
                "发布日期": "2022-10-17",
                "摘要": "  We propose a novel positional encoding for learning graph on Transformer\narchitecture. Existing approaches either linearize a graph to encode absolute\nposition in the sequence of nodes, or encode relative position with another\nnode using bias terms. The former loses preciseness of relative position from\nlinearization, while the latter loses a tight integration of node-edge and\nnode-topology interaction. To overcome the weakness of the previous approaches,\nour method encodes a graph without linearization and considers both\nnode-topology and node-edge interaction. We name our method Graph Relative\nPositional Encoding dedicated to graph representation learning. Experiments\nconducted on various graph datasets show that the proposed method outperforms\nprevious approaches significantly. Our code is publicly available at\nhttps://github.com/lenscloth/GRPE.\n",
                "链接": "https://arxiv.org/abs/2201.12787"
            },
            {
                "文章ID": "45624",
                "标题": "Generalized Laplacian Positional Encoding for Graph Representation\n  Learning",
                "作者": " Sohir Maskey,  Ali Parviz,  Maximilian Thiessen,  Hannes Stärk,  Ylli Sadikaj,  Haggai Maron",
                "发布日期": "2022-11-11",
                "摘要": "  Graph neural networks (GNNs) are the primary tool for processing\ngraph-structured data. Unfortunately, the most commonly used GNNs, called\nMessage Passing Neural Networks (MPNNs) suffer from several fundamental\nlimitations. To overcome these limitations, recent works have adapted the idea\nof positional encodings to graph data. This paper draws inspiration from the\nrecent success of Laplacian-based positional encoding and defines a novel\nfamily of positional encoding schemes for graphs. We accomplish this by\ngeneralizing the optimization problem that defines the Laplace embedding to\nmore general dissimilarity functions rather than the 2-norm used in the\noriginal formulation. This family of positional encodings is then instantiated\nby considering p-norms. We discuss a method for calculating these positional\nencoding schemes, implement it in PyTorch and demonstrate how the resulting\npositional encoding captures different properties of the graph. Furthermore, we\ndemonstrate that this novel family of positional encodings can improve the\nexpressive power of MPNNs. Lastly, we present preliminary experimental results.\n",
                "链接": "https://arxiv.org/abs/2210.15956"
            },
            {
                "文章ID": "82296",
                "标题": "The Impact of Positional Encoding on Length Generalization in\n  Transformers",
                "作者": " Amirhossein Kazemnejad,  Inkit Padhi,  Karthikeyan Natesan Ramamurthy,  Payel Das,  Siva Reddy",
                "发布日期": "2023-11-08",
                "摘要": "  Length generalization, the ability to generalize from small training context\nsizes to larger ones, is a critical challenge in the development of\nTransformer-based language models. Positional encoding (PE) has been identified\nas a major factor influencing length generalization, but the exact impact of\ndifferent PE schemes on extrapolation in downstream tasks remains unclear. In\nthis paper, we conduct a systematic empirical study comparing the length\ngeneralization performance of decoder-only Transformers with five different\nposition encoding approaches including Absolute Position Embedding (APE), T5's\nRelative PE, ALiBi, and Rotary, in addition to Transformers without positional\nencoding (NoPE). Our evaluation encompasses a battery of reasoning and\nmathematical tasks. Our findings reveal that the most commonly used positional\nencoding methods, such as ALiBi, Rotary, and APE, are not well suited for\nlength generalization in downstream tasks. More importantly, NoPE outperforms\nother explicit positional encoding methods while requiring no additional\ncomputation. We theoretically demonstrate that NoPE can represent both absolute\nand relative PEs, but when trained with SGD, it mostly resembles T5's relative\nPE attention patterns. Finally, we find that scratchpad is not always helpful\nto solve length generalization and its format highly impacts the model's\nperformance. Overall, our work suggests that explicit position embeddings are\nnot essential for decoder-only Transformers to generalize well to longer\nsequences.\n",
                "链接": "https://arxiv.org/abs/2305.19466"
            },
            {
                "文章ID": "37058",
                "标题": "Document-aware Positional Encoding and Linguistic-guided Encoding for\n  Abstractive Multi-document Summarization",
                "作者": " Congbo Ma,  Wei Emma Zhang,  Pitawelayalage Dasun Dileepa Pitawela,  Yutong Qu,  Haojie Zhuang,  Hu Wang",
                "发布日期": "2022-09-14",
                "摘要": "  One key challenge in multi-document summarization is to capture the relations\namong input documents that distinguish between single document summarization\n(SDS) and multi-document summarization (MDS). Few existing MDS works address\nthis issue. One effective way is to encode document positional information to\nassist models in capturing cross-document relations. However, existing MDS\nmodels, such as Transformer-based models, only consider token-level positional\ninformation. Moreover, these models fail to capture sentences' linguistic\nstructure, which inevitably causes confusions in the generated summaries.\nTherefore, in this paper, we propose document-aware positional encoding and\nlinguistic-guided encoding that can be fused with Transformer architecture for\nMDS. For document-aware positional encoding, we introduce a general protocol to\nguide the selection of document encoding functions. For linguistic-guided\nencoding, we propose to embed syntactic dependency relations into the\ndependency relation mask with a simple but effective non-linear encoding\nlearner for feature learning. Extensive experiments show the proposed model can\ngenerate summaries with high quality.\n",
                "链接": "https://arxiv.org/abs/2209.05929"
            }
        ]
    },
    {
        "question": {
            "question": "利用大模型做数学题生成的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "111569",
                "标题": "math-PVS: A Large Language Model Framework to Map Scientific\n  Publications to PVS Theories",
                "作者": " Hassen Saidi,  Susmit Jha,  Tuhin Sahai",
                "发布日期": "2023-10-27",
                "摘要": "  As artificial intelligence (AI) gains greater adoption in a wide variety of\napplications, it has immense potential to contribute to mathematical discovery,\nby guiding conjecture generation, constructing counterexamples, assisting in\nformalizing mathematics, and discovering connections between different\nmathematical areas, to name a few.\n  While prior work has leveraged computers for exhaustive mathematical proof\nsearch, recent efforts based on large language models (LLMs) aspire to position\ncomputing platforms as co-contributors in the mathematical research process.\nDespite their current limitations in logic and mathematical tasks, there is\ngrowing interest in melding theorem proving systems with foundation models.\nThis work investigates the applicability of LLMs in formalizing advanced\nmathematical concepts and proposes a framework that can critically review and\ncheck mathematical reasoning in research papers. Given the noted reasoning\nshortcomings of LLMs, our approach synergizes the capabilities of proof\nassistants, specifically PVS, with LLMs, enabling a bridge between textual\ndescriptions in academic papers and formal specifications in PVS. By harnessing\nthe PVS environment, coupled with data ingestion and conversion mechanisms, we\nenvision an automated process, called \\emph{math-PVS}, to extract and formalize\nmathematical theorems from research papers, offering an innovative tool for\nacademic review and discovery.\n",
                "链接": "https://arxiv.org/abs/2310.17064"
            },
            {
                "文章ID": "93990",
                "标题": "Trustworthiness of Children Stories Generated by Large Language Models",
                "作者": " Prabin Bhandari,  Hannah Marie Brennan",
                "发布日期": "2023-08-02",
                "摘要": "  Large Language Models (LLMs) have shown a tremendous capacity for generating\nliterary text. However, their effectiveness in generating children's stories\nhas yet to be thoroughly examined. In this study, we evaluate the\ntrustworthiness of children's stories generated by LLMs using various measures,\nand we compare and contrast our results with both old and new children's\nstories to better assess their significance. Our findings suggest that LLMs\nstill struggle to generate children's stories at the level of quality and\nnuance found in actual stories\n",
                "链接": "https://arxiv.org/abs/2308.00073"
            },
            {
                "文章ID": "72234",
                "标题": "How Useful are Educational Questions Generated by Large Language Models?",
                "作者": " Sabina Elkins,  Ekaterina Kochmar,  Jackie C. K. Cheung,  Iulian Serban",
                "发布日期": "2023-04-14",
                "摘要": "  Controllable text generation (CTG) by large language models has a huge\npotential to transform education for teachers and students alike. Specifically,\nhigh quality and diverse question generation can dramatically reduce the load\non teachers and improve the quality of their educational content. Recent work\nin this domain has made progress with generation, but fails to show that real\nteachers judge the generated questions as sufficiently useful for the classroom\nsetting; or if instead the questions have errors and/or pedagogically unhelpful\ncontent. We conduct a human evaluation with teachers to assess the quality and\nusefulness of outputs from combining CTG and question taxonomies (Bloom's and a\ndifficulty taxonomy). The results demonstrate that the questions generated are\nhigh quality and sufficiently useful, showing their promise for widespread use\nin the classroom setting.\n",
                "链接": "https://arxiv.org/abs/2304.06638"
            },
            {
                "文章ID": "96002",
                "标题": "Enhancing Network Management Using Code Generated by Large Language\n  Models",
                "作者": " Sathiya Kumaran Mani,  Yajie Zhou,  Kevin Hsieh,  Santiago Segarra,  Ranveer Chandra,  Srikanth Kandula",
                "发布日期": "2023-08-14",
                "摘要": "  Analyzing network topologies and communication graphs plays a crucial role in\ncontemporary network management. However, the absence of a cohesive approach\nleads to a challenging learning curve, heightened errors, and inefficiencies.\nIn this paper, we introduce a novel approach to facilitate a\nnatural-language-based network management experience, utilizing large language\nmodels (LLMs) to generate task-specific code from natural language queries.\nThis method tackles the challenges of explainability, scalability, and privacy\nby allowing network operators to inspect the generated code, eliminating the\nneed to share network data with LLMs, and concentrating on application-specific\nrequests combined with general program synthesis techniques. We design and\nevaluate a prototype system using benchmark applications, showcasing high\naccuracy, cost-effectiveness, and the potential for further enhancements using\ncomplementary program synthesis techniques.\n",
                "链接": "https://arxiv.org/abs/2308.06261"
            },
            {
                "文章ID": "65723",
                "标题": "MathPrompter: Mathematical Reasoning using Large Language Models",
                "作者": " Shima Imani,  Liang Du,  Harsh Shrivastava",
                "发布日期": "2023-03-10",
                "摘要": "  Large Language Models (LLMs) have limited performance when solving arithmetic\nreasoning tasks and often provide incorrect answers. Unlike natural language\nunderstanding, math problems typically have a single correct answer, making the\ntask of generating accurate solutions more challenging for LLMs. To the best of\nour knowledge, we are not aware of any LLMs that indicate their level of\nconfidence in their responses which fuels a trust deficit in these models\nimpeding their adoption. To address this deficiency, we propose `MathPrompter',\na technique that improves performance of LLMs on arithmetic problems along with\nincreased reliance in the predictions. MathPrompter uses the Zero-shot\nchain-of-thought prompting technique to generate multiple Algebraic expressions\nor Python functions to solve the same math problem in different ways and\nthereby raise the confidence level in the output results. This is in contrast\nto other prompt based CoT methods, where there is no check on the validity of\nthe intermediate steps followed. Our technique improves over state-of-the-art\non the MultiArith dataset ($78.7\\%\\rightarrow92.5\\%$) evaluated using 175B\nparameter GPT-based LLM.\n",
                "链接": "https://arxiv.org/abs/2303.05398"
            },
            {
                "文章ID": "91891",
                "标题": "Generating Mathematical Derivations with Large Language Models",
                "作者": " Jordan Meadows,  Marco Valentino,  Andre Freitas",
                "发布日期": "2023-08-09",
                "摘要": "  The derivation of mathematical results in specialised fields, using Large\nLanguage Models (LLMs), is an emerging research direction that can help\nidentify models' limitations, and potentially support mathematical discovery.\nIn this paper, we leverage a symbolic engine to generate derivations of\nequations at scale, and investigate the capabilities of LLMs when deriving goal\nequations from premises. Specifically, we employ in-context learning for GPT\nand fine-tune a range of T5 models to compare the robustness and generalisation\nof pre-training strategies to specialised models. Empirical results show that\nfine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and\nout-of-distribution test sets in conventional scores. However, an in-depth\nanalysis reveals that the fine-tuned models are more sensitive to perturbations\ninvolving unseen symbols and (to a lesser extent) changes to equation\nstructure. In addition, we analyse 1.7K equations, and over 200 derivations, to\nhighlight common reasoning errors such as the inclusion of incorrect,\nirrelevant, and redundant equations. Finally, we explore the suitability of\nexisting metrics for evaluating mathematical derivations and find evidence\nthat, while they can capture general properties such as sensitivity to\nperturbations, they fail to highlight fine-grained reasoning errors and\nessential differences between models. Overall, this work demonstrates that\ntraining models on synthetic data may improve their math capabilities beyond\nmuch larger LLMs, but current metrics are not appropriately assessing the\nquality of generated mathematical text.\n",
                "链接": "https://arxiv.org/abs/2307.09998"
            },
            {
                "文章ID": "99865",
                "标题": "Extracting Mathematical Concepts with Large Language Models",
                "作者": " Valeria de Paiva,  Qiyue Gao,  Pavel Kovalev,  Lawrence S. Moss",
                "发布日期": "2023-09-06",
                "摘要": "  We extract mathematical concepts from mathematical text using generative\nlarge language models (LLMs) like ChatGPT, contributing to the field of\nautomatic term extraction (ATE) and mathematical text processing, and also to\nthe study of LLMs themselves. Our work builds on that of others in that we aim\nfor automatic extraction of terms (keywords) in one mathematical field,\ncategory theory, using as a corpus the 755 abstracts from a snapshot of the\nonline journal \"Theory and Applications of Categories\", circa 2020. Where our\nstudy diverges from previous work is in (1) providing a more thorough analysis\nof what makes mathematical term extraction a difficult problem to begin with;\n(2) paying close attention to inter-annotator disagreements; (3) providing a\nset of guidelines which both human and machine annotators could use to\nstandardize the extraction process; (4) introducing a new annotation tool to\nhelp humans with ATE, applicable to any mathematical field and even beyond\nmathematics; (5) using prompts to ChatGPT as part of the extraction process,\nand proposing best practices for such prompts; and (6) raising the question of\nwhether ChatGPT could be used as an annotator on the same level as human\nexperts. Our overall findings are that the matter of mathematical ATE is an\ninteresting field which can benefit from participation by LLMs, but LLMs\nthemselves cannot at this time surpass human performance on it.\n",
                "链接": "https://arxiv.org/abs/2309.00642"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            },
            {
                "文章ID": "117134",
                "标题": "Extracting Definienda in Mathematical Scholarly Articles with\n  Transformers",
                "作者": "VALDA  Shufan Jiang, DI-ENS, VALDA  Pierre Senellart",
                "发布日期": "2023-11-22",
                "摘要": "  We consider automatically identifying the defined term within a mathematical\ndefinition from the text of an academic article. Inspired by the development of\ntransformer-based natural language processing applications, we pose the problem\nas (a) a token-level classification task using fine-tuned pre-trained\ntransformers; and (b) a question-answering task using a generalist large\nlanguage model (GPT). We also propose a rule-based approach to build a labeled\ndataset from the LATEX source of papers. Experimental results show that it is\npossible to reach high levels of precision and recall using either recent (and\nexpensive) GPT 4 or simpler pre-trained models fine-tuned on our task.\n",
                "链接": "https://arxiv.org/abs/2311.12448"
            },
            {
                "文章ID": "109206",
                "标题": "Llemma: An Open Language Model For Mathematics",
                "作者": " Zhangir Azerbayev,  Hailey Schoelkopf,  Keiran Paster,  Marco Dos Santos,  Stephen McAleer,  Albert Q. Jiang,  Jia Deng,  Stella Biderman,  Sean Welleck",
                "发布日期": "2023-12-04",
                "摘要": "  We present Llemma, a large language model for mathematics. We continue\npretraining Code Llama on the Proof-Pile-2, a mixture of scientific papers, web\ndata containing mathematics, and mathematical code, yielding Llemma. On the\nMATH benchmark Llemma outperforms all known open base models, as well as the\nunreleased Minerva model suite on an equi-parameter basis. Moreover, Llemma is\ncapable of tool use and formal theorem proving without any further finetuning.\nWe openly release all artifacts, including 7 billion and 34 billion parameter\nmodels, the Proof-Pile-2, and code to replicate our experiments.\n",
                "链接": "https://arxiv.org/abs/2310.10631"
            }
        ]
    },
    {
        "question": {
            "question": "查找可以用于验证模型推理能力的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "4699",
                "标题": "Validating Causal Inference Methods",
                "作者": " Harsh Parikh,  Carlos Varjao,  Louise Xu,  Eric Tchetgen Tchetgen",
                "发布日期": "2022-08-01",
                "摘要": "  The fundamental challenge of drawing causal inference is that counterfactual\noutcomes are not fully observed for any unit. Furthermore, in observational\nstudies, treatment assignment is likely to be confounded. Many statistical\nmethods have emerged for causal inference under unconfoundedness conditions\ngiven pre-treatment covariates, including propensity score-based methods,\nprognostic score-based methods, and doubly robust methods. Unfortunately for\napplied researchers, there is no `one-size-fits-all' causal method that can\nperform optimally universally. In practice, causal methods are primarily\nevaluated quantitatively on handcrafted simulated data. Such data-generative\nprocedures can be of limited value because they are typically stylized models\nof reality. They are simplified for tractability and lack the complexities of\nreal-world data. For applied researchers, it is critical to understand how well\na method performs for the data at hand. Our work introduces a deep generative\nmodel-based framework, Credence, to validate causal inference methods. The\nframework's novelty stems from its ability to generate synthetic data anchored\nat the empirical distribution for the observed sample, and therefore virtually\nindistinguishable from the latter. The approach allows the user to specify\nground truth for the form and magnitude of causal effects and confounding bias\nas functions of covariates. Thus simulated data sets are used to evaluate the\npotential performance of various causal estimation methods when applied to data\nsimilar to the observed sample. We demonstrate Credence's ability to accurately\nassess the relative performance of causal estimation techniques in an extensive\nsimulation study and two real-world data applications from Lalonde and Project\nSTAR studies.\n",
                "链接": "https://arxiv.org/abs/2202.04208"
            },
            {
                "文章ID": "120555",
                "标题": "Teaching Specific Scientific Knowledge into Large Language Models\n  through Additional Training",
                "作者": " Kan Hatakeyama-Sato,  Yasuhiko Igarashi,  Shun Katakami,  Yuta Nabae,  Teruaki Hayakawa",
                "发布日期": "2023-12-19",
                "摘要": "  Through additional training, we explore embedding specialized scientific\nknowledge into the Llama 2 Large Language Model (LLM). Key findings reveal that\neffective knowledge integration requires reading texts from multiple\nperspectives, especially in instructional formats. We utilize text augmentation\nto tackle the scarcity of specialized texts, including style conversions and\ntranslations. Hyperparameter optimization proves crucial, with different size\nmodels (7b, 13b, and 70b) reasonably undergoing additional training. Validating\nour methods, we construct a dataset of 65,000 scientific papers. Although we\nhave succeeded in partially embedding knowledge, the study highlights the\ncomplexities and limitations of incorporating specialized information into\nLLMs, suggesting areas for further improvement.\n",
                "链接": "https://arxiv.org/abs/2312.03360"
            },
            {
                "文章ID": "102959",
                "标题": "OpenMSD: Towards Multilingual Scientific Documents Similarity\n  Measurement",
                "作者": " Yang Gao,  Ji Ma,  Ivan Korotkov,  Keith Hall,  Dana Alon,  Don Metzler",
                "发布日期": "2023-09-20",
                "摘要": "  We develop and evaluate multilingual scientific documents similarity\nmeasurement models in this work. Such models can be used to find related works\nin different languages, which can help multilingual researchers find and\nexplore papers more efficiently. We propose the first multilingual scientific\ndocuments dataset, Open-access Multilingual Scientific Documents (OpenMSD),\nwhich has 74M papers in 103 languages and 778M citation pairs. With OpenMSD, we\npretrain science-specialized language models, and explore different strategies\nto derive \"related\" paper pairs to fine-tune the models, including using a\nmixture of citation, co-citation, and bibliographic-coupling pairs. To further\nimprove the models' performance for non-English papers, we explore the use of\ngenerative language models to enrich the non-English papers with English\nsummaries. This allows us to leverage the models' English capabilities to\ncreate better representations for non-English papers. Our best model\nsignificantly outperforms strong baselines by 7-16% (in mean average\nprecision).\n",
                "链接": "https://arxiv.org/abs/2309.10539"
            },
            {
                "文章ID": "44848",
                "标题": "Bridging the Training-Inference Gap for Dense Phrase Retrieval",
                "作者": " Gyuwan Kim,  Jinhyuk Lee,  Barlas Oguz,  Wenhan Xiong,  Yizhe Zhang,  Yashar Mehdad,  William Yang Wang",
                "发布日期": "2022-10-26",
                "摘要": "  Building dense retrievers requires a series of standard procedures, including\ntraining and validating neural models and creating indexes for efficient\nsearch. However, these procedures are often misaligned in that training\nobjectives do not exactly reflect the retrieval scenario at inference time. In\nthis paper, we explore how the gap between training and inference in dense\nretrieval can be reduced, focusing on dense phrase retrieval (Lee et al., 2021)\nwhere billions of representations are indexed at inference. Since validating\nevery dense retriever with a large-scale index is practically infeasible, we\npropose an efficient way of validating dense retrievers using a small subset of\nthe entire corpus. This allows us to validate various training strategies\nincluding unifying contrastive loss terms and using hard negatives for phrase\nretrieval, which largely reduces the training-inference discrepancy. As a\nresult, we improve top-1 phrase retrieval accuracy by 2~3 points and top-20\npassage retrieval accuracy by 2~4 points for open-domain question answering.\nOur work urges modeling dense retrievers with careful consideration of training\nand inference via efficient validation while advancing phrase retrieval as a\ngeneral solution for dense retrieval.\n",
                "链接": "https://arxiv.org/abs/2210.13678"
            },
            {
                "文章ID": "113190",
                "标题": "VQA-GEN: A Visual Question Answering Benchmark for Domain Generalization",
                "作者": " Suraj Jyothi Unni,  Raha Moraffah,  Huan Liu",
                "发布日期": "2023-11-03",
                "摘要": "  Visual question answering (VQA) models are designed to demonstrate\nvisual-textual reasoning capabilities. However, their real-world applicability\nis hindered by a lack of comprehensive benchmark datasets. Existing domain\ngeneralization datasets for VQA exhibit a unilateral focus on textual shifts\nwhile VQA being a multi-modal task contains shifts across both visual and\ntextual domains. We propose VQA-GEN, the first ever multi-modal benchmark\ndataset for distribution shift generated through a shift induced pipeline.\nExperiments demonstrate VQA-GEN dataset exposes the vulnerability of existing\nmethods to joint multi-modal distribution shifts. validating that comprehensive\nmulti-modal shifts are critical for robust VQA generalization. Models trained\non VQA-GEN exhibit improved cross-domain and in-domain performance, confirming\nthe value of VQA-GEN. Further, we analyze the importance of each shift\ntechnique of our pipeline contributing to the generalization of the model.\n",
                "链接": "https://arxiv.org/abs/2311.00807"
            },
            {
                "文章ID": "71217",
                "标题": "Hierarchical Catalogue Generation for Literature Review: A Benchmark",
                "作者": " Kun Zhu,  Xiaocheng Feng,  Xiachong Feng,  Yingsheng Wu,  Bing Qin",
                "发布日期": "2023-11-20",
                "摘要": "  Scientific literature review generation aims to extract and organize\nimportant information from an abundant collection of reference papers and\nproduces corresponding reviews while lacking a clear and logical hierarchy. We\nobserve that a high-quality catalogue-guided generation process can effectively\nalleviate this problem. Therefore, we present an atomic and challenging task\nnamed Hierarchical Catalogue Generation for Literature Review as the first step\nfor review generation, which aims to produce a hierarchical catalogue of a\nreview paper given various references. We construct a novel English\nHierarchical Catalogues of Literature Reviews Dataset with 7.6k literature\nreview catalogues and 389k reference papers. To accurately assess the model\nperformance, we design two evaluation metrics for informativeness and\nsimilarity to ground truth from semantics and structure.Our extensive analyses\nverify the high quality of our dataset and the effectiveness of our evaluation\nmetrics. We further benchmark diverse experiments on state-of-the-art\nsummarization models like BART and large language models like ChatGPT to\nevaluate their capabilities. We further discuss potential directions for this\ntask to motivate future research.\n",
                "链接": "https://arxiv.org/abs/2304.03512"
            },
            {
                "文章ID": "103641",
                "标题": "Unlocking Model Insights: A Dataset for Automated Model Card Generation",
                "作者": " Shruti Singh,  Hitesh Lodwal,  Husain Malwat,  Rakesh Thakur,  Mayank Singh",
                "发布日期": "2023-09-25",
                "摘要": "  Language models (LMs) are no longer restricted to ML community, and\ninstruction-tuned LMs have led to a rise in autonomous AI agents. As the\naccessibility of LMs grows, it is imperative that an understanding of their\ncapabilities, intended usage, and development cycle also improves. Model cards\nare a popular practice for documenting detailed information about an ML model.\nTo automate model card generation, we introduce a dataset of 500\nquestion-answer pairs for 25 ML models that cover crucial aspects of the model,\nsuch as its training configurations, datasets, biases, architecture details,\nand training resources. We employ annotators to extract the answers from the\noriginal paper. Further, we explore the capabilities of LMs in generating model\ncards by answering questions. Our initial experiments with ChatGPT-3.5, LLaMa,\nand Galactica showcase a significant gap in the understanding of research\npapers by these aforementioned LMs as well as generating factual textual\nresponses. We posit that our dataset can be used to train models to automate\nthe generation of model cards from paper text and reduce human effort in the\nmodel card curation process. The complete dataset is available on\nhttps://osf.io/hqt7p/?view_only=3b9114e3904c4443bcd9f5c270158d37\n",
                "链接": "https://arxiv.org/abs/2309.12616"
            },
            {
                "文章ID": "1654",
                "标题": "CoAuthor: Designing a Human-AI Collaborative Writing Dataset for\n  Exploring Language Model Capabilities",
                "作者": " Mina Lee,  Percy Liang,  Qian Yang",
                "发布日期": "2022-01-26",
                "摘要": "  Large language models (LMs) offer unprecedented language generation\ncapabilities and exciting opportunities for interaction design. However, their\nhighly context-dependent capabilities are difficult to grasp and are often\nsubjectively interpreted. In this paper, we argue that by curating and\nanalyzing large interaction datasets, the HCI community can foster more\nincisive examinations of LMs' generative capabilities. Exemplifying this\napproach, we present CoAuthor, a dataset designed for revealing GPT-3's\ncapabilities in assisting creative and argumentative writing. CoAuthor captures\nrich interactions between 63 writers and four instances of GPT-3 across 1445\nwriting sessions. We demonstrate that CoAuthor can address questions about\nGPT-3's language, ideation, and collaboration capabilities, and reveal its\ncontribution as a writing \"collaborator\" under various definitions of good\ncollaboration. Finally, we discuss how this work may facilitate a more\nprincipled discussion around LMs' promises and pitfalls in relation to\ninteraction design. The dataset and an interface for replaying the writing\nsessions are publicly available at https://coauthor.stanford.edu.\n",
                "链接": "https://arxiv.org/abs/2201.06796"
            },
            {
                "文章ID": "16810",
                "标题": "Capabilities and Skills in Manufacturing: A Survey Over the Last Decade\n  of ETFA",
                "作者": " Roman Froschauer,  Aljosha Köcher,  Kristof Meixner,  Siwara Schmitt,  Fabian Spitzer",
                "发布日期": "2022-11-07",
                "摘要": "  Industry 4.0 envisions Cyber-Physical Production Systems (CPPSs) to foster\nadaptive production of mass-customizable products. Manufacturing approaches\nbased on capabilities and skills aim to support this adaptability by\nencapsulating machine functions and decoupling them from specific production\nprocesses. At the 2022 IEEE conference on Emerging Technologies and Factory\nAutomation (ETFA), a special session on capability- and skill-based\nmanufacturing is hosted for the fourth time. However, an overview on\ncapability- and skill based systems in factory automation and manufacturing\nsystems is missing. This paper aims to provide such an overview and give\ninsights to this particular field of research. We conducted a concise\nliterature survey of papers covering the topics of capabilities and skills in\nmanufacturing from the last ten years of the ETFA conference. We found 247\npapers with a notion on capabilities and skills and identified and analyzed 34\nrelevant papers which met this survey's inclusion criteria. In this paper, we\nprovide (i) an overview of the research field, (ii) an analysis of the\ncharacteristics of capabilities and skills, and (iii) a discussion on gaps and\nopportunities.\n",
                "链接": "https://arxiv.org/abs/2204.12908"
            },
            {
                "文章ID": "5419",
                "标题": "ArgSciChat: A Dataset for Argumentative Dialogues on Scientific Papers",
                "作者": " Federico Ruggeri,  Mohsen Mesgar,  Iryna Gurevych",
                "发布日期": "2022-10-14",
                "摘要": "  The applications of conversational agents for scientific disciplines (as\nexpert domains) are understudied due to the lack of dialogue data to train such\nagents. While most data collection frameworks, such as Amazon Mechanical Turk,\nfoster data collection for generic domains by connecting crowd workers and task\ndesigners, these frameworks are not much optimized for data collection in\nexpert domains. Scientists are rarely present in these frameworks due to their\nlimited time budget. Therefore, we introduce a novel framework to collect\ndialogues between scientists as domain experts on scientific papers. Our\nframework lets scientists present their scientific papers as groundings for\ndialogues and participate in dialogue they like its paper title. We use our\nframework to collect a novel argumentative dialogue dataset, ArgSciChat. It\nconsists of 498 messages collected from 41 dialogues on 20 scientific papers.\nAlongside extensive analysis on ArgSciChat, we evaluate a recent conversational\nagent on our dataset. Experimental results show that this agent poorly performs\non ArgSciChat, motivating further research on argumentative scientific agents.\nWe release our framework and the dataset.\n",
                "链接": "https://arxiv.org/abs/2202.06690"
            }
        ]
    },
    {
        "question": {
            "question": "帮我找一下用大模型进行论文查找的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "110649",
                "标题": "Large Search Model: Redefining Search Stack in the Era of LLMs",
                "作者": " Liang Wang,  Nan Yang,  Xiaolong Huang,  Linjun Yang,  Rangan Majumder,  Furu Wei",
                "发布日期": "2023-10-24",
                "摘要": "  Modern search engines are built on a stack of different components, including\nquery understanding, retrieval, multi-stage ranking, and question answering,\namong others. These components are often optimized and deployed independently.\nIn this paper, we introduce a novel conceptual framework called large search\nmodel, which redefines the conventional search stack by unifying search tasks\nwith one large language model (LLM). All tasks are formulated as autoregressive\ntext generation problems, allowing for the customization of tasks through the\nuse of natural language prompts. This proposed framework capitalizes on the\nstrong language understanding and reasoning capabilities of LLMs, offering the\npotential to enhance search result quality while simultaneously simplifying the\nexisting cumbersome search stack. To substantiate the feasibility of this\nframework, we present a series of proof-of-concept experiments and discuss the\npotential challenges associated with implementing this approach within\nreal-world search systems.\n",
                "链接": "https://arxiv.org/abs/2310.14587"
            },
            {
                "文章ID": "34",
                "标题": "Semantic Search for Large Scale Clinical Ontologies",
                "作者": " Duy-Hoa Ngo,  Madonna Kemp,  Donna Truran,  Bevan Koopman,  Alejandro Metke-Jimenez",
                "发布日期": "2022-01-04",
                "摘要": "  Finding concepts in large clinical ontologies can be challenging when queries\nuse different vocabularies. A search algorithm that overcomes this problem is\nuseful in applications such as concept normalisation and ontology matching,\nwhere concepts can be referred to in different ways, using different synonyms.\nIn this paper, we present a deep learning based approach to build a semantic\nsearch system for large clinical ontologies. We propose a Triplet-BERT model\nand a method that generates training data directly from the ontologies. The\nmodel is evaluated using five real benchmark data sets and the results show\nthat our approach achieves high results on both free text to concept and\nconcept to concept searching tasks, and outperforms all baseline methods.\n",
                "链接": "https://arxiv.org/abs/2201.00118"
            },
            {
                "文章ID": "118095",
                "标题": "Algorithm Evolution Using Large Language Model",
                "作者": " Fei Liu,  Xialiang Tong,  Mingxuan Yuan,  Qingfu Zhang",
                "发布日期": "2023-11-28",
                "摘要": "  Optimization can be found in many real-life applications. Designing an\neffective algorithm for a specific optimization problem typically requires a\ntedious amount of effort from human experts with domain knowledge and algorithm\ndesign skills. In this paper, we propose a novel approach called Algorithm\nEvolution using Large Language Model (AEL). It utilizes a large language model\n(LLM) to automatically generate optimization algorithms via an evolutionary\nframework. AEL does algorithm-level evolution without model training. Human\neffort and requirements for domain knowledge can be significantly reduced. We\ntake constructive methods for the salesman traveling problem as a test example,\nwe show that the constructive algorithm obtained by AEL outperforms simple\nhand-crafted and LLM-generated heuristics. Compared with other domain deep\nlearning model-based algorithms, these methods exhibit excellent scalability\nacross different problem sizes. AEL is also very different from previous\nattempts that utilize LLMs as search operators in algorithms.\n",
                "链接": "https://arxiv.org/abs/2311.15249"
            },
            {
                "文章ID": "125196",
                "标题": "Adaptive Anytime Multi-Agent Path Finding Using Bandit-Based Large\n  Neighborhood Search",
                "作者": " Thomy Phan,  Taoan Huang,  Bistra Dilkina,  Sven Koenig",
                "发布日期": "2023-12-29",
                "摘要": "  Anytime multi-agent path finding (MAPF) is a promising approach to scalable\npath optimization in large-scale multi-agent systems. State-of-the-art anytime\nMAPF is based on Large Neighborhood Search (LNS), where a fast initial solution\nis iteratively optimized by destroying and repairing a fixed number of parts,\ni.e., the neighborhood, of the solution, using randomized destroy heuristics\nand prioritized planning. Despite their recent success in various MAPF\ninstances, current LNS-based approaches lack exploration and flexibility due to\ngreedy optimization with a fixed neighborhood size which can lead to low\nquality solutions in general. So far, these limitations have been addressed\nwith extensive prior effort in tuning or offline machine learning beyond actual\nplanning. In this paper, we focus on online learning in LNS and propose\nBandit-based Adaptive LArge Neighborhood search Combined with Exploration\n(BALANCE). BALANCE uses a bi-level multi-armed bandit scheme to adapt the\nselection of destroy heuristics and neighborhood sizes on the fly during\nsearch. We evaluate BALANCE on multiple maps from the MAPF benchmark set and\nempirically demonstrate cost improvements of at least 50% compared to\nstate-of-the-art anytime MAPF in large-scale scenarios. We find that Thompson\nSampling performs particularly well compared to alternative multi-armed bandit\nalgorithms.\n",
                "链接": "https://arxiv.org/abs/2312.16767"
            },
            {
                "文章ID": "2828",
                "标题": "Learning Deep Semantic Model for Code Search using CodeSearchNet Corpus",
                "作者": " Chen Wu,  Ming Yan",
                "发布日期": "2022-01-28",
                "摘要": "  Semantic code search is the task of retrieving relevant code snippet given a\nnatural language query. Different from typical information retrieval tasks,\ncode search requires to bridge the semantic gap between the programming\nlanguage and natural language, for better describing intrinsic concepts and\nsemantics. Recently, deep neural network for code search has been a hot\nresearch topic. Typical methods for neural code search first represent the code\nsnippet and query text as separate embeddings, and then use vector distance\n(e.g. dot-product or cosine) to calculate the semantic similarity between them.\nThere exist many different ways for aggregating the variable length of code or\nquery tokens into a learnable embedding, including bi-encoder, cross-encoder,\nand poly-encoder. The goal of the query encoder and code encoder is to produce\nembeddings that are close with each other for a related pair of query and the\ncorresponding desired code snippet, in which the choice and design of encoder\nis very significant.\n  In this paper, we propose a novel deep semantic model which makes use of the\nutilities of not only the multi-modal sources, but also feature extractors such\nas self-attention, the aggregated vectors, combination of the intermediate\nrepresentations. We apply the proposed model to tackle the CodeSearchNet\nchallenge about semantic code search. We align cross-lingual embedding for\nmulti-modality learning with large batches and hard example mining, and combine\ndifferent learned representations for better enhancing the representation\nlearning. Our model is trained on CodeSearchNet corpus and evaluated on the\nheld-out data, the final model achieves 0.384 NDCG and won the first place in\nthis benchmark. Models and code are available at\nhttps://github.com/overwindows/SemanticCodeSearch.git.\n",
                "链接": "https://arxiv.org/abs/2201.11313"
            },
            {
                "文章ID": "36968",
                "标题": "An Embedding-Based Grocery Search Model at Instacart",
                "作者": " Yuqing Xie,  Taesik Na,  Xiao Xiao,  Saurav Manchanda,  Young Rao,  Zhihong Xu,  Guanghua Shu,  Esther Vasiete,  Tejaswi Tenneti,  Haixun Wang",
                "发布日期": "2022-09-14",
                "摘要": "  The key to e-commerce search is how to best utilize the large yet noisy log\ndata. In this paper, we present our embedding-based model for grocery search at\nInstacart. The system learns query and product representations with a two-tower\ntransformer-based encoder architecture. To tackle the cold-start problem, we\nfocus on content-based features. To train the model efficiently on noisy data,\nwe propose a self-adversarial learning method and a cascade training method.\nAccOn an offline human evaluation dataset, we achieve 10% relative improvement\nin RECALL@20, and for online A/B testing, we achieve 4.1% cart-adds per search\n(CAPS) and 1.5% gross merchandise value (GMV) improvement. We describe how we\ntrain and deploy the embedding based search model and give a detailed analysis\nof the effectiveness of our method.\n",
                "链接": "https://arxiv.org/abs/2209.05555"
            },
            {
                "文章ID": "95732",
                "标题": "WeaverBird: Empowering Financial Decision-Making with Large Language\n  Model, Knowledge Base, and Search Engine",
                "作者": " Siqiao Xue,  Fan Zhou,  Yi Xu,  Ming Jin,  Qingsong Wen,  Hongyan Hao,  Qingyang Dai,  Caigao Jiang,  Hongyu Zhao,  Shuo Xie,  Jianshan He,  James Zhang,  Hongyuan Mei",
                "发布日期": "2023-12-05",
                "摘要": "  We present WeaverBird, an intelligent dialogue system designed specifically\nfor the finance domain. Our system harnesses a large language model of GPT\narchitecture that has been tuned using extensive corpora of finance-related\ntext. As a result, our system possesses the capability to understand complex\nfinancial queries, such as \"How should I manage my investments during\ninflation?\", and provide informed responses. Furthermore, our system\nincorporates a local knowledge base and a search engine to retrieve relevant\ninformation. The final responses are conditioned on the search results and\ninclude proper citations to the sources, thus enjoying an enhanced credibility.\nThrough a range of finance-related questions, we have demonstrated the superior\nperformance of our system compared to other models. To experience our system\nfirsthand, users can interact with our live demo at\nhttps://weaverbird.ttic.edu, as well as watch our 2-min video illustration at\nhttps://www.youtube.com/watch?v=fyV2qQkX6Tc.\n",
                "链接": "https://arxiv.org/abs/2308.05361"
            },
            {
                "文章ID": "114213",
                "标题": "Large Language Model based Long-tail Query Rewriting in Taobao Search",
                "作者": " Wenjun Peng,  Guiyang Li,  Yue Jiang,  Zilong Wang,  Dan Ou,  Xiaoyi Zeng,  Derong Xu,   Tongxu,  Enhong Chen",
                "发布日期": "2023-11-14",
                "摘要": "  In the realm of e-commerce search, the significance of semantic matching\ncannot be overstated, as it directly impacts both user experience and company\nrevenue. Along this line, query rewriting, serving as an important technique to\nbridge the semantic gaps inherent in the semantic matching process, has\nattached wide attention from the industry and academia. However, existing query\nrewriting methods often struggle to effectively optimize long-tail queries and\nalleviate the phenomenon of \"few-recall\" caused by semantic gap. In this paper,\nwe present BEQUE, a comprehensive framework that Bridges the sEmantic gap for\nlong-tail QUEries. In detail, BEQUE comprises three stages: multi-instruction\nsupervised fine tuning (SFT), offline feedback, and objective alignment. We\nfirst construct a rewriting dataset based on rejection sampling and auxiliary\ntasks mixing to fine-tune our large language model (LLM) in a supervised\nfashion. Subsequently, with the well-trained LLM, we employ beam search to\ngenerate multiple candidate rewrites, and feed them into Taobao offline system\nto obtain the partial order. Leveraging the partial order of rewrites, we\nintroduce a contrastive learning method to highlight the distinctions between\nrewrites, and align the model with the Taobao online objectives. Offline\nexperiments prove the effectiveness of our method in bridging semantic gap.\nOnline A/B tests reveal that our method can significantly boost gross\nmerchandise volume (GMV), number of transaction (#Trans) and unique visitor\n(UV) for long-tail queries. BEQUE has been deployed on Taobao, one of most\npopular online shopping platforms in China, since October 2023.\n",
                "链接": "https://arxiv.org/abs/2311.03758"
            },
            {
                "文章ID": "120976",
                "标题": "Using Large Language Models for Hyperparameter Optimization",
                "作者": " Michael R. Zhang,  Nishkrit Desai,  Juhan Bae,  Jonathan Lorraine,  Jimmy Ba",
                "发布日期": "2023-12-08",
                "摘要": "  This paper studies using foundational large language models (LLMs) to make\ndecisions during hyperparameter optimization (HPO). Empirical evaluations\ndemonstrate that in settings with constrained search budgets, LLMs can perform\ncomparably or better than traditional HPO methods like random search and\nBayesian optimization on standard benchmarks. Furthermore, we propose to treat\nthe code specifying our model as a hyperparameter, which the LLM outputs, going\nbeyond the capabilities of existing HPO approaches. Our findings suggest that\nLLMs are a promising tool for improving efficiency in the traditional\ndecision-making problem of hyperparameter optimization.\n",
                "链接": "https://arxiv.org/abs/2312.04528"
            },
            {
                "文章ID": "105172",
                "标题": "Alphazero-like Tree-Search can Guide Large Language Model Decoding and\n  Training",
                "作者": " Xidong Feng,  Ziyu Wan,  Muning Wen,  Ying Wen,  Weinan Zhang,  Jun Wang",
                "发布日期": "2023-10-02",
                "摘要": "  Large language models (LLMs) typically employ sampling or beam search,\naccompanied by prompts such as Chain-of-Thought (CoT), to boost reasoning and\ndecoding ability. Recent work like Tree-of-Thought (ToT) and Reasoning via\nPlanning (RAP) aim to augment the reasoning capabilities of LLMs by utilizing\ntree-search algorithms to guide multi-step reasoning. These methods mainly\nfocus on LLMs' reasoning ability during inference and heavily rely on\nhuman-designed prompts to activate LLM as a value function, which lacks general\napplicability and scalability. To address these limitations, we present an\nAlphaZero-like tree-search framework for LLMs (termed TS-LLM), systematically\nillustrating how tree-search with a learned value function can guide LLMs'\ndecoding ability. TS-LLM distinguishes itself in two key ways: (1) Leveraging a\nlearned value function, our approach can be generally applied to different\ntasks beyond reasoning (such as RLHF alignment), and LLMs of any size, without\nprompting advanced, large-scale models. (2) It can guide LLM's decoding during\nboth inference and training. Empirical evaluations across reasoning, planning,\nand RLHF alignment tasks validate the effectiveness of TS-LLM, even on trees\nwith a depth of 64.\n",
                "链接": "https://arxiv.org/abs/2309.17179"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到，最早提出分布式词表示的论文是哪一篇？",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "119444",
                "标题": "Robust Concept Erasure via Kernelized Rate-Distortion Maximization",
                "作者": " Somnath Basu Roy Chowdhury,  Nicholas Monath,  Avinava Dubey,  Amr Ahmed,  Snigdha Chaturvedi",
                "发布日期": "2023-12-04",
                "摘要": "  Distributed representations provide a vector space that captures meaningful\nrelationships between data instances. The distributed nature of these\nrepresentations, however, entangles together multiple attributes or concepts of\ndata instances (e.g., the topic or sentiment of a text, characteristics of the\nauthor (age, gender, etc), etc). Recent work has proposed the task of concept\nerasure, in which rather than making a concept predictable, the goal is to\nremove an attribute from distributed representations while retaining other\ninformation from the original representation space as much as possible. In this\npaper, we propose a new distance metric learning-based objective, the\nKernelized Rate-Distortion Maximizer (KRaM), for performing concept erasure.\nKRaM fits a transformation of representations to match a specified distance\nmeasure (defined by a labeled concept to erase) using a modified\nrate-distortion function. Specifically, KRaM's objective function aims to make\ninstances with similar concept labels dissimilar in the learned representation\nspace while retaining other information. We find that optimizing KRaM\neffectively erases various types of concepts: categorical, continuous, and\nvector-valued variables from data representations across diverse domains. We\nalso provide a theoretical analysis of several properties of KRaM's objective.\nTo assess the quality of the learned representations, we propose an alignment\nscore to evaluate their similarity with the original representation space.\nAdditionally, we conduct experiments to showcase KRaM's efficacy in various\nsettings, from erasing binary gender variables in word embeddings to\nvector-valued variables in GPT-3 representations.\n",
                "链接": "https://arxiv.org/abs/2312.00194"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下nips 2023 paper list",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "84628",
                "标题": "Overview of the Problem List Summarization (ProbSum) 2023 Shared Task on\n  Summarizing Patients' Active Diagnoses and Problems from Electronic Health\n  Record Progress Notes",
                "作者": " Yanjun Gao,  Dmitriy Dligach,  Timothy Miller,  Matthew M. Churpek,  Majid Afshar",
                "发布日期": "2023-06-09",
                "摘要": "  The BioNLP Workshop 2023 initiated the launch of a shared task on Problem\nList Summarization (ProbSum) in January 2023. The aim of this shared task is to\nattract future research efforts in building NLP models for real-world\ndiagnostic decision support applications, where a system generating relevant\nand accurate diagnoses will augment the healthcare providers decision-making\nprocess and improve the quality of care for patients. The goal for participants\nis to develop models that generated a list of diagnoses and problems using\ninput from the daily care notes collected from the hospitalization of\ncritically ill patients. Eight teams submitted their final systems to the\nshared task leaderboard. In this paper, we describe the tasks, datasets,\nevaluation metrics, and baseline systems. Additionally, the techniques and\nresults of the evaluation of the different approaches tried by the\nparticipating teams are summarized.\n",
                "链接": "https://arxiv.org/abs/2306.05270"
            },
            {
                "文章ID": "40312",
                "标题": "SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis",
                "作者": " Jiaxin Pei,  Vítor Silva,  Maarten Bos,  Yozon Liu,  Leonardo Neves,  David Jurgens,  Francesco Barbieri",
                "发布日期": "2023-02-06",
                "摘要": "  We propose MINT, a new Multilingual INTimacy analysis dataset covering 13,372\ntweets in 10 languages including English, French, Spanish, Italian, Portuguese,\nKorean, Dutch, Chinese, Hindi, and Arabic. We benchmarked a list of popular\nmultilingual pre-trained language models. The dataset is released along with\nthe SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis\n(https://sites.google.com/umich.edu/semeval-2023-tweet-intimacy).\n",
                "链接": "https://arxiv.org/abs/2210.01108"
            },
            {
                "文章ID": "47574",
                "标题": "A Characterization of List Learnability",
                "作者": " Moses Charikar,  Chirag Pabbaraju",
                "发布日期": "2023-03-28",
                "摘要": "  A classical result in learning theory shows the equivalence of PAC\nlearnability of binary hypothesis classes and the finiteness of VC dimension.\nExtending this to the multiclass setting was an open problem, which was settled\nin a recent breakthrough result characterizing multiclass PAC learnability via\nthe DS dimension introduced earlier by Daniely and Shalev-Shwartz. In this work\nwe consider list PAC learning where the goal is to output a list of $k$\npredictions. List learning algorithms have been developed in several settings\nbefore and indeed, list learning played an important role in the recent\ncharacterization of multiclass learnability. In this work we ask: when is it\npossible to $k$-list learn a hypothesis class? We completely characterize\n$k$-list learnability in terms of a generalization of DS dimension that we call\nthe $k$-DS dimension. Generalizing the recent characterization of multiclass\nlearnability, we show that a hypothesis class is $k$-list learnable if and only\nif the $k$-DS dimension is finite.\n",
                "链接": "https://arxiv.org/abs/2211.04956"
            },
            {
                "文章ID": "69199",
                "标题": "List Online Classification",
                "作者": " Shay Moran,  Ohad Sharon,  Iska Tsubari,  Sivan Yosebashvili",
                "发布日期": "2023-05-19",
                "摘要": "  We study multiclass online prediction where the learner can predict using a\nlist of multiple labels (as opposed to just one label in the traditional\nsetting). We characterize learnability in this model using the $b$-ary\nLittlestone dimension. This dimension is a variation of the classical\nLittlestone dimension with the difference that binary mistake trees are\nreplaced with $(k+1)$-ary mistake trees, where $k$ is the number of labels in\nthe list. In the agnostic setting, we explore different scenarios depending on\nwhether the comparator class consists of single-labeled or multi-labeled\nfunctions and its tradeoff with the size of the lists the algorithm uses. We\nfind that it is possible to achieve negative regret in some cases and provide a\ncomplete characterization of when this is possible. As part of our work, we\nadapt classical algorithms such as Littlestone's SOA and Rosenblatt's\nPerceptron to predict using lists of labels. We also establish combinatorial\nresults for list-learnable classes, including an list online version of the\nSauer-Shelah-Perles Lemma. We state our results within the framework of pattern\nclasses -- a generalization of hypothesis classes which can represent adaptive\nhypotheses (i.e. functions with memory), and model data-dependent assumptions\nsuch as linear classification with margin.\n",
                "链接": "https://arxiv.org/abs/2303.15383"
            },
            {
                "文章ID": "101771",
                "标题": "OWL Reasoners still useable in 2023",
                "作者": " Konrad Abicht",
                "发布日期": "2023-09-14",
                "摘要": "  In a systematic literature and software review over 100 OWL reasoners/systems\nwere analyzed to see if they would still be usable in 2023. This has never been\ndone in this capacity. OWL reasoners still play an important role in knowledge\norganisation and management, but the last comprehensive surveys/studies are\nmore than 8 years old. The result of this work is a comprehensive list of 95\nstandalone OWL reasoners and systems using an OWL reasoner. For each item,\ninformation on project pages, source code repositories and related\ndocumentation was gathered. The raw research data is provided in a Github\nrepository for anyone to use.\n",
                "链接": "https://arxiv.org/abs/2309.06888"
            },
            {
                "文章ID": "91898",
                "标题": "Rob\\^oCIn Small Size League Extended Team Description Paper for RoboCup\n  2023",
                "作者": " Aline Lima de Oliveira,  Cauê Addae da Silva Gomes,  Cecília Virginia Santos da Silva,  Charles Matheus de Sousa Alves,  Danilo Andrade Martins de Souza,  Driele Pires Ferreira Araújo Xavier,  Edgleyson Pereira da Silva,  Felipe Bezerra Martins,  Lucas Henrique Cavalcanti Santos,  Lucas Dias Maciel,  Matheus Paixão Gumercindo dos Santos,  Matheus Lafayette Vasconcelos,  Matheus Vinícius Teotonio do Nascimento Andrade,  João Guilherme Oliveira Carvalho de Melo,  João Pedro Souza Pereira de Moura,  José Ronald da Silva,  José Victor Silva Cruz,  Pedro Henrique Santana de Morais,  Pedro Paulo Salman de Oliveira,  Riei Joaquim Matos Rodrigues,  Roberto Costa Fernandes,  Ryan Vinicius Santos Morais,  Tamara Mayara Ramos Teobaldo,  Washington Igor dos Santos Silva,  Edna Natividade Silva Barros",
                "发布日期": "2023-07-20",
                "摘要": "  Rob\\^oCIn has participated in RoboCup Small Size League since 2019, won its\nfirst world title in 2022 (Division B), and is currently a three-times\nLatin-American champion. This paper presents our improvements to defend the\nSmall Size League (SSL) division B title in RoboCup 2023 in Bordeaux, France.\nThis paper aims to share some of the academic research that our team developed\nover the past year. Our team has successfully published 2 articles related to\nSSL at two high-impact conferences: the 25th RoboCup International Symposium\nand the 19th IEEE Latin American Robotics Symposium (LARS 2022). Over the last\nyear, we have been continuously migrating from our past codebase to\nUnification. We will describe the new architecture implemented and some points\nof software and AI refactoring. In addition, we discuss the process of\nintegrating machined components into the mechanical system, our development for\nparticipating in the vision blackout challenge last year and what we are\npreparing for this year.\n",
                "链接": "https://arxiv.org/abs/2307.10018"
            },
            {
                "文章ID": "25879",
                "标题": "List-Decodable Covariance Estimation",
                "作者": " Misha Ivkov,  Pravesh K. Kothari",
                "发布日期": "2022-06-23",
                "摘要": "  We give the first polynomial time algorithm for \\emph{list-decodable\ncovariance estimation}. For any $\\alpha > 0$, our algorithm takes input a\nsample $Y \\subseteq \\mathbb{R}^d$ of size $n\\geq d^{\\mathsf{poly}(1/\\alpha)}$\nobtained by adversarially corrupting an $(1-\\alpha)n$ points in an i.i.d.\nsample $X$ of size $n$ from the Gaussian distribution with unknown mean $\\mu_*$\nand covariance $\\Sigma_*$. In $n^{\\mathsf{poly}(1/\\alpha)}$ time, it outputs a\nconstant-size list of $k = k(\\alpha)= (1/\\alpha)^{\\mathsf{poly}(1/\\alpha)}$\ncandidate parameters that, with high probability, contains a\n$(\\hat{\\mu},\\hat{\\Sigma})$ such that the total variation distance\n$TV(\\mathcal{N}(\\mu_*,\\Sigma_*),\\mathcal{N}(\\hat{\\mu},\\hat{\\Sigma}))<1-O_{\\alpha}(1)$.\nThis is the statistically strongest notion of distance and implies\nmultiplicative spectral and relative Frobenius distance approximation for\nparameters with dimension independent error. Our algorithm works more generally\nfor $(1-\\alpha)$-corruptions of any distribution $D$ that possesses low-degree\nsum-of-squares certificates of two natural analytic properties: 1)\nanti-concentration of one-dimensional marginals and 2) hypercontractivity of\ndegree 2 polynomials.\n  Prior to our work, the only known results for estimating covariance in the\nlist-decodable setting were for the special cases of list-decodable linear\nregression and subspace recovery due to Karmarkar, Klivans, and Kothari (2019),\nRaghavendra and Yau (2019 and 2020) and Bakshi and Kothari (2020). These\nresults need superpolynomial time for obtaining any subconstant error in the\nunderlying dimension. Our result implies the first polynomial-time \\emph{exact}\nalgorithm for list-decodable linear regression and subspace recovery that\nallows, in particular, to obtain $2^{-\\mathsf{poly}(d)}$ error in\npolynomial-time. Our result also implies an improved algorithm for clustering\nnon-spherical mixtures.\n",
                "链接": "https://arxiv.org/abs/2206.10942"
            },
            {
                "文章ID": "84651",
                "标题": "CUED at ProbSum 2023: Hierarchical Ensemble of Summarization Models",
                "作者": " Potsawee Manakul,  Yassir Fathullah,  Adian Liusie,  Vyas Raina,  Vatsal Raina,  Mark Gales",
                "发布日期": "2023-06-09",
                "摘要": "  In this paper, we consider the challenge of summarizing patients' medical\nprogress notes in a limited data setting. For the Problem List Summarization\n(shared task 1A) at the BioNLP Workshop 2023, we demonstrate that Clinical-T5\nfine-tuned to 765 medical clinic notes outperforms other extractive,\nabstractive and zero-shot baselines, yielding reasonable baseline systems for\nmedical note summarization. Further, we introduce Hierarchical Ensemble of\nSummarization Models (HESM), consisting of token-level ensembles of diverse\nfine-tuned Clinical-T5 models, followed by Minimum Bayes Risk (MBR) decoding.\nOur HESM approach lead to a considerable summarization performance boost, and\nwhen evaluated on held-out challenge data achieved a ROUGE-L of 32.77, which\nwas the best-performing system at the top of the shared task leaderboard.\n",
                "链接": "https://arxiv.org/abs/2306.05317"
            },
            {
                "文章ID": "49997",
                "标题": "Efficient List-Decodable Regression using Batches",
                "作者": " Abhimanyu Das,  Ayush Jain,  Weihao Kong,  Rajat Sen",
                "发布日期": "2022-11-24",
                "摘要": "  We begin the study of list-decodable linear regression using batches. In this\nsetting only an $\\alpha \\in (0,1]$ fraction of the batches are genuine. Each\ngenuine batch contains $\\ge n$ i.i.d. samples from a common unknown\ndistribution and the remaining batches may contain arbitrary or even\nadversarial samples. We derive a polynomial time algorithm that for any $n\\ge\n\\tilde \\Omega(1/\\alpha)$ returns a list of size $\\mathcal O(1/\\alpha^2)$ such\nthat one of the items in the list is close to the true regression parameter.\nThe algorithm requires only $\\tilde{\\mathcal{O}}(d/\\alpha^2)$ genuine batches\nand works under fairly general assumptions on the distribution.\n  The results demonstrate the utility of batch structure, which allows for the\nfirst polynomial time algorithm for list-decodable regression, which may be\nimpossible for the non-batch setting, as suggested by a recent SQ lower bound\n\\cite{diakonikolas2021statistical} for the non-batch setting.\n",
                "链接": "https://arxiv.org/abs/2211.12743"
            },
            {
                "文章ID": "16951",
                "标题": "List-Mode PET Image Reconstruction Using Deep Image Prior",
                "作者": " Kibo Ote,  Fumio Hashimoto,  Yuya Onishi,  Takashi Isobe,  Yasuomi Ouchi",
                "发布日期": "2023-02-10",
                "摘要": "  List-mode positron emission tomography (PET) image reconstruction is an\nimportant tool for PET scanners with many lines-of-response and additional\ninformation such as time-of-flight and depth-of-interaction. Deep learning is\none possible solution to enhance the quality of PET image reconstruction.\nHowever, the application of deep learning techniques to list-mode PET image\nreconstruction has not been progressed because list data is a sequence of bit\ncodes and unsuitable for processing by convolutional neural networks (CNN). In\nthis study, we propose a novel list-mode PET image reconstruction method using\nan unsupervised CNN called deep image prior (DIP) which is the first trial to\nintegrate list-mode PET image reconstruction and CNN. The proposed list-mode\nDIP reconstruction (LM-DIPRecon) method alternatively iterates the regularized\nlist-mode dynamic row action maximum likelihood algorithm (LM-DRAMA) and\nmagnetic resonance imaging conditioned DIP (MR-DIP) using an alternating\ndirection method of multipliers. We evaluated LM-DIPRecon using both simulation\nand clinical data, and it achieved sharper images and better tradeoff curves\nbetween contrast and noise than the LM-DRAMA, MR-DIP and sinogram-based\nDIPRecon methods. These results indicated that the LM-DIPRecon is useful for\nquantitative PET imaging with limited events while keeping accurate raw data\ninformation. In addition, as list data has finer temporal information than\ndynamic sinograms, list-mode deep image prior reconstruction is expected to be\nuseful for 4D PET imaging and motion correction.\n",
                "链接": "https://arxiv.org/abs/2204.13404"
            }
        ]
    },
    {
        "question": {
            "question": "请列出近一年来工业界发表的搜广推工作落地实践的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "73721",
                "标题": "MAWSEO: Adversarial Wiki Search Poisoning for Illicit Online Promotion",
                "作者": " Zilong Lin,  Zhengyi Li,  Xiaojing Liao,  XiaoFeng Wang,  Xiaozhong Liu",
                "发布日期": "2023-11-07",
                "摘要": "  As a prominent instance of vandalism edits, Wiki search poisoning for illicit\npromotion is a cybercrime in which the adversary aims at editing Wiki articles\nto promote illicit businesses through Wiki search results of relevant queries.\nIn this paper, we report a study that, for the first time, shows that such\nstealthy blackhat SEO on Wiki can be automated. Our technique, called MAWSEO,\nemploys adversarial revisions to achieve real-world cybercriminal objectives,\nincluding rank boosting, vandalism detection evasion, topic relevancy, semantic\nconsistency, user awareness (but not alarming) of promotional content, etc. Our\nevaluation and user study demonstrate that MAWSEO is capable of effectively and\nefficiently generating adversarial vandalism edits, which can bypass\nstate-of-the-art built-in Wiki vandalism detectors, and also get promotional\ncontent through to Wiki users without triggering their alarms. In addition, we\ninvestigated potential defense, including coherence based detection and\nadversarial training of vandalism detection, against our attack in the Wiki\necosystem.\n",
                "链接": "https://arxiv.org/abs/2304.11300"
            },
            {
                "文章ID": "95207",
                "标题": "Search Engine and Recommendation System for the Music Industry built\n  with JinaAI",
                "作者": " Ishita Gopalakrishnan,  Sanjjushri Varshini R,  Ponshriharini V",
                "发布日期": "2023-08-09",
                "摘要": "  One of the most intriguing debates regarding a novel task is the development\nof search engines and recommendation-based systems in the music industry.\nStudies have shown a drastic depression in the search engine fields, due to\nconcerning factors such as speed, accuracy and the format of data given for\nquerying. Often people face difficulty in searching for a song solely based on\nthe title, hence a solution is proposed to complete a search analysis through a\nsingle query input and is matched with the lyrics of the songs present in the\ndatabase. Hence it is essential to incorporate cutting-edge technology tools\nfor developing a user-friendly search engine. Jina AI is an MLOps framework for\nbuilding neural search engines that are utilized, in order for the user to\nobtain accurate results. Jina AI effectively helps to maintain and enhance the\nquality of performance for the search engine for the query given. An effective\nsearch engine and a recommendation system for the music industry, built with\nJinaAI.\n",
                "链接": "https://arxiv.org/abs/2308.03842"
            },
            {
                "文章ID": "116105",
                "标题": "Work State-Centric AI Agents: Design, Implementation, and Management of\n  Cognitive Work Threads",
                "作者": " Chen Zhang",
                "发布日期": "2023-11-17",
                "摘要": "  AI agents excel in executing predefined tasks, but the dynamic management of\nwork state information during task execution remains an underexplored area. We\npropose a work state-centric AI agent model employing \"work notes\" to record\nand reflect the state throughout task execution. This paper details the model's\narchitecture, featuring worker threads for task oversight, planner modules for\ntask decomposition and planning, and executor modules for performing subtasks\nusing a ReAct-inspired thought-action loop. We provide an exhaustive work state\nrecord incorporating plans and outcomes, constituting a comprehensive work\njournal. Our results show that this model not only improves task execution\nefficiency but also lays a solid foundation for subsequent task analysis and\nauditing.\n",
                "链接": "https://arxiv.org/abs/2311.09576"
            },
            {
                "文章ID": "86257",
                "标题": "A Design Approach and Prototype Implementation for Factory Monitoring\n  Based on Virtual and Augmented Reality at the Edge of Industry 4.0",
                "作者": " Christos Anagnostopoulos,  Georgios Mylonas,  Apostolos P. Fournaris,  Christos Koulamas",
                "发布日期": "2023-06-19",
                "摘要": "  Virtual and augmented reality are currently enjoying a great deal of\nattention from the research community and the industry towards their adoption\nwithin industrial spaces and processes. However, the current design and\nimplementation landscape is still very fluid, while the community as a whole\nhas not yet consolidated into concrete design directions, other than basic\npatterns. Other open issues include the choice over a cloud or edge-based\narchitecture when designing such systems. Within this work, we present our\napproach for a monitoring intervention inside a factory space utilizing both VR\nand AR, based primarily on edge computing, while also utilizing the cloud. We\ndiscuss its main design directions, as well as a basic ontology to aid in\nsimple description of factory assets. In order to highlight the design aspects\nof our approach, we present a prototype implementation, based on a use case\nscenario in a factory site, within the context of the ENERMAN H2020 project.\n",
                "链接": "https://arxiv.org/abs/2306.09692"
            },
            {
                "文章ID": "88276",
                "标题": "Reducing Redundant Work in Jump Point Search",
                "作者": " Shizhe Zhao,  Daniel Harabor,  Peter J. Stuckey",
                "发布日期": "2023-06-29",
                "摘要": "  JPS (Jump Point Search) is a state-of-the-art optimal algorithm for online\ngrid-based pathfinding. Widely used in games and other navigation scenarios,\nJPS nevertheless can exhibit pathological behaviours which are not well\nstudied: (i) it may repeatedly scan the same area of the map to find\nsuccessors; (ii) it may generate and expand suboptimal search nodes. In this\nwork, we examine the source of these pathological behaviours, show how they can\noccur in practice, and propose a purely online approach, called Constrained JPS\n(CJPS), to tackle them efficiently. Experimental results show that CJPS has low\noverheads and is often faster than JPS in dynamically changing grid\nenvironments: by up to 7x in large game maps and up to 14x in pathological\nscenarios.\n",
                "链接": "https://arxiv.org/abs/2306.15928"
            },
            {
                "文章ID": "81774",
                "标题": "Attention Paper: How Generative AI Reshapes Digital Shadow Industry?",
                "作者": " Qichao Wang,  Huan Ma,  Wentao Wei,  Hangyu Li,  Liang Chen,  Peilin Zhao,  Binwen Zhao,  Bo Hu,  Shu Zhang,  Zibin Zheng,  Bingzhe Wu",
                "发布日期": "2023-05-31",
                "摘要": "  The rapid development of digital economy has led to the emergence of various\nblack and shadow internet industries, which pose potential risks that can be\nidentified and managed through digital risk management (DRM) that uses\ndifferent techniques such as machine learning and deep learning. The evolution\nof DRM architecture has been driven by changes in data forms. However, the\ndevelopment of AI-generated content (AIGC) technology, such as ChatGPT and\nStable Diffusion, has given black and shadow industries powerful tools to\npersonalize data and generate realistic images and conversations for fraudulent\nactivities. This poses a challenge for DRM systems to control risks from the\nsource of data generation and to respond quickly to the fast-changing risk\nenvironment. This paper aims to provide a technical analysis of the challenges\nand opportunities of AIGC from upstream, midstream, and downstream paths of\nblack/shadow industries and suggest future directions for improving existing\nrisk control systems. The paper will explore the new black and shadow\ntechniques triggered by generative AI technology and provide insights for\nbuilding the next-generation DRM system.\n",
                "链接": "https://arxiv.org/abs/2305.18346"
            },
            {
                "文章ID": "102599",
                "标题": "Search and Learning for Unsupervised Text Generation",
                "作者": " Lili Mou",
                "发布日期": "2023-09-19",
                "摘要": "  With the advances of deep learning techniques, text generation is attracting\nincreasing interest in the artificial intelligence (AI) community, because of\nits wide applications and because it is an essential component of AI.\nTraditional text generation systems are trained in a supervised way, requiring\nmassive labeled parallel corpora. In this paper, I will introduce our recent\nwork on search and learning approaches to unsupervised text generation, where a\nheuristic objective function estimates the quality of a candidate sentence, and\ndiscrete search algorithms generate a sentence by maximizing the search\nobjective. A machine learning model further learns from the search results to\nsmooth out noise and improve efficiency. Our approach is important to the\nindustry for building minimal viable products for a new task; it also has high\nsocial impacts for saving human annotation labor and for processing\nlow-resource languages.\n",
                "链接": "https://arxiv.org/abs/2309.09497"
            },
            {
                "文章ID": "86572",
                "标题": "INDCOR white paper 3: Interactive Digital Narratives and Interaction",
                "作者": " Frank Nack,  Sandy Louchart,  Kris Lund,  Mattia Bellini,  Iva Georgieva,  Pratama W. Atmaja,  Peter Makai",
                "发布日期": "2023-07-19",
                "摘要": "  The nature of interaction within Interactive Digital Narrative (IDN) is\ninherently complex. This is due, in part, to the wide range of potential\ninteraction modes through which IDNs can be conceptualised, produced and\ndeployed and the complex dynamics this might entail. The purpose of this\nwhitepaper is to provide IDN practitioners with the essential knowledge on the\nnature of interaction in IDNs and allow them to make informed design decisions\nthat lead to the incorporation of complexity thinking throughout the design\npipeline, the implementation of the work, and the ways its audience perceives\nit. This white paper is concerned with the complexities of authoring,\ndelivering and processing dynamic interactive contents from the perspectives of\nboth creators and audiences. This white paper is part of a series of\npublications by the INDCOR COST Action 18230 (Interactive Narrative Design for\nComplexity Representations), which all clarify how IDNs representing complexity\ncan be understood and applied (INDCOR WP 0 - 5, 2023).\n",
                "链接": "https://arxiv.org/abs/2306.10547"
            },
            {
                "文章ID": "91128",
                "标题": "Promotion/Inhibition Effects in Networks: A Model with Negative\n  Probabilities",
                "作者": " Anqi Dong,  Tryphon T. Georgiou,  Allen Tannenbaum",
                "发布日期": "2023-08-21",
                "摘要": "  Biological networks often encapsulate promotion/inhibition as signed\nedge-weights of a graph. Nodes may correspond to genes assigned expression\nlevels (mass) of respective proteins. The promotion/inhibition nature of\nco-expression between nodes is encoded in the sign of the corresponding entry\nof a sign-indefinite adjacency matrix, though the strength of such\nco-expression (i.e., the precise value of edge weights) cannot typically be\ndirectly measured. Herein we address the inverse problem to determine network\nedge-weights based on a sign-indefinite adjacency and expression levels at the\nnodes. While our motivation originates in gene networks, the framework applies\nto networks where promotion/inhibition dictates a stationary mass distribution\nat the nodes. In order to identify suitable edge-weights we adopt a framework\nof ``negative probabilities,'' advocated by P.\\ Dirac and R.\\ Feynman, and we\nset up a likelihood formalism to obtain values for the sought edge-weights. The\nproposed optimization problem can be solved via a generalization of the\nwell-known Sinkhorn algorithm; in our setting the Sinkhorn-type ``diagonal\nscalings'' are multiplicative or inverse-multiplicative, depending on the sign\nof the respective entries in the adjacency matrix, with value computed as the\npositive root of a quadratic polynomial.\n",
                "链接": "https://arxiv.org/abs/2307.07738"
            },
            {
                "文章ID": "117763",
                "标题": "Out-of-Distribution Generalized Dynamic Graph Neural Network with\n  Disentangled Intervention and Invariance Promotion",
                "作者": " Zeyang Zhang,  Xin Wang,  Ziwei Zhang,  Haoyang Li,  Wenwu Zhu",
                "发布日期": "2023-11-27",
                "摘要": "  Dynamic graph neural networks (DyGNNs) have demonstrated powerful predictive\nabilities by exploiting graph structural and temporal dynamics. However, the\nexisting DyGNNs fail to handle distribution shifts, which naturally exist in\ndynamic graphs, mainly because the patterns exploited by DyGNNs may be variant\nwith respect to labels under distribution shifts. In this paper, we propose\nDisentangled Intervention-based Dynamic graph Attention networks with\nInvariance Promotion (I-DIDA) to handle spatio-temporal distribution shifts in\ndynamic graphs by discovering and utilizing invariant patterns, i.e.,\nstructures and features whose predictive abilities are stable across\ndistribution shifts. Specifically, we first propose a disentangled\nspatio-temporal attention network to capture the variant and invariant\npatterns. By utilizing the disentangled patterns, we design a spatio-temporal\nintervention mechanism to create multiple interventional distributions and an\nenvironment inference module to infer the latent spatio-temporal environments,\nand minimize the variance of predictions among these intervened distributions\nand environments, so that our model can make predictions based on invariant\npatterns with stable predictive abilities under distribution shifts. Extensive\nexperiments demonstrate the superiority of our method over state-of-the-art\nbaselines under distribution shifts. Our work is the first study of\nspatio-temporal distribution shifts in dynamic graphs, to the best of our\nknowledge.\n",
                "链接": "https://arxiv.org/abs/2311.14255"
            }
        ]
    },
    {
        "question": {
            "question": "闭源大模型用户数据隐私保护研究",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "推荐与AutoGPT相似的10篇文献",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "86417",
                "标题": "AD-AutoGPT: An Autonomous GPT for Alzheimer's Disease Infodemiology",
                "作者": " Haixing Dai,  Yiwei Li,  Zhengliang Liu,  Lin Zhao,  Zihao Wu,  Suhang Song,  Ye Shen,  Dajiang Zhu,  Xiang Li,  Sheng Li,  Xiaobai Yao,  Lu Shi,  Quanzheng Li,  Zhuo Chen,  Donglan Zhang,  Gengchen Mai,  Tianming Liu",
                "发布日期": "2023-06-21",
                "摘要": "  In this pioneering study, inspired by AutoGPT, the state-of-the-art\nopen-source application based on the GPT-4 large language model, we develop a\nnovel tool called AD-AutoGPT which can conduct data collection, processing, and\nanalysis about complex health narratives of Alzheimer's Disease in an\nautonomous manner via users' textual prompts. We collated comprehensive data\nfrom a variety of news sources, including the Alzheimer's Association, BBC,\nMayo Clinic, and the National Institute on Aging since June 2022, leading to\nthe autonomous execution of robust trend analyses, intertopic distance maps\nvisualization, and identification of salient terms pertinent to Alzheimer's\nDisease. This approach has yielded not only a quantifiable metric of relevant\ndiscourse but also valuable insights into public focus on Alzheimer's Disease.\nThis application of AD-AutoGPT in public health signifies the transformative\npotential of AI in facilitating a data-rich understanding of complex health\nnarratives like Alzheimer's Disease in an autonomous manner, setting the\ngroundwork for future AI-driven investigations in global health landscapes.\n",
                "链接": "https://arxiv.org/abs/2306.10095"
            },
            {
                "文章ID": "89683",
                "标题": "PLIERS: a Popularity-Based Recommender System for Content Dissemination\n  in Online Social Networks",
                "作者": " Valerio Arnaboldi,  Mattia Giovanni Campana,  Franca Delmastro,  Elena Pagani",
                "发布日期": "2023-07-07",
                "摘要": "  In this paper, we propose a novel tag-based recommender system called PLIERS,\nwhich relies on the assumption that users are mainly interested in items and\ntags with similar popularity to those they already own. PLIERS is aimed at\nreaching a good tradeoff between algorithmic complexity and the level of\npersonalization of recommended items. To evaluate PLIERS, we performed a set of\nexperiments on real OSN datasets, demonstrating that it outperforms\nstate-of-the-art solutions in terms of personalization, relevance, and novelty\nof recommendations.\n",
                "链接": "https://arxiv.org/abs/2307.02865"
            },
            {
                "文章ID": "123126",
                "标题": "Do Similar Entities have Similar Embeddings?",
                "作者": " Nicolas Hubert,  Heiko Paulheim,  Armelle Brun,  Davy Monticolo",
                "发布日期": "2023-12-19",
                "摘要": "  Knowledge graph embedding models (KGEMs) developed for link prediction learn\nvector representations for graph entities, known as embeddings. A common tacit\nassumption is the KGE entity similarity assumption, which states that these\nKGEMs retain the graph's structure within their embedding space, i.e., position\nsimilar entities close to one another. This desirable property make KGEMs\nwidely used in downstream tasks such as recommender systems or drug\nrepurposing. Yet, the alignment of graph similarity with embedding space\nsimilarity has rarely been formally evaluated. Typically, KGEMs are assessed\nbased on their sole link prediction capabilities, using ranked-based metrics\nsuch as Hits@K or Mean Rank. This paper challenges the prevailing assumption\nthat entity similarity in the graph is inherently mirrored in the embedding\nspace. Therefore, we conduct extensive experiments to measure the capability of\nKGEMs to cluster similar entities together, and investigate the nature of the\nunderlying factors. Moreover, we study if different KGEMs expose a different\nnotion of similarity. Datasets, pre-trained embeddings and code are available\nat: https://github.com/nicolas-hbt/similar-embeddings.\n",
                "链接": "https://arxiv.org/abs/2312.10370"
            },
            {
                "文章ID": "119726",
                "标题": "A Hypergraph-Based Approach to Recommend Online Resources in a Library",
                "作者": " Debashish Roy,  Rajarshi Roy Chowdhury",
                "发布日期": "2023-12-05",
                "摘要": "  When users in a digital library read or browse online resources, it generates\nan immense amount of data. If the underlying system can recommend items, such\nas books and journals, to the users, it will help them to find the related\nitems. This research analyzes a digital library's usage data to recommend items\nto its users, and it uses different clustering algorithms to design the\nrecommender system. We have used content-based clustering, including\nhierarchical, expectation maximization (EM), K-mean, FarthestFirst, and\ndensity-based clustering algorithms, and user access pattern-based clustering,\nwhich uses a hypergraph-based approach to generate the clusters. This research\nshows that the recommender system designed using the hypergraph algorithm\ngenerates the most accurate recommendation model compared to those designed\nusing the content-based clustering approaches.\n",
                "链接": "https://arxiv.org/abs/2312.01007"
            },
            {
                "文章ID": "1281",
                "标题": "RecoMed: A Knowledge-Aware Recommender System for Hypertension\n  Medications",
                "作者": " Maryam Sajde,  Hamed Malek,  Mehran Mohsenzadeh",
                "发布日期": "2022-06-10",
                "摘要": "  Background and Objective High medicine diversity has always been a\nsignificant challenge for prescription, causing confusion or doubt in\nphysicians' decision-making process. This paper aims to develop a medicine\nrecommender system called RecoMed to aid the physician in the prescription\nprocess of hypertension by providing information about what medications have\nbeen prescribed by other doctors and figuring out what other medicines can be\nrecommended in addition to the one in question. Methods There are two steps to\nthe developed method: First, association rule mining algorithms are employed to\nfind medicine association rules. The second step entails graph mining and\nclustering to present an enriched recommendation via ATC code, which itself\ncomprises several steps. First, the initial graph is constructed from\nhistorical prescription data. Then, data pruning is performed in the second\nstep, after which the medicines with a high repetition rate are removed at the\ndiscretion of a general medical practitioner. Next, the medicines are matched\nto a well-known medicine classification system called the ATC code to provide\nan enriched recommendation. And finally, the DBSCAN and Louvain algorithms\ncluster medicines in the final step. Results A list of recommended medicines is\nprovided as the system's output, and physicians can choose one or more of the\nmedicines based on the patient's clinical symptoms. Only the medicines of class\n2, related to high blood pressure medications, are used to assess the system's\nperformance. The results obtained from this system have been reviewed and\nconfirmed by an expert in this field.\n",
                "链接": "https://arxiv.org/abs/2201.05461"
            },
            {
                "文章ID": "63484",
                "标题": "AugGPT: Leveraging ChatGPT for Text Data Augmentation",
                "作者": " Haixing Dai,  Zhengliang Liu,  Wenxiong Liao,  Xiaoke Huang,  Yihan Cao,  Zihao Wu,  Lin Zhao,  Shaochen Xu,  Wei Liu,  Ninghao Liu,  Sheng Li,  Dajiang Zhu,  Hongmin Cai,  Lichao Sun,  Quanzheng Li,  Dinggang Shen,  Tianming Liu,  Xiang Li",
                "发布日期": "2023-03-21",
                "摘要": "  Text data augmentation is an effective strategy for overcoming the challenge\nof limited sample sizes in many natural language processing (NLP) tasks. This\nchallenge is especially prominent in the few-shot learning scenario, where the\ndata in the target domain is generally much scarcer and of lowered quality. A\nnatural and widely-used strategy to mitigate such challenges is to perform data\naugmentation to better capture the data invariance and increase the sample\nsize. However, current text data augmentation methods either can't ensure the\ncorrect labeling of the generated data (lacking faithfulness) or can't ensure\nsufficient diversity in the generated data (lacking compactness), or both.\nInspired by the recent success of large language models, especially the\ndevelopment of ChatGPT, which demonstrated improved language comprehension\nabilities, in this work, we propose a text data augmentation approach based on\nChatGPT (named AugGPT). AugGPT rephrases each sentence in the training samples\ninto multiple conceptually similar but semantically different samples. The\naugmented samples can then be used in downstream model training. Experiment\nresults on few-shot learning text classification tasks show the superior\nperformance of the proposed AugGPT approach over state-of-the-art text data\naugmentation methods in terms of testing accuracy and distribution of the\naugmented samples.\n",
                "链接": "https://arxiv.org/abs/2302.13007"
            },
            {
                "文章ID": "20384",
                "标题": "Diversity Preference-Aware Link Recommendation for Online Social\n  Networks",
                "作者": " Kexin Yin,  Xiao Fang,  Bintong Chen,  Olivia Sheng",
                "发布日期": "2022-10-19",
                "摘要": "  Link recommendation, which recommends links to connect unlinked online social\nnetwork users, is a fundamental social network analytics problem with ample\nbusiness implications. Existing link recommendation methods tend to recommend\nsimilar friends to a user but overlook the user's diversity preference,\nalthough social psychology theories suggest the criticality of diversity\npreference to link recommendation performance. In recommender systems, a field\nrelated to link recommendation, a number of diversification methods have been\nproposed to improve the diversity of recommended items. Nevertheless, diversity\npreference is distinct from diversity studied by diversification methods. To\naddress these research gaps, we define and operationalize the concept of\ndiversity preference for link recommendation and propose a new link\nrecommendation problem: the diversity preference-aware link recommendation\nproblem. We then analyze key properties of the new link recommendation problem\nand develop a novel link recommendation method to solve the problem. Using two\nlarge-scale online social network data sets, we conduct extensive empirical\nevaluations to demonstrate the superior performance of our method over\nrepresentative diversification methods adapted for link recommendation as well\nas state-of-the-art link recommendation methods.\n",
                "链接": "https://arxiv.org/abs/2205.10689"
            },
            {
                "文章ID": "108389",
                "标题": "AutoVP: An Automated Visual Prompting Framework and Benchmark",
                "作者": " Hsi-Ai Tsao,  Lei Hsiung,  Pin-Yu Chen,  Sijia Liu,  Tsung-Yi Ho",
                "发布日期": "2023-10-13",
                "摘要": "  Visual prompting (VP) is an emerging parameter-efficient fine-tuning approach\nto adapting pre-trained vision models to solve various downstream\nimage-classification tasks. However, there has hitherto been little systematic\nstudy of the design space of VP and no clear benchmark for evaluating its\nperformance. To bridge this gap, we propose AutoVP, an end-to-end expandable\nframework for automating VP design choices, along with 12 downstream\nimage-classification tasks that can serve as a holistic VP-performance\nbenchmark. Our design space covers 1) the joint optimization of the prompts; 2)\nthe selection of pre-trained models, including image classifiers and text-image\nencoders; and 3) model output mapping strategies, including nonparametric and\ntrainable label mapping. Our extensive experimental results show that AutoVP\noutperforms the best-known current VP methods by a substantial margin, having\nup to 6.7% improvement in accuracy; and attains a maximum performance increase\nof 27.5% compared to linear-probing (LP) baseline. AutoVP thus makes a two-fold\ncontribution: serving both as an efficient tool for hyperparameter tuning on VP\ndesign choices, and as a comprehensive benchmark that can reasonably be\nexpected to accelerate VP's development. The source code is available at\nhttps://github.com/IBM/AutoVP.\n",
                "链接": "https://arxiv.org/abs/2310.08381"
            },
            {
                "文章ID": "72991",
                "标题": "MATURE-HEALTH: HEALTH Recommender System for MAndatory FeaTURE choices",
                "作者": " Ritu Shandilya,  Sugam Sharma,  Johnny Wong",
                "发布日期": "2023-04-24",
                "摘要": "  Balancing electrolytes is utmost important and essential for appropriate\nfunctioning of organs in human body as electrolytes imbalance can be an\nindication of the development of underlying pathophysiology. Efficient\nmonitoring of electrolytes imbalance not only can increase the chances of early\ndetection of disease, but also prevents the further deterioration of the health\nby strictly following nutrient controlled diet for balancing the electrolytes\npost disease detection. In this research, a recommender system MATURE Health is\nproposed and implemented, which predicts the imbalance of mandatory\nelectrolytes and other substances presented in blood and recommends the food\nitems with the balanced nutrients to avoid occurrence of the electrolytes\nimbalance. The proposed model takes user most recent laboratory results and\ndaily food intake into account to predict the electrolytes imbalance. MATURE\nHealth relies on MATURE Food algorithm to recommend food items as latter\nrecommends only those food items that satisfy all mandatory nutrient\nrequirements while also considering user past food preferences. To validate the\nproposed method, particularly sodium, potassium, and BUN levels have been\npredicted with prediction algorithm, Random Forest, for dialysis patients using\ntheir laboratory reports history and daily food intake. And, the proposed model\ndemonstrates 99.53 percent, 96.94 percent and 95.35 percent accuracy for\nSodium, Potassium, and BUN respectively. MATURE Health is a novel health\nrecommender system that implements machine learning models to predict the\nimbalance of mandatory electrolytes and other substances in the blood and\nrecommends the food items which contain the required amount of the nutrients\nthat prevent or at least reduce the risk of the electrolytes imbalance.\n",
                "链接": "https://arxiv.org/abs/2304.09099"
            },
            {
                "文章ID": "91448",
                "标题": "Leveraging Recommender Systems to Reduce Content Gaps on Peer Production\n  Platforms",
                "作者": " Mo Houtti,  Isaac Johnson,  Loren Terveen",
                "发布日期": "2023-07-19",
                "摘要": "  Peer production platforms like Wikipedia commonly suffer from content gaps.\nPrior research suggests recommender systems can help solve this problem, by\nguiding editors towards underrepresented topics. However, it remains unclear\nwhether this approach would result in less relevant recommendations, leading to\nreduced overall engagement with recommended items. To answer this question, we\nfirst conducted offline analyses (Study 1) on SuggestBot, a task-routing\nrecommender system for Wikipedia, then did a three-month controlled experiment\n(Study 2). Our results show that presenting users with articles from\nunderrepresented topics increased the proportion of work done on those articles\nwithout significantly reducing overall recommendation uptake. We discuss the\nimplications of our results, including how ignoring the article discovery\nprocess can artificially narrow recommendations. We draw parallels between this\nphenomenon and the common issue of \"filter bubbles\" to show how any platform\nthat employs recommender systems is susceptible to it.\n",
                "链接": "https://arxiv.org/abs/2307.08669"
            }
        ]
    },
    {
        "question": {
            "question": "请搜索近一年发表的有关多模态大模型与产业相结合、与具体应用场景相结合的论文",
            "type": "2"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究，特别关注使用自动标注和迁移学习方法的论文，时间跨度覆盖2019年至今。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "请找出最近一年内发表的关于自然语言处理领域中，使用Transformer模型并在大规模数据集上进行预训练的论文。特别关注模型结构和性能指标。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "109322",
                "标题": "Enhanced Transformer Architecture for Natural Language Processing",
                "作者": " Woohyeon Moon,  Taeyoung Kim,  Bumgeun Park,  Dongsoo Har",
                "发布日期": "2023-10-18",
                "摘要": "  Transformer is a state-of-the-art model in the field of natural language\nprocessing (NLP). Current NLP models primarily increase the number of\ntransformers to improve processing performance. However, this technique\nrequires a lot of training resources such as computing capacity. In this paper,\na novel structure of Transformer is proposed. It is featured by full layer\nnormalization, weighted residual connection, positional encoding exploiting\nreinforcement learning, and zero masked self-attention. The proposed\nTransformer model, which is called Enhanced Transformer, is validated by the\nbilingual evaluation understudy (BLEU) score obtained with the Multi30k\ntranslation dataset. As a result, the Enhanced Transformer achieves 202.96%\nhigher BLEU score as compared to the original transformer with the translation\ndataset.\n",
                "链接": "https://arxiv.org/abs/2310.10930"
            },
            {
                "文章ID": "75927",
                "标题": "Online Gesture Recognition using Transformer and Natural Language\n  Processing",
                "作者": " G. C. M. Silvestre,  F. Balado,  O. Akinremi,  M. Ramo",
                "发布日期": "2023-05-08",
                "摘要": "  The Transformer architecture is shown to provide a powerful machine\ntransduction framework for online handwritten gestures corresponding to glyph\nstrokes of natural language sentences. The attention mechanism is successfully\nused to create latent representations of an end-to-end encoder-decoder model,\nsolving multi-level segmentation while also learning some language features and\nsyntax rules. The additional use of a large decoding space with some learned\nByte-Pair-Encoding (BPE) is shown to provide robustness to ablated inputs and\nsyntax rules. The encoder stack was directly fed with spatio-temporal data\ntokens potentially forming an infinitely large input vocabulary, an approach\nthat finds applications beyond that of this work. Encoder transfer learning\ncapabilities is also demonstrated on several languages resulting in faster\noptimisation and shared parameters. A new supervised dataset of online\nhandwriting gestures suitable for generic handwriting recognition tasks was\nused to successfully train a small transformer model to an average normalised\nLevenshtein accuracy of 96% on English or German sentences and 94% in French.\n",
                "链接": "https://arxiv.org/abs/2305.03407"
            },
            {
                "文章ID": "15795",
                "标题": "COOL, a Context Outlooker, and its Application to Question Answering and\n  other Natural Language Processing Tasks",
                "作者": " Fangyi Zhu,  See-Kiong Ng,  Stéphane Bressan",
                "发布日期": "2023-05-16",
                "摘要": "  Vision outlooker improves the performance of vision transformers, which\nimplements a self-attention mechanism by adding an outlook attention, a form of\nlocal attention.\n  In natural language processing, as has been the case in computer vision and\nother domains, transformer-based models constitute the state-of-the-art for\nmost processing tasks. In this domain, too, many authors have argued and\ndemonstrated the importance of local context.\n  We present an outlook attention mechanism, COOL, for natural language\nprocessing. COOL, added on top of the self-attention layers of a\ntransformer-based model, encodes local syntactic context considering word\nproximity and more pair-wise constraints than dynamic convolution used by\nexisting approaches.\n  A comparative empirical performance evaluation of an implementation of COOL\nwith different transformer-based models confirms the opportunity for\nimprovement over a baseline using the original models alone for various natural\nlanguage processing tasks, including question answering. The proposed approach\nachieves competitive performance with existing state-of-the-art methods on some\ntasks.\n",
                "链接": "https://arxiv.org/abs/2204.09593"
            },
            {
                "文章ID": "78199",
                "标题": "Generative Pre-trained Transformer: A Comprehensive Review on Enabling\n  Technologies, Potential Applications, Emerging Challenges, and Future\n  Directions",
                "作者": " Gokul Yenduri,  Ramalingam M,  Chemmalar Selvi G,  Supriya Y,  Gautam Srivastava,  Praveen Kumar Reddy Maddikunta,  Deepti Raj G,  Rutvij H Jhaveri,  Prabadevi B,  Weizheng Wang,  Athanasios V. Vasilakos,  Thippa Reddy Gadekallu",
                "发布日期": "2023-05-23",
                "摘要": "  The Generative Pre-trained Transformer (GPT) represents a notable\nbreakthrough in the domain of natural language processing, which is propelling\nus toward the development of machines that can understand and communicate using\nlanguage in a manner that closely resembles that of humans. GPT is based on the\ntransformer architecture, a deep neural network designed for natural language\nprocessing tasks. Due to their impressive performance on natural language\nprocessing tasks and ability to effectively converse, GPT have gained\nsignificant popularity among researchers and industrial communities, making\nthem one of the most widely used and effective models in natural language\nprocessing and related fields, which motivated to conduct this review. This\nreview provides a detailed overview of the GPT, including its architecture,\nworking process, training procedures, enabling technologies, and its impact on\nvarious applications. In this review, we also explored the potential challenges\nand limitations of a GPT. Furthermore, we discuss potential solutions and\nfuture directions. Overall, this paper aims to provide a comprehensive\nunderstanding of GPT, enabling technologies, their impact on various\napplications, emerging challenges, and potential solutions.\n",
                "链接": "https://arxiv.org/abs/2305.10435"
            },
            {
                "文章ID": "115729",
                "标题": "Natural Language Processing for Financial Regulation",
                "作者": " Ixandra Achitouv,  Dragos Gorduza,  Antoine Jacquier",
                "发布日期": "2023-11-16",
                "摘要": "  This article provides an understanding of Natural Language Processing\ntechniques in the framework of financial regulation, more specifically in order\nto perform semantic matching search between rules and policy when no dataset is\navailable for supervised learning. We outline how to outperform simple\npre-trained sentences-transformer models using freely available resources and\nexplain the mathematical concepts behind the key building blocks of Natural\nLanguage Processing.\n",
                "链接": "https://arxiv.org/abs/2311.08533"
            },
            {
                "文章ID": "103848",
                "标题": "Hindi to English: Transformer-Based Neural Machine Translation",
                "作者": " Kavit Gangar,  Hardik Ruparel,  Shreyas Lele",
                "发布日期": "2023-09-26",
                "摘要": "  Machine Translation (MT) is one of the most prominent tasks in Natural\nLanguage Processing (NLP) which involves the automatic conversion of texts from\none natural language to another while preserving its meaning and fluency.\nAlthough the research in machine translation has been going on since multiple\ndecades, the newer approach of integrating deep learning techniques in natural\nlanguage processing has led to significant improvements in the translation\nquality. In this paper, we have developed a Neural Machine Translation (NMT)\nsystem by training the Transformer model to translate texts from Indian\nLanguage Hindi to English. Hindi being a low resource language has made it\ndifficult for neural networks to understand the language thereby leading to a\nslow growth in the development of neural machine translators. Thus, to address\nthis gap, we implemented back-translation to augment the training data and for\ncreating the vocabulary, we experimented with both word and subword level\ntokenization using Byte Pair Encoding (BPE) thereby ending up training the\nTransformer in 10 different configurations. This led us to achieve a\nstate-of-the-art BLEU score of 24.53 on the test set of IIT Bombay\nEnglish-Hindi Corpus in one of the configurations.\n",
                "链接": "https://arxiv.org/abs/2309.13222"
            },
            {
                "文章ID": "98764",
                "标题": "Improving Knowledge Distillation for BERT Models: Loss Functions,\n  Mapping Methods, and Weight Tuning",
                "作者": " Apoorv Dankar,  Adeem Jassani,  Kartikaeya Kumar",
                "发布日期": "2023-08-29",
                "摘要": "  The use of large transformer-based models such as BERT, GPT, and T5 has led\nto significant advancements in natural language processing. However, these\nmodels are computationally expensive, necessitating model compression\ntechniques that reduce their size and complexity while maintaining accuracy.\nThis project investigates and applies knowledge distillation for BERT model\ncompression, specifically focusing on the TinyBERT student model. We explore\nvarious techniques to improve knowledge distillation, including experimentation\nwith loss functions, transformer layer mapping methods, and tuning the weights\nof attention and representation loss and evaluate our proposed techniques on a\nselection of downstream tasks from the GLUE benchmark. The goal of this work is\nto improve the efficiency and effectiveness of knowledge distillation, enabling\nthe development of more efficient and accurate models for a range of natural\nlanguage processing tasks.\n",
                "链接": "https://arxiv.org/abs/2308.13958"
            },
            {
                "文章ID": "88808",
                "标题": "Investigating Masking-based Data Generation in Language Models",
                "作者": " Ed S. Ma",
                "发布日期": "2023-07-04",
                "摘要": "  The current era of natural language processing (NLP) has been defined by the\nprominence of pre-trained language models since the advent of BERT. A feature\nof BERT and models with similar architecture is the objective of masked\nlanguage modeling, in which part of the input is intentionally masked and the\nmodel is trained to predict this piece of masked information. Data augmentation\nis a data-driven technique widely used in machine learning, including research\nareas like computer vision and natural language processing, to improve model\nperformance by artificially augmenting the training data set by designated\ntechniques. Masked language models (MLM), an essential training feature of\nBERT, have introduced a novel approach to perform effective pre-training on\nTransformer based models in natural language processing tasks. Recent studies\nhave utilized masked language model to generate artificially augmented data for\nNLP downstream tasks. The experimental results show that Mask based data\naugmentation method provides a simple but efficient approach to improve the\nmodel performance. In this paper, we explore and discuss the broader\nutilization of these data augmentation methods based on MLM.\n",
                "链接": "https://arxiv.org/abs/2307.00008"
            },
            {
                "文章ID": "107377",
                "标题": "ViTs are Everywhere: A Comprehensive Study Showcasing Vision\n  Transformers in Different Domain",
                "作者": " Md Sohag Mia,  Abu Bakor Hayat Arnob,  Abdu Naim,  Abdullah Al Bary Voban,  Md Shariful Islam",
                "发布日期": "2023-10-16",
                "摘要": "  Transformer design is the de facto standard for natural language processing\ntasks. The success of the transformer design in natural language processing has\nlately piqued the interest of researchers in the domain of computer vision.\nWhen compared to Convolutional Neural Networks (CNNs), Vision Transformers\n(ViTs) are becoming more popular and dominant solutions for many vision\nproblems. Transformer-based models outperform other types of networks, such as\nconvolutional and recurrent neural networks, in a range of visual benchmarks.\nWe evaluate various vision transformer models in this work by dividing them\ninto distinct jobs and examining their benefits and drawbacks. ViTs can\novercome several possible difficulties with convolutional neural networks\n(CNNs). The goal of this survey is to show the first use of ViTs in CV. In the\nfirst phase, we categorize various CV applications where ViTs are appropriate.\nImage classification, object identification, image segmentation, video\ntransformer, image denoising, and NAS are all CV applications. Our next step\nwill be to analyze the state-of-the-art in each area and identify the models\nthat are currently available. In addition, we outline numerous open research\ndifficulties as well as prospective research possibilities.\n",
                "链接": "https://arxiv.org/abs/2310.05664"
            },
            {
                "文章ID": "91947",
                "标题": "Several categories of Large Language Models (LLMs): A Short Survey",
                "作者": " Saurabh Pahune,  Manoj Chandrasekharan",
                "发布日期": "2023-07-21",
                "摘要": "  Large Language Models(LLMs)have become effective tools for natural language\nprocessing and have been used in many different fields. This essay offers a\nsuccinct summary of various LLM subcategories. The survey emphasizes recent\ndevelopments and efforts made for various LLM kinds, including task-based\nfinancial LLMs, multilingual language LLMs, biomedical and clinical LLMs,\nvision language LLMs, and code language models. The survey gives a general\nsummary of the methods, attributes, datasets, transformer models, and\ncomparison metrics applied in each category of LLMs. Furthermore, it highlights\nunresolved problems in the field of developing chatbots and virtual assistants,\nsuch as boosting natural language processing, enhancing chatbot intelligence,\nand resolving moral and legal dilemmas. The purpose of this study is to provide\nreaders, developers, academics, and users interested in LLM-based chatbots and\nvirtual intelligent assistant technologies with useful information and future\ndirections.\n",
                "链接": "https://arxiv.org/abs/2307.10188"
            }
        ]
    },
    {
        "question": {
            "question": "请查找关于智能体的研究进展的综述或调查论文。重点关注不同领域中智能体的方法和应用，以及相关的挑战和未来方向。",
            "type": "5"
        },
        "results": []
    }
]