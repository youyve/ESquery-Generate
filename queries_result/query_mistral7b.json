[
    {
        "question": {
            "question": "查询近一年模型推理加速相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "111604",
                "标题": "Hierarchical Semi-Implicit Variational Inference with Application to\n  Diffusion Model Acceleration",
                "作者": " Longlin Yu,  Tianyu Xie,  Yu Zhu,  Tong Yang,  Xiangyu Zhang,  Cheng Zhang",
                "发布日期": "2023-10-27",
                "摘要": "  Semi-implicit variational inference (SIVI) has been introduced to expand the\nanalytical variational families by defining expressive semi-implicit\ndistributions in a hierarchical manner. However, the single-layer architecture\ncommonly used in current SIVI methods can be insufficient when the target\nposterior has complicated structures. In this paper, we propose hierarchical\nsemi-implicit variational inference, called HSIVI, which generalizes SIVI to\nallow more expressive multi-layer construction of semi-implicit distributions.\nBy introducing auxiliary distributions that interpolate between a simple base\ndistribution and the target distribution, the conditional layers can be trained\nby progressively matching these auxiliary distributions one layer after\nanother. Moreover, given pre-trained score networks, HSIVI can be used to\naccelerate the sampling process of diffusion models with the score matching\nobjective. We show that HSIVI significantly enhances the expressiveness of SIVI\non several Bayesian inference problems with complicated target distributions.\nWhen used for diffusion model acceleration, we show that HSIVI can produce high\nquality samples comparable to or better than the existing fast diffusion model\nbased samplers with a small number of function evaluations on various datasets.\n",
                "链接": "https://arxiv.org/abs/2310.17153"
            },
            {
                "文章ID": "123966",
                "标题": "Lookahead: An Inference Acceleration Framework for Large Language Model\n  with Lossless Generation Accuracy",
                "作者": " Yao Zhao,  Zhitian Xie,  Chenyi Zhuang,  Jinjie Gu",
                "发布日期": "2023-12-21",
                "摘要": "  As Large Language Models (LLMs) have made significant advancements across\nvarious tasks, such as question answering, translation, text summarization, and\ndialogue systems, the need for accuracy in information becomes crucial,\nespecially for serious financial products serving billions of users like\nAlipay. To address this, Alipay has developed a Retrieval-Augmented Generation\n(RAG) system that grounds LLMs on the most accurate and up-to-date information.\nHowever, for a real-world product serving millions of users, the inference\nspeed of LLMs becomes a critical factor compared to a mere experimental model.\n  Hence, this paper presents a generic framework for accelerating the inference\nprocess, resulting in a substantial increase in speed and cost reduction for\nour RAG system, with lossless generation accuracy. In the traditional inference\nprocess, each token is generated sequentially by the LLM, leading to a time\nconsumption proportional to the number of generated tokens. To enhance this\nprocess, our framework, named \\textit{lookahead}, introduces a\n\\textit{multi-branch} strategy. Instead of generating a single token at a time,\nwe propose a \\textit{Trie-based Retrieval} (TR) process that enables the\ngeneration of multiple branches simultaneously, each of which is a sequence of\ntokens. Subsequently, for each branch, a \\textit{Verification and Accept} (VA)\nprocess is performed to identify the longest correct sub-sequence as the final\noutput. Our strategy offers two distinct advantages: (1) it guarantees absolute\ncorrectness of the output, avoiding any approximation algorithms, and (2) the\nworst-case performance of our approach is equivalent to the conventional\nprocess. We conduct extensive experiments to demonstrate the significant\nimprovements achieved by applying our inference acceleration framework.\n",
                "链接": "https://arxiv.org/abs/2312.12728"
            },
            {
                "文章ID": "124676",
                "标题": "Understanding the Potential of FPGA-Based Spatial Acceleration for Large\n  Language Model Inference",
                "作者": " Hongzheng Chen,  Jiahao Zhang,  Yixiao Du,  Shaojie Xiang,  Zichao Yue,  Niansong Zhang,  Yaohui Cai,  Zhiru Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Recent advancements in large language models (LLMs) boasting billions of\nparameters have generated a significant demand for efficient deployment in\ninference workloads. The majority of existing approaches rely on temporal\narchitectures that reuse hardware units for different network layers and\noperators. However, these methods often encounter challenges in achieving low\nlatency due to considerable memory access overhead. This paper investigates the\nfeasibility and potential of model-specific spatial acceleration for LLM\ninference on FPGAs. Our approach involves the specialization of distinct\nhardware units for specific operators or layers, facilitating direct\ncommunication between them through a dataflow architecture while minimizing\noff-chip memory accesses. We introduce a comprehensive analytical model for\nestimating the performance of a spatial LLM accelerator, taking into account\nthe on-chip compute and memory resources available on an FPGA. Through our\nanalysis, we can determine the scenarios in which FPGA-based spatial\nacceleration can outperform its GPU-based counterpart. To enable more\nproductive implementations of an LLM model on FPGAs, we further provide a\nlibrary of high-level synthesis (HLS) kernels that are composable and reusable.\nThis library will be made available as open-source. To validate the\neffectiveness of both our analytical model and HLS library, we have implemented\nBERT and GPT2 on an AMD Alveo U280 FPGA device. Experimental results\ndemonstrate our approach can achieve up to 16.1x speedup when compared to\nprevious FPGA-based accelerators for the BERT model. For GPT generative\ninference, we attain a 2.2x speedup compared to DFX, an FPGA overlay, in the\nprefill stage, while achieving a 1.9x speedup and a 5.7x improvement in energy\nefficiency compared to the NVIDIA A100 GPU in the decode stage.\n",
                "链接": "https://arxiv.org/abs/2312.15159"
            },
            {
                "文章ID": "107843",
                "标题": "Sparse Fine-tuning for Inference Acceleration of Large Language Models",
                "作者": " Eldar Kurtic,  Denis Kuznedelev,  Elias Frantar,  Michael Goin,  Dan Alistarh",
                "发布日期": "2023-10-16",
                "摘要": "  We consider the problem of accurate sparse fine-tuning of large language\nmodels (LLMs), that is, fine-tuning pretrained LLMs on specialized tasks, while\ninducing sparsity in their weights. On the accuracy side, we observe that\nstandard loss-based fine-tuning may fail to recover accuracy, especially at\nhigh sparsities. To address this, we perform a detailed study of\ndistillation-type losses, determining an L2-based distillation approach we term\nSquareHead which enables accurate recovery even at higher sparsities, across\nall model types. On the practical efficiency side, we show that sparse LLMs can\nbe executed with speedups by taking advantage of sparsity, for both CPU and GPU\nruntimes. While the standard approach is to leverage sparsity for computational\nreduction, we observe that in the case of memory-bound LLMs sparsity can also\nbe leveraged for reducing memory bandwidth. We exhibit end-to-end results\nshowing speedups due to sparsity, while recovering accuracy, on T5 (language\ntranslation), Whisper (speech translation), and open GPT-type (MPT for text\ngeneration). For MPT text generation, we show for the first time that sparse\nfine-tuning can reach 75% sparsity without accuracy drops, provide notable\nend-to-end speedups for both CPU and GPU inference, and highlight that sparsity\nis also compatible with quantization approaches. Models and software for\nreproducing our results are provided in Section 6.\n",
                "链接": "https://arxiv.org/abs/2310.06927"
            },
            {
                "文章ID": "71550",
                "标题": "Inference with Reference: Lossless Acceleration of Large Language Models",
                "作者": " Nan Yang,  Tao Ge,  Liang Wang,  Binxing Jiao,  Daxin Jiang,  Linjun Yang,  Rangan Majumder,  Furu Wei",
                "发布日期": "2023-04-11",
                "摘要": "  We propose LLMA, an LLM accelerator to losslessly speed up Large Language\nModel (LLM) inference with references. LLMA is motivated by the observation\nthat there are abundant identical text spans between the decoding result by an\nLLM and the reference that is available in many real world scenarios (e.g.,\nretrieved documents). LLMA first selects a text span from the reference and\ncopies its tokens to the decoder and then efficiently checks the tokens'\nappropriateness as the decoding result in parallel within one decoding step.\nThe improved computational parallelism allows LLMA to achieve over 2x speed-up\nfor LLMs with identical generation results as greedy decoding in many practical\ngeneration scenarios where significant overlap between in-context reference and\noutputs exists (e.g., search engines and multi-turn conversations).\n",
                "链接": "https://arxiv.org/abs/2304.04487"
            },
            {
                "文章ID": "94810",
                "标题": "Exploiting On-chip Heterogeneity of Versal Architecture for GNN\n  Inference Acceleration",
                "作者": " Paul Chen,  Pavan Manjunath,  Sasindu Wijeratne,  Bingyi Zhang,  Viktor Prasanna",
                "发布日期": "2023-08-08",
                "摘要": "  Graph Neural Networks (GNNs) have revolutionized many Machine Learning (ML)\napplications, such as social network analysis, bioinformatics, etc. GNN\ninference can be accelerated by exploiting data sparsity in the input graph,\nvertex features, and intermediate data in GNN computations. For dynamic\nsparsity exploitation, we leverage the heterogeneous computing capabilities of\nAMD Versal ACAP architecture to accelerate GNN inference. We develop a custom\nhardware module that executes the sparse primitives of the computation kernel\non the Programmable Logic (PL) and efficiently computes the dense primitives\nusing the AI Engine (AIE). To exploit data sparsity during inference, we devise\na runtime kernel mapping strategy that dynamically assigns computation tasks to\nthe PL and AIE based on data sparsity. Our implementation on the VCK5000 ACAP\nplatform leads to superior performance compared with the state-of-the-art\nimplementations on CPU, GPU, ACAP, and other custom GNN accelerators. Compared\nwith these implementations, we achieve significant average runtime speedup\nacross various models and datasets of 162.42x, 17.01x, 9.90x, and 27.23x,\nrespectively. Furthermore, for Graph Convolutional Network (GCN) inference, our\napproach leads to a speedup of 3.9-96.7x compared to designs using PL only on\nthe same ACAP device.\n",
                "链接": "https://arxiv.org/abs/2308.02749"
            },
            {
                "文章ID": "35194",
                "标题": "FFCNN: Fast FPGA based Acceleration for Convolution neural network\n  inference",
                "作者": " F. Keddous,  H-N. Nguyen,  A. Nakib",
                "发布日期": "2022-08-30",
                "摘要": "  We present a new efficient OpenCL-based Accelerator for large scale\nConvolutional Neural Networks called Fast Inference on FPGAs for Convolution\nNeural Network (FFCNN). FFCNN is based on a deeply pipelined OpenCL kernels\narchitecture. As pointed out before, high-level synthesis tools such as the\nOpenCL framework can easily port codes originally designed for CPUs and GPUs to\nFPGAs, but it is still difficult to make OpenCL codes run efficiently on FPGAs.\nThis work aims to propose an efficient FPGA implementation of OpenCL\nHigh-Performance Computing Applications. To do so, a Data reuse and task\nmapping techniques are also presented to improve design efficiency. In\naddition, the following motivations were taken into account when developing\nFFCNN: 1) FFCNN has been designed to be easily implemented on Intel OpenCL SDK\nbased FPGA design flow. 2) In FFFCN, different techniques have been integrated\nto improve the memory band with and throughput. A performance analysis is\nconducted on two deep CNN for Large-Scale Images classification. The obtained\nresults, and the comparison with other works designed to accelerate the same\ntypes of architectures, show the efficiency and the competitiveness of the\nproposed accelerator design by significantly improved performance and resource\nutilization.\n",
                "链接": "https://arxiv.org/abs/2208.13250"
            },
            {
                "文章ID": "50323",
                "标题": "Design and Prototyping Distributed CNN Inference Acceleration in Edge\n  Computing",
                "作者": " Zhongtian Dong,  Nan Li,  Alexandros Iosifidis,  Qi Zhang",
                "发布日期": "2022-11-29",
                "摘要": "  For time-critical IoT applications using deep learning, inference\nacceleration through distributed computing is a promising approach to meet a\nstringent deadline. In this paper, we implement a working prototype of a new\ndistributed inference acceleration method HALP using three raspberry Pi 4. HALP\naccelerates inference by designing a seamless collaboration among edge devices\n(EDs) in Edge Computing. We maximize the parallelization between communication\nand computation among the collaborative EDs by optimizing the task partitioning\nratio based on the segment-based partitioning. Experimental results show that\nthe distributed inference HALP achieves 1.7x inference acceleration for VGG-16.\nThen, we combine distributed inference with conventional neural network model\ncompression by setting up different shrinking hyperparameters for MobileNet-V1.\nIn this way, we can further accelerate inference but at the cost of inference\naccuracy loss. To strike a balance between latency and accuracy, we propose\ndynamic model selection to select a model which provides the highest accuracy\nwithin the latency constraint. It is shown that the model selection with\ndistributed inference HALP can significantly improve service reliability\ncompared to the conventional stand-alone computation.\n",
                "链接": "https://arxiv.org/abs/2211.13778"
            },
            {
                "文章ID": "87109",
                "标题": "Adaptive DNN Surgery for Selfish Inference Acceleration with On-demand\n  Edge Resource",
                "作者": " Xiang Yang,  Dezhi Chen,  Qi Qi,  Jingyu Wang,  Haifeng Sun,  Jianxin Liao,  Song Guo",
                "发布日期": "2023-06-22",
                "摘要": "  Deep Neural Networks (DNNs) have significantly improved the accuracy of\nintelligent applications on mobile devices. DNN surgery, which partitions DNN\nprocessing between mobile devices and multi-access edge computing (MEC)\nservers, can enable real-time inference despite the computational limitations\nof mobile devices. However, DNN surgery faces a critical challenge: determining\nthe optimal computing resource demand from the server and the corresponding\npartition strategy, while considering both inference latency and MEC server\nusage costs. This problem is compounded by two factors: (1) the finite\ncomputing capacity of the MEC server, which is shared among multiple devices,\nleading to inter-dependent demands, and (2) the shift in modern DNN\narchitecture from chains to directed acyclic graphs (DAGs), which complicates\npotential solutions.\n  In this paper, we introduce a novel Decentralized DNN Surgery (DDS)\nframework. We formulate the partition strategy as a min-cut and propose a\nresource allocation game to adaptively schedule the demands of mobile devices\nin an MEC environment. We prove the existence of a Nash Equilibrium (NE), and\ndevelop an iterative algorithm to efficiently reach the NE for each device. Our\nextensive experiments demonstrate that DDS can effectively handle varying MEC\nscenarios, achieving up to 1.25$\\times$ acceleration compared to the\nstate-of-the-art algorithm.\n",
                "链接": "https://arxiv.org/abs/2306.12185"
            },
            {
                "文章ID": "30578",
                "标题": "Distributed Deep Learning Inference Acceleration using Seamless\n  Collaboration in Edge Computing",
                "作者": " Nan Li,  Alexandros Iosifidis,  Qi Zhang",
                "发布日期": "2022-09-12",
                "摘要": "  This paper studies inference acceleration using distributed convolutional\nneural networks (CNNs) in collaborative edge computing. To ensure inference\naccuracy in inference task partitioning, we consider the receptive-field when\nperforming segment-based partitioning. To maximize the parallelization between\nthe communication and computing processes, thereby minimizing the total\ninference time of an inference task, we design a novel task collaboration\nscheme in which the overlapping zone of the sub-tasks on secondary edge servers\n(ESs) is executed on the host ES, named as HALP. We further extend HALP to the\nscenario of multiple tasks. Experimental results show that HALP can accelerate\nCNN inference in VGG-16 by 1.7-2.0x for a single task and 1.7-1.8x for 4 tasks\nper batch on GTX 1080TI and JETSON AGX Xavier, which outperforms the\nstate-of-the-art work MoDNN. Moreover, we evaluate the service reliability\nunder time-variant channel, which shows that HALP is an effective solution to\nensure high service reliability with strict service deadline.\n",
                "链接": "https://arxiv.org/abs/2207.11294"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本识别最新进展。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "54214",
                "标题": "Transferring General Multimodal Pretrained Models to Text Recognition",
                "作者": " Junyang Lin,  Xuancheng Ren,  Yichang Zhang,  Gao Liu,  Peng Wang,  An Yang,  Chang Zhou",
                "发布日期": "2022-12-20",
                "摘要": "  This paper proposes a new method, OFA-OCR, to transfer multimodal pretrained\nmodels to text recognition. Specifically, we recast text recognition as image\ncaptioning and directly transfer a unified vision-language pretrained model to\nthe end task. Without pretraining on large-scale annotated or synthetic text\nrecognition data, OFA-OCR outperforms the baselines and achieves\nstate-of-the-art performance in the Chinese text recognition benchmark.\nAdditionally, we construct an OCR pipeline with OFA-OCR, and we demonstrate\nthat it can achieve competitive performance with the product-level API. The\ncode (https://github.com/OFA-Sys/OFA) and demo\n(https://modelscope.cn/studios/damo/ofa_ocr_pipeline/summary) are publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2212.09297"
            },
            {
                "文章ID": "111490",
                "标题": "Exploring OCR Capabilities of GPT-4V(ision) : A Quantitative and\n  In-depth Evaluation",
                "作者": " Yongxin Shi,  Dezhi Peng,  Wenhui Liao,  Zening Lin,  Xinhong Chen,  Chongyu Liu,  Yuyi Zhang,  Lianwen Jin",
                "发布日期": "2023-10-31",
                "摘要": "  This paper presents a comprehensive evaluation of the Optical Character\nRecognition (OCR) capabilities of the recently released GPT-4V(ision), a Large\nMultimodal Model (LMM). We assess the model's performance across a range of OCR\ntasks, including scene text recognition, handwritten text recognition,\nhandwritten mathematical expression recognition, table structure recognition,\nand information extraction from visually-rich document. The evaluation reveals\nthat GPT-4V performs well in recognizing and understanding Latin contents, but\nstruggles with multilingual scenarios and complex tasks. Specifically, it\nshowed limitations when dealing with non-Latin languages and complex tasks such\nas handwriting mathematical expression recognition, table structure\nrecognition, and end-to-end semantic entity recognition and pair extraction\nfrom document image. Based on these observations, we affirm the necessity and\ncontinued research value of specialized OCR models. In general, despite its\nversatility in handling diverse OCR tasks, GPT-4V does not outperform existing\nstate-of-the-art OCR models. How to fully utilize pre-trained general-purpose\nLMMs such as GPT-4V for OCR downstream tasks remains an open problem. The study\noffers a critical reference for future research in OCR with LMMs. Evaluation\npipeline and results are available at\nhttps://github.com/SCUT-DLVCLab/GPT-4V_OCR.\n",
                "链接": "https://arxiv.org/abs/2310.16809"
            },
            {
                "文章ID": "23281",
                "标题": "PP-OCRv3: More Attempts for the Improvement of Ultra Lightweight OCR\n  System",
                "作者": " Chenxia Li,  Weiwei Liu,  Ruoyu Guo,  Xiaoting Yin,  Kaitao Jiang,  Yongkun Du,  Yuning Du,  Lingfeng Zhu,  Baohua Lai,  Xiaoguang Hu,  Dianhai Yu,  Yanjun Ma",
                "发布日期": "2022-06-15",
                "摘要": "  Optical character recognition (OCR) technology has been widely used in\nvarious scenes, as shown in Figure 1. Designing a practical OCR system is still\na meaningful but challenging task. In previous work, considering the efficiency\nand accuracy, we proposed a practical ultra lightweight OCR system (PP-OCR),\nand an optimized version PP-OCRv2. In order to further improve the performance\nof PP-OCRv2, a more robust OCR system PP-OCRv3 is proposed in this paper.\nPP-OCRv3 upgrades the text detection model and text recognition model in 9\naspects based on PP-OCRv2. For text detector, we introduce a PAN module with\nlarge receptive field named LK-PAN, a FPN module with residual attention\nmechanism named RSE-FPN, and DML distillation strategy. For text recognizer,\nthe base model is replaced from CRNN to SVTR, and we introduce lightweight text\nrecognition network SVTR LCNet, guided training of CTC by attention, data\naugmentation strategy TextConAug, better pre-trained model by self-supervised\nTextRotNet, UDML, and UIM to accelerate the model and improve the effect.\nExperiments on real data show that the hmean of PP-OCRv3 is 5% higher than\nPP-OCRv2 under comparable inference speed. All the above mentioned models are\nopen-sourced and the code is available in the GitHub repository PaddleOCR which\nis powered by PaddlePaddle.\n",
                "链接": "https://arxiv.org/abs/2206.03001"
            },
            {
                "文章ID": "123651",
                "标题": "Advancements and Challenges in Arabic Optical Character Recognition: A\n  Comprehensive Survey",
                "作者": " Mahmoud SalahEldin Kasem,  Mohamed Mahmoud,  Hyun-Soo Kang",
                "发布日期": "2023-12-20",
                "摘要": "  Optical character recognition (OCR) is a vital process that involves the\nextraction of handwritten or printed text from scanned or printed images,\nconverting it into a format that can be understood and processed by machines.\nThis enables further data processing activities such as searching and editing.\nThe automatic extraction of text through OCR plays a crucial role in digitizing\ndocuments, enhancing productivity, improving accessibility, and preserving\nhistorical records. This paper seeks to offer an exhaustive review of\ncontemporary applications, methodologies, and challenges associated with Arabic\nOptical Character Recognition (OCR). A thorough analysis is conducted on\nprevailing techniques utilized throughout the OCR process, with a dedicated\neffort to discern the most efficacious approaches that demonstrate enhanced\noutcomes. To ensure a thorough evaluation, a meticulous keyword-search\nmethodology is adopted, encompassing a comprehensive analysis of articles\nrelevant to Arabic OCR, including both backward and forward citation reviews.\nIn addition to presenting cutting-edge techniques and methods, this paper\ncritically identifies research gaps within the realm of Arabic OCR. By\nhighlighting these gaps, we shed light on potential areas for future\nexploration and development, thereby guiding researchers toward promising\navenues in the field of Arabic OCR. The outcomes of this study provide valuable\ninsights for researchers, practitioners, and stakeholders involved in Arabic\nOCR, ultimately fostering advancements in the field and facilitating the\ncreation of more accurate and efficient OCR systems for the Arabic language.\n",
                "链接": "https://arxiv.org/abs/2312.11812"
            },
            {
                "文章ID": "90438",
                "标题": "Handwritten Text Recognition Using Convolutional Neural Network",
                "作者": " Atman Mishra,  A. Sharath Ram,  Kavyashree C",
                "发布日期": "2023-07-12",
                "摘要": "  OCR (Optical Character Recognition) is a technology that offers comprehensive\nalphanumeric recognition of handwritten and printed characters at electronic\nspeed by merely scanning the document. Recently, the understanding of visual\ndata has been termed Intelligent Character Recognition (ICR). Intelligent\nCharacter Recognition (ICR) is the OCR module that can convert scans of\nhandwritten or printed characters into ASCII text. ASCII data is the standard\nformat for data encoding in electronic communication. ASCII assigns standard\nnumeric values to letters, numeral, symbols, white-spaces and other characters.\nIn more technical terms, OCR is the process of using an electronic device to\ntransform 2-Dimensional textual information into machine-encoded text. Anything\nthat contains text both machine written or handwritten can be scanned either\nthrough a scanner or just simply a picture of the text is enough for the\nrecognition system to distinguish the text. The goal of this papers is to show\nthe results of a Convolutional Neural Network model which has been trained on\nNational Institute of Science and Technology (NIST) dataset containing over a\n100,000 images. The network learns from the features extracted from the images\nand use it to generate the probability of each class to which the picture\nbelongs to. We have achieved an accuracy of 90.54% with a loss of 2.53%.\n",
                "链接": "https://arxiv.org/abs/2307.05396"
            },
            {
                "文章ID": "53136",
                "标题": "Extending TrOCR for Text Localization-Free OCR of Full-Page Scanned\n  Receipt Images",
                "作者": " Hongkuan Zhang,  Edward Whittaker,  Ikuo Kitagishi",
                "发布日期": "2023-10-17",
                "摘要": "  Digitization of scanned receipts aims to extract text from receipt images and\nsave it into structured documents. This is usually split into two sub-tasks:\ntext localization and optical character recognition (OCR). Most existing OCR\nmodels only focus on the cropped text instance images, which require the\nbounding box information provided by a text region detection model. Introducing\nan additional detector to identify the text instance images in advance adds\ncomplexity, however instance-level OCR models have very low accuracy when\nprocessing the whole image for the document-level OCR, such as receipt images\ncontaining multiple text lines arranged in various layouts. To this end, we\npropose a localization-free document-level OCR model for transcribing all the\ncharacters in a receipt image into an ordered sequence end-to-end.\nSpecifically, we finetune the pretrained instance-level model TrOCR with\nrandomly cropped image chunks, and gradually increase the image chunk size to\ngeneralize the recognition ability from instance images to full-page images. In\nour experiments on the SROIE receipt OCR dataset, the model finetuned with our\nstrategy achieved 64.4 F1-score and a 22.8% character error rate (CER),\nrespectively, which outperforms the baseline results with 48.5 F1-score and\n50.6% CER. The best model, which splits the full image into 15 equally sized\nchunks, gives 87.8 F1-score and 4.98% CER with minimal additional pre or\npost-processing of the output. Moreover, the characters in the generated\ndocument-level sequences are arranged in the reading order, which is practical\nfor real-world applications.\n",
                "链接": "https://arxiv.org/abs/2212.05525"
            },
            {
                "文章ID": "30789",
                "标题": "Optimal Boxes: Boosting End-to-End Scene Text Recognition by Adjusting\n  Annotated Bounding Boxes via Reinforcement Learning",
                "作者": " Jingqun Tang,  Wenming Qian,  Luchuan Song,  Xiena Dong,  Lan Li,  Xiang Bai",
                "发布日期": "2022-07-27",
                "摘要": "  Text detection and recognition are essential components of a modern OCR\nsystem. Most OCR approaches attempt to obtain accurate bounding boxes of text\nat the detection stage, which is used as the input of the text recognition\nstage. We observe that when using tight text bounding boxes as input, a text\nrecognizer frequently fails to achieve optimal performance due to the\ninconsistency between bounding boxes and deep representations of text\nrecognition. In this paper, we propose Box Adjuster, a reinforcement\nlearning-based method for adjusting the shape of each text bounding box to make\nit more compatible with text recognition models. Additionally, when dealing\nwith cross-domain problems such as synthetic-to-real, the proposed method\nsignificantly reduces mismatches in domain distribution between the source and\ntarget domains. Experiments demonstrate that the performance of end-to-end text\nrecognition systems can be improved when using the adjusted bounding boxes as\nthe ground truths for training. Specifically, on several benchmark datasets for\nscene text understanding, the proposed method outperforms state-of-the-art text\nspotters by an average of 2.0% F-Score on end-to-end text recognition tasks and\n4.6% F-Score on domain adaptation tasks.\n",
                "链接": "https://arxiv.org/abs/2207.11934"
            },
            {
                "文章ID": "19103",
                "标题": "An empirical study of CTC based models for OCR of Indian languages",
                "作者": " Minesh Mathew,  CV Jawahar",
                "发布日期": "2022-05-16",
                "摘要": "  Recognition of text on word or line images, without the need for sub-word\nsegmentation has become the mainstream of research and development of text\nrecognition for Indian languages. Modelling unsegmented sequences using\nConnectionist Temporal Classification (CTC) is the most commonly used approach\nfor segmentation-free OCR. In this work we present a comprehensive empirical\nstudy of various neural network models that uses CTC for transcribing step-wise\npredictions in the neural network output to a Unicode sequence. The study is\nconducted for 13 Indian languages, using an internal dataset that has around\n1000 pages per language. We study the choice of line vs word as the recognition\nunit, and use of synthetic data to train the models. We compare our models with\npopular publicly available OCR tools for end-to-end document image recognition.\nOur end-to-end pipeline that employ our recognition models and existing text\nsegmentation tools outperform these public OCR tools for 8 out of the 13\nlanguages. We also introduce a new public dataset called Mozhi for word and\nline recognition in Indian language. The dataset contains more than 1.2 million\nannotated word images (120 thousand text lines) across 13 Indian languages. Our\ncode, trained models and the Mozhi dataset will be made available at\nhttp://cvit.iiit.ac.in/research/projects/cvit-projects/\n",
                "链接": "https://arxiv.org/abs/2205.06740"
            },
            {
                "文章ID": "118261",
                "标题": "Optimization of Image Processing Algorithms for Character Recognition in\n  Cultural Typewritten Documents",
                "作者": " Mariana Dias,  Carla Teixeira Lopes",
                "发布日期": "2023-11-28",
                "摘要": "  Linked Data is used in various fields as a new way of structuring and\nconnecting data. Cultural heritage institutions have been using linked data to\nimprove archival descriptions and facilitate the discovery of information. Most\narchival records have digital representations of physical artifacts in the form\nof scanned images that are non-machine-readable. Optical Character Recognition\n(OCR) recognizes text in images and translates it into machine-encoded text.\nThis paper evaluates the impact of image processing methods and parameter\ntuning in OCR applied to typewritten cultural heritage documents. The approach\nuses a multi-objective problem formulation to minimize Levenshtein edit\ndistance and maximize the number of words correctly identified with a\nnon-dominated sorting genetic algorithm (NSGA-II) to tune the methods'\nparameters. Evaluation results show that parameterization by digital\nrepresentation typology benefits the performance of image pre-processing\nalgorithms in OCR. Furthermore, our findings suggest that employing image\npre-processing algorithms in OCR might be more suitable for typologies where\nthe text recognition task without pre-processing does not produce good results.\nIn particular, Adaptive Thresholding, Bilateral Filter, and Opening are the\nbest-performing algorithms for the theatre plays' covers, letters, and overall\ndataset, respectively, and should be applied before OCR to improve its\nperformance.\n",
                "链接": "https://arxiv.org/abs/2311.15740"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月agent系列决策文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "106592",
                "标题": "Comparing Time-Series Analysis Approaches Utilized in Research Papers to\n  Forecast COVID-19 Cases in Africa: A Literature Review",
                "作者": " Ali Ebadi,  Ebrahim Sahafizadeh",
                "发布日期": "2023-10-06",
                "摘要": "  This literature review aimed to compare various time-series analysis\napproaches utilized in forecasting COVID-19 cases in Africa. The study involved\na methodical search for English-language research papers published between\nJanuary 2020 and July 2023, focusing specifically on papers that utilized\ntime-series analysis approaches on COVID-19 datasets in Africa. A variety of\ndatabases including PubMed, Google Scholar, Scopus, and Web of Science were\nutilized for this process. The research papers underwent an evaluation process\nto extract relevant information regarding the implementation and performance of\nthe time-series analysis models. The study highlighted the different\nmethodologies employed, evaluating their effectiveness and limitations in\nforecasting the spread of the virus. The result of this review could contribute\ndeeper insights into the field, and future research should consider these\ninsights to improve time series analysis models and explore the integration of\ndifferent approaches for enhanced public health decision-making.\n",
                "链接": "https://arxiv.org/abs/2310.03606"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "888",
                "标题": "Pavlovian Signalling with General Value Functions in Agent-Agent\n  Temporal Decision Making",
                "作者": " Andrew Butcher,  Michael Bradley Johanson,  Elnaz Davoodi,  Dylan J. A. Brenneis,  Leslie Acker,  Adam S. R. Parker,  Adam White,  Joseph Modayil,  Patrick M. Pilarski",
                "发布日期": "2022-01-12",
                "摘要": "  In this paper, we contribute a multi-faceted study into Pavlovian signalling\n-- a process by which learned, temporally extended predictions made by one\nagent inform decision-making by another agent. Signalling is intimately\nconnected to time and timing. In service of generating and receiving signals,\nhumans and other animals are known to represent time, determine time since past\nevents, predict the time until a future stimulus, and both recognize and\ngenerate patterns that unfold in time. We investigate how different temporal\nprocesses impact coordination and signalling between learning agents by\nintroducing a partially observable decision-making domain we call the Frost\nHollow. In this domain, a prediction learning agent and a reinforcement\nlearning agent are coupled into a two-part decision-making system that works to\nacquire sparse reward while avoiding time-conditional hazards. We evaluate two\ndomain variations: machine agents interacting in a seven-state linear walk, and\nhuman-machine interaction in a virtual-reality environment. Our results\nshowcase the speed of learning for Pavlovian signalling, the impact that\ndifferent temporal representations do (and do not) have on agent-agent\ncoordination, and how temporal aliasing impacts agent-agent and human-agent\ninteractions differently. As a main contribution, we establish Pavlovian\nsignalling as a natural bridge between fixed signalling paradigms and fully\nadaptive communication learning between two agents. We further show how to\ncomputationally build this adaptive signalling process out of a fixed\nsignalling process, characterized by fast continual prediction learning and\nminimal constraints on the nature of the agent receiving signals. Our results\ntherefore suggest an actionable, constructivist path towards communication\nlearning between reinforcement learning agents.\n",
                "链接": "https://arxiv.org/abs/2201.03709"
            },
            {
                "文章ID": "109649",
                "标题": "Masked Pretraining for Multi-Agent Decision Making",
                "作者": " Jie Liu,  Yinmin Zhang,  Chuming Li,  Chao Yang,  Yaodong Yang,  Yu Liu,  Wanli Ouyang",
                "发布日期": "2023-10-19",
                "摘要": "  Building a single generalist agent with zero-shot capability has recently\nsparked significant advancements in decision-making. However, extending this\ncapability to multi-agent scenarios presents challenges. Most current works\nstruggle with zero-shot capabilities, due to two challenges particular to the\nmulti-agent settings: a mismatch between centralized pretraining and\ndecentralized execution, and varying agent numbers and action spaces, making it\ndifficult to create generalizable representations across diverse downstream\ntasks. To overcome these challenges, we propose a \\textbf{Mask}ed pretraining\nframework for \\textbf{M}ulti-\\textbf{a}gent decision making (MaskMA). This\nmodel, based on transformer architecture, employs a mask-based collaborative\nlearning strategy suited for decentralized execution with partial observation.\nMoreover, MaskMA integrates a generalizable action representation by dividing\nthe action space into actions toward self-information and actions related to\nother entities. This flexibility allows MaskMA to tackle tasks with varying\nagent numbers and thus different action spaces. Extensive experiments in SMAC\nreveal MaskMA, with a single model pretrained on 11 training maps, can achieve\nan impressive 77.8% zero-shot win rate on 60 unseen test maps by decentralized\nexecution, while also performing effectively on other types of downstream tasks\n(\\textit{e.g.,} varied policies collaboration and ad hoc team play).\n",
                "链接": "https://arxiv.org/abs/2310.11846"
            },
            {
                "文章ID": "5419",
                "标题": "ArgSciChat: A Dataset for Argumentative Dialogues on Scientific Papers",
                "作者": " Federico Ruggeri,  Mohsen Mesgar,  Iryna Gurevych",
                "发布日期": "2022-10-14",
                "摘要": "  The applications of conversational agents for scientific disciplines (as\nexpert domains) are understudied due to the lack of dialogue data to train such\nagents. While most data collection frameworks, such as Amazon Mechanical Turk,\nfoster data collection for generic domains by connecting crowd workers and task\ndesigners, these frameworks are not much optimized for data collection in\nexpert domains. Scientists are rarely present in these frameworks due to their\nlimited time budget. Therefore, we introduce a novel framework to collect\ndialogues between scientists as domain experts on scientific papers. Our\nframework lets scientists present their scientific papers as groundings for\ndialogues and participate in dialogue they like its paper title. We use our\nframework to collect a novel argumentative dialogue dataset, ArgSciChat. It\nconsists of 498 messages collected from 41 dialogues on 20 scientific papers.\nAlongside extensive analysis on ArgSciChat, we evaluate a recent conversational\nagent on our dataset. Experimental results show that this agent poorly performs\non ArgSciChat, motivating further research on argumentative scientific agents.\nWe release our framework and the dataset.\n",
                "链接": "https://arxiv.org/abs/2202.06690"
            },
            {
                "文章ID": "21021",
                "标题": "MAVIPER: Learning Decision Tree Policies for Interpretable Multi-Agent\n  Reinforcement Learning",
                "作者": " Stephanie Milani,  Zhicheng Zhang,  Nicholay Topin,  Zheyuan Ryan Shi,  Charles Kamhoua,  Evangelos E. Papalexakis,  Fei Fang",
                "发布日期": "2022-07-13",
                "摘要": "  Many recent breakthroughs in multi-agent reinforcement learning (MARL)\nrequire the use of deep neural networks, which are challenging for human\nexperts to interpret and understand. On the other hand, existing work on\ninterpretable reinforcement learning (RL) has shown promise in extracting more\ninterpretable decision tree-based policies from neural networks, but only in\nthe single-agent setting. To fill this gap, we propose the first set of\nalgorithms that extract interpretable decision-tree policies from neural\nnetworks trained with MARL. The first algorithm, IVIPER, extends VIPER, a\nrecent method for single-agent interpretable RL, to the multi-agent setting. We\ndemonstrate that IVIPER learns high-quality decision-tree policies for each\nagent. To better capture coordination between agents, we propose a novel\ncentralized decision-tree training algorithm, MAVIPER. MAVIPER jointly grows\nthe trees of each agent by predicting the behavior of the other agents using\ntheir anticipated trees, and uses resampling to focus on states that are\ncritical for its interactions with other agents. We show that both algorithms\ngenerally outperform the baselines and that MAVIPER-trained agents achieve\nbetter-coordinated performance than IVIPER-trained agents on three different\nmulti-agent particle-world environments.\n",
                "链接": "https://arxiv.org/abs/2205.12449"
            },
            {
                "文章ID": "51573",
                "标题": "Decision Market Based Learning For Multi-agent Contextual Bandit\n  Problems",
                "作者": " Wenlong Wang,  Thomas Pfeiffer",
                "发布日期": "2022-12-02",
                "摘要": "  Information is often stored in a distributed and proprietary form, and agents\nwho own information are often self-interested and require incentives to reveal\ntheir information. Suitable mechanisms are required to elicit and aggregate\nsuch distributed information for decision making. In this paper, we use\nsimulations to investigate the use of decision markets as mechanisms in a\nmulti-agent learning system to aggregate distributed information for\ndecision-making in a contextual bandit problem. The system utilises strictly\nproper decision scoring rules to assess the accuracy of probabilistic reports\nfrom agents, which allows agents to learn to solve the contextual bandit\nproblem jointly. Our simulations show that our multi-agent system with\ndistributed information can be trained as efficiently as a centralised\ncounterpart with a single agent that receives all information. Moreover, we use\nour system to investigate scenarios with deterministic decision scoring rules\nwhich are not incentive compatible. We observe the emergence of more complex\ndynamics with manipulative behaviour, which agrees with existing theoretical\nanalyses.\n",
                "链接": "https://arxiv.org/abs/2212.00271"
            },
            {
                "文章ID": "75128",
                "标题": "On the Complexity of Multi-Agent Decision Making: From Learning in Games\n  to Partial Monitoring",
                "作者": " Dylan J. Foster,  Dean P. Foster,  Noah Golowich,  Alexander Rakhlin",
                "发布日期": "2023-05-02",
                "摘要": "  A central problem in the theory of multi-agent reinforcement learning (MARL)\nis to understand what structural conditions and algorithmic principles lead to\nsample-efficient learning guarantees, and how these considerations change as we\nmove from few to many agents. We study this question in a general framework for\ninteractive decision making with multiple agents, encompassing Markov games\nwith function approximation and normal-form games with bandit feedback. We\nfocus on equilibrium computation, in which a centralized learning algorithm\naims to compute an equilibrium by controlling multiple agents that interact\nwith an unknown environment. Our main contributions are:\n  - We provide upper and lower bounds on the optimal sample complexity for\nmulti-agent decision making based on a multi-agent generalization of the\nDecision-Estimation Coefficient, a complexity measure introduced by Foster et\nal. (2021) in the single-agent counterpart to our setting. Compared to the best\nresults for the single-agent setting, our bounds have additional gaps. We show\nthat no \"reasonable\" complexity measure can close these gaps, highlighting a\nstriking separation between single and multiple agents.\n  - We show that characterizing the statistical complexity for multi-agent\ndecision making is equivalent to characterizing the statistical complexity of\nsingle-agent decision making, but with hidden (unobserved) rewards, a framework\nthat subsumes variants of the partial monitoring problem. As a consequence, we\ncharacterize the statistical complexity for hidden-reward interactive decision\nmaking to the best extent possible.\n  Building on this development, we provide several new structural results,\nincluding 1) conditions under which the statistical complexity of multi-agent\ndecision making can be reduced to that of single-agent, and 2) conditions under\nwhich the so-called curse of multiple agents can be avoided.\n",
                "链接": "https://arxiv.org/abs/2305.00684"
            },
            {
                "文章ID": "77334",
                "标题": "Stackelberg Decision Transformer for Asynchronous Action Coordination in\n  Multi-Agent Systems",
                "作者": " Bin Zhang,  Hangyu Mao,  Lijuan Li,  Zhiwei Xu,  Dapeng Li,  Rui Zhao,  Guoliang Fan",
                "发布日期": "2023-05-16",
                "摘要": "  Asynchronous action coordination presents a pervasive challenge in\nMulti-Agent Systems (MAS), which can be represented as a Stackelberg game (SG).\nHowever, the scalability of existing Multi-Agent Reinforcement Learning (MARL)\nmethods based on SG is severely constrained by network structures or\nenvironmental limitations. To address this issue, we propose the Stackelberg\nDecision Transformer (STEER), a heuristic approach that resolves the\ndifficulties of hierarchical coordination among agents. STEER efficiently\nmanages decision-making processes in both spatial and temporal contexts by\nincorporating the hierarchical decision structure of SG, the modeling\ncapability of autoregressive sequence models, and the exploratory learning\nmethodology of MARL. Our research contributes to the development of an\neffective and adaptable asynchronous action coordination method that can be\nwidely applied to various task types and environmental configurations in MAS.\nExperimental results demonstrate that our method can converge to Stackelberg\nequilibrium solutions and outperforms other existing methods in complex\nscenarios.\n",
                "链接": "https://arxiv.org/abs/2305.07856"
            },
            {
                "文章ID": "81280",
                "标题": "Research on Multi-Agent Communication and Collaborative Decision-Making\n  Based on Deep Reinforcement Learning",
                "作者": " Zeng Da",
                "发布日期": "2023-05-30",
                "摘要": "  In a multi-agent environment, In order to overcome and alleviate the\nnon-stationarity of the multi-agent environment, the mainstream method is to\nadopt the framework of Centralized Training Decentralized Execution (CTDE).\nThis thesis is based on the framework of CTDE, and studies the cooperative\ndecision-making of multi-agent based on the Multi-Agent Proximal Policy\nOptimization (MAPPO) algorithm for multi-agent proximal policy optimization. In\norder to alleviate the non-stationarity of the multi-agent environment, a\nmulti-agent communication mechanism based on weight scheduling and attention\nmodule is introduced. Different agents can alleviate the non-stationarity\ncaused by local observations through information exchange between agents,\nassisting in the collaborative decision-making of agents. The specific method\nis to introduce a communication module in the policy network part. The\ncommunication module is composed of a weight generator, a weight scheduler, a\nmessage encoder, a message pool and an attention module. Among them, the weight\ngenerator and weight scheduler will generate weights as the selection basis for\ncommunication, the message encoder is used to compress and encode communication\ninformation, the message pool is used to store communication messages, and the\nattention module realizes the interactive processing of the agent's own\ninformation and communication information. This thesis proposes a Multi-Agent\nCommunication and Global Information Optimization Proximal Policy\nOptimization(MCGOPPO)algorithm, and conducted experiments in the SMAC and the\nMPE. The experimental results show that the improvement has achieved certain\neffects, which can better alleviate the non-stationarity of the multi-agent\nenvironment, and improve the collaborative decision-making ability among the\nagents.\n",
                "链接": "https://arxiv.org/abs/2305.17141"
            }
        ]
    },
    {
        "question": {
            "question": "查找大模型推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "116170",
                "标题": "Large Language Model Inference with Lexical Shortlisting",
                "作者": " Nikolay Bogoychev,  Pinzhen Chen,  Barry Haddow,  Alexandra Birch",
                "发布日期": "2023-11-17",
                "摘要": "  Large language model (LLM) inference is computation and memory intensive, so\nwe adapt lexical shortlisting to it hoping to improve both. While lexical\nshortlisting is well-explored in tasks like machine translation, it requires\nmodifications before being suitable for LLMs as the intended applications vary\nsignificantly. Our work studies two heuristics to shortlist sub-vocabulary at\nLLM inference time: Unicode-based script filtering and corpus-based selection.\nWe explore different LLM families and sizes, and we find that lexical\nshortlisting can reduce the memory usage of some models by nearly 50\\% and has\nan upper bound of 25\\% improvement in generation speed. In this pilot study, we\nalso identify the drawbacks of such vocabulary selection methods and propose\navenues for future research.\n",
                "链接": "https://arxiv.org/abs/2311.09709"
            },
            {
                "文章ID": "83366",
                "标题": "On Optimal Caching and Model Multiplexing for Large Model Inference",
                "作者": " Banghua Zhu,  Ying Sheng,  Lianmin Zheng,  Clark Barrett,  Michael I. Jordan,  Jiantao Jiao",
                "发布日期": "2023-08-30",
                "摘要": "  Large Language Models (LLMs) and other large foundation models have achieved\nnoteworthy success, but their size exacerbates existing resource consumption\nand latency challenges. In particular, the large-scale deployment of these\nmodels is hindered by the significant resource requirements during inference.\nIn this paper, we study two approaches for mitigating these challenges:\nemploying a cache to store previous queries and learning a model multiplexer to\nchoose from an ensemble of models for query processing.\n  Theoretically, we provide an optimal algorithm for jointly optimizing both\napproaches to reduce the inference cost in both offline and online tabular\nsettings. By combining a caching algorithm, namely Greedy Dual Size with\nFrequency (GDSF) or Least Expected Cost (LEC), with a model multiplexer, we\nachieve optimal rates in both offline and online settings. Empirically,\nsimulations show that the combination of our caching and model multiplexing\nalgorithms greatly improves over the baselines, with up to $50\\times$\nimprovement over the baseline when the ratio between the maximum cost and\nminimum cost is $100$. Experiments on real datasets show a $4.3\\times$\nimprovement in FLOPs over the baseline when the ratio for FLOPs is $10$, and a\n$1.8\\times$ improvement in latency when the ratio for average latency is\n$1.85$.\n",
                "链接": "https://arxiv.org/abs/2306.02003"
            },
            {
                "文章ID": "55730",
                "标题": "Rethinking with Retrieval: Faithful Large Language Model Inference",
                "作者": " Hangfeng He,  Hongming Zhang,  Dan Roth",
                "发布日期": "2023-01-03",
                "摘要": "  Despite the success of large language models (LLMs) in various natural\nlanguage processing (NLP) tasks, the stored knowledge in these models may\ninevitably be incomplete, out-of-date, or incorrect. This motivates the need to\nutilize external knowledge to assist LLMs. Unfortunately, current methods for\nincorporating external knowledge often require additional training or\nfine-tuning, which can be costly and may not be feasible for LLMs. To address\nthis issue, we propose a novel post-processing approach, rethinking with\nretrieval (RR), which retrieves relevant external knowledge based on the\ndecomposed reasoning steps obtained from the chain-of-thought (CoT) prompting.\nThis lightweight approach does not require additional training or fine-tuning\nand is not limited by the input length of LLMs. We evaluate the effectiveness\nof RR through extensive experiments with GPT-3 on three complex reasoning\ntasks: commonsense reasoning, temporal reasoning, and tabular reasoning. Our\nresults show that RR can produce more faithful explanations and improve the\nperformance of LLMs.\n",
                "链接": "https://arxiv.org/abs/2301.00303"
            },
            {
                "文章ID": "113368",
                "标题": "FlashDecoding++: Faster Large Language Model Inference on GPUs",
                "作者": " Ke Hong,  Guohao Dai,  Jiaming Xu,  Qiuli Mao,  Xiuhong Li,  Jun Liu,  Kangdi Chen,  Yuhan Dong,  Yu Wang",
                "发布日期": "2023-11-13",
                "摘要": "  As the Large Language Model (LLM) becomes increasingly important in various\ndomains. However, the following challenges still remain unsolved in\naccelerating LLM inference: (1) Synchronized partial softmax update. The\nsoftmax operation requires a synchronized update operation among each partial\nsoftmax result, leading to ~20% overheads for the attention computation in\nLLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices\nperforming GEMM in LLM inference is flat, leading to under-utilized computation\nand >50% performance loss after padding zeros in previous designs. (3)\nPerformance loss due to static dataflow. Kernel performance in LLM depends on\nvaried input data features, hardware configurations, etc. A single and static\ndataflow may lead to a 50.25% performance loss for GEMMs of different shapes in\nLLM inference.\n  We present FlashDecoding++, a fast LLM inference engine supporting mainstream\nLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++\ncreatively proposes: (1) Asynchronized softmax with unified max value.\nFlashDecoding++ introduces a unified max value technique for different partial\nsoftmax computations to avoid synchronization. (2) Flat GEMM optimization with\ndouble buffering. FlashDecoding++ points out that flat GEMMs with different\nshapes face varied bottlenecks. Then, techniques like double buffering are\nintroduced. (3) Heuristic dataflow with hardware resource adaptation.\nFlashDecoding++ heuristically optimizes dataflow using different hardware\nresource considering input dynamics. Due to the versatility of optimizations in\nFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on\nboth NVIDIA and AMD GPUs compared to Hugging Face implementations.\nFlashDecoding++ also achieves an average speedup of 1.37x compared to\nstate-of-the-art LLM inference engines on mainstream LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.01282"
            },
            {
                "文章ID": "57741",
                "标题": "Batch Prompting: Efficient Inference with Large Language Model APIs",
                "作者": " Zhoujun Cheng,  Jungo Kasai,  Tao Yu",
                "发布日期": "2023-10-25",
                "摘要": "  Performing inference on large volumes of samples with large language models\n(LLMs) can be computationally and financially costly in industry and real-world\nuse. We propose batch prompting, a simple yet effective prompting approach that\nenables the LLM to run inference in batches, instead of one sample at a time.\nOur method reduces both token and time costs while retaining downstream\nperformance. We theoretically demonstrate that under a few-shot in-context\nlearning setting, the inference costs decrease almost inverse linearly with the\nnumber of samples in each batch. We extensively validate the effectiveness of\nbatch prompting on ten datasets across commonsense QA, arithmetic reasoning,\nand NLI/NLU: batch prompting significantly~(up to 5x with six samples in batch)\nreduces the LLM (Codex) inference token and time costs while achieving better\nor comparable performance. For state-of-the-art Chat-based LLMs, e.g., GPT-3.5\nand GPT-4, we show the benefits of batch prompting also hold. Further analysis\nshows that the number of samples in each batch and the complexity of tasks\naffect its performance. Moreover, batch prompting can be applied across\ndifferent reasoning methods using LLMs. Our code can be found at the site\nhttps://github.com/xlang-ai/batch-prompting.\n",
                "链接": "https://arxiv.org/abs/2301.08721"
            },
            {
                "文章ID": "120482",
                "标题": "A Hardware Evaluation Framework for Large Language Model Inference",
                "作者": " Hengrui Zhang,  August Ning,  Rohan Prabhakar,  David Wentzlaff",
                "发布日期": "2023-12-07",
                "摘要": "  The past year has witnessed the increasing popularity of Large Language\nModels (LLMs). Their unprecedented scale and associated high hardware cost have\nimpeded their broader adoption, calling for efficient hardware designs. With\nthe large hardware needed to simply run LLM inference, evaluating different\nhardware designs becomes a new bottleneck.\n  This work introduces LLMCompass, a hardware evaluation framework for LLM\ninference workloads. LLMCompass is fast, accurate, versatile, and able to\ndescribe and evaluate different hardware designs. LLMCompass includes a mapper\nto automatically find performance-optimal mapping and scheduling. It also\nincorporates an area-based cost model to help architects reason about their\ndesign choices. Compared to real-world hardware, LLMCompass' estimated latency\nachieves an average 10.4% error rate across various operators with various\ninput sizes and an average 4.1% error rate for LLM inference. With LLMCompass,\nsimulating a 4-NVIDIA A100 GPU node running GPT-3 175B inference can be done\nwithin 16 minutes on commodity hardware, including 26,400 rounds of the\nmapper's parameter search.\n  With the aid of LLMCompass, this work draws architectural implications and\nexplores new cost-effective hardware designs. By reducing the compute\ncapability or replacing High Bandwidth Memory (HBM) with traditional DRAM,\nthese new designs can achieve as much as 3.41x improvement in performance/cost\ncompared to an NVIDIA A100, making them promising choices for democratizing\nLLMs.\n  LLMCompass is planned to be fully open-source.\n",
                "链接": "https://arxiv.org/abs/2312.03134"
            },
            {
                "文章ID": "65490",
                "标题": "Cost-Effective Hyperparameter Optimization for Large Language Model\n  Generation Inference",
                "作者": " Chi Wang,  Susan Xueqing Liu,  Ahmed H. Awadallah",
                "发布日期": "2023-08-10",
                "摘要": "  Large Language Models (LLMs) have sparked significant interest in their\ngenerative capabilities, leading to the development of various commercial\napplications. The high cost of using the models drives application builders to\nmaximize the value of generation under a limited inference budget. This paper\npresents a study of optimizing inference hyperparameters such as the number of\nresponses, temperature and max tokens, which significantly affects the\nutility/cost of text generation. We design a framework named EcoOptiGen which\nleverages economical hyperparameter optimization and cost-based pruning.\nExperiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its\neffectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAML\nlibrary: \\url{https://aka.ms/autogen}.\n",
                "链接": "https://arxiv.org/abs/2303.04673"
            },
            {
                "文章ID": "100993",
                "标题": "LLMCad: Fast and Scalable On-device Large Language Model Inference",
                "作者": " Daliang Xu,  Wangsong Yin,  Xin Jin,  Ying Zhang,  Shiyun Wei,  Mengwei Xu,  Xuanzhe Liu",
                "发布日期": "2023-09-11",
                "摘要": "  Generative tasks, such as text generation and question answering, hold a\ncrucial position in the realm of mobile applications. Due to their sensitivity\nto privacy concerns, there is a growing demand for their execution directly on\nmobile devices. Currently, the execution of these generative tasks heavily\ndepends on Large Language Models (LLMs). Nevertheless, the limited memory\ncapacity of these devices presents a formidable challenge to the scalability of\nsuch models.\n  In our research, we introduce LLMCad, an innovative on-device inference\nengine specifically designed for efficient generative Natural Language\nProcessing (NLP) tasks. The core idea behind LLMCad revolves around model\ncollaboration: a compact LLM, residing in memory, takes charge of generating\nthe most straightforward tokens, while a high-precision LLM steps in to\nvalidate these tokens and rectify any identified errors. LLMCad incorporates\nthree novel techniques: (1) Instead of generating candidate tokens in a\nsequential manner, LLMCad employs the smaller LLM to construct a token tree,\nencompassing a wider range of plausible token pathways. Subsequently, the\nlarger LLM can efficiently validate all of these pathways simultaneously. (2)\nIt employs a self-adjusting fallback strategy, swiftly initiating the\nverification process whenever the smaller LLM generates an erroneous token. (3)\nTo ensure a continuous flow of token generation, LLMCad speculatively generates\ntokens during the verification process by implementing a compute-IO pipeline.\nThrough an extensive series of experiments, LLMCad showcases an impressive\ntoken generation speed, achieving rates up to 9.3x faster than existing\ninference engines.\n",
                "链接": "https://arxiv.org/abs/2309.04255"
            },
            {
                "文章ID": "119522",
                "标题": "LinguaLinked: A Distributed Large Language Model Inference System for\n  Mobile Devices",
                "作者": " Junchen Zhao,  Yurun Song,  Simeng Liu,  Ian G. Harris,  Sangeetha Abdu Jyothi",
                "发布日期": "2023-12-04",
                "摘要": "  Deploying Large Language Models (LLMs) locally on mobile devices presents a\nsignificant challenge due to their extensive memory requirements. In this\npaper, we introduce LinguaLinked, a system for decentralized, distributed LLM\ninference on mobile devices. LinguaLinked enables collaborative execution of\nthe inference task across multiple trusted devices. LinguaLinked ensures data\nprivacy by processing information locally. LinguaLinked uses three key\nstrategies. First, an optimized model assignment technique segments LLMs and\nuses linear optimization to align segments with each device's capabilities.\nSecond, an optimized data transmission mechanism ensures efficient and\nstructured data flow between model segments while also maintaining the\nintegrity of the original model structure. Finally, LinguaLinked incorporates a\nruntime load balancer that actively monitors and redistributes tasks among\nmobile devices to prevent bottlenecks, enhancing the system's overall\nefficiency and responsiveness. We demonstrate that LinguaLinked facilitates\nefficient LLM inference while maintaining consistent throughput and minimal\nlatency through extensive testing across various mobile devices, from high-end\nto low-end Android devices. In our evaluations, compared to the baseline,\nLinguaLinked achieves an inference performance acceleration of $1.11\\times$ to\n$1.61\\times$ in single-threaded settings, $1.73\\times$ to $2.65\\times$ with\nmulti-threading. Additionally, runtime load balancing yields an overall\ninference acceleration of $1.29\\times$ to $1.32\\times$.\n",
                "链接": "https://arxiv.org/abs/2312.00388"
            },
            {
                "文章ID": "106719",
                "标题": "Chain of Natural Language Inference for Reducing Large Language Model\n  Ungrounded Hallucinations",
                "作者": " Deren Lei,  Yaxi Li,  Mengya Hu,  Mingyu Wang,  Vincent Yun,  Emily Ching,  Eslam Kamal",
                "发布日期": "2023-10-11",
                "摘要": "  Large language models (LLMs) can generate fluent natural language texts when\ngiven relevant documents as background context. This ability has attracted\nconsiderable interest in developing industry applications of LLMs. However,\nLLMs are prone to generate hallucinations that are not supported by the\nprovided sources. In this paper, we propose a hierarchical framework to detect\nand mitigate such ungrounded hallucination. Our framework uses Chain of Natural\nLanguage Inference (CoNLI) for hallucination detection and hallucination\nreduction via post-editing. Our approach achieves state-of-the-art performance\non hallucination detection and enhances text quality through rewrite, using\nLLMs without any fine-tuning or domain-specific prompt engineering. We show\nthat this simple plug-and-play framework can serve as an effective choice for\nhallucination detection and reduction, achieving competitive performance across\nvarious contexts.\n",
                "链接": "https://arxiv.org/abs/2310.03951"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月自然语言处理相关的文章。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "2023年以后关于NLP领域的持续性学习论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "51089",
                "标题": "Posterior Sampling for Continuing Environments",
                "作者": " Wanqiao Xu,  Shi Dong,  Benjamin Van Roy",
                "发布日期": "2023-02-02",
                "摘要": "  We develop an extension of posterior sampling for reinforcement learning\n(PSRL) that is suited for a continuing agent-environment interface and\nintegrates naturally into agent designs that scale to complex environments. The\napproach, continuing PSRL, maintains a statistically plausible model of the\nenvironment and follows a policy that maximizes expected $\\gamma$-discounted\nreturn in that model. At each time, with probability $1-\\gamma$, the model is\nreplaced by a sample from the posterior distribution over environments. For a\nchoice of discount factor that suitably depends on the horizon $T$, we\nestablish an $\\tilde{O}(\\tau S \\sqrt{A T})$ bound on the Bayesian regret, where\n$S$ is the number of environment states, $A$ is the number of actions, and\n$\\tau$ denotes the reward averaging time, which is a bound on the duration\nrequired to accurately estimate the average reward of any policy. Our work is\nthe first to formalize and rigorously analyze the resampling approach with\nrandomized exploration.\n",
                "链接": "https://arxiv.org/abs/2211.15931"
            },
            {
                "文章ID": "83317",
                "标题": "Tackling Unbounded State Spaces in Continuing Task Reinforcement\n  Learning",
                "作者": " Brahma S. Pavse,  Yudong Chen,  Qiaomin Xie,  Josiah P. Hanna",
                "发布日期": "2023-06-06",
                "摘要": "  While deep reinforcement learning (RL) algorithms have been successfully\napplied to many tasks, their inability to extrapolate and strong reliance on\nepisodic resets inhibits their applicability to many real-world settings. For\ninstance, in stochastic queueing problems, the state space can be unbounded and\nthe agent may have to learn online without the system ever being reset to\nstates the agent has seen before. In such settings, we show that deep RL agents\ncan diverge into unseen states from which they can never recover due to the\nlack of resets, especially in highly stochastic environments. Towards\novercoming this divergence, we introduce a Lyapunov-inspired reward shaping\napproach that encourages the agent to first learn to be stable (i.e. to achieve\nbounded cost) and then to learn to be optimal. We theoretically show that our\nreward shaping technique reduces the rate of divergence of the agent and\nempirically find that it prevents it. We further combine our reward shaping\napproach with a weight annealing scheme that gradually introduces optimality\nand log-transform of state inputs, and find that these techniques enable deep\nRL algorithms to learn high performing policies when learning online in\nunbounded state space domains.\n",
                "链接": "https://arxiv.org/abs/2306.01896"
            },
            {
                "文章ID": "108865",
                "标题": "Domain-Specific Language Model Post-Training for Indonesian Financial\n  NLP",
                "作者": " Ni Putu Intan Maharani,  Yoga Yustiawan,  Fauzy Caesar Rochim,  Ayu Purwarianti",
                "发布日期": "2023-10-17",
                "摘要": "  BERT and IndoBERT have achieved impressive performance in several NLP tasks.\nThere has been several investigation on its adaption in specialized domains\nespecially for English language. We focus on financial domain and Indonesian\nlanguage, where we perform post-training on pre-trained IndoBERT for financial\ndomain using a small scale of Indonesian financial corpus. In this paper, we\nconstruct an Indonesian self-supervised financial corpus, Indonesian financial\nsentiment analysis dataset, Indonesian financial topic classification dataset,\nand release a family of BERT models for financial NLP. We also evaluate the\neffectiveness of domain-specific post-training on sentiment analysis and topic\nclassification tasks. Our findings indicate that the post-training increases\nthe effectiveness of a language model when it is fine-tuned to domain-specific\ndownstream tasks.\n",
                "链接": "https://arxiv.org/abs/2310.09736"
            },
            {
                "文章ID": "110753",
                "标题": "Universal Domain Adaptation for Robust Handling of Distributional Shifts\n  in NLP",
                "作者": " Hyuhng Joon Kim,  Hyunsoo Cho,  Sang-Woo Lee,  Junyeob Kim,  Choonghyun Park,  Sang-goo Lee,  Kang Min Yoo,  Taeuk Kim",
                "发布日期": "2023-10-24",
                "摘要": "  When deploying machine learning systems to the wild, it is highly desirable\nfor them to effectively leverage prior knowledge to the unfamiliar domain while\nalso firing alarms to anomalous inputs. In order to address these requirements,\nUniversal Domain Adaptation (UniDA) has emerged as a novel research area in\ncomputer vision, focusing on achieving both adaptation ability and robustness\n(i.e., the ability to detect out-of-distribution samples). While UniDA has led\nsignificant progress in computer vision, its application on language input\nstill needs to be explored despite its feasibility. In this paper, we propose a\ncomprehensive benchmark for natural language that offers thorough viewpoints of\nthe model's generalizability and robustness. Our benchmark encompasses multiple\ndatasets with varying difficulty levels and characteristics, including temporal\nshifts and diverse domains. On top of our testbed, we validate existing UniDA\nmethods from computer vision and state-of-the-art domain adaptation techniques\nfrom NLP literature, yielding valuable findings: We observe that UniDA methods\noriginally designed for image input can be effectively transferred to the\nnatural language domain while also underscoring the effect of adaptation\ndifficulty in determining the model's performance.\n",
                "链接": "https://arxiv.org/abs/2310.14849"
            },
            {
                "文章ID": "53069",
                "标题": "A Unified Knowledge Graph Augmentation Service for Boosting\n  Domain-specific NLP Tasks",
                "作者": " Ruiqing Ding,  Xiao Han,  Leye Wang",
                "发布日期": "2023-06-06",
                "摘要": "  By focusing the pre-training process on domain-specific corpora, some\ndomain-specific pre-trained language models (PLMs) have achieved\nstate-of-the-art results. However, it is under-investigated to design a unified\nparadigm to inject domain knowledge in the PLM fine-tuning stage. We propose\nKnowledgeDA, a unified domain language model development service to enhance the\ntask-specific training procedure with domain knowledge graphs. Given\ndomain-specific task texts input, KnowledgeDA can automatically generate a\ndomain-specific language model following three steps: (i) localize domain\nknowledge entities in texts via an embedding-similarity approach; (ii) generate\naugmented samples by retrieving replaceable domain entity pairs from two views\nof both knowledge graph and training data; (iii) select high-quality augmented\nsamples for fine-tuning via confidence-based assessment. We implement a\nprototype of KnowledgeDA to learn language models for two domains, healthcare\nand software development. Experiments on domain-specific text classification\nand QA tasks verify the effectiveness and generalizability of KnowledgeDA.\n",
                "链接": "https://arxiv.org/abs/2212.05251"
            },
            {
                "文章ID": "20180",
                "标题": "FedAdapter: Efficient Federated Learning for Modern NLP",
                "作者": " Dongqi Cai,  Yaozong Wu,  Shangguang Wang,  Felix Xiaozhu Lin,  Mengwei Xu",
                "发布日期": "2023-05-10",
                "摘要": "  Transformer-based pre-trained models have revolutionized NLP for superior\nperformance and generality. Fine-tuning pre-trained models for downstream tasks\noften requires private data, for which federated learning is the de-facto\napproach (i.e., FedNLP). However, our measurements show that FedNLP is\nprohibitively slow due to the large model sizes and the resultant high\nnetwork/computation cost. Towards practical FedNLP, we identify as the key\nbuilding blocks adapters, small bottleneck modules inserted at a variety of\nmodel layers. A key challenge is to properly configure the depth and width of\nadapters, to which the training speed and efficiency is highly sensitive. No\nsilver-bullet configuration exists: the optimal choice varies across downstream\nNLP tasks, desired model accuracy, and mobile resources. To automate adapter\nconfiguration, we propose FedAdapter, a framework that enhances the existing\nFedNLP with two novel designs. First, FedAdapter progressively upgrades the\nadapter configuration throughout a training session; the principle is to\nquickly learn shallow knowledge by only training fewer and smaller adapters at\nthe model's top layers, and incrementally learn deep knowledge by incorporating\ndeeper and larger adapters. Second, FedAdapter continuously profiles future\nadapter configurations by allocating participant devices to trial groups.\nExtensive experiments show that FedAdapter can reduce FedNLP's model\nconvergence delay to no more than several hours, which is up to 155.5$\\times$\nfaster compared to vanilla FedNLP and 48$\\times$ faster compared to strong\nbaselines.\n",
                "链接": "https://arxiv.org/abs/2205.10162"
            },
            {
                "文章ID": "53261",
                "标题": "Federated Few-Shot Learning for Mobile NLP",
                "作者": " Dongqi Cai,  Shangguang Wang,  Yaozong Wu,  Felix Xiaozhu Lin,  Mengwei Xu",
                "发布日期": "2023-08-22",
                "摘要": "  Natural language processing (NLP) sees rich mobile applications. To support\nvarious language understanding tasks, a foundation NLP model is often\nfine-tuned in a federated, privacy-preserving setting (FL). This process\ncurrently relies on at least hundreds of thousands of labeled training samples\nfrom mobile clients; yet mobile users often lack willingness or knowledge to\nlabel their data. Such an inadequacy of data labels is known as a few-shot\nscenario; it becomes the key blocker for mobile NLP applications.\n  For the first time, this work investigates federated NLP in the few-shot\nscenario (FedFSL). By retrofitting algorithmic advances of pseudo labeling and\nprompt learning, we first establish a training pipeline that delivers\ncompetitive accuracy when only 0.05% (fewer than 100) of the training data is\nlabeled and the remaining is unlabeled. To instantiate the workflow, we further\npresent a system FeS, addressing the high execution cost with novel designs.\n(1) Curriculum pacing, which injects pseudo labels to the training workflow at\na rate commensurate to the learning progress; (2) Representational diversity, a\nmechanism for selecting the most learnable data, only for which pseudo labels\nwill be generated; (3) Co-planning of a model's training depth and layer\ncapacity. Together, these designs reduce the training delay, client energy, and\nnetwork traffic by up to 46.0$\\times$, 41.2$\\times$ and 3000.0$\\times$,\nrespectively. Through algorithm/system co-design, FFNLP demonstrates that FL\ncan apply to challenging settings where most training samples are unlabeled.\n",
                "链接": "https://arxiv.org/abs/2212.05974"
            },
            {
                "文章ID": "83849",
                "标题": "shs-nlp at RadSum23: Domain-Adaptive Pre-training of Instruction-tuned\n  LLMs for Radiology Report Impression Generation",
                "作者": " Sanjeev Kumar Karn,  Rikhiya Ghosh,  Kusuma P,  Oladimeji Farri",
                "发布日期": "2023-06-07",
                "摘要": "  Instruction-tuned generative Large language models (LLMs) like ChatGPT and\nBloomz possess excellent generalization abilities, but they face limitations in\nunderstanding radiology reports, particularly in the task of generating the\nIMPRESSIONS section from the FINDINGS section. They tend to generate either\nverbose or incomplete IMPRESSIONS, mainly due to insufficient exposure to\nmedical text data during training. We present a system which leverages\nlarge-scale medical text data for domain-adaptive pre-training of\ninstruction-tuned LLMs to enhance its medical knowledge and performance on\nspecific medical tasks. We show that this system performs better in a zero-shot\nsetting than a number of pretrain-and-finetune adaptation methods on the\nIMPRESSIONS generation task, and ranks 1st among participating systems in Task\n1B: Radiology Report Summarization at the BioNLP 2023 workshop.\n",
                "链接": "https://arxiv.org/abs/2306.03264"
            },
            {
                "文章ID": "90487",
                "标题": "NLP Meets RNA: Unsupervised Embedding Learning for Ribozymes with\n  Word2Vec",
                "作者": " Andrew Kean Gao",
                "发布日期": "2023-07-13",
                "摘要": "  Ribozymes, RNA molecules with distinct 3D structures and catalytic activity,\nhave widespread applications in synthetic biology and therapeutics. However,\nrelatively little research has focused on leveraging deep learning to enhance\nour understanding of ribozymes. This study implements Word2Vec, an unsupervised\nlearning technique for natural language processing, to learn ribozyme\nembeddings. Ribo2Vec was trained on over 9,000 diverse ribozymes, learning to\nmap sequences to 128 and 256-dimensional vector spaces. Using Ribo2Vec,\nsequence embeddings for five classes of ribozymes (hatchet, pistol, hairpin,\nhovlinc, and twister sister) were calculated. Principal component analysis\ndemonstrated the ability of these embeddings to distinguish between ribozyme\nclasses. Furthermore, a simple SVM classifier trained on ribozyme embeddings\nshowed promising results in accurately classifying ribozyme types. Our results\nsuggest that the embedding vectors contained meaningful information about\nribozymes. Interestingly, 256-dimensional embeddings behaved similarly to\n128-dimensional embeddings, suggesting that a lower dimension vector space is\ngenerally sufficient to capture ribozyme features. This approach demonstrates\nthe potential of Word2Vec for bioinformatics, opening new avenues for ribozyme\nresearch. Future research includes using a Transformer-based method to learn\nRNA embeddings, which can capture long-range interactions between nucleotides.\n",
                "链接": "https://arxiv.org/abs/2307.05537"
            },
            {
                "文章ID": "62616",
                "标题": "Time to Embrace Natural Language Processing (NLP)-based Digital\n  Pathology: Benchmarking NLP- and Convolutional Neural Network-based Deep\n  Learning Pipelines",
                "作者": " Min Cen,  Xingyu Li,  Bangwei Guo,  Jitendra Jonnagaddala,  Hong Zhang,  Xu Steven Xu",
                "发布日期": "2023-02-22",
                "摘要": "  NLP-based computer vision models, particularly vision transformers, have been\nshown to outperform CNN models in many imaging tasks. However, most digital\npathology artificial-intelligence models are based on CNN architectures,\nprobably owing to a lack of data regarding NLP models for pathology images. In\nthis study, we developed digital pathology pipelines to benchmark the five most\nrecently proposed NLP models (vision transformer (ViT), Swin Transformer,\nMobileViT, CMT, and Sequencer2D) and four popular CNN models (ResNet18,\nResNet50, MobileNetV2, and EfficientNet) to predict biomarkers in colorectal\ncancer (microsatellite instability, CpG island methylator phenotype, and BRAF\nmutation). Hematoxylin and eosin-stained whole-slide images from Molecular and\nCellular Oncology and The Cancer Genome Atlas were used as training and\nexternal validation datasets, respectively. Cross-study external validations\nrevealed that the NLP-based models significantly outperformed the CNN-based\nmodels in biomarker prediction tasks, improving the overall prediction and\nprecision up to approximately 10% and 26%, respectively. Notably, compared with\nexisting models in the current literature using large training datasets, our\nNLP models achieved state-of-the-art predictions for all three biomarkers using\na relatively small training dataset, suggesting that large training datasets\nare not a prerequisite for NLP models or transformers, and NLP may be more\nsuitable for clinical studies in which small training datasets are commonly\ncollected. The superior performance of Sequencer2D suggests that further\nresearch and innovation on both transformer and bidirectional long short-term\nmemory architectures are warranted in the field of digital pathology. NLP\nmodels can replace classic CNN architectures and become the new workhorse\nbackbone in the field of digital pathology.\n",
                "链接": "https://arxiv.org/abs/2302.10406"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下工具评测相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "34033",
                "标题": "SimLDA: A tool for topic model evaluation",
                "作者": " Rebecca M. C. Taylor,  Johan A. du Preez",
                "发布日期": "2022-08-22",
                "摘要": "  Variational Bayes (VB) applied to latent Dirichlet allocation (LDA) has\nbecome the most popular algorithm for aspect modeling. While sufficiently\nsuccessful in text topic extraction from large corpora, VB is less successful\nin identifying aspects in the presence of limited data. We present a novel\nvariational message passing algorithm as applied to Latent Dirichlet Allocation\n(LDA) and compare it with the gold standard VB and collapsed Gibbs sampling. In\nsituations where marginalisation leads to non-conjugate messages, we use ideas\nfrom sampling to derive approximate update equations. In cases where conjugacy\nholds, Loopy Belief update (LBU) (also known as Lauritzen-Spiegelhalter) is\nused. Our algorithm, ALBU (approximate LBU), has strong similarities with\nVariational Message Passing (VMP) (which is the message passing variant of VB).\nTo compare the performance of the algorithms in the presence of limited data,\nwe use data sets consisting of tweets and news groups. Using coherence measures\nwe show that ALBU learns latent distributions more accurately than does VB,\nespecially for smaller data sets.\n",
                "链接": "https://arxiv.org/abs/2208.09299"
            },
            {
                "文章ID": "25887",
                "标题": "Diagnostic Tool for Out-of-Sample Model Evaluation",
                "作者": " Ludvig Hult,  Dave Zachariah,  Petre Stoica",
                "发布日期": "2023-10-17",
                "摘要": "  Assessment of model fitness is a key part of machine learning. The standard\nparadigm is to learn models by minimizing a chosen loss function averaged over\ntraining data, with the aim of achieving small losses on future data. In this\npaper, we consider the use of a finite calibration data set to characterize the\nfuture, out-of-sample losses of a model. We propose a simple model diagnostic\ntool that provides finite-sample guarantees under weak assumptions. The tool is\nsimple to compute and to interpret. Several numerical experiments are presented\nto show how the proposed method quantifies the impact of distribution shifts,\naids the analysis of regression, and enables model selection as well as\nhyper-parameter tuning.\n",
                "链接": "https://arxiv.org/abs/2206.10982"
            },
            {
                "文章ID": "108993",
                "标题": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
                "作者": " Alon Jacovi,  Avi Caciularu,  Jonathan Herzig,  Roee Aharoni,  Bernd Bohnet,  Mor Geva",
                "发布日期": "2023-12-29",
                "摘要": "  A growing area of research investigates augmenting language models with tools\n(e.g., search engines, calculators) to overcome their shortcomings (e.g.,\nmissing or incorrect knowledge, incorrect logical inferences). Various few-shot\ntool-usage strategies have been proposed. However, there is no systematic and\nfair comparison across different strategies, or between these strategies and\nstrong baselines that do not leverage tools. We conduct an extensive empirical\nanalysis, finding that (1) across various datasets, example difficulty levels,\nand models, strong no-tool baselines are competitive to tool-assisted\nstrategies, implying that effectively using tools with in-context\ndemonstrations is a difficult unsolved problem; (2) for knowledge-retrieval\ntasks, strategies that *refine* incorrect outputs with tools outperform\nstrategies that retrieve relevant information *ahead of* or *during\ngeneration*; (3) tool-assisted strategies are expensive in the number of tokens\nthey require to work -- incurring additional costs by orders of magnitude --\nwhich does not translate into significant improvement in performance. Overall,\nour findings suggest that few-shot tool integration is still an open challenge,\nemphasizing the need for comprehensive evaluations of future strategies to\naccurately assess their *benefits* and *costs*.\n",
                "链接": "https://arxiv.org/abs/2310.10062"
            },
            {
                "文章ID": "86296",
                "标题": "INDCOR white paper 4: Evaluation of Interactive Narrative Design For\n  Complexity Representations",
                "作者": " Christian Roth,  Breanne Pitt,  Lāsma Šķestere,  Jonathan Barbara,  Agnes Karolina Bakk,  Kirsty Dunlop,  Maria del Mar Grandio,  Miguel Barreda,  Despoina Sampatakou,  Michael Schlauch",
                "发布日期": "2023-07-07",
                "摘要": "  While a strength of Interactive Digital Narratives (IDN) is its support for\nmultiperspectivity, this also poses a substantial challenge to its evaluation.\nMoreover, evaluation has to assess the system's ability to represent a complex\nreality as well as the user's understanding of that complex reality as a result\nof the experience of interacting with the system. This is needed to measure an\nIDN's efficiency and effectiveness in representing the chosen complex\nphenomenon. We here present some empirical methods employed by INDCOR members\nin their research including UX toolkits and scales. Particularly, we consider\nthe impact of IDN on transformative learning and its evaluation through\nself-reporting and other alternatives.\n",
                "链接": "https://arxiv.org/abs/2306.09817"
            },
            {
                "文章ID": "18767",
                "标题": "ALIGNMEET: A Comprehensive Tool for Meeting Annotation, Alignment, and\n  Evaluation",
                "作者": " Peter Polák,  Muskaan Singh,  Anna Nedoluzhko,  Ondřej Bojar",
                "发布日期": "2022-05-12",
                "摘要": "  Summarization is a challenging problem, and even more challenging is to\nmanually create, correct, and evaluate the summaries. The severity of the\nproblem grows when the inputs are multi-party dialogues in a meeting setup. To\nfacilitate the research in this area, we present ALIGNMEET, a comprehensive\ntool for meeting annotation, alignment, and evaluation. The tool aims to\nprovide an efficient and clear interface for fast annotation while mitigating\nthe risk of introducing errors. Moreover, we add an evaluation mode that\nenables a comprehensive quality evaluation of meeting minutes. To the best of\nour knowledge, there is no such tool available. We release the tool as open\nsource. It is also directly installable from PyPI.\n",
                "链接": "https://arxiv.org/abs/2205.05433"
            },
            {
                "文章ID": "38679",
                "标题": "An Interdisciplinary Perspective on Evaluation and Experimental Design\n  for Visual Text Analytics: Position Paper",
                "作者": " Kostiantyn Kucher,  Nicole Sultanum,  Angel Daza,  Vasiliki Simaki,  Maria Skeppstedt,  Barbara Plank,  Jean-Daniel Fekete,  Narges Mahyar",
                "发布日期": "2022-12-21",
                "摘要": "  Appropriate evaluation and experimental design are fundamental for empirical\nsciences, particularly in data-driven fields. Due to the successes in\ncomputational modeling of languages, for instance, research outcomes are having\nan increasingly immediate impact on end users. As the gap in adoption by end\nusers decreases, the need increases to ensure that tools and models developed\nby the research communities and practitioners are reliable, trustworthy, and\nsupportive of the users in their goals. In this position paper, we focus on the\nissues of evaluating visual text analytics approaches. We take an\ninterdisciplinary perspective from the visualization and natural language\nprocessing communities, as we argue that the design and validation of visual\ntext analytics include concerns beyond computational or visual/interactive\nmethods on their own. We identify four key groups of challenges for evaluating\nvisual text analytics approaches (data ambiguity, experimental design, user\ntrust, and \"big picture\" concerns) and provide suggestions for research\nopportunities from an interdisciplinary perspective.\n",
                "链接": "https://arxiv.org/abs/2209.11534"
            },
            {
                "文章ID": "46198",
                "标题": "Evaluation Metrics for Symbolic Knowledge Extracted from Machine\n  Learning Black Boxes: A Discussion Paper",
                "作者": " Federico Sabbatini,  Roberta Calegari",
                "发布日期": "2022-11-02",
                "摘要": "  As opaque decision systems are being increasingly adopted in almost any\napplication field, issues about their lack of transparency and human\nreadability are a concrete concern for end-users. Amongst existing proposals to\nassociate human-interpretable knowledge with accurate predictions provided by\nopaque models, there are rule extraction techniques, capable of extracting\nsymbolic knowledge out of an opaque model. However, how to assess the level of\nreadability of the extracted knowledge quantitatively is still an open issue.\nFinding such a metric would be the key, for instance, to enable automatic\ncomparison between a set of different knowledge representations, paving the way\nfor the development of parameter autotuning algorithms for knowledge\nextractors. In this paper we discuss the need for such a metric as well as the\ncriticalities of readability assessment and evaluation, taking into account the\nmost common knowledge representations while highlighting the most puzzling\nissues.\n",
                "链接": "https://arxiv.org/abs/2211.00238"
            },
            {
                "文章ID": "88457",
                "标题": "CORAE: A Tool for Intuitive and Continuous Retrospective Evaluation of\n  Interactions",
                "作者": " Michael J. Sack,  Maria Teresa Parreira,  Jenny Fu,  Asher Lipman,  Hifza Javed,  Nawid Jamali,  Malte Jung",
                "发布日期": "2023-06-30",
                "摘要": "  This paper introduces CORAE, a novel web-based open-source tool for\nCOntinuous Retrospective Affect Evaluation, designed to capture continuous\naffect data about interpersonal perceptions in dyadic interactions. Grounded in\nbehavioral ecology perspectives of emotion, this approach replaces valence as\nthe relevant rating dimension with approach and withdrawal, reflecting the\ndegree to which behavior is perceived as increasing or decreasing social\ndistance. We conducted a study to experimentally validate the efficacy of our\nplatform with 24 participants. The tool's effectiveness was tested in the\ncontext of dyadic negotiation, revealing insights about how interpersonal\ndynamics evolve over time. We find that the continuous affect rating method is\nconsistent with individuals' perception of the overall interaction. This paper\ncontributes to the growing body of research on affective computing and offers a\nvaluable tool for researchers interested in investigating the temporal dynamics\nof affect and emotion in social interactions.\n",
                "链接": "https://arxiv.org/abs/2306.16629"
            },
            {
                "文章ID": "65053",
                "标题": "Population-based Evaluation in Repeated Rock-Paper-Scissors as a\n  Benchmark for Multiagent Reinforcement Learning",
                "作者": " Marc Lanctot,  John Schultz,  Neil Burch,  Max Olan Smith,  Daniel Hennes,  Thomas Anthony,  Julien Perolat",
                "发布日期": "2023-11-02",
                "摘要": "  Progress in fields of machine learning and adversarial planning has benefited\nsignificantly from benchmark domains, from checkers and the classic UCI data\nsets to Go and Diplomacy. In sequential decision-making, agent evaluation has\nlargely been restricted to few interactions against experts, with the aim to\nreach some desired level of performance (e.g. beating a human professional\nplayer). We propose a benchmark for multiagent learning based on repeated play\nof the simple game Rock, Paper, Scissors along with a population of forty-three\ntournament entries, some of which are intentionally sub-optimal. We describe\nmetrics to measure the quality of agents based both on average returns and\nexploitability. We then show that several RL, online learning, and language\nmodel approaches can learn good counter-strategies and generalize well, but\nultimately lose to the top-performing bots, creating an opportunity for\nresearch in multiagent learning.\n",
                "链接": "https://arxiv.org/abs/2303.03196"
            },
            {
                "文章ID": "33437",
                "标题": "ELEVANT: A Fully Automatic Fine-Grained Entity Linking Evaluation and\n  Analysis Tool",
                "作者": " Hannah Bast,  Matthias Hertel,  Natalie Prange",
                "发布日期": "2022-08-16",
                "摘要": "  We present Elevant, a tool for the fully automatic fine-grained evaluation of\na set of entity linkers on a set of benchmarks. Elevant provides an automatic\nbreakdown of the performance by various error categories and by entity type.\nElevant also provides a rich and compact, yet very intuitive and\nself-explanatory visualization of the results of a linker on a benchmark in\ncomparison to the ground truth. A live demo, the link to the complete code base\non GitHub and a link to a demo video are provided under\nhttps://elevant.cs.uni-freiburg.de .\n",
                "链接": "https://arxiv.org/abs/2208.07193"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查询2022年以来指令遵循数据集构建相关的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找关于gpt4自动生成prompt的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "新的大模型结构相关探索的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "110744",
                "标题": "ALCUNA: Large Language Models Meet New Knowledge",
                "作者": " Xunjian Yin,  Baizhou Huang,  Xiaojun Wan",
                "发布日期": "2023-10-24",
                "摘要": "  With the rapid development of NLP, large-scale language models (LLMs) excel\nin various tasks across multiple domains now. However, existing benchmarks may\nnot adequately measure these models' capabilities, especially when faced with\nnew knowledge. In this paper, we address the lack of benchmarks to evaluate\nLLMs' ability to handle new knowledge, an important and challenging aspect in\nthe rapidly evolving world. We propose an approach called KnowGen that\ngenerates new knowledge by altering existing entity attributes and\nrelationships, resulting in artificial entities that are distinct from\nreal-world entities. With KnowGen, we introduce a benchmark named ALCUNA to\nassess LLMs' abilities in knowledge understanding, differentiation, and\nassociation. We benchmark several LLMs, reveals that their performance in face\nof new knowledge is not satisfactory, particularly in reasoning between new and\ninternal knowledge. We also explore the impact of entity similarity on the\nmodel's understanding of entity knowledge and the influence of contextual\nentities. We appeal to the need for caution when using LLMs in new scenarios or\nwith new knowledge, and hope that our benchmarks can help drive the development\nof LLMs in face of new knowledge.\n",
                "链接": "https://arxiv.org/abs/2310.14820"
            },
            {
                "文章ID": "2013",
                "标题": "Encoding large information structures in linear algebra and statistical\n  models",
                "作者": " David Banh,  Alan Huang",
                "发布日期": "2022-06-23",
                "摘要": "  Large information sizes in samples and features can be encoded to speed up\nthe learning of statistical models based on linear algebra and remove unwanted\nsignals. Encoding information can reduce both sample and feature dimension to a\nsmaller representational set. Here two examples are shown on linear mixed\nmodels and mixture models speeding up the run time for parameter estimation by\na factor defined by the user's choice on dimension reduction (can be linear,\nquadratic or beyond based on dimension specification).\n",
                "链接": "https://arxiv.org/abs/2201.08233"
            },
            {
                "文章ID": "95218",
                "标题": "Evaluating and Explaining Large Language Models for Code Using Syntactic\n  Structures",
                "作者": " David N Palacio,  Alejandro Velasco,  Daniel Rodriguez-Cardenas,  Kevin Moran,  Denys Poshyvanyk",
                "发布日期": "2023-08-09",
                "摘要": "  Large Language Models (LLMs) for code are a family of high-parameter,\ntransformer-based neural networks pre-trained on massive datasets of both\nnatural and programming languages. These models are rapidly being employed in\ncommercial AI-based developer tools, such as GitHub CoPilot. However, measuring\nand explaining their effectiveness on programming tasks is a challenging\nproposition, given their size and complexity. The methods for evaluating and\nexplaining LLMs for code are inextricably linked. That is, in order to explain\na model's predictions, they must be reliably mapped to fine-grained,\nunderstandable concepts. Once this mapping is achieved, new methods for\ndetailed model evaluations are possible. However, most current explainability\ntechniques and evaluation benchmarks focus on model robustness or individual\ntask performance, as opposed to interpreting model predictions.\n  To this end, this paper introduces ASTxplainer, an explainability method\nspecific to LLMs for code that enables both new methods for LLM evaluation and\nvisualizations of LLM predictions that aid end-users in understanding model\npredictions. At its core, ASTxplainer provides an automated method for aligning\ntoken predictions with AST nodes, by extracting and aggregating normalized\nmodel logits within AST structures. To demonstrate the practical benefit of\nASTxplainer, we illustrate the insights that our framework can provide by\nperforming an empirical evaluation on 12 popular LLMs for code using a curated\ndataset of the most popular GitHub projects. Additionally, we perform a user\nstudy examining the usefulness of an ASTxplainer-derived visualization of model\npredictions aimed at enabling model users to explain predictions. The results\nof these studies illustrate the potential for ASTxplainer to provide insights\ninto LLM effectiveness, and aid end-users in understanding predictions.\n",
                "链接": "https://arxiv.org/abs/2308.03873"
            },
            {
                "文章ID": "105692",
                "标题": "Large Language Model-Powered Smart Contract Vulnerability Detection: New\n  Perspectives",
                "作者": " Sihao Hu,  Tiansheng Huang,  Fatih İlhan,  Selim Furkan Tekin,  Ling Liu",
                "发布日期": "2023-10-18",
                "摘要": "  This paper provides a systematic analysis of the opportunities, challenges,\nand potential solutions of harnessing Large Language Models (LLMs) such as\nGPT-4 to dig out vulnerabilities within smart contracts based on our ongoing\nresearch. For the task of smart contract vulnerability detection, achieving\npractical usability hinges on identifying as many true vulnerabilities as\npossible while minimizing the number of false positives. Nonetheless, our\nempirical study reveals contradictory yet interesting findings: generating more\nanswers with higher randomness largely boosts the likelihood of producing a\ncorrect answer but inevitably leads to a higher number of false positives. To\nmitigate this tension, we propose an adversarial framework dubbed GPTLens that\nbreaks the conventional one-stage detection into two synergistic stages $-$\ngeneration and discrimination, for progressive detection and refinement,\nwherein the LLM plays dual roles, i.e., auditor and critic, respectively. The\ngoal of auditor is to yield a broad spectrum of vulnerabilities with the hope\nof encompassing the correct answer, whereas the goal of critic that evaluates\nthe validity of identified vulnerabilities is to minimize the number of false\npositives. Experimental results and illustrative examples demonstrate that\nauditor and critic work together harmoniously to yield pronounced improvements\nover the conventional one-stage detection. GPTLens is intuitive, strategic, and\nentirely LLM-driven without relying on specialist expertise in smart contracts,\nshowcasing its methodical generality and potential to detect a broad spectrum\nof vulnerabilities. Our code is available at:\nhttps://github.com/git-disl/GPTLens.\n",
                "链接": "https://arxiv.org/abs/2310.01152"
            },
            {
                "文章ID": "84596",
                "标题": "Robot Task Planning Based on Large Language Model Representing Knowledge\n  with Directed Graph Structures",
                "作者": " Yue Zhen,  Sheng Bi,  Lu Xing-tong,  Pan Wei-qin,  Shi Hai-peng,  Chen Zi-rui,  Fang Yi-shu",
                "发布日期": "2023-06-09",
                "摘要": "  Traditional robot task planning methods face challenges when dealing with\nhighly unstructured environments and complex tasks. We propose a task planning\nmethod that combines human expertise with an LLM and have designed an LLM\nprompt template, Think_Net_Prompt, with stronger expressive power to represent\nstructured professional knowledge. We further propose a method to progressively\ndecompose tasks and generate a task tree to reduce the planning volume for each\ntask, and we have designed a strategy to decouple robot task planning. By\ndividing different planning entities and separating the task from the actual\nmachine binding process, the task planning process becomes more flexible.\nResearch results show that our method performs well in handling specified code\nformats, understanding the relationship between tasks and subtasks, and\nextracting parameters from text descriptions. However, there are also problems\nsuch as limited complexity of task logic handling, ambiguity in the quantity of\nparts and the precise location of assembly. Improving the precision of task\ndescription and cognitive structure can bring certain improvements.\nhttps://github.com/NOMIzy/Think_Net_Prompt\n",
                "链接": "https://arxiv.org/abs/2306.05171"
            },
            {
                "文章ID": "14145",
                "标题": "Towards Understanding Large-Scale Discourse Structures in Pre-Trained\n  and Fine-Tuned Language Models",
                "作者": " Patrick Huber,  Giuseppe Carenini",
                "发布日期": "2022-04-12",
                "摘要": "  With a growing number of BERTology work analyzing different components of\npre-trained language models, we extend this line of research through an\nin-depth analysis of discourse information in pre-trained and fine-tuned\nlanguage models. We move beyond prior work along three dimensions: First, we\ndescribe a novel approach to infer discourse structures from arbitrarily long\ndocuments. Second, we propose a new type of analysis to explore where and how\naccurately intrinsic discourse is captured in the BERT and BART models.\nFinally, we assess how similar the generated structures are to a variety of\nbaselines as well as their distribution within and between models.\n",
                "链接": "https://arxiv.org/abs/2204.04289"
            },
            {
                "文章ID": "38875",
                "标题": "Partial annotations for the segmentation of large structures with low\n  annotation cost",
                "作者": " Bella Specktor Fadida,  Daphna Link Sourani,  Liat Ben Sira Elka Miller,  Dafna Ben Bashat,  Leo Joskowicz",
                "发布日期": "2022-09-27",
                "摘要": "  Deep learning methods have been shown to be effective for the automatic\nsegmentation of structures and pathologies in medical imaging. However, they\nrequire large annotated datasets, whose manual segmentation is a tedious and\ntime-consuming task, especially for large structures. We present a new method\nof partial annotations that uses a small set of consecutive annotated slices\nfrom each scan with an annotation effort that is equal to that of only few\nannotated cases. The training with partial annotations is performed by using\nonly annotated blocks, incorporating information about slices outside the\nstructure of interest and modifying a batch loss function to consider only the\nannotated slices. To facilitate training in a low data regime, we use a\ntwo-step optimization process. We tested the method with the popular soft Dice\nloss for the fetal body segmentation task in two MRI sequences, TRUFI and\nFIESTA, and compared full annotation regime to partial annotations with a\nsimilar annotation effort. For TRUFI data, the use of partial annotations\nyielded slightly better performance on average compared to full annotations\nwith an increase in Dice score from 0.936 to 0.942, and a substantial decrease\nin Standard Deviations (STD) of Dice score by 22% and Average Symmetric Surface\nDistance (ASSD) by 15%. For the FIESTA sequence, partial annotations also\nyielded a decrease in STD of the Dice score and ASSD metrics by 27.5% and 33%\nrespectively for in-distribution data, and a substantial improvement also in\naverage performance on out-of-distribution data, increasing Dice score from\n0.84 to 0.9 and decreasing ASSD from 7.46 to 4.01 mm. The two-step optimization\nprocess was helpful for partial annotations for both in-distribution and\nout-of-distribution data. The partial annotations method with the two-step\noptimizer is therefore recommended to improve segmentation performance under\nlow data regime.\n",
                "链接": "https://arxiv.org/abs/2209.12216"
            },
            {
                "文章ID": "50463",
                "标题": "Learning Large Causal Structures from Inverse Covariance Matrix via\n  Matrix Decomposition",
                "作者": " Shuyu Dong,  Kento Uemura,  Akito Fujii,  Shuang Chang,  Yusuke Koyanagi,  Koji Maruhashi,  Michèle Sebag",
                "发布日期": "2023-05-30",
                "摘要": "  Learning causal structures from observational data is a fundamental yet\nhighly complex problem when the number of variables is large. In this paper, we\nstart from linear structural equation models (SEMs) and investigate ways of\nlearning causal structures from the inverse covariance matrix. The proposed\nmethod, called $\\mathcal{O}$-ICID (for {\\it Independence-preserving}\nDecomposition from Oracle Inverse Covariance matrix), is based on continuous\noptimization of a type of matrix decomposition that preserves the nonzero\npatterns of the inverse covariance matrix. We show that $\\mathcal{O}$-ICID\nprovides an efficient way for identifying the true directed acyclic graph (DAG)\nunder the knowledge of noise variances. With weaker prior information, the\nproposed method gives directed graph solutions that are useful for making more\nrefined causal discovery. The proposed method enjoys a low complexity when the\ntrue DAG has bounded node degrees, as reflected by its time efficiency in\nexperiments in comparison with state-of-the-art algorithms.\n",
                "链接": "https://arxiv.org/abs/2211.14221"
            },
            {
                "文章ID": "33132",
                "标题": "Automatically Creating a Large Number of New Bilingual Dictionaries",
                "作者": " Khang Nhut Lam,  Feras Al Tarouti,  Jugal Kalita",
                "发布日期": "2022-08-15",
                "摘要": "  This paper proposes approaches to automatically create a large number of new\nbilingual dictionaries for low-resource languages, especially resource-poor and\nendangered languages, from a single input bilingual dictionary. Our algorithms\nproduce translations of words in a source language to plentiful target\nlanguages using available Wordnets and a machine translator (MT). Since our\napproaches rely on just one input dictionary, available Wordnets and an MT,\nthey are applicable to any bilingual dictionary as long as one of the two\nlanguages is English or has a Wordnet linked to the Princeton Wordnet. Starting\nwith 5 available bilingual dictionaries, we create 48 new bilingual\ndictionaries. Of these, 30 pairs of languages are not supported by the popular\nMTs: Google and Bing.\n",
                "链接": "https://arxiv.org/abs/2208.06110"
            },
            {
                "文章ID": "74919",
                "标题": "Causal Reasoning and Large Language Models: Opening a New Frontier for\n  Causality",
                "作者": " Emre Kıcıman,  Robert Ness,  Amit Sharma,  Chenhao Tan",
                "发布日期": "2023-05-09",
                "摘要": "  The causal capabilities of large language models (LLMs) is a matter of\nsignificant debate, with critical implications for the use of LLMs in\nsocietally impactful domains such as medicine, science, law, and policy. We\nfurther our understanding of LLMs and their causal implications, considering\nthe distinctions between different types of causal reasoning tasks, as well as\nthe entangled threats of construct and measurement validity. LLM-based methods\nestablish new state-of-the-art accuracies on multiple causal benchmarks.\nAlgorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise\ncausal discovery task (97%, 13 points gain), counterfactual reasoning task\n(92%, 20 points gain), and actual causality (86% accuracy in determining\nnecessary and sufficient causes in vignettes). At the same time, LLMs exhibit\nunpredictable failure modes and we provide some techniques to interpret their\nrobustness.\n  Crucially, LLMs perform these causal tasks while relying on sources of\nknowledge and methods distinct from and complementary to non-LLM based\napproaches. Specifically, LLMs bring capabilities so far understood to be\nrestricted to humans, such as using collected knowledge to generate causal\ngraphs or identifying background causal context from natural language. We\nenvision LLMs to be used alongside existing causal methods, as a proxy for\nhuman domain knowledge and to reduce human effort in setting up a causal\nanalysis, one of the biggest impediments to the widespread adoption of causal\nmethods. We also see existing causal methods as promising tools for LLMs to\nformalize, validate, and communicate their reasoning especially in high-stakes\nscenarios.\n  In capturing common sense and domain knowledge about causal mechanisms and\nsupporting translation between natural language and formal methods, LLMs open\nnew frontiers for advancing the research, practice, and adoption of causality.\n",
                "链接": "https://arxiv.org/abs/2305.00050"
            }
        ]
    },
    {
        "question": {
            "question": "多模态细粒度图片编辑和生成相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "20765",
                "标题": "M6-Fashion: High-Fidelity Multi-modal Image Generation and Editing",
                "作者": " Zhikang Li,  Huiling Zhou,  Shuai Bai,  Peike Li,  Chang Zhou,  Hongxia Yang",
                "发布日期": "2022-05-25",
                "摘要": "  The fashion industry has diverse applications in multi-modal image generation\nand editing. It aims to create a desired high-fidelity image with the\nmulti-modal conditional signal as guidance. Most existing methods learn\ndifferent condition guidance controls by introducing extra models or ignoring\nthe style prior knowledge, which is difficult to handle multiple signal\ncombinations and faces a low-fidelity problem. In this paper, we adapt both\nstyle prior knowledge and flexibility of multi-modal control into one unified\ntwo-stage framework, M6-Fashion, focusing on the practical AI-aided Fashion\ndesign. It decouples style codes in both spatial and semantic dimensions to\nguarantee high-fidelity image generation in the first stage. M6-Fashion\nutilizes self-correction for the non-autoregressive generation to improve\ninference speed, enhance holistic consistency, and support various signal\ncontrols. Extensive experiments on a large-scale clothing dataset M2C-Fashion\ndemonstrate superior performances on various image generation and editing\ntasks. M6-Fashion model serves as a highly potential AI designer for the\nfashion industry.\n",
                "链接": "https://arxiv.org/abs/2205.11705"
            },
            {
                "文章ID": "73443",
                "标题": "Collaborative Diffusion for Multi-Modal Face Generation and Editing",
                "作者": " Ziqi Huang,  Kelvin C. K. Chan,  Yuming Jiang,  Ziwei Liu",
                "发布日期": "2023-04-21",
                "摘要": "  Diffusion models arise as a powerful generative tool recently. Despite the\ngreat progress, existing diffusion models mainly focus on uni-modal control,\ni.e., the diffusion process is driven by only one modality of condition. To\nfurther unleash the users' creativity, it is desirable for the model to be\ncontrollable by multiple modalities simultaneously, e.g., generating and\nediting faces by describing the age (text-driven) while drawing the face shape\n(mask-driven). In this work, we present Collaborative Diffusion, where\npre-trained uni-modal diffusion models collaborate to achieve multi-modal face\ngeneration and editing without re-training. Our key insight is that diffusion\nmodels driven by different modalities are inherently complementary regarding\nthe latent denoising steps, where bilateral connections can be established\nupon. Specifically, we propose dynamic diffuser, a meta-network that adaptively\nhallucinates multi-modal denoising steps by predicting the spatial-temporal\ninfluence functions for each pre-trained uni-modal model. Collaborative\nDiffusion not only collaborates generation capabilities from uni-modal\ndiffusion models, but also integrates multiple uni-modal manipulations to\nperform multi-modal editing. Extensive qualitative and quantitative experiments\ndemonstrate the superiority of our framework in both image quality and\ncondition consistency.\n",
                "链接": "https://arxiv.org/abs/2304.10530"
            },
            {
                "文章ID": "43616",
                "标题": "CLIP-Driven Fine-grained Text-Image Person Re-identification",
                "作者": " Shuanglin Yan,  Neng Dong,  Liyan Zhang,  Jinhui Tang",
                "发布日期": "2022-10-20",
                "摘要": "  TIReID aims to retrieve the image corresponding to the given text query from\na pool of candidate images. Existing methods employ prior knowledge from\nsingle-modality pre-training to facilitate learning, but lack multi-modal\ncorrespondences. Besides, due to the substantial gap between modalities,\nexisting methods embed the original modal features into the same latent space\nfor cross-modal alignment. However, feature embedding may lead to intra-modal\ninformation distortion. Recently, CLIP has attracted extensive attention from\nresearchers due to its powerful semantic concept learning capacity and rich\nmulti-modal knowledge, which can help us solve the above problems. Accordingly,\nin the paper, we propose a CLIP-driven Fine-grained information excavation\nframework (CFine) to fully utilize the powerful knowledge of CLIP for TIReID.\nTo transfer the multi-modal knowledge effectively, we perform fine-grained\ninformation excavation to mine intra-modal discriminative clues and inter-modal\ncorrespondences. Specifically, we first design a multi-grained global feature\nlearning module to fully mine intra-modal discriminative local information,\nwhich can emphasize identity-related discriminative clues by enhancing the\ninteractions between global image (text) and informative local patches (words).\nSecondly, cross-grained feature refinement (CFR) and fine-grained\ncorrespondence discovery (FCD) modules are proposed to establish the\ncross-grained and fine-grained interactions between modalities, which can\nfilter out non-modality-shared image patches/words and mine cross-modal\ncorrespondences from coarse to fine. CFR and FCD are removed during inference\nto save computational costs. Note that the above process is performed in the\noriginal modality space without further feature embedding. Extensive\nexperiments on multiple benchmarks demonstrate the superior performance of our\nmethod on TIReID.\n",
                "链接": "https://arxiv.org/abs/2210.10276"
            },
            {
                "文章ID": "123145",
                "标题": "M2ConceptBase: A Fine-grained Aligned Multi-modal Conceptual Knowledge\n  Base",
                "作者": " Zhiwei Zha,  Jiaan Wang,  Zhixu Li,  Xiangru Zhu,  Wei Song,  Yanghua Xiao",
                "发布日期": "2023-12-19",
                "摘要": "  Large multi-modal models (LMMs) have demonstrated promising intelligence\nowing to the rapid development of pre-training techniques. However, their\nfine-grained cross-modal alignment ability is constrained by the coarse\nalignment in image-text pairs. This limitation hinders awareness of\nfine-grained concepts, resulting in sub-optimal performance. In this paper, we\npropose a multi-modal conceptual knowledge base, named M2ConceptBase, which\naims to provide fine-grained alignment between images and concepts.\nSpecifically, M2ConceptBase models concepts as nodes, associating each with\nrelevant images and detailed text, thereby enhancing LMMs' cross-modal\nalignment with rich conceptual knowledge. To collect concept-image and\nconcept-description alignments, we propose a context-aware multi-modal symbol\ngrounding approach that considers context information in existing large-scale\nimage-text pairs with respect to each concept. A cutting-edge large language\nmodel supplements descriptions for concepts not grounded via our symbol\ngrounding approach. Finally, our M2ConceptBase contains more than 951K images\nand 152K concepts, each associating with an average of 6.27 images and a single\ndetailed description. We conduct experiments on the OK-VQA task, demonstrating\nthat our M2ConceptBase facilitates the model in achieving state-of-the-art\nperformance. Moreover, we construct a comprehensive benchmark to evaluate the\nconcept understanding of LMMs and show that M2ConceptBase could effectively\nimprove LMMs' concept understanding and cross-modal alignment abilities.\n",
                "链接": "https://arxiv.org/abs/2312.10417"
            },
            {
                "文章ID": "31414",
                "标题": "Paired Cross-Modal Data Augmentation for Fine-Grained Image-to-Text\n  Retrieval",
                "作者": " Hao Wang,  Guosheng Lin,  Steven C. H. Hoi,  Chunyan Miao",
                "发布日期": "2022-08-01",
                "摘要": "  This paper investigates an open research problem of generating text-image\npairs to improve the training of fine-grained image-to-text cross-modal\nretrieval task, and proposes a novel framework for paired data augmentation by\nuncovering the hidden semantic information of StyleGAN2 model. Specifically, we\nfirst train a StyleGAN2 model on the given dataset. We then project the real\nimages back to the latent space of StyleGAN2 to obtain the latent codes. To\nmake the generated images manipulatable, we further introduce a latent space\nalignment module to learn the alignment between StyleGAN2 latent codes and the\ncorresponding textual caption features. When we do online paired data\naugmentation, we first generate augmented text through random token\nreplacement, then pass the augmented text into the latent space alignment\nmodule to output the latent codes, which are finally fed to StyleGAN2 to\ngenerate the augmented images. We evaluate the efficacy of our augmented data\napproach on two public cross-modal retrieval datasets, in which the promising\nexperimental results demonstrate the augmented text-image pair data can be\ntrained together with the original data to boost the image-to-text cross-modal\nretrieval performance.\n",
                "链接": "https://arxiv.org/abs/2207.14428"
            },
            {
                "文章ID": "43683",
                "标题": "Cross-Modal Fusion Distillation for Fine-Grained Sketch-Based Image\n  Retrieval",
                "作者": " Abhra Chaudhuri,  Massimiliano Mancini,  Yanbei Chen,  Zeynep Akata,  Anjan Dutta",
                "发布日期": "2022-10-20",
                "摘要": "  Representation learning for sketch-based image retrieval has mostly been\ntackled by learning embeddings that discard modality-specific information. As\ninstances from different modalities can often provide complementary information\ndescribing the underlying concept, we propose a cross-attention framework for\nVision Transformers (XModalViT) that fuses modality-specific information\ninstead of discarding them. Our framework first maps paired datapoints from the\nindividual photo and sketch modalities to fused representations that unify\ninformation from both modalities. We then decouple the input space of the\naforementioned modality fusion network into independent encoders of the\nindividual modalities via contrastive and relational cross-modal knowledge\ndistillation. Such encoders can then be applied to downstream tasks like\ncross-modal retrieval. We demonstrate the expressive capacity of the learned\nrepresentations by performing a wide range of experiments and achieving\nstate-of-the-art results on three fine-grained sketch-based image retrieval\nbenchmarks: Shoe-V2, Chair-V2 and Sketchy. Implementation is available at\nhttps://github.com/abhrac/xmodal-vit.\n",
                "链接": "https://arxiv.org/abs/2210.10486"
            },
            {
                "文章ID": "13260",
                "标题": "Flexible Portrait Image Editing with Fine-Grained Control",
                "作者": " Linlin Liu,  Qian Fu,  Fei Hou,  Ying He",
                "发布日期": "2022-04-05",
                "摘要": "  We develop a new method for portrait image editing, which supports\nfine-grained editing of geometries, colors, lights and shadows using a single\nneural network model. We adopt a novel asymmetric conditional GAN architecture:\nthe generators take the transformed conditional inputs, such as edge maps,\ncolor palette, sliders and masks, that can be directly edited by the user; the\ndiscriminators take the conditional inputs in the way that can guide\ncontrollable image generation more effectively. Taking color editing as an\nexample, we feed color palettes (which can be edited easily) into the\ngenerator, and color maps (which contain positional information of colors) into\nthe discriminator. We also design a region-weighted discriminator so that\nhigher weights are assigned to more important regions, like eyes and skin.\nUsing a color palette, the user can directly specify the desired colors of\nhair, skin, eyes, lip and background. Color sliders allow the user to blend\ncolors in an intuitive manner. The user can also edit lights and shadows by\nmodifying the corresponding masks. We demonstrate the effectiveness of our\nmethod by evaluating it on the CelebAMask-HQ dataset with a wide range of\ntasks, including geometry/color/shadow/light editing, hand-drawn sketch to\nimage translation, and color transfer. We also present ablation studies to\njustify our design.\n",
                "链接": "https://arxiv.org/abs/2204.01318"
            },
            {
                "文章ID": "15884",
                "标题": "Exploring a Fine-Grained Multiscale Method for Cross-Modal Remote\n  Sensing Image Retrieval",
                "作者": " Zhiqiang Yuan,  Wenkai Zhang,  Kun Fu,  Xuan Li,  Chubo Deng,  Hongqi Wang,  Xian Sun",
                "发布日期": "2022-04-22",
                "摘要": "  Remote sensing (RS) cross-modal text-image retrieval has attracted extensive\nattention for its advantages of flexible input and efficient query. However,\ntraditional methods ignore the characteristics of multi-scale and redundant\ntargets in RS image, leading to the degradation of retrieval accuracy. To cope\nwith the problem of multi-scale scarcity and target redundancy in RS multimodal\nretrieval task, we come up with a novel asymmetric multimodal feature matching\nnetwork (AMFMN). Our model adapts to multi-scale feature inputs, favors\nmulti-source retrieval methods, and can dynamically filter redundant features.\nAMFMN employs the multi-scale visual self-attention (MVSA) module to extract\nthe salient features of RS image and utilizes visual features to guide the text\nrepresentation. Furthermore, to alleviate the positive samples ambiguity caused\nby the strong intraclass similarity in RS image, we propose a triplet loss\nfunction with dynamic variable margin based on prior similarity of sample\npairs. Finally, unlike the traditional RS image-text dataset with coarse text\nand higher intraclass similarity, we construct a fine-grained and more\nchallenging Remote sensing Image-Text Match dataset (RSITMD), which supports RS\nimage retrieval through keywords and sentence separately and jointly.\nExperiments on four RS text-image datasets demonstrate that the proposed model\ncan achieve state-of-the-art performance in cross-modal RS text-image retrieval\ntask.\n",
                "链接": "https://arxiv.org/abs/2204.09868"
            },
            {
                "文章ID": "30841",
                "标题": "Cross-Modal Contrastive Representation Learning for Audio-to-Image\n  Generation",
                "作者": " HaeChun Chung,  JooYong Shim,  Jong-Kook Kim",
                "发布日期": "2022-07-26",
                "摘要": "  Multiple modalities for certain information provide a variety of perspectives\non that information, which can improve the understanding of the information.\nThus, it may be crucial to generate data of different modality from the\nexisting data to enhance the understanding. In this paper, we investigate the\ncross-modal audio-to-image generation problem and propose Cross-Modal\nContrastive Representation Learning (CMCRL) to extract useful features from\naudios and use it in the generation phase. Experimental results show that CMCRL\nenhances quality of images generated than previous research.\n",
                "链接": "https://arxiv.org/abs/2207.12121"
            },
            {
                "文章ID": "73561",
                "标题": "Rethinking Benchmarks for Cross-modal Image-text Retrieval",
                "作者": " Weijing Chen,  Linli Yao,  Qin Jin",
                "发布日期": "2023-04-24",
                "摘要": "  Image-text retrieval, as a fundamental and important branch of information\nretrieval, has attracted extensive research attentions. The main challenge of\nthis task is cross-modal semantic understanding and matching. Some recent works\nfocus more on fine-grained cross-modal semantic matching. With the prevalence\nof large scale multimodal pretraining models, several state-of-the-art models\n(e.g. X-VLM) have achieved near-perfect performance on widely-used image-text\nretrieval benchmarks, i.e. MSCOCO-Test-5K and Flickr30K-Test-1K. In this paper,\nwe review the two common benchmarks and observe that they are insufficient to\nassess the true capability of models on fine-grained cross-modal semantic\nmatching. The reason is that a large amount of images and texts in the\nbenchmarks are coarse-grained. Based on the observation, we renovate the\ncoarse-grained images and texts in the old benchmarks and establish the\nimproved benchmarks called MSCOCO-FG and Flickr30K-FG. Specifically, on the\nimage side, we enlarge the original image pool by adopting more similar images.\nOn the text side, we propose a novel semi-automatic renovation approach to\nrefine coarse-grained sentences into finer-grained ones with little human\neffort. Furthermore, we evaluate representative image-text retrieval models on\nour new benchmarks to demonstrate the effectiveness of our method. We also\nanalyze the capability of models on fine-grained semantic comprehension through\nextensive experiments. The results show that even the state-of-the-art models\nhave much room for improvement in fine-grained semantic understanding,\nespecially in distinguishing attributes of close objects in images. Our code\nand improved benchmark datasets are publicly available at:\nhttps://github.com/cwj1412/MSCOCO-Flikcr30K_FG, which we hope will inspire\nfurther in-depth research on cross-modal retrieval.\n",
                "链接": "https://arxiv.org/abs/2304.10824"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找风格化机器翻译相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "92370",
                "标题": "Incorporating Human Translator Style into English-Turkish Literary\n  Machine Translation",
                "作者": " Zeynep Yirmibeşoğlu,  Olgun Dursun,  Harun Dallı,  Mehmet Şahin,  Ena Hodzik,  Sabri Gürses,  Tunga Güngör",
                "发布日期": "2023-07-24",
                "摘要": "  Although machine translation systems are mostly designed to serve in the\ngeneral domain, there is a growing tendency to adapt these systems to other\ndomains like literary translation. In this paper, we focus on English-Turkish\nliterary translation and develop machine translation models that take into\naccount the stylistic features of translators. We fine-tune a pre-trained\nmachine translation model by the manually-aligned works of a particular\ntranslator. We make a detailed analysis of the effects of manual and automatic\nalignments, data augmentation methods, and corpus size on the translations. We\npropose an approach based on stylistic features to evaluate the style of a\ntranslator in the output translations. We show that the human translator style\ncan be highly recreated in the target machine translations by adapting the\nmodels to the style of the translator.\n",
                "链接": "https://arxiv.org/abs/2307.11457"
            },
            {
                "文章ID": "81274",
                "标题": "RAMP: Retrieval and Attribute-Marking Enhanced Prompting for\n  Attribute-Controlled Translation",
                "作者": " Gabriele Sarti,  Phu Mon Htut,  Xing Niu,  Benjamin Hsu,  Anna Currey,  Georgiana Dinu,  Maria Nadejde",
                "发布日期": "2023-09-08",
                "摘要": "  Attribute-controlled translation (ACT) is a subtask of machine translation\nthat involves controlling stylistic or linguistic attributes (like formality\nand gender) of translation outputs. While ACT has garnered attention in recent\nyears due to its usefulness in real-world applications, progress in the task is\ncurrently limited by dataset availability, since most prior approaches rely on\nsupervised methods. To address this limitation, we propose Retrieval and\nAttribute-Marking enhanced Prompting (RAMP), which leverages large multilingual\nlanguage models to perform ACT in few-shot and zero-shot settings. RAMP\nimproves generation accuracy over the standard prompting approach by (1)\nincorporating a semantic similarity retrieval component for selecting similar\nin-context examples, and (2) marking in-context examples with attribute\nannotations. Our comprehensive experiments show that RAMP is a viable approach\nin both zero-shot and few-shot settings.\n",
                "链接": "https://arxiv.org/abs/2305.17131"
            },
            {
                "文章ID": "45035",
                "标题": "Exploring Document-Level Literary Machine Translation with Parallel\n  Paragraphs from World Literature",
                "作者": " Katherine Thai,  Marzena Karpinska,  Kalpesh Krishna,  Bill Ray,  Moira Inghilleri,  John Wieting,  Mohit Iyyer",
                "发布日期": "2022-10-27",
                "摘要": "  Literary translation is a culturally significant task, but it is bottlenecked\nby the small number of qualified literary translators relative to the many\nuntranslated works published around the world. Machine translation (MT) holds\npotential to complement the work of human translators by improving both\ntraining procedures and their overall efficiency. Literary translation is less\nconstrained than more traditional MT settings since translators must balance\nmeaning equivalence, readability, and critical interpretability in the target\nlanguage. This property, along with the complex discourse-level context present\nin literary texts, also makes literary MT more challenging to computationally\nmodel and evaluate. To explore this task, we collect a dataset (Par3) of\nnon-English language novels in the public domain, each aligned at the paragraph\nlevel to both human and automatic English translations. Using Par3, we discover\nthat expert literary translators prefer reference human translations over\nmachine-translated paragraphs at a rate of 84%, while state-of-the-art\nautomatic MT metrics do not correlate with those preferences. The experts note\nthat MT outputs contain not only mistranslations, but also discourse-disrupting\nerrors and stylistic inconsistencies. To address these problems, we train a\npost-editing model whose output is preferred over normal MT output at a rate of\n69% by experts. We publicly release Par3 at\nhttps://github.com/katherinethai/par3/ to spur future research into literary\nMT.\n",
                "链接": "https://arxiv.org/abs/2210.14250"
            },
            {
                "文章ID": "112746",
                "标题": "Is Robustness Transferable across Languages in Multilingual Neural\n  Machine Translation?",
                "作者": " Leiyu Pan,   Supryadi,  Deyi Xiong",
                "发布日期": "2023-11-01",
                "摘要": "  Robustness, the ability of models to maintain performance in the face of\nperturbations, is critical for developing reliable NLP systems. Recent studies\nhave shown promising results in improving the robustness of models through\nadversarial training and data augmentation. However, in machine translation,\nmost of these studies have focused on bilingual machine translation with a\nsingle translation direction. In this paper, we investigate the transferability\nof robustness across different languages in multilingual neural machine\ntranslation. We propose a robustness transfer analysis protocol and conduct a\nseries of experiments. In particular, we use character-, word-, and multi-level\nnoises to attack the specific translation direction of the multilingual neural\nmachine translation model and evaluate the robustness of other translation\ndirections. Our findings demonstrate that the robustness gained in one\ntranslation direction can indeed transfer to other translation directions.\nAdditionally, we empirically find scenarios where robustness to character-level\nnoise and word-level noise is more likely to transfer.\n",
                "链接": "https://arxiv.org/abs/2310.20162"
            },
            {
                "文章ID": "50351",
                "标题": "Competency-Aware Neural Machine Translation: Can Machine Translation\n  Know its Own Translation Quality?",
                "作者": " Pei Zhang,  Baosong Yang,  Haoran Wei,  Dayiheng Liu,  Kai Fan,  Luo Si,  Jun Xie",
                "发布日期": "2022-11-28",
                "摘要": "  Neural machine translation (NMT) is often criticized for failures that happen\nwithout awareness. The lack of competency awareness makes NMT untrustworthy.\nThis is in sharp contrast to human translators who give feedback or conduct\nfurther investigations whenever they are in doubt about predictions. To fill\nthis gap, we propose a novel competency-aware NMT by extending conventional NMT\nwith a self-estimator, offering abilities to translate a source sentence and\nestimate its competency. The self-estimator encodes the information of the\ndecoding procedure and then examines whether it can reconstruct the original\nsemantics of the source sentence. Experimental results on four translation\ntasks demonstrate that the proposed method not only carries out translation\ntasks intact but also delivers outstanding performance on quality estimation.\nWithout depending on any reference or annotated data typically required by\nstate-of-the-art metric and quality estimation methods, our model yields an\neven higher correlation with human quality judgments than a variety of\naforementioned methods, such as BLEURT, COMET, and BERTScore. Quantitative and\nqualitative analyses show better robustness of competency awareness in our\nmodel.\n",
                "链接": "https://arxiv.org/abs/2211.13865"
            },
            {
                "文章ID": "75582",
                "标题": "Evaluating the Efficacy of Length-Controllable Machine Translation",
                "作者": " Hao Cheng,  Meng Zhang,  Weixuan Wang,  Liangyou Li,  Qun Liu,  Zhihua Zhang",
                "发布日期": "2023-05-04",
                "摘要": "  Length-controllable machine translation is a type of constrained translation.\nIt aims to contain the original meaning as much as possible while controlling\nthe length of the translation. We can use automatic summarization or machine\ntranslation evaluation metrics for length-controllable machine translation, but\nthis is not necessarily suitable and accurate. This work is the first attempt\nto evaluate the automatic metrics for length-controllable machine translation\ntasks systematically. We conduct a rigorous human evaluation on two translation\ndirections and evaluate 18 summarization or translation evaluation metrics. We\nfind that BLEURT and COMET have the highest correlation with human evaluation\nand are most suitable as evaluation metrics for length-controllable machine\ntranslation.\n",
                "链接": "https://arxiv.org/abs/2305.02300"
            },
            {
                "文章ID": "6201",
                "标题": "PETCI: A Parallel English Translation Dataset of Chinese Idioms",
                "作者": "The University of Chicago  Kenan Tang",
                "发布日期": "2022-02-22",
                "摘要": "  Idioms are an important language phenomenon in Chinese, but idiom translation\nis notoriously hard. Current machine translation models perform poorly on idiom\ntranslation, while idioms are sparse in many translation datasets. We present\nPETCI, a parallel English translation dataset of Chinese idioms, aiming to\nimprove idiom translation by both human and machine. The dataset is built by\nleveraging human and machine effort. Baseline generation models show\nunsatisfactory abilities to improve translation, but structure-aware\nclassification models show good performance on distinguishing good\ntranslations. Furthermore, the size of PETCI can be easily increased without\nexpertise. Overall, PETCI can be helpful to language learners and machine\ntranslation systems.\n",
                "链接": "https://arxiv.org/abs/2202.09509"
            },
            {
                "文章ID": "59415",
                "标题": "An Evaluation of Persian-English Machine Translation Datasets with\n  Transformers",
                "作者": " Amir Sartipi,  Meghdad Dehghan,  Afsaneh Fatemi",
                "发布日期": "2023-02-02",
                "摘要": "  Nowadays, many researchers are focusing their attention on the subject of\nmachine translation (MT). However, Persian machine translation has remained\nunexplored despite a vast amount of research being conducted in languages with\nhigh resources, such as English. Moreover, while a substantial amount of\nresearch has been undertaken in statistical machine translation for some\ndatasets in Persian, there is currently no standard baseline for\ntransformer-based text2text models on each corpus. This study collected and\nanalysed the most popular and valuable parallel corpora, which were used for\nPersian-English translation. Furthermore, we fine-tuned and evaluated two\nstate-of-the-art attention-based seq2seq models on each dataset separately (48\nresults). We hope this paper will assist researchers in comparing their Persian\nto English and vice versa machine translation results to a standard baseline.\n",
                "链接": "https://arxiv.org/abs/2302.00321"
            },
            {
                "文章ID": "52440",
                "标题": "Neural Machine Translation with Contrastive Translation Memories",
                "作者": " Xin Cheng,  Shen Gao,  Lemao Liu,  Dongyan Zhao,  Rui Yan",
                "发布日期": "2022-12-07",
                "摘要": "  Retrieval-augmented Neural Machine Translation models have been successful in\nmany translation scenarios. Different from previous works that make use of\nmutually similar but redundant translation memories~(TMs), we propose a new\nretrieval-augmented NMT to model contrastively retrieved translation memories\nthat are holistically similar to the source sentence while individually\ncontrastive to each other providing maximal information gains in three phases.\nFirst, in TM retrieval phase, we adopt a contrastive retrieval algorithm to\navoid redundancy and uninformativeness of similar translation pieces. Second,\nin memory encoding stage, given a set of TMs we propose a novel Hierarchical\nGroup Attention module to gather both local context of each TM and global\ncontext of the whole TM set. Finally, in training phase, a Multi-TM contrastive\nlearning objective is introduced to learn salient feature of each TM with\nrespect to target sentence. Experimental results show that our framework\nobtains improvements over strong baselines on the benchmark datasets.\n",
                "链接": "https://arxiv.org/abs/2212.03140"
            },
            {
                "文章ID": "56953",
                "标题": "Prompting Neural Machine Translation with Translation Memories",
                "作者": " Abudurexiti Reheman,  Tao Zhou,  Yingfeng Luo,  Di Yang,  Tong Xiao,  Jingbo Zhu",
                "发布日期": "2023-02-08",
                "摘要": "  Improving machine translation (MT) systems with translation memories (TMs) is\nof great interest to practitioners in the MT community. However, previous\napproaches require either a significant update of the model architecture and/or\nadditional training efforts to make the models well-behaved when TMs are taken\nas additional input. In this paper, we present a simple but effective method to\nintroduce TMs into neural machine translation (NMT) systems. Specifically, we\ntreat TMs as prompts to the NMT model at test time, but leave the training\nprocess unchanged. The result is a slight update of an existing NMT system,\nwhich can be implemented in a few hours by anyone who is familiar with NMT.\nExperimental results on several datasets demonstrate that our system\nsignificantly outperforms strong baselines.\n",
                "链接": "https://arxiv.org/abs/2301.05380"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下最近用反事实做数据增强的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "86799",
                "标题": "A Novel Counterfactual Data Augmentation Method for Aspect-Based\n  Sentiment Analysis",
                "作者": " Dongming Wu,  Lulu Wen,  Chao Chen,  Zhaoshu Shi",
                "发布日期": "2023-10-10",
                "摘要": "  Aspect-based-sentiment-analysis (ABSA) is a fine-grained sentiment evaluation\ntask, which analyzes the emotional polarity of the evaluation aspects.\nGenerally, the emotional polarity of an aspect exists in the corresponding\nopinion expression, whose diversity has great impact on model's performance. To\nmitigate this problem, we propose a novel and simple counterfactual data\naugmentation method to generate opinion expressions with reversed sentiment\npolarity. In particular, the integrated gradients are calculated to locate and\nmask the opinion expression. Then, a prompt combined with the reverse\nexpression polarity is added to the original text, and a Pre-trained language\nmodel (PLM), T5, is finally was employed to predict the masks. The experimental\nresults shows the proposed counterfactual data augmentation method performs\nbetter than current augmentation methods on three ABSA datasets, i.e. Laptop,\nRestaurant, and MAMS.\n",
                "链接": "https://arxiv.org/abs/2306.11260"
            },
            {
                "文章ID": "110605",
                "标题": "EXPLAIN, EDIT, GENERATE: Rationale-Sensitive Counterfactual Data\n  Augmentation for Multi-hop Fact Verification",
                "作者": " Yingjie Zhu,  Jiasheng Si,  Yibo Zhao,  Haiyang Zhu,  Deyu Zhou,  Yulan He",
                "发布日期": "2023-10-24",
                "摘要": "  Automatic multi-hop fact verification task has gained significant attention\nin recent years. Despite impressive results, these well-designed models perform\npoorly on out-of-domain data. One possible solution is to augment the training\ndata with counterfactuals, which are generated by minimally altering the causal\nfeatures of the original data. However, current counterfactual data\naugmentation techniques fail to handle multi-hop fact verification due to their\nincapability to preserve the complex logical relationships within multiple\ncorrelated texts. In this paper, we overcome this limitation by developing a\nrationale-sensitive method to generate linguistically diverse and\nlabel-flipping counterfactuals while preserving logical relationships. In\nspecific, the diverse and fluent counterfactuals are generated via an\nExplain-Edit-Generate architecture. Moreover, the checking and filtering\nmodules are proposed to regularize the counterfactual data with logical\nrelations and flipped labels. Experimental results show that the proposed\napproach outperforms the SOTA baselines and can generate linguistically diverse\ncounterfactual data without disrupting their logical relationships.\n",
                "链接": "https://arxiv.org/abs/2310.14508"
            },
            {
                "文章ID": "105684",
                "标题": "Target-Aware Contextual Political Bias Detection in News",
                "作者": " Iffat Maab,  Edison Marrese-Taylor,  Yutaka Matsuo",
                "发布日期": "2023-10-03",
                "摘要": "  Media bias detection requires comprehensive integration of information\nderived from multiple news sources. Sentence-level political bias detection in\nnews is no exception, and has proven to be a challenging task that requires an\nunderstanding of bias in consideration of the context. Inspired by the fact\nthat humans exhibit varying degrees of writing styles, resulting in a diverse\nrange of statements with different local and global contexts, previous work in\nmedia bias detection has proposed augmentation techniques to exploit this fact.\nDespite their success, we observe that these techniques introduce noise by\nover-generalizing bias context boundaries, which hinders performance. To\nalleviate this issue, we propose techniques to more carefully search for\ncontext using a bias-sensitive, target-aware approach for data augmentation.\nComprehensive experiments on the well-known BASIL dataset show that when\ncombined with pre-trained models such as BERT, our augmentation techniques lead\nto state-of-the-art results. Our approach outperforms previous methods\nsignificantly, obtaining an F1-score of 58.15 over state-of-the-art bias\ndetection task.\n",
                "链接": "https://arxiv.org/abs/2310.01138"
            },
            {
                "文章ID": "108673",
                "标题": "Automated Claim Matching with Large Language Models: Empowering\n  Fact-Checkers in the Fight Against Misinformation",
                "作者": " Eun Cheol Choi,  Emilio Ferrara",
                "发布日期": "2023-10-16",
                "摘要": "  In today's digital era, the rapid spread of misinformation poses threats to\npublic well-being and societal trust. As online misinformation proliferates,\nmanual verification by fact checkers becomes increasingly challenging. We\nintroduce FACT-GPT (Fact-checking Augmentation with Claim matching\nTask-oriented Generative Pre-trained Transformer), a framework designed to\nautomate the claim matching phase of fact-checking using Large Language Models\n(LLMs). This framework identifies new social media content that either supports\nor contradicts claims previously debunked by fact-checkers. Our approach\nemploys GPT-4 to generate a labeled dataset consisting of simulated social\nmedia posts. This data set serves as a training ground for fine-tuning more\nspecialized LLMs. We evaluated FACT-GPT on an extensive dataset of social media\ncontent related to public health. The results indicate that our fine-tuned LLMs\nrival the performance of larger pre-trained LLMs in claim matching tasks,\naligning closely with human annotations. This study achieves three key\nmilestones: it provides an automated framework for enhanced fact-checking;\ndemonstrates the potential of LLMs to complement human expertise; offers public\nresources, including datasets and models, to further research and applications\nin the fact-checking domain.\n",
                "链接": "https://arxiv.org/abs/2310.09223"
            },
            {
                "文章ID": "39711",
                "标题": "Automatic Data Augmentation via Invariance-Constrained Learning",
                "作者": " Ignacio Hounie,  Luiz F. O. Chamon,  Alejandro Ribeiro",
                "发布日期": "2023-09-19",
                "摘要": "  Underlying data structures, such as symmetries or invariances to\ntransformations, are often exploited to improve the solution of learning tasks.\nHowever, embedding these properties in models or learning algorithms can be\nchallenging and computationally intensive. Data augmentation, on the other\nhand, induces these symmetries during training by applying multiple\ntransformations to the input data. Despite its ubiquity, its effectiveness\ndepends on the choices of which transformations to apply, when to do so, and\nhow often. In fact, there is both empirical and theoretical evidence that the\nindiscriminate use of data augmentation can introduce biases that outweigh its\nbenefits. This work tackles these issues by automatically adapting the data\naugmentation while solving the learning task. To do so, it formulates data\naugmentation as an invariance-constrained learning problem and leverages Monte\nCarlo Markov Chain (MCMC) sampling to solve it. The result is a practical\nalgorithm that not only does away with a priori searches for augmentation\ndistributions, but also dynamically controls if and when data augmentation is\napplied. Our experiments illustrate the performance of this method, which\nachieves state-of-the-art results in automatic data augmentation benchmarks for\nCIFAR datasets. Furthermore, this approach can be used to gather insights on\nthe actual symmetries underlying a learning task.\n",
                "链接": "https://arxiv.org/abs/2209.15031"
            },
            {
                "文章ID": "53753",
                "标题": "Population Template-Based Brain Graph Augmentation for Improving\n  One-Shot Learning Classification",
                "作者": " Oben Özgür,  Arwa Rekik,  Islem Rekik",
                "发布日期": "2022-12-16",
                "摘要": "  The challenges of collecting medical data on neurological disorder diagnosis\nproblems paved the way for learning methods with scarce number of samples. Due\nto this reason, one-shot learning still remains one of the most challenging and\ntrending concepts of deep learning as it proposes to simulate the human-like\nlearning approach in classification problems. Previous studies have focused on\ngenerating more accurate fingerprints of the population using graph neural\nnetworks (GNNs) with connectomic brain graph data. Thereby, generated\npopulation fingerprints named connectional brain template (CBTs) enabled\ndetecting discriminative bio-markers of the population on classification tasks.\nHowever, the reverse problem of data augmentation from single graph data\nrepresenting brain connectivity has never been tackled before. In this paper,\nwe propose an augmentation pipeline in order to provide improved metrics on our\nbinary classification problem. Divergently from the previous studies, we\nexamine augmentation from a single population template by utilizing graph-based\ngenerative adversarial network (gGAN) architecture for a classification\nproblem. We benchmarked our proposed solution on AD/LMCI dataset consisting of\nbrain connectomes with Alzheimer's Disease (AD) and Late Mild Cognitive\nImpairment (LMCI). In order to evaluate our model's generalizability, we used\ncross-validation strategy and randomly sampled the folds multiple times. Our\nresults on classification not only provided better accuracy when augmented data\ngenerated from one sample is introduced, but yields more balanced results on\nother metrics as well.\n",
                "链接": "https://arxiv.org/abs/2212.07790"
            },
            {
                "文章ID": "28152",
                "标题": "Supervised Contrastive Learning Approach for Contextual Ranking",
                "作者": " Abhijit Anand,  Jurek Leonhardt,  Koustav Rudra,  Avishek Anand",
                "发布日期": "2022-07-08",
                "摘要": "  Contextual ranking models have delivered impressive performance improvements\nover classical models in the document ranking task. However, these highly\nover-parameterized models tend to be data-hungry and require large amounts of\ndata even for fine tuning. This paper proposes a simple yet effective method to\nimprove ranking performance on smaller datasets using supervised contrastive\nlearning for the document ranking problem. We perform data augmentation by\ncreating training data using parts of the relevant documents in the\nquery-document pairs. We then use a supervised contrastive learning objective\nto learn an effective ranking model from the augmented dataset. Our experiments\non subsets of the TREC-DL dataset show that, although data augmentation leads\nto an increasing the training data sizes, it does not necessarily improve the\nperformance using existing pointwise or pairwise training objectives. However,\nour proposed supervised contrastive loss objective leads to performance\nimprovements over the standard non-augmented setting showcasing the utility of\ndata augmentation using contrastive losses. Finally, we show the real benefit\nof using supervised contrastive learning objectives by showing marked\nimprovements in smaller ranking datasets relating to news (Robust04), finance\n(FiQA), and scientific fact checking (SciFact).\n",
                "链接": "https://arxiv.org/abs/2207.03153"
            },
            {
                "文章ID": "109089",
                "标题": "Untying the Reversal Curse via Bidirectional Language Model Editing",
                "作者": " Jun-Yu Ma,  Jia-Chen Gu,  Zhen-Hua Ling,  Quan Liu,  Cong Liu",
                "发布日期": "2023-10-17",
                "摘要": "  Recent studies have demonstrated that large language models (LLMs) store\nmassive factual knowledge within their parameters. But existing LLMs are prone\nto hallucinate unintended text due to false or outdated knowledge. Since\nretraining LLMs is resource intensive, there has been a growing interest in the\nconcept of model editing. Despite the emergence of benchmarks and approaches,\nthese unidirectional editing and evaluation have failed to explore the reversal\ncurse. Intuitively, if \"The capital of France is\" is edited to be a counterfact\n\"London\" within a model, then it should be able to naturally reason and recall\nthe reverse fact, i.e., \"London is the capital of\" followed by \"France\" instead\nof \"England\". In this paper, we study bidirectional language model editing,\naiming to provide rigorous model editing evaluation to assess if edited LLMs\ncan recall the editing knowledge bidirectionally. A new evaluation metric of\nreversibility is introduced, and a benchmark dubbed as Bidirectional Assessment\nfor Knowledge Editing (BAKE) is constructed to evaluate the reversibility of\nedited models in recalling knowledge in the reverse direction of editing. We\nsurprisingly observe that while current editing methods and LLMs can\neffectively recall editing facts in the direction of editing, they suffer\nserious deficiencies when evaluated in the reverse direction. To mitigate the\nreversal curse, a method named Bidirectionally Inversible Relationship moDeling\n(BIRD) is proposed. A set of editing objectives that incorporate bidirectional\nrelationships between subject and object into the updated model weights are\ndesigned. Experiments show that BIRD improves the performance of four\nrepresentative LLMs of different sizes via question answering and judgement.\n",
                "链接": "https://arxiv.org/abs/2310.10322"
            },
            {
                "文章ID": "11863",
                "标题": "Reverse Engineering of Imperceptible Adversarial Image Perturbations",
                "作者": " Yifan Gong,  Yuguang Yao,  Yize Li,  Yimeng Zhang,  Xiaoming Liu,  Xue Lin,  Sijia Liu",
                "发布日期": "2022-04-04",
                "摘要": "  It has been well recognized that neural network based image classifiers are\neasily fooled by images with tiny perturbations crafted by an adversary. There\nhas been a vast volume of research to generate and defend such adversarial\nattacks. However, the following problem is left unexplored: How to\nreverse-engineer adversarial perturbations from an adversarial image? This\nleads to a new adversarial learning paradigm--Reverse Engineering of Deceptions\n(RED). If successful, RED allows us to estimate adversarial perturbations and\nrecover the original images. However, carefully crafted, tiny adversarial\nperturbations are difficult to recover by optimizing a unilateral RED\nobjective. For example, the pure image denoising method may overfit to\nminimizing the reconstruction error but hardly preserve the classification\nproperties of the true adversarial perturbations. To tackle this challenge, we\nformalize the RED problem and identify a set of principles crucial to the RED\napproach design. Particularly, we find that prediction alignment and proper\ndata augmentation (in terms of spatial transformations) are two criteria to\nachieve a generalizable RED approach. By integrating these RED principles with\nimage denoising, we propose a new Class-Discriminative Denoising based RED\nframework, termed CDD-RED. Extensive experiments demonstrate the effectiveness\nof CDD-RED under different evaluation metrics (ranging from the pixel-level,\nprediction-level to the attribution-level alignment) and a variety of attack\ngeneration methods (e.g., FGSM, PGD, CW, AutoAttack, and adaptive attacks).\n",
                "链接": "https://arxiv.org/abs/2203.14145"
            },
            {
                "文章ID": "30079",
                "标题": "Revisiting data augmentation for subspace clustering",
                "作者": " Maryam Abdolali,  Nicolas Gillis",
                "发布日期": "2023-01-26",
                "摘要": "  Subspace clustering is the classical problem of clustering a collection of\ndata samples that approximately lie around several low-dimensional subspaces.\nThe current state-of-the-art approaches for this problem are based on the\nself-expressive model which represents the samples as linear combination of\nother samples. However, these approaches require sufficiently well-spread\nsamples for accurate representation which might not be necessarily accessible\nin many applications. In this paper, we shed light on this commonly neglected\nissue and argue that data distribution within each subspace plays a critical\nrole in the success of self-expressive models. Our proposed solution to tackle\nthis issue is motivated by the central role of data augmentation in the\ngeneralization power of deep neural networks. We propose two subspace\nclustering frameworks for both unsupervised and semi-supervised settings that\nuse augmented samples as an enlarged dictionary to improve the quality of the\nself-expressive representation. We present an automatic augmentation strategy\nusing a few labeled samples for the semi-supervised problem relying on the fact\nthat the data samples lie in the union of multiple linear subspaces.\nExperimental results confirm the effectiveness of data augmentation, as it\nsignificantly improves the performance of general self-expressive models.\n",
                "链接": "https://arxiv.org/abs/2207.09728"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用蒙特卡罗树搜索解决序列决策问题的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "54835",
                "标题": "Feature Acquisition using Monte Carlo Tree Search",
                "作者": " Sungsoo Lim,  Diego Klabjan,  Mark Shapiro",
                "发布日期": "2022-12-23",
                "摘要": "  Feature acquisition algorithms address the problem of acquiring informative\nfeatures while balancing the costs of acquisition to improve the learning\nperformances of ML models. Previous approaches have focused on calculating the\nexpected utility values of features to determine the acquisition sequences.\nOther approaches formulated the problem as a Markov Decision Process (MDP) and\napplied reinforcement learning based algorithms. In comparison to previous\napproaches, we focus on 1) formulating the feature acquisition problem as a MDP\nand applying Monte Carlo Tree Search, 2) calculating the intermediary rewards\nfor each acquisition step based on model improvements and acquisition costs and\n3) simultaneously optimizing model improvement and acquisition costs with\nmulti-objective Monte Carlo Tree Search. With Proximal Policy Optimization and\nDeep Q-Network algorithms as benchmark, we show the effectiveness of our\nproposed approach with experimental study.\n",
                "链接": "https://arxiv.org/abs/2212.11360"
            },
            {
                "文章ID": "53055",
                "标题": "Lookahead Pathology in Monte-Carlo Tree Search",
                "作者": " Khoi P. N. Nguyen,  Raghuram Ramanujan",
                "发布日期": "2022-12-13",
                "摘要": "  Monte-Carlo Tree Search (MCTS) is an adversarial search paradigm that first\nfound prominence with its success in the domain of computer Go. Early\ntheoretical work established the game-theoretic soundness and convergence\nbounds for Upper Confidence bounds applied to Trees (UCT), the most popular\ninstantiation of MCTS; however, there remain notable gaps in our understanding\nof how UCT behaves in practice. In this work, we address one such gap by\nconsidering the question of whether UCT can exhibit lookahead pathology -- a\nparadoxical phenomenon first observed in Minimax search where greater search\neffort leads to worse decision-making. We introduce a novel family of synthetic\ngames that offer rich modeling possibilities while remaining amenable to\nmathematical analysis. Our theoretical and experimental results suggest that\nUCT is indeed susceptible to pathological behavior in a range of games drawn\nfrom this family.\n",
                "链接": "https://arxiv.org/abs/2212.05208"
            },
            {
                "文章ID": "67092",
                "标题": "Proof Number Based Monte-Carlo Tree Search",
                "作者": " Jakub Kowalski,  Elliot Doe,  Mark H. M. Winands,  Daniel Górski,  Dennis J. N. J. Soemers",
                "发布日期": "2023-12-22",
                "摘要": "  This paper proposes a new game-search algorithm, PN-MCTS, which combines\nMonte-Carlo Tree Search (MCTS) and Proof-Number Search (PNS). These two\nalgorithms have been successfully applied for decision making in a range of\ndomains. We define three areas where the additional knowledge provided by the\nproof and disproof numbers gathered in MCTS trees might be used: final move\nselection, solving subtrees, and the UCB1 selection mechanism. We test all\npossible combinations on different time settings, playing against vanilla UCT\non several games: Lines of Action ($7$$\\times$$7$ and $8$$\\times$$8$ board\nsizes), MiniShogi, Knightthrough, and Awari. Furthermore, we extend this new\nalgorithm to properly address games with draws, like Awari, by adding an\nadditional layer of PNS on top of the MCTS tree. The experiments show that\nPN-MCTS confidently outperforms MCTS in all tested game domains, achieving win\nrates up to 96.2\\% for Lines of Action.\n",
                "链接": "https://arxiv.org/abs/2303.09449"
            },
            {
                "文章ID": "23592",
                "标题": "Combining Monte-Carlo Tree Search with Proof-Number Search",
                "作者": " Elliot Doe,  Mark H. M. Winands,  Dennis J. N. J. Soemers,  Cameron Browne",
                "发布日期": "2022-06-09",
                "摘要": "  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
                "链接": "https://arxiv.org/abs/2206.03965"
            },
            {
                "文章ID": "102301",
                "标题": "Maneuver Decision-Making Through Proximal Policy Optimization And Monte\n  Carlo Tree Search",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-09-19",
                "摘要": "  Maneuver decision-making can be regarded as a Markov decision process and can\nbe address by reinforcement learning. However, original reinforcement learning\nalgorithms can hardly solve the maneuvering decision-making problem. One reason\nis that agents use random actions in the early stages of training, which makes\nit difficult to get rewards and learn how to make effective decisions. To\naddress this issue, a method based on proximal policy optimization and Monte\nCarlo tree search is proposed. The method uses proximal policy optimization to\ntrain the agent, and regards the results of air combat as targets to train the\nvalue network. Then, based on the value network and the visit count of each\nnode, Monte Carlo tree search is used to find the actions with more expected\nreturns than random actions, which can improve the training performance. The\nablation studies and simulation experiments indicate that agents trained by the\nproposed method can make different decisions according to different states,\nwhich demonstrates that the method can solve the maneuvering decision problem\nthat the original reinforcement learning algorithm cannot solve.\n",
                "链接": "https://arxiv.org/abs/2309.08611"
            },
            {
                "文章ID": "107708",
                "标题": "Accelerating Monte Carlo Tree Search with Probability Tree State\n  Abstraction",
                "作者": " Yangqing Fu,  Ming Sun,  Buqing Nie,  Yue Gao",
                "发布日期": "2023-10-11",
                "摘要": "  Monte Carlo Tree Search (MCTS) algorithms such as AlphaGo and MuZero have\nachieved superhuman performance in many challenging tasks. However, the\ncomputational complexity of MCTS-based algorithms is influenced by the size of\nthe search space. To address this issue, we propose a novel probability tree\nstate abstraction (PTSA) algorithm to improve the search efficiency of MCTS. A\ngeneral tree state abstraction with path transitivity is defined. In addition,\nthe probability tree state abstraction is proposed for fewer mistakes during\nthe aggregation step. Furthermore, the theoretical guarantees of the\ntransitivity and aggregation error bound are justified. To evaluate the\neffectiveness of the PTSA algorithm, we integrate it with state-of-the-art\nMCTS-based algorithms, such as Sampled MuZero and Gumbel MuZero. Experimental\nresults on different tasks demonstrate that our method can accelerate the\ntraining process of state-of-the-art algorithms with 10%-45% search space\nreduction.\n",
                "链接": "https://arxiv.org/abs/2310.06513"
            },
            {
                "文章ID": "80845",
                "标题": "C-MCTS: Safe Planning with Monte Carlo Tree Search",
                "作者": " Dinesh Parthasarathy,  Georgios Kontes,  Axel Plinge,  Christopher Mutschler",
                "发布日期": "2023-10-03",
                "摘要": "  The Constrained Markov Decision Process (CMDP) formulation allows to solve\nsafety-critical decision making tasks that are subject to constraints. While\nCMDPs have been extensively studied in the Reinforcement Learning literature,\nlittle attention has been given to sampling-based planning algorithms such as\nMCTS for solving them. Previous approaches perform conservatively with respect\nto costs as they avoid constraint violations by using Monte Carlo cost\nestimates that suffer from high variance. We propose Constrained MCTS (C-MCTS),\nwhich estimates cost using a safety critic that is trained with Temporal\nDifference learning in an offline phase prior to agent deployment. The critic\nlimits exploration by pruning unsafe trajectories within MCTS during\ndeployment. C-MCTS satisfies cost constraints but operates closer to the\nconstraint boundary, achieving higher rewards than previous work. As a nice\nbyproduct, the planner is more efficient w.r.t. planning steps. Most\nimportantly, under model mismatch between the planner and the real world,\nC-MCTS is less susceptible to cost violations than previous work.\n",
                "链接": "https://arxiv.org/abs/2305.16209"
            },
            {
                "文章ID": "7216",
                "标题": "Decision Making in Non-Stationary Environments with Policy-Augmented\n  Monte Carlo Tree Search",
                "作者": " Geoffrey Pettet,  Ayan Mukhopadhyay,  Abhishek Dubey",
                "发布日期": "2022-03-01",
                "摘要": "  Decision-making under uncertainty (DMU) is present in many important\nproblems. An open challenge is DMU in non-stationary environments, where the\ndynamics of the environment can change over time. Reinforcement Learning (RL),\na popular approach for DMU problems, learns a policy by interacting with a\nmodel of the environment offline. Unfortunately, if the environment changes the\npolicy can become stale and take sub-optimal actions, and relearning the policy\nfor the updated environment takes time and computational effort. An alternative\nis online planning approaches such as Monte Carlo Tree Search (MCTS), which\nperform their computation at decision time. Given the current environment, MCTS\nplans using high-fidelity models to determine promising action trajectories.\nThese models can be updated as soon as environmental changes are detected to\nimmediately incorporate them into decision making. However, MCTS's convergence\ncan be slow for domains with large state-action spaces. In this paper, we\npresent a novel hybrid decision-making approach that combines the strengths of\nRL and planning while mitigating their weaknesses. Our approach, called Policy\nAugmented MCTS (PA-MCTS), integrates a policy's actin-value estimates into\nMCTS, using the estimates to seed the action trajectories favored by the\nsearch. We hypothesize that PA-MCTS will converge more quickly than standard\nMCTS while making better decisions than the policy can make on its own when\nfaced with nonstationary environments. We test our hypothesis by comparing\nPA-MCTS with pure MCTS and an RL agent applied to the classical CartPole\nenvironment. We find that PC-MCTS can achieve higher cumulative rewards than\nthe policy in isolation under several environmental shifts while converging in\nsignificantly fewer iterations than pure MCTS.\n",
                "链接": "https://arxiv.org/abs/2202.13003"
            },
            {
                "文章ID": "22592",
                "标题": "Policy Gradient Algorithms with Monte-Carlo Tree Search for Non-Markov\n  Decision Processes",
                "作者": " Tetsuro Morimura,  Kazuhiro Ota,  Kenshi Abe,  Peinan Zhang",
                "发布日期": "2022-06-03",
                "摘要": "  Policy gradient (PG) is a reinforcement learning (RL) approach that optimizes\na parameterized policy model for an expected return using gradient ascent.\nGiven a well-parameterized policy model, such as a neural network model, with\nappropriate initial parameters, the PG algorithms work well even when\nenvironment does not have the Markov property. Otherwise, they can be trapped\non a plateau or suffer from peakiness effects. As another successful RL\napproach, algorithms based on Monte-Carlo Tree Search (MCTS), which include\nAlphaZero, have obtained groundbreaking results especially on the board game\nplaying domain. They are also suitable to be applied to non-Markov decision\nprocesses. However, since the standard MCTS does not have the ability to learn\nstate representation, the size of the tree-search space can be too large to\nsearch. In this work, we examine a mixture policy of PG and MCTS to complement\neach other's difficulties and take advantage of them. We derive conditions for\nasymptotic convergence with results of a two-timescale stochastic approximation\nand propose an algorithm that satisfies these conditions. The effectivity of\nthe proposed methods is verified through numerical experiments on non-Markov\ndecision processes.\n",
                "链接": "https://arxiv.org/abs/2206.01011"
            },
            {
                "文章ID": "59436",
                "标题": "Alphazzle: Jigsaw Puzzle Solver with Deep Monte-Carlo Tree Search",
                "作者": " Marie-Morgane Paumard,  Hedi Tabia,  David Picard",
                "发布日期": "2023-02-02",
                "摘要": "  Solving jigsaw puzzles requires to grasp the visual features of a sequence of\npatches and to explore efficiently a solution space that grows exponentially\nwith the sequence length. Therefore, visual deep reinforcement learning (DRL)\nshould answer this problem more efficiently than optimization solvers coupled\nwith neural networks. Based on this assumption, we introduce Alphazzle, a\nreassembly algorithm based on single-player Monte Carlo Tree Search (MCTS). A\nmajor difference with DRL algorithms lies in the unavailability of game reward\nfor MCTS, and we show how to estimate it from the visual input with neural\nnetworks. This constraint is induced by the puzzle-solving task and\ndramatically adds to the task complexity (and interest!). We perform an in-deep\nablation study that shows the importance of MCTS and the neural networks\nworking together. We achieve excellent results and get exciting insights into\nthe combination of DRL and visual feature learning.\n",
                "链接": "https://arxiv.org/abs/2302.00384"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用gpt4做评测指标优缺点的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "116110",
                "标题": "Enhancing Medical Text Evaluation with GPT-4",
                "作者": " Yiqing Xie,  Sheng Zhang,  Hao Cheng,  Zelalem Gero,  Cliff Wong,  Tristan Naumann,  Hoifung Poon",
                "发布日期": "2023-11-17",
                "摘要": "  In the evaluation of medical text generation, it is essential to scrutinize\neach piece of information and ensure the utmost accuracy of the evaluation.\nExisting evaluation metrics either focus on coarse-level evaluation that\nassigns one score for the whole generated output or rely on evaluation models\ntrained on general domain, resulting in inaccuracies when adapted to the\nmedical domain. To address these issues, we propose a set of factuality-centric\nevaluation aspects and design corresponding GPT-4-based metrics for medical\ntext generation. We systematically compare these metrics with existing ones on\nclinical note generation and medical report summarization tasks, revealing low\ninter-metric correlation. A comprehensive human evaluation confirms that the\nproposed GPT-4-based metrics exhibit substantially higher agreement with human\njudgments than existing evaluation metrics. Our study contributes to the\nunderstanding of medical text generation evaluation and offers a more reliable\nalternative to existing metrics.\n",
                "链接": "https://arxiv.org/abs/2311.09581"
            },
            {
                "文章ID": "66852",
                "标题": "GPT-4 Technical Report",
                "作者": "Rai   OpenAI, Rai   :, Rai  Josh Achiam, Rai  Steven Adler, Rai  Sandhini Agarwal, Rai  Lama Ahmad, Rai  Ilge Akkaya, Rai  Florencia Leoni Aleman, Rai  Diogo Almeida, Rai  Janko Altenschmidt, Rai  Sam Altman, Rai  Shyamal Anadkat, Rai  Red Avila, Rai  Igor Babuschkin, Rai  Suchir Balaji, Rai  Valerie Balcom, Rai  Paul Baltescu, Rai  Haiming Bao, Rai  Mo Bavarian, Rai  Jeff Belgum, Rai  Irwan Bello, Rai  Jake Berdine, Rai  Gabriel Bernadett-Shapiro, Rai  Christopher Berner, Rai  Lenny Bogdonoff, Rai  Oleg Boiko, Rai  Madelaine Boyd, Rai  Anna-Luisa Brakman, Rai  Greg Brockman, Rai  Tim Brooks, Rai  Miles Brundage, Rai  Kevin Button, Rai  Trevor Cai, Rai  Rosie Campbell, Rai  Andrew Cann, Rai  Brittany Carey, Rai  Chelsea Carlson, Rai  Rory Carmichael, Rai  Brooke Chan, Rai  Che Chang, Rai  Fotis Chantzis, Rai  Derek Chen, Rai  Sully Chen, Rai  Ruby Chen, Rai  Jason Chen, Rai  Mark Chen, Rai  Ben Chess, Rai  Chester Cho, Rai  Casey Chu, Rai  Hyung Won Chung, Rai  Dave Cummings, Rai  Jeremiah Currier, Rai  Yunxing Dai, Rai  Cory Decareaux, Rai  Thomas Degry, Rai  Noah Deutsch, Rai  Damien Deville, Rai  Arka Dhar, Rai  David Dohan, Rai  Steve Dowling, Rai  Sheila Dunning, Rai  Adrien Ecoffet, Rai  Atty Eleti, Rai  Tyna Eloundou, Rai  David Farhi, Rai  Liam Fedus, Rai  Niko Felix, Rai  Simón Posada Fishman, Rai  Juston Forte, Rai  Isabella Fulford, Rai  Leo Gao, Rai  Elie Georges, Rai  Christian Gibson, Rai  Vik Goel, Rai  Tarun Gogineni, Rai  Gabriel Goh, Rai  Rapha Gontijo-Lopes, Rai  Jonathan Gordon, Rai  Morgan Grafstein, Rai  Scott Gray, Rai  Ryan Greene, Rai  Joshua Gross, Rai  Shixiang Shane Gu, Rai  Yufei Guo, Rai  Chris Hallacy, Rai  Jesse Han, Rai  Jeff Harris, Rai  Yuchen He, Rai  Mike Heaton, Rai  Johannes Heidecke, Rai  Chris Hesse, Rai  Alan Hickey, Rai  Wade Hickey, Rai  Peter Hoeschele, Rai  Brandon Houghton, Rai  Kenny Hsu, Rai  Shengli Hu, Rai  Xin Hu, Rai  Joost Huizinga, Rai  Shantanu Jain, Rai  Shawn Jain, Rai  Joanne Jang, Rai  Angela Jiang, Rai  Roger Jiang, Rai  Haozhun Jin, Rai  Denny Jin, Rai  Shino Jomoto, Rai  Billie Jonn, Rai  Heewoo Jun, Rai  Tomer Kaftan, Rai  Łukasz Kaiser, Rai  Ali Kamali, Rai  Ingmar Kanitscheider, Rai  Nitish Shirish Keskar, Rai  Tabarak Khan, Rai  Logan Kilpatrick, Rai  Jong Wook Kim, Rai  Christina Kim, Rai  Yongjik Kim, Rai  Hendrik Kirchner, Rai  Jamie Kiros, Rai  Matt Knight, Rai  Daniel Kokotajlo, Rai  Łukasz Kondraciuk, Rai  Andrew Kondrich, Rai  Aris Konstantinidis, Rai  Kyle Kosic, Rai  Gretchen Krueger, Rai  Vishal Kuo, Rai  Michael Lampe, Rai  Ikai Lan, Rai  Teddy Lee, Rai  Jan Leike, Rai  Jade Leung, Rai  Daniel Levy, Rai  Chak Ming Li, Rai  Rachel Lim, Rai  Molly Lin, Rai  Stephanie Lin, Rai  Mateusz Litwin, Rai  Theresa Lopez, Rai  Ryan Lowe, Rai  Patricia Lue, Rai  Anna Makanju, Rai  Kim Malfacini, Rai  Sam Manning, Rai  Todor Markov, Rai  Yaniv Markovski, Rai  Bianca Martin, Rai  Katie Mayer, Rai  Andrew Mayne, Rai  Bob McGrew, Rai  Scott Mayer McKinney, Rai  Christine McLeavey, Rai  Paul McMillan, Rai  Jake McNeil, Rai  David Medina, Rai  Aalok Mehta, Rai  Jacob Menick, Rai  Luke Metz, Rai  Andrey Mishchenko, Rai  Pamela Mishkin, Rai  Vinnie Monaco, Rai  Evan Morikawa, Rai  Daniel Mossing, Rai  Tong Mu, Rai  Mira Murati, Rai  Oleg Murk, Rai  David Mély, Rai  Ashvin Nair, Rai  Reiichiro Nakano, Rai  Rajeev Nayak, Rai  Arvind Neelakantan, Rai  Richard Ngo, Rai  Hyeonwoo Noh, Rai  Long Ouyang, Rai  Cullen O'Keefe, Rai  Jakub Pachocki, Rai  Alex Paino, Rai  Joe Palermo, Rai  Ashley Pantuliano, Rai  Giambattista Parascandolo, Rai  Joel Parish, Rai  Emy Parparita, Rai  Alex Passos, Rai  Mikhail Pavlov, Rai  Andrew Peng, Rai  Adam Perelman, Rai  Filipe de Avila Belbute Peres, Rai  Michael Petrov, Rai  Henrique Ponde de Oliveira Pinto, Rai   Michael,   Pokorny,  Michelle Pokrass,  Vitchyr Pong,  Tolly Powell,  Alethea Power,  Boris Power,  Elizabeth Proehl,  Raul Puri,  Alec Radford,  Jack Rae,  Aditya Ramesh,  Cameron Raymond,  Francis Real,  Kendra Rimbach,  Carl Ross,  Bob Rotsted,  Henri Roussez,  Nick Ryder,  Mario Saltarelli,  Ted Sanders,  Shibani Santurkar,  Girish Sastry,  Heather Schmidt,  David Schnurr,  John Schulman,  Daniel Selsam,  Kyla Sheppard,  Toki Sherbakov,  Jessica Shieh,  Sarah Shoker,  Pranav Shyam,  Szymon Sidor,  Eric Sigler,  Maddie Simens,  Jordan Sitkin,  Katarina Slama,  Ian Sohl,  Benjamin Sokolowsky,  Yang Song,  Natalie Staudacher,  Felipe Petroski Such,  Natalie Summers,  Ilya Sutskever,  Jie Tang,  Nikolas Tezak,  Madeleine Thompson,  Phil Tillet,  Amin Tootoonchian,  Elizabeth Tseng,  Preston Tuggle,  Nick Turley,  Jerry Tworek,  Juan Felipe Cerón Uribe,  Andrea Vallone,  Arun Vijayvergiya,  Chelsea Voss,  Carroll Wainwright,  Justin Jay Wang,  Alvin Wang,  Ben Wang,  Jonathan Ward,  Jason Wei,  CJ Weinmann,  Akila Welihinda,  Peter Welinder,  Jiayi Weng,  Lilian Weng,  Matt Wiethoff,  Dave Willner,  Clemens Winter,  Samuel Wolrich,  Hannah Wong,  Lauren Workman,  Sherwin Wu,  Jeff Wu,  Michael Wu,  Kai Xiao,  Tao Xu,  Sarah Yoo,  Kevin Yu,  Qiming Yuan,  Wojciech Zaremba,  Rowan Zellers,  Chong Zhang,  Marvin Zhang,  Shengjia Zhao,  Tianhao Zheng,  Juntang Zhuang,  William Zhuk,  Barret Zoph",
                "发布日期": "2023-12-20",
                "摘要": "  We report the development of GPT-4, a large-scale, multimodal model which can\naccept image and text inputs and produce text outputs. While less capable than\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance on\nvarious professional and academic benchmarks, including passing a simulated bar\nexam with a score around the top 10% of test takers. GPT-4 is a\nTransformer-based model pre-trained to predict the next token in a document.\nThe post-training alignment process results in improved performance on measures\nof factuality and adherence to desired behavior. A core component of this\nproject was developing infrastructure and optimization methods that behave\npredictably across a wide range of scales. This allowed us to accurately\npredict some aspects of GPT-4's performance based on models trained with no\nmore than 1/1,000th the compute of GPT-4.\n",
                "链接": "https://arxiv.org/abs/2303.08774"
            },
            {
                "文章ID": "95177",
                "标题": "GPT-4 Can't Reason",
                "作者": " Konstantine Arkoudas",
                "发布日期": "2023-08-11",
                "摘要": "  GPT-4 was released in March 2023 to wide acclaim, marking a very substantial\nimprovement across the board over GPT-3.5 (OpenAI's previously best model,\nwhich had powered the initial release of ChatGPT). However, despite the\ngenuinely impressive improvement, there are good reasons to be highly skeptical\nof GPT-4's ability to reason. This position paper discusses the nature of\nreasoning; criticizes the current formulation of reasoning problems in the NLP\ncommunity, as well as the way in which LLM reasoning performance is currently\nevaluated; introduces a small collection of 21 diverse reasoning problems; and\nperforms a detailed qualitative evaluation of GPT-4's performance on those\nproblems. Based on this analysis, the paper concludes that, despite its\noccasional flashes of analytical brilliance, GPT-4 at present is utterly\nincapable of reasoning.\n",
                "链接": "https://arxiv.org/abs/2308.03762"
            },
            {
                "文章ID": "94757",
                "标题": "Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings",
                "作者": " Veronika Hackl,  Alexandra Elena Müller,  Michael Granitzer,  Maximilian Sailer",
                "发布日期": "2023-08-08",
                "摘要": "  This study investigates the consistency of feedback ratings generated by\nOpenAI's GPT-4, a state-of-the-art artificial intelligence language model,\nacross multiple iterations, time spans and stylistic variations. The model\nrated responses to tasks within the Higher Education (HE) subject domain of\nmacroeconomics in terms of their content and style. Statistical analysis was\nconducted in order to learn more about the interrater reliability, consistency\nof the ratings across iterations and the correlation between ratings in terms\nof content and style. The results revealed a high interrater reliability with\nICC scores ranging between 0.94 and 0.99 for different timespans, suggesting\nthat GPT-4 is capable of generating consistent ratings across repetitions with\na clear prompt. Style and content ratings show a high correlation of 0.87. When\napplying a non-adequate style the average content ratings remained constant,\nwhile style ratings decreased, which indicates that the large language model\n(LLM) effectively distinguishes between these two criteria during evaluation.\nThe prompt used in this study is furthermore presented and explained. Further\nresearch is necessary to assess the robustness and reliability of AI models in\nvarious use cases.\n",
                "链接": "https://arxiv.org/abs/2308.02575"
            },
            {
                "文章ID": "110350",
                "标题": "Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large\n  Language Models on Sequence to Sequence Tasks",
                "作者": " Andrea Sottana,  Bin Liang,  Kai Zou,  Zheng Yuan",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) evaluation is a patchy and inconsistent\nlandscape, and it is becoming clear that the quality of automatic evaluation\nmetrics is not keeping up with the pace of development of generative models. We\naim to improve the understanding of current models' performance by providing a\npreliminary and hybrid evaluation on a range of open and closed-source\ngenerative LLMs on three NLP benchmarks: text summarisation, text\nsimplification and grammatical error correction (GEC), using both automatic and\nhuman evaluation. We also explore the potential of the recently released GPT-4\nto act as an evaluator. We find that ChatGPT consistently outperforms many\nother popular models according to human reviewers on the majority of metrics,\nwhile scoring much more poorly when using classic automatic evaluation metrics.\nWe also find that human reviewers rate the gold reference as much worse than\nthe best models' outputs, indicating the poor quality of many popular\nbenchmarks. Finally, we find that GPT-4 is capable of ranking models' outputs\nin a way which aligns reasonably closely to human judgement despite\ntask-specific variations, with a lower alignment in the GEC task.\n",
                "链接": "https://arxiv.org/abs/2310.13800"
            },
            {
                "文章ID": "71129",
                "标题": "Instruction Tuning with GPT-4",
                "作者": " Baolin Peng,  Chunyuan Li,  Pengcheng He,  Michel Galley,  Jianfeng Gao",
                "发布日期": "2023-04-07",
                "摘要": "  Prior work has shown that finetuning large language models (LLMs) using\nmachine-generated instruction-following data enables such models to achieve\nremarkable zero-shot capabilities on new tasks, and no human-written\ninstructions are needed. In this paper, we present the first attempt to use\nGPT-4 to generate instruction-following data for LLM finetuning. Our early\nexperiments on instruction-tuned LLaMA models show that the 52K English and\nChinese instruction-following data generated by GPT-4 leads to superior\nzero-shot performance on new tasks to the instruction-following data generated\nby previous state-of-the-art models. We also collect feedback and comparison\ndata from GPT-4 to enable a comprehensive evaluation and reward model training.\nWe make our data generated using GPT-4 as well as our codebase publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2304.03277"
            },
            {
                "文章ID": "124407",
                "标题": "Exploiting Novel GPT-4 APIs",
                "作者": " Kellin Pelrine,  Mohammad Taufeeque,  Michał Zając,  Euan McLean,  Adam Gleave",
                "发布日期": "2023-12-25",
                "摘要": "  Language model attacks typically assume one of two extreme threat models:\nfull white-box access to model weights, or black-box access limited to a text\ngeneration API. However, real-world APIs are often more flexible than just text\ngeneration: these APIs expose ``gray-box'' access leading to new threat\nvectors. To explore this, we red-team three new functionalities exposed in the\nGPT-4 APIs: fine-tuning, function calling and knowledge retrieval. We find that\nfine-tuning a model on as few as 15 harmful examples or 100 benign examples can\nremove core safeguards from GPT-4, enabling a range of harmful outputs.\nFurthermore, we find that GPT-4 Assistants readily divulge the function call\nschema and can be made to execute arbitrary function calls. Finally, we find\nthat knowledge retrieval can be hijacked by injecting instructions into\nretrieval documents. These vulnerabilities highlight that any additions to the\nfunctionality exposed by an API can create new vulnerabilities.\n",
                "链接": "https://arxiv.org/abs/2312.14302"
            },
            {
                "文章ID": "102940",
                "标题": "An Evaluation of GPT-4 on the ETHICS Dataset",
                "作者": " Sergey Rodionov,  Zarathustra Amadeus Goertzel,  Ben Goertzel",
                "发布日期": "2023-09-20",
                "摘要": "  This report summarizes a short study of the performance of GPT-4 on the\nETHICS dataset. The ETHICS dataset consists of five sub-datasets covering\ndifferent fields of ethics: Justice, Deontology, Virtue Ethics, Utilitarianism,\nand Commonsense Ethics. The moral judgments were curated so as to have a high\ndegree of agreement with the aim of representing shared human values rather\nthan moral dilemmas. GPT-4's performance is much better than that of previous\nmodels and suggests that learning to work with common human values is not the\nhard problem for AI ethics.\n",
                "链接": "https://arxiv.org/abs/2309.10492"
            },
            {
                "文章ID": "106172",
                "标题": "Low-Resource Languages Jailbreak GPT-4",
                "作者": " Zheng-Xin Yong,  Cristina Menghini,  Stephen H. Bach",
                "发布日期": "2023-10-05",
                "摘要": "  AI safety training and red-teaming of large language models (LLMs) are\nmeasures to mitigate the generation of unsafe content. Our work exposes the\ninherent cross-lingual vulnerability of these safety mechanisms, resulting from\nthe linguistic inequality of safety training data, by successfully\ncircumventing GPT-4's safeguard through translating unsafe English inputs into\nlow-resource languages. On the AdvBenchmark, GPT-4 engages with the unsafe\ntranslated inputs and provides actionable items that can get the users towards\ntheir harmful goals 79% of the time, which is on par with or even surpassing\nstate-of-the-art jailbreaking attacks. Other high-/mid-resource languages have\nsignificantly lower attack success rate, which suggests that the cross-lingual\nvulnerability mainly applies to low-resource languages. Previously, limited\ntraining on low-resource languages primarily affects speakers of those\nlanguages, causing technological disparities. However, our work highlights a\ncrucial shift: this deficiency now poses a risk to all LLMs users. Publicly\navailable translation APIs enable anyone to exploit LLMs' safety\nvulnerabilities. Therefore, our work calls for a more holistic red-teaming\nefforts to develop robust multilingual safeguards with wide language coverage.\n",
                "链接": "https://arxiv.org/abs/2310.02446"
            },
            {
                "文章ID": "73599",
                "标题": "Can GPT-4 Perform Neural Architecture Search?",
                "作者": " Mingkai Zheng,  Xiu Su,  Shan You,  Fei Wang,  Chen Qian,  Chang Xu,  Samuel Albanie",
                "发布日期": "2023-08-03",
                "摘要": "  We investigate the potential of GPT-4~\\cite{gpt4} to perform Neural\nArchitecture Search (NAS) -- the task of designing effective neural\narchitectures. Our proposed approach, \\textbf{G}PT-4 \\textbf{E}nhanced\n\\textbf{N}eural arch\\textbf{I}tect\\textbf{U}re \\textbf{S}earch (GENIUS),\nleverages the generative capabilities of GPT-4 as a black-box optimiser to\nquickly navigate the architecture search space, pinpoint promising candidates,\nand iteratively refine these candidates to improve performance. We assess\nGENIUS across several benchmarks, comparing it with existing state-of-the-art\nNAS techniques to illustrate its effectiveness. Rather than targeting\nstate-of-the-art performance, our objective is to highlight GPT-4's potential\nto assist research on a challenging technical problem through a simple\nprompting scheme that requires relatively limited domain\nexpertise\\footnote{Code available at\n\\href{https://github.com/mingkai-zheng/GENIUS}{https://github.com/mingkai-zheng/GENIUS}.}.\nMore broadly, we believe our preliminary results point to future research that\nharnesses general purpose language models for diverse optimisation tasks. We\nalso highlight important limitations to our study, and note implications for AI\nsafety.\n",
                "链接": "https://arxiv.org/abs/2304.10970"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用GPT4v完成多模态智能体的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "46784",
                "标题": "Scalable Multi-Agent Reinforcement Learning through Intelligent\n  Information Aggregation",
                "作者": " Siddharth Nayak,  Kenneth Choi,  Wenqi Ding,  Sydney Dolan,  Karthik Gopalakrishnan,  Hamsa Balakrishnan",
                "发布日期": "2023-05-17",
                "摘要": "  We consider the problem of multi-agent navigation and collision avoidance\nwhen observations are limited to the local neighborhood of each agent. We\npropose InforMARL, a novel architecture for multi-agent reinforcement learning\n(MARL) which uses local information intelligently to compute paths for all the\nagents in a decentralized manner. Specifically, InforMARL aggregates\ninformation about the local neighborhood of agents for both the actor and the\ncritic using a graph neural network and can be used in conjunction with any\nstandard MARL algorithm. We show that (1) in training, InforMARL has better\nsample efficiency and performance than baseline approaches, despite using less\ninformation, and (2) in testing, it scales well to environments with arbitrary\nnumbers of agents and obstacles. We illustrate these results using four task\nenvironments, including one with predetermined goals for each agent, and one in\nwhich the agents collectively try to cover all goals. Code available at\nhttps://github.com/nsidn98/InforMARL.\n",
                "链接": "https://arxiv.org/abs/2211.02127"
            },
            {
                "文章ID": "103042",
                "标题": "Guide Your Agent with Adaptive Multimodal Rewards",
                "作者": " Changyeon Kim,  Younggyo Seo,  Hao Liu,  Lisa Lee,  Jinwoo Shin,  Honglak Lee,  Kimin Lee",
                "发布日期": "2023-10-26",
                "摘要": "  Developing an agent capable of adapting to unseen environments remains a\ndifficult challenge in imitation learning. This work presents Adaptive\nReturn-conditioned Policy (ARP), an efficient framework designed to enhance the\nagent's generalization ability using natural language task descriptions and\npre-trained multimodal encoders. Our key idea is to calculate a similarity\nbetween visual observations and natural language instructions in the\npre-trained multimodal embedding space (such as CLIP) and use it as a reward\nsignal. We then train a return-conditioned policy using expert demonstrations\nlabeled with multimodal rewards. Because the multimodal rewards provide\nadaptive signals at each timestep, our ARP effectively mitigates the goal\nmisgeneralization. This results in superior generalization performances even\nwhen faced with unseen text instructions, compared to existing text-conditioned\npolicies. To improve the quality of rewards, we also introduce a fine-tuning\nmethod for pre-trained multimodal encoders, further enhancing the performance.\nVideo demonstrations and source code are available on the project website:\n\\url{https://sites.google.com/view/2023arp}.\n",
                "链接": "https://arxiv.org/abs/2309.10790"
            },
            {
                "文章ID": "11531",
                "标题": "Intelligent Systematic Investment Agent: an ensemble of deep learning\n  and evolutionary strategies",
                "作者": " Prasang Gupta,  Shaz Hoda,  Anand Rao",
                "发布日期": "2022-03-25",
                "摘要": "  Machine learning driven trading strategies have garnered a lot of interest\nover the past few years. There is, however, limited consensus on the ideal\napproach for the development of such trading strategies. Further, most\nliterature has focused on trading strategies for short-term trading, with\nlittle or no focus on strategies that attempt to build long-term wealth. Our\npaper proposes a new approach for developing long-term investment strategies\nusing an ensemble of evolutionary algorithms and a deep learning model by\ntaking a series of short-term purchase decisions. Our methodology focuses on\nbuilding long-term wealth by improving systematic investment planning (SIP)\ndecisions on Exchange Traded Funds (ETF) over a period of time. We provide\nempirical evidence of superior performance (around 1% higher returns) using our\nensemble approach as compared to the traditional daily systematic investment\npractice on a given ETF. Our results are based on live trading decisions made\nby our algorithm and executed on the Robinhood trading platform.\n",
                "链接": "https://arxiv.org/abs/2203.13125"
            },
            {
                "文章ID": "41917",
                "标题": "iMedBot: A Web-based Intelligent Agent for Healthcare Related Prediction\n  and Deep Learning",
                "作者": " Chuhan Xu,  Xia Jiang",
                "发布日期": "2022-10-13",
                "摘要": "  Background: Breast cancer is a multifactorial disease, genetic and\nenvironmental factors will affect its incidence probability. Breast cancer\nmetastasis is one of the main cause of breast cancer related deaths reported by\nthe American Cancer Society (ACS). Method: the iMedBot is a web application\nthat we developed using the python Flask web framework and deployed on Amazon\nWeb Services. It contains a frontend and a backend. The backend is supported by\na python program we developed using the python Keras and scikit-learn packages,\nwhich can be used to learn deep feedforward neural network (DFNN) models.\nResult: the iMedBot can provide two main services: 1. it can predict 5-, 10-,\nor 15-year breast cancer metastasis based on a set of clinical information\nprovided by a user. The prediction is done by using a set of DFNN models that\nwere pretrained, and 2. It can train DFNN models for a user using user-provided\ndataset. The model trained will be evaluated using AUC and both the AUC value\nand the AUC ROC curve will be provided. Conclusion: The iMedBot web application\nprovides a user-friendly interface for user-agent interaction in conducting\npersonalized prediction and model training. It is an initial attempt to convert\nresults of deep learning research into an online tool that may stir further\nresearch interests in this direction. Keywords: Deep learning, Breast Cancer,\nWeb application, Model training.\n",
                "链接": "https://arxiv.org/abs/2210.05671"
            },
            {
                "文章ID": "83996",
                "标题": "Enabling Intelligent Interactions between an Agent and an LLM: A\n  Reinforcement Learning Approach",
                "作者": " Bin Hu,  Chenyang Zhao,  Pu Zhang,  Zihao Zhou,  Yuanhang Yang,  Zenglin Xu,  Bin Liu",
                "发布日期": "2023-09-01",
                "摘要": "  Large language models (LLMs) encode a vast amount of world knowledge acquired\nfrom massive text datasets. Recent studies have demonstrated that LLMs can\nassist an embodied agent in solving complex sequential decision making tasks by\nproviding high-level instructions. However, interactions with LLMs can be\ntime-consuming. In many practical scenarios, they require a significant amount\nof storage space that can only be deployed on remote cloud server nodes.\nAdditionally, using commercial LLMs can be costly since they may charge based\non usage frequency. In this paper, we explore how to enable intelligent\ncost-effective interactions between the agent and an LLM. We propose When2Ask,\na reinforcement learning based approach that learns when it is necessary to\nquery LLMs for high-level instructions to accomplish a target task. Experiments\non MiniGrid and Habitat environments that entail planning sub-goals demonstrate\nthat When2Ask learns to solve target tasks with only a few necessary\ninteractions with an LLM, and significantly reduces interaction costs in\ntesting environments compared with baseline methods. Experiment results also\nsuggest that by learning a mediator model to interact with the LLM, the agent's\nperformance becomes more robust against partial observability of the\nenvironment. Our code is available at https://github.com/ZJLAB-AMMI/LLM4RL.\n",
                "链接": "https://arxiv.org/abs/2306.03604"
            },
            {
                "文章ID": "56258",
                "标题": "Evidence of behavior consistent with self-interest and altruism in an\n  artificially intelligent agent",
                "作者": " Tim Johnson,  Nick Obradovich",
                "发布日期": "2023-01-09",
                "摘要": "  Members of various species engage in altruism--i.e. accepting personal costs\nto benefit others. Here we present an incentivized experiment to test for\naltruistic behavior among AI agents consisting of large language models\ndeveloped by the private company OpenAI. Using real incentives for AI agents\nthat take the form of tokens used to purchase their services, we first examine\nwhether AI agents maximize their payoffs in a non-social decision task in which\nthey select their payoff from a given range. We then place AI agents in a\nseries of dictator games in which they can share resources with a\nrecipient--either another AI agent, the human experimenter, or an anonymous\ncharity, depending on the experimental condition. Here we find that only the\nmost-sophisticated AI agent in the study maximizes its payoffs more often than\nnot in the non-social decision task (it does so in 92% of all trials), and this\nAI agent also exhibits the most-generous altruistic behavior in the dictator\ngame, resembling humans' rates of sharing with other humans in the game. The\nagent's altruistic behaviors, moreover, vary by recipient: the AI agent shared\nsubstantially less of the endowment with the human experimenter or an anonymous\ncharity than with other AI agents. Our findings provide evidence of behavior\nconsistent with self-interest and altruism in an AI agent. Moreover, our study\nalso offers a novel method for tracking the development of such behaviors in\nfuture AI agents.\n",
                "链接": "https://arxiv.org/abs/2301.02330"
            },
            {
                "文章ID": "68836",
                "标题": "Intelligent Load Balancing and Resource Allocation in O-RAN: A\n  Multi-Agent Multi-Armed Bandit Approach",
                "作者": " Chia-Hsiang Lai,  Li-Hsiang Shen,  Kai-Ten Feng",
                "发布日期": "2023-03-28",
                "摘要": "  The open radio access network (O-RAN) architecture offers a cost-effective\nand scalable solution for internet service providers to optimize their networks\nusing machine learning algorithms. The architecture's open interfaces enable\nnetwork function virtualization, with the O-RAN serving as the primary\ncommunication device for users. However, the limited frequency resources and\ninformation explosion make it difficult to achieve an optimal network\nexperience without effective traffic control or resource allocation. To address\nthis, we consider mobility-aware load balancing to evenly distribute loads\nacross the network, preventing network congestion and user outages caused by\nexcessive load concentration on open radio unit (O-RU) governed by a single\nopen distributed unit (O-DU). We have proposed a multi-agent multi-armed bandit\nfor load balancing and resource allocation (mmLBRA) scheme, designed to both\nachieve load balancing and improve the effective sum-rate performance of the\nO-RAN network. We also present the mmLBRA-LB and mmLBRA-RA sub-schemes that can\noperate independently in non-realtime RAN intelligent controller (Non-RT RIC)\nand near-RT RIC, respectively, providing a solution with moderate loads and\nhigh-rate in O-RUs. Simulation results show that the proposed mmLBRA scheme\nsignificantly increases the effective network sum-rate while achieving better\nload balancing across O-RUs compared to rule-based and other existing heuristic\nmethods in open literature.\n",
                "链接": "https://arxiv.org/abs/2303.14355"
            },
            {
                "文章ID": "117277",
                "标题": "Intelligent Knee Sleeves: A Real-time Multimodal Dataset for 3D Lower\n  Body Motion Estimation Using Smart Textile",
                "作者": " Wenwen Zhang,  Arvin Tashakori,  Zenan Jiang,  Amir Servati,  Harishkumar Narayana,  Saeid Soltanian,  Rou Yi Yeap,  Meng Han Ma,  Lauren Toy,  Peyman Servati",
                "发布日期": "2023-11-23",
                "摘要": "  The kinematics of human movements and locomotion are closely linked to the\nactivation and contractions of muscles. To investigate this, we present a\nmultimodal dataset with benchmarks collected using a novel pair of Intelligent\nKnee Sleeves (Texavie MarsWear Knee Sleeves) for human pose estimation. Our\nsystem utilizes synchronized datasets that comprise time-series data from the\nKnee Sleeves and the corresponding ground truth labels from the visualized\nmotion capture camera system. We employ these to generate 3D human models\nsolely based on the wearable data of individuals performing different\nactivities. We demonstrate the effectiveness of this camera-free system and\nmachine learning algorithms in the assessment of various movements and\nexercises, including extension to unseen exercises and individuals. The results\nshow an average error of 7.21 degrees across all eight lower body joints when\ncompared to the ground truth, indicating the effectiveness and reliability of\nthe Knee Sleeve system for the prediction of different lower body joints beyond\nthe knees. The results enable human pose estimation in a seamless manner\nwithout being limited by visual occlusion or the field of view of cameras. Our\nresults show the potential of multimodal wearable sensing in a variety of\napplications from home fitness to sports, healthcare, and physical\nrehabilitation focusing on pose and movement estimation.\n",
                "链接": "https://arxiv.org/abs/2311.12829"
            },
            {
                "文章ID": "38331",
                "标题": "Intelligent wayfinding vehicle design based on visual recognition",
                "作者": " Zhanyu Guo,  Shenyuan Guo,  Jialong Wang,  Yifan Feng",
                "发布日期": "2022-09-22",
                "摘要": "  Intelligent drug delivery trolley is an advanced intelligent drug delivery\nequipment. Compared with traditional manual drug delivery, it has higher drug\ndelivery efficiency and lower error rate. In this project, an intelligent drug\ndelivery car is designed and manufactured, which can recognize the road route\nand the room number of the target ward through visual recognition technology.\nThe trolley selects the corresponding route according to the identified room\nnumber, accurately transports the drugs to the target ward, and can return to\nthe pharmacy after the drugs are delivered. The intelligent drug delivery car\nuses DC power supply, and the motor drive module controls two DC motors, which\novercomes the problem of excessive deviation of turning angle. The trolley line\ninspection function uses closed-loop control to improve the accuracy of line\ninspection and the controllability of trolley speed. The identification of ward\nnumber is completed by the camera module with microcontroller, and has the\nfunctions of adaptive adjustment of ambient brightness, distortion correction,\nautomatic calibration and so on. The communication between two cooperative drug\ndelivery vehicles is realized by Bluetooth module, which achieves efficient and\naccurate communication and interaction. Experiments show that the intelligent\ndrug delivery car can accurately identify the room number and plan the route to\ndeliver drugs to the far, middle and near wards, and has the characteristics of\nfast speed and accurate judgment. In addition, two drug delivery trolleys can\ncooperate to deliver drugs to the same ward, with high efficiency and high\ncooperation.\n",
                "链接": "https://arxiv.org/abs/2209.10229"
            },
            {
                "文章ID": "112337",
                "标题": "Multimodal ChatGPT for Medical Applications: an Experimental Study of\n  GPT-4V",
                "作者": " Zhiling Yan,  Kai Zhang,  Rong Zhou,  Lifang He,  Xiang Li,  Lichao Sun",
                "发布日期": "2023-10-31",
                "摘要": "  In this paper, we critically evaluate the capabilities of the\nstate-of-the-art multimodal large language model, i.e., GPT-4 with Vision\n(GPT-4V), on Visual Question Answering (VQA) task. Our experiments thoroughly\nassess GPT-4V's proficiency in answering questions paired with images using\nboth pathology and radiology datasets from 11 modalities (e.g. Microscopy,\nDermoscopy, X-ray, CT, etc.) and fifteen objects of interests (brain, liver,\nlung, etc.). Our datasets encompass a comprehensive range of medical inquiries,\nincluding sixteen distinct question types. Throughout our evaluations, we\ndevised textual prompts for GPT-4V, directing it to synergize visual and\ntextual information. The experiments with accuracy score conclude that the\ncurrent version of GPT-4V is not recommended for real-world diagnostics due to\nits unreliable and suboptimal accuracy in responding to diagnostic medical\nquestions. In addition, we delineate seven unique facets of GPT-4V's behavior\nin medical VQA, highlighting its constraints within this complex arena. The\ncomplete details of our evaluation cases are accessible at\nhttps://github.com/ZhilingYan/GPT4V-Medical-Report.\n",
                "链接": "https://arxiv.org/abs/2310.19061"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用CrossWoz或MultiWoz数据集进行DST评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "46848",
                "标题": "MultiWOZ-DF -- A Dataflow implementation of the MultiWOZ dataset",
                "作者": " Joram Meron,  Victor Guimarães",
                "发布日期": "2022-11-07",
                "摘要": "  Semantic Machines (SM) have introduced the use of the dataflow (DF) paradigm\nto dialogue modelling, using computational graphs to hierarchically represent\nuser requests, data, and the dialogue history [Semantic Machines et al. 2020].\nAlthough the main focus of that paper was the SMCalFlow dataset (to date, the\nonly dataset with \"native\" DF annotations), they also reported some results of\nan experiment using a transformed version of the commonly used MultiWOZ dataset\n[Budzianowski et al. 2018] into a DF format. In this paper, we expand the\nexperiments using DF for the MultiWOZ dataset, exploring some additional\nexperimental set-ups. The code and instructions to reproduce the experiments\nreported here have been released. The contributions of this paper are: 1.) A DF\nimplementation capable of executing MultiWOZ dialogues; 2.) Several versions of\nconversion of MultiWOZ into a DF format are presented; 3.) Experimental results\non state match and translation accuracy.\n",
                "链接": "https://arxiv.org/abs/2211.02303"
            },
            {
                "文章ID": "45137",
                "标题": "Is MultiWOZ a Solved Task? An Interactive TOD Evaluation Framework with\n  User Simulator",
                "作者": " Qinyuan Cheng,  Linyang Li,  Guofeng Quan,  Feng Gao,  Xiaofeng Mou,  Xipeng Qiu",
                "发布日期": "2022-10-27",
                "摘要": "  Task-Oriented Dialogue (TOD) systems are drawing more and more attention in\nrecent studies. Current methods focus on constructing pre-trained models or\nfine-tuning strategies while the evaluation of TOD is limited by a policy\nmismatch problem. That is, during evaluation, the user utterances are from the\nannotated dataset while these utterances should interact with previous\nresponses which can have many alternatives besides annotated texts. Therefore,\nin this work, we propose an interactive evaluation framework for TOD. We first\nbuild a goal-oriented user simulator based on pre-trained models and then use\nthe user simulator to interact with the dialogue system to generate dialogues.\nBesides, we introduce a sentence-level and a session-level score to measure the\nsentence fluency and session coherence in the interactive evaluation.\nExperimental results show that RL-based TOD systems trained by our proposed\nuser simulator can achieve nearly 98% inform and success rates in the\ninteractive evaluation of MultiWOZ dataset and the proposed scores measure the\nresponse quality besides the inform and success rates. We are hoping that our\nwork will encourage simulator-based interactive evaluations in the TOD task.\n",
                "链接": "https://arxiv.org/abs/2210.14529"
            },
            {
                "文章ID": "60862",
                "标题": "Find a witness or shatter: the landscape of computable PAC learning",
                "作者": " Valentino Delle Rose,  Alexander Kozachinskiy,  Cristobal Rojas,  Tomasz Steifer",
                "发布日期": "2023-02-24",
                "摘要": "  This paper contributes to the study of CPAC learnability -- a computable\nversion of PAC learning -- by solving three open questions from recent papers.\nFirstly, we prove that every improperly CPAC learnable class is contained in a\nclass which is properly CPAC learnable with polynomial sample complexity. This\nconfirms a conjecture by Agarwal et al (COLT 2021). Secondly, we show that\nthere exists a decidable class of hypothesis which is properly CPAC learnable,\nbut only with uncomputably fast growing sample complexity. This solves a\nquestion from Sterkenburg (COLT 2022). Finally, we construct a decidable class\nof finite Littlestone dimension which is not improperly CPAC learnable,\nstrengthening a recent result of Sterkenburg (2022) and answering a question\nposed by Hasrati and Ben-David (ALT 2023). Together with previous work, our\nresults provide a complete landscape for the learnability problem in the CPAC\nsetting.\n",
                "链接": "https://arxiv.org/abs/2302.04731"
            },
            {
                "文章ID": "100215",
                "标题": "Donkii: Can Annotation Error Detection Methods Find Errors in\n  Instruction-Tuning Datasets?",
                "作者": " Leon Weber-Genzel,  Robert Litschko,  Ekaterina Artemova,  Barbara Plank",
                "发布日期": "2023-09-06",
                "摘要": "  Instruction-tuning has become an integral part of training pipelines for\nLarge Language Models (LLMs) and has been shown to yield strong performance\ngains. In an orthogonal line of research, Annotation Error Detection (AED) has\nemerged as a tool for detecting quality issues of gold-standard labels. But so\nfar, the application of AED methods is limited to discriminative settings. It\nis an open question how well AED methods generalize to generative settings\nwhich are becoming widespread via generative LLMs. In this work, we present a\nfirst and new benchmark for AED on instruction-tuning data: Donkii. It\nencompasses three instruction-tuning datasets enriched with annotations by\nexperts and semi-automatic methods. We find that all three datasets contain\nclear-cut errors that sometimes directly propagate into instruction-tuned LLMs.\nWe propose four AED baselines for the generative setting and evaluate them\ncomprehensively on the newly introduced dataset. Our results demonstrate that\nchoosing the right AED method and model size is indeed crucial, thereby\nderiving practical recommendations. To gain insights, we provide a first\ncase-study to examine how the quality of the instruction-tuning datasets\ninfluences downstream performance.\n",
                "链接": "https://arxiv.org/abs/2309.01669"
            },
            {
                "文章ID": "111434",
                "标题": "In the user's eyes we find trust: Using gaze data as a predictor or\n  trust in an artifical intelligence",
                "作者": " Martin Johannes Dechant,  Olga Lukashova-Sanz,  Siegfried Wahl",
                "发布日期": "2023-10-26",
                "摘要": "  Trust is essential for our interactions with others but also with artificial\nintelligence (AI) based systems. To understand whether a user trusts an AI,\nresearchers need reliable measurement tools. However, currently discussed\nmarkers mostly rely on expensive and invasive sensors, like\nelectroencephalograms, which may cause discomfort. The analysis of gaze data\nhas been suggested as a convenient tool for trust assessment. However, the\nrelationship between trust and several aspects of the gaze behaviour is not yet\nfully understood. To provide more insights into this relationship, we propose a\nexploration study in virtual reality where participants have to perform a\nsorting task together with a simulated AI in a simulated robotic arm embedded\nin a gaming. We discuss the potential benefits of this approach and outline our\nstudy design in this submission.\n",
                "链接": "https://arxiv.org/abs/2310.16672"
            },
            {
                "文章ID": "6598",
                "标题": "Policy Evaluation for Temporal and/or Spatial Dependent Experiments",
                "作者": " Shikai Luo,  Ying Yang,  Chengchun Shi,  Fang Yao,  Jieping Ye,  Hongtu Zhu",
                "发布日期": "2023-12-05",
                "摘要": "  The aim of this paper is to establish a causal link between the policies\nimplemented by technology companies and the outcomes they yield within\nintricate temporal and/or spatial dependent experiments. We propose a novel\ntemporal/spatio-temporal Varying Coefficient Decision Process (VCDP) model,\ncapable of effectively capturing the evolving treatment effects in situations\ncharacterized by temporal and/or spatial dependence. Our methodology\nencompasses the decomposition of the Average Treatment Effect (ATE) into the\nDirect Effect (DE) and the Indirect Effect (IE). We subsequently devise\ncomprehensive procedures for estimating and making inferences about both DE and\nIE. Additionally, we provide a rigorous analysis of the statistical properties\nof these procedures, such as asymptotic power. To substantiate the\neffectiveness of our approach, we carry out extensive simulations and real data\nanalyses.\n",
                "链接": "https://arxiv.org/abs/2202.10887"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "13538",
                "标题": "Design Guidelines for Inclusive Speaker Verification Evaluation Datasets",
                "作者": " Wiebke Toussaint Hutiri,  Lauriane Gorce,  Aaron Yi Ding",
                "发布日期": "2022-09-14",
                "摘要": "  Speaker verification (SV) provides billions of voice-enabled devices with\naccess control, and ensures the security of voice-driven technologies. As a\ntype of biometrics, it is necessary that SV is unbiased, with consistent and\nreliable performance across speakers irrespective of their demographic, social\nand economic attributes. Current SV evaluation practices are insufficient for\nevaluating bias: they are over-simplified and aggregate users, not\nrepresentative of real-life usage scenarios, and consequences of errors are not\naccounted for. This paper proposes design guidelines for constructing SV\nevaluation datasets that address these short-comings. We propose a schema for\ngrading the difficulty of utterance pairs, and present an algorithm for\ngenerating inclusive SV datasets. We empirically validate our proposed method\nin a set of experiments on the VoxCeleb1 dataset. Our results confirm that the\ncount of utterance pairs/speaker, and the difficulty grading of utterance pairs\nhave a significant effect on evaluation performance and variability. Our work\ncontributes to the development of SV evaluation practices that are inclusive\nand fair.\n",
                "链接": "https://arxiv.org/abs/2204.02281"
            },
            {
                "文章ID": "53858",
                "标题": "Evaluation of Synthetic Datasets for Conversational Recommender Systems",
                "作者": " Harsh Lara,  Manoj Tiwari",
                "发布日期": "2022-12-19",
                "摘要": "  For researchers leveraging Large-Language Models (LLMs) in the generation of\ntraining datasets, especially for conversational recommender systems - the\nabsence of robust evaluation frameworks has been a long-standing problem. The\nefficiency brought about by LLMs in the data generation phase is impeded during\nthe process of evaluation of the generated data, since it generally requires\nhuman-raters to ensure that the data generated is of high quality and has\nsufficient diversity. Since the quality of training data is critical for\ndownstream applications, it is important to develop metrics that evaluate the\nquality holistically and identify biases. In this paper, we present a framework\nthat takes a multi-faceted approach towards evaluating datasets produced by\ngenerative models and discuss the advantages and limitations of various\nevaluation methods.\n",
                "链接": "https://arxiv.org/abs/2212.08167"
            },
            {
                "文章ID": "112862",
                "标题": "Multi-User MultiWOZ: Task-Oriented Dialogues among Multiple Users",
                "作者": " Yohan Jo,  Xinyan Zhao,  Arijit Biswas,  Nikoletta Basiou,  Vincent Auvray,  Nikolaos Malandrakis,  Angeliki Metallinou,  Alexandros Potamianos",
                "发布日期": "2023-11-01",
                "摘要": "  While most task-oriented dialogues assume conversations between the agent and\none user at a time, dialogue systems are increasingly expected to communicate\nwith multiple users simultaneously who make decisions collaboratively. To\nfacilitate development of such systems, we release the Multi-User MultiWOZ\ndataset: task-oriented dialogues among two users and one agent. To collect this\ndataset, each user utterance from MultiWOZ 2.2 was replaced with a small chat\nbetween two users that is semantically and pragmatically consistent with the\noriginal user utterance, thus resulting in the same dialogue state and system\nresponse. These dialogues reflect interesting dynamics of collaborative\ndecision-making in task-oriented scenarios, e.g., social chatter and\ndeliberation. Supported by this data, we propose the novel task of multi-user\ncontextual query rewriting: to rewrite a task-oriented chat between two users\nas a concise task-oriented query that retains only task-relevant information\nand that is directly consumable by the dialogue system. We demonstrate that in\nmulti-user dialogues, using predicted rewrites substantially improves dialogue\nstate tracking without modifying existing dialogue systems that are trained for\nsingle-user dialogues. Further, this method surpasses training a medium-sized\nmodel directly on multi-user dialogues and generalizes to unseen domains.\n",
                "链接": "https://arxiv.org/abs/2310.20479"
            }
        ]
    },
    {
        "question": {
            "question": "2023年后利用hotpotqa数据集做问题生成任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "77821",
                "标题": "When is an SHM problem a Multi-Task-Learning problem?",
                "作者": " Sarah Bee,  Lawrence Bull,  Nikolas Dervilis,  Keith Worden",
                "发布日期": "2023-05-17",
                "摘要": "  Multi-task neural networks learn tasks simultaneously to improve individual\ntask performance. There are three mechanisms of multi-task learning (MTL) which\nare explored here for the context of structural health monitoring (SHM): (i)\nthe natural occurrence of multiple tasks; (ii) using outputs as inputs (both\nlinked to the recent research in population-based SHM (PBSHM)); and, (iii)\nadditional loss functions to provide different insights. Each of these problem\nsettings for MTL is detailed and an example is given.\n",
                "链接": "https://arxiv.org/abs/2305.09425"
            },
            {
                "文章ID": "89344",
                "标题": "On the Constrained Time-Series Generation Problem",
                "作者": " Andrea Coletta,  Sriram Gopalakrishan,  Daniel Borrajo,  Svitlana Vyetrenko",
                "发布日期": "2023-09-18",
                "摘要": "  Synthetic time series are often used in practical applications to augment the\nhistorical time series dataset for better performance of machine learning\nalgorithms, amplify the occurrence of rare events, and also create\ncounterfactual scenarios described by the time series.\nDistributional-similarity (which we refer to as realism) as well as the\nsatisfaction of certain numerical constraints are common requirements in\ncounterfactual time series scenario generation requests. For instance, the US\nFederal Reserve publishes synthetic market stress scenarios given by the\nconstrained time series for financial institutions to assess their performance\nin hypothetical recessions. Existing approaches for generating constrained time\nseries usually penalize training loss to enforce constraints, and reject\nnon-conforming samples. However, these approaches would require re-training if\nwe change constraints, and rejection sampling can be computationally expensive,\nor impractical for complex constraints. In this paper, we propose a novel set\nof methods to tackle the constrained time series generation problem and provide\nefficient sampling while ensuring the realism of generated time series. In\nparticular, we frame the problem using a constrained optimization framework and\nthen we propose a set of generative methods including \"GuidedDiffTime\", a\nguided diffusion model to generate realistic time series. Empirically, we\nevaluate our work on several datasets for financial and energy data, where\nincorporating constraints is critical. We show that our approaches outperform\nexisting work both qualitatively and quantitatively. Most importantly, we show\nthat our \"GuidedDiffTime\" model is the only solution where re-training is not\nnecessary for new constraints, resulting in a significant carbon footprint\nreduction, up to 92% w.r.t. existing deep learning methods.\n",
                "链接": "https://arxiv.org/abs/2307.01717"
            },
            {
                "文章ID": "69640",
                "标题": "A Gold Standard Dataset for the Reviewer Assignment Problem",
                "作者": " Ivan Stelmakh,  John Wieting,  Graham Neubig,  Nihar B. Shah",
                "发布日期": "2023-03-30",
                "摘要": "  Many peer-review venues are either using or looking to use algorithms to\nassign submissions to reviewers. The crux of such automated approaches is the\nnotion of the \"similarity score\"--a numerical estimate of the expertise of a\nreviewer in reviewing a paper--and many algorithms have been proposed to\ncompute these scores. However, these algorithms have not been subjected to a\nprincipled comparison, making it difficult for stakeholders to choose the\nalgorithm in an evidence-based manner. The key challenge in comparing existing\nalgorithms and developing better algorithms is the lack of the publicly\navailable gold-standard data that would be needed to perform reproducible\nresearch. We address this challenge by collecting a novel dataset of similarity\nscores that we release to the research community. Our dataset consists of 477\nself-reported expertise scores provided by 58 researchers who evaluated their\nexpertise in reviewing papers they have read previously.\n  We use this data to compare several popular algorithms employed in computer\nscience conferences and come up with recommendations for stakeholders. Our main\nfindings are as follows. First, all algorithms make a non-trivial amount of\nerror. For the task of ordering two papers in terms of their relevance for a\nreviewer, the error rates range from 12%-30% in easy cases to 36%-43% in hard\ncases, highlighting the vital need for more research on the\nsimilarity-computation problem. Second, most existing algorithms are designed\nto work with titles and abstracts of papers, and in this regime the Specter+MFR\nalgorithm performs best. Third, to improve performance, it may be important to\ndevelop modern deep-learning based algorithms that can make use of the full\ntexts of papers: the classical TD-IDF algorithm enhanced with full texts of\npapers is on par with the deep-learning based Specter+MFR that cannot make use\nof this information.\n",
                "链接": "https://arxiv.org/abs/2303.16750"
            },
            {
                "文章ID": "73495",
                "标题": "The Dataset Multiplicity Problem: How Unreliable Data Impacts\n  Predictions",
                "作者": " Anna P. Meyer,  Aws Albarghouthi,  Loris D'Antoni",
                "发布日期": "2023-04-24",
                "摘要": "  We introduce dataset multiplicity, a way to study how inaccuracies,\nuncertainty, and social bias in training datasets impact test-time predictions.\nThe dataset multiplicity framework asks a counterfactual question of what the\nset of resultant models (and associated test-time predictions) would be if we\ncould somehow access all hypothetical, unbiased versions of the dataset. We\ndiscuss how to use this framework to encapsulate various sources of uncertainty\nin datasets' factualness, including systemic social bias, data collection\npractices, and noisy labels or features. We show how to exactly analyze the\nimpacts of dataset multiplicity for a specific model architecture and type of\nuncertainty: linear models with label errors. Our empirical analysis shows that\nreal-world datasets, under reasonable assumptions, contain many test samples\nwhose predictions are affected by dataset multiplicity. Furthermore, the choice\nof domain-specific dataset multiplicity definition determines what samples are\naffected, and whether different demographic groups are disparately impacted.\nFinally, we discuss implications of dataset multiplicity for machine learning\npractice and research, including considerations for when model outcomes should\nnot be trusted.\n",
                "链接": "https://arxiv.org/abs/2304.10655"
            },
            {
                "文章ID": "114655",
                "标题": "Conic10K: A Challenging Math Problem Understanding and Reasoning Dataset",
                "作者": " Haoyi Wu,  Wenyang Hui,  Yezeng Chen,  Weiqi Wu,  Kewei Tu,  Yi Zhou",
                "发布日期": "2023-11-10",
                "摘要": "  Mathematical understanding and reasoning are crucial tasks for assessing the\ncapabilities of artificial intelligence (AI). However, existing benchmarks\neither require just a few steps of reasoning, or only contain a small amount of\ndata in one specific topic, making it hard to analyse AI's behaviour with\nreference to different problems within a specific topic in detail. In this\nwork, we propose Conic10K, a challenging math problem dataset on conic sections\nin Chinese senior high school education. Our dataset contains various problems\nwith different reasoning depths, while only the knowledge from conic sections\nis required. Since the dataset only involves a narrow range of knowledge, it is\neasy to separately analyse the knowledge a model possesses and the reasoning\nability it has. For each problem, we provide a high-quality formal\nrepresentation, the reasoning steps, and the final solution. Experiments show\nthat existing large language models, including GPT-4, exhibit weak performance\non complex reasoning. We hope that our findings could inspire more advanced\ntechniques for precise natural language understanding and reasoning. Our\ndataset and codes are available at https://github.com/whyNLP/Conic10K.\n",
                "链接": "https://arxiv.org/abs/2311.05113"
            },
            {
                "文章ID": "68623",
                "标题": "Graph Neural Networks for the Offline Nanosatellite Task Scheduling\n  Problem",
                "作者": " Bruno Machado Pacheco,  Laio Oriel Seman,  Cezar Antonio Rigo,  Eduardo Camponogara,  Eduardo Augusto Bezerra,  Leandro dos Santos Coelho",
                "发布日期": "2023-09-22",
                "摘要": "  This study investigates how to schedule nanosatellite tasks more efficiently\nusing Graph Neural Networks (GNNs). In the Offline Nanosatellite Task\nScheduling (ONTS) problem, the goal is to find the optimal schedule for tasks\nto be carried out in orbit while taking into account Quality-of-Service (QoS)\nconsiderations such as priority, minimum and maximum activation events,\nexecution time-frames, periods, and execution windows, as well as constraints\non the satellite's power resources and the complexity of energy harvesting and\nmanagement. The ONTS problem has been approached using conventional\nmathematical formulations and exact methods, but their applicability to\nchallenging cases of the problem is limited. This study examines the use of\nGNNs in this context, which has been effectively applied to optimization\nproblems such as the traveling salesman, scheduling, and facility placement\nproblems. More specifically, we investigate whether GNNs can learn the complex\nstructure of the ONTS problem with respect to feasibility and optimality of\ncandidate solutions. Furthermore, we evaluate using GNN-based heuristic\nsolutions to provide better solutions (w.r.t. the objective value) to the ONTS\nproblem and reduce the optimization cost. Our experiments show that GNNs are\nnot only able to learn feasibility and optimality for instances of the ONTS\nproblem, but they can generalize to harder instances than those seen during\ntraining. Furthermore, the GNN-based heuristics improved the expected objective\nvalue of the best solution found under the time limit in 45%, and reduced the\nexpected time to find a feasible solution in 35%, when compared to the SCIP\n(Solving Constraint Integer Programs) solver in its off-the-shelf configuration\n",
                "链接": "https://arxiv.org/abs/2303.13773"
            },
            {
                "文章ID": "106949",
                "标题": "Visual Abductive Reasoning Meets Driving Hazard Prediction: Problem\n  Formulation and Dataset",
                "作者": " Korawat Charoenpitaks,  Van-Quang Nguyen,  Masanori Suganuma,  Masahiro Takahashi,  Ryoma Niihara,  Takayuki Okatani",
                "发布日期": "2023-10-11",
                "摘要": "  This paper addresses the problem of predicting hazards that drivers may\nencounter while driving a car. We formulate it as a task of anticipating\nimpending accidents using a single input image captured by car dashcams. Unlike\nexisting approaches to driving hazard prediction that rely on computational\nsimulations or anomaly detection from videos, this study focuses on high-level\ninference from static images. The problem needs predicting and reasoning about\nfuture events based on uncertain observations, which falls under visual\nabductive reasoning. To enable research in this understudied area, a new\ndataset named the DHPR (Driving Hazard Prediction and Reasoning) dataset is\ncreated. The dataset consists of 15K dashcam images of street scenes, and each\nimage is associated with a tuple containing car speed, a hypothesized hazard\ndescription, and visual entities present in the scene. These are annotated by\nhuman annotators, who identify risky scenes and provide descriptions of\npotential accidents that could occur a few seconds later. We present several\nbaseline methods and evaluate their performance on our dataset, identifying\nremaining issues and discussing future directions. This study contributes to\nthe field by introducing a novel problem formulation and dataset, enabling\nresearchers to explore the potential of multi-modal AI for driving hazard\nprediction.\n",
                "链接": "https://arxiv.org/abs/2310.04671"
            },
            {
                "文章ID": "86008",
                "标题": "Learning by Analogy: Diverse Questions Generation in Math Word Problem",
                "作者": " Zihao Zhou,  Maizhen Ning,  Qiufeng Wang,  Jie Yao,  Wei Wang,  Xiaowei Huang,  Kaizhu Huang",
                "发布日期": "2023-06-16",
                "摘要": "  Solving math word problem (MWP) with AI techniques has recently made great\nprogress with the success of deep neural networks (DNN), but it is far from\nbeing solved. We argue that the ability of learning by analogy is essential for\nan MWP solver to better understand same problems which may typically be\nformulated in diverse ways. However most existing works exploit the shortcut\nlearning to train MWP solvers simply based on samples with a single question.\nIn lack of diverse questions, these methods merely learn shallow heuristics. In\nthis paper, we make a first attempt to solve MWPs by generating diverse yet\nconsistent questions/equations. Given a typical MWP including the scenario\ndescription, question, and equation (i.e., answer), we first generate multiple\nconsistent equations via a group of heuristic rules. We then feed them to a\nquestion generator together with the scenario to obtain the corresponding\ndiverse questions, forming a new MWP with a variety of questions and equations.\nFinally we engage a data filter to remove those unreasonable MWPs, keeping the\nhigh-quality augmented ones. To evaluate the ability of learning by analogy for\nan MWP solver, we generate a new MWP dataset (called DiverseMath23K) with\ndiverse questions by extending the current benchmark Math23K. Extensive\nexperimental results demonstrate that our proposed method can generate\nhigh-quality diverse questions with corresponding equations, further leading to\nperformance improvement on Diverse-Math23K. The code and dataset is available\nat: https://github.com/zhouzihao501/DiverseMWP\n",
                "链接": "https://arxiv.org/abs/2306.09064"
            },
            {
                "文章ID": "77317",
                "标题": "MetaMorphosis: Task-oriented Privacy Cognizant Feature Generation for\n  Multi-task Learning",
                "作者": " Md Adnan Arefeen,  Zhouyu Li,  Md Yusuf Sarwar Uddin,  Anupam Das",
                "发布日期": "2023-05-16",
                "摘要": "  With the growth of computer vision applications, deep learning, and edge\ncomputing contribute to ensuring practical collaborative intelligence (CI) by\ndistributing the workload among edge devices and the cloud. However, running\nseparate single-task models on edge devices is inefficient regarding the\nrequired computational resource and time. In this context, multi-task learning\nallows leveraging a single deep learning model for performing multiple tasks,\nsuch as semantic segmentation and depth estimation on incoming video frames.\nThis single processing pipeline generates common deep features that are shared\namong multi-task modules. However, in a collaborative intelligence scenario,\ngenerating common deep features has two major issues. First, the deep features\nmay inadvertently contain input information exposed to the downstream modules\n(violating input privacy). Second, the generated universal features expose a\npiece of collective information than what is intended for a certain task, in\nwhich features for one task can be utilized to perform another task (violating\ntask privacy). This paper proposes a novel deep learning-based\nprivacy-cognizant feature generation process called MetaMorphosis that limits\ninference capability to specific tasks at hand. To achieve this, we propose a\nchannel squeeze-excitation based feature metamorphosis module, Cross-SEC, to\nachieve distinct attention of all tasks and a de-correlation loss function with\ndifferential-privacy to train a deep learning model that produces distinct\nprivacy-aware features as an output for the respective tasks. With extensive\nexperimentation on four datasets consisting of diverse images related to scene\nunderstanding and facial attributes, we show that MetaMorphosis outperforms\nrecent adversarial learning and universal feature generation methods by\nguaranteeing privacy requirements in an efficient way for image and video\nanalytics.\n",
                "链接": "https://arxiv.org/abs/2305.07815"
            },
            {
                "文章ID": "108022",
                "标题": "Target-oriented Proactive Dialogue Systems with Personalization: Problem\n  Formulation and Dataset Curation",
                "作者": " Jian Wang,  Yi Cheng,  Dongding Lin,  Chak Tou Leong,  Wenjie Li",
                "发布日期": "2023-10-16",
                "摘要": "  Target-oriented dialogue systems, designed to proactively steer conversations\ntoward predefined targets or accomplish specific system-side goals, are an\nexciting area in conversational AI. In this work, by formulating a <dialogue\nact, topic> pair as the conversation target, we explore a novel problem of\npersonalized target-oriented dialogue by considering personalization during the\ntarget accomplishment process. However, there remains an emergent need for\nhigh-quality datasets, and building one from scratch requires tremendous human\neffort. To address this, we propose an automatic dataset curation framework\nusing a role-playing approach. Based on this framework, we construct a\nlarge-scale personalized target-oriented dialogue dataset, TopDial, which\ncomprises about 18K multi-turn dialogues. The experimental results show that\nthis dataset is of high quality and could contribute to exploring personalized\ntarget-oriented dialogue.\n",
                "链接": "https://arxiv.org/abs/2310.07397"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "94331",
                "标题": "Deep learning for unsupervised domain adaptation in medical imaging:\n  Recent advancements and future perspectives",
                "作者": " Suruchi Kumari,  Pravendra Singh",
                "发布日期": "2023-08-03",
                "摘要": "  Deep learning has demonstrated remarkable performance across various tasks in\nmedical imaging. However, these approaches primarily focus on supervised\nlearning, assuming that the training and testing data are drawn from the same\ndistribution. Unfortunately, this assumption may not always hold true in\npractice. To address these issues, unsupervised domain adaptation (UDA)\ntechniques have been developed to transfer knowledge from a labeled domain to a\nrelated but unlabeled domain. In recent years, significant advancements have\nbeen made in UDA, resulting in a wide range of methodologies, including feature\nalignment, image translation, self-supervision, and disentangled representation\nmethods, among others. In this paper, we provide a comprehensive literature\nreview of recent deep UDA approaches in medical imaging from a technical\nperspective. Specifically, we categorize current UDA research in medical\nimaging into six groups and further divide them into finer subcategories based\non the different tasks they perform. We also discuss the respective datasets\nused in the studies to assess the divergence between the different domains.\nFinally, we discuss emerging areas and provide insights and discussions on\nfuture research directions to conclude this survey.\n",
                "链接": "https://arxiv.org/abs/2308.01265"
            },
            {
                "文章ID": "125268",
                "标题": "Continual Learning in Medical Imaging Analysis: A Comprehensive Review\n  of Recent Advancements and Future Prospects",
                "作者": " Pratibha Kumari,  Joohi Chauhan,  Afshin Bozorgpour,  Reza Azad,  Dorit Merhof",
                "发布日期": "2023-12-29",
                "摘要": "  Medical imaging analysis has witnessed remarkable advancements even\nsurpassing human-level performance in recent years, driven by the rapid\ndevelopment of advanced deep-learning algorithms. However, when the inference\ndataset slightly differs from what the model has seen during one-time training,\nthe model performance is greatly compromised. The situation requires restarting\nthe training process using both the old and the new data which is\ncomputationally costly, does not align with the human learning process, and\nimposes storage constraints and privacy concerns. Alternatively, continual\nlearning has emerged as a crucial approach for developing unified and\nsustainable deep models to deal with new classes, tasks, and the drifting\nnature of data in non-stationary environments for various application areas.\nContinual learning techniques enable models to adapt and accumulate knowledge\nover time, which is essential for maintaining performance on evolving datasets\nand novel tasks. This systematic review paper provides a comprehensive overview\nof the state-of-the-art in continual learning techniques applied to medical\nimaging analysis. We present an extensive survey of existing research, covering\ntopics including catastrophic forgetting, data drifts, stability, and\nplasticity requirements. Further, an in-depth discussion of key components of a\ncontinual learning framework such as continual learning scenarios, techniques,\nevaluation schemes, and metrics is provided. Continual learning techniques\nencompass various categories, including rehearsal, regularization,\narchitectural, and hybrid strategies. We assess the popularity and\napplicability of continual learning categories in various medical sub-fields\nlike radiology and histopathology...\n",
                "链接": "https://arxiv.org/abs/2312.17004"
            },
            {
                "文章ID": "33280",
                "标题": "Recent Progress in Transformer-based Medical Image Analysis",
                "作者": " Zhaoshan Liu,  Qiujie Lv,  Ziduo Yang,  Yifan Li,  Chau Hung Lee,  Lei Shen",
                "发布日期": "2023-07-26",
                "摘要": "  The transformer is primarily used in the field of natural language\nprocessing. Recently, it has been adopted and shows promise in the computer\nvision (CV) field. Medical image analysis (MIA), as a critical branch of CV,\nalso greatly benefits from this state-of-the-art technique. In this review, we\nfirst recap the core component of the transformer, the attention mechanism, and\nthe detailed structures of the transformer. After that, we depict the recent\nprogress of the transformer in the field of MIA. We organize the applications\nin a sequence of different tasks, including classification, segmentation,\ncaptioning, registration, detection, enhancement, localization, and synthesis.\nThe mainstream classification and segmentation tasks are further divided into\neleven medical image modalities. A large number of experiments studied in this\nreview illustrate that the transformer-based method outperforms existing\nmethods through comparisons with multiple evaluation metrics. Finally, we\ndiscuss the open challenges and future opportunities in this field. This\ntask-modality review with the latest contents, detailed information, and\ncomprehensive comparison may greatly benefit the broad MIA community.\n",
                "链接": "https://arxiv.org/abs/2208.06643"
            },
            {
                "文章ID": "5953",
                "标题": "An overview of deep learning in medical imaging",
                "作者": " Imran Ul Haq",
                "发布日期": "2022-02-18",
                "摘要": "  Machine learning (ML) has seen enormous consideration during the most recent\ndecade. This success started in 2012 when an ML model accomplished a remarkable\ntriumph in the ImageNet Classification, the world's most famous competition for\ncomputer vision. This model was a kind of convolutional neural system (CNN)\ncalled deep learning (DL). Since then, researchers have started to participate\nefficiently in DL's fastest developing area of research. These days, DL systems\nare cutting-edge ML systems spanning a broad range of disciplines, from human\nlanguage processing to video analysis, and commonly used in the scholarly world\nand enterprise sector. Recent advances can bring tremendous improvement to the\nmedical field. Improved and innovative methods for data processing, image\nanalysis and can significantly improve the diagnostic technologies and\nmedicinal services gradually. A quick review of current developments with\nrelevant problems in the field of DL used for medical imaging has been\nprovided. The primary purposes of the review are four: (i) provide a brief\nprolog to DL by discussing different DL models, (ii) review of the DL usage for\nmedical image analysis (classification, detection, segmentation, and\nregistration), (iii) review seven main application fields of DL in medical\nimaging, (iv) give an initial stage to those keen on adding to the research\narea about DL in clinical imaging by providing links of some useful informative\nassets, such as freely available DL codes, public datasets Table 7, and medical\nimaging competition sources Table 8 and end our survey by outlining distinct\ncontinuous difficulties, lessons learned and future of DL in the field of\nmedical science.\n",
                "链接": "https://arxiv.org/abs/2202.08546"
            },
            {
                "文章ID": "116047",
                "标题": "Synthetically Enhanced: Unveiling Synthetic Data's Potential in Medical\n  Imaging Research",
                "作者": " Bardia Khosravi,  Frank Li,  Theo Dapamede,  Pouria Rouzrokh,  Cooper U. Gamble,  Hari M. Trivedi,  Cody C. Wyles,  Andrew B. Sellergren,  Saptarshi Purkayastha,  Bradley J. Erickson,  Judy W. Gichoya",
                "发布日期": "2023-11-17",
                "摘要": "  Chest X-rays (CXR) are the most common medical imaging study and are used to\ndiagnose multiple medical conditions. This study examines the impact of\nsynthetic data supplementation, using diffusion models, on the performance of\ndeep learning (DL) classifiers for CXR analysis. We employed three datasets:\nCheXpert, MIMIC-CXR, and Emory Chest X-ray, training conditional denoising\ndiffusion probabilistic models (DDPMs) to generate synthetic frontal\nradiographs. Our approach ensured that synthetic images mirrored the\ndemographic and pathological traits of the original data. Evaluating the\nclassifiers' performance on internal and external datasets revealed that\nsynthetic data supplementation enhances model accuracy, particularly in\ndetecting less prevalent pathologies. Furthermore, models trained on synthetic\ndata alone approached the performance of those trained on real data. This\nsuggests that synthetic data can potentially compensate for real data shortages\nin training robust DL models. However, despite promising outcomes, the\nsuperiority of real data persists.\n",
                "链接": "https://arxiv.org/abs/2311.09402"
            },
            {
                "文章ID": "39016",
                "标题": "Recent trends and analysis of Generative Adversarial Networks in\n  Cervical Cancer Imaging",
                "作者": " Tamanna Sood",
                "发布日期": "2022-09-27",
                "摘要": "  Cervical cancer is one of the most common types of cancer found in females.\nIt contributes to 6-29% of all cancers in women. It is caused by the Human\nPapilloma Virus (HPV). The 5-year survival chances of cervical cancer range\nfrom 17%-92% depending upon the stage at which it is detected. Early detection\nof this disease helps in better treatment and survival rate of the patient.\nMany deep learning algorithms are being used for the detection of cervical\ncancer these days. A special category of deep learning techniques known as\nGenerative Adversarial Networks (GANs) are catching up with speed in the\nscreening, detection, and classification of cervical cancer. In this work, we\npresent a detailed analysis of the recent trends relating to the use of various\nGAN models, their applications, and the evaluation metrics used for their\nperformance evaluation in the field of cervical cancer imaging.\n",
                "链接": "https://arxiv.org/abs/2209.12680"
            },
            {
                "文章ID": "43911",
                "标题": "Reproducibility of the Methods in Medical Imaging with Deep Learning",
                "作者": " Attila Simko,  Anders Garpebring,  Joakim Jonsson,  Tufve Nyholm,  Tommy Löfstedt",
                "发布日期": "2022-10-21",
                "摘要": "  Concerns about the reproducibility of deep learning research are more\nprominent than ever, with no clear solution in sight. The relevance of machine\nlearning research can only be improved if we also employ empirical rigor that\nincorporates reproducibility guidelines, especially so in the medical imaging\nfield. The Medical Imaging with Deep Learning (MIDL) conference has made\nadvancements in this direction by advocating open access, and recently also\nrecommending authors to make their code public - both aspects being adopted by\nthe majority of the conference submissions. This helps the reproducibility of\nthe methods, however, there is currently little or no support for further\nevaluation of these supplementary material, making them vulnerable to poor\nquality, which affects the impact of the entire submission. We have evaluated\nall accepted full paper submissions to MIDL between 2018 and 2022 using\nestablished, but slightly adjusted guidelines on reproducibility and the\nquality of the public repositories. The evaluations show that publishing\nrepositories and using public datasets are becoming more popular, which helps\ntraceability, but the quality of the repositories has not improved over the\nyears, leaving room for improvement in every aspect of designing repositories.\nMerely 22% of all submissions contain a repository that were deemed repeatable\nusing our evaluations. From the commonly encountered issues during the\nevaluations, we propose a set of guidelines for machine learning-related\nresearch for medical imaging applications, adjusted specifically for future\nsubmissions to MIDL.\n",
                "链接": "https://arxiv.org/abs/2210.11146"
            },
            {
                "文章ID": "92854",
                "标题": "Deep Learning Approaches for Data Augmentation in Medical Imaging: A\n  Review",
                "作者": " Aghiles Kebaili,  Jérôme Lapuyade-Lahorgue,  Su Ruan",
                "发布日期": "2023-07-26",
                "摘要": "  Deep learning has become a popular tool for medical image analysis, but the\nlimited availability of training data remains a major challenge, particularly\nin the medical field where data acquisition can be costly and subject to\nprivacy regulations. Data augmentation techniques offer a solution by\nartificially increasing the number of training samples, but these techniques\noften produce limited and unconvincing results. To address this issue, a\ngrowing number of studies have proposed the use of deep generative models to\ngenerate more realistic and diverse data that conform to the true distribution\nof the data. In this review, we focus on three types of deep generative models\nfor medical image augmentation: variational autoencoders, generative\nadversarial networks, and diffusion models. We provide an overview of the\ncurrent state of the art in each of these models and discuss their potential\nfor use in different downstream tasks in medical imaging, including\nclassification, segmentation, and cross-modal translation. We also evaluate the\nstrengths and limitations of each model and suggest directions for future\nresearch in this field. Our goal is to provide a comprehensive review about the\nuse of deep generative models for medical image augmentation and to highlight\nthe potential of these models for improving the performance of deep learning\nalgorithms in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2307.13125"
            },
            {
                "文章ID": "119919",
                "标题": "Survey on deep learning in multimodal medical imaging for cancer\n  detection",
                "作者": " Yan Tian,  Zhaocheng Xu,  Yujun Ma,  Weiping Ding,  Ruili Wang,  Zhihong Gao,  Guohua Cheng,  Linyang He,  Xuran Zhao",
                "发布日期": "2023-12-06",
                "摘要": "  The task of multimodal cancer detection is to determine the locations and\ncategories of lesions by using different imaging techniques, which is one of\nthe key research methods for cancer diagnosis. Recently, deep learning-based\nobject detection has made significant developments due to its strength in\nsemantic feature extraction and nonlinear function fitting. However, multimodal\ncancer detection remains challenging due to morphological differences in\nlesions, interpatient variability, difficulty in annotation, and imaging\nartifacts. In this survey, we mainly investigate over 150 papers in recent\nyears with respect to multimodal cancer detection using deep learning, with a\nfocus on datasets and solutions to various challenges such as data annotation,\nvariance between classes, small-scale lesions, and occlusion. We also provide\nan overview of the advantages and drawbacks of each approach. Finally, we\ndiscuss the current scope of work and provide directions for the future\ndevelopment of multimodal cancer detection.\n",
                "链接": "https://arxiv.org/abs/2312.01573"
            },
            {
                "文章ID": "36855",
                "标题": "Reproducibility in machine learning for medical imaging",
                "作者": " Olivier Colliot,  Elina Thibeau-Sutre,  Ninon Burgos",
                "发布日期": "2022-09-13",
                "摘要": "  Reproducibility is a cornerstone of science, as the replication of findings\nis the process through which they become knowledge. It is widely considered\nthat many fields of science are undergoing a reproducibility crisis. This has\nled to the publications of various guidelines in order to improve research\nreproducibility.\n  This didactic chapter intends at being an introduction to reproducibility for\nresearchers in the field of machine learning for medical imaging. We first\ndistinguish between different types of reproducibility. For each of them, we\naim at defining it, at describing the requirements to achieve it and at\ndiscussing its utility. The chapter ends with a discussion on the benefits of\nreproducibility and with a plea for a non-dogmatic approach to this concept and\nits implementation in research practice.\n",
                "链接": "https://arxiv.org/abs/2209.05097"
            }
        ]
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和脑科学交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "105384",
                "标题": "In-Context Learning in Large Language Models: A Neuroscience-inspired\n  Analysis of Representations",
                "作者": " Safoora Yousefi,  Leo Betthauser,  Hosein Hasanbeig,  Akanksha Saran,  Raphaël Millière,  Ida Momennejad",
                "发布日期": "2023-10-19",
                "摘要": "  Large language models (LLMs) exhibit remarkable performance improvement\nthrough in-context learning (ICL) by leveraging task-specific examples in the\ninput. However, the mechanisms behind this improvement remain elusive. In this\nwork, we investigate embeddings and attention representations in Llama-2 70B\nand Vicuna 13B. Specifically, we study how embeddings and attention change\nafter in-context-learning, and how these changes mediate improvement in\nbehavior. We employ neuroscience-inspired techniques, such as representational\nsimilarity analysis (RSA), and propose novel methods for parameterized probing\nand attention ratio analysis (ARA, measuring the ratio of attention to relevant\nvs. irrelevant information). We designed three tasks with a priori\nrelationships among their conditions: reading comprehension, linear regression,\nand adversarial prompt injection. We formed hypotheses about expected\nsimilarities in task representations to investigate latent changes in\nembeddings and attention. Our analyses revealed a meaningful correlation\nbetween changes in both embeddings and attention representations with\nimprovements in behavioral performance after ICL. This empirical framework\nempowers a nuanced understanding of how latent representations affect LLM\nbehavior with and without ICL, offering valuable tools and insights for future\nresearch and practical applications.\n",
                "链接": "https://arxiv.org/abs/2310.00313"
            },
            {
                "文章ID": "79552",
                "标题": "A Study of Generative Large Language Model for Medical Research and\n  Healthcare",
                "作者": " Cheng Peng,  Xi Yang,  Aokun Chen,  Kaleb E Smith,  Nima PourNejatian,  Anthony B Costa,  Cheryl Martin,  Mona G Flores,  Ying Zhang,  Tanja Magoc,  Gloria Lipori,  Duane A Mitchell,  Naykky S Ospina,  Mustafa M Ahmed,  William R Hogan,  Elizabeth A Shenkman,  Yi Guo,  Jiang Bian,  Yonghui Wu",
                "发布日期": "2023-11-20",
                "摘要": "  There is enormous enthusiasm and concerns in using large language models\n(LLMs) in healthcare, yet current assumptions are all based on general-purpose\nLLMs such as ChatGPT. This study develops a clinical generative LLM,\nGatorTronGPT, using 277 billion words of mixed clinical and English text with a\nGPT-3 architecture of 20 billion parameters. GatorTronGPT improves biomedical\nnatural language processing for medical research. Synthetic NLP models trained\nusing GatorTronGPT generated text outperform NLP models trained using\nreal-world clinical text. Physicians Turing test using 1 (worst) to 9 (best)\nscale shows that there is no significant difference in linguistic readability\n(p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical\nrelevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that\nphysicians cannot differentiate them (p < 0.001). This study provides insights\non the opportunities and challenges of LLMs for medical research and\nhealthcare.\n",
                "链接": "https://arxiv.org/abs/2305.13523"
            },
            {
                "文章ID": "98470",
                "标题": "SciEval: A Multi-Level Large Language Model Evaluation Benchmark for\n  Scientific Research",
                "作者": " Liangtai Sun,  Yang Han,  Zihan Zhao,  Da Ma,  Zhennan Shen,  Baocai Chen,  Lu Chen,  Kai Yu",
                "发布日期": "2023-08-28",
                "摘要": "  Recently, there has been growing interest in using Large Language Models\n(LLMs) for scientific research. Numerous benchmarks have been proposed to\nevaluate the ability of LLMs for scientific research. However, current\nbenchmarks are mostly based on pre-collected objective questions. This design\nsuffers from data leakage problem and lacks the evaluation of subjective Q/A\nability. In this paper, we propose SciEval, a comprehensive and\nmulti-disciplinary evaluation benchmark to address these issues. Based on\nBloom's taxonomy, SciEval covers four dimensions to systematically evaluate\nscientific research ability. In particular, we design a \"dynamic\" subset based\non scientific principles to prevent evaluation from potential data leakage.\nBoth objective and subjective questions are included in SciEval. These\ncharacteristics make SciEval a more effective benchmark for scientific research\nability evaluation of LLMs. Comprehensive experiments on most advanced LLMs\nshow that, although GPT-4 achieves SOTA performance compared to other LLMs,\nthere is still substantial room for improvement, especially for dynamic\nquestions. The data and codes are now publicly available.\n",
                "链接": "https://arxiv.org/abs/2308.13149"
            },
            {
                "文章ID": "106494",
                "标题": "Benchmarking Large Language Models As AI Research Agents",
                "作者": " Qian Huang,  Jian Vora,  Percy Liang,  Jure Leskovec",
                "发布日期": "2023-10-06",
                "摘要": "  Scientific experimentation involves an iterative process of creating\nhypotheses, designing experiments, running experiments, and analyzing the\nresults. Can we build AI research agents to perform these long-horizon tasks?\nTo take a step towards building and evaluating research agents on such\nopen-ended decision-making tasks, we focus on the problem of machine learning\nengineering: given a task description and a dataset, build a high-performing\nmodel. In this paper, we propose MLAgentBench, a suite of ML tasks for\nbenchmarking AI research agents. Agents can perform actions like\nreading/writing files, executing code, and inspecting outputs. With these\nactions, agents could run experiments, analyze the results, and modify the code\nof entire machine learning pipelines, such as data processing, architecture,\ntraining processes, etc. The benchmark then automatically evaluates the agent's\nperformance objectively over various metrics related to performance and\nefficiency. We also design an LLM-based research agent to automatically perform\nexperimentation loops in such an environment. Empirically, we find that a\nGPT-4-based research agent can feasibly build compelling ML models over many\ntasks in MLAgentBench, displaying highly interpretable plans and actions.\nHowever, the success rates vary considerably; they span from almost 90\\% on\nwell-established older datasets to as low as 10\\% on recent Kaggle Challenges\n-- unavailable during the LLM model's pretraining -- and even 0\\% on newer\nresearch challenges like BabyLM. Finally, we identify several key challenges\nfor LLM-based research agents such as long-term planning and hallucination. Our\ncode is released at https://github.com/snap-stanford/MLAgentBench.\n",
                "链接": "https://arxiv.org/abs/2310.03302"
            },
            {
                "文章ID": "112056",
                "标题": "Large-scale Foundation Models and Generative AI for BigData Neuroscience",
                "作者": " Ran Wang,  Zhe Sage Chen",
                "发布日期": "2023-10-31",
                "摘要": "  Recent advances in machine learning have made revolutionary breakthroughs in\ncomputer games, image and natural language understanding, and scientific\ndiscovery. Foundation models and large-scale language models (LLMs) have\nrecently achieved human-like intelligence thanks to BigData. With the help of\nself-supervised learning (SSL) and transfer learning, these models may\npotentially reshape the landscapes of neuroscience research and make a\nsignificant impact on the future. Here we present a mini-review on recent\nadvances in foundation models and generative AI models as well as their\napplications in neuroscience, including natural language and speech, semantic\nmemory, brain-machine interfaces (BMIs), and data augmentation. We argue that\nthis paradigm-shift framework will open new avenues for many neuroscience\nresearch directions and discuss the accompanying challenges and opportunities.\n",
                "链接": "https://arxiv.org/abs/2310.18377"
            },
            {
                "文章ID": "83258",
                "标题": "A Quantitative Review on Language Model Efficiency Research",
                "作者": " Meng Jiang,  Hy Dang,  Lingbo Tong",
                "发布日期": "2023-06-06",
                "摘要": "  Language models (LMs) are being scaled and becoming powerful. Improving their\nefficiency is one of the core research topics in neural information processing\nsystems. Tay et al. (2022) provided a comprehensive overview of efficient\nTransformers that have become an indispensable staple in the field of NLP.\nHowever, in the section of \"On Evaluation\", they left an open question \"which\nfundamental efficient Transformer one should consider,\" answered by \"still a\nmystery\" because \"many research papers select their own benchmarks.\"\nUnfortunately, there was not quantitative analysis about the performances of\nTransformers on any benchmarks. Moreover, state space models (SSMs) have\ndemonstrated their abilities of modeling long-range sequences with\nnon-attention mechanisms, which were not discussed in the prior review. This\narticle makes a meta analysis on the results from a set of papers on efficient\nTransformers as well as those on SSMs. It provides a quantitative review on LM\nefficiency research and gives suggestions for future research.\n",
                "链接": "https://arxiv.org/abs/2306.01768"
            },
            {
                "文章ID": "71835",
                "标题": "Emergent autonomous scientific research capabilities of large language\n  models",
                "作者": " Daniil A. Boiko,  Robert MacKnight,  Gabe Gomes",
                "发布日期": "2023-04-12",
                "摘要": "  Transformer-based large language models are rapidly advancing in the field of\nmachine learning research, with applications spanning natural language,\nbiology, chemistry, and computer programming. Extreme scaling and reinforcement\nlearning from human feedback have significantly improved the quality of\ngenerated text, enabling these models to perform various tasks and reason about\ntheir choices. In this paper, we present an Intelligent Agent system that\ncombines multiple large language models for autonomous design, planning, and\nexecution of scientific experiments. We showcase the Agent's scientific\nresearch capabilities with three distinct examples, with the most complex being\nthe successful performance of catalyzed cross-coupling reactions. Finally, we\ndiscuss the safety implications of such systems and propose measures to prevent\ntheir misuse.\n",
                "链接": "https://arxiv.org/abs/2304.05332"
            },
            {
                "文章ID": "101124",
                "标题": "Toward Reproducing Network Research Results Using Large Language Models",
                "作者": " Qiao Xiang,  Yuling Lin,  Mingjun Fang,  Bang Huang,  Siyong Huang,  Ridi Wen,  Franck Le,  Linghe Kong,  Jiwu Shu",
                "发布日期": "2023-09-12",
                "摘要": "  Reproducing research results in the networking community is important for\nboth academia and industry. The current best practice typically resorts to\nthree approaches: (1) looking for publicly available prototypes; (2) contacting\nthe authors to get a private prototype; and (3) manually implementing a\nprototype following the description of the publication. However, most published\nnetwork research does not have public prototypes and private prototypes are\nhard to get. As such, most reproducing efforts are spent on manual\nimplementation based on the publications, which is both time and labor\nconsuming and error-prone. In this paper, we boldly propose reproducing network\nresearch results using the emerging large language models (LLMs). In\nparticular, we first prove its feasibility with a small-scale experiment, in\nwhich four students with essential networking knowledge each reproduces a\ndifferent networking system published in prominent conferences and journals by\nprompt engineering ChatGPT. We report the experiment's observations and lessons\nand discuss future open research questions of this proposal. This work raises\nno ethical issue.\n",
                "链接": "https://arxiv.org/abs/2309.04716"
            },
            {
                "文章ID": "76562",
                "标题": "Large Language Model Programs",
                "作者": " Imanol Schlag,  Sainbayar Sukhbaatar,  Asli Celikyilmaz,  Wen-tau Yih,  Jason Weston,  Jürgen Schmidhuber,  Xian Li",
                "发布日期": "2023-05-10",
                "摘要": "  In recent years, large pre-trained language models (LLMs) have demonstrated\nthe ability to follow instructions and perform novel tasks from a few examples.\nThe possibility to parameterise an LLM through such in-context examples widens\ntheir capability at a much lower cost than finetuning. We extend this line of\nreasoning and present a method which further expands the capabilities of an LLM\nby embedding it within an algorithm or program. To demonstrate the benefits of\nthis approach, we present an illustrative example of evidence-supported\nquestion-answering. We obtain a 6.4\\% improvement over the chain of thought\nbaseline through a more algorithmic approach without any finetuning.\nFurthermore, we highlight recent work from this perspective and discuss the\nadvantages and disadvantages in comparison to the standard approaches.\n",
                "链接": "https://arxiv.org/abs/2305.05364"
            },
            {
                "文章ID": "109237",
                "标题": "Large Language Model Unlearning",
                "作者": " Yuanshun Yao,  Xiaojun Xu,  Yang Liu",
                "发布日期": "2023-10-18",
                "摘要": "  We study how to perform unlearning, i.e. forgetting undesirable\n(mis)behaviors, on large language models (LLMs). We show at least three\nscenarios of aligning LLMs with human preferences can benefit from unlearning:\n(1) removing harmful responses, (2) erasing copyright-protected content as\nrequested, and (3) eliminating hallucinations. Unlearning, as an alignment\ntechnique, has three advantages. (1) It only requires negative (e.g. harmful)\nexamples, which are much easier and cheaper to collect (e.g. via red teaming or\nuser reporting) than positive (e.g. helpful and often human-written) examples\nrequired in RLHF (RL from human feedback). (2) It is computationally efficient.\n(3) It is especially effective when we know which training samples cause the\nmisbehavior. To the best of our knowledge, our work is among the first to\nexplore LLM unlearning. We are also among the first to formulate the settings,\ngoals, and evaluations in LLM unlearning. We show that if practitioners only\nhave limited resources, and therefore the priority is to stop generating\nundesirable outputs rather than to try to generate desirable outputs,\nunlearning is particularly appealing. Despite only having negative samples, our\nablation study shows that unlearning can still achieve better alignment\nperformance than RLHF with just 2% of its computational time.\n",
                "链接": "https://arxiv.org/abs/2310.10683"
            }
        ]
    },
    {
        "question": {
            "question": "2022年后与AI for Science相关的综述论文",
            "type": "6"
        },
        "results": []
    },
    {
        "question": {
            "question": "对比解码综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "35198",
                "标题": "Podcast Summary Assessment: A Resource for Evaluating Summary Assessment\n  Methods",
                "作者": " Potsawee Manakul,  Mark J. F. Gales",
                "发布日期": "2022-08-30",
                "摘要": "  Automatic summary assessment is useful for both machine-generated and\nhuman-produced summaries. Automatically evaluating the summary text given the\ndocument enables, for example, summary generation system development and\ndetection of inappropriate summaries. Summary assessment can be run in a number\nof modes: ranking summary generation systems; ranking summaries of a particular\ndocument; and estimating the quality of a document-summary pair on an absolute\nscale. Existing datasets with annotation for summary assessment are usually\nbased on news summarization datasets such as CNN/DailyMail or XSum. In this\nwork, we describe a new dataset, the podcast summary assessment corpus, a\ncollection of podcast summaries that were evaluated by human experts at\nTREC2020. Compared to existing summary assessment data, this dataset has two\nunique aspects: (i) long-input, speech podcast based, documents; and (ii) an\nopportunity to detect inappropriate reference summaries in podcast corpus.\nFirst, we examine existing assessment methods, including model-free and\nmodel-based methods, and provide benchmark results for this long-input summary\nassessment dataset. Second, with the aim of filtering reference\nsummary-document pairings for training, we apply summary assessment for data\nselection. The experimental results on these two aspects provide interesting\ninsights on the summary assessment and generation tasks. The podcast summary\nassessment data is available.\n",
                "链接": "https://arxiv.org/abs/2208.13265"
            },
            {
                "文章ID": "43109",
                "标题": "Towards Summary Candidates Fusion",
                "作者": " Mathieu Ravaut,  Shafiq Joty,  Nancy F. Chen",
                "发布日期": "2023-05-29",
                "摘要": "  Sequence-to-sequence deep neural models fine-tuned for abstractive\nsummarization can achieve great performance on datasets with enough human\nannotations. Yet, it has been shown that they have not reached their full\npotential, with a wide gap between the top beam search output and the oracle\nbeam. Recently, re-ranking methods have been proposed, to learn to select a\nbetter summary candidate. However, such methods are limited by the summary\nquality aspects captured by the first-stage candidates. To bypass this\nlimitation, we propose a new paradigm in second-stage abstractive summarization\ncalled SummaFusion that fuses several summary candidates to produce a novel\nabstractive second-stage summary. Our method works well on several\nsummarization datasets, improving both the ROUGE scores and qualitative\nproperties of fused summaries. It is especially good when the candidates to\nfuse are worse, such as in the few-shot setup where we set a new\nstate-of-the-art. We will make our code and checkpoints available at\nhttps://github.com/ntunlp/SummaFusion/.\n",
                "链接": "https://arxiv.org/abs/2210.08779"
            },
            {
                "文章ID": "18214",
                "标题": "Summary Markov Models for Event Sequences",
                "作者": " Debarun Bhattacharjya,  Saurabh Sihag,  Oktie Hassanzadeh,  Liza Bialik",
                "发布日期": "2022-05-09",
                "摘要": "  Datasets involving sequences of different types of events without meaningful\ntime stamps are prevalent in many applications, for instance when extracted\nfrom textual corpora. We propose a family of models for such event sequences --\nsummary Markov models -- where the probability of observing an event type\ndepends only on a summary of historical occurrences of its influencing set of\nevent types. This Markov model family is motivated by Granger causal models for\ntime series, with the important distinction that only one event can occur in a\nposition in an event sequence. We show that a unique minimal influencing set\nexists for any set of event types of interest and choice of summary function,\nformulate two novel models from the general family that represent specific\nsequence dynamics, and propose a greedy search algorithm for learning them from\nevent sequence data. We conduct an experimental investigation comparing the\nproposed models with relevant baselines, and illustrate their knowledge\nacquisition and discovery capabilities through case studies involving sequences\nfrom text.\n",
                "链接": "https://arxiv.org/abs/2205.03375"
            },
            {
                "文章ID": "46790",
                "标题": "Book Cover Synthesis from the Summary",
                "作者": " Emdadul Haque,  Md. Faraz Kabir Khan,  Mohammad Imrul Jubair,  Jarin Anjum,  Abrar Zahir Niloy",
                "发布日期": "2022-11-07",
                "摘要": "  The cover is the face of a book and is a point of attraction for the readers.\nDesigning book covers is an essential task in the publishing industry. One of\nthe main challenges in creating a book cover is representing the theme of the\nbook's content in a single image. In this research, we explore ways to produce\na book cover using artificial intelligence based on the fact that there exists\na relationship between the summary of the book and its cover. Our key\nmotivation is the application of text-to-image synthesis methods to generate\nimages from given text or captions. We explore several existing text-to-image\nconversion techniques for this purpose and propose an approach to exploit these\nframeworks for producing book covers from provided summaries. We construct a\ndataset of English books that contains a large number of samples of summaries\nof existing books and their cover images. In this paper, we describe our\napproach to collecting, organizing, and pre-processing the dataset to use it\nfor training models. We apply different text-to-image synthesis techniques to\ngenerate book covers from the summary and exhibit the results in this paper.\n",
                "链接": "https://arxiv.org/abs/2211.02138"
            },
            {
                "文章ID": "56035",
                "标题": "A Succinct Summary of Reinforcement Learning",
                "作者": " Sanjeevan Ahilan",
                "发布日期": "2023-01-05",
                "摘要": "  This document is a concise summary of many key results in single-agent\nreinforcement learning (RL). The intended audience are those who already have\nsome familiarity with RL and are looking to review, reference and/or remind\nthemselves of important ideas in the field.\n",
                "链接": "https://arxiv.org/abs/2301.01379"
            },
            {
                "文章ID": "64690",
                "标题": "Summary Statistic Privacy in Data Sharing",
                "作者": " Zinan Lin,  Shuaiqi Wang,  Vyas Sekar,  Giulia Fanti",
                "发布日期": "2023-10-31",
                "摘要": "  We study a setting where a data holder wishes to share data with a receiver,\nwithout revealing certain summary statistics of the data distribution (e.g.,\nmean, standard deviation). It achieves this by passing the data through a\nrandomization mechanism. We propose summary statistic privacy, a metric for\nquantifying the privacy risk of such a mechanism based on the worst-case\nprobability of an adversary guessing the distributional secret within some\nthreshold. Defining distortion as a worst-case Wasserstein-1 distance between\nthe real and released data, we prove lower bounds on the tradeoff between\nprivacy and distortion. We then propose a class of quantization mechanisms that\ncan be adapted to different data distributions. We show that the quantization\nmechanism's privacy-distortion tradeoff matches our lower bounds under certain\nregimes, up to small constant factors. Finally, we demonstrate on real-world\ndatasets that the proposed quantization mechanisms achieve better\nprivacy-distortion tradeoffs than alternative privacy mechanisms.\n",
                "链接": "https://arxiv.org/abs/2303.02014"
            },
            {
                "文章ID": "16150",
                "标题": "A Summary of the ALQAC 2021 Competition",
                "作者": " Nguyen Ha Thanh,  Bui Minh Quan,  Chau Nguyen,  Tung Le,  Nguyen Minh Phuong,  Dang Tran Binh,  Vuong Thi Hai Yen,  Teeradaj Racharak,  Nguyen Le Minh,  Tran Duc Vu,  Phan Viet Anh,  Nguyen Truong Son,  Huy Tien Nguyen,  Bhumindr Butr-indr,  Peerapon Vateekul,  Prachya Boonkwan",
                "发布日期": "2022-04-26",
                "摘要": "  We summarize the evaluation of the first Automated Legal Question Answering\nCompetition (ALQAC 2021). The competition this year contains three tasks, which\naims at processing the statute law document, which are Legal Text Information\nRetrieval (Task 1), Legal Text Entailment Prediction (Task 2), and Legal Text\nQuestion Answering (Task 3). The final goal of these tasks is to build a system\nthat can automatically determine whether a particular statement is lawful.\nThere is no limit to the approaches of the participating teams. This year,\nthere are 5 teams participating in Task 1, 6 teams participating in Task 2, and\n5 teams participating in Task 3. There are in total 36 runs submitted to the\norganizer. In this paper, we summarize each team's approaches, official\nresults, and some discussion about the competition. Only results of the teams\nwho successfully submit their approach description paper are reported in this\npaper.\n",
                "链接": "https://arxiv.org/abs/2204.10717"
            },
            {
                "文章ID": "49805",
                "标题": "HaRiM$^+$: Evaluating Summary Quality with Hallucination Risk",
                "作者": " Seonil Son,  Junsoo Park,  Jeong-in Hwang,  Junghwa Lee,  Hyungjong Noh,  Yeonsoo Lee",
                "发布日期": "2022-11-28",
                "摘要": "  One of the challenges of developing a summarization model arises from the\ndifficulty in measuring the factual inconsistency of the generated text. In\nthis study, we reinterpret the decoder overconfidence-regularizing objective\nsuggested in (Miao et al., 2021) as a hallucination risk measurement to better\nestimate the quality of generated summaries. We propose a reference-free\nmetric, HaRiM+, which only requires an off-the-shelf summarization model to\ncompute the hallucination risk based on token likelihoods. Deploying it\nrequires no additional training of models or ad-hoc modules, which usually need\nalignment to human judgments. For summary-quality estimation, HaRiM+ records\nstate-of-the-art correlation to human judgment on three summary-quality\nannotation sets: FRANK, QAGS, and SummEval. We hope that our work, which merits\nthe use of summarization models, facilitates the progress of both automated\nevaluation and generation of summary.\n",
                "链接": "https://arxiv.org/abs/2211.12118"
            },
            {
                "文章ID": "60635",
                "标题": "Leveraging Summary Guidance on Medical Report Summarization",
                "作者": " Yunqi Zhu,  Xuebing Yang,  Yuanyuan Wu,  Wensheng Zhang",
                "发布日期": "2023-02-09",
                "摘要": "  This study presents three deidentified large medical text datasets, named\nDISCHARGE, ECHO and RADIOLOGY, which contain 50K, 16K and 378K pairs of report\nand summary that are derived from MIMIC-III, respectively. We implement\nconvincing baselines of automated abstractive summarization on the proposed\ndatasets with pre-trained encoder-decoder language models, including BERT2BERT,\nT5-large and BART. Further, based on the BART model, we leverage the sampled\nsummaries from the train set as prior knowledge guidance, for encoding\nadditional contextual representations of the guidance with the encoder and\nenhancing the decoding representations in the decoder. The experimental results\nconfirm the improvement of ROUGE scores and BERTScore made by the proposed\nmethod, outperforming the larger model T5-large.\n",
                "链接": "https://arxiv.org/abs/2302.04001"
            },
            {
                "文章ID": "73962",
                "标题": "Diabetic Foot Ulcer Grand Challenge 2022 Summary",
                "作者": " Connah Kendrick,  Bill Cassidy,  Neil D. Reeves,  Joseph M. Pappachan,  Claire O'Shea,  Vishnu Chandrabalan,  Moi Hoon Yap",
                "发布日期": "2023-04-25",
                "摘要": "  The Diabetic Foot Ulcer Challenge 2022 focused on the task of diabetic foot\nulcer segmentation, based on the work completed in previous DFU challenges. The\nchallenge provided 4000 images of full-view foot ulcer images together with\ncorresponding delineation of ulcer regions. This paper provides an overview of\nthe challenge, a summary of the methods proposed by the challenge participants,\nthe results obtained from each technique, and a comparison of the challenge\nresults. The best-performing network was a modified HarDNet-MSEG, with a Dice\nscore of 0.7287.\n",
                "链接": "https://arxiv.org/abs/2304.12001"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于通过prompt经验性研究大语言模型行为的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "114612",
                "标题": "Prompt Sketching for Large Language Models",
                "作者": " Luca Beurer-Kellner,  Mark Niklas Müller,  Marc Fischer,  Martin Vechev",
                "发布日期": "2023-11-10",
                "摘要": "  Many recent prompting strategies for large language models (LLMs) query the\nmodel multiple times sequentially -- first to produce intermediate results and\nthen the final answer. However, using these methods, both decoder and model are\nunaware of potential follow-up prompts, leading to disconnected and undesirably\nwordy intermediate responses. In this work, we address this issue by proposing\nprompt sketching, a new prompting paradigm in which an LLM does not only\nrespond by completing a prompt, but by predicting values for multiple variables\nin a template. This way, sketching grants users more control over the\ngeneration process, e.g., by providing a reasoning framework via intermediate\ninstructions, leading to better overall results. The key idea enabling\nsketching with existing, autoregressive models is to adapt the decoding\nprocedure to also score follow-up instructions during text generation, thus\noptimizing overall template likelihood in inference. Our experiments show that\nin a zero-shot setting, prompt sketching outperforms existing, sequential\nprompting schemes such as direct asking or chain-of-thought on 7 out of 8 LLM\nbenchmarking tasks, including state tracking, arithmetic reasoning, and general\nquestion answering. To facilitate future use, we release a number of generic,\nyet effective sketches applicable to many tasks, and an open source library\ncalled dclib, powering our sketch-aware decoders.\n",
                "链接": "https://arxiv.org/abs/2311.04954"
            },
            {
                "文章ID": "102889",
                "标题": "Explaining Agent Behavior with Large Language Models",
                "作者": " Xijia Zhang,  Yue Guo,  Simon Stepputtis,  Katia Sycara,  Joseph Campbell",
                "发布日期": "2023-09-20",
                "摘要": "  Intelligent agents such as robots are increasingly deployed in real-world,\nsafety-critical settings. It is vital that these agents are able to explain the\nreasoning behind their decisions to human counterparts, however, their behavior\nis often produced by uninterpretable models such as deep neural networks. We\npropose an approach to generate natural language explanations for an agent's\nbehavior based only on observations of states and actions, agnostic to the\nunderlying model representation. We show how a compact representation of the\nagent's behavior can be learned and used to produce plausible explanations with\nminimal hallucination while affording user interaction with a pre-trained large\nlanguage model. Through user studies and empirical experiments, we show that\nour approach generates explanations as helpful as those generated by a human\ndomain expert while enabling beneficial interactions such as clarification and\ncounterfactual queries.\n",
                "链接": "https://arxiv.org/abs/2309.10346"
            },
            {
                "文章ID": "119665",
                "标题": "Large Language Models for Travel Behavior Prediction",
                "作者": " Baichuan Mo,  Hanyong Xu,  Dingyi Zhuang,  Ruoyun Ma,  Xiaotong Guo,  Jinhua Zhao",
                "发布日期": "2023-12-05",
                "摘要": "  Travel behavior prediction is a fundamental task in transportation demand\nmanagement. The conventional methods for travel behavior prediction rely on\nnumerical data to construct mathematical models and calibrate model parameters\nto represent human preferences. Recent advancement in large language models\n(LLMs) has shown great reasoning abilities to solve complex problems. In this\nstudy, we propose to use LLMs to predict travel behavior with prompt\nengineering without data-based parameter learning. Specifically, we carefully\ndesign our prompts that include 1) task description, 2) travel characteristics,\n3) individual attributes, and 4) guides of thinking with domain knowledge, and\nask the LLMs to predict an individual's travel behavior and explain the\nresults. We select the travel mode choice task as a case study. Results show\nthat, though no training samples are provided, LLM-based predictions have\ncompetitive accuracy and F1-score as canonical supervised learning methods such\nas multinomial logit, random forest, and neural networks. LLMs can also output\nreasons that support their prediction. However, though in most of the cases,\nthe output explanations are reasonable, we still observe cases that violate\nlogic or with hallucinations.\n",
                "链接": "https://arxiv.org/abs/2312.00819"
            },
            {
                "文章ID": "73058",
                "标题": "Promptify: Text-to-Image Generation through Interactive Prompt\n  Exploration with Large Language Models",
                "作者": " Stephen Brade,  Bryan Wang,  Mauricio Sousa,  Sageev Oore,  Tovi Grossman",
                "发布日期": "2023-04-20",
                "摘要": "  Text-to-image generative models have demonstrated remarkable capabilities in\ngenerating high-quality images based on textual prompts. However, crafting\nprompts that accurately capture the user's creative intent remains challenging.\nIt often involves laborious trial-and-error procedures to ensure that the model\ninterprets the prompts in alignment with the user's intention. To address the\nchallenges, we present Promptify, an interactive system that supports prompt\nexploration and refinement for text-to-image generative models. Promptify\nutilizes a suggestion engine powered by large language models to help users\nquickly explore and craft diverse prompts. Our interface allows users to\norganize the generated images flexibly, and based on their preferences,\nPromptify suggests potential changes to the original prompt. This feedback loop\nenables users to iteratively refine their prompts and enhance desired features\nwhile avoiding unwanted ones. Our user study shows that Promptify effectively\nfacilitates the text-to-image workflow and outperforms an existing baseline\ntool widely used for text-to-image generation.\n",
                "链接": "https://arxiv.org/abs/2304.09337"
            },
            {
                "文章ID": "98834",
                "标题": "Large Language Models Streamline Automated Machine Learning for Clinical\n  Studies",
                "作者": " Soroosh Tayebi Arasteh,  Tianyu Han,  Mahshad Lotfinia,  Christiane Kuhl,  Jakob Nikolas Kather,  Daniel Truhn,  Sven Nebelung",
                "发布日期": "2023-10-11",
                "摘要": "  A knowledge gap persists between machine learning (ML) developers (e.g., data\nscientists) and practitioners (e.g., clinicians), hampering the full\nutilization of ML for clinical data analysis. We investigated the potential of\nthe ChatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge this\ngap and perform ML analyses efficiently. Real-world clinical datasets and study\ndetails from large trials across various medical specialties were presented to\nChatGPT ADA without specific guidance. ChatGPT ADA autonomously developed\nstate-of-the-art ML models based on the original study's training data to\npredict clinical outcomes such as cancer development, cancer progression,\ndisease complications, or biomarkers such as pathogenic gene sequences.\nFollowing the re-implementation and optimization of the published models, the\nhead-to-head comparison of the ChatGPT ADA-crafted ML models and their\nrespective manually crafted counterparts revealed no significant differences in\ntraditional performance metrics (P>0.474). Strikingly, the ChatGPT ADA-crafted\nML models often outperformed their counterparts. In conclusion, ChatGPT ADA\noffers a promising avenue to democratize ML in medicine by simplifying complex\ndata analyses, yet should enhance, not replace, specialized training and\nresources, to promote broader applications in medical research and practice.\n",
                "链接": "https://arxiv.org/abs/2308.14120"
            },
            {
                "文章ID": "72018",
                "标题": "Boosted Prompt Ensembles for Large Language Models",
                "作者": " Silviu Pitis,  Michael R. Zhang,  Andrew Wang,  Jimmy Ba",
                "发布日期": "2023-04-13",
                "摘要": "  Methods such as chain-of-thought prompting and self-consistency have pushed\nthe frontier of language model reasoning performance with no additional\ntraining. To further improve performance, we propose a prompt ensembling method\nfor large language models, which uses a small dataset to construct a set of few\nshot prompts that together comprise a ``boosted prompt ensemble''. The few shot\nexamples for each prompt are chosen in a stepwise fashion to be ``hard''\nexamples on which the previous step's ensemble is uncertain. We show that this\noutperforms single-prompt output-space ensembles and bagged prompt-space\nensembles on the GSM8k and AQuA datasets, among others. We propose both\ntrain-time and test-time versions of boosted prompting that use different\nlevels of available annotation and conduct a detailed empirical study of our\nalgorithm.\n",
                "链接": "https://arxiv.org/abs/2304.05970"
            },
            {
                "文章ID": "85594",
                "标题": "Understanding Telecom Language Through Large Language Models",
                "作者": " Lina Bariah,  Hang Zou,  Qiyang Zhao,  Belkacem Mouhouche,  Faouzi Bader,  Merouane Debbah",
                "发布日期": "2023-06-14",
                "摘要": "  The recent progress of artificial intelligence (AI) opens up new frontiers in\nthe possibility of automating many tasks involved in Telecom networks design,\nimplementation, and deployment. This has been further pushed forward with the\nevolution of generative artificial intelligence (AI), including the emergence\nof large language models (LLMs), which is believed to be the cornerstone toward\nrealizing self-governed, interactive AI agents. Motivated by this, in this\npaper, we aim to adapt the paradigm of LLMs to the Telecom domain. In\nparticular, we fine-tune several LLMs including BERT, distilled BERT, RoBERTa\nand GPT-2, to the Telecom domain languages, and demonstrate a use case for\nidentifying the 3rd Generation Partnership Project (3GPP) standard working\ngroups. We consider training the selected models on 3GPP technical documents\n(Tdoc) pertinent to years 2009-2019 and predict the Tdoc categories in years\n2020-2023. The results demonstrate that fine-tuning BERT and RoBERTa model\nachieves 84.6% accuracy, while GPT-2 model achieves 83% in identifying 3GPP\nworking groups. The distilled BERT model with around 50% less parameters\nachieves similar performance as others. This corroborates that fine-tuning\npretrained LLM can effectively identify the categories of Telecom language. The\ndeveloped framework shows a stepping stone towards realizing intent-driven and\nself-evolving wireless networks from Telecom languages, and paves the way for\nthe implementation of generative AI in the Telecom domain.\n",
                "链接": "https://arxiv.org/abs/2306.07933"
            },
            {
                "文章ID": "61193",
                "标题": "Level Generation Through Large Language Models",
                "作者": " Graham Todd,  Sam Earle,  Muhammad Umair Nasir,  Michael Cerny Green,  Julian Togelius",
                "发布日期": "2023-06-02",
                "摘要": "  Large Language Models (LLMs) are powerful tools, capable of leveraging their\ntraining on natural language to write stories, generate code, and answer\nquestions. But can they generate functional video game levels? Game levels,\nwith their complex functional constraints and spatial relationships in more\nthan one dimension, are very different from the kinds of data an LLM typically\nsees during training. Datasets of game levels are also hard to come by,\npotentially taxing the abilities of these data-hungry models. We investigate\nthe use of LLMs to generate levels for the game Sokoban, finding that LLMs are\nindeed capable of doing so, and that their performance scales dramatically with\ndataset size. We also perform preliminary experiments on controlling LLM level\ngenerators and discuss promising areas for future work.\n",
                "链接": "https://arxiv.org/abs/2302.05817"
            },
            {
                "文章ID": "81715",
                "标题": "Practical PCG Through Large Language Models",
                "作者": " Muhammad U Nasir,  Julian Togelius",
                "发布日期": "2023-07-04",
                "摘要": "  Large Language Models (LLMs) have proven to be useful tools in various\ndomains outside of the field of their inception, which was natural language\nprocessing. In this study, we provide practical directions on how to use LLMs\nto generate 2D-game rooms for an under-development game, named Metavoidal. Our\ntechnique can harness the power of GPT-3 by Human-in-the-loop fine-tuning which\nallows our method to create 37% Playable-Novel levels from as scarce data as\nonly 60 hand-designed rooms under a scenario of the non-trivial game, with\nrespect to (Procedural Content Generation) PCG, that has a good amount of local\nand global constraints.\n",
                "链接": "https://arxiv.org/abs/2305.18243"
            },
            {
                "文章ID": "46722",
                "标题": "Large Language Models Are Human-Level Prompt Engineers",
                "作者": " Yongchao Zhou,  Andrei Ioan Muresanu,  Ziwen Han,  Keiran Paster,  Silviu Pitis,  Harris Chan,  Jimmy Ba",
                "发布日期": "2023-03-13",
                "摘要": "  By conditioning on natural language instructions, large language models\n(LLMs) have displayed impressive capabilities as general-purpose computers.\nHowever, task performance depends significantly on the quality of the prompt\nused to steer the model, and most effective prompts have been handcrafted by\nhumans. Inspired by classical program synthesis and the human approach to\nprompt engineering, we propose Automatic Prompt Engineer (APE) for automatic\ninstruction generation and selection. In our method, we treat the instruction\nas the \"program,\" optimized by searching over a pool of instruction candidates\nproposed by an LLM in order to maximize a chosen score function. To evaluate\nthe quality of the selected instruction, we evaluate the zero-shot performance\nof another LLM following the selected instruction. Experiments on 24 NLP tasks\nshow that our automatically generated instructions outperform the prior LLM\nbaseline by a large margin and achieve better or comparable performance to the\ninstructions generated by human annotators on 19/24 tasks. We conduct extensive\nqualitative and quantitative analyses to explore the performance of APE. We\nshow that APE-engineered prompts can be applied to steer models toward\ntruthfulness and/or informativeness, as well as to improve few-shot learning\nperformance by simply prepending them to standard in-context learning prompts.\nPlease check out our webpage at\nhttps://sites.google.com/view/automatic-prompt-engineer.\n",
                "链接": "https://arxiv.org/abs/2211.01910"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态大模型理解和生成统一建模、端到端训练相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "72936",
                "标题": "Understand Data Preprocessing for Effective End-to-End Training of Deep\n  Neural Networks",
                "作者": " Ping Gong,  Yuxin Ma,  Cheng Li,  Xiaosong Ma,  Sam H. Noh",
                "发布日期": "2023-04-19",
                "摘要": "  In this paper, we primarily focus on understanding the data preprocessing\npipeline for DNN Training in the public cloud. First, we run experiments to\ntest the performance implications of the two major data preprocessing methods\nusing either raw data or record files. The preliminary results show that data\npreprocessing is a clear bottleneck, even with the most efficient software and\nhardware configuration enabled by NVIDIA DALI, a high-optimized data\npreprocessing library. Second, we identify the potential causes, exercise a\nvariety of optimization methods, and present their pros and cons. We hope this\nwork will shed light on the new co-design of ``data storage, loading pipeline''\nand ``training framework'' and flexible resource configurations between them so\nthat the resources can be fully exploited and performance can be maximized.\n",
                "链接": "https://arxiv.org/abs/2304.08925"
            },
            {
                "文章ID": "21046",
                "标题": "End-to-End Multimodal Fact-Checking and Explanation Generation: A\n  Challenging Dataset and Models",
                "作者": "Virginia Tech  Barry Menglong Yao, Virginia Tech  Aditya Shah, Lehigh University  Lichao Sun, Virginia Tech  Jin-Hee Cho, Virginia Tech  Lifu Huang",
                "发布日期": "2023-07-10",
                "摘要": "  We propose end-to-end multimodal fact-checking and explanation generation,\nwhere the input is a claim and a large collection of web sources, including\narticles, images, videos, and tweets, and the goal is to assess the\ntruthfulness of the claim by retrieving relevant evidence and predicting a\ntruthfulness label (e.g., support, refute or not enough information), and to\ngenerate a statement to summarize and explain the reasoning and ruling process.\nTo support this research, we construct Mocheg, a large-scale dataset consisting\nof 15,601 claims where each claim is annotated with a truthfulness label and a\nruling statement, and 33,880 textual paragraphs and 12,112 images in total as\nevidence. To establish baseline performances on Mocheg, we experiment with\nseveral state-of-the-art neural architectures on the three pipelined subtasks:\nmultimodal evidence retrieval, claim verification, and explanation generation,\nand demonstrate that the performance of the state-of-the-art end-to-end\nmultimodal fact-checking does not provide satisfactory outcomes. To the best of\nour knowledge, we are the first to build the benchmark dataset and solutions\nfor end-to-end multimodal fact-checking and explanation generation. The\ndataset, source code and model checkpoints are available at\nhttps://github.com/VT-NLP/Mocheg.\n",
                "链接": "https://arxiv.org/abs/2205.12487"
            },
            {
                "文章ID": "100055",
                "标题": "End-to-End Learning on Multimodal Knowledge Graphs",
                "作者": " W. X. Wilcke,  P. Bloem,  V. de Boer,  R. H. van t Veer",
                "发布日期": "2023-09-06",
                "摘要": "  Knowledge graphs enable data scientists to learn end-to-end on heterogeneous\nknowledge. However, most end-to-end models solely learn from the relational\ninformation encoded in graphs' structure: raw values, encoded as literal nodes,\nare either omitted completely or treated as regular nodes without consideration\nfor their values. In either case we lose potentially relevant information which\ncould have otherwise been exploited by our learning methods. We propose a\nmultimodal message passing network which not only learns end-to-end from the\nstructure of graphs, but also from their possibly divers set of multimodal node\nfeatures. Our model uses dedicated (neural) encoders to naturally learn\nembeddings for node features belonging to five different types of modalities,\nincluding numbers, texts, dates, images and geometries, which are projected\ninto a joint representation space together with their relational information.\nWe implement and demonstrate our model on node classification and link\nprediction for artificial and real-worlds datasets, and evaluate the effect\nthat each modality has on the overall performance in an inverse ablation study.\nOur results indicate that end-to-end multimodal learning from any arbitrary\nknowledge graph is indeed possible, and that including multimodal information\ncan significantly affect performance, but that much depends on the\ncharacteristics of the data.\n",
                "链接": "https://arxiv.org/abs/2309.01169"
            },
            {
                "文章ID": "12174",
                "标题": "Towards End-to-End Unified Scene Text Detection and Layout Analysis",
                "作者": " Shangbang Long,  Siyang Qin,  Dmitry Panteleev,  Alessandro Bissacco,  Yasuhisa Fujii,  Michalis Raptis",
                "发布日期": "2022-06-06",
                "摘要": "  Scene text detection and document layout analysis have long been treated as\ntwo separate tasks in different image domains. In this paper, we bring them\ntogether and introduce the task of unified scene text detection and layout\nanalysis. The first hierarchical scene text dataset is introduced to enable\nthis novel research task. We also propose a novel method that is able to\nsimultaneously detect scene text and form text clusters in a unified way.\nComprehensive experiments show that our unified model achieves better\nperformance than multiple well-designed baseline methods. Additionally, this\nmodel achieves state-of-the-art results on multiple scene text detection\ndatasets without the need of complex post-processing. Dataset and code:\nhttps://github.com/google-research-datasets/hiertext and\nhttps://github.com/tensorflow/models/tree/master/official/projects/unified_detector.\n",
                "链接": "https://arxiv.org/abs/2203.15143"
            },
            {
                "文章ID": "104271",
                "标题": "LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language\n  Models",
                "作者": " Ahmad Faiz,  Sotaro Kaneda,  Ruhan Wang,  Rita Osi,  Parteek Sharma,  Fan Chen,  Lei Jiang",
                "发布日期": "2023-09-27",
                "摘要": "  The carbon footprint associated with large language models (LLMs) is a\nsignificant concern, encompassing emissions from their training, inference,\nexperimentation, and storage processes, including operational and embodied\ncarbon emissions. An essential aspect is accurately estimating the carbon\nimpact of emerging LLMs even before their training, which heavily relies on GPU\nusage. Existing studies have reported the carbon footprint of LLM training, but\nonly one tool, mlco2, can predict the carbon footprint of new neural networks\nprior to physical training. However, mlco2 has several serious limitations. It\ncannot extend its estimation to dense or mixture-of-experts (MoE) LLMs,\ndisregards critical architectural parameters, focuses solely on GPUs, and\ncannot model embodied carbon footprints. Addressing these gaps, we introduce\n\\textit{LLMCarbon}, an end-to-end carbon footprint projection model designed\nfor both dense and MoE LLMs. Compared to mlco2, LLMCarbon significantly\nenhances the accuracy of carbon footprint estimations for various LLMs.\n",
                "链接": "https://arxiv.org/abs/2309.14393"
            },
            {
                "文章ID": "2020",
                "标题": "End-to-end Generative Pretraining for Multimodal Video Captioning",
                "作者": " Paul Hongsuck Seo,  Arsha Nagrani,  Anurag Arnab,  Cordelia Schmid",
                "发布日期": "2022-05-11",
                "摘要": "  Recent video and language pretraining frameworks lack the ability to generate\nsentences. We present Multimodal Video Generative Pretraining (MV-GPT), a new\npretraining framework for learning from unlabelled videos which can be\neffectively used for generative tasks such as multimodal video captioning.\nUnlike recent video-language pretraining frameworks, our framework trains both\na multimodal video encoder and a sentence decoder jointly. To overcome the lack\nof captions in unlabelled videos, we leverage the future utterance as an\nadditional text source and propose a bidirectional generation objective -- we\ngenerate future utterances given the present mulitmodal context, and also the\npresent utterance given future observations. With this objective, we train an\nencoder-decoder model end-to-end to generate a caption from raw pixels and\ntranscribed speech directly. Our model achieves state-of-the-art performance\nfor multimodal video captioning on four standard benchmarks, as well as for\nother video understanding tasks such as VideoQA, video retrieval and action\nclassification.\n",
                "链接": "https://arxiv.org/abs/2201.08264"
            },
            {
                "文章ID": "45133",
                "标题": "End-to-End Multimodal Representation Learning for Video Dialog",
                "作者": " Huda Alamri,  Anthony Bilic,  Michael Hu,  Apoorva Beedu,  Irfan Essa",
                "发布日期": "2022-10-27",
                "摘要": "  Video-based dialog task is a challenging multimodal learning task that has\nreceived increasing attention over the past few years with state-of-the-art\nobtaining new performance records. This progress is largely powered by the\nadaptation of the more powerful transformer-based language encoders. Despite\nthis progress, existing approaches do not effectively utilize visual features\nto help solve tasks. Recent studies show that state-of-the-art models are\nbiased toward textual information rather than visual cues. In order to better\nleverage the available visual information, this study proposes a new framework\nthat combines 3D-CNN network and transformer-based networks into a single\nvisual encoder to extract more robust semantic representations from videos. The\nvisual encoder is jointly trained end-to-end with other input modalities such\nas text and audio. Experiments on the AVSD task show significant improvement\nover baselines in both generative and retrieval tasks.\n",
                "链接": "https://arxiv.org/abs/2210.14512"
            },
            {
                "文章ID": "10229",
                "标题": "UNIMO-2: End-to-End Unified Vision-Language Grounded Learning",
                "作者": " Wei Li,  Can Gao,  Guocheng Niu,  Xinyan Xiao,  Hao Liu,  Jiachen Liu,  Hua Wu,  Haifeng Wang",
                "发布日期": "2022-03-18",
                "摘要": "  Vision-Language Pre-training (VLP) has achieved impressive performance on\nvarious cross-modal downstream tasks. However, most existing methods can only\nlearn from aligned image-caption data and rely heavily on expensive regional\nfeatures, which greatly limits their scalability and performance. In this\npaper, we propose an end-to-end unified-modal pre-training framework, namely\nUNIMO-2, for joint learning on both aligned image-caption data and unaligned\nimage-only and text-only corpus. We build a unified Transformer model to\njointly learn visual representations, textual representations and semantic\nalignment between images and texts. In particular, we propose to conduct\ngrounded learning on both images and texts via a sharing grounded space, which\nhelps bridge unaligned images and texts, and align the visual and textual\nsemantic spaces on different types of corpora. The experiments show that our\ngrounded learning method can improve textual and visual semantic alignment for\nimproving performance on various cross-modal tasks. Moreover, benefiting from\neffective joint modeling of different types of corpora, our model also achieves\nimpressive performance on single-modal visual and textual tasks. Our code and\nmodels are public at the UNIMO project page https://unimo-ptm.github.io/.\n",
                "链接": "https://arxiv.org/abs/2203.09067"
            },
            {
                "文章ID": "46362",
                "标题": "Unified End-to-End Speech Recognition and Endpointing for Fast and\n  Efficient Speech Systems",
                "作者": " Shaan Bijwadia,  Shuo-yiin Chang,  Bo Li,  Tara Sainath,  Chao Zhang,  Yanzhang He",
                "发布日期": "2023-02-16",
                "摘要": "  Automatic speech recognition (ASR) systems typically rely on an external\nendpointer (EP) model to identify speech boundaries. In this work, we propose a\nmethod to jointly train the ASR and EP tasks in a single end-to-end (E2E)\nmultitask model, improving EP quality by optionally leveraging information from\nthe ASR audio encoder. We introduce a \"switch\" connection, which trains the EP\nto consume either the audio frames directly or low-level latent representations\nfrom the ASR model. This results in a single E2E model that can be used during\ninference to perform frame filtering at low cost, and also make high quality\nend-of-query (EOQ) predictions based on ongoing ASR computation. We present\nresults on a voice search test set showing that, compared to separate\nsingle-task models, this approach reduces median endpoint latency by 120 ms\n(30.8% reduction), and 90th percentile latency by 170 ms (23.0% reduction),\nwithout regressing word error rate. For continuous recognition, WER improves by\n10.6% (relative).\n",
                "链接": "https://arxiv.org/abs/2211.00786"
            },
            {
                "文章ID": "46154",
                "标题": "UmeTrack: Unified multi-view end-to-end hand tracking for VR",
                "作者": " Shangchen Han,  Po-chen Wu,  Yubo Zhang,  Beibei Liu,  Linguang Zhang,  Zheng Wang,  Weiguang Si,  Peizhao Zhang,  Yujun Cai,  Tomas Hodan,  Randi Cabezas,  Luan Tran,  Muzaffer Akbay,  Tsz-Ho Yu,  Cem Keskin,  Robert Wang",
                "发布日期": "2022-11-02",
                "摘要": "  Real-time tracking of 3D hand pose in world space is a challenging problem\nand plays an important role in VR interaction. Existing work in this space are\nlimited to either producing root-relative (versus world space) 3D pose or rely\non multiple stages such as generating heatmaps and kinematic optimization to\nobtain 3D pose. Moreover, the typical VR scenario, which involves multi-view\ntracking from wide \\ac{fov} cameras is seldom addressed by these methods. In\nthis paper, we present a unified end-to-end differentiable framework for\nmulti-view, multi-frame hand tracking that directly predicts 3D hand pose in\nworld space. We demonstrate the benefits of end-to-end differentiabilty by\nextending our framework with downstream tasks such as jitter reduction and\npinch prediction. To demonstrate the efficacy of our model, we further present\na new large-scale egocentric hand pose dataset that consists of both real and\nsynthetic data. Experiments show that our system trained on this dataset\nhandles various challenging interactive motions, and has been successfully\napplied to real-time VR applications.\n",
                "链接": "https://arxiv.org/abs/2211.00099"
            }
        ]
    },
    {
        "question": {
            "question": "利用大模型做数学题生成的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "14278",
                "标题": "DISK: Domain-constrained Instance Sketch for Math Word Problem\n  Generation",
                "作者": " Tianyang Cao,  Shuang Zeng,  Xiaodan Xu,  Mairgup Mansur,  Baobao Chang",
                "发布日期": "2022-04-12",
                "摘要": "  A math word problem (MWP) is a coherent narrative which reflects the\nunderlying logic of math equations. Successful MWP generation can automate the\nwriting of mathematics questions. Previous methods mainly generate MWP text\nbased on inflexible pre-defined templates. In this paper, we propose a neural\nmodel for generating MWP text from math equations. Firstly, we incorporate a\nmatching model conditioned on the domain knowledge to retrieve a MWP instance\nwhich is most consistent with the ground-truth, where the domain is a latent\nvariable extracted with a domain summarizer. Secondly, by constructing a\nQuantity Cell Graph (QCG) from the retrieved MWP instance and reasoning over\nit, we improve the model's comprehension of real-world scenarios and derive a\ndomain-constrained instance sketch to guide the generation. Besides, the QCG\nalso interacts with the equation encoder to enhance the alignment between math\ntokens (e.g., quantities and variables) and MWP text. Experiments and empirical\nanalysis on educational MWP set show that our model achieves impressive\nperformance in both automatic evaluation metrics and human evaluation metrics.\n",
                "链接": "https://arxiv.org/abs/2204.04686"
            },
            {
                "文章ID": "92856",
                "标题": "Explaining Math Word Problem Solvers",
                "作者": " Abby Newcomb,  Jugal Kalita",
                "发布日期": "2023-07-26",
                "摘要": "  Automated math word problem solvers based on neural networks have\nsuccessfully managed to obtain 70-80\\% accuracy in solving arithmetic word\nproblems. However, it has been shown that these solvers may rely on superficial\npatterns to obtain their equations. In order to determine what information math\nword problem solvers use to generate solutions, we remove parts of the input\nand measure the model's performance on the perturbed dataset. Our results show\nthat the model is not sensitive to the removal of many words from the input and\ncan still manage to find a correct answer when given a nonsense question. This\nindicates that automatic solvers do not follow the semantic logic of math word\nproblems, and may be overfitting to the presence of specific words.\n",
                "链接": "https://arxiv.org/abs/2307.13128"
            },
            {
                "文章ID": "79980",
                "标题": "Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with\n  Customized Exercise Generation",
                "作者": " Zhenwen Liang,  Wenhao Yu,  Tanmay Rajpurohit,  Peter Clark,  Xiangliang Zhang,  Ashwin Kaylan",
                "发布日期": "2023-05-25",
                "摘要": "  In this paper, we present a novel approach for distilling math word problem\nsolving capabilities from large language models (LLMs) into smaller, more\nefficient student models. Our approach is designed to consider the student\nmodel's weaknesses and foster a tailored learning experience by generating\ntargeted exercises aligned with educational science principles, such as\nknowledge tracing and personalized learning. Concretely, we let GPT-3 be a math\ntutor and run two steps iteratively: 1) assessing the student model's current\nlearning status on a GPT-generated exercise book, and 2) improving the student\nmodel by training it with tailored exercise samples generated by GPT-3.\nExperimental results reveal that our approach outperforms LLMs (e.g., GPT-3 and\nPaLM) in accuracy across three distinct benchmarks while employing\nsignificantly fewer parameters. Furthermore, we provide a comprehensive\nanalysis of the various components within our methodology to substantiate their\nefficacy.\n",
                "链接": "https://arxiv.org/abs/2305.14386"
            },
            {
                "文章ID": "82852",
                "标题": "Interpretable Math Word Problem Solution Generation Via Step-by-step\n  Planning",
                "作者": " Mengxue Zhang,  Zichao Wang,  Zhichao Yang,  Weiqi Feng,  Andrew Lan",
                "发布日期": "2023-06-02",
                "摘要": "  Solutions to math word problems (MWPs) with step-by-step explanations are\nvaluable, especially in education, to help students better comprehend\nproblem-solving strategies. Most existing approaches only focus on obtaining\nthe final correct answer. A few recent approaches leverage intermediate\nsolution steps to improve final answer correctness but often cannot generate\ncoherent steps with a clear solution strategy. Contrary to existing work, we\nfocus on improving the correctness and coherence of the intermediate solutions\nsteps. We propose a step-by-step planning approach for intermediate solution\ngeneration, which strategically plans the generation of the next solution step\nbased on the MWP and the previous solution steps. Our approach first plans the\nnext step by predicting the necessary math operation needed to proceed, given\nhistory steps, then generates the next step, token-by-token, by prompting a\nlanguage model with the predicted math operation. Experiments on the GSM8K\ndataset demonstrate that our approach improves the accuracy and\ninterpretability of the solution on both automatic metrics and human\nevaluation.\n",
                "链接": "https://arxiv.org/abs/2306.00784"
            },
            {
                "文章ID": "98724",
                "标题": "Solving Math Word Problem with Problem Type Classification",
                "作者": " Jie Yao,  Zihao Zhou,  Qiufeng Wang",
                "发布日期": "2023-08-29",
                "摘要": "  Math word problems (MWPs) require analyzing text descriptions and generating\nmathematical equations to derive solutions. Existing works focus on solving\nMWPs with two types of solvers: tree-based solver and large language model\n(LLM) solver. However, these approaches always solve MWPs by a single solver,\nwhich will bring the following problems: (1) Single type of solver is hard to\nsolve all types of MWPs well. (2) A single solver will result in poor\nperformance due to over-fitting. To address these challenges, this paper\nutilizes multiple ensemble approaches to improve MWP-solving ability. Firstly,\nWe propose a problem type classifier that combines the strengths of the\ntree-based solver and the LLM solver. This ensemble approach leverages their\nrespective advantages and broadens the range of MWPs that can be solved.\nFurthermore, we also apply ensemble techniques to both tree-based solver and\nLLM solver to improve their performance. For the tree-based solver, we propose\nan ensemble learning framework based on ten-fold cross-validation and voting\nmechanism. In the LLM solver, we adopt self-consistency (SC) method to improve\nanswer selection. Experimental results demonstrate the effectiveness of these\nensemble approaches in enhancing MWP-solving ability. The comprehensive\nevaluation showcases improved performance, validating the advantages of our\nproposed approach. Our code is available at this url:\nhttps://github.com/zhouzihao501/NLPCC2023-Shared-Task3-ChineseMWP.\n",
                "链接": "https://arxiv.org/abs/2308.13844"
            },
            {
                "文章ID": "86008",
                "标题": "Learning by Analogy: Diverse Questions Generation in Math Word Problem",
                "作者": " Zihao Zhou,  Maizhen Ning,  Qiufeng Wang,  Jie Yao,  Wei Wang,  Xiaowei Huang,  Kaizhu Huang",
                "发布日期": "2023-06-16",
                "摘要": "  Solving math word problem (MWP) with AI techniques has recently made great\nprogress with the success of deep neural networks (DNN), but it is far from\nbeing solved. We argue that the ability of learning by analogy is essential for\nan MWP solver to better understand same problems which may typically be\nformulated in diverse ways. However most existing works exploit the shortcut\nlearning to train MWP solvers simply based on samples with a single question.\nIn lack of diverse questions, these methods merely learn shallow heuristics. In\nthis paper, we make a first attempt to solve MWPs by generating diverse yet\nconsistent questions/equations. Given a typical MWP including the scenario\ndescription, question, and equation (i.e., answer), we first generate multiple\nconsistent equations via a group of heuristic rules. We then feed them to a\nquestion generator together with the scenario to obtain the corresponding\ndiverse questions, forming a new MWP with a variety of questions and equations.\nFinally we engage a data filter to remove those unreasonable MWPs, keeping the\nhigh-quality augmented ones. To evaluate the ability of learning by analogy for\nan MWP solver, we generate a new MWP dataset (called DiverseMath23K) with\ndiverse questions by extending the current benchmark Math23K. Extensive\nexperimental results demonstrate that our proposed method can generate\nhigh-quality diverse questions with corresponding equations, further leading to\nperformance improvement on Diverse-Math23K. The code and dataset is available\nat: https://github.com/zhouzihao501/DiverseMWP\n",
                "链接": "https://arxiv.org/abs/2306.09064"
            },
            {
                "文章ID": "87612",
                "标题": "Math Word Problem Solving by Generating Linguistic Variants of Problem\n  Statements",
                "作者": " Syed Rifat Raiyan,  Md. Nafis Faiyaz,  Shah Md. Jawad Kabir,  Mohsinul Kabir,  Hasan Mahmud,  Md Kamrul Hasan",
                "发布日期": "2023-06-27",
                "摘要": "  The art of mathematical reasoning stands as a fundamental pillar of\nintellectual progress and is a central catalyst in cultivating human ingenuity.\nResearchers have recently published a plethora of works centered around the\ntask of solving Math Word Problems (MWP) $-$ a crucial stride towards general\nAI. These existing models are susceptible to dependency on shallow heuristics\nand spurious correlations to derive the solution expressions. In order to\nameliorate this issue, in this paper, we propose a framework for MWP solvers\nbased on the generation of linguistic variants of the problem text. The\napproach involves solving each of the variant problems and electing the\npredicted expression with the majority of the votes. We use DeBERTa\n(Decoding-enhanced BERT with disentangled attention) as the encoder to leverage\nits rich textual representations and enhanced mask decoder to construct the\nsolution expressions. Furthermore, we introduce a challenging dataset,\n$\\mathrm{P\\small{ARA}\\normalsize{MAWPS}}$, consisting of paraphrased,\nadversarial, and inverse variants of selectively sampled MWPs from the\nbenchmark $\\mathrm{M\\small{AWPS}}$ dataset. We extensively experiment on this\ndataset along with other benchmark datasets using some baseline MWP solver\nmodels. We show that training on linguistic variants of problem statements and\nvoting on candidate predictions improve the mathematical reasoning and\nrobustness of the model. We make our code and data publicly available.\n",
                "链接": "https://arxiv.org/abs/2306.13899"
            },
            {
                "文章ID": "103132",
                "标题": "Design of Chain-of-Thought in Math Problem Solving",
                "作者": " Zhanming Jie,  Trung Quoc Luong,  Xinbo Zhang,  Xiaoran Jin,  Hang Li",
                "发布日期": "2023-10-03",
                "摘要": "  Chain-of-Thought (CoT) plays a crucial role in reasoning for math problem\nsolving. We conduct a comprehensive examination of methods for designing CoT,\ncomparing conventional natural language CoT with various program CoTs,\nincluding the self-describing program, the comment-describing program, and the\nnon-describing program. Furthermore, we investigate the impact of programming\nlanguage on program CoTs, comparing Python and Wolfram Language. Through\nextensive experiments on GSM8K, MATHQA, and SVAMP, we find that program CoTs\noften have superior effectiveness in math problem solving. Notably, the best\nperforming combination with 30B parameters beats GPT-3.5-turbo by a significant\nmargin. The results show that self-describing program offers greater diversity\nand thus can generally achieve higher performance. We also find that Python is\na better choice of language than Wolfram for program CoTs. The experimental\nresults provide a valuable guideline for future CoT designs that take into\naccount both programming language and coding style for further advancements.\nOur datasets and code are publicly available.\n",
                "链接": "https://arxiv.org/abs/2309.11054"
            },
            {
                "文章ID": "51749",
                "标题": "Generalizing Math Word Problem Solvers via Solution Diversification",
                "作者": " Zhenwen Liang,  Jipeng Zhang,  Lei Wang,  Yan Wang,  Jie Shao,  Xiangliang Zhang",
                "发布日期": "2022-12-05",
                "摘要": "  Current math word problem (MWP) solvers are usually Seq2Seq models trained by\nthe (one-problem; one-solution) pairs, each of which is made of a problem\ndescription and a solution showing reasoning flow to get the correct answer.\nHowever, one MWP problem naturally has multiple solution equations. The\ntraining of an MWP solver with (one-problem; one-solution) pairs excludes other\ncorrect solutions, and thus limits the generalizability of the MWP solver. One\nfeasible solution to this limitation is to augment multiple solutions to a\ngiven problem. However, it is difficult to collect diverse and accurate augment\nsolutions through human efforts. In this paper, we design a new training\nframework for an MWP solver by introducing a solution buffer and a solution\ndiscriminator. The buffer includes solutions generated by an MWP solver to\nencourage the training data diversity. The discriminator controls the quality\nof buffered solutions to participate in training. Our framework is flexibly\napplicable to a wide setting of fully, semi-weakly and weakly supervised\ntraining for all Seq2Seq MWP solvers. We conduct extensive experiments on a\nbenchmark dataset Math23k and a new dataset named Weak12k, and show that our\nframework improves the performance of various MWP solvers under different\nsettings by generating correct and diverse solutions.\n",
                "链接": "https://arxiv.org/abs/2212.00833"
            },
            {
                "文章ID": "60355",
                "标题": "Techniques to Improve Neural Math Word Problem Solvers",
                "作者": " Youyuan Zhang",
                "发布日期": "2023-02-08",
                "摘要": "  Developing automatic Math Word Problem (MWP) solvers is a challenging task\nthat demands the ability of understanding and mathematical reasoning over the\nnatural language. Recent neural-based approaches mainly encode the problem text\nusing a language model and decode a mathematical expression over quantities and\noperators iteratively. Note the problem text of a MWP consists of a context\npart and a question part, a recent work finds these neural solvers may only\nperform shallow pattern matching between the context text and the golden\nexpression, where question text is not well used. Meanwhile, existing decoding\nprocesses fail to enforce the mathematical laws into the design, where the\nrepresentations for mathematical equivalent expressions are different. To\naddress these two issues, we propose a new encoder-decoder architecture that\nfully leverages the question text and preserves step-wise commutative law.\nBesides generating quantity embeddings, our encoder further encodes the\nquestion text and uses it to guide the decoding process. At each step, our\ndecoder uses Deep Sets to compute expression representations so that these\nembeddings are invariant under any permutation of quantities. Experiments on\nfour established benchmarks demonstrate that our framework outperforms\nstate-of-the-art neural MWP solvers, showing the effectiveness of our\ntechniques. We also conduct a detailed analysis of the results to show the\nlimitations of our approach and further discuss the potential future work. Code\nis available at https://github.com/sophistz/Question-Aware-Deductive-MWP.\n",
                "链接": "https://arxiv.org/abs/2302.03145"
            }
        ]
    },
    {
        "question": {
            "question": "查找可以用于验证模型推理能力的数据集论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "帮我找一下用大模型进行论文查找的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "120419",
                "标题": "Literature Review of Mixed Reality Research",
                "作者": " Aizierjiang Aiersilan",
                "发布日期": "2023-12-18",
                "摘要": "  In the global context, while mixed reality has been an emerging concept for\nyears, recent technological and scientific advancements have now made it poised\nto revolutionize industries and daily life by offering enhanced functionalities\nand improved services. Besides reviewing the highly cited papers in the last 20\nyears among over a thousand research papers on mixed reality, this systematic\nreview provides the state-of-the-art applications and utilities of the mixed\nreality by primarily scrutinizing the associated papers in 2022 and 2023.\nFocusing on the potentials that this technology have in providing digitally\nsupported simulations and other utilities in the era of large language models,\nhighlighting the potential and limitations of the innovative solutions and also\nbringing focus to emerging research directions, such as telemedicine, remote\ncontrol and optimization of direct volume rendering. The paper's associated\nrepository is publicly accessible at https://aizierjiang.github.io/mr.\n",
                "链接": "https://arxiv.org/abs/2312.02995"
            },
            {
                "文章ID": "84494",
                "标题": "covLLM: Large Language Models for COVID-19 Biomedical Literature",
                "作者": " Yousuf A. Khan,  Clarisse Hokia,  Jennifer Xu,  Ben Ehlert",
                "发布日期": "2023-06-09",
                "摘要": "  The COVID-19 pandemic led to 1.1 million deaths in the United States, despite\nthe explosion of coronavirus research. These new findings are slow to translate\nto clinical interventions, leading to poorer patient outcomes and unnecessary\ndeaths. One reason is that clinicians, overwhelmed by patients, struggle to\nkeep pace with the rate of new coronavirus literature. A potential solution is\ndeveloping a tool for evaluating coronavirus literature using large language\nmodels (LLMs) -- neural networks that are deployed for natural language\nprocessing. LLMs can be used to summarize and extract user-specified\ninformation. The greater availability and advancement of LLMs and pre-processed\ncoronavirus literature databases provide the opportunity to assist clinicians\nin evaluating coronavirus literature through a coronavirus literature specific\nLLM (covLLM), a tool that directly takes an inputted research article and a\nuser query to return an answer. Using the COVID-19 Open Research Dataset\n(CORD-19), we produced two datasets: (1) synCovid, which uses a combination of\nhandwritten prompts and synthetic prompts generated using OpenAI, and (2) real\nabstracts, which contains abstract and title pairs. covLLM was trained with\nLLaMA 7B as a baseline model to produce three models trained on (1) the Alpaca\nand synCovid datasets, (2) the synCovid dataset, and (3) the synCovid and real\nabstract datasets. These models were evaluated by two human evaluators and\nChatGPT. Results demonstrate that training covLLM on the synCovid and abstract\npairs datasets performs competitively with ChatGPT and outperforms covLLM\ntrained primarily using the Alpaca dataset.\n",
                "链接": "https://arxiv.org/abs/2306.04926"
            },
            {
                "文章ID": "106494",
                "标题": "Benchmarking Large Language Models As AI Research Agents",
                "作者": " Qian Huang,  Jian Vora,  Percy Liang,  Jure Leskovec",
                "发布日期": "2023-10-06",
                "摘要": "  Scientific experimentation involves an iterative process of creating\nhypotheses, designing experiments, running experiments, and analyzing the\nresults. Can we build AI research agents to perform these long-horizon tasks?\nTo take a step towards building and evaluating research agents on such\nopen-ended decision-making tasks, we focus on the problem of machine learning\nengineering: given a task description and a dataset, build a high-performing\nmodel. In this paper, we propose MLAgentBench, a suite of ML tasks for\nbenchmarking AI research agents. Agents can perform actions like\nreading/writing files, executing code, and inspecting outputs. With these\nactions, agents could run experiments, analyze the results, and modify the code\nof entire machine learning pipelines, such as data processing, architecture,\ntraining processes, etc. The benchmark then automatically evaluates the agent's\nperformance objectively over various metrics related to performance and\nefficiency. We also design an LLM-based research agent to automatically perform\nexperimentation loops in such an environment. Empirically, we find that a\nGPT-4-based research agent can feasibly build compelling ML models over many\ntasks in MLAgentBench, displaying highly interpretable plans and actions.\nHowever, the success rates vary considerably; they span from almost 90\\% on\nwell-established older datasets to as low as 10\\% on recent Kaggle Challenges\n-- unavailable during the LLM model's pretraining -- and even 0\\% on newer\nresearch challenges like BabyLM. Finally, we identify several key challenges\nfor LLM-based research agents such as long-term planning and hallucination. Our\ncode is released at https://github.com/snap-stanford/MLAgentBench.\n",
                "链接": "https://arxiv.org/abs/2310.03302"
            },
            {
                "文章ID": "97576",
                "标题": "Large Language Models for Software Engineering: A Systematic Literature\n  Review",
                "作者": " Xinyi Hou,  Yanjie Zhao,  Yue Liu,  Zhou Yang,  Kailong Wang,  Li Li,  Xiapu Luo,  David Lo,  John Grundy,  Haoyu Wang",
                "发布日期": "2023-09-13",
                "摘要": "  Large Language Models (LLMs) have significantly impacted numerous domains,\nincluding Software Engineering (SE). Many recent publications have explored\nLLMs applied to various SE tasks. Nevertheless, a comprehensive understanding\nof the application, effects, and possible limitations of LLMs on SE is still in\nits early stages. To bridge this gap, we conducted a systematic literature\nreview on LLM4SE, with a particular focus on understanding how LLMs can be\nexploited to optimize processes and outcomes. We collect and analyze 229\nresearch papers from 2017 to 2023 to answer four key research questions (RQs).\nIn RQ1, we categorize different LLMs that have been employed in SE tasks,\ncharacterizing their distinctive features and uses. In RQ2, we analyze the\nmethods used in data collection, preprocessing, and application highlighting\nthe role of well-curated datasets for successful LLM for SE implementation. RQ3\ninvestigates the strategies employed to optimize and evaluate the performance\nof LLMs in SE. Finally, RQ4 examines the specific SE tasks where LLMs have\nshown success to date, illustrating their practical contributions to the field.\nFrom the answers to these RQs, we discuss the current state-of-the-art and\ntrends, identifying gaps in existing research, and flagging promising areas for\nfuture study.\n",
                "链接": "https://arxiv.org/abs/2308.10620"
            },
            {
                "文章ID": "53740",
                "标题": "Synthesizing Research on Programmers' Mental Models of Programs, Tasks\n  and Concepts -- a Systematic Literature Review",
                "作者": " Ava Heinonen,  Bettina Lehtelä,  Arto Hellas,  Fabian Fagerholm",
                "发布日期": "2022-12-16",
                "摘要": "  Programmers' mental models represent their knowledge and understanding of\nprograms, programming concepts, and programming in general. They guide\nprogrammers' work and influence their task performance. Understanding mental\nmodels is important for designing work systems and practices that support\nprogrammers. Although the importance of programmers' mental models is widely\nacknowledged, research on mental models has decreased over the years. The\nresults are scattered and do not take into account recent developments in\nsoftware engineering. We analyze the state of research into programmers' mental\nmodels and provide an overview of existing research. We connect results on\nmental models from different strands of research to form a more unified\nknowledge base on the topic. We conducted a systematic literature review on\nprogrammers' mental models. We analyzed literature addressing mental models in\ndifferent contexts, including mental models of programs, programming tasks, and\nprogramming concepts. Using nine search engines, we found 3678 articles\n(excluding duplicates). 84 were selected for further analysis. Using the\nsnowballing technique, we obtained a final result set containing 187 articles.\nWe show that the literature shares a kernel of shared understanding of mental\nmodels. By collating and connecting results on mental models from different\nfields of research, we uncovered some well-researched aspects, which we argue\nare fundamental characteristics of programmers' mental models. This work\nprovides a basis for future work on mental models. The research field on\nprogrammers' mental models still faces many challenges rising from a lack of a\nshared knowledge base and poorly defined constructs. We created a unified\nknowledge base on the topic. We also point to directions for future studies. In\nparticular, we call for studies that examine programmers working with modern\npractices and tools.\n",
                "链接": "https://arxiv.org/abs/2212.07763"
            },
            {
                "文章ID": "71835",
                "标题": "Emergent autonomous scientific research capabilities of large language\n  models",
                "作者": " Daniil A. Boiko,  Robert MacKnight,  Gabe Gomes",
                "发布日期": "2023-04-12",
                "摘要": "  Transformer-based large language models are rapidly advancing in the field of\nmachine learning research, with applications spanning natural language,\nbiology, chemistry, and computer programming. Extreme scaling and reinforcement\nlearning from human feedback have significantly improved the quality of\ngenerated text, enabling these models to perform various tasks and reason about\ntheir choices. In this paper, we present an Intelligent Agent system that\ncombines multiple large language models for autonomous design, planning, and\nexecution of scientific experiments. We showcase the Agent's scientific\nresearch capabilities with three distinct examples, with the most complex being\nthe successful performance of catalyzed cross-coupling reactions. Finally, we\ndiscuss the safety implications of such systems and propose measures to prevent\ntheir misuse.\n",
                "链接": "https://arxiv.org/abs/2304.05332"
            },
            {
                "文章ID": "101124",
                "标题": "Toward Reproducing Network Research Results Using Large Language Models",
                "作者": " Qiao Xiang,  Yuling Lin,  Mingjun Fang,  Bang Huang,  Siyong Huang,  Ridi Wen,  Franck Le,  Linghe Kong,  Jiwu Shu",
                "发布日期": "2023-09-12",
                "摘要": "  Reproducing research results in the networking community is important for\nboth academia and industry. The current best practice typically resorts to\nthree approaches: (1) looking for publicly available prototypes; (2) contacting\nthe authors to get a private prototype; and (3) manually implementing a\nprototype following the description of the publication. However, most published\nnetwork research does not have public prototypes and private prototypes are\nhard to get. As such, most reproducing efforts are spent on manual\nimplementation based on the publications, which is both time and labor\nconsuming and error-prone. In this paper, we boldly propose reproducing network\nresearch results using the emerging large language models (LLMs). In\nparticular, we first prove its feasibility with a small-scale experiment, in\nwhich four students with essential networking knowledge each reproduces a\ndifferent networking system published in prominent conferences and journals by\nprompt engineering ChatGPT. We report the experiment's observations and lessons\nand discuss future open research questions of this proposal. This work raises\nno ethical issue.\n",
                "链接": "https://arxiv.org/abs/2309.04716"
            },
            {
                "文章ID": "13792",
                "标题": "Advancing Data Justice Research and Practice: An Integrated Literature\n  Review",
                "作者": " David Leslie,  Michael Katell,  Mhairi Aitken,  Jatinder Singh,  Morgan Briggs,  Rosamund Powell,  Cami Rincón,  Thompson Chengeta,  Abeba Birhane,  Antonella Perini,  Smera Jayadeva,  Anjali Mazumder",
                "发布日期": "2022-04-08",
                "摘要": "  The Advancing Data Justice Research and Practice (ADJRP) project aims to\nwiden the lens of current thinking around data justice and to provide\nactionable resources that will help policymakers, practitioners, and impacted\ncommunities gain a broader understanding of what equitable, freedom-promoting,\nand rights-sustaining data collection, governance, and use should look like in\nincreasingly dynamic and global data innovation ecosystems. In this integrated\nliterature review we hope to lay the conceptual groundwork needed to support\nthis aspiration. The introduction motivates the broadening of data justice that\nis undertaken by the literature review which follows. First, we address how\ncertain limitations of the current study of data justice drive the need for a\nre-location of data justice research and practice. We map out the strengths and\nshortcomings of the contemporary state of the art and then elaborate on the\nchallenges faced by our own effort to broaden the data justice perspective in\nthe decolonial context. The body of the literature review covers seven thematic\nareas. For each theme, the ADJRP team has systematically collected and analysed\nkey texts in order to tell the critical empirical story of how existing social\nstructures and power dynamics present challenges to data justice and related\njustice fields. In each case, this critical empirical story is also\nsupplemented by the transformational story of how activists, policymakers, and\nacademics are challenging longstanding structures of inequity to advance social\njustice in data innovation ecosystems and adjacent areas of technological\npractice.\n",
                "链接": "https://arxiv.org/abs/2204.03090"
            },
            {
                "文章ID": "71870",
                "标题": "Galactic ChitChat: Using Large Language Models to Converse with\n  Astronomy Literature",
                "作者": " Ioana Ciucă,  Yuan-Sen Ting",
                "发布日期": "2023-09-13",
                "摘要": "  We demonstrate the potential of the state-of-the-art OpenAI GPT-4 large\nlanguage model to engage in meaningful interactions with Astronomy papers using\nin-context prompting. To optimize for efficiency, we employ a distillation\ntechnique that effectively reduces the size of the original input paper by\n50\\%, while maintaining the paragraph structure and overall semantic integrity.\nWe then explore the model's responses using a multi-document context (ten\ndistilled documents). Our findings indicate that GPT-4 excels in the\nmulti-document domain, providing detailed answers contextualized within the\nframework of related research findings. Our results showcase the potential of\nlarge language models for the astronomical community, offering a promising\navenue for further exploration, particularly the possibility of utilizing the\nmodels for hypothesis generation.\n",
                "链接": "https://arxiv.org/abs/2304.05406"
            },
            {
                "文章ID": "113973",
                "标题": "LitSumm: Large language models for literature summarisation of\n  non-coding RNAs",
                "作者": " Andrew Green,  Carlos Ribas,  Nancy Ontiveros-Palacios,  Anton I. Petrov,  Alex Bateman,  Blake Sweeney",
                "发布日期": "2023-11-07",
                "摘要": "  Motivation: Curation of literature in life sciences is a growing challenge.\nThe continued increase in the rate of publication, coupled with the relatively\nfixed number of curators worldwide presents a major challenge to developers of\nbiomedical knowledgebases. Very few knowledgebases have resources to scale to\nthe whole relevant literature and all have to prioritise their efforts.\n  Results: In this work, we take a first step to alleviating the lack of\ncurator time in RNA science by generating summaries of literature for\nnon-coding RNAs using large language models (LLMs). We demonstrate that\nhigh-quality, factually accurate summaries with accurate references can be\nautomatically generated from the literature using a commercial LLM and a chain\nof prompts and checks. Manual assessment was carried out for a subset of\nsummaries, with the majority being rated extremely high quality. We also\napplied the most commonly used automated evaluation approaches, finding that\nthey do not correlate with human assessment. Finally, we apply our tool to a\nselection of over 4,600 ncRNAs and make the generated summaries available via\nthe RNAcentral resource. We conclude that automated literature summarization is\nfeasible with the current generation of LLMs, provided careful prompting and\nautomated checking are applied.\n  Availability: Code used to produce these summaries can be found here:\nhttps://github.com/RNAcentral/litscan-summarization and the dataset of contexts\nand summaries can be found here:\nhttps://huggingface.co/datasets/RNAcentral/litsumm-v1. Summaries are also\ndisplayed on the RNA report pages in RNAcentral (https://rnacentral.org/)\n",
                "链接": "https://arxiv.org/abs/2311.03056"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下nips 2023 paper list",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "121476",
                "标题": "Proceedings of the 2023 XCSP3 Competition",
                "作者": " Gilles Audemard,  Christophe Lecoutre,  Emmanuel Lonca",
                "发布日期": "2023-12-12",
                "摘要": "  This document represents the proceedings of the 2023 XCSP3 Competition. The\nresults of this competition of constraint solvers were presented at CP'23 (the\n29th International Conference on Principles and Practice of Constraint\nProgramming, held in Toronto, Canada from 27th to 31th August, 2023).\n",
                "链接": "https://arxiv.org/abs/2312.05877"
            },
            {
                "文章ID": "95325",
                "标题": "EFaR 2023: Efficient Face Recognition Competition",
                "作者": " Jan Niklas Kolf,  Fadi Boutros,  Jurek Elliesen,  Markus Theuerkauf,  Naser Damer,  Mohamad Alansari,  Oussama Abdul Hay,  Sara Alansari,  Sajid Javed,  Naoufel Werghi,  Klemen Grm,  Vitomir Štruc,  Fernando Alonso-Fernandez,  Kevin Hernandez Diaz,  Josef Bigun,  Anjith George,  Christophe Ecabert,  Hatef Otroshi Shahreza,  Ketan Kotwal,  Sébastien Marcel,  Iurii Medvedev,  Bo Jin,  Diogo Nunes,  Ahmad Hassanpour,  Pankaj Khatiwada,  Aafan Ahmad Toor,  Bian Yang",
                "发布日期": "2023-08-09",
                "摘要": "  This paper presents the summary of the Efficient Face Recognition Competition\n(EFaR) held at the 2023 International Joint Conference on Biometrics (IJCB\n2023). The competition received 17 submissions from 6 different teams. To drive\nfurther development of efficient face recognition models, the submitted\nsolutions are ranked based on a weighted score of the achieved verification\naccuracies on a diverse set of benchmarks, as well as the deployability given\nby the number of floating-point operations and model size. The evaluation of\nsubmissions is extended to bias, cross-quality, and large-scale recognition\nbenchmarks. Overall, the paper gives an overview of the achieved performance\nvalues of the submitted solutions as well as a diverse set of baselines. The\nsubmitted solutions use small, efficient network architectures to reduce the\ncomputational cost, some solutions apply model quantization. An outlook on\npossible techniques that are underrepresented in current solutions is given as\nwell.\n",
                "链接": "https://arxiv.org/abs/2308.04168"
            },
            {
                "文章ID": "111240",
                "标题": "BLP 2023 Task 2: Sentiment Analysis",
                "作者": " Md. Arid Hasan,  Firoj Alam,  Anika Anjum,  Shudipta Das,  Afiyat Anjum",
                "发布日期": "2023-10-26",
                "摘要": "  We present an overview of the BLP Sentiment Shared Task, organized as part of\nthe inaugural BLP 2023 workshop, co-located with EMNLP 2023. The task is\ndefined as the detection of sentiment in a given piece of social media text.\nThis task attracted interest from 71 participants, among whom 29 and 30 teams\nsubmitted systems during the development and evaluation phases, respectively.\nIn total, participants submitted 597 runs. However, a total of 15 teams\nsubmitted system description papers. The range of approaches in the submitted\nsystems spans from classical machine learning models, fine-tuning pre-trained\nmodels, to leveraging Large Language Model (LLMs) in zero- and few-shot\nsettings. In this paper, we provide a detailed account of the task setup,\nincluding dataset development and evaluation setup. Additionally, we provide a\nbrief overview of the systems submitted by the participants. All datasets and\nevaluation scripts from the shared task have been made publicly available for\nthe research community, to foster further research in this domain\n",
                "链接": "https://arxiv.org/abs/2310.16183"
            },
            {
                "文章ID": "101511",
                "标题": "SoccerNet 2023 Challenges Results",
                "作者": " Anthony Cioppa,  Silvio Giancola,  Vladimir Somers,  Floriane Magera,  Xin Zhou,  Hassan Mkhallati,  Adrien Deliège,  Jan Held,  Carlos Hinojosa,  Amir M. Mansourian,  Pierre Miralles,  Olivier Barnich,  Christophe De Vleeschouwer,  Alexandre Alahi,  Bernard Ghanem,  Marc Van Droogenbroeck,  Abdullah Kamal,  Adrien Maglo,  Albert Clapés,  Amr Abdelaziz,  Artur Xarles,  Astrid Orcesi,  Atom Scott,  Bin Liu,  Byoungkwon Lim,  Chen Chen,  Fabian Deuser,  Feng Yan,  Fufu Yu,  Gal Shitrit,  Guanshuo Wang,  Gyusik Choi,  Hankyul Kim,  Hao Guo,  Hasby Fahrudin,  Hidenari Koguchi,  Håkan Ardö,  Ibrahim Salah,  Ido Yerushalmy,  Iftikar Muhammad,  Ikuma Uchida,  Ishay Be'ery,  Jaonary Rabarisoa,  Jeongae Lee,  Jiajun Fu,  Jianqin Yin,  Jinghang Xu,  Jongho Nang,  Julien Denize,  Junjie Li,  Junpei Zhang,  Juntae Kim,  Kamil Synowiec,  Kenji Kobayashi,  Kexin Zhang,  Konrad Habel,  Kota Nakajima,  Licheng Jiao,  Lin Ma,  Lizhi Wang,  Luping Wang,  Menglong Li,  Mengying Zhou,  Mohamed Nasr,  Mohamed Abdelwahed,  Mykola Liashuha,  Nikolay Falaleev,  Norbert Oswald,  Qiong Jia,  Quoc-Cuong Pham,  Ran Song,  Romain Hérault,  Rui Peng,  Ruilong Chen,  Ruixuan Liu,  Ruslan Baikulov,  Ryuto Fukushima,  Sergio Escalera,  Seungcheon Lee,  Shimin Chen,  Shouhong Ding,  Taiga Someya,  Thomas B. Moeslund,  Tianjiao Li,  Wei Shen,  Wei Zhang,  Wei Li,  Wei Dai,  Weixin Luo,  Wending Zhao,  Wenjie Zhang,  Xinquan Yang,  Yanbiao Ma,  Yeeun Joo,  Yingsen Zeng,  Yiyang Gan,  Yongqiang Zhu,  Yujie Zhong,  Zheng Ruan,  Zhiheng Li,  Zhijian Huang,  Ziyu Meng",
                "发布日期": "2023-09-13",
                "摘要": "  The SoccerNet 2023 challenges were the third annual video understanding\nchallenges organized by the SoccerNet team. For this third edition, the\nchallenges were composed of seven vision-based tasks split into three main\nthemes. The first theme, broadcast video understanding, is composed of three\nhigh-level tasks related to describing events occurring in the video\nbroadcasts: (1) action spotting, focusing on retrieving all timestamps related\nto global actions in soccer, (2) ball action spotting, focusing on retrieving\nall timestamps related to the soccer ball change of state, and (3) dense video\ncaptioning, focusing on describing the broadcast with natural language and\nanchored timestamps. The second theme, field understanding, relates to the\nsingle task of (4) camera calibration, focusing on retrieving the intrinsic and\nextrinsic camera parameters from images. The third and last theme, player\nunderstanding, is composed of three low-level tasks related to extracting\ninformation about the players: (5) re-identification, focusing on retrieving\nthe same players across multiple views, (6) multiple object tracking, focusing\non tracking players and the ball through unedited video streams, and (7) jersey\nnumber recognition, focusing on recognizing the jersey number of players from\ntracklets. Compared to the previous editions of the SoccerNet challenges, tasks\n(2-3-7) are novel, including new annotations and data, task (4) was enhanced\nwith more data and annotations, and task (6) now focuses on end-to-end\napproaches. More information on the tasks, challenges, and leaderboards are\navailable on https://www.soccer-net.org. Baselines and development kits can be\nfound on https://github.com/SoccerNet.\n",
                "链接": "https://arxiv.org/abs/2309.06006"
            },
            {
                "文章ID": "82537",
                "标题": "Findings of the VarDial Evaluation Campaign 2023",
                "作者": " Noëmi Aepli,  Çağrı Çöltekin,  Rob Van Der Goot,  Tommi Jauhiainen,  Mourhaf Kazzaz,  Nikola Ljubešić,  Kai North,  Barbara Plank,  Yves Scherrer,  Marcos Zampieri",
                "发布日期": "2023-06-01",
                "摘要": "  This report presents the results of the shared tasks organized as part of the\nVarDial Evaluation Campaign 2023. The campaign is part of the tenth workshop on\nNatural Language Processing (NLP) for Similar Languages, Varieties and Dialects\n(VarDial), co-located with EACL 2023. Three separate shared tasks were included\nthis year: Slot and intent detection for low-resource language varieties\n(SID4LR), Discriminating Between Similar Languages -- True Labels (DSL-TL), and\nDiscriminating Between Similar Languages -- Speech (DSL-S). All three tasks\nwere organized for the first time this year.\n",
                "链接": "https://arxiv.org/abs/2305.20080"
            },
            {
                "文章ID": "111594",
                "标题": "Core Challenge 2023: Solver and Graph Descriptions",
                "作者": " Takehide Soh,  Tomoya Tanjo,  Yoshio Okamoto,  Takehiro Ito",
                "发布日期": "2023-10-30",
                "摘要": "  This paper collects all descriptions of solvers and ISR instances submitted\nto CoRe Challenge 2023.\n",
                "链接": "https://arxiv.org/abs/2310.17136"
            },
            {
                "文章ID": "113325",
                "标题": "ACES: Translation Accuracy Challenge Sets at WMT 2023",
                "作者": " Chantal Amrhein,  Nikita Moghe,  Liane Guillou",
                "发布日期": "2023-11-03",
                "摘要": "  We benchmark the performance of segmentlevel metrics submitted to WMT 2023\nusing the ACES Challenge Set (Amrhein et al., 2022). The challenge set consists\nof 36K examples representing challenges from 68 phenomena and covering 146\nlanguage pairs. The phenomena range from simple perturbations at the\nword/character level to more complex errors based on discourse and real-world\nknowledge. For each metric, we provide a detailed profile of performance over a\nrange of error categories as well as an overall ACES-Score for quick\ncomparison. We also measure the incremental performance of the metrics\nsubmitted to both WMT 2023 and 2022. We find that 1) there is no clear winner\namong the metrics submitted to WMT 2023, and 2) performance change between the\n2023 and 2022 versions of the metrics is highly variable. Our recommendations\nare similar to those from WMT 2022. Metric developers should focus on: building\nensembles of metrics from different design families, developing metrics that\npay more attention to the source and rely less on surface-level overlap, and\ncarefully determining the influence of multilingual embeddings on MT\nevaluation.\n",
                "链接": "https://arxiv.org/abs/2311.01153"
            },
            {
                "文章ID": "98264",
                "标题": "UNISOUND System for VoxCeleb Speaker Recognition Challenge 2023",
                "作者": " Yu Zheng,  Yajun Zhang,  Chuanying Niu,  Yibin Zhan,  Yanhua Long,  Dongxing Xu",
                "发布日期": "2023-08-25",
                "摘要": "  This report describes the UNISOUND submission for Track1 and Track2 of\nVoxCeleb Speaker Recognition Challenge 2023 (VoxSRC 2023). We submit the same\nsystem on Track 1 and Track 2, which is trained with only VoxCeleb2-dev.\nLarge-scale ResNet and RepVGG architectures are developed for the challenge. We\npropose a consistency-aware score calibration method, which leverages the\nstability of audio voiceprints in similarity score by a Consistency Measure\nFactor (CMF). CMF brings a huge performance boost in this challenge. Our final\nsystem is a fusion of six models and achieves the first place in Track 1 and\nsecond place in Track 2 of VoxSRC 2023. The minDCF of our submission is 0.0855\nand the EER is 1.5880%.\n",
                "链接": "https://arxiv.org/abs/2308.12526"
            },
            {
                "文章ID": "40312",
                "标题": "SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis",
                "作者": " Jiaxin Pei,  Vítor Silva,  Maarten Bos,  Yozon Liu,  Leonardo Neves,  David Jurgens,  Francesco Barbieri",
                "发布日期": "2023-02-06",
                "摘要": "  We propose MINT, a new Multilingual INTimacy analysis dataset covering 13,372\ntweets in 10 languages including English, French, Spanish, Italian, Portuguese,\nKorean, Dutch, Chinese, Hindi, and Arabic. We benchmarked a list of popular\nmultilingual pre-trained language models. The dataset is released along with\nthe SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis\n(https://sites.google.com/umich.edu/semeval-2023-tweet-intimacy).\n",
                "链接": "https://arxiv.org/abs/2210.01108"
            },
            {
                "文章ID": "101771",
                "标题": "OWL Reasoners still useable in 2023",
                "作者": " Konrad Abicht",
                "发布日期": "2023-09-14",
                "摘要": "  In a systematic literature and software review over 100 OWL reasoners/systems\nwere analyzed to see if they would still be usable in 2023. This has never been\ndone in this capacity. OWL reasoners still play an important role in knowledge\norganisation and management, but the last comprehensive surveys/studies are\nmore than 8 years old. The result of this work is a comprehensive list of 95\nstandalone OWL reasoners and systems using an OWL reasoner. For each item,\ninformation on project pages, source code repositories and related\ndocumentation was gathered. The raw research data is provided in a Github\nrepository for anyone to use.\n",
                "链接": "https://arxiv.org/abs/2309.06888"
            }
        ]
    },
    {
        "question": {
            "question": "请搜索近一年发表的有关多模态大模型与产业相结合、与具体应用场景相结合的论文",
            "type": "2"
        },
        "results": [
            {
                "文章ID": "83281",
                "标题": "Word Embeddings for Banking Industry",
                "作者": " Avnish Patel",
                "发布日期": "2023-06-06",
                "摘要": "  Applications of Natural Language Processing (NLP) are plentiful, from\nsentiment analysis to text classification. Practitioners rely on static word\nembeddings (e.g. Word2Vec or GloVe) or static word representation from\ncontextual models (e.g. BERT or ELMo) to perform many of these NLP tasks. These\nwidely available word embeddings are built from large amount of text, so they\nare likely to have captured most of the vocabulary in different context.\nHowever, how well would they capture domain-specific semantics and word\nrelatedness? This paper explores this idea by creating a bank-specific word\nembeddings and evaluates them against other sources of word embeddings such as\nGloVe and BERT. Not surprising that embeddings built from bank-specific corpora\ndoes a better job of capturing the bank-specific semantics and word\nrelatedness. This finding suggests that bank-specific word embeddings could be\na good stand-alone source or a complement to other widely available embeddings\nwhen performing NLP tasks specific to the banking industry.\n",
                "链接": "https://arxiv.org/abs/2306.01807"
            },
            {
                "文章ID": "83975",
                "标题": "Scalable Concept Extraction in Industry 4.0",
                "作者": " Andrés Felipe Posada-Moreno,  Kai Müller,  Florian Brillowski,  Friedrich Solowjow,  Thomas Gries,  Sebastian Trimpe",
                "发布日期": "2023-06-07",
                "摘要": "  The industry 4.0 is leveraging digital technologies and machine learning\ntechniques to connect and optimize manufacturing processes. Central to this\nidea is the ability to transform raw data into human understandable knowledge\nfor reliable data-driven decision-making. Convolutional Neural Networks (CNNs)\nhave been instrumental in processing image data, yet, their ``black box''\nnature complicates the understanding of their prediction process. In this\ncontext, recent advances in the field of eXplainable Artificial Intelligence\n(XAI) have proposed the extraction and localization of concepts, or which\nvisual cues intervene on the prediction process of CNNs. This paper tackles the\napplication of concept extraction (CE) methods to industry 4.0 scenarios. To\nthis end, we modify a recently developed technique, ``Extracting Concepts with\nLocal Aggregated Descriptors'' (ECLAD), improving its scalability.\nSpecifically, we propose a novel procedure for calculating concept importance,\nutilizing a wrapper function designed for CNNs. This process is aimed at\ndecreasing the number of times each image needs to be evaluated. Subsequently,\nwe demonstrate the potential of CE methods, by applying them in three\nindustrial use cases. We selected three representative use cases in the context\nof quality control for material design (tailored textiles), manufacturing\n(carbon fiber reinforcement), and maintenance (photovoltaic module inspection).\nIn these examples, CE was able to successfully extract and locate concepts\ndirectly related to each task. This is, the visual cues related to each\nconcept, coincided with what human experts would use to perform the task\nthemselves, even when the visual cues were entangled between multiple classes.\nThrough empirical results, we show that CE can be applied for understanding\nCNNs in an industrial context, giving useful insights that can relate to domain\nknowledge.\n",
                "链接": "https://arxiv.org/abs/2306.03551"
            },
            {
                "文章ID": "106851",
                "标题": "Generative AI in the Construction Industry: Opportunities & Challenges",
                "作者": " Prashnna Ghimire,  Kyungki Kim,  Manoj Acharya",
                "发布日期": "2023-10-10",
                "摘要": "  In the last decade, despite rapid advancements in artificial intelligence\n(AI) transforming many industry practices, construction largely lags in\nadoption. Recently, the emergence and rapid adoption of advanced large language\nmodels (LLM) like OpenAI's GPT, Google's PaLM, and Meta's Llama have shown\ngreat potential and sparked considerable global interest. However, the current\nsurge lacks a study investigating the opportunities and challenges of\nimplementing Generative AI (GenAI) in the construction sector, creating a\ncritical knowledge gap for researchers and practitioners. This underlines the\nnecessity to explore the prospects and complexities of GenAI integration.\nBridging this gap is fundamental to optimizing GenAI's early-stage adoption\nwithin the construction sector. Given GenAI's unprecedented capabilities to\ngenerate human-like content based on learning from existing content, we reflect\non two guiding questions: What will the future bring for GenAI in the\nconstruction industry? What are the potential opportunities and challenges in\nimplementing GenAI in the construction industry? This study delves into\nreflected perception in literature, analyzes the industry perception using\nprogramming-based word cloud and frequency analysis, and integrates authors'\nopinions to answer these questions. This paper recommends a conceptual GenAI\nimplementation framework, provides practical recommendations, summarizes future\nresearch questions, and builds foundational literature to foster subsequent\nresearch expansion in GenAI within the construction and its allied architecture\n& engineering domains.\n",
                "链接": "https://arxiv.org/abs/2310.04427"
            },
            {
                "文章ID": "81774",
                "标题": "Attention Paper: How Generative AI Reshapes Digital Shadow Industry?",
                "作者": " Qichao Wang,  Huan Ma,  Wentao Wei,  Hangyu Li,  Liang Chen,  Peilin Zhao,  Binwen Zhao,  Bo Hu,  Shu Zhang,  Zibin Zheng,  Bingzhe Wu",
                "发布日期": "2023-05-31",
                "摘要": "  The rapid development of digital economy has led to the emergence of various\nblack and shadow internet industries, which pose potential risks that can be\nidentified and managed through digital risk management (DRM) that uses\ndifferent techniques such as machine learning and deep learning. The evolution\nof DRM architecture has been driven by changes in data forms. However, the\ndevelopment of AI-generated content (AIGC) technology, such as ChatGPT and\nStable Diffusion, has given black and shadow industries powerful tools to\npersonalize data and generate realistic images and conversations for fraudulent\nactivities. This poses a challenge for DRM systems to control risks from the\nsource of data generation and to respond quickly to the fast-changing risk\nenvironment. This paper aims to provide a technical analysis of the challenges\nand opportunities of AIGC from upstream, midstream, and downstream paths of\nblack/shadow industries and suggest future directions for improving existing\nrisk control systems. The paper will explore the new black and shadow\ntechniques triggered by generative AI technology and provide insights for\nbuilding the next-generation DRM system.\n",
                "链接": "https://arxiv.org/abs/2305.18346"
            },
            {
                "文章ID": "104128",
                "标题": "Egocentric RGB+Depth Action Recognition in Industry-Like Settings",
                "作者": " Jyoti Kini,  Sarah Fleischer,  Ishan Dave,  Mubarak Shah",
                "发布日期": "2023-09-26",
                "摘要": "  Action recognition from an egocentric viewpoint is a crucial perception task\nin robotics and enables a wide range of human-robot interactions. While most\ncomputer vision approaches prioritize the RGB camera, the Depth modality -\nwhich can further amplify the subtleties of actions from an egocentric\nperspective - remains underexplored. Our work focuses on recognizing actions\nfrom egocentric RGB and Depth modalities in an industry-like environment. To\nstudy this problem, we consider the recent MECCANO dataset, which provides a\nwide range of assembling actions. Our framework is based on the 3D Video SWIN\nTransformer to encode both RGB and Depth modalities effectively. To address the\ninherent skewness in real-world multimodal action occurrences, we propose a\ntraining strategy using an exponentially decaying variant of the focal loss\nmodulating factor. Additionally, to leverage the information in both RGB and\nDepth modalities, we opt for late fusion to combine the predictions from each\nmodality. We thoroughly evaluate our method on the action recognition task of\nthe MECCANO dataset, and it significantly outperforms the prior work. Notably,\nour method also secured first place at the multimodal action recognition\nchallenge at ICIAP 2023.\n",
                "链接": "https://arxiv.org/abs/2309.13962"
            },
            {
                "文章ID": "74391",
                "标题": "Blockchain-based Access Control for Secure Smart Industry Management\n  Systems",
                "作者": " Aditya Pribadi Kalapaaking,  Ibrahim Khalil,  Mohammad Saidur Rahman,  Abdelaziz Bouras",
                "发布日期": "2023-04-27",
                "摘要": "  Smart manufacturing systems involve a large number of interconnected devices\nresulting in massive data generation. Cloud computing technology has recently\ngained increasing attention in smart manufacturing systems for facilitating\ncost-effective service provisioning and massive data management. In a\ncloud-based manufacturing system, ensuring authorized access to the data is\ncrucial. A cloud platform is operated under a single authority. Hence, a cloud\nplatform is prone to a single point of failure and vulnerable to adversaries.\nAn internal or external adversary can easily modify users' access to allow\nunauthorized users to access the data. This paper proposes a role-based access\ncontrol to prevent modification attacks by leveraging blockchain and smart\ncontracts in a cloud-based smart manufacturing system. The role-based access\ncontrol is developed to determine users' roles and rights in smart contracts.\nThe smart contracts are then deployed to the private blockchain network. We\nevaluate our solution by utilizing Ethereum private blockchain network to\ndeploy the smart contract. The experimental results demonstrate the feasibility\nand evaluation of the proposed framework's performance.\n",
                "链接": "https://arxiv.org/abs/2304.13379"
            },
            {
                "文章ID": "74990",
                "标题": "Industry Classification Using a Novel Financial Time-Series Case\n  Representation",
                "作者": " Rian Dolphin,  Barry Smyth,  Ruihai Dong",
                "发布日期": "2023-05-02",
                "摘要": "  The financial domain has proven to be a fertile source of challenging machine\nlearning problems across a variety of tasks including prediction, clustering,\nand classification. Researchers can access an abundance of time-series data and\neven modest performance improvements can be translated into significant\nadditional value. In this work, we consider the use of case-based reasoning for\nan important task in this domain, by using historical stock returns time-series\ndata for industry sector classification. We discuss why time-series data can\npresent some significant representational challenges for conventional\ncase-based reasoning approaches, and in response, we propose a novel\nrepresentation based on stock returns embeddings, which can be readily\ncalculated from raw stock returns data. We argue that this representation is\nwell suited to case-based reasoning and evaluate our approach using a\nlarge-scale public dataset for the industry sector classification task,\ndemonstrating substantial performance improvements over several baselines using\nmore conventional representations.\n",
                "链接": "https://arxiv.org/abs/2305.00245"
            },
            {
                "文章ID": "86605",
                "标题": "LaDe: The First Comprehensive Last-mile Delivery Dataset from Industry",
                "作者": " Lixia Wu,  Haomin Wen,  Haoyuan Hu,  Xiaowei Mao,  Yutong Xia,  Ergang Shan,  Jianbin Zhen,  Junhong Lou,  Yuxuan Liang,  Liuqing Yang,  Roger Zimmermann,  Youfang Lin,  Huaiyu Wan",
                "发布日期": "2023-06-21",
                "摘要": "  Real-world last-mile delivery datasets are crucial for research in logistics,\nsupply chain management, and spatio-temporal data mining. Despite a plethora of\nalgorithms developed to date, no widely accepted, publicly available last-mile\ndelivery dataset exists to support research in this field. In this paper, we\nintroduce \\texttt{LaDe}, the first publicly available last-mile delivery\ndataset with millions of packages from the industry. LaDe has three unique\ncharacteristics: (1) Large-scale. It involves 10,677k packages of 21k couriers\nover 6 months of real-world operation. (2) Comprehensive information. It offers\noriginal package information, such as its location and time requirements, as\nwell as task-event information, which records when and where the courier is\nwhile events such as task-accept and task-finish events happen. (3) Diversity.\nThe dataset includes data from various scenarios, including package pick-up and\ndelivery, and from multiple cities, each with its unique spatio-temporal\npatterns due to their distinct characteristics such as populations. We verify\nLaDe on three tasks by running several classical baseline models per task. We\nbelieve that the large-scale, comprehensive, diverse feature of LaDe can offer\nunparalleled opportunities to researchers in the supply chain community, data\nmining community, and beyond. The dataset homepage is publicly available at\nhttps://huggingface.co/datasets/Cainiao-AI/LaDe.\n",
                "链接": "https://arxiv.org/abs/2306.10675"
            },
            {
                "文章ID": "95924",
                "标题": "Large Language Models for Telecom: Forthcoming Impact on the Industry",
                "作者": " Ali Maatouk,  Nicola Piovesan,  Fadhel Ayed,  Antonio De Domenico,  Merouane Debbah",
                "发布日期": "2023-08-14",
                "摘要": "  Large Language Models (LLMs) have emerged as a transformative force,\nrevolutionizing numerous fields well beyond the conventional domain of Natural\nLanguage Processing (NLP) and garnering unprecedented attention. As LLM\ntechnology continues to progress, the telecom industry is facing the prospect\nof its potential impact on its landscape. To elucidate these implications, we\ndelve into the inner workings of LLMs, providing insights into their current\ncapabilities and limitations. We also examine the use cases that can be readily\nimplemented in the telecom industry, streamlining numerous tasks that currently\nhinder operational efficiency and demand significant manpower and engineering\nexpertise. Furthermore, we uncover essential research directions that deal with\nthe distinctive challenges of utilizing the LLMs within the telecom domain.\nAddressing these challenges represents a significant stride towards fully\nharnessing the potential of LLMs and unlocking their capabilities to the\nfullest extent within the telecom domain.\n",
                "链接": "https://arxiv.org/abs/2308.06013"
            },
            {
                "文章ID": "103461",
                "标题": "Prompt Tuned Embedding Classification for Multi-Label Industry Sector\n  Allocation",
                "作者": " Valentin Leonhard Buchner,  Lele Cao,  Jan-Christoph Kalo,  Vilhelm von Ehrenheim",
                "发布日期": "2023-10-24",
                "摘要": "  Prompt Tuning is emerging as a scalable and cost-effective method to\nfine-tune Pretrained Language Models (PLMs), which are often referred to as\nLarge Language Models (LLMs). This study benchmarks the performance and\ncomputational efficiency of Prompt Tuning and baselines for multi-label text\nclassification. This is applied to the challenging task of classifying\ncompanies into an investment firm's proprietary industry taxonomy, supporting\ntheir thematic investment strategy. Text-to-text classification is frequently\nreported to outperform task-specific classification heads, but has several\nlimitations when applied to a multi-label classification problem where each\nlabel consists of multiple tokens: (a) Generated labels may not match any label\nin the label taxonomy; (b) The fine-tuning process lacks permutation invariance\nand is sensitive to the order of the provided labels; (c) The model provides\nbinary decisions rather than appropriate confidence scores. Limitation (a) is\naddressed by applying constrained decoding using Trie Search, which slightly\nimproves classification performance. All limitations (a), (b), and (c) are\naddressed by replacing the PLM's language head with a classification head,\nwhich is referred to as Prompt Tuned Embedding Classification (PTEC). This\nimproves performance significantly, while also reducing computational costs\nduring inference. In our industrial application, the training data is skewed\ntowards well-known companies. We confirm that the model's performance is\nconsistent across both well-known and less-known companies. Our overall results\nindicate the continuing need to adapt state-of-the-art methods to\ndomain-specific tasks, even in the era of PLMs with strong generalization\nabilities. We release our codebase and a benchmarking dataset at\nhttps://github.com/EQTPartners/PTEC.\n",
                "链接": "https://arxiv.org/abs/2309.12075"
            }
        ]
    },
    {
        "question": {
            "question": "请查找关于智能体的研究进展的综述或调查论文。重点关注不同领域中智能体的方法和应用，以及相关的挑战和未来方向。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "43710",
                "标题": "CEntRE: A paragraph-level Chinese dataset for Relation Extraction among\n  Enterprises",
                "作者": " Peipei Liu,  Hong Li,  Zhiyu Wang,  Yimo Ren,  Jie Liu,  Fei Lyu,  Hongsong Zhu,  Limin Sun",
                "发布日期": "2022-10-20",
                "摘要": "  Enterprise relation extraction aims to detect pairs of enterprise entities\nand identify the business relations between them from unstructured or\nsemi-structured text data, and it is crucial for several real-world\napplications such as risk analysis, rating research and supply chain security.\nHowever, previous work mainly focuses on getting attribute information about\nenterprises like personnel and corporate business, and pays little attention to\nenterprise relation extraction. To encourage further progress in the research,\nwe introduce the CEntRE, a new dataset constructed from publicly available\nbusiness news data with careful human annotation and intelligent data\nprocessing. Extensive experiments on CEntRE with six excellent models\ndemonstrate the challenges of our proposed dataset.\n",
                "链接": "https://arxiv.org/abs/2210.10581"
            },
            {
                "文章ID": "48672",
                "标题": "H2-Golden-Retriever: Methodology and Tool for an Evidence-Based Hydrogen\n  Research Grantsmanship",
                "作者": " Paul Seurin,  Olusola Olabanjo,  Joseph Wiggins,  Lorien Pratt,  Loveneesh Rana,  Rozhin Yasaei,  Gregory Renard",
                "发布日期": "2022-11-17",
                "摘要": "  Hydrogen is poised to play a major role in decarbonizing the economy. The\nneed to discover, develop, and understand low-cost, high-performance, durable\nmaterials that can help maximize the cost of electrolysis as well as the need\nfor an intelligent tool to make evidence-based Hydrogen research funding\ndecisions relatively easier warranted this study.In this work, we developed H2\nGolden Retriever (H2GR) system for Hydrogen knowledge discovery and\nrepresentation using Natural Language Processing (NLP), Knowledge Graph and\nDecision Intelligence. This system represents a novel methodology encapsulating\nstate-of-the-art technique for evidence-based research grantmanship. Relevant\nHydrogen papers were scraped and indexed from the web and preprocessing was\ndone using noise and stop-words removal, language and spell check, stemming and\nlemmatization. The NLP tasks included Named Entity Recognition using Stanford\nand Spacy NER, topic modeling using Latent Dirichlet Allocation and TF-IDF. The\nKnowledge Graph module was used for the generation of meaningful entities and\ntheir relationships, trends and patterns in relevant H2 papers, thanks to an\nontology of the hydrogen production domain. The Decision Intelligence component\nprovides stakeholders with a simulation environment for cost and quantity\ndependencies. PageRank algorithm was used to rank papers of interest. Random\nsearches were made on the proposed H2GR and the results included a list of\npapers ranked by relevancy score, entities, graphs of relationships between the\nentities, ontology of H2 production and Causal Decision Diagrams showing\ncomponent interactivity. Qualitative assessment was done by the experts and\nH2GR is deemed to function to a satisfactory level.\n",
                "链接": "https://arxiv.org/abs/2211.08614"
            },
            {
                "文章ID": "68823",
                "标题": "The Semantic Reader Project: Augmenting Scholarly Documents through\n  AI-Powered Interactive Reading Interfaces",
                "作者": " Kyle Lo,  Joseph Chee Chang,  Andrew Head,  Jonathan Bragg,  Amy X. Zhang,  Cassidy Trier,  Chloe Anastasiades,  Tal August,  Russell Authur,  Danielle Bragg,  Erin Bransom,  Isabel Cachola,  Stefan Candra,  Yoganand Chandrasekhar,  Yen-Sung Chen,  Evie Yu-Yen Cheng,  Yvonne Chou,  Doug Downey,  Rob Evans,  Raymond Fok,  Fangzhou Hu,  Regan Huff,  Dongyeop Kang,  Tae Soo Kim,  Rodney Kinney,  Aniket Kittur,  Hyeonsu Kang,  Egor Klevak,  Bailey Kuehl,  Michael Langan,  Matt Latzke,  Jaron Lochner,  Kelsey MacMillan,  Eric Marsh,  Tyler Murray,  Aakanksha Naik,  Ngoc-Uyen Nguyen,  Srishti Palani,  Soya Park,  Caroline Paulic,  Napol Rachatasumrit,  Smita Rao,  Paul Sayre,  Zejiang Shen,  Pao Siangliulue,  Luca Soldaini,  Huy Tran,  Madeleine van Zuylen,  Lucy Lu Wang,  Christopher Wilhelm,  Caroline Wu,  Jiangjiang Yang,  Angele Zamarron,  Marti A. Hearst,  Daniel S. Weld",
                "发布日期": "2023-04-25",
                "摘要": "  Scholarly publications are key to the transfer of knowledge from scholars to\nothers. However, research papers are information-dense, and as the volume of\nthe scientific literature grows, the need for new technology to support the\nreading process grows. In contrast to the process of finding papers, which has\nbeen transformed by Internet technology, the experience of reading research\npapers has changed little in decades. The PDF format for sharing research\npapers is widely used due to its portability, but it has significant downsides\nincluding: static content, poor accessibility for low-vision readers, and\ndifficulty reading on mobile devices. This paper explores the question \"Can\nrecent advances in AI and HCI power intelligent, interactive, and accessible\nreading interfaces -- even for legacy PDFs?\" We describe the Semantic Reader\nProject, a collaborative effort across multiple institutions to explore\nautomatic creation of dynamic reading interfaces for research papers. Through\nthis project, we've developed ten research prototype interfaces and conducted\nusability studies with more than 300 participants and real-world users showing\nimproved reading experiences for scholars. We've also released a production\nreading interface for research papers that will incorporate the best features\nas they mature. We structure this paper around challenges scholars and the\npublic face when reading research papers -- Discovery, Efficiency,\nComprehension, Synthesis, and Accessibility -- and present an overview of our\nprogress and remaining open challenges.\n",
                "链接": "https://arxiv.org/abs/2303.14334"
            },
            {
                "文章ID": "13706",
                "标题": "Hammer PDF: An Intelligent PDF Reader for Scientific Papers",
                "作者": " Sheng-Fu Wang,  Shu-Hang Liu,  Tian-Yi Che,  Yi-Fan Lu,  Song-Xiao Yang,  Heyan Huang,  Xian-Ling Mao",
                "发布日期": "2022-06-22",
                "摘要": "  It is the most important way for researchers to acquire academic progress via\nreading scientific papers, most of which are in PDF format. However, existing\nPDF Readers like Adobe Acrobat Reader and Foxit PDF Reader are usually only for\nreading by rendering PDF files as a whole, and do not consider the\nmulti-granularity content understanding of a paper itself. Specifically, taking\na paper as a basic and separate unit, existing PDF Readers cannot access\nextended information about the paper, such as corresponding videos, blogs and\ncodes. Meanwhile, they cannot understand the academic content of a paper, such\nas terms, authors, and citations. To solve these problems, we introduce Hammer\nPDF, an intelligent PDF Reader for scientific papers. Apart from basic reading\nfunctions, Hammer PDF has the following four innovative features: (1)\ninformation extraction ability, which can locate and mark spans like terms and\nother entities; (2) information extension ability, which can present relevant\nacademic content of a paper, such as citations, references, codes, videos,\nblogs; (3) built-in Hammer Scholar, an academic search engine based on academic\ninformation collected from major academic databases; (4) built-in Q&A bot,\nwhich can find helpful conference information. The proposed Hammer PDF Reader\ncan help researchers, especially those studying computer science, to improve\nthe efficiency and experience of reading scientific papers. We have released\nHammer PDF, available at https://pdf.hammerscholar.net/face.\n",
                "链接": "https://arxiv.org/abs/2204.02809"
            },
            {
                "文章ID": "78373",
                "标题": "Expanding the Role of Affective Phenomena in Multimodal Interaction\n  Research",
                "作者": " Leena Mathur,  Maja J Matarić,  Louis-Philippe Morency",
                "发布日期": "2023-05-19",
                "摘要": "  In recent decades, the field of affective computing has made substantial\nprogress in advancing the ability of AI systems to recognize and express\naffective phenomena, such as affect and emotions, during human-human and\nhuman-machine interactions. This paper describes our examination of research at\nthe intersection of multimodal interaction and affective computing, with the\nobjective of observing trends and identifying understudied areas. We examined\nover 16,000 papers from selected conferences in multimodal interaction,\naffective computing, and natural language processing: ACM International\nConference on Multimodal Interaction, AAAC International Conference on\nAffective Computing and Intelligent Interaction, Annual Meeting of the\nAssociation for Computational Linguistics, and Conference on Empirical Methods\nin Natural Language Processing. We identified 910 affect-related papers and\npresent our analysis of the role of affective phenomena in these papers. We\nfind that this body of research has primarily focused on enabling machines to\nrecognize and express affect and emotion. However, we find limited research on\nhow affect and emotion predictions might be used by AI systems to enhance\nmachine understanding of human social behaviors and cognitive states. Based on\nour analysis, we discuss directions to expand the role of affective phenomena\nin multimodal interaction research.\n",
                "链接": "https://arxiv.org/abs/2305.10827"
            },
            {
                "文章ID": "21114",
                "标题": "A Zipf's Law-based Text Generation Approach for Addressing Imbalance in\n  Entity Extraction",
                "作者": " Zhenhua Wang,  Ming Ren,  Dong Gao,  Zhuang Li",
                "发布日期": "2023-09-04",
                "摘要": "  Entity extraction is critical in the intelligent advancement across diverse\ndomains. Nevertheless, a challenge to its effectiveness arises from the data\nimbalance. This paper proposes a novel approach by viewing the issue through\nthe quantitative information, recognizing that entities exhibit certain levels\nof commonality while others are scarce, which can be reflected in the\nquantifiable distribution of words. The Zipf's Law emerges as a well-suited\nadoption, and to transition from words to entities, words within the documents\nare classified as common and rare ones. Subsequently, sentences are classified\ninto common and rare ones, and are further processed by text generation models\naccordingly. Rare entities within the generated sentences are then labeled\nusing human-designed rules, serving as a supplement to the raw dataset, thereby\nmitigating the imbalance problem. The study presents a case of extracting\nentities from technical documents, and experimental results from two datasets\nprove the effectiveness of the proposed method. Furthermore, the significance\nof Zipf's law in driving the progress of AI is discussed, broadening the reach\nand coverage of Informetrics. This paper presents a successful demonstration of\nextending Informetrics to interface with AI through Zipf's Law.\n",
                "链接": "https://arxiv.org/abs/2205.12636"
            },
            {
                "文章ID": "49541",
                "标题": "Challenges and Applications of Automated Extraction of Socio-political\n  Events from Text (CASE 2022): Workshop and Shared Task Report",
                "作者": " Ali Hürriyetoğlu,  Hristo Tanev,  Vanni Zavarella,  Reyyan Yeniterzi,  Osman Mutlu,  Erdem Yörük",
                "发布日期": "2022-11-22",
                "摘要": "  We provide a summary of the fifth edition of the CASE workshop that is held\nin the scope of EMNLP 2022. The workshop consists of regular papers, two\nkeynotes, working papers of shared task participants, and task overview papers.\nThis workshop has been bringing together all aspects of event information\ncollection across technical and social science fields. In addition to the\nprogress in depth, the submission and acceptance of multimodal approaches show\nthe widening of this interdisciplinary research topic.\n",
                "链接": "https://arxiv.org/abs/2211.11359"
            },
            {
                "文章ID": "16372",
                "标题": "Personal Research Knowledge Graphs",
                "作者": " Prantika Chakraborty,  Sudakshina Dutta,  Debarshi Kumar Sanyal",
                "发布日期": "2022-04-26",
                "摘要": "  Maintaining research-related information in an organized manner can be\nchallenging for a researcher. In this paper, we envision personal research\nknowledge graphs (PRKGs) as a means to represent structured information about\nthe research activities of a researcher. PRKGs can be used to power intelligent\npersonal assistants, and personalize various applications. We explore what\nentities and relations could be potentially included in a PRKG, how to extract\nthem from various sources, and how to share a PRKG within a research group.\n",
                "链接": "https://arxiv.org/abs/2204.11428"
            },
            {
                "文章ID": "115623",
                "标题": "All Data on the Table: Novel Dataset and Benchmark for Cross-Modality\n  Scientific Information Extraction",
                "作者": " Yuhan Li,  Jian Wu,  Zhiwei Yu,  Börje F. Karlsson,  Wei Shen,  Manabu Okumura,  Chin-Yew Lin",
                "发布日期": "2023-12-19",
                "摘要": "  Extracting key information from scientific papers has the potential to help\nresearchers work more efficiently and accelerate the pace of scientific\nprogress. Over the last few years, research on Scientific Information\nExtraction (SciIE) witnessed the release of several new systems and benchmarks.\nHowever, existing paper-focused datasets mostly focus only on specific parts of\na manuscript (e.g., abstracts) and are single-modality (i.e., text- or\ntable-only), due to complex processing and expensive annotations. Moreover,\ncore information can be present in either text or tables or across both. To\nclose this gap in data availability and enable cross-modality IE, while\nalleviating labeling costs, we propose a semi-supervised pipeline for\nannotating entities in text, as well as entities and relations in tables, in an\niterative procedure. Based on this pipeline, we release novel resources for the\nscientific community, including a high-quality benchmark, a large-scale corpus,\nand a semi-supervised annotation pipeline. We further report the performance of\nstate-of-the-art IE models on the proposed benchmark dataset, as a baseline.\nLastly, we explore the potential capability of large language models such as\nChatGPT for the current task. Our new dataset, results, and analysis validate\nthe effectiveness and efficiency of our semi-supervised pipeline, and we\ndiscuss its remaining limitations.\n",
                "链接": "https://arxiv.org/abs/2311.08189"
            },
            {
                "文章ID": "43550",
                "标题": "Detecting and analyzing missing citations to published scientific\n  entities",
                "作者": " Jialiang Lin,  Yao Yu,  Jiaxin Song,  Xiaodong Shi",
                "发布日期": "2022-10-20",
                "摘要": "  Proper citation is of great importance in academic writing for it enables\nknowledge accumulation and maintains academic integrity. However, citing\nproperly is not an easy task. For published scientific entities, the\never-growing academic publications and over-familiarity of terms easily lead to\nmissing citations. To deal with this situation, we design a special method\nCitation Recommendation for Published Scientific Entity (CRPSE) based on the\ncooccurrences between published scientific entities and in-text citations in\nthe same sentences from previous researchers. Experimental outcomes show the\neffectiveness of our method in recommending the source papers for published\nscientific entities. We further conduct a statistical analysis on missing\ncitations among papers published in prestigious computer science conferences in\n2020. In the 12,278 papers collected, 475 published scientific entities of\ncomputer science and mathematics are found to have missing citations. Many\nentities mentioned without citations are found to be well-accepted research\nresults. On a median basis, the papers proposing these published scientific\nentities with missing citations were published 8 years ago, which can be\nconsidered the time frame for a published scientific entity to develop into a\nwell-accepted concept. For published scientific entities, we appeal for\naccurate and full citation of their source papers as required by academic\nstandards.\n",
                "链接": "https://arxiv.org/abs/2210.10073"
            }
        ]
    }
]