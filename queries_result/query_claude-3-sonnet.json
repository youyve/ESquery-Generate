[
    {
        "question": {
            "question": "与大模型工具学习相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "82016",
                "标题": "GPT4Tools: Teaching Large Language Model to Use Tools via\n  Self-instruction",
                "作者": " Rui Yang,  Lin Song,  Yanwei Li,  Sijie Zhao,  Yixiao Ge,  Xiu Li,  Ying Shan",
                "发布日期": "2023-05-31",
                "摘要": "  This paper aims to efficiently enable Large Language Models (LLMs) to use\nmultimodal tools. Advanced proprietary LLMs, such as ChatGPT and GPT-4, have\nshown great potential for tool usage through sophisticated prompt engineering.\nNevertheless, these models typically rely on prohibitive computational costs\nand publicly inaccessible data. To address these challenges, we propose the\nGPT4Tools based on self-instruct to enable open-source LLMs, such as LLaMA and\nOPT, to use tools. It generates an instruction-following dataset by prompting\nan advanced teacher with various multi-modal contexts. By using the Low-Rank\nAdaptation (LoRA) optimization, our approach facilitates the open-source LLMs\nto solve a range of visual problems, including visual comprehension and image\ngeneration. Moreover, we provide a benchmark to evaluate the ability of LLMs to\nuse tools, which is performed in both zero-shot and fine-tuning ways. Extensive\nexperiments demonstrate the effectiveness of our method on various language\nmodels, which not only significantly improves the accuracy of invoking seen\ntools, but also enables the zero-shot capacity for unseen tools. The code and\ndemo are available at https://github.com/StevenGrove/GPT4Tools.\n",
                "链接": "https://arxiv.org/abs/2305.18752"
            },
            {
                "文章ID": "107503",
                "标题": "An evolutionary model of personality traits related to cooperative\n  behavior using a large language model",
                "作者": " Reiji Suzuki,  Takaya Arita",
                "发布日期": "2023-10-11",
                "摘要": "  This paper aims to shed light on the evolutionary dynamics of diverse and\nsocial populations by introducing the rich expressiveness of generative models\ninto the trait expression of social agent-based evolutionary models.\nSpecifically, we focus on the evolution of personality traits in the context of\na game-theoretic relationship as a situation in which inter-individual\ninterests exert strong selection pressures. We construct an agent model in\nwhich linguistic descriptions of personality traits related to cooperative\nbehavior are used as genes. The deterministic strategies extracted from Large\nLanguage Model (LLM) that make behavioral decisions based on these personality\ntraits are used as behavioral traits. The population is evolved according to\nselection based on average payoff and mutation of genes by asking LLM to\nslightly modify the parent gene toward cooperative or selfish. Through\npreliminary experiments and analyses, we clarify that such a model can indeed\nexhibit the evolution of cooperative behavior based on the diverse and\nhigher-order representation of personality traits. We also observed the\nrepeated intrusion of cooperative and selfish personality traits through\nchanges in the expression of personality traits, and found that the emerging\nwords in the evolved gene well reflected the behavioral tendency of its\npersonality in terms of their semantics.\n",
                "链接": "https://arxiv.org/abs/2310.05976"
            },
            {
                "文章ID": "125173",
                "标题": "A Large Language Model-based Computational Approach to Improve\n  Identity-Related Write-Ups",
                "作者": " Alex Doboli",
                "发布日期": "2023-12-29",
                "摘要": "  Creating written products is essential to modern life, including writings\nabout one's identity and personal experiences. However, writing is often a\ndifficult activity that requires extensive effort to frame the central ideas,\nthe pursued approach to communicate the central ideas, e.g., using analogies,\nmetaphors, or other possible means, the needed presentation structure, and the\nactual verbal expression. Large Language Models, a recently emerged approach in\nMachine Learning, can offer a significant help in reducing the effort and\nimproving the quality of written products. This paper proposes a new\ncomputational approach to explore prompts that given as inputs to a Large\nLanguage Models can generate cues to improve the considered written products.\nTwo case studies on improving write-ups, one based on an analogy and one on a\nmetaphor, are also presented in the paper.\n",
                "链接": "https://arxiv.org/abs/2312.16659"
            },
            {
                "文章ID": "73161",
                "标题": "GeneGPT: Augmenting Large Language Models with Domain Tools for Improved\n  Access to Biomedical Information",
                "作者": " Qiao Jin,  Yifan Yang,  Qingyu Chen,  Zhiyong Lu",
                "发布日期": "2023-05-17",
                "摘要": "  While large language models (LLMs) have been successfully applied to various\ntasks, they still face challenges with hallucinations. Augmenting LLMs with\ndomain-specific tools such as database utilities can facilitate easier and more\nprecise access to specialized knowledge. In this paper, we present GeneGPT, a\nnovel method for teaching LLMs to use the Web APIs of the National Center for\nBiotechnology Information (NCBI) for answering genomics questions.\nSpecifically, we prompt Codex to solve the GeneTuring tests with NCBI Web APIs\nby in-context learning and an augmented decoding algorithm that can detect and\nexecute API calls. Experimental results show that GeneGPT achieves\nstate-of-the-art performance on eight tasks in the GeneTuring benchmark with an\naverage score of 0.83, largely surpassing retrieval-augmented LLMs such as the\nnew Bing (0.44), biomedical LLMs such as BioMedLM (0.08) and BioGPT (0.04), as\nwell as GPT-3 (0.16) and ChatGPT (0.12). Our further analyses suggest that: (1)\nAPI demonstrations have good cross-task generalizability and are more useful\nthan documentations for in-context learning; (2) GeneGPT can generalize to\nlonger chains of API calls and answer multi-hop questions in GeneHop, a novel\ndataset introduced in this work; (3) Different types of errors are enriched in\ndifferent tasks, providing valuable insights for future improvements.\n",
                "链接": "https://arxiv.org/abs/2304.09667"
            },
            {
                "文章ID": "106448",
                "标题": "Misusing Tools in Large Language Models With Visual Adversarial Examples",
                "作者": " Xiaohan Fu,  Zihan Wang,  Shuheng Li,  Rajesh K. Gupta,  Niloofar Mireshghallah,  Taylor Berg-Kirkpatrick,  Earlence Fernandes",
                "发布日期": "2023-10-06",
                "摘要": "  Large Language Models (LLMs) are being enhanced with the ability to use tools\nand to process multiple modalities. These new capabilities bring new benefits\nand also new security risks. In this work, we show that an attacker can use\nvisual adversarial examples to cause attacker-desired tool usage. For example,\nthe attacker could cause a victim LLM to delete calendar events, leak private\nconversations and book hotels. Different from prior work, our attacks can\naffect the confidentiality and integrity of user resources connected to the LLM\nwhile being stealthy and generalizable to multiple input prompts. We construct\nthese attacks using gradient-based adversarial training and characterize\nperformance along multiple dimensions. We find that our adversarial images can\nmanipulate the LLM to invoke tools following real-world syntax almost always\n(~98%) while maintaining high similarity to clean images (~0.9 SSIM).\nFurthermore, using human scoring and automated metrics, we find that the\nattacks do not noticeably affect the conversation (and its semantics) between\nthe user and the LLM.\n",
                "链接": "https://arxiv.org/abs/2310.03185"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            },
            {
                "文章ID": "12740",
                "标题": "ESGBERT: Language Model to Help with Classification Tasks Related to\n  Companies Environmental, Social, and Governance Practices",
                "作者": " Srishti Mehra,  Robert Louka,  Yixun Zhang",
                "发布日期": "2022-04-01",
                "摘要": "  Environmental, Social, and Governance (ESG) are non-financial factors that\nare garnering attention from investors as they increasingly look to apply these\nas part of their analysis to identify material risks and growth opportunities.\nSome of this attention is also driven by clients who, now more aware than ever,\nare demanding for their money to be managed and invested responsibly. As the\ninterest in ESG grows, so does the need for investors to have access to\nconsumable ESG information. Since most of it is in text form in reports,\ndisclosures, press releases, and 10-Q filings, we see a need for sophisticated\nNLP techniques for classification tasks for ESG text. We hypothesize that an\nESG domain-specific pre-trained model will help with such and study building of\nthe same in this paper. We explored doing this by fine-tuning BERTs pre-trained\nweights using ESG specific text and then further fine-tuning the model for a\nclassification task. We were able to achieve accuracy better than the original\nBERT and baseline models in environment-specific classification tasks.\n",
                "链接": "https://arxiv.org/abs/2203.16788"
            },
            {
                "文章ID": "94111",
                "标题": "Structural Embeddings of Tools for Large Language Models",
                "作者": " Eren Unlu",
                "发布日期": "2023-08-02",
                "摘要": "  It is evident that the current state of Large Language Models (LLMs)\nnecessitates the incorporation of external tools. The lack of straightforward\nalgebraic and logical reasoning is well documented and prompted researchers to\ndevelop frameworks which allow LLMs to operate via external tools. The\nontological nature of tool utilization for a specific task can be well\nformulated with a Directed Acyclic Graph (DAG). The central aim of the paper is\nto highlight the importance of graph based approaches to LLM-tool interaction\nin near future. We propose an exemplary framework to guide the orchestration of\nexponentially increasing numbers of external tools with LLMs,where objectives\nand functionalities of tools are graph encoded hierarchically. Assuming that\ntextual segments of a Chain-of-Thought (CoT) can be imagined as a tool as\ndefined here, the graph based framework can pave new avenues in that particular\ndirection as well.\n",
                "链接": "https://arxiv.org/abs/2308.00447"
            },
            {
                "文章ID": "106425",
                "标题": "MetaTool Benchmark for Large Language Models: Deciding Whether to Use\n  Tools and Which to Use",
                "作者": " Yue Huang,  Jiawen Shi,  Yuan Li,  Chenrui Fan,  Siyuan Wu,  Qihui Zhang,  Yixin Liu,  Pan Zhou,  Yao Wan,  Neil Zhenqiang Gong,  Lichao Sun",
                "发布日期": "2023-10-25",
                "摘要": "  Large language models (LLMs) have garnered significant attention due to their\nimpressive natural language processing (NLP) capabilities. Recently, many\nstudies have focused on the tool utilization ability of LLMs. They primarily\ninvestigated how LLMs effectively collaborate with given specific tools.\nHowever, in scenarios where LLMs serve as intelligent agents, as seen in\napplications like AutoGPT and MetaGPT, LLMs are expected to engage in intricate\ndecision-making processes that involve deciding whether to employ a tool and\nselecting the most suitable tool(s) from a collection of available tools to\nfulfill user requests. Therefore, in this paper, we introduce MetaTool, a\nbenchmark designed to evaluate whether LLMs have tool usage awareness and can\ncorrectly choose tools. Specifically, we create a dataset called ToolE within\nthe benchmark. This dataset contains various types of user queries in the form\nof prompts that trigger LLMs to use tools, including both single-tool and\nmulti-tool scenarios. Subsequently, we set the tasks for both tool usage\nawareness and tool selection. We define four subtasks from different\nperspectives in tool selection, including tool selection with similar choices,\ntool selection in specific scenarios, tool selection with possible reliability\nissues, and multi-tool selection. We conduct experiments involving nine popular\nLLMs and find that the majority of them still struggle to effectively select\ntools, highlighting the existing gaps between LLMs and genuine intelligent\nagents. However, through the error analysis, we found there is still\nsignificant room for improvement. Finally, we conclude with insights for tool\ndevelopers that follow ChatGPT to provide detailed descriptions that can\nenhance the tool selection performance of LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.03128"
            },
            {
                "文章ID": "120700",
                "标题": "Methods to Estimate Large Language Model Confidence",
                "作者": " Maia Kotelanski,  Robert Gallo,  Ashwin Nayak,  Thomas Savage",
                "发布日期": "2023-12-11",
                "摘要": "  Large Language Models have difficulty communicating uncertainty, which is a\nsignificant obstacle to applying LLMs to complex medical tasks. This study\nevaluates methods to measure LLM confidence when suggesting a diagnosis for\nchallenging clinical vignettes. GPT4 was asked a series of challenging case\nquestions using Chain of Thought and Self Consistency prompting. Multiple\nmethods were investigated to assess model confidence and evaluated on their\nability to predict the models observed accuracy. The methods evaluated were\nIntrinsic Confidence, SC Agreement Frequency and CoT Response Length. SC\nAgreement Frequency correlated with observed accuracy, yielding a higher Area\nunder the Receiver Operating Characteristic Curve compared to Intrinsic\nConfidence and CoT Length analysis. SC agreement is the most useful proxy for\nmodel confidence, especially for medical diagnosis. Model Intrinsic Confidence\nand CoT Response Length exhibit a weaker ability to differentiate between\ncorrect and incorrect answers, preventing them from being reliable and\ninterpretable markers for model confidence. We conclude GPT4 has a limited\nability to assess its own diagnostic accuracy. SC Agreement Frequency is the\nmost useful method to measure GPT4 confidence.\n",
                "链接": "https://arxiv.org/abs/2312.03733"
            }
        ]
    },
    {
        "question": {
            "question": "和大模型可解释相关的最新论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "116604",
                "标题": "RecExplainer: Aligning Large Language Models for Recommendation Model\n  Interpretability",
                "作者": " Yuxuan Lei,  Jianxun Lian,  Jing Yao,  Xu Huang,  Defu Lian,  Xing Xie",
                "发布日期": "2023-11-21",
                "摘要": "  Recommender systems are widely used in various online services, with\nembedding-based models being particularly popular due to their expressiveness\nin representing complex signals. However, these models often lack\ninterpretability, making them less reliable and transparent for both users and\ndevelopers. With the emergence of large language models (LLMs), we find that\ntheir capabilities in language expression, knowledge-aware reasoning, and\ninstruction following are exceptionally powerful. Based on this, we propose a\nnew model interpretation approach for recommender systems, by using LLMs as\nsurrogate models and learn to mimic and comprehend target recommender models.\nSpecifically, we introduce three alignment methods: behavior alignment,\nintention alignment, and hybrid alignment. Behavior alignment operates in the\nlanguage space, representing user preferences and item information as text to\nlearn the recommendation model's behavior; intention alignment works in the\nlatent space of the recommendation model, using user and item representations\nto understand the model's behavior; hybrid alignment combines both language and\nlatent spaces for alignment training. To demonstrate the effectiveness of our\nmethods, we conduct evaluation from two perspectives: alignment effect, and\nexplanation generation ability on three public datasets. Experimental results\nindicate that our approach effectively enables LLMs to comprehend the patterns\nof recommendation models and generate highly credible recommendation\nexplanations.\n",
                "链接": "https://arxiv.org/abs/2311.10947"
            },
            {
                "文章ID": "104462",
                "标题": "Large Language Model Alignment: A Survey",
                "作者": " Tianhao Shen,  Renren Jin,  Yufei Huang,  Chuang Liu,  Weilong Dong,  Zishan Guo,  Xinwei Wu,  Yan Liu,  Deyi Xiong",
                "发布日期": "2023-09-27",
                "摘要": "  Recent years have witnessed remarkable progress made in large language models\n(LLMs). Such advancements, while garnering significant attention, have\nconcurrently elicited various concerns. The potential of these models is\nundeniably vast; however, they may yield texts that are imprecise, misleading,\nor even detrimental. Consequently, it becomes paramount to employ alignment\ntechniques to ensure these models to exhibit behaviors consistent with human\nvalues.\n  This survey endeavors to furnish an extensive exploration of alignment\nmethodologies designed for LLMs, in conjunction with the extant capability\nresearch in this domain. Adopting the lens of AI alignment, we categorize the\nprevailing methods and emergent proposals for the alignment of LLMs into outer\nand inner alignment. We also probe into salient issues including the models'\ninterpretability, and potential vulnerabilities to adversarial attacks. To\nassess LLM alignment, we present a wide variety of benchmarks and evaluation\nmethodologies. After discussing the state of alignment research for LLMs, we\nfinally cast a vision toward the future, contemplating the promising avenues of\nresearch that lie ahead.\n  Our aspiration for this survey extends beyond merely spurring research\ninterests in this realm. We also envision bridging the gap between the AI\nalignment research community and the researchers engrossed in the capability\nexploration of LLMs for both capable and safe LLMs.\n",
                "链接": "https://arxiv.org/abs/2309.15025"
            },
            {
                "文章ID": "89475",
                "标题": "Generative Job Recommendations with Large Language Model",
                "作者": " Zhi Zheng,  Zhaopeng Qiu,  Xiao Hu,  Likang Wu,  Hengshu Zhu,  Hui Xiong",
                "发布日期": "2023-07-06",
                "摘要": "  The rapid development of online recruitment services has encouraged the\nutilization of recommender systems to streamline the job seeking process.\nPredominantly, current job recommendations deploy either collaborative\nfiltering or person-job matching strategies. However, these models tend to\noperate as \"black-box\" systems and lack the capacity to offer explainable\nguidance to job seekers. Moreover, conventional matching-based recommendation\nmethods are limited to retrieving and ranking existing jobs in the database,\nrestricting their potential as comprehensive career AI advisors. To this end,\nhere we present GIRL (GeneratIve job Recommendation based on Large language\nmodels), a novel approach inspired by recent advancements in the field of Large\nLanguage Models (LLMs). We initially employ a Supervised Fine-Tuning (SFT)\nstrategy to instruct the LLM-based generator in crafting suitable Job\nDescriptions (JDs) based on the Curriculum Vitae (CV) of a job seeker.\nMoreover, we propose to train a model which can evaluate the matching degree\nbetween CVs and JDs as a reward model, and we use Proximal Policy Optimization\n(PPO)-based Reinforcement Learning (RL) method to further fine-tine the\ngenerator. This aligns the generator with recruiter feedback, tailoring the\noutput to better meet employer preferences. In particular, GIRL serves as a job\nseeker-centric generative model, providing job suggestions without the need of\na candidate set. This capability also enhances the performance of existing job\nrecommendation models by supplementing job seeking features with generated\ncontent. With extensive experiments on a large-scale real-world dataset, we\ndemonstrate the substantial effectiveness of our approach. We believe that GIRL\nintroduces a paradigm-shifting approach to job recommendation systems,\nfostering a more personalized and comprehensive job-seeking experience.\n",
                "链接": "https://arxiv.org/abs/2307.02157"
            },
            {
                "文章ID": "125033",
                "标题": "An Explainable AI Approach to Large Language Model Assisted Causal Model\n  Auditing and Development",
                "作者": " Yanming Zhang,  Brette Fitzgibbon,  Dino Garofolo,  Akshith Kota,  Eric Papenhausen,  Klaus Mueller",
                "发布日期": "2023-12-29",
                "摘要": "  Causal networks are widely used in many fields, including epidemiology,\nsocial science, medicine, and engineering, to model the complex relationships\nbetween variables. While it can be convenient to algorithmically infer these\nmodels directly from observational data, the resulting networks are often\nplagued with erroneous edges. Auditing and correcting these networks may\nrequire domain expertise frequently unavailable to the analyst. We propose the\nuse of large language models such as ChatGPT as an auditor for causal networks.\nOur method presents ChatGPT with a causal network, one edge at a time, to\nproduce insights about edge directionality, possible confounders, and mediating\nvariables. We ask ChatGPT to reflect on various aspects of each causal link and\nwe then produce visualizations that summarize these viewpoints for the human\nanalyst to direct the edge, gather more data, or test further hypotheses. We\nenvision a system where large language models, automated causal inference, and\nthe human analyst and domain expert work hand in hand as a team to derive\nholistic and comprehensive causal models for any given case scenario. This\npaper presents first results obtained with an emerging prototype.\n",
                "链接": "https://arxiv.org/abs/2312.16211"
            },
            {
                "文章ID": "116584",
                "标题": "Flexible Model Interpretability through Natural Language Model Editing",
                "作者": " Karel D'Oosterlinck,  Thomas Demeester,  Chris Develder,  Christopher Potts",
                "发布日期": "2023-11-21",
                "摘要": "  Model interpretability and model editing are crucial goals in the age of\nlarge language models. Interestingly, there exists a link between these two\ngoals: if a method is able to systematically edit model behavior with regard to\na human concept of interest, this editor method can help make internal\nrepresentations more interpretable by pointing towards relevant representations\nand systematically manipulating them.\n",
                "链接": "https://arxiv.org/abs/2311.10905"
            },
            {
                "文章ID": "118536",
                "标题": "LLMGA: Multimodal Large Language Model based Generation Assistant",
                "作者": " Bin Xia,  Shiyin Wang,  Yingfan Tao,  Yitong Wang,  Jiaya Jia",
                "发布日期": "2023-12-13",
                "摘要": "  In this paper, we introduce a Multimodal Large Language Model-based\nGeneration Assistant (LLMGA), leveraging the vast reservoir of knowledge and\nproficiency in reasoning, comprehension, and response inherent in Large\nLanguage Models (LLMs) to assist users in image generation and editing.\nDiverging from existing approaches where Multimodal Large Language Models\n(MLLMs) generate fixed-size embeddings to control Stable Diffusion (SD), our\nLLMGA provides a detailed language generation prompt for precise control over\nSD. This not only augments LLM context understanding but also reduces noise in\ngeneration prompts, yields images with more intricate and precise content, and\nelevates the interpretability of the network. To this end, we curate a\ncomprehensive dataset comprising prompt refinement, similar image generation,\ninpainting $\\&$ outpainting, and visual question answering. Moreover, we\npropose a two-stage training scheme. In the first stage, we train the MLLM to\ngrasp the properties of image generation and editing, enabling it to generate\ndetailed prompts. In the second stage, we optimize SD to align with the MLLM's\ngeneration prompts. Additionally, we propose a reference-based restoration\nnetwork to alleviate texture, brightness, and contrast disparities between\ngenerated and preserved regions during image editing. Extensive results show\nthat LLMGA has promising generative capabilities and can enable wider\napplications in an interactive manner.\n",
                "链接": "https://arxiv.org/abs/2311.16500"
            },
            {
                "文章ID": "99995",
                "标题": "Explainability for Large Language Models: A Survey",
                "作者": " Haiyan Zhao,  Hanjie Chen,  Fan Yang,  Ninghao Liu,  Huiqi Deng,  Hengyi Cai,  Shuaiqiang Wang,  Dawei Yin,  Mengnan Du",
                "发布日期": "2023-11-30",
                "摘要": "  Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language processing. However, their internal mechanisms are still\nunclear and this lack of transparency poses unwanted risks for downstream\napplications. Therefore, understanding and explaining these models is crucial\nfor elucidating their behaviors, limitations, and social impacts. In this\npaper, we introduce a taxonomy of explainability techniques and provide a\nstructured overview of methods for explaining Transformer-based language\nmodels. We categorize techniques based on the training paradigms of LLMs:\ntraditional fine-tuning-based paradigm and prompting-based paradigm. For each\nparadigm, we summarize the goals and dominant approaches for generating local\nexplanations of individual predictions and global explanations of overall model\nknowledge. We also discuss metrics for evaluating generated explanations, and\ndiscuss how explanations can be leveraged to debug models and improve\nperformance. Lastly, we examine key challenges and emerging opportunities for\nexplanation techniques in the era of LLMs in comparison to conventional machine\nlearning models.\n",
                "链接": "https://arxiv.org/abs/2309.01029"
            },
            {
                "文章ID": "97658",
                "标题": "Enhancing Recommender Systems with Large Language Model Reasoning Graphs",
                "作者": " Yan Wang,  Zhixuan Chu,  Xin Ouyang,  Simeng Wang,  Hongyan Hao,  Yue Shen,  Jinjie Gu,  Siqiao Xue,  James Y Zhang,  Qing Cui,  Longfei Li,  Jun Zhou,  Sheng Li",
                "发布日期": "2023-08-22",
                "摘要": "  Recommendation systems aim to provide users with relevant suggestions, but\noften lack interpretability and fail to capture higher-level semantic\nrelationships between user behaviors and profiles. In this paper, we propose a\nnovel approach that leverages large language models (LLMs) to construct\npersonalized reasoning graphs. These graphs link a user's profile and\nbehavioral sequences through causal and logical inferences, representing the\nuser's interests in an interpretable way. Our approach, LLM reasoning graphs\n(LLMRG), has four components: chained graph reasoning, divergent extension,\nself-verification and scoring, and knowledge base self-improvement. The\nresulting reasoning graph is encoded using graph neural networks, which serves\nas additional input to improve conventional recommender systems, without\nrequiring extra user or item information. Our approach demonstrates how LLMs\ncan enable more logical and interpretable recommender systems through\npersonalized reasoning graphs. LLMRG allows recommendations to benefit from\nboth engineered recommendation systems and LLM-derived reasoning graphs. We\ndemonstrate the effectiveness of LLMRG on benchmarks and real-world scenarios\nin enhancing base recommendation models.\n",
                "链接": "https://arxiv.org/abs/2308.10835"
            },
            {
                "文章ID": "79948",
                "标题": "Automatic Model Selection with Large Language Models for Reasoning",
                "作者": " James Xu Zhao,  Yuxi Xie,  Kenji Kawaguchi,  Junxian He,  Michael Qizhe Xie",
                "发布日期": "2023-10-24",
                "摘要": "  Chain-of-Thought (CoT) and Program-Aided Language Models (PAL) represent two\ndistinct reasoning methods, each with its own strengths. CoT employs natural\nlanguage, offering flexibility and interpretability, while PAL utilizes\nprogramming language, yielding more structured and rigorous logic. We introduce\na model selection method to combine the best of both worlds by employing a\nlarge language model (LLM) to dynamically select between them. Our theoretical\nanalysis underscores the feasibility of this method, which is further\ncorroborated by empirical results. Our proposed method demonstrates significant\nperformance improvements across eight reasoning datasets with Codex, ChatGPT,\nand GPT-4. Additionally, our method is complementary to self-consistency; when\nintegrated, it can further enhance performance while significantly reducing\ncomputation costs. Moreover, we achieve new state-of-the-art results on GSM8K\nand SVAMP, with respective accuracies of 96.8% and 93.7%. Our code, data and\nprompts are available at https://github.com/XuZhao0/Model-Selection-Reasoning\n",
                "链接": "https://arxiv.org/abs/2305.14333"
            },
            {
                "文章ID": "96202",
                "标题": "Diagnostic Reasoning Prompts Reveal the Potential for Large Language\n  Model Interpretability in Medicine",
                "作者": " Thomas Savage,  Ashwin Nayak,  Robert Gallo,  Ekanath Rangan,  Jonathan H Chen",
                "发布日期": "2023-08-15",
                "摘要": "  One of the major barriers to using large language models (LLMs) in medicine\nis the perception they use uninterpretable methods to make clinical decisions\nthat are inherently different from the cognitive processes of clinicians. In\nthis manuscript we develop novel diagnostic reasoning prompts to study whether\nLLMs can perform clinical reasoning to accurately form a diagnosis. We find\nthat GPT4 can be prompted to mimic the common clinical reasoning processes of\nclinicians without sacrificing diagnostic accuracy. This is significant because\nan LLM that can use clinical reasoning to provide an interpretable rationale\noffers physicians a means to evaluate whether LLMs can be trusted for patient\ncare. Novel prompting methods have the potential to expose the black box of\nLLMs, bringing them one step closer to safe and effective use in medicine.\n",
                "链接": "https://arxiv.org/abs/2308.06834"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于大模型Agent应用的最新发表论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "10750",
                "标题": "Model-based Multi-agent Reinforcement Learning: Recent Progress and\n  Prospects",
                "作者": " Xihuai Wang,  Zhicheng Zhang,  Weinan Zhang",
                "发布日期": "2022-03-22",
                "摘要": "  Significant advances have recently been achieved in Multi-Agent Reinforcement\nLearning (MARL) which tackles sequential decision-making problems involving\nmultiple participants. However, MARL requires a tremendous number of samples\nfor effective training. On the other hand, model-based methods have been shown\nto achieve provable advantages of sample efficiency. However, the attempts of\nmodel-based methods to MARL have just started very recently. This paper\npresents a review of the existing research on model-based MARL, including\ntheoretical analyses, algorithms, and applications, and analyzes the advantages\nand potential of model-based MARL. Specifically, we provide a detailed taxonomy\nof the algorithms and point out the pros and cons for each algorithm according\nto the challenges inherent to multi-agent scenarios. We also outline promising\ndirections for future development of this field.\n",
                "链接": "https://arxiv.org/abs/2203.10603"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "98891",
                "标题": "RecMind: Large Language Model Powered Agent For Recommendation",
                "作者": " Yancheng Wang,  Ziyan Jiang,  Zheng Chen,  Fan Yang,  Yingxue Zhou,  Eunah Cho,  Xing Fan,  Xiaojiang Huang,  Yanbin Lu,  Yingzhen Yang",
                "发布日期": "2023-08-29",
                "摘要": "  Recent advancements in instructing Large Language Models (LLMs) to utilize\nexternal tools and execute multi-step plans have significantly enhanced their\nability to solve intricate tasks, ranging from mathematical problems to\ncreative writing. Yet, there remains a notable gap in studying the capacity of\nLLMs in responding to personalized queries such as a recommendation request. To\nbridge this gap, we have designed an LLM-powered autonomous recommender agent,\nRecMind, which is capable of providing precise personalized recommendations\nthrough careful planning, utilizing tools for obtaining external knowledge, and\nleveraging individual data. We propose a novel algorithm, Self-Inspiring, to\nimprove the planning ability of the LLM agent. At each intermediate planning\nstep, the LLM 'self-inspires' to consider all previously explored states to\nplan for next step. This mechanism greatly improves the model's ability to\ncomprehend and utilize historical planning information for recommendation. We\nevaluate RecMind's performance in various recommendation scenarios, including\nrating prediction, sequential recommendation, direct recommendation,\nexplanation generation, and review summarization. Our experiment shows that\nRecMind outperforms existing zero/few-shot LLM-based recommendation methods in\ndifferent recommendation tasks and achieves competitive performance to a recent\nmodel P5, which requires fully pre-train for the recommendation tasks.\n",
                "链接": "https://arxiv.org/abs/2308.14296"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "85679",
                "标题": "AVIS: Autonomous Visual Information Seeking with Large Language Model\n  Agent",
                "作者": " Ziniu Hu,  Ahmet Iscen,  Chen Sun,  Kai-Wei Chang,  Yizhou Sun,  David A Ross,  Cordelia Schmid,  Alireza Fathi",
                "发布日期": "2023-11-03",
                "摘要": "  In this paper, we propose an autonomous information seeking visual question\nanswering framework, AVIS. Our method leverages a Large Language Model (LLM) to\ndynamically strategize the utilization of external tools and to investigate\ntheir outputs, thereby acquiring the indispensable knowledge needed to provide\nanswers to the posed questions. Responding to visual questions that necessitate\nexternal knowledge, such as \"What event is commemorated by the building\ndepicted in this image?\", is a complex task. This task presents a combinatorial\nsearch space that demands a sequence of actions, including invoking APIs,\nanalyzing their responses, and making informed decisions. We conduct a user\nstudy to collect a variety of instances of human decision-making when faced\nwith this task. This data is then used to design a system comprised of three\ncomponents: an LLM-powered planner that dynamically determines which tool to\nuse next, an LLM-powered reasoner that analyzes and extracts key information\nfrom the tool outputs, and a working memory component that retains the acquired\ninformation throughout the process. The collected user behavior serves as a\nguide for our system in two key ways. First, we create a transition graph by\nanalyzing the sequence of decisions made by users. This graph delineates\ndistinct states and confines the set of actions available at each state.\nSecond, we use examples of user decision-making to provide our LLM-powered\nplanner and reasoner with relevant contextual instances, enhancing their\ncapacity to make informed decisions. We show that AVIS achieves\nstate-of-the-art results on knowledge-intensive visual question answering\nbenchmarks such as Infoseek and OK-VQA.\n",
                "链接": "https://arxiv.org/abs/2306.08129"
            },
            {
                "文章ID": "97404",
                "标题": "ChatEDA: A Large Language Model Powered Autonomous Agent for EDA",
                "作者": " Zhuolun He,  Haoyuan Wu,  Xinyun Zhang,  Xufeng Yao,  Su Zheng,  Haisheng Zheng,  Bei Yu",
                "发布日期": "2023-08-22",
                "摘要": "  The integration of a complex set of Electronic Design Automation (EDA) tools\nto enhance interoperability is a critical concern for circuit designers. Recent\nadvancements in large language models (LLMs) have showcased their exceptional\ncapabilities in natural language processing and comprehension, offering a novel\napproach to interfacing with EDA tools. This research paper introduces ChatEDA,\nan autonomous agent for EDA empowered by a large language model, AutoMage,\ncomplemented by EDA tools serving as executors. ChatEDA streamlines the design\nflow from the Register-Transfer Level (RTL) to the Graphic Data System Version\nII (GDSII) by effectively managing task planning, script generation, and task\nexecution. Through comprehensive experimental evaluations, ChatEDA has\ndemonstrated its proficiency in handling diverse requirements, and our\nfine-tuned AutoMage model has exhibited superior performance compared to GPT-4\nand other similar LLMs.\n",
                "链接": "https://arxiv.org/abs/2308.10204"
            },
            {
                "文章ID": "122182",
                "标题": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications",
                "作者": " Feibo Jiang,  Li Dong,  Yubo Peng,  Kezhi Wang,  Kun Yang,  Cunhua Pan,  Dusit Niyato,  Octavia A. Dobre",
                "发布日期": "2023-12-14",
                "摘要": "  The rapid development of the Large Language Model (LLM) presents huge\nopportunities for 6G communications, e.g., network optimization and management\nby allowing users to input task requirements to LLMs by nature language.\nHowever, directly applying native LLMs in 6G encounters various challenges,\nsuch as a lack of private communication data and knowledge, limited logical\nreasoning, evaluation, and refinement abilities. Integrating LLMs with the\ncapabilities of retrieval, planning, memory, evaluation and reflection in\nagents can greatly enhance the potential of LLMs for 6G communications. To this\nend, we propose a multi-agent system with customized communication knowledge\nand tools for solving communication related tasks using natural language,\ncomprising three components: (1) Multi-agent Data Retrieval (MDR), which\nemploys the condensate and inference agents to refine and summarize\ncommunication knowledge from the knowledge base, expanding the knowledge\nboundaries of LLMs in 6G communications; (2) Multi-agent Collaborative Planning\n(MCP), which utilizes multiple planning agents to generate feasible solutions\nfor the communication related task from different perspectives based on the\nretrieved knowledge; (3) Multi-agent Evaluation and Reflecxion (MER), which\nutilizes the evaluation agent to assess the solutions, and applies the\nreflexion agent and refinement agent to provide improvement suggestions for\ncurrent solutions. Finally, we validate the effectiveness of the proposed\nmulti-agent system by designing a semantic communication system, as a case\nstudy of 6G communications.\n",
                "链接": "https://arxiv.org/abs/2312.07850"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "103034",
                "标题": "Interactive Distillation of Large Single-Topic Corpora of Scientific\n  Papers",
                "作者": " Nicholas Solovyev,  Ryan Barron,  Manish Bhattarai,  Maksim E. Eren,  Kim O. Rasmussen,  Boian S. Alexandrov",
                "发布日期": "2023-09-20",
                "摘要": "  Highly specific datasets of scientific literature are important for both\nresearch and education. However, it is difficult to build such datasets at\nscale. A common approach is to build these datasets reductively by applying\ntopic modeling on an established corpus and selecting specific topics. A more\nrobust but time-consuming approach is to build the dataset constructively in\nwhich a subject matter expert (SME) handpicks documents. This method does not\nscale and is prone to error as the dataset grows. Here we showcase a new tool,\nbased on machine learning, for constructively generating targeted datasets of\nscientific literature. Given a small initial \"core\" corpus of papers, we build\na citation network of documents. At each step of the citation network, we\ngenerate text embeddings and visualize the embeddings through dimensionality\nreduction. Papers are kept in the dataset if they are \"similar\" to the core or\nare otherwise pruned through human-in-the-loop selection. Additional insight\ninto the papers is gained through sub-topic modeling using SeNMFk. We\ndemonstrate our new tool for literature review by applying it to two different\nfields in machine learning.\n",
                "链接": "https://arxiv.org/abs/2309.10772"
            }
        ]
    },
    {
        "question": {
            "question": "查询近一年模型推理加速相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "94780",
                "标题": "Radiation reaction on an accelerating point charge",
                "作者": " Jerrold Franklin",
                "发布日期": "2023-08-08",
                "摘要": "  A point charge accelerating under the influence of an external force emits\nelectromagnetic radiation that reduces the increase in its mechanical energy.\nThis causes a reduction in the particle's acceleration. We derive the decrease\nin acceleration due to radiation reaction for a particle accelerating parallel\nto its velocity, and show that it has a negligible effect.\n",
                "链接": "https://arxiv.org/abs/2308.02628"
            },
            {
                "文章ID": "114776",
                "标题": "LCM-LoRA: A Universal Stable-Diffusion Acceleration Module",
                "作者": " Simian Luo,  Yiqin Tan,  Suraj Patil,  Daniel Gu,  Patrick von Platen,  Apolinário Passos,  Longbo Huang,  Jian Li,  Hang Zhao",
                "发布日期": "2023-11-10",
                "摘要": "  Latent Consistency Models (LCMs) have achieved impressive performance in\naccelerating text-to-image generative tasks, producing high-quality images with\nminimal inference steps. LCMs are distilled from pre-trained latent diffusion\nmodels (LDMs), requiring only ~32 A100 GPU training hours. This report further\nextends LCMs' potential in two aspects: First, by applying LoRA distillation to\nStable-Diffusion models including SD-V1.5, SSD-1B, and SDXL, we have expanded\nLCM's scope to larger models with significantly less memory consumption,\nachieving superior image generation quality. Second, we identify the LoRA\nparameters obtained through LCM distillation as a universal Stable-Diffusion\nacceleration module, named LCM-LoRA. LCM-LoRA can be directly plugged into\nvarious Stable-Diffusion fine-tuned models or LoRAs without training, thus\nrepresenting a universally applicable accelerator for diverse image generation\ntasks. Compared with previous numerical PF-ODE solvers such as DDIM,\nDPM-Solver, LCM-LoRA can be viewed as a plug-in neural PF-ODE solver that\npossesses strong generalization abilities. Project page:\nhttps://github.com/luosiallen/latent-consistency-model.\n",
                "链接": "https://arxiv.org/abs/2311.05556"
            },
            {
                "文章ID": "108944",
                "标题": "Chameleon: a heterogeneous and disaggregated accelerator system for\n  retrieval-augmented language models",
                "作者": " Wenqi Jiang,  Marco Zeller,  Roger Waleffe,  Torsten Hoefler,  Gustavo Alonso",
                "发布日期": "2023-11-30",
                "摘要": "  A Retrieval-Augmented Language Model (RALM) augments a generative language\nmodel by retrieving context-specific knowledge from an external database. This\nstrategy facilitates impressive text generation quality even with smaller\nmodels, thus reducing orders of magnitude of computational demands. However,\nRALMs introduce unique system design challenges due to (a) the diverse workload\ncharacteristics between LM inference and retrieval and (b) the various system\nrequirements and bottlenecks for different RALM configurations such as model\nsizes, database sizes, and retrieval frequencies. We propose Chameleon, a\nheterogeneous accelerator system that integrates both LM and retrieval\naccelerators in a disaggregated architecture. The heterogeneity ensures\nefficient acceleration of both LM inference and retrieval, while the\naccelerator disaggregation enables the system to independently scale both types\nof accelerators to fulfill diverse RALM requirements. Our Chameleon prototype\nimplements retrieval accelerators on FPGAs and assigns LM inference to GPUs,\nwith a CPU server orchestrating these accelerators over the network. Compared\nto CPU-based and CPU-GPU vector search systems, Chameleon achieves up to 23.72x\nspeedup and 26.2x energy efficiency. Evaluated on various RALMs, Chameleon\nexhibits up to 2.16x reduction in latency and 3.18x speedup in throughput\ncompared to the hybrid CPU-GPU architecture. These promising results pave the\nway for bringing accelerator heterogeneity and disaggregation into future RALM\nsystems.\n",
                "链接": "https://arxiv.org/abs/2310.09949"
            },
            {
                "文章ID": "124055",
                "标题": "Accelerator-driven Data Arrangement to Minimize Transformers Run-time on\n  Multi-core Architectures",
                "作者": " Alireza Amirshahi,  Giovanni Ansaloni,  David Atienza",
                "发布日期": "2023-12-21",
                "摘要": "  The increasing complexity of transformer models in artificial intelligence\nexpands their computational costs, memory usage, and energy consumption.\nHardware acceleration tackles the ensuing challenges by designing processors\nand accelerators tailored for transformer models, supporting their computation\nhotspots with high efficiency. However, memory bandwidth can hinder\nimprovements in hardware accelerators. Against this backdrop, in this paper we\npropose a novel memory arrangement strategy, governed by the hardware\naccelerator's kernel size, which effectively minimizes off-chip data access.\nThis arrangement is particularly beneficial for end-to-end transformer model\ninference, where most of the computation is based on general matrix\nmultiplication (GEMM) operations. Additionally, we address the overhead of\nnon-GEMM operations in transformer models within the scope of this memory data\narrangement. Our study explores the implementation and effectiveness of the\nproposed accelerator-driven data arrangement approach in both single- and\nmulti-core systems. Our evaluation demonstrates that our approach can achieve\nup to a 2.8x speed increase when executing inferences employing\nstate-of-the-art transformers.\n",
                "链接": "https://arxiv.org/abs/2312.13000"
            },
            {
                "文章ID": "102164",
                "标题": "Draft & Verify: Lossless Large Language Model Acceleration via\n  Self-Speculative Decoding",
                "作者": " Jun Zhang,  Jue Wang,  Huan Li,  Lidan Shou,  Ke Chen,  Gang Chen,  Sharad Mehrotra",
                "发布日期": "2023-09-18",
                "摘要": "  We present a novel inference scheme, self-speculative decoding, for\naccelerating Large Language Models (LLMs) without the need for an auxiliary\nmodel. This approach is characterized by a two-stage process: drafting and\nverification. The drafting stage generates draft tokens at a slightly lower\nquality but more quickly, which is achieved by selectively skipping certain\nintermediate layers during drafting Subsequently, the verification stage\nemploys the original LLM to validate those draft output tokens in one forward\npass. This process ensures the final output remains identical to that produced\nby the unaltered LLM, thereby maintaining output quality. The proposed method\nrequires no additional neural network training and no extra memory footprint,\nmaking it a plug-and-play and cost-effective solution for inference\nacceleration. Benchmarks with LLaMA-2 and its fine-tuned models demonstrated a\nspeedup up to 1.73$\\times$.\n",
                "链接": "https://arxiv.org/abs/2309.08168"
            },
            {
                "文章ID": "100868",
                "标题": "Training Acceleration of Low-Rank Decomposed Networks using Sequential\n  Freezing and Rank Quantization",
                "作者": " Habib Hajimolahoseini,  Walid Ahmed,  Yang Liu",
                "发布日期": "2023-09-08",
                "摘要": "  Low Rank Decomposition (LRD) is a model compression technique applied to the\nweight tensors of deep learning models in order to reduce the number of\ntrainable parameters and computational complexity. However, due to high number\nof new layers added to the architecture after applying LRD, it may not lead to\na high training/inference acceleration if the decomposition ranks are not small\nenough. The issue is that using small ranks increases the risk of significant\naccuracy drop after decomposition. In this paper, we propose two techniques for\naccelerating low rank decomposed models without requiring to use small ranks\nfor decomposition. These methods include rank optimization and sequential\nfreezing of decomposed layers. We perform experiments on both convolutional and\ntransformer-based models. Experiments show that these techniques can improve\nthe model throughput up to 60% during training and 37% during inference when\ncombined together while preserving the accuracy close to that of the original\nmodels\n",
                "链接": "https://arxiv.org/abs/2309.03824"
            },
            {
                "文章ID": "124676",
                "标题": "Understanding the Potential of FPGA-Based Spatial Acceleration for Large\n  Language Model Inference",
                "作者": " Hongzheng Chen,  Jiahao Zhang,  Yixiao Du,  Shaojie Xiang,  Zichao Yue,  Niansong Zhang,  Yaohui Cai,  Zhiru Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Recent advancements in large language models (LLMs) boasting billions of\nparameters have generated a significant demand for efficient deployment in\ninference workloads. The majority of existing approaches rely on temporal\narchitectures that reuse hardware units for different network layers and\noperators. However, these methods often encounter challenges in achieving low\nlatency due to considerable memory access overhead. This paper investigates the\nfeasibility and potential of model-specific spatial acceleration for LLM\ninference on FPGAs. Our approach involves the specialization of distinct\nhardware units for specific operators or layers, facilitating direct\ncommunication between them through a dataflow architecture while minimizing\noff-chip memory accesses. We introduce a comprehensive analytical model for\nestimating the performance of a spatial LLM accelerator, taking into account\nthe on-chip compute and memory resources available on an FPGA. Through our\nanalysis, we can determine the scenarios in which FPGA-based spatial\nacceleration can outperform its GPU-based counterpart. To enable more\nproductive implementations of an LLM model on FPGAs, we further provide a\nlibrary of high-level synthesis (HLS) kernels that are composable and reusable.\nThis library will be made available as open-source. To validate the\neffectiveness of both our analytical model and HLS library, we have implemented\nBERT and GPT2 on an AMD Alveo U280 FPGA device. Experimental results\ndemonstrate our approach can achieve up to 16.1x speedup when compared to\nprevious FPGA-based accelerators for the BERT model. For GPT generative\ninference, we attain a 2.2x speedup compared to DFX, an FPGA overlay, in the\nprefill stage, while achieving a 1.9x speedup and a 5.7x improvement in energy\nefficiency compared to the NVIDIA A100 GPU in the decode stage.\n",
                "链接": "https://arxiv.org/abs/2312.15159"
            },
            {
                "文章ID": "116519",
                "标题": "Exponentially Faster Language Modelling",
                "作者": " Peter Belcak,  Roger Wattenhofer",
                "发布日期": "2023-11-22",
                "摘要": "  Language models only really need to use an exponential fraction of their\nneurons for individual inferences. As proof, we present UltraFastBERT, a BERT\nvariant that uses 0.3% of its neurons during inference while performing on par\nwith similar BERT models. UltraFastBERT selectively engages just 12 out of 4095\nneurons for each layer inference. This is achieved by replacing feedforward\nnetworks with fast feedforward networks (FFFs). While no truly efficient\nimplementation currently exists to unlock the full acceleration potential of\nconditional neural execution, we provide high-level CPU code achieving 78x\nspeedup over the optimized baseline feedforward implementation, and a PyTorch\nimplementation delivering 40x speedup over the equivalent batched feedforward\ninference. We publish our training code, benchmarking setup, and model weights.\n",
                "链接": "https://arxiv.org/abs/2311.10770"
            },
            {
                "文章ID": "89860",
                "标题": "ITA: An Energy-Efficient Attention and Softmax Accelerator for Quantized\n  Transformers",
                "作者": " Gamze İslamoğlu,  Moritz Scherer,  Gianna Paulin,  Tim Fischer,  Victor J. B. Jung,  Angelo Garofalo,  Luca Benini",
                "发布日期": "2023-07-11",
                "摘要": "  Transformer networks have emerged as the state-of-the-art approach for\nnatural language processing tasks and are gaining popularity in other domains\nsuch as computer vision and audio processing. However, the efficient hardware\nacceleration of transformer models poses new challenges due to their high\narithmetic intensities, large memory requirements, and complex dataflow\ndependencies. In this work, we propose ITA, a novel accelerator architecture\nfor transformers and related models that targets efficient inference on\nembedded systems by exploiting 8-bit quantization and an innovative softmax\nimplementation that operates exclusively on integer values. By computing\non-the-fly in streaming mode, our softmax implementation minimizes data\nmovement and energy consumption. ITA achieves competitive energy efficiency\nwith respect to state-of-the-art transformer accelerators with 16.9 TOPS/W,\nwhile outperforming them in area efficiency with 5.93 TOPS/mm$^2$ in 22 nm\nfully-depleted silicon-on-insulator technology at 0.8 V.\n",
                "链接": "https://arxiv.org/abs/2307.03493"
            },
            {
                "文章ID": "120589",
                "标题": "F3-Pruning: A Training-Free and Generalized Pruning Strategy towards\n  Faster and Finer Text-to-Video Synthesis",
                "作者": " Sitong Su,  Jianzhi Liu,  Lianli Gao,  Jingkuan Song",
                "发布日期": "2023-12-07",
                "摘要": "  Recently Text-to-Video (T2V) synthesis has undergone a breakthrough by\ntraining transformers or diffusion models on large-scale datasets.\nNevertheless, inferring such large models incurs huge costs.Previous inference\nacceleration works either require costly retraining or are model-specific.To\naddress this issue, instead of retraining we explore the inference process of\ntwo mainstream T2V models using transformers and diffusion models.The\nexploration reveals the redundancy in temporal attention modules of both\nmodels, which are commonly utilized to establish temporal relations among\nframes.Consequently, we propose a training-free and generalized pruning\nstrategy called F3-Pruning to prune redundant temporal attention\nweights.Specifically, when aggregate temporal attention values are ranked below\na certain ratio, corresponding weights will be pruned.Extensive experiments on\nthree datasets using a classic transformer-based model CogVideo and a typical\ndiffusion-based model Tune-A-Video verify the effectiveness of F3-Pruning in\ninference acceleration, quality assurance and broad applicability.\n",
                "链接": "https://arxiv.org/abs/2312.03459"
            }
        ]
    },
    {
        "question": {
            "question": "查找论文中包含指令微调细节描述的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "117394",
                "标题": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
                "作者": " Chengyu Wang,  Junbing Yan,  Wei Zhang,  Jun Huang",
                "发布日期": "2023-11-23",
                "摘要": "  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.13126"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "118911",
                "标题": "The devil is in the fine-grained details: Evaluating open-vocabulary\n  object detectors for fine-grained understanding",
                "作者": " Lorenzo Bianchi,  Fabio Carrara,  Nicola Messina,  Claudio Gennaro,  Fabrizio Falchi",
                "发布日期": "2023-11-30",
                "摘要": "  Recent advancements in large vision-language models enabled visual object\ndetection in open-vocabulary scenarios, where object classes are defined in\nfree-text formats during inference. In this paper, we aim to probe the\nstate-of-the-art methods for open-vocabulary object detection to determine to\nwhat extent they understand fine-grained properties of objects and their parts.\nTo this end, we introduce an evaluation protocol based on dynamic vocabulary\ngeneration to test whether models detect, discern, and assign the correct\nfine-grained description to objects in the presence of hard-negative classes.\nWe contribute with a benchmark suite of increasing difficulty and probing\ndifferent properties like color, pattern, and material. We further enhance our\ninvestigation by evaluating several state-of-the-art open-vocabulary object\ndetectors using the proposed protocol and find that most existing solutions,\nwhich shine in standard open-vocabulary benchmarks, struggle to accurately\ncapture and distinguish finer object details. We conclude the paper by\nhighlighting the limitations of current methodologies and exploring promising\nresearch directions to overcome the discovered drawbacks. Data and code are\navailable at https://github.com/lorebianchi98/FG-OVD.\n",
                "链接": "https://arxiv.org/abs/2311.17518"
            },
            {
                "文章ID": "123289",
                "标题": "Understanding the Instruction Mixture for Large Language Model\n  Fine-tuning",
                "作者": " Renxi Wang,  Minghao Wu,  Yuxia Wang,  Xudong Han,  Chiyu Zhang,  Haonan Li",
                "发布日期": "2023-12-20",
                "摘要": "  While instructions fine-tuning of large language models (LLMs) has been\nproven to enhance performance across various applications, the influence of the\ninstruction dataset mixture on LLMs has not been thoroughly explored. In this\nstudy, we classify instructions into three main types: NLP downstream tasks,\ncoding, and general chatting, and investigate their impact on LLMs. Our\nfindings reveal that specific types of instructions are more beneficial for\nparticular uses, while it may cause harms to other aspects, emphasizing the\nimportance of meticulously designing the instruction mixture to maximize model\nperformance. This study sheds light on the instruction mixture and paves the\nway for future research.\n",
                "链接": "https://arxiv.org/abs/2312.10793"
            },
            {
                "文章ID": "103771",
                "标题": "What is the Title of this Paper? Solving logic puzzles using algorithms",
                "作者": " Ujaan Rakshit,  Nishchal Dwivedi",
                "发布日期": "2023-09-26",
                "摘要": "  This work delves into the realm of logic puzzles by focusing on the Knight\nand Knave problems popularized by Raymond Smullyan in his book series \"What is\nthe Name of This Book?\". The puzzles revolve around characters known as Knights\n(truth-tellers) and Knaves (liars), challenging solvers to determine the true\nidentity of each person based on their statements. This paper explores the\nutilization of Python algorithms to automate the process of solving these\npuzzles, offering a computational approach that enhances efficiency and\naccessibility. In this work, we aim to develop a Python algorithm capable of\nparsing and analyzing the statements provided in the Knight and Knave puzzles.\nA logical reasoning framework is integrated within the algorithm to deduce the\nidentities of the characters based on their statements. The algorithm processes\nthe input statements, create a knowledge base, and make deductions following\nthe rules of Knight and Knave logic. The developed algorithm is thoroughly\ntested on various instances of Knight and Knave puzzles, comparing its results\nto known solutions and manual approaches. We further expand the scope of the\nproblem by introducing a Normal (who can sometimes lie and sometimes say the\ntruth).\n",
                "链接": "https://arxiv.org/abs/2309.13044"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "75172",
                "标题": "Outline, Then Details: Syntactically Guided Coarse-To-Fine Code\n  Generation",
                "作者": " Wenqing Zheng,  S P Sharan,  Ajay Kumar Jaiswal,  Kevin Wang,  Yihan Xi,  Dejia Xu,  Zhangyang Wang",
                "发布日期": "2023-07-20",
                "摘要": "  For a complicated algorithm, its implementation by a human programmer usually\nstarts with outlining a rough control flow followed by iterative enrichments,\neventually yielding carefully generated syntactic structures and variables in a\nhierarchy. However, state-of-the-art large language models generate codes in a\nsingle pass, without intermediate warm-ups to reflect the structured thought\nprocess of \"outline-then-detail\". Inspired by the recent success of\nchain-of-thought prompting, we propose ChainCoder, a program synthesis language\nmodel that generates Python code progressively, i.e. from coarse to fine in\nmultiple passes. We first decompose source code into layout frame components\nand accessory components via abstract syntax tree parsing to construct a\nhierarchical representation. We then reform our prediction target into a\nmulti-pass objective, each pass generates a subsequence, which is concatenated\nin the hierarchy. Finally, a tailored transformer architecture is leveraged to\njointly encode the natural language descriptions and syntactically aligned I/O\ndata samples. Extensive evaluations show that ChainCoder outperforms\nstate-of-the-arts, demonstrating that our progressive generation eases the\nreasoning procedure and guides the language model to generate higher-quality\nsolutions. Our codes are available at:\nhttps://github.com/VITA-Group/ChainCoder.\n",
                "链接": "https://arxiv.org/abs/2305.00909"
            },
            {
                "文章ID": "49528",
                "标题": "Recovering Fine Details for Neural Implicit Surface Reconstruction",
                "作者": " Decai Chen,  Peng Zhang,  Ingo Feldmann,  Oliver Schreer,  Peter Eisert",
                "发布日期": "2022-11-22",
                "摘要": "  Recent works on implicit neural representations have made significant\nstrides. Learning implicit neural surfaces using volume rendering has gained\npopularity in multi-view reconstruction without 3D supervision. However,\naccurately recovering fine details is still challenging, due to the underlying\nambiguity of geometry and appearance representation. In this paper, we present\nD-NeuS, a volume rendering-base neural implicit surface reconstruction method\ncapable to recover fine geometry details, which extends NeuS by two additional\nloss functions targeting enhanced reconstruction quality. First, we encourage\nthe rendered surface points from alpha compositing to have zero signed distance\nvalues, alleviating the geometry bias arising from transforming SDF to density\nfor volume rendering. Second, we impose multi-view feature consistency on the\nsurface points, derived by interpolating SDF zero-crossings from sampled points\nalong rays. Extensive quantitative and qualitative results demonstrate that our\nmethod reconstructs high-accuracy surfaces with details, and outperforms the\nstate of the art.\n",
                "链接": "https://arxiv.org/abs/2211.11320"
            },
            {
                "文章ID": "50760",
                "标题": "Fine-tuning language models to find agreement among humans with diverse\n  preferences",
                "作者": " Michiel A. Bakker,  Martin J. Chadwick,  Hannah R. Sheahan,  Michael Henry Tessler,  Lucy Campbell-Gillingham,  Jan Balaguer,  Nat McAleese,  Amelia Glaese,  John Aslanides,  Matthew M. Botvinick,  Christopher Summerfield",
                "发布日期": "2022-11-29",
                "摘要": "  Recent work in large language modeling (LLMs) has used fine-tuning to align\noutputs with the preferences of a prototypical user. This work assumes that\nhuman preferences are static and homogeneous across individuals, so that\naligning to a a single \"generic\" user will confer more general alignment. Here,\nwe embrace the heterogeneity of human preferences to consider a different\nchallenge: how might a machine help people with diverse views find agreement?\nWe fine-tune a 70 billion parameter LLM to generate statements that maximize\nthe expected approval for a group of people with potentially diverse opinions.\nHuman participants provide written opinions on thousands of questions touching\non moral and political issues (e.g., \"should we raise taxes on the rich?\"), and\nrate the LLM's generated candidate consensus statements for agreement and\nquality. A reward model is then trained to predict individual preferences,\nenabling it to quantify and rank consensus statements in terms of their appeal\nto the overall group, defined according to different aggregation (social\nwelfare) functions. The model produces consensus statements that are preferred\nby human users over those from prompted LLMs (>70%) and significantly\noutperforms a tight fine-tuned baseline that lacks the final ranking step.\nFurther, our best model's consensus statements are preferred over the best\nhuman-generated opinions (>65%). We find that when we silently constructed\nconsensus statements from only a subset of group members, those who were\nexcluded were more likely to dissent, revealing the sensitivity of the\nconsensus to individual contributions. These results highlight the potential to\nuse LLMs to help groups of humans align their values with one another.\n",
                "链接": "https://arxiv.org/abs/2211.15006"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本检测最新进展",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "43946",
                "标题": "OCR-VQGAN: Taming Text-within-Image Generation",
                "作者": " Juan A. Rodriguez,  David Vazquez,  Issam Laradji,  Marco Pedersoli,  Pau Rodriguez",
                "发布日期": "2022-10-26",
                "摘要": "  Synthetic image generation has recently experienced significant improvements\nin domains such as natural image or art generation. However, the problem of\nfigure and diagram generation remains unexplored. A challenging aspect of\ngenerating figures and diagrams is effectively rendering readable texts within\nthe images. To alleviate this problem, we present OCR-VQGAN, an image encoder,\nand decoder that leverages OCR pre-trained features to optimize a text\nperceptual loss, encouraging the architecture to preserve high-fidelity text\nand diagram structure. To explore our approach, we introduce the Paper2Fig100k\ndataset, with over 100k images of figures and texts from research papers. The\nfigures show architecture diagrams and methodologies of articles available at\narXiv.org from fields like artificial intelligence and computer vision. Figures\nusually include text and discrete objects, e.g., boxes in a diagram, with lines\nand arrows that connect them. We demonstrate the effectiveness of OCR-VQGAN by\nconducting several experiments on the task of figure reconstruction.\nAdditionally, we explore the qualitative and quantitative impact of weighting\ndifferent perceptual metrics in the overall loss function. We release code,\nmodels, and dataset at https://github.com/joanrod/ocr-vqgan.\n",
                "链接": "https://arxiv.org/abs/2210.11248"
            },
            {
                "文章ID": "39423",
                "标题": "Leveraging machine learning for less developed languages: Progress on\n  Urdu text detection",
                "作者": " Hazrat Ali",
                "发布日期": "2022-09-29",
                "摘要": "  Text detection in natural scene images has applications for autonomous\ndriving, navigation help for elderly and blind people. However, the research on\nUrdu text detection is usually hindered by lack of data resources. We have\ndeveloped a dataset of scene images with Urdu text. We present the use of\nmachine learning methods to perform detection of Urdu text from the scene\nimages. We extract text regions using channel enhanced Maximally Stable\nExtremal Region (MSER) method. First, we classify text and noise based on their\ngeometric properties. Next, we use a support vector machine for early\ndiscarding of non-text regions. To further remove the non-text regions, we use\nhistogram of oriented gradients (HoG) features obtained and train a second SVM\nclassifier. This improves the overall performance on text region detection\nwithin the scene images. To support research on Urdu text, We aim to make the\ndata freely available for research use. We also aim to highlight the challenges\nand the research gap for Urdu text detection.\n",
                "链接": "https://arxiv.org/abs/2209.14022"
            },
            {
                "文章ID": "87564",
                "标题": "Resume Information Extraction via Post-OCR Text Processing",
                "作者": " Selahattin Serdar Helli,  Senem Tanberk,  Sena Nur Cavsak",
                "发布日期": "2023-06-27",
                "摘要": "  Information extraction (IE), one of the main tasks of natural language\nprocessing (NLP), has recently increased importance in the use of resumes. In\nstudies on the text to extract information from the CV, sentence classification\nwas generally made using NLP models. In this study, it is aimed to extract\ninformation by classifying all of the text groups after pre-processing such as\nOptical Character Recognition (OCT) and object recognition with the YOLOv8\nmodel of the resumes. The text dataset consists of 286 resumes collected for 5\ndifferent (education, experience, talent, personal and language) job\ndescriptions in the IT industry. The dataset created for object recognition\nconsists of 1198 resumes, which were collected from the open-source internet\nand labeled as sets of text. BERT, BERT-t, DistilBERT, RoBERTa and XLNet were\nused as models. F1 score variances were used to compare the model results. In\naddition, the YOLOv8 model has also been reported comparatively in itself. As a\nresult of the comparison, DistilBERT was showed better results despite having a\nlower number of parameters than other models.\n",
                "链接": "https://arxiv.org/abs/2306.13775"
            },
            {
                "文章ID": "85288",
                "标题": "When Vision Fails: Text Attacks Against ViT and OCR",
                "作者": " Nicholas Boucher,  Jenny Blessing,  Ilia Shumailov,  Ross Anderson,  Nicolas Papernot",
                "发布日期": "2023-06-13",
                "摘要": "  While text-based machine learning models that operate on visual inputs of\nrendered text have become robust against a wide range of existing attacks, we\nshow that they are still vulnerable to visual adversarial examples encoded as\ntext. We use the Unicode functionality of combining diacritical marks to\nmanipulate encoded text so that small visual perturbations appear when the text\nis rendered. We show how a genetic algorithm can be used to generate visual\nadversarial examples in a black-box setting, and conduct a user study to\nestablish that the model-fooling adversarial examples do not affect human\ncomprehension. We demonstrate the effectiveness of these attacks in the real\nworld by creating adversarial examples against production models published by\nFacebook, Microsoft, IBM, and Google.\n",
                "链接": "https://arxiv.org/abs/2306.07033"
            },
            {
                "文章ID": "19555",
                "标题": "Detection Masking for Improved OCR on Noisy Documents",
                "作者": " Daniel Rotman,  Ophir Azulai,  Inbar Shapira,  Yevgeny Burshtein,  Udi Barzelay",
                "发布日期": "2022-05-18",
                "摘要": "  Optical Character Recognition (OCR), the task of extracting textual\ninformation from scanned documents is a vital and broadly used technology for\ndigitizing and indexing physical documents. Existing technologies perform well\nfor clean documents, but when the document is visually degraded, or when there\nare non-textual elements, OCR quality can be greatly impacted, specifically due\nto erroneous detections. In this paper we present an improved detection network\nwith a masking system to improve the quality of OCR performed on documents. By\nfiltering non-textual elements from the image we can utilize document-level OCR\nto incorporate contextual information to improve OCR results. We perform a\nunified evaluation on a publicly available dataset demonstrating the usefulness\nand broad applicability of our method. Additionally, we present and make\npublicly available our synthetic dataset with a unique hard-negative component\nspecifically tuned to improve detection results, and evaluate the benefits that\ncan be gained from its usage\n",
                "链接": "https://arxiv.org/abs/2205.08257"
            },
            {
                "文章ID": "36484",
                "标题": "Levenshtein OCR",
                "作者": " Cheng Da,  Peng Wang,  Cong Yao",
                "发布日期": "2022-11-15",
                "摘要": "  A novel scene text recognizer based on Vision-Language Transformer (VLT) is\npresented. Inspired by Levenshtein Transformer in the area of NLP, the proposed\nmethod (named Levenshtein OCR, and LevOCR for short) explores an alternative\nway for automatically transcribing textual content from cropped natural images.\nSpecifically, we cast the problem of scene text recognition as an iterative\nsequence refinement process. The initial prediction sequence produced by a pure\nvision model is encoded and fed into a cross-modal transformer to interact and\nfuse with the visual features, to progressively approximate the ground truth.\nThe refinement process is accomplished via two basic character-level\noperations: deletion and insertion, which are learned with imitation learning\nand allow for parallel decoding, dynamic length change and good\ninterpretability. The quantitative experiments clearly demonstrate that LevOCR\nachieves state-of-the-art performances on standard benchmarks and the\nqualitative analyses verify the effectiveness and advantage of the proposed\nLevOCR algorithm. Code is available at\nhttps://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/LevOCR.\n",
                "链接": "https://arxiv.org/abs/2209.03594"
            },
            {
                "文章ID": "98478",
                "标题": "DISGO: Automatic End-to-End Evaluation for Scene Text OCR",
                "作者": " Mei-Yuh Hwang,  Yangyang Shi,  Ankit Ramchandani,  Guan Pang,  Praveen Krishnan,  Lucas Kabela,  Frank Seide,  Samyak Datta,  Jun Liu",
                "发布日期": "2023-08-28",
                "摘要": "  This paper discusses the challenges of optical character recognition (OCR) on\nnatural scenes, which is harder than OCR on documents due to the wild content\nand various image backgrounds. We propose to uniformly use word error rates\n(WER) as a new measurement for evaluating scene-text OCR, both end-to-end (e2e)\nperformance and individual system component performances. Particularly for the\ne2e metric, we name it DISGO WER as it considers Deletion, Insertion,\nSubstitution, and Grouping/Ordering errors. Finally we propose to utilize the\nconcept of super blocks to automatically compute BLEU scores for e2e OCR\nmachine translation. The small SCUT public test set is used to demonstrate WER\nperformance by a modularized OCR system.\n",
                "链接": "https://arxiv.org/abs/2308.13173"
            },
            {
                "文章ID": "7207",
                "标题": "OCR-IDL: OCR Annotations for Industry Document Library Dataset",
                "作者": " Ali Furkan Biten,  Rubèn Tito,  Lluis Gomez,  Ernest Valveny,  Dimosthenis Karatzas",
                "发布日期": "2022-03-01",
                "摘要": "  Pretraining has proven successful in Document Intelligence tasks where deluge\nof documents are used to pretrain the models only later to be finetuned on\ndownstream tasks. One of the problems of the pretraining approaches is the\ninconsistent usage of pretraining data with different OCR engines leading to\nincomparable results between models. In other words, it is not obvious whether\nthe performance gain is coming from diverse usage of amount of data and\ndistinct OCR engines or from the proposed models. To remedy the problem, we\nmake public the OCR annotations for IDL documents using commercial OCR engine\ngiven their superior performance over open source OCR models. The contributed\ndataset (OCR-IDL) has an estimated monetary value over 20K US$. It is our hope\nthat OCR-IDL can be a starting point for future works on Document Intelligence.\nAll of our data and its collection process with the annotations can be found in\nhttps://github.com/furkanbiten/idl_data.\n",
                "链接": "https://arxiv.org/abs/2202.12985"
            },
            {
                "文章ID": "48455",
                "标题": "A Benchmark and Dataset for Post-OCR text correction in Sanskrit",
                "作者": " Ayush Maheshwari,  Nikhil Singh,  Amrith Krishna,  Ganesh Ramakrishnan",
                "发布日期": "2022-11-16",
                "摘要": "  Sanskrit is a classical language with about 30 million extant manuscripts fit\nfor digitisation, available in written, printed or scannedimage forms. However,\nit is still considered to be a low-resource language when it comes to available\ndigital resources. In this work, we release a post-OCR text correction dataset\ncontaining around 218,000 sentences, with 1.5 million words, from 30 different\nbooks. Texts in Sanskrit are known to be diverse in terms of their linguistic\nand stylistic usage since Sanskrit was the 'lingua franca' for discourse in the\nIndian subcontinent for about 3 millennia. Keeping this in mind, we release a\nmulti-domain dataset, from areas as diverse as astronomy, medicine and\nmathematics, with some of them as old as 18 centuries. Further, we release\nmultiple strong baselines as benchmarks for the task, based on pre-trained\nSeq2Seq language models. We find that our best-performing model, consisting of\nbyte level tokenization in conjunction with phonetic encoding (Byt5+SLP1),\nyields a 23% point increase over the OCR output in terms of word and character\nerror rates. Moreover, we perform extensive experiments in evaluating these\nmodels on their performance and analyse common causes of mispredictions both at\nthe graphemic and lexical levels. Our code and dataset is publicly available at\nhttps://github.com/ayushbits/pe-ocr-sanskrit.\n",
                "链接": "https://arxiv.org/abs/2211.07980"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本识别最新进展。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "90438",
                "标题": "Handwritten Text Recognition Using Convolutional Neural Network",
                "作者": " Atman Mishra,  A. Sharath Ram,  Kavyashree C",
                "发布日期": "2023-07-12",
                "摘要": "  OCR (Optical Character Recognition) is a technology that offers comprehensive\nalphanumeric recognition of handwritten and printed characters at electronic\nspeed by merely scanning the document. Recently, the understanding of visual\ndata has been termed Intelligent Character Recognition (ICR). Intelligent\nCharacter Recognition (ICR) is the OCR module that can convert scans of\nhandwritten or printed characters into ASCII text. ASCII data is the standard\nformat for data encoding in electronic communication. ASCII assigns standard\nnumeric values to letters, numeral, symbols, white-spaces and other characters.\nIn more technical terms, OCR is the process of using an electronic device to\ntransform 2-Dimensional textual information into machine-encoded text. Anything\nthat contains text both machine written or handwritten can be scanned either\nthrough a scanner or just simply a picture of the text is enough for the\nrecognition system to distinguish the text. The goal of this papers is to show\nthe results of a Convolutional Neural Network model which has been trained on\nNational Institute of Science and Technology (NIST) dataset containing over a\n100,000 images. The network learns from the features extracted from the images\nand use it to generate the probability of each class to which the picture\nbelongs to. We have achieved an accuracy of 90.54% with a loss of 2.53%.\n",
                "链接": "https://arxiv.org/abs/2307.05396"
            },
            {
                "文章ID": "100439",
                "标题": "STEP -- Towards Structured Scene-Text Spotting",
                "作者": " Sergi Garcia-Bordils,  Dimosthenis Karatzas,  Marçal Rusiñol",
                "发布日期": "2023-12-12",
                "摘要": "  We introduce the structured scene-text spotting task, which requires a\nscene-text OCR system to spot text in the wild according to a query regular\nexpression. Contrary to generic scene text OCR, structured scene-text spotting\nseeks to dynamically condition both scene text detection and recognition on\nuser-provided regular expressions. To tackle this task, we propose the\nStructured TExt sPotter (STEP), a model that exploits the provided text\nstructure to guide the OCR process. STEP is able to deal with regular\nexpressions that contain spaces and it is not bound to detection at the\nword-level granularity. Our approach enables accurate zero-shot structured text\nspotting in a wide variety of real-world reading scenarios and is solely\ntrained on publicly available data. To demonstrate the effectiveness of our\napproach, we introduce a new challenging test dataset that contains several\ntypes of out-of-vocabulary structured text, reflecting important reading\napplications of fields such as prices, dates, serial numbers, license plates\netc. We demonstrate that STEP can provide specialised OCR performance on demand\nin all tested scenarios.\n",
                "链接": "https://arxiv.org/abs/2309.02356"
            },
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "97589",
                "标题": "bbOCR: An Open-source Multi-domain OCR Pipeline for Bengali Documents",
                "作者": " Imam Mohammad Zulkarnain,  Shayekh Bin Islam,  Md. Zami Al Zunaed Farabe,  Md. Mehedi Hasan Shawon,  Jawaril Munshad Abedin,  Beig Rajibul Hasan,  Marsia Haque,  Istiak Shihab,  Syed Mobassir,  MD. Nazmuddoha Ansary,  Asif Sushmit,  Farig Sadeque",
                "发布日期": "2023-08-23",
                "摘要": "  Despite the existence of numerous Optical Character Recognition (OCR) tools,\nthe lack of comprehensive open-source systems hampers the progress of document\ndigitization in various low-resource languages, including Bengali. Low-resource\nlanguages, especially those with an alphasyllabary writing system, suffer from\nthe lack of large-scale datasets for various document OCR components such as\nword-level OCR, document layout extraction, and distortion correction; which\nare available as individual modules in high-resource languages. In this paper,\nwe introduce Bengali$.$AI-BRACU-OCR (bbOCR): an open-source scalable document\nOCR system that can reconstruct Bengali documents into a structured searchable\ndigitized format that leverages a novel Bengali text recognition model and two\nnovel synthetic datasets. We present extensive component-level and system-level\nevaluation: both use a novel diversified evaluation dataset and comprehensive\nevaluation metrics. Our extensive evaluation suggests that our proposed\nsolution is preferable over the current state-of-the-art Bengali OCR systems.\nThe source codes and datasets are available here:\nhttps://bengaliai.github.io/bbocr.\n",
                "链接": "https://arxiv.org/abs/2308.10647"
            },
            {
                "文章ID": "54214",
                "标题": "Transferring General Multimodal Pretrained Models to Text Recognition",
                "作者": " Junyang Lin,  Xuancheng Ren,  Yichang Zhang,  Gao Liu,  Peng Wang,  An Yang,  Chang Zhou",
                "发布日期": "2022-12-20",
                "摘要": "  This paper proposes a new method, OFA-OCR, to transfer multimodal pretrained\nmodels to text recognition. Specifically, we recast text recognition as image\ncaptioning and directly transfer a unified vision-language pretrained model to\nthe end task. Without pretraining on large-scale annotated or synthetic text\nrecognition data, OFA-OCR outperforms the baselines and achieves\nstate-of-the-art performance in the Chinese text recognition benchmark.\nAdditionally, we construct an OCR pipeline with OFA-OCR, and we demonstrate\nthat it can achieve competitive performance with the product-level API. The\ncode (https://github.com/OFA-Sys/OFA) and demo\n(https://modelscope.cn/studios/damo/ofa_ocr_pipeline/summary) are publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2212.09297"
            },
            {
                "文章ID": "90096",
                "标题": "A Novel Pipeline for Improving Optical Character Recognition through\n  Post-processing Using Natural Language Processing",
                "作者": " Aishik Rakshit,  Samyak Mehta,  Anirban Dasgupta",
                "发布日期": "2023-07-11",
                "摘要": "  Optical Character Recognition (OCR) technology finds applications in\ndigitizing books and unstructured documents, along with applications in other\ndomains such as mobility statistics, law enforcement, traffic, security\nsystems, etc. The state-of-the-art methods work well with the OCR with printed\ntext on license plates, shop names, etc. However, applications such as printed\ntextbooks and handwritten texts have limited accuracy with existing techniques.\nThe reason may be attributed to similar-looking characters and variations in\nhandwritten characters. Since these issues are challenging to address with OCR\ntechnologies exclusively, we propose a post-processing approach using Natural\nLanguage Processing (NLP) tools. This work presents an end-to-end pipeline that\nfirst performs OCR on the handwritten or printed text and then improves its\naccuracy using NLP.\n",
                "链接": "https://arxiv.org/abs/2307.04245"
            },
            {
                "文章ID": "111490",
                "标题": "Exploring OCR Capabilities of GPT-4V(ision) : A Quantitative and\n  In-depth Evaluation",
                "作者": " Yongxin Shi,  Dezhi Peng,  Wenhui Liao,  Zening Lin,  Xinhong Chen,  Chongyu Liu,  Yuyi Zhang,  Lianwen Jin",
                "发布日期": "2023-10-31",
                "摘要": "  This paper presents a comprehensive evaluation of the Optical Character\nRecognition (OCR) capabilities of the recently released GPT-4V(ision), a Large\nMultimodal Model (LMM). We assess the model's performance across a range of OCR\ntasks, including scene text recognition, handwritten text recognition,\nhandwritten mathematical expression recognition, table structure recognition,\nand information extraction from visually-rich document. The evaluation reveals\nthat GPT-4V performs well in recognizing and understanding Latin contents, but\nstruggles with multilingual scenarios and complex tasks. Specifically, it\nshowed limitations when dealing with non-Latin languages and complex tasks such\nas handwriting mathematical expression recognition, table structure\nrecognition, and end-to-end semantic entity recognition and pair extraction\nfrom document image. Based on these observations, we affirm the necessity and\ncontinued research value of specialized OCR models. In general, despite its\nversatility in handling diverse OCR tasks, GPT-4V does not outperform existing\nstate-of-the-art OCR models. How to fully utilize pre-trained general-purpose\nLMMs such as GPT-4V for OCR downstream tasks remains an open problem. The study\noffers a critical reference for future research in OCR with LMMs. Evaluation\npipeline and results are available at\nhttps://github.com/SCUT-DLVCLab/GPT-4V_OCR.\n",
                "链接": "https://arxiv.org/abs/2310.16809"
            },
            {
                "文章ID": "94665",
                "标题": "Universal Defensive Underpainting Patch: Making Your Text Invisible to\n  Optical Character Recognition",
                "作者": " JiaCheng Deng,  Li Dong,  Jiahao Chen,  Diqun Yan,  Rangding Wang,  Dengpan Ye,  Lingchen Zhao,  Jinyu Tian",
                "发布日期": "2023-08-07",
                "摘要": "  Optical Character Recognition (OCR) enables automatic text extraction from\nscanned or digitized text images, but it also makes it easy to pirate valuable\nor sensitive text from these images. Previous methods to prevent OCR piracy by\ndistorting characters in text images are impractical in real-world scenarios,\nas pirates can capture arbitrary portions of the text images, rendering the\ndefenses ineffective. In this work, we propose a novel and effective defense\nmechanism termed the Universal Defensive Underpainting Patch (UDUP) that\nmodifies the underpainting of text images instead of the characters. UDUP is\ncreated through an iterative optimization process to craft a small, fixed-size\ndefensive patch that can generate non-overlapping underpainting for text images\nof any size. Experimental results show that UDUP effectively defends against\nunauthorized OCR under the setting of any screenshot range or complex image\nbackground. It is agnostic to the content, size, colors, and languages of\ncharacters, and is robust to typical image operations such as scaling and\ncompressing. In addition, the transferability of UDUP is demonstrated by\nevading several off-the-shelf OCRs. The code is available at\nhttps://github.com/QRICKDD/UDUP.\n",
                "链接": "https://arxiv.org/abs/2308.02369"
            },
            {
                "文章ID": "123651",
                "标题": "Advancements and Challenges in Arabic Optical Character Recognition: A\n  Comprehensive Survey",
                "作者": " Mahmoud SalahEldin Kasem,  Mohamed Mahmoud,  Hyun-Soo Kang",
                "发布日期": "2023-12-20",
                "摘要": "  Optical character recognition (OCR) is a vital process that involves the\nextraction of handwritten or printed text from scanned or printed images,\nconverting it into a format that can be understood and processed by machines.\nThis enables further data processing activities such as searching and editing.\nThe automatic extraction of text through OCR plays a crucial role in digitizing\ndocuments, enhancing productivity, improving accessibility, and preserving\nhistorical records. This paper seeks to offer an exhaustive review of\ncontemporary applications, methodologies, and challenges associated with Arabic\nOptical Character Recognition (OCR). A thorough analysis is conducted on\nprevailing techniques utilized throughout the OCR process, with a dedicated\neffort to discern the most efficacious approaches that demonstrate enhanced\noutcomes. To ensure a thorough evaluation, a meticulous keyword-search\nmethodology is adopted, encompassing a comprehensive analysis of articles\nrelevant to Arabic OCR, including both backward and forward citation reviews.\nIn addition to presenting cutting-edge techniques and methods, this paper\ncritically identifies research gaps within the realm of Arabic OCR. By\nhighlighting these gaps, we shed light on potential areas for future\nexploration and development, thereby guiding researchers toward promising\navenues in the field of Arabic OCR. The outcomes of this study provide valuable\ninsights for researchers, practitioners, and stakeholders involved in Arabic\nOCR, ultimately fostering advancements in the field and facilitating the\ncreation of more accurate and efficient OCR systems for the Arabic language.\n",
                "链接": "https://arxiv.org/abs/2312.11812"
            },
            {
                "文章ID": "115320",
                "标题": "What Large Language Models Bring to Text-rich VQA?",
                "作者": " Xuejing Liu,  Wei Tang,  Xinzhe Ni,  Jinghui Lu,  Rui Zhao,  Zechao Li,  Fei Tan",
                "发布日期": "2023-11-14",
                "摘要": "  Text-rich VQA, namely Visual Question Answering based on text recognition in\nthe images, is a cross-modal task that requires both image comprehension and\ntext recognition. In this work, we focus on investigating the advantages and\nbottlenecks of LLM-based approaches in addressing this problem. To address the\nabove concern, we separate the vision and language modules, where we leverage\nexternal OCR models to recognize texts in the image and Large Language Models\n(LLMs) to answer the question given texts. The whole framework is training-free\nbenefiting from the in-context ability of LLMs. This pipeline achieved superior\nperformance compared to the majority of existing Multimodal Large Language\nModels (MLLM) on four text-rich VQA datasets. Besides, based on the ablation\nstudy, we find that LLM brings stronger comprehension ability and may introduce\nhelpful knowledge for the VQA problem. The bottleneck for LLM to address\ntext-rich VQA problems may primarily lie in visual part. We also combine the\nOCR module with MLLMs and pleasantly find that the combination of OCR module\nwith MLLM also works. It's worth noting that not all MLLMs can comprehend the\nOCR information, which provides insights into how to train an MLLM that\npreserves the abilities of LLM.\n",
                "链接": "https://arxiv.org/abs/2311.07306"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月agent系列决策文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "56258",
                "标题": "Evidence of behavior consistent with self-interest and altruism in an\n  artificially intelligent agent",
                "作者": " Tim Johnson,  Nick Obradovich",
                "发布日期": "2023-01-09",
                "摘要": "  Members of various species engage in altruism--i.e. accepting personal costs\nto benefit others. Here we present an incentivized experiment to test for\naltruistic behavior among AI agents consisting of large language models\ndeveloped by the private company OpenAI. Using real incentives for AI agents\nthat take the form of tokens used to purchase their services, we first examine\nwhether AI agents maximize their payoffs in a non-social decision task in which\nthey select their payoff from a given range. We then place AI agents in a\nseries of dictator games in which they can share resources with a\nrecipient--either another AI agent, the human experimenter, or an anonymous\ncharity, depending on the experimental condition. Here we find that only the\nmost-sophisticated AI agent in the study maximizes its payoffs more often than\nnot in the non-social decision task (it does so in 92% of all trials), and this\nAI agent also exhibits the most-generous altruistic behavior in the dictator\ngame, resembling humans' rates of sharing with other humans in the game. The\nagent's altruistic behaviors, moreover, vary by recipient: the AI agent shared\nsubstantially less of the endowment with the human experimenter or an anonymous\ncharity than with other AI agents. Our findings provide evidence of behavior\nconsistent with self-interest and altruism in an AI agent. Moreover, our study\nalso offers a novel method for tracking the development of such behaviors in\nfuture AI agents.\n",
                "链接": "https://arxiv.org/abs/2301.02330"
            },
            {
                "文章ID": "21021",
                "标题": "MAVIPER: Learning Decision Tree Policies for Interpretable Multi-Agent\n  Reinforcement Learning",
                "作者": " Stephanie Milani,  Zhicheng Zhang,  Nicholay Topin,  Zheyuan Ryan Shi,  Charles Kamhoua,  Evangelos E. Papalexakis,  Fei Fang",
                "发布日期": "2022-07-13",
                "摘要": "  Many recent breakthroughs in multi-agent reinforcement learning (MARL)\nrequire the use of deep neural networks, which are challenging for human\nexperts to interpret and understand. On the other hand, existing work on\ninterpretable reinforcement learning (RL) has shown promise in extracting more\ninterpretable decision tree-based policies from neural networks, but only in\nthe single-agent setting. To fill this gap, we propose the first set of\nalgorithms that extract interpretable decision-tree policies from neural\nnetworks trained with MARL. The first algorithm, IVIPER, extends VIPER, a\nrecent method for single-agent interpretable RL, to the multi-agent setting. We\ndemonstrate that IVIPER learns high-quality decision-tree policies for each\nagent. To better capture coordination between agents, we propose a novel\ncentralized decision-tree training algorithm, MAVIPER. MAVIPER jointly grows\nthe trees of each agent by predicting the behavior of the other agents using\ntheir anticipated trees, and uses resampling to focus on states that are\ncritical for its interactions with other agents. We show that both algorithms\ngenerally outperform the baselines and that MAVIPER-trained agents achieve\nbetter-coordinated performance than IVIPER-trained agents on three different\nmulti-agent particle-world environments.\n",
                "链接": "https://arxiv.org/abs/2205.12449"
            },
            {
                "文章ID": "90666",
                "标题": "Maneuver Decision-Making Through Automatic Curriculum Reinforcement\n  Learning Without Handcrafted Reward functions",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-07-13",
                "摘要": "  Maneuver decision-making is the core of unmanned combat aerial vehicle for\nautonomous air combat. To solve this problem, we propose an automatic\ncurriculum reinforcement learning method, which enables agents to learn\neffective decisions in air combat from scratch. The range of initial states are\nused for distinguishing curricula of different difficulty levels, thereby\nmaneuver decision is divided into a series of sub-tasks from easy to difficult,\nand test results are used to change sub-tasks. As sub-tasks change, agents\ngradually learn to complete a series of sub-tasks from easy to difficult,\nenabling them to make effective maneuvering decisions to cope with various\nstates without the need to spend effort designing reward functions. The\nablation studied show that the automatic curriculum learning proposed in this\narticle is an essential component for training through reinforcement learning,\nnamely, agents cannot complete effective decisions without curriculum learning.\nSimulation experiments show that, after training, agents are able to make\neffective decisions given different states, including tracking, attacking and\nescaping, which are both rational and interpretable.\n",
                "链接": "https://arxiv.org/abs/2307.06152"
            },
            {
                "文章ID": "116901",
                "标题": "Approximate Linear Programming and Decentralized Policy Improvement in\n  Cooperative Multi-agent Markov Decision Processes",
                "作者": " Lakshmi Mandal,  Chandrashekar Lakshminarayanan,  Shalabh Bhatnagar",
                "发布日期": "2023-11-21",
                "摘要": "  In this work, we consider a `cooperative' multi-agent Markov decision process\n(MDP) involving m greater than 1 agents, where all agents are aware of the\nsystem model. At each decision epoch, all the m agents cooperatively select\nactions in order to maximize a common long-term objective. Since the number of\nactions grows exponentially in the number of agents, policy improvement is\ncomputationally expensive. Recent works have proposed using decentralized\npolicy improvement in which each agent assumes that the decisions of the other\nagents are fixed and it improves its decisions unilaterally. Yet, in these\nworks, exact values are computed. In our work, for cooperative multi-agent\nfinite and infinite horizon discounted MDPs, we propose suitable approximate\npolicy iteration algorithms, wherein we use approximate linear programming to\ncompute the approximate value function and use decentralized policy\nimprovement. Thus our algorithms can handle both large number of states as well\nas multiple agents. We provide theoretical guarantees for our algorithms and\nalso demonstrate the performance of our algorithms on some numerical examples.\n",
                "链接": "https://arxiv.org/abs/2311.11789"
            },
            {
                "文章ID": "8476",
                "标题": "Diversifying Agent's Behaviors in Interactive Decision Models",
                "作者": " Yinghui Pan,  Hanyi Zhang,  Yifeng Zeng,  Biyang Ma,  Jing Tang,  Zhong Ming",
                "发布日期": "2022-03-08",
                "摘要": "  Modelling other agents' behaviors plays an important role in decision models\nfor interactions among multiple agents. To optimise its own decisions, a\nsubject agent needs to model what other agents act simultaneously in an\nuncertain environment. However, modelling insufficiency occurs when the agents\nare competitive and the subject agent can not get full knowledge about other\nagents. Even when the agents are collaborative, they may not share their true\nbehaviors due to their privacy concerns. In this article, we investigate into\ndiversifying behaviors of other agents in the subject agent's decision model\nprior to their interactions. Starting with prior knowledge about other agents'\nbehaviors, we use a linear reduction technique to extract representative\nbehavioral features from the known behaviors. We subsequently generate their\nnew behaviors by expanding the features and propose two diversity measurements\nto select top-K behaviors. We demonstrate the performance of the new techniques\nin two well-studied problem domains. This research will contribute to\nintelligent systems dealing with unknown unknowns in an open artificial\nintelligence world.\n",
                "链接": "https://arxiv.org/abs/2203.03068"
            },
            {
                "文章ID": "105972",
                "标题": "AutoCast++: Enhancing World Event Prediction with Zero-shot\n  Ranking-based Context Retrieval",
                "作者": " Qi Yan,  Raihan Seraj,  Jiawei He,  Lili Meng,  Tristan Sylvain",
                "发布日期": "2023-10-04",
                "摘要": "  Machine-based prediction of real-world events is garnering attention due to\nits potential for informed decision-making. Whereas traditional forecasting\npredominantly hinges on structured data like time-series, recent breakthroughs\nin language models enable predictions using unstructured text. In particular,\n(Zou et al., 2022) unveils AutoCast, a new benchmark that employs news articles\nfor answering forecasting queries. Nevertheless, existing methods still trail\nbehind human performance. The cornerstone of accurate forecasting, we argue,\nlies in identifying a concise, yet rich subset of news snippets from a vast\ncorpus. With this motivation, we introduce AutoCast++, a zero-shot\nranking-based context retrieval system, tailored to sift through expansive news\ndocument collections for event forecasting. Our approach first re-ranks\narticles based on zero-shot question-passage relevance, honing in on\nsemantically pertinent news. Following this, the chosen articles are subjected\nto zero-shot summarization to attain succinct context. Leveraging a pre-trained\nlanguage model, we conduct both the relevance evaluation and article\nsummarization without needing domain-specific training. Notably, recent\narticles can sometimes be at odds with preceding ones due to new facts or\nunanticipated incidents, leading to fluctuating temporal dynamics. To tackle\nthis, our re-ranking mechanism gives preference to more recent articles, and we\nfurther regularize the multi-passage representation learning to align with\nhuman forecaster responses made on different dates. Empirical results\nunderscore marked improvements across multiple metrics, improving the\nperformance for multiple-choice questions (MCQ) by 48% and true/false (TF)\nquestions by up to 8%.\n",
                "链接": "https://arxiv.org/abs/2310.01880"
            },
            {
                "文章ID": "40701",
                "标题": "Cost Aware Asynchronous Multi-Agent Active Search",
                "作者": " Arundhati Banerjee,  Ramina Ghods,  Jeff Schneider",
                "发布日期": "2022-10-06",
                "摘要": "  Multi-agent active search requires autonomous agents to choose sensing\nactions that efficiently locate targets. In a realistic setting, agents also\nmust consider the costs that their decisions incur. Previously proposed active\nsearch algorithms simplify the problem by ignoring uncertainty in the agent's\nenvironment, using myopic decision making, and/or overlooking costs. In this\npaper, we introduce an online active search algorithm to detect targets in an\nunknown environment by making adaptive cost-aware decisions regarding the\nagent's actions. Our algorithm combines principles from Thompson Sampling (for\nsearch space exploration and decentralized multi-agent decision making), Monte\nCarlo Tree Search (for long horizon planning) and pareto-optimal confidence\nbounds (for multi-objective optimization in an unknown environment) to propose\nan online lookahead planner that removes all the simplifications. We analyze\nthe algorithm's performance in simulation to show its efficacy in cost aware\nactive search.\n",
                "链接": "https://arxiv.org/abs/2210.02259"
            },
            {
                "文章ID": "102301",
                "标题": "Maneuver Decision-Making Through Proximal Policy Optimization And Monte\n  Carlo Tree Search",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-09-19",
                "摘要": "  Maneuver decision-making can be regarded as a Markov decision process and can\nbe address by reinforcement learning. However, original reinforcement learning\nalgorithms can hardly solve the maneuvering decision-making problem. One reason\nis that agents use random actions in the early stages of training, which makes\nit difficult to get rewards and learn how to make effective decisions. To\naddress this issue, a method based on proximal policy optimization and Monte\nCarlo tree search is proposed. The method uses proximal policy optimization to\ntrain the agent, and regards the results of air combat as targets to train the\nvalue network. Then, based on the value network and the visit count of each\nnode, Monte Carlo tree search is used to find the actions with more expected\nreturns than random actions, which can improve the training performance. The\nablation studies and simulation experiments indicate that agents trained by the\nproposed method can make different decisions according to different states,\nwhich demonstrates that the method can solve the maneuvering decision problem\nthat the original reinforcement learning algorithm cannot solve.\n",
                "链接": "https://arxiv.org/abs/2309.08611"
            },
            {
                "文章ID": "118042",
                "标题": "A GPU-based Hydrodynamic Simulator with Boid Interactions",
                "作者": " Xi Liu,  Gizem Kayar,  Ken Perlin",
                "发布日期": "2023-12-22",
                "摘要": "  We present a hydrodynamic simulation system using the GPU compute shaders of\nDirectX for simulating virtual agent behaviors and navigation inside a smoothed\nparticle hydrodynamical (SPH) fluid environment with real-time water mesh\nsurface reconstruction. The current SPH literature includes interactions\nbetween SPH and heterogeneous meshes but seldom involves interactions between\nSPH and virtual boid agents. The contribution of the system lies in the\ncombination of the parallel smoothed particle hydrodynamics model with the\ndistributed boid model of virtual agents to enable agents to interact with\nfluids. The agents based on the boid algorithm influence the motion of SPH\nfluid particles, and the forces from the SPH algorithm affect the movement of\nthe boids. To enable realistic fluid rendering and simulation in a\nparticle-based system, it is essential to construct a mesh from the particle\nattributes. Our system also contributes to the surface reconstruction aspect of\nthe pipeline, in which we performed a set of experiments with the parallel\nmarching cubes algorithm per frame for constructing the mesh from the fluid\nparticles in a real-time compute and memory-intensive application, producing a\nwide range of triangle configurations. We also demonstrate that our system is\nversatile enough for reinforced robotic agents instead of boid agents to\ninteract with the fluid environment for underwater navigation and remote\ncontrol engineering purposes.\n",
                "链接": "https://arxiv.org/abs/2311.15088"
            },
            {
                "文章ID": "123500",
                "标题": "Factored Online Planning in Many-Agent POMDPs",
                "作者": " Maris F. L. Galesloot,  Thiago D. Simão,  Sebastian Junges,  Nils Jansen",
                "发布日期": "2023-12-25",
                "摘要": "  In centralized multi-agent systems, often modeled as multi-agent partially\nobservable Markov decision processes (MPOMDPs), the action and observation\nspaces grow exponentially with the number of agents, making the value and\nbelief estimation of single-agent online planning ineffective. Prior work\npartially tackles value estimation by exploiting the inherent structure of\nmulti-agent settings via so-called coordination graphs. Additionally, belief\nestimation has been improved by incorporating the likelihood of observations\ninto the approximation. However, the challenges of value estimation and belief\nestimation have only been tackled individually, which prevents existing methods\nfrom scaling to many agents. Therefore, we address these challenges\nsimultaneously. First, we introduce weighted particle filtering to a\nsample-based online planner for MPOMDPs. Second, we present a scalable\napproximation of the belief. Third, we bring an approach that exploits the\ntypical locality of agent interactions to novel online planning algorithms for\nMPOMDPs operating on a so-called sparse particle filter tree. Our experimental\nevaluation against several state-of-the-art baselines shows that our methods\n(1) are competitive in settings with only a few agents and (2) improve over the\nbaselines in the presence of many agents.\n",
                "链接": "https://arxiv.org/abs/2312.11434"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态优化训练方式的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "54383",
                "标题": "Generalizing Multimodal Variational Methods to Sets",
                "作者": " Jinzhao Zhou,  Yiqun Duan,  Zhihong Chen,  Yu-Cheng Chang,  Chin-Teng Lin",
                "发布日期": "2022-12-21",
                "摘要": "  Making sense of multiple modalities can yield a more comprehensive\ndescription of real-world phenomena. However, learning the co-representation of\ndiverse modalities is still a long-standing endeavor in emerging machine\nlearning applications and research. Previous generative approaches for\nmultimodal input approximate a joint-modality posterior by uni-modality\nposteriors as product-of-experts (PoE) or mixture-of-experts (MoE). We argue\nthat these approximations lead to a defective bound for the optimization\nprocess and loss of semantic connection among modalities. This paper presents a\nnovel variational method on sets called the Set Multimodal VAE (SMVAE) for\nlearning a multimodal latent space while handling the missing modality problem.\nBy modeling the joint-modality posterior distribution directly, the proposed\nSMVAE learns to exchange information between multiple modalities and compensate\nfor the drawbacks caused by factorization. In public datasets of various\ndomains, the experimental results demonstrate that the proposed method is\napplicable to order-agnostic cross-modal generation while achieving outstanding\nperformance compared to the state-of-the-art multimodal methods. The source\ncode for our method is available online\nhttps://anonymous.4open.science/r/SMVAE-9B3C/.\n",
                "链接": "https://arxiv.org/abs/2212.09918"
            },
            {
                "文章ID": "67955",
                "标题": "Clustering US Counties to Find Patterns Related to the COVID-19 Pandemic",
                "作者": " Cora Brown,  Sarah Milstein,  Tianyi Sun,  Cooper Zhao",
                "发布日期": "2023-03-22",
                "摘要": "  When COVID-19 first started spreading and quarantine was implemented, the\nSociety for Industrial and Applied Mathematics (SIAM) Student Chapter at the\nUniversity of Minnesota-Twin Cities began a collaboration with Ecolab to use\nour skills as data scientists and mathematicians to extract useful insights\nfrom relevant data relating to the pandemic. This collaboration consisted of\nmultiple groups working on different projects. In this write-up we focus on\nusing clustering techniques to help us find groups of similar counties in the\nUS and use that to help us understand the pandemic. Our team for this project\nconsisted of University of Minnesota students Cora Brown, Sarah Milstein,\nTianyi Sun, and Cooper Zhao, with help from Ecolab Data Scientist Jimmy\nBroomfield and University of Minnesota student Skye Ke. In the sections below\nwe describe all of the work done for this project. In Section 2, we list the\ndata we gathered, as well as the feature engineering we performed. In Section\n3, we describe the metrics we used for evaluating our models. In Section 4, we\nexplain the methods we used for interpreting the results of our various\nclustering approaches. In Section 5, we describe the different clustering\nmethods we implemented. In Section 6, we present the results of our clustering\ntechniques and provide relevant interpretation. Finally, in Section 7, we\nprovide some concluding remarks comparing the different clustering methods.\n",
                "链接": "https://arxiv.org/abs/2303.11936"
            },
            {
                "文章ID": "2627",
                "标题": "A Method to Predict Semantic Relations on Artificial Intelligence Papers",
                "作者": " Francisco Andrades,  Ricardo Ñanculef",
                "发布日期": "2022-01-26",
                "摘要": "  Predicting the emergence of links in large evolving networks is a difficult\ntask with many practical applications. Recently, the Science4cast competition\nhas illustrated this challenge presenting a network of 64.000 AI concepts and\nasking the participants to predict which topics are going to be researched\ntogether in the future. In this paper, we present a solution to this problem\nbased on a new family of deep learning approaches, namely Graph Neural\nNetworks. The results of the challenge show that our solution is competitive\neven if we had to impose severe restrictions to obtain a computationally\nefficient and parsimonious model: ignoring the intrinsic dynamics of the graph\nand using only a small subset of the nodes surrounding a target link.\nPreliminary experiments presented in this paper suggest the model is learning\ntwo related, but different patterns: the absorption of a node by a sub-graph\nand union of more dense sub-graphs. The model seems to excel at recognizing the\nfirst type of pattern.\n",
                "链接": "https://arxiv.org/abs/2201.10518"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "8082",
                "标题": "Practitioner Motives to Select Hyperparameter Optimization Methods",
                "作者": " Niklas Hasebrook,  Felix Morsbach,  Niclas Kannengießer,  Marc Zöller,  Jörg Franke,  Marius Lindauer,  Frank Hutter,  Ali Sunyaev",
                "发布日期": "2023-06-27",
                "摘要": "  Advanced programmatic hyperparameter optimization (HPO) methods, such as\nBayesian optimization, have high sample efficiency in reproducibly finding\noptimal hyperparameter values of machine learning (ML) models. Yet, ML\npractitioners often apply less sample-efficient HPO methods, such as grid\nsearch, which often results in under-optimized ML models. As a reason for this\nbehavior, we suspect practitioners choose HPO methods based on individual\nmotives, consisting of contextual factors and individual goals. However,\npractitioners' motives still need to be clarified, hindering the evaluation of\nHPO methods for achieving specific goals and the user-centered development of\nHPO tools. To understand practitioners' motives for using specific HPO methods,\nwe used a mixed-methods approach involving 20 semi-structured interviews and a\nsurvey study with 71 ML experts to gather evidence of the external validity of\nthe interview results. By presenting six main goals (e.g., improving model\nunderstanding) and 14 contextual factors affecting practitioners' selection of\nHPO methods (e.g., available computer resources), our study explains why\npractitioners use HPO methods that seem inappropriate at first glance. This\nstudy lays a foundation for designing user-centered and context-adaptive HPO\ntools and, thus, linking social and technical research on HPO.\n",
                "链接": "https://arxiv.org/abs/2203.01717"
            },
            {
                "文章ID": "68954",
                "标题": "An Evaluation of Memory Optimization Methods for Training Neural\n  Networks",
                "作者": " Xiaoxuan Liu,  Siddharth Jha,  Alvin Cheung",
                "发布日期": "2023-06-06",
                "摘要": "  As models continue to grow in size, the development of memory optimization\nmethods (MOMs) has emerged as a solution to address the memory bottleneck\nencountered when training large models. To comprehensively examine the\npractical value of various MOMs, we have conducted a thorough analysis of\nexisting literature from a systems perspective. Our analysis has revealed a\nnotable challenge within the research community: the absence of standardized\nmetrics for effectively evaluating the efficacy of MOMs. The scarcity of\ninformative evaluation metrics hinders the ability of researchers and\npractitioners to compare and benchmark different approaches reliably.\nConsequently, drawing definitive conclusions and making informed decisions\nregarding the selection and application of MOMs becomes a challenging endeavor.\nTo address the challenge, this paper summarizes the scenarios in which MOMs\nprove advantageous for model training. We propose the use of distinct\nevaluation metrics under different scenarios. By employing these metrics, we\nevaluate the prevailing MOMs and find that their benefits are not universal. We\npresent insights derived from experiments and discuss the circumstances in\nwhich they can be advantageous.\n",
                "链接": "https://arxiv.org/abs/2303.14633"
            },
            {
                "文章ID": "79792",
                "标题": "A Simple Method for Unsupervised Bilingual Lexicon Induction for\n  Data-Imbalanced, Closely Related Language Pairs",
                "作者": " Niyati Bafna,  Cristina España-Bonet,  Josef van Genabith,  Benoît Sagot,  Rachel Bawden",
                "发布日期": "2023-05-24",
                "摘要": "  Existing approaches for unsupervised bilingual lexicon induction (BLI) often\ndepend on good quality static or contextual embeddings trained on large\nmonolingual corpora for both languages. In reality, however, unsupervised BLI\nis most likely to be useful for dialects and languages that do not have\nabundant amounts of monolingual data. We introduce a simple and fast method for\nunsupervised BLI for low-resource languages with a related mid-to-high resource\nlanguage, only requiring inference on the higher-resource language monolingual\nBERT. We work with two low-resource languages ($<5M$ monolingual tokens),\nBhojpuri and Magahi, of the severely under-researched Indic dialect continuum,\nshowing that state-of-the-art methods in the literature show near-zero\nperformance in these settings, and that our simpler method gives much better\nresults. We repeat our experiments on Marathi and Nepali, two higher-resource\nIndic languages, to compare approach performances by resource range. We release\nautomatically created bilingual lexicons for the first time for five languages\nof the Indic dialect continuum.\n",
                "链接": "https://arxiv.org/abs/2305.14012"
            },
            {
                "文章ID": "61490",
                "标题": "Relatedly: Scaffolding Literature Reviews with Existing Related Work\n  Sections",
                "作者": " Srishti Palani,  Aakanksha Naik,  Doug Downey,  Amy X. Zhang,  Jonathan Bragg,  Joseph Chee Chang",
                "发布日期": "2023-02-15",
                "摘要": "  Scholars who want to research a scientific topic must take time to read,\nextract meaning, and identify connections across many papers. As scientific\nliterature grows, this becomes increasingly challenging. Meanwhile, authors\nsummarize prior research in papers' related work sections, though this is\nscoped to support a single paper. A formative study found that while reading\nmultiple related work paragraphs helps overview a topic, it is hard to navigate\noverlapping and diverging references and research foci. In this work, we design\na system, Relatedly, that scaffolds exploring and reading multiple related work\nparagraphs on a topic, with features including dynamic re-ranking and\nhighlighting to spotlight unexplored dissimilar information, auto-generated\ndescriptive paragraph headings, and low-lighting of redundant information. From\na within-subjects user study (n=15), we found that scholars generate more\ncoherent, insightful, and comprehensive topic outlines using Relatedly compared\nto a baseline paper list.\n",
                "链接": "https://arxiv.org/abs/2302.06754"
            },
            {
                "文章ID": "114036",
                "标题": "Parameter-Agnostic Optimization under Relaxed Smoothness",
                "作者": " Florian Hübler,  Junchi Yang,  Xiang Li,  Niao He",
                "发布日期": "2023-11-07",
                "摘要": "  Tuning hyperparameters, such as the stepsize, presents a major challenge of\ntraining machine learning models. To address this challenge, numerous adaptive\noptimization algorithms have been developed that achieve near-optimal\ncomplexities, even when stepsizes are independent of problem-specific\nparameters, provided that the loss function is $L$-smooth. However, as the\nassumption is relaxed to the more realistic $(L_0, L_1)$-smoothness, all\nexisting convergence results still necessitate tuning of the stepsize. In this\nstudy, we demonstrate that Normalized Stochastic Gradient Descent with Momentum\n(NSGD-M) can achieve a (nearly) rate-optimal complexity without prior knowledge\nof any problem parameter, though this comes at the cost of introducing an\nexponential term dependent on $L_1$ in the complexity. We further establish\nthat this exponential term is inevitable to such schemes by introducing a\ntheoretical framework of lower bounds tailored explicitly for\nparameter-agnostic algorithms. Interestingly, in deterministic settings, the\nexponential factor can be neutralized by employing Gradient Descent with a\nBacktracking Line Search. To the best of our knowledge, these findings\nrepresent the first parameter-agnostic convergence results under the\ngeneralized smoothness condition. Our empirical experiments further confirm our\ntheoretical insights.\n",
                "链接": "https://arxiv.org/abs/2311.03252"
            }
        ]
    },
    {
        "question": {
            "question": "与大模型安全相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "39802",
                "标题": "On the Impossible Safety of Large AI Models",
                "作者": " El-Mahdi El-Mhamdi,  Sadegh Farhadkhani,  Rachid Guerraoui,  Nirupam Gupta,  Lê-Nguyên Hoang,  Rafael Pinot,  Sébastien Rouault,  John Stephan",
                "发布日期": "2023-05-10",
                "摘要": "  Large AI Models (LAIMs), of which large language models are the most\nprominent recent example, showcase some impressive performance. However they\nhave been empirically found to pose serious security issues. This paper\nsystematizes our knowledge about the fundamental impossibility of building\narbitrarily accurate and secure machine learning models. More precisely, we\nidentify key challenging features of many of today's machine learning settings.\nNamely, high accuracy seems to require memorizing large training datasets,\nwhich are often user-generated and highly heterogeneous, with both sensitive\ninformation and fake users. We then survey statistical lower bounds that, we\nargue, constitute a compelling case against the possibility of designing\nhigh-accuracy LAIMs with strong security guarantees.\n",
                "链接": "https://arxiv.org/abs/2209.15259"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "107503",
                "标题": "An evolutionary model of personality traits related to cooperative\n  behavior using a large language model",
                "作者": " Reiji Suzuki,  Takaya Arita",
                "发布日期": "2023-10-11",
                "摘要": "  This paper aims to shed light on the evolutionary dynamics of diverse and\nsocial populations by introducing the rich expressiveness of generative models\ninto the trait expression of social agent-based evolutionary models.\nSpecifically, we focus on the evolution of personality traits in the context of\na game-theoretic relationship as a situation in which inter-individual\ninterests exert strong selection pressures. We construct an agent model in\nwhich linguistic descriptions of personality traits related to cooperative\nbehavior are used as genes. The deterministic strategies extracted from Large\nLanguage Model (LLM) that make behavioral decisions based on these personality\ntraits are used as behavioral traits. The population is evolved according to\nselection based on average payoff and mutation of genes by asking LLM to\nslightly modify the parent gene toward cooperative or selfish. Through\npreliminary experiments and analyses, we clarify that such a model can indeed\nexhibit the evolution of cooperative behavior based on the diverse and\nhigher-order representation of personality traits. We also observed the\nrepeated intrusion of cooperative and selfish personality traits through\nchanges in the expression of personality traits, and found that the emerging\nwords in the evolved gene well reflected the behavioral tendency of its\npersonality in terms of their semantics.\n",
                "链接": "https://arxiv.org/abs/2310.05976"
            },
            {
                "文章ID": "73408",
                "标题": "Safety Assessment of Chinese Large Language Models",
                "作者": " Hao Sun,  Zhexin Zhang,  Jiawen Deng,  Jiale Cheng,  Minlie Huang",
                "发布日期": "2023-04-21",
                "摘要": "  With the rapid popularity of large language models such as ChatGPT and GPT-4,\na growing amount of attention is paid to their safety concerns. These models\nmay generate insulting and discriminatory content, reflect incorrect social\nvalues, and may be used for malicious purposes such as fraud and dissemination\nof misleading information. Evaluating and enhancing their safety is\nparticularly essential for the wide application of large language models\n(LLMs). To further promote the safe deployment of LLMs, we develop a Chinese\nLLM safety assessment benchmark. Our benchmark explores the comprehensive\nsafety performance of LLMs from two perspectives: 8 kinds of typical safety\nscenarios and 6 types of more challenging instruction attacks. Our benchmark is\nbased on a straightforward process in which it provides the test prompts and\nevaluates the safety of the generated responses from the evaluated model. In\nevaluation, we utilize the LLM's strong evaluation ability and develop it as a\nsafety evaluator by prompting. On top of this benchmark, we conduct safety\nassessments and analyze 15 LLMs including the OpenAI GPT series and other\nwell-known Chinese LLMs, where we observe some interesting findings. For\nexample, we find that instruction attacks are more likely to expose safety\nissues of all LLMs. Moreover, to promote the development and deployment of\nsafe, responsible, and ethical AI, we publicly release SafetyPrompts including\n100k augmented prompts and responses by LLMs.\n",
                "链接": "https://arxiv.org/abs/2304.10436"
            },
            {
                "文章ID": "114317",
                "标题": "Unveiling Safety Vulnerabilities of Large Language Models",
                "作者": " George Kour,  Marcel Zalmanovici,  Naama Zwerdling,  Esther Goldbraich,  Ora Nova Fandina,  Ateret Anaby-Tavor,  Orna Raz,  Eitan Farchi",
                "发布日期": "2023-11-08",
                "摘要": "  As large language models become more prevalent, their possible harmful or\ninappropriate responses are a cause for concern. This paper introduces a unique\ndataset containing adversarial examples in the form of questions, which we call\nAttaQ, designed to provoke such harmful or inappropriate responses. We assess\nthe efficacy of our dataset by analyzing the vulnerabilities of various models\nwhen subjected to it. Additionally, we introduce a novel automatic approach for\nidentifying and naming vulnerable semantic regions - input semantic areas for\nwhich the model is likely to produce harmful outputs. This is achieved through\nthe application of specialized clustering techniques that consider both the\nsemantic similarity of the input attacks and the harmfulness of the model's\nresponses. Automatically identifying vulnerable semantic regions enhances the\nevaluation of model weaknesses, facilitating targeted improvements to its\nsafety mechanisms and overall reliability.\n",
                "链接": "https://arxiv.org/abs/2311.04124"
            },
            {
                "文章ID": "125173",
                "标题": "A Large Language Model-based Computational Approach to Improve\n  Identity-Related Write-Ups",
                "作者": " Alex Doboli",
                "发布日期": "2023-12-29",
                "摘要": "  Creating written products is essential to modern life, including writings\nabout one's identity and personal experiences. However, writing is often a\ndifficult activity that requires extensive effort to frame the central ideas,\nthe pursued approach to communicate the central ideas, e.g., using analogies,\nmetaphors, or other possible means, the needed presentation structure, and the\nactual verbal expression. Large Language Models, a recently emerged approach in\nMachine Learning, can offer a significant help in reducing the effort and\nimproving the quality of written products. This paper proposes a new\ncomputational approach to explore prompts that given as inputs to a Large\nLanguage Models can generate cues to improve the considered written products.\nTwo case studies on improving write-ups, one based on an analogy and one on a\nmetaphor, are also presented in the paper.\n",
                "链接": "https://arxiv.org/abs/2312.16659"
            },
            {
                "文章ID": "81272",
                "标题": "Large Language Models as Tool Makers",
                "作者": " Tianle Cai,  Xuezhi Wang,  Tengyu Ma,  Xinyun Chen,  Denny Zhou",
                "发布日期": "2023-05-29",
                "摘要": "  Recent research shows the potential of enhancing the problem-solving ability\nof large language models (LLMs) through the use of external tools. However,\nprior work along this line depends on the availability of existing tools. In\nthis work, we take an initial step towards removing this dependency by\nproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),\nwhere LLMs create their own reusable tools for problem-solving. Our approach\nconsists of two key phases: 1) tool making: an LLM acts as the tool maker that\ncrafts tools for given tasks, where a tool is implemented as a Python utility\nfunction. 2) tool using: an LLM acts as the tool user, which applies the tool\nbuilt by the tool maker for problem-solving. The tool user can be either the\nsame or a different LLM from the tool maker. Tool-making enables an LLM to\ncontinually generate tools that can be applied to different requests so that\nfuture requests can call the corresponding APIs when beneficial for solving the\ntasks. Furthermore, the division of labor among LLMs for tool-making and\ntool-using phases introduces the opportunity to achieve cost effectiveness\nwithout degrading the quality of generated tools and problem solutions. For\nexample, recognizing that tool-making demands more sophisticated capabilities\nthan tool-using, we can apply a powerful yet resource-intensive model as the\ntool maker, and a lightweight while cost-effective model as the tool user. We\nvalidate the effectiveness of our approach across a variety of complex\nreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and\nGPT-3.5 as the tool user, LATM can achieve performance that is on par with\nusing GPT-4 for both tool making and tool using, while the inference cost is\nsignificantly reduced.\n",
                "链接": "https://arxiv.org/abs/2305.17126"
            },
            {
                "文章ID": "117473",
                "标题": "Applying Large Language Models to Power Systems: Potential Security\n  Threats",
                "作者": " Jiaqi Ruan,  Gaoqi Liang,  Huan Zhao,  Guolong Liu,  Jing Qiu,  Junhua Zhao,  Zhao Xu,  Fushuan Wen,  Zhao Yang Dong",
                "发布日期": "2023-11-23",
                "摘要": "  Applying large language models (LLMs) to power systems presents a promising\navenue for enhancing decision-making and operational efficiency. However, this\naction may also incur potential security threats, which have not been fully\nrecognized so far. To this end, this letter analyzes potential threats incurred\nby applying LLMs to power systems, emphasizing the need for urgent research and\ndevelopment of countermeasures.\n",
                "链接": "https://arxiv.org/abs/2311.13361"
            },
            {
                "文章ID": "91785",
                "标题": "CValues: Measuring the Values of Chinese Large Language Models from\n  Safety to Responsibility",
                "作者": " Guohai Xu,  Jiayi Liu,  Ming Yan,  Haotian Xu,  Jinghui Si,  Zhuoran Zhou,  Peng Yi,  Xing Gao,  Jitao Sang,  Rong Zhang,  Ji Zhang,  Chao Peng,  Fei Huang,  Jingren Zhou",
                "发布日期": "2023-07-20",
                "摘要": "  With the rapid evolution of large language models (LLMs), there is a growing\nconcern that they may pose risks or have negative social impacts. Therefore,\nevaluation of human values alignment is becoming increasingly important.\nPrevious work mainly focuses on assessing the performance of LLMs on certain\nknowledge and reasoning abilities, while neglecting the alignment to human\nvalues, especially in a Chinese context. In this paper, we present CValues, the\nfirst Chinese human values evaluation benchmark to measure the alignment\nability of LLMs in terms of both safety and responsibility criteria. As a\nresult, we have manually collected adversarial safety prompts across 10\nscenarios and induced responsibility prompts from 8 domains by professional\nexperts. To provide a comprehensive values evaluation of Chinese LLMs, we not\nonly conduct human evaluation for reliable comparison, but also construct\nmulti-choice prompts for automatic evaluation. Our findings suggest that while\nmost Chinese LLMs perform well in terms of safety, there is considerable room\nfor improvement in terms of responsibility. Moreover, both the automatic and\nhuman evaluation are important for assessing the human values alignment in\ndifferent aspects. The benchmark and code is available on ModelScope and\nGithub.\n",
                "链接": "https://arxiv.org/abs/2307.09705"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            }
        ]
    },
    {
        "question": {
            "question": "查找大模型推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "116170",
                "标题": "Large Language Model Inference with Lexical Shortlisting",
                "作者": " Nikolay Bogoychev,  Pinzhen Chen,  Barry Haddow,  Alexandra Birch",
                "发布日期": "2023-11-17",
                "摘要": "  Large language model (LLM) inference is computation and memory intensive, so\nwe adapt lexical shortlisting to it hoping to improve both. While lexical\nshortlisting is well-explored in tasks like machine translation, it requires\nmodifications before being suitable for LLMs as the intended applications vary\nsignificantly. Our work studies two heuristics to shortlist sub-vocabulary at\nLLM inference time: Unicode-based script filtering and corpus-based selection.\nWe explore different LLM families and sizes, and we find that lexical\nshortlisting can reduce the memory usage of some models by nearly 50\\% and has\nan upper bound of 25\\% improvement in generation speed. In this pilot study, we\nalso identify the drawbacks of such vocabulary selection methods and propose\navenues for future research.\n",
                "链接": "https://arxiv.org/abs/2311.09709"
            },
            {
                "文章ID": "83366",
                "标题": "On Optimal Caching and Model Multiplexing for Large Model Inference",
                "作者": " Banghua Zhu,  Ying Sheng,  Lianmin Zheng,  Clark Barrett,  Michael I. Jordan,  Jiantao Jiao",
                "发布日期": "2023-08-30",
                "摘要": "  Large Language Models (LLMs) and other large foundation models have achieved\nnoteworthy success, but their size exacerbates existing resource consumption\nand latency challenges. In particular, the large-scale deployment of these\nmodels is hindered by the significant resource requirements during inference.\nIn this paper, we study two approaches for mitigating these challenges:\nemploying a cache to store previous queries and learning a model multiplexer to\nchoose from an ensemble of models for query processing.\n  Theoretically, we provide an optimal algorithm for jointly optimizing both\napproaches to reduce the inference cost in both offline and online tabular\nsettings. By combining a caching algorithm, namely Greedy Dual Size with\nFrequency (GDSF) or Least Expected Cost (LEC), with a model multiplexer, we\nachieve optimal rates in both offline and online settings. Empirically,\nsimulations show that the combination of our caching and model multiplexing\nalgorithms greatly improves over the baselines, with up to $50\\times$\nimprovement over the baseline when the ratio between the maximum cost and\nminimum cost is $100$. Experiments on real datasets show a $4.3\\times$\nimprovement in FLOPs over the baseline when the ratio for FLOPs is $10$, and a\n$1.8\\times$ improvement in latency when the ratio for average latency is\n$1.85$.\n",
                "链接": "https://arxiv.org/abs/2306.02003"
            },
            {
                "文章ID": "55730",
                "标题": "Rethinking with Retrieval: Faithful Large Language Model Inference",
                "作者": " Hangfeng He,  Hongming Zhang,  Dan Roth",
                "发布日期": "2023-01-03",
                "摘要": "  Despite the success of large language models (LLMs) in various natural\nlanguage processing (NLP) tasks, the stored knowledge in these models may\ninevitably be incomplete, out-of-date, or incorrect. This motivates the need to\nutilize external knowledge to assist LLMs. Unfortunately, current methods for\nincorporating external knowledge often require additional training or\nfine-tuning, which can be costly and may not be feasible for LLMs. To address\nthis issue, we propose a novel post-processing approach, rethinking with\nretrieval (RR), which retrieves relevant external knowledge based on the\ndecomposed reasoning steps obtained from the chain-of-thought (CoT) prompting.\nThis lightweight approach does not require additional training or fine-tuning\nand is not limited by the input length of LLMs. We evaluate the effectiveness\nof RR through extensive experiments with GPT-3 on three complex reasoning\ntasks: commonsense reasoning, temporal reasoning, and tabular reasoning. Our\nresults show that RR can produce more faithful explanations and improve the\nperformance of LLMs.\n",
                "链接": "https://arxiv.org/abs/2301.00303"
            },
            {
                "文章ID": "113368",
                "标题": "FlashDecoding++: Faster Large Language Model Inference on GPUs",
                "作者": " Ke Hong,  Guohao Dai,  Jiaming Xu,  Qiuli Mao,  Xiuhong Li,  Jun Liu,  Kangdi Chen,  Yuhan Dong,  Yu Wang",
                "发布日期": "2023-11-13",
                "摘要": "  As the Large Language Model (LLM) becomes increasingly important in various\ndomains. However, the following challenges still remain unsolved in\naccelerating LLM inference: (1) Synchronized partial softmax update. The\nsoftmax operation requires a synchronized update operation among each partial\nsoftmax result, leading to ~20% overheads for the attention computation in\nLLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices\nperforming GEMM in LLM inference is flat, leading to under-utilized computation\nand >50% performance loss after padding zeros in previous designs. (3)\nPerformance loss due to static dataflow. Kernel performance in LLM depends on\nvaried input data features, hardware configurations, etc. A single and static\ndataflow may lead to a 50.25% performance loss for GEMMs of different shapes in\nLLM inference.\n  We present FlashDecoding++, a fast LLM inference engine supporting mainstream\nLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++\ncreatively proposes: (1) Asynchronized softmax with unified max value.\nFlashDecoding++ introduces a unified max value technique for different partial\nsoftmax computations to avoid synchronization. (2) Flat GEMM optimization with\ndouble buffering. FlashDecoding++ points out that flat GEMMs with different\nshapes face varied bottlenecks. Then, techniques like double buffering are\nintroduced. (3) Heuristic dataflow with hardware resource adaptation.\nFlashDecoding++ heuristically optimizes dataflow using different hardware\nresource considering input dynamics. Due to the versatility of optimizations in\nFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on\nboth NVIDIA and AMD GPUs compared to Hugging Face implementations.\nFlashDecoding++ also achieves an average speedup of 1.37x compared to\nstate-of-the-art LLM inference engines on mainstream LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.01282"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "57741",
                "标题": "Batch Prompting: Efficient Inference with Large Language Model APIs",
                "作者": " Zhoujun Cheng,  Jungo Kasai,  Tao Yu",
                "发布日期": "2023-10-25",
                "摘要": "  Performing inference on large volumes of samples with large language models\n(LLMs) can be computationally and financially costly in industry and real-world\nuse. We propose batch prompting, a simple yet effective prompting approach that\nenables the LLM to run inference in batches, instead of one sample at a time.\nOur method reduces both token and time costs while retaining downstream\nperformance. We theoretically demonstrate that under a few-shot in-context\nlearning setting, the inference costs decrease almost inverse linearly with the\nnumber of samples in each batch. We extensively validate the effectiveness of\nbatch prompting on ten datasets across commonsense QA, arithmetic reasoning,\nand NLI/NLU: batch prompting significantly~(up to 5x with six samples in batch)\nreduces the LLM (Codex) inference token and time costs while achieving better\nor comparable performance. For state-of-the-art Chat-based LLMs, e.g., GPT-3.5\nand GPT-4, we show the benefits of batch prompting also hold. Further analysis\nshows that the number of samples in each batch and the complexity of tasks\naffect its performance. Moreover, batch prompting can be applied across\ndifferent reasoning methods using LLMs. Our code can be found at the site\nhttps://github.com/xlang-ai/batch-prompting.\n",
                "链接": "https://arxiv.org/abs/2301.08721"
            },
            {
                "文章ID": "120482",
                "标题": "A Hardware Evaluation Framework for Large Language Model Inference",
                "作者": " Hengrui Zhang,  August Ning,  Rohan Prabhakar,  David Wentzlaff",
                "发布日期": "2023-12-07",
                "摘要": "  The past year has witnessed the increasing popularity of Large Language\nModels (LLMs). Their unprecedented scale and associated high hardware cost have\nimpeded their broader adoption, calling for efficient hardware designs. With\nthe large hardware needed to simply run LLM inference, evaluating different\nhardware designs becomes a new bottleneck.\n  This work introduces LLMCompass, a hardware evaluation framework for LLM\ninference workloads. LLMCompass is fast, accurate, versatile, and able to\ndescribe and evaluate different hardware designs. LLMCompass includes a mapper\nto automatically find performance-optimal mapping and scheduling. It also\nincorporates an area-based cost model to help architects reason about their\ndesign choices. Compared to real-world hardware, LLMCompass' estimated latency\nachieves an average 10.4% error rate across various operators with various\ninput sizes and an average 4.1% error rate for LLM inference. With LLMCompass,\nsimulating a 4-NVIDIA A100 GPU node running GPT-3 175B inference can be done\nwithin 16 minutes on commodity hardware, including 26,400 rounds of the\nmapper's parameter search.\n  With the aid of LLMCompass, this work draws architectural implications and\nexplores new cost-effective hardware designs. By reducing the compute\ncapability or replacing High Bandwidth Memory (HBM) with traditional DRAM,\nthese new designs can achieve as much as 3.41x improvement in performance/cost\ncompared to an NVIDIA A100, making them promising choices for democratizing\nLLMs.\n  LLMCompass is planned to be fully open-source.\n",
                "链接": "https://arxiv.org/abs/2312.03134"
            },
            {
                "文章ID": "34213",
                "标题": "Twin Papers: A Simple Framework of Causal Inference for Citations via\n  Coupling",
                "作者": " Ryoma Sato,  Makoto Yamada,  Hisashi Kashima",
                "发布日期": "2022-08-23",
                "摘要": "  The research process includes many decisions, e.g., how to entitle and where\nto publish the paper. In this paper, we introduce a general framework for\ninvestigating the effects of such decisions. The main difficulty in\ninvestigating the effects is that we need to know counterfactual results, which\nare not available in reality. The key insight of our framework is inspired by\nthe existing counterfactual analysis using twins, where the researchers regard\ntwins as counterfactual units. The proposed framework regards a pair of papers\nthat cite each other as twins. Such papers tend to be parallel works, on\nsimilar topics, and in similar communities. We investigate twin papers that\nadopted different decisions, observe the progress of the research impact\nbrought by these studies, and estimate the effect of decisions by the\ndifference in the impacts of these studies. We release our code and data, which\nwe believe are highly beneficial owing to the scarcity of the dataset on\ncounterfactual studies.\n",
                "链接": "https://arxiv.org/abs/2208.09862"
            },
            {
                "文章ID": "103034",
                "标题": "Interactive Distillation of Large Single-Topic Corpora of Scientific\n  Papers",
                "作者": " Nicholas Solovyev,  Ryan Barron,  Manish Bhattarai,  Maksim E. Eren,  Kim O. Rasmussen,  Boian S. Alexandrov",
                "发布日期": "2023-09-20",
                "摘要": "  Highly specific datasets of scientific literature are important for both\nresearch and education. However, it is difficult to build such datasets at\nscale. A common approach is to build these datasets reductively by applying\ntopic modeling on an established corpus and selecting specific topics. A more\nrobust but time-consuming approach is to build the dataset constructively in\nwhich a subject matter expert (SME) handpicks documents. This method does not\nscale and is prone to error as the dataset grows. Here we showcase a new tool,\nbased on machine learning, for constructively generating targeted datasets of\nscientific literature. Given a small initial \"core\" corpus of papers, we build\na citation network of documents. At each step of the citation network, we\ngenerate text embeddings and visualize the embeddings through dimensionality\nreduction. Papers are kept in the dataset if they are \"similar\" to the core or\nare otherwise pruned through human-in-the-loop selection. Additional insight\ninto the papers is gained through sub-topic modeling using SeNMFk. We\ndemonstrate our new tool for literature review by applying it to two different\nfields in machine learning.\n",
                "链接": "https://arxiv.org/abs/2309.10772"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月自然语言处理相关的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "26137",
                "标题": "Urdu News Article Recommendation Model using Natural Language Processing\n  Techniques",
                "作者": " Syed Zain Abbas,  Dr. Arif ur Rahman,  Abdul Basit Mughal,  Syed Mujtaba Haider",
                "发布日期": "2022-06-24",
                "摘要": "  There are several online newspapers in urdu but for the users it is difficult\nto find the content they are looking for because these most of them contain\nirrelevant data and most users did not get what they want to retrieve. Our\nproposed framework will help to predict Urdu news in the interests of users and\nreduce the users searching time for news. For this purpose, NLP techniques are\nused for pre-processing, and then TF-IDF with cosine similarity is used for\ngaining the highest similarity and recommended news on user preferences.\nMoreover, the BERT language model is also used for similarity, and by using the\nBERT model similarity increases as compared to TF-IDF so the approach works\nbetter with the BERT language model and recommends news to the user on their\ninterest. The news is recommended when the similarity of the articles is above\n60 percent.\n",
                "链接": "https://arxiv.org/abs/2206.11862"
            },
            {
                "文章ID": "44791",
                "标题": "Classification of Misinformation in New Articles using Natural Language\n  Processing and a Recurrent Neural Network",
                "作者": " Brendan Cunha,  Lydia Manikonda",
                "发布日期": "2022-10-26",
                "摘要": "  This paper seeks to address the classification of misinformation in news\narticles using a Long Short Term Memory Recurrent Neural Network. Articles were\ntaken from 2018; a year that was filled with reporters writing about President\nDonald Trump, Special Counsel Robert Mueller, the Fifa World Cup, and Russia.\nThe model presented successfully classifies these articles with an accuracy\nscore of 0.779944. We consider this to be successful because the model was\ntrained on articles that included languages other than English as well as\nincomplete, or fragmented, articles.\n",
                "链接": "https://arxiv.org/abs/2210.13534"
            },
            {
                "文章ID": "197",
                "标题": "Robust Natural Language Processing: Recent Advances, Challenges, and\n  Future Directions",
                "作者": " Marwan Omar,  Soohyeon Choi,  DaeHun Nyang,  David Mohaisen",
                "发布日期": "2022-10-24",
                "摘要": "  Recent natural language processing (NLP) techniques have accomplished high\nperformance on benchmark datasets, primarily due to the significant improvement\nin the performance of deep learning. The advances in the research community\nhave led to great enhancements in state-of-the-art production systems for NLP\ntasks, such as virtual assistants, speech recognition, and sentiment analysis.\nHowever, such NLP systems still often fail when tested with adversarial\nattacks. The initial lack of robustness exposed troubling gaps in current\nmodels' language understanding capabilities, creating problems when NLP systems\nare deployed in real life. In this paper, we present a structured overview of\nNLP robustness research by summarizing the literature in a systemic way across\nvarious dimensions. We then take a deep-dive into the various dimensions of\nrobustness, across techniques, metrics, embeddings, and benchmarks. Finally, we\nargue that robustness should be multi-dimensional, provide insights into\ncurrent research, identify gaps in the literature to suggest directions worth\npursuing to address these gaps.\n",
                "链接": "https://arxiv.org/abs/2201.00768"
            },
            {
                "文章ID": "65525",
                "标题": "Comprehensive Event Representations using Event Knowledge Graphs and\n  Natural Language Processing",
                "作者": " Tin Kuculo",
                "发布日期": "2023-03-09",
                "摘要": "  Recent work has utilised knowledge-aware approaches to natural language\nunderstanding, question answering, recommendation systems, and other tasks.\nThese approaches rely on well-constructed and large-scale knowledge graphs that\ncan be useful for many downstream applications and empower knowledge-aware\nmodels with commonsense reasoning. Such knowledge graphs are constructed\nthrough knowledge acquisition tasks such as relation extraction and knowledge\ngraph completion. This work seeks to utilise and build on the growing body of\nwork that uses findings from the field of natural language processing (NLP) to\nextract knowledge from text and build knowledge graphs. The focus of this\nresearch project is on how we can use transformer-based approaches to extract\nand contextualise event information, matching it to existing ontologies, to\nbuild a comprehensive knowledge of graph-based event representations.\nSpecifically, sub-event extraction is used as a way of creating sub-event-aware\nevent representations. These event representations are then further enriched\nthrough fine-grained location extraction and contextualised through the\nalignment of historically relevant quotes.\n",
                "链接": "https://arxiv.org/abs/2303.04794"
            },
            {
                "文章ID": "79436",
                "标题": "Interactive Natural Language Processing",
                "作者": " Zekun Wang,  Ge Zhang,  Kexin Yang,  Ning Shi,  Wangchunshu Zhou,  Shaochun Hao,  Guangzheng Xiong,  Yizhi Li,  Mong Yuan Sim,  Xiuying Chen,  Qingqing Zhu,  Zhenzhu Yang,  Adam Nik,  Qi Liu,  Chenghua Lin,  Shi Wang,  Ruibo Liu,  Wenhu Chen,  Ke Xu,  Dayiheng Liu,  Yike Guo,  Jie Fu",
                "发布日期": "2023-05-23",
                "摘要": "  Interactive Natural Language Processing (iNLP) has emerged as a novel\nparadigm within the field of NLP, aimed at addressing limitations in existing\nframeworks while aligning with the ultimate goals of artificial intelligence.\nThis paradigm considers language models as agents capable of observing, acting,\nand receiving feedback iteratively from external entities. Specifically,\nlanguage models in this context can: (1) interact with humans for better\nunderstanding and addressing user needs, personalizing responses, aligning with\nhuman values, and improving the overall user experience; (2) interact with\nknowledge bases for enriching language representations with factual knowledge,\nenhancing the contextual relevance of responses, and dynamically leveraging\nexternal information to generate more accurate and informed responses; (3)\ninteract with models and tools for effectively decomposing and addressing\ncomplex tasks, leveraging specialized expertise for specific subtasks, and\nfostering the simulation of social behaviors; and (4) interact with\nenvironments for learning grounded representations of language, and effectively\ntackling embodied tasks such as reasoning, planning, and decision-making in\nresponse to environmental observations. This paper offers a comprehensive\nsurvey of iNLP, starting by proposing a unified definition and framework of the\nconcept. We then provide a systematic classification of iNLP, dissecting its\nvarious components, including interactive objects, interaction interfaces, and\ninteraction methods. We proceed to delve into the evaluation methodologies used\nin the field, explore its diverse applications, scrutinize its ethical and\nsafety issues, and discuss prospective research directions. This survey serves\nas an entry point for researchers who are interested in this rapidly evolving\narea and offers a broad view of the current landscape and future trajectory of\niNLP.\n",
                "链接": "https://arxiv.org/abs/2305.13246"
            },
            {
                "文章ID": "68432",
                "标题": "SwissBERT: The Multilingual Language Model for Switzerland",
                "作者": " Jannis Vamvas,  Johannes Graën,  Rico Sennrich",
                "发布日期": "2023-06-13",
                "摘要": "  We present SwissBERT, a masked language model created specifically for\nprocessing Switzerland-related text. SwissBERT is a pre-trained model that we\nadapted to news articles written in the national languages of Switzerland --\nGerman, French, Italian, and Romansh. We evaluate SwissBERT on natural language\nunderstanding tasks related to Switzerland and find that it tends to outperform\nprevious models on these tasks, especially when processing contemporary news\nand/or Romansh Grischun. Since SwissBERT uses language adapters, it may be\nextended to Swiss German dialects in future work. The model and our open-source\ncode are publicly released at https://github.com/ZurichNLP/swissbert.\n",
                "链接": "https://arxiv.org/abs/2303.13310"
            },
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "28218",
                "标题": "Bayesian Modeling of Language-Evoked Event-Related Potentials",
                "作者": " Davide Turco,  Conor Houghton",
                "发布日期": "2022-08-17",
                "摘要": "  Bayesian hierarchical models are well-suited to analyzing the often noisy\ndata from electroencephalography experiments in cognitive neuroscience: these\nmodels provide an intuitive framework to account for structures and\ncorrelations in the data, and they allow a straightforward handling of\nuncertainty. In a typical neurolinguistic experiment, event-related potentials\nshow only very small effect sizes and frequentist approaches to data analysis\nfail to establish the significance of some of these effects. Here, we present a\nBayesian approach to analyzing event-related potentials using as an example\ndata from an experiment which relates word surprisal and neural response. Our\nmodel is able to estimate the effect of word surprisal on most components of\nthe event-related potential and provides a richer description of the data. The\nBayesian framework also allows easier comparison between estimates based on\nsurprisal values calculated using different language models.\n",
                "链接": "https://arxiv.org/abs/2207.03392"
            },
            {
                "文章ID": "60462",
                "标题": "Natural Language Processing for Policymaking",
                "作者": " Zhijing Jin,  Rada Mihalcea",
                "发布日期": "2023-02-08",
                "摘要": "  Language is the medium for many political activities, from campaigns to news\nreports. Natural language processing (NLP) uses computational tools to parse\ntext into key information that is needed for policymaking. In this chapter, we\nintroduce common methods of NLP, including text classification, topic modeling,\nevent extraction, and text scaling. We then overview how these methods can be\nused for policymaking through four major applications including data collection\nfor evidence-based policymaking, interpretation of political decisions, policy\ncommunication, and investigation of policy effects. Finally, we highlight some\npotential limitations and ethical concerns when using NLP for policymaking.\n  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational\nSocial Science for Policy (2023). Open Access on Springer:\nhttps://doi.org/10.1007/978-3-031-16624-2\n",
                "链接": "https://arxiv.org/abs/2302.03490"
            },
            {
                "文章ID": "85699",
                "标题": "Operationalising Representation in Natural Language Processing",
                "作者": " Jacqueline Harding",
                "发布日期": "2023-11-21",
                "摘要": "  Despite its centrality in the philosophy of cognitive science, there has been\nlittle prior philosophical work engaging with the notion of representation in\ncontemporary NLP practice. This paper attempts to fill that lacuna: drawing on\nideas from cognitive science, I introduce a framework for evaluating the\nrepresentational claims made about components of neural NLP models, proposing\nthree criteria with which to evaluate whether a component of a model represents\na property and operationalising these criteria using probing classifiers, a\npopular analysis technique in NLP (and deep learning more broadly).\n  The project of operationalising a philosophically-informed notion of\nrepresentation should be of interest to both philosophers of science and NLP\npractitioners. It affords philosophers a novel testing-ground for claims about\nthe nature of representation, and helps NLPers organise the large literature on\nprobing experiments, suggesting novel avenues for empirical research.\n",
                "链接": "https://arxiv.org/abs/2306.08193"
            }
        ]
    },
    {
        "question": {
            "question": "查找多语言情感分析的最新论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "2025",
                "标题": "NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual\n  Sentiment Analysis",
                "作者": " Shamsuddeen Hassan Muhammad,  David Ifeoluwa Adelani,  Sebastian Ruder,  Ibrahim Said Ahmad,  Idris Abdulmumin,  Bello Shehu Bello,  Monojit Choudhury,  Chris Chinenye Emezue,  Saheed Salahudeen Abdullahi,  Anuoluwapo Aremu,  Alipio Jeorge,  Pavel Brazdil",
                "发布日期": "2022-06-22",
                "摘要": "  Sentiment analysis is one of the most widely studied applications in NLP, but\nmost work focuses on languages with large amounts of data. We introduce the\nfirst large-scale human-annotated Twitter sentiment dataset for the four most\nwidely spoken languages in Nigeria (Hausa, Igbo, Nigerian-Pidgin, and\nYor\\`ub\\'a ) consisting of around 30,000 annotated tweets per language (and\n14,000 for Nigerian-Pidgin), including a significant fraction of code-mixed\ntweets. We propose text collection, filtering, processing and labeling methods\nthat enable us to create datasets for these low-resource languages. We evaluate\na rangeof pre-trained models and transfer strategies on the dataset. We find\nthat language-specific models and language-adaptivefine-tuning generally\nperform best. We release the datasets, trained models, sentiment lexicons, and\ncode to incentivizeresearch on sentiment analysis in under-represented\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2201.08277"
            },
            {
                "文章ID": "122117",
                "标题": "Multimodal Sentiment Analysis: Perceived vs Induced Sentiments",
                "作者": " Aditi Aggarwal,  Deepika Varshney,  Saurabh Patel",
                "发布日期": "2023-12-14",
                "摘要": "  Social media has created a global network where people can easily access and\nexchange vast information. This information gives rise to a variety of\nopinions, reflecting both positive and negative viewpoints. GIFs stand out as a\nmultimedia format offering a visually engaging way for users to communicate. In\nthis research, we propose a multimodal framework that integrates visual and\ntextual features to predict the GIF sentiment. It also incorporates attributes\nincluding face emotion detection and OCR generated captions to capture the\nsemantic aspects of the GIF. The developed classifier achieves an accuracy of\n82.7% on Twitter GIFs, which is an improvement over state-of-the-art models.\nMoreover, we have based our research on the ReactionGIF dataset, analysing the\nvariance in sentiment perceived by the author and sentiment induced in the\nreader\n",
                "链接": "https://arxiv.org/abs/2312.07627"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "23956",
                "标题": "Sentiment analysis on electricity twitter posts",
                "作者": " Pardeep Kaur,  Maryam Edalati",
                "发布日期": "2022-06-13",
                "摘要": "  In today's world, everyone is expressive in some way, and the focus of this\nproject is on people's opinions about rising electricity prices in United\nKingdom and India using data from Twitter, a micro-blogging platform on which\npeople post messages, known as tweets. Because many people's incomes are not\ngood and they have to pay so many taxes and bills, maintaining a home has\nbecome a disputed issue these days. Despite the fact that Government offered\nsubsidy schemes to compensate people electricity bills but it is not welcomed\nby people. In this project, the aim is to perform sentiment analysis on\npeople's expressions and opinions expressed on Twitter. In order to grasp the\nelectricity prices opinion, it is necessary to carry out sentiment analysis for\nthe government and consumers in energy market. Furthermore, text present on\nthese medias are unstructured in nature, so to process them we firstly need to\npre-process the data. There are so many feature extraction techniques such as\nBag of Words, TF-IDF (Term Frequency-Inverse Document Frequency), word\nembedding, NLP based features like word count. In this project, we analysed the\nimpact of feature TF-IDF word level on electricity bills dataset of sentiment\nanalysis. We found that by using TF-IDF word level performance of sentiment\nanalysis is 3-4 higher than using N-gram features. Analysis is done using four\nclassification algorithms including Naive Bayes, Decision Tree, Random Forest,\nand Logistic Regression and considering F-Score, Accuracy, Precision, and\nRecall performance parameters.\n",
                "链接": "https://arxiv.org/abs/2206.05042"
            },
            {
                "文章ID": "3562",
                "标题": "Negativity Spreads Faster: A Large-Scale Multilingual Twitter Analysis\n  on the Role of Sentiment in Political Communication",
                "作者": " Dimosthenis Antypas,  Alun Preece,  Jose Camacho-Collados",
                "发布日期": "2023-04-05",
                "摘要": "  Social media has become extremely influential when it comes to policy making\nin modern societies, especially in the western world, where platforms such as\nTwitter allow users to follow politicians, thus making citizens more involved\nin political discussion. In the same vein, politicians use Twitter to express\ntheir opinions, debate among others on current topics and promote their\npolitical agendas aiming to influence voter behaviour. In this paper, we\nattempt to analyse tweets of politicians from three European countries and\nexplore the virality of their tweets. Previous studies have shown that tweets\nconveying negative sentiment are likely to be retweeted more frequently. By\nutilising state-of-the-art pre-trained language models, we performed sentiment\nanalysis on hundreds of thousands of tweets collected from members of\nparliament in Greece, Spain and the United Kingdom, including devolved\nadministrations. We achieved this by systematically exploring and analysing the\ndifferences between influential and less popular tweets. Our analysis indicates\nthat politicians' negatively charged tweets spread more widely, especially in\nmore recent times, and highlights interesting differences between political\nparties as well as between politicians and the general population.\n",
                "链接": "https://arxiv.org/abs/2202.00396"
            },
            {
                "文章ID": "14369",
                "标题": "Assessment of Massively Multilingual Sentiment Classifiers",
                "作者": " Krzysztof Rajda,  Łukasz Augustyniak,  Piotr Gramacki,  Marcin Gruza,  Szymon Woźniak,  Tomasz Kajdanowicz",
                "发布日期": "2022-04-12",
                "摘要": "  Models are increasing in size and complexity in the hunt for SOTA. But what\nif those 2\\% increase in performance does not make a difference in a production\nuse case? Maybe benefits from a smaller, faster model outweigh those slight\nperformance gains. Also, equally good performance across languages in\nmultilingual tasks is more important than SOTA results on a single one. We\npresent the biggest, unified, multilingual collection of sentiment analysis\ndatasets. We use these to assess 11 models and 80 high-quality sentiment\ndatasets (out of 342 raw datasets collected) in 27 languages and included\nresults on the internally annotated datasets. We deeply evaluate multiple\nsetups, including fine-tuning transformer-based models for measuring\nperformance. We compare results in numerous dimensions addressing the imbalance\nin both languages coverage and dataset sizes. Finally, we present some best\npractices for working with such a massive collection of datasets and models\nfrom a multilingual perspective.\n",
                "链接": "https://arxiv.org/abs/2204.04937"
            },
            {
                "文章ID": "22243",
                "标题": "Uzbek Sentiment Analysis based on local Restaurant Reviews",
                "作者": " Sanatbek Matlatipov,  Hulkar Rahimboeva,  Jaloliddin Rajabov,  Elmurod Kuriyozov",
                "发布日期": "2022-06-01",
                "摘要": "  Extracting useful information for sentiment analysis and classification\nproblems from a big amount of user-generated feedback, such as restaurant\nreviews, is a crucial task of natural language processing, which is not only\nfor customer satisfaction where it can give personalized services, but can also\ninfluence the further development of a company. In this paper, we present a\nwork done on collecting restaurant reviews data as a sentiment analysis dataset\nfor the Uzbek language, a member of the Turkic family which is heavily affected\nby the low-resource constraint, and provide some further analysis of the novel\ndataset by evaluation using different techniques, from logistic regression\nbased models, to support vector machines, and even deep learning models, such\nas recurrent neural networks, as well as convolutional neural networks. The\npaper includes detailed information on how the data was collected, how it was\npre-processed for better quality optimization, as well as experimental setups\nfor the evaluation process. The overall evaluation results indicate that by\nperforming pre-processing steps, such as stemming for agglutinative languages,\nthe system yields better results, eventually achieving 91% accuracy result in\nthe best performing model\n",
                "链接": "https://arxiv.org/abs/2205.15930"
            },
            {
                "文章ID": "40184",
                "标题": "Sentiment Analysis of ESG disclosures on Stock Market",
                "作者": " Sudeep R. Bapat,  Saumya Kothari,  Rushil Bansal",
                "发布日期": "2022-10-04",
                "摘要": "  In this paper, we look at the impact of Environment, Social and Governance\nrelated news articles and social media data on the stock market performance. We\npick four stocks of companies which are widely known in their domain to\nunderstand the complete effect of ESG as the newly opted investment style\nremains restricted to only the stocks with widespread information. We summarise\nlive data of both twitter tweets and newspaper articles and create a sentiment\nindex using a dictionary technique based on online information for the month of\nJuly, 2022. We look at the stock price data for all the four companies and\ncalculate the percentage change in each of them. We also compare the overall\nsentiment of the company to its percentage change over a specific historical\nperiod.\n",
                "链接": "https://arxiv.org/abs/2210.00731"
            },
            {
                "文章ID": "75848",
                "标题": "New Adversarial Image Detection Based on Sentiment Analysis",
                "作者": " Yulong Wang,  Tianxiang Li,  Shenghong Li,  Xin Yuan,  Wei Ni",
                "发布日期": "2023-05-08",
                "摘要": "  Deep Neural Networks (DNNs) are vulnerable to adversarial examples, while\nadversarial attack models, e.g., DeepFool, are on the rise and outrunning\nadversarial example detection techniques. This paper presents a new adversarial\nexample detector that outperforms state-of-the-art detectors in identifying the\nlatest adversarial attacks on image datasets. Specifically, we propose to use\nsentiment analysis for adversarial example detection, qualified by the\nprogressively manifesting impact of an adversarial perturbation on the\nhidden-layer feature maps of a DNN under attack. Accordingly, we design a\nmodularized embedding layer with the minimum learnable parameters to embed the\nhidden-layer feature maps into word vectors and assemble sentences ready for\nsentiment analysis. Extensive experiments demonstrate that the new detector\nconsistently surpasses the state-of-the-art detection algorithms in detecting\nthe latest attacks launched against ResNet and Inception neutral networks on\nthe CIFAR-10, CIFAR-100 and SVHN datasets. The detector only has about 2\nmillion parameters, and takes shorter than 4.6 milliseconds to detect an\nadversarial example generated by the latest attack models using a Tesla K80 GPU\ncard.\n",
                "链接": "https://arxiv.org/abs/2305.03173"
            },
            {
                "文章ID": "120683",
                "标题": "Sentiment Analysis of Twitter Posts on Global Conflicts",
                "作者": " Ujwal Sasikumar,  Ank Zaman,  Abdul-Rahman Mawlood-Yunis,  Prosenjit Chatterjee",
                "发布日期": "2023-12-08",
                "摘要": "  Sentiment analysis of social media data is an emerging field with vast\napplications in various domains. In this study, we developed a sentiment\nanalysis model to analyze social media sentiment, especially tweets, during\nglobal conflicting scenarios. To establish our research experiment, we\nidentified a recent global dispute incident on Twitter and collected around\n31,000 filtered Tweets for several months to analyze human sentiment worldwide.\n",
                "链接": "https://arxiv.org/abs/2312.03715"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于NLP领域的持续性学习论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "108574",
                "标题": "PerturbScore: Connecting Discrete and Continuous Perturbations in NLP",
                "作者": " Linyang Li,  Ke Ren,  Yunfan Shao,  Pengyu Wang,  Xipeng Qiu",
                "发布日期": "2023-10-16",
                "摘要": "  With the rapid development of neural network applications in NLP, model\nrobustness problem is gaining more attention. Different from computer vision,\nthe discrete nature of texts makes it more challenging to explore robustness in\nNLP. Therefore, in this paper, we aim to connect discrete perturbations with\ncontinuous perturbations, therefore we can use such connections as a bridge to\nhelp understand discrete perturbations in NLP models. Specifically, we first\nexplore how to connect and measure the correlation between discrete\nperturbations and continuous perturbations. Then we design a regression task as\na PerturbScore to learn the correlation automatically. Through experimental\nresults, we find that we can build a connection between discrete and continuous\nperturbations and use the proposed PerturbScore to learn such correlation,\nsurpassing previous methods used in discrete perturbation measuring. Further,\nthe proposed PerturbScore can be well generalized to different datasets,\nperturbation methods, indicating that we can use it as a powerful tool to study\nmodel robustness in NLP.\n",
                "链接": "https://arxiv.org/abs/2310.08889"
            },
            {
                "文章ID": "59134",
                "标题": "Continuous Spatiotemporal Transformers",
                "作者": " Antonio H. de O. Fonseca,  Emanuele Zappala,  Josue Ortega Caro,  David van Dijk",
                "发布日期": "2023-08-01",
                "摘要": "  Modeling spatiotemporal dynamical systems is a fundamental challenge in\nmachine learning. Transformer models have been very successful in NLP and\ncomputer vision where they provide interpretable representations of data.\nHowever, a limitation of transformers in modeling continuous dynamical systems\nis that they are fundamentally discrete time and space models and thus have no\nguarantees regarding continuous sampling. To address this challenge, we present\nthe Continuous Spatiotemporal Transformer (CST), a new transformer architecture\nthat is designed for the modeling of continuous systems. This new framework\nguarantees a continuous and smooth output via optimization in Sobolev space. We\nbenchmark CST against traditional transformers as well as other spatiotemporal\ndynamics modeling methods and achieve superior performance in a number of tasks\non synthetic and real systems, including learning brain dynamics from calcium\nimaging data.\n",
                "链接": "https://arxiv.org/abs/2301.13338"
            },
            {
                "文章ID": "5931",
                "标题": "Learning continuous models for continuous physics",
                "作者": " Aditi S. Krishnapriyan,  Alejandro F. Queiruga,  N. Benjamin Erichson,  Michael W. Mahoney",
                "发布日期": "2023-11-23",
                "摘要": "  Dynamical systems that evolve continuously over time are ubiquitous\nthroughout science and engineering. Machine learning (ML) provides data-driven\napproaches to model and predict the dynamics of such systems. A core issue with\nthis approach is that ML models are typically trained on discrete data, using\nML methodologies that are not aware of underlying continuity properties. This\nresults in models that often do not capture any underlying continuous dynamics\n-- either of the system of interest, or indeed of any related system. To\naddress this challenge, we develop a convergence test based on numerical\nanalysis theory. Our test verifies whether a model has learned a function that\naccurately approximates an underlying continuous dynamics. Models that fail\nthis test fail to capture relevant dynamics, rendering them of limited utility\nfor many scientific prediction tasks; while models that pass this test enable\nboth better interpolation and better extrapolation in multiple ways. Our\nresults illustrate how principled numerical analysis methods can be coupled\nwith existing ML training/testing methodologies to validate models for science\nand engineering applications.\n",
                "链接": "https://arxiv.org/abs/2202.08494"
            },
            {
                "文章ID": "107263",
                "标题": "Continuous Invariance Learning",
                "作者": " Yong Lin,  Fan Zhou,  Lu Tan,  Lintao Ma,  Jiameng Liu,  Yansu He,  Yuan Yuan,  Yu Liu,  James Zhang,  Yujiu Yang,  Hao Wang",
                "发布日期": "2023-10-10",
                "摘要": "  Invariance learning methods aim to learn invariant features in the hope that\nthey generalize under distributional shifts. Although many tasks are naturally\ncharacterized by continuous domains, current invariance learning techniques\ngenerally assume categorically indexed domains. For example, auto-scaling in\ncloud computing often needs a CPU utilization prediction model that generalizes\nacross different times (e.g., time of a day and date of a year), where `time'\nis a continuous domain index. In this paper, we start by theoretically showing\nthat existing invariance learning methods can fail for continuous domain\nproblems. Specifically, the naive solution of splitting continuous domains into\ndiscrete ones ignores the underlying relationship among domains, and therefore\npotentially leads to suboptimal performance. To address this challenge, we then\npropose Continuous Invariance Learning (CIL), which extracts invariant features\nacross continuously indexed domains. CIL is a novel adversarial procedure that\nmeasures and controls the conditional independence between the labels and\ncontinuous domain indices given the extracted features. Our theoretical\nanalysis demonstrates the superiority of CIL over existing invariance learning\nmethods. Empirical results on both synthetic and real-world datasets (including\ndata collected from production systems) show that CIL consistently outperforms\nstrong baselines among all the tasks.\n",
                "链接": "https://arxiv.org/abs/2310.05348"
            },
            {
                "文章ID": "77004",
                "标题": "COCKATIEL: COntinuous Concept ranKed ATtribution with Interpretable\n  ELements for explaining neural net classifiers on NLP tasks",
                "作者": " Fanny Jourdan,  Agustin Picard,  Thomas Fel,  Laurent Risser,  Jean Michel Loubes,  Nicholas Asher",
                "发布日期": "2023-06-26",
                "摘要": "  Transformer architectures are complex and their use in NLP, while it has\nengendered many successes, makes their interpretability or explainability\nchallenging. Recent debates have shown that attention maps and attribution\nmethods are unreliable (Pruthi et al., 2019; Brunner et al., 2019). In this\npaper, we present some of their limitations and introduce COCKATIEL, which\nsuccessfully addresses some of them. COCKATIEL is a novel, post-hoc,\nconcept-based, model-agnostic XAI technique that generates meaningful\nexplanations from the last layer of a neural net model trained on an NLP\nclassification task by using Non-Negative Matrix Factorization (NMF) to\ndiscover the concepts the model leverages to make predictions and by exploiting\na Sensitivity Analysis to estimate accurately the importance of each of these\nconcepts for the model. It does so without compromising the accuracy of the\nunderlying model or requiring a new one to be trained. We conduct experiments\nin single and multi-aspect sentiment analysis tasks and we show COCKATIEL's\nsuperior ability to discover concepts that align with humans' on Transformer\nmodels without any supervision, we objectively verify the faithfulness of its\nexplanations through fidelity metrics, and we showcase its ability to provide\nmeaningful explanations in two different datasets.\n",
                "链接": "https://arxiv.org/abs/2305.06754"
            },
            {
                "文章ID": "107426",
                "标题": "DiffuSeq-v2: Bridging Discrete and Continuous Text Spaces for\n  Accelerated Seq2Seq Diffusion Models",
                "作者": " Shansan Gong,  Mukai Li,  Jiangtao Feng,  Zhiyong Wu,  Lingpeng Kong",
                "发布日期": "2023-10-17",
                "摘要": "  Diffusion models have gained prominence in generating high-quality sequences\nof text. Nevertheless, current approaches predominantly represent discrete text\nwithin a continuous diffusion space, which incurs substantial computational\noverhead during training and results in slower sampling speeds. In this paper,\nwe introduce a soft absorbing state that facilitates the diffusion model in\nlearning to reconstruct discrete mutations based on the underlying Gaussian\nspace, thereby enhancing its capacity to recover conditional signals. During\nthe sampling phase, we employ state-of-the-art ODE solvers within the\ncontinuous space to expedite the sampling process. Comprehensive experimental\nevaluations reveal that our proposed method effectively accelerates the\ntraining convergence by 4x and generates samples of similar quality 800x\nfaster, rendering it significantly closer to practical application.\n\\footnote{The code is released at \\url{https://github.com/Shark-NLP/DiffuSeq}\n",
                "链接": "https://arxiv.org/abs/2310.05793"
            },
            {
                "文章ID": "72957",
                "标题": "D2CSE: Difference-aware Deep continuous prompts for Contrastive Sentence\n  Embeddings",
                "作者": " Hyunjae Lee",
                "发布日期": "2023-04-19",
                "摘要": "  This paper describes Difference-aware Deep continuous prompt for Contrastive\nSentence Embeddings (D2CSE) that learns sentence embeddings. Compared to\nstate-of-the-art approaches, D2CSE computes sentence vectors that are\nexceptional to distinguish a subtle difference in similar sentences by\nemploying a simple neural architecture for continuous prompts. Unlike existing\narchitectures that require multiple pretrained language models (PLMs) to\nprocess a pair of the original and corrupted (subtly modified) sentences, D2CSE\navoids cumbersome fine-tuning of multiple PLMs by only optimizing continuous\nprompts by performing multiple tasks -- i.e., contrastive learning and\nconditional replaced token detection all done in a self-guided manner. D2CSE\noverloads a single PLM on continuous prompts and greatly saves memory\nconsumption as a result. The number of training parameters in D2CSE is reduced\nto about 1\\% of existing approaches while substantially improving the quality\nof sentence embeddings. We evaluate D2CSE on seven Semantic Textual Similarity\n(STS) benchmarks, using three different metrics, namely, Spearman's rank\ncorrelation, recall@K for a retrieval task, and the anisotropy of an embedding\nspace measured in alignment and uniformity. Our empirical results suggest that\nshallow (not too meticulously devised) continuous prompts can be honed\neffectively for multiple NLP tasks and lead to improvements upon existing\nstate-of-the-art approaches.\n",
                "链接": "https://arxiv.org/abs/2304.08991"
            },
            {
                "文章ID": "110217",
                "标题": "The Past, Present, and Future of Typological Databases in NLP",
                "作者": " Emi Baylor,  Esther Ploeger,  Johannes Bjerva",
                "发布日期": "2023-10-23",
                "摘要": "  Typological information has the potential to be beneficial in the development\nof NLP models, particularly for low-resource languages. Unfortunately, current\nlarge-scale typological databases, notably WALS and Grambank, are inconsistent\nboth with each other and with other sources of typological information, such as\nlinguistic grammars. Some of these inconsistencies stem from coding errors or\nlinguistic variation, but many of the disagreements are due to the discrete\ncategorical nature of these databases. We shed light on this issue by\nsystematically exploring disagreements across typological databases and\nresources, and their uses in NLP, covering the past and present. We next\ninvestigate the future of such work, offering an argument that a continuous\nview of typological features is clearly beneficial, echoing recommendations\nfrom linguistics. We propose that such a view of typology has significant\npotential in the future, including in language modeling in low-resource\nscenarios.\n",
                "链接": "https://arxiv.org/abs/2310.13440"
            },
            {
                "文章ID": "105892",
                "标题": "Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across\n  Language Models",
                "作者": " Zijun Wu,  Yongkang Wu,  Lili Mou",
                "发布日期": "2023-10-04",
                "摘要": "  Prompt tuning in natural language processing (NLP) has become an increasingly\npopular method for adapting large language models to specific tasks. However,\nthe transferability of these prompts, especially continuous prompts, between\ndifferent models remains a challenge. In this work, we propose a zero-shot\ncontinuous prompt transfer method, where source prompts are encoded into\nrelative space and the corresponding target prompts are searched for\ntransferring to target models. Experimental results confirm the effectiveness\nof our method, showing that 'task semantics' in continuous prompts can be\ngeneralized across various language models. Moreover, we find that combining\n'task semantics' from multiple source models can further enhance the\ngeneralizability of transfer.\n",
                "链接": "https://arxiv.org/abs/2310.01691"
            },
            {
                "文章ID": "100564",
                "标题": "Near-continuous time Reinforcement Learning for continuous state-action\n  spaces",
                "作者": "CEREMADE  Lorenzo Croissant, CEREMADE  Marc Abeille, CEREMADE  Bruno Bouchard",
                "发布日期": "2023-09-07",
                "摘要": "  We consider the Reinforcement Learning problem of controlling an unknown\ndynamical system to maximise the long-term average reward along a single\ntrajectory. Most of the literature considers system interactions that occur in\ndiscrete time and discrete state-action spaces. Although this standpoint is\nsuitable for games, it is often inadequate for mechanical or digital systems in\nwhich interactions occur at a high frequency, if not in continuous time, and\nwhose state spaces are large if not inherently continuous. Perhaps the only\nexception is the Linear Quadratic framework for which results exist both in\ndiscrete and continuous time. However, its ability to handle continuous states\ncomes with the drawback of a rigid dynamic and reward structure. This work aims\nto overcome these shortcomings by modelling interaction times with a Poisson\nclock of frequency $\\varepsilon^{-1}$, which captures arbitrary time scales:\nfrom discrete ($\\varepsilon=1$) to continuous time ($\\varepsilon\\downarrow0$).\nIn addition, we consider a generic reward function and model the state dynamics\naccording to a jump process with an arbitrary transition kernel on\n$\\mathbb{R}^d$. We show that the celebrated optimism protocol applies when the\nsub-tasks (learning and planning) can be performed effectively. We tackle\nlearning within the eluder dimension framework and propose an approximate\nplanning method based on a diffusive limit approximation of the jump process.\nOverall, our algorithm enjoys a regret of order\n$\\tilde{\\mathcal{O}}(\\varepsilon^{1/2} T+\\sqrt{T})$. As the frequency of\ninteractions blows up, the approximation error $\\varepsilon^{1/2} T$ vanishes,\nshowing that $\\tilde{\\mathcal{O}}(\\sqrt{T})$ is attainable in near-continuous\ntime.\n",
                "链接": "https://arxiv.org/abs/2309.02815"
            }
        ]
    },
    {
        "question": {
            "question": "找一下最近关于大模型评测的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "72313",
                "标题": "Evaluation of Social Biases in Recent Large Pre-Trained Models",
                "作者": " Swapnil Sharma,  Nikita Anand,  Kranthi Kiran G. V.,  Alind Jain",
                "发布日期": "2023-04-17",
                "摘要": "  Large pre-trained language models are widely used in the community. These\nmodels are usually trained on unmoderated and unfiltered data from open sources\nlike the Internet. Due to this, biases that we see in platforms online which\nare a reflection of those in society are in turn captured and learned by these\nmodels. These models are deployed in applications that affect millions of\npeople and their inherent biases are harmful to the targeted social groups. In\nthis work, we study the general trend in bias reduction as newer pre-trained\nmodels are released. Three recent models ( ELECTRA, DeBERTa, and DistilBERT)\nare chosen and evaluated against two bias benchmarks, StereoSet and\nCrowS-Pairs. They are compared to the baseline of BERT using the associated\nmetrics. We explore whether as advancements are made and newer, faster, lighter\nmodels are released: are they being developed responsibly such that their\ninherent social biases have been reduced compared to their older counterparts?\nThe results are compiled and we find that all the models under study do exhibit\nbiases but have generally improved as compared to BERT.\n",
                "链接": "https://arxiv.org/abs/2304.06861"
            },
            {
                "文章ID": "7420",
                "标题": "Did AI get more negative recently?",
                "作者": " Dominik Beese,  Begüm Altunbaş,  Görkem Güzeler,  Steffen Eger",
                "发布日期": "2023-06-30",
                "摘要": "  In this paper, we classify scientific articles in the domain of natural\nlanguage processing (NLP) and machine learning (ML), as core subfields of\nartificial intelligence (AI), into whether (i) they extend the current\nstate-of-the-art by the introduction of novel techniques which beat existing\nmodels or whether (ii) they mainly criticize the existing state-of-the-art,\ni.e. that it is deficient with respect to some property (e.g. wrong evaluation,\nwrong datasets, misleading task specification). We refer to contributions under\n(i) as having a 'positive stance' and contributions under (ii) as having a\n'negative stance' (to related work). We annotate over 1.5 k papers from NLP and\nML to train a SciBERT-based model to automatically predict the stance of a\npaper based on its title and abstract. We then analyse large-scale trends on\nover 41 k papers from the last approximately 35 years in NLP and ML, finding\nthat papers have become substantially more positive over time, but negative\npapers also got more negative and we observe considerably more negative papers\nin recent years. Negative papers are also more influential in terms of\ncitations they receive.\n",
                "链接": "https://arxiv.org/abs/2202.13610"
            },
            {
                "文章ID": "80431",
                "标题": "SciReviewGen: A Large-scale Dataset for Automatic Literature Review\n  Generation",
                "作者": " Tetsu Kasanishi,  Masaru Isonuma,  Junichiro Mori,  Ichiro Sakata",
                "发布日期": "2023-05-25",
                "摘要": "  Automatic literature review generation is one of the most challenging tasks\nin natural language processing. Although large language models have tackled\nliterature review generation, the absence of large-scale datasets has been a\nstumbling block to the progress. We release SciReviewGen, consisting of over\n10,000 literature reviews and 690,000 papers cited in the reviews. Based on the\ndataset, we evaluate recent transformer-based summarization models on the\nliterature review generation task, including Fusion-in-Decoder extended for\nliterature review generation. Human evaluation results show that some\nmachine-generated summaries are comparable to human-written reviews, while\nrevealing the challenges of automatic literature review generation such as\nhallucinations and a lack of detailed information. Our dataset and code are\navailable at https://github.com/tetsu9923/SciReviewGen.\n",
                "链接": "https://arxiv.org/abs/2305.15186"
            },
            {
                "文章ID": "108517",
                "标题": "Question Answering for Electronic Health Records: A Scoping Review of\n  datasets and models",
                "作者": " Jayetri Bardhan,  Kirk Roberts,  Daisy Zhe Wang",
                "发布日期": "2023-11-09",
                "摘要": "  Question Answering (QA) systems on patient-related data can assist both\nclinicians and patients. They can, for example, assist clinicians in\ndecision-making and enable patients to have a better understanding of their\nmedical history. Significant amounts of patient data are stored in Electronic\nHealth Records (EHRs), making EHR QA an important research area. In EHR QA, the\nanswer is obtained from the medical record of the patient. Because of the\ndifferences in data format and modality, this differs greatly from other\nmedical QA tasks that employ medical websites or scientific papers to retrieve\nanswers, making it critical to research EHR question answering. This study\naimed to provide a methodological review of existing works on QA over EHRs. We\nsearched for articles from January 1st, 2005 to September 30th, 2023 in four\ndigital sources including Google Scholar, ACL Anthology, ACM Digital Library,\nand PubMed to collect relevant publications on EHR QA. 4111 papers were\nidentified for our study, and after screening based on our inclusion criteria,\nwe obtained a total of 47 papers for further study. Out of the 47 papers, 25\npapers were about EHR QA datasets, and 37 papers were about EHR QA models. It\nwas observed that QA on EHRs is relatively new and unexplored. Most of the\nworks are fairly recent. Also, it was observed that emrQA is by far the most\npopular EHR QA dataset, both in terms of citations and usage in other papers.\nFurthermore, we identified the different models used in EHR QA along with the\nevaluation metrics used for these models.\n",
                "链接": "https://arxiv.org/abs/2310.08759"
            },
            {
                "文章ID": "85250",
                "标题": "The Devil is in the Details: On the Pitfalls of Event Extraction\n  Evaluation",
                "作者": " Hao Peng,  Xiaozhi Wang,  Feng Yao,  Kaisheng Zeng,  Lei Hou,  Juanzi Li,  Zhiyuan Liu,  Weixing Shen",
                "发布日期": "2023-06-16",
                "摘要": "  Event extraction (EE) is a crucial task aiming at extracting events from\ntexts, which includes two subtasks: event detection (ED) and event argument\nextraction (EAE). In this paper, we check the reliability of EE evaluations and\nidentify three major pitfalls: (1) The data preprocessing discrepancy makes the\nevaluation results on the same dataset not directly comparable, but the data\npreprocessing details are not widely noted and specified in papers. (2) The\noutput space discrepancy of different model paradigms makes different-paradigm\nEE models lack grounds for comparison and also leads to unclear mapping issues\nbetween predictions and annotations. (3) The absence of pipeline evaluation of\nmany EAE-only works makes them hard to be directly compared with EE works and\nmay not well reflect the model performance in real-world pipeline scenarios. We\ndemonstrate the significant influence of these pitfalls through comprehensive\nmeta-analyses of recent papers and empirical experiments. To avoid these\npitfalls, we suggest a series of remedies, including specifying data\npreprocessing, standardizing outputs, and providing pipeline evaluation\nresults. To help implement these remedies, we develop a consistent evaluation\nframework OMNIEVENT, which can be obtained from\nhttps://github.com/THU-KEG/OmniEvent.\n",
                "链接": "https://arxiv.org/abs/2306.06918"
            },
            {
                "文章ID": "54601",
                "标题": "Transformers Go for the LOLs: Generating (Humourous) Titles from\n  Scientific Abstracts End-to-End",
                "作者": " Yanran Chen,  Steffen Eger",
                "发布日期": "2023-12-27",
                "摘要": "  We consider the end-to-end abstract-to-title generation problem, exploring\nseven recent transformer based models (including ChatGPT) fine-tuned on more\nthan 30k abstract-title pairs from NLP and machine learning (ML) venues. As an\nextension, we also consider the harder problem of generating humorous paper\ntitles. For the latter, we compile the first large-scale humor annotated\ndataset for scientific papers in the NLP/ML domains, comprising almost ~2.6k\ntitles. We evaluate all models using human and automatic metrics. Our human\nevaluation suggests that our best end-to-end system performs similarly to human\nauthors (but arguably slightly worse). Generating funny titles is more\ndifficult, however, and our automatic systems clearly underperform relative to\nhumans and often learn dataset artefacts of humor. Finally, ChatGPT, without\nany fine-tuning, performs on the level of our best fine-tuned system.\n",
                "链接": "https://arxiv.org/abs/2212.10522"
            },
            {
                "文章ID": "104036",
                "标题": "ALLURE: Auditing and Improving LLM-based Evaluation of Text using\n  Iterative In-Context-Learning",
                "作者": " Hosein Hasanbeig,  Hiteshi Sharma,  Leo Betthauser,  Felipe Vieira Frujeri,  Ida Momennejad",
                "发布日期": "2023-09-28",
                "摘要": "  From grading papers to summarizing medical documents, large language models\n(LLMs) are evermore used for evaluation of text generated by humans and AI\nalike. However, despite their extensive utility, LLMs exhibit distinct failure\nmodes, necessitating a thorough audit and improvement of their text evaluation\ncapabilities. Here we introduce ALLURE, a systematic approach to Auditing Large\nLanguage Models Understanding and Reasoning Errors. ALLURE involves comparing\nLLM-generated evaluations with annotated data, and iteratively incorporating\ninstances of significant deviation into the evaluator, which leverages\nin-context learning (ICL) to enhance and improve robust evaluation of text by\nLLMs. Through this iterative process, we refine the performance of the\nevaluator LLM, ultimately reducing reliance on human annotators in the\nevaluation process. We anticipate ALLURE to serve diverse applications of LLMs\nin various domains related to evaluation of textual data, such as medical\nsummarization, education, and and productivity.\n",
                "链接": "https://arxiv.org/abs/2309.13701"
            },
            {
                "文章ID": "95587",
                "标题": "NLLG Quarterly arXiv Report 06/23: What are the most influential current\n  AI Papers?",
                "作者": " Steffen Eger,  Christoph Leiter,  Jonas Belouadi,  Ran Zhang,  Aida Kostikova,  Daniil Larionov,  Yanran Chen,  Vivian Fresen",
                "发布日期": "2023-08-15",
                "摘要": "  The rapid growth of information in the field of Generative Artificial\nIntelligence (AI), particularly in the subfields of Natural Language Processing\n(NLP) and Machine Learning (ML), presents a significant challenge for\nresearchers and practitioners to keep pace with the latest developments. To\naddress the problem of information overload, this report by the Natural\nLanguage Learning Group at Bielefeld University focuses on identifying the most\npopular papers on arXiv, with a specific emphasis on NLP and ML. The objective\nis to offer a quick guide to the most relevant and widely discussed research,\naiding both newcomers and established researchers in staying abreast of current\ntrends. In particular, we compile a list of the 40 most popular papers based on\nnormalized citation counts from the first half of 2023. We observe the\ndominance of papers related to Large Language Models (LLMs) and specifically\nChatGPT during the first half of 2023, with the latter showing signs of\ndeclining popularity more recently, however. Further, NLP related papers are\nthe most influential (around 60\\% of top papers) even though there are twice as\nmany ML related papers in our data. Core issues investigated in the most\nheavily cited papers are: LLM efficiency, evaluation techniques, ethical\nconsiderations, embodied agents, and problem-solving with LLMs. Additionally,\nwe examine the characteristics of top papers in comparison to others outside\nthe top-40 list (noticing the top paper's focus on LLM related issues and\nhigher number of co-authors) and analyze the citation distributions in our\ndataset, among others.\n",
                "链接": "https://arxiv.org/abs/2308.04889"
            },
            {
                "文章ID": "90669",
                "标题": "Deep Generative Models for Physiological Signals: A Systematic\n  Literature Review",
                "作者": " Nour Neifar,  Afef Mdhaffar,  Achraf Ben-Hamadou,  Mohamed Jmaiel",
                "发布日期": "2023-07-13",
                "摘要": "  In this paper, we present a systematic literature review on deep generative\nmodels for physiological signals, particularly electrocardiogram,\nelectroencephalogram, photoplethysmogram and electromyogram. Compared to the\nexisting review papers, we present the first review that summarizes the recent\nstate-of-the-art deep generative models. By analysing the state-of-the-art\nresearch related to deep generative models along with their main applications\nand challenges, this review contributes to the overall understanding of these\nmodels applied to physiological signals. Additionally, by highlighting the\nemployed evaluation protocol and the most used physiological databases, this\nreview facilitates the assessment and benchmarking of deep generative models.\n",
                "链接": "https://arxiv.org/abs/2307.06162"
            },
            {
                "文章ID": "70684",
                "标题": "Toward Verifiable and Reproducible Human Evaluation for Text-to-Image\n  Generation",
                "作者": " Mayu Otani,  Riku Togashi,  Yu Sawai,  Ryosuke Ishigami,  Yuta Nakashima,  Esa Rahtu,  Janne Heikkilä,  Shin'ichi Satoh",
                "发布日期": "2023-04-05",
                "摘要": "  Human evaluation is critical for validating the performance of text-to-image\ngenerative models, as this highly cognitive process requires deep comprehension\nof text and images. However, our survey of 37 recent papers reveals that many\nworks rely solely on automatic measures (e.g., FID) or perform poorly described\nhuman evaluations that are not reliable or repeatable. This paper proposes a\nstandardized and well-defined human evaluation protocol to facilitate\nverifiable and reproducible human evaluation in future works. In our pilot data\ncollection, we experimentally show that the current automatic measures are\nincompatible with human perception in evaluating the performance of the\ntext-to-image generation results. Furthermore, we provide insights for\ndesigning human evaluation experiments reliably and conclusively. Finally, we\nmake several resources publicly available to the community to facilitate easy\nand fast implementations.\n",
                "链接": "https://arxiv.org/abs/2304.01816"
            }
        ]
    },
    {
        "question": {
            "question": "近一个月与多模态大模型相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "97795",
                "标题": "Federated Learning in Big Model Era: Domain-Specific Multimodal Large\n  Models",
                "作者": " Zengxiang Li,  Zhaoxiang Hou,  Hui Liu,  Ying Wang,  Tongzhi Li,  Longfei Xie,  Chao Shi,  Chengyi Yang,  Weishan Zhang,  Zelei Liu,  Liang Xu",
                "发布日期": "2023-08-25",
                "摘要": "  Multimodal data, which can comprehensively perceive and recognize the\nphysical world, has become an essential path towards general artificial\nintelligence. However, multimodal large models trained on public datasets often\nunderperform in specific industrial domains. This paper proposes a multimodal\nfederated learning framework that enables multiple enterprises to utilize\nprivate domain data to collaboratively train large models for vertical domains,\nachieving intelligent services across scenarios. The authors discuss in-depth\nthe strategic transformation of federated learning in terms of intelligence\nfoundation and objectives in the era of big model, as well as the new\nchallenges faced in heterogeneous data, model aggregation, performance and cost\ntrade-off, data privacy, and incentive mechanism. The paper elaborates a case\nstudy of leading enterprises contributing multimodal data and expert knowledge\nto city safety operation management , including distributed deployment and\nefficient coordination of the federated learning platform, technical\ninnovations on data quality improvement based on large model capabilities and\nefficient joint fine-tuning approaches. Preliminary experiments show that\nenterprises can enhance and accumulate intelligent capabilities through\nmultimodal model federated learning, thereby jointly creating an smart city\nmodel that provides high-quality intelligent services covering energy\ninfrastructure safety, residential community security, and urban operation\nmanagement. The established federated learning cooperation ecosystem is\nexpected to further aggregate industry, academia, and research resources,\nrealize large models in multiple vertical domains, and promote the large-scale\nindustrial application of artificial intelligence and cutting-edge research on\nmultimodal federated learning.\n",
                "链接": "https://arxiv.org/abs/2308.11217"
            },
            {
                "文章ID": "11847",
                "标题": "A Roadmap for Big Model",
                "作者": " Sha Yuan,  Hanyu Zhao,  Shuai Zhao,  Jiahong Leng,  Yangxiao Liang,  Xiaozhi Wang,  Jifan Yu,  Xin Lv,  Zhou Shao,  Jiaao He,  Yankai Lin,  Xu Han,  Zhenghao Liu,  Ning Ding,  Yongming Rao,  Yizhao Gao,  Liang Zhang,  Ming Ding,  Cong Fang,  Yisen Wang,  Mingsheng Long,  Jing Zhang,  Yinpeng Dong,  Tianyu Pang,  Peng Cui,  Lingxiao Huang,  Zheng Liang,  Huawei Shen,  Hui Zhang,  Quanshi Zhang,  Qingxiu Dong,  Zhixing Tan,  Mingxuan Wang,  Shuo Wang,  Long Zhou,  Haoran Li,  Junwei Bao,  Yingwei Pan,  Weinan Zhang,  Zhou Yu,  Rui Yan,  Chence Shi,  Minghao Xu,  Zuobai Zhang,  Guoqiang Wang,  Xiang Pan,  Mengjie Li,  Xiaoyu Chu,  Zijun Yao,  Fangwei Zhu,  Shulin Cao,  Weicheng Xue,  Zixuan Ma,  Zhengyan Zhang,  Shengding Hu,  Yujia Qin,  Chaojun Xiao,  Zheni Zeng,  Ganqu Cui,  Weize Chen,  Weilin Zhao,  Yuan Yao,  Peng Li,  Wenzhao Zheng,  Wenliang Zhao,  Ziyi Wang,  Borui Zhang,  Nanyi Fei,  Anwen Hu,  Zenan Ling,  Haoyang Li,  Boxi Cao,  Xianpei Han,  Weidong Zhan,  Baobao Chang,  Hao Sun,  Jiawen Deng,  Chujie Zheng,  Juanzi Li,  Lei Hou,  Xigang Cao,  Jidong Zhai,  Zhiyuan Liu,  Maosong Sun,  Jiwen Lu,  Zhiwu Lu,  Qin Jin,  Ruihua Song,  Ji-Rong Wen,  Zhouchen Lin,  Liwei Wang,  Hang Su,  Jun Zhu,  Zhifang Sui,  Jiajun Zhang,  Yang Liu,  Xiaodong He,  Minlie Huang,  Jian Tang,  Jie Tang",
                "发布日期": "2022-04-21",
                "摘要": "  With the rapid development of deep learning, training Big Models (BMs) for\nmultiple downstream tasks becomes a popular paradigm. Researchers have achieved\nvarious outcomes in the construction of BMs and the BM application in many\nfields. At present, there is a lack of research work that sorts out the overall\nprogress of BMs and guides the follow-up research. In this paper, we cover not\nonly the BM technologies themselves but also the prerequisites for BM training\nand applications with BMs, dividing the BM review into four parts: Resource,\nModels, Key Technologies and Application. We introduce 16 specific BM-related\ntopics in those four parts, they are Data, Knowledge, Computing System,\nParallel Training System, Language Model, Vision Model, Multi-modal Model,\nTheory&Interpretability, Commonsense Reasoning, Reliability&Security,\nGovernance, Evaluation, Machine Translation, Text Generation, Dialogue and\nProtein Research. In each topic, we summarize clearly the current studies and\npropose some future research directions. At the end of this paper, we conclude\nthe further development of BMs in a more general view.\n",
                "链接": "https://arxiv.org/abs/2203.14101"
            },
            {
                "文章ID": "118781",
                "标题": "Large Model Based Referring Camouflaged Object Detection",
                "作者": " Shupeng Cheng,  Ge-Peng Ji,  Pengda Qin,  Deng-Ping Fan,  Bowen Zhou,  Peng Xu",
                "发布日期": "2023-11-30",
                "摘要": "  Referring camouflaged object detection (Ref-COD) is a recently-proposed\nproblem aiming to segment out specified camouflaged objects matched with a\ntextual or visual reference. This task involves two major challenges: the COD\ndomain-specific perception and multimodal reference-image alignment. Our\nmotivation is to make full use of the semantic intelligence and intrinsic\nknowledge of recent Multimodal Large Language Models (MLLMs) to decompose this\ncomplex task in a human-like way. As language is highly condensed and\ninductive, linguistic expression is the main media of human knowledge learning,\nand the transmission of knowledge information follows a multi-level progression\nfrom simplicity to complexity. In this paper, we propose a large-model-based\nMulti-Level Knowledge-Guided multimodal method for Ref-COD termed MLKG, where\nmulti-level knowledge descriptions from MLLM are organized to guide the large\nvision model of segmentation to perceive the camouflage-targets and\ncamouflage-scene progressively and meanwhile deeply align the textual\nreferences with camouflaged photos. To our knowledge, our contributions mainly\ninclude: (1) This is the first time that the MLLM knowledge is studied for\nRef-COD and COD. (2) We, for the first time, propose decomposing Ref-COD into\ntwo main perspectives of perceiving the target and scene by integrating MLLM\nknowledge, and contribute a multi-level knowledge-guided method. (3) Our method\nachieves the state-of-the-art on the Ref-COD benchmark outperforming numerous\nstrong competitors. Moreover, thanks to the injected rich knowledge, it\ndemonstrates zero-shot generalization ability on uni-modal COD datasets. We\nwill release our code soon.\n",
                "链接": "https://arxiv.org/abs/2311.17122"
            },
            {
                "文章ID": "124096",
                "标题": "AccidentGPT: Accident Analysis and Prevention from V2X Environmental\n  Perception with Multi-modal Large Model",
                "作者": " Lening Wang,  Han Jiang,  Pinlong Cai,  Daocheng Fu,  Tianqi Wang,  Zhiyong Cui,  Yilong Ren,  Haiyang Yu,  Xuesong Wang,  Hanchu Zhou,  Helai Huang,  Yinhai Wang",
                "发布日期": "2023-12-29",
                "摘要": "  Traffic accidents, being a significant contributor to both human casualties\nand property damage, have long been a focal point of research for many scholars\nin the field of traffic safety. However, previous studies, whether focusing on\nstatic environmental assessments or dynamic driving analyses, as well as\npre-accident predictions or post-accident rule analyses, have typically been\nconducted in isolation. There has been a lack of an effective framework for\ndeveloping a comprehensive understanding and application of traffic safety. To\naddress this gap, this paper introduces AccidentGPT, a comprehensive accident\nanalysis and prevention multi-modal large model. AccidentGPT establishes a\nmulti-modal information interaction framework grounded in multi-sensor\nperception, thereby enabling a holistic approach to accident analysis and\nprevention in the field of traffic safety. Specifically, our capabilities can\nbe categorized as follows: for autonomous driving vehicles, we provide\ncomprehensive environmental perception and understanding to control the vehicle\nand avoid collisions. For human-driven vehicles, we offer proactive long-range\nsafety warnings and blind-spot alerts while also providing safety driving\nrecommendations and behavioral norms through human-machine dialogue and\ninteraction. Additionally, for traffic police and management agencies, our\nframework supports intelligent and real-time analysis of traffic safety,\nencompassing pedestrian, vehicles, roads, and the environment through\ncollaborative perception from multiple vehicles and road testing devices. The\nsystem is also capable of providing a thorough analysis of accident causes and\nliability after vehicle collisions. Our framework stands as the first large\nmodel to integrate comprehensive scene understanding into traffic safety\nstudies. Project page: https://accidentgpt.github.io\n",
                "链接": "https://arxiv.org/abs/2312.13156"
            },
            {
                "文章ID": "82820",
                "标题": "GPT4Image: Can Large Pre-trained Models Help Vision Models on Perception\n  Tasks?",
                "作者": " Ning Ding,  Yehui Tang,  Zhongqian Fu,  Chao Xu,  Kai Han,  Yunhe Wang",
                "发布日期": "2023-06-08",
                "摘要": "  The recent upsurge in pre-trained large models (e.g. GPT-4) has swept across\nthe entire deep learning community. Such powerful large language models (LLMs)\ndemonstrate advanced generative ability and multimodal understanding\ncapability, which quickly achieve new state-of-the-art performances on a\nvariety of benchmarks. The pre-trained LLM usually plays the role as a\nuniversal AI model that can conduct various tasks, including context reasoning,\narticle analysis and image content comprehension. However, considering the\nprohibitively high memory and computational cost for implementing such a large\nmodel, the conventional models (such as CNN and ViT), are still essential for\nmany visual perception tasks. In this paper, we propose to enhance the\nrepresentation ability of ordinary vision models for perception tasks (e.g.\nimage classification) by taking advantage of large pre-trained models. We\npresent a new learning paradigm in which the knowledge extracted from large\npre-trained models are utilized to help models like CNN and ViT learn enhanced\nrepresentations and achieve better performance. Firstly, we curate a high\nquality description set by prompting a multimodal LLM to generate descriptive\ntext for all training images. Furthermore, we feed these detailed descriptions\ninto a pre-trained encoder to extract text embeddings with rich semantic\ninformation that encodes the content of images. During training, text\nembeddings will serve as extra supervising signals and be aligned with image\nrepresentations learned by vision models. The alignment process helps vision\nmodels learn better and achieve higher accuracy with the assistance of\npre-trained LLMs. We conduct extensive experiments to verify that the proposed\nalgorithm consistently improves the performance for various vision models with\nheterogeneous architectures.\n",
                "链接": "https://arxiv.org/abs/2306.00693"
            },
            {
                "文章ID": "117119",
                "标题": "nach0: Multimodal Natural and Chemical Languages Foundation Model",
                "作者": " Micha Livne,  Zulfat Miftahutdinov,  Elena Tutubalina,  Maksim Kuznetsov,  Daniil Polykovskiy,  Annika Brundyn,  Aastha Jhunjhunwala,  Anthony Costa,  Alex Aliper,  Alex Zhavoronkov",
                "发布日期": "2023-11-22",
                "摘要": "  Large Language Models (LLMs) have substantially driven scientific progress in\nvarious domains, and many papers have demonstrated their ability to tackle\ncomplex problems with creative solutions. Our paper introduces a new foundation\nmodel, nach0, capable of solving various chemical and biological tasks:\nbiomedical question answering, named entity recognition, molecular generation,\nmolecular synthesis, attributes prediction, and others. nach0 is a multi-domain\nand multi-task encoder-decoder LLM pre-trained on unlabeled text from\nscientific literature, patents, and molecule strings to incorporate a range of\nchemical and linguistic knowledge. We employed instruction tuning, where\nspecific task-related instructions are utilized to fine-tune nach0 for the\nfinal set of tasks. To train nach0 effectively, we leverage the NeMo framework,\nenabling efficient parallel optimization of both base and large model versions.\nExtensive experiments demonstrate that our model outperforms state-of-the-art\nbaselines on single-domain and cross-domain tasks. Furthermore, it can generate\nhigh-quality outputs in molecular and textual formats, showcasing its\neffectiveness in multi-domain setups.\n",
                "链接": "https://arxiv.org/abs/2311.12410"
            },
            {
                "文章ID": "76919",
                "标题": "ChatGPT-Like Large-Scale Foundation Models for Prognostics and Health\n  Management: A Survey and Roadmaps",
                "作者": " Yan-Fu Li,  Huan Wang,  Muxia Sun",
                "发布日期": "2023-05-15",
                "摘要": "  Prognostics and health management (PHM) technology plays a critical role in\nindustrial production and equipment maintenance by identifying and predicting\npossible equipment failures and damages, thereby allowing necessary maintenance\nmeasures to be taken to enhance equipment service life and reliability while\nreducing production costs and downtime. In recent years, PHM technology based\non artificial intelligence (AI) has made remarkable achievements in the context\nof the industrial IoT and big data, and it is widely used in various\nindustries, such as railway, energy, and aviation, for condition monitoring,\nfault prediction, and health management. The emergence of large-scale\nfoundation models (LSF-Models) such as ChatGPT and DALLE-E marks the entry of\nAI into a new era of AI-2.0 from AI-1.0, where deep models have rapidly evolved\nfrom a research paradigm of single-modal, single-task, and limited-data to a\nmulti-modal, multi-task, massive data, and super-large model paradigm. ChatGPT\nrepresents a landmark achievement in this research paradigm, offering hope for\ngeneral artificial intelligence due to its highly intelligent natural language\nunderstanding ability. However, the PHM field lacks a consensus on how to\nrespond to this significant change in the AI field, and a systematic review and\nroadmap is required to elucidate future development directions. To fill this\ngap, this paper systematically expounds on the key components and latest\ndevelopments of LSF-Models. Then, we systematically answered how to build the\nLSF-Model applicable to PHM tasks and outlined the challenges and future\ndevelopment roadmaps for this research paradigm.\n",
                "链接": "https://arxiv.org/abs/2305.06472"
            }
        ]
    },
    {
        "question": {
            "question": "查找近六个月工具学习评测数据集的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "108993",
                "标题": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
                "作者": " Alon Jacovi,  Avi Caciularu,  Jonathan Herzig,  Roee Aharoni,  Bernd Bohnet,  Mor Geva",
                "发布日期": "2023-12-29",
                "摘要": "  A growing area of research investigates augmenting language models with tools\n(e.g., search engines, calculators) to overcome their shortcomings (e.g.,\nmissing or incorrect knowledge, incorrect logical inferences). Various few-shot\ntool-usage strategies have been proposed. However, there is no systematic and\nfair comparison across different strategies, or between these strategies and\nstrong baselines that do not leverage tools. We conduct an extensive empirical\nanalysis, finding that (1) across various datasets, example difficulty levels,\nand models, strong no-tool baselines are competitive to tool-assisted\nstrategies, implying that effectively using tools with in-context\ndemonstrations is a difficult unsolved problem; (2) for knowledge-retrieval\ntasks, strategies that *refine* incorrect outputs with tools outperform\nstrategies that retrieve relevant information *ahead of* or *during\ngeneration*; (3) tool-assisted strategies are expensive in the number of tokens\nthey require to work -- incurring additional costs by orders of magnitude --\nwhich does not translate into significant improvement in performance. Overall,\nour findings suggest that few-shot tool integration is still an open challenge,\nemphasizing the need for comprehensive evaluations of future strategies to\naccurately assess their *benefits* and *costs*.\n",
                "链接": "https://arxiv.org/abs/2310.10062"
            },
            {
                "文章ID": "118185",
                "标题": "SVRDA: A Web-based Dataset Annotation Tool for Slice-to-Volume\n  Registration",
                "作者": " Weixun Luo,  Alexandre Triay Bagur,  Paul Aljabar,  George Ralli,  Sir Michael Brady",
                "发布日期": "2023-11-28",
                "摘要": "  Background and Objective: The lack of benchmark datasets has impeded the\ndevelopment of slice-to-volume registration algorithms. Such datasets are\ndifficult to annotate, primarily due to the dimensional difference within data\nand the dearth of task-specific software. We aim to develop a user-friendly\ntool to streamline dataset annotation for slice-to-volume registration.\n  Methods: The proposed tool, named SVRDA, is an installation-free web\napplication for platform-agnostic collaborative dataset annotation. It enables\nefficient transformation manipulation via keyboard shortcuts and smooth case\ntransitions with auto-saving. SVRDA supports configuration-based data loading\nand adheres to the separation of concerns, offering great flexibility and\nextensibility for future research. Various supplementary features have been\nimplemented to facilitate slice-to-volume registration.\n  Results: We validated the effectiveness of SVRDA by indirectly evaluating the\npost-registration segmentation quality on UK Biobank data, observing a dramatic\noverall improvement (24.02% in the Dice Similarity Coefficient and 48.93% in\nthe 95th percentile Hausdorff distance, respectively) supported by highly\nstatistically significant evidence ($p<0.001$).We further showcased the\nclinical usage of SVRDA by integrating it into test-retest T1 quantification on\nin-house magnetic resonance images, leading to more consistent results after\nregistration.\n  Conclusions: SVRDA can facilitate collaborative annotation of benchmark\ndatasets while being potentially applicable to other pipelines incorporating\nslice-to-volume registration. Full source code and documentation are available\nat https://github.com/Roldbach/SVRDA\n",
                "链接": "https://arxiv.org/abs/2311.15536"
            },
            {
                "文章ID": "122009",
                "标题": "CholecTrack20: A Dataset for Multi-Class Multiple Tool Tracking in\n  Laparoscopic Surgery",
                "作者": " Chinedu Innocent Nwoye,  Kareem Elgohary,  Anvita Srinivas,  Fauzan Zaid,  Joël L. Lavanchy,  Nicolas Padoy",
                "发布日期": "2023-12-13",
                "摘要": "  Tool tracking in surgical videos is vital in computer-assisted intervention\nfor tasks like surgeon skill assessment, safety zone estimation, and\nhuman-machine collaboration during minimally invasive procedures. The lack of\nlarge-scale datasets hampers Artificial Intelligence implementation in this\ndomain. Current datasets exhibit overly generic tracking formalization, often\nlacking surgical context: a deficiency that becomes evident when tools move out\nof the camera's scope, resulting in rigid trajectories that hinder realistic\nsurgical representation. This paper addresses the need for a more precise and\nadaptable tracking formalization tailored to the intricacies of endoscopic\nprocedures by introducing CholecTrack20, an extensive dataset meticulously\nannotated for multi-class multi-tool tracking across three perspectives\nrepresenting the various ways of considering the temporal duration of a tool\ntrajectory: (1) intraoperative, (2) intracorporeal, and (3) visibility within\nthe camera's scope. The dataset comprises 20 laparoscopic videos with over\n35,000 frames and 65,000 annotated tool instances with details on spatial\nlocation, category, identity, operator, phase, and surgical visual conditions.\nThis detailed dataset caters to the evolving assistive requirements within a\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2312.07352"
            },
            {
                "文章ID": "117713",
                "标题": "Brain MRI Screening Tool with Federated Learning",
                "作者": " Roman Stoklasa,  Ioannis Stathopoulos,  Efstratios Karavasilis,  Efstathios Efstathopoulos,  Marek Dostál,  Miloš Keřkovský,  Michal Kozubek,  Luigi Serio",
                "发布日期": "2023-11-27",
                "摘要": "  In clinical practice, we often see significant delays between MRI scans and\nthe diagnosis made by radiologists, even for severe cases. In some cases, this\nmay be caused by the lack of additional information and clues, so even the\nsevere cases need to wait in the queue for diagnosis. This can be avoided if\nthere is an automatic software tool, which would supplement additional\ninformation, alerting radiologists that the particular patient may be a severe\ncase.\n  We are presenting an automatic brain MRI Screening Tool and we are\ndemonstrating its capabilities for detecting tumor-like pathologies. It is the\nfirst version on the path toward a robust multi-pathology screening solution.\nThe tool supports Federated Learning, so multiple institutions may contribute\nto the model without disclosing their private data.\n",
                "链接": "https://arxiv.org/abs/2311.14086"
            },
            {
                "文章ID": "114590",
                "标题": "Contextualizing the Limits of Model & Evaluation Dataset Curation on\n  Semantic Similarity Classification Tasks",
                "作者": " Daniel Theron",
                "发布日期": "2023-11-10",
                "摘要": "  This paper demonstrates how the limitations of pre-trained models and open\nevaluation datasets factor into assessing the performance of binary semantic\nsimilarity classification tasks. As (1) end-user-facing documentation around\nthe curation of these datasets and pre-trained model training regimes is often\nnot easily accessible and (2) given the lower friction and higher demand to\nquickly deploy such systems in real-world contexts, our study reinforces prior\nwork showing performance disparities across datasets, embedding techniques and\ndistance metrics, while highlighting the importance of understanding how data\nis collected, curated and analyzed in semantic similarity classification.\n",
                "链接": "https://arxiv.org/abs/2311.04927"
            },
            {
                "文章ID": "116300",
                "标题": "The Song Describer Dataset: a Corpus of Audio Captions for\n  Music-and-Language Evaluation",
                "作者": " Ilaria Manco,  Benno Weck,  SeungHeon Doh,  Minz Won,  Yixiao Zhang,  Dmitry Bogdanov,  Yusong Wu,  Ke Chen,  Philip Tovstogan,  Emmanouil Benetos,  Elio Quinton,  György Fazekas,  Juhan Nam",
                "发布日期": "2023-11-27",
                "摘要": "  We introduce the Song Describer dataset (SDD), a new crowdsourced corpus of\nhigh-quality audio-caption pairs, designed for the evaluation of\nmusic-and-language models. The dataset consists of 1.1k human-written natural\nlanguage descriptions of 706 music recordings, all publicly accessible and\nreleased under Creative Common licenses. To showcase the use of our dataset, we\nbenchmark popular models on three key music-and-language tasks (music\ncaptioning, text-to-music generation and music-language retrieval). Our\nexperiments highlight the importance of cross-dataset evaluation and offer\ninsights into how researchers can use SDD to gain a broader understanding of\nmodel performance.\n",
                "链接": "https://arxiv.org/abs/2311.10057"
            },
            {
                "文章ID": "121559",
                "标题": "MATK: The Meme Analytical Tool Kit",
                "作者": " Ming Shan Hee,  Aditi Kumaresan,  Nguyen Khoi Hoang,  Nirmalendu Prakash,  Rui Cao,  Roy Ka-Wei Lee",
                "发布日期": "2023-12-12",
                "摘要": "  The rise of social media platforms has brought about a new digital culture\ncalled memes. Memes, which combine visuals and text, can strongly influence\npublic opinions on social and cultural issues. As a result, people have become\ninterested in categorizing memes, leading to the development of various\ndatasets and multimodal models that show promising results in this field.\nHowever, there is currently a lack of a single library that allows for the\nreproduction, evaluation, and comparison of these models using fair benchmarks\nand settings. To fill this gap, we introduce the Meme Analytical Tool Kit\n(MATK), an open-source toolkit specifically designed to support existing memes\ndatasets and cutting-edge multimodal models. MATK aims to assist researchers\nand engineers in training and reproducing these multimodal models for meme\nclassification tasks, while also providing analysis techniques to gain insights\ninto their strengths and weaknesses. To access MATK, please visit\n\\url{https://github.com/Social-AI-Studio/MATK}.\n",
                "链接": "https://arxiv.org/abs/2312.06094"
            },
            {
                "文章ID": "123110",
                "标题": "ProTIP: Progressive Tool Retrieval Improves Planning",
                "作者": " Raviteja Anantha,  Bortik Bandyopadhyay,  Anirudh Kashi,  Sayantan Mahinder,  Andrew W Hill,  Srinivas Chappidi",
                "发布日期": "2023-12-19",
                "摘要": "  Large language models (LLMs) are increasingly employed for complex multi-step\nplanning tasks, where the tool retrieval (TR) step is crucial for achieving\nsuccessful outcomes. Two prevalent approaches for TR are single-step retrieval,\nwhich utilizes the complete query, and sequential retrieval using task\ndecomposition (TD), where a full query is segmented into discrete atomic\nsubtasks. While single-step retrieval lacks the flexibility to handle\n\"inter-tool dependency,\" the TD approach necessitates maintaining \"subtask-tool\natomicity alignment,\" as the toolbox can evolve dynamically. To address these\nlimitations, we introduce the Progressive Tool retrieval to Improve Planning\n(ProTIP) framework. ProTIP is a lightweight, contrastive learning-based\nframework that implicitly performs TD without the explicit requirement of\nsubtask labels, while simultaneously maintaining subtask-tool atomicity. On the\nToolBench dataset, ProTIP outperforms the ChatGPT task decomposition-based\napproach by a remarkable margin, achieving a 24% improvement in Recall@K=10 for\nTR and a 41% enhancement in tool accuracy for plan generation.\n",
                "链接": "https://arxiv.org/abs/2312.10332"
            },
            {
                "文章ID": "6899",
                "标题": "XAutoML: A Visual Analytics Tool for Understanding and Validating\n  Automated Machine Learning",
                "作者": " Marc-André Zöller,  Waldemar Titov,  Thomas Schlegel,  Marco F. Huber",
                "发布日期": "2023-11-27",
                "摘要": "  In the last ten years, various automated machine learning (AutoM ) systems\nhave been proposed to build end-to-end machine learning (ML) pipelines with\nminimal human interaction. Even though such automatically synthesized ML\npipelines are able to achieve a competitive performance, recent studies have\nshown that users do not trust models constructed by AutoML due to missing\ntransparency of AutoML systems and missing explanations for the constructed ML\npipelines. In a requirements analysis study with 36 domain experts, data\nscientists, and AutoML researchers from different professions with vastly\ndifferent expertise in ML, we collect detailed informational needs for AutoML.\nWe propose XAutoML, an interactive visual analytics tool for explaining\narbitrary AutoML optimization procedures and ML pipelines constructed by\nAutoML. XAutoML combines interactive visualizations with established techniques\nfrom explainable artificial intelligence (XAI) to make the complete AutoML\nprocedure transparent and explainable. By integrating XAutoML with JupyterLab,\nexperienced users can extend the visual analytics with ad-hoc visualizations\nbased on information extracted from XAutoML. We validate our approach in a user\nstudy with the same diverse user group from the requirements analysis. All\nparticipants were able to extract useful information from XAutoML, leading to a\nsignificantly increased understanding of ML pipelines produced by AutoML and\nthe AutoML optimization itself.\n",
                "链接": "https://arxiv.org/abs/2202.11954"
            },
            {
                "文章ID": "98794",
                "标题": "Confucius: Iterative Tool Learning from Introspection Feedback by\n  Easy-to-Difficult Curriculum",
                "作者": " Shen Gao,  Zhengliang Shi,  Minghang Zhu,  Bowen Fang,  Xin Xin,  Pengjie Ren,  Zhumin Chen,  Jun Ma,  Zhaochun Ren",
                "发布日期": "2023-12-22",
                "摘要": "  Augmenting large language models (LLMs) with external tools has emerged as a\npromising approach to extending the capability of LLMs. Although some works\nemploy open-source LLMs for the tool learning task, most of them are trained in\na controlled environment in which LLMs only learn to execute the human-provided\ntools. However, selecting proper tools from the large toolset is also a crucial\nability for the tool learning model to be applied in real-world applications.\nExisting methods usually directly employ self-instruction methods to train the\nmodel, which ignores differences in tool complexity. In this paper, we propose\nthe Confucius, a novel tool learning framework to train LLM to use complicated\ntools in real-world scenarios, which contains two main phases: (1) We first\npropose a multi-stage learning method to teach the LLM to use various tools\nfrom an easy-to-difficult curriculum; (2) thenceforth, we propose the Iterative\nSelf-instruct from Introspective Feedback (ISIF) to dynamically construct the\ndataset to improve the ability to use the complicated tool. Extensive\nexperiments conducted on both controlled and real-world settings demonstrate\nthe superiority of our tool learning framework in the real-world application\nscenarios compared to both tuning-free (e.g. ChatGPT, Claude) and tuning-based\nbaselines (e.g. GPT4Tools).\n",
                "链接": "https://arxiv.org/abs/2308.14034"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下工具评测相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "81656",
                "标题": "The impact and applications of ChatGPT: a systematic review of\n  literature reviews",
                "作者": " Irene S. Gabashvili",
                "发布日期": "2023-05-30",
                "摘要": "  The conversational artificial-intelligence (AI) technology ChatGPT has become\none of the most widely used natural language processing tools. With thousands\nof published papers demonstrating its applications across various industries\nand fields, ChatGPT has sparked significant interest in the research community.\nReviews of primary data have also begun to emerge. An overview of the available\nevidence from multiple reviews and studies could provide further insights,\nminimize redundancy, and identify areas where further research is needed.\nObjective: To evaluate the existing reviews and literature related to ChatGPT's\napplications and its potential impact on different fields by conducting a\nsystematic review of reviews and bibliometric analysis of primary literature.\nMethods: PubMed, EuropePMC, Dimensions AI, medRxiv, bioRxiv, arXiv, and Google\nScholar were searched for ChatGPT-related publications from 2022 to 4/30/2023.\nStudies including secondary data related to the application of ChatGPT were\nconsidered. Reporting and risk of bias assesment was performed using PRISMA\nguidelines. Results: A total of 305 unique records with potential relevance to\nthe review were identified from a pool of over 2,000 original articles. After\nmulti-step screening process, 11 reviews were selected, consisting of 9 reviews\nspecifically focused on ChatGPT and 2 reviews on broader AI topics that also\nincluded discussions on ChatGPT. We also conducted bibliometric analysis of\nprimary data. Conclusions: While AI has the potential to revolutionize various\nindustries, further interdisciplinary research, customized integrations, and\nethical innovation are necessary to address existing concerns and ensure its\nresponsible use. Protocol Registration: PROSPERO registration no.\nCRD42023417336, DOI 10.17605/OSF.IO/87U6Q.\n",
                "链接": "https://arxiv.org/abs/2305.18086"
            },
            {
                "文章ID": "60466",
                "标题": "Can ChatGPT Write a Good Boolean Query for Systematic Review Literature\n  Search?",
                "作者": " Shuai Wang,  Harrisen Scells,  Bevan Koopman,  Guido Zuccon",
                "发布日期": "2023-02-10",
                "摘要": "  Systematic reviews are comprehensive reviews of the literature for a highly\nfocused research question. These reviews are often treated as the highest form\nof evidence in evidence-based medicine, and are the key strategy to answer\nresearch questions in the medical field. To create a high-quality systematic\nreview, complex Boolean queries are often constructed to retrieve studies for\nthe review topic. However, it often takes a long time for systematic review\nresearchers to construct a high quality systematic review Boolean query, and\noften the resulting queries are far from effective. Poor queries may lead to\nbiased or invalid reviews, because they missed to retrieve key evidence, or to\nextensive increase in review costs, because they retrieved too many irrelevant\nstudies. Recent advances in Transformer-based generative models have shown\ngreat potential to effectively follow instructions from users and generate\nanswers based on the instructions being made. In this paper, we investigate the\neffectiveness of the latest of such models, ChatGPT, in generating effective\nBoolean queries for systematic review literature search. Through a number of\nextensive experiments on standard test collections for the task, we find that\nChatGPT is capable of generating queries that lead to high search precision,\nalthough trading-off this for recall. Overall, our study demonstrates the\npotential of ChatGPT in generating effective Boolean queries for systematic\nreview literature search. The ability of ChatGPT to follow complex instructions\nand generate queries with high precision makes it a valuable tool for\nresearchers conducting systematic reviews, particularly for rapid reviews where\ntime is a constraint and often trading-off higher precision for lower recall is\nacceptable.\n",
                "链接": "https://arxiv.org/abs/2302.03495"
            },
            {
                "文章ID": "121615",
                "标题": "Team-related Features in Code Review Prediction Models",
                "作者": " Eduardo Witter,  Ingrid Nunes,  Dietmar Jannach",
                "发布日期": "2023-12-12",
                "摘要": "  Modern Code Review (MCR) is an informal tool-assisted quality assurance\npractice. It relies on the asynchronous communication among the authors of code\nchanges and reviewers, who are developers that provide feedback. However, from\ncandidate developers, some are able to provide better feedback than others\ngiven a particular context. The selection of reviewers is thus an important\ntask, which can benefit from automated support. Many approaches have been\nproposed in this direction, using for example data from code review\nrepositories to recommend reviewers. In this paper, we propose the use of\nteam-related features to improve the performance of predictions that are\nhelpful to build code reviewer recommenders, with our target predictions being\nthe identification of reviewers that would participate in a review and the\nprovided amount of feedback. We evaluate the prediction power of these\nfeatures, which are related to code ownership, workload, and team relationship.\nThis evaluation was done by carefully addressing challenges imposed by the MCR\ndomain, such as temporal aspects of the dataset and unbalanced classes.\nMoreover, given that it is currently unknown how much past data is needed for\nbuilding MCR prediction models with acceptable performance, we explore the\namount of past data used to build prediction models. Our results show that,\nindividually, features related to code ownership have the best prediction\npower. However, based on feature selection, we conclude that all proposed\nfeatures together with lines of code can make the best predictions for both\nreviewer participation and amount of feedback. Regarding the amount of past\ndata, the timeframes of 3, 6, 9, and 12 months of data produce similar results.\nTherefore, models can be trained considering short timeframes, thus reducing\nthe computational costs with negligible impact in the prediction performance\n...\n",
                "链接": "https://arxiv.org/abs/2312.06244"
            },
            {
                "文章ID": "61490",
                "标题": "Relatedly: Scaffolding Literature Reviews with Existing Related Work\n  Sections",
                "作者": " Srishti Palani,  Aakanksha Naik,  Doug Downey,  Amy X. Zhang,  Jonathan Bragg,  Joseph Chee Chang",
                "发布日期": "2023-02-15",
                "摘要": "  Scholars who want to research a scientific topic must take time to read,\nextract meaning, and identify connections across many papers. As scientific\nliterature grows, this becomes increasingly challenging. Meanwhile, authors\nsummarize prior research in papers' related work sections, though this is\nscoped to support a single paper. A formative study found that while reading\nmultiple related work paragraphs helps overview a topic, it is hard to navigate\noverlapping and diverging references and research foci. In this work, we design\na system, Relatedly, that scaffolds exploring and reading multiple related work\nparagraphs on a topic, with features including dynamic re-ranking and\nhighlighting to spotlight unexplored dissimilar information, auto-generated\ndescriptive paragraph headings, and low-lighting of redundant information. From\na within-subjects user study (n=15), we found that scholars generate more\ncoherent, insightful, and comprehensive topic outlines using Relatedly compared\nto a baseline paper list.\n",
                "链接": "https://arxiv.org/abs/2302.06754"
            },
            {
                "文章ID": "81377",
                "标题": "Counterfactual Evaluation of Peer-Review Assignment Policies",
                "作者": " Martin Saveski,  Steven Jecmen,  Nihar B. Shah,  Johan Ugander",
                "发布日期": "2023-05-30",
                "摘要": "  Peer review assignment algorithms aim to match research papers to suitable\nexpert reviewers, working to maximize the quality of the resulting reviews. A\nkey challenge in designing effective assignment policies is evaluating how\nchanges to the assignment algorithm map to changes in review quality. In this\nwork, we leverage recently proposed policies that introduce randomness in\npeer-review assignment--in order to mitigate fraud--as a valuable opportunity\nto evaluate counterfactual assignment policies. Specifically, we exploit how\nsuch randomized assignments provide a positive probability of observing the\nreviews of many assignment policies of interest. To address challenges in\napplying standard off-policy evaluation methods, such as violations of\npositivity, we introduce novel methods for partial identification based on\nmonotonicity and Lipschitz smoothness assumptions for the mapping between\nreviewer-paper covariates and outcomes. We apply our methods to peer-review\ndata from two computer science venues: the TPDP'21 workshop (95 papers and 35\nreviewers) and the AAAI'22 conference (8,450 papers and 3,145 reviewers). We\nconsider estimates of (i) the effect on review quality when changing weights in\nthe assignment algorithm, e.g., weighting reviewers' bids vs. textual\nsimilarity (between the review's past papers and the submission), and (ii) the\n\"cost of randomization\", capturing the difference in expected quality between\nthe perturbed and unperturbed optimal match. We find that placing higher weight\non text similarity results in higher review quality and that introducing\nrandomization in the reviewer-paper assignment only marginally reduces the\nreview quality. Our methods for partial identification may be of independent\ninterest, while our off-policy approach can likely find use evaluating a broad\nclass of algorithmic matching systems.\n",
                "链接": "https://arxiv.org/abs/2305.17339"
            },
            {
                "文章ID": "38047",
                "标题": "PoxVerifi: An Information Verification System to Combat Monkeypox\n  Misinformation",
                "作者": " Akaash Kolluri,  Kami Vinton,  Dhiraj Murthy",
                "发布日期": "2022-09-21",
                "摘要": "  Following recent outbreaks, monkeypox-related misinformation continues to\nrapidly spread online. This negatively impacts response strategies and\ndisproportionately harms LGBTQ+ communities in the short-term, and ultimately\nundermines the overall effectiveness of public health responses. In an attempt\nto combat monkeypox-related misinformation, we present PoxVerifi, an\nopen-source, extensible tool that provides a comprehensive approach to\nassessing the accuracy of monkeypox related claims. Leveraging information from\nexisting fact checking sources and published World Health Organization (WHO)\ninformation, we created an open-sourced corpus of 225 rated monkeypox claims.\nAdditionally, we trained an open-sourced BERT-based machine learning model for\nspecifically classifying monkeypox information, which achieved 96%\ncross-validation accuracy. PoxVerifi is a Google Chrome browser extension\ndesigned to empower users to navigate through monkeypox-related misinformation.\nSpecifically, PoxVerifi provides users with a comprehensive toolkit to assess\nthe veracity of headlines on any webpage across the Internet without having to\nvisit an external site. Users can view an automated accuracy review from our\ntrained machine learning model, a user-generated accuracy review based on\ncommunity-member votes, and have the ability to see similar, vetted, claims.\nBesides PoxVerifi's comprehensive approach to claim-testing, our platform\nprovides an efficient and accessible method to crowdsource accuracy ratings on\nmonkeypox related-claims, which can be aggregated to create new labeled\nmisinformation datasets.\n",
                "链接": "https://arxiv.org/abs/2209.09300"
            },
            {
                "文章ID": "60467",
                "标题": "Sentiment Analysis on YouTube Smart Phone Unboxing Video Reviews in Sri\n  Lanka",
                "作者": " Sherina Sally",
                "发布日期": "2023-02-08",
                "摘要": "  Product-related reviews are based on users' experiences that are mostly\nshared on videos in YouTube. It is the second most popular website globally in\n2021. People prefer to watch videos on recently released products prior to\npurchasing, in order to gather overall feedback and make worthy decisions.\nThese videos are created by vloggers who are enthusiastic about technical\nmaterials and feedback is usually placed by experienced users of the product or\nits brand. Analyzing the sentiment of the user reviews gives useful insights\ninto the product in general. This study is focused on three smartphone reviews,\nnamely, Apple iPhone 13, Google Pixel 6, and Samsung Galaxy S21 which were\nreleased in 2021. VADER, which is a lexicon and rule-based sentiment analysis\ntool was used to classify each comment to its appropriate positive or negative\norientation. All three smartphones show a positive sentiment from the users'\nperspective and iPhone 13 has the highest number of positive reviews. The\nresulting models have been tested using N\\\"aive Bayes, Decision Tree, and\nSupport Vector Machine. Among these three classifiers, Support Vector Machine\nshows higher accuracies and F1-scores.\n",
                "链接": "https://arxiv.org/abs/2302.03496"
            },
            {
                "文章ID": "77346",
                "标题": "Reviewer assignment problem: A scoping review",
                "作者": " Jelena Jovanovic,  Ebrahim Bagheri",
                "发布日期": "2023-05-16",
                "摘要": "  Peer review is an integral component of scientific research. The quality of\npeer review, and consequently the published research, depends to a large extent\non the ability to recruit adequate reviewers for submitted papers. However,\nfinding such reviewers is an increasingly difficult task due to several\nfactors, such as the continuous increase both in the production of scientific\npapers and the workload of scholars. To mitigate these challenges, solutions\nfor automated association of papers with \"well matching\" reviewers - the task\noften referred to as reviewer assignment problem (RAP) - have been the subject\nof research for thirty years now. Even though numerous solutions have been\nsuggested, to our knowledge, a recent systematic synthesis of the RAP-related\nliterature is missing. To fill this gap and support further RAP-related\nresearch, in this paper, we present a scoping review of computational\napproaches for addressing RAP. Following the latest methodological guidance for\nscoping reviews, we have collected recent literature on RAP from three\ndatabases (Scopus, Google Scholar, DBLP) and, after applying the eligibility\ncriteria, retained 26 studies for extracting and synthesising data on several\naspects of RAP research including: i) the overall framing of and approach to\nRAP; ii) the criteria for reviewer selection; iii) the modelling of candidate\nreviewers and submissions; iv) the computational methods for matching reviewers\nand submissions; and v) the methods for evaluating the performance of the\nproposed solutions. The paper summarises and discusses the findings for each of\nthe aforementioned aspects of RAP research and suggests future research\ndirections.\n",
                "链接": "https://arxiv.org/abs/2305.07887"
            },
            {
                "文章ID": "84645",
                "标题": "ToolAlpaca: Generalized Tool Learning for Language Models with 3000\n  Simulated Cases",
                "作者": " Qiaoyu Tang,  Ziliang Deng,  Hongyu Lin,  Xianpei Han,  Qiao Liang,  Boxi Cao,  Le Sun",
                "发布日期": "2023-09-08",
                "摘要": "  Enabling large language models to utilize real-world tools effectively is\ncrucial for achieving embodied intelligence. Existing approaches to tool\nlearning have either primarily relied on extremely large language models, such\nas GPT-4, to attain generalized tool-use abilities in a zero-shot manner, or\nutilized supervised learning to train limited scopes of tools on compact\nmodels. However, it remains uncertain whether smaller language models can\nachieve generalized tool-use abilities without tool-specific training. To\naddress this question, this paper introduces ToolAlpaca, a novel framework\ndesigned to automatically generate a diverse tool-use corpus and learn\ngeneralized tool-use abilities on compact language models with minimal human\nintervention. Specifically, ToolAlpaca first automatically creates a highly\ndiversified tool-use corpus by building a multi-agent simulation environment.\nThe corpus contains 3938 tool-use instances from more than 400 real-world tool\nAPIs spanning 50 distinct categories. Subsequently, the constructed corpus is\nemployed to fine-tune compact language models, resulting in two models, namely\nToolAlpaca-7B and ToolAlpaca-13B, respectively. Finally, we evaluate the\nability of these models to utilize previously unseen tools without specific\ntraining. Experimental results demonstrate that ToolAlpaca achieves effective\ngeneralized tool-use capabilities comparable to those of extremely large\nlanguage models like GPT-3.5, demonstrating that learning generalized tool-use\nability is feasible for compact language models.\n",
                "链接": "https://arxiv.org/abs/2306.05301"
            },
            {
                "文章ID": "88345",
                "标题": "More efficient manual review of automatically transcribed tabular data",
                "作者": " Bjørn-Richard Pedersen,  Rigmor Katrine Johansen,  Einar Holsbø,  Hilde Sommerseth,  Lars Ailo Bongo",
                "发布日期": "2023-06-29",
                "摘要": "  Machine learning methods have proven useful in transcribing historical data.\nHowever, results from even highly accurate methods require manual verification\nand correction. Such manual review can be time-consuming and expensive,\ntherefore the objective of this paper was to make it more efficient.\nPreviously, we used machine learning to transcribe 2.3 million handwritten\noccupation codes from the Norwegian 1950 census with high accuracy (97%). We\nmanually reviewed the 90,000 (3%) codes with the lowest model confidence. We\nallocated those 90,000 codes to human reviewers, who used our annotation tool\nto review the codes. To assess reviewer agreement, some codes were assigned to\nmultiple reviewers. We then analyzed the review results to understand the\nrelationship between accuracy improvements and effort. Additionally, we\ninterviewed the reviewers to improve the workflow. The reviewers corrected\n62.8% of the labels and agreed with the model label in 31.9% of cases. About\n0.2% of the images could not be assigned a label, while for 5.1% the reviewers\nwere uncertain, or they assigned an invalid label. 9,000 images were\nindependently reviewed by multiple reviewers, resulting in an agreement of\n86.43% and disagreement of 8.96%. We learned that our automatic transcription\nis biased towards the most frequent codes, with a higher degree of\nmisclassification for the lowest frequency codes. Our interview findings show\nthat the reviewers did internal quality control and found our custom tool\nwell-suited. So, only one reviewer is needed, but they should report\nuncertainty.\n",
                "链接": "https://arxiv.org/abs/2306.16126"
            }
        ]
    },
    {
        "question": {
            "question": "大模型在游戏方面的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "75161",
                "标题": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
                "作者": " Eddie Guo,  Mehul Gupta,  Jiawen Deng,  Ye-Jean Park,  Mike Paget,  Christopher Naugler",
                "发布日期": "2023-10-09",
                "摘要": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
                "链接": "https://arxiv.org/abs/2305.00844"
            },
            {
                "文章ID": "106983",
                "标题": "Kawaii Game Vocalics: A Preliminary Model",
                "作者": " Katie Seaborn,  Katja Rogers,  Somang Name,  Miu Kojima",
                "发布日期": "2023-10-10",
                "摘要": "  Kawaii is the Japanese concept of cute++, a global export with local\ncharacteristics. Recent work has explored kawaii as a feature of user\nexperience (UX) with social robots, virtual characters, and voice assistants,\ni.e., kawaii vocalics. Games have a long history of incorporating characters\nthat use voice as a means of expressing kawaii. Nevertheless, no work to date\nhas evaluated kawaii game voices or mapped out a model of kawaii game vocalics.\nIn this work, we explored whether and how a model of kawaii vocalics maps onto\ngame character voices. We conducted an online perceptions study (N=157) using\n18 voices from kawaii characters in Japanese games. We replicated the results\nfor computer voice and discovered nuanced relationships between gender and age,\nespecially youthfulness, agelessness, gender ambiguity, and gender neutrality.\nWe provide our initial model and advocate for future work on character visuals\nand within play contexts.\n",
                "链接": "https://arxiv.org/abs/2310.04731"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            },
            {
                "文章ID": "117394",
                "标题": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
                "作者": " Chengyu Wang,  Junbing Yan,  Wei Zhang,  Jun Huang",
                "发布日期": "2023-11-23",
                "摘要": "  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.13126"
            },
            {
                "文章ID": "121257",
                "标题": "GlitchBench: Can large multimodal models detect video game glitches?",
                "作者": " Mohammad Reza Taesiri,  Tianjun Feng,  Cor-Paul Bezemer,  Anh Nguyen",
                "发布日期": "2023-12-12",
                "摘要": "  Large multimodal models (LMMs) have evolved from large language models (LLMs)\nto integrate multiple input modalities, such as visual inputs. This integration\naugments the capacity of LLMs for tasks requiring visual comprehension and\nreasoning. However, the extent and limitations of their enhanced abilities are\nnot fully understood, especially when it comes to real-world tasks. To address\nthis gap, we introduce GlitchBench, a novel benchmark derived from video game\nquality assurance tasks, to test and evaluate the reasoning capabilities of\nLMMs. Our benchmark is curated from a variety of unusual and glitched scenarios\nfrom video games and aims to challenge both the visual and linguistic reasoning\npowers of LMMs in detecting and interpreting out-of-the-ordinary events. We\nevaluate multiple state-of-the-art LMMs, and we show that GlitchBench presents\na new challenge for these models. Code and data are available at:\nhttps://glitchbench.github.io/\n",
                "链接": "https://arxiv.org/abs/2312.05291"
            },
            {
                "文章ID": "75237",
                "标题": "Multidimensional Fairness in Paper Recommendation",
                "作者": " Reem Alsaffar,  Susan Gauch,  Hiba Al-Kawaz",
                "发布日期": "2023-05-05",
                "摘要": "  To prevent potential bias in the paper review and selection process for\nconferences and journals, most include double blind review. Despite this,\nstudies show that bias still exists. Recommendation algorithms for paper review\nalso may have implicit bias. We offer three fair methods that specifically take\ninto account author diversity in paper recommendation to address this. Our\nmethods provide fair outcomes across many protected variables concurrently, in\ncontrast to typical fair algorithms that only use one protected variable. Five\ndemographic characteristics-gender, ethnicity, career stage, university rank,\nand geolocation-are included in our multidimensional author profiles. The\nOverall Diversity approach uses a score for overall diversity to rank\npublications. The Round Robin Diversity technique chooses papers from authors\nwho are members of each protected group in turn, whereas the Multifaceted\nDiversity method chooses papers that initially fill the demographic feature\nwith the highest importance. We compare the effectiveness of author diversity\nprofiles based on Boolean and continuous-valued features. By selecting papers\nfrom a pool of SIGCHI 2017, DIS 2017, and IUI 2017 papers, we recommend papers\nfor SIGCHI 2017 and evaluate these algorithms using the user profiles. We\ncontrast the papers that were recommended with those that were selected by the\nconference. We find that utilizing profiles with either Boolean or continuous\nfeature values, all three techniques boost diversity while just slightly\ndecreasing utility or not decreasing. By choosing authors who are 42.50% more\ndiverse and with a 2.45% boost in utility, our best technique, Multifaceted\nDiversity, suggests a set of papers that match demographic parity. The\nselection of grant proposals, conference papers, journal articles, and other\nacademic duties might all use this strategy.\n",
                "链接": "https://arxiv.org/abs/2305.01141"
            },
            {
                "文章ID": "104212",
                "标题": "Prediction Model For Wordle Game Results With High Robustness",
                "作者": " Jiaqi Weng,  Chunlin Feng",
                "发布日期": "2023-09-26",
                "摘要": "  In this study, we delve into the dynamics of Wordle using data analysis and\nmachine learning. Our analysis initially focused on the correlation between the\ndate and the number of submitted results. Due to initial popularity bias, we\nmodeled stable data using an ARIMAX model with coefficient values of 9, 0, 2,\nand weekdays/weekends as the exogenous variable. We found no significant\nrelationship between word attributes and hard mode results.\n  To predict word difficulty, we employed a Backpropagation Neural Network,\novercoming overfitting via feature engineering. We also used K-means\nclustering, optimized at five clusters, to categorize word difficulty\nnumerically. Our findings indicate that on March 1st, 2023, around 12,884\nresults will be submitted and the word \"eerie\" averages 4.8 attempts, falling\ninto the hardest difficulty cluster.\n  We further examined the percentage of loyal players and their propensity to\nundertake daily challenges. Our models underwent rigorous sensitivity analyses,\nincluding ADF, ACF, PACF tests, and cross-validation, confirming their\nrobustness. Overall, our study provides a predictive framework for Wordle\ngameplay based on date or a given five-letter word. Results have been\nsummarized and submitted to the Puzzle Editor of the New York Times.\n",
                "链接": "https://arxiv.org/abs/2309.14250"
            },
            {
                "文章ID": "108644",
                "标题": "The Consensus Game: Language Model Generation via Equilibrium Search",
                "作者": " Athul Paul Jacob,  Yikang Shen,  Gabriele Farina,  Jacob Andreas",
                "发布日期": "2023-10-16",
                "摘要": "  When applied to question answering and other text generation tasks, language\nmodels (LMs) may be queried generatively (by sampling answers from their output\ndistribution) or discriminatively (by using them to score or rank a set of\ncandidate outputs). These procedures sometimes yield very different\npredictions. How do we reconcile mutually incompatible scoring procedures to\nobtain coherent LM predictions? We introduce a new, a training-free,\ngame-theoretic procedure for language model decoding. Our approach casts\nlanguage model decoding as a regularized imperfect-information sequential\nsignaling game - which we term the CONSENSUS GAME - in which a GENERATOR seeks\nto communicate an abstract correctness parameter using natural language\nsentences to a DISCRIMINATOR. We develop computational procedures for finding\napproximate equilibria of this game, resulting in a decoding algorithm we call\nEQUILIBRIUM-RANKING. Applied to a large number of tasks (including reading\ncomprehension, commonsense reasoning, mathematical problem-solving, and\ndialog), EQUILIBRIUM-RANKING consistently, and sometimes substantially,\nimproves performance over existing LM decoding procedures - on multiple\nbenchmarks, we observe that applying EQUILIBRIUM-RANKING to LLaMA-7B\noutperforms the much larger LLaMA-65B and PaLM-540B models. These results\nhighlight the promise of game-theoretic tools for addressing fundamental\nchallenges of truthfulness and consistency in LMs.\n",
                "链接": "https://arxiv.org/abs/2310.09139"
            },
            {
                "文章ID": "101477",
                "标题": "Strategic Behavior of Large Language Models: Game Structure vs.\n  Contextual Framing",
                "作者": " Nunzio Lorè,  Babak Heydari",
                "发布日期": "2023-09-13",
                "摘要": "  This paper investigates the strategic decision-making capabilities of three\nLarge Language Models (LLMs): GPT-3.5, GPT-4, and LLaMa-2, within the framework\nof game theory. Utilizing four canonical two-player games -- Prisoner's\nDilemma, Stag Hunt, Snowdrift, and Prisoner's Delight -- we explore how these\nmodels navigate social dilemmas, situations where players can either cooperate\nfor a collective benefit or defect for individual gain. Crucially, we extend\nour analysis to examine the role of contextual framing, such as diplomatic\nrelations or casual friendships, in shaping the models' decisions. Our findings\nreveal a complex landscape: while GPT-3.5 is highly sensitive to contextual\nframing, it shows limited ability to engage in abstract strategic reasoning.\nBoth GPT-4 and LLaMa-2 adjust their strategies based on game structure and\ncontext, but LLaMa-2 exhibits a more nuanced understanding of the games'\nunderlying mechanics. These results highlight the current limitations and\nvaried proficiencies of LLMs in strategic decision-making, cautioning against\ntheir unqualified use in tasks requiring complex strategic reasoning.\n",
                "链接": "https://arxiv.org/abs/2309.05898"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "117885",
                "标题": "Decoding Social Sentiment in DAO: A Comparative Analysis of Blockchain\n  Governance Communities",
                "作者": " Yutong Quan,  Xintong Wu,  Wanlin Deng,  Luyao Zhang",
                "发布日期": "2023-11-30",
                "摘要": "  Blockchain technology is leading a revolutionary transformation across\ndiverse industries, with effective governance standing as a critical\ndeterminant for the success and sustainability of blockchain projects.\nCommunity forums, pivotal in engaging decentralized autonomous organizations\n(DAOs), wield a substantial impact on blockchain governance decisions.\nConcurrently, Natural Language Processing (NLP), particularly sentiment\nanalysis, provides powerful insights from textual data. While prior research\nhas explored the potential of NLP tools in social media sentiment analysis, a\ngap persists in understanding the sentiment landscape of blockchain governance\ncommunities. The evolving discourse and sentiment dynamics on the forums of top\nDAOs remain largely unknown. This paper delves deep into the evolving discourse\nand sentiment dynamics on the public forums of leading DeFi projects -- Aave,\nUniswap, Curve Dao, Aragon, Yearn.finance, Merit Circle, and Balancer --\nplacing a primary focus on discussions related to governance issues. Despite\ndiffering activity patterns, participants across these decentralized\ncommunities consistently express positive sentiments in their Discord\ndiscussions, indicating optimism towards governance decisions. Additionally,\nour research suggests a potential interplay between discussion intensity and\nsentiment dynamics, indicating that higher discussion volumes may contribute to\nmore stable and positive emotions. The insights gained from this study are\nvaluable for decision-makers in blockchain governance, underscoring the pivotal\nrole of sentiment analysis in interpreting community emotions and its evolving\nimpact on the landscape of blockchain governance. This research significantly\ncontributes to the interdisciplinary exploration of the intersection of\nblockchain and society, with a specific emphasis on the decentralized\nblockchain governance ecosystem.\n",
                "链接": "https://arxiv.org/abs/2311.14676"
            },
            {
                "文章ID": "109426",
                "标题": "EEG motor imagery decoding: A framework for comparative analysis with\n  channel attention mechanisms",
                "作者": " Martin Wimpff,  Leonardo Gizzi,  Jan Zerfowski,  Bin Yang",
                "发布日期": "2023-10-18",
                "摘要": "  The objective of this study is to investigate the application of various\nchannel attention mechanisms within the domain of brain-computer interface\n(BCI) for motor imagery decoding. Channel attention mechanisms can be seen as a\npowerful evolution of spatial filters traditionally used for motor imagery\ndecoding. This study systematically compares such mechanisms by integrating\nthem into a lightweight architecture framework to evaluate their impact. We\ncarefully construct a straightforward and lightweight baseline architecture\ndesigned to seamlessly integrate different channel attention mechanisms. This\napproach is contrary to previous works which only investigate one attention\nmechanism and usually build a very complex, sometimes nested architecture. Our\nframework allows us to evaluate and compare the impact of different attention\nmechanisms under the same circumstances. The easy integration of different\nchannel attention mechanisms as well as the low computational complexity\nenables us to conduct a wide range of experiments on three datasets to\nthoroughly assess the effectiveness of the baseline model and the attention\nmechanisms. Our experiments demonstrate the strength and generalizability of\nour architecture framework as well as how channel attention mechanisms can\nimprove the performance while maintaining the small memory footprint and low\ncomputational complexity of our baseline architecture. Our architecture\nemphasizes simplicity, offering easy integration of channel attention\nmechanisms, while maintaining a high degree of generalizability across\ndatasets, making it a versatile and efficient solution for EEG motor imagery\ndecoding within brain-computer interfaces.\n",
                "链接": "https://arxiv.org/abs/2310.11198"
            },
            {
                "文章ID": "50906",
                "标题": "Fine-tuned Sentiment Analysis of COVID-19 Vaccine-Related Social Media\n  Data: Comparative Study",
                "作者": " Chad A Melton,  Brianna M White,  Robert L Davis,  Robert A Bednarczyk,  Arash Shaban-Nejad",
                "发布日期": "2022-11-29",
                "摘要": "  This study investigated and compared public sentiment related to COVID-19\nvaccines expressed on two popular social media platforms, Reddit and Twitter,\nharvested from January 1, 2020, to March 1, 2022. To accomplish this task, we\ncreated a fine-tuned DistilRoBERTa model to predict sentiments of approximately\n9.5 million Tweets and 70 thousand Reddit comments. To fine-tune our model, our\nteam manually labeled the sentiment of 3600 Tweets and then augmented our\ndataset by the method of back-translation. Text sentiment for each social media\nplatform was then classified with our fine-tuned model using Python and the\nHuggingface sentiment analysis pipeline. Our results determined that the\naverage sentiment expressed on Twitter was more negative (52% positive) than\npositive and the sentiment expressed on Reddit was more positive than negative\n(53% positive). Though average sentiment was found to vary between these social\nmedia platforms, both displayed similar behavior related to sentiment shared at\nkey vaccine-related developments during the pandemic. Considering this similar\ntrend in shared sentiment demonstrated across social media platforms, Twitter\nand Reddit continue to be valuable data sources that public health officials\ncan utilize to strengthen vaccine confidence and combat misinformation. As the\nspread of misinformation poses a range of psychological and psychosocial risks\n(anxiety, fear, etc.), there is an urgency in understanding the public\nperspective and attitude toward shared falsities. Comprehensive educational\ndelivery systems tailored to the population's expressed sentiments that\nfacilitate digital literacy, health information-seeking behavior, and precision\nhealth promotion could aid in clarifying such misinformation.\n",
                "链接": "https://arxiv.org/abs/2211.15407"
            },
            {
                "文章ID": "95351",
                "标题": "Auditory Attention Decoding with Task-Related Multi-View Contrastive\n  Learning",
                "作者": " Xiaoyu Chen,  Changde Du,  Qiongyi Zhou,  Huiguang He",
                "发布日期": "2023-08-09",
                "摘要": "  The human brain can easily focus on one speaker and suppress others in\nscenarios such as a cocktail party. Recently, researchers found that auditory\nattention can be decoded from the electroencephalogram (EEG) data. However,\nmost existing deep learning methods are difficult to use prior knowledge of\ndifferent views (that is attended speech and EEG are task-related views) and\nextract an unsatisfactory representation. Inspired by Broadbent's filter model,\nwe decode auditory attention in a multi-view paradigm and extract the most\nrelevant and important information utilizing the missing view. Specifically, we\npropose an auditory attention decoding (AAD) method based on multi-view VAE\nwith task-related multi-view contrastive (TMC) learning. Employing TMC learning\nin multi-view VAE can utilize the missing view to accumulate prior knowledge of\ndifferent views into the fusion of representation, and extract the approximate\ntask-related representation. We examine our method on two popular AAD datasets,\nand demonstrate the superiority of our method by comparing it to the\nstate-of-the-art method.\n",
                "链接": "https://arxiv.org/abs/2308.04244"
            },
            {
                "文章ID": "24473",
                "标题": "An analysis of retracted papers in Computer Science",
                "作者": " Martin Shepperd,  Leila Yousefi",
                "发布日期": "2023-07-19",
                "摘要": "  Context: The retraction of research papers, for whatever reason, is a growing\nphenomenon. However, although retracted paper information is publicly available\nvia publishers, it is somewhat distributed and inconsistent. Objective: The aim\nis to assess: (i) the extent and nature of retracted research in Computer\nScience (CS) (ii) the post-retraction citation behaviour of retracted works and\n(iii) the potential impact on systematic reviews and mapping studies. Method:\nWe analyse the Retraction Watch database and take citation information from the\nWeb of Science and Google scholar. Results: We find that of the 33,955 entries\nin the Retraction watch database (16 May 2022), 2,816 are classified as CS,\ni.e., approximately 8.3%. For CS, 56% of retracted papers, provide little or no\ninformation as to the reasons. This contrasts with 26% for other disciplines.\nThere is also a remarkable disparity between different publishers, a tendency\nfor multiple versions of a retracted paper over and above the Version of Record\n(VoR), and for new citations long after a paper is officially retracted.\nConclusions: Unfortunately retraction seems to be a sufficiently common outcome\nfor a scientific paper that we as a research community need to take it more\nseriously, e.g., standardising procedures and taxonomies across publishers and\nthe provision of appropriate research tools. Finally, we recommend particular\ncaution when undertaking secondary analyses and meta-analyses which are at risk\nof becoming contaminated by these problem primary studies.\n",
                "链接": "https://arxiv.org/abs/2206.06706"
            },
            {
                "文章ID": "19141",
                "标题": "Sentiment Analysis of Covid-related Reddits",
                "作者": " Yilin Yang,  Tomas Fieg,  Marina Sokolova",
                "发布日期": "2022-05-17",
                "摘要": "  This paper focuses on Sentiment Analysis of Covid-19 related messages from\nthe r/Canada and r/Unitedkingdom subreddits of Reddit. We apply manual\nannotation and three Machine Learning algorithms to analyze sentiments conveyed\nin those messages. We use VADER and TextBlob to label messages for Machine\nLearning experiments. Our results show that removal of shortest and longest\nmessages improves VADER and TextBlob agreement on positive sentiments and\nF-score of sentiment classification by all the three algorithms\n",
                "链接": "https://arxiv.org/abs/2205.06863"
            },
            {
                "文章ID": "95084",
                "标题": "Deepfake Detection: A Comparative Analysis",
                "作者": " Sohail Ahmed Khan,  Duc-Tien Dang-Nguyen",
                "发布日期": "2023-08-08",
                "摘要": "  This paper present a comprehensive comparative analysis of supervised and\nself-supervised models for deepfake detection. We evaluate eight supervised\ndeep learning architectures and two transformer-based models pre-trained using\nself-supervised strategies (DINO, CLIP) on four benchmarks (FakeAVCeleb,\nCelebDF-V2, DFDC, and FaceForensics++). Our analysis includes intra-dataset and\ninter-dataset evaluations, examining the best performing models, generalisation\ncapabilities, and impact of augmentations. We also investigate the trade-off\nbetween model size and performance. Our main goal is to provide insights into\nthe effectiveness of different deep learning architectures (transformers,\nCNNs), training strategies (supervised, self-supervised), and deepfake\ndetection benchmarks. These insights can help guide the development of more\naccurate and reliable deepfake detection systems, which are crucial in\nmitigating the harmful impact of deepfakes on individuals and society.\n",
                "链接": "https://arxiv.org/abs/2308.03471"
            },
            {
                "文章ID": "93199",
                "标题": "Comparative Analysis of Libraries for the Sentimental Analysis",
                "作者": " Wendy Ccoya,  Edson Pinto",
                "发布日期": "2023-07-27",
                "摘要": "  This study is main goal is to provide a comparative comparison of libraries\nusing machine learning methods. Experts in natural language processing (NLP)\nare becoming more and more interested in sentiment analysis (SA) of text\nchanges. The objective of employing NLP text analysis techniques is to\nrecognize and categorize feelings related to twitter users utterances. In this\nexamination, issues with SA and the libraries utilized are also looked at.\nprovides a number of cooperative methods to classify emotional polarity. The\nNaive Bayes Classifier, Decision Tree Classifier, Maxent Classifier, Sklearn\nClassifier, Sklearn Classifier MultinomialNB, and other conjoint learning\nalgorithms, according to recent research, are very effective. In the project\nwill use Five Python and R libraries NLTK, TextBlob, Vader, Transformers (GPT\nand BERT pretrained), and Tidytext will be used in the study to apply sentiment\nanalysis techniques. Four machine learning models Tree of Decisions (DT),\nSupport Vector Machine (SVM), Naive Bayes (NB), and K-Nearest Neighbor (KNN)\nwill also be used. To evaluate how well libraries for SA operate in the social\nnetwork environment, comparative study was also carried out. The measures to\nassess the best algorithms in this experiment, which used a single data set for\neach method, were precision, recall, and F1 score. We conclude that the BERT\ntransformer method with an Accuracy: 0.973 is recommended for sentiment\nanalysis.\n",
                "链接": "https://arxiv.org/abs/2307.14311"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "91711",
                "标题": "A comparative analysis of SRGAN models",
                "作者": " Fatemeh Rezapoor Nikroo,  Ajinkya Deshmukh,  Anantha Sharma,  Adrian Tam,  Kaarthik Kumar,  Cleo Norris,  Aditya Dangi",
                "发布日期": "2023-07-20",
                "摘要": "  In this study, we evaluate the performance of multiple state-of-the-art SRGAN\n(Super Resolution Generative Adversarial Network) models, ESRGAN, Real-ESRGAN\nand EDSR, on a benchmark dataset of real-world images which undergo degradation\nusing a pipeline. Our results show that some models seem to significantly\nincrease the resolution of the input images while preserving their visual\nquality, this is assessed using Tesseract OCR engine. We observe that EDSR-BASE\nmodel from huggingface outperforms the remaining candidate models in terms of\nboth quantitative metrics and subjective visual quality assessments with least\ncompute overhead. Specifically, EDSR generates images with higher peak\nsignal-to-noise ratio (PSNR) and structural similarity index (SSIM) values and\nare seen to return high quality OCR results with Tesseract OCR engine. These\nfindings suggest that EDSR is a robust and effective approach for single-image\nsuper-resolution and may be particularly well-suited for applications where\nhigh-quality visual fidelity is critical and optimized compute.\n",
                "链接": "https://arxiv.org/abs/2307.09456"
            }
        ]
    },
    {
        "question": {
            "question": "请找到缓和噪声标签影响的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "48397",
                "标题": "Quantifying the Impact of Label Noise on Federated Learning",
                "作者": " Shuqi Ke,  Chao Huang,  Xin Liu",
                "发布日期": "2023-04-04",
                "摘要": "  Federated Learning (FL) is a distributed machine learning paradigm where\nclients collaboratively train a model using their local (human-generated)\ndatasets. While existing studies focus on FL algorithm development to tackle\ndata heterogeneity across clients, the important issue of data quality (e.g.,\nlabel noise) in FL is overlooked. This paper aims to fill this gap by providing\na quantitative study on the impact of label noise on FL. We derive an upper\nbound for the generalization error that is linear in the clients' label noise\nlevel. Then we conduct experiments on MNIST and CIFAR-10 datasets using various\nFL algorithms. Our empirical results show that the global model accuracy\nlinearly decreases as the noise level increases, which is consistent with our\ntheoretical analysis. We further find that label noise slows down the\nconvergence of FL training, and the global model tends to overfit when the\nnoise level is high.\n",
                "链接": "https://arxiv.org/abs/2211.07816"
            },
            {
                "文章ID": "88300",
                "标题": "Systematic analysis of the impact of label noise correction on ML\n  Fairness",
                "作者": " I. Oliveira e Silva,  C. Soares,  I. Sousa,  R. Ghani",
                "发布日期": "2023-06-29",
                "摘要": "  Arbitrary, inconsistent, or faulty decision-making raises serious concerns,\nand preventing unfair models is an increasingly important challenge in Machine\nLearning. Data often reflect past discriminatory behavior, and models trained\non such data may reflect bias on sensitive attributes, such as gender, race, or\nage. One approach to developing fair models is to preprocess the training data\nto remove the underlying biases while preserving the relevant information, for\nexample, by correcting biased labels. While multiple label noise correction\nmethods are available, the information about their behavior in identifying\ndiscrimination is very limited. In this work, we develop an empirical\nmethodology to systematically evaluate the effectiveness of label noise\ncorrection techniques in ensuring the fairness of models trained on biased\ndatasets. Our methodology involves manipulating the amount of label noise and\ncan be used with fairness benchmarks but also with standard ML datasets. We\napply the methodology to analyze six label noise correction methods according\nto several fairness metrics on standard OpenML datasets. Our results suggest\nthat the Hybrid Label Noise Correction method achieves the best trade-off\nbetween predictive performance and fairness. Clustering-Based Correction can\nreduce discrimination the most, however, at the cost of lower predictive\nperformance.\n",
                "链接": "https://arxiv.org/abs/2306.15994"
            },
            {
                "文章ID": "111388",
                "标题": "Label Propagation for Graph Label Noise",
                "作者": " Yao Cheng,  Caihua Shan,  Yifei Shen,  Xiang Li,  Siqiang Luo,  Dongsheng Li",
                "发布日期": "2023-10-26",
                "摘要": "  Label noise is a common challenge in large datasets, as it can significantly\ndegrade the generalization ability of deep neural networks. Most existing\nstudies focus on noisy labels in computer vision; however, graph models\nencompass both node features and graph topology as input, and become more\nsusceptible to label noise through message-passing mechanisms. Recently, only a\nfew works have been proposed to tackle the label noise on graphs. One major\nlimitation is that they assume the graph is homophilous and the labels are\nsmoothly distributed. Nevertheless, real-world graphs may contain varying\ndegrees of heterophily or even be heterophily-dominated, leading to the\ninadequacy of current methods. In this paper, we study graph label noise in the\ncontext of arbitrary heterophily, with the aim of rectifying noisy labels and\nassigning labels to previously unlabeled nodes. We begin by conducting two\nempirical analyses to explore the impact of graph homophily on graph label\nnoise. Following observations, we propose a simple yet efficient algorithm,\ndenoted as LP4GLN. Specifically, LP4GLN is an iterative algorithm with three\nsteps: (1) reconstruct the graph to recover the homophily property, (2) utilize\nlabel propagation to rectify the noisy labels, (3) select high-confidence\nlabels to retain for the next iteration. By iterating these steps, we obtain a\nset of correct labels, ultimately achieving high accuracy in the node\nclassification task. The theoretical analysis is also provided to demonstrate\nits remarkable denoising \"effect\". Finally, we conduct experiments on 10\nbenchmark datasets under varying graph heterophily levels and noise types,\ncomparing the performance of LP4GLN with 7 typical baselines. Our results\nillustrate the superior performance of the proposed LP4GLN.\n",
                "链接": "https://arxiv.org/abs/2310.16560"
            },
            {
                "文章ID": "33646",
                "标题": "Investigating the Impact of Model Width and Density on Generalization in\n  Presence of Label Noise",
                "作者": " Yihao Xue,  Kyle Whitecross,  Baharan Mirzasoleiman",
                "发布日期": "2023-06-16",
                "摘要": "  Increasing the size of overparameterized neural networks has been a key in\nachieving state-of-the-art performance. This is captured by the double descent\nphenomenon, where the test loss follows a decreasing-increasing-decreasing\npattern as model width increases. However, the effect of label noise on the\ntest loss curve has not been fully explored. In this work, we uncover an\nintriguing phenomenon where label noise leads to a \\textit{final ascent} in the\noriginally observed double descent curve. Specifically, under a sufficiently\nlarge noise-to-sample-size ratio, optimal generalization is achieved at\nintermediate widths. Through theoretical analysis, we attribute this phenomenon\nto the shape transition of test loss variance induced by label noise.\nFurthermore, we extend the final ascent phenomenon to model density and provide\nthe first theoretical characterization showing that reducing density by\nrandomly dropping trainable parameters improves generalization under label\nnoise. We also thoroughly examine the roles of regularization and sample size.\nSurprisingly, we find that larger $\\ell_2$ regularization and robust learning\nmethods against label noise exacerbate the final ascent. We confirm the\nvalidity of our findings through extensive experiments on ReLu networks trained\non MNIST, ResNets trained on CIFAR-10/100, and InceptionResNet-v2 trained on\nStanford Cars with real-world noisy labels.\n",
                "链接": "https://arxiv.org/abs/2208.08003"
            },
            {
                "文章ID": "94423",
                "标题": "Feature Noise Boosts DNN Generalization under Label Noise",
                "作者": " Lu Zeng,  Xuan Chen,  Xiaoshuang Shi,  Heng Tao Shen",
                "发布日期": "2023-08-04",
                "摘要": "  The presence of label noise in the training data has a profound impact on the\ngeneralization of deep neural networks (DNNs). In this study, we introduce and\ntheoretically demonstrate a simple feature noise method, which directly adds\nnoise to the features of training data, can enhance the generalization of DNNs\nunder label noise. Specifically, we conduct theoretical analyses to reveal that\nlabel noise leads to weakened DNN generalization by loosening the PAC-Bayes\ngeneralization bound, and feature noise results in better DNN generalization by\nimposing an upper bound on the mutual information between the model weights and\nthe features, which constrains the PAC-Bayes generalization bound. Furthermore,\nto ensure effective generalization of DNNs in the presence of label noise, we\nconduct application analyses to identify the optimal types and levels of\nfeature noise to add for obtaining desirable label noise generalization.\nFinally, extensive experimental results on several popular datasets demonstrate\nthe feature noise method can significantly enhance the label noise\ngeneralization of the state-of-the-art label noise method.\n",
                "链接": "https://arxiv.org/abs/2308.01609"
            },
            {
                "文章ID": "92847",
                "标题": "Label Noise: Correcting a Correction",
                "作者": " William Toner,  Amos Storkey",
                "发布日期": "2023-07-26",
                "摘要": "  Training neural network classifiers on datasets with label noise poses a risk\nof overfitting them to the noisy labels. To address this issue, researchers\nhave explored alternative loss functions that aim to be more robust. However,\nmany of these alternatives are heuristic in nature and still vulnerable to\noverfitting or underfitting. In this work, we propose a more direct approach to\ntackling overfitting caused by label noise. We observe that the presence of\nlabel noise implies a lower bound on the noisy generalised risk. Building upon\nthis observation, we propose imposing a lower bound on the empirical risk\nduring training to mitigate overfitting. Our main contribution is providing\ntheoretical results that yield explicit, easily computable bounds on the\nminimum achievable noisy risk for different loss functions. We empirically\ndemonstrate that using these bounds significantly enhances robustness in\nvarious settings, with virtually no additional computational cost.\n",
                "链接": "https://arxiv.org/abs/2307.13100"
            },
            {
                "文章ID": "8323",
                "标题": "Learning from Label Proportions by Learning with Label Noise",
                "作者": " Jianxin Zhang,  Yutong Wang,  Clayton Scott",
                "发布日期": "2023-09-26",
                "摘要": "  Learning from label proportions (LLP) is a weakly supervised classification\nproblem where data points are grouped into bags, and the label proportions\nwithin each bag are observed instead of the instance-level labels. The task is\nto learn a classifier to predict the individual labels of future individual\ninstances. Prior work on LLP for multi-class data has yet to develop a\ntheoretically grounded algorithm. In this work, we provide a theoretically\ngrounded approach to LLP based on a reduction to learning with label noise,\nusing the forward correction (FC) loss of \\citet{Patrini2017MakingDN}. We\nestablish an excess risk bound and generalization error analysis for our\napproach, while also extending the theory of the FC loss which may be of\nindependent interest. Our approach demonstrates improved empirical performance\nin deep learning scenarios across multiple datasets and architectures, compared\nto the leading existing methods.\n",
                "链接": "https://arxiv.org/abs/2203.02496"
            },
            {
                "文章ID": "83903",
                "标题": "Binary Classification with Instance and Label Dependent Label Noise",
                "作者": " Hyungki Im,  Paul Grigas",
                "发布日期": "2023-06-07",
                "摘要": "  Learning with label dependent label noise has been extensively explored in\nboth theory and practice; however, dealing with instance (i.e., feature) and\nlabel dependent label noise continues to be a challenging task. The difficulty\narises from the fact that the noise rate varies for each instance, making it\nchallenging to estimate accurately. The question of whether it is possible to\nlearn a reliable model using only noisy samples remains unresolved. We answer\nthis question with a theoretical analysis that provides matching upper and\nlower bounds. Surprisingly, our results show that, without any additional\nassumptions, empirical risk minimization achieves the optimal excess risk\nbound. Specifically, we derive a novel excess risk bound proportional to the\nnoise level, which holds in very general settings, by comparing the empirical\nrisk minimizers obtained from clean samples and noisy samples. Second, we show\nthat the minimax lower bound for the 0-1 loss is a constant proportional to the\naverage noise rate. Our findings suggest that learning solely with noisy\nsamples is impossible without access to clean samples or strong assumptions on\nthe distribution of the data.\n",
                "链接": "https://arxiv.org/abs/2306.03402"
            },
            {
                "文章ID": "4031",
                "标题": "Identifiability of Label Noise Transition Matrix",
                "作者": " Yang Liu,  Hao Cheng,  Kun Zhang",
                "发布日期": "2022-07-05",
                "摘要": "  The noise transition matrix plays a central role in the problem of learning\nwith noisy labels. Among many other reasons, a large number of existing\nsolutions rely on access to it. Identifying and estimating the transition\nmatrix without ground truth labels is a critical and challenging task. When\nlabel noise transition depends on each instance, the problem of identifying the\ninstance-dependent noise transition matrix becomes substantially more\nchallenging. Despite recent works proposing solutions for learning from\ninstance-dependent noisy labels, the field lacks a unified understanding of\nwhen such a problem remains identifiable. The goal of this paper is to\ncharacterize the identifiability of the label noise transition matrix. Building\non Kruskal's identifiability results, we are able to show the necessity of\nmultiple noisy labels in identifying the noise transition matrix for the\ngeneric case at the instance level. We further instantiate the results to\nexplain the successes of the state-of-the-art solutions and how additional\nassumptions alleviated the requirement of multiple noisy labels. Our result\nalso reveals that disentangled features are helpful in the above identification\ntask and we provide empirical evidence.\n",
                "链接": "https://arxiv.org/abs/2202.02016"
            },
            {
                "文章ID": "79671",
                "标题": "Mitigating Label Noise through Data Ambiguation",
                "作者": " Julian Lienen,  Eyke Hüllermeier",
                "发布日期": "2023-05-24",
                "摘要": "  Label noise poses an important challenge in machine learning, especially in\ndeep learning, in which large models with high expressive power dominate the\nfield. Models of that kind are prone to memorizing incorrect labels, thereby\nharming generalization performance. Many methods have been proposed to address\nthis problem, including robust loss functions and more complex label correction\napproaches. Robust loss functions are appealing due to their simplicity, but\ntypically lack flexibility, while label correction usually adds substantial\ncomplexity to the training setup. In this paper, we suggest to address the\nshortcomings of both methodologies by \"ambiguating\" the target information,\nadding additional, complementary candidate labels in case the learner is not\nsufficiently convinced of the observed training label. More precisely, we\nleverage the framework of so-called superset learning to construct set-valued\ntargets based on a confidence threshold, which deliver imprecise yet more\nreliable beliefs about the ground-truth, effectively helping the learner to\nsuppress the memorization effect. In an extensive empirical evaluation, our\nmethod demonstrates favorable learning behavior on synthetic and real-world\nnoise, confirming the effectiveness in detecting and correcting erroneous\ntraining labels.\n",
                "链接": "https://arxiv.org/abs/2305.13764"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下文本检索任务上，是否有关于大模型在语义坍缩问题上的研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "77357",
                "标题": "Mask to reconstruct: Cooperative Semantics Completion for Video-text\n  Retrieval",
                "作者": " Han Fang,  Zhifei Yang,  Xianghao Zang,  Chao Ban,  Hao Sun",
                "发布日期": "2023-05-16",
                "摘要": "  Recently, masked video modeling has been widely explored and significantly\nimproved the model's understanding ability of visual regions at a local level.\nHowever, existing methods usually adopt random masking and follow the same\nreconstruction paradigm to complete the masked regions, which do not leverage\nthe correlations between cross-modal content. In this paper, we present Mask\nfor Semantics Completion (MASCOT) based on semantic-based masked modeling.\nSpecifically, after applying attention-based video masking to generate\nhigh-informed and low-informed masks, we propose Informed Semantics Completion\nto recover masked semantics information. The recovery mechanism is achieved by\naligning the masked content with the unmasked visual regions and corresponding\ntextual context, which makes the model capture more text-related details at a\npatch level. Additionally, we shift the emphasis of reconstruction from\nirrelevant backgrounds to discriminative parts to ignore regions with\nlow-informed masks. Furthermore, we design dual-mask co-learning to incorporate\nvideo cues under different masks and learn more aligned video representation.\nOur MASCOT performs state-of-the-art performance on four major text-video\nretrieval benchmarks, including MSR-VTT, LSMDC, ActivityNet, and DiDeMo.\nExtensive ablation studies demonstrate the effectiveness of the proposed\nschemes.\n",
                "链接": "https://arxiv.org/abs/2305.07910"
            },
            {
                "文章ID": "87459",
                "标题": "Long-range Language Modeling with Self-retrieval",
                "作者": " Ohad Rubin,  Jonathan Berant",
                "发布日期": "2023-06-26",
                "摘要": "  Retrieval-augmented language models (LMs) have received much attention\nrecently. However, typically the retriever is not trained jointly as a native\ncomponent of the LM, but added to an already-pretrained LM, which limits the\nability of the LM and the retriever to adapt to one another. In this work, we\npropose the Retrieval-Pretrained Transformer (RPT), an architecture and\ntraining procedure for jointly training a retrieval-augmented LM from scratch\nfor the task of modeling long texts. Given a recently generated text chunk in a\nlong document, the LM computes query representations, which are then used to\nretrieve earlier chunks in the document, located potentially tens of thousands\nof tokens before. Information from retrieved chunks is fused into the LM\nrepresentations to predict the next target chunk. We train the retriever\ncomponent with a semantic objective, where the goal is to retrieve chunks that\nincrease the probability of the next chunk, according to a reference LM. We\nevaluate RPT on four long-range language modeling tasks, spanning books, code,\nand mathematical writing, and demonstrate that RPT improves retrieval quality\nand subsequently perplexity across the board compared to strong baselines.\n",
                "链接": "https://arxiv.org/abs/2306.13421"
            },
            {
                "文章ID": "81507",
                "标题": "Reward Collapse in Aligning Large Language Models",
                "作者": " Ziang Song,  Tianle Cai,  Jason D. Lee,  Weijie J. Su",
                "发布日期": "2023-05-30",
                "摘要": "  The extraordinary capabilities of large language models (LLMs) such as\nChatGPT and GPT-4 are in part unleashed by aligning them with reward models\nthat are trained on human preferences, which are often represented as rankings\nof responses to prompts. In this paper, we document the phenomenon of\n\\textit{reward collapse}, an empirical observation where the prevailing\nranking-based approach results in an \\textit{identical} reward distribution\n\\textit{regardless} of the prompts during the terminal phase of training. This\noutcome is undesirable as open-ended prompts like ``write a short story about\nyour best friend'' should yield a continuous range of rewards for their\ncompletions, while specific prompts like ``what is the capital of New Zealand''\nshould generate either high or low rewards. Our theoretical investigation\nreveals that reward collapse is primarily due to the insufficiency of the\nranking-based objective function to incorporate prompt-related information\nduring optimization. This insight allows us to derive closed-form expressions\nfor the reward distribution associated with a set of utility functions in an\nasymptotic regime. To overcome reward collapse, we introduce a prompt-aware\noptimization scheme that provably admits a prompt-dependent reward distribution\nwithin the interpolating regime. Our experimental results suggest that our\nproposed prompt-aware utility functions significantly alleviate reward collapse\nduring the training of reward models.\n",
                "链接": "https://arxiv.org/abs/2305.17608"
            },
            {
                "文章ID": "100175",
                "标题": "MultiWay-Adapater: Adapting large-scale multi-modal models for scalable\n  image-text retrieval",
                "作者": " Zijun Long,  George Killick,  Richard McCreadie,  Gerardo Aragon Camarasa",
                "发布日期": "2023-09-14",
                "摘要": "  As the size of Large Multi-Modal Models (LMMs) increases consistently, the\nadaptation of these pre-trained models to specialized tasks has become a\ncomputationally and memory-intensive challenge. Traditional fine-tuning methods\nrequire isolated, exhaustive retuning for each new task, limiting the models'\nversatility. Moreover, current efficient adaptation techniques often overlook\nmodality alignment, focusing only on the knowledge extraction of new tasks. To\ntackle these issues, we introduce Multiway-Adapter, an innovative framework\nincorporating an 'Alignment Enhancer' to deepen modality alignment, enabling\nhigh transferability without tuning pre-trained parameters. Our method adds\nfewer than 1.25\\% of additional parameters to LMMs, exemplified by the BEiT-3\nmodel in our study. This leads to superior zero-shot image-text retrieval\nperformance compared to fully fine-tuned models, while achieving up to a 57\\%\nreduction in fine-tuning time. Our approach offers a resource-efficient and\neffective adaptation pathway for LMMs, broadening their applicability. The\nsource code is publicly available at:\n\\url{https://github.com/longkukuhi/MultiWay-Adapter}.\n",
                "链接": "https://arxiv.org/abs/2309.01516"
            },
            {
                "文章ID": "108354",
                "标题": "Direction-Oriented Visual-semantic Embedding Model for Remote Sensing\n  Image-text Retrieval",
                "作者": " Qing Ma,  Jiancheng Pan,  Cong Bai",
                "发布日期": "2023-10-13",
                "摘要": "  Image-text retrieval has developed rapidly in recent years. However, it is\nstill a challenge in remote sensing due to visual-semantic imbalance, which\nleads to incorrect matching of non-semantic visual and textual features. To\nsolve this problem, we propose a novel Direction-Oriented Visual-semantic\nEmbedding Model (DOVE) to mine the relationship between vision and language.\nConcretely, a Regional-Oriented Attention Module (ROAM) adaptively adjusts the\ndistance between the final visual and textual embeddings in the latent semantic\nspace, oriented by regional visual features. Meanwhile, a lightweight Digging\nText Genome Assistant (DTGA) is designed to expand the range of tractable\ntextual representation and enhance global word-level semantic connections using\nless attention operations. Ultimately, we exploit a global visual-semantic\nconstraint to reduce single visual dependency and serve as an external\nconstraint for the final visual and textual representations. The effectiveness\nand superiority of our method are verified by extensive experiments including\nparameter evaluation, quantitative comparison, ablation studies and visual\nanalysis, on two benchmark datasets, RSICD and RSITMD.\n",
                "链接": "https://arxiv.org/abs/2310.08276"
            },
            {
                "文章ID": "65811",
                "标题": "Semantic-Preserving Augmentation for Robust Image-Text Retrieval",
                "作者": " Sunwoo Kim,  Kyuhong Shim,  Luong Trung Nguyen,  Byonghyo Shim",
                "发布日期": "2023-03-13",
                "摘要": "  Image text retrieval is a task to search for the proper textual descriptions\nof the visual world and vice versa. One challenge of this task is the\nvulnerability to input image and text corruptions. Such corruptions are often\nunobserved during the training, and degrade the retrieval model decision\nquality substantially. In this paper, we propose a novel image text retrieval\ntechnique, referred to as robust visual semantic embedding (RVSE), which\nconsists of novel image-based and text-based augmentation techniques called\nsemantic preserving augmentation for image (SPAugI) and text (SPAugT). Since\nSPAugI and SPAugT change the original data in a way that its semantic\ninformation is preserved, we enforce the feature extractors to generate\nsemantic aware embedding vectors regardless of the corruption, improving the\nmodel robustness significantly. From extensive experiments using benchmark\ndatasets, we show that RVSE outperforms conventional retrieval schemes in terms\nof image-text retrieval performance.\n",
                "链接": "https://arxiv.org/abs/2303.05692"
            },
            {
                "文章ID": "70917",
                "标题": "CT Multi-Task Learning with a Large Image-Text (LIT) Model",
                "作者": " Chuang Niu,  Ge Wang",
                "发布日期": "2023-04-07",
                "摘要": "  Large language models (LLM) not only empower multiple language tasks but also\nserve as a general interface across different spaces. Up to now, it has not\nbeen demonstrated yet how to effectively translate the successes of LLMs in the\ncomputer vision field to the medical imaging field which involves\nhigh-dimensional and multi-modal medical images. In this paper, we report a\nfeasibility study of building a multi-task CT large image-text (LIT) model for\nlung cancer diagnosis by combining an LLM and a large image model (LIM).\nSpecifically, the LLM and LIM are used as encoders to perceive multi-modal\ninformation under task-specific text prompts, which synergizes multi-source\ninformation and task-specific and patient-specific priors for optimized\ndiagnostic performance. The key components of our LIT model and associated\ntechniques are evaluated with an emphasis on 3D lung CT analysis. Our initial\nresults show that the LIT model performs multiple medical tasks well, including\nlung segmentation, lung nodule detection, and lung cancer classification.\nActive efforts are in progress to develop large image-language models for\nsuperior medical imaging in diverse applications and optimal patient outcomes.\n",
                "链接": "https://arxiv.org/abs/2304.02649"
            },
            {
                "文章ID": "54702",
                "标题": "Multi-modal Molecule Structure-text Model for Text-based Retrieval and\n  Editing",
                "作者": " Shengchao Liu,  Weili Nie,  Chengpeng Wang,  Jiarui Lu,  Zhuoran Qiao,  Ling Liu,  Jian Tang,  Chaowei Xiao,  Anima Anandkumar",
                "发布日期": "2023-12-05",
                "摘要": "  There is increasing adoption of artificial intelligence in drug discovery.\nHowever, existing studies use machine learning to mainly utilize the chemical\nstructures of molecules but ignore the vast textual knowledge available in\nchemistry. Incorporating textual knowledge enables us to realize new drug\ndesign objectives, adapt to text-based instructions and predict complex\nbiological activities. Here we present a multi-modal molecule structure-text\nmodel, MoleculeSTM, by jointly learning molecules' chemical structures and\ntextual descriptions via a contrastive learning strategy. To train MoleculeSTM,\nwe construct a large multi-modal dataset, namely, PubChemSTM, with over 280,000\nchemical structure-text pairs. To demonstrate the effectiveness and utility of\nMoleculeSTM, we design two challenging zero-shot tasks based on text\ninstructions, including structure-text retrieval and molecule editing.\nMoleculeSTM has two main properties: open vocabulary and compositionality via\nnatural language. In experiments, MoleculeSTM obtains the state-of-the-art\ngeneralization ability to novel biochemical concepts across various benchmarks.\n",
                "链接": "https://arxiv.org/abs/2212.10789"
            },
            {
                "文章ID": "54710",
                "标题": "ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language\n  Models",
                "作者": " Dheeraj Mekala,  Jason Wolfe,  Subhro Roy",
                "发布日期": "2022-12-22",
                "摘要": "  We explore the use of large language models (LLMs) for zero-shot semantic\nparsing. Semantic parsing involves mapping natural language utterances to\ntask-specific meaning representations. Language models are generally trained on\nthe publicly available text and code and cannot be expected to directly\ngeneralize to domain-specific parsing tasks in a zero-shot setting. In this\nwork, we propose ZEROTOP, a zero-shot task-oriented parsing method that\ndecomposes a semantic parsing problem into a set of abstractive and extractive\nquestion-answering (QA) problems, enabling us to leverage the ability of LLMs\nto zero-shot answer reading comprehension questions. For each utterance, we\nprompt the LLM with questions corresponding to its top-level intent and a set\nof slots and use the LLM generations to construct the target meaning\nrepresentation. We observe that current LLMs fail to detect unanswerable\nquestions; and as a result, cannot handle questions corresponding to missing\nslots. To address this problem, we fine-tune a language model on public QA\ndatasets using synthetic negative samples. Experimental results show that our\nQA-based decomposition paired with the fine-tuned LLM can correctly parse ~16%\nof utterances in the MTOP dataset without requiring any annotated data.\n",
                "链接": "https://arxiv.org/abs/2212.10815"
            },
            {
                "文章ID": "28104",
                "标题": "Multi-Task Retrieval-Augmented Text Generation with Relevance Sampling",
                "作者": " Sebastian Hofstätter,  Jiecao Chen,  Karthik Raman,  Hamed Zamani",
                "发布日期": "2022-07-08",
                "摘要": "  This paper studies multi-task training of retrieval-augmented generation\nmodels for knowledge-intensive tasks. We propose to clean the training set by\nutilizing a distinct property of knowledge-intensive generation: The connection\nof query-answer pairs to items in the knowledge base. We filter training\nexamples via a threshold of confidence on the relevance labels, whether a pair\nis answerable by the knowledge base or not. We train a single Fusion-in-Decoder\n(FiD) generator on seven combined tasks of the KILT benchmark. The experimental\nresults suggest that our simple yet effective approach substantially improves\ncompetitive baselines on two strongly imbalanced tasks; and shows either\nsmaller improvements or no significant regression on the remaining tasks.\nFurthermore, we demonstrate our multi-task training with relevance label\nsampling scales well with increased model capacity and achieves\nstate-of-the-art results in five out of seven KILT tasks.\n",
                "链接": "https://arxiv.org/abs/2207.03030"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找对机器翻译数据集质量进行评估的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "84997",
                "标题": "Conformalizing Machine Translation Evaluation",
                "作者": " Chrysoula Zerva,  André F. T. Martins",
                "发布日期": "2023-06-13",
                "摘要": "  Several uncertainty estimation methods have been recently proposed for\nmachine translation evaluation. While these methods can provide a useful\nindication of when not to trust model predictions, we show in this paper that\nthe majority of them tend to underestimate model uncertainty, and as a result\nthey often produce misleading confidence intervals that do not cover the ground\ntruth. We propose as an alternative the use of conformal prediction, a\ndistribution-free method to obtain confidence intervals with a theoretically\nestablished guarantee on coverage. First, we demonstrate that split conformal\nprediction can ``correct'' the confidence intervals of previous methods to\nyield a desired coverage level. Then, we highlight biases in estimated\nconfidence intervals, both in terms of the translation language pairs and the\nquality of translations. We apply conditional conformal prediction techniques\nto obtain calibration subsets for each data subgroup, leading to equalized\ncoverage.\n",
                "链接": "https://arxiv.org/abs/2306.06221"
            },
            {
                "文章ID": "87010",
                "标题": "Evaluation of Chinese-English Machine Translation of Emotion-Loaded\n  Microblog Texts: A Human Annotated Dataset for the Quality Assessment of\n  Emotion Translation",
                "作者": " Shenbin Qian,  Constantin Orasan,  Felix do Carmo,  Qiuliang Li,  Diptesh Kanojia",
                "发布日期": "2023-06-22",
                "摘要": "  In this paper, we focus on how current Machine Translation (MT) tools perform\non the translation of emotion-loaded texts by evaluating outputs from Google\nTranslate according to a framework proposed in this paper. We propose this\nevaluation framework based on the Multidimensional Quality Metrics (MQM) and\nperform a detailed error analysis of the MT outputs. From our analysis, we\nobserve that about 50% of the MT outputs fail to preserve the original emotion.\nAfter further analysis of the errors, we find that emotion carrying words and\nlinguistic phenomena such as polysemous words, negation, abbreviation etc., are\ncommon causes for these translation errors.\n",
                "链接": "https://arxiv.org/abs/2306.11900"
            },
            {
                "文章ID": "39818",
                "标题": "QUAK: A Synthetic Quality Estimation Dataset for Korean-English Neural\n  Machine Translation",
                "作者": " Sugyeong Eo,  Chanjun Park,  Hyeonseok Moon,  Jaehyung Seo,  Gyeongmin Kim,  Jungseob Lee,  Heuiseok Lim",
                "发布日期": "2022-11-30",
                "摘要": "  With the recent advance in neural machine translation demonstrating its\nimportance, research on quality estimation (QE) has been steadily progressing.\nQE aims to automatically predict the quality of machine translation (MT) output\nwithout reference sentences. Despite its high utility in the real world, there\nremain several limitations concerning manual QE data creation: inevitably\nincurred non-trivial costs due to the need for translation experts, and issues\nwith data scaling and language expansion. To tackle these limitations, we\npresent QUAK, a Korean-English synthetic QE dataset generated in a fully\nautomatic manner. This consists of three sub-QUAK datasets QUAK-M, QUAK-P, and\nQUAK-H, produced through three strategies that are relatively free from\nlanguage constraints. Since each strategy requires no human effort, which\nfacilitates scalability, we scale our data up to 1.58M for QUAK-P, H and 6.58M\nfor QUAK-M. As an experiment, we quantitatively analyze word-level QE results\nin various ways while performing statistical analysis. Moreover, we show that\ndatasets scaled in an efficient way also contribute to performance improvements\nby observing meaningful performance gains in QUAK-M, P when adding data up to\n1.58M.\n",
                "链接": "https://arxiv.org/abs/2209.15285"
            },
            {
                "文章ID": "50351",
                "标题": "Competency-Aware Neural Machine Translation: Can Machine Translation\n  Know its Own Translation Quality?",
                "作者": " Pei Zhang,  Baosong Yang,  Haoran Wei,  Dayiheng Liu,  Kai Fan,  Luo Si,  Jun Xie",
                "发布日期": "2022-11-28",
                "摘要": "  Neural machine translation (NMT) is often criticized for failures that happen\nwithout awareness. The lack of competency awareness makes NMT untrustworthy.\nThis is in sharp contrast to human translators who give feedback or conduct\nfurther investigations whenever they are in doubt about predictions. To fill\nthis gap, we propose a novel competency-aware NMT by extending conventional NMT\nwith a self-estimator, offering abilities to translate a source sentence and\nestimate its competency. The self-estimator encodes the information of the\ndecoding procedure and then examines whether it can reconstruct the original\nsemantics of the source sentence. Experimental results on four translation\ntasks demonstrate that the proposed method not only carries out translation\ntasks intact but also delivers outstanding performance on quality estimation.\nWithout depending on any reference or annotated data typically required by\nstate-of-the-art metric and quality estimation methods, our model yields an\neven higher correlation with human quality judgments than a variety of\naforementioned methods, such as BLEURT, COMET, and BERTScore. Quantitative and\nqualitative analyses show better robustness of competency awareness in our\nmodel.\n",
                "链接": "https://arxiv.org/abs/2211.13865"
            },
            {
                "文章ID": "37434",
                "标题": "Rethinking Round-Trip Translation for Machine Translation Evaluation",
                "作者": " Terry Yue Zhuo,  Qiongkai Xu,  Xuanli He,  Trevor Cohn",
                "发布日期": "2023-05-16",
                "摘要": "  Automatic evaluation on low-resource language translation suffers from a\ndeficiency of parallel corpora. Round-trip translation could be served as a\nclever and straightforward technique to alleviate the requirement of the\nparallel evaluation corpus. However, there was an observation of obscure\ncorrelations between the evaluation scores by forward and round-trip\ntranslations in the era of statistical machine translation (SMT). In this\npaper, we report the surprising finding that round-trip translation can be used\nfor automatic evaluation without the references. Firstly, our revisit on the\nround-trip translation in SMT evaluation unveils that its long-standing\nmisunderstanding is essentially caused by copying mechanism. After removing\ncopying mechanism in SMT, round-trip translation scores can appropriately\nreflect the forward translation performance. Then, we demonstrate the\nrectification is overdue as round-trip translation could benefit multiple\nmachine translation evaluation tasks. To be more specific, round-trip\ntranslation could be used i) to predict corresponding forward translation\nscores; ii) to improve the performance of the recently advanced quality\nestimation model; and iii) to identify adversarial competitors in shared tasks\nvia cross-system verification.\n",
                "链接": "https://arxiv.org/abs/2209.07351"
            },
            {
                "文章ID": "6641",
                "标题": "An Overview on Machine Translation Evaluation",
                "作者": " Lifeng Han",
                "发布日期": "2022-02-23",
                "摘要": "  Since the 1950s, machine translation (MT) has become one of the important\ntasks of AI and development, and has experienced several different periods and\nstages of development, including rule-based methods, statistical methods, and\nrecently proposed neural network-based learning methods. Accompanying these\nstaged leaps is the evaluation research and development of MT, especially the\nimportant role of evaluation methods in statistical translation and neural\ntranslation research. The evaluation task of MT is not only to evaluate the\nquality of machine translation, but also to give timely feedback to machine\ntranslation researchers on the problems existing in machine translation itself,\nhow to improve and how to optimise. In some practical application fields, such\nas in the absence of reference translations, the quality estimation of machine\ntranslation plays an important role as an indicator to reveal the credibility\nof automatically translated target languages. This report mainly includes the\nfollowing contents: a brief history of machine translation evaluation (MTE),\nthe classification of research methods on MTE, and the the cutting-edge\nprogress, including human evaluation, automatic evaluation, and evaluation of\nevaluation methods (meta-evaluation). Manual evaluation and automatic\nevaluation include reference-translation based and reference-translation\nindependent participation; automatic evaluation methods include traditional\nn-gram string matching, models applying syntax and semantics, and deep learning\nmodels; evaluation of evaluation methods includes estimating the credibility of\nhuman evaluations, the reliability of the automatic evaluation, the reliability\nof the test set, etc. Advances in cutting-edge evaluation methods include\ntask-based evaluation, using pre-trained language models based on big data, and\nlightweight optimisation models using distillation techniques.\n",
                "链接": "https://arxiv.org/abs/2202.11027"
            },
            {
                "文章ID": "14818",
                "标题": "Disentangling Uncertainty in Machine Translation Evaluation",
                "作者": " Chrysoula Zerva,  Taisiya Glushkova,  Ricardo Rei,  André F. T. Martins",
                "发布日期": "2022-12-01",
                "摘要": "  Trainable evaluation metrics for machine translation (MT) exhibit strong\ncorrelation with human judgements, but they are often hard to interpret and\nmight produce unreliable scores under noisy or out-of-domain data. Recent work\nhas attempted to mitigate this with simple uncertainty quantification\ntechniques (Monte Carlo dropout and deep ensembles), however these techniques\n(as we show) are limited in several ways -- for example, they are unable to\ndistinguish between different kinds of uncertainty, and they are time and\nmemory consuming. In this paper, we propose more powerful and efficient\nuncertainty predictors for MT evaluation, and we assess their ability to target\ndifferent sources of aleatoric and epistemic uncertainty. To this end, we\ndevelop and compare training objectives for the COMET metric to enhance it with\nan uncertainty prediction output, including heteroscedastic regression,\ndivergence minimization, and direct uncertainty prediction. Our experiments\nshow improved results on uncertainty prediction for the WMT metrics task\ndatasets, with a substantial reduction in computational costs. Moreover, they\ndemonstrate the ability of these predictors to address specific uncertainty\ncauses in MT evaluation, such as low quality references and out-of-domain data.\n",
                "链接": "https://arxiv.org/abs/2204.06546"
            },
            {
                "文章ID": "54518",
                "标题": "Extrinsic Evaluation of Machine Translation Metrics",
                "作者": " Nikita Moghe,  Tom Sherborne,  Mark Steedman,  Alexandra Birch",
                "发布日期": "2023-06-21",
                "摘要": "  Automatic machine translation (MT) metrics are widely used to distinguish the\ntranslation qualities of machine translation systems across relatively large\ntest sets (system-level evaluation). However, it is unclear if automatic\nmetrics are reliable at distinguishing good translations from bad translations\nat the sentence level (segment-level evaluation). In this paper, we investigate\nhow useful MT metrics are at detecting the success of a machine translation\ncomponent when placed in a larger platform with a downstream task. We evaluate\nthe segment-level performance of the most widely used MT metrics (chrF, COMET,\nBERTScore, etc.) on three downstream cross-lingual tasks (dialogue state\ntracking, question answering, and semantic parsing). For each task, we only\nhave access to a monolingual task-specific model. We calculate the correlation\nbetween the metric's ability to predict a good/bad translation with the\nsuccess/failure on the final task for the Translate-Test setup. Our experiments\ndemonstrate that all metrics exhibit negligible correlation with the extrinsic\nevaluation of the downstream outcomes. We also find that the scores provided by\nneural metrics are not interpretable mostly because of undefined ranges. We\nsynthesise our analysis into recommendations for future MT metrics to produce\nlabels rather than scores for more informative interaction between machine\ntranslation and multilingual language understanding.\n",
                "链接": "https://arxiv.org/abs/2212.10297"
            },
            {
                "文章ID": "17492",
                "标题": "Quality-Aware Decoding for Neural Machine Translation",
                "作者": " Patrick Fernandes,  António Farinhas,  Ricardo Rei,  José G. C. de Souza,  Perez Ogayo,  Graham Neubig,  André F. T. Martins",
                "发布日期": "2022-05-03",
                "摘要": "  Despite the progress in machine translation quality estimation and evaluation\nin the last years, decoding in neural machine translation (NMT) is mostly\noblivious to this and centers around finding the most probable translation\naccording to the model (MAP decoding), approximated with beam search. In this\npaper, we bring together these two lines of research and propose quality-aware\ndecoding for NMT, by leveraging recent breakthroughs in reference-free and\nreference-based MT evaluation through various inference methods like $N$-best\nreranking and minimum Bayes risk decoding. We perform an extensive comparison\nof various possible candidate generation and ranking methods across four\ndatasets and two model classes and find that quality-aware decoding\nconsistently outperforms MAP-based decoding according both to state-of-the-art\nautomatic metrics (COMET and BLEURT) and to human assessments. Our code is\navailable at https://github.com/deep-spin/qaware-decode.\n",
                "链接": "https://arxiv.org/abs/2205.00978"
            },
            {
                "文章ID": "87351",
                "标题": "Towards Explainable Evaluation Metrics for Machine Translation",
                "作者": " Christoph Leiter,  Piyawat Lertvittayakumjorn,  Marina Fomicheva,  Wei Zhao,  Yang Gao,  Steffen Eger",
                "发布日期": "2023-06-23",
                "摘要": "  Unlike classical lexical overlap metrics such as BLEU, most current\nevaluation metrics for machine translation (for example, COMET or BERTScore)\nare based on black-box large language models. They often achieve strong\ncorrelations with human judgments, but recent research indicates that the\nlower-quality classical metrics remain dominant, one of the potential reasons\nbeing that their decision processes are more transparent. To foster more\nwidespread acceptance of novel high-quality metrics, explainability thus\nbecomes crucial. In this concept paper, we identify key properties as well as\nkey goals of explainable machine translation metrics and provide a\ncomprehensive synthesis of recent techniques, relating them to our established\ngoals and properties. In this context, we also discuss the latest\nstate-of-the-art approaches to explainable metrics based on generative models\nsuch as ChatGPT and GPT4. Finally, we contribute a vision of next-generation\napproaches, including natural language explanations. We hope that our work can\nhelp catalyze and guide future research on explainable evaluation metrics and,\nmediately, also contribute to better and more transparent machine translation\nsystems.\n",
                "链接": "https://arxiv.org/abs/2306.13041"
            }
        ]
    },
    {
        "question": {
            "question": "查找大语言模型相关的分析类型的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "75161",
                "标题": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
                "作者": " Eddie Guo,  Mehul Gupta,  Jiawen Deng,  Ye-Jean Park,  Mike Paget,  Christopher Naugler",
                "发布日期": "2023-10-09",
                "摘要": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
                "链接": "https://arxiv.org/abs/2305.00844"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            },
            {
                "文章ID": "117394",
                "标题": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
                "作者": " Chengyu Wang,  Junbing Yan,  Wei Zhang,  Jun Huang",
                "发布日期": "2023-11-23",
                "摘要": "  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.13126"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "110493",
                "标题": "LUNA: A Model-Based Universal Analysis Framework for Large Language\n  Models",
                "作者": " Da Song,  Xuan Xie,  Jiayang Song,  Derui Zhu,  Yuheng Huang,  Felix Juefei-Xu,  Lei Ma",
                "发布日期": "2023-10-24",
                "摘要": "  Over the past decade, Artificial Intelligence (AI) has had great success\nrecently and is being used in a wide range of academic and industrial fields.\nMore recently, LLMs have made rapid advancements that have propelled AI to a\nnew level, enabling even more diverse applications and industrial domains with\nintelligence, particularly in areas like software engineering and natural\nlanguage processing. Nevertheless, a number of emerging trustworthiness\nconcerns and issues exhibited in LLMs have already recently received much\nattention, without properly solving which the widespread adoption of LLMs could\nbe greatly hindered in practice. The distinctive characteristics of LLMs, such\nas the self-attention mechanism, extremely large model scale, and\nautoregressive generation schema, differ from classic AI software based on CNNs\nand RNNs and present new challenges for quality analysis. Up to the present, it\nstill lacks universal and systematic analysis techniques for LLMs despite the\nurgent industrial demand. Towards bridging this gap, we initiate an early\nexploratory study and propose a universal analysis framework for LLMs, LUNA,\ndesigned to be general and extensible, to enable versatile analysis of LLMs\nfrom multiple quality perspectives in a human-interpretable manner. In\nparticular, we first leverage the data from desired trustworthiness\nperspectives to construct an abstract model as an auxiliary analysis asset,\nwhich is empowered by various abstract model construction methods. To assess\nthe quality of the abstract model, we collect and define a number of evaluation\nmetrics, aiming at both abstract model level and the semantics level. Then, the\nsemantics, which is the degree of satisfaction of the LLM w.r.t. the\ntrustworthiness perspective, is bound to and enriches the abstract model with\nsemantics, which enables more detailed analysis applications for diverse\npurposes.\n",
                "链接": "https://arxiv.org/abs/2310.14211"
            },
            {
                "文章ID": "39922",
                "标题": "Family-Based Fingerprint Analysis: A Position Paper",
                "作者": " Carlos Diego Nascimento Damasceno,  Daniel Strüber",
                "发布日期": "2022-10-03",
                "摘要": "  Thousands of vulnerabilities are reported on a monthly basis to security\nrepositories, such as the National Vulnerability Database. Among these\nvulnerabilities, software misconfiguration is one of the top 10 security risks\nfor web applications. With this large influx of vulnerability reports, software\nfingerprinting has become a highly desired capability to discover distinctive\nand efficient signatures and recognize reportedly vulnerable software\nimplementations. Due to the exponential worst-case complexity of fingerprint\nmatching, designing more efficient methods for fingerprinting becomes highly\ndesirable, especially for variability-intensive systems where optional features\nadd another exponential factor to its analysis. This position paper presents\nour vision of a framework that lifts model learning and family-based analysis\nprinciples to software fingerprinting. In this framework, we propose unifying\ndatabases of signatures into a featured finite state machine and using presence\nconditions to specify whether and in which circumstances a given input-output\ntrace is observed. We believe feature-based signatures can aid performance\nimprovements by reducing the size of fingerprints under analysis.\n",
                "链接": "https://arxiv.org/abs/2209.15620"
            },
            {
                "文章ID": "69238",
                "标题": "Can Large Language Models assist in Hazard Analysis?",
                "作者": " Simon Diemert,  Jens H Weber",
                "发布日期": "2023-03-29",
                "摘要": "  Large Language Models (LLMs), such as GPT-3, have demonstrated remarkable\nnatural language processing and generation capabilities and have been applied\nto a variety tasks, such as source code generation. This paper explores the\npotential of integrating LLMs in the hazard analysis for safety-critical\nsystems, a process which we refer to as co-hazard analysis (CoHA). In CoHA, a\nhuman analyst interacts with an LLM via a context-aware chat session and uses\nthe responses to support elicitation of possible hazard causes. In this\nexperiment, we explore CoHA with three increasingly complex versions of a\nsimple system, using Open AI's ChatGPT service. The quality of ChatGPT's\nresponses were systematically assessed to determine the feasibility of CoHA\ngiven the current state of LLM technology. The results suggest that LLMs may be\nuseful for supporting human analysts performing hazard analysis.\n",
                "链接": "https://arxiv.org/abs/2303.15473"
            },
            {
                "文章ID": "101649",
                "标题": "Leveraging Large Language Models for Automated Dialogue Analysis",
                "作者": " Sarah E. Finch,  Ellie S. Paek,  Jinho D. Choi",
                "发布日期": "2023-09-14",
                "摘要": "  Developing high-performing dialogue systems benefits from the automatic\nidentification of undesirable behaviors in system responses. However, detecting\nsuch behaviors remains challenging, as it draws on a breadth of general\nknowledge and understanding of conversational practices. Although recent\nresearch has focused on building specialized classifiers for detecting specific\ndialogue behaviors, the behavior coverage is still incomplete and there is a\nlack of testing on real-world human-bot interactions. This paper investigates\nthe ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to\nperform dialogue behavior detection for nine categories in real human-bot\ndialogues. We aim to assess whether ChatGPT can match specialized models and\napproximate human performance, thereby reducing the cost of behavior detection\ntasks. Our findings reveal that neither specialized models nor ChatGPT have yet\nachieved satisfactory results for this task, falling short of human\nperformance. Nevertheless, ChatGPT shows promising potential and often\noutperforms specialized detection models. We conclude with an in-depth\nexamination of the prevalent shortcomings of ChatGPT, offering guidance for\nfuture research to enhance LLM capabilities.\n",
                "链接": "https://arxiv.org/abs/2309.06490"
            }
        ]
    },
    {
        "question": {
            "question": "查询2022年以来指令遵循数据集构建相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "98821",
                "标题": "MedAlign: A Clinician-Generated Dataset for Instruction Following with\n  Electronic Medical Records",
                "作者": " Scott L. Fleming,  Alejandro Lozano,  William J. Haberkorn,  Jenelle A. Jindal,  Eduardo P. Reis,  Rahul Thapa,  Louis Blankemeier,  Julian Z. Genkins,  Ethan Steinberg,  Ashwin Nayak,  Birju S. Patel,  Chia-Chun Chiang,  Alison Callahan,  Zepeng Huo,  Sergios Gatidis,  Scott J. Adams,  Oluseyi Fayanju,  Shreya J. Shah,  Thomas Savage,  Ethan Goh,  Akshay S. Chaudhari,  Nima Aghaeepour,  Christopher Sharp,  Michael A. Pfeffer,  Percy Liang,  Jonathan H. Chen,  Keith E. Morse,  Emma P. Brunskill,  Jason A. Fries,  Nigam H. Shah",
                "发布日期": "2023-12-27",
                "摘要": "  The ability of large language models (LLMs) to follow natural language\ninstructions with human-level fluency suggests many opportunities in healthcare\nto reduce administrative burden and improve quality of care. However,\nevaluating LLMs on realistic text generation tasks for healthcare remains\nchallenging. Existing question answering datasets for electronic health record\n(EHR) data fail to capture the complexity of information needs and\ndocumentation burdens experienced by clinicians. To address these challenges,\nwe introduce MedAlign, a benchmark dataset of 983 natural language instructions\nfor EHR data. MedAlign is curated by 15 clinicians (7 specialities), includes\nclinician-written reference responses for 303 instructions, and provides 276\nlongitudinal EHRs for grounding instruction-response pairs. We used MedAlign to\nevaluate 6 general domain LLMs, having clinicians rank the accuracy and quality\nof each LLM response. We found high error rates, ranging from 35% (GPT-4) to\n68% (MPT-7B-Instruct), and an 8.3% drop in accuracy moving from 32k to 2k\ncontext lengths for GPT-4. Finally, we report correlations between clinician\nrankings and automated natural language generation metrics as a way to rank\nLLMs without human review. We make MedAlign available under a research data use\nagreement to enable LLM evaluations on tasks aligned with clinician needs and\npreferences.\n",
                "链接": "https://arxiv.org/abs/2308.14089"
            },
            {
                "文章ID": "76886",
                "标题": "Accessible Instruction-Following Agent",
                "作者": " Kairui Zhou",
                "发布日期": "2023-05-12",
                "摘要": "  Humans can collaborate and complete tasks based on visual signals and\ninstruction from the environment. Training such a robot is difficult especially\ndue to the understanding of the instruction and the complicated environment.\nPrevious instruction-following agents are biased to English-centric corpus,\nmaking it unrealizable to be applied to users that use multiple languages or\neven low-resource languages. Nevertheless, the instruction-following agents are\npre-trained in a mode that assumes the user can observe the environment, which\nlimits its accessibility. In this work, we're trying to generalize the success\nof instruction-following agents to non-English languages with little corpus\nresources, and improve its intractability and accessibility. We introduce UVLN\n(Universal Vision-Language Navigation), a novel machine-translation\ninstructional augmented framework for cross-lingual vision-language navigation,\nwith a novel composition of state-of-the-art large language model (GPT3) with\nthe image caption model (BLIP). We first collect a multilanguage\nvision-language navigation dataset via machine translation. Then we extend the\nstandard VLN training objectives to a multilingual setting via a cross-lingual\nlanguage encoder. The alignment between different languages is captured through\na shared vision and action context via a cross-modal transformer, which encodes\nthe inputs of language instruction, visual observation, and action decision\nsequences. To improve the intractability, we connect our agent with the large\nlanguage model that informs the situation and current state to the user and\nalso explains the action decisions. Experiments over Room Across Room Dataset\nprove the effectiveness of our approach. And the qualitative results show the\npromising intractability and accessibility of our instruction-following agent.\n",
                "链接": "https://arxiv.org/abs/2305.06358"
            },
            {
                "文章ID": "102710",
                "标题": "Instruction-Following Speech Recognition",
                "作者": " Cheng-I Jeff Lai,  Zhiyun Lu,  Liangliang Cao,  Ruoming Pang",
                "发布日期": "2023-09-19",
                "摘要": "  Conventional end-to-end Automatic Speech Recognition (ASR) models primarily\nfocus on exact transcription tasks, lacking flexibility for nuanced user\ninteractions. With the advent of Large Language Models (LLMs) in speech\nprocessing, more organic, text-prompt-based interactions have become possible.\nHowever, the mechanisms behind these models' speech understanding and\n\"reasoning\" capabilities remain underexplored. To study this question from the\ndata perspective, we introduce instruction-following speech recognition,\ntraining a Listen-Attend-Spell model to understand and execute a diverse set of\nfree-form text instructions. This enables a multitude of speech recognition\ntasks -- ranging from transcript manipulation to summarization -- without\nrelying on predefined command sets. Remarkably, our model, trained from scratch\non Librispeech, interprets and executes simple instructions without requiring\nLLMs or pre-trained speech modules. It also offers selective transcription\noptions based on instructions like \"transcribe first half and then turn off\nlistening,\" providing an additional layer of privacy and safety compared to\nexisting LLMs. Our findings highlight the significant potential of\ninstruction-following training to advance speech foundation models.\n",
                "链接": "https://arxiv.org/abs/2309.09843"
            },
            {
                "文章ID": "48332",
                "标题": "UGIF: UI Grounded Instruction Following",
                "作者": " Sagar Gubbi Venkatesh,  Partha Talukdar,  Srini Narayanan",
                "发布日期": "2023-05-24",
                "摘要": "  Smartphone users often find it difficult to navigate myriad menus to perform\ncommon tasks such as \"How to block calls from unknown numbers?\". Currently,\nhelp documents with step-by-step instructions are manually written to aid the\nuser. The user experience can be further enhanced by grounding the instructions\nin the help document to the UI and overlaying a tutorial on the phone UI. To\nbuild such tutorials, several natural language processing components including\nretrieval, parsing, and grounding are necessary, but there isn't any relevant\ndataset for such a task. Thus, we introduce UGIF-DataSet, a multi-lingual,\nmulti-modal UI grounded dataset for step-by-step task completion on the\nsmartphone containing 4,184 tasks across 8 languages. As an initial approach to\nthis problem, we propose retrieving the relevant instruction steps based on the\nuser's query and parsing the steps using Large Language Models (LLMs) to\ngenerate macros that can be executed on-device. The instruction steps are often\navailable only in English, so the challenge includes cross-modal, cross-lingual\nretrieval of English how-to pages from user queries in many languages and\nmapping English instruction steps to UI in a potentially different language. We\ncompare the performance of different LLMs including PaLM and GPT-3 and find\nthat the end-to-end task completion rate is 48% for English UI but the\nperformance drops to 32% for other languages. We analyze the common failure\nmodes of existing models on this task and point out areas for improvement.\n",
                "链接": "https://arxiv.org/abs/2211.07615"
            },
            {
                "文章ID": "118475",
                "标题": "Releasing the CRaQAn (Coreference Resolution in Question-Answering): An\n  open-source dataset and dataset creation methodology using\n  instruction-following models",
                "作者": " Rob Grzywinski,  Joshua D'Arcy,  Rob Naidoff,  Ashish Shukla,  Alex Browne,  Ren Gibbons,  Brinnae Bent",
                "发布日期": "2023-11-29",
                "摘要": "  Instruction-following language models demand robust methodologies for\ninformation retrieval to augment instructions for question-answering\napplications. A primary challenge is the resolution of coreferences in the\ncontext of chunking strategies for long documents. The critical barrier to\nexperimentation of handling coreferences is a lack of open source datasets,\nspecifically in question-answering tasks that require coreference resolution.\nIn this work we present our Coreference Resolution in Question-Answering\n(CRaQAn) dataset, an open-source dataset that caters to the nuanced information\nretrieval requirements of coreference resolution in question-answering tasks by\nproviding over 250 question-answer pairs containing coreferences. To develop\nthis dataset, we developed a novel approach for creating high-quality datasets\nusing an instruction-following model (GPT-4) and a Recursive Criticism and\nImprovement Loop.\n",
                "链接": "https://arxiv.org/abs/2311.16338"
            },
            {
                "文章ID": "44753",
                "标题": "Instruction-Following Agents with Multimodal Transformer",
                "作者": " Hao Liu,  Lisa Lee,  Kimin Lee,  Pieter Abbeel",
                "发布日期": "2023-03-28",
                "摘要": "  Humans are excellent at understanding language and vision to accomplish a\nwide range of tasks. In contrast, creating general instruction-following\nembodied agents remains a difficult challenge. Prior work that uses pure\nlanguage-only models lack visual grounding, making it difficult to connect\nlanguage instructions with visual observations. On the other hand, methods that\nuse pre-trained multimodal models typically come with divided language and\nvisual representations, requiring designing specialized network architecture to\nfuse them together. We propose a simple yet effective model for robots to solve\ninstruction-following tasks in vision-based environments. Our \\ours method\nconsists of a multimodal transformer that encodes visual observations and\nlanguage instructions, and a transformer-based policy that predicts actions\nbased on encoded representations. The multimodal transformer is pre-trained on\nmillions of image-text pairs and natural language text, thereby producing\ngeneric cross-modal representations of observations and instructions. The\ntransformer-based policy keeps track of the full history of observations and\nactions, and predicts actions autoregressively. Despite its simplicity, we show\nthat this unified transformer model outperforms all state-of-the-art\npre-trained or trained-from-scratch methods in both single-task and multi-task\nsettings. Our model also shows better model scalability and generalization\nability than prior work.\n",
                "链接": "https://arxiv.org/abs/2210.13431"
            },
            {
                "文章ID": "92076",
                "标题": "Instruction-following Evaluation through Verbalizer Manipulation",
                "作者": " Shiyang Li,  Jun Yan,  Hai Wang,  Zheng Tang,  Xiang Ren,  Vijay Srinivasan,  Hongxia Jin",
                "发布日期": "2023-07-21",
                "摘要": "  While instruction-tuned models have shown remarkable success in various\nnatural language processing tasks, accurately evaluating their ability to\nfollow instructions remains challenging. Existing benchmarks primarily focus on\ncommon instructions that align well with what the model learned during\ntraining. However, proficiency in responding to these instructions does not\nnecessarily imply strong ability in instruction following. In this paper, we\npropose a novel instruction-following evaluation protocol called verbalizer\nmanipulation. It instructs the model to verbalize the task label with words\naligning with model priors to different extents, adopting verbalizers from\nhighly aligned (e.g., outputting ``postive'' for positive sentiment), to\nminimally aligned (e.g., outputting ``negative'' for positive sentiment).\nVerbalizer manipulation can be seamlessly integrated with any classification\nbenchmark to examine the model's reliance on priors and its ability to override\nthem to accurately follow the instructions. We conduct a comprehensive\nevaluation of four major model families across nine datasets, employing twelve\nsets of verbalizers for each of them. We observe that the instruction-following\nabilities of models, across different families and scales, are significantly\ndistinguished by their performance on less natural verbalizers. Even the\nstrongest GPT-4 model struggles to perform better than random guessing on the\nmost challenging verbalizer, emphasizing the need for continued advancements to\nimprove their instruction-following abilities.\n",
                "链接": "https://arxiv.org/abs/2307.10558"
            },
            {
                "文章ID": "119138",
                "标题": "Automatic Construction of a Korean Toxic Instruction Dataset for Ethical\n  Tuning of Large Language Models",
                "作者": " Sungjoo Byun,  Dongjun Jang,  Hyemi Jo,  Hyopil Shin",
                "发布日期": "2023-12-01",
                "摘要": "  Caution: this paper may include material that could be offensive or\ndistressing.\n  The advent of Large Language Models (LLMs) necessitates the development of\ntraining approaches that mitigate the generation of unethical language and\naptly manage toxic user queries. Given the challenges related to human labor\nand the scarcity of data, we present KoTox, comprising 39K unethical\ninstruction-output pairs. This collection of automatically generated toxic\ninstructions refines the training of LLMs and establishes a foundational\nframework for improving LLMs' ethical awareness and response to various toxic\ninputs, promoting more secure and responsible interactions in Natural Language\nProcessing (NLP) applications.\n",
                "链接": "https://arxiv.org/abs/2311.18215"
            },
            {
                "文章ID": "115526",
                "标题": "Instruction-Following Evaluation for Large Language Models",
                "作者": " Jeffrey Zhou,  Tianjian Lu,  Swaroop Mishra,  Siddhartha Brahma,  Sujoy Basu,  Yi Luan,  Denny Zhou,  Le Hou",
                "发布日期": "2023-11-15",
                "摘要": "  One core capability of Large Language Models (LLMs) is to follow natural\nlanguage instructions. However, the evaluation of such abilities is not\nstandardized: Human evaluations are expensive, slow, and not objectively\nreproducible, while LLM-based auto-evaluation is potentially biased or limited\nby the ability of the evaluator LLM. To overcome these issues, we introduce\nInstruction-Following Eval (IFEval) for large language models. IFEval is a\nstraightforward and easy-to-reproduce evaluation benchmark. It focuses on a set\nof \"verifiable instructions\" such as \"write in more than 400 words\" and\n\"mention the keyword of AI at least 3 times\". We identified 25 types of those\nverifiable instructions and constructed around 500 prompts, with each prompt\ncontaining one or more verifiable instructions. We show evaluation results of\ntwo widely available LLMs on the market. Our code and data can be found at\nhttps://github.com/google-research/google-research/tree/master/instruction_following_eval\n",
                "链接": "https://arxiv.org/abs/2311.07911"
            },
            {
                "文章ID": "7321",
                "标题": "DialFRED: Dialogue-Enabled Agents for Embodied Instruction Following",
                "作者": " Xiaofeng Gao,  Qiaozi Gao,  Ran Gong,  Kaixiang Lin,  Govind Thattai,  Gaurav S. Sukhatme",
                "发布日期": "2022-08-17",
                "摘要": "  Language-guided Embodied AI benchmarks requiring an agent to navigate an\nenvironment and manipulate objects typically allow one-way communication: the\nhuman user gives a natural language command to the agent, and the agent can\nonly follow the command passively. We present DialFRED, a dialogue-enabled\nembodied instruction following benchmark based on the ALFRED benchmark.\nDialFRED allows an agent to actively ask questions to the human user; the\nadditional information in the user's response is used by the agent to better\ncomplete its task. We release a human-annotated dataset with 53K task-relevant\nquestions and answers and an oracle to answer questions. To solve DialFRED, we\npropose a questioner-performer framework wherein the questioner is pre-trained\nwith the human-annotated data and fine-tuned with reinforcement learning. We\nmake DialFRED publicly available and encourage researchers to propose and\nevaluate their solutions to building dialog-enabled embodied agents.\n",
                "链接": "https://arxiv.org/abs/2202.13330"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于gpt4自动生成prompt的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "41620",
                "标题": "The 'Problematic Paper Screener' automatically selects suspect\n  publications for post-publication (re)assessment",
                "作者": " Guillaume Cabanac,  Cyril Labbé,  Alexander Magazinov",
                "发布日期": "2022-10-12",
                "摘要": "  Post publication assessment remains necessary to check erroneous or\nfraudulent scientific publications. We present an online platform, the\n'Problematic Paper Screener'\n(https://www.irit.fr/~Guillaume.Cabanac/problematic-paper-screener) that\nleverages both automatic machine detection and human assessment to identify and\nflag already published problematic articles. We provide a new effective tool to\ncurate the scientific literature.\n",
                "链接": "https://arxiv.org/abs/2210.04895"
            },
            {
                "文章ID": "89162",
                "标题": "Prompt Middleware: Mapping Prompts for Large Language Models to UI\n  Affordances",
                "作者": " Stephen MacNeil,  Andrew Tran,  Joanne Kim,  Ziheng Huang,  Seth Bernstein,  Dan Mogil",
                "发布日期": "2023-07-04",
                "摘要": "  To help users do complex work, researchers have developed techniques to\nintegrate AI and human intelligence into user interfaces (UIs). With the recent\nintroduction of large language models (LLMs), which can generate text in\nresponse to a natural language prompt, there are new opportunities to consider\nhow to integrate LLMs into UIs. We present Prompt Middleware, a framework for\ngenerating prompts for LLMs based on UI affordances. These include prompts that\nare predefined by experts (static prompts), generated from templates with\nfill-in options in the UI (template-based prompts), or created from scratch\n(free-form prompts). We demonstrate this framework with FeedbackBuffet, a\nwriting assistant that automatically generates feedback based on a user's text\ninput. Inspired by prior research showing how templates can help non-experts\nperform more like experts, FeedbackBuffet leverages template-based prompt\nmiddleware to enable feedback seekers to specify the types of feedback they\nwant to receive as options in a UI. These options are composed using a template\nto form a feedback request prompt to GPT-3. We conclude with a discussion about\nhow Prompt Middleware can help developers integrate LLMs into UIs.\n",
                "链接": "https://arxiv.org/abs/2307.01142"
            },
            {
                "文章ID": "79177",
                "标题": "G3Detector: General GPT-Generated Text Detector",
                "作者": " Haolan Zhan,  Xuanli He,  Qiongkai Xu,  Yuxiang Wu,  Pontus Stenetorp",
                "发布日期": "2023-08-07",
                "摘要": "  The burgeoning progress in the field of Large Language Models (LLMs) heralds\nsignificant benefits due to their unparalleled capacities. However, it is\ncritical to acknowledge the potential misuse of these models, which could give\nrise to a spectrum of social and ethical dilemmas. Despite numerous preceding\nefforts centered around distinguishing synthetic text, most existing detection\nsystems fail to identify data synthesized by the latest LLMs, such as ChatGPT\nand GPT-4. In response to this challenge, we introduce an unpretentious yet\npotent detection approach proficient in identifying synthetic text across a\nwide array of fields. Moreover, our detector demonstrates outstanding\nperformance uniformly across various model architectures and decoding\nstrategies. It also possesses the capability to identify text generated\nutilizing a potent detection-evasion technique. Our comprehensive research\nunderlines our commitment to boosting the robustness and efficiency of\nmachine-generated text detection mechanisms, particularly in the context of\nswiftly progressing and increasingly adaptive AI technologies.\n",
                "链接": "https://arxiv.org/abs/2305.12680"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "80632",
                "标题": "Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts",
                "作者": " Mohna Chakraborty,  Adithya Kulkarni,  Qi Li",
                "发布日期": "2023-07-04",
                "摘要": "  Recent studies have demonstrated that natural-language prompts can help to\nleverage the knowledge learned by pre-trained language models for the binary\nsentence-level sentiment classification task. Specifically, these methods\nutilize few-shot learning settings to fine-tune the sentiment classification\nmodel using manual or automatically generated prompts. However, the performance\nof these methods is sensitive to the perturbations of the utilized prompts.\nFurthermore, these methods depend on a few labeled instances for automatic\nprompt generation and prompt ranking. This study aims to find high-quality\nprompts for the given task in a zero-shot setting. Given a base prompt, our\nproposed approach automatically generates multiple prompts similar to the base\nprompt employing positional, reasoning, and paraphrasing techniques and then\nranks the prompts using a novel metric. We empirically demonstrate that the\ntop-ranked prompts are high-quality and significantly outperform the base\nprompt and the prompts generated using few-shot learning for the binary\nsentence-level sentiment classification task.\n",
                "链接": "https://arxiv.org/abs/2305.15689"
            },
            {
                "文章ID": "81774",
                "标题": "Attention Paper: How Generative AI Reshapes Digital Shadow Industry?",
                "作者": " Qichao Wang,  Huan Ma,  Wentao Wei,  Hangyu Li,  Liang Chen,  Peilin Zhao,  Binwen Zhao,  Bo Hu,  Shu Zhang,  Zibin Zheng,  Bingzhe Wu",
                "发布日期": "2023-05-31",
                "摘要": "  The rapid development of digital economy has led to the emergence of various\nblack and shadow internet industries, which pose potential risks that can be\nidentified and managed through digital risk management (DRM) that uses\ndifferent techniques such as machine learning and deep learning. The evolution\nof DRM architecture has been driven by changes in data forms. However, the\ndevelopment of AI-generated content (AIGC) technology, such as ChatGPT and\nStable Diffusion, has given black and shadow industries powerful tools to\npersonalize data and generate realistic images and conversations for fraudulent\nactivities. This poses a challenge for DRM systems to control risks from the\nsource of data generation and to respond quickly to the fast-changing risk\nenvironment. This paper aims to provide a technical analysis of the challenges\nand opportunities of AIGC from upstream, midstream, and downstream paths of\nblack/shadow industries and suggest future directions for improving existing\nrisk control systems. The paper will explore the new black and shadow\ntechniques triggered by generative AI technology and provide insights for\nbuilding the next-generation DRM system.\n",
                "链接": "https://arxiv.org/abs/2305.18346"
            },
            {
                "文章ID": "75775",
                "标题": "An automatically discovered chain-of-thought prompt generalizes to novel\n  models and datasets",
                "作者": " Konstantin Hebenstreit,  Robert Praas,  Louis P Kiesewetter,  Matthias Samwald",
                "发布日期": "2023-08-04",
                "摘要": "  Emergent chain-of-thought (CoT) reasoning capabilities promise to improve\nperformance and explainability of large language models (LLMs). However,\nuncertainties remain about how reasoning strategies formulated for previous\nmodel generations generalize to new model generations and different datasets.\nIn this small-scale study, we compare different reasoning strategies induced by\nzero-shot prompting across six recently released LLMs (davinci-002,\ndavinci-003, GPT-3.5-turbo, GPT-4, Flan-T5-xxl and Cohere command-xlarge) on a\nmixture of six question-answering datasets, including datasets from scientific\nand medical domains. Our findings demonstrate that while some variations in\neffectiveness occur, gains from CoT reasoning strategies remain robust across\ndifferent models and datasets. GPT-4 has the most benefit from current\nstate-of-the-art reasoning strategies and exhibits the best performance by\napplying a prompt previously discovered through automated discovery.\n",
                "链接": "https://arxiv.org/abs/2305.02897"
            },
            {
                "文章ID": "52695",
                "标题": "Demystifying Prompts in Language Models via Perplexity Estimation",
                "作者": " Hila Gonen,  Srini Iyer,  Terra Blevins,  Noah A. Smith,  Luke Zettlemoyer",
                "发布日期": "2022-12-09",
                "摘要": "  Language models can be prompted to perform a wide variety of zero- and\nfew-shot learning problems. However, performance varies significantly with the\nchoice of prompt, and we do not yet understand why this happens or how to pick\nthe best prompts. In this work, we analyze the factors that contribute to this\nvariance and establish a new empirical hypothesis: the performance of a prompt\nis coupled with the extent to which the model is familiar with the language it\ncontains. Over a wide range of tasks, we show that the lower the perplexity of\nthe prompt is, the better the prompt is able to perform the task. As a result,\nwe devise a method for creating prompts: (1) automatically extend a small seed\nset of manually written prompts by paraphrasing using GPT3 and backtranslation\nand (2) choose the lowest perplexity prompts to get significant gains in\nperformance.\n",
                "链接": "https://arxiv.org/abs/2212.04037"
            },
            {
                "文章ID": "60524",
                "标题": "Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt\n  Tuning and Discovery",
                "作者": " Yuxin Wen,  Neel Jain,  John Kirchenbauer,  Micah Goldblum,  Jonas Geiping,  Tom Goldstein",
                "发布日期": "2023-06-02",
                "摘要": "  The strength of modern generative models lies in their ability to be\ncontrolled through text-based prompts. Typical \"hard\" prompts are made from\ninterpretable words and tokens, and must be hand-crafted by humans. There are\nalso \"soft\" prompts, which consist of continuous feature vectors. These can be\ndiscovered using powerful optimization methods, but they cannot be easily\ninterpreted, re-used across models, or plugged into a text-based interface.\n  We describe an approach to robustly optimize hard text prompts through\nefficient gradient-based optimization. Our approach automatically generates\nhard text-based prompts for both text-to-image and text-to-text applications.\nIn the text-to-image setting, the method creates hard prompts for diffusion\nmodels, allowing API users to easily generate, discover, and mix and match\nimage concepts without prior knowledge on how to prompt the model. In the\ntext-to-text setting, we show that hard prompts can be automatically discovered\nthat are effective in tuning LMs for classification.\n",
                "链接": "https://arxiv.org/abs/2302.03668"
            },
            {
                "文章ID": "124983",
                "标题": "A Prompt Learning Framework for Source Code Summarization",
                "作者": " Weisong Sun,  Chunrong Fang,  Yudu You,  Yuchen Chen,  Yi Liu,  Chong Wang,  Jian Zhang,  Quanjun Zhang,  Hanwei Qian,  Wei Zhao,  Yang Liu,  Zhenyu Chen",
                "发布日期": "2023-12-27",
                "摘要": "  (Source) code summarization is the task of automatically generating natural\nlanguage summaries for given code snippets. Such summaries play a key role in\nhelping developers understand and maintain source code. Recently, with the\nsuccessful application of large language models (LLMs) in numerous fields,\nsoftware engineering researchers have also attempted to adapt LLMs to solve\ncode summarization tasks. The main adaptation schemes include instruction\nprompting and task-oriented fine-tuning. However, instruction prompting\ninvolves designing crafted prompts for zero-shot learning or selecting\nappropriate samples for few-shot learning and requires users to have\nprofessional domain knowledge, while task-oriented fine-tuning requires high\ntraining costs. In this paper, we propose a novel prompt learning framework for\ncode summarization called PromptCS. PromptCS trains a prompt agent that can\ngenerate continuous prompts to unleash the potential for LLMs in code\nsummarization. Compared to the human-written discrete prompt, the continuous\nprompts are produced under the guidance of LLMs and are therefore easier to\nunderstand by LLMs. PromptCS freezes the parameters of LLMs when training the\nprompt agent, which can greatly reduce the requirements for training resources.\nWe evaluate PromptCS on the CodeSearchNet dataset involving multiple\nprogramming languages. The results show that PromptCS significantly outperforms\ninstruction prompting schemes on all four widely used metrics. In some base\nLLMs, e.g., CodeGen-Multi-2B and StarCoderBase-1B and -3B, PromptCS even\noutperforms the task-oriented fine-tuning scheme. More importantly, the\ntraining efficiency of PromptCS is faster than the task-oriented fine-tuning\nscheme, with a more pronounced advantage on larger LLMs. The results of the\nhuman evaluation demonstrate that PromptCS can generate more good summaries\ncompared to baselines.\n",
                "链接": "https://arxiv.org/abs/2312.16066"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态agent, 具身智能的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "123652",
                "标题": "Urban Generative Intelligence (UGI): A Foundational Platform for Agents\n  in Embodied City Environment",
                "作者": " Fengli Xu,  Jun Zhang,  Chen Gao,  Jie Feng,  Yong Li",
                "发布日期": "2023-12-20",
                "摘要": "  Urban environments, characterized by their complex, multi-layered networks\nencompassing physical, social, economic, and environmental dimensions, face\nsignificant challenges in the face of rapid urbanization. These challenges,\nranging from traffic congestion and pollution to social inequality, call for\nadvanced technological interventions. Recent developments in big data,\nartificial intelligence, urban computing, and digital twins have laid the\ngroundwork for sophisticated city modeling and simulation. However, a gap\npersists between these technological capabilities and their practical\nimplementation in addressing urban challenges in an systemic-intelligent way.\nThis paper proposes Urban Generative Intelligence (UGI), a novel foundational\nplatform integrating Large Language Models (LLMs) into urban systems to foster\na new paradigm of urban intelligence. UGI leverages CityGPT, a foundation model\ntrained on city-specific multi-source data, to create embodied agents for\nvarious urban tasks. These agents, operating within a textual urban environment\nemulated by city simulator and urban knowledge graph, interact through a\nnatural language interface, offering an open platform for diverse intelligent\nand embodied agent development. This platform not only addresses specific urban\nissues but also simulates complex urban systems, providing a multidisciplinary\napproach to understand and manage urban complexity. This work signifies a\ntransformative step in city science and urban intelligence, harnessing the\npower of LLMs to unravel and address the intricate dynamics of urban systems.\nThe code repository with demonstrations will soon be released here\nhttps://github.com/tsinghua-fib-lab/UGI.\n",
                "链接": "https://arxiv.org/abs/2312.11813"
            },
            {
                "文章ID": "102059",
                "标题": "The Rise and Potential of Large Language Model Based Agents: A Survey",
                "作者": " Zhiheng Xi,  Wenxiang Chen,  Xin Guo,  Wei He,  Yiwen Ding,  Boyang Hong,  Ming Zhang,  Junzhe Wang,  Senjie Jin,  Enyu Zhou,  Rui Zheng,  Xiaoran Fan,  Xiao Wang,  Limao Xiong,  Yuhao Zhou,  Weiran Wang,  Changhao Jiang,  Yicheng Zou,  Xiangyang Liu,  Zhangyue Yin,  Shihan Dou,  Rongxiang Weng,  Wensen Cheng,  Qi Zhang,  Wenjuan Qin,  Yongyan Zheng,  Xipeng Qiu,  Xuanjing Huang,  Tao Gui",
                "发布日期": "2023-09-20",
                "摘要": "  For a long time, humanity has pursued artificial intelligence (AI) equivalent\nto or surpassing the human level, with AI agents considered a promising vehicle\nfor this pursuit. AI agents are artificial entities that sense their\nenvironment, make decisions, and take actions. Many efforts have been made to\ndevelop intelligent agents, but they mainly focus on advancement in algorithms\nor training strategies to enhance specific capabilities or performance on\nparticular tasks. Actually, what the community lacks is a general and powerful\nmodel to serve as a starting point for designing AI agents that can adapt to\ndiverse scenarios. Due to the versatile capabilities they demonstrate, large\nlanguage models (LLMs) are regarded as potential sparks for Artificial General\nIntelligence (AGI), offering hope for building general AI agents. Many\nresearchers have leveraged LLMs as the foundation to build AI agents and have\nachieved significant progress. In this paper, we perform a comprehensive survey\non LLM-based agents. We start by tracing the concept of agents from its\nphilosophical origins to its development in AI, and explain why LLMs are\nsuitable foundations for agents. Building upon this, we present a general\nframework for LLM-based agents, comprising three main components: brain,\nperception, and action, and the framework can be tailored for different\napplications. Subsequently, we explore the extensive applications of LLM-based\nagents in three aspects: single-agent scenarios, multi-agent scenarios, and\nhuman-agent cooperation. Following this, we delve into agent societies,\nexploring the behavior and personality of LLM-based agents, the social\nphenomena that emerge from an agent society, and the insights they offer for\nhuman society. Finally, we discuss several key topics and open problems within\nthe field. A repository for the related papers at\nhttps://github.com/WooooDyy/LLM-Agent-Paper-List.\n",
                "链接": "https://arxiv.org/abs/2309.07864"
            },
            {
                "文章ID": "53365",
                "标题": "Generative artificial intelligence-enabled dynamic detection of\n  nicotine-related circuits",
                "作者": " Changwei Gong,  Changhong Jing,  Ye Li,  Xinan Liu,  Zuxin Chen,  Shuqiang Wang",
                "发布日期": "2022-12-14",
                "摘要": "  The identification of addiction-related circuits is critical for explaining\naddiction processes and developing addiction treatments. And models of\nfunctional addiction circuits developed from functional imaging are an\neffective tool for discovering and verifying addiction circuits. However,\nanalyzing functional imaging data of addiction and detecting functional\naddiction circuits still have challenges. We have developed a data-driven and\nend-to-end generative artificial intelligence(AI) framework to address these\ndifficulties. The framework integrates dynamic brain network modeling and novel\nnetwork architecture networks architecture, including temporal graph\nTransformer and contrastive learning modules. A complete workflow is formed by\nour generative AI framework: the functional imaging data, from neurobiological\nexperiments, and computational modeling, to end-to-end neural networks, is\ntransformed into dynamic nicotine addiction-related circuits. It enables the\ndetection of addiction-related brain circuits with dynamic properties and\nreveals the underlying mechanisms of addiction.\n",
                "链接": "https://arxiv.org/abs/2212.06330"
            },
            {
                "文章ID": "114225",
                "标题": "Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI",
                "作者": " Song Yaoxian,  Sun Penglei,  Liu Haoyu,  Li Zhixu,  Song Wei,  Xiao Yanghua,  Zhou Xiaofang",
                "发布日期": "2023-11-08",
                "摘要": "  Embodied AI is one of the most popular studies in artificial intelligence and\nrobotics, which can effectively improve the intelligence of real-world agents\n(i.e. robots) serving human beings. Scene knowledge is important for an agent\nto understand the surroundings and make correct decisions in the varied open\nworld. Currently, knowledge base for embodied tasks is missing and most\nexisting work use general knowledge base or pre-trained models to enhance the\nintelligence of an agent. For conventional knowledge base, it is sparse,\ninsufficient in capacity and cost in data collection. For pre-trained models,\nthey face the uncertainty of knowledge and hard maintenance. To overcome the\nchallenges of scene knowledge, we propose a scene-driven multimodal knowledge\ngraph (Scene-MMKG) construction method combining conventional knowledge\nengineering and large language models. A unified scene knowledge injection\nframework is introduced for knowledge representation. To evaluate the\nadvantages of our proposed method, we instantiate Scene-MMKG considering\ntypical indoor robotic functionalities (Manipulation and Mobility), named\nManipMob-MMKG. Comparisons in characteristics indicate our instantiated\nManipMob-MMKG has broad superiority in data-collection efficiency and knowledge\nquality. Experimental results on typical embodied tasks show that\nknowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the\nperformance obviously without re-designing model structures complexly. Our\nproject can be found at https://sites.google.com/view/manipmob-mmkg\n",
                "链接": "https://arxiv.org/abs/2311.03783"
            },
            {
                "文章ID": "63780",
                "标题": "Multimodal Speech Recognition for Language-Guided Embodied Agents",
                "作者": " Allen Chang,  Xiaoyuan Zhu,  Aarav Monga,  Seoho Ahn,  Tejas Srinivasan,  Jesse Thomason",
                "发布日期": "2023-10-11",
                "摘要": "  Benchmarks for language-guided embodied agents typically assume text-based\ninstructions, but deployed agents will encounter spoken instructions. While\nAutomatic Speech Recognition (ASR) models can bridge the input gap, erroneous\nASR transcripts can hurt the agents' ability to complete tasks. In this work,\nwe propose training a multimodal ASR model to reduce errors in transcribing\nspoken instructions by considering the accompanying visual context. We train\nour model on a dataset of spoken instructions, synthesized from the ALFRED task\ncompletion dataset, where we simulate acoustic noise by systematically masking\nspoken words. We find that utilizing visual observations facilitates masked\nword recovery, with multimodal ASR models recovering up to 30% more masked\nwords than unimodal baselines. We also find that a text-trained embodied agent\nsuccessfully completes tasks more often by following transcribed instructions\nfrom multimodal ASR models. github.com/Cylumn/embodied-multimodal-asr\n",
                "链接": "https://arxiv.org/abs/2302.14030"
            },
            {
                "文章ID": "2627",
                "标题": "A Method to Predict Semantic Relations on Artificial Intelligence Papers",
                "作者": " Francisco Andrades,  Ricardo Ñanculef",
                "发布日期": "2022-01-26",
                "摘要": "  Predicting the emergence of links in large evolving networks is a difficult\ntask with many practical applications. Recently, the Science4cast competition\nhas illustrated this challenge presenting a network of 64.000 AI concepts and\nasking the participants to predict which topics are going to be researched\ntogether in the future. In this paper, we present a solution to this problem\nbased on a new family of deep learning approaches, namely Graph Neural\nNetworks. The results of the challenge show that our solution is competitive\neven if we had to impose severe restrictions to obtain a computationally\nefficient and parsimonious model: ignoring the intrinsic dynamics of the graph\nand using only a small subset of the nodes surrounding a target link.\nPreliminary experiments presented in this paper suggest the model is learning\ntwo related, but different patterns: the absorption of a node by a sub-graph\nand union of more dense sub-graphs. The model seems to excel at recognizing the\nfirst type of pattern.\n",
                "链接": "https://arxiv.org/abs/2201.10518"
            },
            {
                "文章ID": "7214",
                "标题": "Integrated multimodal artificial intelligence framework for healthcare\n  applications",
                "作者": " Luis R. Soenksen,  Yu Ma,  Cynthia Zeng,  Leonard D. J. Boussioux,  Kimberly Villalobos Carballo,  Liangyuan Na,  Holly M. Wiberg,  Michael L. Li,  Ignacio Fuentes,  Dimitris Bertsimas",
                "发布日期": "2022-09-28",
                "摘要": "  Artificial intelligence (AI) systems hold great promise to improve healthcare\nover the next decades. Specifically, AI systems leveraging multiple data\nsources and input modalities are poised to become a viable method to deliver\nmore accurate results and deployable pipelines across a wide range of\napplications. In this work, we propose and evaluate a unified Holistic AI in\nMedicine (HAIM) framework to facilitate the generation and testing of AI\nsystems that leverage multimodal inputs. Our approach uses generalizable data\npre-processing and machine learning modeling stages that can be readily adapted\nfor research and deployment in healthcare environments. We evaluate our HAIM\nframework by training and characterizing 14,324 independent models based on\nHAIM-MIMIC-MM, a multimodal clinical database (N=34,537 samples) containing\n7,279 unique hospitalizations and 6,485 patients, spanning all possible input\ncombinations of 4 data modalities (i.e., tabular, time-series, text, and\nimages), 11 unique data sources and 12 predictive tasks. We show that this\nframework can consistently and robustly produce models that outperform similar\nsingle-source approaches across various healthcare demonstrations (by 6-33%),\nincluding 10 distinct chest pathology diagnoses, along with length-of-stay and\n48-hour mortality predictions. We also quantify the contribution of each\nmodality and data source using Shapley values, which demonstrates the\nheterogeneity in data modality importance and the necessity of multimodal\ninputs across different healthcare-relevant tasks. The generalizable properties\nand flexibility of our Holistic AI in Medicine (HAIM) framework could offer a\npromising pathway for future multimodal predictive systems in clinical and\noperational healthcare settings.\n",
                "链接": "https://arxiv.org/abs/2202.12998"
            },
            {
                "文章ID": "81277",
                "标题": "Integrating Generative Artificial Intelligence in Intelligent Vehicle\n  Systems",
                "作者": " Lukas Stappen,  Jeremy Dillmann,  Serena Striegel,  Hans-Jörg Vögel,  Nicolas Flores-Herr,  Björn W. Schuller",
                "发布日期": "2023-05-30",
                "摘要": "  This paper aims to serve as a comprehensive guide for researchers and\npractitioners, offering insights into the current state, potential\napplications, and future research directions for generative artificial\nintelligence and foundation models within the context of intelligent vehicles.\nAs the automotive industry progressively integrates AI, generative artificial\nintelligence technologies hold the potential to revolutionize user\ninteractions, delivering more immersive, intuitive, and personalised in-car\nexperiences. We provide an overview of current applications of generative\nartificial intelligence in the automotive domain, emphasizing speech, audio,\nvision, and multimodal interactions. We subsequently outline critical future\nresearch areas, including domain adaptability, alignment, multimodal\nintegration and others, as well as, address the challenges and risks associated\nwith ethics. By fostering collaboration and addressing these research areas,\ngenerative artificial intelligence can unlock its full potential, transforming\nthe driving experience and shaping the future of intelligent vehicles.\n",
                "链接": "https://arxiv.org/abs/2305.17137"
            },
            {
                "文章ID": "78677",
                "标题": "Artificial intelligence moral agent as Adam Smith's impartial spectator",
                "作者": " Nikodem Tomczak",
                "发布日期": "2023-05-22",
                "摘要": "  Adam Smith developed a version of moral philosophy where better decisions are\nmade by interrogating an impartial spectator within us. We discuss the\npossibility of using an external non-human-based substitute tool that would\naugment our internal mental processes and play the role of the impartial\nspectator. Such tool would have more knowledge about the world, be more\nimpartial, and would provide a more encompassing perspective on moral\nassessment.\n",
                "链接": "https://arxiv.org/abs/2305.11519"
            },
            {
                "文章ID": "61287",
                "标题": "Universal Agent Mixtures and the Geometry of Intelligence",
                "作者": " Samuel Allen Alexander,  David Quarel,  Len Du,  Marcus Hutter",
                "发布日期": "2023-02-14",
                "摘要": "  Inspired by recent progress in multi-agent Reinforcement Learning (RL), in\nthis work we examine the collective intelligent behaviour of theoretical\nuniversal agents by introducing a weighted mixture operation. Given a weighted\nset of agents, their weighted mixture is a new agent whose expected total\nreward in any environment is the corresponding weighted average of the original\nagents' expected total rewards in that environment. Thus, if RL agent\nintelligence is quantified in terms of performance across environments, the\nweighted mixture's intelligence is the weighted average of the original agents'\nintelligences. This operation enables various interesting new theorems that\nshed light on the geometry of RL agent intelligence, namely: results about\nsymmetries, convex agent-sets, and local extrema. We also show that any RL\nagent intelligence measure based on average performance across environments,\nsubject to certain weak technical conditions, is identical (up to a constant\nfactor) to performance within a single environment dependent on said\nintelligence measure.\n",
                "链接": "https://arxiv.org/abs/2302.06083"
            }
        ]
    },
    {
        "question": {
            "question": "新的大模型结构相关探索的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "103034",
                "标题": "Interactive Distillation of Large Single-Topic Corpora of Scientific\n  Papers",
                "作者": " Nicholas Solovyev,  Ryan Barron,  Manish Bhattarai,  Maksim E. Eren,  Kim O. Rasmussen,  Boian S. Alexandrov",
                "发布日期": "2023-09-20",
                "摘要": "  Highly specific datasets of scientific literature are important for both\nresearch and education. However, it is difficult to build such datasets at\nscale. A common approach is to build these datasets reductively by applying\ntopic modeling on an established corpus and selecting specific topics. A more\nrobust but time-consuming approach is to build the dataset constructively in\nwhich a subject matter expert (SME) handpicks documents. This method does not\nscale and is prone to error as the dataset grows. Here we showcase a new tool,\nbased on machine learning, for constructively generating targeted datasets of\nscientific literature. Given a small initial \"core\" corpus of papers, we build\na citation network of documents. At each step of the citation network, we\ngenerate text embeddings and visualize the embeddings through dimensionality\nreduction. Papers are kept in the dataset if they are \"similar\" to the core or\nare otherwise pruned through human-in-the-loop selection. Additional insight\ninto the papers is gained through sub-topic modeling using SeNMFk. We\ndemonstrate our new tool for literature review by applying it to two different\nfields in machine learning.\n",
                "链接": "https://arxiv.org/abs/2309.10772"
            },
            {
                "文章ID": "107503",
                "标题": "An evolutionary model of personality traits related to cooperative\n  behavior using a large language model",
                "作者": " Reiji Suzuki,  Takaya Arita",
                "发布日期": "2023-10-11",
                "摘要": "  This paper aims to shed light on the evolutionary dynamics of diverse and\nsocial populations by introducing the rich expressiveness of generative models\ninto the trait expression of social agent-based evolutionary models.\nSpecifically, we focus on the evolution of personality traits in the context of\na game-theoretic relationship as a situation in which inter-individual\ninterests exert strong selection pressures. We construct an agent model in\nwhich linguistic descriptions of personality traits related to cooperative\nbehavior are used as genes. The deterministic strategies extracted from Large\nLanguage Model (LLM) that make behavioral decisions based on these personality\ntraits are used as behavioral traits. The population is evolved according to\nselection based on average payoff and mutation of genes by asking LLM to\nslightly modify the parent gene toward cooperative or selfish. Through\npreliminary experiments and analyses, we clarify that such a model can indeed\nexhibit the evolution of cooperative behavior based on the diverse and\nhigher-order representation of personality traits. We also observed the\nrepeated intrusion of cooperative and selfish personality traits through\nchanges in the expression of personality traits, and found that the emerging\nwords in the evolved gene well reflected the behavioral tendency of its\npersonality in terms of their semantics.\n",
                "链接": "https://arxiv.org/abs/2310.05976"
            },
            {
                "文章ID": "69949",
                "标题": "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language\n  Model Society",
                "作者": " Guohao Li,  Hasan Abed Al Kader Hammoud,  Hani Itani,  Dmitrii Khizbullin,  Bernard Ghanem",
                "发布日期": "2023-11-03",
                "摘要": "  The rapid advancement of chat-based language models has led to remarkable\nprogress in complex task-solving. However, their success heavily relies on\nhuman input to guide the conversation, which can be challenging and\ntime-consuming. This paper explores the potential of building scalable\ntechniques to facilitate autonomous cooperation among communicative agents, and\nprovides insight into their \"cognitive\" processes. To address the challenges of\nachieving autonomous cooperation, we propose a novel communicative agent\nframework named role-playing. Our approach involves using inception prompting\nto guide chat agents toward task completion while maintaining consistency with\nhuman intentions. We showcase how role-playing can be used to generate\nconversational data for studying the behaviors and capabilities of a society of\nagents, providing a valuable resource for investigating conversational language\nmodels. In particular, we conduct comprehensive studies on\ninstruction-following cooperation in multi-agent settings. Our contributions\ninclude introducing a novel communicative agent framework, offering a scalable\napproach for studying the cooperative behaviors and capabilities of multi-agent\nsystems, and open-sourcing our library to support research on communicative\nagents and beyond: https://github.com/camel-ai/camel.\n",
                "链接": "https://arxiv.org/abs/2303.17760"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "116872",
                "标题": "Causal Structure Learning Supervised by Large Language Model",
                "作者": " Taiyu Ban,  Lyuzhou Chen,  Derui Lyu,  Xiangyu Wang,  Huanhuan Chen",
                "发布日期": "2023-11-21",
                "摘要": "  Causal discovery from observational data is pivotal for deciphering complex\nrelationships. Causal Structure Learning (CSL), which focuses on deriving\ncausal Directed Acyclic Graphs (DAGs) from data, faces challenges due to vast\nDAG spaces and data sparsity. The integration of Large Language Models (LLMs),\nrecognized for their causal reasoning capabilities, offers a promising\ndirection to enhance CSL by infusing it with knowledge-based causal inferences.\nHowever, existing approaches utilizing LLMs for CSL have encountered issues,\nincluding unreliable constraints from imperfect LLM inferences and the\ncomputational intensity of full pairwise variable analyses. In response, we\nintroduce the Iterative LLM Supervised CSL (ILS-CSL) framework. ILS-CSL\ninnovatively integrates LLM-based causal inference with CSL in an iterative\nprocess, refining the causal DAG using feedback from LLMs. This method not only\nutilizes LLM resources more efficiently but also generates more robust and\nhigh-quality structural constraints compared to previous methodologies. Our\ncomprehensive evaluation across eight real-world datasets demonstrates\nILS-CSL's superior performance, setting a new standard in CSL efficacy and\nshowcasing its potential to significantly advance the field of causal\ndiscovery. The codes are available at\n\\url{https://github.com/tyMadara/ILS-CSL}.\n",
                "链接": "https://arxiv.org/abs/2311.11689"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "18762",
                "标题": "Recommending Research Papers to Chemists: A Specialized Interface for\n  Chemical Entity Exploration",
                "作者": " Corinna Breitinger,  Kay Herklotz,  Tim Flegelskamp,  Norman Meuschke",
                "发布日期": "2022-05-12",
                "摘要": "  Researchers and scientists increasingly rely on specialized information\nretrieval (IR) or recommendation systems (RS) to support them in their daily\nresearch tasks. Paper recommender systems are one such tool scientists use to\nstay on top of the ever-increasing number of academic publications in their\nfield. Improving research paper recommender systems is an active research\nfield. However, less research has focused on how the interfaces of research\npaper recommender systems can be tailored to suit the needs of different\nresearch domains. For example, in the field of biomedicine and chemistry,\nresearchers are not only interested in textual relevance but may also want to\ndiscover or compare the contained chemical entity information found in a\npaper's full text. Existing recommender systems for academic literature do not\nsupport the discovery of this non-textual, but semantically valuable, chemical\nentity data. We present the first implementation of a specialized chemistry\npaper recommender system capable of visualizing the contained chemical\nstructures, chemical formulae, and synonyms for chemical compounds within the\ndocument's full text. We review existing tools and related research in this\nfield before describing the implementation of our ChemVis system. With the help\nof chemists, we are expanding the functionality of ChemVis, and will perform an\nevaluation of recommendation performance and usability in future work.\n",
                "链接": "https://arxiv.org/abs/2205.05414"
            },
            {
                "文章ID": "68450",
                "标题": "ChatGPT and a New Academic Reality: Artificial Intelligence-Written\n  Research Papers and the Ethics of the Large Language Models in Scholarly\n  Publishing",
                "作者": " Brady Lund,  Ting Wang,  Nishith Reddy Mannuru,  Bing Nie,  Somipam Shimray,  Ziang Wang",
                "发布日期": "2023-04-03",
                "摘要": "  This paper discusses OpenAIs ChatGPT, a generative pre-trained transformer,\nwhich uses natural language processing to fulfill text-based user requests\n(i.e., a chatbot). The history and principles behind ChatGPT and similar models\nare discussed. This technology is then discussed in relation to its potential\nimpact on academia and scholarly research and publishing. ChatGPT is seen as a\npotential model for the automated preparation of essays and other types of\nscholarly manuscripts. Potential ethical issues that could arise with the\nemergence of large language models like GPT-3, the underlying technology behind\nChatGPT, and its usage by academics and researchers, are discussed and situated\nwithin the context of broader advancements in artificial intelligence, machine\nlearning, and natural language processing for research and scholarly\npublishing.\n",
                "链接": "https://arxiv.org/abs/2303.13367"
            },
            {
                "文章ID": "87136",
                "标题": "From structure mining to unsupervised exploration of atomic octahedral\n  networks",
                "作者": " R. Patrick Xian,  Ryan J. Morelock,  Ido Hadar,  Charles B. Musgrave,  Christopher Sutton",
                "发布日期": "2023-06-22",
                "摘要": "  Networks of atom-centered coordination octahedra commonly occur in inorganic\nand hybrid solid-state materials. Characterizing their spatial arrangements and\ncharacteristics is crucial for relating structures to properties for many\nmaterials families. The traditional method using case-by-case inspection\nbecomes prohibitive for discovering trends and similarities in large datasets.\nHere, we operationalize chemical intuition to automate the geometric parsing,\nquantification, and classification of coordination octahedral networks. We find\naxis-resolved tilting trends in ABO$_{3}$ perovskite polymorphs, which assist\nin detecting oxidation state changes. Moreover, we develop a scale-invariant\nencoding scheme to represent these networks, which, combined with\nhuman-assisted unsupervised machine learning, allows us to taxonomize the\ninorganic framework polytypes in hybrid iodoplumbates (A$_x$Pb$_y$I$_z$).\nConsequently, we uncover a violation of Pauling's third rule and the design\nprinciples underpinning their topological diversity. Our results offer a\nglimpse into the vast design space of atomic octahedral networks and inform\nhigh-throughput, targeted screening of specific structure types.\n",
                "链接": "https://arxiv.org/abs/2306.12272"
            },
            {
                "文章ID": "125173",
                "标题": "A Large Language Model-based Computational Approach to Improve\n  Identity-Related Write-Ups",
                "作者": " Alex Doboli",
                "发布日期": "2023-12-29",
                "摘要": "  Creating written products is essential to modern life, including writings\nabout one's identity and personal experiences. However, writing is often a\ndifficult activity that requires extensive effort to frame the central ideas,\nthe pursued approach to communicate the central ideas, e.g., using analogies,\nmetaphors, or other possible means, the needed presentation structure, and the\nactual verbal expression. Large Language Models, a recently emerged approach in\nMachine Learning, can offer a significant help in reducing the effort and\nimproving the quality of written products. This paper proposes a new\ncomputational approach to explore prompts that given as inputs to a Large\nLanguage Models can generate cues to improve the considered written products.\nTwo case studies on improving write-ups, one based on an analogy and one on a\nmetaphor, are also presented in the paper.\n",
                "链接": "https://arxiv.org/abs/2312.16659"
            }
        ]
    },
    {
        "question": {
            "question": "多模态细粒度图片编辑和生成相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "124621",
                "标题": "FineMoGen: Fine-Grained Spatio-Temporal Motion Generation and Editing",
                "作者": " Mingyuan Zhang,  Huirong Li,  Zhongang Cai,  Jiawei Ren,  Lei Yang,  Ziwei Liu",
                "发布日期": "2023-12-27",
                "摘要": "  Text-driven motion generation has achieved substantial progress with the\nemergence of diffusion models. However, existing methods still struggle to\ngenerate complex motion sequences that correspond to fine-grained descriptions,\ndepicting detailed and accurate spatio-temporal actions. This lack of fine\ncontrollability limits the usage of motion generation to a larger audience. To\ntackle these challenges, we present FineMoGen, a diffusion-based motion\ngeneration and editing framework that can synthesize fine-grained motions, with\nspatial-temporal composition to the user instructions. Specifically, FineMoGen\nbuilds upon diffusion model with a novel transformer architecture dubbed\nSpatio-Temporal Mixture Attention (SAMI). SAMI optimizes the generation of the\nglobal attention template from two perspectives: 1) explicitly modeling the\nconstraints of spatio-temporal composition; and 2) utilizing sparsely-activated\nmixture-of-experts to adaptively extract fine-grained features. To facilitate a\nlarge-scale study on this new fine-grained motion generation task, we\ncontribute the HuMMan-MoGen dataset, which consists of 2,968 videos and 102,336\nfine-grained spatio-temporal descriptions. Extensive experiments validate that\nFineMoGen exhibits superior motion generation quality over state-of-the-art\nmethods. Notably, FineMoGen further enables zero-shot motion editing\ncapabilities with the aid of modern large language models (LLM), which\nfaithfully manipulates motion sequences with fine-grained instructions. Project\nPage: https://mingyuan-zhang.github.io/projects/FineMoGen.html\n",
                "链接": "https://arxiv.org/abs/2312.15004"
            },
            {
                "文章ID": "13260",
                "标题": "Flexible Portrait Image Editing with Fine-Grained Control",
                "作者": " Linlin Liu,  Qian Fu,  Fei Hou,  Ying He",
                "发布日期": "2022-04-05",
                "摘要": "  We develop a new method for portrait image editing, which supports\nfine-grained editing of geometries, colors, lights and shadows using a single\nneural network model. We adopt a novel asymmetric conditional GAN architecture:\nthe generators take the transformed conditional inputs, such as edge maps,\ncolor palette, sliders and masks, that can be directly edited by the user; the\ndiscriminators take the conditional inputs in the way that can guide\ncontrollable image generation more effectively. Taking color editing as an\nexample, we feed color palettes (which can be edited easily) into the\ngenerator, and color maps (which contain positional information of colors) into\nthe discriminator. We also design a region-weighted discriminator so that\nhigher weights are assigned to more important regions, like eyes and skin.\nUsing a color palette, the user can directly specify the desired colors of\nhair, skin, eyes, lip and background. Color sliders allow the user to blend\ncolors in an intuitive manner. The user can also edit lights and shadows by\nmodifying the corresponding masks. We demonstrate the effectiveness of our\nmethod by evaluating it on the CelebAMask-HQ dataset with a wide range of\ntasks, including geometry/color/shadow/light editing, hand-drawn sketch to\nimage translation, and color transfer. We also present ablation studies to\njustify our design.\n",
                "链接": "https://arxiv.org/abs/2204.01318"
            },
            {
                "文章ID": "39047",
                "标题": "Towards Fine-Dining Recipe Generation with Generative Pre-trained\n  Transformers",
                "作者": " Konstantinos Katserelis,  Konstantinos Skianis",
                "发布日期": "2022-09-27",
                "摘要": "  Food is essential to human survival. So much so that we have developed\ndifferent recipes to suit our taste needs. In this work, we propose a novel way\nof creating new, fine-dining recipes from scratch using Transformers,\nspecifically auto-regressive language models. Given a small dataset of food\nrecipes, we try to train models to identify cooking techniques, propose novel\nrecipes, and test the power of fine-tuning with minimal data.\n",
                "链接": "https://arxiv.org/abs/2209.12774"
            },
            {
                "文章ID": "52126",
                "标题": "Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models",
                "作者": " Naoki Matsunaga,  Masato Ishii,  Akio Hayakawa,  Kenji Suzuki,  Takuya Narihira",
                "发布日期": "2023-06-01",
                "摘要": "  Our goal is to develop fine-grained real-image editing methods suitable for\nreal-world applications. In this paper, we first summarize four requirements\nfor these methods and propose a novel diffusion-based image editing framework\nwith pixel-wise guidance that satisfies these requirements. Specifically, we\ntrain pixel-classifiers with a few annotated data and then infer the\nsegmentation map of a target image. Users then manipulate the map to instruct\nhow the image will be edited. We utilize a pre-trained diffusion model to\ngenerate edited images aligned with the user's intention with pixel-wise\nguidance. The effective combination of proposed guidance and other techniques\nenables highly controllable editing with preserving the outside of the edited\narea, which results in meeting our requirements. The experimental results\ndemonstrate that our proposal outperforms the GAN-based method for editing\nquality and speed.\n",
                "链接": "https://arxiv.org/abs/2212.02024"
            },
            {
                "文章ID": "123024",
                "标题": "Focus on Your Instruction: Fine-grained and Multi-instruction Image\n  Editing by Attention Modulation",
                "作者": " Qin Guo,  Tianwei Lin",
                "发布日期": "2023-12-19",
                "摘要": "  Recently, diffusion-based methods, like InstructPix2Pix (IP2P), have achieved\neffective instruction-based image editing, requiring only natural language\ninstructions from the user. However, these methods often inadvertently alter\nunintended areas and struggle with multi-instruction editing, resulting in\ncompromised outcomes. To address these issues, we introduce the Focus on Your\nInstruction (FoI), a method designed to ensure precise and harmonious editing\nacross multiple instructions without extra training or test-time optimization.\nIn the FoI, we primarily emphasize two aspects: (1) precisely extracting\nregions of interest for each instruction and (2) guiding the denoising process\nto concentrate within these regions of interest. For the first objective, we\nidentify the implicit grounding capability of IP2P from the cross-attention\nbetween instruction and image, then develop an effective mask extraction\nmethod. For the second objective, we introduce a cross attention modulation\nmodule for rough isolation of target editing regions and unrelated regions.\nAdditionally, we introduce a mask-guided disentangle sampling strategy to\nfurther ensure clear region isolation. Experimental results demonstrate that\nFoI surpasses existing methods in both quantitative and qualitative\nevaluations, especially excelling in multi-instruction editing task.\n",
                "链接": "https://arxiv.org/abs/2312.10113"
            },
            {
                "文章ID": "124901",
                "标题": "SERF: Fine-Grained Interactive 3D Segmentation and Editing with Radiance\n  Fields",
                "作者": " Kaichen Zhou,  Lanqing Hong,  Enze Xie,  Yongxin Yang,  Zhenguo Li,  Wei Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Although significant progress has been made in the field of 2D-based\ninteractive editing, fine-grained 3D-based interactive editing remains\nrelatively unexplored. This limitation can be attributed to two main\nchallenges: the lack of an efficient 3D representation robust to different\nmodifications and the absence of an effective 3D interactive segmentation\nmethod. In this paper, we introduce a novel fine-grained interactive 3D\nsegmentation and editing algorithm with radiance fields, which we refer to as\nSERF. Our method entails creating a neural mesh representation by integrating\nmulti-view algorithms with pre-trained 2D models. Building upon this\nrepresentation, we introduce a novel surface rendering technique that preserves\nlocal information and is robust to deformation. Moreover, this representation\nforms the basis for achieving accurate and interactive 3D segmentation without\nrequiring 3D supervision. Harnessing this representation facilitates a range of\ninteractive 3D editing operations, encompassing tasks such as interactive\ngeometry editing and texture painting. Extensive experiments and visualization\nexamples of editing on both real and synthetic data demonstrate the superiority\nof our method on representation quality and editing ability.\n",
                "链接": "https://arxiv.org/abs/2312.15856"
            },
            {
                "文章ID": "61490",
                "标题": "Relatedly: Scaffolding Literature Reviews with Existing Related Work\n  Sections",
                "作者": " Srishti Palani,  Aakanksha Naik,  Doug Downey,  Amy X. Zhang,  Jonathan Bragg,  Joseph Chee Chang",
                "发布日期": "2023-02-15",
                "摘要": "  Scholars who want to research a scientific topic must take time to read,\nextract meaning, and identify connections across many papers. As scientific\nliterature grows, this becomes increasingly challenging. Meanwhile, authors\nsummarize prior research in papers' related work sections, though this is\nscoped to support a single paper. A formative study found that while reading\nmultiple related work paragraphs helps overview a topic, it is hard to navigate\noverlapping and diverging references and research foci. In this work, we design\na system, Relatedly, that scaffolds exploring and reading multiple related work\nparagraphs on a topic, with features including dynamic re-ranking and\nhighlighting to spotlight unexplored dissimilar information, auto-generated\ndescriptive paragraph headings, and low-lighting of redundant information. From\na within-subjects user study (n=15), we found that scholars generate more\ncoherent, insightful, and comprehensive topic outlines using Relatedly compared\nto a baseline paper list.\n",
                "链接": "https://arxiv.org/abs/2302.06754"
            },
            {
                "文章ID": "96626",
                "标题": "DragNUWA: Fine-grained Control in Video Generation by Integrating Text,\n  Image, and Trajectory",
                "作者": " Shengming Yin,  Chenfei Wu,  Jian Liang,  Jie Shi,  Houqiang Li,  Gong Ming,  Nan Duan",
                "发布日期": "2023-08-17",
                "摘要": "  Controllable video generation has gained significant attention in recent\nyears. However, two main limitations persist: Firstly, most existing works\nfocus on either text, image, or trajectory-based control, leading to an\ninability to achieve fine-grained control in videos. Secondly, trajectory\ncontrol research is still in its early stages, with most experiments being\nconducted on simple datasets like Human3.6M. This constraint limits the models'\ncapability to process open-domain images and effectively handle complex curved\ntrajectories. In this paper, we propose DragNUWA, an open-domain\ndiffusion-based video generation model. To tackle the issue of insufficient\ncontrol granularity in existing works, we simultaneously introduce text, image,\nand trajectory information to provide fine-grained control over video content\nfrom semantic, spatial, and temporal perspectives. To resolve the problem of\nlimited open-domain trajectory control in current research, We propose\ntrajectory modeling with three aspects: a Trajectory Sampler (TS) to enable\nopen-domain control of arbitrary trajectories, a Multiscale Fusion (MF) to\ncontrol trajectories in different granularities, and an Adaptive Training (AT)\nstrategy to generate consistent videos following trajectories. Our experiments\nvalidate the effectiveness of DragNUWA, demonstrating its superior performance\nin fine-grained control in video generation. The homepage link is\n\\url{https://www.microsoft.com/en-us/research/project/dragnuwa/}\n",
                "链接": "https://arxiv.org/abs/2308.08089"
            },
            {
                "文章ID": "80167",
                "标题": "BLIP-Diffusion: Pre-trained Subject Representation for Controllable\n  Text-to-Image Generation and Editing",
                "作者": " Dongxu Li,  Junnan Li,  Steven C. H. Hoi",
                "发布日期": "2023-06-23",
                "摘要": "  Subject-driven text-to-image generation models create novel renditions of an\ninput subject based on text prompts. Existing models suffer from lengthy\nfine-tuning and difficulties preserving the subject fidelity. To overcome these\nlimitations, we introduce BLIP-Diffusion, a new subject-driven image generation\nmodel that supports multimodal control which consumes inputs of subject images\nand text prompts. Unlike other subject-driven generation models, BLIP-Diffusion\nintroduces a new multimodal encoder which is pre-trained to provide subject\nrepresentation. We first pre-train the multimodal encoder following BLIP-2 to\nproduce visual representation aligned with the text. Then we design a subject\nrepresentation learning task which enables a diffusion model to leverage such\nvisual representation and generates new subject renditions. Compared with\nprevious methods such as DreamBooth, our model enables zero-shot subject-driven\ngeneration, and efficient fine-tuning for customized subject with up to 20x\nspeedup. We also demonstrate that BLIP-Diffusion can be flexibly combined with\nexisting techniques such as ControlNet and prompt-to-prompt to enable novel\nsubject-driven generation and editing applications. Code and models will be\nreleased at\nhttps://github.com/salesforce/LAVIS/tree/main/projects/blip-diffusion. Project\npage at https://dxli94.github.io/BLIP-Diffusion-website/.\n",
                "链接": "https://arxiv.org/abs/2305.14720"
            },
            {
                "文章ID": "117252",
                "标题": "A Fine-Grained Image Description Generation Method Based on Joint\n  Objectives",
                "作者": " Yifan Zhang,  Chunzhen Lin,  Donglin Cao,  Dazhen Lin",
                "发布日期": "2023-11-23",
                "摘要": "  The goal of fine-grained image description generation techniques is to learn\ndetailed information from images and simulate human-like descriptions that\nprovide coherent and comprehensive textual details about the image content.\nCurrently, most of these methods face two main challenges: description\nrepetition and omission. Moreover, the existing evaluation metrics cannot\nclearly reflect the performance of models on these two issues. To address these\nchallenges, we propose an innovative Fine-grained Image Description Generation\nmodel based on Joint Objectives. Furthermore, we introduce new object-based\nevaluation metrics to more intuitively assess the model's performance in\nhandling description repetition and omission. This novel approach combines\nvisual features at both the image level and object level to maximize their\nadvantages and incorporates an object penalty mechanism to reduce description\nrepetition. Experimental results demonstrate that our proposed method\nsignificantly improves the CIDEr evaluation metric, indicating its excellent\nperformance in addressing description repetition and omission issues.\n",
                "链接": "https://arxiv.org/abs/2311.12799"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找风格化机器翻译相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "119453",
                "标题": "Relevance-guided Neural Machine Translation",
                "作者": " Isidora Chara Tourni,  Derry Wijaya",
                "发布日期": "2023-12-04",
                "摘要": "  With the advent of the Transformer architecture, Neural Machine Translation\n(NMT) results have shown great improvement lately. However, results in\nlow-resource conditions still lag behind in both bilingual and multilingual\nsetups, due to the limited amount of available monolingual and/or parallel\ndata; hence, the need for methods addressing data scarcity in an efficient, and\nexplainable way, is eminent. We propose an explainability-based training\napproach for NMT, applied in Unsupervised and Supervised model training, for\ntranslation of three languages of varying resources, French, Gujarati, Kazakh,\nto and from English. Our results show our method can be promising, particularly\nwhen training in low-resource conditions, outperforming simple training\nbaselines; though the improvement is marginal, it sets the ground for further\nexploration of the approach and the parameters, and its extension to other\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2312.00214"
            },
            {
                "文章ID": "20418",
                "标题": "How sensitive are translation systems to extra contexts? Mitigating\n  gender bias in Neural Machine Translation models through relevant contexts",
                "作者": " Shanya Sharma,  Manan Dey,  Koustuv Sinha",
                "发布日期": "2022-10-18",
                "摘要": "  Neural Machine Translation systems built on top of Transformer-based\narchitectures are routinely improving the state-of-the-art in translation\nquality according to word-overlap metrics. However, a growing number of studies\nalso highlight the inherent gender bias that these models incorporate during\ntraining, which reflects poorly in their translations. In this work, we\ninvestigate whether these models can be instructed to fix their bias during\ninference using targeted, guided instructions as contexts. By translating\nrelevant contextual sentences during inference along with the input, we observe\nlarge improvements in reducing the gender bias in translations, across three\npopular test suites (WinoMT, BUG, SimpleGen). We further propose a novel metric\nto assess several large pre-trained models (OPUS-MT, M2M-100) on their\nsensitivity towards using contexts during translation to correct their biases.\nOur approach requires no fine-tuning and thus can be used easily in production\nsystems to de-bias translations from stereotypical gender-occupation bias 1. We\nhope our method, along with our metric, can be used to build better, bias-free\ntranslation systems.\n",
                "链接": "https://arxiv.org/abs/2205.10762"
            },
            {
                "文章ID": "45035",
                "标题": "Exploring Document-Level Literary Machine Translation with Parallel\n  Paragraphs from World Literature",
                "作者": " Katherine Thai,  Marzena Karpinska,  Kalpesh Krishna,  Bill Ray,  Moira Inghilleri,  John Wieting,  Mohit Iyyer",
                "发布日期": "2022-10-27",
                "摘要": "  Literary translation is a culturally significant task, but it is bottlenecked\nby the small number of qualified literary translators relative to the many\nuntranslated works published around the world. Machine translation (MT) holds\npotential to complement the work of human translators by improving both\ntraining procedures and their overall efficiency. Literary translation is less\nconstrained than more traditional MT settings since translators must balance\nmeaning equivalence, readability, and critical interpretability in the target\nlanguage. This property, along with the complex discourse-level context present\nin literary texts, also makes literary MT more challenging to computationally\nmodel and evaluate. To explore this task, we collect a dataset (Par3) of\nnon-English language novels in the public domain, each aligned at the paragraph\nlevel to both human and automatic English translations. Using Par3, we discover\nthat expert literary translators prefer reference human translations over\nmachine-translated paragraphs at a rate of 84%, while state-of-the-art\nautomatic MT metrics do not correlate with those preferences. The experts note\nthat MT outputs contain not only mistranslations, but also discourse-disrupting\nerrors and stylistic inconsistencies. To address these problems, we train a\npost-editing model whose output is preferred over normal MT output at a rate of\n69% by experts. We publicly release Par3 at\nhttps://github.com/katherinethai/par3/ to spur future research into literary\nMT.\n",
                "链接": "https://arxiv.org/abs/2210.14250"
            },
            {
                "文章ID": "87034",
                "标题": "RSMT: Real-time Stylized Motion Transition for Characters",
                "作者": " Xiangjun Tang,  Linjun Wu,  He Wang,  Bo Hu,  Xu Gong,  Yuchen Liao,  Songnan Li,  Qilong Kou,  Xiaogang Jin",
                "发布日期": "2023-06-22",
                "摘要": "  Styled online in-between motion generation has important application\nscenarios in computer animation and games. Its core challenge lies in the need\nto satisfy four critical requirements simultaneously: generation speed, motion\nquality, style diversity, and synthesis controllability. While the first two\nchallenges demand a delicate balance between simple fast models and learning\ncapacity for generation quality, the latter two are rarely investigated\ntogether in existing methods, which largely focus on either control without\nstyle or uncontrolled stylized motions. To this end, we propose a Real-time\nStylized Motion Transition method (RSMT) to achieve all aforementioned goals.\nOur method consists of two critical, independent components: a general motion\nmanifold model and a style motion sampler. The former acts as a high-quality\nmotion source and the latter synthesizes styled motions on the fly under\ncontrol signals. Since both components can be trained separately on different\ndatasets, our method provides great flexibility, requires less data, and\ngeneralizes well when no/few samples are available for unseen styles. Through\nexhaustive evaluation, our method proves to be fast, high-quality, versatile,\nand controllable. The code and data are available at\n{https://github.com/yuyujunjun/RSMT-Realtime-Stylized-Motion-Transition.}\n",
                "链接": "https://arxiv.org/abs/2306.11970"
            },
            {
                "文章ID": "21061",
                "标题": "Machine Translation Robustness to Natural Asemantic Variation",
                "作者": " Jacob Bremerman,  Xiang Ren,  Jonathan May",
                "发布日期": "2022-11-11",
                "摘要": "  Current Machine Translation (MT) models still struggle with more challenging\ninput, such as noisy data and tail-end words and phrases. Several works have\naddressed this robustness issue by identifying specific categories of noise and\nvariation then tuning models to perform better on them. An important yet\nunder-studied category involves minor variations in nuance (non-typos) that\npreserve meaning w.r.t. the target language. We introduce and formalize this\ncategory as Natural Asemantic Variation (NAV) and investigate it in the context\nof MT robustness. We find that existing MT models fail when presented with NAV\ndata, but we demonstrate strategies to improve performance on NAV by\nfine-tuning them with human-generated variations. We also show that NAV\nrobustness can be transferred across languages and find that synthetic\nperturbations can achieve some but not all of the benefits of organic NAV data.\n",
                "链接": "https://arxiv.org/abs/2205.12514"
            },
            {
                "文章ID": "27030",
                "标题": "Building Multilingual Machine Translation Systems That Serve Arbitrary\n  X-Y Translations",
                "作者": " Akiko Eriguchi,  Shufang Xie,  Tao Qin,  Hany Hassan Awadalla",
                "发布日期": "2022-07-01",
                "摘要": "  Multilingual Neural Machine Translation (MNMT) enables one system to\ntranslate sentences from multiple source languages to multiple target\nlanguages, greatly reducing deployment costs compared with conventional\nbilingual systems. The MNMT training benefit, however, is often limited to\nmany-to-one directions. The model suffers from poor performance in one-to-many\nand many-to-many with zero-shot setup. To address this issue, this paper\ndiscusses how to practically build MNMT systems that serve arbitrary X-Y\ntranslation directions while leveraging multilinguality with a two-stage\ntraining strategy of pretraining and finetuning. Experimenting with the WMT'21\nmultilingual translation task, we demonstrate that our systems outperform the\nconventional baselines of direct bilingual models and pivot translation models\nfor most directions, averagely giving +6.0 and +4.1 BLEU, without the need for\narchitecture change or extra data collection. Moreover, we also examine our\nproposed approach in an extremely large-scale data setting to accommodate\npractical deployment scenarios.\n",
                "链接": "https://arxiv.org/abs/2206.14982"
            },
            {
                "文章ID": "67893",
                "标题": "LEAPT: Learning Adaptive Prefix-to-prefix Translation For Simultaneous\n  Machine Translation",
                "作者": " Lei Lin,  Shuangtao Li,  Xiaodong Shi",
                "发布日期": "2023-03-22",
                "摘要": "  Simultaneous machine translation, which aims at a real-time translation, is\nuseful in many live scenarios but very challenging due to the trade-off between\naccuracy and latency. To achieve the balance for both, the model needs to wait\nfor appropriate streaming text (READ policy) and then generates its translation\n(WRITE policy). However, WRITE policies of previous work either are specific to\nthe method itself due to the end-to-end training or suffer from the input\nmismatch between training and decoding for the non-end-to-end training.\nTherefore, it is essential to learn a generic and better WRITE policy for\nsimultaneous machine translation. Inspired by strategies utilized by human\ninterpreters and \"wait\" policies, we propose a novel adaptive prefix-to-prefix\ntraining policy called LEAPT, which allows our machine translation model to\nlearn how to translate source sentence prefixes and make use of the future\ncontext. Experiments show that our proposed methods greatly outperform\ncompetitive baselines and achieve promising results.\n",
                "链接": "https://arxiv.org/abs/2303.11750"
            },
            {
                "文章ID": "92370",
                "标题": "Incorporating Human Translator Style into English-Turkish Literary\n  Machine Translation",
                "作者": " Zeynep Yirmibeşoğlu,  Olgun Dursun,  Harun Dallı,  Mehmet Şahin,  Ena Hodzik,  Sabri Gürses,  Tunga Güngör",
                "发布日期": "2023-07-24",
                "摘要": "  Although machine translation systems are mostly designed to serve in the\ngeneral domain, there is a growing tendency to adapt these systems to other\ndomains like literary translation. In this paper, we focus on English-Turkish\nliterary translation and develop machine translation models that take into\naccount the stylistic features of translators. We fine-tune a pre-trained\nmachine translation model by the manually-aligned works of a particular\ntranslator. We make a detailed analysis of the effects of manual and automatic\nalignments, data augmentation methods, and corpus size on the translations. We\npropose an approach based on stylistic features to evaluate the style of a\ntranslator in the output translations. We show that the human translator style\ncan be highly recreated in the target machine translations by adapting the\nmodels to the style of the translator.\n",
                "链接": "https://arxiv.org/abs/2307.11457"
            },
            {
                "文章ID": "90236",
                "标题": "Information decomposition to identify relevant variation in complex\n  systems with machine learning",
                "作者": " Kieran A. Murphy,  Dani S. Bassett",
                "发布日期": "2023-07-11",
                "摘要": "  One of the fundamental steps toward understanding a complex system is\nidentifying variation at the scale of the system's components that is most\nrelevant to behavior on a macroscopic scale. Mutual information is a natural\nmeans of linking variation across scales of a system due to its independence of\nthe particular functional relationship between variables. However, estimating\nmutual information given high-dimensional, continuous-valued data is\nnotoriously difficult, and the desideratum -- to reveal important variation in\na comprehensible manner -- is only readily achieved through exhaustive search.\nHere we propose a practical, efficient, and broadly applicable methodology to\ndecompose the information contained in a set of measurements by lossily\ncompressing each measurement with machine learning. Guided by the distributed\ninformation bottleneck as a learning objective, the information decomposition\nsorts variation in the measurements of the system state by relevance to\nspecified macroscale behavior, revealing the most important subsets of\nmeasurements for different amounts of predictive information. Additional\ngranularity is achieved by inspection of the learned compression schemes: the\nvariation transmitted during compression is composed of distinctions among\nmeasurement values that are most relevant to the macroscale behavior. We focus\nour analysis on two paradigmatic complex systems: a Boolean circuit and an\namorphous material undergoing plastic deformation. In both examples, specific\nbits of entropy are identified out of the high entropy of the system state as\nmost related to macroscale behavior for insight about the connection between\nmicro- and macro- in the complex system. The identification of meaningful\nvariation in data, with the full generality brought by information theory, is\nmade practical for the study of complex systems.\n",
                "链接": "https://arxiv.org/abs/2307.04755"
            },
            {
                "文章ID": "56448",
                "标题": "Applying Automated Machine Translation to Educational Video Courses",
                "作者": " Linden Wang",
                "发布日期": "2023-09-20",
                "摘要": "  We studied the capability of automated machine translation in the online\nvideo education space by automatically translating Khan Academy videos with\nstate-of-the-art translation models and applying text-to-speech synthesis and\naudio/video synchronization to build engaging videos in target languages. We\nalso analyzed and established two reliable translation confidence estimators\nbased on round-trip translations in order to efficiently manage translation\nquality and reduce human translation effort. Finally, we developed a deployable\nsystem to deliver translated videos to end users and collect user corrections\nfor iterative improvement.\n",
                "链接": "https://arxiv.org/abs/2301.03141"
            }
        ]
    },
    {
        "question": {
            "question": "查找中文ner常用的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "5948",
                "标题": "AISHELL-NER: Named Entity Recognition from Chinese Speech",
                "作者": " Boli Chen,  Guangwei Xu,  Xiaobin Wang,  Pengjun Xie,  Meishan Zhang,  Fei Huang",
                "发布日期": "2022-02-18",
                "摘要": "  Named Entity Recognition (NER) from speech is among Spoken Language\nUnderstanding (SLU) tasks, aiming to extract semantic information from the\nspeech signal. NER from speech is usually made through a two-step pipeline that\nconsists of (1) processing the audio using an Automatic Speech Recognition\n(ASR) system and (2) applying an NER tagger to the ASR outputs. Recent works\nhave shown the capability of the End-to-End (E2E) approach for NER from English\nand French speech, which is essentially entity-aware ASR. However, due to the\nmany homophones and polyphones that exist in Chinese, NER from Chinese speech\nis effectively a more challenging task. In this paper, we introduce a new\ndataset AISEHLL-NER for NER from Chinese speech. Extensive experiments are\nconducted to explore the performance of several state-of-the-art methods. The\nresults demonstrate that the performance could be improved by combining\nentity-aware ASR and pretrained NER tagger, which can be easily applied to the\nmodern SLU pipeline. The dataset is publicly available at\ngithub.com/Alibaba-NLP/AISHELL-NER.\n",
                "链接": "https://arxiv.org/abs/2202.08533"
            },
            {
                "文章ID": "6079",
                "标题": "TURNER: The Uncertainty-based Retrieval Framework for Chinese NER",
                "作者": " Zhichao Geng,  Hang Yan,  Zhangyue Yin,  Chenxin An,  Xipeng Qiu",
                "发布日期": "2022-02-21",
                "摘要": "  Chinese NER is a difficult undertaking due to the ambiguity of Chinese\ncharacters and the absence of word boundaries. Previous work on Chinese NER\nfocus on lexicon-based methods to introduce boundary information and reduce\nout-of-vocabulary (OOV) cases during prediction. However, it is expensive to\nobtain and dynamically maintain high-quality lexicons in specific domains,\nwhich motivates us to utilize more general knowledge resources, e.g., search\nengines. In this paper, we propose TURNER: The Uncertainty-based Retrieval\nframework for Chinese NER. The idea behind TURNER is to imitate human behavior:\nwe frequently retrieve auxiliary knowledge as assistance when encountering an\nunknown or uncertain entity. To improve the efficiency and effectiveness of\nretrieval, we first propose two types of uncertainty sampling methods for\nselecting the most ambiguous entity-level uncertain components of the input\ntext. Then, the Knowledge Fusion Model re-predict the uncertain samples by\ncombining retrieved knowledge. Experiments on four benchmark datasets\ndemonstrate TURNER's effectiveness. TURNER outperforms existing lexicon-based\napproaches and achieves the new SOTA.\n",
                "链接": "https://arxiv.org/abs/2202.09022"
            },
            {
                "文章ID": "124014",
                "标题": "CORECODE: A Common Sense Annotated Dialogue Dataset with Benchmark Tasks\n  for Chinese Large Language Models",
                "作者": " Dan Shi,  Chaobin You,  Jiantao Huang,  Taihao Li,  Deyi Xiong",
                "发布日期": "2023-12-21",
                "摘要": "  As an indispensable ingredient of intelligence, commonsense reasoning is\ncrucial for large language models (LLMs) in real-world scenarios. In this\npaper, we propose CORECODE, a dataset that contains abundant commonsense\nknowledge manually annotated on dyadic dialogues, to evaluate the commonsense\nreasoning and commonsense conflict detection capabilities of Chinese LLMs. We\ncategorize commonsense knowledge in everyday conversations into three\ndimensions: entity, event, and social interaction. For easy and consistent\nannotation, we standardize the form of commonsense knowledge annotation in\nopen-domain dialogues as \"domain: slot = value\". A total of 9 domains and 37\nslots are defined to capture diverse commonsense knowledge. With these\npre-defined domains and slots, we collect 76,787 commonsense knowledge\nannotations from 19,700 dialogues through crowdsourcing. To evaluate and\nenhance the commonsense reasoning capability for LLMs on the curated dataset,\nwe establish a series of dialogue-level reasoning and detection tasks,\nincluding commonsense knowledge filling, commonsense knowledge generation,\ncommonsense conflict phrase detection, domain identification, slot\nidentification, and event causal inference. A wide variety of existing\nopen-source Chinese LLMs are evaluated with these tasks on our dataset.\nExperimental results demonstrate that these models are not competent to predict\nCORECODE's plentiful reasoning content, and even ChatGPT could only achieve\n0.275 and 0.084 accuracy on the domain identification and slot identification\ntasks under the zero-shot setting. We release the data and codes of CORECODE at\nhttps://github.com/danshi777/CORECODE to promote commonsense reasoning\nevaluation and study of LLMs in the context of daily conversations.\n",
                "链接": "https://arxiv.org/abs/2312.12853"
            },
            {
                "文章ID": "65767",
                "标题": "Position Paper on Dataset Engineering to Accelerate Science",
                "作者": " Emilio Vital Brazil,  Eduardo Soares,  Lucas Villa Real,  Leonardo Azevedo,  Vinicius Segura,  Luiz Zerkowski,  Renato Cerqueira",
                "发布日期": "2023-03-13",
                "摘要": "  Data is a critical element in any discovery process. In the last decades, we\nobserved exponential growth in the volume of available data and the technology\nto manipulate it. However, data is only practical when one can structure it for\na well-defined task. For instance, we need a corpus of text broken into\nsentences to train a natural language machine-learning model. In this work, we\nwill use the token \\textit{dataset} to designate a structured set of data built\nto perform a well-defined task. Moreover, the dataset will be used in most\ncases as a blueprint of an entity that at any moment can be stored as a table.\nSpecifically, in science, each area has unique forms to organize, gather and\nhandle its datasets. We believe that datasets must be a first-class entity in\nany knowledge-intensive process, and all workflows should have exceptional\nattention to datasets' lifecycle, from their gathering to uses and evolution.\nWe advocate that science and engineering discovery processes are extreme\ninstances of the need for such organization on datasets, claiming for new\napproaches and tooling. Furthermore, these requirements are more evident when\nthe discovery workflow uses artificial intelligence methods to empower the\nsubject-matter expert. In this work, we discuss an approach to bringing\ndatasets as a critical entity in the discovery process in science. We\nillustrate some concepts using material discovery as a use case. We chose this\ndomain because it leverages many significant problems that can be generalized\nto other science fields.\n",
                "链接": "https://arxiv.org/abs/2303.05545"
            },
            {
                "文章ID": "27917",
                "标题": "A Dataset on Malicious Paper Bidding in Peer Review",
                "作者": " Steven Jecmen,  Minji Yoon,  Vincent Conitzer,  Nihar B. Shah,  Fei Fang",
                "发布日期": "2023-03-14",
                "摘要": "  In conference peer review, reviewers are often asked to provide \"bids\" on\neach submitted paper that express their interest in reviewing that paper. A\npaper assignment algorithm then uses these bids (along with other data) to\ncompute a high-quality assignment of reviewers to papers. However, this process\nhas been exploited by malicious reviewers who strategically bid in order to\nunethically manipulate the paper assignment, crucially undermining the peer\nreview process. For example, these reviewers may aim to get assigned to a\nfriend's paper as part of a quid-pro-quo deal. A critical impediment towards\ncreating and evaluating methods to mitigate this issue is the lack of any\npublicly-available data on malicious paper bidding. In this work, we collect\nand publicly release a novel dataset to fill this gap, collected from a mock\nconference activity where participants were instructed to bid either honestly\nor maliciously. We further provide a descriptive analysis of the bidding\nbehavior, including our categorization of different strategies employed by\nparticipants. Finally, we evaluate the ability of each strategy to manipulate\nthe assignment, and also evaluate the performance of some simple algorithms\nmeant to detect malicious bidding. The performance of these detection\nalgorithms can be taken as a baseline for future research on detecting\nmalicious bidding.\n",
                "链接": "https://arxiv.org/abs/2207.02303"
            },
            {
                "文章ID": "84049",
                "标题": "Some voices are too common: Building fair speech recognition systems\n  using the Common Voice dataset",
                "作者": " Lucas Maison,  Yannick Estève",
                "发布日期": "2023-06-07",
                "摘要": "  Automatic speech recognition (ASR) systems become increasingly efficient\nthanks to new advances in neural network training like self-supervised\nlearning. However, they are known to be unfair toward certain groups, for\ninstance, people speaking with an accent. In this work, we use the French\nCommon Voice dataset to quantify the biases of a pre-trained wav2vec~2.0 model\ntoward several demographic groups. By fine-tuning the pre-trained model on a\nvariety of fixed-size, carefully crafted training sets, we demonstrate the\nimportance of speaker diversity. We also run an in-depth analysis of the Common\nVoice corpus and identify important shortcomings that should be taken into\naccount by users of this dataset.\n",
                "链接": "https://arxiv.org/abs/2306.03773"
            },
            {
                "文章ID": "76534",
                "标题": "VCSUM: A Versatile Chinese Meeting Summarization Dataset",
                "作者": " Han Wu,  Mingjie Zhan,  Haochen Tan,  Zhaohui Hou,  Ding Liang,  Linqi Song",
                "发布日期": "2023-05-16",
                "摘要": "  Compared to news and chat summarization, the development of meeting\nsummarization is hugely decelerated by the limited data. To this end, we\nintroduce a versatile Chinese meeting summarization dataset, dubbed VCSum,\nconsisting of 239 real-life meetings, with a total duration of over 230 hours.\nWe claim our dataset is versatile because we provide the annotations of topic\nsegmentation, headlines, segmentation summaries, overall meeting summaries, and\nsalient sentences for each meeting transcript. As such, the dataset can adapt\nto various summarization tasks or methods, including segmentation-based\nsummarization, multi-granularity summarization and retrieval-then-generate\nsummarization. Our analysis confirms the effectiveness and robustness of VCSum.\nWe also provide a set of benchmark models regarding different downstream\nsummarization tasks on VCSum to facilitate further research. The dataset and\ncode will be released at https://github.com/hahahawu/VCSum.\n",
                "链接": "https://arxiv.org/abs/2305.05280"
            },
            {
                "文章ID": "85346",
                "标题": "LTCR: Long-Text Chinese Rumor Detection Dataset",
                "作者": " Ziyang Ma,  Mengsha Liu,  Guian Fang,  Ying Shen",
                "发布日期": "2023-06-14",
                "摘要": "  False information can spread quickly on social media, negatively influencing\nthe citizens' behaviors and responses to social events. To better detect all of\nthe fake news, especially long texts which are harder to find completely, a\nLong-Text Chinese Rumor detection dataset named LTCR is proposed. The LTCR\ndataset provides a valuable resource for accurately detecting misinformation,\nespecially in the context of complex fake news related to COVID-19. The dataset\nconsists of 1,729 and 500 pieces of real and fake news, respectively. The\naverage lengths of real and fake news are approximately 230 and 152 characters.\nWe also propose \\method, Salience-aware Fake News Detection Model, which\nachieves the highest accuracy (95.85%), fake news recall (90.91%) and F-score\n(90.60%) on the dataset. (https://github.com/Enderfga/DoubleCheck)\n",
                "链接": "https://arxiv.org/abs/2306.07201"
            },
            {
                "文章ID": "1409",
                "标题": "Common Phone: A Multilingual Dataset for Robust Acoustic Modelling",
                "作者": " Philipp Klumpp,  Tomás Arias-Vergara,  Paula Andrea Pérez-Toro,  Elmar Nöth,  Juan Rafael Orozco-Arroyave",
                "发布日期": "2022-02-01",
                "摘要": "  Current state of the art acoustic models can easily comprise more than 100\nmillion parameters. This growing complexity demands larger training datasets to\nmaintain a decent generalization of the final decision function. An ideal\ndataset is not necessarily large in size, but large with respect to the amount\nof unique speakers, utilized hardware and varying recording conditions. This\nenables a machine learning model to explore as much of the domain-specific\ninput space as possible during parameter estimation. This work introduces\nCommon Phone, a gender-balanced, multilingual corpus recorded from more than\n11.000 contributors via Mozilla's Common Voice project. It comprises around 116\nhours of speech enriched with automatically generated phonetic segmentation. A\nWav2Vec 2.0 acoustic model was trained with the Common Phone to perform\nphonetic symbol recognition and validate the quality of the generated phonetic\nannotation. The architecture achieved a PER of 18.1 % on the entire test set,\ncomputed with all 101 unique phonetic symbols, showing slight differences\nbetween the individual languages. We conclude that Common Phone provides\nsufficient variability and reliable phonetic annotation to help bridging the\ngap between research and application of acoustic models.\n",
                "链接": "https://arxiv.org/abs/2201.05912"
            },
            {
                "文章ID": "26793",
                "标题": "Bengali Common Voice Speech Dataset for Automatic Speech Recognition",
                "作者": " Samiul Alam,  Asif Sushmit,  Zaowad Abdullah,  Shahrin Nakkhatra,  MD. Nazmuddoha Ansary,  Syed Mobassir Hossen,  Sazia Morshed Mehnaz,  Tahsin Reasat,  Ahmed Imtiaz Humayun",
                "发布日期": "2022-06-30",
                "摘要": "  Bengali is one of the most spoken languages in the world with over 300\nmillion speakers globally. Despite its popularity, research into the\ndevelopment of Bengali speech recognition systems is hindered due to the lack\nof diverse open-source datasets. As a way forward, we have crowdsourced the\nBengali Common Voice Speech Dataset, which is a sentence-level automatic speech\nrecognition corpus. Collected on the Mozilla Common Voice platform, the dataset\nis part of an ongoing campaign that has led to the collection of over 400 hours\nof data in 2 months and is growing rapidly. Our analysis shows that this\ndataset has more speaker, phoneme, and environmental diversity compared to the\nOpenSLR Bengali ASR dataset, the largest existing open-source Bengali speech\ndataset. We present insights obtained from the dataset and discuss key\nlinguistic challenges that need to be addressed in future versions.\nAdditionally, we report the current performance of a few Automatic Speech\nRecognition (ASR) algorithms and set a benchmark for future research.\n",
                "链接": "https://arxiv.org/abs/2206.14053"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下最近用反事实做数据增强的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "36857",
                "标题": "Bias Challenges in Counterfactual Data Augmentation",
                "作者": " S Chandra Mouli,  Yangze Zhou,  Bruno Ribeiro",
                "发布日期": "2022-09-15",
                "摘要": "  Deep learning models tend not to be out-of-distribution robust primarily due\nto their reliance on spurious features to solve the task. Counterfactual data\naugmentations provide a general way of (approximately) achieving\nrepresentations that are counterfactual-invariant to spurious features, a\nrequirement for out-of-distribution (OOD) robustness. In this work, we show\nthat counterfactual data augmentations may not achieve the desired\ncounterfactual-invariance if the augmentation is performed by a\ncontext-guessing machine, an abstract machine that guesses the most-likely\ncontext of a given input. We theoretically analyze the invariance imposed by\nsuch counterfactual data augmentations and describe an exemplar NLP task where\ncounterfactual data augmentation by a context-guessing machine does not lead to\nrobust OOD classifiers.\n",
                "链接": "https://arxiv.org/abs/2209.05104"
            },
            {
                "文章ID": "81687",
                "标题": "On Counterfactual Data Augmentation Under Confounding",
                "作者": " Abbavaram Gowtham Reddy,  Saketh Bachu,  Saloni Dash,  Charchit Sharma,  Amit Sharma,  Vineeth N Balasubramanian",
                "发布日期": "2023-11-22",
                "摘要": "  Counterfactual data augmentation has recently emerged as a method to mitigate\nconfounding biases in the training data. These biases, such as spurious\ncorrelations, arise due to various observed and unobserved confounding\nvariables in the data generation process. In this paper, we formally analyze\nhow confounding biases impact downstream classifiers and present a causal\nviewpoint to the solutions based on counterfactual data augmentation. We\nexplore how removing confounding biases serves as a means to learn invariant\nfeatures, ultimately aiding in generalization beyond the observed data\ndistribution. Additionally, we present a straightforward yet powerful algorithm\nfor generating counterfactual images, which effectively mitigates the influence\nof confounding effects on downstream classifiers. Through experiments on MNIST\nvariants and the CelebA datasets, we demonstrate how our simple augmentation\nmethod helps existing state-of-the-art methods achieve good results.\n",
                "链接": "https://arxiv.org/abs/2305.18183"
            },
            {
                "文章ID": "34843",
                "标题": "Data Augmentation for Graph Data: Recent Advancements",
                "作者": " Maria Marrium,  Arif Mahmood",
                "发布日期": "2022-08-26",
                "摘要": "  Graph Neural Network (GNNs) based methods have recently become a popular tool\nto deal with graph data because of their ability to incorporate structural\ninformation. The only hurdle in the performance of GNNs is the lack of labeled\ndata. Data Augmentation techniques for images and text data can not be used for\ngraph data because of the complex and non-euclidean structure of graph data.\nThis gap has forced researchers to shift their focus towards the development of\ndata augmentation techniques for graph data. Most of the proposed Graph Data\nAugmentation (GDA) techniques are task-specific. In this paper, we survey the\nexisting GDA techniques based on different graph tasks. This survey not only\nprovides a reference to the research community of GDA but also provides the\nnecessary information to the researchers of other domains.\n",
                "链接": "https://arxiv.org/abs/2208.11973"
            },
            {
                "文章ID": "74413",
                "标题": "Implicit Counterfactual Data Augmentation for Deep Neural Networks",
                "作者": " Xiaoling Zhou,  Ou Wu",
                "发布日期": "2023-04-27",
                "摘要": "  Machine-learning models are prone to capturing the spurious correlations\nbetween non-causal attributes and classes, with counterfactual data\naugmentation being a promising direction for breaking these spurious\nassociations. However, explicitly generating counterfactual data is\nchallenging, with the training efficiency declining. Therefore, this study\nproposes an implicit counterfactual data augmentation (ICDA) method to remove\nspurious correlations and make stable predictions. Specifically, first, a novel\nsample-wise augmentation strategy is developed that generates semantically and\ncounterfactually meaningful deep features with distinct augmentation strength\nfor each sample. Second, we derive an easy-to-compute surrogate loss on the\naugmented feature set when the number of augmented samples becomes infinite.\nThird, two concrete schemes are proposed, including direct quantification and\nmeta-learning, to derive the key parameters for the robust loss. In addition,\nICDA is explained from a regularization aspect, with extensive experiments\nindicating that our method consistently improves the generalization performance\nof popular depth networks on multiple typical learning scenarios that require\nout-of-distribution generalization.\n",
                "链接": "https://arxiv.org/abs/2304.13431"
            },
            {
                "文章ID": "43960",
                "标题": "MoCoDA: Model-based Counterfactual Data Augmentation",
                "作者": " Silviu Pitis,  Elliot Creager,  Ajay Mandlekar,  Animesh Garg",
                "发布日期": "2022-10-21",
                "摘要": "  The number of states in a dynamic process is exponential in the number of\nobjects, making reinforcement learning (RL) difficult in complex, multi-object\ndomains. For agents to scale to the real world, they will need to react to and\nreason about unseen combinations of objects. We argue that the ability to\nrecognize and use local factorization in transition dynamics is a key element\nin unlocking the power of multi-object reasoning. To this end, we show that (1)\nknown local structure in the environment transitions is sufficient for an\nexponential reduction in the sample complexity of training a dynamics model,\nand (2) a locally factored dynamics model provably generalizes\nout-of-distribution to unseen states and actions. Knowing the local structure\nalso allows us to predict which unseen states and actions this dynamics model\nwill generalize to. We propose to leverage these observations in a novel\nModel-based Counterfactual Data Augmentation (MoCoDA) framework. MoCoDA applies\na learned locally factored dynamics model to an augmented distribution of\nstates and actions to generate counterfactual transitions for RL. MoCoDA works\nwith a broader set of local structures than prior work and allows for direct\ncontrol over the augmented training distribution. We show that MoCoDA enables\nRL agents to learn policies that generalize to unseen states and actions. We\nuse MoCoDA to train an offline RL agent to solve an out-of-distribution\nrobotics manipulation task on which standard offline RL algorithms fail.\n",
                "链接": "https://arxiv.org/abs/2210.11287"
            },
            {
                "文章ID": "114161",
                "标题": "Counterfactual Data Augmentation with Contrastive Learning",
                "作者": " Ahmed Aloui,  Juncheng Dong,  Cat P. Le,  Vahid Tarokh",
                "发布日期": "2023-11-08",
                "摘要": "  Statistical disparity between distinct treatment groups is one of the most\nsignificant challenges for estimating Conditional Average Treatment Effects\n(CATE). To address this, we introduce a model-agnostic data augmentation method\nthat imputes the counterfactual outcomes for a selected subset of individuals.\nSpecifically, we utilize contrastive learning to learn a representation space\nand a similarity measure such that in the learned representation space close\nindividuals identified by the learned similarity measure have similar potential\noutcomes. This property ensures reliable imputation of counterfactual outcomes\nfor the individuals with close neighbors from the alternative treatment group.\nBy augmenting the original dataset with these reliable imputations, we can\neffectively reduce the discrepancy between different treatment groups, while\ninducing minimal imputation error. The augmented dataset is subsequently\nemployed to train CATE estimation models. Theoretical analysis and experimental\nstudies on synthetic and semi-synthetic benchmarks demonstrate that our method\nachieves significant improvements in both performance and robustness to\noverfitting across state-of-the-art models.\n",
                "链接": "https://arxiv.org/abs/2311.03630"
            },
            {
                "文章ID": "110605",
                "标题": "EXPLAIN, EDIT, GENERATE: Rationale-Sensitive Counterfactual Data\n  Augmentation for Multi-hop Fact Verification",
                "作者": " Yingjie Zhu,  Jiasheng Si,  Yibo Zhao,  Haiyang Zhu,  Deyu Zhou,  Yulan He",
                "发布日期": "2023-10-24",
                "摘要": "  Automatic multi-hop fact verification task has gained significant attention\nin recent years. Despite impressive results, these well-designed models perform\npoorly on out-of-domain data. One possible solution is to augment the training\ndata with counterfactuals, which are generated by minimally altering the causal\nfeatures of the original data. However, current counterfactual data\naugmentation techniques fail to handle multi-hop fact verification due to their\nincapability to preserve the complex logical relationships within multiple\ncorrelated texts. In this paper, we overcome this limitation by developing a\nrationale-sensitive method to generate linguistically diverse and\nlabel-flipping counterfactuals while preserving logical relationships. In\nspecific, the diverse and fluent counterfactuals are generated via an\nExplain-Edit-Generate architecture. Moreover, the checking and filtering\nmodules are proposed to regularize the counterfactual data with logical\nrelations and flipped labels. Experimental results show that the proposed\napproach outperforms the SOTA baselines and can generate linguistically diverse\ncounterfactual data without disrupting their logical relationships.\n",
                "链接": "https://arxiv.org/abs/2310.14508"
            },
            {
                "文章ID": "21004",
                "标题": "Counterfactual Data Augmentation improves Factuality of Abstractive\n  Summarization",
                "作者": " Dheeraj Rajagopal,  Siamak Shakeri,  Cicero Nogueira dos Santos,  Eduard Hovy,  Chung-Ching Chang",
                "发布日期": "2022-05-26",
                "摘要": "  Abstractive summarization systems based on pretrained language models often\ngenerate coherent but factually inconsistent sentences. In this paper, we\npresent a counterfactual data augmentation approach where we augment data with\nperturbed summaries that increase the training data diversity. Specifically, we\npresent three augmentation approaches based on replacing (i) entities from\nother and the same category and (ii) nouns with their corresponding WordNet\nhypernyms. We show that augmenting the training data with our approach improves\nthe factual correctness of summaries without significantly affecting the ROUGE\nscore. We show that in two commonly used summarization datasets (CNN/Dailymail\nand XSum), we improve the factual correctness by about 2.5 points on average\n",
                "链接": "https://arxiv.org/abs/2205.12416"
            },
            {
                "文章ID": "79824",
                "标题": "Counterfactual Augmentation for Multimodal Learning Under Presentation\n  Bias",
                "作者": " Victoria Lin,  Louis-Philippe Morency,  Dimitrios Dimitriadis,  Srinagesh Sharma",
                "发布日期": "2023-11-01",
                "摘要": "  In real-world machine learning systems, labels are often derived from user\nbehaviors that the system wishes to encourage. Over time, new models must be\ntrained as new training examples and features become available. However,\nfeedback loops between users and models can bias future user behavior, inducing\na presentation bias in the labels that compromises the ability to train new\nmodels. In this paper, we propose counterfactual augmentation, a novel causal\nmethod for correcting presentation bias using generated counterfactual labels.\nOur empirical evaluations demonstrate that counterfactual augmentation yields\nbetter downstream performance compared to both uncorrected models and existing\nbias-correction methods. Model analyses further indicate that the generated\ncounterfactuals align closely with true counterfactuals in an oracle setting.\n",
                "链接": "https://arxiv.org/abs/2305.14083"
            },
            {
                "文章ID": "45900",
                "标题": "Counterfactual Data Augmentation via Perspective Transition for\n  Open-Domain Dialogues",
                "作者": " Jiao Ou,  Jinchao Zhang,  Yang Feng,  Jie Zhou",
                "发布日期": "2022-11-01",
                "摘要": "  The construction of open-domain dialogue systems requires high-quality\ndialogue datasets. The dialogue data admits a wide variety of responses for a\ngiven dialogue history, especially responses with different semantics. However,\ncollecting high-quality such a dataset in most scenarios is labor-intensive and\ntime-consuming. In this paper, we propose a data augmentation method to\nautomatically augment high-quality responses with different semantics by\ncounterfactual inference. Specifically, given an observed dialogue, our\ncounterfactual generation model first infers semantically different responses\nby replacing the observed reply perspective with substituted ones. Furthermore,\nour data selection method filters out detrimental augmented responses.\nExperimental results show that our data augmentation method can augment\nhigh-quality responses with different semantics for a given dialogue history,\nand can outperform competitive baselines on multiple downstream tasks.\n",
                "链接": "https://arxiv.org/abs/2210.16838"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用蒙特卡罗树搜索解决序列决策问题的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "54835",
                "标题": "Feature Acquisition using Monte Carlo Tree Search",
                "作者": " Sungsoo Lim,  Diego Klabjan,  Mark Shapiro",
                "发布日期": "2022-12-23",
                "摘要": "  Feature acquisition algorithms address the problem of acquiring informative\nfeatures while balancing the costs of acquisition to improve the learning\nperformances of ML models. Previous approaches have focused on calculating the\nexpected utility values of features to determine the acquisition sequences.\nOther approaches formulated the problem as a Markov Decision Process (MDP) and\napplied reinforcement learning based algorithms. In comparison to previous\napproaches, we focus on 1) formulating the feature acquisition problem as a MDP\nand applying Monte Carlo Tree Search, 2) calculating the intermediary rewards\nfor each acquisition step based on model improvements and acquisition costs and\n3) simultaneously optimizing model improvement and acquisition costs with\nmulti-objective Monte Carlo Tree Search. With Proximal Policy Optimization and\nDeep Q-Network algorithms as benchmark, we show the effectiveness of our\nproposed approach with experimental study.\n",
                "链接": "https://arxiv.org/abs/2212.11360"
            },
            {
                "文章ID": "108378",
                "标题": "LightZero: A Unified Benchmark for Monte Carlo Tree Search in General\n  Sequential Decision Scenarios",
                "作者": " Yazhe Niu,  Yuan Pu,  Zhenjie Yang,  Xueyan Li,  Tong Zhou,  Jiyuan Ren,  Shuai Hu,  Hongsheng Li,  Yu Liu",
                "发布日期": "2023-10-13",
                "摘要": "  Building agents based on tree-search planning capabilities with learned\nmodels has achieved remarkable success in classic decision-making problems,\nsuch as Go and Atari. However, it has been deemed challenging or even\ninfeasible to extend Monte Carlo Tree Search (MCTS) based algorithms to diverse\nreal-world applications, especially when these environments involve complex\naction spaces and significant simulation costs, or inherent stochasticity. In\nthis work, we introduce LightZero, the first unified benchmark for deploying\nMCTS/MuZero in general sequential decision scenarios. Specificially, we\nsummarize the most critical challenges in designing a general MCTS-style\ndecision-making solver, then decompose the tightly-coupled algorithm and system\ndesign of tree-search RL methods into distinct sub-modules. By incorporating\nmore appropriate exploration and optimization strategies, we can significantly\nenhance these sub-modules and construct powerful LightZero agents to tackle\ntasks across a wide range of domains, such as board games, Atari, MuJoCo,\nMiniGrid and GoBigger. Detailed benchmark results reveal the significant\npotential of such methods in building scalable and efficient decision\nintelligence. The code is available as part of OpenDILab at\nhttps://github.com/opendilab/LightZero.\n",
                "链接": "https://arxiv.org/abs/2310.08348"
            },
            {
                "文章ID": "3914",
                "标题": "On Monte Carlo Tree Search for Weighted Vertex Coloring",
                "作者": " Cyril Grelier,  Olivier Goudet,  Jin-Kao Hao",
                "发布日期": "2022-04-08",
                "摘要": "  This work presents the first study of using the popular Monte Carlo Tree\nSearch (MCTS) method combined with dedicated heuristics for solving the\nWeighted Vertex Coloring Problem. Starting with the basic MCTS algorithm, we\ngradually introduce a number of algorithmic variants where MCTS is extended by\nvarious simulation strategies including greedy and local search heuristics. We\nconduct experiments on well-known benchmark instances to assess the value of\neach studied combination. We also provide empirical evidence to shed light on\nthe advantages and limits of each strategy.\n",
                "链接": "https://arxiv.org/abs/2202.01665"
            },
            {
                "文章ID": "53055",
                "标题": "Lookahead Pathology in Monte-Carlo Tree Search",
                "作者": " Khoi P. N. Nguyen,  Raghuram Ramanujan",
                "发布日期": "2022-12-13",
                "摘要": "  Monte-Carlo Tree Search (MCTS) is an adversarial search paradigm that first\nfound prominence with its success in the domain of computer Go. Early\ntheoretical work established the game-theoretic soundness and convergence\nbounds for Upper Confidence bounds applied to Trees (UCT), the most popular\ninstantiation of MCTS; however, there remain notable gaps in our understanding\nof how UCT behaves in practice. In this work, we address one such gap by\nconsidering the question of whether UCT can exhibit lookahead pathology -- a\nparadoxical phenomenon first observed in Minimax search where greater search\neffort leads to worse decision-making. We introduce a novel family of synthetic\ngames that offer rich modeling possibilities while remaining amenable to\nmathematical analysis. Our theoretical and experimental results suggest that\nUCT is indeed susceptible to pathological behavior in a range of games drawn\nfrom this family.\n",
                "链接": "https://arxiv.org/abs/2212.05208"
            },
            {
                "文章ID": "67092",
                "标题": "Proof Number Based Monte-Carlo Tree Search",
                "作者": " Jakub Kowalski,  Elliot Doe,  Mark H. M. Winands,  Daniel Górski,  Dennis J. N. J. Soemers",
                "发布日期": "2023-12-22",
                "摘要": "  This paper proposes a new game-search algorithm, PN-MCTS, which combines\nMonte-Carlo Tree Search (MCTS) and Proof-Number Search (PNS). These two\nalgorithms have been successfully applied for decision making in a range of\ndomains. We define three areas where the additional knowledge provided by the\nproof and disproof numbers gathered in MCTS trees might be used: final move\nselection, solving subtrees, and the UCB1 selection mechanism. We test all\npossible combinations on different time settings, playing against vanilla UCT\non several games: Lines of Action ($7$$\\times$$7$ and $8$$\\times$$8$ board\nsizes), MiniShogi, Knightthrough, and Awari. Furthermore, we extend this new\nalgorithm to properly address games with draws, like Awari, by adding an\nadditional layer of PNS on top of the MCTS tree. The experiments show that\nPN-MCTS confidently outperforms MCTS in all tested game domains, achieving win\nrates up to 96.2\\% for Lines of Action.\n",
                "链接": "https://arxiv.org/abs/2303.09449"
            },
            {
                "文章ID": "102301",
                "标题": "Maneuver Decision-Making Through Proximal Policy Optimization And Monte\n  Carlo Tree Search",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-09-19",
                "摘要": "  Maneuver decision-making can be regarded as a Markov decision process and can\nbe address by reinforcement learning. However, original reinforcement learning\nalgorithms can hardly solve the maneuvering decision-making problem. One reason\nis that agents use random actions in the early stages of training, which makes\nit difficult to get rewards and learn how to make effective decisions. To\naddress this issue, a method based on proximal policy optimization and Monte\nCarlo tree search is proposed. The method uses proximal policy optimization to\ntrain the agent, and regards the results of air combat as targets to train the\nvalue network. Then, based on the value network and the visit count of each\nnode, Monte Carlo tree search is used to find the actions with more expected\nreturns than random actions, which can improve the training performance. The\nablation studies and simulation experiments indicate that agents trained by the\nproposed method can make different decisions according to different states,\nwhich demonstrates that the method can solve the maneuvering decision problem\nthat the original reinforcement learning algorithm cannot solve.\n",
                "链接": "https://arxiv.org/abs/2309.08611"
            },
            {
                "文章ID": "116381",
                "标题": "Graph Sparsifications using Neural Network Assisted Monte Carlo Tree\n  Search",
                "作者": " Alvin Chiu,  Mithun Ghosh,  Reyan Ahmed,  Kwang-Sung Jun,  Stephen Kobourov,  Michael T. Goodrich",
                "发布日期": "2023-11-20",
                "摘要": "  Graph neural networks have been successful for machine learning, as well as\nfor combinatorial and graph problems such as the Subgraph Isomorphism Problem\nand the Traveling Salesman Problem. We describe an approach for computing graph\nsparsifiers by combining a graph neural network and Monte Carlo Tree Search. We\nfirst train a graph neural network that takes as input a partial solution and\nproposes a new node to be added as output. This neural network is then used in\na Monte Carlo search to compute a sparsifier. The proposed method consistently\noutperforms several standard approximation algorithms on different types of\ngraphs and often finds the optimal solution.\n",
                "链接": "https://arxiv.org/abs/2311.10316"
            },
            {
                "文章ID": "23592",
                "标题": "Combining Monte-Carlo Tree Search with Proof-Number Search",
                "作者": " Elliot Doe,  Mark H. M. Winands,  Dennis J. N. J. Soemers,  Cameron Browne",
                "发布日期": "2022-06-09",
                "摘要": "  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
                "链接": "https://arxiv.org/abs/2206.03965"
            },
            {
                "文章ID": "107708",
                "标题": "Accelerating Monte Carlo Tree Search with Probability Tree State\n  Abstraction",
                "作者": " Yangqing Fu,  Ming Sun,  Buqing Nie,  Yue Gao",
                "发布日期": "2023-10-11",
                "摘要": "  Monte Carlo Tree Search (MCTS) algorithms such as AlphaGo and MuZero have\nachieved superhuman performance in many challenging tasks. However, the\ncomputational complexity of MCTS-based algorithms is influenced by the size of\nthe search space. To address this issue, we propose a novel probability tree\nstate abstraction (PTSA) algorithm to improve the search efficiency of MCTS. A\ngeneral tree state abstraction with path transitivity is defined. In addition,\nthe probability tree state abstraction is proposed for fewer mistakes during\nthe aggregation step. Furthermore, the theoretical guarantees of the\ntransitivity and aggregation error bound are justified. To evaluate the\neffectiveness of the PTSA algorithm, we integrate it with state-of-the-art\nMCTS-based algorithms, such as Sampled MuZero and Gumbel MuZero. Experimental\nresults on different tasks demonstrate that our method can accelerate the\ntraining process of state-of-the-art algorithms with 10%-45% search space\nreduction.\n",
                "链接": "https://arxiv.org/abs/2310.06513"
            },
            {
                "文章ID": "7216",
                "标题": "Decision Making in Non-Stationary Environments with Policy-Augmented\n  Monte Carlo Tree Search",
                "作者": " Geoffrey Pettet,  Ayan Mukhopadhyay,  Abhishek Dubey",
                "发布日期": "2022-03-01",
                "摘要": "  Decision-making under uncertainty (DMU) is present in many important\nproblems. An open challenge is DMU in non-stationary environments, where the\ndynamics of the environment can change over time. Reinforcement Learning (RL),\na popular approach for DMU problems, learns a policy by interacting with a\nmodel of the environment offline. Unfortunately, if the environment changes the\npolicy can become stale and take sub-optimal actions, and relearning the policy\nfor the updated environment takes time and computational effort. An alternative\nis online planning approaches such as Monte Carlo Tree Search (MCTS), which\nperform their computation at decision time. Given the current environment, MCTS\nplans using high-fidelity models to determine promising action trajectories.\nThese models can be updated as soon as environmental changes are detected to\nimmediately incorporate them into decision making. However, MCTS's convergence\ncan be slow for domains with large state-action spaces. In this paper, we\npresent a novel hybrid decision-making approach that combines the strengths of\nRL and planning while mitigating their weaknesses. Our approach, called Policy\nAugmented MCTS (PA-MCTS), integrates a policy's actin-value estimates into\nMCTS, using the estimates to seed the action trajectories favored by the\nsearch. We hypothesize that PA-MCTS will converge more quickly than standard\nMCTS while making better decisions than the policy can make on its own when\nfaced with nonstationary environments. We test our hypothesis by comparing\nPA-MCTS with pure MCTS and an RL agent applied to the classical CartPole\nenvironment. We find that PC-MCTS can achieve higher cumulative rewards than\nthe policy in isolation under several environmental shifts while converging in\nsignificantly fewer iterations than pure MCTS.\n",
                "链接": "https://arxiv.org/abs/2202.13003"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用GPT4v完成多模态智能体的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "106036",
                "标题": "Towards End-to-End Embodied Decision Making via Multi-modal Large\n  Language Model: Explorations with GPT4-Vision and Beyond",
                "作者": " Liang Chen,  Yichi Zhang,  Shuhuai Ren,  Haozhe Zhao,  Zefan Cai,  Yuchi Wang,  Peiyi Wang,  Tianyu Liu,  Baobao Chang",
                "发布日期": "2023-11-29",
                "摘要": "  In this study, we explore the potential of Multimodal Large Language Models\n(MLLMs) in improving embodied decision-making processes for agents. While Large\nLanguage Models (LLMs) have been widely used due to their advanced reasoning\nskills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual\nunderstanding and reasoning capabilities. We investigate whether\nstate-of-the-art MLLMs can handle embodied decision-making in an end-to-end\nmanner and whether collaborations between LLMs and MLLMs can enhance\ndecision-making. To address these questions, we introduce a new benchmark\ncalled PCA-EVAL, which evaluates embodied decision-making from the perspectives\nof Perception, Cognition, and Action. Additionally, we propose HOLMES, a\nmulti-agent cooperation framework that allows LLMs to leverage MLLMs and APIs\nto gather multimodal information for informed decision-making. We compare\nend-to-end embodied decision-making and HOLMES on our benchmark and find that\nthe GPT4-Vision model demonstrates strong end-to-end embodied decision-making\nabilities, outperforming GPT4-HOLMES in terms of average decision accuracy\n(+3%). However, this performance is exclusive to the latest GPT4-Vision model,\nsurpassing the open-source state-of-the-art MLLM by 26%. Our results indicate\nthat powerful MLLMs like GPT4-Vision hold promise for decision-making in\nembodied agents, offering new avenues for MLLM research. Code and data are open\nat https://github.com/pkunlp-icler/PCA-EVAL/.\n",
                "链接": "https://arxiv.org/abs/2310.02071"
            },
            {
                "文章ID": "83868",
                "标题": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM\n  Agents",
                "作者": " Yashar Talebirad,  Amirhossein Nadiri",
                "发布日期": "2023-06-07",
                "摘要": "  In this paper, we present a novel framework for enhancing the capabilities of\nlarge language models (LLMs) by leveraging the power of multi-agent systems.\nOur framework introduces a collaborative environment where multiple intelligent\nagent components, each with distinctive attributes and roles, work together to\nhandle complex tasks more efficiently and effectively. We demonstrate the\npracticality and versatility of our framework through case studies in\nartificial general intelligence (AGI), specifically focusing on the Auto-GPT\nand BabyAGI models. We also examine the \"Gorilla\" model, which integrates\nexternal APIs into the LLM. Our framework addresses limitations and challenges\nsuch as looping issues, security risks, scalability, system evaluation, and\nethical considerations. By modeling various domains such as courtroom\nsimulations and software development scenarios, we showcase the potential\napplications and benefits of our proposed multi-agent system. Our framework\nprovides an avenue for advancing the capabilities and performance of LLMs\nthrough collaboration and knowledge exchange among intelligent agents.\n",
                "链接": "https://arxiv.org/abs/2306.03314"
            },
            {
                "文章ID": "61287",
                "标题": "Universal Agent Mixtures and the Geometry of Intelligence",
                "作者": " Samuel Allen Alexander,  David Quarel,  Len Du,  Marcus Hutter",
                "发布日期": "2023-02-14",
                "摘要": "  Inspired by recent progress in multi-agent Reinforcement Learning (RL), in\nthis work we examine the collective intelligent behaviour of theoretical\nuniversal agents by introducing a weighted mixture operation. Given a weighted\nset of agents, their weighted mixture is a new agent whose expected total\nreward in any environment is the corresponding weighted average of the original\nagents' expected total rewards in that environment. Thus, if RL agent\nintelligence is quantified in terms of performance across environments, the\nweighted mixture's intelligence is the weighted average of the original agents'\nintelligences. This operation enables various interesting new theorems that\nshed light on the geometry of RL agent intelligence, namely: results about\nsymmetries, convex agent-sets, and local extrema. We also show that any RL\nagent intelligence measure based on average performance across environments,\nsubject to certain weak technical conditions, is identical (up to a constant\nfactor) to performance within a single environment dependent on said\nintelligence measure.\n",
                "链接": "https://arxiv.org/abs/2302.06083"
            },
            {
                "文章ID": "63940",
                "标题": "Scenarios and branch points to future machine intelligence",
                "作者": " Koichi Takahashi",
                "发布日期": "2023-03-03",
                "摘要": "  We discuss scenarios and branch points to four major possible consequences\nregarding future machine intelligence; 1) the singleton scenario where the\nfirst and only super-intelligence acquires a decisive strategic advantage, 2)\nthe multipolar scenario where the singleton scenario is not technically denied\nbut political or other factors in human society or multi-agent interactions\nbetween the intelligent agents prevent a single agent from gaining a decisive\nstrategic advantage, 3) the ecosystem scenario where the singleton scenario is\ndenied and many autonomous intelligent agents operate in such a way that they\nare interdependent and virtually unstoppable, and 4) the upper-bound scenario\nwhere cognitive capabilities that can be achieved by human-designed intelligent\nagents or their descendants are inherently limited to the sub-human level. We\nidentify six major constraints that can form branch points to these scenarios;\n(1) constraints on autonomy, (2) constraints on the ability to improve\nself-structure, (3) constraints related to thermodynamic efficiency, (4)\nconstraints on updating physical infrastructure, (5) constraints on relative\nadvantage, and (6) constraints on locality.\n",
                "链接": "https://arxiv.org/abs/2302.14478"
            },
            {
                "文章ID": "86459",
                "标题": "Genes in Intelligent Agents",
                "作者": " Fu Feng,  Jing Wang,  Xu Yang,  Xin Geng",
                "发布日期": "2023-10-30",
                "摘要": "  The genes in nature give the lives on earth the current biological\nintelligence through transmission and accumulation over billions of years.\nInspired by the biological intelligence, artificial intelligence (AI) has\ndevoted to building the machine intelligence. Although it has achieved thriving\nsuccesses, the machine intelligence still lags far behind the biological\nintelligence. The reason may lie in that animals are born with some\nintelligence encoded in their genes, but machines lack such intelligence and\nlearn from scratch. Inspired by the genes of animals, we define the ``genes''\nof machines named as the ``learngenes'' and propose the Genetic Reinforcement\nLearning (GRL). GRL is a computational framework that simulates the evolution\nof organisms in reinforcement learning (RL) and leverages the learngenes to\nlearn and evolve the intelligence agents. Leveraging GRL, we first show that\nthe learngenes take the form of the fragments of the agents' neural networks\nand can be inherited across generations. Second, we validate that the\nlearngenes can transfer ancestral experience to the agents and bring them\ninstincts and strong learning abilities. Third, we justify the Lamarckian\ninheritance of the intelligent agents and the continuous evolution of the\nlearngenes. Overall, the learngenes have taken the machine intelligence one\nmore step toward the biological intelligence.\n",
                "链接": "https://arxiv.org/abs/2306.10225"
            },
            {
                "文章ID": "102901",
                "标题": "Pointing out Human Answer Mistakes in a Goal-Oriented Visual Dialogue",
                "作者": " Ryosuke Oshima,  Seitaro Shinagawa,  Hideki Tsunashima,  Qi Feng,  Shigeo Morishima",
                "发布日期": "2023-09-20",
                "摘要": "  Effective communication between humans and intelligent agents has promising\napplications for solving complex problems. One such approach is visual\ndialogue, which leverages multimodal context to assist humans. However,\nreal-world scenarios occasionally involve human mistakes, which can cause\nintelligent agents to fail. While most prior research assumes perfect answers\nfrom human interlocutors, we focus on a setting where the agent points out\nunintentional mistakes for the interlocutor to review, better reflecting\nreal-world situations. In this paper, we show that human answer mistakes depend\non question type and QA turn in the visual dialogue by analyzing a previously\nunused data collection of human mistakes. We demonstrate the effectiveness of\nthose factors for the model's accuracy in a pointing-human-mistake task through\nexperiments using a simple MLP model and a Visual Language Model.\n",
                "链接": "https://arxiv.org/abs/2309.10375"
            },
            {
                "文章ID": "102059",
                "标题": "The Rise and Potential of Large Language Model Based Agents: A Survey",
                "作者": " Zhiheng Xi,  Wenxiang Chen,  Xin Guo,  Wei He,  Yiwen Ding,  Boyang Hong,  Ming Zhang,  Junzhe Wang,  Senjie Jin,  Enyu Zhou,  Rui Zheng,  Xiaoran Fan,  Xiao Wang,  Limao Xiong,  Yuhao Zhou,  Weiran Wang,  Changhao Jiang,  Yicheng Zou,  Xiangyang Liu,  Zhangyue Yin,  Shihan Dou,  Rongxiang Weng,  Wensen Cheng,  Qi Zhang,  Wenjuan Qin,  Yongyan Zheng,  Xipeng Qiu,  Xuanjing Huang,  Tao Gui",
                "发布日期": "2023-09-20",
                "摘要": "  For a long time, humanity has pursued artificial intelligence (AI) equivalent\nto or surpassing the human level, with AI agents considered a promising vehicle\nfor this pursuit. AI agents are artificial entities that sense their\nenvironment, make decisions, and take actions. Many efforts have been made to\ndevelop intelligent agents, but they mainly focus on advancement in algorithms\nor training strategies to enhance specific capabilities or performance on\nparticular tasks. Actually, what the community lacks is a general and powerful\nmodel to serve as a starting point for designing AI agents that can adapt to\ndiverse scenarios. Due to the versatile capabilities they demonstrate, large\nlanguage models (LLMs) are regarded as potential sparks for Artificial General\nIntelligence (AGI), offering hope for building general AI agents. Many\nresearchers have leveraged LLMs as the foundation to build AI agents and have\nachieved significant progress. In this paper, we perform a comprehensive survey\non LLM-based agents. We start by tracing the concept of agents from its\nphilosophical origins to its development in AI, and explain why LLMs are\nsuitable foundations for agents. Building upon this, we present a general\nframework for LLM-based agents, comprising three main components: brain,\nperception, and action, and the framework can be tailored for different\napplications. Subsequently, we explore the extensive applications of LLM-based\nagents in three aspects: single-agent scenarios, multi-agent scenarios, and\nhuman-agent cooperation. Following this, we delve into agent societies,\nexploring the behavior and personality of LLM-based agents, the social\nphenomena that emerge from an agent society, and the insights they offer for\nhuman society. Finally, we discuss several key topics and open problems within\nthe field. A repository for the related papers at\nhttps://github.com/WooooDyy/LLM-Agent-Paper-List.\n",
                "链接": "https://arxiv.org/abs/2309.07864"
            },
            {
                "文章ID": "124256",
                "标题": "AppAgent: Multimodal Agents as Smartphone Users",
                "作者": " Chi Zhang,  Zhao Yang,  Jiaxuan Liu,  Yucheng Han,  Xin Chen,  Zebiao Huang,  Bin Fu,  Gang Yu",
                "发布日期": "2023-12-25",
                "摘要": "  Recent advancements in large language models (LLMs) have led to the creation\nof intelligent agents capable of performing complex tasks. This paper\nintroduces a novel LLM-based multimodal agent framework designed to operate\nsmartphone applications. Our framework enables the agent to operate smartphone\napplications through a simplified action space, mimicking human-like\ninteractions such as tapping and swiping. This novel approach bypasses the need\nfor system back-end access, thereby broadening its applicability across diverse\napps. Central to our agent's functionality is its innovative learning method.\nThe agent learns to navigate and use new apps either through autonomous\nexploration or by observing human demonstrations. This process generates a\nknowledge base that the agent refers to for executing complex tasks across\ndifferent applications. To demonstrate the practicality of our agent, we\nconducted extensive testing over 50 tasks in 10 different applications,\nincluding social media, email, maps, shopping, and sophisticated image editing\ntools. The results affirm our agent's proficiency in handling a diverse array\nof high-level tasks.\n",
                "链接": "https://arxiv.org/abs/2312.13771"
            },
            {
                "文章ID": "89555",
                "标题": "What Matters in Training a GPT4-Style Language Model with Multimodal\n  Inputs?",
                "作者": " Yan Zeng,  Hanbo Zhang,  Jiani Zheng,  Jiangnan Xia,  Guoqiang Wei,  Yang Wei,  Yuchen Zhang,  Tao Kong",
                "发布日期": "2023-08-01",
                "摘要": "  Recent advancements in Large Language Models (LLMs) such as GPT4 have\ndisplayed exceptional multi-modal capabilities in following open-ended\ninstructions given images. However, the performance of these models heavily\nrelies on design choices such as network structures, training data, and\ntraining strategies, and these choices have not been extensively discussed in\nthe literature, making it difficult to quantify progress in this field. To\naddress this issue, this paper presents a systematic and comprehensive study,\nquantitatively and qualitatively, on training such models. We implement over 20\nvariants with controlled settings. Concretely, for network structures, we\ncompare different LLM backbones and model designs. For training data, we\ninvestigate the impact of data and sampling strategies. For instructions, we\nexplore the influence of diversified prompts on the instruction-following\nability of the trained models. For benchmarks, we contribute the first, to our\nbest knowledge, comprehensive evaluation set including both image and video\ntasks through crowd-sourcing. Based on our findings, we present Lynx, which\nperforms the most accurate multi-modal understanding while keeping the best\nmulti-modal generation ability compared to existing open-sourced GPT4-style\nmodels.\n",
                "链接": "https://arxiv.org/abs/2307.02469"
            },
            {
                "文章ID": "21325",
                "标题": "Evaluating Multimodal Interactive Agents",
                "作者": " Josh Abramson,  Arun Ahuja,  Federico Carnevale,  Petko Georgiev,  Alex Goldin,  Alden Hung,  Jessica Landon,  Timothy Lillicrap,  Alistair Muldal,  Blake Richards,  Adam Santoro,  Tamara von Glehn,  Greg Wayne,  Nathaniel Wong,  Chen Yan",
                "发布日期": "2022-07-15",
                "摘要": "  Creating agents that can interact naturally with humans is a common goal in\nartificial intelligence (AI) research. However, evaluating these interactions\nis challenging: collecting online human-agent interactions is slow and\nexpensive, yet faster proxy metrics often do not correlate well with\ninteractive evaluation. In this paper, we assess the merits of these existing\nevaluation metrics and present a novel approach to evaluation called the\nStandardised Test Suite (STS). The STS uses behavioural scenarios mined from\nreal human interaction data. Agents see replayed scenario context, receive an\ninstruction, and are then given control to complete the interaction offline.\nThese agent continuations are recorded and sent to human annotators to mark as\nsuccess or failure, and agents are ranked according to the proportion of\ncontinuations in which they succeed. The resulting STS is fast, controlled,\ninterpretable, and representative of naturalistic interactions. Altogether, the\nSTS consolidates much of what is desirable across many of our standard\nevaluation metrics, allowing us to accelerate research progress towards\nproducing agents that can interact naturally with humans. A video may be found\nat https://youtu.be/YR1TngGORGQ.\n",
                "链接": "https://arxiv.org/abs/2205.13274"
            }
        ]
    },
    {
        "question": {
            "question": "使用LLM进行蛋白质结构/功能/性质预测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "34638",
                "标题": "Secondary Protein Structure Prediction Using Neural Networks",
                "作者": " Sidharth Malhotra,  Robin Walters",
                "发布日期": "2022-08-25",
                "摘要": "  In this paper we experiment with using neural network structures to predict a\nprotein's secondary structure ({\\alpha} helix positions) from only its primary\nstructure (amino acid sequence). We implement a fully connected neural network\n(FCNN) and preform three experiments using that FCNN. Firstly, we do a\ncross-species comparison of models trained and tested on mouse and human\ndatasets. Secondly, we test the impact of varying the length of protein\nsequence we input into the model. Thirdly, we compare custom error functions\ndesigned to focus on the center of the input window. At the end of paper we\npropose a alternative, recurrent neural network model which can be applied to\nthe problem.\n",
                "链接": "https://arxiv.org/abs/2208.11248"
            },
            {
                "文章ID": "109510",
                "标题": "Protein 3D Graph Structure Learning for Robust Structure-based Protein\n  Property Prediction",
                "作者": " Yufei Huang,  Siyuan Li,  Jin Su,  Lirong Wu,  Odin Zhang,  Haitao Lin,  Jingqi Qi,  Zihan Liu,  Zhangyang Gao,  Yuyang Liu,  Jiangbin Zheng,  Stan. ZQ. Li",
                "发布日期": "2023-10-20",
                "摘要": "  Protein structure-based property prediction has emerged as a promising\napproach for various biological tasks, such as protein function prediction and\nsub-cellular location estimation. The existing methods highly rely on\nexperimental protein structure data and fail in scenarios where these data are\nunavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were\nutilized as alternatives. However, we observed that current practices, which\nsimply employ accurately predicted structures during inference, suffer from\nnotable degradation in prediction accuracy. While similar phenomena have been\nextensively studied in general fields (e.g., Computer Vision) as model\nrobustness, their impact on protein property prediction remains unexplored. In\nthis paper, we first investigate the reason behind the performance decrease\nwhen utilizing predicted structures, attributing it to the structure embedding\nbias from the perspective of structure representation learning. To study this\nproblem, we identify a Protein 3D Graph Structure Learning Problem for Robust\nProtein Property Prediction (PGSL-RP3), collect benchmark datasets, and present\na protein Structure embedding Alignment Optimization framework (SAO) to\nmitigate the problem of structure embedding bias between the predicted and\nexperimental protein structures. Extensive experiments have shown that our\nframework is model-agnostic and effective in improving the property prediction\nof both predicted structures and experimental structures. The benchmark\ndatasets and codes will be released to benefit the community.\n",
                "链接": "https://arxiv.org/abs/2310.11466"
            },
            {
                "文章ID": "26245",
                "标题": "PSP: Million-level Protein Sequence Dataset for Protein Structure\n  Prediction",
                "作者": " Sirui Liu,  Jun Zhang,  Haotian Chu,  Min Wang,  Boxin Xue,  Ningxi Ni,  Jialiang Yu,  Yuhao Xie,  Zhenyu Chen,  Mengyun Chen,  Yuan Liu,  Piya Patra,  Fan Xu,  Jie Chen,  Zidong Wang,  Lijiang Yang,  Fan Yu,  Lei Chen,  Yi Qin Gao",
                "发布日期": "2022-06-27",
                "摘要": "  Proteins are essential component of human life and their structures are\nimportant for function and mechanism analysis. Recent work has shown the\npotential of AI-driven methods for protein structure prediction. However, the\ndevelopment of new models is restricted by the lack of dataset and benchmark\ntraining procedure. To the best of our knowledge, the existing open source\ndatasets are far less to satisfy the needs of modern protein sequence-structure\nrelated research. To solve this problem, we present the first million-level\nprotein structure prediction dataset with high coverage and diversity, named as\nPSP. This dataset consists of 570k true structure sequences (10TB) and 745k\ncomplementary distillation sequences (15TB). We provide in addition the\nbenchmark training procedure for SOTA protein structure prediction model on\nthis dataset. We validate the utility of this dataset for training by\nparticipating CAMEO contest in which our model won the first place. We hope our\nPSP dataset together with the training benchmark can enable a broader community\nof AI/biology researchers for AI-driven protein related research.\n",
                "链接": "https://arxiv.org/abs/2206.12240"
            },
            {
                "文章ID": "48975",
                "标题": "A Review of Deep Learning Techniques for Protein Function Prediction",
                "作者": " Divyanshu Aggarwal,  Yasha Hasija",
                "发布日期": "2022-11-18",
                "摘要": "  Deep Learning and big data have shown tremendous success in bioinformatics\nand computational biology in recent years; artificial intelligence methods have\nalso significantly contributed in the task of protein function classification.\nThis review paper analyzes the recent developments in approaches for the task\nof predicting protein function using deep learning. We explain the importance\nof determining the protein function and why automating the following task is\ncrucial. Then, after reviewing the widely used deep learning techniques for\nthis task, we continue our review and highlight the emergence of the modern\nState of The Art (SOTA) deep learning models which have achieved groundbreaking\nresults in the field of computer vision, natural language processing and\nmulti-modal learning in the last few years. We hope that this review will\nprovide a broad view of the current role and advances of deep learning in\nbiological sciences, especially in predicting protein function tasks and\nencourage new researchers to contribute to this area.\n",
                "链接": "https://arxiv.org/abs/2211.09705"
            },
            {
                "文章ID": "31301",
                "标题": "HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein\n  Language Model as an Alternative",
                "作者": " Xiaomin Fang,  Fan Wang,  Lihang Liu,  Jingzhou He,  Dayong Lin,  Yingfei Xiang,  Xiaonan Zhang,  Hua Wu,  Hui Li,  Le Song",
                "发布日期": "2023-10-19",
                "摘要": "  AI-based protein structure prediction pipelines, such as AlphaFold2, have\nachieved near-experimental accuracy. These advanced pipelines mainly rely on\nMultiple Sequence Alignments (MSAs) as inputs to learn the co-evolution\ninformation from the homologous sequences. Nonetheless, searching MSAs from\nprotein databases is time-consuming, usually taking dozens of minutes.\nConsequently, we attempt to explore the limits of fast protein structure\nprediction by using only primary sequences of proteins. HelixFold-Single is\nproposed to combine a large-scale protein language model with the superior\ngeometric learning capability of AlphaFold2. Our proposed method,\nHelixFold-Single, first pre-trains a large-scale protein language model (PLM)\nwith thousands of millions of primary sequences utilizing the self-supervised\nlearning paradigm, which will be used as an alternative to MSAs for learning\nthe co-evolution information. Then, by combining the pre-trained PLM and the\nessential components of AlphaFold2, we obtain an end-to-end differentiable\nmodel to predict the 3D coordinates of atoms from only the primary sequence.\nHelixFold-Single is validated in datasets CASP14 and CAMEO, achieving\ncompetitive accuracy with the MSA-based methods on the targets with large\nhomologous families. Furthermore, HelixFold-Single consumes much less time than\nthe mainstream pipelines for protein structure prediction, demonstrating its\npotential in tasks requiring many predictions. The code of HelixFold-Single is\navailable at\nhttps://github.com/PaddlePaddle/PaddleHelix/tree/dev/apps/protein_folding/helixfold-single,\nand we also provide stable web services on\nhttps://paddlehelix.baidu.com/app/drug/protein-single/forecast.\n",
                "链接": "https://arxiv.org/abs/2207.13921"
            },
            {
                "文章ID": "100807",
                "标题": "Insights Into the Inner Workings of Transformer Models for Protein\n  Function Prediction",
                "作者": " Markus Wenzel,  Erik Grüner,  Nils Strodthoff",
                "发布日期": "2023-09-08",
                "摘要": "  Motivation: We explored how explainable AI (XAI) can help to shed light into\nthe inner workings of neural networks for protein function prediction, by\nextending the widely used XAI method of integrated gradients such that latent\nrepresentations inside of transformer models, which were finetuned to Gene\nOntology term and Enzyme Commission number prediction, can be inspected too.\nResults: The approach enabled us to identify amino acids in the sequences that\nthe transformers pay particular attention to, and to show that these relevant\nsequence parts reflect expectations from biology and chemistry, both in the\nembedding layer and inside of the model, where we identified transformer heads\nwith a statistically significant correspondence of attribution maps with ground\ntruth sequence annotations (e.g., transmembrane regions, active sites) across\nmany proteins. Availability and Implementation: Source code can be accessed at\nhttps://github.com/markuswenzel/xai-proteins .\n",
                "链接": "https://arxiv.org/abs/2309.03631"
            },
            {
                "文章ID": "84482",
                "标题": "Multi-level Protein Representation Learning for Blind Mutational Effect\n  Prediction",
                "作者": " Yang Tan,  Bingxin Zhou,  Yuanhong Jiang,  Yu Guang Wang,  Liang Hong",
                "发布日期": "2023-06-09",
                "摘要": "  Directed evolution plays an indispensable role in protein engineering that\nrevises existing protein sequences to attain new or enhanced functions.\nAccurately predicting the effects of protein variants necessitates an in-depth\nunderstanding of protein structure and function. Although large self-supervised\nlanguage models have demonstrated remarkable performance in zero-shot inference\nusing only protein sequences, these models inherently do not interpret the\nspatial characteristics of protein structures, which are crucial for\ncomprehending protein folding stability and internal molecular interactions.\nThis paper introduces a novel pre-training framework that cascades sequential\nand geometric analyzers for protein primary and tertiary structures. It guides\nmutational directions toward desired traits by simulating natural selection on\nwild-type proteins and evaluates the effects of variants based on their fitness\nto perform the function. We assess the proposed approach using a public\ndatabase and two new databases for a variety of variant effect prediction\ntasks, which encompass a diverse set of proteins and assays from different\ntaxa. The prediction results achieve state-of-the-art performance over other\nzero-shot learning methods for both single-site mutations and deep mutations.\n",
                "链接": "https://arxiv.org/abs/2306.04899"
            },
            {
                "文章ID": "70802",
                "标题": "EigenFold: Generative Protein Structure Prediction with Diffusion Models",
                "作者": " Bowen Jing,  Ezra Erives,  Peter Pao-Huang,  Gabriele Corso,  Bonnie Berger,  Tommi Jaakkola",
                "发布日期": "2023-04-06",
                "摘要": "  Protein structure prediction has reached revolutionary levels of accuracy on\nsingle structures, yet distributional modeling paradigms are needed to capture\nthe conformational ensembles and flexibility that underlie biological function.\nTowards this goal, we develop EigenFold, a diffusion generative modeling\nframework for sampling a distribution of structures from a given protein\nsequence. We define a diffusion process that models the structure as a system\nof harmonic oscillators and which naturally induces a cascading-resolution\ngenerative process along the eigenmodes of the system. On recent CAMEO targets,\nEigenFold achieves a median TMScore of 0.84, while providing a more\ncomprehensive picture of model uncertainty via the ensemble of sampled\nstructures relative to existing methods. We then assess EigenFold's ability to\nmodel and predict conformational heterogeneity for fold-switching proteins and\nligand-induced conformational change. Code is available at\nhttps://github.com/bjing2016/EigenFold.\n",
                "链接": "https://arxiv.org/abs/2304.02198"
            },
            {
                "文章ID": "106475",
                "标题": "InstructProtein: Aligning Human and Protein Language via Knowledge\n  Instruction",
                "作者": " Zeyuan Wang,  Qiang Zhang,  Keyan Ding,  Ming Qin,  Xiang Zhuang,  Xiaotong Li,  Huajun Chen",
                "发布日期": "2023-10-06",
                "摘要": "  Large Language Models (LLMs) have revolutionized the field of natural\nlanguage processing, but they fall short in comprehending biological sequences\nsuch as proteins. To address this challenge, we propose InstructProtein, an\ninnovative LLM that possesses bidirectional generation capabilities in both\nhuman and protein languages: (i) taking a protein sequence as input to predict\nits textual function description and (ii) using natural language to prompt\nprotein sequence generation. To achieve this, we first pre-train an LLM on both\nprotein and natural language corpora, enabling it to comprehend individual\nlanguages. Then supervised instruction tuning is employed to facilitate the\nalignment of these two distinct languages. Herein, we introduce a knowledge\ngraph-based instruction generation framework to construct a high-quality\ninstruction dataset, addressing annotation imbalance and instruction deficits\nin existing protein-text corpus. In particular, the instructions inherit the\nstructural relations between proteins and function annotations in knowledge\ngraphs, which empowers our model to engage in the causal modeling of protein\nfunctions, akin to the chain-of-thought processes in natural languages.\nExtensive experiments on bidirectional protein-text generation tasks show that\nInstructProtein outperforms state-of-the-art LLMs by large margins. Moreover,\nInstructProtein serves as a pioneering step towards text-based protein function\nprediction and sequence design, effectively bridging the gap between protein\nand human language understanding.\n",
                "链接": "https://arxiv.org/abs/2310.03269"
            },
            {
                "文章ID": "106701",
                "标题": "CrysFormer: Protein Structure Prediction via 3d Patterson Maps and\n  Partial Structure Attention",
                "作者": " Chen Dun,  Qiutai Pan,  Shikai Jin,  Ria Stevens,  Mitchell D. Miller, Jr. George N. Phillips,,  Anastasios Kyrillidis",
                "发布日期": "2023-10-09",
                "摘要": "  Determining the structure of a protein has been a decades-long open question.\nA protein's three-dimensional structure often poses nontrivial computation\ncosts, when classical simulation algorithms are utilized. Advances in the\ntransformer neural network architecture -- such as AlphaFold2 -- achieve\nsignificant improvements for this problem, by learning from a large dataset of\nsequence information and corresponding protein structures. Yet, such methods\nonly focus on sequence information; other available prior knowledge, such as\nprotein crystallography and partial structure of amino acids, could be\npotentially utilized. To the best of our knowledge, we propose the first\ntransformer-based model that directly utilizes protein crystallography and\npartial structure information to predict the electron density maps of proteins.\nVia two new datasets of peptide fragments (2-residue and 15-residue) , we\ndemonstrate our method, dubbed \\texttt{CrysFormer}, can achieve accurate\npredictions, based on a much smaller dataset size and with reduced computation\ncosts.\n",
                "链接": "https://arxiv.org/abs/2310.03899"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用BERT和RoBERTa进行多语言情感分析的最新论文，要求涵盖2022年以来的研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "2025",
                "标题": "NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual\n  Sentiment Analysis",
                "作者": " Shamsuddeen Hassan Muhammad,  David Ifeoluwa Adelani,  Sebastian Ruder,  Ibrahim Said Ahmad,  Idris Abdulmumin,  Bello Shehu Bello,  Monojit Choudhury,  Chris Chinenye Emezue,  Saheed Salahudeen Abdullahi,  Anuoluwapo Aremu,  Alipio Jeorge,  Pavel Brazdil",
                "发布日期": "2022-06-22",
                "摘要": "  Sentiment analysis is one of the most widely studied applications in NLP, but\nmost work focuses on languages with large amounts of data. We introduce the\nfirst large-scale human-annotated Twitter sentiment dataset for the four most\nwidely spoken languages in Nigeria (Hausa, Igbo, Nigerian-Pidgin, and\nYor\\`ub\\'a ) consisting of around 30,000 annotated tweets per language (and\n14,000 for Nigerian-Pidgin), including a significant fraction of code-mixed\ntweets. We propose text collection, filtering, processing and labeling methods\nthat enable us to create datasets for these low-resource languages. We evaluate\na rangeof pre-trained models and transfer strategies on the dataset. We find\nthat language-specific models and language-adaptivefine-tuning generally\nperform best. We release the datasets, trained models, sentiment lexicons, and\ncode to incentivizeresearch on sentiment analysis in under-represented\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2201.08277"
            },
            {
                "文章ID": "824",
                "标题": "BERT for Sentiment Analysis: Pre-trained and Fine-Tuned Alternatives",
                "作者": " Frederico Souza,  João Filho",
                "发布日期": "2022-01-11",
                "摘要": "  BERT has revolutionized the NLP field by enabling transfer learning with\nlarge language models that can capture complex textual patterns, reaching the\nstate-of-the-art for an expressive number of NLP applications. For text\nclassification tasks, BERT has already been extensively explored. However,\naspects like how to better cope with the different embeddings provided by the\nBERT output layer and the usage of language-specific instead of multilingual\nmodels are not well studied in the literature, especially for the Brazilian\nPortuguese language. The purpose of this article is to conduct an extensive\nexperimental study regarding different strategies for aggregating the features\nproduced in the BERT output layer, with a focus on the sentiment analysis task.\nThe experiments include BERT models trained with Brazilian Portuguese corpora\nand the multilingual version, contemplating multiple aggregation strategies and\nopen-source datasets with predefined training, validation, and test partitions\nto facilitate the reproducibility of the results. BERT achieved the highest\nROC-AUC values for the majority of cases as compared to TF-IDF. Nonetheless,\nTF-IDF represents a good trade-off between the predictive performance and\ncomputational cost.\n",
                "链接": "https://arxiv.org/abs/2201.03382"
            },
            {
                "文章ID": "51693",
                "标题": "Adapted Multimodal BERT with Layer-wise Fusion for Sentiment Analysis",
                "作者": " Odysseas S. Chlapanis,  Georgios Paraskevopoulos,  Alexandros Potamianos",
                "发布日期": "2022-12-02",
                "摘要": "  Multimodal learning pipelines have benefited from the success of pretrained\nlanguage models. However, this comes at the cost of increased model parameters.\nIn this work, we propose Adapted Multimodal BERT (AMB), a BERT-based\narchitecture for multimodal tasks that uses a combination of adapter modules\nand intermediate fusion layers. The adapter adjusts the pretrained language\nmodel for the task at hand, while the fusion layers perform task-specific,\nlayer-wise fusion of audio-visual information with textual BERT\nrepresentations. During the adaptation process the pre-trained language model\nparameters remain frozen, allowing for fast, parameter-efficient training. In\nour ablations we see that this approach leads to efficient models, that can\noutperform their fine-tuned counterparts and are robust to input noise. Our\nexperiments on sentiment analysis with CMU-MOSEI show that AMB outperforms the\ncurrent state-of-the-art across metrics, with 3.4% relative reduction in the\nresulting error and 2.1% relative improvement in 7-class classification\naccuracy.\n",
                "链接": "https://arxiv.org/abs/2212.00678"
            },
            {
                "文章ID": "82977",
                "标题": "UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of\n  Multilingual BERT for Low-resource Sentiment Analysis",
                "作者": " Dou Hu,  Lingwei Wei,  Yaxin Liu,  Wei Zhou,  Songlin Hu",
                "发布日期": "2023-06-05",
                "摘要": "  This paper describes our system designed for SemEval-2023 Task 12: Sentiment\nanalysis for African languages. The challenge faced by this task is the\nscarcity of labeled data and linguistic resources in low-resource settings. To\nalleviate these, we propose a generalized multilingual system SACL-XLMR for\nsentiment analysis on low-resource languages. Specifically, we design a\nlexicon-based multilingual BERT to facilitate language adaptation and\nsentiment-aware representation learning. Besides, we apply a supervised\nadversarial contrastive learning technique to learn sentiment-spread structured\nrepresentations and enhance model generalization. Our system achieved\ncompetitive results, largely outperforming baselines on both multilingual and\nzero-shot sentiment classification subtasks. Notably, the system obtained the\n1st rank on the zero-shot classification subtask in the official ranking.\nExtensive experiments demonstrate the effectiveness of our system.\n",
                "链接": "https://arxiv.org/abs/2306.01093"
            },
            {
                "文章ID": "122161",
                "标题": "Sentiment analysis in Tourism: Fine-tuning BERT or sentence embeddings\n  concatenation?",
                "作者": " Ibrahim Bouabdallaoui,  Fatima Guerouate,  Samya Bouhaddour,  Chaimae Saadi,  Mohammed Sbihi",
                "发布日期": "2023-12-14",
                "摘要": "  Undoubtedly that the Bidirectional Encoder representations from Transformers\nis the most powerful technique in making Natural Language Processing tasks such\nas Named Entity Recognition, Question & Answers or Sentiment Analysis, however,\nthe use of traditional techniques remains a major potential for the improvement\nof recent models, in particular word tokenization techniques and embeddings,\nbut also the improvement of neural network architectures which are now the core\nof each architecture. recent. In this paper, we conduct a comparative study\nbetween Fine-Tuning the Bidirectional Encoder Representations from Transformers\nand a method of concatenating two embeddings to boost the performance of a\nstacked Bidirectional Long Short-Term Memory-Bidirectional Gated Recurrent\nUnits model; these two approaches are applied in the context of sentiment\nanalysis of shopping places in Morocco. A search for the best learning rate was\nmade at the level of the two approaches, and a comparison of the best\noptimizers was made for each sentence embedding combination with regard to the\nsecond approach.\n",
                "链接": "https://arxiv.org/abs/2312.07797"
            },
            {
                "文章ID": "95613",
                "标题": "Performance Analysis of Transformer Based Models (BERT, ALBERT and\n  RoBERTa) in Fake News Detection",
                "作者": " Shafna Fitria Nur Azizah,  Hasan Dwi Cahyono,  Sari Widya Sihwi,  Wisnu Widiarto",
                "发布日期": "2023-08-10",
                "摘要": "  Fake news is fake material in a news media format but is not processed\nproperly by news agencies. The fake material can provoke or defame significant\nentities or individuals or potentially even for the personal interests of the\ncreators, causing problems for society. Distinguishing fake news and real news\nis challenging due to limited of domain knowledge and time constraints.\nAccording to the survey, the top three areas most exposed to hoaxes and\nmisinformation by residents are in Banten, DKI Jakarta and West Java. The model\nof transformers is referring to an approach in the field of artificial\nintelligence (AI) in natural language processing utilizing the deep learning\narchitectures. Transformers exercise a powerful attention mechanism to process\ntext in parallel and produce rich and contextual word representations. A\nprevious study indicates a superior performance of a transformer model known as\nBERT over and above non transformer approach. However, some studies suggest the\nperformance can be improved with the use of improved BERT models known as\nALBERT and RoBERTa. However, the modified BERT models are not well explored for\ndetecting fake news in Bahasa Indonesia. In this research, we explore those\ntransformer models and found that ALBERT outperformed other models with 87.6%\naccuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch)\nrespectively. Source code available at:\nhttps://github.com/Shafna81/fakenewsdetection.git\n",
                "链接": "https://arxiv.org/abs/2308.04950"
            },
            {
                "文章ID": "28107",
                "标题": "Sensitivity Analysis on Transferred Neural Architectures of BERT and\n  GPT-2 for Financial Sentiment Analysis",
                "作者": " Tracy Qian,  Andy Xie,  Camille Bruckmann",
                "发布日期": "2022-07-08",
                "摘要": "  The explosion in novel NLP word embedding and deep learning techniques has\ninduced significant endeavors into potential applications. One of these\ndirections is in the financial sector. Although there is a lot of work done in\nstate-of-the-art models like GPT and BERT, there are relatively few works on\nhow well these methods perform through fine-tuning after being pre-trained, as\nwell as info on how sensitive their parameters are. We investigate the\nperformance and sensitivity of transferred neural architectures from\npre-trained GPT-2 and BERT models. We test the fine-tuning performance based on\nfreezing transformer layers, batch size, and learning rate. We find the\nparameters of BERT are hypersensitive to stochasticity in fine-tuning and that\nGPT-2 is more stable in such practice. It is also clear that the earlier layers\nof GPT-2 and BERT contain essential word pattern information that should be\nmaintained.\n",
                "链接": "https://arxiv.org/abs/2207.03037"
            },
            {
                "文章ID": "11114",
                "标题": "BERT-ASC: Implicit Aspect Representation Learning through\n  Auxiliary-Sentence Construction for Sentiment Analysis",
                "作者": " Murtadha Ahmed,  Shengfeng Pan,  Jianlin Su,  Xinxin Cao,  Wenze Zhang,  Bo Wen,  Yunfeng Liu",
                "发布日期": "2022-11-18",
                "摘要": "  Aspect-based sentiment analysis (ABSA) task aim at associating a piece of\ntext with a set of aspects and meanwhile infer their respective sentimental\npolarities. The state-of-the-art approaches are built upon fine-tuning of\nvarious pre-trained language models. They commonly attempt to learn\naspect-specific representation from the corpus. Unfortunately, the aspect is\noften expressed implicitly through a set of representatives and thus renders\nimplicit mapping process unattainable unless sufficient labeled examples are\navailable. However, high-quality labeled examples may not be readily available\nin real-world scenarios. In this paper, we propose to jointly address aspect\ncategorization and aspect-based sentiment subtasks in a unified framework.\nSpecifically, we first introduce a simple but effective mechanism to construct\nan auxiliary-sentence for the implicit aspect based on the semantic information\nin the corpus. Then, we encourage BERT to learn the aspect-specific\nrepresentation in response to the automatically constructed auxiliary-sentence\ninstead of the aspect itself. Finally, we empirically evaluate the performance\nof the proposed solution by a comparative study on real benchmark datasets for\nboth ABSA and Targeted-ABSA tasks. Our extensive experiments show that it\nconsistently achieves state-of-the-art performance in terms of aspect\ncategorization and aspect-based sentiment across all datasets and the\nimprovement margins are considerable. The code of BERT-ASC is available in\nGitHub: https://github.com/amurtadha/BERT-ASC.\n",
                "链接": "https://arxiv.org/abs/2203.11702"
            },
            {
                "文章ID": "18471",
                "标题": "A Dataset and BERT-based Models for Targeted Sentiment Analysis on\n  Turkish Texts",
                "作者": " M. Melih Mutlu,  Arzucan Özgür",
                "发布日期": "2022-05-10",
                "摘要": "  Targeted Sentiment Analysis aims to extract sentiment towards a particular\ntarget from a given text. It is a field that is attracting attention due to the\nincreasing accessibility of the Internet, which leads people to generate an\nenormous amount of data. Sentiment analysis, which in general requires\nannotated data for training, is a well-researched area for widely studied\nlanguages such as English. For low-resource languages such as Turkish, there is\na lack of such annotated data. We present an annotated Turkish dataset suitable\nfor targeted sentiment analysis. We also propose BERT-based models with\ndifferent architectures to accomplish the task of targeted sentiment analysis.\nThe results demonstrate that the proposed models outperform the traditional\nsentiment analysis models for the targeted sentiment analysis task.\n",
                "链接": "https://arxiv.org/abs/2205.04185"
            },
            {
                "文章ID": "47660",
                "标题": "BERT-Based Combination of Convolutional and Recurrent Neural Network for\n  Indonesian Sentiment Analysis",
                "作者": " Hendri Murfi,   Syamsyuriani,  Theresia Gowandi,  Gianinna Ardaneswari,  Siti Nurrohmah",
                "发布日期": "2022-11-11",
                "摘要": "  Sentiment analysis is the computational study of opinions and emotions\nex-pressed in text. Deep learning is a model that is currently producing\nstate-of-the-art in various application domains, including sentiment analysis.\nMany researchers are using a hybrid approach that combines different deep\nlearning models and has been shown to improve model performance. In sentiment\nanalysis, input in text data is first converted into a numerical\nrepresentation. The standard method used to obtain a text representation is the\nfine-tuned embedding method. However, this method does not pay attention to\neach word's context in the sentence. Therefore, the Bidirectional Encoder\nRepresentation from Transformer (BERT) model is used to obtain text\nrepresentations based on the context and position of words in sentences. This\nresearch extends the previous hybrid deep learning using BERT representation\nfor Indonesian sentiment analysis. Our simulation shows that the BERT\nrepresentation improves the accuracies of all hybrid architectures. The\nBERT-based LSTM-CNN also reaches slightly better accuracies than other\nBERT-based hybrid architectures.\n",
                "链接": "https://arxiv.org/abs/2211.05273"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找一下2018年以后使用强化学习做机器翻译任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "96953",
                "标题": "Reinforced Self-Training (ReST) for Language Modeling",
                "作者": " Caglar Gulcehre,  Tom Le Paine,  Srivatsan Srinivasan,  Ksenia Konyushkova,  Lotte Weerts,  Abhishek Sharma,  Aditya Siddhant,  Alex Ahern,  Miaosen Wang,  Chenjie Gu,  Wolfgang Macherey,  Arnaud Doucet,  Orhan Firat,  Nando de Freitas",
                "发布日期": "2023-08-22",
                "摘要": "  Reinforcement learning from human feedback (RLHF) can improve the quality of\nlarge language model's (LLM) outputs by aligning them with human preferences.\nWe propose a simple algorithm for aligning LLMs with human preferences inspired\nby growing batch reinforcement learning (RL), which we call Reinforced\nSelf-Training (ReST). Given an initial LLM policy, ReST produces a dataset by\ngenerating samples from the policy, which are then used to improve the LLM\npolicy using offline RL algorithms. ReST is more efficient than typical online\nRLHF methods because the training dataset is produced offline, which allows\ndata reuse. While ReST is a general approach applicable to all generative\nlearning settings, we focus on its application to machine translation. Our\nresults show that ReST can substantially improve translation quality, as\nmeasured by automated metrics and human evaluation on machine translation\nbenchmarks in a compute and sample-efficient manner.\n",
                "链接": "https://arxiv.org/abs/2308.08998"
            },
            {
                "文章ID": "29736",
                "标题": "MAD for Robust Reinforcement Learning in Machine Translation",
                "作者": " Domenic Donato,  Lei Yu,  Wang Ling,  Chris Dyer",
                "发布日期": "2022-07-19",
                "摘要": "  We introduce a new distributed policy gradient algorithm and show that it\noutperforms existing reward-aware training procedures such as REINFORCE,\nminimum risk training (MRT) and proximal policy optimization (PPO) in terms of\ntraining stability and generalization performance when optimizing machine\ntranslation models. Our algorithm, which we call MAD (on account of using the\nmean absolute deviation in the importance weighting calculation), has\ndistributed data generators sampling multiple candidates per source sentence on\nworker nodes, while a central learner updates the policy. MAD depends crucially\non two variance reduction strategies: (1) a conditional reward normalization\nmethod that ensures each source sentence has both positive and negative reward\ntranslation examples and (2) a new robust importance weighting scheme that acts\nas a conditional entropy regularizer. Experiments on a variety of translation\ntasks show that policies learned using the MAD algorithm perform very well when\nusing both greedy decoding and beam search, and that the learned policies are\nsensitive to the specific reward used during training.\n",
                "链接": "https://arxiv.org/abs/2207.08583"
            },
            {
                "文章ID": "79608",
                "标题": "Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine\n  Translation",
                "作者": " Jiayi Wang,  Ke Wang,  Yuqi Zhang,  Yu Zhao,  Pontus Stenetorp",
                "发布日期": "2023-05-24",
                "摘要": "  Non-parametric, k-nearest-neighbor algorithms have recently made inroads to\nassist generative models such as language models and machine translation\ndecoders. We explore whether such non-parametric models can improve machine\ntranslation models at the fine-tuning stage by incorporating statistics from\nthe kNN predictions to inform the gradient updates for a baseline translation\nmodel. There are multiple methods which could be used to incorporate kNN\nstatistics and we investigate gradient scaling by a gating mechanism, the kNN's\nground truth probability, and reinforcement learning. For four standard\nin-domain machine translation datasets, compared with classic fine-tuning, we\nreport consistent improvements of all of the three methods by as much as 1.45\nBLEU and 1.28 BLEU for German-English and English-German translations\nrespectively. Through qualitative analysis, we found particular improvements\nwhen it comes to translating grammatical relations or function words, which\nresults in increased fluency of our model.\n",
                "链接": "https://arxiv.org/abs/2305.13648"
            },
            {
                "文章ID": "112036",
                "标题": "A Review of Reinforcement Learning for Natural Language Processing, and\n  Applications in Healthcare",
                "作者": " Ying Liu,  Haozhu Wang,  Huixue Zhou,  Mingchen Li,  Yu Hou,  Sicheng Zhou,  Fang Wang,  Rama Hoetzlein,  Rui Zhang",
                "发布日期": "2023-10-31",
                "摘要": "  Reinforcement learning (RL) has emerged as a powerful approach for tackling\ncomplex medical decision-making problems such as treatment planning,\npersonalized medicine, and optimizing the scheduling of surgeries and\nappointments. It has gained significant attention in the field of Natural\nLanguage Processing (NLP) due to its ability to learn optimal strategies for\ntasks such as dialogue systems, machine translation, and question-answering.\nThis paper presents a review of the RL techniques in NLP, highlighting key\nadvancements, challenges, and applications in healthcare. The review begins by\nvisualizing a roadmap of machine learning and its applications in healthcare.\nAnd then it explores the integration of RL with NLP tasks. We examined dialogue\nsystems where RL enables the learning of conversational strategies, RL-based\nmachine translation models, question-answering systems, text summarization, and\ninformation extraction. Additionally, ethical considerations and biases in\nRL-NLP systems are addressed.\n",
                "链接": "https://arxiv.org/abs/2310.18354"
            },
            {
                "文章ID": "40957",
                "标题": "Reinforcement Learning with Large Action Spaces for Neural Machine\n  Translation",
                "作者": " Asaf Yehudai,  Leshem Choshen,  Lior Fox,  Omri Abend",
                "发布日期": "2022-10-07",
                "摘要": "  Applying Reinforcement learning (RL) following maximum likelihood estimation\n(MLE) pre-training is a versatile method for enhancing neural machine\ntranslation (NMT) performance. However, recent work has argued that the gains\nproduced by RL for NMT are mostly due to promoting tokens that have already\nreceived a fairly high probability in pre-training. We hypothesize that the\nlarge action space is a main obstacle to RL's effectiveness in MT, and conduct\ntwo sets of experiments that lend support to our hypothesis. First, we find\nthat reducing the size of the vocabulary improves RL's effectiveness. Second,\nwe find that effectively reducing the dimension of the action space without\nchanging the vocabulary also yields notable improvement as evaluated by BLEU,\nsemantic similarity, and human evaluation. Indeed, by initializing the\nnetwork's final fully connected layer (that maps the network's internal\ndimension to the vocabulary dimension), with a layer that generalizes over\nsimilar actions, we obtain a substantial improvement in RL performance: 1.5\nBLEU points on average.\n",
                "链接": "https://arxiv.org/abs/2210.03053"
            },
            {
                "文章ID": "94624",
                "标题": "ESRL: Efficient Sampling-based Reinforcement Learning for Sequence\n  Generation",
                "作者": " Chenglong Wang,  Hang Zhou,  Yimin Hu,  Yifu Huo,  Bei Li,  Tongran Liu,  Tong Xiao,  Jingbo Zhu",
                "发布日期": "2023-08-07",
                "摘要": "  Applying Reinforcement Learning (RL) to sequence generation models enables\nthe direct optimization of long-term rewards (\\textit{e.g.,} BLEU and human\nfeedback), but typically requires large-scale sampling over a space of action\nsequences. This is a computational challenge as presented by the practice of\nsequence generation problems, such as machine translation, where we often deal\nwith a large action space (\\textit{e.g.,} a vocabulary) and a long action\nsequence (\\textit{e.g.,} a translation). In this work, we introduce two-stage\nsampling and dynamic sampling approaches to improve the sampling efficiency\nduring training sequence generation models via RL. We experiment with our\napproaches on the traditional sequence generation tasks, including machine\ntranslation and abstractive summarization. Furthermore, we evaluate our\napproaches in RL from human feedback (RLHF) through training a large language\nmodel using the reward model. Experimental results show that the efficient\nsampling-based RL, referred to as ESRL, can outperform all baselines in terms\nof both training efficiency and memory consumption. Notably, ESRL yields\nconsistent performance gains over the strong REINFORCE, minimum risk training,\nand proximal policy optimization methods.\n",
                "链接": "https://arxiv.org/abs/2308.02223"
            },
            {
                "文章ID": "80020",
                "标题": "Language Model Self-improvement by Reinforcement Learning Contemplation",
                "作者": " Jing-Cheng Pang,  Pengyuan Wang,  Kaiyuan Li,  Xiong-Hui Chen,  Jiacheng Xu,  Zongzhang Zhang,  Yang Yu",
                "发布日期": "2023-05-25",
                "摘要": "  Large Language Models (LLMs) have exhibited remarkable performance across\nvarious natural language processing (NLP) tasks. However, fine-tuning these\nmodels often necessitates substantial supervision, which can be expensive and\ntime-consuming to obtain. This paper introduces a novel unsupervised method\ncalled LanguageModel Self-Improvement by Reinforcement Learning Contemplation\n(SIRLC) that improves LLMs without reliance on external labels. Our approach is\ngrounded in the observation that it is simpler for language models to assess\ntext quality than to generate text. Building on this insight, SIRLC assigns\nLLMs dual roles as both student and teacher. As a student, the LLM generates\nanswers to unlabeled questions, while as a teacher, it evaluates the generated\ntext and assigns scores accordingly. The model parameters are updated using\nreinforcement learning to maximize the evaluation score. We demonstrate that\nSIRLC can be applied to various NLP tasks, such as reasoning problems, text\ngeneration, and machine translation. Our experiments show that SIRLC\neffectively improves LLM performance without external supervision, resulting in\na 5.6% increase in answering accuracy for reasoning tasks and a rise in\nBERTScore from 0.82 to 0.86 for translation tasks. Furthermore, SIRLC can be\napplied to models of different sizes, showcasing its broad applicability.\n",
                "链接": "https://arxiv.org/abs/2305.14483"
            },
            {
                "文章ID": "115935",
                "标题": "Aligning Neural Machine Translation Models: Human Feedback in Training\n  and Inference",
                "作者": " Miguel Moura Ramos,  Patrick Fernandes,  António Farinhas,  André F. T. Martins",
                "发布日期": "2023-11-16",
                "摘要": "  Reinforcement learning from human feedback (RLHF) is a recent technique to\nimprove the quality of the text generated by a language model, making it closer\nto what humans would generate. A core ingredient in RLHF's success in aligning\nand improving large language models (LLMs) is its reward model, trained using\nhuman feedback on model outputs. In machine translation (MT), where metrics\ntrained from human annotations can readily be used as reward models, recent\nmethods using minimum Bayes risk decoding and reranking have succeeded in\nimproving the final quality of translation. In this study, we comprehensively\nexplore and compare techniques for integrating quality metrics as reward models\ninto the MT pipeline. This includes using the reward model for data filtering,\nduring the training phase through RL, and at inference time by employing\nreranking techniques, and we assess the effects of combining these in a unified\napproach. Our experimental results, conducted across multiple translation\ntasks, underscore the crucial role of effective data filtering, based on\nestimated quality, in harnessing the full potential of RL in enhancing MT\nquality. Furthermore, our findings demonstrate the effectiveness of combining\nRL training with reranking techniques, showcasing substantial improvements in\ntranslation quality.\n",
                "链接": "https://arxiv.org/abs/2311.09132"
            },
            {
                "文章ID": "10776",
                "标题": "Mitigating Gender Bias in Machine Translation through Adversarial\n  Learning",
                "作者": " Eve Fleisig,  Christiane Fellbaum",
                "发布日期": "2022-03-22",
                "摘要": "  Machine translation and other NLP systems often contain significant biases\nregarding sensitive attributes, such as gender or race, that worsen system\nperformance and perpetuate harmful stereotypes. Recent preliminary research\nsuggests that adversarial learning can be used as part of a model-agnostic bias\nmitigation method that requires no data modifications. However, adapting this\nstrategy for machine translation and other modern NLP domains requires (1)\nrestructuring training objectives in the context of fine-tuning pretrained\nlarge language models and (2) developing measures for gender or other protected\nvariables for tasks in which these attributes must be deduced from the data\nitself.\n  We present an adversarial learning framework that addresses these challenges\nto mitigate gender bias in seq2seq machine translation. Our framework improves\nthe disparity in translation quality for sentences with male vs. female\nentities by 86% for English-German translation and 91% for English-French\ntranslation, with minimal effect on translation quality. The results suggest\nthat adversarial learning is a promising technique for mitigating gender bias\nin machine translation.\n",
                "链接": "https://arxiv.org/abs/2203.10675"
            },
            {
                "文章ID": "110267",
                "标题": "Simultaneous Machine Translation with Tailored Reference",
                "作者": " Shoutao Guo,  Shaolei Zhang,  Yang Feng",
                "发布日期": "2023-10-27",
                "摘要": "  Simultaneous machine translation (SiMT) generates translation while reading\nthe whole source sentence. However, existing SiMT models are typically trained\nusing the same reference disregarding the varying amounts of available source\ninformation at different latency. Training the model with ground-truth at low\nlatency may introduce forced anticipations, whereas utilizing reference\nconsistent with the source word order at high latency results in performance\ndegradation. Consequently, it is crucial to train the SiMT model with\nappropriate reference that avoids forced anticipations during training while\nmaintaining high quality. In this paper, we propose a novel method that\nprovides tailored reference for the SiMT models trained at different latency by\nrephrasing the ground-truth. Specifically, we introduce the tailor, induced by\nreinforcement learning, to modify ground-truth to the tailored reference. The\nSiMT model is trained with the tailored reference and jointly optimized with\nthe tailor to enhance performance. Importantly, our method is applicable to a\nwide range of current SiMT approaches. Experiments on three translation tasks\ndemonstrate that our method achieves state-of-the-art performance in both fixed\nand adaptive policies.\n",
                "链接": "https://arxiv.org/abs/2310.13588"
            }
        ]
    },
    {
        "question": {
            "question": "请找出使用Transformer模型并在大规模数据集上进行预训练的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "33690",
                "标题": "CommitBART: A Large Pre-trained Model for GitHub Commits",
                "作者": " Shangqing Liu,  Yanzhou Li,  Xiaofei Xie,  Yang Liu",
                "发布日期": "2023-01-24",
                "摘要": "  GitHub commits, which record the code changes with natural language messages\nfor description, play a critical role for software developers to comprehend the\nsoftware evolution. To promote the development of the open-source software\ncommunity, we collect a commit benchmark including over 7.99 million commits\nacross 7 programming languages. Based on this benchmark, we present CommitBART,\na large pre-trained encoder-decoder Transformer model for GitHub commits. The\nmodel is pre-trained by three categories (i.e., denoising objectives,\ncross-modal generation and contrastive learning) for six pre-training tasks to\nlearn commit fragment representations. Furthermore, we unify a ``commit\nintelligence'' framework with one understanding task and three generation tasks\nfor commits. The comprehensive experiments on these tasks demonstrate that\nCommitBARTsignificantly outperforms previous pre-trained works for code.\nFurther analysis also reveals each pre-training task enhances the model\nperformance.\n",
                "链接": "https://arxiv.org/abs/2208.08100"
            },
            {
                "文章ID": "58942",
                "标题": "CSDR-BERT: a pre-trained scientific dataset match model for Chinese\n  Scientific Dataset Retrieval",
                "作者": " Xintao Chu,  Jianping Liu,  Jian Wang,  Xiaofeng Wang,  Yingfei Wang,  Meng Wang,  Xunxun Gu",
                "发布日期": "2023-03-31",
                "摘要": "  As the number of open and shared scientific datasets on the Internet\nincreases under the open science movement, efficiently retrieving these\ndatasets is a crucial task in information retrieval (IR) research. In recent\nyears, the development of large models, particularly the pre-training and\nfine-tuning paradigm, which involves pre-training on large models and\nfine-tuning on downstream tasks, has provided new solutions for IR match tasks.\nIn this study, we use the original BERT token in the embedding layer, improve\nthe Sentence-BERT model structure in the model layer by introducing the SimCSE\nand K-Nearest Neighbors method, and use the cosent loss function in the\noptimization phase to optimize the target output. Our experimental results show\nthat our model outperforms other competing models on both public and self-built\ndatasets through comparative experiments and ablation implementations. This\nstudy explores and validates the feasibility and efficiency of pre-training\ntechniques for semantic retrieval of Chinese scientific datasets.\n",
                "链接": "https://arxiv.org/abs/2301.12700"
            },
            {
                "文章ID": "71356",
                "标题": "FlexMoE: Scaling Large-scale Sparse Pre-trained Model Training via\n  Dynamic Device Placement",
                "作者": " Xiaonan Nie,  Xupeng Miao,  Zilong Wang,  Zichao Yang,  Jilong Xue,  Lingxiao Ma,  Gang Cao,  Bin Cui",
                "发布日期": "2023-04-11",
                "摘要": "  With the increasing data volume, there is a trend of using large-scale\npre-trained models to store the knowledge into an enormous number of model\nparameters. The training of these models is composed of lots of dense algebras,\nrequiring a huge amount of hardware resources. Recently, sparsely-gated\nMixture-of-Experts (MoEs) are becoming more popular and have demonstrated\nimpressive pretraining scalability in various downstream tasks. However, such a\nsparse conditional computation may not be effective as expected in practical\nsystems due to the routing imbalance and fluctuation problems. Generally, MoEs\nare becoming a new data analytics paradigm in the data life cycle and suffering\nfrom unique challenges at scales, complexities, and granularities never before\npossible.\n  In this paper, we propose a novel DNN training framework, FlexMoE, which\nsystematically and transparently address the inefficiency caused by dynamic\ndataflow. We first present an empirical analysis on the problems and\nopportunities of training MoE models, which motivates us to overcome the\nrouting imbalance and fluctuation problems by a dynamic expert management and\ndevice placement mechanism. Then we introduce a novel scheduling module over\nthe existing DNN runtime to monitor the data flow, make the scheduling plans,\nand dynamically adjust the model-to-hardware mapping guided by the real-time\ndata traffic. A simple but efficient heuristic algorithm is exploited to\ndynamically optimize the device placement during training. We have conducted\nexperiments on both NLP models (e.g., BERT and GPT) and vision models (e.g.,\nSwin). And results show FlexMoE can achieve superior performance compared with\nexisting systems on real-world workloads -- FlexMoE outperforms DeepSpeed by\n1.70x on average and up to 2.10x, and outperforms FasterMoE by 1.30x on average\nand up to 1.45x.\n",
                "链接": "https://arxiv.org/abs/2304.03946"
            },
            {
                "文章ID": "11046",
                "标题": "WuDaoMM: A large-scale Multi-Modal Dataset for Pre-training models",
                "作者": " Sha Yuan,  Shuai Zhao,  Jiahong Leng,  Zhao Xue,  Hanyu Zhao,  Peiyu Liu,  Zheng Gong,  Wayne Xin Zhao,  Junyi Li,  Jie Tang",
                "发布日期": "2022-05-03",
                "摘要": "  Compared with the domain-specific model, the vision-language pre-training\nmodels (VLPMs) have shown superior performance on downstream tasks with fast\nfine-tuning process. For example, ERNIE-ViL, Oscar and UNIMO trained VLPMs with\na uniform transformers stack architecture and large amounts of image-text\npaired data, achieving remarkable results on downstream tasks such as\nimage-text reference(IR and TR), vision question answering (VQA) and image\ncaptioning (IC) etc. During the training phase, VLPMs are always fed with a\ncombination of multiple public datasets to meet the demand of large-scare\ntraining data. However, due to the unevenness of data distribution including\nsize, task type and quality, using the mixture of multiple datasets for model\ntraining can be problematic. In this work, we introduce a large-scale\nmulti-modal corpora named WuDaoMM, totally containing more than 650M image-text\npairs. Specifically, about 600 million pairs of data are collected from\nmultiple webpages in which image and caption present weak correlation, and the\nother 50 million strong-related image-text pairs are collected from some\nhigh-quality graphic websites. We also release a base version of WuDaoMM with 5\nmillion strong-correlated image-text pairs, which is sufficient to support the\ncommon cross-modal model pre-training. Besides, we trained both an\nunderstanding and a generation vision-language (VL) model to test the dataset\neffectiveness. The results show that WuDaoMM can be applied as an efficient\ndataset for VLPMs, especially for the model in text-to-image generation task.\nThe data is released at https://data.wudaoai.cn\n",
                "链接": "https://arxiv.org/abs/2203.11480"
            },
            {
                "文章ID": "103670",
                "标题": "TrTr: A Versatile Pre-Trained Large Traffic Model based on Transformer\n  for Capturing Trajectory Diversity in Vehicle Population",
                "作者": " Ruyi Feng,  Zhibin Li,  Bowen Liu,  Yan Ding",
                "发布日期": "2023-12-04",
                "摘要": "  Understanding trajectory diversity is a fundamental aspect of addressing\npractical traffic tasks. However, capturing the diversity of trajectories\npresents challenges, particularly with traditional machine learning and\nrecurrent neural networks due to the requirement of large-scale parameters. The\nemerging Transformer technology, renowned for its parallel computation\ncapabilities enabling the utilization of models with hundreds of millions of\nparameters, offers a promising solution. In this study, we apply the\nTransformer architecture to traffic tasks, aiming to learn the diversity of\ntrajectories within vehicle populations. We analyze the Transformer's attention\nmechanism and its adaptability to the goals of traffic tasks, and subsequently,\ndesign specific pre-training tasks. To achieve this, we create a data structure\ntailored to the attention mechanism and introduce a set of noises that\ncorrespond to spatio-temporal demands, which are incorporated into the\nstructured data during the pre-training process. The designed pre-training\nmodel demonstrates excellent performance in capturing the spatial distribution\nof the vehicle population, with no instances of vehicle overlap and an RMSE of\n0.6059 when compared to the ground truth values. In the context of time series\nprediction, approximately 95% of the predicted trajectories' speeds closely\nalign with the true speeds, within a deviation of 7.5144m/s. Furthermore, in\nthe stability test, the model exhibits robustness by continuously predicting a\ntime series ten times longer than the input sequence, delivering smooth\ntrajectories and showcasing diverse driving behaviors. The pre-trained model\nalso provides a good basis for downstream fine-tuning tasks. The number of\nparameters of our model is over 50 million.\n",
                "链接": "https://arxiv.org/abs/2309.12677"
            },
            {
                "文章ID": "41603",
                "标题": "Transformer-based Localization from Embodied Dialog with Large-scale\n  Pre-training",
                "作者": " Meera Hahn,  James M. Rehg",
                "发布日期": "2022-10-11",
                "摘要": "  We address the challenging task of Localization via Embodied Dialog (LED).\nGiven a dialog from two agents, an Observer navigating through an unknown\nenvironment and a Locator who is attempting to identify the Observer's\nlocation, the goal is to predict the Observer's final location in a map. We\ndevelop a novel LED-Bert architecture and present an effective pretraining\nstrategy. We show that a graph-based scene representation is more effective\nthan the top-down 2D maps used in prior works. Our approach outperforms\nprevious baselines.\n",
                "链接": "https://arxiv.org/abs/2210.04864"
            },
            {
                "文章ID": "123681",
                "标题": "Sparse is Enough in Fine-tuning Pre-trained Large Language Model",
                "作者": " Weixi Song,  Zuchao Li,  Lefei Zhang,  Hai Zhao,  Bo Du",
                "发布日期": "2023-12-20",
                "摘要": "  With the prevalence of pre-training-fine-tuning paradigm, how to efficiently\nadapt the pre-trained model to the downstream tasks has been an intriguing\nissue. Parameter-Efficient Fine-Tuning (PEFT) methods have been proposed for\nlow-cost adaptation, including Adapters, Bia-only, and the recently widely used\nLow-Rank Adaptation. Although these methods have demonstrated their\neffectiveness to some extent and have been widely applied, the underlying\nprinciples are still unclear. In this paper, we reveal the transition of loss\nlandscape in the downstream domain from random initialization to pre-trained\ninitialization, that is, from low-amplitude oscillation to high-amplitude\noscillation. The parameter gradients exhibit a property akin to sparsity, where\na small fraction of components dominate the total gradient norm, for instance,\n1% of the components account for 99% of the gradient. This property ensures\nthat the pre-trained model can easily find a flat minimizer which guarantees\nthe model's ability to generalize even with a low number of trainable\nparameters. Based on this, we propose a gradient-based sparse fine-tuning\nalgorithm, named Sparse Increment Fine-Tuning (SIFT), and validate its\neffectiveness on a range of tasks including the GLUE Benchmark and\nInstruction-tuning. The code is accessible at https://github.com/song-wx/SIFT/.\n",
                "链接": "https://arxiv.org/abs/2312.11875"
            },
            {
                "文章ID": "73428",
                "标题": "Video Pre-trained Transformer: A Multimodal Mixture of Pre-trained\n  Experts",
                "作者": " Kastan Day,  Daniel Christl,  Rohan Salvi,  Pranav Sriram",
                "发布日期": "2023-04-21",
                "摘要": "  We present Video Pre-trained Transformer. VPT uses four SOTA encoder models\nfrom prior work to convert a video into a sequence of compact embeddings. Our\nbackbone, based on a reference Flan-T5-11B architecture, learns a universal\nrepresentation of the video that is a non-linear sum of the encoder models. It\nlearns using an autoregressive causal language modeling loss by predicting the\nwords spoken in YouTube videos. Finally, we evaluate on standard downstream\nbenchmarks by training fully connected prediction heads for each task. To the\nbest of our knowledge, this is the first use of multiple frozen SOTA models as\nencoders in an \"embedding -> backbone -> prediction head\" design pattern - all\nothers have trained their own joint encoder models. Additionally, we include\nmore modalities than the current SOTA, Merlot Reserve, by adding explicit Scene\nGraph information. For these two reasons, we believe it could combine the\nworld's best open-source models to achieve SOTA performance. Initial\nexperiments demonstrate the model is learning appropriately, but more\nexperimentation and compute is necessary, and already in progress, to realize\nour loftier goals. Alongside this work, we build on the YT-20M dataset,\nreproducing it and adding 25,000 personally selected YouTube videos to its\ncorpus. All code and model checkpoints are open sourced under a standard MIT\nlicense.\n",
                "链接": "https://arxiv.org/abs/2304.10505"
            },
            {
                "文章ID": "82786",
                "标题": "AD-PT: Autonomous Driving Pre-Training with Large-scale Point Cloud\n  Dataset",
                "作者": " Jiakang Yuan,  Bo Zhang,  Xiangchao Yan,  Tao Chen,  Botian Shi,  Yikang Li,  Yu Qiao",
                "发布日期": "2023-10-27",
                "摘要": "  It is a long-term vision for Autonomous Driving (AD) community that the\nperception models can learn from a large-scale point cloud dataset, to obtain\nunified representations that can achieve promising results on different tasks\nor benchmarks. Previous works mainly focus on the self-supervised pre-training\npipeline, meaning that they perform the pre-training and fine-tuning on the\nsame benchmark, which is difficult to attain the performance scalability and\ncross-dataset application for the pre-training checkpoint. In this paper, for\nthe first time, we are committed to building a large-scale pre-training\npoint-cloud dataset with diverse data distribution, and meanwhile learning\ngeneralizable representations from such a diverse pre-training dataset. We\nformulate the point-cloud pre-training task as a semi-supervised problem, which\nleverages the few-shot labeled and massive unlabeled point-cloud data to\ngenerate the unified backbone representations that can be directly applied to\nmany baseline models and benchmarks, decoupling the AD-related pre-training\nprocess and downstream fine-tuning task. During the period of backbone\npre-training, by enhancing the scene- and instance-level distribution diversity\nand exploiting the backbone's ability to learn from unknown instances, we\nachieve significant performance gains on a series of downstream perception\nbenchmarks including Waymo, nuScenes, and KITTI, under different baseline\nmodels like PV-RCNN++, SECOND, CenterPoint.\n",
                "链接": "https://arxiv.org/abs/2306.00612"
            },
            {
                "文章ID": "39840",
                "标题": "PART: Pre-trained Authorship Representation Transformer",
                "作者": " Javier Huertas-Tato,  Alvaro Huertas-Garcia,  Alejandro Martin,  David Camacho",
                "发布日期": "2022-10-03",
                "摘要": "  Authors writing documents imprint identifying information within their texts:\nvocabulary, registry, punctuation, misspellings, or even emoji usage. Finding\nthese details is very relevant to profile authors, relating back to their\ngender, occupation, age, and so on. But most importantly, repeating writing\npatterns can help attributing authorship to a text. Previous works use\nhand-crafted features or classification tasks to train their authorship models,\nleading to poor performance on out-of-domain authors. A better approach to this\ntask is to learn stylometric representations, but this by itself is an open\nresearch challenge. In this paper, we propose PART: a contrastively trained\nmodel fit to learn \\textbf{authorship embeddings} instead of semantics. By\ncomparing pairs of documents written by the same author, we are able to\ndetermine the proprietary of a text by evaluating the cosine similarity of the\nevaluated documents, a zero-shot generalization to authorship identification.\nTo this end, a pre-trained Transformer with an LSTM head is trained with the\ncontrastive training method. We train our model on a diverse set of authors,\nfrom literature, anonymous blog posters and corporate emails; a heterogeneous\nset with distinct and identifiable writing styles. The model is evaluated on\nthese datasets, achieving zero-shot 72.39\\% and 86.73\\% accuracy and top-5\naccuracy respectively on the joint evaluation dataset when determining\nauthorship from a set of 250 different authors. We qualitatively assess the\nrepresentations with different data visualizations on the available datasets,\nprofiling features such as book types, gender, age, or occupation of the\nauthor.\n",
                "链接": "https://arxiv.org/abs/2209.15373"
            }
        ]
    },
    {
        "question": {
            "question": "找一下使用强化学习做代码生成的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "59289",
                "标题": "Execution-based Code Generation using Deep Reinforcement Learning",
                "作者": " Parshin Shojaee,  Aneesh Jain,  Sindhu Tipirneni,  Chandan K. Reddy",
                "发布日期": "2023-07-21",
                "摘要": "  The utilization of programming language (PL) models, pre-trained on\nlarge-scale code corpora, as a means of automating software engineering\nprocesses has demonstrated considerable potential in streamlining various code\ngeneration tasks such as code completion, code translation, and program\nsynthesis. However, current approaches mainly rely on supervised fine-tuning\nobjectives borrowed from text generation, neglecting unique sequence-level\ncharacteristics of code, including but not limited to compilability as well as\nsyntactic and functional correctness. To address this limitation, we propose\nPPOCoder, a new framework for code generation that synergistically combines\npre-trained PL models with Proximal Policy Optimization (PPO) which is a widely\nused deep reinforcement learning technique. By utilizing non-differentiable\nfeedback from code execution and structure alignment, PPOCoder seamlessly\nintegrates external code-specific knowledge into the model optimization\nprocess. It's important to note that PPOCoder is a task-agnostic and\nmodel-agnostic framework that can be used across different code generation\ntasks and PLs. Extensive experiments on three code generation tasks demonstrate\nthe effectiveness of our proposed approach compared to SOTA methods, achieving\nsignificant improvements in compilation success rates and functional\ncorrectness across different PLs.\n",
                "链接": "https://arxiv.org/abs/2301.13816"
            },
            {
                "文章ID": "27761",
                "标题": "CodeRL: Mastering Code Generation through Pretrained Models and Deep\n  Reinforcement Learning",
                "作者": " Hung Le,  Yue Wang,  Akhilesh Deepak Gotmare,  Silvio Savarese,  Steven C. H. Hoi",
                "发布日期": "2022-11-04",
                "摘要": "  Program synthesis or code generation aims to generate a program that\nsatisfies a problem specification. Recent approaches using large-scale\npretrained language models (LMs) have shown promising results, yet they have\nsome critical limitations. In particular, they often follow a standard\nsupervised fine-tuning procedure to train a code generation model only from the\npairs of natural-language problem descriptions and ground-truth programs. Such\nparadigm largely ignores some important but potentially useful signals in the\nproblem specification such as unit tests, which thus often results in poor\nperformance when solving complex unseen coding tasks. To address the\nlimitations, we propose \"CodeRL\", a new framework for program synthesis tasks\nthrough pretrained LMs and deep reinforcement learning (RL). Specifically,\nduring training, we treat the code-generating LM as an actor network, and\nintroduce a critic network that is trained to predict the functional\ncorrectness of generated programs and provide dense feedback signals to the\nactor. During inference, we introduce a new generation procedure with a\ncritical sampling strategy that allows a model to automatically regenerate\nprograms based on feedback from example unit tests and critic scores. For the\nmodel backbones, we extended the encoder-decoder architecture of CodeT5 with\nenhanced learning objectives, larger model sizes, and better pretraining data.\nOur method not only achieves new SOTA results on the challenging APPS\nbenchmark, but also shows strong zero-shot transfer capability with new SOTA\nresults on the simpler MBPP benchmark.\n",
                "链接": "https://arxiv.org/abs/2207.01780"
            },
            {
                "文章ID": "110290",
                "标题": "Automatic Unit Test Data Generation and Actor-Critic Reinforcement\n  Learning for Code Synthesis",
                "作者": " Philip John Gorinski,  Matthieu Zimmer,  Gerasimos Lampouras,  Derrick Goh Xin Deik,  Ignacio Iacobacci",
                "发布日期": "2023-10-23",
                "摘要": "  The advent of large pre-trained language models in the domain of Code\nSynthesis has shown remarkable performance on various benchmarks, treating the\nproblem of Code Generation in a fashion similar to Natural Language Generation,\ntrained with a Language Modelling (LM) objective. In addition, the property of\nprogramming language code being precisely evaluable with respect to its\nsemantics -- through the use of Unit Tests to check its functional correctness\n-- lends itself to using Reinforcement Learning (RL) as a further training\nparadigm. Previous work has shown that RL can be applied as such to improve\nmodels' coding capabilities; however, such RL-based methods rely on a reward\nsignal based on defined Unit Tests, which are much harder to obtain compared to\nthe huge crawled code datasets used in LM objectives. In this work, we present\na novel approach to automatically obtain data consisting of function signatures\nand associated Unit Tests, suitable for RL training of Code Synthesis models.\nWe also introduce a straightforward, simple yet effective Actor-Critic RL\ntraining scheme and show that it, in conjunction with automatically generated\ntraining data, leads to improvement of a pre-trained code language model's\nperformance by up to 9.9% improvement over the original underlying code\nsynthesis LM, and up to 4.3% over RL-based models trained with standard PPO or\nCodeRL.\n",
                "链接": "https://arxiv.org/abs/2310.13669"
            },
            {
                "文章ID": "72734",
                "标题": "Stochastic Code Generation",
                "作者": " Swapnil Sharma,  Nikita Anand, V Kranthi Kiran G.",
                "发布日期": "2023-04-18",
                "摘要": "  Large language models pre-trained for code generation can generate\nhigh-quality short code but often struggle with generating coherent long code\nand understanding higher-level or system-level specifications. This issue is\nalso observed in language modeling for long text generation, and one proposed\nsolution is the use of a latent stochastic process. This approach involves\ngenerating a document plan and then producing text that is consistent with it.\n  In this study, we investigate whether this technique can be applied to code\ngeneration to improve coherence. We base our proposed encoder and decoder on\nthe pre-trained GPT-2 based CodeParrot model and utilize the APPS dataset for\ntraining. We evaluate our results using the HumanEval benchmark and observe\nthat the modified Time Control model performs similarly to CodeParrot on this\nevaluation.\n",
                "链接": "https://arxiv.org/abs/2304.08243"
            },
            {
                "文章ID": "89545",
                "标题": "Exploring Continual Learning for Code Generation Models",
                "作者": " Prateek Yadav,  Qing Sun,  Hantian Ding,  Xiaopeng Li,  Dejiao Zhang,  Ming Tan,  Xiaofei Ma,  Parminder Bhatia,  Ramesh Nallapati,  Murali Krishna Ramanathan,  Mohit Bansal,  Bing Xiang",
                "发布日期": "2023-07-06",
                "摘要": "  Large-scale code generation models such as Codex and CodeT5 have achieved\nimpressive performance. However, libraries are upgraded or deprecated very\nfrequently and re-training large-scale language models is computationally\nexpensive. Therefore, Continual Learning (CL) is an important aspect that\nremains underexplored in the code domain. In this paper, we introduce a\nbenchmark called CodeTask-CL that covers a wide range of tasks, including code\ngeneration, translation, summarization, and refinement, with different input\nand output programming languages. Next, on our CodeTask-CL benchmark, we\ncompare popular CL techniques from NLP and Vision domains. We find that\neffective methods like Prompt Pooling (PP) suffer from catastrophic forgetting\ndue to the unstable training of the prompt selection mechanism caused by stark\ndistribution shifts in coding tasks. We address this issue with our proposed\nmethod, Prompt Pooling with Teacher Forcing (PP-TF), that stabilizes training\nby enforcing constraints on the prompt selection mechanism and leads to a\n21.54% improvement over Prompt Pooling. Along with the benchmark, we establish\na training pipeline that can be used for CL on code models, which we believe\ncan motivate further development of CL methods for code models. Our code is\navailable at https://github.com/amazon-science/codetaskcl-pptf\n",
                "链接": "https://arxiv.org/abs/2307.02435"
            },
            {
                "文章ID": "119060",
                "标题": "Self-Infilling Code Generation",
                "作者": " Lin Zheng,  Jianbo Yuan,  Zhi Zhang,  Hongxia Yang,  Lingpeng Kong",
                "发布日期": "2023-12-01",
                "摘要": "  This work introduces a general code generation framework that incorporates\ninfilling operations into auto-regressive decoding. Our approach capitalizes on\nthe observation that recent code language models with infilling capabilities\ncan perform \\emph{self-infilling}: whereas infilling operations aim to fill in\nthe middle based on a predefined prefix and suffix, self-infilling sequentially\ngenerates both such surrounding context and the infilled content. We utilize\nthis feature to develop an infilling-augmented decoding process that\nfacilitates non-monotonic generation. This approach allows for postponing the\ngeneration of uncertain code snippets until a definitive suffix is established,\nleading to improved control over the generation sequence. In addition, it\nfacilitates a looping mechanism, which can iteratively update and synchronize\neach piece of generation in a cyclic manner. Extensive experiments are\nconducted to demonstrate that our proposed decoding process is effective in\nenhancing regularity and quality across several code generation benchmarks.\n",
                "链接": "https://arxiv.org/abs/2311.17972"
            },
            {
                "文章ID": "122586",
                "标题": "Entity-Augmented Code Generation",
                "作者": " Anton Shapkin,  Denis Litvinov,  Timofey Bryksin",
                "发布日期": "2023-12-15",
                "摘要": "  The current state-of-the-art large language models (LLMs) are effective in\ngenerating high-quality text and encapsulating a broad spectrum of world\nknowledge. However, these models often hallucinate during generation and are\nnot designed to utilize external information sources. To enable requests to the\nexternal knowledge bases, also called knowledge grounding, retrieval-augmented\nLLMs were introduced. For now, their applications have largely involved Open\nDomain Question Answering, Abstractive Question Answering, and such. In this\npaper, we broaden the scope of retrieval-augmented LLMs by venturing into a new\ntask - code generation using external entities. For this task, we collect and\npublish a new dataset for project-level code generation, where the model should\nreuse functions defined in the project during generation. As we show, existing\nretrieval-augmented LLMs fail to assign relevance scores between similar entity\nnames, and to mitigate it, they expand entity names with description context\nand append it to the input. In practice, due to the limited context size they\ncan not accommodate the indefinitely large context of the whole project. To\nsolve this issue, we propose a novel end-to-end trainable architecture with an\nscalable entity retriever injected directly into the LLM decoder. We\ndemonstrate that our model can outperform common baselines in several\nscenarios, including project-level code generation, as well as Bash and SQL\nscripting.\n",
                "链接": "https://arxiv.org/abs/2312.08976"
            },
            {
                "文章ID": "69960",
                "标题": "AceCoder: Utilizing Existing Code to Enhance Code Generation",
                "作者": " Jia Li,  Yunfei Zhao,  Yongmin Li,  Ge Li,  Zhi Jin",
                "发布日期": "2023-09-08",
                "摘要": "  Large Language Models (LLMs) have shown great success in code generation.\nLLMs take as the input a prompt and output the code. A key question is how to\nmake prompts (i.e., Prompting Techniques). Existing prompting techniques are\ndesigned for natural language generation and have low accuracy in code\ngeneration.\n  In this paper, we propose a new prompting technique named AceCoder. Our\nmotivation is that code generation meets two unique challenges (i.e.,\nrequirement understanding and code implementation). AceCoder contains two novel\nmechanisms (i.e., guided code generation and example retrieval) to solve these\nchallenges. (1) Guided code generation asks LLMs first to analyze requirements\nand output an intermediate preliminary (e.g., test cases). The preliminary is\nused to clarify requirements and tell LLMs \"what to write\". (2) Example\nretrieval selects similar programs as examples in prompts, which provide lots\nof relevant content (e.g., algorithms, APIs) and teach LLMs \"how to write\". We\napply AceCoder to three LLMs (e.g., Codex) and evaluate it on three public\nbenchmarks using the Pass@k. Results show that AceCoder can significantly\nimprove the performance of LLMs on code generation. (1) In terms of Pass@1,\nAceCoder outperforms the state-of-the-art baseline by up to 56.4% in MBPP,\n70.7% in MBJP, and 88.4% in MBJSP. (2) AceCoder is effective in LLMs with\ndifferent sizes (i.e., 6B to 13B) and different languages (i.e., Python, Java,\nand JavaScript). (3) Human evaluation shows human developers prefer programs\nfrom AceCoder.\n",
                "链接": "https://arxiv.org/abs/2303.17780"
            },
            {
                "文章ID": "80370",
                "标题": "Who Wrote this Code? Watermarking for Code Generation",
                "作者": " Taehyun Lee,  Seokhee Hong,  Jaewoo Ahn,  Ilgee Hong,  Hwaran Lee,  Sangdoo Yun,  Jamin Shin,  Gunhee Kim",
                "发布日期": "2023-11-20",
                "摘要": "  With the remarkable generation performance of large language models, ethical\nand legal concerns about using them have been raised, such as plagiarism and\ncopyright issues. For such concerns, several approaches to watermark and detect\nLLM-generated text have been proposed very recently. However, we discover that\nthe previous methods fail to function appropriately with code generation tasks\nbecause of the syntactic and semantic characteristics of code. Based on\n\\citet{Kirchenbauer2023watermark}, we propose a new watermarking method,\nSelective WatErmarking via Entropy Thresholding (SWEET), that promotes \"green\"\ntokens only at the position with high entropy of the token distribution during\ngeneration, thereby preserving the correctness of the generated code. The\nwatermarked code is detected by the statistical test and Z-score based on the\nentropy information. Our experiments on HumanEval and MBPP show that SWEET\nsignificantly improves the Pareto Frontier between the code correctness and\nwatermark detection performance. We also show that notable post-hoc detection\nmethods (e.g. DetectGPT) fail to work well in this task. Finally, we show that\nsetting a reasonable entropy threshold is not much of a challenge. Code is\navailable at https://github.com/hongcheki/sweet-watermark.\n",
                "链接": "https://arxiv.org/abs/2305.15060"
            },
            {
                "文章ID": "61100",
                "标题": "CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code",
                "作者": " Shuyan Zhou,  Uri Alon,  Sumit Agarwal,  Graham Neubig",
                "发布日期": "2023-11-01",
                "摘要": "  Since the rise of neural natural-language-to-code models (NL->Code) that can\ngenerate long expressions and statements rather than a single next-token, one\nof the major problems has been reliably evaluating their generated output. In\nthis paper, we propose CodeBERTScore: an evaluation metric for code generation,\nwhich builds on BERTScore (Zhang et al., 2020). Instead of encoding only the\ngenerated tokens as in BERTScore, CodeBERTScore also encodes the natural\nlanguage input preceding the generated code, thus modeling the consistency\nbetween the generated code and its given natural language context as well. We\nperform an extensive evaluation of CodeBERTScore across four programming\nlanguages. We find that CodeBERTScore achieves a higher correlation with human\npreference and with functional correctness than all existing metrics. That is,\ngenerated code that receives a higher score by CodeBERTScore is more likely to\nbe preferred by humans, as well as to function correctly when executed. We\nrelease five language-specific pretrained models to use with our publicly\navailable code. Our language-specific models have been downloaded more than\n1,000,000 times from the Huggingface Hub. Our code and data are available at\nhttps://github.com/neulab/code-bert-score\n",
                "链接": "https://arxiv.org/abs/2302.05527"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下关于大模型使用工具的安全性的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "94111",
                "标题": "Structural Embeddings of Tools for Large Language Models",
                "作者": " Eren Unlu",
                "发布日期": "2023-08-02",
                "摘要": "  It is evident that the current state of Large Language Models (LLMs)\nnecessitates the incorporation of external tools. The lack of straightforward\nalgebraic and logical reasoning is well documented and prompted researchers to\ndevelop frameworks which allow LLMs to operate via external tools. The\nontological nature of tool utilization for a specific task can be well\nformulated with a Directed Acyclic Graph (DAG). The central aim of the paper is\nto highlight the importance of graph based approaches to LLM-tool interaction\nin near future. We propose an exemplary framework to guide the orchestration of\nexponentially increasing numbers of external tools with LLMs,where objectives\nand functionalities of tools are graph encoded hierarchically. Assuming that\ntextual segments of a Chain-of-Thought (CoT) can be imagined as a tool as\ndefined here, the graph based framework can pave new avenues in that particular\ndirection as well.\n",
                "链接": "https://arxiv.org/abs/2308.00447"
            },
            {
                "文章ID": "117473",
                "标题": "Applying Large Language Models to Power Systems: Potential Security\n  Threats",
                "作者": " Jiaqi Ruan,  Gaoqi Liang,  Huan Zhao,  Guolong Liu,  Jing Qiu,  Junhua Zhao,  Zhao Xu,  Fushuan Wen,  Zhao Yang Dong",
                "发布日期": "2023-11-23",
                "摘要": "  Applying large language models (LLMs) to power systems presents a promising\navenue for enhancing decision-making and operational efficiency. However, this\naction may also incur potential security threats, which have not been fully\nrecognized so far. To this end, this letter analyzes potential threats incurred\nby applying LLMs to power systems, emphasizing the need for urgent research and\ndevelopment of countermeasures.\n",
                "链接": "https://arxiv.org/abs/2311.13361"
            },
            {
                "文章ID": "49428",
                "标题": "Semantic Similarity-Based Clustering of Findings From Security Testing\n  Tools",
                "作者": " Phillip Schneider,  Markus Voggenreiter,  Abdullah Gulraiz,  Florian Matthes",
                "发布日期": "2022-11-22",
                "摘要": "  Over the last years, software development in domains with high security\ndemands transitioned from traditional methodologies to uniting modern\napproaches from software development and operations (DevOps). Key principles of\nDevOps gained more importance and are now applied to security aspects of\nsoftware development, resulting in the automation of security-enhancing\nactivities. In particular, it is common practice to use automated security\ntesting tools that generate reports after inspecting a software artifact from\nmultiple perspectives. However, this raises the challenge of generating\nduplicate security findings. To identify these duplicate findings manually, a\nsecurity expert has to invest resources like time, effort, and knowledge. A\npartial automation of this process could reduce the analysis effort, encourage\nDevOps principles, and diminish the chance of human error. In this study, we\ninvestigated the potential of applying Natural Language Processing for\nclustering semantically similar security findings to support the identification\nof problem-specific duplicate findings. Towards this goal, we developed a web\napplication for annotating and assessing security testing tool reports and\npublished a human-annotated corpus of clustered security findings. In addition,\nwe performed a comparison of different semantic similarity techniques for\nautomatically grouping security findings. Finally, we assess the resulting\nclusters using both quantitative and qualitative evaluation methods.\n",
                "链接": "https://arxiv.org/abs/2211.11057"
            },
            {
                "文章ID": "95590",
                "标题": "An Empirical Study on Using Large Language Models to Analyze Software\n  Supply Chain Security Failures",
                "作者": " Tanmay Singla,  Dharun Anandayuvaraj,  Kelechi G. Kalu,  Taylor R. Schorlemmer,  James C. Davis",
                "发布日期": "2023-08-10",
                "摘要": "  As we increasingly depend on software systems, the consequences of breaches\nin the software supply chain become more severe. High-profile cyber attacks\nlike those on SolarWinds and ShadowHammer have resulted in significant\nfinancial and data losses, underlining the need for stronger cybersecurity. One\nway to prevent future breaches is by studying past failures. However,\ntraditional methods of analyzing these failures require manually reading and\nsummarizing reports about them. Automated support could reduce costs and allow\nanalysis of more failures. Natural Language Processing (NLP) techniques such as\nLarge Language Models (LLMs) could be leveraged to assist the analysis of\nfailures. In this study, we assessed the ability of Large Language Models\n(LLMs) to analyze historical software supply chain breaches. We used LLMs to\nreplicate the manual analysis of 69 software supply chain security failures\nperformed by members of the Cloud Native Computing Foundation (CNCF). We\ndeveloped prompts for LLMs to categorize these by four dimensions: type of\ncompromise, intent, nature, and impact. GPT 3.5s categorizations had an average\naccuracy of 68% and Bard had an accuracy of 58% over these dimensions. We\nreport that LLMs effectively characterize software supply chain failures when\nthe source articles are detailed enough for consensus among manual analysts,\nbut cannot yet replace human analysts. Future work can improve LLM performance\nin this context, and study a broader range of articles and failures.\n",
                "链接": "https://arxiv.org/abs/2308.04898"
            },
            {
                "文章ID": "79369",
                "标题": "Decomposed Prompting for Machine Translation Between Related Languages\n  using Large Language Models",
                "作者": " Ratish Puduppully,  Anoop Kunchukuttan,  Raj Dabre,  Ai Ti Aw,  Nancy F. Chen",
                "发布日期": "2023-10-24",
                "摘要": "  This study investigates machine translation between related languages i.e.,\nlanguages within the same family that share linguistic characteristics such as\nword order and lexical similarity. Machine translation through few-shot\nprompting leverages a small set of translation pair examples to generate\ntranslations for test sentences. This procedure requires the model to learn how\nto generate translations while simultaneously ensuring that token ordering is\nmaintained to produce a fluent and accurate translation. We propose that for\nrelated languages, the task of machine translation can be simplified by\nleveraging the monotonic alignment characteristic of such languages. We\nintroduce DecoMT, a novel approach of few-shot prompting that decomposes the\ntranslation process into a sequence of word chunk translations. Through\nautomatic and human evaluation conducted on multiple related language pairs\nacross various language families, we demonstrate that our proposed approach of\ndecomposed prompting surpasses multiple established few-shot baseline\napproaches. For example, DecoMT outperforms the strong few-shot prompting BLOOM\nmodel with an average improvement of 8 chrF++ scores across the examined\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2305.13085"
            },
            {
                "文章ID": "107503",
                "标题": "An evolutionary model of personality traits related to cooperative\n  behavior using a large language model",
                "作者": " Reiji Suzuki,  Takaya Arita",
                "发布日期": "2023-10-11",
                "摘要": "  This paper aims to shed light on the evolutionary dynamics of diverse and\nsocial populations by introducing the rich expressiveness of generative models\ninto the trait expression of social agent-based evolutionary models.\nSpecifically, we focus on the evolution of personality traits in the context of\na game-theoretic relationship as a situation in which inter-individual\ninterests exert strong selection pressures. We construct an agent model in\nwhich linguistic descriptions of personality traits related to cooperative\nbehavior are used as genes. The deterministic strategies extracted from Large\nLanguage Model (LLM) that make behavioral decisions based on these personality\ntraits are used as behavioral traits. The population is evolved according to\nselection based on average payoff and mutation of genes by asking LLM to\nslightly modify the parent gene toward cooperative or selfish. Through\npreliminary experiments and analyses, we clarify that such a model can indeed\nexhibit the evolution of cooperative behavior based on the diverse and\nhigher-order representation of personality traits. We also observed the\nrepeated intrusion of cooperative and selfish personality traits through\nchanges in the expression of personality traits, and found that the emerging\nwords in the evolved gene well reflected the behavioral tendency of its\npersonality in terms of their semantics.\n",
                "链接": "https://arxiv.org/abs/2310.05976"
            },
            {
                "文章ID": "122196",
                "标题": "Causality Analysis for Evaluating the Security of Large Language Models",
                "作者": " Wei Zhao,  Zhe Li,  Jun Sun",
                "发布日期": "2023-12-14",
                "摘要": "  Large Language Models (LLMs) such as GPT and Llama2 are increasingly adopted\nin many safety-critical applications. Their security is thus essential. Even\nwith considerable efforts spent on reinforcement learning from human feedback\n(RLHF), recent studies have shown that LLMs are still subject to attacks such\nas adversarial perturbation and Trojan attacks. Further research is thus needed\nto evaluate their security and/or understand the lack of it. In this work, we\npropose a framework for conducting light-weight causality-analysis of LLMs at\nthe token, layer, and neuron level. We applied our framework to open-source\nLLMs such as Llama2 and Vicuna and had multiple interesting discoveries. Based\non a layer-level causality analysis, we show that RLHF has the effect of\noverfitting a model to harmful prompts. It implies that such security can be\neasily overcome by `unusual' harmful prompts. As evidence, we propose an\nadversarial perturbation method that achieves 100\\% attack success rate on the\nred-teaming tasks of the Trojan Detection Competition 2023. Furthermore, we\nshow the existence of one mysterious neuron in both Llama2 and Vicuna that has\nan unreasonably high causal effect on the output. While we are uncertain on why\nsuch a neuron exists, we show that it is possible to conduct a ``Trojan''\nattack targeting that particular neuron to completely cripple the LLM, i.e., we\ncan generate transferable suffixes to prompts that frequently make the LLM\nproduce meaningless responses.\n",
                "链接": "https://arxiv.org/abs/2312.07876"
            },
            {
                "文章ID": "115037",
                "标题": "Distilling Large Language Models using Skill-Occupation Graph Context\n  for HR-Related Tasks",
                "作者": " Pouya Pezeshkpour,  Hayate Iso,  Thom Lake,  Nikita Bhutani,  Estevam Hruschka",
                "发布日期": "2023-11-14",
                "摘要": "  Numerous HR applications are centered around resumes and job descriptions.\nWhile they can benefit from advancements in NLP, particularly large language\nmodels, their real-world adoption faces challenges due to absence of\ncomprehensive benchmarks for various HR tasks, and lack of smaller models with\ncompetitive capabilities. In this paper, we aim to bridge this gap by\nintroducing the Resume-Job Description Benchmark (RJDB). We meticulously craft\nthis benchmark to cater to a wide array of HR tasks, including matching and\nexplaining resumes to job descriptions, extracting skills and experiences from\nresumes, and editing resumes. To create this benchmark, we propose to distill\ndomain-specific knowledge from a large language model (LLM). We rely on a\ncurated skill-occupation graph to ensure diversity and provide context for LLMs\ngeneration. Our benchmark includes over 50 thousand triples of job\ndescriptions, matched resumes and unmatched resumes. Using RJDB, we train\nmultiple smaller student models. Our experiments reveal that the student models\nachieve near/better performance than the teacher model (GPT-4), affirming the\neffectiveness of the benchmark. Additionally, we explore the utility of RJDB on\nout-of-distribution data for skill extraction and resume-job description\nmatching, in zero-shot and weak supervision manner. We release our datasets and\ncode to foster further research and industry applications.\n",
                "链接": "https://arxiv.org/abs/2311.06383"
            },
            {
                "文章ID": "106425",
                "标题": "MetaTool Benchmark for Large Language Models: Deciding Whether to Use\n  Tools and Which to Use",
                "作者": " Yue Huang,  Jiawen Shi,  Yuan Li,  Chenrui Fan,  Siyuan Wu,  Qihui Zhang,  Yixin Liu,  Pan Zhou,  Yao Wan,  Neil Zhenqiang Gong,  Lichao Sun",
                "发布日期": "2023-10-25",
                "摘要": "  Large language models (LLMs) have garnered significant attention due to their\nimpressive natural language processing (NLP) capabilities. Recently, many\nstudies have focused on the tool utilization ability of LLMs. They primarily\ninvestigated how LLMs effectively collaborate with given specific tools.\nHowever, in scenarios where LLMs serve as intelligent agents, as seen in\napplications like AutoGPT and MetaGPT, LLMs are expected to engage in intricate\ndecision-making processes that involve deciding whether to employ a tool and\nselecting the most suitable tool(s) from a collection of available tools to\nfulfill user requests. Therefore, in this paper, we introduce MetaTool, a\nbenchmark designed to evaluate whether LLMs have tool usage awareness and can\ncorrectly choose tools. Specifically, we create a dataset called ToolE within\nthe benchmark. This dataset contains various types of user queries in the form\nof prompts that trigger LLMs to use tools, including both single-tool and\nmulti-tool scenarios. Subsequently, we set the tasks for both tool usage\nawareness and tool selection. We define four subtasks from different\nperspectives in tool selection, including tool selection with similar choices,\ntool selection in specific scenarios, tool selection with possible reliability\nissues, and multi-tool selection. We conduct experiments involving nine popular\nLLMs and find that the majority of them still struggle to effectively select\ntools, highlighting the existing gaps between LLMs and genuine intelligent\nagents. However, through the error analysis, we found there is still\nsignificant room for improvement. Finally, we conclude with insights for tool\ndevelopers that follow ChatGPT to provide detailed descriptions that can\nenhance the tool selection performance of LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.03128"
            },
            {
                "文章ID": "50884",
                "标题": "On the Security Vulnerabilities of Text-to-SQL Models",
                "作者": " Xutan Peng,  Yipeng Zhang,  Jingfeng Yang,  Mark Stevenson",
                "发布日期": "2023-10-13",
                "摘要": "  Although it has been demonstrated that Natural Language Processing (NLP)\nalgorithms are vulnerable to deliberate attacks, the question of whether such\nweaknesses can lead to software security threats is under-explored. To bridge\nthis gap, we conducted vulnerability tests on Text-to-SQL systems that are\ncommonly used to create natural language interfaces to databases. We showed\nthat the Text-to-SQL modules within six commercial applications can be\nmanipulated to produce malicious code, potentially leading to data breaches and\nDenial of Service attacks. This is the first demonstration that NLP models can\nbe exploited as attack vectors in the wild. In addition, experiments using four\nopen-source language models verified that straightforward backdoor attacks on\nText-to-SQL systems achieve a 100% success rate without affecting their\nperformance. The aim of this work is to draw the community's attention to\npotential software security issues associated with NLP algorithms and encourage\nexploration of methods to mitigate against them.\n",
                "链接": "https://arxiv.org/abs/2211.15363"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下对使用GPT生成数据集的训练步骤进行改进的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "81391",
                "标题": "DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of\n  GPT-Generated Text",
                "作者": " Xianjun Yang,  Wei Cheng,  Yue Wu,  Linda Petzold,  William Yang Wang,  Haifeng Chen",
                "发布日期": "2023-10-05",
                "摘要": "  Large language models (LLMs) have notably enhanced the fluency and diversity\nof machine-generated text. However, this progress also presents a significant\nchallenge in detecting the origin of a given text, and current research on\ndetection methods lags behind the rapid evolution of LLMs. Conventional\ntraining-based methods have limitations in flexibility, particularly when\nadapting to new domains, and they often lack explanatory power. To address this\ngap, we propose a novel training-free detection strategy called Divergent\nN-Gram Analysis (DNA-GPT). Given a text, we first truncate it in the middle and\nthen use only the preceding portion as input to the LLMs to regenerate the new\nremaining parts. By analyzing the differences between the original and new\nremaining parts through N-gram analysis in black-box or probability divergence\nin white-box, we unveil significant discrepancies between the distribution of\nmachine-generated text and the distribution of human-written text. We conducted\nextensive experiments on the most advanced LLMs from OpenAI, including\ntext-davinci-003, GPT-3.5-turbo, and GPT-4, as well as open-source models such\nas GPT-NeoX-20B and LLaMa-13B. Results show that our zero-shot approach\nexhibits state-of-the-art performance in distinguishing between human and\nGPT-generated text on four English and one German dataset, outperforming\nOpenAI's own classifier, which is trained on millions of text. Additionally,\nour methods provide reasonable explanations and evidence to support our claim,\nwhich is a unique feature of explainable detection. Our method is also robust\nunder the revised text attack and can additionally solve model sourcing. Codes\nare available at https://github.com/Xianjun-Yang/DNA-GPT.\n",
                "链接": "https://arxiv.org/abs/2305.17359"
            },
            {
                "文章ID": "80486",
                "标题": "Training on Thin Air: Improve Image Classification with Generated Data",
                "作者": " Yongchao Zhou,  Hshmat Sahak,  Jimmy Ba",
                "发布日期": "2023-05-25",
                "摘要": "  Acquiring high-quality data for training discriminative models is a crucial\nyet challenging aspect of building effective predictive systems. In this paper,\nwe present Diffusion Inversion, a simple yet effective method that leverages\nthe pre-trained generative model, Stable Diffusion, to generate diverse,\nhigh-quality training data for image classification. Our approach captures the\noriginal data distribution and ensures data coverage by inverting images to the\nlatent space of Stable Diffusion, and generates diverse novel training images\nby conditioning the generative model on noisy versions of these vectors. We\nidentify three key components that allow our generated images to successfully\nsupplant the original dataset, leading to a 2-3x enhancement in sample\ncomplexity and a 6.5x decrease in sampling time. Moreover, our approach\nconsistently outperforms generic prompt-based steering methods and KNN\nretrieval baseline across a wide range of datasets. Additionally, we\ndemonstrate the compatibility of our approach with widely-used data\naugmentation techniques, as well as the reliability of the generated data in\nsupporting various neural architectures and enhancing few-shot learning.\n",
                "链接": "https://arxiv.org/abs/2305.15316"
            },
            {
                "文章ID": "50516",
                "标题": "Deep Learning Training Procedure Augmentations",
                "作者": " Cristian Simionescu",
                "发布日期": "2022-11-29",
                "摘要": "  Recent advances in Deep Learning have greatly improved performance on various\ntasks such as object detection, image segmentation, sentiment analysis. The\nfocus of most research directions up until very recently has been on beating\nstate-of-the-art results. This has materialized in the utilization of bigger\nand bigger models and techniques which help the training procedure to extract\nmore predictive power out of a given dataset. While this has lead to great\nresults, many of which with real-world applications, other relevant aspects of\ndeep learning have remained neglected and unknown. In this work, we will\npresent several novel deep learning training techniques which, while capable of\noffering significant performance gains they also reveal several interesting\nanalysis results regarding convergence speed, optimization landscape\nsmoothness, and adversarial robustness. The methods presented in this work are\nthe following:\n  $\\bullet$ Perfect Ordering Approximation; a generalized model agnostic\ncurriculum learning approach. The results show the effectiveness of the\ntechnique for improving training time as well as offer some new insight into\nthe training process of deep networks.\n  $\\bullet$ Cascading Sum Augmentation; an extension of mixup capable of\nutilizing more data points for linear interpolation by leveraging a smoother\noptimization landscape. This can be used for computer vision tasks in order to\nimprove both prediction performance as well as improve passive model\nrobustness.\n",
                "链接": "https://arxiv.org/abs/2211.14395"
            },
            {
                "文章ID": "79102",
                "标题": "GPT Paternity Test: GPT Generated Text Detection with GPT Genetic\n  Inheritance",
                "作者": " Xiao Yu,  Yuang Qi,  Kejiang Chen,  Guoqiang Chen,  Xi Yang,  Pengyuan Zhu,  Weiming Zhang,  Nenghai Yu",
                "发布日期": "2023-05-23",
                "摘要": "  Large Language Models (LLMs) can generate texts that carry the risk of\nvarious misuses, including plagiarism, planting fake reviews on e-commerce\nplatforms, or creating fake social media postings that can sway election\nresults. Detecting whether a text is machine-generated has thus become\nincreasingly important. While machine-learning-based detection strategies\nexhibit superior performance, they often lack generalizability, limiting their\npracticality. In this work, we introduce GPT Paternity Test (GPT-Pat), which\nreliably detects machine-generated text across varied datasets. Given a text\nunder scrutiny, we leverage ChatGPT to generate a corresponding question and\nprovide a re-answer to the question. By comparing the similarity between the\noriginal text and the generated re-answered text, it can be determined whether\nthe text is machine-generated. GPT-Pat consists of a Siamese network to compute\nthe similarity between the original text and the generated re-answered text and\na binary classifier. Our method achieved an average accuracy of 94.57% on four\ngeneralization test sets, surpassing the state-of-the-art RoBERTa-based method\nby 12.34%. The accuracy drop of our method is only about half of that of the\nRoBERTa-based method when it is attacked by re-translation and polishing.\n",
                "链接": "https://arxiv.org/abs/2305.12519"
            },
            {
                "文章ID": "79177",
                "标题": "G3Detector: General GPT-Generated Text Detector",
                "作者": " Haolan Zhan,  Xuanli He,  Qiongkai Xu,  Yuxiang Wu,  Pontus Stenetorp",
                "发布日期": "2023-08-07",
                "摘要": "  The burgeoning progress in the field of Large Language Models (LLMs) heralds\nsignificant benefits due to their unparalleled capacities. However, it is\ncritical to acknowledge the potential misuse of these models, which could give\nrise to a spectrum of social and ethical dilemmas. Despite numerous preceding\nefforts centered around distinguishing synthetic text, most existing detection\nsystems fail to identify data synthesized by the latest LLMs, such as ChatGPT\nand GPT-4. In response to this challenge, we introduce an unpretentious yet\npotent detection approach proficient in identifying synthetic text across a\nwide array of fields. Moreover, our detector demonstrates outstanding\nperformance uniformly across various model architectures and decoding\nstrategies. It also possesses the capability to identify text generated\nutilizing a potent detection-evasion technique. Our comprehensive research\nunderlines our commitment to boosting the robustness and efficiency of\nmachine-generated text detection mechanisms, particularly in the context of\nswiftly progressing and increasingly adaptive AI technologies.\n",
                "链接": "https://arxiv.org/abs/2305.12680"
            },
            {
                "文章ID": "68411",
                "标题": "Enriching Neural Network Training Dataset to Improve Worst-Case\n  Performance Guarantees",
                "作者": " Rahul Nellikkath,  Spyros Chatzivasileiadis",
                "发布日期": "2023-03-24",
                "摘要": "  Machine learning algorithms, especially Neural Networks (NNs), are a valuable\ntool used to approximate non-linear relationships, like the AC-Optimal Power\nFlow (AC-OPF), with considerable accuracy -- and achieving a speedup of several\norders of magnitude when deployed for use. Often in power systems literature,\nthe NNs are trained with a fixed dataset generated prior to the training\nprocess. In this paper, we show that adapting the NN training dataset during\ntraining can improve the NN performance and substantially reduce its worst-case\nviolations. This paper proposes an algorithm that identifies and enriches the\ntraining dataset with critical datapoints that reduce the worst-case violations\nand deliver a neural network with improved worst-case performance guarantees.\nWe demonstrate the performance of our algorithm in four test power systems,\nranging from 39-buses to 162-buses.\n",
                "链接": "https://arxiv.org/abs/2303.13228"
            },
            {
                "文章ID": "77375",
                "标题": "GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content",
                "作者": " Yutian Chen,  Hao Kang,  Vivian Zhai,  Liangze Li,  Rita Singh,  Bhiksha Raj",
                "发布日期": "2023-05-19",
                "摘要": "  This paper presents a novel approach for detecting ChatGPT-generated vs.\nhuman-written text using language models. To this end, we first collected and\nreleased a pre-processed dataset named OpenGPTText, which consists of rephrased\ncontent generated using ChatGPT. We then designed, implemented, and trained two\ndifferent models for text classification, using Robustly Optimized BERT\nPretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5),\nrespectively. Our models achieved remarkable results, with an accuracy of over\n97% on the test dataset, as evaluated through various metrics. Furthermore, we\nconducted an interpretability study to showcase our model's ability to extract\nand differentiate key features between human-written and ChatGPT-generated\ntext. Our findings provide important insights into the effective use of\nlanguage models to detect generated text.\n",
                "链接": "https://arxiv.org/abs/2305.07969"
            },
            {
                "文章ID": "65767",
                "标题": "Position Paper on Dataset Engineering to Accelerate Science",
                "作者": " Emilio Vital Brazil,  Eduardo Soares,  Lucas Villa Real,  Leonardo Azevedo,  Vinicius Segura,  Luiz Zerkowski,  Renato Cerqueira",
                "发布日期": "2023-03-13",
                "摘要": "  Data is a critical element in any discovery process. In the last decades, we\nobserved exponential growth in the volume of available data and the technology\nto manipulate it. However, data is only practical when one can structure it for\na well-defined task. For instance, we need a corpus of text broken into\nsentences to train a natural language machine-learning model. In this work, we\nwill use the token \\textit{dataset} to designate a structured set of data built\nto perform a well-defined task. Moreover, the dataset will be used in most\ncases as a blueprint of an entity that at any moment can be stored as a table.\nSpecifically, in science, each area has unique forms to organize, gather and\nhandle its datasets. We believe that datasets must be a first-class entity in\nany knowledge-intensive process, and all workflows should have exceptional\nattention to datasets' lifecycle, from their gathering to uses and evolution.\nWe advocate that science and engineering discovery processes are extreme\ninstances of the need for such organization on datasets, claiming for new\napproaches and tooling. Furthermore, these requirements are more evident when\nthe discovery workflow uses artificial intelligence methods to empower the\nsubject-matter expert. In this work, we discuss an approach to bringing\ndatasets as a critical entity in the discovery process in science. We\nillustrate some concepts using material discovery as a use case. We chose this\ndomain because it leverages many significant problems that can be generalized\nto other science fields.\n",
                "链接": "https://arxiv.org/abs/2303.05545"
            },
            {
                "文章ID": "4574",
                "标题": "Semantic features of object concepts generated with GPT-3",
                "作者": " Hannes Hansen,  Martin N. Hebart",
                "发布日期": "2022-05-11",
                "摘要": "  Semantic features have been playing a central role in investigating the\nnature of our conceptual representations. Yet the enormous time and effort\nrequired to empirically sample and norm features from human raters has\nrestricted their use to a limited set of manually curated concepts. Given\nrecent promising developments with transformer-based language models, here we\nasked whether it was possible to use such models to automatically generate\nmeaningful lists of properties for arbitrary object concepts and whether these\nmodels would produce features similar to those found in humans. To this end, we\nprobed a GPT-3 model to generate semantic features for 1,854 objects and\ncompared automatically-generated features to existing human feature norms.\nGPT-3 generated many more features than humans, yet showed a similar\ndistribution in the types of generated features. Generated feature norms\nrivaled human norms in predicting similarity, relatedness, and category\nmembership, while variance partitioning demonstrated that these predictions\nwere driven by similar variance in humans and GPT-3. Together, these results\nhighlight the potential of large language models to capture important facets of\nhuman knowledge and yield a new approach for automatically generating\ninterpretable feature sets, thus drastically expanding the potential use of\nsemantic features in psychological and linguistic studies.\n",
                "链接": "https://arxiv.org/abs/2202.03753"
            },
            {
                "文章ID": "81531",
                "标题": "Evaluating GPT-3 Generated Explanations for Hateful Content Moderation",
                "作者": " Han Wang,  Ming Shan Hee,  Md Rabiul Awal,  Kenny Tsu Wei Choo,  Roy Ka-Wei Lee",
                "发布日期": "2023-08-31",
                "摘要": "  Recent research has focused on using large language models (LLMs) to generate\nexplanations for hate speech through fine-tuning or prompting. Despite the\ngrowing interest in this area, these generated explanations' effectiveness and\npotential limitations remain poorly understood. A key concern is that these\nexplanations, generated by LLMs, may lead to erroneous judgments about the\nnature of flagged content by both users and content moderators. For instance,\nan LLM-generated explanation might inaccurately convince a content moderator\nthat a benign piece of content is hateful. In light of this, we propose an\nanalytical framework for examining hate speech explanations and conducted an\nextensive survey on evaluating such explanations. Specifically, we prompted\nGPT-3 to generate explanations for both hateful and non-hateful content, and a\nsurvey was conducted with 2,400 unique respondents to evaluate the generated\nexplanations. Our findings reveal that (1) human evaluators rated the\nGPT-generated explanations as high quality in terms of linguistic fluency,\ninformativeness, persuasiveness, and logical soundness, (2) the persuasive\nnature of these explanations, however, varied depending on the prompting\nstrategy employed, and (3) this persuasiveness may result in incorrect\njudgments about the hatefulness of the content. Our study underscores the need\nfor caution in applying LLM-generated explanations for content moderation. Code\nand results are available at https://github.com/Social-AI-Studio/GPT3-HateEval.\n",
                "链接": "https://arxiv.org/abs/2305.17680"
            }
        ]
    },
    {
        "question": {
            "question": "请找到利用clip做开放词汇检测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "41351",
                "标题": "Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP",
                "作者": " Feng Liang,  Bichen Wu,  Xiaoliang Dai,  Kunpeng Li,  Yinan Zhao,  Hang Zhang,  Peizhao Zhang,  Peter Vajda,  Diana Marculescu",
                "发布日期": "2023-04-04",
                "摘要": "  Open-vocabulary semantic segmentation aims to segment an image into semantic\nregions according to text descriptions, which may not have been seen during\ntraining. Recent two-stage methods first generate class-agnostic mask proposals\nand then leverage pre-trained vision-language models, e.g., CLIP, to classify\nmasked regions. We identify the performance bottleneck of this paradigm to be\nthe pre-trained CLIP model, since it does not perform well on masked images. To\naddress this, we propose to finetune CLIP on a collection of masked image\nregions and their corresponding text descriptions. We collect training data by\nmining an existing image-caption dataset (e.g., COCO Captions), using CLIP to\nmatch masked image regions to nouns in the image captions. Compared with the\nmore precise and manually annotated segmentation labels with fixed classes\n(e.g., COCO-Stuff), we find our noisy but diverse dataset can better retain\nCLIP's generalization ability. Along with finetuning the entire model, we\nutilize the \"blank\" areas in masked images using a method we dub mask prompt\ntuning. Experiments demonstrate mask prompt tuning brings significant\nimprovement without modifying any weights of CLIP, and it can further improve a\nfully finetuned model. In particular, when trained on COCO and evaluated on\nADE20K-150, our best model achieves 29.6% mIoU, which is +8.5% higher than the\nprevious state-of-the-art. For the first time, open-vocabulary generalist\nmodels match the performance of supervised specialist models in 2017 without\ndataset-specific adaptations.\n",
                "链接": "https://arxiv.org/abs/2210.04150"
            },
            {
                "文章ID": "104220",
                "标题": "CLIP-DIY: CLIP Dense Inference Yields Open-Vocabulary Semantic\n  Segmentation For-Free",
                "作者": " Monika Wysoczańska,  Michaël Ramamonjisoa,  Tomasz Trzciński,  Oriane Siméoni",
                "发布日期": "2023-11-29",
                "摘要": "  The emergence of CLIP has opened the way for open-world image perception. The\nzero-shot classification capabilities of the model are impressive but are\nharder to use for dense tasks such as image segmentation. Several methods have\nproposed different modifications and learning schemes to produce dense output.\nInstead, we propose in this work an open-vocabulary semantic segmentation\nmethod, dubbed CLIP-DIY, which does not require any additional training or\nannotations, but instead leverages existing unsupervised object localization\napproaches. In particular, CLIP-DIY is a multi-scale approach that directly\nexploits CLIP classification abilities on patches of different sizes and\naggregates the decision in a single map. We further guide the segmentation\nusing foreground/background scores obtained using unsupervised object\nlocalization methods. With our method, we obtain state-of-the-art zero-shot\nsemantic segmentation results on PASCAL VOC and perform on par with the best\nmethods on COCO. The code is available at\nhttp://github.com/wysoczanska/clip-diy\n",
                "链接": "https://arxiv.org/abs/2309.14289"
            },
            {
                "文章ID": "50058",
                "标题": "Open-vocabulary Attribute Detection",
                "作者": " María A. Bravo,  Sudhanshu Mittal,  Simon Ging,  Thomas Brox",
                "发布日期": "2023-03-10",
                "摘要": "  Vision-language modeling has enabled open-vocabulary tasks where predictions\ncan be queried using any text prompt in a zero-shot manner. Existing\nopen-vocabulary tasks focus on object classes, whereas research on object\nattributes is limited due to the lack of a reliable attribute-focused\nevaluation benchmark. This paper introduces the Open-Vocabulary Attribute\nDetection (OVAD) task and the corresponding OVAD benchmark. The objective of\nthe novel task and benchmark is to probe object-level attribute information\nlearned by vision-language models. To this end, we created a clean and densely\nannotated test set covering 117 attribute classes on the 80 object classes of\nMS COCO. It includes positive and negative annotations, which enables\nopen-vocabulary evaluation. Overall, the benchmark consists of 1.4 million\nannotations. For reference, we provide a first baseline method for\nopen-vocabulary attribute detection. Moreover, we demonstrate the benchmark's\nvalue by studying the attribute detection performance of several foundation\nmodels. Project page https://ovad-benchmark.github.io\n",
                "链接": "https://arxiv.org/abs/2211.12914"
            },
            {
                "文章ID": "12649",
                "标题": "PromptDet: Towards Open-vocabulary Detection using Uncurated Images",
                "作者": " Chengjian Feng,  Yujie Zhong,  Zequn Jie,  Xiangxiang Chu,  Haibing Ren,  Xiaolin Wei,  Weidi Xie,  Lin Ma",
                "发布日期": "2022-07-19",
                "摘要": "  The goal of this work is to establish a scalable pipeline for expanding an\nobject detector towards novel/unseen categories, using zero manual annotations.\nTo achieve that, we make the following four contributions: (i) in pursuit of\ngeneralisation, we propose a two-stage open-vocabulary object detector, where\nthe class-agnostic object proposals are classified with a text encoder from\npre-trained visual-language model; (ii) To pair the visual latent space (of RPN\nbox proposals) with that of the pre-trained text encoder, we propose the idea\nof regional prompt learning to align the textual embedding space with regional\nvisual object features; (iii) To scale up the learning procedure towards\ndetecting a wider spectrum of objects, we exploit the available online resource\nvia a novel self-training framework, which allows to train the proposed\ndetector on a large corpus of noisy uncurated web images. Lastly, (iv) to\nevaluate our proposed detector, termed as PromptDet, we conduct extensive\nexperiments on the challenging LVIS and MS-COCO dataset. PromptDet shows\nsuperior performance over existing approaches with fewer additional training\nimages and zero manual annotations whatsoever. Project page with code:\nhttps://fcjian.github.io/promptdet.\n",
                "链接": "https://arxiv.org/abs/2203.16513"
            },
            {
                "文章ID": "68341",
                "标题": "Open-Vocabulary Object Detection using Pseudo Caption Labels",
                "作者": " Han-Cheol Cho,  Won Young Jhoo,  Wooyoung Kang,  Byungseok Roh",
                "发布日期": "2023-03-24",
                "摘要": "  Recent open-vocabulary detection methods aim to detect novel objects by\ndistilling knowledge from vision-language models (VLMs) trained on a vast\namount of image-text pairs. To improve the effectiveness of these methods,\nresearchers have utilized datasets with a large vocabulary that contains a\nlarge number of object classes, under the assumption that such data will enable\nmodels to extract comprehensive knowledge on the relationships between various\nobjects and better generalize to unseen object classes. In this study, we argue\nthat more fine-grained labels are necessary to extract richer knowledge about\nnovel objects, including object attributes and relationships, in addition to\ntheir names. To address this challenge, we propose a simple and effective\nmethod named Pseudo Caption Labeling (PCL), which utilizes an image captioning\nmodel to generate captions that describe object instances from diverse\nperspectives. The resulting pseudo caption labels offer dense samples for\nknowledge distillation. On the LVIS benchmark, our best model trained on the\nde-duplicated VisualGenome dataset achieves an AP of 34.5 and an APr of 30.6,\ncomparable to the state-of-the-art performance. PCL's simplicity and\nflexibility are other notable features, as it is a straightforward\npre-processing technique that can be used with any image captioning model\nwithout imposing any restrictions on model architecture or training process.\n",
                "链接": "https://arxiv.org/abs/2303.13040"
            },
            {
                "文章ID": "116861",
                "标题": "CastDet: Toward Open Vocabulary Aerial Object Detection with\n  CLIP-Activated Student-Teacher Learning",
                "作者": " Yan Li,  Weiwei Guo,  Dunyun He,  Jiaqi Zhou,  Yuze Gao,  Wenxian Yu",
                "发布日期": "2023-11-21",
                "摘要": "  Object detection in aerial images is a pivotal task for various earth\nobservation applications, whereas current algorithms learn to detect only a\npre-defined set of object categories demanding sufficient bounding-box\nannotated training samples and fail to detect novel object categories. In this\npaper, we consider open-vocabulary object detection (OVD) in aerial images that\nenables the characterization of new objects beyond training categories on the\nearth surface without annotating training images for these new categories. The\nperformance of OVD depends on the quality of class-agnostic region proposals\nand pseudo-labels that can generalize well to novel object categories. To\nsimultaneously generate high-quality proposals and pseudo-labels, we propose\nCastDet, a CLIP-activated student-teacher open-vocabulary object Detection\nframework. Our end-to-end framework within the student-teacher mechanism\nemploys the CLIP model as an extra omniscient teacher of rich knowledge into\nthe student-teacher self-learning process. By doing so, our approach boosts\nnovel object proposals and classification. Furthermore, we design a dynamic\nlabel queue technique to maintain high-quality pseudo labels during batch\ntraining and mitigate label imbalance. We conduct extensive experiments on\nmultiple existing aerial object detection datasets, which are set up for the\nOVD task. Experimental results demonstrate our CastDet achieving superior\nopen-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean),\nwhich outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD\ndataset.\n",
                "链接": "https://arxiv.org/abs/2311.11646"
            },
            {
                "文章ID": "68353",
                "标题": "CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting\n  and Anchor Pre-Matching",
                "作者": " Xiaoshi Wu,  Feng Zhu,  Rui Zhao,  Hongsheng Li",
                "发布日期": "2023-03-24",
                "摘要": "  Open-vocabulary detection (OVD) is an object detection task aiming at\ndetecting objects from novel categories beyond the base categories on which the\ndetector is trained. Recent OVD methods rely on large-scale visual-language\npre-trained models, such as CLIP, for recognizing novel objects. We identify\nthe two core obstacles that need to be tackled when incorporating these models\ninto detector training: (1) the distribution mismatch that happens when\napplying a VL-model trained on whole images to region recognition tasks; (2)\nthe difficulty of localizing objects of unseen classes. To overcome these\nobstacles, we propose CORA, a DETR-style framework that adapts CLIP for\nOpen-vocabulary detection by Region prompting and Anchor pre-matching. Region\nprompting mitigates the whole-to-region distribution gap by prompting the\nregion features of the CLIP-based region classifier. Anchor pre-matching helps\nlearning generalizable object localization by a class-aware matching mechanism.\nWe evaluate CORA on the COCO OVD benchmark, where we achieve 41.7 AP50 on novel\nclasses, which outperforms the previous SOTA by 2.4 AP50 even without resorting\nto extra training data. When extra training data is available, we train\nCORA$^+$ on both ground-truth base-category annotations and additional pseudo\nbounding box labels computed by CORA. CORA$^+$ achieves 43.1 AP50 on the COCO\nOVD benchmark and 28.1 box APr on the LVIS OVD benchmark.\n",
                "链接": "https://arxiv.org/abs/2303.13076"
            },
            {
                "文章ID": "86253",
                "标题": "Scaling Open-Vocabulary Object Detection",
                "作者": " Matthias Minderer,  Alexey Gritsenko,  Neil Houlsby",
                "发布日期": "2023-07-21",
                "摘要": "  Open-vocabulary object detection has benefited greatly from pretrained\nvision-language models, but is still limited by the amount of available\ndetection training data. While detection training data can be expanded by using\nWeb image-text pairs as weak supervision, this has not been done at scales\ncomparable to image-level pretraining. Here, we scale up detection data with\nself-training, which uses an existing detector to generate pseudo-box\nannotations on image-text pairs. Major challenges in scaling self-training are\nthe choice of label space, pseudo-annotation filtering, and training\nefficiency. We present the OWLv2 model and OWL-ST self-training recipe, which\naddress these challenges. OWLv2 surpasses the performance of previous\nstate-of-the-art open-vocabulary detectors already at comparable training\nscales (~10M examples). However, with OWL-ST, we can scale to over 1B examples,\nyielding further large improvement: With an L/14 architecture, OWL-ST improves\nAP on LVIS rare classes, for which the model has seen no human box annotations,\nfrom 31.2% to 44.6% (43% relative improvement). OWL-ST unlocks Web-scale\ntraining for open-world localization, similar to what has been seen for image\nclassification and language modelling.\n",
                "链接": "https://arxiv.org/abs/2306.09683"
            },
            {
                "文章ID": "115237",
                "标题": "Open-Vocabulary Video Anomaly Detection",
                "作者": " Peng Wu,  Xuerong Zhou,  Guansong Pang,  Yujia Sun,  Jing Liu,  Peng Wang,  Yanning Zhang",
                "发布日期": "2023-11-16",
                "摘要": "  Video anomaly detection (VAD) with weak supervision has achieved remarkable\nperformance in utilizing video-level labels to discriminate whether a video\nframe is normal or abnormal. However, current approaches are inherently limited\nto a closed-set setting and may struggle in open-world applications where there\ncan be anomaly categories in the test data unseen during training. A few recent\nstudies attempt to tackle a more realistic setting, open-set VAD, which aims to\ndetect unseen anomalies given seen anomalies and normal videos. However, such a\nsetting focuses on predicting frame anomaly scores, having no ability to\nrecognize the specific categories of anomalies, despite the fact that this\nability is essential for building more informed video surveillance systems.\nThis paper takes a step further and explores open-vocabulary video anomaly\ndetection (OVVAD), in which we aim to leverage pre-trained large models to\ndetect and categorize seen and unseen anomalies. To this end, we propose a\nmodel that decouples OVVAD into two mutually complementary tasks --\nclass-agnostic detection and class-specific classification -- and jointly\noptimizes both tasks. Particularly, we devise a semantic knowledge injection\nmodule to introduce semantic knowledge from large language models for the\ndetection task, and design a novel anomaly synthesis module to generate pseudo\nunseen anomaly videos with the help of large vision generation models for the\nclassification task. These semantic knowledge and synthesis anomalies\nsubstantially extend our model's capability in detecting and categorizing a\nvariety of seen and unseen anomalies. Extensive experiments on three\nwidely-used benchmarks demonstrate our model achieves state-of-the-art\nperformance on OVVAD task.\n",
                "链接": "https://arxiv.org/abs/2311.07042"
            },
            {
                "文章ID": "100046",
                "标题": "EdaDet: Open-Vocabulary Object Detection Using Early Dense Alignment",
                "作者": " Cheng Shi,  Sibei Yang",
                "发布日期": "2023-09-06",
                "摘要": "  Vision-language models such as CLIP have boosted the performance of\nopen-vocabulary object detection, where the detector is trained on base\ncategories but required to detect novel categories. Existing methods leverage\nCLIP's strong zero-shot recognition ability to align object-level embeddings\nwith textual embeddings of categories. However, we observe that using CLIP for\nobject-level alignment results in overfitting to base categories, i.e., novel\ncategories most similar to base categories have particularly poor performance\nas they are recognized as similar base categories. In this paper, we first\nidentify that the loss of critical fine-grained local image semantics hinders\nexisting methods from attaining strong base-to-novel generalization. Then, we\npropose Early Dense Alignment (EDA) to bridge the gap between generalizable\nlocal semantics and object-level prediction. In EDA, we use object-level\nsupervision to learn the dense-level rather than object-level alignment to\nmaintain the local fine-grained semantics. Extensive experiments demonstrate\nour superior performance to competing approaches under the same strict setting\nand without using external training resources, i.e., improving the +8.4% novel\nbox AP50 on COCO and +3.9% rare mask AP on LVIS.\n",
                "链接": "https://arxiv.org/abs/2309.01151"
            }
        ]
    },
    {
        "question": {
            "question": "请找到使用自蒸馏加强目标检测性能的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "65588",
                "标题": "Smooth and Stepwise Self-Distillation for Object Detection",
                "作者": " Jieren Deng,  Xin Zhou,  Hao Tian,  Zhihong Pan,  Derek Aguiar",
                "发布日期": "2023-03-10",
                "摘要": "  Distilling the structured information captured in feature maps has\ncontributed to improved results for object detection tasks, but requires\ncareful selection of baseline architectures and substantial pre-training.\nSelf-distillation addresses these limitations and has recently achieved\nstate-of-the-art performance for object detection despite making several\nsimplifying architectural assumptions. Building on this work, we propose Smooth\nand Stepwise Self-Distillation (SSSD) for object detection. Our SSSD\narchitecture forms an implicit teacher from object labels and a feature pyramid\nnetwork backbone to distill label-annotated feature maps using Jensen-Shannon\ndistance, which is smoother than distillation losses used in prior work. We\nadditionally add a distillation coefficient that is adaptively configured based\non the learning rate. We extensively benchmark SSSD against a baseline and two\nstate-of-the-art object detector architectures on the COCO dataset by varying\nthe coefficients and backbone and detector networks. We demonstrate that SSSD\nachieves higher average precision in most experimental settings, is robust to a\nwide range of coefficients, and benefits from our stepwise distillation\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2303.05015"
            },
            {
                "文章ID": "66024",
                "标题": "Enhanced K-Radar: Optimal Density Reduction to Improve Detection\n  Performance and Accessibility of 4D Radar Tensor-based Object Detection",
                "作者": " Dong-Hee Paek,  Seung-Hyun Kong,  Kevin Tirta Wijaya",
                "发布日期": "2023-03-14",
                "摘要": "  Recent works have shown the superior robustness of four-dimensional (4D)\nRadar-based three-dimensional (3D) object detection in adverse weather\nconditions. However, processing 4D Radar data remains a challenge due to the\nlarge data size, which require substantial amount of memory for computing and\nstorage. In previous work, an online density reduction is performed on the 4D\nRadar Tensor (4DRT) to reduce the data size, in which the density reduction\nlevel is chosen arbitrarily. However, the impact of density reduction on the\ndetection performance and memory consumption remains largely unknown. In this\npaper, we aim to address this issue by conducting extensive hyperparamter\ntuning on the density reduction level. Experimental results show that\nincreasing the density level from 0.01% to 50% of the original 4DRT density\nlevel proportionally improves the detection performance, at a cost of memory\nconsumption. However, when the density level is increased beyond 5%, only the\nmemory consumption increases, while the detection performance oscillates below\nthe peak point. In addition to the optimized density hyperparameter, we also\nintroduce 4D Sparse Radar Tensor (4DSRT), a new representation for 4D Radar\ndata with offline density reduction, leading to a significantly reduced raw\ndata size. An optimized development kit for training the neural networks is\nalso provided, which along with the utilization of 4DSRT, improves training\nspeed by a factor of 17.1 compared to the state-of-the-art 4DRT-based neural\nnetworks. All codes are available at: https://github.com/kaist-avelab/K-Radar.\n",
                "链接": "https://arxiv.org/abs/2303.06342"
            },
            {
                "文章ID": "111321",
                "标题": "A model for multi-attack classification to improve intrusion detection\n  performance using deep learning approaches",
                "作者": " Arun Kumar Silivery,  Ram Mohan Rao Kovvur",
                "发布日期": "2023-10-26",
                "摘要": "  This proposed model introduces novel deep learning methodologies. The\nobjective here is to create a reliable intrusion detection mechanism to help\nidentify malicious attacks. Deep learning based solution framework is developed\nconsisting of three approaches. The first approach is Long-Short Term Memory\nRecurrent Neural Network (LSTM-RNN) with seven optimizer functions such as\nadamax, SGD, adagrad, adam, RMSprop, nadam and adadelta. The model is evaluated\non NSL-KDD dataset and classified multi attack classification. The model has\noutperformed with adamax optimizer in terms of accuracy, detection rate and low\nfalse alarm rate. The results of LSTM-RNN with adamax optimizer is compared\nwith existing shallow machine and deep learning models in terms of accuracy,\ndetection rate and low false alarm rate. The multi model methodology consisting\nof Recurrent Neural Network (RNN), Long-Short Term Memory Recurrent Neural\nNetwork (LSTM-RNN), and Deep Neural Network (DNN). The multi models are\nevaluated on bench mark datasets such as KDD99, NSL-KDD, and UNSWNB15 datasets.\nThe models self-learnt the features and classifies the attack classes as\nmulti-attack classification. The models RNN, and LSTM-RNN provide considerable\nperformance compared to other existing methods on KDD99 and NSL-KDD dataset\n",
                "链接": "https://arxiv.org/abs/2310.16380"
            },
            {
                "文章ID": "92560",
                "标题": "Spatial Self-Distillation for Object Detection with Inaccurate Bounding\n  Boxes",
                "作者": " Di Wu,  Pengfei Chen,  Xuehui Yu,  Guorong Li,  Zhenjun Han,  Jianbin Jiao",
                "发布日期": "2023-08-16",
                "摘要": "  Object detection via inaccurate bounding boxes supervision has boosted a\nbroad interest due to the expensive high-quality annotation data or the\noccasional inevitability of low annotation quality (\\eg tiny objects). The\nprevious works usually utilize multiple instance learning (MIL), which highly\ndepends on category information, to select and refine a low-quality box. Those\nmethods suffer from object drift, group prediction and part domination problems\nwithout exploring spatial information. In this paper, we heuristically propose\na \\textbf{Spatial Self-Distillation based Object Detector (SSD-Det)} to mine\nspatial information to refine the inaccurate box in a self-distillation\nfashion. SSD-Det utilizes a Spatial Position Self-Distillation \\textbf{(SPSD)}\nmodule to exploit spatial information and an interactive structure to combine\nspatial information and category information, thus constructing a high-quality\nproposal bag. To further improve the selection procedure, a Spatial Identity\nSelf-Distillation \\textbf{(SISD)} module is introduced in SSD-Det to obtain\nspatial confidence to help select the best proposals. Experiments on MS-COCO\nand VOC datasets with noisy box annotation verify our method's effectiveness\nand achieve state-of-the-art performance. The code is available at\nhttps://github.com/ucas-vg/PointTinyBenchmark/tree/SSD-Det.\n",
                "链接": "https://arxiv.org/abs/2307.12101"
            },
            {
                "文章ID": "116884",
                "标题": "Leveraging Uncertainty Estimates To Improve Classifier Performance",
                "作者": " Gundeep Arora,  Srujana Merugu,  Anoop Saladi,  Rajeev Rastogi",
                "发布日期": "2023-11-21",
                "摘要": "  Binary classification involves predicting the label of an instance based on\nwhether the model score for the positive class exceeds a threshold chosen based\non the application requirements (e.g., maximizing recall for a precision\nbound). However, model scores are often not aligned with the true positivity\nrate. This is especially true when the training involves a differential\nsampling across classes or there is distributional drift between train and test\nsettings. In this paper, we provide theoretical analysis and empirical evidence\nof the dependence of model score estimation bias on both uncertainty and score\nitself. Further, we formulate the decision boundary selection in terms of both\nmodel score and uncertainty, prove that it is NP-hard, and present algorithms\nbased on dynamic programming and isotonic regression. Evaluation of the\nproposed algorithms on three real-world datasets yield 25%-40% gain in recall\nat high precision bounds over the traditional approach of using model score\nalone, highlighting the benefits of leveraging uncertainty.\n",
                "链接": "https://arxiv.org/abs/2311.11723"
            },
            {
                "文章ID": "43891",
                "标题": "Frequency of Interest-based Noise Attenuation Method to Improve Anomaly\n  Detection Performance",
                "作者": " YeongHyeon Park,  Myung Jin Kim,  Won Seok Park",
                "发布日期": "2022-12-05",
                "摘要": "  Accurately extracting driving events is the way to maximize computational\nefficiency and anomaly detection performance in the tire frictional nose-based\nanomaly detection task. This study proposes a concise and highly useful method\nfor improving the precision of the event extraction that is hindered by extra\nnoise such as wind noise, which is difficult to characterize clearly due to its\nrandomness. The core of the proposed method is based on the identification of\nthe road friction sound corresponding to the frequency of interest and removing\nthe opposite characteristics with several frequency filters. Our method enables\nprecision maximization of driving event extraction while improving anomaly\ndetection performance by an average of 8.506%. Therefore, we conclude our\nmethod is a practical solution suitable for road surface anomaly detection\npurposes in outdoor edge computing environments.\n",
                "链接": "https://arxiv.org/abs/2210.11068"
            },
            {
                "文章ID": "60199",
                "标题": "Trust, but Verify: Using Self-Supervised Probing to Improve\n  Trustworthiness",
                "作者": " Ailin Deng,  Shen Li,  Miao Xiong,  Zhirui Chen,  Bryan Hooi",
                "发布日期": "2023-02-07",
                "摘要": "  Trustworthy machine learning is of primary importance to the practical\ndeployment of deep learning models. While state-of-the-art models achieve\nastonishingly good performance in terms of accuracy, recent literature reveals\nthat their predictive confidence scores unfortunately cannot be trusted: e.g.,\nthey are often overconfident when wrong predictions are made, or so even for\nobvious outliers. In this paper, we introduce a new approach of self-supervised\nprobing, which enables us to check and mitigate the overconfidence issue for a\ntrained model, thereby improving its trustworthiness. We provide a simple yet\neffective framework, which can be flexibly applied to existing\ntrustworthiness-related methods in a plug-and-play manner. Extensive\nexperiments on three trustworthiness-related tasks (misclassification\ndetection, calibration and out-of-distribution detection) across various\nbenchmarks verify the effectiveness of our proposed probing framework.\n",
                "链接": "https://arxiv.org/abs/2302.02628"
            },
            {
                "文章ID": "39884",
                "标题": "Using Knowledge Distillation to improve interpretable models in a retail\n  banking context",
                "作者": " Maxime Biehler,  Mohamed Guermazi,  Célim Starck",
                "发布日期": "2022-10-03",
                "摘要": "  This article sets forth a review of knowledge distillation techniques with a\nfocus on their applicability to retail banking contexts. Predictive machine\nlearning algorithms used in banking environments, especially in risk and\ncontrol functions, are generally subject to regulatory and technical\nconstraints limiting their complexity. Knowledge distillation gives the\nopportunity to improve the performances of simple models without burdening\ntheir application, using the results of other - generally more complex and\nbetter-performing - models. Parsing recent advances in this field, we highlight\nthree main approaches: Soft Targets, Sample Selection and Data Augmentation. We\nassess the relevance of a subset of such techniques by applying them to open\nsource datasets, before putting them to the test on the use cases of BPCE, a\nmajor French institution in the retail banking sector. As such, we demonstrate\nthe potential of knowledge distillation to improve the performance of these\nmodels without altering their form and simplicity.\n",
                "链接": "https://arxiv.org/abs/2209.15496"
            },
            {
                "文章ID": "14674",
                "标题": "Localization Distillation for Object Detection",
                "作者": " Zhaohui Zheng,  Rongguang Ye,  Qibin Hou,  Dongwei Ren,  Ping Wang,  Wangmeng Zuo,  Ming-Ming Cheng",
                "发布日期": "2022-12-09",
                "摘要": "  Previous knowledge distillation (KD) methods for object detection mostly\nfocus on feature imitation instead of mimicking the prediction logits due to\nits inefficiency in distilling the localization information. In this paper, we\ninvestigate whether logit mimicking always lags behind feature imitation.\nTowards this goal, we first present a novel localization distillation (LD)\nmethod which can efficiently transfer the localization knowledge from the\nteacher to the student. Second, we introduce the concept of valuable\nlocalization region that can aid to selectively distill the classification and\nlocalization knowledge for a certain region. Combining these two new\ncomponents, for the first time, we show that logit mimicking can outperform\nfeature imitation and the absence of localization distillation is a critical\nreason for why logit mimicking underperforms for years. The thorough studies\nexhibit the great potential of logit mimicking that can significantly alleviate\nthe localization ambiguity, learn robust feature representation, and ease the\ntraining difficulty in the early stage. We also provide the theoretical\nconnection between the proposed LD and the classification KD, that they share\nthe equivalent optimization effect. Our distillation scheme is simple as well\nas effective and can be easily applied to both dense horizontal object\ndetectors and rotated object detectors. Extensive experiments on the MS COCO,\nPASCAL VOC, and DOTA benchmarks demonstrate that our method can achieve\nconsiderable AP improvement without any sacrifice on the inference speed. Our\nsource code and pretrained models are publicly available at\nhttps://github.com/HikariTJU/LD.\n",
                "链接": "https://arxiv.org/abs/2204.05957"
            },
            {
                "文章ID": "38197",
                "标题": "An Outlier Exposure Approach to Improve Visual Anomaly Detection\n  Performance for Mobile Robots",
                "作者": " Dario Mantegazza,  Alessandro Giusti,  Luca Maria Gambardella,  Jérôme Guzzi",
                "发布日期": "2022-09-21",
                "摘要": "  We consider the problem of building visual anomaly detection systems for\nmobile robots. Standard anomaly detection models are trained using large\ndatasets composed only of non-anomalous data. However, in robotics\napplications, it is often the case that (potentially very few) examples of\nanomalies are available. We tackle the problem of exploiting these data to\nimprove the performance of a Real-NVP anomaly detection model, by minimizing,\njointly with the Real-NVP loss, an auxiliary outlier exposure margin loss. We\nperform quantitative experiments on a novel dataset (which we publish as\nsupplementary material) designed for anomaly detection in an indoor patrolling\nscenario. On a disjoint test set, our approach outperforms alternatives and\nshows that exposing even a small number of anomalous frames yields significant\nperformance improvements.\n",
                "链接": "https://arxiv.org/abs/2209.09786"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用2020年以后CONLL 2004数据集进行NER评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "19232",
                "标题": "The VoicePrivacy 2020 Challenge Evaluation Plan",
                "作者": " Natalia Tomashenko,  Brij Mohan Lal Srivastava,  Xin Wang,  Emmanuel Vincent,  Andreas Nautsch,  Junichi Yamagishi,  Nicholas Evans,  Jose Patino,  Jean-François Bonastre,  Paul-Gauthier Noé,  Massimiliano Todisco",
                "发布日期": "2022-05-17",
                "摘要": "  The VoicePrivacy Challenge aims to promote the development of privacy\npreservation tools for speech technology by gathering a new community to define\nthe tasks of interest and the evaluation methodology, and benchmarking\nsolutions through a series of challenges. In this document, we formulate the\nvoice anonymization task selected for the VoicePrivacy 2020 Challenge and\ndescribe the datasets used for system development and evaluation. We also\npresent the attack models and the associated objective and subjective\nevaluation metrics. We introduce two anonymization baselines and report\nobjective evaluation results.\n",
                "链接": "https://arxiv.org/abs/2205.07123"
            },
            {
                "文章ID": "54351",
                "标题": "Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?",
                "作者": " Shuheng Liu,  Alan Ritter",
                "发布日期": "2023-07-13",
                "摘要": "  The CoNLL-2003 English named entity recognition (NER) dataset has been widely\nused to train and evaluate NER models for almost 20 years. However, it is\nunclear how well models that are trained on this 20-year-old data and developed\nover a period of decades using the same test set will perform when applied on\nmodern data. In this paper, we evaluate the generalization of over 20 different\nmodels trained on CoNLL-2003, and show that NER models have very different\ngeneralization. Surprisingly, we find no evidence of performance degradation in\npre-trained Transformers, such as RoBERTa and T5, even when fine-tuned using\ndecades-old data. We investigate why some models generalize well to new data\nwhile others do not, and attempt to disentangle the effects of temporal drift\nand overfitting due to test reuse. Our analysis suggests that most\ndeterioration is due to temporal mismatch between the pre-training corpora and\nthe downstream test sets. We found that four factors are important for good\ngeneralization: model architecture, number of parameters, time period of the\npre-training corpus, in addition to the amount of fine-tuning data. We suggest\ncurrent evaluation methods have, in some sense, underestimated progress on NER\nover the past 20 years, as NER models have not only improved on the original\nCoNLL-2003 test set, but improved even more on modern data. Our datasets can be\nfound at https://github.com/ShuhengL/acl2023_conllpp.\n",
                "链接": "https://arxiv.org/abs/2212.09747"
            },
            {
                "文章ID": "50504",
                "标题": "Finetuning BERT on Partially Annotated NER Corpora",
                "作者": " Viktor Scherbakov,  Vladimir Mayorov",
                "发布日期": "2022-11-29",
                "摘要": "  Most Named Entity Recognition (NER) models operate under the assumption that\ntraining datasets are fully labelled. While it is valid for established\ndatasets like CoNLL 2003 and OntoNotes, sometimes it is not feasible to obtain\nthe complete dataset annotation. These situations may occur, for instance,\nafter selective annotation of entities for cost reduction. This work presents\nan approach to finetuning BERT on such partially labelled datasets using\nself-supervision and label preprocessing. Our approach outperforms the previous\nLSTM-based label preprocessing baseline, significantly improving the\nperformance on poorly labelled datasets. We demonstrate that following our\napproach while finetuning RoBERTa on CoNLL 2003 dataset with only 10% of total\nentities labelled is enough to reach the performance of the baseline trained on\nthe same dataset with 50% of the entities labelled.\n",
                "链接": "https://arxiv.org/abs/2211.14360"
            },
            {
                "文章ID": "46217",
                "标题": "Recognizing Nested Entities from Flat Supervision: A New NER Subtask,\n  Feasibility and Challenges",
                "作者": " Enwei Zhu,  Yiyang Liu,  Ming Jin,  Jinpeng Li",
                "发布日期": "2022-11-02",
                "摘要": "  Many recent named entity recognition (NER) studies criticize flat NER for its\nnon-overlapping assumption, and switch to investigating nested NER. However,\nexisting nested NER models heavily rely on training data annotated with nested\nentities, while labeling such data is costly. This study proposes a new\nsubtask, nested-from-flat NER, which corresponds to a realistic application\nscenario: given data annotated with flat entities only, one may still desire\nthe trained model capable of recognizing nested entities. To address this task,\nwe train span-based models and deliberately ignore the spans nested inside\nlabeled entities, since these spans are possibly unlabeled entities. With\nnested entities removed from the training data, our model achieves 54.8%, 54.2%\nand 41.1% F1 scores on the subset of spans within entities on ACE 2004, ACE\n2005 and GENIA, respectively. This suggests the effectiveness of our approach\nand the feasibility of the task. In addition, the model's performance on flat\nentities is entirely unaffected. We further manually annotate the nested\nentities in the test set of CoNLL 2003, creating a nested-from-flat NER\nbenchmark. Analysis results show that the main challenges stem from the data\nand annotation inconsistencies between the flat and nested entities.\n",
                "链接": "https://arxiv.org/abs/2211.00301"
            },
            {
                "文章ID": "111254",
                "标题": "CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset",
                "作者": " Susanna Rücker,  Alan Akbik",
                "发布日期": "2023-10-26",
                "摘要": "  The CoNLL-03 corpus is arguably the most well-known and utilized benchmark\ndataset for named entity recognition (NER). However, prior works found\nsignificant numbers of annotation errors, incompleteness, and inconsistencies\nin the data. This poses challenges to objectively comparing NER approaches and\nanalyzing their errors, as current state-of-the-art models achieve F1-scores\nthat are comparable to or even exceed the estimated noise level in CoNLL-03. To\naddress this issue, we present a comprehensive relabeling effort assisted by\nautomatic consistency checking that corrects 7.0% of all labels in the English\nCoNLL-03. Our effort adds a layer of entity linking annotation both for better\nexplainability of NER labels and as additional safeguard of annotation quality.\nOur experimental evaluation finds not only that state-of-the-art approaches\nreach significantly higher F1-scores (97.1%) on our data, but crucially that\nthe share of correct predictions falsely counted as errors due to annotation\nnoise drops from 47% to 6%. This indicates that our resource is well suited to\nanalyze the remaining errors made by state-of-the-art models, and that the\ntheoretical upper bound even on high resource, coarse-grained NER is not yet\nreached. To facilitate such analysis, we make CleanCoNLL publicly available to\nthe research community.\n",
                "链接": "https://arxiv.org/abs/2310.16225"
            },
            {
                "文章ID": "12159",
                "标题": "Federated Named Entity Recognition",
                "作者": " Joel Mathew,  Dimitris Stripelis,  José Luis Ambite",
                "发布日期": "2022-03-30",
                "摘要": "  We present an analysis of the performance of Federated Learning in a\nparadigmatic natural-language processing task: Named-Entity Recognition (NER).\nFor our evaluation, we use the language-independent CoNLL-2003 dataset as our\nbenchmark dataset and a Bi-LSTM-CRF model as our benchmark NER model. We show\nthat federated training reaches almost the same performance as the centralized\nmodel, though with some performance degradation as the learning environments\nbecome more heterogeneous. We also show the convergence rate of federated\nmodels for NER. Finally, we discuss existing challenges of Federated Learning\nfor NLP applications that can foster future research directions.\n",
                "链接": "https://arxiv.org/abs/2203.15101"
            },
            {
                "文章ID": "82089",
                "标题": "A Multilingual Evaluation of NER Robustness to Adversarial Inputs",
                "作者": " Akshay Srinivasan,  Sowmya Vajjala",
                "发布日期": "2023-05-31",
                "摘要": "  Adversarial evaluations of language models typically focus on English alone.\nIn this paper, we performed a multilingual evaluation of Named Entity\nRecognition (NER) in terms of its robustness to small perturbations in the\ninput. Our results showed the NER models we explored across three languages\n(English, German and Hindi) are not very robust to such changes, as indicated\nby the fluctuations in the overall F1 score as well as in a more fine-grained\nevaluation. With that knowledge, we further explored whether it is possible to\nimprove the existing NER models using a part of the generated adversarial data\nsets as augmented training data to train a new NER model or as fine-tuning data\nto adapt an existing NER model. Our results showed that both these approaches\nimprove performance on the original as well as adversarial test sets. While\nthere is no significant difference between the two approaches for English,\nre-training is significantly better than fine-tuning for German and Hindi.\n",
                "链接": "https://arxiv.org/abs/2305.18933"
            },
            {
                "文章ID": "10782",
                "标题": "Leveraging Expert Guided Adversarial Augmentation For Improving\n  Generalization in Named Entity Recognition",
                "作者": " Aaron Reich,  Jiaao Chen,  Aastha Agrawal,  Yanzhe Zhang,  Diyi Yang",
                "发布日期": "2022-03-22",
                "摘要": "  Named Entity Recognition (NER) systems often demonstrate great performance on\nin-distribution data, but perform poorly on examples drawn from a shifted\ndistribution. One way to evaluate the generalization ability of NER models is\nto use adversarial examples, on which the specific variations associated with\nnamed entities are rarely considered. To this end, we propose leveraging\nexpert-guided heuristics to change the entity tokens and their surrounding\ncontexts thereby altering their entity types as adversarial attacks. Using\nexpert-guided heuristics, we augmented the CoNLL 2003 test set and manually\nannotated it to construct a high-quality challenging set. We found that\nstate-of-the-art NER systems trained on CoNLL 2003 training data drop\nperformance dramatically on our challenging set. By training on adversarial\naugmented training examples and using mixup for regularization, we were able to\nsignificantly improve the performance on the challenging set as well as improve\nout-of-domain generalization which we evaluated by using OntoNotes data. We\nhave publicly released our dataset and code at\nhttps://github.com/GT-SALT/Guided-Adversarial-Augmentation.\n",
                "链接": "https://arxiv.org/abs/2203.10693"
            },
            {
                "文章ID": "39331",
                "标题": "mRobust04: A Multilingual Version of the TREC Robust 2004 Benchmark",
                "作者": " Vitor Jeronymo,  Mauricio Nascimento,  Roberto Lotufo,  Rodrigo Nogueira",
                "发布日期": "2022-09-29",
                "摘要": "  Robust 2004 is an information retrieval benchmark whose large number of\njudgments per query make it a reliable evaluation dataset. In this paper, we\npresent mRobust04, a multilingual version of Robust04 that was translated to 8\nlanguages using Google Translate. We also provide results of three different\nmultilingual retrievers on this dataset. The dataset is available at\nhttps://huggingface.co/datasets/unicamp-dl/mrobust\n",
                "链接": "https://arxiv.org/abs/2209.13738"
            },
            {
                "文章ID": "118407",
                "标题": "After-Stroke Arm Paresis Detection using Kinematic Data",
                "作者": " Kenneth Lai,  Mohammed Almekhlafi,  Svetlana Yanushkevich",
                "发布日期": "2023-11-29",
                "摘要": "  This paper presents an approach for detecting unilateral arm\nparalysis/weakness using kinematic data. Our method employs temporal\nconvolution networks and recurrent neural networks, guided by knowledge\ndistillation, where we use inertial measurement units attached to the body to\ncapture kinematic information such as acceleration, rotation, and flexion of\nbody joints during an action. This information is then analyzed to recognize\nbody actions and patterns. Our proposed network achieves a high paretic\ndetection accuracy of 97.99\\%, with an action classification accuracy of\n77.69\\%, through knowledge sharing. Furthermore, by incorporating causal\nreasoning, we can gain additional insights into the patient's condition, such\nas their Fugl-Meyer assessment score or impairment level based on the machine\nlearning result. Overall, our approach demonstrates the potential of using\nkinematic data and machine learning for detecting arm paralysis/weakness. The\nresults suggest that our method could be a useful tool for clinicians and\nhealthcare professionals working with patients with this condition.\n",
                "链接": "https://arxiv.org/abs/2311.16138"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用CrossWoz或MultiWoz数据集进行DST评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "46848",
                "标题": "MultiWOZ-DF -- A Dataflow implementation of the MultiWOZ dataset",
                "作者": " Joram Meron,  Victor Guimarães",
                "发布日期": "2022-11-07",
                "摘要": "  Semantic Machines (SM) have introduced the use of the dataflow (DF) paradigm\nto dialogue modelling, using computational graphs to hierarchically represent\nuser requests, data, and the dialogue history [Semantic Machines et al. 2020].\nAlthough the main focus of that paper was the SMCalFlow dataset (to date, the\nonly dataset with \"native\" DF annotations), they also reported some results of\nan experiment using a transformed version of the commonly used MultiWOZ dataset\n[Budzianowski et al. 2018] into a DF format. In this paper, we expand the\nexperiments using DF for the MultiWOZ dataset, exploring some additional\nexperimental set-ups. The code and instructions to reproduce the experiments\nreported here have been released. The contributions of this paper are: 1.) A DF\nimplementation capable of executing MultiWOZ dialogues; 2.) Several versions of\nconversion of MultiWOZ into a DF format are presented; 3.) Experimental results\non state match and translation accuracy.\n",
                "链接": "https://arxiv.org/abs/2211.02303"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "7222",
                "标题": "ASSIST: Towards Label Noise-Robust Dialogue State Tracking",
                "作者": " Fanghua Ye,  Yue Feng,  Emine Yilmaz",
                "发布日期": "2022-03-15",
                "摘要": "  The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state\ntracking (DST). However, substantial noise has been discovered in its state\nannotations. Such noise brings about huge challenges for training DST models\nrobustly. Although several refined versions, including MultiWOZ 2.1-2.4, have\nbeen published recently, there are still lots of noisy labels, especially in\nthe training set. Besides, it is costly to rectify all the problematic\nannotations. In this paper, instead of improving the annotation quality\nfurther, we propose a general framework, named ASSIST (lAbel noiSe-robuSt\ndIalogue State Tracking), to train DST models robustly from noisy labels.\nASSIST first generates pseudo labels for each sample in the training set by\nusing an auxiliary model trained on a small clean dataset, then puts the\ngenerated pseudo labels and vanilla noisy labels together to train the primary\nmodel. We show the validity of ASSIST theoretically. Experimental results also\ndemonstrate that ASSIST improves the joint goal accuracy of DST by up to\n$28.16\\%$ on MultiWOZ 2.0 and $8.41\\%$ on MultiWOZ 2.4, compared to using only\nthe vanilla noisy labels.\n",
                "链接": "https://arxiv.org/abs/2202.13024"
            },
            {
                "文章ID": "105774",
                "标题": "DST-Det: Simple Dynamic Self-Training for Open-Vocabulary Object\n  Detection",
                "作者": " Shilin Xu,  Xiangtai Li,  Size Wu,  Wenwei Zhang,  Yining Li,  Guangliang Cheng,  Yunhai Tong,  Kai Chen,  Chen Change Loy",
                "发布日期": "2023-12-27",
                "摘要": "  Open-vocabulary object detection (OVOD) aims to detect the objects beyond the\nset of classes observed during training. This work presents a simple yet\neffective strategy that leverages the zero-shot classification ability of\npre-trained vision-language models (VLM), such as CLIP, to directly discover\nproposals of possible novel classes. Unlike previous works that ignore novel\nclasses during training and rely solely on the region proposal network (RPN)\nfor novel object detection, our method selectively filters proposals based on\nspecific design criteria. The resulting sets of identified proposals serve as\npseudo-labels of potential novel classes during the training phase. This\nself-training strategy improves the recall and accuracy of novel classes\nwithout requiring additional annotations or datasets. We further propose a\nsimple offline pseudo-label generation strategy to refine the object detector.\nEmpirical evaluations on three datasets, including LVIS, V3Det, and COCO,\ndemonstrate significant improvements over the baseline performance without\nincurring additional parameters or computational costs during inference. In\nparticular, compared with previous F-VLM, our method achieves a 1.7\\%\nimprovement on the LVIS dataset. We also achieve over 6.5\\% improvement on the\nrecent challenging V3Det dataset. When combined with the recent method\nCLIPSelf, our method also achieves 46.7 novel class AP on COCO without\nintroducing extra data for pertaining.\n",
                "链接": "https://arxiv.org/abs/2310.01393"
            },
            {
                "文章ID": "95138",
                "标题": "Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using\n  EmotionBench",
                "作者": " Jen-tse Huang,  Man Ho Lam,  Eric John Li,  Shujie Ren,  Wenxuan Wang,  Wenxiang Jiao,  Zhaopeng Tu,  Michael R. Lyu",
                "发布日期": "2023-11-17",
                "摘要": "  Recently, the community has witnessed the advancement of Large Language\nModels (LLMs), which have shown remarkable performance on various downstream\ntasks. Led by powerful models like ChatGPT and Claude, LLMs are revolutionizing\nhow users engage with software, assuming more than mere tools but intelligent\nassistants. Consequently, evaluating LLMs' anthropomorphic capabilities becomes\nincreasingly important in contemporary discourse. Utilizing the emotion\nappraisal theory from psychology, we propose to evaluate the empathy ability of\nLLMs, i.e., how their feelings change when presented with specific situations.\nAfter a careful and comprehensive survey, we collect a dataset containing over\n400 situations that have proven effective in eliciting the eight emotions\ncentral to our study. Categorizing the situations into 36 factors, we conduct a\nhuman evaluation involving more than 1,200 subjects worldwide. With the human\nevaluation results as references, our evaluation includes five LLMs, covering\nboth commercial and open-source models, including variations in model sizes,\nfeaturing the latest iterations, such as GPT-4 and LLaMA 2. A conclusion can be\ndrawn from the results that, despite several misalignments, LLMs can generally\nrespond appropriately to certain situations. Nevertheless, they fall short in\nalignment with the emotional behaviors of human beings and cannot establish\nconnections between similar situations. Our collected dataset of situations,\nthe human evaluation results, and the code of our testing framework, dubbed\nEmotionBench, is made publicly in https://github.com/CUHK-ARISE/EmotionBench.\nWe aspire to contribute to the advancement of LLMs regarding better alignment\nwith the emotional behaviors of human beings, thereby enhancing their utility\nand applicability as intelligent assistants.\n",
                "链接": "https://arxiv.org/abs/2308.03656"
            },
            {
                "文章ID": "93134",
                "标题": "Multi3WOZ: A Multilingual, Multi-Domain, Multi-Parallel Dataset for\n  Training and Evaluating Culturally Adapted Task-Oriented Dialog Systems",
                "作者": " Songbo Hu,  Han Zhou,  Mete Hergul,  Milan Gritta,  Guchun Zhang,  Ignacio Iacobacci,  Ivan Vulić,  Anna Korhonen",
                "发布日期": "2023-07-27",
                "摘要": "  Creating high-quality annotated data for task-oriented dialog (ToD) is known\nto be notoriously difficult, and the challenges are amplified when the goal is\nto create equitable, culturally adapted, and large-scale ToD datasets for\nmultiple languages. Therefore, the current datasets are still very scarce and\nsuffer from limitations such as translation-based non-native dialogs with\ntranslation artefacts, small scale, or lack of cultural adaptation, among\nothers. In this work, we first take stock of the current landscape of\nmultilingual ToD datasets, offering a systematic overview of their properties\nand limitations. Aiming to reduce all the detected limitations, we then\nintroduce Multi3WOZ, a novel multilingual, multi-domain, multi-parallel ToD\ndataset. It is large-scale and offers culturally adapted dialogs in 4 languages\nto enable training and evaluation of multilingual and cross-lingual ToD\nsystems. We describe a complex bottom-up data collection process that yielded\nthe final dataset, and offer the first sets of baseline scores across different\nToD-related tasks for future reference, also highlighting its challenging\nnature.\n",
                "链接": "https://arxiv.org/abs/2307.14031"
            },
            {
                "文章ID": "8498",
                "标题": "Mismatch between Multi-turn Dialogue and its Evaluation Metric in\n  Dialogue State Tracking",
                "作者": " Takyoung Kim,  Hoonsang Yoon,  Yukyung Lee,  Pilsung Kang,  Misuk Kim",
                "发布日期": "2022-04-01",
                "摘要": "  Dialogue state tracking (DST) aims to extract essential information from\nmulti-turn dialogue situations and take appropriate actions. A belief state,\none of the core pieces of information, refers to the subject and its specific\ncontent, and appears in the form of domain-slot-value. The trained model\npredicts \"accumulated\" belief states in every turn, and joint goal accuracy and\nslot accuracy are mainly used to evaluate the prediction; however, we specify\nthat the current evaluation metrics have a critical limitation when evaluating\nbelief states accumulated as the dialogue proceeds, especially in the most used\nMultiWOZ dataset. Additionally, we propose relative slot accuracy to complement\nexisting metrics. Relative slot accuracy does not depend on the number of\npredefined slots, and allows intuitive evaluation by assigning relative scores\naccording to the turn of each dialogue. This study also encourages not solely\nthe reporting of joint goal accuracy, but also various complementary metrics in\nDST tasks for the sake of a realistic evaluation.\n",
                "链接": "https://arxiv.org/abs/2203.03123"
            },
            {
                "文章ID": "40726",
                "标题": "Schema Encoding for Transferable Dialogue State Tracking",
                "作者": " Hyunmin Jeon,  Gary Geunbae Lee",
                "发布日期": "2022-10-06",
                "摘要": "  Dialogue state tracking (DST) is an essential sub-task for task-oriented\ndialogue systems. Recent work has focused on deep neural models for DST.\nHowever, the neural models require a large dataset for training. Furthermore,\napplying them to another domain needs a new dataset because the neural models\nare generally trained to imitate the given dataset. In this paper, we propose\nSchema Encoding for Transferable Dialogue State Tracking (SETDST), which is a\nneural DST method for effective transfer to new domains. Transferable DST could\nassist developments of dialogue systems even with few dataset on target\ndomains. We use a schema encoder not just to imitate the dataset but to\ncomprehend the schema of the dataset. We aim to transfer the model to new\ndomains by encoding new schemas and using them for DST on multi-domain\nsettings. As a result, SET-DST improved the joint accuracy by 1.46 points on\nMultiWOZ 2.1.\n",
                "链接": "https://arxiv.org/abs/2210.02351"
            },
            {
                "文章ID": "45137",
                "标题": "Is MultiWOZ a Solved Task? An Interactive TOD Evaluation Framework with\n  User Simulator",
                "作者": " Qinyuan Cheng,  Linyang Li,  Guofeng Quan,  Feng Gao,  Xiaofeng Mou,  Xipeng Qiu",
                "发布日期": "2022-10-27",
                "摘要": "  Task-Oriented Dialogue (TOD) systems are drawing more and more attention in\nrecent studies. Current methods focus on constructing pre-trained models or\nfine-tuning strategies while the evaluation of TOD is limited by a policy\nmismatch problem. That is, during evaluation, the user utterances are from the\nannotated dataset while these utterances should interact with previous\nresponses which can have many alternatives besides annotated texts. Therefore,\nin this work, we propose an interactive evaluation framework for TOD. We first\nbuild a goal-oriented user simulator based on pre-trained models and then use\nthe user simulator to interact with the dialogue system to generate dialogues.\nBesides, we introduce a sentence-level and a session-level score to measure the\nsentence fluency and session coherence in the interactive evaluation.\nExperimental results show that RL-based TOD systems trained by our proposed\nuser simulator can achieve nearly 98% inform and success rates in the\ninteractive evaluation of MultiWOZ dataset and the proposed scores measure the\nresponse quality besides the inform and success rates. We are hoping that our\nwork will encourage simulator-based interactive evaluations in the TOD task.\n",
                "链接": "https://arxiv.org/abs/2210.14529"
            },
            {
                "文章ID": "20266",
                "标题": "Multi2WOZ: A Robust Multilingual Dataset and Conversational Pretraining\n  for Task-Oriented Dialog",
                "作者": " Chia-Chien Hung,  Anne Lauscher,  Ivan Vulić,  Simone Paolo Ponzetto,  Goran Glavaš",
                "发布日期": "2022-05-24",
                "摘要": "  Research on (multi-domain) task-oriented dialog (TOD) has predominantly\nfocused on the English language, primarily due to the shortage of robust TOD\ndatasets in other languages, preventing the systematic investigation of\ncross-lingual transfer for this crucial NLP application area. In this work, we\nintroduce Multi2WOZ, a new multilingual multi-domain TOD dataset, derived from\nthe well-established English dataset MultiWOZ, that spans four typologically\ndiverse languages: Chinese, German, Arabic, and Russian. In contrast to\nconcurrent efforts, Multi2WOZ contains gold-standard dialogs in target\nlanguages that are directly comparable with development and test portions of\nthe English dataset, enabling reliable and comparative estimates of\ncross-lingual transfer performance for TOD. We then introduce a new framework\nfor multilingual conversational specialization of pretrained language models\n(PrLMs) that aims to facilitate cross-lingual transfer for arbitrary downstream\nTOD tasks. Using such conversational PrLMs specialized for concrete target\nlanguages, we systematically benchmark a number of zero-shot and few-shot\ncross-lingual transfer approaches on two standard TOD tasks: Dialog State\nTracking and Response Retrieval. Our experiments show that, in most setups, the\nbest performance entails the combination of (I) conversational specialization\nin the target language and (ii) few-shot transfer for the concrete TOD task.\nMost importantly, we show that our conversational specialization in the target\nlanguage allows for an exceptionally sample-efficient few-shot transfer for\ndownstream TOD tasks.\n",
                "链接": "https://arxiv.org/abs/2205.10400"
            }
        ]
    },
    {
        "question": {
            "question": "2023年后利用hotpotqa数据集做问题生成任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "42469",
                "标题": "Few-Shot Visual Question Generation: A Novel Task and Benchmark Datasets",
                "作者": " Anurag Roy,  David Johnson Ekka,  Saptarshi Ghosh,  Abir Das",
                "发布日期": "2023-01-09",
                "摘要": "  Generating natural language questions from visual scenes, known as Visual\nQuestion Generation (VQG), has been explored in the recent past where large\namounts of meticulously labeled data provide the training corpus. However, in\npractice, it is not uncommon to have only a few images with question\nannotations corresponding to a few types of answers. In this paper, we propose\na new and challenging Few-Shot Visual Question Generation (FS-VQG) task and\nprovide a comprehensive benchmark to it. Specifically, we evaluate various\nexisting VQG approaches as well as popular few-shot solutions based on\nmeta-learning and self-supervised strategies for the FS-VQG task. We conduct\nexperiments on two popular existing datasets VQG and Visual7w. In addition, we\nhave also cleaned and extended the VQG dataset for use in a few-shot scenario,\nwith additional image-question pairs as well as additional answer categories.\nWe call this new dataset VQG-23. Several important findings emerge from our\nexperiments, that shed light on the limits of current models in few-shot vision\nand language generation tasks. We find that trivially extending existing VQG\napproaches with transfer learning or meta-learning may not be enough to tackle\nthe inherent challenges in few-shot VQG. We believe that this work will\ncontribute to accelerating the progress in few-shot learning research.\n",
                "链接": "https://arxiv.org/abs/2210.07076"
            },
            {
                "文章ID": "61747",
                "标题": "Generation of Highlights from Research Papers Using Pointer-Generator\n  Networks and SciBERT Embeddings",
                "作者": " Tohida Rehman,  Debarshi Kumar Sanyal,  Samiran Chattopadhyay,  Plaban Kumar Bhowmick,  Partha Pratim Das",
                "发布日期": "2023-09-19",
                "摘要": "  Nowadays many research articles are prefaced with research highlights to\nsummarize the main findings of the paper. Highlights not only help researchers\nprecisely and quickly identify the contributions of a paper, they also enhance\nthe discoverability of the article via search engines. We aim to automatically\nconstruct research highlights given certain segments of a research paper. We\nuse a pointer-generator network with coverage mechanism and a contextual\nembedding layer at the input that encodes the input tokens into SciBERT\nembeddings. We test our model on a benchmark dataset, CSPubSum, and also\npresent MixSub, a new multi-disciplinary corpus of papers for automatic\nresearch highlight generation. For both CSPubSum and MixSub, we have observed\nthat the proposed model achieves the best performance compared to related\nvariants and other models proposed in the literature. On the CSPubSum dataset,\nour model achieves the best performance when the input is only the abstract of\na paper as opposed to other segments of the paper. It produces ROUGE-1, ROUGE-2\nand ROUGE-L F1-scores of 38.26, 14.26 and 35.51, respectively, METEOR score of\n32.62, and BERTScore F1 of 86.65 which outperform all other baselines. On the\nnew MixSub dataset, where only the abstract is the input, our proposed model\n(when trained on the whole training corpus without distinguishing between the\nsubject categories) achieves ROUGE-1, ROUGE-2 and ROUGE-L F1-scores of 31.78,\n9.76 and 29.3, respectively, METEOR score of 24.00, and BERTScore F1 of 85.25.\n",
                "链接": "https://arxiv.org/abs/2302.07729"
            },
            {
                "文章ID": "5419",
                "标题": "ArgSciChat: A Dataset for Argumentative Dialogues on Scientific Papers",
                "作者": " Federico Ruggeri,  Mohsen Mesgar,  Iryna Gurevych",
                "发布日期": "2022-10-14",
                "摘要": "  The applications of conversational agents for scientific disciplines (as\nexpert domains) are understudied due to the lack of dialogue data to train such\nagents. While most data collection frameworks, such as Amazon Mechanical Turk,\nfoster data collection for generic domains by connecting crowd workers and task\ndesigners, these frameworks are not much optimized for data collection in\nexpert domains. Scientists are rarely present in these frameworks due to their\nlimited time budget. Therefore, we introduce a novel framework to collect\ndialogues between scientists as domain experts on scientific papers. Our\nframework lets scientists present their scientific papers as groundings for\ndialogues and participate in dialogue they like its paper title. We use our\nframework to collect a novel argumentative dialogue dataset, ArgSciChat. It\nconsists of 498 messages collected from 41 dialogues on 20 scientific papers.\nAlongside extensive analysis on ArgSciChat, we evaluate a recent conversational\nagent on our dataset. Experimental results show that this agent poorly performs\non ArgSciChat, motivating further research on argumentative scientific agents.\nWe release our framework and the dataset.\n",
                "链接": "https://arxiv.org/abs/2202.06690"
            },
            {
                "文章ID": "85260",
                "标题": "The BEA 2023 Shared Task on Generating AI Teacher Responses in\n  Educational Dialogues",
                "作者": " Anaïs Tack,  Ekaterina Kochmar,  Zheng Yuan,  Serge Bibauw,  Chris Piech",
                "发布日期": "2023-06-13",
                "摘要": "  This paper describes the results of the first shared task on the generation\nof teacher responses in educational dialogues. The goal of the task was to\nbenchmark the ability of generative language models to act as AI teachers,\nreplying to a student in a teacher-student dialogue. Eight teams participated\nin the competition hosted on CodaLab. They experimented with a wide variety of\nstate-of-the-art models, including Alpaca, Bloom, DialoGPT, DistilGPT-2,\nFlan-T5, GPT-2, GPT-3, GPT- 4, LLaMA, OPT-2.7B, and T5-base. Their submissions\nwere automatically scored using BERTScore and DialogRPT metrics, and the top\nthree among them were further manually evaluated in terms of pedagogical\nability based on Tack and Piech (2022). The NAISTeacher system, which ranked\nfirst in both automated and human evaluation, generated responses with GPT-3.5\nusing an ensemble of prompts and a DialogRPT-based ranking of responses for\ngiven dialogue contexts. Despite the promising achievements of the\nparticipating teams, the results also highlight the need for evaluation metrics\nbetter suited to educational contexts.\n",
                "链接": "https://arxiv.org/abs/2306.06941"
            },
            {
                "文章ID": "109543",
                "标题": "What is a good question? Task-oriented asking with fact-level masking",
                "作者": " Matthew Toles,  Yukun Huang,  Zhou Yu,  Luis Gravano",
                "发布日期": "2023-10-19",
                "摘要": "  Asking questions is an important element of real-life collaboration on\nreasoning tasks like question answering. For example, a legal assistant chatbot\nmay be unable to make accurate recommendations without specific information on\nthe user's circumstances. However, large language models are usually deployed\nto solve reasoning tasks directly without asking follow-up questions to the\nuser or third parties. We term this problem task-oriented asking (TOA).\nZero-shot chat models can perform TOA, but their training is primarily based on\nnext-token prediction rather than whether questions contribute to successful\ncollaboration. To enable the training and evaluation of TOA models, we present\na definition and framework for natural language task-oriented asking, the\nproblem of generating questions that result in answers useful for a reasoning\ntask. We also present fact-level masking (FLM), a procedure for converting\nnatural language datasets into self-supervised TOA datasets by omitting\nparticular critical facts. Finally, we generate a TOA dataset from the HotpotQA\ndataset using FLM and evaluate several zero-shot language models on it. Our\nexperiments show that current zero-shot models struggle to ask questions that\nretrieve useful information, as compared to human annotators. These results\ndemonstrate an opportunity to use FLM datasets and the TOA framework to train\nand evaluate better TOA models.\n",
                "链接": "https://arxiv.org/abs/2310.11571"
            },
            {
                "文章ID": "19819",
                "标题": "Modeling Multi-hop Question Answering as Single Sequence Prediction",
                "作者": " Semih Yavuz,  Kazuma Hashimoto,  Yingbo Zhou,  Nitish Shirish Keskar,  Caiming Xiong",
                "发布日期": "2022-05-20",
                "摘要": "  Fusion-in-decoder (Fid) (Izacard and Grave, 2020) is a generative question\nanswering (QA) model that leverages passage retrieval with a pre-trained\ntransformer and pushed the state of the art on single-hop QA. However, the\ncomplexity of multi-hop QA hinders the effectiveness of the generative QA\napproach. In this work, we propose a simple generative approach (PathFid) that\nextends the task beyond just answer generation by explicitly modeling the\nreasoning process to resolve the answer for multi-hop questions. By linearizing\nthe hierarchical reasoning path of supporting passages, their key sentences,\nand finally the factoid answer, we cast the problem as a single sequence\nprediction task. To facilitate complex reasoning with multiple clues, we\nfurther extend the unified flat representation of multiple input documents by\nencoding cross-passage interactions. Our extensive experiments demonstrate that\nPathFid leads to strong performance gains on two multi-hop QA datasets:\nHotpotQA and IIRC. Besides the performance gains, PathFid is more\ninterpretable, which in turn yields answers that are more faithfully grounded\nto the supporting passages and facts compared to the baseline Fid model.\n",
                "链接": "https://arxiv.org/abs/2205.09226"
            },
            {
                "文章ID": "42285",
                "标题": "Improving Question Answering with Generation of NQ-like Questions",
                "作者": " Saptarashmi Bandyopadhyay,  Shraman Pal,  Hao Zou,  Abhranil Chandra,  Jordan Boyd-Graber",
                "发布日期": "2022-10-14",
                "摘要": "  Question Answering (QA) systems require a large amount of annotated data\nwhich is costly and time-consuming to gather. Converting datasets of existing\nQA benchmarks are challenging due to different formats and complexities. To\naddress these issues, we propose an algorithm to automatically generate shorter\nquestions resembling day-to-day human communication in the Natural Questions\n(NQ) dataset from longer trivia questions in Quizbowl (QB) dataset by\nleveraging conversion in style among the datasets. This provides an automated\nway to generate more data for our QA systems. To ensure quality as well as\nquantity of data, we detect and remove ill-formed questions using a neural\nclassifier. We demonstrate that in a low resource setting, using the generated\ndata improves the QA performance over the baseline system on both NQ and QB\ndata. Our algorithm improves the scalability of training data while maintaining\nquality of data for QA systems.\n",
                "链接": "https://arxiv.org/abs/2210.06599"
            },
            {
                "文章ID": "60822",
                "标题": "Generating a Structured Summary of Numerous Academic Papers: Dataset and\n  Method",
                "作者": " Shuaiqi Liu,  Jiannong Cao,  Ruosong Yang,  Zhiyuan Wen",
                "发布日期": "2023-02-10",
                "摘要": "  Writing a survey paper on one research topic usually needs to cover the\nsalient content from numerous related papers, which can be modeled as a\nmulti-document summarization (MDS) task. Existing MDS datasets usually focus on\nproducing the structureless summary covering a few input documents. Meanwhile,\nprevious structured summary generation works focus on summarizing a single\ndocument into a multi-section summary. These existing datasets and methods\ncannot meet the requirements of summarizing numerous academic papers into a\nstructured summary. To deal with the scarcity of available data, we propose\nBigSurvey, the first large-scale dataset for generating comprehensive summaries\nof numerous academic papers on each topic. We collect target summaries from\nmore than seven thousand survey papers and utilize their 430 thousand reference\npapers' abstracts as input documents. To organize the diverse content from\ndozens of input documents and ensure the efficiency of processing long text\nsequences, we propose a summarization method named category-based alignment and\nsparse transformer (CAST). The experimental results show that our CAST method\noutperforms various advanced summarization methods.\n",
                "链接": "https://arxiv.org/abs/2302.04580"
            },
            {
                "文章ID": "59883",
                "标题": "LIQUID: A Framework for List Question Answering Dataset Generation",
                "作者": " Seongyun Lee,  Hyunjae Kim,  Jaewoo Kang",
                "发布日期": "2023-02-07",
                "摘要": "  Question answering (QA) models often rely on large-scale training datasets,\nwhich necessitates the development of a data generation framework to reduce the\ncost of manual annotations. Although several recent studies have aimed to\ngenerate synthetic questions with single-span answers, no study has been\nconducted on the creation of list questions with multiple, non-contiguous spans\nas answers. To address this gap, we propose LIQUID, an automated framework for\ngenerating list QA datasets from unlabeled corpora. We first convert a passage\nfrom Wikipedia or PubMed into a summary and extract named entities from the\nsummarized text as candidate answers. This allows us to select answers that are\nsemantically correlated in context and is, therefore, suitable for constructing\nlist questions. We then create questions using an off-the-shelf question\ngenerator with the extracted entities and original passage. Finally, iterative\nfiltering and answer expansion are performed to ensure the accuracy and\ncompleteness of the answers. Using our synthetic data, we significantly improve\nthe performance of the previous best list QA models by exact-match F1 scores of\n5.0 on MultiSpanQA, 1.9 on Quoref, and 2.8 averaged across three BioASQ\nbenchmarks.\n",
                "链接": "https://arxiv.org/abs/2302.01691"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用机器学习方法进行心理健康疾病研究的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "98633",
                "标题": "Discovering Mental Health Research Topics with Topic Modeling",
                "作者": " Xin Gao,  Cem Sazara",
                "发布日期": "2023-08-29",
                "摘要": "  Mental health significantly influences various aspects of our daily lives,\nand its importance has been increasingly recognized by the research community\nand the general public, particularly in the wake of the COVID-19 pandemic. This\nheightened interest is evident in the growing number of publications dedicated\nto mental health in the past decade. In this study, our goal is to identify\ngeneral trends in the field and pinpoint high-impact research topics by\nanalyzing a large dataset of mental health research papers. To accomplish this,\nwe collected abstracts from various databases and trained a customized\nSentence-BERT based embedding model leveraging the BERTopic framework. Our\ndataset comprises 96,676 research papers pertaining to mental health, enabling\nus to examine the relationships between different topics using their abstracts.\nTo evaluate the effectiveness of the model, we compared it against two other\nstate-of-the-art methods: Top2Vec model and LDA-BERT model. The model\ndemonstrated superior performance in metrics that measure topic diversity and\ncoherence. To enhance our analysis, we also generated word clouds to provide a\ncomprehensive overview of the machine learning models applied in mental health\nresearch, shedding light on commonly utilized techniques and emerging trends.\nFurthermore, we provide a GitHub link* to the dataset used in this paper,\nensuring its accessibility for further research endeavors.\n",
                "链接": "https://arxiv.org/abs/2308.13569"
            },
            {
                "文章ID": "113411",
                "标题": "Identifying Alzheimer Disease Dementia Levels Using Machine Learning\n  Methods",
                "作者": " Md Gulzar Hussain,  Ye Shiren",
                "发布日期": "2023-11-06",
                "摘要": "  Dementia, a prevalent neurodegenerative condition, is a major manifestation\nof Alzheimer's disease (AD). As the condition progresses from mild to severe,\nit significantly impairs the individual's ability to perform daily tasks\nindependently, necessitating the need for timely and accurate AD\nclassification. Machine learning or deep learning models have emerged as\neffective tools for this purpose. In this study, we suggested an approach for\nclassifying the four stages of dementia using RF, SVM, and CNN algorithms,\naugmented with watershed segmentation for feature extraction from MRI images.\nOur results reveal that SVM with watershed features achieves an impressive\naccuracy of 96.25%, surpassing other classification methods. The ADNI dataset\nis utilized to evaluate the effectiveness of our method, and we observed that\nthe inclusion of watershed segmentation contributes to the enhanced performance\nof the models.\n",
                "链接": "https://arxiv.org/abs/2311.01428"
            },
            {
                "文章ID": "20900",
                "标题": "Bias Discovery in Machine Learning Models for Mental Health",
                "作者": " Pablo Mosteiro,  Jesse Kuiper,  Judith Masthoff,  Floortje Scheepers,  Marco Spruit",
                "发布日期": "2022-05-25",
                "摘要": "  Fairness and bias are crucial concepts in artificial intelligence, yet they\nare relatively ignored in machine learning applications in clinical psychiatry.\nWe computed fairness metrics and present bias mitigation strategies using a\nmodel trained on clinical mental health data. We collected structured data\nrelated to the admission, diagnosis, and treatment of patients in the\npsychiatry department of the University Medical Center Utrecht. We trained a\nmachine learning model to predict future administrations of benzodiazepines on\nthe basis of past data. We found that gender plays an unexpected role in the\npredictions-this constitutes bias. Using the AI Fairness 360 package, we\nimplemented reweighing and discrimination-aware regularization as bias\nmitigation strategies, and we explored their implications for model\nperformance. This is the first application of bias exploration and mitigation\nin a machine learning model trained on real clinical psychiatry data.\n",
                "链接": "https://arxiv.org/abs/2205.12093"
            },
            {
                "文章ID": "22134",
                "标题": "Individual health-disease phase diagrams for disease prevention based on\n  machine learning",
                "作者": " Kazuki Nakamura,  Eiichiro Uchino,  Noriaki Sato,  Ayano Araki,  Kei Terayama,  Ryosuke Kojima,  Koichi Murashita,  Ken Itoh,  Tatsuya Mikami,  Yoshinori Tamada,  Yasushi Okuno",
                "发布日期": "2022-07-08",
                "摘要": "  Early disease detection and prevention methods based on effective\ninterventions are gaining attention. Machine learning technology has enabled\nprecise disease prediction by capturing individual differences in multivariate\ndata. Progress in precision medicine has revealed that substantial\nheterogeneity exists in health data at the individual level and that complex\nhealth factors are involved in the development of chronic diseases. However, it\nremains a challenge to identify individual physiological state changes in\ncross-disease onset processes because of the complex relationships among\nmultiple biomarkers. Here, we present the health-disease phase diagram (HDPD),\nwhich represents a personal health state by visualizing the boundary values of\nmultiple biomarkers that fluctuate early in the disease progression process. In\nHDPDs, future onset predictions are represented by perturbing multiple\nbiomarker values while accounting for dependencies among variables. We\nconstructed HDPDs for 11 non-communicable diseases (NCDs) from a longitudinal\nhealth checkup cohort of 3,238 individuals, comprising 3,215 measurement items\nand genetic data. Improvement of biomarker values to the non-onset region in\nHDPD significantly prevented future disease onset in 7 out of 11 NCDs. Our\nresults demonstrate that HDPDs can represent individual physiological states in\nthe onset process and be used as intervention goals for disease prevention.\n",
                "链接": "https://arxiv.org/abs/2205.15598"
            },
            {
                "文章ID": "57937",
                "标题": "Deep Learning Mental Health Dialogue System",
                "作者": " Lennart Brocki,  George C. Dyer,  Anna Gładka,  Neo Christopher Chung",
                "发布日期": "2023-01-24",
                "摘要": "  Mental health counseling remains a major challenge in modern society due to\ncost, stigma, fear, and unavailability. We posit that generative artificial\nintelligence (AI) models designed for mental health counseling could help\nimprove outcomes by lowering barriers to access. To this end, we have developed\na deep learning (DL) dialogue system called Serena. The system consists of a\ncore generative model and post-processing algorithms. The core generative model\nis a 2.7 billion parameter Seq2Seq Transformer fine-tuned on thousands of\ntranscripts of person-centered-therapy (PCT) sessions. The series of\npost-processing algorithms detects contradictions, improves coherency, and\nremoves repetitive answers. Serena is implemented and deployed on\n\\url{https://serena.chat}, which currently offers limited free services. While\nthe dialogue system is capable of responding in a qualitatively empathetic and\nengaging manner, occasionally it displays hallucination and long-term\nincoherence. Overall, we demonstrate that a deep learning mental health\ndialogue system has the potential to provide a low-cost and effective\ncomplement to traditional human counselors with less barriers to access.\n",
                "链接": "https://arxiv.org/abs/2301.09412"
            },
            {
                "文章ID": "56312",
                "标题": "Causal Categorization of Mental Health Posts using Transformers",
                "作者": " Simranjeet Kaur,  Ritika Bhardwaj,  Aastha Jain,  Muskan Garg,  Chandni Saxena",
                "发布日期": "2023-01-18",
                "摘要": "  With recent developments in digitization of clinical psychology, NLP research\ncommunity has revolutionized the field of mental health detection on social\nmedia. Existing research in mental health analysis revolves around the\ncross-sectional studies to classify users' intent on social media. For in-depth\nanalysis, we investigate existing classifiers to solve the problem of causal\ncategorization which suggests the inefficiency of learning based methods due to\nlimited training samples. To handle this challenge, we use transformer models\nand demonstrate the efficacy of a pre-trained transfer learning on \"CAMS\"\ndataset. The experimental result improves the accuracy and depicts the\nimportance of identifying cause-and-effect relationships in the underlying\ntext.\n",
                "链接": "https://arxiv.org/abs/2301.02589"
            },
            {
                "文章ID": "23569",
                "标题": "Counseling Summarization using Mental Health Knowledge Guided Utterance\n  Filtering",
                "作者": "Grin  Aseem Srivastava, Grin  Tharun Suresh, Grin  Sarah Peregrine,   Lord,  Md. Shad Akhtar,  Tanmoy Chakraborty",
                "发布日期": "2022-06-09",
                "摘要": "  The psychotherapy intervention technique is a multifaceted conversation\nbetween a therapist and a patient. Unlike general clinical discussions,\npsychotherapy's core components (viz. symptoms) are hard to distinguish, thus\nbecoming a complex problem to summarize later. A structured counseling\nconversation may contain discussions about symptoms, history of mental health\nissues, or the discovery of the patient's behavior. It may also contain\ndiscussion filler words irrelevant to a clinical summary. We refer to these\nelements of structured psychotherapy as counseling components. In this paper,\nthe aim is mental health counseling summarization to build upon domain\nknowledge and to help clinicians quickly glean meaning. We create a new dataset\nafter annotating 12.9K utterances of counseling components and reference\nsummaries for each dialogue. Further, we propose ConSum, a novel\ncounseling-component guided summarization model. ConSum undergoes three\nindependent modules. First, to assess the presence of depressive symptoms, it\nfilters utterances utilizing the Patient Health Questionnaire (PHQ-9), while\nthe second and third modules aim to classify counseling components. At last, we\npropose a problem-specific Mental Health Information Capture (MHIC) evaluation\nmetric for counseling summaries. Our comparative study shows that we improve on\nperformance and generate cohesive, semantic, and coherent summaries. We\ncomprehensively analyze the generated summaries to investigate the capturing of\npsychotherapy elements. Human and clinical evaluations on the summary show that\nConSum generates quality summary. Further, mental health experts validate the\nclinical acceptability of the ConSum. Lastly, we discuss the uniqueness in\nmental health counseling summarization in the real world and show evidences of\nits deployment on an online application with the support of mpathic.ai\n",
                "链接": "https://arxiv.org/abs/2206.03886"
            },
            {
                "文章ID": "21978",
                "标题": "Machine Learning Methods for Health-Index Prediction in Coating Chambers",
                "作者": " Clemens Heistracher,  Anahid Jalali,  Jürgen Schneeweiss,  Klaudia Kovacs,  Catherine Laflamme,  Bernhard Haslhofer",
                "发布日期": "2022-05-31",
                "摘要": "  Coating chambers create thin layers that improve the mechanical and optical\nsurface properties in jewelry production using physical vapor deposition. In\nsuch a process, evaporated material condensates on the walls of such chambers\nand, over time, causes mechanical defects and unstable processes. As a result,\nmanufacturers perform extensive maintenance procedures to reduce production\nloss. Current rule-based maintenance strategies neglect the impact of specific\nrecipes and the actual condition of the vacuum chamber. Our overall goal is to\npredict the future condition of the coating chamber to allow cost and quality\noptimized maintenance of the equipment. This paper describes the derivation of\na novel health indicator that serves as a step toward condition-based\nmaintenance for coating chambers. We indirectly use gas emissions of the\nchamber's contamination to evaluate the machine's condition. Our approach\nrelies on process data and does not require additional hardware installation.\nFurther, we evaluated multiple machine learning algorithms for a\ncondition-based forecast of the health indicator that also reflects production\nplanning. Our results show that models based on decision trees are the most\neffective and outperform all three benchmarks, improving at least $0.22$ in the\nmean average error. Our work paves the way for cost and quality optimized\nmaintenance of coating applications.\n",
                "链接": "https://arxiv.org/abs/2205.15145"
            },
            {
                "文章ID": "116401",
                "标题": "Dates Fruit Disease Recognition using Machine Learning",
                "作者": " Ghassen Ben Brahim,  Jaafar Alghazo,  Ghazanfar Latif,  Khalid Alnujaidi",
                "发布日期": "2023-11-20",
                "摘要": "  Many countries such as Saudi Arabia, Morocco and Tunisia are among the top\nexporters and consumers of palm date fruits. Date fruit production plays a\nmajor role in the economies of the date fruit exporting countries. Date fruits\nare susceptible to disease just like any fruit and early detection and\nintervention can end up saving the produce. However, with the vast farming\nlands, it is nearly impossible for farmers to observe date trees on a frequent\nbasis for early disease detection. In addition, even with human observation the\nprocess is prone to human error and increases the date fruit cost. With the\nrecent advances in computer vision, machine learning, drone technology, and\nother technologies; an integrated solution can be proposed for the automatic\ndetection of date fruit disease. In this paper, a hybrid features based method\nwith the standard classifiers is proposed based on the extraction of L*a*b\ncolor features, statistical features, and Discrete Wavelet Transform (DWT)\ntexture features for the early detection and classification of date fruit\ndisease. A dataset was developed for this work consisting of 871 images divided\ninto the following classes; Healthy date, Initial stage of disease,\nMalnourished date, and Parasite infected. The extracted features were input to\ncommon classifiers such as the Random Forest (RF), Multilayer Perceptron (MLP),\nNa\\\"ive Bayes (NB), and Fuzzy Decision Trees (FDT). The highest average\naccuracy was achieved when combining the L*a*b, Statistical, and DWT Features.\n",
                "链接": "https://arxiv.org/abs/2311.10365"
            },
            {
                "文章ID": "32474",
                "标题": "Bias Reducing Multitask Learning on Mental Health Prediction",
                "作者": " Khadija Zanna,  Kusha Sridhar,  Han Yu,  Akane Sano",
                "发布日期": "2022-08-09",
                "摘要": "  There has been an increase in research in developing machine learning models\nfor mental health detection or prediction in recent years due to increased\nmental health issues in society. Effective use of mental health prediction or\ndetection models can help mental health practitioners re-define mental\nillnesses more objectively than currently done, and identify illnesses at an\nearlier stage when interventions may be more effective. However, there is still\na lack of standard in evaluating bias in such machine learning models in the\nfield, which leads to challenges in providing reliable predictions and in\naddressing disparities. This lack of standards persists due to factors such as\ntechnical difficulties, complexities of high dimensional clinical health data,\netc., which are especially true for physiological signals. This along with\nprior evidence of relations between some physiological signals with certain\ndemographic identities restates the importance of exploring bias in mental\nhealth prediction models that utilize physiological signals. In this work, we\naim to perform a fairness analysis and implement a multi-task learning based\nbias mitigation method on anxiety prediction models using ECG data. Our method\nis based on the idea of epistemic uncertainty and its relationship with model\nweights and feature space representation. Our analysis showed that our anxiety\nprediction base model introduced some bias with regards to age, income,\nethnicity, and whether a participant is born in the U.S. or not, and our bias\nmitigation method performed better at reducing the bias in the model, when\ncompared to the reweighting mitigation technique. Our analysis on feature\nimportance also helped identify relationships between heart rate variability\nand multiple demographic groupings.\n",
                "链接": "https://arxiv.org/abs/2208.03621"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "69437",
                "标题": "Medical Image Analysis using Deep Relational Learning",
                "作者": " Zhihua Liu",
                "发布日期": "2023-03-29",
                "摘要": "  In the past ten years, with the help of deep learning, especially the rapid\ndevelopment of deep neural networks, medical image analysis has made remarkable\nprogress. However, how to effectively use the relational information between\nvarious tissues or organs in medical images is still a very challenging\nproblem, and it has not been fully studied. In this thesis, we propose two\nnovel solutions to this problem based on deep relational learning. First, we\npropose a context-aware fully convolutional network that effectively models\nimplicit relation information between features to perform medical image\nsegmentation. The network achieves the state-of-the-art segmentation results on\nthe Multi Modal Brain Tumor Segmentation 2017 (BraTS2017) and Multi Modal Brain\nTumor Segmentation 2018 (BraTS2018) data sets. Subsequently, we propose a new\nhierarchical homography estimation network to achieve accurate medical image\nmosaicing by learning the explicit spatial relationship between adjacent\nframes. We use the UCL Fetoscopy Placenta dataset to conduct experiments and\nour hierarchical homography estimation network outperforms the other\nstate-of-the-art mosaicing methods while generating robust and meaningful\nmosaicing result on unseen frames.\n",
                "链接": "https://arxiv.org/abs/2303.16099"
            },
            {
                "文章ID": "107726",
                "标题": "Data efficient deep learning for medical image analysis: A survey",
                "作者": " Suruchi Kumari,  Pravendra Singh",
                "发布日期": "2023-10-11",
                "摘要": "  The rapid evolution of deep learning has significantly advanced the field of\nmedical image analysis. However, despite these achievements, the further\nenhancement of deep learning models for medical image analysis faces a\nsignificant challenge due to the scarcity of large, well-annotated datasets. To\naddress this issue, recent years have witnessed a growing emphasis on the\ndevelopment of data-efficient deep learning methods. This paper conducts a\nthorough review of data-efficient deep learning methods for medical image\nanalysis. To this end, we categorize these methods based on the level of\nsupervision they rely on, encompassing categories such as no supervision,\ninexact supervision, incomplete supervision, inaccurate supervision, and only\nlimited supervision. We further divide these categories into finer\nsubcategories. For example, we categorize inexact supervision into multiple\ninstance learning and learning with weak annotations. Similarly, we categorize\nincomplete supervision into semi-supervised learning, active learning, and\ndomain-adaptive learning and so on. Furthermore, we systematically summarize\ncommonly used datasets for data efficient deep learning in medical image\nanalysis and investigate future research directions to conclude this survey.\n",
                "链接": "https://arxiv.org/abs/2310.06557"
            },
            {
                "文章ID": "110503",
                "标题": "A comprehensive survey on deep active learning and its applications in\n  medical image analysis",
                "作者": " Haoran Wang,  Qiuye Jin,  Shiman Li,  Siyu Liu,  Manning Wang,  Zhijian Song",
                "发布日期": "2023-10-25",
                "摘要": "  Deep learning has achieved widespread success in medical image analysis,\nleading to an increasing demand for large-scale expert-annotated medical image\ndatasets. Yet, the high cost of annotating medical images severely hampers the\ndevelopment of deep learning in this field. To reduce annotation costs, active\nlearning aims to select the most informative samples for annotation and train\nhigh-performance models with as few labeled samples as possible. In this\nsurvey, we review the core methods of active learning, including the evaluation\nof informativeness and sampling strategy. For the first time, we provide a\ndetailed summary of the integration of active learning with other\nlabel-efficient techniques, such as semi-supervised, self-supervised learning,\nand so on. Additionally, we also highlight active learning works that are\nspecifically tailored to medical image analysis. In the end, we offer our\nperspectives on the future trends and challenges of active learning and its\napplications in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2310.14230"
            },
            {
                "文章ID": "90244",
                "标题": "Invariant Scattering Transform for Medical Imaging",
                "作者": " Nafisa Labiba Ishrat Huda,  Angona Biswas,  MD Abdullah Al Nasim,  Md. Fahim Rahman,  Shoaib Ahmed",
                "发布日期": "2023-07-12",
                "摘要": "  Invariant scattering transform introduces new area of research that merges\nthe signal processing with deep learning for computer vision. Nowadays, Deep\nLearning algorithms are able to solve a variety of problems in medical sector.\nMedical images are used to detect diseases brain cancer or tumor, Alzheimer's\ndisease, breast cancer, Parkinson's disease and many others. During pandemic\nback in 2020, machine learning and deep learning has played a critical role to\ndetect COVID-19 which included mutation analysis, prediction, diagnosis and\ndecision making. Medical images like X-ray, MRI known as magnetic resonance\nimaging, CT scans are used for detecting diseases. There is another method in\ndeep learning for medical imaging which is scattering transform. It builds\nuseful signal representation for image classification. It is a wavelet\ntechnique; which is impactful for medical image classification problems. This\nresearch article discusses scattering transform as the efficient system for\nmedical image analysis where it's figured by scattering the signal information\nimplemented in a deep convolutional network. A step by step case study is\nmanifested at this research work.\n",
                "链接": "https://arxiv.org/abs/2307.04771"
            },
            {
                "文章ID": "68755",
                "标题": "Adversarial Attack and Defense for Medical Image Analysis: Methods and\n  Applications",
                "作者": " Junhao Dong,  Junxi Chen,  Xiaohua Xie,  Jianhuang Lai,  Hao Chen",
                "发布日期": "2023-03-27",
                "摘要": "  Deep learning techniques have achieved superior performance in computer-aided\nmedical image analysis, yet they are still vulnerable to imperceptible\nadversarial attacks, resulting in potential misdiagnosis in clinical practice.\nOppositely, recent years have also witnessed remarkable progress in defense\nagainst these tailored adversarial examples in deep medical diagnosis systems.\nIn this exposition, we present a comprehensive survey on recent advances in\nadversarial attack and defense for medical image analysis with a novel taxonomy\nin terms of the application scenario. We also provide a unified theoretical\nframework for different types of adversarial attack and defense methods for\nmedical image analysis. For a fair comparison, we establish a new benchmark for\nadversarially robust medical diagnosis models obtained by adversarial training\nunder various scenarios. To the best of our knowledge, this is the first survey\npaper that provides a thorough evaluation of adversarially robust medical\ndiagnosis models. By analyzing qualitative and quantitative results, we\nconclude this survey with a detailed discussion of current challenges for\nadversarial attack and defense in medical image analysis systems to shed light\non future research directions.\n",
                "链接": "https://arxiv.org/abs/2303.14133"
            },
            {
                "文章ID": "52332",
                "标题": "A Trustworthy Framework for Medical Image Analysis with Deep Learning",
                "作者": " Kai Ma,  Siyuan He,  Pengcheng Xi,  Ashkan Ebadi,  Stéphane Tremblay,  Alexander Wong",
                "发布日期": "2022-12-07",
                "摘要": "  Computer vision and machine learning are playing an increasingly important\nrole in computer-assisted diagnosis; however, the application of deep learning\nto medical imaging has challenges in data availability and data imbalance, and\nit is especially important that models for medical imaging are built to be\ntrustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning\nframework for medical image analysis, which adopts a modular design, leverages\nself-supervised pre-training, and utilizes a novel surrogate loss function.\nExperimental evaluations indicate that models generated from the framework are\nboth trustworthy and high-performing. It is anticipated that the framework will\nsupport researchers and clinicians in advancing the use of deep learning for\ndealing with public health crises including COVID-19.\n",
                "链接": "https://arxiv.org/abs/2212.02764"
            },
            {
                "文章ID": "92854",
                "标题": "Deep Learning Approaches for Data Augmentation in Medical Imaging: A\n  Review",
                "作者": " Aghiles Kebaili,  Jérôme Lapuyade-Lahorgue,  Su Ruan",
                "发布日期": "2023-07-26",
                "摘要": "  Deep learning has become a popular tool for medical image analysis, but the\nlimited availability of training data remains a major challenge, particularly\nin the medical field where data acquisition can be costly and subject to\nprivacy regulations. Data augmentation techniques offer a solution by\nartificially increasing the number of training samples, but these techniques\noften produce limited and unconvincing results. To address this issue, a\ngrowing number of studies have proposed the use of deep generative models to\ngenerate more realistic and diverse data that conform to the true distribution\nof the data. In this review, we focus on three types of deep generative models\nfor medical image augmentation: variational autoencoders, generative\nadversarial networks, and diffusion models. We provide an overview of the\ncurrent state of the art in each of these models and discuss their potential\nfor use in different downstream tasks in medical imaging, including\nclassification, segmentation, and cross-modal translation. We also evaluate the\nstrengths and limitations of each model and suggest directions for future\nresearch in this field. Our goal is to provide a comprehensive review about the\nuse of deep generative models for medical image augmentation and to highlight\nthe potential of these models for improving the performance of deep learning\nalgorithms in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2307.13125"
            },
            {
                "文章ID": "4940",
                "标题": "Deep Learning for Computational Cytology: A Survey",
                "作者": " Hao Jiang,  Yanning Zhou,  Yi Lin,  Ronald CK Chan,  Jiang Liu,  Hao Chen",
                "发布日期": "2023-03-21",
                "摘要": "  Computational cytology is a critical, rapid-developing, yet challenging topic\nin the field of medical image computing which analyzes the digitized cytology\nimage by computer-aided technologies for cancer screening. Recently, an\nincreasing number of deep learning (DL) algorithms have made significant\nprogress in medical image analysis, leading to the boosting publications of\ncytological studies. To investigate the advanced methods and comprehensive\napplications, we survey more than 120 publications of DL-based cytology image\nanalysis in this article. We first introduce various deep learning methods,\nincluding fully supervised, weakly supervised, unsupervised, and transfer\nlearning. Then, we systematically summarize the public datasets, evaluation\nmetrics, versatile cytology image analysis applications including\nclassification, detection, segmentation, and other related tasks. Finally, we\ndiscuss current challenges and potential research directions of computational\ncytology.\n",
                "链接": "https://arxiv.org/abs/2202.05126"
            },
            {
                "文章ID": "100761",
                "标题": "SAM3D: Segment Anything Model in Volumetric Medical Images",
                "作者": " Nhat-Tan Bui,  Dinh-Hieu Hoang,  Minh-Triet Tran,  Gianfranco Doretto,  Donald Adjeroh,  Brijesh Patel,  Arabinda Choudhary,  Ngan Le",
                "发布日期": "2023-11-27",
                "摘要": "  Image segmentation remains a pivotal component in medical image analysis,\naiding in the extraction of critical information for precise diagnostic\npractices. With the advent of deep learning, automated image segmentation\nmethods have risen to prominence, showcasing exceptional proficiency in\nprocessing medical imagery. Motivated by the Segment Anything Model (SAM)-a\nfoundational model renowned for its remarkable precision and robust\ngeneralization capabilities in segmenting 2D natural images-we introduce SAM3D,\nan innovative adaptation tailored for 3D volumetric medical image analysis.\nUnlike current SAM-based methods that segment volumetric data by converting the\nvolume into separate 2D slices for individual analysis, our SAM3D model\nprocesses the entire 3D volume image in a unified approach. Extensive\nexperiments are conducted on multiple medical image datasets to demonstrate\nthat our network attains competitive results compared with other\nstate-of-the-art methods in 3D medical segmentation tasks while being\nsignificantly efficient in terms of parameters. Code and checkpoints are\navailable at https://github.com/UARK-AICV/SAM3D.\n",
                "链接": "https://arxiv.org/abs/2309.03493"
            },
            {
                "文章ID": "20042",
                "标题": "Generation of Artificial CT Images using Patch-based Conditional\n  Generative Adversarial Networks",
                "作者": " Marija Habijan,  Irena Galic",
                "发布日期": "2022-05-23",
                "摘要": "  Deep learning has a great potential to alleviate diagnosis and prognosis for\nvarious clinical procedures. However, the lack of a sufficient number of\nmedical images is the most common obstacle in conducting image-based analysis\nusing deep learning. Due to the annotations scarcity, semi-supervised\ntechniques in the automatic medical analysis are getting high attention.\nArtificial data augmentation and generation techniques such as generative\nadversarial networks (GANs) may help overcome this obstacle. In this work, we\npresent an image generation approach that uses generative adversarial networks\nwith a conditional discriminator where segmentation masks are used as\nconditions for image generation. We validate the feasibility of GAN-enhanced\nmedical image generation on whole heart computed tomography (CT) images and its\nseven substructures, namely: left ventricle, right ventricle, left atrium,\nright atrium, myocardium, pulmonary arteries, and aorta. Obtained results\ndemonstrate the suitability of the proposed adversarial approach for the\naccurate generation of high-quality CT images. The presented method shows great\npotential to facilitate further research in the domain of artificial medical\nimage generation.\n",
                "链接": "https://arxiv.org/abs/2205.09842"
            }
        ]
    },
    {
        "question": {
            "question": "查找基于优化实现模型越狱的文献",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "71794",
                "标题": "Multi-step Jailbreaking Privacy Attacks on ChatGPT",
                "作者": " Haoran Li,  Dadi Guo,  Wei Fan,  Mingshi Xu,  Jie Huang,  Fanpu Meng,  Yangqiu Song",
                "发布日期": "2023-11-02",
                "摘要": "  With the rapid progress of large language models (LLMs), many downstream NLP\ntasks can be well solved given appropriate prompts. Though model developers and\nresearchers work hard on dialog safety to avoid generating harmful content from\nLLMs, it is still challenging to steer AI-generated content (AIGC) for the\nhuman good. As powerful LLMs are devouring existing text data from various\ndomains (e.g., GPT-3 is trained on 45TB texts), it is natural to doubt whether\nthe private information is included in the training data and what privacy\nthreats can these LLMs and their downstream applications bring. In this paper,\nwe study the privacy threats from OpenAI's ChatGPT and the New Bing enhanced by\nChatGPT and show that application-integrated LLMs may cause new privacy\nthreats. To this end, we conduct extensive experiments to support our claims\nand discuss LLMs' privacy implications.\n",
                "链接": "https://arxiv.org/abs/2304.05197"
            },
            {
                "文章ID": "27272",
                "标题": "Literature on Hand GESTURE Recognition using Graph based methods",
                "作者": " Neha Baranwal,  Varun Sharma",
                "发布日期": "2022-07-04",
                "摘要": "  Skeleton based recognition systems are gaining popularity and machine\nlearning models focusing on points or joints in a skeleton have proved to be\ncomputationally effective and application in many areas like Robotics. It is\neasy to track points and thereby preserving spatial and temporal information,\nwhich plays an important role in abstracting the required information,\nclassification becomes an easy task. In this paper, we aim to study these\npoints but using a cloud mechanism, where we define a cloud as collection of\npoints. However, when we add temporal information, it may not be possible to\nretrieve the coordinates of a point in each frame and hence instead of focusing\non a single point, we can use k-neighbors to retrieve the state of the point\nunder discussion. Our focus is to gather such information using weight sharing\nbut making sure that when we try to retrieve the information from neighbors, we\ndo not carry noise with it. LSTM which has capability of long-term modelling\nand can carry both temporal and spatial information. In this article we tried\nto summarise graph based gesture recognition method.\n",
                "链接": "https://arxiv.org/abs/2207.00329"
            },
            {
                "文章ID": "80421",
                "标题": "Collaborative Recommendation Model Based on Multi-modal Multi-view\n  Attention Network: Movie and literature cases",
                "作者": " Zheng Hu,  Shi-Min Cai,  Jun Wang,  Tao Zhou",
                "发布日期": "2023-05-25",
                "摘要": "  The existing collaborative recommendation models that use multi-modal\ninformation emphasize the representation of users' preferences but easily\nignore the representation of users' dislikes. Nevertheless, modelling users'\ndislikes facilitates comprehensively characterizing user profiles. Thus, the\nrepresentation of users' dislikes should be integrated into the user modelling\nwhen we construct a collaborative recommendation model. In this paper, we\npropose a novel Collaborative Recommendation Model based on Multi-modal\nmulti-view Attention Network (CRMMAN), in which the users are represented from\nboth preference and dislike views. Specifically, the users' historical\ninteractions are divided into positive and negative interactions, used to model\nthe user's preference and dislike views, respectively. Furthermore, the\nsemantic and structural information extracted from the scene is employed to\nenrich the item representation. We validate CRMMAN by designing contrast\nexperiments based on two benchmark MovieLens-1M and Book-Crossing datasets.\nMovielens-1m has about a million ratings, and Book-Crossing has about 300,000\nratings. Compared with the state-of-the-art knowledge-graph-based and\nmulti-modal recommendation methods, the AUC, NDCG@5 and NDCG@10 are improved by\n2.08%, 2.20% and 2.26% on average of two datasets. We also conduct controlled\nexperiments to explore the effects of multi-modal information and multi-view\nmechanism. The experimental results show that both of them enhance the model's\nperformance.\n",
                "链接": "https://arxiv.org/abs/2305.15159"
            },
            {
                "文章ID": "6524",
                "标题": "On Uncertainty Estimation by Tree-based Surrogate Models in Sequential\n  Model-based Optimization",
                "作者": " Jungtaek Kim,  Seungjin Choi",
                "发布日期": "2022-02-23",
                "摘要": "  Sequential model-based optimization sequentially selects a candidate point by\nconstructing a surrogate model with the history of evaluations, to solve a\nblack-box optimization problem. Gaussian process (GP) regression is a popular\nchoice as a surrogate model, because of its capability of calculating\nprediction uncertainty analytically. On the other hand, an ensemble of\nrandomized trees is another option and has practical merits over GPs due to its\nscalability and easiness of handling continuous/discrete mixed variables. In\nthis paper we revisit various ensembles of randomized trees to investigate\ntheir behavior in the perspective of prediction uncertainty estimation. Then,\nwe propose a new way of constructing an ensemble of randomized trees, referred\nto as BwO forest, where bagging with oversampling is employed to construct\nbootstrapped samples that are used to build randomized trees with random\nsplitting. Experimental results demonstrate the validity and good performance\nof BwO forest over existing tree-based models in various circumstances.\n",
                "链接": "https://arxiv.org/abs/2202.10669"
            },
            {
                "文章ID": "64933",
                "标题": "A Provably Secure Strong PUF based on LWE: Construction and\n  Implementation",
                "作者": " Xiaodan Xi,  Ge Li,  Ye Wang,  Yeonsoo Jeon,  Michael Orshansky",
                "发布日期": "2023-03-07",
                "摘要": "  We construct a strong PUF with provable security against ML attacks on both\nclassical and quantum computers. The security is guaranteed by the\ncryptographic hardness of learning decryption functions of public-key\ncryptosystems, and the hardness of the learning-with-errors (LWE) problem\ndefined on integer lattices. We call our construction the lattice PUF.\n  We construct lattice PUF with a physically obfuscated key and an LWE\ndecryption function block. To allow deployments in different scenarios, we\ndemonstrate designs with different latency-area trade-offs. A compact design\nuses a highly serialized LFSR and LWE decryption function, while a\nlatency-optimized design uses an unrolled LFSR and a parallel datapath.\n  We prototype lattice PUF designs with $2^{136}$ challenge-response pairs\n(CRPs) on a Spartan 6 FPGA. In addition to theoretical security guarantee, we\nevaluate empirical resistance to the various leading ML techniques: the\nprediction error remains above $49.76\\%$ after $1$ million training CRPs. The\nresource-efficient design requires only $45$ slices for the PUF logic proper,\nand $351$ slices for a fuzzy extractor. The latency-optimized design achieves a\n$148X$ reduction in latency, at a $10X$ increase in PUF hardware utilization.\nThe mean uniformity of PUF responses is $49.98\\%$, the mean uniqueness is\n$50.00\\%$, and the mean reliability is $1.26\\%$.\n",
                "链接": "https://arxiv.org/abs/2303.02802"
            },
            {
                "文章ID": "17996",
                "标题": "Model-Based Deep Learning: On the Intersection of Deep Learning and\n  Optimization",
                "作者": " Nir Shlezinger,  Yonina C. Eldar,  Stephen P. Boyd",
                "发布日期": "2022-06-23",
                "摘要": "  Decision making algorithms are used in a multitude of different applications.\nConventional approaches for designing decision algorithms employ principled and\nsimplified modelling, based on which one can determine decisions via tractable\noptimization. More recently, deep learning approaches that use highly\nparametric architectures tuned from data without relying on mathematical\nmodels, are becoming increasingly popular. Model-based optimization and\ndata-centric deep learning are often considered to be distinct disciplines.\nHere, we characterize them as edges of a continuous spectrum varying in\nspecificity and parameterization, and provide a tutorial-style presentation to\nthe methodologies lying in the middle ground of this spectrum, referred to as\nmodel-based deep learning. We accompany our presentation with running examples\nin super-resolution and stochastic control, and show how they are expressed\nusing the provided characterization and specialized in each of the detailed\nmethodologies. The gains of combining model-based optimization and deep\nlearning are demonstrated using experimental results in various applications,\nranging from biomedical imaging to digital communications.\n",
                "链接": "https://arxiv.org/abs/2205.02640"
            },
            {
                "文章ID": "46671",
                "标题": "Implementation of the Digital QS-SVM-based Beamformer on an FPGA\n  Platform",
                "作者": " Somayeh Komeylian,  Christopher Paolini",
                "发布日期": "2022-11-04",
                "摘要": "  To address practical challenges in establishing and maintaining robust\nwireless connectivity such as multi-path effects, low latency, size reduction,\nand high data rate, the digital beamformer is performed by the hybrid antenna\narray at the frequency of operation of 10 GHz. The proposed digital beamformer,\nas a spatial filter, is capable of performing Direction of Arrival (DOA)\nestimation and beamforming. The most well-established machine learning\ntechnique of support vector machine (SVM) for the DoA estimation is limited to\nproblems with linearly-separable datasets.\n  To overcome the aforementioned constraint, in the proposed beamformer, the\nQS-SVM classifier with a small regularizer has been used for the DoA estimation\nin addition to the two beamforming techniques of LCMV and MVDR. The\nQS-SVM-based beamformer has been deployed in an FPGA board, as demonstrated in\ndetail in this work. The implementation results have verified the strong\nperformance of the QS-SVM-based beamformer in suppressing undesired signals,\ndeep nulls with powers less than -10 dB in undesired signals, and transferring\ndesired signals. Furthermore, we have demonstrated that the performance of the\nQS-SVM-based beamformer consists of other advantages of average latency time in\nthe order of milliseconds, performance efficiency of more than 90\\%, and\nthroughput of about 100\\%.\n",
                "链接": "https://arxiv.org/abs/2211.01763"
            },
            {
                "文章ID": "9248",
                "标题": "Particle Swarm Optimization based on Novelty Search",
                "作者": " Mr. Rajesh Misra,  Dr. Kumar S Ray",
                "发布日期": "2023-11-07",
                "摘要": "  In this paper we propose a Particle Swarm Optimization algorithm combined\nwith Novelty Search. Novelty Search finds novel place to search in the search\ndomain and then Particle Swarm Optimization rigorously searches that area for\nglobal optimum solution. This method is never blocked in local optima because\nit is controlled by Novelty Search which is objective free. For those functions\nwhere there are many more local optima and second global optimum is far from\ntrue optimum, the present method works successfully. The present algorithm\nnever stops until it searches entire search area. A series of experimental\ntrials prove the robustness and effectiveness of the present algorithm on\ncomplex optimization test functions.\n",
                "链接": "https://arxiv.org/abs/2203.05674"
            },
            {
                "文章ID": "15507",
                "标题": "LitMC-BERT: transformer-based multi-label classification of biomedical\n  literature with an application on COVID-19 literature curation",
                "作者": " Qingyu Chen,  Jingcheng Du,  Alexis Allot,  Zhiyong Lu",
                "发布日期": "2022-04-20",
                "摘要": "  The rapid growth of biomedical literature poses a significant challenge for\ncuration and interpretation. This has become more evident during the COVID-19\npandemic. LitCovid, a literature database of COVID-19 related papers in PubMed,\nhas accumulated over 180,000 articles with millions of accesses. Approximately\n10,000 new articles are added to LitCovid every month. A main curation task in\nLitCovid is topic annotation where an article is assigned with up to eight\ntopics, e.g., Treatment and Diagnosis. The annotated topics have been widely\nused both in LitCovid (e.g., accounting for ~18% of total uses) and downstream\nstudies such as network generation. However, it has been a primary curation\nbottleneck due to the nature of the task and the rapid literature growth. This\nstudy proposes LITMC-BERT, a transformer-based multi-label classification\nmethod in biomedical literature. It uses a shared transformer backbone for all\nthe labels while also captures label-specific features and the correlations\nbetween label pairs. We compare LITMC-BERT with three baseline models on two\ndatasets. Its micro-F1 and instance-based F1 are 5% and 4% higher than the\ncurrent best results, respectively, and only requires ~18% of the inference\ntime than the Binary BERT baseline. The related datasets and models are\navailable via https://github.com/ncbi/ml-transformer.\n",
                "链接": "https://arxiv.org/abs/2204.08649"
            },
            {
                "文章ID": "57354",
                "标题": "An Energy-Efficient Reconfigurable Autoencoder Implementation on FPGA",
                "作者": " Murat Isik,  Matthew Oldland,  Lifeng Zhou",
                "发布日期": "2023-01-18",
                "摘要": "  Autoencoders are unsupervised neural networks that are used to process and\ncompress input data and then reconstruct the data back to the original data\nsize. This allows autoencoders to be used for different processing applications\nsuch as data compression, image classification, image noise reduction, and\nimage coloring. Hardware-wise, re-configurable architectures like Field\nProgrammable Gate Arrays (FPGAs) have been used for accelerating computations\nfrom several domains because of their unique combination of flexibility,\nperformance, and power efficiency. In this paper, we look at the different\nautoencoders available and use the convolutional autoencoder in both FPGA and\nGPU-based implementations to process noisy static MNIST images. We compare the\ndifferent results achieved with the FPGA and GPU-based implementations and then\ndiscuss the pros and cons of each implementation. The evaluation of the\nproposed design achieved 80%accuracy and our experimental results show that the\nproposed accelerator achieves a throughput of 21.12 Giga-Operations Per Second\n(GOP/s) with a 5.93 W on-chip power consumption at 100 MHz. The comparison\nresults with off-the-shelf devices and recent state-of-the-art implementations\nillustrate that the proposed accelerator has obvious advantages in terms of\nenergy efficiency and design flexibility. We also discuss future work that can\nbe done with the use of our proposed accelerator.\n",
                "链接": "https://arxiv.org/abs/2301.07050"
            }
        ]
    },
    {
        "question": {
            "question": "强化学习在大语言模型领域中应用的相关论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "79369",
                "标题": "Decomposed Prompting for Machine Translation Between Related Languages\n  using Large Language Models",
                "作者": " Ratish Puduppully,  Anoop Kunchukuttan,  Raj Dabre,  Ai Ti Aw,  Nancy F. Chen",
                "发布日期": "2023-10-24",
                "摘要": "  This study investigates machine translation between related languages i.e.,\nlanguages within the same family that share linguistic characteristics such as\nword order and lexical similarity. Machine translation through few-shot\nprompting leverages a small set of translation pair examples to generate\ntranslations for test sentences. This procedure requires the model to learn how\nto generate translations while simultaneously ensuring that token ordering is\nmaintained to produce a fluent and accurate translation. We propose that for\nrelated languages, the task of machine translation can be simplified by\nleveraging the monotonic alignment characteristic of such languages. We\nintroduce DecoMT, a novel approach of few-shot prompting that decomposes the\ntranslation process into a sequence of word chunk translations. Through\nautomatic and human evaluation conducted on multiple related language pairs\nacross various language families, we demonstrate that our proposed approach of\ndecomposed prompting surpasses multiple established few-shot baseline\napproaches. For example, DecoMT outperforms the strong few-shot prompting BLOOM\nmodel with an average improvement of 8 chrF++ scores across the examined\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2305.13085"
            },
            {
                "文章ID": "81272",
                "标题": "Large Language Models as Tool Makers",
                "作者": " Tianle Cai,  Xuezhi Wang,  Tengyu Ma,  Xinyun Chen,  Denny Zhou",
                "发布日期": "2023-05-29",
                "摘要": "  Recent research shows the potential of enhancing the problem-solving ability\nof large language models (LLMs) through the use of external tools. However,\nprior work along this line depends on the availability of existing tools. In\nthis work, we take an initial step towards removing this dependency by\nproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),\nwhere LLMs create their own reusable tools for problem-solving. Our approach\nconsists of two key phases: 1) tool making: an LLM acts as the tool maker that\ncrafts tools for given tasks, where a tool is implemented as a Python utility\nfunction. 2) tool using: an LLM acts as the tool user, which applies the tool\nbuilt by the tool maker for problem-solving. The tool user can be either the\nsame or a different LLM from the tool maker. Tool-making enables an LLM to\ncontinually generate tools that can be applied to different requests so that\nfuture requests can call the corresponding APIs when beneficial for solving the\ntasks. Furthermore, the division of labor among LLMs for tool-making and\ntool-using phases introduces the opportunity to achieve cost effectiveness\nwithout degrading the quality of generated tools and problem solutions. For\nexample, recognizing that tool-making demands more sophisticated capabilities\nthan tool-using, we can apply a powerful yet resource-intensive model as the\ntool maker, and a lightweight while cost-effective model as the tool user. We\nvalidate the effectiveness of our approach across a variety of complex\nreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and\nGPT-3.5 as the tool user, LATM can achieve performance that is on par with\nusing GPT-4 for both tool making and tool using, while the inference cost is\nsignificantly reduced.\n",
                "链接": "https://arxiv.org/abs/2305.17126"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            },
            {
                "文章ID": "81151",
                "标题": "Playing repeated games with Large Language Models",
                "作者": " Elif Akata,  Lion Schulz,  Julian Coda-Forno,  Seong Joon Oh,  Matthias Bethge,  Eric Schulz",
                "发布日期": "2023-05-29",
                "摘要": "  Large Language Models (LLMs) are transforming society and permeating into\ndiverse applications. As a result, LLMs will frequently interact with us and\nother agents. It is, therefore, of great societal value to understand how LLMs\nbehave in interactive social settings. Here, we propose to use behavioral game\ntheory to study LLM's cooperation and coordination behavior. To do so, we let\ndifferent LLMs (GPT-3, GPT-3.5, and GPT-4) play finitely repeated games with\neach other and with other, human-like strategies. Our results show that LLMs\ngenerally perform well in such tasks and also uncover persistent behavioral\nsignatures. In a large set of two players-two strategies games, we find that\nLLMs are particularly good at games where valuing their own self-interest pays\noff, like the iterated Prisoner's Dilemma family. However, they behave\nsub-optimally in games that require coordination. We, therefore, further focus\non two games from these distinct families. In the canonical iterated Prisoner's\nDilemma, we find that GPT-4 acts particularly unforgivingly, always defecting\nafter another agent has defected only once. In the Battle of the Sexes, we find\nthat GPT-4 cannot match the behavior of the simple convention to alternate\nbetween options. We verify that these behavioral signatures are stable across\nrobustness checks. Finally, we show how GPT-4's behavior can be modified by\nproviding further information about the other player as well as by asking it to\npredict the other player's actions before making a choice. These results enrich\nour understanding of LLM's social behavior and pave the way for a behavioral\ngame theory for machines.\n",
                "链接": "https://arxiv.org/abs/2305.16867"
            },
            {
                "文章ID": "90826",
                "标题": "Negated Complementary Commonsense using Large Language Models",
                "作者": " Navid Rezaei,  Marek Z. Reformat",
                "发布日期": "2023-07-14",
                "摘要": "  Larger language models, such as GPT-3, have shown to be excellent in many\ntasks. However, we demonstrate that out-of-ordinary questions can throw the\nmodel off guard. This work focuses on finding answers to negated complementary\nquestions in commonsense scenarios. We illustrate how such questions adversely\naffect the model responses. We propose a model-agnostic methodology to improve\nthe performance in negated complementary scenarios. Our method outperforms\nfew-shot generation from GPT-3 (by more than 11 points) and, more importantly,\nhighlights the significance of studying the response of large language models\nin negated complementary questions. The code, data, and experiments are\navailable under: https://github.com/navidre/negated_complementary_commonsense.\n",
                "链接": "https://arxiv.org/abs/2307.06794"
            },
            {
                "文章ID": "123543",
                "标题": "Large Language Models are Complex Table Parsers",
                "作者": " Bowen Zhao,  Changkai Ji,  Yuejie Zhang,  Wen He,  Yingwen Wang,  Qing Wang,  Rui Feng,  Xiaobo Zhang",
                "发布日期": "2023-12-20",
                "摘要": "  With the Generative Pre-trained Transformer 3.5 (GPT-3.5) exhibiting\nremarkable reasoning and comprehension abilities in Natural Language Processing\n(NLP), most Question Answering (QA) research has primarily centered around\ngeneral QA tasks based on GPT, neglecting the specific challenges posed by\nComplex Table QA. In this paper, we propose to incorporate GPT-3.5 to address\nsuch challenges, in which complex tables are reconstructed into tuples and\nspecific prompt designs are employed for dialogues. Specifically, we encode\neach cell's hierarchical structure, position information, and content as a\ntuple. By enhancing the prompt template with an explanatory description of the\nmeaning of each tuple and the logical reasoning process of the task, we\neffectively improve the hierarchical structure awareness capability of GPT-3.5\nto better parse the complex tables. Extensive experiments and results on\nComplex Table QA datasets, i.e., the open-domain dataset HiTAB and the aviation\ndomain dataset AIT-QA show that our approach significantly outperforms previous\nwork on both datasets, leading to state-of-the-art (SOTA) performance.\n",
                "链接": "https://arxiv.org/abs/2312.11521"
            },
            {
                "文章ID": "91937",
                "标题": "Challenges and Applications of Large Language Models",
                "作者": " Jean Kaddour,  Joshua Harris,  Maximilian Mozes,  Herbie Bradley,  Roberta Raileanu,  Robert McHardy",
                "发布日期": "2023-07-20",
                "摘要": "  Large Language Models (LLMs) went from non-existent to ubiquitous in the\nmachine learning discourse within a few years. Due to the fast pace of the\nfield, it is difficult to identify the remaining challenges and already\nfruitful application areas. In this paper, we aim to establish a systematic set\nof open problems and application successes so that ML researchers can\ncomprehend the field's current state more quickly and become productive.\n",
                "链接": "https://arxiv.org/abs/2307.10169"
            },
            {
                "文章ID": "110634",
                "标题": "AlpaCare:Instruction-tuned Large Language Models for Medical Application",
                "作者": " Xinlu Zhang,  Chenxin Tian,  Xianjun Yang,  Lichang Chen,  Zekun Li,  Linda Ruth Petzold",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) have demonstrated significant enhancements in\ninstruction-following abilities through instruction tuning, achieving notable\nperformances across various tasks. Previous research has focused on fine-tuning\nmedical domain-specific LLMs using an extensive array of medical-specific data,\nincorporating millions of pieces of biomedical literature to augment their\nmedical capabilities. However, existing medical instruction-tuned LLMs have\nbeen constrained by the limited scope of tasks and instructions available,\nrestricting the efficacy of instruction tuning and adversely affecting\nperformance in the general domain. In this paper, we fine-tune LLaMA-series\nmodels using 52k diverse, machine-generated, medical instruction-following\ndata, MedInstruct-52k, resulting in the model AlpaCare. Comprehensive\nexperimental results on both general and medical-specific domain free-form\ninstruction evaluations showcase AlpaCare's strong medical proficiency and\ngeneralizability compared to previous instruction-tuned models in both medical\nand general domains. We provide public access to our MedInstruct-52k dataset\nand a clinician-crafted free-form instruction test set, MedInstruct-test, along\nwith our codebase, to foster further research and development. Our project page\nis available at https://github.com/XZhang97666/AlpaCare.\n",
                "链接": "https://arxiv.org/abs/2310.14558"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            }
        ]
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "117493",
                "标题": "Transfer Attacks and Defenses for Large Language Models on Coding Tasks",
                "作者": " Chi Zhang,  Zifan Wang,  Ravi Mangal,  Matt Fredrikson,  Limin Jia,  Corina Pasareanu",
                "发布日期": "2023-11-23",
                "摘要": "  Modern large language models (LLMs), such as ChatGPT, have demonstrated\nimpressive capabilities for coding tasks including writing and reasoning about\ncode. They improve upon previous neural network models of code, such as\ncode2seq or seq2seq, that already demonstrated competitive results when\nperforming tasks such as code summarization and identifying code\nvulnerabilities. However, these previous code models were shown vulnerable to\nadversarial examples, i.e. small syntactic perturbations that do not change the\nprogram's semantics, such as the inclusion of \"dead code\" through false\nconditions or the addition of inconsequential print statements, designed to\n\"fool\" the models. LLMs can also be vulnerable to the same adversarial\nperturbations but a detailed study on this concern has been lacking so far. In\nthis paper we aim to investigate the effect of adversarial perturbations on\ncoding tasks with LLMs. In particular, we study the transferability of\nadversarial examples, generated through white-box attacks on smaller code\nmodels, to LLMs. Furthermore, to make the LLMs more robust against such\nadversaries without incurring the cost of retraining, we propose prompt-based\ndefenses that involve modifying the prompt to include additional information\nsuch as examples of adversarially perturbed code and explicit instructions for\nreversing adversarial perturbations. Our experiments show that adversarial\nexamples obtained with a smaller code model are indeed transferable, weakening\nthe LLMs' performance. The proposed defenses show promise in improving the\nmodel's resilience, paving the way to more robust defensive solutions for LLMs\nin code-related applications.\n",
                "链接": "https://arxiv.org/abs/2311.13445"
            },
            {
                "文章ID": "110744",
                "标题": "ALCUNA: Large Language Models Meet New Knowledge",
                "作者": " Xunjian Yin,  Baizhou Huang,  Xiaojun Wan",
                "发布日期": "2023-10-24",
                "摘要": "  With the rapid development of NLP, large-scale language models (LLMs) excel\nin various tasks across multiple domains now. However, existing benchmarks may\nnot adequately measure these models' capabilities, especially when faced with\nnew knowledge. In this paper, we address the lack of benchmarks to evaluate\nLLMs' ability to handle new knowledge, an important and challenging aspect in\nthe rapidly evolving world. We propose an approach called KnowGen that\ngenerates new knowledge by altering existing entity attributes and\nrelationships, resulting in artificial entities that are distinct from\nreal-world entities. With KnowGen, we introduce a benchmark named ALCUNA to\nassess LLMs' abilities in knowledge understanding, differentiation, and\nassociation. We benchmark several LLMs, reveals that their performance in face\nof new knowledge is not satisfactory, particularly in reasoning between new and\ninternal knowledge. We also explore the impact of entity similarity on the\nmodel's understanding of entity knowledge and the influence of contextual\nentities. We appeal to the need for caution when using LLMs in new scenarios or\nwith new knowledge, and hope that our benchmarks can help drive the development\nof LLMs in face of new knowledge.\n",
                "链接": "https://arxiv.org/abs/2310.14820"
            },
            {
                "文章ID": "114645",
                "标题": "Characterizing Large Language Models as Rationalizers of\n  Knowledge-intensive Tasks",
                "作者": " Aditi Mishra,  Sajjadur Rahman,  Hannah Kim,  Kushan Mitra,  Estevam Hruschka",
                "发布日期": "2023-11-10",
                "摘要": "  Large language models (LLMs) are proficient at generating fluent text with\nminimal task-specific supervision. Yet, their ability to provide well-grounded\nrationalizations for knowledge-intensive tasks remains under-explored. Such\ntasks, like commonsense multiple-choice questions, require rationales based on\nworld knowledge to support predictions and refute alternate options. We\nconsider the task of generating knowledge-guided rationalization in natural\nlanguage by using expert-written examples in a few-shot manner. Surprisingly,\ncrowd-workers preferred knowledge-grounded rationales over crowdsourced\nrationalizations, citing their factuality, sufficiency, and comprehensive\nrefutations. Although LLMs-generated rationales were preferable, further\nimprovements in conciseness and novelty are required. In another study, we show\nhow rationalization of incorrect model predictions erodes humans' trust in\nLLM-generated rationales. Motivated by these observations, we create a\ntwo-stage pipeline to review task predictions and eliminate potential incorrect\ndecisions before rationalization, enabling trustworthy rationale generation.\n",
                "链接": "https://arxiv.org/abs/2311.05085"
            },
            {
                "文章ID": "61947",
                "标题": "Large Language Models Fail on Trivial Alterations to Theory-of-Mind\n  Tasks",
                "作者": " Tomer Ullman",
                "发布日期": "2023-03-15",
                "摘要": "  Intuitive psychology is a pillar of common-sense reasoning. The replication\nof this reasoning in machine intelligence is an important stepping-stone on the\nway to human-like artificial intelligence. Several recent tasks and benchmarks\nfor examining this reasoning in Large-Large Models have focused in particular\non belief attribution in Theory-of-Mind tasks. These tasks have shown both\nsuccesses and failures. We consider in particular a recent purported success\ncase, and show that small variations that maintain the principles of ToM turn\nthe results on their head. We argue that in general, the zero-hypothesis for\nmodel evaluation in intuitive psychology should be skeptical, and that outlying\nfailure cases should outweigh average success rates. We also consider what\npossible future successes on Theory-of-Mind tasks by more powerful LLMs would\nmean for ToM tasks with people.\n",
                "链接": "https://arxiv.org/abs/2302.08399"
            },
            {
                "文章ID": "32533",
                "标题": "On Transfer of Adversarial Robustness from Pretraining to Downstream\n  Tasks",
                "作者": " Laura Fee Nern,  Harsh Raj,  Maurice Georgi,  Yash Sharma",
                "发布日期": "2023-10-10",
                "摘要": "  As large-scale training regimes have gained popularity, the use of pretrained\nmodels for downstream tasks has become common practice in machine learning.\nWhile pretraining has been shown to enhance the performance of models in\npractice, the transfer of robustness properties from pretraining to downstream\ntasks remains poorly understood. In this study, we demonstrate that the\nrobustness of a linear predictor on downstream tasks can be constrained by the\nrobustness of its underlying representation, regardless of the protocol used\nfor pretraining. We prove (i) a bound on the loss that holds independent of any\ndownstream task, as well as (ii) a criterion for robust classification in\nparticular. We validate our theoretical results in practical applications, show\nhow our results can be used for calibrating expectations of downstream\nrobustness, and when our results are useful for optimal transfer learning.\nTaken together, our results offer an initial step towards characterizing the\nrequirements of the representation function for reliable post-adaptation\nperformance.\n",
                "链接": "https://arxiv.org/abs/2208.03835"
            },
            {
                "文章ID": "14047",
                "标题": "Does Robustness on ImageNet Transfer to Downstream Tasks?",
                "作者": " Yutaro Yamada,  Mayu Otani",
                "发布日期": "2022-04-11",
                "摘要": "  As clean ImageNet accuracy nears its ceiling, the research community is\nincreasingly more concerned about robust accuracy under distributional shifts.\nWhile a variety of methods have been proposed to robustify neural networks,\nthese techniques often target models trained on ImageNet classification. At the\nsame time, it is a common practice to use ImageNet pretrained backbones for\ndownstream tasks such as object detection, semantic segmentation, and image\nclassification from different domains. This raises a question: Can these robust\nimage classifiers transfer robustness to downstream tasks? For object detection\nand semantic segmentation, we find that a vanilla Swin Transformer, a variant\nof Vision Transformer tailored for dense prediction tasks, transfers robustness\nbetter than Convolutional Neural Networks that are trained to be robust to the\ncorrupted version of ImageNet. For CIFAR10 classification, we find that models\nthat are robustified for ImageNet do not retain robustness when fully\nfine-tuned. These findings suggest that current robustification techniques tend\nto emphasize ImageNet evaluations. Moreover, network architecture is a strong\nsource of robustness when we consider transfer learning.\n",
                "链接": "https://arxiv.org/abs/2204.03934"
            },
            {
                "文章ID": "5760",
                "标题": "Knowledge Transfer from Large-scale Pretrained Language Models to\n  End-to-end Speech Recognizers",
                "作者": " Yotaro Kubo,  Shigeki Karita,  Michiel Bacchiani",
                "发布日期": "2022-02-17",
                "摘要": "  End-to-end speech recognition is a promising technology for enabling compact\nautomatic speech recognition (ASR) systems since it can unify the acoustic and\nlanguage model into a single neural network. However, as a drawback, training\nof end-to-end speech recognizers always requires transcribed utterances. Since\nend-to-end models are also known to be severely data hungry, this constraint is\ncrucial especially because obtaining transcribed utterances is costly and can\npossibly be impractical or impossible. This paper proposes a method for\nalleviating this issue by transferring knowledge from a language model neural\nnetwork that can be pretrained with text-only data. Specifically, this paper\nattempts to transfer semantic knowledge acquired in embedding vectors of\nlarge-scale language models. Since embedding vectors can be assumed as implicit\nrepresentations of linguistic information such as part-of-speech, intent, and\nso on, those are also expected to be useful modeling cues for ASR decoders.\nThis paper extends two types of ASR decoders, attention-based decoders and\nneural transducers, by modifying training loss functions to include embedding\nprediction terms. The proposed systems were shown to be effective for error\nrate reduction without incurring extra computational costs in the decoding\nphase.\n",
                "链接": "https://arxiv.org/abs/2202.07894"
            },
            {
                "文章ID": "41595",
                "标题": "Knowledge Distillation Transfer Sets and their Impact on Downstream NLU\n  Tasks",
                "作者": " Charith Peris,  Lizhen Tan,  Thomas Gueudre,  Turan Gojayev,  Pan Wei,  Gokmen Oz",
                "发布日期": "2022-10-19",
                "摘要": "  Teacher-student knowledge distillation is a popular technique for compressing\ntoday's prevailing large language models into manageable sizes that fit\nlow-latency downstream applications. Both the teacher and the choice of\ntransfer set used for distillation are crucial ingredients in creating a high\nquality student. Yet, the generic corpora used to pretrain the teacher and the\ncorpora associated with the downstream target domain are often significantly\ndifferent, which raises a natural question: should the student be distilled\nover the generic corpora, so as to learn from high-quality teacher predictions,\nor over the downstream task corpora to align with finetuning? Our study\ninvestigates this trade-off using Domain Classification (DC) and Intent\nClassification/Named Entity Recognition (ICNER) as downstream tasks. We distill\nseveral multilingual students from a larger multilingual LM with varying\nproportions of generic and task-specific datasets, and report their performance\nafter finetuning on DC and ICNER. We observe significant improvements across\ntasks and test sets when only task-specific corpora is used. We also report on\nhow the impact of adding task-specific data to the transfer set correlates with\nthe similarity between generic and task-specific data. Our results clearly\nindicate that, while distillation from a generic LM benefits downstream tasks,\nstudents learn better using target domain data even if it comes at the price of\nnoisier teacher predictions. In other words, target domain data still trumps\nteacher knowledge.\n",
                "链接": "https://arxiv.org/abs/2210.04834"
            },
            {
                "文章ID": "21024",
                "标题": "Sparse*BERT: Sparse Models Generalize To New tasks and Domains",
                "作者": " Daniel Campos,  Alexandre Marques,  Tuan Nguyen,  Mark Kurtz,  ChengXiang Zhai",
                "发布日期": "2023-04-07",
                "摘要": "  Large Language Models have become the core architecture upon which most\nmodern natural language processing (NLP) systems build. These models can\nconsistently deliver impressive accuracy and robustness across tasks and\ndomains, but their high computational overhead can make inference difficult and\nexpensive. To make using these models less costly, recent work has explored\nleveraging structured and unstructured pruning, quantization, and distillation\nto improve inference speed and decrease size. This paper studies how models\npruned using Gradual Unstructured Magnitude Pruning can transfer between\ndomains and tasks. Our experimentation shows that models that are pruned during\npretraining using general domain masked language models can transfer to novel\ndomains and tasks without extensive hyperparameter exploration or specialized\napproaches. We demonstrate that our general sparse model Sparse*BERT can become\nSparseBioBERT simply by pretraining the compressed architecture on unstructured\nbiomedical text. Moreover, we show that SparseBioBERT can match the quality of\nBioBERT with only 10\\% of the parameters.\n",
                "链接": "https://arxiv.org/abs/2205.12452"
            },
            {
                "文章ID": "80054",
                "标题": "Sources of Hallucination by Large Language Models on Inference Tasks",
                "作者": " Nick McKenna,  Tianyi Li,  Liang Cheng,  Mohammad Javad Hosseini,  Mark Johnson,  Mark Steedman",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) are claimed to be capable of Natural Language\nInference (NLI), necessary for applied tasks like question answering and\nsummarization. We present a series of behavioral studies on several LLM\nfamilies (LLaMA, GPT-3.5, and PaLM) which probe their behavior using controlled\nexperiments. We establish two biases originating from pretraining which predict\nmuch of their behavior, and show that these are major sources of hallucination\nin generative LLMs. First, memorization at the level of sentences: we show\nthat, regardless of the premise, models falsely label NLI test samples as\nentailing when the hypothesis is attested in training data, and that entities\nare used as ``indices'' to access the memorized data. Second, statistical\npatterns of usage learned at the level of corpora: we further show a similar\neffect when the premise predicate is less frequent than that of the hypothesis\nin the training data, a bias following from previous studies. We demonstrate\nthat LLMs perform significantly worse on NLI test samples which do not conform\nto these biases than those which do, and we offer these as valuable controls\nfor future LLM evaluation.\n",
                "链接": "https://arxiv.org/abs/2305.14552"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和人文学科交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "70754",
                "标题": "A Bibliometric Review of Large Language Models Research from 2017 to\n  2023",
                "作者": " Lizhou Fan,  Lingyao Li,  Zihui Ma,  Sanggyu Lee,  Huizi Yu,  Libby Hemphill",
                "发布日期": "2023-04-06",
                "摘要": "  Large language models (LLMs) are a class of language models that have\ndemonstrated outstanding performance across a range of natural language\nprocessing (NLP) tasks and have become a highly sought-after research area,\nbecause of their ability to generate human-like language and their potential to\nrevolutionize science and technology. In this study, we conduct bibliometric\nand discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000\npublications, this paper serves as a roadmap for researchers, practitioners,\nand policymakers to navigate the current landscape of LLMs research. We present\nthe research trends from 2017 to early 2023, identifying patterns in research\nparadigms and collaborations. We start with analyzing the core algorithm\ndevelopments and NLP tasks that are fundamental in LLMs research. We then\ninvestigate the applications of LLMs in various fields and domains including\nmedicine, engineering, social science, and humanities. Our review also reveals\nthe dynamic, fast-paced evolution of LLMs research. Overall, this paper offers\nvaluable insights into the current state, impact, and potential of LLMs\nresearch and its applications.\n",
                "链接": "https://arxiv.org/abs/2304.02020"
            },
            {
                "文章ID": "113893",
                "标题": "On the Intersection of Self-Correction and Trust in Language Models",
                "作者": " Satyapriya Krishna",
                "发布日期": "2023-11-07",
                "摘要": "  Large Language Models (LLMs) have demonstrated remarkable capabilities in\nperforming complex cognitive tasks. However, their complexity and lack of\ntransparency have raised several trustworthiness concerns, including the\npropagation of misinformation and toxicity. Recent research has explored the\nself-correction capabilities of LLMs to enhance their performance. In this\nwork, we investigate whether these self-correction capabilities can be\nharnessed to improve the trustworthiness of LLMs. We conduct experiments\nfocusing on two key aspects of trustworthiness: truthfulness and toxicity. Our\nfindings reveal that self-correction can lead to improvements in toxicity and\ntruthfulness, but the extent of these improvements varies depending on the\nspecific aspect of trustworthiness and the nature of the task. Interestingly,\nour study also uncovers instances of \"self-doubt\" in LLMs during the\nself-correction process, introducing a new set of challenges that need to be\naddressed.\n",
                "链接": "https://arxiv.org/abs/2311.02801"
            },
            {
                "文章ID": "96394",
                "标题": "Exploring the Intersection of Large Language Models and Agent-Based\n  Modeling via Prompt Engineering",
                "作者": " Edward Junprung",
                "发布日期": "2023-08-16",
                "摘要": "  The final frontier for simulation is the accurate representation of complex,\nreal-world social systems. While agent-based modeling (ABM) seeks to study the\nbehavior and interactions of agents within a larger system, it is unable to\nfaithfully capture the full complexity of human-driven behavior. Large language\nmodels (LLMs), like ChatGPT, have emerged as a potential solution to this\nbottleneck by enabling researchers to explore human-driven interactions in\npreviously unimaginable ways. Our research investigates simulations of human\ninteractions using LLMs. Through prompt engineering, inspired by Park et al.\n(2023), we present two simulations of believable proxies of human behavior: a\ntwo-agent negotiation and a six-agent murder mystery game.\n",
                "链接": "https://arxiv.org/abs/2308.07411"
            },
            {
                "文章ID": "81668",
                "标题": "The Utility of Large Language Models and Generative AI for Education\n  Research",
                "作者": " Andrew Katz,  Umair Shakir,  Ben Chambers",
                "发布日期": "2023-05-30",
                "摘要": "  The use of natural language processing (NLP) techniques in engineering\neducation can provide valuable insights into the underlying processes involved\nin generating text. While accessing these insights can be labor-intensive if\ndone manually, recent advances in NLP and large language models have made it a\nrealistic option for individuals. This study explores and evaluates a\ncombination of clustering, summarization, and prompting techniques to analyze\nover 1,000 student essays in which students discussed their career interests.\nThe specific assignment prompted students to define and explain their career\ngoals as engineers. Using text embedding representations of student responses,\nwe clustered the responses together to identify thematically similar statements\nfrom students. The clustered responses were then summarized to quickly identify\ncareer interest themes. We also used a set of a priori codes about career\nsatisfaction and sectors to demonstrate an alternative approach to using these\ngenerative text models to analyze student writing. The results of this study\ndemonstrate the feasibility and usefulness of NLP techniques in engineering\neducation research. By automating the initial analysis of student essays,\nresearchers and educators can more efficiently and accurately identify key\nthemes and patterns in student writing. The methods presented in this paper\nhave broader applications for engineering education and research purposes\nbeyond analyzing student essays. By explaining these methods to the engineering\neducation community, readers can utilize them in their own contexts.\n",
                "链接": "https://arxiv.org/abs/2305.18125"
            },
            {
                "文章ID": "112605",
                "标题": "The Eval4NLP 2023 Shared Task on Prompting Large Language Models as\n  Explainable Metrics",
                "作者": " Christoph Leiter,  Juri Opitz,  Daniel Deutsch,  Yang Gao,  Rotem Dror,  Steffen Eger",
                "发布日期": "2023-10-31",
                "摘要": "  With an increasing number of parameters and pre-training data, generative\nlarge language models (LLMs) have shown remarkable capabilities to solve tasks\nwith minimal or no task-related examples. Notably, LLMs have been successfully\nemployed as evaluation metrics in text generation tasks. Within this context,\nwe introduce the Eval4NLP 2023 shared task that asks participants to explore\nprompting and score extraction for machine translation (MT) and summarization\nevaluation. Specifically, we propose a novel competition setting in which we\nselect a list of allowed LLMs and disallow fine-tuning to ensure a focus on\nprompting. We present an overview of participants' approaches and evaluate them\non a new reference-free test set spanning three language pairs for MT and a\nsummarization dataset. Notably, despite the task's restrictions, the\nbest-performing systems achieve results on par with or even surpassing recent\nreference-free metrics developed using larger models, including GEMBA and\nComet-Kiwi-XXL. Finally, as a separate track, we perform a small-scale human\nevaluation of the plausibility of explanations given by the LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.19792"
            },
            {
                "文章ID": "70693",
                "标题": "Summary of ChatGPT-Related Research and Perspective Towards the Future\n  of Large Language Models",
                "作者": " Yiheng Liu,  Tianle Han,  Siyuan Ma,  Jiayue Zhang,  Yuanyuan Yang,  Jiaming Tian,  Hao He,  Antong Li,  Mengshen He,  Zhengliang Liu,  Zihao Wu,  Lin Zhao,  Dajiang Zhu,  Xiang Li,  Ning Qiang,  Dingang Shen,  Tianming Liu,  Bao Ge",
                "发布日期": "2023-08-25",
                "摘要": "  This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and\nGPT-4) research, state-of-the-art large language models (LLM) from the GPT\nseries, and their prospective applications across diverse domains. Indeed, key\ninnovations such as large-scale pre-training that captures knowledge across the\nentire world wide web, instruction fine-tuning and Reinforcement Learning from\nHuman Feedback (RLHF) have played significant roles in enhancing LLMs'\nadaptability and performance. We performed an in-depth analysis of 194 relevant\npapers on arXiv, encompassing trend analysis, word cloud representation, and\ndistribution analysis across various application domains. The findings reveal a\nsignificant and increasing interest in ChatGPT-related research, predominantly\ncentered on direct natural language processing applications, while also\ndemonstrating considerable potential in areas ranging from education and\nhistory to mathematics, medicine, and physics. This study endeavors to furnish\ninsights into ChatGPT's capabilities, potential implications, ethical concerns,\nand offer direction for future advancements in this field.\n",
                "链接": "https://arxiv.org/abs/2304.01852"
            },
            {
                "文章ID": "117438",
                "标题": "On the Calibration of Large Language Models and Alignment",
                "作者": " Chiwei Zhu,  Benfeng Xu,  Quan Wang,  Yongdong Zhang,  Zhendong Mao",
                "发布日期": "2023-11-23",
                "摘要": "  As large language models attract increasing attention and find widespread\napplication, concurrent challenges of reliability also arise at the same time.\nConfidence calibration, an effective analysis method for gauging the\nreliability of deep models, serves as a crucial tool for assessing and\nimproving their reliability. However, such investigation has been comparatively\nunderexplored. In this work, we conduct a systematic examination of the\ncalibration of aligned language models throughout the entire construction\nprocess, including pretraining and alignment training. At each stage, we\ninvestigate how different training settings, such as parameter scales and\ntraining data, affect model calibration. To thoroughly assess model\ncalibration, we evaluate models on three most concerned aspects: generation,\nfactuality and understanding. Our work sheds light on whether popular LLMs are\nwell-calibrated and how the training process influences model calibration.\n",
                "链接": "https://arxiv.org/abs/2311.13240"
            },
            {
                "文章ID": "70118",
                "标题": "On the Creativity of Large Language Models",
                "作者": " Giorgio Franceschelli,  Mirco Musolesi",
                "发布日期": "2023-07-11",
                "摘要": "  Large Language Models (LLMs) are revolutionizing several areas of Artificial\nIntelligence. One of the most remarkable applications is creative writing,\ne.g., poetry or storytelling: the generated outputs are often of astonishing\nquality. However, a natural question arises: can LLMs be really considered\ncreative? In this article we firstly analyze the development of LLMs under the\nlens of creativity theories, investigating the key open questions and\nchallenges. In particular, we focus our discussion around the dimensions of\nvalue, novelty and surprise as proposed by Margaret Boden in her work. Then, we\nconsider different classic perspectives, namely product, process, press and\nperson. We discuss a set of ``easy'' and ``hard'' problems in machine\ncreativity, presenting them in relation to LLMs. Finally, we examine the\nsocietal impact of these technologies with a particular focus on the creative\nindustries, analyzing the opportunities offered by them, the challenges arising\nby them and the potential associated risks, from both legal and ethical points\nof view.\n",
                "链接": "https://arxiv.org/abs/2304.00008"
            },
            {
                "文章ID": "101621",
                "标题": "Modeling Recommender Ecosystems: Research Challenges at the Intersection\n  of Mechanism Design, Reinforcement Learning and Generative Models",
                "作者": " Craig Boutilier,  Martin Mladenov,  Guy Tennenholtz",
                "发布日期": "2023-09-25",
                "摘要": "  Modern recommender systems lie at the heart of complex ecosystems that couple\nthe behavior of users, content providers, advertisers, and other actors.\nDespite this, the focus of the majority of recommender research -- and most\npractical recommenders of any import -- is on the local, myopic optimization of\nthe recommendations made to individual users. This comes at a significant cost\nto the long-term utility that recommenders could generate for its users. We\nargue that explicitly modeling the incentives and behaviors of all actors in\nthe system -- and the interactions among them induced by the recommender's\npolicy -- is strictly necessary if one is to maximize the value the system\nbrings to these actors and improve overall ecosystem \"health\". Doing so\nrequires: optimization over long horizons using techniques such as\nreinforcement learning; making inevitable tradeoffs in the utility that can be\ngenerated for different actors using the methods of social choice; reducing\ninformation asymmetry, while accounting for incentives and strategic behavior,\nusing the tools of mechanism design; better modeling of both user and\nitem-provider behaviors by incorporating notions from behavioral economics and\npsychology; and exploiting recent advances in generative and foundation models\nto make these mechanisms interpretable and actionable. We propose a conceptual\nframework that encompasses these elements, and articulate a number of research\nchallenges that emerge at the intersection of these different disciplines.\n",
                "链接": "https://arxiv.org/abs/2309.06375"
            },
            {
                "文章ID": "112477",
                "标题": "Artificial intelligence and the limits of the humanities",
                "作者": " Włodzisław Duch",
                "发布日期": "2023-10-31",
                "摘要": "  The complexity of cultures in the modern world is now beyond human\ncomprehension. Cognitive sciences cast doubts on the traditional explanations\nbased on mental models. The core subjects in humanities may lose their\nimportance. Humanities have to adapt to the digital age. New, interdisciplinary\nbranches of humanities emerge. Instant access to information will be replaced\nby instant access to knowledge. Understanding the cognitive limitations of\nhumans and the opportunities opened by the development of artificial\nintelligence and interdisciplinary research necessary to address global\nchallenges is the key to the revitalization of humanities. Artificial\nintelligence will radically change humanities, from art to political sciences\nand philosophy, making these disciplines attractive to students and enabling\nthem to go beyond current limitations.\n",
                "链接": "https://arxiv.org/abs/2310.19425"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和脑科学交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "70754",
                "标题": "A Bibliometric Review of Large Language Models Research from 2017 to\n  2023",
                "作者": " Lizhou Fan,  Lingyao Li,  Zihui Ma,  Sanggyu Lee,  Huizi Yu,  Libby Hemphill",
                "发布日期": "2023-04-06",
                "摘要": "  Large language models (LLMs) are a class of language models that have\ndemonstrated outstanding performance across a range of natural language\nprocessing (NLP) tasks and have become a highly sought-after research area,\nbecause of their ability to generate human-like language and their potential to\nrevolutionize science and technology. In this study, we conduct bibliometric\nand discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000\npublications, this paper serves as a roadmap for researchers, practitioners,\nand policymakers to navigate the current landscape of LLMs research. We present\nthe research trends from 2017 to early 2023, identifying patterns in research\nparadigms and collaborations. We start with analyzing the core algorithm\ndevelopments and NLP tasks that are fundamental in LLMs research. We then\ninvestigate the applications of LLMs in various fields and domains including\nmedicine, engineering, social science, and humanities. Our review also reveals\nthe dynamic, fast-paced evolution of LLMs research. Overall, this paper offers\nvaluable insights into the current state, impact, and potential of LLMs\nresearch and its applications.\n",
                "链接": "https://arxiv.org/abs/2304.02020"
            },
            {
                "文章ID": "105384",
                "标题": "In-Context Learning in Large Language Models: A Neuroscience-inspired\n  Analysis of Representations",
                "作者": " Safoora Yousefi,  Leo Betthauser,  Hosein Hasanbeig,  Akanksha Saran,  Raphaël Millière,  Ida Momennejad",
                "发布日期": "2023-10-19",
                "摘要": "  Large language models (LLMs) exhibit remarkable performance improvement\nthrough in-context learning (ICL) by leveraging task-specific examples in the\ninput. However, the mechanisms behind this improvement remain elusive. In this\nwork, we investigate embeddings and attention representations in Llama-2 70B\nand Vicuna 13B. Specifically, we study how embeddings and attention change\nafter in-context-learning, and how these changes mediate improvement in\nbehavior. We employ neuroscience-inspired techniques, such as representational\nsimilarity analysis (RSA), and propose novel methods for parameterized probing\nand attention ratio analysis (ARA, measuring the ratio of attention to relevant\nvs. irrelevant information). We designed three tasks with a priori\nrelationships among their conditions: reading comprehension, linear regression,\nand adversarial prompt injection. We formed hypotheses about expected\nsimilarities in task representations to investigate latent changes in\nembeddings and attention. Our analyses revealed a meaningful correlation\nbetween changes in both embeddings and attention representations with\nimprovements in behavioral performance after ICL. This empirical framework\nempowers a nuanced understanding of how latent representations affect LLM\nbehavior with and without ICL, offering valuable tools and insights for future\nresearch and practical applications.\n",
                "链接": "https://arxiv.org/abs/2310.00313"
            },
            {
                "文章ID": "96394",
                "标题": "Exploring the Intersection of Large Language Models and Agent-Based\n  Modeling via Prompt Engineering",
                "作者": " Edward Junprung",
                "发布日期": "2023-08-16",
                "摘要": "  The final frontier for simulation is the accurate representation of complex,\nreal-world social systems. While agent-based modeling (ABM) seeks to study the\nbehavior and interactions of agents within a larger system, it is unable to\nfaithfully capture the full complexity of human-driven behavior. Large language\nmodels (LLMs), like ChatGPT, have emerged as a potential solution to this\nbottleneck by enabling researchers to explore human-driven interactions in\npreviously unimaginable ways. Our research investigates simulations of human\ninteractions using LLMs. Through prompt engineering, inspired by Park et al.\n(2023), we present two simulations of believable proxies of human behavior: a\ntwo-agent negotiation and a six-agent murder mystery game.\n",
                "链接": "https://arxiv.org/abs/2308.07411"
            },
            {
                "文章ID": "112056",
                "标题": "Large-scale Foundation Models and Generative AI for BigData Neuroscience",
                "作者": " Ran Wang,  Zhe Sage Chen",
                "发布日期": "2023-10-31",
                "摘要": "  Recent advances in machine learning have made revolutionary breakthroughs in\ncomputer games, image and natural language understanding, and scientific\ndiscovery. Foundation models and large-scale language models (LLMs) have\nrecently achieved human-like intelligence thanks to BigData. With the help of\nself-supervised learning (SSL) and transfer learning, these models may\npotentially reshape the landscapes of neuroscience research and make a\nsignificant impact on the future. Here we present a mini-review on recent\nadvances in foundation models and generative AI models as well as their\napplications in neuroscience, including natural language and speech, semantic\nmemory, brain-machine interfaces (BMIs), and data augmentation. We argue that\nthis paradigm-shift framework will open new avenues for many neuroscience\nresearch directions and discuss the accompanying challenges and opportunities.\n",
                "链接": "https://arxiv.org/abs/2310.18377"
            },
            {
                "文章ID": "87950",
                "标题": "Large Multimodal Models: Notes on CVPR 2023 Tutorial",
                "作者": " Chunyuan Li",
                "发布日期": "2023-06-27",
                "摘要": "  This tutorial note summarizes the presentation on ``Large Multimodal Models:\nTowards Building and Surpassing Multimodal GPT-4'', a part of CVPR 2023\ntutorial on ``Recent Advances in Vision Foundation Models''. The tutorial\nconsists of three parts. We first introduce the background on recent GPT-like\nlarge models for vision-and-language modeling to motivate the research in\ninstruction-tuned large multimodal models (LMMs). As a pre-requisite, we\ndescribe the basics of instruction-tuning in large language models, which is\nfurther extended to the multimodal space. Lastly, we illustrate how to build\nthe minimum prototype of multimodal GPT-4 like models with the open-source\nresource, and review the recently emerged topics.\n",
                "链接": "https://arxiv.org/abs/2306.14895"
            },
            {
                "文章ID": "49891",
                "标题": "Data-Driven Network Neuroscience: On Data Collection and Benchmark",
                "作者": " Jiaxing Xu,  Yunhan Yang,  David Tse Jung Huang,  Sophi Shilpa Gururajapathy,  Yiping Ke,  Miao Qiao,  Alan Wang,  Haribalan Kumar,  Josh McGeown,  Eryn Kwon",
                "发布日期": "2023-10-31",
                "摘要": "  This paper presents a comprehensive and quality collection of functional\nhuman brain network data for potential research in the intersection of\nneuroscience, machine learning, and graph analytics. Anatomical and functional\nMRI images have been used to understand the functional connectivity of the\nhuman brain and are particularly important in identifying underlying\nneurodegenerative conditions such as Alzheimer's, Parkinson's, and Autism.\nRecently, the study of the brain in the form of brain networks using machine\nlearning and graph analytics has become increasingly popular, especially to\npredict the early onset of these conditions. A brain network, represented as a\ngraph, retains rich structural and positional information that traditional\nexamination methods are unable to capture. However, the lack of publicly\naccessible brain network data prevents researchers from data-driven\nexplorations. One of the main difficulties lies in the complicated\ndomain-specific preprocessing steps and the exhaustive computation required to\nconvert the data from MRI images into brain networks. We bridge this gap by\ncollecting a large amount of MRI images from public databases and a private\nsource, working with domain experts to make sensible design choices, and\npreprocessing the MRI images to produce a collection of brain network datasets.\nThe datasets originate from 6 different sources, cover 4 brain conditions, and\nconsist of a total of 2,702 subjects. We test our graph datasets on 12 machine\nlearning models to provide baselines and validate the data quality on a recent\ngraph analysis model. To lower the barrier to entry and promote the research in\nthis interdisciplinary field, we release our brain network data and complete\npreprocessing details including codes at\nhttps://doi.org/10.17608/k6.auckland.21397377 and\nhttps://github.com/brainnetuoa/data_driven_network_neuroscience.\n",
                "链接": "https://arxiv.org/abs/2211.12421"
            },
            {
                "文章ID": "113893",
                "标题": "On the Intersection of Self-Correction and Trust in Language Models",
                "作者": " Satyapriya Krishna",
                "发布日期": "2023-11-07",
                "摘要": "  Large Language Models (LLMs) have demonstrated remarkable capabilities in\nperforming complex cognitive tasks. However, their complexity and lack of\ntransparency have raised several trustworthiness concerns, including the\npropagation of misinformation and toxicity. Recent research has explored the\nself-correction capabilities of LLMs to enhance their performance. In this\nwork, we investigate whether these self-correction capabilities can be\nharnessed to improve the trustworthiness of LLMs. We conduct experiments\nfocusing on two key aspects of trustworthiness: truthfulness and toxicity. Our\nfindings reveal that self-correction can lead to improvements in toxicity and\ntruthfulness, but the extent of these improvements varies depending on the\nspecific aspect of trustworthiness and the nature of the task. Interestingly,\nour study also uncovers instances of \"self-doubt\" in LLMs during the\nself-correction process, introducing a new set of challenges that need to be\naddressed.\n",
                "链接": "https://arxiv.org/abs/2311.02801"
            },
            {
                "文章ID": "111240",
                "标题": "BLP 2023 Task 2: Sentiment Analysis",
                "作者": " Md. Arid Hasan,  Firoj Alam,  Anika Anjum,  Shudipta Das,  Afiyat Anjum",
                "发布日期": "2023-10-26",
                "摘要": "  We present an overview of the BLP Sentiment Shared Task, organized as part of\nthe inaugural BLP 2023 workshop, co-located with EMNLP 2023. The task is\ndefined as the detection of sentiment in a given piece of social media text.\nThis task attracted interest from 71 participants, among whom 29 and 30 teams\nsubmitted systems during the development and evaluation phases, respectively.\nIn total, participants submitted 597 runs. However, a total of 15 teams\nsubmitted system description papers. The range of approaches in the submitted\nsystems spans from classical machine learning models, fine-tuning pre-trained\nmodels, to leveraging Large Language Model (LLMs) in zero- and few-shot\nsettings. In this paper, we provide a detailed account of the task setup,\nincluding dataset development and evaluation setup. Additionally, we provide a\nbrief overview of the systems submitted by the participants. All datasets and\nevaluation scripts from the shared task have been made publicly available for\nthe research community, to foster further research in this domain\n",
                "链接": "https://arxiv.org/abs/2310.16183"
            },
            {
                "文章ID": "112605",
                "标题": "The Eval4NLP 2023 Shared Task on Prompting Large Language Models as\n  Explainable Metrics",
                "作者": " Christoph Leiter,  Juri Opitz,  Daniel Deutsch,  Yang Gao,  Rotem Dror,  Steffen Eger",
                "发布日期": "2023-10-31",
                "摘要": "  With an increasing number of parameters and pre-training data, generative\nlarge language models (LLMs) have shown remarkable capabilities to solve tasks\nwith minimal or no task-related examples. Notably, LLMs have been successfully\nemployed as evaluation metrics in text generation tasks. Within this context,\nwe introduce the Eval4NLP 2023 shared task that asks participants to explore\nprompting and score extraction for machine translation (MT) and summarization\nevaluation. Specifically, we propose a novel competition setting in which we\nselect a list of allowed LLMs and disallow fine-tuning to ensure a focus on\nprompting. We present an overview of participants' approaches and evaluate them\non a new reference-free test set spanning three language pairs for MT and a\nsummarization dataset. Notably, despite the task's restrictions, the\nbest-performing systems achieve results on par with or even surpassing recent\nreference-free metrics developed using larger models, including GEMBA and\nComet-Kiwi-XXL. Finally, as a separate track, we perform a small-scale human\nevaluation of the plausibility of explanations given by the LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.19792"
            },
            {
                "文章ID": "82900",
                "标题": "The feasibility of artificial consciousness through the lens of\n  neuroscience",
                "作者": " Jaan Aru,  Matthew Larkum,  James M. Shine",
                "发布日期": "2023-08-29",
                "摘要": "  Interactions with large language models have led to the suggestion that these\nmodels may soon be conscious. From the perspective of neuroscience, this\nposition is difficult to defend. For one, the inputs to large language models\nlack the embodied, embedded information content characteristic of our sensory\ncontact with the world around us. Secondly, the architecture of large language\nmodels is missing key features of the thalamocortical system that have been\nlinked to conscious awareness in mammals. Finally, the evolutionary and\ndevelopmental trajectories that led to the emergence of living conscious\norganisms arguably have no parallels in artificial systems as envisioned today.\nThe existence of living organisms depends on their actions, and their survival\nis intricately linked to multi-level cellular, inter-cellular, and organismal\nprocesses culminating in agency and consciousness.\n",
                "链接": "https://arxiv.org/abs/2306.00915"
            }
        ]
    },
    {
        "question": {
            "question": "2022年后与AI for Science相关的综述论文",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "96846",
                "标题": "Consciousness in Artificial Intelligence: Insights from the Science of\n  Consciousness",
                "作者": " Patrick Butlin,  Robert Long,  Eric Elmoznino,  Yoshua Bengio,  Jonathan Birch,  Axel Constant,  George Deane,  Stephen M. Fleming,  Chris Frith,  Xu Ji,  Ryota Kanai,  Colin Klein,  Grace Lindsay,  Matthias Michel,  Liad Mudrik,  Megan A. K. Peters,  Eric Schwitzgebel,  Jonathan Simon,  Rufin VanRullen",
                "发布日期": "2023-08-23",
                "摘要": "  Whether current or near-term AI systems could be conscious is a topic of\nscientific interest and increasing public concern. This report argues for, and\nexemplifies, a rigorous and empirically grounded approach to AI consciousness:\nassessing existing AI systems in detail, in light of our best-supported\nneuroscientific theories of consciousness. We survey several prominent\nscientific theories of consciousness, including recurrent processing theory,\nglobal workspace theory, higher-order theories, predictive processing, and\nattention schema theory. From these theories we derive \"indicator properties\"\nof consciousness, elucidated in computational terms that allow us to assess AI\nsystems for these properties. We use these indicator properties to assess\nseveral recent AI systems, and we discuss how future systems might implement\nthem. Our analysis suggests that no current AI systems are conscious, but also\nsuggests that there are no obvious technical barriers to building AI systems\nwhich satisfy these indicators.\n",
                "链接": "https://arxiv.org/abs/2308.08708"
            },
            {
                "文章ID": "13297",
                "标题": "On scientific understanding with artificial intelligence",
                "作者": " Mario Krenn,  Robert Pollice,  Si Yue Guo,  Matteo Aldeghi,  Alba Cervera-Lierta,  Pascal Friederich,  Gabriel dos Passos Gomes,  Florian Häse,  Adrian Jinich,  AkshatKumar Nigam,  Zhenpeng Yao,  Alán Aspuru-Guzik",
                "发布日期": "2023-01-18",
                "摘要": "  Imagine an oracle that correctly predicts the outcome of every particle\nphysics experiment, the products of every chemical reaction, or the function of\nevery protein. Such an oracle would revolutionize science and technology as we\nknow them. However, as scientists, we would not be satisfied with the oracle\nitself. We want more. We want to comprehend how the oracle conceived these\npredictions. This feat, denoted as scientific understanding, has frequently\nbeen recognized as the essential aim of science. Now, the ever-growing power of\ncomputers and artificial intelligence poses one ultimate question: How can\nadvanced artificial systems contribute to scientific understanding or achieve\nit autonomously?\n  We are convinced that this is not a mere technical question but lies at the\ncore of science. Therefore, here we set out to answer where we are and where we\ncan go from here. We first seek advice from the philosophy of science to\nunderstand scientific understanding. Then we review the current state of the\nart, both from literature and by collecting dozens of anecdotes from scientists\nabout how they acquired new conceptual understanding with the help of\ncomputers. Those combined insights help us to define three dimensions of\nandroid-assisted scientific understanding: The android as a I) computational\nmicroscope, II) resource of inspiration and the ultimate, not yet existent III)\nagent of understanding. For each dimension, we explain new avenues to push\nbeyond the status quo and unleash the full power of artificial intelligence's\ncontribution to the central aim of science. We hope our perspective inspires\nand focuses research towards androids that get new scientific understanding and\nultimately bring us closer to true artificial scientists.\n",
                "链接": "https://arxiv.org/abs/2204.01467"
            },
            {
                "文章ID": "108537",
                "标题": "Advancing Perception in Artificial Intelligence through Principles of\n  Cognitive Science",
                "作者": " Palaash Agrawal,  Cheston Tan,  Heena Rathore",
                "发布日期": "2023-10-16",
                "摘要": "  Although artificial intelligence (AI) has achieved many feats at a rapid\npace, there still exist open problems and fundamental shortcomings related to\nperformance and resource efficiency. Since AI researchers benchmark a\nsignificant proportion of performance standards through human intelligence,\ncognitive sciences-inspired AI is a promising domain of research. Studying\ncognitive science can provide a fresh perspective to building fundamental\nblocks in AI research, which can lead to improved performance and efficiency.\nIn this review paper, we focus on the cognitive functions of perception, which\nis the process of taking signals from one's surroundings as input, and\nprocessing them to understand the environment. Particularly, we study and\ncompare its various processes through the lens of both cognitive sciences and\nAI. Through this study, we review all current major theories from various\nsub-disciplines of cognitive science (specifically neuroscience, psychology and\nlinguistics), and draw parallels with theories and techniques from current\npractices in AI. We, hence, present a detailed collection of methods in AI for\nresearchers to build AI systems inspired by cognitive science. Further, through\nthe process of reviewing the state of cognitive-inspired AI, we point out many\ngaps in the current state of AI (with respect to the performance of the human\nbrain), and hence present potential directions for researchers to develop\nbetter perception systems in AI.\n",
                "链接": "https://arxiv.org/abs/2310.08803"
            },
            {
                "文章ID": "70041",
                "标题": "Artificial Intelligence in Ovarian Cancer Histopathology: A Systematic\n  Review",
                "作者": " Jack Breen,  Katie Allen,  Kieran Zucker,  Pratik Adusumilli,  Andy Scarsbrook,  Geoff Hall,  Nicolas M. Orsi,  Nishant Ravikumar",
                "发布日期": "2023-06-19",
                "摘要": "  Purpose - To characterise and assess the quality of published research\nevaluating artificial intelligence (AI) methods for ovarian cancer diagnosis or\nprognosis using histopathology data. Methods - A search of PubMed, Scopus, Web\nof Science, CENTRAL, and WHO-ICTRP was conducted up to 19/05/2023. The\ninclusion criteria required that research evaluated AI on histopathology images\nfor diagnostic or prognostic inferences in ovarian cancer. The risk of bias was\nassessed using PROBAST. Information about each model of interest was tabulated\nand summary statistics were reported. PRISMA 2020 reporting guidelines were\nfollowed. Results - 1573 records were identified, of which 45 were eligible for\ninclusion. There were 80 models of interest, including 37 diagnostic models, 22\nprognostic models, and 21 models with other diagnostically relevant outcomes.\nModels were developed using 1-1375 slides from 1-776 ovarian cancer patients.\nModel outcomes included treatment response (11/80), malignancy status (10/80),\nstain quantity (9/80), and histological subtype (7/80). All models were found\nto be at high or unclear risk of bias overall, with most research having a high\nrisk of bias in the analysis and a lack of clarity regarding participants and\npredictors in the study. Research frequently suffered from insufficient\nreporting and limited validation using small sample sizes. Conclusion - Limited\nresearch has been conducted on the application of AI to histopathology images\nfor diagnostic or prognostic purposes in ovarian cancer, and none of the\nassociated models have been demonstrated to be ready for real-world\nimplementation. Key aspects to help ensure clinical translation include more\ntransparent and comprehensive reporting of data provenance and modelling\napproaches, as well as improved quantitative performance evaluation using\ncross-validation and external validations.\n",
                "链接": "https://arxiv.org/abs/2303.18005"
            },
            {
                "文章ID": "27469",
                "标题": "Complementary artificial intelligence designed to augment human\n  discovery",
                "作者": " Jamshid Sourati,  James Evans",
                "发布日期": "2022-07-05",
                "摘要": "  Neither artificial intelligence designed to play Turing's imitation game, nor\naugmented intelligence built to maximize the human manipulation of information\nare tuned to accelerate innovation and improve humanity's collective advance\nagainst its greatest challenges. We reconceptualize and pilot beneficial AI to\nradically augment human understanding by complementing rather than competing\nwith human cognitive capacity. Our approach to complementary intelligence\nbuilds on insights underlying the wisdom of crowds, which hinges on the\nindependence and diversity of crowd members' information and approach. By\nprogrammatically incorporating information on the evolving distribution of\nscientific expertise from research papers, our approach follows the\ndistribution of content in the literature while avoiding the scientific crowd\nand the hypotheses cognitively available to it. We use this approach to\ngenerate valuable predictions for what materials possess valuable\nenergy-related properties (e.g., thermoelectricity), and what compounds possess\nvaluable medical properties (e.g., asthma) that complement the human scientific\ncrowd. We demonstrate that our complementary predictions, if identified by\nhuman scientists and inventors at all, are only discovered years further into\nthe future. When we evaluate the promise of our predictions with\nfirst-principles equations, we demonstrate that increased complementarity of\nour predictions does not decrease and in some cases increases the probability\nthat the predictions possess the targeted properties. In summary, by tuning AI\nto avoid the crowd, we can generate hypotheses unlikely to be imagined or\npursued until the distant future and promise to punctuate scientific advance.\nBy identifying and correcting for collective human bias, these models also\nsuggest opportunities to improve human prediction by reformulating science\neducation for discovery.\n",
                "链接": "https://arxiv.org/abs/2207.00902"
            },
            {
                "文章ID": "90755",
                "标题": "Artificial Intelligence for Drug Discovery: Are We There Yet?",
                "作者": " Catrin Hasselgren,  Tudor I. Oprea",
                "发布日期": "2023-07-14",
                "摘要": "  Drug discovery is adapting to novel technologies such as data science,\ninformatics, and artificial intelligence (AI) to accelerate effective treatment\ndevelopment while reducing costs and animal experiments. AI is transforming\ndrug discovery, as indicated by increasing interest from investors, industrial\nand academic scientists, and legislators. Successful drug discovery requires\noptimizing properties related to pharmacodynamics, pharmacokinetics, and\nclinical outcomes. This review discusses the use of AI in the three pillars of\ndrug discovery: diseases, targets, and therapeutic modalities, with a focus on\nsmall molecule drugs. AI technologies, such as generative chemistry, machine\nlearning, and multi-property optimization, have enabled several compounds to\nenter clinical trials. The scientific community must carefully vet known\ninformation to address the reproducibility crisis. The full potential of AI in\ndrug discovery can only be realized with sufficient ground truth and\nappropriate human intervention at later pipeline stages.\n",
                "链接": "https://arxiv.org/abs/2307.06521"
            },
            {
                "文章ID": "89772",
                "标题": "A Comprehensive Survey of Artificial Intelligence Techniques for Talent\n  Analytics",
                "作者": " Chuan Qin,  Le Zhang,  Rui Zha,  Dazhong Shen,  Qi Zhang,  Ying Sun,  Chen Zhu,  Hengshu Zhu,  Hui Xiong",
                "发布日期": "2023-07-10",
                "摘要": "  In today's competitive and fast-evolving business environment, it is a\ncritical time for organizations to rethink how to make talent-related decisions\nin a quantitative manner. Indeed, the recent development of Big Data and\nArtificial Intelligence (AI) techniques have revolutionized human resource\nmanagement. The availability of large-scale talent and management-related data\nprovides unparalleled opportunities for business leaders to comprehend\norganizational behaviors and gain tangible knowledge from a data science\nperspective, which in turn delivers intelligence for real-time decision-making\nand effective talent management at work for their organizations. In the last\ndecade, talent analytics has emerged as a promising field in applied data\nscience for human resource management, garnering significant attention from AI\ncommunities and inspiring numerous research efforts. To this end, we present an\nup-to-date and comprehensive survey on AI technologies used for talent\nanalytics in the field of human resource management. Specifically, we first\nprovide the background knowledge of talent analytics and categorize various\npertinent data. Subsequently, we offer a comprehensive taxonomy of relevant\nresearch efforts, categorized based on three distinct application-driven\nscenarios: talent management, organization management, and labor market\nanalysis. In conclusion, we summarize the open challenges and potential\nprospects for future research directions in the domain of AI-driven talent\nanalytics.\n",
                "链接": "https://arxiv.org/abs/2307.03195"
            },
            {
                "文章ID": "38596",
                "标题": "Artificial Intelligence in Material Engineering: A review on\n  applications of AI in Material Engineering",
                "作者": " Lipichanda Goswami,  Manoj Deka,  Mohendra Roy",
                "发布日期": "2023-04-28",
                "摘要": "  The role of artificial intelligence (AI) in material science and engineering\n(MSE) is becoming increasingly important as AI technology advances. The\ndevelopment of high-performance computing has made it possible to test deep\nlearning (DL) models with significant parameters, providing an opportunity to\novercome the limitation of traditional computational methods, such as density\nfunctional theory (DFT), in property prediction. Machine learning (ML)-based\nmethods are faster and more accurate than DFT-based methods. Furthermore, the\ngenerative adversarial networks (GANs) have facilitated the generation of\nchemical compositions of inorganic materials without using crystal structure\ninformation. These developments have significantly impacted material\nengineering (ME) and research. Some of the latest developments in AI in ME\nherein are reviewed. First, the development of AI in the critical areas of ME,\nsuch as in material processing, the study of structure and material property,\nand measuring the performance of materials in various aspects, is discussed.\nThen, the significant methods of AI and their uses in MSE, such as graph neural\nnetwork, generative models, transfer of learning, etc. are discussed. The use\nof AI to analyze the results from existing analytical instruments is also\ndiscussed. Finally, AI's advantages, disadvantages, and future in ME are\ndiscussed.\n",
                "链接": "https://arxiv.org/abs/2209.11234"
            },
            {
                "文章ID": "65243",
                "标题": "AI Risk Skepticism, A Comprehensive Survey",
                "作者": " Vemir Michael Ambartsoumean,  Roman V. Yampolskiy",
                "发布日期": "2023-03-08",
                "摘要": "  In this thorough study, we took a closer look at the skepticism that has\narisen with respect to potential dangers associated with artificial\nintelligence, denoted as AI Risk Skepticism. Our study takes into account\ndifferent points of view on the topic and draws parallels with other forms of\nskepticism that have shown up in science. We categorize the various skepticisms\nregarding the dangers of AI by the type of mistaken thinking involved. We hope\nthis will be of interest and value to AI researchers concerned about the future\nof AI and the risks that it may pose. The issues of skepticism and risk in AI\nare decidedly important and require serious consideration. By addressing these\nissues with the rigor and precision of scientific research, we hope to better\nunderstand the objections we face and to find satisfactory ways to resolve\nthem.\n",
                "链接": "https://arxiv.org/abs/2303.03885"
            },
            {
                "文章ID": "102726",
                "标题": "The role of causality in explainable artificial intelligence",
                "作者": " Gianluca Carloni,  Andrea Berti,  Sara Colantonio",
                "发布日期": "2023-09-19",
                "摘要": "  Causality and eXplainable Artificial Intelligence (XAI) have developed as\nseparate fields in computer science, even though the underlying concepts of\ncausation and explanation share common ancient roots. This is further enforced\nby the lack of review works jointly covering these two fields. In this paper,\nwe investigate the literature to try to understand how and to what extent\ncausality and XAI are intertwined. More precisely, we seek to uncover what\nkinds of relationships exist between the two concepts and how one can benefit\nfrom them, for instance, in building trust in AI systems. As a result, three\nmain perspectives are identified. In the first one, the lack of causality is\nseen as one of the major limitations of current AI and XAI approaches, and the\n\"optimal\" form of explanations is investigated. The second is a pragmatic\nperspective and considers XAI as a tool to foster scientific exploration for\ncausal inquiry, via the identification of pursue-worthy experimental\nmanipulations. Finally, the third perspective supports the idea that causality\nis propaedeutic to XAI in three possible manners: exploiting concepts borrowed\nfrom causality to support or improve XAI, utilizing counterfactuals for\nexplainability, and considering accessing a causal model as explaining itself.\nTo complement our analysis, we also provide relevant software solutions used to\nautomate causal tasks. We believe our work provides a unified view of the two\nfields of causality and XAI by highlighting potential domain bridges and\nuncovering possible limitations.\n",
                "链接": "https://arxiv.org/abs/2309.09901"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下2023年关于LLM-based Agent的综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "97862",
                "标题": "A Survey on Large Language Model based Autonomous Agents",
                "作者": " Lei Wang,  Chen Ma,  Xueyang Feng,  Zeyu Zhang,  Hao Yang,  Jingsen Zhang,  Zhiyuan Chen,  Jiakai Tang,  Xu Chen,  Yankai Lin,  Wayne Xin Zhao,  Zhewei Wei,  Ji-Rong Wen",
                "发布日期": "2023-09-08",
                "摘要": "  Autonomous agents have long been a prominent research focus in both academic\nand industry communities. Previous research in this field often focuses on\ntraining agents with limited knowledge within isolated environments, which\ndiverges significantly from human learning processes, and thus makes the agents\nhard to achieve human-like decisions. Recently, through the acquisition of vast\namounts of web knowledge, large language models (LLMs) have demonstrated\nremarkable potential in achieving human-level intelligence. This has sparked an\nupsurge in studies investigating LLM-based autonomous agents. In this paper, we\npresent a comprehensive survey of these studies, delivering a systematic review\nof the field of LLM-based autonomous agents from a holistic perspective. More\nspecifically, we first discuss the construction of LLM-based autonomous agents,\nfor which we propose a unified framework that encompasses a majority of the\nprevious work. Then, we present a comprehensive overview of the diverse\napplications of LLM-based autonomous agents in the fields of social science,\nnatural science, and engineering. Finally, we delve into the evaluation\nstrategies commonly used for LLM-based autonomous agents. Based on the previous\nstudies, we also present several challenges and future directions in this\nfield. To keep track of this field and continuously update our survey, we\nmaintain a repository of relevant references at\nhttps://github.com/Paitesanshi/LLM-Agent-Survey.\n",
                "链接": "https://arxiv.org/abs/2308.11432"
            },
            {
                "文章ID": "107902",
                "标题": "ClausewitzGPT Framework: A New Frontier in Theoretical Large Language\n  Model Enhanced Information Operations",
                "作者": " Benjamin Kereopa-Yorke",
                "发布日期": "2023-10-12",
                "摘要": "  In a digital epoch where cyberspace is the emerging nexus of geopolitical\ncontention, the melding of information operations and Large Language Models\n(LLMs) heralds a paradigm shift, replete with immense opportunities and\nintricate challenges. As tools like the Mistral 7B LLM (Mistral, 2023)\ndemocratise access to LLM capabilities (Jin et al., 2023), a vast spectrum of\nactors, from sovereign nations to rogue entities (Howard et al., 2023), find\nthemselves equipped with potent narrative-shaping instruments (Goldstein et\nal., 2023). This paper puts forth a framework for navigating this brave new\nworld in the \"ClausewitzGPT\" equation. This novel formulation not only seeks to\nquantify the risks inherent in machine-speed LLM-augmented operations but also\nunderscores the vital role of autonomous AI agents (Wang, Xie, et al., 2023).\nThese agents, embodying ethical considerations (Hendrycks et al., 2021), emerge\nas indispensable components (Wang, Ma, et al., 2023), ensuring that as we race\nforward, we do not lose sight of moral compasses and societal imperatives.\n  Mathematically underpinned and inspired by the timeless tenets of\nClausewitz's military strategy (Clausewitz, 1832), this thesis delves into the\nintricate dynamics of AI-augmented information operations. With references to\nrecent findings and research (Department of State, 2023), it highlights the\nstaggering year-on-year growth of AI information campaigns (Evgeny Pashentsev,\n2023), stressing the urgency of our current juncture. The synthesis of\nEnlightenment thinking, and Clausewitz's principles provides a foundational\nlens, emphasising the imperative of clear strategic vision, ethical\nconsiderations, and holistic understanding in the face of rapid technological\nadvancement.\n",
                "链接": "https://arxiv.org/abs/2310.07099"
            },
            {
                "文章ID": "78885",
                "标题": "Deep Learning Approaches to Lexical Simplification: A Survey",
                "作者": " Kai North,  Tharindu Ranasinghe,  Matthew Shardlow,  Marcos Zampieri",
                "发布日期": "2023-05-23",
                "摘要": "  Lexical Simplification (LS) is the task of replacing complex for simpler\nwords in a sentence whilst preserving the sentence's original meaning. LS is\nthe lexical component of Text Simplification (TS) with the aim of making texts\nmore accessible to various target populations. A past survey (Paetzold and\nSpecia, 2017) has provided a detailed overview of LS. Since this survey,\nhowever, the AI/NLP community has been taken by storm by recent advances in\ndeep learning, particularly with the introduction of large language models\n(LLM) and prompt learning. The high performance of these models sparked renewed\ninterest in LS. To reflect these recent advances, we present a comprehensive\nsurvey of papers published between 2017 and 2023 on LS and its sub-tasks with a\nspecial focus on deep learning. We also present benchmark datasets for the\nfuture development of LS systems.\n",
                "链接": "https://arxiv.org/abs/2305.12000"
            },
            {
                "文章ID": "88267",
                "标题": "The 2nd Place Solution for 2023 Waymo Open Sim Agents Challenge",
                "作者": " Cheng Qian,  Di Xiu,  Minghao Tian",
                "发布日期": "2023-06-29",
                "摘要": "  In this technical report, we present the 2nd place solution of 2023 Waymo\nOpen Sim Agents Challenge (WOSAC)[4]. We propose a simple yet effective\nautoregressive method for simulating multi-agent behaviors, which is built upon\na well-known multimodal motion forecasting framework called Motion Transformer\n(MTR)[5] with postprocessing algorithms applied. Our submission named MTR+++\nachieves 0.4697 on the Realism Meta metric in 2023 WOSAC. Besides, a modified\nmodel based on MTR named MTR_E is proposed after the challenge, which has a\nbetter score 0.4911 and is ranked the 3rd on the leaderboard of WOSAC as of\nJune 25, 2023.\n",
                "链接": "https://arxiv.org/abs/2306.15914"
            },
            {
                "文章ID": "91574",
                "标题": "How is ChatGPT's behavior changing over time?",
                "作者": " Lingjiao Chen,  Matei Zaharia,  James Zou",
                "发布日期": "2023-11-01",
                "摘要": "  GPT-3.5 and GPT-4 are the two most widely used large language model (LLM)\nservices. However, when and how these models are updated over time is opaque.\nHere, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\nseveral diverse tasks: 1) math problems, 2) sensitive/dangerous questions, 3)\nopinion surveys, 4) multi-hop knowledge-intensive questions, 5) generating\ncode, 6) US Medical License tests, and 7) visual reasoning. We find that the\nperformance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.\nFor example, GPT-4 (March 2023) was reasonable at identifying prime vs.\ncomposite numbers (84% accuracy) but GPT-4 (June 2023) was poor on these same\nquestions (51% accuracy). This is partly explained by a drop in GPT-4's amenity\nto follow chain-of-thought prompting. Interestingly, GPT-3.5 was much better in\nJune than in March in this task. GPT-4 became less willing to answer sensitive\nquestions and opinion survey questions in June than in March. GPT-4 performed\nbetter at multi-hop questions in June than in March, while GPT-3.5's\nperformance dropped on this task. Both GPT-4 and GPT-3.5 had more formatting\nmistakes in code generation in June than in March. We provide evidence that\nGPT-4's ability to follow user instructions has decreased over time, which is\none common factor behind the many behavior drifts. Overall, our findings show\nthat the behavior of the \"same\" LLM service can change substantially in a\nrelatively short amount of time, highlighting the need for continuous\nmonitoring of LLMs.\n",
                "链接": "https://arxiv.org/abs/2307.09009"
            },
            {
                "文章ID": "96394",
                "标题": "Exploring the Intersection of Large Language Models and Agent-Based\n  Modeling via Prompt Engineering",
                "作者": " Edward Junprung",
                "发布日期": "2023-08-16",
                "摘要": "  The final frontier for simulation is the accurate representation of complex,\nreal-world social systems. While agent-based modeling (ABM) seeks to study the\nbehavior and interactions of agents within a larger system, it is unable to\nfaithfully capture the full complexity of human-driven behavior. Large language\nmodels (LLMs), like ChatGPT, have emerged as a potential solution to this\nbottleneck by enabling researchers to explore human-driven interactions in\npreviously unimaginable ways. Our research investigates simulations of human\ninteractions using LLMs. Through prompt engineering, inspired by Park et al.\n(2023), we present two simulations of believable proxies of human behavior: a\ntwo-agent negotiation and a six-agent murder mystery game.\n",
                "链接": "https://arxiv.org/abs/2308.07411"
            },
            {
                "文章ID": "102059",
                "标题": "The Rise and Potential of Large Language Model Based Agents: A Survey",
                "作者": " Zhiheng Xi,  Wenxiang Chen,  Xin Guo,  Wei He,  Yiwen Ding,  Boyang Hong,  Ming Zhang,  Junzhe Wang,  Senjie Jin,  Enyu Zhou,  Rui Zheng,  Xiaoran Fan,  Xiao Wang,  Limao Xiong,  Yuhao Zhou,  Weiran Wang,  Changhao Jiang,  Yicheng Zou,  Xiangyang Liu,  Zhangyue Yin,  Shihan Dou,  Rongxiang Weng,  Wensen Cheng,  Qi Zhang,  Wenjuan Qin,  Yongyan Zheng,  Xipeng Qiu,  Xuanjing Huang,  Tao Gui",
                "发布日期": "2023-09-20",
                "摘要": "  For a long time, humanity has pursued artificial intelligence (AI) equivalent\nto or surpassing the human level, with AI agents considered a promising vehicle\nfor this pursuit. AI agents are artificial entities that sense their\nenvironment, make decisions, and take actions. Many efforts have been made to\ndevelop intelligent agents, but they mainly focus on advancement in algorithms\nor training strategies to enhance specific capabilities or performance on\nparticular tasks. Actually, what the community lacks is a general and powerful\nmodel to serve as a starting point for designing AI agents that can adapt to\ndiverse scenarios. Due to the versatile capabilities they demonstrate, large\nlanguage models (LLMs) are regarded as potential sparks for Artificial General\nIntelligence (AGI), offering hope for building general AI agents. Many\nresearchers have leveraged LLMs as the foundation to build AI agents and have\nachieved significant progress. In this paper, we perform a comprehensive survey\non LLM-based agents. We start by tracing the concept of agents from its\nphilosophical origins to its development in AI, and explain why LLMs are\nsuitable foundations for agents. Building upon this, we present a general\nframework for LLM-based agents, comprising three main components: brain,\nperception, and action, and the framework can be tailored for different\napplications. Subsequently, we explore the extensive applications of LLM-based\nagents in three aspects: single-agent scenarios, multi-agent scenarios, and\nhuman-agent cooperation. Following this, we delve into agent societies,\nexploring the behavior and personality of LLM-based agents, the social\nphenomena that emerge from an agent society, and the insights they offer for\nhuman society. Finally, we discuss several key topics and open problems within\nthe field. A repository for the related papers at\nhttps://github.com/WooooDyy/LLM-Agent-Paper-List.\n",
                "链接": "https://arxiv.org/abs/2309.07864"
            },
            {
                "文章ID": "103247",
                "标题": "Safurai 001: New Qualitative Approach for Code LLM Evaluation",
                "作者": " Davide Cifarelli,  Leonardo Boiardi,  Alessandro Puppo",
                "发布日期": "2023-09-21",
                "摘要": "  This paper presents Safurai-001, a new Large Language Model (LLM) with\nsignificant potential in the domain of coding assistance. Driven by recent\nadvancements in coding LLMs, Safurai-001 competes in performance with the\nlatest models like WizardCoder [Xu et al., 2023], PanguCoder [Shen et al.,\n2023] and Phi-1 [Gunasekar et al., 2023] but aims to deliver a more\nconversational interaction. By capitalizing on the progress in data engineering\n(including latest techniques of data transformation and prompt engineering) and\ninstruction tuning, this new model promises to stand toe-to-toe with recent\nclosed and open source developments. Recognizing the need for an efficacious\nevaluation metric for coding LLMs, this paper also introduces GPT4-based\nMultiParameters, an evaluation benchmark that harnesses varied parameters to\npresent a comprehensive insight into the models functioning and performance.\nOur assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and\nWizardCoder by 18.78% in the Code Readability parameter and more.\n",
                "链接": "https://arxiv.org/abs/2309.11385"
            },
            {
                "文章ID": "78899",
                "标题": "The Waymo Open Sim Agents Challenge",
                "作者": " Nico Montali,  John Lambert,  Paul Mougin,  Alex Kuefler,  Nick Rhinehart,  Michelle Li,  Cole Gulino,  Tristan Emrich,  Zoey Yang,  Shimon Whiteson,  Brandyn White,  Dragomir Anguelov",
                "发布日期": "2023-12-12",
                "摘要": "  Simulation with realistic, interactive agents represents a key task for\nautonomous vehicle software development. In this work, we introduce the Waymo\nOpen Sim Agents Challenge (WOSAC). WOSAC is the first public challenge to\ntackle this task and propose corresponding metrics. The goal of the challenge\nis to stimulate the design of realistic simulators that can be used to evaluate\nand train a behavior model for autonomous driving. We outline our evaluation\nmethodology, present results for a number of different baseline simulation\nagent methods, and analyze several submissions to the 2023 competition which\nran from March 16, 2023 to May 23, 2023. The WOSAC evaluation server remains\nopen for submissions and we discuss open problems for the task.\n",
                "链接": "https://arxiv.org/abs/2305.12032"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "27724",
                "标题": "Location reference recognition from texts: A survey and comparison",
                "作者": " Xuke Hu,  Zhiyong Zhou,  Hao Li,  Yingjie Hu,  Fuqiang Gu,  Jens Kersten,  Hongchao Fan,  Friederike Klan",
                "发布日期": "2022-07-06",
                "摘要": "  A vast amount of location information exists in unstructured texts, such as\nsocial media posts, news stories, scientific articles, web pages, travel blogs,\nand historical archives. Geoparsing refers to the process of recognizing\nlocation references from texts and identifying their geospatial\nrepresentations. While geoparsing can benefit many domains, a summary of the\nspecific applications is still missing. Further, there lacks a comprehensive\nreview and comparison of existing approaches for location reference\nrecognition, which is the first and a core step of geoparsing. To fill these\nresearch gaps, this review first summarizes seven typical application domains\nof geoparsing: geographic information retrieval, disaster management, disease\nsurveillance, traffic management, spatial humanities, tourism management, and\ncrime management. We then review existing approaches for location reference\nrecognition by categorizing these approaches into four groups based on their\nunderlying functional principle: rule-based, gazetteer matching-based,\nstatistical learning-based, and hybrid approaches. Next, we thoroughly evaluate\nthe correctness and computational efficiency of the 27 most widely used\napproaches for location reference recognition based on 26 public datasets with\ndifferent types of texts (e.g., social media posts and news stories) containing\n39,736 location references across the world. Results from this thorough\nevaluation can help inform future methodological developments for location\nreference recognition, and can help guide the selection of proper approaches\nbased on application needs.\n",
                "链接": "https://arxiv.org/abs/2207.01683"
            },
            {
                "文章ID": "21330",
                "标题": "Surround-view Fisheye Camera Perception for Automated Driving: Overview,\n  Survey and Challenges",
                "作者": " Varun Ravi Kumar,  Ciaran Eising,  Christian Witt,  Senthil Yogamani",
                "发布日期": "2023-01-06",
                "摘要": "  Surround-view fisheye cameras are commonly used for near-field sensing in\nautomated driving. Four fisheye cameras on four sides of the vehicle are\nsufficient to cover 360{\\deg} around the vehicle capturing the entire\nnear-field region. Some primary use cases are automated parking, traffic jam\nassist, and urban driving. There are limited datasets and very little work on\nnear-field perception tasks as the focus in automotive perception is on\nfar-field perception. In contrast to far-field, surround-view perception poses\nadditional challenges due to high precision object detection requirements of\n10cm and partial visibility of objects. Due to the large radial distortion of\nfisheye cameras, standard algorithms cannot be extended easily to the\nsurround-view use case. Thus, we are motivated to provide a self-contained\nreference for automotive fisheye camera perception for researchers and\npractitioners. Firstly, we provide a unified and taxonomic treatment of\ncommonly used fisheye camera models. Secondly, we discuss various perception\ntasks and existing literature. Finally, we discuss the challenges and future\ndirection.\n",
                "链接": "https://arxiv.org/abs/2205.13281"
            },
            {
                "文章ID": "91982",
                "标题": "Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding\n  (Survey)",
                "作者": " Subba Reddy Oota,  Manish Gupta,  Raju S. Bapi,  Gael Jobard,  Frederic Alexandre,  Xavier Hinaut",
                "发布日期": "2023-07-21",
                "摘要": "  How does the brain represent different modes of information? Can we design a\nsystem that automatically understands what the user is thinking? Such questions\ncan be answered by studying brain recordings like functional magnetic resonance\nimaging (fMRI). As a first step, the neuroscience community has contributed\nseveral large cognitive neuroscience datasets related to passive\nreading/listening/viewing of concept words, narratives, pictures and movies.\nEncoding and decoding models using these datasets have also been proposed in\nthe past two decades. These models serve as additional tools for basic research\nin cognitive science and neuroscience. Encoding models aim at generating fMRI\nbrain representations given a stimulus automatically. They have several\npractical applications in evaluating and diagnosing neurological conditions and\nthus also help design therapies for brain damage. Decoding models solve the\ninverse problem of reconstructing the stimuli given the fMRI. They are useful\nfor designing brain-machine or brain-computer interfaces. Inspired by the\neffectiveness of deep learning models for natural language processing, computer\nvision, and speech, recently several neural encoding and decoding models have\nbeen proposed. In this survey, we will first discuss popular representations of\nlanguage, vision and speech stimuli, and present a summary of neuroscience\ndatasets. Further, we will review popular deep learning based encoding and\ndecoding architectures and note their benefits and limitations. Finally, we\nwill conclude with a brief summary and discussion about future trends. Given\nthe large amount of recently published work in the `computational cognitive\nneuroscience' community, we believe that this survey nicely organizes the\nplethora of work and presents it as a coherent story.\n",
                "链接": "https://arxiv.org/abs/2307.10246"
            },
            {
                "文章ID": "11882",
                "标题": "Recent Few-Shot Object Detection Algorithms: A Survey with Performance\n  Comparison",
                "作者": " Tianying Liu,  Lu Zhang,  Yang Wang,  Jihong Guan,  Yanwei Fu,  Jiajia Zhao,  Shuigeng Zhou",
                "发布日期": "2023-04-13",
                "摘要": "  The generic object detection (GOD) task has been successfully tackled by\nrecent deep neural networks, trained by an avalanche of annotated training\nsamples from some common classes. However, it is still non-trivial to\ngeneralize these object detectors to the novel long-tailed object classes,\nwhich have only few labeled training samples. To this end, the Few-Shot Object\nDetection (FSOD) has been topical recently, as it mimics the humans' ability of\nlearning to learn, and intelligently transfers the learned generic object\nknowledge from the common heavy-tailed, to the novel long-tailed object\nclasses. Especially, the research in this emerging field has been flourishing\nin recent years with various benchmarks, backbones, and methodologies proposed.\nTo review these FSOD works, there are several insightful FSOD survey articles\n[58, 59, 74, 78] that systematically study and compare them as the groups of\nfine-tuning/transfer learning, and meta-learning methods. In contrast, we\nreview the existing FSOD algorithms from a new perspective under a new taxonomy\nbased on their contributions, i.e., data-oriented, model-oriented, and\nalgorithm-oriented. Thus, a comprehensive survey with performance comparison is\nconducted on recent achievements of FSOD. Furthermore, we also analyze the\ntechnical challenges, the merits and demerits of these methods, and envision\nthe future directions of FSOD. Specifically, we give an overview of FSOD,\nincluding the problem definition, common datasets, and evaluation protocols.\nThe taxonomy is then proposed that groups FSOD methods into three types.\nFollowing this taxonomy, we provide a systematic review of the advances in\nFSOD. Finally, further discussions on performance, challenges, and future\ndirections are presented.\n",
                "链接": "https://arxiv.org/abs/2203.14205"
            },
            {
                "文章ID": "51147",
                "标题": "PAC-Bayes Bounds for Bandit Problems: A Survey and Experimental\n  Comparison",
                "作者": " Hamish Flynn,  David Reeb,  Melih Kandemir,  Jan Peters",
                "发布日期": "2023-09-26",
                "摘要": "  PAC-Bayes has recently re-emerged as an effective theory with which one can\nderive principled learning algorithms with tight performance guarantees.\nHowever, applications of PAC-Bayes to bandit problems are relatively rare,\nwhich is a great misfortune. Many decision-making problems in healthcare,\nfinance and natural sciences can be modelled as bandit problems. In many of\nthese applications, principled algorithms with strong performance guarantees\nwould be very much appreciated. This survey provides an overview of PAC-Bayes\nbounds for bandit problems and an experimental comparison of these bounds. On\nthe one hand, we found that PAC-Bayes bounds are a useful tool for designing\noffline bandit algorithms with performance guarantees. In our experiments, a\nPAC-Bayesian offline contextual bandit algorithm was able to learn randomised\nneural network polices with competitive expected reward and non-vacuous\nperformance guarantees. On the other hand, the PAC-Bayesian online bandit\nalgorithms that we tested had loose cumulative regret bounds. We conclude by\ndiscussing some topics for future work on PAC-Bayesian bandit algorithms.\n",
                "链接": "https://arxiv.org/abs/2211.16110"
            },
            {
                "文章ID": "96181",
                "标题": "A Survey on Deep Neural Network Pruning-Taxonomy, Comparison, Analysis,\n  and Recommendations",
                "作者": " Hongrong Cheng,  Miao Zhang,  Javen Qinfeng Shi",
                "发布日期": "2023-08-15",
                "摘要": "  Modern deep neural networks, particularly recent large language models, come\nwith massive model sizes that require significant computational and storage\nresources. To enable the deployment of modern models on resource-constrained\nenvironments and accelerate inference time, researchers have increasingly\nexplored pruning techniques as a popular research direction in neural network\ncompression. However, there is a dearth of up-to-date comprehensive review\npapers on pruning. To address this issue, in this survey, we provide a\ncomprehensive review of existing research works on deep neural network pruning\nin a taxonomy of 1) universal/specific speedup, 2) when to prune, 3) how to\nprune, and 4) fusion of pruning and other compression techniques. We then\nprovide a thorough comparative analysis of seven pairs of contrast settings for\npruning (e.g., unstructured/structured) and explore emerging topics, including\npost-training pruning, different levels of supervision for pruning, and broader\napplications (e.g., adversarial robustness) to shed light on the commonalities\nand differences of existing methods and lay the foundation for further method\ndevelopment. To facilitate future research, we build a curated collection of\ndatasets, networks, and evaluations on different applications. Finally, we\nprovide some valuable recommendations on selecting pruning methods and prospect\npromising research directions. We build a repository at\nhttps://github.com/hrcheng1066/awesome-pruning.\n",
                "链接": "https://arxiv.org/abs/2308.06767"
            },
            {
                "文章ID": "44092",
                "标题": "Video Summarization Overview",
                "作者": " Mayu Otani,  Yale Song,  Yang Wang",
                "发布日期": "2022-10-24",
                "摘要": "  With the broad growth of video capturing devices and applications on the web,\nit is more demanding to provide desired video content for users efficiently.\nVideo summarization facilitates quickly grasping video content by creating a\ncompact summary of videos. Much effort has been devoted to automatic video\nsummarization, and various problem settings and approaches have been proposed.\nOur goal is to provide an overview of this field. This survey covers early\nstudies as well as recent approaches which take advantage of deep learning\ntechniques. We describe video summarization approaches and their underlying\nconcepts. We also discuss benchmarks and evaluations. We overview how prior\nwork addressed evaluation and detail the pros and cons of the evaluation\nprotocols. Last but not least, we discuss open challenges in this field.\n",
                "链接": "https://arxiv.org/abs/2210.11707"
            },
            {
                "文章ID": "104862",
                "标题": "Decoding the Workplace & EOR: An Employee Survey Analysis by Data\n  Science Techniques and Visualization",
                "作者": " Kishankumar Bhimani,  Khushbu Saradva",
                "发布日期": "2023-09-29",
                "摘要": "  This research study explores the new dynamics of employee-organi-zation\nrelationships (EOR) [6] using advanced data science methodologies and presents\nfindings through accessible visualizations. Leveraging a dataset pro-cured from\na comprehensive nationwide big employee survey, this study employs innovative\nstrategy for theoretical researcher by using our state-of-the-art\nvisual-ization. The results present insightful visualizations encapsulating\ndemographic analysis, workforce satisfaction, work environment scrutiny, and\nthe employee's view via word cloud interpretations and burnout predictions.\n  The study underscores the profound implications of data science across\nvarious management sectors, enhancing understanding of workplace dynamics and\npro-moting mutual growth and satisfaction. This multifaceted approach caters to\na diverse array of readers, from researchers in sociology and management to\nfirms seeking detailed understanding of their workforce's satisfaction,\nemphasizing on practicality and interpretability.\n  The research encourages proactive measures to improve workplace\nenviron-ments, boost employee satisfaction, and foster healthier, more\nproductive organ-izations. It serves as a resourceful tool for those committed\nto these objectives, manifesting the transformative potential of data science\nin driving insightful nar-ratives about workplace dynamics and\nemployee-organization relationships. In essence, this research unearths\nvaluable insights to aid management, HR profes-sionals, and companies\n",
                "链接": "https://arxiv.org/abs/2309.16329"
            },
            {
                "文章ID": "37976",
                "标题": "Overview of the SV-Ident 2022 Shared Task on Survey Variable\n  Identification in Social Science Publications",
                "作者": " Tornike Tsereteli,  Yavuz Selim Kartal,  Simone Paolo Ponzetto,  Andrea Zielinski,  Kai Eckert,  Philipp Mayr",
                "发布日期": "2022-09-20",
                "摘要": "  In this paper, we provide an overview of the SV-Ident shared task as part of\nthe 3rd Workshop on Scholarly Document Processing (SDP) at COLING 2022. In the\nshared task, participants were provided with a sentence and a vocabulary of\nvariables, and asked to identify which variables, if any, are mentioned in\nindividual sentences from scholarly documents in full text. Two teams made a\ntotal of 9 submissions to the shared task leaderboard. While none of the teams\nimprove on the baseline systems, we still draw insights from their submissions.\nFurthermore, we provide a detailed evaluation. Data and baselines for our\nshared task are freely available at https://github.com/vadis-project/sv-ident\n",
                "链接": "https://arxiv.org/abs/2209.09062"
            },
            {
                "文章ID": "6077",
                "标题": "A Comprehensive Survey with Quantitative Comparison of Image Analysis\n  Methods for Microorganism Biovolume Measurements",
                "作者": " Jiawei Zhang,  Chen Li,  Md Mamunur Rahaman,  Yudong Yao,  Pingli Ma,  Jinghua Zhang,  Xin Zhao,  Tao Jiang,  Marcin Grzegorzek",
                "发布日期": "2022-05-03",
                "摘要": "  With the acceleration of urbanization and living standards, microorganisms\nplay increasingly important roles in industrial production, bio-technique, and\nfood safety testing. Microorganism biovolume measurements are one of the\nessential parts of microbial analysis. However, traditional manual measurement\nmethods are time-consuming and challenging to measure the characteristics\nprecisely. With the development of digital image processing techniques, the\ncharacteristics of the microbial population can be detected and quantified. The\nchanging trend can be adjusted in time and provided a basis for the\nimprovement. The applications of the microorganism biovolume measurement method\nhave developed since the 1980s. More than 62 articles are reviewed in this\nstudy, and the articles are grouped by digital image segmentation methods with\nperiods. This study has high research significance and application value, which\ncan be referred to microbial researchers to have a comprehensive understanding\nof microorganism biovolume measurements using digital image analysis methods\nand potential applications.\n",
                "链接": "https://arxiv.org/abs/2202.09020"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近三个月有关语言模型rlhf的arxiv上的全部文章。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大模型结合树搜索方法进行推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "23592",
                "标题": "Combining Monte-Carlo Tree Search with Proof-Number Search",
                "作者": " Elliot Doe,  Mark H. M. Winands,  Dennis J. N. J. Soemers,  Cameron Browne",
                "发布日期": "2022-06-09",
                "摘要": "  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
                "链接": "https://arxiv.org/abs/2206.03965"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "105289",
                "标题": "SocREval: Large Language Models with the Socratic Method for\n  Reference-Free Reasoning Evaluation",
                "作者": " Hangfeng He,  Hongming Zhang,  Dan Roth",
                "发布日期": "2023-10-03",
                "摘要": "  To comprehensively assess the capacity of current models for complex\nreasoning, it is crucial to assess their step-by-step reasoning in a scalable\nmanner. Established reference-based evaluation metrics rely on human-annotated\nreasoning chains to assess the model-derived chains. However, such\n``gold-standard'' human-written reasoning chains may not be unique and their\nacquisition is often labor-intensive. Existing reference-free reasoning metrics\neliminate the need for human-crafted reasoning chains as references, but they\ntypically require fine-tuning on datasets with human-derived reasoning chains,\nwhich complicates the process and raises concerns regarding generalizability\nacross diverse datasets. To address these challenges, we harness GPT-4 to\nautomatically evaluate reasoning chain quality, obviating the need for\nhuman-crafted references. Leveraging the Socratic method, we devise tailored\nprompts to enhance reference-free reasoning evaluation, which we term SocREval\n(Socratic method for Reasoning Evaluation). Empirical results from four human\nannotated datasets reveal that SocREval significantly improves GPT-4's\nperformance, surpassing existing reference-free and reference-based reasoning\nevaluation metrics. Beyond its demonstrated efficacy, our proposed framework,\nlarge language models (LLMs) with the Socratic method, proves to be both\ncost-efficient and robust to prompt writing and example selection, as\nsubstantiated by our in-depth analysis.\n",
                "链接": "https://arxiv.org/abs/2310.00074"
            },
            {
                "文章ID": "102013",
                "标题": "Tree of Uncertain Thoughts Reasoning for Large Language Models",
                "作者": " Shentong Mo,  Miao Xin",
                "发布日期": "2023-09-15",
                "摘要": "  While the recently introduced Tree of Thoughts (ToT) has heralded\nadvancements in allowing Large Language Models (LLMs) to reason through\nforesight and backtracking for global decision-making, it has overlooked the\ninherent local uncertainties in intermediate decision points or \"thoughts\".\nThese local uncertainties, intrinsic to LLMs given their potential for diverse\nresponses, remain a significant concern in the reasoning process. Addressing\nthis pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) - a\nreasoning framework tailored for LLMs. Our TouT effectively leverages Monte\nCarlo Dropout to quantify uncertainty scores associated with LLMs' diverse\nlocal responses at these intermediate steps. By marrying this local uncertainty\nquantification with global search algorithms, TouT enhances the model's\nprecision in response generation. We substantiate our approach with rigorous\nexperiments on two demanding planning tasks: Game of 24 and Mini Crosswords.\nThe empirical evidence underscores TouT's superiority over both ToT and\nchain-of-thought prompting methods.\n",
                "链接": "https://arxiv.org/abs/2309.07694"
            },
            {
                "文章ID": "73991",
                "标题": "Combining Monte Carlo Tree Search and Heuristic Search for Weighted\n  Vertex Coloring",
                "作者": " Cyril Grelier,  Olivier Goudet,  Jin-Kao Hao",
                "发布日期": "2023-04-25",
                "摘要": "  This work investigates the Monte Carlo Tree Search (MCTS) method combined\nwith dedicated heuristics for solving the Weighted Vertex Coloring Problem. In\naddition to the basic MCTS algorithm, we study several MCTS variants where the\nconventional random simulation is replaced by other simulation strategies\nincluding greedy and local search heuristics. We conduct experiments on\nwell-known benchmark instances to assess these combined MCTS variants. We\nprovide empirical evidence to shed light on the advantages and limits of each\nsimulation strategy. This is an extension of the work of Grelier and al.\npresented at EvoCOP2022.\n",
                "链接": "https://arxiv.org/abs/2304.12146"
            },
            {
                "文章ID": "109239",
                "标题": "Autonomous Tree-search Ability of Large Language Models",
                "作者": " Zheyu Zhang,  Zhuorui Ye,  Yikang Shen,  Chuang Gan",
                "发布日期": "2023-10-18",
                "摘要": "  Large Language Models have excelled in remarkable reasoning capabilities with\nadvanced prompting techniques, but they fall short on tasks that require\nexploration, strategic foresight, and sequential decision-making. Recent works\npropose to utilize external programs to define search logic, such that LLMs can\nperform passive tree search to solve more challenging reasoning tasks. Though\nimpressive results have been achieved, there are several fundamental\nlimitations of these approaches. First, passive tree searches are not efficient\nas they usually require multiple rounds of LLM API calls to solve one single\nproblem. Moreover, passive search methods are not flexible since they need\ntask-specific program designs. Then a natural question arises: can we maintain\nthe tree-search capability of LLMs without the aid of external programs, and\ncan still generate responses that clearly demonstrate the process of a\ntree-structure search? To this end, we propose a new concept called autonomous\ntree-search ability of LLM, which can automatically generate a response\ncontaining search trajectories for the correct answer. Concretely, we perform\nsearch trajectories using capable LLM API via a fixed system prompt, allowing\nthem to perform autonomous tree-search (ATS) right out of the box. Experiments\non 4 puzzle games demonstrate our method can achieve huge improvements. The\nATS-BFS method outperforms the Chain of Thought approach by achieving an\naverage accuracy improvement of 33%. Compared to Tree of Thoughts, it requires\n65.6% or 47.7% less GPT-api cost to attain a comparable level of accuracy.\nMoreover, we have collected data using the ATS prompt method and fine-tuned\nLLaMA. This approach yield a greater improvement compared to the ones\nfine-tuned on CoT data. Specifically, it outperforms CoT-tuned LLaMAs by an\naverage of 40.6% and 38.5% for LLaMA2-7B and LLaMA2-13B, respectively.\n",
                "链接": "https://arxiv.org/abs/2310.10686"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "81190",
                "标题": "Levin Tree Search with Context Models",
                "作者": " Laurent Orseau,  Marcus Hutter,  Levi H. S. Lelis",
                "发布日期": "2023-06-28",
                "摘要": "  Levin Tree Search (LTS) is a search algorithm that makes use of a policy (a\nprobability distribution over actions) and comes with a theoretical guarantee\non the number of expansions before reaching a goal node, depending on the\nquality of the policy. This guarantee can be used as a loss function, which we\ncall the LTS loss, to optimize neural networks representing the policy\n(LTS+NN). In this work we show that the neural network can be substituted with\nparameterized context models originating from the online compression literature\n(LTS+CM). We show that the LTS loss is convex under this new model, which\nallows for using standard convex optimization tools, and obtain convergence\nguarantees to the optimal parameters in an online setting for a given set of\nsolution trajectories -- guarantees that cannot be provided for neural\nnetworks. The new LTS+CM algorithm compares favorably against LTS+NN on several\nbenchmarks: Sokoban (Boxoban), The Witness, and the 24-Sliding Tile puzzle\n(STP). The difference is particularly large on STP, where LTS+NN fails to solve\nmost of the test instances while LTS+CM solves each test instance in a fraction\nof a second. Furthermore, we show that LTS+CM is able to learn a policy that\nsolves the Rubik's cube in only a few hundred expansions, which considerably\nimproves upon previous machine learning techniques.\n",
                "链接": "https://arxiv.org/abs/2305.16945"
            },
            {
                "文章ID": "79948",
                "标题": "Automatic Model Selection with Large Language Models for Reasoning",
                "作者": " James Xu Zhao,  Yuxi Xie,  Kenji Kawaguchi,  Junxian He,  Michael Qizhe Xie",
                "发布日期": "2023-10-24",
                "摘要": "  Chain-of-Thought (CoT) and Program-Aided Language Models (PAL) represent two\ndistinct reasoning methods, each with its own strengths. CoT employs natural\nlanguage, offering flexibility and interpretability, while PAL utilizes\nprogramming language, yielding more structured and rigorous logic. We introduce\na model selection method to combine the best of both worlds by employing a\nlarge language model (LLM) to dynamically select between them. Our theoretical\nanalysis underscores the feasibility of this method, which is further\ncorroborated by empirical results. Our proposed method demonstrates significant\nperformance improvements across eight reasoning datasets with Codex, ChatGPT,\nand GPT-4. Additionally, our method is complementary to self-consistency; when\nintegrated, it can further enhance performance while significantly reducing\ncomputation costs. Moreover, we achieve new state-of-the-art results on GSM8K\nand SVAMP, with respective accuracies of 96.8% and 93.7%. Our code, data and\nprompts are available at https://github.com/XuZhao0/Model-Selection-Reasoning\n",
                "链接": "https://arxiv.org/abs/2305.14333"
            },
            {
                "文章ID": "103741",
                "标题": "Trusta: Reasoning about Assurance Cases with Formal Methods and Large\n  Language Models",
                "作者": " Zezhong Chen,  Yuxin Deng,  Wenjie Du",
                "发布日期": "2023-09-25",
                "摘要": "  Assurance cases can be used to argue for the safety of products in safety\nengineering. In safety-critical areas, the construction of assurance cases is\nindispensable. Trustworthiness Derivation Trees (TDTs) enhance assurance cases\nby incorporating formal methods, rendering it possible for automatic reasoning\nabout assurance cases. We present Trustworthiness Derivation Tree Analyzer\n(Trusta), a desktop application designed to automatically construct and verify\nTDTs. The tool has a built-in Prolog interpreter in its backend, and is\nsupported by the constraint solvers Z3 and MONA. Therefore, it can solve\nconstraints about logical formulas involving arithmetic, sets, Horn clauses\netc. Trusta also utilizes large language models to make the creation and\nevaluation of assurance cases more convenient. It allows for interactive human\nexamination and modification. We evaluated top language models like\nChatGPT-3.5, ChatGPT-4, and PaLM 2 for generating assurance cases. Our tests\nshowed a 50%-80% similarity between machine-generated and human-created cases.\nIn addition, Trusta can extract formal constraints from text in natural\nlanguages, facilitating an easier interpretation and validation process. This\nextraction is subject to human review and correction, blending the best of\nautomated efficiency with human insight. To our knowledge, this marks the first\nintegration of large language models in automatic creating and reasoning about\nassurance cases, bringing a novel approach to a traditional challenge. Through\nseveral industrial case studies, Trusta has proven to quickly find some subtle\nissues that are typically missed in manual inspection, demonstrating its\npractical value in enhancing the assurance case development process.\n",
                "链接": "https://arxiv.org/abs/2309.12941"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于通过prompt经验性研究大语言模型行为的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找多模态大模型理解和生成统一建模、端到端训练相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "76841",
                "标题": "Multi-Task End-to-End Training Improves Conversational Recommendation",
                "作者": " Naveen Ram,  Dima Kuzmin,  Ellie Ka In Chio,  Moustafa Farid Alzantot,  Santiago Ontanon,  Ambarish Jash,  Judith Yue Li",
                "发布日期": "2023-05-11",
                "摘要": "  In this paper, we analyze the performance of a multitask end-to-end\ntransformer model on the task of conversational recommendations, which aim to\nprovide recommendations based on a user's explicit preferences expressed in\ndialogue. While previous works in this area adopt complex multi-component\napproaches where the dialogue management and entity recommendation tasks are\nhandled by separate components, we show that a unified transformer model, based\non the T5 text-to-text transformer model, can perform competitively in both\nrecommending relevant items and generating conversation dialogue. We fine-tune\nour model on the ReDIAL conversational movie recommendation dataset, and create\nadditional training tasks derived from MovieLens (such as the prediction of\nmovie attributes and related movies based on an input movie), in a multitask\nlearning setting. Using a series of probe studies, we demonstrate that the\nlearned knowledge in the additional tasks is transferred to the conversational\nsetting, where each task leads to a 9%-52% increase in its related probe score.\n",
                "链接": "https://arxiv.org/abs/2305.06218"
            },
            {
                "文章ID": "75571",
                "标题": "End-to-end Training and Decoding for Pivot-based Cascaded Translation\n  Model",
                "作者": " Hao Cheng,  Meng Zhang,  Liangyou Li,  Qun Liu,  Zhihua Zhang",
                "发布日期": "2023-05-04",
                "摘要": "  Utilizing pivot language effectively can significantly improve low-resource\nmachine translation. Usually, the two translation models, source-pivot and\npivot-target, are trained individually and do not utilize the limited (source,\ntarget) parallel data. This work proposes an end-to-end training method for the\ncascaded translation model and configures an improved decoding algorithm. The\ninput of the pivot-target model is modified to weighted pivot embedding based\non the probability distribution output by the source-pivot model. This allows\nthe model to be trained end-to-end. In addition, we mitigate the inconsistency\nbetween tokens and probability distributions while using beam search in pivot\ndecoding. Experiments demonstrate that our method enhances the quality of\ntranslation.\n",
                "链接": "https://arxiv.org/abs/2305.02261"
            },
            {
                "文章ID": "5923",
                "标题": "End-to-End Training for Back-Translation with Categorical\n  Reparameterization Trick",
                "作者": " DongNyeong Heo,  Heeyoul Choi",
                "发布日期": "2023-05-03",
                "摘要": "  Back-translation is an effective semi-supervised learning framework in neural\nmachine translation (NMT). A pre-trained NMT model translates monolingual\nsentences and makes synthetic bilingual sentence pairs for the training of the\nother NMT model, and vice versa. Understanding the two NMT models as inference\nand generation models, respectively, previous works applied the training\nframework of variational auto-encoder (VAE). However, the discrete property of\ntranslated sentences prevents gradient information from flowing between the two\nNMT models. In this paper, we propose a categorical reparameterization trick\nthat makes NMT models generate differentiable sentences so that the VAE's\ntraining framework can work in the end-to-end fashion. Our experiments\ndemonstrate that our method effectively trains the NMT models and achieves\nbetter BLEU scores than the previous baseline on the datasets of the WMT\ntranslation task.\n",
                "链接": "https://arxiv.org/abs/2202.08465"
            },
            {
                "文章ID": "20742",
                "标题": "DOGE-Train: Discrete Optimization on GPU with End-to-end Training",
                "作者": " Ahmed Abbas,  Paul Swoboda",
                "发布日期": "2022-05-25",
                "摘要": "  We present a fast, scalable, data-driven approach for solving linear\nrelaxations of 0-1 integer linear programs using a graph neural network. Our\nsolver is based on the Lagrange decomposition based algorithm FastDOG (Abbas et\nal. (2022)). We make the algorithm differentiable and perform backpropagation\nthrough the dual update scheme for end-to-end training of its algorithmic\nparameters. This allows to preserve the algorithm's theoretical properties\nincluding feasibility and guaranteed non-decrease in the lower bound. Since\nFastDOG can get stuck in suboptimal fixed points, we provide additional freedom\nto our graph neural network to predict non-parametric update steps for escaping\nsuch points while maintaining dual feasibility. For training of the graph\nneural network we use an unsupervised loss and perform experiments on\nlarge-scale real world datasets. We train on smaller problems and test on\nlarger ones showing strong generalization performance with a graph neural\nnetwork comprising only around 10k parameters. Our solver achieves\nsignificantly faster performance and better dual objectives than its\nnon-learned version. In comparison to commercial solvers our learned solver\nachieves close to optimal objective values of LP relaxations and is faster by\nup to an order of magnitude on very large problems from structured prediction\nand on selected combinatorial optimization problems.\n",
                "链接": "https://arxiv.org/abs/2205.11638"
            },
            {
                "文章ID": "109808",
                "标题": "Retrieve-Cluster-Summarize: An Alternative to End-to-End Training for\n  Query-specific Article Generation",
                "作者": " Connor Lennox,  Sumanta Kashyapi,  Laura Dietz",
                "发布日期": "2023-10-20",
                "摘要": "  Query-specific article generation is the task of, given a search query,\ngenerate a single article that gives an overview of the topic. We envision such\narticles as an alternative to presenting a ranking of search results. While\ngenerative Large Language Models (LLMs) like chatGPT also address this task,\nthey are known to hallucinate new information, their models are secret, hard to\nanalyze and control. Some generative LLMs provide supporting references, yet\nthese are often unrelated to the generated content. As an alternative, we\npropose to study article generation systems that integrate document retrieval,\nquery-specific clustering, and summarization. By design, such models can\nprovide actual citations as provenance for their generated text. In particular,\nwe contribute an evaluation framework that allows to separately trains and\nevaluate each of these three components before combining them into one system.\nWe experimentally demonstrate that a system comprised of the best-performing\nindividual components also obtains the best F-1 overall system quality.\n",
                "链接": "https://arxiv.org/abs/2310.12361"
            },
            {
                "文章ID": "23737",
                "标题": "Convolutional Dictionary Learning by End-To-End Training of Iterative\n  Neural Networks",
                "作者": " Andreas Kofler,  Christian Wald,  Tobias Schaeffter,  Markus Haltmeier,  Christoph Kolbitsch",
                "发布日期": "2022-06-10",
                "摘要": "  Sparsity-based methods have a long history in the field of signal processing\nand have been successfully applied to various image reconstruction problems.\nThe involved sparsifying transformations or dictionaries are typically either\npre-trained using a model which reflects the assumed properties of the signals\nor adaptively learned during the reconstruction - yielding so-called blind\nCompressed Sensing approaches. However, by doing so, the transforms are never\nexplicitly trained in conjunction with the physical model which generates the\nsignals. In addition, properly choosing the involved regularization parameters\nremains a challenging task. Another recently emerged training-paradigm for\nregularization methods is to use iterative neural networks (INNs) - also known\nas unrolled networks - which contain the physical model. In this work, we\nconstruct an INN which can be used as a supervised and physics-informed online\nconvolutional dictionary learning algorithm. We evaluated the proposed approach\nby applying it to a realistic large-scale dynamic MR reconstruction problem and\ncompared it to several other recently published works. We show that the\nproposed INN improves over two conventional model-agnostic training methods and\nyields competitive results also compared to a deep INN. Further, it does not\nrequire to choose the regularization parameters and - in contrast to deep INNs\n- each network component is entirely interpretable.\n",
                "链接": "https://arxiv.org/abs/2206.04447"
            },
            {
                "文章ID": "122889",
                "标题": "End-to-End Training of Neural Networks for Automotive Radar Interference\n  Mitigation",
                "作者": " Christian Oswald,  Mate Toth,  Paul Meissner,  Franz Pernkopf",
                "发布日期": "2023-12-18",
                "摘要": "  In this paper we propose a new method for training neural networks (NNs) for\nfrequency modulated continuous wave (FMCW) radar mutual interference\nmitigation. Instead of training NNs to regress from interfered to clean radar\nsignals as in previous work, we train NNs directly on object detection maps. We\ndo so by performing a continuous relaxation of the cell-averaging constant\nfalse alarm rate (CA-CFAR) peak detector, which is a well-established algorithm\nfor object detection using radar. With this new training objective we are able\nto increase object detection performance by a large margin. Furthermore, we\nintroduce separable convolution kernels to strongly reduce the number of\nparameters and computational complexity of convolutional NN architectures for\nradar applications. We validate our contributions with experiments on\nreal-world measurement data and compare them against signal processing\ninterference mitigation methods.\n",
                "链接": "https://arxiv.org/abs/2312.09790"
            },
            {
                "文章ID": "8235",
                "标题": "Convolutional Analysis Operator Learning by End-To-End Training of\n  Iterative Neural Networks",
                "作者": " Andreas Kofler,  Christian Wald,  Tobias Schaeffter,  Markus Haltmeier,  Christoph Kolbitsch",
                "发布日期": "2022-03-07",
                "摘要": "  The concept of sparsity has been extensively applied for regularization in\nimage reconstruction. Typically, sparsifying transforms are either pre-trained\non ground-truth images or adaptively trained during the reconstruction.\nThereby, learning algorithms are designed to minimize some target function\nwhich encodes the desired properties of the transform. However, this procedure\nignores the subsequently employed reconstruction algorithm as well as the\nphysical model which is responsible for the image formation process. Iterative\nneural networks - which contain the physical model - can overcome these issues.\nIn this work, we demonstrate how convolutional sparsifying filters can be\nefficiently learned by end-to-end training of iterative neural networks. We\nevaluated our approach on a non-Cartesian 2D cardiac cine MRI example and show\nthat the obtained filters are better suitable for the corresponding\nreconstruction algorithm than the ones obtained by decoupled pre-training.\n",
                "链接": "https://arxiv.org/abs/2203.02166"
            },
            {
                "文章ID": "72936",
                "标题": "Understand Data Preprocessing for Effective End-to-End Training of Deep\n  Neural Networks",
                "作者": " Ping Gong,  Yuxin Ma,  Cheng Li,  Xiaosong Ma,  Sam H. Noh",
                "发布日期": "2023-04-19",
                "摘要": "  In this paper, we primarily focus on understanding the data preprocessing\npipeline for DNN Training in the public cloud. First, we run experiments to\ntest the performance implications of the two major data preprocessing methods\nusing either raw data or record files. The preliminary results show that data\npreprocessing is a clear bottleneck, even with the most efficient software and\nhardware configuration enabled by NVIDIA DALI, a high-optimized data\npreprocessing library. Second, we identify the potential causes, exercise a\nvariety of optimization methods, and present their pros and cons. We hope this\nwork will shed light on the new co-design of ``data storage, loading pipeline''\nand ``training framework'' and flexible resource configurations between them so\nthat the resources can be fully exploited and performance can be maximized.\n",
                "链接": "https://arxiv.org/abs/2304.08925"
            },
            {
                "文章ID": "106272",
                "标题": "End-to-End Training of a Neural HMM with Label and Transition\n  Probabilities",
                "作者": " Daniel Mann,  Tina Raissi,  Wilfried Michel,  Ralf Schlüter,  Hermann Ney",
                "发布日期": "2023-10-10",
                "摘要": "  We investigate a novel modeling approach for end-to-end neural network\ntraining using hidden Markov models (HMM) where the transition probabilities\nbetween hidden states are modeled and learned explicitly. Most contemporary\nsequence-to-sequence models allow for from-scratch training by summing over all\npossible label segmentations in a given topology. In our approach there are\nexplicit, learnable probabilities for transitions between segments as opposed\nto a blank label that implicitly encodes duration statistics. We implement a\nGPU-based forward-backward algorithm that enables the simultaneous training of\nlabel and transition probabilities. We investigate recognition results and\nadditionally Viterbi alignments of our models. We find that while the\ntransition model training does not improve recognition performance, it has a\npositive impact on the alignment quality. The generated alignments are shown to\nbe viable targets in state-of-the-art Viterbi trainings.\n",
                "链接": "https://arxiv.org/abs/2310.02724"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近两年关于语言模型奖励建模评估的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105659",
                "标题": "Tool-Augmented Reward Modeling",
                "作者": " Lei Li,  Yekun Chai,  Shuohuan Wang,  Yu Sun,  Hao Tian,  Ningyu Zhang,  Hua Wu",
                "发布日期": "2023-10-03",
                "摘要": "  Reward modeling (a.k.a., preference modeling) is instrumental for aligning\nlarge language models with human preferences, particularly within the context\nof reinforcement learning from human feedback (RLHF). While conventional reward\nmodels (RMs) have exhibited remarkable scalability, they oft struggle with\nfundamental functionality such as arithmetic computation, code execution, and\nfactual lookup. In this paper, we propose a tool-augmented preference modeling\napproach, named \\name, to address these limitations by empowering RMs with\naccess to external environments, including calculators and search engines. This\napproach not only fosters synergy between tool utilization and reward grading\nbut also enhances interpretive capacity and scoring reliability. Our study\ndelves into the integration of external tools into RMs, enabling them to\ninteract with diverse external sources and construct task-specific tool\nengagement and reasoning traces in an autoregressive manner. We validate our\napproach across a wide range of domains, incorporating seven distinct external\ntools. Our experimental results demonstrate a noteworthy overall improvement of\n17.7% across eight tasks in preference ranking. Furthermore, our approach\noutperforms Gopher 280B by 7.3% on TruthfulQA task in zero-shot evaluation. In\nhuman evaluations, RLHF trained with Themis attains an average win rate of 32%\nwhen compared to baselines across four distinct tasks. Additionally, we provide\na comprehensive collection of tool-related RM datasets, incorporating data from\nseven distinct tool APIs, totaling 15,000 instances. We anticipate that this\npublicly available dataset will facilitate and inspire further research\nadvancements in the field.\n",
                "链接": "https://arxiv.org/abs/2310.01045"
            },
            {
                "文章ID": "6241",
                "标题": "Reward Modeling for Mitigating Toxicity in Transformer-based Language\n  Models",
                "作者": " Farshid Faal,  Ketra Schmitt,  Jia Yuan Yu",
                "发布日期": "2022-07-28",
                "摘要": "  Transformer-based language models are able to generate fluent text and be\nefficiently adapted across various natural language generation tasks. However,\nlanguage models that are pretrained on large unlabeled web text corpora have\nbeen shown to suffer from degenerating toxic content and social bias behaviors,\nconsequently hindering their safe deployment. Various detoxification methods\nwere proposed to mitigate the language model's toxicity; however, these methods\nstruggled to detoxify language models when conditioned on prompts that contain\nspecific social identities related to gender, race, or religion. In this study,\nwe propose Reinforce-Detoxify; A reinforcement learning-based method for\nmitigating toxicity in language models. We address the challenge of safety in\nlanguage models and propose a new reward model that is able to detect toxic\ncontent and mitigate unintended bias towards social identities in toxicity\nprediction. The experiments demonstrate that the Reinforce-Detoxify method for\nlanguage model detoxification outperforms existing detoxification approaches in\nautomatic evaluation metrics, indicating the ability of our approach in\nlanguage model detoxification and less prone to unintended bias toward social\nidentities in generated content.\n",
                "链接": "https://arxiv.org/abs/2202.09662"
            },
            {
                "文章ID": "81738",
                "标题": "Direct Preference Optimization: Your Language Model is Secretly a Reward\n  Model",
                "作者": " Rafael Rafailov,  Archit Sharma,  Eric Mitchell,  Stefano Ermon,  Christopher D. Manning,  Chelsea Finn",
                "发布日期": "2023-12-14",
                "摘要": "  While large-scale unsupervised language models (LMs) learn broad world\nknowledge and some reasoning skills, achieving precise control of their\nbehavior is difficult due to the completely unsupervised nature of their\ntraining. Existing methods for gaining such steerability collect human labels\nof the relative quality of model generations and fine-tune the unsupervised LM\nto align with these preferences, often with reinforcement learning from human\nfeedback (RLHF). However, RLHF is a complex and often unstable procedure, first\nfitting a reward model that reflects the human preferences, and then\nfine-tuning the large unsupervised LM using reinforcement learning to maximize\nthis estimated reward without drifting too far from the original model. In this\npaper we introduce a new parameterization of the reward model in RLHF that\nenables extraction of the corresponding optimal policy in closed form, allowing\nus to solve the standard RLHF problem with only a simple classification loss.\nThe resulting algorithm, which we call Direct Preference Optimization (DPO), is\nstable, performant, and computationally lightweight, eliminating the need for\nsampling from the LM during fine-tuning or performing significant\nhyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align\nwith human preferences as well as or better than existing methods. Notably,\nfine-tuning with DPO exceeds PPO-based RLHF in ability to control sentiment of\ngenerations, and matches or improves response quality in summarization and\nsingle-turn dialogue while being substantially simpler to implement and train.\n",
                "链接": "https://arxiv.org/abs/2305.18290"
            },
            {
                "文章ID": "110451",
                "标题": "Learning Reward for Physical Skills using Large Language Model",
                "作者": " Yuwei Zeng,  Yiqing Xu",
                "发布日期": "2023-10-24",
                "摘要": "  Learning reward functions for physical skills are challenging due to the vast\nspectrum of skills, the high-dimensionality of state and action space, and\nnuanced sensory feedback. The complexity of these tasks makes acquiring expert\ndemonstration data both costly and time-consuming. Large Language Models (LLMs)\ncontain valuable task-related knowledge that can aid in learning these reward\nfunctions. However, the direct application of LLMs for proposing reward\nfunctions has its limitations such as numerical instability and inability to\nincorporate the environment feedback. We aim to extract task knowledge from\nLLMs using environment feedback to create efficient reward functions for\nphysical skills. Our approach consists of two components. We first use the LLM\nto propose features and parameterization of the reward function. Next, we\nupdate the parameters of this proposed reward function through an iterative\nself-alignment process. In particular, this process minimizes the ranking\ninconsistency between the LLM and our learned reward functions based on the new\nobservations. We validated our method by testing it on three simulated physical\nskill learning tasks, demonstrating effective support for our design choices.\n",
                "链接": "https://arxiv.org/abs/2310.14092"
            },
            {
                "文章ID": "40287",
                "标题": "Reward Learning with Trees: Methods and Evaluation",
                "作者": " Tom Bewley,  Jonathan Lawry,  Arthur Richards,  Rachel Craddock,  Ian Henderson",
                "发布日期": "2022-10-04",
                "摘要": "  Recent efforts to learn reward functions from human feedback have tended to\nuse deep neural networks, whose lack of transparency hampers our ability to\nexplain agent behaviour or verify alignment. We explore the merits of learning\nintrinsically interpretable tree models instead. We develop a recently proposed\nmethod for learning reward trees from preference labels, and show it to be\nbroadly competitive with neural networks on challenging high-dimensional tasks,\nwith good robustness to limited or corrupted data. Having found that reward\ntree learning can be done effectively in complex settings, we then consider why\nit should be used, demonstrating that the interpretable reward structure gives\nsignificant scope for traceability, verification and explanation.\n",
                "链接": "https://arxiv.org/abs/2210.01007"
            },
            {
                "文章ID": "58975",
                "标题": "Direct Preference-based Policy Optimization without Reward Modeling",
                "作者": " Gaon An,  Junhyeok Lee,  Xingdong Zuo,  Norio Kosaka,  Kyung-Min Kim,  Hyun Oh Song",
                "发布日期": "2023-10-30",
                "摘要": "  Preference-based reinforcement learning (PbRL) is an approach that enables RL\nagents to learn from preference, which is particularly useful when formulating\na reward function is challenging. Existing PbRL methods generally involve a\ntwo-step procedure: they first learn a reward model based on given preference\ndata and then employ off-the-shelf reinforcement learning algorithms using the\nlearned reward model. However, obtaining an accurate reward model solely from\npreference information, especially when the preference is from human teachers,\ncan be difficult. Instead, we propose a PbRL algorithm that directly learns\nfrom preference without requiring any reward modeling. To achieve this, we\nadopt a contrastive learning framework to design a novel policy scoring metric\nthat assigns a high score to policies that align with the given preferences. We\napply our algorithm to offline RL tasks with actual human preference labels and\nshow that our algorithm outperforms or is on par with the existing PbRL\nmethods. Notably, on high-dimensional control tasks, our algorithm surpasses\noffline RL methods that learn with ground-truth reward information. Finally, we\nshow that our algorithm can be successfully applied to fine-tune large language\nmodels.\n",
                "链接": "https://arxiv.org/abs/2301.12842"
            },
            {
                "文章ID": "59850",
                "标题": "Controlling for Stereotypes in Multimodal Language Model Evaluation",
                "作者": " Manuj Malik,  Richard Johansson",
                "发布日期": "2023-02-06",
                "摘要": "  We propose a methodology and design two benchmark sets for measuring to what\nextent language-and-vision language models use the visual signal in the\npresence or absence of stereotypes. The first benchmark is designed to test for\nstereotypical colors of common objects, while the second benchmark considers\ngender stereotypes. The key idea is to compare predictions when the image\nconforms to the stereotype to predictions when it does not.\n  Our results show that there is significant variation among multimodal models:\nthe recent Transformer-based FLAVA seems to be more sensitive to the choice of\nimage and less affected by stereotypes than older CNN-based models such as\nVisualBERT and LXMERT. This effect is more discernible in this type of\ncontrolled setting than in traditional evaluations where we do not know whether\nthe model relied on the stereotype or the visual signal.\n",
                "链接": "https://arxiv.org/abs/2302.01582"
            },
            {
                "文章ID": "109754",
                "标题": "Pseudointelligence: A Unifying Framework for Language Model Evaluation",
                "作者": " Shikhar Murty,  Orr Paradise,  Pratyusha Sharma",
                "发布日期": "2023-10-19",
                "摘要": "  With large language models surpassing human performance on an increasing\nnumber of benchmarks, we must take a principled approach for targeted\nevaluation of model capabilities. Inspired by pseudorandomness, we propose\npseudointelligence, which captures the maxim that \"(perceived) intelligence\nlies in the eye of the beholder\". That is, that claims of intelligence are\nmeaningful only when their evaluator is taken into account. Concretely, we\npropose a complexity-theoretic framework of model evaluation cast as a dynamic\ninteraction between a model and a learned evaluator. We demonstrate that this\nframework can be used to reason about two case studies in language model\nevaluation, as well as analyze existing evaluation methods.\n",
                "链接": "https://arxiv.org/abs/2310.12135"
            },
            {
                "文章ID": "64063",
                "标题": "Reward Design with Language Models",
                "作者": " Minae Kwon,  Sang Michael Xie,  Kalesha Bullard,  Dorsa Sadigh",
                "发布日期": "2023-03-02",
                "摘要": "  Reward design in reinforcement learning (RL) is challenging since specifying\nhuman notions of desired behavior may be difficult via reward functions or\nrequire many expert demonstrations. Can we instead cheaply design rewards using\na natural language interface? This paper explores how to simplify reward design\nby prompting a large language model (LLM) such as GPT-3 as a proxy reward\nfunction, where the user provides a textual prompt containing a few examples\n(few-shot) or a description (zero-shot) of the desired behavior. Our approach\nleverages this proxy reward function in an RL framework. Specifically, users\nspecify a prompt once at the beginning of training. During training, the LLM\nevaluates an RL agent's behavior against the desired behavior described by the\nprompt and outputs a corresponding reward signal. The RL agent then uses this\nreward to update its behavior. We evaluate whether our approach can train\nagents aligned with user objectives in the Ultimatum Game, matrix games, and\nthe DealOrNoDeal negotiation task. In all three tasks, we show that RL agents\ntrained with our framework are well-aligned with the user's objectives and\noutperform RL agents trained with reward functions learned via supervised\nlearning\n",
                "链接": "https://arxiv.org/abs/2303.00001"
            },
            {
                "文章ID": "53814",
                "标题": "Attributed Question Answering: Evaluation and Modeling for Attributed\n  Large Language Models",
                "作者": " Bernd Bohnet,  Vinh Q. Tran,  Pat Verga,  Roee Aharoni,  Daniel Andor,  Livio Baldini Soares,  Massimiliano Ciaramita,  Jacob Eisenstein,  Kuzman Ganchev,  Jonathan Herzig,  Kai Hui,  Tom Kwiatkowski,  Ji Ma,  Jianmo Ni,  Lierni Sestorain Saralegui,  Tal Schuster,  William W. Cohen,  Michael Collins,  Dipanjan Das,  Donald Metzler,  Slav Petrov,  Kellie Webster",
                "发布日期": "2023-02-14",
                "摘要": "  Large language models (LLMs) have shown impressive results while requiring\nlittle or no direct supervision. Further, there is mounting evidence that LLMs\nmay have potential in information-seeking scenarios. We believe the ability of\nan LLM to attribute the text that it generates is likely to be crucial in this\nsetting. We formulate and study Attributed QA as a key first step in the\ndevelopment of attributed LLMs. We propose a reproducible evaluation framework\nfor the task and benchmark a broad set of architectures. We take human\nannotations as a gold standard and show that a correlated automatic metric is\nsuitable for development. Our experimental work gives concrete answers to two\nkey questions (How to measure attribution?, and How well do current\nstate-of-the-art methods perform on attribution?), and give some hints as to\nhow to address a third (How to build LLMs with attribution?).\n",
                "链接": "https://arxiv.org/abs/2212.08037"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到从位置编码角度改善模型长序列建模能力的相关论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "106847",
                "标题": "Functional Interpolation for Relative Positions Improves Long Context\n  Transformers",
                "作者": " Shanda Li,  Chong You,  Guru Guruganesh,  Joshua Ainslie,  Santiago Ontanon,  Manzil Zaheer,  Sumit Sanghai,  Yiming Yang,  Sanjiv Kumar,  Srinadh Bhojanapalli",
                "发布日期": "2023-10-09",
                "摘要": "  Preventing the performance decay of Transformers on inputs longer than those\nused for training has been an important challenge in extending the context\nlength of these models. Though the Transformer architecture has fundamentally\nno limits on the input sequence lengths it can process, the choice of position\nencoding used during training can limit the performance of these models on\nlonger inputs. We propose a novel functional relative position encoding with\nprogressive interpolation, FIRE, to improve Transformer generalization to\nlonger contexts. We theoretically prove that this can represent some of the\npopular relative position encodings, such as T5's RPE, Alibi, and Kerple. We\nnext empirically show that FIRE models have better generalization to longer\ncontexts on both zero-shot language modeling and long text benchmarks.\n",
                "链接": "https://arxiv.org/abs/2310.04418"
            },
            {
                "文章ID": "9782",
                "标题": "Efficient Long Sequence Encoding via Synchronization",
                "作者": " Xiangyang Mou,  Mo Yu,  Bingsheng Yao,  Lifu Huang",
                "发布日期": "2022-03-16",
                "摘要": "  Pre-trained Transformer models have achieved successes in a wide range of NLP\ntasks, but are inefficient when dealing with long input sequences. Existing\nstudies try to overcome this challenge via segmenting the long sequence\nfollowed by hierarchical encoding or post-hoc aggregation. We propose a\nsynchronization mechanism for hierarchical encoding. Our approach first\nidentifies anchor tokens across segments and groups them by their roles in the\noriginal input sequence. Then inside Transformer layer, anchor embeddings are\nsynchronized within their group via a self-attention module. Our approach is a\ngeneral framework with sufficient flexibility -- when adapted to a new task, it\nis easy to be enhanced with the task-specific anchor definitions. Experiments\non two representative tasks with different types of long input texts,\nNarrativeQA summary setting and wild multi-hop reasoning from HotpotQA,\ndemonstrate that our approach is able to improve the global information\nexchange among segments while maintaining efficiency.\n",
                "链接": "https://arxiv.org/abs/2203.07644"
            },
            {
                "文章ID": "76364",
                "标题": "Toeplitz Neural Network for Sequence Modeling",
                "作者": " Zhen Qin,  Xiaodong Han,  Weixuan Sun,  Bowen He,  Dong Li,  Dongxu Li,  Yuchao Dai,  Lingpeng Kong,  Yiran Zhong",
                "发布日期": "2023-05-09",
                "摘要": "  Sequence modeling has important applications in natural language processing\nand computer vision. Recently, the transformer-based models have shown strong\nperformance on various sequence modeling tasks, which rely on attention to\ncapture pairwise token relations, and position embedding to inject positional\ninformation. While showing good performance, the transformer models are\ninefficient to scale to long input sequences, mainly due to the quadratic\nspace-time complexity of attention. To overcome this inefficiency, we propose\nto model sequences with a relative position encoded Toeplitz matrix and use a\nToeplitz matrix-vector production trick to reduce the space-time complexity of\nthe sequence modeling to log linear. A lightweight sub-network called relative\nposition encoder is proposed to generate relative position coefficients with a\nfixed budget of parameters, enabling the proposed Toeplitz neural network to\ndeal with varying sequence lengths. In addition, despite being trained on\n512-token sequences, our model can extrapolate input sequence length up to 14K\ntokens in inference with consistent performance. Extensive experiments on\nautoregressive and bidirectional language modeling, image modeling, and the\nchallenging Long-Range Arena benchmark show that our method achieves better\nperformance than its competitors in most downstream tasks while being\nsignificantly faster. The code is available at\nhttps://github.com/OpenNLPLab/Tnn.\n",
                "链接": "https://arxiv.org/abs/2305.04749"
            },
            {
                "文章ID": "42698",
                "标题": "CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling",
                "作者": " Jun Zhang,  Shuyang Jiang,  Jiangtao Feng,  Lin Zheng,  Lingpeng Kong",
                "发布日期": "2023-07-04",
                "摘要": "  Transformer has achieved remarkable success in language, image, and speech\nprocessing. Recently, various efficient attention architectures have been\nproposed to improve transformer's efficiency while largely preserving its\nefficacy, especially in modeling long sequences. A widely-used benchmark to\ntest these efficient methods' capability on long-range modeling is Long Range\nArena (LRA). However, LRA only focuses on the standard bidirectional (or\nnoncausal) self attention, and completely ignores cross attentions and\nunidirectional (or causal) attentions, which are equally important to\ndownstream applications. In this paper, we propose Comprehensive Attention\nBenchmark (CAB) under a fine-grained attention taxonomy with four\ndistinguishable attention patterns, namely, noncausal self, causal self,\nnoncausal cross, and causal cross attentions. CAB collects seven real-world\ntasks from different research areas to evaluate efficient attentions under the\nfour attention patterns. Among these tasks, CAB validates efficient attentions\nin eight backbone networks to show their generalization across neural\narchitectures. We conduct exhaustive experiments to benchmark the performances\nof nine widely-used efficient attention architectures designed with different\nphilosophies on CAB. Extensive experimental results also shed light on the\nfundamental problems of efficient attentions, such as efficiency length against\nvanilla attention, performance consistency across attention patterns, the\nbenefit of attention mechanisms, and interpolation/extrapolation on\nlong-context language modeling.\n",
                "链接": "https://arxiv.org/abs/2210.07661"
            },
            {
                "文章ID": "106867",
                "标题": "Spherical Position Encoding for Transformers",
                "作者": " Eren Unlu",
                "发布日期": "2023-10-10",
                "摘要": "  Position encoding is the primary mechanism which induces notion of sequential\norder for input tokens in transformer architectures. Even though this\nformulation in the original transformer paper has yielded plausible performance\nfor general purpose language understanding and generation, several new\nframeworks such as Rotary Position Embedding (RoPE) are proposed for further\nenhancement. In this paper, we introduce the notion of \"geotokens\" which are\ninput elements for transformer architectures, each representing an information\nrelated to a geological location. Unlike the natural language the sequential\nposition is not important for the model but the geographical coordinates are.\nIn order to induce the concept of relative position for such a setting and\nmaintain the proportion between the physical distance and distance on embedding\nspace, we formulate a position encoding mechanism based on RoPE architecture\nwhich is adjusted for spherical coordinates.\n",
                "链接": "https://arxiv.org/abs/2310.04454"
            },
            {
                "文章ID": "40615",
                "标题": "WavSpA: Wavelet Space Attention for Boosting Transformers' Long Sequence\n  Learning Ability",
                "作者": " Yufan Zhuang,  Zihan Wang,  Fangbo Tao,  Jingbo Shang",
                "发布日期": "2023-05-24",
                "摘要": "  Transformer and its variants are fundamental neural architectures in deep\nlearning. Recent works show that learning attention in the Fourier space can\nimprove the long sequence learning capability of Transformers. We argue that\nwavelet transform shall be a better choice because it captures both position\nand frequency information with linear time complexity. Therefore, in this\npaper, we systematically study the synergy between wavelet transform and\nTransformers. We propose Wavelet Space Attention (WavSpA) that facilitates\nattention learning in a learnable wavelet coefficient space which replaces the\nattention in Transformers by (1) applying forward wavelet transform to project\nthe input sequences to multi-resolution bases, (2) conducting attention\nlearning in the wavelet coefficient space, and (3) reconstructing the\nrepresentation in input space via backward wavelet transform. Extensive\nexperiments on the Long Range Arena demonstrate that learning attention in the\nwavelet space using either fixed or adaptive wavelets can consistently improve\nTransformer's performance and also significantly outperform learning in Fourier\nspace. We further show our method can enhance Transformer's reasoning\nextrapolation capability over distance on the LEGO chain-of-reasoning task.\n",
                "链接": "https://arxiv.org/abs/2210.01989"
            },
            {
                "文章ID": "125279",
                "标题": "Length Extrapolation of Transformers: A Survey from the Perspective of\n  Position Encoding",
                "作者": " Liang Zhao,  Xiaocheng Feng,  Xiachong Feng,  Bin Qin,  Ting Liu",
                "发布日期": "2023-12-29",
                "摘要": "  Transformer has taken the natural language processing (NLP) field by storm\nsince birth, owing to its superior ability to model complex dependencies in\nsequences. Despite the great success of pretrained language models (PLMs) based\non Transformer across almost all NLP tasks, they all suffer from a preset\nlength limit and thus can hardly extend this success to longer sequences beyond\nseen data, namely the length extrapolation problem. Length extrapolation has\naroused great interest among researchers, as it is the core feature of human\nlanguage capacity. To enhance length extrapolation of Transformers, a plethora\nof methods have been proposed, mostly focusing on extrapolatable position\nencodings. In this article, we provide an organized and systematical review of\nthese research efforts in a unified notation from a position encoding\nperspective, aiming to enable the reader to gain a deep understanding of\nexisting methods and provide stimuli for future research.\n",
                "链接": "https://arxiv.org/abs/2312.17044"
            },
            {
                "文章ID": "88526",
                "标题": "A Formal Perspective on Byte-Pair Encoding",
                "作者": " Vilém Zouhar,  Clara Meister,  Juan Luis Gastaldi,  Li Du,  Tim Vieira,  Mrinmaya Sachan,  Ryan Cotterell",
                "发布日期": "2023-06-30",
                "摘要": "  Byte-Pair Encoding (BPE) is a popular algorithm used for tokenizing data in\nNLP, despite being devised initially as a compression method. BPE appears to be\na greedy algorithm at face value, but the underlying optimization problem that\nBPE seeks to solve has not yet been laid down. We formalize BPE as a\ncombinatorial optimization problem. Via submodular functions, we prove that the\niterative greedy version is a\n$\\frac{1}{{\\sigma(\\boldsymbol{\\mu}^\\star)}}(1-e^{-{\\sigma(\\boldsymbol{\\mu}^\\star)}})$-approximation\nof an optimal merge sequence, where ${\\sigma(\\boldsymbol{\\mu}^\\star)}$ is the\ntotal backward curvature with respect to the optimal merge sequence\n$\\boldsymbol{\\mu}^\\star$. Empirically the lower bound of the approximation is\n$\\approx 0.37$.\n  We provide a faster implementation of BPE which improves the runtime\ncomplexity from $\\mathcal{O}\\left(N M\\right)$ to $\\mathcal{O}\\left(N \\log\nM\\right)$, where $N$ is the sequence length and $M$ is the merge count.\nFinally, we optimize the brute-force algorithm for optimal BPE using\nmemoization.\n",
                "链接": "https://arxiv.org/abs/2306.16837"
            },
            {
                "文章ID": "98132",
                "标题": "Instruction Position Matters in Sequence Generation with Large Language\n  Models",
                "作者": " Yijin Liu,  Xianfeng Zeng,  Fandong Meng,  Jie Zhou",
                "发布日期": "2023-08-24",
                "摘要": "  Large language models (LLMs) are capable of performing conditional sequence\ngeneration tasks, such as translation or summarization, through instruction\nfine-tuning. The fine-tuning data is generally sequentially concatenated from a\nspecific task instruction, an input sentence, and the corresponding response.\nConsidering the locality modeled by the self-attention mechanism of LLMs, these\nmodels face the risk of instruction forgetting when generating responses for\nlong input sentences. To mitigate this issue, we propose enhancing the\ninstruction-following capability of LLMs by shifting the position of task\ninstructions after the input sentences. Theoretical analysis suggests that our\nstraightforward method can alter the model's learning focus, thereby\nemphasizing the training of instruction-following capabilities. Concurrently,\nexperimental results demonstrate that our approach consistently outperforms\ntraditional settings across various model scales (1B / 7B / 13B) and different\nsequence generation tasks (translation and summarization), without any\nadditional data or annotation costs. Notably, our method significantly improves\nthe zero-shot performance on conditional sequence generation, e.g., up to 9.7\nBLEU points on WMT zero-shot translation tasks.\n",
                "链接": "https://arxiv.org/abs/2308.12097"
            },
            {
                "文章ID": "75898",
                "标题": "HiPool: Modeling Long Documents Using Graph Neural Networks",
                "作者": " Irene Li,  Aosong Feng,  Dragomir Radev,  Rex Ying",
                "发布日期": "2023-05-16",
                "摘要": "  Encoding long sequences in Natural Language Processing (NLP) is a challenging\nproblem. Though recent pretraining language models achieve satisfying\nperformances in many NLP tasks, they are still restricted by a pre-defined\nmaximum length, making them challenging to be extended to longer sequences. So\nsome recent works utilize hierarchies to model long sequences. However, most of\nthem apply sequential models for upper hierarchies, suffering from long\ndependency issues. In this paper, we alleviate these issues through a\ngraph-based method. We first chunk the sequence with a fixed length to model\nthe sentence-level information. We then leverage graphs to model intra- and\ncross-sentence correlations with a new attention mechanism. Additionally, due\nto limited standard benchmarks for long document classification (LDC), we\npropose a new challenging benchmark, totaling six datasets with up to 53k\nsamples and 4034 average tokens' length. Evaluation shows our model surpasses\ncompetitive baselines by 2.6% in F1 score, and 4.8% on the longest sequence\ndataset. Our method is shown to outperform hierarchical sequential models with\nbetter performance and scalability, especially for longer sequences.\n",
                "链接": "https://arxiv.org/abs/2305.03319"
            }
        ]
    },
    {
        "question": {
            "question": "利用大模型做数学题生成的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "94507",
                "标题": "Reasoning in Large Language Models Through Symbolic Math Word Problems",
                "作者": " Vedant Gaur,  Nikunj Saunshi",
                "发布日期": "2023-08-04",
                "摘要": "  Large language models (LLMs) have revolutionized NLP by solving downstream\ntasks with little to no labeled data. Despite their versatile abilities, the\nlarger question of their ability to reason remains ill-understood. This paper\naddresses reasoning in math word problems (MWPs) by studying symbolic versions\nof the numeric problems, since a symbolic expression is a \"concise explanation\"\nof the numeric answer. We create and use a symbolic version of the SVAMP\ndataset and find that GPT-3's davinci-002 model also has good zero-shot\naccuracy on symbolic MWPs. To evaluate the faithfulness of the model's\nreasoning, we go beyond accuracy and additionally evaluate the alignment\nbetween the final answer and the outputted reasoning, which correspond to\nnumeric and symbolic answers respectively for MWPs. We explore a self-prompting\napproach to encourage the symbolic reasoning to align with the numeric answer,\nthus equipping the LLM with the ability to provide a concise and verifiable\nreasoning and making it more interpretable. Surprisingly, self-prompting also\nimproves the symbolic accuracy to be higher than both the numeric and symbolic\naccuracies, thus providing an ensembling effect. The SVAMP_Sym dataset will be\nreleased for future research on symbolic math problems.\n",
                "链接": "https://arxiv.org/abs/2308.01906"
            },
            {
                "文章ID": "84264",
                "标题": "World Models for Math Story Problems",
                "作者": " Andreas Opedal,  Niklas Stoehr,  Abulhair Saparov,  Mrinmaya Sachan",
                "发布日期": "2023-06-08",
                "摘要": "  Solving math story problems is a complex task for students and NLP models\nalike, requiring them to understand the world as described in the story and\nreason over it to compute an answer. Recent years have seen impressive\nperformance on automatically solving these problems with large pre-trained\nlanguage models and innovative techniques to prompt them. However, it remains\nunclear if these models possess accurate representations of mathematical\nconcepts. This leads to lack of interpretability and trustworthiness which\nimpedes their usefulness in various applications. In this paper, we consolidate\nprevious work on categorizing and representing math story problems and develop\nMathWorld, which is a graph-based semantic formalism specific for the domain of\nmath story problems. With MathWorld, we can assign world models to math story\nproblems which represent the situations and actions introduced in the text and\ntheir mathematical relationships. We combine math story problems from several\nexisting datasets and annotate a corpus of 1,019 problems and 3,204 logical\nforms with MathWorld. Using this data, we demonstrate the following use cases\nof MathWorld: (1) prompting language models with synthetically generated\nquestion-answer pairs to probe their reasoning and world modeling abilities,\nand (2) generating new problems by using the world models as a design space.\n",
                "链接": "https://arxiv.org/abs/2306.04347"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            },
            {
                "文章ID": "119955",
                "标题": "ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating\n  Pre-university Math Questions",
                "作者": " Phuoc Pham Van Long,  Duc Anh Vu,  Nhat M. Hoang,  Xuan Long Do,  Anh Tuan Luu",
                "发布日期": "2023-12-05",
                "摘要": "  Mathematical questioning is crucial for assessing students problem-solving\nskills. Since manually creating such questions requires substantial effort,\nautomatic methods have been explored. Existing state-of-the-art models rely on\nfine-tuning strategies and struggle to generate questions that heavily involve\nmultiple steps of logical and arithmetic reasoning. Meanwhile, large language\nmodels(LLMs) such as ChatGPT have excelled in many NLP tasks involving logical\nand arithmetic reasoning. Nonetheless, their applications in generating\neducational questions are underutilized, especially in the field of\nmathematics. To bridge this gap, we take the first step to conduct an in-depth\nanalysis of ChatGPT in generating pre-university math questions. Our analysis\nis categorized into two main settings: context-aware and context-unaware. In\nthe context-aware setting, we evaluate ChatGPT on existing math\nquestion-answering benchmarks covering elementary, secondary, and ternary\nclasses. In the context-unaware setting, we evaluate ChatGPT in generating math\nquestions for each lesson from pre-university math curriculums that we crawl.\nOur crawling results in TopicMath, a comprehensive and novel collection of\npre-university math curriculums collected from 121 math topics and 428 lessons\nfrom elementary, secondary, and tertiary classes. Through this analysis, we aim\nto provide insight into the potential of ChatGPT as a math questioner.\n",
                "链接": "https://arxiv.org/abs/2312.01661"
            },
            {
                "文章ID": "91485",
                "标题": "A mixed policy to improve performance of language models on math\n  problems",
                "作者": " Gang Chen",
                "发布日期": "2023-07-19",
                "摘要": "  When to solve math problems, most language models take a sampling strategy to\npredict next word according conditional probabilities. In the math reasoning\nstep, it may generate wrong answer. Considering math problems are\ndeterministic, we propose a mixed policy exploration approach to solve math\nproblems with reinforcement learning. In peculiar, we propose a two level token\nexploration policy: the abstract level explores next token with probability and\nthe second level is deterministic. Specifically, the abstract level policy will\ndecide whether the token is operator or operand with probability sampling,\nwhile the second level is deterministic to select next token with the highest\nscore in a greedy way. We test our method on GSM8K dataset with GPT-2 model,\nand demonstrate more than $2\\%$ performance gain. Our implementation is\navailable at https://github.com/vividitytech/math_lm_rl.\n",
                "链接": "https://arxiv.org/abs/2307.08767"
            },
            {
                "文章ID": "75161",
                "标题": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
                "作者": " Eddie Guo,  Mehul Gupta,  Jiawen Deng,  Ye-Jean Park,  Mike Paget,  Christopher Naugler",
                "发布日期": "2023-10-09",
                "摘要": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
                "链接": "https://arxiv.org/abs/2305.00844"
            },
            {
                "文章ID": "108984",
                "标题": "Improving Large Language Model Fine-tuning for Solving Math Problems",
                "作者": " Yixin Liu,  Avi Singh,  C. Daniel Freeman,  John D. Co-Reyes,  Peter J. Liu",
                "发布日期": "2023-10-17",
                "摘要": "  Despite their success in many natural language tasks, solving math problems\nremains a significant challenge for large language models (LLMs). A large gap\nexists between LLMs' pass-at-one and pass-at-N performance in solving math\nproblems, suggesting LLMs might be close to finding correct solutions,\nmotivating our exploration of fine-tuning methods to unlock LLMs' performance.\nUsing the challenging MATH dataset, we investigate three fine-tuning\nstrategies: (1) solution fine-tuning, where we fine-tune to generate a detailed\nsolution for a given math problem; (2) solution-cluster re-ranking, where the\nLLM is fine-tuned as a solution verifier/evaluator to choose among generated\ncandidate solution clusters; (3) multi-task sequential fine-tuning, which\nintegrates both solution generation and evaluation tasks together efficiently\nto enhance the LLM performance. With these methods, we present a thorough\nempirical study on a series of PaLM 2 models and find: (1) The quality and\nstyle of the step-by-step solutions used for fine-tuning can make a significant\nimpact on the model performance; (2) While solution re-ranking and majority\nvoting are both effective for improving the model performance when used\nseparately, they can also be used together for an even greater performance\nboost; (3) Multi-task fine-tuning that sequentially separates the solution\ngeneration and evaluation tasks can offer improved performance compared with\nthe solution fine-tuning baseline. Guided by these insights, we design a\nfine-tuning recipe that yields approximately 58.8% accuracy on the MATH dataset\nwith fine-tuned PaLM 2-L models, an 11.2% accuracy improvement over the\nfew-shot performance of pre-trained PaLM 2-L model with majority voting.\n",
                "链接": "https://arxiv.org/abs/2310.10047"
            },
            {
                "文章ID": "45726",
                "标题": "Solving Math Word Problems via Cooperative Reasoning induced Language\n  Models",
                "作者": " Xinyu Zhu,  Junjie Wang,  Lin Zhang,  Yuxiang Zhang,  Yongfeng Huang,  Ruyi Gan,  Jiaxing Zhang,  Yujiu Yang",
                "发布日期": "2023-08-11",
                "摘要": "  Large-scale pre-trained language models (PLMs) bring new opportunities to\nchallenging problems, especially those that need high-level intelligence, such\nas the math word problem (MWPs). However, directly applying existing PLMs to\nMWPs can fail as the generation process lacks sufficient supervision and thus\nlacks fast adaptivity as humans. We notice that human reasoning has a dual\nreasoning framework that consists of an immediate reaction system (system 1)\nand a delicate reasoning system (system 2), where the entire reasoning is\ndetermined by their interaction. This inspires us to develop a cooperative\nreasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe),\nresulting in a human-like reasoning architecture with system 1 as the generator\nand system 2 as the verifier. In our approach, the generator is responsible for\ngenerating reasoning paths, and the verifiers are used to supervise the\nevaluation in order to obtain reliable feedback for the generator. We evaluate\nour CoRe framework on several mathematical reasoning datasets and achieve\ndecent improvement over state-of-the-art methods, up to 9.6% increase over best\nbaselines. Our codes are available at https://github.com/TianHongZXY/CoRe\n",
                "链接": "https://arxiv.org/abs/2210.16257"
            },
            {
                "文章ID": "98401",
                "标题": "Diagnosing Infeasible Optimization Problems Using Large Language Models",
                "作者": " Hao Chen,  Gonzalo E. Constante-Flores,  Can Li",
                "发布日期": "2023-08-25",
                "摘要": "  Decision-making problems can be represented as mathematical optimization\nmodels, finding wide applications in fields such as economics, engineering and\nmanufacturing, transportation, and health care. Optimization models are\nmathematical abstractions of the problem of making the best decision while\nsatisfying a set of requirements or constraints. One of the primary barriers to\ndeploying these models in practice is the challenge of helping practitioners\nunderstand and interpret such models, particularly when they are infeasible,\nmeaning no decision satisfies all the constraints. Existing methods for\ndiagnosing infeasible optimization models often rely on expert systems,\nnecessitating significant background knowledge in optimization. In this paper,\nwe introduce OptiChat, a first-of-its-kind natural language-based system\nequipped with a chatbot GUI for engaging in interactive conversations about\ninfeasible optimization models. OptiChat can provide natural language\ndescriptions of the optimization model itself, identify potential sources of\ninfeasibility, and offer suggestions to make the model feasible. The\nimplementation of OptiChat is built on GPT-4, which interfaces with an\noptimization solver to identify the minimal subset of constraints that render\nthe entire optimization problem infeasible, also known as the Irreducible\nInfeasible Subset (IIS). We utilize few-shot learning, expert chain-of-thought,\nkey-retrieve, and sentiment prompts to enhance OptiChat's reliability. Our\nexperiments demonstrate that OptiChat assists both expert and non-expert users\nin improving their understanding of the optimization models, enabling them to\nquickly identify the sources of infeasibility.\n",
                "链接": "https://arxiv.org/abs/2308.12923"
            },
            {
                "文章ID": "108799",
                "标题": "Solving Math Word Problems with Reexamination",
                "作者": " Yi Bin,  Wenhao Shi,  Yujuan Ding,  Yang Yang,  See-Kiong Ng",
                "发布日期": "2023-11-21",
                "摘要": "  Math word problem (MWP) solving aims to understand the descriptive math\nproblem and calculate the result, for which previous efforts are mostly devoted\nto upgrade different technical modules. This paper brings a different\nperspective of \\textit{reexamination process} during training by introducing a\npseudo-dual task to enhance the MWP solving. We propose a pseudo-dual (PseDual)\nlearning scheme to model such process, which is model-agnostic thus can be\nadapted to any existing MWP solvers. The pseudo-dual task is specifically\ndefined as filling the numbers in the expression back into the original word\nproblem with numbers masked. To facilitate the effective joint learning of the\ntwo tasks, we further design a scheduled fusion strategy for the number\ninfilling task, which smoothly switches the input from the ground-truth math\nexpressions to the predicted ones. Our pseudo-dual learning scheme has been\ntested and proven effective when being equipped in several representative MWP\nsolvers through empirical studies. \\textit{The codes and trained models are\navailable at:} \\url{https://github.com/steven640pixel/PsedualMWP}.\n\\end{abstract}\n",
                "链接": "https://arxiv.org/abs/2310.09590"
            }
        ]
    },
    {
        "question": {
            "question": "查找可以用于验证模型推理能力的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "94708",
                "标题": "MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities",
                "作者": " Weihao Yu,  Zhengyuan Yang,  Linjie Li,  Jianfeng Wang,  Kevin Lin,  Zicheng Liu,  Xinchao Wang,  Lijuan Wang",
                "发布日期": "2023-10-25",
                "摘要": "  We propose MM-Vet, an evaluation benchmark that examines large multimodal\nmodels (LMMs) on complicated multimodal tasks. Recent LMMs have shown various\nintriguing abilities, such as solving math problems written on the blackboard,\nreasoning about events and celebrities in news images, and explaining visual\njokes. Rapid model advancements pose challenges to evaluation benchmark\ndevelopment. Problems include: (1) How to systematically structure and evaluate\nthe complicated multimodal tasks; (2) How to design evaluation metrics that\nwork well across question and answer types; and (3) How to give model insights\nbeyond a simple performance ranking. To this end, we present MM-Vet, designed\nbased on the insight that the intriguing ability to solve complicated tasks is\noften achieved by a generalist model being able to integrate different core\nvision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and\nexamines the 16 integrations of interest derived from the capability\ncombination. For evaluation metrics, we propose an LLM-based evaluator for\nopen-ended outputs. The evaluator enables the evaluation across different\nquestion types and answer styles, resulting in a unified scoring metric. We\nevaluate representative LMMs on MM-Vet, providing insights into the\ncapabilities of different LMM system paradigms and models. Code and data are\navailable at https://github.com/yuweihao/MM-Vet.\n",
                "链接": "https://arxiv.org/abs/2308.02490"
            },
            {
                "文章ID": "83002",
                "标题": "Evaluating the Capabilities of Multi-modal Reasoning Models with\n  Synthetic Task Data",
                "作者": " Nathan Vaska,  Victoria Helus",
                "发布日期": "2023-06-05",
                "摘要": "  The impressive advances and applications of large language and joint\nlanguage-and-visual understanding models has led to an increased need for\nmethods of probing their potential reasoning capabilities. However, the\ndifficulty of gather naturally-occurring data for complex multi-modal reasoning\ntasks bottlenecks the evaluation of AI methods on tasks which are not already\ncovered by an academic dataset. In this work, we leverage recent advances in\nhigh resolution text-to-image generation to develop a framework for generating\nevaluation data for multi-modal reasoning tasks. We apply this framework to\ngenerate context-dependent anomaly data, creating a synthetic dataset on a\nchallenging task which is not well covered by existing datasets. We benchmark\nthe performance of a state-of-the-art visual question answering (VQA) model\nagainst data generated with this method, and demonstrate that while the task is\ntractable, the model performs significantly worse on the context-dependent\nanomaly detection task than on standard VQA tasks.\n",
                "链接": "https://arxiv.org/abs/2306.01144"
            },
            {
                "文章ID": "86629",
                "标题": "Jamp: Controlled Japanese Temporal Inference Dataset for Evaluating\n  Generalization Capacity of Language Models",
                "作者": " Tomoki Sugimoto,  Yasumasa Onoe,  Hitomi Yanaka",
                "发布日期": "2023-06-21",
                "摘要": "  Natural Language Inference (NLI) tasks involving temporal inference remain\nchallenging for pre-trained language models (LMs). Although various datasets\nhave been created for this task, they primarily focus on English and do not\naddress the need for resources in other languages. It is unclear whether\ncurrent LMs realize the generalization capacity for temporal inference across\nlanguages. In this paper, we present Jamp, a Japanese NLI benchmark focused on\ntemporal inference. Our dataset includes a range of temporal inference\npatterns, which enables us to conduct fine-grained analysis. To begin the data\nannotation process, we create diverse inference templates based on the formal\nsemantics test suites. We then automatically generate diverse NLI examples by\nusing the Japanese case frame dictionary and well-designed templates while\ncontrolling the distribution of inference patterns and gold labels. We evaluate\nthe generalization capacities of monolingual/multilingual LMs by splitting our\ndataset based on tense fragments (i.e., temporal inference patterns). Our\nfindings demonstrate that LMs struggle with specific linguistic phenomena, such\nas habituality, indicating that there is potential for the development of more\neffective NLI models across languages.\n",
                "链接": "https://arxiv.org/abs/2306.10727"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "95564",
                "标题": "Evaluating the Generation Capabilities of Large Chinese Language Models",
                "作者": " Hui Zeng,  Jingyuan Xue,  Meng Hao,  Chen Sun,  Bin Ning,  Na Zhang",
                "发布日期": "2023-11-21",
                "摘要": "  This paper presents CG-Eval, the first comprehensive evaluation of the\ngeneration capabilities of large Chinese language models across a wide range of\nacademic disciplines. The models' performance was assessed based on their\nability to generate accurate and relevant responses to different types of\nquestions in six disciplines, namely, Science and Engineering, Humanities and\nSocial Sciences, Mathematical Calculations, Medical Practitioner Qualification\nExamination, Judicial Examination, and Certified Public Accountant Examination.\nThis paper also presents Gscore, a composite index derived from the weighted\nsum of multiple metrics to measure the quality of model's generation against a\nreference. The test data and test results can be found at\nhttp://cgeval.besteasy.com/.\n",
                "链接": "https://arxiv.org/abs/2308.04823"
            },
            {
                "文章ID": "37962",
                "标题": "Dataset Inference for Self-Supervised Models",
                "作者": " Adam Dziedzic,  Haonan Duan,  Muhammad Ahmad Kaleem,  Nikita Dhawan,  Jonas Guan,  Yannis Cattan,  Franziska Boenisch,  Nicolas Papernot",
                "发布日期": "2023-01-18",
                "摘要": "  Self-supervised models are increasingly prevalent in machine learning (ML)\nsince they reduce the need for expensively labeled data. Because of their\nversatility in downstream applications, they are increasingly used as a service\nexposed via public APIs. At the same time, these encoder models are\nparticularly vulnerable to model stealing attacks due to the high\ndimensionality of vector representations they output. Yet, encoders remain\nundefended: existing mitigation strategies for stealing attacks focus on\nsupervised learning. We introduce a new dataset inference defense, which uses\nthe private training set of the victim encoder model to attribute its ownership\nin the event of stealing. The intuition is that the log-likelihood of an\nencoder's output representations is higher on the victim's training data than\non test data if it is stolen from the victim, but not if it is independently\ntrained. We compute this log-likelihood using density estimation models. As\npart of our evaluation, we also propose measuring the fidelity of stolen\nencoders and quantifying the effectiveness of the theft detection without\ninvolving downstream tasks; instead, we leverage mutual information and\ndistance measurements. Our extensive empirical results in the vision domain\ndemonstrate that dataset inference is a promising direction for defending\nself-supervised models against model stealing.\n",
                "链接": "https://arxiv.org/abs/2209.09024"
            },
            {
                "文章ID": "90313",
                "标题": "Synthetic Dataset for Evaluating Complex Compositional Knowledge for\n  Natural Language Inference",
                "作者": " Sushma Anand Akoju,  Robert Vacareanu,  Haris Riaz,  Eduardo Blanco,  Mihai Surdeanu",
                "发布日期": "2023-07-13",
                "摘要": "  We introduce a synthetic dataset called Sentences Involving Complex\nCompositional Knowledge (SICCK) and a novel analysis that investigates the\nperformance of Natural Language Inference (NLI) models to understand\ncompositionality in logic. We produce 1,304 sentence pairs by modifying 15\nexamples from the SICK dataset (Marelli et al., 2014). To this end, we modify\nthe original texts using a set of phrases - modifiers that correspond to\nuniversal quantifiers, existential quantifiers, negation, and other concept\nmodifiers in Natural Logic (NL) (MacCartney, 2009). We use these phrases to\nmodify the subject, verb, and object parts of the premise and hypothesis.\nLastly, we annotate these modified texts with the corresponding entailment\nlabels following NL rules. We conduct a preliminary verification of how well\nthe change in the structural and semantic composition is captured by neural NLI\nmodels, in both zero-shot and fine-tuned scenarios. We found that the\nperformance of NLI models under the zero-shot setting is poor, especially for\nmodified sentences with negation and existential quantifiers. After fine-tuning\nthis dataset, we observe that models continue to perform poorly over negation,\nexistential and universal modifiers.\n",
                "链接": "https://arxiv.org/abs/2307.05034"
            },
            {
                "文章ID": "13031",
                "标题": "Evaluating the Text-to-SQL Capabilities of Large Language Models",
                "作者": " Nitarshan Rajkumar,  Raymond Li,  Dzmitry Bahdanau",
                "发布日期": "2022-04-04",
                "摘要": "  We perform an empirical evaluation of Text-to-SQL capabilities of the Codex\nlanguage model. We find that, without any finetuning, Codex is a strong\nbaseline on the Spider benchmark; we also analyze the failure modes of Codex in\nthis setting. Furthermore, we demonstrate on the GeoQuery and Scholar\nbenchmarks that a small number of in-domain examples provided in the prompt\nenables Codex to perform better than state-of-the-art models finetuned on such\nfew-shot examples.\n",
                "链接": "https://arxiv.org/abs/2204.00498"
            },
            {
                "文章ID": "61963",
                "标题": "Evaluating and Improving the Coreference Capabilities of Machine\n  Translation Models",
                "作者": " Asaf Yehudai,  Arie Cattan,  Omri Abend,  Gabriel Stanovsky",
                "发布日期": "2023-02-17",
                "摘要": "  Machine translation (MT) requires a wide range of linguistic capabilities,\nwhich current end-to-end models are expected to learn implicitly by observing\naligned sentences in bilingual corpora. In this work, we ask: \\emph{How well do\nMT models learn coreference resolution from implicit signal?} To answer this\nquestion, we develop an evaluation methodology that derives coreference\nclusters from MT output and evaluates them without requiring annotations in the\ntarget language. We further evaluate several prominent open-source and\ncommercial MT systems, translating from English to six target languages, and\ncompare them to state-of-the-art coreference resolvers on three challenging\nbenchmarks. Our results show that the monolingual resolvers greatly outperform\nMT models. Motivated by this result, we experiment with different methods for\nincorporating the output of coreference resolution models in MT, showing\nimprovement over strong baselines.\n",
                "链接": "https://arxiv.org/abs/2302.08464"
            },
            {
                "文章ID": "1654",
                "标题": "CoAuthor: Designing a Human-AI Collaborative Writing Dataset for\n  Exploring Language Model Capabilities",
                "作者": " Mina Lee,  Percy Liang,  Qian Yang",
                "发布日期": "2022-01-26",
                "摘要": "  Large language models (LMs) offer unprecedented language generation\ncapabilities and exciting opportunities for interaction design. However, their\nhighly context-dependent capabilities are difficult to grasp and are often\nsubjectively interpreted. In this paper, we argue that by curating and\nanalyzing large interaction datasets, the HCI community can foster more\nincisive examinations of LMs' generative capabilities. Exemplifying this\napproach, we present CoAuthor, a dataset designed for revealing GPT-3's\ncapabilities in assisting creative and argumentative writing. CoAuthor captures\nrich interactions between 63 writers and four instances of GPT-3 across 1445\nwriting sessions. We demonstrate that CoAuthor can address questions about\nGPT-3's language, ideation, and collaboration capabilities, and reveal its\ncontribution as a writing \"collaborator\" under various definitions of good\ncollaboration. Finally, we discuss how this work may facilitate a more\nprincipled discussion around LMs' promises and pitfalls in relation to\ninteraction design. The dataset and an interface for replaying the writing\nsessions are publicly available at https://coauthor.stanford.edu.\n",
                "链接": "https://arxiv.org/abs/2201.06796"
            }
        ]
    },
    {
        "question": {
            "question": "帮我找一下用大模型进行论文查找的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "97463",
                "标题": "Can Large Language Models Find And Fix Vulnerable Software?",
                "作者": " David Noever",
                "发布日期": "2023-08-22",
                "摘要": "  In this study, we evaluated the capability of Large Language Models (LLMs),\nparticularly OpenAI's GPT-4, in detecting software vulnerabilities, comparing\ntheir performance against traditional static code analyzers like Snyk and\nFortify. Our analysis covered numerous repositories, including those from NASA\nand the Department of Defense. GPT-4 identified approximately four times the\nvulnerabilities than its counterparts. Furthermore, it provided viable fixes\nfor each vulnerability, demonstrating a low rate of false positives. Our tests\nencompassed 129 code samples across eight programming languages, revealing the\nhighest vulnerabilities in PHP and JavaScript. GPT-4's code corrections led to\na 90% reduction in vulnerabilities, requiring only an 11% increase in code\nlines. A critical insight was LLMs' ability to self-audit, suggesting fixes for\ntheir identified vulnerabilities and underscoring their precision. Future\nresearch should explore system-level vulnerabilities and integrate multiple\nstatic code analyzers for a holistic perspective on LLMs' potential.\n",
                "链接": "https://arxiv.org/abs/2308.10345"
            },
            {
                "文章ID": "75161",
                "标题": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
                "作者": " Eddie Guo,  Mehul Gupta,  Jiawen Deng,  Ye-Jean Park,  Mike Paget,  Christopher Naugler",
                "发布日期": "2023-10-09",
                "摘要": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
                "链接": "https://arxiv.org/abs/2305.00844"
            },
            {
                "文章ID": "44293",
                "标题": "FIND: An Unsupervised Implicit 3D Model of Articulated Human Feet",
                "作者": " Oliver Boyne,  James Charles,  Roberto Cipolla",
                "发布日期": "2022-11-23",
                "摘要": "  In this paper we present a high fidelity and articulated 3D human foot model.\nThe model is parameterised by a disentangled latent code in terms of shape,\ntexture and articulated pose. While high fidelity models are typically created\nwith strong supervision such as 3D keypoint correspondences or\npre-registration, we focus on the difficult case of little to no annotation. To\nthis end, we make the following contributions: (i) we develop a Foot Implicit\nNeural Deformation field model, named FIND, capable of tailoring explicit\nmeshes at any resolution i.e. for low or high powered devices; (ii) an approach\nfor training our model in various modes of weak supervision with progressively\nbetter disentanglement as more labels, such as pose categories, are provided;\n(iii) a novel unsupervised part-based loss for fitting our model to 2D images\nwhich is better than traditional photometric or silhouette losses; (iv)\nfinally, we release a new dataset of high resolution 3D human foot scans,\nFoot3D. On this dataset, we show our model outperforms a strong PCA\nimplementation trained on the same data in terms of shape quality and part\ncorrespondences, and that our novel unsupervised part-based loss improves\ninference on images.\n",
                "链接": "https://arxiv.org/abs/2210.12241"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            },
            {
                "文章ID": "43057",
                "标题": "An efficient deep neural network to find small objects in large 3D\n  images",
                "作者": " Jungkyu Park,  Jakub Chłędowski,  Stanisław Jastrzębski,  Jan Witowski,  Yanqi Xu,  Linda Du,  Sushma Gaddam,  Eric Kim,  Alana Lewin,  Ujas Parikh,  Anastasia Plaunova,  Sardius Chen,  Alexandra Millet,  James Park,  Kristine Pysarenko,  Shalin Patel,  Julia Goldberg,  Melanie Wegener,  Linda Moy,  Laura Heacock,  Beatriu Reig,  Krzysztof J. Geras",
                "发布日期": "2023-02-28",
                "摘要": "  3D imaging enables accurate diagnosis by providing spatial information about\norgan anatomy. However, using 3D images to train AI models is computationally\nchallenging because they consist of 10x or 100x more pixels than their 2D\ncounterparts. To be trained with high-resolution 3D images, convolutional\nneural networks resort to downsampling them or projecting them to 2D. We\npropose an effective alternative, a neural network that enables efficient\nclassification of full-resolution 3D medical images. Compared to off-the-shelf\nconvolutional neural networks, our network, 3D Globally-Aware Multiple Instance\nClassifier (3D-GMIC), uses 77.98%-90.05% less GPU memory and 91.23%-96.02% less\ncomputation. While it is trained only with image-level labels, without\nsegmentation labels, it explains its predictions by providing pixel-level\nsaliency maps. On a dataset collected at NYU Langone Health, including 85,526\npatients with full-field 2D mammography (FFDM), synthetic 2D mammography, and\n3D mammography, 3D-GMIC achieves an AUC of 0.831 (95% CI: 0.769-0.887) in\nclassifying breasts with malignant findings using 3D mammography. This is\ncomparable to the performance of GMIC on FFDM (0.816, 95% CI: 0.737-0.878) and\nsynthetic 2D (0.826, 95% CI: 0.754-0.884), which demonstrates that 3D-GMIC\nsuccessfully classified large 3D images despite focusing computation on a\nsmaller percentage of its input compared to GMIC. Therefore, 3D-GMIC identifies\nand utilizes extremely small regions of interest from 3D images consisting of\nhundreds of millions of pixels, dramatically reducing associated computational\nchallenges. 3D-GMIC generalizes well to BCS-DBT, an external dataset from Duke\nUniversity Hospital, achieving an AUC of 0.848 (95% CI: 0.798-0.896).\n",
                "链接": "https://arxiv.org/abs/2210.08645"
            },
            {
                "文章ID": "117394",
                "标题": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
                "作者": " Chengyu Wang,  Junbing Yan,  Wei Zhang,  Jun Huang",
                "发布日期": "2023-11-23",
                "摘要": "  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.13126"
            },
            {
                "文章ID": "75237",
                "标题": "Multidimensional Fairness in Paper Recommendation",
                "作者": " Reem Alsaffar,  Susan Gauch,  Hiba Al-Kawaz",
                "发布日期": "2023-05-05",
                "摘要": "  To prevent potential bias in the paper review and selection process for\nconferences and journals, most include double blind review. Despite this,\nstudies show that bias still exists. Recommendation algorithms for paper review\nalso may have implicit bias. We offer three fair methods that specifically take\ninto account author diversity in paper recommendation to address this. Our\nmethods provide fair outcomes across many protected variables concurrently, in\ncontrast to typical fair algorithms that only use one protected variable. Five\ndemographic characteristics-gender, ethnicity, career stage, university rank,\nand geolocation-are included in our multidimensional author profiles. The\nOverall Diversity approach uses a score for overall diversity to rank\npublications. The Round Robin Diversity technique chooses papers from authors\nwho are members of each protected group in turn, whereas the Multifaceted\nDiversity method chooses papers that initially fill the demographic feature\nwith the highest importance. We compare the effectiveness of author diversity\nprofiles based on Boolean and continuous-valued features. By selecting papers\nfrom a pool of SIGCHI 2017, DIS 2017, and IUI 2017 papers, we recommend papers\nfor SIGCHI 2017 and evaluate these algorithms using the user profiles. We\ncontrast the papers that were recommended with those that were selected by the\nconference. We find that utilizing profiles with either Boolean or continuous\nfeature values, all three techniques boost diversity while just slightly\ndecreasing utility or not decreasing. By choosing authors who are 42.50% more\ndiverse and with a 2.45% boost in utility, our best technique, Multifaceted\nDiversity, suggests a set of papers that match demographic parity. The\nselection of grant proposals, conference papers, journal articles, and other\nacademic duties might all use this strategy.\n",
                "链接": "https://arxiv.org/abs/2305.01141"
            },
            {
                "文章ID": "19420",
                "标题": "CurFi: An automated tool to find the best regression analysis model\n  using curve fitting",
                "作者": " Ayon Roy,  Tausif Al Zubayer,  Nafisa Tabassum,  Muhammad Nazrul Islam,  Md. Abdus Sattar",
                "发布日期": "2022-05-17",
                "摘要": "  Regression analysis is a well known quantitative research method that\nprimarily explores the relationship between one or more independent variables\nand a dependent variable. Conducting regression analysis manually on large\ndatasets with multiple independent variables can be tedious. An automated\nsystem for regression analysis will be of great help for researchers as well as\nnon-expert users. Thus, the objective of this research is to design and develop\nan automated curve fitting system. As outcome, a curve fitting system named\n\"CurFi\" was developed that uses linear regression models to fit a curve to a\ndataset and to find out the best fit model. The system facilitates to upload a\ndataset, split the dataset into training set and test set, select relevant\nfeatures and label from the dataset; and the system will return the best fit\nlinear regression model after training is completed. The developed tool would\nbe a great resource for the users having limited technical knowledge who will\nalso be able to find the best fit regression model for a dataset using the\ndeveloped \"CurFi\" system.\n",
                "链接": "https://arxiv.org/abs/2205.07804"
            },
            {
                "文章ID": "38738",
                "标题": "Toward Smart Doors: A Position Paper",
                "作者": " Luigi Capogrosso,  Geri Skenderi,  Federico Girella,  Franco Fummi,  Marco Cristani",
                "发布日期": "2022-09-27",
                "摘要": "  Conventional automatic doors cannot distinguish between people wishing to\npass through the door and people passing by the door, so they often open\nunnecessarily. This leads to the need to adopt new systems in both commercial\nand non-commercial environments: smart doors. In particular, a smart door\nsystem predicts the intention of people near the door based on the social\ncontext of the surrounding environment and then makes rational decisions about\nwhether or not to open the door. This work proposes the first position paper\nrelated to smart doors, without bells and whistles. We first point out that the\nproblem not only concerns reliability, climate control, safety, and mode of\noperation. Indeed, a system to predict the intention of people near the door\nalso involves a deeper understanding of the social context of the scene through\na complex combined analysis of proxemics and scene reasoning. Furthermore, we\nconduct an exhaustive literature review about automatic doors, providing a\nnovel system formulation. Also, we present an analysis of the possible future\napplication of smart doors, a description of the ethical shortcomings, and\nlegislative issues.\n",
                "链接": "https://arxiv.org/abs/2209.11770"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到，最早提出分布式词表示的论文是哪一篇？",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "36500",
                "标题": "Tag-Aware Document Representation for Research Paper Recommendation",
                "作者": " Hebatallah A. Mohamed,  Giuseppe Sansonetti,  Alessandro Micarelli",
                "发布日期": "2022-09-09",
                "摘要": "  Finding online research papers relevant to one's interests is very\nchallenging due to the increasing number of publications. Therefore,\npersonalized research paper recommendation has become a significant and timely\nresearch topic. Collaborative filtering is a successful recommendation\napproach, which exploits the ratings given to items by users as a source of\ninformation for learning to make accurate recommendations. However, the ratings\nare often very sparse as in the research paper domain, due to the huge number\nof publications growing every year. Therefore, more attention has been drawn to\nhybrid methods that consider both ratings and content information.\nNevertheless, most of the hybrid recommendation approaches that are based on\ntext embedding have utilized bag-of-words techniques, which ignore word order\nand semantic meaning. In this paper, we propose a hybrid approach that\nleverages deep semantic representation of research papers based on social tags\nassigned by users. The experimental evaluation is performed on CiteULike, a\nreal and publicly available dataset. The obtained findings show that the\nproposed model is effective in recommending research papers even when the\nrating data is very sparse.\n",
                "链接": "https://arxiv.org/abs/2209.03660"
            },
            {
                "文章ID": "16842",
                "标题": "Extremal GloVe: Theoretically Accurate Distributed Word Embedding by\n  Tail Inference",
                "作者": " Hao Wang",
                "发布日期": "2022-04-28",
                "摘要": "  Distributed word embeddings such as Word2Vec and GloVe have been widely\nadopted in industrial context settings. Major technical applications of GloVe\ninclude recommender systems and natural language processing. The fundamental\ntheory behind GloVe relies on the selection of a weighting function in the\nweighted least squres formulation that computes the powered ratio of word\noccurrence count and the maximum word count in the corpus. However, the initial\nformulation of GloVe is not theoretically sound in two aspects, namely the\nselection of the weighting function and its power exponent is ad-hoc. In this\npaper, we utilize the theory of extreme value analysis and propose a\ntheoretically accurate version of GloVe. By reformulating the weighted least\nsquares loss function as the expected loss function and accurately choosing the\npower exponent, we create a theoretically accurate version of GloVe. We\ndemonstrate the competitiveness of our algorithm and show that the initial\nformulation of GloVe with the suggested optimal parameter can be viewed as a\nspecial case of our paradigm.\n",
                "链接": "https://arxiv.org/abs/2204.13009"
            },
            {
                "文章ID": "42603",
                "标题": "Multilingual Word Sense Disambiguation with Unified Sense Representation",
                "作者": " Ying Su,  Hongming Zhang,  Yangqiu Song,  Tong Zhang",
                "发布日期": "2022-10-17",
                "摘要": "  As a key natural language processing (NLP) task, word sense disambiguation\n(WSD) evaluates how well NLP models can understand the lexical semantics of\nwords under specific contexts. Benefited from the large-scale annotation,\ncurrent WSD systems have achieved impressive performances in English by\ncombining supervised learning with lexical knowledge. However, such success is\nhard to be replicated in other languages, where we only have limited\nannotations.In this paper, based on the multilingual lexicon BabelNet\ndescribing the same set of concepts across languages, we propose building\nknowledge and supervised-based Multilingual Word Sense Disambiguation (MWSD)\nsystems. We build unified sense representations for multiple languages and\naddress the annotation scarcity problem for MWSD by transferring annotations\nfrom rich-sourced languages to poorer ones. With the unified sense\nrepresentations, annotations from multiple languages can be jointly trained to\nbenefit the MWSD tasks. Evaluations of SemEval-13 and SemEval-15 datasets\ndemonstrate the effectiveness of our methodology.\n",
                "链接": "https://arxiv.org/abs/2210.07447"
            },
            {
                "文章ID": "49974",
                "标题": "Word-Level Representation From Bytes For Language Modeling",
                "作者": " Chu-Tak Lee,  Qipeng Guo,  Xipeng Qiu",
                "发布日期": "2022-11-24",
                "摘要": "  Modern language models mostly take sub-words as input, a design that balances\nthe trade-off between vocabulary size, number of parameters, and performance.\nHowever, sub-word tokenization still has disadvantages like not being robust to\nnoise and difficult to generalize to new languages. Also, the current trend of\nscaling up models reveals that larger models require larger embeddings but that\nmakes parallelization hard. Previous work on image classification proves\nsplitting raw input into a sequence of chucks is a strong, model-agnostic\ninductive bias. Based on this observation, we rethink the existing\ncharacter-aware method that takes character-level inputs but makes word-level\nsequence modeling and prediction. We overhaul this method by introducing a\ncross-attention network that builds word-level representation directly from\nbytes, and a sub-word level prediction based on word-level hidden states to\navoid the time and space requirement of word-level prediction. With these two\nimprovements combined, we have a token free model with slim input embeddings\nfor downstream tasks. We name our method Byte2Word and perform evaluations on\nlanguage modeling and text classification. Experiments show that Byte2Word is\non par with the strong sub-word baseline BERT but only takes up 10\\% of\nembedding size. We further test our method on synthetic noise and cross-lingual\ntransfer and find it competitive to baseline methods on both settings.\n",
                "链接": "https://arxiv.org/abs/2211.12677"
            },
            {
                "文章ID": "19560",
                "标题": "KGNN: Distributed Framework for Graph Neural Knowledge Representation",
                "作者": " Binbin Hu,  Zhiyang Hu,  Zhiqiang Zhang,  Jun Zhou,  Chuan Shi",
                "发布日期": "2022-05-18",
                "摘要": "  Knowledge representation learning has been commonly adopted to incorporate\nknowledge graph (KG) into various online services. Although existing knowledge\nrepresentation learning methods have achieved considerable performance\nimprovement, they ignore high-order structure and abundant attribute\ninformation, resulting unsatisfactory performance on semantics-rich KGs.\nMoreover, they fail to make prediction in an inductive manner and cannot scale\nto large industrial graphs. To address these issues, we develop a novel\nframework called KGNN to take full advantage of knowledge data for\nrepresentation learning in the distributed learning system. KGNN is equipped\nwith GNN based encoder and knowledge aware decoder, which aim to jointly\nexplore high-order structure and attribute information together in a\nfine-grained fashion and preserve the relation patterns in KGs, respectively.\nExtensive experiments on three datasets for link prediction and triplet\nclassification task demonstrate the effectiveness and scalability of KGNN\nframework.\n",
                "链接": "https://arxiv.org/abs/2205.08285"
            },
            {
                "文章ID": "73435",
                "标题": "Distributed Neural Representation for Reactive in situ Visualization",
                "作者": " Qi Wu,  Joseph A. Insley,  Victor A. Mateevitsi,  Silvio Rizzi,  Michael E. Papka,  Kwan-Liu Ma",
                "发布日期": "2023-04-21",
                "摘要": "  In situ visualization and steering of computational modeling can be\neffectively achieved using reactive programming, which leverages temporal\nabstraction and data caching mechanisms to create dynamic workflows. However,\nimplementing a temporal cache for large-scale simulations can be challenging.\nImplicit neural networks have proven effective in compressing large volume\ndata. However, their application to distributed data has yet to be fully\nexplored. In this work, we develop an implicit neural representation for\ndistributed volume data and incorporate it into the DIVA reactive programming\nsystem. This implementation enables us to build an in situ temporal caching\nsystem with a capacity 100 times larger than previously achieved. We integrate\nour implementation into the Ascent infrastructure and evaluate its performance\nusing real-world simulations.\n",
                "链接": "https://arxiv.org/abs/2304.10516"
            },
            {
                "文章ID": "3597",
                "标题": "Towards a Theoretical Understanding of Word and Relation Representation",
                "作者": " Carl Allen",
                "发布日期": "2022-02-02",
                "摘要": "  Representing words by vectors, or embeddings, enables computational reasoning\nand is foundational to automating natural language tasks. For example, if word\nembeddings of similar words contain similar values, word similarity can be\nreadily assessed, whereas judging that from their spelling is often impossible\n(e.g. cat /feline) and to predetermine and store similarities between all words\nis prohibitively time-consuming, memory intensive and subjective. We focus on\nword embeddings learned from text corpora and knowledge graphs. Several\nwell-known algorithms learn word embeddings from text on an unsupervised basis\nby learning to predict those words that occur around each word, e.g. word2vec\nand GloVe. Parameters of such word embeddings are known to reflect word\nco-occurrence statistics, but how they capture semantic meaning has been\nunclear. Knowledge graph representation models learn representations both of\nentities (words, people, places, etc.) and relations between them, typically by\ntraining a model to predict known facts in a supervised manner. Despite steady\nimprovements in fact prediction accuracy, little is understood of the latent\nstructure that enables this.\n  The limited understanding of how latent semantic structure is encoded in the\ngeometry of word embeddings and knowledge graph representations makes a\nprincipled means of improving their performance, reliability or\ninterpretability unclear. To address this:\n  1. we theoretically justify the empirical observation that particular\ngeometric relationships between word embeddings learned by algorithms such as\nword2vec and GloVe correspond to semantic relations between words; and\n  2. we extend this correspondence between semantics and geometry to the\nentities and relations of knowledge graphs, providing a model for the latent\nstructure of knowledge graph representation linked to that of word embeddings.\n",
                "链接": "https://arxiv.org/abs/2202.00486"
            },
            {
                "文章ID": "57181",
                "标题": "Representation Learning for Tablet and Paper Domain Adaptation in Favor\n  of Online Handwriting Recognition",
                "作者": " Felix Ott,  David Rügamer,  Lucas Heublein,  Bernd Bischl,  Christopher Mutschler",
                "发布日期": "2023-01-18",
                "摘要": "  The performance of a machine learning model degrades when it is applied to\ndata from a similar but different domain than the data it has initially been\ntrained on. The goal of domain adaptation (DA) is to mitigate this domain shift\nproblem by searching for an optimal feature transformation to learn a\ndomain-invariant representation. Such a domain shift can appear in handwriting\nrecognition (HWR) applications where the motion pattern of the hand and with\nthat the motion pattern of the pen is different for writing on paper and on\ntablet. This becomes visible in the sensor data for online handwriting (OnHW)\nfrom pens with integrated inertial measurement units. This paper proposes a\nsupervised DA approach to enhance learning for OnHW recognition between tablet\nand paper data. Our method exploits loss functions such as maximum mean\ndiscrepancy and correlation alignment to learn a domain-invariant feature\nrepresentation (i.e., similar covariances between tablet and paper features).\nWe use a triplet loss that takes negative samples of the auxiliary domain\n(i.e., paper samples) to increase the amount of samples of the tablet dataset.\nWe conduct an evaluation on novel sequence-based OnHW datasets (i.e., words)\nand show an improvement on the paper domain with an early fusion strategy by\nusing pairwise learning.\n",
                "链接": "https://arxiv.org/abs/2301.06293"
            },
            {
                "文章ID": "80919",
                "标题": "A Distributed Automatic Domain-Specific Multi-Word Term Recognition\n  Architecture using Spark Ecosystem",
                "作者": " Ciprian-Octavian Truică,  Neculai-Ovidiu Istrate,  Elena-Simona Apostol",
                "发布日期": "2023-05-29",
                "摘要": "  Automatic Term Recognition is used to extract domain-specific terms that\nbelong to a given domain. In order to be accurate, these corpus and\nlanguage-dependent methods require large volumes of textual data that need to\nbe processed to extract candidate terms that are afterward scored according to\na given metric. To improve text preprocessing and candidate terms extraction\nand scoring, we propose a distributed Spark-based architecture to automatically\nextract domain-specific terms. The main contributions are as follows: (1)\npropose a novel distributed automatic domain-specific multi-word term\nrecognition architecture built on top of the Spark ecosystem; (2) perform an\nin-depth analysis of our architecture in terms of accuracy and scalability; (3)\ndesign an easy-to-integrate Python implementation that enables the use of Big\nData processing in fields such as Computational Linguistics and Natural\nLanguage Processing. We prove empirically the feasibility of our architecture\nby performing experiments on two real-world datasets.\n",
                "链接": "https://arxiv.org/abs/2305.16343"
            },
            {
                "文章ID": "116434",
                "标题": "Collaborative Word-based Pre-trained Item Representation for\n  Transferable Recommendation",
                "作者": " Shenghao Yang,  Chenyang Wang,  Yankai Liu,  Kangping Xu,  Weizhi Ma,  Yiqun Liu,  Min Zhang,  Haitao Zeng,  Junlan Feng,  Chao Deng",
                "发布日期": "2023-12-22",
                "摘要": "  Item representation learning (IRL) plays an essential role in recommender\nsystems, especially for sequential recommendation. Traditional sequential\nrecommendation models usually utilize ID embeddings to represent items, which\nare not shared across different domains and lack the transferable ability.\nRecent studies use pre-trained language models (PLM) for item text embeddings\n(text-based IRL) that are universally applicable across domains. However, the\nexisting text-based IRL is unaware of the important collaborative filtering\n(CF) information. In this paper, we propose CoWPiRec, an approach of\nCollaborative Word-based Pre-trained item representation for Recommendation. To\neffectively incorporate CF information into text-based IRL, we convert the\nitem-level interaction data to a word graph containing word-level\ncollaborations. Subsequently, we design a novel pre-training task to align the\nword-level semantic- and CF-related item representation. Extensive experimental\nresults on multiple public datasets demonstrate that compared to\nstate-of-the-art transferable sequential recommenders, CoWPiRec achieves\nsignificantly better performances in both fine-tuning and zero-shot settings\nfor cross-scenario recommendation and effectively alleviates the cold-start\nissue. The code is available at: https://github.com/ysh-1998/CoWPiRec.\n",
                "链接": "https://arxiv.org/abs/2311.10501"
            }
        ]
    },
    {
        "question": {
            "question": "请列出近一年来工业界发表的搜广推工作落地实践的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "83119",
                "标题": "An Architecture for Deploying Reinforcement Learning in Industrial\n  Environments",
                "作者": " Georg Schäfer,  Reuf Kozlica,  Stefan Wegenkittl,  Stefan Huber",
                "发布日期": "2023-06-05",
                "摘要": "  Industry 4.0 is driven by demands like shorter time-to-market, mass\ncustomization of products, and batch size one production. Reinforcement\nLearning (RL), a machine learning paradigm shown to possess a great potential\nin improving and surpassing human level performance in numerous complex tasks,\nallows coping with the mentioned demands. In this paper, we present an OPC UA\nbased Operational Technology (OT)-aware RL architecture, which extends the\nstandard RL setting, combining it with the setting of digital twins. Moreover,\nwe define an OPC UA information model allowing for a generalized plug-and-play\nlike approach for exchanging the RL agent used. In conclusion, we demonstrate\nand evaluate the architecture, by creating a proof of concept. By means of\nsolving a toy example, we show that this architecture can be used to determine\nthe optimal policy using a real control system.\n",
                "链接": "https://arxiv.org/abs/2306.01420"
            },
            {
                "文章ID": "114344",
                "标题": "Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary\n  Case Study",
                "作者": " Peilin Zhou,  Meng Cao,  You-Liang Huang,  Qichen Ye,  Peiyan Zhang,  Junling Liu,  Yueqi Xie,  Yining Hua,  Jaeboum Kim",
                "发布日期": "2023-11-08",
                "摘要": "  Large Multimodal Models (LMMs) have demonstrated impressive performance\nacross various vision and language tasks, yet their potential applications in\nrecommendation tasks with visual assistance remain unexplored. To bridge this\ngap, we present a preliminary case study investigating the recommendation\ncapabilities of GPT-4V(ison), a recently released LMM by OpenAI. We construct a\nseries of qualitative test samples spanning multiple domains and employ these\nsamples to assess the quality of GPT-4V's responses within recommendation\nscenarios. Evaluation results on these test samples prove that GPT-4V has\nremarkable zero-shot recommendation abilities across diverse domains, thanks to\nits robust visual-text comprehension capabilities and extensive general\nknowledge. However, we have also identified some limitations in using GPT-4V\nfor recommendations, including a tendency to provide similar responses when\ngiven similar inputs. This report concludes with an in-depth discussion of the\nchallenges and research opportunities associated with utilizing GPT-4V in\nrecommendation scenarios. Our objective is to explore the potential of\nextending LMMs from vision and language tasks to recommendation tasks. We hope\nto inspire further research into next-generation multimodal generative\nrecommendation models, which can enhance user experiences by offering greater\ndiversity and interactivity. All images and prompts used in this report will be\naccessible at https://github.com/PALIN2018/Evaluate_GPT-4V_Rec.\n",
                "链接": "https://arxiv.org/abs/2311.04199"
            },
            {
                "文章ID": "92744",
                "标题": "Industrial Segment Anything -- a Case Study in Aircraft Manufacturing,\n  Intralogistics, Maintenance, Repair, and Overhaul",
                "作者": " Keno Moenck,  Arne Wendt,  Philipp Prünte,  Julian Koch,  Arne Sahrhage,  Johann Gierecker,  Ole Schmedemann,  Falko Kähler,  Dirk Holst,  Martin Gomse,  Thorsten Schüppstuhl,  Daniel Schoepflin",
                "发布日期": "2023-07-25",
                "摘要": "  Deploying deep learning-based applications in specialized domains like the\naircraft production industry typically suffers from the training data\navailability problem. Only a few datasets represent non-everyday objects,\nsituations, and tasks. Recent advantages in research around Vision Foundation\nModels (VFM) opened a new area of tasks and models with high generalization\ncapabilities in non-semantic and semantic predictions. As recently demonstrated\nby the Segment Anything Project, exploiting VFM's zero-shot capabilities is a\npromising direction in tackling the boundaries spanned by data, context, and\nsensor variety. Although, investigating its application within specific domains\nis subject to ongoing research. This paper contributes here by surveying\napplications of the SAM in aircraft production-specific use cases. We include\nmanufacturing, intralogistics, as well as maintenance, repair, and overhaul\nprocesses, also representing a variety of other neighboring industrial domains.\nBesides presenting the various use cases, we further discuss the injection of\ndomain knowledge.\n",
                "链接": "https://arxiv.org/abs/2307.12674"
            },
            {
                "文章ID": "113872",
                "标题": "Attention Modules Improve Image-Level Anomaly Detection for Industrial\n  Inspection: A DifferNet Case Study",
                "作者": " André Luiz Buarque Vieira e Silva,  Francisco Simões,  Danny Kowerko,  Tobias Schlosser,  Felipe Battisti,  Veronica Teichrieb",
                "发布日期": "2023-11-08",
                "摘要": "  Within (semi-)automated visual industrial inspection, learning-based\napproaches for assessing visual defects, including deep neural networks, enable\nthe processing of otherwise small defect patterns in pixel size on\nhigh-resolution imagery. The emergence of these often rarely occurring defect\npatterns explains the general need for labeled data corpora. To alleviate this\nissue and advance the current state of the art in unsupervised visual\ninspection, this work proposes a DifferNet-based solution enhanced with\nattention modules: AttentDifferNet. It improves image-level detection and\nclassification capabilities on three visual anomaly detection datasets for\nindustrial inspection: InsPLAD-fault, MVTec AD, and Semiconductor Wafer. In\ncomparison to the state of the art, AttentDifferNet achieves improved results,\nwhich are, in turn, highlighted throughout our quali-quantitative study. Our\nquantitative evaluation shows an average improvement - compared to DifferNet -\nof 1.77 +/- 0.25 percentage points in overall AUROC considering all three\ndatasets, reaching SOTA results in InsPLAD-fault, an industrial inspection\nin-the-wild dataset. As our variants to AttentDifferNet show great prospects in\nthe context of currently investigated approaches, a baseline is formulated,\nemphasizing the importance of attention for industrial anomaly detection both\nin the wild and in controlled environments.\n",
                "链接": "https://arxiv.org/abs/2311.02747"
            },
            {
                "文章ID": "90885",
                "标题": "IR Design for Application-Specific Natural Language: A Case Study on\n  Traffic Data",
                "作者": " Wei Hu,  Xuhong Wang,  Ding Wang,  Shengyue Yao,  Zuqiu Mao,  Li Li,  Fei-Yue Wang,  Yilun Lin",
                "发布日期": "2023-07-17",
                "摘要": "  In the realm of software applications in the transportation industry,\nDomain-Specific Languages (DSLs) have enjoyed widespread adoption due to their\nease of use and various other benefits. With the ceaseless progress in computer\nperformance and the rapid development of large-scale models, the possibility of\nprogramming using natural language in specified applications - referred to as\nApplication-Specific Natural Language (ASNL) - has emerged. ASNL exhibits\ngreater flexibility and freedom, which, in turn, leads to an increase in\ncomputational complexity for parsing and a decrease in processing performance.\nTo tackle this issue, our paper advances a design for an intermediate\nrepresentation (IR) that caters to ASNL and can uniformly process\ntransportation data into graph data format, improving data processing\nperformance. Experimental comparisons reveal that in standard data query\noperations, our proposed IR design can achieve a speed improvement of over\nforty times compared to direct usage of standard XML format data.\n",
                "链接": "https://arxiv.org/abs/2307.06983"
            },
            {
                "文章ID": "100714",
                "标题": "Robotic Table Tennis: A Case Study into a High Speed Learning System",
                "作者": " David B. D'Ambrosio,  Jonathan Abelian,  Saminda Abeyruwan,  Michael Ahn,  Alex Bewley,  Justin Boyd,  Krzysztof Choromanski,  Omar Cortes,  Erwin Coumans,  Tianli Ding,  Wenbo Gao,  Laura Graesser,  Atil Iscen,  Navdeep Jaitly,  Deepali Jain,  Juhana Kangaspunta,  Satoshi Kataoka,  Gus Kouretas,  Yuheng Kuang,  Nevena Lazic,  Corey Lynch,  Reza Mahjourian,  Sherry Q. Moore,  Thinh Nguyen,  Ken Oslund,  Barney J Reed,  Krista Reymann,  Pannag R. Sanketi,  Anish Shankar,  Pierre Sermanet,  Vikas Sindhwani,  Avi Singh,  Vincent Vanhoucke,  Grace Vesom,  Peng Xu",
                "发布日期": "2023-09-19",
                "摘要": "  We present a deep-dive into a real-world robotic learning system that, in\nprevious work, was shown to be capable of hundreds of table tennis rallies with\na human and has the ability to precisely return the ball to desired targets.\nThis system puts together a highly optimized perception subsystem, a high-speed\nlow-latency robot controller, a simulation paradigm that can prevent damage in\nthe real world and also train policies for zero-shot transfer, and automated\nreal world environment resets that enable autonomous training and evaluation on\nphysical robots. We complement a complete system description, including\nnumerous design decisions that are typically not widely disseminated, with a\ncollection of studies that clarify the importance of mitigating various sources\nof latency, accounting for training and deployment distribution shifts,\nrobustness of the perception system, sensitivity to policy hyper-parameters,\nand choice of action space. A video demonstrating the components of the system\nand details of experimental results can be found at\nhttps://youtu.be/uFcnWjB42I0.\n",
                "链接": "https://arxiv.org/abs/2309.03315"
            },
            {
                "文章ID": "98610",
                "标题": "A Preliminary Study on a Conceptual Game Feature Generation and\n  Recommendation System",
                "作者": " M Charity,  Yash Bhartia,  Daniel Zhang,  Ahmed Khalifa,  Julian Togelius",
                "发布日期": "2023-08-29",
                "摘要": "  This paper introduces a system used to generate game feature suggestions\nbased on a text prompt. Trained on the game descriptions of almost 60k games,\nit uses the word embeddings of a small GLoVe model to extract features and\nentities found in thematically similar games which are then passed through a\ngenerator model to generate new features for a user's prompt. We perform a\nshort user study comparing the features generated from a fine-tuned GPT-2\nmodel, a model using the ConceptNet, and human-authored game features. Although\nhuman suggestions won the overall majority of votes, the GPT-2 model\noutperformed the human suggestions in certain games. This system is part of a\nlarger game design assistant tool that is able to collaborate with users at a\nconceptual level.\n",
                "链接": "https://arxiv.org/abs/2308.13538"
            },
            {
                "文章ID": "118899",
                "标题": "Non-Visible Light Data Synthesis and Application: A Case Study for\n  Synthetic Aperture Radar Imagery",
                "作者": " Zichen Tian,  Zhaozheng Chen,  Qianru Sun",
                "发布日期": "2023-11-30",
                "摘要": "  We explore the \"hidden\" ability of large-scale pre-trained image generation\nmodels, such as Stable Diffusion and Imagen, in non-visible light domains,\ntaking Synthetic Aperture Radar (SAR) data for a case study. Due to the\ninherent challenges in capturing satellite data, acquiring ample SAR training\nsamples is infeasible. For instance, for a particular category of ship in the\nopen sea, we can collect only few-shot SAR images which are too limited to\nderive effective ship recognition models. If large-scale models pre-trained\nwith regular images can be adapted to generating novel SAR images, the problem\nis solved. In preliminary study, we found that fine-tuning these models with\nfew-shot SAR images is not working, as the models can not capture the two\nprimary differences between SAR and regular images: structure and modality. To\naddress this, we propose a 2-stage low-rank adaptation method, and we call it\n2LoRA. In the first stage, the model is adapted using aerial-view regular image\ndata (whose structure matches SAR), followed by the second stage where the base\nmodel from the first stage is further adapted using SAR modality data.\nParticularly in the second stage, we introduce a novel prototype LoRA (pLoRA),\nas an improved version of 2LoRA, to resolve the class imbalance problem in SAR\ndatasets. For evaluation, we employ the resulting generation model to\nsynthesize additional SAR data. This augmentation, when integrated into the\ntraining process of SAR classification as well as segmentation models, yields\nnotably improved performance for minor classes\n",
                "链接": "https://arxiv.org/abs/2311.17486"
            },
            {
                "文章ID": "84583",
                "标题": "A Meta-Generation framework for Industrial System Generation",
                "作者": " Fouad Oubari,  Raphael Meunier,  Rodrigue Décatoire,  Mathilde Mougeot",
                "发布日期": "2023-06-09",
                "摘要": "  Generative design is an increasingly important tool in the industrial world.\nIt allows the designers and engineers to easily explore vast ranges of design\noptions, providing a cheaper and faster alternative to the trial and failure\napproaches. Thanks to the flexibility they offer, Deep Generative Models are\ngaining popularity amongst Generative Design technologies. However, developing\nand evaluating these models can be challenging. The field lacks accessible\nbenchmarks, in order to evaluate and compare objectively different Deep\nGenerative Models architectures. Moreover, vanilla Deep Generative Models\nappear to be unable to accurately generate multi-components industrial systems\nthat are controlled by latent design constraints. To address these challenges,\nwe propose an industry-inspired use case that incorporates actual industrial\nsystem characteristics. This use case can be quickly generated and used as a\nbenchmark. We propose a Meta-VAE capable of producing multi-component\nindustrial systems and showcase its application on the proposed use case.\n",
                "链接": "https://arxiv.org/abs/2306.05123"
            },
            {
                "文章ID": "95803",
                "标题": "A Smart Robotic System for Industrial Plant Supervision",
                "作者": " D. Adriana Gómez-Rosal,  Max Bergau,  Georg K. J. Fischer,  Andreas Wachaja,  Johannes Gräter,  Matthias Odenweller,  Uwe Piechottka,  Fabian Hoeflinger,  Nikhil Gosala,  Niklas Wetzel,  Daniel Büscher,  Abhinav Valada,  Wolfram Burgard",
                "发布日期": "2023-09-04",
                "摘要": "  In today's chemical plants, human field operators perform frequent integrity\nchecks to guarantee high safety standards, and thus are possibly the first to\nencounter dangerous operating conditions. To alleviate their task, we present a\nsystem consisting of an autonomously navigating robot integrated with various\nsensors and intelligent data processing. It is able to detect methane leaks and\nestimate its flow rate, detect more general gas anomalies, recognize oil films,\nlocalize sound sources and detect failure cases, map the environment in 3D, and\nnavigate autonomously, employing recognition and avoidance of dynamic\nobstacles. We evaluate our system at a wastewater facility in full working\nconditions. Our results demonstrate that the system is able to robustly\nnavigate the plant and provide useful information about critical operating\nconditions.\n",
                "链接": "https://arxiv.org/abs/2308.05612"
            }
        ]
    },
    {
        "question": {
            "question": "闭源大模型用户数据隐私保护研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "106181",
                "标题": "Large Language Models Can Be Good Privacy Protection Learners",
                "作者": " Yijia Xiao,  Yiqiao Jin,  Yushi Bai,  Yue Wu,  Xianjun Yang,  Xiao Luo,  Wenchao Yu,  Xujiang Zhao,  Yanchi Liu,  Haifeng Chen,  Wei Wang,  Wei Cheng",
                "发布日期": "2023-10-10",
                "摘要": "  The proliferation of Large Language Models (LLMs) has driven considerable\ninterest in fine-tuning them with domain-specific data to create specialized\nlanguage models. Nevertheless, such domain-specific fine-tuning data often\ncontains sensitive personally identifiable information (PII). Direct\nfine-tuning LLMs on this data without privacy protection poses a risk of\nleakage. To address this challenge, we introduce Privacy Protection Language\nModels (PPLM), a novel paradigm for fine-tuning LLMs that effectively injects\ndomain-specific knowledge while safeguarding data privacy. Our work offers a\ntheoretical analysis for model design and delves into various techniques such\nas corpus curation, penalty-based unlikelihood in training loss, and\ninstruction-based tuning, etc. Extensive experiments across diverse datasets\nand scenarios demonstrate the effectiveness of our approaches. In particular,\ninstruction tuning with both positive and negative examples, stands out as a\npromising method, effectively protecting private data while enhancing the\nmodel's knowledge. Our work underscores the potential for Large Language Models\nas robust privacy protection learners.\n",
                "链接": "https://arxiv.org/abs/2310.02469"
            },
            {
                "文章ID": "108690",
                "标题": "User Inference Attacks on Large Language Models",
                "作者": " Nikhil Kandpal,  Krishna Pillutla,  Alina Oprea,  Peter Kairouz,  Christopher A. Choquette-Choo,  Zheng Xu",
                "发布日期": "2023-10-16",
                "摘要": "  Fine-tuning is a common and effective method for tailoring large language\nmodels (LLMs) to specialized tasks and applications. In this paper, we study\nthe privacy implications of fine-tuning LLMs on user data. To this end, we\ndefine a realistic threat model, called user inference, wherein an attacker\ninfers whether or not a user's data was used for fine-tuning. We implement\nattacks for this threat model that require only a small set of samples from a\nuser (possibly different from the samples used for training) and black-box\naccess to the fine-tuned LLM. We find that LLMs are susceptible to user\ninference attacks across a variety of fine-tuning datasets, at times with near\nperfect attack success rates. Further, we investigate which properties make\nusers vulnerable to user inference, finding that outlier users (i.e. those with\ndata distributions sufficiently different from other users) and users who\ncontribute large quantities of data are most susceptible to attack. Finally, we\nexplore several heuristics for mitigating privacy attacks. We find that\ninterventions in the training algorithm, such as batch or per-example gradient\nclipping and early stopping fail to prevent user inference. However, limiting\nthe number of fine-tuning samples from a single user can reduce attack\neffectiveness, albeit at the cost of reducing the total amount of fine-tuning\ndata.\n",
                "链接": "https://arxiv.org/abs/2310.09266"
            },
            {
                "文章ID": "111764",
                "标题": "An Open Source Data Contamination Report for Large Language Models",
                "作者": " Yucheng Li",
                "发布日期": "2023-12-19",
                "摘要": "  Data contamination in language model evaluation is increasingly prevalent as\nthe popularity of large language models. It allows models to \"cheat\" via\nmemorisation instead of displaying true capabilities. Therefore, contamination\nanalysis has became an crucial part of reliable model evaluation to validate\nresults. However, existing contamination analysis is usually conducted\ninternally by LLM developers and often lacks transparency and completeness.\nThis paper present an open source data contamination reports for the Llama\nseries models. We analyse six popular multi-choice QA benchmarks and quantify\ntheir overlapping with the training set of Llama. Various levels of\ncontamination ranging from 1\\% to 8.7\\% are found across benchmarks. Our\ncomparison also reveals that Llama models can gain over 5\\% higher accuracy on\ncontaminated subsets versus clean subsets. Data and code are available at:\nhttps://github.com/liyucheng09/Contamination_Detector.\n",
                "链接": "https://arxiv.org/abs/2310.17589"
            },
            {
                "文章ID": "41014",
                "标题": "PQLM -- Multilingual Decentralized Portable Quantum Language Model for\n  Privacy Protection",
                "作者": " Shuyue Stella Li,  Xiangyu Zhang,  Shu Zhou,  Hongchao Shu,  Ruixing Liang,  Hexin Liu,  Leibny Paola Garcia",
                "发布日期": "2023-02-28",
                "摘要": "  With careful manipulation, malicious agents can reverse engineer private\ninformation encoded in pre-trained language models. Security concerns motivate\nthe development of quantum pre-training. In this work, we propose a highly\nPortable Quantum Language Model (PQLM) that can easily transmit information to\ndownstream tasks on classical machines. The framework consists of a cloud PQLM\nbuilt with random Variational Quantum Classifiers (VQC) and local models for\ndownstream applications. We demonstrate the ad hoc portability of the quantum\nmodel by extracting only the word embeddings and effectively applying them to\ndownstream tasks on classical machines. Our PQLM exhibits comparable\nperformance to its classical counterpart on both intrinsic evaluation (loss,\nperplexity) and extrinsic evaluation (multilingual sentiment analysis accuracy)\nmetrics. We also perform ablation studies on the factors affecting PQLM\nperformance to analyze model stability. Our work establishes a theoretical\nfoundation for a portable quantum pre-trained language model that could be\ntrained on private data and made available for public use with privacy\nprotection guarantees.\n",
                "链接": "https://arxiv.org/abs/2210.03221"
            },
            {
                "文章ID": "114592",
                "标题": "An Interdisciplinary Outlook on Large Language Models for Scientific\n  Research",
                "作者": " James Boyko,  Joseph Cohen,  Nathan Fox,  Maria Han Veiga,  Jennifer I-Hsiu Li,  Jing Liu,  Bernardo Modenesi,  Andreas H. Rauch,  Kenneth N. Reid,  Soumi Tribedi,  Anastasia Visheratina,  Xin Xie",
                "发布日期": "2023-11-10",
                "摘要": "  In this paper, we describe the capabilities and constraints of Large Language\nModels (LLMs) within disparate academic disciplines, aiming to delineate their\nstrengths and limitations with precision. We examine how LLMs augment\nscientific inquiry, offering concrete examples such as accelerating literature\nreview by summarizing vast numbers of publications, enhancing code development\nthrough automated syntax correction, and refining the scientific writing\nprocess. Simultaneously, we articulate the challenges LLMs face, including\ntheir reliance on extensive and sometimes biased datasets, and the potential\nethical dilemmas stemming from their use. Our critical discussion extends to\nthe varying impacts of LLMs across fields, from the natural sciences, where\nthey help model complex biological sequences, to the social sciences, where\nthey can parse large-scale qualitative data. We conclude by offering a nuanced\nperspective on how LLMs can be both a boon and a boundary to scientific\nprogress.\n",
                "链接": "https://arxiv.org/abs/2311.04929"
            },
            {
                "文章ID": "80553",
                "标题": "Large Language Models for User Interest Journeys",
                "作者": " Konstantina Christakopoulou,  Alberto Lalama,  Cj Adams,  Iris Qu,  Yifat Amir,  Samer Chucri,  Pierce Vollucci,  Fabio Soldo,  Dina Bseiso,  Sarah Scodel,  Lucas Dixon,  Ed H. Chi,  Minmin Chen",
                "发布日期": "2023-05-26",
                "摘要": "  Large language models (LLMs) have shown impressive capabilities in natural\nlanguage understanding and generation. Their potential for deeper user\nunderstanding and improved personalized user experience on recommendation\nplatforms is, however, largely untapped. This paper aims to address this gap.\nRecommender systems today capture users' interests through encoding their\nhistorical activities on the platforms. The generated user representations are\nhard to examine or interpret. On the other hand, if we were to ask people about\ninterests they pursue in their life, they might talk about their hobbies, like\nI just started learning the ukulele, or their relaxation routines, e.g., I like\nto watch Saturday Night Live, or I want to plant a vertical garden. We argue,\nand demonstrate through extensive experiments, that LLMs as foundation models\ncan reason through user activities, and describe their interests in nuanced and\ninteresting ways, similar to how a human would.\n  We define interest journeys as the persistent and overarching user interests,\nin other words, the non-transient ones. These are the interests that we believe\nwill benefit most from the nuanced and personalized descriptions. We introduce\na framework in which we first perform personalized extraction of interest\njourneys, and then summarize the extracted journeys via LLMs, using techniques\nlike few-shot prompting, prompt-tuning and fine-tuning. Together, our results\nin prompting LLMs to name extracted user journeys in a large-scale industrial\nplatform demonstrate great potential of these models in providing deeper, more\ninterpretable, and controllable user understanding. We believe LLM powered user\nunderstanding can be a stepping stone to entirely new user experiences on\nrecommendation platforms that are journey-aware, assistive, and enabling\nfrictionless conversation down the line.\n",
                "链接": "https://arxiv.org/abs/2305.15498"
            },
            {
                "文章ID": "98842",
                "标题": "Examining User-Friendly and Open-Sourced Large GPT Models: A Survey on\n  Language, Multimodal, and Scientific GPT Models",
                "作者": " Kaiyuan Gao,  Sunan He,  Zhenyu He,  Jiacheng Lin,  QiZhi Pei,  Jie Shao,  Wei Zhang",
                "发布日期": "2023-08-29",
                "摘要": "  Generative pre-trained transformer (GPT) models have revolutionized the field\nof natural language processing (NLP) with remarkable performance in various\ntasks and also extend their power to multimodal domains. Despite their success,\nlarge GPT models like GPT-4 face inherent limitations such as considerable\nsize, high computational requirements, complex deployment processes, and closed\ndevelopment loops. These constraints restrict their widespread adoption and\nraise concerns regarding their responsible development and usage. The need for\nuser-friendly, relatively small, and open-sourced alternative GPT models arises\nfrom the desire to overcome these limitations while retaining high performance.\nIn this survey paper, we provide an examination of alternative open-sourced\nmodels of large GPTs, focusing on user-friendly and relatively small models\nthat facilitate easier deployment and accessibility. Through this extensive\nsurvey, we aim to equip researchers, practitioners, and enthusiasts with a\nthorough understanding of user-friendly and relatively small open-sourced\nmodels of large GPTs, their current state, challenges, and future research\ndirections, inspiring the development of more efficient, accessible, and\nversatile GPT models that cater to the broader scientific community and advance\nthe field of general artificial intelligence. The source contents are\ncontinuously updating in https://github.com/GPT-Alternatives/gpt_alternatives.\n",
                "链接": "https://arxiv.org/abs/2308.14149"
            },
            {
                "文章ID": "85712",
                "标题": "Protecting User Privacy in Remote Conversational Systems: A\n  Privacy-Preserving framework based on text sanitization",
                "作者": " Zhigang Kan,  Linbo Qiao,  Hao Yu,  Liwen Peng,  Yifu Gao,  Dongsheng Li",
                "发布日期": "2023-06-16",
                "摘要": "  Large Language Models (LLMs) are gaining increasing attention due to their\nexceptional performance across numerous tasks. As a result, the general public\nutilize them as an influential tool for boosting their productivity while\nnatural language processing researchers endeavor to employ them in solving\nexisting or new research problems. Unfortunately, individuals can only access\nsuch powerful AIs through APIs, which ultimately leads to the transmission of\nraw data to the models' providers and increases the possibility of privacy data\nleakage. Current privacy-preserving methods for cloud-deployed language models\naim to protect privacy information in the pre-training dataset or during the\nmodel training phase. However, they do not meet the specific challenges\npresented by the remote access approach of new large-scale language models.\n  This paper introduces a novel task, \"User Privacy Protection for Dialogue\nModels,\" which aims to safeguard sensitive user information from any possible\ndisclosure while conversing with chatbots. We also present an evaluation scheme\nfor this task, which covers evaluation metrics for privacy protection, data\navailability, and resistance to simulation attacks. Moreover, we propose the\nfirst framework for this task, namely privacy protection through text\nsanitization. Before sending the input to remote large models, it filters out\nthe sensitive information, using several rounds of text sanitization based on\nprivacy types that users define. Upon receiving responses from the larger\nmodel, our framework automatically restores privacy to ensure that the\nconversation goes smoothly, without intervention from the privacy filter.\nExperiments based on real-world datasets demonstrate the efficacy of our\nprivacy-preserving approach against eavesdropping from potential attackers.\n",
                "链接": "https://arxiv.org/abs/2306.08223"
            },
            {
                "文章ID": "5282",
                "标题": "Privacy protection based on mask template",
                "作者": " Hao Wang,  Yu Bai,  Guangmin Sun,  Jie Liu",
                "发布日期": "2022-02-15",
                "摘要": "  Powerful recognition algorithms are widely used in the Internet or important\nmedical systems, which poses a serious threat to personal privacy. Although the\nlaw provides for diversity protection, e.g. The General Data Protection\nRegulation (GDPR) in Europe and Articles 1032 to 1039 of the civil code in\nChina. However, as an important privacy disclosure event, biometric data is\noften hidden, which is difficult for the owner to detect and trace to the\nsource. Human biometrics generally exist in images. In order to avoid the\ndisclosure of personal privacy, we should prevent unauthorized recognition\nalgorithms from acquiring the real features of the original image.\n",
                "链接": "https://arxiv.org/abs/2202.06250"
            },
            {
                "文章ID": "24967",
                "标题": "Adversarial Privacy Protection on Speech Enhancement",
                "作者": " Mingyu Dong,  Diqun Yan,  Rangding Wang",
                "发布日期": "2022-06-17",
                "摘要": "  Speech is easily leaked imperceptibly, such as being recorded by mobile\nphones in different situations. Private content in speech may be maliciously\nextracted through speech enhancement technology. Speech enhancement technology\nhas developed rapidly along with deep neural networks (DNNs), but adversarial\nexamples can cause DNNs to fail. In this work, we propose an adversarial method\nto degrade speech enhancement systems. Experimental results show that generated\nadversarial examples can erase most content information in original examples or\nreplace it with target speech content through speech enhancement. The word\nerror rate (WER) between an enhanced original example and enhanced adversarial\nexample recognition result can reach 89.0%. WER of target attack between\nenhanced adversarial example and target example is low to 33.75% . Adversarial\nperturbation can bring the rate of change to the original example to more than\n1.4430. This work can prevent the malicious extraction of speech.\n",
                "链接": "https://arxiv.org/abs/2206.08170"
            }
        ]
    },
    {
        "question": {
            "question": "推荐与AutoGPT相似的10篇文献",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "123126",
                "标题": "Do Similar Entities have Similar Embeddings?",
                "作者": " Nicolas Hubert,  Heiko Paulheim,  Armelle Brun,  Davy Monticolo",
                "发布日期": "2023-12-19",
                "摘要": "  Knowledge graph embedding models (KGEMs) developed for link prediction learn\nvector representations for graph entities, known as embeddings. A common tacit\nassumption is the KGE entity similarity assumption, which states that these\nKGEMs retain the graph's structure within their embedding space, i.e., position\nsimilar entities close to one another. This desirable property make KGEMs\nwidely used in downstream tasks such as recommender systems or drug\nrepurposing. Yet, the alignment of graph similarity with embedding space\nsimilarity has rarely been formally evaluated. Typically, KGEMs are assessed\nbased on their sole link prediction capabilities, using ranked-based metrics\nsuch as Hits@K or Mean Rank. This paper challenges the prevailing assumption\nthat entity similarity in the graph is inherently mirrored in the embedding\nspace. Therefore, we conduct extensive experiments to measure the capability of\nKGEMs to cluster similar entities together, and investigate the nature of the\nunderlying factors. Moreover, we study if different KGEMs expose a different\nnotion of similarity. Datasets, pre-trained embeddings and code are available\nat: https://github.com/nicolas-hbt/similar-embeddings.\n",
                "链接": "https://arxiv.org/abs/2312.10370"
            },
            {
                "文章ID": "100452",
                "标题": "Doppelgangers: Learning to Disambiguate Images of Similar Structures",
                "作者": " Ruojin Cai,  Joseph Tung,  Qianqian Wang,  Hadar Averbuch-Elor,  Bharath Hariharan,  Noah Snavely",
                "发布日期": "2023-09-06",
                "摘要": "  We consider the visual disambiguation task of determining whether a pair of\nvisually similar images depict the same or distinct 3D surfaces (e.g., the same\nor opposite sides of a symmetric building). Illusory image matches, where two\nimages observe distinct but visually similar 3D surfaces, can be challenging\nfor humans to differentiate, and can also lead 3D reconstruction algorithms to\nproduce erroneous results. We propose a learning-based approach to visual\ndisambiguation, formulating it as a binary classification task on image pairs.\nTo that end, we introduce a new dataset for this problem, Doppelgangers, which\nincludes image pairs of similar structures with ground truth labels. We also\ndesign a network architecture that takes the spatial distribution of local\nkeypoints and matches as input, allowing for better reasoning about both local\nand global cues. Our evaluation shows that our method can distinguish illusory\nmatches in difficult cases, and can be integrated into SfM pipelines to produce\ncorrect, disambiguated 3D reconstructions. See our project page for our code,\ndatasets, and more results: http://doppelgangers-3d.github.io/.\n",
                "链接": "https://arxiv.org/abs/2309.02420"
            },
            {
                "文章ID": "11104",
                "标题": "CNNs and Transformers Perceive Hybrid Images Similar to Humans",
                "作者": " Ali Borji",
                "发布日期": "2022-03-23",
                "摘要": "  Hybrid images is a technique to generate images with two interpretations that\nchange as a function of viewing distance. It has been utilized to study\nmultiscale processing of images by the human visual system. Using 63,000 hybrid\nimages across 10 fruit categories, here we show that predictions of deep\nlearning vision models qualitatively matches with the human perception of these\nimages. Our results provide yet another evidence in support of the hypothesis\nthat Convolutional Neural Networks (CNNs) and Transformers are good at modeling\nthe feedforward sweep of information in the ventral stream of visual cortex.\nCode and data is available at https://github.com/aliborji/hybrid_images.git.\n",
                "链接": "https://arxiv.org/abs/2203.11678"
            },
            {
                "文章ID": "86417",
                "标题": "AD-AutoGPT: An Autonomous GPT for Alzheimer's Disease Infodemiology",
                "作者": " Haixing Dai,  Yiwei Li,  Zhengliang Liu,  Lin Zhao,  Zihao Wu,  Suhang Song,  Ye Shen,  Dajiang Zhu,  Xiang Li,  Sheng Li,  Xiaobai Yao,  Lu Shi,  Quanzheng Li,  Zhuo Chen,  Donglan Zhang,  Gengchen Mai,  Tianming Liu",
                "发布日期": "2023-06-21",
                "摘要": "  In this pioneering study, inspired by AutoGPT, the state-of-the-art\nopen-source application based on the GPT-4 large language model, we develop a\nnovel tool called AD-AutoGPT which can conduct data collection, processing, and\nanalysis about complex health narratives of Alzheimer's Disease in an\nautonomous manner via users' textual prompts. We collated comprehensive data\nfrom a variety of news sources, including the Alzheimer's Association, BBC,\nMayo Clinic, and the National Institute on Aging since June 2022, leading to\nthe autonomous execution of robust trend analyses, intertopic distance maps\nvisualization, and identification of salient terms pertinent to Alzheimer's\nDisease. This approach has yielded not only a quantifiable metric of relevant\ndiscourse but also valuable insights into public focus on Alzheimer's Disease.\nThis application of AD-AutoGPT in public health signifies the transformative\npotential of AI in facilitating a data-rich understanding of complex health\nnarratives like Alzheimer's Disease in an autonomous manner, setting the\ngroundwork for future AI-driven investigations in global health landscapes.\n",
                "链接": "https://arxiv.org/abs/2306.10095"
            },
            {
                "文章ID": "119654",
                "标题": "A Turing Test: Are AI Chatbots Behaviorally Similar to Humans?",
                "作者": " Qiaozhu Mei,  Yutong Xie,  Walter Yuan,  Matthew O. Jackson",
                "发布日期": "2023-12-05",
                "摘要": "  We administer a Turing Test to AI Chatbots. We examine how Chatbots behave in\na suite of classic behavioral games that are designed to elicit characteristics\nsuch as trust, fairness, risk-aversion, cooperation, \\textit{etc.}; as well as\na traditional Big-5 psychological survey that measures personality traits.\nChatGPT-4 passes the Turing Test in that it consistently exhibits human-like\nbehavioral and personality traits based on a comparison to the behavior of\nhundreds of thousands of humans from more than 50 countries. Chatbots also\nmodify their behavior based on previous experience and contexts ``as if'' they\nwere learning from the interactions, and change their behavior in response to\ndifferent framings of the same strategic situation. Their behaviors are often\ndistinct from average and modal human behaviors, in which case they tend to\nbehave on the more altruistic and cooperative end of the distribution. We\nestimate that they act as if they are maximizing an average of their own and\npartner's payoff.\n",
                "链接": "https://arxiv.org/abs/2312.00798"
            },
            {
                "文章ID": "96778",
                "标题": "Understanding User Intent Modeling for Conversational Recommender\n  Systems: A Systematic Literature Review",
                "作者": " Siamak Farshidi,  Kiyan Rezaee,  Sara Mazaheri,  Amir Hossein Rahimi,  Ali Dadashzadeh,  Morteza Ziabakhsh,  Sadegh Eskandari,  Slinger Jansen",
                "发布日期": "2023-08-17",
                "摘要": "  Context: User intent modeling is a crucial process in Natural Language\nProcessing that aims to identify the underlying purpose behind a user's\nrequest, enabling personalized responses. With a vast array of approaches\nintroduced in the literature (over 13,000 papers in the last decade),\nunderstanding the related concepts and commonly used models in AI-based systems\nis essential. Method: We conducted a systematic literature review to gather\ndata on models typically employed in designing conversational recommender\nsystems. From the collected data, we developed a decision model to assist\nresearchers in selecting the most suitable models for their systems.\nAdditionally, we performed two case studies to evaluate the effectiveness of\nour proposed decision model. Results: Our study analyzed 59 distinct models and\nidentified 74 commonly used features. We provided insights into potential model\ncombinations, trends in model selection, quality concerns, evaluation measures,\nand frequently used datasets for training and evaluating these models.\nContribution: Our study contributes practical insights and a comprehensive\nunderstanding of user intent modeling, empowering the development of more\neffective and personalized conversational recommender systems. With the\nConversational Recommender System, researchers can perform a more systematic\nand efficient assessment of fitting intent modeling frameworks.\n",
                "链接": "https://arxiv.org/abs/2308.08496"
            },
            {
                "文章ID": "18016",
                "标题": "Do Different Deep Metric Learning Losses Lead to Similar Learned\n  Features?",
                "作者": " Konstantin Kobs,  Michael Steininger,  Andrzej Dulny,  Andreas Hotho",
                "发布日期": "2022-05-06",
                "摘要": "  Recent studies have shown that many deep metric learning loss functions\nperform very similarly under the same experimental conditions. One potential\nreason for this unexpected result is that all losses let the network focus on\nsimilar image regions or properties. In this paper, we investigate this by\nconducting a two-step analysis to extract and compare the learned visual\nfeatures of the same model architecture trained with different loss functions:\nFirst, we compare the learned features on the pixel level by correlating\nsaliency maps of the same input images. Second, we compare the clustering of\nembeddings for several image properties, e.g. object color or illumination. To\nprovide independent control over these properties, photo-realistic 3D car\nrenders similar to images in the Cars196 dataset are generated. In our\nanalysis, we compare 14 pretrained models from a recent study and find that,\neven though all models perform similarly, different loss functions can guide\nthe model to learn different features. We especially find differences between\nclassification and ranking based losses. Our analysis also shows that some\nseemingly irrelevant properties can have significant influence on the resulting\nembedding. We encourage researchers from the deep metric learning community to\nuse our methods to get insights into the features learned by their proposed\nmethods.\n",
                "链接": "https://arxiv.org/abs/2205.02698"
            },
            {
                "文章ID": "27348",
                "标题": "Is neural language acquisition similar to natural? A chronological\n  probing study",
                "作者": " Ekaterina Voloshina,  Oleg Serikov,  Tatiana Shavrina",
                "发布日期": "2022-07-04",
                "摘要": "  The probing methodology allows one to obtain a partial representation of\nlinguistic phenomena stored in the inner layers of the neural network, using\nexternal classifiers and statistical analysis. Pre-trained transformer-based\nlanguage models are widely used both for natural language understanding (NLU)\nand natural language generation (NLG) tasks making them most commonly used for\ndownstream applications. However, little analysis was carried out, whether the\nmodels were pre-trained enough or contained knowledge correlated with\nlinguistic theory. We are presenting the chronological probing study of\ntransformer English models such as MultiBERT and T5. We sequentially compare\nthe information about the language learned by the models in the process of\ntraining on corpora. The results show that 1) linguistic information is\nacquired in the early stages of training 2) both language models demonstrate\ncapabilities to capture various features from various levels of language,\nincluding morphology, syntax, and even discourse, while they also can\ninconsistently fail on tasks that are perceived as easy. We also introduce the\nopen-source framework for chronological probing research, compatible with other\ntransformer-based models.\nhttps://github.com/EkaterinaVoloshina/chronological_probing\n",
                "链接": "https://arxiv.org/abs/2207.00560"
            },
            {
                "文章ID": "20384",
                "标题": "Diversity Preference-Aware Link Recommendation for Online Social\n  Networks",
                "作者": " Kexin Yin,  Xiao Fang,  Bintong Chen,  Olivia Sheng",
                "发布日期": "2022-10-19",
                "摘要": "  Link recommendation, which recommends links to connect unlinked online social\nnetwork users, is a fundamental social network analytics problem with ample\nbusiness implications. Existing link recommendation methods tend to recommend\nsimilar friends to a user but overlook the user's diversity preference,\nalthough social psychology theories suggest the criticality of diversity\npreference to link recommendation performance. In recommender systems, a field\nrelated to link recommendation, a number of diversification methods have been\nproposed to improve the diversity of recommended items. Nevertheless, diversity\npreference is distinct from diversity studied by diversification methods. To\naddress these research gaps, we define and operationalize the concept of\ndiversity preference for link recommendation and propose a new link\nrecommendation problem: the diversity preference-aware link recommendation\nproblem. We then analyze key properties of the new link recommendation problem\nand develop a novel link recommendation method to solve the problem. Using two\nlarge-scale online social network data sets, we conduct extensive empirical\nevaluations to demonstrate the superior performance of our method over\nrepresentative diversification methods adapted for link recommendation as well\nas state-of-the-art link recommendation methods.\n",
                "链接": "https://arxiv.org/abs/2205.10689"
            },
            {
                "文章ID": "60937",
                "标题": "AutoNMT: A Framework to Streamline the Research of Seq2Seq Models",
                "作者": " Salvador Carrión,  Francisco Casacuberta",
                "发布日期": "2023-02-13",
                "摘要": "  We present AutoNMT, a framework to streamline the research of seq-to-seq\nmodels by automating the data pipeline (i.e., file management, data\npreprocessing, and exploratory analysis), automating experimentation in a\ntoolkit-agnostic manner, which allows users to use either their own models or\nexisting seq-to-seq toolkits such as Fairseq or OpenNMT, and finally,\nautomating the report generation (plots and summaries). Furthermore, this\nlibrary comes with its own seq-to-seq toolkit so that users can easily\ncustomize it for non-standard tasks.\n",
                "链接": "https://arxiv.org/abs/2302.04981"
            }
        ]
    },
    {
        "question": {
            "question": "请搜索近一年发表的有关多模态大模型与产业相结合、与具体应用场景相结合的论文",
            "type": "2"
        },
        "results": [
            {
                "文章ID": "117658",
                "标题": "Some Like It Small: Czech Semantic Embedding Models for Industry\n  Applications",
                "作者": " Jiří Bednář,  Jakub Náplava,  Petra Barančíková,  Ondřej Lisický",
                "发布日期": "2023-11-27",
                "摘要": "  This article focuses on the development and evaluation of Small-sized Czech\nsentence embedding models. Small models are important components for real-time\nindustry applications in resource-constrained environments. Given the limited\navailability of labeled Czech data, alternative approaches, including\npre-training, knowledge distillation, and unsupervised contrastive fine-tuning,\nare investigated. Comprehensive intrinsic and extrinsic analyses are conducted,\nshowcasing the competitive performance of our models compared to significantly\nlarger counterparts, with approximately 8 times smaller size and 5 times faster\nspeed than conventional Base-sized models. To promote cooperation and\nreproducibility, both the models and the evaluation pipeline are made publicly\naccessible. Ultimately, this article presents practical applications of the\ndeveloped sentence embedding models in Seznam.cz, the Czech search engine.\nThese models have effectively replaced previous counterparts, enhancing the\noverall search experience for instance, in organic search, featured snippets,\nand image search. This transition has yielded improved performance.\n",
                "链接": "https://arxiv.org/abs/2311.13921"
            },
            {
                "文章ID": "95924",
                "标题": "Large Language Models for Telecom: Forthcoming Impact on the Industry",
                "作者": " Ali Maatouk,  Nicola Piovesan,  Fadhel Ayed,  Antonio De Domenico,  Merouane Debbah",
                "发布日期": "2023-08-14",
                "摘要": "  Large Language Models (LLMs) have emerged as a transformative force,\nrevolutionizing numerous fields well beyond the conventional domain of Natural\nLanguage Processing (NLP) and garnering unprecedented attention. As LLM\ntechnology continues to progress, the telecom industry is facing the prospect\nof its potential impact on its landscape. To elucidate these implications, we\ndelve into the inner workings of LLMs, providing insights into their current\ncapabilities and limitations. We also examine the use cases that can be readily\nimplemented in the telecom industry, streamlining numerous tasks that currently\nhinder operational efficiency and demand significant manpower and engineering\nexpertise. Furthermore, we uncover essential research directions that deal with\nthe distinctive challenges of utilizing the LLMs within the telecom domain.\nAddressing these challenges represents a significant stride towards fully\nharnessing the potential of LLMs and unlocking their capabilities to the\nfullest extent within the telecom domain.\n",
                "链接": "https://arxiv.org/abs/2308.06013"
            },
            {
                "文章ID": "104627",
                "标题": "Jointly Training Large Autoregressive Multimodal Models",
                "作者": " Emanuele Aiello,  Lili Yu,  Yixin Nie,  Armen Aghajanyan,  Barlas Oguz",
                "发布日期": "2023-09-29",
                "摘要": "  In recent years, advances in the large-scale pretraining of language and\ntext-to-image models have revolutionized the field of machine learning. Yet,\nintegrating these two modalities into a single, robust model capable of\ngenerating seamless multimodal outputs remains a significant challenge. To\naddress this gap, we present the Joint Autoregressive Mixture (JAM) framework,\na modular approach that systematically fuses existing text and image generation\nmodels. We also introduce a specialized, data-efficient instruction-tuning\nstrategy, tailored for mixed-modal generation tasks. Our final instruct-tuned\nmodel demonstrates unparalleled performance in generating high-quality\nmultimodal outputs and represents the first model explicitly designed for this\npurpose.\n",
                "链接": "https://arxiv.org/abs/2309.15564"
            },
            {
                "文章ID": "117408",
                "标题": "Multimodal Large Language Models: A Survey",
                "作者": " Jiayang Wu,  Wensheng Gan,  Zefeng Chen,  Shicheng Wan,  Philip S. Yu",
                "发布日期": "2023-11-23",
                "摘要": "  The exploration of multimodal language models integrates multiple data types,\nsuch as images, text, language, audio, and other heterogeneity. While the\nlatest large language models excel in text-based tasks, they often struggle to\nunderstand and process other data types. Multimodal models address this\nlimitation by combining various modalities, enabling a more comprehensive\nunderstanding of diverse data. This paper begins by defining the concept of\nmultimodal and examining the historical development of multimodal algorithms.\nFurthermore, we introduce a range of multimodal products, focusing on the\nefforts of major technology companies. A practical guide is provided, offering\ninsights into the technical aspects of multimodal models. Moreover, we present\na compilation of the latest algorithms and commonly used datasets, providing\nresearchers with valuable resources for experimentation and evaluation. Lastly,\nwe explore the applications of multimodal models and discuss the challenges\nassociated with their development. By addressing these aspects, this paper aims\nto facilitate a deeper understanding of multimodal models and their potential\nin various domains.\n",
                "链接": "https://arxiv.org/abs/2311.13165"
            },
            {
                "文章ID": "91937",
                "标题": "Challenges and Applications of Large Language Models",
                "作者": " Jean Kaddour,  Joshua Harris,  Maximilian Mozes,  Herbie Bradley,  Roberta Raileanu,  Robert McHardy",
                "发布日期": "2023-07-20",
                "摘要": "  Large Language Models (LLMs) went from non-existent to ubiquitous in the\nmachine learning discourse within a few years. Due to the fast pace of the\nfield, it is difficult to identify the remaining challenges and already\nfruitful application areas. In this paper, we aim to establish a systematic set\nof open problems and application successes so that ML researchers can\ncomprehend the field's current state more quickly and become productive.\n",
                "链接": "https://arxiv.org/abs/2307.10169"
            },
            {
                "文章ID": "87495",
                "标题": "A Survey on Multimodal Large Language Models",
                "作者": " Shukang Yin,  Chaoyou Fu,  Sirui Zhao,  Ke Li,  Xing Sun,  Tong Xu,  Enhong Chen",
                "发布日期": "2023-06-26",
                "摘要": "  Multimodal Large Language Model (MLLM) recently has been a new rising\nresearch hotspot, which uses powerful Large Language Models (LLMs) as a brain\nto perform multimodal tasks. The surprising emergent capabilities of MLLM, such\nas writing stories based on images and OCR-free math reasoning, are rare in\ntraditional methods, suggesting a potential path to artificial general\nintelligence. In this paper, we aim to trace and summarize the recent progress\nof MLLM. First of all, we present the formulation of MLLM and delineate its\nrelated concepts. Then, we discuss the key techniques and applications,\nincluding Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning\n(M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning\n(LAVR). Finally, we discuss existing challenges and point out promising\nresearch directions. In light of the fact that the era of MLLM has only just\nbegun, we will keep updating this survey and hope it can inspire more research.\nAn associated GitHub link collecting the latest papers is available at\nhttps://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.\n",
                "链接": "https://arxiv.org/abs/2306.13549"
            },
            {
                "文章ID": "99625",
                "标题": "Socratis: Are large multimodal models emotionally aware?",
                "作者": " Katherine Deng,  Arijit Ray,  Reuben Tan,  Saadia Gabriel,  Bryan A. Plummer,  Kate Saenko",
                "发布日期": "2023-11-03",
                "摘要": "  Existing emotion prediction benchmarks contain coarse emotion labels which do\nnot consider the diversity of emotions that an image and text can elicit in\nhumans due to various reasons. Learning diverse reactions to multimodal content\nis important as intelligent machines take a central role in generating and\ndelivering content to society. To address this gap, we propose Socratis, a\nsocietal reactions benchmark, where each image-caption (IC) pair is annotated\nwith multiple emotions and the reasons for feeling them. Socratis contains 18K\nfree-form reactions for 980 emotions on 2075 image-caption pairs from 5\nwidely-read news and image-caption (IC) datasets. We benchmark the capability\nof state-of-the-art multimodal large language models to generate the reasons\nfor feeling an emotion given an IC pair. Based on a preliminary human study, we\nobserve that humans prefer human-written reasons over 2 times more often than\nmachine-generated ones. This shows our task is harder than standard generation\ntasks because it starkly contrasts recent findings where humans cannot tell\napart machine vs human-written news articles, for instance. We further see that\ncurrent captioning metrics based on large vision-language models also fail to\ncorrelate with human preferences. We hope that these findings and our benchmark\nwill inspire further research on training emotionally aware models.\n",
                "链接": "https://arxiv.org/abs/2308.16741"
            },
            {
                "文章ID": "108418",
                "标题": "Can We Edit Multimodal Large Language Models?",
                "作者": " Siyuan Cheng,  Bozhong Tian,  Qingbin Liu,  Xi Chen,  Yongheng Wang,  Huajun Chen,  Ningyu Zhang",
                "发布日期": "2023-12-29",
                "摘要": "  In this paper, we focus on editing Multimodal Large Language Models (MLLMs).\nCompared to editing single-modal LLMs, multimodal model editing is more\nchallenging, which demands a higher level of scrutiny and careful consideration\nin the editing process. To facilitate research in this area, we construct a new\nbenchmark, dubbed MMEdit, for editing multimodal LLMs and establishing a suite\nof innovative metrics for evaluation. We conduct comprehensive experiments\ninvolving various model editing baselines and analyze the impact of editing\ndifferent components for multimodal LLMs. Empirically, we notice that previous\nbaselines can implement editing multimodal LLMs to some extent, but the effect\nis still barely satisfactory, indicating the potential difficulty of this task.\nWe hope that our work can provide the NLP community with insights. Code and\ndataset are available in https://github.com/zjunlp/EasyEdit.\n",
                "链接": "https://arxiv.org/abs/2310.08475"
            },
            {
                "文章ID": "118448",
                "标题": "Continual Instruction Tuning for Large Multimodal Models",
                "作者": " Jinghan He,  Haiyun Guo,  Ming Tang,  Jinqiao Wang",
                "发布日期": "2023-11-29",
                "摘要": "  Instruction tuning is now a widely adopted approach to aligning large\nmultimodal models (LMMs) to follow human intent. It unifies the data format of\nvision-language tasks, enabling multi-task joint training. However,\nvision-language tasks are constantly being created in practice. Instead of\nalways re-training LMMs when new tasks arrive, continual learning offers\nflexibility for models to continually and efficiently exploit the evolving\ndata. This work aims to explore the following two questions: 1) Do LMMs still\nsuffer from catastrophic forgetting in continual instruction tuning? 2) Are the\nexisting three classes of continual learning methods still applicable to the\ncontinual instruction tuning of LMMs? An extensive study is conducted to\naddress the above questions. First, we establish the first benchmark in this\nsetting and reveal that catastrophic forgetting is still observed when\ncontinually instruction-tuning LMMs. However, the multi-task joint instruction\ntuning can facilitate the model's continual learning ability and mitigate\nforgetting. Second, we integrate and adapt classic continual learning methods\nto our context, demonstrating the efficacy of data replay and model expansion\nstrategies across diverse scenarios. In contrast, regularization-based methods\nonly perform well on models that have been jointly instruction-tuned on\nmultiple tasks. Third, we delve into the correlation and forgetting dynamics\nbetween vision-language task pairs and propose task-similarity-informed\nregularization and model expansion methods for continual instruction tuning of\nLMMs. Experimental results show that our approach consistently boosts the\nmodel's performance.\n",
                "链接": "https://arxiv.org/abs/2311.16206"
            },
            {
                "文章ID": "116733",
                "标题": "Rethinking Large Language Models in Mental Health Applications",
                "作者": " Shaoxiong Ji,  Tianlin Zhang,  Kailai Yang,  Sophia Ananiadou,  Erik Cambria",
                "发布日期": "2023-12-19",
                "摘要": "  Large Language Models (LLMs) have become valuable assets in mental health,\nshowing promise in both classification tasks and counseling applications. This\npaper offers a perspective on using LLMs in mental health applications. It\ndiscusses the instability of generative models for prediction and the potential\nfor generating hallucinatory outputs, underscoring the need for ongoing audits\nand evaluations to maintain their reliability and dependability. The paper also\ndistinguishes between the often interchangeable terms ``explainability'' and\n``interpretability'', advocating for developing inherently interpretable\nmethods instead of relying on potentially hallucinated self-explanations\ngenerated by LLMs. Despite the advancements in LLMs, human counselors'\nempathetic understanding, nuanced interpretation, and contextual awareness\nremain irreplaceable in the sensitive and complex realm of mental health\ncounseling. The use of LLMs should be approached with a judicious and\nconsiderate mindset, viewing them as tools that complement human expertise\nrather than seeking to replace it.\n",
                "链接": "https://arxiv.org/abs/2311.11267"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究，特别关注使用自动标注和迁移学习方法的论文，时间跨度覆盖2019年至今。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "69437",
                "标题": "Medical Image Analysis using Deep Relational Learning",
                "作者": " Zhihua Liu",
                "发布日期": "2023-03-29",
                "摘要": "  In the past ten years, with the help of deep learning, especially the rapid\ndevelopment of deep neural networks, medical image analysis has made remarkable\nprogress. However, how to effectively use the relational information between\nvarious tissues or organs in medical images is still a very challenging\nproblem, and it has not been fully studied. In this thesis, we propose two\nnovel solutions to this problem based on deep relational learning. First, we\npropose a context-aware fully convolutional network that effectively models\nimplicit relation information between features to perform medical image\nsegmentation. The network achieves the state-of-the-art segmentation results on\nthe Multi Modal Brain Tumor Segmentation 2017 (BraTS2017) and Multi Modal Brain\nTumor Segmentation 2018 (BraTS2018) data sets. Subsequently, we propose a new\nhierarchical homography estimation network to achieve accurate medical image\nmosaicing by learning the explicit spatial relationship between adjacent\nframes. We use the UCL Fetoscopy Placenta dataset to conduct experiments and\nour hierarchical homography estimation network outperforms the other\nstate-of-the-art mosaicing methods while generating robust and meaningful\nmosaicing result on unseen frames.\n",
                "链接": "https://arxiv.org/abs/2303.16099"
            },
            {
                "文章ID": "105884",
                "标题": "Keypoint-Augmented Self-Supervised Learning for Medical Image\n  Segmentation with Limited Annotation",
                "作者": " Zhangsihao Yang,  Mengwei Ren,  Kaize Ding,  Guido Gerig,  Yalin Wang",
                "发布日期": "2023-10-20",
                "摘要": "  Pretraining CNN models (i.e., UNet) through self-supervision has become a\npowerful approach to facilitate medical image segmentation under low annotation\nregimes. Recent contrastive learning methods encourage similar global\nrepresentations when the same image undergoes different transformations, or\nenforce invariance across different image/patch features that are intrinsically\ncorrelated. However, CNN-extracted global and local features are limited in\ncapturing long-range spatial dependencies that are essential in biological\nanatomy. To this end, we present a keypoint-augmented fusion layer that\nextracts representations preserving both short- and long-range self-attention.\nIn particular, we augment the CNN feature map at multiple scales by\nincorporating an additional input that learns long-range spatial self-attention\namong localized keypoint features. Further, we introduce both global and local\nself-supervised pretraining for the framework. At the global scale, we obtain\nglobal representations from both the bottleneck of the UNet, and by aggregating\nmultiscale keypoint features. These global features are subsequently\nregularized through image-level contrastive objectives. At the local scale, we\ndefine a distance-based criterion to first establish correspondences among\nkeypoints and encourage similarity between their features. Through extensive\nexperiments on both MRI and CT segmentation tasks, we demonstrate the\narchitectural advantages of our proposed method in comparison to both CNN and\nTransformer-based UNets, when all architectures are trained with randomly\ninitialized weights. With our proposed pretraining strategy, our method further\noutperforms existing SSL methods by producing more robust self-attention and\nachieving state-of-the-art segmentation results. The code is available at\nhttps://github.com/zshyang/kaf.git.\n",
                "链接": "https://arxiv.org/abs/2310.01680"
            },
            {
                "文章ID": "34051",
                "标题": "PyMIC: A deep learning toolkit for annotation-efficient medical image\n  segmentation",
                "作者": " Guotai Wang,  Xiangde Luo,  Ran Gu,  Shuojue Yang,  Yijie Qu,  Shuwei Zhai,  Qianfei Zhao,  Kang Li,  Shaoting Zhang",
                "发布日期": "2023-02-14",
                "摘要": "  Background and Objective: Open-source deep learning toolkits are one of the\ndriving forces for developing medical image segmentation models. Existing\ntoolkits mainly focus on fully supervised segmentation and require full and\naccurate pixel-level annotations that are time-consuming and difficult to\nacquire for segmentation tasks, which makes learning from imperfect labels\nhighly desired for reducing the annotation cost. We aim to develop a new deep\nlearning toolkit to support annotation-efficient learning for medical image\nsegmentation.\n  Methods: Our proposed toolkit named PyMIC is a modular deep learning library\nfor medical image segmentation tasks. In addition to basic components that\nsupport development of high-performance models for fully supervised\nsegmentation, it contains several advanced components tailored for learning\nfrom imperfect annotations, such as loading annotated and unannounced images,\nloss functions for unannotated, partially or inaccurately annotated images, and\ntraining procedures for co-learning between multiple networks, etc. PyMIC\nsupports development of semi-supervised, weakly supervised and noise-robust\nlearning methods for medical image segmentation.\n  Results: We present several illustrative medical image segmentation tasks\nbased on PyMIC: (1) Achieving competitive performance on fully supervised\nlearning; (2) Semi-supervised cardiac structure segmentation with only 10%\ntraining images annotated; (3) Weakly supervised segmentation using scribble\nannotations; and (4) Learning from noisy labels for chest radiograph\nsegmentation.\n  Conclusions: The PyMIC toolkit is easy to use and facilitates efficient\ndevelopment of medical image segmentation models with imperfect annotations. It\nis modular and flexible, which enables researchers to develop high-performance\nmodels with low annotation cost. The source code is available at:\nhttps://github.com/HiLab-git/PyMIC.\n",
                "链接": "https://arxiv.org/abs/2208.09350"
            },
            {
                "文章ID": "93650",
                "标题": "Cross-dimensional transfer learning in medical image segmentation with\n  deep learning",
                "作者": " Hicham Messaoudi,  Ahror Belaid,  Douraied Ben Salem,  Pierre-Henri Conze",
                "发布日期": "2023-08-01",
                "摘要": "  Over the last decade, convolutional neural networks have emerged and advanced\nthe state-of-the-art in various image analysis and computer vision\napplications. The performance of 2D image classification networks is constantly\nimproving and being trained on databases made of millions of natural images.\nHowever, progress in medical image analysis has been hindered by limited\nannotated data and acquisition constraints. These limitations are even more\npronounced given the volumetry of medical imaging data. In this paper, we\nintroduce an efficient way to transfer the efficiency of a 2D classification\nnetwork trained on natural images to 2D, 3D uni- and multi-modal medical image\nsegmentation applications. In this direction, we designed novel architectures\nbased on two key principles: weight transfer by embedding a 2D pre-trained\nencoder into a higher dimensional U-Net, and dimensional transfer by expanding\na 2D segmentation network into a higher dimension one. The proposed networks\nwere tested on benchmarks comprising different modalities: MR, CT, and\nultrasound images. Our 2D network ranked first on the CAMUS challenge dedicated\nto echo-cardiographic data segmentation and surpassed the state-of-the-art.\nRegarding 2D/3D MR and CT abdominal images from the CHAOS challenge, our\napproach largely outperformed the other 2D-based methods described in the\nchallenge paper on Dice, RAVD, ASSD, and MSSD scores and ranked third on the\nonline evaluation platform. Our 3D network applied to the BraTS 2022\ncompetition also achieved promising results, reaching an average Dice score of\n91.69% (91.22%) for the whole tumor, 83.23% (84.77%) for the tumor core, and\n81.75% (83.88%) for enhanced tumor using the approach based on weight\n(dimensional) transfer. Experimental and qualitative results illustrate the\neffectiveness of our methods for multi-dimensional medical image segmentation.\n",
                "链接": "https://arxiv.org/abs/2307.15872"
            },
            {
                "文章ID": "110503",
                "标题": "A comprehensive survey on deep active learning and its applications in\n  medical image analysis",
                "作者": " Haoran Wang,  Qiuye Jin,  Shiman Li,  Siyu Liu,  Manning Wang,  Zhijian Song",
                "发布日期": "2023-10-25",
                "摘要": "  Deep learning has achieved widespread success in medical image analysis,\nleading to an increasing demand for large-scale expert-annotated medical image\ndatasets. Yet, the high cost of annotating medical images severely hampers the\ndevelopment of deep learning in this field. To reduce annotation costs, active\nlearning aims to select the most informative samples for annotation and train\nhigh-performance models with as few labeled samples as possible. In this\nsurvey, we review the core methods of active learning, including the evaluation\nof informativeness and sampling strategy. For the first time, we provide a\ndetailed summary of the integration of active learning with other\nlabel-efficient techniques, such as semi-supervised, self-supervised learning,\nand so on. Additionally, we also highlight active learning works that are\nspecifically tailored to medical image analysis. In the end, we offer our\nperspectives on the future trends and challenges of active learning and its\napplications in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2310.14230"
            },
            {
                "文章ID": "68134",
                "标题": "Label-Efficient Deep Learning in Medical Image Analysis: Challenges and\n  Future Directions",
                "作者": " Cheng Jin,  Zhengrui Guo,  Yi Lin,  Luyang Luo,  Hao Chen",
                "发布日期": "2023-12-21",
                "摘要": "  Deep learning has seen rapid growth in recent years and achieved\nstate-of-the-art performance in a wide range of applications. However, training\nmodels typically requires expensive and time-consuming collection of large\nquantities of labeled data. This is particularly true within the scope of\nmedical imaging analysis (MIA), where data are limited and labels are expensive\nto be acquired. Thus, label-efficient deep learning methods are developed to\nmake comprehensive use of the labeled data as well as the abundance of\nunlabeled and weak-labeled data. In this survey, we extensively investigated\nover 300 recent papers to provide a comprehensive overview of recent progress\non label-efficient learning strategies in MIA. We first present the background\nof label-efficient learning and categorize the approaches into different\nschemes. Next, we examine the current state-of-the-art methods in detail\nthrough each scheme. Specifically, we provide an in-depth investigation,\ncovering not only canonical semi-supervised, self-supervised, and\nmulti-instance learning schemes, but also recently emerged active and\nannotation-efficient learning strategies. Moreover, as a comprehensive\ncontribution to the field, this survey not only elucidates the commonalities\nand unique features of the surveyed methods but also presents a detailed\nanalysis of the current challenges in the field and suggests potential avenues\nfor future research.\n",
                "链接": "https://arxiv.org/abs/2303.12484"
            },
            {
                "文章ID": "52332",
                "标题": "A Trustworthy Framework for Medical Image Analysis with Deep Learning",
                "作者": " Kai Ma,  Siyuan He,  Pengcheng Xi,  Ashkan Ebadi,  Stéphane Tremblay,  Alexander Wong",
                "发布日期": "2022-12-07",
                "摘要": "  Computer vision and machine learning are playing an increasingly important\nrole in computer-assisted diagnosis; however, the application of deep learning\nto medical imaging has challenges in data availability and data imbalance, and\nit is especially important that models for medical imaging are built to be\ntrustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning\nframework for medical image analysis, which adopts a modular design, leverages\nself-supervised pre-training, and utilizes a novel surrogate loss function.\nExperimental evaluations indicate that models generated from the framework are\nboth trustworthy and high-performing. It is anticipated that the framework will\nsupport researchers and clinicians in advancing the use of deep learning for\ndealing with public health crises including COVID-19.\n",
                "链接": "https://arxiv.org/abs/2212.02764"
            },
            {
                "文章ID": "104026",
                "标题": "OneSeg: Self-learning and One-shot Learning based Single-slice\n  Annotation for 3D Medical Image Segmentation",
                "作者": " Yixuan Wu,  Bo Zheng,  Jintai Chen,  Danny Z. Chen,  Jian Wu",
                "发布日期": "2023-09-26",
                "摘要": "  As deep learning methods continue to improve medical image segmentation\nperformance, data annotation is still a big bottleneck due to the\nlabor-intensive and time-consuming burden on medical experts, especially for 3D\nimages. To significantly reduce annotation efforts while attaining competitive\nsegmentation accuracy, we propose a self-learning and one-shot learning based\nframework for 3D medical image segmentation by annotating only one slice of\neach 3D image. Our approach takes two steps: (1) self-learning of a\nreconstruction network to learn semantic correspondence among 2D slices within\n3D images, and (2) representative selection of single slices for one-shot\nmanual annotation and propagating the annotated data with the well-trained\nreconstruction network. Extensive experiments verify that our new framework\nachieves comparable performance with less than 1% annotated data compared with\nfully supervised methods and generalizes well on several out-of-distribution\ntesting sets.\n",
                "链接": "https://arxiv.org/abs/2309.13671"
            },
            {
                "文章ID": "64758",
                "标题": "Exploring Self-Supervised Representation Learning For Low-Resource\n  Medical Image Analysis",
                "作者": " Soumitri Chattopadhyay,  Soham Ganguly,  Sreejit Chaudhury,  Sayan Nag,  Samiran Chattopadhyay",
                "发布日期": "2023-06-30",
                "摘要": "  The success of self-supervised learning (SSL) has mostly been attributed to\nthe availability of unlabeled yet large-scale datasets. However, in a\nspecialized domain such as medical imaging which is a lot different from\nnatural images, the assumption of data availability is unrealistic and\nimpractical, as the data itself is scanty and found in small databases,\ncollected for specific prognosis tasks. To this end, we seek to investigate the\napplicability of self-supervised learning algorithms on small-scale medical\nimaging datasets. In particular, we evaluate $4$ state-of-the-art SSL methods\non three publicly accessible \\emph{small} medical imaging datasets. Our\ninvestigation reveals that in-domain low-resource SSL pre-training can yield\ncompetitive performance to transfer learning from large-scale datasets (such as\nImageNet). Furthermore, we extensively analyse our empirical findings to\nprovide valuable insights that can motivate for further research towards\ncircumventing the need for pre-training on a large image corpus. To the best of\nour knowledge, this is the first attempt to holistically explore\nself-supervision on low-resource medical datasets.\n",
                "链接": "https://arxiv.org/abs/2303.02245"
            },
            {
                "文章ID": "80236",
                "标题": "Deep Learning-based Bio-Medical Image Segmentation using UNet\n  Architecture and Transfer Learning",
                "作者": " Nima Hassanpour,  Abouzar Ghavami",
                "发布日期": "2023-05-25",
                "摘要": "  Image segmentation is a branch of computer vision that is widely used in real\nworld applications including biomedical image processing. With recent\nadvancement of deep learning, image segmentation has achieved at a very high\nlevel performance. Recently, UNet architecture is found as the core of novel\ndeep learning segmentation methods. In this paper we implement UNet\narchitecture from scratch with using basic blocks in Pytorch and evaluate its\nperformance on multiple biomedical image datasets. We also use transfer\nlearning to apply novel modified UNet segmentation packages on the biomedical\nimage datasets. We fine tune the pre-trained transferred model with each\nspecific dataset. We compare its performance with our fundamental UNet\nimplementation. We show that transferred learning model has better performance\nin image segmentation than UNet model that is implemented from scratch.\n",
                "链接": "https://arxiv.org/abs/2305.14841"
            }
        ]
    },
    {
        "question": {
            "question": "请找出最近一年内发表的关于自然语言处理领域中，使用Transformer模型并在大规模数据集上进行预训练的论文。特别关注模型结构和性能指标。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "109322",
                "标题": "Enhanced Transformer Architecture for Natural Language Processing",
                "作者": " Woohyeon Moon,  Taeyoung Kim,  Bumgeun Park,  Dongsoo Har",
                "发布日期": "2023-10-18",
                "摘要": "  Transformer is a state-of-the-art model in the field of natural language\nprocessing (NLP). Current NLP models primarily increase the number of\ntransformers to improve processing performance. However, this technique\nrequires a lot of training resources such as computing capacity. In this paper,\na novel structure of Transformer is proposed. It is featured by full layer\nnormalization, weighted residual connection, positional encoding exploiting\nreinforcement learning, and zero masked self-attention. The proposed\nTransformer model, which is called Enhanced Transformer, is validated by the\nbilingual evaluation understudy (BLEU) score obtained with the Multi30k\ntranslation dataset. As a result, the Enhanced Transformer achieves 202.96%\nhigher BLEU score as compared to the original transformer with the translation\ndataset.\n",
                "链接": "https://arxiv.org/abs/2310.10930"
            },
            {
                "文章ID": "85409",
                "标题": "EriBERTa: A Bilingual Pre-Trained Language Model for Clinical Natural\n  Language Processing",
                "作者": " Iker de la Iglesia,  Aitziber Atutxa,  Koldo Gojenola,  Ander Barrena",
                "发布日期": "2023-06-14",
                "摘要": "  The utilization of clinical reports for various secondary purposes, including\nhealth research and treatment monitoring, is crucial for enhancing patient\ncare. Natural Language Processing (NLP) tools have emerged as valuable assets\nfor extracting and processing relevant information from these reports. However,\nthe availability of specialized language models for the clinical domain in\nSpanish has been limited.\n  In this paper, we introduce EriBERTa, a bilingual domain-specific language\nmodel pre-trained on extensive medical and clinical corpora. We demonstrate\nthat EriBERTa outperforms previous Spanish language models in the clinical\ndomain, showcasing its superior capabilities in understanding medical texts and\nextracting meaningful information. Moreover, EriBERTa exhibits promising\ntransfer learning abilities, allowing for knowledge transfer from one language\nto another. This aspect is particularly beneficial given the scarcity of\nSpanish clinical data.\n",
                "链接": "https://arxiv.org/abs/2306.07373"
            },
            {
                "文章ID": "85489",
                "标题": "Soft Language Clustering for Multilingual Model Pre-training",
                "作者": " Jiali Zeng,  Yufan Jiang,  Yongjing Yin,  Yi Jing,  Fandong Meng,  Binghuai Lin,  Yunbo Cao,  Jie Zhou",
                "发布日期": "2023-06-14",
                "摘要": "  Multilingual pre-trained language models have demonstrated impressive\n(zero-shot) cross-lingual transfer abilities, however, their performance is\nhindered when the target language has distant typology from source languages or\nwhen pre-training data is limited in size. In this paper, we propose XLM-P,\nwhich contextually retrieves prompts as flexible guidance for encoding\ninstances conditionally. Our XLM-P enables (1) lightweight modeling of\nlanguage-invariant and language-specific knowledge across languages, and (2)\neasy integration with other multilingual pre-training methods. On the tasks of\nXTREME including text classification, sequence labeling, question answering,\nand sentence retrieval, both base- and large-size language models pre-trained\nwith our proposed method exhibit consistent performance improvement.\nFurthermore, it provides substantial advantages for low-resource languages in\nunsupervised sentence retrieval and for target languages that differ greatly\nfrom the source language in cross-lingual transfer.\n",
                "链接": "https://arxiv.org/abs/2306.07610"
            },
            {
                "文章ID": "93014",
                "标题": "Evaluating Large Language Models for Radiology Natural Language\n  Processing",
                "作者": " Zhengliang Liu,  Tianyang Zhong,  Yiwei Li,  Yutong Zhang,  Yi Pan,  Zihao Zhao,  Peixin Dong,  Chao Cao,  Yuxiao Liu,  Peng Shu,  Yaonai Wei,  Zihao Wu,  Chong Ma,  Jiaqi Wang,  Sheng Wang,  Mengyue Zhou,  Zuowei Jiang,  Chunlin Li,  Jason Holmes,  Shaochen Xu,  Lu Zhang,  Haixing Dai,  Kai Zhang,  Lin Zhao,  Yuanhao Chen,  Xu Liu,  Peilong Wang,  Pingkun Yan,  Jun Liu,  Bao Ge,  Lichao Sun,  Dajiang Zhu,  Xiang Li,  Wei Liu,  Xiaoyan Cai,  Xintao Hu,  Xi Jiang,  Shu Zhang,  Xin Zhang,  Tuo Zhang,  Shijie Zhao,  Quanzheng Li,  Hongtu Zhu,  Dinggang Shen,  Tianming Liu",
                "发布日期": "2023-07-28",
                "摘要": "  The rise of large language models (LLMs) has marked a pivotal shift in the\nfield of natural language processing (NLP). LLMs have revolutionized a\nmultitude of domains, and they have made a significant impact in the medical\nfield. Large language models are now more abundant than ever, and many of these\nmodels exhibit bilingual capabilities, proficient in both English and Chinese.\nHowever, a comprehensive evaluation of these models remains to be conducted.\nThis lack of assessment is especially apparent within the context of radiology\nNLP. This study seeks to bridge this gap by critically evaluating thirty two\nLLMs in interpreting radiology reports, a crucial component of radiology NLP.\nSpecifically, the ability to derive impressions from radiologic findings is\nassessed. The outcomes of this evaluation provide key insights into the\nperformance, strengths, and weaknesses of these LLMs, informing their practical\napplications within the medical domain.\n",
                "链接": "https://arxiv.org/abs/2307.13693"
            },
            {
                "文章ID": "95268",
                "标题": "Continual Pre-Training of Large Language Models: How to (re)warm your\n  model?",
                "作者": " Kshitij Gupta,  Benjamin Thérien,  Adam Ibrahim,  Mats L. Richter,  Quentin Anthony,  Eugene Belilovsky,  Irina Rish,  Timothée Lesort",
                "发布日期": "2023-09-08",
                "摘要": "  Large language models (LLMs) are routinely pre-trained on billions of tokens,\nonly to restart the process over again once new data becomes available. A much\ncheaper and more efficient solution would be to enable the continual\npre-training of these models, i.e. updating pre-trained models with new data\ninstead of re-training them from scratch. However, the distribution shift\ninduced by novel data typically results in degraded performance on past data.\nTaking a step towards efficient continual pre-training, in this work, we\nexamine the effect of different warm-up strategies. Our hypothesis is that the\nlearning rate must be re-increased to improve compute efficiency when training\non a new dataset. We study the warmup phase of models pre-trained on the Pile\n(upstream data, 300B tokens) as we continue to pre-train on SlimPajama\n(downstream data, 297B tokens), following a linear warmup and cosine decay\nschedule. We conduct all experiments on the Pythia 410M language model\narchitecture and evaluate performance through validation perplexity. We\nexperiment with different pre-training checkpoints, various maximum learning\nrates, and various warmup lengths. Our results show that while rewarming models\nfirst increases the loss on upstream and downstream data, in the longer run it\nimproves the downstream performance, outperforming models trained from\nscratch$\\unicode{x2013}$even for a large downstream dataset.\n",
                "链接": "https://arxiv.org/abs/2308.04014"
            },
            {
                "文章ID": "96698",
                "标题": "Pre-training with Large Language Model-based Document Expansion for\n  Dense Passage Retrieval",
                "作者": " Guangyuan Ma,  Xing Wu,  Peng Wang,  Zijia Lin,  Songlin Hu",
                "发布日期": "2023-08-17",
                "摘要": "  In this paper, we systematically study the potential of pre-training with\nLarge Language Model(LLM)-based document expansion for dense passage retrieval.\nConcretely, we leverage the capabilities of LLMs for document expansion, i.e.\nquery generation, and effectively transfer expanded knowledge to retrievers\nusing pre-training strategies tailored for passage retrieval. These strategies\ninclude contrastive learning and bottlenecked query generation. Furthermore, we\nincorporate a curriculum learning strategy to reduce the reliance on LLM\ninferences. Experimental results demonstrate that pre-training with LLM-based\ndocument expansion significantly boosts the retrieval performance on\nlarge-scale web-search tasks. Our work shows strong zero-shot and out-of-domain\nretrieval abilities, making it more widely applicable for retrieval when\ninitializing with no human-labeled data.\n",
                "链接": "https://arxiv.org/abs/2308.08285"
            },
            {
                "文章ID": "111100",
                "标题": "MindLLM: Pre-training Lightweight Large Language Model from Scratch,\n  Evaluations and Domain Applications",
                "作者": " Yizhe Yang,  Huashan Sun,  Jiawei Li,  Runheng Liu,  Yinghao Li,  Yuhang Liu,  Heyan Huang,  Yang Gao",
                "发布日期": "2023-10-31",
                "摘要": "  Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious natural language tasks, marking significant strides towards general\nartificial intelligence. While general artificial intelligence is leveraged by\ndeveloping increasingly large-scale models, there could be another branch to\ndevelop lightweight custom models that better serve certain domains, taking\ninto account the high cost of training and deploying LLMs and the scarcity of\nresources. In this paper, we present MindLLM, a novel series of bilingual\nlightweight large language models, trained from scratch, alleviating such\nburdens by offering models with 1.3 billion and 3 billion parameters. A\nthorough account of experiences accrued during large model development is\ngiven, covering every step of the process, including data construction, model\narchitecture, evaluation, and applications. Such insights are hopefully\nvaluable for fellow academics and developers. MindLLM consistently matches or\nsurpasses the performance of other open-source larger models on some public\nbenchmarks. We also introduce an innovative instruction tuning framework\ntailored for smaller models to enhance their capabilities efficiently.\nMoreover, we explore the application of MindLLM in specific vertical domains\nsuch as law and finance, underscoring the agility and adaptability of our\nlightweight models.\n",
                "链接": "https://arxiv.org/abs/2310.15777"
            },
            {
                "文章ID": "102542",
                "标题": "Performance of the Pre-Trained Large Language Model GPT-4 on Automated\n  Short Answer Grading",
                "作者": " Gerd Kortemeyer",
                "发布日期": "2023-09-19",
                "摘要": "  Automated Short Answer Grading (ASAG) has been an active area of\nmachine-learning research for over a decade. It promises to let educators grade\nand give feedback on free-form responses in large-enrollment courses in spite\nof limited availability of human graders. Over the years, carefully trained\nmodels have achieved increasingly higher levels of performance. More recently,\npre-trained Large Language Models (LLMs) emerged as a commodity, and an\nintriguing question is how a general-purpose tool without additional training\ncompares to specialized models. We studied the performance of GPT-4 on the\nstandard benchmark 2-way and 3-way datasets SciEntsBank and Beetle, where in\naddition to the standard task of grading the alignment of the student answer\nwith a reference answer, we also investigated withholding the reference answer.\nWe found that overall, the performance of the pre-trained general-purpose GPT-4\nLLM is comparable to hand-engineered models, but worse than pre-trained LLMs\nthat had specialized training.\n",
                "链接": "https://arxiv.org/abs/2309.09338"
            },
            {
                "文章ID": "88831",
                "标题": "Dataset balancing can hurt model performance",
                "作者": " R. Channing Moore,  Daniel P. W. Ellis,  Eduardo Fonseca,  Shawn Hershey,  Aren Jansen,  Manoj Plakal",
                "发布日期": "2023-07-04",
                "摘要": "  Machine learning from training data with a skewed distribution of examples\nper class can lead to models that favor performance on common classes at the\nexpense of performance on rare ones. AudioSet has a very wide range of priors\nover its 527 sound event classes. Classification performance on AudioSet is\nusually evaluated by a simple average over per-class metrics, meaning that\nperformance on rare classes is equal in importance to the performance on common\nones. Several recent papers have used dataset balancing techniques to improve\nperformance on AudioSet. We find, however, that while balancing improves\nperformance on the public AudioSet evaluation data it simultaneously hurts\nperformance on an unpublished evaluation set collected under the same\nconditions. By varying the degree of balancing, we show that its benefits are\nfragile and depend on the evaluation set. We also do not find evidence\nindicating that balancing improves rare class performance relative to common\nclasses. We therefore caution against blind application of balancing, as well\nas against paying too much attention to small improvements on a public\nevaluation set.\n",
                "链接": "https://arxiv.org/abs/2307.00079"
            },
            {
                "文章ID": "99535",
                "标题": "Enhancing Subtask Performance of Multi-modal Large Language Model",
                "作者": " Yongqiang Zhao,  Zhenyu Li,  Feng Zhang,  Xinhai Xu,  Donghong Liu",
                "发布日期": "2023-09-01",
                "摘要": "  Multi-modal Large Language Model (MLLM) refers to a model expanded from a\nLarge Language Model (LLM) that possesses the capability to handle and infer\nmulti-modal data. Current MLLMs typically begin by using LLMs to decompose\ntasks into multiple subtasks, then employing individual pre-trained models to\ncomplete specific subtasks, and ultimately utilizing LLMs to integrate the\nresults of each subtasks to obtain the results of the task. In real-world\nscenarios, when dealing with large projects, it is common practice to break\ndown the project into smaller sub-projects, with different teams providing\ncorresponding solutions or results. The project owner then decides which\nsolution or result to use, ensuring the best possible outcome for each subtask\nand, consequently, for the entire project. Inspired by this, this study\nconsiders selecting multiple pre-trained models to complete the same subtask.\nBy combining the results from multiple pre-trained models, the optimal subtask\nresult is obtained, enhancing the performance of the MLLM. Specifically, this\nstudy first selects multiple pre-trained models focused on the same subtask\nbased on distinct evaluation approaches, and then invokes these models in\nparallel to process input data and generate corresponding subtask results.\nFinally, the results from multiple pre-trained models for the same subtask are\ncompared using the LLM, and the best result is chosen as the outcome for that\nsubtask. Extensive experiments are conducted in this study using GPT-4\nannotated datasets and human-annotated datasets. The results of various\nevaluation metrics adequately demonstrate the effectiveness of the proposed\napproach in this paper.\n",
                "链接": "https://arxiv.org/abs/2308.16474"
            }
        ]
    },
    {
        "question": {
            "question": "请查找关于智能体的研究进展的综述或调查论文。重点关注不同领域中智能体的方法和应用，以及相关的挑战和未来方向。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "48833",
                "标题": "A Review of Intelligent Music Generation Systems",
                "作者": " Lei Wang,  Ziyi Zhao,  Hanwei Liu,  Junwei Pang,  Yi Qin,  Qidi Wu",
                "发布日期": "2023-11-21",
                "摘要": "  With the introduction of ChatGPT, the public's perception of AI-generated\ncontent (AIGC) has begun to reshape. Artificial intelligence has significantly\nreduced the barrier to entry for non-professionals in creative endeavors,\nenhancing the efficiency of content creation. Recent advancements have seen\nsignificant improvements in the quality of symbolic music generation, which is\nenabled by the use of modern generative algorithms to extract patterns implicit\nin a piece of music based on rule constraints or a musical corpus.\nNevertheless, existing literature reviews tend to present a conventional and\nconservative perspective on future development trajectories, with a notable\nabsence of thorough benchmarking of generative models. This paper provides a\nsurvey and analysis of recent intelligent music generation techniques,\noutlining their respective characteristics and discussing existing methods for\nevaluation. Additionally, the paper compares the different characteristics of\nmusic generation techniques in the East and West as well as analysing the\nfield's development prospects.\n",
                "链接": "https://arxiv.org/abs/2211.09124"
            },
            {
                "文章ID": "108515",
                "标题": "Intelligent Scoliosis Screening and Diagnosis: A Survey",
                "作者": " Zhang Zhenlin,  Pu Lixin,  Li Ang,  Zhang Jun,  Li Xianjie,  Fan Jipeng",
                "发布日期": "2023-10-16",
                "摘要": "  Scoliosis is a three-dimensional spinal deformity, which may lead to abnormal\nmorphologies, such as thoracic deformity, and pelvic tilt. Severe patients may\nsuffer from nerve damage and urinary abnormalities. At present, the number of\nscoliosis patients in primary and secondary schools has exceeded five million\nin China, the incidence rate is about 3% to 5% which is growing every year. The\nresearch on scoliosis, therefore, has important clinical value. This paper\nsystematically introduces computer-assisted scoliosis screening and diagnosis\nas well as analyzes the advantages and limitations of different algorithm\nmodels in the current issue field. Moreover, the paper also discusses the\ncurrent development bottlenecks in this field and looks forward to future\ndevelopment trends.\n",
                "链接": "https://arxiv.org/abs/2310.08756"
            },
            {
                "文章ID": "78203",
                "标题": "Intelligent multicast routing method based on multi-agent deep\n  reinforcement learning in SDWN",
                "作者": " Hongwen Hu,  Miao Ye,  Chenwei Zhao,  Qiuxiang Jiang,  Yong Wang,  Hongbing Qiu,  Xiaofang Deng",
                "发布日期": "2023-05-19",
                "摘要": "  Multicast communication technology is widely applied in wireless environments\nwith a high device density. Traditional wireless network architectures have\ndifficulty flexibly obtaining and maintaining global network state information\nand cannot quickly respond to network state changes, thus affecting the\nthroughput, delay, and other QoS requirements of existing multicasting\nsolutions. Therefore, this paper proposes a new multicast routing method based\non multiagent deep reinforcement learning (MADRL-MR) in a software-defined\nwireless networking (SDWN) environment. First, SDWN technology is adopted to\nflexibly configure the network and obtain network state information in the form\nof traffic matrices representing global network links information, such as link\nbandwidth, delay, and packet loss rate. Second, the multicast routing problem\nis divided into multiple subproblems, which are solved through multiagent\ncooperation. To enable each agent to accurately understand the current network\nstate and the status of multicast tree construction, the state space of each\nagent is designed based on the traffic and multicast tree status matrices, and\nthe set of AP nodes in the network is used as the action space. A novel\nsingle-hop action strategy is designed, along with a reward function based on\nthe four states that may occur during tree construction: progress, invalid,\nloop, and termination. Finally, a decentralized training approach is combined\nwith transfer learning to enable each agent to quickly adapt to dynamic network\nchanges and accelerate convergence. Simulation experiments show that MADRL-MR\noutperforms existing algorithms in terms of throughput, delay, packet loss\nrate, etc., and can establish more intelligent multicast routes.\n",
                "链接": "https://arxiv.org/abs/2305.10440"
            },
            {
                "文章ID": "20410",
                "标题": "Multi-Agent Feedback Enabled Neural Networks for Intelligent\n  Communications",
                "作者": " Fanglei Sun,  Yang Li,  Ying Wen,  Jingchen Hu,  Jun Wang,  Yang Yang,  Kai Li",
                "发布日期": "2022-05-25",
                "摘要": "  In the intelligent communication field, deep learning (DL) has attracted much\nattention due to its strong fitting ability and data-driven learning\ncapability. Compared with the typical DL feedforward network structures, an\nenhancement structure with direct data feedback have been studied and proved to\nhave better performance than the feedfoward networks. However, due to the above\nsimple feedback methods lack sufficient analysis and learning ability on the\nfeedback data, it is inadequate to deal with more complicated nonlinear systems\nand therefore the performance is limited for further improvement. In this\npaper, a novel multi-agent feedback enabled neural network (MAFENN) framework\nis proposed, which make the framework have stronger feedback learning\ncapabilities and more intelligence on feature abstraction, denoising or\ngeneration, etc. Furthermore, the MAFENN framework is theoretically formulated\ninto a three-player Feedback Stackelberg game, and the game is proved to\nconverge to the Feedback Stackelberg equilibrium. The design of MAFENN\nframework and algorithm are dedicated to enhance the learning capability of the\nfeedfoward DL networks or their variations with the simple data feedback. To\nverify the MAFENN framework's feasibility in wireless communications, a\nmulti-agent MAFENN based equalizer (MAFENN-E) is developed for wireless fading\nchannels with inter-symbol interference (ISI). Experimental results show that\nwhen the quadrature phase-shift keying (QPSK) modulation scheme is adopted, the\nSER performance of our proposed method outperforms that of the traditional\nequalizers by about 2 dB in linear channels. When in nonlinear channels, the\nSER performance of our proposed method outperforms that of either traditional\nor DL based equalizers more significantly, which shows the effectiveness and\nrobustness of our proposal in the complex channel environment.\n",
                "链接": "https://arxiv.org/abs/2205.10750"
            },
            {
                "文章ID": "46784",
                "标题": "Scalable Multi-Agent Reinforcement Learning through Intelligent\n  Information Aggregation",
                "作者": " Siddharth Nayak,  Kenneth Choi,  Wenqi Ding,  Sydney Dolan,  Karthik Gopalakrishnan,  Hamsa Balakrishnan",
                "发布日期": "2023-05-17",
                "摘要": "  We consider the problem of multi-agent navigation and collision avoidance\nwhen observations are limited to the local neighborhood of each agent. We\npropose InforMARL, a novel architecture for multi-agent reinforcement learning\n(MARL) which uses local information intelligently to compute paths for all the\nagents in a decentralized manner. Specifically, InforMARL aggregates\ninformation about the local neighborhood of agents for both the actor and the\ncritic using a graph neural network and can be used in conjunction with any\nstandard MARL algorithm. We show that (1) in training, InforMARL has better\nsample efficiency and performance than baseline approaches, despite using less\ninformation, and (2) in testing, it scales well to environments with arbitrary\nnumbers of agents and obstacles. We illustrate these results using four task\nenvironments, including one with predetermined goals for each agent, and one in\nwhich the agents collectively try to cover all goals. Code available at\nhttps://github.com/nsidn98/InforMARL.\n",
                "链接": "https://arxiv.org/abs/2211.02127"
            },
            {
                "文章ID": "7396",
                "标题": "Machine Learning Empowered Intelligent Data Center Networking: A Survey",
                "作者": " Bo Li,  Ting Wang,  Peng Yang,  Mingsong Chen,  Shui Yu,  Mounir Hamdi",
                "发布日期": "2022-03-02",
                "摘要": "  To support the needs of ever-growing cloud-based services, the number of\nservers and network devices in data centers is increasing exponentially, which\nin turn results in high complexities and difficulties in network optimization.\nTo address these challenges, both academia and industry turn to artificial\nintelligence technology to realize network intelligence. To this end, a\nconsiderable number of novel and creative machine learning-based (ML-based)\nresearch works have been put forward in recent few years. Nevertheless, there\nare still enormous challenges faced by the intelligent optimization of data\ncenter networks (DCNs), especially in the scenario of online real-time dynamic\nprocessing of massive heterogeneous services and traffic data. To best of our\nknowledge, there is a lack of systematic and original comprehensively\ninvestigations with in-depth analysis on intelligent DCN. To this end, in this\npaper, we comprehensively investigate the application of machine learning to\ndata center networking, and provide a general overview and in-depth analysis of\nthe recent works, covering flow prediction, flow classification, load\nbalancing, resource management, routing optimization, and congestion control.\nIn order to provide a multi-dimensional and multi-perspective comparison of\nvarious solutions, we design a quality assessment criteria called REBEL-3S to\nimpartially measure the strengths and weaknesses of these research works.\nMoreover, we also present unique insights into the technology evolution of the\nfusion of data center network and machine learning, together with some\nchallenges and potential future research opportunities.\n",
                "链接": "https://arxiv.org/abs/2202.13549"
            },
            {
                "文章ID": "88004",
                "标题": "Deep Transfer Learning for Intelligent Vehicle Perception: a Survey",
                "作者": " Xinyu Liu,  Jinlong Li,  Jin Ma,  Huiming Sun,  Zhigang Xu,  Tianyun Zhang,  Hongkai Yu",
                "发布日期": "2023-10-03",
                "摘要": "  Deep learning-based intelligent vehicle perception has been developing\nprominently in recent years to provide a reliable source for motion planning\nand decision making in autonomous driving. A large number of powerful deep\nlearning-based methods can achieve excellent performance in solving various\nperception problems of autonomous driving. However, these deep learning methods\nstill have several limitations, for example, the assumption that lab-training\n(source domain) and real-testing (target domain) data follow the same feature\ndistribution may not be practical in the real world. There is often a dramatic\ndomain gap between them in many real-world cases. As a solution to this\nchallenge, deep transfer learning can handle situations excellently by\ntransferring the knowledge from one domain to another. Deep transfer learning\naims to improve task performance in a new domain by leveraging the knowledge of\nsimilar tasks learned in another domain before. Nevertheless, there are\ncurrently no survey papers on the topic of deep transfer learning for\nintelligent vehicle perception. To the best of our knowledge, this paper\nrepresents the first comprehensive survey on the topic of the deep transfer\nlearning for intelligent vehicle perception. This paper discusses the domain\ngaps related to the differences of sensor, data, and model for the intelligent\nvehicle perception. The recent applications, challenges, future researches in\nintelligent vehicle perception are also explored.\n",
                "链接": "https://arxiv.org/abs/2306.15110"
            },
            {
                "文章ID": "122318",
                "标题": "A Survey of Generative AI for Intelligent Transportation Systems",
                "作者": " Huan Yan,  Yong Li",
                "发布日期": "2023-12-14",
                "摘要": "  Intelligent transportation systems play a crucial role in modern traffic\nmanagement and optimization, greatly improving traffic efficiency and safety.\nWith the rapid development of generative artificial intelligence (Generative\nAI) technologies in the fields of image generation and natural language\nprocessing, generative AI has also played a crucial role in addressing key\nissues in intelligent transportation systems, such as data sparsity, difficulty\nin observing abnormal scenarios, and in modeling data uncertainty. In this\nreview, we systematically investigate the relevant literature on generative AI\ntechniques in addressing key issues in different types of tasks in intelligent\ntransportation systems. First, we introduce the principles of different\ngenerative AI techniques, and their potential applications. Then, we classify\ntasks in intelligent transportation systems into four types: traffic\nperception, traffic prediction, traffic simulation, and traffic\ndecision-making. We systematically illustrate how generative AI techniques\naddresses key issues in these four different types of tasks. Finally, we\nsummarize the challenges faced in applying generative AI to intelligent\ntransportation systems, and discuss future research directions based on\ndifferent application scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08248"
            },
            {
                "文章ID": "40525",
                "标题": "Multi-Agent Chance-Constrained Stochastic Shortest Path with Application\n  to Risk-Aware Intelligent Intersection",
                "作者": " Majid Khonji,  Rashid Alyassi,  Wolfgang Merkt,  Areg Karapetyan,  Xin Huang,  Sungkweon Hong,  Jorge Dias,  Brian Williams",
                "发布日期": "2022-10-05",
                "摘要": "  In transportation networks, where traffic lights have traditionally been used\nfor vehicle coordination, intersections act as natural bottlenecks. A\nformidable challenge for existing automated intersections lies in detecting and\nreasoning about uncertainty from the operating environment and human-driven\nvehicles. In this paper, we propose a risk-aware intelligent intersection\nsystem for autonomous vehicles (AVs) as well as human-driven vehicles (HVs). We\ncast the problem as a novel class of Multi-agent Chance-Constrained Stochastic\nShortest Path (MCC-SSP) problems and devise an exact Integer Linear Programming\n(ILP) formulation that is scalable in the number of agents' interaction points\n(e.g., potential collision points at the intersection). In particular, when the\nnumber of agents within an interaction point is small, which is often the case\nin intersections, the ILP has a polynomial number of variables and constraints.\nTo further improve the running time performance, we show that the collision\nrisk computation can be performed offline. Additionally, a trajectory\noptimization workflow is provided to generate risk-aware trajectories for any\ngiven intersection. The proposed framework is implemented in CARLA simulator\nand evaluated under a fully autonomous intersection with AVs only as well as in\na hybrid setup with a signalized intersection for HVs and an intelligent scheme\nfor AVs. As verified via simulations, the featured approach improves\nintersection's efficiency by up to $200\\%$ while also conforming to the\nspecified tunable risk threshold.\n",
                "链接": "https://arxiv.org/abs/2210.01766"
            },
            {
                "文章ID": "34903",
                "标题": "A survey, review, and future trends of skin lesion segmentation and\n  classification",
                "作者": " Md. Kamrul Hasan,  Md. Asif Ahamad,  Choon Hwai Yap,  Guang Yang",
                "发布日期": "2023-02-03",
                "摘要": "  The Computer-aided Diagnosis or Detection (CAD) approach for skin lesion\nanalysis is an emerging field of research that has the potential to alleviate\nthe burden and cost of skin cancer screening. Researchers have recently\nindicated increasing interest in developing such CAD systems, with the\nintention of providing a user-friendly tool to dermatologists to reduce the\nchallenges encountered or associated with manual inspection. This article aims\nto provide a comprehensive literature survey and review of a total of 594\npublications (356 for skin lesion segmentation and 238 for skin lesion\nclassification) published between 2011 and 2022. These articles are analyzed\nand summarized in a number of different ways to contribute vital information\nregarding the methods for the development of CAD systems. These ways include\nrelevant and essential definitions and theories, input data (dataset\nutilization, preprocessing, augmentations, and fixing imbalance problems),\nmethod configuration (techniques, architectures, module frameworks, and\nlosses), training tactics (hyperparameter settings), and evaluation criteria.\nWe intend to investigate a variety of performance-enhancing approaches,\nincluding ensemble and post-processing. We also discuss these dimensions to\nreveal their current trends based on utilization frequencies. In addition, we\nhighlight the primary difficulties associated with evaluating skin lesion\nsegmentation and classification systems using minimal datasets, as well as the\npotential solutions to these difficulties. Findings, recommendations, and\ntrends are disclosed to inform future research on developing an automated and\nrobust CAD system for skin lesion analysis.\n",
                "链接": "https://arxiv.org/abs/2208.12232"
            }
        ]
    }
]