[
    {
        "question": {
            "question": "和大模型可解释相关的最新论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "91774",
                "标题": "What's meant by explainable model: A Scoping Review",
                "作者": " Mallika Mainali,  Rosina O Weber",
                "发布日期": "2023-08-30",
                "摘要": "  We often see the term explainable in the titles of papers that describe\napplications based on artificial intelligence (AI). However, the literature in\nexplainable artificial intelligence (XAI) indicates that explanations in XAI\nare application- and domain-specific, hence requiring evaluation whenever they\nare employed to explain a model that makes decisions for a specific application\nproblem. Additionally, the literature reveals that the performance of post-hoc\nmethods, particularly feature attribution methods, varies substantially hinting\nthat they do not represent a solution to AI explainability. Therefore, when\nusing XAI methods, the quality and suitability of their information outputs\nshould be evaluated within the specific application. For these reasons, we used\na scoping review methodology to investigate papers that apply AI models and\nadopt methods to generate post-hoc explanations while referring to said models\nas explainable. This paper investigates whether the term explainable model is\nadopted by authors under the assumption that incorporating a post-hoc XAI\nmethod suffices to characterize a model as explainable. To inspect this\nproblem, our review analyzes whether these papers conducted evaluations. We\nfound that 81% of the application papers that refer to their approaches as an\nexplainable model do not conduct any form of evaluation on the XAI method they\nused.\n",
                "链接": "https://arxiv.org/abs/2307.09673"
            },
            {
                "文章ID": "77833",
                "标题": "Unjustified Sample Sizes and Generalizations in Explainable AI Research:\n  Principles for More Inclusive User Studies",
                "作者": " Uwe Peters,  Mary Carman",
                "发布日期": "2023-10-17",
                "摘要": "  Many ethical frameworks require artificial intelligence (AI) systems to be\nexplainable. Explainable AI (XAI) models are frequently tested for their\nadequacy in user studies. Since different people may have different explanatory\nneeds, it is important that participant samples in user studies are large\nenough to represent the target population to enable generalizations. However,\nit is unclear to what extent XAI researchers reflect on and justify their\nsample sizes or avoid broad generalizations across people. We analyzed XAI user\nstudies (n = 220) published between 2012 and 2022. Most studies did not offer\nrationales for their sample sizes. Moreover, most papers generalized their\nconclusions beyond their target population, and there was no evidence that\nbroader conclusions in quantitative studies were correlated with larger\nsamples. These methodological problems can impede evaluations of whether XAI\nsystems implement the explainability called for in ethical frameworks. We\noutline principles for more inclusive XAI user studies.\n",
                "链接": "https://arxiv.org/abs/2305.09477"
            },
            {
                "文章ID": "95587",
                "标题": "NLLG Quarterly arXiv Report 06/23: What are the most influential current\n  AI Papers?",
                "作者": " Steffen Eger,  Christoph Leiter,  Jonas Belouadi,  Ran Zhang,  Aida Kostikova,  Daniil Larionov,  Yanran Chen,  Vivian Fresen",
                "发布日期": "2023-08-15",
                "摘要": "  The rapid growth of information in the field of Generative Artificial\nIntelligence (AI), particularly in the subfields of Natural Language Processing\n(NLP) and Machine Learning (ML), presents a significant challenge for\nresearchers and practitioners to keep pace with the latest developments. To\naddress the problem of information overload, this report by the Natural\nLanguage Learning Group at Bielefeld University focuses on identifying the most\npopular papers on arXiv, with a specific emphasis on NLP and ML. The objective\nis to offer a quick guide to the most relevant and widely discussed research,\naiding both newcomers and established researchers in staying abreast of current\ntrends. In particular, we compile a list of the 40 most popular papers based on\nnormalized citation counts from the first half of 2023. We observe the\ndominance of papers related to Large Language Models (LLMs) and specifically\nChatGPT during the first half of 2023, with the latter showing signs of\ndeclining popularity more recently, however. Further, NLP related papers are\nthe most influential (around 60\\% of top papers) even though there are twice as\nmany ML related papers in our data. Core issues investigated in the most\nheavily cited papers are: LLM efficiency, evaluation techniques, ethical\nconsiderations, embodied agents, and problem-solving with LLMs. Additionally,\nwe examine the characteristics of top papers in comparison to others outside\nthe top-40 list (noticing the top paper's focus on LLM related issues and\nhigher number of co-authors) and analyze the citation distributions in our\ndataset, among others.\n",
                "链接": "https://arxiv.org/abs/2308.04889"
            },
            {
                "文章ID": "53807",
                "标题": "Online Handbook of Argumentation for AI: Volume 3",
                "作者": " Lars Bengel,  Elfia Bezou-Vrakatseli,  Lydia Blümel,  Federico Castagna,  Giulia D'Agostino,  Daphne Odekerken,  Minal Suresh Patil,  Jordan Robinson,  Hao Wu,  Andreas Xydis",
                "发布日期": "2022-12-16",
                "摘要": "  This volume contains revised versions of the papers selected for the third\nvolume of the Online Handbook of Argumentation for AI (OHAAI). Previously,\nformal theories of argument and argument interaction have been proposed and\nstudied, and this has led to the more recent study of computational models of\nargument. Argumentation, as a field within artificial intelligence (AI), is\nhighly relevant for researchers interested in symbolic representations of\nknowledge and defeasible reasoning. The purpose of this handbook is to provide\nan open access and curated anthology for the argumentation research community.\nOHAAI is designed to serve as a research hub to keep track of the latest and\nupcoming PhD-driven research on the theory and application of argumentation in\nall areas related to AI.\n",
                "链接": "https://arxiv.org/abs/2212.07996"
            },
            {
                "文章ID": "44048",
                "标题": "Towards Human-centered Explainable AI: A Survey of User Studies for\n  Model Explanations",
                "作者": " Yao Rong,  Tobias Leemann,  Thai-trang Nguyen,  Lisa Fiedler,  Peizhu Qian,  Vaibhav Unhelkar,  Tina Seidel,  Gjergji Kasneci,  Enkelejda Kasneci",
                "发布日期": "2023-12-20",
                "摘要": "  Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI\nresearch. A better understanding of the needs of XAI users, as well as\nhuman-centered evaluations of explainable models are both a necessity and a\nchallenge. In this paper, we explore how HCI and AI researchers conduct user\nstudies in XAI applications based on a systematic literature review. After\nidentifying and thoroughly analyzing 97core papers with human-based XAI\nevaluations over the past five years, we categorize them along the measured\ncharacteristics of explanatory methods, namely trust, understanding, usability,\nand human-AI collaboration performance. Our research shows that XAI is\nspreading more rapidly in certain application domains, such as recommender\nsystems than in others, but that user evaluations are still rather sparse and\nincorporate hardly any insights from cognitive or social sciences. Based on a\ncomprehensive discussion of best practices, i.e., common models, design\nchoices, and measures in user studies, we propose practical guidelines on\ndesigning and conducting user studies for XAI researchers and practitioners.\nLastly, this survey also highlights several open research directions,\nparticularly linking psychological science and human-centered XAI.\n",
                "链接": "https://arxiv.org/abs/2210.11584"
            },
            {
                "文章ID": "105505",
                "标题": "A Survey of Robustness and Safety of 2D and 3D Deep Learning Models\n  Against Adversarial Attacks",
                "作者": " Yanjie Li,  Bin Xie,  Songtao Guo,  Yuanyuan Yang,  Bin Xiao",
                "发布日期": "2023-10-03",
                "摘要": "  Benefiting from the rapid development of deep learning, 2D and 3D computer\nvision applications are deployed in many safe-critical systems, such as\nautopilot and identity authentication. However, deep learning models are not\ntrustworthy enough because of their limited robustness against adversarial\nattacks. The physically realizable adversarial attacks further pose fatal\nthreats to the application and human safety. Lots of papers have emerged to\ninvestigate the robustness and safety of deep learning models against\nadversarial attacks. To lead to trustworthy AI, we first construct a general\nthreat model from different perspectives and then comprehensively review the\nlatest progress of both 2D and 3D adversarial attacks. We extend the concept of\nadversarial examples beyond imperceptive perturbations and collate over 170\npapers to give an overview of deep learning model robustness against various\nadversarial attacks. To the best of our knowledge, we are the first to\nsystematically investigate adversarial attacks for 3D models, a flourishing\nfield applied to many real-world applications. In addition, we examine physical\nadversarial attacks that lead to safety violations. Last but not least, we\nsummarize present popular topics, give insights on challenges, and shed light\non future research on trustworthy AI.\n",
                "链接": "https://arxiv.org/abs/2310.00633"
            },
            {
                "文章ID": "39463",
                "标题": "Automatic Analysis of Available Source Code of Top Artificial\n  Intelligence Conference Papers",
                "作者": " Jialiang Lin,  Yingmin Wang,  Yao Yu,  Yu Zhou,  Yidong Chen,  Xiaodong Shi",
                "发布日期": "2022-09-29",
                "摘要": "  Source code is essential for researchers to reproduce the methods and\nreplicate the results of artificial intelligence (AI) papers. Some\norganizations and researchers manually collect AI papers with available source\ncode to contribute to the AI community. However, manual collection is a\nlabor-intensive and time-consuming task. To address this issue, we propose a\nmethod to automatically identify papers with available source code and extract\ntheir source code repository URLs. With this method, we find that 20.5% of\nregular papers of 10 top AI conferences published from 2010 to 2019 are\nidentified as papers with available source code and that 8.1% of these source\ncode repositories are no longer accessible. We also create the XMU NLP Lab\nREADME Dataset, the largest dataset of labeled README files for source code\ndocument research. Through this dataset, we have discovered that quite a few\nREADME files have no installation instructions or usage tutorials provided.\nFurther, a large-scale comprehensive statistical analysis is made for a general\npicture of the source code of AI conference papers. The proposed solution can\nalso go beyond AI conference papers to analyze other scientific papers from\nboth journals and conferences to shed light on more domains.\n",
                "链接": "https://arxiv.org/abs/2209.14155"
            },
            {
                "文章ID": "112858",
                "标题": "Linked Papers With Code: The Latest in Machine Learning as an RDF\n  Knowledge Graph",
                "作者": " Michael Färber,  David Lamprecht",
                "发布日期": "2023-11-01",
                "摘要": "  In this paper, we introduce Linked Papers With Code (LPWC), an RDF knowledge\ngraph that provides comprehensive, current information about almost 400,000\nmachine learning publications. This includes the tasks addressed, the datasets\nutilized, the methods implemented, and the evaluations conducted, along with\ntheir results. Compared to its non-RDF-based counterpart Papers With Code, LPWC\nnot only translates the latest advancements in machine learning into RDF\nformat, but also enables novel ways for scientific impact quantification and\nscholarly key content recommendation. LPWC is openly accessible at\nhttps://linkedpaperswithcode.com and is licensed under CC-BY-SA 4.0. As a\nknowledge graph in the Linked Open Data cloud, we offer LPWC in multiple\nformats, from RDF dump files to a SPARQL endpoint for direct web queries, as\nwell as a data source with resolvable URIs and links to the data sources\nSemOpenAlex, Wikidata, and DBLP. Additionally, we supply knowledge graph\nembeddings, enabling LPWC to be readily applied in machine learning\napplications.\n",
                "链接": "https://arxiv.org/abs/2310.20475"
            },
            {
                "文章ID": "82371",
                "标题": "Explainable AI for Malnutrition Risk Prediction from m-Health and\n  Clinical Data",
                "作者": " Flavio Di Martino,  Franca Delmastro,  Cristina Dolciotti",
                "发布日期": "2023-06-01",
                "摘要": "  Malnutrition is a serious and prevalent health problem in the older\npopulation, and especially in hospitalised or institutionalised subjects.\nAccurate and early risk detection is essential for malnutrition management and\nprevention. M-health services empowered with Artificial Intelligence (AI) may\nlead to important improvements in terms of a more automatic, objective, and\ncontinuous monitoring and assessment. Moreover, the latest Explainable AI (XAI)\nmethodologies may make AI decisions interpretable and trustworthy for end\nusers. This paper presents a novel AI framework for early and explainable\nmalnutrition risk detection based on heterogeneous m-health data. We performed\nan extensive model evaluation including both subject-independent and\npersonalised predictions, and the obtained results indicate Random Forest (RF)\nand Gradient Boosting as the best performing classifiers, especially when\nincorporating body composition assessment data. We also investigated several\nbenchmark XAI methods to extract global model explanations. Model-specific\nexplanation consistency assessment indicates that each selected model\nprivileges similar subsets of the most relevant predictors, with the highest\nagreement shown between SHapley Additive ExPlanations (SHAP) and feature\npermutation method. Furthermore, we performed a preliminary clinical validation\nto verify that the learned feature-output trends are compliant with the current\nevidence-based assessment.\n",
                "链接": "https://arxiv.org/abs/2305.19636"
            },
            {
                "文章ID": "93461",
                "标题": "A Method for Generating Dynamic Responsible AI Guidelines for\n  Collaborative Action",
                "作者": " Marios Constantinides,  Edyta Bogucka,  Daniele Quercia,  Susanna Kallio,  Mohammad Tahaei",
                "发布日期": "2023-07-31",
                "摘要": "  To improve the development of responsible AI systems, developers are\nincreasingly utilizing tools such as checklists or guideline cards to ensure\nfairness, transparency, and sustainability. However, these tools face two main\nchallenges. First, they are static and are not meant to keep pace with the\nlatest responsible AI literature and international standards. Second, they tend\nto prioritize individual usage over fostering collaboration among AI\npractitioners. To overcome these limitations, we propose a method that enables\neasy updates of responsible AI guidelines by incorporating research papers and\nISO standards, ensuring that the content remains relevant and up to date, while\nemphasizing actionable guidelines that can be implemented by a wide range of AI\npractitioners. We validated our method in a case study at a large tech company\nby designing and deploying a tool that recommends interactive and actionable\nguidelines, which were generated by a team of engineers, standardization\nexperts, and a lawyer using our method. Through the study involving AI\ndevelopers and engineers, we assessed the usability and effectiveness of the\ntool, showing that the guidelines were considered practical and actionable. The\nguidelines encouraged self-reflection and facilitated a better understanding of\nthe ethical considerations of AI during the early stages of development,\nsignificantly contributing to the idea of \"Responsible AI by Design\" -- a\ndesign-first approach that considers responsible AI values throughout the\ndevelopment lifecycle and across business roles.\n",
                "链接": "https://arxiv.org/abs/2307.15158"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于大模型Agent应用的最新发表论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "61323",
                "标题": "Order Matters: Agent-by-agent Policy Optimization",
                "作者": " Xihuai Wang,  Zheng Tian,  Ziyu Wan,  Ying Wen,  Jun Wang,  Weinan Zhang",
                "发布日期": "2023-02-28",
                "摘要": "  While multi-agent trust region algorithms have achieved great success\nempirically in solving coordination tasks, most of them, however, suffer from a\nnon-stationarity problem since agents update their policies simultaneously. In\ncontrast, a sequential scheme that updates policies agent-by-agent provides\nanother perspective and shows strong performance. However, sample inefficiency\nand lack of monotonic improvement guarantees for each agent are still the two\nsignificant challenges for the sequential scheme. In this paper, we propose the\n\\textbf{A}gent-by-\\textbf{a}gent \\textbf{P}olicy \\textbf{O}ptimization (A2PO)\nalgorithm to improve the sample efficiency and retain the guarantees of\nmonotonic improvement for each agent during training. We justify the tightness\nof the monotonic improvement bound compared with other trust region algorithms.\nFrom the perspective of sequentially updating agents, we further consider the\neffect of agent updating order and extend the theory of non-stationarity into\nthe sequential update scheme. To evaluate A2PO, we conduct a comprehensive\nempirical study on four benchmarks: StarCraftII, Multi-agent MuJoCo,\nMulti-agent Particle Environment, and Google Research Football full game\nscenarios. A2PO consistently outperforms strong baselines.\n",
                "链接": "https://arxiv.org/abs/2302.06205"
            },
            {
                "文章ID": "106067",
                "标题": "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with\n  Agent Team Optimization",
                "作者": " Zijun Liu,  Yanzhe Zhang,  Peng Li,  Yang Liu,  Diyi Yang",
                "发布日期": "2023-10-04",
                "摘要": "  Large language model (LLM) agents have been shown effective on a wide range\nof tasks, and by ensembling multiple LLM agents, their performances could be\nfurther improved. Existing approaches employ a fixed set of agents to interact\nwith each other in a static architecture, which limits their generalizability\nto various tasks and requires strong human prior in designing these agents. In\nthis work, we propose to construct a strategic team of agents communicating in\na dynamic interaction architecture based on the task query. Specifically, we\nbuild a framework named Dynamic LLM-Agent Network ($\\textbf{DyLAN}$) for\nLLM-agent collaboration on complicated tasks like reasoning and code\ngeneration. DyLAN enables agents to interact for multiple rounds in a dynamic\narchitecture with inference-time agent selection and an early-stopping\nmechanism to improve performance and efficiency. We further design an automatic\nagent team optimization algorithm based on an unsupervised metric termed\n$\\textit{Agent Importance Score}$, enabling the selection of best agents based\non the contribution each agent makes. Empirically, we demonstrate that DyLAN\nperforms well in both reasoning and code generation tasks with reasonable\ncomputational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and\nHumanEval, respectively, compared to a single execution on GPT-35-turbo. On\nspecific subjects of MMLU, agent team optimization in DyLAN increases accuracy\nby up to 25.0%.\n",
                "链接": "https://arxiv.org/abs/2310.02170"
            },
            {
                "文章ID": "109786",
                "标题": "Fact-based Agent modeling for Multi-Agent Reinforcement Learning",
                "作者": " Baofu Fang,  Caiming Zheng,  Hao Wang",
                "发布日期": "2023-10-20",
                "摘要": "  In multi-agent systems, agents need to interact and collaborate with other\nagents in environments. Agent modeling is crucial to facilitate agent\ninteractions and make adaptive cooperation strategies. However, it is\nchallenging for agents to model the beliefs, behaviors, and intentions of other\nagents in non-stationary environment where all agent policies are learned\nsimultaneously. In addition, the existing methods realize agent modeling\nthrough behavior cloning which assume that the local information of other\nagents can be accessed during execution or training. However, this assumption\nis infeasible in unknown scenarios characterized by unknown agents, such as\ncompetition teams, unreliable communication and federated learning due to\nprivacy concerns. To eliminate this assumption and achieve agent modeling in\nunknown scenarios, Fact-based Agent modeling (FAM) method is proposed in which\nfact-based belief inference (FBI) network models other agents in partially\nobservable environment only based on its local information. The reward and\nobservation obtained by agents after taking actions are called facts, and FAM\nuses facts as reconstruction target to learn the policy representation of other\nagents through a variational autoencoder. We evaluate FAM on various Multiagent\nParticle Environment (MPE) and compare the results with several\nstate-of-the-art MARL algorithms. Experimental results show that compared with\nbaseline methods, FAM can effectively improve the efficiency of agent policy\nlearning by making adaptive cooperation strategies in multi-agent reinforcement\nlearning tasks, while achieving higher returns in complex\ncompetitive-cooperative mixed scenarios.\n",
                "链接": "https://arxiv.org/abs/2310.12290"
            },
            {
                "文章ID": "124839",
                "标题": "TAPE: Leveraging Agent Topology for Cooperative Multi-Agent Policy\n  Gradient",
                "作者": " Xingzhou Lou,  Junge Zhang,  Timothy J. Norman,  Kaiqi Huang,  Yali Du",
                "发布日期": "2023-12-27",
                "摘要": "  Multi-Agent Policy Gradient (MAPG) has made significant progress in recent\nyears. However, centralized critics in state-of-the-art MAPG methods still face\nthe centralized-decentralized mismatch (CDM) issue, which means sub-optimal\nactions by some agents will affect other agent's policy learning. While using\nindividual critics for policy updates can avoid this issue, they severely limit\ncooperation among agents. To address this issue, we propose an agent topology\nframework, which decides whether other agents should be considered in policy\ngradient and achieves compromise between facilitating cooperation and\nalleviating the CDM issue. The agent topology allows agents to use coalition\nutility as learning objective instead of global utility by centralized critics\nor local utility by individual critics. To constitute the agent topology,\nvarious models are studied. We propose Topology-based multi-Agent Policy\ngradiEnt (TAPE) for both stochastic and deterministic MAPG methods. We prove\nthe policy improvement theorem for stochastic TAPE and give a theoretical\nexplanation for the improved cooperation among agents. Experiment results on\nseveral benchmarks show the agent topology is able to facilitate agent\ncooperation and alleviate CDM issue respectively to improve performance of\nTAPE. Finally, multiple ablation studies and a heuristic graph search algorithm\nare devised to show the efficacy of the agent topology.\n",
                "链接": "https://arxiv.org/abs/2312.15667"
            },
            {
                "文章ID": "118652",
                "标题": "Agent-Aware Training for Agent-Agnostic Action Advising in Deep\n  Reinforcement Learning",
                "作者": " Yaoquan Wei,  Shunyu Liu,  Jie Song,  Tongya Zheng,  Kaixuan Chen,  Yong Wang,  Mingli Song",
                "发布日期": "2023-11-29",
                "摘要": "  Action advising endeavors to leverage supplementary guidance from expert\nteachers to alleviate the issue of sampling inefficiency in Deep Reinforcement\nLearning (DRL). Previous agent-specific action advising methods are hindered by\nimperfections in the agent itself, while agent-agnostic approaches exhibit\nlimited adaptability to the learning agent. In this study, we propose a novel\nframework called Agent-Aware trAining yet Agent-Agnostic Action Advising (A7)\nto strike a balance between the two. The underlying concept of A7 revolves\naround utilizing the similarity of state features as an indicator for\nsoliciting advice. However, unlike prior methodologies, the measurement of\nstate feature similarity is performed by neither the error-prone learning agent\nnor the agent-agnostic advisor. Instead, we employ a proxy model to extract\nstate features that are both discriminative (adaptive to the agent) and\ngenerally applicable (robust to agent noise). Furthermore, we utilize behavior\ncloning to train a model for reusing advice and introduce an intrinsic reward\nfor the advised samples to incentivize the utilization of expert guidance.\nExperiments are conducted on the GridWorld, LunarLander, and six prominent\nscenarios from Atari games. The results demonstrate that A7 significantly\naccelerates the learning process and surpasses existing methods (both\nagent-specific and agent-agnostic) by a substantial margin. Our code will be\nmade publicly available.\n",
                "链接": "https://arxiv.org/abs/2311.16807"
            },
            {
                "文章ID": "46127",
                "标题": "Agent-Time Attention for Sparse Rewards Multi-Agent Reinforcement\n  Learning",
                "作者": " Jennifer She,  Jayesh K. Gupta,  Mykel J. Kochenderfer",
                "发布日期": "2022-11-01",
                "摘要": "  Sparse and delayed rewards pose a challenge to single agent reinforcement\nlearning. This challenge is amplified in multi-agent reinforcement learning\n(MARL) where credit assignment of these rewards needs to happen not only across\ntime, but also across agents. We propose Agent-Time Attention (ATA), a neural\nnetwork model with auxiliary losses for redistributing sparse and delayed\nrewards in collaborative MARL. We provide a simple example that demonstrates\nhow providing agents with their own local redistributed rewards and shared\nglobal redistributed rewards motivate different policies. We extend several\nMiniGrid environments, specifically MultiRoom and DoorKey, to the multi-agent\nsparse delayed rewards setting. We demonstrate that ATA outperforms various\nbaselines on many instances of these environments. Source code of the\nexperiments is available at https://github.com/jshe/agent-time-attention.\n",
                "链接": "https://arxiv.org/abs/2210.17540"
            },
            {
                "文章ID": "4942",
                "标题": "Group-Agent Reinforcement Learning",
                "作者": " Kaiyue Wu,  Xiao-Jun Zeng",
                "发布日期": "2023-10-03",
                "摘要": "  It can largely benefit the reinforcement learning (RL) process of each agent\nif multiple geographically distributed agents perform their separate RL tasks\ncooperatively. Different from multi-agent reinforcement learning (MARL) where\nmultiple agents are in a common environment and should learn to cooperate or\ncompete with each other, in this case each agent has its separate environment\nand only communicates with others to share knowledge without any cooperative or\ncompetitive behaviour as a learning outcome. In fact, this scenario exists\nwidely in real life whose concept can be utilised in many applications, but is\nnot well understood yet and not well formulated. As the first effort, we\npropose group-agent system for RL as a formulation of this scenario and the\nthird type of RL system with respect to single-agent and multi-agent systems.\nWe then propose a distributed RL framework called DDAL (Decentralised\nDistributed Asynchronous Learning) designed for group-agent reinforcement\nlearning (GARL). We show through experiments that DDAL achieved desirable\nperformance with very stable training and has good scalability.\n",
                "链接": "https://arxiv.org/abs/2202.05135"
            },
            {
                "文章ID": "888",
                "标题": "Pavlovian Signalling with General Value Functions in Agent-Agent\n  Temporal Decision Making",
                "作者": " Andrew Butcher,  Michael Bradley Johanson,  Elnaz Davoodi,  Dylan J. A. Brenneis,  Leslie Acker,  Adam S. R. Parker,  Adam White,  Joseph Modayil,  Patrick M. Pilarski",
                "发布日期": "2022-01-12",
                "摘要": "  In this paper, we contribute a multi-faceted study into Pavlovian signalling\n-- a process by which learned, temporally extended predictions made by one\nagent inform decision-making by another agent. Signalling is intimately\nconnected to time and timing. In service of generating and receiving signals,\nhumans and other animals are known to represent time, determine time since past\nevents, predict the time until a future stimulus, and both recognize and\ngenerate patterns that unfold in time. We investigate how different temporal\nprocesses impact coordination and signalling between learning agents by\nintroducing a partially observable decision-making domain we call the Frost\nHollow. In this domain, a prediction learning agent and a reinforcement\nlearning agent are coupled into a two-part decision-making system that works to\nacquire sparse reward while avoiding time-conditional hazards. We evaluate two\ndomain variations: machine agents interacting in a seven-state linear walk, and\nhuman-machine interaction in a virtual-reality environment. Our results\nshowcase the speed of learning for Pavlovian signalling, the impact that\ndifferent temporal representations do (and do not) have on agent-agent\ncoordination, and how temporal aliasing impacts agent-agent and human-agent\ninteractions differently. As a main contribution, we establish Pavlovian\nsignalling as a natural bridge between fixed signalling paradigms and fully\nadaptive communication learning between two agents. We further show how to\ncomputationally build this adaptive signalling process out of a fixed\nsignalling process, characterized by fast continual prediction learning and\nminimal constraints on the nature of the agent receiving signals. Our results\ntherefore suggest an actionable, constructivist path towards communication\nlearning between reinforcement learning agents.\n",
                "链接": "https://arxiv.org/abs/2201.03709"
            },
            {
                "文章ID": "73230",
                "标题": "Heterogeneous-Agent Reinforcement Learning",
                "作者": " Yifan Zhong,  Jakub Grudzien Kuba,  Xidong Feng,  Siyi Hu,  Jiaming Ji,  Yaodong Yang",
                "发布日期": "2023-12-29",
                "摘要": "  The necessity for cooperation among intelligent machines has popularised\ncooperative multi-agent reinforcement learning (MARL) in AI research. However,\nmany research endeavours heavily rely on parameter sharing among agents, which\nconfines them to only homogeneous-agent setting and leads to training\ninstability and lack of convergence guarantees. To achieve effective\ncooperation in the general heterogeneous-agent setting, we propose\nHeterogeneous-Agent Reinforcement Learning (HARL) algorithms that resolve the\naforementioned issues. Central to our findings are the multi-agent advantage\ndecomposition lemma and the sequential update scheme. Based on these, we\ndevelop the provably correct Heterogeneous-Agent Trust Region Learning (HATRL),\nand derive HATRPO and HAPPO by tractable approximations. Furthermore, we\ndiscover a novel framework named Heterogeneous-Agent Mirror Learning (HAML),\nwhich strengthens theoretical guarantees for HATRPO and HAPPO and provides a\ngeneral template for cooperative MARL algorithmic designs. We prove that all\nalgorithms derived from HAML inherently enjoy monotonic improvement of joint\nreturn and convergence to Nash Equilibrium. As its natural outcome, HAML\nvalidates more novel algorithms in addition to HATRPO and HAPPO, including\nHAA2C, HADDPG, and HATD3, which generally outperform their existing\nMA-counterparts. We comprehensively test HARL algorithms on six challenging\nbenchmarks and demonstrate their superior effectiveness and stability for\ncoordinating heterogeneous agents compared to strong baselines such as MAPPO\nand QMIX.\n",
                "链接": "https://arxiv.org/abs/2304.09870"
            },
            {
                "文章ID": "109467",
                "标题": "Agent-Specific Effects",
                "作者": " Stelios Triantafyllou,  Aleksa Sukovic,  Debmalya Mandal,  Goran Radanovic",
                "发布日期": "2023-10-18",
                "摘要": "  Establishing causal relationships between actions and outcomes is fundamental\nfor accountable multi-agent decision-making. However, interpreting and\nquantifying agents' contributions to such relationships pose significant\nchallenges. These challenges are particularly prominent in the context of\nmulti-agent sequential decision-making, where the causal effect of an agent's\naction on the outcome depends on how the other agents respond to that action.\nIn this paper, our objective is to present a systematic approach for\nattributing the causal effects of agents' actions to the influence they exert\non other agents. Focusing on multi-agent Markov decision processes, we\nintroduce agent-specific effects (ASE), a novel causal quantity that measures\nthe effect of an agent's action on the outcome that propagates through other\nagents. We then turn to the counterfactual counterpart of ASE (cf-ASE), provide\na sufficient set of conditions for identifying cf-ASE, and propose a practical\nsampling-based algorithm for estimating it. Finally, we experimentally evaluate\nthe utility of cf-ASE through a simulation-based testbed, which includes a\nsepsis management environment.\n",
                "链接": "https://arxiv.org/abs/2310.11334"
            }
        ]
    },
    {
        "question": {
            "question": "查询近一年模型推理加速相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "111604",
                "标题": "Hierarchical Semi-Implicit Variational Inference with Application to\n  Diffusion Model Acceleration",
                "作者": " Longlin Yu,  Tianyu Xie,  Yu Zhu,  Tong Yang,  Xiangyu Zhang,  Cheng Zhang",
                "发布日期": "2023-10-27",
                "摘要": "  Semi-implicit variational inference (SIVI) has been introduced to expand the\nanalytical variational families by defining expressive semi-implicit\ndistributions in a hierarchical manner. However, the single-layer architecture\ncommonly used in current SIVI methods can be insufficient when the target\nposterior has complicated structures. In this paper, we propose hierarchical\nsemi-implicit variational inference, called HSIVI, which generalizes SIVI to\nallow more expressive multi-layer construction of semi-implicit distributions.\nBy introducing auxiliary distributions that interpolate between a simple base\ndistribution and the target distribution, the conditional layers can be trained\nby progressively matching these auxiliary distributions one layer after\nanother. Moreover, given pre-trained score networks, HSIVI can be used to\naccelerate the sampling process of diffusion models with the score matching\nobjective. We show that HSIVI significantly enhances the expressiveness of SIVI\non several Bayesian inference problems with complicated target distributions.\nWhen used for diffusion model acceleration, we show that HSIVI can produce high\nquality samples comparable to or better than the existing fast diffusion model\nbased samplers with a small number of function evaluations on various datasets.\n",
                "链接": "https://arxiv.org/abs/2310.17153"
            },
            {
                "文章ID": "124676",
                "标题": "Understanding the Potential of FPGA-Based Spatial Acceleration for Large\n  Language Model Inference",
                "作者": " Hongzheng Chen,  Jiahao Zhang,  Yixiao Du,  Shaojie Xiang,  Zichao Yue,  Niansong Zhang,  Yaohui Cai,  Zhiru Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Recent advancements in large language models (LLMs) boasting billions of\nparameters have generated a significant demand for efficient deployment in\ninference workloads. The majority of existing approaches rely on temporal\narchitectures that reuse hardware units for different network layers and\noperators. However, these methods often encounter challenges in achieving low\nlatency due to considerable memory access overhead. This paper investigates the\nfeasibility and potential of model-specific spatial acceleration for LLM\ninference on FPGAs. Our approach involves the specialization of distinct\nhardware units for specific operators or layers, facilitating direct\ncommunication between them through a dataflow architecture while minimizing\noff-chip memory accesses. We introduce a comprehensive analytical model for\nestimating the performance of a spatial LLM accelerator, taking into account\nthe on-chip compute and memory resources available on an FPGA. Through our\nanalysis, we can determine the scenarios in which FPGA-based spatial\nacceleration can outperform its GPU-based counterpart. To enable more\nproductive implementations of an LLM model on FPGAs, we further provide a\nlibrary of high-level synthesis (HLS) kernels that are composable and reusable.\nThis library will be made available as open-source. To validate the\neffectiveness of both our analytical model and HLS library, we have implemented\nBERT and GPT2 on an AMD Alveo U280 FPGA device. Experimental results\ndemonstrate our approach can achieve up to 16.1x speedup when compared to\nprevious FPGA-based accelerators for the BERT model. For GPT generative\ninference, we attain a 2.2x speedup compared to DFX, an FPGA overlay, in the\nprefill stage, while achieving a 1.9x speedup and a 5.7x improvement in energy\nefficiency compared to the NVIDIA A100 GPU in the decode stage.\n",
                "链接": "https://arxiv.org/abs/2312.15159"
            },
            {
                "文章ID": "123966",
                "标题": "Lookahead: An Inference Acceleration Framework for Large Language Model\n  with Lossless Generation Accuracy",
                "作者": " Yao Zhao,  Zhitian Xie,  Chenyi Zhuang,  Jinjie Gu",
                "发布日期": "2023-12-21",
                "摘要": "  As Large Language Models (LLMs) have made significant advancements across\nvarious tasks, such as question answering, translation, text summarization, and\ndialogue systems, the need for accuracy in information becomes crucial,\nespecially for serious financial products serving billions of users like\nAlipay. To address this, Alipay has developed a Retrieval-Augmented Generation\n(RAG) system that grounds LLMs on the most accurate and up-to-date information.\nHowever, for a real-world product serving millions of users, the inference\nspeed of LLMs becomes a critical factor compared to a mere experimental model.\n  Hence, this paper presents a generic framework for accelerating the inference\nprocess, resulting in a substantial increase in speed and cost reduction for\nour RAG system, with lossless generation accuracy. In the traditional inference\nprocess, each token is generated sequentially by the LLM, leading to a time\nconsumption proportional to the number of generated tokens. To enhance this\nprocess, our framework, named \\textit{lookahead}, introduces a\n\\textit{multi-branch} strategy. Instead of generating a single token at a time,\nwe propose a \\textit{Trie-based Retrieval} (TR) process that enables the\ngeneration of multiple branches simultaneously, each of which is a sequence of\ntokens. Subsequently, for each branch, a \\textit{Verification and Accept} (VA)\nprocess is performed to identify the longest correct sub-sequence as the final\noutput. Our strategy offers two distinct advantages: (1) it guarantees absolute\ncorrectness of the output, avoiding any approximation algorithms, and (2) the\nworst-case performance of our approach is equivalent to the conventional\nprocess. We conduct extensive experiments to demonstrate the significant\nimprovements achieved by applying our inference acceleration framework.\n",
                "链接": "https://arxiv.org/abs/2312.12728"
            },
            {
                "文章ID": "108754",
                "标题": "Towards More Accurate Diffusion Model Acceleration with A Timestep\n  Aligner",
                "作者": " Mengfei Xia,  Yujun Shen,  Changsong Lei,  Yu Zhou,  Ran Yi,  Deli Zhao,  Wenping Wang,  Yong-jin Liu",
                "发布日期": "2023-10-17",
                "摘要": "  A diffusion model, which is formulated to produce an image using thousands of\ndenoising steps, usually suffers from a slow inference speed. Existing\nacceleration algorithms simplify the sampling by skipping most steps yet\nexhibit considerable performance degradation. By viewing the generation of\ndiffusion models as a discretized integrating process, we argue that the\nquality drop is partly caused by applying an inaccurate integral direction to a\ntimestep interval. To rectify this issue, we propose a timestep aligner that\nhelps find a more accurate integral direction for a particular interval at the\nminimum cost. Specifically, at each denoising step, we replace the original\nparameterization by conditioning the network on a new timestep, which is\nobtained by aligning the sampling distribution to the real distribution.\nExtensive experiments show that our plug-in design can be trained efficiently\nand boost the inference performance of various state-of-the-art acceleration\nmethods, especially when there are few denoising steps. For example, when using\n10 denoising steps on the popular LSUN Bedroom dataset, we improve the FID of\nDDIM from 9.65 to 6.07, simply by adopting our method for a more appropriate\nset of timesteps. Code will be made publicly available.\n",
                "链接": "https://arxiv.org/abs/2310.09469"
            },
            {
                "文章ID": "102164",
                "标题": "Draft & Verify: Lossless Large Language Model Acceleration via\n  Self-Speculative Decoding",
                "作者": " Jun Zhang,  Jue Wang,  Huan Li,  Lidan Shou,  Ke Chen,  Gang Chen,  Sharad Mehrotra",
                "发布日期": "2023-09-18",
                "摘要": "  We present a novel inference scheme, self-speculative decoding, for\naccelerating Large Language Models (LLMs) without the need for an auxiliary\nmodel. This approach is characterized by a two-stage process: drafting and\nverification. The drafting stage generates draft tokens at a slightly lower\nquality but more quickly, which is achieved by selectively skipping certain\nintermediate layers during drafting Subsequently, the verification stage\nemploys the original LLM to validate those draft output tokens in one forward\npass. This process ensures the final output remains identical to that produced\nby the unaltered LLM, thereby maintaining output quality. The proposed method\nrequires no additional neural network training and no extra memory footprint,\nmaking it a plug-and-play and cost-effective solution for inference\nacceleration. Benchmarks with LLaMA-2 and its fine-tuned models demonstrated a\nspeedup up to 1.73$\\times$.\n",
                "链接": "https://arxiv.org/abs/2309.08168"
            },
            {
                "文章ID": "112504",
                "标题": "SparseByteNN: A Novel Mobile Inference Acceleration Framework Based on\n  Fine-Grained Group Sparsity",
                "作者": " Haitao Xu,  Songwei Liu,  Yuyang Xu,  Shuai Wang,  Jiashi Li,  Chenqian Yan,  Liangqiang Li,  Lean Fu,  Xin Pan,  Fangmin Chen",
                "发布日期": "2023-10-31",
                "摘要": "  To address the challenge of increasing network size, researchers have\ndeveloped sparse models through network pruning. However, maintaining model\naccuracy while achieving significant speedups on general computing devices\nremains an open problem. In this paper, we present a novel mobile inference\nacceleration framework SparseByteNN, which leverages fine-grained kernel\nsparsity to achieve real-time execution as well as high accuracy. Our framework\nconsists of two parts: (a) A fine-grained kernel sparsity schema with a\nsparsity granularity between structured pruning and unstructured pruning. It\ndesigns multiple sparse patterns for different operators. Combined with our\nproposed whole network rearrangement strategy, the schema achieves a high\ncompression rate and high precision at the same time. (b) Inference engine\nco-optimized with the sparse pattern. The conventional wisdom is that this\nreduction in theoretical FLOPs does not translate into real-world efficiency\ngains. We aim to correct this misconception by introducing a family of\nefficient sparse kernels for ARM and WebAssembly. Equipped with our efficient\nimplementation of sparse primitives, we show that sparse versions of\nMobileNet-v1 outperform strong dense baselines on the efficiency-accuracy\ncurve. Experimental results on Qualcomm 855 show that for 30% sparse\nMobileNet-v1, SparseByteNN achieves 1.27x speedup over the dense version and\n1.29x speedup over the state-of-the-art sparse inference engine MNN with a\nslight accuracy drop of 0.224%. The source code of SparseByteNN will be\navailable at https://github.com/lswzjuer/SparseByteNN\n",
                "链接": "https://arxiv.org/abs/2310.19509"
            },
            {
                "文章ID": "87109",
                "标题": "Adaptive DNN Surgery for Selfish Inference Acceleration with On-demand\n  Edge Resource",
                "作者": " Xiang Yang,  Dezhi Chen,  Qi Qi,  Jingyu Wang,  Haifeng Sun,  Jianxin Liao,  Song Guo",
                "发布日期": "2023-06-22",
                "摘要": "  Deep Neural Networks (DNNs) have significantly improved the accuracy of\nintelligent applications on mobile devices. DNN surgery, which partitions DNN\nprocessing between mobile devices and multi-access edge computing (MEC)\nservers, can enable real-time inference despite the computational limitations\nof mobile devices. However, DNN surgery faces a critical challenge: determining\nthe optimal computing resource demand from the server and the corresponding\npartition strategy, while considering both inference latency and MEC server\nusage costs. This problem is compounded by two factors: (1) the finite\ncomputing capacity of the MEC server, which is shared among multiple devices,\nleading to inter-dependent demands, and (2) the shift in modern DNN\narchitecture from chains to directed acyclic graphs (DAGs), which complicates\npotential solutions.\n  In this paper, we introduce a novel Decentralized DNN Surgery (DDS)\nframework. We formulate the partition strategy as a min-cut and propose a\nresource allocation game to adaptively schedule the demands of mobile devices\nin an MEC environment. We prove the existence of a Nash Equilibrium (NE), and\ndevelop an iterative algorithm to efficiently reach the NE for each device. Our\nextensive experiments demonstrate that DDS can effectively handle varying MEC\nscenarios, achieving up to 1.25$\\times$ acceleration compared to the\nstate-of-the-art algorithm.\n",
                "链接": "https://arxiv.org/abs/2306.12185"
            },
            {
                "文章ID": "119522",
                "标题": "LinguaLinked: A Distributed Large Language Model Inference System for\n  Mobile Devices",
                "作者": " Junchen Zhao,  Yurun Song,  Simeng Liu,  Ian G. Harris,  Sangeetha Abdu Jyothi",
                "发布日期": "2023-12-04",
                "摘要": "  Deploying Large Language Models (LLMs) locally on mobile devices presents a\nsignificant challenge due to their extensive memory requirements. In this\npaper, we introduce LinguaLinked, a system for decentralized, distributed LLM\ninference on mobile devices. LinguaLinked enables collaborative execution of\nthe inference task across multiple trusted devices. LinguaLinked ensures data\nprivacy by processing information locally. LinguaLinked uses three key\nstrategies. First, an optimized model assignment technique segments LLMs and\nuses linear optimization to align segments with each device's capabilities.\nSecond, an optimized data transmission mechanism ensures efficient and\nstructured data flow between model segments while also maintaining the\nintegrity of the original model structure. Finally, LinguaLinked incorporates a\nruntime load balancer that actively monitors and redistributes tasks among\nmobile devices to prevent bottlenecks, enhancing the system's overall\nefficiency and responsiveness. We demonstrate that LinguaLinked facilitates\nefficient LLM inference while maintaining consistent throughput and minimal\nlatency through extensive testing across various mobile devices, from high-end\nto low-end Android devices. In our evaluations, compared to the baseline,\nLinguaLinked achieves an inference performance acceleration of $1.11\\times$ to\n$1.61\\times$ in single-threaded settings, $1.73\\times$ to $2.65\\times$ with\nmulti-threading. Additionally, runtime load balancing yields an overall\ninference acceleration of $1.29\\times$ to $1.32\\times$.\n",
                "链接": "https://arxiv.org/abs/2312.00388"
            },
            {
                "文章ID": "91683",
                "标题": "Using the IBM Analog In-Memory Hardware Acceleration Kit for Neural\n  Network Training and Inference",
                "作者": " Manuel Le Gallo,  Corey Lammie,  Julian Buechel,  Fabio Carta,  Omobayode Fagbohungbe,  Charles Mackin,  Hsinyu Tsai,  Vijay Narayanan,  Abu Sebastian,  Kaoutar El Maghraoui,  Malte J. Rasch",
                "发布日期": "2023-07-19",
                "摘要": "  Analog In-Memory Computing (AIMC) is a promising approach to reduce the\nlatency and energy consumption of Deep Neural Network (DNN) inference and\ntraining. However, the noisy and non-linear device characteristics, and the\nnon-ideal peripheral circuitry in AIMC chips, require adapting DNNs to be\ndeployed on such hardware to achieve equivalent accuracy to digital computing.\nIn this tutorial, we provide a deep dive into how such adaptations can be\nachieved and evaluated using the recently released IBM Analog Hardware\nAcceleration Kit (AIHWKit), freely available at https://github.com/IBM/aihwkit.\nThe AIHWKit is a Python library that simulates inference and training of DNNs\nusing AIMC. We present an in-depth description of the AIHWKit design,\nfunctionality, and best practices to properly perform inference and training.\nWe also present an overview of the Analog AI Cloud Composer, that provides the\nbenefits of using the AIHWKit simulation platform in a fully managed cloud\nsetting. Finally, we show examples on how users can expand and customize\nAIHWKit for their own needs. This tutorial is accompanied by comprehensive\nJupyter Notebook code examples that can be run using AIHWKit, which can be\ndownloaded from https://github.com/IBM/aihwkit/tree/master/notebooks/tutorial.\n",
                "链接": "https://arxiv.org/abs/2307.09357"
            },
            {
                "文章ID": "87672",
                "标题": "A Survey on Graph Neural Network Acceleration: Algorithms, Systems, and\n  Customized Hardware",
                "作者": "Celine  Shichang Zhang, Celine  Atefeh Sohrabizadeh, Celine  Cheng Wan, Celine  Zijie Huang, Celine  Ziniu Hu, Celine  Yewen Wang, Celine   Yingyan,   Lin,  Jason Cong,  Yizhou Sun",
                "发布日期": "2023-06-27",
                "摘要": "  Graph neural networks (GNNs) are emerging for machine learning research on\ngraph-structured data. GNNs achieve state-of-the-art performance on many tasks,\nbut they face scalability challenges when it comes to real-world applications\nthat have numerous data and strict latency requirements. Many studies have been\nconducted on how to accelerate GNNs in an effort to address these challenges.\nThese acceleration techniques touch on various aspects of the GNN pipeline,\nfrom smart training and inference algorithms to efficient systems and\ncustomized hardware. As the amount of research on GNN acceleration has grown\nrapidly, there lacks a systematic treatment to provide a unified view and\naddress the complexity of relevant works. In this survey, we provide a taxonomy\nof GNN acceleration, review the existing approaches, and suggest future\nresearch directions. Our taxonomic treatment of GNN acceleration connects the\nexisting works and sets the stage for further development in this area.\n",
                "链接": "https://arxiv.org/abs/2306.14052"
            }
        ]
    },
    {
        "question": {
            "question": "查找论文中包含指令微调细节描述的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "115229",
                "标题": "Context-dependent Instruction Tuning for Dialogue Response Generation",
                "作者": " Jin Myung Kwak,  Minseon Kim,  Sung Ju Hwang",
                "发布日期": "2023-11-14",
                "摘要": "  Recent language models have achieved impressive performance in natural\nlanguage tasks by incorporating instructions with task input during\nfine-tuning. Since all samples in the same natural language task can be\nexplained with the same task instructions, many instruction datasets only\nprovide a few instructions for the entire task, without considering the input\nof each example in the task. However, this approach becomes ineffective in\ncomplex multi-turn dialogue generation tasks, where the input varies highly\nwith each turn as the dialogue context changes, so that simple task\ninstructions cannot improve the generation performance. To address this\nlimitation, we introduce a context-based instruction fine-tuning framework for\neach multi-turn dialogue which generates both responses and instructions based\non the previous context as input. During the evaluation, the model generates\ninstructions based on the previous context to self-guide the response. The\nproposed framework produces comparable or even outstanding results compared to\nthe baselines by aligning instructions to the input during fine-tuning with the\ninstructions in quantitative evaluations on dialogue benchmark datasets with\nreduced computation budget.\n",
                "链接": "https://arxiv.org/abs/2311.07006"
            },
            {
                "文章ID": "54694",
                "标题": "MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction\n  Tuning",
                "作者": " Zhiyang Xu,  Ying Shen,  Lifu Huang",
                "发布日期": "2023-06-13",
                "摘要": "  Instruction tuning, a new learning paradigm that fine-tunes pre-trained\nlanguage models on tasks specified through instructions, has shown promising\nzero-shot performance on various natural language processing tasks. However, it\nhas yet to be explored for vision and multimodal tasks. In this work, we\nintroduce MUL-TIINSTRUCT, the first multimodal instruction tuning benchmark\ndataset that consists of 62 diverse multimodal tasks in a unified seq-to-seq\nformat covering 10 broad categories. The tasks are derived from 21 existing\nopen-source datasets and each task is equipped with 5 expert-written\ninstructions. We take OFA as the base pre-trained model for multimodal\ninstruction tuning, and to further improve its zero-shot performance, we\nexplore multiple transfer learning strategies to leverage the large-scale\nNATURAL INSTRUCTIONS dataset. Experimental results demonstrate strong zero-shot\nperformance on various unseen multimodal tasks and the benefit of transfer\nlearning from a text-only instruction dataset. We also design a new evaluation\nmetric - Sensitivity, to evaluate how sensitive the model is to the variety of\ninstructions. Our results indicate that fine-tuning the model on a diverse set\nof tasks and instructions leads to a reduced sensitivity to variations in\ninstructions for each task.\n",
                "链接": "https://arxiv.org/abs/2212.10773"
            },
            {
                "文章ID": "106890",
                "标题": "Ada-Instruct: Adapting Instruction Generators for Complex Reasoning",
                "作者": " Wanyun Cui,  Qianle Wang",
                "发布日期": "2023-10-11",
                "摘要": "  Generating diverse and sophisticated instructions for downstream tasks by\nLarge Language Models (LLMs) is pivotal for advancing the effect. Current\napproaches leverage closed-source LLMs, employing in-context prompting for\ninstruction generation. However, in this paper, we found that in-context\nprompting cannot generate complex instructions with length $\\ge 100$ for tasks\nlike code completion.\n  To solve this problem, we introduce Ada-Instruct, an adaptive instruction\ngenerator developed by fine-tuning open-source LLMs. Our pivotal finding\nillustrates that fine-tuning open-source LLMs with a mere ten samples generates\nlong instructions that maintain distributional consistency for complex\nreasoning tasks. We empirically validated Ada-Instruct's efficacy across\ndifferent applications, including code completion, mathematical reasoning, and\ncommonsense reasoning. The results underscore Ada-Instruct's superiority,\nevidencing its improvements over its base models, current self-instruct\nmethods, and other state-of-the-art models.\n",
                "链接": "https://arxiv.org/abs/2310.04484"
            },
            {
                "文章ID": "86802",
                "标题": "Evaluating the Zero-shot Robustness of Instruction-tuned Language Models",
                "作者": " Jiuding Sun,  Chantal Shaib,  Byron C. Wallace",
                "发布日期": "2023-07-13",
                "摘要": "  Instruction fine-tuning has recently emerged as a promising approach for\nimproving the zero-shot capabilities of Large Language Models (LLMs) on new\ntasks. This technique has shown particular strength in improving the\nperformance of modestly sized LLMs, sometimes inducing performance competitive\nwith much larger model variants. In this paper we ask two questions: (1) How\nsensitive are instruction-tuned models to the particular phrasings of\ninstructions, and, (2) How can we make them more robust to such natural\nlanguage variation? To answer the former, we collect a set of 319 instructions\nmanually written by NLP practitioners for over 80 unique tasks included in\nwidely used benchmarks, and we evaluate the variance and average performance of\nthese instructions as compared to instruction phrasings observed during\ninstruction fine-tuning. We find that using novel (unobserved) but appropriate\ninstruction phrasings consistently degrades model performance, sometimes\nsubstantially so. Further, such natural instructions yield a wide variance in\ndownstream performance, despite their semantic equivalence. Put another way,\ninstruction-tuned models are not especially robust to instruction re-phrasings.\nWe propose a simple method to mitigate this issue by introducing ``soft\nprompt'' embedding parameters and optimizing these to maximize the similarity\nbetween representations of semantically equivalent instructions. We show that\nthis method consistently improves the robustness of instruction-tuned models.\n",
                "链接": "https://arxiv.org/abs/2306.11270"
            },
            {
                "文章ID": "102063",
                "标题": "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language\n  Models that Follow Instructions",
                "作者": " Federico Bianchi,  Mirac Suzgun,  Giuseppe Attanasio,  Paul Röttger,  Dan Jurafsky,  Tatsunori Hashimoto,  James Zou",
                "发布日期": "2023-09-26",
                "摘要": "  Training large language models to follow instructions makes them perform\nbetter on a wide range of tasks, generally becoming more helpful. However, a\nperfectly helpful model will follow even the most malicious instructions and\nreadily generate harmful content. In this paper, we raise concerns over the\nsafety of models that only emphasize helpfulness, not safety, in their\ninstruction-tuning. We show that several popular instruction-tuned models are\nhighly unsafe. Moreover, we show that adding just 3% safety examples (a few\nhundred demonstrations) in the training set when fine-tuning a model like LLaMA\ncan substantially improve their safety. Our safety-tuning does not make models\nsignificantly less capable or helpful as measured by standard benchmarks.\nHowever, we do find a behavior of exaggerated safety, where too much\nsafety-tuning makes models refuse to respond to reasonable prompts that\nsuperficially resemble unsafe ones. Our study sheds light on trade-offs in\ntraining LLMs to follow instructions and exhibit safe behavior.\n",
                "链接": "https://arxiv.org/abs/2309.07875"
            },
            {
                "文章ID": "110123",
                "标题": "Enhancing Zero-Shot Crypto Sentiment with Fine-tuned Language Model and\n  Prompt Engineering",
                "作者": " Rahman S M Wahidur,  Ishmam Tashdeed,  Manjit Kaur,   Heung-No-Lee",
                "发布日期": "2023-10-23",
                "摘要": "  Blockchain technology has revolutionized the financial landscape, with\ncryptocurrencies gaining widespread adoption for their decentralized and\ntransparent nature. As the sentiment expressed on social media platforms can\nsignificantly influence cryptocurrency discussions and market movements,\nsentiment analysis has emerged as a crucial tool for understanding public\nopinion and predicting market trends. Motivated by the aim to enhance sentiment\nanalysis accuracy in the cryptocurrency domain, this paper investigates\nfine-tuning techniques on large language models. This paper also investigates\nthe efficacy of supervised fine-tuning and instruction-based fine-tuning on\nlarge language models for unseen tasks. Experimental results demonstrate a\nsignificant average zero-shot performance gain of 40% after fine-tuning,\nhighlighting the potential of this technique in optimizing pre-trained language\nmodel efficiency. Additionally, the impact of instruction tuning on models of\nvarying scales is examined, revealing that larger models benefit from\ninstruction tuning, achieving the highest average accuracy score of 75.16%. In\ncontrast, smaller-scale models may experience reduced generalization due to the\ncomplete utilization of model capacity. To gain deeper insight about how\ninstruction works with these language models, this paper presents an\nexperimental investigation into the response of an instruction-based model\nunder different instruction tuning setups. The investigation demonstrates that\nthe model achieves an average accuracy score of 72.38% for short and simple\ninstructions. This performance significantly outperforms its accuracy under\nlong and complex instructions by over 12%, thereby effectively highlighting the\nprofound significance of instruction characteristics in maximizing model\nperformance.\n",
                "链接": "https://arxiv.org/abs/2310.13226"
            },
            {
                "文章ID": "95319",
                "标题": "Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative\n  Instructions",
                "作者": " Juncheng Li,  Kaihang Pan,  Zhiqi Ge,  Minghe Gao,  Hanwang Zhang,  Wei Ji,  Wenqiao Zhang,  Tat-Seng Chua,  Siliang Tang,  Yueting Zhuang",
                "发布日期": "2023-10-03",
                "摘要": "  Recent advancements in Multimodal Large Language Models (MLLMs) have been\nutilizing Visual Prompt Generators (VPGs) to convert visual features into\ntokens that LLMs can recognize. This is achieved by training the VPGs on\nmillions of image-caption pairs, where the VPG-generated tokens of images are\nfed into a frozen LLM to generate the corresponding captions. However, this\nimage-captioning based training objective inherently biases the VPG to\nconcentrate solely on the primary visual contents sufficient for caption\ngeneration, often neglecting other visual details. This shortcoming results in\nMLLMs' underperformance in comprehending demonstrative instructions consisting\nof multiple, interleaved, and multimodal instructions that demonstrate the\nrequired context to complete a task. To address this issue, we introduce a\ngeneric and lightweight Visual Prompt Generator Complete module (VPG-C), which\ncan infer and complete the missing details essential for comprehending\ndemonstrative instructions. Further, we propose a synthetic discriminative\ntraining strategy to fine-tune VPG-C, eliminating the need for supervised\ndemonstrative instructions. As for evaluation, we build DEMON, a comprehensive\nbenchmark for demonstrative instruction understanding. Synthetically trained\nwith the proposed strategy, VPG-C achieves significantly stronger zero-shot\nperformance across all tasks of DEMON. Further evaluation on the MME and\nOwlEval benchmarks also demonstrate the superiority of VPG-C. Our benchmark,\ncode, and pre-trained models are available at\nhttps://github.com/DCDmllm/Cheetah.\n",
                "链接": "https://arxiv.org/abs/2308.04152"
            },
            {
                "文章ID": "54525",
                "标题": "HINT: Hypernetwork Instruction Tuning for Efficient Zero- & Few-Shot\n  Generalisation",
                "作者": " Hamish Ivison,  Akshita Bhagia,  Yizhong Wang,  Hannaneh Hajishirzi,  Matthew Peters",
                "发布日期": "2023-05-26",
                "摘要": "  Recent NLP models have shown the remarkable ability to effectively generalise\n`zero-shot' to new tasks using only natural language instructions as guidance.\nHowever, many of these approaches suffer from high computational costs due to\ntheir reliance on concatenating lengthy instructions with every input example,\nresulting in costly reprocessing of the instruction. To avoid this, we\nintroduce Hypernetworks for INstruction Tuning (HINT), which convert task\ninstructions and examples into parameter-efficient modules inserted into an\nunderlying model using a pretrained text encoder, eliminating the need to\ninclude instructions in the model input. The hypernetwork in HINT also produces\nan encoded instruction, which we concatenate with encoded inputs during\ndecoding to further improve performance. HINT models outperform strong\nstate-of-the-art baselines by over 10% when controlling for compute (measured\nin FLOPs). By converting instructions into modules, HINT models can effectively\ndisregard the length of instructions and few-shot example inputs in terms of\ncompute usage. As a result, HINT can enhance its performance by up to 25% by\nincorporating additional few-shot data, while utilizing only up to 5% more\ncompute. This combines the strengths of parameter-efficient fine-tuning and\nin-context learning.\n",
                "链接": "https://arxiv.org/abs/2212.10315"
            },
            {
                "文章ID": "112674",
                "标题": "BioInstruct: Instruction Tuning of Large Language Models for Biomedical\n  Natural Language Processing",
                "作者": " Hieu Tran,  Zhichao Yang,  Zonghai Yao,  Hong Yu",
                "发布日期": "2023-11-07",
                "摘要": "  To enhance the performance of large language models (LLMs) in biomedical\nnatural language processing (BioNLP) by introducing a domain-specific\ninstruction dataset and examining its impact when combined with multi-task\nlearning principles. We created the BioInstruct, comprising 25,005 instructions\nto instruction-tune LLMs(LLaMA 1 & 2, 7B & 13B version). The instructions were\ncreated by prompting the GPT-4 language model with three-seed samples randomly\ndrawn from an 80 human curated instructions. We employed Low-Rank\nAdaptation(LoRA) for parameter-efficient fine-tuning. We then evaluated these\ninstruction-tuned LLMs on several BioNLP tasks, which can be grouped into three\nmajor categories: question answering(QA), information extraction(IE), and text\ngeneration(GEN). We also examined whether categories(e.g., QA, IE, and\ngeneration) of instructions impact model performance. Comparing with LLMs\nwithout instruction-tuned, our instruction-tuned LLMs demonstrated marked\nperformance gains: 17.3% in QA, 5.7% in IE, and 96% in Generation tasks. Our\n7B-parameter instruction-tuned LLaMA 1 model was competitive or even surpassed\nother LLMs in the biomedical domain that were also fine-tuned from LLaMA 1 with\nvast domain-specific data or a variety of tasks. Our results also show that the\nperformance gain is significantly higher when instruction fine-tuning is\nconducted with closely related tasks. Our findings align with the observations\nof multi-task learning, suggesting the synergies between two tasks. The\nBioInstruct dataset serves as a valuable resource and instruction tuned LLMs\nlead to the best performing BioNLP applications.\n",
                "链接": "https://arxiv.org/abs/2310.19975"
            },
            {
                "文章ID": "110091",
                "标题": "Auto-Instruct: Automatic Instruction Generation and Ranking for\n  Black-Box Language Models",
                "作者": " Zhihan Zhang,  Shuohang Wang,  Wenhao Yu,  Yichong Xu,  Dan Iter,  Qingkai Zeng,  Yang Liu,  Chenguang Zhu,  Meng Jiang",
                "发布日期": "2023-10-23",
                "摘要": "  Large language models (LLMs) can perform a wide range of tasks by following\nnatural language instructions, without the necessity of task-specific\nfine-tuning. Unfortunately, the performance of LLMs is greatly influenced by\nthe quality of these instructions, and manually writing effective instructions\nfor each task is a laborious and subjective process. In this paper, we\nintroduce Auto-Instruct, a novel method to automatically improve the quality of\ninstructions provided to LLMs. Our method leverages the inherent generative\nability of LLMs to produce diverse candidate instructions for a given task, and\nthen ranks them using a scoring model trained on a variety of 575 existing NLP\ntasks. In experiments on 118 out-of-domain tasks, Auto-Instruct surpasses both\nhuman-written instructions and existing baselines of LLM-generated\ninstructions. Furthermore, our method exhibits notable generalizability even\nwith other LLMs that are not incorporated into its training process.\n",
                "链接": "https://arxiv.org/abs/2310.13127"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月agent系列决策文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "888",
                "标题": "Pavlovian Signalling with General Value Functions in Agent-Agent\n  Temporal Decision Making",
                "作者": " Andrew Butcher,  Michael Bradley Johanson,  Elnaz Davoodi,  Dylan J. A. Brenneis,  Leslie Acker,  Adam S. R. Parker,  Adam White,  Joseph Modayil,  Patrick M. Pilarski",
                "发布日期": "2022-01-12",
                "摘要": "  In this paper, we contribute a multi-faceted study into Pavlovian signalling\n-- a process by which learned, temporally extended predictions made by one\nagent inform decision-making by another agent. Signalling is intimately\nconnected to time and timing. In service of generating and receiving signals,\nhumans and other animals are known to represent time, determine time since past\nevents, predict the time until a future stimulus, and both recognize and\ngenerate patterns that unfold in time. We investigate how different temporal\nprocesses impact coordination and signalling between learning agents by\nintroducing a partially observable decision-making domain we call the Frost\nHollow. In this domain, a prediction learning agent and a reinforcement\nlearning agent are coupled into a two-part decision-making system that works to\nacquire sparse reward while avoiding time-conditional hazards. We evaluate two\ndomain variations: machine agents interacting in a seven-state linear walk, and\nhuman-machine interaction in a virtual-reality environment. Our results\nshowcase the speed of learning for Pavlovian signalling, the impact that\ndifferent temporal representations do (and do not) have on agent-agent\ncoordination, and how temporal aliasing impacts agent-agent and human-agent\ninteractions differently. As a main contribution, we establish Pavlovian\nsignalling as a natural bridge between fixed signalling paradigms and fully\nadaptive communication learning between two agents. We further show how to\ncomputationally build this adaptive signalling process out of a fixed\nsignalling process, characterized by fast continual prediction learning and\nminimal constraints on the nature of the agent receiving signals. Our results\ntherefore suggest an actionable, constructivist path towards communication\nlearning between reinforcement learning agents.\n",
                "链接": "https://arxiv.org/abs/2201.03709"
            },
            {
                "文章ID": "109649",
                "标题": "Masked Pretraining for Multi-Agent Decision Making",
                "作者": " Jie Liu,  Yinmin Zhang,  Chuming Li,  Chao Yang,  Yaodong Yang,  Yu Liu,  Wanli Ouyang",
                "发布日期": "2023-10-19",
                "摘要": "  Building a single generalist agent with zero-shot capability has recently\nsparked significant advancements in decision-making. However, extending this\ncapability to multi-agent scenarios presents challenges. Most current works\nstruggle with zero-shot capabilities, due to two challenges particular to the\nmulti-agent settings: a mismatch between centralized pretraining and\ndecentralized execution, and varying agent numbers and action spaces, making it\ndifficult to create generalizable representations across diverse downstream\ntasks. To overcome these challenges, we propose a \\textbf{Mask}ed pretraining\nframework for \\textbf{M}ulti-\\textbf{a}gent decision making (MaskMA). This\nmodel, based on transformer architecture, employs a mask-based collaborative\nlearning strategy suited for decentralized execution with partial observation.\nMoreover, MaskMA integrates a generalizable action representation by dividing\nthe action space into actions toward self-information and actions related to\nother entities. This flexibility allows MaskMA to tackle tasks with varying\nagent numbers and thus different action spaces. Extensive experiments in SMAC\nreveal MaskMA, with a single model pretrained on 11 training maps, can achieve\nan impressive 77.8% zero-shot win rate on 60 unseen test maps by decentralized\nexecution, while also performing effectively on other types of downstream tasks\n(\\textit{e.g.,} varied policies collaboration and ad hoc team play).\n",
                "链接": "https://arxiv.org/abs/2310.11846"
            },
            {
                "文章ID": "21021",
                "标题": "MAVIPER: Learning Decision Tree Policies for Interpretable Multi-Agent\n  Reinforcement Learning",
                "作者": " Stephanie Milani,  Zhicheng Zhang,  Nicholay Topin,  Zheyuan Ryan Shi,  Charles Kamhoua,  Evangelos E. Papalexakis,  Fei Fang",
                "发布日期": "2022-07-13",
                "摘要": "  Many recent breakthroughs in multi-agent reinforcement learning (MARL)\nrequire the use of deep neural networks, which are challenging for human\nexperts to interpret and understand. On the other hand, existing work on\ninterpretable reinforcement learning (RL) has shown promise in extracting more\ninterpretable decision tree-based policies from neural networks, but only in\nthe single-agent setting. To fill this gap, we propose the first set of\nalgorithms that extract interpretable decision-tree policies from neural\nnetworks trained with MARL. The first algorithm, IVIPER, extends VIPER, a\nrecent method for single-agent interpretable RL, to the multi-agent setting. We\ndemonstrate that IVIPER learns high-quality decision-tree policies for each\nagent. To better capture coordination between agents, we propose a novel\ncentralized decision-tree training algorithm, MAVIPER. MAVIPER jointly grows\nthe trees of each agent by predicting the behavior of the other agents using\ntheir anticipated trees, and uses resampling to focus on states that are\ncritical for its interactions with other agents. We show that both algorithms\ngenerally outperform the baselines and that MAVIPER-trained agents achieve\nbetter-coordinated performance than IVIPER-trained agents on three different\nmulti-agent particle-world environments.\n",
                "链接": "https://arxiv.org/abs/2205.12449"
            },
            {
                "文章ID": "51573",
                "标题": "Decision Market Based Learning For Multi-agent Contextual Bandit\n  Problems",
                "作者": " Wenlong Wang,  Thomas Pfeiffer",
                "发布日期": "2022-12-02",
                "摘要": "  Information is often stored in a distributed and proprietary form, and agents\nwho own information are often self-interested and require incentives to reveal\ntheir information. Suitable mechanisms are required to elicit and aggregate\nsuch distributed information for decision making. In this paper, we use\nsimulations to investigate the use of decision markets as mechanisms in a\nmulti-agent learning system to aggregate distributed information for\ndecision-making in a contextual bandit problem. The system utilises strictly\nproper decision scoring rules to assess the accuracy of probabilistic reports\nfrom agents, which allows agents to learn to solve the contextual bandit\nproblem jointly. Our simulations show that our multi-agent system with\ndistributed information can be trained as efficiently as a centralised\ncounterpart with a single agent that receives all information. Moreover, we use\nour system to investigate scenarios with deterministic decision scoring rules\nwhich are not incentive compatible. We observe the emergence of more complex\ndynamics with manipulative behaviour, which agrees with existing theoretical\nanalyses.\n",
                "链接": "https://arxiv.org/abs/2212.00271"
            },
            {
                "文章ID": "75128",
                "标题": "On the Complexity of Multi-Agent Decision Making: From Learning in Games\n  to Partial Monitoring",
                "作者": " Dylan J. Foster,  Dean P. Foster,  Noah Golowich,  Alexander Rakhlin",
                "发布日期": "2023-05-02",
                "摘要": "  A central problem in the theory of multi-agent reinforcement learning (MARL)\nis to understand what structural conditions and algorithmic principles lead to\nsample-efficient learning guarantees, and how these considerations change as we\nmove from few to many agents. We study this question in a general framework for\ninteractive decision making with multiple agents, encompassing Markov games\nwith function approximation and normal-form games with bandit feedback. We\nfocus on equilibrium computation, in which a centralized learning algorithm\naims to compute an equilibrium by controlling multiple agents that interact\nwith an unknown environment. Our main contributions are:\n  - We provide upper and lower bounds on the optimal sample complexity for\nmulti-agent decision making based on a multi-agent generalization of the\nDecision-Estimation Coefficient, a complexity measure introduced by Foster et\nal. (2021) in the single-agent counterpart to our setting. Compared to the best\nresults for the single-agent setting, our bounds have additional gaps. We show\nthat no \"reasonable\" complexity measure can close these gaps, highlighting a\nstriking separation between single and multiple agents.\n  - We show that characterizing the statistical complexity for multi-agent\ndecision making is equivalent to characterizing the statistical complexity of\nsingle-agent decision making, but with hidden (unobserved) rewards, a framework\nthat subsumes variants of the partial monitoring problem. As a consequence, we\ncharacterize the statistical complexity for hidden-reward interactive decision\nmaking to the best extent possible.\n  Building on this development, we provide several new structural results,\nincluding 1) conditions under which the statistical complexity of multi-agent\ndecision making can be reduced to that of single-agent, and 2) conditions under\nwhich the so-called curse of multiple agents can be avoided.\n",
                "链接": "https://arxiv.org/abs/2305.00684"
            },
            {
                "文章ID": "105753",
                "标题": "ChoiceMates: Supporting Unfamiliar Online Decision-Making with\n  Multi-Agent Conversational Interactions",
                "作者": " Jeongeon Park,  Bryan Min,  Xiaojuan Ma,  Juho Kim",
                "发布日期": "2023-11-15",
                "摘要": "  Unfamiliar decisions -- decisions where people lack adequate domain knowledge\nor expertise -- specifically increase the complexity and uncertainty of the\nprocess of searching for, understanding, and making decisions with online\ninformation. Through our formative study (n=14), we observed users' challenges\nin accessing diverse perspectives, identifying relevant information, and\ndeciding the right moment to make the final decision. We present ChoiceMates, a\nsystem that enables conversations with a dynamic set of LLM-powered agents for\na holistic domain understanding and efficient discovery and management of\ninformation to make decisions. Agents, as opinionated personas, flexibly join\nthe conversation, not only providing responses but also conversing among\nthemselves to elicit each agent's preferences. Our between-subjects study\n(n=36) comparing ChoiceMates to conventional web search and single-agent showed\nthat ChoiceMates was more helpful in discovering, diving deeper, and managing\ninformation compared to Web with higher confidence. We also describe how\nparticipants utilized multi-agent conversations in their decision-making\nprocess.\n",
                "链接": "https://arxiv.org/abs/2310.01331"
            },
            {
                "文章ID": "77334",
                "标题": "Stackelberg Decision Transformer for Asynchronous Action Coordination in\n  Multi-Agent Systems",
                "作者": " Bin Zhang,  Hangyu Mao,  Lijuan Li,  Zhiwei Xu,  Dapeng Li,  Rui Zhao,  Guoliang Fan",
                "发布日期": "2023-05-16",
                "摘要": "  Asynchronous action coordination presents a pervasive challenge in\nMulti-Agent Systems (MAS), which can be represented as a Stackelberg game (SG).\nHowever, the scalability of existing Multi-Agent Reinforcement Learning (MARL)\nmethods based on SG is severely constrained by network structures or\nenvironmental limitations. To address this issue, we propose the Stackelberg\nDecision Transformer (STEER), a heuristic approach that resolves the\ndifficulties of hierarchical coordination among agents. STEER efficiently\nmanages decision-making processes in both spatial and temporal contexts by\nincorporating the hierarchical decision structure of SG, the modeling\ncapability of autoregressive sequence models, and the exploratory learning\nmethodology of MARL. Our research contributes to the development of an\neffective and adaptable asynchronous action coordination method that can be\nwidely applied to various task types and environmental configurations in MAS.\nExperimental results demonstrate that our method can converge to Stackelberg\nequilibrium solutions and outperforms other existing methods in complex\nscenarios.\n",
                "链接": "https://arxiv.org/abs/2305.07856"
            },
            {
                "文章ID": "116901",
                "标题": "Approximate Linear Programming and Decentralized Policy Improvement in\n  Cooperative Multi-agent Markov Decision Processes",
                "作者": " Lakshmi Mandal,  Chandrashekar Lakshminarayanan,  Shalabh Bhatnagar",
                "发布日期": "2023-11-21",
                "摘要": "  In this work, we consider a `cooperative' multi-agent Markov decision process\n(MDP) involving m greater than 1 agents, where all agents are aware of the\nsystem model. At each decision epoch, all the m agents cooperatively select\nactions in order to maximize a common long-term objective. Since the number of\nactions grows exponentially in the number of agents, policy improvement is\ncomputationally expensive. Recent works have proposed using decentralized\npolicy improvement in which each agent assumes that the decisions of the other\nagents are fixed and it improves its decisions unilaterally. Yet, in these\nworks, exact values are computed. In our work, for cooperative multi-agent\nfinite and infinite horizon discounted MDPs, we propose suitable approximate\npolicy iteration algorithms, wherein we use approximate linear programming to\ncompute the approximate value function and use decentralized policy\nimprovement. Thus our algorithms can handle both large number of states as well\nas multiple agents. We provide theoretical guarantees for our algorithms and\nalso demonstrate the performance of our algorithms on some numerical examples.\n",
                "链接": "https://arxiv.org/abs/2311.11789"
            },
            {
                "文章ID": "81280",
                "标题": "Research on Multi-Agent Communication and Collaborative Decision-Making\n  Based on Deep Reinforcement Learning",
                "作者": " Zeng Da",
                "发布日期": "2023-05-30",
                "摘要": "  In a multi-agent environment, In order to overcome and alleviate the\nnon-stationarity of the multi-agent environment, the mainstream method is to\nadopt the framework of Centralized Training Decentralized Execution (CTDE).\nThis thesis is based on the framework of CTDE, and studies the cooperative\ndecision-making of multi-agent based on the Multi-Agent Proximal Policy\nOptimization (MAPPO) algorithm for multi-agent proximal policy optimization. In\norder to alleviate the non-stationarity of the multi-agent environment, a\nmulti-agent communication mechanism based on weight scheduling and attention\nmodule is introduced. Different agents can alleviate the non-stationarity\ncaused by local observations through information exchange between agents,\nassisting in the collaborative decision-making of agents. The specific method\nis to introduce a communication module in the policy network part. The\ncommunication module is composed of a weight generator, a weight scheduler, a\nmessage encoder, a message pool and an attention module. Among them, the weight\ngenerator and weight scheduler will generate weights as the selection basis for\ncommunication, the message encoder is used to compress and encode communication\ninformation, the message pool is used to store communication messages, and the\nattention module realizes the interactive processing of the agent's own\ninformation and communication information. This thesis proposes a Multi-Agent\nCommunication and Global Information Optimization Proximal Policy\nOptimization(MCGOPPO)algorithm, and conducted experiments in the SMAC and the\nMPE. The experimental results show that the improvement has achieved certain\neffects, which can better alleviate the non-stationarity of the multi-agent\nenvironment, and improve the collaborative decision-making ability among the\nagents.\n",
                "链接": "https://arxiv.org/abs/2305.17141"
            },
            {
                "文章ID": "117191",
                "标题": "Decentralised Q-Learning for Multi-Agent Markov Decision Processes with\n  a Satisfiability Criterion",
                "作者": " Keshav P. Keval,  Vivek S. Borkar",
                "发布日期": "2023-11-22",
                "摘要": "  In this paper, we propose a reinforcement learning algorithm to solve a\nmulti-agent Markov decision process (MMDP). The goal, inspired by Blackwell's\nApproachability Theorem, is to lower the time average cost of each agent to\nbelow a pre-specified agent-specific bound. For the MMDP, we assume the state\ndynamics to be controlled by the joint actions of agents, but the per-stage\ncosts to only depend on the individual agent's actions. We combine the\nQ-learning algorithm for a weighted combination of the costs of each agent,\nobtained by a gossip algorithm with the Metropolis-Hastings or Multiplicative\nWeights formalisms to modulate the averaging matrix of the gossip. We use\nmultiple timescales in our algorithm and prove that under mild conditions, it\napproximately achieves the desired bounds for each of the agents. We also\ndemonstrate the empirical performance of this algorithm in the more general\nsetting of MMDPs having jointly controlled per-stage costs.\n",
                "链接": "https://arxiv.org/abs/2311.12613"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态优化训练方式的相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大模型推理的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "近几个月自然语言处理相关的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "115729",
                "标题": "Natural Language Processing for Financial Regulation",
                "作者": " Ixandra Achitouv,  Dragos Gorduza,  Antoine Jacquier",
                "发布日期": "2023-11-16",
                "摘要": "  This article provides an understanding of Natural Language Processing\ntechniques in the framework of financial regulation, more specifically in order\nto perform semantic matching search between rules and policy when no dataset is\navailable for supervised learning. We outline how to outperform simple\npre-trained sentences-transformer models using freely available resources and\nexplain the mathematical concepts behind the key building blocks of Natural\nLanguage Processing.\n",
                "链接": "https://arxiv.org/abs/2311.08533"
            },
            {
                "文章ID": "53444",
                "标题": "Categorical Tools for Natural Language Processing",
                "作者": " Giovanni de Felice",
                "发布日期": "2022-12-14",
                "摘要": "  This thesis develops the translation between category theory and\ncomputational linguistics as a foundation for natural language processing. The\nthree chapters deal with syntax, semantics and pragmatics. First, string\ndiagrams provide a unified model of syntactic structures in formal grammars.\nSecond, functors compute semantics by turning diagrams into logical, tensor,\nneural or quantum computation. Third, the resulting functorial models can be\ncomposed to form games where equilibria are the solutions of language\nprocessing tasks. This framework is implemented as part of DisCoPy, the Python\nlibrary for computing with string diagrams. We describe the correspondence\nbetween categorical, linguistic and computational structures, and demonstrate\ntheir applications in compositional natural language processing.\n",
                "链接": "https://arxiv.org/abs/2212.06636"
            },
            {
                "文章ID": "119807",
                "标题": "Enabling Quantum Natural Language Processing for Hindi Language",
                "作者": " Naman Srivastava,  Gaurang Belekar,  Sunil Saumya,  Aswath Babu H",
                "发布日期": "2023-12-05",
                "摘要": "  Quantum Natural Language Processing (QNLP) is taking huge leaps in solving\nthe shortcomings of classical Natural Language Processing (NLP) techniques and\nmoving towards a more \"Explainable\" NLP system. The current literature around\nQNLP focuses primarily on implementing QNLP techniques in sentences in the\nEnglish language. In this paper, we propose to enable the QNLP approach to\nHINDI, which is the third most spoken language in South Asia. We present the\nprocess of building the parameterized quantum circuits required to undertake\nQNLP on Hindi sentences. We use the pregroup representation of Hindi and the\nDisCoCat framework to draw sentence diagrams. Later, we translate these\ndiagrams to Parameterised Quantum Circuits based on Instantaneous Quantum\nPolynomial (IQP) style ansatz. Using these parameterized quantum circuits\nallows one to train grammar and topic-aware sentence classifiers for the Hindi\nLanguage.\n",
                "链接": "https://arxiv.org/abs/2312.01221"
            },
            {
                "文章ID": "79436",
                "标题": "Interactive Natural Language Processing",
                "作者": " Zekun Wang,  Ge Zhang,  Kexin Yang,  Ning Shi,  Wangchunshu Zhou,  Shaochun Hao,  Guangzheng Xiong,  Yizhi Li,  Mong Yuan Sim,  Xiuying Chen,  Qingqing Zhu,  Zhenzhu Yang,  Adam Nik,  Qi Liu,  Chenghua Lin,  Shi Wang,  Ruibo Liu,  Wenhu Chen,  Ke Xu,  Dayiheng Liu,  Yike Guo,  Jie Fu",
                "发布日期": "2023-05-23",
                "摘要": "  Interactive Natural Language Processing (iNLP) has emerged as a novel\nparadigm within the field of NLP, aimed at addressing limitations in existing\nframeworks while aligning with the ultimate goals of artificial intelligence.\nThis paradigm considers language models as agents capable of observing, acting,\nand receiving feedback iteratively from external entities. Specifically,\nlanguage models in this context can: (1) interact with humans for better\nunderstanding and addressing user needs, personalizing responses, aligning with\nhuman values, and improving the overall user experience; (2) interact with\nknowledge bases for enriching language representations with factual knowledge,\nenhancing the contextual relevance of responses, and dynamically leveraging\nexternal information to generate more accurate and informed responses; (3)\ninteract with models and tools for effectively decomposing and addressing\ncomplex tasks, leveraging specialized expertise for specific subtasks, and\nfostering the simulation of social behaviors; and (4) interact with\nenvironments for learning grounded representations of language, and effectively\ntackling embodied tasks such as reasoning, planning, and decision-making in\nresponse to environmental observations. This paper offers a comprehensive\nsurvey of iNLP, starting by proposing a unified definition and framework of the\nconcept. We then provide a systematic classification of iNLP, dissecting its\nvarious components, including interactive objects, interaction interfaces, and\ninteraction methods. We proceed to delve into the evaluation methodologies used\nin the field, explore its diverse applications, scrutinize its ethical and\nsafety issues, and discuss prospective research directions. This survey serves\nas an entry point for researchers who are interested in this rapidly evolving\narea and offers a broad view of the current landscape and future trajectory of\niNLP.\n",
                "链接": "https://arxiv.org/abs/2305.13246"
            },
            {
                "文章ID": "60462",
                "标题": "Natural Language Processing for Policymaking",
                "作者": " Zhijing Jin,  Rada Mihalcea",
                "发布日期": "2023-02-08",
                "摘要": "  Language is the medium for many political activities, from campaigns to news\nreports. Natural language processing (NLP) uses computational tools to parse\ntext into key information that is needed for policymaking. In this chapter, we\nintroduce common methods of NLP, including text classification, topic modeling,\nevent extraction, and text scaling. We then overview how these methods can be\nused for policymaking through four major applications including data collection\nfor evidence-based policymaking, interpretation of political decisions, policy\ncommunication, and investigation of policy effects. Finally, we highlight some\npotential limitations and ethical concerns when using NLP for policymaking.\n  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational\nSocial Science for Policy (2023). Open Access on Springer:\nhttps://doi.org/10.1007/978-3-031-16624-2\n",
                "链接": "https://arxiv.org/abs/2302.03490"
            },
            {
                "文章ID": "121029",
                "标题": "PyThaiNLP: Thai Natural Language Processing in Python",
                "作者": " Wannaphong Phatthiyaphaibun,  Korakot Chaovavanich,  Charin Polpanumas,  Arthit Suriyawongkul,  Lalita Lowphansirikul,  Pattarawat Chormai,  Peerat Limkonchotiwat,  Thanathip Suntorntip,  Can Udomcharoenchaikit",
                "发布日期": "2023-12-11",
                "摘要": "  We present PyThaiNLP, a free and open-source natural language processing\n(NLP) library for Thai language implemented in Python. It provides a wide range\nof software, models, and datasets for Thai language. We first provide a brief\nhistorical context of tools for Thai language prior to the development of\nPyThaiNLP. We then outline the functionalities it provided as well as datasets\nand pre-trained language models. We later summarize its development milestones\nand discuss our experience during its development. We conclude by demonstrating\nhow industrial and research communities utilize PyThaiNLP in their work. The\nlibrary is freely available at https://github.com/pythainlp/pythainlp.\n",
                "链接": "https://arxiv.org/abs/2312.04649"
            },
            {
                "文章ID": "68255",
                "标题": "Features matching using natural language processing",
                "作者": " Muhammad Danial Khilji",
                "发布日期": "2023-03-24",
                "摘要": "  The feature matching is a basic step in matching different datasets. This\narticle proposes shows a new hybrid model of a pretrained Natural Language\nProcessing (NLP) based model called BERT used in parallel with a statistical\nmodel based on Jaccard similarity to measure the similarity between list of\nfeatures from two different datasets. This reduces the time required to search\nfor correlations or manually match each feature from one dataset to another.\n",
                "链接": "https://arxiv.org/abs/2303.12804"
            },
            {
                "文章ID": "113818",
                "标题": "mahaNLP: A Marathi Natural Language Processing Library",
                "作者": " Vidula Magdum,  Omkar Dhekane,  Sharayu Hiwarkhedkar,  Saloni Mittal,  Raviraj Joshi",
                "发布日期": "2023-11-07",
                "摘要": "  We present mahaNLP, an open-source natural language processing (NLP) library\nspecifically built for the Marathi language. It aims to enhance the support for\nthe low-resource Indian language Marathi in the field of NLP. It is an\neasy-to-use, extensible, and modular toolkit for Marathi text analysis built on\nstate-of-the-art MahaBERT-based transformer models. Our work holds significant\nimportance as other existing Indic NLP libraries provide basic Marathi\nprocessing support and rely on older models with restricted performance. Our\ntoolkit stands out by offering a comprehensive array of NLP tasks, encompassing\nboth fundamental preprocessing tasks and advanced NLP tasks like sentiment\nanalysis, NER, hate speech detection, and sentence completion. This paper\nfocuses on an overview of the mahaNLP framework, its features, and its usage.\nThis work is a part of the L3Cube MahaNLP initiative, more information about it\ncan be found at https://github.com/l3cube-pune/MarathiNLP .\n",
                "链接": "https://arxiv.org/abs/2311.02579"
            },
            {
                "文章ID": "112711",
                "标题": "Partial Tensorized Transformers for Natural Language Processing",
                "作者": " Subhadra Vadlamannati,  Ryan Solgi",
                "发布日期": "2023-11-01",
                "摘要": "  The transformer architecture has revolutionized Natural Language Processing\n(NLP) and other machine-learning tasks, due to its unprecedented accuracy.\nHowever, their extensive memory and parameter requirements often hinder their\npractical applications. In this work, we study the effect of tensor-train\ndecomposition to improve the accuracy and compress transformer vision-language\nneural networks, namely BERT and ViT. We focus both on embedding-layer\ncompression and partial tensorization of neural networks (PTNN) through an\nalgorithmic approach. Our novel PTNN approach significantly improves the\naccuracy of existing models by up to 5%, all without the need for post-training\nadjustments, breaking new ground in the field of tensor decomposition.\n",
                "链接": "https://arxiv.org/abs/2310.20077"
            }
        ]
    },
    {
        "question": {
            "question": "查找多语言情感分析的最新论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "85580",
                "标题": "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted\n  Sentiment Classification Benchmark",
                "作者": " Łukasz Augustyniak,  Szymon Woźniak,  Marcin Gruza,  Piotr Gramacki,  Krzysztof Rajda,  Mikołaj Morzy,  Tomasz Kajdanowicz",
                "发布日期": "2023-06-14",
                "摘要": "  Despite impressive advancements in multilingual corpora collection and model\ntraining, developing large-scale deployments of multilingual models still\npresents a significant challenge. This is particularly true for language tasks\nthat are culture-dependent. One such example is the area of multilingual\nsentiment analysis, where affective markers can be subtle and deeply ensconced\nin culture. This work presents the most extensive open massively multilingual\ncorpus of datasets for training sentiment models. The corpus consists of 79\nmanually selected datasets from over 350 datasets reported in the scientific\nliterature based on strict quality criteria. The corpus covers 27 languages\nrepresenting 6 language families. Datasets can be queried using several\nlinguistic and functional features. In addition, we present a multi-faceted\nsentiment classification benchmark summarizing hundreds of experiments\nconducted on different base models, training objectives, dataset collections,\nand fine-tuning strategies.\n",
                "链接": "https://arxiv.org/abs/2306.07902"
            },
            {
                "文章ID": "82977",
                "标题": "UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of\n  Multilingual BERT for Low-resource Sentiment Analysis",
                "作者": " Dou Hu,  Lingwei Wei,  Yaxin Liu,  Wei Zhou,  Songlin Hu",
                "发布日期": "2023-06-05",
                "摘要": "  This paper describes our system designed for SemEval-2023 Task 12: Sentiment\nanalysis for African languages. The challenge faced by this task is the\nscarcity of labeled data and linguistic resources in low-resource settings. To\nalleviate these, we propose a generalized multilingual system SACL-XLMR for\nsentiment analysis on low-resource languages. Specifically, we design a\nlexicon-based multilingual BERT to facilitate language adaptation and\nsentiment-aware representation learning. Besides, we apply a supervised\nadversarial contrastive learning technique to learn sentiment-spread structured\nrepresentations and enhance model generalization. Our system achieved\ncompetitive results, largely outperforming baselines on both multilingual and\nzero-shot sentiment classification subtasks. Notably, the system obtained the\n1st rank on the zero-shot classification subtask in the official ranking.\nExtensive experiments demonstrate the effectiveness of our system.\n",
                "链接": "https://arxiv.org/abs/2306.01093"
            },
            {
                "文章ID": "14369",
                "标题": "Assessment of Massively Multilingual Sentiment Classifiers",
                "作者": " Krzysztof Rajda,  Łukasz Augustyniak,  Piotr Gramacki,  Marcin Gruza,  Szymon Woźniak,  Tomasz Kajdanowicz",
                "发布日期": "2022-04-12",
                "摘要": "  Models are increasing in size and complexity in the hunt for SOTA. But what\nif those 2\\% increase in performance does not make a difference in a production\nuse case? Maybe benefits from a smaller, faster model outweigh those slight\nperformance gains. Also, equally good performance across languages in\nmultilingual tasks is more important than SOTA results on a single one. We\npresent the biggest, unified, multilingual collection of sentiment analysis\ndatasets. We use these to assess 11 models and 80 high-quality sentiment\ndatasets (out of 342 raw datasets collected) in 27 languages and included\nresults on the internally annotated datasets. We deeply evaluate multiple\nsetups, including fine-tuning transformer-based models for measuring\nperformance. We compare results in numerous dimensions addressing the imbalance\nin both languages coverage and dataset sizes. Finally, we present some best\npractices for working with such a massive collection of datasets and models\nfrom a multilingual perspective.\n",
                "链接": "https://arxiv.org/abs/2204.04937"
            },
            {
                "文章ID": "2025",
                "标题": "NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual\n  Sentiment Analysis",
                "作者": " Shamsuddeen Hassan Muhammad,  David Ifeoluwa Adelani,  Sebastian Ruder,  Ibrahim Said Ahmad,  Idris Abdulmumin,  Bello Shehu Bello,  Monojit Choudhury,  Chris Chinenye Emezue,  Saheed Salahudeen Abdullahi,  Anuoluwapo Aremu,  Alipio Jeorge,  Pavel Brazdil",
                "发布日期": "2022-06-22",
                "摘要": "  Sentiment analysis is one of the most widely studied applications in NLP, but\nmost work focuses on languages with large amounts of data. We introduce the\nfirst large-scale human-annotated Twitter sentiment dataset for the four most\nwidely spoken languages in Nigeria (Hausa, Igbo, Nigerian-Pidgin, and\nYor\\`ub\\'a ) consisting of around 30,000 annotated tweets per language (and\n14,000 for Nigerian-Pidgin), including a significant fraction of code-mixed\ntweets. We propose text collection, filtering, processing and labeling methods\nthat enable us to create datasets for these low-resource languages. We evaluate\na rangeof pre-trained models and transfer strategies on the dataset. We find\nthat language-specific models and language-adaptivefine-tuning generally\nperform best. We release the datasets, trained models, sentiment lexicons, and\ncode to incentivizeresearch on sentiment analysis in under-represented\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2201.08277"
            },
            {
                "文章ID": "74935",
                "标题": "NLNDE at SemEval-2023 Task 12: Adaptive Pretraining and Source Language\n  Selection for Low-Resource Multilingual Sentiment Analysis",
                "作者": " Mingyang Wang,  Heike Adel,  Lukas Lange,  Jannik Strötgen,  Hinrich Schütze",
                "发布日期": "2023-05-02",
                "摘要": "  This paper describes our system developed for the SemEval-2023 Task 12\n\"Sentiment Analysis for Low-resource African Languages using Twitter Dataset\".\nSentiment analysis is one of the most widely studied applications in natural\nlanguage processing. However, most prior work still focuses on a small number\nof high-resource languages. Building reliable sentiment analysis systems for\nlow-resource languages remains challenging, due to the limited training data in\nthis task. In this work, we propose to leverage language-adaptive and\ntask-adaptive pretraining on African texts and study transfer learning with\nsource language selection on top of an African language-centric pretrained\nlanguage model. Our key findings are: (1) Adapting the pretrained model to the\ntarget language and task using a small yet relevant corpus improves performance\nremarkably by more than 10 F1 score points. (2) Selecting source languages with\npositive transfer gains during training can avoid harmful interference from\ndissimilar languages, leading to better results in multilingual and\ncross-lingual settings. In the shared task, our system wins 8 out of 15 tracks\nand, in particular, performs best in the multilingual evaluation.\n",
                "链接": "https://arxiv.org/abs/2305.00090"
            },
            {
                "文章ID": "121053",
                "标题": "Deep Emotions Across Languages: A Novel Approach for Sentiment\n  Propagation in Multilingual WordNets",
                "作者": " Jan Kocoń",
                "发布日期": "2023-12-11",
                "摘要": "  Sentiment analysis involves using WordNets enriched with emotional metadata,\nwhich are valuable resources. However, manual annotation is time-consuming and\nexpensive, resulting in only a few WordNet Lexical Units being annotated. This\npaper introduces two new techniques for automatically propagating sentiment\nannotations from a partially annotated WordNet to its entirety and to a WordNet\nin a different language: Multilingual Structured Synset Embeddings (MSSE) and\nCross-Lingual Deep Neural Sentiment Propagation (CLDNS). We evaluated the\nproposed MSSE+CLDNS method extensively using Princeton WordNet and Polish\nWordNet, which have many inter-lingual relations. Our results show that the\nMSSE+CLDNS method outperforms existing propagation methods, indicating its\neffectiveness in enriching WordNets with emotional metadata across multiple\nlanguages. This work provides a solid foundation for large-scale, multilingual\nsentiment analysis and is valuable for academic research and practical\napplications.\n",
                "链接": "https://arxiv.org/abs/2312.04715"
            },
            {
                "文章ID": "59246",
                "标题": "Automated Sentiment and Hate Speech Analysis of Facebook Data by\n  Employing Multilingual Transformer Models",
                "作者": " Ritumbra Manuvie,  Saikat Chatterjee",
                "发布日期": "2023-02-01",
                "摘要": "  In recent years, there has been a heightened consensus within academia and in\nthe public discourse that Social Media Platforms (SMPs), amplify the spread of\nhateful and negative sentiment content. Researchers have identified how hateful\ncontent, political propaganda, and targeted messaging contributed to real-world\nharms including insurrections against democratically elected governments,\ngenocide, and breakdown of social cohesion due to heightened negative discourse\ntowards certain communities in parts of the world. To counter these issues,\nSMPs have created semi-automated systems that can help identify toxic speech.\nIn this paper we analyse the statistical distribution of hateful and negative\nsentiment contents within a representative Facebook dataset (n= 604,703)\nscrapped through 648 public Facebook pages which identify themselves as\nproponents (and followers) of far-right Hindutva actors. These pages were\nidentified manually using keyword searches on Facebook and on CrowdTangleand\nclassified as far-right Hindutva pages based on page names, page descriptions,\nand discourses shared on these pages. We employ state-of-the-art, open-source\nXLM-T multilingual transformer-based language models to perform sentiment and\nhate speech analysis of the textual contents shared on these pages over a\nperiod of 5.5 years. The result shows the statistical distributions of the\npredicted sentiment and the hate speech labels; top actors, and top page\ncategories. We further discuss the benchmark performances and limitations of\nthese pre-trained language models.\n",
                "链接": "https://arxiv.org/abs/2301.13668"
            },
            {
                "文章ID": "52169",
                "标题": "Video Games as a Corpus: Sentiment Analysis using Fallout New Vegas\n  Dialog",
                "作者": " Mika Hämäläinen,  Khalid Alnajjar,  Thierry Poibeau",
                "发布日期": "2022-12-06",
                "摘要": "  We present a method for extracting a multilingual sentiment annotated dialog\ndata set from Fallout New Vegas. The game developers have preannotated every\nline of dialog in the game in one of the 8 different sentiments: \\textit{anger,\ndisgust, fear, happy, neutral, pained, sad } and \\textit{surprised}. The game\nhas been translated into English, Spanish, German, French and Italian. We\nconduct experiments on multilingual, multilabel sentiment analysis on the\nextracted data set using multilingual BERT, XLMRoBERTa and language specific\nBERT models. In our experiments, multilingual BERT outperformed XLMRoBERTa for\nmost of the languages, also language specific models were slightly better than\nmultilingual BERT for most of the languages. The best overall accuracy was 54\\%\nand it was achieved by using multilingual BERT on Spanish data. The extracted\ndata set presents a challenging task for sentiment analysis. We have released\nthe data, including the testing and training splits, openly on Zenodo. The data\nset has been shuffled for copyright reasons.\n",
                "链接": "https://arxiv.org/abs/2212.02168"
            },
            {
                "文章ID": "110460",
                "标题": "Sentiment Analysis Across Multiple African Languages: A Current\n  Benchmark",
                "作者": " Saurav K. Aryal,  Howard Prioleau,  Surakshya Aryal",
                "发布日期": "2023-10-24",
                "摘要": "  Sentiment analysis is a fundamental and valuable task in NLP. However, due to\nlimitations in data and technological availability, research into sentiment\nanalysis of African languages has been fragmented and lacking. With the recent\nrelease of the AfriSenti-SemEval Shared Task 12, hosted as a part of The 17th\nInternational Workshop on Semantic Evaluation, an annotated sentiment analysis\nof 14 African languages was made available. We benchmarked and compared current\nstate-of-art transformer models across 12 languages and compared the\nperformance of training one-model-per-language versus\nsingle-model-all-languages. We also evaluated the performance of standard\nmultilingual models and their ability to learn and transfer cross-lingual\nrepresentation from non-African to African languages. Our results show that\ndespite work in low resource modeling, more data still produces better models\non a per-language basis. Models explicitly developed for African languages\noutperform other models on all tasks. Additionally, no one-model-fits-all\nsolution exists for a per-language evaluation of the models evaluated.\nMoreover, for some languages with a smaller sample size, a larger multilingual\nmodel may perform better than a dedicated per-language model for sentiment\nclassification.\n",
                "链接": "https://arxiv.org/abs/2310.14120"
            },
            {
                "文章ID": "45781",
                "标题": "Sentiment Classification of Code-Switched Text using Pre-trained\n  Multilingual Embeddings and Segmentation",
                "作者": " Saurav K. Aryal,  Howard Prioleau,  Gloria Washington",
                "发布日期": "2022-11-01",
                "摘要": "  With increasing globalization and immigration, various studies have estimated\nthat about half of the world population is bilingual. Consequently, individuals\nconcurrently use two or more languages or dialects in casual conversational\nsettings. However, most research is natural language processing is focused on\nmonolingual text. To further the work in code-switched sentiment analysis, we\npropose a multi-step natural language processing algorithm utilizing points of\ncode-switching in mixed text and conduct sentiment analysis around those\nidentified points. The proposed sentiment analysis algorithm uses semantic\nsimilarity derived from large pre-trained multilingual models with a\nhandcrafted set of positive and negative words to determine the polarity of\ncode-switched text. The proposed approach outperforms a comparable baseline\nmodel by 11.2% for accuracy and 11.64% for F1-score on a Spanish-English\ndataset. Theoretically, the proposed algorithm can be expanded for sentiment\nanalysis of multiple languages with limited human expertise.\n",
                "链接": "https://arxiv.org/abs/2210.16461"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于NLP领域的持续性学习论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "110535",
                "标题": "The Law and NLP: Bridging Disciplinary Disconnects",
                "作者": " Robert Mahari,  Dominik Stammbach,  Elliott Ash,  Alex 'Sandy' Pentland",
                "发布日期": "2023-10-24",
                "摘要": "  Legal practice is intrinsically rooted in the fabric of language, yet legal\npractitioners and scholars have been slow to adopt tools from natural language\nprocessing (NLP). At the same time, the legal system is experiencing an access\nto justice crisis, which could be partially alleviated with NLP. In this\nposition paper, we argue that the slow uptake of NLP in legal practice is\nexacerbated by a disconnect between the needs of the legal community and the\nfocus of NLP researchers. In a review of recent trends in the legal NLP\nliterature, we find limited overlap between the legal NLP community and legal\nacademia. Our interpretation is that some of the most popular legal NLP tasks\nfail to address the needs of legal practitioners. We discuss examples of legal\nNLP tasks that promise to bridge disciplinary disconnects and highlight\ninteresting areas for legal NLP research that remain underexplored.\n",
                "链接": "https://arxiv.org/abs/2310.14346"
            },
            {
                "文章ID": "115688",
                "标题": "A Material Lens on Coloniality in NLP",
                "作者": " William Held,  Camille Harris,  Michael Best,  Diyi Yang",
                "发布日期": "2023-11-15",
                "摘要": "  Coloniality, the continuation of colonial harms beyond \"official\"\ncolonization, has pervasive effects across society and scientific fields.\nNatural Language Processing (NLP) is no exception to this broad phenomenon. In\nthis work, we argue that coloniality is implicitly embedded in and amplified by\nNLP data, algorithms, and software. We formalize this analysis using\nActor-Network Theory (ANT): an approach to understanding social phenomena\nthrough the network of relationships between human stakeholders and technology.\nWe use our Actor-Network to guide a quantitative survey of the geography of\ndifferent phases of NLP research, providing evidence that inequality along\ncolonial boundaries increases as NLP builds on itself. Based on this, we argue\nthat combating coloniality in NLP requires not only changing current values but\nalso active work to remove the accumulation of colonial ideals in our\nfoundational data and algorithms.\n",
                "链接": "https://arxiv.org/abs/2311.08391"
            },
            {
                "文章ID": "70948",
                "标题": "Sejarah dan Perkembangan Teknik Natural Language Processing (NLP) Bahasa\n  Indonesia: Tinjauan tentang sejarah, perkembangan teknologi, dan aplikasi NLP\n  dalam bahasa Indonesia",
                "作者": " Mukhlis Amien",
                "发布日期": "2023-04-07",
                "摘要": "  This study provides an overview of the history of the development of Natural\nLanguage Processing (NLP) in the context of the Indonesian language, with a\nfocus on the basic technologies, methods, and practical applications that have\nbeen developed. This review covers developments in basic NLP technologies such\nas stemming, part-of-speech tagging, and related methods; practical\napplications in cross-language information retrieval systems, information\nextraction, and sentiment analysis; and methods and techniques used in\nIndonesian language NLP research, such as machine learning, statistics-based\nmachine translation, and conflict-based approaches. This study also explores\nthe application of NLP in Indonesian language industry and research and\nidentifies challenges and opportunities in Indonesian language NLP research and\ndevelopment. Recommendations for future Indonesian language NLP research and\ndevelopment include developing more efficient methods and technologies,\nexpanding NLP applications, increasing sustainability, further research into\nthe potential of NLP, and promoting interdisciplinary collaboration. It is\nhoped that this review will help researchers, practitioners, and the government\nto understand the development of Indonesian language NLP and identify\nopportunities for further research and development.\n",
                "链接": "https://arxiv.org/abs/2304.02746"
            },
            {
                "文章ID": "112899",
                "标题": "Defining a New NLP Playground",
                "作者": " Sha Li,  Chi Han,  Pengfei Yu,  Carl Edwards,  Manling Li,  Xingyao Wang,  Yi R. Fung,  Charles Yu,  Joel R. Tetreault,  Eduard H. Hovy,  Heng Ji",
                "发布日期": "2023-11-01",
                "摘要": "  The recent explosion of performance of large language models (LLMs) has\nchanged the field of Natural Language Processing (NLP) more abruptly and\nseismically than any other shift in the field's 80-year history. This has\nresulted in concerns that the field will become homogenized and\nresource-intensive. The new status quo has put many academic researchers,\nespecially PhD students, at a disadvantage. This paper aims to define a new NLP\nplayground by proposing 20+ PhD-dissertation-worthy research directions,\ncovering theoretical analysis, new and challenging problems, learning\nparadigms, and interdisciplinary applications.\n",
                "链接": "https://arxiv.org/abs/2310.20633"
            },
            {
                "文章ID": "61160",
                "标题": "Synthesizing Human Gaze Feedback for Improved NLP Performance",
                "作者": " Varun Khurana,  Yaman Kumar Singla,  Nora Hollenstein,  Rajesh Kumar,  Balaji Krishnamurthy",
                "发布日期": "2023-02-14",
                "摘要": "  Integrating human feedback in models can improve the performance of natural\nlanguage processing (NLP) models. Feedback can be either explicit (e.g. ranking\nused in training language models) or implicit (e.g. using human cognitive\nsignals in the form of eyetracking). Prior eye tracking and NLP research reveal\nthat cognitive processes, such as human scanpaths, gleaned from human gaze\npatterns aid in the understanding and performance of NLP models. However, the\ncollection of real eyetracking data for NLP tasks is challenging due to the\nrequirement of expensive and precise equipment coupled with privacy invasion\nissues. To address this challenge, we propose ScanTextGAN, a novel model for\ngenerating human scanpaths over text. We show that ScanTextGAN-generated\nscanpaths can approximate meaningful cognitive signals in human gaze patterns.\nWe include synthetically generated scanpaths in four popular NLP tasks spanning\nsix different datasets as proof of concept and show that the models augmented\nwith generated scanpaths improve the performance of all downstream NLP tasks.\n",
                "链接": "https://arxiv.org/abs/2302.05721"
            },
            {
                "文章ID": "57807",
                "标题": "Rationalization for Explainable NLP: A Survey",
                "作者": " Sai Gurrapu,  Ajay Kulkarni,  Lifu Huang,  Ismini Lourentzou,  Laura Freeman,  Feras A. Batarseh",
                "发布日期": "2023-11-14",
                "摘要": "  Recent advances in deep learning have improved the performance of many\nNatural Language Processing (NLP) tasks such as translation,\nquestion-answering, and text classification. However, this improvement comes at\nthe expense of model explainability. Black-box models make it difficult to\nunderstand the internals of a system and the process it takes to arrive at an\noutput. Numerical (LIME, Shapley) and visualization (saliency heatmap)\nexplainability techniques are helpful; however, they are insufficient because\nthey require specialized knowledge. These factors led rationalization to emerge\nas a more accessible explainable technique in NLP. Rationalization justifies a\nmodel's output by providing a natural language explanation (rationale). Recent\nimprovements in natural language generation have made rationalization an\nattractive technique because it is intuitive, human-comprehensible, and\naccessible to non-technical users. Since rationalization is a relatively new\nfield, it is disorganized. As the first survey, rationalization literature in\nNLP from 2007-2022 is analyzed. This survey presents available methods,\nexplainable evaluations, code, and datasets used across various NLP tasks that\nuse rationalization. Further, a new subfield in Explainable AI (XAI), namely,\nRational AI (RAI), is introduced to advance the current state of\nrationalization. A discussion on observed insights, challenges, and future\ndirections is provided to point to promising research opportunities.\n",
                "链接": "https://arxiv.org/abs/2301.08912"
            },
            {
                "文章ID": "62616",
                "标题": "Time to Embrace Natural Language Processing (NLP)-based Digital\n  Pathology: Benchmarking NLP- and Convolutional Neural Network-based Deep\n  Learning Pipelines",
                "作者": " Min Cen,  Xingyu Li,  Bangwei Guo,  Jitendra Jonnagaddala,  Hong Zhang,  Xu Steven Xu",
                "发布日期": "2023-02-22",
                "摘要": "  NLP-based computer vision models, particularly vision transformers, have been\nshown to outperform CNN models in many imaging tasks. However, most digital\npathology artificial-intelligence models are based on CNN architectures,\nprobably owing to a lack of data regarding NLP models for pathology images. In\nthis study, we developed digital pathology pipelines to benchmark the five most\nrecently proposed NLP models (vision transformer (ViT), Swin Transformer,\nMobileViT, CMT, and Sequencer2D) and four popular CNN models (ResNet18,\nResNet50, MobileNetV2, and EfficientNet) to predict biomarkers in colorectal\ncancer (microsatellite instability, CpG island methylator phenotype, and BRAF\nmutation). Hematoxylin and eosin-stained whole-slide images from Molecular and\nCellular Oncology and The Cancer Genome Atlas were used as training and\nexternal validation datasets, respectively. Cross-study external validations\nrevealed that the NLP-based models significantly outperformed the CNN-based\nmodels in biomarker prediction tasks, improving the overall prediction and\nprecision up to approximately 10% and 26%, respectively. Notably, compared with\nexisting models in the current literature using large training datasets, our\nNLP models achieved state-of-the-art predictions for all three biomarkers using\na relatively small training dataset, suggesting that large training datasets\nare not a prerequisite for NLP models or transformers, and NLP may be more\nsuitable for clinical studies in which small training datasets are commonly\ncollected. The superior performance of Sequencer2D suggests that further\nresearch and innovation on both transformer and bidirectional long short-term\nmemory architectures are warranted in the field of digital pathology. NLP\nmodels can replace classic CNN architectures and become the new workhorse\nbackbone in the field of digital pathology.\n",
                "链接": "https://arxiv.org/abs/2302.10406"
            },
            {
                "文章ID": "112732",
                "标题": "Ling-CL: Understanding NLP Models through Linguistic Curricula",
                "作者": " Mohamed Elgaar,  Hadi Amiri",
                "发布日期": "2023-11-01",
                "摘要": "  We employ a characterization of linguistic complexity from psycholinguistic\nand language acquisition research to develop data-driven curricula to\nunderstand the underlying linguistic knowledge that models learn to address NLP\ntasks. The novelty of our approach is in the development of linguistic\ncurricula derived from data, existing knowledge about linguistic complexity,\nand model behavior during training. By analyzing several benchmark NLP\ndatasets, our curriculum learning approaches identify sets of linguistic\nmetrics (indices) that inform the challenges and reasoning required to address\neach task. Our work will inform future research in all NLP areas, allowing\nlinguistic complexity to be considered early in the research and development\nprocess. In addition, our work prompts an examination of gold standards and\nfair evaluation in NLP.\n",
                "链接": "https://arxiv.org/abs/2310.20121"
            },
            {
                "文章ID": "81025",
                "标题": "NLP Reproducibility For All: Understanding Experiences of Beginners",
                "作者": " Shane Storks,  Keunwoo Peter Yu,  Ziqiao Ma,  Joyce Chai",
                "发布日期": "2023-06-06",
                "摘要": "  As natural language processing (NLP) has recently seen an unprecedented level\nof excitement, and more people are eager to enter the field, it is unclear\nwhether current research reproducibility efforts are sufficient for this group\nof beginners to apply the latest developments. To understand their needs, we\nconducted a study with 93 students in an introductory NLP course, where\nstudents reproduced the results of recent NLP papers. Surprisingly, we find\nthat their programming skill and comprehension of research papers have a\nlimited impact on their effort spent completing the exercise. Instead, we find\naccessibility efforts by research authors to be the key to success, including\ncomplete documentation, better coding practice, and easier access to data\nfiles. Going forward, we recommend that NLP researchers pay close attention to\nthese simple aspects of open-sourcing their work, and use insights from\nbeginners' feedback to provide actionable ideas on how to better support them.\n",
                "链接": "https://arxiv.org/abs/2305.16579"
            },
            {
                "文章ID": "108574",
                "标题": "PerturbScore: Connecting Discrete and Continuous Perturbations in NLP",
                "作者": " Linyang Li,  Ke Ren,  Yunfan Shao,  Pengyu Wang,  Xipeng Qiu",
                "发布日期": "2023-10-16",
                "摘要": "  With the rapid development of neural network applications in NLP, model\nrobustness problem is gaining more attention. Different from computer vision,\nthe discrete nature of texts makes it more challenging to explore robustness in\nNLP. Therefore, in this paper, we aim to connect discrete perturbations with\ncontinuous perturbations, therefore we can use such connections as a bridge to\nhelp understand discrete perturbations in NLP models. Specifically, we first\nexplore how to connect and measure the correlation between discrete\nperturbations and continuous perturbations. Then we design a regression task as\na PerturbScore to learn the correlation automatically. Through experimental\nresults, we find that we can build a connection between discrete and continuous\nperturbations and use the proposed PerturbScore to learn such correlation,\nsurpassing previous methods used in discrete perturbation measuring. Further,\nthe proposed PerturbScore can be well generalized to different datasets,\nperturbation methods, indicating that we can use it as a powerful tool to study\nmodel robustness in NLP.\n",
                "链接": "https://arxiv.org/abs/2310.08889"
            }
        ]
    },
    {
        "question": {
            "question": "找一下最近关于大模型评测的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "7277",
                "标题": "A Systematic Evaluation of Large Language Models of Code",
                "作者": " Frank F. Xu,  Uri Alon,  Graham Neubig,  Vincent J. Hellendoorn",
                "发布日期": "2022-05-05",
                "摘要": "  Large language models (LMs) of code have recently shown tremendous promise in\ncompleting code and synthesizing code from natural language descriptions.\nHowever, the current state-of-the-art code LMs (e.g., Codex (Chen et al.,\n2021)) are not publicly available, leaving many questions about their model and\ndata design decisions. We aim to fill in some of these blanks through a\nsystematic evaluation of the largest existing models: Codex, GPT-J, GPT-Neo,\nGPT-NeoX-20B, and CodeParrot, across various programming languages. Although\nCodex itself is not open-source, we find that existing open-source models do\nachieve close results in some programming languages, although targeted mainly\nfor natural language modeling. We further identify an important missing piece\nin the form of a large open-source model trained exclusively on a multi-lingual\ncorpus of code. We release a new model, PolyCoder, with 2.7B parameters based\non the GPT-2 architecture, which was trained on 249GB of code across 12\nprogramming languages on a single machine. In the C programming language,\nPolyCoder outperforms all models including Codex. Our trained models are\nopen-source and publicly available at https://github.com/VHellendoorn/Code-LMs,\nwhich enables future research and application in this area.\n",
                "链接": "https://arxiv.org/abs/2202.13169"
            },
            {
                "文章ID": "44085",
                "标题": "SLING: Sino Linguistic Evaluation of Large Language Models",
                "作者": " Yixiao Song,  Kalpesh Krishna,  Rajesh Bhatt,  Mohit Iyyer",
                "发布日期": "2022-10-24",
                "摘要": "  To understand what kinds of linguistic knowledge are encoded by pretrained\nChinese language models (LMs), we introduce the benchmark of Sino LINGuistics\n(SLING), which consists of 38K minimal sentence pairs in Mandarin Chinese\ngrouped into 9 high-level linguistic phenomena. Each pair demonstrates the\nacceptability contrast of a specific syntactic or semantic phenomenon (e.g.,\nThe keys are lost vs. The keys is lost), and an LM should assign lower\nperplexity to the acceptable sentence. In contrast to the CLiMP dataset (Xiang\net al., 2021), which also contains Chinese minimal pairs and was created by\ntranslating the vocabulary of the English BLiMP dataset, the minimal pairs in\nSLING are derived primarily by applying syntactic and lexical transformations\nto naturally-occurring, linguist-annotated sentences from the Chinese Treebank\n9.0, thus addressing severe issues in CLiMP's data generation process. We test\n18 publicly available pretrained monolingual (e.g., BERT-base-zh, CPM) and\nmulti-lingual (e.g., mT5, XLM) language models on SLING. Our experiments show\nthat the average accuracy for LMs is far below human performance (69.7% vs.\n97.1%), while BERT-base-zh achieves the highest accuracy (84.8%) of all tested\nLMs, even much larger ones. Additionally, we find that most LMs have a strong\ngender and number (singular/plural) bias, and they perform better on local\nphenomena than hierarchical ones.\n",
                "链接": "https://arxiv.org/abs/2210.11689"
            },
            {
                "文章ID": "76868",
                "标题": "Automatic Evaluation of Attribution by Large Language Models",
                "作者": " Xiang Yue,  Boshi Wang,  Ziru Chen,  Kai Zhang,  Yu Su,  Huan Sun",
                "发布日期": "2023-10-10",
                "摘要": "  A recent focus of large language model (LLM) development, as exemplified by\ngenerative search engines, is to incorporate external references to generate\nand support its claims. However, evaluating the attribution, i.e., verifying\nwhether the generated statement is fully supported by the cited reference,\nremains an open problem. Although human evaluation is common practice, it is\ncostly and time-consuming. In this paper, we investigate the automatic\nevaluation of attribution given by LLMs. We begin by defining different types\nof attribution errors, and then explore two approaches for automatic\nevaluation: prompting LLMs and fine-tuning smaller LMs. The fine-tuning data is\nrepurposed from related tasks such as question answering, fact-checking,\nnatural language inference, and summarization. We manually curate a set of test\nexamples covering 12 domains from a generative search engine, New Bing. Our\nresults on this curated test set and simulated examples from existing\nbenchmarks highlight both promising signals and challenges. We hope our problem\nformulation, testbeds, and findings will help lay the foundation for future\nstudies on this important problem.\n",
                "链接": "https://arxiv.org/abs/2305.06311"
            },
            {
                "文章ID": "89744",
                "标题": "A Survey on Evaluation of Large Language Models",
                "作者": " Yupeng Chang,  Xu Wang,  Jindong Wang,  Yuan Wu,  Linyi Yang,  Kaijie Zhu,  Hao Chen,  Xiaoyuan Yi,  Cunxiang Wang,  Yidong Wang,  Wei Ye,  Yue Zhang,  Yi Chang,  Philip S. Yu,  Qiang Yang,  Xing Xie",
                "发布日期": "2023-10-18",
                "摘要": "  Large language models (LLMs) are gaining increasing popularity in both\nacademia and industry, owing to their unprecedented performance in various\napplications. As LLMs continue to play a vital role in both research and daily\nuse, their evaluation becomes increasingly critical, not only at the task\nlevel, but also at the society level for better understanding of their\npotential risks. Over the past years, significant efforts have been made to\nexamine LLMs from various perspectives. This paper presents a comprehensive\nreview of these evaluation methods for LLMs, focusing on three key dimensions:\nwhat to evaluate, where to evaluate, and how to evaluate. Firstly, we provide\nan overview from the perspective of evaluation tasks, encompassing general\nnatural language processing tasks, reasoning, medical usage, ethics,\neducations, natural and social sciences, agent applications, and other areas.\nSecondly, we answer the `where' and `how' questions by diving into the\nevaluation methods and benchmarks, which serve as crucial components in\nassessing performance of LLMs. Then, we summarize the success and failure cases\nof LLMs in different tasks. Finally, we shed light on several future challenges\nthat lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to\nresearchers in the realm of LLMs evaluation, thereby aiding the development of\nmore proficient LLMs. Our key point is that evaluation should be treated as an\nessential discipline to better assist the development of LLMs. We consistently\nmaintain the related open-source materials at:\nhttps://github.com/MLGroupJLU/LLM-eval-survey.\n",
                "链接": "https://arxiv.org/abs/2307.03109"
            },
            {
                "文章ID": "105548",
                "标题": "FELM: Benchmarking Factuality Evaluation of Large Language Models",
                "作者": " Shiqi Chen,  Yiran Zhao,  Jinghan Zhang,  I-Chun Chern,  Siyang Gao,  Pengfei Liu,  Junxian He",
                "发布日期": "2023-11-29",
                "摘要": "  Assessing factuality of text generated by large language models (LLMs) is an\nemerging yet crucial research area, aimed at alerting users to potential errors\nand guiding the development of more reliable LLMs. Nonetheless, the evaluators\nassessing factuality necessitate suitable evaluation themselves to gauge\nprogress and foster advancements. This direction remains under-explored,\nresulting in substantial impediments to the progress of factuality evaluators.\nTo mitigate this issue, we introduce a benchmark for Factuality Evaluation of\nlarge Language Models, referred to as felm. In this benchmark, we collect\nresponses generated from LLMs and annotate factuality labels in a fine-grained\nmanner. Contrary to previous studies that primarily concentrate on the\nfactuality of world knowledge (e.g.~information from Wikipedia), felm focuses\non factuality across diverse domains, spanning from world knowledge to math and\nreasoning. Our annotation is based on text segments, which can help pinpoint\nspecific factual errors. The factuality annotations are further supplemented by\npredefined error types and reference links that either support or contradict\nthe statement. In our experiments, we investigate the performance of several\nLLM-based factuality evaluators on felm, including both vanilla LLMs and those\naugmented with retrieval mechanisms and chain-of-thought processes. Our\nfindings reveal that while retrieval aids factuality evaluation, current LLMs\nare far from satisfactory to faithfully detect factual errors.\n",
                "链接": "https://arxiv.org/abs/2310.00741"
            },
            {
                "文章ID": "105164",
                "标题": "DyVal: Graph-informed Dynamic Evaluation of Large Language Models",
                "作者": " Kaijie Zhu,  Jiaao Chen,  Jindong Wang,  Neil Zhenqiang Gong,  Diyi Yang,  Xing Xie",
                "发布日期": "2023-10-06",
                "摘要": "  Large language models (LLMs) have achieved remarkable performance in various\nevaluation benchmarks. However, concerns about their performance are raised on\npotential data contamination in their considerable volume of training corpus.\nMoreover, the static nature and fixed complexity of current benchmarks may\ninadequately gauge the advancing capabilities of LLMs. In this paper, we\nintroduce DyVal, a novel, general, and flexible evaluation protocol for dynamic\nevaluation of LLMs. Based on our proposed dynamic evaluation framework, we\nbuild graph-informed DyVal by leveraging the structural advantage of directed\nacyclic graphs to dynamically generate evaluation samples with controllable\ncomplexities. DyVal generates challenging evaluation sets on reasoning tasks\nincluding mathematics, logical reasoning, and algorithm problems. We evaluate\nvarious LLMs ranging from Flan-T5-large to ChatGPT and GPT4. Experiments\ndemonstrate that LLMs perform worse in DyVal-generated evaluation samples with\ndifferent complexities, emphasizing the significance of dynamic evaluation. We\nalso analyze the failure cases and results of different prompting methods.\nMoreover, DyVal-generated samples are not only evaluation sets, but also\nhelpful data for fine-tuning to improve the performance of LLMs on existing\nbenchmarks. We hope that DyVal can shed light on the future evaluation research\nof LLMs.\n",
                "链接": "https://arxiv.org/abs/2309.17167"
            },
            {
                "文章ID": "105811",
                "标题": "Meta Semantic Template for Evaluation of Large Language Models",
                "作者": " Yachuan Liu,  Liang Chen,  Jindong Wang,  Qiaozhu Mei,  Xing Xie",
                "发布日期": "2023-10-20",
                "摘要": "  Do large language models (LLMs) genuinely understand the semantics of the\nlanguage, or just memorize the training data? The recent concern on potential\ndata contamination of LLMs has raised awareness of the community to conduct\nresearch on LLMs evaluation. In this paper, we propose MSTemp, an approach that\ncreates meta semantic templates to evaluate the semantic understanding ability\nof LLMs. The core of MSTemp is not to perform evaluation directly on existing\nbenchmark datasets, but to generate new out-of-distribution (OOD) evaluation\nsets using existing datasets as seeds. Specifically, for a given sentence,\nMSTemp leverages another language model to generate new samples while\npreserving its semantics. The new samples are called semantic templates to the\noriginal sentence. Then, MSTemp generates evaluation samples via sentence\nparsing and random word replacement on the semantic templates. MSTemp is highly\nflexible, dynamic, and cost-effective. Our initial experiments show that\nMSTemp-generated samples can significantly reduce the performance of LLMs using\nexisting datasets as seeds. We hope this initial work can shed light on future\nresearch of LLMs evaluation.\n",
                "链接": "https://arxiv.org/abs/2310.01448"
            },
            {
                "文章ID": "119112",
                "标题": "ROBBIE: Robust Bias Evaluation of Large Generative Language Models",
                "作者": " David Esiobu,  Xiaoqing Tan,  Saghar Hosseini,  Megan Ung,  Yuchen Zhang,  Jude Fernandes,  Jane Dwivedi-Yu,  Eleonora Presani,  Adina Williams,  Eric Michael Smith",
                "发布日期": "2023-12-01",
                "摘要": "  As generative large language models (LLMs) grow more performant and\nprevalent, we must develop comprehensive enough tools to measure and improve\ntheir fairness. Different prompt-based datasets can be used to measure social\nbias across multiple text domains and demographic axes, meaning that testing\nLLMs on more datasets can potentially help us characterize their biases more\nfully, and better ensure equal and equitable treatment of marginalized\ndemographic groups. In this work, our focus is two-fold:\n  (1) Benchmarking: a comparison of 6 different prompt-based bias and toxicity\nmetrics across 12 demographic axes and 5 families of generative LLMs. Out of\nthose 6 metrics, AdvPromptSet and HolisticBiasR are novel datasets proposed in\nthe paper. The comparison of those benchmarks gives us insights about the bias\nand toxicity of the compared models. Therefore, we explore the frequency of\ndemographic terms in common LLM pre-training corpora and how this may relate to\nmodel biases.\n  (2) Mitigation: we conduct a comprehensive study of how well 3 bias/toxicity\nmitigation techniques perform across our suite of measurements. ROBBIE aims to\nprovide insights for practitioners while deploying a model, emphasizing the\nneed to not only measure potential harms, but also understand how they arise by\ncharacterizing the data, mitigate harms once found, and balance any trade-offs.\nWe open-source our analysis code in hopes of encouraging broader measurements\nof bias in future LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.18140"
            },
            {
                "文章ID": "100927",
                "标题": "Evaluation of large language models for discovery of gene set function",
                "作者": " Mengzhou Hu,  Sahar Alkhairy,  Ingoo Lee,  Rudolf T. Pillich,  Robin Bachelder,  Trey Ideker,  Dexter Pratt",
                "发布日期": "2023-09-11",
                "摘要": "  Gene set analysis is a mainstay of functional genomics, but it relies on\nmanually curated databases of gene functions that are incomplete and unaware of\nbiological context. Here we evaluate the ability of OpenAI's GPT-4, a Large\nLanguage Model (LLM), to develop hypotheses about common gene functions from\nits embedded biomedical knowledge. We created a GPT-4 pipeline to label gene\nsets with names that summarize their consensus functions, substantiated by\nanalysis text and citations. Benchmarking against named gene sets in the Gene\nOntology, GPT-4 generated very similar names in 50% of cases, while in most\nremaining cases it recovered the name of a more general concept. In gene sets\ndiscovered in 'omics data, GPT-4 names were more informative than gene set\nenrichment, with supporting statements and citations that largely verified in\nhuman review. The ability to rapidly synthesize common gene functions positions\nLLMs as valuable functional genomics assistants.\n",
                "链接": "https://arxiv.org/abs/2309.04019"
            },
            {
                "文章ID": "72313",
                "标题": "Evaluation of Social Biases in Recent Large Pre-Trained Models",
                "作者": " Swapnil Sharma,  Nikita Anand,  Kranthi Kiran G. V.,  Alind Jain",
                "发布日期": "2023-04-17",
                "摘要": "  Large pre-trained language models are widely used in the community. These\nmodels are usually trained on unmoderated and unfiltered data from open sources\nlike the Internet. Due to this, biases that we see in platforms online which\nare a reflection of those in society are in turn captured and learned by these\nmodels. These models are deployed in applications that affect millions of\npeople and their inherent biases are harmful to the targeted social groups. In\nthis work, we study the general trend in bias reduction as newer pre-trained\nmodels are released. Three recent models ( ELECTRA, DeBERTa, and DistilBERT)\nare chosen and evaluated against two bias benchmarks, StereoSet and\nCrowS-Pairs. They are compared to the baseline of BERT using the associated\nmetrics. We explore whether as advancements are made and newer, faster, lighter\nmodels are released: are they being developed responsibly such that their\ninherent social biases have been reduced compared to their older counterparts?\nThe results are compiled and we find that all the models under study do exhibit\nbiases but have generally improved as compared to BERT.\n",
                "链接": "https://arxiv.org/abs/2304.06861"
            }
        ]
    },
    {
        "question": {
            "question": "近一个月与多模态大模型相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "114375",
                "标题": "mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with\n  Modality Collaboration",
                "作者": " Qinghao Ye,  Haiyang Xu,  Jiabo Ye,  Ming Yan,  Anwen Hu,  Haowei Liu,  Qi Qian,  Ji Zhang,  Fei Huang,  Jingren Zhou",
                "发布日期": "2023-11-13",
                "摘要": "  Multi-modal Large Language Models (MLLMs) have demonstrated impressive\ninstruction abilities across various open-ended tasks. However, previous\nmethods primarily focus on enhancing multi-modal capabilities. In this work, we\nintroduce a versatile multi-modal large language model, mPLUG-Owl2, which\neffectively leverages modality collaboration to improve performance in both\ntext and multi-modal tasks. mPLUG-Owl2 utilizes a modularized network design,\nwith the language decoder acting as a universal interface for managing\ndifferent modalities. Specifically, mPLUG-Owl2 incorporates shared functional\nmodules to facilitate modality collaboration and introduces a modality-adaptive\nmodule that preserves modality-specific features. Extensive experiments reveal\nthat mPLUG-Owl2 is capable of generalizing both text tasks and multi-modal\ntasks and achieving state-of-the-art performances with a single generic model.\nNotably, mPLUG-Owl2 is the first MLLM model that demonstrates the modality\ncollaboration phenomenon in both pure-text and multi-modal scenarios, setting a\npioneering path in the development of future multi-modal foundation models.\n",
                "链接": "https://arxiv.org/abs/2311.04257"
            },
            {
                "文章ID": "52728",
                "标题": "DialogCC: Large-Scale Multi-Modal Dialogue Dataset",
                "作者": " Young-Jun Lee,  Byungsoo Ko,  Han-Gyu Kim,  Ho-Jin Choi",
                "发布日期": "2022-12-09",
                "摘要": "  As sharing images in an instant message is a crucial factor, there has been\nactive research on learning a image-text multi-modal dialogue model. However,\ntraining a well-generalized multi-modal dialogue model is challenging because\nexisting multi-modal dialogue datasets contain a small number of data, limited\ntopics, and a restricted variety of images per dialogue. In this paper, we\npresent a multi-modal dialogue dataset creation pipeline that involves matching\nlarge-scale images to dialogues based on CLIP similarity. Using this automatic\npipeline, we propose a large-scale multi-modal dialogue dataset, DialogCC,\nwhich covers diverse real-world topics and various images per dialogue. With\nextensive experiments, we demonstrate that training a multi-modal dialogue\nmodel with our dataset can improve generalization performance. Additionally,\nexisting models trained with our dataset achieve state-of-the-art performance\non image and text retrieval tasks. The source code and the dataset will be\nreleased after publication.\n",
                "链接": "https://arxiv.org/abs/2212.04119"
            },
            {
                "文章ID": "112817",
                "标题": "Enhancing the Spatial Awareness Capability of Multi-Modal Large Language\n  Model",
                "作者": " Yongqiang Zhao,  Zhenyu Li,  Zhi Jin,  Feng Zhang,  Haiyan Zhao,  Chengfeng Dou,  Zhengwei Tao,  Xinhai Xu,  Donghong Liu",
                "发布日期": "2023-11-02",
                "摘要": "  The Multi-Modal Large Language Model (MLLM) refers to an extension of the\nLarge Language Model (LLM) equipped with the capability to receive and infer\nmulti-modal data. Spatial awareness stands as one of the crucial abilities of\nMLLM, encompassing diverse skills related to understanding spatial\nrelationships among objects and between objects and the scene area. Industries\nsuch as autonomous driving, smart healthcare, robotics, virtual, and augmented\nreality heavily demand MLLM's spatial awareness capabilities. However, there\nexists a noticeable gap between the current spatial awareness capabilities of\nMLLM and the requirements set by human needs. To address this issue, this paper\nproposes using more precise spatial position information between objects to\nguide MLLM in providing more accurate responses to user-related inquiries.\nSpecifically, for a particular multi-modal task, we utilize algorithms for\nacquiring geometric spatial information and scene graphs to obtain relevant\ngeometric spatial information and scene details of objects involved in the\nquery. Subsequently, based on this information, we direct MLLM to address\nspatial awareness-related queries posed by the user. Extensive experiments were\nconducted in benchmarks such as MME, MM-Vet, and other multi-modal large\nlanguage models. The experimental results thoroughly confirm the efficacy of\nthe proposed method in enhancing the spatial awareness tasks and associated\ntasks of MLLM.\n",
                "链接": "https://arxiv.org/abs/2310.20357"
            },
            {
                "文章ID": "112809",
                "标题": "Large Multi-modal Encoders for Recommendation",
                "作者": " Zixuan Yi,  Zijun Long,  Iadh Ounis,  Craig Macdonald,  Richard Mccreadie",
                "发布日期": "2023-11-06",
                "摘要": "  In recent years, the rapid growth of online multimedia services, such as\ne-commerce platforms, has necessitated the development of personalised\nrecommendation approaches that can encode diverse content about each item.\nIndeed, modern multi-modal recommender systems exploit diverse features\nobtained from raw images and item descriptions to enhance the recommendation\nperformance. However, the existing multi-modal recommenders primarily depend on\nthe features extracted individually from different media through pre-trained\nmodality-specific encoders, and exhibit only shallow alignments between\ndifferent modalities - limiting these systems' ability to capture the\nunderlying relationships between the modalities. In this paper, we investigate\nthe usage of large multi-modal encoders within the specific context of\nrecommender systems, as these have previously demonstrated state-of-the-art\neffectiveness when ranking items across various domains. Specifically, we\ntailor two state-of-the-art multi-modal encoders (CLIP and VLMo) for\nrecommendation tasks using a range of strategies, including the exploration of\npre-trained and fine-tuned encoders, as well as the assessment of the\nend-to-end training of these encoders. We demonstrate that pre-trained large\nmulti-modal encoders can generate more aligned and effective user/item\nrepresentations compared to existing modality-specific encoders across three\nmulti-modal recommendation datasets. Furthermore, we show that fine-tuning\nthese large multi-modal encoders with recommendation datasets leads to an\nenhanced recommendation performance. In terms of different training paradigms,\nour experiments highlight the essential role of the end-to-end training of\nlarge multi-modal encoders in multi-modal recommendation systems.\n",
                "链接": "https://arxiv.org/abs/2310.20343"
            },
            {
                "文章ID": "99535",
                "标题": "Enhancing Subtask Performance of Multi-modal Large Language Model",
                "作者": " Yongqiang Zhao,  Zhenyu Li,  Feng Zhang,  Xinhai Xu,  Donghong Liu",
                "发布日期": "2023-09-01",
                "摘要": "  Multi-modal Large Language Model (MLLM) refers to a model expanded from a\nLarge Language Model (LLM) that possesses the capability to handle and infer\nmulti-modal data. Current MLLMs typically begin by using LLMs to decompose\ntasks into multiple subtasks, then employing individual pre-trained models to\ncomplete specific subtasks, and ultimately utilizing LLMs to integrate the\nresults of each subtasks to obtain the results of the task. In real-world\nscenarios, when dealing with large projects, it is common practice to break\ndown the project into smaller sub-projects, with different teams providing\ncorresponding solutions or results. The project owner then decides which\nsolution or result to use, ensuring the best possible outcome for each subtask\nand, consequently, for the entire project. Inspired by this, this study\nconsiders selecting multiple pre-trained models to complete the same subtask.\nBy combining the results from multiple pre-trained models, the optimal subtask\nresult is obtained, enhancing the performance of the MLLM. Specifically, this\nstudy first selects multiple pre-trained models focused on the same subtask\nbased on distinct evaluation approaches, and then invokes these models in\nparallel to process input data and generate corresponding subtask results.\nFinally, the results from multiple pre-trained models for the same subtask are\ncompared using the LLM, and the best result is chosen as the outcome for that\nsubtask. Extensive experiments are conducted in this study using GPT-4\nannotated datasets and human-annotated datasets. The results of various\nevaluation metrics adequately demonstrate the effectiveness of the proposed\napproach in this paper.\n",
                "链接": "https://arxiv.org/abs/2308.16474"
            },
            {
                "文章ID": "61427",
                "标题": "Large Scale Multi-Lingual Multi-Modal Summarization Dataset",
                "作者": " Yash Verma,  Anubhav Jangra,  Raghvendra Kumar,  Sriparna Saha",
                "发布日期": "2023-02-14",
                "摘要": "  Significant developments in techniques such as encoder-decoder models have\nenabled us to represent information comprising multiple modalities. This\ninformation can further enhance many downstream tasks in the field of\ninformation retrieval and natural language processing; however, improvements in\nmulti-modal techniques and their performance evaluation require large-scale\nmulti-modal data which offers sufficient diversity. Multi-lingual modeling for\na variety of tasks like multi-modal summarization, text generation, and\ntranslation leverages information derived from high-quality multi-lingual\nannotated data. In this work, we present the current largest multi-lingual\nmulti-modal summarization dataset (M3LS), and it consists of over a million\ninstances of document-image pairs along with a professionally annotated\nmulti-modal summary for each pair. It is derived from news articles published\nby British Broadcasting Corporation(BBC) over a decade and spans 20 languages,\ntargeting diversity across five language roots, it is also the largest\nsummarization dataset for 13 languages and consists of cross-lingual\nsummarization data for 2 languages. We formally define the multi-lingual\nmulti-modal summarization task utilizing our dataset and report baseline scores\nfrom various state-of-the-art summarization techniques in a multi-lingual\nsetting. We also compare it with many similar datasets to analyze the\nuniqueness and difficulty of M3LS.\n",
                "链接": "https://arxiv.org/abs/2302.06560"
            },
            {
                "文章ID": "115630",
                "标题": "Unlock the Power: Competitive Distillation for Multi-Modal Large\n  Language Models",
                "作者": " Xinwei Li,  Li Lin,  Shuai Wang,  Chen Qian",
                "发布日期": "2023-11-15",
                "摘要": "  Recently, multi-modal content generation has attracted lots of attention from\nresearchers by investigating the utilization of visual instruction tuning based\non large language models (LLMs). To enhance the performance and generalization\nability of such LLMs, the practice of distilling knowledge from pretrained\nmulti-modal models (a.k.a. teachers) to more compact multi-modal LLMs\n(students) has gained considerable interest. However, the prevailing paradigm\nof instructiontuning in multi-modal LLMs knowledge distillation is\nresource-intensive and unidirectional, neglecting the potential for mutual\nfeedback between the student and teacher models. Thus, we propose an innovative\nCompetitive Multi-modal Distillation framework (CoMD), which captures\nbidirectional feedback between teacher and student models and continually\nupdates the multi-modal capabilities that the student model has learned. It\ncomprises two stages: multi-modal pre-training and multi-modal competitive\ndistillation. The first stage pre-trains the student model on a large number of\nfiltered multi-modal datasets. The second stage facilitates a bidirectional\nknowledge transfer between the student and teacher models. Our experimental\nanalysis of diverse datasets shows that our knowledge transfer method\nconsistently improves the capabilities of the student model. Finally, the\n7B-sized student model after four distillations surpassed the current\nstate-of-the-art model LLaVA-13B on the ScienceQA and LLaVA Test dataset, also\noutperforms other strong baselines in the zero-shot setting.\n",
                "链接": "https://arxiv.org/abs/2311.08213"
            },
            {
                "文章ID": "108409",
                "标题": "Towards Robust Multi-Modal Reasoning via Model Selection",
                "作者": " Xiangyan Liu,  Rongxue Li,  Wei Ji,  Tao Lin",
                "发布日期": "2023-10-13",
                "摘要": "  The reasoning capabilities of LLM (Large Language Model) are widely\nacknowledged in recent research, inspiring studies on tool learning and\nautonomous agents. LLM serves as the \"brain\" of agent, orchestrating multiple\ntools for collaborative multi-step task solving. Unlike methods invoking tools\nlike calculators or weather APIs for straightforward tasks, multi-modal agents\nexcel by integrating diverse AI models for complex challenges. However, current\nmulti-modal agents neglect the significance of model selection: they primarily\nfocus on the planning and execution phases, and will only invoke predefined\ntask-specific models for each subtask, making the execution fragile. Meanwhile,\nother traditional model selection methods are either incompatible with or\nsuboptimal for the multi-modal agent scenarios, due to ignorance of\ndependencies among subtasks arising by multi-step reasoning.\n  To this end, we identify the key challenges therein and propose the\n$\\textit{M}^3$ framework as a plug-in with negligible runtime overhead at\ntest-time. This framework improves model selection and bolsters the robustness\nof multi-modal agents in multi-step reasoning. In the absence of suitable\nbenchmarks, we create MS-GQA, a new dataset specifically designed to\ninvestigate the model selection challenge in multi-modal agents. Our\nexperiments reveal that our framework enables dynamic model selection,\nconsidering both user inputs and subtask dependencies, thereby robustifying the\noverall reasoning process. Our code and benchmark:\nhttps://github.com/LINs-lab/M3.\n",
                "链接": "https://arxiv.org/abs/2310.08446"
            },
            {
                "文章ID": "124615",
                "标题": "FoodLMM: A Versatile Food Assistant using Large Multi-modal Model",
                "作者": " Yuehao Yin,  Huiyan Qi,  Bin Zhu,  Jingjing Chen,  Yu-Gang Jiang,  Chong-Wah Ngo",
                "发布日期": "2023-12-27",
                "摘要": "  Large Multi-modal Models (LMMs) have made impressive progress in many\nvision-language tasks. Nevertheless, the performance of general LMMs in\nspecific domains is still far from satisfactory. This paper proposes FoodLMM, a\nversatile food assistant based on LMMs with various capabilities, including\nfood recognition, ingredient recognition, recipe generation, nutrition\nestimation, food segmentation and multi-round conversation. To facilitate\nFoodLMM to deal with tasks beyond pure text output, we introduce a series of\nnovel task-specific tokens and heads, enabling the model to predict food\nnutritional values and multiple segmentation masks. We adopt a two-stage\ntraining strategy. In the first stage, we utilize multiple public food\nbenchmarks for multi-task learning by leveraging instruct-following paradigm.\nIn the second stage, we construct a multi-round conversation and a reasoning\nsegmentation datasets to fine-tune the model, enabling it to conduct\nprofessional dialogues and generate segmentation masks based on complex\nreasoning in food domain. Our fine-tuned FoodLMM achieves state-of-the-art\nresults across several food benchmarks. We will make our code, models and\ndatasets publicly available.\n",
                "链接": "https://arxiv.org/abs/2312.14991"
            },
            {
                "文章ID": "107198",
                "标题": "Improving Discriminative Multi-Modal Learning with Large-Scale\n  Pre-Trained Models",
                "作者": " Chenzhuang Du,  Yue Zhao,  Chonghua Liao,  Jiacheng You,  Jie Fu,  Hang Zhao",
                "发布日期": "2023-10-10",
                "摘要": "  This paper investigates how to better leverage large-scale pre-trained\nuni-modal models to further enhance discriminative multi-modal learning. Even\nwhen fine-tuned with only uni-modal data, these models can outperform previous\nmulti-modal models in certain tasks. It's clear that their incorporation into\nmulti-modal learning would significantly improve performance. However,\nmulti-modal learning with these models still suffers from insufficient learning\nof uni-modal features, which weakens the resulting multi-modal model's\ngeneralization ability. While fine-tuning uni-modal models separately and then\naggregating their predictions is straightforward, it doesn't allow for adequate\nadaptation between modalities, also leading to sub-optimal results. To this\nend, we introduce Multi-Modal Low-Rank Adaptation learning (MMLoRA). By\nfreezing the weights of uni-modal fine-tuned models, adding extra trainable\nrank decomposition matrices to them, and subsequently performing multi-modal\njoint training, our method enhances adaptation between modalities and boosts\noverall performance. We demonstrate the effectiveness of MMLoRA on three\ndataset categories: audio-visual (e.g., AVE, Kinetics-Sound, CREMA-D),\nvision-language (e.g., MM-IMDB, UPMC Food101), and RGB-Optical Flow (UCF101).\n",
                "链接": "https://arxiv.org/abs/2310.05193"
            }
        ]
    },
    {
        "question": {
            "question": "查找近六个月工具学习评测数据集的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "108993",
                "标题": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
                "作者": " Alon Jacovi,  Avi Caciularu,  Jonathan Herzig,  Roee Aharoni,  Bernd Bohnet,  Mor Geva",
                "发布日期": "2023-12-29",
                "摘要": "  A growing area of research investigates augmenting language models with tools\n(e.g., search engines, calculators) to overcome their shortcomings (e.g.,\nmissing or incorrect knowledge, incorrect logical inferences). Various few-shot\ntool-usage strategies have been proposed. However, there is no systematic and\nfair comparison across different strategies, or between these strategies and\nstrong baselines that do not leverage tools. We conduct an extensive empirical\nanalysis, finding that (1) across various datasets, example difficulty levels,\nand models, strong no-tool baselines are competitive to tool-assisted\nstrategies, implying that effectively using tools with in-context\ndemonstrations is a difficult unsolved problem; (2) for knowledge-retrieval\ntasks, strategies that *refine* incorrect outputs with tools outperform\nstrategies that retrieve relevant information *ahead of* or *during\ngeneration*; (3) tool-assisted strategies are expensive in the number of tokens\nthey require to work -- incurring additional costs by orders of magnitude --\nwhich does not translate into significant improvement in performance. Overall,\nour findings suggest that few-shot tool integration is still an open challenge,\nemphasizing the need for comprehensive evaluations of future strategies to\naccurately assess their *benefits* and *costs*.\n",
                "链接": "https://arxiv.org/abs/2310.10062"
            },
            {
                "文章ID": "124318",
                "标题": "T-Eval: Evaluating the Tool Utilization Capability Step by Step",
                "作者": " Zehui Chen,  Weihua Du,  Wenwei Zhang,  Kuikun Liu,  Jiangning Liu,  Miao Zheng,  Jingming Zhuo,  Songyang Zhang,  Dahua Lin,  Kai Chen,  Feng Zhao",
                "发布日期": "2023-12-22",
                "摘要": "  Large language models (LLM) have achieved remarkable performance on various\nNLP tasks and are augmented by tools for broader applications. Yet, how to\nevaluate and analyze the tool-utilization capability of LLMs is still\nunder-explored. In contrast to previous works that evaluate models\nholistically, we comprehensively decompose the tool utilization into multiple\nsub-processes, including instruction following, planning, reasoning, retrieval,\nunderstanding, and review. Based on that, we further introduce \\shortname~to\nevaluate the tool utilization capability step by step. \\shortname~disentangles\nthe tool utilization evaluation into several sub-domains along model\ncapabilities, facilitating the inner understanding of both holistic and\nisolated competency of LLMs. We conduct extensive experiments on \\shortname~and\nin-depth analysis of various LLMs. \\shortname~ not only exhibits consistency\nwith the outcome-oriented evaluation but also provides a more fine-grained\nanalysis of the capabilities of LLMs, providing a new perspective in LLM\nevaluation on tool-utilization ability. The benchmark will be available at\n\\href{https://github.com/open-compass/T-Eval}{https://github.com/open-compass/T-Eval}.\n",
                "链接": "https://arxiv.org/abs/2312.14033"
            },
            {
                "文章ID": "117713",
                "标题": "Brain MRI Screening Tool with Federated Learning",
                "作者": " Roman Stoklasa,  Ioannis Stathopoulos,  Efstratios Karavasilis,  Efstathios Efstathopoulos,  Marek Dostál,  Miloš Keřkovský,  Michal Kozubek,  Luigi Serio",
                "发布日期": "2023-11-27",
                "摘要": "  In clinical practice, we often see significant delays between MRI scans and\nthe diagnosis made by radiologists, even for severe cases. In some cases, this\nmay be caused by the lack of additional information and clues, so even the\nsevere cases need to wait in the queue for diagnosis. This can be avoided if\nthere is an automatic software tool, which would supplement additional\ninformation, alerting radiologists that the particular patient may be a severe\ncase.\n  We are presenting an automatic brain MRI Screening Tool and we are\ndemonstrating its capabilities for detecting tumor-like pathologies. It is the\nfirst version on the path toward a robust multi-pathology screening solution.\nThe tool supports Federated Learning, so multiple institutions may contribute\nto the model without disclosing their private data.\n",
                "链接": "https://arxiv.org/abs/2311.14086"
            },
            {
                "文章ID": "114252",
                "标题": "Understanding Tool Discovery and Tool Innovation Using Active Inference",
                "作者": " Poppy Collis,  Paul F Kinghorn,  Christopher L Buckley",
                "发布日期": "2023-11-08",
                "摘要": "  The ability to invent new tools has been identified as an important facet of\nour ability as a species to problem solve in dynamic and novel environments.\nWhile the use of tools by artificial agents presents a challenging task and has\nbeen widely identified as a key goal in the field of autonomous robotics, far\nless research has tackled the invention of new tools by agents. In this paper,\n(1) we articulate the distinction between tool discovery and tool innovation by\nproviding a minimal description of the two concepts under the formalism of\nactive inference. We then (2) apply this description to construct a toy model\nof tool innovation by introducing the notion of tool affordances into the\nhidden states of the agent's probabilistic generative model. This particular\nstate factorisation facilitates the ability to not just discover tools but\ninvent them through the offline induction of an appropriate tool property. We\ndiscuss the implications of these preliminary results and outline future\ndirections of research.\n",
                "链接": "https://arxiv.org/abs/2311.03893"
            },
            {
                "文章ID": "98794",
                "标题": "Confucius: Iterative Tool Learning from Introspection Feedback by\n  Easy-to-Difficult Curriculum",
                "作者": " Shen Gao,  Zhengliang Shi,  Minghang Zhu,  Bowen Fang,  Xin Xin,  Pengjie Ren,  Zhumin Chen,  Jun Ma,  Zhaochun Ren",
                "发布日期": "2023-12-22",
                "摘要": "  Augmenting large language models (LLMs) with external tools has emerged as a\npromising approach to extending the capability of LLMs. Although some works\nemploy open-source LLMs for the tool learning task, most of them are trained in\na controlled environment in which LLMs only learn to execute the human-provided\ntools. However, selecting proper tools from the large toolset is also a crucial\nability for the tool learning model to be applied in real-world applications.\nExisting methods usually directly employ self-instruction methods to train the\nmodel, which ignores differences in tool complexity. In this paper, we propose\nthe Confucius, a novel tool learning framework to train LLM to use complicated\ntools in real-world scenarios, which contains two main phases: (1) We first\npropose a multi-stage learning method to teach the LLM to use various tools\nfrom an easy-to-difficult curriculum; (2) thenceforth, we propose the Iterative\nSelf-instruct from Introspective Feedback (ISIF) to dynamically construct the\ndataset to improve the ability to use the complicated tool. Extensive\nexperiments conducted on both controlled and real-world settings demonstrate\nthe superiority of our tool learning framework in the real-world application\nscenarios compared to both tuning-free (e.g. ChatGPT, Claude) and tuning-based\nbaselines (e.g. GPT4Tools).\n",
                "链接": "https://arxiv.org/abs/2308.14034"
            },
            {
                "文章ID": "123110",
                "标题": "ProTIP: Progressive Tool Retrieval Improves Planning",
                "作者": " Raviteja Anantha,  Bortik Bandyopadhyay,  Anirudh Kashi,  Sayantan Mahinder,  Andrew W Hill,  Srinivas Chappidi",
                "发布日期": "2023-12-19",
                "摘要": "  Large language models (LLMs) are increasingly employed for complex multi-step\nplanning tasks, where the tool retrieval (TR) step is crucial for achieving\nsuccessful outcomes. Two prevalent approaches for TR are single-step retrieval,\nwhich utilizes the complete query, and sequential retrieval using task\ndecomposition (TD), where a full query is segmented into discrete atomic\nsubtasks. While single-step retrieval lacks the flexibility to handle\n\"inter-tool dependency,\" the TD approach necessitates maintaining \"subtask-tool\natomicity alignment,\" as the toolbox can evolve dynamically. To address these\nlimitations, we introduce the Progressive Tool retrieval to Improve Planning\n(ProTIP) framework. ProTIP is a lightweight, contrastive learning-based\nframework that implicitly performs TD without the explicit requirement of\nsubtask labels, while simultaneously maintaining subtask-tool atomicity. On the\nToolBench dataset, ProTIP outperforms the ChatGPT task decomposition-based\napproach by a remarkable margin, achieving a 24% improvement in Recall@K=10 for\nTR and a 41% enhancement in tool accuracy for plan generation.\n",
                "链接": "https://arxiv.org/abs/2312.10332"
            },
            {
                "文章ID": "116523",
                "标题": "ToolTalk: Evaluating Tool-Usage in a Conversational Setting",
                "作者": " Nicholas Farn,  Richard Shin",
                "发布日期": "2023-11-21",
                "摘要": "  Large language models (LLMs) have displayed massive improvements in reasoning\nand decision-making skills and can hold natural conversations with users. Many\nrecent works seek to augment LLM-based assistants with external tools so they\ncan access private or up-to-date information and carry out actions on behalf of\nusers. To better measure the performance of these assistants, this paper\nintroduces ToolTalk, a benchmark consisting of complex user intents requiring\nmulti-step tool usage specified through dialogue. ToolTalk contains 28 tools\ngrouped into 7 plugins, and includes a complete simulated implementation of\neach tool, allowing for fully automated evaluation of assistants that rely on\nexecution feedback. ToolTalk also emphasizes tools that externally affect the\nworld rather than only tools for referencing or searching information. We\nevaluate GPT-3.5 and GPT-4 on ToolTalk resulting in success rates of 26% and\n50% respectively. Our analysis of the errors reveals three major categories and\nsuggests some future directions for improvement. We release ToolTalk at\nhttps://github.com/microsoft/ToolTalk.\n",
                "链接": "https://arxiv.org/abs/2311.10775"
            },
            {
                "文章ID": "121559",
                "标题": "MATK: The Meme Analytical Tool Kit",
                "作者": " Ming Shan Hee,  Aditi Kumaresan,  Nguyen Khoi Hoang,  Nirmalendu Prakash,  Rui Cao,  Roy Ka-Wei Lee",
                "发布日期": "2023-12-12",
                "摘要": "  The rise of social media platforms has brought about a new digital culture\ncalled memes. Memes, which combine visuals and text, can strongly influence\npublic opinions on social and cultural issues. As a result, people have become\ninterested in categorizing memes, leading to the development of various\ndatasets and multimodal models that show promising results in this field.\nHowever, there is currently a lack of a single library that allows for the\nreproduction, evaluation, and comparison of these models using fair benchmarks\nand settings. To fill this gap, we introduce the Meme Analytical Tool Kit\n(MATK), an open-source toolkit specifically designed to support existing memes\ndatasets and cutting-edge multimodal models. MATK aims to assist researchers\nand engineers in training and reproducing these multimodal models for meme\nclassification tasks, while also providing analysis techniques to gain insights\ninto their strengths and weaknesses. To access MATK, please visit\n\\url{https://github.com/Social-AI-Studio/MATK}.\n",
                "链接": "https://arxiv.org/abs/2312.06094"
            },
            {
                "文章ID": "79938",
                "标题": "ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large\n  Language Models",
                "作者": " Zhipeng Chen,  Kun Zhou,  Beichen Zhang,  Zheng Gong,  Wayne Xin Zhao,  Ji-Rong Wen",
                "发布日期": "2023-11-07",
                "摘要": "  Although large language models (LLMs) have achieved excellent performance in\na variety of evaluation benchmarks, they still struggle in complex reasoning\ntasks which require specific knowledge and multi-hop reasoning. To improve the\nreasoning abilities, we propose ChatCoT, a tool-augmented chain-of-thought\nreasoning framework for chat-based LLMs (e.g., ChatGPT). In ChatCoT, we model\nthe chain-of-thought (CoT) reasoning as multi-turn conversations, to utilize\ntools in a more natural way through chatting. At each turn, LLMs can either\ninteract with tools or perform the reasoning. Our approach can effectively\nleverage the multi-turn conversation ability of chat-based LLMs, and integrate\nthe thought chain following and tools manipulation in a unified way. Specially,\nwe initialize the early turns of the conversation by the knowledge about tools,\ntasks, and reasoning format, and propose an iterative tool-augmented reasoning\nstep to perform step-by-step tool-augmented reasoning. The experiment results\non two complex reasoning datasets (MATH and HotpotQA) have shown the\neffectiveness of ChatCoT on complex reasoning tasks, achieving a 7.9% relative\nimprovement over the state-of-the-art baseline. Our code and data are available\nat: \\url{https://github.com/RUCAIBOX/ChatCoT}.\n",
                "链接": "https://arxiv.org/abs/2305.14323"
            },
            {
                "文章ID": "124873",
                "标题": "Design and Implementation of a Tool for Extracting Uzbek Syllables",
                "作者": " Ulugbek Salaev,  Elmurod Kuriyozov,  Gayrat Matlatipov",
                "发布日期": "2023-12-27",
                "摘要": "  The accurate syllabification of words plays a vital role in various Natural\nLanguage Processing applications. Syllabification is a versatile linguistic\ntool with applications in linguistic research, language technology, education,\nand various fields where understanding and processing language is essential. In\nthis paper, we present a comprehensive approach to syllabification for the\nUzbek language, including rule-based techniques and machine learning\nalgorithms. Our rule-based approach utilizes advanced methods for dividing\nwords into syllables, generating hyphenations for line breaks and count of\nsyllables. Additionally, we collected a dataset for evaluating and training\nusing machine learning algorithms comprising word-syllable mappings,\nhyphenations, and syllable counts to predict syllable counts as well as for the\nevaluation of the proposed model. Our results demonstrate the effectiveness and\nefficiency of both approaches in achieving accurate syllabification. The\nresults of our experiments show that both approaches achieved a high level of\naccuracy, exceeding 99%. This study provides valuable insights and\nrecommendations for future research on syllabification and related areas in not\nonly the Uzbek language itself, but also in other closely-related Turkic\nlanguages with low-resource factor.\n",
                "链接": "https://arxiv.org/abs/2312.15779"
            }
        ]
    },
    {
        "question": {
            "question": "大模型在游戏方面的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "请找到缓和噪声标签影响的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下文本检索任务上，是否有关于大模型在语义坍缩问题上的研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "81507",
                "标题": "Reward Collapse in Aligning Large Language Models",
                "作者": " Ziang Song,  Tianle Cai,  Jason D. Lee,  Weijie J. Su",
                "发布日期": "2023-05-30",
                "摘要": "  The extraordinary capabilities of large language models (LLMs) such as\nChatGPT and GPT-4 are in part unleashed by aligning them with reward models\nthat are trained on human preferences, which are often represented as rankings\nof responses to prompts. In this paper, we document the phenomenon of\n\\textit{reward collapse}, an empirical observation where the prevailing\nranking-based approach results in an \\textit{identical} reward distribution\n\\textit{regardless} of the prompts during the terminal phase of training. This\noutcome is undesirable as open-ended prompts like ``write a short story about\nyour best friend'' should yield a continuous range of rewards for their\ncompletions, while specific prompts like ``what is the capital of New Zealand''\nshould generate either high or low rewards. Our theoretical investigation\nreveals that reward collapse is primarily due to the insufficiency of the\nranking-based objective function to incorporate prompt-related information\nduring optimization. This insight allows us to derive closed-form expressions\nfor the reward distribution associated with a set of utility functions in an\nasymptotic regime. To overcome reward collapse, we introduce a prompt-aware\noptimization scheme that provably admits a prompt-dependent reward distribution\nwithin the interpolating regime. Our experimental results suggest that our\nproposed prompt-aware utility functions significantly alleviate reward collapse\nduring the training of reward models.\n",
                "链接": "https://arxiv.org/abs/2305.17608"
            },
            {
                "文章ID": "55962",
                "标题": "Understanding Imbalanced Semantic Segmentation Through Neural Collapse",
                "作者": " Zhisheng Zhong,  Jiequan Cui,  Yibo Yang,  Xiaoyang Wu,  Xiaojuan Qi,  Xiangyu Zhang,  Jiaya Jia",
                "发布日期": "2023-01-04",
                "摘要": "  A recent study has shown a phenomenon called neural collapse in that the\nwithin-class means of features and the classifier weight vectors converge to\nthe vertices of a simplex equiangular tight frame at the terminal phase of\ntraining for classification. In this paper, we explore the corresponding\nstructures of the last-layer feature centers and classifiers in semantic\nsegmentation. Based on our empirical and theoretical analysis, we point out\nthat semantic segmentation naturally brings contextual correlation and\nimbalanced distribution among classes, which breaks the equiangular and\nmaximally separated structure of neural collapse for both feature centers and\nclassifiers. However, such a symmetric structure is beneficial to\ndiscrimination for the minor classes. To preserve these advantages, we\nintroduce a regularizer on feature centers to encourage the network to learn\nfeatures closer to the appealing structure in imbalanced semantic segmentation.\nExperimental results show that our method can bring significant improvements on\nboth 2D and 3D semantic segmentation benchmarks. Moreover, our method ranks 1st\nand sets a new record (+6.8% mIoU) on the ScanNet200 test leaderboard. Code\nwill be available at https://github.com/dvlab-research/Imbalanced-Learning.\n",
                "链接": "https://arxiv.org/abs/2301.01100"
            },
            {
                "文章ID": "107265",
                "标题": "Generalized Neural Collapse for a Large Number of Classes",
                "作者": " Jiachen Jiang,  Jinxin Zhou,  Peng Wang,  Qing Qu,  Dustin Mixon,  Chong You,  Zhihui Zhu",
                "发布日期": "2023-10-30",
                "摘要": "  Neural collapse provides an elegant mathematical characterization of learned\nlast layer representations (a.k.a. features) and classifier weights in deep\nclassification models. Such results not only provide insights but also motivate\nnew techniques for improving practical deep models. However, most of the\nexisting empirical and theoretical studies in neural collapse focus on the case\nthat the number of classes is small relative to the dimension of the feature\nspace. This paper extends neural collapse to cases where the number of classes\nare much larger than the dimension of feature space, which broadly occur for\nlanguage models, retrieval systems, and face recognition applications. We show\nthat the features and classifier exhibit a generalized neural collapse\nphenomenon, where the minimum one-vs-rest margins is maximized.We provide\nempirical study to verify the occurrence of generalized neural collapse in\npractical deep neural networks. Moreover, we provide theoretical study to show\nthat the generalized neural collapse provably occurs under unconstrained\nfeature model with spherical constraint, under certain technical conditions on\nfeature dimension and number of classes.\n",
                "链接": "https://arxiv.org/abs/2310.05351"
            },
            {
                "文章ID": "80825",
                "标题": "Feature Collapse",
                "作者": " Thomas Laurent,  James H. von Brecht,  Xavier Bresson",
                "发布日期": "2023-05-26",
                "摘要": "  We formalize and study a phenomenon called feature collapse that makes\nprecise the intuitive idea that entities playing a similar role in a learning\ntask receive similar representations. As feature collapse requires a notion of\ntask, we leverage a simple but prototypical NLP task to study it. We start by\nshowing experimentally that feature collapse goes hand in hand with\ngeneralization. We then prove that, in the large sample limit, distinct words\nthat play identical roles in this NLP task receive identical local feature\nrepresentations in a neural network. This analysis reveals the crucial role\nthat normalization mechanisms, such as LayerNorm, play in feature collapse and\nin generalization.\n",
                "链接": "https://arxiv.org/abs/2305.16162"
            },
            {
                "文章ID": "107413",
                "标题": "Unleashing the power of Neural Collapse for Transferability Estimation",
                "作者": " Yuhe Ding,  Bo Jiang,  Lijun Sheng,  Aihua Zheng,  Jian Liang",
                "发布日期": "2023-10-10",
                "摘要": "  Transferability estimation aims to provide heuristics for quantifying how\nsuitable a pre-trained model is for a specific downstream task, without\nfine-tuning them all. Prior studies have revealed that well-trained models\nexhibit the phenomenon of Neural Collapse. Based on a widely used neural\ncollapse metric in existing literature, we observe a strong correlation between\nthe neural collapse of pre-trained models and their corresponding fine-tuned\nmodels. Inspired by this observation, we propose a novel method termed Fair\nCollapse (FaCe) for transferability estimation by comprehensively measuring the\ndegree of neural collapse in the pre-trained model. Typically, FaCe comprises\ntwo different terms: the variance collapse term, which assesses the class\nseparation and within-class compactness, and the class fairness term, which\nquantifies the fairness of the pre-trained model towards each class. We\ninvestigate FaCe on a variety of pre-trained classification models across\ndifferent network architectures, source datasets, and training loss functions.\nResults show that FaCe yields state-of-the-art performance on different tasks\nincluding image classification, semantic segmentation, and text classification,\nwhich demonstrate the effectiveness and generalization of our method.\n",
                "链接": "https://arxiv.org/abs/2310.05754"
            },
            {
                "文章ID": "106836",
                "标题": "On the Embedding Collapse when Scaling up Recommendation Models",
                "作者": " Xingzhuo Guo,  Junwei Pan,  Ximei Wang,  Baixu Chen,  Jie Jiang,  Mingsheng Long",
                "发布日期": "2023-10-09",
                "摘要": "  Recent advances in deep foundation models have led to a promising trend of\ndeveloping large recommendation models to leverage vast amounts of available\ndata. However, we experiment to scale up existing recommendation models and\nobserve that the enlarged models do not improve satisfactorily. In this\ncontext, we investigate the embedding layers of enlarged models and identify a\nphenomenon of embedding collapse, which ultimately hinders scalability, wherein\nthe embedding matrix tends to reside in a low-dimensional subspace. Through\nempirical and theoretical analysis, we demonstrate that the feature interaction\nmodule specific to recommendation models has a two-sided effect. On the one\nhand, the interaction restricts embedding learning when interacting with\ncollapsed embeddings, exacerbating the collapse issue. On the other hand,\nfeature interaction is crucial in mitigating the fitting of spurious features,\nthereby improving scalability. Based on this analysis, we propose a simple yet\neffective multi-embedding design incorporating embedding-set-specific\ninteraction modules to capture diverse patterns and reduce collapse. Extensive\nexperiments demonstrate that this proposed design provides consistent\nscalability for various recommendation models.\n",
                "链接": "https://arxiv.org/abs/2310.04400"
            },
            {
                "文章ID": "122223",
                "标题": "Semantic-aware Data Augmentation for Text-to-image Synthesis",
                "作者": " Zhaorui Tan,  Xi Yang,  Kaizhu Huang",
                "发布日期": "2023-12-14",
                "摘要": "  Data augmentation has been recently leveraged as an effective regularizer in\nvarious vision-language deep neural networks. However, in text-to-image\nsynthesis (T2Isyn), current augmentation wisdom still suffers from the semantic\nmismatch between augmented paired data. Even worse, semantic collapse may occur\nwhen generated images are less semantically constrained. In this paper, we\ndevelop a novel Semantic-aware Data Augmentation (SADA) framework dedicated to\nT2Isyn. In particular, we propose to augment texts in the semantic space via an\nImplicit Textual Semantic Preserving Augmentation ($ITA$), in conjunction with\na specifically designed Image Semantic Regularization Loss ($L_r$) as Generated\nImage Semantic Conservation, to cope well with semantic mismatch and collapse.\nAs one major contribution, we theoretically show that $ITA$ can certify better\ntext-image consistency while $L_r$ regularizing the semantics of generated\nimages would avoid semantic collapse and enhance image quality. Extensive\nexperiments validate that SADA enhances text-image consistency and improves\nimage quality significantly in T2Isyn models across various backbones.\nEspecially, incorporating SADA during the tuning process of Stable Diffusion\nmodels also yields performance improvements.\n",
                "链接": "https://arxiv.org/abs/2312.07951"
            },
            {
                "文章ID": "28395",
                "标题": "Event Collapse in Contrast Maximization Frameworks",
                "作者": " Shintaro Shiba,  Yoshimitsu Aoki,  Guillermo Gallego",
                "发布日期": "2022-07-12",
                "摘要": "  Contrast maximization (CMax) is a framework that provides state-of-the-art\nresults on several event-based computer vision tasks, such as ego-motion or\noptical flow estimation. However, it may suffer from a problem called event\ncollapse, which is an undesired solution where events are warped into too few\npixels. As prior works have largely ignored the issue or proposed workarounds,\nit is imperative to analyze this phenomenon in detail. Our work demonstrates\nevent collapse in its simplest form and proposes collapse metrics by using\nfirst principles of space-time deformation based on differential geometry and\nphysics. We experimentally show on publicly available datasets that the\nproposed metrics mitigate event collapse and do not harm well-posed warps. To\nthe best of our knowledge, regularizers based on the proposed metrics are the\nonly effective solution against event collapse in the experimental settings\nconsidered, compared with other methods. We hope that this work inspires\nfurther research to tackle more complex warp models.\n",
                "链接": "https://arxiv.org/abs/2207.04007"
            },
            {
                "文章ID": "45847",
                "标题": "Perturbation Analysis of Neural Collapse",
                "作者": " Tom Tirer,  Haoxiang Huang,  Jonathan Niles-Weed",
                "发布日期": "2023-05-30",
                "摘要": "  Training deep neural networks for classification often includes minimizing\nthe training loss beyond the zero training error point. In this phase of\ntraining, a \"neural collapse\" behavior has been observed: the variability of\nfeatures (outputs of the penultimate layer) of within-class samples decreases\nand the mean features of different classes approach a certain tight frame\nstructure. Recent works analyze this behavior via idealized unconstrained\nfeatures models where all the minimizers exhibit exact collapse. However, with\npractical networks and datasets, the features typically do not reach exact\ncollapse, e.g., because deep layers cannot arbitrarily modify intermediate\nfeatures that are far from being collapsed. In this paper, we propose a richer\nmodel that can capture this phenomenon by forcing the features to stay in the\nvicinity of a predefined features matrix (e.g., intermediate features). We\nexplore the model in the small vicinity case via perturbation analysis and\nestablish results that cannot be obtained by the previously studied models. For\nexample, we prove reduction in the within-class variability of the optimized\nfeatures compared to the predefined input features (via analyzing gradient flow\non the \"central-path\" with minimal assumptions), analyze the minimizers in the\nnear-collapse regime, and provide insights on the effect of regularization\nhyperparameters on the closeness to collapse. We support our theory with\nexperiments in practical deep learning settings.\n",
                "链接": "https://arxiv.org/abs/2210.16658"
            },
            {
                "文章ID": "105436",
                "标题": "On the Role of Neural Collapse in Meta Learning Models for Few-shot\n  Learning",
                "作者": " Saaketh Medepalli,  Naren Doraiswamy",
                "发布日期": "2023-10-10",
                "摘要": "  Meta-learning frameworks for few-shot learning aims to learn models that can\nlearn new skills or adapt to new environments rapidly with a few training\nexamples. This has led to the generalizability of the developed model towards\nnew classes with just a few labelled samples. However these networks are seen\nas black-box models and understanding the representations learnt under\ndifferent learning scenarios is crucial. Neural collapse ($\\mathcal{NC}$) is a\nrecently discovered phenomenon which showcases unique properties at the network\nproceeds towards zero loss. The input features collapse to their respective\nclass means, the class means form a Simplex equiangular tight frame (ETF) where\nthe class means are maximally distant and linearly separable, and the\nclassifier acts as a simple nearest neighbor classifier. While these phenomena\nhave been observed in simple classification networks, this study is the first\nto explore and understand the properties of neural collapse in meta learning\nframeworks for few-shot learning. We perform studies on the Omniglot dataset in\nthe few-shot setting and study the neural collapse phenomenon. We observe that\nthe learnt features indeed have the trend of neural collapse, especially as\nmodel size grows, but to do not necessarily showcase the complete collapse as\nmeasured by the $\\mathcal{NC}$ properties.\n",
                "链接": "https://arxiv.org/abs/2310.00451"
            }
        ]
    },
    {
        "question": {
            "question": "查找大语言模型相关的分析类型的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "70928",
                "标题": "Revolutionizing Single Cell Analysis: The Power of Large Language Models\n  for Cell Type Annotation",
                "作者": " Zehua Zeng,  Hongwu Du",
                "发布日期": "2023-04-07",
                "摘要": "  In recent years, single cell RNA sequencing has become a widely used\ntechnique to study cellular diversity and function. However, accurately\nannotating cell types from single cell data has been a challenging task, as it\nrequires extensive knowledge of cell biology and gene function. The emergence\nof large language models such as ChatGPT and New Bing in 2023 has\nrevolutionized this process by integrating the scientific literature and\nproviding accurate annotations of cell types. This breakthrough enables\nresearchers to conduct literature reviews more efficiently and accurately, and\ncan potentially uncover new insights into cell type annotation. By using\nChatGPT to annotate single cell data, we can relate rare cell type to their\nfunction and reveal specific differentiation trajectories of cell subtypes that\nwere previously overlooked. This can have important applications in\nunderstanding cancer progression, mammalian development, and stem cell\ndifferentiation, and can potentially lead to the discovery of key cells that\ninterrupt the differentiation pathway and solve key problems in the life\nsciences. Overall, the future of cell type annotation in single cell data looks\npromising and the Large Language model will be an important milestone in the\nhistory of single cell analysis.\n",
                "链接": "https://arxiv.org/abs/2304.02697"
            },
            {
                "文章ID": "75161",
                "标题": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
                "作者": " Eddie Guo,  Mehul Gupta,  Jiawen Deng,  Ye-Jean Park,  Mike Paget,  Christopher Naugler",
                "发布日期": "2023-10-09",
                "摘要": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
                "链接": "https://arxiv.org/abs/2305.00844"
            },
            {
                "文章ID": "105266",
                "标题": "A Large Language Model Approach to Educational Survey Feedback Analysis",
                "作者": " Michael J. Parker,  Caitlin Anderson,  Claire Stone,  YeaRim Oh",
                "发布日期": "2023-10-02",
                "摘要": "  This paper assesses the potential for the large language models (LLMs) GPT-4\nand GPT-3.5 to aid in deriving insight from education feedback surveys.\nExploration of LLM use cases in education has focused on teaching and learning,\nwith less exploration of capabilities in education feedback analysis. Survey\nanalysis in education involves goals such as finding gaps in curricula or\nevaluating teachers, often requiring time-consuming manual processing of\ntextual responses. LLMs have the potential to provide a flexible means of\nachieving these goals without specialized machine learning models or\nfine-tuning. We demonstrate a versatile approach to such goals by treating them\nas sequences of natural language processing (NLP) tasks including\nclassification (multi-label, multi-class, and binary), extraction, thematic\nanalysis, and sentiment analysis, each performed by LLM. We apply these\nworkflows to a real-world dataset of 2500 end-of-course survey comments from\nbiomedical science courses, and evaluate a zero-shot approach (i.e., requiring\nno examples or labeled training data) across all tasks, reflecting education\nsettings, where labeled data is often scarce. By applying effective prompting\npractices, we achieve human-level performance on multiple tasks with GPT-4,\nenabling workflows necessary to achieve typical goals. We also show the\npotential of inspecting LLMs' chain-of-thought (CoT) reasoning for providing\ninsight that may foster confidence in practice. Moreover, this study features\ndevelopment of a versatile set of classification categories, suitable for\nvarious course types (online, hybrid, or in-person) and amenable to\ncustomization. Our results suggest that LLMs can be used to derive a range of\ninsights from survey text.\n",
                "链接": "https://arxiv.org/abs/2309.17447"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            },
            {
                "文章ID": "39922",
                "标题": "Family-Based Fingerprint Analysis: A Position Paper",
                "作者": " Carlos Diego Nascimento Damasceno,  Daniel Strüber",
                "发布日期": "2022-10-03",
                "摘要": "  Thousands of vulnerabilities are reported on a monthly basis to security\nrepositories, such as the National Vulnerability Database. Among these\nvulnerabilities, software misconfiguration is one of the top 10 security risks\nfor web applications. With this large influx of vulnerability reports, software\nfingerprinting has become a highly desired capability to discover distinctive\nand efficient signatures and recognize reportedly vulnerable software\nimplementations. Due to the exponential worst-case complexity of fingerprint\nmatching, designing more efficient methods for fingerprinting becomes highly\ndesirable, especially for variability-intensive systems where optional features\nadd another exponential factor to its analysis. This position paper presents\nour vision of a framework that lifts model learning and family-based analysis\nprinciples to software fingerprinting. In this framework, we propose unifying\ndatabases of signatures into a featured finite state machine and using presence\nconditions to specify whether and in which circumstances a given input-output\ntrace is observed. We believe feature-based signatures can aid performance\nimprovements by reducing the size of fingerprints under analysis.\n",
                "链接": "https://arxiv.org/abs/2209.15620"
            },
            {
                "文章ID": "67132",
                "标题": "TypeT5: Seq2seq Type Inference using Static Analysis",
                "作者": " Jiayi Wei,  Greg Durrett,  Isil Dillig",
                "发布日期": "2023-03-20",
                "摘要": "  There has been growing interest in automatically predicting missing type\nannotations in programs written in Python and JavaScript. While prior methods\nhave achieved impressive accuracy when predicting the most common types, they\noften perform poorly on rare or complex types. In this paper, we present a new\ntype inference method that treats type prediction as a code infilling task by\nleveraging CodeT5, a state-of-the-art seq2seq pre-trained language model for\ncode. Our method uses static analysis to construct dynamic contexts for each\ncode element whose type signature is to be predicted by the model. We also\npropose an iterative decoding scheme that incorporates previous type\npredictions in the model's input context, allowing information exchange between\nrelated code elements. Our evaluation shows that the proposed approach, TypeT5,\nnot only achieves a higher overall accuracy (particularly on rare and complex\ntypes) but also produces more coherent results with fewer type errors -- while\nenabling easy user intervention.\n",
                "链接": "https://arxiv.org/abs/2303.09564"
            },
            {
                "文章ID": "73257",
                "标题": "SurgicalGPT: End-to-End Language-Vision GPT for Visual Question\n  Answering in Surgery",
                "作者": " Lalithkumar Seenivasan,  Mobarakol Islam,  Gokul Kannan,  Hongliang Ren",
                "发布日期": "2023-07-25",
                "摘要": "  Advances in GPT-based large language models (LLMs) are revolutionizing\nnatural language processing, exponentially increasing its use across various\ndomains. Incorporating uni-directional attention, these autoregressive LLMs can\ngenerate long and coherent paragraphs. However, for visual question answering\n(VQA) tasks that require both vision and language processing, models with\nbi-directional attention or models employing fusion techniques are often\nemployed to capture the context of multiple modalities all at once. As GPT does\nnot natively process vision tokens, to exploit the advancements in GPT models\nfor VQA in robotic surgery, we design an end-to-end trainable Language-Vision\nGPT (LV-GPT) model that expands the GPT2 model to include vision input (image).\nThe proposed LV-GPT incorporates a feature extractor (vision tokenizer) and\nvision token embedding (token type and pose). Given the limitations of\nunidirectional attention in GPT models and their ability to generate coherent\nlong paragraphs, we carefully sequence the word tokens before vision tokens,\nmimicking the human thought process of understanding the question to infer an\nanswer from an image. Quantitatively, we prove that the LV-GPT model\noutperforms other state-of-the-art VQA models on two publically available\nsurgical-VQA datasets (based on endoscopic vision challenge robotic scene\nsegmentation 2018 and CholecTriplet2021) and on our newly annotated dataset\n(based on the holistic surgical scene dataset). We further annotate all three\ndatasets to include question-type annotations to allow sub-type analysis.\nFurthermore, we extensively study and present the effects of token sequencing,\ntoken type and pose embedding for vision tokens in the LV-GPT model.\n",
                "链接": "https://arxiv.org/abs/2304.09974"
            },
            {
                "文章ID": "94373",
                "标题": "FinVis-GPT: A Multimodal Large Language Model for Financial Chart\n  Analysis",
                "作者": " Ziao Wang,  Yuhang Li,  Junda Wu,  Jaehyeon Soon,  Xiaofeng Zhang",
                "发布日期": "2023-08-04",
                "摘要": "  In this paper, we propose FinVis-GPT, a novel multimodal large language model\n(LLM) specifically designed for financial chart analysis. By leveraging the\npower of LLMs and incorporating instruction tuning and multimodal capabilities,\nFinVis-GPT is capable of interpreting financial charts and providing valuable\nanalysis. To train FinVis-GPT, a financial task oriented dataset was generated\nfor pre-training alignment and instruction tuning, comprising various types of\nfinancial charts and their corresponding descriptions. We evaluate the model\nperformance via several case studies due to the time limit, and the promising\nresults demonstrated that FinVis-GPT is superior in various financial chart\nrelated tasks, including generating descriptions, answering questions and\npredicting future market trends, surpassing existing state-of-the-art\nmultimodal LLMs. The proposed FinVis-GPT serves as a pioneering effort in\nutilizing multimodal LLMs in the finance domain and our generated dataset will\nbe release for public use in the near future to speedup related research.\n",
                "链接": "https://arxiv.org/abs/2308.01430"
            },
            {
                "文章ID": "110493",
                "标题": "LUNA: A Model-Based Universal Analysis Framework for Large Language\n  Models",
                "作者": " Da Song,  Xuan Xie,  Jiayang Song,  Derui Zhu,  Yuheng Huang,  Felix Juefei-Xu,  Lei Ma",
                "发布日期": "2023-10-24",
                "摘要": "  Over the past decade, Artificial Intelligence (AI) has had great success\nrecently and is being used in a wide range of academic and industrial fields.\nMore recently, LLMs have made rapid advancements that have propelled AI to a\nnew level, enabling even more diverse applications and industrial domains with\nintelligence, particularly in areas like software engineering and natural\nlanguage processing. Nevertheless, a number of emerging trustworthiness\nconcerns and issues exhibited in LLMs have already recently received much\nattention, without properly solving which the widespread adoption of LLMs could\nbe greatly hindered in practice. The distinctive characteristics of LLMs, such\nas the self-attention mechanism, extremely large model scale, and\nautoregressive generation schema, differ from classic AI software based on CNNs\nand RNNs and present new challenges for quality analysis. Up to the present, it\nstill lacks universal and systematic analysis techniques for LLMs despite the\nurgent industrial demand. Towards bridging this gap, we initiate an early\nexploratory study and propose a universal analysis framework for LLMs, LUNA,\ndesigned to be general and extensible, to enable versatile analysis of LLMs\nfrom multiple quality perspectives in a human-interpretable manner. In\nparticular, we first leverage the data from desired trustworthiness\nperspectives to construct an abstract model as an auxiliary analysis asset,\nwhich is empowered by various abstract model construction methods. To assess\nthe quality of the abstract model, we collect and define a number of evaluation\nmetrics, aiming at both abstract model level and the semantics level. Then, the\nsemantics, which is the degree of satisfaction of the LLM w.r.t. the\ntrustworthiness perspective, is bound to and enriches the abstract model with\nsemantics, which enables more detailed analysis applications for diverse\npurposes.\n",
                "链接": "https://arxiv.org/abs/2310.14211"
            }
        ]
    },
    {
        "question": {
            "question": "查询2022年以来指令遵循数据集构建相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "23375",
                "标题": "DLT Compliance Reporting",
                "作者": " Henrik Axelsen,  Johannes Rude Jensen,  Omri Ross",
                "发布日期": "2022-06-08",
                "摘要": "  The IS discourse on the potential of distributed ledger technology (DLT) in\nthe financial services has grown at a tremendous pace in recent years. Yet,\nlittle has been said about the related implications for the costly and highly\nregulated process of compliance reporting. Working with a group of\nrepresentatives from industry and regulatory authorities, we employ the design\nscience research methodology (DSR) in the design, development, and evaluation\nof an artefact, enabling the automated collection and enrichment of\ntransactional data. Our findings indicate that DLT may facilitate the\nautomation of key compliance processes through the implementation of a\n\"pull-model\", in which regulators can access compliance data in near real-time\nto stage aggregate exposures at the supranational level. Generalizing our\npreliminary results, we present four propositions on the implications of DLT in\ncompliance. The findings contribute new practical insights on the topic of\ncompliance to the growing IS discourse on DLT.\n",
                "链接": "https://arxiv.org/abs/2206.03270"
            },
            {
                "文章ID": "15105",
                "标题": "Stateless and Rule-Based Verification For Compliance Checking\n  Applications",
                "作者": " Mohammad Reza Besharati,  Mohammad Izadi,  Ehsaneddin Asgari",
                "发布日期": "2022-05-02",
                "摘要": "  Underlying computational model has an important role in any computation. The\nstate and transition (such as in automata) and rule and value (such as in Lisp\nand logic programming) are two comparable and counterpart computational models.\nBoth of deductive and model checking verification techniques are relying on a\nnotion of state and as a result, their underlying computational models are\nstate dependent. Some verification problems (such as compliance checking by\nwhich an under compliance system is verified against some regulations and\nrules) have not a strong notion of state nor transition. Behalf of it, these\nsystems have a strong notion of value symbols and declarative rules defined on\nthem. SARV (Stateless And Rule-Based Verification) is a verification framework\nthat designed to simplify the overall process of verification for stateless and\nrule-based verification problems (e.g. compliance checking). In this paper, a\nformal logic-based framework for creating intelligent compliance checking\nsystems is presented. We define and introduce this framework, report a case\nstudy and present results of an experiment on it. The case study is about\nprotocol compliance checking for smart cities. Using this solution, a Rescue\nScenario use case and its compliance checking are sketched and modeled. An\nautomation engine for and a compliance solution with SARV are introduced. Based\non 300 data experiments, the SARV-based compliance solution outperforms famous\nmachine learning methods on a 3125-records software quality dataset.\n",
                "链接": "https://arxiv.org/abs/2204.07430"
            },
            {
                "文章ID": "120242",
                "标题": "MUFFIN: Curating Multi-Faceted Instructions for Improving\n  Instruction-Following",
                "作者": " Renze Lou,  Kai Zhang,  Jian Xie,  Yuxuan Sun,  Janice Ahn,  Hanzi Xu,  Yu Su,  Wenpeng Yin",
                "发布日期": "2023-12-06",
                "摘要": "  In the realm of large language models (LLMs), enhancing instruction-following\ncapability often involves curating expansive training data. This is achieved\nthrough two primary schemes: i) Scaling-Inputs: Amplifying (input, output)\npairs per task instruction, aiming for better instruction adherence. ii)\nScaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction,\noutput) pair (without requiring a separate input anymore). However, LLMs under\nScaling-Inputs tend to be overly sensitive to inputs, leading to\nmisinterpretation or non-compliance with instructions. Conversely, Scaling\nInput-Free Tasks demands a substantial number of tasks but is less effective in\ninstruction following when dealing with instances in Scaling-Inputs. This work\nintroduces MUFFIN, a new scheme of instruction-following dataset curation.\nSpecifically, we automatically Scale Tasks per Input by diversifying these\ntasks with various input facets. Experimental results across four zero-shot\nbenchmarks, spanning both Scaling-Inputs and Scaling Input-Free Tasks schemes,\nreveal that LLMs, at various scales, trained on MUFFIN generally demonstrate\nsuperior instruction-following capabilities compared to those trained on the\ntwo aforementioned schemes.\n",
                "链接": "https://arxiv.org/abs/2312.02436"
            },
            {
                "文章ID": "6215",
                "标题": "SODA: Site Object Detection dAtaset for Deep Learning in Construction",
                "作者": " Rui Duan,  Hui Deng,  Mao Tian,  Yichuan Deng,  Jiarui Lin",
                "发布日期": "2023-05-18",
                "摘要": "  Computer vision-based deep learning object detection algorithms have been\ndeveloped sufficiently powerful to support the ability to recognize various\nobjects. Although there are currently general datasets for object detection,\nthere is still a lack of large-scale, open-source dataset for the construction\nindustry, which limits the developments of object detection algorithms as they\ntend to be data-hungry. Therefore, this paper develops a new large-scale image\ndataset specifically collected and annotated for the construction site, called\nSite Object Detection dAtaset (SODA), which contains 15 kinds of object classes\ncategorized by workers, materials, machines, and layout. Firstly, more than\n20,000 images were collected from multiple construction sites in different site\nconditions, weather conditions, and construction phases, which covered\ndifferent angles and perspectives. After careful screening and processing,\n19,846 images including 286,201 objects were then obtained and annotated with\nlabels in accordance with predefined categories. Statistical analysis shows\nthat the developed dataset is advantageous in terms of diversity and volume.\nFurther evaluation with two widely-adopted object detection algorithms based on\ndeep learning (YOLO v3/ YOLO v4) also illustrates the feasibility of the\ndataset for typical construction scenarios, achieving a maximum mAP of 81.47%.\nIn this manner, this research contributes a large-scale image dataset for the\ndevelopment of deep learning-based object detection methods in the construction\nindustry and sets up a performance benchmark for further evaluation of\ncorresponding algorithms in this area.\n",
                "链接": "https://arxiv.org/abs/2202.09554"
            },
            {
                "文章ID": "119138",
                "标题": "Automatic Construction of a Korean Toxic Instruction Dataset for Ethical\n  Tuning of Large Language Models",
                "作者": " Sungjoo Byun,  Dongjun Jang,  Hyemi Jo,  Hyopil Shin",
                "发布日期": "2023-12-01",
                "摘要": "  Caution: this paper may include material that could be offensive or\ndistressing.\n  The advent of Large Language Models (LLMs) necessitates the development of\ntraining approaches that mitigate the generation of unethical language and\naptly manage toxic user queries. Given the challenges related to human labor\nand the scarcity of data, we present KoTox, comprising 39K unethical\ninstruction-output pairs. This collection of automatically generated toxic\ninstructions refines the training of LLMs and establishes a foundational\nframework for improving LLMs' ethical awareness and response to various toxic\ninputs, promoting more secure and responsible interactions in Natural Language\nProcessing (NLP) applications.\n",
                "链接": "https://arxiv.org/abs/2311.18215"
            },
            {
                "文章ID": "97640",
                "标题": "Instruction Tuning for Large Language Models: A Survey",
                "作者": " Shengyu Zhang,  Linfeng Dong,  Xiaoya Li,  Sen Zhang,  Xiaofei Sun,  Shuhe Wang,  Jiwei Li,  Runyi Hu,  Tianwei Zhang,  Fei Wu,  Guoyin Wang",
                "发布日期": "2023-10-10",
                "摘要": "  This paper surveys research works in the quickly advancing field of\ninstruction tuning (IT), a crucial technique to enhance the capabilities and\ncontrollability of large language models (LLMs). Instruction tuning refers to\nthe process of further training LLMs on a dataset consisting of\n\\textsc{(instruction, output)} pairs in a supervised fashion, which bridges the\ngap between the next-word prediction objective of LLMs and the users' objective\nof having LLMs adhere to human instructions. In this work, we make a systematic\nreview of the literature, including the general methodology of IT, the\nconstruction of IT datasets, the training of IT models, and applications to\ndifferent modalities, domains and applications, along with an analysis on\naspects that influence the outcome of IT (e.g., generation of instruction\noutputs, size of the instruction dataset, etc). We also review the potential\npitfalls of IT along with criticism against it, along with efforts pointing out\ncurrent deficiencies of existing strategies and suggest some avenues for\nfruitful research. Project page: github.com/xiaoya-li/Instruction-Tuning-Survey\n",
                "链接": "https://arxiv.org/abs/2308.10792"
            },
            {
                "文章ID": "78681",
                "标题": "InstructIE: A Chinese Instruction-based Information Extraction Dataset",
                "作者": " Honghao Gui,  Jintian Zhang,  Hongbin Ye,  Ningyu Zhang",
                "发布日期": "2023-05-22",
                "摘要": "  We introduce a new Information Extraction (IE) task dubbed Instruction-based\nIE, which aims to ask the system to follow specific instructions or guidelines\nto extract information. To facilitate research in this area, we construct a\ndataset called InstructIE, consisting of 270,000 weakly supervised data from\nChinese Wikipedia and 1,000 high-quality crowdsourced annotated instances. We\nfurther evaluate the performance of various baseline models on the InstructIE\ndataset. The results reveal that although current models exhibit promising\nperformance, there is still room for improvement. Furthermore, we conduct a\ncomprehensive case study analysis, underlining the challenges inherent in the\nInstruction-based IE task. Code and dataset are available at\nhttps://github.com/zjunlp/DeepKE/tree/main/example/llm.\n",
                "链接": "https://arxiv.org/abs/2305.11527"
            },
            {
                "文章ID": "115619",
                "标题": "Vision-Language Instruction Tuning: A Review and Analysis",
                "作者": " Chen Li,  Yixiao Ge,  Dian Li,  Ying Shan",
                "发布日期": "2023-11-28",
                "摘要": "  Instruction tuning is a crucial supervised training phase in Large Language\nModels (LLMs), aiming to enhance the LLM's ability to generalize instruction\nexecution and adapt to user preferences. With the increasing integration of\nmulti-modal data into LLMs, there is growing interest in Vision-Language\nInstruction Tuning (VLIT), which presents more complex characteristics compared\nto pure text instruction tuning. In this paper, we systematically review the\nlatest VLIT settings and corresponding datasets in multi-modal LLMs and provide\ninsights into the intrinsic motivations behind their design. For the first\ntime, we offer a detailed multi-perspective categorization for existing VLIT\ndatasets and identify the characteristics that high-quality VLIT data should\npossess. By incorporating these characteristics as guiding principles into the\nexisting VLIT data construction process, we conduct extensive experiments and\nverify their positive impact on the performance of tuned multi-modal LLMs.\nFurthermore, we discuss the current challenges and future research directions\nof VLIT, providing insights for the continuous development of this field. The\ncode and dataset related to this paper have been open-sourced at\nhttps://github.com/palchenli/VL-Instruction-Tuning.\n",
                "链接": "https://arxiv.org/abs/2311.08172"
            },
            {
                "文章ID": "100738",
                "标题": "From Base to Conversational: Japanese Instruction Dataset and Tuning\n  Large Language Models",
                "作者": " Masahiro Suzuki,  Masanori Hirano,  Hiroki Sakaji",
                "发布日期": "2023-11-07",
                "摘要": "  Instruction tuning is essential for large language models (LLMs) to become\ninteractive. While many instruction tuning datasets exist in English, there is\na noticeable lack in other languages. Also, their effectiveness has not been\nwell verified in non-English languages. We construct a Japanese instruction\ndataset by expanding and filtering existing datasets and apply the dataset to a\nJapanese pre-trained base model. We performed Low-Rank Adaptation (LoRA) tuning\non both Japanese and English existing models using our instruction dataset. We\nevaluated these models from both quantitative and qualitative perspectives. As\na result, the effectiveness of Japanese instruction datasets is confirmed. The\nresults also indicate that even with relatively small LLMs, performances in\ndownstream tasks would be improved through instruction tuning. Our instruction\ndataset, tuned models, and implementation are publicly available online.\n",
                "链接": "https://arxiv.org/abs/2309.03412"
            },
            {
                "文章ID": "125130",
                "标题": "ConstScene: Dataset and Model for Advancing Robust Semantic Segmentation\n  in Construction Environments",
                "作者": " Maghsood Salimi,  Mohammad Loni,  Sara Afshar,  Marjan Sirjani,  Antonio Cicchetti",
                "发布日期": "2023-12-29",
                "摘要": "  The increasing demand for autonomous machines in construction environments\nnecessitates the development of robust object detection algorithms that can\nperform effectively across various weather and environmental conditions. This\npaper introduces a new semantic segmentation dataset specifically tailored for\nconstruction sites, taking into account the diverse challenges posed by adverse\nweather and environmental conditions. The dataset is designed to enhance the\ntraining and evaluation of object detection models, fostering their\nadaptability and reliability in real-world construction applications. Our\ndataset comprises annotated images captured under a wide range of different\nweather conditions, including but not limited to sunny days, rainy periods,\nfoggy atmospheres, and low-light situations. Additionally, environmental\nfactors such as the existence of dirt/mud on the camera lens are integrated\ninto the dataset through actual captures and synthetic generation to simulate\nthe complex conditions prevalent in construction sites. We also generate\nsynthetic images of the annotations including precise semantic segmentation\nmasks for various objects commonly found in construction environments, such as\nwheel loader machines, personnel, cars, and structural elements. To demonstrate\nthe dataset's utility, we evaluate state-of-the-art object detection algorithms\non our proposed benchmark. The results highlight the dataset's success in\nadversarial training models across diverse conditions, showcasing its efficacy\ncompared to existing datasets that lack such environmental variability.\n",
                "链接": "https://arxiv.org/abs/2312.16516"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于gpt4自动生成prompt的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "118879",
                "标题": "TARGET: Template-Transferable Backdoor Attack Against Prompt-based NLP\n  Models via GPT4",
                "作者": " Zihao Tan,  Qingliang Chen,  Yongjian Huang,  Chen Liang",
                "发布日期": "2023-11-30",
                "摘要": "  Prompt-based learning has been widely applied in many low-resource NLP tasks\nsuch as few-shot scenarios. However, this paradigm has been shown to be\nvulnerable to backdoor attacks. Most of the existing attack methods focus on\ninserting manually predefined templates as triggers in the pre-training phase\nto train the victim model and utilize the same triggers in the downstream task\nto perform inference, which tends to ignore the transferability and\nstealthiness of the templates. In this work, we propose a novel approach of\nTARGET (Template-trAnsfeRable backdoor attack aGainst prompt-basEd NLP models\nvia GPT4), which is a data-independent attack method. Specifically, we first\nutilize GPT4 to reformulate manual templates to generate tone-strong and normal\ntemplates, and the former are injected into the model as a backdoor trigger in\nthe pre-training phase. Then, we not only directly employ the above templates\nin the downstream task, but also use GPT4 to generate templates with similar\ntone to the above templates to carry out transferable attacks. Finally we have\nconducted extensive experiments on five NLP datasets and three BERT series\nmodels, with experimental results justifying that our TARGET method has better\nattack performance and stealthiness compared to the two-external baseline\nmethods on direct attacks, and in addition achieves satisfactory attack\ncapability in the unseen tone-similar templates.\n",
                "链接": "https://arxiv.org/abs/2311.17429"
            },
            {
                "文章ID": "103106",
                "标题": "Is GPT4 a Good Trader?",
                "作者": " Bingzhe Wu",
                "发布日期": "2023-09-21",
                "摘要": "  Recently, large language models (LLMs), particularly GPT-4, have demonstrated\nsignificant capabilities in various planning and reasoning tasks\n\\cite{cheng2023gpt4,bubeck2023sparks}. Motivated by these advancements, there\nhas been a surge of interest among researchers to harness the capabilities of\nGPT-4 for the automated design of quantitative factors that do not overlap with\nexisting factor libraries, with an aspiration to achieve alpha returns\n\\cite{webpagequant}. In contrast to these work, this study aims to examine the\nfidelity of GPT-4's comprehension of classic trading theories and its\nproficiency in applying its code interpreter abilities to real-world trading\ndata analysis. Such an exploration is instrumental in discerning whether the\nunderlying logic GPT-4 employs for trading is intrinsically reliable.\nFurthermore, given the acknowledged interpretative latitude inherent in most\ntrading theories, we seek to distill more precise methodologies of deploying\nthese theories from GPT-4's analytical process, potentially offering invaluable\ninsights to human traders.\n  To achieve this objective, we selected daily candlestick (K-line) data from\nspecific periods for certain assets, such as the Shanghai Stock Index. Through\nmeticulous prompt engineering, we guided GPT-4 to analyze the technical\nstructures embedded within this data, based on specific theories like the\nElliott Wave Theory. We then subjected its analytical output to manual\nevaluation, assessing its interpretative depth and accuracy vis-\\`a-vis these\ntrading theories from multiple dimensions. The results and findings from this\nstudy could pave the way for a synergistic amalgamation of human expertise and\nAI-driven insights in the realm of trading.\n",
                "链接": "https://arxiv.org/abs/2309.10982"
            },
            {
                "文章ID": "103691",
                "标题": "OpenAi's GPT4 as coding assistant",
                "作者": " Lefteris Moussiades,  George Zografos",
                "发布日期": "2023-09-25",
                "摘要": "  Lately, Large Language Models have been widely used in code generation. GPT4\nis considered the most potent Large Language Model from Openai. In this paper,\nwe examine GPT3.5 and GPT4 as coding assistants. More specifically, we have\nconstructed appropriate tests to check whether the two systems can a) answer\ntypical questions that can arise during the code development, b) produce\nreliable code, and c) contribute to code debugging. The test results are\nimpressive. The performance of GPT4 is outstanding and signals an increase in\nthe productivity of programmers and the reorganization of software development\nprocedures based on these new tools.\n",
                "链接": "https://arxiv.org/abs/2309.12732"
            },
            {
                "文章ID": "34967",
                "标题": "AutoQGS: Auto-Prompt for Low-Resource Knowledge-based Question\n  Generation from SPARQL",
                "作者": " Guanming Xiong,  Junwei Bao,  Wen Zhao,  Youzheng Wu,  Xiaodong He",
                "发布日期": "2022-08-29",
                "摘要": "  This study investigates the task of knowledge-based question generation\n(KBQG). Conventional KBQG works generated questions from fact triples in the\nknowledge graph, which could not express complex operations like aggregation\nand comparison in SPARQL. Moreover, due to the costly annotation of large-scale\nSPARQL-question pairs, KBQG from SPARQL under low-resource scenarios urgently\nneeds to be explored. Recently, since the generative pre-trained language\nmodels (PLMs) typically trained in natural language (NL)-to-NL paradigm have\nbeen proven effective for low-resource generation, e.g., T5 and BART, how to\neffectively utilize them to generate NL-question from non-NL SPARQL is\nchallenging. To address these challenges, AutoQGS, an auto-prompt approach for\nlow-resource KBQG from SPARQL, is proposed. Firstly, we put forward to generate\nquestions directly from SPARQL for the KBQG task to handle complex operations.\nSecondly, we propose an auto-prompter trained on large-scale unsupervised data\nto rephrase SPARQL into NL description, smoothing the low-resource\ntransformation from non-NL SPARQL to NL question with PLMs. Experimental\nresults on the WebQuestionsSP, ComlexWebQuestions 1.1, and PathQuestions show\nthat our model achieves state-of-the-art performance, especially in\nlow-resource settings. Furthermore, a corpus of 330k factoid complex\nquestion-SPARQL pairs is generated for further KBQG research.\n",
                "链接": "https://arxiv.org/abs/2208.12461"
            },
            {
                "文章ID": "116159",
                "标题": "Do Physicians Know How to Prompt? The Need for Automatic Prompt\n  Optimization Help in Clinical Note Generation",
                "作者": " Zonghai Yao,  Ahmed Jaafar,  Beining Wang,  Yue Zhu,  Zhichao Yang,  Hong Yu",
                "发布日期": "2023-11-17",
                "摘要": "  This study examines the effect of prompt engineering on the performance of\nLarge Language Models (LLMs) in clinical note generation. We introduce an\nAutomatic Prompt Optimization (APO) framework to refine initial prompts and\ncompare the outputs of medical experts, non-medical experts, and APO-enhanced\nGPT3.5 and GPT4. Results highlight GPT4 APO's superior performance in\nstandardizing prompt quality across clinical note sections. A human-in-the-loop\napproach shows that experts maintain content quality post-APO, with a\npreference for their own modifications, suggesting the value of expert\ncustomization. We recommend a two-phase optimization process, leveraging\nAPO-GPT4 for consistency and expert input for personalization.\n",
                "链接": "https://arxiv.org/abs/2311.09684"
            },
            {
                "文章ID": "123546",
                "标题": "Assessing GPT4-V on Structured Reasoning Tasks",
                "作者": " Mukul Singh,  José Cambronero,  Sumit Gulwani,  Vu Le,  Gust Verbruggen",
                "发布日期": "2023-12-20",
                "摘要": "  Multi-modality promises to unlock further uses for large language models.\nRecently, the state-of-the-art language model GPT-4 was enhanced with vision\ncapabilities. We carry out a prompting evaluation of GPT-4V and five other\nbaselines on structured reasoning tasks, such as mathematical reasoning, visual\ndata analysis, and code generation. We show that visual Chain-of-Thought, an\nextension of Chain-of-Thought to multi-modal LLMs, yields significant\nimprovements over the vanilla model. We also present a categorized analysis of\nscenarios where these models perform well and where they struggle, highlighting\nchallenges associated with coherent multimodal reasoning.\n",
                "链接": "https://arxiv.org/abs/2312.11524"
            },
            {
                "文章ID": "90467",
                "标题": "GPT4 is Slightly Helpful for Peer-Review Assistance: A Pilot Study",
                "作者": " Zachary Robertson",
                "发布日期": "2023-07-13",
                "摘要": "  In this pilot study, we investigate the use of GPT4 to assist in the\npeer-review process. Our key hypothesis was that GPT-generated reviews could\nachieve comparable helpfulness to human reviewers. By comparing reviews\ngenerated by both human reviewers and GPT models for academic papers submitted\nto a major machine learning conference, we provide initial evidence that\nartificial intelligence can contribute effectively to the peer-review process.\nWe also perform robustness experiments with inserted errors to understand which\nparts of the paper the model tends to focus on. Our findings open new avenues\nfor leveraging machine learning tools to address resource constraints in peer\nreview. The results also shed light on potential enhancements to the review\nprocess and lay the groundwork for further research on scaling oversight in a\ndomain where human-feedback is increasingly a scarce resource.\n",
                "链接": "https://arxiv.org/abs/2307.05492"
            },
            {
                "文章ID": "116443",
                "标题": "Segment Anything Model with Uncertainty Rectification for Auto-Prompting\n  Medical Image Segmentation",
                "作者": " Yichi Zhang,  Shiyao Hu,  Chen Jiang,  Yuan Cheng,  Yuan Qi",
                "发布日期": "2023-12-14",
                "摘要": "  The introduction of the Segment Anything Model (SAM) has marked a significant\nadvancement in prompt-driven image segmentation. However, SAM's application to\nmedical image segmentation requires manual prompting of target structures to\nobtain acceptable performance, which is still labor-intensive. Despite attempts\nof auto-prompting to turn SAM into a fully automatic manner, it still exhibits\nsubpar performance and lacks of reliability in the field of medical imaging. In\nthis paper, we propose UR-SAM, an uncertainty rectified SAM framework to\nenhance the robustness and reliability for auto-prompting medical image\nsegmentation. Our method incorporates a prompt augmentation module to estimate\nthe distribution of predictions and generate uncertainty maps, and an\nuncertainty-based rectification module to further enhance the performance of\nSAM. Extensive experiments on two public 3D medical datasets covering the\nsegmentation of 35 organs demonstrate that without supplementary training or\nfine-tuning, our method further improves the segmentation performance with up\nto 10.7 % and 13.8 % in dice similarity coefficient, demonstrating efficiency\nand broad capabilities for medical image segmentation without manual prompting.\n",
                "链接": "https://arxiv.org/abs/2311.10529"
            },
            {
                "文章ID": "89555",
                "标题": "What Matters in Training a GPT4-Style Language Model with Multimodal\n  Inputs?",
                "作者": " Yan Zeng,  Hanbo Zhang,  Jiani Zheng,  Jiangnan Xia,  Guoqiang Wei,  Yang Wei,  Yuchen Zhang,  Tao Kong",
                "发布日期": "2023-08-01",
                "摘要": "  Recent advancements in Large Language Models (LLMs) such as GPT4 have\ndisplayed exceptional multi-modal capabilities in following open-ended\ninstructions given images. However, the performance of these models heavily\nrelies on design choices such as network structures, training data, and\ntraining strategies, and these choices have not been extensively discussed in\nthe literature, making it difficult to quantify progress in this field. To\naddress this issue, this paper presents a systematic and comprehensive study,\nquantitatively and qualitatively, on training such models. We implement over 20\nvariants with controlled settings. Concretely, for network structures, we\ncompare different LLM backbones and model designs. For training data, we\ninvestigate the impact of data and sampling strategies. For instructions, we\nexplore the influence of diversified prompts on the instruction-following\nability of the trained models. For benchmarks, we contribute the first, to our\nbest knowledge, comprehensive evaluation set including both image and video\ntasks through crowd-sourcing. Based on our findings, we present Lynx, which\nperforms the most accurate multi-modal understanding while keeping the best\nmulti-modal generation ability compared to existing open-sourced GPT4-style\nmodels.\n",
                "链接": "https://arxiv.org/abs/2307.02469"
            },
            {
                "文章ID": "106886",
                "标题": "Auto-survey Challenge",
                "作者": "TAU, LISN  Thanh Gia Hieu Khuong, TAU, LISN  Benedictus Kent Rachmat",
                "发布日期": "2023-10-11",
                "摘要": "  We present a novel platform for evaluating the capability of Large Language\nModels (LLMs) to autonomously compose and critique survey papers spanning a\nvast array of disciplines including sciences, humanities, education, and law.\nWithin this framework, AI systems undertake a simulated peer-review mechanism\nakin to traditional scholarly journals, with human organizers serving in an\neditorial oversight capacity. Within this framework, we organized a competition\nfor the AutoML conference 2023. Entrants are tasked with presenting stand-alone\nmodels adept at authoring articles from designated prompts and subsequently\nappraising them. Assessment criteria include clarity, reference\nappropriateness, accountability, and the substantive value of the content. This\npaper presents the design of the competition, including the implementation\nbaseline submissions and methods of evaluation.\n",
                "链接": "https://arxiv.org/abs/2310.04480"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态agent, 具身智能的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "114225",
                "标题": "Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI",
                "作者": " Song Yaoxian,  Sun Penglei,  Liu Haoyu,  Li Zhixu,  Song Wei,  Xiao Yanghua,  Zhou Xiaofang",
                "发布日期": "2023-11-08",
                "摘要": "  Embodied AI is one of the most popular studies in artificial intelligence and\nrobotics, which can effectively improve the intelligence of real-world agents\n(i.e. robots) serving human beings. Scene knowledge is important for an agent\nto understand the surroundings and make correct decisions in the varied open\nworld. Currently, knowledge base for embodied tasks is missing and most\nexisting work use general knowledge base or pre-trained models to enhance the\nintelligence of an agent. For conventional knowledge base, it is sparse,\ninsufficient in capacity and cost in data collection. For pre-trained models,\nthey face the uncertainty of knowledge and hard maintenance. To overcome the\nchallenges of scene knowledge, we propose a scene-driven multimodal knowledge\ngraph (Scene-MMKG) construction method combining conventional knowledge\nengineering and large language models. A unified scene knowledge injection\nframework is introduced for knowledge representation. To evaluate the\nadvantages of our proposed method, we instantiate Scene-MMKG considering\ntypical indoor robotic functionalities (Manipulation and Mobility), named\nManipMob-MMKG. Comparisons in characteristics indicate our instantiated\nManipMob-MMKG has broad superiority in data-collection efficiency and knowledge\nquality. Experimental results on typical embodied tasks show that\nknowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the\nperformance obviously without re-designing model structures complexly. Our\nproject can be found at https://sites.google.com/view/manipmob-mmkg\n",
                "链接": "https://arxiv.org/abs/2311.03783"
            },
            {
                "文章ID": "2448",
                "标题": "Learning to Act with Affordance-Aware Multimodal Neural SLAM",
                "作者": " Zhiwei Jia,  Kaixiang Lin,  Yizhou Zhao,  Qiaozi Gao,  Govind Thattai,  Gaurav Sukhatme",
                "发布日期": "2022-10-26",
                "摘要": "  Recent years have witnessed an emerging paradigm shift toward embodied\nartificial intelligence, in which an agent must learn to solve challenging\ntasks by interacting with its environment. There are several challenges in\nsolving embodied multimodal tasks, including long-horizon planning,\nvision-and-language grounding, and efficient exploration. We focus on a\ncritical bottleneck, namely the performance of planning and navigation. To\ntackle this challenge, we propose a Neural SLAM approach that, for the first\ntime, utilizes several modalities for exploration, predicts an affordance-aware\nsemantic map, and plans over it at the same time. This significantly improves\nexploration efficiency, leads to robust long-horizon planning, and enables\neffective vision-and-language grounding. With the proposed Affordance-aware\nMultimodal Neural SLAM (AMSLAM) approach, we obtain more than 40% improvement\nover prior published work on the ALFRED benchmark and set a new\nstate-of-the-art generalization performance at a success rate of 23.48% on the\ntest unseen scenes.\n",
                "链接": "https://arxiv.org/abs/2201.09862"
            },
            {
                "文章ID": "49630",
                "标题": "Improving Multimodal Interactive Agents with Reinforcement Learning from\n  Human Feedback",
                "作者": " Josh Abramson,  Arun Ahuja,  Federico Carnevale,  Petko Georgiev,  Alex Goldin,  Alden Hung,  Jessica Landon,  Jirka Lhotka,  Timothy Lillicrap,  Alistair Muldal,  George Powell,  Adam Santoro,  Guy Scully,  Sanjana Srivastava,  Tamara von Glehn,  Greg Wayne,  Nathaniel Wong,  Chen Yan,  Rui Zhu",
                "发布日期": "2022-11-22",
                "摘要": "  An important goal in artificial intelligence is to create agents that can\nboth interact naturally with humans and learn from their feedback. Here we\ndemonstrate how to use reinforcement learning from human feedback (RLHF) to\nimprove upon simulated, embodied agents trained to a base level of competency\nwith imitation learning. First, we collected data of humans interacting with\nagents in a simulated 3D world. We then asked annotators to record moments\nwhere they believed that agents either progressed toward or regressed from\ntheir human-instructed goal. Using this annotation data we leveraged a novel\nmethod - which we call \"Inter-temporal Bradley-Terry\" (IBT) modelling - to\nbuild a reward model that captures human judgments. Agents trained to optimise\nrewards delivered from IBT reward models improved with respect to all of our\nmetrics, including subsequent human judgment during live interactions with\nagents. Altogether our results demonstrate how one can successfully leverage\nhuman judgments to improve agent behaviour, allowing us to use reinforcement\nlearning in complex, embodied domains without programmatic reward functions.\nVideos of agent behaviour may be found at https://youtu.be/v_Z9F2_eKk4.\n",
                "链接": "https://arxiv.org/abs/2211.11602"
            },
            {
                "文章ID": "63780",
                "标题": "Multimodal Speech Recognition for Language-Guided Embodied Agents",
                "作者": " Allen Chang,  Xiaoyuan Zhu,  Aarav Monga,  Seoho Ahn,  Tejas Srinivasan,  Jesse Thomason",
                "发布日期": "2023-10-11",
                "摘要": "  Benchmarks for language-guided embodied agents typically assume text-based\ninstructions, but deployed agents will encounter spoken instructions. While\nAutomatic Speech Recognition (ASR) models can bridge the input gap, erroneous\nASR transcripts can hurt the agents' ability to complete tasks. In this work,\nwe propose training a multimodal ASR model to reduce errors in transcribing\nspoken instructions by considering the accompanying visual context. We train\nour model on a dataset of spoken instructions, synthesized from the ALFRED task\ncompletion dataset, where we simulate acoustic noise by systematically masking\nspoken words. We find that utilizing visual observations facilitates masked\nword recovery, with multimodal ASR models recovering up to 30% more masked\nwords than unimodal baselines. We also find that a text-trained embodied agent\nsuccessfully completes tasks more often by following transcribed instructions\nfrom multimodal ASR models. github.com/Cylumn/embodied-multimodal-asr\n",
                "链接": "https://arxiv.org/abs/2302.14030"
            },
            {
                "文章ID": "42792",
                "标题": "AVLEN: Audio-Visual-Language Embodied Navigation in 3D Environments",
                "作者": " Sudipta Paul,  Amit K. Roy-Chowdhury,  Anoop Cherian",
                "发布日期": "2022-10-17",
                "摘要": "  Recent years have seen embodied visual navigation advance in two distinct\ndirections: (i) in equipping the AI agent to follow natural language\ninstructions, and (ii) in making the navigable world multimodal, e.g.,\naudio-visual navigation. However, the real world is not only multimodal, but\nalso often complex, and thus in spite of these advances, agents still need to\nunderstand the uncertainty in their actions and seek instructions to navigate.\nTo this end, we present AVLEN~ -- an interactive agent for\nAudio-Visual-Language Embodied Navigation. Similar to audio-visual navigation\ntasks, the goal of our embodied agent is to localize an audio event via\nnavigating the 3D visual world; however, the agent may also seek help from a\nhuman (oracle), where the assistance is provided in free-form natural language.\nTo realize these abilities, AVLEN uses a multimodal hierarchical reinforcement\nlearning backbone that learns: (a) high-level policies to choose either\naudio-cues for navigation or to query the oracle, and (b) lower-level policies\nto select navigation actions based on its audio-visual and language inputs. The\npolicies are trained via rewarding for the success on the navigation task while\nminimizing the number of queries to the oracle. To empirically evaluate AVLEN,\nwe present experiments on the SoundSpaces framework for semantic audio-visual\nnavigation tasks. Our results show that equipping the agent to ask for help\nleads to a clear improvement in performance, especially in challenging cases,\ne.g., when the sound is unheard during training or in the presence of\ndistractor sounds.\n",
                "链接": "https://arxiv.org/abs/2210.07940"
            },
            {
                "文章ID": "106036",
                "标题": "Towards End-to-End Embodied Decision Making via Multi-modal Large\n  Language Model: Explorations with GPT4-Vision and Beyond",
                "作者": " Liang Chen,  Yichi Zhang,  Shuhuai Ren,  Haozhe Zhao,  Zefan Cai,  Yuchi Wang,  Peiyi Wang,  Tianyu Liu,  Baobao Chang",
                "发布日期": "2023-11-29",
                "摘要": "  In this study, we explore the potential of Multimodal Large Language Models\n(MLLMs) in improving embodied decision-making processes for agents. While Large\nLanguage Models (LLMs) have been widely used due to their advanced reasoning\nskills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual\nunderstanding and reasoning capabilities. We investigate whether\nstate-of-the-art MLLMs can handle embodied decision-making in an end-to-end\nmanner and whether collaborations between LLMs and MLLMs can enhance\ndecision-making. To address these questions, we introduce a new benchmark\ncalled PCA-EVAL, which evaluates embodied decision-making from the perspectives\nof Perception, Cognition, and Action. Additionally, we propose HOLMES, a\nmulti-agent cooperation framework that allows LLMs to leverage MLLMs and APIs\nto gather multimodal information for informed decision-making. We compare\nend-to-end embodied decision-making and HOLMES on our benchmark and find that\nthe GPT4-Vision model demonstrates strong end-to-end embodied decision-making\nabilities, outperforming GPT4-HOLMES in terms of average decision accuracy\n(+3%). However, this performance is exclusive to the latest GPT4-Vision model,\nsurpassing the open-source state-of-the-art MLLM by 26%. Our results indicate\nthat powerful MLLMs like GPT4-Vision hold promise for decision-making in\nembodied agents, offering new avenues for MLLM research. Code and data are open\nat https://github.com/pkunlp-icler/PCA-EVAL/.\n",
                "链接": "https://arxiv.org/abs/2310.02071"
            },
            {
                "文章ID": "104544",
                "标题": "The Importance of Multimodal Emotion Conditioning and Affect Consistency\n  for Embodied Conversational Agents",
                "作者": " Che-Jui Chang,  Samuel S. Sohn,  Sen Zhang,  Rajath Jayashankar,  Muhammad Usman,  Mubbasir Kapadia",
                "发布日期": "2023-12-08",
                "摘要": "  Previous studies regarding the perception of emotions for embodied virtual\nagents have shown the effectiveness of using virtual characters in conveying\nemotions through interactions with humans. However, creating an autonomous\nembodied conversational agent with expressive behaviors presents two major\nchallenges. The first challenge is the difficulty of synthesizing the\nconversational behaviors for each modality that are as expressive as real human\nbehaviors. The second challenge is that the affects are modeled independently,\nwhich makes it difficult to generate multimodal responses with consistent\nemotions across all modalities. In this work, we propose a conceptual\nframework, ACTOR (Affect-Consistent mulTimodal behaviOR generation), that aims\nto increase the perception of affects by generating multimodal behaviors\nconditioned on a consistent driving affect. We have conducted a user study with\n199 participants to assess how the average person judges the affects perceived\nfrom multimodal behaviors that are consistent and inconsistent with respect to\na driving affect. The result shows that among all model conditions, our\naffect-consistent framework receives the highest Likert scores for the\nperception of driving affects. Our statistical analysis suggests that making a\nmodality affect-inconsistent significantly decreases the perception of driving\naffects. We also observe that multimodal behaviors conditioned on consistent\naffects are more expressive compared to behaviors with inconsistent affects.\nTherefore, we conclude that multimodal emotion conditioning and affect\nconsistency are vital to enhancing the perception of affects for embodied\nconversational agents.\n",
                "链接": "https://arxiv.org/abs/2309.15311"
            },
            {
                "文章ID": "118026",
                "标题": "Agent as Cerebrum, Controller as Cerebellum: Implementing an Embodied\n  LMM-based Agent on Drones",
                "作者": " Haoran Zhao,  Fengxing Pan,  Huqiuyue Ping,  Yaoming Zhou",
                "发布日期": "2023-11-28",
                "摘要": "  In this study, we present a novel paradigm for industrial robotic embodied\nagents, encapsulating an 'agent as cerebrum, controller as cerebellum'\narchitecture. Our approach harnesses the power of Large Multimodal Models\n(LMMs) within an agent framework known as AeroAgent, tailored for drone\ntechnology in industrial settings. To facilitate seamless integration with\nrobotic systems, we introduce ROSchain, a bespoke linkage framework connecting\nLMM-based agents to the Robot Operating System (ROS). We report findings from\nextensive empirical research, including simulated experiments on the Airgen and\nreal-world case study, particularly in individual search and rescue operations.\nThe results demonstrate AeroAgent's superior performance in comparison to\nexisting Deep Reinforcement Learning (DRL)-based agents, highlighting the\nadvantages of the embodied LMM in complex, real-world scenarios.\n",
                "链接": "https://arxiv.org/abs/2311.15033"
            },
            {
                "文章ID": "89377",
                "标题": "Embodied Task Planning with Large Language Models",
                "作者": " Zhenyu Wu,  Ziwei Wang,  Xiuwei Xu,  Jiwen Lu,  Haibin Yan",
                "发布日期": "2023-07-07",
                "摘要": "  Equipping embodied agents with commonsense is important for robots to\nsuccessfully complete complex human instructions in general environments.\nRecent large language models (LLM) can embed rich semantic knowledge for agents\nin plan generation of complex tasks, while they lack the information about the\nrealistic world and usually yield infeasible action sequences. In this paper,\nwe propose a TAsk Planing Agent (TaPA) in embodied tasks for grounded planning\nwith physical scene constraint, where the agent generates executable plans\naccording to the existed objects in the scene by aligning LLMs with the visual\nperception models. Specifically, we first construct a multimodal dataset\ncontaining triplets of indoor scenes, instructions and action plans, where we\nprovide the designed prompts and the list of existing objects in the scene for\nGPT-3.5 to generate a large number of instructions and corresponding planned\nactions. The generated data is leveraged for grounded plan tuning of\npre-trained LLMs. During inference, we discover the objects in the scene by\nextending open-vocabulary object detectors to multi-view RGB images collected\nin different achievable locations. Experimental results show that the generated\nplan from our TaPA framework can achieve higher success rate than LLaVA and\nGPT-3.5 by a sizable margin, which indicates the practicality of embodied task\nplanning in general and complex environments.\n",
                "链接": "https://arxiv.org/abs/2307.01848"
            },
            {
                "文章ID": "114303",
                "标题": "Multitask Multimodal Prompted Training for Interactive Embodied Task\n  Completion",
                "作者": " Georgios Pantazopoulos,  Malvina Nikandrou,  Amit Parekh,  Bhathiya Hemanthage,  Arash Eshghi,  Ioannis Konstas,  Verena Rieser,  Oliver Lemon,  Alessandro Suglia",
                "发布日期": "2023-11-08",
                "摘要": "  Interactive and embodied tasks pose at least two fundamental challenges to\nexisting Vision & Language (VL) models, including 1) grounding language in\ntrajectories of actions and observations, and 2) referential disambiguation. To\ntackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a\nunified encoder-decoder model that reasons over images and trajectories, and\ncasts action prediction as multimodal text generation. By unifying all tasks as\ntext generation, EMMA learns a language of actions which facilitates transfer\nacross tasks. Different to previous modular approaches with independently\ntrained components, we use a single multitask model where each task contributes\nto goal completion. EMMA performs on par with similar models on several VL\nbenchmarks and sets a new state-of-the-art performance (36.81% success rate) on\nthe Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided\nagents in the Alexa Arena\n",
                "链接": "https://arxiv.org/abs/2311.04067"
            }
        ]
    },
    {
        "question": {
            "question": "新的大模型结构相关探索的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "帮我查找风格化机器翻译相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "83081",
                "标题": "Text Style Transfer Back-Translation",
                "作者": " Daimeng Wei,  Zhanglin Wu,  Hengchao Shang,  Zongyao Li,  Minghan Wang,  Jiaxin Guo,  Xiaoyu Chen,  Zhengzhe Yu,  Hao Yang",
                "发布日期": "2023-06-05",
                "摘要": "  Back Translation (BT) is widely used in the field of machine translation, as\nit has been proved effective for enhancing translation quality. However, BT\nmainly improves the translation of inputs that share a similar style (to be\nmore specific, translation-like inputs), since the source side of BT data is\nmachine-translated. For natural inputs, BT brings only slight improvements and\nsometimes even adverse effects. To address this issue, we propose Text Style\nTransfer Back Translation (TST BT), which uses a style transfer model to modify\nthe source side of BT data. By making the style of source-side text more\nnatural, we aim to improve the translation of natural inputs. Our experiments\non various language pairs, including both high-resource and low-resource ones,\ndemonstrate that TST BT significantly improves translation performance against\npopular BT benchmarks. In addition, TST BT is proved to be effective in domain\nadaptation so this strategy can be regarded as a general data augmentation\nmethod. Our training code and text style transfer model are open-sourced.\n",
                "链接": "https://arxiv.org/abs/2306.01318"
            },
            {
                "文章ID": "19713",
                "标题": "Exploiting Social Media Content for Self-Supervised Style Transfer",
                "作者": " Dana Ruiter,  Thomas Kleinbauer,  Cristina España-Bonet,  Josef van Genabith,  Dietrich Klakow",
                "发布日期": "2022-05-19",
                "摘要": "  Recent research on style transfer takes inspiration from unsupervised neural\nmachine translation (UNMT), learning from large amounts of non-parallel data by\nexploiting cycle consistency loss, back-translation, and denoising\nautoencoders. By contrast, the use of self-supervised NMT (SSNMT), which\nleverages (near) parallel instances hidden in non-parallel data more\nefficiently than UNMT, has not yet been explored for style transfer. In this\npaper we present a novel Self-Supervised Style Transfer (3ST) model, which\naugments SSNMT with UNMT methods in order to identify and efficiently exploit\nsupervisory signals in non-parallel social media posts. We compare 3ST with\nstate-of-the-art (SOTA) style transfer models across civil rephrasing,\nformality and polarity tasks. We show that 3ST is able to balance the three\nmajor objectives (fluency, content preservation, attribute transfer accuracy)\nthe best, outperforming SOTA models on averaged performance across their tested\ntasks in automatic and human evaluation.\n",
                "链接": "https://arxiv.org/abs/2205.08814"
            },
            {
                "文章ID": "1780",
                "标题": "Extending the Vocabulary of Fictional Languages using Neural Networks",
                "作者": " Thomas Zacharias,  Ashutosh Taklikar,  Raja Giryes",
                "发布日期": "2022-01-20",
                "摘要": "  Fictional languages have become increasingly popular over the recent years\nappearing in novels, movies, TV shows, comics, and video games. While some of\nthese fictional languages have a complete vocabulary, most do not. We propose a\ndeep learning solution to the problem. Using style transfer and machine\ntranslation tools, we generate new words for a given target fictional language,\nwhile maintaining the style of its creator, hence extending this language\nvocabulary.\n",
                "链接": "https://arxiv.org/abs/2201.07288"
            },
            {
                "文章ID": "37030",
                "标题": "Time-of-Day Neural Style Transfer for Architectural Photographs",
                "作者": " Yingshu Chen,  Tuan-Anh Vu,  Ka-Chun Shum,  Binh-Son Hua,  Sai-Kit Yeung",
                "发布日期": "2022-10-31",
                "摘要": "  Architectural photography is a genre of photography that focuses on capturing\na building or structure in the foreground with dramatic lighting in the\nbackground. Inspired by recent successes in image-to-image translation methods,\nwe aim to perform style transfer for architectural photographs. However, the\nspecial composition in architectural photography poses great challenges for\nstyle transfer in this type of photographs. Existing neural style transfer\nmethods treat the architectural images as a single entity, which would generate\nmismatched chrominance and destroy geometric features of the original\narchitecture, yielding unrealistic lighting, wrong color rendition, and visual\nartifacts such as ghosting, appearance distortion, or color mismatching. In\nthis paper, we specialize a neural style transfer method for architectural\nphotography. Our method addresses the composition of the foreground and\nbackground in an architectural photograph in a two-branch neural network that\nseparately considers the style transfer of the foreground and the background,\nrespectively. Our method comprises a segmentation module, a learning-based\nimage-to-image translation module, and an image blending optimization module.\nWe trained our image-to-image translation neural network with a new dataset of\nunconstrained outdoor architectural photographs captured at different magic\ntimes of a day, utilizing additional semantic information for better\nchrominance matching and geometry preservation. Our experiments show that our\nmethod can produce photorealistic lighting and color rendition on both the\nforeground and background, and outperforms general image-to-image translation\nand arbitrary style transfer baselines quantitatively and qualitatively. Our\ncode and data are available at\nhttps://github.com/hkust-vgd/architectural_style_transfer.\n",
                "链接": "https://arxiv.org/abs/2209.05800"
            },
            {
                "文章ID": "101979",
                "标题": "Speech-to-Speech Translation with Discrete-Unit-Based Style Transfer",
                "作者": " Yongqi Wang,  Jionghao Bai,  Rongjie Huang,  Ruiqi Li,  Zhiqing Hong,  Zhou Zhao",
                "发布日期": "2023-09-15",
                "摘要": "  Direct speech-to-speech translation (S2ST) with discrete self-supervised\nrepresentations has achieved remarkable accuracy, but is unable to preserve the\nspeaker timbre of the source speech during translation. Meanwhile, the scarcity\nof high-quality speaker-parallel data poses a challenge for learning style\ntransfer between source and target speech. We propose an S2ST framework with an\nacoustic language model based on discrete units from a self-supervised model\nand a neural codec for style transfer. The acoustic language model leverages\nself-supervised in-context learning, acquiring the ability for style transfer\nwithout relying on any speaker-parallel data, thereby overcoming the issue of\ndata scarcity. By using extensive training data, our model achieves zero-shot\ncross-lingual style transfer on previously unseen source languages. Experiments\nshow that our model generates translated speeches with high fidelity and style\nsimilarity. Audio samples are available at http://stylelm.github.io/ .\n",
                "链接": "https://arxiv.org/abs/2309.07566"
            },
            {
                "文章ID": "39805",
                "标题": "Diffusion-based Image Translation using Disentangled Style and Content\n  Representation",
                "作者": " Gihyun Kwon,  Jong Chul Ye",
                "发布日期": "2023-02-02",
                "摘要": "  Diffusion-based image translation guided by semantic texts or a single target\nimage has enabled flexible style transfer which is not limited to the specific\ndomains. Unfortunately, due to the stochastic nature of diffusion models, it is\noften difficult to maintain the original content of the image during the\nreverse diffusion. To address this, here we present a novel diffusion-based\nunsupervised image translation method using disentangled style and content\nrepresentation.\n  Specifically, inspired by the splicing Vision Transformer, we extract\nintermediate keys of multihead self attention layer from ViT model and used\nthem as the content preservation loss. Then, an image guided style transfer is\nperformed by matching the [CLS] classification token from the denoised samples\nand target image, whereas additional CLIP loss is used for the text-driven\nstyle transfer. To further accelerate the semantic change during the reverse\ndiffusion, we also propose a novel semantic divergence loss and resampling\nstrategy. Our experimental results show that the proposed method outperforms\nstate-of-the-art baseline models in both text-guided and image-guided\ntranslation tasks.\n",
                "链接": "https://arxiv.org/abs/2209.15264"
            },
            {
                "文章ID": "7020",
                "标题": "StyleCLIPDraw: Coupling Content and Style in Text-to-Drawing Translation",
                "作者": " Peter Schaldenbrand,  Zhixuan Liu,  Jean Oh",
                "发布日期": "2022-02-28",
                "摘要": "  Generating images that fit a given text description using machine learning\nhas improved greatly with the release of technologies such as the CLIP\nimage-text encoder model; however, current methods lack artistic control of the\nstyle of image to be generated. We present an approach for generating styled\ndrawings for a given text description where a user can specify a desired\ndrawing style using a sample image. Inspired by a theory in art that style and\ncontent are generally inseparable during the creative process, we propose a\ncoupled approach, known here as StyleCLIPDraw, whereby the drawing is generated\nby optimizing for style and content simultaneously throughout the process as\nopposed to applying style transfer after creating content in a sequence. Based\non human evaluation, the styles of images generated by StyleCLIPDraw are\nstrongly preferred to those by the sequential approach. Although the quality of\ncontent generation degrades for certain styles, overall considering both\ncontent \\textit{and} style, StyleCLIPDraw is found far more preferred,\nindicating the importance of style, look, and feel of machine generated images\nto people as well as indicating that style is coupled in the drawing process\nitself. Our code (https://github.com/pschaldenbrand/StyleCLIPDraw), a\ndemonstration (https://replicate.com/pschaldenbrand/style-clip-draw), and style\nevaluation data\n(https://www.kaggle.com/pittsburghskeet/drawings-with-style-evaluation-styleclipdraw)\nare publicly available.\n",
                "链接": "https://arxiv.org/abs/2202.12362"
            },
            {
                "文章ID": "27958",
                "标题": "DCT-Net: Domain-Calibrated Translation for Portrait Stylization",
                "作者": " Yifang Men,  Yuan Yao,  Miaomiao Cui,  Zhouhui Lian,  Xuansong Xie",
                "发布日期": "2022-07-07",
                "摘要": "  This paper introduces DCT-Net, a novel image translation architecture for\nfew-shot portrait stylization. Given limited style exemplars ($\\sim$100), the\nnew architecture can produce high-quality style transfer results with advanced\nability to synthesize high-fidelity contents and strong generality to handle\ncomplicated scenes (e.g., occlusions and accessories). Moreover, it enables\nfull-body image translation via one elegant evaluation network trained by\npartial observations (i.e., stylized heads). Few-shot learning based style\ntransfer is challenging since the learned model can easily become overfitted in\nthe target domain, due to the biased distribution formed by only a few training\nexamples. This paper aims to handle the challenge by adopting the key idea of\n\"calibration first, translation later\" and exploring the augmented global\nstructure with locally-focused translation. Specifically, the proposed DCT-Net\nconsists of three modules: a content adapter borrowing the powerful prior from\nsource photos to calibrate the content distribution of target samples; a\ngeometry expansion module using affine transformations to release spatially\nsemantic constraints; and a texture translation module leveraging samples\nproduced by the calibrated distribution to learn a fine-grained conversion.\nExperimental results demonstrate the proposed method's superiority over the\nstate of the art in head stylization and its effectiveness on full image\ntranslation with adaptive deformations.\n",
                "链接": "https://arxiv.org/abs/2207.02426"
            },
            {
                "文章ID": "92370",
                "标题": "Incorporating Human Translator Style into English-Turkish Literary\n  Machine Translation",
                "作者": " Zeynep Yirmibeşoğlu,  Olgun Dursun,  Harun Dallı,  Mehmet Şahin,  Ena Hodzik,  Sabri Gürses,  Tunga Güngör",
                "发布日期": "2023-07-24",
                "摘要": "  Although machine translation systems are mostly designed to serve in the\ngeneral domain, there is a growing tendency to adapt these systems to other\ndomains like literary translation. In this paper, we focus on English-Turkish\nliterary translation and develop machine translation models that take into\naccount the stylistic features of translators. We fine-tune a pre-trained\nmachine translation model by the manually-aligned works of a particular\ntranslator. We make a detailed analysis of the effects of manual and automatic\nalignments, data augmentation methods, and corpus size on the translations. We\npropose an approach based on stylistic features to evaluate the style of a\ntranslator in the output translations. We show that the human translator style\ncan be highly recreated in the target machine translations by adapting the\nmodels to the style of the translator.\n",
                "链接": "https://arxiv.org/abs/2307.11457"
            },
            {
                "文章ID": "28629",
                "标题": "CCPL: Contrastive Coherence Preserving Loss for Versatile Style Transfer",
                "作者": " Zijie Wu,  Zhen Zhu,  Junping Du,  Xiang Bai",
                "发布日期": "2022-07-20",
                "摘要": "  In this paper, we aim to devise a universally versatile style transfer method\ncapable of performing artistic, photo-realistic, and video style transfer\njointly, without seeing videos during training. Previous single-frame methods\nassume a strong constraint on the whole image to maintain temporal consistency,\nwhich could be violated in many cases. Instead, we make a mild and reasonable\nassumption that global inconsistency is dominated by local inconsistencies and\ndevise a generic Contrastive Coherence Preserving Loss (CCPL) applied to local\npatches. CCPL can preserve the coherence of the content source during style\ntransfer without degrading stylization. Moreover, it owns a neighbor-regulating\nmechanism, resulting in a vast reduction of local distortions and considerable\nvisual quality improvement. Aside from its superior performance on versatile\nstyle transfer, it can be easily extended to other tasks, such as\nimage-to-image translation. Besides, to better fuse content and style features,\nwe propose Simple Covariance Transformation (SCT) to effectively align\nsecond-order statistics of the content feature with the style feature.\nExperiments demonstrate the effectiveness of the resulting model for versatile\nstyle transfer, when armed with CCPL.\n",
                "链接": "https://arxiv.org/abs/2207.04808"
            }
        ]
    },
    {
        "question": {
            "question": "查找中文ner常用的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "5948",
                "标题": "AISHELL-NER: Named Entity Recognition from Chinese Speech",
                "作者": " Boli Chen,  Guangwei Xu,  Xiaobin Wang,  Pengjun Xie,  Meishan Zhang,  Fei Huang",
                "发布日期": "2022-02-18",
                "摘要": "  Named Entity Recognition (NER) from speech is among Spoken Language\nUnderstanding (SLU) tasks, aiming to extract semantic information from the\nspeech signal. NER from speech is usually made through a two-step pipeline that\nconsists of (1) processing the audio using an Automatic Speech Recognition\n(ASR) system and (2) applying an NER tagger to the ASR outputs. Recent works\nhave shown the capability of the End-to-End (E2E) approach for NER from English\nand French speech, which is essentially entity-aware ASR. However, due to the\nmany homophones and polyphones that exist in Chinese, NER from Chinese speech\nis effectively a more challenging task. In this paper, we introduce a new\ndataset AISEHLL-NER for NER from Chinese speech. Extensive experiments are\nconducted to explore the performance of several state-of-the-art methods. The\nresults demonstrate that the performance could be improved by combining\nentity-aware ASR and pretrained NER tagger, which can be easily applied to the\nmodern SLU pipeline. The dataset is publicly available at\ngithub.com/Alibaba-NLP/AISHELL-NER.\n",
                "链接": "https://arxiv.org/abs/2202.08533"
            },
            {
                "文章ID": "12836",
                "标题": "$k$NN-NER: Named Entity Recognition with Nearest Neighbor Search",
                "作者": " Shuhe Wang,  Xiaoya Li,  Yuxian Meng,  Tianwei Zhang,  Rongbin Ouyang,  Jiwei Li,  Guoyin Wang",
                "发布日期": "2022-04-01",
                "摘要": "  Inspired by recent advances in retrieval augmented methods in\nNLP~\\citep{khandelwal2019generalization,khandelwal2020nearest,meng2021gnn}, in\nthis paper, we introduce a $k$ nearest neighbor NER ($k$NN-NER) framework,\nwhich augments the distribution of entity labels by assigning $k$ nearest\nneighbors retrieved from the training set. This strategy makes the model more\ncapable of handling long-tail cases, along with better few-shot learning\nabilities. $k$NN-NER requires no additional operation during the training\nphase, and by interpolating $k$ nearest neighbors search into the vanilla NER\nmodel, $k$NN-NER consistently outperforms its vanilla counterparts: we achieve\na new state-of-the-art F1-score of 72.03 (+1.25) on the Chinese Weibo dataset\nand improved results on a variety of widely used NER benchmarks. Additionally,\nwe show that $k$NN-NER can achieve comparable results to the vanilla NER model\nwith 40\\% less amount of training data. Code available at\n\\url{https://github.com/ShannonAI/KNN-NER}.\n",
                "链接": "https://arxiv.org/abs/2203.17103"
            },
            {
                "文章ID": "73406",
                "标题": "GPT-NER: Named Entity Recognition via Large Language Models",
                "作者": " Shuhe Wang,  Xiaofei Sun,  Xiaoya Li,  Rongbin Ouyang,  Fei Wu,  Tianwei Zhang,  Jiwei Li,  Guoyin Wang",
                "发布日期": "2023-10-10",
                "摘要": "  Despite the fact that large-scale Language Models (LLM) have achieved SOTA\nperformances on a variety of NLP tasks, its performance on NER is still\nsignificantly below supervised baselines. This is due to the gap between the\ntwo tasks the NER and LLMs: the former is a sequence labeling task in nature\nwhile the latter is a text-generation model.\n  In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges the\ngap by transforming the sequence labeling task to a generation task that can be\neasily adapted by LLMs e.g., the task of finding location entities in the input\ntext \"Columbus is a city\" is transformed to generate the text sequence\n\"@@Columbus## is a city\", where special tokens @@## marks the entity to\nextract. To efficiently address the \"hallucination\" issue of LLMs, where LLMs\nhave a strong inclination to over-confidently label NULL inputs as entities, we\npropose a self-verification strategy by prompting LLMs to ask itself whether\nthe extracted entities belong to a labeled entity tag.\n  We conduct experiments on five widely adopted NER datasets, and GPT-NER\nachieves comparable performances to fully supervised baselines, which is the\nfirst time as far as we are concerned. More importantly, we find that GPT-NER\nexhibits a greater ability in the low-resource and few-shot setups, when the\namount of training data is extremely scarce, GPT-NER performs significantly\nbetter than supervised models. This demonstrates the capabilities of GPT-NER in\nreal-world NER applications where the number of labeled examples is limited.\n",
                "链接": "https://arxiv.org/abs/2304.10428"
            },
            {
                "文章ID": "81587",
                "标题": "E-NER: Evidential Deep Learning for Trustworthy Named Entity Recognition",
                "作者": " Zhen Zhang,  Mengting Hu,  Shiwan Zhao,  Minlie Huang,  Haotian Wang,  Lemao Liu,  Zhirui Zhang,  Zhe Liu,  Bingzhe Wu",
                "发布日期": "2023-05-30",
                "摘要": "  Most named entity recognition (NER) systems focus on improving model\nperformance, ignoring the need to quantify model uncertainty, which is critical\nto the reliability of NER systems in open environments. Evidential deep\nlearning (EDL) has recently been proposed as a promising solution to explicitly\nmodel predictive uncertainty for classification tasks. However, directly\napplying EDL to NER applications faces two challenges, i.e., the problems of\nsparse entities and OOV/OOD entities in NER tasks. To address these challenges,\nwe propose a trustworthy NER framework named E-NER by introducing two\nuncertainty-guided loss terms to the conventional EDL, along with a series of\nuncertainty-guided training strategies. Experiments show that E-NER can be\napplied to multiple NER paradigms to obtain accurate uncertainty estimation.\nFurthermore, compared to state-of-the-art baselines, the proposed method\nachieves a better OOV/OOD detection performance and better generalization\nability on OOV entities.\n",
                "链接": "https://arxiv.org/abs/2305.17854"
            },
            {
                "文章ID": "108977",
                "标题": "Empirical Study of Zero-Shot NER with ChatGPT",
                "作者": " Tingyu Xie,  Qi Li,  Jian Zhang,  Yan Zhang,  Zuozhu Liu,  Hongwei Wang",
                "发布日期": "2023-10-17",
                "摘要": "  Large language models (LLMs) exhibited powerful capability in various natural\nlanguage processing tasks. This work focuses on exploring LLM performance on\nzero-shot information extraction, with a focus on the ChatGPT and named entity\nrecognition (NER) task. Inspired by the remarkable reasoning capability of LLM\non symbolic and arithmetic reasoning, we adapt the prevalent reasoning methods\nto NER and propose reasoning strategies tailored for NER. First, we explore a\ndecomposed question-answering paradigm by breaking down the NER task into\nsimpler subproblems by labels. Second, we propose syntactic augmentation to\nstimulate the model's intermediate thinking in two ways: syntactic prompting,\nwhich encourages the model to analyze the syntactic structure itself, and tool\naugmentation, which provides the model with the syntactic information generated\nby a parsing tool. Besides, we adapt self-consistency to NER by proposing a\ntwo-stage majority voting strategy, which first votes for the most consistent\nmentions, then the most consistent types. The proposed methods achieve\nremarkable improvements for zero-shot NER across seven benchmarks, including\nChinese and English datasets, and on both domain-specific and general-domain\nscenarios. In addition, we present a comprehensive analysis of the error types\nwith suggestions for optimization directions. We also verify the effectiveness\nof the proposed methods on the few-shot setting and other LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.10035"
            },
            {
                "文章ID": "81674",
                "标题": "Extrinsic Factors Affecting the Accuracy of Biomedical NER",
                "作者": " Zhiyi Li,  Shengjie Zhang,  Yujie Song,  Jungyeul Park",
                "发布日期": "2023-05-30",
                "摘要": "  Biomedical named entity recognition (NER) is a critial task that aims to\nidentify structured information in clinical text, which is often replete with\ncomplex, technical terms and a high degree of variability. Accurate and\nreliable NER can facilitate the extraction and analysis of important biomedical\ninformation, which can be used to improve downstream applications including the\nhealthcare system. However, NER in the biomedical domain is challenging due to\nlimited data availability, as the high expertise, time, and expenses are\nrequired to annotate its data. In this paper, by using the limited data, we\nexplore various extrinsic factors including the corpus annotation scheme, data\naugmentation techniques, semi-supervised learning and Brill transformation, to\nimprove the performance of a NER model on a clinical text dataset (i2b2 2012,\n\\citet{sun-rumshisky-uzuner:2013}). Our experiments demonstrate that these\napproaches can significantly improve the model's F1 score from original 73.74\nto 77.55. Our findings suggest that considering different extrinsic factors and\ncombining these techniques is a promising approach for improving NER\nperformance in the biomedical domain where the size of data is limited.\n",
                "链接": "https://arxiv.org/abs/2305.18152"
            },
            {
                "文章ID": "81620",
                "标题": "ContrastNER: Contrastive-based Prompt Tuning for Few-shot NER",
                "作者": " Amirhossein Layegh,  Amir H. Payberah,  Ahmet Soylu,  Dumitru Roman,  Mihhail Matskin",
                "发布日期": "2023-08-08",
                "摘要": "  Prompt-based language models have produced encouraging results in numerous\napplications, including Named Entity Recognition (NER) tasks. NER aims to\nidentify entities in a sentence and provide their types. However, the strong\nperformance of most available NER approaches is heavily dependent on the design\nof discrete prompts and a verbalizer to map the model-predicted outputs to\nentity categories, which are complicated undertakings. To address these\nchallenges, we present ContrastNER, a prompt-based NER framework that employs\nboth discrete and continuous tokens in prompts and uses a contrastive learning\napproach to learn the continuous prompts and forecast entity types. The\nexperimental results demonstrate that ContrastNER obtains competitive\nperformance to the state-of-the-art NER methods in high-resource settings and\noutperforms the state-of-the-art models in low-resource circumstances without\nrequiring extensive manual prompt engineering and verbalizer design.\n",
                "链接": "https://arxiv.org/abs/2305.17951"
            },
            {
                "文章ID": "54218",
                "标题": "E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text",
                "作者": " Ting Wai Terence Au,  Ingemar J. Cox,  Vasileios Lampos",
                "发布日期": "2022-12-20",
                "摘要": "  Identifying named entities such as a person, location or organization, in\ndocuments can highlight key information to readers. Training Named Entity\nRecognition (NER) models requires an annotated data set, which can be a\ntime-consuming labour-intensive task. Nevertheless, there are publicly\navailable NER data sets for general English. Recently there has been interest\nin developing NER for legal text. However, prior work and experimental results\nreported here indicate that there is a significant degradation in performance\nwhen NER methods trained on a general English data set are applied to legal\ntext. We describe a publicly available legal NER data set, called E-NER, based\non legal company filings available from the US Securities and Exchange\nCommission's EDGAR data set. Training a number of different NER algorithms on\nthe general English CoNLL-2003 corpus but testing on our test collection\nconfirmed significant degradations in accuracy, as measured by the F1-score, of\nbetween 29.4\\% and 60.4\\%, compared to training and testing on the E-NER\ncollection.\n",
                "链接": "https://arxiv.org/abs/2212.09306"
            },
            {
                "文章ID": "82089",
                "标题": "A Multilingual Evaluation of NER Robustness to Adversarial Inputs",
                "作者": " Akshay Srinivasan,  Sowmya Vajjala",
                "发布日期": "2023-05-31",
                "摘要": "  Adversarial evaluations of language models typically focus on English alone.\nIn this paper, we performed a multilingual evaluation of Named Entity\nRecognition (NER) in terms of its robustness to small perturbations in the\ninput. Our results showed the NER models we explored across three languages\n(English, German and Hindi) are not very robust to such changes, as indicated\nby the fluctuations in the overall F1 score as well as in a more fine-grained\nevaluation. With that knowledge, we further explored whether it is possible to\nimprove the existing NER models using a part of the generated adversarial data\nsets as augmented training data to train a new NER model or as fine-tuning data\nto adapt an existing NER model. Our results showed that both these approaches\nimprove performance on the original as well as adversarial test sets. While\nthere is no significant difference between the two approaches for English,\nre-training is significantly better than fine-tuning for German and Hindi.\n",
                "链接": "https://arxiv.org/abs/2305.18933"
            },
            {
                "文章ID": "78785",
                "标题": "Enhancing Few-shot NER with Prompt Ordering based Data Augmentation",
                "作者": " Huiming Wang,  Liying Cheng,  Wenxuan Zhang,  De Wen Soh,  Lidong Bing",
                "发布日期": "2023-05-22",
                "摘要": "  Recently, data augmentation (DA) methods have been proven to be effective for\npre-trained language models (PLMs) in low-resource settings, including few-shot\nnamed entity recognition (NER). However, conventional NER DA methods are mostly\naimed at sequence labeling models, i.e., token-level classification, and few\nare compatible with unified autoregressive generation frameworks, which can\nhandle a wider range of NER tasks, such as nested NER. Furthermore, these\ngeneration frameworks have a strong assumption that the entities will appear in\nthe target sequence with the same left-to-right order as the source sequence.\nIn this paper, we claim that there is no need to keep this strict order, and\nmore diversified but reasonable target entity sequences can be provided during\nthe training stage as a novel DA method. Nevertheless, a naive mixture of\naugmented data can confuse the model since one source sequence will then be\npaired with different target sequences. Therefore, we propose a simple but\neffective Prompt Ordering based Data Augmentation (PODA) method to improve the\ntraining of unified autoregressive generation frameworks under few-shot NER\nscenarios. Experimental results on three public NER datasets and further\nanalyses demonstrate the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2305.11791"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下最近用反事实做数据增强的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "46263",
                "标题": "Backtracking Counterfactuals",
                "作者": " Julius von Kügelgen,  Abdirisak Mohamed,  Sander Beckers",
                "发布日期": "2023-05-31",
                "摘要": "  Counterfactual reasoning -- envisioning hypothetical scenarios, or possible\nworlds, where some circumstances are different from what (f)actually occurred\n(counter-to-fact) -- is ubiquitous in human cognition. Conventionally,\ncounterfactually-altered circumstances have been treated as \"small miracles\"\nthat locally violate the laws of nature while sharing the same initial\nconditions. In Pearl's structural causal model (SCM) framework this is made\nmathematically rigorous via interventions that modify the causal laws while the\nvalues of exogenous variables are shared. In recent years, however, this purely\ninterventionist account of counterfactuals has increasingly come under scrutiny\nfrom both philosophers and psychologists. Instead, they suggest a backtracking\naccount of counterfactuals, according to which the causal laws remain unchanged\nin the counterfactual world; differences to the factual world are instead\n\"backtracked\" to altered initial conditions (exogenous variables). In the\npresent work, we explore and formalise this alternative mode of counterfactual\nreasoning within the SCM framework. Despite ample evidence that humans\nbacktrack, the present work constitutes, to the best of our knowledge, the\nfirst general account and algorithmisation of backtracking counterfactuals. We\ndiscuss our backtracking semantics in the context of related literature and\ndraw connections to recent developments in explainable artificial intelligence\n(XAI).\n",
                "链接": "https://arxiv.org/abs/2211.00472"
            },
            {
                "文章ID": "54607",
                "标题": "DISCO: Distilling Counterfactuals with Large Language Models",
                "作者": " Zeming Chen,  Qiyue Gao,  Antoine Bosselut,  Ashish Sabharwal,  Kyle Richardson",
                "发布日期": "2023-06-07",
                "摘要": "  Models trained with counterfactually augmented data learn representations of\nthe causal structure of tasks, enabling robust generalization. However,\nhigh-quality counterfactual data is scarce for most tasks and not easily\ngenerated at scale. When crowdsourced, such data is typically limited in scale\nand diversity; when generated using supervised methods, it is computationally\nexpensive to extend to new counterfactual dimensions. In this work, we\nintroduce DISCO (DIStilled COunterfactual Data), a new method for automatically\ngenerating high quality counterfactual data at scale. DISCO engineers prompts\nto generate phrasal perturbations with a large general language model. Then, a\ntask-specific teacher model filters these generations to distill high-quality\ncounterfactual data. While task-agnostic, we apply our pipeline to the task of\nnatural language inference (NLI) and find that on challenging evaluations such\nas the NLI stress test, comparatively smaller student models trained with DISCO\ngenerated counterfactuals are more robust (6% absolute) and generalize better\nacross distributions (2%) compared to models trained without data augmentation.\nFurthermore, DISCO augmented models are 10% more consistent between\ncounterfactual pairs on three evaluation sets, demonstrating that DISCO\naugmentation enables models to more reliably learn causal representations. Our\nrepository is available at: https://github.com/eric11eca/disco\n",
                "链接": "https://arxiv.org/abs/2212.10534"
            },
            {
                "文章ID": "88864",
                "标题": "Counterfactual Collaborative Reasoning",
                "作者": " Jianchao Ji,  Zelong Li,  Shuyuan Xu,  Max Xiong,  Juntao Tan,  Yingqiang Ge,  Hao Wang,  Yongfeng Zhang",
                "发布日期": "2023-07-06",
                "摘要": "  Causal reasoning and logical reasoning are two important types of reasoning\nabilities for human intelligence. However, their relationship has not been\nextensively explored under machine intelligence context. In this paper, we\nexplore how the two reasoning abilities can be jointly modeled to enhance both\naccuracy and explainability of machine learning models. More specifically, by\nintegrating two important types of reasoning ability -- counterfactual\nreasoning and (neural) logical reasoning -- we propose Counterfactual\nCollaborative Reasoning (CCR), which conducts counterfactual logic reasoning to\nimprove the performance. In particular, we use recommender system as an example\nto show how CCR alleviate data scarcity, improve accuracy and enhance\ntransparency. Technically, we leverage counterfactual reasoning to generate\n\"difficult\" counterfactual training examples for data augmentation, which --\ntogether with the original training examples -- can enhance the model\nperformance. Since the augmented data is model irrelevant, they can be used to\nenhance any model, enabling the wide applicability of the technique. Besides,\nmost of the existing data augmentation methods focus on \"implicit data\naugmentation\" over users' implicit feedback, while our framework conducts\n\"explicit data augmentation\" over users explicit feedback based on\ncounterfactual logic reasoning. Experiments on three real-world datasets show\nthat CCR achieves better performance than non-augmented models and implicitly\naugmented models, and also improves model transparency by generating\ncounterfactual explanations.\n",
                "链接": "https://arxiv.org/abs/2307.00165"
            },
            {
                "文章ID": "79559",
                "标题": "Improving Classifier Robustness through Active Generation of Pairwise\n  Counterfactuals",
                "作者": " Ananth Balashankar,  Xuezhi Wang,  Yao Qin,  Ben Packer,  Nithum Thain,  Jilin Chen,  Ed H. Chi,  Alex Beutel",
                "发布日期": "2023-05-24",
                "摘要": "  Counterfactual Data Augmentation (CDA) is a commonly used technique for\nimproving robustness in natural language classifiers. However, one fundamental\nchallenge is how to discover meaningful counterfactuals and efficiently label\nthem, with minimal human labeling cost. Most existing methods either completely\nrely on human-annotated labels, an expensive process which limits the scale of\ncounterfactual data, or implicitly assume label invariance, which may mislead\nthe model with incorrect labels. In this paper, we present a novel framework\nthat utilizes counterfactual generative models to generate a large number of\ndiverse counterfactuals by actively sampling from regions of uncertainty, and\nthen automatically label them with a learned pairwise classifier. Our key\ninsight is that we can more correctly label the generated counterfactuals by\ntraining a pairwise classifier that interpolates the relationship between the\noriginal example and the counterfactual. We demonstrate that with a small\namount of human-annotated counterfactual data (10%), we can generate a\ncounterfactual augmentation dataset with learned labels, that provides an\n18-20% improvement in robustness and a 14-21% reduction in errors on 6\nout-of-domain datasets, comparable to that of a fully human-annotated\ncounterfactual dataset for both sentiment classification and question\nparaphrase tasks.\n",
                "链接": "https://arxiv.org/abs/2305.13535"
            },
            {
                "文章ID": "80211",
                "标题": "Large Language Models as Counterfactual Generator: Strengths and\n  Weaknesses",
                "作者": " Yongqi Li,  Mayi Xu,  Xin Miao,  Shen Zhou,  Tieyun Qian",
                "发布日期": "2023-05-25",
                "摘要": "  Large language models (LLMs) have demonstrated remarkable performance in a\nrange of natural language understanding and generation tasks. Yet, their\nability to generate counterfactuals, which can be used for areas like data\naugmentation, remains under-explored. This study aims to investigate the\ncounterfactual generation capabilities of LLMs and analysis factors that\ninfluence this ability. First, we evaluate how effective are LLMs in\ncounterfactual generation through data augmentation experiments for small\nlanguage models (SLMs) across four tasks: sentiment analysis, natural language\ninference, named entity recognition, and relation extraction. While LLMs show\npromising enhancements in various settings, they struggle in complex tasks due\nto their self-limitations and the lack of logical guidance to produce\ncounterfactuals that align with commonsense. Second, our analysis reveals the\npivotal role of providing accurate task definitions and detailed step-by-step\ninstructions to LLMs in generating counterfactuals. Interestingly, we also find\nthat LLMs can generate reasonable counterfactuals even with unreasonable\ndemonstrations, which illustrates that demonstrations are primarily to regulate\nthe output format.This study provides the first comprehensive insight into\ncounterfactual generation abilities of LLMs, and offers a novel perspective on\nutilizing LLMs for data augmentation to enhance SLMs.\n",
                "链接": "https://arxiv.org/abs/2305.14791"
            },
            {
                "文章ID": "104252",
                "标题": "COCO-Counterfactuals: Automatically Constructed Counterfactual Examples\n  for Image-Text Pairs",
                "作者": " Tiep Le,  Vasudev Lal,  Phillip Howard",
                "发布日期": "2023-11-01",
                "摘要": "  Counterfactual examples have proven to be valuable in the field of natural\nlanguage processing (NLP) for both evaluating and improving the robustness of\nlanguage models to spurious correlations in datasets. Despite their\ndemonstrated utility for NLP, multimodal counterfactual examples have been\nrelatively unexplored due to the difficulty of creating paired image-text data\nwith minimal counterfactual changes. To address this challenge, we introduce a\nscalable framework for automatic generation of counterfactual examples using\ntext-to-image diffusion models. We use our framework to create\nCOCO-Counterfactuals, a multimodal counterfactual dataset of paired image and\ntext captions based on the MS-COCO dataset. We validate the quality of\nCOCO-Counterfactuals through human evaluations and show that existing\nmultimodal models are challenged by our counterfactual image-text pairs.\nAdditionally, we demonstrate the usefulness of COCO-Counterfactuals for\nimproving out-of-domain generalization of multimodal vision-language models via\ntraining data augmentation.\n",
                "链接": "https://arxiv.org/abs/2309.14356"
            },
            {
                "文章ID": "85954",
                "标题": "Counterfactuals Modulo Temporal Logics",
                "作者": " Bernd Finkbeiner,  Julian Siber",
                "发布日期": "2023-06-16",
                "摘要": "  Lewis' theory of counterfactuals is the foundation of many contemporary\nnotions of causality. In this paper, we extend this theory in the temporal\ndirection to enable symbolic counterfactual reasoning on infinite sequences,\nsuch as counterexamples found by a model checker and trajectories produced by a\nreinforcement learning agent. In particular, our extension considers a more\nrelaxed notion of similarity between worlds and proposes two additional\ncounterfactual operators that close a semantic gap between the previous two in\nthis more general setting. Further, we consider versions of counterfactuals\nthat minimize the distance to the witnessing counterfactual worlds, a common\nrequirement in causal analysis. To automate counterfactual reasoning in the\ntemporal domain, we introduce a logic that combines temporal and counterfactual\noperators, and outline decision procedures for the satisfiability and\ntrace-checking problems of this logic.\n",
                "链接": "https://arxiv.org/abs/2306.08916"
            },
            {
                "文章ID": "110605",
                "标题": "EXPLAIN, EDIT, GENERATE: Rationale-Sensitive Counterfactual Data\n  Augmentation for Multi-hop Fact Verification",
                "作者": " Yingjie Zhu,  Jiasheng Si,  Yibo Zhao,  Haiyang Zhu,  Deyu Zhou,  Yulan He",
                "发布日期": "2023-10-24",
                "摘要": "  Automatic multi-hop fact verification task has gained significant attention\nin recent years. Despite impressive results, these well-designed models perform\npoorly on out-of-domain data. One possible solution is to augment the training\ndata with counterfactuals, which are generated by minimally altering the causal\nfeatures of the original data. However, current counterfactual data\naugmentation techniques fail to handle multi-hop fact verification due to their\nincapability to preserve the complex logical relationships within multiple\ncorrelated texts. In this paper, we overcome this limitation by developing a\nrationale-sensitive method to generate linguistically diverse and\nlabel-flipping counterfactuals while preserving logical relationships. In\nspecific, the diverse and fluent counterfactuals are generated via an\nExplain-Edit-Generate architecture. Moreover, the checking and filtering\nmodules are proposed to regularize the counterfactual data with logical\nrelations and flipped labels. Experimental results show that the proposed\napproach outperforms the SOTA baselines and can generate linguistically diverse\ncounterfactual data without disrupting their logical relationships.\n",
                "链接": "https://arxiv.org/abs/2310.14508"
            },
            {
                "文章ID": "41610",
                "标题": "CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation",
                "作者": " Tanay Dixit,  Bhargavi Paranjape,  Hannaneh Hajishirzi,  Luke Zettlemoyer",
                "发布日期": "2022-11-02",
                "摘要": "  Counterfactual data augmentation (CDA) -- i.e., adding minimally perturbed\ninputs during training -- helps reduce model reliance on spurious correlations\nand improves generalization to out-of-distribution (OOD) data. Prior work on\ngenerating counterfactuals only considered restricted classes of perturbations,\nlimiting their effectiveness. We present COunterfactual Generation via\nRetrieval and Editing (CORE), a retrieval-augmented generation framework for\ncreating diverse counterfactual perturbations for CDA. For each training\nexample, CORE first performs a dense retrieval over a task-related unlabeled\ntext corpus using a learned bi-encoder and extracts relevant counterfactual\nexcerpts. CORE then incorporates these into prompts to a large language model\nwith few-shot learning capabilities, for counterfactual editing. Conditioning\nlanguage model edits on naturally occurring data results in diverse\nperturbations. Experiments on natural language inference and sentiment analysis\nbenchmarks show that CORE counterfactuals are more effective at improving\ngeneralization to OOD data compared to other DA approaches. We also show that\nthe CORE retrieval framework can be used to encourage diversity in manually\nauthored perturbations\n",
                "链接": "https://arxiv.org/abs/2210.04873"
            },
            {
                "文章ID": "876",
                "标题": "Learning Fair Node Representations with Graph Counterfactual Fairness",
                "作者": " Jing Ma,  Ruocheng Guo,  Mengting Wan,  Longqi Yang,  Aidong Zhang,  Jundong Li",
                "发布日期": "2022-01-12",
                "摘要": "  Fair machine learning aims to mitigate the biases of model predictions\nagainst certain subpopulations regarding sensitive attributes such as race and\ngender. Among the many existing fairness notions, counterfactual fairness\nmeasures the model fairness from a causal perspective by comparing the\npredictions of each individual from the original data and the counterfactuals.\nIn counterfactuals, the sensitive attribute values of this individual had been\nmodified. Recently, a few works extend counterfactual fairness to graph data,\nbut most of them neglect the following facts that can lead to biases: 1) the\nsensitive attributes of each node's neighbors may causally affect the\nprediction w.r.t. this node; 2) the sensitive attributes may causally affect\nother features and the graph structure. To tackle these issues, in this paper,\nwe propose a novel fairness notion - graph counterfactual fairness, which\nconsiders the biases led by the above facts. To learn node representations\ntowards graph counterfactual fairness, we propose a novel framework based on\ncounterfactual data augmentation. In this framework, we generate\ncounterfactuals corresponding to perturbations on each node's and their\nneighbors' sensitive attributes. Then we enforce fairness by minimizing the\ndiscrepancy between the representations learned from the original graph and the\ncounterfactuals for each node. Experiments on both synthetic and real-world\ngraphs show that our framework outperforms the state-of-the-art baselines in\ngraph counterfactual fairness, and also achieves comparable prediction\nperformance.\n",
                "链接": "https://arxiv.org/abs/2201.03662"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用蒙特卡罗树搜索解决序列决策问题的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "106127",
                "标题": "Rollout Heuristics for Online Stochastic Contingent Planning",
                "作者": " Oded Blumenthal,  Guy Shani",
                "发布日期": "2023-10-05",
                "摘要": "  Partially observable Markov decision processes (POMDP) are a useful model for\ndecision-making under partial observability and stochastic actions. Partially\nObservable Monte-Carlo Planning is an online algorithm for deciding on the next\naction to perform, using a Monte-Carlo tree search approach, based on the UCT\n(UCB applied to trees) algorithm for fully observable Markov-decision\nprocesses. POMCP develops an action-observation tree, and at the leaves, uses a\nrollout policy to provide a value estimate for the leaf. As such, POMCP is\nhighly dependent on the rollout policy to compute good estimates, and hence\nidentify good actions. Thus, many practitioners who use POMCP are required to\ncreate strong, domain-specific heuristics.\n  In this paper, we model POMDPs as stochastic contingent planning problems.\nThis allows us to leverage domain-independent heuristics that were developed in\nthe planning community. We suggest two heuristics, the first is based on the\nwell-known h_add heuristic from classical planning, and the second is computed\nin belief space, taking the value of information into account.\n",
                "链接": "https://arxiv.org/abs/2310.02345"
            },
            {
                "文章ID": "23592",
                "标题": "Combining Monte-Carlo Tree Search with Proof-Number Search",
                "作者": " Elliot Doe,  Mark H. M. Winands,  Dennis J. N. J. Soemers,  Cameron Browne",
                "发布日期": "2022-06-09",
                "摘要": "  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
                "链接": "https://arxiv.org/abs/2206.03965"
            },
            {
                "文章ID": "102301",
                "标题": "Maneuver Decision-Making Through Proximal Policy Optimization And Monte\n  Carlo Tree Search",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-09-19",
                "摘要": "  Maneuver decision-making can be regarded as a Markov decision process and can\nbe address by reinforcement learning. However, original reinforcement learning\nalgorithms can hardly solve the maneuvering decision-making problem. One reason\nis that agents use random actions in the early stages of training, which makes\nit difficult to get rewards and learn how to make effective decisions. To\naddress this issue, a method based on proximal policy optimization and Monte\nCarlo tree search is proposed. The method uses proximal policy optimization to\ntrain the agent, and regards the results of air combat as targets to train the\nvalue network. Then, based on the value network and the visit count of each\nnode, Monte Carlo tree search is used to find the actions with more expected\nreturns than random actions, which can improve the training performance. The\nablation studies and simulation experiments indicate that agents trained by the\nproposed method can make different decisions according to different states,\nwhich demonstrates that the method can solve the maneuvering decision problem\nthat the original reinforcement learning algorithm cannot solve.\n",
                "链接": "https://arxiv.org/abs/2309.08611"
            },
            {
                "文章ID": "50093",
                "标题": "Monte Carlo Tree Search Algorithms for Risk-Aware and Multi-Objective\n  Reinforcement Learning",
                "作者": " Conor F. Hayes,  Mathieu Reymond,  Diederik M. Roijers,  Enda Howley,  Patrick Mannion",
                "发布日期": "2022-12-07",
                "摘要": "  In many risk-aware and multi-objective reinforcement learning settings, the\nutility of the user is derived from a single execution of a policy. In these\nsettings, making decisions based on the average future returns is not suitable.\nFor example, in a medical setting a patient may only have one opportunity to\ntreat their illness. Making decisions using just the expected future returns --\nknown in reinforcement learning as the value -- cannot account for the\npotential range of adverse or positive outcomes a decision may have. Therefore,\nwe should use the distribution over expected future returns differently to\nrepresent the critical information that the agent requires at decision time by\ntaking both the future and accrued returns into consideration. In this paper,\nwe propose two novel Monte Carlo tree search algorithms. Firstly, we present a\nMonte Carlo tree search algorithm that can compute policies for nonlinear\nutility functions (NLU-MCTS) by optimising the utility of the different\npossible returns attainable from individual policy executions, resulting in\ngood policies for both risk-aware and multi-objective settings. Secondly, we\npropose a distributional Monte Carlo tree search algorithm (DMCTS) which\nextends NLU-MCTS. DMCTS computes an approximate posterior distribution over the\nutility of the returns, and utilises Thompson sampling during planning to\ncompute policies in risk-aware and multi-objective settings. Both algorithms\noutperform the state-of-the-art in multi-objective reinforcement learning for\nthe expected utility of the returns.\n",
                "链接": "https://arxiv.org/abs/2211.13032"
            },
            {
                "文章ID": "40416",
                "标题": "Continuous Monte Carlo Graph Search",
                "作者": " Kalle Kujanpää,  Amin Babadi,  Yi Zhao,  Juho Kannala,  Alexander Ilin,  Joni Pajarinen",
                "发布日期": "2023-07-19",
                "摘要": "  In many complex sequential decision-making tasks, online planning is crucial\nfor high performance. For efficient online planning, Monte Carlo Tree Search\n(MCTS) employs a principled mechanism for trading off exploration for\nexploitation. MCTS outperforms comparison methods in many discrete\ndecision-making domains such as Go, Chess, and Shogi. Following, extensions of\nMCTS to continuous domains have been proposed. However, the inherent high\nbranching factor and the resulting explosion of search tree size are limiting\nexisting methods. To address this problem, we propose Continuous Monte Carlo\nGraph Search (CMCGS), a novel extension of MCTS to online planning in\nenvironments with continuous state and action spaces. CMCGS takes advantage of\nthe insight that, during planning, sharing the same action policy between\nseveral states can yield high performance. To implement this idea, at each time\nstep, CMCGS clusters similar states into a limited number of stochastic action\nbandit nodes, which produce a layered directed graph instead of an MCTS search\ntree. Experimental evaluation shows that CMCGS outperforms comparable planning\nmethods in several complex continuous DeepMind Control Suite benchmarks and a\n2D navigation task with limited sample budgets. Furthermore, CMCGS can be\nparallelized to scale up and it outperforms the Cross-Entropy Method (CEM) in\ncontinuous control with learned dynamics models.\n",
                "链接": "https://arxiv.org/abs/2210.01426"
            },
            {
                "文章ID": "108378",
                "标题": "LightZero: A Unified Benchmark for Monte Carlo Tree Search in General\n  Sequential Decision Scenarios",
                "作者": " Yazhe Niu,  Yuan Pu,  Zhenjie Yang,  Xueyan Li,  Tong Zhou,  Jiyuan Ren,  Shuai Hu,  Hongsheng Li,  Yu Liu",
                "发布日期": "2023-10-13",
                "摘要": "  Building agents based on tree-search planning capabilities with learned\nmodels has achieved remarkable success in classic decision-making problems,\nsuch as Go and Atari. However, it has been deemed challenging or even\ninfeasible to extend Monte Carlo Tree Search (MCTS) based algorithms to diverse\nreal-world applications, especially when these environments involve complex\naction spaces and significant simulation costs, or inherent stochasticity. In\nthis work, we introduce LightZero, the first unified benchmark for deploying\nMCTS/MuZero in general sequential decision scenarios. Specificially, we\nsummarize the most critical challenges in designing a general MCTS-style\ndecision-making solver, then decompose the tightly-coupled algorithm and system\ndesign of tree-search RL methods into distinct sub-modules. By incorporating\nmore appropriate exploration and optimization strategies, we can significantly\nenhance these sub-modules and construct powerful LightZero agents to tackle\ntasks across a wide range of domains, such as board games, Atari, MuJoCo,\nMiniGrid and GoBigger. Detailed benchmark results reveal the significant\npotential of such methods in building scalable and efficient decision\nintelligence. The code is available as part of OpenDILab at\nhttps://github.com/opendilab/LightZero.\n",
                "链接": "https://arxiv.org/abs/2310.08348"
            },
            {
                "文章ID": "66610",
                "标题": "Beyond Games: A Systematic Review of Neural Monte Carlo Tree Search\n  Applications",
                "作者": " Marco Kemmerling,  Daniel Lütticke,  Robert H. Schmitt",
                "发布日期": "2023-12-29",
                "摘要": "  The advent of AlphaGo and its successors marked the beginning of a new\nparadigm in playing games using artificial intelligence. This was achieved by\ncombining Monte Carlo tree search, a planning procedure, and deep learning.\nWhile the impact on the domain of games has been undeniable, it is less clear\nhow useful similar approaches are in applications beyond games and how they\nneed to be adapted from the original methodology. We review 129 peer-reviewed\narticles detailing the application of neural Monte Carlo tree search methods in\ndomains other than games. Our goal is to systematically assess how such methods\nare structured in practice and if their success can be extended to other\ndomains. We find applications in a variety of domains, many distinct ways of\nguiding the tree search using learned policy and value functions, and various\ntraining methods. Our review maps the current landscape of algorithms in the\nfamily of neural monte carlo tree search as they are applied to practical\nproblems, which is a first step towards a more principled way of designing such\nalgorithms for specific problems and their requirements.\n",
                "链接": "https://arxiv.org/abs/2303.08060"
            },
            {
                "文章ID": "5515",
                "标题": "A Unified Perspective on Value Backup and Exploration in Monte-Carlo\n  Tree Search",
                "作者": " Tuan Dam,  Carlo D'Eramo,  Jan Peters,  Joni Pajarinen",
                "发布日期": "2022-02-16",
                "摘要": "  Monte-Carlo Tree Search (MCTS) is a class of methods for solving complex\ndecision-making problems through the synergy of Monte-Carlo planning and\nReinforcement Learning (RL). The highly combinatorial nature of the problems\ncommonly addressed by MCTS requires the use of efficient exploration strategies\nfor navigating the planning tree and quickly convergent value backup methods.\nThese crucial problems are particularly evident in recent advances that combine\nMCTS with deep neural networks for function approximation. In this work, we\npropose two methods for improving the convergence rate and exploration based on\na newly introduced backup operator and entropy regularization. We provide\nstrong theoretical guarantees to bound convergence rate, approximation error,\nand regret of our methods. Moreover, we introduce a mathematical framework\nbased on the use of the $\\alpha$-divergence for backup and exploration in MCTS.\nWe show that this theoretical formulation unifies different approaches,\nincluding our newly introduced ones, under the same mathematical framework,\nallowing to obtain different methods by simply changing the value of $\\alpha$.\nIn practice, our unified perspective offers a flexible way to balance between\nexploration and exploitation by tuning the single $\\alpha$ parameter according\nto the problem at hand. We validate our methods through a rigorous empirical\nstudy from basic toy problems to the complex Atari games, and including both\nMDP and POMDP problems.\n",
                "链接": "https://arxiv.org/abs/2202.07071"
            },
            {
                "文章ID": "117818",
                "标题": "How to ensure a safe control strategy? Towards a SRL for urban transit\n  autonomous operation",
                "作者": " Zicong Zhao",
                "发布日期": "2023-11-27",
                "摘要": "  Deep reinforcement learning has gradually shown its latent decision-making\nability in urban rail transit autonomous operation. However, since\nreinforcement learning can not neither guarantee safety during learning nor\nexecution, this is still one of the major obstacles to the practical\napplication of reinforcement learning. Given this drawback, reinforcement\nlearning applied in the safety-critical autonomous operation domain remains\nchallenging without generating a safe control command sequence that avoids\noverspeed operations. Therefore, a SSA-DRL framework is proposed in this paper\nfor safe intelligent control of urban rail transit autonomous operation trains.\nThe proposed framework is combined with linear temporal logic, reinforcement\nlearning and Monte Carlo tree search and consists of four mainly module: a\npost-posed shielding, a searching tree module, a DRL framework and an\nadditional actor. Furthermore, the output of the framework can meet speed\nconstraint, schedule constraint and optimize the operation process. Finally,\nthe proposed SSA-DRL framework for decision-making in urban rail transit\nautonomous operation is evaluated in sixteen different sections, and its\neffectiveness is demonstrated through an ablation experiment and comparison\nwith the scheduled operation plan.\n",
                "链接": "https://arxiv.org/abs/2311.14457"
            },
            {
                "文章ID": "75072",
                "标题": "Nearly Optimal Steiner Trees using Graph Neural Network Assisted Monte\n  Carlo Tree Search",
                "作者": " Reyan Ahmed,  Mithun Ghosh,  Kwang-Sung Jun,  Stephen Kobourov",
                "发布日期": "2023-05-02",
                "摘要": "  Graph neural networks are useful for learning problems, as well as for\ncombinatorial and graph problems such as the Subgraph Isomorphism Problem and\nthe Traveling Salesman Problem. We describe an approach for computing Steiner\nTrees by combining a graph neural network and Monte Carlo Tree Search. We first\ntrain a graph neural network that takes as input a partial solution and\nproposes a new node to be added as output. This neural network is then used in\na Monte Carlo search to compute a Steiner tree. The proposed method\nconsistently outperforms the standard 2-approximation algorithm on many\ndifferent types of graphs and often finds the optimal solution.\n",
                "链接": "https://arxiv.org/abs/2305.00535"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用gpt4做评测指标优缺点的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "116110",
                "标题": "Enhancing Medical Text Evaluation with GPT-4",
                "作者": " Yiqing Xie,  Sheng Zhang,  Hao Cheng,  Zelalem Gero,  Cliff Wong,  Tristan Naumann,  Hoifung Poon",
                "发布日期": "2023-11-17",
                "摘要": "  In the evaluation of medical text generation, it is essential to scrutinize\neach piece of information and ensure the utmost accuracy of the evaluation.\nExisting evaluation metrics either focus on coarse-level evaluation that\nassigns one score for the whole generated output or rely on evaluation models\ntrained on general domain, resulting in inaccuracies when adapted to the\nmedical domain. To address these issues, we propose a set of factuality-centric\nevaluation aspects and design corresponding GPT-4-based metrics for medical\ntext generation. We systematically compare these metrics with existing ones on\nclinical note generation and medical report summarization tasks, revealing low\ninter-metric correlation. A comprehensive human evaluation confirms that the\nproposed GPT-4-based metrics exhibit substantially higher agreement with human\njudgments than existing evaluation metrics. Our study contributes to the\nunderstanding of medical text generation evaluation and offers a more reliable\nalternative to existing metrics.\n",
                "链接": "https://arxiv.org/abs/2311.09581"
            },
            {
                "文章ID": "104458",
                "标题": "Question-Answering Approach to Evaluating Legal Summaries",
                "作者": " Huihui Xu,  Kevin Ashley",
                "发布日期": "2023-12-20",
                "摘要": "  Traditional evaluation metrics like ROUGE compare lexical overlap between the\nreference and generated summaries without taking argumentative structure into\naccount, which is important for legal summaries. In this paper, we propose a\nnovel legal summarization evaluation framework that utilizes GPT-4 to generate\na set of question-answer pairs that cover main points and information in the\nreference summary. GPT-4 is then used to generate answers based on the\ngenerated summary for the questions from the reference summary. Finally, GPT-4\ngrades the answers from the reference summary and the generated summary. We\nexamined the correlation between GPT-4 grading with human grading. The results\nsuggest that this question-answering approach with GPT-4 can be a useful tool\nfor gauging the quality of the summary.\n",
                "链接": "https://arxiv.org/abs/2309.15016"
            },
            {
                "文章ID": "98679",
                "标题": "A Comprehensive Survey for Evaluation Methodologies of AI-Generated\n  Music",
                "作者": " Zeyu Xiong,  Weitao Wang,  Jing Yu,  Yue Lin,  Ziyan Wang",
                "发布日期": "2023-08-29",
                "摘要": "  In recent years, AI-generated music has made significant progress, with\nseveral models performing well in multimodal and complex musical genres and\nscenes. While objective metrics can be used to evaluate generative music, they\noften lack interpretability for musical evaluation. Therefore, researchers\noften resort to subjective user studies to assess the quality of the generated\nworks, which can be resource-intensive and less reproducible than objective\nmetrics. This study aims to comprehensively evaluate the subjective, objective,\nand combined methodologies for assessing AI-generated music, highlighting the\nadvantages and disadvantages of each approach. Ultimately, this study provides\na valuable reference for unifying generative AI in the field of music\nevaluation.\n",
                "链接": "https://arxiv.org/abs/2308.13736"
            },
            {
                "文章ID": "79915",
                "标题": "INSTRUCTSCORE: Explainable Text Generation Evaluation with Finegrained\n  Feedback",
                "作者": " Wenda Xu,  Danqing Wang,  Liangming Pan,  Zhenqiao Song,  Markus Freitag,  William Yang Wang,  Lei Li",
                "发布日期": "2023-10-30",
                "摘要": "  Automatically evaluating the quality of language generation is critical.\nAlthough recent learned metrics show high correlation with human judgement,\nthese metrics can not explain their verdict or associate the scores with\ndefects in generated text. To address this limitation, we present\nInstructScore, an explainable evaluation metric for text generation. By\nharnessing both explicit human instruction and the implicit knowledge of GPT-4,\nwe fine-tune a text evaluation metric based on LLaMA, producing both a score\nfor generated text and a human readable diagnostic report. We evaluate\nInstructScore on a variety of generation tasks, including translation,\ncaptioning, data-to-text and commonsense generation. Experiments show that our\n7B model surpasses all other unsupervised metrics, including those based on\n175B GPT-3 and GPT-4. Surprisingly, our InstructScore, even without direct\nsupervision from human-rated data, achieves performance levels on par with\nstate-of-the-art metrics like COMET22, which were fine-tuned on human ratings.\n",
                "链接": "https://arxiv.org/abs/2305.14282"
            },
            {
                "文章ID": "110350",
                "标题": "Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large\n  Language Models on Sequence to Sequence Tasks",
                "作者": " Andrea Sottana,  Bin Liang,  Kai Zou,  Zheng Yuan",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) evaluation is a patchy and inconsistent\nlandscape, and it is becoming clear that the quality of automatic evaluation\nmetrics is not keeping up with the pace of development of generative models. We\naim to improve the understanding of current models' performance by providing a\npreliminary and hybrid evaluation on a range of open and closed-source\ngenerative LLMs on three NLP benchmarks: text summarisation, text\nsimplification and grammatical error correction (GEC), using both automatic and\nhuman evaluation. We also explore the potential of the recently released GPT-4\nto act as an evaluator. We find that ChatGPT consistently outperforms many\nother popular models according to human reviewers on the majority of metrics,\nwhile scoring much more poorly when using classic automatic evaluation metrics.\nWe also find that human reviewers rate the gold reference as much worse than\nthe best models' outputs, indicating the poor quality of many popular\nbenchmarks. Finally, we find that GPT-4 is capable of ranking models' outputs\nin a way which aligns reasonably closely to human judgement despite\ntask-specific variations, with a lower alignment in the GEC task.\n",
                "链接": "https://arxiv.org/abs/2310.13800"
            },
            {
                "文章ID": "84944",
                "标题": "Overview of Deep Learning Methods for Retinal Vessel Segmentation",
                "作者": " Gorana Gojić,  Ognjen Kundačina,  Dragiša Mišković,  Dinu Dragan",
                "发布日期": "2023-06-13",
                "摘要": "  Methods for automated retinal vessel segmentation play an important role in\nthe treatment and diagnosis of many eye and systemic diseases. With the fast\ndevelopment of deep learning methods, more and more retinal vessel segmentation\nmethods are implemented as deep neural networks. In this paper, we provide a\nbrief review of recent deep learning methods from highly influential journals\nand conferences. The review objectives are: (1) to assess the design\ncharacteristics of the latest methods, (2) to report and analyze quantitative\nvalues of performance evaluation metrics, and (3) to analyze the advantages and\ndisadvantages of the recent solutions.\n",
                "链接": "https://arxiv.org/abs/2306.06116"
            },
            {
                "文章ID": "90338",
                "标题": "Argumentative Segmentation Enhancement for Legal Summarization",
                "作者": " Huihui Xu,  Kevin Ashley",
                "发布日期": "2023-07-12",
                "摘要": "  We use the combination of argumentative zoning [1] and a legal argumentative\nscheme to create legal argumentative segments. Based on the argumentative\nsegmentation, we propose a novel task of classifying argumentative segments of\nlegal case decisions. GPT-3.5 is used to generate summaries based on\nargumentative segments. In terms of automatic evaluation metrics, our method\ngenerates higher quality argumentative summaries while leaving out less\nrelevant context as compared to GPT-4 and non-GPT models.\n",
                "链接": "https://arxiv.org/abs/2307.05081"
            },
            {
                "文章ID": "118259",
                "标题": "GPT4Vis: What Can GPT-4 Do for Zero-shot Visual Recognition?",
                "作者": " Wenhao Wu,  Huanjin Yao,  Mengxi Zhang,  Yuxin Song,  Wanli Ouyang,  Jingdong Wang",
                "发布日期": "2023-11-28",
                "摘要": "  This paper does not present a novel method. Instead, it delves into an\nessential, yet must-know baseline in light of the latest advancements in\nGenerative Artificial Intelligence (GenAI): the utilization of GPT-4 for visual\nunderstanding. Our study centers on the evaluation of GPT-4's linguistic and\nvisual capabilities in zero-shot visual recognition tasks. Specifically, we\nexplore the potential of its generated rich textual descriptions across various\ncategories to enhance recognition performance without any training.\nAdditionally, we evaluate its visual proficiency in directly recognizing\ndiverse visual content. To achieve this, we conduct an extensive series of\nexperiments, systematically quantifying the performance of GPT-4 across three\nmodalities: images, videos, and point clouds. This comprehensive evaluation\nencompasses a total of 16 widely recognized benchmark datasets, providing top-1\nand top-5 accuracy metrics. Our study reveals that leveraging GPT-4's advanced\nlinguistic knowledge to generate rich descriptions markedly improves zero-shot\nrecognition. In terms of visual proficiency, GPT-4V's average performance\nacross 16 datasets sits roughly between the capabilities of OpenAI-CLIP's ViT-L\nand EVA-CLIP's ViT-E. We hope that this research will contribute valuable data\npoints and experience for future studies. We release our code at\nhttps://github.com/whwu95/GPT4Vis.\n",
                "链接": "https://arxiv.org/abs/2311.15732"
            },
            {
                "文章ID": "80356",
                "标题": "Is GPT-4 a Good Data Analyst?",
                "作者": " Liying Cheng,  Xingxuan Li,  Lidong Bing",
                "发布日期": "2023-10-24",
                "摘要": "  As large language models (LLMs) have demonstrated their powerful capabilities\nin plenty of domains and tasks, including context understanding, code\ngeneration, language generation, data storytelling, etc., many data analysts\nmay raise concerns if their jobs will be replaced by artificial intelligence\n(AI). This controversial topic has drawn great attention in public. However, we\nare still at a stage of divergent opinions without any definitive conclusion.\nMotivated by this, we raise the research question of \"is GPT-4 a good data\nanalyst?\" in this work and aim to answer it by conducting head-to-head\ncomparative studies. In detail, we regard GPT-4 as a data analyst to perform\nend-to-end data analysis with databases from a wide range of domains. We\npropose a framework to tackle the problems by carefully designing the prompts\nfor GPT-4 to conduct experiments. We also design several task-specific\nevaluation metrics to systematically compare the performance between several\nprofessional human data analysts and GPT-4. Experimental results show that\nGPT-4 can achieve comparable performance to humans. We also provide in-depth\ndiscussions about our results to shed light on further studies before reaching\nthe conclusion that GPT-4 can replace data analysts.\n",
                "链接": "https://arxiv.org/abs/2305.15038"
            },
            {
                "文章ID": "105289",
                "标题": "SocREval: Large Language Models with the Socratic Method for\n  Reference-Free Reasoning Evaluation",
                "作者": " Hangfeng He,  Hongming Zhang,  Dan Roth",
                "发布日期": "2023-10-03",
                "摘要": "  To comprehensively assess the capacity of current models for complex\nreasoning, it is crucial to assess their step-by-step reasoning in a scalable\nmanner. Established reference-based evaluation metrics rely on human-annotated\nreasoning chains to assess the model-derived chains. However, such\n``gold-standard'' human-written reasoning chains may not be unique and their\nacquisition is often labor-intensive. Existing reference-free reasoning metrics\neliminate the need for human-crafted reasoning chains as references, but they\ntypically require fine-tuning on datasets with human-derived reasoning chains,\nwhich complicates the process and raises concerns regarding generalizability\nacross diverse datasets. To address these challenges, we harness GPT-4 to\nautomatically evaluate reasoning chain quality, obviating the need for\nhuman-crafted references. Leveraging the Socratic method, we devise tailored\nprompts to enhance reference-free reasoning evaluation, which we term SocREval\n(Socratic method for Reasoning Evaluation). Empirical results from four human\nannotated datasets reveal that SocREval significantly improves GPT-4's\nperformance, surpassing existing reference-free and reference-based reasoning\nevaluation metrics. Beyond its demonstrated efficacy, our proposed framework,\nlarge language models (LLMs) with the Socratic method, proves to be both\ncost-efficient and robust to prompt writing and example selection, as\nsubstantiated by our in-depth analysis.\n",
                "链接": "https://arxiv.org/abs/2310.00074"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用GPT4v完成多模态智能体的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "120902",
                "标题": "GPT-4V with Emotion: A Zero-shot Benchmark for Multimodal Emotion\n  Understanding",
                "作者": " Zheng Lian,  Licai Sun,  Haiyang Sun,  Kang Chen,  Zhuofan Wen,  Hao Gu,  Shun Chen,  Bin Liu,  Jianhua Tao",
                "发布日期": "2023-12-08",
                "摘要": "  Recently, GPT-4 with Vision (GPT-4V) has shown remarkable performance across\nvarious multimodal tasks. However, its efficacy in emotion recognition remains\na question. This paper quantitatively evaluates GPT-4V's capabilities in\nmultimodal emotion understanding, encompassing tasks such as facial emotion\nrecognition, visual sentiment analysis, micro-expression recognition, dynamic\nfacial emotion recognition, and multimodal emotion recognition. Our experiments\nshow that GPT-4V exhibits impressive multimodal and temporal understanding\ncapabilities, even surpassing supervised systems in some tasks. Despite these\nachievements, GPT-4V is currently tailored for general domains. It performs\npoorly in micro-expression recognition that requires specialized expertise. The\nmain purpose of this paper is to present quantitative results of GPT-4V on\nemotion understanding and establish a zero-shot benchmark for future research.\nCode and evaluation results are available at:\nhttps://github.com/zeroQiaoba/gpt4v-emotion.\n",
                "链接": "https://arxiv.org/abs/2312.04293"
            },
            {
                "文章ID": "112337",
                "标题": "Multimodal ChatGPT for Medical Applications: an Experimental Study of\n  GPT-4V",
                "作者": " Zhiling Yan,  Kai Zhang,  Rong Zhou,  Lifang He,  Xiang Li,  Lichao Sun",
                "发布日期": "2023-10-31",
                "摘要": "  In this paper, we critically evaluate the capabilities of the\nstate-of-the-art multimodal large language model, i.e., GPT-4 with Vision\n(GPT-4V), on Visual Question Answering (VQA) task. Our experiments thoroughly\nassess GPT-4V's proficiency in answering questions paired with images using\nboth pathology and radiology datasets from 11 modalities (e.g. Microscopy,\nDermoscopy, X-ray, CT, etc.) and fifteen objects of interests (brain, liver,\nlung, etc.). Our datasets encompass a comprehensive range of medical inquiries,\nincluding sixteen distinct question types. Throughout our evaluations, we\ndevised textual prompts for GPT-4V, directing it to synergize visual and\ntextual information. The experiments with accuracy score conclude that the\ncurrent version of GPT-4V is not recommended for real-world diagnostics due to\nits unreliable and suboptimal accuracy in responding to diagnostic medical\nquestions. In addition, we delineate seven unique facets of GPT-4V's behavior\nin medical VQA, highlighting its constraints within this complex arena. The\ncomplete details of our evaluation cases are accessible at\nhttps://github.com/ZhilingYan/GPT4V-Medical-Report.\n",
                "链接": "https://arxiv.org/abs/2310.19061"
            },
            {
                "文章ID": "115104",
                "标题": "Monkey: Image Resolution and Text Label Are Important Things for Large\n  Multi-modal Models",
                "作者": " Zhang Li,  Biao Yang,  Qiang Liu,  Zhiyin Ma,  Shuo Zhang,  Jingxu Yang,  Yabo Sun,  Yuliang Liu,  Xiang Bai",
                "发布日期": "2023-11-27",
                "摘要": "  Large Multimodal Models (LMMs) have shown promise in vision-language tasks\nbut struggle with high-resolution input and detailed scene understanding.\nAddressing these challenges, we introduce Monkey to enhance LMM capabilities.\nFirstly, Monkey processes input images by dividing them into uniform patches,\neach matching the size (e.g., 448x448) used in the original training of the\nwell-trained vision encoder. Equipped with individual adapter for each patch,\nMonkey can handle higher resolutions up to 1344x896 pixels, enabling the\ndetailed capture of complex visual information. Secondly, it employs a\nmulti-level description generation method, enriching the context for\nscene-object associations. This two-part strategy ensures more effective\nlearning from generated data: the higher resolution allows for a more detailed\ncapture of visuals, which in turn enhances the effectiveness of comprehensive\ndescriptions. Extensive ablative results validate the effectiveness of our\ndesigns. Additionally, experiments on 18 datasets further demonstrate that\nMonkey surpasses existing LMMs in many tasks like Image Captioning and various\nVisual Question Answering formats. Specially, in qualitative tests focused on\ndense text question answering, Monkey has exhibited encouraging results\ncompared with GPT4V. Code is available at\nhttps://github.com/Yuliang-Liu/Monkey.\n",
                "链接": "https://arxiv.org/abs/2311.06607"
            },
            {
                "文章ID": "114711",
                "标题": "On the Road with GPT-4V(ision): Early Explorations of Visual-Language\n  Model on Autonomous Driving",
                "作者": " Licheng Wen,  Xuemeng Yang,  Daocheng Fu,  Xiaofeng Wang,  Pinlong Cai,  Xin Li,  Tao Ma,  Yingxuan Li,  Linran Xu,  Dengke Shang,  Zheng Zhu,  Shaoyan Sun,  Yeqi Bai,  Xinyu Cai,  Min Dou,  Shuanglu Hu,  Botian Shi,  Yu Qiao",
                "发布日期": "2023-11-29",
                "摘要": "  The pursuit of autonomous driving technology hinges on the sophisticated\nintegration of perception, decision-making, and control systems. Traditional\napproaches, both data-driven and rule-based, have been hindered by their\ninability to grasp the nuance of complex driving environments and the\nintentions of other road users. This has been a significant bottleneck,\nparticularly in the development of common sense reasoning and nuanced scene\nunderstanding necessary for safe and reliable autonomous driving. The advent of\nVisual Language Models (VLM) represents a novel frontier in realizing fully\nautonomous vehicle driving. This report provides an exhaustive evaluation of\nthe latest state-of-the-art VLM, GPT-4V(ision), and its application in\nautonomous driving scenarios. We explore the model's abilities to understand\nand reason about driving scenes, make decisions, and ultimately act in the\ncapacity of a driver. Our comprehensive tests span from basic scene recognition\nto complex causal reasoning and real-time decision-making under varying\nconditions. Our findings reveal that GPT-4V demonstrates superior performance\nin scene understanding and causal reasoning compared to existing autonomous\nsystems. It showcases the potential to handle out-of-distribution scenarios,\nrecognize intentions, and make informed decisions in real driving contexts.\nHowever, challenges remain, particularly in direction discernment, traffic\nlight recognition, vision grounding, and spatial reasoning tasks. These\nlimitations underscore the need for further research and development. Project\nis now available on GitHub for interested parties to access and utilize:\n\\url{https://github.com/PJLab-ADG/GPT4V-AD-Exploration}\n",
                "链接": "https://arxiv.org/abs/2311.05332"
            },
            {
                "文章ID": "122166",
                "标题": "A Foundational Multimodal Vision Language AI Assistant for Human\n  Pathology",
                "作者": " Ming Y. Lu,  Bowen Chen,  Drew F. K. Williamson,  Richard J. Chen,  Kenji Ikamura,  Georg Gerber,  Ivy Liang,  Long Phi Le,  Tong Ding,  Anil V Parwani,  Faisal Mahmood",
                "发布日期": "2023-12-14",
                "摘要": "  The field of computational pathology has witnessed remarkable progress in the\ndevelopment of both task-specific predictive models and task-agnostic\nself-supervised vision encoders. However, despite the explosive growth of\ngenerative artificial intelligence (AI), there has been limited study on\nbuilding general purpose, multimodal AI assistants tailored to pathology. Here\nwe present PathChat, a vision-language generalist AI assistant for human\npathology using an in-house developed foundational vision encoder pretrained on\n100 million histology images from over 100,000 patient cases and 1.18 million\npathology image-caption pairs. The vision encoder is then combined with a\npretrained large language model and the whole system is finetuned on over\n250,000 diverse disease agnostic visual language instructions. We compare\nPathChat against several multimodal vision language AI assistants as well as\nGPT4V, which powers the commercially available multimodal general purpose AI\nassistant ChatGPT-4. When relevant clinical context is provided with the\nhistology image, PathChat achieved a diagnostic accuracy of 87% on\nmultiple-choice questions based on publicly available cases of diverse tissue\norigins and disease models. Additionally, using open-ended questions and human\nexpert evaluation, we found that overall PathChat produced more accurate and\npathologist-preferable responses to diverse queries related to pathology. As an\ninteractive and general vision language AI assistant that can flexibly handle\nboth visual and natural language inputs, PathChat can potentially find\nimpactful applications in pathology education, research, and human-in-the-loop\nclinical decision making.\n",
                "链接": "https://arxiv.org/abs/2312.07814"
            }
        ]
    },
    {
        "question": {
            "question": "使用LLM进行蛋白质结构/功能/性质预测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "109510",
                "标题": "Protein 3D Graph Structure Learning for Robust Structure-based Protein\n  Property Prediction",
                "作者": " Yufei Huang,  Siyuan Li,  Jin Su,  Lirong Wu,  Odin Zhang,  Haitao Lin,  Jingqi Qi,  Zihan Liu,  Zhangyang Gao,  Yuyang Liu,  Jiangbin Zheng,  Stan. ZQ. Li",
                "发布日期": "2023-10-20",
                "摘要": "  Protein structure-based property prediction has emerged as a promising\napproach for various biological tasks, such as protein function prediction and\nsub-cellular location estimation. The existing methods highly rely on\nexperimental protein structure data and fail in scenarios where these data are\nunavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were\nutilized as alternatives. However, we observed that current practices, which\nsimply employ accurately predicted structures during inference, suffer from\nnotable degradation in prediction accuracy. While similar phenomena have been\nextensively studied in general fields (e.g., Computer Vision) as model\nrobustness, their impact on protein property prediction remains unexplored. In\nthis paper, we first investigate the reason behind the performance decrease\nwhen utilizing predicted structures, attributing it to the structure embedding\nbias from the perspective of structure representation learning. To study this\nproblem, we identify a Protein 3D Graph Structure Learning Problem for Robust\nProtein Property Prediction (PGSL-RP3), collect benchmark datasets, and present\na protein Structure embedding Alignment Optimization framework (SAO) to\nmitigate the problem of structure embedding bias between the predicted and\nexperimental protein structures. Extensive experiments have shown that our\nframework is model-agnostic and effective in improving the property prediction\nof both predicted structures and experimental structures. The benchmark\ndatasets and codes will be released to benefit the community.\n",
                "链接": "https://arxiv.org/abs/2310.11466"
            },
            {
                "文章ID": "70802",
                "标题": "EigenFold: Generative Protein Structure Prediction with Diffusion Models",
                "作者": " Bowen Jing,  Ezra Erives,  Peter Pao-Huang,  Gabriele Corso,  Bonnie Berger,  Tommi Jaakkola",
                "发布日期": "2023-04-06",
                "摘要": "  Protein structure prediction has reached revolutionary levels of accuracy on\nsingle structures, yet distributional modeling paradigms are needed to capture\nthe conformational ensembles and flexibility that underlie biological function.\nTowards this goal, we develop EigenFold, a diffusion generative modeling\nframework for sampling a distribution of structures from a given protein\nsequence. We define a diffusion process that models the structure as a system\nof harmonic oscillators and which naturally induces a cascading-resolution\ngenerative process along the eigenmodes of the system. On recent CAMEO targets,\nEigenFold achieves a median TMScore of 0.84, while providing a more\ncomprehensive picture of model uncertainty via the ensemble of sampled\nstructures relative to existing methods. We then assess EigenFold's ability to\nmodel and predict conformational heterogeneity for fold-switching proteins and\nligand-induced conformational change. Code is available at\nhttps://github.com/bjing2016/EigenFold.\n",
                "链接": "https://arxiv.org/abs/2304.02198"
            },
            {
                "文章ID": "26245",
                "标题": "PSP: Million-level Protein Sequence Dataset for Protein Structure\n  Prediction",
                "作者": " Sirui Liu,  Jun Zhang,  Haotian Chu,  Min Wang,  Boxin Xue,  Ningxi Ni,  Jialiang Yu,  Yuhao Xie,  Zhenyu Chen,  Mengyun Chen,  Yuan Liu,  Piya Patra,  Fan Xu,  Jie Chen,  Zidong Wang,  Lijiang Yang,  Fan Yu,  Lei Chen,  Yi Qin Gao",
                "发布日期": "2022-06-27",
                "摘要": "  Proteins are essential component of human life and their structures are\nimportant for function and mechanism analysis. Recent work has shown the\npotential of AI-driven methods for protein structure prediction. However, the\ndevelopment of new models is restricted by the lack of dataset and benchmark\ntraining procedure. To the best of our knowledge, the existing open source\ndatasets are far less to satisfy the needs of modern protein sequence-structure\nrelated research. To solve this problem, we present the first million-level\nprotein structure prediction dataset with high coverage and diversity, named as\nPSP. This dataset consists of 570k true structure sequences (10TB) and 745k\ncomplementary distillation sequences (15TB). We provide in addition the\nbenchmark training procedure for SOTA protein structure prediction model on\nthis dataset. We validate the utility of this dataset for training by\nparticipating CAMEO contest in which our model won the first place. We hope our\nPSP dataset together with the training benchmark can enable a broader community\nof AI/biology researchers for AI-driven protein related research.\n",
                "链接": "https://arxiv.org/abs/2206.12240"
            },
            {
                "文章ID": "34638",
                "标题": "Secondary Protein Structure Prediction Using Neural Networks",
                "作者": " Sidharth Malhotra,  Robin Walters",
                "发布日期": "2022-08-25",
                "摘要": "  In this paper we experiment with using neural network structures to predict a\nprotein's secondary structure ({\\alpha} helix positions) from only its primary\nstructure (amino acid sequence). We implement a fully connected neural network\n(FCNN) and preform three experiments using that FCNN. Firstly, we do a\ncross-species comparison of models trained and tested on mouse and human\ndatasets. Secondly, we test the impact of varying the length of protein\nsequence we input into the model. Thirdly, we compare custom error functions\ndesigned to focus on the center of the input window. At the end of paper we\npropose a alternative, recurrent neural network model which can be applied to\nthe problem.\n",
                "链接": "https://arxiv.org/abs/2208.11248"
            },
            {
                "文章ID": "125227",
                "标题": "Molecular Property Prediction Based on Graph Structure Learning",
                "作者": " Bangyi Zhao,  Weixia Xu,  Jihong Guan,  Shuigeng Zhou",
                "发布日期": "2023-12-29",
                "摘要": "  Molecular property prediction (MPP) is a fundamental but challenging task in\nthe computer-aided drug discovery process. More and more recent works employ\ndifferent graph-based models for MPP, which have made considerable progress in\nimproving prediction performance. However, current models often ignore\nrelationships between molecules, which could be also helpful for MPP. For this\nsake, in this paper we propose a graph structure learning (GSL) based MPP\napproach, called GSL-MPP. Specifically, we first apply graph neural network\n(GNN) over molecular graphs to extract molecular representations. Then, with\nmolecular fingerprints, we construct a molecular similarity graph (MSG).\nFollowing that, we conduct graph structure learning on the MSG (i.e.,\nmolecule-level graph structure learning) to get the final molecular embeddings,\nwhich are the results of fusing both GNN encoded molecular representations and\nthe relationships among molecules, i.e., combining both intra-molecule and\ninter-molecule information. Finally, we use these molecular embeddings to\nperform MPP. Extensive experiments on seven various benchmark datasets show\nthat our method could achieve state-of-the-art performance in most cases,\nespecially on classification tasks. Further visualization studies also\ndemonstrate the good molecular representations of our method.\n",
                "链接": "https://arxiv.org/abs/2312.16855"
            },
            {
                "文章ID": "106701",
                "标题": "CrysFormer: Protein Structure Prediction via 3d Patterson Maps and\n  Partial Structure Attention",
                "作者": " Chen Dun,  Qiutai Pan,  Shikai Jin,  Ria Stevens,  Mitchell D. Miller, Jr. George N. Phillips,,  Anastasios Kyrillidis",
                "发布日期": "2023-10-09",
                "摘要": "  Determining the structure of a protein has been a decades-long open question.\nA protein's three-dimensional structure often poses nontrivial computation\ncosts, when classical simulation algorithms are utilized. Advances in the\ntransformer neural network architecture -- such as AlphaFold2 -- achieve\nsignificant improvements for this problem, by learning from a large dataset of\nsequence information and corresponding protein structures. Yet, such methods\nonly focus on sequence information; other available prior knowledge, such as\nprotein crystallography and partial structure of amino acids, could be\npotentially utilized. To the best of our knowledge, we propose the first\ntransformer-based model that directly utilizes protein crystallography and\npartial structure information to predict the electron density maps of proteins.\nVia two new datasets of peptide fragments (2-residue and 15-residue) , we\ndemonstrate our method, dubbed \\texttt{CrysFormer}, can achieve accurate\npredictions, based on a much smaller dataset size and with reduced computation\ncosts.\n",
                "链接": "https://arxiv.org/abs/2310.03899"
            },
            {
                "文章ID": "51324",
                "标题": "Protein Language Models and Structure Prediction: Connection and\n  Progression",
                "作者": " Bozhen Hu,  Jun Xia,  Jiangbin Zheng,  Cheng Tan,  Yufei Huang,  Yongjie Xu,  Stan Z. Li",
                "发布日期": "2022-12-01",
                "摘要": "  The prediction of protein structures from sequences is an important task for\nfunction prediction, drug design, and related biological processes\nunderstanding. Recent advances have proved the power of language models (LMs)\nin processing the protein sequence databases, which inherit the advantages of\nattention networks and capture useful information in learning representations\nfor proteins. The past two years have witnessed remarkable success in tertiary\nprotein structure prediction (PSP), including evolution-based and\nsingle-sequence-based PSP. It seems that instead of using energy-based models\nand sampling procedures, protein language model (pLM)-based pipelines have\nemerged as mainstream paradigms in PSP. Despite the fruitful progress, the PSP\ncommunity needs a systematic and up-to-date survey to help bridge the gap\nbetween LMs in the natural language processing (NLP) and PSP domains and\nintroduce their methodologies, advancements and practical applications. To this\nend, in this paper, we first introduce the similarities between protein and\nhuman languages that allow LMs extended to pLMs, and applied to protein\ndatabases. Then, we systematically review recent advances in LMs and pLMs from\nthe perspectives of network architectures, pre-training strategies,\napplications, and commonly-used protein databases. Next, different types of\nmethods for PSP are discussed, particularly how the pLM-based architectures\nfunction in the process of protein folding. Finally, we identify challenges\nfaced by the PSP community and foresee promising research directions along with\nthe advances of pLMs. This survey aims to be a hands-on guide for researchers\nto understand PSP methods, develop pLMs and tackle challenging problems in this\nfield for practical purposes.\n",
                "链接": "https://arxiv.org/abs/2211.16742"
            },
            {
                "文章ID": "48975",
                "标题": "A Review of Deep Learning Techniques for Protein Function Prediction",
                "作者": " Divyanshu Aggarwal,  Yasha Hasija",
                "发布日期": "2022-11-18",
                "摘要": "  Deep Learning and big data have shown tremendous success in bioinformatics\nand computational biology in recent years; artificial intelligence methods have\nalso significantly contributed in the task of protein function classification.\nThis review paper analyzes the recent developments in approaches for the task\nof predicting protein function using deep learning. We explain the importance\nof determining the protein function and why automating the following task is\ncrucial. Then, after reviewing the widely used deep learning techniques for\nthis task, we continue our review and highlight the emergence of the modern\nState of The Art (SOTA) deep learning models which have achieved groundbreaking\nresults in the field of computer vision, natural language processing and\nmulti-modal learning in the last few years. We hope that this review will\nprovide a broad view of the current role and advances of deep learning in\nbiological sciences, especially in predicting protein function tasks and\nencourage new researchers to contribute to this area.\n",
                "链接": "https://arxiv.org/abs/2211.09705"
            },
            {
                "文章ID": "57484",
                "标题": "Beating the Best: Improving on AlphaFold2 at Protein Structure\n  Prediction",
                "作者": " Abbi Abdel-Rehim,  Oghenejokpeme Orhobor,  Hang Lou,  Hao Ni,  Ross D. King",
                "发布日期": "2023-01-24",
                "摘要": "  The goal of Protein Structure Prediction (PSP) problem is to predict a\nprotein's 3D structure (confirmation) from its amino acid sequence. The problem\nhas been a 'holy grail' of science since the Noble prize-winning work of\nAnfinsen demonstrated that protein conformation was determined by sequence. A\nrecent and important step towards this goal was the development of AlphaFold2,\ncurrently the best PSP method. AlphaFold2 is probably the highest profile\napplication of AI to science. Both AlphaFold2 and RoseTTAFold (another\nimpressive PSP method) have been published and placed in the public domain\n(code & models). Stacking is a form of ensemble machine learning ML in which\nmultiple baseline models are first learnt, then a meta-model is learnt using\nthe outputs of the baseline level model to form a model that outperforms the\nbase models. Stacking has been successful in many applications. We developed\nthe ARStack PSP method by stacking AlphaFold2 and RoseTTAFold. ARStack\nsignificantly outperforms AlphaFold2. We rigorously demonstrate this using two\nsets of non-homologous proteins, and a test set of protein structures published\nafter that of AlphaFold2 and RoseTTAFold. As more high quality prediction\nmethods are published it is likely that ensemble methods will increasingly\noutperform any single method.\n",
                "链接": "https://arxiv.org/abs/2301.07568"
            },
            {
                "文章ID": "31301",
                "标题": "HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein\n  Language Model as an Alternative",
                "作者": " Xiaomin Fang,  Fan Wang,  Lihang Liu,  Jingzhou He,  Dayong Lin,  Yingfei Xiang,  Xiaonan Zhang,  Hua Wu,  Hui Li,  Le Song",
                "发布日期": "2023-10-19",
                "摘要": "  AI-based protein structure prediction pipelines, such as AlphaFold2, have\nachieved near-experimental accuracy. These advanced pipelines mainly rely on\nMultiple Sequence Alignments (MSAs) as inputs to learn the co-evolution\ninformation from the homologous sequences. Nonetheless, searching MSAs from\nprotein databases is time-consuming, usually taking dozens of minutes.\nConsequently, we attempt to explore the limits of fast protein structure\nprediction by using only primary sequences of proteins. HelixFold-Single is\nproposed to combine a large-scale protein language model with the superior\ngeometric learning capability of AlphaFold2. Our proposed method,\nHelixFold-Single, first pre-trains a large-scale protein language model (PLM)\nwith thousands of millions of primary sequences utilizing the self-supervised\nlearning paradigm, which will be used as an alternative to MSAs for learning\nthe co-evolution information. Then, by combining the pre-trained PLM and the\nessential components of AlphaFold2, we obtain an end-to-end differentiable\nmodel to predict the 3D coordinates of atoms from only the primary sequence.\nHelixFold-Single is validated in datasets CASP14 and CAMEO, achieving\ncompetitive accuracy with the MSA-based methods on the targets with large\nhomologous families. Furthermore, HelixFold-Single consumes much less time than\nthe mainstream pipelines for protein structure prediction, demonstrating its\npotential in tasks requiring many predictions. The code of HelixFold-Single is\navailable at\nhttps://github.com/PaddlePaddle/PaddleHelix/tree/dev/apps/protein_folding/helixfold-single,\nand we also provide stable web services on\nhttps://paddlehelix.baidu.com/app/drug/protein-single/forecast.\n",
                "链接": "https://arxiv.org/abs/2207.13921"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用BERT和RoBERTa进行多语言情感分析的最新论文，要求涵盖2022年以来的研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "15513",
                "标题": "Mono vs Multilingual BERT for Hate Speech Detection and Text\n  Classification: A Case Study in Marathi",
                "作者": " Abhishek Velankar,  Hrushikesh Patil,  Raviraj Joshi",
                "发布日期": "2022-11-15",
                "摘要": "  Transformers are the most eminent architectures used for a vast range of\nNatural Language Processing tasks. These models are pre-trained over a large\ntext corpus and are meant to serve state-of-the-art results over tasks like\ntext classification. In this work, we conduct a comparative study between\nmonolingual and multilingual BERT models. We focus on the Marathi language and\nevaluate the models on the datasets for hate speech detection, sentiment\nanalysis and simple text classification in Marathi. We use standard\nmultilingual models such as mBERT, indicBERT and xlm-RoBERTa and compare with\nMahaBERT, MahaALBERT and MahaRoBERTa, the monolingual models for Marathi. We\nfurther show that Marathi monolingual models outperform the multilingual BERT\nvariants on five different downstream fine-tuning experiments. We also evaluate\nsentence embeddings from these models by freezing the BERT encoder layers. We\nshow that monolingual MahaBERT based models provide rich representations as\ncompared to sentence embeddings from multi-lingual counterparts. However, we\nobserve that these embeddings are not generic enough and do not work well on\nout of domain social media datasets. We consider two Marathi hate speech\ndatasets L3Cube-MahaHate, HASOC-2021, a Marathi sentiment classification\ndataset L3Cube-MahaSent, and Marathi Headline, Articles classification\ndatasets.\n",
                "链接": "https://arxiv.org/abs/2204.08669"
            },
            {
                "文章ID": "52169",
                "标题": "Video Games as a Corpus: Sentiment Analysis using Fallout New Vegas\n  Dialog",
                "作者": " Mika Hämäläinen,  Khalid Alnajjar,  Thierry Poibeau",
                "发布日期": "2022-12-06",
                "摘要": "  We present a method for extracting a multilingual sentiment annotated dialog\ndata set from Fallout New Vegas. The game developers have preannotated every\nline of dialog in the game in one of the 8 different sentiments: \\textit{anger,\ndisgust, fear, happy, neutral, pained, sad } and \\textit{surprised}. The game\nhas been translated into English, Spanish, German, French and Italian. We\nconduct experiments on multilingual, multilabel sentiment analysis on the\nextracted data set using multilingual BERT, XLMRoBERTa and language specific\nBERT models. In our experiments, multilingual BERT outperformed XLMRoBERTa for\nmost of the languages, also language specific models were slightly better than\nmultilingual BERT for most of the languages. The best overall accuracy was 54\\%\nand it was achieved by using multilingual BERT on Spanish data. The extracted\ndata set presents a challenging task for sentiment analysis. We have released\nthe data, including the testing and training splits, openly on Zenodo. The data\nset has been shuffled for copyright reasons.\n",
                "链接": "https://arxiv.org/abs/2212.02168"
            },
            {
                "文章ID": "31048",
                "标题": "Enhancing Collaborative Filtering Recommender with Prompt-Based\n  Sentiment Analysis",
                "作者": " Elliot Dang,  Zheyuan Hu,  Tong Li",
                "发布日期": "2022-07-27",
                "摘要": "  Collaborative Filtering(CF) recommender is a crucial application in the\nonline market and ecommerce. However, CF recommender has been proven to suffer\nfrom persistent problems related to sparsity of the user rating that will\nfurther lead to a cold-start issue. Existing methods address the data sparsity\nissue by applying token-level sentiment analysis that translate text review\ninto sentiment scores as a complement of the user rating. In this paper, we\nattempt to optimize the sentiment analysis with advanced NLP models including\nBERT and RoBERTa, and experiment on whether the CF recommender has been further\nenhanced. We build the recommenders on the Amazon US Reviews dataset, and tune\nthe pretrained BERT and RoBERTa with the traditional fine-tuned paradigm as\nwell as the new prompt-based learning paradigm. Experimental result shows that\nthe recommender enhanced with the sentiment ratings predicted by the fine-tuned\nRoBERTa has the best performance, and achieved 30.7% overall gain by comparing\nMAP, NDCG and precision at K to the baseline recommender. Prompt-based learning\nparadigm, although superior to traditional fine-tune paradigm in pure sentiment\nanalysis, fail to further improve the CF recommender.\n",
                "链接": "https://arxiv.org/abs/2207.12883"
            },
            {
                "文章ID": "114320",
                "标题": "Modelling Sentiment Analysis: LLMs and data augmentation techniques",
                "作者": " Guillem Senabre Prades",
                "发布日期": "2023-11-08",
                "摘要": "  This paper provides different approaches for a binary sentiment\nclassification on a small training dataset. LLMs that provided state-of-the-art\nresults in sentiment analysis and similar domains are being used, such as BERT,\nRoBERTa and XLNet.\n",
                "链接": "https://arxiv.org/abs/2311.04139"
            },
            {
                "文章ID": "74465",
                "标题": "HausaNLP at SemEval-2023 Task 12: Leveraging African Low Resource\n  TweetData for Sentiment Analysis",
                "作者": " Saheed Abdullahi Salahudeen,  Falalu Ibrahim Lawan,  Ahmad Mustapha Wali,  Amina Abubakar Imam,  Aliyu Rabiu Shuaibu,  Aliyu Yusuf,  Nur Bala Rabiu,  Musa Bello,  Shamsuddeen Umaru Adamu,  Saminu Mohammad Aliyu,  Murja Sani Gadanya,  Sanah Abdullahi Muaz,  Mahmoud Said Ahmad,  Abdulkadir Abdullahi,  Abdulmalik Yusuf Jamoh",
                "发布日期": "2023-04-27",
                "摘要": "  We present the findings of SemEval-2023 Task 12, a shared task on sentiment\nanalysis for low-resource African languages using Twitter dataset. The task\nfeatured three subtasks; subtask A is monolingual sentiment classification with\n12 tracks which are all monolingual languages, subtask B is multilingual\nsentiment classification using the tracks in subtask A and subtask C is a\nzero-shot sentiment classification. We present the results and findings of\nsubtask A, subtask B and subtask C. We also release the code on github. Our\ngoal is to leverage low-resource tweet data using pre-trained Afro-xlmr-large,\nAfriBERTa-Large, Bert-base-arabic-camelbert-da-sentiment (Arabic-camelbert),\nMultilingual-BERT (mBERT) and BERT models for sentiment analysis of 14 African\nlanguages. The datasets for these subtasks consists of a gold standard\nmulti-class labeled Twitter datasets from these languages. Our results\ndemonstrate that Afro-xlmr-large model performed better compared to the other\nmodels in most of the languages datasets. Similarly, Nigerian languages: Hausa,\nIgbo, and Yoruba achieved better performance compared to other languages and\nthis can be attributed to the higher volume of data present in the languages.\n",
                "链接": "https://arxiv.org/abs/2304.13634"
            },
            {
                "文章ID": "82977",
                "标题": "UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of\n  Multilingual BERT for Low-resource Sentiment Analysis",
                "作者": " Dou Hu,  Lingwei Wei,  Yaxin Liu,  Wei Zhou,  Songlin Hu",
                "发布日期": "2023-06-05",
                "摘要": "  This paper describes our system designed for SemEval-2023 Task 12: Sentiment\nanalysis for African languages. The challenge faced by this task is the\nscarcity of labeled data and linguistic resources in low-resource settings. To\nalleviate these, we propose a generalized multilingual system SACL-XLMR for\nsentiment analysis on low-resource languages. Specifically, we design a\nlexicon-based multilingual BERT to facilitate language adaptation and\nsentiment-aware representation learning. Besides, we apply a supervised\nadversarial contrastive learning technique to learn sentiment-spread structured\nrepresentations and enhance model generalization. Our system achieved\ncompetitive results, largely outperforming baselines on both multilingual and\nzero-shot sentiment classification subtasks. Notably, the system obtained the\n1st rank on the zero-shot classification subtask in the official ranking.\nExtensive experiments demonstrate the effectiveness of our system.\n",
                "链接": "https://arxiv.org/abs/2306.01093"
            },
            {
                "文章ID": "93437",
                "标题": "Detecting the Presence of COVID-19 Vaccination Hesitancy from South\n  African Twitter Data Using Machine Learning",
                "作者": " Nicholas Perikli,  Srimoy Bhattacharya,  Blessing Ogbuokiri,  Zahra Movahedi Nia,  Benjamin Lieberman,  Nidhi Tripathi,  Salah-Eddine Dahbi,  Finn Stevenson,  Nicola Bragazzi,  Jude Kong,  Bruce Mellado",
                "发布日期": "2023-07-31",
                "摘要": "  Very few social media studies have been done on South African user-generated\ncontent during the COVID-19 pandemic and even fewer using hand-labelling over\nautomated methods. Vaccination is a major tool in the fight against the\npandemic, but vaccine hesitancy jeopardizes any public health effort. In this\nstudy, sentiment analysis on South African tweets related to vaccine hesitancy\nwas performed, with the aim of training AI-mediated classification models and\nassessing their reliability in categorizing UGC. A dataset of 30000 tweets from\nSouth Africa were extracted and hand-labelled into one of three sentiment\nclasses: positive, negative, neutral. The machine learning models used were\nLSTM, bi-LSTM, SVM, BERT-base-cased and the RoBERTa-base models, whereby their\nhyperparameters were carefully chosen and tuned using the WandB platform. We\nused two different approaches when we pre-processed our data for comparison:\none was semantics-based, while the other was corpus-based. The pre-processing\nof the tweets in our dataset was performed using both methods, respectively.\nAll models were found to have low F1-scores within a range of 45$\\%$-55$\\%$,\nexcept for BERT and RoBERTa which both achieved significantly better measures\nwith overall F1-scores of 60$\\%$ and 61$\\%$, respectively. Topic modelling\nusing an LDA was performed on the miss-classified tweets of the RoBERTa model\nto gain insight on how to further improve model accuracy.\n",
                "链接": "https://arxiv.org/abs/2307.15072"
            },
            {
                "文章ID": "83498",
                "标题": "Leverage Points in Modality Shifts: Comparing Language-only and\n  Multimodal Word Representations",
                "作者": " Aleksey Tikhonov,  Lisa Bylinina,  Denis Paperno",
                "发布日期": "2023-06-06",
                "摘要": "  Multimodal embeddings aim to enrich the semantic information in neural\nrepresentations of language compared to text-only models. While different\nembeddings exhibit different applicability and performance on downstream tasks,\nlittle is known about the systematic representation differences attributed to\nthe visual modality. Our paper compares word embeddings from three\nvision-and-language models (CLIP, OpenCLIP and Multilingual CLIP) and three\ntext-only models, with static (FastText) as well as contextual representations\n(multilingual BERT; XLM-RoBERTa). This is the first large-scale study of the\neffect of visual grounding on language representations, including 46 semantic\nparameters. We identify meaning properties and relations that characterize\nwords whose embeddings are most affected by the inclusion of visual modality in\nthe training data; that is, points where visual grounding turns out most\nimportant. We find that the effect of visual modality correlates most with\ndenotational semantic properties related to concreteness, but is also detected\nfor several specific semantic classes, as well as for valence, a\nsentiment-related connotational property of linguistic expressions.\n",
                "链接": "https://arxiv.org/abs/2306.02348"
            },
            {
                "文章ID": "87606",
                "标题": "L3Cube-MahaSent-MD: A Multi-domain Marathi Sentiment Analysis Dataset\n  and Transformer Models",
                "作者": " Aabha Pingle,  Aditya Vyawahare,  Isha Joshi,  Rahul Tangsali,  Raviraj Joshi",
                "发布日期": "2023-06-27",
                "摘要": "  The exploration of sentiment analysis in low-resource languages, such as\nMarathi, has been limited due to the availability of suitable datasets. In this\nwork, we present L3Cube-MahaSent-MD, a multi-domain Marathi sentiment analysis\ndataset, with four different domains - movie reviews, general tweets, TV show\nsubtitles, and political tweets. The dataset consists of around 60,000 manually\ntagged samples covering 3 distinct sentiments - positive, negative, and\nneutral. We create a sub-dataset for each domain comprising 15k samples. The\nMahaSent-MD is the first comprehensive multi-domain sentiment analysis dataset\nwithin the Indic sentiment landscape. We fine-tune different monolingual and\nmultilingual BERT models on these datasets and report the best accuracy with\nthe MahaBERT model. We also present an extensive in-domain and cross-domain\nanalysis thus highlighting the need for low-resource multi-domain datasets. The\ndata and models are available at https://github.com/l3cube-pune/MarathiNLP .\n",
                "链接": "https://arxiv.org/abs/2306.13888"
            },
            {
                "文章ID": "49478",
                "标题": "L3Cube-MahaSBERT and HindSBERT: Sentence BERT Models and Benchmarking\n  BERT Sentence Representations for Hindi and Marathi",
                "作者": " Ananya Joshi,  Aditi Kajale,  Janhavi Gadre,  Samruddhi Deode,  Raviraj Joshi",
                "发布日期": "2022-11-23",
                "摘要": "  Sentence representation from vanilla BERT models does not work well on\nsentence similarity tasks. Sentence-BERT models specifically trained on STS or\nNLI datasets are shown to provide state-of-the-art performance. However,\nbuilding these models for low-resource languages is not straightforward due to\nthe lack of these specialized datasets. This work focuses on two low-resource\nIndian languages, Hindi and Marathi. We train sentence-BERT models for these\nlanguages using synthetic NLI and STS datasets prepared using machine\ntranslation. We show that the strategy of NLI pre-training followed by STSb\nfine-tuning is effective in generating high-performance sentence-similarity\nmodels for Hindi and Marathi. The vanilla BERT models trained using this simple\nstrategy outperform the multilingual LaBSE trained using a complex training\nstrategy. These models are evaluated on downstream text classification and\nsimilarity tasks. We evaluate these models on real text classification datasets\nto show embeddings obtained from synthetic data training are generalizable to\nreal datasets as well and thus represent an effective training strategy for\nlow-resource languages. We also provide a comparative analysis of sentence\nembeddings from fast text models, multilingual BERT models (mBERT, IndicBERT,\nxlm-RoBERTa, MuRIL), multilingual sentence embedding models (LASER, LaBSE), and\nmonolingual BERT models based on L3Cube-MahaBERT and HindBERT. We release\nL3Cube-MahaSBERT and HindSBERT, the state-of-the-art sentence-BERT models for\nMarathi and Hindi respectively. Our work also serves as a guide to building\nlow-resource sentence embedding models.\n",
                "链接": "https://arxiv.org/abs/2211.11187"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找一下2018年以后使用强化学习做机器翻译任务的论文",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "请找出使用Transformer模型并在大规模数据集上进行预训练的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "88555",
                "标题": "MIS-FM: 3D Medical Image Segmentation using Foundation Models Pretrained\n  on a Large-Scale Unannotated Dataset",
                "作者": " Guotai Wang,  Jianghao Wu,  Xiangde Luo,  Xinglong Liu,  Kang Li,  Shaoting Zhang",
                "发布日期": "2023-06-30",
                "摘要": "  Pretraining with large-scale 3D volumes has a potential for improving the\nsegmentation performance on a target medical image dataset where the training\nimages and annotations are limited. Due to the high cost of acquiring\npixel-level segmentation annotations on the large-scale pretraining dataset,\npretraining with unannotated images is highly desirable. In this work, we\npropose a novel self-supervised learning strategy named Volume Fusion (VF) for\npretraining 3D segmentation models. It fuses several random patches from a\nforeground sub-volume to a background sub-volume based on a predefined set of\ndiscrete fusion coefficients, and forces the model to predict the fusion\ncoefficient of each voxel, which is formulated as a self-supervised\nsegmentation task without manual annotations. Additionally, we propose a novel\nnetwork architecture based on parallel convolution and transformer blocks that\nis suitable to be transferred to different downstream segmentation tasks with\nvarious scales of organs and lesions. The proposed model was pretrained with\n110k unannotated 3D CT volumes, and experiments with different downstream\nsegmentation targets including head and neck organs, thoracic/abdominal organs\nshowed that our pretrained model largely outperformed training from scratch and\nseveral state-of-the-art self-supervised training methods and segmentation\nmodels. The code and pretrained model are available at\nhttps://github.com/openmedlab/MIS-FM.\n",
                "链接": "https://arxiv.org/abs/2306.16925"
            },
            {
                "文章ID": "70364",
                "标题": "GreekBART: The First Pretrained Greek Sequence-to-Sequence Model",
                "作者": " Iakovos Evdaimon,  Hadi Abdine,  Christos Xypolopoulos,  Stamatis Outsios,  Michalis Vazirgiannis,  Giorgos Stamou",
                "发布日期": "2023-04-04",
                "摘要": "  The era of transfer learning has revolutionized the fields of Computer Vision\nand Natural Language Processing, bringing powerful pretrained models with\nexceptional performance across a variety of tasks. Specifically, Natural\nLanguage Processing tasks have been dominated by transformer-based language\nmodels. In Natural Language Inference and Natural Language Generation tasks,\nthe BERT model and its variants, as well as the GPT model and its successors,\ndemonstrated exemplary performance. However, the majority of these models are\npretrained and assessed primarily for the English language or on a multilingual\ncorpus. In this paper, we introduce GreekBART, the first Seq2Seq model based on\nBART-base architecture and pretrained on a large-scale Greek corpus. We\nevaluate and compare GreekBART against BART-random, Greek-BERT, and XLM-R on a\nvariety of discriminative tasks. In addition, we examine its performance on two\nNLG tasks from GreekSUM, a newly introduced summarization dataset for the Greek\nlanguage. The model, the code, and the new summarization dataset will be\npublicly available.\n",
                "链接": "https://arxiv.org/abs/2304.00869"
            },
            {
                "文章ID": "79370",
                "标题": "LMGQS: A Large-scale Dataset for Query-focused Summarization",
                "作者": " Ruochen Xu,  Song Wang,  Yang Liu,  Shuohang Wang,  Yichong Xu,  Dan Iter,  Chenguang Zhu,  Michael Zeng",
                "发布日期": "2023-05-23",
                "摘要": "  Query-focused summarization (QFS) aims to extract or generate a summary of an\ninput document that directly answers or is relevant to a given query. The lack\nof large-scale datasets in the form of documents, queries, and summaries has\nhindered model development in this area. In contrast, multiple large-scale\nhigh-quality datasets for generic summarization exist. We hypothesize that\nthere is a hidden query for each summary sentence in a generic summarization\nannotation, and we utilize a large-scale pretrained language model to recover\nit. In this way, we convert four generic summarization benchmarks into a new\nQFS benchmark dataset, LMGQS, which consists of over 1 million\ndocument-query-summary samples. We thoroughly investigate the properties of our\nproposed dataset and establish baselines with state-of-the-art summarization\nmodels. By fine-tuning a language model on LMGQS, we achieve state-of-the-art\nzero-shot and supervised performance on multiple existing QFS benchmarks,\ndemonstrating the high quality and diversity of LMGQS.\n",
                "链接": "https://arxiv.org/abs/2305.13086"
            },
            {
                "文章ID": "97306",
                "标题": "DESOBAv2: Towards Large-scale Real-world Dataset for Shadow Generation",
                "作者": " Qingyang Liu,  Jianting Wang,  Li Niu",
                "发布日期": "2023-08-22",
                "摘要": "  Image composition refers to inserting a foreground object into a background\nimage to obtain a composite image. In this work, we focus on generating\nplausible shadow for the inserted foreground object to make the composite image\nmore realistic. To supplement the existing small-scale dataset DESOBA, we\ncreate a large-scale dataset called DESOBAv2 by using object-shadow detection\nand inpainting techniques. Specifically, we collect a large number of outdoor\nscene images with object-shadow pairs. Then, we use pretrained inpainting model\nto inpaint the shadow region, resulting in the deshadowed images. Based on real\nimages and deshadowed images, we can construct pairs of synthetic composite\nimages and ground-truth target images. Dataset is available at\nhttps://github.com/bcmi/Object-Shadow-Generation-Dataset-DESOBAv2.\n",
                "链接": "https://arxiv.org/abs/2308.09972"
            },
            {
                "文章ID": "84598",
                "标题": "Large-scale Dataset Pruning with Dynamic Uncertainty",
                "作者": " Muyang He,  Shuo Yang,  Tiejun Huang,  Bo Zhao",
                "发布日期": "2023-06-09",
                "摘要": "  The state of the art of many learning tasks, e.g., image classification, is\nadvanced by collecting larger datasets and then training larger models on them.\nAs the outcome, the increasing computational cost is becoming unaffordable. In\nthis paper, we investigate how to prune the large-scale datasets, and thus\nproduce an informative subset for training sophisticated deep models with\nnegligible performance drop. We propose a simple yet effective dataset pruning\nmethod by exploring both the prediction uncertainty and training dynamics. To\nour knowledge, this is the first work to study dataset pruning on large-scale\ndatasets, i.e., ImageNet-1K and ImageNet-21K, and advanced models, i.e., Swin\nTransformer and ConvNeXt. Extensive experimental results indicate that our\nmethod outperforms the state of the art and achieves 75% lossless compression\nratio on both ImageNet-1K and ImageNet-21K. The code and pruned datasets are\navailable at https://github.com/BAAI-DCAI/Dataset-Pruning.\n",
                "链接": "https://arxiv.org/abs/2306.05175"
            },
            {
                "文章ID": "72325",
                "标题": "Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene\n  Understanding",
                "作者": " Yu-Qi Yang,  Yu-Xiao Guo,  Jian-Yu Xiong,  Yang Liu,  Hao Pan,  Peng-Shuai Wang,  Xin Tong,  Baining Guo",
                "发布日期": "2023-08-17",
                "摘要": "  The use of pretrained backbones with fine-tuning has been successful for 2D\nvision and natural language processing tasks, showing advantages over\ntask-specific networks. In this work, we introduce a pretrained 3D backbone,\ncalled {\\SST}, for 3D indoor scene understanding. We design a 3D Swin\ntransformer as our backbone network, which enables efficient self-attention on\nsparse voxels with linear memory complexity, making the backbone scalable to\nlarge models and datasets. We also introduce a generalized contextual relative\npositional embedding scheme to capture various irregularities of point signals\nfor improved network performance. We pretrained a large {\\SST} model on a\nsynthetic Structured3D dataset, which is an order of magnitude larger than the\nScanNet dataset. Our model pretrained on the synthetic dataset not only\ngeneralizes well to downstream segmentation and detection on real 3D point\ndatasets, but also outperforms state-of-the-art methods on downstream tasks\nwith +2.3 mIoU and +2.2 mIoU on S3DIS Area5 and 6-fold semantic segmentation,\n+1.8 mIoU on ScanNet segmentation (val), +1.9 mAP@0.5 on ScanNet detection, and\n+8.1 mAP@0.5 on S3DIS detection. A series of extensive ablation studies further\nvalidate the scalability, generality, and superior performance enabled by our\napproach. The code and models are available at\nhttps://github.com/microsoft/Swin3D .\n",
                "链接": "https://arxiv.org/abs/2304.06906"
            },
            {
                "文章ID": "68277",
                "标题": "JaCoText: A Pretrained Model for Java Code-Text Generation",
                "作者": " Jessica López Espejel,  Mahaman Sanoussi Yahaya Alassan,  Walid Dahhane,  El Hassane Ettifouri",
                "发布日期": "2023-03-24",
                "摘要": "  Pretrained transformer-based models have shown high performance in natural\nlanguage generation task. However, a new wave of interest has surged: automatic\nprogramming language generation. This task consists of translating natural\nlanguage instructions to a programming code. Despite the fact that well-known\npretrained models on language generation have achieved good performance in\nlearning programming languages, effort is still needed in automatic code\ngeneration. In this paper, we introduce JaCoText, a model based on Transformers\nneural network. It aims to generate java source code from natural language\ntext. JaCoText leverages advantages of both natural language and code\ngeneration models. More specifically, we study some findings from the state of\nthe art and use them to (1) initialize our model from powerful pretrained\nmodels, (2) explore additional pretraining on our java dataset, (3) carry out\nexperiments combining the unimodal and bimodal data in the training, and (4)\nscale the input and output length during the fine-tuning of the model.\nConducted experiments on CONCODE dataset show that JaCoText achieves new\nstate-of-the-art results.\n",
                "链接": "https://arxiv.org/abs/2303.12869"
            },
            {
                "文章ID": "22225",
                "标题": "CogVideo: Large-scale Pretraining for Text-to-Video Generation via\n  Transformers",
                "作者": " Wenyi Hong,  Ming Ding,  Wendi Zheng,  Xinghan Liu,  Jie Tang",
                "发布日期": "2022-06-01",
                "摘要": "  Large-scale pretrained transformers have created milestones in text (GPT-3)\nand text-to-image (DALL-E and CogView) generation. Its application to video\ngeneration is still facing many challenges: The potential huge computation cost\nmakes the training from scratch unaffordable; The scarcity and weak relevance\nof text-video datasets hinder the model understanding complex movement\nsemantics. In this work, we present 9B-parameter transformer CogVideo, trained\nby inheriting a pretrained text-to-image model, CogView2. We also propose\nmulti-frame-rate hierarchical training strategy to better align text and video\nclips. As (probably) the first open-source large-scale pretrained text-to-video\nmodel, CogVideo outperforms all publicly available models at a large margin in\nmachine and human evaluations.\n",
                "链接": "https://arxiv.org/abs/2205.15868"
            },
            {
                "文章ID": "84069",
                "标题": "Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How",
                "作者": " Sebastian Pineda Arango,  Fabio Ferreira,  Arlind Kadra,  Frank Hutter,  Josif Grabocka",
                "发布日期": "2023-07-04",
                "摘要": "  With the ever-increasing number of pretrained models, machine learning\npractitioners are continuously faced with which pretrained model to use, and\nhow to finetune it for a new dataset. In this paper, we propose a methodology\nthat jointly searches for the optimal pretrained model and the hyperparameters\nfor finetuning it. Our method transfers knowledge about the performance of many\npretrained models with multiple hyperparameter configurations on a series of\ndatasets. To this aim, we evaluated over 20k hyperparameter configurations for\nfinetuning 24 pretrained image classification models on 87 datasets to generate\na large-scale meta-dataset. We meta-learn a multi-fidelity performance\npredictor on the learning curves of this meta-dataset and use it for fast\nhyperparameter optimization on new datasets. We empirically demonstrate that\nour resulting approach can quickly select an accurate pretrained model for a\nnew dataset together with its optimal hyperparameters.\n",
                "链接": "https://arxiv.org/abs/2306.03828"
            },
            {
                "文章ID": "88854",
                "标题": "BuildingsBench: A Large-Scale Dataset of 900K Buildings and Benchmark\n  for Short-Term Load Forecasting",
                "作者": " Patrick Emami,  Abhijeet Sahu,  Peter Graf",
                "发布日期": "2023-10-31",
                "摘要": "  Short-term forecasting of residential and commercial building energy\nconsumption is widely used in power systems and continues to grow in\nimportance. Data-driven short-term load forecasting (STLF), although promising,\nhas suffered from a lack of open, large-scale datasets with high building\ndiversity. This has hindered exploring the pretrain-then-fine-tune paradigm for\nSTLF. To help address this, we present BuildingsBench, which consists of: 1)\nBuildings-900K, a large-scale dataset of 900K simulated buildings representing\nthe U.S. building stock; and 2) an evaluation platform with over 1,900 real\nresidential and commercial buildings from 7 open datasets. BuildingsBench\nbenchmarks two under-explored tasks: zero-shot STLF, where a pretrained model\nis evaluated on unseen buildings without fine-tuning, and transfer learning,\nwhere a pretrained model is fine-tuned on a target building. The main finding\nof our benchmark analysis is that synthetically pretrained models generalize\nsurprisingly well to real commercial buildings. An exploration of the effect of\nincreasing dataset size and diversity on zero-shot commercial building\nperformance reveals a power-law with diminishing returns. We also show that\nfine-tuning pretrained models on real commercial and residential buildings\nimproves performance for a majority of target buildings. We hope that\nBuildingsBench encourages and facilitates future research on generalizable\nSTLF. All datasets and code can be accessed from\nhttps://github.com/NREL/BuildingsBench.\n",
                "链接": "https://arxiv.org/abs/2307.00142"
            }
        ]
    },
    {
        "question": {
            "question": "找一下使用强化学习做代码生成的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "59289",
                "标题": "Execution-based Code Generation using Deep Reinforcement Learning",
                "作者": " Parshin Shojaee,  Aneesh Jain,  Sindhu Tipirneni,  Chandan K. Reddy",
                "发布日期": "2023-07-21",
                "摘要": "  The utilization of programming language (PL) models, pre-trained on\nlarge-scale code corpora, as a means of automating software engineering\nprocesses has demonstrated considerable potential in streamlining various code\ngeneration tasks such as code completion, code translation, and program\nsynthesis. However, current approaches mainly rely on supervised fine-tuning\nobjectives borrowed from text generation, neglecting unique sequence-level\ncharacteristics of code, including but not limited to compilability as well as\nsyntactic and functional correctness. To address this limitation, we propose\nPPOCoder, a new framework for code generation that synergistically combines\npre-trained PL models with Proximal Policy Optimization (PPO) which is a widely\nused deep reinforcement learning technique. By utilizing non-differentiable\nfeedback from code execution and structure alignment, PPOCoder seamlessly\nintegrates external code-specific knowledge into the model optimization\nprocess. It's important to note that PPOCoder is a task-agnostic and\nmodel-agnostic framework that can be used across different code generation\ntasks and PLs. Extensive experiments on three code generation tasks demonstrate\nthe effectiveness of our proposed approach compared to SOTA methods, achieving\nsignificant improvements in compilation success rates and functional\ncorrectness across different PLs.\n",
                "链接": "https://arxiv.org/abs/2301.13816"
            },
            {
                "文章ID": "27761",
                "标题": "CodeRL: Mastering Code Generation through Pretrained Models and Deep\n  Reinforcement Learning",
                "作者": " Hung Le,  Yue Wang,  Akhilesh Deepak Gotmare,  Silvio Savarese,  Steven C. H. Hoi",
                "发布日期": "2022-11-04",
                "摘要": "  Program synthesis or code generation aims to generate a program that\nsatisfies a problem specification. Recent approaches using large-scale\npretrained language models (LMs) have shown promising results, yet they have\nsome critical limitations. In particular, they often follow a standard\nsupervised fine-tuning procedure to train a code generation model only from the\npairs of natural-language problem descriptions and ground-truth programs. Such\nparadigm largely ignores some important but potentially useful signals in the\nproblem specification such as unit tests, which thus often results in poor\nperformance when solving complex unseen coding tasks. To address the\nlimitations, we propose \"CodeRL\", a new framework for program synthesis tasks\nthrough pretrained LMs and deep reinforcement learning (RL). Specifically,\nduring training, we treat the code-generating LM as an actor network, and\nintroduce a critic network that is trained to predict the functional\ncorrectness of generated programs and provide dense feedback signals to the\nactor. During inference, we introduce a new generation procedure with a\ncritical sampling strategy that allows a model to automatically regenerate\nprograms based on feedback from example unit tests and critic scores. For the\nmodel backbones, we extended the encoder-decoder architecture of CodeT5 with\nenhanced learning objectives, larger model sizes, and better pretraining data.\nOur method not only achieves new SOTA results on the challenging APPS\nbenchmark, but also shows strong zero-shot transfer capability with new SOTA\nresults on the simpler MBPP benchmark.\n",
                "链接": "https://arxiv.org/abs/2207.01780"
            },
            {
                "文章ID": "110290",
                "标题": "Automatic Unit Test Data Generation and Actor-Critic Reinforcement\n  Learning for Code Synthesis",
                "作者": " Philip John Gorinski,  Matthieu Zimmer,  Gerasimos Lampouras,  Derrick Goh Xin Deik,  Ignacio Iacobacci",
                "发布日期": "2023-10-23",
                "摘要": "  The advent of large pre-trained language models in the domain of Code\nSynthesis has shown remarkable performance on various benchmarks, treating the\nproblem of Code Generation in a fashion similar to Natural Language Generation,\ntrained with a Language Modelling (LM) objective. In addition, the property of\nprogramming language code being precisely evaluable with respect to its\nsemantics -- through the use of Unit Tests to check its functional correctness\n-- lends itself to using Reinforcement Learning (RL) as a further training\nparadigm. Previous work has shown that RL can be applied as such to improve\nmodels' coding capabilities; however, such RL-based methods rely on a reward\nsignal based on defined Unit Tests, which are much harder to obtain compared to\nthe huge crawled code datasets used in LM objectives. In this work, we present\na novel approach to automatically obtain data consisting of function signatures\nand associated Unit Tests, suitable for RL training of Code Synthesis models.\nWe also introduce a straightforward, simple yet effective Actor-Critic RL\ntraining scheme and show that it, in conjunction with automatically generated\ntraining data, leads to improvement of a pre-trained code language model's\nperformance by up to 9.9% improvement over the original underlying code\nsynthesis LM, and up to 4.3% over RL-based models trained with standard PPO or\nCodeRL.\n",
                "链接": "https://arxiv.org/abs/2310.13669"
            },
            {
                "文章ID": "9115",
                "标题": "Compilable Neural Code Generation with Compiler Feedback",
                "作者": " Xin Wang,  Yasheng Wang,  Yao Wan,  Fei Mi,  Yitong Li,  Pingyi Zhou,  Jin Liu,  Hao Wu,  Xin Jiang,  Qun Liu",
                "发布日期": "2022-03-11",
                "摘要": "  Automatically generating compilable programs with (or without) natural\nlanguage descriptions has always been a touchstone problem for computational\nlinguistics and automated software engineering. Existing deep-learning\napproaches model code generation as text generation, either constrained by\ngrammar structures in decoder, or driven by pre-trained language models on\nlarge-scale code corpus (e.g., CodeGPT, PLBART, and CodeT5). However, few of\nthem account for compilability of the generated programs. To improve\ncompilability of the generated programs, this paper proposes COMPCODER, a\nthree-stage pipeline utilizing compiler feedback for compilable code\ngeneration, including language model fine-tuning, compilability reinforcement,\nand compilability discrimination. Comprehensive experiments on two code\ngeneration tasks demonstrate the effectiveness of our proposed approach,\nimproving the success rate of compilation from 44.18 to 89.18 in code\ncompletion on average and from 70.3 to 96.2 in text-to-code generation,\nrespectively, when comparing with the state-of-the-art CodeGPT.\n",
                "链接": "https://arxiv.org/abs/2203.05132"
            },
            {
                "文章ID": "72734",
                "标题": "Stochastic Code Generation",
                "作者": " Swapnil Sharma,  Nikita Anand, V Kranthi Kiran G.",
                "发布日期": "2023-04-18",
                "摘要": "  Large language models pre-trained for code generation can generate\nhigh-quality short code but often struggle with generating coherent long code\nand understanding higher-level or system-level specifications. This issue is\nalso observed in language modeling for long text generation, and one proposed\nsolution is the use of a latent stochastic process. This approach involves\ngenerating a document plan and then producing text that is consistent with it.\n  In this study, we investigate whether this technique can be applied to code\ngeneration to improve coherence. We base our proposed encoder and decoder on\nthe pre-trained GPT-2 based CodeParrot model and utilize the APPS dataset for\ntraining. We evaluate our results using the HumanEval benchmark and observe\nthat the modified Time Control model performs similarly to CodeParrot on this\nevaluation.\n",
                "链接": "https://arxiv.org/abs/2304.08243"
            },
            {
                "文章ID": "119060",
                "标题": "Self-Infilling Code Generation",
                "作者": " Lin Zheng,  Jianbo Yuan,  Zhi Zhang,  Hongxia Yang,  Lingpeng Kong",
                "发布日期": "2023-12-01",
                "摘要": "  This work introduces a general code generation framework that incorporates\ninfilling operations into auto-regressive decoding. Our approach capitalizes on\nthe observation that recent code language models with infilling capabilities\ncan perform \\emph{self-infilling}: whereas infilling operations aim to fill in\nthe middle based on a predefined prefix and suffix, self-infilling sequentially\ngenerates both such surrounding context and the infilled content. We utilize\nthis feature to develop an infilling-augmented decoding process that\nfacilitates non-monotonic generation. This approach allows for postponing the\ngeneration of uncertain code snippets until a definitive suffix is established,\nleading to improved control over the generation sequence. In addition, it\nfacilitates a looping mechanism, which can iteratively update and synchronize\neach piece of generation in a cyclic manner. Extensive experiments are\nconducted to demonstrate that our proposed decoding process is effective in\nenhancing regularity and quality across several code generation benchmarks.\n",
                "链接": "https://arxiv.org/abs/2311.17972"
            },
            {
                "文章ID": "69960",
                "标题": "AceCoder: Utilizing Existing Code to Enhance Code Generation",
                "作者": " Jia Li,  Yunfei Zhao,  Yongmin Li,  Ge Li,  Zhi Jin",
                "发布日期": "2023-09-08",
                "摘要": "  Large Language Models (LLMs) have shown great success in code generation.\nLLMs take as the input a prompt and output the code. A key question is how to\nmake prompts (i.e., Prompting Techniques). Existing prompting techniques are\ndesigned for natural language generation and have low accuracy in code\ngeneration.\n  In this paper, we propose a new prompting technique named AceCoder. Our\nmotivation is that code generation meets two unique challenges (i.e.,\nrequirement understanding and code implementation). AceCoder contains two novel\nmechanisms (i.e., guided code generation and example retrieval) to solve these\nchallenges. (1) Guided code generation asks LLMs first to analyze requirements\nand output an intermediate preliminary (e.g., test cases). The preliminary is\nused to clarify requirements and tell LLMs \"what to write\". (2) Example\nretrieval selects similar programs as examples in prompts, which provide lots\nof relevant content (e.g., algorithms, APIs) and teach LLMs \"how to write\". We\napply AceCoder to three LLMs (e.g., Codex) and evaluate it on three public\nbenchmarks using the Pass@k. Results show that AceCoder can significantly\nimprove the performance of LLMs on code generation. (1) In terms of Pass@1,\nAceCoder outperforms the state-of-the-art baseline by up to 56.4% in MBPP,\n70.7% in MBJP, and 88.4% in MBJSP. (2) AceCoder is effective in LLMs with\ndifferent sizes (i.e., 6B to 13B) and different languages (i.e., Python, Java,\nand JavaScript). (3) Human evaluation shows human developers prefer programs\nfrom AceCoder.\n",
                "链接": "https://arxiv.org/abs/2303.17780"
            },
            {
                "文章ID": "89545",
                "标题": "Exploring Continual Learning for Code Generation Models",
                "作者": " Prateek Yadav,  Qing Sun,  Hantian Ding,  Xiaopeng Li,  Dejiao Zhang,  Ming Tan,  Xiaofei Ma,  Parminder Bhatia,  Ramesh Nallapati,  Murali Krishna Ramanathan,  Mohit Bansal,  Bing Xiang",
                "发布日期": "2023-07-06",
                "摘要": "  Large-scale code generation models such as Codex and CodeT5 have achieved\nimpressive performance. However, libraries are upgraded or deprecated very\nfrequently and re-training large-scale language models is computationally\nexpensive. Therefore, Continual Learning (CL) is an important aspect that\nremains underexplored in the code domain. In this paper, we introduce a\nbenchmark called CodeTask-CL that covers a wide range of tasks, including code\ngeneration, translation, summarization, and refinement, with different input\nand output programming languages. Next, on our CodeTask-CL benchmark, we\ncompare popular CL techniques from NLP and Vision domains. We find that\neffective methods like Prompt Pooling (PP) suffer from catastrophic forgetting\ndue to the unstable training of the prompt selection mechanism caused by stark\ndistribution shifts in coding tasks. We address this issue with our proposed\nmethod, Prompt Pooling with Teacher Forcing (PP-TF), that stabilizes training\nby enforcing constraints on the prompt selection mechanism and leads to a\n21.54% improvement over Prompt Pooling. Along with the benchmark, we establish\na training pipeline that can be used for CL on code models, which we believe\ncan motivate further development of CL methods for code models. Our code is\navailable at https://github.com/amazon-science/codetaskcl-pptf\n",
                "链接": "https://arxiv.org/abs/2307.02435"
            },
            {
                "文章ID": "80370",
                "标题": "Who Wrote this Code? Watermarking for Code Generation",
                "作者": " Taehyun Lee,  Seokhee Hong,  Jaewoo Ahn,  Ilgee Hong,  Hwaran Lee,  Sangdoo Yun,  Jamin Shin,  Gunhee Kim",
                "发布日期": "2023-11-20",
                "摘要": "  With the remarkable generation performance of large language models, ethical\nand legal concerns about using them have been raised, such as plagiarism and\ncopyright issues. For such concerns, several approaches to watermark and detect\nLLM-generated text have been proposed very recently. However, we discover that\nthe previous methods fail to function appropriately with code generation tasks\nbecause of the syntactic and semantic characteristics of code. Based on\n\\citet{Kirchenbauer2023watermark}, we propose a new watermarking method,\nSelective WatErmarking via Entropy Thresholding (SWEET), that promotes \"green\"\ntokens only at the position with high entropy of the token distribution during\ngeneration, thereby preserving the correctness of the generated code. The\nwatermarked code is detected by the statistical test and Z-score based on the\nentropy information. Our experiments on HumanEval and MBPP show that SWEET\nsignificantly improves the Pareto Frontier between the code correctness and\nwatermark detection performance. We also show that notable post-hoc detection\nmethods (e.g. DetectGPT) fail to work well in this task. Finally, we show that\nsetting a reasonable entropy threshold is not much of a challenge. Code is\navailable at https://github.com/hongcheki/sweet-watermark.\n",
                "链接": "https://arxiv.org/abs/2305.15060"
            },
            {
                "文章ID": "122586",
                "标题": "Entity-Augmented Code Generation",
                "作者": " Anton Shapkin,  Denis Litvinov,  Timofey Bryksin",
                "发布日期": "2023-12-15",
                "摘要": "  The current state-of-the-art large language models (LLMs) are effective in\ngenerating high-quality text and encapsulating a broad spectrum of world\nknowledge. However, these models often hallucinate during generation and are\nnot designed to utilize external information sources. To enable requests to the\nexternal knowledge bases, also called knowledge grounding, retrieval-augmented\nLLMs were introduced. For now, their applications have largely involved Open\nDomain Question Answering, Abstractive Question Answering, and such. In this\npaper, we broaden the scope of retrieval-augmented LLMs by venturing into a new\ntask - code generation using external entities. For this task, we collect and\npublish a new dataset for project-level code generation, where the model should\nreuse functions defined in the project during generation. As we show, existing\nretrieval-augmented LLMs fail to assign relevance scores between similar entity\nnames, and to mitigate it, they expand entity names with description context\nand append it to the input. In practice, due to the limited context size they\ncan not accommodate the indefinitely large context of the whole project. To\nsolve this issue, we propose a novel end-to-end trainable architecture with an\nscalable entity retriever injected directly into the LLM decoder. We\ndemonstrate that our model can outperform common baselines in several\nscenarios, including project-level code generation, as well as Bash and SQL\nscripting.\n",
                "链接": "https://arxiv.org/abs/2312.08976"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下关于大模型使用工具的安全性的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "116782",
                "标题": "A Security Risk Taxonomy for Large Language Models",
                "作者": " Erik Derner,  Kristina Batistič,  Jan Zahálka,  Robert Babuška",
                "发布日期": "2023-11-21",
                "摘要": "  As large language models (LLMs) permeate more and more applications, an\nassessment of their associated security risks becomes increasingly necessary.\nThe potential for exploitation by malicious actors, ranging from disinformation\nto data breaches and reputation damage, is substantial. This paper addresses a\ngap in current research by focusing on the security risks posed by LLMs, which\nextends beyond the widely covered ethical and societal implications. Our work\nproposes a taxonomy of security risks along the user-model communication\npipeline, explicitly focusing on prompt-based attacks on LLMs. We categorize\nthe attacks by target and attack type within a prompt-based interaction scheme.\nThe taxonomy is reinforced with specific attack examples to showcase the\nreal-world impact of these risks. Through this taxonomy, we aim to inform the\ndevelopment of robust and secure LLM applications, enhancing their safety and\ntrustworthiness.\n",
                "链接": "https://arxiv.org/abs/2311.11415"
            },
            {
                "文章ID": "61038",
                "标题": "Large Language Models for Code: Security Hardening and Adversarial\n  Testing",
                "作者": " Jingxuan He,  Martin Vechev",
                "发布日期": "2023-10-02",
                "摘要": "  Large language models (large LMs) are increasingly trained on massive\ncodebases and used to generate code. However, LMs lack awareness of security\nand are found to frequently produce unsafe code. This work studies the security\nof LMs along two important axes: (i) security hardening, which aims to enhance\nLMs' reliability in generating secure code, and (ii) adversarial testing, which\nseeks to evaluate LMs' security at an adversarial standpoint. We address both\nof these by formulating a new security task called controlled code generation.\nThe task is parametric and takes as input a binary property to guide the LM to\ngenerate secure or unsafe code, while preserving the LM's capability of\ngenerating functionally correct code. We propose a novel learning-based\napproach called SVEN to solve this task. SVEN leverages property-specific\ncontinuous vectors to guide program generation towards the given property,\nwithout modifying the LM's weights. Our training procedure optimizes these\ncontinuous vectors by enforcing specialized loss terms on different regions of\ncode, using a high-quality dataset carefully curated by us. Our extensive\nevaluation shows that SVEN is highly effective in achieving strong security\ncontrol. For instance, a state-of-the-art CodeGen LM with 2.7B parameters\ngenerates secure code for 59.1% of the time. When we employ SVEN to perform\nsecurity hardening (or adversarial testing) on this LM, the ratio is\nsignificantly boosted to 92.3% (or degraded to 36.8%). Importantly, SVEN\nclosely matches the original LMs in functional correctness.\n",
                "链接": "https://arxiv.org/abs/2302.05319"
            },
            {
                "文章ID": "49428",
                "标题": "Semantic Similarity-Based Clustering of Findings From Security Testing\n  Tools",
                "作者": " Phillip Schneider,  Markus Voggenreiter,  Abdullah Gulraiz,  Florian Matthes",
                "发布日期": "2022-11-22",
                "摘要": "  Over the last years, software development in domains with high security\ndemands transitioned from traditional methodologies to uniting modern\napproaches from software development and operations (DevOps). Key principles of\nDevOps gained more importance and are now applied to security aspects of\nsoftware development, resulting in the automation of security-enhancing\nactivities. In particular, it is common practice to use automated security\ntesting tools that generate reports after inspecting a software artifact from\nmultiple perspectives. However, this raises the challenge of generating\nduplicate security findings. To identify these duplicate findings manually, a\nsecurity expert has to invest resources like time, effort, and knowledge. A\npartial automation of this process could reduce the analysis effort, encourage\nDevOps principles, and diminish the chance of human error. In this study, we\ninvestigated the potential of applying Natural Language Processing for\nclustering semantically similar security findings to support the identification\nof problem-specific duplicate findings. Towards this goal, we developed a web\napplication for annotating and assessing security testing tool reports and\npublished a human-annotated corpus of clustered security findings. In addition,\nwe performed a comparison of different semantic similarity techniques for\nautomatically grouping security findings. Finally, we assess the resulting\nclusters using both quantitative and qualitative evaluation methods.\n",
                "链接": "https://arxiv.org/abs/2211.11057"
            },
            {
                "文章ID": "122196",
                "标题": "Causality Analysis for Evaluating the Security of Large Language Models",
                "作者": " Wei Zhao,  Zhe Li,  Jun Sun",
                "发布日期": "2023-12-14",
                "摘要": "  Large Language Models (LLMs) such as GPT and Llama2 are increasingly adopted\nin many safety-critical applications. Their security is thus essential. Even\nwith considerable efforts spent on reinforcement learning from human feedback\n(RLHF), recent studies have shown that LLMs are still subject to attacks such\nas adversarial perturbation and Trojan attacks. Further research is thus needed\nto evaluate their security and/or understand the lack of it. In this work, we\npropose a framework for conducting light-weight causality-analysis of LLMs at\nthe token, layer, and neuron level. We applied our framework to open-source\nLLMs such as Llama2 and Vicuna and had multiple interesting discoveries. Based\non a layer-level causality analysis, we show that RLHF has the effect of\noverfitting a model to harmful prompts. It implies that such security can be\neasily overcome by `unusual' harmful prompts. As evidence, we propose an\nadversarial perturbation method that achieves 100\\% attack success rate on the\nred-teaming tasks of the Trojan Detection Competition 2023. Furthermore, we\nshow the existence of one mysterious neuron in both Llama2 and Vicuna that has\nan unreasonably high causal effect on the output. While we are uncertain on why\nsuch a neuron exists, we show that it is possible to conduct a ``Trojan''\nattack targeting that particular neuron to completely cripple the LLM, i.e., we\ncan generate transferable suffixes to prompts that frequently make the LLM\nproduce meaningless responses.\n",
                "链接": "https://arxiv.org/abs/2312.07876"
            },
            {
                "文章ID": "124892",
                "标题": "SecQA: A Concise Question-Answering Dataset for Evaluating Large\n  Language Models in Computer Security",
                "作者": " Zefang Liu",
                "发布日期": "2023-12-27",
                "摘要": "  In this paper, we introduce SecQA, a novel dataset tailored for evaluating\nthe performance of Large Language Models (LLMs) in the domain of computer\nsecurity. Utilizing multiple-choice questions generated by GPT-4 based on the\n\"Computer Systems Security: Planning for Success\" textbook, SecQA aims to\nassess LLMs' understanding and application of security principles. We detail\nthe structure and intent of SecQA, which includes two versions of increasing\ncomplexity, to provide a concise evaluation across various difficulty levels.\nAdditionally, we present an extensive evaluation of prominent LLMs, including\nGPT-3.5-Turbo, GPT-4, Llama-2, Vicuna, Mistral, and Zephyr models, using both\n0-shot and 5-shot learning settings. Our results, encapsulated in the SecQA v1\nand v2 datasets, highlight the varying capabilities and limitations of these\nmodels in the computer security context. This study not only offers insights\ninto the current state of LLMs in understanding security-related content but\nalso establishes SecQA as a benchmark for future advancements in this critical\nresearch area.\n",
                "链接": "https://arxiv.org/abs/2312.15838"
            },
            {
                "文章ID": "83602",
                "标题": "Building Resilient SMEs: Harnessing Large Language Models for Cyber\n  Security in Australia",
                "作者": " Benjamin Kereopa-Yorke",
                "发布日期": "2023-06-06",
                "摘要": "  The escalating digitalisation of our lives and enterprises has led to a\nparallel growth in the complexity and frequency of cyber-attacks. Small and\nmedium-sized enterprises (SMEs), particularly in Australia, are experiencing\nincreased vulnerability to cyber threats, posing a significant challenge to the\nnation's cyber security landscape. Embracing transformative technologies such\nas Artificial Intelligence (AI), Machine Learning (ML) and Large Language\nModels (LLMs) can potentially strengthen cyber security policies for Australian\nSMEs. However, their practical application, advantages, and limitations remain\nunderexplored, with prior research mainly focusing on large corporations. This\nstudy aims to address this gap by providing a comprehensive understanding of\nthe potential role of LLMs in enhancing cyber security policies for Australian\nSMEs. Employing a mixed-methods study design, this research includes a\nliterature review, qualitative analysis of SME case studies, and a quantitative\nassessment of LLM performance metrics in cyber security applications. The\nfindings highlight the promising potential of LLMs across various performance\ncriteria, including relevance, accuracy, and applicability, though gaps remain\nin areas such as completeness and clarity. The study underlines the importance\nof integrating human expertise with LLM technology and refining model\ndevelopment to address these limitations. By proposing a robust conceptual\nframework guiding the effective adoption of LLMs, this research aims to\ncontribute to a safer and more resilient cyber environment for Australian SMEs,\nenabling sustainable growth and competitiveness in the digital era.\n",
                "链接": "https://arxiv.org/abs/2306.02612"
            },
            {
                "文章ID": "31453",
                "标题": "Effectiveness of Transformer Models on IoT Security Detection in\n  StackOverflow Discussions",
                "作者": " Nibir Chandra Mandal,  G. M. Shahariar,  Md. Tanvir Rouf Shawon",
                "发布日期": "2023-04-28",
                "摘要": "  The Internet of Things (IoT) is an emerging concept that directly links to\nthe billions of physical items, or \"things\", that are connected to the Internet\nand are all gathering and exchanging information between devices and systems.\nHowever, IoT devices were not built with security in mind, which might lead to\nsecurity vulnerabilities in a multi-device system. Traditionally, we\ninvestigated IoT issues by polling IoT developers and specialists. This\ntechnique, however, is not scalable since surveying all IoT developers is not\nfeasible. Another way to look into IoT issues is to look at IoT developer\ndiscussions on major online development forums like Stack Overflow (SO).\nHowever, finding discussions that are relevant to IoT issues is challenging\nsince they are frequently not categorized with IoT-related terms. In this\npaper, we present the \"IoT Security Dataset\", a domain-specific dataset of 7147\nsamples focused solely on IoT security discussions. As there are no automated\ntools to label these samples, we manually labeled them. We further employed\nmultiple transformer models to automatically detect security discussions.\nThrough rigorous investigations, we found that IoT security discussions are\ndifferent and more complex than traditional security discussions. We\ndemonstrated a considerable performance loss (up to 44%) of transformer models\non cross-domain datasets when we transferred knowledge from a general-purpose\ndataset \"Opiner\", supporting our claim. Thus, we built a domain-specific IoT\nsecurity detector with an F1-Score of 0.69. We have made the dataset public in\nthe hope that developers would learn more about the security discussion and\nvendors would enhance their concerns about product security.\n",
                "链接": "https://arxiv.org/abs/2207.14542"
            },
            {
                "文章ID": "117473",
                "标题": "Applying Large Language Models to Power Systems: Potential Security\n  Threats",
                "作者": " Jiaqi Ruan,  Gaoqi Liang,  Huan Zhao,  Guolong Liu,  Jing Qiu,  Junhua Zhao,  Zhao Xu,  Fushuan Wen,  Zhao Yang Dong",
                "发布日期": "2023-11-23",
                "摘要": "  Applying large language models (LLMs) to power systems presents a promising\navenue for enhancing decision-making and operational efficiency. However, this\naction may also incur potential security threats, which have not been fully\nrecognized so far. To this end, this letter analyzes potential threats incurred\nby applying LLMs to power systems, emphasizing the need for urgent research and\ndevelopment of countermeasures.\n",
                "链接": "https://arxiv.org/abs/2311.13361"
            },
            {
                "文章ID": "10748",
                "标题": "The Dark Side: Security Concerns in Machine Learning for EDA",
                "作者": " Zhiyao Xie,  Jingyu Pan,  Chen-Chia Chang,  Yiran Chen",
                "发布日期": "2022-03-22",
                "摘要": "  The growing IC complexity has led to a compelling need for design efficiency\nimprovement through new electronic design automation (EDA) methodologies. In\nrecent years, many unprecedented efficient EDA methods have been enabled by\nmachine learning (ML) techniques. While ML demonstrates its great potential in\ncircuit design, however, the dark side about security problems, is seldomly\ndiscussed. This paper gives a comprehensive and impartial summary of all\nsecurity concerns we have observed in ML for EDA. Many of them are hidden or\nneglected by practitioners in this field. In this paper, we first provide our\ntaxonomy to define four major types of security concerns, then we analyze\ndifferent application scenarios and special properties in ML for EDA. After\nthat, we present our detailed analysis of each security concern with\nexperiments.\n",
                "链接": "https://arxiv.org/abs/2203.10597"
            },
            {
                "文章ID": "92590",
                "标题": "Security and Privacy Issues of Federated Learning",
                "作者": " Jahid Hasan",
                "发布日期": "2023-07-25",
                "摘要": "  Federated Learning (FL) has emerged as a promising approach to address data\nprivacy and confidentiality concerns by allowing multiple participants to\nconstruct a shared model without centralizing sensitive data. However, this\ndecentralized paradigm introduces new security challenges, necessitating a\ncomprehensive identification and classification of potential risks to ensure\nFL's security guarantees. This paper presents a comprehensive taxonomy of\nsecurity and privacy challenges in Federated Learning (FL) across various\nmachine learning models, including large language models. We specifically\ncategorize attacks performed by the aggregator and participants, focusing on\npoisoning attacks, backdoor attacks, membership inference attacks, generative\nadversarial network (GAN) based attacks, and differential privacy attacks.\nAdditionally, we propose new directions for future research, seeking innovative\nsolutions to fortify FL systems against emerging security risks and uphold\nsensitive data confidentiality in distributed learning environments.\n",
                "链接": "https://arxiv.org/abs/2307.12181"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下对使用GPT生成数据集的训练步骤进行改进的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "56440",
                "标题": "Automatic Generation of German Drama Texts Using Fine Tuned GPT-2 Models",
                "作者": " Mariam Bangura,  Kristina Barabashova,  Anna Karnysheva,  Sarah Semczuk,  Yifan Wang",
                "发布日期": "2023-01-11",
                "摘要": "  This study is devoted to the automatic generation of German drama texts. We\nsuggest an approach consisting of two key steps: fine-tuning a GPT-2 model (the\noutline model) to generate outlines of scenes based on keywords and fine-tuning\na second model (the generation model) to generate scenes from the scene\noutline. The input for the neural model comprises two datasets: the German\nDrama Corpus (GerDraCor) and German Text Archive (Deutsches Textarchiv or DTA).\nIn order to estimate the effectiveness of the proposed method, our models are\ncompared with baseline GPT-2 models. Our models perform well according to\nautomatic quantitative evaluation, but, conversely, manual qualitative analysis\nreveals a poor quality of generated texts. This may be due to the quality of\nthe dataset or training inputs.\n",
                "链接": "https://arxiv.org/abs/2301.03119"
            },
            {
                "文章ID": "74683",
                "标题": "CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to\n  Guardrail Models for Virtual Assistants",
                "作者": " Albert Yu Sun,  Varun Nair,  Elliot Schumacher,  Anitha Kannan",
                "发布日期": "2023-04-28",
                "摘要": "  A wave of new task-based virtual assistants has been fueled by increasingly\npowerful large language models, such as GPT-4. These conversational agents can\nbe customized to serve customer-specific use cases, but ensuring that\nagent-generated text conforms to designer-specified rules included in prompt\ninstructions alone is challenging. Therefore, chatbot designers often use\nanother model, called a guardrail model, to verify that the agent output aligns\nwith their rules and constraints. We explore using a distillation approach to\nguardrail models to monitor the output of the first model using training data\nfrom GPT-4. We find two crucial steps to our CONSCENDI process:\nscenario-augmented generation and contrastive training examples. When\ngenerating conversational data, we generate a set of rule-breaking scenarios,\nwhich enumerate a diverse set of high-level ways a rule can be violated. This\nscenario-guided approach produces a diverse training set of rule-violating\nconversations, and it provides chatbot designers greater control over the\nclassification process. We also prompt GPT-4 to also generate contrastive\nexamples by altering conversations with violations into acceptable\nconversations. This set of borderline, contrastive examples enables the\ndistilled model to learn finer-grained distinctions between what is acceptable\nand what is not. We find that CONSCENDI results in guardrail models that\nimprove over baselines.\n",
                "链接": "https://arxiv.org/abs/2304.14364"
            },
            {
                "文章ID": "15595",
                "标题": "CodexDB: Generating Code for Processing SQL Queries using GPT-3 Codex",
                "作者": " Immanuel Trummer",
                "发布日期": "2022-04-20",
                "摘要": "  CodexDB is an SQL processing engine whose internals can be customized via\nnatural language instructions. CodexDB is based on OpenAI's GPT-3 Codex model\nwhich translates text into code. It is a framework on top of GPT-3 Codex that\ndecomposes complex SQL queries into a series of simple processing steps,\ndescribed in natural language. Processing steps are enriched with user-provided\ninstructions and descriptions of database properties. Codex translates the\nresulting text into query processing code. An early prototype of CodexDB is\nable to generate correct code for a majority of queries of the WikiSQL\nbenchmark and can be customized in various ways.\n",
                "链接": "https://arxiv.org/abs/2204.08941"
            },
            {
                "文章ID": "87132",
                "标题": "Solving and Generating NPR Sunday Puzzles with Large Language Models",
                "作者": " Jingmiao Zhao,  Carolyn Jane Anderson",
                "发布日期": "2023-06-22",
                "摘要": "  We explore the ability of large language models to solve and generate puzzles\nfrom the NPR Sunday Puzzle game show using PUZZLEQA, a dataset comprising 15\nyears of on-air puzzles. We evaluate four large language models using PUZZLEQA,\nin both multiple choice and free response formats, and explore two prompt\nengineering techniques to improve free response performance: chain-of-thought\nreasoning and prompt summarization. We find that state-of-the-art large\nlanguage models can solve many PUZZLEQA puzzles: the best model, GPT-3.5,\nachieves 50.2% loose accuracy. However, in our few-shot puzzle generation\nexperiment, we find no evidence that models can generate puzzles: GPT-3.5\ngenerates puzzles with answers that do not conform to the generated rules.\nPuzzle generation remains a challenging task for future work.\n",
                "链接": "https://arxiv.org/abs/2306.12255"
            },
            {
                "文章ID": "83260",
                "标题": "ProcessGPT: Transforming Business Process Management with Generative\n  Artificial Intelligence",
                "作者": " Amin Beheshti,  Jian Yang,  Quan Z. Sheng,  Boualem Benatallah,  Fabio Casati,  Schahram Dustdar,  Hamid Reza Motahari Nezhad,  Xuyun Zhang,  Shan Xue",
                "发布日期": "2023-06-06",
                "摘要": "  Generative Pre-trained Transformer (GPT) is a state-of-the-art machine\nlearning model capable of generating human-like text through natural language\nprocessing (NLP). GPT is trained on massive amounts of text data and uses deep\nlearning techniques to learn patterns and relationships within the data,\nenabling it to generate coherent and contextually appropriate text. This\nposition paper proposes using GPT technology to generate new process models\nwhen/if needed. We introduce ProcessGPT as a new technology that has the\npotential to enhance decision-making in data-centric and knowledge-intensive\nprocesses. ProcessGPT can be designed by training a generative pre-trained\ntransformer model on a large dataset of business process data. This model can\nthen be fine-tuned on specific process domains and trained to generate process\nflows and make decisions based on context and user input. The model can be\nintegrated with NLP and machine learning techniques to provide insights and\nrecommendations for process improvement. Furthermore, the model can automate\nrepetitive tasks and improve process efficiency while enabling knowledge\nworkers to communicate analysis findings, supporting evidence, and make\ndecisions. ProcessGPT can revolutionize business process management (BPM) by\noffering a powerful tool for process augmentation, automation and improvement.\nFinally, we demonstrate how ProcessGPT can be a powerful tool for augmenting\ndata engineers in maintaining data ecosystem processes within large bank\norganizations. Our scenario highlights the potential of this approach to\nimprove efficiency, reduce costs, and enhance the quality of business\noperations through the automation of data-centric and knowledge-intensive\nprocesses. These results underscore the promise of ProcessGPT as a\ntransformative technology for organizations looking to improve their process\nworkflows.\n",
                "链接": "https://arxiv.org/abs/2306.01771"
            },
            {
                "文章ID": "110235",
                "标题": "Robust Training for Conversational Question Answering Models with\n  Reinforced Reformulation Generation",
                "作者": " Magdalena Kaiser,  Rishiraj Saha Roy,  Gerhard Weikum",
                "发布日期": "2023-11-07",
                "摘要": "  Models for conversational question answering (ConvQA) over knowledge graphs\n(KGs) are usually trained and tested on benchmarks of gold QA pairs. This\nimplies that training is limited to surface forms seen in the respective\ndatasets, and evaluation is on a small set of held-out questions. Through our\nproposed framework REIGN, we take several steps to remedy this restricted\nlearning setup. First, we systematically generate reformulations of training\nquestions to increase robustness of models to surface form variations. This is\na particularly challenging problem, given the incomplete nature of such\nquestions. Second, we guide ConvQA models towards higher performance by feeding\nit only those reformulations that help improve their answering quality, using\ndeep reinforcement learning. Third, we demonstrate the viability of training\nmajor model components on one benchmark and applying them zero-shot to another.\nFinally, for a rigorous evaluation of robustness for trained models, we use and\nrelease large numbers of diverse reformulations generated by prompting GPT for\nbenchmark test sets (resulting in 20x increase in sizes). Our findings show\nthat ConvQA models with robust training via reformulations, significantly\noutperform those with standard training from gold QA pairs only.\n",
                "链接": "https://arxiv.org/abs/2310.13505"
            },
            {
                "文章ID": "78458",
                "标题": "Generalized Multiple Intent Conditioned Slot Filling",
                "作者": " Harshil Shah,  Arthur Wilcke,  Marius Cobzarenco,  Cristi Cobzarenco,  Edward Challis,  David Barber",
                "发布日期": "2023-05-19",
                "摘要": "  Natural language understanding includes the tasks of intent detection\n(identifying a user's objectives) and slot filling (extracting the entities\nrelevant to those objectives). Prior slot filling methods assume that each\nintent type cannot occur more than once within a message, however this is often\nnot a valid assumption for real-world settings. In this work, we generalize\nslot filling by removing the constraint of unique intents in a message. We cast\nthis as a JSON generation task and approach it using a language model. We\ncreate a pre-training dataset by combining DBpedia and existing slot filling\ndatasets that we convert for JSON generation. We also generate an in-domain\ndataset using GPT-3. We train T5 models for this task (with and without\nexemplars in the prompt) and find that both training datasets improve\nperformance, and that the model is able to generalize to intent types not seen\nduring training.\n",
                "链接": "https://arxiv.org/abs/2305.11023"
            },
            {
                "文章ID": "5202",
                "标题": "Maximizing Communication Efficiency for Large-scale Training via 0/1\n  Adam",
                "作者": " Yucheng Lu,  Conglong Li,  Minjia Zhang,  Christopher De Sa,  Yuxiong He",
                "发布日期": "2022-05-24",
                "摘要": "  1-bit gradient compression and local steps are two representative techniques\nthat enable drastic communication reduction in distributed SGD. Their benefits,\nhowever, remain an open question on Adam-based large model pre-training (e.g.\nBERT and GPT). In this paper, we demonstrate the non-linearity in Adam causes\nslow convergence even when 1-bit compression or local steps are individually\napplied. To alleviate this limitation, we propose 0/1 Adam that linearizes each\nAdam step via approximating its optimizer states using their stale estimates\nand linear correlation. 0/1 Adam performs an Adam-like step to preserve the\nadaptivity, while its linearity allows utilizing 1-bit compression and local\nsteps simultaneously for wall-clock time speed up. We provide convergence\nguarantee for 0/1 Adam on smooth non-convex objectives. On various large-scale\nbenchmarks such as BERT-Base, BERT-Large, GPT-2 pre-training and ImageNet, we\ndemonstrate on up to 128 GPUs that 0/1 Adam is able to reduce up to 87% of data\nvolume, 54% of communication rounds, and achieve up to 2$\\times$ higher\ntraining throughput and end-to-end training time reduction compared to the\nstate-of-the-art baseline 1-bit Adam; while enjoying the same statistical\nconvergence speed and end task model accuracy on GLUE dataset and ImageNet\nvalidation set.\n",
                "链接": "https://arxiv.org/abs/2202.06009"
            },
            {
                "文章ID": "75365",
                "标题": "AutoColor: Learned Light Power Control for Multi-Color Holograms",
                "作者": " Yicheng Zhan,  Koray Kavaklı,  Hakan Urey,  Qi Sun,  Kaan Akşit",
                "发布日期": "2023-05-03",
                "摘要": "  Multi-color holograms rely on simultaneous illumination from multiple light\nsources. These multi-color holograms could utilize light sources better than\nconventional single-color holograms and can improve the dynamic range of\nholographic displays. In this letter, we introduce \\projectname, the first\nlearned method for estimating the optimal light source powers required for\nilluminating multi-color holograms. For this purpose, we establish the first\nmulti-color hologram dataset using synthetic images and their depth\ninformation. We generate these synthetic images using a trending pipeline\ncombining generative, large language, and monocular depth estimation models.\nFinally, we train our learned model using our dataset and experimentally\ndemonstrate that \\projectname significantly decreases the number of steps\nrequired to optimize multi-color holograms from $>1000$ to $70$ iteration steps\nwithout compromising image quality.\n",
                "链接": "https://arxiv.org/abs/2305.01611"
            },
            {
                "文章ID": "35504",
                "标题": "Generating Intermediate Steps for NLI with Next-Step Supervision",
                "作者": " Deepanway Ghosal,  Somak Aditya,  Monojit Choudhury",
                "发布日期": "2022-09-01",
                "摘要": "  The Natural Language Inference (NLI) task often requires reasoning over\nmultiple steps to reach the conclusion. While the necessity of generating such\nintermediate steps (instead of a summary explanation) has gained popular\nsupport, it is unclear how to generate such steps without complete end-to-end\nsupervision and how such generated steps can be further utilized. In this work,\nwe train a sequence-to-sequence model to generate only the next step given an\nNLI premise and hypothesis pair (and previous steps); then enhance it with\nexternal knowledge and symbolic search to generate intermediate steps with only\nnext-step supervision. We show the correctness of such generated steps through\nautomated and human verification. Furthermore, we show that such generated\nsteps can help improve end-to-end NLI task performance using simple data\naugmentation strategies, across multiple public NLI datasets.\n",
                "链接": "https://arxiv.org/abs/2208.14641"
            }
        ]
    },
    {
        "question": {
            "question": "请找到利用clip做开放词汇检测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "105778",
                "标题": "CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense\n  Prediction",
                "作者": " Size Wu,  Wenwei Zhang,  Lumin Xu,  Sheng Jin,  Xiangtai Li,  Wentao Liu,  Chen Change Loy",
                "发布日期": "2023-10-03",
                "摘要": "  Open-vocabulary dense prediction tasks including object detection and image\nsegmentation have been advanced by the success of Contrastive Language-Image\nPre-training (CLIP). CLIP models, particularly those incorporating vision\ntransformers (ViTs), have exhibited remarkable generalization ability in\nzero-shot image classification. However, when transferring the vision-language\nalignment of CLIP from global image representation to local region\nrepresentation for the open-vocabulary dense prediction tasks, CLIP ViTs suffer\nfrom the domain shift from full images to local image regions. In this paper,\nwe embark on an in-depth analysis of the region-language alignment in CLIP\nmodels, which is essential for downstream open-vocabulary dense prediction\ntasks. Subsequently, we propose an approach named CLIPSelf, which adapts the\nimage-level recognition ability of CLIP ViT to local image regions without\nneeding any region-text pairs. CLIPSelf empowers ViTs to distill itself by\naligning a region representation extracted from its dense feature map with the\nimage-level representation of the corresponding image crop. With the enhanced\nCLIP ViTs, we achieve new state-of-the-art performance on open-vocabulary\nobject detection, semantic segmentation, and panoptic segmentation across\nvarious benchmarks. Models and code will be available at\nhttps://github.com/wusize/CLIPSelf.\n",
                "链接": "https://arxiv.org/abs/2310.01403"
            },
            {
                "文章ID": "121784",
                "标题": "OpenSD: Unified Open-Vocabulary Segmentation and Detection",
                "作者": " Shuai Li,  Minghan Li,  Pengfei Wang,  Lei Zhang",
                "发布日期": "2023-12-13",
                "摘要": "  Recently, a few open-vocabulary methods have been proposed by employing a\nunified architecture to tackle generic segmentation and detection tasks.\nHowever, their performance still lags behind the task-specific models due to\nthe conflict between different tasks, and their open-vocabulary capability is\nlimited due to the inadequate use of CLIP. To address these challenges, we\npresent a universal transformer-based framework, abbreviated as OpenSD, which\nutilizes the same architecture and network parameters to handle open-vocabulary\nsegmentation and detection tasks. First, we introduce a decoder decoupled\nlearning strategy to alleviate the semantic conflict between thing and staff\ncategories so that each individual task can be learned more effectively under\nthe same framework. Second, to better leverage CLIP for end-to-end segmentation\nand detection, we propose dual classifiers to handle the in-vocabulary domain\nand out-of-vocabulary domain, respectively. The text encoder is further trained\nto be region-aware for both thing and stuff categories through decoupled prompt\nlearning, enabling them to filter out duplicated and low-quality predictions,\nwhich is important to end-to-end segmentation and detection. Extensive\nexperiments are conducted on multiple datasets under various circumstances. The\nresults demonstrate that OpenSD outperforms state-of-the-art open-vocabulary\nsegmentation and detection methods in both closed- and open-vocabulary\nsettings. Code is available at https://github.com/strongwolf/OpenSD\n",
                "链接": "https://arxiv.org/abs/2312.06703"
            },
            {
                "文章ID": "124461",
                "标题": "FM-OV3D: Foundation Model-based Cross-modal Knowledge Blending for\n  Open-Vocabulary 3D Detection",
                "作者": " Dongmei Zhang,  Chang Li,  Ray Zhang,  Shenghao Xie,  Wei Xue,  Xiaodong Xie,  Shanghang Zhang",
                "发布日期": "2023-12-25",
                "摘要": "  The superior performances of pre-trained foundation models in various visual\ntasks underscore their potential to enhance the 2D models' open-vocabulary\nability. Existing methods explore analogous applications in the 3D space.\nHowever, most of them only center around knowledge extraction from singular\nfoundation models, which limits the open-vocabulary ability of 3D models. We\nhypothesize that leveraging complementary pre-trained knowledge from various\nfoundation models can improve knowledge transfer from 2D pre-trained visual\nlanguage models to the 3D space. In this work, we propose FM-OV3D, a method of\nFoundation Model-based Cross-modal Knowledge Blending for Open-Vocabulary 3D\nDetection, which improves the open-vocabulary localization and recognition\nabilities of 3D model by blending knowledge from multiple pre-trained\nfoundation models, achieving true open-vocabulary without facing constraints\nfrom original 3D datasets. Specifically, to learn the open-vocabulary 3D\nlocalization ability, we adopt the open-vocabulary localization knowledge of\nthe Grounded-Segment-Anything model. For open-vocabulary 3D recognition\nability, We leverage the knowledge of generative foundation models, including\nGPT-3 and Stable Diffusion models, and cross-modal discriminative models like\nCLIP. The experimental results on two popular benchmarks for open-vocabulary 3D\nobject detection show that our model efficiently learns knowledge from multiple\nfoundation models to enhance the open-vocabulary ability of the 3D model and\nsuccessfully achieves state-of-the-art performance in open-vocabulary 3D object\ndetection tasks. Code is released at\nhttps://github.com/dmzhang0425/FM-OV3D.git.\n",
                "链接": "https://arxiv.org/abs/2312.14465"
            },
            {
                "文章ID": "68854",
                "标题": "Prompt-Guided Transformers for End-to-End Open-Vocabulary Object\n  Detection",
                "作者": " Hwanjun Song,  Jihwan Bang",
                "发布日期": "2023-03-28",
                "摘要": "  Prompt-OVD is an efficient and effective framework for open-vocabulary object\ndetection that utilizes class embeddings from CLIP as prompts, guiding the\nTransformer decoder to detect objects in both base and novel classes.\nAdditionally, our novel RoI-based masked attention and RoI pruning techniques\nhelp leverage the zero-shot classification ability of the Vision\nTransformer-based CLIP, resulting in improved detection performance at minimal\ncomputational cost. Our experiments on the OV-COCO and OVLVIS datasets\ndemonstrate that Prompt-OVD achieves an impressive 21.2 times faster inference\nspeed than the first end-to-end open-vocabulary detection method (OV-DETR),\nwhile also achieving higher APs than four two-stage-based methods operating\nwithin similar inference time ranges. Code will be made available soon.\n",
                "链接": "https://arxiv.org/abs/2303.14386"
            },
            {
                "文章ID": "110181",
                "标题": "SILC: Improving Vision Language Pretraining with Self-Distillation",
                "作者": " Muhammad Ferjad Naeem,  Yongqin Xian,  Xiaohua Zhai,  Lukas Hoyer,  Luc Van Gool,  Federico Tombari",
                "发布日期": "2023-12-08",
                "摘要": "  Image-Text pretraining on web-scale image caption datasets has become the\ndefault recipe for open vocabulary classification and retrieval models thanks\nto the success of CLIP and its variants. Several works have also used CLIP\nfeatures for dense prediction tasks and have shown the emergence of open-set\nabilities. However, the contrastive objective used by these models only focuses\non image-text alignment and does not incentivise image feature learning for\ndense prediction tasks. In this work, we introduce SILC, a novel framework for\nvision language pretraining. SILC improves image-text contrastive learning with\nthe simple addition of local-to-global correspondence learning by\nself-distillation. We show that distilling local image features from an\nexponential moving average (EMA) teacher model significantly improves model\nperformance on dense predictions tasks like detection and segmentation, while\nalso providing improvements on image-level tasks such as classification and\nretrieval. SILC models sets a new state of the art for zero-shot\nclassification, few shot classification, image and text retrieval, zero-shot\nsegmentation, and open vocabulary segmentation. We further show that SILC\nfeatures greatly benefit open vocabulary detection, captioning and visual\nquestion answering.\n",
                "链接": "https://arxiv.org/abs/2310.13355"
            },
            {
                "文章ID": "22912",
                "标题": "Delving into the Openness of CLIP",
                "作者": " Shuhuai Ren,  Lei Li,  Xuancheng Ren,  Guangxiang Zhao,  Xu Sun",
                "发布日期": "2023-05-09",
                "摘要": "  Contrastive Language-Image Pre-training (CLIP) formulates image\nclassification as an image-to-text matching task, i.e., matching images to the\ncorresponding natural language descriptions instead of discrete category IDs.\nThis allows for open-vocabulary visual recognition, where the model can\nrecognize images from an open class set (also known as an open vocabulary) in a\nzero-shot manner. However, evaluating the openness of CLIP-like models is\nchallenging, as the models are open to arbitrary vocabulary in theory, but\ntheir accuracy varies in practice. To address this, we resort to an incremental\nperspective to assess the openness through vocabulary expansions, and define\nextensibility to measure a model's ability to handle novel classes. Our\nevaluation shows that CLIP-like models are not truly open, and their\nperformance deteriorates as the vocabulary expands. We further dissect the\nfeature space of CLIP from the perspectives of representation alignment and\nuniformity. Our investigation reveals that the overestimation of openness is\ndue to confusion among competing text features, rather than a failure to\ncapture the similarity between image features and text features of novel\nclasses. We hope that our investigation and analysis will facilitate future\nresearch on the CLIP openness issue.\n",
                "链接": "https://arxiv.org/abs/2206.01986"
            },
            {
                "文章ID": "94707",
                "标题": "Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen\n  Convolutional CLIP",
                "作者": " Qihang Yu,  Ju He,  Xueqing Deng,  Xiaohui Shen,  Liang-Chieh Chen",
                "发布日期": "2023-11-16",
                "摘要": "  Open-vocabulary segmentation is a challenging task requiring segmenting and\nrecognizing objects from an open set of categories. One way to address this\nchallenge is to leverage multi-modal models, such as CLIP, to provide image and\ntext features in a shared embedding space, which bridges the gap between\nclosed-vocabulary and open-vocabulary recognition. Hence, existing methods\noften adopt a two-stage framework to tackle the problem, where the inputs first\ngo through a mask generator and then through the CLIP model along with the\npredicted masks. This process involves extracting features from images multiple\ntimes, which can be ineffective and inefficient. By contrast, we propose to\nbuild everything into a single-stage framework using a shared Frozen\nConvolutional CLIP backbone, which not only significantly simplifies the\ncurrent two-stage pipeline, but also remarkably yields a better accuracy-cost\ntrade-off. The proposed FC-CLIP, benefits from the following observations: the\nfrozen CLIP backbone maintains the ability of open-vocabulary classification\nand can also serve as a strong mask generator, and the convolutional CLIP\ngeneralizes well to a larger input resolution than the one used during\ncontrastive image-text pretraining. When training on COCO panoptic data only\nand testing in a zero-shot manner, FC-CLIP achieve 26.8 PQ, 16.8 AP, and 34.1\nmIoU on ADE20K, 18.2 PQ, 27.9 mIoU on Mapillary Vistas, 44.0 PQ, 26.8 AP, 56.2\nmIoU on Cityscapes, outperforming the prior art by +4.2 PQ, +2.4 AP, +4.2 mIoU\non ADE20K, +4.0 PQ on Mapillary Vistas and +20.1 PQ on Cityscapes,\nrespectively. Additionally, the training and testing time of FC-CLIP is 7.5x\nand 6.6x significantly faster than the same prior art, while using 5.9x fewer\nparameters. FC-CLIP also sets a new state-of-the-art performance across various\nopen-vocabulary semantic segmentation datasets. Code at\nhttps://github.com/bytedance/fc-clip\n",
                "链接": "https://arxiv.org/abs/2308.02487"
            },
            {
                "文章ID": "28246",
                "标题": "Bridging the Gap between Object and Image-level Representations for\n  Open-Vocabulary Detection",
                "作者": " Hanoona Rasheed,  Muhammad Maaz,  Muhammad Uzair Khattak,  Salman Khan,  Fahad Shahbaz Khan",
                "发布日期": "2022-11-30",
                "摘要": "  Existing open-vocabulary object detectors typically enlarge their vocabulary\nsizes by leveraging different forms of weak supervision. This helps generalize\nto novel objects at inference. Two popular forms of weak-supervision used in\nopen-vocabulary detection (OVD) include pretrained CLIP model and image-level\nsupervision. We note that both these modes of supervision are not optimally\naligned for the detection task: CLIP is trained with image-text pairs and lacks\nprecise localization of objects while the image-level supervision has been used\nwith heuristics that do not accurately specify local object regions. In this\nwork, we propose to address this problem by performing object-centric alignment\nof the language embeddings from the CLIP model. Furthermore, we visually ground\nthe objects with only image-level supervision using a pseudo-labeling process\nthat provides high-quality object proposals and helps expand the vocabulary\nduring training. We establish a bridge between the above two object-alignment\nstrategies via a novel weight transfer function that aggregates their\ncomplimentary strengths. In essence, the proposed model seeks to minimize the\ngap between object and image-centric representations in the OVD setting. On the\nCOCO benchmark, our proposed approach achieves 36.6 AP50 on novel classes, an\nabsolute 8.2 gain over the previous best performance. For LVIS, we surpass the\nstate-of-the-art ViLD model by 5.0 mask AP for rare categories and 3.4 overall.\nCode: https://github.com/hanoonaR/object-centric-ovd.\n",
                "链接": "https://arxiv.org/abs/2207.03482"
            },
            {
                "文章ID": "120843",
                "标题": "Open-Vocabulary Segmentation with Semantic-Assisted Calibration",
                "作者": " Yong Liu,  Sule Bai,  Guanbin Li,  Yitong Wang,  Yansong Tang",
                "发布日期": "2023-12-08",
                "摘要": "  This paper studies open-vocabulary segmentation (OVS) through calibrating\nin-vocabulary and domain-biased embedding space with generalized contextual\nprior of CLIP. As the core of open-vocabulary understanding, alignment of\nvisual content with the semantics of unbounded text has become the bottleneck\nof this field. To address this challenge, recent works propose to utilize CLIP\nas an additional classifier and aggregate model predictions with CLIP\nclassification results. Despite their remarkable progress, performance of OVS\nmethods in relevant scenarios is still unsatisfactory compared with supervised\ncounterparts. We attribute this to the in-vocabulary embedding and\ndomain-biased CLIP prediction. To this end, we present a Semantic-assisted\nCAlibration Network (SCAN). In SCAN, we incorporate generalized semantic prior\nof CLIP into proposal embedding to avoid collapsing on known categories.\nBesides, a contextual shift strategy is applied to mitigate the lack of global\ncontext and unnatural background noise. With above designs, SCAN achieves\nstate-of-the-art performance on all popular open-vocabulary segmentation\nbenchmarks. Furthermore, we also focus on the problem of existing evaluation\nsystem that ignores semantic duplication across categories, and propose a new\nmetric called Semantic-Guided IoU (SG-IoU).\n",
                "链接": "https://arxiv.org/abs/2312.04089"
            },
            {
                "文章ID": "116861",
                "标题": "CastDet: Toward Open Vocabulary Aerial Object Detection with\n  CLIP-Activated Student-Teacher Learning",
                "作者": " Yan Li,  Weiwei Guo,  Dunyun He,  Jiaqi Zhou,  Yuze Gao,  Wenxian Yu",
                "发布日期": "2023-11-21",
                "摘要": "  Object detection in aerial images is a pivotal task for various earth\nobservation applications, whereas current algorithms learn to detect only a\npre-defined set of object categories demanding sufficient bounding-box\nannotated training samples and fail to detect novel object categories. In this\npaper, we consider open-vocabulary object detection (OVD) in aerial images that\nenables the characterization of new objects beyond training categories on the\nearth surface without annotating training images for these new categories. The\nperformance of OVD depends on the quality of class-agnostic region proposals\nand pseudo-labels that can generalize well to novel object categories. To\nsimultaneously generate high-quality proposals and pseudo-labels, we propose\nCastDet, a CLIP-activated student-teacher open-vocabulary object Detection\nframework. Our end-to-end framework within the student-teacher mechanism\nemploys the CLIP model as an extra omniscient teacher of rich knowledge into\nthe student-teacher self-learning process. By doing so, our approach boosts\nnovel object proposals and classification. Furthermore, we design a dynamic\nlabel queue technique to maintain high-quality pseudo labels during batch\ntraining and mitigate label imbalance. We conduct extensive experiments on\nmultiple existing aerial object detection datasets, which are set up for the\nOVD task. Experimental results demonstrate our CastDet achieving superior\nopen-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean),\nwhich outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD\ndataset.\n",
                "链接": "https://arxiv.org/abs/2311.11646"
            }
        ]
    },
    {
        "question": {
            "question": "请找到使用自蒸馏加强目标检测性能的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "65588",
                "标题": "Smooth and Stepwise Self-Distillation for Object Detection",
                "作者": " Jieren Deng,  Xin Zhou,  Hao Tian,  Zhihong Pan,  Derek Aguiar",
                "发布日期": "2023-03-10",
                "摘要": "  Distilling the structured information captured in feature maps has\ncontributed to improved results for object detection tasks, but requires\ncareful selection of baseline architectures and substantial pre-training.\nSelf-distillation addresses these limitations and has recently achieved\nstate-of-the-art performance for object detection despite making several\nsimplifying architectural assumptions. Building on this work, we propose Smooth\nand Stepwise Self-Distillation (SSSD) for object detection. Our SSSD\narchitecture forms an implicit teacher from object labels and a feature pyramid\nnetwork backbone to distill label-annotated feature maps using Jensen-Shannon\ndistance, which is smoother than distillation losses used in prior work. We\nadditionally add a distillation coefficient that is adaptively configured based\non the learning rate. We extensively benchmark SSSD against a baseline and two\nstate-of-the-art object detector architectures on the COCO dataset by varying\nthe coefficients and backbone and detector networks. We demonstrate that SSSD\nachieves higher average precision in most experimental settings, is robust to a\nwide range of coefficients, and benefits from our stepwise distillation\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2303.05015"
            },
            {
                "文章ID": "92560",
                "标题": "Spatial Self-Distillation for Object Detection with Inaccurate Bounding\n  Boxes",
                "作者": " Di Wu,  Pengfei Chen,  Xuehui Yu,  Guorong Li,  Zhenjun Han,  Jianbin Jiao",
                "发布日期": "2023-08-16",
                "摘要": "  Object detection via inaccurate bounding boxes supervision has boosted a\nbroad interest due to the expensive high-quality annotation data or the\noccasional inevitability of low annotation quality (\\eg tiny objects). The\nprevious works usually utilize multiple instance learning (MIL), which highly\ndepends on category information, to select and refine a low-quality box. Those\nmethods suffer from object drift, group prediction and part domination problems\nwithout exploring spatial information. In this paper, we heuristically propose\na \\textbf{Spatial Self-Distillation based Object Detector (SSD-Det)} to mine\nspatial information to refine the inaccurate box in a self-distillation\nfashion. SSD-Det utilizes a Spatial Position Self-Distillation \\textbf{(SPSD)}\nmodule to exploit spatial information and an interactive structure to combine\nspatial information and category information, thus constructing a high-quality\nproposal bag. To further improve the selection procedure, a Spatial Identity\nSelf-Distillation \\textbf{(SISD)} module is introduced in SSD-Det to obtain\nspatial confidence to help select the best proposals. Experiments on MS-COCO\nand VOC datasets with noisy box annotation verify our method's effectiveness\nand achieve state-of-the-art performance. The code is available at\nhttps://github.com/ucas-vg/PointTinyBenchmark/tree/SSD-Det.\n",
                "链接": "https://arxiv.org/abs/2307.12101"
            },
            {
                "文章ID": "114760",
                "标题": "Object-centric Cross-modal Feature Distillation for Event-based Object\n  Detection",
                "作者": " Lei Li,  Alexander Liniger,  Mario Millhaeusler,  Vagia Tsiminaki,  Yuanyou Li,  Dengxin Dai",
                "发布日期": "2023-11-10",
                "摘要": "  Event cameras are gaining popularity due to their unique properties, such as\ntheir low latency and high dynamic range. One task where these benefits can be\ncrucial is real-time object detection. However, RGB detectors still outperform\nevent-based detectors due to the sparsity of the event data and missing visual\ndetails. In this paper, we develop a novel knowledge distillation approach to\nshrink the performance gap between these two modalities. To this end, we\npropose a cross-modality object detection distillation method that by design\ncan focus on regions where the knowledge distillation works best. We achieve\nthis by using an object-centric slot attention mechanism that can iteratively\ndecouple features maps into object-centric features and corresponding\npixel-features used for distillation. We evaluate our novel distillation\napproach on a synthetic and a real event dataset with aligned grayscale images\nas a teacher modality. We show that object-centric distillation allows to\nsignificantly improve the performance of the event-based student object\ndetector, nearly halving the performance gap with respect to the teacher.\n",
                "链接": "https://arxiv.org/abs/2311.05494"
            },
            {
                "文章ID": "2760",
                "标题": "Adaptive Instance Distillation for Object Detection in Autonomous\n  Driving",
                "作者": " Qizhen Lan,  Qing Tian",
                "发布日期": "2023-03-23",
                "摘要": "  In recent years, knowledge distillation (KD) has been widely used to derive\nefficient models. Through imitating a large teacher model, a lightweight\nstudent model can achieve comparable performance with more efficiency. However,\nmost existing knowledge distillation methods are focused on classification\ntasks. Only a limited number of studies have applied knowledge distillation to\nobject detection, especially in time-sensitive autonomous driving scenarios. In\nthis paper, we propose Adaptive Instance Distillation (AID) to selectively\nimpart teacher's knowledge to the student to improve the performance of\nknowledge distillation. Unlike previous KD methods that treat all instances\nequally, our AID can attentively adjust the distillation weights of instances\nbased on the teacher model's prediction loss. We verified the effectiveness of\nour AID method through experiments on the KITTI and the COCO traffic datasets.\nThe results show that our method improves the performance of state-of-the-art\nattention-guided and non-local distillation methods and achieves better\ndistillation results on both single-stage and two-stage detectors. Compared to\nthe baseline, our AID led to an average of 2.7% and 2.1% mAP increases for\nsingle-stage and two-stage detectors, respectively. Furthermore, our AID is\nalso shown to be useful for self-distillation to improve the teacher model's\nperformance.\n",
                "链接": "https://arxiv.org/abs/2201.11097"
            },
            {
                "文章ID": "33013",
                "标题": "Self-Knowledge Distillation via Dropout",
                "作者": " Hyoje Lee,  Yeachan Park,  Hyun Seo,  Myungjoo Kang",
                "发布日期": "2022-08-12",
                "摘要": "  To boost the performance, deep neural networks require deeper or wider\nnetwork structures that involve massive computational and memory costs. To\nalleviate this issue, the self-knowledge distillation method regularizes the\nmodel by distilling the internal knowledge of the model itself. Conventional\nself-knowledge distillation methods require additional trainable parameters or\nare dependent on the data. In this paper, we propose a simple and effective\nself-knowledge distillation method using a dropout (SD-Dropout). SD-Dropout\ndistills the posterior distributions of multiple models through a dropout\nsampling. Our method does not require any additional trainable modules, does\nnot rely on data, and requires only simple operations. Furthermore, this simple\nmethod can be easily combined with various self-knowledge distillation\napproaches. We provide a theoretical and experimental analysis of the effect of\nforward and reverse KL-divergences in our work. Extensive experiments on\nvarious vision tasks, i.e., image classification, object detection, and\ndistribution shift, demonstrate that the proposed method can effectively\nimprove the generalization of a single network. Further experiments show that\nthe proposed method also improves calibration performance, adversarial\nrobustness, and out-of-distribution detection ability.\n",
                "链接": "https://arxiv.org/abs/2208.05642"
            },
            {
                "文章ID": "65349",
                "标题": "Gradient-Guided Knowledge Distillation for Object Detectors",
                "作者": " Qizhen Lan,  Qing Tian",
                "发布日期": "2023-03-09",
                "摘要": "  Deep learning models have demonstrated remarkable success in object\ndetection, yet their complexity and computational intensity pose a barrier to\ndeploying them in real-world applications (e.g., self-driving perception).\nKnowledge Distillation (KD) is an effective way to derive efficient models.\nHowever, only a small number of KD methods tackle object detection. Also, most\nof them focus on mimicking the plain features of the teacher model but rarely\nconsider how the features contribute to the final detection. In this paper, we\npropose a novel approach for knowledge distillation in object detection, named\nGradient-guided Knowledge Distillation (GKD). Our GKD uses gradient information\nto identify and assign more weights to features that significantly impact the\ndetection loss, allowing the student to learn the most relevant features from\nthe teacher. Furthermore, we present bounding-box-aware multi-grained feature\nimitation (BMFI) to further improve the KD performance. Experiments on the\nKITTI and COCO-Traffic datasets demonstrate our method's efficacy in knowledge\ndistillation for object detection. On one-stage and two-stage detectors, our\nGKD-BMFI leads to an average of 5.1% and 3.8% mAP improvement, respectively,\nbeating various state-of-the-art KD methods.\n",
                "链接": "https://arxiv.org/abs/2303.04240"
            },
            {
                "文章ID": "17577",
                "标题": "Cross Domain Object Detection by Target-Perceived Dual Branch\n  Distillation",
                "作者": " Mengzhe He,  Yali Wang,  Jiaxi Wu,  Yiru Wang,  Hanqing Li,  Bo Li,  Weihao Gan,  Wei Wu,  Yu Qiao",
                "发布日期": "2022-05-04",
                "摘要": "  Cross domain object detection is a realistic and challenging task in the\nwild. It suffers from performance degradation due to large shift of data\ndistributions and lack of instance-level annotations in the target domain.\nExisting approaches mainly focus on either of these two difficulties, even\nthough they are closely coupled in cross domain object detection. To solve this\nproblem, we propose a novel Target-perceived Dual-branch Distillation (TDD)\nframework. By integrating detection branches of both source and target domains\nin a unified teacher-student learning scheme, it can reduce domain shift and\ngenerate reliable supervision effectively. In particular, we first introduce a\ndistinct Target Proposal Perceiver between two domains. It can adaptively\nenhance source detector to perceive objects in a target image, by leveraging\ntarget proposal contexts from iterative cross-attention. Afterwards, we design\na concise Dual Branch Self Distillation strategy for model training, which can\nprogressively integrate complementary object knowledge from different domains\nvia self-distillation in two branches. Finally, we conduct extensive\nexperiments on a number of widely-used scenarios in cross domain object\ndetection. The results show that our TDD significantly outperforms the\nstate-of-the-art methods on all the benchmarks. Our code and model will be\navailable at https://github.com/Feobi1999/TDD.\n",
                "链接": "https://arxiv.org/abs/2205.01291"
            },
            {
                "文章ID": "68022",
                "标题": "Efficient Feature Distillation for Zero-shot Annotation Object Detection",
                "作者": " Zhuoming Liu,  Xuefeng Hu,  Ram Nevatia",
                "发布日期": "2023-11-03",
                "摘要": "  We propose a new setting for detecting unseen objects called Zero-shot\nAnnotation object Detection (ZAD). It expands the zero-shot object detection\nsetting by allowing the novel objects to exist in the training images and\nrestricts the additional information the detector uses to novel category names.\nRecently, to detect unseen objects, large-scale vision-language models (e.g.,\nCLIP) are leveraged by different methods. The distillation-based methods have\ngood overall performance but suffer from a long training schedule caused by two\nfactors. First, existing work creates distillation regions biased to the base\ncategories, which limits the distillation of novel category information.\nSecond, directly using the raw feature from CLIP for distillation neglects the\ndomain gap between the training data of CLIP and the detection datasets, which\nmakes it difficult to learn the mapping from the image region to the\nvision-language feature space. To solve these problems, we propose Efficient\nfeature distillation for Zero-shot Annotation object Detection (EZAD). Firstly,\nEZAD adapts the CLIP's feature space to the target detection domain by\nre-normalizing CLIP; Secondly, EZAD uses CLIP to generate distillation\nproposals with potential novel category names to avoid the distillation being\noverly biased toward the base categories. Finally, EZAD takes advantage of\nsemantic meaning for regression to further improve the model performance. As a\nresult, EZAD outperforms the previous distillation-based methods in COCO by 4%\nwith a much shorter training schedule and achieves a 3% improvement on the LVIS\ndataset. Our code is available at https://github.com/dragonlzm/EZAD\n",
                "链接": "https://arxiv.org/abs/2303.12145"
            },
            {
                "文章ID": "14912",
                "标题": "Spatial Likelihood Voting with Self-Knowledge Distillation for Weakly\n  Supervised Object Detection",
                "作者": " Ze Chen,  Zhihang Fu,  Jianqiang Huang,  Mingyuan Tao,  Rongxin Jiang,  Xiang Tian,  Yaowu Chen,  Xian-sheng Hua",
                "发布日期": "2022-04-15",
                "摘要": "  Weakly supervised object detection (WSOD), which is an effective way to train\nan object detection model using only image-level annotations, has attracted\nconsiderable attention from researchers. However, most of the existing methods,\nwhich are based on multiple instance learning (MIL), tend to localize instances\nto the discriminative parts of salient objects instead of the entire content of\nall objects. In this paper, we propose a WSOD framework called the Spatial\nLikelihood Voting with Self-knowledge Distillation Network (SLV-SD Net). In\nthis framework, we introduce a spatial likelihood voting (SLV) module to\nconverge region proposal localization without bounding box annotations.\nSpecifically, in every iteration during training, all the region proposals in a\ngiven image act as voters voting for the likelihood of each category in the\nspatial dimensions. After dilating the alignment on the area with large\nlikelihood values, the voting results are regularized as bounding boxes, which\nare then used for the final classification and localization. Based on SLV, we\nfurther propose a self-knowledge distillation (SD) module to refine the feature\nrepresentations of the given image. The likelihood maps generated by the SLV\nmodule are used to supervise the feature learning of the backbone network,\nencouraging the network to attend to wider and more diverse areas of the image.\nExtensive experiments on the PASCAL VOC 2007/2012 and MS-COCO datasets\ndemonstrate the excellent performance of SLV-SD Net. In addition, SLV-SD Net\nproduces new state-of-the-art results on these benchmarks.\n",
                "链接": "https://arxiv.org/abs/2204.06899"
            },
            {
                "文章ID": "59214",
                "标题": "AMD: Adaptive Masked Distillation for Object Detection",
                "作者": " Guang Yang,  Yin Tang,  Jun Li,  Jianhua Xu,  Xili Wan",
                "发布日期": "2023-02-13",
                "摘要": "  As a general model compression paradigm, feature-based knowledge distillation\nallows the student model to learn expressive features from the teacher\ncounterpart. In this paper, we mainly focus on designing an effective\nfeature-distillation framework and propose a spatial-channel adaptive masked\ndistillation (AMD) network for object detection. More specifically, in order to\naccurately reconstruct important feature regions, we first perform\nattention-guided feature masking on the feature map of the student network,\nsuch that we can identify the important features via spatially adaptive feature\nmasking instead of random masking in the previous methods. In addition, we\nemploy a simple and efficient module to allow the student network channel to be\nadaptive, improving its model capability in object perception and detection. In\ncontrast to the previous methods, more crucial object-aware features can be\nreconstructed and learned from the proposed network, which is conducive to\naccurate object detection. The empirical experiments demonstrate the\nsuperiority of our method: with the help of our proposed distillation method,\nthe student networks report 41.3%, 42.4%, and 42.7% mAP scores when RetinaNet,\nCascade Mask-RCNN and RepPoints are respectively used as the teacher framework\nfor object detection, which outperforms the previous state-of-the-art\ndistillation methods including FGD and MGD.\n",
                "链接": "https://arxiv.org/abs/2301.13538"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用2020年以后CONLL 2004数据集进行NER评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "0",
                "标题": "A Literature Review on Length of Stay Prediction for Stroke Patients\n  using Machine Learning and Statistical Approaches",
                "作者": " Ola Alkhatib,  Ayman Alahmar",
                "发布日期": "2022-01-06",
                "摘要": "  Hospital length of stay (LOS) is one of the most essential healthcare metrics\nthat reflects the hospital quality of service and helps improve hospital\nscheduling and management. LOS prediction helps in cost management because\npatients who remain in hospitals usually do so in hospital units where\nresources are severely limited. In this study, we reviewed papers on LOS\nprediction using machine learning and statistical approaches. Our literature\nreview considers research studies that focus on LOS prediction for stroke\npatients. Some of the surveyed studies revealed that authors reached\ncontradicting conclusions. For example, the age of the patient was considered\nan important predictor of LOS for stroke patients in some studies, while other\nstudies concluded that age was not a significant factor. Therefore, additional\nresearch is required in this domain to further understand the predictors of LOS\nfor stroke patients.\n",
                "链接": "https://arxiv.org/abs/2201.00005"
            },
            {
                "文章ID": "1",
                "标题": "Leveraging Queue Length and Attention Mechanisms for Enhanced Traffic\n  Signal Control Optimization",
                "作者": " Liang Zhang,  Shubin Xie,  Jianming Deng",
                "发布日期": "2023-09-26",
                "摘要": "  Reinforcement learning (RL) techniques for traffic signal control (TSC) have\ngained increasing popularity in recent years. However, most existing RL-based\nTSC methods tend to focus primarily on the RL model structure while neglecting\nthe significance of proper traffic state representation. Furthermore, some\nRL-based methods heavily rely on expert-designed traffic signal phase\ncompetition. In this paper, we present a novel approach to TSC that utilizes\nqueue length as an efficient state representation. We propose two new methods:\n(1) Max Queue-Length (M-QL), an optimization-based traditional method designed\nbased on the property of queue length; and (2) AttentionLight, an RL model that\nemploys the self-attention mechanism to capture the signal phase correlation\nwithout requiring human knowledge of phase relationships. Comprehensive\nexperiments on multiple real-world datasets demonstrate the effectiveness of\nour approach: (1) the M-QL method outperforms the latest RL-based methods; (2)\nAttentionLight achieves a new state-of-the-art performance; and (3) our results\nhighlight the significance of proper state representation, which is as crucial\nas neural network design in TSC methods. Our findings have important\nimplications for advancing the development of more effective and efficient TSC\nmethods. Our code is released on Github (https://github.\ncom/LiangZhang1996/AttentionLight).\n",
                "链接": "https://arxiv.org/abs/2201.00006"
            },
            {
                "文章ID": "2",
                "标题": "Confidence-Aware Multi-Teacher Knowledge Distillation",
                "作者": " Hailin Zhang,  Defang Chen,  Can Wang",
                "发布日期": "2022-02-15",
                "摘要": "  Knowledge distillation is initially introduced to utilize additional\nsupervision from a single teacher model for the student model training. To\nboost the student performance, some recent variants attempt to exploit diverse\nknowledge sources from multiple teachers. However, existing studies mainly\nintegrate knowledge from diverse sources by averaging over multiple teacher\npredictions or combining them using other various label-free strategies, which\nmay mislead student in the presence of low-quality teacher predictions. To\ntackle this problem, we propose Confidence-Aware Multi-teacher Knowledge\nDistillation (CA-MKD), which adaptively assigns sample-wise reliability for\neach teacher prediction with the help of ground-truth labels, with those\nteacher predictions close to one-hot labels assigned large weights. Besides,\nCA-MKD incorporates intermediate layers to stable the knowledge transfer\nprocess. Extensive experiments show that our CA-MKD consistently outperforms\nall compared state-of-the-art methods across various teacher-student\narchitectures.\n",
                "链接": "https://arxiv.org/abs/2201.00007"
            },
            {
                "文章ID": "3",
                "标题": "A Lightweight and Accurate Spatial-Temporal Transformer for Traffic\n  Forecasting",
                "作者": " Guanyao Li,  Shuhan Zhong,  S. -H. Gary Chan,  Ruiyuan Li,  Chih-Chieh Hung,  Wen-Chih Peng",
                "发布日期": "2022-05-05",
                "摘要": "  We study the forecasting problem for traffic with dynamic, possibly\nperiodical, and joint spatial-temporal dependency between regions. Given the\naggregated inflow and outflow traffic of regions in a city from time slots 0 to\nt-1, we predict the traffic at time t at any region. Prior arts in the area\noften consider the spatial and temporal dependencies in a decoupled manner or\nare rather computationally intensive in training with a large number of\nhyper-parameters to tune. We propose ST-TIS, a novel, lightweight, and accurate\nSpatial-Temporal Transformer with information fusion and region sampling for\ntraffic forecasting. ST-TIS extends the canonical Transformer with information\nfusion and region sampling. The information fusion module captures the complex\nspatial-temporal dependency between regions. The region sampling module is to\nimprove the efficiency and prediction accuracy, cutting the computation\ncomplexity for dependency learning from $O(n^2)$ to $O(n\\sqrt{n})$, where n is\nthe number of regions. With far fewer parameters than state-of-the-art models,\nthe offline training of our model is significantly faster in terms of tuning\nand computation (with a reduction of up to $90\\%$ on training time and network\nparameters). Notwithstanding such training efficiency, extensive experiments\nshow that ST-TIS is substantially more accurate in online prediction than\nstate-of-the-art approaches (with an average improvement of up to $9.5\\%$ on\nRMSE, and $12.4\\%$ on MAPE).\n",
                "链接": "https://arxiv.org/abs/2201.00008"
            },
            {
                "文章ID": "4",
                "标题": "Improving Deep Neural Network Classification Confidence using\n  Heatmap-based eXplainable AI",
                "作者": " Erico Tjoa,  Hong Jing Khok,  Tushar Chouhan,  Guan Cuntai",
                "发布日期": "2023-01-24",
                "摘要": "  This paper quantifies the quality of heatmap-based eXplainable AI (XAI)\nmethods w.r.t image classification problem. Here, a heatmap is considered\ndesirable if it improves the probability of predicting the correct classes.\nDifferent XAI heatmap-based methods are empirically shown to improve\nclassification confidence to different extents depending on the datasets, e.g.\nSaliency works best on ImageNet and Deconvolution on Chest X-Ray Pneumonia\ndataset. The novelty includes a new gap distribution that shows a stark\ndifference between correct and wrong predictions. Finally, the generative\naugmentative explanation is introduced, a method to generate heatmaps capable\nof improving predictive confidence to a high level.\n",
                "链接": "https://arxiv.org/abs/2201.00009"
            },
            {
                "文章ID": "5",
                "标题": "An Efficient Federated Distillation Learning System for Multi-task Time\n  Series Classification",
                "作者": " Huanlai Xing,  Zhiwen Xiao,  Rong Qu,  Zonghai Zhu,  Bowen Zhao",
                "发布日期": "2022-01-04",
                "摘要": "  This paper proposes an efficient federated distillation learning system\n(EFDLS) for multi-task time series classification (TSC). EFDLS consists of a\ncentral server and multiple mobile users, where different users may run\ndifferent TSC tasks. EFDLS has two novel components, namely a feature-based\nstudent-teacher (FBST) framework and a distance-based weights matching (DBWM)\nscheme. Within each user, the FBST framework transfers knowledge from its\nteacher's hidden layers to its student's hidden layers via knowledge\ndistillation, with the teacher and student having identical network structure.\nFor each connected user, its student model's hidden layers' weights are\nuploaded to the EFDLS server periodically. The DBWM scheme is deployed on the\nserver, with the least square distance used to measure the similarity between\nthe weights of two given models. This scheme finds a partner for each connected\nuser such that the user's and its partner's weights are the closest among all\nthe weights uploaded. The server exchanges and sends back the user's and its\npartner's weights to these two users which then load the received weights to\ntheir teachers' hidden layers. Experimental results show that the proposed\nEFDLS achieves excellent performance on a set of selected UCR2018 datasets\nregarding top-1 accuracy.\n",
                "链接": "https://arxiv.org/abs/2201.00011"
            },
            {
                "文章ID": "6",
                "标题": "MORAL: Aligning AI with Human Norms through Multi-Objective Reinforced\n  Active Learning",
                "作者": " Markus Peschl,  Arkady Zgonnikov,  Frans A. Oliehoek,  Luciano C. Siebert",
                "发布日期": "2022-01-04",
                "摘要": "  Inferring reward functions from demonstrations and pairwise preferences are\nauspicious approaches for aligning Reinforcement Learning (RL) agents with\nhuman intentions. However, state-of-the art methods typically focus on learning\na single reward model, thus rendering it difficult to trade off different\nreward functions from multiple experts. We propose Multi-Objective Reinforced\nActive Learning (MORAL), a novel method for combining diverse demonstrations of\nsocial norms into a Pareto-optimal policy. Through maintaining a distribution\nover scalarization weights, our approach is able to interactively tune a deep\nRL agent towards a variety of preferences, while eliminating the need for\ncomputing multiple policies. We empirically demonstrate the effectiveness of\nMORAL in two scenarios, which model a delivery and an emergency task that\nrequire an agent to act in the presence of normative conflicts. Overall, we\nconsider our research a step towards multi-objective RL with learned rewards,\nbridging the gap between current reward learning and machine ethics literature.\n",
                "链接": "https://arxiv.org/abs/2201.00012"
            },
            {
                "文章ID": "7",
                "标题": "Exploiting Bi-directional Global Transition Patterns and Personal\n  Preferences for Missing POI Category Identification",
                "作者": " Dongbo Xi,  Fuzhen Zhuang,  Yanchi Liu,  Hengshu Zhu,  Pengpeng Zhao,  Chang Tan,  Qing He",
                "发布日期": "2022-01-04",
                "摘要": "  Recent years have witnessed the increasing popularity of Location-based\nSocial Network (LBSN) services, which provides unparalleled opportunities to\nbuild personalized Point-of-Interest (POI) recommender systems. Existing POI\nrecommendation and location prediction tasks utilize past information for\nfuture recommendation or prediction from a single direction perspective, while\nthe missing POI category identification task needs to utilize the check-in\ninformation both before and after the missing category. Therefore, a\nlong-standing challenge is how to effectively identify the missing POI\ncategories at any time in the real-world check-in data of mobile users. To this\nend, in this paper, we propose a novel neural network approach to identify the\nmissing POI categories by integrating both bi-directional global non-personal\ntransition patterns and personal preferences of users. Specifically, we\ndelicately design an attention matching cell to model how well the check-in\ncategory information matches their non-personal transition patterns and\npersonal preferences. Finally, we evaluate our model on two real-world\ndatasets, which clearly validate its effectiveness compared with the\nstate-of-the-art baselines. Furthermore, our model can be naturally extended to\naddress next POI category recommendation and prediction tasks with competitive\nperformance.\n",
                "链接": "https://arxiv.org/abs/2201.00014"
            },
            {
                "文章ID": "8",
                "标题": "TransLog: A Unified Transformer-based Framework for Log Anomaly\n  Detection",
                "作者": " Hongcheng Guo,  Xingyu Lin,  Jian Yang,  Yi Zhuang,  Jiaqi Bai,  Tieqiao Zheng,  Bo Zhang,  Zhoujun Li",
                "发布日期": "2022-01-19",
                "摘要": "  Log anomaly detection is a key component in the field of artificial\nintelligence for IT operations (AIOps). Considering log data of variant\ndomains, retraining the whole network for unknown domains is inefficient in\nreal industrial scenarios especially for low-resource domains. However,\nprevious deep models merely focused on extracting the semantics of log sequence\nin the same domain, leading to poor generalization on multi-domain logs.\nTherefore, we propose a unified Transformer-based framework for log anomaly\ndetection (\\ourmethod{}), which is comprised of the pretraining and\nadapter-based tuning stage. Our model is first pretrained on the source domain\nto obtain shared semantic knowledge of log data. Then, we transfer the\npretrained model to the target domain via the adapter-based tuning. The\nproposed method is evaluated on three public datasets including one source\ndomain and two target domains. The experimental results demonstrate that our\nsimple yet efficient approach, with fewer trainable parameters and lower\ntraining costs in the target domain, achieves state-of-the-art performance on\nthree benchmarks.\n",
                "链接": "https://arxiv.org/abs/2201.00016"
            },
            {
                "文章ID": "9",
                "标题": "Stochastic convex optimization for provably efficient apprenticeship\n  learning",
                "作者": " Angeliki Kamoutsi,  Goran Banjac,  John Lygeros",
                "发布日期": "2022-01-04",
                "摘要": "  We consider large-scale Markov decision processes (MDPs) with an unknown cost\nfunction and employ stochastic convex optimization tools to address the problem\nof imitation learning, which consists of learning a policy from a finite set of\nexpert demonstrations.\n  We adopt the apprenticeship learning formalism, which carries the assumption\nthat the true cost function can be represented as a linear combination of some\nknown features. Existing inverse reinforcement learning algorithms come with\nstrong theoretical guarantees, but are computationally expensive because they\nuse reinforcement learning or planning algorithms as a subroutine. On the other\nhand, state-of-the-art policy gradient based algorithms (like IM-REINFORCE,\nIM-TRPO, and GAIL), achieve significant empirical success in challenging\nbenchmark tasks, but are not well understood in terms of theory. With an\nemphasis on non-asymptotic guarantees of performance, we propose a method that\ndirectly learns a policy from expert demonstrations, bypassing the intermediate\nstep of learning the cost function, by formulating the problem as a single\nconvex optimization problem over occupancy measures. We develop a\ncomputationally efficient algorithm and derive high confidence regret bounds on\nthe quality of the extracted policy, utilizing results from stochastic convex\noptimization and recent works in approximate linear programming for solving\nforward MDPs.\n",
                "链接": "https://arxiv.org/abs/2201.00039"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用CrossWoz或MultiWoz数据集进行DST评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "46848",
                "标题": "MultiWOZ-DF -- A Dataflow implementation of the MultiWOZ dataset",
                "作者": " Joram Meron,  Victor Guimarães",
                "发布日期": "2022-11-07",
                "摘要": "  Semantic Machines (SM) have introduced the use of the dataflow (DF) paradigm\nto dialogue modelling, using computational graphs to hierarchically represent\nuser requests, data, and the dialogue history [Semantic Machines et al. 2020].\nAlthough the main focus of that paper was the SMCalFlow dataset (to date, the\nonly dataset with \"native\" DF annotations), they also reported some results of\nan experiment using a transformed version of the commonly used MultiWOZ dataset\n[Budzianowski et al. 2018] into a DF format. In this paper, we expand the\nexperiments using DF for the MultiWOZ dataset, exploring some additional\nexperimental set-ups. The code and instructions to reproduce the experiments\nreported here have been released. The contributions of this paper are: 1.) A DF\nimplementation capable of executing MultiWOZ dialogues; 2.) Several versions of\nconversion of MultiWOZ into a DF format are presented; 3.) Experimental results\non state match and translation accuracy.\n",
                "链接": "https://arxiv.org/abs/2211.02303"
            },
            {
                "文章ID": "112862",
                "标题": "Multi-User MultiWOZ: Task-Oriented Dialogues among Multiple Users",
                "作者": " Yohan Jo,  Xinyan Zhao,  Arijit Biswas,  Nikoletta Basiou,  Vincent Auvray,  Nikolaos Malandrakis,  Angeliki Metallinou,  Alexandros Potamianos",
                "发布日期": "2023-11-01",
                "摘要": "  While most task-oriented dialogues assume conversations between the agent and\none user at a time, dialogue systems are increasingly expected to communicate\nwith multiple users simultaneously who make decisions collaboratively. To\nfacilitate development of such systems, we release the Multi-User MultiWOZ\ndataset: task-oriented dialogues among two users and one agent. To collect this\ndataset, each user utterance from MultiWOZ 2.2 was replaced with a small chat\nbetween two users that is semantically and pragmatically consistent with the\noriginal user utterance, thus resulting in the same dialogue state and system\nresponse. These dialogues reflect interesting dynamics of collaborative\ndecision-making in task-oriented scenarios, e.g., social chatter and\ndeliberation. Supported by this data, we propose the novel task of multi-user\ncontextual query rewriting: to rewrite a task-oriented chat between two users\nas a concise task-oriented query that retains only task-relevant information\nand that is directly consumable by the dialogue system. We demonstrate that in\nmulti-user dialogues, using predicted rewrites substantially improves dialogue\nstate tracking without modifying existing dialogue systems that are trained for\nsingle-user dialogues. Further, this method surpasses training a medium-sized\nmodel directly on multi-user dialogues and generalizes to unseen domains.\n",
                "链接": "https://arxiv.org/abs/2310.20479"
            },
            {
                "文章ID": "43163",
                "标题": "Mars: Modeling Context & State Representations with Contrastive Learning\n  for End-to-End Task-Oriented Dialog",
                "作者": " Haipeng Sun,  Junwei Bao,  Youzheng Wu,  Xiaodong He",
                "发布日期": "2023-07-11",
                "摘要": "  Traditional end-to-end task-oriented dialog systems first convert dialog\ncontext into belief state and action state before generating the system\nresponse. The system response performance is significantly affected by the\nquality of the belief state and action state. We first explore what dialog\ncontext representation is beneficial to improving the quality of the belief\nstate and action state, which further enhances the generated response quality.\nTo tackle our exploration, we propose Mars, an end-to-end task-oriented dialog\nsystem with two contrastive learning strategies to model the relationship\nbetween dialog context and belief/action state representations. Empirical\nresults show dialog context representations, which are more different from\nsemantic state representations, are more conducive to multi-turn task-oriented\ndialog. Moreover, our proposed Mars achieves state-of-the-art performance on\nthe MultiWOZ 2.0, CamRest676, and CrossWOZ.\n",
                "链接": "https://arxiv.org/abs/2210.08917"
            },
            {
                "文章ID": "45137",
                "标题": "Is MultiWOZ a Solved Task? An Interactive TOD Evaluation Framework with\n  User Simulator",
                "作者": " Qinyuan Cheng,  Linyang Li,  Guofeng Quan,  Feng Gao,  Xiaofeng Mou,  Xipeng Qiu",
                "发布日期": "2022-10-27",
                "摘要": "  Task-Oriented Dialogue (TOD) systems are drawing more and more attention in\nrecent studies. Current methods focus on constructing pre-trained models or\nfine-tuning strategies while the evaluation of TOD is limited by a policy\nmismatch problem. That is, during evaluation, the user utterances are from the\nannotated dataset while these utterances should interact with previous\nresponses which can have many alternatives besides annotated texts. Therefore,\nin this work, we propose an interactive evaluation framework for TOD. We first\nbuild a goal-oriented user simulator based on pre-trained models and then use\nthe user simulator to interact with the dialogue system to generate dialogues.\nBesides, we introduce a sentence-level and a session-level score to measure the\nsentence fluency and session coherence in the interactive evaluation.\nExperimental results show that RL-based TOD systems trained by our proposed\nuser simulator can achieve nearly 98% inform and success rates in the\ninteractive evaluation of MultiWOZ dataset and the proposed scores measure the\nresponse quality besides the inform and success rates. We are hoping that our\nwork will encourage simulator-based interactive evaluations in the TOD task.\n",
                "链接": "https://arxiv.org/abs/2210.14529"
            },
            {
                "文章ID": "7222",
                "标题": "ASSIST: Towards Label Noise-Robust Dialogue State Tracking",
                "作者": " Fanghua Ye,  Yue Feng,  Emine Yilmaz",
                "发布日期": "2022-03-15",
                "摘要": "  The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state\ntracking (DST). However, substantial noise has been discovered in its state\nannotations. Such noise brings about huge challenges for training DST models\nrobustly. Although several refined versions, including MultiWOZ 2.1-2.4, have\nbeen published recently, there are still lots of noisy labels, especially in\nthe training set. Besides, it is costly to rectify all the problematic\nannotations. In this paper, instead of improving the annotation quality\nfurther, we propose a general framework, named ASSIST (lAbel noiSe-robuSt\ndIalogue State Tracking), to train DST models robustly from noisy labels.\nASSIST first generates pseudo labels for each sample in the training set by\nusing an auxiliary model trained on a small clean dataset, then puts the\ngenerated pseudo labels and vanilla noisy labels together to train the primary\nmodel. We show the validity of ASSIST theoretically. Experimental results also\ndemonstrate that ASSIST improves the joint goal accuracy of DST by up to\n$28.16\\%$ on MultiWOZ 2.0 and $8.41\\%$ on MultiWOZ 2.4, compared to using only\nthe vanilla noisy labels.\n",
                "链接": "https://arxiv.org/abs/2202.13024"
            },
            {
                "文章ID": "17975",
                "标题": "LUNA: Learning Slot-Turn Alignment for Dialogue State Tracking",
                "作者": " Yifan Wang,  Jing Zhao,  Junwei Bao,  Chaoqun Duan,  Youzheng Wu,  Xiaodong He",
                "发布日期": "2022-05-06",
                "摘要": "  Dialogue state tracking (DST) aims to predict the current dialogue state\ngiven the dialogue history. Existing methods generally exploit the utterances\nof all dialogue turns to assign value for each slot. This could lead to\nsuboptimal results due to the information introduced from irrelevant utterances\nin the dialogue history, which may be useless and can even cause confusion. To\naddress this problem, we propose LUNA, a sLot-tUrN Alignment enhanced approach.\nIt first explicitly aligns each slot with its most relevant utterance, then\nfurther predicts the corresponding value based on this aligned utterance\ninstead of all dialogue utterances. Furthermore, we design a slot ranking\nauxiliary task to learn the temporal correlation among slots which could\nfacilitate the alignment. Comprehensive experiments are conducted on\nmulti-domain task-oriented dialogue datasets, i.e., MultiWOZ 2.0, MultiWOZ 2.1,\nand MultiWOZ 2.2. The results show that LUNA achieves new state-of-the-art\nresults on these datasets.\n",
                "链接": "https://arxiv.org/abs/2205.02550"
            },
            {
                "文章ID": "79647",
                "标题": "Using Textual Interface to Align External Knowledge for End-to-End\n  Task-Oriented Dialogue Systems",
                "作者": " Qingyang Wu,  Deema Alnuhait,  Derek Chen,  Zhou Yu",
                "发布日期": "2023-05-24",
                "摘要": "  Traditional end-to-end task-oriented dialogue systems have been built with a\nmodularized design. However, such design often causes misalignment between the\nagent response and external knowledge, due to inadequate representation of\ninformation. Furthermore, its evaluation metrics emphasize assessing the\nagent's pre-lexicalization response, neglecting the quality of the completed\nresponse. In this work, we propose a novel paradigm that uses a textual\ninterface to align external knowledge and eliminate redundant processes. We\ndemonstrate our paradigm in practice through MultiWOZ-Remake, including an\ninteractive textual interface built for the MultiWOZ database and a\ncorrespondingly re-processed dataset. We train an end-to-end dialogue system to\nevaluate this new dataset. The experimental results show that our approach\ngenerates more natural final responses and achieves a greater task success rate\ncompared to the previous models.\n",
                "链接": "https://arxiv.org/abs/2305.13710"
            },
            {
                "文章ID": "68448",
                "标题": "Reevaluating Data Partitioning for Emotion Detection in EmoWOZ",
                "作者": " Moeen Mostafavi,  Michael D. Porter",
                "发布日期": "2023-03-24",
                "摘要": "  This paper focuses on the EmoWoz dataset, an extension of MultiWOZ that\nprovides emotion labels for the dialogues. MultiWOZ was partitioned initially\nfor another purpose, resulting in a distributional shift when considering the\nnew purpose of emotion recognition. The emotion tags in EmoWoz are highly\nimbalanced and unevenly distributed across the partitions, which causes\nsub-optimal performance and poor comparison of models. We propose a stratified\nsampling scheme based on emotion tags to address this issue, improve the\ndataset's distribution, and reduce dataset shift. We also introduce a special\ntechnique to handle conversation (sequential) data with many emotional tags.\nUsing our proposed sampling method, models built upon EmoWoz can perform\nbetter, making it a more reliable resource for training conversational agents\nwith emotional intelligence. We recommend that future researchers use this new\npartitioning to ensure consistent and accurate performance evaluations.\n",
                "链接": "https://arxiv.org/abs/2303.13364"
            },
            {
                "文章ID": "61900",
                "标题": "Dialogue State Distillation Network with Inter-slot Contrastive Learning\n  for Dialogue State Tracking",
                "作者": " Jing Xu,  Dandan Song,  Chong Liu,  Siu Cheung Hui,  Fei Li,  Qiang Ju,  Xiaonan He,  Jian Xie",
                "发布日期": "2023-03-08",
                "摘要": "  In task-oriented dialogue systems, Dialogue State Tracking (DST) aims to\nextract users' intentions from the dialogue history. Currently, most existing\napproaches suffer from error propagation and are unable to dynamically select\nrelevant information when utilizing previous dialogue states. Moreover, the\nrelations between the updates of different slots provide vital clues for DST.\nHowever, the existing approaches rely only on predefined graphs to indirectly\ncapture the relations. In this paper, we propose a Dialogue State Distillation\nNetwork (DSDN) to utilize relevant information of previous dialogue states and\nmigrate the gap of utilization between training and testing. Thus, it can\ndynamically exploit previous dialogue states and avoid introducing error\npropagation simultaneously. Further, we propose an inter-slot contrastive\nlearning loss to effectively capture the slot co-update relations from dialogue\ncontext. Experiments are conducted on the widely used MultiWOZ 2.0 and MultiWOZ\n2.1 datasets. The experimental results show that our proposed model achieves\nthe state-of-the-art performance for DST.\n",
                "链接": "https://arxiv.org/abs/2302.08220"
            },
            {
                "文章ID": "94649",
                "标题": "Dataflow Dialogue Generation",
                "作者": " Joram Meron,  Victor Guimarães",
                "发布日期": "2023-08-07",
                "摘要": "  We demonstrate task-oriented dialogue generation within the dataflow dialogue\nparadigm. We show an example of agenda driven dialogue generation for the\nMultiWOZ domain, and an example of generation without an agenda for the\nSMCalFlow domain, where we show an improvement in the accuracy of the\ntranslation of user requests to dataflow expressions when the generated\ndialogues are used to augment the translation training dataset.\n",
                "链接": "https://arxiv.org/abs/2308.02323"
            }
        ]
    },
    {
        "question": {
            "question": "2023年后利用hotpotqa数据集做问题生成任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "106859",
                "标题": "Human Mobility Question Answering (Vision Paper)",
                "作者": " Hao Xue,  Flora D. Salim",
                "发布日期": "2023-10-16",
                "摘要": "  Question answering (QA) systems have attracted much attention from the\nartificial intelligence community as they can learn to answer questions based\non the given knowledge source (e.g., images in visual question answering).\nHowever, the research into question answering systems with human mobility data\nremains unexplored. Mining human mobility data is crucial for various\napplications such as smart city planning, pandemic management, and personalised\nrecommendation system. In this paper, we aim to tackle this gap and introduce a\nnovel task, that is, human mobility question answering (MobQA). The aim of the\ntask is to let the intelligent system learn from mobility data and answer\nrelated questions. This task presents a new paradigm change in mobility\nprediction research and further facilitates the research of human mobility\nrecommendation systems. To better support this novel research topic, this\nvision paper also proposes an initial design of the dataset and a potential\ndeep learning model framework for the introduced MobQA task. We hope that this\npaper will provide novel insights and open new directions in human mobility\nresearch and question answering research.\n",
                "链接": "https://arxiv.org/abs/2310.04443"
            },
            {
                "文章ID": "10231",
                "标题": "Ask to Understand: Question Generation for Multi-hop Question Answering",
                "作者": " Jiawei Li,  Mucheng Ren,  Yang Gao,  Yizhe Yang",
                "发布日期": "2022-03-18",
                "摘要": "  Multi-hop Question Answering (QA) requires the machine to answer complex\nquestions by finding scattering clues and reasoning from multiple documents.\nGraph Network (GN) and Question Decomposition (QD) are two common approaches at\npresent. The former uses the \"black-box\" reasoning process to capture the\npotential relationship between entities and sentences, thus achieving good\nperformance. At the same time, the latter provides a clear reasoning logical\nroute by decomposing multi-hop questions into simple single-hop sub-questions.\nIn this paper, we propose a novel method to complete multi-hop QA from the\nperspective of Question Generation (QG). Specifically, we carefully design an\nend-to-end QG module on the basis of a classical QA module, which could help\nthe model understand the context by asking inherently logical sub-questions,\nthus inheriting interpretability from the QD-based method and showing superior\nperformance. Experiments on the HotpotQA dataset demonstrate that the\neffectiveness of our proposed QG module, human evaluation further clarifies its\ninterpretability quantitatively, and thorough analysis shows that the QG module\ncould generate better sub-questions than QD methods in terms of fluency,\nconsistency, and diversity.\n",
                "链接": "https://arxiv.org/abs/2203.09073"
            },
            {
                "文章ID": "5376",
                "标题": "QA4QG: Using Question Answering to Constrain Multi-Hop Question\n  Generation",
                "作者": " Dan Su,  Peng Xu,  Pascale Fung",
                "发布日期": "2022-02-15",
                "摘要": "  Multi-hop question generation (MQG) aims to generate complex questions which\nrequire reasoning over multiple pieces of information of the input passage.\nMost existing work on MQG has focused on exploring graph-based networks to\nequip the traditional Sequence-to-sequence framework with reasoning ability.\nHowever, these models do not take full advantage of the constraint between\nquestions and answers. Furthermore, studies on multi-hop question answering\n(QA) suggest that Transformers can replace the graph structure for multi-hop\nreasoning. Therefore, in this work, we propose a novel framework, QA4QG, a\nQA-augmented BART-based framework for MQG. It augments the standard BART model\nwith an additional multi-hop QA module to further constrain the generated\nquestion. Our results on the HotpotQA dataset show that QA4QG outperforms all\nstate-of-the-art models, with an increase of 8 BLEU-4 and 8 ROUGE points\ncompared to the best results previously reported. Our work suggests the\nadvantage of introducing pre-trained language models and QA module for the MQG\ntask.\n",
                "链接": "https://arxiv.org/abs/2202.06538"
            },
            {
                "文章ID": "64359",
                "标题": "Reinforcement Learning Guided Multi-Objective Exam Paper Generation",
                "作者": " Yuhu Shang,  Xuexiong Luo,  Lihong Wang,  Hao Peng,  Xiankun Zhang,  Yimeng Ren,  Kun Liang",
                "发布日期": "2023-03-03",
                "摘要": "  To reduce the repetitive and complex work of instructors, exam paper\ngeneration (EPG) technique has become a salient topic in the intelligent\neducation field, which targets at generating high-quality exam paper\nautomatically according to instructor-specified assessment criteria. The\ncurrent advances utilize the ability of heuristic algorithms to optimize\nseveral well-known objective constraints, such as difficulty degree, number of\nquestions, etc., for producing optimal solutions. However, in real scenarios,\nconsidering other equally relevant objectives (e.g., distribution of exam\nscores, skill coverage) is extremely important. Besides, how to develop an\nautomatic multi-objective solution that finds an optimal subset of questions\nfrom a huge search space of large-sized question datasets and thus composes a\nhigh-quality exam paper is urgent but non-trivial. To this end, we skillfully\ndesign a reinforcement learning guided Multi-Objective Exam Paper Generation\nframework, termed MOEPG, to simultaneously optimize three exam domain-specific\nobjectives including difficulty degree, distribution of exam scores, and skill\ncoverage. Specifically, to accurately measure the skill proficiency of the\nexaminee group, we first employ deep knowledge tracing to model the interaction\ninformation between examinees and response logs. We then design the flexible\nExam Q-Network, a function approximator, which automatically selects the\nappropriate question to update the exam paper composition process. Later, MOEPG\ndivides the decision space into multiple subspaces to better guide the updated\ndirection of the exam paper. Through extensive experiments on two real-world\ndatasets, we demonstrate that MOEPG is feasible in addressing the multiple\ndilemmas of exam paper generation scenario.\n",
                "链接": "https://arxiv.org/abs/2303.01042"
            },
            {
                "文章ID": "50328",
                "标题": "Question Answering and Question Generation for Finnish",
                "作者": " Ilmari Kylliäinen,  Roman Yangarber",
                "发布日期": "2022-11-28",
                "摘要": "  Recent advances in the field of language modeling have improved the\nstate-of-the-art in question answering (QA) and question generation (QG).\nHowever, the development of modern neural models, their benchmarks, and\ndatasets for training them has mainly focused on English. Finnish, like many\nother languages, faces a shortage of large QA/QG model training resources,\nwhich has prevented experimenting with state-of-the-art QA/QG fine-tuning\nmethods. We present the first neural QA and QG models that work with Finnish.\nTo train the models, we automatically translate the SQuAD dataset and then use\nnormalization methods to reduce the amount of problematic data created during\nthe translation. Using the synthetic data, together with the Finnish partition\nof the TyDi-QA dataset, we fine-tune several transformer-based models to both\nQA and QG and evaluate their performance. To the best of our knowledge, the\nresulting dataset is the first large-scale QA/QG resource for Finnish. This\npaper also sets the initial benchmarks for Finnish-language QA and QG.\n",
                "链接": "https://arxiv.org/abs/2211.13794"
            },
            {
                "文章ID": "91898",
                "标题": "Rob\\^oCIn Small Size League Extended Team Description Paper for RoboCup\n  2023",
                "作者": " Aline Lima de Oliveira,  Cauê Addae da Silva Gomes,  Cecília Virginia Santos da Silva,  Charles Matheus de Sousa Alves,  Danilo Andrade Martins de Souza,  Driele Pires Ferreira Araújo Xavier,  Edgleyson Pereira da Silva,  Felipe Bezerra Martins,  Lucas Henrique Cavalcanti Santos,  Lucas Dias Maciel,  Matheus Paixão Gumercindo dos Santos,  Matheus Lafayette Vasconcelos,  Matheus Vinícius Teotonio do Nascimento Andrade,  João Guilherme Oliveira Carvalho de Melo,  João Pedro Souza Pereira de Moura,  José Ronald da Silva,  José Victor Silva Cruz,  Pedro Henrique Santana de Morais,  Pedro Paulo Salman de Oliveira,  Riei Joaquim Matos Rodrigues,  Roberto Costa Fernandes,  Ryan Vinicius Santos Morais,  Tamara Mayara Ramos Teobaldo,  Washington Igor dos Santos Silva,  Edna Natividade Silva Barros",
                "发布日期": "2023-07-20",
                "摘要": "  Rob\\^oCIn has participated in RoboCup Small Size League since 2019, won its\nfirst world title in 2022 (Division B), and is currently a three-times\nLatin-American champion. This paper presents our improvements to defend the\nSmall Size League (SSL) division B title in RoboCup 2023 in Bordeaux, France.\nThis paper aims to share some of the academic research that our team developed\nover the past year. Our team has successfully published 2 articles related to\nSSL at two high-impact conferences: the 25th RoboCup International Symposium\nand the 19th IEEE Latin American Robotics Symposium (LARS 2022). Over the last\nyear, we have been continuously migrating from our past codebase to\nUnification. We will describe the new architecture implemented and some points\nof software and AI refactoring. In addition, we discuss the process of\nintegrating machined components into the mechanical system, our development for\nparticipating in the vision blackout challenge last year and what we are\npreparing for this year.\n",
                "链接": "https://arxiv.org/abs/2307.10018"
            },
            {
                "文章ID": "25087",
                "标题": "Interpretable AMR-Based Question Decomposition for Multi-hop Question\n  Answering",
                "作者": " Zhenyun Deng,  Yonghua Zhu,  Yang Chen,  Michael Witbrock,  Patricia Riddle",
                "发布日期": "2022-08-29",
                "摘要": "  Effective multi-hop question answering (QA) requires reasoning over multiple\nscattered paragraphs and providing explanations for answers. Most existing\napproaches cannot provide an interpretable reasoning process to illustrate how\nthese models arrive at an answer. In this paper, we propose a Question\nDecomposition method based on Abstract Meaning Representation (QDAMR) for\nmulti-hop QA, which achieves interpretable reasoning by decomposing a multi-hop\nquestion into simpler sub-questions and answering them in order. Since\nannotating the decomposition is expensive, we first delegate the complexity of\nunderstanding the multi-hop question to an AMR parser. We then achieve the\ndecomposition of a multi-hop question via segmentation of the corresponding AMR\ngraph based on the required reasoning type. Finally, we generate sub-questions\nusing an AMR-to-Text generation model and answer them with an off-the-shelf QA\nmodel. Experimental results on HotpotQA demonstrate that our approach is\ncompetitive for interpretable reasoning and that the sub-questions generated by\nQDAMR are well-formed, outperforming existing question-decomposition-based\nmulti-hop QA approaches.\n",
                "链接": "https://arxiv.org/abs/2206.08486"
            },
            {
                "文章ID": "104456",
                "标题": "Automating question generation from educational text",
                "作者": " Ayan Kumar Bhowmick,  Ashish Jagmohan,  Aditya Vempaty,  Prasenjit Dey,  Leigh Hall,  Jeremy Hartman,  Ravi Kokku,  Hema Maheshwari",
                "发布日期": "2023-09-27",
                "摘要": "  The use of question-based activities (QBAs) is wide-spread in education,\ntraditionally forming an integral part of the learning and assessment process.\nIn this paper, we design and evaluate an automated question generation tool for\nformative and summative assessment in schools. We present an expert survey of\none hundred and four teachers, demonstrating the need for automated generation\nof QBAs, as a tool that can significantly reduce the workload of teachers and\nfacilitate personalized learning experiences. Leveraging the recent\nadvancements in generative AI, we then present a modular framework employing\ntransformer based language models for automatic generation of multiple-choice\nquestions (MCQs) from textual content. The presented solution, with distinct\nmodules for question generation, correct answer prediction, and distractor\nformulation, enables us to evaluate different language models and generation\ntechniques. Finally, we perform an extensive quantitative and qualitative\nevaluation, demonstrating trade-offs in the use of different techniques and\nmodels.\n",
                "链接": "https://arxiv.org/abs/2309.15004"
            },
            {
                "文章ID": "44372",
                "标题": "Varifocal Question Generation for Fact-checking",
                "作者": " Nedjma Ousidhoum,  Zhangdie Yuan,  Andreas Vlachos",
                "发布日期": "2022-10-25",
                "摘要": "  Fact-checking requires retrieving evidence related to a claim under\ninvestigation. The task can be formulated as question generation based on a\nclaim, followed by question answering. However, recent question generation\napproaches assume that the answer is known and typically contained in a passage\ngiven as input, whereas such passages are what is being sought when verifying a\nclaim. In this paper, we present {\\it Varifocal}, a method that generates\nquestions based on different focal points within a given claim, i.e.\\ different\nspans of the claim and its metadata, such as its source and date. Our method\noutperforms previous work on a fact-checking question generation dataset on a\nwide range of automatic evaluation metrics. These results are corroborated by\nour manual evaluation, which indicates that our method generates more relevant\nand informative questions. We further demonstrate the potential of focal points\nin generating sets of clarification questions for product descriptions.\n",
                "链接": "https://arxiv.org/abs/2210.12400"
            },
            {
                "文章ID": "85926",
                "标题": "Improving Reading Comprehension Question Generation with Data\n  Augmentation and Overgenerate-and-rank",
                "作者": " Nischal Ashok Kumar,  Nigel Fernandez,  Zichao Wang,  Andrew Lan",
                "发布日期": "2023-06-16",
                "摘要": "  Reading comprehension is a crucial skill in many aspects of education,\nincluding language learning, cognitive development, and fostering early\nliteracy skills in children. Automated answer-aware reading comprehension\nquestion generation has significant potential to scale up learner support in\neducational activities. One key technical challenge in this setting is that\nthere can be multiple questions, sometimes very different from each other, with\nthe same answer; a trained question generation method may not necessarily know\nwhich question human educators would prefer. To address this challenge, we\npropose 1) a data augmentation method that enriches the training dataset with\ndiverse questions given the same context and answer and 2) an\novergenerate-and-rank method to select the best question from a pool of\ncandidates. We evaluate our method on the FairytaleQA dataset, showing a 5%\nabsolute improvement in ROUGE-L over the best existing method. We also\ndemonstrate the effectiveness of our method in generating harder, \"implicit\"\nquestions, where the answers are not contained in the context as text spans.\n",
                "链接": "https://arxiv.org/abs/2306.08847"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用机器学习方法进行心理健康疾病研究的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "98633",
                "标题": "Discovering Mental Health Research Topics with Topic Modeling",
                "作者": " Xin Gao,  Cem Sazara",
                "发布日期": "2023-08-29",
                "摘要": "  Mental health significantly influences various aspects of our daily lives,\nand its importance has been increasingly recognized by the research community\nand the general public, particularly in the wake of the COVID-19 pandemic. This\nheightened interest is evident in the growing number of publications dedicated\nto mental health in the past decade. In this study, our goal is to identify\ngeneral trends in the field and pinpoint high-impact research topics by\nanalyzing a large dataset of mental health research papers. To accomplish this,\nwe collected abstracts from various databases and trained a customized\nSentence-BERT based embedding model leveraging the BERTopic framework. Our\ndataset comprises 96,676 research papers pertaining to mental health, enabling\nus to examine the relationships between different topics using their abstracts.\nTo evaluate the effectiveness of the model, we compared it against two other\nstate-of-the-art methods: Top2Vec model and LDA-BERT model. The model\ndemonstrated superior performance in metrics that measure topic diversity and\ncoherence. To enhance our analysis, we also generated word clouds to provide a\ncomprehensive overview of the machine learning models applied in mental health\nresearch, shedding light on commonly utilized techniques and emerging trends.\nFurthermore, we provide a GitHub link* to the dataset used in this paper,\nensuring its accessibility for further research endeavors.\n",
                "链接": "https://arxiv.org/abs/2308.13569"
            },
            {
                "文章ID": "104767",
                "标题": "Identifying Risk Factors for Post-COVID-19 Mental Health Disorders: A\n  Machine Learning Perspective",
                "作者": " Maitham G. Yousif,  Fadhil G. Al-Amran,  Hector J. Castro",
                "发布日期": "2023-09-29",
                "摘要": "  In this study, we leveraged machine learning techniques to identify risk\nfactors associated with post-COVID-19 mental health disorders. Our analysis,\nbased on data collected from 669 patients across various provinces in Iraq,\nyielded valuable insights. We found that age, gender, and geographical region\nof residence were significant demographic factors influencing the likelihood of\ndeveloping mental health disorders in post-COVID-19 patients. Additionally,\ncomorbidities and the severity of COVID-19 illness were important clinical\npredictors. Psychosocial factors, such as social support, coping strategies,\nand perceived stress levels, also played a substantial role. Our findings\nemphasize the complex interplay of multiple factors in the development of\nmental health disorders following COVID-19 recovery. Healthcare providers and\npolicymakers should consider these risk factors when designing targeted\ninterventions and support systems for individuals at risk. Machine\nlearning-based approaches can provide a valuable tool for predicting and\npreventing adverse mental health outcomes in post-COVID-19 patients. Further\nresearch and prospective studies are needed to validate these findings and\nenhance our understanding of the long-term psychological impact of the COVID-19\npandemic. This study contributes to the growing body of knowledge regarding the\nmental health consequences of the COVID-19 pandemic and underscores the\nimportance of a multidisciplinary approach to address the diverse needs of\nindividuals on the path to recovery. Keywords: COVID-19, mental health, risk\nfactors, machine learning, Iraq\n",
                "链接": "https://arxiv.org/abs/2309.16055"
            },
            {
                "文章ID": "32474",
                "标题": "Bias Reducing Multitask Learning on Mental Health Prediction",
                "作者": " Khadija Zanna,  Kusha Sridhar,  Han Yu,  Akane Sano",
                "发布日期": "2022-08-09",
                "摘要": "  There has been an increase in research in developing machine learning models\nfor mental health detection or prediction in recent years due to increased\nmental health issues in society. Effective use of mental health prediction or\ndetection models can help mental health practitioners re-define mental\nillnesses more objectively than currently done, and identify illnesses at an\nearlier stage when interventions may be more effective. However, there is still\na lack of standard in evaluating bias in such machine learning models in the\nfield, which leads to challenges in providing reliable predictions and in\naddressing disparities. This lack of standards persists due to factors such as\ntechnical difficulties, complexities of high dimensional clinical health data,\netc., which are especially true for physiological signals. This along with\nprior evidence of relations between some physiological signals with certain\ndemographic identities restates the importance of exploring bias in mental\nhealth prediction models that utilize physiological signals. In this work, we\naim to perform a fairness analysis and implement a multi-task learning based\nbias mitigation method on anxiety prediction models using ECG data. Our method\nis based on the idea of epistemic uncertainty and its relationship with model\nweights and feature space representation. Our analysis showed that our anxiety\nprediction base model introduced some bias with regards to age, income,\nethnicity, and whether a participant is born in the U.S. or not, and our bias\nmitigation method performed better at reducing the bias in the model, when\ncompared to the reweighting mitigation technique. Our analysis on feature\nimportance also helped identify relationships between heart rate variability\nand multiple demographic groupings.\n",
                "链接": "https://arxiv.org/abs/2208.03621"
            },
            {
                "文章ID": "115954",
                "标题": "PsyEval: A Comprehensive Large Language Model Evaluation Benchmark for\n  Mental Health",
                "作者": " Haoan Jin,  Siyuan Chen,  Mengyue Wu,  Kenny Q. Zhu",
                "发布日期": "2023-11-16",
                "摘要": "  Recently, there has been a growing interest in utilizing large language\nmodels (LLMs) in mental health research, with studies showcasing their\nremarkable capabilities, such as disease detection. However, there is currently\na lack of a comprehensive benchmark for evaluating the capability of LLMs in\nthis domain. Therefore, we address this gap by introducing the first\ncomprehensive benchmark tailored to the unique characteristics of the mental\nhealth domain. This benchmark encompasses a total of six sub-tasks, covering\nthree dimensions, to systematically assess the capabilities of LLMs in the\nrealm of mental health. We have designed corresponding concise prompts for each\nsub-task. And we comprehensively evaluate a total of eight advanced LLMs using\nour benchmark. Experiment results not only demonstrate significant room for\nimprovement in current LLMs concerning mental health but also unveil potential\ndirections for future model optimization.\n",
                "链接": "https://arxiv.org/abs/2311.09189"
            },
            {
                "文章ID": "22134",
                "标题": "Individual health-disease phase diagrams for disease prevention based on\n  machine learning",
                "作者": " Kazuki Nakamura,  Eiichiro Uchino,  Noriaki Sato,  Ayano Araki,  Kei Terayama,  Ryosuke Kojima,  Koichi Murashita,  Ken Itoh,  Tatsuya Mikami,  Yoshinori Tamada,  Yasushi Okuno",
                "发布日期": "2022-07-08",
                "摘要": "  Early disease detection and prevention methods based on effective\ninterventions are gaining attention. Machine learning technology has enabled\nprecise disease prediction by capturing individual differences in multivariate\ndata. Progress in precision medicine has revealed that substantial\nheterogeneity exists in health data at the individual level and that complex\nhealth factors are involved in the development of chronic diseases. However, it\nremains a challenge to identify individual physiological state changes in\ncross-disease onset processes because of the complex relationships among\nmultiple biomarkers. Here, we present the health-disease phase diagram (HDPD),\nwhich represents a personal health state by visualizing the boundary values of\nmultiple biomarkers that fluctuate early in the disease progression process. In\nHDPDs, future onset predictions are represented by perturbing multiple\nbiomarker values while accounting for dependencies among variables. We\nconstructed HDPDs for 11 non-communicable diseases (NCDs) from a longitudinal\nhealth checkup cohort of 3,238 individuals, comprising 3,215 measurement items\nand genetic data. Improvement of biomarker values to the non-onset region in\nHDPD significantly prevented future disease onset in 7 out of 11 NCDs. Our\nresults demonstrate that HDPDs can represent individual physiological states in\nthe onset process and be used as intervention goals for disease prevention.\n",
                "链接": "https://arxiv.org/abs/2205.15598"
            },
            {
                "文章ID": "92064",
                "标题": "Technology in Association With Mental Health: Meta-ethnography",
                "作者": " Hamza Mohammed",
                "发布日期": "2023-07-28",
                "摘要": "  This research paper presents a meta-analysis of the multifaceted role of\ntechnology in mental health. The pervasive influence of technology on daily\nlives necessitates a deep understanding of its impact on mental health\nservices. This study synthesizes literature covering Behavioral Intervention\nTechnologies (BITs), digital mental health interventions during COVID-19, young\nmen's attitudes toward mental health technologies, technology-based\ninterventions for university students, and the applicability of mobile health\ntechnologies for individuals with serious mental illnesses. BITs are recognized\nfor their potential to provide evidence-based interventions for mental health\nconditions, especially anxiety disorders. The COVID-19 pandemic acted as a\ncatalyst for the adoption of digital mental health services, underscoring their\ncrucial role in providing accessible and quality care; however, their efficacy\nneeds to be reinforced by workforce training, high-quality evidence, and\ndigital equity. A nuanced understanding of young men's attitudes toward mental\nhealth is imperative for devising effective online services. Technology-based\ninterventions for university students are promising, although variable in\neffectiveness; their deployment must be evidence-based and tailored to\nindividual needs. Mobile health technologies, particularly activity tracking,\nhold promise for individuals with serious mental illnesses. Collectively,\ntechnology has immense potential to revolutionize mental health care. However,\nthe implementation must be evidence-based, ethical, and equitable, with\ncontinued research focusing on experiences across diverse populations, ensuring\naccessibility and efficacy for all.\n",
                "链接": "https://arxiv.org/abs/2307.10513"
            },
            {
                "文章ID": "78820",
                "标题": "Amity -- A Hybrid Mental Health Application",
                "作者": " Srija Santhanam,  Kavipriya P,  Balamurugan MS,  Manoj Kumar Rajagopal",
                "发布日期": "2023-05-23",
                "摘要": "  Wellness in trivial terms combines physical, social, and mental wellbeing.\nWhile mental health is neglected, long-term success in a person life is mostly\ndetermined by his psychological health and contentment. For a person in\ndistress, professional mental health services are quite expensive, unpopular,\nand invite a lot of hesitation. Hence, it would be effective to use an Android\napplication that can offer day to day therapeutic assistance, meditation\nsessions, and guidance since it can cater to a massive community instantly. In\nthis paper, we propose a mobile and web application AMITY with a chat group and\nchatbot created using a machine learning approach. We have also built a dataset\nto train the chatbot model that we propose in this paper. We briefly introduce\nthe dataset and the machine learning model in section 3. In section 4, we\ninclude the architecture and the development details of the Hybrid application.\nNext, we present our results on usability and the efficiency of the idea we\npropose.\n",
                "链接": "https://arxiv.org/abs/2305.11871"
            },
            {
                "文章ID": "45343",
                "标题": "Gendered Mental Health Stigma in Masked Language Models",
                "作者": " Inna Wanyin Lin,  Lucille Njoo,  Anjalie Field,  Ashish Sharma,  Katharina Reinecke,  Tim Althoff,  Yulia Tsvetkov",
                "发布日期": "2023-04-13",
                "摘要": "  Mental health stigma prevents many individuals from receiving the appropriate\ncare, and social psychology studies have shown that mental health tends to be\noverlooked in men. In this work, we investigate gendered mental health stigma\nin masked language models. In doing so, we operationalize mental health stigma\nby developing a framework grounded in psychology research: we use clinical\npsychology literature to curate prompts, then evaluate the models' propensity\nto generate gendered words. We find that masked language models capture\nsocietal stigma about gender in mental health: models are consistently more\nlikely to predict female subjects than male in sentences about having a mental\nhealth condition (32% vs. 19%), and this disparity is exacerbated for sentences\nthat indicate treatment-seeking behavior. Furthermore, we find that different\nmodels capture dimensions of stigma differently for men and women, associating\nstereotypes like anger, blame, and pity more with women with mental health\nconditions than with men. In showing the complex nuances of models' gendered\nmental health stigma, we demonstrate that context and overlapping dimensions of\nidentity are important considerations when assessing computational models'\nsocial biases.\n",
                "链接": "https://arxiv.org/abs/2210.15144"
            },
            {
                "文章ID": "109748",
                "标题": "Automatic prediction of mortality in patients with mental illness using\n  electronic health records",
                "作者": " Sean Kim,  Samuel Kim",
                "发布日期": "2023-10-19",
                "摘要": "  Mental disorders impact the lives of millions of people globally, not only\nimpeding their day-to-day lives but also markedly reducing life expectancy.\nThis paper addresses the persistent challenge of predicting mortality in\npatients with mental diagnoses using predictive machine-learning models with\nelectronic health records (EHR). Data from patients with mental disease\ndiagnoses were extracted from the well-known clinical MIMIC-III data set\nutilizing demographic, prescription, and procedural information. Four machine\nlearning algorithms (Logistic Regression, Random Forest, Support Vector\nMachine, and K-Nearest Neighbors) were used, with results indicating that\nRandom Forest and Support Vector Machine models outperformed others, with AUC\nscores of 0.911. Feature importance analysis revealed that drug prescriptions,\nparticularly Morphine Sulfate, play a pivotal role in prediction. We applied a\nvariety of machine learning algorithms to predict 30-day mortality followed by\nfeature importance analysis. This study can be used to assist hospital workers\nin identifying at-risk patients to reduce excess mortality.\n",
                "链接": "https://arxiv.org/abs/2310.12121"
            },
            {
                "文章ID": "20900",
                "标题": "Bias Discovery in Machine Learning Models for Mental Health",
                "作者": " Pablo Mosteiro,  Jesse Kuiper,  Judith Masthoff,  Floortje Scheepers,  Marco Spruit",
                "发布日期": "2022-05-25",
                "摘要": "  Fairness and bias are crucial concepts in artificial intelligence, yet they\nare relatively ignored in machine learning applications in clinical psychiatry.\nWe computed fairness metrics and present bias mitigation strategies using a\nmodel trained on clinical mental health data. We collected structured data\nrelated to the admission, diagnosis, and treatment of patients in the\npsychiatry department of the University Medical Center Utrecht. We trained a\nmachine learning model to predict future administrations of benzodiazepines on\nthe basis of past data. We found that gender plays an unexpected role in the\npredictions-this constitutes bias. Using the AI Fairness 360 package, we\nimplemented reweighing and discrimination-aware regularization as bias\nmitigation strategies, and we explored their implications for model\nperformance. This is the first application of bias exploration and mitigation\nin a machine learning model trained on real clinical psychiatry data.\n",
                "链接": "https://arxiv.org/abs/2205.12093"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "69437",
                "标题": "Medical Image Analysis using Deep Relational Learning",
                "作者": " Zhihua Liu",
                "发布日期": "2023-03-29",
                "摘要": "  In the past ten years, with the help of deep learning, especially the rapid\ndevelopment of deep neural networks, medical image analysis has made remarkable\nprogress. However, how to effectively use the relational information between\nvarious tissues or organs in medical images is still a very challenging\nproblem, and it has not been fully studied. In this thesis, we propose two\nnovel solutions to this problem based on deep relational learning. First, we\npropose a context-aware fully convolutional network that effectively models\nimplicit relation information between features to perform medical image\nsegmentation. The network achieves the state-of-the-art segmentation results on\nthe Multi Modal Brain Tumor Segmentation 2017 (BraTS2017) and Multi Modal Brain\nTumor Segmentation 2018 (BraTS2018) data sets. Subsequently, we propose a new\nhierarchical homography estimation network to achieve accurate medical image\nmosaicing by learning the explicit spatial relationship between adjacent\nframes. We use the UCL Fetoscopy Placenta dataset to conduct experiments and\nour hierarchical homography estimation network outperforms the other\nstate-of-the-art mosaicing methods while generating robust and meaningful\nmosaicing result on unseen frames.\n",
                "链接": "https://arxiv.org/abs/2303.16099"
            },
            {
                "文章ID": "107726",
                "标题": "Data efficient deep learning for medical image analysis: A survey",
                "作者": " Suruchi Kumari,  Pravendra Singh",
                "发布日期": "2023-10-11",
                "摘要": "  The rapid evolution of deep learning has significantly advanced the field of\nmedical image analysis. However, despite these achievements, the further\nenhancement of deep learning models for medical image analysis faces a\nsignificant challenge due to the scarcity of large, well-annotated datasets. To\naddress this issue, recent years have witnessed a growing emphasis on the\ndevelopment of data-efficient deep learning methods. This paper conducts a\nthorough review of data-efficient deep learning methods for medical image\nanalysis. To this end, we categorize these methods based on the level of\nsupervision they rely on, encompassing categories such as no supervision,\ninexact supervision, incomplete supervision, inaccurate supervision, and only\nlimited supervision. We further divide these categories into finer\nsubcategories. For example, we categorize inexact supervision into multiple\ninstance learning and learning with weak annotations. Similarly, we categorize\nincomplete supervision into semi-supervised learning, active learning, and\ndomain-adaptive learning and so on. Furthermore, we systematically summarize\ncommonly used datasets for data efficient deep learning in medical image\nanalysis and investigate future research directions to conclude this survey.\n",
                "链接": "https://arxiv.org/abs/2310.06557"
            },
            {
                "文章ID": "5953",
                "标题": "An overview of deep learning in medical imaging",
                "作者": " Imran Ul Haq",
                "发布日期": "2022-02-18",
                "摘要": "  Machine learning (ML) has seen enormous consideration during the most recent\ndecade. This success started in 2012 when an ML model accomplished a remarkable\ntriumph in the ImageNet Classification, the world's most famous competition for\ncomputer vision. This model was a kind of convolutional neural system (CNN)\ncalled deep learning (DL). Since then, researchers have started to participate\nefficiently in DL's fastest developing area of research. These days, DL systems\nare cutting-edge ML systems spanning a broad range of disciplines, from human\nlanguage processing to video analysis, and commonly used in the scholarly world\nand enterprise sector. Recent advances can bring tremendous improvement to the\nmedical field. Improved and innovative methods for data processing, image\nanalysis and can significantly improve the diagnostic technologies and\nmedicinal services gradually. A quick review of current developments with\nrelevant problems in the field of DL used for medical imaging has been\nprovided. The primary purposes of the review are four: (i) provide a brief\nprolog to DL by discussing different DL models, (ii) review of the DL usage for\nmedical image analysis (classification, detection, segmentation, and\nregistration), (iii) review seven main application fields of DL in medical\nimaging, (iv) give an initial stage to those keen on adding to the research\narea about DL in clinical imaging by providing links of some useful informative\nassets, such as freely available DL codes, public datasets Table 7, and medical\nimaging competition sources Table 8 and end our survey by outlining distinct\ncontinuous difficulties, lessons learned and future of DL in the field of\nmedical science.\n",
                "链接": "https://arxiv.org/abs/2202.08546"
            },
            {
                "文章ID": "92854",
                "标题": "Deep Learning Approaches for Data Augmentation in Medical Imaging: A\n  Review",
                "作者": " Aghiles Kebaili,  Jérôme Lapuyade-Lahorgue,  Su Ruan",
                "发布日期": "2023-07-26",
                "摘要": "  Deep learning has become a popular tool for medical image analysis, but the\nlimited availability of training data remains a major challenge, particularly\nin the medical field where data acquisition can be costly and subject to\nprivacy regulations. Data augmentation techniques offer a solution by\nartificially increasing the number of training samples, but these techniques\noften produce limited and unconvincing results. To address this issue, a\ngrowing number of studies have proposed the use of deep generative models to\ngenerate more realistic and diverse data that conform to the true distribution\nof the data. In this review, we focus on three types of deep generative models\nfor medical image augmentation: variational autoencoders, generative\nadversarial networks, and diffusion models. We provide an overview of the\ncurrent state of the art in each of these models and discuss their potential\nfor use in different downstream tasks in medical imaging, including\nclassification, segmentation, and cross-modal translation. We also evaluate the\nstrengths and limitations of each model and suggest directions for future\nresearch in this field. Our goal is to provide a comprehensive review about the\nuse of deep generative models for medical image augmentation and to highlight\nthe potential of these models for improving the performance of deep learning\nalgorithms in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2307.13125"
            },
            {
                "文章ID": "52332",
                "标题": "A Trustworthy Framework for Medical Image Analysis with Deep Learning",
                "作者": " Kai Ma,  Siyuan He,  Pengcheng Xi,  Ashkan Ebadi,  Stéphane Tremblay,  Alexander Wong",
                "发布日期": "2022-12-07",
                "摘要": "  Computer vision and machine learning are playing an increasingly important\nrole in computer-assisted diagnosis; however, the application of deep learning\nto medical imaging has challenges in data availability and data imbalance, and\nit is especially important that models for medical imaging are built to be\ntrustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning\nframework for medical image analysis, which adopts a modular design, leverages\nself-supervised pre-training, and utilizes a novel surrogate loss function.\nExperimental evaluations indicate that models generated from the framework are\nboth trustworthy and high-performing. It is anticipated that the framework will\nsupport researchers and clinicians in advancing the use of deep learning for\ndealing with public health crises including COVID-19.\n",
                "链接": "https://arxiv.org/abs/2212.02764"
            },
            {
                "文章ID": "110503",
                "标题": "A comprehensive survey on deep active learning and its applications in\n  medical image analysis",
                "作者": " Haoran Wang,  Qiuye Jin,  Shiman Li,  Siyu Liu,  Manning Wang,  Zhijian Song",
                "发布日期": "2023-10-25",
                "摘要": "  Deep learning has achieved widespread success in medical image analysis,\nleading to an increasing demand for large-scale expert-annotated medical image\ndatasets. Yet, the high cost of annotating medical images severely hampers the\ndevelopment of deep learning in this field. To reduce annotation costs, active\nlearning aims to select the most informative samples for annotation and train\nhigh-performance models with as few labeled samples as possible. In this\nsurvey, we review the core methods of active learning, including the evaluation\nof informativeness and sampling strategy. For the first time, we provide a\ndetailed summary of the integration of active learning with other\nlabel-efficient techniques, such as semi-supervised, self-supervised learning,\nand so on. Additionally, we also highlight active learning works that are\nspecifically tailored to medical image analysis. In the end, we offer our\nperspectives on the future trends and challenges of active learning and its\napplications in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2310.14230"
            },
            {
                "文章ID": "65067",
                "标题": "Evaluating the Fairness of Deep Learning Uncertainty Estimates in\n  Medical Image Analysis",
                "作者": " Raghav Mehta,  Changjian Shui,  Tal Arbel",
                "发布日期": "2023-03-07",
                "摘要": "  Although deep learning (DL) models have shown great success in many medical\nimage analysis tasks, deployment of the resulting models into real clinical\ncontexts requires: (1) that they exhibit robustness and fairness across\ndifferent sub-populations, and (2) that the confidence in DL model predictions\nbe accurately expressed in the form of uncertainties. Unfortunately, recent\nstudies have indeed shown significant biases in DL models across demographic\nsubgroups (e.g., race, sex, age) in the context of medical image analysis,\nindicating a lack of fairness in the models. Although several methods have been\nproposed in the ML literature to mitigate a lack of fairness in DL models, they\nfocus entirely on the absolute performance between groups without considering\ntheir effect on uncertainty estimation. In this work, we present the first\nexploration of the effect of popular fairness models on overcoming biases\nacross subgroups in medical image analysis in terms of bottom-line performance,\nand their effects on uncertainty quantification. We perform extensive\nexperiments on three different clinically relevant tasks: (i) skin lesion\nclassification, (ii) brain tumour segmentation, and (iii) Alzheimer's disease\nclinical score regression. Our results indicate that popular ML methods, such\nas data-balancing and distributionally robust optimization, succeed in\nmitigating fairness issues in terms of the model performances for some of the\ntasks. However, this can come at the cost of poor uncertainty estimates\nassociated with the model predictions. This tradeoff must be mitigated if\nfairness models are to be adopted in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2303.03242"
            },
            {
                "文章ID": "2124",
                "标题": "The Security of Deep Learning Defences for Medical Imaging",
                "作者": " Moshe Levy,  Guy Amit,  Yuval Elovici,  Yisroel Mirsky",
                "发布日期": "2022-01-24",
                "摘要": "  Deep learning has shown great promise in the domain of medical image\nanalysis. Medical professionals and healthcare providers have been adopting the\ntechnology to speed up and enhance their work. These systems use deep neural\nnetworks (DNN) which are vulnerable to adversarial samples; images with\nimperceivable changes that can alter the model's prediction. Researchers have\nproposed defences which either make a DNN more robust or detect the adversarial\nsamples before they do harm. However, none of these works consider an informed\nattacker which can adapt to the defence mechanism. We show that an informed\nattacker can evade five of the current state of the art defences while\nsuccessfully fooling the victim's deep learning model, rendering these defences\nuseless. We then suggest better alternatives for securing healthcare DNNs from\nsuch attacks: (1) harden the system's security and (2) use digital signatures.\n",
                "链接": "https://arxiv.org/abs/2201.08661"
            },
            {
                "文章ID": "24460",
                "标题": "Quantitative Imaging Principles Improves Medical Image Learning",
                "作者": " Lambert T. Leong,  Michael C. Wong,  Yannik Glaser,  Thomas Wolfgruber,  Steven B. Heymsfield,  Peter Sadowski,  John A. Shepherd",
                "发布日期": "2022-07-13",
                "摘要": "  Fundamental differences between natural and medical images have recently\nfavored the use of self-supervised learning (SSL) over ImageNet transfer\nlearning for medical image applications. Differences between image types are\nprimarily due to the imaging modality and medical images utilize a wide range\nof physics based techniques while natural images are captured using only\nvisible light. While many have demonstrated that SSL on medical images has\nresulted in better downstream task performance, our work suggests that more\nperformance can be gained. The scientific principles which are used to acquire\nmedical images are not often considered when constructing learning problems.\nFor this reason, we propose incorporating quantitative imaging principles\nduring generative SSL to improve image quality and quantitative biological\naccuracy. We show that this training schema results in better starting states\nfor downstream supervised training on limited data. Our model also generates\nimages that validate on clinical quantitative analysis software.\n",
                "链接": "https://arxiv.org/abs/2206.06663"
            },
            {
                "文章ID": "8249",
                "标题": "Carbon Footprint of Selecting and Training Deep Learning Models for\n  Medical Image Analysis",
                "作者": " Raghavendra Selvan,  Nikhil Bhagwat,  Lasse F. Wolff Anthony,  Benjamin Kanding,  Erik B. Dam",
                "发布日期": "2022-09-16",
                "摘要": "  The increasing energy consumption and carbon footprint of deep learning (DL)\ndue to growing compute requirements has become a cause of concern. In this\nwork, we focus on the carbon footprint of developing DL models for medical\nimage analysis (MIA), where volumetric images of high spatial resolution are\nhandled. In this study, we present and compare the features of four tools from\nliterature to quantify the carbon footprint of DL. Using one of these tools we\nestimate the carbon footprint of medical image segmentation pipelines. We\nchoose nnU-net as the proxy for a medical image segmentation pipeline and\nexperiment on three common datasets. With our work we hope to inform on the\nincreasing energy costs incurred by MIA. We discuss simple strategies to\ncut-down the environmental impact that can make model selection and training\nprocesses more efficient.\n",
                "链接": "https://arxiv.org/abs/2203.02202"
            }
        ]
    },
    {
        "question": {
            "question": "强化学习在大语言模型领域中应用的相关论文",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "119143",
                "标题": "Label-efficient Training of Small Task-specific Models by Leveraging\n  Vision Foundation Models",
                "作者": " Raviteja Vemulapalli,  Hadi Pouransari,  Fartash Faghri,  Sachin Mehta,  Mehrdad Farajtabar,  Mohammad Rastegari,  Oncel Tuzel",
                "发布日期": "2023-12-01",
                "摘要": "  Large Vision Foundation Models (VFMs) pretrained on massive datasets exhibit\nimpressive performance on various downstream tasks, especially with limited\nlabeled target data. However, due to their high memory and compute\nrequirements, these models cannot be deployed in resource constrained settings.\nThis raises an important question: How can we utilize the knowledge from a\nlarge VFM to train a small task-specific model for a new target task with\nlimited labeled training data? In this work, we answer this question by\nproposing a simple and highly effective task-oriented knowledge transfer\napproach to leverage pretrained VFMs for effective training of small\ntask-specific models. Our experimental results on four target tasks under\nlimited labeled data settings show that the proposed knowledge transfer\napproach outperforms task-agnostic VFM distillation, web-scale CLIP pretraining\nand supervised ImageNet pretraining by 1-10.5%, 2-22% and 2-14%, respectively.\nWe also show that the dataset used for transferring knowledge has a significant\neffect on the final target task performance, and propose an image\nretrieval-based approach for curating effective transfer sets.\n",
                "链接": "https://arxiv.org/abs/2311.18237"
            },
            {
                "文章ID": "65848",
                "标题": "Knowledge Transfer via Multi-Head Feature Adaptation for Whole Slide\n  Image Classification",
                "作者": " Conghao Xiong,  Yi Lin,  Hao Chen,  Joseph Sung,  Irwin King",
                "发布日期": "2023-03-13",
                "摘要": "  Transferring prior knowledge from a source domain to the same or similar\ntarget domain can greatly enhance the performance of models on the target\ndomain. However, it is challenging to directly leverage the knowledge from the\nsource domain due to task discrepancy and domain shift. To bridge the gaps\nbetween different tasks and domains, we propose a Multi-Head Feature Adaptation\nmodule, which projects features in the source feature space to a new space that\nis more similar to the target space. Knowledge transfer is particularly\nimportant in Whole Slide Image (WSI) classification since the number of WSIs in\none dataset might be too small to achieve satisfactory performance. Therefore,\nWSI classification is an ideal testbed for our method, and we adapt multiple\nknowledge transfer methods for WSI classification. The experimental results\nshow that models with knowledge transfer outperform models that are trained\nfrom scratch by a large margin regardless of the number of WSIs in the\ndatasets, and our method achieves state-of-the-art performances among other\nknowledge transfer methods on multiple datasets, including TCGA-RCC,\nTCGA-NSCLC, and Camelyon16 datasets.\n",
                "链接": "https://arxiv.org/abs/2303.05780"
            },
            {
                "文章ID": "10705",
                "标题": "Hierarchical Inductive Transfer for Continual Dialogue Learning",
                "作者": " Shaoxiong Feng,  Xuancheng Ren,  Kan Li,  Xu Sun",
                "发布日期": "2022-03-22",
                "摘要": "  Pre-trained models have achieved excellent performance on the dialogue task.\nHowever, for the continual increase of online chit-chat scenarios, directly\nfine-tuning these models for each of the new tasks not only explodes the\ncapacity of the dialogue system on the embedded devices but also causes\nknowledge forgetting on pre-trained models and knowledge interference among\ndiverse dialogue tasks. In this work, we propose a hierarchical inductive\ntransfer framework to learn and deploy the dialogue skills continually and\nefficiently. First, we introduce the adapter module into pre-trained models for\nlearning new dialogue tasks. As the only trainable module, it is beneficial for\nthe dialogue system on the embedded devices to acquire new dialogue skills with\nnegligible additional parameters. Then, for alleviating knowledge interference\nbetween tasks yet benefiting the regularization between them, we further design\nhierarchical inductive transfer that enables new tasks to use general knowledge\nin the base adapter without being misled by diverse knowledge in task-specific\nadapters. Empirical evaluation and analysis indicate that our framework obtains\ncomparable performance under deployment-friendly model capacity.\n",
                "链接": "https://arxiv.org/abs/2203.10484"
            },
            {
                "文章ID": "46363",
                "标题": "Beyond Not-Forgetting: Continual Learning with Backward Knowledge\n  Transfer",
                "作者": " Sen Lin,  Li Yang,  Deliang Fan,  Junshan Zhang",
                "发布日期": "2022-11-03",
                "摘要": "  By learning a sequence of tasks continually, an agent in continual learning\n(CL) can improve the learning performance of both a new task and `old' tasks by\nleveraging the forward knowledge transfer and the backward knowledge transfer,\nrespectively. However, most existing CL methods focus on addressing\ncatastrophic forgetting in neural networks by minimizing the modification of\nthe learnt model for old tasks. This inevitably limits the backward knowledge\ntransfer from the new task to the old tasks, because judicious model updates\ncould possibly improve the learning performance of the old tasks as well. To\ntackle this problem, we first theoretically analyze the conditions under which\nupdating the learnt model of old tasks could be beneficial for CL and also lead\nto backward knowledge transfer, based on the gradient projection onto the input\nsubspaces of old tasks. Building on the theoretical analysis, we next develop a\nContinUal learning method with Backward knowlEdge tRansfer (CUBER), for a fixed\ncapacity neural network without data replay. In particular, CUBER first\ncharacterizes the task correlation to identify the positively correlated old\ntasks in a layer-wise manner, and then selectively modifies the learnt model of\nthe old tasks when learning the new task. Experimental studies show that CUBER\ncan even achieve positive backward knowledge transfer on several existing CL\nbenchmarks for the first time without data replay, where the related baselines\nstill suffer from catastrophic forgetting (negative backward knowledge\ntransfer). The superior performance of CUBER on the backward knowledge transfer\nalso leads to higher accuracy accordingly.\n",
                "链接": "https://arxiv.org/abs/2211.00789"
            },
            {
                "文章ID": "30372",
                "标题": "TinyViT: Fast Pretraining Distillation for Small Vision Transformers",
                "作者": " Kan Wu,  Jinnian Zhang,  Houwen Peng,  Mengchen Liu,  Bin Xiao,  Jianlong Fu,  Lu Yuan",
                "发布日期": "2022-07-22",
                "摘要": "  Vision transformer (ViT) recently has drawn great attention in computer\nvision due to its remarkable model capability. However, most prevailing ViT\nmodels suffer from huge number of parameters, restricting their applicability\non devices with limited resources. To alleviate this issue, we propose TinyViT,\na new family of tiny and efficient small vision transformers pretrained on\nlarge-scale datasets with our proposed fast distillation framework. The central\nidea is to transfer knowledge from large pretrained models to small ones, while\nenabling small models to get the dividends of massive pretraining data. More\nspecifically, we apply distillation during pretraining for knowledge transfer.\nThe logits of large teacher models are sparsified and stored in disk in advance\nto save the memory cost and computation overheads. The tiny student\ntransformers are automatically scaled down from a large pretrained model with\ncomputation and parameter constraints. Comprehensive experiments demonstrate\nthe efficacy of TinyViT. It achieves a top-1 accuracy of 84.8% on ImageNet-1k\nwith only 21M parameters, being comparable to Swin-B pretrained on ImageNet-21k\nwhile using 4.2 times fewer parameters. Moreover, increasing image resolutions,\nTinyViT can reach 86.5% accuracy, being slightly better than Swin-L while using\nonly 11% parameters. Last but not the least, we demonstrate a good transfer\nability of TinyViT on various downstream tasks. Code and models are available\nat https://github.com/microsoft/Cream/tree/main/TinyViT.\n",
                "链接": "https://arxiv.org/abs/2207.10666"
            },
            {
                "文章ID": "40310",
                "标题": "The (In)Effectiveness of Intermediate Task Training For Domain\n  Adaptation and Cross-Lingual Transfer Learning",
                "作者": " Sovesh Mohapatra,  Somesh Mohapatra",
                "发布日期": "2022-11-08",
                "摘要": "  Transfer learning from large language models (LLMs) has emerged as a powerful\ntechnique to enable knowledge-based fine-tuning for a number of tasks,\nadaptation of models for different domains and even languages. However, it\nremains an open question, if and when transfer learning will work, i.e. leading\nto positive or negative transfer. In this paper, we analyze the knowledge\ntransfer across three natural language processing (NLP) tasks - text\nclassification, sentimental analysis, and sentence similarity, using three LLMs\n- BERT, RoBERTa, and XLNet - and analyzing their performance, by fine-tuning on\ntarget datasets for domain and cross-lingual adaptation tasks, with and without\nan intermediate task training on a larger dataset. Our experiments showed that\nfine-tuning without an intermediate task training can lead to a better\nperformance for most tasks, while more generalized tasks might necessitate a\npreceding intermediate task training step. We hope that this work will act as a\nguide on transfer learning to NLP practitioners.\n",
                "链接": "https://arxiv.org/abs/2210.01091"
            },
            {
                "文章ID": "90545",
                "标题": "Towards Robust and Efficient Continual Language Learning",
                "作者": " Adam Fisch,  Amal Rannen-Triki,  Razvan Pascanu,  Jörg Bornschein,  Angeliki Lazaridou,  Elena Gribovskaya,  Marc'Aurelio Ranzato",
                "发布日期": "2023-07-13",
                "摘要": "  As the application space of language models continues to evolve, a natural\nquestion to ask is how we can quickly adapt models to new tasks. We approach\nthis classic question from a continual learning perspective, in which we aim to\ncontinue fine-tuning models trained on past tasks on new tasks, with the goal\nof \"transferring\" relevant knowledge. However, this strategy also runs the risk\nof doing more harm than good, i.e., negative transfer. In this paper, we\nconstruct a new benchmark of task sequences that target different possible\ntransfer scenarios one might face, such as a sequence of tasks with high\npotential of positive transfer, high potential for negative transfer, no\nexpected effect, or a mixture of each. An ideal learner should be able to\nmaximally exploit information from all tasks that have any potential for\npositive transfer, while also avoiding the negative effects of any distracting\ntasks that may confuse it. We then propose a simple, yet effective, learner\nthat satisfies many of our desiderata simply by leveraging a selective strategy\nfor initializing new models from past task checkpoints. Still, limitations\nremain, and we hope this benchmark can help the community to further build and\nanalyze such learners.\n",
                "链接": "https://arxiv.org/abs/2307.05741"
            },
            {
                "文章ID": "70105",
                "标题": "DIME-FM: DIstilling Multimodal and Efficient Foundation Models",
                "作者": " Ximeng Sun,  Pengchuan Zhang,  Peizhao Zhang,  Hardik Shah,  Kate Saenko,  Xide Xia",
                "发布日期": "2023-08-16",
                "摘要": "  Large Vision-Language Foundation Models (VLFM), such as CLIP, ALIGN and\nFlorence, are trained on large-scale datasets of image-caption pairs and\nachieve superior transferability and robustness on downstream tasks, but they\nare difficult to use in many practical applications due to their large size,\nhigh latency and fixed architectures. Unfortunately, recent work shows training\na small custom VLFM for resource-limited applications is currently very\ndifficult using public and smaller-scale data. In this paper, we introduce a\nnew distillation mechanism (DIME-FM) that allows us to transfer the knowledge\ncontained in large VLFMs to smaller, customized foundation models using a\nrelatively small amount of inexpensive, unpaired images and sentences. We\ntransfer the knowledge from the pre-trained CLIP-ViTL/14 model to a ViT-B/32\nmodel, with only 40M public images and 28.4M unpaired public sentences. The\nresulting model \"Distill-ViT-B/32\" rivals the CLIP-ViT-B/32 model pre-trained\non its private WiT dataset (400M image-text pairs): Distill-ViT-B/32 achieves\nsimilar results in terms of zero-shot and linear-probing performance on both\nImageNet and the ELEVATER (20 image classification tasks) benchmarks. It also\ndisplays comparable robustness when evaluated on five datasets with natural\ndistribution shifts from ImageNet.\n",
                "链接": "https://arxiv.org/abs/2303.18232"
            },
            {
                "文章ID": "21169",
                "标题": "An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale\n  Multitask Learning Systems",
                "作者": " Andrea Gesmundo,  Jeff Dean",
                "发布日期": "2022-11-17",
                "摘要": "  Multitask learning assumes that models capable of learning from multiple\ntasks can achieve better quality and efficiency via knowledge transfer, a key\nfeature of human learning. Though, state of the art ML models rely on high\ncustomization for each task and leverage size and data scale rather than\nscaling the number of tasks. Also, continual learning, that adds the temporal\naspect to multitask, is often focused to the study of common pitfalls such as\ncatastrophic forgetting instead of being studied at a large scale as a critical\ncomponent to build the next generation artificial intelligence.We propose an\nevolutionary method capable of generating large scale multitask models that\nsupport the dynamic addition of new tasks. The generated multitask models are\nsparsely activated and integrates a task-based routing that guarantees bounded\ncompute cost and fewer added parameters per task as the model expands.The\nproposed method relies on a knowledge compartmentalization technique to achieve\nimmunity against catastrophic forgetting and other common pitfalls such as\ngradient interference and negative transfer. We demonstrate empirically that\nthe proposed method can jointly solve and achieve competitive results on\n69public image classification tasks, for example improving the state of the art\non a competitive benchmark such as cifar10 by achieving a 15% relative error\nreduction compared to the best model trained on public data.\n",
                "链接": "https://arxiv.org/abs/2205.12755"
            },
            {
                "文章ID": "66657",
                "标题": "Is forgetting less a good inductive bias for forward transfer?",
                "作者": " Jiefeng Chen,  Timothy Nguyen,  Dilan Gorur,  Arslan Chaudhry",
                "发布日期": "2023-03-16",
                "摘要": "  One of the main motivations of studying continual learning is that the\nproblem setting allows a model to accrue knowledge from past tasks to learn new\ntasks more efficiently. However, recent studies suggest that the key metric\nthat continual learning algorithms optimize, reduction in catastrophic\nforgetting, does not correlate well with the forward transfer of knowledge. We\nbelieve that the conclusion previous works reached is due to the way they\nmeasure forward transfer. We argue that the measure of forward transfer to a\ntask should not be affected by the restrictions placed on the continual learner\nin order to preserve knowledge of previous tasks. Instead, forward transfer\nshould be measured by how easy it is to learn a new task given a set of\nrepresentations produced by continual learning on previous tasks. Under this\nnotion of forward transfer, we evaluate different continual learning algorithms\non a variety of image classification benchmarks. Our results indicate that less\nforgetful representations lead to a better forward transfer suggesting a strong\ncorrelation between retaining past information and learning efficiency on new\ntasks. Further, we found less forgetful representations to be more diverse and\ndiscriminative compared to their forgetful counterparts.\n",
                "链接": "https://arxiv.org/abs/2303.08207"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和人文学科交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "70754",
                "标题": "A Bibliometric Review of Large Language Models Research from 2017 to\n  2023",
                "作者": " Lizhou Fan,  Lingyao Li,  Zihui Ma,  Sanggyu Lee,  Huizi Yu,  Libby Hemphill",
                "发布日期": "2023-04-06",
                "摘要": "  Large language models (LLMs) are a class of language models that have\ndemonstrated outstanding performance across a range of natural language\nprocessing (NLP) tasks and have become a highly sought-after research area,\nbecause of their ability to generate human-like language and their potential to\nrevolutionize science and technology. In this study, we conduct bibliometric\nand discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000\npublications, this paper serves as a roadmap for researchers, practitioners,\nand policymakers to navigate the current landscape of LLMs research. We present\nthe research trends from 2017 to early 2023, identifying patterns in research\nparadigms and collaborations. We start with analyzing the core algorithm\ndevelopments and NLP tasks that are fundamental in LLMs research. We then\ninvestigate the applications of LLMs in various fields and domains including\nmedicine, engineering, social science, and humanities. Our review also reveals\nthe dynamic, fast-paced evolution of LLMs research. Overall, this paper offers\nvaluable insights into the current state, impact, and potential of LLMs\nresearch and its applications.\n",
                "链接": "https://arxiv.org/abs/2304.02020"
            },
            {
                "文章ID": "114592",
                "标题": "An Interdisciplinary Outlook on Large Language Models for Scientific\n  Research",
                "作者": " James Boyko,  Joseph Cohen,  Nathan Fox,  Maria Han Veiga,  Jennifer I-Hsiu Li,  Jing Liu,  Bernardo Modenesi,  Andreas H. Rauch,  Kenneth N. Reid,  Soumi Tribedi,  Anastasia Visheratina,  Xin Xie",
                "发布日期": "2023-11-10",
                "摘要": "  In this paper, we describe the capabilities and constraints of Large Language\nModels (LLMs) within disparate academic disciplines, aiming to delineate their\nstrengths and limitations with precision. We examine how LLMs augment\nscientific inquiry, offering concrete examples such as accelerating literature\nreview by summarizing vast numbers of publications, enhancing code development\nthrough automated syntax correction, and refining the scientific writing\nprocess. Simultaneously, we articulate the challenges LLMs face, including\ntheir reliance on extensive and sometimes biased datasets, and the potential\nethical dilemmas stemming from their use. Our critical discussion extends to\nthe varying impacts of LLMs across fields, from the natural sciences, where\nthey help model complex biological sequences, to the social sciences, where\nthey can parse large-scale qualitative data. We conclude by offering a nuanced\nperspective on how LLMs can be both a boon and a boundary to scientific\nprogress.\n",
                "链接": "https://arxiv.org/abs/2311.04929"
            },
            {
                "文章ID": "71835",
                "标题": "Emergent autonomous scientific research capabilities of large language\n  models",
                "作者": " Daniil A. Boiko,  Robert MacKnight,  Gabe Gomes",
                "发布日期": "2023-04-12",
                "摘要": "  Transformer-based large language models are rapidly advancing in the field of\nmachine learning research, with applications spanning natural language,\nbiology, chemistry, and computer programming. Extreme scaling and reinforcement\nlearning from human feedback have significantly improved the quality of\ngenerated text, enabling these models to perform various tasks and reason about\ntheir choices. In this paper, we present an Intelligent Agent system that\ncombines multiple large language models for autonomous design, planning, and\nexecution of scientific experiments. We showcase the Agent's scientific\nresearch capabilities with three distinct examples, with the most complex being\nthe successful performance of catalyzed cross-coupling reactions. Finally, we\ndiscuss the safety implications of such systems and propose measures to prevent\ntheir misuse.\n",
                "链接": "https://arxiv.org/abs/2304.05332"
            },
            {
                "文章ID": "12359",
                "标题": "Cross-Media Scientific Research Achievements Retrieval Based on Deep\n  Language Model",
                "作者": " Benzhi Wang,  Meiyu Liang,  Feifei Kou,  Mingying Xu",
                "发布日期": "2022-03-30",
                "摘要": "  Science and technology big data contain a lot of cross-media\ninformation.There are images and texts in the scientific paper.The s ingle\nmodal search method cannot well meet the needs of scientific researchers.This\npaper proposes a cross-media scientific research achievements retrieval method\nbased on deep language model (CARDL).It achieves a unified cross-media semantic\nrepresentation by learning the semantic association between different modal\ndata, and is applied to the generation of text semantic vector of scientific\nresearch achievements, and then cross-media retrieval is realized through\nsemantic similarity matching between different modal data.Experimental results\nshow that the proposed CARDL method achieves better cross-modal retrieval\nperformance than existing methods. Key words science and technology big data ;\ncross-media retrieval; cross-media semantic association learning; deep language\nmodel; semantic similarity\n",
                "链接": "https://arxiv.org/abs/2203.15595"
            },
            {
                "文章ID": "66370",
                "标题": "Algorithmic Ghost in the Research Shell: Large Language Models and\n  Academic Knowledge Creation in Management Research",
                "作者": " Nigel Williams,  Stanislav Ivanov,  Dimitrios Buhalis",
                "发布日期": "2023-03-14",
                "摘要": "  The paper looks at the role of large language models in academic knowledge\ncreation based on a scoping review (2018 to January 2023) of how researchers\nhave previously used the language model GPT to assist in the performance of\nacademic knowledge creation tasks beyond data analysis. These tasks include\nwriting, editing, reviewing, dataset creation and curation, which have been\ndifficult to perform using earlier ML tools. Based on a synthesis of these\npapers, this study identifies pathways for a future academic research landscape\nthat incorporates wider usage of large language models based on the current\nmodes of adoption in published articles as a Co-Writer, Research Assistant and\nRespondent.\n",
                "链接": "https://arxiv.org/abs/2303.07304"
            },
            {
                "文章ID": "105341",
                "标题": "Finding Pragmatic Differences Between Disciplines",
                "作者": " Lee Kezar,  Jay Pujara",
                "发布日期": "2023-10-03",
                "摘要": "  Scholarly documents have a great degree of variation, both in terms of\ncontent (semantics) and structure (pragmatics). Prior work in scholarly\ndocument understanding emphasizes semantics through document summarization and\ncorpus topic modeling but tends to omit pragmatics such as document\norganization and flow. Using a corpus of scholarly documents across 19\ndisciplines and state-of-the-art language modeling techniques, we learn a fixed\nset of domain-agnostic descriptors for document sections and \"retrofit\" the\ncorpus to these descriptors (also referred to as \"normalization\"). Then, we\nanalyze the position and ordering of these descriptors across documents to\nunderstand the relationship between discipline and structure. We report\nwithin-discipline structural archetypes, variability, and between-discipline\ncomparisons, supporting the hypothesis that scholarly communities, despite\ntheir size, diversity, and breadth, share similar avenues for expressing their\nwork. Our findings lay the foundation for future work in assessing research\nquality, domain style transfer, and further pragmatic analysis.\n",
                "链接": "https://arxiv.org/abs/2310.00204"
            },
            {
                "文章ID": "112844",
                "标题": "Ontologies for Models and Algorithms in Applied Mathematics and Related\n  Disciplines",
                "作者": " Björn Schembera,  Frank Wübbeling,  Hendrik Kleikamp,  Christine Biedinger,  Jochen Fiedler,  Marco Reidelbach,  Aurela Shehu,  Burkhard Schmidt,  Thomas Koprucki,  Dorothea Iglezakis,  Dominik Göddeke",
                "发布日期": "2023-11-01",
                "摘要": "  In applied mathematics and related disciplines, the\nmodeling-simulation-optimization workflow is a prominent scheme, with\nmathematical models and numerical algorithms playing a crucial role. For these\ntypes of mathematical research data, the Mathematical Research Data Initiative\nhas developed, merged and implemented ontologies and knowledge graphs. This\ncontributes to making mathematical research data FAIR by introducing semantic\ntechnology and documenting the mathematical foundations accordingly. Using the\nconcrete example of microfracture analysis of porous media, it is shown how the\nknowledge of the underlying mathematical model and the corresponding numerical\nalgorithms for its solution can be represented by the ontologies.\n",
                "链接": "https://arxiv.org/abs/2310.20443"
            },
            {
                "文章ID": "101124",
                "标题": "Toward Reproducing Network Research Results Using Large Language Models",
                "作者": " Qiao Xiang,  Yuling Lin,  Mingjun Fang,  Bang Huang,  Siyong Huang,  Ridi Wen,  Franck Le,  Linghe Kong,  Jiwu Shu",
                "发布日期": "2023-09-12",
                "摘要": "  Reproducing research results in the networking community is important for\nboth academia and industry. The current best practice typically resorts to\nthree approaches: (1) looking for publicly available prototypes; (2) contacting\nthe authors to get a private prototype; and (3) manually implementing a\nprototype following the description of the publication. However, most published\nnetwork research does not have public prototypes and private prototypes are\nhard to get. As such, most reproducing efforts are spent on manual\nimplementation based on the publications, which is both time and labor\nconsuming and error-prone. In this paper, we boldly propose reproducing network\nresearch results using the emerging large language models (LLMs). In\nparticular, we first prove its feasibility with a small-scale experiment, in\nwhich four students with essential networking knowledge each reproduces a\ndifferent networking system published in prominent conferences and journals by\nprompt engineering ChatGPT. We report the experiment's observations and lessons\nand discuss future open research questions of this proposal. This work raises\nno ethical issue.\n",
                "链接": "https://arxiv.org/abs/2309.04716"
            },
            {
                "文章ID": "100283",
                "标题": "On the Planning, Search, and Memorization Capabilities of Large Language\n  Models",
                "作者": " Yunhao Yang,  Anshul Tomar",
                "发布日期": "2023-09-06",
                "摘要": "  The rapid advancement of large language models, such as the Generative\nPre-trained Transformer (GPT) series, has had significant implications across\nvarious disciplines. In this study, we investigate the potential of the\nstate-of-the-art large language model (GPT-4) for planning tasks. We explore\nits effectiveness in multiple planning subfields, highlighting both its\nstrengths and limitations. Through a comprehensive examination, we identify\nareas where large language models excel in solving planning problems and reveal\nthe constraints that limit their applicability. Our empirical analysis focuses\non GPT-4's performance in planning domain extraction, graph search path\nplanning, and adversarial planning. We then propose a way of fine-tuning a\ndomain-specific large language model to improve its Chain of Thought (CoT)\ncapabilities for the above-mentioned tasks. The results provide valuable\ninsights into the potential applications of large language models in the\nplanning domain and pave the way for future research to overcome their\nlimitations and expand their capabilities.\n",
                "链接": "https://arxiv.org/abs/2309.01868"
            },
            {
                "文章ID": "79552",
                "标题": "A Study of Generative Large Language Model for Medical Research and\n  Healthcare",
                "作者": " Cheng Peng,  Xi Yang,  Aokun Chen,  Kaleb E Smith,  Nima PourNejatian,  Anthony B Costa,  Cheryl Martin,  Mona G Flores,  Ying Zhang,  Tanja Magoc,  Gloria Lipori,  Duane A Mitchell,  Naykky S Ospina,  Mustafa M Ahmed,  William R Hogan,  Elizabeth A Shenkman,  Yi Guo,  Jiang Bian,  Yonghui Wu",
                "发布日期": "2023-11-20",
                "摘要": "  There is enormous enthusiasm and concerns in using large language models\n(LLMs) in healthcare, yet current assumptions are all based on general-purpose\nLLMs such as ChatGPT. This study develops a clinical generative LLM,\nGatorTronGPT, using 277 billion words of mixed clinical and English text with a\nGPT-3 architecture of 20 billion parameters. GatorTronGPT improves biomedical\nnatural language processing for medical research. Synthetic NLP models trained\nusing GatorTronGPT generated text outperform NLP models trained using\nreal-world clinical text. Physicians Turing test using 1 (worst) to 9 (best)\nscale shows that there is no significant difference in linguistic readability\n(p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical\nrelevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that\nphysicians cannot differentiate them (p < 0.001). This study provides insights\non the opportunities and challenges of LLMs for medical research and\nhealthcare.\n",
                "链接": "https://arxiv.org/abs/2305.13523"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和脑科学交叉的研究",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "2022年后与AI for Science相关的综述论文",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "65341",
                "标题": "AI for Science: An Emerging Agenda",
                "作者": " Philipp Berens,  Kyle Cranmer,  Neil D. Lawrence,  Ulrike von Luxburg,  Jessica Montgomery",
                "发布日期": "2023-03-09",
                "摘要": "  This report documents the programme and the outcomes of Dagstuhl Seminar\n22382 \"Machine Learning for Science: Bridging Data-Driven and Mechanistic\nModelling\". Today's scientific challenges are characterised by complexity.\nInterconnected natural, technological, and human systems are influenced by\nforces acting across time- and spatial-scales, resulting in complex\ninteractions and emergent behaviours. Understanding these phenomena -- and\nleveraging scientific advances to deliver innovative solutions to improve\nsociety's health, wealth, and well-being -- requires new ways of analysing\ncomplex systems. The transformative potential of AI stems from its widespread\napplicability across disciplines, and will only be achieved through integration\nacross research domains. AI for science is a rendezvous point. It brings\ntogether expertise from $\\mathrm{AI}$ and application domains; combines\nmodelling knowledge with engineering know-how; and relies on collaboration\nacross disciplines and between humans and machines. Alongside technical\nadvances, the next wave of progress in the field will come from building a\ncommunity of machine learning researchers, domain experts, citizen scientists,\nand engineers working together to design and deploy effective AI tools. This\nreport summarises the discussions from the seminar and provides a roadmap to\nsuggest how different communities can collaborate to deliver a new wave of\nprogress in AI and its application for scientific discovery.\n",
                "链接": "https://arxiv.org/abs/2303.04217"
            },
            {
                "文章ID": "110050",
                "标题": "AI for Mathematics: A Cognitive Science Perspective",
                "作者": " Cedegao E. Zhang,  Katherine M. Collins,  Adrian Weller,  Joshua B. Tenenbaum",
                "发布日期": "2023-10-23",
                "摘要": "  Mathematics is one of the most powerful conceptual systems developed and used\nby the human species. Dreams of automated mathematicians have a storied history\nin artificial intelligence (AI). Rapid progress in AI, particularly propelled\nby advances in large language models (LLMs), has sparked renewed, widespread\ninterest in building such systems. In this work, we reflect on these goals from\na \\textit{cognitive science} perspective. We call attention to several\nclassical and ongoing research directions from cognitive science, which we\nbelieve are valuable for AI practitioners to consider when seeking to build\ntruly human (or superhuman)-level mathematical systems. We close with open\ndiscussions and questions that we believe necessitate a multi-disciplinary\nperspective -- cognitive scientists working in tandem with AI researchers and\nmathematicians -- as we move toward better mathematical AI systems which not\nonly help us push the frontier of the mathematics, but also offer glimpses into\nhow we as humans are even capable of such great cognitive feats.\n",
                "链接": "https://arxiv.org/abs/2310.13021"
            },
            {
                "文章ID": "19147",
                "标题": "AI and Citizen Science for Serendipity",
                "作者": " Marisa Ponti,  Anastasia Skarpeti,  Bruno Kestemont",
                "发布日期": "2022-05-17",
                "摘要": "  It has been argued that introducing AI to creative practices destroys\nspontaneity, intuition and serendipity. However, the design of systems that\nleverage complex interactions between citizen scientists (members of the public\nengaged in research tasks) and computational AI methods have the potential to\nfacilitate creative exploration and chance encounters. Drawing from theories\nand literature about serendipity and computation, this article points to three\ninterrelated aspects that support the emergence of serendipity in hybrid\ncitizen science systems: the task environment; the characteristics of citizen\nscientists; and anomalies and errors.\n",
                "链接": "https://arxiv.org/abs/2205.06890"
            },
            {
                "文章ID": "26706",
                "标题": "Kwame for Science: An AI Teaching Assistant Based on Sentence-BERT for\n  Science Education in West Africa",
                "作者": " George Boateng,  Samuel John,  Andrew Glago,  Samuel Boateng,  Victor Kumbol",
                "发布日期": "2022-07-12",
                "摘要": "  Africa has a high student-to-teacher ratio which limits students' access to\nteachers. Consequently, students struggle to get answers to their questions. In\nthis work, we extended Kwame, our previous AI teaching assistant, adapted it\nfor science education, and deployed it as a web app. Kwame for Science answers\nquestions of students based on the Integrated Science subject of the West\nAfrican Senior Secondary Certificate Examination (WASSCE). Kwame for Science is\na Sentence-BERT-based question-answering web app that displays 3 paragraphs as\nanswers along with a confidence score in response to science questions.\nAdditionally, it displays the top 5 related past exam questions and their\nanswers in addition to the 3 paragraphs. Our preliminary evaluation of the\nKwame for Science with a 2.5-week real-world deployment showed a top 3 accuracy\nof 87.5% (n=56) with 190 users across 11 countries. Kwame for Science will\nenable the delivery of scalable, cost-effective, and quality remote education\nto millions of people across Africa.\n",
                "链接": "https://arxiv.org/abs/2206.13703"
            },
            {
                "文章ID": "91991",
                "标题": "AI empowering research: 10 ways how science can benefit from AI",
                "作者": " César França",
                "发布日期": "2023-07-21",
                "摘要": "  This article explores the transformative impact of artificial intelligence\n(AI) on scientific research. It highlights ten ways in which AI is\nrevolutionizing the work of scientists, including powerful referencing tools,\nimproved understanding of research problems, enhanced research question\ngeneration, optimized research design, stub data generation, data\ntransformation, advanced data analysis, and AI-assisted reporting. While AI\noffers numerous benefits, challenges such as bias, privacy concerns, and the\nneed for human-AI collaboration must be considered. The article emphasizes that\nAI can augment human creativity in science but not replace it.\n",
                "链接": "https://arxiv.org/abs/2307.10265"
            },
            {
                "文章ID": "116688",
                "标题": "Best uses of ChatGPT and Generative AI for computer science research",
                "作者": " Eduardo C. Garrido-Merchan",
                "发布日期": "2023-11-21",
                "摘要": "  Generative Artificial Intelligence (AI), particularly tools like OpenAI's\npopular ChatGPT, is reshaping the landscape of computer science research. Used\nwisely, these tools can boost the productivity of a computer research\nscientist. This paper provides an exploration of the diverse applications of\nChatGPT and other generative AI technologies in computer science academic\nresearch, making recommendations about the use of Generative AI to make more\nproductive the role of the computer research scientist, with the focus of\nwriting new research papers. We highlight innovative uses such as brainstorming\nresearch ideas, aiding in the drafting and styling of academic papers and\nassisting in the synthesis of state-of-the-art section. Further, we delve into\nusing these technologies in understanding interdisciplinary approaches, making\ncomplex texts simpler, and recommending suitable academic journals for\npublication. Significant focus is placed on generative AI's contributions to\nsynthetic data creation, research methodology, and mentorship, as well as in\ntask organization and article quality assessment. The paper also addresses the\nutility of AI in article review, adapting texts to length constraints,\nconstructing counterarguments, and survey development. Moreover, we explore the\ncapabilities of these tools in disseminating ideas, generating images and\naudio, text transcription, and engaging with editors. We also describe some\nnon-recommended uses of generative AI for computer science research, mainly\nbecause of the limitations of this technology.\n",
                "链接": "https://arxiv.org/abs/2311.11175"
            },
            {
                "文章ID": "59052",
                "标题": "Can an AI Win Ghana's National Science and Maths Quiz? An AI Grand\n  Challenge for Education",
                "作者": " George Boateng,  Victor Kumbol,  Elsie Effah Kaufmann",
                "发布日期": "2023-01-31",
                "摘要": "  There is a lack of enough qualified teachers across Africa which hampers\nefforts to provide adequate learning support such as educational question\nanswering (EQA) to students. An AI system that can enable students to ask\nquestions via text or voice and get instant answers will make high-quality\neducation accessible. Despite advances in the field of AI, there exists no\nrobust benchmark or challenge to enable building such an (EQA) AI within the\nAfrican context. Ghana's National Science and Maths Quiz competition (NSMQ) is\nthe perfect competition to evaluate the potential of such an AI due to its wide\ncoverage of scientific fields, variety of question types, highly competitive\nnature, and live, real-world format. The NSMQ is a Jeopardy-style annual live\nquiz competition in which 3 teams of 2 students compete by answering questions\nacross biology, chemistry, physics, and math in 5 rounds over 5 progressive\nstages until a winning team is crowned for that year. In this position paper,\nwe propose the NSMQ AI Grand Challenge, an AI Grand Challenge for Education\nusing Ghana's National Science and Maths Quiz competition (NSMQ) as a case\nstudy. Our proposed grand challenge is to \"Build an AI to compete live in\nGhana's National Science and Maths Quiz (NSMQ) competition and win - performing\nbetter than the best contestants in all rounds and stages of the competition.\"\nWe describe the competition, and key technical challenges to address along with\nideas from recent advances in machine learning that could be leveraged to solve\nthis challenge. This position paper is a first step towards conquering such a\nchallenge and importantly, making advances in AI for education in the African\ncontext towards democratizing high-quality education across Africa.\n",
                "链接": "https://arxiv.org/abs/2301.13089"
            },
            {
                "文章ID": "95379",
                "标题": "Towards an AI to Win Ghana's National Science and Maths Quiz",
                "作者": " George Boateng,  Jonathan Abrefah Mensah,  Kevin Takyi Yeboah,  William Edor,  Andrew Kojo Mensah-Onumah,  Naafi Dasana Ibrahim,  Nana Sam Yeboah",
                "发布日期": "2023-08-09",
                "摘要": "  Can an AI win Ghana's National Science and Maths Quiz (NSMQ)? That is the\nquestion we seek to answer in the NSMQ AI project, an open-source project that\nis building AI to compete live in the NSMQ and win. The NSMQ is an annual live\nscience and mathematics competition for senior secondary school students in\nGhana in which 3 teams of 2 students compete by answering questions across\nbiology, chemistry, physics, and math in 5 rounds over 5 progressive stages\nuntil a winning team is crowned for that year. The NSMQ is an exciting live\nquiz competition with interesting technical challenges across speech-to-text,\ntext-to-speech, question-answering, and human-computer interaction. In this\nongoing work that began in January 2023, we give an overview of the project,\ndescribe each of the teams, progress made thus far, and the next steps toward\nour planned launch and debut of the AI in October for NSMQ 2023. An AI that\nconquers this grand challenge can have real-world impact on education such as\nenabling millions of students across Africa to have one-on-one learning support\nfrom this AI.\n",
                "链接": "https://arxiv.org/abs/2308.04333"
            },
            {
                "文章ID": "62764",
                "标题": "Real-World Deployment and Evaluation of Kwame for Science, An AI\n  Teaching Assistant for Science Education in West Africa",
                "作者": " George Boateng,  Samuel John,  Samuel Boateng,  Philemon Badu,  Patrick Agyeman-Budu,  Victor Kumbol",
                "发布日期": "2023-02-22",
                "摘要": "  Africa has a high student-to-teacher ratio which limits students' access to\nteachers for learning support such as educational question answering. In this\nwork, we extended Kwame, our previous AI teaching assistant for coding\neducation, adapted it for science education, and deployed it as a web app.\nKwame for Science provides passages from well-curated knowledge sources and\nrelated past national exam questions as answers to questions from students\nbased on the Integrated Science subject of the West African Senior Secondary\nCertificate Examination (WASSCE). Furthermore, students can view past national\nexam questions along with their answers and filter by year, question type\n(objectives, theory, and practicals), and topics that were automatically\ncategorized by a topic detection model which we developed (91% unweighted\naverage recall). We deployed Kwame for Science in the real world over 8 months\nand had 750 users across 32 countries (15 in Africa) and 1.5K questions asked.\nOur evaluation showed an 87.2% top 3 accuracy (n=109 questions) implying that\nKwame for Science has a high chance of giving at least one useful answer among\nthe 3 displayed. We categorized the reasons the model incorrectly answered\nquestions to provide insights for future improvements. We also share challenges\nand lessons with the development, deployment, and human-computer interaction\ncomponent of such a tool to enable other researchers to deploy similar tools.\nWith a first-of-its-kind tool within the African context, Kwame for Science has\nthe potential to enable the delivery of scalable, cost-effective, and quality\nremote education to millions of people across Africa.\n",
                "链接": "https://arxiv.org/abs/2302.10786"
            },
            {
                "文章ID": "83860",
                "标题": "Exploring the Role of AI Assistants in Computer Science Education:\n  Methods, Implications, and Instructor Perspectives",
                "作者": " Tianjia Wang,  Daniel Vargas-Díaz,  Chris Brown,  Yan Chen",
                "发布日期": "2023-11-14",
                "摘要": "  The use of AI assistants, along with the challenges they present, has sparked\nsignificant debate within the community of computer science education. While\nthese tools demonstrate the potential to support students' learning and\ninstructors' teaching, they also raise concerns about enabling unethical uses\nby students. Previous research has suggested various strategies aimed at\naddressing these issues. However, they concentrate on the introductory\nprogramming courses and focus on one specific type of problem. The present\nresearch evaluated the performance of ChatGPT, a state-of-the-art AI assistant,\nat solving 187 problems spanning three distinct types that were collected from\nsix undergraduate computer science. The selected courses covered different\ntopics and targeted different program levels. We then explored methods to\nmodify these problems to adapt them to ChatGPT's capabilities to reduce\npotential misuse by students. Finally, we conducted semi-structured interviews\nwith 11 computer science instructors. The aim was to gather their opinions on\nour problem modification methods, understand their perspectives on the impact\nof AI assistants on computer science education, and learn their strategies for\nadapting their courses to leverage these AI capabilities for educational\nimprovement. The results revealed issues ranging from academic fairness to\nlong-term impact on students' mental models. From our results, we derived\ndesign implications and recommended tools to help instructors design and create\nfuture course material that could more effectively adapt to AI assistants'\ncapabilities.\n",
                "链接": "https://arxiv.org/abs/2306.03289"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下2023年关于LLM-based Agent的综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "106067",
                "标题": "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with\n  Agent Team Optimization",
                "作者": " Zijun Liu,  Yanzhe Zhang,  Peng Li,  Yang Liu,  Diyi Yang",
                "发布日期": "2023-10-04",
                "摘要": "  Large language model (LLM) agents have been shown effective on a wide range\nof tasks, and by ensembling multiple LLM agents, their performances could be\nfurther improved. Existing approaches employ a fixed set of agents to interact\nwith each other in a static architecture, which limits their generalizability\nto various tasks and requires strong human prior in designing these agents. In\nthis work, we propose to construct a strategic team of agents communicating in\na dynamic interaction architecture based on the task query. Specifically, we\nbuild a framework named Dynamic LLM-Agent Network ($\\textbf{DyLAN}$) for\nLLM-agent collaboration on complicated tasks like reasoning and code\ngeneration. DyLAN enables agents to interact for multiple rounds in a dynamic\narchitecture with inference-time agent selection and an early-stopping\nmechanism to improve performance and efficiency. We further design an automatic\nagent team optimization algorithm based on an unsupervised metric termed\n$\\textit{Agent Importance Score}$, enabling the selection of best agents based\non the contribution each agent makes. Empirically, we demonstrate that DyLAN\nperforms well in both reasoning and code generation tasks with reasonable\ncomputational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and\nHumanEval, respectively, compared to a single execution on GPT-35-turbo. On\nspecific subjects of MMLU, agent team optimization in DyLAN increases accuracy\nby up to 25.0%.\n",
                "链接": "https://arxiv.org/abs/2310.02170"
            },
            {
                "文章ID": "110807",
                "标题": "LLM-Based Agent Society Investigation: Collaboration and Confrontation\n  in Avalon Gameplay",
                "作者": " Yihuai Lan,  Zhiqiang Hu,  Lei Wang,  Yang Wang,  Deheng Ye,  Peilin Zhao,  Ee-Peng Lim,  Hui Xiong,  Hao Wang",
                "发布日期": "2023-10-24",
                "摘要": "  This paper aims to investigate the open research problem of uncovering the\nsocial behaviors of LLM-based agents. To achieve this goal, we adopt Avalon, a\nrepresentative communication game, as the environment and use system prompts to\nguide LLM agents to play the game. While previous studies have conducted\npreliminary investigations into gameplay with LLM agents, there lacks research\non their social behaviors. In this paper, we present a novel framework designed\nto seamlessly adapt to Avalon gameplay. The core of our proposed framework is a\nmulti-agent system that enables efficient communication and interaction among\nagents. We evaluate the performance of our framework based on metrics from two\nperspectives: winning the game and analyzing the social behaviors of LLM\nagents. Our results demonstrate the effectiveness of our framework in\ngenerating adaptive and intelligent agents and highlight the potential of\nLLM-based agents in addressing the challenges associated with dynamic social\nenvironment interaction. By analyzing the social behaviors of LLM agents from\nthe aspects of both collaboration and confrontation, we provide insights into\nthe research and applications of this domain.\n",
                "链接": "https://arxiv.org/abs/2310.14985"
            },
            {
                "文章ID": "120758",
                "标题": "LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent\n  Ecosystem",
                "作者": " Yingqiang Ge,  Yujie Ren,  Wenyue Hua,  Shuyuan Xu,  Juntao Tan,  Yongfeng Zhang",
                "发布日期": "2023-12-12",
                "摘要": "  This paper envisions a revolutionary AIOS-Agent ecosystem, where Large\nLanguage Model (LLM) serves as the (Artificial) Intelligent Operating System\n(IOS, or AIOS)--an operating system \"with soul\". Upon this foundation, a\ndiverse range of LLM-based AI Agent Applications (Agents, or AAPs) are\ndeveloped, enriching the AIOS-Agent ecosystem and signaling a paradigm shift\nfrom the traditional OS-APP ecosystem. We envision that LLM's impact will not\nbe limited to the AI application level, instead, it will in turn revolutionize\nthe design and implementation of computer system, architecture, software, and\nprogramming language, featured by several main concepts: LLM as OS\n(system-level), Agents as Applications (application-level), Natural Language as\nProgramming Interface (user-level), and Tools as Devices/Libraries\n(hardware/middleware-level). We begin by introducing the architecture of\ntraditional OS. Then we formalize a conceptual framework for AIOS through \"LLM\nas OS (LLMOS)\", drawing analogies between AIOS and traditional OS: LLM is\nlikened to OS kernel, context window to memory, external storage to file\nsystem, hardware tools to peripheral devices, software tools to programming\nlibraries, and user prompts to user commands. Subsequently, we introduce the\nnew AIOS-Agent Ecosystem, where users can easily program Agent Applications\n(AAPs) using natural language, democratizing the development of software, which\nis different from the traditional OS-APP ecosystem. Following this, we explore\nthe diverse scope of Agent Applications. We delve into both single-agent and\nmulti-agent systems, as well as human-agent interaction. Lastly, drawing on the\ninsights from traditional OS-APP ecosystem, we propose a roadmap for the\nevolution of the AIOS-Agent ecosystem. This roadmap is designed to guide the\nfuture research and development, suggesting systematic progresses of AIOS and\nits Agent applications.\n",
                "链接": "https://arxiv.org/abs/2312.03815"
            },
            {
                "文章ID": "75893",
                "标题": "LLM-RM at SemEval-2023 Task 2: Multilingual Complex NER using\n  XLM-RoBERTa",
                "作者": " Rahul Mehta,  Vasudeva Varma",
                "发布日期": "2023-05-08",
                "摘要": "  Named Entity Recognition(NER) is a task of recognizing entities at a token\nlevel in a sentence. This paper focuses on solving NER tasks in a multilingual\nsetting for complex named entities. Our team, LLM-RM participated in the\nrecently organized SemEval 2023 task, Task 2: MultiCoNER II,Multilingual\nComplex Named Entity Recognition. We approach the problem by leveraging\ncross-lingual representation provided by fine-tuning XLM-Roberta base model on\ndatasets of all of the 12 languages provided -- Bangla, Chinese, English,\nFarsi, French, German, Hindi, Italian, Portuguese, Spanish, Swedish and\nUkrainian\n",
                "链接": "https://arxiv.org/abs/2305.03300"
            },
            {
                "文章ID": "118628",
                "标题": "Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld",
                "作者": " Yijun Yang,  Tianyi Zhou,  Kanxue Li,  Dapeng Tao,  Lusong Li,  Li Shen,  Xiaodong He,  Jing Jiang,  Yuhui Shi",
                "发布日期": "2023-11-29",
                "摘要": "  While large language models (LLMs) excel in a simulated world of texts, they\nstruggle to interact with the more realistic world without perceptions of other\nmodalities such as visual or audio signals. Although vision-language models\n(VLMs) integrate LLM modules (1) aligned with static image features, and (2)\nmay possess prior knowledge of world dynamics (as demonstrated in the text\nworld), they have not been trained in an embodied visual world and thus cannot\nalign with its dynamics. On the other hand, training an embodied agent in a\nnoisy visual world without expert guidance is often challenging and\ninefficient. In this paper, we train a VLM agent living in a visual world using\nan LLM agent excelling in a parallel text world (but inapplicable to the visual\nworld). Specifically, we distill LLM's reflection outcomes (improved actions by\nanalyzing mistakes) in a text world's tasks to finetune the VLM on the same\ntasks of the visual world, resulting in an Embodied Multi-Modal Agent (EMMA)\nquickly adapting to the visual world dynamics. Such cross-modality imitation\nlearning between the two parallel worlds enables EMMA to generalize to a broad\nscope of new tasks without any further guidance from the LLM expert. Extensive\nevaluations on the ALFWorld benchmark highlight EMMA's superior performance to\nSOTA VLM-based agents across diverse tasks, e.g., 20%-70% improvement in the\nsuccess rate.\n",
                "链接": "https://arxiv.org/abs/2311.16714"
            },
            {
                "文章ID": "102166",
                "标题": "LASER: LLM Agent with State-Space Exploration for Web Navigation",
                "作者": " Kaixin Ma,  Hongming Zhang,  Hongwei Wang,  Xiaoman Pan,  Dong Yu",
                "发布日期": "2023-09-18",
                "摘要": "  Large language models (LLMs) have been successfully adapted for interactive\ndecision-making tasks like web navigation. While achieving decent performance,\nprevious methods implicitly assume a forward-only execution mode for the model,\nwhere they only provide oracle trajectories as in-context examples to teach the\nmodel how to reason in the interactive environment. Consequently, the model\ncould not handle more challenging scenarios not covered in the in-context\nexamples, e.g., mistakes, leading to sub-optimal performance. To address this\nissue, we propose to model the interactive task as state space exploration,\nwhere the LLM agent transitions among a pre-defined set of states by performing\nactions to complete the task. This formulation enables flexible back-tracking,\nallowing the model to easily recover from errors. We evaluate our proposed LLM\nAgent with State-Space ExploRation (LASER) on the WebShop task. Experimental\nresults show that our LASER agent significantly outperforms previous methods\nand closes the gap with human performance on the web navigation task.\n",
                "链接": "https://arxiv.org/abs/2309.08172"
            },
            {
                "文章ID": "117600",
                "标题": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and\n  Character Design",
                "作者": " Yangyang Yu,  Haohang Li,  Zhi Chen,  Yuechen Jiang,  Yang Li,  Denghui Zhang,  Rong Liu,  Jordan W. Suchow,  Khaldoun Khashanah",
                "发布日期": "2023-12-05",
                "摘要": "  Recent advancements in Large Language Models (LLMs) have exhibited notable\nefficacy in question-answering (QA) tasks across diverse domains. Their prowess\nin integrating extensive web knowledge has fueled interest in developing\nLLM-based autonomous agents. While LLMs are efficient in decoding human\ninstructions and deriving solutions by holistically processing historical\ninputs, transitioning to purpose-driven agents requires a supplementary\nrational architecture to process multi-source information, establish reasoning\nchains, and prioritize critical tasks. Addressing this, we introduce\n\\textsc{FinMem}, a novel LLM-based agent framework devised for financial\ndecision-making. It encompasses three core modules: Profiling, to customize the\nagent's characteristics; Memory, with layered message processing, to aid the\nagent in assimilating hierarchical financial data; and Decision-making, to\nconvert insights gained from memories into investment decisions. Notably,\n\\textsc{FinMem}'s memory module aligns closely with the cognitive structure of\nhuman traders, offering robust interpretability and real-time tuning. Its\nadjustable cognitive span allows for the retention of critical information\nbeyond human perceptual limits, thereby enhancing trading outcomes. This\nframework enables the agent to self-evolve its professional knowledge, react\nagilely to new investment cues, and continuously refine trading decisions in\nthe volatile financial environment. We first compare \\textsc{FinMem} with\nvarious algorithmic agents on a scalable real-world financial dataset,\nunderscoring its leading trading performance in stocks. We then fine-tuned the\nagent's perceptual span and character setting to achieve a significantly\nenhanced trading performance. Collectively, \\textsc{FinMem} presents a\ncutting-edge LLM agent framework for automated trading, boosting cumulative\ninvestment returns.\n",
                "链接": "https://arxiv.org/abs/2311.13743"
            },
            {
                "文章ID": "108435",
                "标题": "Formally Specifying the High-Level Behavior of LLM-Based Agents",
                "作者": " Maxwell Crouse,  Ibrahim Abdelaziz,  Kinjal Basu,  Soham Dan,  Sadhana Kumaravel,  Achille Fokoue,  Pavan Kapanipathi,  Luis Lastras",
                "发布日期": "2023-10-13",
                "摘要": "  LLM-based agents have recently emerged as promising tools for solving\nchallenging problems without the need for task-specific finetuned models that\ncan be expensive to procure. Currently, the design and implementation of such\nagents is ad hoc, as the wide variety of tasks that LLM-based agents may be\napplied to naturally means there can be no one-size-fits-all approach to agent\ndesign. In this work we aim to alleviate the difficulty of designing and\nimplementing new agents by proposing a minimalistic, high-level generation\nframework that simplifies the process of building agents. The framework we\nintroduce allows the user to specify desired agent behaviors in Linear Temporal\nLogic (LTL). The declarative LTL specification is then used to construct a\nconstrained decoder that guarantees the LLM will produce an output exhibiting\nthe desired behavior. By designing our framework in this way, we obtain several\nbenefits, including the ability to enforce complex agent behavior, the ability\nto formally validate prompt examples, and the ability to seamlessly incorporate\ncontent-focused logical constraints into generation. In particular, our\ndeclarative approach, in which the desired behavior is simply described without\nconcern for how it should be implemented or enforced, enables rapid design,\nimplementation and experimentation with different LLM-based agents. We\ndemonstrate how the proposed framework can be used to implement recent\nLLM-based agents, and show how the guardrails our approach provides can lead to\nimprovements in agent performance. In addition, we release our code for general\nuse.\n",
                "链接": "https://arxiv.org/abs/2310.08535"
            },
            {
                "文章ID": "83996",
                "标题": "Enabling Intelligent Interactions between an Agent and an LLM: A\n  Reinforcement Learning Approach",
                "作者": " Bin Hu,  Chenyang Zhao,  Pu Zhang,  Zihao Zhou,  Yuanhang Yang,  Zenglin Xu,  Bin Liu",
                "发布日期": "2023-09-01",
                "摘要": "  Large language models (LLMs) encode a vast amount of world knowledge acquired\nfrom massive text datasets. Recent studies have demonstrated that LLMs can\nassist an embodied agent in solving complex sequential decision making tasks by\nproviding high-level instructions. However, interactions with LLMs can be\ntime-consuming. In many practical scenarios, they require a significant amount\nof storage space that can only be deployed on remote cloud server nodes.\nAdditionally, using commercial LLMs can be costly since they may charge based\non usage frequency. In this paper, we explore how to enable intelligent\ncost-effective interactions between the agent and an LLM. We propose When2Ask,\na reinforcement learning based approach that learns when it is necessary to\nquery LLMs for high-level instructions to accomplish a target task. Experiments\non MiniGrid and Habitat environments that entail planning sub-goals demonstrate\nthat When2Ask learns to solve target tasks with only a few necessary\ninteractions with an LLM, and significantly reduces interaction costs in\ntesting environments compared with baseline methods. Experiment results also\nsuggest that by learning a mediator model to interact with the LLM, the agent's\nperformance becomes more robust against partial observability of the\nenvironment. Our code is available at https://github.com/ZJLAB-AMMI/LLM4RL.\n",
                "链接": "https://arxiv.org/abs/2306.03604"
            },
            {
                "文章ID": "122965",
                "标题": "ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent",
                "作者": " Renat Aksitov,  Sobhan Miryoosefi,  Zonglin Li,  Daliang Li,  Sheila Babayan,  Kavya Kopparapu,  Zachary Fisher,  Ruiqi Guo,  Sushant Prakash,  Pranesh Srinivasan,  Manzil Zaheer,  Felix Yu,  Sanjiv Kumar",
                "发布日期": "2023-12-18",
                "摘要": "  Answering complex natural language questions often necessitates multi-step\nreasoning and integrating external information. Several systems have combined\nknowledge retrieval with a large language model (LLM) to answer such questions.\nThese systems, however, suffer from various failure cases, and we cannot\ndirectly train them end-to-end to fix such failures, as interaction with\nexternal knowledge is non-differentiable. To address these deficiencies, we\ndefine a ReAct-style LLM agent with the ability to reason and act upon external\nknowledge. We further refine the agent through a ReST-like method that\niteratively trains on previous trajectories, employing growing-batch\nreinforcement learning with AI feedback for continuous self-improvement and\nself-distillation. Starting from a prompted large model and after just two\niterations of the algorithm, we can produce a fine-tuned small model that\nachieves comparable performance on challenging compositional question-answering\nbenchmarks with two orders of magnitude fewer parameters.\n",
                "链接": "https://arxiv.org/abs/2312.10003"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近三个月有关语言模型rlhf的arxiv上的全部文章。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大模型结合树搜索方法进行推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "73991",
                "标题": "Combining Monte Carlo Tree Search and Heuristic Search for Weighted\n  Vertex Coloring",
                "作者": " Cyril Grelier,  Olivier Goudet,  Jin-Kao Hao",
                "发布日期": "2023-04-25",
                "摘要": "  This work investigates the Monte Carlo Tree Search (MCTS) method combined\nwith dedicated heuristics for solving the Weighted Vertex Coloring Problem. In\naddition to the basic MCTS algorithm, we study several MCTS variants where the\nconventional random simulation is replaced by other simulation strategies\nincluding greedy and local search heuristics. We conduct experiments on\nwell-known benchmark instances to assess these combined MCTS variants. We\nprovide empirical evidence to shed light on the advantages and limits of each\nsimulation strategy. This is an extension of the work of Grelier and al.\npresented at EvoCOP2022.\n",
                "链接": "https://arxiv.org/abs/2304.12146"
            },
            {
                "文章ID": "103683",
                "标题": "The Mathematical Game",
                "作者": " Marc Pierre,  Quentin Cohen-Solal,  Tristan Cazenave",
                "发布日期": "2023-09-25",
                "摘要": "  Monte Carlo Tree Search can be used for automated theorem proving. Holophrasm\nis a neural theorem prover using MCTS combined with neural networks for the\npolicy and the evaluation. In this paper we propose to improve the performance\nof the Holophrasm theorem prover using other game tree search algorithms.\n",
                "链接": "https://arxiv.org/abs/2309.12711"
            },
            {
                "文章ID": "105172",
                "标题": "Alphazero-like Tree-Search can Guide Large Language Model Decoding and\n  Training",
                "作者": " Xidong Feng,  Ziyu Wan,  Muning Wen,  Ying Wen,  Weinan Zhang,  Jun Wang",
                "发布日期": "2023-10-02",
                "摘要": "  Large language models (LLMs) typically employ sampling or beam search,\naccompanied by prompts such as Chain-of-Thought (CoT), to boost reasoning and\ndecoding ability. Recent work like Tree-of-Thought (ToT) and Reasoning via\nPlanning (RAP) aim to augment the reasoning capabilities of LLMs by utilizing\ntree-search algorithms to guide multi-step reasoning. These methods mainly\nfocus on LLMs' reasoning ability during inference and heavily rely on\nhuman-designed prompts to activate LLM as a value function, which lacks general\napplicability and scalability. To address these limitations, we present an\nAlphaZero-like tree-search framework for LLMs (termed TS-LLM), systematically\nillustrating how tree-search with a learned value function can guide LLMs'\ndecoding ability. TS-LLM distinguishes itself in two key ways: (1) Leveraging a\nlearned value function, our approach can be generally applied to different\ntasks beyond reasoning (such as RLHF alignment), and LLMs of any size, without\nprompting advanced, large-scale models. (2) It can guide LLM's decoding during\nboth inference and training. Empirical evaluations across reasoning, planning,\nand RLHF alignment tasks validate the effectiveness of TS-LLM, even on trees\nwith a depth of 64.\n",
                "链接": "https://arxiv.org/abs/2309.17179"
            },
            {
                "文章ID": "104202",
                "标题": "Combined sizing and layout optimization of truss structures via update\n  Monte Carlo tree search (UMCTS) algorithm",
                "作者": " Fu-Yao Ko,  Katsuyuki Suzuki,  Kazuo Yonekura",
                "发布日期": "2023-09-26",
                "摘要": "  The main concern of this study is to find the optimal design of truss\nstructures considering sizing and layout variables simultaneously. As compared\nto purely sizing optimization problems, this problem is more challenging since\nthe two types of variables involved are fundamentally different in nature. In\nthis paper, a reinforcement learning method combining the update process and\nMonte Carlo tree search called the update Monte Carlo tree search (UMCTS) for\nsizing optimization problems is applied to solve combined sizing and layout\noptimization for truss structures. This study proposes a novel update process\nfor nodal coordinates with two features. (1) The allowed range of each\ncoordinate varies in each round. (2) Accelerators for the number of entries in\nthe allowed range and iteration numbers are introduced to reduce the\ncomputation time. Furthermore, nodal coordinates and member areas are\ndetermined at the same time with only one search tree in each round. The\nvalidation and efficiency of the UMCTS are tested on benchmark problems of\nplanar and spatial trusses with discrete sizing variables and continuous layout\nvariables. It is shown that the CPU time of the UMCTS is two times faster than\nthe branch and bound method. The numerical results demonstrate that the\nproposed method stably achieves a better solution than other traditional\nmethods.\n",
                "链接": "https://arxiv.org/abs/2309.14231"
            },
            {
                "文章ID": "3914",
                "标题": "On Monte Carlo Tree Search for Weighted Vertex Coloring",
                "作者": " Cyril Grelier,  Olivier Goudet,  Jin-Kao Hao",
                "发布日期": "2022-04-08",
                "摘要": "  This work presents the first study of using the popular Monte Carlo Tree\nSearch (MCTS) method combined with dedicated heuristics for solving the\nWeighted Vertex Coloring Problem. Starting with the basic MCTS algorithm, we\ngradually introduce a number of algorithmic variants where MCTS is extended by\nvarious simulation strategies including greedy and local search heuristics. We\nconduct experiments on well-known benchmark instances to assess the value of\neach studied combination. We also provide empirical evidence to shed light on\nthe advantages and limits of each strategy.\n",
                "链接": "https://arxiv.org/abs/2202.01665"
            },
            {
                "文章ID": "6529",
                "标题": "Transition Matrix Representation of Trees with Transposed Convolutions",
                "作者": " Jaemin Yoo,  Lee Sael",
                "发布日期": "2022-02-23",
                "摘要": "  How can we effectively find the best structures in tree models? Tree models\nhave been favored over complex black box models in domains where\ninterpretability is crucial for making irreversible decisions. However,\nsearching for a tree structure that gives the best balance between the\nperformance and the interpretability remains a challenging task. In this paper,\nwe propose TART (Transition Matrix Representation with Transposed\nConvolutions), our novel generalized tree representation for optimal structural\nsearch. TART represents a tree model with a series of transposed convolutions\nthat boost the speed of inference by avoiding the creation of transition\nmatrices. As a result, TART allows one to search for the best tree structure\nwith a few design parameters, achieving higher classification accuracy than\nthose of baseline models in feature-based datasets.\n",
                "链接": "https://arxiv.org/abs/2202.10677"
            },
            {
                "文章ID": "105246",
                "标题": "Tree Cross Attention",
                "作者": " Leo Feng,  Frederick Tung,  Hossein Hajimirsadeghi,  Yoshua Bengio,  Mohamed Osama Ahmed",
                "发布日期": "2023-10-02",
                "摘要": "  Cross Attention is a popular method for retrieving information from a set of\ncontext tokens for making predictions. At inference time, for each prediction,\nCross Attention scans the full set of $\\mathcal{O}(N)$ tokens. In practice,\nhowever, often only a small subset of tokens are required for good performance.\nMethods such as Perceiver IO are cheap at inference as they distill the\ninformation to a smaller-sized set of latent tokens $L < N$ on which cross\nattention is then applied, resulting in only $\\mathcal{O}(L)$ complexity.\nHowever, in practice, as the number of input tokens and the amount of\ninformation to distill increases, the number of latent tokens needed also\nincreases significantly. In this work, we propose Tree Cross Attention (TCA) -\na module based on Cross Attention that only retrieves information from a\nlogarithmic $\\mathcal{O}(\\log(N))$ number of tokens for performing inference.\nTCA organizes the data in a tree structure and performs a tree search at\ninference time to retrieve the relevant tokens for prediction. Leveraging TCA,\nwe introduce ReTreever, a flexible architecture for token-efficient inference.\nWe show empirically that Tree Cross Attention (TCA) performs comparable to\nCross Attention across various classification and uncertainty regression tasks\nwhile being significantly more token-efficient. Furthermore, we compare\nReTreever against Perceiver IO, showing significant gains while using the same\nnumber of tokens for inference.\n",
                "链接": "https://arxiv.org/abs/2309.17388"
            },
            {
                "文章ID": "109239",
                "标题": "Autonomous Tree-search Ability of Large Language Models",
                "作者": " Zheyu Zhang,  Zhuorui Ye,  Yikang Shen,  Chuang Gan",
                "发布日期": "2023-10-18",
                "摘要": "  Large Language Models have excelled in remarkable reasoning capabilities with\nadvanced prompting techniques, but they fall short on tasks that require\nexploration, strategic foresight, and sequential decision-making. Recent works\npropose to utilize external programs to define search logic, such that LLMs can\nperform passive tree search to solve more challenging reasoning tasks. Though\nimpressive results have been achieved, there are several fundamental\nlimitations of these approaches. First, passive tree searches are not efficient\nas they usually require multiple rounds of LLM API calls to solve one single\nproblem. Moreover, passive search methods are not flexible since they need\ntask-specific program designs. Then a natural question arises: can we maintain\nthe tree-search capability of LLMs without the aid of external programs, and\ncan still generate responses that clearly demonstrate the process of a\ntree-structure search? To this end, we propose a new concept called autonomous\ntree-search ability of LLM, which can automatically generate a response\ncontaining search trajectories for the correct answer. Concretely, we perform\nsearch trajectories using capable LLM API via a fixed system prompt, allowing\nthem to perform autonomous tree-search (ATS) right out of the box. Experiments\non 4 puzzle games demonstrate our method can achieve huge improvements. The\nATS-BFS method outperforms the Chain of Thought approach by achieving an\naverage accuracy improvement of 33%. Compared to Tree of Thoughts, it requires\n65.6% or 47.7% less GPT-api cost to attain a comparable level of accuracy.\nMoreover, we have collected data using the ATS prompt method and fine-tuned\nLLaMA. This approach yield a greater improvement compared to the ones\nfine-tuned on CoT data. Specifically, it outperforms CoT-tuned LLaMAs by an\naverage of 40.6% and 38.5% for LLaMA2-7B and LLaMA2-13B, respectively.\n",
                "链接": "https://arxiv.org/abs/2310.10686"
            },
            {
                "文章ID": "78273",
                "标题": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
                "作者": " Shunyu Yao,  Dian Yu,  Jeffrey Zhao,  Izhak Shafran,  Thomas L. Griffiths,  Yuan Cao,  Karthik Narasimhan",
                "发布日期": "2023-12-05",
                "摘要": "  Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nhttps://github.com/princeton-nlp/tree-of-thought-llm.\n",
                "链接": "https://arxiv.org/abs/2305.10601"
            },
            {
                "文章ID": "78585",
                "标题": "Writing your own book: A method for going from closed to open book QA to\n  improve robustness and performance of smaller LLMs",
                "作者": " Giorgi Kokaia,  Pratyush Sinha,  Yutong Jiang,  Nozha Boujemaa",
                "发布日期": "2023-05-22",
                "摘要": "  We introduce two novel methods, Tree-Search and Self-contextualizing QA,\ndesigned to enhance the performance of large language models (LLMs) in\nquestion-answering tasks. Tree-Search is a sampling technique specifically\ncreated to extract diverse information from an LLM for a given prompt.\nSelf-contextualizing QA leverages Tree-Search to enable the model to create its\nown context using a wide range of information relevant to the prompt, evaluate\nit explicitly and return a open book answer to the initial prompt . We\ndemonstrate that the quality of generated answers improves according to various\nmetrics, including accuracy, informativeness, coherence, and consistency, as\nevaluated by GPT3.5(text-davinci-003). Furthermore, we show that our methods\nresult in increased robustness and that performance is positively correlated\nwith tree size, benefiting both answer quality and robustness. Finally, we\ndiscuss other promising applications of Tree-Search, highlighting its potential\nto enhance a broad range of tasks beyond question-answering.\n  \\noindent We also discuss several areas for future work, including refining\nthe Tree-Search and Self-Contextualizing QA methods, improving the coherence of\nthe generated context, and investigating the impact of bootstrapping on model\nrobustness\n",
                "链接": "https://arxiv.org/abs/2305.11334"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于通过prompt经验性研究大语言模型行为的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "96394",
                "标题": "Exploring the Intersection of Large Language Models and Agent-Based\n  Modeling via Prompt Engineering",
                "作者": " Edward Junprung",
                "发布日期": "2023-08-16",
                "摘要": "  The final frontier for simulation is the accurate representation of complex,\nreal-world social systems. While agent-based modeling (ABM) seeks to study the\nbehavior and interactions of agents within a larger system, it is unable to\nfaithfully capture the full complexity of human-driven behavior. Large language\nmodels (LLMs), like ChatGPT, have emerged as a potential solution to this\nbottleneck by enabling researchers to explore human-driven interactions in\npreviously unimaginable ways. Our research investigates simulations of human\ninteractions using LLMs. Through prompt engineering, inspired by Park et al.\n(2023), we present two simulations of believable proxies of human behavior: a\ntwo-agent negotiation and a six-agent murder mystery game.\n",
                "链接": "https://arxiv.org/abs/2308.07411"
            },
            {
                "文章ID": "93410",
                "标题": "A LLM Assisted Exploitation of AI-Guardian",
                "作者": " Nicholas Carlini",
                "发布日期": "2023-07-28",
                "摘要": "  Large language models (LLMs) are now highly capable at a diverse range of\ntasks. This paper studies whether or not GPT-4, one such LLM, is capable of\nassisting researchers in the field of adversarial machine learning. As a case\nstudy, we evaluate the robustness of AI-Guardian, a recent defense to\nadversarial examples published at IEEE S&P 2023, a top computer security\nconference. We completely break this defense: the proposed scheme does not\nincrease robustness compared to an undefended baseline.\n  We write none of the code to attack this model, and instead prompt GPT-4 to\nimplement all attack algorithms following our instructions and guidance. This\nprocess was surprisingly effective and efficient, with the language model at\ntimes producing code from ambiguous instructions faster than the author of this\npaper could have done. We conclude by discussing (1) the warning signs present\nin the evaluation that suggested to us AI-Guardian would be broken, and (2) our\nexperience with designing attacks and performing novel research using the most\nrecent advances in language modeling.\n",
                "链接": "https://arxiv.org/abs/2307.15008"
            },
            {
                "文章ID": "85341",
                "标题": "Large language models and (non-)linguistic recursion",
                "作者": " Maksymilian Dąbkowski,  Gašper Beguš",
                "发布日期": "2023-06-13",
                "摘要": "  Recursion is one of the hallmarks of human language. While many design\nfeatures of language have been shown to exist in animal communication systems,\nrecursion has not. Previous research shows that GPT-4 is the first large\nlanguage model (LLM) to exhibit metalinguistic abilities (Begu\\v{s},\nD\\k{a}bkowski, and Rhodes 2023). Here, we propose several prompt designs aimed\nat eliciting and analyzing recursive behavior in LLMs, both linguistic and\nnon-linguistic. We demonstrate that when explicitly prompted, GPT-4 can both\nproduce and analyze recursive structures. Thus, we present one of the first\nstudies investigating whether meta-linguistic awareness of recursion -- a\nuniquely human cognitive property -- can emerge in transformers with a high\nnumber of parameters such as GPT-4.\n",
                "链接": "https://arxiv.org/abs/2306.07195"
            },
            {
                "文章ID": "63456",
                "标题": "Robot Behavior-Tree-Based Task Generation with Large Language Models",
                "作者": " Yue Cao,  C. S. George Lee",
                "发布日期": "2023-02-28",
                "摘要": "  Nowadays, the behavior tree is gaining popularity as a representation for\nrobot tasks due to its modularity and reusability. Designing behavior-tree\ntasks manually is time-consuming for robot end-users, thus there is a need for\ninvestigating automatic behavior-tree-based task generation. Prior\nbehavior-tree-based task generation approaches focus on fixed primitive tasks\nand lack generalizability to new task domains. To cope with this issue, we\npropose a novel behavior-tree-based task generation approach that utilizes\nstate-of-the-art large language models. We propose a Phase-Step prompt design\nthat enables a hierarchical-structured robot task generation and further\nintegrate it with behavior-tree-embedding-based search to set up the\nappropriate prompt. In this way, we enable an automatic and cross-domain\nbehavior-tree task generation. Our behavior-tree-based task generation approach\ndoes not require a set of pre-defined primitive tasks. End-users only need to\ndescribe an abstract desired task and our proposed approach can swiftly\ngenerate the corresponding behavior tree. A full-process case study is provided\nto demonstrate our proposed approach. An ablation study is conducted to\nevaluate the effectiveness of our Phase-Step prompts. Assessment on Phase-Step\nprompts and the limitation of large language models are presented and\ndiscussed.\n",
                "链接": "https://arxiv.org/abs/2302.12927"
            },
            {
                "文章ID": "96879",
                "标题": "Large Language Models at Work in China's Labor Market",
                "作者": " Qin Chen,  Jinfeng Ge,  Huaqing Xie,  Xingcheng Xu,  Yanqing Yang",
                "发布日期": "2023-08-21",
                "摘要": "  This paper explores the potential impacts of large language models (LLMs) on\nthe Chinese labor market. We analyze occupational exposure to LLM capabilities\nby incorporating human expertise and LLM classifications, following Eloundou et\nal. (2023)'s methodology. We then aggregate occupation exposure to the industry\nlevel to obtain industry exposure scores. The results indicate a positive\ncorrelation between occupation exposure and wage levels/experience premiums,\nsuggesting higher-paying and experience-intensive jobs may face greater\ndisplacement risks from LLM-powered software. The industry exposure scores\nalign with expert assessments and economic intuitions. We also develop an\neconomic growth model incorporating industry exposure to quantify the\nproductivity-employment trade-off from AI adoption. Overall, this study\nprovides an analytical basis for understanding the labor market impacts of\nincreasingly capable AI systems in China. Key innovations include the\noccupation-level exposure analysis, industry aggregation approach, and economic\nmodeling incorporating AI adoption and labor market effects. The findings will\ninform policymakers and businesses on strategies for maximizing the benefits of\nAI while mitigating adverse disruption risks.\n",
                "链接": "https://arxiv.org/abs/2308.08776"
            },
            {
                "文章ID": "103247",
                "标题": "Safurai 001: New Qualitative Approach for Code LLM Evaluation",
                "作者": " Davide Cifarelli,  Leonardo Boiardi,  Alessandro Puppo",
                "发布日期": "2023-09-21",
                "摘要": "  This paper presents Safurai-001, a new Large Language Model (LLM) with\nsignificant potential in the domain of coding assistance. Driven by recent\nadvancements in coding LLMs, Safurai-001 competes in performance with the\nlatest models like WizardCoder [Xu et al., 2023], PanguCoder [Shen et al.,\n2023] and Phi-1 [Gunasekar et al., 2023] but aims to deliver a more\nconversational interaction. By capitalizing on the progress in data engineering\n(including latest techniques of data transformation and prompt engineering) and\ninstruction tuning, this new model promises to stand toe-to-toe with recent\nclosed and open source developments. Recognizing the need for an efficacious\nevaluation metric for coding LLMs, this paper also introduces GPT4-based\nMultiParameters, an evaluation benchmark that harnesses varied parameters to\npresent a comprehensive insight into the models functioning and performance.\nOur assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and\nWizardCoder by 18.78% in the Code Readability parameter and more.\n",
                "链接": "https://arxiv.org/abs/2309.11385"
            },
            {
                "文章ID": "74013",
                "标题": "Performance of ChatGPT on the US Fundamentals of Engineering Exam:\n  Comprehensive Assessment of Proficiency and Potential Implications for\n  Professional Environmental Engineering Practice",
                "作者": " Vinay Pursnani,  Yusuf Sermet,  Ibrahim Demir",
                "发布日期": "2023-04-25",
                "摘要": "  In recent years, advancements in artificial intelligence (AI) have led to the\ndevelopment of large language models like GPT-4, demonstrating potential\napplications in various fields, including education. This study investigates\nthe feasibility and effectiveness of using ChatGPT, a GPT-4 based model, in\nachieving satisfactory performance on the Fundamentals of Engineering (FE)\nEnvironmental Exam. This study further shows a significant improvement in the\nmodel's accuracy when answering FE exam questions through noninvasive prompt\nmodifications, substantiating the utility of prompt modification as a viable\napproach to enhance AI performance in educational contexts. Furthermore, the\nfindings reflect remarkable improvements in mathematical capabilities across\nsuccessive iterations of ChatGPT models, showcasing their potential in solving\ncomplex engineering problems. Our paper also explores future research\ndirections, emphasizing the importance of addressing AI challenges in\neducation, enhancing accessibility and inclusion for diverse student\npopulations, and developing AI-resistant exam questions to maintain examination\nintegrity. By evaluating the performance of ChatGPT in the context of the FE\nEnvironmental Exam, this study contributes valuable insights into the potential\napplications and limitations of large language models in educational settings.\nAs AI continues to evolve, these findings offer a foundation for further\nresearch into the responsible and effective integration of AI models across\nvarious disciplines, ultimately optimizing the learning experience and\nimproving student outcomes.\n",
                "链接": "https://arxiv.org/abs/2304.12198"
            },
            {
                "文章ID": "90541",
                "标题": "Exploring Large Language Model for Graph Data Understanding in Online\n  Job Recommendations",
                "作者": " Likang Wu,  Zhaopeng Qiu,  Zhi Zheng,  Hengshu Zhu,  Enhong Chen",
                "发布日期": "2023-12-27",
                "摘要": "  Large Language Models (LLMs) have revolutionized natural language processing\ntasks, demonstrating their exceptional capabilities in various domains.\nHowever, their potential for behavior graph understanding in job\nrecommendations remains largely unexplored. This paper focuses on unveiling the\ncapability of large language models in understanding behavior graphs and\nleveraging this understanding to enhance recommendations in online recruitment,\nincluding the promotion of out-of-distribution (OOD) application. We present a\nnovel framework that harnesses the rich contextual information and semantic\nrepresentations provided by large language models to analyze behavior graphs\nand uncover underlying patterns and relationships. Specifically, we propose a\nmeta-path prompt constructor that leverages LLM recommender to understand\nbehavior graphs for the first time and design a corresponding path augmentation\nmodule to alleviate the prompt bias introduced by path-based sequence input. By\nleveraging this capability, our framework enables personalized and accurate job\nrecommendations for individual users. We evaluate the effectiveness of our\napproach on a comprehensive dataset and demonstrate its ability to improve the\nrelevance and quality of recommended quality. This research not only sheds\nlight on the untapped potential of large language models but also provides\nvaluable insights for developing advanced recommendation systems in the\nrecruitment market. The findings contribute to the growing field of natural\nlanguage processing and offer practical implications for enhancing job search\nexperiences. We release the code at https://github.com/WLiK/GLRec.\n",
                "链接": "https://arxiv.org/abs/2307.05722"
            },
            {
                "文章ID": "107897",
                "标题": "Diversity of Thought Improves Reasoning Abilities of Large Language\n  Models",
                "作者": " Ranjita Naik,  Varun Chandrasekaran,  Mert Yuksekgonul,  Hamid Palangi,  Besmira Nushi",
                "发布日期": "2023-10-12",
                "摘要": "  Large language models (LLMs) are documented to struggle in settings that\nrequire complex reasoning. Nevertheless, instructing the model to break down\nthe problem into smaller reasoning steps (Wei et al., 2022), or ensembling\nvarious generations through modifying decoding steps (Wang et al., 2023) boosts\nperformance. Current methods assume that the input prompt is fixed and expect\nthe decoding strategies to introduce the diversity needed for ensembling. In\nthis work, we relax this assumption and discuss how one can create and leverage\nvariations of the input prompt as a means to diversity of thought to improve\nmodel performance. We propose a method that automatically improves prompt\ndiversity by soliciting feedback from the LLM to ideate approaches that fit for\nthe problem. We then ensemble the diverse prompts in our method DIV-SE (DIVerse\nreasoning path Self-Ensemble) across multiple inference calls. We also propose\na cost-effective alternative where diverse prompts are used within a single\ninference call; we call this IDIV-SE (In-call DIVerse reasoning path\nSelf-Ensemble). Under a fixed generation budget, DIV-SE and IDIV-SE outperform\nthe previously discussed baselines using both GPT-3.5 and GPT-4 on several\nreasoning benchmarks, without modifying the decoding process. Additionally,\nDIV-SE advances state-of-the-art performance on recent planning benchmarks\n(Valmeekam et al., 2023), exceeding the highest previously reported accuracy by\nat least 29.6 percentage points on the most challenging 4/5 Blocksworld task.\nOur results shed light on how to enforce prompt diversity toward LLM reasoning\nand thereby improve the pareto frontier of the accuracy-cost trade-off.\n",
                "链接": "https://arxiv.org/abs/2310.07088"
            },
            {
                "文章ID": "119665",
                "标题": "Large Language Models for Travel Behavior Prediction",
                "作者": " Baichuan Mo,  Hanyong Xu,  Dingyi Zhuang,  Ruoyun Ma,  Xiaotong Guo,  Jinhua Zhao",
                "发布日期": "2023-12-05",
                "摘要": "  Travel behavior prediction is a fundamental task in transportation demand\nmanagement. The conventional methods for travel behavior prediction rely on\nnumerical data to construct mathematical models and calibrate model parameters\nto represent human preferences. Recent advancement in large language models\n(LLMs) has shown great reasoning abilities to solve complex problems. In this\nstudy, we propose to use LLMs to predict travel behavior with prompt\nengineering without data-based parameter learning. Specifically, we carefully\ndesign our prompts that include 1) task description, 2) travel characteristics,\n3) individual attributes, and 4) guides of thinking with domain knowledge, and\nask the LLMs to predict an individual's travel behavior and explain the\nresults. We select the travel mode choice task as a case study. Results show\nthat, though no training samples are provided, LLM-based predictions have\ncompetitive accuracy and F1-score as canonical supervised learning methods such\nas multinomial logit, random forest, and neural networks. LLMs can also output\nreasons that support their prediction. However, though in most of the cases,\nthe output explanations are reasonable, we still observe cases that violate\nlogic or with hallucinations.\n",
                "链接": "https://arxiv.org/abs/2312.00819"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态大模型理解和生成统一建模、端到端训练相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "118545",
                "标题": "GPT4Video: A Unified Multimodal Large Language Model for\n  lnstruction-Followed Understanding and Safety-Aware Generation",
                "作者": " Zhanyu Wang,  Longyue Wang,  Zhen Zhao,  Minghao Wu,  Chenyang Lyu,  Huayang Li,  Deng Cai,  Luping Zhou,  Shuming Shi,  Zhaopeng Tu",
                "发布日期": "2023-11-29",
                "摘要": "  While the recent advances in Multimodal Large Language Models (MLLMs)\nconstitute a significant leap forward in the field, these models are\npredominantly confined to the realm of input-side multimodal comprehension,\nlacking the capacity for multimodal content generation. To fill this gap, we\npresent GPT4Video, a unified multi-model framework that empowers Large Language\nModels (LLMs) with the capability of both video understanding and generation.\nSpecifically, we develop an instruction-following-based approach integrated\nwith the stable diffusion generative model, which has demonstrated to\neffectively and securely handle video generation scenarios. GPT4Video offers\nthe following benefits: 1) It exhibits impressive capabilities in both video\nunderstanding and generation scenarios. For example, GPT4Video outperforms\nValley by 11.8\\% on the Video Question Answering task, and surpasses NExt-GPT\nby 2.3\\% on the Text to Video generation task. 2) it endows the LLM/MLLM with\nvideo generation capabilities without requiring additional training parameters\nand can flexibly interface with a wide range of models to perform video\ngeneration. 3) it maintains a safe and healthy conversation not only in\noutput-side but also the input side in an end-to-end manner. Qualitative and\nqualitative experiments demonstrate that GPT4Video holds the potential to\nfunction as a effective, safe and Humanoid-like video assistant that can handle\nboth video understanding and generation scenarios.\n",
                "链接": "https://arxiv.org/abs/2311.16511"
            },
            {
                "文章ID": "21046",
                "标题": "End-to-End Multimodal Fact-Checking and Explanation Generation: A\n  Challenging Dataset and Models",
                "作者": "Virginia Tech  Barry Menglong Yao, Virginia Tech  Aditya Shah, Lehigh University  Lichao Sun, Virginia Tech  Jin-Hee Cho, Virginia Tech  Lifu Huang",
                "发布日期": "2023-07-10",
                "摘要": "  We propose end-to-end multimodal fact-checking and explanation generation,\nwhere the input is a claim and a large collection of web sources, including\narticles, images, videos, and tweets, and the goal is to assess the\ntruthfulness of the claim by retrieving relevant evidence and predicting a\ntruthfulness label (e.g., support, refute or not enough information), and to\ngenerate a statement to summarize and explain the reasoning and ruling process.\nTo support this research, we construct Mocheg, a large-scale dataset consisting\nof 15,601 claims where each claim is annotated with a truthfulness label and a\nruling statement, and 33,880 textual paragraphs and 12,112 images in total as\nevidence. To establish baseline performances on Mocheg, we experiment with\nseveral state-of-the-art neural architectures on the three pipelined subtasks:\nmultimodal evidence retrieval, claim verification, and explanation generation,\nand demonstrate that the performance of the state-of-the-art end-to-end\nmultimodal fact-checking does not provide satisfactory outcomes. To the best of\nour knowledge, we are the first to build the benchmark dataset and solutions\nfor end-to-end multimodal fact-checking and explanation generation. The\ndataset, source code and model checkpoints are available at\nhttps://github.com/VT-NLP/Mocheg.\n",
                "链接": "https://arxiv.org/abs/2205.12487"
            },
            {
                "文章ID": "2020",
                "标题": "End-to-end Generative Pretraining for Multimodal Video Captioning",
                "作者": " Paul Hongsuck Seo,  Arsha Nagrani,  Anurag Arnab,  Cordelia Schmid",
                "发布日期": "2022-05-11",
                "摘要": "  Recent video and language pretraining frameworks lack the ability to generate\nsentences. We present Multimodal Video Generative Pretraining (MV-GPT), a new\npretraining framework for learning from unlabelled videos which can be\neffectively used for generative tasks such as multimodal video captioning.\nUnlike recent video-language pretraining frameworks, our framework trains both\na multimodal video encoder and a sentence decoder jointly. To overcome the lack\nof captions in unlabelled videos, we leverage the future utterance as an\nadditional text source and propose a bidirectional generation objective -- we\ngenerate future utterances given the present mulitmodal context, and also the\npresent utterance given future observations. With this objective, we train an\nencoder-decoder model end-to-end to generate a caption from raw pixels and\ntranscribed speech directly. Our model achieves state-of-the-art performance\nfor multimodal video captioning on four standard benchmarks, as well as for\nother video understanding tasks such as VideoQA, video retrieval and action\nclassification.\n",
                "链接": "https://arxiv.org/abs/2201.08264"
            },
            {
                "文章ID": "106028",
                "标题": "Tuning Large language model for End-to-end Speech Translation",
                "作者": " Hao Zhang,  Nianwen Si,  Yaqi Chen,  Wenlin Zhang,  Xukui Yang,  Dan Qu,  Xiaolin Jiao",
                "发布日期": "2023-10-04",
                "摘要": "  With the emergence of large language models (LLMs), multimodal models based\non LLMs have demonstrated significant potential. Models such as LLaSM, X-LLM,\nand SpeechGPT exhibit an impressive ability to comprehend and generate human\ninstructions. However, their performance often falters when faced with complex\ntasks like end-to-end speech translation (E2E-ST), a cross-language and\ncross-modal translation task. In comparison to single-modal models, multimodal\nmodels lag behind in these scenarios. This paper introduces LST, a Large\nmultimodal model designed to excel at the E2E-ST task. LST consists of a speech\nfrontend, an adapter, and a LLM backend. The training of LST consists of two\nstages: (1) Modality adjustment, where the adapter is tuned to align speech\nrepresentation with text embedding space, and (2) Downstream task fine-tuning,\nwhere both the adapter and LLM model are trained to optimize performance on the\nE2EST task. Experimental results on the MuST-C speech translation benchmark\ndemonstrate that LST-13B achieves BLEU scores of 30.39/41.55/35.33 on\nEn-De/En-Fr/En-Es language pairs, surpassing previous models and establishing a\nnew state-of-the-art. Additionally, we conduct an in-depth analysis of\nsingle-modal model selection and the impact of training strategies, which lays\nthe foundation for future research. We will open up our code and models after\nreview.\n",
                "链接": "https://arxiv.org/abs/2310.02050"
            },
            {
                "文章ID": "116124",
                "标题": "Efficient End-to-End Visual Document Understanding with Rationale\n  Distillation",
                "作者": " Wang Zhu,  Alekh Agarwal,  Mandar Joshi,  Robin Jia,  Jesse Thomason,  Kristina Toutanova",
                "发布日期": "2023-11-17",
                "摘要": "  Understanding visually situated language requires recognizing text and visual\nelements, and interpreting complex layouts. State-of-the-art methods commonly\nuse specialized pre-processing tools, such as optical character recognition\n(OCR) systems, that map document image inputs to extracted information in the\nspace of textual tokens, and sometimes also employ large language models (LLMs)\nto reason in text token space. However, the gains from external tools and LLMs\ncome at the cost of increased computational and engineering complexity. In this\npaper, we ask whether small pretrained image-to-text models can learn selective\ntext or layout recognition and reasoning as an intermediate inference step in\nan end-to-end model for pixel-level visual language understanding. We\nincorporate the outputs of such OCR tools, LLMs, and larger multimodal models\nas intermediate ``rationales'' on training data, and train a small student\nmodel to predict both rationales and answers for input questions based on those\ntraining examples. A student model based on Pix2Struct (282M parameters)\nachieves consistent improvements on three visual document understanding\nbenchmarks representing infographics, scanned documents, and figures, with\nimprovements of more than 4\\% absolute over a comparable Pix2Struct model that\npredicts answers directly.\n",
                "链接": "https://arxiv.org/abs/2311.09612"
            },
            {
                "文章ID": "13855",
                "标题": "Three-Module Modeling For End-to-End Spoken Language Understanding Using\n  Pre-trained DNN-HMM-Based Acoustic-Phonetic Model",
                "作者": " Nick J. C. Wang,  Lu Wang,  Yandan Sun,  Haimei Kang,  Dejun Zhang",
                "发布日期": "2022-04-08",
                "摘要": "  In spoken language understanding (SLU), what the user says is converted to\nhis/her intent. Recent work on end-to-end SLU has shown that accuracy can be\nimproved via pre-training approaches. We revisit ideas presented by Lugosch et\nal. using speech pre-training and three-module modeling; however, to ease\nconstruction of the end-to-end SLU model, we use as our phoneme module an\nopen-source acoustic-phonetic model from a DNN-HMM hybrid automatic speech\nrecognition (ASR) system instead of training one from scratch. Hence we\nfine-tune on speech only for the word module, and we apply multi-target\nlearning (MTL) on the word and intent modules to jointly optimize SLU\nperformance. MTL yields a relative reduction of 40% in intent-classification\nerror rates (from 1.0% to 0.6%). Note that our three-module model is a\nstreaming method. The final outcome of the proposed three-module modeling\napproach yields an intent accuracy of 99.4% on FluentSpeech, an intent error\nrate reduction of 50% compared to that of Lugosch et al. Although we focus on\nreal-time streaming methods, we also list non-streaming methods for comparison.\n",
                "链接": "https://arxiv.org/abs/2204.03315"
            },
            {
                "文章ID": "37245",
                "标题": "SPACE-3: Unified Dialog Model Pre-training for Task-Oriented Dialog\n  Understanding and Generation",
                "作者": " Wanwei He,  Yinpei Dai,  Min Yang,  Jian Sun,  Fei Huang,  Luo Si,  Yongbin Li",
                "发布日期": "2022-09-15",
                "摘要": "  Recently, pre-training methods have shown remarkable success in task-oriented\ndialog (TOD) systems. However, most existing pre-trained models for TOD focus\non either dialog understanding or dialog generation, but not both. In this\npaper, we propose SPACE-3, a novel unified semi-supervised pre-trained\nconversation model learning from large-scale dialog corpora with limited\nannotations, which can be effectively fine-tuned on a wide range of downstream\ndialog tasks. Specifically, SPACE-3 consists of four successive components in a\nsingle transformer to maintain a task-flow in TOD systems: (i) a dialog\nencoding module to encode dialog history, (ii) a dialog understanding module to\nextract semantic vectors from either user queries or system responses, (iii) a\ndialog policy module to generate a policy vector that contains high-level\nsemantics of the response, and (iv) a dialog generation module to produce\nappropriate responses. We design a dedicated pre-training objective for each\ncomponent. Concretely, we pre-train the dialog encoding module with span mask\nlanguage modeling to learn contextualized dialog information. To capture the\nstructured dialog semantics, we pre-train the dialog understanding module via a\nnovel tree-induced semi-supervised contrastive learning objective with the help\nof extra dialog annotations. In addition, we pre-train the dialog policy module\nby minimizing the L2 distance between its output policy vector and the semantic\nvector of the response for policy optimization. Finally, the dialog generation\nmodel is pre-trained by language modeling. Results show that SPACE-3 achieves\nstate-of-the-art performance on eight downstream dialog benchmarks, including\nintent prediction, dialog state tracking, and end-to-end dialog modeling. We\nalso show that SPACE-3 has a stronger few-shot ability than existing models\nunder the low-resource setting.\n",
                "链接": "https://arxiv.org/abs/2209.06664"
            },
            {
                "文章ID": "94301",
                "标题": "Interpretable End-to-End Driving Model for Implicit Scene Understanding",
                "作者": " Yiyang Sun,  Xiaonian Wang,  Yangyang Zhang,  Jiagui Tang,  Xiaqiang Tang,  Jing Yao",
                "发布日期": "2023-08-03",
                "摘要": "  Driving scene understanding is to obtain comprehensive scene information\nthrough the sensor data and provide a basis for downstream tasks, which is\nindispensable for the safety of self-driving vehicles. Specific perception\ntasks, such as object detection and scene graph generation, are commonly used.\nHowever, the results of these tasks are only equivalent to the characterization\nof sampling from high-dimensional scene features, which are not sufficient to\nrepresent the scenario. In addition, the goal of perception tasks is\ninconsistent with human driving that just focuses on what may affect the\nego-trajectory. Therefore, we propose an end-to-end Interpretable Implicit\nDriving Scene Understanding (II-DSU) model to extract implicit high-dimensional\nscene features as scene understanding results guided by a planning module and\nto validate the plausibility of scene understanding using auxiliary perception\ntasks for visualization. Experimental results on CARLA benchmarks show that our\napproach achieves the new state-of-the-art and is able to obtain scene features\nthat embody richer scene information relevant to driving, enabling superior\nperformance of the downstream planning.\n",
                "链接": "https://arxiv.org/abs/2308.01180"
            },
            {
                "文章ID": "100055",
                "标题": "End-to-End Learning on Multimodal Knowledge Graphs",
                "作者": " W. X. Wilcke,  P. Bloem,  V. de Boer,  R. H. van t Veer",
                "发布日期": "2023-09-06",
                "摘要": "  Knowledge graphs enable data scientists to learn end-to-end on heterogeneous\nknowledge. However, most end-to-end models solely learn from the relational\ninformation encoded in graphs' structure: raw values, encoded as literal nodes,\nare either omitted completely or treated as regular nodes without consideration\nfor their values. In either case we lose potentially relevant information which\ncould have otherwise been exploited by our learning methods. We propose a\nmultimodal message passing network which not only learns end-to-end from the\nstructure of graphs, but also from their possibly divers set of multimodal node\nfeatures. Our model uses dedicated (neural) encoders to naturally learn\nembeddings for node features belonging to five different types of modalities,\nincluding numbers, texts, dates, images and geometries, which are projected\ninto a joint representation space together with their relational information.\nWe implement and demonstrate our model on node classification and link\nprediction for artificial and real-worlds datasets, and evaluate the effect\nthat each modality has on the overall performance in an inverse ablation study.\nOur results indicate that end-to-end multimodal learning from any arbitrary\nknowledge graph is indeed possible, and that including multimodal information\ncan significantly affect performance, but that much depends on the\ncharacteristics of the data.\n",
                "链接": "https://arxiv.org/abs/2309.01169"
            },
            {
                "文章ID": "10229",
                "标题": "UNIMO-2: End-to-End Unified Vision-Language Grounded Learning",
                "作者": " Wei Li,  Can Gao,  Guocheng Niu,  Xinyan Xiao,  Hao Liu,  Jiachen Liu,  Hua Wu,  Haifeng Wang",
                "发布日期": "2022-03-18",
                "摘要": "  Vision-Language Pre-training (VLP) has achieved impressive performance on\nvarious cross-modal downstream tasks. However, most existing methods can only\nlearn from aligned image-caption data and rely heavily on expensive regional\nfeatures, which greatly limits their scalability and performance. In this\npaper, we propose an end-to-end unified-modal pre-training framework, namely\nUNIMO-2, for joint learning on both aligned image-caption data and unaligned\nimage-only and text-only corpus. We build a unified Transformer model to\njointly learn visual representations, textual representations and semantic\nalignment between images and texts. In particular, we propose to conduct\ngrounded learning on both images and texts via a sharing grounded space, which\nhelps bridge unaligned images and texts, and align the visual and textual\nsemantic spaces on different types of corpora. The experiments show that our\ngrounded learning method can improve textual and visual semantic alignment for\nimproving performance on various cross-modal tasks. Moreover, benefiting from\neffective joint modeling of different types of corpora, our model also achieves\nimpressive performance on single-modal visual and textual tasks. Our code and\nmodels are public at the UNIMO project page https://unimo-ptm.github.io/.\n",
                "链接": "https://arxiv.org/abs/2203.09067"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近两年关于语言模型奖励建模评估的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105659",
                "标题": "Tool-Augmented Reward Modeling",
                "作者": " Lei Li,  Yekun Chai,  Shuohuan Wang,  Yu Sun,  Hao Tian,  Ningyu Zhang,  Hua Wu",
                "发布日期": "2023-10-03",
                "摘要": "  Reward modeling (a.k.a., preference modeling) is instrumental for aligning\nlarge language models with human preferences, particularly within the context\nof reinforcement learning from human feedback (RLHF). While conventional reward\nmodels (RMs) have exhibited remarkable scalability, they oft struggle with\nfundamental functionality such as arithmetic computation, code execution, and\nfactual lookup. In this paper, we propose a tool-augmented preference modeling\napproach, named \\name, to address these limitations by empowering RMs with\naccess to external environments, including calculators and search engines. This\napproach not only fosters synergy between tool utilization and reward grading\nbut also enhances interpretive capacity and scoring reliability. Our study\ndelves into the integration of external tools into RMs, enabling them to\ninteract with diverse external sources and construct task-specific tool\nengagement and reasoning traces in an autoregressive manner. We validate our\napproach across a wide range of domains, incorporating seven distinct external\ntools. Our experimental results demonstrate a noteworthy overall improvement of\n17.7% across eight tasks in preference ranking. Furthermore, our approach\noutperforms Gopher 280B by 7.3% on TruthfulQA task in zero-shot evaluation. In\nhuman evaluations, RLHF trained with Themis attains an average win rate of 32%\nwhen compared to baselines across four distinct tasks. Additionally, we provide\na comprehensive collection of tool-related RM datasets, incorporating data from\nseven distinct tool APIs, totaling 15,000 instances. We anticipate that this\npublicly available dataset will facilitate and inspire further research\nadvancements in the field.\n",
                "链接": "https://arxiv.org/abs/2310.01045"
            },
            {
                "文章ID": "6241",
                "标题": "Reward Modeling for Mitigating Toxicity in Transformer-based Language\n  Models",
                "作者": " Farshid Faal,  Ketra Schmitt,  Jia Yuan Yu",
                "发布日期": "2022-07-28",
                "摘要": "  Transformer-based language models are able to generate fluent text and be\nefficiently adapted across various natural language generation tasks. However,\nlanguage models that are pretrained on large unlabeled web text corpora have\nbeen shown to suffer from degenerating toxic content and social bias behaviors,\nconsequently hindering their safe deployment. Various detoxification methods\nwere proposed to mitigate the language model's toxicity; however, these methods\nstruggled to detoxify language models when conditioned on prompts that contain\nspecific social identities related to gender, race, or religion. In this study,\nwe propose Reinforce-Detoxify; A reinforcement learning-based method for\nmitigating toxicity in language models. We address the challenge of safety in\nlanguage models and propose a new reward model that is able to detect toxic\ncontent and mitigate unintended bias towards social identities in toxicity\nprediction. The experiments demonstrate that the Reinforce-Detoxify method for\nlanguage model detoxification outperforms existing detoxification approaches in\nautomatic evaluation metrics, indicating the ability of our approach in\nlanguage model detoxification and less prone to unintended bias toward social\nidentities in generated content.\n",
                "链接": "https://arxiv.org/abs/2202.09662"
            },
            {
                "文章ID": "58975",
                "标题": "Direct Preference-based Policy Optimization without Reward Modeling",
                "作者": " Gaon An,  Junhyeok Lee,  Xingdong Zuo,  Norio Kosaka,  Kyung-Min Kim,  Hyun Oh Song",
                "发布日期": "2023-10-30",
                "摘要": "  Preference-based reinforcement learning (PbRL) is an approach that enables RL\nagents to learn from preference, which is particularly useful when formulating\na reward function is challenging. Existing PbRL methods generally involve a\ntwo-step procedure: they first learn a reward model based on given preference\ndata and then employ off-the-shelf reinforcement learning algorithms using the\nlearned reward model. However, obtaining an accurate reward model solely from\npreference information, especially when the preference is from human teachers,\ncan be difficult. Instead, we propose a PbRL algorithm that directly learns\nfrom preference without requiring any reward modeling. To achieve this, we\nadopt a contrastive learning framework to design a novel policy scoring metric\nthat assigns a high score to policies that align with the given preferences. We\napply our algorithm to offline RL tasks with actual human preference labels and\nshow that our algorithm outperforms or is on par with the existing PbRL\nmethods. Notably, on high-dimensional control tasks, our algorithm surpasses\noffline RL methods that learn with ground-truth reward information. Finally, we\nshow that our algorithm can be successfully applied to fine-tune large language\nmodels.\n",
                "链接": "https://arxiv.org/abs/2301.12842"
            },
            {
                "文章ID": "108780",
                "标题": "Reward-Augmented Decoding: Efficient Controlled Text Generation With a\n  Unidirectional Reward Model",
                "作者": " Haikang Deng,  Colin Raffel",
                "发布日期": "2023-10-30",
                "摘要": "  While large language models have proven effective in a huge range of\ndownstream applications, they often generate text that is problematic or lacks\na desired attribute. In this paper, we introduce Reward-Augmented Decoding\n(RAD), a text generation procedure that uses a small unidirectional reward\nmodel to encourage a language model to generate text that has certain\nproperties. Specifically, RAD uses the reward model to score generations as\nthey are produced and rescales sampling probabilities to favor high-reward\ntokens. By using a unidirectional reward model, RAD can cache activations from\nprior generation steps to decrease computational overhead. Through experiments\non generating non-toxic and sentiment-controlled text, we demonstrate that RAD\nperforms best among methods that change only the generation procedure and\nmatches the performance of state-of-the-art methods that involve re-training\nthe language model. We further validate that RAD is effective on very large\nlanguage models while incurring a minimal computational overhead.\n",
                "链接": "https://arxiv.org/abs/2310.09520"
            },
            {
                "文章ID": "122681",
                "标题": "Helping or Herding? Reward Model Ensembles Mitigate but do not Eliminate\n  Reward Hacking",
                "作者": " Jacob Eisenstein,  Chirag Nagpal,  Alekh Agarwal,  Ahmad Beirami,  Alex D'Amour,  DJ Dvijotham,  Adam Fisch,  Katherine Heller,  Stephen Pfohl,  Deepak Ramachandran,  Peter Shaw,  Jonathan Berant",
                "发布日期": "2023-12-22",
                "摘要": "  Reward models play a key role in aligning language model applications towards\nhuman preferences. However, this setup creates an incentive for the language\nmodel to exploit errors in the reward model to achieve high estimated reward, a\nphenomenon often termed \\emph{reward hacking}. A natural mitigation is to train\nan ensemble of reward models, aggregating over model outputs to obtain a more\nrobust reward estimate. We explore the application of reward ensembles to\nalignment at both training time (through reinforcement learning) and inference\ntime (through reranking). First, we show that reward models are\n\\emph{underspecified}: reward models that perform similarly in-distribution can\nyield very different rewards when used in alignment, due to distribution shift.\nSecond, underspecification results in overoptimization, where alignment to one\nreward model does not improve reward as measured by another reward model\ntrained on the same data. Third, overoptimization is mitigated by the use of\nreward ensembles, and ensembles that vary by their \\emph{pretraining} seeds\nlead to better generalization than ensembles that differ only by their\n\\emph{fine-tuning} seeds, with both outperforming individual reward models.\nHowever, even pretrain reward ensembles do not eliminate reward hacking: we\nshow several qualitative reward hacking phenomena that are not mitigated by\nensembling because all reward models in the ensemble exhibit similar error\npatterns.\n",
                "链接": "https://arxiv.org/abs/2312.09244"
            },
            {
                "文章ID": "106830",
                "标题": "Confronting Reward Model Overoptimization with Constrained RLHF",
                "作者": " Ted Moskovitz,  Aaditya K. Singh,  DJ Strouse,  Tuomas Sandholm,  Ruslan Salakhutdinov,  Anca D. Dragan,  Stephen McAleer",
                "发布日期": "2023-10-11",
                "摘要": "  Large language models are typically aligned with human preferences by\noptimizing $\\textit{reward models}$ (RMs) fitted to human feedback. However,\nhuman preferences are multi-faceted, and it is increasingly common to derive\nreward from a composition of simpler reward models which each capture a\ndifferent aspect of language quality. This itself presents a challenge, as it\nis difficult to appropriately weight these component RMs when combining them.\nCompounding this difficulty, because any RM is only a proxy for human\nevaluation, this process is vulnerable to $\\textit{overoptimization}$, wherein\npast a certain point, accumulating higher reward is associated with worse human\nratings. In this paper, we perform, to our knowledge, the first study on\noveroptimization in composite RMs, showing that correlation between component\nRMs has a significant effect on the locations of these points. We then\nintroduce an approach to solve this issue using constrained reinforcement\nlearning as a means of preventing the agent from exceeding each RM's threshold\nof usefulness. Our method addresses the problem of weighting component RMs by\nlearning dynamic weights, naturally expressed by Lagrange multipliers. As a\nresult, each RM stays within the range at which it is an effective proxy,\nimproving evaluation performance. Finally, we introduce an adaptive method\nusing gradient-free optimization to identify and optimize towards these points\nduring a single run.\n",
                "链接": "https://arxiv.org/abs/2310.04373"
            },
            {
                "文章ID": "64063",
                "标题": "Reward Design with Language Models",
                "作者": " Minae Kwon,  Sang Michael Xie,  Kalesha Bullard,  Dorsa Sadigh",
                "发布日期": "2023-03-02",
                "摘要": "  Reward design in reinforcement learning (RL) is challenging since specifying\nhuman notions of desired behavior may be difficult via reward functions or\nrequire many expert demonstrations. Can we instead cheaply design rewards using\na natural language interface? This paper explores how to simplify reward design\nby prompting a large language model (LLM) such as GPT-3 as a proxy reward\nfunction, where the user provides a textual prompt containing a few examples\n(few-shot) or a description (zero-shot) of the desired behavior. Our approach\nleverages this proxy reward function in an RL framework. Specifically, users\nspecify a prompt once at the beginning of training. During training, the LLM\nevaluates an RL agent's behavior against the desired behavior described by the\nprompt and outputs a corresponding reward signal. The RL agent then uses this\nreward to update its behavior. We evaluate whether our approach can train\nagents aligned with user objectives in the Ultimatum Game, matrix games, and\nthe DealOrNoDeal negotiation task. In all three tasks, we show that RL agents\ntrained with our framework are well-aligned with the user's objectives and\noutperform RL agents trained with reward functions learned via supervised\nlearning\n",
                "链接": "https://arxiv.org/abs/2303.00001"
            },
            {
                "文章ID": "110451",
                "标题": "Learning Reward for Physical Skills using Large Language Model",
                "作者": " Yuwei Zeng,  Yiqing Xu",
                "发布日期": "2023-10-24",
                "摘要": "  Learning reward functions for physical skills are challenging due to the vast\nspectrum of skills, the high-dimensionality of state and action space, and\nnuanced sensory feedback. The complexity of these tasks makes acquiring expert\ndemonstration data both costly and time-consuming. Large Language Models (LLMs)\ncontain valuable task-related knowledge that can aid in learning these reward\nfunctions. However, the direct application of LLMs for proposing reward\nfunctions has its limitations such as numerical instability and inability to\nincorporate the environment feedback. We aim to extract task knowledge from\nLLMs using environment feedback to create efficient reward functions for\nphysical skills. Our approach consists of two components. We first use the LLM\nto propose features and parameterization of the reward function. Next, we\nupdate the parameters of this proposed reward function through an iterative\nself-alignment process. In particular, this process minimizes the ranking\ninconsistency between the LLM and our learned reward functions based on the new\nobservations. We validated our method by testing it on three simulated physical\nskill learning tasks, demonstrating effective support for our design choices.\n",
                "链接": "https://arxiv.org/abs/2310.14092"
            },
            {
                "文章ID": "81738",
                "标题": "Direct Preference Optimization: Your Language Model is Secretly a Reward\n  Model",
                "作者": " Rafael Rafailov,  Archit Sharma,  Eric Mitchell,  Stefano Ermon,  Christopher D. Manning,  Chelsea Finn",
                "发布日期": "2023-12-14",
                "摘要": "  While large-scale unsupervised language models (LMs) learn broad world\nknowledge and some reasoning skills, achieving precise control of their\nbehavior is difficult due to the completely unsupervised nature of their\ntraining. Existing methods for gaining such steerability collect human labels\nof the relative quality of model generations and fine-tune the unsupervised LM\nto align with these preferences, often with reinforcement learning from human\nfeedback (RLHF). However, RLHF is a complex and often unstable procedure, first\nfitting a reward model that reflects the human preferences, and then\nfine-tuning the large unsupervised LM using reinforcement learning to maximize\nthis estimated reward without drifting too far from the original model. In this\npaper we introduce a new parameterization of the reward model in RLHF that\nenables extraction of the corresponding optimal policy in closed form, allowing\nus to solve the standard RLHF problem with only a simple classification loss.\nThe resulting algorithm, which we call Direct Preference Optimization (DPO), is\nstable, performant, and computationally lightweight, eliminating the need for\nsampling from the LM during fine-tuning or performing significant\nhyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align\nwith human preferences as well as or better than existing methods. Notably,\nfine-tuning with DPO exceeds PPO-based RLHF in ability to control sentiment of\ngenerations, and matches or improves response quality in summarization and\nsingle-turn dialogue while being substantially simpler to implement and train.\n",
                "链接": "https://arxiv.org/abs/2305.18290"
            },
            {
                "文章ID": "106278",
                "标题": "Reward Model Ensembles Help Mitigate Overoptimization",
                "作者": " Thomas Coste,  Usman Anwar,  Robert Kirk,  David Krueger",
                "发布日期": "2023-10-05",
                "摘要": "  Reinforcement learning from human feedback (RLHF) is a standard approach for\nfine-tuning large language models to follow instructions. As part of this\nprocess, learned reward models are used to approximately model human\npreferences. However, as imperfect representations of the \"true\" reward, these\nlearned reward models are susceptible to \\textit{overoptimization}. Gao et al.\n(2023) studied this phenomenon in a synthetic human feedback setup with a\nsignificantly larger \"gold\" reward model acting as the true reward (instead of\nhumans) and showed that overoptimization remains a persistent problem\nregardless of the size of the proxy reward model and training data used. Using\na similar setup, we conduct a systematic study to evaluate the efficacy of\nusing ensemble-based conservative optimization objectives, specifically\nworst-case optimization (WCO) and uncertainty-weighted optimization (UWO), for\nmitigating reward model overoptimization when using two optimization methods:\n(a) best-of-n sampling (BoN) (b) proximal policy optimization (PPO). We\nadditionally extend the setup of Gao et al. (2023) to include 25% label noise\nto better mirror real-world conditions. Both with and without label noise, we\nfind that conservative optimization practically eliminates overoptimization and\nimproves performance by up to 70% for BoN sampling. For PPO, ensemble-based\nconservative optimization always reduces overoptimization and outperforms\nsingle reward model optimization. Moreover, combining it with a small KL\npenalty successfully prevents overoptimization at no performance cost. Overall,\nour results demonstrate that ensemble-based conservative optimization can\neffectively counter overoptimization.\n",
                "链接": "https://arxiv.org/abs/2310.02743"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到从位置编码角度改善模型长序列建模能力的相关论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "6738",
                "标题": "FastRPB: a Scalable Relative Positional Encoding for Long Sequence Tasks",
                "作者": " Maksim Zubkov,  Daniil Gavrilov",
                "发布日期": "2022-02-24",
                "摘要": "  Transformers achieve remarkable performance in various domains, including\nNLP, CV, audio processing, and graph analysis. However, they do not scale well\non long sequence tasks due to their quadratic complexity w.r.t. the inputs\nlength. Linear Transformers were proposed to address this limitation. However,\nthese models have shown weaker performance on the long sequence tasks comparing\nto the original one. In this paper, we explore Linear Transformer models,\nrethinking their two core components. Firstly, we improved Linear Transformer\nwith Shift-Invariant Kernel Function SIKF, which achieve higher accuracy\nwithout loss in speed. Secondly, we introduce FastRPB which stands for Fast\nRelative Positional Bias, which efficiently adds positional information to\nself-attention using Fast Fourier Transformation. FastRPB is independent of the\nself-attention mechanism and can be combined with an original self-attention\nand all its efficient variants. FastRPB has O(N log(N)) computational\ncomplexity, requiring O(N) memory w.r.t. input sequence length N.\n",
                "链接": "https://arxiv.org/abs/2202.11364"
            },
            {
                "文章ID": "91660",
                "标题": "Linearized Relative Positional Encoding",
                "作者": " Zhen Qin,  Weixuan Sun,  Kaiyue Lu,  Hui Deng,  Dongxu Li,  Xiaodong Han,  Yuchao Dai,  Lingpeng Kong,  Yiran Zhong",
                "发布日期": "2023-07-19",
                "摘要": "  Relative positional encoding is widely used in vanilla and linear\ntransformers to represent positional information. However, existing encoding\nmethods of a vanilla transformer are not always directly applicable to a linear\ntransformer, because the latter requires a decomposition of the query and key\nrepresentations into separate kernel functions. Nevertheless, principles for\ndesigning encoding methods suitable for linear transformers remain\nunderstudied. In this work, we put together a variety of existing linear\nrelative positional encoding approaches under a canonical form and further\npropose a family of linear relative positional encoding algorithms via unitary\ntransformation. Our formulation leads to a principled framework that can be\nused to develop new relative positional encoding methods that preserve linear\nspace-time complexity. Equipped with different models, the proposed linearized\nrelative positional encoding (LRPE) family derives effective encoding for\nvarious applications. Experiments show that compared with existing methods,\nLRPE achieves state-of-the-art performance in language modeling, text\nclassification, and image classification. Meanwhile, it emphasizes a general\nparadigm for designing broadly more relative positional encoding methods that\nare applicable to linear transformers. The code is available at\nhttps://github.com/OpenNLPLab/Lrpe.\n",
                "链接": "https://arxiv.org/abs/2307.09270"
            },
            {
                "文章ID": "50484",
                "标题": "PIP: Positional-encoding Image Prior",
                "作者": " Nimrod Shabtay,  Eli Schwartz,  Raja Giryes",
                "发布日期": "2023-04-04",
                "摘要": "  In Deep Image Prior (DIP), a Convolutional Neural Network (CNN) is fitted to\nmap a latent space to a degraded (e.g. noisy) image but in the process learns\nto reconstruct the clean image. This phenomenon is attributed to CNN's internal\nimage-prior. We revisit the DIP framework, examining it from the perspective of\na neural implicit representation. Motivated by this perspective, we replace the\nrandom or learned latent with Fourier-Features (Positional Encoding). We show\nthat thanks to the Fourier features properties, we can replace the convolution\nlayers with simple pixel-level MLPs. We name this scheme ``Positional Encoding\nImage Prior\" (PIP) and exhibit that it performs very similarly to DIP on\nvarious image-reconstruction tasks with much less parameters required.\nAdditionally, we demonstrate that PIP can be easily extended to videos, where\n3D-DIP struggles and suffers from instability. Code and additional examples for\nall tasks, including videos, are available on the project page\nhttps://nimrodshabtay.github.io/PIP/\n",
                "链接": "https://arxiv.org/abs/2211.14298"
            },
            {
                "文章ID": "82296",
                "标题": "The Impact of Positional Encoding on Length Generalization in\n  Transformers",
                "作者": " Amirhossein Kazemnejad,  Inkit Padhi,  Karthikeyan Natesan Ramamurthy,  Payel Das,  Siva Reddy",
                "发布日期": "2023-11-08",
                "摘要": "  Length generalization, the ability to generalize from small training context\nsizes to larger ones, is a critical challenge in the development of\nTransformer-based language models. Positional encoding (PE) has been identified\nas a major factor influencing length generalization, but the exact impact of\ndifferent PE schemes on extrapolation in downstream tasks remains unclear. In\nthis paper, we conduct a systematic empirical study comparing the length\ngeneralization performance of decoder-only Transformers with five different\nposition encoding approaches including Absolute Position Embedding (APE), T5's\nRelative PE, ALiBi, and Rotary, in addition to Transformers without positional\nencoding (NoPE). Our evaluation encompasses a battery of reasoning and\nmathematical tasks. Our findings reveal that the most commonly used positional\nencoding methods, such as ALiBi, Rotary, and APE, are not well suited for\nlength generalization in downstream tasks. More importantly, NoPE outperforms\nother explicit positional encoding methods while requiring no additional\ncomputation. We theoretically demonstrate that NoPE can represent both absolute\nand relative PEs, but when trained with SGD, it mostly resembles T5's relative\nPE attention patterns. Finally, we find that scratchpad is not always helpful\nto solve length generalization and its format highly impacts the model's\nperformance. Overall, our work suggests that explicit position embeddings are\nnot essential for decoder-only Transformers to generalize well to longer\nsequences.\n",
                "链接": "https://arxiv.org/abs/2305.19466"
            },
            {
                "文章ID": "61325",
                "标题": "A Unified View of Long-Sequence Models towards Modeling Million-Scale\n  Dependencies",
                "作者": " Hongyu Hè,  Marko Kabic",
                "发布日期": "2023-02-17",
                "摘要": "  Ever since their conception, Transformers have taken over traditional\nsequence models in many tasks, such as NLP, image classification, and\nvideo/audio processing, for their fast training and superior performance. Much\nof the merit is attributable to positional encoding and multi-head attention.\nHowever, Transformers fall short in learning long-range dependencies mainly due\nto the quadratic complexity scaled with context length, in terms of both time\nand space. Consequently, over the past five years, a myriad of methods has been\nproposed to make Transformers more efficient. In this work, we first take a\nstep back, study and compare existing solutions to long-sequence modeling in\nterms of their pure mathematical formulation. Specifically, we summarize them\nusing a unified template, given their shared nature of token mixing. Through\nbenchmarks, we then demonstrate that long context length does yield better\nperformance, albeit application-dependent, and traditional Transformer models\nfall short in taking advantage of long-range dependencies. Next, inspired by\nemerging sparse models of huge capacity, we propose a machine learning system\nfor handling million-scale dependencies. As a proof of concept, we evaluate the\nperformance of one essential component of this system, namely, the distributed\nmulti-head attention. We show that our algorithm can scale up attention\ncomputation by almost $40\\times$ using four GeForce RTX 4090 GPUs, compared to\nvanilla multi-head attention mechanism. We believe this study is an\ninstrumental step towards modeling million-scale dependencies.\n",
                "链接": "https://arxiv.org/abs/2302.06218"
            },
            {
                "文章ID": "9782",
                "标题": "Efficient Long Sequence Encoding via Synchronization",
                "作者": " Xiangyang Mou,  Mo Yu,  Bingsheng Yao,  Lifu Huang",
                "发布日期": "2022-03-16",
                "摘要": "  Pre-trained Transformer models have achieved successes in a wide range of NLP\ntasks, but are inefficient when dealing with long input sequences. Existing\nstudies try to overcome this challenge via segmenting the long sequence\nfollowed by hierarchical encoding or post-hoc aggregation. We propose a\nsynchronization mechanism for hierarchical encoding. Our approach first\nidentifies anchor tokens across segments and groups them by their roles in the\noriginal input sequence. Then inside Transformer layer, anchor embeddings are\nsynchronized within their group via a self-attention module. Our approach is a\ngeneral framework with sufficient flexibility -- when adapted to a new task, it\nis easy to be enhanced with the task-specific anchor definitions. Experiments\non two representative tasks with different types of long input texts,\nNarrativeQA summary setting and wild multi-hop reasoning from HotpotQA,\ndemonstrate that our approach is able to improve the global information\nexchange among segments while maintaining efficiency.\n",
                "链接": "https://arxiv.org/abs/2203.07644"
            },
            {
                "文章ID": "50009",
                "标题": "Learning Regularized Positional Encoding for Molecular Prediction",
                "作者": " Xiang Gao,  Weihao Gao,  Wenzhi Xiao,  Zhirui Wang,  Chong Wang,  Liang Xiang",
                "发布日期": "2022-11-24",
                "摘要": "  Machine learning has become a promising approach for molecular modeling.\nPositional quantities, such as interatomic distances and bond angles, play a\ncrucial role in molecule physics. The existing works rely on careful manual\ndesign of their representation. To model the complex nonlinearity in predicting\nmolecular properties in an more end-to-end approach, we propose to encode the\npositional quantities with a learnable embedding that is continuous and\ndifferentiable. A regularization technique is employed to encourage embedding\nsmoothness along the physical dimension. We experiment with a variety of\nmolecular property and force field prediction tasks. Improved performance is\nobserved for three different model architectures after plugging in the proposed\npositional encoding method. In addition, the learned positional encoding allows\neasier physics-based interpretation. We observe that tasks of similar physics\nhave the similar learned positional encoding.\n",
                "链接": "https://arxiv.org/abs/2211.12773"
            },
            {
                "文章ID": "3277",
                "标题": "GRPE: Relative Positional Encoding for Graph Transformer",
                "作者": " Wonpyo Park,  Woonggi Chang,  Donggeon Lee,  Juntae Kim,  Seung-won Hwang",
                "发布日期": "2022-10-17",
                "摘要": "  We propose a novel positional encoding for learning graph on Transformer\narchitecture. Existing approaches either linearize a graph to encode absolute\nposition in the sequence of nodes, or encode relative position with another\nnode using bias terms. The former loses preciseness of relative position from\nlinearization, while the latter loses a tight integration of node-edge and\nnode-topology interaction. To overcome the weakness of the previous approaches,\nour method encodes a graph without linearization and considers both\nnode-topology and node-edge interaction. We name our method Graph Relative\nPositional Encoding dedicated to graph representation learning. Experiments\nconducted on various graph datasets show that the proposed method outperforms\nprevious approaches significantly. Our code is publicly available at\nhttps://github.com/lenscloth/GRPE.\n",
                "链接": "https://arxiv.org/abs/2201.12787"
            },
            {
                "文章ID": "45624",
                "标题": "Generalized Laplacian Positional Encoding for Graph Representation\n  Learning",
                "作者": " Sohir Maskey,  Ali Parviz,  Maximilian Thiessen,  Hannes Stärk,  Ylli Sadikaj,  Haggai Maron",
                "发布日期": "2022-11-11",
                "摘要": "  Graph neural networks (GNNs) are the primary tool for processing\ngraph-structured data. Unfortunately, the most commonly used GNNs, called\nMessage Passing Neural Networks (MPNNs) suffer from several fundamental\nlimitations. To overcome these limitations, recent works have adapted the idea\nof positional encodings to graph data. This paper draws inspiration from the\nrecent success of Laplacian-based positional encoding and defines a novel\nfamily of positional encoding schemes for graphs. We accomplish this by\ngeneralizing the optimization problem that defines the Laplace embedding to\nmore general dissimilarity functions rather than the 2-norm used in the\noriginal formulation. This family of positional encodings is then instantiated\nby considering p-norms. We discuss a method for calculating these positional\nencoding schemes, implement it in PyTorch and demonstrate how the resulting\npositional encoding captures different properties of the graph. Furthermore, we\ndemonstrate that this novel family of positional encodings can improve the\nexpressive power of MPNNs. Lastly, we present preliminary experimental results.\n",
                "链接": "https://arxiv.org/abs/2210.15956"
            },
            {
                "文章ID": "37058",
                "标题": "Document-aware Positional Encoding and Linguistic-guided Encoding for\n  Abstractive Multi-document Summarization",
                "作者": " Congbo Ma,  Wei Emma Zhang,  Pitawelayalage Dasun Dileepa Pitawela,  Yutong Qu,  Haojie Zhuang,  Hu Wang",
                "发布日期": "2022-09-14",
                "摘要": "  One key challenge in multi-document summarization is to capture the relations\namong input documents that distinguish between single document summarization\n(SDS) and multi-document summarization (MDS). Few existing MDS works address\nthis issue. One effective way is to encode document positional information to\nassist models in capturing cross-document relations. However, existing MDS\nmodels, such as Transformer-based models, only consider token-level positional\ninformation. Moreover, these models fail to capture sentences' linguistic\nstructure, which inevitably causes confusions in the generated summaries.\nTherefore, in this paper, we propose document-aware positional encoding and\nlinguistic-guided encoding that can be fused with Transformer architecture for\nMDS. For document-aware positional encoding, we introduce a general protocol to\nguide the selection of document encoding functions. For linguistic-guided\nencoding, we propose to embed syntactic dependency relations into the\ndependency relation mask with a simple but effective non-linear encoding\nlearner for feature learning. Extensive experiments show the proposed model can\ngenerate summaries with high quality.\n",
                "链接": "https://arxiv.org/abs/2209.05929"
            }
        ]
    },
    {
        "question": {
            "question": "利用大模型做数学题生成的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找可以用于验证模型推理能力的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "77994",
                "标题": "Model-based Validation as Probabilistic Inference",
                "作者": " Harrison Delecki,  Anthony Corso,  Mykel J. Kochenderfer",
                "发布日期": "2023-05-18",
                "摘要": "  Estimating the distribution over failures is a key step in validating\nautonomous systems. Existing approaches focus on finding failures for a small\nrange of initial conditions or make restrictive assumptions about the\nproperties of the system under test. We frame estimating the distribution over\nfailure trajectories for sequential systems as Bayesian inference. Our\nmodel-based approach represents the distribution over failure trajectories\nusing rollouts of system dynamics and computes trajectory gradients using\nautomatic differentiation. Our approach is demonstrated in an inverted pendulum\ncontrol system, an autonomous vehicle driving scenario, and a partially\nobservable lunar lander. Sampling is performed using an off-the-shelf\nimplementation of Hamiltonian Monte Carlo with multiple chains to capture\nmultimodality and gradient smoothing for safe trajectories. In all experiments,\nwe observed improvements in sample efficiency and parameter space coverage\ncompared to black-box baseline approaches. This work is open sourced.\n",
                "链接": "https://arxiv.org/abs/2305.09930"
            },
            {
                "文章ID": "117710",
                "标题": "Empirical Comparison between Cross-Validation and Mutation-Validation in\n  Model Selection",
                "作者": " Jinyang Yu,  Sami Hamdan,  Leonard Sasse,  Abigail Morrison,  Kaustubh R. Patil",
                "发布日期": "2023-11-27",
                "摘要": "  Mutation validation (MV) is a recently proposed approach for model selection,\ngarnering significant interest due to its unique characteristics and potential\nbenefits compared to the widely used cross-validation (CV) method. In this\nstudy, we empirically compared MV and $k$-fold CV using benchmark and\nreal-world datasets. By employing Bayesian tests, we compared generalization\nestimates yielding three posterior probabilities: practical equivalence, CV\nsuperiority, and MV superiority. We also evaluated the differences in the\ncapacity of the selected models and computational efficiency. We found that\nboth MV and CV select models with practically equivalent generalization\nperformance across various machine learning algorithms and the majority of\nbenchmark datasets. MV exhibited advantages in terms of selecting simpler\nmodels and lower computational costs. However, in some cases MV selected overly\nsimplistic models leading to underfitting and showed instability in\nhyperparameter selection. These limitations of MV became more evident in the\nevaluation of a real-world neuroscientific task of predicting sex at birth\nusing brain functional connectivity.\n",
                "链接": "https://arxiv.org/abs/2311.14079"
            },
            {
                "文章ID": "65767",
                "标题": "Position Paper on Dataset Engineering to Accelerate Science",
                "作者": " Emilio Vital Brazil,  Eduardo Soares,  Lucas Villa Real,  Leonardo Azevedo,  Vinicius Segura,  Luiz Zerkowski,  Renato Cerqueira",
                "发布日期": "2023-03-13",
                "摘要": "  Data is a critical element in any discovery process. In the last decades, we\nobserved exponential growth in the volume of available data and the technology\nto manipulate it. However, data is only practical when one can structure it for\na well-defined task. For instance, we need a corpus of text broken into\nsentences to train a natural language machine-learning model. In this work, we\nwill use the token \\textit{dataset} to designate a structured set of data built\nto perform a well-defined task. Moreover, the dataset will be used in most\ncases as a blueprint of an entity that at any moment can be stored as a table.\nSpecifically, in science, each area has unique forms to organize, gather and\nhandle its datasets. We believe that datasets must be a first-class entity in\nany knowledge-intensive process, and all workflows should have exceptional\nattention to datasets' lifecycle, from their gathering to uses and evolution.\nWe advocate that science and engineering discovery processes are extreme\ninstances of the need for such organization on datasets, claiming for new\napproaches and tooling. Furthermore, these requirements are more evident when\nthe discovery workflow uses artificial intelligence methods to empower the\nsubject-matter expert. In this work, we discuss an approach to bringing\ndatasets as a critical entity in the discovery process in science. We\nillustrate some concepts using material discovery as a use case. We chose this\ndomain because it leverages many significant problems that can be generalized\nto other science fields.\n",
                "链接": "https://arxiv.org/abs/2303.05545"
            },
            {
                "文章ID": "104517",
                "标题": "Cross-Validation for Training and Testing Co-occurrence Network\n  Inference Algorithms",
                "作者": " Daniel Agyapong,  Jeffrey Ryan Propster,  Jane Marks,  Toby Dylan Hocking",
                "发布日期": "2023-09-28",
                "摘要": "  Microorganisms are found in almost every environment, including the soil,\nwater, air, and inside other organisms, like animals and plants. While some\nmicroorganisms cause diseases, most of them help in biological processes such\nas decomposition, fermentation and nutrient cycling. A lot of research has gone\ninto studying microbial communities in various environments and how their\ninteractions and relationships can provide insights into various diseases.\nCo-occurrence network inference algorithms help us understand the complex\nassociations of micro-organisms, especially bacteria. Existing network\ninference algorithms employ techniques such as correlation, regularized linear\nregression, and conditional dependence, which have different hyper-parameters\nthat determine the sparsity of the network. Previous methods for evaluating the\nquality of the inferred network include using external data, and network\nconsistency across sub-samples, both which have several drawbacks that limit\ntheir applicability in real microbiome composition data sets. We propose a\nnovel cross-validation method to evaluate co-occurrence network inference\nalgorithms, and new methods for applying existing algorithms to predict on test\ndata. Our empirical study shows that the proposed method is useful for\nhyper-parameter selection (training) and comparing the quality of the inferred\nnetworks between different algorithms (testing).\n",
                "链接": "https://arxiv.org/abs/2309.15225"
            },
            {
                "文章ID": "27917",
                "标题": "A Dataset on Malicious Paper Bidding in Peer Review",
                "作者": " Steven Jecmen,  Minji Yoon,  Vincent Conitzer,  Nihar B. Shah,  Fei Fang",
                "发布日期": "2023-03-14",
                "摘要": "  In conference peer review, reviewers are often asked to provide \"bids\" on\neach submitted paper that express their interest in reviewing that paper. A\npaper assignment algorithm then uses these bids (along with other data) to\ncompute a high-quality assignment of reviewers to papers. However, this process\nhas been exploited by malicious reviewers who strategically bid in order to\nunethically manipulate the paper assignment, crucially undermining the peer\nreview process. For example, these reviewers may aim to get assigned to a\nfriend's paper as part of a quid-pro-quo deal. A critical impediment towards\ncreating and evaluating methods to mitigate this issue is the lack of any\npublicly-available data on malicious paper bidding. In this work, we collect\nand publicly release a novel dataset to fill this gap, collected from a mock\nconference activity where participants were instructed to bid either honestly\nor maliciously. We further provide a descriptive analysis of the bidding\nbehavior, including our categorization of different strategies employed by\nparticipants. Finally, we evaluate the ability of each strategy to manipulate\nthe assignment, and also evaluate the performance of some simple algorithms\nmeant to detect malicious bidding. The performance of these detection\nalgorithms can be taken as a baseline for future research on detecting\nmalicious bidding.\n",
                "链接": "https://arxiv.org/abs/2207.02303"
            },
            {
                "文章ID": "70306",
                "标题": "A principled approach to model validation in domain generalization",
                "作者": " Boyang Lyu,  Thuan Nguyen,  Matthias Scheutz,  Prakash Ishwar,  Shuchin Aeron",
                "发布日期": "2023-04-04",
                "摘要": "  Domain generalization aims to learn a model with good generalization ability,\nthat is, the learned model should not only perform well on several seen domains\nbut also on unseen domains with different data distributions. State-of-the-art\ndomain generalization methods typically train a representation function\nfollowed by a classifier jointly to minimize both the classification risk and\nthe domain discrepancy. However, when it comes to model selection, most of\nthese methods rely on traditional validation routines that select models solely\nbased on the lowest classification risk on the validation set. In this paper,\nwe theoretically demonstrate a trade-off between minimizing classification risk\nand mitigating domain discrepancy, i.e., it is impossible to achieve the\nminimum of these two objectives simultaneously. Motivated by this theoretical\nresult, we propose a novel model selection method suggesting that the\nvalidation process should account for both the classification risk and the\ndomain discrepancy. We validate the effectiveness of the proposed method by\nnumerical results on several domain generalization datasets.\n",
                "链接": "https://arxiv.org/abs/2304.00629"
            },
            {
                "文章ID": "13859",
                "标题": "Autoencoding Language Model Based Ensemble Learning for Commonsense\n  Validation and Explanation",
                "作者": " Ngo Quang Huy,  Tu Minh Phuong,  Ngo Xuan Bach",
                "发布日期": "2022-04-08",
                "摘要": "  An ultimate goal of artificial intelligence is to build computer systems that\ncan understand human languages. Understanding commonsense knowledge about the\nworld expressed in text is one of the foundational and challenging problems to\ncreate such intelligent systems. As a step towards this goal, we present in\nthis paper ALMEn, an Autoencoding Language Model based Ensemble learning method\nfor commonsense validation and explanation. By ensembling several advanced\npre-trained language models including RoBERTa, DeBERTa, and ELECTRA with\nSiamese neural networks, our method can distinguish natural language statements\nthat are against commonsense (validation subtask) and correctly identify the\nreason for making against commonsense (explanation selection subtask).\nExperimental results on the benchmark dataset of SemEval-2020 Task 4 show that\nour method outperforms state-of-the-art models, reaching 97.9% and 95.4%\naccuracies on the validation and explanation selection subtasks, respectively.\n",
                "链接": "https://arxiv.org/abs/2204.03324"
            },
            {
                "文章ID": "49304",
                "标题": "Exploring validation metrics for offline model-based optimisation",
                "作者": " Christopher Beckham,  Alexandre Piche,  David Vazquez,  Christopher Pal",
                "发布日期": "2023-02-07",
                "摘要": "  In offline model-based optimisation (MBO) we are interested in using machine\nlearning to design candidates that maximise some measure of desirability\nthrough an expensive but real-world scoring process. Offline MBO tries to\napproximate this expensive scoring function and use that to evaluate generated\ndesigns, however evaluation is non-exact because one approximation is being\nevaluated with another. Instead, we ask ourselves: if we did have the real\nworld scoring function at hand, what cheap-to-compute validation metrics would\ncorrelate best with this? Since the real-world scoring function is available\nfor simulated MBO datasets, insights obtained from this can be transferred over\nto real-world offline MBO tasks where the real-world scoring function is\nexpensive to compute. To address this, we propose a conceptual evaluation\nframework that is amenable to measuring extrapolation, and apply this to\nconditional denoising diffusion models. Empirically, we find that two\nvalidation metrics -- agreement and Frechet distance -- correlate quite well\nwith the ground truth. When there is high variability in conditional\ngeneration, feedback is required in the form of an approximated version of the\nreal-world scoring function. Furthermore, we find that generating high-scoring\nsamples may require heavily weighting the generative model in favour of sample\nquality, potentially at the cost of sample diversity.\n",
                "链接": "https://arxiv.org/abs/2211.10747"
            },
            {
                "文章ID": "37962",
                "标题": "Dataset Inference for Self-Supervised Models",
                "作者": " Adam Dziedzic,  Haonan Duan,  Muhammad Ahmad Kaleem,  Nikita Dhawan,  Jonas Guan,  Yannis Cattan,  Franziska Boenisch,  Nicolas Papernot",
                "发布日期": "2023-01-18",
                "摘要": "  Self-supervised models are increasingly prevalent in machine learning (ML)\nsince they reduce the need for expensively labeled data. Because of their\nversatility in downstream applications, they are increasingly used as a service\nexposed via public APIs. At the same time, these encoder models are\nparticularly vulnerable to model stealing attacks due to the high\ndimensionality of vector representations they output. Yet, encoders remain\nundefended: existing mitigation strategies for stealing attacks focus on\nsupervised learning. We introduce a new dataset inference defense, which uses\nthe private training set of the victim encoder model to attribute its ownership\nin the event of stealing. The intuition is that the log-likelihood of an\nencoder's output representations is higher on the victim's training data than\non test data if it is stolen from the victim, but not if it is independently\ntrained. We compute this log-likelihood using density estimation models. As\npart of our evaluation, we also propose measuring the fidelity of stolen\nencoders and quantifying the effectiveness of the theft detection without\ninvolving downstream tasks; instead, we leverage mutual information and\ndistance measurements. Our extensive empirical results in the vision domain\ndemonstrate that dataset inference is a promising direction for defending\nself-supervised models against model stealing.\n",
                "链接": "https://arxiv.org/abs/2209.09024"
            },
            {
                "文章ID": "111185",
                "标题": "Synthetic Data as Validation",
                "作者": " Qixin Hu,  Alan Yuille,  Zongwei Zhou",
                "发布日期": "2023-10-25",
                "摘要": "  This study leverages synthetic data as a validation set to reduce overfitting\nand ease the selection of the best model in AI development. While synthetic\ndata have been used for augmenting the training set, we find that synthetic\ndata can also significantly diversify the validation set, offering marked\nadvantages in domains like healthcare, where data are typically limited,\nsensitive, and from out-domain sources (i.e., hospitals). In this study, we\nillustrate the effectiveness of synthetic data for early cancer detection in\ncomputed tomography (CT) volumes, where synthetic tumors are generated and\nsuperimposed onto healthy organs, thereby creating an extensive dataset for\nrigorous validation. Using synthetic data as validation can improve AI\nrobustness in both in-domain and out-domain test sets. Furthermore, we\nestablish a new continual learning framework that continuously trains AI models\non a stream of out-domain data with synthetic tumors. The AI model trained and\nvalidated in dynamically expanding synthetic data can consistently outperform\nmodels trained and validated exclusively on real-world data. Specifically, the\nDSC score for liver tumor segmentation improves from 26.7% (95% CI:\n22.6%-30.9%) to 34.5% (30.8%-38.2%) when evaluated on an in-domain dataset and\nfrom 31.1% (26.0%-36.2%) to 35.4% (32.1%-38.7%) on an out-domain dataset.\nImportantly, the performance gain is particularly significant in identifying\nvery tiny liver tumors (radius < 5mm) in CT volumes, with Sensitivity improving\nfrom 33.1% to 55.4% on an in-domain dataset and 33.9% to 52.3% on an out-domain\ndataset, justifying the efficacy in early detection of cancer. The application\nof synthetic data, from both training and validation perspectives, underlines a\npromising avenue to enhance AI robustness when dealing with data from varying\ndomains.\n",
                "链接": "https://arxiv.org/abs/2310.16052"
            }
        ]
    },
    {
        "question": {
            "question": "帮我找一下用大模型进行论文查找的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "36500",
                "标题": "Tag-Aware Document Representation for Research Paper Recommendation",
                "作者": " Hebatallah A. Mohamed,  Giuseppe Sansonetti,  Alessandro Micarelli",
                "发布日期": "2022-09-09",
                "摘要": "  Finding online research papers relevant to one's interests is very\nchallenging due to the increasing number of publications. Therefore,\npersonalized research paper recommendation has become a significant and timely\nresearch topic. Collaborative filtering is a successful recommendation\napproach, which exploits the ratings given to items by users as a source of\ninformation for learning to make accurate recommendations. However, the ratings\nare often very sparse as in the research paper domain, due to the huge number\nof publications growing every year. Therefore, more attention has been drawn to\nhybrid methods that consider both ratings and content information.\nNevertheless, most of the hybrid recommendation approaches that are based on\ntext embedding have utilized bag-of-words techniques, which ignore word order\nand semantic meaning. In this paper, we propose a hybrid approach that\nleverages deep semantic representation of research papers based on social tags\nassigned by users. The experimental evaluation is performed on CiteULike, a\nreal and publicly available dataset. The obtained findings show that the\nproposed model is effective in recommending research papers even when the\nrating data is very sparse.\n",
                "链接": "https://arxiv.org/abs/2209.03660"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "98470",
                "标题": "SciEval: A Multi-Level Large Language Model Evaluation Benchmark for\n  Scientific Research",
                "作者": " Liangtai Sun,  Yang Han,  Zihan Zhao,  Da Ma,  Zhennan Shen,  Baocai Chen,  Lu Chen,  Kai Yu",
                "发布日期": "2023-08-28",
                "摘要": "  Recently, there has been growing interest in using Large Language Models\n(LLMs) for scientific research. Numerous benchmarks have been proposed to\nevaluate the ability of LLMs for scientific research. However, current\nbenchmarks are mostly based on pre-collected objective questions. This design\nsuffers from data leakage problem and lacks the evaluation of subjective Q/A\nability. In this paper, we propose SciEval, a comprehensive and\nmulti-disciplinary evaluation benchmark to address these issues. Based on\nBloom's taxonomy, SciEval covers four dimensions to systematically evaluate\nscientific research ability. In particular, we design a \"dynamic\" subset based\non scientific principles to prevent evaluation from potential data leakage.\nBoth objective and subjective questions are included in SciEval. These\ncharacteristics make SciEval a more effective benchmark for scientific research\nability evaluation of LLMs. Comprehensive experiments on most advanced LLMs\nshow that, although GPT-4 achieves SOTA performance compared to other LLMs,\nthere is still substantial room for improvement, especially for dynamic\nquestions. The data and codes are now publicly available.\n",
                "链接": "https://arxiv.org/abs/2308.13149"
            },
            {
                "文章ID": "66370",
                "标题": "Algorithmic Ghost in the Research Shell: Large Language Models and\n  Academic Knowledge Creation in Management Research",
                "作者": " Nigel Williams,  Stanislav Ivanov,  Dimitrios Buhalis",
                "发布日期": "2023-03-14",
                "摘要": "  The paper looks at the role of large language models in academic knowledge\ncreation based on a scoping review (2018 to January 2023) of how researchers\nhave previously used the language model GPT to assist in the performance of\nacademic knowledge creation tasks beyond data analysis. These tasks include\nwriting, editing, reviewing, dataset creation and curation, which have been\ndifficult to perform using earlier ML tools. Based on a synthesis of these\npapers, this study identifies pathways for a future academic research landscape\nthat incorporates wider usage of large language models based on the current\nmodes of adoption in published articles as a Co-Writer, Research Assistant and\nRespondent.\n",
                "链接": "https://arxiv.org/abs/2303.07304"
            },
            {
                "文章ID": "117394",
                "标题": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
                "作者": " Chengyu Wang,  Junbing Yan,  Wei Zhang,  Jun Huang",
                "发布日期": "2023-11-23",
                "摘要": "  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.13126"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "71835",
                "标题": "Emergent autonomous scientific research capabilities of large language\n  models",
                "作者": " Daniil A. Boiko,  Robert MacKnight,  Gabe Gomes",
                "发布日期": "2023-04-12",
                "摘要": "  Transformer-based large language models are rapidly advancing in the field of\nmachine learning research, with applications spanning natural language,\nbiology, chemistry, and computer programming. Extreme scaling and reinforcement\nlearning from human feedback have significantly improved the quality of\ngenerated text, enabling these models to perform various tasks and reason about\ntheir choices. In this paper, we present an Intelligent Agent system that\ncombines multiple large language models for autonomous design, planning, and\nexecution of scientific experiments. We showcase the Agent's scientific\nresearch capabilities with three distinct examples, with the most complex being\nthe successful performance of catalyzed cross-coupling reactions. Finally, we\ndiscuss the safety implications of such systems and propose measures to prevent\ntheir misuse.\n",
                "链接": "https://arxiv.org/abs/2304.05332"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "38582",
                "标题": "Attention is All They Need: Exploring the Media Archaeology of the\n  Computer Vision Research Paper",
                "作者": " Samuel Goree,  Gabriel Appleby,  David Crandall,  Norman Su",
                "发布日期": "2022-09-23",
                "摘要": "  The success of deep learning has led to the rapid transformation and growth\nof many areas of computer science, including computer vision. In this work, we\nexamine the effects of this growth through the computer vision research paper\nitself by analyzing the figures and tables in research papers from a media\narchaeology perspective. We ground our investigation both through interviews\nwith veteran researchers spanning computer vision, graphics and visualization,\nand computational analysis of a decade of vision conference papers. Our\nanalysis focuses on elements with roles in advertising, measuring and\ndisseminating an increasingly commodified \"contribution.\" We argue that each of\nthese elements has shaped and been shaped by the climate of computer vision,\nultimately contributing to that commodification. Through this work, we seek to\nmotivate future discussion surrounding the design of the research paper and the\nbroader socio-technical publishing system.\n",
                "链接": "https://arxiv.org/abs/2209.11200"
            },
            {
                "文章ID": "79552",
                "标题": "A Study of Generative Large Language Model for Medical Research and\n  Healthcare",
                "作者": " Cheng Peng,  Xi Yang,  Aokun Chen,  Kaleb E Smith,  Nima PourNejatian,  Anthony B Costa,  Cheryl Martin,  Mona G Flores,  Ying Zhang,  Tanja Magoc,  Gloria Lipori,  Duane A Mitchell,  Naykky S Ospina,  Mustafa M Ahmed,  William R Hogan,  Elizabeth A Shenkman,  Yi Guo,  Jiang Bian,  Yonghui Wu",
                "发布日期": "2023-11-20",
                "摘要": "  There is enormous enthusiasm and concerns in using large language models\n(LLMs) in healthcare, yet current assumptions are all based on general-purpose\nLLMs such as ChatGPT. This study develops a clinical generative LLM,\nGatorTronGPT, using 277 billion words of mixed clinical and English text with a\nGPT-3 architecture of 20 billion parameters. GatorTronGPT improves biomedical\nnatural language processing for medical research. Synthetic NLP models trained\nusing GatorTronGPT generated text outperform NLP models trained using\nreal-world clinical text. Physicians Turing test using 1 (worst) to 9 (best)\nscale shows that there is no significant difference in linguistic readability\n(p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical\nrelevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that\nphysicians cannot differentiate them (p < 0.001). This study provides insights\non the opportunities and challenges of LLMs for medical research and\nhealthcare.\n",
                "链接": "https://arxiv.org/abs/2305.13523"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到，最早提出分布式词表示的论文是哪一篇？",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "16842",
                "标题": "Extremal GloVe: Theoretically Accurate Distributed Word Embedding by\n  Tail Inference",
                "作者": " Hao Wang",
                "发布日期": "2022-04-28",
                "摘要": "  Distributed word embeddings such as Word2Vec and GloVe have been widely\nadopted in industrial context settings. Major technical applications of GloVe\ninclude recommender systems and natural language processing. The fundamental\ntheory behind GloVe relies on the selection of a weighting function in the\nweighted least squres formulation that computes the powered ratio of word\noccurrence count and the maximum word count in the corpus. However, the initial\nformulation of GloVe is not theoretically sound in two aspects, namely the\nselection of the weighting function and its power exponent is ad-hoc. In this\npaper, we utilize the theory of extreme value analysis and propose a\ntheoretically accurate version of GloVe. By reformulating the weighted least\nsquares loss function as the expected loss function and accurately choosing the\npower exponent, we create a theoretically accurate version of GloVe. We\ndemonstrate the competitiveness of our algorithm and show that the initial\nformulation of GloVe with the suggested optimal parameter can be viewed as a\nspecial case of our paradigm.\n",
                "链接": "https://arxiv.org/abs/2204.13009"
            }
        ]
    },
    {
        "question": {
            "question": "请列出近一年来工业界发表的搜广推工作落地实践的论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "闭源大模型用户数据隐私保护研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "52013",
                "标题": "AI-driven Mobile Apps: an Explorative Study",
                "作者": " Yinghua Li,  Xueqi Dang,  Haoye Tian,  Tiezhu Sun,  Zhijie Wang,  Lei Ma,  Jacques Klein,  Tegawende F. Bissyande",
                "发布日期": "2022-12-06",
                "摘要": "  Recent years have witnessed an astonishing explosion in the evolution of\nmobile applications powered by AI technologies. The rapid growth of AI\nframeworks enables the transition of AI technologies to mobile devices,\nsignificantly prompting the adoption of AI apps (i.e., apps that integrate AI\ninto their functions) among smartphone devices. In this paper, we conduct the\nmost extensive empirical study on 56,682 published AI apps from three\nperspectives: dataset characteristics, development issues, and user feedback\nand privacy. To this end, we build an automated AI app identification tool, AI\nDiscriminator, that detects eligible AI apps from 7,259,232 mobile apps. First,\nwe carry out a dataset analysis, where we explore the AndroZoo large repository\nto identify AI apps and their core characteristics. Subsequently, we pinpoint\nkey issues in AI app development (e.g., model protection). Finally, we focus on\nuser reviews and user privacy protection. Our paper provides several notable\nfindings. Some essential ones involve revealing the issue of insufficient model\nprotection by presenting the lack of model encryption, and demonstrating the\nrisk of user privacy data being leaked. We published our large-scale AI app\ndatasets to inspire more future research.\n",
                "链接": "https://arxiv.org/abs/2212.01635"
            },
            {
                "文章ID": "85712",
                "标题": "Protecting User Privacy in Remote Conversational Systems: A\n  Privacy-Preserving framework based on text sanitization",
                "作者": " Zhigang Kan,  Linbo Qiao,  Hao Yu,  Liwen Peng,  Yifu Gao,  Dongsheng Li",
                "发布日期": "2023-06-16",
                "摘要": "  Large Language Models (LLMs) are gaining increasing attention due to their\nexceptional performance across numerous tasks. As a result, the general public\nutilize them as an influential tool for boosting their productivity while\nnatural language processing researchers endeavor to employ them in solving\nexisting or new research problems. Unfortunately, individuals can only access\nsuch powerful AIs through APIs, which ultimately leads to the transmission of\nraw data to the models' providers and increases the possibility of privacy data\nleakage. Current privacy-preserving methods for cloud-deployed language models\naim to protect privacy information in the pre-training dataset or during the\nmodel training phase. However, they do not meet the specific challenges\npresented by the remote access approach of new large-scale language models.\n  This paper introduces a novel task, \"User Privacy Protection for Dialogue\nModels,\" which aims to safeguard sensitive user information from any possible\ndisclosure while conversing with chatbots. We also present an evaluation scheme\nfor this task, which covers evaluation metrics for privacy protection, data\navailability, and resistance to simulation attacks. Moreover, we propose the\nfirst framework for this task, namely privacy protection through text\nsanitization. Before sending the input to remote large models, it filters out\nthe sensitive information, using several rounds of text sanitization based on\nprivacy types that users define. Upon receiving responses from the larger\nmodel, our framework automatically restores privacy to ensure that the\nconversation goes smoothly, without intervention from the privacy filter.\nExperiments based on real-world datasets demonstrate the efficacy of our\nprivacy-preserving approach against eavesdropping from potential attackers.\n",
                "链接": "https://arxiv.org/abs/2306.08223"
            },
            {
                "文章ID": "119126",
                "标题": "Toward the Tradeoffs between Privacy, Fairness and Utility in Federated\n  Learning",
                "作者": " Kangkang Sun,  Xiaojin Zhang,  Xi Lin,  Gaolei Li,  Jing Wang,  Jianhua Li",
                "发布日期": "2023-12-01",
                "摘要": "  Federated Learning (FL) is a novel privacy-protection distributed machine\nlearning paradigm that guarantees user privacy and prevents the risk of data\nleakage due to the advantage of the client's local training. Researchers have\nstruggled to design fair FL systems that ensure fairness of results. However,\nthe interplay between fairness and privacy has been less studied. Increasing\nthe fairness of FL systems can have an impact on user privacy, while an\nincrease in user privacy can affect fairness. In this work, on the client side,\nwe use fairness metrics, such as Demographic Parity (DemP), Equalized Odds\n(EOs), and Disparate Impact (DI), to construct the local fair model. To protect\nthe privacy of the client model, we propose a privacy-protection fairness FL\nmethod. The results show that the accuracy of the fair model with privacy\nincreases because privacy breaks the constraints of the fairness metrics. In\nour experiments, we conclude the relationship between privacy, fairness and\nutility, and there is a tradeoff between these.\n",
                "链接": "https://arxiv.org/abs/2311.18190"
            },
            {
                "文章ID": "36560",
                "标题": "A Framework for Evaluating Privacy-Utility Trade-off in Vertical\n  Federated Learning",
                "作者": " Yan Kang,  Jiahuan Luo,  Yuanqin He,  Xiaojin Zhang,  Lixin Fan,  Qiang Yang",
                "发布日期": "2022-09-12",
                "摘要": "  Federated learning (FL) has emerged as a practical solution to tackle data\nsilo issues without compromising user privacy. One of its variants, vertical\nfederated learning (VFL), has recently gained increasing attention as the VFL\nmatches the enterprises' demands of leveraging more valuable features to build\nbetter machine learning models while preserving user privacy. Current works in\nVFL concentrate on developing a specific protection or attack mechanism for a\nparticular VFL algorithm. In this work, we propose an evaluation framework that\nformulates the privacy-utility evaluation problem. We then use this framework\nas a guide to comprehensively evaluate a broad range of protection mechanisms\nagainst most of the state-of-the-art privacy attacks for three widely-deployed\nVFL algorithms. These evaluations may help FL practitioners select appropriate\nprotection mechanisms given specific requirements. Our evaluation results\ndemonstrate that: the model inversion and most of the label inference attacks\ncan be thwarted by existing protection mechanisms; the model completion (MC)\nattack is difficult to be prevented, which calls for more advanced MC-targeted\nprotection mechanisms. Based on our evaluation results, we offer concrete\nadvice on improving the privacy-preserving capability of VFL systems.\n",
                "链接": "https://arxiv.org/abs/2209.03885"
            },
            {
                "文章ID": "112402",
                "标题": "Building Real-World Meeting Summarization Systems using Large Language\n  Models: A Practical Perspective",
                "作者": " Md Tahmid Rahman Laskar,  Xue-Yong Fu,  Cheng Chen,  Shashi Bhushan TN",
                "发布日期": "2023-11-09",
                "摘要": "  This paper studies how to effectively build meeting summarization systems for\nreal-world usage using large language models (LLMs). For this purpose, we\nconduct an extensive evaluation and comparison of various closed-source and\nopen-source LLMs, namely, GPT-4, GPT- 3.5, PaLM-2, and LLaMA-2. Our findings\nreveal that most closed-source LLMs are generally better in terms of\nperformance. However, much smaller open-source models like LLaMA- 2 (7B and\n13B) could still achieve performance comparable to the large closed-source\nmodels even in zero-shot scenarios. Considering the privacy concerns of\nclosed-source models for only being accessible via API, alongside the high cost\nassociated with using fine-tuned versions of the closed-source models, the\nopensource models that can achieve competitive performance are more\nadvantageous for industrial use. Balancing performance with associated costs\nand privacy concerns, the LLaMA-2-7B model looks more promising for industrial\nusage. In sum, this paper offers practical insights on using LLMs for\nreal-world business meeting summarization, shedding light on the trade-offs\nbetween performance and cost.\n",
                "链接": "https://arxiv.org/abs/2310.19233"
            },
            {
                "文章ID": "84894",
                "标题": "SoK: Analysis of User-Centered Studies Focusing on Healthcare Privacy &\n  Security",
                "作者": " Faiza Tazi,  Archana Nandakumar,  Josiah Dykstra,  Prashanth Rajivan,  Sanchari Das",
                "发布日期": "2023-06-27",
                "摘要": "  Sensitive information is intrinsically tied to interactions in healthcare,\nand its protection is of paramount importance for achieving high-quality\npatient outcomes. Research in healthcare privacy and security is predominantly\nfocused on understanding the factors that increase the susceptibility of users\nto privacy and security breaches. To understand further, we systematically\nreview 26 research papers in this domain to explore the existing user studies\nin healthcare privacy and security. Following the review, we conducted a\ncard-sorting exercise, allowing us to identify 12 themes integral to this\nsubject such as \"Data Sharing,\" \"Risk Awareness,\" and \"Privacy.\" Further to the\nidentification of these themes, we performed an in-depth analysis of the 26\nresearch papers report on the insights into the discourse within the research\ncommunity about healthcare privacy and security, particularly from the user\nperspective.\n",
                "链接": "https://arxiv.org/abs/2306.06033"
            },
            {
                "文章ID": "16263",
                "标题": "MLP-Hash: Protecting Face Templates via Hashing of Randomized\n  Multi-Layer Perceptron",
                "作者": " Hatef Otroshi Shahreza,  Vedrana Krivokuća Hahn,  Sébastien Marcel",
                "发布日期": "2023-09-06",
                "摘要": "  Applications of face recognition systems for authentication purposes are\ngrowing rapidly. Although state-of-the-art (SOTA) face recognition systems have\nhigh recognition accuracy, the features which are extracted for each user and\nare stored in the system's database contain privacy-sensitive information.\nAccordingly, compromising this data would jeopardize users' privacy. In this\npaper, we propose a new cancelable template protection method, dubbed MLP-hash,\nwhich generates protected templates by passing the extracted features through a\nuser-specific randomly-weighted multi-layer perceptron (MLP) and binarizing the\nMLP output. We evaluated the unlinkability, irreversibility, and recognition\naccuracy of our proposed biometric template protection method to fulfill the\nISO/IEC 30136 standard requirements. Our experiments with SOTA face recognition\nsystems on the MOBIO and LFW datasets show that our method has competitive\nperformance with the BioHashing and IoM Hashing (IoM-GRP and IoM-URP) template\nprotection algorithms. We provide an open-source implementation of all the\nexperiments presented in this paper so that other researchers can verify our\nfindings and build upon our work.\n",
                "链接": "https://arxiv.org/abs/2204.11054"
            },
            {
                "文章ID": "76087",
                "标题": "An Overview of AI and Blockchain Integration for Privacy-Preserving",
                "作者": " Zongwei Li,  Dechao Kong,  Yuanzheng Niu,  Hongli Peng,  Xiaoqi Li,  Wenkai Li",
                "发布日期": "2023-05-09",
                "摘要": "  With the widespread attention and application of artificial intelligence (AI)\nand blockchain technologies, privacy protection techniques arising from their\nintegration are of notable significance. In addition to protecting privacy of\nindividuals, these techniques also guarantee security and dependability of\ndata. This paper initially presents an overview of AI and blockchain,\nsummarizing their combination along with derived privacy protection\ntechnologies. It then explores specific application scenarios in data\nencryption, de-identification, multi-tier distributed ledgers, and k-anonymity\nmethods. Moreover, the paper evaluates five critical aspects of\nAI-blockchain-integration privacy protection systems, including authorization\nmanagement, access control, data protection, network security, and scalability.\nFurthermore, it analyzes the deficiencies and their actual cause, offering\ncorresponding suggestions. This research also classifies and summarizes privacy\nprotection techniques based on AI-blockchain application scenarios and\ntechnical schemes. In conclusion, this paper outlines the future directions of\nprivacy protection technologies emerging from AI and blockchain integration,\nincluding enhancing efficiency and security to achieve a more comprehensive\nprivacy protection of privacy.\n",
                "链接": "https://arxiv.org/abs/2305.03928"
            },
            {
                "文章ID": "37431",
                "标题": "Does CLIP Know My Face?",
                "作者": " Dominik Hintersdorf,  Lukas Struppek,  Manuel Brack,  Felix Friedrich,  Patrick Schramowski,  Kristian Kersting",
                "发布日期": "2023-05-31",
                "摘要": "  With the rise of deep learning in various applications, privacy concerns\naround the protection of training data has become a critical area of research.\nWhereas prior studies have focused on privacy risks in single-modal models, we\nintroduce a novel method to assess privacy for multi-modal models, specifically\nvision-language models like CLIP. The proposed Identity Inference Attack (IDIA)\nreveals whether an individual was included in the training data by querying the\nmodel with images of the same person. Letting the model choose from a wide\nvariety of possible text labels, the model reveals whether it recognizes the\nperson and, therefore, was used for training. Our large-scale experiments on\nCLIP demonstrate that individuals used for training can be identified with very\nhigh accuracy. We confirm that the model has learned to associate names with\ndepicted individuals, implying the existence of sensitive information that can\nbe extracted by adversaries. Our results highlight the need for stronger\nprivacy protection in large-scale models and suggest that IDIAs can be used to\nprove the unauthorized use of data for training and to enforce privacy laws.\n",
                "链接": "https://arxiv.org/abs/2209.07341"
            },
            {
                "文章ID": "36093",
                "标题": "How Much User Context Do We Need? Privacy by Design in Mental Health NLP\n  Application",
                "作者": " Ramit Sawhney,  Atula Tejaswi Neerkaje,  Ivan Habernal,  Lucie Flek",
                "发布日期": "2022-09-07",
                "摘要": "  Clinical NLP tasks such as mental health assessment from text, must take\nsocial constraints into account - the performance maximization must be\nconstrained by the utmost importance of guaranteeing privacy of user data.\nConsumer protection regulations, such as GDPR, generally handle privacy by\nrestricting data availability, such as requiring to limit user data to 'what is\nnecessary' for a given purpose. In this work, we reason that providing stricter\nformal privacy guarantees, while increasing the volume of user data in the\nmodel, in most cases increases benefit for all parties involved, especially for\nthe user. We demonstrate our arguments on two existing suicide risk assessment\ndatasets of Twitter and Reddit posts. We present the first analysis juxtaposing\nuser history length and differential privacy budgets and elaborate how modeling\nadditional user context enables utility preservation while maintaining\nacceptable user privacy guarantees.\n",
                "链接": "https://arxiv.org/abs/2209.02022"
            }
        ]
    },
    {
        "question": {
            "question": "推荐与AutoGPT相似的10篇文献",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "86417",
                "标题": "AD-AutoGPT: An Autonomous GPT for Alzheimer's Disease Infodemiology",
                "作者": " Haixing Dai,  Yiwei Li,  Zhengliang Liu,  Lin Zhao,  Zihao Wu,  Suhang Song,  Ye Shen,  Dajiang Zhu,  Xiang Li,  Sheng Li,  Xiaobai Yao,  Lu Shi,  Quanzheng Li,  Zhuo Chen,  Donglan Zhang,  Gengchen Mai,  Tianming Liu",
                "发布日期": "2023-06-21",
                "摘要": "  In this pioneering study, inspired by AutoGPT, the state-of-the-art\nopen-source application based on the GPT-4 large language model, we develop a\nnovel tool called AD-AutoGPT which can conduct data collection, processing, and\nanalysis about complex health narratives of Alzheimer's Disease in an\nautonomous manner via users' textual prompts. We collated comprehensive data\nfrom a variety of news sources, including the Alzheimer's Association, BBC,\nMayo Clinic, and the National Institute on Aging since June 2022, leading to\nthe autonomous execution of robust trend analyses, intertopic distance maps\nvisualization, and identification of salient terms pertinent to Alzheimer's\nDisease. This approach has yielded not only a quantifiable metric of relevant\ndiscourse but also valuable insights into public focus on Alzheimer's Disease.\nThis application of AD-AutoGPT in public health signifies the transformative\npotential of AI in facilitating a data-rich understanding of complex health\nnarratives like Alzheimer's Disease in an autonomous manner, setting the\ngroundwork for future AI-driven investigations in global health landscapes.\n",
                "链接": "https://arxiv.org/abs/2306.10095"
            },
            {
                "文章ID": "88929",
                "标题": "Lottery and Sprint: Generate a Board Game with Design Sprint Method on\n  AutoGPT",
                "作者": " Maya Grace Torii,  Takahito Murakami,  Yoichi Ochiai",
                "发布日期": "2023-12-25",
                "摘要": "  In this paper, we present a novel approach using the Auto GPT system\nalongside Design Sprint methodology to facilitate board game creation for\ninexperienced users. We introduce the implementation of Auto GPT for generating\ndiverse board games and the subsequent optimization process through a\ncustomized Design Sprint. A user study is conducted to investigate the\nplayability and enjoyment of the generated games, revealing both successes and\nchallenges in employing systems like Auto GPT for board game design. Insights\nand future research directions are proposed to overcome identified limitations\nand enhance computational-driven game creation.\n",
                "链接": "https://arxiv.org/abs/2307.00348"
            }
        ]
    },
    {
        "question": {
            "question": "请搜索近一年发表的有关多模态大模型与产业相结合、与具体应用场景相结合的论文",
            "type": "2"
        },
        "results": [
            {
                "文章ID": "97795",
                "标题": "Federated Learning in Big Model Era: Domain-Specific Multimodal Large\n  Models",
                "作者": " Zengxiang Li,  Zhaoxiang Hou,  Hui Liu,  Ying Wang,  Tongzhi Li,  Longfei Xie,  Chao Shi,  Chengyi Yang,  Weishan Zhang,  Zelei Liu,  Liang Xu",
                "发布日期": "2023-08-25",
                "摘要": "  Multimodal data, which can comprehensively perceive and recognize the\nphysical world, has become an essential path towards general artificial\nintelligence. However, multimodal large models trained on public datasets often\nunderperform in specific industrial domains. This paper proposes a multimodal\nfederated learning framework that enables multiple enterprises to utilize\nprivate domain data to collaboratively train large models for vertical domains,\nachieving intelligent services across scenarios. The authors discuss in-depth\nthe strategic transformation of federated learning in terms of intelligence\nfoundation and objectives in the era of big model, as well as the new\nchallenges faced in heterogeneous data, model aggregation, performance and cost\ntrade-off, data privacy, and incentive mechanism. The paper elaborates a case\nstudy of leading enterprises contributing multimodal data and expert knowledge\nto city safety operation management , including distributed deployment and\nefficient coordination of the federated learning platform, technical\ninnovations on data quality improvement based on large model capabilities and\nefficient joint fine-tuning approaches. Preliminary experiments show that\nenterprises can enhance and accumulate intelligent capabilities through\nmultimodal model federated learning, thereby jointly creating an smart city\nmodel that provides high-quality intelligent services covering energy\ninfrastructure safety, residential community security, and urban operation\nmanagement. The established federated learning cooperation ecosystem is\nexpected to further aggregate industry, academia, and research resources,\nrealize large models in multiple vertical domains, and promote the large-scale\nindustrial application of artificial intelligence and cutting-edge research on\nmultimodal federated learning.\n",
                "链接": "https://arxiv.org/abs/2308.11217"
            },
            {
                "文章ID": "116538",
                "标题": "Modality-invariant and Specific Prompting for Multimodal Human\n  Perception Understanding",
                "作者": " Hao Sun,  Ziwei Niu,  Xinyao Yu,  Jiaqing Liu,  Yen-Wei Chen,  Lanfen Lin",
                "发布日期": "2023-11-21",
                "摘要": "  Understanding human perceptions presents a formidable multimodal challenge\nfor computers, encompassing aspects such as sentiment tendencies and sense of\nhumor. While various methods have recently been introduced to extract\nmodality-invariant and specific information from diverse modalities, with the\ngoal of enhancing the efficacy of multimodal learning, few works emphasize this\naspect in large language models. In this paper, we introduce a novel multimodal\nprompt strategy tailored for tuning large language models. Our method assesses\nthe correlation among different modalities and isolates the modality-invariant\nand specific components, which are then utilized for prompt tuning. This\napproach enables large language models to efficiently and effectively\nassimilate information from various modalities. Furthermore, our strategy is\ndesigned with scalability in mind, allowing the integration of features from\nany modality into pretrained large language models. Experimental results on\npublic datasets demonstrate that our proposed method significantly improves\nperformance compared to previous methods.\n",
                "链接": "https://arxiv.org/abs/2311.10791"
            },
            {
                "文章ID": "113853",
                "标题": "ChEF: A Comprehensive Evaluation Framework for Standardized Assessment\n  of Multimodal Large Language Models",
                "作者": " Zhelun Shi,  Zhipin Wang,  Hongxing Fan,  Zhenfei Yin,  Lu Sheng,  Yu Qiao,  Jing Shao",
                "发布日期": "2023-11-07",
                "摘要": "  Multimodal Large Language Models (MLLMs) have shown impressive abilities in\ninteracting with visual content with myriad potential downstream tasks.\nHowever, even though a list of benchmarks has been proposed, the capabilities\nand limitations of MLLMs are still not comprehensively understood, due to a\nlack of a standardized and holistic evaluation framework. To this end, we\npresent the first Comprehensive Evaluation Framework (ChEF) that can\nholistically profile each MLLM and fairly compare different MLLMs. First, we\nstructure ChEF as four modular components, i.e., Scenario as scalable\nmultimodal datasets, Instruction as flexible instruction retrieving formulae,\nInferencer as reliable question answering strategies, and Metric as indicative\ntask-specific score functions. Based on them, ChEF facilitates versatile\nevaluations in a standardized framework, and new evaluations can be built by\ndesigning new Recipes (systematic selection of these four components). Notably,\ncurrent MLLM benchmarks can be readily summarized as recipes of ChEF. Second,\nwe introduce 6 new recipes to quantify competent MLLMs' desired capabilities\n(or called desiderata, i.e., calibration, in-context learning, instruction\nfollowing, language performance, hallucination, and robustness) as reliable\nagents that can perform real-world multimodal interactions. Third, we conduct a\nlarge-scale evaluation of 9 prominent MLLMs on 9 scenarios and 6 desiderata.\nOur evaluation summarized over 20 valuable observations concerning the\ngeneralizability of MLLMs across various scenarios and the composite capability\nof MLLMs required for multimodal interactions. We will publicly release all the\ndetailed implementations for further analysis, as well as an easy-to-use\nmodular toolkit for the integration of new recipes and models, so that ChEF can\nbe a growing evaluation framework for the MLLM community.\n",
                "链接": "https://arxiv.org/abs/2311.02692"
            },
            {
                "文章ID": "121813",
                "标题": "SmartEdit: Exploring Complex Instruction-based Image Editing with\n  Multimodal Large Language Models",
                "作者": " Yuzhou Huang,  Liangbin Xie,  Xintao Wang,  Ziyang Yuan,  Xiaodong Cun,  Yixiao Ge,  Jiantao Zhou,  Chao Dong,  Rui Huang,  Ruimao Zhang,  Ying Shan",
                "发布日期": "2023-12-13",
                "摘要": "  Current instruction-based editing methods, such as InstructPix2Pix, often\nfail to produce satisfactory results in complex scenarios due to their\ndependence on the simple CLIP text encoder in diffusion models. To rectify\nthis, this paper introduces SmartEdit, a novel approach to instruction-based\nimage editing that leverages Multimodal Large Language Models (MLLMs) to\nenhance their understanding and reasoning capabilities. However, direct\nintegration of these elements still faces challenges in situations requiring\ncomplex reasoning. To mitigate this, we propose a Bidirectional Interaction\nModule that enables comprehensive bidirectional information interactions\nbetween the input image and the MLLM output. During training, we initially\nincorporate perception data to boost the perception and understanding\ncapabilities of diffusion models. Subsequently, we demonstrate that a small\namount of complex instruction editing data can effectively stimulate\nSmartEdit's editing capabilities for more complex instructions. We further\nconstruct a new evaluation dataset, Reason-Edit, specifically tailored for\ncomplex instruction-based image editing. Both quantitative and qualitative\nresults on this evaluation dataset indicate that our SmartEdit surpasses\nprevious methods, paving the way for the practical application of complex\ninstruction-based image editing.\n",
                "链接": "https://arxiv.org/abs/2312.06739"
            },
            {
                "文章ID": "105595",
                "标题": "Application of frozen large-scale models to multimodal task-oriented\n  dialogue",
                "作者": " Tatsuki Kawamoto,  Takuma Suzuki,  Ko Miyama,  Takumi Meguro,  Tomohiro Takagi",
                "发布日期": "2023-10-03",
                "摘要": "  In this study, we use the existing Large Language Models ENnhanced to See\nFramework (LENS Framework) to test the feasibility of multimodal task-oriented\ndialogues. The LENS Framework has been proposed as a method to solve computer\nvision tasks without additional training and with fixed parameters of\npre-trained models. We used the Multimodal Dialogs (MMD) dataset, a multimodal\ntask-oriented dialogue benchmark dataset from the fashion field, and for the\nevaluation, we used the ChatGPT-based G-EVAL, which only accepts textual\nmodalities, with arrangements to handle multimodal data. Compared to\nTransformer-based models in previous studies, our method demonstrated an\nabsolute lift of 10.8% in fluency, 8.8% in usefulness, and 5.2% in relevance\nand coherence. The results show that using large-scale models with fixed\nparameters rather than using models trained on a dataset from scratch improves\nperformance in multimodal task-oriented dialogues. At the same time, we show\nthat Large Language Models (LLMs) are effective for multimodal task-oriented\ndialogues. This is expected to lead to efficient applications to existing\nsystems.\n",
                "链接": "https://arxiv.org/abs/2310.00845"
            },
            {
                "文章ID": "121257",
                "标题": "GlitchBench: Can large multimodal models detect video game glitches?",
                "作者": " Mohammad Reza Taesiri,  Tianjun Feng,  Cor-Paul Bezemer,  Anh Nguyen",
                "发布日期": "2023-12-12",
                "摘要": "  Large multimodal models (LMMs) have evolved from large language models (LLMs)\nto integrate multiple input modalities, such as visual inputs. This integration\naugments the capacity of LLMs for tasks requiring visual comprehension and\nreasoning. However, the extent and limitations of their enhanced abilities are\nnot fully understood, especially when it comes to real-world tasks. To address\nthis gap, we introduce GlitchBench, a novel benchmark derived from video game\nquality assurance tasks, to test and evaluate the reasoning capabilities of\nLMMs. Our benchmark is curated from a variety of unusual and glitched scenarios\nfrom video games and aims to challenge both the visual and linguistic reasoning\npowers of LMMs in detecting and interpreting out-of-the-ordinary events. We\nevaluate multiple state-of-the-art LMMs, and we show that GlitchBench presents\na new challenge for these models. Code and data are available at:\nhttps://glitchbench.github.io/\n",
                "链接": "https://arxiv.org/abs/2312.05291"
            },
            {
                "文章ID": "77191",
                "标题": "Knowledge Soft Integration for Multimodal Recommendation",
                "作者": " Kai Ouyang,  Chen Tang,  Wenhao Zheng,  Xiangjin Xie,  Xuanji Xiao,  Jian Dong,  Hai-Tao Zheng,  Zhi Wang",
                "发布日期": "2023-05-15",
                "摘要": "  One of the main challenges in modern recommendation systems is how to\neffectively utilize multimodal content to achieve more personalized\nrecommendations. Despite various proposed solutions, most of them overlook the\nmismatch between the knowledge gained from independent feature extraction\nprocesses and downstream recommendation tasks. Specifically, multimodal feature\nextraction processes do not incorporate prior knowledge relevant to\nrecommendation tasks, while recommendation tasks often directly use these\nmultimodal features as side information. This mismatch can lead to model\nfitting biases and performance degradation, which this paper refers to as the\n\\textit{curse of knowledge} problem. To address this issue, we propose using\nknowledge soft integration to balance the utilization of multimodal features\nand the curse of knowledge problem it brings about. To achieve this, we put\nforward a Knowledge Soft Integration framework for the multimodal\nrecommendation, abbreviated as KSI, which is composed of the Structure\nEfficiently Injection (SEI) module and the Semantic Soft Integration (SSI)\nmodule. In the SEI module, we model the modality correlation between items\nusing Refined Graph Neural Network (RGNN), and introduce a regularization term\nto reduce the redundancy of user/item representations. In the SSI module, we\ndesign a self-supervised retrieval task to further indirectly integrate the\nsemantic knowledge of multimodal features, and enhance the semantic\ndiscrimination of item representations. Extensive experiments on three\nbenchmark datasets demonstrate the superiority of KSI and validate the\neffectiveness of its two modules.\n",
                "链接": "https://arxiv.org/abs/2305.07419"
            },
            {
                "文章ID": "123840",
                "标题": "Future-proofing geotechnics workflows: accelerating problem-solving with\n  large language models",
                "作者": " Stephen Wu,  Yu Otake,  Daijiro Mizutani,  Chang Liu,  Kotaro Asano,  Nana Sato,  Hidetoshi Baba,  Yusuke Fukunaga,  Yosuke Higo,  Akiyoshi Kamura,  Shinnosuke Kodama,  Masataka Metoki,  Tomoka Nakamura,  Yuto Nakazato,  Taiga Saito,  Akihiro Shioi,  Masahiro Takenobu,  Keigo Tsukioka,  Ryo Yoshikawa",
                "发布日期": "2023-12-20",
                "摘要": "  The integration of Large Language Models (LLMs) like ChatGPT into the\nworkflows of geotechnical engineering has a high potential to transform how the\ndiscipline approaches problem-solving and decision-making. This paper delves\ninto the innovative application of LLMs in geotechnical engineering, as\nexplored in a hands-on workshop held in Tokyo, Japan. The event brought\ntogether a diverse group of 20 participants, including students, researchers,\nand professionals from academia, industry, and government sectors, to\ninvestigate practical uses of LLMs in addressing specific geotechnical\nchallenges. The workshop facilitated the creation of solutions for four\ndifferent practical geotechnical problems as illustrative examples, culminating\nin the development of an academic paper. The paper discusses the potential of\nLLMs to transform geotechnical engineering practices, highlighting their\nproficiency in handling a range of tasks from basic data analysis to complex,\nmultimodal problem-solving. It also addresses the challenges in implementing\nLLMs, particularly in achieving high precision and accuracy in specialized\ntasks, and underscores the need for expert oversight. The findings demonstrate\nLLMs' effectiveness in enhancing efficiency, data processing, and\ndecision-making in geotechnical engineering, suggesting a paradigm shift\ntowards more integrated, data-driven approaches in this field. This study not\nonly showcases the potential of LLMs in a specific engineering domain, but also\nsets a precedent for their broader application in interdisciplinary research\nand practice, where the synergy of human expertise and artificial intelligence\nredefines the boundaries of problem-solving.\n",
                "链接": "https://arxiv.org/abs/2312.12411"
            },
            {
                "文章ID": "76087",
                "标题": "An Overview of AI and Blockchain Integration for Privacy-Preserving",
                "作者": " Zongwei Li,  Dechao Kong,  Yuanzheng Niu,  Hongli Peng,  Xiaoqi Li,  Wenkai Li",
                "发布日期": "2023-05-09",
                "摘要": "  With the widespread attention and application of artificial intelligence (AI)\nand blockchain technologies, privacy protection techniques arising from their\nintegration are of notable significance. In addition to protecting privacy of\nindividuals, these techniques also guarantee security and dependability of\ndata. This paper initially presents an overview of AI and blockchain,\nsummarizing their combination along with derived privacy protection\ntechnologies. It then explores specific application scenarios in data\nencryption, de-identification, multi-tier distributed ledgers, and k-anonymity\nmethods. Moreover, the paper evaluates five critical aspects of\nAI-blockchain-integration privacy protection systems, including authorization\nmanagement, access control, data protection, network security, and scalability.\nFurthermore, it analyzes the deficiencies and their actual cause, offering\ncorresponding suggestions. This research also classifies and summarizes privacy\nprotection techniques based on AI-blockchain application scenarios and\ntechnical schemes. In conclusion, this paper outlines the future directions of\nprivacy protection technologies emerging from AI and blockchain integration,\nincluding enhancing efficiency and security to achieve a more comprehensive\nprivacy protection of privacy.\n",
                "链接": "https://arxiv.org/abs/2305.03928"
            },
            {
                "文章ID": "117088",
                "标题": "A Survey on Multimodal Large Language Models for Autonomous Driving",
                "作者": " Can Cui,  Yunsheng Ma,  Xu Cao,  Wenqian Ye,  Yang Zhou,  Kaizhao Liang,  Jintai Chen,  Juanwu Lu,  Zichong Yang,  Kuei-Da Liao,  Tianren Gao,  Erlong Li,  Kun Tang,  Zhipeng Cao,  Tong Zhou,  Ao Liu,  Xinrui Yan,  Shuqi Mei,  Jianguo Cao,  Ziran Wang,  Chao Zheng",
                "发布日期": "2023-11-22",
                "摘要": "  With the emergence of Large Language Models (LLMs) and Vision Foundation\nModels (VFMs), multimodal AI systems benefiting from large models have the\npotential to equally perceive the real world, make decisions, and control tools\nas humans. In recent months, LLMs have shown widespread attention in autonomous\ndriving and map systems. Despite its immense potential, there is still a lack\nof a comprehensive understanding of key challenges, opportunities, and future\nendeavors to apply in LLM driving systems. In this paper, we present a\nsystematic investigation in this field. We first introduce the background of\nMultimodal Large Language Models (MLLMs), the multimodal models development\nusing LLMs, and the history of autonomous driving. Then, we overview existing\nMLLM tools for driving, transportation, and map systems together with existing\ndatasets and benchmarks. Moreover, we summarized the works in The 1st WACV\nWorkshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD),\nwhich is the first workshop of its kind regarding LLMs in autonomous driving.\nTo further promote the development of this field, we also discuss several\nimportant problems regarding using MLLMs in autonomous driving systems that\nneed to be solved by both academia and industry.\n",
                "链接": "https://arxiv.org/abs/2311.12320"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究，特别关注使用自动标注和迁移学习方法的论文，时间跨度覆盖2019年至今。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "114627",
                "标题": "Transfer learning from a sparsely annotated dataset of 3D medical images",
                "作者": " Gabriel Efrain Humpire-Mamani,  Colin Jacobs,  Mathias Prokop,  Bram van Ginneken,  Nikolas Lessmann",
                "发布日期": "2023-11-10",
                "摘要": "  Transfer learning leverages pre-trained model features from a large dataset\nto save time and resources when training new models for various tasks,\npotentially enhancing performance. Due to the lack of large datasets in the\nmedical imaging domain, transfer learning from one medical imaging model to\nother medical imaging models has not been widely explored. This study explores\nthe use of transfer learning to improve the performance of deep convolutional\nneural networks for organ segmentation in medical imaging. A base segmentation\nmodel (3D U-Net) was trained on a large and sparsely annotated dataset; its\nweights were used for transfer learning on four new down-stream segmentation\ntasks for which a fully annotated dataset was available. We analyzed the\ntraining set size's influence to simulate scarce data. The results showed that\ntransfer learning from the base model was beneficial when small datasets were\navailable, providing significant performance improvements; where fine-tuning\nthe base model is more beneficial than updating all the network weights with\nvanilla transfer learning. Transfer learning with fine-tuning increased the\nperformance by up to 0.129 (+28\\%) Dice score than experiments trained from\nscratch, and on average 23 experiments increased the performance by 0.029 Dice\nscore in the new segmentation tasks. The study also showed that cross-modality\ntransfer learning using CT scans was beneficial. The findings of this study\ndemonstrate the potential of transfer learning to improve the efficiency of\nannotation and increase the accessibility of accurate organ segmentation in\nmedical imaging, ultimately leading to improved patient care. We made the\nnetwork definition and weights publicly available to benefit other users and\nresearchers.\n",
                "链接": "https://arxiv.org/abs/2311.05032"
            },
            {
                "文章ID": "84417",
                "标题": "AutoML Systems For Medical Imaging",
                "作者": " Tasmia Tahmida Jidney,  Angona Biswas,  MD Abdullah Al Nasim,  Ismail Hossain,  Md Jahangir Alam,  Sajedul Talukder,  Mofazzal Hossain,  Dr. Md Azim Ullah",
                "发布日期": "2023-06-21",
                "摘要": "  The integration of machine learning in medical image analysis can greatly\nenhance the quality of healthcare provided by physicians. The combination of\nhuman expertise and computerized systems can result in improved diagnostic\naccuracy. An automated machine learning approach simplifies the creation of\ncustom image recognition models by utilizing neural architecture search and\ntransfer learning techniques. Medical imaging techniques are used to\nnon-invasively create images of internal organs and body parts for diagnostic\nand procedural purposes. This article aims to highlight the potential\napplications, strategies, and techniques of AutoML in medical imaging through\ntheoretical and empirical evidence.\n",
                "链接": "https://arxiv.org/abs/2306.04750"
            },
            {
                "文章ID": "110503",
                "标题": "A comprehensive survey on deep active learning and its applications in\n  medical image analysis",
                "作者": " Haoran Wang,  Qiuye Jin,  Shiman Li,  Siyu Liu,  Manning Wang,  Zhijian Song",
                "发布日期": "2023-10-25",
                "摘要": "  Deep learning has achieved widespread success in medical image analysis,\nleading to an increasing demand for large-scale expert-annotated medical image\ndatasets. Yet, the high cost of annotating medical images severely hampers the\ndevelopment of deep learning in this field. To reduce annotation costs, active\nlearning aims to select the most informative samples for annotation and train\nhigh-performance models with as few labeled samples as possible. In this\nsurvey, we review the core methods of active learning, including the evaluation\nof informativeness and sampling strategy. For the first time, we provide a\ndetailed summary of the integration of active learning with other\nlabel-efficient techniques, such as semi-supervised, self-supervised learning,\nand so on. Additionally, we also highlight active learning works that are\nspecifically tailored to medical image analysis. In the end, we offer our\nperspectives on the future trends and challenges of active learning and its\napplications in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2310.14230"
            },
            {
                "文章ID": "24460",
                "标题": "Quantitative Imaging Principles Improves Medical Image Learning",
                "作者": " Lambert T. Leong,  Michael C. Wong,  Yannik Glaser,  Thomas Wolfgruber,  Steven B. Heymsfield,  Peter Sadowski,  John A. Shepherd",
                "发布日期": "2022-07-13",
                "摘要": "  Fundamental differences between natural and medical images have recently\nfavored the use of self-supervised learning (SSL) over ImageNet transfer\nlearning for medical image applications. Differences between image types are\nprimarily due to the imaging modality and medical images utilize a wide range\nof physics based techniques while natural images are captured using only\nvisible light. While many have demonstrated that SSL on medical images has\nresulted in better downstream task performance, our work suggests that more\nperformance can be gained. The scientific principles which are used to acquire\nmedical images are not often considered when constructing learning problems.\nFor this reason, we propose incorporating quantitative imaging principles\nduring generative SSL to improve image quality and quantitative biological\naccuracy. We show that this training schema results in better starting states\nfor downstream supervised training on limited data. Our model also generates\nimages that validate on clinical quantitative analysis software.\n",
                "链接": "https://arxiv.org/abs/2206.06663"
            },
            {
                "文章ID": "119919",
                "标题": "Survey on deep learning in multimodal medical imaging for cancer\n  detection",
                "作者": " Yan Tian,  Zhaocheng Xu,  Yujun Ma,  Weiping Ding,  Ruili Wang,  Zhihong Gao,  Guohua Cheng,  Linyang He,  Xuran Zhao",
                "发布日期": "2023-12-06",
                "摘要": "  The task of multimodal cancer detection is to determine the locations and\ncategories of lesions by using different imaging techniques, which is one of\nthe key research methods for cancer diagnosis. Recently, deep learning-based\nobject detection has made significant developments due to its strength in\nsemantic feature extraction and nonlinear function fitting. However, multimodal\ncancer detection remains challenging due to morphological differences in\nlesions, interpatient variability, difficulty in annotation, and imaging\nartifacts. In this survey, we mainly investigate over 150 papers in recent\nyears with respect to multimodal cancer detection using deep learning, with a\nfocus on datasets and solutions to various challenges such as data annotation,\nvariance between classes, small-scale lesions, and occlusion. We also provide\nan overview of the advantages and drawbacks of each approach. Finally, we\ndiscuss the current scope of work and provide directions for the future\ndevelopment of multimodal cancer detection.\n",
                "链接": "https://arxiv.org/abs/2312.01573"
            },
            {
                "文章ID": "78299",
                "标题": "DeepEdit: Deep Editable Learning for Interactive Segmentation of 3D\n  Medical Images",
                "作者": " Andres Diaz-Pinto,  Pritesh Mehta,  Sachidanand Alle,  Muhammad Asad,  Richard Brown,  Vishwesh Nath,  Alvin Ihsani,  Michela Antonelli,  Daniel Palkovics,  Csaba Pinter,  Ron Alkalay,  Steve Pieper,  Holger R. Roth,  Daguang Xu,  Prerna Dogra,  Tom Vercauteren,  Andrew Feng,  Abood Quraini,  Sebastien Ourselin,  M. Jorge Cardoso",
                "发布日期": "2023-11-22",
                "摘要": "  Automatic segmentation of medical images is a key step for diagnostic and\ninterventional tasks. However, achieving this requires large amounts of\nannotated volumes, which can be tedious and time-consuming task for expert\nannotators. In this paper, we introduce DeepEdit, a deep learning-based method\nfor volumetric medical image annotation, that allows automatic and\nsemi-automatic segmentation, and click-based refinement. DeepEdit combines the\npower of two methods: a non-interactive (i.e. automatic segmentation using\nnnU-Net, UNET or UNETR) and an interactive segmentation method (i.e. DeepGrow),\ninto a single deep learning model. It allows easy integration of\nuncertainty-based ranking strategies (i.e. aleatoric and epistemic uncertainty\ncomputation) and active learning. We propose and implement a method for\ntraining DeepEdit by using standard training combined with user interaction\nsimulation. Once trained, DeepEdit allows clinicians to quickly segment their\ndatasets by using the algorithm in auto segmentation mode or by providing\nclicks via a user interface (i.e. 3D Slicer, OHIF). We show the value of\nDeepEdit through evaluation on the PROSTATEx dataset for prostate/prostatic\nlesions and the Multi-Atlas Labeling Beyond the Cranial Vault (BTCV) dataset\nfor abdominal CT segmentation, using state-of-the-art network architectures as\nbaseline for comparison. DeepEdit could reduce the time and effort annotating\n3D medical images compared to DeepGrow alone. Source code is available at\nhttps://github.com/Project-MONAI/MONAILabel\n",
                "链接": "https://arxiv.org/abs/2305.10655"
            },
            {
                "文章ID": "31210",
                "标题": "Generalizable multi-task, multi-domain deep segmentation of sparse\n  pediatric imaging datasets via multi-scale contrastive regularization and\n  multi-joint anatomical priors",
                "作者": " Arnaud Boutillon,  Pierre-Henri Conze,  Christelle Pons,  Valérie Burdin,  Bhushan Borotikar",
                "发布日期": "2022-08-17",
                "摘要": "  Clinical diagnosis of the pediatric musculoskeletal system relies on the\nanalysis of medical imaging examinations. In the medical image processing\npipeline, semantic segmentation using deep learning algorithms enables an\nautomatic generation of patient-specific three-dimensional anatomical models\nwhich are crucial for morphological evaluation. However, the scarcity of\npediatric imaging resources may result in reduced accuracy and generalization\nperformance of individual deep segmentation models. In this study, we propose\nto design a novel multi-task, multi-domain learning framework in which a single\nsegmentation network is optimized over the union of multiple datasets arising\nfrom distinct parts of the anatomy. Unlike previous approaches, we\nsimultaneously consider multiple intensity domains and segmentation tasks to\novercome the inherent scarcity of pediatric data while leveraging shared\nfeatures between imaging datasets. To further improve generalization\ncapabilities, we employ a transfer learning scheme from natural image\nclassification, along with a multi-scale contrastive regularization aimed at\npromoting domain-specific clusters in the shared representations, and\nmulti-joint anatomical priors to enforce anatomically consistent predictions.\nWe evaluate our contributions for performing bone segmentation using three\nscarce and pediatric imaging datasets of the ankle, knee, and shoulder joints.\nOur results demonstrate that the proposed approach outperforms individual,\ntransfer, and shared segmentation schemes in Dice metric with statistically\nsufficient margins. The proposed model brings new perspectives towards\nintelligent use of imaging resources and better management of pediatric\nmusculoskeletal disorders.\n",
                "链接": "https://arxiv.org/abs/2207.13502"
            },
            {
                "文章ID": "94331",
                "标题": "Deep learning for unsupervised domain adaptation in medical imaging:\n  Recent advancements and future perspectives",
                "作者": " Suruchi Kumari,  Pravendra Singh",
                "发布日期": "2023-08-03",
                "摘要": "  Deep learning has demonstrated remarkable performance across various tasks in\nmedical imaging. However, these approaches primarily focus on supervised\nlearning, assuming that the training and testing data are drawn from the same\ndistribution. Unfortunately, this assumption may not always hold true in\npractice. To address these issues, unsupervised domain adaptation (UDA)\ntechniques have been developed to transfer knowledge from a labeled domain to a\nrelated but unlabeled domain. In recent years, significant advancements have\nbeen made in UDA, resulting in a wide range of methodologies, including feature\nalignment, image translation, self-supervision, and disentangled representation\nmethods, among others. In this paper, we provide a comprehensive literature\nreview of recent deep UDA approaches in medical imaging from a technical\nperspective. Specifically, we categorize current UDA research in medical\nimaging into six groups and further divide them into finer subcategories based\non the different tasks they perform. We also discuss the respective datasets\nused in the studies to assess the divergence between the different domains.\nFinally, we discuss emerging areas and provide insights and discussions on\nfuture research directions to conclude this survey.\n",
                "链接": "https://arxiv.org/abs/2308.01265"
            },
            {
                "文章ID": "5953",
                "标题": "An overview of deep learning in medical imaging",
                "作者": " Imran Ul Haq",
                "发布日期": "2022-02-18",
                "摘要": "  Machine learning (ML) has seen enormous consideration during the most recent\ndecade. This success started in 2012 when an ML model accomplished a remarkable\ntriumph in the ImageNet Classification, the world's most famous competition for\ncomputer vision. This model was a kind of convolutional neural system (CNN)\ncalled deep learning (DL). Since then, researchers have started to participate\nefficiently in DL's fastest developing area of research. These days, DL systems\nare cutting-edge ML systems spanning a broad range of disciplines, from human\nlanguage processing to video analysis, and commonly used in the scholarly world\nand enterprise sector. Recent advances can bring tremendous improvement to the\nmedical field. Improved and innovative methods for data processing, image\nanalysis and can significantly improve the diagnostic technologies and\nmedicinal services gradually. A quick review of current developments with\nrelevant problems in the field of DL used for medical imaging has been\nprovided. The primary purposes of the review are four: (i) provide a brief\nprolog to DL by discussing different DL models, (ii) review of the DL usage for\nmedical image analysis (classification, detection, segmentation, and\nregistration), (iii) review seven main application fields of DL in medical\nimaging, (iv) give an initial stage to those keen on adding to the research\narea about DL in clinical imaging by providing links of some useful informative\nassets, such as freely available DL codes, public datasets Table 7, and medical\nimaging competition sources Table 8 and end our survey by outlining distinct\ncontinuous difficulties, lessons learned and future of DL in the field of\nmedical science.\n",
                "链接": "https://arxiv.org/abs/2202.08546"
            },
            {
                "文章ID": "71623",
                "标题": "Transfer Learning for Low-Resource Sentiment Analysis",
                "作者": " Razhan Hameed,  Sina Ahmadi,  Fatemeh Daneshfar",
                "发布日期": "2023-04-11",
                "摘要": "  Sentiment analysis is the process of identifying and extracting subjective\ninformation from text. Despite the advances to employ cross-lingual approaches\nin an automatic way, the implementation and evaluation of sentiment analysis\nsystems require language-specific data to consider various sociocultural and\nlinguistic peculiarities. In this paper, the collection and annotation of a\ndataset are described for sentiment analysis of Central Kurdish. We explore a\nfew classical machine learning and neural network-based techniques for this\ntask. Additionally, we employ an approach in transfer learning to leverage\npretrained models for data augmentation. We demonstrate that data augmentation\nachieves a high F$_1$ score and accuracy despite the difficulty of the task.\n",
                "链接": "https://arxiv.org/abs/2304.04703"
            }
        ]
    },
    {
        "question": {
            "question": "请找出最近一年内发表的关于自然语言处理领域中，使用Transformer模型并在大规模数据集上进行预训练的论文。特别关注模型结构和性能指标。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "98088",
                "标题": "Local Distortion Aware Efficient Transformer Adaptation for Image\n  Quality Assessment",
                "作者": " Kangmin Xu,  Liang Liao,  Jing Xiao,  Chaofeng Chen,  Haoning Wu,  Qiong Yan,  Weisi Lin",
                "发布日期": "2023-08-24",
                "摘要": "  Image Quality Assessment (IQA) constitutes a fundamental task within the\nfield of computer vision, yet it remains an unresolved challenge, owing to the\nintricate distortion conditions, diverse image contents, and limited\navailability of data. Recently, the community has witnessed the emergence of\nnumerous large-scale pretrained foundation models, which greatly benefit from\ndramatically increased data and parameter capacities. However, it remains an\nopen problem whether the scaling law in high-level tasks is also applicable to\nIQA task which is closely related to low-level clues. In this paper, we\ndemonstrate that with proper injection of local distortion features, a larger\npretrained and fixed foundation model performs better in IQA tasks.\nSpecifically, for the lack of local distortion structure and inductive bias of\nvision transformer (ViT), alongside the large-scale pretrained ViT, we use\nanother pretrained convolution neural network (CNN), which is well known for\ncapturing the local structure, to extract multi-scale image features. Further,\nwe propose a local distortion extractor to obtain local distortion features\nfrom the pretrained CNN and a local distortion injector to inject the local\ndistortion features into ViT. By only training the extractor and injector, our\nmethod can benefit from the rich knowledge in the powerful foundation models\nand achieve state-of-the-art performance on popular IQA datasets, indicating\nthat IQA is not only a low-level problem but also benefits from stronger\nhigh-level features drawn from large-scale pretrained models.\n",
                "链接": "https://arxiv.org/abs/2308.12001"
            },
            {
                "文章ID": "89887",
                "标题": "Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph\n  Reasoning",
                "作者": " Ke Liang,  Sihang Zhou,  Yue Liu,  Lingyuan Meng,  Meng Liu,  Xinwang Liu",
                "发布日期": "2023-07-10",
                "摘要": "  Multimodal knowledge graphs (MKGs), which intuitively organize information in\nvarious modalities, can benefit multiple practical downstream tasks, such as\nrecommendation systems, and visual question answering. However, most MKGs are\nstill far from complete, which motivates the flourishing of MKG reasoning\nmodels. Recently, with the development of general artificial architectures, the\npretrained transformer models have drawn increasing attention, especially for\nmultimodal scenarios. However, the research of multimodal pretrained\ntransformer (MPT) for knowledge graph reasoning (KGR) is still at an early\nstage. As the biggest difference between MKG and other multimodal data, the\nrich structural information underlying the MKG still cannot be fully leveraged\nin existing MPT models. Most of them only utilize the graph structure as a\nretrieval map for matching images and texts connected with the same entity.\nThis manner hinders their reasoning performances. To this end, we propose the\ngraph Structure Guided Multimodal Pretrained Transformer for knowledge graph\nreasoning, termed SGMPT. Specifically, the graph structure encoder is adopted\nfor structural feature encoding. Then, a structure-guided fusion module with\ntwo different strategies, i.e., weighted summation and alignment constraint, is\nfirst designed to inject the structural information into both the textual and\nvisual features. To the best of our knowledge, SGMPT is the first MPT model for\nmultimodal KGR, which mines the structural information underlying the knowledge\ngraph. Extensive experiments on FB15k-237-IMG and WN18-IMG, demonstrate that\nour SGMPT outperforms existing state-of-the-art models, and prove the\neffectiveness of the designed strategies.\n",
                "链接": "https://arxiv.org/abs/2307.03591"
            },
            {
                "文章ID": "93080",
                "标题": "FinTree: Financial Dataset Pretrain Transformer Encoder for Relation\n  Extraction",
                "作者": " Hyunjong Ok",
                "发布日期": "2023-07-27",
                "摘要": "  We present FinTree, Financial Dataset Pretrain Transformer Encoder for\nRelation Extraction. Utilizing an encoder language model, we further pretrain\nFinTree on the financial dataset, adapting the model in financial domain tasks.\nFinTree stands out with its novel structure that predicts a masked token\ninstead of the conventional [CLS] token, inspired by the Pattern Exploiting\nTraining methodology. This structure allows for more accurate relation\npredictions between two given entities. The model is trained with a unique\ninput pattern to provide contextual and positional information about the\nentities of interest, and a post-processing step ensures accurate predictions\nin line with the entity types. Our experiments demonstrate that FinTree\noutperforms on the REFinD, a large-scale financial relation extraction dataset.\nThe code and pretrained models are available at\nhttps://github.com/HJ-Ok/FinTree.\n",
                "链接": "https://arxiv.org/abs/2307.13900"
            },
            {
                "文章ID": "42798",
                "标题": "Improving Transfer Learning with a Dual Image and Video Transformer for\n  Multi-label Movie Trailer Genre Classification",
                "作者": " Ricardo Montalvo-Lezama,  Berenice Montalvo-Lezama,  Gibran Fuentes-Pineda",
                "发布日期": "2023-03-30",
                "摘要": "  In this paper, we study the transferability of ImageNet spatial and Kinetics\nspatio-temporal representations to multi-label Movie Trailer Genre\nClassification (MTGC). In particular, we present an extensive evaluation of the\ntransferability of ConvNet and Transformer models pretrained on ImageNet and\nKinetics to Trailers12k, a new manually-curated movie trailer dataset composed\nof 12,000 videos labeled with 10 different genres and associated metadata. We\nanalyze different aspects that can influence transferability, such as frame\nrate, input video extension, and spatio-temporal modeling. In order to reduce\nthe spatio-temporal structure gap between ImageNet/Kinetics and Trailers12k, we\npropose Dual Image and Video Transformer Architecture (DIViTA), which performs\nshot detection so as to segment the trailer into highly correlated clips,\nproviding a more cohesive input for pretrained backbones and improving\ntransferability (a 1.83% increase for ImageNet and 3.75% for Kinetics). Our\nresults demonstrate that representations learned on either ImageNet or Kinetics\nare comparatively transferable to Trailers12k. Moreover, both datasets provide\ncomplementary information that can be combined to improve classification\nperformance (a 2.91% gain compared to the top single pretraining).\nInterestingly, using lightweight ConvNets as pretrained backbones resulted in\nonly a 3.46% drop in classification performance compared with the top\nTransformer while requiring only 11.82% of its parameters and 0.81% of its\nFLOPS.\n",
                "链接": "https://arxiv.org/abs/2210.07983"
            },
            {
                "文章ID": "72325",
                "标题": "Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene\n  Understanding",
                "作者": " Yu-Qi Yang,  Yu-Xiao Guo,  Jian-Yu Xiong,  Yang Liu,  Hao Pan,  Peng-Shuai Wang,  Xin Tong,  Baining Guo",
                "发布日期": "2023-08-17",
                "摘要": "  The use of pretrained backbones with fine-tuning has been successful for 2D\nvision and natural language processing tasks, showing advantages over\ntask-specific networks. In this work, we introduce a pretrained 3D backbone,\ncalled {\\SST}, for 3D indoor scene understanding. We design a 3D Swin\ntransformer as our backbone network, which enables efficient self-attention on\nsparse voxels with linear memory complexity, making the backbone scalable to\nlarge models and datasets. We also introduce a generalized contextual relative\npositional embedding scheme to capture various irregularities of point signals\nfor improved network performance. We pretrained a large {\\SST} model on a\nsynthetic Structured3D dataset, which is an order of magnitude larger than the\nScanNet dataset. Our model pretrained on the synthetic dataset not only\ngeneralizes well to downstream segmentation and detection on real 3D point\ndatasets, but also outperforms state-of-the-art methods on downstream tasks\nwith +2.3 mIoU and +2.2 mIoU on S3DIS Area5 and 6-fold semantic segmentation,\n+1.8 mIoU on ScanNet segmentation (val), +1.9 mAP@0.5 on ScanNet detection, and\n+8.1 mAP@0.5 on S3DIS detection. A series of extensive ablation studies further\nvalidate the scalability, generality, and superior performance enabled by our\napproach. The code and models are available at\nhttps://github.com/microsoft/Swin3D .\n",
                "链接": "https://arxiv.org/abs/2304.06906"
            },
            {
                "文章ID": "20224",
                "标题": "Heterformer: Transformer-based Deep Node Representation Learning on\n  Heterogeneous Text-Rich Networks",
                "作者": " Bowen Jin,  Yu Zhang,  Qi Zhu,  Jiawei Han",
                "发布日期": "2023-06-06",
                "摘要": "  Representation learning on networks aims to derive a meaningful vector\nrepresentation for each node, thereby facilitating downstream tasks such as\nlink prediction, node classification, and node clustering. In heterogeneous\ntext-rich networks, this task is more challenging due to (1) presence or\nabsence of text: Some nodes are associated with rich textual information, while\nothers are not; (2) diversity of types: Nodes and edges of multiple types form\na heterogeneous network structure. As pretrained language models (PLMs) have\ndemonstrated their effectiveness in obtaining widely generalizable text\nrepresentations, a substantial amount of effort has been made to incorporate\nPLMs into representation learning on text-rich networks. However, few of them\ncan jointly consider heterogeneous structure (network) information as well as\nrich textual semantic information of each node effectively. In this paper, we\npropose Heterformer, a Heterogeneous Network-Empowered Transformer that\nperforms contextualized text encoding and heterogeneous structure encoding in a\nunified model. Specifically, we inject heterogeneous structure information into\neach Transformer layer when encoding node texts. Meanwhile, Heterformer is\ncapable of characterizing node/edge type heterogeneity and encoding nodes with\nor without texts. We conduct comprehensive experiments on three tasks (i.e.,\nlink prediction, node classification, and node clustering) on three large-scale\ndatasets from different domains, where Heterformer outperforms competitive\nbaselines significantly and consistently.\n",
                "链接": "https://arxiv.org/abs/2205.10282"
            },
            {
                "文章ID": "73117",
                "标题": "NetGPT: Generative Pretrained Transformer for Network Traffic",
                "作者": " Xuying Meng,  Chungang Lin,  Yequan Wang,  Yujun Zhang",
                "发布日期": "2023-05-18",
                "摘要": "  All data on the Internet are transferred by network traffic, thus accurately\nmodeling network traffic can help improve network services quality and protect\ndata privacy. Pretrained models for network traffic can utilize large-scale raw\ndata to learn the essential characteristics of network traffic, and generate\ndistinguishable results for input traffic without considering specific\ndownstream tasks. Effective pretrained models can significantly optimize the\ntraining efficiency and effectiveness of downstream tasks, such as application\nclassification, attack detection and traffic generation. Despite the great\nsuccess of pretraining in natural language processing, there is no work in the\nnetwork field. Considering the diverse demands and characteristics of network\ntraffic and network tasks, it is non-trivial to build a pretrained model for\nnetwork traffic and we face various challenges, especially the heterogeneous\nheaders and payloads in the multi-pattern network traffic and the different\ndependencies for contexts of diverse downstream network tasks.\n  To tackle these challenges, in this paper, we make the first attempt to\nprovide a generative pretrained model NetGPT for both traffic understanding and\ngeneration tasks. We propose the multi-pattern network traffic modeling to\nconstruct unified text inputs and support both traffic understanding and\ngeneration tasks. We further optimize the adaptation effect of the pretrained\nmodel to diversified tasks by shuffling header fields, segmenting packets in\nflows, and incorporating diverse task labels with prompts. With diverse traffic\ndatasets from encrypted software, DNS, private industrial protocols and\ncryptocurrency mining, expensive experiments demonstrate the effectiveness of\nour NetGPT in a range of traffic understanding and generation tasks on traffic\ndatasets, and outperform state-of-the-art baselines by a wide margin.\n",
                "链接": "https://arxiv.org/abs/2304.09513"
            },
            {
                "文章ID": "45934",
                "标题": "ViTASD: Robust Vision Transformer Baselines for Autism Spectrum Disorder\n  Facial Diagnosis",
                "作者": " Xu Cao,  Wenqian Ye,  Elena Sizikova,  Xue Bai,  Megan Coffee,  Hongwu Zeng,  Jianguo Cao",
                "发布日期": "2023-03-14",
                "摘要": "  Autism spectrum disorder (ASD) is a lifelong neurodevelopmental disorder with\nvery high prevalence around the world. Research progress in the field of ASD\nfacial analysis in pediatric patients has been hindered due to a lack of\nwell-established baselines. In this paper, we propose the use of the Vision\nTransformer (ViT) for the computational analysis of pediatric ASD. The\npresented model, known as ViTASD, distills knowledge from large facial\nexpression datasets and offers model structure transferability. Specifically,\nViTASD employs a vanilla ViT to extract features from patients' face images and\nadopts a lightweight decoder with a Gaussian Process layer to enhance the\nrobustness for ASD analysis. Extensive experiments conducted on standard ASD\nfacial analysis benchmarks show that our method outperforms all of the\nrepresentative approaches in ASD facial analysis, while the ViTASD-L achieves a\nnew state-of-the-art. Our code and pretrained models are available at\nhttps://github.com/IrohXu/ViTASD.\n",
                "链接": "https://arxiv.org/abs/2210.16943"
            },
            {
                "文章ID": "100924",
                "标题": "Multimodal Transformer for Material Segmentation",
                "作者": " Md Kaykobad Reza,  Ashley Prater-Bennette,  M. Salman Asif",
                "发布日期": "2023-09-13",
                "摘要": "  Leveraging information across diverse modalities is known to enhance\nperformance on multimodal segmentation tasks. However, effectively fusing\ninformation from different modalities remains challenging due to the unique\ncharacteristics of each modality. In this paper, we propose a novel fusion\nstrategy that can effectively fuse information from different combinations of\nfour different modalities: RGB, Angle of Linear Polarization (AoLP), Degree of\nLinear Polarization (DoLP) and Near-Infrared (NIR). We also propose a new model\nnamed Multi-Modal Segmentation Transformer (MMSFormer) that incorporates the\nproposed fusion strategy to perform multimodal material segmentation. MMSFormer\nachieves 52.05% mIoU outperforming the current state-of-the-art on Multimodal\nMaterial Segmentation (MCubeS) dataset. For instance, our method provides\nsignificant improvement in detecting gravel (+10.4%) and human (+9.1%) classes.\nAblation studies show that different modules in the fusion block are crucial\nfor overall model performance. Furthermore, our ablation studies also highlight\nthe capacity of different input modalities to improve performance in the\nidentification of different types of materials. The code and pretrained models\nwill be made available at https://github.com/csiplab/MMSFormer.\n",
                "链接": "https://arxiv.org/abs/2309.04001"
            },
            {
                "文章ID": "69142",
                "标题": "Image Deblurring by Exploring In-depth Properties of Transformer",
                "作者": " Pengwei Liang,  Junjun Jiang,  Xianming Liu,  Jiayi Ma",
                "发布日期": "2023-03-28",
                "摘要": "  Image deblurring continues to achieve impressive performance with the\ndevelopment of generative models. Nonetheless, there still remains a\ndispleasing problem if one wants to improve perceptual quality and quantitative\nscores of recovered image at the same time. In this study, drawing inspiration\nfrom the research of transformer properties, we introduce the pretrained\ntransformers to address this problem. In particular, we leverage deep features\nextracted from a pretrained vision transformer (ViT) to encourage recovered\nimages to be sharp without sacrificing the performance measured by the\nquantitative metrics. The pretrained transformer can capture the global\ntopological relations (i.e., self-similarity) of image, and we observe that the\ncaptured topological relations about the sharp image will change when blur\noccurs. By comparing the transformer features between recovered image and\ntarget one, the pretrained transformer provides high-resolution blur-sensitive\nsemantic information, which is critical in measuring the sharpness of the\ndeblurred image. On the basis of the advantages, we present two types of novel\nperceptual losses to guide image deblurring. One regards the features as\nvectors and computes the discrepancy between representations extracted from\nrecovered image and target one in Euclidean space. The other type considers the\nfeatures extracted from an image as a distribution and compares the\ndistribution discrepancy between recovered image and target one. We demonstrate\nthe effectiveness of transformer properties in improving the perceptual quality\nwhile not sacrificing the quantitative scores (PSNR) over the most competitive\nmodels, such as Uformer, Restormer, and NAFNet, on defocus deblurring and\nmotion deblurring tasks.\n",
                "链接": "https://arxiv.org/abs/2303.15198"
            }
        ]
    },
    {
        "question": {
            "question": "请查找关于智能体的研究进展的综述或调查论文。重点关注不同领域中智能体的方法和应用，以及相关的挑战和未来方向。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "48059",
                "标题": "A Survey on Explainable Reinforcement Learning: Concepts, Algorithms,\n  Challenges",
                "作者": " Yunpeng Qing,  Shunyu Liu,  Jie Song,  Huiqiong Wang,  Mingli Song",
                "发布日期": "2023-11-02",
                "摘要": "  Reinforcement Learning (RL) is a popular machine learning paradigm where\nintelligent agents interact with the environment to fulfill a long-term goal.\nDriven by the resurgence of deep learning, Deep RL (DRL) has witnessed great\nsuccess over a wide spectrum of complex control tasks. Despite the encouraging\nresults achieved, the deep neural network-based backbone is widely deemed as a\nblack box that impedes practitioners to trust and employ trained agents in\nrealistic scenarios where high security and reliability are essential. To\nalleviate this issue, a large volume of literature devoted to shedding light on\nthe inner workings of the intelligent agents has been proposed, by constructing\nintrinsic interpretability or post-hoc explainability. In this survey, we\nprovide a comprehensive review of existing works on eXplainable RL (XRL) and\nintroduce a new taxonomy where prior works are clearly categorized into\nmodel-explaining, reward-explaining, state-explaining, and task-explaining\nmethods. We also review and highlight RL methods that conversely leverage human\nknowledge to promote learning efficiency and performance of agents while this\nkind of method is often ignored in XRL field. Some challenges and opportunities\nin XRL are discussed. This survey intends to provide a high-level summarization\nof XRL and to motivate future research on more effective XRL solutions.\nCorresponding open source codes are collected and categorized at\nhttps://github.com/Plankson/awesome-explainable-reinforcement-learning.\n",
                "链接": "https://arxiv.org/abs/2211.06665"
            },
            {
                "文章ID": "11378",
                "标题": "Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future\n  Directions",
                "作者": " Jing Gu,  Eliana Stefani,  Qi Wu,  Jesse Thomason,  Xin Eric Wang",
                "发布日期": "2022-06-07",
                "摘要": "  A long-term goal of AI research is to build intelligent agents that can\ncommunicate with humans in natural language, perceive the environment, and\nperform real-world tasks. Vision-and-Language Navigation (VLN) is a fundamental\nand interdisciplinary research topic towards this goal, and receives increasing\nattention from natural language processing, computer vision, robotics, and\nmachine learning communities. In this paper, we review contemporary studies in\nthe emerging field of VLN, covering tasks, evaluation metrics, methods, etc.\nThrough structured analysis of current progress and challenges, we highlight\nthe limitations of current VLN and opportunities for future work. This paper\nserves as a thorough reference for the VLN research community.\n",
                "链接": "https://arxiv.org/abs/2203.12667"
            },
            {
                "文章ID": "5915",
                "标题": "A Survey on Deep Reinforcement Learning-based Approaches for Adaptation\n  and Generalization",
                "作者": " Pamul Yadav,  Ashutosh Mishra,  Junyong Lee,  Shiho Kim",
                "发布日期": "2022-02-18",
                "摘要": "  Deep Reinforcement Learning (DRL) aims to create intelligent agents that can\nlearn to solve complex problems efficiently in a real-world environment.\nTypically, two learning goals: adaptation and generalization are used for\nbaselining DRL algorithm's performance on different tasks and domains. This\npaper presents a survey on the recent developments in DRL-based approaches for\nadaptation and generalization. We begin by formulating these goals in the\ncontext of task and domain. Then we review the recent works under those\napproaches and discuss future research directions through which DRL algorithms'\nadaptability and generalizability can be enhanced and potentially make them\napplicable to a broad range of real-world problems.\n",
                "链接": "https://arxiv.org/abs/2202.08444"
            },
            {
                "文章ID": "58110",
                "标题": "Intrinsic Motivation in Model-based Reinforcement Learning: A Brief\n  Review",
                "作者": " Artem Latyshev,  Aleksandr I. Panov",
                "发布日期": "2023-01-25",
                "摘要": "  The reinforcement learning research area contains a wide range of methods for\nsolving the problems of intelligent agent control. Despite the progress that\nhas been made, the task of creating a highly autonomous agent is still a\nsignificant challenge. One potential solution to this problem is intrinsic\nmotivation, a concept derived from developmental psychology. This review\nconsiders the existing methods for determining intrinsic motivation based on\nthe world model obtained by the agent. We propose a systematic approach to\ncurrent research in this field, which consists of three categories of methods,\ndistinguished by the way they utilize a world model in the agent's components:\ncomplementary intrinsic reward, exploration policy, and intrinsically motivated\ngoals. The proposed unified framework describes the architecture of agents\nusing a world model and intrinsic motivation to improve learning. The potential\nfor developing new techniques in this area of research is also examined.\n",
                "链接": "https://arxiv.org/abs/2301.10067"
            },
            {
                "文章ID": "97862",
                "标题": "A Survey on Large Language Model based Autonomous Agents",
                "作者": " Lei Wang,  Chen Ma,  Xueyang Feng,  Zeyu Zhang,  Hao Yang,  Jingsen Zhang,  Zhiyuan Chen,  Jiakai Tang,  Xu Chen,  Yankai Lin,  Wayne Xin Zhao,  Zhewei Wei,  Ji-Rong Wen",
                "发布日期": "2023-09-08",
                "摘要": "  Autonomous agents have long been a prominent research focus in both academic\nand industry communities. Previous research in this field often focuses on\ntraining agents with limited knowledge within isolated environments, which\ndiverges significantly from human learning processes, and thus makes the agents\nhard to achieve human-like decisions. Recently, through the acquisition of vast\namounts of web knowledge, large language models (LLMs) have demonstrated\nremarkable potential in achieving human-level intelligence. This has sparked an\nupsurge in studies investigating LLM-based autonomous agents. In this paper, we\npresent a comprehensive survey of these studies, delivering a systematic review\nof the field of LLM-based autonomous agents from a holistic perspective. More\nspecifically, we first discuss the construction of LLM-based autonomous agents,\nfor which we propose a unified framework that encompasses a majority of the\nprevious work. Then, we present a comprehensive overview of the diverse\napplications of LLM-based autonomous agents in the fields of social science,\nnatural science, and engineering. Finally, we delve into the evaluation\nstrategies commonly used for LLM-based autonomous agents. Based on the previous\nstudies, we also present several challenges and future directions in this\nfield. To keep track of this field and continuously update our survey, we\nmaintain a repository of relevant references at\nhttps://github.com/Paitesanshi/LLM-Agent-Survey.\n",
                "链接": "https://arxiv.org/abs/2308.11432"
            },
            {
                "文章ID": "5533",
                "标题": "Recent Advances in Reliable Deep Graph Learning: Inherent Noise,\n  Distribution Shift, and Adversarial Attack",
                "作者": " Jintang Li,  Bingzhe Wu,  Chengbin Hou,  Guoji Fu,  Yatao Bian,  Liang Chen,  Junzhou Huang,  Zibin Zheng",
                "发布日期": "2023-05-09",
                "摘要": "  Deep graph learning (DGL) has achieved remarkable progress in both business\nand scientific areas ranging from finance and e-commerce to drug and advanced\nmaterial discovery. Despite the progress, applying DGL to real-world\napplications faces a series of reliability threats including inherent noise,\ndistribution shift, and adversarial attacks. This survey aims to provide a\ncomprehensive review of recent advances for improving the reliability of DGL\nalgorithms against the above threats. In contrast to prior related surveys\nwhich mainly focus on adversarial attacks and defense, our survey covers more\nreliability-related aspects of DGL, i.e., inherent noise and distribution\nshift. Additionally, we discuss the relationships among above aspects and\nhighlight some important issues to be explored in future research.\n",
                "链接": "https://arxiv.org/abs/2202.07114"
            },
            {
                "文章ID": "78547",
                "标题": "Milestones in Autonomous Driving and Intelligent Vehicles Part I:\n  Control, Computing System Design, Communication, HD Map, Testing, and Human\n  Behaviors",
                "作者": " Long Chen,  Yuchen Li,  Chao Huang,  Yang Xing,  Daxin Tian,  Li Li,  Zhongxu Hu,  Siyu Teng,  Chen Lv,  Jinjun Wang,  Dongpu Cao,  Nanning Zheng,  Fei-Yue Wang",
                "发布日期": "2023-05-30",
                "摘要": "  Interest in autonomous driving (AD) and intelligent vehicles (IVs) is growing\nat a rapid pace due to the convenience, safety, and economic benefits. Although\na number of surveys have reviewed research achievements in this field, they are\nstill limited in specific tasks and lack systematic summaries and research\ndirections in the future. Our work is divided into 3 independent articles and\nthe first part is a Survey of Surveys (SoS) for total technologies of AD and\nIVs that involves the history, summarizes the milestones, and provides the\nperspectives, ethics, and future research directions. This is the second part\n(Part I for this technical survey) to review the development of control,\ncomputing system design, communication, High Definition map (HD map), testing,\nand human behaviors in IVs. In addition, the third part (Part II for this\ntechnical survey) is to review the perception and planning sections. The\nobjective of this paper is to involve all the sections of AD, summarize the\nlatest technical milestones, and guide abecedarians to quickly understand the\ndevelopment of AD and IVs. Combining the SoS and Part II, we anticipate that\nthis work will bring novel and diverse insights to researchers and\nabecedarians, and serve as a bridge between past and future.\n",
                "链接": "https://arxiv.org/abs/2305.11239"
            },
            {
                "文章ID": "102901",
                "标题": "Pointing out Human Answer Mistakes in a Goal-Oriented Visual Dialogue",
                "作者": " Ryosuke Oshima,  Seitaro Shinagawa,  Hideki Tsunashima,  Qi Feng,  Shigeo Morishima",
                "发布日期": "2023-09-20",
                "摘要": "  Effective communication between humans and intelligent agents has promising\napplications for solving complex problems. One such approach is visual\ndialogue, which leverages multimodal context to assist humans. However,\nreal-world scenarios occasionally involve human mistakes, which can cause\nintelligent agents to fail. While most prior research assumes perfect answers\nfrom human interlocutors, we focus on a setting where the agent points out\nunintentional mistakes for the interlocutor to review, better reflecting\nreal-world situations. In this paper, we show that human answer mistakes depend\non question type and QA turn in the visual dialogue by analyzing a previously\nunused data collection of human mistakes. We demonstrate the effectiveness of\nthose factors for the model's accuracy in a pointing-human-mistake task through\nexperiments using a simple MLP model and a Visual Language Model.\n",
                "链接": "https://arxiv.org/abs/2309.10375"
            },
            {
                "文章ID": "72881",
                "标题": "A Survey for Biomedical Text Summarization: From Pre-trained to Large\n  Language Models",
                "作者": " Qianqian Xie,  Zheheng Luo,  Benyou Wang,  Sophia Ananiadou",
                "发布日期": "2023-07-17",
                "摘要": "  The exponential growth of biomedical texts such as biomedical literature and\nelectronic health records (EHRs), poses a significant challenge for clinicians\nand researchers to access clinical information efficiently. To tackle this\nchallenge, biomedical text summarization (BTS) has been proposed as a solution\nto support clinical information retrieval and management. BTS aims at\ngenerating concise summaries that distill key information from single or\nmultiple biomedical documents. In recent years, the rapid advancement of\nfundamental natural language processing (NLP) techniques, from pre-trained\nlanguage models (PLMs) to large language models (LLMs), has greatly facilitated\nthe progress of BTS. This growth has led to numerous proposed summarization\nmethods, datasets, and evaluation metrics, raising the need for a comprehensive\nand up-to-date survey for BTS. In this paper, we present a systematic review of\nrecent advancements in BTS, leveraging cutting-edge NLP techniques from PLMs to\nLLMs, to help understand the latest progress, challenges, and future\ndirections. We begin by introducing the foundational concepts of BTS, PLMs and\nLLMs, followed by an in-depth review of available datasets, recent approaches,\nand evaluation metrics in BTS. We finally discuss existing challenges and\npromising future directions in the era of LLMs. To facilitate the research\ncommunity, we line up open resources including available datasets, recent\napproaches, codes, evaluation metrics, and the leaderboard in a public project:\nhttps://github.com/KenZLuo/Biomedical-Text-Summarization-Survey/tree/master. We\nbelieve that this survey will be a useful resource to researchers, allowing\nthem to quickly track recent advancements and provide guidelines for future BTS\nresearch within the research community.\n",
                "链接": "https://arxiv.org/abs/2304.08763"
            },
            {
                "文章ID": "1611",
                "标题": "A Literature Survey of Recent Advances in Chatbots",
                "作者": " Guendalina Caldarini,  Sardar Jaf,  Kenneth McGarry",
                "发布日期": "2022-01-19",
                "摘要": "  Chatbots are intelligent conversational computer systems designed to mimic\nhuman conversation to enable automated online guidance and support. The\nincreased benefits of chatbots led to their wide adoption by many industries in\norder to provide virtual assistance to customers. Chatbots utilise methods and\nalgorithms from two Artificial Intelligence domains: Natural Language\nProcessing and Machine Learning. However, there are many challenges and\nlimitations in their application. In this survey we review recent advances on\nchatbots, where Artificial Intelligence and Natural Language processing are\nused. We highlight the main challenges and limitations of current work and make\nrecommendations for future research investigation.\n",
                "链接": "https://arxiv.org/abs/2201.06657"
            }
        ]
    }
]