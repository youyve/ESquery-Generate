[
    {
        "question": {
            "question": "与大模型工具学习相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "119149",
                "标题": "mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large\n  Language Model",
                "作者": " Anwen Hu,  Yaya Shi,  Haiyang Xu,  Jiabo Ye,  Qinghao Ye,  Ming Yan,  Chenliang Li,  Qi Qian,  Ji Zhang,  Fei Huang",
                "发布日期": "2023-12-01",
                "摘要": "  Recently, the strong text creation ability of Large Language Models(LLMs) has\ngiven rise to many tools for assisting paper reading or even writing. However,\nthe weak diagram analysis abilities of LLMs or Multimodal LLMs greatly limit\ntheir application scenarios, especially for scientific academic paper writing.\nIn this work, towards a more versatile copilot for academic paper writing, we\nmainly focus on strengthening the multi-modal diagram analysis ability of\nMultimodal LLMs. By parsing Latex source files of high-quality papers, we\ncarefully build a multi-modal diagram understanding dataset M-Paper. By\naligning diagrams in the paper with related paragraphs, we construct\nprofessional diagram analysis samples for training and evaluation. M-Paper is\nthe first dataset to support joint comprehension of multiple scientific\ndiagrams, including figures and tables in the format of images or Latex codes.\nBesides, to better align the copilot with the user's intention, we introduce\nthe `outline' as the control signal, which could be directly given by the user\nor revised based on auto-generated ones. Comprehensive experiments with a\nstate-of-the-art Mumtimodal LLM demonstrate that training on our dataset shows\nstronger scientific diagram understanding performance, including diagram\ncaptioning, diagram analysis, and outline recommendation. The dataset, code,\nand model are available at\nhttps://github.com/X-PLUG/mPLUG-DocOwl/tree/main/PaperOwl.\n",
                "链接": "https://arxiv.org/abs/2311.18248"
            },
            {
                "文章ID": "100040",
                "标题": "AutoML-GPT: Large Language Model for AutoML",
                "作者": " Yun-Da Tsai,  Yu-Che Tsai,  Bo-Wei Huang,  Chun-Pai Yang,  Shou-De Lin",
                "发布日期": "2023-09-06",
                "摘要": "  With the emerging trend of GPT models, we have established a framework called\nAutoML-GPT that integrates a comprehensive set of tools and libraries. This\nframework grants users access to a wide range of data preprocessing techniques,\nfeature engineering methods, and model selection algorithms. Through a\nconversational interface, users can specify their requirements, constraints,\nand evaluation metrics. Throughout the process, AutoML-GPT employs advanced\ntechniques for hyperparameter optimization and model selection, ensuring that\nthe resulting model achieves optimal performance. The system effectively\nmanages the complexity of the machine learning pipeline, guiding users towards\nthe best choices without requiring deep domain knowledge. Through our\nexperimental results on diverse datasets, we have demonstrated that AutoML-GPT\nsignificantly reduces the time and effort required for machine learning tasks.\nIts ability to leverage the vast knowledge encoded in large language models\nenables it to provide valuable insights, identify potential pitfalls, and\nsuggest effective solutions to common challenges faced during model training.\n",
                "链接": "https://arxiv.org/abs/2309.01125"
            },
            {
                "文章ID": "93233",
                "标题": "A Large-Scale Feasibility Study of Screen-based 3D Visualization and\n  Augmented Reality Tools for Human Anatomy Education: Exploring Gender\n  Perspectives in Learning Experience",
                "作者": " Roghayeh Leila Barmaki,  Kangsoo Kim,  Zhang Guo,  Qile Wang,  Kevin Yu,  Rebecca Pearlman,  Nassir Navab",
                "发布日期": "2023-07-28",
                "摘要": "  While anatomy learning is an essential part of medical education, there\nremain significant challenges in traditional learning methods, In this paper,\nwe introduce two in-house anatomy training solutions that can visualize and\nsuperimpose 3D virtual anatomy models with informative labels using a hand-held\ntablet or a wide-screen AR. To investigate the feasibility and effectiveness of\nthe proposed tablet-based 3D visualization and AR tools, we conducted a\nlarge-scale study with 236 students enrolled in undergraduate premedical\nprograms (95 M, 141F in 118 dyadic teams). In this study, participant students\nwere split into three groups to use one of the following learning tools in a\nteam-based anatomy painting activity: (1) conventional textbook, (2) hand-held\ntablet-based 3D visualization, and (3) screen-based AR. The results showed that\nstudents who used the tablet-based visualization tool or the AR learning tool\nreported significantly higher (more positive) learning experience scores than\nthose who used a textbook. Though we did not observe a significant difference\nin knowledge retention among the three learning tools, our further analysis of\ngender effects revealed that male participants generally reported more positive\nlearning experience scores than female participants. Also, the overall\nexperience of mixed-gender dyads was reported to be significantly lower than\nothers in most of the learning experience and performance measures. While\ndiscussing the implications of our results in the context of anatomy and\nmedical education, we highlight the potential of our learning tools with\nadditional considerations related to gender and team dynamics in body painting\nanatomy learning interventions.\n",
                "链接": "https://arxiv.org/abs/2307.14383"
            },
            {
                "文章ID": "122182",
                "标题": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications",
                "作者": " Feibo Jiang,  Li Dong,  Yubo Peng,  Kezhi Wang,  Kun Yang,  Cunhua Pan,  Dusit Niyato,  Octavia A. Dobre",
                "发布日期": "2023-12-14",
                "摘要": "  The rapid development of the Large Language Model (LLM) presents huge\nopportunities for 6G communications, e.g., network optimization and management\nby allowing users to input task requirements to LLMs by nature language.\nHowever, directly applying native LLMs in 6G encounters various challenges,\nsuch as a lack of private communication data and knowledge, limited logical\nreasoning, evaluation, and refinement abilities. Integrating LLMs with the\ncapabilities of retrieval, planning, memory, evaluation and reflection in\nagents can greatly enhance the potential of LLMs for 6G communications. To this\nend, we propose a multi-agent system with customized communication knowledge\nand tools for solving communication related tasks using natural language,\ncomprising three components: (1) Multi-agent Data Retrieval (MDR), which\nemploys the condensate and inference agents to refine and summarize\ncommunication knowledge from the knowledge base, expanding the knowledge\nboundaries of LLMs in 6G communications; (2) Multi-agent Collaborative Planning\n(MCP), which utilizes multiple planning agents to generate feasible solutions\nfor the communication related task from different perspectives based on the\nretrieved knowledge; (3) Multi-agent Evaluation and Reflecxion (MER), which\nutilizes the evaluation agent to assess the solutions, and applies the\nreflexion agent and refinement agent to provide improvement suggestions for\ncurrent solutions. Finally, we validate the effectiveness of the proposed\nmulti-agent system by designing a semantic communication system, as a case\nstudy of 6G communications.\n",
                "链接": "https://arxiv.org/abs/2312.07850"
            },
            {
                "文章ID": "32995",
                "标题": "Finding Reusable Machine Learning Components to Build Programming\n  Language Processing Pipelines",
                "作者": " Patrick Flynn,  Tristan Vanderbruggen,  Chunhua Liao,  Pei-Hung Lin,  Murali Emani,  Xipeng Shen",
                "发布日期": "2023-06-19",
                "摘要": "  Programming Language Processing (PLP) using machine learning has made vast\nimprovements in the past few years. Increasingly more people are interested in\nexploring this promising field. However, it is challenging for new researchers\nand developers to find the right components to construct their own machine\nlearning pipelines, given the diverse PLP tasks to be solved, the large number\nof datasets and models being released, and the set of complex compilers or\ntools involved. To improve the findability, accessibility, interoperability and\nreusability (FAIRness) of machine learning components, we collect and analyze a\nset of representative papers in the domain of machine learning-based PLP. We\nthen identify and characterize key concepts including PLP tasks, model\narchitectures and supportive tools. Finally, we show some example use cases of\nleveraging the reusable components to construct machine learning pipelines to\nsolve a set of PLP tasks.\n",
                "链接": "https://arxiv.org/abs/2208.05596"
            },
            {
                "文章ID": "82016",
                "标题": "GPT4Tools: Teaching Large Language Model to Use Tools via\n  Self-instruction",
                "作者": " Rui Yang,  Lin Song,  Yanwei Li,  Sijie Zhao,  Yixiao Ge,  Xiu Li,  Ying Shan",
                "发布日期": "2023-05-31",
                "摘要": "  This paper aims to efficiently enable Large Language Models (LLMs) to use\nmultimodal tools. Advanced proprietary LLMs, such as ChatGPT and GPT-4, have\nshown great potential for tool usage through sophisticated prompt engineering.\nNevertheless, these models typically rely on prohibitive computational costs\nand publicly inaccessible data. To address these challenges, we propose the\nGPT4Tools based on self-instruct to enable open-source LLMs, such as LLaMA and\nOPT, to use tools. It generates an instruction-following dataset by prompting\nan advanced teacher with various multi-modal contexts. By using the Low-Rank\nAdaptation (LoRA) optimization, our approach facilitates the open-source LLMs\nto solve a range of visual problems, including visual comprehension and image\ngeneration. Moreover, we provide a benchmark to evaluate the ability of LLMs to\nuse tools, which is performed in both zero-shot and fine-tuning ways. Extensive\nexperiments demonstrate the effectiveness of our method on various language\nmodels, which not only significantly improves the accuracy of invoking seen\ntools, but also enables the zero-shot capacity for unseen tools. The code and\ndemo are available at https://github.com/StevenGrove/GPT4Tools.\n",
                "链接": "https://arxiv.org/abs/2305.18752"
            },
            {
                "文章ID": "119760",
                "标题": "Self Generated Wargame AI: Double Layer Agent Task Planning Based on\n  Large Language Model",
                "作者": " Y. Sun,  J. Zhao,  C. Yu,  W. Wang,  X. Zhou",
                "发布日期": "2023-12-19",
                "摘要": "  The large language models represented by ChatGPT have a disruptive impact on\nthe field of artificial intelligence. But it mainly focuses on natural language\nprocessing, speech recognition, machine learning and natural language\nunderstanding. This paper innovatively applies the large language model to the\nfield of intelligent decision-making, places the large language model in the\ndecision-making center, and constructs an agent architecture with the large\nlanguage model as the core. Based on this, it further proposes a two-layer\nagent task planning, issues and executes decision commands through the\ninteraction of natural language, and carries out simulation verification\nthrough the wargame simulation environment. Through the game confrontation\nsimulation experiment, it is found that the intelligent decision-making ability\nof the large language model is significantly stronger than the commonly used\nreinforcement learning AI and rule AI, and the intelligence, understandability\nand generalization are all better. And through experiments, it was found that\nthe intelligence of the large language model is closely related to prompt. This\nwork also extends the large language model from previous human-computer\ninteraction to the field of intelligent decision-making, which has important\nreference value and significance for the development of intelligent\ndecision-making.\n",
                "链接": "https://arxiv.org/abs/2312.01090"
            },
            {
                "文章ID": "104308",
                "标题": "People's Perceptions Toward Bias and Related Concepts in Large Language\n  Models: A Systematic Review",
                "作者": " Lu Wang,  Max Song,  Rezvaneh Rezapour,  Bum Chul Kwon,  Jina Huh-Yoo",
                "发布日期": "2023-09-27",
                "摘要": "  Large language models (LLMs) have brought breakthroughs in tasks including\ntranslation, summarization, information retrieval, and language generation,\ngaining growing interest in the CHI community. Meanwhile, the literature shows\nresearchers' controversial perceptions about the efficacy, ethics, and\nintellectual abilities of LLMs. However, we do not know how lay people perceive\nLLMs that are pervasive in everyday tools, specifically regarding their\nexperience with LLMs around bias, stereotypes, social norms, or safety. In this\nstudy, we conducted a systematic review to understand what empirical insights\npapers have gathered about people's perceptions toward LLMs. From a total of\n231 retrieved papers, we full-text reviewed 15 papers that recruited human\nevaluators to assess their experiences with LLMs. We report different biases\nand related concepts investigated by these studies, four broader LLM\napplication areas, the evaluators' perceptions toward LLMs' performances\nincluding advantages, biases, and conflicting perceptions, factors influencing\nthese perceptions, and concerns about LLM applications.\n",
                "链接": "https://arxiv.org/abs/2309.14504"
            },
            {
                "文章ID": "120691",
                "标题": "DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt\n  Engineer",
                "作者": " Junyuan Hong,  Jiachen T. Wang,  Chenhui Zhang,  Zhangheng Li,  Bo Li,  Zhangyang Wang",
                "发布日期": "2023-12-08",
                "摘要": "  Large Language Models (LLMs) have emerged as dominant tools for various\ntasks, particularly when tailored for a specific target by prompt tuning.\nNevertheless, concerns surrounding data privacy present obstacles due to the\ntuned prompts' dependency on sensitive private information. A practical\nsolution is to host a local LLM and optimize a soft prompt privately using\ndata. Yet, hosting a local model becomes problematic when model ownership is\nprotected. Alternative methods, like sending data to the model's provider for\ntraining, intensify these privacy issues facing an untrusted provider. In this\npaper, we present a novel solution called Differentially-Private Offsite Prompt\nTuning (DP-OPT) to address this challenge. Our approach involves tuning a\ndiscrete prompt on the client side and then applying it to the desired cloud\nmodels. We demonstrate that prompts suggested by LLMs themselves can be\ntransferred without compromising performance significantly. To ensure that the\nprompts do not leak private information, we introduce the first private prompt\ngeneration mechanism, by a differentially-private (DP) ensemble of in-context\nlearning with private demonstrations. With DP-OPT, generating\nprivacy-preserving prompts by Vicuna-7b can yield competitive performance\ncompared to non-private in-context learning on GPT3.5 or local private prompt\ntuning. Codes are available at https://github.com/VITA-Group/DP-OPT .\n",
                "链接": "https://arxiv.org/abs/2312.03724"
            },
            {
                "文章ID": "108757",
                "标题": "MiniGPT-v2: large language model as a unified interface for\n  vision-language multi-task learning",
                "作者": " Jun Chen,  Deyao Zhu,  Xiaoqian Shen,  Xiang Li,  Zechun Liu,  Pengchuan Zhang,  Raghuraman Krishnamoorthi,  Vikas Chandra,  Yunyang Xiong,  Mohamed Elhoseiny",
                "发布日期": "2023-11-08",
                "摘要": "  Large language models have shown their remarkable capabilities as a general\ninterface for various language-related applications. Motivated by this, we\ntarget to build a unified interface for completing many vision-language tasks\nincluding image description, visual question answering, and visual grounding,\namong others. The challenge is to use a single model for performing diverse\nvision-language tasks effectively with simple multi-modal instructions. Towards\nthis objective, we introduce MiniGPT-v2, a model that can be treated as a\nunified interface for better handling various vision-language tasks. We propose\nusing unique identifiers for different tasks when training the model. These\nidentifiers enable our model to better distinguish each task instruction\neffortlessly and also improve the model learning efficiency for each task.\nAfter the three-stage training, the experimental results show that MiniGPT-v2\nachieves strong performance on many visual question-answering and visual\ngrounding benchmarks compared to other vision-language generalist models. Our\nmodel and codes are available at https://minigpt-v2.github.io/\n",
                "链接": "https://arxiv.org/abs/2310.09478"
            }
        ]
    },
    {
        "question": {
            "question": "和大模型可解释相关的最新论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "60915",
                "标题": "GCI: A (G)raph (C)oncept (I)nterpretation Framework",
                "作者": " Dmitry Kazhdan,  Botty Dimanov,  Lucie Charlotte Magister,  Pietro Barbiero,  Mateja Jamnik,  Pietro Lio",
                "发布日期": "2023-02-13",
                "摘要": "  Explainable AI (XAI) underwent a recent surge in research on concept\nextraction, focusing on extracting human-interpretable concepts from Deep\nNeural Networks. An important challenge facing concept extraction approaches is\nthe difficulty of interpreting and evaluating discovered concepts, especially\nfor complex tasks such as molecular property prediction. We address this\nchallenge by presenting GCI: a (G)raph (C)oncept (I)nterpretation framework,\nused for quantitatively measuring alignment between concepts discovered from\nGraph Neural Networks (GNNs) and their corresponding human interpretations. GCI\nencodes concept interpretations as functions, which can be used to\nquantitatively measure the alignment between a given interpretation and concept\ndefinition. We demonstrate four applications of GCI: (i) quantitatively\nevaluating concept extractors, (ii) measuring alignment between concept\nextractors and human interpretations, (iii) measuring the completeness of\ninterpretations with respect to an end task and (iv) a practical application of\nGCI to molecular property prediction, in which we demonstrate how to use\nchemical functional groups to explain GNNs trained on molecular property\nprediction tasks, and implement interpretations with a 0.76 AUCROC completeness\nscore.\n",
                "链接": "https://arxiv.org/abs/2302.04899"
            },
            {
                "文章ID": "108904",
                "标题": "LICO: Explainable Models with Language-Image Consistency",
                "作者": " Yiming Lei,  Zilong Li,  Yangyang Li,  Junping Zhang,  Hongming Shan",
                "发布日期": "2023-10-17",
                "摘要": "  Interpreting the decisions of deep learning models has been actively studied\nsince the explosion of deep neural networks. One of the most convincing\ninterpretation approaches is salience-based visual interpretation, such as\nGrad-CAM, where the generation of attention maps depends merely on categorical\nlabels. Although existing interpretation methods can provide explainable\ndecision clues, they often yield partial correspondence between image and\nsaliency maps due to the limited discriminative information from one-hot\nlabels. This paper develops a Language-Image COnsistency model for explainable\nimage classification, termed LICO, by correlating learnable linguistic prompts\nwith corresponding visual features in a coarse-to-fine manner. Specifically, we\nfirst establish a coarse global manifold structure alignment by minimizing the\ndistance between the distributions of image and language features. We then\nachieve fine-grained saliency maps by applying optimal transport (OT) theory to\nassign local feature maps with class-specific prompts. Extensive experimental\nresults on eight benchmark datasets demonstrate that the proposed LICO achieves\na significant improvement in generating more explainable attention maps in\nconjunction with existing interpretation methods such as Grad-CAM. Remarkably,\nLICO improves the classification performance of existing models without\nintroducing any computational overhead during inference. Source code is made\navailable at https://github.com/ymLeiFDU/LICO.\n",
                "链接": "https://arxiv.org/abs/2310.09821"
            },
            {
                "文章ID": "4094",
                "标题": "Towards a consistent interpretation of AIOps models",
                "作者": "Jack  Yingzhe Lyu, Jack  Gopi Krishnan Rajbahadur, Jack  Dayi Lin, Jack  Boyuan Chen, Jack  Zhen Ming,   Jiang",
                "发布日期": "2022-02-07",
                "摘要": "  Artificial Intelligence for IT Operations (AIOps) has been adopted in\norganizations in various tasks, including interpreting models to identify\nindicators of service failures. To avoid misleading practitioners, AIOps model\ninterpretations should be consistent (i.e., different AIOps models on the same\ntask agree with one another on feature importance). However, many AIOps studies\nviolate established practices in the machine learning community when deriving\ninterpretations, such as interpreting models with suboptimal performance,\nthough the impact of such violations on the interpretation consistency has not\nbeen studied. In this paper, we investigate the consistency of AIOps model\ninterpretation along three dimensions: internal consistency, external\nconsistency, and time consistency. We conduct a case study on two AIOps tasks:\npredicting Google cluster job failures, and Backblaze hard drive failures. We\nfind that the randomness from learners, hyperparameter tuning, and data\nsampling should be controlled to generate consistent interpretations. AIOps\nmodels with AUCs greater than 0.75 yield more consistent interpretation\ncompared to low-performing models. Finally, AIOps models that are constructed\nwith the Sliding Window or Full History approaches have the most consistent\ninterpretation with the trends presented in the entire datasets. Our study\nprovides valuable guidelines for practitioners to derive consistent AIOps model\ninterpretation.\n",
                "链接": "https://arxiv.org/abs/2202.02298"
            },
            {
                "文章ID": "79497",
                "标题": "Can LLMs facilitate interpretation of pre-trained language models?",
                "作者": " Basel Mousi,  Nadir Durrani,  Fahim Dalvi",
                "发布日期": "2023-10-23",
                "摘要": "  Work done to uncover the knowledge encoded within pre-trained language models\nrely on annotated corpora or human-in-the-loop methods. However, these\napproaches are limited in terms of scalability and the scope of interpretation.\nWe propose using a large language model, ChatGPT, as an annotator to enable\nfine-grained interpretation analysis of pre-trained language models. We\ndiscover latent concepts within pre-trained language models by applying\nagglomerative hierarchical clustering over contextualized representations and\nthen annotate these concepts using ChatGPT. Our findings demonstrate that\nChatGPT produces accurate and semantically richer annotations compared to\nhuman-annotated concepts. Additionally, we showcase how GPT-based annotations\nempower interpretation analysis methodologies of which we demonstrate two:\nprobing frameworks and neuron interpretation. To facilitate further exploration\nand experimentation in the field, we make available a substantial ConceptNet\ndataset (TCN) comprising 39,000 annotated concepts.\n",
                "链接": "https://arxiv.org/abs/2305.13386"
            },
            {
                "文章ID": "26643",
                "标题": "Thermodynamics of Interpretation",
                "作者": " Shams Mehdi,  Pratyush Tiwary",
                "发布日期": "2023-03-06",
                "摘要": "  Over the past few years, different types of data-driven Artificial\nIntelligence (AI) techniques have been widely adopted in various domains of\nscience for generating predictive models. However, because of their black-box\nnature, it is crucial to establish trust in these models before accepting them\nas accurate. One way of achieving this goal is through the implementation of a\npost-hoc interpretation scheme that can put forward the reasons behind a\nblack-box model's prediction. In this work, we propose a classical\nthermodynamics inspired approach for this purpose: Thermodynamically\nExplainable Representations of AI and other black-box Paradigms (TERP). TERP\nworks by constructing a linear, local surrogate model that approximates the\nbehaviour of the black-box model within a small neighborhood around the\ninstance being explained. By employing a simple forward feature selection\nalgorithm, TERP assigns an interpretability score to all the possible surrogate\nmodels. Compared to existing methods, TERP improves interpretability by\nselecting an optimal interpretation from these models by drawing simple\nparallels with classical thermodynamics. To validate TERP as a generally\napplicable method, we successfully demonstrate how it can be used to obtain\ninterpretations of a wide range of black-box model architectures including deep\nlearning Autoencoders, Recurrent neural networks and Convolutional neural\nnetworks applied to different domains including molecular simulations, image,\nand text classification respectively.\n",
                "链接": "https://arxiv.org/abs/2206.13475"
            },
            {
                "文章ID": "96227",
                "标题": "Generative Interpretation",
                "作者": " Yonathan A. Arbel,  David Hoffman",
                "发布日期": "2023-08-15",
                "摘要": "  We introduce generative interpretation, a new approach to estimating\ncontractual meaning using large language models. As AI triumphalism is the\norder of the day, we proceed by way of grounded case studies, each illustrating\nthe capabilities of these novel tools in distinct ways. Taking well-known\ncontracts opinions, and sourcing the actual agreements that they adjudicated,\nwe show that AI models can help factfinders ascertain ordinary meaning in\ncontext, quantify ambiguity, and fill gaps in parties' agreements. We also\nillustrate how models can calculate the probative value of individual pieces of\nextrinsic evidence. After offering best practices for the use of these models\ngiven their limitations, we consider their implications for judicial practice\nand contract theory. Using LLMs permits courts to estimate what the parties\nintended cheaply and accurately, and as such generative interpretation\nunsettles the current interpretative stalemate. Their use responds to\nefficiency-minded textualists and justice-oriented contextualists, who argue\nabout whether parties will prefer cost and certainty or accuracy and fairness.\nParties--and courts--would prefer a middle path, in which adjudicators strive\nto predict what the contract really meant, admitting just enough context to\napproximate reality while avoiding unguided and biased assimilation of\nevidence. As generative interpretation offers this possibility, we argue it can\nbecome the new workhorse of contractual interpretation.\n",
                "链接": "https://arxiv.org/abs/2308.06907"
            },
            {
                "文章ID": "68170",
                "标题": "Posthoc Interpretation via Quantization",
                "作者": " Francesco Paissan,  Cem Subakan,  Mirco Ravanelli",
                "发布日期": "2023-05-30",
                "摘要": "  In this paper, we introduce a new approach, called Posthoc Interpretation via\nQuantization (PIQ), for interpreting decisions made by trained classifiers. Our\nmethod utilizes vector quantization to transform the representations of a\nclassifier into a discrete, class-specific latent space. The class-specific\ncodebooks act as a bottleneck that forces the interpreter to focus on the parts\nof the input data deemed relevant by the classifier for making a prediction.\nOur model formulation also enables learning concepts by incorporating the\nsupervision of pretrained annotation models such as state-of-the-art image\nsegmentation models. We evaluated our method through quantitative and\nqualitative studies involving black-and-white images, color images, and audio.\nAs a result of these studies we found that PIQ generates interpretations that\nare more easily understood by participants to our user studies when compared to\nseveral other interpretation methods in the literature.\n",
                "链接": "https://arxiv.org/abs/2303.12659"
            },
            {
                "文章ID": "45125",
                "标题": "Leveraging Affirmative Interpretations from Negation Improves Natural\n  Language Understanding",
                "作者": " Md Mosharaf Hossain,  Eduardo Blanco",
                "发布日期": "2022-10-27",
                "摘要": "  Negation poses a challenge in many natural language understanding tasks.\nInspired by the fact that understanding a negated statement often requires\nhumans to infer affirmative interpretations, in this paper we show that doing\nso benefits models for three natural language understanding tasks. We present\nan automated procedure to collect pairs of sentences with negation and their\naffirmative interpretations, resulting in over 150,000 pairs. Experimental\nresults show that leveraging these pairs helps (a) T5 generate affirmative\ninterpretations from negations in a previous benchmark, and (b) a RoBERTa-based\nclassifier solve the task of natural language inference. We also leverage our\npairs to build a plug-and-play neural generator that given a negated statement\ngenerates an affirmative interpretation. Then, we incorporate the pretrained\ngenerator into a RoBERTa-based classifier for sentiment analysis and show that\ndoing so improves the results. Crucially, our proposal does not require any\nmanual effort.\n",
                "链接": "https://arxiv.org/abs/2210.14486"
            },
            {
                "文章ID": "103598",
                "标题": "Multimodal Deep Learning for Scientific Imaging Interpretation",
                "作者": " Abdulelah S. Alshehri,  Franklin L. Lee,  Shihu Wang",
                "发布日期": "2023-09-27",
                "摘要": "  In the domain of scientific imaging, interpreting visual data often demands\nan intricate combination of human expertise and deep comprehension of the\nsubject materials. This study presents a novel methodology to linguistically\nemulate and subsequently evaluate human-like interactions with Scanning\nElectron Microscopy (SEM) images, specifically of glass materials. Leveraging a\nmultimodal deep learning framework, our approach distills insights from both\ntextual and visual data harvested from peer-reviewed articles, further\naugmented by the capabilities of GPT-4 for refined data synthesis and\nevaluation. Despite inherent challenges--such as nuanced interpretations and\nthe limited availability of specialized datasets--our model (GlassLLaVA) excels\nin crafting accurate interpretations, identifying key features, and detecting\ndefects in previously unseen SEM images. Moreover, we introduce versatile\nevaluation metrics, suitable for an array of scientific imaging applications,\nwhich allows for benchmarking against research-grounded answers. Benefiting\nfrom the robustness of contemporary Large Language Models, our model adeptly\naligns with insights from research papers. This advancement not only\nunderscores considerable progress in bridging the gap between human and machine\ninterpretation in scientific imaging, but also hints at expansive avenues for\nfuture research and broader application.\n",
                "链接": "https://arxiv.org/abs/2309.12460"
            },
            {
                "文章ID": "116830",
                "标题": "Exploring Prompting Large Language Models as Explainable Metrics",
                "作者": " Ghazaleh Mahmoudi",
                "发布日期": "2023-11-21",
                "摘要": "  This paper describes the IUST NLP Lab submission to the Prompting Large\nLanguage Models as Explainable Metrics Shared Task at the Eval4NLP 2023\nWorkshop on Evaluation & Comparison of NLP Systems. We have proposed a\nzero-shot prompt-based strategy for explainable evaluation of the summarization\ntask using Large Language Models (LLMs). The conducted experiments demonstrate\nthe promising potential of LLMs as evaluation metrics in Natural Language\nProcessing (NLP), particularly in the field of summarization. Both few-shot and\nzero-shot approaches are employed in these experiments. The performance of our\nbest provided prompts achieved a Kendall correlation of 0.477 with human\nevaluations in the text summarization task on the test data. Code and results\nare publicly available on GitHub.\n",
                "链接": "https://arxiv.org/abs/2311.11552"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于大模型Agent应用的最新发表论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "104257",
                "标题": "An In-depth Survey of Large Language Model-based Artificial Intelligence\n  Agents",
                "作者": " Pengyu Zhao,  Zijian Jin,  Ning Cheng",
                "发布日期": "2023-09-27",
                "摘要": "  Due to the powerful capabilities demonstrated by large language model (LLM),\nthere has been a recent surge in efforts to integrate them with AI agents to\nenhance their performance. In this paper, we have explored the core differences\nand characteristics between LLM-based AI agents and traditional AI agents.\nSpecifically, we first compare the fundamental characteristics of these two\ntypes of agents, clarifying the significant advantages of LLM-based agents in\nhandling natural language, knowledge storage, and reasoning capabilities.\nSubsequently, we conducted an in-depth analysis of the key components of AI\nagents, including planning, memory, and tool use. Particularly, for the crucial\ncomponent of memory, this paper introduced an innovative classification scheme,\nnot only departing from traditional classification methods but also providing a\nfresh perspective on the design of an AI agent's memory system. We firmly\nbelieve that in-depth research and understanding of these core components will\nlay a solid foundation for the future advancement of AI agent technology. At\nthe end of the paper, we provide directional suggestions for further research\nin this field, with the hope of offering valuable insights to scholars and\nresearchers in the field.\n",
                "链接": "https://arxiv.org/abs/2309.14365"
            },
            {
                "文章ID": "97404",
                "标题": "ChatEDA: A Large Language Model Powered Autonomous Agent for EDA",
                "作者": " Zhuolun He,  Haoyuan Wu,  Xinyun Zhang,  Xufeng Yao,  Su Zheng,  Haisheng Zheng,  Bei Yu",
                "发布日期": "2023-08-22",
                "摘要": "  The integration of a complex set of Electronic Design Automation (EDA) tools\nto enhance interoperability is a critical concern for circuit designers. Recent\nadvancements in large language models (LLMs) have showcased their exceptional\ncapabilities in natural language processing and comprehension, offering a novel\napproach to interfacing with EDA tools. This research paper introduces ChatEDA,\nan autonomous agent for EDA empowered by a large language model, AutoMage,\ncomplemented by EDA tools serving as executors. ChatEDA streamlines the design\nflow from the Register-Transfer Level (RTL) to the Graphic Data System Version\nII (GDSII) by effectively managing task planning, script generation, and task\nexecution. Through comprehensive experimental evaluations, ChatEDA has\ndemonstrated its proficiency in handling diverse requirements, and our\nfine-tuned AutoMage model has exhibited superior performance compared to GPT-4\nand other similar LLMs.\n",
                "链接": "https://arxiv.org/abs/2308.10204"
            },
            {
                "文章ID": "122182",
                "标题": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications",
                "作者": " Feibo Jiang,  Li Dong,  Yubo Peng,  Kezhi Wang,  Kun Yang,  Cunhua Pan,  Dusit Niyato,  Octavia A. Dobre",
                "发布日期": "2023-12-14",
                "摘要": "  The rapid development of the Large Language Model (LLM) presents huge\nopportunities for 6G communications, e.g., network optimization and management\nby allowing users to input task requirements to LLMs by nature language.\nHowever, directly applying native LLMs in 6G encounters various challenges,\nsuch as a lack of private communication data and knowledge, limited logical\nreasoning, evaluation, and refinement abilities. Integrating LLMs with the\ncapabilities of retrieval, planning, memory, evaluation and reflection in\nagents can greatly enhance the potential of LLMs for 6G communications. To this\nend, we propose a multi-agent system with customized communication knowledge\nand tools for solving communication related tasks using natural language,\ncomprising three components: (1) Multi-agent Data Retrieval (MDR), which\nemploys the condensate and inference agents to refine and summarize\ncommunication knowledge from the knowledge base, expanding the knowledge\nboundaries of LLMs in 6G communications; (2) Multi-agent Collaborative Planning\n(MCP), which utilizes multiple planning agents to generate feasible solutions\nfor the communication related task from different perspectives based on the\nretrieved knowledge; (3) Multi-agent Evaluation and Reflecxion (MER), which\nutilizes the evaluation agent to assess the solutions, and applies the\nreflexion agent and refinement agent to provide improvement suggestions for\ncurrent solutions. Finally, we validate the effectiveness of the proposed\nmulti-agent system by designing a semantic communication system, as a case\nstudy of 6G communications.\n",
                "链接": "https://arxiv.org/abs/2312.07850"
            },
            {
                "文章ID": "85679",
                "标题": "AVIS: Autonomous Visual Information Seeking with Large Language Model\n  Agent",
                "作者": " Ziniu Hu,  Ahmet Iscen,  Chen Sun,  Kai-Wei Chang,  Yizhou Sun,  David A Ross,  Cordelia Schmid,  Alireza Fathi",
                "发布日期": "2023-11-03",
                "摘要": "  In this paper, we propose an autonomous information seeking visual question\nanswering framework, AVIS. Our method leverages a Large Language Model (LLM) to\ndynamically strategize the utilization of external tools and to investigate\ntheir outputs, thereby acquiring the indispensable knowledge needed to provide\nanswers to the posed questions. Responding to visual questions that necessitate\nexternal knowledge, such as \"What event is commemorated by the building\ndepicted in this image?\", is a complex task. This task presents a combinatorial\nsearch space that demands a sequence of actions, including invoking APIs,\nanalyzing their responses, and making informed decisions. We conduct a user\nstudy to collect a variety of instances of human decision-making when faced\nwith this task. This data is then used to design a system comprised of three\ncomponents: an LLM-powered planner that dynamically determines which tool to\nuse next, an LLM-powered reasoner that analyzes and extracts key information\nfrom the tool outputs, and a working memory component that retains the acquired\ninformation throughout the process. The collected user behavior serves as a\nguide for our system in two key ways. First, we create a transition graph by\nanalyzing the sequence of decisions made by users. This graph delineates\ndistinct states and confines the set of actions available at each state.\nSecond, we use examples of user decision-making to provide our LLM-powered\nplanner and reasoner with relevant contextual instances, enhancing their\ncapacity to make informed decisions. We show that AVIS achieves\nstate-of-the-art results on knowledge-intensive visual question answering\nbenchmarks such as Infoseek and OK-VQA.\n",
                "链接": "https://arxiv.org/abs/2306.08129"
            },
            {
                "文章ID": "98891",
                "标题": "RecMind: Large Language Model Powered Agent For Recommendation",
                "作者": " Yancheng Wang,  Ziyan Jiang,  Zheng Chen,  Fan Yang,  Yingxue Zhou,  Eunah Cho,  Xing Fan,  Xiaojiang Huang,  Yanbin Lu,  Yingzhen Yang",
                "发布日期": "2023-08-29",
                "摘要": "  Recent advancements in instructing Large Language Models (LLMs) to utilize\nexternal tools and execute multi-step plans have significantly enhanced their\nability to solve intricate tasks, ranging from mathematical problems to\ncreative writing. Yet, there remains a notable gap in studying the capacity of\nLLMs in responding to personalized queries such as a recommendation request. To\nbridge this gap, we have designed an LLM-powered autonomous recommender agent,\nRecMind, which is capable of providing precise personalized recommendations\nthrough careful planning, utilizing tools for obtaining external knowledge, and\nleveraging individual data. We propose a novel algorithm, Self-Inspiring, to\nimprove the planning ability of the LLM agent. At each intermediate planning\nstep, the LLM 'self-inspires' to consider all previously explored states to\nplan for next step. This mechanism greatly improves the model's ability to\ncomprehend and utilize historical planning information for recommendation. We\nevaluate RecMind's performance in various recommendation scenarios, including\nrating prediction, sequential recommendation, direct recommendation,\nexplanation generation, and review summarization. Our experiment shows that\nRecMind outperforms existing zero/few-shot LLM-based recommendation methods in\ndifferent recommendation tasks and achieves competitive performance to a recent\nmodel P5, which requires fully pre-train for the recommendation tasks.\n",
                "链接": "https://arxiv.org/abs/2308.14296"
            },
            {
                "文章ID": "119760",
                "标题": "Self Generated Wargame AI: Double Layer Agent Task Planning Based on\n  Large Language Model",
                "作者": " Y. Sun,  J. Zhao,  C. Yu,  W. Wang,  X. Zhou",
                "发布日期": "2023-12-19",
                "摘要": "  The large language models represented by ChatGPT have a disruptive impact on\nthe field of artificial intelligence. But it mainly focuses on natural language\nprocessing, speech recognition, machine learning and natural language\nunderstanding. This paper innovatively applies the large language model to the\nfield of intelligent decision-making, places the large language model in the\ndecision-making center, and constructs an agent architecture with the large\nlanguage model as the core. Based on this, it further proposes a two-layer\nagent task planning, issues and executes decision commands through the\ninteraction of natural language, and carries out simulation verification\nthrough the wargame simulation environment. Through the game confrontation\nsimulation experiment, it is found that the intelligent decision-making ability\nof the large language model is significantly stronger than the commonly used\nreinforcement learning AI and rule AI, and the intelligence, understandability\nand generalization are all better. And through experiments, it was found that\nthe intelligence of the large language model is closely related to prompt. This\nwork also extends the large language model from previous human-computer\ninteraction to the field of intelligent decision-making, which has important\nreference value and significance for the development of intelligent\ndecision-making.\n",
                "链接": "https://arxiv.org/abs/2312.01090"
            },
            {
                "文章ID": "118095",
                "标题": "Algorithm Evolution Using Large Language Model",
                "作者": " Fei Liu,  Xialiang Tong,  Mingxuan Yuan,  Qingfu Zhang",
                "发布日期": "2023-11-28",
                "摘要": "  Optimization can be found in many real-life applications. Designing an\neffective algorithm for a specific optimization problem typically requires a\ntedious amount of effort from human experts with domain knowledge and algorithm\ndesign skills. In this paper, we propose a novel approach called Algorithm\nEvolution using Large Language Model (AEL). It utilizes a large language model\n(LLM) to automatically generate optimization algorithms via an evolutionary\nframework. AEL does algorithm-level evolution without model training. Human\neffort and requirements for domain knowledge can be significantly reduced. We\ntake constructive methods for the salesman traveling problem as a test example,\nwe show that the constructive algorithm obtained by AEL outperforms simple\nhand-crafted and LLM-generated heuristics. Compared with other domain deep\nlearning model-based algorithms, these methods exhibit excellent scalability\nacross different problem sizes. AEL is also very different from previous\nattempts that utilize LLMs as search operators in algorithms.\n",
                "链接": "https://arxiv.org/abs/2311.15249"
            },
            {
                "文章ID": "99535",
                "标题": "Enhancing Subtask Performance of Multi-modal Large Language Model",
                "作者": " Yongqiang Zhao,  Zhenyu Li,  Feng Zhang,  Xinhai Xu,  Donghong Liu",
                "发布日期": "2023-09-01",
                "摘要": "  Multi-modal Large Language Model (MLLM) refers to a model expanded from a\nLarge Language Model (LLM) that possesses the capability to handle and infer\nmulti-modal data. Current MLLMs typically begin by using LLMs to decompose\ntasks into multiple subtasks, then employing individual pre-trained models to\ncomplete specific subtasks, and ultimately utilizing LLMs to integrate the\nresults of each subtasks to obtain the results of the task. In real-world\nscenarios, when dealing with large projects, it is common practice to break\ndown the project into smaller sub-projects, with different teams providing\ncorresponding solutions or results. The project owner then decides which\nsolution or result to use, ensuring the best possible outcome for each subtask\nand, consequently, for the entire project. Inspired by this, this study\nconsiders selecting multiple pre-trained models to complete the same subtask.\nBy combining the results from multiple pre-trained models, the optimal subtask\nresult is obtained, enhancing the performance of the MLLM. Specifically, this\nstudy first selects multiple pre-trained models focused on the same subtask\nbased on distinct evaluation approaches, and then invokes these models in\nparallel to process input data and generate corresponding subtask results.\nFinally, the results from multiple pre-trained models for the same subtask are\ncompared using the LLM, and the best result is chosen as the outcome for that\nsubtask. Extensive experiments are conducted in this study using GPT-4\nannotated datasets and human-annotated datasets. The results of various\nevaluation metrics adequately demonstrate the effectiveness of the proposed\napproach in this paper.\n",
                "链接": "https://arxiv.org/abs/2308.16474"
            },
            {
                "文章ID": "102167",
                "标题": "FedJudge: Federated Legal Large Language Model",
                "作者": " Linan Yue,  Qi Liu,  Yichao Du,  Weibo Gao,  Ye Liu,  Fangzhou Yao",
                "发布日期": "2023-12-22",
                "摘要": "  Large Language Models (LLMs) have gained prominence in the field of Legal\nIntelligence, offering potential applications in assisting legal professionals\nand laymen. However, the centralized training of these Legal LLMs raises data\nprivacy concerns, as legal data is distributed among various institutions\ncontaining sensitive individual information. This paper addresses this\nchallenge by exploring the integration of Legal LLMs with Federated Learning\n(FL) methodologies. By employing FL, Legal LLMs can be fine-tuned locally on\ndevices or clients, and their parameters are aggregated and distributed on a\ncentral server, ensuring data privacy without directly sharing raw data.\nHowever, computation and communication overheads hinder the full fine-tuning of\nLLMs under the FL setting. Moreover, the distribution shift of legal data\nreduces the effectiveness of FL methods. To this end, in this paper, we propose\nthe first Federated Legal Large Language Model (FedJudge) framework, which\nfine-tunes Legal LLMs efficiently and effectively. Specifically, FedJudge\nutilizes parameter-efficient fine-tuning methods to update only a few\nadditional parameters during the FL training. Besides, we explore the continual\nlearning methods to preserve the global model's important parameters when\ntraining local clients to mitigate the problem of data shifts. Extensive\nexperimental results on three real-world datasets clearly validate the\neffectiveness of FedJudge. Code is released at\nhttps://github.com/yuelinan/FedJudge.\n",
                "链接": "https://arxiv.org/abs/2309.08173"
            },
            {
                "文章ID": "97862",
                "标题": "A Survey on Large Language Model based Autonomous Agents",
                "作者": " Lei Wang,  Chen Ma,  Xueyang Feng,  Zeyu Zhang,  Hao Yang,  Jingsen Zhang,  Zhiyuan Chen,  Jiakai Tang,  Xu Chen,  Yankai Lin,  Wayne Xin Zhao,  Zhewei Wei,  Ji-Rong Wen",
                "发布日期": "2023-09-08",
                "摘要": "  Autonomous agents have long been a prominent research focus in both academic\nand industry communities. Previous research in this field often focuses on\ntraining agents with limited knowledge within isolated environments, which\ndiverges significantly from human learning processes, and thus makes the agents\nhard to achieve human-like decisions. Recently, through the acquisition of vast\namounts of web knowledge, large language models (LLMs) have demonstrated\nremarkable potential in achieving human-level intelligence. This has sparked an\nupsurge in studies investigating LLM-based autonomous agents. In this paper, we\npresent a comprehensive survey of these studies, delivering a systematic review\nof the field of LLM-based autonomous agents from a holistic perspective. More\nspecifically, we first discuss the construction of LLM-based autonomous agents,\nfor which we propose a unified framework that encompasses a majority of the\nprevious work. Then, we present a comprehensive overview of the diverse\napplications of LLM-based autonomous agents in the fields of social science,\nnatural science, and engineering. Finally, we delve into the evaluation\nstrategies commonly used for LLM-based autonomous agents. Based on the previous\nstudies, we also present several challenges and future directions in this\nfield. To keep track of this field and continuously update our survey, we\nmaintain a repository of relevant references at\nhttps://github.com/Paitesanshi/LLM-Agent-Survey.\n",
                "链接": "https://arxiv.org/abs/2308.11432"
            }
        ]
    },
    {
        "question": {
            "question": "查询近一年模型推理加速相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "111604",
                "标题": "Hierarchical Semi-Implicit Variational Inference with Application to\n  Diffusion Model Acceleration",
                "作者": " Longlin Yu,  Tianyu Xie,  Yu Zhu,  Tong Yang,  Xiangyu Zhang,  Cheng Zhang",
                "发布日期": "2023-10-27",
                "摘要": "  Semi-implicit variational inference (SIVI) has been introduced to expand the\nanalytical variational families by defining expressive semi-implicit\ndistributions in a hierarchical manner. However, the single-layer architecture\ncommonly used in current SIVI methods can be insufficient when the target\nposterior has complicated structures. In this paper, we propose hierarchical\nsemi-implicit variational inference, called HSIVI, which generalizes SIVI to\nallow more expressive multi-layer construction of semi-implicit distributions.\nBy introducing auxiliary distributions that interpolate between a simple base\ndistribution and the target distribution, the conditional layers can be trained\nby progressively matching these auxiliary distributions one layer after\nanother. Moreover, given pre-trained score networks, HSIVI can be used to\naccelerate the sampling process of diffusion models with the score matching\nobjective. We show that HSIVI significantly enhances the expressiveness of SIVI\non several Bayesian inference problems with complicated target distributions.\nWhen used for diffusion model acceleration, we show that HSIVI can produce high\nquality samples comparable to or better than the existing fast diffusion model\nbased samplers with a small number of function evaluations on various datasets.\n",
                "链接": "https://arxiv.org/abs/2310.17153"
            },
            {
                "文章ID": "124676",
                "标题": "Understanding the Potential of FPGA-Based Spatial Acceleration for Large\n  Language Model Inference",
                "作者": " Hongzheng Chen,  Jiahao Zhang,  Yixiao Du,  Shaojie Xiang,  Zichao Yue,  Niansong Zhang,  Yaohui Cai,  Zhiru Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Recent advancements in large language models (LLMs) boasting billions of\nparameters have generated a significant demand for efficient deployment in\ninference workloads. The majority of existing approaches rely on temporal\narchitectures that reuse hardware units for different network layers and\noperators. However, these methods often encounter challenges in achieving low\nlatency due to considerable memory access overhead. This paper investigates the\nfeasibility and potential of model-specific spatial acceleration for LLM\ninference on FPGAs. Our approach involves the specialization of distinct\nhardware units for specific operators or layers, facilitating direct\ncommunication between them through a dataflow architecture while minimizing\noff-chip memory accesses. We introduce a comprehensive analytical model for\nestimating the performance of a spatial LLM accelerator, taking into account\nthe on-chip compute and memory resources available on an FPGA. Through our\nanalysis, we can determine the scenarios in which FPGA-based spatial\nacceleration can outperform its GPU-based counterpart. To enable more\nproductive implementations of an LLM model on FPGAs, we further provide a\nlibrary of high-level synthesis (HLS) kernels that are composable and reusable.\nThis library will be made available as open-source. To validate the\neffectiveness of both our analytical model and HLS library, we have implemented\nBERT and GPT2 on an AMD Alveo U280 FPGA device. Experimental results\ndemonstrate our approach can achieve up to 16.1x speedup when compared to\nprevious FPGA-based accelerators for the BERT model. For GPT generative\ninference, we attain a 2.2x speedup compared to DFX, an FPGA overlay, in the\nprefill stage, while achieving a 1.9x speedup and a 5.7x improvement in energy\nefficiency compared to the NVIDIA A100 GPU in the decode stage.\n",
                "链接": "https://arxiv.org/abs/2312.15159"
            },
            {
                "文章ID": "123966",
                "标题": "Lookahead: An Inference Acceleration Framework for Large Language Model\n  with Lossless Generation Accuracy",
                "作者": " Yao Zhao,  Zhitian Xie,  Chenyi Zhuang,  Jinjie Gu",
                "发布日期": "2023-12-21",
                "摘要": "  As Large Language Models (LLMs) have made significant advancements across\nvarious tasks, such as question answering, translation, text summarization, and\ndialogue systems, the need for accuracy in information becomes crucial,\nespecially for serious financial products serving billions of users like\nAlipay. To address this, Alipay has developed a Retrieval-Augmented Generation\n(RAG) system that grounds LLMs on the most accurate and up-to-date information.\nHowever, for a real-world product serving millions of users, the inference\nspeed of LLMs becomes a critical factor compared to a mere experimental model.\n  Hence, this paper presents a generic framework for accelerating the inference\nprocess, resulting in a substantial increase in speed and cost reduction for\nour RAG system, with lossless generation accuracy. In the traditional inference\nprocess, each token is generated sequentially by the LLM, leading to a time\nconsumption proportional to the number of generated tokens. To enhance this\nprocess, our framework, named \\textit{lookahead}, introduces a\n\\textit{multi-branch} strategy. Instead of generating a single token at a time,\nwe propose a \\textit{Trie-based Retrieval} (TR) process that enables the\ngeneration of multiple branches simultaneously, each of which is a sequence of\ntokens. Subsequently, for each branch, a \\textit{Verification and Accept} (VA)\nprocess is performed to identify the longest correct sub-sequence as the final\noutput. Our strategy offers two distinct advantages: (1) it guarantees absolute\ncorrectness of the output, avoiding any approximation algorithms, and (2) the\nworst-case performance of our approach is equivalent to the conventional\nprocess. We conduct extensive experiments to demonstrate the significant\nimprovements achieved by applying our inference acceleration framework.\n",
                "链接": "https://arxiv.org/abs/2312.12728"
            },
            {
                "文章ID": "119522",
                "标题": "LinguaLinked: A Distributed Large Language Model Inference System for\n  Mobile Devices",
                "作者": " Junchen Zhao,  Yurun Song,  Simeng Liu,  Ian G. Harris,  Sangeetha Abdu Jyothi",
                "发布日期": "2023-12-04",
                "摘要": "  Deploying Large Language Models (LLMs) locally on mobile devices presents a\nsignificant challenge due to their extensive memory requirements. In this\npaper, we introduce LinguaLinked, a system for decentralized, distributed LLM\ninference on mobile devices. LinguaLinked enables collaborative execution of\nthe inference task across multiple trusted devices. LinguaLinked ensures data\nprivacy by processing information locally. LinguaLinked uses three key\nstrategies. First, an optimized model assignment technique segments LLMs and\nuses linear optimization to align segments with each device's capabilities.\nSecond, an optimized data transmission mechanism ensures efficient and\nstructured data flow between model segments while also maintaining the\nintegrity of the original model structure. Finally, LinguaLinked incorporates a\nruntime load balancer that actively monitors and redistributes tasks among\nmobile devices to prevent bottlenecks, enhancing the system's overall\nefficiency and responsiveness. We demonstrate that LinguaLinked facilitates\nefficient LLM inference while maintaining consistent throughput and minimal\nlatency through extensive testing across various mobile devices, from high-end\nto low-end Android devices. In our evaluations, compared to the baseline,\nLinguaLinked achieves an inference performance acceleration of $1.11\\times$ to\n$1.61\\times$ in single-threaded settings, $1.73\\times$ to $2.65\\times$ with\nmulti-threading. Additionally, runtime load balancing yields an overall\ninference acceleration of $1.29\\times$ to $1.32\\times$.\n",
                "链接": "https://arxiv.org/abs/2312.00388"
            },
            {
                "文章ID": "91683",
                "标题": "Using the IBM Analog In-Memory Hardware Acceleration Kit for Neural\n  Network Training and Inference",
                "作者": " Manuel Le Gallo,  Corey Lammie,  Julian Buechel,  Fabio Carta,  Omobayode Fagbohungbe,  Charles Mackin,  Hsinyu Tsai,  Vijay Narayanan,  Abu Sebastian,  Kaoutar El Maghraoui,  Malte J. Rasch",
                "发布日期": "2023-07-19",
                "摘要": "  Analog In-Memory Computing (AIMC) is a promising approach to reduce the\nlatency and energy consumption of Deep Neural Network (DNN) inference and\ntraining. However, the noisy and non-linear device characteristics, and the\nnon-ideal peripheral circuitry in AIMC chips, require adapting DNNs to be\ndeployed on such hardware to achieve equivalent accuracy to digital computing.\nIn this tutorial, we provide a deep dive into how such adaptations can be\nachieved and evaluated using the recently released IBM Analog Hardware\nAcceleration Kit (AIHWKit), freely available at https://github.com/IBM/aihwkit.\nThe AIHWKit is a Python library that simulates inference and training of DNNs\nusing AIMC. We present an in-depth description of the AIHWKit design,\nfunctionality, and best practices to properly perform inference and training.\nWe also present an overview of the Analog AI Cloud Composer, that provides the\nbenefits of using the AIHWKit simulation platform in a fully managed cloud\nsetting. Finally, we show examples on how users can expand and customize\nAIHWKit for their own needs. This tutorial is accompanied by comprehensive\nJupyter Notebook code examples that can be run using AIHWKit, which can be\ndownloaded from https://github.com/IBM/aihwkit/tree/master/notebooks/tutorial.\n",
                "链接": "https://arxiv.org/abs/2307.09357"
            },
            {
                "文章ID": "87109",
                "标题": "Adaptive DNN Surgery for Selfish Inference Acceleration with On-demand\n  Edge Resource",
                "作者": " Xiang Yang,  Dezhi Chen,  Qi Qi,  Jingyu Wang,  Haifeng Sun,  Jianxin Liao,  Song Guo",
                "发布日期": "2023-06-22",
                "摘要": "  Deep Neural Networks (DNNs) have significantly improved the accuracy of\nintelligent applications on mobile devices. DNN surgery, which partitions DNN\nprocessing between mobile devices and multi-access edge computing (MEC)\nservers, can enable real-time inference despite the computational limitations\nof mobile devices. However, DNN surgery faces a critical challenge: determining\nthe optimal computing resource demand from the server and the corresponding\npartition strategy, while considering both inference latency and MEC server\nusage costs. This problem is compounded by two factors: (1) the finite\ncomputing capacity of the MEC server, which is shared among multiple devices,\nleading to inter-dependent demands, and (2) the shift in modern DNN\narchitecture from chains to directed acyclic graphs (DAGs), which complicates\npotential solutions.\n  In this paper, we introduce a novel Decentralized DNN Surgery (DDS)\nframework. We formulate the partition strategy as a min-cut and propose a\nresource allocation game to adaptively schedule the demands of mobile devices\nin an MEC environment. We prove the existence of a Nash Equilibrium (NE), and\ndevelop an iterative algorithm to efficiently reach the NE for each device. Our\nextensive experiments demonstrate that DDS can effectively handle varying MEC\nscenarios, achieving up to 1.25$\\times$ acceleration compared to the\nstate-of-the-art algorithm.\n",
                "链接": "https://arxiv.org/abs/2306.12185"
            },
            {
                "文章ID": "112504",
                "标题": "SparseByteNN: A Novel Mobile Inference Acceleration Framework Based on\n  Fine-Grained Group Sparsity",
                "作者": " Haitao Xu,  Songwei Liu,  Yuyang Xu,  Shuai Wang,  Jiashi Li,  Chenqian Yan,  Liangqiang Li,  Lean Fu,  Xin Pan,  Fangmin Chen",
                "发布日期": "2023-10-31",
                "摘要": "  To address the challenge of increasing network size, researchers have\ndeveloped sparse models through network pruning. However, maintaining model\naccuracy while achieving significant speedups on general computing devices\nremains an open problem. In this paper, we present a novel mobile inference\nacceleration framework SparseByteNN, which leverages fine-grained kernel\nsparsity to achieve real-time execution as well as high accuracy. Our framework\nconsists of two parts: (a) A fine-grained kernel sparsity schema with a\nsparsity granularity between structured pruning and unstructured pruning. It\ndesigns multiple sparse patterns for different operators. Combined with our\nproposed whole network rearrangement strategy, the schema achieves a high\ncompression rate and high precision at the same time. (b) Inference engine\nco-optimized with the sparse pattern. The conventional wisdom is that this\nreduction in theoretical FLOPs does not translate into real-world efficiency\ngains. We aim to correct this misconception by introducing a family of\nefficient sparse kernels for ARM and WebAssembly. Equipped with our efficient\nimplementation of sparse primitives, we show that sparse versions of\nMobileNet-v1 outperform strong dense baselines on the efficiency-accuracy\ncurve. Experimental results on Qualcomm 855 show that for 30% sparse\nMobileNet-v1, SparseByteNN achieves 1.27x speedup over the dense version and\n1.29x speedup over the state-of-the-art sparse inference engine MNN with a\nslight accuracy drop of 0.224%. The source code of SparseByteNN will be\navailable at https://github.com/lswzjuer/SparseByteNN\n",
                "链接": "https://arxiv.org/abs/2310.19509"
            },
            {
                "文章ID": "108754",
                "标题": "Towards More Accurate Diffusion Model Acceleration with A Timestep\n  Aligner",
                "作者": " Mengfei Xia,  Yujun Shen,  Changsong Lei,  Yu Zhou,  Ran Yi,  Deli Zhao,  Wenping Wang,  Yong-jin Liu",
                "发布日期": "2023-10-17",
                "摘要": "  A diffusion model, which is formulated to produce an image using thousands of\ndenoising steps, usually suffers from a slow inference speed. Existing\nacceleration algorithms simplify the sampling by skipping most steps yet\nexhibit considerable performance degradation. By viewing the generation of\ndiffusion models as a discretized integrating process, we argue that the\nquality drop is partly caused by applying an inaccurate integral direction to a\ntimestep interval. To rectify this issue, we propose a timestep aligner that\nhelps find a more accurate integral direction for a particular interval at the\nminimum cost. Specifically, at each denoising step, we replace the original\nparameterization by conditioning the network on a new timestep, which is\nobtained by aligning the sampling distribution to the real distribution.\nExtensive experiments show that our plug-in design can be trained efficiently\nand boost the inference performance of various state-of-the-art acceleration\nmethods, especially when there are few denoising steps. For example, when using\n10 denoising steps on the popular LSUN Bedroom dataset, we improve the FID of\nDDIM from 9.65 to 6.07, simply by adopting our method for a more appropriate\nset of timesteps. Code will be made publicly available.\n",
                "链接": "https://arxiv.org/abs/2310.09469"
            },
            {
                "文章ID": "115860",
                "标题": "DLAS: An Exploration and Assessment of the Deep Learning Acceleration\n  Stack",
                "作者": " Perry Gibson,  José Cano,  Elliot J. Crowley,  Amos Storkey,  Michael O'Boyle",
                "发布日期": "2023-11-16",
                "摘要": "  Deep Neural Networks (DNNs) are extremely computationally demanding, which\npresents a large barrier to their deployment on resource-constrained devices.\nSince such devices are where many emerging deep learning applications lie\n(e.g., drones, vision-based medical technology), significant bodies of work\nfrom both the machine learning and systems communities have attempted to\nprovide optimizations to accelerate DNNs. To help unify these two perspectives,\nin this paper we combine machine learning and systems techniques within the\nDeep Learning Acceleration Stack (DLAS), and demonstrate how these layers can\nbe tightly dependent on each other with an across-stack perturbation study. We\nevaluate the impact on accuracy and inference time when varying different\nparameters of DLAS across two datasets, seven popular DNN architectures, four\nDNN compression techniques, three algorithmic primitives with sparse and dense\nvariants, untuned and auto-scheduled code generation, and four hardware\nplatforms. Our evaluation highlights how perturbations across DLAS parameters\ncan cause significant variation and across-stack interactions. The highest\nlevel observation from our evaluation is that the model size, accuracy, and\ninference time are not guaranteed to be correlated. Overall we make 13 key\nobservations, including that speedups provided by compression techniques are\nvery hardware dependent, and that compiler auto-tuning can significantly alter\nwhat the best algorithm to use for a given configuration is. With DLAS, we aim\nto provide a reference framework to aid machine learning and systems\npractitioners in reasoning about the context in which their respective DNN\nacceleration solutions exist in. With our evaluation strongly motivating the\nneed for co-design, we believe that DLAS can be a valuable concept for\nexploring the next generation of co-designed accelerated deep learning\nsolutions.\n",
                "链接": "https://arxiv.org/abs/2311.08909"
            },
            {
                "文章ID": "102164",
                "标题": "Draft & Verify: Lossless Large Language Model Acceleration via\n  Self-Speculative Decoding",
                "作者": " Jun Zhang,  Jue Wang,  Huan Li,  Lidan Shou,  Ke Chen,  Gang Chen,  Sharad Mehrotra",
                "发布日期": "2023-09-18",
                "摘要": "  We present a novel inference scheme, self-speculative decoding, for\naccelerating Large Language Models (LLMs) without the need for an auxiliary\nmodel. This approach is characterized by a two-stage process: drafting and\nverification. The drafting stage generates draft tokens at a slightly lower\nquality but more quickly, which is achieved by selectively skipping certain\nintermediate layers during drafting Subsequently, the verification stage\nemploys the original LLM to validate those draft output tokens in one forward\npass. This process ensures the final output remains identical to that produced\nby the unaltered LLM, thereby maintaining output quality. The proposed method\nrequires no additional neural network training and no extra memory footprint,\nmaking it a plug-and-play and cost-effective solution for inference\nacceleration. Benchmarks with LLaMA-2 and its fine-tuned models demonstrated a\nspeedup up to 1.73$\\times$.\n",
                "链接": "https://arxiv.org/abs/2309.08168"
            }
        ]
    },
    {
        "question": {
            "question": "查找论文中包含指令微调细节描述的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "121379",
                "标题": "PILLOW: Enhancing Efficient Instruction Fine-tuning via Prompt Matching",
                "作者": " Zhenting Qi,  Xiaoyu Tan,  Shaojie Shi,  Chao Qu,  Yinghui Xu,  Yuan Qi",
                "发布日期": "2023-12-12",
                "摘要": "  Instruction fine-tuning has conventionally been employed to adapt Large\nLanguage Models (LLMs) to a variety of tasks. Nonetheless, this technique often\nnecessitates substantial computational resources, making it impractical for\ndeployment by individuals or small-scale entities. Recently, Low-Rank\nAdaptation (LoRA) has become a promising alternative, offering high\ncapabilities on par with full tuning with reduced resource overhead. However,\nattaining satisfactory performance through the fine-tuning of LoRA is a\nnon-trivial challenge. In this paper, we propose PILLOW, which aims to improve\nLoRA's performance by a discrimination-based prompting method, leveraging LLMs'\nIn-Context Learning ability. PILLOW incorporates a matching network that\nselects prompts from a user-defined prompt pool, concatenates the selected\nprompts with the user instruction as input, and performs inference using the\nLoRA-fine-tuned LLMs. Trained with Reinforcement Learning, PILLOW exhibits\ncommensurate performance on various evaluation metrics compared with typical\ninstruction fine-tuning methods, utilizing only consumer-grade GPU resources\nand exhibiting a large reduction in computational costs.\n",
                "链接": "https://arxiv.org/abs/2312.05621"
            },
            {
                "文章ID": "72812",
                "标题": "Visual Instruction Tuning",
                "作者": " Haotian Liu,  Chunyuan Li,  Qingyang Wu,  Yong Jae Lee",
                "发布日期": "2023-12-14",
                "摘要": "  Instruction tuning large language models (LLMs) using machine-generated\ninstruction-following data has improved zero-shot capabilities on new tasks,\nbut the idea is less explored in the multimodal field. In this paper, we\npresent the first attempt to use language-only GPT-4 to generate multimodal\nlanguage-image instruction-following data. By instruction tuning on such\ngenerated data, we introduce LLaVA: Large Language and Vision Assistant, an\nend-to-end trained large multimodal model that connects a vision encoder and\nLLM for general-purpose visual and language understanding.Our early experiments\nshow that LLaVA demonstrates impressive multimodel chat abilities, sometimes\nexhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and\nyields a 85.1% relative score compared with GPT-4 on a synthetic multimodal\ninstruction-following dataset. When fine-tuned on Science QA, the synergy of\nLLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make\nGPT-4 generated visual instruction tuning data, our model and code base\npublicly available.\n",
                "链接": "https://arxiv.org/abs/2304.08485"
            },
            {
                "文章ID": "110607",
                "标题": "CITB: A Benchmark for Continual Instruction Tuning",
                "作者": " Zihan Zhang,  Meng Fang,  Ling Chen,  Mohammad-Reza Namazi-Rad",
                "发布日期": "2023-10-24",
                "摘要": "  Continual learning (CL) is a paradigm that aims to replicate the human\nability to learn and accumulate knowledge continually without forgetting\nprevious knowledge and transferring it to new tasks. Recent instruction tuning\n(IT) involves fine-tuning models to make them more adaptable to solving NLP\ntasks in general. However, it is still uncertain how instruction tuning works\nin the context of CL tasks. This challenging yet practical problem is\nformulated as Continual Instruction Tuning (CIT). In this work, we establish a\nCIT benchmark consisting of learning and evaluation protocols. We curate two\nlong dialogue task streams of different types, InstrDialog and InstrDialog++,\nto study various CL methods systematically. Our experiments show that existing\nCL methods do not effectively leverage the rich natural language instructions,\nand fine-tuning an instruction-tuned model sequentially can yield similar or\nbetter results. We further explore different aspects that might affect the\nlearning of CIT. We hope this benchmark will facilitate more research in this\ndirection.\n",
                "链接": "https://arxiv.org/abs/2310.14510"
            },
            {
                "文章ID": "98124",
                "标题": "InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning MiniGPT-4",
                "作者": " Lai Wei,  Zihao Jiang,  Weiran Huang,  Lichao Sun",
                "发布日期": "2023-10-12",
                "摘要": "  Multimodal large language models are typically trained in two stages: first\npre-training on image-text pairs, and then fine-tuning using supervised\nvision-language instruction data. Recent studies have shown that large language\nmodels can achieve satisfactory results even with a limited amount of\nhigh-quality instruction-following data. In this paper, we introduce\nInstructionGPT-4, which is fine-tuned on a small dataset comprising only 200\nexamples, amounting to approximately 6\\% of the instruction-following data used\nin the alignment dataset for MiniGPT-4. To achieve this, we first propose\nseveral metrics to access the quality of multimodal instruction data. Based on\nthese metrics, we present an effective and trainable data selector to\nautomatically identify and filter low-quality vision-language data. By\nemploying this method, InstructionGPT-4 outperforms the original MiniGPT-4 on\nvarious evaluations. Overall, our findings demonstrate that less but\nhigh-quality instruction tuning data is efficient in enabling multimodal large\nlanguage models to generate better output. Our code is available at\nhttps://github.com/waltonfuture/InstructionGPT-4.\n",
                "链接": "https://arxiv.org/abs/2308.12067"
            },
            {
                "文章ID": "124355",
                "标题": "WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with\n  Refined Data Generation",
                "作者": " Zhaojian Yu,  Xin Zhang,  Ning Shang,  Yangyu Huang,  Can Xu,  Yishujie Zhao,  Wenxiang Hu,  Qiufeng Yin",
                "发布日期": "2023-12-27",
                "摘要": "  Recent work demonstrates that, after being fine-tuned on a high-quality\ninstruction dataset, the resulting model can obtain impressive capabilities to\naddress a wide range of tasks. However, existing methods for instruction data\ngeneration often produce duplicate data and are not controllable enough on data\nquality. In this paper, we extend the generalization of instruction tuning by\nclassifying the instruction data to 4 code-related tasks and propose a\nLLM-based Generator-Discriminator data process framework to generate diverse,\nhigh-quality instruction data from open source code. Hence, we introduce\nCodeOcean, a dataset comprising 20,000 instruction instances across 4 universal\ncode-related tasks,which is aimed at augmenting the effectiveness of\ninstruction tuning and improving the generalization ability of fine-tuned\nmodel. Subsequently, we present WaveCoder, a fine-tuned Code LLM with\nWidespread And Versatile Enhanced instruction tuning. This model is\nspecifically designed for enhancing instruction tuning of Code Language Models\n(LLMs). Our experiments demonstrate that Wavecoder models outperform other\nopen-source models in terms of generalization ability across different\ncode-related tasks at the same level of fine-tuning scale. Moreover, Wavecoder\nexhibits high efficiency in previous code generation tasks. This paper thus\noffers a significant contribution to the field of instruction data generation\nand fine-tuning models, providing new insights and tools for enhancing\nperformance in code-related tasks.\n",
                "链接": "https://arxiv.org/abs/2312.14187"
            },
            {
                "文章ID": "122973",
                "标题": "Osprey: Pixel Understanding with Visual Instruction Tuning",
                "作者": " Yuqian Yuan,  Wentong Li,  Jian Liu,  Dongqi Tang,  Xinjie Luo,  Chi Qin,  Lei Zhang,  Jianke Zhu",
                "发布日期": "2023-12-27",
                "摘要": "  Multimodal large language models (MLLMs) have recently achieved impressive\ngeneral-purpose vision-language capabilities through visual instruction tuning.\nHowever, current MLLMs primarily focus on image-level or box-level\nunderstanding, falling short of achieving fine-grained vision-language\nalignment at the pixel level. Besides, the lack of mask-based instruction data\nlimits their advancements. In this paper, we propose Osprey, a mask-text\ninstruction tuning approach, to extend MLLMs by incorporating fine-grained mask\nregions into language instruction, aiming at achieving pixel-wise visual\nunderstanding. To achieve this goal, we first meticulously curate a mask-based\nregion-text dataset with 724K samples, and then design a vision-language model\nby injecting pixel-level representation into LLM. Especially, Osprey adopts a\nconvolutional CLIP backbone as the vision encoder and employs a mask-aware\nvisual extractor to extract precise visual mask features from high resolution\ninput. Experimental results demonstrate Osprey's superiority in various region\nunderstanding tasks, showcasing its new capability for pixel-level instruction\ntuning. In particular, Osprey can be integrated with Segment Anything Model\n(SAM) seamlessly to obtain multi-granularity semantics. The source code,\ndataset and demo can be found at https://github.com/CircleRadon/Osprey.\n",
                "链接": "https://arxiv.org/abs/2312.10032"
            },
            {
                "文章ID": "123289",
                "标题": "Understanding the Instruction Mixture for Large Language Model\n  Fine-tuning",
                "作者": " Renxi Wang,  Minghao Wu,  Yuxia Wang,  Xudong Han,  Chiyu Zhang,  Haonan Li",
                "发布日期": "2023-12-20",
                "摘要": "  While instructions fine-tuning of large language models (LLMs) has been\nproven to enhance performance across various applications, the influence of the\ninstruction dataset mixture on LLMs has not been thoroughly explored. In this\nstudy, we classify instructions into three main types: NLP downstream tasks,\ncoding, and general chatting, and investigate their impact on LLMs. Our\nfindings reveal that specific types of instructions are more beneficial for\nparticular uses, while it may cause harms to other aspects, emphasizing the\nimportance of meticulously designing the instruction mixture to maximize model\nperformance. This study sheds light on the instruction mixture and paves the\nway for future research.\n",
                "链接": "https://arxiv.org/abs/2312.10793"
            },
            {
                "文章ID": "93561",
                "标题": "Exploring Format Consistency for Instruction Tuning",
                "作者": " Shihao Liang,  Kunlun Zhu,  Runchu Tian,  Yujia Qin,  Huadong Wang,  Xin Cong,  Zhiyuan Liu,  Xiaojiang Liu,  Maosong Sun",
                "发布日期": "2023-07-31",
                "摘要": "  Instruction tuning has emerged as a promising approach to enhancing large\nlanguage models in following human instructions. It is shown that increasing\nthe diversity and number of instructions in the training data can consistently\nenhance generalization performance, which facilitates a recent endeavor to\ncollect various instructions and integrate existing instruction tuning datasets\ninto larger collections. However, different users have their unique ways of\nexpressing instructions, and there often exist variations across different\ndatasets in the instruction styles and formats, i.e., format inconsistency. In\nthis work, we study how format inconsistency may impact the performance of\ninstruction tuning. We propose a framework called \"Unified Instruction Tuning\"\n(UIT), which calls OpenAI APIs for automatic format transfer among different\ninstruction tuning datasets. We show that UIT successfully improves the\ngeneralization performance on unseen instructions, which highlights the\nimportance of format consistency for instruction tuning. To make the UIT\nframework more practical, we further propose a novel perplexity-based denoising\nmethod to reduce the noise of automatic format transfer. We also train a\nsmaller offline model that achieves comparable format transfer capability than\nOpenAI APIs to reduce costs in practice.\n",
                "链接": "https://arxiv.org/abs/2307.15504"
            },
            {
                "文章ID": "108778",
                "标题": "Instruction Tuning with Human Curriculum",
                "作者": " Bruce W. Lee,  Hyunsoo Cho,  Kang Min Yoo",
                "发布日期": "2023-10-17",
                "摘要": "  The dominant paradigm for instruction tuning is the random-shuffled training\nof maximally diverse instruction-response pairs. This paper explores the\npotential benefits of applying a structured cognitive learning approach to\ninstruction tuning in contemporary large language models like ChatGPT and\nGPT-4. Unlike the previous conventional randomized instruction dataset, we\npropose a highly structured synthetic dataset that mimics the progressive and\norganized nature of human education. We curate our dataset by aligning it with\neducational frameworks, incorporating meta information including its topic and\ncognitive rigor level for each sample. Our dataset covers comprehensive\nfine-grained topics spanning diverse educational stages (from middle school to\ngraduate school) with various questions for each topic to enhance conceptual\ndepth using Bloom's taxonomy-a classification framework distinguishing various\nlevels of human cognition for each concept. The results demonstrate that this\ncognitive rigorous training approach yields significant performance\nenhancements - +3.06 on the MMLU benchmark and an additional +1.28 on AI2\nReasoning Challenge (hard set) - compared to conventional randomized training,\nall while avoiding additional computational costs. This research highlights the\npotential of leveraging human learning principles to enhance the capabilities\nof language models in comprehending and responding to complex instructions and\ntasks.\n",
                "链接": "https://arxiv.org/abs/2310.09518"
            },
            {
                "文章ID": "105449",
                "标题": "From Language Modeling to Instruction Following: Understanding the\n  Behavior Shift in LLMs after Instruction Tuning",
                "作者": " Xuansheng Wu,  Wenlin Yao,  Jianshu Chen,  Xiaoman Pan,  Xiaoyang Wang,  Ninghao Liu,  Dong Yu",
                "发布日期": "2023-10-03",
                "摘要": "  Large Language Models (LLMs) have achieved remarkable success, demonstrating\npowerful instruction-following capabilities across diverse tasks. Instruction\nfine-tuning is critical in enabling LLMs to align with user intentions and\neffectively follow instructions. In this work, we investigate how instruction\nfine-tuning modifies pre-trained models, focusing on two perspectives:\ninstruction recognition and knowledge evolution. To study the behavior shift of\nLLMs, we employ a suite of local and global explanation methods, including a\ngradient-based approach for input-output attribution and techniques for\ninterpreting patterns and concepts in self-attention and feed-forward layers.\nOur findings reveal three significant impacts of instruction fine-tuning: 1) It\nempowers LLMs to better recognize the instruction parts from user prompts,\nthereby facilitating high-quality response generation and addressing the\n``lost-in-the-middle'' issue observed in pre-trained models; 2) It aligns the\nknowledge stored in feed-forward layers with user-oriented tasks, exhibiting\nminimal shifts across linguistic levels. 3) It facilitates the learning of\nword-word relations with instruction verbs through the self-attention\nmechanism, particularly in the lower and middle layers, indicating enhanced\nrecognition of instruction words. These insights contribute to a deeper\nunderstanding of the behavior shifts in LLMs after instruction fine-tuning and\nlay the groundwork for future research aimed at interpreting and optimizing\nLLMs for various applications. We will release our code and data soon.\n",
                "链接": "https://arxiv.org/abs/2310.00492"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本检测最新进展",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "53136",
                "标题": "Extending TrOCR for Text Localization-Free OCR of Full-Page Scanned\n  Receipt Images",
                "作者": " Hongkuan Zhang,  Edward Whittaker,  Ikuo Kitagishi",
                "发布日期": "2023-10-17",
                "摘要": "  Digitization of scanned receipts aims to extract text from receipt images and\nsave it into structured documents. This is usually split into two sub-tasks:\ntext localization and optical character recognition (OCR). Most existing OCR\nmodels only focus on the cropped text instance images, which require the\nbounding box information provided by a text region detection model. Introducing\nan additional detector to identify the text instance images in advance adds\ncomplexity, however instance-level OCR models have very low accuracy when\nprocessing the whole image for the document-level OCR, such as receipt images\ncontaining multiple text lines arranged in various layouts. To this end, we\npropose a localization-free document-level OCR model for transcribing all the\ncharacters in a receipt image into an ordered sequence end-to-end.\nSpecifically, we finetune the pretrained instance-level model TrOCR with\nrandomly cropped image chunks, and gradually increase the image chunk size to\ngeneralize the recognition ability from instance images to full-page images. In\nour experiments on the SROIE receipt OCR dataset, the model finetuned with our\nstrategy achieved 64.4 F1-score and a 22.8% character error rate (CER),\nrespectively, which outperforms the baseline results with 48.5 F1-score and\n50.6% CER. The best model, which splits the full image into 15 equally sized\nchunks, gives 87.8 F1-score and 4.98% CER with minimal additional pre or\npost-processing of the output. Moreover, the characters in the generated\ndocument-level sequences are arranged in the reading order, which is practical\nfor real-world applications.\n",
                "链接": "https://arxiv.org/abs/2212.05525"
            },
            {
                "文章ID": "98478",
                "标题": "DISGO: Automatic End-to-End Evaluation for Scene Text OCR",
                "作者": " Mei-Yuh Hwang,  Yangyang Shi,  Ankit Ramchandani,  Guan Pang,  Praveen Krishnan,  Lucas Kabela,  Frank Seide,  Samyak Datta,  Jun Liu",
                "发布日期": "2023-08-28",
                "摘要": "  This paper discusses the challenges of optical character recognition (OCR) on\nnatural scenes, which is harder than OCR on documents due to the wild content\nand various image backgrounds. We propose to uniformly use word error rates\n(WER) as a new measurement for evaluating scene-text OCR, both end-to-end (e2e)\nperformance and individual system component performances. Particularly for the\ne2e metric, we name it DISGO WER as it considers Deletion, Insertion,\nSubstitution, and Grouping/Ordering errors. Finally we propose to utilize the\nconcept of super blocks to automatically compute BLEU scores for e2e OCR\nmachine translation. The small SCUT public test set is used to demonstrate WER\nperformance by a modularized OCR system.\n",
                "链接": "https://arxiv.org/abs/2308.13173"
            },
            {
                "文章ID": "94665",
                "标题": "Universal Defensive Underpainting Patch: Making Your Text Invisible to\n  Optical Character Recognition",
                "作者": " JiaCheng Deng,  Li Dong,  Jiahao Chen,  Diqun Yan,  Rangding Wang,  Dengpan Ye,  Lingchen Zhao,  Jinyu Tian",
                "发布日期": "2023-08-07",
                "摘要": "  Optical Character Recognition (OCR) enables automatic text extraction from\nscanned or digitized text images, but it also makes it easy to pirate valuable\nor sensitive text from these images. Previous methods to prevent OCR piracy by\ndistorting characters in text images are impractical in real-world scenarios,\nas pirates can capture arbitrary portions of the text images, rendering the\ndefenses ineffective. In this work, we propose a novel and effective defense\nmechanism termed the Universal Defensive Underpainting Patch (UDUP) that\nmodifies the underpainting of text images instead of the characters. UDUP is\ncreated through an iterative optimization process to craft a small, fixed-size\ndefensive patch that can generate non-overlapping underpainting for text images\nof any size. Experimental results show that UDUP effectively defends against\nunauthorized OCR under the setting of any screenshot range or complex image\nbackground. It is agnostic to the content, size, colors, and languages of\ncharacters, and is robust to typical image operations such as scaling and\ncompressing. In addition, the transferability of UDUP is demonstrated by\nevading several off-the-shelf OCRs. The code is available at\nhttps://github.com/QRICKDD/UDUP.\n",
                "链接": "https://arxiv.org/abs/2308.02369"
            },
            {
                "文章ID": "43946",
                "标题": "OCR-VQGAN: Taming Text-within-Image Generation",
                "作者": " Juan A. Rodriguez,  David Vazquez,  Issam Laradji,  Marco Pedersoli,  Pau Rodriguez",
                "发布日期": "2022-10-26",
                "摘要": "  Synthetic image generation has recently experienced significant improvements\nin domains such as natural image or art generation. However, the problem of\nfigure and diagram generation remains unexplored. A challenging aspect of\ngenerating figures and diagrams is effectively rendering readable texts within\nthe images. To alleviate this problem, we present OCR-VQGAN, an image encoder,\nand decoder that leverages OCR pre-trained features to optimize a text\nperceptual loss, encouraging the architecture to preserve high-fidelity text\nand diagram structure. To explore our approach, we introduce the Paper2Fig100k\ndataset, with over 100k images of figures and texts from research papers. The\nfigures show architecture diagrams and methodologies of articles available at\narXiv.org from fields like artificial intelligence and computer vision. Figures\nusually include text and discrete objects, e.g., boxes in a diagram, with lines\nand arrows that connect them. We demonstrate the effectiveness of OCR-VQGAN by\nconducting several experiments on the task of figure reconstruction.\nAdditionally, we explore the qualitative and quantitative impact of weighting\ndifferent perceptual metrics in the overall loss function. We release code,\nmodels, and dataset at https://github.com/joanrod/ocr-vqgan.\n",
                "链接": "https://arxiv.org/abs/2210.11248"
            },
            {
                "文章ID": "55598",
                "标题": "A Comprehensive Gold Standard and Benchmark for Comics Text Detection\n  and Recognition",
                "作者": " Gürkan Soykan,  Deniz Yuret,  Tevfik Metin Sezgin",
                "发布日期": "2023-01-02",
                "摘要": "  This study focuses on improving the optical character recognition (OCR) data\nfor panels in the COMICS dataset, the largest dataset containing text and\nimages from comic books. To do this, we developed a pipeline for OCR processing\nand labeling of comic books and created the first text detection and\nrecognition datasets for western comics, called \"COMICS Text+: Detection\" and\n\"COMICS Text+: Recognition\". We evaluated the performance of state-of-the-art\ntext detection and recognition models on these datasets and found significant\nimprovement in word accuracy and normalized edit distance compared to the text\nin COMICS. We also created a new dataset called \"COMICS Text+\", which contains\nthe extracted text from the textboxes in the COMICS dataset. Using the improved\ntext data of COMICS Text+ in the comics processing model from resulted in\nstate-of-the-art performance on cloze-style tasks without changing the model\narchitecture. The COMICS Text+ dataset can be a valuable resource for\nresearchers working on tasks including text detection, recognition, and\nhigh-level processing of comics, such as narrative understanding, character\nrelations, and story generation. All the data and inference instructions can be\naccessed in https://github.com/gsoykan/comics_text_plus.\n",
                "链接": "https://arxiv.org/abs/2212.14674"
            },
            {
                "文章ID": "19555",
                "标题": "Detection Masking for Improved OCR on Noisy Documents",
                "作者": " Daniel Rotman,  Ophir Azulai,  Inbar Shapira,  Yevgeny Burshtein,  Udi Barzelay",
                "发布日期": "2022-05-18",
                "摘要": "  Optical Character Recognition (OCR), the task of extracting textual\ninformation from scanned documents is a vital and broadly used technology for\ndigitizing and indexing physical documents. Existing technologies perform well\nfor clean documents, but when the document is visually degraded, or when there\nare non-textual elements, OCR quality can be greatly impacted, specifically due\nto erroneous detections. In this paper we present an improved detection network\nwith a masking system to improve the quality of OCR performed on documents. By\nfiltering non-textual elements from the image we can utilize document-level OCR\nto incorporate contextual information to improve OCR results. We perform a\nunified evaluation on a publicly available dataset demonstrating the usefulness\nand broad applicability of our method. Additionally, we present and make\npublicly available our synthetic dataset with a unique hard-negative component\nspecifically tuned to improve detection results, and evaluate the benefits that\ncan be gained from its usage\n",
                "链接": "https://arxiv.org/abs/2205.08257"
            },
            {
                "文章ID": "11473",
                "标题": "Towards Escaping from Language Bias and OCR Error: Semantics-Centered\n  Text Visual Question Answering",
                "作者": " Chengyang Fang,  Gangyan Zeng,  Yu Zhou,  Daiqing Wu,  Can Ma,  Dayong Hu,  Weiping Wang",
                "发布日期": "2023-09-06",
                "摘要": "  Texts in scene images convey critical information for scene understanding and\nreasoning. The abilities of reading and reasoning matter for the model in the\ntext-based visual question answering (TextVQA) process. However, current\nTextVQA models do not center on the text and suffer from several limitations.\nThe model is easily dominated by language biases and optical character\nrecognition (OCR) errors due to the absence of semantic guidance in the answer\nprediction process. In this paper, we propose a novel Semantics-Centered\nNetwork (SC-Net) that consists of an instance-level contrastive semantic\nprediction module (ICSP) and a semantics-centered transformer module (SCT).\nEquipped with the two modules, the semantics-centered model can resist the\nlanguage biases and the accumulated errors from OCR. Extensive experiments on\nTextVQA and ST-VQA datasets show the effectiveness of our model. SC-Net\nsurpasses previous works with a noticeable margin and is more reasonable for\nthe TextVQA task.\n",
                "链接": "https://arxiv.org/abs/2203.12929"
            },
            {
                "文章ID": "120332",
                "标题": "UPOCR: Towards Unified Pixel-Level OCR Interface",
                "作者": " Dezhi Peng,  Zhenhua Yang,  Jiaxin Zhang,  Chongyu Liu,  Yongxin Shi,  Kai Ding,  Fengjun Guo,  Lianwen Jin",
                "发布日期": "2023-12-06",
                "摘要": "  In recent years, the optical character recognition (OCR) field has been\nproliferating with plentiful cutting-edge approaches for a wide spectrum of\ntasks. However, these approaches are task-specifically designed with divergent\nparadigms, architectures, and training strategies, which significantly\nincreases the complexity of research and maintenance and hinders the fast\ndeployment in applications. To this end, we propose UPOCR, a\nsimple-yet-effective generalist model for Unified Pixel-level OCR interface.\nSpecifically, the UPOCR unifies the paradigm of diverse OCR tasks as\nimage-to-image transformation and the architecture as a vision Transformer\n(ViT)-based encoder-decoder. Learnable task prompts are introduced to push the\ngeneral feature representations extracted by the encoder toward task-specific\nspaces, endowing the decoder with task awareness. Moreover, the model training\nis uniformly aimed at minimizing the discrepancy between the generated and\nground-truth images regardless of the inhomogeneity among tasks. Experiments\nare conducted on three pixel-level OCR tasks including text removal, text\nsegmentation, and tampered text detection. Without bells and whistles, the\nexperimental results showcase that the proposed method can simultaneously\nachieve state-of-the-art performance on three tasks with a unified single\nmodel, which provides valuable strategies and insights for future research on\ngeneralist OCR models. Code will be publicly available.\n",
                "链接": "https://arxiv.org/abs/2312.02694"
            },
            {
                "文章ID": "23778",
                "标题": "Transformer based Urdu Handwritten Text Optical Character Reader",
                "作者": " Mohammad Daniyal Shaiq,  Musa Dildar Ahmed Cheema,  Ali Kamal",
                "发布日期": "2022-06-10",
                "摘要": "  Extracting Handwritten text is one of the most important components of\ndigitizing information and making it available for large scale setting.\nHandwriting Optical Character Reader (OCR) is a research problem in computer\nvision and natural language processing computing, and a lot of work has been\ndone for English, but unfortunately, very little work has been done for low\nresourced languages such as Urdu. Urdu language script is very difficult\nbecause of its cursive nature and change of shape of characters based on it's\nrelative position, therefore, a need arises to propose a model which can\nunderstand complex features and generalize it for every kind of handwriting\nstyle. In this work, we propose a transformer based Urdu Handwritten text\nextraction model. As transformers have been very successful in Natural Language\nUnderstanding task, we explore them further to understand complex Urdu\nHandwriting.\n",
                "链接": "https://arxiv.org/abs/2206.04575"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本识别最新进展。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "97589",
                "标题": "bbOCR: An Open-source Multi-domain OCR Pipeline for Bengali Documents",
                "作者": " Imam Mohammad Zulkarnain,  Shayekh Bin Islam,  Md. Zami Al Zunaed Farabe,  Md. Mehedi Hasan Shawon,  Jawaril Munshad Abedin,  Beig Rajibul Hasan,  Marsia Haque,  Istiak Shihab,  Syed Mobassir,  MD. Nazmuddoha Ansary,  Asif Sushmit,  Farig Sadeque",
                "发布日期": "2023-08-23",
                "摘要": "  Despite the existence of numerous Optical Character Recognition (OCR) tools,\nthe lack of comprehensive open-source systems hampers the progress of document\ndigitization in various low-resource languages, including Bengali. Low-resource\nlanguages, especially those with an alphasyllabary writing system, suffer from\nthe lack of large-scale datasets for various document OCR components such as\nword-level OCR, document layout extraction, and distortion correction; which\nare available as individual modules in high-resource languages. In this paper,\nwe introduce Bengali$.$AI-BRACU-OCR (bbOCR): an open-source scalable document\nOCR system that can reconstruct Bengali documents into a structured searchable\ndigitized format that leverages a novel Bengali text recognition model and two\nnovel synthetic datasets. We present extensive component-level and system-level\nevaluation: both use a novel diversified evaluation dataset and comprehensive\nevaluation metrics. Our extensive evaluation suggests that our proposed\nsolution is preferable over the current state-of-the-art Bengali OCR systems.\nThe source codes and datasets are available here:\nhttps://bengaliai.github.io/bbocr.\n",
                "链接": "https://arxiv.org/abs/2308.10647"
            },
            {
                "文章ID": "98478",
                "标题": "DISGO: Automatic End-to-End Evaluation for Scene Text OCR",
                "作者": " Mei-Yuh Hwang,  Yangyang Shi,  Ankit Ramchandani,  Guan Pang,  Praveen Krishnan,  Lucas Kabela,  Frank Seide,  Samyak Datta,  Jun Liu",
                "发布日期": "2023-08-28",
                "摘要": "  This paper discusses the challenges of optical character recognition (OCR) on\nnatural scenes, which is harder than OCR on documents due to the wild content\nand various image backgrounds. We propose to uniformly use word error rates\n(WER) as a new measurement for evaluating scene-text OCR, both end-to-end (e2e)\nperformance and individual system component performances. Particularly for the\ne2e metric, we name it DISGO WER as it considers Deletion, Insertion,\nSubstitution, and Grouping/Ordering errors. Finally we propose to utilize the\nconcept of super blocks to automatically compute BLEU scores for e2e OCR\nmachine translation. The small SCUT public test set is used to demonstrate WER\nperformance by a modularized OCR system.\n",
                "链接": "https://arxiv.org/abs/2308.13173"
            },
            {
                "文章ID": "53136",
                "标题": "Extending TrOCR for Text Localization-Free OCR of Full-Page Scanned\n  Receipt Images",
                "作者": " Hongkuan Zhang,  Edward Whittaker,  Ikuo Kitagishi",
                "发布日期": "2023-10-17",
                "摘要": "  Digitization of scanned receipts aims to extract text from receipt images and\nsave it into structured documents. This is usually split into two sub-tasks:\ntext localization and optical character recognition (OCR). Most existing OCR\nmodels only focus on the cropped text instance images, which require the\nbounding box information provided by a text region detection model. Introducing\nan additional detector to identify the text instance images in advance adds\ncomplexity, however instance-level OCR models have very low accuracy when\nprocessing the whole image for the document-level OCR, such as receipt images\ncontaining multiple text lines arranged in various layouts. To this end, we\npropose a localization-free document-level OCR model for transcribing all the\ncharacters in a receipt image into an ordered sequence end-to-end.\nSpecifically, we finetune the pretrained instance-level model TrOCR with\nrandomly cropped image chunks, and gradually increase the image chunk size to\ngeneralize the recognition ability from instance images to full-page images. In\nour experiments on the SROIE receipt OCR dataset, the model finetuned with our\nstrategy achieved 64.4 F1-score and a 22.8% character error rate (CER),\nrespectively, which outperforms the baseline results with 48.5 F1-score and\n50.6% CER. The best model, which splits the full image into 15 equally sized\nchunks, gives 87.8 F1-score and 4.98% CER with minimal additional pre or\npost-processing of the output. Moreover, the characters in the generated\ndocument-level sequences are arranged in the reading order, which is practical\nfor real-world applications.\n",
                "链接": "https://arxiv.org/abs/2212.05525"
            },
            {
                "文章ID": "54214",
                "标题": "Transferring General Multimodal Pretrained Models to Text Recognition",
                "作者": " Junyang Lin,  Xuancheng Ren,  Yichang Zhang,  Gao Liu,  Peng Wang,  An Yang,  Chang Zhou",
                "发布日期": "2022-12-20",
                "摘要": "  This paper proposes a new method, OFA-OCR, to transfer multimodal pretrained\nmodels to text recognition. Specifically, we recast text recognition as image\ncaptioning and directly transfer a unified vision-language pretrained model to\nthe end task. Without pretraining on large-scale annotated or synthetic text\nrecognition data, OFA-OCR outperforms the baselines and achieves\nstate-of-the-art performance in the Chinese text recognition benchmark.\nAdditionally, we construct an OCR pipeline with OFA-OCR, and we demonstrate\nthat it can achieve competitive performance with the product-level API. The\ncode (https://github.com/OFA-Sys/OFA) and demo\n(https://modelscope.cn/studios/damo/ofa_ocr_pipeline/summary) are publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2212.09297"
            },
            {
                "文章ID": "111490",
                "标题": "Exploring OCR Capabilities of GPT-4V(ision) : A Quantitative and\n  In-depth Evaluation",
                "作者": " Yongxin Shi,  Dezhi Peng,  Wenhui Liao,  Zening Lin,  Xinhong Chen,  Chongyu Liu,  Yuyi Zhang,  Lianwen Jin",
                "发布日期": "2023-10-31",
                "摘要": "  This paper presents a comprehensive evaluation of the Optical Character\nRecognition (OCR) capabilities of the recently released GPT-4V(ision), a Large\nMultimodal Model (LMM). We assess the model's performance across a range of OCR\ntasks, including scene text recognition, handwritten text recognition,\nhandwritten mathematical expression recognition, table structure recognition,\nand information extraction from visually-rich document. The evaluation reveals\nthat GPT-4V performs well in recognizing and understanding Latin contents, but\nstruggles with multilingual scenarios and complex tasks. Specifically, it\nshowed limitations when dealing with non-Latin languages and complex tasks such\nas handwriting mathematical expression recognition, table structure\nrecognition, and end-to-end semantic entity recognition and pair extraction\nfrom document image. Based on these observations, we affirm the necessity and\ncontinued research value of specialized OCR models. In general, despite its\nversatility in handling diverse OCR tasks, GPT-4V does not outperform existing\nstate-of-the-art OCR models. How to fully utilize pre-trained general-purpose\nLMMs such as GPT-4V for OCR downstream tasks remains an open problem. The study\noffers a critical reference for future research in OCR with LMMs. Evaluation\npipeline and results are available at\nhttps://github.com/SCUT-DLVCLab/GPT-4V_OCR.\n",
                "链接": "https://arxiv.org/abs/2310.16809"
            },
            {
                "文章ID": "43946",
                "标题": "OCR-VQGAN: Taming Text-within-Image Generation",
                "作者": " Juan A. Rodriguez,  David Vazquez,  Issam Laradji,  Marco Pedersoli,  Pau Rodriguez",
                "发布日期": "2022-10-26",
                "摘要": "  Synthetic image generation has recently experienced significant improvements\nin domains such as natural image or art generation. However, the problem of\nfigure and diagram generation remains unexplored. A challenging aspect of\ngenerating figures and diagrams is effectively rendering readable texts within\nthe images. To alleviate this problem, we present OCR-VQGAN, an image encoder,\nand decoder that leverages OCR pre-trained features to optimize a text\nperceptual loss, encouraging the architecture to preserve high-fidelity text\nand diagram structure. To explore our approach, we introduce the Paper2Fig100k\ndataset, with over 100k images of figures and texts from research papers. The\nfigures show architecture diagrams and methodologies of articles available at\narXiv.org from fields like artificial intelligence and computer vision. Figures\nusually include text and discrete objects, e.g., boxes in a diagram, with lines\nand arrows that connect them. We demonstrate the effectiveness of OCR-VQGAN by\nconducting several experiments on the task of figure reconstruction.\nAdditionally, we explore the qualitative and quantitative impact of weighting\ndifferent perceptual metrics in the overall loss function. We release code,\nmodels, and dataset at https://github.com/joanrod/ocr-vqgan.\n",
                "链接": "https://arxiv.org/abs/2210.11248"
            },
            {
                "文章ID": "36484",
                "标题": "Levenshtein OCR",
                "作者": " Cheng Da,  Peng Wang,  Cong Yao",
                "发布日期": "2022-11-15",
                "摘要": "  A novel scene text recognizer based on Vision-Language Transformer (VLT) is\npresented. Inspired by Levenshtein Transformer in the area of NLP, the proposed\nmethod (named Levenshtein OCR, and LevOCR for short) explores an alternative\nway for automatically transcribing textual content from cropped natural images.\nSpecifically, we cast the problem of scene text recognition as an iterative\nsequence refinement process. The initial prediction sequence produced by a pure\nvision model is encoded and fed into a cross-modal transformer to interact and\nfuse with the visual features, to progressively approximate the ground truth.\nThe refinement process is accomplished via two basic character-level\noperations: deletion and insertion, which are learned with imitation learning\nand allow for parallel decoding, dynamic length change and good\ninterpretability. The quantitative experiments clearly demonstrate that LevOCR\nachieves state-of-the-art performances on standard benchmarks and the\nqualitative analyses verify the effectiveness and advantage of the proposed\nLevOCR algorithm. Code is available at\nhttps://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/LevOCR.\n",
                "链接": "https://arxiv.org/abs/2209.03594"
            },
            {
                "文章ID": "90438",
                "标题": "Handwritten Text Recognition Using Convolutional Neural Network",
                "作者": " Atman Mishra,  A. Sharath Ram,  Kavyashree C",
                "发布日期": "2023-07-12",
                "摘要": "  OCR (Optical Character Recognition) is a technology that offers comprehensive\nalphanumeric recognition of handwritten and printed characters at electronic\nspeed by merely scanning the document. Recently, the understanding of visual\ndata has been termed Intelligent Character Recognition (ICR). Intelligent\nCharacter Recognition (ICR) is the OCR module that can convert scans of\nhandwritten or printed characters into ASCII text. ASCII data is the standard\nformat for data encoding in electronic communication. ASCII assigns standard\nnumeric values to letters, numeral, symbols, white-spaces and other characters.\nIn more technical terms, OCR is the process of using an electronic device to\ntransform 2-Dimensional textual information into machine-encoded text. Anything\nthat contains text both machine written or handwritten can be scanned either\nthrough a scanner or just simply a picture of the text is enough for the\nrecognition system to distinguish the text. The goal of this papers is to show\nthe results of a Convolutional Neural Network model which has been trained on\nNational Institute of Science and Technology (NIST) dataset containing over a\n100,000 images. The network learns from the features extracted from the images\nand use it to generate the probability of each class to which the picture\nbelongs to. We have achieved an accuracy of 90.54% with a loss of 2.53%.\n",
                "链接": "https://arxiv.org/abs/2307.05396"
            },
            {
                "文章ID": "23281",
                "标题": "PP-OCRv3: More Attempts for the Improvement of Ultra Lightweight OCR\n  System",
                "作者": " Chenxia Li,  Weiwei Liu,  Ruoyu Guo,  Xiaoting Yin,  Kaitao Jiang,  Yongkun Du,  Yuning Du,  Lingfeng Zhu,  Baohua Lai,  Xiaoguang Hu,  Dianhai Yu,  Yanjun Ma",
                "发布日期": "2022-06-15",
                "摘要": "  Optical character recognition (OCR) technology has been widely used in\nvarious scenes, as shown in Figure 1. Designing a practical OCR system is still\na meaningful but challenging task. In previous work, considering the efficiency\nand accuracy, we proposed a practical ultra lightweight OCR system (PP-OCR),\nand an optimized version PP-OCRv2. In order to further improve the performance\nof PP-OCRv2, a more robust OCR system PP-OCRv3 is proposed in this paper.\nPP-OCRv3 upgrades the text detection model and text recognition model in 9\naspects based on PP-OCRv2. For text detector, we introduce a PAN module with\nlarge receptive field named LK-PAN, a FPN module with residual attention\nmechanism named RSE-FPN, and DML distillation strategy. For text recognizer,\nthe base model is replaced from CRNN to SVTR, and we introduce lightweight text\nrecognition network SVTR LCNet, guided training of CTC by attention, data\naugmentation strategy TextConAug, better pre-trained model by self-supervised\nTextRotNet, UDML, and UIM to accelerate the model and improve the effect.\nExperiments on real data show that the hmean of PP-OCRv3 is 5% higher than\nPP-OCRv2 under comparable inference speed. All the above mentioned models are\nopen-sourced and the code is available in the GitHub repository PaddleOCR which\nis powered by PaddlePaddle.\n",
                "链接": "https://arxiv.org/abs/2206.03001"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月agent系列决策文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105972",
                "标题": "AutoCast++: Enhancing World Event Prediction with Zero-shot\n  Ranking-based Context Retrieval",
                "作者": " Qi Yan,  Raihan Seraj,  Jiawei He,  Lili Meng,  Tristan Sylvain",
                "发布日期": "2023-10-04",
                "摘要": "  Machine-based prediction of real-world events is garnering attention due to\nits potential for informed decision-making. Whereas traditional forecasting\npredominantly hinges on structured data like time-series, recent breakthroughs\nin language models enable predictions using unstructured text. In particular,\n(Zou et al., 2022) unveils AutoCast, a new benchmark that employs news articles\nfor answering forecasting queries. Nevertheless, existing methods still trail\nbehind human performance. The cornerstone of accurate forecasting, we argue,\nlies in identifying a concise, yet rich subset of news snippets from a vast\ncorpus. With this motivation, we introduce AutoCast++, a zero-shot\nranking-based context retrieval system, tailored to sift through expansive news\ndocument collections for event forecasting. Our approach first re-ranks\narticles based on zero-shot question-passage relevance, honing in on\nsemantically pertinent news. Following this, the chosen articles are subjected\nto zero-shot summarization to attain succinct context. Leveraging a pre-trained\nlanguage model, we conduct both the relevance evaluation and article\nsummarization without needing domain-specific training. Notably, recent\narticles can sometimes be at odds with preceding ones due to new facts or\nunanticipated incidents, leading to fluctuating temporal dynamics. To tackle\nthis, our re-ranking mechanism gives preference to more recent articles, and we\nfurther regularize the multi-passage representation learning to align with\nhuman forecaster responses made on different dates. Empirical results\nunderscore marked improvements across multiple metrics, improving the\nperformance for multiple-choice questions (MCQ) by 48% and true/false (TF)\nquestions by up to 8%.\n",
                "链接": "https://arxiv.org/abs/2310.01880"
            },
            {
                "文章ID": "113579",
                "标题": "Agent-based Modelling of Credit Card Promotions",
                "作者": " Conor B. Hamill,  Raad Khraishi,  Simona Gherghel,  Jerrard Lawrence,  Salvatore Mercuri,  Ramin Okhrati,  Greig A. Cowan",
                "发布日期": "2023-11-27",
                "摘要": "  Interest-free promotions are a prevalent strategy employed by credit card\nlenders to attract new customers, yet the research exploring their effects on\nboth consumers and lenders remains relatively sparse. The process of selecting\nan optimal promotion strategy is intricate, involving the determination of an\ninterest-free period duration and promotion-availability window, all within the\ncontext of competing offers, fluctuating market dynamics, and complex consumer\nbehaviour. In this paper, we introduce an agent-based model that facilitates\nthe exploration of various credit card promotions under diverse market\nscenarios. Our approach, distinct from previous agent-based models,\nconcentrates on optimising promotion strategies and is calibrated using\nbenchmarks from the UK credit card market from 2019 to 2020, with agent\nproperties derived from historical distributions of the UK population from\nroughly the same period. We validate our model against stylised facts and\ntime-series data, thereby demonstrating the value of this technique for\ninvestigating pricing strategies and understanding credit card customer\nbehaviour. Our experiments reveal that, in the absence of competitor\npromotions, lender profit is maximised by an interest-free duration of\napproximately 12 months while market share is maximised by offering the longest\nduration possible. When competitors do not offer promotions, extended promotion\navailability windows yield maximum profit for lenders while also maximising\nmarket share. In the context of concurrent interest-free promotions, we\nidentify that the optimal lender strategy entails offering a more competitive\ninterest-free period and a rapid response to competing promotional offers.\nNotably, a delay of three months in responding to a rival promotion corresponds\nto a 2.4% relative decline in income.\n",
                "链接": "https://arxiv.org/abs/2311.01901"
            },
            {
                "文章ID": "33814",
                "标题": "A Framework for Understanding and Visualizing Strategies of RL Agents",
                "作者": " Pedro Sequeira,  Daniel Elenius,  Jesse Hostetler,  Melinda Gervasio",
                "发布日期": "2022-08-19",
                "摘要": "  Recent years have seen significant advances in explainable AI as the need to\nunderstand deep learning models has gained importance with the increased\nemphasis on trust and ethics in AI. Comprehensible models for sequential\ndecision tasks are a particular challenge as they require understanding not\nonly individual predictions but a series of predictions that interact with\nenvironmental dynamics. We present a framework for learning comprehensible\nmodels of sequential decision tasks in which agent strategies are characterized\nusing temporal logic formulas. Given a set of agent traces, we first cluster\nthe traces using a novel embedding method that captures frequent action\npatterns. We then search for logical formulas that explain the agent strategies\nin the different clusters. We evaluate our framework on combat scenarios in\nStarCraft II (SC2), using traces from a handcrafted expert policy and a trained\nreinforcement learning agent. We implemented a feature extractor for SC2\nenvironments that extracts traces as sequences of high-level features\ndescribing both the state of the environment and the agent's local behavior\nfrom agent replays. We further designed a visualization tool depicting the\nmovement of units in the environment that helps understand how different task\nconditions lead to distinct agent behavior patterns in each trace cluster.\nExperimental results show that our framework is capable of separating agent\ntraces into distinct groups of behaviors for which our approach to strategy\ninference produces consistent, meaningful, and easily understood strategy\ndescriptions.\n",
                "链接": "https://arxiv.org/abs/2208.08552"
            },
            {
                "文章ID": "20119",
                "标题": "Survey on Fair Reinforcement Learning: Theory and Practice",
                "作者": " Pratik Gajane,  Akrati Saxena,  Maryam Tavakol,  George Fletcher,  Mykola Pechenizkiy",
                "发布日期": "2022-05-23",
                "摘要": "  Fairness-aware learning aims at satisfying various fairness constraints in\naddition to the usual performance criteria via data-driven machine learning\ntechniques. Most of the research in fairness-aware learning employs the setting\nof fair-supervised learning. However, many dynamic real-world applications can\nbe better modeled using sequential decision-making problems and fair\nreinforcement learning provides a more suitable alternative for addressing\nthese problems. In this article, we provide an extensive overview of fairness\napproaches that have been implemented via a reinforcement learning (RL)\nframework. We discuss various practical applications in which RL methods have\nbeen applied to achieve a fair solution with high accuracy. We further include\nvarious facets of the theory of fair reinforcement learning, organizing them\ninto single-agent RL, multi-agent RL, long-term fairness via RL, and offline\nlearning. Moreover, we highlight a few major issues to explore in order to\nadvance the field of fair-RL, namely - i) correcting societal biases, ii)\nfeasibility of group fairness or individual fairness, and iii) explainability\nin RL. Our work is beneficial for both researchers and practitioners as we\ndiscuss articles providing mathematical guarantees as well as articles with\nempirical studies on real-world problems.\n",
                "链接": "https://arxiv.org/abs/2205.10032"
            },
            {
                "文章ID": "120565",
                "标题": "Diffused Task-Agnostic Milestone Planner",
                "作者": " Mineui Hong,  Minjae Kang,  Songhwai Oh",
                "发布日期": "2023-12-07",
                "摘要": "  Addressing decision-making problems using sequence modeling to predict future\ntrajectories shows promising results in recent years. In this paper, we take a\nstep further to leverage the sequence predictive method in wider areas such as\nlong-term planning, vision-based control, and multi-task decision-making. To\nthis end, we propose a method to utilize a diffusion-based generative sequence\nmodel to plan a series of milestones in a latent space and to have an agent to\nfollow the milestones to accomplish a given task. The proposed method can learn\ncontrol-relevant, low-dimensional latent representations of milestones, which\nmakes it possible to efficiently perform long-term planning and vision-based\ncontrol. Furthermore, our approach exploits generation flexibility of the\ndiffusion model, which makes it possible to plan diverse trajectories for\nmulti-task decision-making. We demonstrate the proposed method across offline\nreinforcement learning (RL) benchmarks and an visual manipulation environment.\nThe results show that our approach outperforms offline RL methods in solving\nlong-horizon, sparse-reward tasks and multi-task problems, while also achieving\nthe state-of-the-art performance on the most challenging vision-based\nmanipulation benchmark.\n",
                "链接": "https://arxiv.org/abs/2312.03395"
            },
            {
                "文章ID": "124841",
                "标题": "Multi-Task Multi-Agent Shared Layers are Universal Cognition of\n  Multi-Agent Coordination",
                "作者": " Jiawei Wang,  Jian Zhao,  Zhengtao Cao,  Ruili Feng,  Rongjun Qin,  Yang Yu",
                "发布日期": "2023-12-27",
                "摘要": "  Multi-agent reinforcement learning shines as the pinnacle of multi-agent\nsystems, conquering intricate real-world challenges, fostering collaboration\nand coordination among agents, and unleashing the potential for intelligent\ndecision-making across domains. However, training a multi-agent reinforcement\nlearning network is a formidable endeavor, demanding substantial computational\nresources to interact with diverse environmental variables, extract state\nrepresentations, and acquire decision-making knowledge. The recent\nbreakthroughs in large-scale pre-trained models ignite our curiosity: Can we\nuncover shared knowledge in multi-agent reinforcement learning and leverage\npre-trained models to expedite training for future tasks? Addressing this\nissue, we present an innovative multi-task learning approach that aims to\nextract and harness common decision-making knowledge, like cooperation and\ncompetition, across different tasks. Our approach involves concurrent training\nof multiple multi-agent tasks, with each task employing independent front-end\nperception layers while sharing back-end decision-making layers. This effective\ndecoupling of state representation extraction from decision-making allows for\nmore efficient training and better transferability. To evaluate the efficacy of\nour proposed approach, we conduct comprehensive experiments in two distinct\nenvironments: the StarCraft Multi-agent Challenge (SMAC) and the Google\nResearch Football (GRF) environments. The experimental results unequivocally\ndemonstrate the smooth transferability of the shared decision-making network to\nother tasks, thereby significantly reducing training costs and improving final\nperformance. Furthermore, visualizations authenticate the presence of general\nmulti-agent decision-making knowledge within the shared network layers, further\nvalidating the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2312.15674"
            },
            {
                "文章ID": "21021",
                "标题": "MAVIPER: Learning Decision Tree Policies for Interpretable Multi-Agent\n  Reinforcement Learning",
                "作者": " Stephanie Milani,  Zhicheng Zhang,  Nicholay Topin,  Zheyuan Ryan Shi,  Charles Kamhoua,  Evangelos E. Papalexakis,  Fei Fang",
                "发布日期": "2022-07-13",
                "摘要": "  Many recent breakthroughs in multi-agent reinforcement learning (MARL)\nrequire the use of deep neural networks, which are challenging for human\nexperts to interpret and understand. On the other hand, existing work on\ninterpretable reinforcement learning (RL) has shown promise in extracting more\ninterpretable decision tree-based policies from neural networks, but only in\nthe single-agent setting. To fill this gap, we propose the first set of\nalgorithms that extract interpretable decision-tree policies from neural\nnetworks trained with MARL. The first algorithm, IVIPER, extends VIPER, a\nrecent method for single-agent interpretable RL, to the multi-agent setting. We\ndemonstrate that IVIPER learns high-quality decision-tree policies for each\nagent. To better capture coordination between agents, we propose a novel\ncentralized decision-tree training algorithm, MAVIPER. MAVIPER jointly grows\nthe trees of each agent by predicting the behavior of the other agents using\ntheir anticipated trees, and uses resampling to focus on states that are\ncritical for its interactions with other agents. We show that both algorithms\ngenerally outperform the baselines and that MAVIPER-trained agents achieve\nbetter-coordinated performance than IVIPER-trained agents on three different\nmulti-agent particle-world environments.\n",
                "链接": "https://arxiv.org/abs/2205.12449"
            },
            {
                "文章ID": "59945",
                "标题": "Analyzing the impact of climate change on critical infrastructure from\n  the scientific literature: A weakly supervised NLP approach",
                "作者": " Tanwi Mallick,  Joshua David Bergerson,  Duane R. Verner,  John K Hutchison,  Leslie-Anne Levy,  Prasanna Balaprakash",
                "发布日期": "2023-02-07",
                "摘要": "  Natural language processing (NLP) is a promising approach for analyzing large\nvolumes of climate-change and infrastructure-related scientific literature.\nHowever, best-in-practice NLP techniques require large collections of relevant\ndocuments (corpus). Furthermore, NLP techniques using machine learning and deep\nlearning techniques require labels grouping the articles based on user-defined\ncriteria for a significant subset of a corpus in order to train the supervised\nmodel. Even labeling a few hundred documents with human subject-matter experts\nis a time-consuming process. To expedite this process, we developed a weak\nsupervision-based NLP approach that leverages semantic similarity between\ncategories and documents to (i) establish a topic-specific corpus by subsetting\na large-scale open-access corpus and (ii) generate category labels for the\ntopic-specific corpus. In comparison with a months-long process of\nsubject-matter expert labeling, we assign category labels to the whole corpus\nusing weak supervision and supervised learning in about 13 hours. The labeled\nclimate and NCF corpus enable targeted, efficient identification of documents\ndiscussing a topic (or combination of topics) of interest and identification of\nvarious effects of climate change on critical infrastructure, improving the\nusability of scientific literature and ultimately supporting enhanced policy\nand decision making. To demonstrate this capability, we conduct topic modeling\non pairs of climate hazards and NCFs to discover trending topics at the\nintersection of these categories. This method is useful for analysts and\ndecision-makers to quickly grasp the relevant topics and most important\ndocuments linked to the topic.\n",
                "链接": "https://arxiv.org/abs/2302.01887"
            },
            {
                "文章ID": "94599",
                "标题": "Retroformer: Retrospective Large Language Agents with Policy Gradient\n  Optimization",
                "作者": " Weiran Yao,  Shelby Heinecke,  Juan Carlos Niebles,  Zhiwei Liu,  Yihao Feng,  Le Xue,  Rithesh Murthy,  Zeyuan Chen,  Jianguo Zhang,  Devansh Arpit,  Ran Xu,  Phil Mui,  Huan Wang,  Caiming Xiong,  Silvio Savarese",
                "发布日期": "2023-08-07",
                "摘要": "  Recent months have seen the emergence of a powerful new trend in which large\nlanguage models (LLMs) are augmented to become autonomous language agents\ncapable of performing objective oriented multi-step tasks on their own, rather\nthan merely responding to queries from human users. Most existing language\nagents, however, are not optimized using environment-specific rewards. Although\nsome agents enable iterative refinement through verbal feedback, they do not\nreason and plan in ways that are compatible with gradient-based learning from\nrewards. This paper introduces a principled framework for reinforcing large\nlanguage agents by learning a retrospective model, which automatically tunes\nthe language agent prompts from environment feedback through policy gradient.\nSpecifically, our proposed agent architecture learns from rewards across\nmultiple environments and tasks, for fine-tuning a pre-trained language model\nwhich refines the language agent prompt by summarizing the root cause of prior\nfailed attempts and proposing action plans. Experimental results on various\ntasks demonstrate that the language agents improve over time and that our\napproach considerably outperforms baselines that do not properly leverage\ngradients from the environment. This demonstrates that using policy gradient\noptimization to improve language agents, for which we believe our work is one\nof the first, seems promising and can be applied to optimize other models in\nthe agent architecture to enhance agent performances over time.\n",
                "链接": "https://arxiv.org/abs/2308.02151"
            },
            {
                "文章ID": "33233",
                "标题": "RLang: A Declarative Language for Describing Partial World Knowledge to\n  Reinforcement Learning Agents",
                "作者": " Rafael Rodriguez-Sanchez,  Benjamin A. Spiegel,  Jennifer Wang,  Roma Patel,  Stefanie Tellex,  George Konidaris",
                "发布日期": "2023-05-31",
                "摘要": "  We introduce RLang, a domain-specific language (DSL) for communicating domain\nknowledge to an RL agent. Unlike existing RL DSLs that ground to\n\\textit{single} elements of a decision-making formalism (e.g., the reward\nfunction or policy), RLang can specify information about every element of a\nMarkov decision process. We define precise syntax and grounding semantics for\nRLang, and provide a parser that grounds RLang programs to an\nalgorithm-agnostic \\textit{partial} world model and policy that can be\nexploited by an RL agent. We provide a series of example RLang programs\ndemonstrating how different RL methods can exploit the resulting knowledge,\nencompassing model-free and model-based tabular algorithms, policy gradient and\nvalue-based methods, hierarchical approaches, and deep methods.\n",
                "链接": "https://arxiv.org/abs/2208.06448"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态优化训练方式的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "23755",
                "标题": "Mitigating Modality Collapse in Multimodal VAEs via Impartial\n  Optimization",
                "作者": " Adrián Javaloy,  Maryam Meghdadi,  Isabel Valera",
                "发布日期": "2022-06-10",
                "摘要": "  A number of variational autoencoders (VAEs) have recently emerged with the\naim of modeling multimodal data, e.g., to jointly model images and their\ncorresponding captions. Still, multimodal VAEs tend to focus solely on a subset\nof the modalities, e.g., by fitting the image while neglecting the caption. We\nrefer to this limitation as modality collapse. In this work, we argue that this\neffect is a consequence of conflicting gradients during multimodal VAE\ntraining. We show how to detect the sub-graphs in the computational graphs\nwhere gradients conflict (impartiality blocks), as well as how to leverage\nexisting gradient-conflict solutions from multitask learning to mitigate\nmodality collapse. That is, to ensure impartial optimization across modalities.\nWe apply our training framework to several multimodal VAE models, losses and\ndatasets from the literature, and empirically show that our framework\nsignificantly improves the reconstruction performance, conditional generation,\nand coherence of the latent space across modalities.\n",
                "链接": "https://arxiv.org/abs/2206.04496"
            },
            {
                "文章ID": "95233",
                "标题": "TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal\n  Backdoored Models",
                "作者": " Indranil Sur,  Karan Sikka,  Matthew Walmer,  Kaushik Koneripalli,  Anirban Roy,  Xiao Lin,  Ajay Divakaran,  Susmit Jha",
                "发布日期": "2023-08-09",
                "摘要": "  We present a Multimodal Backdoor Defense technique TIJO (Trigger Inversion\nusing Joint Optimization). Recent work arXiv:2112.07668 has demonstrated\nsuccessful backdoor attacks on multimodal models for the Visual Question\nAnswering task. Their dual-key backdoor trigger is split across two modalities\n(image and text), such that the backdoor is activated if and only if the\ntrigger is present in both modalities. We propose TIJO that defends against\ndual-key attacks through a joint optimization that reverse-engineers the\ntrigger in both the image and text modalities. This joint optimization is\nchallenging in multimodal models due to the disconnected nature of the visual\npipeline which consists of an offline feature extractor, whose output is then\nfused with the text using a fusion module. The key insight enabling the joint\noptimization in TIJO is that the trigger inversion needs to be carried out in\nthe object detection box feature space as opposed to the pixel space. We\ndemonstrate the effectiveness of our method on the TrojVQA benchmark, where\nTIJO improves upon the state-of-the-art unimodal methods from an AUC of 0.6 to\n0.92 on multimodal dual-key backdoors. Furthermore, our method also improves\nupon the unimodal baselines on unimodal backdoors. We present ablation studies\nand qualitative results to provide insights into our algorithm such as the\ncritical importance of overlaying the inverted feature triggers on all visual\nfeatures during trigger inversion. The prototype implementation of TIJO is\navailable at https://github.com/SRI-CSL/TIJO.\n",
                "链接": "https://arxiv.org/abs/2308.03906"
            },
            {
                "文章ID": "77477",
                "标题": "ULIP-2: Towards Scalable Multimodal Pre-training for 3D Understanding",
                "作者": " Le Xue,  Ning Yu,  Shu Zhang,  Junnan Li,  Roberto Martín-Martín,  Jiajun Wu,  Caiming Xiong,  Ran Xu,  Juan Carlos Niebles,  Silvio Savarese",
                "发布日期": "2023-05-22",
                "摘要": "  Recent advancements in multimodal pre-training methods have shown promising\nefficacy in 3D representation learning by aligning multimodal features across\n3D shapes, their 2D counterparts, and language descriptions. However, the\nmethods used by existing multimodal pre-training frameworks to gather\nmultimodal data for 3D applications lack scalability and comprehensiveness,\npotentially constraining the full potential of multimodal learning. The main\nbottleneck lies in the language modality's scalability and comprehensiveness.\nTo address this, we introduce ULIP-2, a tri-modal pre-training framework that\nleverages state-of-the-art large multimodal models to automatically generate\nholistic language counterparts for 3D objects. It does not require any 3D\nannotations, and is therefore scalable to large datasets. We conduct\nexperiments on two large-scale 3D datasets, Objaverse and ShapeNet, and augment\nthem with tri-modal datasets of 3D point clouds, images, and language for\ntraining ULIP-2. ULIP-2 achieves significant improvements on downstream\nzero-shot classification on ModelNet40 (74.0% in top-1 accuracy); on the\nreal-world ScanObjectNN benchmark, it obtains 91.5% in overall accuracy with\nonly 1.4 million parameters, signifying a breakthrough in scalable multimodal\n3D representation learning without human 3D annotations. The code, along with\nthe generated tri-modal datasets, can be found at\nhttps://github.com/salesforce/ULIP.\n",
                "链接": "https://arxiv.org/abs/2305.08275"
            },
            {
                "文章ID": "92143",
                "标题": "Reparameterized Policy Learning for Multimodal Trajectory Optimization",
                "作者": " Zhiao Huang,  Litian Liang,  Zhan Ling,  Xuanlin Li,  Chuang Gan,  Hao Su",
                "发布日期": "2023-07-21",
                "摘要": "  We investigate the challenge of parametrizing policies for reinforcement\nlearning (RL) in high-dimensional continuous action spaces. Our objective is to\ndevelop a multimodal policy that overcomes limitations inherent in the\ncommonly-used Gaussian parameterization. To achieve this, we propose a\nprincipled framework that models the continuous RL policy as a generative model\nof optimal trajectories. By conditioning the policy on a latent variable, we\nderive a novel variational bound as the optimization objective, which promotes\nexploration of the environment. We then present a practical model-based RL\nmethod, called Reparameterized Policy Gradient (RPG), which leverages the\nmultimodal policy parameterization and learned world model to achieve strong\nexploration capabilities and high data efficiency. Empirical results\ndemonstrate that our method can help agents evade local optima in tasks with\ndense rewards and solve challenging sparse-reward environments by incorporating\nan object-centric intrinsic reward. Our method consistently outperforms\nprevious approaches across a range of tasks. Code and supplementary materials\nare available on the project page https://haosulab.github.io/RPG/\n",
                "链接": "https://arxiv.org/abs/2307.10710"
            },
            {
                "文章ID": "13600",
                "标题": "Training-Free Robust Multimodal Learning via Sample-Wise Jacobian\n  Regularization",
                "作者": " Zhengqi Gao,  Sucheng Ren,  Zihui Xue,  Siting Li,  Hang Zhao",
                "发布日期": "2022-04-07",
                "摘要": "  Multimodal fusion emerges as an appealing technique to improve model\nperformances on many tasks. Nevertheless, the robustness of such fusion methods\nis rarely involved in the present literature. In this paper, we propose a\ntraining-free robust late-fusion method by exploiting conditional independence\nassumption and Jacobian regularization. Our key is to minimize the Frobenius\nnorm of a Jacobian matrix, where the resulting optimization problem is relaxed\nto a tractable Sylvester equation. Furthermore, we provide a theoretical error\nbound of our method and some insights about the function of the extra modality.\nSeveral numerical experiments on AV-MNIST, RAVDESS, and VGGsound demonstrate\nthe efficacy of our method under both adversarial attacks and random\ncorruptions.\n",
                "链接": "https://arxiv.org/abs/2204.02485"
            },
            {
                "文章ID": "54383",
                "标题": "Generalizing Multimodal Variational Methods to Sets",
                "作者": " Jinzhao Zhou,  Yiqun Duan,  Zhihong Chen,  Yu-Cheng Chang,  Chin-Teng Lin",
                "发布日期": "2022-12-21",
                "摘要": "  Making sense of multiple modalities can yield a more comprehensive\ndescription of real-world phenomena. However, learning the co-representation of\ndiverse modalities is still a long-standing endeavor in emerging machine\nlearning applications and research. Previous generative approaches for\nmultimodal input approximate a joint-modality posterior by uni-modality\nposteriors as product-of-experts (PoE) or mixture-of-experts (MoE). We argue\nthat these approximations lead to a defective bound for the optimization\nprocess and loss of semantic connection among modalities. This paper presents a\nnovel variational method on sets called the Set Multimodal VAE (SMVAE) for\nlearning a multimodal latent space while handling the missing modality problem.\nBy modeling the joint-modality posterior distribution directly, the proposed\nSMVAE learns to exchange information between multiple modalities and compensate\nfor the drawbacks caused by factorization. In public datasets of various\ndomains, the experimental results demonstrate that the proposed method is\napplicable to order-agnostic cross-modal generation while achieving outstanding\nperformance compared to the state-of-the-art multimodal methods. The source\ncode for our method is available online\nhttps://anonymous.4open.science/r/SMVAE-9B3C/.\n",
                "链接": "https://arxiv.org/abs/2212.09918"
            },
            {
                "文章ID": "116336",
                "标题": "Improving Unimodal Inference with Multimodal Transformers",
                "作者": " Kateryna Chumachenko,  Alexandros Iosifidis,  Moncef Gabbouj",
                "发布日期": "2023-11-20",
                "摘要": "  This paper proposes an approach for improving performance of unimodal models\nwith multimodal training. Our approach involves a multi-branch architecture\nthat incorporates unimodal models with a multimodal transformer-based branch.\nBy co-training these branches, the stronger multimodal branch can transfer its\nknowledge to the weaker unimodal branches through a multi-task objective,\nthereby improving the performance of the resulting unimodal models. We evaluate\nour approach on tasks of dynamic hand gesture recognition based on RGB and\nDepth, audiovisual emotion recognition based on speech and facial video, and\naudio-video-text based sentiment analysis. Our approach outperforms the\nconventionally trained unimodal counterparts. Interestingly, we also observe\nthat optimization of the unimodal branches improves the multimodal branch,\ncompared to a similar multimodal model trained from scratch.\n",
                "链接": "https://arxiv.org/abs/2311.10170"
            },
            {
                "文章ID": "118791",
                "标题": "UniIR: Training and Benchmarking Universal Multimodal Information\n  Retrievers",
                "作者": " Cong Wei,  Yang Chen,  Haonan Chen,  Hexiang Hu,  Ge Zhang,  Jie Fu,  Alan Ritter,  Wenhu Chen",
                "发布日期": "2023-11-30",
                "摘要": "  Existing information retrieval (IR) models often assume a homogeneous format,\nlimiting their applicability to diverse user needs, such as searching for\nimages with text descriptions, searching for a news article with a headline\nimage, or finding a similar photo with a query image. To approach such\ndifferent information-seeking demands, we introduce UniIR, a unified\ninstruction-guided multimodal retriever capable of handling eight distinct\nretrieval tasks across modalities. UniIR, a single retrieval system jointly\ntrained on ten diverse multimodal-IR datasets, interprets user instructions to\nexecute various retrieval tasks, demonstrating robust performance across\nexisting datasets and zero-shot generalization to new tasks. Our experiments\nhighlight that multi-task training and instruction tuning are keys to UniIR's\ngeneralization ability. Additionally, we construct the M-BEIR, a multimodal\nretrieval benchmark with comprehensive results, to standardize the evaluation\nof universal multimodal information retrieval.\n",
                "链接": "https://arxiv.org/abs/2311.17136"
            },
            {
                "文章ID": "67932",
                "标题": "Multimodal Pre-training Framework for Sequential Recommendation via\n  Contrastive Learning",
                "作者": " Lingzi Zhang,  Xin Zhou,  Zhiqi Shen",
                "发布日期": "2023-03-22",
                "摘要": "  Sequential recommendation systems utilize the sequential interactions of\nusers with items as their main supervision signals in learning users'\npreferences. However, existing methods usually generate unsatisfactory results\ndue to the sparsity of user behavior data. To address this issue, we propose a\nnovel pre-training framework, named Multimodal Sequence Mixup for Sequential\nRecommendation (MSM4SR), which leverages both users' sequential behaviors and\nitems' multimodal content (\\ie text and images) for effectively recommendation.\nSpecifically, MSM4SR tokenizes each item image into multiple textual keywords\nand uses the pre-trained BERT model to obtain initial textual and visual\nfeatures of items, for eliminating the discrepancy between the text and image\nmodalities. A novel backbone network, \\ie Multimodal Mixup Sequence Encoder\n(M$^2$SE), is proposed to bridge the gap between the item multimodal content\nand the user behavior, using a complementary sequence mixup strategy. In\naddition, two contrastive learning tasks are developed to assist M$^2$SE in\nlearning generalized multimodal representations of the user behavior sequence.\nExtensive experiments on real-world datasets demonstrate that MSM4SR\noutperforms state-of-the-art recommendation methods. Moreover, we further\nverify the effectiveness of MSM4SR on other challenging tasks including\ncold-start and cross-domain recommendation.\n",
                "链接": "https://arxiv.org/abs/2303.11879"
            },
            {
                "文章ID": "94136",
                "标题": "Unimodal Intermediate Training for Multimodal Meme Sentiment\n  Classification",
                "作者": " Muzhaffar Hazman,  Susan McKeever,  Josephine Griffith",
                "发布日期": "2023-08-02",
                "摘要": "  Internet Memes remain a challenging form of user-generated content for\nautomated sentiment classification. The availability of labelled memes is a\nbarrier to developing sentiment classifiers of multimodal memes. To address the\nshortage of labelled memes, we propose to supplement the training of a\nmultimodal meme classifier with unimodal (image-only and text-only) data. In\nthis work, we present a novel variant of supervised intermediate training that\nuses relatively abundant sentiment-labelled unimodal data. Our results show a\nstatistically significant performance improvement from the incorporation of\nunimodal text data. Furthermore, we show that the training set of labelled\nmemes can be reduced by 40% without reducing the performance of the downstream\nmodel.\n",
                "链接": "https://arxiv.org/abs/2308.00528"
            }
        ]
    },
    {
        "question": {
            "question": "与大模型安全相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105613",
                "标题": "All Languages Matter: On the Multilingual Safety of Large Language\n  Models",
                "作者": " Wenxuan Wang,  Zhaopeng Tu,  Chang Chen,  Youliang Yuan,  Jen-tse Huang,  Wenxiang Jiao,  Michael R. Lyu",
                "发布日期": "2023-10-03",
                "摘要": "  Safety lies at the core of developing and deploying large language models\n(LLMs). However, previous safety benchmarks only concern the safety in one\nlanguage, e.g. the majority language in the pretraining data such as English.\nIn this work, we build the first multilingual safety benchmark for LLMs,\nXSafety, in response to the global deployment of LLMs in practice. XSafety\ncovers 14 kinds of commonly used safety issues across 10 languages that span\nseveral language families. We utilize XSafety to empirically study the\nmultilingual safety for 4 widely-used LLMs, including both close-API and\nopen-source models. Experimental results show that all LLMs produce\nsignificantly more unsafe responses for non-English queries than English ones,\nindicating the necessity of developing safety alignment for non-English\nlanguages. In addition, we propose several simple and effective prompting\nmethods to improve the multilingual safety of ChatGPT by evoking safety\nknowledge and improving cross-lingual generalization of safety alignment. Our\nprompting method can significantly reduce the ratio of unsafe responses from\n19.1% to 9.7% for non-English queries. We release our data at\nhttps://github.com/Jarviswang94/Multilingual_safety_benchmark.\n",
                "链接": "https://arxiv.org/abs/2310.00905"
            },
            {
                "文章ID": "99892",
                "标题": "SoK: Safer Digital-Safety Research Involving At-Risk Users",
                "作者": " Rosanna Bellini,  Emily Tseng,  Noel Warford,  Alaa Daffalla,  Tara Matthews,  Sunny Consolvo,  Jill Palzkill Woelfer,  Patrick Gage Kelley,  Michelle L. Mazurek,  Dana Cuomo,  Nicola Dell,  Thomas Ristenpart",
                "发布日期": "2023-09-06",
                "摘要": "  Research involving at-risk users -- that is, users who are more likely to\nexperience a digital attack or to be disproportionately affected when harm from\nsuch an attack occurs -- can pose significant safety challenges to both users\nand researchers. Nevertheless, pursuing research in computer security and\nprivacy is crucial to understanding how to meet the digital-safety needs of\nat-risk users and to design safer technology for all. To standardize and\nbolster safer research involving such users, we offer an analysis of 196\nacademic works to elicit 14 research risks and 36 safety practices used by a\ngrowing community of researchers. We pair this inconsistent set of reported\nsafety practices with oral histories from 12 domain experts to contribute\nscaffolded and consolidated pragmatic guidance that researchers can use to\nplan, execute, and share safer digital-safety research involving at-risk users.\nWe conclude by suggesting areas for future research regarding the reporting,\nstudy, and funding of at-risk user research\n",
                "链接": "https://arxiv.org/abs/2309.00735"
            },
            {
                "文章ID": "94329",
                "标题": "XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in\n  Large Language Models",
                "作者": " Paul Röttger,  Hannah Rose Kirk,  Bertie Vidgen,  Giuseppe Attanasio,  Federico Bianchi,  Dirk Hovy",
                "发布日期": "2023-10-18",
                "摘要": "  Without proper safeguards, large language models will readily follow\nmalicious instructions and generate toxic content. This risk motivates safety\nefforts such as red-teaming and large-scale feedback learning, which aim to\nmake models both helpful and harmless. However, there is a tension between\nthese two objectives, since harmlessness requires models to refuse to comply\nwith unsafe prompts, and thus not be helpful. Recent anecdotal evidence\nsuggests that some models may have struck a poor balance, so that even clearly\nsafe prompts are refused if they use similar language to unsafe prompts or\nmention sensitive topics. In this paper, we introduce a new test suite called\nXSTest to identify such eXaggerated Safety behaviours in a systematic way.\nXSTest comprises 250 safe prompts across ten prompt types that well-calibrated\nmodels should not refuse to comply with, and 200 unsafe prompts as contrasts\nthat models, for most applications, should refuse. We describe XSTest's\ncreation and composition, and then use the test suite to highlight systematic\nfailure modes in state-of-the-art language models as well as more general\nchallenges in building safer language models.\n",
                "链接": "https://arxiv.org/abs/2308.01263"
            },
            {
                "文章ID": "41136",
                "标题": "From plane crashes to algorithmic harm: applicability of safety\n  engineering frameworks for responsible ML",
                "作者": " Shalaleh Rismani,  Renee Shelby,  Andrew Smart,  Edgar Jatho,  Joshua Kroll,  AJung Moon,  Negar Rostamzadeh",
                "发布日期": "2022-10-10",
                "摘要": "  Inappropriate design and deployment of machine learning (ML) systems leads to\nnegative downstream social and ethical impact -- described here as social and\nethical risks -- for users, society and the environment. Despite the growing\nneed to regulate ML systems, current processes for assessing and mitigating\nrisks are disjointed and inconsistent. We interviewed 30 industry practitioners\non their current social and ethical risk management practices, and collected\ntheir first reactions on adapting safety engineering frameworks into their\npractice -- namely, System Theoretic Process Analysis (STPA) and Failure Mode\nand Effects Analysis (FMEA). Our findings suggest STPA/FMEA can provide\nappropriate structure toward social and ethical risk assessment and mitigation\nprocesses. However, we also find nontrivial challenges in integrating such\nframeworks in the fast-paced culture of the ML industry. We call on the ML\nresearch community to strengthen existing frameworks and assess their efficacy,\nensuring that ML systems are safer for all people.\n",
                "链接": "https://arxiv.org/abs/2210.03535"
            },
            {
                "文章ID": "62228",
                "标题": "Towards Safer Generative Language Models: A Survey on Safety Risks,\n  Evaluations, and Improvements",
                "作者": " Jiawen Deng,  Jiale Cheng,  Hao Sun,  Zhexin Zhang,  Minlie Huang",
                "发布日期": "2023-12-01",
                "摘要": "  As generative large model capabilities advance, safety concerns become more\npronounced in their outputs. To ensure the sustainable growth of the AI\necosystem, it's imperative to undertake a holistic evaluation and refinement of\nassociated safety risks. This survey presents a framework for safety research\npertaining to large models, delineating the landscape of safety risks as well\nas safety evaluation and improvement methods. We begin by introducing safety\nissues of wide concern, then delve into safety evaluation methods for large\nmodels, encompassing preference-based testing, adversarial attack approaches,\nissues detection, and other advanced evaluation methods. Additionally, we\nexplore the strategies for enhancing large model safety from training to\ndeployment, highlighting cutting-edge safety approaches for each stage in\nbuilding large models. Finally, we discuss the core challenges in advancing\ntowards more responsible AI, including the interpretability of safety\nmechanisms, ongoing safety issues, and robustness against malicious attacks.\nThrough this survey, we aim to provide clear technical guidance for safety\nresearchers and encourage further study on the safety of large models.\n",
                "链接": "https://arxiv.org/abs/2302.09270"
            },
            {
                "文章ID": "17467",
                "标题": "Modeling and mitigation of occupational safety risks in dynamic\n  industrial environments",
                "作者": " Ashutosh Tewari,  Antonio R. Paiva",
                "发布日期": "2022-05-03",
                "摘要": "  Identifying and mitigating safety risks is paramount in a number of\nindustries. In addition to guidelines and best practices, many industries\nalready have safety management systems (SMSs) designed to monitor and reinforce\ngood safety behaviors. The analytic capabilities to analyze the data acquired\nthrough such systems, however, are still lacking in terms of their ability to\nrobustly quantify risks posed by various occupational hazards. Moreover, best\npractices and modern SMSs are unable to account for dynamically evolving\nenvironments/behavioral characteristics commonly found in many industrial\nsettings. This article proposes a method to address these issues by enabling\ncontinuous and quantitative assessment of safety risks in a data-driven manner.\nThe backbone of our method is an intuitive hierarchical probabilistic model\nthat explains sparse and noisy safety data collected by a typical SMS. A fully\nBayesian approach is developed to calibrate this model from safety data in an\nonline fashion. Thereafter, the calibrated model holds necessary information\nthat serves to characterize risk posed by different safety hazards.\nAdditionally, the proposed model can be leveraged for automated decision\nmaking, for instance solving resource allocation problems -- targeted towards\nrisk mitigation -- that are often encountered in resource-constrained\nindustrial environments. The methodology is rigorously validated on a simulated\ntest-bed and its scalability is demonstrated on real data from large\nmaintenance projects at a petrochemical plant.\n",
                "链接": "https://arxiv.org/abs/2205.00894"
            },
            {
                "文章ID": "73408",
                "标题": "Safety Assessment of Chinese Large Language Models",
                "作者": " Hao Sun,  Zhexin Zhang,  Jiawen Deng,  Jiale Cheng,  Minlie Huang",
                "发布日期": "2023-04-21",
                "摘要": "  With the rapid popularity of large language models such as ChatGPT and GPT-4,\na growing amount of attention is paid to their safety concerns. These models\nmay generate insulting and discriminatory content, reflect incorrect social\nvalues, and may be used for malicious purposes such as fraud and dissemination\nof misleading information. Evaluating and enhancing their safety is\nparticularly essential for the wide application of large language models\n(LLMs). To further promote the safe deployment of LLMs, we develop a Chinese\nLLM safety assessment benchmark. Our benchmark explores the comprehensive\nsafety performance of LLMs from two perspectives: 8 kinds of typical safety\nscenarios and 6 types of more challenging instruction attacks. Our benchmark is\nbased on a straightforward process in which it provides the test prompts and\nevaluates the safety of the generated responses from the evaluated model. In\nevaluation, we utilize the LLM's strong evaluation ability and develop it as a\nsafety evaluator by prompting. On top of this benchmark, we conduct safety\nassessments and analyze 15 LLMs including the OpenAI GPT series and other\nwell-known Chinese LLMs, where we observe some interesting findings. For\nexample, we find that instruction attacks are more likely to expose safety\nissues of all LLMs. Moreover, to promote the development and deployment of\nsafe, responsible, and ethical AI, we publicly release SafetyPrompts including\n100k augmented prompts and responses by LLMs.\n",
                "链接": "https://arxiv.org/abs/2304.10436"
            },
            {
                "文章ID": "107434",
                "标题": "SC-Safety: A Multi-round Open-ended Question Adversarial Safety\n  Benchmark for Large Language Models in Chinese",
                "作者": " Liang Xu,  Kangkang Zhao,  Lei Zhu,  Hang Xue",
                "发布日期": "2023-10-10",
                "摘要": "  Large language models (LLMs), like ChatGPT and GPT-4, have demonstrated\nremarkable abilities in natural language understanding and generation. However,\nalongside their positive impact on our daily tasks, they can also produce\nharmful content that negatively affects societal perceptions. To systematically\nassess the safety of Chinese LLMs, we introduce SuperCLUE-Safety (SC-Safety) -\na multi-round adversarial benchmark with 4912 open-ended questions covering\nmore than 20 safety sub-dimensions. Adversarial human-model interactions and\nconversations significantly increase the challenges compared to existing\nmethods. Experiments on 13 major LLMs supporting Chinese yield the following\ninsights: 1) Closed-source models outperform open-sourced ones in terms of\nsafety; 2) Models released from China demonstrate comparable safety levels to\nLLMs like GPT-3.5-turbo; 3) Some smaller models with 6B-13B parameters can\ncompete effectively in terms of safety. By introducing SC-Safety, we aim to\npromote collaborative efforts to create safer and more trustworthy LLMs. The\nbenchmark and findings provide guidance on model selection. Our benchmark can\nbe found at https://www.CLUEbenchmarks.com\n",
                "链接": "https://arxiv.org/abs/2310.05818"
            },
            {
                "文章ID": "116782",
                "标题": "A Security Risk Taxonomy for Large Language Models",
                "作者": " Erik Derner,  Kristina Batistič,  Jan Zahálka,  Robert Babuška",
                "发布日期": "2023-11-21",
                "摘要": "  As large language models (LLMs) permeate more and more applications, an\nassessment of their associated security risks becomes increasingly necessary.\nThe potential for exploitation by malicious actors, ranging from disinformation\nto data breaches and reputation damage, is substantial. This paper addresses a\ngap in current research by focusing on the security risks posed by LLMs, which\nextends beyond the widely covered ethical and societal implications. Our work\nproposes a taxonomy of security risks along the user-model communication\npipeline, explicitly focusing on prompt-based attacks on LLMs. We categorize\nthe attacks by target and attack type within a prompt-based interaction scheme.\nThe taxonomy is reinforced with specific attack examples to showcase the\nreal-world impact of these risks. Through this taxonomy, we aim to inform the\ndevelopment of robust and secure LLM applications, enhancing their safety and\ntrustworthiness.\n",
                "链接": "https://arxiv.org/abs/2311.11415"
            },
            {
                "文章ID": "115677",
                "标题": "SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in\n  Large Language Models",
                "作者": " Bertie Vidgen,  Hannah Rose Kirk,  Rebecca Qian,  Nino Scherrer,  Anand Kannappan,  Scott A. Hale,  Paul Röttger",
                "发布日期": "2023-11-15",
                "摘要": "  The past year has seen rapid acceleration in the development of large\nlanguage models (LLMs). For many tasks, there is now a wide range of\nopen-source and open-access LLMs that are viable alternatives to proprietary\nmodels like ChatGPT. Without proper steering and safeguards, however, LLMs will\nreadily follow malicious instructions, provide unsafe advice, and generate\ntoxic content. This is a critical safety risk for businesses and developers. We\nintroduce SimpleSafetyTests as a new test suite for rapidly and systematically\nidentifying such critical safety risks. The test suite comprises 100 test\nprompts across five harm areas that LLMs, for the vast majority of\napplications, should refuse to comply with. We test 11 popular open LLMs and\nfind critical safety weaknesses in several of them. While some LLMs do not give\na single unsafe response, most models we test respond unsafely on more than 20%\nof cases, with over 50% unsafe responses in the extreme. Prepending a\nsafety-emphasising system prompt substantially reduces the occurrence of unsafe\nresponses, but does not completely stop them from happening. We recommend that\ndevelopers use such system prompts as a first line of defence against critical\nsafety risks.\n",
                "链接": "https://arxiv.org/abs/2311.08370"
            }
        ]
    },
    {
        "question": {
            "question": "查找大模型推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "19994",
                "标题": "Selection-Inference: Exploiting Large Language Models for Interpretable\n  Logical Reasoning",
                "作者": " Antonia Creswell,  Murray Shanahan,  Irina Higgins",
                "发布日期": "2022-05-20",
                "摘要": "  Large language models (LLMs) have been shown to be capable of impressive\nfew-shot generalisation to new tasks. However, they still tend to perform\npoorly on multi-step logical reasoning problems. Here we carry out a\ncomprehensive evaluation of LLMs on 50 tasks that probe different aspects of\nlogical reasoning. We show that language models tend to perform fairly well at\nsingle step inference or entailment tasks, but struggle to chain together\nmultiple reasoning steps to solve more complex problems. In light of this, we\npropose a Selection-Inference (SI) framework that exploits pre-trained LLMs as\ngeneral processing modules, and alternates between selection and inference to\ngenerate a series of interpretable, casual reasoning steps leading to the final\nanswer. We show that a 7B parameter LLM used within the SI framework in a\n5-shot generalisation setting, with no fine-tuning, yields a performance\nimprovement of over 100% compared to an equivalent vanilla baseline on a suite\nof 10 logical reasoning tasks. The same model in the same setting even\noutperforms a significantly larger 280B parameter baseline on the same suite of\ntasks. Moreover, answers produced by the SI framework are accompanied by a\ncausal natural-language-based reasoning trace, which has important implications\nfor the safety and trustworthiness of the system.\n",
                "链接": "https://arxiv.org/abs/2205.09712"
            },
            {
                "文章ID": "79447",
                "标题": "Enhance Reasoning Ability of Visual-Language Models via Large Language\n  Models",
                "作者": " Yueting Yang,  Xintong Zhang,  Wenjuan Han",
                "发布日期": "2023-05-23",
                "摘要": "  Pre-trained visual language models (VLM) have shown excellent performance in\nimage caption tasks. However, it sometimes shows insufficient reasoning\nability. In contrast, large language models (LLMs) emerge with powerful\nreasoning capabilities. Therefore, we propose a method called TReE, which\ntransfers the reasoning ability of a large language model to a visual language\nmodel in zero-shot scenarios. TReE contains three stages: observation,\nthinking, and re-thinking. Observation stage indicates that VLM obtains the\noverall information of the relative image. Thinking stage combines the image\ninformation and task description as the prompt of the LLM, inference with the\nrationals. Re-Thinking stage learns from rationale and then inference the final\nresult through VLM.\n",
                "链接": "https://arxiv.org/abs/2305.13267"
            },
            {
                "文章ID": "79948",
                "标题": "Automatic Model Selection with Large Language Models for Reasoning",
                "作者": " James Xu Zhao,  Yuxi Xie,  Kenji Kawaguchi,  Junxian He,  Michael Qizhe Xie",
                "发布日期": "2023-10-24",
                "摘要": "  Chain-of-Thought (CoT) and Program-Aided Language Models (PAL) represent two\ndistinct reasoning methods, each with its own strengths. CoT employs natural\nlanguage, offering flexibility and interpretability, while PAL utilizes\nprogramming language, yielding more structured and rigorous logic. We introduce\na model selection method to combine the best of both worlds by employing a\nlarge language model (LLM) to dynamically select between them. Our theoretical\nanalysis underscores the feasibility of this method, which is further\ncorroborated by empirical results. Our proposed method demonstrates significant\nperformance improvements across eight reasoning datasets with Codex, ChatGPT,\nand GPT-4. Additionally, our method is complementary to self-consistency; when\nintegrated, it can further enhance performance while significantly reducing\ncomputation costs. Moreover, we achieve new state-of-the-art results on GSM8K\nand SVAMP, with respective accuracies of 96.8% and 93.7%. Our code, data and\nprompts are available at https://github.com/XuZhao0/Model-Selection-Reasoning\n",
                "链接": "https://arxiv.org/abs/2305.14333"
            },
            {
                "文章ID": "54447",
                "标题": "Large Language Models Are Reasoning Teachers",
                "作者": " Namgyu Ho,  Laura Schmid,  Se-Young Yun",
                "发布日期": "2023-06-14",
                "摘要": "  Recent works have shown that chain-of-thought (CoT) prompting can elicit\nlanguage models to solve complex reasoning tasks, step-by-step. However,\nprompt-based CoT methods are dependent on very large models such as GPT-3 175B\nwhich are prohibitive to deploy at scale. In this paper, we use these large\nmodels as reasoning teachers to enable complex reasoning in smaller models and\nreduce model size requirements by several orders of magnitude. We propose\nFine-tune-CoT, a method that generates reasoning samples from very large\nteacher models to fine-tune smaller models. We evaluate our method on a wide\nrange of public models and complex tasks. We find that Fine-tune-CoT enables\nsubstantial reasoning capability in small models, far outperforming\nprompt-based baselines and even the teacher model in many tasks. Additionally,\nwe extend our method by leveraging the teacher model's ability to generate\nmultiple distinct rationales for each original sample. Enriching the\nfine-tuning data with such diverse reasoning results in a substantial\nperformance boost across datasets, even for very small models. We conduct\nablations and sample studies to understand the emergence of reasoning\ncapabilities of student models. Our code implementation and data are available\nat https://github.com/itsnamgyu/reasoning-teacher.\n",
                "链接": "https://arxiv.org/abs/2212.10071"
            },
            {
                "文章ID": "35416",
                "标题": "Faithful Reasoning Using Large Language Models",
                "作者": " Antonia Creswell,  Murray Shanahan",
                "发布日期": "2022-08-31",
                "摘要": "  Although contemporary large language models (LMs) demonstrate impressive\nquestion-answering capabilities, their answers are typically the product of a\nsingle call to the model. This entails an unwelcome degree of opacity and\ncompromises performance, especially on problems that are inherently multi-step.\nTo address these limitations, we show how LMs can be made to perform faithful\nmulti-step reasoning via a process whose causal structure mirrors the\nunderlying logical structure of the problem. Our approach works by chaining\ntogether reasoning steps, where each step results from calls to two fine-tuned\nLMs, one for selection and one for inference, to produce a valid reasoning\ntrace. Our method carries out a beam search through the space of reasoning\ntraces to improve reasoning quality. We demonstrate the effectiveness of our\nmodel on multi-step logical deduction and scientific question-answering,\nshowing that it outperforms baselines on final answer accuracy, and generates\nhumanly interpretable reasoning traces whose validity can be checked by the\nuser.\n",
                "链接": "https://arxiv.org/abs/2208.14271"
            },
            {
                "文章ID": "94177",
                "标题": "LISA: Reasoning Segmentation via Large Language Model",
                "作者": " Xin Lai,  Zhuotao Tian,  Yukang Chen,  Yanwei Li,  Yuhui Yuan,  Shu Liu,  Jiaya Jia",
                "发布日期": "2023-08-04",
                "摘要": "  Although perception systems have made remarkable advancements in recent\nyears, they still rely on explicit human instruction to identify the target\nobjects or categories before executing visual recognition tasks. Such systems\nlack the ability to actively reason and comprehend implicit user intentions. In\nthis work, we propose a new segmentation task -- reasoning segmentation. The\ntask is designed to output a segmentation mask given a complex and implicit\nquery text. Furthermore, we establish a benchmark comprising over one thousand\nimage-instruction pairs, incorporating intricate reasoning and world knowledge\nfor evaluation purposes. Finally, we present LISA: large Language Instructed\nSegmentation Assistant, which inherits the language generation capabilities of\nthe multi-modal Large Language Model (LLM) while also possessing the ability to\nproduce segmentation masks. We expand the original vocabulary with a <SEG>\ntoken and propose the embedding-as-mask paradigm to unlock the segmentation\ncapability. Remarkably, LISA can handle cases involving: 1) complex reasoning;\n2) world knowledge; 3) explanatory answers; 4) multi-turn conversation. Also,\nit demonstrates robust zero-shot capability when trained exclusively on\nreasoning-free datasets. In addition, fine-tuning the model with merely 239\nreasoning segmentation image-instruction pairs results in further performance\nenhancement. Experiments show our method not only unlocks new reasoning\nsegmentation capabilities but also proves effective in both complex reasoning\nsegmentation and standard referring segmentation tasks. Code, models, and demo\nare at https://github.com/dvlab-research/LISA.\n",
                "链接": "https://arxiv.org/abs/2308.00692"
            },
            {
                "文章ID": "87212",
                "标题": "Evaluating Large Language Models with NeuBAROCO: Syllogistic Reasoning\n  Ability and Human-like Biases",
                "作者": " Risako Ando,  Takanobu Morishita,  Hirohiko Abe,  Koji Mineshima,  Mitsuhiro Okada",
                "发布日期": "2023-06-23",
                "摘要": "  This paper investigates whether current large language models exhibit biases\nin logical reasoning, similar to humans. Specifically, we focus on syllogistic\nreasoning, a well-studied form of inference in the cognitive science of human\ndeduction. To facilitate our analysis, we introduce a dataset called NeuBAROCO,\noriginally designed for psychological experiments that assess human logical\nabilities in syllogistic reasoning. The dataset consists of syllogistic\ninferences in both English and Japanese. We examine three types of biases\nobserved in human syllogistic reasoning: belief biases, conversion errors, and\natmosphere effects. Our findings demonstrate that current large language models\nstruggle more with problems involving these three types of biases.\n",
                "链接": "https://arxiv.org/abs/2306.12567"
            },
            {
                "文章ID": "91532",
                "标题": "Large Language Models Perform Diagnostic Reasoning",
                "作者": " Cheng-Kuang Wu,  Wei-Lin Chen,  Hsin-Hsi Chen",
                "发布日期": "2023-07-19",
                "摘要": "  We explore the extension of chain-of-thought (CoT) prompting to medical\nreasoning for the task of automatic diagnosis. Motivated by doctors' underlying\nreasoning process, we present Diagnostic-Reasoning CoT (DR-CoT). Empirical\nresults demonstrate that by simply prompting large language models trained only\non general text corpus with two DR-CoT exemplars, the diagnostic accuracy\nimproves by 15% comparing to standard prompting. Moreover, the gap reaches a\npronounced 18% in out-domain settings. Our findings suggest expert-knowledge\nreasoning in large language models can be elicited through proper promptings.\n",
                "链接": "https://arxiv.org/abs/2307.08922"
            },
            {
                "文章ID": "108241",
                "标题": "Large Language Models for Scientific Synthesis, Inference and\n  Explanation",
                "作者": " Yizhen Zheng,  Huan Yee Koh,  Jiaxin Ju,  Anh T. N. Nguyen,  Lauren T. May,  Geoffrey I. Webb,  Shirui Pan",
                "发布日期": "2023-10-13",
                "摘要": "  Large language models are a form of artificial intelligence systems whose\nprimary knowledge consists of the statistical patterns, semantic relationships,\nand syntactical structures of language1. Despite their limited forms of\n\"knowledge\", these systems are adept at numerous complex tasks including\ncreative writing, storytelling, translation, question-answering, summarization,\nand computer code generation. However, they have yet to demonstrate advanced\napplications in natural science. Here we show how large language models can\nperform scientific synthesis, inference, and explanation. We present a method\nfor using general-purpose large language models to make inferences from\nscientific datasets of the form usually associated with special-purpose machine\nlearning algorithms. We show that the large language model can augment this\n\"knowledge\" by synthesizing from the scientific literature. When a conventional\nmachine learning system is augmented with this synthesized and inferred\nknowledge it can outperform the current state of the art across a range of\nbenchmark tasks for predicting molecular properties. This approach has the\nfurther advantage that the large language model can explain the machine\nlearning system's predictions. We anticipate that our framework will open new\navenues for AI to accelerate the pace of scientific discovery.\n",
                "链接": "https://arxiv.org/abs/2310.07984"
            },
            {
                "文章ID": "105289",
                "标题": "SocREval: Large Language Models with the Socratic Method for\n  Reference-Free Reasoning Evaluation",
                "作者": " Hangfeng He,  Hongming Zhang,  Dan Roth",
                "发布日期": "2023-10-03",
                "摘要": "  To comprehensively assess the capacity of current models for complex\nreasoning, it is crucial to assess their step-by-step reasoning in a scalable\nmanner. Established reference-based evaluation metrics rely on human-annotated\nreasoning chains to assess the model-derived chains. However, such\n``gold-standard'' human-written reasoning chains may not be unique and their\nacquisition is often labor-intensive. Existing reference-free reasoning metrics\neliminate the need for human-crafted reasoning chains as references, but they\ntypically require fine-tuning on datasets with human-derived reasoning chains,\nwhich complicates the process and raises concerns regarding generalizability\nacross diverse datasets. To address these challenges, we harness GPT-4 to\nautomatically evaluate reasoning chain quality, obviating the need for\nhuman-crafted references. Leveraging the Socratic method, we devise tailored\nprompts to enhance reference-free reasoning evaluation, which we term SocREval\n(Socratic method for Reasoning Evaluation). Empirical results from four human\nannotated datasets reveal that SocREval significantly improves GPT-4's\nperformance, surpassing existing reference-free and reference-based reasoning\nevaluation metrics. Beyond its demonstrated efficacy, our proposed framework,\nlarge language models (LLMs) with the Socratic method, proves to be both\ncost-efficient and robust to prompt writing and example selection, as\nsubstantiated by our in-depth analysis.\n",
                "链接": "https://arxiv.org/abs/2310.00074"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月自然语言处理相关的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "79436",
                "标题": "Interactive Natural Language Processing",
                "作者": " Zekun Wang,  Ge Zhang,  Kexin Yang,  Ning Shi,  Wangchunshu Zhou,  Shaochun Hao,  Guangzheng Xiong,  Yizhi Li,  Mong Yuan Sim,  Xiuying Chen,  Qingqing Zhu,  Zhenzhu Yang,  Adam Nik,  Qi Liu,  Chenghua Lin,  Shi Wang,  Ruibo Liu,  Wenhu Chen,  Ke Xu,  Dayiheng Liu,  Yike Guo,  Jie Fu",
                "发布日期": "2023-05-23",
                "摘要": "  Interactive Natural Language Processing (iNLP) has emerged as a novel\nparadigm within the field of NLP, aimed at addressing limitations in existing\nframeworks while aligning with the ultimate goals of artificial intelligence.\nThis paradigm considers language models as agents capable of observing, acting,\nand receiving feedback iteratively from external entities. Specifically,\nlanguage models in this context can: (1) interact with humans for better\nunderstanding and addressing user needs, personalizing responses, aligning with\nhuman values, and improving the overall user experience; (2) interact with\nknowledge bases for enriching language representations with factual knowledge,\nenhancing the contextual relevance of responses, and dynamically leveraging\nexternal information to generate more accurate and informed responses; (3)\ninteract with models and tools for effectively decomposing and addressing\ncomplex tasks, leveraging specialized expertise for specific subtasks, and\nfostering the simulation of social behaviors; and (4) interact with\nenvironments for learning grounded representations of language, and effectively\ntackling embodied tasks such as reasoning, planning, and decision-making in\nresponse to environmental observations. This paper offers a comprehensive\nsurvey of iNLP, starting by proposing a unified definition and framework of the\nconcept. We then provide a systematic classification of iNLP, dissecting its\nvarious components, including interactive objects, interaction interfaces, and\ninteraction methods. We proceed to delve into the evaluation methodologies used\nin the field, explore its diverse applications, scrutinize its ethical and\nsafety issues, and discuss prospective research directions. This survey serves\nas an entry point for researchers who are interested in this rapidly evolving\narea and offers a broad view of the current landscape and future trajectory of\niNLP.\n",
                "链接": "https://arxiv.org/abs/2305.13246"
            },
            {
                "文章ID": "85699",
                "标题": "Operationalising Representation in Natural Language Processing",
                "作者": " Jacqueline Harding",
                "发布日期": "2023-11-21",
                "摘要": "  Despite its centrality in the philosophy of cognitive science, there has been\nlittle prior philosophical work engaging with the notion of representation in\ncontemporary NLP practice. This paper attempts to fill that lacuna: drawing on\nideas from cognitive science, I introduce a framework for evaluating the\nrepresentational claims made about components of neural NLP models, proposing\nthree criteria with which to evaluate whether a component of a model represents\na property and operationalising these criteria using probing classifiers, a\npopular analysis technique in NLP (and deep learning more broadly).\n  The project of operationalising a philosophically-informed notion of\nrepresentation should be of interest to both philosophers of science and NLP\npractitioners. It affords philosophers a novel testing-ground for claims about\nthe nature of representation, and helps NLPers organise the large literature on\nprobing experiments, suggesting novel avenues for empirical research.\n",
                "链接": "https://arxiv.org/abs/2306.08193"
            },
            {
                "文章ID": "115729",
                "标题": "Natural Language Processing for Financial Regulation",
                "作者": " Ixandra Achitouv,  Dragos Gorduza,  Antoine Jacquier",
                "发布日期": "2023-11-16",
                "摘要": "  This article provides an understanding of Natural Language Processing\ntechniques in the framework of financial regulation, more specifically in order\nto perform semantic matching search between rules and policy when no dataset is\navailable for supervised learning. We outline how to outperform simple\npre-trained sentences-transformer models using freely available resources and\nexplain the mathematical concepts behind the key building blocks of Natural\nLanguage Processing.\n",
                "链接": "https://arxiv.org/abs/2311.08533"
            },
            {
                "文章ID": "119807",
                "标题": "Enabling Quantum Natural Language Processing for Hindi Language",
                "作者": " Naman Srivastava,  Gaurang Belekar,  Sunil Saumya,  Aswath Babu H",
                "发布日期": "2023-12-05",
                "摘要": "  Quantum Natural Language Processing (QNLP) is taking huge leaps in solving\nthe shortcomings of classical Natural Language Processing (NLP) techniques and\nmoving towards a more \"Explainable\" NLP system. The current literature around\nQNLP focuses primarily on implementing QNLP techniques in sentences in the\nEnglish language. In this paper, we propose to enable the QNLP approach to\nHINDI, which is the third most spoken language in South Asia. We present the\nprocess of building the parameterized quantum circuits required to undertake\nQNLP on Hindi sentences. We use the pregroup representation of Hindi and the\nDisCoCat framework to draw sentence diagrams. Later, we translate these\ndiagrams to Parameterised Quantum Circuits based on Instantaneous Quantum\nPolynomial (IQP) style ansatz. Using these parameterized quantum circuits\nallows one to train grammar and topic-aware sentence classifiers for the Hindi\nLanguage.\n",
                "链接": "https://arxiv.org/abs/2312.01221"
            },
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "60462",
                "标题": "Natural Language Processing for Policymaking",
                "作者": " Zhijing Jin,  Rada Mihalcea",
                "发布日期": "2023-02-08",
                "摘要": "  Language is the medium for many political activities, from campaigns to news\nreports. Natural language processing (NLP) uses computational tools to parse\ntext into key information that is needed for policymaking. In this chapter, we\nintroduce common methods of NLP, including text classification, topic modeling,\nevent extraction, and text scaling. We then overview how these methods can be\nused for policymaking through four major applications including data collection\nfor evidence-based policymaking, interpretation of political decisions, policy\ncommunication, and investigation of policy effects. Finally, we highlight some\npotential limitations and ethical concerns when using NLP for policymaking.\n  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational\nSocial Science for Policy (2023). Open Access on Springer:\nhttps://doi.org/10.1007/978-3-031-16624-2\n",
                "链接": "https://arxiv.org/abs/2302.03490"
            },
            {
                "文章ID": "115279",
                "标题": "calamanCy: A Tagalog Natural Language Processing Toolkit",
                "作者": " Lester James V. Miranda",
                "发布日期": "2023-11-14",
                "摘要": "  We introduce calamanCy, an open-source toolkit for constructing natural\nlanguage processing (NLP) pipelines for Tagalog. It is built on top of spaCy,\nenabling easy experimentation and integration with other frameworks. calamanCy\naddresses the development gap by providing a consistent API for building NLP\napplications and offering general-purpose multitask models with out-of-the-box\nsupport for dependency parsing, parts-of-speech (POS) tagging, and named entity\nrecognition (NER). calamanCy aims to accelerate the progress of Tagalog NLP by\nconsolidating disjointed resources in a unified framework. The calamanCy\ntoolkit is available on GitHub: https://github.com/ljvmiranda921/calamanCy.\n",
                "链接": "https://arxiv.org/abs/2311.07171"
            },
            {
                "文章ID": "121029",
                "标题": "PyThaiNLP: Thai Natural Language Processing in Python",
                "作者": " Wannaphong Phatthiyaphaibun,  Korakot Chaovavanich,  Charin Polpanumas,  Arthit Suriyawongkul,  Lalita Lowphansirikul,  Pattarawat Chormai,  Peerat Limkonchotiwat,  Thanathip Suntorntip,  Can Udomcharoenchaikit",
                "发布日期": "2023-12-11",
                "摘要": "  We present PyThaiNLP, a free and open-source natural language processing\n(NLP) library for Thai language implemented in Python. It provides a wide range\nof software, models, and datasets for Thai language. We first provide a brief\nhistorical context of tools for Thai language prior to the development of\nPyThaiNLP. We then outline the functionalities it provided as well as datasets\nand pre-trained language models. We later summarize its development milestones\nand discuss our experience during its development. We conclude by demonstrating\nhow industrial and research communities utilize PyThaiNLP in their work. The\nlibrary is freely available at https://github.com/pythainlp/pythainlp.\n",
                "链接": "https://arxiv.org/abs/2312.04649"
            },
            {
                "文章ID": "10640",
                "标题": "Pretraining with Artificial Language: Studying Transferable Knowledge in\n  Language Models",
                "作者": " Ryokan Ri,  Yoshimasa Tsuruoka",
                "发布日期": "2022-03-23",
                "摘要": "  We investigate what kind of structural knowledge learned in neural network\nencoders is transferable to processing natural language. We design artificial\nlanguages with structural properties that mimic natural language, pretrain\nencoders on the data, and see how much performance the encoder exhibits on\ndownstream tasks in natural language. Our experimental results show that\npretraining with an artificial language with a nesting dependency structure\nprovides some knowledge transferable to natural language. A follow-up probing\nanalysis indicates that its success in the transfer is related to the amount of\nencoded contextual information and what is transferred is the knowledge of\nposition-aware context dependence of language. Our results provide insights\ninto how neural network encoders process human languages and the source of\ncross-lingual transferability of recent multilingual language models.\n",
                "链接": "https://arxiv.org/abs/2203.10326"
            },
            {
                "文章ID": "26945",
                "标题": "Extracting Weighted Finite Automata from Recurrent Neural Networks for\n  Natural Languages",
                "作者": " Zeming Wei,  Xiyue Zhang,  Meng Sun",
                "发布日期": "2022-09-28",
                "摘要": "  Recurrent Neural Networks (RNNs) have achieved tremendous success in\nsequential data processing. However, it is quite challenging to interpret and\nverify RNNs' behaviors directly. To this end, many efforts have been made to\nextract finite automata from RNNs. Existing approaches such as exact learning\nare effective in extracting finite-state models to characterize the state\ndynamics of RNNs for formal languages, but are limited in the scalability to\nprocess natural languages. Compositional approaches that are scablable to\nnatural languages fall short in extraction precision. In this paper, we\nidentify the transition sparsity problem that heavily impacts the extraction\nprecision. To address this problem, we propose a transition rule extraction\napproach, which is scalable to natural language processing models and effective\nin improving extraction precision. Specifically, we propose an empirical method\nto complement the missing rules in the transition diagram. In addition, we\nfurther adjust the transition matrices to enhance the context-aware ability of\nthe extracted weighted finite automaton (WFA). Finally, we propose two data\naugmentation tactics to track more dynamic behaviors of the target RNN.\nExperiments on two popular natural language datasets show that our method can\nextract WFA from RNN for natural language processing with better precision than\nexisting approaches. Our code is available at\nhttps://github.com/weizeming/Extract_WFA_from_RNN_for_NL.\n",
                "链接": "https://arxiv.org/abs/2206.14621"
            }
        ]
    },
    {
        "question": {
            "question": "查找多语言情感分析的最新论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "79191",
                "标题": "Cross-lingual Transfer Can Worsen Bias in Sentiment Analysis",
                "作者": " Seraphina Goldfarb-Tarrant,  Björn Ross,  Adam Lopez",
                "发布日期": "2023-05-23",
                "摘要": "  Sentiment analysis (SA) systems are widely deployed in many of the world's\nlanguages, and there is well-documented evidence of demographic bias in these\nsystems. In languages beyond English, scarcer training data is often\nsupplemented with transfer learning using pre-trained models, including\nmultilingual models trained on other languages. In some cases, even supervision\ndata comes from other languages. Does cross-lingual transfer also import new\nbiases? To answer this question, we use counterfactual evaluation to test\nwhether gender or racial biases are imported when using cross-lingual transfer,\ncompared to a monolingual transfer setting. Across five languages, we find that\nsystems using cross-lingual transfer usually become more biased than their\nmonolingual counterparts. We also find racial biases to be much more prevalent\nthan gender biases. To spur further research on this topic, we release the\nsentiment models we used for this study, and the intermediate checkpoints\nthroughout training, yielding 1,525 distinct models; we also release our\nevaluation code.\n",
                "链接": "https://arxiv.org/abs/2305.12709"
            },
            {
                "文章ID": "37409",
                "标题": "Linear Transformations for Cross-lingual Sentiment Analysis",
                "作者": " Pavel Přibáň,  Jakub Šmíd,  Adam Mištera,  Pavel Král",
                "发布日期": "2022-09-16",
                "摘要": "  This paper deals with cross-lingual sentiment analysis in Czech, English and\nFrench languages. We perform zero-shot cross-lingual classification using five\nlinear transformations combined with LSTM and CNN based classifiers. We compare\nthe performance of the individual transformations, and in addition, we confront\nthe transformation-based approach with existing state-of-the-art BERT-like\nmodels. We show that the pre-trained embeddings from the target domain are\ncrucial to improving the cross-lingual classification results, unlike in the\nmonolingual classification, where the effect is not so distinctive.\n",
                "链接": "https://arxiv.org/abs/2209.07244"
            },
            {
                "文章ID": "13111",
                "标题": "CL-XABSA: Contrastive Learning for Cross-lingual Aspect-based Sentiment\n  Analysis",
                "作者": " Nankai Lin,  Yingwen Fu,  Xiaotian Lin,  Aimin Yang,  Shengyi Jiang",
                "发布日期": "2023-01-10",
                "摘要": "  As an extensive research in the field of natural language processing (NLP),\naspect-based sentiment analysis (ABSA) is the task of predicting the sentiment\nexpressed in a text relative to the corresponding aspect. Unfortunately, most\nlanguages lack sufficient annotation resources, thus more and more recent\nresearchers focus on cross-lingual aspect-based sentiment analysis (XABSA).\nHowever, most recent researches only concentrate on cross-lingual data\nalignment instead of model alignment. To this end, we propose a novel\nframework, CL-XABSA: Contrastive Learning for Cross-lingual Aspect-Based\nSentiment Analysis. Based on contrastive learning, we close the distance\nbetween samples with the same label in different semantic spaces, thus\nachieving a convergence of semantic spaces of different languages.\nSpecifically, we design two contrastive strategies, token level contrastive\nlearning of token embeddings (TL-CTE) and sentiment level contrastive learning\nof token embeddings (SL-CTE), to regularize the semantic space of source and\ntarget language to be more uniform. Since our framework can receive datasets in\nmultiple languages during training, our framework can be adapted not only for\nXABSA task but also for multilingual aspect-based sentiment analysis (MABSA).\nTo further improve the performance of our model, we perform knowledge\ndistillation technology leveraging data from unlabeled target language. In the\ndistillation XABSA task, we further explore the comparative effectiveness of\ndifferent data (source dataset, translated dataset, and code-switched dataset).\nThe results demonstrate that the proposed method has a certain improvement in\nthe three tasks of XABSA, distillation XABSA and MABSA. For reproducibility,\nour code for this paper is available at https://github.com/GKLMIP/CL-XABSA.\n",
                "链接": "https://arxiv.org/abs/2204.00791"
            },
            {
                "文章ID": "2025",
                "标题": "NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual\n  Sentiment Analysis",
                "作者": " Shamsuddeen Hassan Muhammad,  David Ifeoluwa Adelani,  Sebastian Ruder,  Ibrahim Said Ahmad,  Idris Abdulmumin,  Bello Shehu Bello,  Monojit Choudhury,  Chris Chinenye Emezue,  Saheed Salahudeen Abdullahi,  Anuoluwapo Aremu,  Alipio Jeorge,  Pavel Brazdil",
                "发布日期": "2022-06-22",
                "摘要": "  Sentiment analysis is one of the most widely studied applications in NLP, but\nmost work focuses on languages with large amounts of data. We introduce the\nfirst large-scale human-annotated Twitter sentiment dataset for the four most\nwidely spoken languages in Nigeria (Hausa, Igbo, Nigerian-Pidgin, and\nYor\\`ub\\'a ) consisting of around 30,000 annotated tweets per language (and\n14,000 for Nigerian-Pidgin), including a significant fraction of code-mixed\ntweets. We propose text collection, filtering, processing and labeling methods\nthat enable us to create datasets for these low-resource languages. We evaluate\na rangeof pre-trained models and transfer strategies on the dataset. We find\nthat language-specific models and language-adaptivefine-tuning generally\nperform best. We release the datasets, trained models, sentiment lexicons, and\ncode to incentivizeresearch on sentiment analysis in under-represented\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2201.08277"
            },
            {
                "文章ID": "53574",
                "标题": "Multi-task Learning for Cross-Lingual Sentiment Analysis",
                "作者": " Gaurish Thakkar,  Nives Mikelic Preradovic,  Marko Tadic",
                "发布日期": "2022-12-15",
                "摘要": "  This paper presents a cross-lingual sentiment analysis of news articles using\nzero-shot and few-shot learning. The study aims to classify the Croatian news\narticles with positive, negative, and neutral sentiments using the Slovene\ndataset. The system is based on a trilingual BERT-based model trained in three\nlanguages: English, Slovene, Croatian. The paper analyses different setups\nusing datasets in two languages and proposes a simple multi-task model to\nperform sentiment classification. The evaluation is performed using the\nfew-shot and zero-shot scenarios in single-task and multi-task experiments for\nCroatian and Slovene.\n",
                "链接": "https://arxiv.org/abs/2212.07160"
            },
            {
                "文章ID": "22103",
                "标题": "A Knowledge-Enhanced Adversarial Model for Cross-lingual Structured\n  Sentiment Analysis",
                "作者": " Qi Zhang,  Jie Zhou,  Qin Chen,  Qingchun Bai,  Jun Xiao,  Liang He",
                "发布日期": "2022-06-01",
                "摘要": "  Structured sentiment analysis, which aims to extract the complex semantic\nstructures such as holders, expressions, targets, and polarities, has obtained\nwidespread attention from both industry and academia. Unfortunately, the\nexisting structured sentiment analysis datasets refer to a few languages and\nare relatively small, limiting neural network models' performance. In this\npaper, we focus on the cross-lingual structured sentiment analysis task, which\naims to transfer the knowledge from the source language to the target one.\nNotably, we propose a Knowledge-Enhanced Adversarial Model (\\texttt{KEAM}) with\nboth implicit distributed and explicit structural knowledge to enhance the\ncross-lingual transfer. First, we design an adversarial embedding adapter for\nlearning an informative and robust representation by capturing implicit\nsemantic information from diverse multi-lingual embeddings adaptively. Then, we\npropose a syntax GCN encoder to transfer the explicit semantic information\n(e.g., universal dependency tree) among multiple languages. We conduct\nexperiments on five datasets and compare \\texttt{KEAM} with both the supervised\nand unsupervised methods. The extensive experimental results show that our\n\\texttt{KEAM} model outperforms all the unsupervised baselines in various\nmetrics.\n",
                "链接": "https://arxiv.org/abs/2205.15514"
            },
            {
                "文章ID": "121053",
                "标题": "Deep Emotions Across Languages: A Novel Approach for Sentiment\n  Propagation in Multilingual WordNets",
                "作者": " Jan Kocoń",
                "发布日期": "2023-12-11",
                "摘要": "  Sentiment analysis involves using WordNets enriched with emotional metadata,\nwhich are valuable resources. However, manual annotation is time-consuming and\nexpensive, resulting in only a few WordNet Lexical Units being annotated. This\npaper introduces two new techniques for automatically propagating sentiment\nannotations from a partially annotated WordNet to its entirety and to a WordNet\nin a different language: Multilingual Structured Synset Embeddings (MSSE) and\nCross-Lingual Deep Neural Sentiment Propagation (CLDNS). We evaluated the\nproposed MSSE+CLDNS method extensively using Princeton WordNet and Polish\nWordNet, which have many inter-lingual relations. Our results show that the\nMSSE+CLDNS method outperforms existing propagation methods, indicating its\neffectiveness in enriching WordNets with emotional metadata across multiple\nlanguages. This work provides a solid foundation for large-scale, multilingual\nsentiment analysis and is valuable for academic research and practical\napplications.\n",
                "链接": "https://arxiv.org/abs/2312.04715"
            },
            {
                "文章ID": "74935",
                "标题": "NLNDE at SemEval-2023 Task 12: Adaptive Pretraining and Source Language\n  Selection for Low-Resource Multilingual Sentiment Analysis",
                "作者": " Mingyang Wang,  Heike Adel,  Lukas Lange,  Jannik Strötgen,  Hinrich Schütze",
                "发布日期": "2023-05-02",
                "摘要": "  This paper describes our system developed for the SemEval-2023 Task 12\n\"Sentiment Analysis for Low-resource African Languages using Twitter Dataset\".\nSentiment analysis is one of the most widely studied applications in natural\nlanguage processing. However, most prior work still focuses on a small number\nof high-resource languages. Building reliable sentiment analysis systems for\nlow-resource languages remains challenging, due to the limited training data in\nthis task. In this work, we propose to leverage language-adaptive and\ntask-adaptive pretraining on African texts and study transfer learning with\nsource language selection on top of an African language-centric pretrained\nlanguage model. Our key findings are: (1) Adapting the pretrained model to the\ntarget language and task using a small yet relevant corpus improves performance\nremarkably by more than 10 F1 score points. (2) Selecting source languages with\npositive transfer gains during training can avoid harmful interference from\ndissimilar languages, leading to better results in multilingual and\ncross-lingual settings. In the shared task, our system wins 8 out of 15 tracks\nand, in particular, performs best in the multilingual evaluation.\n",
                "链接": "https://arxiv.org/abs/2305.00090"
            },
            {
                "文章ID": "85580",
                "标题": "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted\n  Sentiment Classification Benchmark",
                "作者": " Łukasz Augustyniak,  Szymon Woźniak,  Marcin Gruza,  Piotr Gramacki,  Krzysztof Rajda,  Mikołaj Morzy,  Tomasz Kajdanowicz",
                "发布日期": "2023-06-14",
                "摘要": "  Despite impressive advancements in multilingual corpora collection and model\ntraining, developing large-scale deployments of multilingual models still\npresents a significant challenge. This is particularly true for language tasks\nthat are culture-dependent. One such example is the area of multilingual\nsentiment analysis, where affective markers can be subtle and deeply ensconced\nin culture. This work presents the most extensive open massively multilingual\ncorpus of datasets for training sentiment models. The corpus consists of 79\nmanually selected datasets from over 350 datasets reported in the scientific\nliterature based on strict quality criteria. The corpus covers 27 languages\nrepresenting 6 language families. Datasets can be queried using several\nlinguistic and functional features. In addition, we present a multi-faceted\nsentiment classification benchmark summarizing hundreds of experiments\nconducted on different base models, training objectives, dataset collections,\nand fine-tuning strategies.\n",
                "链接": "https://arxiv.org/abs/2306.07902"
            },
            {
                "文章ID": "33857",
                "标题": "Mere Contrastive Learning for Cross-Domain Sentiment Analysis",
                "作者": " Yun Luo,  Fang Guo,  Zihan Liu,  Yue Zhang",
                "发布日期": "2022-08-19",
                "摘要": "  Cross-domain sentiment analysis aims to predict the sentiment of texts in the\ntarget domain using the model trained on the source domain to cope with the\nscarcity of labeled data. Previous studies are mostly cross-entropy-based\nmethods for the task, which suffer from instability and poor generalization. In\nthis paper, we explore contrastive learning on the cross-domain sentiment\nanalysis task. We propose a modified contrastive objective with in-batch\nnegative samples so that the sentence representations from the same class will\nbe pushed close while those from the different classes become further apart in\nthe latent space. Experiments on two widely used datasets show that our model\ncan achieve state-of-the-art performance in both cross-domain and multi-domain\nsentiment analysis tasks. Meanwhile, visualizations demonstrate the\neffectiveness of transferring knowledge learned in the source domain to the\ntarget domain and the adversarial test verifies the robustness of our model.\n",
                "链接": "https://arxiv.org/abs/2208.08678"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于NLP领域的持续性学习论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "49978",
                "标题": "Continual Learning of Natural Language Processing Tasks: A Survey",
                "作者": " Zixuan Ke,  Bing Liu",
                "发布日期": "2023-05-12",
                "摘要": "  Continual learning (CL) is a learning paradigm that emulates the human\ncapability of learning and accumulating knowledge continually without\nforgetting the previously learned knowledge and also transferring the learned\nknowledge to help learn new tasks better. This survey presents a comprehensive\nreview and analysis of the recent progress of CL in NLP, which has significant\ndifferences from CL in computer vision and machine learning. It covers (1) all\nCL settings with a taxonomy of existing techniques; (2) catastrophic forgetting\n(CF) prevention, (3) knowledge transfer (KT), which is particularly important\nfor NLP tasks; and (4) some theory and the hidden challenge of inter-task class\nseparation (ICS). (1), (3) and (4) have not been included in the existing\nsurvey. Finally, a list of future directions is discussed.\n",
                "链接": "https://arxiv.org/abs/2211.12701"
            },
            {
                "文章ID": "92120",
                "标题": "Exploring the Landscape of Natural Language Processing Research",
                "作者": " Tim Schopf,  Karim Arabi,  Florian Matthes",
                "发布日期": "2023-09-26",
                "摘要": "  As an efficient approach to understand, generate, and process natural\nlanguage texts, research in natural language processing (NLP) has exhibited a\nrapid spread and wide adoption in recent years. Given the increasing research\nwork in this area, several NLP-related approaches have been surveyed in the\nresearch community. However, a comprehensive study that categorizes established\ntopics, identifies trends, and outlines areas for future research remains\nabsent. Contributing to closing this gap, we have systematically classified and\nanalyzed research papers in the ACL Anthology. As a result, we present a\nstructured overview of the research landscape, provide a taxonomy of fields of\nstudy in NLP, analyze recent developments in NLP, summarize our findings, and\nhighlight directions for future work.\n",
                "链接": "https://arxiv.org/abs/2307.10652"
            },
            {
                "文章ID": "72771",
                "标题": "Use of social media and Natural Language Processing (NLP) in natural\n  hazard research",
                "作者": " José Augusto Proença Maia Devienne",
                "发布日期": "2023-04-18",
                "摘要": "  Twitter is a microblogging service for sending short, public text messages\n(tweets) that has recently received more attention in scientific comunity. In\nthe works of Sasaki et al. (2010) and Earle et al., (2011) the authors explored\nthe real-time interaction on Twitter for detecting natural hazards (e.g.,\nearthquakes, typhoons) baed on users' tweets. An inherent challenge for such an\napplication is the natural language processing (NLP), which basically consists\nin converting the words in number (vectors and tensors) in order to\n(mathematically/ computationally) make predictions and classifications.\nRecently advanced computational tools have been made available for dealing with\ntext computationally. In this report we implement a NLP machine learning with\nTensorFlow, an end-to-end open source plataform for machine learning\napplications, to process and classify evenct based on files containing only\ntext.\n",
                "链接": "https://arxiv.org/abs/2304.08341"
            },
            {
                "文章ID": "88351",
                "标题": "Generative User-Experience Research for Developing Domain-specific\n  Natural Language Processing Applications",
                "作者": " Anastasia Zhukova,  Lukas von Sperl,  Christian E. Matt,  Bela Gipp",
                "发布日期": "2023-09-15",
                "摘要": "  User experience (UX) is a part of human-computer interaction (HCI) research\nand focuses on increasing intuitiveness, transparency, simplicity, and trust\nfor system users. Most of the UX research for machine learning (ML) or natural\nlanguage processing (NLP) focuses on a data-driven methodology, i.e., it fails\nto focus on users' requirements, and engages domain users mainly for usability\nevaluation. Moreover, more typical UX methods tailor the systems towards user\nusability, unlike learning about the user needs first. The paper proposes a\nmethodology for integrating generative UX research into developing domain NLP\napplications. Generative UX research employs domain users at the initial stages\nof prototype development, i.e., ideation and concept evaluation, and the last\nstage for evaluating the change in user value. In the case study, we report the\nfull-cycle prototype development of a domain-specific semantic search for daily\noperations in the process industry. Our case study shows that involving domain\nexperts increases their interest and trust in the final NLP application.\nMoreover, we show that synergetic UX+NLP research efficiently considers data-\nand user-driven opportunities and constraints, which can be crucial for NLP\napplications in narrow domains\n",
                "链接": "https://arxiv.org/abs/2306.16143"
            },
            {
                "文章ID": "68861",
                "标题": "Natural Language Processing in Ethiopian Languages: Current State,\n  Challenges, and Opportunities",
                "作者": " Atnafu Lambebo Tonja,  Tadesse Destaw Belay,  Israel Abebe Azime,  Abinew Ali Ayele,  Moges Ahmed Mehamed,  Olga Kolesnikova,  Seid Muhie Yimam",
                "发布日期": "2023-03-28",
                "摘要": "  This survey delves into the current state of natural language processing\n(NLP) for four Ethiopian languages: Amharic, Afaan Oromo, Tigrinya, and\nWolaytta. Through this paper, we identify key challenges and opportunities for\nNLP research in Ethiopia. Furthermore, we provide a centralized repository on\nGitHub that contains publicly available resources for various NLP tasks in\nthese languages. This repository can be updated periodically with contributions\nfrom other researchers. Our objective is to identify research gaps and\ndisseminate the information to NLP researchers interested in Ethiopian\nlanguages and encourage future research in this domain.\n",
                "链接": "https://arxiv.org/abs/2303.14406"
            },
            {
                "文章ID": "68449",
                "标题": "Requirement Formalisation using Natural Language Processing and Machine\n  Learning: A Systematic Review",
                "作者": " Shekoufeh Kolahdouz-Rahimi,  Kevin Lano,  Chenghua Lin",
                "发布日期": "2023-03-24",
                "摘要": "  Improvement of software development methodologies attracts developers to\nautomatic Requirement Formalisation (RF) in the Requirement Engineering (RE)\nfield. The potential advantages by applying Natural Language Processing (NLP)\nand Machine Learning (ML) in reducing the ambiguity and incompleteness of\nrequirement written in natural languages is reported in different studies. The\ngoal of this paper is to survey and classify existing work on NLP and ML for\nRF, identifying challenges in this domain and providing promising future\nresearch directions. To achieve this, we conducted a systematic literature\nreview to outline the current state-of-the-art of NLP and ML techniques in RF\nby selecting 257 papers from common used libraries. The search result is\nfiltered by defining inclusion and exclusion criteria and 47 relevant studies\nbetween 2012 and 2022 are selected. We found that heuristic NLP approaches are\nthe most common NLP techniques used for automatic RF, primary operating on\nstructured and semi-structured data. This study also revealed that Deep\nLearning (DL) technique are not widely used, instead classical ML techniques\nare predominant in the surveyed studies. More importantly, we identified the\ndifficulty of comparing the performance of different approaches due to the lack\nof standard benchmark cases for RF.\n",
                "链接": "https://arxiv.org/abs/2303.13365"
            },
            {
                "文章ID": "70948",
                "标题": "Sejarah dan Perkembangan Teknik Natural Language Processing (NLP) Bahasa\n  Indonesia: Tinjauan tentang sejarah, perkembangan teknologi, dan aplikasi NLP\n  dalam bahasa Indonesia",
                "作者": " Mukhlis Amien",
                "发布日期": "2023-04-07",
                "摘要": "  This study provides an overview of the history of the development of Natural\nLanguage Processing (NLP) in the context of the Indonesian language, with a\nfocus on the basic technologies, methods, and practical applications that have\nbeen developed. This review covers developments in basic NLP technologies such\nas stemming, part-of-speech tagging, and related methods; practical\napplications in cross-language information retrieval systems, information\nextraction, and sentiment analysis; and methods and techniques used in\nIndonesian language NLP research, such as machine learning, statistics-based\nmachine translation, and conflict-based approaches. This study also explores\nthe application of NLP in Indonesian language industry and research and\nidentifies challenges and opportunities in Indonesian language NLP research and\ndevelopment. Recommendations for future Indonesian language NLP research and\ndevelopment include developing more efficient methods and technologies,\nexpanding NLP applications, increasing sustainability, further research into\nthe potential of NLP, and promoting interdisciplinary collaboration. It is\nhoped that this review will help researchers, practitioners, and the government\nto understand the development of Indonesian language NLP and identify\nopportunities for further research and development.\n",
                "链接": "https://arxiv.org/abs/2304.02746"
            },
            {
                "文章ID": "90545",
                "标题": "Towards Robust and Efficient Continual Language Learning",
                "作者": " Adam Fisch,  Amal Rannen-Triki,  Razvan Pascanu,  Jörg Bornschein,  Angeliki Lazaridou,  Elena Gribovskaya,  Marc'Aurelio Ranzato",
                "发布日期": "2023-07-13",
                "摘要": "  As the application space of language models continues to evolve, a natural\nquestion to ask is how we can quickly adapt models to new tasks. We approach\nthis classic question from a continual learning perspective, in which we aim to\ncontinue fine-tuning models trained on past tasks on new tasks, with the goal\nof \"transferring\" relevant knowledge. However, this strategy also runs the risk\nof doing more harm than good, i.e., negative transfer. In this paper, we\nconstruct a new benchmark of task sequences that target different possible\ntransfer scenarios one might face, such as a sequence of tasks with high\npotential of positive transfer, high potential for negative transfer, no\nexpected effect, or a mixture of each. An ideal learner should be able to\nmaximally exploit information from all tasks that have any potential for\npositive transfer, while also avoiding the negative effects of any distracting\ntasks that may confuse it. We then propose a simple, yet effective, learner\nthat satisfies many of our desiderata simply by leveraging a selective strategy\nfor initializing new models from past task checkpoints. Still, limitations\nremain, and we hope this benchmark can help the community to further build and\nanalyze such learners.\n",
                "链接": "https://arxiv.org/abs/2307.05741"
            },
            {
                "文章ID": "75751",
                "标题": "The Elephant in the Room: Analyzing the Presence of Big Tech in Natural\n  Language Processing Research",
                "作者": " Mohamed Abdalla,  Jan Philip Wahle,  Terry Ruas,  Aurélie Névéol,  Fanny Ducel,  Saif M. Mohammad,  Karën Fort",
                "发布日期": "2023-10-24",
                "摘要": "  Recent advances in deep learning methods for natural language processing\n(NLP) have created new business opportunities and made NLP research critical\nfor industry development. As one of the big players in the field of NLP,\ntogether with governments and universities, it is important to track the\ninfluence of industry on research. In this study, we seek to quantify and\ncharacterize industry presence in the NLP community over time. Using a corpus\nwith comprehensive metadata of 78,187 NLP publications and 701 resumes of NLP\npublication authors, we explore the industry presence in the field since the\nearly 90s. We find that industry presence among NLP authors has been steady\nbefore a steep increase over the past five years (180% growth from 2017 to\n2022). A few companies account for most of the publications and provide funding\nto academic researchers through grants and internships. Our study shows that\nthe presence and impact of the industry on natural language processing research\nare significant and fast-growing. This work calls for increased transparency of\nindustry influence in the field.\n",
                "链接": "https://arxiv.org/abs/2305.02797"
            },
            {
                "文章ID": "105853",
                "标题": "A Review of Digital Learning Environments for Teaching Natural Language\n  Processing in K-12 Education",
                "作者": " Xiaoyi Tian,  Kristy Elizabeth Boyer",
                "发布日期": "2023-10-04",
                "摘要": "  Natural Language Processing (NLP) plays a significant role in our daily lives\nand has become an essential part of Artificial Intelligence (AI) education in\nK-12. As children grow up with NLP-powered applications, it is crucial to\nintroduce NLP concepts to them, fostering their understanding of language\nprocessing, language generation, and ethical implications of AI and NLP. This\npaper presents a comprehensive review of digital learning environments for\nteaching NLP in K-12. Specifically, it explores existing digital learning\ntools, discusses how they support specific NLP tasks and procedures, and\ninvestigates their explainability and evaluation results in educational\ncontexts. By examining the strengths and limitations of these tools, this\nliterature review sheds light on the current state of NLP learning tools in\nK-12 education. It aims to guide future research efforts to refine existing\ntools, develop new ones, and explore more effective and inclusive strategies\nfor integrating NLP into K-12 educational contexts.\n",
                "链接": "https://arxiv.org/abs/2310.01603"
            }
        ]
    },
    {
        "question": {
            "question": "找一下最近关于大模型评测的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "95587",
                "标题": "NLLG Quarterly arXiv Report 06/23: What are the most influential current\n  AI Papers?",
                "作者": " Steffen Eger,  Christoph Leiter,  Jonas Belouadi,  Ran Zhang,  Aida Kostikova,  Daniil Larionov,  Yanran Chen,  Vivian Fresen",
                "发布日期": "2023-08-15",
                "摘要": "  The rapid growth of information in the field of Generative Artificial\nIntelligence (AI), particularly in the subfields of Natural Language Processing\n(NLP) and Machine Learning (ML), presents a significant challenge for\nresearchers and practitioners to keep pace with the latest developments. To\naddress the problem of information overload, this report by the Natural\nLanguage Learning Group at Bielefeld University focuses on identifying the most\npopular papers on arXiv, with a specific emphasis on NLP and ML. The objective\nis to offer a quick guide to the most relevant and widely discussed research,\naiding both newcomers and established researchers in staying abreast of current\ntrends. In particular, we compile a list of the 40 most popular papers based on\nnormalized citation counts from the first half of 2023. We observe the\ndominance of papers related to Large Language Models (LLMs) and specifically\nChatGPT during the first half of 2023, with the latter showing signs of\ndeclining popularity more recently, however. Further, NLP related papers are\nthe most influential (around 60\\% of top papers) even though there are twice as\nmany ML related papers in our data. Core issues investigated in the most\nheavily cited papers are: LLM efficiency, evaluation techniques, ethical\nconsiderations, embodied agents, and problem-solving with LLMs. Additionally,\nwe examine the characteristics of top papers in comparison to others outside\nthe top-40 list (noticing the top paper's focus on LLM related issues and\nhigher number of co-authors) and analyze the citation distributions in our\ndataset, among others.\n",
                "链接": "https://arxiv.org/abs/2308.04889"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "111067",
                "标题": "Improving Biomedical Abstractive Summarisation with Knowledge\n  Aggregation from Citation Papers",
                "作者": " Chen Tang,  Shun Wang,  Tomas Goldsack,  Chenghua Lin",
                "发布日期": "2023-10-25",
                "摘要": "  Abstracts derived from biomedical literature possess distinct domain-specific\ncharacteristics, including specialised writing styles and biomedical\nterminologies, which necessitate a deep understanding of the related\nliterature. As a result, existing language models struggle to generate\ntechnical summaries that are on par with those produced by biomedical experts,\ngiven the absence of domain-specific background knowledge. This paper aims to\nenhance the performance of language models in biomedical abstractive\nsummarisation by aggregating knowledge from external papers cited within the\nsource article. We propose a novel attention-based citation aggregation model\nthat integrates domain-specific knowledge from citation papers, allowing neural\nnetworks to generate summaries by leveraging both the paper content and\nrelevant knowledge from citation papers. Furthermore, we construct and release\na large-scale biomedical summarisation dataset that serves as a foundation for\nour research. Extensive experiments demonstrate that our model outperforms\nstate-of-the-art approaches and achieves substantial improvements in\nabstractive biomedical text summarisation.\n",
                "链接": "https://arxiv.org/abs/2310.15684"
            },
            {
                "文章ID": "104015",
                "标题": "EvalLM: Interactive Evaluation of Large Language Model Prompts on\n  User-Defined Criteria",
                "作者": " Tae Soo Kim,  Yoonjoo Lee,  Jamin Shin,  Young-Ho Kim,  Juho Kim",
                "发布日期": "2023-09-26",
                "摘要": "  By simply composing prompts, developers can prototype novel generative\napplications with Large Language Models (LLMs). To refine prototypes into\nproducts, however, developers must iteratively revise prompts by evaluating\noutputs to diagnose weaknesses. Formative interviews (N=8) revealed that\ndevelopers invest significant effort in manually evaluating outputs as they\nassess context-specific and subjective criteria. We present EvalLM, an\ninteractive system for iteratively refining prompts by evaluating multiple\noutputs on user-defined criteria. By describing criteria in natural language,\nusers can employ the system's LLM-based evaluator to get an overview of where\nprompts excel or fail, and improve these based on the evaluator's feedback. A\ncomparative study (N=12) showed that EvalLM, when compared to manual\nevaluation, helped participants compose more diverse criteria, examine twice as\nmany outputs, and reach satisfactory prompts with 59% fewer revisions. Beyond\nprompts, our work can be extended to augment model evaluation and alignment in\nspecific application contexts.\n",
                "链接": "https://arxiv.org/abs/2309.13633"
            },
            {
                "文章ID": "117538",
                "标题": "A Survey of Serverless Machine Learning Model Inference",
                "作者": " Kamil Kojs",
                "发布日期": "2023-11-23",
                "摘要": "  Recent developments in Generative AI, Computer Vision, and Natural Language\nProcessing have led to an increased integration of AI models into various\nproducts. This widespread adoption of AI requires significant efforts in\ndeploying these models in production environments. When hosting machine\nlearning models for real-time predictions, it is important to meet defined\nService Level Objectives (SLOs), ensuring reliability, minimal downtime, and\noptimizing operational costs of the underlying infrastructure. Large machine\nlearning models often demand GPU resources for efficient inference to meet\nSLOs. In the context of these trends, there is growing interest in hosting AI\nmodels in a serverless architecture while still providing GPU access for\ninference tasks. This survey aims to summarize and categorize the emerging\nchallenges and optimization opportunities for large-scale deep learning serving\nsystems. By providing a novel taxonomy and summarizing recent trends, we hope\nthat this survey could shed light on new optimization perspectives and motivate\nnovel works in large-scale deep learning serving systems.\n",
                "链接": "https://arxiv.org/abs/2311.13587"
            },
            {
                "文章ID": "111569",
                "标题": "math-PVS: A Large Language Model Framework to Map Scientific\n  Publications to PVS Theories",
                "作者": " Hassen Saidi,  Susmit Jha,  Tuhin Sahai",
                "发布日期": "2023-10-27",
                "摘要": "  As artificial intelligence (AI) gains greater adoption in a wide variety of\napplications, it has immense potential to contribute to mathematical discovery,\nby guiding conjecture generation, constructing counterexamples, assisting in\nformalizing mathematics, and discovering connections between different\nmathematical areas, to name a few.\n  While prior work has leveraged computers for exhaustive mathematical proof\nsearch, recent efforts based on large language models (LLMs) aspire to position\ncomputing platforms as co-contributors in the mathematical research process.\nDespite their current limitations in logic and mathematical tasks, there is\ngrowing interest in melding theorem proving systems with foundation models.\nThis work investigates the applicability of LLMs in formalizing advanced\nmathematical concepts and proposes a framework that can critically review and\ncheck mathematical reasoning in research papers. Given the noted reasoning\nshortcomings of LLMs, our approach synergizes the capabilities of proof\nassistants, specifically PVS, with LLMs, enabling a bridge between textual\ndescriptions in academic papers and formal specifications in PVS. By harnessing\nthe PVS environment, coupled with data ingestion and conversion mechanisms, we\nenvision an automated process, called \\emph{math-PVS}, to extract and formalize\nmathematical theorems from research papers, offering an innovative tool for\nacademic review and discovery.\n",
                "链接": "https://arxiv.org/abs/2310.17064"
            },
            {
                "文章ID": "96350",
                "标题": "The Devil is in the Errors: Leveraging Large Language Models for\n  Fine-grained Machine Translation Evaluation",
                "作者": " Patrick Fernandes,  Daniel Deutsch,  Mara Finkelstein,  Parker Riley,  André F. T. Martins,  Graham Neubig,  Ankush Garg,  Jonathan H. Clark,  Markus Freitag,  Orhan Firat",
                "发布日期": "2023-08-15",
                "摘要": "  Automatic evaluation of machine translation (MT) is a critical tool driving\nthe rapid iterative development of MT systems. While considerable progress has\nbeen made on estimating a single scalar quality score, current metrics lack the\ninformativeness of more detailed schemes that annotate individual errors, such\nas Multidimensional Quality Metrics (MQM). In this paper, we help fill this gap\nby proposing AutoMQM, a prompting technique which leverages the reasoning and\nin-context learning capabilities of large language models (LLMs) and asks them\nto identify and categorize errors in translations. We start by evaluating\nrecent LLMs, such as PaLM and PaLM-2, through simple score prediction\nprompting, and we study the impact of labeled data through in-context learning\nand finetuning. We then evaluate AutoMQM with PaLM-2 models, and we find that\nit improves performance compared to just prompting for scores (with\nparticularly large gains for larger models) while providing interpretability\nthrough error spans that align with human annotations.\n",
                "链接": "https://arxiv.org/abs/2308.07286"
            },
            {
                "文章ID": "78952",
                "标题": "Revisiting Automated Topic Model Evaluation with Large Language Models",
                "作者": " Dominik Stammbach,  Vilém Zouhar,  Alexander Hoyle,  Mrinmaya Sachan,  Elliott Ash",
                "发布日期": "2023-10-24",
                "摘要": "  Topic models are used to make sense of large text collections. However,\nautomatically evaluating topic model output and determining the optimal number\nof topics both have been longstanding challenges, with no effective automated\nsolutions to date. This paper proposes using large language models to evaluate\nsuch output. We find that large language models appropriately assess the\nresulting topics, correlating more strongly with human judgments than existing\nautomated metrics. We then investigate whether we can use large language models\nto automatically determine the optimal number of topics. We automatically\nassign labels to documents and choosing configurations with the most pure\nlabels returns reasonable values for the optimal number of topics.\n",
                "链接": "https://arxiv.org/abs/2305.12152"
            },
            {
                "文章ID": "121044",
                "标题": "Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and\n  Insights",
                "作者": " Maryam Ben Driss,  Essaid Sabir,  Halima Elbiaze,  Walid Saad",
                "发布日期": "2023-12-11",
                "摘要": "  Artificial Intelligence (AI) is expected to play an instrumental role in the\nnext generation of wireless systems, such as sixth-generation (6G) mobile\nnetwork. However, massive data, energy consumption, training complexity, and\nsensitive data protection in wireless systems are all crucial challenges that\nmust be addressed for training AI models and gathering intelligence and\nknowledge from distributed devices. Federated Learning (FL) is a recent\nframework that has emerged as a promising approach for multiple learning agents\nto build an accurate and robust machine learning models without sharing raw\ndata. By allowing mobile handsets and devices to collaboratively learn a global\nmodel without explicit sharing of training data, FL exhibits high privacy and\nefficient spectrum utilization. While there are a lot of survey papers\nexploring FL paradigms and usability in 6G privacy, none of them has clearly\naddressed how FL can be used to improve the protocol stack and wireless\noperations. The main goal of this survey is to provide a comprehensive overview\non FL usability to enhance mobile services and enable smart ecosystems to\nsupport novel use-cases. This paper examines the added-value of implementing FL\nthroughout all levels of the protocol stack. Furthermore, it presents important\nFL applications, addresses hot topics, provides valuable insights and explicits\nguidance for future research and developments. Our concluding remarks aim to\nleverage the synergy between FL and future 6G, while highlighting FL's\npotential to revolutionize wireless industry and sustain the development of\ncutting-edge mobile services.\n",
                "链接": "https://arxiv.org/abs/2312.04688"
            }
        ]
    },
    {
        "question": {
            "question": "近一个月与多模态大模型相关论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找近六个月工具学习评测数据集的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "98794",
                "标题": "Confucius: Iterative Tool Learning from Introspection Feedback by\n  Easy-to-Difficult Curriculum",
                "作者": " Shen Gao,  Zhengliang Shi,  Minghang Zhu,  Bowen Fang,  Xin Xin,  Pengjie Ren,  Zhumin Chen,  Jun Ma,  Zhaochun Ren",
                "发布日期": "2023-12-22",
                "摘要": "  Augmenting large language models (LLMs) with external tools has emerged as a\npromising approach to extending the capability of LLMs. Although some works\nemploy open-source LLMs for the tool learning task, most of them are trained in\na controlled environment in which LLMs only learn to execute the human-provided\ntools. However, selecting proper tools from the large toolset is also a crucial\nability for the tool learning model to be applied in real-world applications.\nExisting methods usually directly employ self-instruction methods to train the\nmodel, which ignores differences in tool complexity. In this paper, we propose\nthe Confucius, a novel tool learning framework to train LLM to use complicated\ntools in real-world scenarios, which contains two main phases: (1) We first\npropose a multi-stage learning method to teach the LLM to use various tools\nfrom an easy-to-difficult curriculum; (2) thenceforth, we propose the Iterative\nSelf-instruct from Introspective Feedback (ISIF) to dynamically construct the\ndataset to improve the ability to use the complicated tool. Extensive\nexperiments conducted on both controlled and real-world settings demonstrate\nthe superiority of our tool learning framework in the real-world application\nscenarios compared to both tuning-free (e.g. ChatGPT, Claude) and tuning-based\nbaselines (e.g. GPT4Tools).\n",
                "链接": "https://arxiv.org/abs/2308.14034"
            },
            {
                "文章ID": "122192",
                "标题": "BESTMVQA: A Benchmark Evaluation System for Medical Visual Question\n  Answering",
                "作者": " Xiaojie Hong,  Zixin Song,  Liangzhi Li,  Xiaoli Wang,  Feiyan Liu",
                "发布日期": "2023-12-14",
                "摘要": "  Medical Visual Question Answering (Med-VQA) is a very important task in\nhealthcare industry, which answers a natural language question with a medical\nimage. Existing VQA techniques in information systems can be directly applied\nto solving the task. However, they often suffer from (i) the data insufficient\nproblem, which makes it difficult to train the state of the arts (SOTAs) for\nthe domain-specific task, and (ii) the reproducibility problem, that many\nexisting models have not been thoroughly evaluated in a unified experimental\nsetup. To address these issues, this paper develops a Benchmark Evaluation\nSysTem for Medical Visual Question Answering, denoted by BESTMVQA. Given\nself-collected clinical data, our system provides a useful tool for users to\nautomatically build Med-VQA datasets, which helps overcoming the data\ninsufficient problem. Users also can conveniently select a wide spectrum of\nSOTA models from our model library to perform a comprehensive empirical study.\nWith simple configurations, our system automatically trains and evaluates the\nselected models over a benchmark dataset, and reports the comprehensive results\nfor users to develop new techniques or perform medical practice. Limitations of\nexisting work are overcome (i) by the data generation tool, which automatically\nconstructs new datasets from unstructured clinical data, and (ii) by evaluating\nSOTAs on benchmark datasets in a unified experimental setup. The demonstration\nvideo of our system can be found at https://youtu.be/QkEeFlu1x4A. Our code and\ndata will be available soon.\n",
                "链接": "https://arxiv.org/abs/2312.07867"
            },
            {
                "文章ID": "124518",
                "标题": "Density Uncertainty Quantification with NeRF-Ensembles: Impact of Data\n  and Scene Constraints",
                "作者": " Miriam Jäger,  Steven Landgraf,  Boris Jutzi",
                "发布日期": "2023-12-25",
                "摘要": "  In the fields of computer graphics, computer vision and photogrammetry,\nNeural Radiance Fields (NeRFs) are a major topic driving current research and\ndevelopment. However, the quality of NeRF-generated 3D scene reconstructions\nand subsequent surface reconstructions, heavily relies on the network output,\nparticularly the density. Regarding this critical aspect, we propose to utilize\nNeRF-Ensembles that provide a density uncertainty estimate alongside the mean\ndensity. We demonstrate that data constraints such as low-quality images and\nposes lead to a degradation of the training process, increased density\nuncertainty and decreased predicted density. Even with high-quality input data,\nthe density uncertainty varies based on scene constraints such as acquisition\nconstellations, occlusions and material properties. NeRF-Ensembles not only\nprovide a tool for quantifying the uncertainty but exhibit two promising\nadvantages: Enhanced robustness and artifact removal. Through the utilization\nof NeRF-Ensembles instead of single NeRFs, small outliers are removed, yielding\na smoother output with improved completeness of structures. Furthermore,\napplying percentile-based thresholds on density uncertainty outliers proves to\nbe effective for the removal of large (foggy) artifacts in post-processing. We\nconduct our methodology on 3 different datasets: (i) synthetic benchmark\ndataset, (ii) real benchmark dataset, (iii) real data under realistic recording\nconditions and sensors.\n",
                "链接": "https://arxiv.org/abs/2312.14664"
            },
            {
                "文章ID": "124880",
                "标题": "Small Effect Sizes in Malware Detection? Make Harder Train/Test Splits!",
                "作者": " Tirth Patel,  Fred Lu,  Edward Raff,  Charles Nicholas,  Cynthia Matuszek,  James Holt",
                "发布日期": "2023-12-27",
                "摘要": "  Industry practitioners care about small improvements in malware detection\naccuracy because their models are deployed to hundreds of millions of machines,\nmeaning a 0.1\\% change can cause an overwhelming number of false positives.\nHowever, academic research is often restrained to public datasets on the order\nof ten thousand samples and is too small to detect improvements that may be\nrelevant to industry. Working within these constraints, we devise an approach\nto generate a benchmark of configurable difficulty from a pool of available\nsamples. This is done by leveraging malware family information from tools like\nAVClass to construct training/test splits that have different generalization\nrates, as measured by a secondary model. Our experiments will demonstrate that\nusing a less accurate secondary model with disparate features is effective at\nproducing benchmarks for a more sophisticated target model that is under\nevaluation. We also ablate against alternative designs to show the need for our\napproach.\n",
                "链接": "https://arxiv.org/abs/2312.15813"
            },
            {
                "文章ID": "117825",
                "标题": "MRxaI: Black-Box Explainability for Image Classifiers in a Medical\n  Setting",
                "作者": " Nathan Blake,  Hana Chockler,  David A. Kelly,  Santiago Calderon Pena,  Akchunya Chanchal",
                "发布日期": "2023-11-27",
                "摘要": "  Existing tools for explaining the output of image classifiers can be divided\ninto white-box, which rely on access to the model internals, and black-box,\nagnostic to the model. As the usage of AI in the medical domain grows, so too\ndoes the usage of explainability tools. Existing work on medical image\nexplanations focuses on white-box tools, such as gradcam. However, there are\nclear advantages to switching to a black-box tool, including the ability to use\nit with any classifier and the wide selection of black-box tools available. On\nstandard images, black-box tools are as precise as white-box. In this paper we\ncompare the performance of several black-box methods against gradcam on a brain\ncancer MRI dataset. We demonstrate that most black-box tools are not suitable\nfor explaining medical image classifications and present a detailed analysis of\nthe reasons for their shortcomings. We also show that one black-box tool, a\ncausal explainability-based rex, performs as well as \\gradcam.\n",
                "链接": "https://arxiv.org/abs/2311.14471"
            },
            {
                "文章ID": "91634",
                "标题": "A benchmark of categorical encoders for binary classification",
                "作者": " Federico Matteucci,  Vadim Arzamasov,  Klemens Boehm",
                "发布日期": "2023-11-21",
                "摘要": "  Categorical encoders transform categorical features into numerical\nrepresentations that are indispensable for a wide range of machine learning\nmodels. Existing encoder benchmark studies lack generalizability because of\ntheir limited choice of (1) encoders, (2) experimental factors, and (3)\ndatasets. Additionally, inconsistencies arise from the adoption of varying\naggregation strategies. This paper is the most comprehensive benchmark of\ncategorical encoders to date, including an extensive evaluation of 32\nconfigurations of encoders from diverse families, with 36 combinations of\nexperimental factors, and on 50 datasets. The study shows the profound\ninfluence of dataset selection, experimental factors, and aggregation\nstrategies on the benchmark's conclusions -- aspects disregarded in previous\nencoder benchmarks.\n",
                "链接": "https://arxiv.org/abs/2307.09191"
            },
            {
                "文章ID": "114088",
                "标题": "Learning Disentangled Speech Representations",
                "作者": " Yusuf Brima,  Ulf Krumnack,  Simone Pika,  Gunther Heidemann",
                "发布日期": "2023-11-08",
                "摘要": "  Disentangled representation learning from speech remains limited despite its\nimportance in many application domains. A key challenge is the lack of speech\ndatasets with known generative factors to evaluate methods. This paper proposes\nSynSpeech: a novel synthetic speech dataset with ground truth factors enabling\nresearch on disentangling speech representations. We plan to present a\ncomprehensive study evaluating supervised techniques using established\nsupervised disentanglement metrics. This benchmark dataset and framework\naddress the gap in the rigorous evaluation of state-of-the-art disentangled\nspeech representation learning methods. Our findings will provide insights to\nadvance this underexplored area and enable more robust speech representations.\n",
                "链接": "https://arxiv.org/abs/2311.03389"
            },
            {
                "文章ID": "122150",
                "标题": "Can LLM find the green circle? Investigation and Human-guided tool\n  manipulation for compositional generalization",
                "作者": " Min Zhang,  Jianfeng He,  Shuo Lei,  Murong Yue,  Linhang Wang,  Chang-Tien Lu",
                "发布日期": "2023-12-14",
                "摘要": "  The meaning of complex phrases in natural language is composed of their\nindividual components. The task of compositional generalization evaluates a\nmodel's ability to understand new combinations of components. Previous studies\ntrained smaller, task-specific models, which exhibited poor generalization.\nWhile large language models (LLMs) exhibit impressive generalization abilities\non many tasks through in-context learning (ICL), their potential for\ncompositional generalization remains unexplored. In this paper, we first\nempirically investigate prevailing ICL methods in compositional generalization.\nWe find that they struggle with complex compositional questions due to\ncumulative errors in long reasoning steps and intricate logic required for\ntool-making. Consequently, we propose a human-guided tool manipulation\nframework (HTM) that generates tools for sub-questions and integrates multiple\ntools. Our method enhances the effectiveness of tool creation and usage with\nminimal human effort. Experiments show that our method achieves\nstate-of-the-art performance on two compositional generalization benchmarks and\noutperforms existing methods on the most challenging test split by 70%.\n",
                "链接": "https://arxiv.org/abs/2312.07763"
            },
            {
                "文章ID": "117605",
                "标题": "3D-MIR: A Benchmark and Empirical Study on 3D Medical Image Retrieval in\n  Radiology",
                "作者": " Asma Ben Abacha,  Alberto Santamaria-Pang,  Ho Hin Lee,  Jameson Merkow,  Qin Cai,  Surya Teja Devarakonda,  Abdullah Islam,  Julia Gong,  Matthew P. Lungren,  Thomas Lin,  Noel C Codella,  Ivan Tarapov",
                "发布日期": "2023-11-27",
                "摘要": "  The increasing use of medical imaging in healthcare settings presents a\nsignificant challenge due to the increasing workload for radiologists, yet it\nalso offers opportunity for enhancing healthcare outcomes if effectively\nleveraged. 3D image retrieval holds potential to reduce radiologist workloads\nby enabling clinicians to efficiently search through diagnostically similar or\notherwise relevant cases, resulting in faster and more precise diagnoses.\nHowever, the field of 3D medical image retrieval is still emerging, lacking\nestablished evaluation benchmarks, comprehensive datasets, and thorough\nstudies. This paper attempts to bridge this gap by introducing a novel\nbenchmark for 3D Medical Image Retrieval (3D-MIR) that encompasses four\ndifferent anatomies imaged with computed tomography. Using this benchmark, we\nexplore a diverse set of search strategies that use aggregated 2D slices, 3D\nvolumes, and multi-modal embeddings from popular multi-modal foundation models\nas queries. Quantitative and qualitative assessments of each approach are\nprovided alongside an in-depth discussion that offers insight for future\nresearch. To promote the advancement of this field, our benchmark, dataset, and\ncode are made publicly available.\n",
                "链接": "https://arxiv.org/abs/2311.13752"
            },
            {
                "文章ID": "104834",
                "标题": "Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph\n  Question Answering Systems",
                "作者": " Catherine Kosten,  Philippe Cudré-Mauroux,  Kurt Stockinger",
                "发布日期": "2023-12-11",
                "摘要": "  With the recent spike in the number and availability of Large Language Models\n(LLMs), it has become increasingly important to provide large and realistic\nbenchmarks for evaluating Knowledge Graph Question Answering (KGQA) systems. So\nfar the majority of benchmarks rely on pattern-based SPARQL query generation\napproaches. The subsequent natural language (NL) question generation is\nconducted through crowdsourcing or other automated methods, such as rule-based\nparaphrasing or NL question templates. Although some of these datasets are of\nconsiderable size, their pitfall lies in their pattern-based generation\napproaches, which do not always generalize well to the vague and linguistically\ndiverse questions asked by humans in real-world contexts. In this paper, we\nintroduce Spider4SPARQL - a new SPARQL benchmark dataset featuring 9,693\npreviously existing manually generated NL questions and 4,721 unique, novel,\nand complex SPARQL queries of varying complexity. In addition to the NL/SPARQL\npairs, we also provide their corresponding 166 knowledge graphs and ontologies,\nwhich cover 138 different domains. Our complex benchmark enables novel ways of\nevaluating the strengths and weaknesses of modern KGQA systems. We evaluate the\nsystem with state-of-the-art KGQA systems as well as LLMs, which achieve only\nup to 45\\% execution accuracy, demonstrating that Spider4SPARQL is a\nchallenging benchmark for future research.\n",
                "链接": "https://arxiv.org/abs/2309.16248"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下工具评测相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "25887",
                "标题": "Diagnostic Tool for Out-of-Sample Model Evaluation",
                "作者": " Ludvig Hult,  Dave Zachariah,  Petre Stoica",
                "发布日期": "2023-10-17",
                "摘要": "  Assessment of model fitness is a key part of machine learning. The standard\nparadigm is to learn models by minimizing a chosen loss function averaged over\ntraining data, with the aim of achieving small losses on future data. In this\npaper, we consider the use of a finite calibration data set to characterize the\nfuture, out-of-sample losses of a model. We propose a simple model diagnostic\ntool that provides finite-sample guarantees under weak assumptions. The tool is\nsimple to compute and to interpret. Several numerical experiments are presented\nto show how the proposed method quantifies the impact of distribution shifts,\naids the analysis of regression, and enables model selection as well as\nhyper-parameter tuning.\n",
                "链接": "https://arxiv.org/abs/2206.10982"
            },
            {
                "文章ID": "34033",
                "标题": "SimLDA: A tool for topic model evaluation",
                "作者": " Rebecca M. C. Taylor,  Johan A. du Preez",
                "发布日期": "2022-08-22",
                "摘要": "  Variational Bayes (VB) applied to latent Dirichlet allocation (LDA) has\nbecome the most popular algorithm for aspect modeling. While sufficiently\nsuccessful in text topic extraction from large corpora, VB is less successful\nin identifying aspects in the presence of limited data. We present a novel\nvariational message passing algorithm as applied to Latent Dirichlet Allocation\n(LDA) and compare it with the gold standard VB and collapsed Gibbs sampling. In\nsituations where marginalisation leads to non-conjugate messages, we use ideas\nfrom sampling to derive approximate update equations. In cases where conjugacy\nholds, Loopy Belief update (LBU) (also known as Lauritzen-Spiegelhalter) is\nused. Our algorithm, ALBU (approximate LBU), has strong similarities with\nVariational Message Passing (VMP) (which is the message passing variant of VB).\nTo compare the performance of the algorithms in the presence of limited data,\nwe use data sets consisting of tweets and news groups. Using coherence measures\nwe show that ALBU learns latent distributions more accurately than does VB,\nespecially for smaller data sets.\n",
                "链接": "https://arxiv.org/abs/2208.09299"
            },
            {
                "文章ID": "13217",
                "标题": "Seemo: A new tool for early design window view satisfaction evaluation\n  in residential buildings",
                "作者": " Jaeha Kim,  Michael Kent,  Katharina Kral,  Timur Dogan",
                "发布日期": "2022-04-05",
                "摘要": "  People spend approximately 90% of their lives indoors, and thus arguably, the\nindoor space design can significantly influence occupant well-being. Adequate\nviews to the outside are one of the most cited indoor qualities related to\noccupant well-being. However, due to urbanization and densification trends,\ndesigners may have difficulties in providing vistas and views to the outside\nwith an assortment of content, which can support the needs of their occupants.\nTo better understand occupant view satisfaction and provide reliable design\nfeedback to architects, existing view satisfaction data must be expanded to\ncapture a wider variety of view scenarios and occupants. Most related research\nremains challenging in architectural practice due to a lack of easy-to-use\nearly-design analysis tools. However, early assessment of view can be\nadvantageous as design decisions in early design, such as building orientation,\nplan layout, and facade design, can improve the view quality. This paper,\nhence, presents results from a 181 participant view satisfaction survey with\n590 window views. The survey data is used to train a tree-regression model to\npredict view satisfaction. The prediction performance was compared to an\nexisting view assessment framework through case studies. The result showed that\nthe new prediction is more accurate to the surveyed result than the framework.\nFurther, the prediction performance was generally high for most responses,\nverifying the reliability. To facilitate view analysis in early design, this\npaper describes integrating the satisfaction prediction model and a ray-casting\ntool to compute view parameters in the CAD environment.\n",
                "链接": "https://arxiv.org/abs/2204.01164"
            },
            {
                "文章ID": "108993",
                "标题": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
                "作者": " Alon Jacovi,  Avi Caciularu,  Jonathan Herzig,  Roee Aharoni,  Bernd Bohnet,  Mor Geva",
                "发布日期": "2023-12-29",
                "摘要": "  A growing area of research investigates augmenting language models with tools\n(e.g., search engines, calculators) to overcome their shortcomings (e.g.,\nmissing or incorrect knowledge, incorrect logical inferences). Various few-shot\ntool-usage strategies have been proposed. However, there is no systematic and\nfair comparison across different strategies, or between these strategies and\nstrong baselines that do not leverage tools. We conduct an extensive empirical\nanalysis, finding that (1) across various datasets, example difficulty levels,\nand models, strong no-tool baselines are competitive to tool-assisted\nstrategies, implying that effectively using tools with in-context\ndemonstrations is a difficult unsolved problem; (2) for knowledge-retrieval\ntasks, strategies that *refine* incorrect outputs with tools outperform\nstrategies that retrieve relevant information *ahead of* or *during\ngeneration*; (3) tool-assisted strategies are expensive in the number of tokens\nthey require to work -- incurring additional costs by orders of magnitude --\nwhich does not translate into significant improvement in performance. Overall,\nour findings suggest that few-shot tool integration is still an open challenge,\nemphasizing the need for comprehensive evaluations of future strategies to\naccurately assess their *benefits* and *costs*.\n",
                "链接": "https://arxiv.org/abs/2310.10062"
            },
            {
                "文章ID": "81655",
                "标题": "Game of Tones: Faculty detection of GPT-4 generated content in\n  university assessments",
                "作者": " Mike Perkins,  Jasper Roe,  Darius Postma,  James McGaughran,  Don Hickerson",
                "发布日期": "2023-11-02",
                "摘要": "  This study explores the robustness of university assessments against the use\nof Open AI's Generative Pre-Trained Transformer 4 (GPT-4) generated content and\nevaluates the ability of academic staff to detect its use when supported by the\nTurnitin Artificial Intelligence (AI) detection tool. The research involved\ntwenty-two GPT-4 generated submissions being created and included in the\nassessment process to be marked by fifteen different faculty members. The study\nreveals that although the detection tool identified 91% of the experimental\nsubmissions as containing some AI-generated content, the total detected content\nwas only 54.8%. This suggests that the use of adversarial techniques regarding\nprompt engineering is an effective method in evading AI detection tools and\nhighlights that improvements to AI detection software are needed. Using the\nTurnitin AI detect tool, faculty reported 54.5% of the experimental submissions\nto the academic misconduct process, suggesting the need for increased awareness\nand training into these tools. Genuine submissions received a mean score of\n54.4, whereas AI-generated content scored 52.3, indicating the comparable\nperformance of GPT-4 in real-life situations. Recommendations include adjusting\nassessment strategies to make them more resistant to the use of AI tools, using\nAI-inclusive assessment where possible, and providing comprehensive training\nprograms for faculty and students. This research contributes to understanding\nthe relationship between AI-generated content and academic assessment, urging\nfurther investigation to preserve academic integrity.\n",
                "链接": "https://arxiv.org/abs/2305.18081"
            },
            {
                "文章ID": "39005",
                "标题": "AI-powered Language Assessment Tools for Dementia",
                "作者": " Mahboobeh Parsapoor,  Muhammad Raisul Alam,  Alex Mihailidis",
                "发布日期": "2022-09-27",
                "摘要": "  The main objective of this paper is to propose an approach for developing an\nArtificial Intelligence (AI)-powered Language Assessment (LA) tool. Such tools\ncan be used to assess language impairments associated with dementia in older\nadults. The Machine Learning (ML) classifiers are the main parts of our\nproposed approach, therefore to develop an accurate tool with high sensitivity\nand specificity, we consider different binary classifiers and evaluate their\nperformances. We also assess the reliability and validity of our approach by\ncomparing the impact of different types of language tasks, features, and\nrecording media on the performance of ML classifiers.\n",
                "链接": "https://arxiv.org/abs/2209.12652"
            },
            {
                "文章ID": "121929",
                "标题": "Navigating the generative AI era: Introducing the AI assessment scale\n  for ethical GenAI assessment",
                "作者": " Mike Perkins,  Leon Furze,  Jasper Roe,  Jason MacVaugh",
                "发布日期": "2023-12-13",
                "摘要": "  Recent developments in Generative Artificial Intelligence (GenAI) have\ncreated a paradigm shift in multiple areas of society, and the use of these\ntechnologies is likely to become a defining feature of education in coming\ndecades. GenAI offers transformative pedagogical opportunities, while\nsimultaneously posing ethical and academic challenges. Against this backdrop,\nwe outline a practical, simple, and sufficiently comprehensive tool to allow\nfor the integration of GenAI tools into educational assessment: the AI\nAssessment Scale (AIAS). The AIAS empowers educators to select the appropriate\nlevel of GenAI usage in assessments based on the learning outcomes they seek to\naddress. The AIAS offers greater clarity and transparency for students and\neducators, provides a fair and equitable policy tool for institutions to work\nwith, and offers a nuanced approach which embraces the opportunities of GenAI\nwhile recognising that there are instances where such tools may not be\npedagogically appropriate or necessary. By adopting a practical, flexible\napproach that can be implemented quickly, the AIAS can form a much-needed\nstarting point to address the current uncertainty and anxiety regarding GenAI\nin education. As a secondary objective, we engage with the current literature\nand advocate for a refocused discourse on GenAI tools in education, one which\nforegrounds how technologies can help support and enhance teaching and\nlearning, which contrasts with the current focus on GenAI as a facilitator of\nacademic misconduct.\n",
                "链接": "https://arxiv.org/abs/2312.07086"
            },
            {
                "文章ID": "27897",
                "标题": "Video-based Surgical Skills Assessment using Long term Tool Tracking",
                "作者": " Mona Fathollahi,  Mohammad Hasan Sarhan,  Ramon Pena,  Lela DiMonte,  Anshu Gupta,  Aishani Ataliwala,  Jocelyn Barker",
                "发布日期": "2022-07-07",
                "摘要": "  Mastering the technical skills required to perform surgery is an extremely\nchallenging task. Video-based assessment allows surgeons to receive feedback on\ntheir technical skills to facilitate learning and development. Currently, this\nfeedback comes primarily from manual video review, which is time-intensive and\nlimits the feasibility of tracking a surgeon's progress over many cases. In\nthis work, we introduce a motion-based approach to automatically assess\nsurgical skills from surgical case video feed. The proposed pipeline first\ntracks surgical tools reliably to create motion trajectories and then uses\nthose trajectories to predict surgeon technical skill levels. The tracking\nalgorithm employs a simple yet effective re-identification module that improves\nID-switch compared to other state-of-the-art methods. This is critical for\ncreating reliable tool trajectories when instruments regularly move on- and\noff-screen or are periodically obscured. The motion-based classification model\nemploys a state-of-the-art self-attention transformer network to capture short-\nand long-term motion patterns that are essential for skill evaluation. The\nproposed method is evaluated on an in-vivo (Cholec80) dataset where an\nexpert-rated GOALS skill assessment of the Calot Triangle Dissection is used as\na quantitative skill measure. We compare transformer-based skill assessment\nwith traditional machine learning approaches using the proposed and\nstate-of-the-art tracking. Our result suggests that using motion trajectories\nfrom reliable tracking methods is beneficial for assessing surgeon skills based\nsolely on video streams.\n",
                "链接": "https://arxiv.org/abs/2207.02247"
            },
            {
                "文章ID": "14389",
                "标题": "TRUE: Re-evaluating Factual Consistency Evaluation",
                "作者": " Or Honovich,  Roee Aharoni,  Jonathan Herzig,  Hagai Taitelbaum,  Doron Kukliansy,  Vered Cohen,  Thomas Scialom,  Idan Szpektor,  Avinatan Hassidim,  Yossi Matias",
                "发布日期": "2022-05-04",
                "摘要": "  Grounded text generation systems often generate text that contains factual\ninconsistencies, hindering their real-world applicability. Automatic factual\nconsistency evaluation may help alleviate this limitation by accelerating\nevaluation cycles, filtering inconsistent outputs and augmenting training data.\nWhile attracting increasing attention, such evaluation metrics are usually\ndeveloped and evaluated in silo for a single task or dataset, slowing their\nadoption. Moreover, previous meta-evaluation protocols focused on system-level\ncorrelations with human annotations, which leave the example-level accuracy of\nsuch metrics unclear. In this work, we introduce TRUE: a comprehensive survey\nand assessment of factual consistency metrics on a standardized collection of\nexisting texts from diverse tasks, manually annotated for factual consistency.\nOur standardization enables an example-level meta-evaluation protocol that is\nmore actionable and interpretable than previously reported correlations,\nyielding clearer quality measures. Across diverse state-of-the-art metrics and\n11 datasets we find that large-scale NLI and question\ngeneration-and-answering-based approaches achieve strong and complementary\nresults. We recommend those methods as a starting point for model and metric\ndevelopers, and hope TRUE will foster progress towards even better evaluation\nmethods.\n",
                "链接": "https://arxiv.org/abs/2204.04991"
            },
            {
                "文章ID": "25784",
                "标题": "The Right Tool for the Job: Open-Source Auditing Tools in Machine\n  Learning",
                "作者": " Cherie M Poland",
                "发布日期": "2022-06-23",
                "摘要": "  In recent years, discussions about fairness in machine learning, AI ethics\nand algorithm audits have increased. Many entities have developed framework\nguidance to establish a baseline rubric for fairness and accountability.\nHowever, in spite of increased discussions and multiple frameworks, algorithm\nand data auditing still remain difficult to execute in practice. Many\nopen-source auditing tools are available, but users aren't always aware of the\ntools, what they are useful for, or how to access them. Model auditing and\nevaluation are not frequently emphasized skills in machine learning. There are\nalso legal reasons for the proactive adoption of these tools that extend beyond\nthe desire for greater fairness in machine learning. There are positive social\nissues of public perception and goodwill that matter in our highly connected\nglobal society. Greater awareness of these tools and the reasons for actively\nutilizing them may be helpful to the entire continuum of programmers, data\nscientists, engineers, researchers, users and consumers of AI and machine\nlearning products. It is important for everyone to better understand the input\nand output differentials, how they are occurring, and what can be done to\npromote FATE (fairness, accountability, transparency, and ethics) in machine-\nand deep learning. The ability to freely access open-source auditing tools\nremoves barriers to fairness assessment at the most basic levels of machine\nlearning. This paper aims to reinforce the urgent need to actually use these\ntools and provides motivations for doing so. The exemplary tools highlighted\nherein are open-source with software or code-base repositories available that\ncan be used immediately by anyone worldwide.\n",
                "链接": "https://arxiv.org/abs/2206.10613"
            }
        ]
    },
    {
        "question": {
            "question": "大模型在游戏方面的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "122132",
                "标题": "Scaling Culture in Blockchain Gaming: Generative AI and Pseudonymous\n  Engagement",
                "作者": " Henrik Axelsen,  Sebastian Axelsen,  Valdemar Licht,  Jason Potts",
                "发布日期": "2023-12-14",
                "摘要": "  Managing rapidly growing decentralized gaming communities brings unique\nchallenges at the nexus of cultural economics and technology. This paper\nintroduces a streamlined analytical framework that utilizes Large Language\nModels (LLMs), in this instance open-access generative pre-trained transformer\n(GPT) models, offering an efficient solution with deeper insights into\ncommunity dynamics. The framework aids moderators in identifying pseudonymous\nactor intent, moderating toxic behavior, rewarding desired actions to avoid\nunintended consequences of blockchain-based gaming, and gauging community\nsentiment as communities venture into metaverse platforms and plan for\nhypergrowth. This framework strengthens community controls, eases onboarding,\nand promotes a common moral mission across communities while reducing agency\ncosts by 95 pct. Highlighting the transformative role of generative AI, the\npaper emphasizes its potential to redefine the cost of cultural production. It\nshowcases the utility of GPTs in digital community management, expanding their\nimplications in cultural economics and transmedia storytelling.\n",
                "链接": "https://arxiv.org/abs/2312.07693"
            },
            {
                "文章ID": "102747",
                "标题": "MindAgent: Emergent Gaming Interaction",
                "作者": " Ran Gong,  Qiuyuan Huang,  Xiaojian Ma,  Hoi Vo,  Zane Durante,  Yusuke Noda,  Zilong Zheng,  Song-Chun Zhu,  Demetri Terzopoulos,  Li Fei-Fei,  Jianfeng Gao",
                "发布日期": "2023-09-20",
                "摘要": "  Large Language Models (LLMs) have the capacity of performing complex\nscheduling in a multi-agent system and can coordinate these agents into\ncompleting sophisticated tasks that require extensive collaboration. However,\ndespite the introduction of numerous gaming frameworks, the community has\ninsufficient benchmarks towards building general multi-agents collaboration\ninfrastructure that encompass both LLM and human-NPCs collaborations. In this\nwork, we propose a novel infrastructure - MindAgent - to evaluate planning and\ncoordination emergent capabilities for gaming interaction. In particular, our\ninfrastructure leverages existing gaming framework, to i) require understanding\nof the coordinator for a multi-agent system, ii) collaborate with human players\nvia un-finetuned proper instructions, and iii) establish an in-context learning\non few-shot prompt with feedback. Furthermore, we introduce CUISINEWORLD, a new\ngaming scenario and related benchmark that dispatch a multi-agent collaboration\nefficiency and supervise multiple agents playing the game simultaneously. We\nconduct comprehensive evaluations with new auto-metric CoS for calculating the\ncollaboration efficiency. Finally, our infrastructure can be deployed into\nreal-world gaming scenarios in a customized VR version of CUISINEWORLD and\nadapted in existing broader Minecraft gaming domain. We hope our findings on\nLLMs and the new infrastructure for general-purpose scheduling and coordination\ncan help shed light on how such skills can be obtained by learning from large\nlanguage corpora.\n",
                "链接": "https://arxiv.org/abs/2309.09971"
            },
            {
                "文章ID": "55440",
                "标题": "Measuring and Estimating Key Quality Indicators in Cloud Gaming services",
                "作者": " Carlos Baena,  O. S. Peñaherrera-Pulla,  Raquel Barco,  Sergio Fortes",
                "发布日期": "2023-05-11",
                "摘要": "  User equipment is one of the main bottlenecks facing the gaming industry\nnowadays. The extremely realistic games which are currently available trigger\nhigh computational requirements of the user devices to run games. As a\nconsequence, the game industry has proposed the concept of Cloud Gaming, a\nparadigm that improves gaming experience in reduced hardware devices. To this\nend, games are hosted on remote servers, relegating users' devices to play only\nthe role of a peripheral for interacting with the game. However, this paradigm\noverloads the communication links connecting the users with the cloud.\nTherefore, service experience becomes highly dependent on network connectivity.\nTo overcome this, Cloud Gaming will be boosted by the promised performance of\n5G and future 6G networks, together with the flexibility provided by mobility\nin multi-RAT scenarios, such as WiFi. In this scope, the present work proposes\na framework for measuring and estimating the main E2E metrics of the Cloud\nGaming service, namely KQIs. In addition, different machine learning techniques\nare assessed for predicting KQIs related to Cloud Gaming user's experience. To\nthis end, the main key quality indicators (KQIs) of the service such as input\nlag, freeze percent or perceived video frame rate are collected in a real\nenvironment. Based on these, results show that machine learning techniques\nprovide a good estimation of these indicators solely from network-based\nmetrics. This is considered a valuable asset to guide the delivery of Cloud\nGaming services through cellular communications networks even without access to\nthe user's device, as it is expected for telecom operators.\n",
                "链接": "https://arxiv.org/abs/2212.14073"
            },
            {
                "文章ID": "12922",
                "标题": "Perceptual Quality Assessment of UGC Gaming Videos",
                "作者": " Xiangxu Yu,  Zhengzhong Tu,  Neil Birkbeck,  Yilin Wang,  Balu Adsumilli,  Alan C. Bovik",
                "发布日期": "2022-04-15",
                "摘要": "  In recent years, with the vigorous development of the video game industry,\nthe proportion of gaming videos on major video websites like YouTube has\ndramatically increased. However, relatively little research has been done on\nthe automatic quality prediction of gaming videos, especially on those that\nfall in the category of \"User-Generated-Content\" (UGC). Since current leading\ngeneral-purpose Video Quality Assessment (VQA) models do not perform well on\nthis type of gaming videos, we have created a new VQA model specifically\ndesigned to succeed on UGC gaming videos, which we call the Gaming Video\nQuality Predictor (GAME-VQP). GAME-VQP successfully predicts the unique\nstatistical characteristics of gaming videos by drawing upon features designed\nunder modified natural scene statistics models, combined with gaming specific\nfeatures learned by a Convolution Neural Network. We study the performance of\nGAME-VQP on a very recent large UGC gaming video database called\nLIVE-YT-Gaming, and find that it both outperforms other mainstream general VQA\nmodels as well as VQA models specifically designed for gaming videos. The new\nmodel will be made public after paper being accepted.\n",
                "链接": "https://arxiv.org/abs/2204.00128"
            },
            {
                "文章ID": "86256",
                "标题": "An Analysis of Physiological and Psychological Responses in Virtual\n  Reality and Flat Screen Gaming",
                "作者": " Ritik Vatsal,  Shrivatsa Mishra,  Rushil Thareja,  Mrinmoy Chakrabarty,  Ojaswa Sharma,  Jainendra Shukla",
                "发布日期": "2023-11-16",
                "摘要": "  Recent research has focused on the effectiveness of Virtual Reality (VR) in\ngames as a more immersive method of interaction. However, there is a lack of\nrobust analysis of the physiological effects between VR and flatscreen (FS)\ngaming. This paper introduces the first systematic comparison and analysis of\nemotional and physiological responses to commercially available games in VR and\nFS environments. To elicit these responses, we first selected four games\nthrough a pilot study of 6 participants to cover all four quadrants of the\nvalence-arousal space. Using these games, we recorded the physiological\nactivity, including Blood Volume Pulse and Electrodermal Activity, and\nself-reported emotions of 33 participants in a user study. Our data analysis\nrevealed that VR gaming elicited more pronounced emotions, higher arousal,\nincreased cognitive load and stress, and lower dominance than FS gaming. The\nVirtual Reality and Flat Screen (VRFS) dataset, containing over 15 hours of\nmultimodal data comparing FS and VR gaming across different games, is also made\npublicly available for research purposes. Our analysis provides valuable\ninsights for further investigations into the physiological and emotional\neffects of VR and FS gaming.\n",
                "链接": "https://arxiv.org/abs/2306.09690"
            },
            {
                "文章ID": "48707",
                "标题": "Reward Gaming in Conditional Text Generation",
                "作者": " Richard Yuanzhe Pang,  Vishakh Padmakumar,  Thibault Sellam,  Ankur P. Parikh,  He He",
                "发布日期": "2023-06-02",
                "摘要": "  To align conditional text generation model outputs with desired behaviors,\nthere has been an increasing focus on training the model using reinforcement\nlearning (RL) with reward functions learned from human annotations. Under this\nframework, we identify three common cases where high rewards are incorrectly\nassigned to undesirable patterns: noise-induced spurious correlation, naturally\noccurring spurious correlation, and covariate shift. We show that even though\nlearned metrics achieve high performance on the distribution of the data used\nto train the reward function, the undesirable patterns may be amplified during\nRL training of the text generation model. While there has been discussion about\nreward gaming in the RL or safety community, in this discussion piece, we would\nlike to highlight reward gaming in the natural language generation (NLG)\ncommunity using concrete conditional text generation examples and discuss\npotential fixes and areas for future work.\n",
                "链接": "https://arxiv.org/abs/2211.08714"
            },
            {
                "文章ID": "11430",
                "标题": "Subjective and Objective Analysis of Streamed Gaming Videos",
                "作者": " Xiangxu Yu,  Zhenqiang Ying,  Neil Birkbeck,  Yilin Wang,  Balu Adsumilli,  Alan C. Bovik",
                "发布日期": "2022-03-25",
                "摘要": "  The rising popularity of online User-Generated-Content (UGC) in the form of\nstreamed and shared videos, has hastened the development of perceptual Video\nQuality Assessment (VQA) models, which can be used to help optimize their\ndelivery. Gaming videos, which are a relatively new type of UGC videos, are\ncreated when skilled gamers post videos of their gameplay. These kinds of\nscreenshots of UGC gameplay videos have become extremely popular on major\nstreaming platforms like YouTube and Twitch. Synthetically-generated gaming\ncontent presents challenges to existing VQA algorithms, including those based\non natural scene/video statistics models. Synthetically generated gaming\ncontent presents different statistical behavior than naturalistic videos. A\nnumber of studies have been directed towards understanding the perceptual\ncharacteristics of professionally generated gaming videos arising in gaming\nvideo streaming, online gaming, and cloud gaming. However, little work has been\ndone on understanding the quality of UGC gaming videos, and how it can be\ncharacterized and predicted. Towards boosting the progress of gaming video VQA\nmodel development, we conducted a comprehensive study of subjective and\nobjective VQA models on UGC gaming videos. To do this, we created a novel UGC\ngaming video resource, called the LIVE-YouTube Gaming video quality\n(LIVE-YT-Gaming) database, comprised of 600 real UGC gaming videos. We\nconducted a subjective human study on this data, yielding 18,600 human quality\nratings recorded by 61 human subjects. We also evaluated a number of\nstate-of-the-art (SOTA) VQA models on the new database, including a new one,\ncalled GAME-VQP, based on both natural video statistics and CNN-learned\nfeatures. To help support work in this field, we are making the new\nLIVE-YT-Gaming Database, publicly available through the link:\nhttps://live.ece.utexas.edu/research/LIVE-YT-Gaming/index.html .\n",
                "链接": "https://arxiv.org/abs/2203.12824"
            },
            {
                "文章ID": "75621",
                "标题": "GAMIVAL: Video Quality Prediction on Mobile Cloud Gaming Content",
                "作者": " Yu-Chih Chen,  Avinab Saha,  Chase Davis,  Bo Qiu,  Xiaoming Wang,  Rahul Gowda,  Ioannis Katsavounidis,  Alan C. Bovik",
                "发布日期": "2023-08-31",
                "摘要": "  The mobile cloud gaming industry has been rapidly growing over the last\ndecade. When streaming gaming videos are transmitted to customers' client\ndevices from cloud servers, algorithms that can monitor distorted video quality\nwithout having any reference video available are desirable tools. However,\ncreating No-Reference Video Quality Assessment (NR VQA) models that can\naccurately predict the quality of streaming gaming videos rendered by computer\ngraphics engines is a challenging problem, since gaming content generally\ndiffers statistically from naturalistic videos, often lacks detail, and\ncontains many smooth regions. Until recently, the problem has been further\ncomplicated by the lack of adequate subjective quality databases of mobile\ngaming content. We have created a new gaming-specific NR VQA model called the\nGaming Video Quality Evaluator (GAMIVAL), which combines and leverages the\nadvantages of spatial and temporal gaming distorted scene statistics models, a\nneural noise model, and deep semantic features. Using a support vector\nregression (SVR) as a regressor, GAMIVAL achieves superior performance on the\nnew LIVE-Meta Mobile Cloud Gaming (LIVE-Meta MCG) video quality database.\n",
                "链接": "https://arxiv.org/abs/2305.02422"
            },
            {
                "文章ID": "81335",
                "标题": "Study of Subjective and Objective Quality Assessment of Mobile Cloud\n  Gaming Videos",
                "作者": " Avinab Saha,  Yu-Chih Chen,  Chase Davis,  Bo Qiu,  Xiaoming Wang,  Rahul Gowda,  Ioannis Katsavounidis,  Alan C. Bovik",
                "发布日期": "2023-06-28",
                "摘要": "  We present the outcomes of a recent large-scale subjective study of Mobile\nCloud Gaming Video Quality Assessment (MCG-VQA) on a diverse set of gaming\nvideos. Rapid advancements in cloud services, faster video encoding\ntechnologies, and increased access to high-speed, low-latency wireless internet\nhave all contributed to the exponential growth of the Mobile Cloud Gaming\nindustry. Consequently, the development of methods to assess the quality of\nreal-time video feeds to end-users of cloud gaming platforms has become\nincreasingly important. However, due to the lack of a large-scale public Mobile\nCloud Gaming Video dataset containing a diverse set of distorted videos with\ncorresponding subjective scores, there has been limited work on the development\nof MCG-VQA models. Towards accelerating progress towards these goals, we\ncreated a new dataset, named the LIVE-Meta Mobile Cloud Gaming (LIVE-Meta-MCG)\nvideo quality database, composed of 600 landscape and portrait gaming videos,\non which we collected 14,400 subjective quality ratings from an in-lab\nsubjective study. Additionally, to demonstrate the usefulness of the new\nresource, we benchmarked multiple state-of-the-art VQA algorithms on the\ndatabase. The new database will be made publicly available on our website:\n\\url{https://live.ece.utexas.edu/research/LIVE-Meta-Mobile-Cloud-Gaming/index.html}\n",
                "链接": "https://arxiv.org/abs/2305.17260"
            },
            {
                "文章ID": "94385",
                "标题": "Efficient neural supersampling on a novel gaming dataset",
                "作者": " Antoine Mercier,  Ruan Erasmus,  Yashesh Savani,  Manik Dhingra,  Fatih Porikli,  Guillaume Berger",
                "发布日期": "2023-08-04",
                "摘要": "  Real-time rendering for video games has become increasingly challenging due\nto the need for higher resolutions, framerates and photorealism. Supersampling\nhas emerged as an effective solution to address this challenge. Our work\nintroduces a novel neural algorithm for supersampling rendered content that is\n4 times more efficient than existing methods while maintaining the same level\nof accuracy. Additionally, we introduce a new dataset which provides auxiliary\nmodalities such as motion vectors and depth generated using graphics rendering\nfeatures like viewport jittering and mipmap biasing at different resolutions.\nWe believe that this dataset fills a gap in the current dataset landscape and\ncan serve as a valuable resource to help measure progress in the field and\nadvance the state-of-the-art in super-resolution techniques for gaming content.\n",
                "链接": "https://arxiv.org/abs/2308.01483"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "68991",
                "标题": "Joint fMRI Decoding and Encoding with Latent Embedding Alignment",
                "作者": " Xuelin Qian,  Yikai Wang,  Yanwei Fu,  Xinwei Sun,  Xiangyang Xue,  Jianfeng Feng",
                "发布日期": "2023-06-06",
                "摘要": "  The connection between brain activity and corresponding visual stimuli is\ncrucial in comprehending the human brain. While deep generative models have\nexhibited advancement in recovering brain recordings by generating images\nconditioned on fMRI signals, accomplishing high-quality generation with\nconsistent semantics continues to pose challenges. Moreover, the prediction of\nbrain activity from visual stimuli remains a formidable undertaking. In this\npaper, we introduce a unified framework that addresses both fMRI decoding and\nencoding. Commencing with the establishment of two latent spaces capable of\nrepresenting and reconstructing fMRI signals and visual images, respectively,\nwe proceed to align the fMRI signals and visual images within the latent space,\nthereby enabling a bidirectional transformation between the two domains. Our\nLatent Embedding Alignment (LEA) model concurrently recovers visual stimuli\nfrom fMRI signals and predicts brain activity from images within a unified\nframework. The performance of LEA surpasses that of existing methods on\nmultiple benchmark fMRI decoding and encoding datasets. By integrating fMRI\ndecoding and encoding, LEA offers a comprehensive solution for modeling the\nintricate relationship between brain activity and visual stimuli.\n",
                "链接": "https://arxiv.org/abs/2303.14730"
            },
            {
                "文章ID": "91982",
                "标题": "Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding\n  (Survey)",
                "作者": " Subba Reddy Oota,  Manish Gupta,  Raju S. Bapi,  Gael Jobard,  Frederic Alexandre,  Xavier Hinaut",
                "发布日期": "2023-07-21",
                "摘要": "  How does the brain represent different modes of information? Can we design a\nsystem that automatically understands what the user is thinking? Such questions\ncan be answered by studying brain recordings like functional magnetic resonance\nimaging (fMRI). As a first step, the neuroscience community has contributed\nseveral large cognitive neuroscience datasets related to passive\nreading/listening/viewing of concept words, narratives, pictures and movies.\nEncoding and decoding models using these datasets have also been proposed in\nthe past two decades. These models serve as additional tools for basic research\nin cognitive science and neuroscience. Encoding models aim at generating fMRI\nbrain representations given a stimulus automatically. They have several\npractical applications in evaluating and diagnosing neurological conditions and\nthus also help design therapies for brain damage. Decoding models solve the\ninverse problem of reconstructing the stimuli given the fMRI. They are useful\nfor designing brain-machine or brain-computer interfaces. Inspired by the\neffectiveness of deep learning models for natural language processing, computer\nvision, and speech, recently several neural encoding and decoding models have\nbeen proposed. In this survey, we will first discuss popular representations of\nlanguage, vision and speech stimuli, and present a summary of neuroscience\ndatasets. Further, we will review popular deep learning based encoding and\ndecoding architectures and note their benefits and limitations. Finally, we\nwill conclude with a brief summary and discussion about future trends. Given\nthe large amount of recently published work in the `computational cognitive\nneuroscience' community, we believe that this survey nicely organizes the\nplethora of work and presents it as a coherent story.\n",
                "链接": "https://arxiv.org/abs/2307.10246"
            },
            {
                "文章ID": "5326",
                "标题": "Hierarchical Point Cloud Encoding and Decoding with Lightweight\n  Self-Attention based Model",
                "作者": " En Yen Puang,  Hao Zhang,  Hongyuan Zhu,  Wei Jing",
                "发布日期": "2022-03-16",
                "摘要": "  In this paper we present SA-CNN, a hierarchical and lightweight\nself-attention based encoding and decoding architecture for representation\nlearning of point cloud data. The proposed SA-CNN introduces convolution and\ntransposed convolution stacks to capture and generate contextual information\namong unordered 3D points. Following conventional hierarchical pipeline, the\nencoding process extracts feature in local-to-global manner, while the decoding\nprocess generates feature and point cloud in coarse-to-fine, multi-resolution\nstages. We demonstrate that SA-CNN is capable of a wide range of applications,\nnamely classification, part segmentation, reconstruction, shape retrieval, and\nunsupervised classification. While achieving the state-of-the-art or comparable\nperformance in the benchmarks, SA-CNN maintains its model complexity several\norder of magnitude lower than the others. In term of qualitative results, we\nvisualize the multi-stage point cloud reconstructions and latent walks on rigid\nobjects as well as deformable non-rigid human and robot models.\n",
                "链接": "https://arxiv.org/abs/2202.06407"
            },
            {
                "文章ID": "27998",
                "标题": "PIC 4th Challenge: Semantic-Assisted Multi-Feature Encoding and\n  Multi-Head Decoding for Dense Video Captioning",
                "作者": " Yifan Lu,  Ziqi Zhang,  Yuxin Chen,  Chunfeng Yuan,  Bing Li,  Weiming Hu",
                "发布日期": "2022-08-16",
                "摘要": "  The task of Dense Video Captioning (DVC) aims to generate captions with\ntimestamps for multiple events in one video. Semantic information plays an\nimportant role for both localization and description of DVC. We present a\nsemantic-assisted dense video captioning model based on the encoding-decoding\nframework. In the encoding stage, we design a concept detector to extract\nsemantic information, which is then fused with multi-modal visual features to\nsufficiently represent the input video. In the decoding stage, we design a\nclassification head, paralleled with the localization and captioning heads, to\nprovide semantic supervision. Our method achieves significant improvements on\nthe YouMakeup dataset under DVC evaluation metrics and achieves high\nperformance in the Makeup Dense Video Captioning (MDVC) task of PIC 4th\nChallenge.\n",
                "链接": "https://arxiv.org/abs/2207.02583"
            },
            {
                "文章ID": "58035",
                "标题": "LDMIC: Learning-based Distributed Multi-view Image Coding",
                "作者": " Xinjie Zhang,  Jiawei Shao,  Jun Zhang",
                "发布日期": "2023-04-13",
                "摘要": "  Multi-view image compression plays a critical role in 3D-related\napplications. Existing methods adopt a predictive coding architecture, which\nrequires joint encoding to compress the corresponding disparity as well as\nresidual information. This demands collaboration among cameras and enforces the\nepipolar geometric constraint between different views, which makes it\nchallenging to deploy these methods in distributed camera systems with randomly\noverlapping fields of view. Meanwhile, distributed source coding theory\nindicates that efficient data compression of correlated sources can be achieved\nby independent encoding and joint decoding, which motivates us to design a\nlearning-based distributed multi-view image coding (LDMIC) framework. With\nindependent encoders, LDMIC introduces a simple yet effective joint context\ntransfer module based on the cross-attention mechanism at the decoder to\neffectively capture the global inter-view correlations, which is insensitive to\nthe geometric relationships between images. Experimental results show that\nLDMIC significantly outperforms both traditional and learning-based MIC methods\nwhile enjoying fast encoding speed. Code will be released at\nhttps://github.com/Xinjie-Q/LDMIC.\n",
                "链接": "https://arxiv.org/abs/2301.09799"
            },
            {
                "文章ID": "48865",
                "标题": "Testing for context-dependent changes in neural encoding in naturalistic\n  experiments",
                "作者": " Yenho Chen,  Carl W. Harris,  Xiaoyu Ma,  Zheng Li,  Francisco Pereira,  Charles Y. Zheng",
                "发布日期": "2022-11-18",
                "摘要": "  We propose a decoding-based approach to detect context effects on neural\ncodes in longitudinal neural recording data. The approach is agnostic to how\ninformation is encoded in neural activity, and can control for a variety of\npossible confounding factors present in the data. We demonstrate our approach\nby determining whether it is possible to decode location encoding from\nprefrontal cortex in the mouse and, further, testing whether the encoding\nchanges due to task engagement.\n",
                "链接": "https://arxiv.org/abs/2211.09295"
            },
            {
                "文章ID": "67824",
                "标题": "Low-complexity Deep Video Compression with A Distributed Coding\n  Architecture",
                "作者": " Xinjie Zhang,  Jiawei Shao,  Jun Zhang",
                "发布日期": "2023-04-04",
                "摘要": "  Prevalent predictive coding-based video compression methods rely on a heavy\nencoder to reduce temporal redundancy, which makes it challenging to deploy\nthem on resource-constrained devices. Since the 1970s, distributed source\ncoding theory has indicated that independent encoding and joint decoding with\nside information (SI) can achieve high-efficient compression of correlated\nsources. This has inspired a distributed coding architecture aiming at reducing\nthe encoding complexity. However, traditional distributed coding methods suffer\nfrom a substantial performance gap to predictive coding ones. Inspired by the\ngreat success of learning-based compression, we propose the first end-to-end\ndistributed deep video compression framework to improve the rate-distortion\nperformance. A key ingredient is an effective SI generation module at the\ndecoder, which helps to effectively exploit inter-frame correlations without\ncomputation-intensive encoder-side motion estimation and compensation.\nExperiments show that our method significantly outperforms conventional\ndistributed video coding and H.264. Meanwhile, it enjoys 6-7x encoding speedup\nagainst DVC [1] with comparable compression performance. Code is released at\nhttps://github.com/Xinjie-Q/Distributed-DVC.\n",
                "链接": "https://arxiv.org/abs/2303.11599"
            },
            {
                "文章ID": "124135",
                "标题": "Computational Spectral Imaging with Unified Encoding Model: A\n  Comparative Study and Beyond",
                "作者": " Xinyuan Liu,  Lizhi Wang,  Lingen Li,  Chang Chen,  Xue Hu,  Fenglong Song,  Youliang Yan",
                "发布日期": "2023-12-22",
                "摘要": "  Computational spectral imaging is drawing increasing attention owing to the\nsnapshot advantage, and amplitude, phase, and wavelength encoding systems are\nthree types of representative implementations. Fairly comparing and\nunderstanding the performance of these systems is essential, but challenging\ndue to the heterogeneity in encoding design. To overcome this limitation, we\npropose the unified encoding model (UEM) that covers all physical systems using\nthe three encoding types. Specifically, the UEM comprises physical amplitude,\nphysical phase, and physical wavelength encoding models that can be combined\nwith a digital decoding model in a joint encoder-decoder optimization framework\nto compare the three systems under a unified experimental setup fairly.\nFurthermore, we extend the UEMs to ideal versions, namely, ideal amplitude,\nideal phase, and ideal wavelength encoding models, which are free from physical\nconstraints, to explore the full potential of the three types of computational\nspectral imaging systems. Finally, we conduct a holistic comparison of the\nthree types of computational spectral imaging systems and provide valuable\ninsights for designing and exploiting these systems in the future.\n",
                "链接": "https://arxiv.org/abs/2312.13310"
            },
            {
                "文章ID": "81153",
                "标题": "Efficient Decoding of Compositional Structure in Holistic\n  Representations",
                "作者": " Denis Kleyko,  Connor Bybee,  Ping-Chen Huang,  Christopher J. Kymn,  Bruno A. Olshausen,  E. Paxon Frady,  Friedrich T. Sommer",
                "发布日期": "2023-05-29",
                "摘要": "  We investigate the task of retrieving information from compositional\ndistributed representations formed by Hyperdimensional Computing/Vector\nSymbolic Architectures and present novel techniques which achieve new\ninformation rate bounds. First, we provide an overview of the decoding\ntechniques that can be used to approach the retrieval task. The techniques are\ncategorized into four groups. We then evaluate the considered techniques in\nseveral settings that involve, e.g., inclusion of external noise and storage\nelements with reduced precision. In particular, we find that the decoding\ntechniques from the sparse coding and compressed sensing literature (rarely\nused for Hyperdimensional Computing/Vector Symbolic Architectures) are also\nwell-suited for decoding information from the compositional distributed\nrepresentations. Combining these decoding techniques with interference\ncancellation ideas from communications improves previously reported bounds\n(Hersche et al., 2021) of the information rate of the distributed\nrepresentations from 1.20 to 1.40 bits per dimension for smaller codebooks and\nfrom 0.60 to 1.26 bits per dimension for larger codebooks.\n",
                "链接": "https://arxiv.org/abs/2305.16873"
            },
            {
                "文章ID": "17492",
                "标题": "Quality-Aware Decoding for Neural Machine Translation",
                "作者": " Patrick Fernandes,  António Farinhas,  Ricardo Rei,  José G. C. de Souza,  Perez Ogayo,  Graham Neubig,  André F. T. Martins",
                "发布日期": "2022-05-03",
                "摘要": "  Despite the progress in machine translation quality estimation and evaluation\nin the last years, decoding in neural machine translation (NMT) is mostly\noblivious to this and centers around finding the most probable translation\naccording to the model (MAP decoding), approximated with beam search. In this\npaper, we bring together these two lines of research and propose quality-aware\ndecoding for NMT, by leveraging recent breakthroughs in reference-free and\nreference-based MT evaluation through various inference methods like $N$-best\nreranking and minimum Bayes risk decoding. We perform an extensive comparison\nof various possible candidate generation and ranking methods across four\ndatasets and two model classes and find that quality-aware decoding\nconsistently outperforms MAP-based decoding according both to state-of-the-art\nautomatic metrics (COMET and BLEURT) and to human assessments. Our code is\navailable at https://github.com/deep-spin/qaware-decode.\n",
                "链接": "https://arxiv.org/abs/2205.00978"
            }
        ]
    },
    {
        "question": {
            "question": "请找到缓和噪声标签影响的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "123805",
                "标题": "FedDiv: Collaborative Noise Filtering for Federated Learning with Noisy\n  Labels",
                "作者": " Jichang Li,  Guanbin Li,  Hui Cheng,  Zicheng Liao,  Yizhou Yu",
                "发布日期": "2023-12-21",
                "摘要": "  Federated learning with noisy labels (F-LNL) aims at seeking an optimal\nserver model via collaborative distributed learning by aggregating multiple\nclient models trained with local noisy or clean samples. On the basis of a\nfederated learning framework, recent advances primarily adopt label noise\nfiltering to separate clean samples from noisy ones on each client, thereby\nmitigating the negative impact of label noise. However, these prior methods do\nnot learn noise filters by exploiting knowledge across all clients, leading to\nsub-optimal and inferior noise filtering performance and thus damaging training\nstability. In this paper, we present FedDiv to tackle the challenges of F-LNL.\nSpecifically, we propose a global noise filter called Federated Noise Filter\nfor effectively identifying samples with noisy labels on every client, thereby\nraising stability during local training sessions. Without sacrificing data\nprivacy, this is achieved by modeling the global distribution of label noise\nacross all clients. Then, in an effort to make the global model achieve higher\nperformance, we introduce a Predictive Consistency based Sampler to identify\nmore credible local data for local model training, thus preventing noise\nmemorization and further boosting the training stability. Extensive experiments\non CIFAR-10, CIFAR-100, and Clothing1M demonstrate that \\texttt{FedDiv}\nachieves superior performance over state-of-the-art F-LNL methods under\ndifferent label noise settings for both IID and non-IID data partitions. Source\ncode is publicly available at https://github.com/lijichang/FLNL-FedDiv.\n",
                "链接": "https://arxiv.org/abs/2312.12263"
            },
            {
                "文章ID": "111388",
                "标题": "Label Propagation for Graph Label Noise",
                "作者": " Yao Cheng,  Caihua Shan,  Yifei Shen,  Xiang Li,  Siqiang Luo,  Dongsheng Li",
                "发布日期": "2023-10-26",
                "摘要": "  Label noise is a common challenge in large datasets, as it can significantly\ndegrade the generalization ability of deep neural networks. Most existing\nstudies focus on noisy labels in computer vision; however, graph models\nencompass both node features and graph topology as input, and become more\nsusceptible to label noise through message-passing mechanisms. Recently, only a\nfew works have been proposed to tackle the label noise on graphs. One major\nlimitation is that they assume the graph is homophilous and the labels are\nsmoothly distributed. Nevertheless, real-world graphs may contain varying\ndegrees of heterophily or even be heterophily-dominated, leading to the\ninadequacy of current methods. In this paper, we study graph label noise in the\ncontext of arbitrary heterophily, with the aim of rectifying noisy labels and\nassigning labels to previously unlabeled nodes. We begin by conducting two\nempirical analyses to explore the impact of graph homophily on graph label\nnoise. Following observations, we propose a simple yet efficient algorithm,\ndenoted as LP4GLN. Specifically, LP4GLN is an iterative algorithm with three\nsteps: (1) reconstruct the graph to recover the homophily property, (2) utilize\nlabel propagation to rectify the noisy labels, (3) select high-confidence\nlabels to retain for the next iteration. By iterating these steps, we obtain a\nset of correct labels, ultimately achieving high accuracy in the node\nclassification task. The theoretical analysis is also provided to demonstrate\nits remarkable denoising \"effect\". Finally, we conduct experiments on 10\nbenchmark datasets under varying graph heterophily levels and noise types,\ncomparing the performance of LP4GLN with 7 typical baselines. Our results\nillustrate the superior performance of the proposed LP4GLN.\n",
                "链接": "https://arxiv.org/abs/2310.16560"
            },
            {
                "文章ID": "78327",
                "标题": "NoisywikiHow: A Benchmark for Learning with Real-world Noisy Labels in\n  Natural Language Processing",
                "作者": " Tingting Wu,  Xiao Ding,  Minji Tang,  Hao Zhang,  Bing Qin,  Ting Liu",
                "发布日期": "2023-05-19",
                "摘要": "  Large-scale datasets in the real world inevitably involve label noise. Deep\nmodels can gradually overfit noisy labels and thus degrade model\ngeneralization. To mitigate the effects of label noise, learning with noisy\nlabels (LNL) methods are designed to achieve better generalization performance.\nDue to the lack of suitable datasets, previous studies have frequently employed\nsynthetic label noise to mimic real-world label noise. However, synthetic noise\nis not instance-dependent, making this approximation not always effective in\npractice. Recent research has proposed benchmarks for learning with real-world\nnoisy labels. However, the noise sources within may be single or fuzzy, making\nbenchmarks different from data with heterogeneous label noises in the real\nworld. To tackle these issues, we contribute NoisywikiHow, the largest NLP\nbenchmark built with minimal supervision. Specifically, inspired by human\ncognition, we explicitly construct multiple sources of label noise to imitate\nhuman errors throughout the annotation, replicating real-world noise, whose\ncorruption is affected by both ground-truth labels and instances. Moreover, we\nprovide a variety of noise levels to support controlled experiments on noisy\ndata, enabling us to evaluate LNL methods systematically and comprehensively.\nAfter that, we conduct extensive multi-dimensional experiments on a broad range\nof LNL methods, obtaining new and intriguing findings.\n",
                "链接": "https://arxiv.org/abs/2305.10709"
            },
            {
                "文章ID": "82321",
                "标题": "Label-Retrieval-Augmented Diffusion Models for Learning from Noisy\n  Labels",
                "作者": " Jian Chen,  Ruiyi Zhang,  Tong Yu,  Rohan Sharma,  Zhiqiang Xu,  Tong Sun,  Changyou Chen",
                "发布日期": "2023-12-05",
                "摘要": "  Learning from noisy labels is an important and long-standing problem in\nmachine learning for real applications. One of the main research lines focuses\non learning a label corrector to purify potential noisy labels. However, these\nmethods typically rely on strict assumptions and are limited to certain types\nof label noise. In this paper, we reformulate the label-noise problem from a\ngenerative-model perspective, $\\textit{i.e.}$, labels are generated by\ngradually refining an initial random guess. This new perspective immediately\nenables existing powerful diffusion models to seamlessly learn the stochastic\ngenerative process. Once the generative uncertainty is modeled, we can perform\nclassification inference using maximum likelihood estimation of labels. To\nmitigate the impact of noisy labels, we propose the\n$\\textbf{L}$abel-$\\textbf{R}$etrieval-$\\textbf{A}$ugmented (LRA) diffusion\nmodel, which leverages neighbor consistency to effectively construct\npseudo-clean labels for diffusion training. Our model is flexible and general,\nallowing easy incorporation of different types of conditional information,\n$\\textit{e.g.}$, use of pre-trained models, to further boost model performance.\nExtensive experiments are conducted for evaluation. Our model achieves new\nstate-of-the-art (SOTA) results on all the standard real-world benchmark\ndatasets. Remarkably, by incorporating conditional information from the\npowerful CLIP model, our method can boost the current SOTA accuracy by 10-20\nabsolute points in many cases.\n",
                "链接": "https://arxiv.org/abs/2305.19518"
            },
            {
                "文章ID": "105104",
                "标题": "Understanding and Mitigating the Label Noise in Pre-training on\n  Downstream Tasks",
                "作者": " Hao Chen,  Jindong Wang,  Ankit Shah,  Ran Tao,  Hongxin Wei,  Xing Xie,  Masashi Sugiyama,  Bhiksha Raj",
                "发布日期": "2023-10-02",
                "摘要": "  Pre-training on large-scale datasets and then fine-tuning on downstream tasks\nhave become a standard practice in deep learning. However, pre-training data\noften contain label noise that may adversely affect the generalization of the\nmodel. This paper aims to understand the nature of noise in pre-training\ndatasets and to mitigate its impact on downstream tasks. More specifically,\nthrough extensive experiments of supervised pre-training models on synthetic\nnoisy ImageNet-1K and YFCC15M datasets, we demonstrate that while slight noise\nin pre-training can benefit in-domain (ID) transfer performance, where the\ntraining and testing data share the same distribution, it always deteriorates\nout-of-domain (OOD) performance, where training and testing data distribution\nare different. We empirically verify that the reason behind is noise in\npre-training shapes the feature space differently. We then propose a\nlightweight black-box tuning method (NMTune) to affine the feature space to\nmitigate the malignant effect of noise and improve generalization on both ID\nand OOD tasks, considering one may not be able to fully fine-tune or even\naccess the pre-trained models. We conduct practical experiments on popular\nvision and language models that are pre-trained on noisy data for evaluation of\nour approach. Our analysis and results show the importance of this interesting\nand novel research direction, which we term Noisy Model Learning.\n",
                "链接": "https://arxiv.org/abs/2309.17002"
            },
            {
                "文章ID": "2704",
                "标题": "PARS: Pseudo-Label Aware Robust Sample Selection for Learning with Noisy\n  Labels",
                "作者": " Arushi Goel,  Yunlong Jiao,  Jordan Massiah",
                "发布日期": "2022-01-27",
                "摘要": "  Acquiring accurate labels on large-scale datasets is both time consuming and\nexpensive. To reduce the dependency of deep learning models on learning from\nclean labeled data, several recent research efforts are focused on learning\nwith noisy labels. These methods typically fall into three design categories to\nlearn a noise robust model: sample selection approaches, noise robust loss\nfunctions, or label correction methods. In this paper, we propose PARS:\nPseudo-Label Aware Robust Sample Selection, a hybrid approach that combines the\nbest from all three worlds in a joint-training framework to achieve robustness\nto noisy labels. Specifically, PARS exploits all training samples using both\nthe raw/noisy labels and estimated/refurbished pseudo-labels via self-training,\ndivides samples into an ambiguous and a noisy subset via loss analysis, and\ndesigns label-dependent noise-aware loss functions for both sets of filtered\nlabels. Results show that PARS significantly outperforms the state of the art\non extensive studies on the noisy CIFAR-10 and CIFAR-100 datasets, particularly\non challenging high-noise and low-resource settings. In particular, PARS\nachieved an absolute 12% improvement in test accuracy on the CIFAR-100 dataset\nwith 90% symmetric label noise, and an absolute 27% improvement in test\naccuracy when only 1/5 of the noisy labels are available during training as an\nadditional restriction. On a real-world noisy dataset, Clothing1M, PARS\nachieves competitive results to the state of the art.\n",
                "链接": "https://arxiv.org/abs/2201.10836"
            },
            {
                "文章ID": "32359",
                "标题": "Neighborhood Collective Estimation for Noisy Label Identification and\n  Correction",
                "作者": " Jichang Li,  Guanbin Li,  Feng Liu,  Yizhou Yu",
                "发布日期": "2022-08-08",
                "摘要": "  Learning with noisy labels (LNL) aims at designing strategies to improve\nmodel performance and generalization by mitigating the effects of model\noverfitting to noisy labels. The key success of LNL lies in identifying as many\nclean samples as possible from massive noisy data, while rectifying the wrongly\nassigned noisy labels. Recent advances employ the predicted label distributions\nof individual samples to perform noise verification and noisy label correction,\neasily giving rise to confirmation bias. To mitigate this issue, we propose\nNeighborhood Collective Estimation, in which the predictive reliability of a\ncandidate sample is re-estimated by contrasting it against its feature-space\nnearest neighbors. Specifically, our method is divided into two steps: 1)\nNeighborhood Collective Noise Verification to separate all training samples\ninto a clean or noisy subset, 2) Neighborhood Collective Label Correction to\nrelabel noisy samples, and then auxiliary techniques are used to assist further\nmodel optimization. Extensive experiments on four commonly used benchmark\ndatasets, i.e., CIFAR-10, CIFAR-100, Clothing-1M and Webvision-1.0, demonstrate\nthat our proposed method considerably outperforms state-of-the-art methods.\n",
                "链接": "https://arxiv.org/abs/2208.03207"
            },
            {
                "文章ID": "41516",
                "标题": "Is your noise correction noisy? PLS: Robustness to label noise with two\n  stage detection",
                "作者": " Paul Albert,  Eric Arazo,  Tarun Krishna,  Noel E. O'Connor,  Kevin McGuinness",
                "发布日期": "2022-10-18",
                "摘要": "  Designing robust algorithms capable of training accurate neural networks on\nuncurated datasets from the web has been the subject of much research as it\nreduces the need for time consuming human labor. The focus of many previous\nresearch contributions has been on the detection of different types of label\nnoise; however, this paper proposes to improve the correction accuracy of noisy\nsamples once they have been detected. In many state-of-the-art contributions, a\ntwo phase approach is adopted where the noisy samples are detected before\nguessing a corrected pseudo-label in a semi-supervised fashion. The guessed\npseudo-labels are then used in the supervised objective without ensuring that\nthe label guess is likely to be correct. This can lead to confirmation bias,\nwhich reduces the noise robustness. Here we propose the pseudo-loss, a simple\nmetric that we find to be strongly correlated with pseudo-label correctness on\nnoisy samples. Using the pseudo-loss, we dynamically down weight\nunder-confident pseudo-labels throughout training to avoid confirmation bias\nand improve the network accuracy. We additionally propose to use a confidence\nguided contrastive objective that learns robust representation on an\ninterpolated objective between class bound (supervised) for confidently\ncorrected samples and unsupervised representation for under-confident label\ncorrections. Experiments demonstrate the state-of-the-art performance of our\nPseudo-Loss Selection (PLS) algorithm on a variety of benchmark datasets\nincluding curated data synthetically corrupted with in-distribution and\nout-of-distribution noise, and two real world web noise datasets. Our\nexperiments are fully reproducible github.com/PaulAlbert31/SNCF\n",
                "链接": "https://arxiv.org/abs/2210.04578"
            },
            {
                "文章ID": "93970",
                "标题": "Rethinking Noisy Label Learning in Real-world Annotation Scenarios from\n  the Noise-type Perspective",
                "作者": " Renyu Zhu,  Haoyu Liu,  Runze Wu,  Minmin Lin,  Tangjie Lv,  Changjie Fan,  Haobo Wang",
                "发布日期": "2023-08-23",
                "摘要": "  In this paper, we investigate the problem of learning with noisy labels in\nreal-world annotation scenarios, where noise can be categorized into two types:\nfactual noise and ambiguity noise. To better distinguish these noise types and\nutilize their semantics, we propose a novel sample selection-based approach for\nnoisy label learning, called Proto-semi. Proto-semi initially divides all\nsamples into the confident and unconfident datasets via warm-up. By leveraging\nthe confident dataset, prototype vectors are constructed to capture class\ncharacteristics. Subsequently, the distances between the unconfident samples\nand the prototype vectors are calculated to facilitate noise classification.\nBased on these distances, the labels are either corrected or retained,\nresulting in the refinement of the confident and unconfident datasets. Finally,\nwe introduce a semi-supervised learning method to enhance training. Empirical\nevaluations on a real-world annotated dataset substantiate the robustness of\nProto-semi in handling the problem of learning from noisy labels. Meanwhile,\nthe prototype-based repartitioning strategy is shown to be effective in\nmitigating the adverse impact of label noise. Our code and data are available\nat https://github.com/fuxiAIlab/ProtoSemi.\n",
                "链接": "https://arxiv.org/abs/2307.16889"
            },
            {
                "文章ID": "76850",
                "标题": "Rethinking the Value of Labels for Instance-Dependent Label Noise\n  Learning",
                "作者": " Hanwen Deng,  Weijia Zhang,  Min-Ling Zhang",
                "发布日期": "2023-05-16",
                "摘要": "  Label noise widely exists in large-scale datasets and significantly\ndegenerates the performances of deep learning algorithms. Due to the\nnon-identifiability of the instance-dependent noise transition matrix, most\nexisting algorithms address the problem by assuming the noisy label generation\nprocess to be independent of the instance features. Unfortunately, noisy labels\nin real-world applications often depend on both the true label and the\nfeatures. In this work, we tackle instance-dependent label noise with a novel\ndeep generative model that avoids explicitly modeling the noise transition\nmatrix. Our algorithm leverages casual representation learning and\nsimultaneously identifies the high-level content and style latent factors from\nthe data. By exploiting the supervision information of noisy labels with\nstructural causal models, our empirical evaluations on a wide range of\nsynthetic and real-world instance-dependent label noise datasets demonstrate\nthat the proposed algorithm significantly outperforms the state-of-the-art\ncounterparts.\n",
                "链接": "https://arxiv.org/abs/2305.06247"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下文本检索任务上，是否有关于大模型在语义坍缩问题上的研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "55962",
                "标题": "Understanding Imbalanced Semantic Segmentation Through Neural Collapse",
                "作者": " Zhisheng Zhong,  Jiequan Cui,  Yibo Yang,  Xiaoyang Wu,  Xiaojuan Qi,  Xiangyu Zhang,  Jiaya Jia",
                "发布日期": "2023-01-04",
                "摘要": "  A recent study has shown a phenomenon called neural collapse in that the\nwithin-class means of features and the classifier weight vectors converge to\nthe vertices of a simplex equiangular tight frame at the terminal phase of\ntraining for classification. In this paper, we explore the corresponding\nstructures of the last-layer feature centers and classifiers in semantic\nsegmentation. Based on our empirical and theoretical analysis, we point out\nthat semantic segmentation naturally brings contextual correlation and\nimbalanced distribution among classes, which breaks the equiangular and\nmaximally separated structure of neural collapse for both feature centers and\nclassifiers. However, such a symmetric structure is beneficial to\ndiscrimination for the minor classes. To preserve these advantages, we\nintroduce a regularizer on feature centers to encourage the network to learn\nfeatures closer to the appealing structure in imbalanced semantic segmentation.\nExperimental results show that our method can bring significant improvements on\nboth 2D and 3D semantic segmentation benchmarks. Moreover, our method ranks 1st\nand sets a new record (+6.8% mIoU) on the ScanNet200 test leaderboard. Code\nwill be available at https://github.com/dvlab-research/Imbalanced-Learning.\n",
                "链接": "https://arxiv.org/abs/2301.01100"
            },
            {
                "文章ID": "122014",
                "标题": "Collapse-Oriented Adversarial Training with Triplet Decoupling for\n  Robust Image Retrieval",
                "作者": " Qiwei Tian,  Chenhao Lin,  Qian Li,  Zhengyu Zhao,  Chao Shen",
                "发布日期": "2023-12-13",
                "摘要": "  Adversarial training has achieved substantial performance in defending image\nretrieval systems against adversarial examples. However, existing studies still\nsuffer from two major limitations: model collapse and weak adversary. This\npaper addresses these two limitations by proposing collapse-oriented (COLO)\nadversarial training with triplet decoupling (TRIDE). Specifically, COLO\nprevents model collapse by temporally orienting the perturbation update\ndirection with a new collapse metric, while TRIDE yields a strong adversary by\nspatially decoupling the update targets of perturbation into the anchor and the\ntwo candidates of a triplet. Experimental results demonstrate that our\nCOLO-TRIDE outperforms the current state of the art by 7% on average over 10\nrobustness metrics and across 3 popular datasets. In addition, we identify the\nfairness limitations of commonly used robustness metrics in image retrieval and\npropose a new metric for more meaningful robustness evaluation. Codes will be\nmade publicly available on GitHub.\n",
                "链接": "https://arxiv.org/abs/2312.07364"
            },
            {
                "文章ID": "65811",
                "标题": "Semantic-Preserving Augmentation for Robust Image-Text Retrieval",
                "作者": " Sunwoo Kim,  Kyuhong Shim,  Luong Trung Nguyen,  Byonghyo Shim",
                "发布日期": "2023-03-13",
                "摘要": "  Image text retrieval is a task to search for the proper textual descriptions\nof the visual world and vice versa. One challenge of this task is the\nvulnerability to input image and text corruptions. Such corruptions are often\nunobserved during the training, and degrade the retrieval model decision\nquality substantially. In this paper, we propose a novel image text retrieval\ntechnique, referred to as robust visual semantic embedding (RVSE), which\nconsists of novel image-based and text-based augmentation techniques called\nsemantic preserving augmentation for image (SPAugI) and text (SPAugT). Since\nSPAugI and SPAugT change the original data in a way that its semantic\ninformation is preserved, we enforce the feature extractors to generate\nsemantic aware embedding vectors regardless of the corruption, improving the\nmodel robustness significantly. From extensive experiments using benchmark\ndatasets, we show that RVSE outperforms conventional retrieval schemes in terms\nof image-text retrieval performance.\n",
                "链接": "https://arxiv.org/abs/2303.05692"
            },
            {
                "文章ID": "107265",
                "标题": "Generalized Neural Collapse for a Large Number of Classes",
                "作者": " Jiachen Jiang,  Jinxin Zhou,  Peng Wang,  Qing Qu,  Dustin Mixon,  Chong You,  Zhihui Zhu",
                "发布日期": "2023-10-30",
                "摘要": "  Neural collapse provides an elegant mathematical characterization of learned\nlast layer representations (a.k.a. features) and classifier weights in deep\nclassification models. Such results not only provide insights but also motivate\nnew techniques for improving practical deep models. However, most of the\nexisting empirical and theoretical studies in neural collapse focus on the case\nthat the number of classes is small relative to the dimension of the feature\nspace. This paper extends neural collapse to cases where the number of classes\nare much larger than the dimension of feature space, which broadly occur for\nlanguage models, retrieval systems, and face recognition applications. We show\nthat the features and classifier exhibit a generalized neural collapse\nphenomenon, where the minimum one-vs-rest margins is maximized.We provide\nempirical study to verify the occurrence of generalized neural collapse in\npractical deep neural networks. Moreover, we provide theoretical study to show\nthat the generalized neural collapse provably occurs under unconstrained\nfeature model with spherical constraint, under certain technical conditions on\nfeature dimension and number of classes.\n",
                "链接": "https://arxiv.org/abs/2310.05351"
            },
            {
                "文章ID": "122223",
                "标题": "Semantic-aware Data Augmentation for Text-to-image Synthesis",
                "作者": " Zhaorui Tan,  Xi Yang,  Kaizhu Huang",
                "发布日期": "2023-12-14",
                "摘要": "  Data augmentation has been recently leveraged as an effective regularizer in\nvarious vision-language deep neural networks. However, in text-to-image\nsynthesis (T2Isyn), current augmentation wisdom still suffers from the semantic\nmismatch between augmented paired data. Even worse, semantic collapse may occur\nwhen generated images are less semantically constrained. In this paper, we\ndevelop a novel Semantic-aware Data Augmentation (SADA) framework dedicated to\nT2Isyn. In particular, we propose to augment texts in the semantic space via an\nImplicit Textual Semantic Preserving Augmentation ($ITA$), in conjunction with\na specifically designed Image Semantic Regularization Loss ($L_r$) as Generated\nImage Semantic Conservation, to cope well with semantic mismatch and collapse.\nAs one major contribution, we theoretically show that $ITA$ can certify better\ntext-image consistency while $L_r$ regularizing the semantics of generated\nimages would avoid semantic collapse and enhance image quality. Extensive\nexperiments validate that SADA enhances text-image consistency and improves\nimage quality significantly in T2Isyn models across various backbones.\nEspecially, incorporating SADA during the tuning process of Stable Diffusion\nmodels also yields performance improvements.\n",
                "链接": "https://arxiv.org/abs/2312.07951"
            },
            {
                "文章ID": "107413",
                "标题": "Unleashing the power of Neural Collapse for Transferability Estimation",
                "作者": " Yuhe Ding,  Bo Jiang,  Lijun Sheng,  Aihua Zheng,  Jian Liang",
                "发布日期": "2023-10-10",
                "摘要": "  Transferability estimation aims to provide heuristics for quantifying how\nsuitable a pre-trained model is for a specific downstream task, without\nfine-tuning them all. Prior studies have revealed that well-trained models\nexhibit the phenomenon of Neural Collapse. Based on a widely used neural\ncollapse metric in existing literature, we observe a strong correlation between\nthe neural collapse of pre-trained models and their corresponding fine-tuned\nmodels. Inspired by this observation, we propose a novel method termed Fair\nCollapse (FaCe) for transferability estimation by comprehensively measuring the\ndegree of neural collapse in the pre-trained model. Typically, FaCe comprises\ntwo different terms: the variance collapse term, which assesses the class\nseparation and within-class compactness, and the class fairness term, which\nquantifies the fairness of the pre-trained model towards each class. We\ninvestigate FaCe on a variety of pre-trained classification models across\ndifferent network architectures, source datasets, and training loss functions.\nResults show that FaCe yields state-of-the-art performance on different tasks\nincluding image classification, semantic segmentation, and text classification,\nwhich demonstrate the effectiveness and generalization of our method.\n",
                "链接": "https://arxiv.org/abs/2310.05754"
            },
            {
                "文章ID": "80825",
                "标题": "Feature Collapse",
                "作者": " Thomas Laurent,  James H. von Brecht,  Xavier Bresson",
                "发布日期": "2023-05-26",
                "摘要": "  We formalize and study a phenomenon called feature collapse that makes\nprecise the intuitive idea that entities playing a similar role in a learning\ntask receive similar representations. As feature collapse requires a notion of\ntask, we leverage a simple but prototypical NLP task to study it. We start by\nshowing experimentally that feature collapse goes hand in hand with\ngeneralization. We then prove that, in the large sample limit, distinct words\nthat play identical roles in this NLP task receive identical local feature\nrepresentations in a neural network. This analysis reveals the crucial role\nthat normalization mechanisms, such as LayerNorm, play in feature collapse and\nin generalization.\n",
                "链接": "https://arxiv.org/abs/2305.16162"
            },
            {
                "文章ID": "81507",
                "标题": "Reward Collapse in Aligning Large Language Models",
                "作者": " Ziang Song,  Tianle Cai,  Jason D. Lee,  Weijie J. Su",
                "发布日期": "2023-05-30",
                "摘要": "  The extraordinary capabilities of large language models (LLMs) such as\nChatGPT and GPT-4 are in part unleashed by aligning them with reward models\nthat are trained on human preferences, which are often represented as rankings\nof responses to prompts. In this paper, we document the phenomenon of\n\\textit{reward collapse}, an empirical observation where the prevailing\nranking-based approach results in an \\textit{identical} reward distribution\n\\textit{regardless} of the prompts during the terminal phase of training. This\noutcome is undesirable as open-ended prompts like ``write a short story about\nyour best friend'' should yield a continuous range of rewards for their\ncompletions, while specific prompts like ``what is the capital of New Zealand''\nshould generate either high or low rewards. Our theoretical investigation\nreveals that reward collapse is primarily due to the insufficiency of the\nranking-based objective function to incorporate prompt-related information\nduring optimization. This insight allows us to derive closed-form expressions\nfor the reward distribution associated with a set of utility functions in an\nasymptotic regime. To overcome reward collapse, we introduce a prompt-aware\noptimization scheme that provably admits a prompt-dependent reward distribution\nwithin the interpolating regime. Our experimental results suggest that our\nproposed prompt-aware utility functions significantly alleviate reward collapse\nduring the training of reward models.\n",
                "链接": "https://arxiv.org/abs/2305.17608"
            },
            {
                "文章ID": "108354",
                "标题": "Direction-Oriented Visual-semantic Embedding Model for Remote Sensing\n  Image-text Retrieval",
                "作者": " Qing Ma,  Jiancheng Pan,  Cong Bai",
                "发布日期": "2023-10-13",
                "摘要": "  Image-text retrieval has developed rapidly in recent years. However, it is\nstill a challenge in remote sensing due to visual-semantic imbalance, which\nleads to incorrect matching of non-semantic visual and textual features. To\nsolve this problem, we propose a novel Direction-Oriented Visual-semantic\nEmbedding Model (DOVE) to mine the relationship between vision and language.\nConcretely, a Regional-Oriented Attention Module (ROAM) adaptively adjusts the\ndistance between the final visual and textual embeddings in the latent semantic\nspace, oriented by regional visual features. Meanwhile, a lightweight Digging\nText Genome Assistant (DTGA) is designed to expand the range of tractable\ntextual representation and enhance global word-level semantic connections using\nless attention operations. Ultimately, we exploit a global visual-semantic\nconstraint to reduce single visual dependency and serve as an external\nconstraint for the final visual and textual representations. The effectiveness\nand superiority of our method are verified by extensive experiments including\nparameter evaluation, quantitative comparison, ablation studies and visual\nanalysis, on two benchmark datasets, RSICD and RSITMD.\n",
                "链接": "https://arxiv.org/abs/2310.08276"
            },
            {
                "文章ID": "18416",
                "标题": "Posterior Collapse of a Linear Latent Variable Model",
                "作者": " Zihao Wang,  Liu Ziyin",
                "发布日期": "2022-10-17",
                "摘要": "  This work identifies the existence and cause of a type of posterior collapse\nthat frequently occurs in the Bayesian deep learning practice. For a general\nlinear latent variable model that includes linear variational autoencoders as a\nspecial case, we precisely identify the nature of posterior collapse to be the\ncompetition between the likelihood and the regularization of the mean due to\nthe prior. Our result suggests that posterior collapse may be related to neural\ncollapse and dimensional collapse and could be a subclass of a general problem\nof learning for deeper architectures.\n",
                "链接": "https://arxiv.org/abs/2205.04009"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找对机器翻译数据集质量进行评估的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "19633",
                "标题": "Consistent Human Evaluation of Machine Translation across Language Pairs",
                "作者": " Daniel Licht,  Cynthia Gao,  Janice Lam,  Francisco Guzman,  Mona Diab,  Philipp Koehn",
                "发布日期": "2022-05-18",
                "摘要": "  Obtaining meaningful quality scores for machine translation systems through\nhuman evaluation remains a challenge given the high variability between human\nevaluators, partly due to subjective expectations for translation quality for\ndifferent language pairs. We propose a new metric called XSTS that is more\nfocused on semantic equivalence and a cross-lingual calibration method that\nenables more consistent assessment. We demonstrate the effectiveness of these\nnovel contributions in large scale evaluation studies across up to 14 language\npairs, with translation both into and out of English.\n",
                "链接": "https://arxiv.org/abs/2205.08533"
            },
            {
                "文章ID": "38541",
                "标题": "Approaching English-Polish Machine Translation Quality Assessment with\n  Neural-based Methods",
                "作者": " Artur Nowakowski",
                "发布日期": "2022-09-23",
                "摘要": "  This paper presents our contribution to the PolEval 2021 Task 2: Evaluation\nof translation quality assessment metrics. We describe experiments with\npre-trained language models and state-of-the-art frameworks for translation\nquality assessment in both nonblind and blind versions of the task. Our\nsolutions ranked second in the nonblind version and third in the blind version.\n",
                "链接": "https://arxiv.org/abs/2209.11016"
            },
            {
                "文章ID": "37434",
                "标题": "Rethinking Round-Trip Translation for Machine Translation Evaluation",
                "作者": " Terry Yue Zhuo,  Qiongkai Xu,  Xuanli He,  Trevor Cohn",
                "发布日期": "2023-05-16",
                "摘要": "  Automatic evaluation on low-resource language translation suffers from a\ndeficiency of parallel corpora. Round-trip translation could be served as a\nclever and straightforward technique to alleviate the requirement of the\nparallel evaluation corpus. However, there was an observation of obscure\ncorrelations between the evaluation scores by forward and round-trip\ntranslations in the era of statistical machine translation (SMT). In this\npaper, we report the surprising finding that round-trip translation can be used\nfor automatic evaluation without the references. Firstly, our revisit on the\nround-trip translation in SMT evaluation unveils that its long-standing\nmisunderstanding is essentially caused by copying mechanism. After removing\ncopying mechanism in SMT, round-trip translation scores can appropriately\nreflect the forward translation performance. Then, we demonstrate the\nrectification is overdue as round-trip translation could benefit multiple\nmachine translation evaluation tasks. To be more specific, round-trip\ntranslation could be used i) to predict corresponding forward translation\nscores; ii) to improve the performance of the recently advanced quality\nestimation model; and iii) to identify adversarial competitors in shared tasks\nvia cross-system verification.\n",
                "链接": "https://arxiv.org/abs/2209.07351"
            },
            {
                "文章ID": "6641",
                "标题": "An Overview on Machine Translation Evaluation",
                "作者": " Lifeng Han",
                "发布日期": "2022-02-23",
                "摘要": "  Since the 1950s, machine translation (MT) has become one of the important\ntasks of AI and development, and has experienced several different periods and\nstages of development, including rule-based methods, statistical methods, and\nrecently proposed neural network-based learning methods. Accompanying these\nstaged leaps is the evaluation research and development of MT, especially the\nimportant role of evaluation methods in statistical translation and neural\ntranslation research. The evaluation task of MT is not only to evaluate the\nquality of machine translation, but also to give timely feedback to machine\ntranslation researchers on the problems existing in machine translation itself,\nhow to improve and how to optimise. In some practical application fields, such\nas in the absence of reference translations, the quality estimation of machine\ntranslation plays an important role as an indicator to reveal the credibility\nof automatically translated target languages. This report mainly includes the\nfollowing contents: a brief history of machine translation evaluation (MTE),\nthe classification of research methods on MTE, and the the cutting-edge\nprogress, including human evaluation, automatic evaluation, and evaluation of\nevaluation methods (meta-evaluation). Manual evaluation and automatic\nevaluation include reference-translation based and reference-translation\nindependent participation; automatic evaluation methods include traditional\nn-gram string matching, models applying syntax and semantics, and deep learning\nmodels; evaluation of evaluation methods includes estimating the credibility of\nhuman evaluations, the reliability of the automatic evaluation, the reliability\nof the test set, etc. Advances in cutting-edge evaluation methods include\ntask-based evaluation, using pre-trained language models based on big data, and\nlightweight optimisation models using distillation techniques.\n",
                "链接": "https://arxiv.org/abs/2202.11027"
            },
            {
                "文章ID": "109147",
                "标题": "xCOMET: Transparent Machine Translation Evaluation through Fine-grained\n  Error Detection",
                "作者": " Nuno M. Guerreiro,  Ricardo Rei,  Daan van Stigt,  Luisa Coheur,  Pierre Colombo,  André F. T. Martins",
                "发布日期": "2023-10-17",
                "摘要": "  Widely used learned metrics for machine translation evaluation, such as COMET\nand BLEURT, estimate the quality of a translation hypothesis by providing a\nsingle sentence-level score. As such, they offer little insight into\ntranslation errors (e.g., what are the errors and what is their severity). On\nthe other hand, generative large language models (LLMs) are amplifying the\nadoption of more granular strategies to evaluation, attempting to detail and\ncategorize translation errors. In this work, we introduce xCOMET, an\nopen-source learned metric designed to bridge the gap between these approaches.\nxCOMET integrates both sentence-level evaluation and error span detection\ncapabilities, exhibiting state-of-the-art performance across all types of\nevaluation (sentence-level, system-level, and error span detection). Moreover,\nit does so while highlighting and categorizing error spans, thus enriching the\nquality assessment. We also provide a robustness analysis with stress tests,\nand show that xCOMET is largely capable of identifying localized critical\nerrors and hallucinations.\n",
                "链接": "https://arxiv.org/abs/2310.10482"
            },
            {
                "文章ID": "87010",
                "标题": "Evaluation of Chinese-English Machine Translation of Emotion-Loaded\n  Microblog Texts: A Human Annotated Dataset for the Quality Assessment of\n  Emotion Translation",
                "作者": " Shenbin Qian,  Constantin Orasan,  Felix do Carmo,  Qiuliang Li,  Diptesh Kanojia",
                "发布日期": "2023-06-22",
                "摘要": "  In this paper, we focus on how current Machine Translation (MT) tools perform\non the translation of emotion-loaded texts by evaluating outputs from Google\nTranslate according to a framework proposed in this paper. We propose this\nevaluation framework based on the Multidimensional Quality Metrics (MQM) and\nperform a detailed error analysis of the MT outputs. From our analysis, we\nobserve that about 50% of the MT outputs fail to preserve the original emotion.\nAfter further analysis of the errors, we find that emotion carrying words and\nlinguistic phenomena such as polysemous words, negation, abbreviation etc., are\ncommon causes for these translation errors.\n",
                "链接": "https://arxiv.org/abs/2306.11900"
            },
            {
                "文章ID": "17492",
                "标题": "Quality-Aware Decoding for Neural Machine Translation",
                "作者": " Patrick Fernandes,  António Farinhas,  Ricardo Rei,  José G. C. de Souza,  Perez Ogayo,  Graham Neubig,  André F. T. Martins",
                "发布日期": "2022-05-03",
                "摘要": "  Despite the progress in machine translation quality estimation and evaluation\nin the last years, decoding in neural machine translation (NMT) is mostly\noblivious to this and centers around finding the most probable translation\naccording to the model (MAP decoding), approximated with beam search. In this\npaper, we bring together these two lines of research and propose quality-aware\ndecoding for NMT, by leveraging recent breakthroughs in reference-free and\nreference-based MT evaluation through various inference methods like $N$-best\nreranking and minimum Bayes risk decoding. We perform an extensive comparison\nof various possible candidate generation and ranking methods across four\ndatasets and two model classes and find that quality-aware decoding\nconsistently outperforms MAP-based decoding according both to state-of-the-art\nautomatic metrics (COMET and BLEURT) and to human assessments. Our code is\navailable at https://github.com/deep-spin/qaware-decode.\n",
                "链接": "https://arxiv.org/abs/2205.00978"
            },
            {
                "文章ID": "87351",
                "标题": "Towards Explainable Evaluation Metrics for Machine Translation",
                "作者": " Christoph Leiter,  Piyawat Lertvittayakumjorn,  Marina Fomicheva,  Wei Zhao,  Yang Gao,  Steffen Eger",
                "发布日期": "2023-06-23",
                "摘要": "  Unlike classical lexical overlap metrics such as BLEU, most current\nevaluation metrics for machine translation (for example, COMET or BERTScore)\nare based on black-box large language models. They often achieve strong\ncorrelations with human judgments, but recent research indicates that the\nlower-quality classical metrics remain dominant, one of the potential reasons\nbeing that their decision processes are more transparent. To foster more\nwidespread acceptance of novel high-quality metrics, explainability thus\nbecomes crucial. In this concept paper, we identify key properties as well as\nkey goals of explainable machine translation metrics and provide a\ncomprehensive synthesis of recent techniques, relating them to our established\ngoals and properties. In this context, we also discuss the latest\nstate-of-the-art approaches to explainable metrics based on generative models\nsuch as ChatGPT and GPT4. Finally, we contribute a vision of next-generation\napproaches, including natural language explanations. We hope that our work can\nhelp catalyze and guide future research on explainable evaluation metrics and,\nmediately, also contribute to better and more transparent machine translation\nsystems.\n",
                "链接": "https://arxiv.org/abs/2306.13041"
            },
            {
                "文章ID": "23081",
                "标题": "MorisienMT: A Dataset for Mauritian Creole Machine Translation",
                "作者": " Raj Dabre,  Aneerav Sukhoo",
                "发布日期": "2022-06-07",
                "摘要": "  In this paper, we describe MorisienMT, a dataset for benchmarking machine\ntranslation quality of Mauritian Creole. Mauritian Creole (Morisien) is the\nlingua franca of the Republic of Mauritius and is a French-based creole\nlanguage. MorisienMT consists of a parallel corpus between English and\nMorisien, French and Morisien and a monolingual corpus for Morisien. We first\ngive an overview of Morisien and then describe the steps taken to create the\ncorpora and, from it, the training and evaluation splits. Thereafter, we\nestablish a variety of baseline models using the created parallel corpora as\nwell as large French--English corpora for transfer learning. We release our\ndatasets publicly for research purposes and hope that this spurs research for\nMorisien machine translation.\n",
                "链接": "https://arxiv.org/abs/2206.02421"
            },
            {
                "文章ID": "84997",
                "标题": "Conformalizing Machine Translation Evaluation",
                "作者": " Chrysoula Zerva,  André F. T. Martins",
                "发布日期": "2023-06-13",
                "摘要": "  Several uncertainty estimation methods have been recently proposed for\nmachine translation evaluation. While these methods can provide a useful\nindication of when not to trust model predictions, we show in this paper that\nthe majority of them tend to underestimate model uncertainty, and as a result\nthey often produce misleading confidence intervals that do not cover the ground\ntruth. We propose as an alternative the use of conformal prediction, a\ndistribution-free method to obtain confidence intervals with a theoretically\nestablished guarantee on coverage. First, we demonstrate that split conformal\nprediction can ``correct'' the confidence intervals of previous methods to\nyield a desired coverage level. Then, we highlight biases in estimated\nconfidence intervals, both in terms of the translation language pairs and the\nquality of translations. We apply conditional conformal prediction techniques\nto obtain calibration subsets for each data subgroup, leading to equalized\ncoverage.\n",
                "链接": "https://arxiv.org/abs/2306.06221"
            }
        ]
    },
    {
        "question": {
            "question": "查找大语言模型相关的分析类型的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "69238",
                "标题": "Can Large Language Models assist in Hazard Analysis?",
                "作者": " Simon Diemert,  Jens H Weber",
                "发布日期": "2023-03-29",
                "摘要": "  Large Language Models (LLMs), such as GPT-3, have demonstrated remarkable\nnatural language processing and generation capabilities and have been applied\nto a variety tasks, such as source code generation. This paper explores the\npotential of integrating LLMs in the hazard analysis for safety-critical\nsystems, a process which we refer to as co-hazard analysis (CoHA). In CoHA, a\nhuman analyst interacts with an LLM via a context-aware chat session and uses\nthe responses to support elicitation of possible hazard causes. In this\nexperiment, we explore CoHA with three increasingly complex versions of a\nsimple system, using Open AI's ChatGPT service. The quality of ChatGPT's\nresponses were systematically assessed to determine the feasibility of CoHA\ngiven the current state of LLM technology. The results suggest that LLMs may be\nuseful for supporting human analysts performing hazard analysis.\n",
                "链接": "https://arxiv.org/abs/2303.15473"
            },
            {
                "文章ID": "76170",
                "标题": "X-LLM: Bootstrapping Advanced Large Language Models by Treating\n  Multi-Modalities as Foreign Languages",
                "作者": " Feilong Chen,  Minglun Han,  Haozhi Zhao,  Qingyang Zhang,  Jing Shi,  Shuang Xu,  Bo Xu",
                "发布日期": "2023-05-23",
                "摘要": "  Large language models (LLMs) have demonstrated remarkable language abilities.\nGPT-4, based on advanced LLMs, exhibits extraordinary multimodal capabilities\nbeyond previous visual language models. We attribute this to the use of more\nadvanced LLMs compared with previous multimodal models. Unfortunately, the\nmodel architecture and training strategies of GPT-4 are unknown. To endow LLMs\nwith multimodal capabilities, we propose X-LLM, which converts Multi-modalities\n(images, speech, videos) into foreign languages using X2L interfaces and inputs\nthem into a large Language model (ChatGLM). Specifically, X-LLM aligns multiple\nfrozen single-modal encoders and a frozen LLM using X2L interfaces, where ``X''\ndenotes multi-modalities such as image, speech, and videos, and ``L'' denotes\nlanguages. X-LLM's training consists of three stages: (1) Converting Multimodal\nInformation: The first stage trains each X2L interface to align with its\nrespective single-modal encoder separately to convert multimodal information\ninto languages. (2) Aligning X2L representations with the LLM: single-modal\nencoders are aligned with the LLM through X2L interfaces independently. (3)\nIntegrating multiple modalities: all single-modal encoders are aligned with the\nLLM through X2L interfaces to integrate multimodal capabilities into the LLM.\nOur experiments show that X-LLM demonstrates impressive multimodel chat\nabilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen\nimages/instructions, and yields a 84.5\\% relative score compared with GPT-4 on\na synthetic multimodal instruction-following dataset. And we also conduct\nquantitative tests on using LLM for ASR and multimodal ASR, hoping to promote\nthe era of LLM-based speech recognition.\n",
                "链接": "https://arxiv.org/abs/2305.04160"
            },
            {
                "文章ID": "110853",
                "标题": "LLM-in-the-loop: Leveraging Large Language Model for Thematic Analysis",
                "作者": " Shih-Chieh Dai,  Aiping Xiong,  Lun-Wei Ku",
                "发布日期": "2023-10-24",
                "摘要": "  Thematic analysis (TA) has been widely used for analyzing qualitative data in\nmany disciplines and fields. To ensure reliable analysis, the same piece of\ndata is typically assigned to at least two human coders. Moreover, to produce\nmeaningful and useful analysis, human coders develop and deepen their data\ninterpretation and coding over multiple iterations, making TA labor-intensive\nand time-consuming. Recently the emerging field of large language models (LLMs)\nresearch has shown that LLMs have the potential replicate human-like behavior\nin various tasks: in particular, LLMs outperform crowd workers on\ntext-annotation tasks, suggesting an opportunity to leverage LLMs on TA. We\npropose a human-LLM collaboration framework (i.e., LLM-in-the-loop) to conduct\nTA with in-context learning (ICL). This framework provides the prompt to frame\ndiscussions with a LLM (e.g., GPT-3.5) to generate the final codebook for TA.\nWe demonstrate the utility of this framework using survey datasets on the\naspects of the music listening experience and the usage of a password manager.\nResults of the two case studies show that the proposed framework yields similar\ncoding quality to that of human coders but reduces TA's labor and time demands.\n",
                "链接": "https://arxiv.org/abs/2310.15100"
            },
            {
                "文章ID": "101120",
                "标题": "Analysis of Disinformation and Fake News Detection Using Fine-Tuned\n  Large Language Model",
                "作者": " Bohdan M. Pavlyshenko",
                "发布日期": "2023-09-12",
                "摘要": "  The paper considers the possibility of fine-tuning Llama 2 large language\nmodel (LLM) for the disinformation analysis and fake news detection. For\nfine-tuning, the PEFT/LoRA based approach was used. In the study, the model was\nfine-tuned for the following tasks: analysing a text on revealing\ndisinformation and propaganda narratives, fact checking, fake news detection,\nmanipulation analytics, extracting named entities with their sentiments. The\nobtained results show that the fine-tuned Llama 2 model can perform a deep\nanalysis of texts and reveal complex styles and narratives. Extracted\nsentiments for named entities can be considered as predictive features in\nsupervised machine learning models.\n",
                "链接": "https://arxiv.org/abs/2309.04704"
            },
            {
                "文章ID": "124538",
                "标题": "Large Language Model (LLM) Bias Index -- LLMBI",
                "作者": " Abiodun Finbarrs Oketunji,  Muhammad Anas,  Deepthi Saina",
                "发布日期": "2023-12-27",
                "摘要": "  The Large Language Model Bias Index (LLMBI) is a pioneering approach designed\nto quantify and address biases inherent in large language models (LLMs), such\nas GPT-4. We recognise the increasing prevalence and impact of LLMs across\ndiverse sectors. This research introduces a novel metric, LLMBI, to\nsystematically measure and mitigate biases potentially skewing model responses.\nWe formulated LLMBI using a composite scoring system incorporating multiple\ndimensions of bias, including but not limited to age, gender, and racial\nbiases.\n  To operationalise this metric, we engaged in a multi-step process involving\ncollecting and annotating LLM responses, applying sophisticated Natural\nLanguage Processing (NLP) techniques for bias detection, and computing the\nLLMBI score through a specially crafted mathematical formula. The formula\nintegrates weighted averages of various bias dimensions, a penalty for dataset\ndiversity deficiencies, and a correction for sentiment biases. Our empirical\nanalysis, conducted using responses from OpenAI's API, employs advanced\nsentiment analysis as a representative method for bias detection.\n  The research reveals LLMs, whilst demonstrating impressive capabilities in\ntext generation, exhibit varying degrees of bias across different dimensions.\nLLMBI provides a quantifiable measure to compare biases across models and over\ntime, offering a vital tool for systems engineers, researchers and regulators\nin enhancing the fairness and reliability of LLMs. It highlights the potential\nof LLMs in mimicking unbiased human-like responses. Additionally, it\nunderscores the necessity of continuously monitoring and recalibrating such\nmodels to align with evolving societal norms and ethical standards.\n",
                "链接": "https://arxiv.org/abs/2312.14769"
            },
            {
                "文章ID": "112194",
                "标题": "Using Large Language Models to Support Thematic Analysis in Empirical\n  Legal Studies",
                "作者": " Jakub Drápal,  Hannes Westermann,  Jaromir Savelka",
                "发布日期": "2023-10-31",
                "摘要": "  Thematic analysis and other variants of inductive coding are widely used\nqualitative analytic methods within empirical legal studies (ELS). We propose a\nnovel framework facilitating effective collaboration of a legal expert with a\nlarge language model (LLM) for generating initial codes (phase 2 of thematic\nanalysis), searching for themes (phase 3), and classifying the data in terms of\nthe themes (to kick-start phase 4). We employed the framework for an analysis\nof a dataset (n=785) of facts descriptions from criminal court opinions\nregarding thefts. The goal of the analysis was to discover classes of typical\nthefts. Our results show that the LLM, namely OpenAI's GPT-4, generated\nreasonable initial codes, and it was capable of improving the quality of the\ncodes based on expert feedback. They also suggest that the model performed well\nin zero-shot classification of facts descriptions in terms of the themes.\nFinally, the themes autonomously discovered by the LLM appear to map fairly\nwell to the themes arrived at by legal experts. These findings can be leveraged\nby legal researchers to guide their decisions in integrating LLMs into their\nthematic analyses, as well as other inductive coding projects.\n",
                "链接": "https://arxiv.org/abs/2310.18729"
            },
            {
                "文章ID": "71614",
                "标题": "Multilingual Machine Translation with Large Language Models: Empirical\n  Results and Analysis",
                "作者": " Wenhao Zhu,  Hongyi Liu,  Qingxiu Dong,  Jingjing Xu,  Shujian Huang,  Lingpeng Kong,  Jiajun Chen,  Lei Li",
                "发布日期": "2023-10-31",
                "摘要": "  Large language models (LLMs) have demonstrated remarkable potential in\nhandling multilingual machine translation (MMT). In this paper, we\nsystematically investigate the advantages and challenges of LLMs for MMT by\nanswering two questions: 1) How well do LLMs perform in translating massive\nlanguages? 2) Which factors affect LLMs' performance in translation? We\nthoroughly evaluate eight popular LLMs, including ChatGPT and GPT-4. Our\nempirical results show that translation capabilities of LLMs are continually\nimproving. GPT-4 has beat the strong supervised baseline NLLB in 40.91% of\ntranslation directions but still faces a large gap towards the commercial\ntranslation system, especially on low-resource languages. Through further\nanalysis, we discover that LLMs exhibit new working patterns when used for MMT.\nFirst, instruction semantics can surprisingly be ignored when given in-context\nexemplars. Second, cross-lingual exemplars can provide better task guidance for\nlow-resource translation than exemplars in the same language pairs. Third, LLM\ncan acquire translation ability in a resource-efficient way and generate\nmoderate translation even on zero-resource languages.\n",
                "链接": "https://arxiv.org/abs/2304.04675"
            },
            {
                "文章ID": "87969",
                "标题": "LLM-Assisted Content Analysis: Using Large Language Models to Support\n  Deductive Coding",
                "作者": " Robert Chew,  John Bollenbacher,  Michael Wenger,  Jessica Speer,  Annice Kim",
                "发布日期": "2023-06-28",
                "摘要": "  Deductive coding is a widely used qualitative research method for determining\nthe prevalence of themes across documents. While useful, deductive coding is\noften burdensome and time consuming since it requires researchers to read,\ninterpret, and reliably categorize a large body of unstructured text documents.\nLarge language models (LLMs), like ChatGPT, are a class of quickly evolving AI\ntools that can perform a range of natural language processing and reasoning\ntasks. In this study, we explore the use of LLMs to reduce the time it takes\nfor deductive coding while retaining the flexibility of a traditional content\nanalysis. We outline the proposed approach, called LLM-assisted content\nanalysis (LACA), along with an in-depth case study using GPT-3.5 for LACA on a\npublicly available deductive coding data set. Additionally, we conduct an\nempirical benchmark using LACA on 4 publicly available data sets to assess the\nbroader question of how well GPT-3.5 performs across a range of deductive\ncoding tasks. Overall, we find that GPT-3.5 can often perform deductive coding\nat levels of agreement comparable to human coders. Additionally, we demonstrate\nthat LACA can help refine prompts for deductive coding, identify codes for\nwhich an LLM is randomly guessing, and help assess when to use LLMs vs. human\ncoders for deductive coding. We conclude with several implications for future\npractice of deductive coding and related research methods.\n",
                "链接": "https://arxiv.org/abs/2306.14924"
            },
            {
                "文章ID": "115552",
                "标题": "How good are Large Language Models on African Languages?",
                "作者": " Jessica Ojo,  Kelechi Ogueji,  Pontus Stenetorp,  David I. Adelani",
                "发布日期": "2023-11-15",
                "摘要": "  Recent advancements in natural language processing have led to the\nproliferation of large language models (LLMs). These models have been shown to\nyield good performance, using in-context learning, even on unseen tasks and\nlanguages. Additionally, they have been widely adopted as\nlanguage-model-as-a-service commercial APIs like GPT-4 API. However, their\nperformance on African languages is largely unknown. We present an analysis of\nthree popular large language models (mT0, LLaMa 2, and GPT-4) on five tasks\n(news topic classification, sentiment classification, machine translation,\nquestion answering, and named entity recognition) across 30 African languages,\nspanning different language families and geographical regions. Our results\nsuggest that all LLMs produce below-par performance on African languages, and\nthere is a large gap in performance compared to high-resource languages like\nEnglish most tasks. We find that GPT-4 has an average or impressive performance\non classification tasks but very poor results on generative tasks like machine\ntranslation. Surprisingly, we find that mT0 had the best overall on\ncross-lingual QA, better than the state-of-the-art supervised model (i.e.\nfine-tuned mT5) and GPT-4 on African languages. Overall, LLaMa 2 records the\nworst performance due to its limited multilingual capabilities and\nEnglish-centric pre-training corpus. In general, our findings present a\ncall-to-action to ensure African languages are well represented in large\nlanguage models, given their growing popularity.\n",
                "链接": "https://arxiv.org/abs/2311.07978"
            },
            {
                "文章ID": "110493",
                "标题": "LUNA: A Model-Based Universal Analysis Framework for Large Language\n  Models",
                "作者": " Da Song,  Xuan Xie,  Jiayang Song,  Derui Zhu,  Yuheng Huang,  Felix Juefei-Xu,  Lei Ma",
                "发布日期": "2023-10-24",
                "摘要": "  Over the past decade, Artificial Intelligence (AI) has had great success\nrecently and is being used in a wide range of academic and industrial fields.\nMore recently, LLMs have made rapid advancements that have propelled AI to a\nnew level, enabling even more diverse applications and industrial domains with\nintelligence, particularly in areas like software engineering and natural\nlanguage processing. Nevertheless, a number of emerging trustworthiness\nconcerns and issues exhibited in LLMs have already recently received much\nattention, without properly solving which the widespread adoption of LLMs could\nbe greatly hindered in practice. The distinctive characteristics of LLMs, such\nas the self-attention mechanism, extremely large model scale, and\nautoregressive generation schema, differ from classic AI software based on CNNs\nand RNNs and present new challenges for quality analysis. Up to the present, it\nstill lacks universal and systematic analysis techniques for LLMs despite the\nurgent industrial demand. Towards bridging this gap, we initiate an early\nexploratory study and propose a universal analysis framework for LLMs, LUNA,\ndesigned to be general and extensible, to enable versatile analysis of LLMs\nfrom multiple quality perspectives in a human-interpretable manner. In\nparticular, we first leverage the data from desired trustworthiness\nperspectives to construct an abstract model as an auxiliary analysis asset,\nwhich is empowered by various abstract model construction methods. To assess\nthe quality of the abstract model, we collect and define a number of evaluation\nmetrics, aiming at both abstract model level and the semantics level. Then, the\nsemantics, which is the degree of satisfaction of the LLM w.r.t. the\ntrustworthiness perspective, is bound to and enriches the abstract model with\nsemantics, which enables more detailed analysis applications for diverse\npurposes.\n",
                "链接": "https://arxiv.org/abs/2310.14211"
            }
        ]
    },
    {
        "question": {
            "question": "查询2022年以来指令遵循数据集构建相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "120242",
                "标题": "MUFFIN: Curating Multi-Faceted Instructions for Improving\n  Instruction-Following",
                "作者": " Renze Lou,  Kai Zhang,  Jian Xie,  Yuxuan Sun,  Janice Ahn,  Hanzi Xu,  Yu Su,  Wenpeng Yin",
                "发布日期": "2023-12-06",
                "摘要": "  In the realm of large language models (LLMs), enhancing instruction-following\ncapability often involves curating expansive training data. This is achieved\nthrough two primary schemes: i) Scaling-Inputs: Amplifying (input, output)\npairs per task instruction, aiming for better instruction adherence. ii)\nScaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction,\noutput) pair (without requiring a separate input anymore). However, LLMs under\nScaling-Inputs tend to be overly sensitive to inputs, leading to\nmisinterpretation or non-compliance with instructions. Conversely, Scaling\nInput-Free Tasks demands a substantial number of tasks but is less effective in\ninstruction following when dealing with instances in Scaling-Inputs. This work\nintroduces MUFFIN, a new scheme of instruction-following dataset curation.\nSpecifically, we automatically Scale Tasks per Input by diversifying these\ntasks with various input facets. Experimental results across four zero-shot\nbenchmarks, spanning both Scaling-Inputs and Scaling Input-Free Tasks schemes,\nreveal that LLMs, at various scales, trained on MUFFIN generally demonstrate\nsuperior instruction-following capabilities compared to those trained on the\ntwo aforementioned schemes.\n",
                "链接": "https://arxiv.org/abs/2312.02436"
            },
            {
                "文章ID": "92076",
                "标题": "Instruction-following Evaluation through Verbalizer Manipulation",
                "作者": " Shiyang Li,  Jun Yan,  Hai Wang,  Zheng Tang,  Xiang Ren,  Vijay Srinivasan,  Hongxia Jin",
                "发布日期": "2023-07-21",
                "摘要": "  While instruction-tuned models have shown remarkable success in various\nnatural language processing tasks, accurately evaluating their ability to\nfollow instructions remains challenging. Existing benchmarks primarily focus on\ncommon instructions that align well with what the model learned during\ntraining. However, proficiency in responding to these instructions does not\nnecessarily imply strong ability in instruction following. In this paper, we\npropose a novel instruction-following evaluation protocol called verbalizer\nmanipulation. It instructs the model to verbalize the task label with words\naligning with model priors to different extents, adopting verbalizers from\nhighly aligned (e.g., outputting ``postive'' for positive sentiment), to\nminimally aligned (e.g., outputting ``negative'' for positive sentiment).\nVerbalizer manipulation can be seamlessly integrated with any classification\nbenchmark to examine the model's reliance on priors and its ability to override\nthem to accurately follow the instructions. We conduct a comprehensive\nevaluation of four major model families across nine datasets, employing twelve\nsets of verbalizers for each of them. We observe that the instruction-following\nabilities of models, across different families and scales, are significantly\ndistinguished by their performance on less natural verbalizers. Even the\nstrongest GPT-4 model struggles to perform better than random guessing on the\nmost challenging verbalizer, emphasizing the need for continued advancements to\nimprove their instruction-following abilities.\n",
                "链接": "https://arxiv.org/abs/2307.10558"
            },
            {
                "文章ID": "76886",
                "标题": "Accessible Instruction-Following Agent",
                "作者": " Kairui Zhou",
                "发布日期": "2023-05-12",
                "摘要": "  Humans can collaborate and complete tasks based on visual signals and\ninstruction from the environment. Training such a robot is difficult especially\ndue to the understanding of the instruction and the complicated environment.\nPrevious instruction-following agents are biased to English-centric corpus,\nmaking it unrealizable to be applied to users that use multiple languages or\neven low-resource languages. Nevertheless, the instruction-following agents are\npre-trained in a mode that assumes the user can observe the environment, which\nlimits its accessibility. In this work, we're trying to generalize the success\nof instruction-following agents to non-English languages with little corpus\nresources, and improve its intractability and accessibility. We introduce UVLN\n(Universal Vision-Language Navigation), a novel machine-translation\ninstructional augmented framework for cross-lingual vision-language navigation,\nwith a novel composition of state-of-the-art large language model (GPT3) with\nthe image caption model (BLIP). We first collect a multilanguage\nvision-language navigation dataset via machine translation. Then we extend the\nstandard VLN training objectives to a multilingual setting via a cross-lingual\nlanguage encoder. The alignment between different languages is captured through\na shared vision and action context via a cross-modal transformer, which encodes\nthe inputs of language instruction, visual observation, and action decision\nsequences. To improve the intractability, we connect our agent with the large\nlanguage model that informs the situation and current state to the user and\nalso explains the action decisions. Experiments over Room Across Room Dataset\nprove the effectiveness of our approach. And the qualitative results show the\npromising intractability and accessibility of our instruction-following agent.\n",
                "链接": "https://arxiv.org/abs/2305.06358"
            },
            {
                "文章ID": "78681",
                "标题": "InstructIE: A Chinese Instruction-based Information Extraction Dataset",
                "作者": " Honghao Gui,  Jintian Zhang,  Hongbin Ye,  Ningyu Zhang",
                "发布日期": "2023-05-22",
                "摘要": "  We introduce a new Information Extraction (IE) task dubbed Instruction-based\nIE, which aims to ask the system to follow specific instructions or guidelines\nto extract information. To facilitate research in this area, we construct a\ndataset called InstructIE, consisting of 270,000 weakly supervised data from\nChinese Wikipedia and 1,000 high-quality crowdsourced annotated instances. We\nfurther evaluate the performance of various baseline models on the InstructIE\ndataset. The results reveal that although current models exhibit promising\nperformance, there is still room for improvement. Furthermore, we conduct a\ncomprehensive case study analysis, underlining the challenges inherent in the\nInstruction-based IE task. Code and dataset are available at\nhttps://github.com/zjunlp/DeepKE/tree/main/example/llm.\n",
                "链接": "https://arxiv.org/abs/2305.11527"
            },
            {
                "文章ID": "102710",
                "标题": "Instruction-Following Speech Recognition",
                "作者": " Cheng-I Jeff Lai,  Zhiyun Lu,  Liangliang Cao,  Ruoming Pang",
                "发布日期": "2023-09-19",
                "摘要": "  Conventional end-to-end Automatic Speech Recognition (ASR) models primarily\nfocus on exact transcription tasks, lacking flexibility for nuanced user\ninteractions. With the advent of Large Language Models (LLMs) in speech\nprocessing, more organic, text-prompt-based interactions have become possible.\nHowever, the mechanisms behind these models' speech understanding and\n\"reasoning\" capabilities remain underexplored. To study this question from the\ndata perspective, we introduce instruction-following speech recognition,\ntraining a Listen-Attend-Spell model to understand and execute a diverse set of\nfree-form text instructions. This enables a multitude of speech recognition\ntasks -- ranging from transcript manipulation to summarization -- without\nrelying on predefined command sets. Remarkably, our model, trained from scratch\non Librispeech, interprets and executes simple instructions without requiring\nLLMs or pre-trained speech modules. It also offers selective transcription\noptions based on instructions like \"transcribe first half and then turn off\nlistening,\" providing an additional layer of privacy and safety compared to\nexisting LLMs. Our findings highlight the significant potential of\ninstruction-following training to advance speech foundation models.\n",
                "链接": "https://arxiv.org/abs/2309.09843"
            },
            {
                "文章ID": "118475",
                "标题": "Releasing the CRaQAn (Coreference Resolution in Question-Answering): An\n  open-source dataset and dataset creation methodology using\n  instruction-following models",
                "作者": " Rob Grzywinski,  Joshua D'Arcy,  Rob Naidoff,  Ashish Shukla,  Alex Browne,  Ren Gibbons,  Brinnae Bent",
                "发布日期": "2023-11-29",
                "摘要": "  Instruction-following language models demand robust methodologies for\ninformation retrieval to augment instructions for question-answering\napplications. A primary challenge is the resolution of coreferences in the\ncontext of chunking strategies for long documents. The critical barrier to\nexperimentation of handling coreferences is a lack of open source datasets,\nspecifically in question-answering tasks that require coreference resolution.\nIn this work we present our Coreference Resolution in Question-Answering\n(CRaQAn) dataset, an open-source dataset that caters to the nuanced information\nretrieval requirements of coreference resolution in question-answering tasks by\nproviding over 250 question-answer pairs containing coreferences. To develop\nthis dataset, we developed a novel approach for creating high-quality datasets\nusing an instruction-following model (GPT-4) and a Recursive Criticism and\nImprovement Loop.\n",
                "链接": "https://arxiv.org/abs/2311.16338"
            },
            {
                "文章ID": "66734",
                "标题": "Lana: A Language-Capable Navigator for Instruction Following and\n  Generation",
                "作者": " Xiaohan Wang,  Wenguan Wang,  Jiayi Shao,  Yi Yang",
                "发布日期": "2023-03-16",
                "摘要": "  Recently, visual-language navigation (VLN) -- entailing robot agents to\nfollow navigation instructions -- has shown great advance. However, existing\nliterature put most emphasis on interpreting instructions into actions, only\ndelivering \"dumb\" wayfinding agents. In this article, we devise LANA, a\nlanguage-capable navigation agent which is able to not only execute\nhuman-written navigation commands, but also provide route descriptions to\nhumans. This is achieved by simultaneously learning instruction following and\ngeneration with only one single model. More specifically, two encoders,\nrespectively for route and language encoding, are built and shared by two\ndecoders, respectively, for action prediction and instruction generation, so as\nto exploit cross-task knowledge and capture task-specific characteristics.\nThroughout pretraining and fine-tuning, both instruction following and\ngeneration are set as optimization objectives. We empirically verify that,\ncompared with recent advanced task-specific solutions, LANA attains better\nperformances on both instruction following and route description, with nearly\nhalf complexity. In addition, endowed with language generation capability, LANA\ncan explain to humans its behaviors and assist human's wayfinding. This work is\nexpected to foster future efforts towards building more trustworthy and\nsocially-intelligent navigation robots.\n",
                "链接": "https://arxiv.org/abs/2303.08409"
            },
            {
                "文章ID": "97652",
                "标题": "Evaluating the Instruction-Following Robustness of Large Language Models\n  to Prompt Injection",
                "作者": " Zekun Li,  Baolin Peng,  Pengcheng He,  Xifeng Yan",
                "发布日期": "2023-11-28",
                "摘要": "  Large Language Models (LLMs) have demonstrated exceptional proficiency in\ninstruction-following, becoming increasingly crucial across various\napplications. However, this capability brings with it the risk of prompt\ninjection attacks, where attackers inject instructions into LLMs' input to\nelicit undesirable actions or content. Understanding the robustness of LLMs\nagainst such attacks is vital for their safe implementation. In this work, we\nestablish a benchmark to evaluate the robustness of instruction-following LLMs\nagainst prompt injection attacks. Our objective is to determine the extent to\nwhich LLMs can be influenced by injected instructions and their ability to\ndifferentiate between these injected and original target instructions. Through\nextensive experiments with leading instruction-following LLMs, we uncover\nsignificant vulnerabilities in their robustness to such attacks. Our results\nindicate that some models are overly tuned to follow any embedded instructions\nin the prompt, overly focusing on the latter parts of the prompt without fully\ngrasping the entire context. By contrast, models with a better grasp of the\ncontext and instruction-following capabilities will potentially be more\nsusceptible to compromise by injected instructions. This underscores the need\nto shift the focus from merely enhancing LLMs' instruction-following\ncapabilities to improving their overall comprehension of prompts and\ndiscernment of instructions that are appropriate to follow. We hope our\nin-depth analysis offers insights into the underlying causes of these\nvulnerabilities, aiding in the development of future solutions. Code and data\nare available at\nhttps://github.com/Leezekun/instruction-following-robustness-eval\n",
                "链接": "https://arxiv.org/abs/2308.10819"
            },
            {
                "文章ID": "86706",
                "标题": "BayLing: Bridging Cross-lingual Alignment and Instruction Following\n  through Interactive Translation for Large Language Models",
                "作者": " Shaolei Zhang,  Qingkai Fang,  Zhuocheng Zhang,  Zhengrui Ma,  Yan Zhou,  Langlin Huang,  Mengyu Bu,  Shangtong Gui,  Yunji Chen,  Xilin Chen,  Yang Feng",
                "发布日期": "2023-06-22",
                "摘要": "  Large language models (LLMs) have demonstrated remarkable prowess in language\nunderstanding and generation. Advancing from foundation LLMs to\ninstructionfollowing LLMs, instruction tuning plays a vital role in aligning\nLLMs to human preferences. However, the existing LLMs are usually focused on\nEnglish, leading to inferior performance in non-English languages. In order to\nimprove the performance for non-English languages, it is necessary to collect\nlanguage-specific training data for foundation LLMs and construct\nlanguage-specific instructions for instruction tuning, both of which are heavy\nloads. To minimize human workload, we propose to transfer the capabilities of\nlanguage generation and instruction following from English to other languages\nthrough an interactive translation task. We have developed BayLing, an\ninstruction-following LLM by utilizing LLaMA as the foundation LLM and\nautomatically constructing interactive translation instructions for instructing\ntuning. Extensive assessments demonstrate that BayLing achieves comparable\nperformance to GPT-3.5-turbo, despite utilizing a considerably smaller\nparameter size of only 13 billion. Experimental results on translation tasks\nshow that BayLing achieves 95% of single-turn translation capability compared\nto GPT-4 with automatic evaluation and 96% of interactive translation\ncapability compared to GPT-3.5-turbo with human evaluation. To estimate the\nperformance on general tasks, we created a multi-turn instruction test set\ncalled BayLing-80. The experimental results on BayLing-80 indicate that BayLing\nachieves 89% of performance compared to GPT-3.5-turbo. BayLing also\ndemonstrates outstanding performance on knowledge assessment of Chinese GaoKao\nand English SAT, second only to GPT-3.5-turbo among a multitude of\ninstruction-following LLMs. Demo, homepage, code and models of BayLing are\navailable.\n",
                "链接": "https://arxiv.org/abs/2306.10968"
            },
            {
                "文章ID": "44753",
                "标题": "Instruction-Following Agents with Multimodal Transformer",
                "作者": " Hao Liu,  Lisa Lee,  Kimin Lee,  Pieter Abbeel",
                "发布日期": "2023-03-28",
                "摘要": "  Humans are excellent at understanding language and vision to accomplish a\nwide range of tasks. In contrast, creating general instruction-following\nembodied agents remains a difficult challenge. Prior work that uses pure\nlanguage-only models lack visual grounding, making it difficult to connect\nlanguage instructions with visual observations. On the other hand, methods that\nuse pre-trained multimodal models typically come with divided language and\nvisual representations, requiring designing specialized network architecture to\nfuse them together. We propose a simple yet effective model for robots to solve\ninstruction-following tasks in vision-based environments. Our \\ours method\nconsists of a multimodal transformer that encodes visual observations and\nlanguage instructions, and a transformer-based policy that predicts actions\nbased on encoded representations. The multimodal transformer is pre-trained on\nmillions of image-text pairs and natural language text, thereby producing\ngeneric cross-modal representations of observations and instructions. The\ntransformer-based policy keeps track of the full history of observations and\nactions, and predicts actions autoregressively. Despite its simplicity, we show\nthat this unified transformer model outperforms all state-of-the-art\npre-trained or trained-from-scratch methods in both single-task and multi-task\nsettings. Our model also shows better model scalability and generalization\nability than prior work.\n",
                "链接": "https://arxiv.org/abs/2210.13431"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于gpt4自动生成prompt的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "116159",
                "标题": "Do Physicians Know How to Prompt? The Need for Automatic Prompt\n  Optimization Help in Clinical Note Generation",
                "作者": " Zonghai Yao,  Ahmed Jaafar,  Beining Wang,  Yue Zhu,  Zhichao Yang,  Hong Yu",
                "发布日期": "2023-11-17",
                "摘要": "  This study examines the effect of prompt engineering on the performance of\nLarge Language Models (LLMs) in clinical note generation. We introduce an\nAutomatic Prompt Optimization (APO) framework to refine initial prompts and\ncompare the outputs of medical experts, non-medical experts, and APO-enhanced\nGPT3.5 and GPT4. Results highlight GPT4 APO's superior performance in\nstandardizing prompt quality across clinical note sections. A human-in-the-loop\napproach shows that experts maintain content quality post-APO, with a\npreference for their own modifications, suggesting the value of expert\ncustomization. We recommend a two-phase optimization process, leveraging\nAPO-GPT4 for consistency and expert input for personalization.\n",
                "链接": "https://arxiv.org/abs/2311.09684"
            },
            {
                "文章ID": "118879",
                "标题": "TARGET: Template-Transferable Backdoor Attack Against Prompt-based NLP\n  Models via GPT4",
                "作者": " Zihao Tan,  Qingliang Chen,  Yongjian Huang,  Chen Liang",
                "发布日期": "2023-11-30",
                "摘要": "  Prompt-based learning has been widely applied in many low-resource NLP tasks\nsuch as few-shot scenarios. However, this paradigm has been shown to be\nvulnerable to backdoor attacks. Most of the existing attack methods focus on\ninserting manually predefined templates as triggers in the pre-training phase\nto train the victim model and utilize the same triggers in the downstream task\nto perform inference, which tends to ignore the transferability and\nstealthiness of the templates. In this work, we propose a novel approach of\nTARGET (Template-trAnsfeRable backdoor attack aGainst prompt-basEd NLP models\nvia GPT4), which is a data-independent attack method. Specifically, we first\nutilize GPT4 to reformulate manual templates to generate tone-strong and normal\ntemplates, and the former are injected into the model as a backdoor trigger in\nthe pre-training phase. Then, we not only directly employ the above templates\nin the downstream task, but also use GPT4 to generate templates with similar\ntone to the above templates to carry out transferable attacks. Finally we have\nconducted extensive experiments on five NLP datasets and three BERT series\nmodels, with experimental results justifying that our TARGET method has better\nattack performance and stealthiness compared to the two-external baseline\nmethods on direct attacks, and in addition achieves satisfactory attack\ncapability in the unseen tone-similar templates.\n",
                "链接": "https://arxiv.org/abs/2311.17429"
            },
            {
                "文章ID": "103691",
                "标题": "OpenAi's GPT4 as coding assistant",
                "作者": " Lefteris Moussiades,  George Zografos",
                "发布日期": "2023-09-25",
                "摘要": "  Lately, Large Language Models have been widely used in code generation. GPT4\nis considered the most potent Large Language Model from Openai. In this paper,\nwe examine GPT3.5 and GPT4 as coding assistants. More specifically, we have\nconstructed appropriate tests to check whether the two systems can a) answer\ntypical questions that can arise during the code development, b) produce\nreliable code, and c) contribute to code debugging. The test results are\nimpressive. The performance of GPT4 is outstanding and signals an increase in\nthe productivity of programmers and the reorganization of software development\nprocedures based on these new tools.\n",
                "链接": "https://arxiv.org/abs/2309.12732"
            },
            {
                "文章ID": "91013",
                "标题": "AutoHint: Automatic Prompt Optimization with Hint Generation",
                "作者": " Hong Sun,  Xue Li,  Yinchuan Xu,  Youkow Homma,  Qi Cao,  Min Wu,  Jian Jiao,  Denis Charles",
                "发布日期": "2023-08-10",
                "摘要": "  This paper presents AutoHint, a novel framework for automatic prompt\nengineering and optimization for Large Language Models (LLM). While LLMs have\ndemonstrated remarkable ability in achieving high-quality annotation in various\ntasks, the key to applying this ability to specific tasks lies in developing\nhigh-quality prompts. Thus we propose a framework to inherit the merits of both\nin-context learning and zero-shot learning by incorporating enriched\ninstructions derived from input-output demonstrations to optimize original\nprompt. We refer to the enrichment as the hint and propose a framework to\nautomatically generate the hint from labeled data. More concretely, starting\nfrom an initial prompt, our method first instructs a LLM to deduce new hints\nfor selected samples from incorrect predictions, and then summarizes from\nper-sample hints and adds the results back to the initial prompt to form a new,\nenriched instruction. The proposed method is evaluated on the BIG-Bench\nInstruction Induction dataset for both zero-shot and few-short prompts, where\nexperiments demonstrate our method is able to significantly boost accuracy for\nmultiple tasks.\n",
                "链接": "https://arxiv.org/abs/2307.07415"
            },
            {
                "文章ID": "114811",
                "标题": "Prompt Engineering a Prompt Engineer",
                "作者": " Qinyuan Ye,  Maxamed Axmed,  Reid Pryzant,  Fereshte Khani",
                "发布日期": "2023-11-13",
                "摘要": "  Prompt engineering is a challenging yet crucial task for optimizing the\nperformance of large language models (LLMs). It requires complex reasoning to\nexamine the model's errors, hypothesize what is missing or misleading in the\ncurrent prompt, and communicate the task with clarity. While recent works\nindicate that LLMs can be meta-prompted to perform automatic prompt\nengineering, their potentials may not be fully untapped due to the lack of\nsufficient guidance to elicit complex reasoning capabilities in LLMs in the\nmeta-prompt. In this work, we investigate the problem of \"prompt engineering a\nprompt engineer\" -- constructing a meta-prompt that more effectively guides\nLLMs to perform automatic prompt engineering. We introduce and analyze key\ncomponents, such as a step-by-step reasoning template and context\nspecification, which lead to improved performance. In addition, inspired by\ncommon optimization concepts such as batch size, step size and momentum, we\nintroduce their verbalized counterparts to the meta-prompt and investigate\ntheir effects. Our final method, named PE2, finds a prompt that outperforms\n\"let's think step by step\" by 6.3% on the MultiArith dataset and 3.1% on the\nGSM8K dataset. To demonstrate its versatility, we apply PE2 to the Instruction\nInduction benchmark, a suite of counterfactual tasks, and a lengthy, real-world\nindustrial prompt. In these settings, PE2 achieves strong performance and\noutperforms prior automatic prompt engineering baselines. Further, we show that\nPE2 makes meaningful and targeted prompt edits, amends erroneous or incomplete\nprompts, and presents non-trivial counterfactual reasoning abilities.\n",
                "链接": "https://arxiv.org/abs/2311.05661"
            },
            {
                "文章ID": "103106",
                "标题": "Is GPT4 a Good Trader?",
                "作者": " Bingzhe Wu",
                "发布日期": "2023-09-21",
                "摘要": "  Recently, large language models (LLMs), particularly GPT-4, have demonstrated\nsignificant capabilities in various planning and reasoning tasks\n\\cite{cheng2023gpt4,bubeck2023sparks}. Motivated by these advancements, there\nhas been a surge of interest among researchers to harness the capabilities of\nGPT-4 for the automated design of quantitative factors that do not overlap with\nexisting factor libraries, with an aspiration to achieve alpha returns\n\\cite{webpagequant}. In contrast to these work, this study aims to examine the\nfidelity of GPT-4's comprehension of classic trading theories and its\nproficiency in applying its code interpreter abilities to real-world trading\ndata analysis. Such an exploration is instrumental in discerning whether the\nunderlying logic GPT-4 employs for trading is intrinsically reliable.\nFurthermore, given the acknowledged interpretative latitude inherent in most\ntrading theories, we seek to distill more precise methodologies of deploying\nthese theories from GPT-4's analytical process, potentially offering invaluable\ninsights to human traders.\n  To achieve this objective, we selected daily candlestick (K-line) data from\nspecific periods for certain assets, such as the Shanghai Stock Index. Through\nmeticulous prompt engineering, we guided GPT-4 to analyze the technical\nstructures embedded within this data, based on specific theories like the\nElliott Wave Theory. We then subjected its analytical output to manual\nevaluation, assessing its interpretative depth and accuracy vis-\\`a-vis these\ntrading theories from multiple dimensions. The results and findings from this\nstudy could pave the way for a synergistic amalgamation of human expertise and\nAI-driven insights in the realm of trading.\n",
                "链接": "https://arxiv.org/abs/2309.10982"
            },
            {
                "文章ID": "105319",
                "标题": "Automatic Prompt Rewriting for Personalized Text Generation",
                "作者": " Cheng Li,  Mingyang Zhang,  Qiaozhu Mei,  Weize Kong,  Michael Bendersky",
                "发布日期": "2023-10-03",
                "摘要": "  Facilitated by large language models (LLMs), personalized text generation has\nbecome a rapidly growing research direction. Most existing studies focus on\ndesigning specialized models for a particular domain, or they require\nfine-tuning the LLMs to generate personalized text. We consider a typical\nscenario in which the large language model, which generates personalized\noutput, is frozen and can only be accessed through APIs. Under this constraint,\nall one can do is to improve the input text (i.e., text prompts) sent to the\nLLM, a procedure that is usually done manually. In this paper, we propose a\nnovel method to automatically revise prompts for personalized text generation.\nThe proposed method takes the initial prompts generated by a state-of-the-art,\nmultistage framework for personalized generation and rewrites a few critical\ncomponents that summarize and synthesize the personal context. The prompt\nrewriter employs a training paradigm that chains together supervised learning\n(SL) and reinforcement learning (RL), where SL reduces the search space of RL\nand RL facilitates end-to-end training of the rewriter. Using datasets from\nthree representative domains, we demonstrate that the rewritten prompts\noutperform both the original prompts and the prompts optimized via supervised\nlearning or reinforcement learning alone. In-depth analysis of the rewritten\nprompts shows that they are not only human readable, but also able to guide\nmanual revision of prompts when there is limited resource to employ\nreinforcement learning to train the prompt rewriter, or when it is costly to\ndeploy an automatic prompt rewriter for inference.\n",
                "链接": "https://arxiv.org/abs/2310.00152"
            },
            {
                "文章ID": "112250",
                "标题": "Prompt-Engineering and Transformer-based Question Generation and\n  Evaluation",
                "作者": " Rubaba Amyeen",
                "发布日期": "2023-10-31",
                "摘要": "  Question generation has numerous applications in the educational context.\nQuestion generation can prove helpful for students when reviewing content and\ntesting themselves. Furthermore, a question generation model can aid teachers\nby lessening the burden of creating assessments and other practice material.\nThis paper aims to find the best method to generate questions from textual data\nthrough a transformer model and prompt engineering. In this research, we\nfinetuned a pretrained distilBERT model on the SQuAD question answering dataset\nto generate questions. In addition to training a transformer model, prompt\nengineering was applied to generate questions effectively using the LLaMA\nmodel. The generated questions were compared against the baseline questions in\nthe SQuAD dataset to evaluate the effectiveness of four different prompts. All\nfour prompts demonstrated over 60% similarity on average. Of the\nprompt-generated questions, 30% achieved a high similarity score greater than\n70%.\n",
                "链接": "https://arxiv.org/abs/2310.18867"
            },
            {
                "文章ID": "95574",
                "标题": "Emotion-Conditioned Text Generation through Automatic Prompt\n  Optimization",
                "作者": " Yarik Menchaca Resendiz,  Roman Klinger",
                "发布日期": "2023-08-10",
                "摘要": "  Conditional natural language generation methods often require either\nexpensive fine-tuning or training a large language model from scratch. Both are\nunlikely to lead to good results without a substantial amount of data and\ncomputational resources. Prompt learning without changing the parameters of a\nlarge language model presents a promising alternative. It is a cost-effective\napproach, while still achieving competitive results. While this procedure is\nnow established for zero- and few-shot text classification and structured\nprediction, it has received limited attention in conditional text generation.\nWe present the first automatic prompt optimization approach for\nemotion-conditioned text generation with instruction-fine-tuned models. Our\nmethod uses an iterative optimization procedure that changes the prompt by\nadding, removing, or replacing tokens. As objective function, we only require a\ntext classifier that measures the realization of the conditional variable in\nthe generated text. We evaluate the method on emotion-conditioned text\ngeneration with a focus on event reports and compare it to manually designed\nprompts that also act as the seed for the optimization procedure. The optimized\nprompts achieve 0.75 macro-average F1 to fulfill the emotion condition in\ncontrast to manually designed seed prompts with only 0.22 macro-average F1.\n",
                "链接": "https://arxiv.org/abs/2308.04857"
            },
            {
                "文章ID": "62985",
                "标题": "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT",
                "作者": " Jules White,  Quchen Fu,  Sam Hays,  Michael Sandborn,  Carlos Olea,  Henry Gilbert,  Ashraf Elnashar,  Jesse Spencer-Smith,  Douglas C. Schmidt",
                "发布日期": "2023-02-23",
                "摘要": "  Prompt engineering is an increasingly important skill set needed to converse\neffectively with large language models (LLMs), such as ChatGPT. Prompts are\ninstructions given to an LLM to enforce rules, automate processes, and ensure\nspecific qualities (and quantities) of generated output. Prompts are also a\nform of programming that can customize the outputs and interactions with an\nLLM. This paper describes a catalog of prompt engineering techniques presented\nin pattern form that have been applied to solve common problems when conversing\nwith LLMs. Prompt patterns are a knowledge transfer method analogous to\nsoftware patterns since they provide reusable solutions to common problems\nfaced in a particular context, i.e., output generation and interaction when\nworking with LLMs. This paper provides the following contributions to research\non prompt engineering that apply LLMs to automate software development tasks.\nFirst, it provides a framework for documenting patterns for structuring prompts\nto solve a range of problems so that they can be adapted to different domains.\nSecond, it presents a catalog of patterns that have been applied successfully\nto improve the outputs of LLM conversations. Third, it explains how prompts can\nbe built from multiple patterns and illustrates prompt patterns that benefit\nfrom combination with other prompt patterns.\n",
                "链接": "https://arxiv.org/abs/2302.11382"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态agent, 具身智能的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "63780",
                "标题": "Multimodal Speech Recognition for Language-Guided Embodied Agents",
                "作者": " Allen Chang,  Xiaoyuan Zhu,  Aarav Monga,  Seoho Ahn,  Tejas Srinivasan,  Jesse Thomason",
                "发布日期": "2023-10-11",
                "摘要": "  Benchmarks for language-guided embodied agents typically assume text-based\ninstructions, but deployed agents will encounter spoken instructions. While\nAutomatic Speech Recognition (ASR) models can bridge the input gap, erroneous\nASR transcripts can hurt the agents' ability to complete tasks. In this work,\nwe propose training a multimodal ASR model to reduce errors in transcribing\nspoken instructions by considering the accompanying visual context. We train\nour model on a dataset of spoken instructions, synthesized from the ALFRED task\ncompletion dataset, where we simulate acoustic noise by systematically masking\nspoken words. We find that utilizing visual observations facilitates masked\nword recovery, with multimodal ASR models recovering up to 30% more masked\nwords than unimodal baselines. We also find that a text-trained embodied agent\nsuccessfully completes tasks more often by following transcribed instructions\nfrom multimodal ASR models. github.com/Cylumn/embodied-multimodal-asr\n",
                "链接": "https://arxiv.org/abs/2302.14030"
            },
            {
                "文章ID": "104544",
                "标题": "The Importance of Multimodal Emotion Conditioning and Affect Consistency\n  for Embodied Conversational Agents",
                "作者": " Che-Jui Chang,  Samuel S. Sohn,  Sen Zhang,  Rajath Jayashankar,  Muhammad Usman,  Mubbasir Kapadia",
                "发布日期": "2023-12-08",
                "摘要": "  Previous studies regarding the perception of emotions for embodied virtual\nagents have shown the effectiveness of using virtual characters in conveying\nemotions through interactions with humans. However, creating an autonomous\nembodied conversational agent with expressive behaviors presents two major\nchallenges. The first challenge is the difficulty of synthesizing the\nconversational behaviors for each modality that are as expressive as real human\nbehaviors. The second challenge is that the affects are modeled independently,\nwhich makes it difficult to generate multimodal responses with consistent\nemotions across all modalities. In this work, we propose a conceptual\nframework, ACTOR (Affect-Consistent mulTimodal behaviOR generation), that aims\nto increase the perception of affects by generating multimodal behaviors\nconditioned on a consistent driving affect. We have conducted a user study with\n199 participants to assess how the average person judges the affects perceived\nfrom multimodal behaviors that are consistent and inconsistent with respect to\na driving affect. The result shows that among all model conditions, our\naffect-consistent framework receives the highest Likert scores for the\nperception of driving affects. Our statistical analysis suggests that making a\nmodality affect-inconsistent significantly decreases the perception of driving\naffects. We also observe that multimodal behaviors conditioned on consistent\naffects are more expressive compared to behaviors with inconsistent affects.\nTherefore, we conclude that multimodal emotion conditioning and affect\nconsistency are vital to enhancing the perception of affects for embodied\nconversational agents.\n",
                "链接": "https://arxiv.org/abs/2309.15311"
            },
            {
                "文章ID": "114225",
                "标题": "Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI",
                "作者": " Song Yaoxian,  Sun Penglei,  Liu Haoyu,  Li Zhixu,  Song Wei,  Xiao Yanghua,  Zhou Xiaofang",
                "发布日期": "2023-11-08",
                "摘要": "  Embodied AI is one of the most popular studies in artificial intelligence and\nrobotics, which can effectively improve the intelligence of real-world agents\n(i.e. robots) serving human beings. Scene knowledge is important for an agent\nto understand the surroundings and make correct decisions in the varied open\nworld. Currently, knowledge base for embodied tasks is missing and most\nexisting work use general knowledge base or pre-trained models to enhance the\nintelligence of an agent. For conventional knowledge base, it is sparse,\ninsufficient in capacity and cost in data collection. For pre-trained models,\nthey face the uncertainty of knowledge and hard maintenance. To overcome the\nchallenges of scene knowledge, we propose a scene-driven multimodal knowledge\ngraph (Scene-MMKG) construction method combining conventional knowledge\nengineering and large language models. A unified scene knowledge injection\nframework is introduced for knowledge representation. To evaluate the\nadvantages of our proposed method, we instantiate Scene-MMKG considering\ntypical indoor robotic functionalities (Manipulation and Mobility), named\nManipMob-MMKG. Comparisons in characteristics indicate our instantiated\nManipMob-MMKG has broad superiority in data-collection efficiency and knowledge\nquality. Experimental results on typical embodied tasks show that\nknowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the\nperformance obviously without re-designing model structures complexly. Our\nproject can be found at https://sites.google.com/view/manipmob-mmkg\n",
                "链接": "https://arxiv.org/abs/2311.03783"
            },
            {
                "文章ID": "114303",
                "标题": "Multitask Multimodal Prompted Training for Interactive Embodied Task\n  Completion",
                "作者": " Georgios Pantazopoulos,  Malvina Nikandrou,  Amit Parekh,  Bhathiya Hemanthage,  Arash Eshghi,  Ioannis Konstas,  Verena Rieser,  Oliver Lemon,  Alessandro Suglia",
                "发布日期": "2023-11-08",
                "摘要": "  Interactive and embodied tasks pose at least two fundamental challenges to\nexisting Vision & Language (VL) models, including 1) grounding language in\ntrajectories of actions and observations, and 2) referential disambiguation. To\ntackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a\nunified encoder-decoder model that reasons over images and trajectories, and\ncasts action prediction as multimodal text generation. By unifying all tasks as\ntext generation, EMMA learns a language of actions which facilitates transfer\nacross tasks. Different to previous modular approaches with independently\ntrained components, we use a single multitask model where each task contributes\nto goal completion. EMMA performs on par with similar models on several VL\nbenchmarks and sets a new state-of-the-art performance (36.81% success rate) on\nthe Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided\nagents in the Alexa Arena\n",
                "链接": "https://arxiv.org/abs/2311.04067"
            },
            {
                "文章ID": "93062",
                "标题": "MAEA: Multimodal Attribution for Embodied AI",
                "作者": " Vidhi Jain,  Jayant Sravan Tamarapalli,  Sahiti Yerramilli,  Yonatan Bisk",
                "发布日期": "2023-07-27",
                "摘要": "  Understanding multimodal perception for embodied AI is an open question\nbecause such inputs may contain highly complementary as well as redundant\ninformation for the task. A relevant direction for multimodal policies is\nunderstanding the global trends of each modality at the fusion layer. To this\nend, we disentangle the attributions for visual, language, and previous action\ninputs across different policies trained on the ALFRED dataset. Attribution\nanalysis can be utilized to rank and group the failure scenarios, investigate\nmodeling and dataset biases, and critically analyze multimodal EAI policies for\nrobustness and user trust before deployment. We present MAEA, a framework to\ncompute global attributions per modality of any differentiable policy. In\naddition, we show how attributions enable lower-level behavior analysis in EAI\npolicies for language and visual attributions.\n",
                "链接": "https://arxiv.org/abs/2307.13850"
            },
            {
                "文章ID": "118026",
                "标题": "Agent as Cerebrum, Controller as Cerebellum: Implementing an Embodied\n  LMM-based Agent on Drones",
                "作者": " Haoran Zhao,  Fengxing Pan,  Huqiuyue Ping,  Yaoming Zhou",
                "发布日期": "2023-11-28",
                "摘要": "  In this study, we present a novel paradigm for industrial robotic embodied\nagents, encapsulating an 'agent as cerebrum, controller as cerebellum'\narchitecture. Our approach harnesses the power of Large Multimodal Models\n(LMMs) within an agent framework known as AeroAgent, tailored for drone\ntechnology in industrial settings. To facilitate seamless integration with\nrobotic systems, we introduce ROSchain, a bespoke linkage framework connecting\nLMM-based agents to the Robot Operating System (ROS). We report findings from\nextensive empirical research, including simulated experiments on the Airgen and\nreal-world case study, particularly in individual search and rescue operations.\nThe results demonstrate AeroAgent's superior performance in comparison to\nexisting Deep Reinforcement Learning (DRL)-based agents, highlighting the\nadvantages of the embodied LMM in complex, real-world scenarios.\n",
                "链接": "https://arxiv.org/abs/2311.15033"
            },
            {
                "文章ID": "65105",
                "标题": "PaLM-E: An Embodied Multimodal Language Model",
                "作者": " Danny Driess,  Fei Xia,  Mehdi S. M. Sajjadi,  Corey Lynch,  Aakanksha Chowdhery,  Brian Ichter,  Ayzaan Wahid,  Jonathan Tompson,  Quan Vuong,  Tianhe Yu,  Wenlong Huang,  Yevgen Chebotar,  Pierre Sermanet,  Daniel Duckworth,  Sergey Levine,  Vincent Vanhoucke,  Karol Hausman,  Marc Toussaint,  Klaus Greff,  Andy Zeng,  Igor Mordatch,  Pete Florence",
                "发布日期": "2023-03-07",
                "摘要": "  Large language models excel at a wide range of complex tasks. However,\nenabling general inference in the real world, e.g., for robotics problems,\nraises the challenge of grounding. We propose embodied language models to\ndirectly incorporate real-world continuous sensor modalities into language\nmodels and thereby establish the link between words and percepts. Input to our\nembodied language model are multi-modal sentences that interleave visual,\ncontinuous state estimation, and textual input encodings. We train these\nencodings end-to-end, in conjunction with a pre-trained large language model,\nfor multiple embodied tasks including sequential robotic manipulation planning,\nvisual question answering, and captioning. Our evaluations show that PaLM-E, a\nsingle large embodied multimodal model, can address a variety of embodied\nreasoning tasks, from a variety of observation modalities, on multiple\nembodiments, and further, exhibits positive transfer: the model benefits from\ndiverse joint training across internet-scale language, vision, and\nvisual-language domains. Our largest model, PaLM-E-562B with 562B parameters,\nin addition to being trained on robotics tasks, is a visual-language generalist\nwith state-of-the-art performance on OK-VQA, and retains generalist language\ncapabilities with increasing scale.\n",
                "链接": "https://arxiv.org/abs/2303.03378"
            },
            {
                "文章ID": "76926",
                "标题": "Multimodal Contextualized Plan Prediction for Embodied Task Completion",
                "作者": " Mert İnan,  Aishwarya Padmakumar,  Spandana Gella,  Patrick Lange,  Dilek Hakkani-Tur",
                "发布日期": "2023-05-12",
                "摘要": "  Task planning is an important component of traditional robotics systems\nenabling robots to compose fine grained skills to perform more complex tasks.\nRecent work building systems for translating natural language to executable\nactions for task completion in simulated embodied agents is focused on directly\npredicting low level action sequences that would be expected to be directly\nexecutable by a physical robot. In this work, we instead focus on predicting a\nhigher level plan representation for one such embodied task completion dataset\n- TEACh, under the assumption that techniques for high-level plan prediction\nfrom natural language are expected to be more transferable to physical robot\nsystems. We demonstrate that better plans can be predicted using multimodal\ncontext, and that plan prediction and plan execution modules are likely\ndependent on each other and hence it may not be ideal to fully decouple them.\nFurther, we benchmark execution of oracle plans to quantify the scope for\nimprovement in plan prediction models.\n",
                "链接": "https://arxiv.org/abs/2305.06485"
            },
            {
                "文章ID": "89562",
                "标题": "Building Cooperative Embodied Agents Modularly with Large Language\n  Models",
                "作者": " Hongxin Zhang,  Weihua Du,  Jiaming Shan,  Qinhong Zhou,  Yilun Du,  Joshua B. Tenenbaum,  Tianmin Shu,  Chuang Gan",
                "发布日期": "2023-07-06",
                "摘要": "  Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.\n",
                "链接": "https://arxiv.org/abs/2307.02485"
            },
            {
                "文章ID": "123652",
                "标题": "Urban Generative Intelligence (UGI): A Foundational Platform for Agents\n  in Embodied City Environment",
                "作者": " Fengli Xu,  Jun Zhang,  Chen Gao,  Jie Feng,  Yong Li",
                "发布日期": "2023-12-20",
                "摘要": "  Urban environments, characterized by their complex, multi-layered networks\nencompassing physical, social, economic, and environmental dimensions, face\nsignificant challenges in the face of rapid urbanization. These challenges,\nranging from traffic congestion and pollution to social inequality, call for\nadvanced technological interventions. Recent developments in big data,\nartificial intelligence, urban computing, and digital twins have laid the\ngroundwork for sophisticated city modeling and simulation. However, a gap\npersists between these technological capabilities and their practical\nimplementation in addressing urban challenges in an systemic-intelligent way.\nThis paper proposes Urban Generative Intelligence (UGI), a novel foundational\nplatform integrating Large Language Models (LLMs) into urban systems to foster\na new paradigm of urban intelligence. UGI leverages CityGPT, a foundation model\ntrained on city-specific multi-source data, to create embodied agents for\nvarious urban tasks. These agents, operating within a textual urban environment\nemulated by city simulator and urban knowledge graph, interact through a\nnatural language interface, offering an open platform for diverse intelligent\nand embodied agent development. This platform not only addresses specific urban\nissues but also simulates complex urban systems, providing a multidisciplinary\napproach to understand and manage urban complexity. This work signifies a\ntransformative step in city science and urban intelligence, harnessing the\npower of LLMs to unravel and address the intricate dynamics of urban systems.\nThe code repository with demonstrations will soon be released here\nhttps://github.com/tsinghua-fib-lab/UGI.\n",
                "链接": "https://arxiv.org/abs/2312.11813"
            }
        ]
    },
    {
        "question": {
            "question": "新的大模型结构相关探索的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "111645",
                "标题": "IDENAS: Internal Dependency Exploration for Neural Architecture Search",
                "作者": " Anh T. Hoang,  Zsolt J. Viharos",
                "发布日期": "2023-10-27",
                "摘要": "  Machine learning is a powerful tool for extracting valuable information and\nmaking various predictions from diverse datasets. Traditional algorithms rely\non well-defined input and output variables however, there are scenarios where\nthe distinction between the input and output variables and the underlying,\nassociated (input and output) layers of the model, are unknown. Neural\nArchitecture Search (NAS) and Feature Selection have emerged as promising\nsolutions in such scenarios. This research proposes IDENAS, an Internal\nDependency-based Exploration for Neural Architecture Search, integrating NAS\nwith feature selection. The methodology explores internal dependencies in the\ncomplete parameter space for classification involving 1D sensor and 2D image\ndata as well. IDENAS employs a modified encoder-decoder model and the\nSequential Forward Search (SFS) algorithm, combining input-output configuration\nsearch with embedded feature selection. Experimental results demonstrate\nIDENASs superior performance in comparison to other algorithms, showcasing its\neffectiveness in model development pipelines and automated machine learning. On\naverage, IDENAS achieved significant modelling improvements, underscoring its\nsignificant contribution to advancing the state-of-the-art in neural\narchitecture search and feature selection integration.\n",
                "链接": "https://arxiv.org/abs/2310.17250"
            },
            {
                "文章ID": "117402",
                "标题": "Building the Future of Responsible AI: A Reference Architecture for\n  Designing Large Language Model based Agents",
                "作者": " Qinghua Lu,  Liming Zhu,  Xiwei Xu,  Zhenchang Xing,  Stefan Harrer,  Jon Whittle",
                "发布日期": "2023-11-29",
                "摘要": "  Large language models (LLMs) have been widely recognised as transformative\nartificial generative intelligence (AGI) technologies due to their capabilities\nto understand and generate content, including plans with reasoning\ncapabilities. Foundation model based agents derive their autonomy from the\ncapabilities of foundation models, which enable them to autonomously break down\na given goal into a set of manageable tasks and orchestrate task execution to\nmeet the goal. Despite the huge efforts put into building foundation model\nbased autonomous agents, the architecture design of the agents has not yet been\nsystematically explored. Also, while there are significant benefits of using\nautonomous agents for planning and execution, there are serious considerations\nregarding responsible AI related software quality attributes, such as security\nand accountability. Therefore, this paper presents a pattern-oriented reference\narchitecture that serves as architecture design guidance and enables\nresponsible-AI-by-design when designing foundation model based autonomous\nagents. We evaluate the completeness and utility of the proposed reference\narchitecture by mapping it to the architecture of two real-world agents.\n",
                "链接": "https://arxiv.org/abs/2311.13148"
            },
            {
                "文章ID": "48430",
                "标题": "Learning-Augmented Model-Based Planning for Visual Exploration",
                "作者": " Yimeng Li,  Arnab Debnath,  Gregory Stein,  Jana Kosecka",
                "发布日期": "2023-08-10",
                "摘要": "  We consider the problem of time-limited robotic exploration in previously\nunseen environments where exploration is limited by a predefined amount of\ntime. We propose a novel exploration approach using learning-augmented\nmodel-based planning. We generate a set of subgoals associated with frontiers\non the current map and derive a Bellman Equation for exploration with these\nsubgoals. Visual sensing and advances in semantic mapping of indoor scenes are\nexploited for training a deep convolutional neural network to estimate\nproperties associated with each frontier: the expected unobserved area beyond\nthe frontier and the expected timesteps (discretized actions) required to\nexplore it. The proposed model-based planner is guaranteed to explore the whole\nscene if time permits. We thoroughly evaluate our approach on a large-scale\npseudo-realistic indoor dataset (Matterport3D) with the Habitat simulator. We\ncompare our approach with classical and more recent RL-based exploration\nmethods. Our approach surpasses the greedy strategies by 2.1% and the RL-based\nexploration methods by 8.4% in terms of coverage.\n",
                "链接": "https://arxiv.org/abs/2211.07898"
            },
            {
                "文章ID": "89984",
                "标题": "On decoder-only architecture for speech-to-text and large language model\n  integration",
                "作者": " Jian Wu,  Yashesh Gaur,  Zhuo Chen,  Long Zhou,  Yimeng Zhu,  Tianrui Wang,  Jinyu Li,  Shujie Liu,  Bo Ren,  Linquan Liu,  Yu Wu",
                "发布日期": "2023-10-03",
                "摘要": "  Large language models (LLMs) have achieved remarkable success in the field of\nnatural language processing, enabling better human-computer interaction using\nnatural language. However, the seamless integration of speech signals into LLMs\nhas not been explored well. The \"decoder-only\" architecture has also not been\nwell studied for speech processing tasks. In this research, we introduce\nSpeech-LLaMA, a novel approach that effectively incorporates acoustic\ninformation into text-based large language models. Our method leverages\nConnectionist Temporal Classification and a simple audio encoder to map the\ncompressed acoustic features to the continuous semantic space of the LLM. In\naddition, we further probe the decoder-only architecture for speech-to-text\ntasks by training a smaller scale randomly initialized speech-LLaMA model from\nspeech-text paired data alone. We conduct experiments on multilingual\nspeech-to-text translation tasks and demonstrate a significant improvement over\nstrong baselines, highlighting the potential advantages of decoder-only models\nfor speech-to-text conversion.\n",
                "链接": "https://arxiv.org/abs/2307.03917"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "12421",
                "标题": "CHEX: CHannel EXploration for CNN Model Compression",
                "作者": " Zejiang Hou,  Minghai Qin,  Fei Sun,  Xiaolong Ma,  Kun Yuan,  Yi Xu,  Yen-Kuang Chen,  Rong Jin,  Yuan Xie,  Sun-Yuan Kung",
                "发布日期": "2022-03-30",
                "摘要": "  Channel pruning has been broadly recognized as an effective technique to\nreduce the computation and memory cost of deep convolutional neural networks.\nHowever, conventional pruning methods have limitations in that: they are\nrestricted to pruning process only, and they require a fully pre-trained large\nmodel. Such limitations may lead to sub-optimal model quality as well as\nexcessive memory and training cost. In this paper, we propose a novel Channel\nExploration methodology, dubbed as CHEX, to rectify these problems. As opposed\nto pruning-only strategy, we propose to repeatedly prune and regrow the\nchannels throughout the training process, which reduces the risk of pruning\nimportant channels prematurely. More exactly: From intra-layer's aspect, we\ntackle the channel pruning problem via a well known column subset selection\n(CSS) formulation. From inter-layer's aspect, our regrowing stages open a path\nfor dynamically re-allocating the number of channels across all the layers\nunder a global channel sparsity constraint. In addition, all the exploration\nprocess is done in a single training from scratch without the need of a\npre-trained large model. Experimental results demonstrate that CHEX can\neffectively reduce the FLOPs of diverse CNN architectures on a variety of\ncomputer vision tasks, including image classification, object detection,\ninstance segmentation, and 3D vision. For example, our compressed ResNet-50\nmodel on ImageNet dataset achieves 76% top1 accuracy with only 25% FLOPs of the\noriginal ResNet-50 model, outperforming previous state-of-the-art channel\npruning methods. The checkpoints and code are available at here .\n",
                "链接": "https://arxiv.org/abs/2203.15794"
            },
            {
                "文章ID": "57742",
                "标题": "Neural Architecture Search: Insights from 1000 Papers",
                "作者": " Colin White,  Mahmoud Safari,  Rhea Sukthanker,  Binxin Ru,  Thomas Elsken,  Arber Zela,  Debadeepta Dey,  Frank Hutter",
                "发布日期": "2023-01-26",
                "摘要": "  In the past decade, advances in deep learning have resulted in breakthroughs\nin a variety of areas, including computer vision, natural language\nunderstanding, speech recognition, and reinforcement learning. Specialized,\nhigh-performing neural architectures are crucial to the success of deep\nlearning in these areas. Neural architecture search (NAS), the process of\nautomating the design of neural architectures for a given task, is an\ninevitable next step in automating machine learning and has already outpaced\nthe best human-designed architectures on many tasks. In the past few years,\nresearch in NAS has been progressing rapidly, with over 1000 papers released\nsince 2020 (Deng and Lindauer, 2021). In this survey, we provide an organized\nand comprehensive guide to neural architecture search. We give a taxonomy of\nsearch spaces, algorithms, and speedup techniques, and we discuss resources\nsuch as benchmarks, best practices, other surveys, and open-source libraries.\n",
                "链接": "https://arxiv.org/abs/2301.08727"
            },
            {
                "文章ID": "13374",
                "标题": "QuadraLib: A Performant Quadratic Neural Network Library for\n  Architecture Optimization and Design Exploration",
                "作者": " Zirui Xu,  Fuxun Yu,  Jinjun Xiong,  Xiang Chen",
                "发布日期": "2022-04-06",
                "摘要": "  The significant success of Deep Neural Networks (DNNs) is highly promoted by\nthe multiple sophisticated DNN libraries. On the contrary, although some work\nhave proved that Quadratic Deep Neuron Networks (QDNNs) show better\nnon-linearity and learning capability than the first-order DNNs, their neuron\ndesign suffers certain drawbacks from theoretical performance to practical\ndeployment. In this paper, we first proposed a new QDNN neuron architecture\ndesign, and further developed QuadraLib, a QDNN library to provide architecture\noptimization and design exploration for QDNNs. Extensive experiments show that\nour design has good performance regarding prediction accuracy and computation\nconsumption on multiple learning tasks.\n",
                "链接": "https://arxiv.org/abs/2204.01701"
            },
            {
                "文章ID": "39924",
                "标题": "A Functional Model For Information Exploration Systems",
                "作者": " Thiago Nunes,  Daniel Schwabe",
                "发布日期": "2022-10-03",
                "摘要": "  Information exploration tasks are inherently complex, ill-structured, and\ninvolve sequences of actions usually spread over many sessions. When exploring\na dataset, users tend to experiment higher degrees of uncertainty, mostly\nraised by knowledge gaps concerning the information sources, the task, and the\nefficiency of the chosen exploration actions, strategies, and tools in\nsupporting the task solution process. Provided these concerns, exploration\ntools should be designed with the goal of leveraging the mapping between user's\ncognitive actions and solution strategies onto the current systems' operations.\nHowever, state-of-the-art systems fail in providing an expressive set of\noperations that covers a wide range of exploration problems. There is not a\ncommon understanding of neither which operators are required nor in which ways\nthey can be used by explorers. In order to mitigate these shortcomings, this\nwork presents a formal framework of exploration operations expressive enough to\ndescribe at least the majority of state-of-the-art exploration interfaces and\ntasks. We also show how the framework leveraged a new evaluation approach,\nwhere we draw precise comparisons between tools concerning the range of\nexploration tasks they support.\n",
                "链接": "https://arxiv.org/abs/2209.15622"
            },
            {
                "文章ID": "90011",
                "标题": "Efficient Model-Free Exploration in Low-Rank MDPs",
                "作者": " Zakaria Mhammedi,  Adam Block,  Dylan J. Foster,  Alexander Rakhlin",
                "发布日期": "2023-07-11",
                "摘要": "  A major challenge in reinforcement learning is to develop practical,\nsample-efficient algorithms for exploration in high-dimensional domains where\ngeneralization and function approximation is required. Low-Rank Markov Decision\nProcesses -- where transition probabilities admit a low-rank factorization\nbased on an unknown feature embedding -- offer a simple, yet expressive\nframework for RL with function approximation, but existing algorithms are\neither (1) computationally intractable, or (2) reliant upon restrictive\nstatistical assumptions such as latent variable structure, access to\nmodel-based function approximation, or reachability. In this work, we propose\nthe first provably sample-efficient algorithm for exploration in Low-Rank MDPs\nthat is both computationally efficient and model-free, allowing for general\nfunction approximation and requiring no additional structural assumptions. Our\nalgorithm, VoX, uses the notion of a generalized optimal design for the feature\nembedding as an efficiently computable basis for exploration, performing\nefficient optimal design computation by interleaving representation learning\nand policy optimization. Our analysis -- which is appealingly simple and\nmodular -- carefully combines several techniques, including a new reduction\nfrom optimal design computation to policy optimization based on the Frank-Wolfe\nmethod, and an improved analysis of a certain minimax representation learning\nobjective found in prior work.\n",
                "链接": "https://arxiv.org/abs/2307.03997"
            }
        ]
    },
    {
        "question": {
            "question": "多模态细粒度图片编辑和生成相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "80167",
                "标题": "BLIP-Diffusion: Pre-trained Subject Representation for Controllable\n  Text-to-Image Generation and Editing",
                "作者": " Dongxu Li,  Junnan Li,  Steven C. H. Hoi",
                "发布日期": "2023-06-23",
                "摘要": "  Subject-driven text-to-image generation models create novel renditions of an\ninput subject based on text prompts. Existing models suffer from lengthy\nfine-tuning and difficulties preserving the subject fidelity. To overcome these\nlimitations, we introduce BLIP-Diffusion, a new subject-driven image generation\nmodel that supports multimodal control which consumes inputs of subject images\nand text prompts. Unlike other subject-driven generation models, BLIP-Diffusion\nintroduces a new multimodal encoder which is pre-trained to provide subject\nrepresentation. We first pre-train the multimodal encoder following BLIP-2 to\nproduce visual representation aligned with the text. Then we design a subject\nrepresentation learning task which enables a diffusion model to leverage such\nvisual representation and generates new subject renditions. Compared with\nprevious methods such as DreamBooth, our model enables zero-shot subject-driven\ngeneration, and efficient fine-tuning for customized subject with up to 20x\nspeedup. We also demonstrate that BLIP-Diffusion can be flexibly combined with\nexisting techniques such as ControlNet and prompt-to-prompt to enable novel\nsubject-driven generation and editing applications. Code and models will be\nreleased at\nhttps://github.com/salesforce/LAVIS/tree/main/projects/blip-diffusion. Project\npage at https://dxli94.github.io/BLIP-Diffusion-website/.\n",
                "链接": "https://arxiv.org/abs/2305.14720"
            },
            {
                "文章ID": "16141",
                "标题": "Reinforcing Generated Images via Meta-learning for One-Shot Fine-Grained\n  Visual Recognition",
                "作者": " Satoshi Tsutsui,  Yanwei Fu,  David Crandall",
                "发布日期": "2022-04-25",
                "摘要": "  One-shot fine-grained visual recognition often suffers from the problem of\nhaving few training examples for new fine-grained classes. To alleviate this\nproblem, off-the-shelf image generation techniques based on Generative\nAdversarial Networks (GANs) can potentially create additional training images.\nHowever, these GAN-generated images are often not helpful for actually\nimproving the accuracy of one-shot fine-grained recognition. In this paper, we\npropose a meta-learning framework to combine generated images with original\nimages, so that the resulting \"hybrid\" training images improve one-shot\nlearning. Specifically, the generic image generator is updated by a few\ntraining instances of novel classes, and a Meta Image Reinforcing Network\n(MetaIRNet) is proposed to conduct one-shot fine-grained recognition as well as\nimage reinforcement. Our experiments demonstrate consistent improvement over\nbaselines on one-shot fine-grained image classification benchmarks.\nFurthermore, our analysis shows that the reinforced images have more diversity\ncompared to the original and GAN-generated images.\n",
                "链接": "https://arxiv.org/abs/2204.10689"
            },
            {
                "文章ID": "39556",
                "标题": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
                "作者": " Wenhu Chen,  Hexiang Hu,  Chitwan Saharia,  William W. Cohen",
                "发布日期": "2022-11-23",
                "摘要": "  Research on text-to-image generation has witnessed significant progress in\ngenerating diverse and photo-realistic images, driven by diffusion and\nauto-regressive models trained on large-scale image-text data. Though\nstate-of-the-art models can generate high-quality images of common entities,\nthey often have difficulty generating images of uncommon entities, such as\n`Chortai (dog)' or `Picarones (food)'. To tackle this issue, we present the\nRetrieval-Augmented Text-to-Image Generator (Re-Imagen), a generative model\nthat uses retrieved information to produce high-fidelity and faithful images,\neven for rare or unseen entities. Given a text prompt, Re-Imagen accesses an\nexternal multi-modal knowledge base to retrieve relevant (image, text) pairs\nand uses them as references to generate the image. With this retrieval step,\nRe-Imagen is augmented with the knowledge of high-level semantics and low-level\nvisual details of the mentioned entities, and thus improves its accuracy in\ngenerating the entities' visual appearances. We train Re-Imagen on a\nconstructed dataset containing (image, text, retrieval) triples to teach the\nmodel to ground on both text prompt and retrieval. Furthermore, we develop a\nnew sampling strategy to interleave the classifier-free guidance for text and\nretrieval conditions to balance the text and retrieval alignment. Re-Imagen\nachieves significant gain on FID score over COCO and WikiImage. To further\nevaluate the capabilities of the model, we introduce EntityDrawBench, a new\nbenchmark that evaluates image generation for diverse entities, from frequent\nto rare, across multiple object categories including dogs, foods, landmarks,\nbirds, and characters. Human evaluation on EntityDrawBench shows that Re-Imagen\ncan significantly improve the fidelity of generated images, especially on less\nfrequent entities.\n",
                "链接": "https://arxiv.org/abs/2209.14491"
            },
            {
                "文章ID": "52841",
                "标题": "SINE: SINgle Image Editing with Text-to-Image Diffusion Models",
                "作者": " Zhixing Zhang,  Ligong Han,  Arnab Ghosh,  Dimitris Metaxas,  Jian Ren",
                "发布日期": "2022-12-09",
                "摘要": "  Recent works on diffusion models have demonstrated a strong capability for\nconditioning image generation, e.g., text-guided image synthesis. Such success\ninspires many efforts trying to use large-scale pre-trained diffusion models\nfor tackling a challenging problem--real image editing. Works conducted in this\narea learn a unique textual token corresponding to several images containing\nthe same object. However, under many circumstances, only one image is\navailable, such as the painting of the Girl with a Pearl Earring. Using\nexisting works on fine-tuning the pre-trained diffusion models with a single\nimage causes severe overfitting issues. The information leakage from the\npre-trained diffusion models makes editing can not keep the same content as the\ngiven image while creating new features depicted by the language guidance. This\nwork aims to address the problem of single-image editing. We propose a novel\nmodel-based guidance built upon the classifier-free guidance so that the\nknowledge from the model trained on a single image can be distilled into the\npre-trained diffusion model, enabling content creation even with one given\nimage. Additionally, we propose a patch-based fine-tuning that can effectively\nhelp the model generate images of arbitrary resolution. We provide extensive\nexperiments to validate the design choices of our approach and show promising\nediting capabilities, including changing style, content addition, and object\nmanipulation. The code is available for research purposes at\nhttps://github.com/zhang-zx/SINE.git .\n",
                "链接": "https://arxiv.org/abs/2212.04489"
            },
            {
                "文章ID": "29583",
                "标题": "Effect of Instance Normalization on Fine-Grained Control for\n  Sketch-Based Face Image Generation",
                "作者": " Zhihua Cheng,  Xuejin Chen",
                "发布日期": "2022-07-19",
                "摘要": "  Sketching is an intuitive and effective way for content creation. While\nsignificant progress has been made for photorealistic image generation by using\ngenerative adversarial networks, it remains challenging to take a fine-grained\ncontrol on synthetic content. The instance normalization layer, which is widely\nadopted in existing image translation networks, washes away details in the\ninput sketch and leads to loss of precise control on the desired shape of the\ngenerated face images. In this paper, we comprehensively investigate the effect\nof instance normalization on generating photorealistic face images from\nhand-drawn sketches. We first introduce a visualization approach to analyze the\nfeature embedding for sketches with a group of specific changes. Based on the\nvisual analysis, we modify the instance normalization layers in the baseline\nimage translation model. We elaborate a new set of hand-drawn sketches with 11\ncategories of specially designed changes and conduct extensive experimental\nanalysis. The results and user studies demonstrate that our method markedly\nimprove the quality of synthesized images and the conformance with user\nintention.\n",
                "链接": "https://arxiv.org/abs/2207.08072"
            },
            {
                "文章ID": "43345",
                "标题": "UniTune: Text-Driven Image Editing by Fine Tuning a Diffusion Model on a\n  Single Image",
                "作者": " Dani Valevski,  Matan Kalman,  Eyal Molad,  Eyal Segalis,  Yossi Matias,  Yaniv Leviathan",
                "发布日期": "2023-07-06",
                "摘要": "  Text-driven image generation methods have shown impressive results recently,\nallowing casual users to generate high quality images by providing textual\ndescriptions. However, similar capabilities for editing existing images are\nstill out of reach. Text-driven image editing methods usually need edit masks,\nstruggle with edits that require significant visual changes and cannot easily\nkeep specific details of the edited portion. In this paper we make the\nobservation that image-generation models can be converted to image-editing\nmodels simply by fine-tuning them on a single image. We also show that\ninitializing the stochastic sampler with a noised version of the base image\nbefore the sampling and interpolating relevant details from the base image\nafter sampling further increase the quality of the edit operation. Combining\nthese observations, we propose UniTune, a novel image editing method. UniTune\ngets as input an arbitrary image and a textual edit description, and carries\nout the edit while maintaining high fidelity to the input image. UniTune does\nnot require additional inputs, like masks or sketches, and can perform multiple\nedits on the same image without retraining. We test our method using the Imagen\nmodel in a range of different use cases. We demonstrate that it is broadly\napplicable and can perform a surprisingly wide range of expressive editing\noperations, including those requiring significant visual changes that were\npreviously impossible.\n",
                "链接": "https://arxiv.org/abs/2210.09477"
            },
            {
                "文章ID": "52126",
                "标题": "Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models",
                "作者": " Naoki Matsunaga,  Masato Ishii,  Akio Hayakawa,  Kenji Suzuki,  Takuya Narihira",
                "发布日期": "2023-06-01",
                "摘要": "  Our goal is to develop fine-grained real-image editing methods suitable for\nreal-world applications. In this paper, we first summarize four requirements\nfor these methods and propose a novel diffusion-based image editing framework\nwith pixel-wise guidance that satisfies these requirements. Specifically, we\ntrain pixel-classifiers with a few annotated data and then infer the\nsegmentation map of a target image. Users then manipulate the map to instruct\nhow the image will be edited. We utilize a pre-trained diffusion model to\ngenerate edited images aligned with the user's intention with pixel-wise\nguidance. The effective combination of proposed guidance and other techniques\nenables highly controllable editing with preserving the outside of the edited\narea, which results in meeting our requirements. The experimental results\ndemonstrate that our proposal outperforms the GAN-based method for editing\nquality and speed.\n",
                "链接": "https://arxiv.org/abs/2212.02024"
            },
            {
                "文章ID": "21265",
                "标题": "Fine-grained Image Captioning with CLIP Reward",
                "作者": " Jaemin Cho,  Seunghyun Yoon,  Ajinkya Kale,  Franck Dernoncourt,  Trung Bui,  Mohit Bansal",
                "发布日期": "2023-03-31",
                "摘要": "  Modern image captioning models are usually trained with text similarity\nobjectives. However, since reference captions in public datasets often describe\nthe most salient common objects, models trained with text similarity objectives\ntend to ignore specific and detailed aspects of an image that distinguish it\nfrom others. Toward more descriptive and distinctive caption generation, we\npropose using CLIP, a multimodal encoder trained on huge image-text pairs from\nweb, to calculate multimodal similarity and use it as a reward function. We\nalso propose a simple finetuning strategy of the CLIP text encoder to improve\ngrammar that does not require extra text annotation. This completely eliminates\nthe need for reference captions during the reward computation. To\ncomprehensively evaluate descriptive captions, we introduce FineCapEval, a new\ndataset for caption evaluation with fine-grained criteria: overall, background,\nobject, relations. In our experiments on text-to-image retrieval and\nFineCapEval, the proposed CLIP-guided model generates more distinctive captions\nthan the CIDEr-optimized model. We also show that our unsupervised grammar\nfinetuning of the CLIP text encoder alleviates the degeneration problem of the\nnaive CLIP reward. Lastly, we show human analysis where the annotators strongly\nprefer the CLIP reward to the CIDEr and MLE objectives according to various\ncriteria. Code and Data: https://github.com/j-min/CLIP-Caption-Reward\n",
                "链接": "https://arxiv.org/abs/2205.13115"
            },
            {
                "文章ID": "13260",
                "标题": "Flexible Portrait Image Editing with Fine-Grained Control",
                "作者": " Linlin Liu,  Qian Fu,  Fei Hou,  Ying He",
                "发布日期": "2022-04-05",
                "摘要": "  We develop a new method for portrait image editing, which supports\nfine-grained editing of geometries, colors, lights and shadows using a single\nneural network model. We adopt a novel asymmetric conditional GAN architecture:\nthe generators take the transformed conditional inputs, such as edge maps,\ncolor palette, sliders and masks, that can be directly edited by the user; the\ndiscriminators take the conditional inputs in the way that can guide\ncontrollable image generation more effectively. Taking color editing as an\nexample, we feed color palettes (which can be edited easily) into the\ngenerator, and color maps (which contain positional information of colors) into\nthe discriminator. We also design a region-weighted discriminator so that\nhigher weights are assigned to more important regions, like eyes and skin.\nUsing a color palette, the user can directly specify the desired colors of\nhair, skin, eyes, lip and background. Color sliders allow the user to blend\ncolors in an intuitive manner. The user can also edit lights and shadows by\nmodifying the corresponding masks. We demonstrate the effectiveness of our\nmethod by evaluating it on the CelebAMask-HQ dataset with a wide range of\ntasks, including geometry/color/shadow/light editing, hand-drawn sketch to\nimage translation, and color transfer. We also present ablation studies to\njustify our design.\n",
                "链接": "https://arxiv.org/abs/2204.01318"
            },
            {
                "文章ID": "41367",
                "标题": "MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language\n  Representation Learning",
                "作者": " Zijia Zhao,  Longteng Guo,  Xingjian He,  Shuai Shao,  Zehuan Yuan,  Jing Liu",
                "发布日期": "2023-06-16",
                "摘要": "  Multimodal representation learning has shown promising improvements on\nvarious vision-language tasks. Most existing methods excel at building\nglobal-level alignment between vision and language while lacking effective\nfine-grained image-text interaction. In this paper, we propose a jointly masked\nmultimodal modeling method to learn fine-grained multimodal representations.\nOur method performs joint masking on image-text input and integrates both\nimplicit and explicit targets for the masked signals to recover. The implicit\ntarget provides a unified and debiased objective for vision and language, where\nthe model predicts latent multimodal representations of the unmasked input. The\nexplicit target further enriches the multimodal representations by recovering\nhigh-level and semantically meaningful information: momentum visual features of\nimage patches and concepts of word tokens. Through such a masked modeling\nprocess, our model not only learns fine-grained multimodal interaction, but\nalso avoids the semantic gap between high-level representations and low- or\nmid-level prediction targets (e.g. image pixels), thus producing semantically\nrich multimodal representations that perform well on both zero-shot and\nfine-tuned settings. Our pre-trained model (named MAMO) achieves\nstate-of-the-art performance on various downstream vision-language tasks,\nincluding image-text retrieval, visual question answering, visual reasoning,\nand weakly-supervised visual grounding.\n",
                "链接": "https://arxiv.org/abs/2210.04183"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找风格化机器翻译相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "83081",
                "标题": "Text Style Transfer Back-Translation",
                "作者": " Daimeng Wei,  Zhanglin Wu,  Hengchao Shang,  Zongyao Li,  Minghan Wang,  Jiaxin Guo,  Xiaoyu Chen,  Zhengzhe Yu,  Hao Yang",
                "发布日期": "2023-06-05",
                "摘要": "  Back Translation (BT) is widely used in the field of machine translation, as\nit has been proved effective for enhancing translation quality. However, BT\nmainly improves the translation of inputs that share a similar style (to be\nmore specific, translation-like inputs), since the source side of BT data is\nmachine-translated. For natural inputs, BT brings only slight improvements and\nsometimes even adverse effects. To address this issue, we propose Text Style\nTransfer Back Translation (TST BT), which uses a style transfer model to modify\nthe source side of BT data. By making the style of source-side text more\nnatural, we aim to improve the translation of natural inputs. Our experiments\non various language pairs, including both high-resource and low-resource ones,\ndemonstrate that TST BT significantly improves translation performance against\npopular BT benchmarks. In addition, TST BT is proved to be effective in domain\nadaptation so this strategy can be regarded as a general data augmentation\nmethod. Our training code and text style transfer model are open-sourced.\n",
                "链接": "https://arxiv.org/abs/2306.01318"
            },
            {
                "文章ID": "92370",
                "标题": "Incorporating Human Translator Style into English-Turkish Literary\n  Machine Translation",
                "作者": " Zeynep Yirmibeşoğlu,  Olgun Dursun,  Harun Dallı,  Mehmet Şahin,  Ena Hodzik,  Sabri Gürses,  Tunga Güngör",
                "发布日期": "2023-07-24",
                "摘要": "  Although machine translation systems are mostly designed to serve in the\ngeneral domain, there is a growing tendency to adapt these systems to other\ndomains like literary translation. In this paper, we focus on English-Turkish\nliterary translation and develop machine translation models that take into\naccount the stylistic features of translators. We fine-tune a pre-trained\nmachine translation model by the manually-aligned works of a particular\ntranslator. We make a detailed analysis of the effects of manual and automatic\nalignments, data augmentation methods, and corpus size on the translations. We\npropose an approach based on stylistic features to evaluate the style of a\ntranslator in the output translations. We show that the human translator style\ncan be highly recreated in the target machine translations by adapting the\nmodels to the style of the translator.\n",
                "链接": "https://arxiv.org/abs/2307.11457"
            },
            {
                "文章ID": "119702",
                "标题": "Quick Back-Translation for Unsupervised Machine Translation",
                "作者": " Benjamin Brimacombe,  Jiawei Zhou",
                "发布日期": "2023-12-05",
                "摘要": "  The field of unsupervised machine translation has seen significant\nadvancement from the marriage of the Transformer and the back-translation\nalgorithm. The Transformer is a powerful generative model, and back-translation\nleverages Transformer's high-quality translations for iterative\nself-improvement. However, the Transformer is encumbered by the run-time of\nautoregressive inference during back-translation, and back-translation is\nlimited by a lack of synthetic data efficiency. We propose a two-for-one\nimprovement to Transformer back-translation: Quick Back-Translation (QBT). QBT\nre-purposes the encoder as a generative model, and uses encoder-generated\nsequences to train the decoder in conjunction with the original autoregressive\nback-translation step, improving data throughput and utilization. Experiments\non various WMT benchmarks demonstrate that a relatively small number of\nrefining steps of QBT improve current unsupervised machine translation models,\nand that QBT dramatically outperforms standard back-translation only method in\nterms of training efficiency for comparable translation qualities.\n",
                "链接": "https://arxiv.org/abs/2312.00912"
            },
            {
                "文章ID": "54085",
                "标题": "Controlling Styles in Neural Machine Translation with Activation Prompt",
                "作者": " Yifan Wang,  Zewei Sun,  Shanbo Cheng,  Weiguo Zheng,  Mingxuan Wang",
                "发布日期": "2023-05-30",
                "摘要": "  Controlling styles in neural machine translation (NMT) has attracted wide\nattention, as it is crucial for enhancing user experience. Earlier studies on\nthis topic typically concentrate on regulating the level of formality and\nachieve some progress in this area. However, they still encounter two major\nchallenges. The first is the difficulty in style evaluation. The style\ncomprises various aspects such as lexis, syntax, and others that provide\nabundant information. Nevertheless, only formality has been thoroughly\ninvestigated. The second challenge involves excessive dependence on incremental\nadjustments, particularly when new styles are necessary. To address both\nchallenges, this paper presents a new benchmark and approach. A multiway\nstylized machine translation (MSMT) benchmark is introduced, incorporating\ndiverse categories of styles across four linguistic domains. Then, we propose a\nmethod named style activation prompt (StyleAP) by retrieving prompts from\nstylized monolingual corpus, which does not require extra fine-tuning.\nExperiments show that StyleAP could effectively control the style of\ntranslation and achieve remarkable performance.\n",
                "链接": "https://arxiv.org/abs/2212.08909"
            },
            {
                "文章ID": "10215",
                "标题": "Triangular Transfer: Freezing the Pivot for Triangular Machine\n  Translation",
                "作者": " Meng Zhang,  Liangyou Li,  Qun Liu",
                "发布日期": "2022-03-18",
                "摘要": "  Triangular machine translation is a special case of low-resource machine\ntranslation where the language pair of interest has limited parallel data, but\nboth languages have abundant parallel data with a pivot language. Naturally,\nthe key to triangular machine translation is the successful exploitation of\nsuch auxiliary data. In this work, we propose a transfer-learning-based\napproach that utilizes all types of auxiliary data. As we train auxiliary\nsource-pivot and pivot-target translation models, we initialize some parameters\nof the pivot side with a pre-trained language model and freeze them to\nencourage both translation models to work in the same pivot language space, so\nthat they can be smoothly transferred to the source-target translation model.\nExperiments show that our approach can outperform previous ones.\n",
                "链接": "https://arxiv.org/abs/2203.09027"
            },
            {
                "文章ID": "37434",
                "标题": "Rethinking Round-Trip Translation for Machine Translation Evaluation",
                "作者": " Terry Yue Zhuo,  Qiongkai Xu,  Xuanli He,  Trevor Cohn",
                "发布日期": "2023-05-16",
                "摘要": "  Automatic evaluation on low-resource language translation suffers from a\ndeficiency of parallel corpora. Round-trip translation could be served as a\nclever and straightforward technique to alleviate the requirement of the\nparallel evaluation corpus. However, there was an observation of obscure\ncorrelations between the evaluation scores by forward and round-trip\ntranslations in the era of statistical machine translation (SMT). In this\npaper, we report the surprising finding that round-trip translation can be used\nfor automatic evaluation without the references. Firstly, our revisit on the\nround-trip translation in SMT evaluation unveils that its long-standing\nmisunderstanding is essentially caused by copying mechanism. After removing\ncopying mechanism in SMT, round-trip translation scores can appropriately\nreflect the forward translation performance. Then, we demonstrate the\nrectification is overdue as round-trip translation could benefit multiple\nmachine translation evaluation tasks. To be more specific, round-trip\ntranslation could be used i) to predict corresponding forward translation\nscores; ii) to improve the performance of the recently advanced quality\nestimation model; and iii) to identify adversarial competitors in shared tasks\nvia cross-system verification.\n",
                "链接": "https://arxiv.org/abs/2209.07351"
            },
            {
                "文章ID": "56953",
                "标题": "Prompting Neural Machine Translation with Translation Memories",
                "作者": " Abudurexiti Reheman,  Tao Zhou,  Yingfeng Luo,  Di Yang,  Tong Xiao,  Jingbo Zhu",
                "发布日期": "2023-02-08",
                "摘要": "  Improving machine translation (MT) systems with translation memories (TMs) is\nof great interest to practitioners in the MT community. However, previous\napproaches require either a significant update of the model architecture and/or\nadditional training efforts to make the models well-behaved when TMs are taken\nas additional input. In this paper, we present a simple but effective method to\nintroduce TMs into neural machine translation (NMT) systems. Specifically, we\ntreat TMs as prompts to the NMT model at test time, but leave the training\nprocess unchanged. The result is a slight update of an existing NMT system,\nwhich can be implemented in a few hours by anyone who is familiar with NMT.\nExperimental results on several datasets demonstrate that our system\nsignificantly outperforms strong baselines.\n",
                "链接": "https://arxiv.org/abs/2301.05380"
            },
            {
                "文章ID": "7091",
                "标题": "Screening Gender Transfer in Neural Machine Translation",
                "作者": " Guillaume Wisniewski,  Lichao Zhu,  Nicolas Ballier,  François Yvon",
                "发布日期": "2022-02-28",
                "摘要": "  This paper aims at identifying the information flow in state-of-the-art\nmachine translation systems, taking as example the transfer of gender when\ntranslating from French into English. Using a controlled set of examples, we\nexperiment several ways to investigate how gender information circulates in a\nencoder-decoder architecture considering both probing techniques as well as\ninterventions on the internal representations used in the MT system. Our\nresults show that gender information can be found in all token representations\nbuilt by the encoder and the decoder and lead us to conclude that there are\nmultiple pathways for gender transfer.\n",
                "链接": "https://arxiv.org/abs/2202.12568"
            },
            {
                "文章ID": "52440",
                "标题": "Neural Machine Translation with Contrastive Translation Memories",
                "作者": " Xin Cheng,  Shen Gao,  Lemao Liu,  Dongyan Zhao,  Rui Yan",
                "发布日期": "2022-12-07",
                "摘要": "  Retrieval-augmented Neural Machine Translation models have been successful in\nmany translation scenarios. Different from previous works that make use of\nmutually similar but redundant translation memories~(TMs), we propose a new\nretrieval-augmented NMT to model contrastively retrieved translation memories\nthat are holistically similar to the source sentence while individually\ncontrastive to each other providing maximal information gains in three phases.\nFirst, in TM retrieval phase, we adopt a contrastive retrieval algorithm to\navoid redundancy and uninformativeness of similar translation pieces. Second,\nin memory encoding stage, given a set of TMs we propose a novel Hierarchical\nGroup Attention module to gather both local context of each TM and global\ncontext of the whole TM set. Finally, in training phase, a Multi-TM contrastive\nlearning objective is introduced to learn salient feature of each TM with\nrespect to target sentence. Experimental results show that our framework\nobtains improvements over strong baselines on the benchmark datasets.\n",
                "链接": "https://arxiv.org/abs/2212.03140"
            },
            {
                "文章ID": "50351",
                "标题": "Competency-Aware Neural Machine Translation: Can Machine Translation\n  Know its Own Translation Quality?",
                "作者": " Pei Zhang,  Baosong Yang,  Haoran Wei,  Dayiheng Liu,  Kai Fan,  Luo Si,  Jun Xie",
                "发布日期": "2022-11-28",
                "摘要": "  Neural machine translation (NMT) is often criticized for failures that happen\nwithout awareness. The lack of competency awareness makes NMT untrustworthy.\nThis is in sharp contrast to human translators who give feedback or conduct\nfurther investigations whenever they are in doubt about predictions. To fill\nthis gap, we propose a novel competency-aware NMT by extending conventional NMT\nwith a self-estimator, offering abilities to translate a source sentence and\nestimate its competency. The self-estimator encodes the information of the\ndecoding procedure and then examines whether it can reconstruct the original\nsemantics of the source sentence. Experimental results on four translation\ntasks demonstrate that the proposed method not only carries out translation\ntasks intact but also delivers outstanding performance on quality estimation.\nWithout depending on any reference or annotated data typically required by\nstate-of-the-art metric and quality estimation methods, our model yields an\neven higher correlation with human quality judgments than a variety of\naforementioned methods, such as BLEURT, COMET, and BERTScore. Quantitative and\nqualitative analyses show better robustness of competency awareness in our\nmodel.\n",
                "链接": "https://arxiv.org/abs/2211.13865"
            }
        ]
    },
    {
        "question": {
            "question": "查找中文ner常用的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "5948",
                "标题": "AISHELL-NER: Named Entity Recognition from Chinese Speech",
                "作者": " Boli Chen,  Guangwei Xu,  Xiaobin Wang,  Pengjun Xie,  Meishan Zhang,  Fei Huang",
                "发布日期": "2022-02-18",
                "摘要": "  Named Entity Recognition (NER) from speech is among Spoken Language\nUnderstanding (SLU) tasks, aiming to extract semantic information from the\nspeech signal. NER from speech is usually made through a two-step pipeline that\nconsists of (1) processing the audio using an Automatic Speech Recognition\n(ASR) system and (2) applying an NER tagger to the ASR outputs. Recent works\nhave shown the capability of the End-to-End (E2E) approach for NER from English\nand French speech, which is essentially entity-aware ASR. However, due to the\nmany homophones and polyphones that exist in Chinese, NER from Chinese speech\nis effectively a more challenging task. In this paper, we introduce a new\ndataset AISEHLL-NER for NER from Chinese speech. Extensive experiments are\nconducted to explore the performance of several state-of-the-art methods. The\nresults demonstrate that the performance could be improved by combining\nentity-aware ASR and pretrained NER tagger, which can be easily applied to the\nmodern SLU pipeline. The dataset is publicly available at\ngithub.com/Alibaba-NLP/AISHELL-NER.\n",
                "链接": "https://arxiv.org/abs/2202.08533"
            },
            {
                "文章ID": "6079",
                "标题": "TURNER: The Uncertainty-based Retrieval Framework for Chinese NER",
                "作者": " Zhichao Geng,  Hang Yan,  Zhangyue Yin,  Chenxin An,  Xipeng Qiu",
                "发布日期": "2022-02-21",
                "摘要": "  Chinese NER is a difficult undertaking due to the ambiguity of Chinese\ncharacters and the absence of word boundaries. Previous work on Chinese NER\nfocus on lexicon-based methods to introduce boundary information and reduce\nout-of-vocabulary (OOV) cases during prediction. However, it is expensive to\nobtain and dynamically maintain high-quality lexicons in specific domains,\nwhich motivates us to utilize more general knowledge resources, e.g., search\nengines. In this paper, we propose TURNER: The Uncertainty-based Retrieval\nframework for Chinese NER. The idea behind TURNER is to imitate human behavior:\nwe frequently retrieve auxiliary knowledge as assistance when encountering an\nunknown or uncertain entity. To improve the efficiency and effectiveness of\nretrieval, we first propose two types of uncertainty sampling methods for\nselecting the most ambiguous entity-level uncertain components of the input\ntext. Then, the Knowledge Fusion Model re-predict the uncertain samples by\ncombining retrieved knowledge. Experiments on four benchmark datasets\ndemonstrate TURNER's effectiveness. TURNER outperforms existing lexicon-based\napproaches and achieves the new SOTA.\n",
                "链接": "https://arxiv.org/abs/2202.09022"
            },
            {
                "文章ID": "75893",
                "标题": "LLM-RM at SemEval-2023 Task 2: Multilingual Complex NER using\n  XLM-RoBERTa",
                "作者": " Rahul Mehta,  Vasudeva Varma",
                "发布日期": "2023-05-08",
                "摘要": "  Named Entity Recognition(NER) is a task of recognizing entities at a token\nlevel in a sentence. This paper focuses on solving NER tasks in a multilingual\nsetting for complex named entities. Our team, LLM-RM participated in the\nrecently organized SemEval 2023 task, Task 2: MultiCoNER II,Multilingual\nComplex Named Entity Recognition. We approach the problem by leveraging\ncross-lingual representation provided by fine-tuning XLM-Roberta base model on\ndatasets of all of the 12 languages provided -- Bangla, Chinese, English,\nFarsi, French, German, Hindi, Italian, Portuguese, Spanish, Swedish and\nUkrainian\n",
                "链接": "https://arxiv.org/abs/2305.03300"
            },
            {
                "文章ID": "44485",
                "标题": "Improving Chinese Named Entity Recognition by Search Engine Augmentation",
                "作者": " Qinghua Mao,  Jiatong Li,  Kui Meng",
                "发布日期": "2022-10-25",
                "摘要": "  Compared with English, Chinese suffers from more grammatical ambiguities,\nlike fuzzy word boundaries and polysemous words. In this case, contextual\ninformation is not sufficient to support Chinese named entity recognition\n(NER), especially for rare and emerging named entities. Semantic augmentation\nusing external knowledge is a potential way to alleviate this problem, while\nhow to obtain and leverage external knowledge for the NER task remains a\nchallenge. In this paper, we propose a neural-based approach to perform\nsemantic augmentation using external knowledge from search engine for Chinese\nNER. In particular, a multi-channel semantic fusion model is adopted to\ngenerate the augmented input representations, which aggregates external related\ntexts retrieved from the search engine. Experiments have shown the superiority\nof our model across 4 NER datasets, including formal and social media language\ncontexts, which further prove the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2210.12662"
            },
            {
                "文章ID": "125250",
                "标题": "Unified Lattice Graph Fusion for Chinese Named Entity Recognition",
                "作者": " Dixiang Zhang,  Junyu Lu,  Pingjian Zhang",
                "发布日期": "2023-12-29",
                "摘要": "  Integrating lexicon into character-level sequence has been proven effective\nto leverage word boundary and semantic information in Chinese named entity\nrecognition (NER). However, prior approaches usually utilize feature weighting\nand position coupling to integrate word information, but ignore the semantic\nand contextual correspondence between the fine-grained semantic units in the\ncharacter-word space. To solve this issue, we propose a Unified Lattice Graph\nFusion (ULGF) approach for Chinese NER. ULGF can explicitly capture various\nsemantic and boundary relations across different semantic units with the\nadjacency matrix by converting the lattice structure into a unified graph. We\nstack multiple graph-based intra-source self-attention and inter-source\ncross-gating fusion layers that iteratively carry out semantic interactions to\nlearn node representations. To alleviate the over-reliance on word information,\nwe further propose to leverage lexicon entity classification as an auxiliary\ntask. Experiments on four Chinese NER benchmark datasets demonstrate the\nsuperiority of our ULGF approach.\n",
                "链接": "https://arxiv.org/abs/2312.16917"
            },
            {
                "文章ID": "14564",
                "标题": "Delving Deep into Regularity: A Simple but Effective Method for Chinese\n  Named Entity Recognition",
                "作者": " Yingjie Gu,  Xiaoye Qu,  Zhefeng Wang,  Yi Zheng,  Baoxing Huai,  Nicholas Jing Yuan",
                "发布日期": "2022-04-19",
                "摘要": "  Recent years have witnessed the improving performance of Chinese Named Entity\nRecognition (NER) from proposing new frameworks or incorporating word lexicons.\nHowever, the inner composition of entity mentions in character-level Chinese\nNER has been rarely studied. Actually, most mentions of regular types have\nstrong name regularity. For example, entities end with indicator words such as\n\"company\" or \"bank\" usually belong to organization. In this paper, we propose a\nsimple but effective method for investigating the regularity of entity spans in\nChinese NER, dubbed as Regularity-Inspired reCOgnition Network (RICON).\nSpecifically, the proposed model consists of two branches: a regularity-aware\nmodule and a regularityagnostic module. The regularity-aware module captures\nthe internal regularity of each span for better entity type prediction, while\nthe regularity-agnostic module is employed to locate the boundary of entities\nand relieve the excessive attention to span regularity. An orthogonality space\nis further constructed to encourage two modules to extract different aspects of\nregularity features. To verify the effectiveness of our method, we conduct\nextensive experiments on three benchmark datasets and a practical medical\ndataset. The experimental results show that our RICON significantly outperforms\nprevious state-of-the-art methods, including various lexicon-based methods.\n",
                "链接": "https://arxiv.org/abs/2204.05544"
            },
            {
                "文章ID": "116256",
                "标题": "GSAP-NER: A Novel Task, Corpus, and Baseline for Scholarly Entity\n  Extraction Focused on Machine Learning Models and Datasets",
                "作者": " Wolfgang Otto,  Matthäus Zloch,  Lu Gan,  Saurav Karmakar,  Stefan Dietze",
                "发布日期": "2023-11-17",
                "摘要": "  Named Entity Recognition (NER) models play a crucial role in various NLP\ntasks, including information extraction (IE) and text understanding. In\nacademic writing, references to machine learning models and datasets are\nfundamental components of various computer science publications and necessitate\naccurate models for identification. Despite the advancements in NER, existing\nground truth datasets do not treat fine-grained types like ML model and model\narchitecture as separate entity types, and consequently, baseline models cannot\nrecognize them as such. In this paper, we release a corpus of 100 manually\nannotated full-text scientific publications and a first baseline model for 10\nentity types centered around ML models and datasets. In order to provide a\nnuanced understanding of how ML models and datasets are mentioned and utilized,\nour dataset also contains annotations for informal mentions like \"our\nBERT-based model\" or \"an image CNN\". You can find the ground truth dataset and\ncode to replicate model training at https://data.gesis.org/gsap/gsap-ner.\n",
                "链接": "https://arxiv.org/abs/2311.09860"
            },
            {
                "文章ID": "15120",
                "标题": "Qtrade AI at SemEval-2022 Task 11: An Unified Framework for Multilingual\n  NER Task",
                "作者": " Weichao Gan,  Yuanping Lin,  Guangbo Yu,  Guimin Chen,  Qian Ye",
                "发布日期": "2022-04-18",
                "摘要": "  This paper describes our system, which placed third in the Multilingual Track\n(subtask 11), fourth in the Code-Mixed Track (subtask 12), and seventh in the\nChinese Track (subtask 9) in the SemEval 2022 Task 11: MultiCoNER Multilingual\nComplex Named Entity Recognition. Our system's key contributions are as\nfollows: 1) For multilingual NER tasks, we offer an unified framework with\nwhich one can easily execute single-language or multilingual NER tasks, 2) for\nlow-resource code-mixed NER task, one can easily enhance his or her dataset\nthrough implementing several simple data augmentation methods and 3) for\nChinese tasks, we propose a model that can capture Chinese lexical semantic,\nlexical border, and lexical graph structural information. Finally, our system\nachieves macro-f1 scores of 77.66, 84.35, and 74.00 on subtasks 11, 12, and 9,\nrespectively, during the testing phase.\n",
                "链接": "https://arxiv.org/abs/2204.07459"
            },
            {
                "文章ID": "28049",
                "标题": "Rethinking the Value of Gazetteer in Chinese Named Entity Recognition",
                "作者": " Qianglong Chen,  Xiangji Zeng,  Jiangang Zhu,  Yin Zhang,  Bojia Lin,  Yang Yang,  Daxin Jiang",
                "发布日期": "2022-07-19",
                "摘要": "  Gazetteer is widely used in Chinese named entity recognition (NER) to enhance\nspan boundary detection and type classification. However, to further understand\nthe generalizability and effectiveness of gazetteers, the NLP community still\nlacks a systematic analysis of the gazetteer-enhanced NER model. In this paper,\nwe first re-examine the effectiveness several common practices of the\ngazetteer-enhanced NER models and carry out a series of detailed analysis to\nevaluate the relationship between the model performance and the gazetteer\ncharacteristics, which can guide us to build a more suitable gazetteer. The\nfindings of this paper are as follows: (1) the gazetteer improves most of the\nsituations that the traditional NER model datasets are difficult to learn. (2)\nthe performance of model greatly benefits from the high-quality pre-trained\nlexeme embeddings. (3) a good gazetteer should cover more entities that can be\nmatched in both the training set and testing set.\n",
                "链接": "https://arxiv.org/abs/2207.02802"
            },
            {
                "文章ID": "35129",
                "标题": "Domain-Specific NER via Retrieving Correlated Samples",
                "作者": " Xin Zhang,  Yong Jiang,  Xiaobin Wang,  Xuming Hu,  Yueheng Sun,  Pengjun Xie,  Meishan Zhang",
                "发布日期": "2022-09-29",
                "摘要": "  Successful Machine Learning based Named Entity Recognition models could fail\non texts from some special domains, for instance, Chinese addresses and\ne-commerce titles, where requires adequate background knowledge. Such texts are\nalso difficult for human annotators. In fact, we can obtain some potentially\nhelpful information from correlated texts, which have some common entities, to\nhelp the text understanding. Then, one can easily reason out the correct answer\nby referencing correlated samples. In this paper, we suggest enhancing NER\nmodels with correlated samples. We draw correlated samples by the sparse BM25\nretriever from large-scale in-domain unlabeled data. To explicitly simulate the\nhuman reasoning process, we perform a training-free entity type calibrating by\nmajority voting. To capture correlation features in the training stage, we\nsuggest to model correlated samples by the transformer-based multi-instance\ncross-encoder. Empirical results on datasets of the above two domains show the\nefficacy of our methods.\n",
                "链接": "https://arxiv.org/abs/2208.12995"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下最近用反事实做数据增强的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "81687",
                "标题": "On Counterfactual Data Augmentation Under Confounding",
                "作者": " Abbavaram Gowtham Reddy,  Saketh Bachu,  Saloni Dash,  Charchit Sharma,  Amit Sharma,  Vineeth N Balasubramanian",
                "发布日期": "2023-11-22",
                "摘要": "  Counterfactual data augmentation has recently emerged as a method to mitigate\nconfounding biases in the training data. These biases, such as spurious\ncorrelations, arise due to various observed and unobserved confounding\nvariables in the data generation process. In this paper, we formally analyze\nhow confounding biases impact downstream classifiers and present a causal\nviewpoint to the solutions based on counterfactual data augmentation. We\nexplore how removing confounding biases serves as a means to learn invariant\nfeatures, ultimately aiding in generalization beyond the observed data\ndistribution. Additionally, we present a straightforward yet powerful algorithm\nfor generating counterfactual images, which effectively mitigates the influence\nof confounding effects on downstream classifiers. Through experiments on MNIST\nvariants and the CelebA datasets, we demonstrate how our simple augmentation\nmethod helps existing state-of-the-art methods achieve good results.\n",
                "链接": "https://arxiv.org/abs/2305.18183"
            },
            {
                "文章ID": "114161",
                "标题": "Counterfactual Data Augmentation with Contrastive Learning",
                "作者": " Ahmed Aloui,  Juncheng Dong,  Cat P. Le,  Vahid Tarokh",
                "发布日期": "2023-11-08",
                "摘要": "  Statistical disparity between distinct treatment groups is one of the most\nsignificant challenges for estimating Conditional Average Treatment Effects\n(CATE). To address this, we introduce a model-agnostic data augmentation method\nthat imputes the counterfactual outcomes for a selected subset of individuals.\nSpecifically, we utilize contrastive learning to learn a representation space\nand a similarity measure such that in the learned representation space close\nindividuals identified by the learned similarity measure have similar potential\noutcomes. This property ensures reliable imputation of counterfactual outcomes\nfor the individuals with close neighbors from the alternative treatment group.\nBy augmenting the original dataset with these reliable imputations, we can\neffectively reduce the discrepancy between different treatment groups, while\ninducing minimal imputation error. The augmented dataset is subsequently\nemployed to train CATE estimation models. Theoretical analysis and experimental\nstudies on synthetic and semi-synthetic benchmarks demonstrate that our method\nachieves significant improvements in both performance and robustness to\noverfitting across state-of-the-art models.\n",
                "链接": "https://arxiv.org/abs/2311.03630"
            },
            {
                "文章ID": "86799",
                "标题": "A Novel Counterfactual Data Augmentation Method for Aspect-Based\n  Sentiment Analysis",
                "作者": " Dongming Wu,  Lulu Wen,  Chao Chen,  Zhaoshu Shi",
                "发布日期": "2023-10-10",
                "摘要": "  Aspect-based-sentiment-analysis (ABSA) is a fine-grained sentiment evaluation\ntask, which analyzes the emotional polarity of the evaluation aspects.\nGenerally, the emotional polarity of an aspect exists in the corresponding\nopinion expression, whose diversity has great impact on model's performance. To\nmitigate this problem, we propose a novel and simple counterfactual data\naugmentation method to generate opinion expressions with reversed sentiment\npolarity. In particular, the integrated gradients are calculated to locate and\nmask the opinion expression. Then, a prompt combined with the reverse\nexpression polarity is added to the original text, and a Pre-trained language\nmodel (PLM), T5, is finally was employed to predict the masks. The experimental\nresults shows the proposed counterfactual data augmentation method performs\nbetter than current augmentation methods on three ABSA datasets, i.e. Laptop,\nRestaurant, and MAMS.\n",
                "链接": "https://arxiv.org/abs/2306.11260"
            },
            {
                "文章ID": "110605",
                "标题": "EXPLAIN, EDIT, GENERATE: Rationale-Sensitive Counterfactual Data\n  Augmentation for Multi-hop Fact Verification",
                "作者": " Yingjie Zhu,  Jiasheng Si,  Yibo Zhao,  Haiyang Zhu,  Deyu Zhou,  Yulan He",
                "发布日期": "2023-10-24",
                "摘要": "  Automatic multi-hop fact verification task has gained significant attention\nin recent years. Despite impressive results, these well-designed models perform\npoorly on out-of-domain data. One possible solution is to augment the training\ndata with counterfactuals, which are generated by minimally altering the causal\nfeatures of the original data. However, current counterfactual data\naugmentation techniques fail to handle multi-hop fact verification due to their\nincapability to preserve the complex logical relationships within multiple\ncorrelated texts. In this paper, we overcome this limitation by developing a\nrationale-sensitive method to generate linguistically diverse and\nlabel-flipping counterfactuals while preserving logical relationships. In\nspecific, the diverse and fluent counterfactuals are generated via an\nExplain-Edit-Generate architecture. Moreover, the checking and filtering\nmodules are proposed to regularize the counterfactual data with logical\nrelations and flipped labels. Experimental results show that the proposed\napproach outperforms the SOTA baselines and can generate linguistically diverse\ncounterfactual data without disrupting their logical relationships.\n",
                "链接": "https://arxiv.org/abs/2310.14508"
            },
            {
                "文章ID": "88864",
                "标题": "Counterfactual Collaborative Reasoning",
                "作者": " Jianchao Ji,  Zelong Li,  Shuyuan Xu,  Max Xiong,  Juntao Tan,  Yingqiang Ge,  Hao Wang,  Yongfeng Zhang",
                "发布日期": "2023-07-06",
                "摘要": "  Causal reasoning and logical reasoning are two important types of reasoning\nabilities for human intelligence. However, their relationship has not been\nextensively explored under machine intelligence context. In this paper, we\nexplore how the two reasoning abilities can be jointly modeled to enhance both\naccuracy and explainability of machine learning models. More specifically, by\nintegrating two important types of reasoning ability -- counterfactual\nreasoning and (neural) logical reasoning -- we propose Counterfactual\nCollaborative Reasoning (CCR), which conducts counterfactual logic reasoning to\nimprove the performance. In particular, we use recommender system as an example\nto show how CCR alleviate data scarcity, improve accuracy and enhance\ntransparency. Technically, we leverage counterfactual reasoning to generate\n\"difficult\" counterfactual training examples for data augmentation, which --\ntogether with the original training examples -- can enhance the model\nperformance. Since the augmented data is model irrelevant, they can be used to\nenhance any model, enabling the wide applicability of the technique. Besides,\nmost of the existing data augmentation methods focus on \"implicit data\naugmentation\" over users' implicit feedback, while our framework conducts\n\"explicit data augmentation\" over users explicit feedback based on\ncounterfactual logic reasoning. Experiments on three real-world datasets show\nthat CCR achieves better performance than non-augmented models and implicitly\naugmented models, and also improves model transparency by generating\ncounterfactual explanations.\n",
                "链接": "https://arxiv.org/abs/2307.00165"
            },
            {
                "文章ID": "82682",
                "标题": "CAISA at SemEval-2023 Task 8: Counterfactual Data Augmentation for\n  Mitigating Class Imbalance in Causal Claim Identification",
                "作者": " Akbar Karimi,  Lucie Flek",
                "发布日期": "2023-06-02",
                "摘要": "  The class imbalance problem can cause machine learning models to produce an\nundesirable performance on the minority class as well as the whole dataset.\nUsing data augmentation techniques to increase the number of samples is one way\nto tackle this problem. We introduce a novel counterfactual data augmentation\nby verb replacement for the identification of medical claims. In addition, we\ninvestigate the impact of this method and compare it with 3 other data\naugmentation techniques, showing that the proposed method can result in a\nsignificant (relative) improvement in the minority class.\n",
                "链接": "https://arxiv.org/abs/2306.00346"
            },
            {
                "文章ID": "80211",
                "标题": "Large Language Models as Counterfactual Generator: Strengths and\n  Weaknesses",
                "作者": " Yongqi Li,  Mayi Xu,  Xin Miao,  Shen Zhou,  Tieyun Qian",
                "发布日期": "2023-05-25",
                "摘要": "  Large language models (LLMs) have demonstrated remarkable performance in a\nrange of natural language understanding and generation tasks. Yet, their\nability to generate counterfactuals, which can be used for areas like data\naugmentation, remains under-explored. This study aims to investigate the\ncounterfactual generation capabilities of LLMs and analysis factors that\ninfluence this ability. First, we evaluate how effective are LLMs in\ncounterfactual generation through data augmentation experiments for small\nlanguage models (SLMs) across four tasks: sentiment analysis, natural language\ninference, named entity recognition, and relation extraction. While LLMs show\npromising enhancements in various settings, they struggle in complex tasks due\nto their self-limitations and the lack of logical guidance to produce\ncounterfactuals that align with commonsense. Second, our analysis reveals the\npivotal role of providing accurate task definitions and detailed step-by-step\ninstructions to LLMs in generating counterfactuals. Interestingly, we also find\nthat LLMs can generate reasonable counterfactuals even with unreasonable\ndemonstrations, which illustrates that demonstrations are primarily to regulate\nthe output format.This study provides the first comprehensive insight into\ncounterfactual generation abilities of LLMs, and offers a novel perspective on\nutilizing LLMs for data augmentation to enhance SLMs.\n",
                "链接": "https://arxiv.org/abs/2305.14791"
            },
            {
                "文章ID": "91298",
                "标题": "Learning for Counterfactual Fairness from Observational Data",
                "作者": " Jing Ma,  Ruocheng Guo,  Aidong Zhang,  Jundong Li",
                "发布日期": "2023-07-18",
                "摘要": "  Fairness-aware machine learning has attracted a surge of attention in many\ndomains, such as online advertising, personalized recommendation, and social\nmedia analysis in web applications. Fairness-aware machine learning aims to\neliminate biases of learning models against certain subgroups described by\ncertain protected (sensitive) attributes such as race, gender, and age. Among\nmany existing fairness notions, counterfactual fairness is a popular notion\ndefined from a causal perspective. It measures the fairness of a predictor by\ncomparing the prediction of each individual in the original world and that in\nthe counterfactual worlds in which the value of the sensitive attribute is\nmodified. A prerequisite for existing methods to achieve counterfactual\nfairness is the prior human knowledge of the causal model for the data.\nHowever, in real-world scenarios, the underlying causal model is often unknown,\nand acquiring such human knowledge could be very difficult. In these scenarios,\nit is risky to directly trust the causal models obtained from information\nsources with unknown reliability and even causal discovery methods, as\nincorrect causal models can consequently bring biases to the predictor and lead\nto unfair predictions. In this work, we address the problem of counterfactually\nfair prediction from observational data without given causal models by\nproposing a novel framework CLAIRE. Specifically, under certain general\nassumptions, CLAIRE effectively mitigates the biases from the sensitive\nattribute with a representation learning framework based on counterfactual data\naugmentation and an invariant penalty. Experiments conducted on both synthetic\nand real-world datasets validate the superiority of CLAIRE in both\ncounterfactual fairness and prediction performance.\n",
                "链接": "https://arxiv.org/abs/2307.08232"
            },
            {
                "文章ID": "83688",
                "标题": "Improving Conversational Recommendation Systems via Counterfactual Data\n  Simulation",
                "作者": " Xiaolei Wang,  Kun Zhou,  Xinyu Tang,  Wayne Xin Zhao,  Fan Pan,  Zhao Cao,  Ji-Rong Wen",
                "发布日期": "2023-06-09",
                "摘要": "  Conversational recommender systems (CRSs) aim to provide recommendation\nservices via natural language conversations. Although a number of approaches\nhave been proposed for developing capable CRSs, they typically rely on\nsufficient training data for training. Since it is difficult to annotate\nrecommendation-oriented dialogue datasets, existing CRS approaches often suffer\nfrom the issue of insufficient training due to the scarcity of training data.\nTo address this issue, in this paper, we propose a CounterFactual data\nsimulation approach for CRS, named CFCRS, to alleviate the issue of data\nscarcity in CRSs. Our approach is developed based on the framework of\ncounterfactual data augmentation, which gradually incorporates the rewriting to\nthe user preference from a real dialogue without interfering with the entire\nconversation flow. To develop our approach, we characterize user preference and\norganize the conversation flow by the entities involved in the dialogue, and\ndesign a multi-stage recommendation dialogue simulator based on a conversation\nflow language model. Under the guidance of the learned user preference and\ndialogue schema, the flow language model can produce reasonable, coherent\nconversation flows, which can be further realized into complete dialogues.\nBased on the simulator, we perform the intervention at the representations of\nthe interacted entities of target users, and design an adversarial training\nmethod with a curriculum schedule that can gradually optimize the data\naugmentation strategy. Extensive experiments show that our approach can\nconsistently boost the performance of several competitive CRSs, and outperform\nother data augmentation methods, especially when the training data is limited.\nOur code is publicly available at https://github.com/RUCAIBox/CFCRS.\n",
                "链接": "https://arxiv.org/abs/2306.02842"
            },
            {
                "文章ID": "97852",
                "标题": "Targeted Data Augmentation for bias mitigation",
                "作者": " Agnieszka Mikołajczyk-Bareła,  Maria Ferlin,  Michał Grochowski",
                "发布日期": "2023-08-23",
                "摘要": "  The development of fair and ethical AI systems requires careful consideration\nof bias mitigation, an area often overlooked or ignored. In this study, we\nintroduce a novel and efficient approach for addressing biases called Targeted\nData Augmentation (TDA), which leverages classical data augmentation techniques\nto tackle the pressing issue of bias in data and models. Unlike the laborious\ntask of removing biases, our method proposes to insert biases instead,\nresulting in improved performance. To identify biases, we annotated two diverse\ndatasets: a dataset of clinical skin lesions and a dataset of male and female\nfaces. These bias annotations are published for the first time in this study,\nproviding a valuable resource for future research. Through Counterfactual Bias\nInsertion, we discovered that biases associated with the frame, ruler, and\nglasses had a significant impact on models. By randomly introducing biases\nduring training, we mitigated these biases and achieved a substantial decrease\nin bias measures, ranging from two-fold to more than 50-fold, while maintaining\na negligible increase in the error rate.\n",
                "链接": "https://arxiv.org/abs/2308.11386"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用蒙特卡罗树搜索解决序列决策问题的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "108378",
                "标题": "LightZero: A Unified Benchmark for Monte Carlo Tree Search in General\n  Sequential Decision Scenarios",
                "作者": " Yazhe Niu,  Yuan Pu,  Zhenjie Yang,  Xueyan Li,  Tong Zhou,  Jiyuan Ren,  Shuai Hu,  Hongsheng Li,  Yu Liu",
                "发布日期": "2023-10-13",
                "摘要": "  Building agents based on tree-search planning capabilities with learned\nmodels has achieved remarkable success in classic decision-making problems,\nsuch as Go and Atari. However, it has been deemed challenging or even\ninfeasible to extend Monte Carlo Tree Search (MCTS) based algorithms to diverse\nreal-world applications, especially when these environments involve complex\naction spaces and significant simulation costs, or inherent stochasticity. In\nthis work, we introduce LightZero, the first unified benchmark for deploying\nMCTS/MuZero in general sequential decision scenarios. Specificially, we\nsummarize the most critical challenges in designing a general MCTS-style\ndecision-making solver, then decompose the tightly-coupled algorithm and system\ndesign of tree-search RL methods into distinct sub-modules. By incorporating\nmore appropriate exploration and optimization strategies, we can significantly\nenhance these sub-modules and construct powerful LightZero agents to tackle\ntasks across a wide range of domains, such as board games, Atari, MuJoCo,\nMiniGrid and GoBigger. Detailed benchmark results reveal the significant\npotential of such methods in building scalable and efficient decision\nintelligence. The code is available as part of OpenDILab at\nhttps://github.com/opendilab/LightZero.\n",
                "链接": "https://arxiv.org/abs/2310.08348"
            },
            {
                "文章ID": "7216",
                "标题": "Decision Making in Non-Stationary Environments with Policy-Augmented\n  Monte Carlo Tree Search",
                "作者": " Geoffrey Pettet,  Ayan Mukhopadhyay,  Abhishek Dubey",
                "发布日期": "2022-03-01",
                "摘要": "  Decision-making under uncertainty (DMU) is present in many important\nproblems. An open challenge is DMU in non-stationary environments, where the\ndynamics of the environment can change over time. Reinforcement Learning (RL),\na popular approach for DMU problems, learns a policy by interacting with a\nmodel of the environment offline. Unfortunately, if the environment changes the\npolicy can become stale and take sub-optimal actions, and relearning the policy\nfor the updated environment takes time and computational effort. An alternative\nis online planning approaches such as Monte Carlo Tree Search (MCTS), which\nperform their computation at decision time. Given the current environment, MCTS\nplans using high-fidelity models to determine promising action trajectories.\nThese models can be updated as soon as environmental changes are detected to\nimmediately incorporate them into decision making. However, MCTS's convergence\ncan be slow for domains with large state-action spaces. In this paper, we\npresent a novel hybrid decision-making approach that combines the strengths of\nRL and planning while mitigating their weaknesses. Our approach, called Policy\nAugmented MCTS (PA-MCTS), integrates a policy's actin-value estimates into\nMCTS, using the estimates to seed the action trajectories favored by the\nsearch. We hypothesize that PA-MCTS will converge more quickly than standard\nMCTS while making better decisions than the policy can make on its own when\nfaced with nonstationary environments. We test our hypothesis by comparing\nPA-MCTS with pure MCTS and an RL agent applied to the classical CartPole\nenvironment. We find that PC-MCTS can achieve higher cumulative rewards than\nthe policy in isolation under several environmental shifts while converging in\nsignificantly fewer iterations than pure MCTS.\n",
                "链接": "https://arxiv.org/abs/2202.13003"
            },
            {
                "文章ID": "102301",
                "标题": "Maneuver Decision-Making Through Proximal Policy Optimization And Monte\n  Carlo Tree Search",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-09-19",
                "摘要": "  Maneuver decision-making can be regarded as a Markov decision process and can\nbe address by reinforcement learning. However, original reinforcement learning\nalgorithms can hardly solve the maneuvering decision-making problem. One reason\nis that agents use random actions in the early stages of training, which makes\nit difficult to get rewards and learn how to make effective decisions. To\naddress this issue, a method based on proximal policy optimization and Monte\nCarlo tree search is proposed. The method uses proximal policy optimization to\ntrain the agent, and regards the results of air combat as targets to train the\nvalue network. Then, based on the value network and the visit count of each\nnode, Monte Carlo tree search is used to find the actions with more expected\nreturns than random actions, which can improve the training performance. The\nablation studies and simulation experiments indicate that agents trained by the\nproposed method can make different decisions according to different states,\nwhich demonstrates that the method can solve the maneuvering decision problem\nthat the original reinforcement learning algorithm cannot solve.\n",
                "链接": "https://arxiv.org/abs/2309.08611"
            },
            {
                "文章ID": "23592",
                "标题": "Combining Monte-Carlo Tree Search with Proof-Number Search",
                "作者": " Elliot Doe,  Mark H. M. Winands,  Dennis J. N. J. Soemers,  Cameron Browne",
                "发布日期": "2022-06-09",
                "摘要": "  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
                "链接": "https://arxiv.org/abs/2206.03965"
            },
            {
                "文章ID": "50093",
                "标题": "Monte Carlo Tree Search Algorithms for Risk-Aware and Multi-Objective\n  Reinforcement Learning",
                "作者": " Conor F. Hayes,  Mathieu Reymond,  Diederik M. Roijers,  Enda Howley,  Patrick Mannion",
                "发布日期": "2022-12-07",
                "摘要": "  In many risk-aware and multi-objective reinforcement learning settings, the\nutility of the user is derived from a single execution of a policy. In these\nsettings, making decisions based on the average future returns is not suitable.\nFor example, in a medical setting a patient may only have one opportunity to\ntreat their illness. Making decisions using just the expected future returns --\nknown in reinforcement learning as the value -- cannot account for the\npotential range of adverse or positive outcomes a decision may have. Therefore,\nwe should use the distribution over expected future returns differently to\nrepresent the critical information that the agent requires at decision time by\ntaking both the future and accrued returns into consideration. In this paper,\nwe propose two novel Monte Carlo tree search algorithms. Firstly, we present a\nMonte Carlo tree search algorithm that can compute policies for nonlinear\nutility functions (NLU-MCTS) by optimising the utility of the different\npossible returns attainable from individual policy executions, resulting in\ngood policies for both risk-aware and multi-objective settings. Secondly, we\npropose a distributional Monte Carlo tree search algorithm (DMCTS) which\nextends NLU-MCTS. DMCTS computes an approximate posterior distribution over the\nutility of the returns, and utilises Thompson sampling during planning to\ncompute policies in risk-aware and multi-objective settings. Both algorithms\noutperform the state-of-the-art in multi-objective reinforcement learning for\nthe expected utility of the returns.\n",
                "链接": "https://arxiv.org/abs/2211.13032"
            },
            {
                "文章ID": "67092",
                "标题": "Proof Number Based Monte-Carlo Tree Search",
                "作者": " Jakub Kowalski,  Elliot Doe,  Mark H. M. Winands,  Daniel Górski,  Dennis J. N. J. Soemers",
                "发布日期": "2023-12-22",
                "摘要": "  This paper proposes a new game-search algorithm, PN-MCTS, which combines\nMonte-Carlo Tree Search (MCTS) and Proof-Number Search (PNS). These two\nalgorithms have been successfully applied for decision making in a range of\ndomains. We define three areas where the additional knowledge provided by the\nproof and disproof numbers gathered in MCTS trees might be used: final move\nselection, solving subtrees, and the UCB1 selection mechanism. We test all\npossible combinations on different time settings, playing against vanilla UCT\non several games: Lines of Action ($7$$\\times$$7$ and $8$$\\times$$8$ board\nsizes), MiniShogi, Knightthrough, and Awari. Furthermore, we extend this new\nalgorithm to properly address games with draws, like Awari, by adding an\nadditional layer of PNS on top of the MCTS tree. The experiments show that\nPN-MCTS confidently outperforms MCTS in all tested game domains, achieving win\nrates up to 96.2\\% for Lines of Action.\n",
                "链接": "https://arxiv.org/abs/2303.09449"
            },
            {
                "文章ID": "22592",
                "标题": "Policy Gradient Algorithms with Monte-Carlo Tree Search for Non-Markov\n  Decision Processes",
                "作者": " Tetsuro Morimura,  Kazuhiro Ota,  Kenshi Abe,  Peinan Zhang",
                "发布日期": "2022-06-03",
                "摘要": "  Policy gradient (PG) is a reinforcement learning (RL) approach that optimizes\na parameterized policy model for an expected return using gradient ascent.\nGiven a well-parameterized policy model, such as a neural network model, with\nappropriate initial parameters, the PG algorithms work well even when\nenvironment does not have the Markov property. Otherwise, they can be trapped\non a plateau or suffer from peakiness effects. As another successful RL\napproach, algorithms based on Monte-Carlo Tree Search (MCTS), which include\nAlphaZero, have obtained groundbreaking results especially on the board game\nplaying domain. They are also suitable to be applied to non-Markov decision\nprocesses. However, since the standard MCTS does not have the ability to learn\nstate representation, the size of the tree-search space can be too large to\nsearch. In this work, we examine a mixture policy of PG and MCTS to complement\neach other's difficulties and take advantage of them. We derive conditions for\nasymptotic convergence with results of a two-timescale stochastic approximation\nand propose an algorithm that satisfies these conditions. The effectivity of\nthe proposed methods is verified through numerical experiments on non-Markov\ndecision processes.\n",
                "链接": "https://arxiv.org/abs/2206.01011"
            },
            {
                "文章ID": "53055",
                "标题": "Lookahead Pathology in Monte-Carlo Tree Search",
                "作者": " Khoi P. N. Nguyen,  Raghuram Ramanujan",
                "发布日期": "2022-12-13",
                "摘要": "  Monte-Carlo Tree Search (MCTS) is an adversarial search paradigm that first\nfound prominence with its success in the domain of computer Go. Early\ntheoretical work established the game-theoretic soundness and convergence\nbounds for Upper Confidence bounds applied to Trees (UCT), the most popular\ninstantiation of MCTS; however, there remain notable gaps in our understanding\nof how UCT behaves in practice. In this work, we address one such gap by\nconsidering the question of whether UCT can exhibit lookahead pathology -- a\nparadoxical phenomenon first observed in Minimax search where greater search\neffort leads to worse decision-making. We introduce a novel family of synthetic\ngames that offer rich modeling possibilities while remaining amenable to\nmathematical analysis. Our theoretical and experimental results suggest that\nUCT is indeed susceptible to pathological behavior in a range of games drawn\nfrom this family.\n",
                "链接": "https://arxiv.org/abs/2212.05208"
            },
            {
                "文章ID": "123470",
                "标题": "Monte Carlo Tree Search in the Presence of Transition Uncertainty",
                "作者": " Farnaz Kohankhaki,  Kiarash Aghakasiri,  Hongming Zhang,  Ting-Han Wei,  Chao Gao,  Martin Müller",
                "发布日期": "2023-12-19",
                "摘要": "  Monte Carlo Tree Search (MCTS) is an immensely popular search-based framework\nused for decision making. It is traditionally applied to domains where a\nperfect simulation model of the environment is available. We study and improve\nMCTS in the context where the environment model is given but imperfect. We show\nthat the discrepancy between the model and the actual environment can lead to\nsignificant performance degradation with standard MCTS. We therefore develop\nUncertainty Adapted MCTS (UA-MCTS), a more robust algorithm within the MCTS\nframework. We estimate the transition uncertainty in the given model, and\ndirect the search towards more certain transitions in the state space. We\nmodify all four MCTS phases to improve the search behavior by considering these\nestimates. We prove, in the corrupted bandit case, that adding uncertainty\ninformation to adapt UCB leads to tighter regret bound than standard UCB.\nEmpirically, we evaluate UA-MCTS and its individual components on the\ndeterministic domains from the MinAtar test suite. Our results demonstrate that\nUA-MCTS strongly improves MCTS in the presence of model transition errors.\n",
                "链接": "https://arxiv.org/abs/2312.11348"
            },
            {
                "文章ID": "113248",
                "标题": "An Integrated Framework Integrating Monte Carlo Tree Search and\n  Supervised Learning for Train Timetabling Problem",
                "作者": " Feiyu Yang",
                "发布日期": "2023-11-03",
                "摘要": "  The single-track railway train timetabling problem (TTP) is an important and\ncomplex problem. This article proposes an integrated Monte Carlo Tree Search\n(MCTS) computing framework that combines heuristic methods, unsupervised\nlearning methods, and supervised learning methods for solving TTP in discrete\naction spaces. This article first describes the mathematical model and\nsimulation system dynamics of TTP, analyzes the characteristics of the solution\nfrom the perspective of MCTS, and proposes some heuristic methods to improve\nMCTS. This article considers these methods as planners in the proposed\nframework. Secondly, this article utilizes deep convolutional neural networks\nto approximate the value of nodes and further applies them to the MCTS search\nprocess, referred to as learners. The experiment shows that the proposed\nheuristic MCTS method is beneficial for solving TTP; The algorithm framework\nthat integrates planners and learners can improve the data efficiency of\nsolving TTP; The proposed method provides a new paradigm for solving TTP.\n",
                "链接": "https://arxiv.org/abs/2311.00971"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用gpt4做评测指标优缺点的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "116110",
                "标题": "Enhancing Medical Text Evaluation with GPT-4",
                "作者": " Yiqing Xie,  Sheng Zhang,  Hao Cheng,  Zelalem Gero,  Cliff Wong,  Tristan Naumann,  Hoifung Poon",
                "发布日期": "2023-11-17",
                "摘要": "  In the evaluation of medical text generation, it is essential to scrutinize\neach piece of information and ensure the utmost accuracy of the evaluation.\nExisting evaluation metrics either focus on coarse-level evaluation that\nassigns one score for the whole generated output or rely on evaluation models\ntrained on general domain, resulting in inaccuracies when adapted to the\nmedical domain. To address these issues, we propose a set of factuality-centric\nevaluation aspects and design corresponding GPT-4-based metrics for medical\ntext generation. We systematically compare these metrics with existing ones on\nclinical note generation and medical report summarization tasks, revealing low\ninter-metric correlation. A comprehensive human evaluation confirms that the\nproposed GPT-4-based metrics exhibit substantially higher agreement with human\njudgments than existing evaluation metrics. Our study contributes to the\nunderstanding of medical text generation evaluation and offers a more reliable\nalternative to existing metrics.\n",
                "链接": "https://arxiv.org/abs/2311.09581"
            },
            {
                "文章ID": "98248",
                "标题": "GPTEval: A Survey on Assessments of ChatGPT and GPT-4",
                "作者": " Rui Mao,  Guanyi Chen,  Xulang Zhang,  Frank Guerin,  Erik Cambria",
                "发布日期": "2023-08-25",
                "摘要": "  The emergence of ChatGPT has generated much speculation in the press about\nits potential to disrupt social and economic systems. Its astonishing language\nability has aroused strong curiosity among scholars about its performance in\ndifferent domains. There have been many studies evaluating the ability of\nChatGPT and GPT-4 in different tasks and disciplines. However, a comprehensive\nreview summarizing the collective assessment findings is lacking. The objective\nof this survey is to thoroughly analyze prior assessments of ChatGPT and GPT-4,\nfocusing on its language and reasoning abilities, scientific knowledge, and\nethical considerations. Furthermore, an examination of the existing evaluation\nmethods is conducted, offering several recommendations for future research in\nevaluating large language models.\n",
                "链接": "https://arxiv.org/abs/2308.12488"
            },
            {
                "文章ID": "67765",
                "标题": "Mind meets machine: Unravelling GPT-4's cognitive psychology",
                "作者": " Sifatkaur Dhingra,  Manmeet Singh,  Vaisakh SB,  Neetiraj Malviya,  Sukhpal Singh Gill",
                "发布日期": "2023-04-13",
                "摘要": "  Cognitive psychology delves on understanding perception, attention, memory,\nlanguage, problem-solving, decision-making, and reasoning. Large language\nmodels (LLMs) are emerging as potent tools increasingly capable of performing\nhuman-level tasks. The recent development in the form of GPT-4 and its\ndemonstrated success in tasks complex to humans exam and complex problems has\nled to an increased confidence in the LLMs to become perfect instruments of\nintelligence. Although GPT-4 report has shown performance on some cognitive\npsychology tasks, a comprehensive assessment of GPT-4, via the existing\nwell-established datasets is required. In this study, we focus on the\nevaluation of GPT-4's performance on a set of cognitive psychology datasets\nsuch as CommonsenseQA, SuperGLUE, MATH and HANS. In doing so, we understand how\nGPT-4 processes and integrates cognitive psychology with contextual\ninformation, providing insight into the underlying cognitive processes that\nenable its ability to generate the responses. We show that GPT-4 exhibits a\nhigh level of accuracy in cognitive psychology tasks relative to the prior\nstate-of-the-art models. Our results strengthen the already available\nassessments and confidence on GPT-4's cognitive psychology abilities. It has\nsignificant potential to revolutionize the field of AI, by enabling machines to\nbridge the gap between human and machine reasoning.\n",
                "链接": "https://arxiv.org/abs/2303.11436"
            },
            {
                "文章ID": "95177",
                "标题": "GPT-4 Can't Reason",
                "作者": " Konstantine Arkoudas",
                "发布日期": "2023-08-11",
                "摘要": "  GPT-4 was released in March 2023 to wide acclaim, marking a very substantial\nimprovement across the board over GPT-3.5 (OpenAI's previously best model,\nwhich had powered the initial release of ChatGPT). However, despite the\ngenuinely impressive improvement, there are good reasons to be highly skeptical\nof GPT-4's ability to reason. This position paper discusses the nature of\nreasoning; criticizes the current formulation of reasoning problems in the NLP\ncommunity, as well as the way in which LLM reasoning performance is currently\nevaluated; introduces a small collection of 21 diverse reasoning problems; and\nperforms a detailed qualitative evaluation of GPT-4's performance on those\nproblems. Based on this analysis, the paper concludes that, despite its\noccasional flashes of analytical brilliance, GPT-4 at present is utterly\nincapable of reasoning.\n",
                "链接": "https://arxiv.org/abs/2308.03762"
            },
            {
                "文章ID": "102940",
                "标题": "An Evaluation of GPT-4 on the ETHICS Dataset",
                "作者": " Sergey Rodionov,  Zarathustra Amadeus Goertzel,  Ben Goertzel",
                "发布日期": "2023-09-20",
                "摘要": "  This report summarizes a short study of the performance of GPT-4 on the\nETHICS dataset. The ETHICS dataset consists of five sub-datasets covering\ndifferent fields of ethics: Justice, Deontology, Virtue Ethics, Utilitarianism,\nand Commonsense Ethics. The moral judgments were curated so as to have a high\ndegree of agreement with the aim of representing shared human values rather\nthan moral dilemmas. GPT-4's performance is much better than that of previous\nmodels and suggests that learning to work with common human values is not the\nhard problem for AI ethics.\n",
                "链接": "https://arxiv.org/abs/2309.10492"
            },
            {
                "文章ID": "94757",
                "标题": "Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings",
                "作者": " Veronika Hackl,  Alexandra Elena Müller,  Michael Granitzer,  Maximilian Sailer",
                "发布日期": "2023-08-08",
                "摘要": "  This study investigates the consistency of feedback ratings generated by\nOpenAI's GPT-4, a state-of-the-art artificial intelligence language model,\nacross multiple iterations, time spans and stylistic variations. The model\nrated responses to tasks within the Higher Education (HE) subject domain of\nmacroeconomics in terms of their content and style. Statistical analysis was\nconducted in order to learn more about the interrater reliability, consistency\nof the ratings across iterations and the correlation between ratings in terms\nof content and style. The results revealed a high interrater reliability with\nICC scores ranging between 0.94 and 0.99 for different timespans, suggesting\nthat GPT-4 is capable of generating consistent ratings across repetitions with\na clear prompt. Style and content ratings show a high correlation of 0.87. When\napplying a non-adequate style the average content ratings remained constant,\nwhile style ratings decreased, which indicates that the large language model\n(LLM) effectively distinguishes between these two criteria during evaluation.\nThe prompt used in this study is furthermore presented and explained. Further\nresearch is necessary to assess the robustness and reliability of AI models in\nvarious use cases.\n",
                "链接": "https://arxiv.org/abs/2308.02575"
            },
            {
                "文章ID": "110966",
                "标题": "GPT-4 as an Effective Zero-Shot Evaluator for Scientific Figure Captions",
                "作者": " Ting-Yao Hsu,  Chieh-Yang Huang,  Ryan Rossi,  Sungchul Kim,  C. Lee Giles,  Ting-Hao K. Huang",
                "发布日期": "2023-10-25",
                "摘要": "  There is growing interest in systems that generate captions for scientific\nfigures. However, assessing these systems output poses a significant challenge.\nHuman evaluation requires academic expertise and is costly, while automatic\nevaluation depends on often low-quality author-written captions. This paper\ninvestigates using large language models (LLMs) as a cost-effective,\nreference-free method for evaluating figure captions. We first constructed\nSCICAP-EVAL, a human evaluation dataset that contains human judgments for 3,600\nscientific figure captions, both original and machine-made, for 600 arXiv\nfigures. We then prompted LLMs like GPT-4 and GPT-3 to score (1-6) each caption\nbased on its potential to aid reader understanding, given relevant context such\nas figure-mentioning paragraphs. Results show that GPT-4, used as a zero-shot\nevaluator, outperformed all other models and even surpassed assessments made by\nComputer Science and Informatics undergraduates, achieving a Kendall\ncorrelation score of 0.401 with Ph.D. students rankings\n",
                "链接": "https://arxiv.org/abs/2310.15405"
            },
            {
                "文章ID": "112767",
                "标题": "Does GPT-4 Pass the Turing Test?",
                "作者": " Cameron Jones,  Benjamin Bergen",
                "发布日期": "2023-11-01",
                "摘要": "  We evaluated GPT-4 in a public online Turing Test. The best-performing GPT-4\nprompt passed in 41% of games, outperforming baselines set by ELIZA (27%) and\nGPT-3.5 (14%), but falling short of chance and the baseline set by human\nparticipants (63%). Participants' decisions were based mainly on linguistic\nstyle (35%) and socio-emotional traits (27%), supporting the idea that\nintelligence is not sufficient to pass the Turing Test. Participants'\ndemographics, including education and familiarity with LLMs, did not predict\ndetection rate, suggesting that even those who understand systems deeply and\ninteract with them frequently may be susceptible to deception. Despite known\nlimitations as a test of intelligence, we argue that the Turing Test continues\nto be relevant as an assessment of naturalistic communication and deception. AI\nmodels with the ability to masquerade as humans could have widespread societal\nconsequences, and we analyse the effectiveness of different strategies and\ncriteria for judging humanlikeness.\n",
                "链接": "https://arxiv.org/abs/2310.20216"
            },
            {
                "文章ID": "110350",
                "标题": "Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large\n  Language Models on Sequence to Sequence Tasks",
                "作者": " Andrea Sottana,  Bin Liang,  Kai Zou,  Zheng Yuan",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) evaluation is a patchy and inconsistent\nlandscape, and it is becoming clear that the quality of automatic evaluation\nmetrics is not keeping up with the pace of development of generative models. We\naim to improve the understanding of current models' performance by providing a\npreliminary and hybrid evaluation on a range of open and closed-source\ngenerative LLMs on three NLP benchmarks: text summarisation, text\nsimplification and grammatical error correction (GEC), using both automatic and\nhuman evaluation. We also explore the potential of the recently released GPT-4\nto act as an evaluator. We find that ChatGPT consistently outperforms many\nother popular models according to human reviewers on the majority of metrics,\nwhile scoring much more poorly when using classic automatic evaluation metrics.\nWe also find that human reviewers rate the gold reference as much worse than\nthe best models' outputs, indicating the poor quality of many popular\nbenchmarks. Finally, we find that GPT-4 is capable of ranking models' outputs\nin a way which aligns reasonably closely to human judgement despite\ntask-specific variations, with a lower alignment in the GEC task.\n",
                "链接": "https://arxiv.org/abs/2310.13800"
            },
            {
                "文章ID": "80356",
                "标题": "Is GPT-4 a Good Data Analyst?",
                "作者": " Liying Cheng,  Xingxuan Li,  Lidong Bing",
                "发布日期": "2023-10-24",
                "摘要": "  As large language models (LLMs) have demonstrated their powerful capabilities\nin plenty of domains and tasks, including context understanding, code\ngeneration, language generation, data storytelling, etc., many data analysts\nmay raise concerns if their jobs will be replaced by artificial intelligence\n(AI). This controversial topic has drawn great attention in public. However, we\nare still at a stage of divergent opinions without any definitive conclusion.\nMotivated by this, we raise the research question of \"is GPT-4 a good data\nanalyst?\" in this work and aim to answer it by conducting head-to-head\ncomparative studies. In detail, we regard GPT-4 as a data analyst to perform\nend-to-end data analysis with databases from a wide range of domains. We\npropose a framework to tackle the problems by carefully designing the prompts\nfor GPT-4 to conduct experiments. We also design several task-specific\nevaluation metrics to systematically compare the performance between several\nprofessional human data analysts and GPT-4. Experimental results show that\nGPT-4 can achieve comparable performance to humans. We also provide in-depth\ndiscussions about our results to shed light on further studies before reaching\nthe conclusion that GPT-4 can replace data analysts.\n",
                "链接": "https://arxiv.org/abs/2305.15038"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用GPT4v完成多模态智能体的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "74335",
                "标题": "AI-assisted coding: Experiments with GPT-4",
                "作者": " Russell A Poldrack,  Thomas Lu,  Gašper Beguš",
                "发布日期": "2023-04-27",
                "摘要": "  Artificial intelligence (AI) tools based on large language models have\nacheived human-level performance on some computer programming tasks. We report\nseveral experiments using GPT-4 to generate computer code. These experiments\ndemonstrate that AI code generation using the current generation of tools,\nwhile powerful, requires substantial human validation to ensure accurate\nperformance. We also demonstrate that GPT-4 refactoring of existing code can\nsignificantly improve that code along several established metrics for code\nquality, and we show that GPT-4 can generate tests with substantial coverage,\nbut that many of the tests fail when applied to the associated code. These\nfindings suggest that while AI coding tools are very powerful, they still\nrequire humans in the loop to ensure validity and accuracy of the results.\n",
                "链接": "https://arxiv.org/abs/2304.13187"
            },
            {
                "文章ID": "66852",
                "标题": "GPT-4 Technical Report",
                "作者": "Rai   OpenAI, Rai   :, Rai  Josh Achiam, Rai  Steven Adler, Rai  Sandhini Agarwal, Rai  Lama Ahmad, Rai  Ilge Akkaya, Rai  Florencia Leoni Aleman, Rai  Diogo Almeida, Rai  Janko Altenschmidt, Rai  Sam Altman, Rai  Shyamal Anadkat, Rai  Red Avila, Rai  Igor Babuschkin, Rai  Suchir Balaji, Rai  Valerie Balcom, Rai  Paul Baltescu, Rai  Haiming Bao, Rai  Mo Bavarian, Rai  Jeff Belgum, Rai  Irwan Bello, Rai  Jake Berdine, Rai  Gabriel Bernadett-Shapiro, Rai  Christopher Berner, Rai  Lenny Bogdonoff, Rai  Oleg Boiko, Rai  Madelaine Boyd, Rai  Anna-Luisa Brakman, Rai  Greg Brockman, Rai  Tim Brooks, Rai  Miles Brundage, Rai  Kevin Button, Rai  Trevor Cai, Rai  Rosie Campbell, Rai  Andrew Cann, Rai  Brittany Carey, Rai  Chelsea Carlson, Rai  Rory Carmichael, Rai  Brooke Chan, Rai  Che Chang, Rai  Fotis Chantzis, Rai  Derek Chen, Rai  Sully Chen, Rai  Ruby Chen, Rai  Jason Chen, Rai  Mark Chen, Rai  Ben Chess, Rai  Chester Cho, Rai  Casey Chu, Rai  Hyung Won Chung, Rai  Dave Cummings, Rai  Jeremiah Currier, Rai  Yunxing Dai, Rai  Cory Decareaux, Rai  Thomas Degry, Rai  Noah Deutsch, Rai  Damien Deville, Rai  Arka Dhar, Rai  David Dohan, Rai  Steve Dowling, Rai  Sheila Dunning, Rai  Adrien Ecoffet, Rai  Atty Eleti, Rai  Tyna Eloundou, Rai  David Farhi, Rai  Liam Fedus, Rai  Niko Felix, Rai  Simón Posada Fishman, Rai  Juston Forte, Rai  Isabella Fulford, Rai  Leo Gao, Rai  Elie Georges, Rai  Christian Gibson, Rai  Vik Goel, Rai  Tarun Gogineni, Rai  Gabriel Goh, Rai  Rapha Gontijo-Lopes, Rai  Jonathan Gordon, Rai  Morgan Grafstein, Rai  Scott Gray, Rai  Ryan Greene, Rai  Joshua Gross, Rai  Shixiang Shane Gu, Rai  Yufei Guo, Rai  Chris Hallacy, Rai  Jesse Han, Rai  Jeff Harris, Rai  Yuchen He, Rai  Mike Heaton, Rai  Johannes Heidecke, Rai  Chris Hesse, Rai  Alan Hickey, Rai  Wade Hickey, Rai  Peter Hoeschele, Rai  Brandon Houghton, Rai  Kenny Hsu, Rai  Shengli Hu, Rai  Xin Hu, Rai  Joost Huizinga, Rai  Shantanu Jain, Rai  Shawn Jain, Rai  Joanne Jang, Rai  Angela Jiang, Rai  Roger Jiang, Rai  Haozhun Jin, Rai  Denny Jin, Rai  Shino Jomoto, Rai  Billie Jonn, Rai  Heewoo Jun, Rai  Tomer Kaftan, Rai  Łukasz Kaiser, Rai  Ali Kamali, Rai  Ingmar Kanitscheider, Rai  Nitish Shirish Keskar, Rai  Tabarak Khan, Rai  Logan Kilpatrick, Rai  Jong Wook Kim, Rai  Christina Kim, Rai  Yongjik Kim, Rai  Hendrik Kirchner, Rai  Jamie Kiros, Rai  Matt Knight, Rai  Daniel Kokotajlo, Rai  Łukasz Kondraciuk, Rai  Andrew Kondrich, Rai  Aris Konstantinidis, Rai  Kyle Kosic, Rai  Gretchen Krueger, Rai  Vishal Kuo, Rai  Michael Lampe, Rai  Ikai Lan, Rai  Teddy Lee, Rai  Jan Leike, Rai  Jade Leung, Rai  Daniel Levy, Rai  Chak Ming Li, Rai  Rachel Lim, Rai  Molly Lin, Rai  Stephanie Lin, Rai  Mateusz Litwin, Rai  Theresa Lopez, Rai  Ryan Lowe, Rai  Patricia Lue, Rai  Anna Makanju, Rai  Kim Malfacini, Rai  Sam Manning, Rai  Todor Markov, Rai  Yaniv Markovski, Rai  Bianca Martin, Rai  Katie Mayer, Rai  Andrew Mayne, Rai  Bob McGrew, Rai  Scott Mayer McKinney, Rai  Christine McLeavey, Rai  Paul McMillan, Rai  Jake McNeil, Rai  David Medina, Rai  Aalok Mehta, Rai  Jacob Menick, Rai  Luke Metz, Rai  Andrey Mishchenko, Rai  Pamela Mishkin, Rai  Vinnie Monaco, Rai  Evan Morikawa, Rai  Daniel Mossing, Rai  Tong Mu, Rai  Mira Murati, Rai  Oleg Murk, Rai  David Mély, Rai  Ashvin Nair, Rai  Reiichiro Nakano, Rai  Rajeev Nayak, Rai  Arvind Neelakantan, Rai  Richard Ngo, Rai  Hyeonwoo Noh, Rai  Long Ouyang, Rai  Cullen O'Keefe, Rai  Jakub Pachocki, Rai  Alex Paino, Rai  Joe Palermo, Rai  Ashley Pantuliano, Rai  Giambattista Parascandolo, Rai  Joel Parish, Rai  Emy Parparita, Rai  Alex Passos, Rai  Mikhail Pavlov, Rai  Andrew Peng, Rai  Adam Perelman, Rai  Filipe de Avila Belbute Peres, Rai  Michael Petrov, Rai  Henrique Ponde de Oliveira Pinto, Rai   Michael,   Pokorny,  Michelle Pokrass,  Vitchyr Pong,  Tolly Powell,  Alethea Power,  Boris Power,  Elizabeth Proehl,  Raul Puri,  Alec Radford,  Jack Rae,  Aditya Ramesh,  Cameron Raymond,  Francis Real,  Kendra Rimbach,  Carl Ross,  Bob Rotsted,  Henri Roussez,  Nick Ryder,  Mario Saltarelli,  Ted Sanders,  Shibani Santurkar,  Girish Sastry,  Heather Schmidt,  David Schnurr,  John Schulman,  Daniel Selsam,  Kyla Sheppard,  Toki Sherbakov,  Jessica Shieh,  Sarah Shoker,  Pranav Shyam,  Szymon Sidor,  Eric Sigler,  Maddie Simens,  Jordan Sitkin,  Katarina Slama,  Ian Sohl,  Benjamin Sokolowsky,  Yang Song,  Natalie Staudacher,  Felipe Petroski Such,  Natalie Summers,  Ilya Sutskever,  Jie Tang,  Nikolas Tezak,  Madeleine Thompson,  Phil Tillet,  Amin Tootoonchian,  Elizabeth Tseng,  Preston Tuggle,  Nick Turley,  Jerry Tworek,  Juan Felipe Cerón Uribe,  Andrea Vallone,  Arun Vijayvergiya,  Chelsea Voss,  Carroll Wainwright,  Justin Jay Wang,  Alvin Wang,  Ben Wang,  Jonathan Ward,  Jason Wei,  CJ Weinmann,  Akila Welihinda,  Peter Welinder,  Jiayi Weng,  Lilian Weng,  Matt Wiethoff,  Dave Willner,  Clemens Winter,  Samuel Wolrich,  Hannah Wong,  Lauren Workman,  Sherwin Wu,  Jeff Wu,  Michael Wu,  Kai Xiao,  Tao Xu,  Sarah Yoo,  Kevin Yu,  Qiming Yuan,  Wojciech Zaremba,  Rowan Zellers,  Chong Zhang,  Marvin Zhang,  Shengjia Zhao,  Tianhao Zheng,  Juntang Zhuang,  William Zhuk,  Barret Zoph",
                "发布日期": "2023-12-20",
                "摘要": "  We report the development of GPT-4, a large-scale, multimodal model which can\naccept image and text inputs and produce text outputs. While less capable than\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance on\nvarious professional and academic benchmarks, including passing a simulated bar\nexam with a score around the top 10% of test takers. GPT-4 is a\nTransformer-based model pre-trained to predict the next token in a document.\nThe post-training alignment process results in improved performance on measures\nof factuality and adherence to desired behavior. A core component of this\nproject was developing infrastructure and optimization methods that behave\npredictably across a wide range of scales. This allowed us to accurately\npredict some aspects of GPT-4's performance based on models trained with no\nmore than 1/1,000th the compute of GPT-4.\n",
                "链接": "https://arxiv.org/abs/2303.08774"
            },
            {
                "文章ID": "115991",
                "标题": "Comparing Humans, GPT-4, and GPT-4V On Abstraction and Reasoning Tasks",
                "作者": " Melanie Mitchell,  Alessandro B. Palmarini,  Arseny Moskvichev",
                "发布日期": "2023-12-25",
                "摘要": "  We explore the abstract reasoning abilities of text-only and multimodal\nversions of GPT-4, using the ConceptARC benchmark [10], which is designed to\nevaluate robust understanding and reasoning with core-knowledge concepts. We\nextend the work of Moskvichev et al. [10] by evaluating GPT-4 on more detailed,\none-shot prompting (rather than simple, zero-shot prompts) with text versions\nof ConceptARC tasks, and by evaluating GPT-4V, the multimodal version of GPT-4,\non zero- and one-shot prompts using image versions of the simplest tasks. Our\nexperimental results support the conclusion that neither version of GPT-4 has\ndeveloped robust abstraction abilities at humanlike levels.\n",
                "链接": "https://arxiv.org/abs/2311.09247"
            },
            {
                "文章ID": "87962",
                "标题": "A GPT-4 Reticular Chemist for Guiding MOF Discovery",
                "作者": " Zhiling Zheng,  Zichao Rong,  Nakul Rampal,  Christian Borgs,  Jennifer T. Chayes,  Omar M. Yaghi",
                "发布日期": "2023-11-01",
                "摘要": "  We present a new framework integrating the AI model GPT-4 into the iterative\nprocess of reticular chemistry experimentation, leveraging a cooperative\nworkflow of interaction between AI and a human researcher. This GPT-4 Reticular\nChemist is an integrated system composed of three phases. Each of these\nutilizes GPT-4 in various capacities, wherein GPT-4 provides detailed\ninstructions for chemical experimentation and the human provides feedback on\nthe experimental outcomes, including both success and failures, for the\nin-context learning of AI in the next iteration. This iterative human-AI\ninteraction enabled GPT-4 to learn from the outcomes, much like an experienced\nchemist, by a prompt-learning strategy. Importantly, the system is based on\nnatural language for both development and operation, eliminating the need for\ncoding skills, and thus, make it accessible to all chemists. Our collaboration\nwith GPT-4 Reticular Chemist guided the discovery of an isoreticular series of\nMOFs, with each synthesis fine-tuned through iterative feedback and expert\nsuggestions. This workflow presents a potential for broader applications in\nscientific research by harnessing the capability of large language models like\nGPT-4 to enhance the feasibility and efficiency of research activities.\n",
                "链接": "https://arxiv.org/abs/2306.14915"
            },
            {
                "文章ID": "83156",
                "标题": "Can LLMs like GPT-4 outperform traditional AI tools in dementia\n  diagnosis? Maybe, but not today",
                "作者": " Zhuo Wang,  Rongzhen Li,  Bowen Dong,  Jie Wang,  Xiuxing Li,  Ning Liu,  Chenhui Mao,  Wei Zhang,  Liling Dong,  Jing Gao,  Jianyong Wang",
                "发布日期": "2023-06-05",
                "摘要": "  Recent investigations show that large language models (LLMs), specifically\nGPT-4, not only have remarkable capabilities in common Natural Language\nProcessing (NLP) tasks but also exhibit human-level performance on various\nprofessional and academic benchmarks. However, whether GPT-4 can be directly\nused in practical applications and replace traditional artificial intelligence\n(AI) tools in specialized domains requires further experimental validation. In\nthis paper, we explore the potential of LLMs such as GPT-4 to outperform\ntraditional AI tools in dementia diagnosis. Comprehensive comparisons between\nGPT-4 and traditional AI tools are conducted to examine their diagnostic\naccuracy in a clinical setting. Experimental results on two real clinical\ndatasets show that, although LLMs like GPT-4 demonstrate potential for future\nadvancements in dementia diagnosis, they currently do not surpass the\nperformance of traditional AI tools. The interpretability and faithfulness of\nGPT-4 are also evaluated by comparison with real doctors. We discuss the\nlimitations of GPT-4 in its current state and propose future research\ndirections to enhance GPT-4 in dementia diagnosis.\n",
                "链接": "https://arxiv.org/abs/2306.01499"
            },
            {
                "文章ID": "68191",
                "标题": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
                "作者": " Sébastien Bubeck,  Varun Chandrasekaran,  Ronen Eldan,  Johannes Gehrke,  Eric Horvitz,  Ece Kamar,  Peter Lee,  Yin Tat Lee,  Yuanzhi Li,  Scott Lundberg,  Harsha Nori,  Hamid Palangi,  Marco Tulio Ribeiro,  Yi Zhang",
                "发布日期": "2023-04-17",
                "摘要": "  Artificial intelligence (AI) researchers have been developing and refining\nlarge language models (LLMs) that exhibit remarkable capabilities across a\nvariety of domains and tasks, challenging our understanding of learning and\ncognition. The latest model developed by OpenAI, GPT-4, was trained using an\nunprecedented scale of compute and data. In this paper, we report on our\ninvestigation of an early version of GPT-4, when it was still in active\ndevelopment by OpenAI. We contend that (this early version of) GPT-4 is part of\na new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that\nexhibit more general intelligence than previous AI models. We discuss the\nrising capabilities and implications of these models. We demonstrate that,\nbeyond its mastery of language, GPT-4 can solve novel and difficult tasks that\nspan mathematics, coding, vision, medicine, law, psychology and more, without\nneeding any special prompting. Moreover, in all of these tasks, GPT-4's\nperformance is strikingly close to human-level performance, and often vastly\nsurpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's\ncapabilities, we believe that it could reasonably be viewed as an early (yet\nstill incomplete) version of an artificial general intelligence (AGI) system.\nIn our exploration of GPT-4, we put special emphasis on discovering its\nlimitations, and we discuss the challenges ahead for advancing towards deeper\nand more comprehensive versions of AGI, including the possible need for\npursuing a new paradigm that moves beyond next-word prediction. We conclude\nwith reflections on societal influences of the recent technological leap and\nfuture research directions.\n",
                "链接": "https://arxiv.org/abs/2303.12712"
            },
            {
                "文章ID": "73599",
                "标题": "Can GPT-4 Perform Neural Architecture Search?",
                "作者": " Mingkai Zheng,  Xiu Su,  Shan You,  Fei Wang,  Chen Qian,  Chang Xu,  Samuel Albanie",
                "发布日期": "2023-08-03",
                "摘要": "  We investigate the potential of GPT-4~\\cite{gpt4} to perform Neural\nArchitecture Search (NAS) -- the task of designing effective neural\narchitectures. Our proposed approach, \\textbf{G}PT-4 \\textbf{E}nhanced\n\\textbf{N}eural arch\\textbf{I}tect\\textbf{U}re \\textbf{S}earch (GENIUS),\nleverages the generative capabilities of GPT-4 as a black-box optimiser to\nquickly navigate the architecture search space, pinpoint promising candidates,\nand iteratively refine these candidates to improve performance. We assess\nGENIUS across several benchmarks, comparing it with existing state-of-the-art\nNAS techniques to illustrate its effectiveness. Rather than targeting\nstate-of-the-art performance, our objective is to highlight GPT-4's potential\nto assist research on a challenging technical problem through a simple\nprompting scheme that requires relatively limited domain\nexpertise\\footnote{Code available at\n\\href{https://github.com/mingkai-zheng/GENIUS}{https://github.com/mingkai-zheng/GENIUS}.}.\nMore broadly, we believe our preliminary results point to future research that\nharnesses general purpose language models for diverse optimisation tasks. We\nalso highlight important limitations to our study, and note implications for AI\nsafety.\n",
                "链接": "https://arxiv.org/abs/2304.10970"
            },
            {
                "文章ID": "80356",
                "标题": "Is GPT-4 a Good Data Analyst?",
                "作者": " Liying Cheng,  Xingxuan Li,  Lidong Bing",
                "发布日期": "2023-10-24",
                "摘要": "  As large language models (LLMs) have demonstrated their powerful capabilities\nin plenty of domains and tasks, including context understanding, code\ngeneration, language generation, data storytelling, etc., many data analysts\nmay raise concerns if their jobs will be replaced by artificial intelligence\n(AI). This controversial topic has drawn great attention in public. However, we\nare still at a stage of divergent opinions without any definitive conclusion.\nMotivated by this, we raise the research question of \"is GPT-4 a good data\nanalyst?\" in this work and aim to answer it by conducting head-to-head\ncomparative studies. In detail, we regard GPT-4 as a data analyst to perform\nend-to-end data analysis with databases from a wide range of domains. We\npropose a framework to tackle the problems by carefully designing the prompts\nfor GPT-4 to conduct experiments. We also design several task-specific\nevaluation metrics to systematically compare the performance between several\nprofessional human data analysts and GPT-4. Experimental results show that\nGPT-4 can achieve comparable performance to humans. We also provide in-depth\ndiscussions about our results to shed light on further studies before reaching\nthe conclusion that GPT-4 can replace data analysts.\n",
                "链接": "https://arxiv.org/abs/2305.15038"
            },
            {
                "文章ID": "105208",
                "标题": "Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind\n  Aware GPT-4",
                "作者": " Jiaxian Guo,  Bo Yang,  Paul Yoo,  Bill Yuchen Lin,  Yusuke Iwasawa,  Yutaka Matsuo",
                "发布日期": "2023-10-09",
                "摘要": "  Unlike perfect information games, where all elements are known to every\nplayer, imperfect information games emulate the real-world complexities of\ndecision-making under uncertain or incomplete information. GPT-4, the recent\nbreakthrough in large language models (LLMs) trained on massive passive data,\nis notable for its knowledge retrieval and reasoning abilities. This paper\ndelves into the applicability of GPT-4's learned knowledge for imperfect\ninformation games. To achieve this, we introduce \\textbf{Suspicion-Agent}, an\ninnovative agent that leverages GPT-4's capabilities for performing in\nimperfect information games. With proper prompt engineering to achieve\ndifferent functions, Suspicion-Agent based on GPT-4 demonstrates remarkable\nadaptability across a range of imperfect information card games. Importantly,\nGPT-4 displays a strong high-order theory of mind (ToM) capacity, meaning it\ncan understand others and intentionally impact others' behavior. Leveraging\nthis, we design a planning strategy that enables GPT-4 to competently play\nagainst different opponents, adapting its gameplay style as needed, while\nrequiring only the game rules and descriptions of observations as input. In the\nexperiments, we qualitatively showcase the capabilities of Suspicion-Agent\nacross three different imperfect information games and then quantitatively\nevaluate it in Leduc Hold'em. The results show that Suspicion-Agent can\npotentially outperform traditional algorithms designed for imperfect\ninformation games, without any specialized training or examples. In order to\nencourage and foster deeper insights within the community, we make our\ngame-related data publicly available.\n",
                "链接": "https://arxiv.org/abs/2309.17277"
            },
            {
                "文章ID": "105803",
                "标题": "Graph Neural Architecture Search with GPT-4",
                "作者": " Haishuai Wang,  Yang Gao,  Xin Zheng,  Peng Zhang,  Hongyang Chen,  Jiajun Bu",
                "发布日期": "2023-10-04",
                "摘要": "  Graph Neural Architecture Search (GNAS) has shown promising results in\nautomatically designing graph neural networks. However, GNAS still requires\nintensive human labor with rich domain knowledge to design the search space and\nsearch strategy. In this paper, we integrate GPT-4 into GNAS and propose a new\nGPT-4 based Graph Neural Architecture Search method (GPT4GNAS for short). The\nbasic idea of our method is to design a new class of prompts for GPT-4 to guide\nGPT-4 toward the generative task of graph neural architectures. The prompts\nconsist of descriptions of the search space, search strategy, and search\nfeedback of GNAS. By iteratively running GPT-4 with the prompts, GPT4GNAS\ngenerates more accurate graph neural networks with fast convergence.\nExperimental results show that embedding GPT-4 into GNAS outperforms the\nstate-of-the-art GNAS methods.\n",
                "链接": "https://arxiv.org/abs/2310.01436"
            }
        ]
    },
    {
        "question": {
            "question": "使用LLM进行蛋白质结构/功能/性质预测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "120437",
                "标题": "Protein Language Model-Powered 3D Ligand Binding Site Prediction from\n  Protein Sequence",
                "作者": " Shuo Zhang,  Lei Xie",
                "发布日期": "2023-12-07",
                "摘要": "  Prediction of ligand binding sites of proteins is a fundamental and important\ntask for understanding the function of proteins and screening potential drugs.\nMost existing methods require experimentally determined protein holo-structures\nas input. However, such structures can be unavailable on novel or less-studied\nproteins. To tackle this limitation, we propose LaMPSite, which only takes\nprotein sequences and ligand molecular graphs as input for ligand binding site\npredictions. The protein sequences are used to retrieve residue-level\nembeddings and contact maps from the pre-trained ESM-2 protein language model.\nThe ligand molecular graphs are fed into a graph neural network to compute\natom-level embeddings. Then we compute and update the protein-ligand\ninteraction embedding based on the protein residue-level embeddings and ligand\natom-level embeddings, and the geometric constraints in the inferred protein\ncontact map and ligand distance map. A final pooling on protein-ligand\ninteraction embedding would indicate which residues belong to the binding\nsites. Without any 3D coordinate information of proteins, our proposed model\nachieves competitive performance compared to baseline methods that require 3D\nprotein structures when predicting binding sites. Given that less than 50% of\nproteins have reliable structure information in the current stage, LaMPSite\nwill provide new opportunities for drug discovery.\n",
                "链接": "https://arxiv.org/abs/2312.03016"
            },
            {
                "文章ID": "109510",
                "标题": "Protein 3D Graph Structure Learning for Robust Structure-based Protein\n  Property Prediction",
                "作者": " Yufei Huang,  Siyuan Li,  Jin Su,  Lirong Wu,  Odin Zhang,  Haitao Lin,  Jingqi Qi,  Zihan Liu,  Zhangyang Gao,  Yuyang Liu,  Jiangbin Zheng,  Stan. ZQ. Li",
                "发布日期": "2023-10-20",
                "摘要": "  Protein structure-based property prediction has emerged as a promising\napproach for various biological tasks, such as protein function prediction and\nsub-cellular location estimation. The existing methods highly rely on\nexperimental protein structure data and fail in scenarios where these data are\nunavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were\nutilized as alternatives. However, we observed that current practices, which\nsimply employ accurately predicted structures during inference, suffer from\nnotable degradation in prediction accuracy. While similar phenomena have been\nextensively studied in general fields (e.g., Computer Vision) as model\nrobustness, their impact on protein property prediction remains unexplored. In\nthis paper, we first investigate the reason behind the performance decrease\nwhen utilizing predicted structures, attributing it to the structure embedding\nbias from the perspective of structure representation learning. To study this\nproblem, we identify a Protein 3D Graph Structure Learning Problem for Robust\nProtein Property Prediction (PGSL-RP3), collect benchmark datasets, and present\na protein Structure embedding Alignment Optimization framework (SAO) to\nmitigate the problem of structure embedding bias between the predicted and\nexperimental protein structures. Extensive experiments have shown that our\nframework is model-agnostic and effective in improving the property prediction\nof both predicted structures and experimental structures. The benchmark\ndatasets and codes will be released to benefit the community.\n",
                "链接": "https://arxiv.org/abs/2310.11466"
            },
            {
                "文章ID": "51324",
                "标题": "Protein Language Models and Structure Prediction: Connection and\n  Progression",
                "作者": " Bozhen Hu,  Jun Xia,  Jiangbin Zheng,  Cheng Tan,  Yufei Huang,  Yongjie Xu,  Stan Z. Li",
                "发布日期": "2022-12-01",
                "摘要": "  The prediction of protein structures from sequences is an important task for\nfunction prediction, drug design, and related biological processes\nunderstanding. Recent advances have proved the power of language models (LMs)\nin processing the protein sequence databases, which inherit the advantages of\nattention networks and capture useful information in learning representations\nfor proteins. The past two years have witnessed remarkable success in tertiary\nprotein structure prediction (PSP), including evolution-based and\nsingle-sequence-based PSP. It seems that instead of using energy-based models\nand sampling procedures, protein language model (pLM)-based pipelines have\nemerged as mainstream paradigms in PSP. Despite the fruitful progress, the PSP\ncommunity needs a systematic and up-to-date survey to help bridge the gap\nbetween LMs in the natural language processing (NLP) and PSP domains and\nintroduce their methodologies, advancements and practical applications. To this\nend, in this paper, we first introduce the similarities between protein and\nhuman languages that allow LMs extended to pLMs, and applied to protein\ndatabases. Then, we systematically review recent advances in LMs and pLMs from\nthe perspectives of network architectures, pre-training strategies,\napplications, and commonly-used protein databases. Next, different types of\nmethods for PSP are discussed, particularly how the pLM-based architectures\nfunction in the process of protein folding. Finally, we identify challenges\nfaced by the PSP community and foresee promising research directions along with\nthe advances of pLMs. This survey aims to be a hands-on guide for researchers\nto understand PSP methods, develop pLMs and tackle challenging problems in this\nfield for practical purposes.\n",
                "链接": "https://arxiv.org/abs/2211.16742"
            },
            {
                "文章ID": "26245",
                "标题": "PSP: Million-level Protein Sequence Dataset for Protein Structure\n  Prediction",
                "作者": " Sirui Liu,  Jun Zhang,  Haotian Chu,  Min Wang,  Boxin Xue,  Ningxi Ni,  Jialiang Yu,  Yuhao Xie,  Zhenyu Chen,  Mengyun Chen,  Yuan Liu,  Piya Patra,  Fan Xu,  Jie Chen,  Zidong Wang,  Lijiang Yang,  Fan Yu,  Lei Chen,  Yi Qin Gao",
                "发布日期": "2022-06-27",
                "摘要": "  Proteins are essential component of human life and their structures are\nimportant for function and mechanism analysis. Recent work has shown the\npotential of AI-driven methods for protein structure prediction. However, the\ndevelopment of new models is restricted by the lack of dataset and benchmark\ntraining procedure. To the best of our knowledge, the existing open source\ndatasets are far less to satisfy the needs of modern protein sequence-structure\nrelated research. To solve this problem, we present the first million-level\nprotein structure prediction dataset with high coverage and diversity, named as\nPSP. This dataset consists of 570k true structure sequences (10TB) and 745k\ncomplementary distillation sequences (15TB). We provide in addition the\nbenchmark training procedure for SOTA protein structure prediction model on\nthis dataset. We validate the utility of this dataset for training by\nparticipating CAMEO contest in which our model won the first place. We hope our\nPSP dataset together with the training benchmark can enable a broader community\nof AI/biology researchers for AI-driven protein related research.\n",
                "链接": "https://arxiv.org/abs/2206.12240"
            },
            {
                "文章ID": "84482",
                "标题": "Multi-level Protein Representation Learning for Blind Mutational Effect\n  Prediction",
                "作者": " Yang Tan,  Bingxin Zhou,  Yuanhong Jiang,  Yu Guang Wang,  Liang Hong",
                "发布日期": "2023-06-09",
                "摘要": "  Directed evolution plays an indispensable role in protein engineering that\nrevises existing protein sequences to attain new or enhanced functions.\nAccurately predicting the effects of protein variants necessitates an in-depth\nunderstanding of protein structure and function. Although large self-supervised\nlanguage models have demonstrated remarkable performance in zero-shot inference\nusing only protein sequences, these models inherently do not interpret the\nspatial characteristics of protein structures, which are crucial for\ncomprehending protein folding stability and internal molecular interactions.\nThis paper introduces a novel pre-training framework that cascades sequential\nand geometric analyzers for protein primary and tertiary structures. It guides\nmutational directions toward desired traits by simulating natural selection on\nwild-type proteins and evaluates the effects of variants based on their fitness\nto perform the function. We assess the proposed approach using a public\ndatabase and two new databases for a variety of variant effect prediction\ntasks, which encompass a diverse set of proteins and assays from different\ntaxa. The prediction results achieve state-of-the-art performance over other\nzero-shot learning methods for both single-site mutations and deep mutations.\n",
                "链接": "https://arxiv.org/abs/2306.04899"
            },
            {
                "文章ID": "24433",
                "标题": "Exploring evolution-aware & -free protein language models as protein\n  function predictors",
                "作者": " Mingyang Hu,  Fajie Yuan,  Kevin K. Yang,  Fusong Ju,  Jin Su,  Hui Wang,  Fei Yang,  Qiuyang Ding",
                "发布日期": "2022-10-18",
                "摘要": "  Large-scale Protein Language Models (PLMs) have improved performance in\nprotein prediction tasks, ranging from 3D structure prediction to various\nfunction predictions. In particular, AlphaFold, a ground-breaking AI system,\ncould potentially reshape structural biology. However, the utility of the PLM\nmodule in AlphaFold, Evoformer, has not been explored beyond structure\nprediction. In this paper, we investigate the representation ability of three\npopular PLMs: ESM-1b (single sequence), MSA-Transformer (multiple sequence\nalignment) and Evoformer (structural), with a special focus on Evoformer.\nSpecifically, we aim to answer the following key questions: (i) Does the\nEvoformer trained as part of AlphaFold produce representations amenable to\npredicting protein function? (ii) If yes, can Evoformer replace ESM-1b and\nMSA-Transformer? (ii) How much do these PLMs rely on evolution-related protein\ndata? In this regard, are they complementary to each other? We compare these\nmodels by empirical study along with new insights and conclusions. All code and\ndatasets for reproducibility are available at\nhttps://github.com/elttaes/Revisiting-PLMs.\n",
                "链接": "https://arxiv.org/abs/2206.06583"
            },
            {
                "文章ID": "31301",
                "标题": "HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein\n  Language Model as an Alternative",
                "作者": " Xiaomin Fang,  Fan Wang,  Lihang Liu,  Jingzhou He,  Dayong Lin,  Yingfei Xiang,  Xiaonan Zhang,  Hua Wu,  Hui Li,  Le Song",
                "发布日期": "2023-10-19",
                "摘要": "  AI-based protein structure prediction pipelines, such as AlphaFold2, have\nachieved near-experimental accuracy. These advanced pipelines mainly rely on\nMultiple Sequence Alignments (MSAs) as inputs to learn the co-evolution\ninformation from the homologous sequences. Nonetheless, searching MSAs from\nprotein databases is time-consuming, usually taking dozens of minutes.\nConsequently, we attempt to explore the limits of fast protein structure\nprediction by using only primary sequences of proteins. HelixFold-Single is\nproposed to combine a large-scale protein language model with the superior\ngeometric learning capability of AlphaFold2. Our proposed method,\nHelixFold-Single, first pre-trains a large-scale protein language model (PLM)\nwith thousands of millions of primary sequences utilizing the self-supervised\nlearning paradigm, which will be used as an alternative to MSAs for learning\nthe co-evolution information. Then, by combining the pre-trained PLM and the\nessential components of AlphaFold2, we obtain an end-to-end differentiable\nmodel to predict the 3D coordinates of atoms from only the primary sequence.\nHelixFold-Single is validated in datasets CASP14 and CAMEO, achieving\ncompetitive accuracy with the MSA-based methods on the targets with large\nhomologous families. Furthermore, HelixFold-Single consumes much less time than\nthe mainstream pipelines for protein structure prediction, demonstrating its\npotential in tasks requiring many predictions. The code of HelixFold-Single is\navailable at\nhttps://github.com/PaddlePaddle/PaddleHelix/tree/dev/apps/protein_folding/helixfold-single,\nand we also provide stable web services on\nhttps://paddlehelix.baidu.com/app/drug/protein-single/forecast.\n",
                "链接": "https://arxiv.org/abs/2207.13921"
            },
            {
                "文章ID": "106475",
                "标题": "InstructProtein: Aligning Human and Protein Language via Knowledge\n  Instruction",
                "作者": " Zeyuan Wang,  Qiang Zhang,  Keyan Ding,  Ming Qin,  Xiang Zhuang,  Xiaotong Li,  Huajun Chen",
                "发布日期": "2023-10-06",
                "摘要": "  Large Language Models (LLMs) have revolutionized the field of natural\nlanguage processing, but they fall short in comprehending biological sequences\nsuch as proteins. To address this challenge, we propose InstructProtein, an\ninnovative LLM that possesses bidirectional generation capabilities in both\nhuman and protein languages: (i) taking a protein sequence as input to predict\nits textual function description and (ii) using natural language to prompt\nprotein sequence generation. To achieve this, we first pre-train an LLM on both\nprotein and natural language corpora, enabling it to comprehend individual\nlanguages. Then supervised instruction tuning is employed to facilitate the\nalignment of these two distinct languages. Herein, we introduce a knowledge\ngraph-based instruction generation framework to construct a high-quality\ninstruction dataset, addressing annotation imbalance and instruction deficits\nin existing protein-text corpus. In particular, the instructions inherit the\nstructural relations between proteins and function annotations in knowledge\ngraphs, which empowers our model to engage in the causal modeling of protein\nfunctions, akin to the chain-of-thought processes in natural languages.\nExtensive experiments on bidirectional protein-text generation tasks show that\nInstructProtein outperforms state-of-the-art LLMs by large margins. Moreover,\nInstructProtein serves as a pioneering step towards text-based protein function\nprediction and sequence design, effectively bridging the gap between protein\nand human language understanding.\n",
                "链接": "https://arxiv.org/abs/2310.03269"
            },
            {
                "文章ID": "106818",
                "标题": "Functional Geometry Guided Protein Sequence and Backbone Structure\n  Co-Design",
                "作者": " Zhenqiao Song,  Yunlong Zhao,  Wenxian Shi,  Yang Yang,  Lei Li",
                "发布日期": "2023-10-10",
                "摘要": "  Proteins are macromolecules responsible for essential functions in almost all\nliving organisms. Designing reasonable proteins with desired functions is\ncrucial. A protein's sequence and structure are strongly correlated and they\ntogether determine its function. In this paper, we propose NAEPro, a model to\njointly design Protein sequence and structure based on automatically detected\nfunctional sites. NAEPro is powered by an interleaving network of attention and\nequivariant layers, which can capture global correlation in a whole sequence\nand local influence from nearest amino acids in three dimensional (3D) space.\nSuch an architecture facilitates effective yet economic message passing at two\nlevels. We evaluate our model and several strong baselines on two protein\ndatasets, $\\beta$-lactamase and myoglobin. Experimental results show that our\nmodel consistently achieves the highest amino acid recovery rate, TM-score, and\nthe lowest RMSD among all competitors. These findings prove the capability of\nour model to design protein sequences and structures that closely resemble\ntheir natural counterparts. Furthermore, in-depth analysis further confirms our\nmodel's ability to generate highly effective proteins capable of binding to\ntheir target metallocofactors. We provide code, data and models in Github.\n",
                "链接": "https://arxiv.org/abs/2310.04343"
            },
            {
                "文章ID": "70802",
                "标题": "EigenFold: Generative Protein Structure Prediction with Diffusion Models",
                "作者": " Bowen Jing,  Ezra Erives,  Peter Pao-Huang,  Gabriele Corso,  Bonnie Berger,  Tommi Jaakkola",
                "发布日期": "2023-04-06",
                "摘要": "  Protein structure prediction has reached revolutionary levels of accuracy on\nsingle structures, yet distributional modeling paradigms are needed to capture\nthe conformational ensembles and flexibility that underlie biological function.\nTowards this goal, we develop EigenFold, a diffusion generative modeling\nframework for sampling a distribution of structures from a given protein\nsequence. We define a diffusion process that models the structure as a system\nof harmonic oscillators and which naturally induces a cascading-resolution\ngenerative process along the eigenmodes of the system. On recent CAMEO targets,\nEigenFold achieves a median TMScore of 0.84, while providing a more\ncomprehensive picture of model uncertainty via the ensemble of sampled\nstructures relative to existing methods. We then assess EigenFold's ability to\nmodel and predict conformational heterogeneity for fold-switching proteins and\nligand-induced conformational change. Code is available at\nhttps://github.com/bjing2016/EigenFold.\n",
                "链接": "https://arxiv.org/abs/2304.02198"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用BERT和RoBERTa进行多语言情感分析的最新论文，要求涵盖2022年以来的研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "52169",
                "标题": "Video Games as a Corpus: Sentiment Analysis using Fallout New Vegas\n  Dialog",
                "作者": " Mika Hämäläinen,  Khalid Alnajjar,  Thierry Poibeau",
                "发布日期": "2022-12-06",
                "摘要": "  We present a method for extracting a multilingual sentiment annotated dialog\ndata set from Fallout New Vegas. The game developers have preannotated every\nline of dialog in the game in one of the 8 different sentiments: \\textit{anger,\ndisgust, fear, happy, neutral, pained, sad } and \\textit{surprised}. The game\nhas been translated into English, Spanish, German, French and Italian. We\nconduct experiments on multilingual, multilabel sentiment analysis on the\nextracted data set using multilingual BERT, XLMRoBERTa and language specific\nBERT models. In our experiments, multilingual BERT outperformed XLMRoBERTa for\nmost of the languages, also language specific models were slightly better than\nmultilingual BERT for most of the languages. The best overall accuracy was 54\\%\nand it was achieved by using multilingual BERT on Spanish data. The extracted\ndata set presents a challenging task for sentiment analysis. We have released\nthe data, including the testing and training splits, openly on Zenodo. The data\nset has been shuffled for copyright reasons.\n",
                "链接": "https://arxiv.org/abs/2212.02168"
            },
            {
                "文章ID": "31048",
                "标题": "Enhancing Collaborative Filtering Recommender with Prompt-Based\n  Sentiment Analysis",
                "作者": " Elliot Dang,  Zheyuan Hu,  Tong Li",
                "发布日期": "2022-07-27",
                "摘要": "  Collaborative Filtering(CF) recommender is a crucial application in the\nonline market and ecommerce. However, CF recommender has been proven to suffer\nfrom persistent problems related to sparsity of the user rating that will\nfurther lead to a cold-start issue. Existing methods address the data sparsity\nissue by applying token-level sentiment analysis that translate text review\ninto sentiment scores as a complement of the user rating. In this paper, we\nattempt to optimize the sentiment analysis with advanced NLP models including\nBERT and RoBERTa, and experiment on whether the CF recommender has been further\nenhanced. We build the recommenders on the Amazon US Reviews dataset, and tune\nthe pretrained BERT and RoBERTa with the traditional fine-tuned paradigm as\nwell as the new prompt-based learning paradigm. Experimental result shows that\nthe recommender enhanced with the sentiment ratings predicted by the fine-tuned\nRoBERTa has the best performance, and achieved 30.7% overall gain by comparing\nMAP, NDCG and precision at K to the baseline recommender. Prompt-based learning\nparadigm, although superior to traditional fine-tune paradigm in pure sentiment\nanalysis, fail to further improve the CF recommender.\n",
                "链接": "https://arxiv.org/abs/2207.12883"
            },
            {
                "文章ID": "82977",
                "标题": "UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of\n  Multilingual BERT for Low-resource Sentiment Analysis",
                "作者": " Dou Hu,  Lingwei Wei,  Yaxin Liu,  Wei Zhou,  Songlin Hu",
                "发布日期": "2023-06-05",
                "摘要": "  This paper describes our system designed for SemEval-2023 Task 12: Sentiment\nanalysis for African languages. The challenge faced by this task is the\nscarcity of labeled data and linguistic resources in low-resource settings. To\nalleviate these, we propose a generalized multilingual system SACL-XLMR for\nsentiment analysis on low-resource languages. Specifically, we design a\nlexicon-based multilingual BERT to facilitate language adaptation and\nsentiment-aware representation learning. Besides, we apply a supervised\nadversarial contrastive learning technique to learn sentiment-spread structured\nrepresentations and enhance model generalization. Our system achieved\ncompetitive results, largely outperforming baselines on both multilingual and\nzero-shot sentiment classification subtasks. Notably, the system obtained the\n1st rank on the zero-shot classification subtask in the official ranking.\nExtensive experiments demonstrate the effectiveness of our system.\n",
                "链接": "https://arxiv.org/abs/2306.01093"
            },
            {
                "文章ID": "114320",
                "标题": "Modelling Sentiment Analysis: LLMs and data augmentation techniques",
                "作者": " Guillem Senabre Prades",
                "发布日期": "2023-11-08",
                "摘要": "  This paper provides different approaches for a binary sentiment\nclassification on a small training dataset. LLMs that provided state-of-the-art\nresults in sentiment analysis and similar domains are being used, such as BERT,\nRoBERTa and XLNet.\n",
                "链接": "https://arxiv.org/abs/2311.04139"
            },
            {
                "文章ID": "74465",
                "标题": "HausaNLP at SemEval-2023 Task 12: Leveraging African Low Resource\n  TweetData for Sentiment Analysis",
                "作者": " Saheed Abdullahi Salahudeen,  Falalu Ibrahim Lawan,  Ahmad Mustapha Wali,  Amina Abubakar Imam,  Aliyu Rabiu Shuaibu,  Aliyu Yusuf,  Nur Bala Rabiu,  Musa Bello,  Shamsuddeen Umaru Adamu,  Saminu Mohammad Aliyu,  Murja Sani Gadanya,  Sanah Abdullahi Muaz,  Mahmoud Said Ahmad,  Abdulkadir Abdullahi,  Abdulmalik Yusuf Jamoh",
                "发布日期": "2023-04-27",
                "摘要": "  We present the findings of SemEval-2023 Task 12, a shared task on sentiment\nanalysis for low-resource African languages using Twitter dataset. The task\nfeatured three subtasks; subtask A is monolingual sentiment classification with\n12 tracks which are all monolingual languages, subtask B is multilingual\nsentiment classification using the tracks in subtask A and subtask C is a\nzero-shot sentiment classification. We present the results and findings of\nsubtask A, subtask B and subtask C. We also release the code on github. Our\ngoal is to leverage low-resource tweet data using pre-trained Afro-xlmr-large,\nAfriBERTa-Large, Bert-base-arabic-camelbert-da-sentiment (Arabic-camelbert),\nMultilingual-BERT (mBERT) and BERT models for sentiment analysis of 14 African\nlanguages. The datasets for these subtasks consists of a gold standard\nmulti-class labeled Twitter datasets from these languages. Our results\ndemonstrate that Afro-xlmr-large model performed better compared to the other\nmodels in most of the languages datasets. Similarly, Nigerian languages: Hausa,\nIgbo, and Yoruba achieved better performance compared to other languages and\nthis can be attributed to the higher volume of data present in the languages.\n",
                "链接": "https://arxiv.org/abs/2304.13634"
            },
            {
                "文章ID": "87606",
                "标题": "L3Cube-MahaSent-MD: A Multi-domain Marathi Sentiment Analysis Dataset\n  and Transformer Models",
                "作者": " Aabha Pingle,  Aditya Vyawahare,  Isha Joshi,  Rahul Tangsali,  Raviraj Joshi",
                "发布日期": "2023-06-27",
                "摘要": "  The exploration of sentiment analysis in low-resource languages, such as\nMarathi, has been limited due to the availability of suitable datasets. In this\nwork, we present L3Cube-MahaSent-MD, a multi-domain Marathi sentiment analysis\ndataset, with four different domains - movie reviews, general tweets, TV show\nsubtitles, and political tweets. The dataset consists of around 60,000 manually\ntagged samples covering 3 distinct sentiments - positive, negative, and\nneutral. We create a sub-dataset for each domain comprising 15k samples. The\nMahaSent-MD is the first comprehensive multi-domain sentiment analysis dataset\nwithin the Indic sentiment landscape. We fine-tune different monolingual and\nmultilingual BERT models on these datasets and report the best accuracy with\nthe MahaBERT model. We also present an extensive in-domain and cross-domain\nanalysis thus highlighting the need for low-resource multi-domain datasets. The\ndata and models are available at https://github.com/l3cube-pune/MarathiNLP .\n",
                "链接": "https://arxiv.org/abs/2306.13888"
            },
            {
                "文章ID": "15513",
                "标题": "Mono vs Multilingual BERT for Hate Speech Detection and Text\n  Classification: A Case Study in Marathi",
                "作者": " Abhishek Velankar,  Hrushikesh Patil,  Raviraj Joshi",
                "发布日期": "2022-11-15",
                "摘要": "  Transformers are the most eminent architectures used for a vast range of\nNatural Language Processing tasks. These models are pre-trained over a large\ntext corpus and are meant to serve state-of-the-art results over tasks like\ntext classification. In this work, we conduct a comparative study between\nmonolingual and multilingual BERT models. We focus on the Marathi language and\nevaluate the models on the datasets for hate speech detection, sentiment\nanalysis and simple text classification in Marathi. We use standard\nmultilingual models such as mBERT, indicBERT and xlm-RoBERTa and compare with\nMahaBERT, MahaALBERT and MahaRoBERTa, the monolingual models for Marathi. We\nfurther show that Marathi monolingual models outperform the multilingual BERT\nvariants on five different downstream fine-tuning experiments. We also evaluate\nsentence embeddings from these models by freezing the BERT encoder layers. We\nshow that monolingual MahaBERT based models provide rich representations as\ncompared to sentence embeddings from multi-lingual counterparts. However, we\nobserve that these embeddings are not generic enough and do not work well on\nout of domain social media datasets. We consider two Marathi hate speech\ndatasets L3Cube-MahaHate, HASOC-2021, a Marathi sentiment classification\ndataset L3Cube-MahaSent, and Marathi Headline, Articles classification\ndatasets.\n",
                "链接": "https://arxiv.org/abs/2204.08669"
            },
            {
                "文章ID": "78993",
                "标题": "SEntFiN 1.0: Entity-Aware Sentiment Analysis for Financial News",
                "作者": " Ankur Sinha,  Satishwar Kedas,  Rishu Kumar,  Pekka Malo",
                "发布日期": "2023-05-23",
                "摘要": "  Fine-grained financial sentiment analysis on news headlines is a challenging\ntask requiring human-annotated datasets to achieve high performance. Limited\nstudies have tried to address the sentiment extraction task in a setting where\nmultiple entities are present in a news headline. In an effort to further\nresearch in this area, we make publicly available SEntFiN 1.0, a\nhuman-annotated dataset of 10,753 news headlines with entity-sentiment\nannotations, of which 2,847 headlines contain multiple entities, often with\nconflicting sentiments. We augment our dataset with a database of over 1,000\nfinancial entities and their various representations in news media amounting to\nover 5,000 phrases. We propose a framework that enables the extraction of\nentity-relevant sentiments using a feature-based approach rather than an\nexpression-based approach. For sentiment extraction, we utilize 12 different\nlearning schemes utilizing lexicon-based and pre-trained sentence\nrepresentations and five classification approaches. Our experiments indicate\nthat lexicon-based n-gram ensembles are above par with pre-trained word\nembedding schemes such as GloVe. Overall, RoBERTa and finBERT (domain-specific\nBERT) achieve the highest average accuracy of 94.29% and F1-score of 93.27%.\nFurther, using over 210,000 entity-sentiment predictions, we validate the\neconomic effect of sentiments on aggregate market movements over a long\nduration.\n",
                "链接": "https://arxiv.org/abs/2305.12257"
            },
            {
                "文章ID": "85580",
                "标题": "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted\n  Sentiment Classification Benchmark",
                "作者": " Łukasz Augustyniak,  Szymon Woźniak,  Marcin Gruza,  Piotr Gramacki,  Krzysztof Rajda,  Mikołaj Morzy,  Tomasz Kajdanowicz",
                "发布日期": "2023-06-14",
                "摘要": "  Despite impressive advancements in multilingual corpora collection and model\ntraining, developing large-scale deployments of multilingual models still\npresents a significant challenge. This is particularly true for language tasks\nthat are culture-dependent. One such example is the area of multilingual\nsentiment analysis, where affective markers can be subtle and deeply ensconced\nin culture. This work presents the most extensive open massively multilingual\ncorpus of datasets for training sentiment models. The corpus consists of 79\nmanually selected datasets from over 350 datasets reported in the scientific\nliterature based on strict quality criteria. The corpus covers 27 languages\nrepresenting 6 language families. Datasets can be queried using several\nlinguistic and functional features. In addition, we present a multi-faceted\nsentiment classification benchmark summarizing hundreds of experiments\nconducted on different base models, training objectives, dataset collections,\nand fine-tuning strategies.\n",
                "链接": "https://arxiv.org/abs/2306.07902"
            },
            {
                "文章ID": "14369",
                "标题": "Assessment of Massively Multilingual Sentiment Classifiers",
                "作者": " Krzysztof Rajda,  Łukasz Augustyniak,  Piotr Gramacki,  Marcin Gruza,  Szymon Woźniak,  Tomasz Kajdanowicz",
                "发布日期": "2022-04-12",
                "摘要": "  Models are increasing in size and complexity in the hunt for SOTA. But what\nif those 2\\% increase in performance does not make a difference in a production\nuse case? Maybe benefits from a smaller, faster model outweigh those slight\nperformance gains. Also, equally good performance across languages in\nmultilingual tasks is more important than SOTA results on a single one. We\npresent the biggest, unified, multilingual collection of sentiment analysis\ndatasets. We use these to assess 11 models and 80 high-quality sentiment\ndatasets (out of 342 raw datasets collected) in 27 languages and included\nresults on the internally annotated datasets. We deeply evaluate multiple\nsetups, including fine-tuning transformer-based models for measuring\nperformance. We compare results in numerous dimensions addressing the imbalance\nin both languages coverage and dataset sizes. Finally, we present some best\npractices for working with such a massive collection of datasets and models\nfrom a multilingual perspective.\n",
                "链接": "https://arxiv.org/abs/2204.04937"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找一下2018年以后使用强化学习做机器翻译任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "29736",
                "标题": "MAD for Robust Reinforcement Learning in Machine Translation",
                "作者": " Domenic Donato,  Lei Yu,  Wang Ling,  Chris Dyer",
                "发布日期": "2022-07-19",
                "摘要": "  We introduce a new distributed policy gradient algorithm and show that it\noutperforms existing reward-aware training procedures such as REINFORCE,\nminimum risk training (MRT) and proximal policy optimization (PPO) in terms of\ntraining stability and generalization performance when optimizing machine\ntranslation models. Our algorithm, which we call MAD (on account of using the\nmean absolute deviation in the importance weighting calculation), has\ndistributed data generators sampling multiple candidates per source sentence on\nworker nodes, while a central learner updates the policy. MAD depends crucially\non two variance reduction strategies: (1) a conditional reward normalization\nmethod that ensures each source sentence has both positive and negative reward\ntranslation examples and (2) a new robust importance weighting scheme that acts\nas a conditional entropy regularizer. Experiments on a variety of translation\ntasks show that policies learned using the MAD algorithm perform very well when\nusing both greedy decoding and beam search, and that the learned policies are\nsensitive to the specific reward used during training.\n",
                "链接": "https://arxiv.org/abs/2207.08583"
            },
            {
                "文章ID": "40957",
                "标题": "Reinforcement Learning with Large Action Spaces for Neural Machine\n  Translation",
                "作者": " Asaf Yehudai,  Leshem Choshen,  Lior Fox,  Omri Abend",
                "发布日期": "2022-10-07",
                "摘要": "  Applying Reinforcement learning (RL) following maximum likelihood estimation\n(MLE) pre-training is a versatile method for enhancing neural machine\ntranslation (NMT) performance. However, recent work has argued that the gains\nproduced by RL for NMT are mostly due to promoting tokens that have already\nreceived a fairly high probability in pre-training. We hypothesize that the\nlarge action space is a main obstacle to RL's effectiveness in MT, and conduct\ntwo sets of experiments that lend support to our hypothesis. First, we find\nthat reducing the size of the vocabulary improves RL's effectiveness. Second,\nwe find that effectively reducing the dimension of the action space without\nchanging the vocabulary also yields notable improvement as evaluated by BLEU,\nsemantic similarity, and human evaluation. Indeed, by initializing the\nnetwork's final fully connected layer (that maps the network's internal\ndimension to the vocabulary dimension), with a layer that generalizes over\nsimilar actions, we obtain a substantial improvement in RL performance: 1.5\nBLEU points on average.\n",
                "链接": "https://arxiv.org/abs/2210.03053"
            },
            {
                "文章ID": "79608",
                "标题": "Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine\n  Translation",
                "作者": " Jiayi Wang,  Ke Wang,  Yuqi Zhang,  Yu Zhao,  Pontus Stenetorp",
                "发布日期": "2023-05-24",
                "摘要": "  Non-parametric, k-nearest-neighbor algorithms have recently made inroads to\nassist generative models such as language models and machine translation\ndecoders. We explore whether such non-parametric models can improve machine\ntranslation models at the fine-tuning stage by incorporating statistics from\nthe kNN predictions to inform the gradient updates for a baseline translation\nmodel. There are multiple methods which could be used to incorporate kNN\nstatistics and we investigate gradient scaling by a gating mechanism, the kNN's\nground truth probability, and reinforcement learning. For four standard\nin-domain machine translation datasets, compared with classic fine-tuning, we\nreport consistent improvements of all of the three methods by as much as 1.45\nBLEU and 1.28 BLEU for German-English and English-German translations\nrespectively. Through qualitative analysis, we found particular improvements\nwhen it comes to translating grammatical relations or function words, which\nresults in increased fluency of our model.\n",
                "链接": "https://arxiv.org/abs/2305.13648"
            },
            {
                "文章ID": "55838",
                "标题": "Active Learning for Neural Machine Translation",
                "作者": " Neeraj Vashistha,  Kriti Singh,  Ramakant Shakya",
                "发布日期": "2023-01-03",
                "摘要": "  The machine translation mechanism translates texts automatically between\ndifferent natural languages, and Neural Machine Translation (NMT) has gained\nattention for its rational context analysis and fluent translation accuracy.\nHowever, processing low-resource languages that lack relevant training\nattributes like supervised data is a current challenge for Natural Language\nProcessing (NLP). We incorporated a technique known Active Learning with the\nNMT toolkit Joey NMT to reach sufficient accuracy and robust predictions of\nlow-resource language translation. With active learning, a semi-supervised\nmachine learning strategy, the training algorithm determines which unlabeled\ndata would be the most beneficial for obtaining labels using selected query\ntechniques. We implemented two model-driven acquisition functions for selecting\nthe samples to be validated. This work uses transformer-based NMT systems;\nbaseline model (BM), fully trained model (FTM) , active learning least\nconfidence based model (ALLCM), and active learning margin sampling based model\n(ALMSM) when translating English to Hindi. The Bilingual Evaluation Understudy\n(BLEU) metric has been used to evaluate system results. The BLEU scores of BM,\nFTM, ALLCM and ALMSM systems are 16.26, 22.56 , 24.54, and 24.20, respectively.\nThe findings in this paper demonstrate that active learning techniques helps\nthe model to converge early and improve the overall quality of the translation\nsystem.\n",
                "链接": "https://arxiv.org/abs/2301.00688"
            },
            {
                "文章ID": "10776",
                "标题": "Mitigating Gender Bias in Machine Translation through Adversarial\n  Learning",
                "作者": " Eve Fleisig,  Christiane Fellbaum",
                "发布日期": "2022-03-22",
                "摘要": "  Machine translation and other NLP systems often contain significant biases\nregarding sensitive attributes, such as gender or race, that worsen system\nperformance and perpetuate harmful stereotypes. Recent preliminary research\nsuggests that adversarial learning can be used as part of a model-agnostic bias\nmitigation method that requires no data modifications. However, adapting this\nstrategy for machine translation and other modern NLP domains requires (1)\nrestructuring training objectives in the context of fine-tuning pretrained\nlarge language models and (2) developing measures for gender or other protected\nvariables for tasks in which these attributes must be deduced from the data\nitself.\n  We present an adversarial learning framework that addresses these challenges\nto mitigate gender bias in seq2seq machine translation. Our framework improves\nthe disparity in translation quality for sentences with male vs. female\nentities by 86% for English-German translation and 91% for English-French\ntranslation, with minimal effect on translation quality. The results suggest\nthat adversarial learning is a promising technique for mitigating gender bias\nin machine translation.\n",
                "链接": "https://arxiv.org/abs/2203.10675"
            },
            {
                "文章ID": "110267",
                "标题": "Simultaneous Machine Translation with Tailored Reference",
                "作者": " Shoutao Guo,  Shaolei Zhang,  Yang Feng",
                "发布日期": "2023-10-27",
                "摘要": "  Simultaneous machine translation (SiMT) generates translation while reading\nthe whole source sentence. However, existing SiMT models are typically trained\nusing the same reference disregarding the varying amounts of available source\ninformation at different latency. Training the model with ground-truth at low\nlatency may introduce forced anticipations, whereas utilizing reference\nconsistent with the source word order at high latency results in performance\ndegradation. Consequently, it is crucial to train the SiMT model with\nappropriate reference that avoids forced anticipations during training while\nmaintaining high quality. In this paper, we propose a novel method that\nprovides tailored reference for the SiMT models trained at different latency by\nrephrasing the ground-truth. Specifically, we introduce the tailor, induced by\nreinforcement learning, to modify ground-truth to the tailored reference. The\nSiMT model is trained with the tailored reference and jointly optimized with\nthe tailor to enhance performance. Importantly, our method is applicable to a\nwide range of current SiMT approaches. Experiments on three translation tasks\ndemonstrate that our method achieves state-of-the-art performance in both fixed\nand adaptive policies.\n",
                "链接": "https://arxiv.org/abs/2310.13588"
            },
            {
                "文章ID": "112036",
                "标题": "A Review of Reinforcement Learning for Natural Language Processing, and\n  Applications in Healthcare",
                "作者": " Ying Liu,  Haozhu Wang,  Huixue Zhou,  Mingchen Li,  Yu Hou,  Sicheng Zhou,  Fang Wang,  Rama Hoetzlein,  Rui Zhang",
                "发布日期": "2023-10-31",
                "摘要": "  Reinforcement learning (RL) has emerged as a powerful approach for tackling\ncomplex medical decision-making problems such as treatment planning,\npersonalized medicine, and optimizing the scheduling of surgeries and\nappointments. It has gained significant attention in the field of Natural\nLanguage Processing (NLP) due to its ability to learn optimal strategies for\ntasks such as dialogue systems, machine translation, and question-answering.\nThis paper presents a review of the RL techniques in NLP, highlighting key\nadvancements, challenges, and applications in healthcare. The review begins by\nvisualizing a roadmap of machine learning and its applications in healthcare.\nAnd then it explores the integration of RL with NLP tasks. We examined dialogue\nsystems where RL enables the learning of conversational strategies, RL-based\nmachine translation models, question-answering systems, text summarization, and\ninformation extraction. Additionally, ethical considerations and biases in\nRL-NLP systems are addressed.\n",
                "链接": "https://arxiv.org/abs/2310.18354"
            },
            {
                "文章ID": "107113",
                "标题": "Synslator: An Interactive Machine Translation Tool with Online Learning",
                "作者": " Jiayi Wang,  Ke Wang,  Fengming Zhou,  Chengyu Wang,  Zhiyong Fu,  Zeyu Feng,  Yu Zhao,  Yuqi Zhang",
                "发布日期": "2023-10-10",
                "摘要": "  Interactive machine translation (IMT) has emerged as a progression of the\ncomputer-aided translation paradigm, where the machine translation system and\nthe human translator collaborate to produce high-quality translations. This\npaper introduces Synslator, a user-friendly computer-aided translation (CAT)\ntool that not only supports IMT, but is adept at online learning with real-time\ntranslation memories. To accommodate various deployment environments for CAT\nservices, Synslator integrates two different neural translation models to\nhandle translation memories for online learning. Additionally, the system\nemploys a language model to enhance the fluency of translations in an\ninteractive mode. In evaluation, we have confirmed the effectiveness of online\nlearning through the translation models, and have observed a 13% increase in\npost-editing efficiency with the interactive functionalities of Synslator. A\ntutorial video is available at:https://youtu.be/K0vRsb2lTt8.\n",
                "链接": "https://arxiv.org/abs/2310.05025"
            },
            {
                "文章ID": "96953",
                "标题": "Reinforced Self-Training (ReST) for Language Modeling",
                "作者": " Caglar Gulcehre,  Tom Le Paine,  Srivatsan Srinivasan,  Ksenia Konyushkova,  Lotte Weerts,  Abhishek Sharma,  Aditya Siddhant,  Alex Ahern,  Miaosen Wang,  Chenjie Gu,  Wolfgang Macherey,  Arnaud Doucet,  Orhan Firat,  Nando de Freitas",
                "发布日期": "2023-08-22",
                "摘要": "  Reinforcement learning from human feedback (RLHF) can improve the quality of\nlarge language model's (LLM) outputs by aligning them with human preferences.\nWe propose a simple algorithm for aligning LLMs with human preferences inspired\nby growing batch reinforcement learning (RL), which we call Reinforced\nSelf-Training (ReST). Given an initial LLM policy, ReST produces a dataset by\ngenerating samples from the policy, which are then used to improve the LLM\npolicy using offline RL algorithms. ReST is more efficient than typical online\nRLHF methods because the training dataset is produced offline, which allows\ndata reuse. While ReST is a general approach applicable to all generative\nlearning settings, we focus on its application to machine translation. Our\nresults show that ReST can substantially improve translation quality, as\nmeasured by automated metrics and human evaluation on machine translation\nbenchmarks in a compute and sample-efficient manner.\n",
                "链接": "https://arxiv.org/abs/2308.08998"
            },
            {
                "文章ID": "6641",
                "标题": "An Overview on Machine Translation Evaluation",
                "作者": " Lifeng Han",
                "发布日期": "2022-02-23",
                "摘要": "  Since the 1950s, machine translation (MT) has become one of the important\ntasks of AI and development, and has experienced several different periods and\nstages of development, including rule-based methods, statistical methods, and\nrecently proposed neural network-based learning methods. Accompanying these\nstaged leaps is the evaluation research and development of MT, especially the\nimportant role of evaluation methods in statistical translation and neural\ntranslation research. The evaluation task of MT is not only to evaluate the\nquality of machine translation, but also to give timely feedback to machine\ntranslation researchers on the problems existing in machine translation itself,\nhow to improve and how to optimise. In some practical application fields, such\nas in the absence of reference translations, the quality estimation of machine\ntranslation plays an important role as an indicator to reveal the credibility\nof automatically translated target languages. This report mainly includes the\nfollowing contents: a brief history of machine translation evaluation (MTE),\nthe classification of research methods on MTE, and the the cutting-edge\nprogress, including human evaluation, automatic evaluation, and evaluation of\nevaluation methods (meta-evaluation). Manual evaluation and automatic\nevaluation include reference-translation based and reference-translation\nindependent participation; automatic evaluation methods include traditional\nn-gram string matching, models applying syntax and semantics, and deep learning\nmodels; evaluation of evaluation methods includes estimating the credibility of\nhuman evaluations, the reliability of the automatic evaluation, the reliability\nof the test set, etc. Advances in cutting-edge evaluation methods include\ntask-based evaluation, using pre-trained language models based on big data, and\nlightweight optimisation models using distillation techniques.\n",
                "链接": "https://arxiv.org/abs/2202.11027"
            }
        ]
    },
    {
        "question": {
            "question": "请找出使用Transformer模型并在大规模数据集上进行预训练的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "22225",
                "标题": "CogVideo: Large-scale Pretraining for Text-to-Video Generation via\n  Transformers",
                "作者": " Wenyi Hong,  Ming Ding,  Wendi Zheng,  Xinghan Liu,  Jie Tang",
                "发布日期": "2022-06-01",
                "摘要": "  Large-scale pretrained transformers have created milestones in text (GPT-3)\nand text-to-image (DALL-E and CogView) generation. Its application to video\ngeneration is still facing many challenges: The potential huge computation cost\nmakes the training from scratch unaffordable; The scarcity and weak relevance\nof text-video datasets hinder the model understanding complex movement\nsemantics. In this work, we present 9B-parameter transformer CogVideo, trained\nby inheriting a pretrained text-to-image model, CogView2. We also propose\nmulti-frame-rate hierarchical training strategy to better align text and video\nclips. As (probably) the first open-source large-scale pretrained text-to-video\nmodel, CogVideo outperforms all publicly available models at a large margin in\nmachine and human evaluations.\n",
                "链接": "https://arxiv.org/abs/2205.15868"
            },
            {
                "文章ID": "111531",
                "标题": "Transferring a molecular foundation model for polymer property\n  predictions",
                "作者": " Pei Zhang,  Logan Kearney,  Debsindhu Bhowmik,  Zachary Fox,  Amit K. Naskar,  John Gounley",
                "发布日期": "2023-10-27",
                "摘要": "  Transformer-based large language models have remarkable potential to\naccelerate design optimization for applications such as drug development and\nmaterials discovery. Self-supervised pretraining of transformer models requires\nlarge-scale datasets, which are often sparsely populated in topical areas such\nas polymer science. State-of-the-art approaches for polymers conduct data\naugmentation to generate additional samples but unavoidably incurs extra\ncomputational costs. In contrast, large-scale open-source datasets are\navailable for small molecules and provide a potential solution to data scarcity\nthrough transfer learning. In this work, we show that using transformers\npretrained on small molecules and fine-tuned on polymer properties achieve\ncomparable accuracy to those trained on augmented polymer datasets for a series\nof benchmark prediction tasks.\n",
                "链接": "https://arxiv.org/abs/2310.16958"
            },
            {
                "文章ID": "98088",
                "标题": "Local Distortion Aware Efficient Transformer Adaptation for Image\n  Quality Assessment",
                "作者": " Kangmin Xu,  Liang Liao,  Jing Xiao,  Chaofeng Chen,  Haoning Wu,  Qiong Yan,  Weisi Lin",
                "发布日期": "2023-08-24",
                "摘要": "  Image Quality Assessment (IQA) constitutes a fundamental task within the\nfield of computer vision, yet it remains an unresolved challenge, owing to the\nintricate distortion conditions, diverse image contents, and limited\navailability of data. Recently, the community has witnessed the emergence of\nnumerous large-scale pretrained foundation models, which greatly benefit from\ndramatically increased data and parameter capacities. However, it remains an\nopen problem whether the scaling law in high-level tasks is also applicable to\nIQA task which is closely related to low-level clues. In this paper, we\ndemonstrate that with proper injection of local distortion features, a larger\npretrained and fixed foundation model performs better in IQA tasks.\nSpecifically, for the lack of local distortion structure and inductive bias of\nvision transformer (ViT), alongside the large-scale pretrained ViT, we use\nanother pretrained convolution neural network (CNN), which is well known for\ncapturing the local structure, to extract multi-scale image features. Further,\nwe propose a local distortion extractor to obtain local distortion features\nfrom the pretrained CNN and a local distortion injector to inject the local\ndistortion features into ViT. By only training the extractor and injector, our\nmethod can benefit from the rich knowledge in the powerful foundation models\nand achieve state-of-the-art performance on popular IQA datasets, indicating\nthat IQA is not only a low-level problem but also benefits from stronger\nhigh-level features drawn from large-scale pretrained models.\n",
                "链接": "https://arxiv.org/abs/2308.12001"
            },
            {
                "文章ID": "112949",
                "标题": "Neuroformer: Multimodal and Multitask Generative Pretraining for Brain\n  Data",
                "作者": " Antonis Antoniades,  Yiyi Yu,  Joseph Canzano,  William Wang,  Spencer LaVere Smith",
                "发布日期": "2023-11-10",
                "摘要": "  State-of-the-art systems neuroscience experiments yield large-scale\nmultimodal data, and these data sets require new tools for analysis. Inspired\nby the success of large pretrained models in vision and language domains, we\nreframe the analysis of large-scale, cellular-resolution neuronal spiking data\ninto an autoregressive spatiotemporal generation problem. Neuroformer is a\nmultimodal, multitask generative pretrained transformer (GPT) model that is\nspecifically designed to handle the intricacies of data in systems\nneuroscience. It scales linearly with feature size, can process an arbitrary\nnumber of modalities, and is adaptable to downstream tasks, such as predicting\nbehavior. We first trained Neuroformer on simulated datasets, and found that it\nboth accurately predicted simulated neuronal circuit activity, and also\nintrinsically inferred the underlying neural circuit connectivity, including\ndirection. When pretrained to decode neural responses, the model predicted the\nbehavior of a mouse with only few-shot fine-tuning, suggesting that the model\nbegins learning how to do so directly from the neural representations\nthemselves, without any explicit supervision. We used an ablation study to show\nthat joint training on neuronal responses and behavior boosted performance,\nhighlighting the model's ability to associate behavioral and neural\nrepresentations in an unsupervised manner. These findings show that Neuroformer\ncan analyze neural datasets and their emergent properties, informing the\ndevelopment of models and hypotheses associated with the brain.\n",
                "链接": "https://arxiv.org/abs/2311.00136"
            },
            {
                "文章ID": "108446",
                "标题": "Transformers as Decision Makers: Provable In-Context Reinforcement\n  Learning via Supervised Pretraining",
                "作者": " Licong Lin,  Yu Bai,  Song Mei",
                "发布日期": "2023-10-13",
                "摘要": "  Large transformer models pretrained on offline reinforcement learning\ndatasets have demonstrated remarkable in-context reinforcement learning (ICRL)\ncapabilities, where they can make good decisions when prompted with interaction\ntrajectories from unseen environments. However, when and how transformers can\nbe trained to perform ICRL have not been theoretically well-understood. In\nparticular, it is unclear which reinforcement-learning algorithms transformers\ncan perform in context, and how distribution mismatch in offline training data\naffects the learned algorithms. This paper provides a theoretical framework\nthat analyzes supervised pretraining for ICRL. This includes two recently\nproposed training methods -- algorithm distillation and decision-pretrained\ntransformers. First, assuming model realizability, we prove the\nsupervised-pretrained transformer will imitate the conditional expectation of\nthe expert algorithm given the observed trajectory. The generalization error\nwill scale with model capacity and a distribution divergence factor between the\nexpert and offline algorithms. Second, we show transformers with ReLU attention\ncan efficiently approximate near-optimal online reinforcement learning\nalgorithms like LinUCB and Thompson sampling for stochastic linear bandits, and\nUCB-VI for tabular Markov decision processes. This provides the first\nquantitative analysis of the ICRL capabilities of transformers pretrained from\noffline trajectories.\n",
                "链接": "https://arxiv.org/abs/2310.08566"
            },
            {
                "文章ID": "30372",
                "标题": "TinyViT: Fast Pretraining Distillation for Small Vision Transformers",
                "作者": " Kan Wu,  Jinnian Zhang,  Houwen Peng,  Mengchen Liu,  Bin Xiao,  Jianlong Fu,  Lu Yuan",
                "发布日期": "2022-07-22",
                "摘要": "  Vision transformer (ViT) recently has drawn great attention in computer\nvision due to its remarkable model capability. However, most prevailing ViT\nmodels suffer from huge number of parameters, restricting their applicability\non devices with limited resources. To alleviate this issue, we propose TinyViT,\na new family of tiny and efficient small vision transformers pretrained on\nlarge-scale datasets with our proposed fast distillation framework. The central\nidea is to transfer knowledge from large pretrained models to small ones, while\nenabling small models to get the dividends of massive pretraining data. More\nspecifically, we apply distillation during pretraining for knowledge transfer.\nThe logits of large teacher models are sparsified and stored in disk in advance\nto save the memory cost and computation overheads. The tiny student\ntransformers are automatically scaled down from a large pretrained model with\ncomputation and parameter constraints. Comprehensive experiments demonstrate\nthe efficacy of TinyViT. It achieves a top-1 accuracy of 84.8% on ImageNet-1k\nwith only 21M parameters, being comparable to Swin-B pretrained on ImageNet-21k\nwhile using 4.2 times fewer parameters. Moreover, increasing image resolutions,\nTinyViT can reach 86.5% accuracy, being slightly better than Swin-L while using\nonly 11% parameters. Last but not the least, we demonstrate a good transfer\nability of TinyViT on various downstream tasks. Code and models are available\nat https://github.com/microsoft/Cream/tree/main/TinyViT.\n",
                "链接": "https://arxiv.org/abs/2207.10666"
            },
            {
                "文章ID": "20054",
                "标题": "Transformer with Memory Replay",
                "作者": " Rui Liu,  Barzan Mozafari",
                "发布日期": "2022-05-23",
                "摘要": "  Transformers achieve state-of-the-art performance for natural language\nprocessing tasks by pre-training on large-scale text corpora. They are\nextremely compute-intensive and have very high sample complexity. Memory replay\nis a mechanism that remembers and reuses past examples by saving to and\nreplaying from a memory buffer. It has been successfully used in reinforcement\nlearning and GANs due to better sample efficiency. In this paper, we propose\n\\emph{Transformer with Memory Replay} (TMR), which integrates memory replay\nwith transformer, making transformer more sample-efficient. Experiments on GLUE\nand SQuAD benchmark datasets show that Transformer with Memory Replay achieves\nat least $1\\%$ point increase compared to the baseline transformer model when\npretrained with the same number of examples. Further, by adopting a careful\ndesign that reduces the wall-clock time overhead of memory replay, we also\nempirically achieve a better runtime efficiency.\n",
                "链接": "https://arxiv.org/abs/2205.09869"
            },
            {
                "文章ID": "40929",
                "标题": "SynBench: Task-Agnostic Benchmarking of Pretrained Representations using\n  Synthetic Data",
                "作者": " Ching-Yun Ko,  Pin-Yu Chen,  Jeet Mohapatra,  Payel Das,  Luca Daniel",
                "发布日期": "2022-10-10",
                "摘要": "  Recent success in fine-tuning large models, that are pretrained on broad data\nat scale, on downstream tasks has led to a significant paradigm shift in deep\nlearning, from task-centric model design to task-agnostic representation\nlearning and task-specific fine-tuning. As the representations of pretrained\nmodels are used as a foundation for different downstream tasks, this paper\nproposes a new task-agnostic framework, \\textit{SynBench}, to measure the\nquality of pretrained representations using synthetic data. We set up a\nreference by a theoretically-derived robustness-accuracy tradeoff of the class\nconditional Gaussian mixture. Given a pretrained model, the representations of\ndata synthesized from the Gaussian mixture are used to compare with our\nreference to infer the quality. By comparing the ratio of area-under-curve\nbetween the raw data and their representations, SynBench offers a quantifiable\nscore for robustness-accuracy performance benchmarking. Our framework applies\nto a wide range of pretrained models taking continuous data inputs and is\nindependent of the downstream tasks and datasets. Evaluated with several\npretrained vision transformer models, the experimental results show that our\nSynBench score well matches the actual linear probing performance of the\npre-trained model when fine-tuned on downstream tasks. Moreover, our framework\ncan be used to inform the design of robust linear probing on pretrained\nrepresentations to mitigate the robustness-accuracy tradeoff in downstream\ntasks.\n",
                "链接": "https://arxiv.org/abs/2210.02989"
            },
            {
                "文章ID": "73117",
                "标题": "NetGPT: Generative Pretrained Transformer for Network Traffic",
                "作者": " Xuying Meng,  Chungang Lin,  Yequan Wang,  Yujun Zhang",
                "发布日期": "2023-05-18",
                "摘要": "  All data on the Internet are transferred by network traffic, thus accurately\nmodeling network traffic can help improve network services quality and protect\ndata privacy. Pretrained models for network traffic can utilize large-scale raw\ndata to learn the essential characteristics of network traffic, and generate\ndistinguishable results for input traffic without considering specific\ndownstream tasks. Effective pretrained models can significantly optimize the\ntraining efficiency and effectiveness of downstream tasks, such as application\nclassification, attack detection and traffic generation. Despite the great\nsuccess of pretraining in natural language processing, there is no work in the\nnetwork field. Considering the diverse demands and characteristics of network\ntraffic and network tasks, it is non-trivial to build a pretrained model for\nnetwork traffic and we face various challenges, especially the heterogeneous\nheaders and payloads in the multi-pattern network traffic and the different\ndependencies for contexts of diverse downstream network tasks.\n  To tackle these challenges, in this paper, we make the first attempt to\nprovide a generative pretrained model NetGPT for both traffic understanding and\ngeneration tasks. We propose the multi-pattern network traffic modeling to\nconstruct unified text inputs and support both traffic understanding and\ngeneration tasks. We further optimize the adaptation effect of the pretrained\nmodel to diversified tasks by shuffling header fields, segmenting packets in\nflows, and incorporating diverse task labels with prompts. With diverse traffic\ndatasets from encrypted software, DNS, private industrial protocols and\ncryptocurrency mining, expensive experiments demonstrate the effectiveness of\nour NetGPT in a range of traffic understanding and generation tasks on traffic\ndatasets, and outperform state-of-the-art baselines by a wide margin.\n",
                "链接": "https://arxiv.org/abs/2304.09513"
            },
            {
                "文章ID": "121119",
                "标题": "Adapting Vision Transformer for Efficient Change Detection",
                "作者": " Yang Zhao,  Yuxiang Zhang,  Yanni Dong,  Bo Du",
                "发布日期": "2023-12-11",
                "摘要": "  Most change detection models based on vision transformers currently follow a\n\"pretraining then fine-tuning\" strategy. This involves initializing the model\nweights using large scale classification datasets, which can be either natural\nimages or remote sensing images. However, fully tuning such a model requires\nsignificant time and resources. In this paper, we propose an efficient tuning\napproach that involves freezing the parameters of the pretrained image encoder\nand introducing additional training parameters. Through this approach, we have\nachieved competitive or even better results while maintaining extremely low\nresource consumption across six change detection benchmarks. For example,\ntraining time on LEVIR-CD, a change detection benchmark, is only half an hour\nwith 9 GB memory usage, which could be very convenient for most researchers.\nAdditionally, the decoupled tuning framework can be extended to any pretrained\nmodel for semantic change detection and multi temporal change detection as\nwell. We hope that our proposed approach will serve as a part of foundational\nmodel to inspire more unified training approaches on change detection in the\nfuture.\n",
                "链接": "https://arxiv.org/abs/2312.04869"
            }
        ]
    },
    {
        "question": {
            "question": "找一下使用强化学习做代码生成的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "59289",
                "标题": "Execution-based Code Generation using Deep Reinforcement Learning",
                "作者": " Parshin Shojaee,  Aneesh Jain,  Sindhu Tipirneni,  Chandan K. Reddy",
                "发布日期": "2023-07-21",
                "摘要": "  The utilization of programming language (PL) models, pre-trained on\nlarge-scale code corpora, as a means of automating software engineering\nprocesses has demonstrated considerable potential in streamlining various code\ngeneration tasks such as code completion, code translation, and program\nsynthesis. However, current approaches mainly rely on supervised fine-tuning\nobjectives borrowed from text generation, neglecting unique sequence-level\ncharacteristics of code, including but not limited to compilability as well as\nsyntactic and functional correctness. To address this limitation, we propose\nPPOCoder, a new framework for code generation that synergistically combines\npre-trained PL models with Proximal Policy Optimization (PPO) which is a widely\nused deep reinforcement learning technique. By utilizing non-differentiable\nfeedback from code execution and structure alignment, PPOCoder seamlessly\nintegrates external code-specific knowledge into the model optimization\nprocess. It's important to note that PPOCoder is a task-agnostic and\nmodel-agnostic framework that can be used across different code generation\ntasks and PLs. Extensive experiments on three code generation tasks demonstrate\nthe effectiveness of our proposed approach compared to SOTA methods, achieving\nsignificant improvements in compilation success rates and functional\ncorrectness across different PLs.\n",
                "链接": "https://arxiv.org/abs/2301.13816"
            },
            {
                "文章ID": "110290",
                "标题": "Automatic Unit Test Data Generation and Actor-Critic Reinforcement\n  Learning for Code Synthesis",
                "作者": " Philip John Gorinski,  Matthieu Zimmer,  Gerasimos Lampouras,  Derrick Goh Xin Deik,  Ignacio Iacobacci",
                "发布日期": "2023-10-23",
                "摘要": "  The advent of large pre-trained language models in the domain of Code\nSynthesis has shown remarkable performance on various benchmarks, treating the\nproblem of Code Generation in a fashion similar to Natural Language Generation,\ntrained with a Language Modelling (LM) objective. In addition, the property of\nprogramming language code being precisely evaluable with respect to its\nsemantics -- through the use of Unit Tests to check its functional correctness\n-- lends itself to using Reinforcement Learning (RL) as a further training\nparadigm. Previous work has shown that RL can be applied as such to improve\nmodels' coding capabilities; however, such RL-based methods rely on a reward\nsignal based on defined Unit Tests, which are much harder to obtain compared to\nthe huge crawled code datasets used in LM objectives. In this work, we present\na novel approach to automatically obtain data consisting of function signatures\nand associated Unit Tests, suitable for RL training of Code Synthesis models.\nWe also introduce a straightforward, simple yet effective Actor-Critic RL\ntraining scheme and show that it, in conjunction with automatically generated\ntraining data, leads to improvement of a pre-trained code language model's\nperformance by up to 9.9% improvement over the original underlying code\nsynthesis LM, and up to 4.3% over RL-based models trained with standard PPO or\nCodeRL.\n",
                "链接": "https://arxiv.org/abs/2310.13669"
            },
            {
                "文章ID": "27761",
                "标题": "CodeRL: Mastering Code Generation through Pretrained Models and Deep\n  Reinforcement Learning",
                "作者": " Hung Le,  Yue Wang,  Akhilesh Deepak Gotmare,  Silvio Savarese,  Steven C. H. Hoi",
                "发布日期": "2022-11-04",
                "摘要": "  Program synthesis or code generation aims to generate a program that\nsatisfies a problem specification. Recent approaches using large-scale\npretrained language models (LMs) have shown promising results, yet they have\nsome critical limitations. In particular, they often follow a standard\nsupervised fine-tuning procedure to train a code generation model only from the\npairs of natural-language problem descriptions and ground-truth programs. Such\nparadigm largely ignores some important but potentially useful signals in the\nproblem specification such as unit tests, which thus often results in poor\nperformance when solving complex unseen coding tasks. To address the\nlimitations, we propose \"CodeRL\", a new framework for program synthesis tasks\nthrough pretrained LMs and deep reinforcement learning (RL). Specifically,\nduring training, we treat the code-generating LM as an actor network, and\nintroduce a critic network that is trained to predict the functional\ncorrectness of generated programs and provide dense feedback signals to the\nactor. During inference, we introduce a new generation procedure with a\ncritical sampling strategy that allows a model to automatically regenerate\nprograms based on feedback from example unit tests and critic scores. For the\nmodel backbones, we extended the encoder-decoder architecture of CodeT5 with\nenhanced learning objectives, larger model sizes, and better pretraining data.\nOur method not only achieves new SOTA results on the challenging APPS\nbenchmark, but also shows strong zero-shot transfer capability with new SOTA\nresults on the simpler MBPP benchmark.\n",
                "链接": "https://arxiv.org/abs/2207.01780"
            },
            {
                "文章ID": "109858",
                "标题": "SDGym: Low-Code Reinforcement Learning Environments using System\n  Dynamics Models",
                "作者": " Emmanuel Klu,  Sameer Sethi,  DJ Passey, Jr Donald Martin",
                "发布日期": "2023-10-20",
                "摘要": "  Understanding the long-term impact of algorithmic interventions on society is\nvital to achieving responsible AI. Traditional evaluation strategies often fall\nshort due to the complex, adaptive and dynamic nature of society. While\nreinforcement learning (RL) can be a powerful approach for optimizing decisions\nin dynamic settings, the difficulty of realistic environment design remains a\nbarrier to building robust agents that perform well in practical settings. To\naddress this issue we tap into the field of system dynamics (SD) as a\ncomplementary method that incorporates collaborative simulation model\nspecification practices. We introduce SDGym, a low-code library built on the\nOpenAI Gym framework which enables the generation of custom RL environments\nbased on SD simulation models. Through a feasibility study we validate that\nwell specified, rich RL environments can be generated from preexisting SD\nmodels and a few lines of configuration code. We demonstrate the capabilities\nof the SDGym environment using an SD model of the electric vehicle adoption\nproblem. We compare two SD simulators, PySD and BPTK-Py for parity, and train a\nD4PG agent using the Acme framework to showcase learning and environment\ninteraction. Our preliminary findings underscore the dual potential of SD to\nimprove RL environment design and for RL to improve dynamic policy discovery\nwithin SD models. By open-sourcing SDGym, the intent is to galvanize further\nresearch and promote adoption across the SD and RL communities, thereby\ncatalyzing collaboration in this emerging interdisciplinary space.\n",
                "链接": "https://arxiv.org/abs/2310.12494"
            },
            {
                "文章ID": "106137",
                "标题": "Reinforcement Learning from Automatic Feedback for High-Quality Unit\n  Test Generation",
                "作者": " Benjamin Steenhoek,  Michele Tufano,  Neel Sundaresan,  Alexey Svyatkovskiy",
                "发布日期": "2023-10-05",
                "摘要": "  Software testing is a crucial aspect of software development, and the\ncreation of high-quality tests that adhere to best practices is essential for\neffective maintenance. Recently, Large Language Models (LLMs) have gained\npopularity for code generation, including the automated creation of test cases.\nHowever, these LLMs are often trained on vast amounts of publicly available\ncode, which may include test cases that do not adhere to best practices and may\neven contain test smells (anti-patterns). To address this issue, we propose a\nnovel technique called Reinforcement Learning from Static Quality Metrics\n(RLSQM). To begin, we analyze the anti-patterns generated by the LLM and show\nthat LLMs can generate undesirable test smells. Thus, we train specific reward\nmodels for each static quality metric, then utilize Proximal Policy\nOptimization (PPO) to train models for optimizing a single quality metric at a\ntime. Furthermore, we amalgamate these rewards into a unified reward model\naimed at capturing different best practices and quality aspects of tests. By\ncomparing RL-trained models with those trained using supervised learning, we\nprovide insights into how reliably utilize RL to improve test generation\nquality and into the effects of various training strategies. Our experimental\nresults demonstrate that the RL-optimized model consistently generated\nhigh-quality test cases compared to the base LLM, improving the model by up to\n21%, and successfully generates nearly 100% syntactically correct code. RLSQM\nalso outperformed GPT-4 on four out of seven metrics. This represents a\nsignificant step towards enhancing the overall efficiency and reliability of\nsoftware testing through Reinforcement Learning and static quality metrics. Our\ndata are available at this link: https://figshare.com/s/ded476c8d4c221222849.\n",
                "链接": "https://arxiv.org/abs/2310.02368"
            },
            {
                "文章ID": "9115",
                "标题": "Compilable Neural Code Generation with Compiler Feedback",
                "作者": " Xin Wang,  Yasheng Wang,  Yao Wan,  Fei Mi,  Yitong Li,  Pingyi Zhou,  Jin Liu,  Hao Wu,  Xin Jiang,  Qun Liu",
                "发布日期": "2022-03-11",
                "摘要": "  Automatically generating compilable programs with (or without) natural\nlanguage descriptions has always been a touchstone problem for computational\nlinguistics and automated software engineering. Existing deep-learning\napproaches model code generation as text generation, either constrained by\ngrammar structures in decoder, or driven by pre-trained language models on\nlarge-scale code corpus (e.g., CodeGPT, PLBART, and CodeT5). However, few of\nthem account for compilability of the generated programs. To improve\ncompilability of the generated programs, this paper proposes COMPCODER, a\nthree-stage pipeline utilizing compiler feedback for compilable code\ngeneration, including language model fine-tuning, compilability reinforcement,\nand compilability discrimination. Comprehensive experiments on two code\ngeneration tasks demonstrate the effectiveness of our proposed approach,\nimproving the success rate of compilation from 44.18 to 89.18 in code\ncompletion on average and from 70.3 to 96.2 in text-to-code generation,\nrespectively, when comparing with the state-of-the-art CodeGPT.\n",
                "链接": "https://arxiv.org/abs/2203.05132"
            },
            {
                "文章ID": "90123",
                "标题": "RLTF: Reinforcement Learning from Unit Test Feedback",
                "作者": " Jiate Liu,  Yiqin Zhu,  Kaiwen Xiao,  Qiang Fu,  Xiao Han,  Wei Yang,  Deheng Ye",
                "发布日期": "2023-11-14",
                "摘要": "  The goal of program synthesis, or code generation, is to generate executable\ncode based on given descriptions. Recently, there has been an increasing number\nof studies employing reinforcement learning (RL) to improve the performance of\nlarge language models (LLMs) for code. However, current representative works\neither rely solely on offline frameworks, limiting the exploration of new\nsample spaces, or fall short in the utilization of unit test signals, not\naccounting for specific error locations within the code. To address these\nissues, we propose RLTF, i.e., Reinforcement Learning from Unit Test Feedback,\na novel online RL framework with unit test feedback of multi-granularity for\nrefining code LLMs. Our approach generates data in real-time during training\nand simultaneously utilizes fine-grained feedback signals to guide the model\ntowards producing higher-quality code. Extensive experiments show that RLTF\nachieves state-of-the-art performance on the APPS and the MBPP benchmarks. Our\ncode is available at: https://github.com/Zyq-scut/RLTF.\n",
                "链接": "https://arxiv.org/abs/2307.04349"
            },
            {
                "文章ID": "23129",
                "标题": "A Deep Reinforcement Learning Framework For Column Generation",
                "作者": " Cheng Chi,  Amine Mohamed Aboussalah,  Elias B. Khalil,  Juyoung Wang,  Zoha Sherkat-Masoumi",
                "发布日期": "2023-01-16",
                "摘要": "  Column Generation (CG) is an iterative algorithm for solving linear programs\n(LPs) with an extremely large number of variables (columns). CG is the\nworkhorse for tackling large-scale \\textit{integer} linear programs, which rely\non CG to solve LP relaxations within a branch and price algorithm. Two\ncanonical applications are the Cutting Stock Problem (CSP) and Vehicle Routing\nProblem with Time Windows (VRPTW). In VRPTW, for example, each binary variable\nrepresents the decision to include or exclude a \\textit{route}, of which there\nare exponentially many; CG incrementally grows the subset of columns being\nused, ultimately converging to an optimal solution. We propose RLCG, the first\nReinforcement Learning (RL) approach for CG. Unlike typical column selection\nrules which myopically select a column based on local information at each\niteration, we treat CG as a sequential decision-making problem: the column\nselected in a given iteration affects subsequent column selections. This\nperspective lends itself to a Deep Reinforcement Learning approach that uses\nGraph Neural Networks (GNNs) to represent the variable-constraint structure in\nthe LP of interest. We perform an extensive set of experiments using the\npublicly available BPPLIB benchmark for CSP and Solomon benchmark for VRPTW.\nRLCG converges faster and reduces the number of CG iterations by 22.4\\% for CSP\nand 40.9\\% for VRPTW on average compared to a commonly used greedy policy. Our\ncode is available at\nhttps://github.com/chichengmessi/reinforcement-learning-for-column-generation.git.\n",
                "链接": "https://arxiv.org/abs/2206.02568"
            },
            {
                "文章ID": "81771",
                "标题": "Coarse-Tuning Models of Code with Reinforcement Learning Feedback",
                "作者": " Abhinav Jain,  Chima Adiole,  Swarat Chaudhuri,  Thomas Reps,  Chris Jermaine",
                "发布日期": "2023-12-27",
                "摘要": "  Large Language Models (LLMs) pre-trained on code have recently emerged as the\ndominant approach to program synthesis. However, these models are trained using\nnext-token prediction, which ignores the syntax and semantics of code. We\npropose RLCF, that further trains a pre-trained LLM via reinforcement learning,\nusing feedback from a grounding function that scores the quality of the code.\nThe grounding function uses (i) compiler-derived feedback on whether the code\nit generates passes a set of correctness checks; and (ii) feedback from a\ndifferent LLM that compares the generated code to a reference code. RLCF is\nmodel- and language-agnostic. We empirically evaluate it on the MBJP and MathQA\ntasks for Java. Our experiments show that RLCF raises the odds that an\nLLM-generated program compiles, is executable, and produces the right output on\ntests, often allowing LLMs to match the performance of 2x-8x larger LLMs.\n",
                "链接": "https://arxiv.org/abs/2305.18341"
            },
            {
                "文章ID": "93392",
                "标题": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking\n  Feedback",
                "作者": " Bo Shen,  Jiaxin Zhang,  Taihong Chen,  Daoguang Zan,  Bing Geng,  An Fu,  Muhan Zeng,  Ailun Yu,  Jichuan Ji,  Jingyang Zhao,  Yuenan Guo,  Qianxiang Wang",
                "发布日期": "2023-07-28",
                "摘要": "  Large Language Models for Code (Code LLM) are flourishing. New and powerful\nmodels are released on a weekly basis, demonstrating remarkable performance on\nthe code generation task. Various approaches have been proposed to boost the\ncode generation performance of pre-trained Code LLMs, such as supervised\nfine-tuning, instruction tuning, reinforcement learning, etc. In this paper, we\npropose a novel RRTF (Rank Responses to align Test&Teacher Feedback) framework,\nwhich can effectively and efficiently boost pre-trained large language models\nfor code generation. Under this framework, we present PanGu-Coder2, which\nachieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, through\nan extensive evaluation on CoderEval and LeetCode benchmarks, we show that\nPanGu-Coder2 consistently outperforms all previous Code LLMs.\n",
                "链接": "https://arxiv.org/abs/2307.14936"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下关于大模型使用工具的安全性的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "81272",
                "标题": "Large Language Models as Tool Makers",
                "作者": " Tianle Cai,  Xuezhi Wang,  Tengyu Ma,  Xinyun Chen,  Denny Zhou",
                "发布日期": "2023-05-29",
                "摘要": "  Recent research shows the potential of enhancing the problem-solving ability\nof large language models (LLMs) through the use of external tools. However,\nprior work along this line depends on the availability of existing tools. In\nthis work, we take an initial step towards removing this dependency by\nproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),\nwhere LLMs create their own reusable tools for problem-solving. Our approach\nconsists of two key phases: 1) tool making: an LLM acts as the tool maker that\ncrafts tools for given tasks, where a tool is implemented as a Python utility\nfunction. 2) tool using: an LLM acts as the tool user, which applies the tool\nbuilt by the tool maker for problem-solving. The tool user can be either the\nsame or a different LLM from the tool maker. Tool-making enables an LLM to\ncontinually generate tools that can be applied to different requests so that\nfuture requests can call the corresponding APIs when beneficial for solving the\ntasks. Furthermore, the division of labor among LLMs for tool-making and\ntool-using phases introduces the opportunity to achieve cost effectiveness\nwithout degrading the quality of generated tools and problem solutions. For\nexample, recognizing that tool-making demands more sophisticated capabilities\nthan tool-using, we can apply a powerful yet resource-intensive model as the\ntool maker, and a lightweight while cost-effective model as the tool user. We\nvalidate the effectiveness of our approach across a variety of complex\nreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and\nGPT-3.5 as the tool user, LATM can achieve performance that is on par with\nusing GPT-4 for both tool making and tool using, while the inference cost is\nsignificantly reduced.\n",
                "链接": "https://arxiv.org/abs/2305.17126"
            },
            {
                "文章ID": "80992",
                "标题": "On the Tool Manipulation Capability of Open-source Large Language Models",
                "作者": " Qiantong Xu,  Fenglu Hong,  Bo Li,  Changran Hu,  Zhengyu Chen,  Jian Zhang",
                "发布日期": "2023-05-29",
                "摘要": "  Recent studies on software tool manipulation with large language models\n(LLMs) mostly rely on closed model APIs. The industrial adoption of these\nmodels is substantially constrained due to the security and robustness risks in\nexposing information to closed LLM API services. In this paper, we ask can we\nenhance open-source LLMs to be competitive to leading closed LLM APIs in tool\nmanipulation, with practical amount of human supervision. By analyzing common\ntool manipulation failures, we first demonstrate that open-source LLMs may\nrequire training with usage examples, in-context demonstration and generation\nstyle regulation to resolve failures. These insights motivate us to revisit\nclassical methods in LLM literature, and demonstrate that we can adapt them as\nmodel alignment with programmatic data generation, system prompts and\nin-context demonstration retrievers to enhance open-source LLMs for tool\nmanipulation. To evaluate these techniques, we create the ToolBench, a tool\nmanipulation benchmark consisting of diverse software tools for real-world\ntasks. We demonstrate that our techniques can boost leading open-source LLMs by\nup to 90% success rate, showing capabilities competitive to OpenAI GPT-4 in 4\nout of 8 ToolBench tasks. We show that such enhancement typically requires\nabout one developer day to curate data for each tool, rendering a recipe with\npractical amount of human supervision.\n",
                "链接": "https://arxiv.org/abs/2305.16504"
            },
            {
                "文章ID": "95072",
                "标题": "TPTU: Large Language Model-based AI Agents for Task Planning and Tool\n  Usage",
                "作者": " Jingqing Ruan,  Yihong Chen,  Bin Zhang,  Zhiwei Xu,  Tianpeng Bao,  Guoqing Du,  Shiwei Shi,  Hangyu Mao,  Ziyue Li,  Xingyu Zeng,  Rui Zhao",
                "发布日期": "2023-11-08",
                "摘要": "  With recent advancements in natural language processing, Large Language\nModels (LLMs) have emerged as powerful tools for various real-world\napplications. Despite their prowess, the intrinsic generative abilities of LLMs\nmay prove insufficient for handling complex tasks which necessitate a\ncombination of task planning and the usage of external tools. In this paper, we\nfirst propose a structured framework tailored for LLM-based AI Agents and\ndiscuss the crucial capabilities necessary for tackling intricate problems.\nWithin this framework, we design two distinct types of agents (i.e., one-step\nagent and sequential agent) to execute the inference process. Subsequently, we\ninstantiate the framework using various LLMs and evaluate their Task Planning\nand Tool Usage (TPTU) abilities on typical tasks. By highlighting key findings\nand challenges, our goal is to provide a helpful resource for researchers and\npractitioners to leverage the power of LLMs in their AI applications. Our study\nemphasizes the substantial potential of these models, while also identifying\nareas that need more investigation and improvement.\n",
                "链接": "https://arxiv.org/abs/2308.03427"
            },
            {
                "文章ID": "95257",
                "标题": "SimplyRetrieve: A Private and Lightweight Retrieval-Centric Generative\n  AI Tool",
                "作者": " Youyang Ng,  Daisuke Miyashita,  Yasuto Hoshi,  Yasuhiro Morioka,  Osamu Torii,  Tomoya Kodama,  Jun Deguchi",
                "发布日期": "2023-08-09",
                "摘要": "  Large Language Model (LLM) based Generative AI systems have seen significant\nprogress in recent years. Integrating a knowledge retrieval architecture allows\nfor seamless integration of private data into publicly available Generative AI\nsystems using pre-trained LLM without requiring additional model fine-tuning.\nMoreover, Retrieval-Centric Generation (RCG) approach, a promising future\nresearch direction that explicitly separates roles of LLMs and retrievers in\ncontext interpretation and knowledge memorization, potentially leads to more\nefficient implementation. SimplyRetrieve is an open-source tool with the goal\nof providing a localized, lightweight, and user-friendly interface to these\nsophisticated advancements to the machine learning community. SimplyRetrieve\nfeatures a GUI and API based RCG platform, assisted by a Private Knowledge Base\nConstructor and a Retrieval Tuning Module. By leveraging these capabilities,\nusers can explore the potential of RCG for improving generative AI performance\nwhile maintaining privacy standards. The tool is available at\nhttps://github.com/RCGAI/SimplyRetrieve with an MIT license.\n",
                "链接": "https://arxiv.org/abs/2308.03983"
            },
            {
                "文章ID": "94169",
                "标题": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language\n  Models",
                "作者": " Cheng-Yu Hsieh,  Si-An Chen,  Chun-Liang Li,  Yasuhisa Fujii,  Alexander Ratner,  Chen-Yu Lee,  Ranjay Krishna,  Tomas Pfister",
                "发布日期": "2023-08-02",
                "摘要": "  Today, large language models (LLMs) are taught to use new tools by providing\na few demonstrations of the tool's usage. Unfortunately, demonstrations are\nhard to acquire, and can result in undesirable biased usage if the wrong\ndemonstration is chosen. Even in the rare scenario that demonstrations are\nreadily available, there is no principled selection protocol to determine how\nmany and which ones to provide. As tasks grow more complex, the selection\nsearch grows combinatorially and invariably becomes intractable. Our work\nprovides an alternative to demonstrations: tool documentation. We advocate the\nuse of tool documentation, descriptions for the individual tool usage, over\ndemonstrations. We substantiate our claim through three main empirical findings\non 6 tasks across both vision and language modalities. First, on existing\nbenchmarks, zero-shot prompts with only tool documentation are sufficient for\neliciting proper tool usage, achieving performance on par with few-shot\nprompts. Second, on a newly collected realistic tool-use dataset with hundreds\nof available tool APIs, we show that tool documentation is significantly more\nvaluable than demonstrations, with zero-shot documentation significantly\noutperforming few-shot without documentation. Third, we highlight the benefits\nof tool documentations by tackling image generation and video tracking using\njust-released unseen state-of-the-art models as tools. Finally, we highlight\nthe possibility of using tool documentation to automatically enable new\napplications: by using nothing more than the documentation of GroundingDino,\nStable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the\njust-released Grounded-SAM and Track Anything models.\n",
                "链接": "https://arxiv.org/abs/2308.00675"
            },
            {
                "文章ID": "42954",
                "标题": "HUDD: A tool to debug DNNs for safety analysis",
                "作者": " Hazem Fahmy,  Fabrizio Pastore,  Lionel Briand",
                "发布日期": "2022-10-18",
                "摘要": "  We present HUDD, a tool that supports safety analysis practices for systems\nenabled by Deep Neural Networks (DNNs) by automatically identifying the root\ncauses for DNN errors and retraining the DNN. HUDD stands for Heatmap-based\nUnsupervised Debugging of DNNs, it automatically clusters error-inducing images\nwhose results are due to common subsets of DNN neurons. The intent is for the\ngenerated clusters to group error-inducing images having common\ncharacteristics, that is, having a common root cause. HUDD identifies root\ncauses by applying a clustering algorithm to matrices (i.e., heatmaps)\ncapturing the relevance of every DNN neuron on the DNN outcome. Also, HUDD\nretrains DNNs with images that are automatically selected based on their\nrelatedness to the identified image clusters. Our empirical evaluation with\nDNNs from the automotive domain have shown that HUDD automatically identifies\nall the distinct root causes of DNN errors, thus supporting safety analysis.\nAlso, our retraining approach has shown to be more effective at improving DNN\naccuracy than existing approaches. A demo video of HUDD is available at\nhttps://youtu.be/drjVakP7jdU.\n",
                "链接": "https://arxiv.org/abs/2210.08356"
            },
            {
                "文章ID": "80331",
                "标题": "LLMDet: A Third Party Large Language Models Generated Text Detection\n  Tool",
                "作者": " Kangxi Wu,  Liang Pang,  Huawei Shen,  Xueqi Cheng,  Tat-Seng Chua",
                "发布日期": "2023-11-06",
                "摘要": "  Generated texts from large language models (LLMs) are remarkably close to\nhigh-quality human-authored text, raising concerns about their potential misuse\nin spreading false information and academic misconduct. Consequently, there is\nan urgent need for a highly practical detection tool capable of accurately\nidentifying the source of a given text. However, existing detection tools\ntypically rely on access to LLMs and can only differentiate between\nmachine-generated and human-authored text, failing to meet the requirements of\nfine-grained tracing, intermediary judgment, and rapid detection. Therefore, we\npropose LLMDet, a model-specific, secure, efficient, and extendable detection\ntool, that can source text from specific LLMs, such as GPT-2, OPT, LLaMA, and\nothers. In LLMDet, we record the next-token probabilities of salient n-grams as\nfeatures to calculate proxy perplexity for each LLM. By jointly analyzing the\nproxy perplexities of LLMs, we can determine the source of the generated text.\nExperimental results show that LLMDet yields impressive detection performance\nwhile ensuring speed and security, achieving 98.54% precision and x5.0 faster\nfor recognizing human-authored text. Additionally, LLMDet can effortlessly\nextend its detection capabilities to a new open-source model. We will provide\nan open-source tool at https://github.com/TrustedLLM/LLMDet.\n",
                "链接": "https://arxiv.org/abs/2305.15004"
            },
            {
                "文章ID": "91489",
                "标题": "GEAR: Augmenting Language Models with Generalizable and Efficient Tool\n  Resolution",
                "作者": " Yining Lu,  Haoping Yu,  Daniel Khashabi",
                "发布日期": "2023-07-19",
                "摘要": "  Augmenting large language models (LLM) to use external tools enhances their\nperformance across a variety of tasks. However, prior works over-rely on\ntask-specific demonstration of tool use that limits their generalizability and\ncomputational cost due to making many calls to large-scale LLMs. We introduce\nGEAR, a computationally efficient query-tool grounding algorithm that is\ngeneralizable to various tasks that require tool use while not relying on\ntask-specific demonstrations. GEAR achieves better efficiency by delegating\ntool grounding and execution to small language models (SLM) and LLM,\nrespectively; while leveraging semantic and pattern-based evaluation at both\nquestion and answer levels for generalizable tool grounding. We evaluate GEAR\non 14 datasets across 6 downstream tasks, demonstrating its strong\ngeneralizability to novel tasks, tools and different SLMs. Despite offering\nmore efficiency, GEAR achieves higher precision in tool grounding compared to\nprior strategies using LLM prompting, thus improving downstream accuracy at a\nreduced computational cost. For example, we demonstrate that GEAR-augmented\nGPT-J and GPT-3 outperform counterpart tool-augmented baselines because of\nbetter tool use.\n",
                "链接": "https://arxiv.org/abs/2307.08775"
            },
            {
                "文章ID": "83744",
                "标题": "The Chai Platform's AI Safety Framework",
                "作者": " Xiaoding Lu,  Aleksey Korshuk,  Zongyi Liu,  William Beauchamp",
                "发布日期": "2023-06-06",
                "摘要": "  Chai empowers users to create and interact with customized chatbots, offering\nunique and engaging experiences. Despite the exciting prospects, the work\nrecognizes the inherent challenges of a commitment to modern safety standards.\nTherefore, this paper presents the integrated AI safety principles into Chai to\nprioritize user safety, data protection, and ethical technology use. The paper\nspecifically explores the multidimensional domain of AI safety research,\ndemonstrating its application in Chai's conversational chatbot platform. It\npresents Chai's AI safety principles, informed by well-established AI research\ncentres and adapted for chat AI. This work proposes the following safety\nframework: Content Safeguarding; Stability and Robustness; and Operational\nTransparency and Traceability. The subsequent implementation of these\nprinciples is outlined, followed by an experimental analysis of Chai's AI\nsafety framework's real-world impact. We emphasise the significance of\nconscientious application of AI safety principles and robust safety measures.\nThe successful implementation of the safe AI framework in Chai indicates the\npracticality of mitigating potential risks for responsible and ethical use of\nAI technologies. The ultimate vision is a transformative AI tool fostering\nprogress and innovation while prioritizing user safety and ethical standards.\n",
                "链接": "https://arxiv.org/abs/2306.02979"
            },
            {
                "文章ID": "110390",
                "标题": "GPTutor: an open-source AI pair programming tool alternative to Copilot",
                "作者": " Eason Chen,  Ray Huang,  Justa Liang,  Damien Chen,  Pierce Hung",
                "发布日期": "2023-10-26",
                "摘要": "  This paper presents the latest progress of GPTutor: a ChatGPT-powered\nprogramming tool extension in Visual Studio Code. The emergence of Large\nLanguage Models (LLMs) has improved software development efficiency, but their\nperformance can be hindered by training data limitations and prompt design\nissues. Existing LLM development tools often operate as black boxes, with users\nunable to view the prompts used and unable to improve performance by correcting\nprompts when errors occur. To address the aforementioned issues, GPTutor was\nintroduced as an open-source AI pair programming tool, offering an alternative\nto Copilot. GPTutor empowers users to customize prompts for various programming\nlanguages and scenarios, with support for 120+ human languages and 50+\nprogramming languages. Users can fine-tune prompts to correct the errors from\nLLM for precision and efficient code generation. At the end of the paper, we\nunderscore GPTutor's potential through examples, including demonstrating its\nproficiency in interpreting and generating Sui-Move, a newly introduced smart\ncontract language, using prompt engineering.\n",
                "链接": "https://arxiv.org/abs/2310.13896"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下对使用GPT生成数据集的训练步骤进行改进的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "79980",
                "标题": "Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with\n  Customized Exercise Generation",
                "作者": " Zhenwen Liang,  Wenhao Yu,  Tanmay Rajpurohit,  Peter Clark,  Xiangliang Zhang,  Ashwin Kaylan",
                "发布日期": "2023-05-25",
                "摘要": "  In this paper, we present a novel approach for distilling math word problem\nsolving capabilities from large language models (LLMs) into smaller, more\nefficient student models. Our approach is designed to consider the student\nmodel's weaknesses and foster a tailored learning experience by generating\ntargeted exercises aligned with educational science principles, such as\nknowledge tracing and personalized learning. Concretely, we let GPT-3 be a math\ntutor and run two steps iteratively: 1) assessing the student model's current\nlearning status on a GPT-generated exercise book, and 2) improving the student\nmodel by training it with tailored exercise samples generated by GPT-3.\nExperimental results reveal that our approach outperforms LLMs (e.g., GPT-3 and\nPaLM) in accuracy across three distinct benchmarks while employing\nsignificantly fewer parameters. Furthermore, we provide a comprehensive\nanalysis of the various components within our methodology to substantiate their\nefficacy.\n",
                "链接": "https://arxiv.org/abs/2305.14386"
            },
            {
                "文章ID": "74683",
                "标题": "CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to\n  Guardrail Models for Virtual Assistants",
                "作者": " Albert Yu Sun,  Varun Nair,  Elliot Schumacher,  Anitha Kannan",
                "发布日期": "2023-04-28",
                "摘要": "  A wave of new task-based virtual assistants has been fueled by increasingly\npowerful large language models, such as GPT-4. These conversational agents can\nbe customized to serve customer-specific use cases, but ensuring that\nagent-generated text conforms to designer-specified rules included in prompt\ninstructions alone is challenging. Therefore, chatbot designers often use\nanother model, called a guardrail model, to verify that the agent output aligns\nwith their rules and constraints. We explore using a distillation approach to\nguardrail models to monitor the output of the first model using training data\nfrom GPT-4. We find two crucial steps to our CONSCENDI process:\nscenario-augmented generation and contrastive training examples. When\ngenerating conversational data, we generate a set of rule-breaking scenarios,\nwhich enumerate a diverse set of high-level ways a rule can be violated. This\nscenario-guided approach produces a diverse training set of rule-violating\nconversations, and it provides chatbot designers greater control over the\nclassification process. We also prompt GPT-4 to also generate contrastive\nexamples by altering conversations with violations into acceptable\nconversations. This set of borderline, contrastive examples enables the\ndistilled model to learn finer-grained distinctions between what is acceptable\nand what is not. We find that CONSCENDI results in guardrail models that\nimprove over baselines.\n",
                "链接": "https://arxiv.org/abs/2304.14364"
            },
            {
                "文章ID": "71129",
                "标题": "Instruction Tuning with GPT-4",
                "作者": " Baolin Peng,  Chunyuan Li,  Pengcheng He,  Michel Galley,  Jianfeng Gao",
                "发布日期": "2023-04-07",
                "摘要": "  Prior work has shown that finetuning large language models (LLMs) using\nmachine-generated instruction-following data enables such models to achieve\nremarkable zero-shot capabilities on new tasks, and no human-written\ninstructions are needed. In this paper, we present the first attempt to use\nGPT-4 to generate instruction-following data for LLM finetuning. Our early\nexperiments on instruction-tuned LLaMA models show that the 52K English and\nChinese instruction-following data generated by GPT-4 leads to superior\nzero-shot performance on new tasks to the instruction-following data generated\nby previous state-of-the-art models. We also collect feedback and comparison\ndata from GPT-4 to enable a comprehensive evaluation and reward model training.\nWe make our data generated using GPT-4 as well as our codebase publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2304.03277"
            },
            {
                "文章ID": "99462",
                "标题": "Quantifying Uncertainty in Answers from any Language Model and Enhancing\n  their Trustworthiness",
                "作者": " Jiuhai Chen,  Jonas Mueller",
                "发布日期": "2023-10-05",
                "摘要": "  We introduce BSDetector, a method for detecting bad and speculative answers\nfrom a pretrained Large Language Model by estimating a numeric confidence score\nfor any output it generated. Our uncertainty quantification technique works for\nany LLM accessible only via a black-box API, whose training data remains\nunknown. By expending a bit of extra computation, users of any LLM API can now\nget the same response as they would ordinarily, as well as a confidence\nestimate that cautions when not to trust this response. Experiments on both\nclosed and open-form Question-Answer benchmarks reveal that BSDetector more\naccurately identifies incorrect LLM responses than alternative uncertainty\nestimation procedures (for both GPT-3 and ChatGPT). By sampling multiple\nresponses from the LLM and considering the one with the highest confidence\nscore, we can additionally obtain more accurate responses from the same LLM,\nwithout any extra training steps. In applications involving automated\nevaluation with LLMs, accounting for our confidence scores leads to more\nreliable evaluation in both human-in-the-loop and fully-automated settings\n(across both GPT 3.5 and 4).\n",
                "链接": "https://arxiv.org/abs/2308.16175"
            },
            {
                "文章ID": "56440",
                "标题": "Automatic Generation of German Drama Texts Using Fine Tuned GPT-2 Models",
                "作者": " Mariam Bangura,  Kristina Barabashova,  Anna Karnysheva,  Sarah Semczuk,  Yifan Wang",
                "发布日期": "2023-01-11",
                "摘要": "  This study is devoted to the automatic generation of German drama texts. We\nsuggest an approach consisting of two key steps: fine-tuning a GPT-2 model (the\noutline model) to generate outlines of scenes based on keywords and fine-tuning\na second model (the generation model) to generate scenes from the scene\noutline. The input for the neural model comprises two datasets: the German\nDrama Corpus (GerDraCor) and German Text Archive (Deutsches Textarchiv or DTA).\nIn order to estimate the effectiveness of the proposed method, our models are\ncompared with baseline GPT-2 models. Our models perform well according to\nautomatic quantitative evaluation, but, conversely, manual qualitative analysis\nreveals a poor quality of generated texts. This may be due to the quality of\nthe dataset or training inputs.\n",
                "链接": "https://arxiv.org/abs/2301.03119"
            },
            {
                "文章ID": "13451",
                "标题": "Data Augmentation for Intent Classification with Off-the-shelf Large\n  Language Models",
                "作者": " Gaurav Sahu,  Pau Rodriguez,  Issam H. Laradji,  Parmida Atighehchian,  David Vazquez,  Dzmitry Bahdanau",
                "发布日期": "2022-04-06",
                "摘要": "  Data augmentation is a widely employed technique to alleviate the problem of\ndata scarcity. In this work, we propose a prompting-based approach to generate\nlabelled training data for intent classification with off-the-shelf language\nmodels (LMs) such as GPT-3. An advantage of this method is that no\ntask-specific LM-fine-tuning for data generation is required; hence the method\nrequires no hyper-parameter tuning and is applicable even when the available\ntraining data is very scarce. We evaluate the proposed method in a few-shot\nsetting on four diverse intent classification tasks. We find that GPT-generated\ndata significantly boosts the performance of intent classifiers when intents in\nconsideration are sufficiently distinct from each other. In tasks with\nsemantically close intents, we observe that the generated data is less helpful.\nOur analysis shows that this is because GPT often generates utterances that\nbelong to a closely-related intent instead of the desired one. We present\npreliminary evidence that a prompting-based GPT classifier could be helpful in\nfiltering the generated data to enhance its quality.\n",
                "链接": "https://arxiv.org/abs/2204.01959"
            },
            {
                "文章ID": "79918",
                "标题": "LLM-powered Data Augmentation for Enhanced Cross-lingual Performance",
                "作者": " Chenxi Whitehouse,  Monojit Choudhury,  Alham Fikri Aji",
                "发布日期": "2023-10-24",
                "摘要": "  This paper explores the potential of leveraging Large Language Models (LLMs)\nfor data augmentation in multilingual commonsense reasoning datasets where the\navailable training data is extremely limited. To achieve this, we utilise\nseveral LLMs, namely Dolly-v2, StableVicuna, ChatGPT, and GPT-4, to augment\nthree datasets: XCOPA, XWinograd, and XStoryCloze. Subsequently, we evaluate\nthe effectiveness of fine-tuning smaller multilingual models, mBERT and XLMR,\nusing the synthesised data. We compare the performance of training with data\ngenerated in English and target languages, as well as translated\nEnglish-generated data, revealing the overall advantages of incorporating data\ngenerated by LLMs, e.g. a notable 13.4 accuracy score improvement for the best\ncase. Furthermore, we conduct a human evaluation by asking native speakers to\nassess the naturalness and logical coherence of the generated examples across\ndifferent languages. The results of the evaluation indicate that LLMs such as\nChatGPT and GPT-4 excel at producing natural and coherent text in most\nlanguages, however, they struggle to generate meaningful text in certain\nlanguages like Tamil. We also observe that ChatGPT falls short in generating\nplausible alternatives compared to the original dataset, whereas examples from\nGPT-4 exhibit competitive logical consistency.\n",
                "链接": "https://arxiv.org/abs/2305.14288"
            },
            {
                "文章ID": "83441",
                "标题": "GPT-FL: Generative Pre-trained Model-Assisted Federated Learning",
                "作者": " Tuo Zhang,  Tiantian Feng,  Samiul Alam,  Dimitrios Dimitriadis,  Mi Zhang,  Shrikanth S. Narayanan,  Salman Avestimehr",
                "发布日期": "2023-10-03",
                "摘要": "  In this work, we propose GPT-FL, a generative pre-trained model-assisted\nfederated learning (FL) framework. At its core, GPT-FL leverages generative\npre-trained models to generate diversified synthetic data. These generated data\nare used to train a downstream model on the server, which is then fine-tuned\nwith private client data under the standard FL framework. We show that GPT-FL\nconsistently outperforms state-of-the-art FL methods in terms of model test\naccuracy, communication efficiency, and client sampling efficiency. Through\ncomprehensive ablation analysis, we discover that the downstream model\ngenerated by synthetic data plays a crucial role in controlling the direction\nof gradient diversity during FL training, which enhances convergence speed and\ncontributes to the notable accuracy boost observed with GPT-FL. Also,\nregardless of whether the target data falls within or outside the domain of the\npre-trained generative model, GPT-FL consistently achieves significant\nperformance gains, surpassing the results obtained by models trained solely\nwith FL or synthetic data.\n",
                "链接": "https://arxiv.org/abs/2306.02210"
            },
            {
                "文章ID": "5202",
                "标题": "Maximizing Communication Efficiency for Large-scale Training via 0/1\n  Adam",
                "作者": " Yucheng Lu,  Conglong Li,  Minjia Zhang,  Christopher De Sa,  Yuxiong He",
                "发布日期": "2022-05-24",
                "摘要": "  1-bit gradient compression and local steps are two representative techniques\nthat enable drastic communication reduction in distributed SGD. Their benefits,\nhowever, remain an open question on Adam-based large model pre-training (e.g.\nBERT and GPT). In this paper, we demonstrate the non-linearity in Adam causes\nslow convergence even when 1-bit compression or local steps are individually\napplied. To alleviate this limitation, we propose 0/1 Adam that linearizes each\nAdam step via approximating its optimizer states using their stale estimates\nand linear correlation. 0/1 Adam performs an Adam-like step to preserve the\nadaptivity, while its linearity allows utilizing 1-bit compression and local\nsteps simultaneously for wall-clock time speed up. We provide convergence\nguarantee for 0/1 Adam on smooth non-convex objectives. On various large-scale\nbenchmarks such as BERT-Base, BERT-Large, GPT-2 pre-training and ImageNet, we\ndemonstrate on up to 128 GPUs that 0/1 Adam is able to reduce up to 87% of data\nvolume, 54% of communication rounds, and achieve up to 2$\\times$ higher\ntraining throughput and end-to-end training time reduction compared to the\nstate-of-the-art baseline 1-bit Adam; while enjoying the same statistical\nconvergence speed and end task model accuracy on GLUE dataset and ImageNet\nvalidation set.\n",
                "链接": "https://arxiv.org/abs/2202.06009"
            },
            {
                "文章ID": "74576",
                "标题": "SweCTRL-Mini: a data-transparent Transformer-based large language model\n  for controllable text generation in Swedish",
                "作者": " Dmytro Kalpakchi,  Johan Boye",
                "发布日期": "2023-06-23",
                "摘要": "  We present SweCTRL-Mini, a large Swedish language model that can be used for\ninference and fine-tuning on a single consumer-grade GPU. The model is based on\nthe CTRL architecture by Keskar, McCann, Varshney, Xiong, and Socher (2019),\nwhich means that users of the SweCTRL-Mini model can control the genre of the\ngenerated text by inserting special tokens in the generation prompts.\nSweCTRL-Mini is trained on a subset of the Swedish part of the mC4 corpus and a\nset of Swedish novels. In this article, we provide (1) a detailed account of\nthe utilized training data and text pre-processing steps, to the extent that it\nis possible to check whether a specific phrase/source was a part of the\ntraining data, and (2) an evaluation of the model on both discriminative tasks,\nusing automatic evaluation methods, and generative tasks, using human referees.\nWe also compare the generative capabilities of the model with those of GPT-3.\nSweCTRL-Mini is fully open and available for download.\n",
                "链接": "https://arxiv.org/abs/2304.13994"
            }
        ]
    },
    {
        "question": {
            "question": "请找到利用clip做开放词汇检测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "68353",
                "标题": "CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting\n  and Anchor Pre-Matching",
                "作者": " Xiaoshi Wu,  Feng Zhu,  Rui Zhao,  Hongsheng Li",
                "发布日期": "2023-03-24",
                "摘要": "  Open-vocabulary detection (OVD) is an object detection task aiming at\ndetecting objects from novel categories beyond the base categories on which the\ndetector is trained. Recent OVD methods rely on large-scale visual-language\npre-trained models, such as CLIP, for recognizing novel objects. We identify\nthe two core obstacles that need to be tackled when incorporating these models\ninto detector training: (1) the distribution mismatch that happens when\napplying a VL-model trained on whole images to region recognition tasks; (2)\nthe difficulty of localizing objects of unseen classes. To overcome these\nobstacles, we propose CORA, a DETR-style framework that adapts CLIP for\nOpen-vocabulary detection by Region prompting and Anchor pre-matching. Region\nprompting mitigates the whole-to-region distribution gap by prompting the\nregion features of the CLIP-based region classifier. Anchor pre-matching helps\nlearning generalizable object localization by a class-aware matching mechanism.\nWe evaluate CORA on the COCO OVD benchmark, where we achieve 41.7 AP50 on novel\nclasses, which outperforms the previous SOTA by 2.4 AP50 even without resorting\nto extra training data. When extra training data is available, we train\nCORA$^+$ on both ground-truth base-category annotations and additional pseudo\nbounding box labels computed by CORA. CORA$^+$ achieves 43.1 AP50 on the COCO\nOVD benchmark and 28.1 box APr on the LVIS OVD benchmark.\n",
                "链接": "https://arxiv.org/abs/2303.13076"
            },
            {
                "文章ID": "116861",
                "标题": "CastDet: Toward Open Vocabulary Aerial Object Detection with\n  CLIP-Activated Student-Teacher Learning",
                "作者": " Yan Li,  Weiwei Guo,  Dunyun He,  Jiaqi Zhou,  Yuze Gao,  Wenxian Yu",
                "发布日期": "2023-11-21",
                "摘要": "  Object detection in aerial images is a pivotal task for various earth\nobservation applications, whereas current algorithms learn to detect only a\npre-defined set of object categories demanding sufficient bounding-box\nannotated training samples and fail to detect novel object categories. In this\npaper, we consider open-vocabulary object detection (OVD) in aerial images that\nenables the characterization of new objects beyond training categories on the\nearth surface without annotating training images for these new categories. The\nperformance of OVD depends on the quality of class-agnostic region proposals\nand pseudo-labels that can generalize well to novel object categories. To\nsimultaneously generate high-quality proposals and pseudo-labels, we propose\nCastDet, a CLIP-activated student-teacher open-vocabulary object Detection\nframework. Our end-to-end framework within the student-teacher mechanism\nemploys the CLIP model as an extra omniscient teacher of rich knowledge into\nthe student-teacher self-learning process. By doing so, our approach boosts\nnovel object proposals and classification. Furthermore, we design a dynamic\nlabel queue technique to maintain high-quality pseudo labels during batch\ntraining and mitigate label imbalance. We conduct extensive experiments on\nmultiple existing aerial object detection datasets, which are set up for the\nOVD task. Experimental results demonstrate our CastDet achieving superior\nopen-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean),\nwhich outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD\ndataset.\n",
                "链接": "https://arxiv.org/abs/2311.11646"
            },
            {
                "文章ID": "70348",
                "标题": "Open-Vocabulary Point-Cloud Object Detection without 3D Annotation",
                "作者": " Yuheng Lu,  Chenfeng Xu,  Xiaobao Wei,  Xiaodong Xie,  Masayoshi Tomizuka,  Kurt Keutzer,  Shanghang Zhang",
                "发布日期": "2023-05-18",
                "摘要": "  The goal of open-vocabulary detection is to identify novel objects based on\narbitrary textual descriptions. In this paper, we address open-vocabulary 3D\npoint-cloud detection by a dividing-and-conquering strategy, which involves: 1)\ndeveloping a point-cloud detector that can learn a general representation for\nlocalizing various objects, and 2) connecting textual and point-cloud\nrepresentations to enable the detector to classify novel object categories\nbased on text prompting. Specifically, we resort to rich image pre-trained\nmodels, by which the point-cloud detector learns localizing objects under the\nsupervision of predicted 2D bounding boxes from 2D pre-trained detectors.\nMoreover, we propose a novel de-biased triplet cross-modal contrastive learning\nto connect the modalities of image, point-cloud and text, thereby enabling the\npoint-cloud detector to benefit from vision-language pre-trained\nmodels,i.e.,CLIP. The novel use of image and vision-language pre-trained models\nfor point-cloud detectors allows for open-vocabulary 3D object detection\nwithout the need for 3D annotations. Experiments demonstrate that the proposed\nmethod improves at least 3.03 points and 7.47 points over a wide range of\nbaselines on the ScanNet and SUN RGB-D datasets, respectively. Furthermore, we\nprovide a comprehensive analysis to explain why our approach works.\n",
                "链接": "https://arxiv.org/abs/2304.00788"
            },
            {
                "文章ID": "123157",
                "标题": "Simple Image-level Classification Improves Open-vocabulary Object\n  Detection",
                "作者": " Ruohuan Fang,  Guansong Pang,  Xiao Bai",
                "发布日期": "2023-12-20",
                "摘要": "  Open-Vocabulary Object Detection (OVOD) aims to detect novel objects beyond a\ngiven set of base categories on which the detection model is trained. Recent\nOVOD methods focus on adapting the image-level pre-trained vision-language\nmodels (VLMs), such as CLIP, to a region-level object detection task via, eg.,\nregion-level knowledge distillation, regional prompt learning, or region-text\npre-training, to expand the detection vocabulary. These methods have\ndemonstrated remarkable performance in recognizing regional visual concepts,\nbut they are weak in exploiting the VLMs' powerful global scene understanding\nability learned from the billion-scale image-level text descriptions. This\nlimits their capability in detecting hard objects of small, blurred, or\noccluded appearance from novel/base categories, whose detection heavily relies\non contextual information. To address this, we propose a novel approach, namely\nSimple Image-level Classification for Context-Aware Detection Scoring\n(SIC-CADS), to leverage the superior global knowledge yielded from CLIP for\ncomplementing the current OVOD models from a global perspective. The core of\nSIC-CADS is a multi-modal multi-label recognition (MLR) module that learns the\nobject co-occurrence-based contextual information from CLIP to recognize all\npossible object categories in the scene. These image-level MLR scores can then\nbe utilized to refine the instance-level detection scores of the current OVOD\nmodels in detecting those hard objects. This is verified by extensive empirical\nresults on two popular benchmarks, OV-LVIS and OV-COCO, which show that\nSIC-CADS achieves significant and consistent improvement when combined with\ndifferent types of OVOD models. Further, SIC-CADS also improves the\ncross-dataset generalization ability on Objects365 and OpenImages. The code is\navailable at https://github.com/mala-lab/SIC-CADS.\n",
                "链接": "https://arxiv.org/abs/2312.10439"
            },
            {
                "文章ID": "99749",
                "标题": "What Makes Good Open-Vocabulary Detector: A Disassembling Perspective",
                "作者": " Jincheng Li,  Chunyu Xie,  Xiaoyu Wu,  Bin Wang,  Dawei Leng",
                "发布日期": "2023-09-04",
                "摘要": "  Open-vocabulary detection (OVD) is a new object detection paradigm, aiming to\nlocalize and recognize unseen objects defined by an unbounded vocabulary. This\nis challenging since traditional detectors can only learn from pre-defined\ncategories and thus fail to detect and localize objects out of pre-defined\nvocabulary. To handle the challenge, OVD leverages pre-trained cross-modal VLM,\nsuch as CLIP, ALIGN, etc. Previous works mainly focus on the open vocabulary\nclassification part, with less attention on the localization part. We argue\nthat for a good OVD detector, both classification and localization should be\nparallelly studied for the novel object categories. We show in this work that\nimproving localization as well as cross-modal classification complement each\nother, and compose a good OVD detector jointly. We analyze three families of\nOVD methods with different design emphases. We first propose a vanilla\nmethod,i.e., cropping a bounding box obtained by a localizer and resizing it\ninto the CLIP. We next introduce another approach, which combines a standard\ntwo-stage object detector with CLIP. A two-stage object detector includes a\nvisual backbone, a region proposal network (RPN), and a region of interest\n(RoI) head. We decouple RPN and ROI head (DRR) and use RoIAlign to extract\nmeaningful features. In this case, it avoids resizing objects. To further\naccelerate the training time and reduce the model parameters, we couple RPN and\nROI head (CRR) as the third approach. We conduct extensive experiments on these\nthree types of approaches in different settings. On the OVD-COCO benchmark, DRR\nobtains the best performance and achieves 35.8 Novel AP$_{50}$, an absolute 2.8\ngain over the previous state-of-the-art (SOTA). For OVD-LVIS, DRR surpasses the\nprevious SOTA by 1.9 AP$_{50}$ in rare categories. We also provide an object\ndetection dataset called PID and provide a baseline on PID.\n",
                "链接": "https://arxiv.org/abs/2309.00227"
            },
            {
                "文章ID": "68854",
                "标题": "Prompt-Guided Transformers for End-to-End Open-Vocabulary Object\n  Detection",
                "作者": " Hwanjun Song,  Jihwan Bang",
                "发布日期": "2023-03-28",
                "摘要": "  Prompt-OVD is an efficient and effective framework for open-vocabulary object\ndetection that utilizes class embeddings from CLIP as prompts, guiding the\nTransformer decoder to detect objects in both base and novel classes.\nAdditionally, our novel RoI-based masked attention and RoI pruning techniques\nhelp leverage the zero-shot classification ability of the Vision\nTransformer-based CLIP, resulting in improved detection performance at minimal\ncomputational cost. Our experiments on the OV-COCO and OVLVIS datasets\ndemonstrate that Prompt-OVD achieves an impressive 21.2 times faster inference\nspeed than the first end-to-end open-vocabulary detection method (OV-DETR),\nwhile also achieving higher APs than four two-stage-based methods operating\nwithin similar inference time ranges. Code will be made available soon.\n",
                "链接": "https://arxiv.org/abs/2303.14386"
            },
            {
                "文章ID": "116723",
                "标题": "Open-Vocabulary Camouflaged Object Segmentation",
                "作者": " Youwei Pang,  Xiaoqi Zhao,  Jiaming Zuo,  Lihe Zhang,  Huchuan Lu",
                "发布日期": "2023-11-21",
                "摘要": "  Recently, the emergence of the large-scale vision-language model (VLM), such\nas CLIP, has opened the way towards open-world object perception. Many works\nhas explored the utilization of pre-trained VLM for the challenging\nopen-vocabulary dense prediction task that requires perceive diverse objects\nwith novel classes at inference time. Existing methods construct experiments\nbased on the public datasets of related tasks, which are not tailored for open\nvocabulary and rarely involves imperceptible objects camouflaged in complex\nscenes due to data collection bias and annotation costs. To fill in the gaps,\nwe introduce a new task, open-vocabulary camouflaged object segmentation\n(OVCOS) and construct a large-scale complex scene dataset (\\textbf{OVCamo})\nwhich containing 11,483 hand-selected images with fine annotations and\ncorresponding object classes. Further, we build a strong single-stage\nopen-vocabulary \\underline{c}amouflaged \\underline{o}bject\n\\underline{s}egmentation transform\\underline{er} baseline \\textbf{OVCoser}\nattached to the parameter-fixed CLIP with iterative semantic guidance and\nstructure enhancement. By integrating the guidance of class semantic knowledge\nand the supplement of visual structure cues from the edge and depth\ninformation, the proposed method can efficiently capture camouflaged objects.\nMoreover, this effective framework also surpasses previous state-of-the-arts of\nopen-vocabulary semantic image segmentation by a large margin on our OVCamo\ndataset. With the proposed dataset and baseline, we hope that this new task\nwith more practical value can further expand the research on open-vocabulary\ndense prediction tasks.\n",
                "链接": "https://arxiv.org/abs/2311.11241"
            },
            {
                "文章ID": "28246",
                "标题": "Bridging the Gap between Object and Image-level Representations for\n  Open-Vocabulary Detection",
                "作者": " Hanoona Rasheed,  Muhammad Maaz,  Muhammad Uzair Khattak,  Salman Khan,  Fahad Shahbaz Khan",
                "发布日期": "2022-11-30",
                "摘要": "  Existing open-vocabulary object detectors typically enlarge their vocabulary\nsizes by leveraging different forms of weak supervision. This helps generalize\nto novel objects at inference. Two popular forms of weak-supervision used in\nopen-vocabulary detection (OVD) include pretrained CLIP model and image-level\nsupervision. We note that both these modes of supervision are not optimally\naligned for the detection task: CLIP is trained with image-text pairs and lacks\nprecise localization of objects while the image-level supervision has been used\nwith heuristics that do not accurately specify local object regions. In this\nwork, we propose to address this problem by performing object-centric alignment\nof the language embeddings from the CLIP model. Furthermore, we visually ground\nthe objects with only image-level supervision using a pseudo-labeling process\nthat provides high-quality object proposals and helps expand the vocabulary\nduring training. We establish a bridge between the above two object-alignment\nstrategies via a novel weight transfer function that aggregates their\ncomplimentary strengths. In essence, the proposed model seeks to minimize the\ngap between object and image-centric representations in the OVD setting. On the\nCOCO benchmark, our proposed approach achieves 36.6 AP50 on novel classes, an\nabsolute 8.2 gain over the previous best performance. For LVIS, we surpass the\nstate-of-the-art ViLD model by 5.0 mask AP for rare categories and 3.4 overall.\nCode: https://github.com/hanoonaR/object-centric-ovd.\n",
                "链接": "https://arxiv.org/abs/2207.03482"
            },
            {
                "文章ID": "11160",
                "标题": "Open-Vocabulary DETR with Conditional Matching",
                "作者": " Yuhang Zang,  Wei Li,  Kaiyang Zhou,  Chen Huang,  Chen Change Loy",
                "发布日期": "2022-12-01",
                "摘要": "  Open-vocabulary object detection, which is concerned with the problem of\ndetecting novel objects guided by natural language, has gained increasing\nattention from the community. Ideally, we would like to extend an\nopen-vocabulary detector such that it can produce bounding box predictions\nbased on user inputs in form of either natural language or exemplar image. This\noffers great flexibility and user experience for human-computer interaction. To\nthis end, we propose a novel open-vocabulary detector based on DETR -- hence\nthe name OV-DETR -- which, once trained, can detect any object given its class\nname or an exemplar image. The biggest challenge of turning DETR into an\nopen-vocabulary detector is that it is impossible to calculate the\nclassification cost matrix of novel classes without access to their labeled\nimages. To overcome this challenge, we formulate the learning objective as a\nbinary matching one between input queries (class name or exemplar image) and\nthe corresponding objects, which learns useful correspondence to generalize to\nunseen queries during testing. For training, we choose to condition the\nTransformer decoder on the input embeddings obtained from a pre-trained\nvision-language model like CLIP, in order to enable matching for both text and\nimage queries. With extensive experiments on LVIS and COCO datasets, we\ndemonstrate that our OV-DETR -- the first end-to-end Transformer-based\nopen-vocabulary detector -- achieves non-trivial improvements over current\nstate of the arts.\n",
                "链接": "https://arxiv.org/abs/2203.11876"
            },
            {
                "文章ID": "119030",
                "标题": "Active Open-Vocabulary Recognition: Let Intelligent Moving Mitigate CLIP\n  Limitations",
                "作者": " Lei Fan,  Jianxiong Zhou,  Xiaoying Xing,  Ying Wu",
                "发布日期": "2023-12-01",
                "摘要": "  Active recognition, which allows intelligent agents to explore observations\nfor better recognition performance, serves as a prerequisite for various\nembodied AI tasks, such as grasping, navigation and room arrangements. Given\nthe evolving environment and the multitude of object classes, it is impractical\nto include all possible classes during the training stage. In this paper, we\naim at advancing active open-vocabulary recognition, empowering embodied agents\nto actively perceive and classify arbitrary objects. However, directly adopting\nrecent open-vocabulary classification models, like Contrastive Language Image\nPretraining (CLIP), poses its unique challenges. Specifically, we observe that\nCLIP's performance is heavily affected by the viewpoint and occlusions,\ncompromising its reliability in unconstrained embodied perception scenarios.\nFurther, the sequential nature of observations in agent-environment\ninteractions necessitates an effective method for integrating features that\nmaintains discriminative strength for open-vocabulary classification. To\naddress these issues, we introduce a novel agent for active open-vocabulary\nrecognition. The proposed method leverages inter-frame and inter-concept\nsimilarities to navigate agent movements and to fuse features, without relying\non class-specific knowledge. Compared to baseline CLIP model with 29.6%\naccuracy on ShapeNet dataset, the proposed agent could achieve 53.3% accuracy\nfor open-vocabulary recognition, without any fine-tuning to the equipped CLIP\nmodel. Additional experiments conducted with the Habitat simulator further\naffirm the efficacy of our method.\n",
                "链接": "https://arxiv.org/abs/2311.17938"
            }
        ]
    },
    {
        "question": {
            "question": "请找到使用自蒸馏加强目标检测性能的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "109063",
                "标题": "Mask wearing object detection algorithm based on improved YOLOv5",
                "作者": " Peng Wen,  Junhu Zhang,  Haitao Li",
                "发布日期": "2023-10-17",
                "摘要": "  Wearing a mask is one of the important measures to prevent infectious\ndiseases. However, it is difficult to detect people's mask-wearing situation in\npublic places with high traffic flow. To address the above problem, this paper\nproposes a mask-wearing face detection model based on YOLOv5l. Firstly,\nMulti-Head Attentional Self-Convolution not only improves the convergence speed\nof the model but also enhances the accuracy of the model detection. Secondly,\nthe introduction of Swin Transformer Block is able to extract more useful\nfeature information, enhance the detection ability of small targets, and\nimprove the overall accuracy of the model. Our designed I-CBAM module can\nimprove target detection accuracy. In addition, using enhanced feature fusion\nenables the model to better adapt to object detection tasks of different\nscales. In the experimentation on the MASK dataset, the results show that the\nmodel proposed in this paper achieved a 1.1% improvement in mAP(0.5) and a 1.3%\nimprovement in mAP(0.5:0.95) compared to the YOLOv5l model. Our proposed method\nsignificantly enhances the detection capability of mask-wearing.\n",
                "链接": "https://arxiv.org/abs/2310.10245"
            },
            {
                "文章ID": "65588",
                "标题": "Smooth and Stepwise Self-Distillation for Object Detection",
                "作者": " Jieren Deng,  Xin Zhou,  Hao Tian,  Zhihong Pan,  Derek Aguiar",
                "发布日期": "2023-03-10",
                "摘要": "  Distilling the structured information captured in feature maps has\ncontributed to improved results for object detection tasks, but requires\ncareful selection of baseline architectures and substantial pre-training.\nSelf-distillation addresses these limitations and has recently achieved\nstate-of-the-art performance for object detection despite making several\nsimplifying architectural assumptions. Building on this work, we propose Smooth\nand Stepwise Self-Distillation (SSSD) for object detection. Our SSSD\narchitecture forms an implicit teacher from object labels and a feature pyramid\nnetwork backbone to distill label-annotated feature maps using Jensen-Shannon\ndistance, which is smoother than distillation losses used in prior work. We\nadditionally add a distillation coefficient that is adaptively configured based\non the learning rate. We extensively benchmark SSSD against a baseline and two\nstate-of-the-art object detector architectures on the COCO dataset by varying\nthe coefficients and backbone and detector networks. We demonstrate that SSSD\nachieves higher average precision in most experimental settings, is robust to a\nwide range of coefficients, and benefits from our stepwise distillation\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2303.05015"
            },
            {
                "文章ID": "17577",
                "标题": "Cross Domain Object Detection by Target-Perceived Dual Branch\n  Distillation",
                "作者": " Mengzhe He,  Yali Wang,  Jiaxi Wu,  Yiru Wang,  Hanqing Li,  Bo Li,  Weihao Gan,  Wei Wu,  Yu Qiao",
                "发布日期": "2022-05-04",
                "摘要": "  Cross domain object detection is a realistic and challenging task in the\nwild. It suffers from performance degradation due to large shift of data\ndistributions and lack of instance-level annotations in the target domain.\nExisting approaches mainly focus on either of these two difficulties, even\nthough they are closely coupled in cross domain object detection. To solve this\nproblem, we propose a novel Target-perceived Dual-branch Distillation (TDD)\nframework. By integrating detection branches of both source and target domains\nin a unified teacher-student learning scheme, it can reduce domain shift and\ngenerate reliable supervision effectively. In particular, we first introduce a\ndistinct Target Proposal Perceiver between two domains. It can adaptively\nenhance source detector to perceive objects in a target image, by leveraging\ntarget proposal contexts from iterative cross-attention. Afterwards, we design\na concise Dual Branch Self Distillation strategy for model training, which can\nprogressively integrate complementary object knowledge from different domains\nvia self-distillation in two branches. Finally, we conduct extensive\nexperiments on a number of widely-used scenarios in cross domain object\ndetection. The results show that our TDD significantly outperforms the\nstate-of-the-art methods on all the benchmarks. Our code and model will be\navailable at https://github.com/Feobi1999/TDD.\n",
                "链接": "https://arxiv.org/abs/2205.01291"
            },
            {
                "文章ID": "92560",
                "标题": "Spatial Self-Distillation for Object Detection with Inaccurate Bounding\n  Boxes",
                "作者": " Di Wu,  Pengfei Chen,  Xuehui Yu,  Guorong Li,  Zhenjun Han,  Jianbin Jiao",
                "发布日期": "2023-08-16",
                "摘要": "  Object detection via inaccurate bounding boxes supervision has boosted a\nbroad interest due to the expensive high-quality annotation data or the\noccasional inevitability of low annotation quality (\\eg tiny objects). The\nprevious works usually utilize multiple instance learning (MIL), which highly\ndepends on category information, to select and refine a low-quality box. Those\nmethods suffer from object drift, group prediction and part domination problems\nwithout exploring spatial information. In this paper, we heuristically propose\na \\textbf{Spatial Self-Distillation based Object Detector (SSD-Det)} to mine\nspatial information to refine the inaccurate box in a self-distillation\nfashion. SSD-Det utilizes a Spatial Position Self-Distillation \\textbf{(SPSD)}\nmodule to exploit spatial information and an interactive structure to combine\nspatial information and category information, thus constructing a high-quality\nproposal bag. To further improve the selection procedure, a Spatial Identity\nSelf-Distillation \\textbf{(SISD)} module is introduced in SSD-Det to obtain\nspatial confidence to help select the best proposals. Experiments on MS-COCO\nand VOC datasets with noisy box annotation verify our method's effectiveness\nand achieve state-of-the-art performance. The code is available at\nhttps://github.com/ucas-vg/PointTinyBenchmark/tree/SSD-Det.\n",
                "链接": "https://arxiv.org/abs/2307.12101"
            },
            {
                "文章ID": "94259",
                "标题": "Three Factors to Improve Out-of-Distribution Detection",
                "作者": " Hyunjun Choi,  JaeHo Chung,  Hawook Jeong,  Jin Young Choi",
                "发布日期": "2023-08-03",
                "摘要": "  In the problem of out-of-distribution (OOD) detection, the usage of auxiliary\ndata as outlier data for fine-tuning has demonstrated encouraging performance.\nHowever, previous methods have suffered from a trade-off between classification\naccuracy (ACC) and OOD detection performance (AUROC, FPR, AUPR). To improve\nthis trade-off, we make three contributions: (i) Incorporating a self-knowledge\ndistillation loss can enhance the accuracy of the network; (ii) Sampling\nsemi-hard outlier data for training can improve OOD detection performance with\nminimal impact on accuracy; (iii) The introduction of our novel supervised\ncontrastive learning can simultaneously improve OOD detection performance and\nthe accuracy of the network. By incorporating all three factors, our approach\nenhances both accuracy and OOD detection performance by addressing the\ntrade-off between classification and OOD detection. Our method achieves\nimprovements over previous approaches in both performance metrics.\n",
                "链接": "https://arxiv.org/abs/2308.01030"
            },
            {
                "文章ID": "112170",
                "标题": "Efficient Object Detection in Optical Remote Sensing Imagery via\n  Attention-based Feature Distillation",
                "作者": " Pourya Shamsolmoali,  Jocelyn Chanussot,  Huiyu Zhou,  Yue Lu",
                "发布日期": "2023-10-31",
                "摘要": "  Efficient object detection methods have recently received great attention in\nremote sensing. Although deep convolutional networks often have excellent\ndetection accuracy, their deployment on resource-limited edge devices is\ndifficult. Knowledge distillation (KD) is a strategy for addressing this issue\nsince it makes models lightweight while maintaining accuracy. However, existing\nKD methods for object detection have encountered two constraints. First, they\ndiscard potentially important background information and only distill nearby\nforeground regions. Second, they only rely on the global context, which limits\nthe student detector's ability to acquire local information from the teacher\ndetector. To address the aforementioned challenges, we propose Attention-based\nFeature Distillation (AFD), a new KD approach that distills both local and\nglobal information from the teacher detector. To enhance local distillation, we\nintroduce a multi-instance attention mechanism that effectively distinguishes\nbetween background and foreground elements. This approach prompts the student\ndetector to focus on the pertinent channels and pixels, as identified by the\nteacher detector. Local distillation lacks global information, thus attention\nglobal distillation is proposed to reconstruct the relationship between various\npixels and pass it from teacher to student detector. The performance of AFD is\nevaluated on two public aerial image benchmarks, and the evaluation results\ndemonstrate that AFD in object detection can attain the performance of other\nstate-of-the-art models while being efficient.\n",
                "链接": "https://arxiv.org/abs/2310.18676"
            },
            {
                "文章ID": "11100",
                "标题": "Channel Self-Supervision for Online Knowledge Distillation",
                "作者": " Shixiao Fan,  Xuan Cheng,  Xiaomin Wang,  Chun Yang,  Pan Deng,  Minghui Liu,  Jiali Deng,  Ming Liu",
                "发布日期": "2022-03-24",
                "摘要": "  Recently, researchers have shown an increased interest in the online\nknowledge distillation. Adopting an one-stage and end-to-end training fashion,\nonline knowledge distillation uses aggregated intermediated predictions of\nmultiple peer models for training. However, the absence of a powerful teacher\nmodel may result in the homogeneity problem between group peers, affecting the\neffectiveness of group distillation adversely. In this paper, we propose a\nnovel online knowledge distillation method, \\textbf{C}hannel\n\\textbf{S}elf-\\textbf{S}upervision for Online Knowledge Distillation (CSS),\nwhich structures diversity in terms of input, target, and network to alleviate\nthe homogenization problem. Specifically, we construct a dual-network\nmulti-branch structure and enhance inter-branch diversity through\nself-supervised learning, adopting the feature-level transformation and\naugmenting the corresponding labels. Meanwhile, the dual network structure has\na larger space of independent parameters to resist the homogenization problem\nduring distillation. Extensive quantitative experiments on CIFAR-100 illustrate\nthat our method provides greater diversity than OKDDip and we also give pretty\nperformance improvement, even over the state-of-the-art such as PCL. The\nresults on three fine-grained datasets (StanfordDogs, StanfordCars,\nCUB-200-211) also show the significant generalization capability of our\napproach.\n",
                "链接": "https://arxiv.org/abs/2203.11660"
            },
            {
                "文章ID": "68022",
                "标题": "Efficient Feature Distillation for Zero-shot Annotation Object Detection",
                "作者": " Zhuoming Liu,  Xuefeng Hu,  Ram Nevatia",
                "发布日期": "2023-11-03",
                "摘要": "  We propose a new setting for detecting unseen objects called Zero-shot\nAnnotation object Detection (ZAD). It expands the zero-shot object detection\nsetting by allowing the novel objects to exist in the training images and\nrestricts the additional information the detector uses to novel category names.\nRecently, to detect unseen objects, large-scale vision-language models (e.g.,\nCLIP) are leveraged by different methods. The distillation-based methods have\ngood overall performance but suffer from a long training schedule caused by two\nfactors. First, existing work creates distillation regions biased to the base\ncategories, which limits the distillation of novel category information.\nSecond, directly using the raw feature from CLIP for distillation neglects the\ndomain gap between the training data of CLIP and the detection datasets, which\nmakes it difficult to learn the mapping from the image region to the\nvision-language feature space. To solve these problems, we propose Efficient\nfeature distillation for Zero-shot Annotation object Detection (EZAD). Firstly,\nEZAD adapts the CLIP's feature space to the target detection domain by\nre-normalizing CLIP; Secondly, EZAD uses CLIP to generate distillation\nproposals with potential novel category names to avoid the distillation being\noverly biased toward the base categories. Finally, EZAD takes advantage of\nsemantic meaning for regression to further improve the model performance. As a\nresult, EZAD outperforms the previous distillation-based methods in COCO by 4%\nwith a much shorter training schedule and achieves a 3% improvement on the LVIS\ndataset. Our code is available at https://github.com/dragonlzm/EZAD\n",
                "链接": "https://arxiv.org/abs/2303.12145"
            },
            {
                "文章ID": "9204",
                "标题": "Prediction-Guided Distillation for Dense Object Detection",
                "作者": " Chenhongyi Yang,  Mateusz Ochal,  Amos Storkey,  Elliot J. Crowley",
                "发布日期": "2022-07-19",
                "摘要": "  Real-world object detection models should be cheap and accurate. Knowledge\ndistillation (KD) can boost the accuracy of a small, cheap detection model by\nleveraging useful information from a larger teacher model. However, a key\nchallenge is identifying the most informative features produced by the teacher\nfor distillation. In this work, we show that only a very small fraction of\nfeatures within a ground-truth bounding box are responsible for a teacher's\nhigh detection performance. Based on this, we propose Prediction-Guided\nDistillation (PGD), which focuses distillation on these key predictive regions\nof the teacher and yields considerable gains in performance over many existing\nKD baselines. In addition, we propose an adaptive weighting scheme over the key\nregions to smooth out their influence and achieve even better performance. Our\nproposed approach outperforms current state-of-the-art KD baselines on a\nvariety of advanced one-stage detection architectures. Specifically, on the\nCOCO dataset, our method achieves between +3.1% and +4.6% AP improvement using\nResNet-101 and ResNet-50 as the teacher and student backbones, respectively. On\nthe CrowdHuman dataset, we achieve +3.2% and +2.0% improvements in MR and AP,\nalso using these backbones. Our code is available at\nhttps://github.com/ChenhongyiYang/PGD.\n",
                "链接": "https://arxiv.org/abs/2203.05469"
            },
            {
                "文章ID": "23285",
                "标题": "Self-Knowledge Distillation based Self-Supervised Learning for Covid-19\n  Detection from Chest X-Ray Images",
                "作者": " Guang Li,  Ren Togo,  Takahiro Ogawa,  Miki Haseyama",
                "发布日期": "2022-06-08",
                "摘要": "  The global outbreak of the Coronavirus 2019 (COVID-19) has overloaded\nworldwide healthcare systems. Computer-aided diagnosis for COVID-19 fast\ndetection and patient triage is becoming critical. This paper proposes a novel\nself-knowledge distillation based self-supervised learning method for COVID-19\ndetection from chest X-ray images. Our method can use self-knowledge of images\nbased on similarities of their visual features for self-supervised learning.\nExperimental results show that our method achieved an HM score of 0.988, an AUC\nof 0.999, and an accuracy of 0.957 on the largest open COVID-19 chest X-ray\ndataset.\n",
                "链接": "https://arxiv.org/abs/2206.03009"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用2020年以后CONLL 2004数据集进行NER评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "46217",
                "标题": "Recognizing Nested Entities from Flat Supervision: A New NER Subtask,\n  Feasibility and Challenges",
                "作者": " Enwei Zhu,  Yiyang Liu,  Ming Jin,  Jinpeng Li",
                "发布日期": "2022-11-02",
                "摘要": "  Many recent named entity recognition (NER) studies criticize flat NER for its\nnon-overlapping assumption, and switch to investigating nested NER. However,\nexisting nested NER models heavily rely on training data annotated with nested\nentities, while labeling such data is costly. This study proposes a new\nsubtask, nested-from-flat NER, which corresponds to a realistic application\nscenario: given data annotated with flat entities only, one may still desire\nthe trained model capable of recognizing nested entities. To address this task,\nwe train span-based models and deliberately ignore the spans nested inside\nlabeled entities, since these spans are possibly unlabeled entities. With\nnested entities removed from the training data, our model achieves 54.8%, 54.2%\nand 41.1% F1 scores on the subset of spans within entities on ACE 2004, ACE\n2005 and GENIA, respectively. This suggests the effectiveness of our approach\nand the feasibility of the task. In addition, the model's performance on flat\nentities is entirely unaffected. We further manually annotate the nested\nentities in the test set of CoNLL 2003, creating a nested-from-flat NER\nbenchmark. Analysis results show that the main challenges stem from the data\nand annotation inconsistencies between the flat and nested entities.\n",
                "链接": "https://arxiv.org/abs/2211.00301"
            },
            {
                "文章ID": "50504",
                "标题": "Finetuning BERT on Partially Annotated NER Corpora",
                "作者": " Viktor Scherbakov,  Vladimir Mayorov",
                "发布日期": "2022-11-29",
                "摘要": "  Most Named Entity Recognition (NER) models operate under the assumption that\ntraining datasets are fully labelled. While it is valid for established\ndatasets like CoNLL 2003 and OntoNotes, sometimes it is not feasible to obtain\nthe complete dataset annotation. These situations may occur, for instance,\nafter selective annotation of entities for cost reduction. This work presents\nan approach to finetuning BERT on such partially labelled datasets using\nself-supervision and label preprocessing. Our approach outperforms the previous\nLSTM-based label preprocessing baseline, significantly improving the\nperformance on poorly labelled datasets. We demonstrate that following our\napproach while finetuning RoBERTa on CoNLL 2003 dataset with only 10% of total\nentities labelled is enough to reach the performance of the baseline trained on\nthe same dataset with 50% of the entities labelled.\n",
                "链接": "https://arxiv.org/abs/2211.14360"
            },
            {
                "文章ID": "54218",
                "标题": "E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text",
                "作者": " Ting Wai Terence Au,  Ingemar J. Cox,  Vasileios Lampos",
                "发布日期": "2022-12-20",
                "摘要": "  Identifying named entities such as a person, location or organization, in\ndocuments can highlight key information to readers. Training Named Entity\nRecognition (NER) models requires an annotated data set, which can be a\ntime-consuming labour-intensive task. Nevertheless, there are publicly\navailable NER data sets for general English. Recently there has been interest\nin developing NER for legal text. However, prior work and experimental results\nreported here indicate that there is a significant degradation in performance\nwhen NER methods trained on a general English data set are applied to legal\ntext. We describe a publicly available legal NER data set, called E-NER, based\non legal company filings available from the US Securities and Exchange\nCommission's EDGAR data set. Training a number of different NER algorithms on\nthe general English CoNLL-2003 corpus but testing on our test collection\nconfirmed significant degradations in accuracy, as measured by the F1-score, of\nbetween 29.4\\% and 60.4\\%, compared to training and testing on the E-NER\ncollection.\n",
                "链接": "https://arxiv.org/abs/2212.09306"
            },
            {
                "文章ID": "12159",
                "标题": "Federated Named Entity Recognition",
                "作者": " Joel Mathew,  Dimitris Stripelis,  José Luis Ambite",
                "发布日期": "2022-03-30",
                "摘要": "  We present an analysis of the performance of Federated Learning in a\nparadigmatic natural-language processing task: Named-Entity Recognition (NER).\nFor our evaluation, we use the language-independent CoNLL-2003 dataset as our\nbenchmark dataset and a Bi-LSTM-CRF model as our benchmark NER model. We show\nthat federated training reaches almost the same performance as the centralized\nmodel, though with some performance degradation as the learning environments\nbecome more heterogeneous. We also show the convergence rate of federated\nmodels for NER. Finally, we discuss existing challenges of Federated Learning\nfor NLP applications that can foster future research directions.\n",
                "链接": "https://arxiv.org/abs/2203.15101"
            },
            {
                "文章ID": "111254",
                "标题": "CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset",
                "作者": " Susanna Rücker,  Alan Akbik",
                "发布日期": "2023-10-26",
                "摘要": "  The CoNLL-03 corpus is arguably the most well-known and utilized benchmark\ndataset for named entity recognition (NER). However, prior works found\nsignificant numbers of annotation errors, incompleteness, and inconsistencies\nin the data. This poses challenges to objectively comparing NER approaches and\nanalyzing their errors, as current state-of-the-art models achieve F1-scores\nthat are comparable to or even exceed the estimated noise level in CoNLL-03. To\naddress this issue, we present a comprehensive relabeling effort assisted by\nautomatic consistency checking that corrects 7.0% of all labels in the English\nCoNLL-03. Our effort adds a layer of entity linking annotation both for better\nexplainability of NER labels and as additional safeguard of annotation quality.\nOur experimental evaluation finds not only that state-of-the-art approaches\nreach significantly higher F1-scores (97.1%) on our data, but crucially that\nthe share of correct predictions falsely counted as errors due to annotation\nnoise drops from 47% to 6%. This indicates that our resource is well suited to\nanalyze the remaining errors made by state-of-the-art models, and that the\ntheoretical upper bound even on high resource, coarse-grained NER is not yet\nreached. To facilitate such analysis, we make CleanCoNLL publicly available to\nthe research community.\n",
                "链接": "https://arxiv.org/abs/2310.16225"
            },
            {
                "文章ID": "10782",
                "标题": "Leveraging Expert Guided Adversarial Augmentation For Improving\n  Generalization in Named Entity Recognition",
                "作者": " Aaron Reich,  Jiaao Chen,  Aastha Agrawal,  Yanzhe Zhang,  Diyi Yang",
                "发布日期": "2022-03-22",
                "摘要": "  Named Entity Recognition (NER) systems often demonstrate great performance on\nin-distribution data, but perform poorly on examples drawn from a shifted\ndistribution. One way to evaluate the generalization ability of NER models is\nto use adversarial examples, on which the specific variations associated with\nnamed entities are rarely considered. To this end, we propose leveraging\nexpert-guided heuristics to change the entity tokens and their surrounding\ncontexts thereby altering their entity types as adversarial attacks. Using\nexpert-guided heuristics, we augmented the CoNLL 2003 test set and manually\nannotated it to construct a high-quality challenging set. We found that\nstate-of-the-art NER systems trained on CoNLL 2003 training data drop\nperformance dramatically on our challenging set. By training on adversarial\naugmented training examples and using mixup for regularization, we were able to\nsignificantly improve the performance on the challenging set as well as improve\nout-of-domain generalization which we evaluated by using OntoNotes data. We\nhave publicly released our dataset and code at\nhttps://github.com/GT-SALT/Guided-Adversarial-Augmentation.\n",
                "链接": "https://arxiv.org/abs/2203.10693"
            },
            {
                "文章ID": "38990",
                "标题": "T-NER: An All-Round Python Library for Transformer-based Named Entity\n  Recognition",
                "作者": " Asahi Ushio,  Jose Camacho-Collados",
                "发布日期": "2022-09-27",
                "摘要": "  Language model (LM) pretraining has led to consistent improvements in many\nNLP downstream tasks, including named entity recognition (NER). In this paper,\nwe present T-NER (Transformer-based Named Entity Recognition), a Python library\nfor NER LM finetuning. In addition to its practical utility, T-NER facilitates\nthe study and investigation of the cross-domain and cross-lingual\ngeneralization ability of LMs finetuned on NER. Our library also provides a web\napp where users can get model predictions interactively for arbitrary text,\nwhich facilitates qualitative model evaluation for non-expert programmers. We\nshow the potential of the library by compiling nine public NER datasets into a\nunified format and evaluating the cross-domain and cross-lingual performance\nacross the datasets. The results from our initial experiments show that\nin-domain performance is generally competitive across datasets. However,\ncross-domain generalization is challenging even with a large pretrained LM,\nwhich has nevertheless capacity to learn domain-specific features if fine-tuned\non a combined dataset. To facilitate future research, we also release all our\nLM checkpoints via the Hugging Face model hub.\n",
                "链接": "https://arxiv.org/abs/2209.12616"
            },
            {
                "文章ID": "5948",
                "标题": "AISHELL-NER: Named Entity Recognition from Chinese Speech",
                "作者": " Boli Chen,  Guangwei Xu,  Xiaobin Wang,  Pengjun Xie,  Meishan Zhang,  Fei Huang",
                "发布日期": "2022-02-18",
                "摘要": "  Named Entity Recognition (NER) from speech is among Spoken Language\nUnderstanding (SLU) tasks, aiming to extract semantic information from the\nspeech signal. NER from speech is usually made through a two-step pipeline that\nconsists of (1) processing the audio using an Automatic Speech Recognition\n(ASR) system and (2) applying an NER tagger to the ASR outputs. Recent works\nhave shown the capability of the End-to-End (E2E) approach for NER from English\nand French speech, which is essentially entity-aware ASR. However, due to the\nmany homophones and polyphones that exist in Chinese, NER from Chinese speech\nis effectively a more challenging task. In this paper, we introduce a new\ndataset AISEHLL-NER for NER from Chinese speech. Extensive experiments are\nconducted to explore the performance of several state-of-the-art methods. The\nresults demonstrate that the performance could be improved by combining\nentity-aware ASR and pretrained NER tagger, which can be easily applied to the\nmodern SLU pipeline. The dataset is publicly available at\ngithub.com/Alibaba-NLP/AISHELL-NER.\n",
                "链接": "https://arxiv.org/abs/2202.08533"
            },
            {
                "文章ID": "67040",
                "标题": "BanglaCoNER: Towards Robust Bangla Complex Named Entity Recognition",
                "作者": " HAZ Sameen Shahgir,  Ramisa Alam,  Md. Zarif Ul Alam",
                "发布日期": "2023-03-20",
                "摘要": "  Named Entity Recognition (NER) is a fundamental task in natural language\nprocessing that involves identifying and classifying named entities in text.\nBut much work hasn't been done for complex named entity recognition in Bangla,\ndespite being the seventh most spoken language globally. CNER is a more\nchallenging task than traditional NER as it involves identifying and\nclassifying complex and compound entities, which are not common in Bangla\nlanguage. In this paper, we present the winning solution of Bangla Complex\nNamed Entity Recognition Challenge - addressing the CNER task on BanglaCoNER\ndataset using two different approaches, namely Conditional Random Fields (CRF)\nand finetuning transformer based Deep Learning models such as BanglaBERT.\n  The dataset consisted of 15300 sentences for training and 800 sentences for\nvalidation, in the .conll format. Exploratory Data Analysis (EDA) on the\ndataset revealed that the dataset had 7 different NER tags, with notable\npresence of English words, suggesting that the dataset is synthetic and likely\na product of translation.\n  We experimented with a variety of feature combinations including Part of\nSpeech (POS) tags, word suffixes, Gazetteers, and cluster information from\nembeddings, while also finetuning the BanglaBERT (large) model for NER. We\nfound that not all linguistic patterns are immediately apparent or even\nintuitive to humans, which is why Deep Learning based models has proved to be\nthe more effective model in NLP, including CNER task. Our fine tuned BanglaBERT\n(large) model achieves an F1 Score of 0.79 on the validation set. Overall, our\nstudy highlights the importance of Bangla Complex Named Entity Recognition,\nparticularly in the context of synthetic datasets. Our findings also\ndemonstrate the efficacy of Deep Learning models such as BanglaBERT for NER in\nBangla language.\n",
                "链接": "https://arxiv.org/abs/2303.09306"
            },
            {
                "文章ID": "17226",
                "标题": "What do we Really Know about State of the Art NER?",
                "作者": " Sowmya Vajjala,  Ramya Balasubramaniam",
                "发布日期": "2022-05-05",
                "摘要": "  Named Entity Recognition (NER) is a well researched NLP task and is widely\nused in real world NLP scenarios. NER research typically focuses on the\ncreation of new ways of training NER, with relatively less emphasis on\nresources and evaluation. Further, state of the art (SOTA) NER models, trained\non standard datasets, typically report only a single performance measure\n(F-score) and we don't really know how well they do for different entity types\nand genres of text, or how robust are they to new, unseen entities. In this\npaper, we perform a broad evaluation of NER using a popular dataset, that takes\ninto consideration various text genres and sources constituting the dataset at\nhand. Additionally, we generate six new adversarial test sets through small\nperturbations in the original test set, replacing select entities while\nretaining the context. We also train and test our models on randomly generated\ntrain/dev/test splits followed by an experiment where the models are trained on\na select set of genres but tested genres not seen in training. These\ncomprehensive evaluation strategies were performed using three SOTA NER models.\nBased on our results, we recommend some useful reporting practices for NER\nresearchers, that could help in providing a better understanding of a SOTA\nmodel's performance in future.\n",
                "链接": "https://arxiv.org/abs/2205.00034"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用CrossWoz或MultiWoz数据集进行DST评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "46848",
                "标题": "MultiWOZ-DF -- A Dataflow implementation of the MultiWOZ dataset",
                "作者": " Joram Meron,  Victor Guimarães",
                "发布日期": "2022-11-07",
                "摘要": "  Semantic Machines (SM) have introduced the use of the dataflow (DF) paradigm\nto dialogue modelling, using computational graphs to hierarchically represent\nuser requests, data, and the dialogue history [Semantic Machines et al. 2020].\nAlthough the main focus of that paper was the SMCalFlow dataset (to date, the\nonly dataset with \"native\" DF annotations), they also reported some results of\nan experiment using a transformed version of the commonly used MultiWOZ dataset\n[Budzianowski et al. 2018] into a DF format. In this paper, we expand the\nexperiments using DF for the MultiWOZ dataset, exploring some additional\nexperimental set-ups. The code and instructions to reproduce the experiments\nreported here have been released. The contributions of this paper are: 1.) A DF\nimplementation capable of executing MultiWOZ dialogues; 2.) Several versions of\nconversion of MultiWOZ into a DF format are presented; 3.) Experimental results\non state match and translation accuracy.\n",
                "链接": "https://arxiv.org/abs/2211.02303"
            },
            {
                "文章ID": "112862",
                "标题": "Multi-User MultiWOZ: Task-Oriented Dialogues among Multiple Users",
                "作者": " Yohan Jo,  Xinyan Zhao,  Arijit Biswas,  Nikoletta Basiou,  Vincent Auvray,  Nikolaos Malandrakis,  Angeliki Metallinou,  Alexandros Potamianos",
                "发布日期": "2023-11-01",
                "摘要": "  While most task-oriented dialogues assume conversations between the agent and\none user at a time, dialogue systems are increasingly expected to communicate\nwith multiple users simultaneously who make decisions collaboratively. To\nfacilitate development of such systems, we release the Multi-User MultiWOZ\ndataset: task-oriented dialogues among two users and one agent. To collect this\ndataset, each user utterance from MultiWOZ 2.2 was replaced with a small chat\nbetween two users that is semantically and pragmatically consistent with the\noriginal user utterance, thus resulting in the same dialogue state and system\nresponse. These dialogues reflect interesting dynamics of collaborative\ndecision-making in task-oriented scenarios, e.g., social chatter and\ndeliberation. Supported by this data, we propose the novel task of multi-user\ncontextual query rewriting: to rewrite a task-oriented chat between two users\nas a concise task-oriented query that retains only task-relevant information\nand that is directly consumable by the dialogue system. We demonstrate that in\nmulti-user dialogues, using predicted rewrites substantially improves dialogue\nstate tracking without modifying existing dialogue systems that are trained for\nsingle-user dialogues. Further, this method surpasses training a medium-sized\nmodel directly on multi-user dialogues and generalizes to unseen domains.\n",
                "链接": "https://arxiv.org/abs/2310.20479"
            },
            {
                "文章ID": "45137",
                "标题": "Is MultiWOZ a Solved Task? An Interactive TOD Evaluation Framework with\n  User Simulator",
                "作者": " Qinyuan Cheng,  Linyang Li,  Guofeng Quan,  Feng Gao,  Xiaofeng Mou,  Xipeng Qiu",
                "发布日期": "2022-10-27",
                "摘要": "  Task-Oriented Dialogue (TOD) systems are drawing more and more attention in\nrecent studies. Current methods focus on constructing pre-trained models or\nfine-tuning strategies while the evaluation of TOD is limited by a policy\nmismatch problem. That is, during evaluation, the user utterances are from the\nannotated dataset while these utterances should interact with previous\nresponses which can have many alternatives besides annotated texts. Therefore,\nin this work, we propose an interactive evaluation framework for TOD. We first\nbuild a goal-oriented user simulator based on pre-trained models and then use\nthe user simulator to interact with the dialogue system to generate dialogues.\nBesides, we introduce a sentence-level and a session-level score to measure the\nsentence fluency and session coherence in the interactive evaluation.\nExperimental results show that RL-based TOD systems trained by our proposed\nuser simulator can achieve nearly 98% inform and success rates in the\ninteractive evaluation of MultiWOZ dataset and the proposed scores measure the\nresponse quality besides the inform and success rates. We are hoping that our\nwork will encourage simulator-based interactive evaluations in the TOD task.\n",
                "链接": "https://arxiv.org/abs/2210.14529"
            },
            {
                "文章ID": "37569",
                "标题": "SF-DST: Few-Shot Self-Feeding Reading Comprehension Dialogue State\n  Tracking with Auxiliary Task",
                "作者": " Jihyun Lee,  Gary Geunbae Lee",
                "发布日期": "2022-09-19",
                "摘要": "  Few-shot dialogue state tracking (DST) model tracks user requests in dialogue\nwith reliable accuracy even with a small amount of data. In this paper, we\nintroduce an ontology-free few-shot DST with self-feeding belief state input.\nThe self-feeding belief state input increases the accuracy in multi-turn\ndialogue by summarizing previous dialogue. Also, we newly developed a slot-gate\nauxiliary task. This new auxiliary task helps classify whether a slot is\nmentioned in the dialogue. Our model achieved the best score in a few-shot\nsetting for four domains on multiWOZ 2.0.\n",
                "链接": "https://arxiv.org/abs/2209.07742"
            },
            {
                "文章ID": "8498",
                "标题": "Mismatch between Multi-turn Dialogue and its Evaluation Metric in\n  Dialogue State Tracking",
                "作者": " Takyoung Kim,  Hoonsang Yoon,  Yukyung Lee,  Pilsung Kang,  Misuk Kim",
                "发布日期": "2022-04-01",
                "摘要": "  Dialogue state tracking (DST) aims to extract essential information from\nmulti-turn dialogue situations and take appropriate actions. A belief state,\none of the core pieces of information, refers to the subject and its specific\ncontent, and appears in the form of domain-slot-value. The trained model\npredicts \"accumulated\" belief states in every turn, and joint goal accuracy and\nslot accuracy are mainly used to evaluate the prediction; however, we specify\nthat the current evaluation metrics have a critical limitation when evaluating\nbelief states accumulated as the dialogue proceeds, especially in the most used\nMultiWOZ dataset. Additionally, we propose relative slot accuracy to complement\nexisting metrics. Relative slot accuracy does not depend on the number of\npredefined slots, and allows intuitive evaluation by assigning relative scores\naccording to the turn of each dialogue. This study also encourages not solely\nthe reporting of joint goal accuracy, but also various complementary metrics in\nDST tasks for the sake of a realistic evaluation.\n",
                "链接": "https://arxiv.org/abs/2203.03123"
            },
            {
                "文章ID": "14657",
                "标题": "XQA-DST: Multi-Domain and Multi-Lingual Dialogue State Tracking",
                "作者": " Han Zhou,  Ignacio Iacobacci,  Pasquale Minervini",
                "发布日期": "2023-02-28",
                "摘要": "  Dialogue State Tracking (DST), a crucial component of task-oriented dialogue\n(ToD) systems, keeps track of all important information pertaining to dialogue\nhistory: filling slots with the most probable values throughout the\nconversation. Existing methods generally rely on a predefined set of values and\nstruggle to generalise to previously unseen slots in new domains. To overcome\nthese challenges, we propose a domain-agnostic extractive question answering\n(QA) approach with shared weights across domains. To disentangle the complex\ndomain information in ToDs, we train our DST with a novel domain filtering\nstrategy by excluding out-of-domain question samples. With an independent\nclassifier that predicts the presence of multiple domains given the context,\nour model tackles DST by extracting spans in active domains. Empirical results\ndemonstrate that our model can efficiently leverage domain-agnostic QA datasets\nby two-stage fine-tuning while being both domain-scalable and open-vocabulary\nin DST. It shows strong transferability by achieving zero-shot\ndomain-adaptation results on MultiWOZ 2.1 with an average JGA of 36.7%. It\nfurther achieves cross-lingual transfer with state-of-the-art zero-shot\nresults, 66.2% JGA from English to German and 75.7% JGA from English to Italian\non WOZ 2.0.\n",
                "链接": "https://arxiv.org/abs/2204.05895"
            },
            {
                "文章ID": "109152",
                "标题": "UNO-DST: Leveraging Unlabelled Data in Zero-Shot Dialogue State Tracking",
                "作者": " Chuang Li,  Yan Zhang,  Min-Yen Kan,  Haizhou Li",
                "发布日期": "2023-10-17",
                "摘要": "  Previous zero-shot dialogue state tracking (DST) methods only apply transfer\nlearning, but ignore unlabelled data in the target domain. We transform\nzero-shot DST into few-shot DST by utilising such unlabelled data via joint and\nself-training methods. Our method incorporates auxiliary tasks that generate\nslot types as inverse prompts for main tasks, creating slot values during joint\ntraining. Cycle consistency between these two tasks enables the generation and\nselection of quality samples in unknown target domains for subsequent\nfine-tuning. This approach also facilitates automatic label creation, thereby\noptimizing the training and fine-tuning of DST models. We demonstrate this\nmethod's effectiveness on large language models in zero-shot scenarios,\nimproving average joint goal accuracy by $8\\%$ across all domains in MultiWOZ.\n",
                "链接": "https://arxiv.org/abs/2310.10492"
            },
            {
                "文章ID": "7222",
                "标题": "ASSIST: Towards Label Noise-Robust Dialogue State Tracking",
                "作者": " Fanghua Ye,  Yue Feng,  Emine Yilmaz",
                "发布日期": "2022-03-15",
                "摘要": "  The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state\ntracking (DST). However, substantial noise has been discovered in its state\nannotations. Such noise brings about huge challenges for training DST models\nrobustly. Although several refined versions, including MultiWOZ 2.1-2.4, have\nbeen published recently, there are still lots of noisy labels, especially in\nthe training set. Besides, it is costly to rectify all the problematic\nannotations. In this paper, instead of improving the annotation quality\nfurther, we propose a general framework, named ASSIST (lAbel noiSe-robuSt\ndIalogue State Tracking), to train DST models robustly from noisy labels.\nASSIST first generates pseudo labels for each sample in the training set by\nusing an auxiliary model trained on a small clean dataset, then puts the\ngenerated pseudo labels and vanilla noisy labels together to train the primary\nmodel. We show the validity of ASSIST theoretically. Experimental results also\ndemonstrate that ASSIST improves the joint goal accuracy of DST by up to\n$28.16\\%$ on MultiWOZ 2.0 and $8.41\\%$ on MultiWOZ 2.4, compared to using only\nthe vanilla noisy labels.\n",
                "链接": "https://arxiv.org/abs/2202.13024"
            },
            {
                "文章ID": "32158",
                "标题": "Act-Aware Slot-Value Predicting in Multi-Domain Dialogue State Tracking",
                "作者": " Ruolin Su,  Ting-Wei Wu,  Biing-Hwang Juang",
                "发布日期": "2022-08-05",
                "摘要": "  As an essential component in task-oriented dialogue systems, dialogue state\ntracking (DST) aims to track human-machine interactions and generate state\nrepresentations for managing the dialogue. Representations of dialogue states\nare dependent on the domain ontology and the user's goals. In several\ntask-oriented dialogues with a limited scope of objectives, dialogue states can\nbe represented as a set of slot-value pairs. As the capabilities of dialogue\nsystems expand to support increasing naturalness in communication,\nincorporating dialogue act processing into dialogue model design becomes\nessential. The lack of such consideration limits the scalability of dialogue\nstate tracking models for dialogues having specific objectives and ontology. To\naddress this issue, we formulate and incorporate dialogue acts, and leverage\nrecent advances in machine reading comprehension to predict both categorical\nand non-categorical types of slots for multi-domain dialogue state tracking.\nExperimental results show that our models can improve the overall accuracy of\ndialogue state tracking on the MultiWOZ 2.1 dataset, and demonstrate that\nincorporating dialogue acts can guide dialogue state design for future\ntask-oriented dialogue systems.\n",
                "链接": "https://arxiv.org/abs/2208.02462"
            },
            {
                "文章ID": "102377",
                "标题": "S3-DST: Structured Open-Domain Dialogue Segmentation and State Tracking\n  in the Era of LLMs",
                "作者": " Sarkar Snigdha Sarathi Das,  Chirag Shah,  Mengting Wan,  Jennifer Neville,  Longqi Yang,  Reid Andersen,  Georg Buscher,  Tara Safavi",
                "发布日期": "2023-09-19",
                "摘要": "  The traditional Dialogue State Tracking (DST) problem aims to track user\npreferences and intents in user-agent conversations. While sufficient for\ntask-oriented dialogue systems supporting narrow domain applications, the\nadvent of Large Language Model (LLM)-based chat systems has introduced many\nreal-world intricacies in open-domain dialogues. These intricacies manifest in\nthe form of increased complexity in contextual interactions, extended dialogue\nsessions encompassing a diverse array of topics, and more frequent contextual\nshifts. To handle these intricacies arising from evolving LLM-based chat\nsystems, we propose joint dialogue segmentation and state tracking per segment\nin open-domain dialogue systems. Assuming a zero-shot setting appropriate to a\ntrue open-domain dialogue system, we propose S3-DST, a structured prompting\ntechnique that harnesses Pre-Analytical Recollection, a novel grounding\nmechanism we designed for improving long context tracking. To demonstrate the\nefficacy of our proposed approach in joint segmentation and state tracking, we\nevaluate S3-DST on a proprietary anonymized open-domain dialogue dataset, as\nwell as publicly available DST and segmentation datasets. Across all datasets\nand settings, S3-DST consistently outperforms the state-of-the-art,\ndemonstrating its potency and robustness the next generation of LLM-based chat\nsystems.\n",
                "链接": "https://arxiv.org/abs/2309.08827"
            }
        ]
    },
    {
        "question": {
            "question": "2023年后利用hotpotqa数据集做问题生成任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "85143",
                "标题": "Weakly Supervised Visual Question Answer Generation",
                "作者": " Charani Alampalle,  Shamanthak Hegde,  Soumya Jahagirdar,  Shankar Gangisetty",
                "发布日期": "2023-09-12",
                "摘要": "  Growing interest in conversational agents promote twoway human-computer\ncommunications involving asking and answering visual questions have become an\nactive area of research in AI. Thus, generation of visual questionanswer\npair(s) becomes an important and challenging task. To address this issue, we\npropose a weakly-supervised visual question answer generation method that\ngenerates a relevant question-answer pairs for a given input image and\nassociated caption. Most of the prior works are supervised and depend on the\nannotated question-answer datasets. In our work, we present a weakly supervised\nmethod that synthetically generates question-answer pairs procedurally from\nvisual information and captions. The proposed method initially extracts list of\nanswer words, then does nearest question generation that uses the caption and\nanswer word to generate synthetic question. Next, the relevant question\ngenerator converts the nearest question to relevant language question by\ndependency parsing and in-order tree traversal, finally, fine-tune a ViLBERT\nmodel with the question-answer pair(s) generated at end. We perform an\nexhaustive experimental analysis on VQA dataset and see that our model\nsignificantly outperform SOTA methods on BLEU scores. We also show the results\nwrt baseline models and ablation study.\n",
                "链接": "https://arxiv.org/abs/2306.06622"
            },
            {
                "文章ID": "108331",
                "标题": "Visual Question Generation in Bengali",
                "作者": " Mahmud Hasan,  Labiba Islam,  Jannatul Ferdous Ruma,  Tasmiah Tahsin Mayeesha,  Rashedur M. Rahman",
                "发布日期": "2023-10-13",
                "摘要": "  The task of Visual Question Generation (VQG) is to generate human-like\nquestions relevant to the given image. As VQG is an emerging research field,\nexisting works tend to focus only on resource-rich language such as English due\nto the availability of datasets. In this paper, we propose the first Bengali\nVisual Question Generation task and develop a novel transformer-based\nencoder-decoder architecture that generates questions in Bengali when given an\nimage. We propose multiple variants of models - (i) image-only: baseline model\nof generating questions from images without additional information, (ii)\nimage-category and image-answer-category: guided VQG where we condition the\nmodel to generate questions based on the answer and the category of expected\nquestion. These models are trained and evaluated on the translated VQAv2.0\ndataset. Our quantitative and qualitative results establish the first state of\nthe art models for VQG task in Bengali and demonstrate that our models are\ncapable of generating grammatically correct and relevant questions. Our\nquantitative results show that our image-cat model achieves a BLUE-1 score of\n33.12 and BLEU-3 score of 7.56 which is the highest of the other two variants.\nWe also perform a human evaluation to assess the quality of the generation\ntasks. Human evaluation suggests that image-cat model is capable of generating\ngoal-driven and attribute-specific questions and also stays relevant to the\ncorresponding image.\n",
                "链接": "https://arxiv.org/abs/2310.08187"
            },
            {
                "文章ID": "104456",
                "标题": "Automating question generation from educational text",
                "作者": " Ayan Kumar Bhowmick,  Ashish Jagmohan,  Aditya Vempaty,  Prasenjit Dey,  Leigh Hall,  Jeremy Hartman,  Ravi Kokku,  Hema Maheshwari",
                "发布日期": "2023-09-27",
                "摘要": "  The use of question-based activities (QBAs) is wide-spread in education,\ntraditionally forming an integral part of the learning and assessment process.\nIn this paper, we design and evaluate an automated question generation tool for\nformative and summative assessment in schools. We present an expert survey of\none hundred and four teachers, demonstrating the need for automated generation\nof QBAs, as a tool that can significantly reduce the workload of teachers and\nfacilitate personalized learning experiences. Leveraging the recent\nadvancements in generative AI, we then present a modular framework employing\ntransformer based language models for automatic generation of multiple-choice\nquestions (MCQs) from textual content. The presented solution, with distinct\nmodules for question generation, correct answer prediction, and distractor\nformulation, enables us to evaluate different language models and generation\ntechniques. Finally, we perform an extensive quantitative and qualitative\nevaluation, demonstrating trade-offs in the use of different techniques and\nmodels.\n",
                "链接": "https://arxiv.org/abs/2309.15004"
            },
            {
                "文章ID": "74474",
                "标题": "Using Implicit Feedback to Improve Question Generation",
                "作者": " Hugo Rodrigues,  Eric Nyberg,  Luisa Coheur",
                "发布日期": "2023-04-27",
                "摘要": "  Question Generation (QG) is a task of Natural Language Processing (NLP) that\naims at automatically generating questions from text. Many applications can\nbenefit from automatically generated questions, but often it is necessary to\ncurate those questions, either by selecting or editing them. This task is\ninformative on its own, but it is typically done post-generation, and, thus,\nthe effort is wasted. In addition, most existing systems cannot incorporate\nthis feedback back into them easily. In this work, we present a system, GEN,\nthat learns from such (implicit) feedback. Following a pattern-based approach,\nit takes as input a small set of sentence/question pairs and creates patterns\nwhich are then applied to new unseen sentences. Each generated question, after\nbeing corrected by the user, is used as a new seed in the next iteration, so\nmore patterns are created each time. We also take advantage of the corrections\nmade by the user to score the patterns and therefore rank the generated\nquestions. Results show that GEN is able to improve by learning from both\nlevels of implicit feedback when compared to the version with no learning,\nconsidering the top 5, 10, and 20 questions. Improvements go up from 10%,\ndepending on the metric and strategy used.\n",
                "链接": "https://arxiv.org/abs/2304.13664"
            },
            {
                "文章ID": "87964",
                "标题": "Towards Enriched Controllability for Educational Question Generation",
                "作者": " Bernardo Leite,  Henrique Lopes Cardoso",
                "发布日期": "2023-06-28",
                "摘要": "  Question Generation (QG) is a task within Natural Language Processing (NLP)\nthat involves automatically generating questions given an input, typically\ncomposed of a text and a target answer. Recent work on QG aims to control the\ntype of generated questions so that they meet educational needs. A remarkable\nexample of controllability in educational QG is the generation of questions\nunderlying certain narrative elements, e.g., causal relationship, outcome\nresolution, or prediction. This study aims to enrich controllability in QG by\nintroducing a new guidance attribute: question explicitness. We propose to\ncontrol the generation of explicit and implicit wh-questions from\nchildren-friendly stories. We show preliminary evidence of controlling QG via\nquestion explicitness alone and simultaneously with another target attribute:\nthe question's narrative element. The code is publicly available at\ngithub.com/bernardoleite/question-generation-control.\n",
                "链接": "https://arxiv.org/abs/2306.14917"
            },
            {
                "文章ID": "111349",
                "标题": "Diversity Enhanced Narrative Question Generation for Storybooks",
                "作者": " Hokeun Yoon,  JinYeong Bak",
                "发布日期": "2023-10-26",
                "摘要": "  Question generation (QG) from a given context can enhance comprehension,\nengagement, assessment, and overall efficacy in learning or conversational\nenvironments. Despite recent advancements in QG, the challenge of enhancing or\nmeasuring the diversity of generated questions often remains unaddressed. In\nthis paper, we introduce a multi-question generation model (mQG), which is\ncapable of generating multiple, diverse, and answerable questions by focusing\non context and questions. To validate the answerability of the generated\nquestions, we employ a SQuAD2.0 fine-tuned question answering model,\nclassifying the questions as answerable or not. We train and evaluate mQG on\nthe FairytaleQA dataset, a well-structured QA dataset based on storybooks, with\nnarrative questions. We further apply a zero-shot adaptation on the TellMeWhy\nand SQuAD1.1 datasets. mQG shows promising results across various evaluation\nmetrics, among strong baselines.\n",
                "链接": "https://arxiv.org/abs/2310.16446"
            },
            {
                "文章ID": "58927",
                "标题": "Zero-shot Clarifying Question Generation for Conversational Search",
                "作者": " Zhenduo Wang,  Yuancheng Tu,  Corby Rosset,  Nick Craswell,  Ming Wu,  Qingyao Ai",
                "发布日期": "2023-02-13",
                "摘要": "  A long-standing challenge for search and conversational assistants is query\nintention detection in ambiguous queries. Asking clarifying questions in\nconversational search has been widely studied and considered an effective\nsolution to resolve query ambiguity. Existing work have explored various\napproaches for clarifying question ranking and generation. However, due to the\nlack of real conversational search data, they have to use artificial datasets\nfor training, which limits their generalizability to real-world search\nscenarios. As a result, the industry has shown reluctance to implement them in\nreality, further suspending the availability of real conversational search\ninteraction data. The above dilemma can be formulated as a cold start problem\nof clarifying question generation and conversational search in general.\nFurthermore, even if we do have large-scale conversational logs, it is not\nrealistic to gather training data that can comprehensively cover all possible\nqueries and topics in open-domain search scenarios. The risk of fitting bias\nwhen training a clarifying question retrieval/generation model on\nincomprehensive dataset is thus another important challenge.\n  In this work, we innovatively explore generating clarifying questions in a\nzero-shot setting to overcome the cold start problem and we propose a\nconstrained clarifying question generation system which uses both question\ntemplates and query facets to guide the effective and precise question\ngeneration. The experiment results show that our method outperforms existing\nstate-of-the-art zero-shot baselines by a large margin. Human annotations to\nour model outputs also indicate our method generates 25.2\\% more natural\nquestions, 18.1\\% more useful questions, 6.1\\% less unnatural and 4\\% less\nuseless questions.\n",
                "链接": "https://arxiv.org/abs/2301.12660"
            },
            {
                "文章ID": "112250",
                "标题": "Prompt-Engineering and Transformer-based Question Generation and\n  Evaluation",
                "作者": " Rubaba Amyeen",
                "发布日期": "2023-10-31",
                "摘要": "  Question generation has numerous applications in the educational context.\nQuestion generation can prove helpful for students when reviewing content and\ntesting themselves. Furthermore, a question generation model can aid teachers\nby lessening the burden of creating assessments and other practice material.\nThis paper aims to find the best method to generate questions from textual data\nthrough a transformer model and prompt engineering. In this research, we\nfinetuned a pretrained distilBERT model on the SQuAD question answering dataset\nto generate questions. In addition to training a transformer model, prompt\nengineering was applied to generate questions effectively using the LLaMA\nmodel. The generated questions were compared against the baseline questions in\nthe SQuAD dataset to evaluate the effectiveness of four different prompts. All\nfour prompts demonstrated over 60% similarity on average. Of the\nprompt-generated questions, 30% achieved a high similarity score greater than\n70%.\n",
                "链接": "https://arxiv.org/abs/2310.18867"
            },
            {
                "文章ID": "101214",
                "标题": "FOLLOWUPQG: Towards Information-Seeking Follow-up Question Generation",
                "作者": " Yan Meng,  Liangming Pan,  Yixin Cao,  Min-Yen Kan",
                "发布日期": "2023-09-20",
                "摘要": "  Humans ask follow-up questions driven by curiosity, which reflects a creative\nhuman cognitive process. We introduce the task of real-world\ninformation-seeking follow-up question generation (FQG), which aims to generate\nfollow-up questions seeking a more in-depth understanding of an initial\nquestion and answer. We construct FOLLOWUPQG, a dataset of over 3K real-world\n(initial question, answer, follow-up question) tuples collected from a Reddit\nforum providing layman-friendly explanations for open-ended questions. In\ncontrast to existing datasets, questions in FOLLOWUPQG use more diverse\npragmatic strategies to seek information, and they also show higher-order\ncognitive skills (such as applying and relating). We evaluate current question\ngeneration models on their efficacy for generating follow-up questions,\nexploring how to generate specific types of follow-up questions based on\nstep-by-step demonstrations. Our results validate FOLLOWUPQG as a challenging\nbenchmark, as model-generated questions are adequate but far from human-raised\nquestions in terms of informativeness and complexity.\n",
                "链接": "https://arxiv.org/abs/2309.05007"
            },
            {
                "文章ID": "84676",
                "标题": "Modular Visual Question Answering via Code Generation",
                "作者": " Sanjay Subramanian,  Medhini Narasimhan,  Kushal Khangaonkar,  Kevin Yang,  Arsha Nagrani,  Cordelia Schmid,  Andy Zeng,  Trevor Darrell,  Dan Klein",
                "发布日期": "2023-06-09",
                "摘要": "  We present a framework that formulates visual question answering as modular\ncode generation. In contrast to prior work on modular approaches to VQA, our\napproach requires no additional training and relies on pre-trained language\nmodels (LMs), visual models pre-trained on image-caption pairs, and fifty VQA\nexamples used for in-context learning. The generated Python programs invoke and\ncompose the outputs of the visual models using arithmetic and conditional\nlogic. Our approach improves accuracy on the COVR dataset by at least 3% and on\nthe GQA dataset by roughly 2% compared to the few-shot baseline that does not\nemploy code generation.\n",
                "链接": "https://arxiv.org/abs/2306.05392"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用机器学习方法进行心理健康疾病研究的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "104767",
                "标题": "Identifying Risk Factors for Post-COVID-19 Mental Health Disorders: A\n  Machine Learning Perspective",
                "作者": " Maitham G. Yousif,  Fadhil G. Al-Amran,  Hector J. Castro",
                "发布日期": "2023-09-29",
                "摘要": "  In this study, we leveraged machine learning techniques to identify risk\nfactors associated with post-COVID-19 mental health disorders. Our analysis,\nbased on data collected from 669 patients across various provinces in Iraq,\nyielded valuable insights. We found that age, gender, and geographical region\nof residence were significant demographic factors influencing the likelihood of\ndeveloping mental health disorders in post-COVID-19 patients. Additionally,\ncomorbidities and the severity of COVID-19 illness were important clinical\npredictors. Psychosocial factors, such as social support, coping strategies,\nand perceived stress levels, also played a substantial role. Our findings\nemphasize the complex interplay of multiple factors in the development of\nmental health disorders following COVID-19 recovery. Healthcare providers and\npolicymakers should consider these risk factors when designing targeted\ninterventions and support systems for individuals at risk. Machine\nlearning-based approaches can provide a valuable tool for predicting and\npreventing adverse mental health outcomes in post-COVID-19 patients. Further\nresearch and prospective studies are needed to validate these findings and\nenhance our understanding of the long-term psychological impact of the COVID-19\npandemic. This study contributes to the growing body of knowledge regarding the\nmental health consequences of the COVID-19 pandemic and underscores the\nimportance of a multidisciplinary approach to address the diverse needs of\nindividuals on the path to recovery. Keywords: COVID-19, mental health, risk\nfactors, machine learning, Iraq\n",
                "链接": "https://arxiv.org/abs/2309.16055"
            },
            {
                "文章ID": "29057",
                "标题": "Towards Knowledge-based Mining of Mental Disorder Patterns from Textual\n  Data",
                "作者": " Maryam Shahabikargar",
                "发布日期": "2022-07-14",
                "摘要": "  Mental health disorders may cause severe consequences on all the countries'\neconomies and health. For example, the impacts of the COVID-19 pandemic, such\nas isolation and travel ban, can make us feel depressed. Identifying early\nsigns of mental health disorders is vital. For example, depression may increase\nan individual's risk of suicide. The state-of-the-art research in identifying\nmental disorder patterns from textual data, uses hand-labelled training sets,\nespecially when a domain expert's knowledge is required to analyse various\nsymptoms. This task could be time-consuming and expensive. To address this\nchallenge, in this paper, we study and analyse the various clinical and\nnon-clinical approaches to identifying mental health disorders. We leverage the\ndomain knowledge and expertise in cognitive science to build a domain-specific\nKnowledge Base (KB) for the mental health disorder concepts and patterns. We\npresent a weaker form of supervision by facilitating the generating of training\ndata from a domain-specific Knowledge Base (KB). We adopt a typical scenario\nfor analysing social media to identify major depressive disorder symptoms from\nthe textual content generated by social users. We use this scenario to evaluate\nhow our knowledge-based approach significantly improves the quality of results.\n",
                "链接": "https://arxiv.org/abs/2207.06254"
            },
            {
                "文章ID": "88540",
                "标题": "Harnessing the Power of Hugging Face Transformers for Predicting Mental\n  Health Disorders in Social Networks",
                "作者": " Alireza Pourkeyvan,  Ramin Safa,  Ali Sorourkhah",
                "发布日期": "2023-07-03",
                "摘要": "  Early diagnosis of mental disorders and intervention can facilitate the\nprevention of severe injuries and the improvement of treatment results. Using\nsocial media and pre-trained language models, this study explores how\nuser-generated data can be used to predict mental disorder symptoms. Our study\ncompares four different BERT models of Hugging Face with standard machine\nlearning techniques used in automatic depression diagnosis in recent\nliterature. The results show that new models outperform the previous approach\nwith an accuracy rate of up to 97%. Analyzing the results while complementing\npast findings, we find that even tiny amounts of data (like users' bio\ndescriptions) have the potential to predict mental disorders. We conclude that\nsocial media data is an excellent source of mental health screening, and\npre-trained models can effectively automate this critical task.\n",
                "链接": "https://arxiv.org/abs/2306.16891"
            },
            {
                "文章ID": "114640",
                "标题": "Mental Health Diagnosis in the Digital Age: Harnessing Sentiment\n  Analysis on Social Media Platforms upon Ultra-Sparse Feature Content",
                "作者": " Haijian Shao,  Ming Zhu,  Shengjie Zhai",
                "发布日期": "2023-11-10",
                "摘要": "  Amid growing global mental health concerns, particularly among vulnerable\ngroups, natural language processing offers a tremendous potential for early\ndetection and intervention of people's mental disorders via analyzing their\npostings and discussions on social media platforms. However, ultra-sparse\ntraining data, often due to vast vocabularies and low-frequency words, hinders\nthe analysis accuracy. Multi-labeling and Co-occurrences of symptoms may also\nblur the boundaries in distinguishing similar/co-related disorders. To address\nthese issues, we propose a novel semantic feature preprocessing technique with\na three-folded structure: 1) mitigating the feature sparsity with a weak\nclassifier, 2) adaptive feature dimension with modulus loops, and 3)\ndeep-mining and extending features among the contexts. With enhanced semantic\nfeatures, we train a machine learning model to predict and classify mental\ndisorders. We utilize the Reddit Mental Health Dataset 2022 to examine\nconditions such as Anxiety, Borderline Personality Disorder (BPD), and\nBipolar-Disorder (BD) and present solutions to the data sparsity challenge,\nhighlighted by 99.81% non-zero elements. After applying our preprocessing\ntechnique, the feature sparsity decreases to 85.4%. Overall, our methods, when\ncompared to seven benchmark models, demonstrate significant performance\nimprovements: 8.0% in accuracy, 0.069 in precision, 0.093 in recall, 0.102 in\nF1 score, and 0.059 in AUC. This research provides foundational insights for\nmental health prediction and monitoring, providing innovative solutions to\nnavigate challenges associated with ultra-sparse data feature and intricate\nmulti-label classification in the domain of mental health analysis.\n",
                "链接": "https://arxiv.org/abs/2311.05075"
            },
            {
                "文章ID": "98633",
                "标题": "Discovering Mental Health Research Topics with Topic Modeling",
                "作者": " Xin Gao,  Cem Sazara",
                "发布日期": "2023-08-29",
                "摘要": "  Mental health significantly influences various aspects of our daily lives,\nand its importance has been increasingly recognized by the research community\nand the general public, particularly in the wake of the COVID-19 pandemic. This\nheightened interest is evident in the growing number of publications dedicated\nto mental health in the past decade. In this study, our goal is to identify\ngeneral trends in the field and pinpoint high-impact research topics by\nanalyzing a large dataset of mental health research papers. To accomplish this,\nwe collected abstracts from various databases and trained a customized\nSentence-BERT based embedding model leveraging the BERTopic framework. Our\ndataset comprises 96,676 research papers pertaining to mental health, enabling\nus to examine the relationships between different topics using their abstracts.\nTo evaluate the effectiveness of the model, we compared it against two other\nstate-of-the-art methods: Top2Vec model and LDA-BERT model. The model\ndemonstrated superior performance in metrics that measure topic diversity and\ncoherence. To enhance our analysis, we also generated word clouds to provide a\ncomprehensive overview of the machine learning models applied in mental health\nresearch, shedding light on commonly utilized techniques and emerging trends.\nFurthermore, we provide a GitHub link* to the dataset used in this paper,\nensuring its accessibility for further research endeavors.\n",
                "链接": "https://arxiv.org/abs/2308.13569"
            },
            {
                "文章ID": "58217",
                "标题": "Predicting mental health using social media: A roadmap for future\n  development",
                "作者": " Ramin Safa,  S. A. Edalatpanah,  Ali Sorourkhah",
                "发布日期": "2023-01-26",
                "摘要": "  Mental disorders such as depression and suicidal ideation are hazardous,\naffecting more than 300 million people over the world. However, on social\nmedia, mental disorder symptoms can be observed, and automated approaches are\nincreasingly capable of detecting them. The considerable number of social media\nusers and the tremendous quantity of user-generated data on social platforms\nprovide a unique opportunity for researchers to distinguish patterns that\ncorrelate with mental status. This research offers a roadmap for analysis,\nwhere mental state detection can be based on machine learning techniques. We\ndescribe the common approaches for predicting and identifying the disorder\nusing user-generated content. This research is organized according to the data\ncollection, feature extraction, and prediction algorithms. Furthermore, we\nreview several recent studies conducted to explore different features of\ncandidate profiles and their analytical methods. Following, we debate various\naspects of the development of experimental auto-detection frameworks for\nidentifying users who suffer from disorders, and we conclude with a discussion\nof future trends. The introduced methods can help complement screening\nprocedures, identify at-risk people through social media monitoring on a large\nscale, and make disorders easier to treat in the future.\n",
                "链接": "https://arxiv.org/abs/2301.10453"
            },
            {
                "文章ID": "84095",
                "标题": "Utterance Classification with Logical Neural Network: Explainable AI for\n  Mental Disorder Diagnosis",
                "作者": " Yeldar Toleubay,  Don Joven Agravante,  Daiki Kimura,  Baihan Lin,  Djallel Bouneffouf,  Michiaki Tatsubori",
                "发布日期": "2023-06-07",
                "摘要": "  In response to the global challenge of mental health problems, we proposes a\nLogical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis\nof mental disorders. Due to the lack of effective therapy coverage for mental\ndisorders, there is a need for an AI solution that can assist therapists with\nthe diagnosis. However, current Neural Network models lack explainability and\nmay not be trusted by therapists. The LNN is a Recurrent Neural Network\narchitecture that combines the learning capabilities of neural networks with\nthe reasoning capabilities of classical logic-based AI. The proposed system\nuses input predicates from clinical interviews to output a mental disorder\nclass, and different predicate pruning techniques are used to achieve\nscalability and higher scores. In addition, we provide an insight extraction\nmethod to aid therapists with their diagnosis. The proposed system addresses\nthe lack of explainability of current Neural Network models and provides a more\ntrustworthy solution for mental disorder diagnosis.\n",
                "链接": "https://arxiv.org/abs/2306.03902"
            },
            {
                "文章ID": "92064",
                "标题": "Technology in Association With Mental Health: Meta-ethnography",
                "作者": " Hamza Mohammed",
                "发布日期": "2023-07-28",
                "摘要": "  This research paper presents a meta-analysis of the multifaceted role of\ntechnology in mental health. The pervasive influence of technology on daily\nlives necessitates a deep understanding of its impact on mental health\nservices. This study synthesizes literature covering Behavioral Intervention\nTechnologies (BITs), digital mental health interventions during COVID-19, young\nmen's attitudes toward mental health technologies, technology-based\ninterventions for university students, and the applicability of mobile health\ntechnologies for individuals with serious mental illnesses. BITs are recognized\nfor their potential to provide evidence-based interventions for mental health\nconditions, especially anxiety disorders. The COVID-19 pandemic acted as a\ncatalyst for the adoption of digital mental health services, underscoring their\ncrucial role in providing accessible and quality care; however, their efficacy\nneeds to be reinforced by workforce training, high-quality evidence, and\ndigital equity. A nuanced understanding of young men's attitudes toward mental\nhealth is imperative for devising effective online services. Technology-based\ninterventions for university students are promising, although variable in\neffectiveness; their deployment must be evidence-based and tailored to\nindividual needs. Mobile health technologies, particularly activity tracking,\nhold promise for individuals with serious mental illnesses. Collectively,\ntechnology has immense potential to revolutionize mental health care. However,\nthe implementation must be evidence-based, ethical, and equitable, with\ncontinued research focusing on experiences across diverse populations, ensuring\naccessibility and efficacy for all.\n",
                "链接": "https://arxiv.org/abs/2307.10513"
            },
            {
                "文章ID": "13268",
                "标题": "Extended Reality for Anxiety and Depression Therapy amidst Mental\n  Disorders -- A Systematic Review",
                "作者": " Omisore Olatunji,  Ifeanyi Odenigbo,  Joseph Orji,  Amelia Beltran,  Rita Orji,  Nilufar Baghaei,  Meier Sandra",
                "发布日期": "2022-04-05",
                "摘要": "  This systematic study is aimed to investigate the implementation level of\ndifferent extended reality (XR) techniques in the care of mental disorder. We\npoint out some XR technologies used to deliver care for mental disorders, and\nto evaluate the effectiveness of using XR systems for anxiety and depression\namidst other mental disorders. A search period of May 2017 and August 2021 was\ndefined to filter out articles related to the usage of virtual reality (VR),\naugmented reality (AR) and mixed reality (AR) in a mental health context.\nSearch done on three databases namely Google Scholar, PubMED, and Association\nfor Computing Machinery Digital Library yielded 689 articles. Also, 10 articles\nwere recommended. Upon eligibility filtering, only 72 articles were found\nrelevant and were utilized for the study. Results show that the 72 studies were\ndone in only 23 countries across the globe, with the majority of studies being\nreported for developed countries such as USA (20.64%) and Germany (11.11%).\nThus this could rapidly aid intervention of mental health disorder with XR.\nMeanwhile, none of the studies observed was from an African country. The\nmajority of the articles reported that XR techniques led to significant\nreduction in symptoms of anxiety or depression. The majority of studies (23,\n36.51%) were published in the year 2021 of the total studies included. In a\nsense, this data might be attributed to COVID-19 pandemic. Most studies (30,\n47.62%) focused a population with age range of 18 to 65 years, while fewer\nstudies (4, 6.35%) focused on each of adolescents (10 - 19 years) and seniors\n(over 64 years). Also, more studies were done experimentally (52, 82.54%)\nrather than by analytical and modeling approach (5, 7.94%) as found in other XR\nstudies domain. This review study could aid the development of XR systems for\neffective cognitive behavioral and exposure therapies of mental disorders.\n",
                "链接": "https://arxiv.org/abs/2204.01348"
            },
            {
                "文章ID": "27506",
                "标题": "Mental Illness Classification on Social Media Texts using Deep Learning\n  and Transfer Learning",
                "作者": " Iqra Ameer,  Muhammad Arif,  Grigori Sidorov,  Helena Gòmez-Adorno,  Alexander Gelbukh",
                "发布日期": "2022-07-05",
                "摘要": "  Given the current social distance restrictions across the world, most\nindividuals now use social media as their major medium of communication.\nMillions of people suffering from mental diseases have been isolated due to\nthis, and they are unable to get help in person. They have become more reliant\non online venues to express themselves and seek advice on dealing with their\nmental disorders. According to the World health organization (WHO),\napproximately 450 million people are affected. Mental illnesses, such as\ndepression, anxiety, etc., are immensely common and have affected an\nindividuals' physical health. Recently Artificial Intelligence (AI) methods\nhave been presented to help mental health providers, including psychiatrists\nand psychologists, in decision making based on patients' authentic information\n(e.g., medical records, behavioral data, social media utilization, etc.). AI\ninnovations have demonstrated predominant execution in numerous real-world\napplications broadening from computer vision to healthcare. This study analyzes\nunstructured user data on the Reddit platform and classifies five common mental\nillnesses: depression, anxiety, bipolar disorder, ADHD, and PTSD. We trained\ntraditional machine learning, deep learning, and transfer learning multi-class\nmodels to detect mental disorders of individuals. This effort will benefit the\npublic health system by automating the detection process and informing\nappropriate authorities about people who require emergency assistance.\n",
                "链接": "https://arxiv.org/abs/2207.01012"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "107726",
                "标题": "Data efficient deep learning for medical image analysis: A survey",
                "作者": " Suruchi Kumari,  Pravendra Singh",
                "发布日期": "2023-10-11",
                "摘要": "  The rapid evolution of deep learning has significantly advanced the field of\nmedical image analysis. However, despite these achievements, the further\nenhancement of deep learning models for medical image analysis faces a\nsignificant challenge due to the scarcity of large, well-annotated datasets. To\naddress this issue, recent years have witnessed a growing emphasis on the\ndevelopment of data-efficient deep learning methods. This paper conducts a\nthorough review of data-efficient deep learning methods for medical image\nanalysis. To this end, we categorize these methods based on the level of\nsupervision they rely on, encompassing categories such as no supervision,\ninexact supervision, incomplete supervision, inaccurate supervision, and only\nlimited supervision. We further divide these categories into finer\nsubcategories. For example, we categorize inexact supervision into multiple\ninstance learning and learning with weak annotations. Similarly, we categorize\nincomplete supervision into semi-supervised learning, active learning, and\ndomain-adaptive learning and so on. Furthermore, we systematically summarize\ncommonly used datasets for data efficient deep learning in medical image\nanalysis and investigate future research directions to conclude this survey.\n",
                "链接": "https://arxiv.org/abs/2310.06557"
            },
            {
                "文章ID": "69437",
                "标题": "Medical Image Analysis using Deep Relational Learning",
                "作者": " Zhihua Liu",
                "发布日期": "2023-03-29",
                "摘要": "  In the past ten years, with the help of deep learning, especially the rapid\ndevelopment of deep neural networks, medical image analysis has made remarkable\nprogress. However, how to effectively use the relational information between\nvarious tissues or organs in medical images is still a very challenging\nproblem, and it has not been fully studied. In this thesis, we propose two\nnovel solutions to this problem based on deep relational learning. First, we\npropose a context-aware fully convolutional network that effectively models\nimplicit relation information between features to perform medical image\nsegmentation. The network achieves the state-of-the-art segmentation results on\nthe Multi Modal Brain Tumor Segmentation 2017 (BraTS2017) and Multi Modal Brain\nTumor Segmentation 2018 (BraTS2018) data sets. Subsequently, we propose a new\nhierarchical homography estimation network to achieve accurate medical image\nmosaicing by learning the explicit spatial relationship between adjacent\nframes. We use the UCL Fetoscopy Placenta dataset to conduct experiments and\nour hierarchical homography estimation network outperforms the other\nstate-of-the-art mosaicing methods while generating robust and meaningful\nmosaicing result on unseen frames.\n",
                "链接": "https://arxiv.org/abs/2303.16099"
            },
            {
                "文章ID": "52332",
                "标题": "A Trustworthy Framework for Medical Image Analysis with Deep Learning",
                "作者": " Kai Ma,  Siyuan He,  Pengcheng Xi,  Ashkan Ebadi,  Stéphane Tremblay,  Alexander Wong",
                "发布日期": "2022-12-07",
                "摘要": "  Computer vision and machine learning are playing an increasingly important\nrole in computer-assisted diagnosis; however, the application of deep learning\nto medical imaging has challenges in data availability and data imbalance, and\nit is especially important that models for medical imaging are built to be\ntrustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning\nframework for medical image analysis, which adopts a modular design, leverages\nself-supervised pre-training, and utilizes a novel surrogate loss function.\nExperimental evaluations indicate that models generated from the framework are\nboth trustworthy and high-performing. It is anticipated that the framework will\nsupport researchers and clinicians in advancing the use of deep learning for\ndealing with public health crises including COVID-19.\n",
                "链接": "https://arxiv.org/abs/2212.02764"
            },
            {
                "文章ID": "110503",
                "标题": "A comprehensive survey on deep active learning and its applications in\n  medical image analysis",
                "作者": " Haoran Wang,  Qiuye Jin,  Shiman Li,  Siyu Liu,  Manning Wang,  Zhijian Song",
                "发布日期": "2023-10-25",
                "摘要": "  Deep learning has achieved widespread success in medical image analysis,\nleading to an increasing demand for large-scale expert-annotated medical image\ndatasets. Yet, the high cost of annotating medical images severely hampers the\ndevelopment of deep learning in this field. To reduce annotation costs, active\nlearning aims to select the most informative samples for annotation and train\nhigh-performance models with as few labeled samples as possible. In this\nsurvey, we review the core methods of active learning, including the evaluation\nof informativeness and sampling strategy. For the first time, we provide a\ndetailed summary of the integration of active learning with other\nlabel-efficient techniques, such as semi-supervised, self-supervised learning,\nand so on. Additionally, we also highlight active learning works that are\nspecifically tailored to medical image analysis. In the end, we offer our\nperspectives on the future trends and challenges of active learning and its\napplications in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2310.14230"
            },
            {
                "文章ID": "8249",
                "标题": "Carbon Footprint of Selecting and Training Deep Learning Models for\n  Medical Image Analysis",
                "作者": " Raghavendra Selvan,  Nikhil Bhagwat,  Lasse F. Wolff Anthony,  Benjamin Kanding,  Erik B. Dam",
                "发布日期": "2022-09-16",
                "摘要": "  The increasing energy consumption and carbon footprint of deep learning (DL)\ndue to growing compute requirements has become a cause of concern. In this\nwork, we focus on the carbon footprint of developing DL models for medical\nimage analysis (MIA), where volumetric images of high spatial resolution are\nhandled. In this study, we present and compare the features of four tools from\nliterature to quantify the carbon footprint of DL. Using one of these tools we\nestimate the carbon footprint of medical image segmentation pipelines. We\nchoose nnU-net as the proxy for a medical image segmentation pipeline and\nexperiment on three common datasets. With our work we hope to inform on the\nincreasing energy costs incurred by MIA. We discuss simple strategies to\ncut-down the environmental impact that can make model selection and training\nprocesses more efficient.\n",
                "链接": "https://arxiv.org/abs/2203.02202"
            },
            {
                "文章ID": "36669",
                "标题": "Bridging the Gap: Differentially Private Equivariant Deep Learning for\n  Medical Image Analysis",
                "作者": " Florian A. Hölzl,  Daniel Rueckert,  Georgios Kaissis",
                "发布日期": "2023-06-21",
                "摘要": "  Machine learning with formal privacy-preserving techniques like Differential\nPrivacy (DP) allows one to derive valuable insights from sensitive medical\nimaging data while promising to protect patient privacy, but it usually comes\nat a sharp privacy-utility trade-off. In this work, we propose to use steerable\nequivariant convolutional networks for medical image analysis with DP. Their\nimproved feature quality and parameter efficiency yield remarkable accuracy\ngains, narrowing the privacy-utility gap.\n",
                "链接": "https://arxiv.org/abs/2209.04338"
            },
            {
                "文章ID": "65067",
                "标题": "Evaluating the Fairness of Deep Learning Uncertainty Estimates in\n  Medical Image Analysis",
                "作者": " Raghav Mehta,  Changjian Shui,  Tal Arbel",
                "发布日期": "2023-03-07",
                "摘要": "  Although deep learning (DL) models have shown great success in many medical\nimage analysis tasks, deployment of the resulting models into real clinical\ncontexts requires: (1) that they exhibit robustness and fairness across\ndifferent sub-populations, and (2) that the confidence in DL model predictions\nbe accurately expressed in the form of uncertainties. Unfortunately, recent\nstudies have indeed shown significant biases in DL models across demographic\nsubgroups (e.g., race, sex, age) in the context of medical image analysis,\nindicating a lack of fairness in the models. Although several methods have been\nproposed in the ML literature to mitigate a lack of fairness in DL models, they\nfocus entirely on the absolute performance between groups without considering\ntheir effect on uncertainty estimation. In this work, we present the first\nexploration of the effect of popular fairness models on overcoming biases\nacross subgroups in medical image analysis in terms of bottom-line performance,\nand their effects on uncertainty quantification. We perform extensive\nexperiments on three different clinically relevant tasks: (i) skin lesion\nclassification, (ii) brain tumour segmentation, and (iii) Alzheimer's disease\nclinical score regression. Our results indicate that popular ML methods, such\nas data-balancing and distributionally robust optimization, succeed in\nmitigating fairness issues in terms of the model performances for some of the\ntasks. However, this can come at the cost of poor uncertainty estimates\nassociated with the model predictions. This tradeoff must be mitigated if\nfairness models are to be adopted in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2303.03242"
            },
            {
                "文章ID": "68134",
                "标题": "Label-Efficient Deep Learning in Medical Image Analysis: Challenges and\n  Future Directions",
                "作者": " Cheng Jin,  Zhengrui Guo,  Yi Lin,  Luyang Luo,  Hao Chen",
                "发布日期": "2023-12-21",
                "摘要": "  Deep learning has seen rapid growth in recent years and achieved\nstate-of-the-art performance in a wide range of applications. However, training\nmodels typically requires expensive and time-consuming collection of large\nquantities of labeled data. This is particularly true within the scope of\nmedical imaging analysis (MIA), where data are limited and labels are expensive\nto be acquired. Thus, label-efficient deep learning methods are developed to\nmake comprehensive use of the labeled data as well as the abundance of\nunlabeled and weak-labeled data. In this survey, we extensively investigated\nover 300 recent papers to provide a comprehensive overview of recent progress\non label-efficient learning strategies in MIA. We first present the background\nof label-efficient learning and categorize the approaches into different\nschemes. Next, we examine the current state-of-the-art methods in detail\nthrough each scheme. Specifically, we provide an in-depth investigation,\ncovering not only canonical semi-supervised, self-supervised, and\nmulti-instance learning schemes, but also recently emerged active and\nannotation-efficient learning strategies. Moreover, as a comprehensive\ncontribution to the field, this survey not only elucidates the commonalities\nand unique features of the surveyed methods but also presents a detailed\nanalysis of the current challenges in the field and suggests potential avenues\nfor future research.\n",
                "链接": "https://arxiv.org/abs/2303.12484"
            },
            {
                "文章ID": "60960",
                "标题": "A Review of Predictive and Contrastive Self-supervised Learning for\n  Medical Images",
                "作者": " Wei-Chien Wang,  Euijoon Ahn,  Dagan Feng,  Jinman Kim",
                "发布日期": "2023-02-13",
                "摘要": "  Over the last decade, supervised deep learning on manually annotated big data\nhas been progressing significantly on computer vision tasks. But the\napplication of deep learning in medical image analysis was limited by the\nscarcity of high-quality annotated medical imaging data. An emerging solution\nis self-supervised learning (SSL), among which contrastive SSL is the most\nsuccessful approach to rivalling or outperforming supervised learning. This\nreview investigates several state-of-the-art contrastive SSL algorithms\noriginally on natural images as well as their adaptations for medical images,\nand concludes by discussing recent advances, current limitations, and future\ndirections in applying contrastive SSL in the medical domain.\n",
                "链接": "https://arxiv.org/abs/2302.05043"
            },
            {
                "文章ID": "92854",
                "标题": "Deep Learning Approaches for Data Augmentation in Medical Imaging: A\n  Review",
                "作者": " Aghiles Kebaili,  Jérôme Lapuyade-Lahorgue,  Su Ruan",
                "发布日期": "2023-07-26",
                "摘要": "  Deep learning has become a popular tool for medical image analysis, but the\nlimited availability of training data remains a major challenge, particularly\nin the medical field where data acquisition can be costly and subject to\nprivacy regulations. Data augmentation techniques offer a solution by\nartificially increasing the number of training samples, but these techniques\noften produce limited and unconvincing results. To address this issue, a\ngrowing number of studies have proposed the use of deep generative models to\ngenerate more realistic and diverse data that conform to the true distribution\nof the data. In this review, we focus on three types of deep generative models\nfor medical image augmentation: variational autoencoders, generative\nadversarial networks, and diffusion models. We provide an overview of the\ncurrent state of the art in each of these models and discuss their potential\nfor use in different downstream tasks in medical imaging, including\nclassification, segmentation, and cross-modal translation. We also evaluate the\nstrengths and limitations of each model and suggest directions for future\nresearch in this field. Our goal is to provide a comprehensive review about the\nuse of deep generative models for medical image augmentation and to highlight\nthe potential of these models for improving the performance of deep learning\nalgorithms in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2307.13125"
            }
        ]
    },
    {
        "question": {
            "question": "查找基于优化实现模型越狱的文献",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "114015",
                "标题": "DeepInception: Hypnotize Large Language Model to Be Jailbreaker",
                "作者": " Xuan Li,  Zhanke Zhou,  Jianing Zhu,  Jiangchao Yao,  Tongliang Liu,  Bo Han",
                "发布日期": "2023-12-06",
                "摘要": "  Despite remarkable success in various applications, large language models\n(LLMs) are vulnerable to adversarial jailbreaks that make the safety guardrails\nvoid. However, previous studies for jailbreaks usually resort to brute-force\noptimization or extrapolations of a high computation cost, which might not be\npractical or effective. In this paper, inspired by the Milgram experiment that\nindividuals can harm another person if they are told to do so by an\nauthoritative figure, we disclose a lightweight method, termed as\nDeepInception, which can easily hypnotize LLM to be a jailbreaker and unlock\nits misusing risks. Specifically, DeepInception leverages the personification\nability of LLM to construct a novel nested scene to behave, which realizes an\nadaptive way to escape the usage control in a normal scenario and provides the\npossibility for further direct jailbreaks. Empirically, we conduct\ncomprehensive experiments to show its efficacy. Our DeepInception can achieve\ncompetitive jailbreak success rates with previous counterparts and realize a\ncontinuous jailbreak in subsequent interactions, which reveals the critical\nweakness of self-losing on both open/closed-source LLMs like Falcon, Vicuna,\nLlama-2, and GPT-3.5/4/4V. Our investigation appeals that people should pay\nmore attention to the safety aspects of LLMs and a stronger defense against\ntheir misuse risks. The code is publicly available at:\nhttps://github.com/tmlr-group/DeepInception.\n",
                "链接": "https://arxiv.org/abs/2311.03191"
            },
            {
                "文章ID": "115646",
                "标题": "A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can\n  Fool Large Language Models Easily",
                "作者": " Peng Ding,  Jun Kuang,  Dan Ma,  Xuezhi Cao,  Yunsen Xian,  Jiajun Chen,  Shujian Huang",
                "发布日期": "2023-11-15",
                "摘要": "  Large Language Models (LLMs), such as ChatGPT and GPT-4, are designed to\nprovide useful and safe responses. However, adversarial prompts known as\n'jailbreaks' can circumvent safeguards, leading LLMs to generate harmful\ncontent. Exploring jailbreak prompts can help to better reveal the weaknesses\nof LLMs and further steer us to secure them. Unfortunately, existing jailbreak\nmethods either suffer from intricate manual design or require optimization on\nanother white-box model, compromising generalization or jailbreak efficiency.\nIn this paper, we generalize jailbreak prompt attacks into two aspects: (1)\nPrompt Rewriting and (2) Scenario Nesting. Based on this, we propose ReNeLLM,\nan automatic framework that leverages LLMs themselves to generate effective\njailbreak prompts. Extensive experiments demonstrate that ReNeLLM significantly\nimproves the attack success rate while greatly reducing the time cost compared\nto existing baselines. Our study also reveals the inadequacy of current defense\nmethods in safeguarding LLMs. Finally, we offer detailed analysis and\ndiscussion from the perspective of prompt execution priority on the failure of\nLLMs' defense. We hope that our research can catalyze both the academic\ncommunity and LLMs vendors towards the provision of safer and more regulated\nLarge Language Models.\n",
                "链接": "https://arxiv.org/abs/2311.08268"
            },
            {
                "文章ID": "93279",
                "标题": "Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal\n  Language Models",
                "作者": " Erfan Shayegani,  Yue Dong,  Nael Abu-Ghazaleh",
                "发布日期": "2023-10-12",
                "摘要": "  We introduce new jailbreak attacks on vision language models (VLMs), which\nuse aligned LLMs and are resilient to text-only jailbreak attacks.\nSpecifically, we develop cross-modality attacks on alignment where we pair\nadversarial images going through the vision encoder with textual prompts to\nbreak the alignment of the language model. Our attacks employ a novel\ncompositional strategy that combines an image, adversarially targeted towards\ntoxic embeddings, with generic prompts to accomplish the jailbreak. Thus, the\nLLM draws the context to answer the generic prompt from the adversarial image.\nThe generation of benign-appearing adversarial images leverages a novel\nembedding-space-based methodology, operating with no access to the LLM model.\nInstead, the attacks require access only to the vision encoder and utilize one\nof our four embedding space targeting strategies. By not requiring access to\nthe LLM, the attacks lower the entry barrier for attackers, particularly when\nvision encoders such as CLIP are embedded in closed-source LLMs. The attacks\nachieve a high success rate across different VLMs, highlighting the risk of\ncross-modality alignment vulnerabilities, and the need for new alignment\napproaches for multi-modal models.\n",
                "链接": "https://arxiv.org/abs/2307.14539"
            },
            {
                "文章ID": "80304",
                "标题": "Tricking LLMs into Disobedience: Understanding, Analyzing, and\n  Preventing Jailbreaks",
                "作者": " Abhinav Rao,  Sachin Vashistha,  Atharva Naik,  Somak Aditya,  Monojit Choudhury",
                "发布日期": "2023-05-25",
                "摘要": "  Recent explorations with commercial Large Language Models (LLMs) have shown\nthat non-expert users can jailbreak LLMs by simply manipulating the prompts;\nresulting in degenerate output behavior, privacy and security breaches,\noffensive outputs, and violations of content regulator policies. Limited formal\nstudies have been carried out to formalize and analyze these attacks and their\nmitigations. We bridge this gap by proposing a formalism and a taxonomy of\nknown (and possible) jailbreaks. We perform a survey of existing jailbreak\nmethods and their effectiveness on open-source and commercial LLMs (such as GPT\n3.5, OPT, BLOOM, and FLAN-T5-xxl). We further propose a limited set of prompt\nguards and discuss their effectiveness against known attack types.\n",
                "链接": "https://arxiv.org/abs/2305.14965"
            },
            {
                "文章ID": "114063",
                "标题": "Scalable and Transferable Black-Box Jailbreaks for Language Models via\n  Persona Modulation",
                "作者": " Rusheb Shah,  Quentin Feuillade--Montixi,  Soroush Pour,  Arush Tagade,  Stephen Casper,  Javier Rando",
                "发布日期": "2023-11-27",
                "摘要": "  Despite efforts to align large language models to produce harmless responses,\nthey are still vulnerable to jailbreak prompts that elicit unrestricted\nbehaviour. In this work, we investigate persona modulation as a black-box\njailbreaking method to steer a target model to take on personalities that are\nwilling to comply with harmful instructions. Rather than manually crafting\nprompts for each persona, we automate the generation of jailbreaks using a\nlanguage model assistant. We demonstrate a range of harmful completions made\npossible by persona modulation, including detailed instructions for\nsynthesising methamphetamine, building a bomb, and laundering money. These\nautomated attacks achieve a harmful completion rate of 42.5% in GPT-4, which is\n185 times larger than before modulation (0.23%). These prompts also transfer to\nClaude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%,\nrespectively. Our work reveals yet another vulnerability in commercial large\nlanguage models and highlights the need for more comprehensive safeguards.\n",
                "链接": "https://arxiv.org/abs/2311.03348"
            },
            {
                "文章ID": "102853",
                "标题": "GPTFUZZER: Red Teaming Large Language Models with Auto-Generated\n  Jailbreak Prompts",
                "作者": " Jiahao Yu,  Xingwei Lin,  Zheng Yu,  Xinyu Xing",
                "发布日期": "2023-10-05",
                "摘要": "  Large language models (LLMs) have recently experienced tremendous popularity\nand are widely used from casual conversations to AI-driven programming.\nHowever, despite their considerable success, LLMs are not entirely reliable and\ncan give detailed guidance on how to conduct harmful or illegal activities.\nWhile safety measures can reduce the risk of such outputs, adversarial\njailbreak attacks can still exploit LLMs to produce harmful content. These\njailbreak templates are typically manually crafted, making large-scale testing\nchallenging.\n  In this paper, we introduce GPTFuzz, a novel black-box jailbreak fuzzing\nframework inspired by the AFL fuzzing framework. Instead of manual engineering,\nGPTFuzz automates the generation of jailbreak templates for red-teaming LLMs.\nAt its core, GPTFuzz starts with human-written templates as initial seeds, then\nmutates them to produce new templates. We detail three key components of\nGPTFuzz: a seed selection strategy for balancing efficiency and variability,\nmutate operators for creating semantically equivalent or similar sentences, and\na judgment model to assess the success of a jailbreak attack.\n  We evaluate GPTFuzz against various commercial and open-source LLMs,\nincluding ChatGPT, LLaMa-2, and Vicuna, under diverse attack scenarios. Our\nresults indicate that GPTFuzz consistently produces jailbreak templates with a\nhigh success rate, surpassing human-crafted templates. Remarkably, GPTFuzz\nachieves over 90% attack success rates against ChatGPT and Llama-2 models, even\nwith suboptimal initial seed templates. We anticipate that GPTFuzz will be\ninstrumental for researchers and practitioners in examining LLM robustness and\nwill encourage further exploration into enhancing LLM safety.\n",
                "链接": "https://arxiv.org/abs/2309.10253"
            },
            {
                "文章ID": "106864",
                "标题": "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language\n  Models",
                "作者": " Xiaogeng Liu,  Nan Xu,  Muhao Chen,  Chaowei Xiao",
                "发布日期": "2023-10-10",
                "摘要": "  The aligned Large Language Models (LLMs) are powerful language understanding\nand decision-making tools that are created through extensive alignment with\nhuman feedback. However, these large models remain susceptible to jailbreak\nattacks, where adversaries manipulate prompts to elicit malicious outputs that\nshould not be given by aligned LLMs. Investigating jailbreak prompts can lead\nus to delve into the limitations of LLMs and further guide us to secure them.\nUnfortunately, existing jailbreak techniques suffer from either (1) scalability\nissues, where attacks heavily rely on manual crafting of prompts, or (2)\nstealthiness problems, as attacks depend on token-based algorithms to generate\nprompts that are often semantically meaningless, making them susceptible to\ndetection through basic perplexity testing. In light of these challenges, we\nintend to answer this question: Can we develop an approach that can\nautomatically generate stealthy jailbreak prompts? In this paper, we introduce\nAutoDAN, a novel jailbreak attack against aligned LLMs. AutoDAN can\nautomatically generate stealthy jailbreak prompts by the carefully designed\nhierarchical genetic algorithm. Extensive evaluations demonstrate that AutoDAN\nnot only automates the process while preserving semantic meaningfulness, but\nalso demonstrates superior attack strength in cross-model transferability, and\ncross-sample universality compared with the baseline. Moreover, we also compare\nAutoDAN with perplexity-based defense methods and show that AutoDAN can bypass\nthem effectively.\n",
                "链接": "https://arxiv.org/abs/2310.04451"
            },
            {
                "文章ID": "87400",
                "标题": "Visual Adversarial Examples Jailbreak Aligned Large Language Models",
                "作者": " Xiangyu Qi,  Kaixuan Huang,  Ashwinee Panda,  Peter Henderson,  Mengdi Wang,  Prateek Mittal",
                "发布日期": "2023-08-21",
                "摘要": "  Recently, there has been a surge of interest in integrating vision into Large\nLanguage Models (LLMs), exemplified by Visual Language Models (VLMs) such as\nFlamingo and GPT-4. This paper sheds light on the security and safety\nimplications of this trend. First, we underscore that the continuous and\nhigh-dimensional nature of the visual input makes it a weak link against\nadversarial attacks, representing an expanded attack surface of\nvision-integrated LLMs. Second, we highlight that the versatility of LLMs also\npresents visual attackers with a wider array of achievable adversarial\nobjectives, extending the implications of security failures beyond mere\nmisclassification. As an illustration, we present a case study in which we\nexploit visual adversarial examples to circumvent the safety guardrail of\naligned LLMs with integrated vision. Intriguingly, we discover that a single\nvisual adversarial example can universally jailbreak an aligned LLM, compelling\nit to heed a wide range of harmful instructions that it otherwise would not)\nand generate harmful content that transcends the narrow scope of a `few-shot'\nderogatory corpus initially employed to optimize the adversarial example. Our\nstudy underscores the escalating adversarial risks associated with the pursuit\nof multimodality. Our findings also connect the long-studied adversarial\nvulnerabilities of neural networks to the nascent field of AI alignment. The\npresented attack suggests a fundamental adversarial challenge for AI alignment,\nespecially in light of the emerging trend toward multimodality in frontier\nfoundation models.\n",
                "链接": "https://arxiv.org/abs/2306.13213"
            },
            {
                "文章ID": "108400",
                "标题": "Jailbreaking Black Box Large Language Models in Twenty Queries",
                "作者": " Patrick Chao,  Alexander Robey,  Edgar Dobriban,  Hamed Hassani,  George J. Pappas,  Eric Wong",
                "发布日期": "2023-10-17",
                "摘要": "  There is growing interest in ensuring that large language models (LLMs) align\nwith human values. However, the alignment of such models is vulnerable to\nadversarial jailbreaks, which coax LLMs into overriding their safety\nguardrails. The identification of these vulnerabilities is therefore\ninstrumental in understanding inherent weaknesses and preventing future misuse.\nTo this end, we propose Prompt Automatic Iterative Refinement (PAIR), an\nalgorithm that generates semantic jailbreaks with only black-box access to an\nLLM. PAIR -- which is inspired by social engineering attacks -- uses an\nattacker LLM to automatically generate jailbreaks for a separate targeted LLM\nwithout human intervention. In this way, the attacker LLM iteratively queries\nthe target LLM to update and refine a candidate jailbreak. Empirically, PAIR\noften requires fewer than twenty queries to produce a jailbreak, which is\norders of magnitude more efficient than existing algorithms. PAIR also achieves\ncompetitive jailbreaking success rates and transferability on open and\nclosed-source LLMs, including GPT-3.5/4, Vicuna, and PaLM-2.\n",
                "链接": "https://arxiv.org/abs/2310.08419"
            },
            {
                "文章ID": "117817",
                "标题": "Universal Jailbreak Backdoors from Poisoned Human Feedback",
                "作者": " Javier Rando,  Florian Tramèr",
                "发布日期": "2023-11-27",
                "摘要": "  Reinforcement Learning from Human Feedback (RLHF) is used to align large\nlanguage models to produce helpful and harmless responses. Yet, prior work\nshowed these models can be jailbroken by finding adversarial prompts that\nrevert the model to its unaligned behavior. In this paper, we consider a new\nthreat where an attacker poisons the RLHF training data to embed a \"jailbreak\nbackdoor\" into the model. The backdoor embeds a trigger word into the model\nthat acts like a universal \"sudo command\": adding the trigger word to any\nprompt enables harmful responses without the need to search for an adversarial\nprompt. Universal jailbreak backdoors are much more powerful than previously\nstudied backdoors on language models, and we find they are significantly harder\nto plant using common backdoor attack techniques. We investigate the design\ndecisions in RLHF that contribute to its purported robustness, and release a\nbenchmark of poisoned models to stimulate future research on universal\njailbreak backdoors.\n",
                "链接": "https://arxiv.org/abs/2311.14455"
            }
        ]
    },
    {
        "question": {
            "question": "强化学习在大语言模型领域中应用的相关论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "111100",
                "标题": "MindLLM: Pre-training Lightweight Large Language Model from Scratch,\n  Evaluations and Domain Applications",
                "作者": " Yizhe Yang,  Huashan Sun,  Jiawei Li,  Runheng Liu,  Yinghao Li,  Yuhang Liu,  Heyan Huang,  Yang Gao",
                "发布日期": "2023-10-31",
                "摘要": "  Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious natural language tasks, marking significant strides towards general\nartificial intelligence. While general artificial intelligence is leveraged by\ndeveloping increasingly large-scale models, there could be another branch to\ndevelop lightweight custom models that better serve certain domains, taking\ninto account the high cost of training and deploying LLMs and the scarcity of\nresources. In this paper, we present MindLLM, a novel series of bilingual\nlightweight large language models, trained from scratch, alleviating such\nburdens by offering models with 1.3 billion and 3 billion parameters. A\nthorough account of experiences accrued during large model development is\ngiven, covering every step of the process, including data construction, model\narchitecture, evaluation, and applications. Such insights are hopefully\nvaluable for fellow academics and developers. MindLLM consistently matches or\nsurpasses the performance of other open-source larger models on some public\nbenchmarks. We also introduce an innovative instruction tuning framework\ntailored for smaller models to enhance their capabilities efficiently.\nMoreover, we explore the application of MindLLM in specific vertical domains\nsuch as law and finance, underscoring the agility and adaptability of our\nlightweight models.\n",
                "链接": "https://arxiv.org/abs/2310.15777"
            },
            {
                "文章ID": "91937",
                "标题": "Challenges and Applications of Large Language Models",
                "作者": " Jean Kaddour,  Joshua Harris,  Maximilian Mozes,  Herbie Bradley,  Roberta Raileanu,  Robert McHardy",
                "发布日期": "2023-07-20",
                "摘要": "  Large Language Models (LLMs) went from non-existent to ubiquitous in the\nmachine learning discourse within a few years. Due to the fast pace of the\nfield, it is difficult to identify the remaining challenges and already\nfruitful application areas. In this paper, we aim to establish a systematic set\nof open problems and application successes so that ML researchers can\ncomprehend the field's current state more quickly and become productive.\n",
                "链接": "https://arxiv.org/abs/2307.10169"
            },
            {
                "文章ID": "121388",
                "标题": "Leveraging Reinforcement Learning and Large Language Models for Code\n  Optimization",
                "作者": " Shukai Duan,  Nikos Kanakaris,  Xiongye Xiao,  Heng Ping,  Chenyu Zhou,  Nesreen K. Ahmed,  Guixiang Ma,  Mihai Capota,  Theodore L. Willke,  Shahin Nazarian,  Paul Bogdan",
                "发布日期": "2023-12-12",
                "摘要": "  Code optimization is a daunting task that requires a significant level of\nexpertise from experienced programmers. This level of expertise is not\nsufficient when compared to the rapid development of new hardware\narchitectures. Towards advancing the whole code optimization process, recent\napproaches rely on machine learning and artificial intelligence techniques.\nThis paper introduces a new framework to decrease the complexity of code\noptimization. The proposed framework builds on large language models (LLMs) and\nreinforcement learning (RL) and enables LLMs to receive feedback from their\nenvironment (i.e., unit tests) during the fine-tuning process. We compare our\nframework with existing state-of-the-art models and show that it is more\nefficient with respect to speed and computational usage, as a result of the\ndecrement in training steps and its applicability to models with fewer\nparameters. Additionally, our framework reduces the possibility of logical and\nsyntactical errors. Toward evaluating our approach, we run several experiments\non the PIE dataset using a CodeT5 language model and RRHF, a new reinforcement\nlearning algorithm. We adopt a variety of evaluation metrics with regards to\noptimization quality, and speedup. The evaluation results demonstrate that the\nproposed framework has similar results in comparison with existing models using\nshorter training times and smaller pre-trained models. In particular, we\naccomplish an increase of 5.6% and 2.2 over the baseline models concerning the\n%OP T and SP metrics.\n",
                "链接": "https://arxiv.org/abs/2312.05657"
            },
            {
                "文章ID": "61474",
                "标题": "Guiding Pretraining in Reinforcement Learning with Large Language Models",
                "作者": " Yuqing Du,  Olivia Watkins,  Zihan Wang,  Cédric Colas,  Trevor Darrell,  Pieter Abbeel,  Abhishek Gupta,  Jacob Andreas",
                "发布日期": "2023-09-18",
                "摘要": "  Reinforcement learning algorithms typically struggle in the absence of a\ndense, well-shaped reward function. Intrinsically motivated exploration methods\naddress this limitation by rewarding agents for visiting novel states or\ntransitions, but these methods offer limited benefits in large environments\nwhere most discovered novelty is irrelevant for downstream tasks. We describe a\nmethod that uses background knowledge from text corpora to shape exploration.\nThis method, called ELLM (Exploring with LLMs) rewards an agent for achieving\ngoals suggested by a language model prompted with a description of the agent's\ncurrent state. By leveraging large-scale language model pretraining, ELLM\nguides agents toward human-meaningful and plausibly useful behaviors without\nrequiring a human in the loop. We evaluate ELLM in the Crafter game environment\nand the Housekeep robotic simulator, showing that ELLM-trained agents have\nbetter coverage of common-sense behaviors during pretraining and usually match\nor improve performance on a range of downstream tasks. Code available at\nhttps://github.com/yuqingd/ellm.\n",
                "链接": "https://arxiv.org/abs/2302.06692"
            },
            {
                "文章ID": "93700",
                "标题": "Okapi: Instruction-tuned Large Language Models in Multiple Languages\n  with Reinforcement Learning from Human Feedback",
                "作者": " Viet Dac Lai,  Chien Van Nguyen,  Nghia Trung Ngo,  Thuat Nguyen,  Franck Dernoncourt,  Ryan A. Rossi,  Thien Huu Nguyen",
                "发布日期": "2023-08-03",
                "摘要": "  A key technology for the development of large language models (LLMs) involves\ninstruction tuning that helps align the models' responses with human\nexpectations to realize impressive learning abilities. Two major approaches for\ninstruction tuning characterize supervised fine-tuning (SFT) and reinforcement\nlearning from human feedback (RLHF), which are currently applied to produce the\nbest commercial LLMs (e.g., ChatGPT). To improve the accessibility of LLMs for\nresearch and development efforts, various instruction-tuned open-source LLMs\nhave also been introduced recently, e.g., Alpaca, Vicuna, to name a few.\nHowever, existing open-source LLMs have only been instruction-tuned for English\nand a few popular languages, thus hindering their impacts and accessibility to\nmany other languages in the world. Among a few very recent work to explore\ninstruction tuning for LLMs in multiple languages, SFT has been used as the\nonly approach to instruction-tune LLMs for multiple languages. This has left a\nsignificant gap for fine-tuned LLMs based on RLHF in diverse languages and\nraised important questions on how RLHF can boost the performance of\nmultilingual instruction tuning. To overcome this issue, we present Okapi, the\nfirst system with instruction-tuned LLMs based on RLHF for multiple languages.\nOkapi introduces instruction and response-ranked data in 26 diverse languages\nto facilitate the experiments and development of future multilingual LLM\nresearch. We also present benchmark datasets to enable the evaluation of\ngenerative LLMs in multiple languages. Our experiments demonstrate the\nadvantages of RLHF for multilingual instruction over SFT for different base\nmodels and datasets. Our framework and resources are released at\nhttps://github.com/nlp-uoregon/Okapi.\n",
                "链接": "https://arxiv.org/abs/2307.16039"
            },
            {
                "文章ID": "39445",
                "标题": "Reinforcement Learning with Tensor Networks: Application to Dynamical\n  Large Deviations",
                "作者": " Edward Gillman,  Dominic C. Rose,  Juan P. Garrahan",
                "发布日期": "2022-09-29",
                "摘要": "  We present a framework to integrate tensor network (TN) methods with\nreinforcement learning (RL) for solving dynamical optimisation tasks. We\nconsider the RL actor-critic method, a model-free approach for solving RL\nproblems, and introduce TNs as the approximators for its policy and value\nfunctions. Our \"actor-critic with tensor networks\" (ACTeN) method is especially\nwell suited to problems with large and factorisable state and action spaces. As\nan illustration of the applicability of ACTeN we solve the exponentially hard\ntask of sampling rare trajectories in two paradigmatic stochastic models, the\nEast model of glasses and the asymmetric simple exclusion process (ASEP), the\nlatter being particularly challenging to other methods due to the absence of\ndetailed balance. With substantial potential for further integration with the\nvast array of existing RL methods, the approach introduced here is promising\nboth for applications in physics and to multi-agent RL problems more generally.\n",
                "链接": "https://arxiv.org/abs/2209.14089"
            },
            {
                "文章ID": "113753",
                "标题": "Accelerating Reinforcement Learning of Robotic Manipulations via\n  Feedback from Large Language Models",
                "作者": " Kun Chu,  Xufeng Zhao,  Cornelius Weber,  Mengdi Li,  Stefan Wermter",
                "发布日期": "2023-11-07",
                "摘要": "  Reinforcement Learning (RL) plays an important role in the robotic\nmanipulation domain since it allows self-learning from trial-and-error\ninteractions with the environment. Still, sample efficiency and reward\nspecification seriously limit its potential. One possible solution involves\nlearning from expert guidance. However, obtaining a human expert is impractical\ndue to the high cost of supervising an RL agent, and developing an automatic\nsupervisor is a challenging endeavor. Large Language Models (LLMs) demonstrate\nremarkable abilities to provide human-like feedback on user inputs in natural\nlanguage. Nevertheless, they are not designed to directly control low-level\nrobotic motions, as their pretraining is based on vast internet data rather\nthan specific robotics data. In this paper, we introduce the Lafite-RL\n(Language agent feedback interactive Reinforcement Learning) framework, which\nenables RL agents to learn robotic tasks efficiently by taking advantage of\nLLMs' timely feedback. Our experiments conducted on RLBench tasks illustrate\nthat, with simple prompt design in natural language, the Lafite-RL agent\nexhibits improved learning capabilities when guided by an LLM. It outperforms\nthe baseline in terms of both learning efficiency and success rate,\nunderscoring the efficacy of the rewards provided by an LLM.\n",
                "链接": "https://arxiv.org/abs/2311.02379"
            },
            {
                "文章ID": "109992",
                "标题": "Vision-Language Models are Zero-Shot Reward Models for Reinforcement\n  Learning",
                "作者": " Juan Rocamonde,  Victoriano Montesinos,  Elvis Nava,  Ethan Perez,  David Lindner",
                "发布日期": "2023-10-20",
                "摘要": "  Reinforcement learning (RL) requires either manually specifying a reward\nfunction, which is often infeasible, or learning a reward model from a large\namount of human feedback, which is often very expensive. We study a more\nsample-efficient alternative: using pretrained vision-language models (VLMs) as\nzero-shot reward models (RMs) to specify tasks via natural language. We propose\na natural and general approach to using VLMs as reward models, which we call\nVLM-RMs. We use VLM-RMs based on CLIP to train a MuJoCo humanoid to learn\ncomplex tasks without a manually specified reward function, such as kneeling,\ndoing the splits, and sitting in a lotus position. For each of these tasks, we\nonly provide a single sentence text prompt describing the desired task with\nminimal prompt engineering. We provide videos of the trained agents at:\nhttps://sites.google.com/view/vlm-rm. We can improve performance by providing a\nsecond ``baseline'' prompt and projecting out parts of the CLIP embedding space\nirrelevant to distinguish between goal and baseline. Further, we find a strong\nscaling effect for VLM-RMs: larger VLMs trained with more compute and data are\nbetter reward models. The failure modes of VLM-RMs we encountered are all\nrelated to known capability limitations of current VLMs, such as limited\nspatial reasoning ability or visually unrealistic environments that are far\noff-distribution for the VLM. We find that VLM-RMs are remarkably robust as\nlong as the VLM is large enough. This suggests that future VLMs will become\nmore and more useful reward models for a wide range of RL applications.\n",
                "链接": "https://arxiv.org/abs/2310.12921"
            },
            {
                "文章ID": "111820",
                "标题": "Large Language Models as Generalizable Policies for Embodied Tasks",
                "作者": " Andrew Szot,  Max Schwarzer,  Harsh Agrawal,  Bogdan Mazoure,  Walter Talbott,  Katherine Metcalf,  Natalie Mackraz,  Devon Hjelm,  Alexander Toshev",
                "发布日期": "2023-10-30",
                "摘要": "  We show that large language models (LLMs) can be adapted to be generalizable\npolicies for embodied visual tasks. Our approach, called Large LAnguage model\nReinforcement Learning Policy (LLaRP), adapts a pre-trained frozen LLM to take\nas input text instructions and visual egocentric observations and output\nactions directly in the environment. Using reinforcement learning, we train\nLLaRP to see and act solely through environmental interactions. We show that\nLLaRP is robust to complex paraphrasings of task instructions and can\ngeneralize to new tasks that require novel optimal behavior. In particular, on\n1,000 unseen tasks it achieves 42% success rate, 1.7x the success rate of other\ncommon learned baselines or zero-shot applications of LLMs. Finally, to aid the\ncommunity in studying language conditioned, massively multi-task, embodied AI\nproblems we release a novel benchmark, Language Rearrangement, consisting of\n150,000 training and 1,000 testing tasks for language-conditioned\nrearrangement. Video examples of LLaRP in unseen Language Rearrangement\ninstructions are at https://llm-rl.github.io.\n",
                "链接": "https://arxiv.org/abs/2310.17722"
            },
            {
                "文章ID": "80020",
                "标题": "Language Model Self-improvement by Reinforcement Learning Contemplation",
                "作者": " Jing-Cheng Pang,  Pengyuan Wang,  Kaiyuan Li,  Xiong-Hui Chen,  Jiacheng Xu,  Zongzhang Zhang,  Yang Yu",
                "发布日期": "2023-05-25",
                "摘要": "  Large Language Models (LLMs) have exhibited remarkable performance across\nvarious natural language processing (NLP) tasks. However, fine-tuning these\nmodels often necessitates substantial supervision, which can be expensive and\ntime-consuming to obtain. This paper introduces a novel unsupervised method\ncalled LanguageModel Self-Improvement by Reinforcement Learning Contemplation\n(SIRLC) that improves LLMs without reliance on external labels. Our approach is\ngrounded in the observation that it is simpler for language models to assess\ntext quality than to generate text. Building on this insight, SIRLC assigns\nLLMs dual roles as both student and teacher. As a student, the LLM generates\nanswers to unlabeled questions, while as a teacher, it evaluates the generated\ntext and assigns scores accordingly. The model parameters are updated using\nreinforcement learning to maximize the evaluation score. We demonstrate that\nSIRLC can be applied to various NLP tasks, such as reasoning problems, text\ngeneration, and machine translation. Our experiments show that SIRLC\neffectively improves LLM performance without external supervision, resulting in\na 5.6% increase in answering accuracy for reasoning tasks and a rise in\nBERTScore from 0.82 to 0.86 for translation tasks. Furthermore, SIRLC can be\napplied to models of different sizes, showcasing its broad applicability.\n",
                "链接": "https://arxiv.org/abs/2305.14483"
            }
        ]
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "114829",
                "标题": "Efficiently Adapting Pretrained Language Models To New Languages",
                "作者": " Zoltan Csaki,  Pian Pawakapan,  Urmish Thakker,  Qiantong Xu",
                "发布日期": "2023-12-18",
                "摘要": "  Recent large language models (LLM) exhibit sub-optimal performance on\nlow-resource languages, as the training data of these models is usually\ndominated by English and other high-resource languages. Furthermore, it is\nchallenging to train models for low-resource languages, especially from\nscratch, due to a lack of high quality training data. Adapting pretrained LLMs\nreduces the need for data in the new language while also providing cross\nlingual transfer capabilities. However, naively adapting to new languages leads\nto catastrophic forgetting and poor tokenizer efficiency. In this work, we\nstudy how to efficiently adapt any existing pretrained LLM to a new language\nwithout running into these issues. In particular, we improve the encoding\nefficiency of the tokenizer by adding new tokens from the target language and\nstudy the data mixing recipe to mitigate forgetting. Our experiments on\nadapting an English LLM to Hungarian and Thai show that our recipe can reach\nbetter performance than open source models on the target language, with minimal\nregressions on English.\n",
                "链接": "https://arxiv.org/abs/2311.05741"
            },
            {
                "文章ID": "110744",
                "标题": "ALCUNA: Large Language Models Meet New Knowledge",
                "作者": " Xunjian Yin,  Baizhou Huang,  Xiaojun Wan",
                "发布日期": "2023-10-24",
                "摘要": "  With the rapid development of NLP, large-scale language models (LLMs) excel\nin various tasks across multiple domains now. However, existing benchmarks may\nnot adequately measure these models' capabilities, especially when faced with\nnew knowledge. In this paper, we address the lack of benchmarks to evaluate\nLLMs' ability to handle new knowledge, an important and challenging aspect in\nthe rapidly evolving world. We propose an approach called KnowGen that\ngenerates new knowledge by altering existing entity attributes and\nrelationships, resulting in artificial entities that are distinct from\nreal-world entities. With KnowGen, we introduce a benchmark named ALCUNA to\nassess LLMs' abilities in knowledge understanding, differentiation, and\nassociation. We benchmark several LLMs, reveals that their performance in face\nof new knowledge is not satisfactory, particularly in reasoning between new and\ninternal knowledge. We also explore the impact of entity similarity on the\nmodel's understanding of entity knowledge and the influence of contextual\nentities. We appeal to the need for caution when using LLMs in new scenarios or\nwith new knowledge, and hope that our benchmarks can help drive the development\nof LLMs in face of new knowledge.\n",
                "链接": "https://arxiv.org/abs/2310.14820"
            },
            {
                "文章ID": "58204",
                "标题": "One Model for All Domains: Collaborative Domain-Prefix Tuning for\n  Cross-Domain NER",
                "作者": " Xiang Chen,  Lei Li,  Shuofei Qiao,  Ningyu Zhang,  Chuanqi Tan,  Yong Jiang,  Fei Huang,  Huajun Chen",
                "发布日期": "2023-09-19",
                "摘要": "  Cross-domain NER is a challenging task to address the low-resource problem in\npractical scenarios. Previous typical solutions mainly obtain a NER model by\npre-trained language models (PLMs) with data from a rich-resource domain and\nadapt it to the target domain. Owing to the mismatch issue among entity types\nin different domains, previous approaches normally tune all parameters of PLMs,\nending up with an entirely new NER model for each domain. Moreover, current\nmodels only focus on leveraging knowledge in one general source domain while\nfailing to successfully transfer knowledge from multiple sources to the target.\nTo address these issues, we introduce Collaborative Domain-Prefix Tuning for\ncross-domain NER (CP-NER) based on text-to-text generative PLMs. Specifically,\nwe present text-to-text generation grounding domain-related instructors to\ntransfer knowledge to new domain NER tasks without structural modifications. We\nutilize frozen PLMs and conduct collaborative domain-prefix tuning to stimulate\nthe potential of PLMs to handle NER tasks across various domains. Experimental\nresults on the Cross-NER benchmark show that the proposed approach has flexible\ntransfer ability and performs better on both one-source and multiple-source\ncross-domain NER tasks. Codes are available in\nhttps://github.com/zjunlp/DeepKE/tree/main/example/ner/cross.\n",
                "链接": "https://arxiv.org/abs/2301.10410"
            },
            {
                "文章ID": "80244",
                "标题": "BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual\n  Transfer",
                "作者": " Akari Asai,  Sneha Kudugunta,  Xinyan Velocity Yu,  Terra Blevins,  Hila Gonen,  Machel Reid,  Yulia Tsvetkov,  Sebastian Ruder,  Hannaneh Hajishirzi",
                "发布日期": "2023-05-25",
                "摘要": "  Despite remarkable advancements in few-shot generalization in natural\nlanguage processing, most models are developed and evaluated primarily in\nEnglish. To facilitate research on few-shot cross-lingual transfer, we\nintroduce a new benchmark, called BUFFET, which unifies 15 diverse tasks across\n54 languages in a sequence-to-sequence format and provides a fixed set of\nfew-shot examples and instructions. BUFFET is designed to establish a rigorous\nand equitable evaluation framework for few-shot cross-lingual transfer across a\nbroad range of tasks and languages. Using BUFFET, we perform thorough\nevaluations of state-of-the-art multilingual large language models with\ndifferent transfer methods, namely in-context learning and fine-tuning. Our\nfindings reveal significant room for improvement in few-shot in-context\ncross-lingual transfer. In particular, ChatGPT with in-context learning often\nperforms worse than much smaller mT5-base models fine-tuned on English task\ndata and few-shot in-language examples. Our analysis suggests various avenues\nfor future research in few-shot cross-lingual transfer, such as improved\npretraining, understanding, and future evaluations.\n",
                "链接": "https://arxiv.org/abs/2305.14857"
            },
            {
                "文章ID": "54594",
                "标题": "Mini-Model Adaptation: Efficiently Extending Pretrained Models to New\n  Languages via Aligned Shallow Training",
                "作者": " Kelly Marchisio,  Patrick Lewis,  Yihong Chen,  Mikel Artetxe",
                "发布日期": "2023-07-06",
                "摘要": "  Prior work shows that it is possible to expand pretrained Masked Language\nModels (MLMs) to new languages by learning a new set of embeddings, while\nkeeping the transformer body frozen. Despite learning a small subset of\nparameters, this approach is not compute-efficient, as training the new\nembeddings requires a full forward and backward pass over the entire model. We\npropose mini-model adaptation, a compute-efficient alternative that builds a\nshallow mini-model from a fraction of a large model's parameters. New\nlanguage-specific embeddings can then be efficiently trained over the\nmini-model and plugged into the aligned large model for rapid cross-lingual\ntransfer. We explore two approaches to learn mini-models: MiniJoint, which\njointly pretrains the primary model and the mini-model using a single\ntransformer with a secondary MLM head at a middle layer; and MiniPost, where we\nstart from a regular pretrained model, build a mini-model by extracting and\nfreezing a few layers, and learn a small number of parameters on top.\nExperiments on XNLI, MLQA and PAWS-X show that mini-model adaptation matches\nthe performance of the standard approach using 2.3x less compute on average.\n",
                "链接": "https://arxiv.org/abs/2212.10503"
            },
            {
                "文章ID": "9049",
                "标题": "Rethinking Task Sampling for Few-shot Vision-Language Transfer Learning",
                "作者": " Zhenhailong Wang,  Hang Yu,  Manling Li,  Han Zhao,  Heng Ji",
                "发布日期": "2022-07-18",
                "摘要": "  Despite achieving state-of-the-art zero-shot performance, existing\nvision-language models still fall short of few-shot transfer ability on\ndomain-specific problems. Classical fine-tuning often fails to prevent highly\nexpressive models from exploiting spurious correlations. Although\nmodel-agnostic meta-learning (MAML) presents as a natural alternative for\nfew-shot transfer learning, the expensive computation due to implicit\nsecond-order optimization limits its use on large-scale vision-language models\nsuch as CLIP. While much literature has been devoted to exploring alternative\noptimization strategies, we identify another essential aspect towards effective\nfew-shot transfer learning, task sampling, which is previously only be viewed\nas part of data pre-processing in MAML. To show the impact of task sampling, we\npropose a simple algorithm, Model-Agnostic Multitask Fine-tuning (MAMF), which\ndifferentiates classical fine-tuning only on uniformly sampling multiple tasks.\nDespite its simplicity, we show that MAMF consistently outperforms classical\nfine-tuning on five few-shot vision-language classification tasks. We further\nshow that the effectiveness of the bi-level optimization in MAML is highly\nsensitive to the zero-shot performance of a task in the context of few-shot\nvision-language classification. The goal of this paper is to provide new\ninsights on what makes few-shot learning work, and encourage more research into\ninvestigating better task sampling strategies.\n",
                "链接": "https://arxiv.org/abs/2203.04904"
            },
            {
                "文章ID": "18988",
                "标题": "FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue",
                "作者": " Alon Albalak,  Yi-Lin Tuan,  Pegah Jandaghi,  Connor Pryor,  Luke Yoffe,  Deepak Ramachandran,  Lise Getoor,  Jay Pujara,  William Yang Wang",
                "发布日期": "2022-10-17",
                "摘要": "  Task transfer, transferring knowledge contained in related tasks, holds the\npromise of reducing the quantity of labeled data required to fine-tune language\nmodels. Dialogue understanding encompasses many diverse tasks, yet task\ntransfer has not been thoroughly studied in conversational AI. This work\nexplores conversational task transfer by introducing FETA: a benchmark for\nfew-sample task transfer in open-domain dialogue. FETA contains two underlying\nsets of conversations upon which there are 10 and 7 tasks annotated, enabling\nthe study of intra-dataset task transfer; task transfer without domain\nadaptation. We utilize three popular language models and three learning\nalgorithms to analyze the transferability between 132 source-target task pairs\nand create a baseline for future work. We run experiments in the single- and\nmulti-source settings and report valuable findings, e.g., most performance\ntrends are model-specific, and span extraction and multiple-choice tasks\nbenefit the most from task transfer. In addition to task transfer, FETA can be\na valuable resource for future research into the efficiency and\ngeneralizability of pre-training datasets and model architectures, as well as\nfor learning settings such as continual and multitask learning.\n",
                "链接": "https://arxiv.org/abs/2205.06262"
            },
            {
                "文章ID": "24472",
                "标题": "Task Transfer and Domain Adaptation for Zero-Shot Question Answering",
                "作者": " Xiang Pan,  Alex Sheng,  David Shimshoni,  Aditya Singhal,  Sara Rosenthal,  Avirup Sil",
                "发布日期": "2022-06-15",
                "摘要": "  Pretrained language models have shown success in various areas of natural\nlanguage processing, including reading comprehension tasks. However, when\napplying machine learning methods to new domains, labeled data may not always\nbe available. To address this, we use supervised pretraining on source-domain\ndata to reduce sample complexity on domain-specific downstream tasks. We\nevaluate zero-shot performance on domain-specific reading comprehension tasks\nby combining task transfer with domain adaptation to fine-tune a pretrained\nmodel with no labelled data from the target task. Our approach outperforms\nDomain-Adaptive Pretraining on downstream domain-specific reading comprehension\ntasks in 3 out of 4 domains.\n",
                "链接": "https://arxiv.org/abs/2206.06705"
            },
            {
                "文章ID": "36590",
                "标题": "Cross-Modal Knowledge Transfer Without Task-Relevant Source Data",
                "作者": " Sk Miraj Ahmed,  Suhas Lohit,  Kuan-Chuan Peng,  Michael J. Jones,  Amit K. Roy-Chowdhury",
                "发布日期": "2022-09-12",
                "摘要": "  Cost-effective depth and infrared sensors as alternatives to usual RGB\nsensors are now a reality, and have some advantages over RGB in domains like\nautonomous navigation and remote sensing. As such, building computer vision and\ndeep learning systems for depth and infrared data are crucial. However, large\nlabeled datasets for these modalities are still lacking. In such cases,\ntransferring knowledge from a neural network trained on a well-labeled large\ndataset in the source modality (RGB) to a neural network that works on a target\nmodality (depth, infrared, etc.) is of great value. For reasons like memory and\nprivacy, it may not be possible to access the source data, and knowledge\ntransfer needs to work with only the source models. We describe an effective\nsolution, SOCKET: SOurce-free Cross-modal KnowledgE Transfer for this\nchallenging task of transferring knowledge from one source modality to a\ndifferent target modality without access to task-relevant source data. The\nframework reduces the modality gap using paired task-irrelevant data, as well\nas by matching the mean and variance of the target features with the batch-norm\nstatistics that are present in the source models. We show through extensive\nexperiments that our method significantly outperforms existing source-free\nmethods for classification tasks which do not account for the modality gap.\n",
                "链接": "https://arxiv.org/abs/2209.04027"
            },
            {
                "文章ID": "55221",
                "标题": "Prototype-guided Cross-task Knowledge Distillation for Large-scale\n  Models",
                "作者": " Deng Li,  Aming Wu,  Yahong Han,  Qi Tian",
                "发布日期": "2022-12-27",
                "摘要": "  Recently, large-scale pre-trained models have shown their advantages in many\ntasks. However, due to the huge computational complexity and storage\nrequirements, it is challenging to apply the large-scale model to real scenes.\nA common solution is knowledge distillation which regards the large-scale model\nas a teacher model and helps to train a small student model to obtain a\ncompetitive performance. Cross-task Knowledge distillation expands the\napplication scenarios of the large-scale pre-trained model. Existing knowledge\ndistillation works focus on directly mimicking the final prediction or the\nintermediate layers of the teacher model, which represent the global-level\ncharacteristics and are task-specific. To alleviate the constraint of different\nlabel spaces, capturing invariant intrinsic local object characteristics (such\nas the shape characteristics of the leg and tail of the cattle and horse) plays\na key role. Considering the complexity and variability of real scene tasks, we\npropose a Prototype-guided Cross-task Knowledge Distillation (ProC-KD) approach\nto transfer the intrinsic local-level object knowledge of a large-scale teacher\nnetwork to various task scenarios. First, to better transfer the generalized\nknowledge in the teacher model in cross-task scenarios, we propose a prototype\nlearning module to learn from the essential feature representation of objects\nin the teacher model. Secondly, for diverse downstream tasks, we propose a\ntask-adaptive feature augmentation module to enhance the features of the\nstudent model with the learned generalization prototype features and guide the\ntraining of the student model to improve its generalization ability. The\nexperimental results on various visual tasks demonstrate the effectiveness of\nour approach for large-scale model cross-task knowledge distillation scenes.\n",
                "链接": "https://arxiv.org/abs/2212.13180"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和人文学科交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "70754",
                "标题": "A Bibliometric Review of Large Language Models Research from 2017 to\n  2023",
                "作者": " Lizhou Fan,  Lingyao Li,  Zihui Ma,  Sanggyu Lee,  Huizi Yu,  Libby Hemphill",
                "发布日期": "2023-04-06",
                "摘要": "  Large language models (LLMs) are a class of language models that have\ndemonstrated outstanding performance across a range of natural language\nprocessing (NLP) tasks and have become a highly sought-after research area,\nbecause of their ability to generate human-like language and their potential to\nrevolutionize science and technology. In this study, we conduct bibliometric\nand discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000\npublications, this paper serves as a roadmap for researchers, practitioners,\nand policymakers to navigate the current landscape of LLMs research. We present\nthe research trends from 2017 to early 2023, identifying patterns in research\nparadigms and collaborations. We start with analyzing the core algorithm\ndevelopments and NLP tasks that are fundamental in LLMs research. We then\ninvestigate the applications of LLMs in various fields and domains including\nmedicine, engineering, social science, and humanities. Our review also reveals\nthe dynamic, fast-paced evolution of LLMs research. Overall, this paper offers\nvaluable insights into the current state, impact, and potential of LLMs\nresearch and its applications.\n",
                "链接": "https://arxiv.org/abs/2304.02020"
            },
            {
                "文章ID": "109281",
                "标题": "If the Sources Could Talk: Evaluating Large Language Models for Research\n  Assistance in History",
                "作者": " Giselle Gonzalez Garcia,  Christian Weilbach",
                "发布日期": "2023-10-18",
                "摘要": "  The recent advent of powerful Large-Language Models (LLM) provides a new\nconversational form of inquiry into historical memory (or, training data, in\nthis case). We show that by augmenting such LLMs with vector embeddings from\nhighly specialized academic sources, a conversational methodology can be made\naccessible to historians and other researchers in the Humanities. Concretely,\nwe evaluate and demonstrate how LLMs have the ability of assisting researchers\nwhile they examine a customized corpora of different types of documents,\nincluding, but not exclusive to: (1). primary sources, (2). secondary sources\nwritten by experts, and (3). the combination of these two. Compared to\nestablished search interfaces for digital catalogues, such as metadata and\nfull-text search, we evaluate the richer conversational style of LLMs on the\nperformance of two main types of tasks: (1). question-answering, and (2).\nextraction and organization of data. We demonstrate that LLMs semantic\nretrieval and reasoning abilities on problem-specific tasks can be applied to\nlarge textual archives that have not been part of the its training data.\nTherefore, LLMs can be augmented with sources relevant to specific research\nprojects, and can be queried privately by researchers.\n",
                "链接": "https://arxiv.org/abs/2310.10808"
            },
            {
                "文章ID": "71835",
                "标题": "Emergent autonomous scientific research capabilities of large language\n  models",
                "作者": " Daniil A. Boiko,  Robert MacKnight,  Gabe Gomes",
                "发布日期": "2023-04-12",
                "摘要": "  Transformer-based large language models are rapidly advancing in the field of\nmachine learning research, with applications spanning natural language,\nbiology, chemistry, and computer programming. Extreme scaling and reinforcement\nlearning from human feedback have significantly improved the quality of\ngenerated text, enabling these models to perform various tasks and reason about\ntheir choices. In this paper, we present an Intelligent Agent system that\ncombines multiple large language models for autonomous design, planning, and\nexecution of scientific experiments. We showcase the Agent's scientific\nresearch capabilities with three distinct examples, with the most complex being\nthe successful performance of catalyzed cross-coupling reactions. Finally, we\ndiscuss the safety implications of such systems and propose measures to prevent\ntheir misuse.\n",
                "链接": "https://arxiv.org/abs/2304.05332"
            },
            {
                "文章ID": "95564",
                "标题": "Evaluating the Generation Capabilities of Large Chinese Language Models",
                "作者": " Hui Zeng,  Jingyuan Xue,  Meng Hao,  Chen Sun,  Bin Ning,  Na Zhang",
                "发布日期": "2023-11-21",
                "摘要": "  This paper presents CG-Eval, the first comprehensive evaluation of the\ngeneration capabilities of large Chinese language models across a wide range of\nacademic disciplines. The models' performance was assessed based on their\nability to generate accurate and relevant responses to different types of\nquestions in six disciplines, namely, Science and Engineering, Humanities and\nSocial Sciences, Mathematical Calculations, Medical Practitioner Qualification\nExamination, Judicial Examination, and Certified Public Accountant Examination.\nThis paper also presents Gscore, a composite index derived from the weighted\nsum of multiple metrics to measure the quality of model's generation against a\nreference. The test data and test results can be found at\nhttp://cgeval.besteasy.com/.\n",
                "链接": "https://arxiv.org/abs/2308.04823"
            },
            {
                "文章ID": "66370",
                "标题": "Algorithmic Ghost in the Research Shell: Large Language Models and\n  Academic Knowledge Creation in Management Research",
                "作者": " Nigel Williams,  Stanislav Ivanov,  Dimitrios Buhalis",
                "发布日期": "2023-03-14",
                "摘要": "  The paper looks at the role of large language models in academic knowledge\ncreation based on a scoping review (2018 to January 2023) of how researchers\nhave previously used the language model GPT to assist in the performance of\nacademic knowledge creation tasks beyond data analysis. These tasks include\nwriting, editing, reviewing, dataset creation and curation, which have been\ndifficult to perform using earlier ML tools. Based on a synthesis of these\npapers, this study identifies pathways for a future academic research landscape\nthat incorporates wider usage of large language models based on the current\nmodes of adoption in published articles as a Co-Writer, Research Assistant and\nRespondent.\n",
                "链接": "https://arxiv.org/abs/2303.07304"
            },
            {
                "文章ID": "101124",
                "标题": "Toward Reproducing Network Research Results Using Large Language Models",
                "作者": " Qiao Xiang,  Yuling Lin,  Mingjun Fang,  Bang Huang,  Siyong Huang,  Ridi Wen,  Franck Le,  Linghe Kong,  Jiwu Shu",
                "发布日期": "2023-09-12",
                "摘要": "  Reproducing research results in the networking community is important for\nboth academia and industry. The current best practice typically resorts to\nthree approaches: (1) looking for publicly available prototypes; (2) contacting\nthe authors to get a private prototype; and (3) manually implementing a\nprototype following the description of the publication. However, most published\nnetwork research does not have public prototypes and private prototypes are\nhard to get. As such, most reproducing efforts are spent on manual\nimplementation based on the publications, which is both time and labor\nconsuming and error-prone. In this paper, we boldly propose reproducing network\nresearch results using the emerging large language models (LLMs). In\nparticular, we first prove its feasibility with a small-scale experiment, in\nwhich four students with essential networking knowledge each reproduces a\ndifferent networking system published in prominent conferences and journals by\nprompt engineering ChatGPT. We report the experiment's observations and lessons\nand discuss future open research questions of this proposal. This work raises\nno ethical issue.\n",
                "链接": "https://arxiv.org/abs/2309.04716"
            },
            {
                "文章ID": "78124",
                "标题": "M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark\n  for Chinese Large Language Models",
                "作者": " Chuang Liu,  Renren Jin,  Yuqi Ren,  Linhao Yu,  Tianyu Dong,  Xiaohan Peng,  Shuting Zhang,  Jianxiang Peng,  Peiyi Zhang,  Qingqing Lyu,  Xiaowen Su,  Qun Liu,  Deyi Xiong",
                "发布日期": "2023-05-23",
                "摘要": "  Large language models have recently made tremendous progress in a variety of\naspects, e.g., cross-task generalization, instruction following.\nComprehensively evaluating the capability of large language models in multiple\ntasks is of great importance. In this paper, we propose M3KE, a Massive\nMulti-Level Multi-Subject Knowledge Evaluation benchmark, which is developed to\nmeasure knowledge acquired by Chinese large language models by testing their\nmultitask accuracy in zero- and few-shot settings. We have collected 20,477\nquestions from 71 tasks. Our selection covers all major levels of Chinese\neducation system, ranging from the primary school to college, as well as a wide\nvariety of subjects, including humanities, history, politics, law, education,\npsychology, science, technology, art and religion. All questions are\nmultiple-choice questions with four options, hence guaranteeing a standardized\nand unified assessment process. We've assessed a number of state-of-the-art\nopen-source Chinese large language models on the proposed benchmark. The size\nof these models varies from 335M to 130B parameters. Experiment results\ndemonstrate that they perform significantly worse than GPT-3.5 that reaches an\naccuracy of ~ 48% on M3KE. The dataset is available at\nhttps://github.com/tjunlp-lab/M3KE.\n",
                "链接": "https://arxiv.org/abs/2305.10263"
            },
            {
                "文章ID": "123540",
                "标题": "User Modeling in the Era of Large Language Models: Current Research and\n  Future Directions",
                "作者": " Zhaoxuan Tan,  Meng Jiang",
                "发布日期": "2023-12-27",
                "摘要": "  User modeling (UM) aims to discover patterns or learn representations from\nuser data about the characteristics of a specific user, such as profile,\npreference, and personality. The user models enable personalization and\nsuspiciousness detection in many online applications such as recommendation,\neducation, and healthcare. Two common types of user data are text and graph, as\nthe data usually contain a large amount of user-generated content (UGC) and\nonline interactions. The research of text and graph mining is developing\nrapidly, contributing many notable solutions in the past two decades. Recently,\nlarge language models (LLMs) have shown superior performance on generating,\nunderstanding, and even reasoning over text data. The approaches of user\nmodeling have been equipped with LLMs and soon become outstanding. This article\nsummarizes existing research about how and why LLMs are great tools of modeling\nand understanding UGC. Then it reviews a few categories of large language\nmodels for user modeling (LLM-UM) approaches that integrate the LLMs with text\nand graph-based methods in different ways. Then it introduces specific LLM-UM\ntechniques for a variety of UM applications. Finally, it presents remaining\nchallenges and future directions in the LLM-UM research. We maintain the\nreading list at: https://github.com/TamSiuhin/LLM-UM-Reading\n",
                "链接": "https://arxiv.org/abs/2312.11518"
            },
            {
                "文章ID": "90102",
                "标题": "Shaping the Emerging Norms of Using Large Language Models in Social\n  Computing Research",
                "作者": " Hong Shen,  Tianshi Li,  Toby Jia-Jun Li,  Joon Sung Park,  Diyi Yang",
                "发布日期": "2023-07-11",
                "摘要": "  The emergence of Large Language Models (LLMs) has brought both excitement and\nconcerns to social computing research. On the one hand, LLMs offer\nunprecedented capabilities in analyzing vast amounts of textual data and\ngenerating human-like responses, enabling researchers to delve into complex\nsocial phenomena. On the other hand, concerns are emerging regarding the\nvalidity, privacy, and ethics of the research when LLMs are involved. This SIG\naims at offering an open space for social computing researchers who are\ninterested in understanding the impacts of LLMs to discuss their current\npractices, perspectives, challenges when engaging with LLMs in their everyday\nwork and collectively shaping the emerging norms of using LLMs in social\ncomputing research.\n",
                "链接": "https://arxiv.org/abs/2307.04280"
            },
            {
                "文章ID": "87578",
                "标题": "Potential Benefits of Employing Large Language Models in Research in\n  Moral Education and Development",
                "作者": " Hyemin Han",
                "发布日期": "2023-08-22",
                "摘要": "  Recently, computer scientists have developed large language models (LLMs) by\ntraining prediction models with large-scale language corpora and human\nreinforcements. The LLMs have become one promising way to implement artificial\nintelligence with accuracy in various fields. Interestingly, recent LLMs\npossess emergent functional features that emulate sophisticated human\ncognition, especially in-context learning and the chain of thought, which were\nunavailable in previous prediction models. In this paper, I will examine how\nLLMs might contribute to moral education and development research. To achieve\nthis goal, I will review the most recently published conference papers and\nArXiv preprints to overview the novel functional features implemented in LLMs.\nI also intend to conduct brief experiments with ChatGPT to investigate how LLMs\nbehave while addressing ethical dilemmas and external feedback. The results\nsuggest that LLMs might be capable of solving dilemmas based on reasoning and\nrevising their reasoning process with external input. Furthermore, a\npreliminary experimental result from the moral exemplar test may demonstrate\nthat exemplary stories can elicit moral elevation in LLMs as do they among\nhuman participants. I will discuss the potential implications of LLMs on\nresearch on moral education and development with the results.\n",
                "链接": "https://arxiv.org/abs/2306.13805"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和脑科学交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "112056",
                "标题": "Large-scale Foundation Models and Generative AI for BigData Neuroscience",
                "作者": " Ran Wang,  Zhe Sage Chen",
                "发布日期": "2023-10-31",
                "摘要": "  Recent advances in machine learning have made revolutionary breakthroughs in\ncomputer games, image and natural language understanding, and scientific\ndiscovery. Foundation models and large-scale language models (LLMs) have\nrecently achieved human-like intelligence thanks to BigData. With the help of\nself-supervised learning (SSL) and transfer learning, these models may\npotentially reshape the landscapes of neuroscience research and make a\nsignificant impact on the future. Here we present a mini-review on recent\nadvances in foundation models and generative AI models as well as their\napplications in neuroscience, including natural language and speech, semantic\nmemory, brain-machine interfaces (BMIs), and data augmentation. We argue that\nthis paradigm-shift framework will open new avenues for many neuroscience\nresearch directions and discuss the accompanying challenges and opportunities.\n",
                "链接": "https://arxiv.org/abs/2310.18377"
            },
            {
                "文章ID": "117074",
                "标题": "ATLANTIC: Structure-Aware Retrieval-Augmented Language Model for\n  Interdisciplinary Science",
                "作者": " Sai Munikoti,  Anurag Acharya,  Sridevi Wagle,  Sameera Horawalavithana",
                "发布日期": "2023-11-22",
                "摘要": "  Large language models record impressive performance on many natural language\nprocessing tasks. However, their knowledge capacity is limited to the\npretraining corpus. Retrieval augmentation offers an effective solution by\nretrieving context from external knowledge sources to complement the language\nmodel. However, existing retrieval augmentation techniques ignore the\nstructural relationships between these documents. Furthermore, retrieval models\nare not explored much in scientific tasks, especially in regard to the\nfaithfulness of retrieved documents. In this paper, we propose a novel\nstructure-aware retrieval augmented language model that accommodates document\nstructure during retrieval augmentation. We create a heterogeneous document\ngraph capturing multiple types of relationships (e.g., citation, co-authorship,\netc.) that connect documents from more than 15 scientific disciplines (e.g.,\nPhysics, Medicine, Chemistry, etc.). We train a graph neural network on the\ncurated document graph to act as a structural encoder for the corresponding\npassages retrieved during the model pretraining. Particularly, along with text\nembeddings of the retrieved passages, we obtain structural embeddings of the\ndocuments (passages) and fuse them together before feeding them to the language\nmodel. We evaluate our model extensively on various scientific benchmarks that\ninclude science question-answering and scientific document classification\ntasks. Experimental results demonstrate that structure-aware retrieval improves\nretrieving more coherent, faithful and contextually relevant passages, while\nshowing a comparable performance in the overall accuracy.\n",
                "链接": "https://arxiv.org/abs/2311.12289"
            },
            {
                "文章ID": "78623",
                "标题": "Towards Human-AI Collaborative Urban Science Research Enabled by\n  Pre-trained Large Language Models",
                "作者": " Jiayi Fu,  Haoying Han,  Xing Su,  Chao Fan",
                "发布日期": "2023-05-22",
                "摘要": "  Pre-trained large language models (PLMs) have the potential to support urban\nscience research through content creation, information extraction, assisted\nprogramming, text classification, and other technical advances. In this\nresearch, we explored the opportunities, challenges, and prospects of PLMs in\nurban science research. Specifically, we discussed potential applications of\nPLMs to urban institution, urban space, urban information, and citizen\nbehaviors research through seven examples using ChatGPT. We also examined the\nchallenges of PLMs in urban science research from both technical and social\nperspectives. The prospects of the application of PLMs in urban science\nresearch were then proposed. We found that PLMs can effectively aid in\nunderstanding complex concepts in urban science, facilitate urban spatial form\nidentification, assist in disaster monitoring, and sense public sentiment. At\nthe same time, however, the applications of PLMs in urban science research face\nevident threats, such as technical limitations, security, privacy, and social\nbias. The development of fundamental models based on domain knowledge and\nhuman-AI collaboration may help improve PLMs to support urban science research\nin future.\n",
                "链接": "https://arxiv.org/abs/2305.11418"
            },
            {
                "文章ID": "80483",
                "标题": "Science in the Era of ChatGPT, Large Language Models and Generative AI:\n  Challenges for Research Ethics and How to Respond",
                "作者": " Evangelos Pournaras",
                "发布日期": "2023-08-01",
                "摘要": "  Large language models of artificial intelligence (AI), such as ChatGPT, find\nremarkable but controversial applicability in science and research. This paper\nreviews epistemological challenges, ethical and integrity risks in science\nconduct in the advent of generative AI. This is with the aim to lay new timely\nfoundations for a high-quality research ethics review. The role of AI language\nmodels as a research instrument and subject is scrutinized along with ethical\nimplications for scientists, participants and reviewers. New emerging practices\nfor research ethics review are discussed, concluding with ten recommendations\nthat shape a response for a more responsible research conduct in the era of AI.\n",
                "链接": "https://arxiv.org/abs/2305.15299"
            },
            {
                "文章ID": "91982",
                "标题": "Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding\n  (Survey)",
                "作者": " Subba Reddy Oota,  Manish Gupta,  Raju S. Bapi,  Gael Jobard,  Frederic Alexandre,  Xavier Hinaut",
                "发布日期": "2023-07-21",
                "摘要": "  How does the brain represent different modes of information? Can we design a\nsystem that automatically understands what the user is thinking? Such questions\ncan be answered by studying brain recordings like functional magnetic resonance\nimaging (fMRI). As a first step, the neuroscience community has contributed\nseveral large cognitive neuroscience datasets related to passive\nreading/listening/viewing of concept words, narratives, pictures and movies.\nEncoding and decoding models using these datasets have also been proposed in\nthe past two decades. These models serve as additional tools for basic research\nin cognitive science and neuroscience. Encoding models aim at generating fMRI\nbrain representations given a stimulus automatically. They have several\npractical applications in evaluating and diagnosing neurological conditions and\nthus also help design therapies for brain damage. Decoding models solve the\ninverse problem of reconstructing the stimuli given the fMRI. They are useful\nfor designing brain-machine or brain-computer interfaces. Inspired by the\neffectiveness of deep learning models for natural language processing, computer\nvision, and speech, recently several neural encoding and decoding models have\nbeen proposed. In this survey, we will first discuss popular representations of\nlanguage, vision and speech stimuli, and present a summary of neuroscience\ndatasets. Further, we will review popular deep learning based encoding and\ndecoding architectures and note their benefits and limitations. Finally, we\nwill conclude with a brief summary and discussion about future trends. Given\nthe large amount of recently published work in the `computational cognitive\nneuroscience' community, we believe that this survey nicely organizes the\nplethora of work and presents it as a coherent story.\n",
                "链接": "https://arxiv.org/abs/2307.10246"
            },
            {
                "文章ID": "54735",
                "标题": "Training language models to summarize narratives improves brain\n  alignment",
                "作者": " Khai Loong Aw,  Mariya Toneva",
                "发布日期": "2023-03-02",
                "摘要": "  Building systems that achieve a deeper understanding of language is one of\nthe central goals of natural language processing (NLP). Towards this goal,\nrecent works have begun to train language models on narrative datasets which\nrequire extracting the most critical information by integrating across long\ncontexts. However, it is still an open question whether these models are\nlearning a deeper understanding of the text, or if the models are simply\nlearning a heuristic to complete the task. This work investigates this further\nby turning to the one language processing system that truly understands complex\nlanguage: the human brain. We show that training language models for deeper\nnarrative understanding results in richer representations that have improved\nalignment to human brain activity. We further find that the improvements in\nbrain alignment are larger for character names than for other discourse\nfeatures, which indicates that these models are learning important narrative\nelements. Taken together, these results suggest that this type of training can\nindeed lead to deeper language understanding. These findings have consequences\nboth for cognitive neuroscience by revealing some of the significant factors\nbehind brain-NLP alignment, and for NLP by highlighting that understanding of\nlong-range context can be improved beyond language modeling.\n",
                "链接": "https://arxiv.org/abs/2212.10898"
            },
            {
                "文章ID": "5542",
                "标题": "Integrating AI Planning with Natural Language Processing: A Combination\n  of Explicit and Tacit Knowledge",
                "作者": " Kebing Jin,  Hankz Hankui Zhuo",
                "发布日期": "2023-04-14",
                "摘要": "  Natural language processing (NLP) aims at investigating the interactions\nbetween agents and humans, processing and analyzing large amounts of natural\nlanguage data. Large-scale language models play an important role in current\nnatural language processing. However, the challenges of explainability and\ncomplexity come along with the developments of language models. One way is to\nintroduce logical relations and rules into natural language processing models,\nsuch as making use of Automated Planning. Automated planning (AI planning)\nfocuses on building symbolic domain models and synthesizing plans to transit\ninitial states to goals based on domain models. Recently, there have been\nplenty of works related to these two fields, which have the abilities to\ngenerate explicit knowledge, e.g., preconditions and effects of action models,\nand learn from tacit knowledge, e.g., neural models, respectively. Integrating\nAI planning and natural language processing effectively improves the\ncommunication between human and intelligent agents. This paper outlines the\ncommons and relations between AI planning and natural language processing,\nargues that each of them can effectively impact on the other one by five areas:\n(1) planning-based text understanding, (2) planning-based natural language\nprocessing, (3) planning-based explainability, (4) text-based human-robot\ninteraction, and (5) applications. We also explore some potential future issues\nbetween AI planning and natural language processing. To the best of our\nknowledge, this survey is the first work that addresses the deep connections\nbetween AI planning and Natural language processing.\n",
                "链接": "https://arxiv.org/abs/2202.07138"
            },
            {
                "文章ID": "39387",
                "标题": "Hierarchical MixUp Multi-label Classification with Imbalanced\n  Interdisciplinary Research Proposals",
                "作者": " Meng Xiao,  Min Wu,  Ziyue Qiao,  Zhiyuan Ning,  Yi Du,  Yanjie Fu,  Yuanchun Zhou",
                "发布日期": "2023-06-29",
                "摘要": "  Funding agencies are largely relied on a topic matching between domain\nexperts and research proposals to assign proposal reviewers. As proposals are\nincreasingly interdisciplinary, it is challenging to profile the\ninterdisciplinary nature of a proposal, and, thereafter, find expert reviewers\nwith an appropriate set of expertise. An essential step in solving this\nchallenge is to accurately model and classify the interdisciplinary labels of a\nproposal. Existing methodological and application-related literature, such as\ntextual classification and proposal classification, are insufficient in jointly\naddressing the three key unique issues introduced by interdisciplinary proposal\ndata: 1) the hierarchical structure of discipline labels of a proposal from\ncoarse-grain to fine-grain, e.g., from information science to AI to\nfundamentals of AI. 2) the heterogeneous semantics of various main textual\nparts that play different roles in a proposal; 3) the number of proposals is\nimbalanced between non-interdisciplinary and interdisciplinary research. Can we\nsimultaneously address the three issues in understanding the proposal's\ninterdisciplinary nature? In response to this question, we propose a\nhierarchical mixup multiple-label classification framework, which we called\nH-MixUp. H-MixUp leverages a transformer-based semantic information extractor\nand a GCN-based interdisciplinary knowledge extractor for the first and second\nissues. H-MixUp develops a fused training method of Wold-level MixUp,\nWord-level CutMix, Manifold MixUp, and Document-level MixUp to address the\nthird issue.\n",
                "链接": "https://arxiv.org/abs/2209.13912"
            },
            {
                "文章ID": "76934",
                "标题": "How Good are Commercial Large Language Models on African Languages?",
                "作者": " Jessica Ojo,  Kelechi Ogueji",
                "发布日期": "2023-05-12",
                "摘要": "  Recent advancements in Natural Language Processing (NLP) has led to the\nproliferation of large pretrained language models. These models have been shown\nto yield good performance, using in-context learning, even on unseen tasks and\nlanguages. They have also been exposed as commercial APIs as a form of\nlanguage-model-as-a-service, with great adoption. However, their performance on\nAfrican languages is largely unknown. We present a preliminary analysis of\ncommercial large language models on two tasks (machine translation and text\nclassification) across eight African languages, spanning different language\nfamilies and geographical areas. Our results suggest that commercial language\nmodels produce below-par performance on African languages. We also find that\nthey perform better on text classification than machine translation. In\ngeneral, our findings present a call-to-action to ensure African languages are\nwell represented in commercial large language models, given their growing\npopularity.\n",
                "链接": "https://arxiv.org/abs/2305.06530"
            },
            {
                "文章ID": "115369",
                "标题": "MEGAVERSE: Benchmarking Large Language Models Across Languages,\n  Modalities, Models and Tasks",
                "作者": " Sanchit Ahuja,  Divyanshu Aggarwal,  Varun Gumma,  Ishaan Watts,  Ashutosh Sathe,  Millicent Ochieng,  Rishav Hada,  Prachi Jain,  Maxamed Axmed,  Kalika Bali,  Sunayana Sitaram",
                "发布日期": "2023-11-14",
                "摘要": "  Recently, there has been a rapid advancement in research on Large Language\nModels (LLMs), resulting in significant progress in several Natural Language\nProcessing (NLP) tasks. Consequently, there has been a surge in LLM evaluation\nresearch to comprehend the models' capabilities and limitations. However, much\nof this research has been confined to the English language, leaving LLM\nbuilding and evaluation for non-English languages relatively unexplored. There\nhas been an introduction of several new LLMs, necessitating their evaluation on\nnon-English languages. This study aims to expand our MEGA benchmarking suite by\nincluding six new datasets to form the MEGAVERSE benchmark. The benchmark\ncomprises 22 datasets covering 81 languages, including low-resource African\nlanguages. We evaluate several state-of-the-art LLMs like GPT-3.5-Turbo, GPT4,\nPaLM2, and Llama2 on the MEGAVERSE datasets. Additionally, we include two\nmultimodal datasets in the benchmark and assess the performance of the\nLLaVa-v1.5 model. Our experiments suggest that GPT4 and PaLM2 outperform the\nLlama models on various tasks, notably on low-resource languages, with GPT4\noutperforming PaLM2 on more datasets than vice versa. However, issues such as\ndata contamination must be addressed to obtain an accurate assessment of LLM\nperformance on non-English languages.\n",
                "链接": "https://arxiv.org/abs/2311.07463"
            }
        ]
    },
    {
        "question": {
            "question": "2022年后与AI for Science相关的综述论文",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "108537",
                "标题": "Advancing Perception in Artificial Intelligence through Principles of\n  Cognitive Science",
                "作者": " Palaash Agrawal,  Cheston Tan,  Heena Rathore",
                "发布日期": "2023-10-16",
                "摘要": "  Although artificial intelligence (AI) has achieved many feats at a rapid\npace, there still exist open problems and fundamental shortcomings related to\nperformance and resource efficiency. Since AI researchers benchmark a\nsignificant proportion of performance standards through human intelligence,\ncognitive sciences-inspired AI is a promising domain of research. Studying\ncognitive science can provide a fresh perspective to building fundamental\nblocks in AI research, which can lead to improved performance and efficiency.\nIn this review paper, we focus on the cognitive functions of perception, which\nis the process of taking signals from one's surroundings as input, and\nprocessing them to understand the environment. Particularly, we study and\ncompare its various processes through the lens of both cognitive sciences and\nAI. Through this study, we review all current major theories from various\nsub-disciplines of cognitive science (specifically neuroscience, psychology and\nlinguistics), and draw parallels with theories and techniques from current\npractices in AI. We, hence, present a detailed collection of methods in AI for\nresearchers to build AI systems inspired by cognitive science. Further, through\nthe process of reviewing the state of cognitive-inspired AI, we point out many\ngaps in the current state of AI (with respect to the performance of the human\nbrain), and hence present potential directions for researchers to develop\nbetter perception systems in AI.\n",
                "链接": "https://arxiv.org/abs/2310.08803"
            },
            {
                "文章ID": "59467",
                "标题": "Serious Games and AI: Challenges and Opportunities for Computational\n  Social Science",
                "作者": " Jaime Pérez,  Mario Castro,  Gregorio López",
                "发布日期": "2023-07-06",
                "摘要": "  The video game industry plays an essential role in the entertainment sphere\nof our society. However, from Monopoly to Flight Simulators, serious games have\nalso been appealing tools for learning a new language, conveying values, or\ntraining skills. Furthermore, the resurgence of Artificial Intelligence (AI)\nand data science in the last decade has created a unique opportunity since the\namount of data collected through a game is immense, as is the amount of data\nneeded to feed such AI algorithms. This paper aims to identify relevant\nresearch lines using Serious Games as a novel research tool, especially in\nComputational Social Sciences. To contextualize, we also conduct a\n(non-systematic) literature review of this field. We conclude that the synergy\nbetween games and data can foster the use of AI for good and open up new\nstrategies to empower humanity and support social research with novel\ncomputational tools. We also discuss the challenges and new opportunities that\narise from aspiring to such lofty goals.\n",
                "链接": "https://arxiv.org/abs/2302.00500"
            },
            {
                "文章ID": "99506",
                "标题": "Science Communications for Explainable Artificial Intelligence",
                "作者": " Simon Hudson,  Matija Franklin",
                "发布日期": "2023-09-01",
                "摘要": "  Artificial Intelligence (AI) has a communication problem. XAI methods have\nbeen used to make AI more understandable and helped resolve some of the\ntransparency issues that inhibit AI's broader usability. However, user\nevaluation studies reveal that the often numerical explanations provided by XAI\nmethods have not always been effective for many types of users of AI systems.\nThis article aims to adapt the major communications models from Science\nCommunications into a framework for practitioners to understand, influence, and\nintegrate the context of audiences both for their communications supporting AI\nliteracy in the public and in designing XAI systems that are more adaptive to\ndifferent users.\n",
                "链接": "https://arxiv.org/abs/2308.16377"
            },
            {
                "文章ID": "121743",
                "标题": "Control Risk for Potential Misuse of Artificial Intelligence in Science",
                "作者": " Jiyan He,  Weitao Feng,  Yaosen Min,  Jingwei Yi,  Kunsheng Tang,  Shuai Li,  Jie Zhang,  Kejiang Chen,  Wenbo Zhou,  Xing Xie,  Weiming Zhang,  Nenghai Yu,  Shuxin Zheng",
                "发布日期": "2023-12-12",
                "摘要": "  The expanding application of Artificial Intelligence (AI) in scientific\nfields presents unprecedented opportunities for discovery and innovation.\nHowever, this growth is not without risks. AI models in science, if misused,\ncan amplify risks like creation of harmful substances, or circumvention of\nestablished regulations. In this study, we aim to raise awareness of the\ndangers of AI misuse in science, and call for responsible AI development and\nuse in this domain. We first itemize the risks posed by AI in scientific\ncontexts, then demonstrate the risks by highlighting real-world examples of\nmisuse in chemical science. These instances underscore the need for effective\nrisk management strategies. In response, we propose a system called SciGuard to\ncontrol misuse risks for AI models in science. We also propose a red-teaming\nbenchmark SciMT-Safety to assess the safety of different systems. Our proposed\nSciGuard shows the least harmful impact in the assessment without compromising\nperformance in benign tests. Finally, we highlight the need for a\nmultidisciplinary and collaborative effort to ensure the safe and ethical use\nof AI models in science. We hope that our study can spark productive\ndiscussions on using AI ethically in science among researchers, practitioners,\npolicymakers, and the public, to maximize benefits and minimize the risks of\nmisuse.\n",
                "链接": "https://arxiv.org/abs/2312.06632"
            },
            {
                "文章ID": "114602",
                "标题": "Interpretable Geoscience Artificial Intelligence (XGeoS-AI): Application\n  to Demystify Image Recognition",
                "作者": " Jin-Jian Xu,  Hao Zhang,  Chao-Sheng Tang,  Lin Li,  Bin Shi",
                "发布日期": "2023-11-10",
                "摘要": "  As Earth science enters the era of big data, artificial intelligence (AI) not\nonly offers great potential for solving geoscience problems, but also plays a\ncritical role in accelerating the understanding of the complex, interactive,\nand multiscale processes of Earth's behavior. As geoscience AI models are\nprogressively utilized for significant predictions in crucial situations,\ngeoscience researchers are increasingly demanding their interpretability and\nversatility. This study proposes an interpretable geoscience artificial\nintelligence (XGeoS-AI) framework to unravel the mystery of image recognition\nin the Earth sciences, and its effectiveness and versatility is demonstrated by\ntaking computed tomography (CT) image recognition as an example. Inspired by\nthe mechanism of human vision, the proposed XGeoS-AI framework generates a\nthreshold value from a local region within the whole image to complete the\nrecognition. Different kinds of artificial intelligence (AI) methods, such as\nSupport Vector Regression (SVR), Multilayer Perceptron (MLP), Convolutional\nNeural Network (CNN), can be adopted as the AI engines of the proposed XGeoS-AI\nframework to efficiently complete geoscience image recognition tasks.\nExperimental results demonstrate that the effectiveness, versatility, and\nheuristics of the proposed framework have great potential in solving geoscience\nimage recognition problems. Interpretable AI should receive more and more\nattention in the field of the Earth sciences, which is the key to promoting\nmore rational and wider applications of AI in the field of Earth sciences. In\naddition, the proposed interpretable framework may be the forerunner of\ntechnological innovation in the Earth sciences.\n",
                "链接": "https://arxiv.org/abs/2311.04940"
            },
            {
                "文章ID": "91365",
                "标题": "Artificial Intelligence for Science in Quantum, Atomistic, and Continuum\n  Systems",
                "作者": " Xuan Zhang,  Limei Wang,  Jacob Helwig,  Youzhi Luo,  Cong Fu,  Yaochen Xie,  Meng Liu,  Yuchao Lin,  Zhao Xu,  Keqiang Yan,  Keir Adams,  Maurice Weiler,  Xiner Li,  Tianfan Fu,  Yucheng Wang,  Haiyang Yu,  YuQing Xie,  Xiang Fu,  Alex Strasser,  Shenglong Xu,  Yi Liu,  Yuanqi Du,  Alexandra Saxton,  Hongyi Ling,  Hannah Lawrence,  Hannes Stärk,  Shurui Gui,  Carl Edwards,  Nicholas Gao,  Adriana Ladera,  Tailin Wu,  Elyssa F. Hofgard,  Aria Mansouri Tehrani,  Rui Wang,  Ameya Daigavane,  Montgomery Bohde,  Jerry Kurtin,  Qian Huang,  Tuong Phung,  Minkai Xu,  Chaitanya K. Joshi,  Simon V. Mathis,  Kamyar Azizzadenesheli,  Ada Fang,  Alán Aspuru-Guzik,  Erik Bekkers,  Michael Bronstein,  Marinka Zitnik,  Anima Anandkumar,  Stefano Ermon,  Pietro Liò,  Rose Yu,  Stephan Günnemann,  Jure Leskovec,  Heng Ji,  Jimeng Sun,  Regina Barzilay,  Tommi Jaakkola,  Connor W. Coley,  Xiaoning Qian,  Xiaofeng Qian,  Tess Smidt,  Shuiwang Ji",
                "发布日期": "2023-11-16",
                "摘要": "  Advances in artificial intelligence (AI) are fueling a new paradigm of\ndiscoveries in natural sciences. Today, AI has started to advance natural\nsciences by improving, accelerating, and enabling our understanding of natural\nphenomena at a wide range of spatial and temporal scales, giving rise to a new\narea of research known as AI for science (AI4Science). Being an emerging\nresearch paradigm, AI4Science is unique in that it is an enormous and highly\ninterdisciplinary area. Thus, a unified and technical treatment of this field\nis needed yet challenging. This work aims to provide a technically thorough\naccount of a subarea of AI4Science; namely, AI for quantum, atomistic, and\ncontinuum systems. These areas aim at understanding the physical world from the\nsubatomic (wavefunctions and electron density), atomic (molecules, proteins,\nmaterials, and interactions), to macro (fluids, climate, and subsurface) scales\nand form an important subarea of AI4Science. A unique advantage of focusing on\nthese areas is that they largely share a common set of challenges, thereby\nallowing a unified and foundational treatment. A key common challenge is how to\ncapture physics first principles, especially symmetries, in natural systems by\ndeep learning methods. We provide an in-depth yet intuitive account of\ntechniques to achieve equivariance to symmetry transformations. We also discuss\nother common technical challenges, including explainability,\nout-of-distribution generalization, knowledge transfer with foundation and\nlarge language models, and uncertainty quantification. To facilitate learning\nand education, we provide categorized lists of resources that we found to be\nuseful. We strive to be thorough and unified and hope this initial effort may\ntrigger more community interests and efforts to further advance AI4Science.\n",
                "链接": "https://arxiv.org/abs/2307.08423"
            },
            {
                "文章ID": "80483",
                "标题": "Science in the Era of ChatGPT, Large Language Models and Generative AI:\n  Challenges for Research Ethics and How to Respond",
                "作者": " Evangelos Pournaras",
                "发布日期": "2023-08-01",
                "摘要": "  Large language models of artificial intelligence (AI), such as ChatGPT, find\nremarkable but controversial applicability in science and research. This paper\nreviews epistemological challenges, ethical and integrity risks in science\nconduct in the advent of generative AI. This is with the aim to lay new timely\nfoundations for a high-quality research ethics review. The role of AI language\nmodels as a research instrument and subject is scrutinized along with ethical\nimplications for scientists, participants and reviewers. New emerging practices\nfor research ethics review are discussed, concluding with ten recommendations\nthat shape a response for a more responsible research conduct in the era of AI.\n",
                "链接": "https://arxiv.org/abs/2305.15299"
            },
            {
                "文章ID": "116688",
                "标题": "Best uses of ChatGPT and Generative AI for computer science research",
                "作者": " Eduardo C. Garrido-Merchan",
                "发布日期": "2023-11-21",
                "摘要": "  Generative Artificial Intelligence (AI), particularly tools like OpenAI's\npopular ChatGPT, is reshaping the landscape of computer science research. Used\nwisely, these tools can boost the productivity of a computer research\nscientist. This paper provides an exploration of the diverse applications of\nChatGPT and other generative AI technologies in computer science academic\nresearch, making recommendations about the use of Generative AI to make more\nproductive the role of the computer research scientist, with the focus of\nwriting new research papers. We highlight innovative uses such as brainstorming\nresearch ideas, aiding in the drafting and styling of academic papers and\nassisting in the synthesis of state-of-the-art section. Further, we delve into\nusing these technologies in understanding interdisciplinary approaches, making\ncomplex texts simpler, and recommending suitable academic journals for\npublication. Significant focus is placed on generative AI's contributions to\nsynthetic data creation, research methodology, and mentorship, as well as in\ntask organization and article quality assessment. The paper also addresses the\nutility of AI in article review, adapting texts to length constraints,\nconstructing counterarguments, and survey development. Moreover, we explore the\ncapabilities of these tools in disseminating ideas, generating images and\naudio, text transcription, and engaging with editors. We also describe some\nnon-recommended uses of generative AI for computer science research, mainly\nbecause of the limitations of this technology.\n",
                "链接": "https://arxiv.org/abs/2311.11175"
            },
            {
                "文章ID": "116561",
                "标题": "Generative AI has lowered the barriers to computational social sciences",
                "作者": " Yongjun Zhang",
                "发布日期": "2023-11-21",
                "摘要": "  Generative artificial intelligence (AI) has revolutionized the field of\ncomputational social science, unleashing new possibilities for analyzing\nmultimodal data, especially for scholars who may not have extensive programming\nexpertise. This breakthrough carries profound implications for the realm of\nsocial sciences. Firstly, generative AI can significantly enhance the\nproductivity of social scientists by automating the generation, annotation, and\ndebugging of code. Secondly, it empowers researchers to delve into\nsophisticated data analysis through the innovative use of prompt engineering.\nLastly, the educational sphere of computational social science stands to\nbenefit immensely from these tools, given their exceptional ability to annotate\nand elucidate complex codes for learners, thereby simplifying the learning\nprocess and making the technology more accessible.\n",
                "链接": "https://arxiv.org/abs/2311.10833"
            },
            {
                "文章ID": "96543",
                "标题": "REFORMS: Reporting Standards for Machine Learning Based Science",
                "作者": " Sayash Kapoor,  Emily Cantrell,  Kenny Peng,  Thanh Hien Pham,  Christopher A. Bail,  Odd Erik Gundersen,  Jake M. Hofman,  Jessica Hullman,  Michael A. Lones,  Momin M. Malik,  Priyanka Nanayakkara,  Russell A. Poldrack,  Inioluwa Deborah Raji,  Michael Roberts,  Matthew J. Salganik,  Marta Serra-Garcia,  Brandon M. Stewart,  Gilles Vandewiele,  Arvind Narayanan",
                "发布日期": "2023-09-21",
                "摘要": "  Machine learning (ML) methods are proliferating in scientific research.\nHowever, the adoption of these methods has been accompanied by failures of\nvalidity, reproducibility, and generalizability. These failures can hinder\nscientific progress, lead to false consensus around invalid claims, and\nundermine the credibility of ML-based science. ML methods are often applied and\nfail in similar ways across disciplines. Motivated by this observation, our\ngoal is to provide clear reporting standards for ML-based science. Drawing from\nan extensive review of past literature, we present the REFORMS checklist\n($\\textbf{Re}$porting Standards $\\textbf{For}$ $\\textbf{M}$achine Learning\nBased $\\textbf{S}$cience). It consists of 32 questions and a paired set of\nguidelines. REFORMS was developed based on a consensus of 19 researchers across\ncomputer science, data science, mathematics, social sciences, and biomedical\nsciences. REFORMS can serve as a resource for researchers when designing and\nimplementing a study, for referees when reviewing papers, and for journals when\nenforcing standards for transparency and reproducibility.\n",
                "链接": "https://arxiv.org/abs/2308.07832"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下2023年关于LLM-based Agent的综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "97862",
                "标题": "A Survey on Large Language Model based Autonomous Agents",
                "作者": " Lei Wang,  Chen Ma,  Xueyang Feng,  Zeyu Zhang,  Hao Yang,  Jingsen Zhang,  Zhiyuan Chen,  Jiakai Tang,  Xu Chen,  Yankai Lin,  Wayne Xin Zhao,  Zhewei Wei,  Ji-Rong Wen",
                "发布日期": "2023-09-08",
                "摘要": "  Autonomous agents have long been a prominent research focus in both academic\nand industry communities. Previous research in this field often focuses on\ntraining agents with limited knowledge within isolated environments, which\ndiverges significantly from human learning processes, and thus makes the agents\nhard to achieve human-like decisions. Recently, through the acquisition of vast\namounts of web knowledge, large language models (LLMs) have demonstrated\nremarkable potential in achieving human-level intelligence. This has sparked an\nupsurge in studies investigating LLM-based autonomous agents. In this paper, we\npresent a comprehensive survey of these studies, delivering a systematic review\nof the field of LLM-based autonomous agents from a holistic perspective. More\nspecifically, we first discuss the construction of LLM-based autonomous agents,\nfor which we propose a unified framework that encompasses a majority of the\nprevious work. Then, we present a comprehensive overview of the diverse\napplications of LLM-based autonomous agents in the fields of social science,\nnatural science, and engineering. Finally, we delve into the evaluation\nstrategies commonly used for LLM-based autonomous agents. Based on the previous\nstudies, we also present several challenges and future directions in this\nfield. To keep track of this field and continuously update our survey, we\nmaintain a repository of relevant references at\nhttps://github.com/Paitesanshi/LLM-Agent-Survey.\n",
                "链接": "https://arxiv.org/abs/2308.11432"
            },
            {
                "文章ID": "102059",
                "标题": "The Rise and Potential of Large Language Model Based Agents: A Survey",
                "作者": " Zhiheng Xi,  Wenxiang Chen,  Xin Guo,  Wei He,  Yiwen Ding,  Boyang Hong,  Ming Zhang,  Junzhe Wang,  Senjie Jin,  Enyu Zhou,  Rui Zheng,  Xiaoran Fan,  Xiao Wang,  Limao Xiong,  Yuhao Zhou,  Weiran Wang,  Changhao Jiang,  Yicheng Zou,  Xiangyang Liu,  Zhangyue Yin,  Shihan Dou,  Rongxiang Weng,  Wensen Cheng,  Qi Zhang,  Wenjuan Qin,  Yongyan Zheng,  Xipeng Qiu,  Xuanjing Huang,  Tao Gui",
                "发布日期": "2023-09-20",
                "摘要": "  For a long time, humanity has pursued artificial intelligence (AI) equivalent\nto or surpassing the human level, with AI agents considered a promising vehicle\nfor this pursuit. AI agents are artificial entities that sense their\nenvironment, make decisions, and take actions. Many efforts have been made to\ndevelop intelligent agents, but they mainly focus on advancement in algorithms\nor training strategies to enhance specific capabilities or performance on\nparticular tasks. Actually, what the community lacks is a general and powerful\nmodel to serve as a starting point for designing AI agents that can adapt to\ndiverse scenarios. Due to the versatile capabilities they demonstrate, large\nlanguage models (LLMs) are regarded as potential sparks for Artificial General\nIntelligence (AGI), offering hope for building general AI agents. Many\nresearchers have leveraged LLMs as the foundation to build AI agents and have\nachieved significant progress. In this paper, we perform a comprehensive survey\non LLM-based agents. We start by tracing the concept of agents from its\nphilosophical origins to its development in AI, and explain why LLMs are\nsuitable foundations for agents. Building upon this, we present a general\nframework for LLM-based agents, comprising three main components: brain,\nperception, and action, and the framework can be tailored for different\napplications. Subsequently, we explore the extensive applications of LLM-based\nagents in three aspects: single-agent scenarios, multi-agent scenarios, and\nhuman-agent cooperation. Following this, we delve into agent societies,\nexploring the behavior and personality of LLM-based agents, the social\nphenomena that emerge from an agent society, and the insights they offer for\nhuman society. Finally, we discuss several key topics and open problems within\nthe field. A repository for the related papers at\nhttps://github.com/WooooDyy/LLM-Agent-Paper-List.\n",
                "链接": "https://arxiv.org/abs/2309.07864"
            },
            {
                "文章ID": "122230",
                "标题": "A multi-sourced data and agent-based approach for complementing Time Use\n  Surveys in the context of residential human activity and load curve\n  simulation",
                "作者": "OASIS  Mathieu Schumann, OASIS  Quentin Reynaud, OASIS  François Sempé, RIFT, UNIGE  Julien Guibourdenche, CPU  Jean-Baptiste Ly, CPU, CPU, CPU  Nicolas Sabouret",
                "发布日期": "2023-12-14",
                "摘要": "  To address the major issues associated with using Time-Use Survey (TUS) for\nsimulating residential load curves, we present the SMACH approach, which\ncombines qualitative and quantitative data with agent-based simulation. Our\nmodel consists of autonomous agents assigned with daily tasks. The agents try\nto accomplish their assigned tasks to the best of their abilities. Quantitative\ndata are used to generate tasks assignments. Qualitative studies allow us to\ndefine how agents select, based on plausible cognitive principles, the tasks to\naccomplish depending on the context. Our results show a better representation\nof weekdays and weekends, a more flexible association of tasks with appliances,\nand an improved simulation of load curves compared to real data. Highlights\n$\\bullet$ Discussion about Time-Use Surveys (TUS) limits and the use of TUS in\nactivity and energy simulation $\\bullet$ Presentation of complementary data\nboth qualitative and quantitative used to complement TUS data $\\bullet$\nProposition of an agent-based approach that balances these limitations\n",
                "链接": "https://arxiv.org/abs/2312.07966"
            },
            {
                "文章ID": "106067",
                "标题": "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with\n  Agent Team Optimization",
                "作者": " Zijun Liu,  Yanzhe Zhang,  Peng Li,  Yang Liu,  Diyi Yang",
                "发布日期": "2023-10-04",
                "摘要": "  Large language model (LLM) agents have been shown effective on a wide range\nof tasks, and by ensembling multiple LLM agents, their performances could be\nfurther improved. Existing approaches employ a fixed set of agents to interact\nwith each other in a static architecture, which limits their generalizability\nto various tasks and requires strong human prior in designing these agents. In\nthis work, we propose to construct a strategic team of agents communicating in\na dynamic interaction architecture based on the task query. Specifically, we\nbuild a framework named Dynamic LLM-Agent Network ($\\textbf{DyLAN}$) for\nLLM-agent collaboration on complicated tasks like reasoning and code\ngeneration. DyLAN enables agents to interact for multiple rounds in a dynamic\narchitecture with inference-time agent selection and an early-stopping\nmechanism to improve performance and efficiency. We further design an automatic\nagent team optimization algorithm based on an unsupervised metric termed\n$\\textit{Agent Importance Score}$, enabling the selection of best agents based\non the contribution each agent makes. Empirically, we demonstrate that DyLAN\nperforms well in both reasoning and code generation tasks with reasonable\ncomputational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and\nHumanEval, respectively, compared to a single execution on GPT-35-turbo. On\nspecific subjects of MMLU, agent team optimization in DyLAN increases accuracy\nby up to 25.0%.\n",
                "链接": "https://arxiv.org/abs/2310.02170"
            },
            {
                "文章ID": "123719",
                "标题": "Large Language Models Empowered Agent-based Modeling and Simulation: A\n  Survey and Perspectives",
                "作者": " Chen Gao,  Xiaochong Lan,  Nian Li,  Yuan Yuan,  Jingtao Ding,  Zhilun Zhou,  Fengli Xu,  Yong Li",
                "发布日期": "2023-12-20",
                "摘要": "  Agent-based modeling and simulation has evolved as a powerful tool for\nmodeling complex systems, offering insights into emergent behaviors and\ninteractions among diverse agents. Integrating large language models into\nagent-based modeling and simulation presents a promising avenue for enhancing\nsimulation capabilities. This paper surveys the landscape of utilizing large\nlanguage models in agent-based modeling and simulation, examining their\nchallenges and promising future directions. In this survey, since this is an\ninterdisciplinary field, we first introduce the background of agent-based\nmodeling and simulation and large language model-empowered agents. We then\ndiscuss the motivation for applying large language models to agent-based\nsimulation and systematically analyze the challenges in environment perception,\nhuman alignment, action generation, and evaluation. Most importantly, we\nprovide a comprehensive overview of the recent works of large language\nmodel-empowered agent-based modeling and simulation in multiple scenarios,\nwhich can be divided into four domains: cyber, physical, social, and hybrid,\ncovering simulation of both real-world and virtual environments. Finally, since\nthis area is new and quickly evolving, we discuss the open problems and\npromising future directions.\n",
                "链接": "https://arxiv.org/abs/2312.11970"
            },
            {
                "文章ID": "120758",
                "标题": "LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent\n  Ecosystem",
                "作者": " Yingqiang Ge,  Yujie Ren,  Wenyue Hua,  Shuyuan Xu,  Juntao Tan,  Yongfeng Zhang",
                "发布日期": "2023-12-12",
                "摘要": "  This paper envisions a revolutionary AIOS-Agent ecosystem, where Large\nLanguage Model (LLM) serves as the (Artificial) Intelligent Operating System\n(IOS, or AIOS)--an operating system \"with soul\". Upon this foundation, a\ndiverse range of LLM-based AI Agent Applications (Agents, or AAPs) are\ndeveloped, enriching the AIOS-Agent ecosystem and signaling a paradigm shift\nfrom the traditional OS-APP ecosystem. We envision that LLM's impact will not\nbe limited to the AI application level, instead, it will in turn revolutionize\nthe design and implementation of computer system, architecture, software, and\nprogramming language, featured by several main concepts: LLM as OS\n(system-level), Agents as Applications (application-level), Natural Language as\nProgramming Interface (user-level), and Tools as Devices/Libraries\n(hardware/middleware-level). We begin by introducing the architecture of\ntraditional OS. Then we formalize a conceptual framework for AIOS through \"LLM\nas OS (LLMOS)\", drawing analogies between AIOS and traditional OS: LLM is\nlikened to OS kernel, context window to memory, external storage to file\nsystem, hardware tools to peripheral devices, software tools to programming\nlibraries, and user prompts to user commands. Subsequently, we introduce the\nnew AIOS-Agent Ecosystem, where users can easily program Agent Applications\n(AAPs) using natural language, democratizing the development of software, which\nis different from the traditional OS-APP ecosystem. Following this, we explore\nthe diverse scope of Agent Applications. We delve into both single-agent and\nmulti-agent systems, as well as human-agent interaction. Lastly, drawing on the\ninsights from traditional OS-APP ecosystem, we propose a roadmap for the\nevolution of the AIOS-Agent ecosystem. This roadmap is designed to guide the\nfuture research and development, suggesting systematic progresses of AIOS and\nits Agent applications.\n",
                "链接": "https://arxiv.org/abs/2312.03815"
            },
            {
                "文章ID": "115612",
                "标题": "Towards Reasoning in Large Language Models via Multi-Agent Peer Review\n  Collaboration",
                "作者": " Zhenran Xu,  Senbao Shi,  Baotian Hu,  Jindi Yu,  Dongfang Li,  Min Zhang,  Yuxiang Wu",
                "发布日期": "2023-12-19",
                "摘要": "  Large Language Models (LLMs) have shown remarkable capabilities in general\nnatural language processing tasks but often fall short in complex reasoning\ntasks. Recent studies have explored human-like problem-solving strategies, such\nas self-correct, to push further the boundary of single-model reasoning\nability. In this work, we let a single model \"step outside the box\" by engaging\nmultiple models to correct each other. We introduce a multi-agent collaboration\nstrategy that emulates the academic peer review process. Each agent\nindependently constructs its own solution, provides reviews on the solutions of\nothers, and assigns confidence levels to its reviews. Upon receiving peer\nreviews, agents revise their initial solutions. Extensive experiments on three\ndifferent types of reasoning tasks show that our collaboration approach\ndelivers superior accuracy across all ten datasets compared to existing\nmethods. Further study underscores the effectiveness of integrating confidence\nin reviews, demonstrates the superiority of feedback exchange over mere\nsolution sharing, and highlights the role of capability and diversity in\nfostering successful collaboration.\n",
                "链接": "https://arxiv.org/abs/2311.08152"
            },
            {
                "文章ID": "116128",
                "标题": "Simulating Opinion Dynamics with Networks of LLM-based Agents",
                "作者": " Yun-Shiuan Chuang,  Agam Goyal,  Nikunj Harlalka,  Siddharth Suresh,  Robert Hawkins,  Sijia Yang,  Dhavan Shah,  Junjie Hu,  Timothy T. Rogers",
                "发布日期": "2023-11-17",
                "摘要": "  Accurately simulating human opinion dynamics is crucial for understanding a\nvariety of societal phenomena, including polarization and the spread of\nmisinformation. However, the agent-based models (ABMs) commonly used for such\nsimulations lack fidelity to human behavior. We propose a new approach to\nsimulating opinion dynamics based on populations of Large Language Models\n(LLMs). Our findings reveal a strong inherent bias in LLM agents towards\naccurate information, leading to consensus in line with scientific reality.\nHowever, this bias limits the simulation of individuals with resistant views on\nissues like climate change. After inducing confirmation bias through prompt\nengineering, we observed opinion fragmentation in line with existing\nagent-based research. These insights highlight the promise and limitations of\nLLM agents in this domain and suggest a path forward: refining LLMs with\nreal-world discourse to better simulate the evolution of human beliefs.\n",
                "链接": "https://arxiv.org/abs/2311.09618"
            },
            {
                "文章ID": "116927",
                "标题": "Evil Geniuses: Delving into the Safety of LLM-based Agents",
                "作者": " Yu Tian,  Xiao Yang,  Jingyuan Zhang,  Yinpeng Dong,  Hang Su",
                "发布日期": "2023-11-21",
                "摘要": "  The rapid advancements in large language models (LLMs) have led to a\nresurgence in LLM-based agents, which demonstrate impressive human-like\nbehaviors and cooperative capabilities in various interactions and strategy\nformulations. However, evaluating the safety of LLM-based agents remains a\ncomplex challenge. This paper elaborately conducts a series of manual jailbreak\nprompts along with a virtual chat-powered evil plan development team, dubbed\nEvil Geniuses, to thoroughly probe the safety aspects of these agents. Our\ninvestigation reveals three notable phenomena: 1) LLM-based agents exhibit\nreduced robustness against malicious attacks. 2) the attacked agents could\nprovide more nuanced responses. 3) the detection of the produced improper\nresponses is more challenging. These insights prompt us to question the\neffectiveness of LLM-based attacks on agents, highlighting vulnerabilities at\nvarious levels and within different role specializations within the\nsystem/agent of LLM-based agents. Extensive evaluation and discussion reveal\nthat LLM-based agents face significant challenges in safety and yield insights\nfor future research. Our code is available at\nhttps://github.com/T1aNS1R/Evil-Geniuses.\n",
                "链接": "https://arxiv.org/abs/2311.11855"
            },
            {
                "文章ID": "119618",
                "标题": "The Efficiency Spectrum of Large Language Models: An Algorithmic Survey",
                "作者": " Tianyu Ding,  Tianyi Chen,  Haidong Zhu,  Jiachen Jiang,  Yiqi Zhong,  Jinxin Zhou,  Guangzhi Wang,  Zhihui Zhu,  Ilya Zharkov,  Luming Liang",
                "发布日期": "2023-12-04",
                "摘要": "  The rapid growth of Large Language Models (LLMs) has been a driving force in\ntransforming various domains, reshaping the artificial general intelligence\nlandscape. However, the increasing computational and memory demands of these\nmodels present substantial challenges, hindering both academic research and\npractical applications. To address these issues, a wide array of methods,\nincluding both algorithmic and hardware solutions, have been developed to\nenhance the efficiency of LLMs. This survey delivers a comprehensive review of\nalgorithmic advancements aimed at improving LLM efficiency. Unlike other\nsurveys that typically focus on specific areas such as training or model\ncompression, this paper examines the multi-faceted dimensions of efficiency\nessential for the end-to-end algorithmic development of LLMs. Specifically, it\ncovers various topics related to efficiency, including scaling laws, data\nutilization, architectural innovations, training and tuning strategies, and\ninference techniques. This paper aims to serve as a valuable resource for\nresearchers and practitioners, laying the groundwork for future innovations in\nthis critical research area. Our repository of relevant references is\nmaintained at url{https://github.com/tding1/Efficient-LLM-Survey}.\n",
                "链接": "https://arxiv.org/abs/2312.00678"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "99859",
                "标题": "Through their eyes: multi-subject Brain Decoding with simple alignment\n  techniques",
                "作者": " Matteo Ferrante,  Tommaso Boccato,  Nicola Toschi",
                "发布日期": "2023-09-06",
                "摘要": "  Previous brain decoding research primarily involves single-subject studies,\nreconstructing stimuli via fMRI activity from the same subject. Our study aims\nto introduce a generalization technique for cross-subject brain decoding,\nfacilitated by exploring data alignment methods. We utilized the NSD dataset, a\ncomprehensive 7T fMRI vision experiment involving multiple subjects exposed to\n9841 images, 982 of which were viewed by all. Our approach involved training a\ndecoding model on one subject, aligning others' data to this space, and testing\nthe decoding on the second subject. We compared ridge regression, hyper\nalignment, and anatomical alignment techniques for fMRI data alignment. We\nestablished that cross-subject brain decoding is feasible, even using around\n10% of the total data, or 982 common images, with comparable performance to\nsingle-subject decoding. Ridge regression was the best method for functional\nalignment. Through subject alignment, we achieved superior brain decoding and a\npotential 90% reduction in scan time. This could pave the way for more\nefficient experiments and further advancements in the field, typically\nrequiring an exorbitant 20-hour scan time per subject.\n",
                "链接": "https://arxiv.org/abs/2309.00627"
            },
            {
                "文章ID": "81153",
                "标题": "Efficient Decoding of Compositional Structure in Holistic\n  Representations",
                "作者": " Denis Kleyko,  Connor Bybee,  Ping-Chen Huang,  Christopher J. Kymn,  Bruno A. Olshausen,  E. Paxon Frady,  Friedrich T. Sommer",
                "发布日期": "2023-05-29",
                "摘要": "  We investigate the task of retrieving information from compositional\ndistributed representations formed by Hyperdimensional Computing/Vector\nSymbolic Architectures and present novel techniques which achieve new\ninformation rate bounds. First, we provide an overview of the decoding\ntechniques that can be used to approach the retrieval task. The techniques are\ncategorized into four groups. We then evaluate the considered techniques in\nseveral settings that involve, e.g., inclusion of external noise and storage\nelements with reduced precision. In particular, we find that the decoding\ntechniques from the sparse coding and compressed sensing literature (rarely\nused for Hyperdimensional Computing/Vector Symbolic Architectures) are also\nwell-suited for decoding information from the compositional distributed\nrepresentations. Combining these decoding techniques with interference\ncancellation ideas from communications improves previously reported bounds\n(Hersche et al., 2021) of the information rate of the distributed\nrepresentations from 1.20 to 1.40 bits per dimension for smaller codebooks and\nfrom 0.60 to 1.26 bits per dimension for larger codebooks.\n",
                "链接": "https://arxiv.org/abs/2305.16873"
            },
            {
                "文章ID": "48299",
                "标题": "High-Accuracy Machine Learning Techniques for Functional Connectome\n  Fingerprinting and Cognitive State Decoding",
                "作者": " Andrew Hannum,  Mario A. Lopez,  Saúl A. Blanco,  Richard F. Betzel",
                "发布日期": "2022-11-15",
                "摘要": "  The human brain is a complex network comprised of functionally and\nanatomically interconnected brain regions. A growing number of studies have\nsuggested that empirical estimates of brain networks may be useful for\ndiscovery of biomarkers of disease and cognitive state. A prerequisite for\nrealizing this aim, however, is that brain networks also serve as reliable\nmarkers of an individual. Here, using Human Connectome Project data, we build\nupon recent studies examining brain-based fingerprints of individual subjects\nand cognitive states based on cognitively-demanding tasks that assess, for\nexample, working memory, theory of mind, and motor function. Our approach\nachieves accuracy of up to 99\\% for both identification of the subject of an\nfMRI scan, and for classification of the cognitive state of a previously-unseen\nsubject in a scan. More broadly, we explore the accuracy and reliability of\nfive different machine learning techniques on subject fingerprinting and\ncognitive state decoding objectives, using functional connectivity data from\nfMRI scans of a high number of subjects (865) across a number of cognitive\nstates (8). These results represent an advance on existing techniques for\nfunctional connectivity-based brain fingerprinting and state decoding.\nAdditionally, 16 different pre-processing pipelines are compared in order to\ncharacterize the effects of different aspects of the production of functional\nconnectomes (FCs) on the accuracy of subject and task classification, and to\nidentify possible confounds.\n",
                "链接": "https://arxiv.org/abs/2211.07507"
            },
            {
                "文章ID": "115879",
                "标题": "Speculative Contrastive Decoding",
                "作者": " Hongyi Yuan,  Keming Lu,  Fei Huang,  Zheng Yuan,  Chang Zhou",
                "发布日期": "2023-11-16",
                "摘要": "  Large language models (LLMs) have shown extraordinary performance in various\nlanguage tasks, but high computational requirements hinder their widespread\ndeployment. Speculative decoding, which uses amateur models to predict the\ngeneration of expert models, has been proposed as a way to accelerate LLM\ninference. However, speculative decoding focuses on acceleration instead of\nmaking the best use of the token distribution from amateur models. We proposed\nSpeculative Contrastive Decoding (SCD), an accelerated decoding method\nleveraging the natural contrast between expert and amateur models in\nspeculative decoding. Comprehensive evaluations on four benchmarks show that\nSCD can achieve similar acceleration factors as speculative decoding while\nfurther improving the generation quality as the contrastive decoding. The\nanalysis of token probabilities further demonstrates the compatibility between\nspeculative and contrastive decoding. Overall, SCD provides an effective\napproach to enhance the decoding quality of LLMs while saving computational\nresources.\n",
                "链接": "https://arxiv.org/abs/2311.08981"
            },
            {
                "文章ID": "13791",
                "标题": "Knowledge Infused Decoding",
                "作者": " Ruibo Liu,  Guoqing Zheng,  Shashank Gupta,  Radhika Gaonkar,  Chongyang Gao,  Soroush Vosoughi,  Milad Shokouhi,  Ahmed Hassan Awadallah",
                "发布日期": "2022-04-08",
                "摘要": "  Pre-trained language models (LMs) have been shown to memorize a substantial\namount of knowledge from the pre-training corpora; however, they are still\nlimited in recalling factually correct knowledge given a certain context.\nHence, they tend to suffer from counterfactual or hallucinatory generation when\nused in knowledge-intensive natural language generation (NLG) tasks. Recent\nremedies to this problem focus on modifying either the pre-training or task\nfine-tuning objectives to incorporate knowledge, which normally require\nadditional costly training or architecture modification of LMs for practical\napplications. We present Knowledge Infused Decoding (KID) -- a novel decoding\nalgorithm for generative LMs, which dynamically infuses external knowledge into\neach step of the LM decoding. Specifically, we maintain a local knowledge\nmemory based on the current context, interacting with a dynamically created\nexternal knowledge trie, and continuously update the local memory as a\nknowledge-aware constraint to guide decoding via reinforcement learning. On six\ndiverse knowledge-intensive NLG tasks, task-agnostic LMs (e.g., GPT-2 and BART)\narmed with KID outperform many task-optimized state-of-the-art models, and show\nparticularly strong performance in few-shot scenarios over seven related\nknowledge-infusion techniques. Human evaluation confirms KID's ability to\ngenerate more relevant and factual language for the input context when compared\nwith multiple baselines. Finally, KID also alleviates exposure bias and\nprovides stable generation quality when generating longer sequences. Code for\nKID is available at https://github.com/microsoft/KID.\n",
                "链接": "https://arxiv.org/abs/2204.03084"
            },
            {
                "文章ID": "120092",
                "标题": "TPPoet: Transformer-Based Persian Poem Generation using Minimal Data and\n  Advanced Decoding Techniques",
                "作者": " Amir Panahandeh,  Hanie Asemi,  Esmaeil Nourani",
                "发布日期": "2023-12-07",
                "摘要": "  Recent advances in language models (LMs), have demonstrated significant\nefficacy in tasks related to the arts and humanities. While LMs have exhibited\nexceptional performance across a wide range of natural language processing\ntasks, there are notable challenges associated with their utilization on small\ndatasets and their ability to replicate more creative human capacities. In this\nstudy, we aim to address these challenges by training a Persian classical\npoetry generation model using a transformer architecture on a specialized\ndataset with no pretraining. Additionally, we propose a novel decoding method\nto enhance coherence and meaningfulness in the generated poetry, effectively\nmanaging the tradeoff between diversity and quality. Furthermore, the results\nof our training approach and the proposed decoding method are evaluated through\ncomprehensive set of automatic and human evaluations and showed its superior\ncapability to generate coherent and meaningful poetry in compare to other\ndecoding methods and an existing Persian large language model (LLM).\n",
                "链接": "https://arxiv.org/abs/2312.02125"
            },
            {
                "文章ID": "47160",
                "标题": "Decoding Neural Signals with Computational Models: A Systematic Review\n  of Invasive BMI",
                "作者": " Rezwan Firuzi,  Hamed Ahmadyani,  Mohammad Foad Abdi,  Dana Naderi,  Jahan Hassan,  Ayub Bokani",
                "发布日期": "2022-11-08",
                "摘要": "  There are significant milestones in modern human's civilization in which\nmankind stepped into a different level of life with a new spectrum of\npossibilities and comfort. From fire-lighting technology and wheeled wagons to\nwriting, electricity and the Internet, each one changed our lives dramatically.\nIn this paper, we take a deep look into the invasive Brain Machine Interface\n(BMI), an ambitious and cutting-edge technology which has the potential to be\nanother important milestone in human civilization. Not only beneficial for\npatients with severe medical conditions, the invasive BMI technology can\nsignificantly impact different technologies and almost every aspect of human's\nlife. We review the biological and engineering concepts that underpin the\nimplementation of BMI applications. There are various essential techniques that\nare necessary for making invasive BMI applications a reality. We review these\nthrough providing an analysis of (i) possible applications of invasive BMI\ntechnology, (ii) the methods and devices for detecting and decoding brain\nsignals, as well as (iii) possible options for stimulating signals into human's\nbrain. Finally, we discuss the challenges and opportunities of invasive BMI for\nfurther development in the area.\n",
                "链接": "https://arxiv.org/abs/2211.03324"
            },
            {
                "文章ID": "90598",
                "标题": "Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM\n  Decoding",
                "作者": " Seongjun Yang,  Gibbeum Lee,  Jaewoong Cho,  Dimitris Papailiopoulos,  Kangwook Lee",
                "发布日期": "2023-07-13",
                "摘要": "  This paper presents \"Predictive Pipelined Decoding (PPD),\" an approach that\nspeeds up greedy decoding in Large Language Models (LLMs) while maintaining the\nexact same output as the original decoding. Unlike conventional strategies, PPD\nemploys additional compute resources to parallelize the initiation of\nsubsequent token decoding during the current token decoding. This innovative\nmethod reduces decoding latency and reshapes the understanding of trade-offs in\nLLM decoding strategies. We have developed a theoretical framework that allows\nus to analyze the trade-off between computation and latency. Using this\nframework, we can analytically estimate the potential reduction in latency\nassociated with our proposed method, achieved through the assessment of the\nmatch rate, represented as p_correct. The results demonstrate that the use of\nextra computational resources has the potential to accelerate LLM greedy\ndecoding.\n",
                "链接": "https://arxiv.org/abs/2307.05908"
            },
            {
                "文章ID": "17492",
                "标题": "Quality-Aware Decoding for Neural Machine Translation",
                "作者": " Patrick Fernandes,  António Farinhas,  Ricardo Rei,  José G. C. de Souza,  Perez Ogayo,  Graham Neubig,  André F. T. Martins",
                "发布日期": "2022-05-03",
                "摘要": "  Despite the progress in machine translation quality estimation and evaluation\nin the last years, decoding in neural machine translation (NMT) is mostly\noblivious to this and centers around finding the most probable translation\naccording to the model (MAP decoding), approximated with beam search. In this\npaper, we bring together these two lines of research and propose quality-aware\ndecoding for NMT, by leveraging recent breakthroughs in reference-free and\nreference-based MT evaluation through various inference methods like $N$-best\nreranking and minimum Bayes risk decoding. We perform an extensive comparison\nof various possible candidate generation and ranking methods across four\ndatasets and two model classes and find that quality-aware decoding\nconsistently outperforms MAP-based decoding according both to state-of-the-art\nautomatic metrics (COMET and BLEURT) and to human assessments. Our code is\navailable at https://github.com/deep-spin/qaware-decode.\n",
                "链接": "https://arxiv.org/abs/2205.00978"
            },
            {
                "文章ID": "110770",
                "标题": "Air-Decoding: Attribute Distribution Reconstruction for Decoding-Time\n  Controllable Text Generation",
                "作者": " Tianqi Zhong,  Quan Wang,  Jingxuan Han,  Yongdong Zhang,  Zhendong Mao",
                "发布日期": "2023-11-03",
                "摘要": "  Controllable text generation (CTG) aims to generate text with desired\nattributes, and decoding-time-based methods have shown promising performance on\nthis task. However, in this paper, we identify the phenomenon of Attribute\nCollapse for the first time. It causes the fluency of generated text to rapidly\ndecrease when the control strength exceeds a critical value, rendering the text\ncompletely unusable. This limitation hinders the effectiveness of decoding\nmethods in achieving high levels of controllability. To address this problem,\nwe propose a novel lightweight decoding framework named Air-Decoding. Its main\nidea is reconstructing the attribute distributions to balance the weights\nbetween attribute words and non-attribute words to generate more fluent text.\nSpecifically, we train prefixes by prefix-tuning to obtain attribute\ndistributions. Then we design a novel attribute distribution reconstruction\nmethod to balance the obtained distributions and use the reconstructed\ndistributions to guide language models for generation, effectively avoiding the\nissue of Attribute Collapse. Experiments on multiple CTG tasks prove that our\nmethod achieves a new state-of-the-art control performance.\n",
                "链接": "https://arxiv.org/abs/2310.14892"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近三个月有关语言模型rlhf的arxiv上的全部文章。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大模型结合树搜索方法进行推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105172",
                "标题": "Alphazero-like Tree-Search can Guide Large Language Model Decoding and\n  Training",
                "作者": " Xidong Feng,  Ziyu Wan,  Muning Wen,  Ying Wen,  Weinan Zhang,  Jun Wang",
                "发布日期": "2023-10-02",
                "摘要": "  Large language models (LLMs) typically employ sampling or beam search,\naccompanied by prompts such as Chain-of-Thought (CoT), to boost reasoning and\ndecoding ability. Recent work like Tree-of-Thought (ToT) and Reasoning via\nPlanning (RAP) aim to augment the reasoning capabilities of LLMs by utilizing\ntree-search algorithms to guide multi-step reasoning. These methods mainly\nfocus on LLMs' reasoning ability during inference and heavily rely on\nhuman-designed prompts to activate LLM as a value function, which lacks general\napplicability and scalability. To address these limitations, we present an\nAlphaZero-like tree-search framework for LLMs (termed TS-LLM), systematically\nillustrating how tree-search with a learned value function can guide LLMs'\ndecoding ability. TS-LLM distinguishes itself in two key ways: (1) Leveraging a\nlearned value function, our approach can be generally applied to different\ntasks beyond reasoning (such as RLHF alignment), and LLMs of any size, without\nprompting advanced, large-scale models. (2) It can guide LLM's decoding during\nboth inference and training. Empirical evaluations across reasoning, planning,\nand RLHF alignment tasks validate the effectiveness of TS-LLM, even on trees\nwith a depth of 64.\n",
                "链接": "https://arxiv.org/abs/2309.17179"
            },
            {
                "文章ID": "109239",
                "标题": "Autonomous Tree-search Ability of Large Language Models",
                "作者": " Zheyu Zhang,  Zhuorui Ye,  Yikang Shen,  Chuang Gan",
                "发布日期": "2023-10-18",
                "摘要": "  Large Language Models have excelled in remarkable reasoning capabilities with\nadvanced prompting techniques, but they fall short on tasks that require\nexploration, strategic foresight, and sequential decision-making. Recent works\npropose to utilize external programs to define search logic, such that LLMs can\nperform passive tree search to solve more challenging reasoning tasks. Though\nimpressive results have been achieved, there are several fundamental\nlimitations of these approaches. First, passive tree searches are not efficient\nas they usually require multiple rounds of LLM API calls to solve one single\nproblem. Moreover, passive search methods are not flexible since they need\ntask-specific program designs. Then a natural question arises: can we maintain\nthe tree-search capability of LLMs without the aid of external programs, and\ncan still generate responses that clearly demonstrate the process of a\ntree-structure search? To this end, we propose a new concept called autonomous\ntree-search ability of LLM, which can automatically generate a response\ncontaining search trajectories for the correct answer. Concretely, we perform\nsearch trajectories using capable LLM API via a fixed system prompt, allowing\nthem to perform autonomous tree-search (ATS) right out of the box. Experiments\non 4 puzzle games demonstrate our method can achieve huge improvements. The\nATS-BFS method outperforms the Chain of Thought approach by achieving an\naverage accuracy improvement of 33%. Compared to Tree of Thoughts, it requires\n65.6% or 47.7% less GPT-api cost to attain a comparable level of accuracy.\nMoreover, we have collected data using the ATS prompt method and fine-tuned\nLLaMA. This approach yield a greater improvement compared to the ones\nfine-tuned on CoT data. Specifically, it outperforms CoT-tuned LLaMAs by an\naverage of 40.6% and 38.5% for LLaMA2-7B and LLaMA2-13B, respectively.\n",
                "链接": "https://arxiv.org/abs/2310.10686"
            },
            {
                "文章ID": "79447",
                "标题": "Enhance Reasoning Ability of Visual-Language Models via Large Language\n  Models",
                "作者": " Yueting Yang,  Xintong Zhang,  Wenjuan Han",
                "发布日期": "2023-05-23",
                "摘要": "  Pre-trained visual language models (VLM) have shown excellent performance in\nimage caption tasks. However, it sometimes shows insufficient reasoning\nability. In contrast, large language models (LLMs) emerge with powerful\nreasoning capabilities. Therefore, we propose a method called TReE, which\ntransfers the reasoning ability of a large language model to a visual language\nmodel in zero-shot scenarios. TReE contains three stages: observation,\nthinking, and re-thinking. Observation stage indicates that VLM obtains the\noverall information of the relative image. Thinking stage combines the image\ninformation and task description as the prompt of the LLM, inference with the\nrationals. Re-Thinking stage learns from rationale and then inference the final\nresult through VLM.\n",
                "链接": "https://arxiv.org/abs/2305.13267"
            },
            {
                "文章ID": "105289",
                "标题": "SocREval: Large Language Models with the Socratic Method for\n  Reference-Free Reasoning Evaluation",
                "作者": " Hangfeng He,  Hongming Zhang,  Dan Roth",
                "发布日期": "2023-10-03",
                "摘要": "  To comprehensively assess the capacity of current models for complex\nreasoning, it is crucial to assess their step-by-step reasoning in a scalable\nmanner. Established reference-based evaluation metrics rely on human-annotated\nreasoning chains to assess the model-derived chains. However, such\n``gold-standard'' human-written reasoning chains may not be unique and their\nacquisition is often labor-intensive. Existing reference-free reasoning metrics\neliminate the need for human-crafted reasoning chains as references, but they\ntypically require fine-tuning on datasets with human-derived reasoning chains,\nwhich complicates the process and raises concerns regarding generalizability\nacross diverse datasets. To address these challenges, we harness GPT-4 to\nautomatically evaluate reasoning chain quality, obviating the need for\nhuman-crafted references. Leveraging the Socratic method, we devise tailored\nprompts to enhance reference-free reasoning evaluation, which we term SocREval\n(Socratic method for Reasoning Evaluation). Empirical results from four human\nannotated datasets reveal that SocREval significantly improves GPT-4's\nperformance, surpassing existing reference-free and reference-based reasoning\nevaluation metrics. Beyond its demonstrated efficacy, our proposed framework,\nlarge language models (LLMs) with the Socratic method, proves to be both\ncost-efficient and robust to prompt writing and example selection, as\nsubstantiated by our in-depth analysis.\n",
                "链接": "https://arxiv.org/abs/2310.00074"
            },
            {
                "文章ID": "78273",
                "标题": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
                "作者": " Shunyu Yao,  Dian Yu,  Jeffrey Zhao,  Izhak Shafran,  Thomas L. Griffiths,  Yuan Cao,  Karthik Narasimhan",
                "发布日期": "2023-12-05",
                "摘要": "  Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nhttps://github.com/princeton-nlp/tree-of-thought-llm.\n",
                "链接": "https://arxiv.org/abs/2305.10601"
            },
            {
                "文章ID": "71550",
                "标题": "Inference with Reference: Lossless Acceleration of Large Language Models",
                "作者": " Nan Yang,  Tao Ge,  Liang Wang,  Binxing Jiao,  Daxin Jiang,  Linjun Yang,  Rangan Majumder,  Furu Wei",
                "发布日期": "2023-04-11",
                "摘要": "  We propose LLMA, an LLM accelerator to losslessly speed up Large Language\nModel (LLM) inference with references. LLMA is motivated by the observation\nthat there are abundant identical text spans between the decoding result by an\nLLM and the reference that is available in many real world scenarios (e.g.,\nretrieved documents). LLMA first selects a text span from the reference and\ncopies its tokens to the decoder and then efficiently checks the tokens'\nappropriateness as the decoding result in parallel within one decoding step.\nThe improved computational parallelism allows LLMA to achieve over 2x speed-up\nfor LLMs with identical generation results as greedy decoding in many practical\ngeneration scenarios where significant overlap between in-context reference and\noutputs exists (e.g., search engines and multi-turn conversations).\n",
                "链接": "https://arxiv.org/abs/2304.04487"
            },
            {
                "文章ID": "106837",
                "标题": "Language Agent Tree Search Unifies Reasoning Acting and Planning in\n  Language Models",
                "作者": " Andy Zhou,  Kai Yan,  Michal Shlapentokh-Rothman,  Haohan Wang,  Yu-Xiong Wang",
                "发布日期": "2023-12-06",
                "摘要": "  While large language models (LLMs) have demonstrated impressive performance\non a range of decision-making tasks, they rely on simple acting processes and\nfall short of broad deployment as autonomous agents. We introduce LATS\n(Language Agent Tree Search), a general framework that synergizes the\ncapabilities of LLMs in planning, acting, and reasoning. Drawing inspiration\nfrom Monte Carlo tree search in model-based reinforcement learning, LATS\nemploys LLMs as agents, value functions, and optimizers, repurposing their\nlatent strengths for enhanced decision-making. What is crucial in this method\nis the use of an environment for external feedback, which offers a more\ndeliberate and adaptive problem-solving mechanism that moves beyond the\nlimitations of existing techniques. Our experimental evaluation across diverse\ndomains, such as programming, HotPotQA, and WebShop, illustrates the\napplicability of LATS for both reasoning and acting. In particular, LATS\nachieves 94.4% for programming on HumanEval with GPT-4 and an average score of\n75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness\nand generality of our method.\n",
                "链接": "https://arxiv.org/abs/2310.04406"
            },
            {
                "文章ID": "77937",
                "标题": "SpecInfer: Accelerating Generative Large Language Model Serving with\n  Speculative Inference and Token Tree Verification",
                "作者": " Xupeng Miao,  Gabriele Oliaro,  Zhihao Zhang,  Xinhao Cheng,  Zeyu Wang,  Rae Ying Yee Wong,  Alan Zhu,  Lijie Yang,  Xiaoxiang Shi,  Chunan Shi,  Zhuoming Chen,  Daiyaan Arfeen,  Reyna Abhyankar,  Zhihao Jia",
                "发布日期": "2023-08-17",
                "摘要": "  The high computational and memory requirements of generative large language\nmodels (LLMs) make it challenging to serve them quickly and cheaply. This paper\nintroduces SpecInfer, an LLM serving system that accelerates generative LLM\ninference with speculative inference and token tree verification. A key insight\nbehind Specinfer is to combine various collectively boost-tuned small language\nmodels to jointly predict the LLM's outputs; the predictions are organized as a\ntoken tree, whose nodes each represent a candidate token sequence. The\ncorrectness of all candidate token sequences represented by a token tree is\nverified against the LLM in parallel using a novel tree-based parallel decoding\nmechanism. SpecInfer uses an LLM as a token tree verifier instead of an\nincremental decoder, which significantly reduces the end-to-end latency and\ncomputational requirement for serving generative LLMs while provably preserving\nmodel quality. Our evaluation shows that SpecInfer outperforms existing LLM\nserving systems by 1.3-2.4x for distributed LLM inference and by 2.6-3.5x for\noffloading-based LLM inference, while preserving the same generative\nperformance. SpecInfer is publicly available at\nhttps://github.com/flexflow/FlexFlow/tree/inference.\n",
                "链接": "https://arxiv.org/abs/2305.09781"
            },
            {
                "文章ID": "19994",
                "标题": "Selection-Inference: Exploiting Large Language Models for Interpretable\n  Logical Reasoning",
                "作者": " Antonia Creswell,  Murray Shanahan,  Irina Higgins",
                "发布日期": "2022-05-20",
                "摘要": "  Large language models (LLMs) have been shown to be capable of impressive\nfew-shot generalisation to new tasks. However, they still tend to perform\npoorly on multi-step logical reasoning problems. Here we carry out a\ncomprehensive evaluation of LLMs on 50 tasks that probe different aspects of\nlogical reasoning. We show that language models tend to perform fairly well at\nsingle step inference or entailment tasks, but struggle to chain together\nmultiple reasoning steps to solve more complex problems. In light of this, we\npropose a Selection-Inference (SI) framework that exploits pre-trained LLMs as\ngeneral processing modules, and alternates between selection and inference to\ngenerate a series of interpretable, casual reasoning steps leading to the final\nanswer. We show that a 7B parameter LLM used within the SI framework in a\n5-shot generalisation setting, with no fine-tuning, yields a performance\nimprovement of over 100% compared to an equivalent vanilla baseline on a suite\nof 10 logical reasoning tasks. The same model in the same setting even\noutperforms a significantly larger 280B parameter baseline on the same suite of\ntasks. Moreover, answers produced by the SI framework are accompanied by a\ncausal natural-language-based reasoning trace, which has important implications\nfor the safety and trustworthiness of the system.\n",
                "链接": "https://arxiv.org/abs/2205.09712"
            },
            {
                "文章ID": "100689",
                "标题": "No Train Still Gain. Unleash Mathematical Reasoning of Large Language\n  Models with Monte Carlo Tree Search Guided by Energy Function",
                "作者": " Haotian Xu",
                "发布日期": "2023-09-13",
                "摘要": "  Large language models (LLMs) demonstrate impressive language understanding\nand contextual learning abilities, making them suitable for natural language\nprocessing (NLP) tasks and complex mathematical reasoning. However, when\napplied to mathematical reasoning tasks, LLMs often struggle to generate\ncorrect reasoning steps and answers despite having high probabilities for the\nsolutions. To overcome this limitation and enhance the mathematical reasoning\ncapabilities of fine-tuned LLMs without additional fine-tuning steps, we\npropose a method that incorporates Monte Carlo Tree Search (MCTS) and a\nlightweight energy function to rank decision steps and enable immediate\nreaction and precise reasoning. Specifically, we re-formulate the fine-tuned\nLLMs into a Residual-based Energy Model (Residual-EBM) and employ noise\ncontrastive estimation to estimate the energy function's parameters. We then\nutilize MCTS with the energy function as a path verifier to search the output\nspace and evaluate the reasoning path. Through extensive experiments on two\nmathematical reasoning benchmarks, GSM8k and AQUA-RAT, we demonstrate the\nexceptional capabilities of our method, which significantly improves the pass@1\nmetric of the fine-tuned model without requiring additional fine-tuning or\nreinforcement learning with human feedback alignment.\n",
                "链接": "https://arxiv.org/abs/2309.03224"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于通过prompt经验性研究大语言模型行为的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "72018",
                "标题": "Boosted Prompt Ensembles for Large Language Models",
                "作者": " Silviu Pitis,  Michael R. Zhang,  Andrew Wang,  Jimmy Ba",
                "发布日期": "2023-04-13",
                "摘要": "  Methods such as chain-of-thought prompting and self-consistency have pushed\nthe frontier of language model reasoning performance with no additional\ntraining. To further improve performance, we propose a prompt ensembling method\nfor large language models, which uses a small dataset to construct a set of few\nshot prompts that together comprise a ``boosted prompt ensemble''. The few shot\nexamples for each prompt are chosen in a stepwise fashion to be ``hard''\nexamples on which the previous step's ensemble is uncertain. We show that this\noutperforms single-prompt output-space ensembles and bagged prompt-space\nensembles on the GSM8k and AQuA datasets, among others. We propose both\ntrain-time and test-time versions of boosted prompting that use different\nlevels of available annotation and conduct a detailed empirical study of our\nalgorithm.\n",
                "链接": "https://arxiv.org/abs/2304.05970"
            },
            {
                "文章ID": "58986",
                "标题": "On Robustness of Prompt-based Semantic Parsing with Large Pre-trained\n  Language Model: An Empirical Study on Codex",
                "作者": " Terry Yue Zhuo,  Zhuang Li,  Yujin Huang,  Fatemeh Shiri,  Weiqing Wang,  Gholamreza Haffari,  Yuan-Fang Li",
                "发布日期": "2023-03-10",
                "摘要": "  Semantic parsing is a technique aimed at constructing a structured\nrepresentation of the meaning of a natural-language question. Recent\nadvancements in few-shot language models trained on code have demonstrated\nsuperior performance in generating these representations compared to\ntraditional unimodal language models, which are trained on downstream tasks.\nDespite these advancements, existing fine-tuned neural semantic parsers are\nsusceptible to adversarial attacks on natural-language inputs. While it has\nbeen established that the robustness of smaller semantic parsers can be\nenhanced through adversarial training, this approach is not feasible for large\nlanguage models in real-world scenarios, as it requires both substantial\ncomputational resources and expensive human annotation on in-domain semantic\nparsing data. This paper presents the first empirical study on the adversarial\nrobustness of a large prompt-based language model of code, \\codex. Our results\ndemonstrate that the state-of-the-art (SOTA) code-language models are\nvulnerable to carefully crafted adversarial examples. To address this\nchallenge, we propose methods for improving robustness without the need for\nsignificant amounts of labeled data or heavy computational resources.\n",
                "链接": "https://arxiv.org/abs/2301.12868"
            },
            {
                "文章ID": "102889",
                "标题": "Explaining Agent Behavior with Large Language Models",
                "作者": " Xijia Zhang,  Yue Guo,  Simon Stepputtis,  Katia Sycara,  Joseph Campbell",
                "发布日期": "2023-09-20",
                "摘要": "  Intelligent agents such as robots are increasingly deployed in real-world,\nsafety-critical settings. It is vital that these agents are able to explain the\nreasoning behind their decisions to human counterparts, however, their behavior\nis often produced by uninterpretable models such as deep neural networks. We\npropose an approach to generate natural language explanations for an agent's\nbehavior based only on observations of states and actions, agnostic to the\nunderlying model representation. We show how a compact representation of the\nagent's behavior can be learned and used to produce plausible explanations with\nminimal hallucination while affording user interaction with a pre-trained large\nlanguage model. Through user studies and empirical experiments, we show that\nour approach generates explanations as helpful as those generated by a human\ndomain expert while enabling beneficial interactions such as clarification and\ncounterfactual queries.\n",
                "链接": "https://arxiv.org/abs/2309.10346"
            },
            {
                "文章ID": "63456",
                "标题": "Robot Behavior-Tree-Based Task Generation with Large Language Models",
                "作者": " Yue Cao,  C. S. George Lee",
                "发布日期": "2023-02-28",
                "摘要": "  Nowadays, the behavior tree is gaining popularity as a representation for\nrobot tasks due to its modularity and reusability. Designing behavior-tree\ntasks manually is time-consuming for robot end-users, thus there is a need for\ninvestigating automatic behavior-tree-based task generation. Prior\nbehavior-tree-based task generation approaches focus on fixed primitive tasks\nand lack generalizability to new task domains. To cope with this issue, we\npropose a novel behavior-tree-based task generation approach that utilizes\nstate-of-the-art large language models. We propose a Phase-Step prompt design\nthat enables a hierarchical-structured robot task generation and further\nintegrate it with behavior-tree-embedding-based search to set up the\nappropriate prompt. In this way, we enable an automatic and cross-domain\nbehavior-tree task generation. Our behavior-tree-based task generation approach\ndoes not require a set of pre-defined primitive tasks. End-users only need to\ndescribe an abstract desired task and our proposed approach can swiftly\ngenerate the corresponding behavior tree. A full-process case study is provided\nto demonstrate our proposed approach. An ablation study is conducted to\nevaluate the effectiveness of our Phase-Step prompts. Assessment on Phase-Step\nprompts and the limitation of large language models are presented and\ndiscussed.\n",
                "链接": "https://arxiv.org/abs/2302.12927"
            },
            {
                "文章ID": "119665",
                "标题": "Large Language Models for Travel Behavior Prediction",
                "作者": " Baichuan Mo,  Hanyong Xu,  Dingyi Zhuang,  Ruoyun Ma,  Xiaotong Guo,  Jinhua Zhao",
                "发布日期": "2023-12-05",
                "摘要": "  Travel behavior prediction is a fundamental task in transportation demand\nmanagement. The conventional methods for travel behavior prediction rely on\nnumerical data to construct mathematical models and calibrate model parameters\nto represent human preferences. Recent advancement in large language models\n(LLMs) has shown great reasoning abilities to solve complex problems. In this\nstudy, we propose to use LLMs to predict travel behavior with prompt\nengineering without data-based parameter learning. Specifically, we carefully\ndesign our prompts that include 1) task description, 2) travel characteristics,\n3) individual attributes, and 4) guides of thinking with domain knowledge, and\nask the LLMs to predict an individual's travel behavior and explain the\nresults. We select the travel mode choice task as a case study. Results show\nthat, though no training samples are provided, LLM-based predictions have\ncompetitive accuracy and F1-score as canonical supervised learning methods such\nas multinomial logit, random forest, and neural networks. LLMs can also output\nreasons that support their prediction. However, though in most of the cases,\nthe output explanations are reasonable, we still observe cases that violate\nlogic or with hallucinations.\n",
                "链接": "https://arxiv.org/abs/2312.00819"
            },
            {
                "文章ID": "108480",
                "标题": "Multimodal Large Language Model for Visual Navigation",
                "作者": " Yao-Hung Hubert Tsai,  Vansh Dhar,  Jialu Li,  Bowen Zhang,  Jian Zhang",
                "发布日期": "2023-11-07",
                "摘要": "  Recent efforts to enable visual navigation using large language models have\nmainly focused on developing complex prompt systems. These systems incorporate\ninstructions, observations, and history into massive text prompts, which are\nthen combined with pre-trained large language models to facilitate visual\nnavigation. In contrast, our approach aims to fine-tune large language models\nfor visual navigation without extensive prompt engineering. Our design involves\na simple text prompt, current observations, and a history collector model that\ngathers information from previous observations as input. For output, our design\nprovides a probability distribution of possible actions that the agent can take\nduring navigation. We train our model using human demonstrations and collision\nsignals from the Habitat-Matterport 3D Dataset (HM3D). Experimental results\ndemonstrate that our method outperforms state-of-the-art behavior cloning\nmethods and effectively reduces collision rates.\n",
                "链接": "https://arxiv.org/abs/2310.08669"
            },
            {
                "文章ID": "40736",
                "标题": "Bayesian Prompt Learning for Image-Language Model Generalization",
                "作者": " Mohammad Mahdi Derakhshani,  Enrique Sanchez,  Adrian Bulat,  Victor Guilherme Turrisi da Costa,  Cees G. M. Snoek,  Georgios Tzimiropoulos,  Brais Martinez",
                "发布日期": "2023-08-22",
                "摘要": "  Foundational image-language models have generated considerable interest due\nto their efficient adaptation to downstream tasks by prompt learning. Prompt\nlearning treats part of the language model input as trainable while freezing\nthe rest, and optimizes an Empirical Risk Minimization objective. However,\nEmpirical Risk Minimization is known to suffer from distributional shifts which\nhurt generalizability to prompts unseen during training. By leveraging the\nregularization ability of Bayesian methods, we frame prompt learning from the\nBayesian perspective and formulate it as a variational inference problem. Our\napproach regularizes the prompt space, reduces overfitting to the seen prompts\nand improves the prompt generalization on unseen prompts. Our framework is\nimplemented by modeling the input prompt space in a probabilistic manner, as an\na priori distribution which makes our proposal compatible with prompt learning\napproaches that are unconditional or conditional on the image. We demonstrate\nempirically on 15 benchmarks that Bayesian prompt learning provides an\nappropriate coverage of the prompt space, prevents learning spurious features,\nand exploits transferable invariant features. This results in better\ngeneralization of unseen prompts, even across different datasets and domains.\nCode available at: https://github.com/saic-fi/Bayesian-Prompt-Learning\n",
                "链接": "https://arxiv.org/abs/2210.02390"
            },
            {
                "文章ID": "90541",
                "标题": "Exploring Large Language Model for Graph Data Understanding in Online\n  Job Recommendations",
                "作者": " Likang Wu,  Zhaopeng Qiu,  Zhi Zheng,  Hengshu Zhu,  Enhong Chen",
                "发布日期": "2023-12-27",
                "摘要": "  Large Language Models (LLMs) have revolutionized natural language processing\ntasks, demonstrating their exceptional capabilities in various domains.\nHowever, their potential for behavior graph understanding in job\nrecommendations remains largely unexplored. This paper focuses on unveiling the\ncapability of large language models in understanding behavior graphs and\nleveraging this understanding to enhance recommendations in online recruitment,\nincluding the promotion of out-of-distribution (OOD) application. We present a\nnovel framework that harnesses the rich contextual information and semantic\nrepresentations provided by large language models to analyze behavior graphs\nand uncover underlying patterns and relationships. Specifically, we propose a\nmeta-path prompt constructor that leverages LLM recommender to understand\nbehavior graphs for the first time and design a corresponding path augmentation\nmodule to alleviate the prompt bias introduced by path-based sequence input. By\nleveraging this capability, our framework enables personalized and accurate job\nrecommendations for individual users. We evaluate the effectiveness of our\napproach on a comprehensive dataset and demonstrate its ability to improve the\nrelevance and quality of recommended quality. This research not only sheds\nlight on the untapped potential of large language models but also provides\nvaluable insights for developing advanced recommendation systems in the\nrecruitment market. The findings contribute to the growing field of natural\nlanguage processing and offer practical implications for enhancing job search\nexperiences. We release the code at https://github.com/WLiK/GLRec.\n",
                "链接": "https://arxiv.org/abs/2307.05722"
            },
            {
                "文章ID": "96394",
                "标题": "Exploring the Intersection of Large Language Models and Agent-Based\n  Modeling via Prompt Engineering",
                "作者": " Edward Junprung",
                "发布日期": "2023-08-16",
                "摘要": "  The final frontier for simulation is the accurate representation of complex,\nreal-world social systems. While agent-based modeling (ABM) seeks to study the\nbehavior and interactions of agents within a larger system, it is unable to\nfaithfully capture the full complexity of human-driven behavior. Large language\nmodels (LLMs), like ChatGPT, have emerged as a potential solution to this\nbottleneck by enabling researchers to explore human-driven interactions in\npreviously unimaginable ways. Our research investigates simulations of human\ninteractions using LLMs. Through prompt engineering, inspired by Park et al.\n(2023), we present two simulations of believable proxies of human behavior: a\ntwo-agent negotiation and a six-agent murder mystery game.\n",
                "链接": "https://arxiv.org/abs/2308.07411"
            },
            {
                "文章ID": "79767",
                "标题": "Robust Prompt Optimization for Large Language Models Against\n  Distribution Shifts",
                "作者": " Moxin Li,  Wenjie Wang,  Fuli Feng,  Yixin Cao,  Jizhi Zhang,  Tat-Seng Chua",
                "发布日期": "2023-10-17",
                "摘要": "  Large Language Model (LLM) has demonstrated significant ability in various\nNatural Language Processing tasks. However, their effectiveness is highly\ndependent on the phrasing of the task prompt, leading to research on automatic\nprompt optimization using labeled task data. We reveal that these prompt\noptimization techniques are vulnerable to distribution shifts such as\nsubpopulation shifts, which are common for LLMs in real-world scenarios such as\ncustomer reviews analysis. In this light, we propose a new problem of robust\nprompt optimization for LLMs against distribution shifts, which requires the\nprompt optimized over the labeled source group can simultaneously generalize to\nan unlabeled target group. To solve this problem, we propose Generalized Prompt\nOptimization framework, which incorporates the unlabeled data from the target\ngroup into prompt optimization. Extensive experimental results demonstrate the\neffectiveness of the proposed framework with significant performance\nimprovement on the target group and comparable performance on the source group.\n",
                "链接": "https://arxiv.org/abs/2305.13954"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态大模型理解和生成统一建模、端到端训练相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "118545",
                "标题": "GPT4Video: A Unified Multimodal Large Language Model for\n  lnstruction-Followed Understanding and Safety-Aware Generation",
                "作者": " Zhanyu Wang,  Longyue Wang,  Zhen Zhao,  Minghao Wu,  Chenyang Lyu,  Huayang Li,  Deng Cai,  Luping Zhou,  Shuming Shi,  Zhaopeng Tu",
                "发布日期": "2023-11-29",
                "摘要": "  While the recent advances in Multimodal Large Language Models (MLLMs)\nconstitute a significant leap forward in the field, these models are\npredominantly confined to the realm of input-side multimodal comprehension,\nlacking the capacity for multimodal content generation. To fill this gap, we\npresent GPT4Video, a unified multi-model framework that empowers Large Language\nModels (LLMs) with the capability of both video understanding and generation.\nSpecifically, we develop an instruction-following-based approach integrated\nwith the stable diffusion generative model, which has demonstrated to\neffectively and securely handle video generation scenarios. GPT4Video offers\nthe following benefits: 1) It exhibits impressive capabilities in both video\nunderstanding and generation scenarios. For example, GPT4Video outperforms\nValley by 11.8\\% on the Video Question Answering task, and surpasses NExt-GPT\nby 2.3\\% on the Text to Video generation task. 2) it endows the LLM/MLLM with\nvideo generation capabilities without requiring additional training parameters\nand can flexibly interface with a wide range of models to perform video\ngeneration. 3) it maintains a safe and healthy conversation not only in\noutput-side but also the input side in an end-to-end manner. Qualitative and\nqualitative experiments demonstrate that GPT4Video holds the potential to\nfunction as a effective, safe and Humanoid-like video assistant that can handle\nboth video understanding and generation scenarios.\n",
                "链接": "https://arxiv.org/abs/2311.16511"
            },
            {
                "文章ID": "50165",
                "标题": "Unified Multimodal Model with Unlikelihood Training for Visual Dialog",
                "作者": " Zihao Wang,  Junli Wang,  Changjun Jiang",
                "发布日期": "2022-11-28",
                "摘要": "  The task of visual dialog requires a multimodal chatbot to answer sequential\nquestions from humans about image content. Prior work performs the standard\nlikelihood training for answer generation on the positive instances (involving\ncorrect answers). However, the likelihood objective often leads to frequent and\ndull outputs and fails to exploit the useful knowledge from negative instances\n(involving incorrect answers). In this paper, we propose a Unified Multimodal\nModel with UnLikelihood Training, named UniMM-UL, to tackle this problem.\nFirst, to improve visual dialog understanding and generation by multi-task\nlearning, our model extends ViLBERT from only supporting answer discrimination\nto holding both answer discrimination and answer generation seamlessly by\ndifferent attention masks. Specifically, in order to make the original\ndiscriminative model compatible with answer generation, we design novel\ngenerative attention masks to implement the autoregressive Masked Language\nModeling (autoregressive MLM) task. And to attenuate the adverse effects of the\nlikelihood objective, we exploit unlikelihood training on negative instances to\nmake the model less likely to generate incorrect answers. Then, to utilize\ndense annotations, we adopt different fine-tuning methods for both generating\nand discriminating answers, rather than just for discriminating answers as in\nthe prior work. Finally, on the VisDial dataset, our model achieves the best\ngenerative results (69.23 NDCG score). And our model also yields comparable\ndiscriminative results with the state-of-the-art in both single-model and\nensemble settings (75.92 and 76.17 NDCG scores).\n",
                "链接": "https://arxiv.org/abs/2211.13235"
            },
            {
                "文章ID": "47547",
                "标题": "ERNIE-UniX2: A Unified Cross-lingual Cross-modal Framework for\n  Understanding and Generation",
                "作者": " Bin Shan,  Yaqian Han,  Weichong Yin,  Shuohuan Wang,  Yu Sun,  Hao Tian,  Hua Wu,  Haifeng Wang",
                "发布日期": "2022-11-10",
                "摘要": "  Recent cross-lingual cross-modal works attempt to extend Vision-Language\nPre-training (VLP) models to non-English inputs and achieve impressive\nperformance. However, these models focus only on understanding tasks utilizing\nencoder-only architecture. In this paper, we propose ERNIE-UniX2, a unified\ncross-lingual cross-modal pre-training framework for both generation and\nunderstanding tasks. ERNIE-UniX2 integrates multiple pre-training paradigms\n(e.g., contrastive learning and language modeling) based on encoder-decoder\narchitecture and attempts to learn a better joint representation across\nlanguages and modalities. Furthermore, ERNIE-UniX2 can be seamlessly fine-tuned\nfor varieties of generation and understanding downstream tasks. Pre-trained on\nboth multilingual text-only and image-text datasets, ERNIE-UniX2 achieves SOTA\nresults on various cross-lingual cross-modal generation and understanding tasks\nsuch as multimodal machine translation and multilingual visual question\nanswering.\n",
                "链接": "https://arxiv.org/abs/2211.04861"
            },
            {
                "文章ID": "125308",
                "标题": "Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision,\n  Language, Audio, and Action",
                "作者": " Jiasen Lu,  Christopher Clark,  Sangho Lee,  Zichen Zhang,  Savya Khosla,  Ryan Marten,  Derek Hoiem,  Aniruddha Kembhavi",
                "发布日期": "2023-12-29",
                "摘要": "  We present Unified-IO 2, the first autoregressive multimodal model that is\ncapable of understanding and generating image, text, audio, and action. To\nunify different modalities, we tokenize inputs and outputs -- images, text,\naudio, action, bounding boxes, etc., into a shared semantic space and then\nprocess them with a single encoder-decoder transformer model. Since training\nwith such diverse modalities is challenging, we propose various architectural\nimprovements to stabilize model training. We train our model from scratch on a\nlarge multimodal pre-training corpus from diverse sources with a multimodal\nmixture of denoisers objective. To learn an expansive set of skills, such as\nfollowing multimodal instructions, we construct and finetune on an ensemble of\n120 datasets with prompts and augmentations. With a single unified model,\nUnified-IO 2 achieves state-of-the-art performance on the GRIT benchmark and\nstrong results in more than 35 benchmarks, including image generation and\nunderstanding, natural language understanding, video and audio understanding,\nand robotic manipulation. We release all our models to the research community.\n",
                "链接": "https://arxiv.org/abs/2312.17172"
            },
            {
                "文章ID": "120414",
                "标题": "GPT4Point: A Unified Framework for Point-Language Understanding and\n  Generation",
                "作者": " Zhangyang Qi,  Ye Fang,  Zeyi Sun,  Xiaoyang Wu,  Tong Wu,  Jiaqi Wang,  Dahua Lin,  Hengshuang Zhao",
                "发布日期": "2023-12-06",
                "摘要": "  Multimodal Large Language Models (MLLMs) have excelled in 2D image-text\ncomprehension and image generation, but their understanding of the 3D world is\nnotably deficient, limiting progress in 3D language understanding and\ngeneration. To solve this problem, we introduce GPT4Point, an innovative\ngroundbreaking point-language multimodal model designed specifically for\nunified 3D object understanding and generation within the MLLM framework.\nGPT4Point as a powerful 3D MLLM seamlessly can execute a variety of point-text\nreference tasks such as point-cloud captioning and Q&A. Additionally, GPT4Point\nis equipped with advanced capabilities for controllable 3D generation, it can\nget high-quality results through a low-quality point-text feature maintaining\nthe geometric shapes and colors. To support the expansive needs of 3D\nobject-text pairs, we develop Pyramid-XL, a point-language dataset annotation\nengine. It constructs a large-scale database over 1M objects of varied text\ngranularity levels from the Objaverse-XL dataset, essential for training\nGPT4Point. A comprehensive benchmark has been proposed to evaluate 3D\npoint-language understanding capabilities. In extensive evaluations, GPT4Point\nhas demonstrated superior performance in understanding and generation.\n",
                "链接": "https://arxiv.org/abs/2312.02980"
            },
            {
                "文章ID": "37245",
                "标题": "SPACE-3: Unified Dialog Model Pre-training for Task-Oriented Dialog\n  Understanding and Generation",
                "作者": " Wanwei He,  Yinpei Dai,  Min Yang,  Jian Sun,  Fei Huang,  Luo Si,  Yongbin Li",
                "发布日期": "2022-09-15",
                "摘要": "  Recently, pre-training methods have shown remarkable success in task-oriented\ndialog (TOD) systems. However, most existing pre-trained models for TOD focus\non either dialog understanding or dialog generation, but not both. In this\npaper, we propose SPACE-3, a novel unified semi-supervised pre-trained\nconversation model learning from large-scale dialog corpora with limited\nannotations, which can be effectively fine-tuned on a wide range of downstream\ndialog tasks. Specifically, SPACE-3 consists of four successive components in a\nsingle transformer to maintain a task-flow in TOD systems: (i) a dialog\nencoding module to encode dialog history, (ii) a dialog understanding module to\nextract semantic vectors from either user queries or system responses, (iii) a\ndialog policy module to generate a policy vector that contains high-level\nsemantics of the response, and (iv) a dialog generation module to produce\nappropriate responses. We design a dedicated pre-training objective for each\ncomponent. Concretely, we pre-train the dialog encoding module with span mask\nlanguage modeling to learn contextualized dialog information. To capture the\nstructured dialog semantics, we pre-train the dialog understanding module via a\nnovel tree-induced semi-supervised contrastive learning objective with the help\nof extra dialog annotations. In addition, we pre-train the dialog policy module\nby minimizing the L2 distance between its output policy vector and the semantic\nvector of the response for policy optimization. Finally, the dialog generation\nmodel is pre-trained by language modeling. Results show that SPACE-3 achieves\nstate-of-the-art performance on eight downstream dialog benchmarks, including\nintent prediction, dialog state tracking, and end-to-end dialog modeling. We\nalso show that SPACE-3 has a stronger few-shot ability than existing models\nunder the low-resource setting.\n",
                "链接": "https://arxiv.org/abs/2209.06664"
            },
            {
                "文章ID": "122686",
                "标题": "VL-GPT: A Generative Pre-trained Transformer for Vision and Language\n  Understanding and Generation",
                "作者": " Jinguo Zhu,  Xiaohan Ding,  Yixiao Ge,  Yuying Ge,  Sijie Zhao,  Hengshuang Zhao,  Xiaohua Wang,  Ying Shan",
                "发布日期": "2023-12-15",
                "摘要": "  In this work, we introduce Vision-Language Generative Pre-trained Transformer\n(VL-GPT), a transformer model proficient at concurrently perceiving and\ngenerating visual and linguistic data. VL-GPT achieves a unified pre-training\napproach for both image and text modalities by employing a straightforward\nauto-regressive objective, thereby enabling the model to process image and text\nas seamlessly as a language model processes text. To accomplish this, we\ninitially propose a novel image tokenizer-detokenizer framework for visual\ndata, specifically designed to transform raw images into a sequence of\ncontinuous embeddings and reconstruct them accordingly. In combination with the\nexisting text tokenizer and detokenizer, this framework allows for the encoding\nof interleaved image-text data into a multimodal sequence, which can\nsubsequently be fed into the transformer model. Consequently, VL-GPT can\nperform large-scale pre-training on multimodal corpora utilizing a unified\nauto-regressive objective (i.e., next-token prediction). Upon completion of\npre-training, VL-GPT exhibits remarkable zero-shot and few-shot performance\nacross a diverse range of vision and language understanding and generation\ntasks, including image captioning, visual question answering, text-to-image\ngeneration, and more. Additionally, the pre-trained model retrains in-context\nlearning capabilities when provided with multimodal prompts. We further conduct\ninstruction tuning on our VL-GPT, highlighting its exceptional potential for\nmultimodal assistance. The source code and model weights shall be released.\n",
                "链接": "https://arxiv.org/abs/2312.09251"
            },
            {
                "文章ID": "90867",
                "标题": "InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding\n  and Generation",
                "作者": " Yi Wang,  Yinan He,  Yizhuo Li,  Kunchang Li,  Jiashuo Yu,  Xin Ma,  Xinyuan Chen,  Yaohui Wang,  Ping Luo,  Ziwei Liu,  Yali Wang,  Limin Wang,  Yu Qiao",
                "发布日期": "2023-07-14",
                "摘要": "  This paper introduces InternVid, a large-scale video-centric multimodal\ndataset that enables learning powerful and transferable video-text\nrepresentations for multimodal understanding and generation. The InternVid\ndataset contains over 7 million videos lasting nearly 760K hours, yielding 234M\nvideo clips accompanied by detailed descriptions of total 4.1B words. Our core\ncontribution is to develop a scalable approach to autonomously build a\nhigh-quality video-text dataset with large language models (LLM), thereby\nshowcasing its efficacy in learning video-language representation at scale.\nSpecifically, we utilize a multi-scale approach to generate video-related\ndescriptions. Furthermore, we introduce ViCLIP, a video-text representation\nlearning model based on ViT-L. Learned on InternVid via contrastive learning,\nthis model demonstrates leading zero-shot action recognition and competitive\nvideo retrieval performance. Beyond basic video understanding tasks like\nrecognition and retrieval, our dataset and model have broad applications. They\nare particularly beneficial for generating interleaved video-text data for\nlearning a video-centric dialogue system, advancing video-to-text and\ntext-to-video generation research. These proposed resources provide a tool for\nresearchers and practitioners interested in multimodal video understanding and\ngeneration.\n",
                "链接": "https://arxiv.org/abs/2307.06942"
            },
            {
                "文章ID": "24805",
                "标题": "Write and Paint: Generative Vision-Language Models are Unified Modal\n  Learners",
                "作者": " Shizhe Diao,  Wangchunshu Zhou,  Xinsong Zhang,  Jiawei Wang",
                "发布日期": "2023-02-20",
                "摘要": "  Recent advances in vision-language pre-training have pushed the\nstate-of-the-art on various vision-language tasks, making machines more capable\nof multi-modal writing (image-to-text generation) and painting (text-to-image\ngeneration). However, few studies investigate if these two essential\ncapabilities can be learned together and boost each other, making a versatile\nand powerful multi-modal foundation model. In this work, we disclose the\npotential of symmetric generative vision-language pre-training in learning to\nwrite and paint concurrently, and propose a new unified modal model, named\nDaVinci, trained with prefix language modeling and prefix image modeling, a\nsimple generative self-supervised objective on image-text pairs. Thanks to the\nproposed prefix multi-modal modeling framework, DaVinci is simple to train,\nscalable to huge data, adaptable to both writing and painting tasks, and also\nstrong on other vision, text, and multi-modal understanding tasks. DaVinci\nachieves competitive performance on a wide range of 27 generation/understanding\ntasks and demonstrates the superiority of combining vision/language generative\npre-training. Furthermore, we carefully benchmark the performance of different\nvision-language pre-training objectives on different scales of pre-training\ndatasets on a heterogeneous and broad distribution coverage. Our results\ndemonstrate the potential of exploiting self-supervision in both language and\nvision inputs, and establish new, stronger baselines for future comparisons at\ndifferent data scales. The code and pre-trained models are available at\nhttps://github.com/shizhediao/DaVinci.\n",
                "链接": "https://arxiv.org/abs/2206.07699"
            },
            {
                "文章ID": "120272",
                "标题": "Towards More Unified In-context Visual Understanding",
                "作者": " Dianmo Sheng,  Dongdong Chen,  Zhentao Tan,  Qiankun Liu,  Qi Chu,  Jianmin Bao,  Tao Gong,  Bin Liu,  Shengwei Xu,  Nenghai Yu",
                "发布日期": "2023-12-06",
                "摘要": "  The rapid advancement of large language models (LLMs) has accelerated the\nemergence of in-context learning (ICL) as a cutting-edge approach in the\nnatural language processing domain. Recently, ICL has been employed in visual\nunderstanding tasks, such as semantic segmentation and image captioning,\nyielding promising results. However, existing visual ICL framework can not\nenable producing content across multiple modalities, which limits their\npotential usage scenarios. To address this issue, we present a new ICL\nframework for visual understanding with multi-modal output enabled. First, we\nquantize and embed both text and visual prompt into a unified representational\nspace, structured as interleaved in-context sequences. Then a decoder-only\nsparse transformer architecture is employed to perform generative modeling on\nthem, facilitating in-context learning. Thanks to this design, the model is\ncapable of handling in-context vision understanding tasks with multimodal\noutput in a unified pipeline. Experimental results demonstrate that our model\nachieves competitive performance compared with specialized models and previous\nICL baselines. Overall, our research takes a further step toward unified\nmultimodal in-context learning.\n",
                "链接": "https://arxiv.org/abs/2312.02520"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近两年关于语言模型奖励建模评估的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "6241",
                "标题": "Reward Modeling for Mitigating Toxicity in Transformer-based Language\n  Models",
                "作者": " Farshid Faal,  Ketra Schmitt,  Jia Yuan Yu",
                "发布日期": "2022-07-28",
                "摘要": "  Transformer-based language models are able to generate fluent text and be\nefficiently adapted across various natural language generation tasks. However,\nlanguage models that are pretrained on large unlabeled web text corpora have\nbeen shown to suffer from degenerating toxic content and social bias behaviors,\nconsequently hindering their safe deployment. Various detoxification methods\nwere proposed to mitigate the language model's toxicity; however, these methods\nstruggled to detoxify language models when conditioned on prompts that contain\nspecific social identities related to gender, race, or religion. In this study,\nwe propose Reinforce-Detoxify; A reinforcement learning-based method for\nmitigating toxicity in language models. We address the challenge of safety in\nlanguage models and propose a new reward model that is able to detect toxic\ncontent and mitigate unintended bias towards social identities in toxicity\nprediction. The experiments demonstrate that the Reinforce-Detoxify method for\nlanguage model detoxification outperforms existing detoxification approaches in\nautomatic evaluation metrics, indicating the ability of our approach in\nlanguage model detoxification and less prone to unintended bias toward social\nidentities in generated content.\n",
                "链接": "https://arxiv.org/abs/2202.09662"
            },
            {
                "文章ID": "105659",
                "标题": "Tool-Augmented Reward Modeling",
                "作者": " Lei Li,  Yekun Chai,  Shuohuan Wang,  Yu Sun,  Hao Tian,  Ningyu Zhang,  Hua Wu",
                "发布日期": "2023-10-03",
                "摘要": "  Reward modeling (a.k.a., preference modeling) is instrumental for aligning\nlarge language models with human preferences, particularly within the context\nof reinforcement learning from human feedback (RLHF). While conventional reward\nmodels (RMs) have exhibited remarkable scalability, they oft struggle with\nfundamental functionality such as arithmetic computation, code execution, and\nfactual lookup. In this paper, we propose a tool-augmented preference modeling\napproach, named \\name, to address these limitations by empowering RMs with\naccess to external environments, including calculators and search engines. This\napproach not only fosters synergy between tool utilization and reward grading\nbut also enhances interpretive capacity and scoring reliability. Our study\ndelves into the integration of external tools into RMs, enabling them to\ninteract with diverse external sources and construct task-specific tool\nengagement and reasoning traces in an autoregressive manner. We validate our\napproach across a wide range of domains, incorporating seven distinct external\ntools. Our experimental results demonstrate a noteworthy overall improvement of\n17.7% across eight tasks in preference ranking. Furthermore, our approach\noutperforms Gopher 280B by 7.3% on TruthfulQA task in zero-shot evaluation. In\nhuman evaluations, RLHF trained with Themis attains an average win rate of 32%\nwhen compared to baselines across four distinct tasks. Additionally, we provide\na comprehensive collection of tool-related RM datasets, incorporating data from\nseven distinct tool APIs, totaling 15,000 instances. We anticipate that this\npublicly available dataset will facilitate and inspire further research\nadvancements in the field.\n",
                "链接": "https://arxiv.org/abs/2310.01045"
            },
            {
                "文章ID": "64063",
                "标题": "Reward Design with Language Models",
                "作者": " Minae Kwon,  Sang Michael Xie,  Kalesha Bullard,  Dorsa Sadigh",
                "发布日期": "2023-03-02",
                "摘要": "  Reward design in reinforcement learning (RL) is challenging since specifying\nhuman notions of desired behavior may be difficult via reward functions or\nrequire many expert demonstrations. Can we instead cheaply design rewards using\na natural language interface? This paper explores how to simplify reward design\nby prompting a large language model (LLM) such as GPT-3 as a proxy reward\nfunction, where the user provides a textual prompt containing a few examples\n(few-shot) or a description (zero-shot) of the desired behavior. Our approach\nleverages this proxy reward function in an RL framework. Specifically, users\nspecify a prompt once at the beginning of training. During training, the LLM\nevaluates an RL agent's behavior against the desired behavior described by the\nprompt and outputs a corresponding reward signal. The RL agent then uses this\nreward to update its behavior. We evaluate whether our approach can train\nagents aligned with user objectives in the Ultimatum Game, matrix games, and\nthe DealOrNoDeal negotiation task. In all three tasks, we show that RL agents\ntrained with our framework are well-aligned with the user's objectives and\noutperform RL agents trained with reward functions learned via supervised\nlearning\n",
                "链接": "https://arxiv.org/abs/2303.00001"
            },
            {
                "文章ID": "81507",
                "标题": "Reward Collapse in Aligning Large Language Models",
                "作者": " Ziang Song,  Tianle Cai,  Jason D. Lee,  Weijie J. Su",
                "发布日期": "2023-05-30",
                "摘要": "  The extraordinary capabilities of large language models (LLMs) such as\nChatGPT and GPT-4 are in part unleashed by aligning them with reward models\nthat are trained on human preferences, which are often represented as rankings\nof responses to prompts. In this paper, we document the phenomenon of\n\\textit{reward collapse}, an empirical observation where the prevailing\nranking-based approach results in an \\textit{identical} reward distribution\n\\textit{regardless} of the prompts during the terminal phase of training. This\noutcome is undesirable as open-ended prompts like ``write a short story about\nyour best friend'' should yield a continuous range of rewards for their\ncompletions, while specific prompts like ``what is the capital of New Zealand''\nshould generate either high or low rewards. Our theoretical investigation\nreveals that reward collapse is primarily due to the insufficiency of the\nranking-based objective function to incorporate prompt-related information\nduring optimization. This insight allows us to derive closed-form expressions\nfor the reward distribution associated with a set of utility functions in an\nasymptotic regime. To overcome reward collapse, we introduce a prompt-aware\noptimization scheme that provably admits a prompt-dependent reward distribution\nwithin the interpolating regime. Our experimental results suggest that our\nproposed prompt-aware utility functions significantly alleviate reward collapse\nduring the training of reward models.\n",
                "链接": "https://arxiv.org/abs/2305.17608"
            },
            {
                "文章ID": "79143",
                "标题": "PrOnto: Language Model Evaluations for 859 Languages",
                "作者": " Luke Gessler",
                "发布日期": "2023-05-23",
                "摘要": "  Evaluation datasets are critical resources for measuring the quality of\npretrained language models. However, due to the high cost of dataset\nannotation, these resources are scarce for most languages other than English,\nmaking it difficult to assess the quality of language models. In this work, we\npresent a new method for evaluation dataset construction which enables any\nlanguage with a New Testament translation to receive a suite of evaluation\ndatasets suitable for pretrained language model evaluation. The method\ncritically involves aligning verses with those in the New Testament portion of\nEnglish OntoNotes, and then projecting annotations from English to the target\nlanguage, with no manual annotation required. We apply this method to 1051 New\nTestament translations in 859 and make them publicly available. Additionally,\nwe conduct experiments which demonstrate the efficacy of our method for\ncreating evaluation tasks which can assess language model quality.\n",
                "链接": "https://arxiv.org/abs/2305.12612"
            },
            {
                "文章ID": "98183",
                "标题": "Language Reward Modulation for Pretraining Reinforcement Learning",
                "作者": " Ademi Adeniji,  Amber Xie,  Carmelo Sferrazza,  Younggyo Seo,  Stephen James,  Pieter Abbeel",
                "发布日期": "2023-08-24",
                "摘要": "  Using learned reward functions (LRFs) as a means to solve sparse-reward\nreinforcement learning (RL) tasks has yielded some steady progress in\ntask-complexity through the years. In this work, we question whether today's\nLRFs are best-suited as a direct replacement for task rewards. Instead, we\npropose leveraging the capabilities of LRFs as a pretraining signal for RL.\nConcretely, we propose $\\textbf{LA}$nguage Reward $\\textbf{M}$odulated\n$\\textbf{P}$retraining (LAMP) which leverages the zero-shot capabilities of\nVision-Language Models (VLMs) as a $\\textit{pretraining}$ utility for RL as\nopposed to a downstream task reward. LAMP uses a frozen, pretrained VLM to\nscalably generate noisy, albeit shaped exploration rewards by computing the\ncontrastive alignment between a highly diverse collection of language\ninstructions and the image observations of an agent in its pretraining\nenvironment. LAMP optimizes these rewards in conjunction with standard\nnovelty-seeking exploration rewards with reinforcement learning to acquire a\nlanguage-conditioned, pretrained policy. Our VLM pretraining approach, which is\na departure from previous attempts to use LRFs, can warmstart sample-efficient\nlearning on robot manipulation tasks in RLBench.\n",
                "链接": "https://arxiv.org/abs/2308.12270"
            },
            {
                "文章ID": "122677",
                "标题": "Auto MC-Reward: Automated Dense Reward Design with Large Language Models\n  for Minecraft",
                "作者": " Hao Li,  Xue Yang,  Zhaokai Wang,  Xizhou Zhu,  Jie Zhou,  Yu Qiao,  Xiaogang Wang,  Hongsheng Li,  Lewei Lu,  Jifeng Dai",
                "发布日期": "2023-12-15",
                "摘要": "  Traditional reinforcement-learning-based agents rely on sparse rewards that\noften only use binary values to indicate task completion or failure. The\nchallenge in exploration efficiency makes it difficult to effectively learn\ncomplex tasks in Minecraft. To address this, this paper introduces an advanced\nlearning system, named Auto MC-Reward, that leverages Large Language Models\n(LLMs) to automatically design dense reward functions, thereby enhancing the\nlearning efficiency. Auto MC-Reward consists of three important components:\nReward Designer, Reward Critic, and Trajectory Analyzer. Given the environment\ninformation and task descriptions, the Reward Designer first design the reward\nfunction by coding an executable Python function with predefined observation\ninputs. Then, our Reward Critic will be responsible for verifying the code,\nchecking whether the code is self-consistent and free of syntax and semantic\nerrors. Further, the Trajectory Analyzer summarizes possible failure causes and\nprovides refinement suggestions according to collected trajectories. In the\nnext round, Reward Designer will take further refine and iterate the dense\nreward function based on feedback. Experiments demonstrate a significant\nimprovement in the success rate and learning efficiency of our agents in\ncomplex tasks in Minecraft, such as obtaining diamond with the efficient\nability to avoid lava, and efficiently explore trees and animals that are\nsparse on the plains biome.\n",
                "链接": "https://arxiv.org/abs/2312.09238"
            },
            {
                "文章ID": "124338",
                "标题": "Diffusion Reward: Learning Rewards via Conditional Video Diffusion",
                "作者": " Tao Huang,  Guangqi Jiang,  Yanjie Ze,  Huazhe Xu",
                "发布日期": "2023-12-22",
                "摘要": "  Learning rewards from expert videos offers an affordable and effective\nsolution to specify the intended behaviors for reinforcement learning tasks. In\nthis work, we propose Diffusion Reward, a novel framework that learns rewards\nfrom expert videos via conditional video diffusion models for solving complex\nvisual RL problems. Our key insight is that lower generative diversity is\nobserved when conditioned on expert trajectories. Diffusion Reward is\naccordingly formalized by the negative of conditional entropy that encourages\nproductive exploration of expert-like behaviors. We show the efficacy of our\nmethod over 10 robotic manipulation tasks from MetaWorld and Adroit with visual\ninput and sparse reward. Moreover, Diffusion Reward could even solve unseen\ntasks successfully and effectively, largely surpassing baseline methods.\nProject page and code: https://diffusion-reward.github.io/.\n",
                "链接": "https://arxiv.org/abs/2312.14134"
            },
            {
                "文章ID": "109995",
                "标题": "Eureka: Human-Level Reward Design via Coding Large Language Models",
                "作者": " Yecheng Jason Ma,  William Liang,  Guanzhi Wang,  De-An Huang,  Osbert Bastani,  Dinesh Jayaraman,  Yuke Zhu,  Linxi Fan,  Anima Anandkumar",
                "发布日期": "2023-10-20",
                "摘要": "  Large Language Models (LLMs) have excelled as high-level semantic planners\nfor sequential decision-making tasks. However, harnessing them to learn complex\nlow-level manipulation tasks, such as dexterous pen spinning, remains an open\nproblem. We bridge this fundamental gap and present Eureka, a human-level\nreward design algorithm powered by LLMs. Eureka exploits the remarkable\nzero-shot generation, code-writing, and in-context improvement capabilities of\nstate-of-the-art LLMs, such as GPT-4, to perform evolutionary optimization over\nreward code. The resulting rewards can then be used to acquire complex skills\nvia reinforcement learning. Without any task-specific prompting or pre-defined\nreward templates, Eureka generates reward functions that outperform expert\nhuman-engineered rewards. In a diverse suite of 29 open-source RL environments\nthat include 10 distinct robot morphologies, Eureka outperforms human experts\non 83% of the tasks, leading to an average normalized improvement of 52%. The\ngenerality of Eureka also enables a new gradient-free in-context learning\napproach to reinforcement learning from human feedback (RLHF), readily\nincorporating human inputs to improve the quality and the safety of the\ngenerated rewards without model updating. Finally, using Eureka rewards in a\ncurriculum learning setting, we demonstrate for the first time, a simulated\nShadow Hand capable of performing pen spinning tricks, adeptly manipulating a\npen in circles at rapid speed.\n",
                "链接": "https://arxiv.org/abs/2310.12931"
            },
            {
                "文章ID": "120776",
                "标题": "FoMo Rewards: Can we cast foundation models as reward functions?",
                "作者": " Ekdeep Singh Lubana,  Johann Brehmer,  Pim de Haan,  Taco Cohen",
                "发布日期": "2023-12-08",
                "摘要": "  We explore the viability of casting foundation models as generic reward\nfunctions for reinforcement learning. To this end, we propose a simple pipeline\nthat interfaces an off-the-shelf vision model with a large language model.\nSpecifically, given a trajectory of observations, we infer the likelihood of an\ninstruction describing the task that the user wants an agent to perform. We\nshow that this generic likelihood function exhibits the characteristics ideally\nexpected from a reward function: it associates high values with the desired\nbehaviour and lower values for several similar, but incorrect policies.\nOverall, our work opens the possibility of designing open-ended agents for\ninteractive tasks via foundation models.\n",
                "链接": "https://arxiv.org/abs/2312.03881"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到从位置编码角度改善模型长序列建模能力的相关论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "106847",
                "标题": "Functional Interpolation for Relative Positions Improves Long Context\n  Transformers",
                "作者": " Shanda Li,  Chong You,  Guru Guruganesh,  Joshua Ainslie,  Santiago Ontanon,  Manzil Zaheer,  Sumit Sanghai,  Yiming Yang,  Sanjiv Kumar,  Srinadh Bhojanapalli",
                "发布日期": "2023-10-09",
                "摘要": "  Preventing the performance decay of Transformers on inputs longer than those\nused for training has been an important challenge in extending the context\nlength of these models. Though the Transformer architecture has fundamentally\nno limits on the input sequence lengths it can process, the choice of position\nencoding used during training can limit the performance of these models on\nlonger inputs. We propose a novel functional relative position encoding with\nprogressive interpolation, FIRE, to improve Transformer generalization to\nlonger contexts. We theoretically prove that this can represent some of the\npopular relative position encodings, such as T5's RPE, Alibi, and Kerple. We\nnext empirically show that FIRE models have better generalization to longer\ncontexts on both zero-shot language modeling and long text benchmarks.\n",
                "链接": "https://arxiv.org/abs/2310.04418"
            },
            {
                "文章ID": "12688",
                "标题": "Transformer Language Models without Positional Encodings Still Learn\n  Positional Information",
                "作者": " Adi Haviv,  Ori Ram,  Ofir Press,  Peter Izsak,  Omer Levy",
                "发布日期": "2022-12-07",
                "摘要": "  Causal transformer language models (LMs), such as GPT-3, typically require\nsome form of positional encoding, such as positional embeddings. However, we\nshow that LMs without any explicit positional encoding are still competitive\nwith standard models, and that this phenomenon is robust across different\ndatasets, model sizes, and sequence lengths. Probing experiments reveal that\nsuch models acquire an implicit notion of absolute positions throughout the\nnetwork, effectively compensating for the missing information. We conjecture\nthat causal attention enables the model to infer the number of predecessors\nthat each token can attend to, thereby approximating its absolute position. Our\nfindings indicate that causal LMs might derive positional awareness not only\nfrom the explicit positioning mechanism, but also from the effects of the\ncausal mask.\n",
                "链接": "https://arxiv.org/abs/2203.16634"
            },
            {
                "文章ID": "81138",
                "标题": "Randomized Positional Encodings Boost Length Generalization of\n  Transformers",
                "作者": " Anian Ruoss,  Grégoire Delétang,  Tim Genewein,  Jordi Grau-Moya,  Róbert Csordás,  Mehdi Bennani,  Shane Legg,  Joel Veness",
                "发布日期": "2023-05-29",
                "摘要": "  Transformers have impressive generalization capabilities on tasks with a\nfixed context length. However, they fail to generalize to sequences of\narbitrary length, even for seemingly simple tasks such as duplicating a string.\nMoreover, simply training on longer sequences is inefficient due to the\nquadratic computation complexity of the global attention mechanism. In this\nwork, we demonstrate that this failure mode is linked to positional encodings\nbeing out-of-distribution for longer sequences (even for relative encodings)\nand introduce a novel family of positional encodings that can overcome this\nproblem. Concretely, our randomized positional encoding scheme simulates the\npositions of longer sequences and randomly selects an ordered subset to fit the\nsequence's length. Our large-scale empirical evaluation of 6000 models across\n15 algorithmic reasoning tasks shows that our method allows Transformers to\ngeneralize to sequences of unseen length (increasing test accuracy by 12.0% on\naverage).\n",
                "链接": "https://arxiv.org/abs/2305.16843"
            },
            {
                "文章ID": "6738",
                "标题": "FastRPB: a Scalable Relative Positional Encoding for Long Sequence Tasks",
                "作者": " Maksim Zubkov,  Daniil Gavrilov",
                "发布日期": "2022-02-24",
                "摘要": "  Transformers achieve remarkable performance in various domains, including\nNLP, CV, audio processing, and graph analysis. However, they do not scale well\non long sequence tasks due to their quadratic complexity w.r.t. the inputs\nlength. Linear Transformers were proposed to address this limitation. However,\nthese models have shown weaker performance on the long sequence tasks comparing\nto the original one. In this paper, we explore Linear Transformer models,\nrethinking their two core components. Firstly, we improved Linear Transformer\nwith Shift-Invariant Kernel Function SIKF, which achieve higher accuracy\nwithout loss in speed. Secondly, we introduce FastRPB which stands for Fast\nRelative Positional Bias, which efficiently adds positional information to\nself-attention using Fast Fourier Transformation. FastRPB is independent of the\nself-attention mechanism and can be combined with an original self-attention\nand all its efficient variants. FastRPB has O(N log(N)) computational\ncomplexity, requiring O(N) memory w.r.t. input sequence length N.\n",
                "链接": "https://arxiv.org/abs/2202.11364"
            },
            {
                "文章ID": "101299",
                "标题": "CONFLATOR: Incorporating Switching Point based Rotatory Positional\n  Encodings for Code-Mixed Language Modeling",
                "作者": " Mohsin Ali,  Kandukuri Sai Teja,  Neeharika Gupta,  Parth Patwa,  Anubhab Chatterjee,  Vinija Jain,  Aman Chadha,  Amitava Das",
                "发布日期": "2023-10-20",
                "摘要": "  The mixing of two or more languages is called Code-Mixing (CM). CM is a\nsocial norm in multilingual societies. Neural Language Models (NLMs) like\ntransformers have been effective on many NLP tasks. However, NLM for CM is an\nunder-explored area. Though transformers are capable and powerful, they cannot\nalways encode positional information since they are non-recurrent. Therefore,\nto enrich word information and incorporate positional information, positional\nencoding is defined. We hypothesize that Switching Points (SPs), i.e.,\njunctions in the text where the language switches (L1 -> L2 or L2 -> L1), pose\na challenge for CM Language Models (LMs), and hence give special emphasis to\nSPs in the modeling process. We experiment with several positional encoding\nmechanisms and show that rotatory positional encodings along with switching\npoint information yield the best results.\n  We introduce CONFLATOR: a neural language modeling approach for code-mixed\nlanguages. CONFLATOR tries to learn to emphasize switching points using smarter\npositional encoding, both at unigram and bigram levels. CONFLATOR outperforms\nthe state-of-the-art on two tasks based on code-mixed Hindi and English\n(Hinglish): (i) sentiment analysis and (ii) machine translation.\n",
                "链接": "https://arxiv.org/abs/2309.05270"
            },
            {
                "文章ID": "82296",
                "标题": "The Impact of Positional Encoding on Length Generalization in\n  Transformers",
                "作者": " Amirhossein Kazemnejad,  Inkit Padhi,  Karthikeyan Natesan Ramamurthy,  Payel Das,  Siva Reddy",
                "发布日期": "2023-11-08",
                "摘要": "  Length generalization, the ability to generalize from small training context\nsizes to larger ones, is a critical challenge in the development of\nTransformer-based language models. Positional encoding (PE) has been identified\nas a major factor influencing length generalization, but the exact impact of\ndifferent PE schemes on extrapolation in downstream tasks remains unclear. In\nthis paper, we conduct a systematic empirical study comparing the length\ngeneralization performance of decoder-only Transformers with five different\nposition encoding approaches including Absolute Position Embedding (APE), T5's\nRelative PE, ALiBi, and Rotary, in addition to Transformers without positional\nencoding (NoPE). Our evaluation encompasses a battery of reasoning and\nmathematical tasks. Our findings reveal that the most commonly used positional\nencoding methods, such as ALiBi, Rotary, and APE, are not well suited for\nlength generalization in downstream tasks. More importantly, NoPE outperforms\nother explicit positional encoding methods while requiring no additional\ncomputation. We theoretically demonstrate that NoPE can represent both absolute\nand relative PEs, but when trained with SGD, it mostly resembles T5's relative\nPE attention patterns. Finally, we find that scratchpad is not always helpful\nto solve length generalization and its format highly impacts the model's\nperformance. Overall, our work suggests that explicit position embeddings are\nnot essential for decoder-only Transformers to generalize well to longer\nsequences.\n",
                "链接": "https://arxiv.org/abs/2305.19466"
            },
            {
                "文章ID": "91660",
                "标题": "Linearized Relative Positional Encoding",
                "作者": " Zhen Qin,  Weixuan Sun,  Kaiyue Lu,  Hui Deng,  Dongxu Li,  Xiaodong Han,  Yuchao Dai,  Lingpeng Kong,  Yiran Zhong",
                "发布日期": "2023-07-19",
                "摘要": "  Relative positional encoding is widely used in vanilla and linear\ntransformers to represent positional information. However, existing encoding\nmethods of a vanilla transformer are not always directly applicable to a linear\ntransformer, because the latter requires a decomposition of the query and key\nrepresentations into separate kernel functions. Nevertheless, principles for\ndesigning encoding methods suitable for linear transformers remain\nunderstudied. In this work, we put together a variety of existing linear\nrelative positional encoding approaches under a canonical form and further\npropose a family of linear relative positional encoding algorithms via unitary\ntransformation. Our formulation leads to a principled framework that can be\nused to develop new relative positional encoding methods that preserve linear\nspace-time complexity. Equipped with different models, the proposed linearized\nrelative positional encoding (LRPE) family derives effective encoding for\nvarious applications. Experiments show that compared with existing methods,\nLRPE achieves state-of-the-art performance in language modeling, text\nclassification, and image classification. Meanwhile, it emphasizes a general\nparadigm for designing broadly more relative positional encoding methods that\nare applicable to linear transformers. The code is available at\nhttps://github.com/OpenNLPLab/Lrpe.\n",
                "链接": "https://arxiv.org/abs/2307.09270"
            },
            {
                "文章ID": "76364",
                "标题": "Toeplitz Neural Network for Sequence Modeling",
                "作者": " Zhen Qin,  Xiaodong Han,  Weixuan Sun,  Bowen He,  Dong Li,  Dongxu Li,  Yuchao Dai,  Lingpeng Kong,  Yiran Zhong",
                "发布日期": "2023-05-09",
                "摘要": "  Sequence modeling has important applications in natural language processing\nand computer vision. Recently, the transformer-based models have shown strong\nperformance on various sequence modeling tasks, which rely on attention to\ncapture pairwise token relations, and position embedding to inject positional\ninformation. While showing good performance, the transformer models are\ninefficient to scale to long input sequences, mainly due to the quadratic\nspace-time complexity of attention. To overcome this inefficiency, we propose\nto model sequences with a relative position encoded Toeplitz matrix and use a\nToeplitz matrix-vector production trick to reduce the space-time complexity of\nthe sequence modeling to log linear. A lightweight sub-network called relative\nposition encoder is proposed to generate relative position coefficients with a\nfixed budget of parameters, enabling the proposed Toeplitz neural network to\ndeal with varying sequence lengths. In addition, despite being trained on\n512-token sequences, our model can extrapolate input sequence length up to 14K\ntokens in inference with consistent performance. Extensive experiments on\nautoregressive and bidirectional language modeling, image modeling, and the\nchallenging Long-Range Arena benchmark show that our method achieves better\nperformance than its competitors in most downstream tasks while being\nsignificantly faster. The code is available at\nhttps://github.com/OpenNLPLab/Tnn.\n",
                "链接": "https://arxiv.org/abs/2305.04749"
            },
            {
                "文章ID": "9782",
                "标题": "Efficient Long Sequence Encoding via Synchronization",
                "作者": " Xiangyang Mou,  Mo Yu,  Bingsheng Yao,  Lifu Huang",
                "发布日期": "2022-03-16",
                "摘要": "  Pre-trained Transformer models have achieved successes in a wide range of NLP\ntasks, but are inefficient when dealing with long input sequences. Existing\nstudies try to overcome this challenge via segmenting the long sequence\nfollowed by hierarchical encoding or post-hoc aggregation. We propose a\nsynchronization mechanism for hierarchical encoding. Our approach first\nidentifies anchor tokens across segments and groups them by their roles in the\noriginal input sequence. Then inside Transformer layer, anchor embeddings are\nsynchronized within their group via a self-attention module. Our approach is a\ngeneral framework with sufficient flexibility -- when adapted to a new task, it\nis easy to be enhanced with the task-specific anchor definitions. Experiments\non two representative tasks with different types of long input texts,\nNarrativeQA summary setting and wild multi-hop reasoning from HotpotQA,\ndemonstrate that our approach is able to improve the global information\nexchange among segments while maintaining efficiency.\n",
                "链接": "https://arxiv.org/abs/2203.07644"
            },
            {
                "文章ID": "3277",
                "标题": "GRPE: Relative Positional Encoding for Graph Transformer",
                "作者": " Wonpyo Park,  Woonggi Chang,  Donggeon Lee,  Juntae Kim,  Seung-won Hwang",
                "发布日期": "2022-10-17",
                "摘要": "  We propose a novel positional encoding for learning graph on Transformer\narchitecture. Existing approaches either linearize a graph to encode absolute\nposition in the sequence of nodes, or encode relative position with another\nnode using bias terms. The former loses preciseness of relative position from\nlinearization, while the latter loses a tight integration of node-edge and\nnode-topology interaction. To overcome the weakness of the previous approaches,\nour method encodes a graph without linearization and considers both\nnode-topology and node-edge interaction. We name our method Graph Relative\nPositional Encoding dedicated to graph representation learning. Experiments\nconducted on various graph datasets show that the proposed method outperforms\nprevious approaches significantly. Our code is publicly available at\nhttps://github.com/lenscloth/GRPE.\n",
                "链接": "https://arxiv.org/abs/2201.12787"
            }
        ]
    },
    {
        "question": {
            "question": "利用大模型做数学题生成的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "14278",
                "标题": "DISK: Domain-constrained Instance Sketch for Math Word Problem\n  Generation",
                "作者": " Tianyang Cao,  Shuang Zeng,  Xiaodan Xu,  Mairgup Mansur,  Baobao Chang",
                "发布日期": "2022-04-12",
                "摘要": "  A math word problem (MWP) is a coherent narrative which reflects the\nunderlying logic of math equations. Successful MWP generation can automate the\nwriting of mathematics questions. Previous methods mainly generate MWP text\nbased on inflexible pre-defined templates. In this paper, we propose a neural\nmodel for generating MWP text from math equations. Firstly, we incorporate a\nmatching model conditioned on the domain knowledge to retrieve a MWP instance\nwhich is most consistent with the ground-truth, where the domain is a latent\nvariable extracted with a domain summarizer. Secondly, by constructing a\nQuantity Cell Graph (QCG) from the retrieved MWP instance and reasoning over\nit, we improve the model's comprehension of real-world scenarios and derive a\ndomain-constrained instance sketch to guide the generation. Besides, the QCG\nalso interacts with the equation encoder to enhance the alignment between math\ntokens (e.g., quantities and variables) and MWP text. Experiments and empirical\nanalysis on educational MWP set show that our model achieves impressive\nperformance in both automatic evaluation metrics and human evaluation metrics.\n",
                "链接": "https://arxiv.org/abs/2204.04686"
            },
            {
                "文章ID": "79980",
                "标题": "Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with\n  Customized Exercise Generation",
                "作者": " Zhenwen Liang,  Wenhao Yu,  Tanmay Rajpurohit,  Peter Clark,  Xiangliang Zhang,  Ashwin Kaylan",
                "发布日期": "2023-05-25",
                "摘要": "  In this paper, we present a novel approach for distilling math word problem\nsolving capabilities from large language models (LLMs) into smaller, more\nefficient student models. Our approach is designed to consider the student\nmodel's weaknesses and foster a tailored learning experience by generating\ntargeted exercises aligned with educational science principles, such as\nknowledge tracing and personalized learning. Concretely, we let GPT-3 be a math\ntutor and run two steps iteratively: 1) assessing the student model's current\nlearning status on a GPT-generated exercise book, and 2) improving the student\nmodel by training it with tailored exercise samples generated by GPT-3.\nExperimental results reveal that our approach outperforms LLMs (e.g., GPT-3 and\nPaLM) in accuracy across three distinct benchmarks while employing\nsignificantly fewer parameters. Furthermore, we provide a comprehensive\nanalysis of the various components within our methodology to substantiate their\nefficacy.\n",
                "链接": "https://arxiv.org/abs/2305.14386"
            },
            {
                "文章ID": "83091",
                "标题": "An Empirical Study on Challenging Math Problem Solving with GPT-4",
                "作者": " Yiran Wu,  Feiran Jia,  Shaokun Zhang,  Hangyu Li,  Erkang Zhu,  Yue Wang,  Yin Tat Lee,  Richard Peng,  Qingyun Wu,  Chi Wang",
                "发布日期": "2023-06-09",
                "摘要": "  Employing Large Language Models (LLMs) to address mathematical problems is an\nintriguing research endeavor, considering the abundance of math problems\nexpressed in natural language across numerous science and engineering fields.\nWhile several prior works have investigated solving elementary mathematics\nusing LLMs, this work explores the frontier of using GPT-4 for solving more\ncomplex and challenging math problems. We evaluate various ways of using GPT-4.\nSome of them are adapted from existing work, and one is MathChat, a\nconversational problem-solving framework newly proposed in this work. We\nperform the evaluation on difficult high school competition problems from the\nMATH dataset, which shows the advantage of the proposed conversational\napproach.\n",
                "链接": "https://arxiv.org/abs/2306.01337"
            },
            {
                "文章ID": "50031",
                "标题": "Automatic Generation of Socratic Subquestions for Teaching Math Word\n  Problems",
                "作者": " Kumar Shridhar,  Jakub Macina,  Mennatallah El-Assady,  Tanmay Sinha,  Manu Kapur,  Mrinmaya Sachan",
                "发布日期": "2022-11-24",
                "摘要": "  Socratic questioning is an educational method that allows students to\ndiscover answers to complex problems by asking them a series of thoughtful\nquestions. Generation of didactically sound questions is challenging, requiring\nunderstanding of the reasoning process involved in the problem. We hypothesize\nthat such questioning strategy can not only enhance the human performance, but\nalso assist the math word problem (MWP) solvers. In this work, we explore the\nability of large language models (LMs) in generating sequential questions for\nguiding math word problem-solving. We propose various guided question\ngeneration schemes based on input conditioning and reinforcement learning. On\nboth automatic and human quality evaluations, we find that LMs constrained with\ndesirable question properties generate superior questions and improve the\noverall performance of a math word problem solver. We conduct a preliminary\nuser study to examine the potential value of such question generation models in\nthe education domain. Results suggest that the difficulty level of problems\nplays an important role in determining whether questioning improves or hinders\nhuman performance. We discuss the future of using such questioning strategies\nin education.\n",
                "链接": "https://arxiv.org/abs/2211.12835"
            },
            {
                "文章ID": "108984",
                "标题": "Improving Large Language Model Fine-tuning for Solving Math Problems",
                "作者": " Yixin Liu,  Avi Singh,  C. Daniel Freeman,  John D. Co-Reyes,  Peter J. Liu",
                "发布日期": "2023-10-17",
                "摘要": "  Despite their success in many natural language tasks, solving math problems\nremains a significant challenge for large language models (LLMs). A large gap\nexists between LLMs' pass-at-one and pass-at-N performance in solving math\nproblems, suggesting LLMs might be close to finding correct solutions,\nmotivating our exploration of fine-tuning methods to unlock LLMs' performance.\nUsing the challenging MATH dataset, we investigate three fine-tuning\nstrategies: (1) solution fine-tuning, where we fine-tune to generate a detailed\nsolution for a given math problem; (2) solution-cluster re-ranking, where the\nLLM is fine-tuned as a solution verifier/evaluator to choose among generated\ncandidate solution clusters; (3) multi-task sequential fine-tuning, which\nintegrates both solution generation and evaluation tasks together efficiently\nto enhance the LLM performance. With these methods, we present a thorough\nempirical study on a series of PaLM 2 models and find: (1) The quality and\nstyle of the step-by-step solutions used for fine-tuning can make a significant\nimpact on the model performance; (2) While solution re-ranking and majority\nvoting are both effective for improving the model performance when used\nseparately, they can also be used together for an even greater performance\nboost; (3) Multi-task fine-tuning that sequentially separates the solution\ngeneration and evaluation tasks can offer improved performance compared with\nthe solution fine-tuning baseline. Guided by these insights, we design a\nfine-tuning recipe that yields approximately 58.8% accuracy on the MATH dataset\nwith fine-tuned PaLM 2-L models, an 11.2% accuracy improvement over the\nfew-shot performance of pre-trained PaLM 2-L model with majority voting.\n",
                "链接": "https://arxiv.org/abs/2310.10047"
            },
            {
                "文章ID": "82852",
                "标题": "Interpretable Math Word Problem Solution Generation Via Step-by-step\n  Planning",
                "作者": " Mengxue Zhang,  Zichao Wang,  Zhichao Yang,  Weiqi Feng,  Andrew Lan",
                "发布日期": "2023-06-02",
                "摘要": "  Solutions to math word problems (MWPs) with step-by-step explanations are\nvaluable, especially in education, to help students better comprehend\nproblem-solving strategies. Most existing approaches only focus on obtaining\nthe final correct answer. A few recent approaches leverage intermediate\nsolution steps to improve final answer correctness but often cannot generate\ncoherent steps with a clear solution strategy. Contrary to existing work, we\nfocus on improving the correctness and coherence of the intermediate solutions\nsteps. We propose a step-by-step planning approach for intermediate solution\ngeneration, which strategically plans the generation of the next solution step\nbased on the MWP and the previous solution steps. Our approach first plans the\nnext step by predicting the necessary math operation needed to proceed, given\nhistory steps, then generates the next step, token-by-token, by prompting a\nlanguage model with the predicted math operation. Experiments on the GSM8K\ndataset demonstrate that our approach improves the accuracy and\ninterpretability of the solution on both automatic metrics and human\nevaluation.\n",
                "链接": "https://arxiv.org/abs/2306.00784"
            },
            {
                "文章ID": "89573",
                "标题": "Math Agents: Computational Infrastructure, Mathematical Embedding, and\n  Genomics",
                "作者": " Melanie Swan,  Takashi Kido,  Eric Roland,  Renato P. dos Santos",
                "发布日期": "2023-07-07",
                "摘要": "  The advancement in generative AI could be boosted with more accessible\nmathematics. Beyond human-AI chat, large language models (LLMs) are emerging in\nprogramming, algorithm discovery, and theorem proving, yet their genomics\napplication is limited. This project introduces Math Agents and mathematical\nembedding as fresh entries to the \"Moore's Law of Mathematics\", using a\nGPT-based workflow to convert equations from literature into LaTeX and Python\nformats. While many digital equation representations exist, there's a lack of\nautomated large-scale evaluation tools. LLMs are pivotal as linguistic user\ninterfaces, providing natural language access for human-AI chat and formal\nlanguages for large-scale AI-assisted computational infrastructure. Given the\ninfinite formal possibility spaces, Math Agents, which interact with math,\ncould potentially shift us from \"big data\" to \"big math\". Math, unlike the more\nflexible natural language, has properties subject to proof, enabling its use\nbeyond traditional applications like high-validation math-certified icons for\nAI alignment aims. This project aims to use Math Agents and mathematical\nembeddings to address the ageing issue in information systems biology by\napplying multiscalar physics mathematics to disease models and genomic data.\nGenerative AI with episodic memory could help analyse causal relations in\nlongitudinal health records, using SIR Precision Health models. Genomic data is\nsuggested for addressing the unsolved Alzheimer's disease problem.\n",
                "链接": "https://arxiv.org/abs/2307.02502"
            },
            {
                "文章ID": "119955",
                "标题": "ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating\n  Pre-university Math Questions",
                "作者": " Phuoc Pham Van Long,  Duc Anh Vu,  Nhat M. Hoang,  Xuan Long Do,  Anh Tuan Luu",
                "发布日期": "2023-12-05",
                "摘要": "  Mathematical questioning is crucial for assessing students problem-solving\nskills. Since manually creating such questions requires substantial effort,\nautomatic methods have been explored. Existing state-of-the-art models rely on\nfine-tuning strategies and struggle to generate questions that heavily involve\nmultiple steps of logical and arithmetic reasoning. Meanwhile, large language\nmodels(LLMs) such as ChatGPT have excelled in many NLP tasks involving logical\nand arithmetic reasoning. Nonetheless, their applications in generating\neducational questions are underutilized, especially in the field of\nmathematics. To bridge this gap, we take the first step to conduct an in-depth\nanalysis of ChatGPT in generating pre-university math questions. Our analysis\nis categorized into two main settings: context-aware and context-unaware. In\nthe context-aware setting, we evaluate ChatGPT on existing math\nquestion-answering benchmarks covering elementary, secondary, and ternary\nclasses. In the context-unaware setting, we evaluate ChatGPT in generating math\nquestions for each lesson from pre-university math curriculums that we crawl.\nOur crawling results in TopicMath, a comprehensive and novel collection of\npre-university math curriculums collected from 121 math topics and 428 lessons\nfrom elementary, secondary, and tertiary classes. Through this analysis, we aim\nto provide insight into the potential of ChatGPT as a math questioner.\n",
                "链接": "https://arxiv.org/abs/2312.01661"
            },
            {
                "文章ID": "100220",
                "标题": "MathAttack: Attacking Large Language Models Towards Math Solving Ability",
                "作者": " Zihao Zhou,  Qiufeng Wang,  Mingyu Jin,  Jie Yao,  Jianan Ye,  Wei Liu,  Wei Wang,  Xiaowei Huang,  Kaizhu Huang",
                "发布日期": "2023-09-06",
                "摘要": "  With the boom of Large Language Models (LLMs), the research of solving Math\nWord Problem (MWP) has recently made great progress. However, there are few\nstudies to examine the security of LLMs in math solving ability. Instead of\nattacking prompts in the use of LLMs, we propose a MathAttack model to attack\nMWP samples which are closer to the essence of security in solving math\nproblems. Compared to traditional text adversarial attack, it is essential to\npreserve the mathematical logic of original MWPs during the attacking. To this\nend, we propose logical entity recognition to identify logical entries which\nare then frozen. Subsequently, the remaining text are attacked by adopting a\nword-level attacker. Furthermore, we propose a new dataset RobustMath to\nevaluate the robustness of LLMs in math solving ability. Extensive experiments\non our RobustMath and two another math benchmark datasets GSM8K and MultiAirth\nshow that MathAttack could effectively attack the math solving ability of LLMs.\nIn the experiments, we observe that (1) Our adversarial samples from\nhigher-accuracy LLMs are also effective for attacking LLMs with lower accuracy\n(e.g., transfer from larger to smaller-size LLMs, or from few-shot to zero-shot\nprompts); (2) Complex MWPs (such as more solving steps, longer text, more\nnumbers) are more vulnerable to attack; (3) We can improve the robustness of\nLLMs by using our adversarial samples in few-shot prompts. Finally, we hope our\npractice and observation can serve as an important attempt towards enhancing\nthe robustness of LLMs in math solving ability. We will release our code and\ndataset.\n",
                "链接": "https://arxiv.org/abs/2309.01686"
            },
            {
                "文章ID": "92856",
                "标题": "Explaining Math Word Problem Solvers",
                "作者": " Abby Newcomb,  Jugal Kalita",
                "发布日期": "2023-07-26",
                "摘要": "  Automated math word problem solvers based on neural networks have\nsuccessfully managed to obtain 70-80\\% accuracy in solving arithmetic word\nproblems. However, it has been shown that these solvers may rely on superficial\npatterns to obtain their equations. In order to determine what information math\nword problem solvers use to generate solutions, we remove parts of the input\nand measure the model's performance on the perturbed dataset. Our results show\nthat the model is not sensitive to the removal of many words from the input and\ncan still manage to find a correct answer when given a nonsense question. This\nindicates that automatic solvers do not follow the semantic logic of math word\nproblems, and may be overfitting to the presence of specific words.\n",
                "链接": "https://arxiv.org/abs/2307.13128"
            }
        ]
    },
    {
        "question": {
            "question": "查找可以用于验证模型推理能力的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "79516",
                "标题": "Evaluating Model Performance in Medical Datasets Over Time",
                "作者": " Helen Zhou,  Yuwen Chen,  Zachary C. Lipton",
                "发布日期": "2023-07-21",
                "摘要": "  Machine learning (ML) models deployed in healthcare systems must face data\ndrawn from continually evolving environments. However, researchers proposing\nsuch models typically evaluate them in a time-agnostic manner, splitting\ndatasets according to patients sampled randomly throughout the entire study\ntime period. This work proposes the Evaluation on Medical Datasets Over Time\n(EMDOT) framework, which evaluates the performance of a model class across\ntime. Inspired by the concept of backtesting, EMDOT simulates possible training\nprocedures that practitioners might have been able to execute at each point in\ntime and evaluates the resulting models on all future time points. Evaluating\nboth linear and more complex models on six distinct medical data sources\n(tabular and imaging), we show how depending on the dataset, using all\nhistorical data may be ideal in many cases, whereas using a window of the most\nrecent data could be advantageous in others. In datasets where models suffer\nfrom sudden degradations in performance, we investigate plausible explanations\nfor these shocks. We release the EMDOT package to help facilitate further works\nin deployment-oriented evaluation over time.\n",
                "链接": "https://arxiv.org/abs/2305.13426"
            },
            {
                "文章ID": "12157",
                "标题": "LogicInference: A New Dataset for Teaching Logical Inference to seq2seq\n  Models",
                "作者": " Santiago Ontanon,  Joshua Ainslie,  Vaclav Cvicek,  Zachary Fisher",
                "发布日期": "2022-04-12",
                "摘要": "  Machine learning models such as Transformers or LSTMs struggle with tasks\nthat are compositional in nature such as those involving reasoning/inference.\nAlthough many datasets exist to evaluate compositional generalization, when it\ncomes to evaluating inference abilities, options are more limited. This paper\npresents LogicInference, a new dataset to evaluate the ability of models to\nperform logical inference. The dataset focuses on inference using propositional\nlogic and a small subset of first-order logic, represented both in semi-formal\nlogical notation, as well as in natural language. We also report initial\nresults using a collection of machine learning models to establish an initial\nbaseline in this dataset.\n",
                "链接": "https://arxiv.org/abs/2203.15099"
            },
            {
                "文章ID": "107738",
                "标题": "REVO-LION: Evaluating and Refining Vision-Language Instruction Tuning\n  Datasets",
                "作者": " Ning Liao,  Shaofeng Zhang,  Renqiu Xia,  Bo Zhang,  Min Cao,  Yu Qiao,  Junchi Yan",
                "发布日期": "2023-10-11",
                "摘要": "  There is an emerging line of research on multimodal instruction tuning, and a\nline of benchmarks have been proposed for evaluating these models recently.\nInstead of evaluating the models directly, in this paper we try to evaluate the\nVision-Language Instruction-Tuning (VLIT) datasets themselves and further seek\nthe way of building a dataset for developing an all-powerful VLIT model, which\nwe believe could also be of utility for establishing a grounded protocol for\nbenchmarking VLIT models. For effective analysis of VLIT datasets that remains\nan open question, we propose a tune-cross-evaluation paradigm: tuning on one\ndataset and evaluating on the others in turn. For each single tune-evaluation\nexperiment set, we define the Meta Quality (MQ) as the mean score measured by a\nseries of caption metrics including BLEU, METEOR, and ROUGE-L to quantify the\nquality of a certain dataset or a sample. On this basis, to evaluate the\ncomprehensiveness of a dataset, we develop the Dataset Quality (DQ) covering\nall tune-evaluation sets. To lay the foundation for building a comprehensive\ndataset and developing an all-powerful model for practical applications, we\nfurther define the Sample Quality (SQ) to quantify the all-sided quality of\neach sample. Extensive experiments validate the rationality of the proposed\nevaluation paradigm. Based on the holistic evaluation, we build a new dataset,\nREVO-LION (REfining VisiOn-Language InstructiOn tuNing), by collecting samples\nwith higher SQ from each dataset. With only half of the full data, the model\ntrained on REVO-LION can achieve performance comparable to simply adding all\nVLIT datasets up. In addition to developing an all-powerful model, REVO-LION\nalso includes an evaluation set, which is expected to serve as a convenient\nevaluation benchmark for future research.\n",
                "链接": "https://arxiv.org/abs/2310.06594"
            },
            {
                "文章ID": "32390",
                "标题": "A Case for Dataset Specific Profiling",
                "作者": " Seth Ockerman,  John Wu,  Christopher Stewart",
                "发布日期": "2022-08-09",
                "摘要": "  Data-driven science is an emerging paradigm where scientific discoveries\ndepend on the execution of computational AI models against rich,\ndiscipline-specific datasets. With modern machine learning frameworks, anyone\ncan develop and execute computational models that reveal concepts hidden in the\ndata that could enable scientific applications. For important and widely used\ndatasets, computing the performance of every computational model that can run\nagainst a dataset is cost prohibitive in terms of cloud resources. Benchmarking\napproaches used in practice use representative datasets to infer performance\nwithout actually executing models. While practicable, these approaches limit\nextensive dataset profiling to a few datasets and introduce bias that favors\nmodels suited for representative datasets. As a result, each dataset's unique\ncharacteristics are left unexplored and subpar models are selected based on\ninference from generalized datasets. This necessitates a new paradigm that\nintroduces dataset profiling into the model selection process. To demonstrate\nthe need for dataset-specific profiling, we answer two questions:(1) Can\nscientific datasets significantly permute the rank order of computational\nmodels compared to widely used representative datasets? (2) If so, could\nlightweight model execution improve benchmarking accuracy? Taken together, the\nanswers to these questions lay the foundation for a new dataset-aware\nbenchmarking paradigm.\n",
                "链接": "https://arxiv.org/abs/2208.03315"
            },
            {
                "文章ID": "86629",
                "标题": "Jamp: Controlled Japanese Temporal Inference Dataset for Evaluating\n  Generalization Capacity of Language Models",
                "作者": " Tomoki Sugimoto,  Yasumasa Onoe,  Hitomi Yanaka",
                "发布日期": "2023-06-21",
                "摘要": "  Natural Language Inference (NLI) tasks involving temporal inference remain\nchallenging for pre-trained language models (LMs). Although various datasets\nhave been created for this task, they primarily focus on English and do not\naddress the need for resources in other languages. It is unclear whether\ncurrent LMs realize the generalization capacity for temporal inference across\nlanguages. In this paper, we present Jamp, a Japanese NLI benchmark focused on\ntemporal inference. Our dataset includes a range of temporal inference\npatterns, which enables us to conduct fine-grained analysis. To begin the data\nannotation process, we create diverse inference templates based on the formal\nsemantics test suites. We then automatically generate diverse NLI examples by\nusing the Japanese case frame dictionary and well-designed templates while\ncontrolling the distribution of inference patterns and gold labels. We evaluate\nthe generalization capacities of monolingual/multilingual LMs by splitting our\ndataset based on tense fragments (i.e., temporal inference patterns). Our\nfindings demonstrate that LMs struggle with specific linguistic phenomena, such\nas habituality, indicating that there is potential for the development of more\neffective NLI models across languages.\n",
                "链接": "https://arxiv.org/abs/2306.10727"
            },
            {
                "文章ID": "26012",
                "标题": "The ArtBench Dataset: Benchmarking Generative Models with Artworks",
                "作者": " Peiyuan Liao,  Xiuyu Li,  Xihui Liu,  Kurt Keutzer",
                "发布日期": "2022-06-24",
                "摘要": "  We introduce ArtBench-10, the first class-balanced, high-quality, cleanly\nannotated, and standardized dataset for benchmarking artwork generation. It\ncomprises 60,000 images of artwork from 10 distinctive artistic styles, with\n5,000 training images and 1,000 testing images per style. ArtBench-10 has\nseveral advantages over previous artwork datasets. Firstly, it is\nclass-balanced while most previous artwork datasets suffer from the long tail\nclass distributions. Secondly, the images are of high quality with clean\nannotations. Thirdly, ArtBench-10 is created with standardized data collection,\nannotation, filtering, and preprocessing procedures. We provide three versions\nof the dataset with different resolutions ($32\\times32$, $256\\times256$, and\noriginal image size), formatted in a way that is easy to be incorporated by\npopular machine learning frameworks. We also conduct extensive benchmarking\nexperiments using representative image synthesis models with ArtBench-10 and\npresent in-depth analysis. The dataset is available at\nhttps://github.com/liaopeiyuan/artbench under a Fair Use license.\n",
                "链接": "https://arxiv.org/abs/2206.11404"
            },
            {
                "文章ID": "83237",
                "标题": "DaTaSeg: Taming a Universal Multi-Dataset Multi-Task Segmentation Model",
                "作者": " Xiuye Gu,  Yin Cui,  Jonathan Huang,  Abdullah Rashwan,  Xuan Yang,  Xingyi Zhou,  Golnaz Ghiasi,  Weicheng Kuo,  Huizhong Chen,  Liang-Chieh Chen,  David A Ross",
                "发布日期": "2023-06-05",
                "摘要": "  Observing the close relationship among panoptic, semantic and instance\nsegmentation tasks, we propose to train a universal multi-dataset multi-task\nsegmentation model: DaTaSeg.We use a shared representation (mask proposals with\nclass predictions) for all tasks. To tackle task discrepancy, we adopt\ndifferent merge operations and post-processing for different tasks. We also\nleverage weak-supervision, allowing our segmentation model to benefit from\ncheaper bounding box annotations. To share knowledge across datasets, we use\ntext embeddings from the same semantic embedding space as classifiers and share\nall network parameters among datasets. We train DaTaSeg on ADE semantic, COCO\npanoptic, and Objects365 detection datasets. DaTaSeg improves performance on\nall datasets, especially small-scale datasets, achieving 54.0 mIoU on ADE\nsemantic and 53.5 PQ on COCO panoptic. DaTaSeg also enables weakly-supervised\nknowledge transfer on ADE panoptic and Objects365 instance segmentation.\nExperiments show DaTaSeg scales with the number of training datasets and\nenables open-vocabulary segmentation through direct transfer. In addition, we\nannotate an Objects365 instance segmentation set of 1,000 images and will\nrelease it as a public benchmark.\n",
                "链接": "https://arxiv.org/abs/2306.01736"
            },
            {
                "文章ID": "54203",
                "标题": "Statistical Dataset Evaluation: Reliability, Difficulty, and Validity",
                "作者": " Chengwen Wang,  Qingxiu Dong,  Xiaochen Wang,  Haitao Wang,  Zhifang Sui",
                "发布日期": "2022-12-20",
                "摘要": "  Datasets serve as crucial training resources and model performance trackers.\nHowever, existing datasets have exposed a plethora of problems, inducing biased\nmodels and unreliable evaluation results. In this paper, we propose a\nmodel-agnostic dataset evaluation framework for automatic dataset quality\nevaluation. We seek the statistical properties of the datasets and address\nthree fundamental dimensions: reliability, difficulty, and validity, following\na classical testing theory. Taking the Named Entity Recognition (NER) datasets\nas a case study, we introduce $9$ statistical metrics for a statistical dataset\nevaluation framework. Experimental results and human evaluation validate that\nour evaluation framework effectively assesses various aspects of the dataset\nquality. Furthermore, we study how the dataset scores on our statistical\nmetrics affect the model performance, and appeal for dataset quality evaluation\nor targeted dataset improvement before training or testing models.\n",
                "链接": "https://arxiv.org/abs/2212.09272"
            },
            {
                "文章ID": "84200",
                "标题": "Benchmarking Foundation Models with Language-Model-as-an-Examiner",
                "作者": " Yushi Bai,  Jiahao Ying,  Yixin Cao,  Xin Lv,  Yuze He,  Xiaozhi Wang,  Jifan Yu,  Kaisheng Zeng,  Yijia Xiao,  Haozhe Lyu,  Jiayin Zhang,  Juanzi Li,  Lei Hou",
                "发布日期": "2023-11-07",
                "摘要": "  Numerous benchmarks have been established to assess the performance of\nfoundation models on open-ended question answering, which serves as a\ncomprehensive test of a model's ability to understand and generate language in\na manner similar to humans. Most of these works focus on proposing new\ndatasets, however, we see two main issues within previous benchmarking\npipelines, namely testing leakage and evaluation automation. In this paper, we\npropose a novel benchmarking framework, Language-Model-as-an-Examiner, where\nthe LM serves as a knowledgeable examiner that formulates questions based on\nits knowledge and evaluates responses in a reference-free manner. Our framework\nallows for effortless extensibility as various LMs can be adopted as the\nexaminer, and the questions can be constantly updated given more diverse\ntrigger topics. For a more comprehensive and equitable evaluation, we devise\nthree strategies: (1) We instruct the LM examiner to generate questions across\na multitude of domains to probe for a broad acquisition, and raise follow-up\nquestions to engage in a more in-depth assessment. (2) Upon evaluation, the\nexaminer combines both scoring and ranking measurements, providing a reliable\nresult as it aligns closely with human annotations. (3) We additionally propose\na decentralized Peer-examination method to address the biases in a single\nexaminer. Our data and benchmarking results are available at:\nhttp://lmexam.xlore.cn.\n",
                "链接": "https://arxiv.org/abs/2306.04181"
            },
            {
                "文章ID": "68",
                "标题": "On the Cross-dataset Generalization in License Plate Recognition",
                "作者": " Rayson Laroca,  Everton V. Cardoso,  Diego R. Lucio,  Valter Estevam,  David Menotti",
                "发布日期": "2022-12-22",
                "摘要": "  Automatic License Plate Recognition (ALPR) systems have shown remarkable\nperformance on license plates (LPs) from multiple regions due to advances in\ndeep learning and the increasing availability of datasets. The evaluation of\ndeep ALPR systems is usually done within each dataset; therefore, it is\nquestionable if such results are a reliable indicator of generalization\nability. In this paper, we propose a traditional-split versus\nleave-one-dataset-out experimental setup to empirically assess the\ncross-dataset generalization of 12 Optical Character Recognition (OCR) models\napplied to LP recognition on nine publicly available datasets with a great\nvariety in several aspects (e.g., acquisition settings, image resolution, and\nLP layouts). We also introduce a public dataset for end-to-end ALPR that is the\nfirst to contain images of vehicles with Mercosur LPs and the one with the\nhighest number of motorcycle images. The experimental results shed light on the\nlimitations of the traditional-split protocol for evaluating approaches in the\nALPR context, as there are significant drops in performance for most datasets\nwhen training and testing the models in a leave-one-dataset-out fashion.\n",
                "链接": "https://arxiv.org/abs/2201.00267"
            }
        ]
    },
    {
        "question": {
            "question": "帮我找一下用大模型进行论文查找的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "77185",
                "标题": "Synergistic Interplay between Search and Large Language Models for\n  Information Retrieval",
                "作者": " Jiazhan Feng,  Chongyang Tao,  Xiubo Geng,  Tao Shen,  Can Xu,  Guodong Long,  Dongyan Zhao,  Daxin Jiang",
                "发布日期": "2023-12-13",
                "摘要": "  Information retrieval (IR) plays a crucial role in locating relevant\nresources from vast amounts of data, and its applications have evolved from\ntraditional knowledge bases to modern retrieval models (RMs). The emergence of\nlarge language models (LLMs) has further revolutionized the IR field by\nenabling users to interact with search systems in natural languages. In this\npaper, we explore the advantages and disadvantages of LLMs and RMs,\nhighlighting their respective strengths in understanding user-issued queries\nand retrieving up-to-date information. To leverage the benefits of both\nparadigms while circumventing their limitations, we propose InteR, a novel\nframework that facilitates information refinement through synergy between RMs\nand LLMs. InteR allows RMs to expand knowledge in queries using LLM-generated\nknowledge collections and enables LLMs to enhance prompt formulation using\nretrieved documents. This iterative refinement process augments the inputs of\nRMs and LLMs, leading to more accurate retrieval. Experiments on large-scale\nretrieval benchmarks involving web search and low-resource retrieval tasks\ndemonstrate that InteR achieves overall superior zero-shot retrieval\nperformance compared to state-of-the-art methods, even those using relevance\njudgment. Source code is available at https://github.com/Cyril-JZ/InteR\n",
                "链接": "https://arxiv.org/abs/2305.07402"
            },
            {
                "文章ID": "79916",
                "标题": "Query Rewriting for Retrieval-Augmented Large Language Models",
                "作者": " Xinbei Ma,  Yeyun Gong,  Pengcheng He,  Hai Zhao,  Nan Duan",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) play powerful, black-box readers in the\nretrieve-then-read pipeline, making remarkable progress in knowledge-intensive\ntasks. This work introduces a new framework, Rewrite-Retrieve-Read instead of\nthe previous retrieve-then-read for the retrieval-augmented LLMs from the\nperspective of the query rewriting. Unlike prior studies focusing on adapting\neither the retriever or the reader, our approach pays attention to the\nadaptation of the search query itself, for there is inevitably a gap between\nthe input text and the needed knowledge in retrieval. We first prompt an LLM to\ngenerate the query, then use a web search engine to retrieve contexts.\nFurthermore, to better align the query to the frozen modules, we propose a\ntrainable scheme for our pipeline. A small language model is adopted as a\ntrainable rewriter to cater to the black-box LLM reader. The rewriter is\ntrained using the feedback of the LLM reader by reinforcement learning.\nEvaluation is conducted on downstream tasks, open-domain QA and multiple-choice\nQA. Experiments results show consistent performance improvement, indicating\nthat our framework is proven effective and scalable, and brings a new framework\nfor retrieval-augmented LLM.\n",
                "链接": "https://arxiv.org/abs/2305.14283"
            },
            {
                "文章ID": "84609",
                "标题": "RETA-LLM: A Retrieval-Augmented Large Language Model Toolkit",
                "作者": " Jiongnan Liu,  Jiajie Jin,  Zihan Wang,  Jiehan Cheng,  Zhicheng Dou,  Ji-Rong Wen",
                "发布日期": "2023-06-09",
                "摘要": "  Although Large Language Models (LLMs) have demonstrated extraordinary\ncapabilities in many domains, they still have a tendency to hallucinate and\ngenerate fictitious responses to user requests. This problem can be alleviated\nby augmenting LLMs with information retrieval (IR) systems (also known as\nretrieval-augmented LLMs). Applying this strategy, LLMs can generate more\nfactual texts in response to user input according to the relevant content\nretrieved by IR systems from external corpora as references. In addition, by\nincorporating external knowledge, retrieval-augmented LLMs can answer in-domain\nquestions that cannot be answered by solely relying on the world knowledge\nstored in parameters. To support research in this area and facilitate the\ndevelopment of retrieval-augmented LLM systems, we develop RETA-LLM, a\n{RET}reival-{A}ugmented LLM toolkit. In RETA-LLM, we create a complete pipeline\nto help researchers and users build their customized in-domain LLM-based\nsystems. Compared with previous retrieval-augmented LLM systems, RETA-LLM\nprovides more plug-and-play modules to support better interaction between IR\nsystems and LLMs, including {request rewriting, document retrieval, passage\nextraction, answer generation, and fact checking} modules. Our toolkit is\npublicly available at https://github.com/RUC-GSAI/YuLan-IR/tree/main/RETA-LLM.\n",
                "链接": "https://arxiv.org/abs/2306.05212"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            },
            {
                "文章ID": "74640",
                "标题": "Large Language Models are Strong Zero-Shot Retriever",
                "作者": " Tao Shen,  Guodong Long,  Xiubo Geng,  Chongyang Tao,  Tianyi Zhou,  Daxin Jiang",
                "发布日期": "2023-08-03",
                "摘要": "  In this work, we propose a simple method that applies a large language model\n(LLM) to large-scale retrieval in zero-shot scenarios. Our method, the Language\nlanguage model as Retriever (LameR), is built upon no other neural models but\nan LLM, while breaking brute-force combinations of retrievers with LLMs and\nlifting the performance of zero-shot retrieval to be very competitive on\nbenchmark datasets. Essentially, we propose to augment a query with its\npotential answers by prompting LLMs with a composition of the query and the\nquery's in-domain candidates. The candidates, regardless of correct or wrong,\nare obtained by a vanilla retrieval procedure on the target collection. As a\npart of the prompts, they are likely to help LLM generate more precise answers\nby pattern imitation or candidate summarization. Even if all the candidates are\nwrong, the prompts at least make LLM aware of in-collection patterns and\ngenres. Moreover, due to the low performance of a self-supervised retriever,\nthe LLM-based query augmentation becomes less effective as the retriever\nbottlenecks the whole pipeline. Therefore, we propose to leverage a\nnon-parametric lexicon-based method (e.g., BM25) as the retrieval module to\ncapture query-document overlap in a literal fashion. As such, LameR makes the\nretrieval procedure transparent to the LLM, thus circumventing the performance\nbottleneck.\n",
                "链接": "https://arxiv.org/abs/2304.14233"
            },
            {
                "文章ID": "100653",
                "标题": "Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from\n  Knowledge Graphs",
                "作者": " Chao Feng,  Xinyu Zhang,  Zichu Fei",
                "发布日期": "2023-09-07",
                "摘要": "  Large language models (LLMs), such as ChatGPT and GPT-4, are versatile and\ncan solve different tasks due to their emergent ability and generalizability.\nHowever, LLMs sometimes lack domain-specific knowledge to perform tasks, which\nwould also cause hallucination during inference. In some previous works,\nadditional modules like graph neural networks (GNNs) are trained on retrieved\nknowledge from external knowledge bases, aiming to mitigate the problem of\nlacking domain-specific knowledge. However, incorporating additional modules:\n1) would need retraining additional modules when encountering novel domains; 2)\nwould become a bottleneck since LLMs' strong abilities are not fully utilized\nfor retrieval. In this paper, we propose a paradigm, termed Knowledge Solver\n(KSL), to teach LLMs to search for essential knowledge from external knowledge\nbases by harnessing their own strong generalizability. Specifically, we design\na simple yet effective prompt to transform retrieval into a multi-hop decision\nsequence, which empowers LLMs with searching knowledge ability in zero-shot\nmanner. Additionally, KSL is able to provide complete retrieval paths and\ntherefore increase explainability of LLMs' reasoning processes. We conduct\nexperiments on three datasets: CommonsenseQA, OpenbookQA, and MedQA-USMLE, and\nfound that our approach improves LLM baseline performance by a relatively large\nmargin.\n",
                "链接": "https://arxiv.org/abs/2309.03118"
            },
            {
                "文章ID": "67983",
                "标题": "cTBLS: Augmenting Large Language Models with Conversational Tables",
                "作者": " Anirudh S Sundar,  Larry Heck",
                "发布日期": "2023-06-01",
                "摘要": "  Optimizing accuracy and performance while eliminating hallucinations of\nopen-domain conversational large language models (LLMs) is an open research\nchallenge. A particularly promising direction is to augment and ground LLMs\nwith information from structured sources. This paper introduces Conversational\nTables (cTBLS), a three-step architecture to retrieve and generate dialogue\nresponses grounded on retrieved tabular information. cTBLS uses Transformer\nencoder embeddings for Dense Table Retrieval and obtains up to 125% relative\nimprovement over the retriever in the previous state-of-the-art system on the\nHyrbiDialogue dataset. cTBLS then uses a shared process between encoder and\ndecoder models to perform a coarse+fine tabular knowledge (e.g., cell) ranking\ncombined with a GPT-3.5 LLM response generator to yield a 2x relative\nimprovement in ROUGE scores. Finally, human evaluators prefer cTBLs +80% of the\ntime (coherency, fluency) and judge informativeness to be 4x better than the\nprevious state-of-the-art.\n",
                "链接": "https://arxiv.org/abs/2303.12024"
            },
            {
                "文章ID": "110649",
                "标题": "Large Search Model: Redefining Search Stack in the Era of LLMs",
                "作者": " Liang Wang,  Nan Yang,  Xiaolong Huang,  Linjun Yang,  Rangan Majumder,  Furu Wei",
                "发布日期": "2023-10-24",
                "摘要": "  Modern search engines are built on a stack of different components, including\nquery understanding, retrieval, multi-stage ranking, and question answering,\namong others. These components are often optimized and deployed independently.\nIn this paper, we introduce a novel conceptual framework called large search\nmodel, which redefines the conventional search stack by unifying search tasks\nwith one large language model (LLM). All tasks are formulated as autoregressive\ntext generation problems, allowing for the customization of tasks through the\nuse of natural language prompts. This proposed framework capitalizes on the\nstrong language understanding and reasoning capabilities of LLMs, offering the\npotential to enhance search result quality while simultaneously simplifying the\nexisting cumbersome search stack. To substantiate the feasibility of this\nframework, we present a series of proof-of-concept experiments and discuss the\npotential challenges associated with implementing this approach within\nreal-world search systems.\n",
                "链接": "https://arxiv.org/abs/2310.14587"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到，最早提出分布式词表示的论文是哪一篇？",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "54196",
                "标题": "Multi hash embeddings in spaCy",
                "作者": " Lester James Miranda,  Ákos Kádár,  Adriane Boyd,  Sofie Van Landeghem,  Anders Søgaard,  Matthew Honnibal",
                "发布日期": "2022-12-20",
                "摘要": "  The distributed representation of symbols is one of the key technologies in\nmachine learning systems today, playing a pivotal role in modern natural\nlanguage processing. Traditional word embeddings associate a separate vector\nwith each word. While this approach is simple and leads to good performance, it\nrequires a lot of memory for representing a large vocabulary. To reduce the\nmemory footprint, the default embedding layer in spaCy is a hash embeddings\nlayer. It is a stochastic approximation of traditional embeddings that provides\nunique vectors for a large number of words without explicitly storing a\nseparate vector for each of them. To be able to compute meaningful\nrepresentations for both known and unknown words, hash embeddings represent\neach word as a summary of the normalized word form, subword information and\nword shape. Together, these features produce a multi-embedding of a word. In\nthis technical report we lay out a bit of history and introduce the embedding\nmethods in spaCy in detail. Second, we critically evaluate the hash embedding\narchitecture with multi-embeddings on Named Entity Recognition datasets from a\nvariety of domains and languages. The experiments validate most key design\nchoices behind spaCy's embedders, but we also uncover a few surprising results.\n",
                "链接": "https://arxiv.org/abs/2212.09255"
            },
            {
                "文章ID": "119444",
                "标题": "Robust Concept Erasure via Kernelized Rate-Distortion Maximization",
                "作者": " Somnath Basu Roy Chowdhury,  Nicholas Monath,  Avinava Dubey,  Amr Ahmed,  Snigdha Chaturvedi",
                "发布日期": "2023-12-04",
                "摘要": "  Distributed representations provide a vector space that captures meaningful\nrelationships between data instances. The distributed nature of these\nrepresentations, however, entangles together multiple attributes or concepts of\ndata instances (e.g., the topic or sentiment of a text, characteristics of the\nauthor (age, gender, etc), etc). Recent work has proposed the task of concept\nerasure, in which rather than making a concept predictable, the goal is to\nremove an attribute from distributed representations while retaining other\ninformation from the original representation space as much as possible. In this\npaper, we propose a new distance metric learning-based objective, the\nKernelized Rate-Distortion Maximizer (KRaM), for performing concept erasure.\nKRaM fits a transformation of representations to match a specified distance\nmeasure (defined by a labeled concept to erase) using a modified\nrate-distortion function. Specifically, KRaM's objective function aims to make\ninstances with similar concept labels dissimilar in the learned representation\nspace while retaining other information. We find that optimizing KRaM\neffectively erases various types of concepts: categorical, continuous, and\nvector-valued variables from data representations across diverse domains. We\nalso provide a theoretical analysis of several properties of KRaM's objective.\nTo assess the quality of the learned representations, we propose an alignment\nscore to evaluate their similarity with the original representation space.\nAdditionally, we conduct experiments to showcase KRaM's efficacy in various\nsettings, from erasing binary gender variables in word embeddings to\nvector-valued variables in GPT-3 representations.\n",
                "链接": "https://arxiv.org/abs/2312.00194"
            },
            {
                "文章ID": "123445",
                "标题": "Disentangling continuous and discrete linguistic signals in\n  transformer-based sentence embeddings",
                "作者": " Vivi Nastase,  Paola Merlo",
                "发布日期": "2023-12-19",
                "摘要": "  Sentence and word embeddings encode structural and semantic information in a\ndistributed manner. Part of the information encoded -- particularly lexical\ninformation -- can be seen as continuous, whereas other -- like structural\ninformation -- is most often discrete. We explore whether we can compress\ntransformer-based sentence embeddings into a representation that separates\ndifferent linguistic signals -- in particular, information relevant to\nsubject-verb agreement and verb alternations. We show that by compressing an\ninput sequence that shares a targeted phenomenon into the latent layer of a\nvariational autoencoder-like system, the targeted linguistic information\nbecomes more explicit. A latent layer with both discrete and continuous\ncomponents captures better the targeted phenomena than a latent layer with only\ndiscrete or only continuous components. These experiments are a step towards\nseparating linguistic signals from distributed text embeddings and linking them\nto more symbolic representations.\n",
                "链接": "https://arxiv.org/abs/2312.11272"
            },
            {
                "文章ID": "78675",
                "标题": "Contextualized Word Vector-based Methods for Discovering Semantic\n  Differences with No Training nor Word Alignment",
                "作者": " Ryo Nagata,  Hiroya Takamura,  Naoki Otani,  Yoshifumi Kawasaki",
                "发布日期": "2023-05-22",
                "摘要": "  In this paper, we propose methods for discovering semantic differences in\nwords appearing in two corpora based on the norms of contextualized word\nvectors. The key idea is that the coverage of meanings is reflected in the norm\nof its mean word vector. The proposed methods do not require the assumptions\nconcerning words and corpora for comparison that the previous methods do. All\nthey require are to compute the mean vector of contextualized word vectors and\nits norm for each word type. Nevertheless, they are (i) robust for the skew in\ncorpus size; (ii) capable of detecting semantic differences in infrequent\nwords; and (iii) effective in pinpointing word instances that have a meaning\nmissing in one of the two corpora for comparison. We show these advantages for\nnative and non-native English corpora and also for historical corpora.\n",
                "链接": "https://arxiv.org/abs/2305.11516"
            },
            {
                "文章ID": "7057",
                "标题": "Prediction of Depression Severity Based on the Prosodic and Semantic\n  Features with Bidirectional LSTM and Time Distributed CNN",
                "作者": " Kaining Mao,  Wei Zhang,  Deborah Baofeng Wang,  Ang Li,  Rongqi Jiao,  Yanhui Zhu,  Bin Wu,  Tiansheng Zheng,  Lei Qian,  Wei Lyu,  Minjie Ye,  Jie Chen",
                "发布日期": "2022-02-28",
                "摘要": "  Depression is increasingly impacting individuals both physically and\npsychologically worldwide. It has become a global major public health problem\nand attracts attention from various research fields. Traditionally, the\ndiagnosis of depression is formulated through semi-structured interviews and\nsupplementary questionnaires, which makes the diagnosis heavily relying on\nphysicians experience and is subject to bias. Mental health monitoring and\ncloud-based remote diagnosis can be implemented through an automated depression\ndiagnosis system. In this article, we propose an attention-based multimodality\nspeech and text representation for depression prediction. Our model is trained\nto estimate the depression severity of participants using the Distress Analysis\nInterview Corpus-Wizard of Oz (DAIC-WOZ) dataset. For the audio modality, we\nuse the collaborative voice analysis repository (COVAREP) features provided by\nthe dataset and employ a Bidirectional Long Short-Term Memory Network (Bi-LSTM)\nfollowed by a Time-distributed Convolutional Neural Network (T-CNN). For the\ntext modality, we use global vectors for word representation (GloVe) to perform\nword embeddings and the embeddings are fed into the Bi-LSTM network. Results\nshow that both audio and text models perform well on the depression severity\nestimation task, with best sequence level F1 score of 0.9870 and patient-level\nF1 score of 0.9074 for the audio model over five classes (healthy, mild,\nmoderate, moderately severe, and severe), as well as sequence level F1 score of\n0.9709 and patient-level F1 score of 0.9245 for the text model over five\nclasses. Results are similar for the multimodality fused model, with the\nhighest F1 score of 0.9580 on the patient-level depression detection task over\nfive classes. Experiments show statistically significant improvements over\nprevious works.\n",
                "链接": "https://arxiv.org/abs/2202.12456"
            },
            {
                "文章ID": "10524",
                "标题": "Training a Tokenizer for Free with Private Federated Learning",
                "作者": " Eugene Bagdasaryan,  Congzheng Song,  Rogier van Dalen,  Matt Seigel,  Áine Cahill",
                "发布日期": "2022-03-21",
                "摘要": "  Federated learning with differential privacy, i.e. private federated learning\n(PFL), makes it possible to train models on private data distributed across\nusers' devices without harming privacy. PFL is efficient for models, such as\nneural networks, that have a fixed number of parameters, and thus a\nfixed-dimensional gradient vector. Such models include neural-net language\nmodels, but not tokenizers, the topic of this work. Training a tokenizer\nrequires frequencies of words from an unlimited vocabulary, and existing\nmethods for finding an unlimited vocabulary need a separate privacy budget.\n  A workaround is to train the tokenizer on publicly available data. However,\nin this paper we first show that a tokenizer trained on mismatched data results\nin worse model performance compared to a privacy-violating \"oracle\" tokenizer\nthat accesses user data, with perplexity increasing by 20%. We also show that\nsub-word tokenizers are better suited to the federated context than word-level\nones, since they can encode new words, though with more tokens per word.\n  Second, we propose a novel method to obtain a tokenizer without using any\nadditional privacy budget. During private federated learning of the language\nmodel, we sample from the model, train a new tokenizer on the sampled\nsequences, and update the model embeddings. We then continue private federated\nlearning, and obtain performance within 1% of the \"oracle\" tokenizer. Since\nthis process trains the tokenizer only indirectly on private data, we can use\nthe \"postprocessing guarantee\" of differential privacy and thus use no\nadditional privacy budget.\n",
                "链接": "https://arxiv.org/abs/2203.09943"
            },
            {
                "文章ID": "45905",
                "标题": "Using Context-to-Vector with Graph Retrofitting to Improve Word\n  Embeddings",
                "作者": " Jiangbin Zheng,  Yile Wang,  Ge Wang,  Jun Xia,  Yufei Huang,  Guojiang Zhao,  Yue Zhang,  Stan Z. Li",
                "发布日期": "2023-03-24",
                "摘要": "  Although contextualized embeddings generated from large-scale pre-trained\nmodels perform well in many tasks, traditional static embeddings (e.g.,\nSkip-gram, Word2Vec) still play an important role in low-resource and\nlightweight settings due to their low computational cost, ease of deployment,\nand stability. In this paper, we aim to improve word embeddings by 1)\nincorporating more contextual information from existing pre-trained models into\nthe Skip-gram framework, which we call Context-to-Vec; 2) proposing a\npost-processing retrofitting method for static embeddings independent of\ntraining by employing priori synonym knowledge and weighted vector\ndistribution. Through extrinsic and intrinsic tasks, our methods are well\nproven to outperform the baselines by a large margin.\n",
                "链接": "https://arxiv.org/abs/2210.16848"
            },
            {
                "文章ID": "53258",
                "标题": "RPN: A Word Vector Level Data Augmentation Algorithm in Deep Learning\n  for Language Understanding",
                "作者": " Zhengqing Yuan,  Xiaolong Zhang,  Yue Wang,  Xuecong Hou,  Huiwen Xue,  Zhuanzhe Zhao,  Yongming Liu",
                "发布日期": "2023-07-06",
                "摘要": "  Data augmentation is a widely used technique in machine learning to improve\nmodel performance. However, existing data augmentation techniques in natural\nlanguage understanding (NLU) may not fully capture the complexity of natural\nlanguage variations, and they can be challenging to apply to large datasets.\nThis paper proposes the Random Position Noise (RPN) algorithm, a novel data\naugmentation technique that operates at the word vector level. RPN modifies the\nword embeddings of the original text by introducing noise based on the existing\nvalues of selected word vectors, allowing for more fine-grained modifications\nand better capturing natural language variations. Unlike traditional data\naugmentation methods, RPN does not require gradients in the computational graph\nduring virtual sample updates, making it simpler to apply to large datasets.\nExperimental results demonstrate that RPN consistently outperforms existing\ndata augmentation techniques across various NLU tasks, including sentiment\nanalysis, natural language inference, and paraphrase detection. Moreover, RPN\nperforms well in low-resource settings and is applicable to any model featuring\na word embeddings layer. The proposed RPN algorithm is a promising approach for\nenhancing NLU performance and addressing the challenges associated with\ntraditional data augmentation techniques in large-scale NLU tasks. Our\nexperimental results demonstrated that the RPN algorithm achieved\nstate-of-the-art performance in all seven NLU tasks, thereby highlighting its\neffectiveness and potential for real-world NLU applications.\n",
                "链接": "https://arxiv.org/abs/2212.05961"
            },
            {
                "文章ID": "32973",
                "标题": "The Analysis about Building Cross-lingual Sememe Knowledge Base Based on\n  Deep Clustering Network",
                "作者": " Xiaoran Li,  Toshiaki Takano",
                "发布日期": "2022-08-11",
                "摘要": "  A sememe is defined as the minimum semantic unit of human languages. Sememe\nknowledge bases (KBs), which contain words annotated with sememes, have been\nsuccessfully applied to many NLP tasks, and we believe that by learning the\nsmallest unit of meaning, computers can more easily understand human language.\nHowever, Existing sememe KBs are built on only manual annotation, human\nannotations have personal understanding biases, and the meaning of vocabulary\nwill be constantly updated and changed with the times, and artificial methods\nare not always practical. To address the issue, we propose an unsupervised\nmethod based on a deep clustering network (DCN) to build a sememe KB, and you\ncan use any language to build a KB through this method. We first learn the\ndistributed representation of multilingual words, use MUSE to align them in a\nsingle vector space, learn the multi-layer meaning of each word through the\nself-attention mechanism, and use a DNC to cluster sememe features. Finally, we\ncompleted the prediction using only the 10-dimensional sememe space in English.\nWe found that the low-dimensional space can still retain the main feature of\nthe sememes.\n",
                "链接": "https://arxiv.org/abs/2208.05462"
            },
            {
                "文章ID": "33033",
                "标题": "Word-Embeddings Distinguish Denominal and Root-Derived Verbs in Semitic",
                "作者": "MIT  Ido Benbaji, MIT  Omri Doron, MIT  Adèle Hénot-Mortier",
                "发布日期": "2022-08-12",
                "摘要": "  Proponents of the Distributed Morphology framework have posited the existence\nof two levels of morphological word formation: a lower one, leading to loose\ninput-output semantic relationships; and an upper one, leading to tight\ninput-output semantic relationships. In this work, we propose to test the\nvalidity of this assumption in the context of Hebrew word embeddings. If the\ntwo-level hypothesis is borne out, we expect state-of-the-art Hebrew word\nembeddings to encode (1) a noun, (2) a denominal derived from it (via an\nupper-level operation), and (3) a verb related to the noun (via a lower-level\noperation on the noun's root), in such a way that the denominal (2) should be\ncloser in the embedding space to the noun (1) than the related verb (3) is to\nthe same noun (1). We report that this hypothesis is verified by four embedding\nmodels of Hebrew: fastText, GloVe, Word2Vec and AlephBERT. This suggests that\nword embedding models are able to capture complex and fine-grained semantic\nproperties that are morphologically motivated.\n",
                "链接": "https://arxiv.org/abs/2208.05721"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下nips 2023 paper list",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "36791",
                "标题": "An Improved Algorithm For Online Min-Sum Set Cover",
                "作者": " Marcin Bienkowski,  Marcin Mucha",
                "发布日期": "2023-03-28",
                "摘要": "  We study a fundamental model of online preference aggregation, where an\nalgorithm maintains an ordered list of $n$ elements. An input is a stream of\npreferred sets $R_1, R_2, \\dots, R_t, \\dots$. Upon seeing $R_t$ and without\nknowledge of any future sets, an algorithm has to rerank elements (change the\nlist ordering), so that at least one element of $R_t$ is found near the list\nfront. The incurred cost is a sum of the list update costs (the number of swaps\nof neighboring list elements) and access costs (position of the first element\nof $R_t$ on the list). This scenario occurs naturally in applications such as\nordering items in an online shop using aggregated preferences of shop\ncustomers. The theoretical underpinning of this problem is known as Min-Sum Set\nCover.\n  Unlike previous work (Fotakis et al., ICALP 2020, NIPS 2020) that mostly\nstudied the performance of an online algorithm ALG against the static optimal\nsolution (a single optimal list ordering), in this paper, we study an arguably\nharder variant where the benchmark is the provably stronger optimal dynamic\nsolution OPT (that may also modify the list ordering). In terms of an online\nshop, this means that the aggregated preferences of its user base evolve with\ntime. We construct a computationally efficient randomized algorithm whose\ncompetitive ratio (ALG-to-OPT cost ratio) is $O(r^2)$ and prove the existence\nof a deterministic $O(r^4)$-competitive algorithm. Here, $r$ is the maximum\ncardinality of sets $R_t$. This is the first algorithm whose ratio does not\ndepend on $n$: the previously best algorithm for this problem was $O(r^{3/2}\n\\cdot \\sqrt{n})$-competitive and $\\Omega(r)$ is a lower bound on the\nperformance of any deterministic online algorithm.\n",
                "链接": "https://arxiv.org/abs/2209.04870"
            },
            {
                "文章ID": "84628",
                "标题": "Overview of the Problem List Summarization (ProbSum) 2023 Shared Task on\n  Summarizing Patients' Active Diagnoses and Problems from Electronic Health\n  Record Progress Notes",
                "作者": " Yanjun Gao,  Dmitriy Dligach,  Timothy Miller,  Matthew M. Churpek,  Majid Afshar",
                "发布日期": "2023-06-09",
                "摘要": "  The BioNLP Workshop 2023 initiated the launch of a shared task on Problem\nList Summarization (ProbSum) in January 2023. The aim of this shared task is to\nattract future research efforts in building NLP models for real-world\ndiagnostic decision support applications, where a system generating relevant\nand accurate diagnoses will augment the healthcare providers decision-making\nprocess and improve the quality of care for patients. The goal for participants\nis to develop models that generated a list of diagnoses and problems using\ninput from the daily care notes collected from the hospitalization of\ncritically ill patients. Eight teams submitted their final systems to the\nshared task leaderboard. In this paper, we describe the tasks, datasets,\nevaluation metrics, and baseline systems. Additionally, the techniques and\nresults of the evaluation of the different approaches tried by the\nparticipating teams are summarized.\n",
                "链接": "https://arxiv.org/abs/2306.05270"
            },
            {
                "文章ID": "83654",
                "标题": "PULSAR: Pre-training with Extracted Healthcare Terms for Summarising\n  Patients' Problems and Data Augmentation with Black-box Large Language Models",
                "作者": " Hao Li,  Yuping Wu,  Viktor Schlegel,  Riza Batista-Navarro,  Thanh-Tung Nguyen,  Abhinav Ramesh Kashyap,  Xiaojun Zeng,  Daniel Beck,  Stefan Winkler,  Goran Nenadic",
                "发布日期": "2023-06-06",
                "摘要": "  Medical progress notes play a crucial role in documenting a patient's\nhospital journey, including his or her condition, treatment plan, and any\nupdates for healthcare providers. Automatic summarisation of a patient's\nproblems in the form of a problem list can aid stakeholders in understanding a\npatient's condition, reducing workload and cognitive bias. BioNLP 2023 Shared\nTask 1A focuses on generating a list of diagnoses and problems from the\nprovider's progress notes during hospitalisation. In this paper, we introduce\nour proposed approach to this task, which integrates two complementary\ncomponents. One component employs large language models (LLMs) for data\naugmentation; the other is an abstractive summarisation LLM with a novel\npre-training objective for generating the patients' problems summarised as a\nlist. Our approach was ranked second among all submissions to the shared task.\nThe performance of our model on the development and test datasets shows that\nour approach is more robust on unknown data, with an improvement of up to 3.1\npoints over the same size of the larger model.\n",
                "链接": "https://arxiv.org/abs/2306.02754"
            },
            {
                "文章ID": "84651",
                "标题": "CUED at ProbSum 2023: Hierarchical Ensemble of Summarization Models",
                "作者": " Potsawee Manakul,  Yassir Fathullah,  Adian Liusie,  Vyas Raina,  Vatsal Raina,  Mark Gales",
                "发布日期": "2023-06-09",
                "摘要": "  In this paper, we consider the challenge of summarizing patients' medical\nprogress notes in a limited data setting. For the Problem List Summarization\n(shared task 1A) at the BioNLP Workshop 2023, we demonstrate that Clinical-T5\nfine-tuned to 765 medical clinic notes outperforms other extractive,\nabstractive and zero-shot baselines, yielding reasonable baseline systems for\nmedical note summarization. Further, we introduce Hierarchical Ensemble of\nSummarization Models (HESM), consisting of token-level ensembles of diverse\nfine-tuned Clinical-T5 models, followed by Minimum Bayes Risk (MBR) decoding.\nOur HESM approach lead to a considerable summarization performance boost, and\nwhen evaluated on held-out challenge data achieved a ROUGE-L of 32.77, which\nwas the best-performing system at the top of the shared task leaderboard.\n",
                "链接": "https://arxiv.org/abs/2306.05317"
            },
            {
                "文章ID": "110962",
                "标题": "MEMPSEP III. A machine learning-oriented multivariate data set for\n  forecasting the Occurrence and Properties of Solar Energetic Particle Events\n  using a Multivariate Ensemble Approach",
                "作者": " Kimberly Moreland,  Maher Dayeh,  Hazel M. Bain,  Subhamoy Chatterjee,  Andres Munoz-Jaramillo,  Samuel Hart",
                "发布日期": "2023-10-30",
                "摘要": "  We introduce a new multivariate data set that utilizes multiple spacecraft\ncollecting in-situ and remote sensing heliospheric measurements shown to be\nlinked to physical processes responsible for generating solar energetic\nparticles (SEPs). Using the Geostationary Operational Environmental Satellites\n(GOES) flare event list from Solar Cycle (SC) 23 and part of SC 24 (1998-2013),\nwe identify 252 solar events (flares) that produce SEPs and 17,542 events that\ndo not. For each identified event, we acquire the local plasma properties at 1\nau, such as energetic proton and electron data, upstream solar wind conditions,\nand the interplanetary magnetic field vector quantities using various\ninstruments onboard GOES and the Advanced Composition Explorer (ACE)\nspacecraft. We also collect remote sensing data from instruments onboard the\nSolar Dynamic Observatory (SDO), Solar and Heliospheric Observatory (SoHO), and\nthe Wind solar radio instrument WAVES. The data set is designed to allow for\nvariations of the inputs and feature sets for machine learning (ML) in\nheliophysics and has a specific purpose for forecasting the occurrence of SEP\nevents and their subsequent properties. This paper describes a dataset created\nfrom multiple publicly available observation sources that is validated,\ncleaned, and carefully curated for our machine-learning pipeline. The dataset\nhas been used to drive the newly-developed Multivariate Ensemble of Models for\nProbabilistic Forecast of Solar Energetic Particles (MEMPSEP; see MEMPSEP I\n(Chatterjee et al., 2023) and MEMPSEP II (Dayeh et al., 2023) for associated\npapers).\n",
                "链接": "https://arxiv.org/abs/2310.15390"
            },
            {
                "文章ID": "101187",
                "标题": "Transformers in Small Object Detection: A Benchmark and Survey of\n  State-of-the-Art",
                "作者": " Aref Miri Rekavandi,  Shima Rashidi,  Farid Boussaid,  Stephen Hoefs,  Emre Akbas,  Mohammed bennamoun",
                "发布日期": "2023-09-12",
                "摘要": "  Transformers have rapidly gained popularity in computer vision, especially in\nthe field of object recognition and detection. Upon examining the outcomes of\nstate-of-the-art object detection methods, we noticed that transformers\nconsistently outperformed well-established CNN-based detectors in almost every\nvideo or image dataset. While transformer-based approaches remain at the\nforefront of small object detection (SOD) techniques, this paper aims to\nexplore the performance benefits offered by such extensive networks and\nidentify potential reasons for their SOD superiority. Small objects have been\nidentified as one of the most challenging object types in detection frameworks\ndue to their low visibility. We aim to investigate potential strategies that\ncould enhance transformers' performance in SOD. This survey presents a taxonomy\nof over 60 research studies on developed transformers for the task of SOD,\nspanning the years 2020 to 2023. These studies encompass a variety of detection\napplications, including small object detection in generic images, aerial\nimages, medical images, active millimeter images, underwater images, and\nvideos. We also compile and present a list of 12 large-scale datasets suitable\nfor SOD that were overlooked in previous studies and compare the performance of\nthe reviewed studies using popular metrics such as mean Average Precision\n(mAP), Frames Per Second (FPS), number of parameters, and more. Researchers can\nkeep track of newer studies on our web page, which is available at\n\\url{https://github.com/arekavandi/Transformer-SOD}.\n",
                "链接": "https://arxiv.org/abs/2309.04902"
            },
            {
                "文章ID": "111753",
                "标题": "Skill-Mix: a Flexible and Expandable Family of Evaluations for AI models",
                "作者": " Dingli Yu,  Simran Kaur,  Arushi Gupta,  Jonah Brown-Cohen,  Anirudh Goyal,  Sanjeev Arora",
                "发布日期": "2023-10-27",
                "摘要": "  With LLMs shifting their role from statistical modeling of language to\nserving as general-purpose AI agents, how should LLM evaluations change?\nArguably, a key ability of an AI agent is to flexibly combine, as needed, the\nbasic skills it has learned. The capability to combine skills plays an\nimportant role in (human) pedagogy and also in a paper on emergence phenomena\n(Arora & Goyal, 2023).\n  This work introduces Skill-Mix, a new evaluation to measure ability to\ncombine skills. Using a list of $N$ skills the evaluator repeatedly picks\nrandom subsets of $k$ skills and asks the LLM to produce text combining that\nsubset of skills. Since the number of subsets grows like $N^k$, for even modest\n$k$ this evaluation will, with high probability, require the LLM to produce\ntext significantly different from any text in the training set. The paper\ndevelops a methodology for (a) designing and administering such an evaluation,\nand (b) automatic grading (plus spot-checking by humans) of the results using\nGPT-4 as well as the open LLaMA-2 70B model.\n  Administering a version of to popular chatbots gave results that, while\ngenerally in line with prior expectations, contained surprises. Sizeable\ndifferences exist among model capabilities that are not captured by their\nranking on popular LLM leaderboards (\"cramming for the leaderboard\").\nFurthermore, simple probability calculations indicate that GPT-4's reasonable\nperformance on $k=5$ is suggestive of going beyond \"stochastic parrot\" behavior\n(Bender et al., 2021), i.e., it combines skills in ways that it had not seen\nduring training.\n  We sketch how the methodology can lead to a Skill-Mix based eco-system of\nopen evaluations for AI capabilities of future models.\n",
                "链接": "https://arxiv.org/abs/2310.17567"
            }
        ]
    },
    {
        "question": {
            "question": "请列出近一年来工业界发表的搜广推工作落地实践的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "85487",
                "标题": "Practice with Graph-based ANN Algorithms on Sparse Data: Chi-square\n  Two-tower model, HNSW, Sign Cauchy Projections",
                "作者": " Ping Li,  Weijie Zhao,  Chao Wang,  Qi Xia,  Alice Wu,  Lijun Peng",
                "发布日期": "2023-06-14",
                "摘要": "  Sparse data are common. The traditional ``handcrafted'' features are often\nsparse. Embedding vectors from trained models can also be very sparse, for\nexample, embeddings trained via the ``ReLu'' activation function. In this\npaper, we report our exploration of efficient search in sparse data with\ngraph-based ANN algorithms (e.g., HNSW, or SONG which is the GPU version of\nHNSW), which are popular in industrial practice, e.g., search and ads\n(advertising).\n  We experiment with the proprietary ads targeting application, as well as\nbenchmark public datasets. For ads targeting, we train embeddings with the\nstandard ``cosine two-tower'' model and we also develop the ``chi-square\ntwo-tower'' model. Both models produce (highly) sparse embeddings when they are\nintegrated with the ``ReLu'' activation function. In EBR (embedding-based\nretrieval) applications, after we the embeddings are trained, the next crucial\ntask is the approximate near neighbor (ANN) search for serving. While there are\nmany ANN algorithms we can choose from, in this study, we focus on the\ngraph-based ANN algorithm (e.g., HNSW-type).\n  Sparse embeddings should help improve the efficiency of EBR. One benefit is\nthe reduced memory cost for the embeddings. The other obvious benefit is the\nreduced computational time for evaluating similarities, because, for\ngraph-based ANN algorithms such as HNSW, computing similarities is often the\ndominating cost. In addition to the effort on leveraging data sparsity for\nstorage and computation, we also integrate ``sign cauchy random projections''\n(SignCRP) to hash vectors to bits, to further reduce the memory cost and speed\nup the ANN search. In NIPS'13, SignCRP was proposed to hash the chi-square\nsimilarity, which is a well-adopted nonlinear kernel in NLP and computer\nvision. Therefore, the chi-square two-tower model, SignCRP, and HNSW are now\ntightly integrated.\n",
                "链接": "https://arxiv.org/abs/2306.07607"
            },
            {
                "文章ID": "71518",
                "标题": "Delving into E-Commerce Product Retrieval with Vision-Language\n  Pre-training",
                "作者": " Xiaoyang Zheng,  Fuyu Lv,  Zilong Wang,  Qingwen Liu,  Xiaoyi Zeng",
                "发布日期": "2023-04-18",
                "摘要": "  E-commerce search engines comprise a retrieval phase and a ranking phase,\nwhere the first one returns a candidate product set given user queries.\nRecently, vision-language pre-training, combining textual information with\nvisual clues, has been popular in the application of retrieval tasks. In this\npaper, we propose a novel V+L pre-training method to solve the retrieval\nproblem in Taobao Search. We design a visual pre-training task based on\ncontrastive learning, outperforming common regression-based visual pre-training\ntasks. In addition, we adopt two negative sampling schemes, tailored for the\nlarge-scale retrieval task. Besides, we introduce the details of the online\ndeployment of our proposed method in real-world situations. Extensive\noffline/online experiments demonstrate the superior performance of our method\non the retrieval task. Our proposed method is employed as one retrieval channel\nof Taobao Search and serves hundreds of millions of users in real time.\n",
                "链接": "https://arxiv.org/abs/2304.04377"
            },
            {
                "文章ID": "84452",
                "标题": "Unified Embedding Based Personalized Retrieval in Etsy Search",
                "作者": " Rishikesh Jha,  Siddharth Subramaniyam,  Ethan Benjamin,  Thrivikrama Taula",
                "发布日期": "2023-06-09",
                "摘要": "  Embedding-based neural retrieval is a prevalent approach to address the\nsemantic gap problem which often arises in product search on tail queries. In\ncontrast, popular queries typically lack context and have a broad intent where\nadditional context from users historical interaction can be helpful. In this\npaper, we share our novel approach to address both: the semantic gap problem\nfollowed by an end to end trained model for personalized semantic retrieval. We\npropose learning a unified embedding model incorporating graph, transformer and\nterm-based embeddings end to end and share our design choices for optimal\ntradeoff between performance and efficiency. We share our learnings in feature\nengineering, hard negative sampling strategy, and application of transformer\nmodel, including a novel pre-training strategy and other tricks for improving\nsearch relevance and deploying such a model at industry scale. Our personalized\nretrieval model significantly improves the overall search experience, as\nmeasured by a 5.58% increase in search purchase rate and a 2.63% increase in\nsite-wide conversion rate, aggregated across multiple A/B tests - on live\ntraffic.\n",
                "链接": "https://arxiv.org/abs/2306.04833"
            },
            {
                "文章ID": "60182",
                "标题": "Recommender Systems: A Primer",
                "作者": " Pablo Castells,  Dietmar Jannach",
                "发布日期": "2023-02-07",
                "摘要": "  Personalized recommendations have become a common feature of modern online\nservices, including most major e-commerce sites, media platforms and social\nnetworks. Today, due to their high practical relevance, research in the area of\nrecommender systems is flourishing more than ever. However, with the new\napplication scenarios of recommender systems that we observe today, constantly\nnew challenges arise as well, both in terms of algorithmic requirements and\nwith respect to the evaluation of such systems. In this paper, we first provide\nan overview of the traditional formulation of the recommendation problem. We\nthen review the classical algorithmic paradigms for item retrieval and ranking\nand elaborate how such systems can be evaluated. Afterwards, we discuss a\nnumber of recent developments in recommender systems research, including\nresearch on session-based recommendation, biases in recommender systems, and\nquestions regarding the impact and value of recommender systems in practice.\n",
                "链接": "https://arxiv.org/abs/2302.02579"
            },
            {
                "文章ID": "83899",
                "标题": "Computational Technologies for Fashion Recommendation: A Survey",
                "作者": " Yujuan Ding,  Zhihui Lai,  P. Y. Mok,  Tat-Seng Chua",
                "发布日期": "2023-10-31",
                "摘要": "  Fashion recommendation is a key research field in computational fashion\nresearch and has attracted considerable interest in the computer vision,\nmultimedia, and information retrieval communities in recent years. Due to the\ngreat demand for applications, various fashion recommendation tasks, such as\npersonalized fashion product recommendation, complementary (mix-and-match)\nrecommendation, and outfit recommendation, have been posed and explored in the\nliterature. The continuing research attention and advances impel us to look\nback and in-depth into the field for a better understanding. In this paper, we\ncomprehensively review recent research efforts on fashion recommendation from a\ntechnological perspective. We first introduce fashion recommendation at a macro\nlevel and analyse its characteristics and differences with general\nrecommendation tasks. We then clearly categorize different fashion\nrecommendation efforts into several sub-tasks and focus on each sub-task in\nterms of its problem formulation, research focus, state-of-the-art methods, and\nlimitations. We also summarize the datasets proposed in the literature for use\nin fashion recommendation studies to give readers a brief illustration.\nFinally, we discuss several promising directions for future research in this\nfield. Overall, this survey systematically reviews the development of fashion\nrecommendation research. It also discusses the current limitations and gaps\nbetween academic research and the real needs of the fashion industry. In the\nprocess, we offer a deep insight into how the fashion industry could benefit\nfrom the computational technologies of fashion recommendation.\n",
                "链接": "https://arxiv.org/abs/2306.03395"
            },
            {
                "文章ID": "119044",
                "标题": "Transformer-empowered Multi-modal Item Embedding for Enhanced Image\n  Search in E-Commerce",
                "作者": " Chang Liu,  Peng Hou,  Anxiang Zeng,  Han Yu",
                "发布日期": "2023-12-01",
                "摘要": "  Over the past decade, significant advances have been made in the field of\nimage search for e-commerce applications. Traditional image-to-image retrieval\nmodels, which focus solely on image details such as texture, tend to overlook\nuseful semantic information contained within the images. As a result, the\nretrieved products might possess similar image details, but fail to fulfil the\nuser's search goals. Moreover, the use of image-to-image retrieval models for\nproducts containing multiple images results in significant online product\nfeature storage overhead and complex mapping implementations. In this paper, we\nreport the design and deployment of the proposed Multi-modal Item Embedding\nModel (MIEM) to address these limitations. It is capable of utilizing both\ntextual information and multiple images about a product to construct meaningful\nproduct features. By leveraging semantic information from images, MIEM\neffectively supplements the image search process, improving the overall\naccuracy of retrieval results. MIEM has become an integral part of the Shopee\nimage search platform. Since its deployment in March 2023, it has achieved a\nremarkable 9.90% increase in terms of clicks per user and a 4.23% boost in\nterms of orders per user for the image search feature on the Shopee e-commerce\nplatform.\n",
                "链接": "https://arxiv.org/abs/2311.17954"
            },
            {
                "文章ID": "73784",
                "标题": "(Vector) Space is Not the Final Frontier: Product Search as Program\n  Synthesis",
                "作者": " Jacopo Tagliabue,  Ciro Greco",
                "发布日期": "2023-06-13",
                "摘要": "  As ecommerce continues growing, huge investments in ML and NLP for\nInformation Retrieval are following. While the vector space model dominated\nretrieval modelling in product search - even as vectorization itself greatly\nchanged with the advent of deep learning -, our position paper argues in a\ncontrarian fashion that program synthesis provides significant advantages for\nmany queries and a significant number of players in the market. We detail the\nindustry significance of the proposed approach, sketch implementation details,\nand address common objections drawing from our experience building a similar\nsystem at Tooso.\n",
                "链接": "https://arxiv.org/abs/2304.11473"
            },
            {
                "文章ID": "66507",
                "标题": "Efficient Image-Text Retrieval via Keyword-Guided Pre-Screening",
                "作者": " Min Cao,  Yang Bai,  Jingyao Wang,  Ziqiang Cao,  Liqiang Nie,  Min Zhang",
                "发布日期": "2023-03-15",
                "摘要": "  Under the flourishing development in performance, current image-text\nretrieval methods suffer from $N$-related time complexity, which hinders their\napplication in practice. Targeting at efficiency improvement, this paper\npresents a simple and effective keyword-guided pre-screening framework for the\nimage-text retrieval. Specifically, we convert the image and text data into the\nkeywords and perform the keyword matching across modalities to exclude a large\nnumber of irrelevant gallery samples prior to the retrieval network. For the\nkeyword prediction, we transfer it into a multi-label classification problem\nand propose a multi-task learning scheme by appending the multi-label\nclassifiers to the image-text retrieval network to achieve a lightweight and\nhigh-performance keyword prediction. For the keyword matching, we introduce the\ninverted index in the search engine and create a win-win situation on both time\nand space complexities for the pre-screening. Extensive experiments on two\nwidely-used datasets, i.e., Flickr30K and MS-COCO, verify the effectiveness of\nthe proposed framework. The proposed framework equipped with only two embedding\nlayers achieves $O(1)$ querying time complexity, while improving the retrieval\nefficiency and keeping its performance, when applied prior to the common\nimage-text retrieval methods. Our code will be released.\n",
                "链接": "https://arxiv.org/abs/2303.07740"
            },
            {
                "文章ID": "112826",
                "标题": "Overview of LiLAS 2020 -- Living Labs for Academic Search",
                "作者": " Philipp Schaer,  Johann Schaible,  Leyla Jael Garcia Castro",
                "发布日期": "2023-11-01",
                "摘要": "  Academic Search is a timeless challenge that the field of Information\nRetrieval has been dealing with for many years. Even today, the search for\nacademic material is a broad field of research that recently started working on\nproblems like the COVID-19 pandemic. However, test collections and specialized\ndata sets like CORD-19 only allow for system-oriented experiments, while the\nevaluation of algorithms in real-world environments is only available to\nresearchers from industry. In LiLAS, we open up two academic search platforms\nto allow participating research to evaluate their systems in a Docker-based\nresearch environment. This overview paper describes the motivation,\ninfrastructure, and two systems LIVIVO and GESIS Search that are part of this\nCLEF lab.\n",
                "链接": "https://arxiv.org/abs/2310.20387"
            },
            {
                "文章ID": "64204",
                "标题": "OmniForce: On Human-Centered, Large Model Empowered and Cloud-Edge\n  Collaborative AutoML System",
                "作者": " Chao Xue,  Wei Liu,  Shuai Xie,  Zhenfang Wang,  Jiaxing Li,  Xuyang Peng,  Liang Ding,  Shanshan Zhao,  Qiong Cao,  Yibo Yang,  Fengxiang He,  Bohua Cai,  Rongcheng Bian,  Yiyan Zhao,  Heliang Zheng,  Xiangyang Liu,  Dongkai Liu,  Daqing Liu,  Li Shen,  Chang Li,  Shijin Zhang,  Yukang Zhang,  Guanpu Chen,  Shixiang Chen,  Yibing Zhan,  Jing Zhang,  Chaoyue Wang,  Dacheng Tao",
                "发布日期": "2023-07-11",
                "摘要": "  Automated machine learning (AutoML) seeks to build ML models with minimal\nhuman effort. While considerable research has been conducted in the area of\nAutoML in general, aiming to take humans out of the loop when building\nartificial intelligence (AI) applications, scant literature has focused on how\nAutoML works well in open-environment scenarios such as the process of training\nand updating large models, industrial supply chains or the industrial\nmetaverse, where people often face open-loop problems during the search\nprocess: they must continuously collect data, update data and models, satisfy\nthe requirements of the development and deployment environment, support massive\ndevices, modify evaluation metrics, etc. Addressing the open-environment issue\nwith pure data-driven approaches requires considerable data, computing\nresources, and effort from dedicated data engineers, making current AutoML\nsystems and platforms inefficient and computationally intractable.\nHuman-computer interaction is a practical and feasible way to tackle the\nproblem of open-environment AI. In this paper, we introduce OmniForce, a\nhuman-centered AutoML (HAML) system that yields both human-assisted ML and\nML-assisted human techniques, to put an AutoML system into practice and build\nadaptive AI in open-environment scenarios. Specifically, we present OmniForce\nin terms of ML version management; pipeline-driven development and deployment\ncollaborations; a flexible search strategy framework; and widely provisioned\nand crowdsourced application algorithms, including large models. Furthermore,\nthe (large) models constructed by OmniForce can be automatically turned into\nremote services in a few minutes; this process is dubbed model as a service\n(MaaS). Experimental results obtained in multiple search spaces and real-world\nuse cases demonstrate the efficacy and efficiency of OmniForce.\n",
                "链接": "https://arxiv.org/abs/2303.00501"
            }
        ]
    },
    {
        "question": {
            "question": "闭源大模型用户数据隐私保护研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "106181",
                "标题": "Large Language Models Can Be Good Privacy Protection Learners",
                "作者": " Yijia Xiao,  Yiqiao Jin,  Yushi Bai,  Yue Wu,  Xianjun Yang,  Xiao Luo,  Wenchao Yu,  Xujiang Zhao,  Yanchi Liu,  Haifeng Chen,  Wei Wang,  Wei Cheng",
                "发布日期": "2023-10-10",
                "摘要": "  The proliferation of Large Language Models (LLMs) has driven considerable\ninterest in fine-tuning them with domain-specific data to create specialized\nlanguage models. Nevertheless, such domain-specific fine-tuning data often\ncontains sensitive personally identifiable information (PII). Direct\nfine-tuning LLMs on this data without privacy protection poses a risk of\nleakage. To address this challenge, we introduce Privacy Protection Language\nModels (PPLM), a novel paradigm for fine-tuning LLMs that effectively injects\ndomain-specific knowledge while safeguarding data privacy. Our work offers a\ntheoretical analysis for model design and delves into various techniques such\nas corpus curation, penalty-based unlikelihood in training loss, and\ninstruction-based tuning, etc. Extensive experiments across diverse datasets\nand scenarios demonstrate the effectiveness of our approaches. In particular,\ninstruction tuning with both positive and negative examples, stands out as a\npromising method, effectively protecting private data while enhancing the\nmodel's knowledge. Our work underscores the potential for Large Language Models\nas robust privacy protection learners.\n",
                "链接": "https://arxiv.org/abs/2310.02469"
            },
            {
                "文章ID": "85712",
                "标题": "Protecting User Privacy in Remote Conversational Systems: A\n  Privacy-Preserving framework based on text sanitization",
                "作者": " Zhigang Kan,  Linbo Qiao,  Hao Yu,  Liwen Peng,  Yifu Gao,  Dongsheng Li",
                "发布日期": "2023-06-16",
                "摘要": "  Large Language Models (LLMs) are gaining increasing attention due to their\nexceptional performance across numerous tasks. As a result, the general public\nutilize them as an influential tool for boosting their productivity while\nnatural language processing researchers endeavor to employ them in solving\nexisting or new research problems. Unfortunately, individuals can only access\nsuch powerful AIs through APIs, which ultimately leads to the transmission of\nraw data to the models' providers and increases the possibility of privacy data\nleakage. Current privacy-preserving methods for cloud-deployed language models\naim to protect privacy information in the pre-training dataset or during the\nmodel training phase. However, they do not meet the specific challenges\npresented by the remote access approach of new large-scale language models.\n  This paper introduces a novel task, \"User Privacy Protection for Dialogue\nModels,\" which aims to safeguard sensitive user information from any possible\ndisclosure while conversing with chatbots. We also present an evaluation scheme\nfor this task, which covers evaluation metrics for privacy protection, data\navailability, and resistance to simulation attacks. Moreover, we propose the\nfirst framework for this task, namely privacy protection through text\nsanitization. Before sending the input to remote large models, it filters out\nthe sensitive information, using several rounds of text sanitization based on\nprivacy types that users define. Upon receiving responses from the larger\nmodel, our framework automatically restores privacy to ensure that the\nconversation goes smoothly, without intervention from the privacy filter.\nExperiments based on real-world datasets demonstrate the efficacy of our\nprivacy-preserving approach against eavesdropping from potential attackers.\n",
                "链接": "https://arxiv.org/abs/2306.08223"
            },
            {
                "文章ID": "100632",
                "标题": "Hide and Seek (HaS): A Lightweight Framework for Prompt Privacy\n  Protection",
                "作者": " Yu Chen,  Tingxin Li,  Huiming Liu,  Yang Yu",
                "发布日期": "2023-09-07",
                "摘要": "  Numerous companies have started offering services based on large language\nmodels (LLM), such as ChatGPT, which inevitably raises privacy concerns as\nusers' prompts are exposed to the model provider. Previous research on secure\nreasoning using multi-party computation (MPC) has proven to be impractical for\nLLM applications due to its time-consuming and communication-intensive nature.\nWhile lightweight anonymization techniques can protect private information in\nprompts through substitution or masking, they fail to recover sensitive data\nreplaced in the LLM-generated results. In this paper, we expand the application\nscenarios of anonymization techniques by training a small local model to\nde-anonymize the LLM's returned results with minimal computational overhead. We\nintroduce the HaS framework, where \"H(ide)\" and \"S(eek)\" represent its two core\nprocesses: hiding private entities for anonymization and seeking private\nentities for de-anonymization, respectively. To quantitatively assess HaS's\nprivacy protection performance, we propose both black-box and white-box\nadversarial models. Furthermore, we conduct experiments to evaluate HaS's\nusability in translation and classification tasks. The experimental findings\ndemonstrate that the HaS framework achieves an optimal balance between privacy\nprotection and utility.\n",
                "链接": "https://arxiv.org/abs/2309.03057"
            },
            {
                "文章ID": "59863",
                "标题": "Private, fair and accurate: Training large-scale, privacy-preserving AI\n  models in medical imaging",
                "作者": " Soroosh Tayebi Arasteh,  Alexander Ziller,  Christiane Kuhl,  Marcus Makowski,  Sven Nebelung,  Rickmer Braren,  Daniel Rueckert,  Daniel Truhn,  Georgios Kaissis",
                "发布日期": "2023-03-08",
                "摘要": "  Artificial intelligence (AI) models are increasingly used in the medical\ndomain. However, as medical data is highly sensitive, special precautions to\nensure its protection are required. The gold standard for privacy preservation\nis the introduction of differential privacy (DP) to model training. Prior work\nindicates that DP has negative implications on model accuracy and fairness,\nwhich are unacceptable in medicine and represent a main barrier to the\nwidespread use of privacy-preserving techniques. In this work, we evaluated the\neffect of privacy-preserving training of AI models for chest radiograph\ndiagnosis regarding accuracy and fairness compared to non-private training. For\nthis, we used a large dataset (N=193,311) of high quality clinical chest\nradiographs, which were retrospectively collected and manually labeled by\nexperienced radiologists. We then compared non-private deep convolutional\nneural networks (CNNs) and privacy-preserving (DP) models with respect to\nprivacy-utility trade-offs measured as area under the\nreceiver-operator-characteristic curve (AUROC), and privacy-fairness\ntrade-offs, measured as Pearson's r or Statistical Parity Difference. We found\nthat the non-private CNNs achieved an average AUROC score of 0.90 +- 0.04 over\nall labels, whereas the DP CNNs with a privacy budget of epsilon=7.89 resulted\nin an AUROC of 0.87 +- 0.04, i.e., a mere 2.6% performance decrease compared to\nnon-private training. Furthermore, we found the privacy-preserving training not\nto amplify discrimination against age, sex or co-morbidity. Our study shows\nthat -- under the challenging realistic circumstances of a real-life clinical\ndataset -- the privacy-preserving training of diagnostic deep learning models\nis possible with excellent diagnostic accuracy and fairness.\n",
                "链接": "https://arxiv.org/abs/2302.01622"
            },
            {
                "文章ID": "101319",
                "标题": "Diff-Privacy: Diffusion-based Face Privacy Protection",
                "作者": " Xiao He,  Mingrui Zhu,  Dongxin Chen,  Nannan Wang,  Xinbo Gao",
                "发布日期": "2023-09-12",
                "摘要": "  Privacy protection has become a top priority as the proliferation of AI\ntechniques has led to widespread collection and misuse of personal data.\nAnonymization and visual identity information hiding are two important facial\nprivacy protection tasks that aim to remove identification characteristics from\nfacial images at the human perception level. However, they have a significant\ndifference in that the former aims to prevent the machine from recognizing\ncorrectly, while the latter needs to ensure the accuracy of machine\nrecognition. Therefore, it is difficult to train a model to complete these two\ntasks simultaneously. In this paper, we unify the task of anonymization and\nvisual identity information hiding and propose a novel face privacy protection\nmethod based on diffusion models, dubbed Diff-Privacy. Specifically, we train\nour proposed multi-scale image inversion module (MSI) to obtain a set of SDM\nformat conditional embeddings of the original image. Based on the conditional\nembeddings, we design corresponding embedding scheduling strategies and\nconstruct different energy functions during the denoising process to achieve\nanonymization and visual identity information hiding. Extensive experiments\nhave been conducted to validate the effectiveness of our proposed framework in\nprotecting facial privacy.\n",
                "链接": "https://arxiv.org/abs/2309.05330"
            },
            {
                "文章ID": "111984",
                "标题": "$\\alpha$-Mutual Information: A Tunable Privacy Measure for Privacy\n  Protection in Data Sharing",
                "作者": " MirHamed Jafarzadeh Asl,  Mohammadhadi Shateri,  Fabrice Labeau",
                "发布日期": "2023-10-30",
                "摘要": "  This paper adopts Arimoto's $\\alpha$-Mutual Information as a tunable privacy\nmeasure, in a privacy-preserving data release setting that aims to prevent\ndisclosing private data to adversaries. By fine-tuning the privacy metric, we\ndemonstrate that our approach yields superior models that effectively thwart\nattackers across various performance dimensions. We formulate a general\ndistortion-based mechanism that manipulates the original data to offer privacy\nprotection. The distortion metrics are determined according to the data\nstructure of a specific experiment. We confront the problem expressed in the\nformulation by employing a general adversarial deep learning framework that\nconsists of a releaser and an adversary, trained with opposite goals. This\nstudy conducts empirical experiments on images and time-series data to verify\nthe functionality of $\\alpha$-Mutual Information. We evaluate the\nprivacy-utility trade-off of customized models and compare them to mutual\ninformation as the baseline measure. Finally, we analyze the consequence of an\nattacker's access to side information about private data and witness that\nadapting the privacy measure results in a more refined model than the\nstate-of-the-art in terms of resiliency against side information.\n",
                "链接": "https://arxiv.org/abs/2310.18241"
            },
            {
                "文章ID": "119797",
                "标题": "PAC Privacy Preserving Diffusion Models",
                "作者": " Qipan Xu,  Youlong Ding,  Jie Gao,  Hao Wang",
                "发布日期": "2023-12-05",
                "摘要": "  Data privacy protection is garnering increased attention among researchers.\nDiffusion models (DMs), particularly with strict differential privacy, can\npotentially produce images with both high privacy and visual quality. However,\nchallenges arise in ensuring robust protection in privatizing specific data\nattributes, areas where current models often fall short. To address these\nchallenges, we introduce the PAC Privacy Preserving Diffusion Model, a model\nleverages diffusion principles and ensure Probably Approximately Correct (PAC)\nprivacy. We enhance privacy protection by integrating a private classifier\nguidance into the Langevin Sampling Process. Additionally, recognizing the gap\nin measuring the privacy of models, we have developed a novel metric to gauge\nprivacy levels. Our model, assessed with this new metric and supported by\nGaussian matrix computations for the PAC bound, has shown superior performance\nin privacy protection over existing leading private generative models according\nto benchmark tests.\n",
                "链接": "https://arxiv.org/abs/2312.01201"
            },
            {
                "文章ID": "117358",
                "标题": "GeoLocator: a location-integrated large multimodal model for inferring\n  geo-privacy",
                "作者": " Yifan Yang,  Yixian Zhang,  Daoyang Li,  Shuju Sun,  Junhong Duan,  Junzhou He,  Qingyang Wu,  Hao Liu",
                "发布日期": "2023-12-15",
                "摘要": "  Geographic privacy or geo-privacy refers to the keeping private of one's\ngeographic location, especially the restriction of geographical data maintained\nby personal electronic equipment. Geo-privacy is a crucial aspect of personal\nsecurity, however often goes unnoticed in daily activities. With the surge in\nthe use of Large Multimodal Models (LMM), such as GPT-4, for Open Source\nIntelligence (OSINT), the potential risks associated with geo-privacy breaches\nhave intensified. This study develops a location-integrated GPT-4 based model\nnamed GeoLocator and designed four-dimensional experiments to demonstrate its\ncapability in inferring and identifying the locational information of input\nimageries and/or social media contents. Our experiments reveal that GeoLocator\ngenerates specific geographic details with high accuracy and consequently\nembeds the risk of the model users exposing geospatial information to the\npublic unintentionally, highlighting the thread of online data sharing,\ninformation gathering technologies and LLM on geo-privacy. We conclude with the\nbroader implications of GeoLocator and our findings for individuals and the\ncommunity at large, by emphasizing the urgency for enhanced awareness and\nprotective measures against geo-privacy leakage in the era of advanced AI and\nwidespread social media usage.\n  Keywords: geoprivacy, GPT-4, image comprehension, Large Multimodal Model\n(LMM), Open Source Intelligence (OSINT)\n",
                "链接": "https://arxiv.org/abs/2311.13018"
            },
            {
                "文章ID": "93749",
                "标题": "Shuffled Differentially Private Federated Learning for Time Series Data\n  Analytics",
                "作者": " Chenxi Huang,  Chaoyang Jiang,  Zhenghua Chen",
                "发布日期": "2023-08-01",
                "摘要": "  Trustworthy federated learning aims to achieve optimal performance while\nensuring clients' privacy. Existing privacy-preserving federated learning\napproaches are mostly tailored for image data, lacking applications for time\nseries data, which have many important applications, like machine health\nmonitoring, human activity recognition, etc. Furthermore, protective noising on\na time series data analytics model can significantly interfere with\ntemporal-dependent learning, leading to a greater decline in accuracy. To\naddress these issues, we develop a privacy-preserving federated learning\nalgorithm for time series data. Specifically, we employ local differential\nprivacy to extend the privacy protection trust boundary to the clients. We also\nincorporate shuffle techniques to achieve a privacy amplification, mitigating\nthe accuracy decline caused by leveraging local differential privacy. Extensive\nexperiments were conducted on five time series datasets. The evaluation results\nreveal that our algorithm experienced minimal accuracy loss compared to\nnon-private federated learning in both small and large client scenarios. Under\nthe same level of privacy protection, our algorithm demonstrated improved\naccuracy compared to the centralized differentially private federated learning\nin both scenarios.\n",
                "链接": "https://arxiv.org/abs/2307.16196"
            },
            {
                "文章ID": "86366",
                "标题": "CLIP2Protect: Protecting Facial Privacy using Text-Guided Makeup via\n  Adversarial Latent Search",
                "作者": " Fahad Shamshad,  Muzammal Naseer,  Karthik Nandakumar",
                "发布日期": "2023-06-21",
                "摘要": "  The success of deep learning based face recognition systems has given rise to\nserious privacy concerns due to their ability to enable unauthorized tracking\nof users in the digital world. Existing methods for enhancing privacy fail to\ngenerate naturalistic images that can protect facial privacy without\ncompromising user experience. We propose a novel two-step approach for facial\nprivacy protection that relies on finding adversarial latent codes in the\nlow-dimensional manifold of a pretrained generative model. The first step\ninverts the given face image into the latent space and finetunes the generative\nmodel to achieve an accurate reconstruction of the given image from its latent\ncode. This step produces a good initialization, aiding the generation of\nhigh-quality faces that resemble the given identity. Subsequently, user-defined\nmakeup text prompts and identity-preserving regularization are used to guide\nthe search for adversarial codes in the latent space. Extensive experiments\ndemonstrate that faces generated by our approach have stronger black-box\ntransferability with an absolute gain of 12.06% over the state-of-the-art\nfacial privacy protection approach under the face verification task. Finally,\nwe demonstrate the effectiveness of the proposed approach for commercial face\nrecognition systems. Our code is available at\nhttps://github.com/fahadshamshad/Clip2Protect.\n",
                "链接": "https://arxiv.org/abs/2306.10008"
            }
        ]
    },
    {
        "question": {
            "question": "推荐与AutoGPT相似的10篇文献",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "86417",
                "标题": "AD-AutoGPT: An Autonomous GPT for Alzheimer's Disease Infodemiology",
                "作者": " Haixing Dai,  Yiwei Li,  Zhengliang Liu,  Lin Zhao,  Zihao Wu,  Suhang Song,  Ye Shen,  Dajiang Zhu,  Xiang Li,  Sheng Li,  Xiaobai Yao,  Lu Shi,  Quanzheng Li,  Zhuo Chen,  Donglan Zhang,  Gengchen Mai,  Tianming Liu",
                "发布日期": "2023-06-21",
                "摘要": "  In this pioneering study, inspired by AutoGPT, the state-of-the-art\nopen-source application based on the GPT-4 large language model, we develop a\nnovel tool called AD-AutoGPT which can conduct data collection, processing, and\nanalysis about complex health narratives of Alzheimer's Disease in an\nautonomous manner via users' textual prompts. We collated comprehensive data\nfrom a variety of news sources, including the Alzheimer's Association, BBC,\nMayo Clinic, and the National Institute on Aging since June 2022, leading to\nthe autonomous execution of robust trend analyses, intertopic distance maps\nvisualization, and identification of salient terms pertinent to Alzheimer's\nDisease. This approach has yielded not only a quantifiable metric of relevant\ndiscourse but also valuable insights into public focus on Alzheimer's Disease.\nThis application of AD-AutoGPT in public health signifies the transformative\npotential of AI in facilitating a data-rich understanding of complex health\nnarratives like Alzheimer's Disease in an autonomous manner, setting the\ngroundwork for future AI-driven investigations in global health landscapes.\n",
                "链接": "https://arxiv.org/abs/2306.10095"
            },
            {
                "文章ID": "123625",
                "标题": "Robust Stochastic Graph Generator for Counterfactual Explanations",
                "作者": " Mario Alfonso Prado-Romero,  Bardh Prenkaj,  Giovanni Stilo",
                "发布日期": "2023-12-20",
                "摘要": "  Counterfactual Explanation (CE) techniques have garnered attention as a means\nto provide insights to the users engaging with AI systems. While extensively\nresearched in domains such as medical imaging and autonomous vehicles, Graph\nCounterfactual Explanation (GCE) methods have been comparatively\nunder-explored. GCEs generate a new graph similar to the original one, with a\ndifferent outcome grounded on the underlying predictive model. Among these GCE\ntechniques, those rooted in generative mechanisms have received relatively\nlimited investigation despite demonstrating impressive accomplishments in other\ndomains, such as artistic styles and natural language modelling. The preference\nfor generative explainers stems from their capacity to generate counterfactual\ninstances during inference, leveraging autonomously acquired perturbations of\nthe input graph. Motivated by the rationales above, our study introduces\nRSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual\nExplanations able to produce counterfactual examples from the learned latent\nspace considering a partially ordered generation sequence. Furthermore, we\nundertake quantitative and qualitative analyses to compare RSGG-CE's\nperformance against SoA generative explainers, highlighting its increased\nability to engendering plausible counterfactual candidates.\n",
                "链接": "https://arxiv.org/abs/2312.11747"
            },
            {
                "文章ID": "89655",
                "标题": "Large Language Models Empowered Autonomous Edge AI for Connected\n  Intelligence",
                "作者": " Yifei Shen,  Jiawei Shao,  Xinjie Zhang,  Zehong Lin,  Hao Pan,  Dongsheng Li,  Jun Zhang,  Khaled B. Letaief",
                "发布日期": "2023-12-27",
                "摘要": "  The evolution of wireless networks gravitates towards connected intelligence,\na concept that envisions seamless interconnectivity among humans, objects, and\nintelligence in a hyper-connected cyber-physical world. Edge artificial\nintelligence (Edge AI) is a promising solution to achieve connected\nintelligence by delivering high-quality, low-latency, and privacy-preserving AI\nservices at the network edge. This article presents a vision of autonomous edge\nAI systems that automatically organize, adapt, and optimize themselves to meet\nusers' diverse requirements, leveraging the power of large language models\n(LLMs), i.e., Generative Pretrained Transformer (GPT). By exploiting the\npowerful abilities of GPT in language understanding, planning, and code\ngeneration, as well as incorporating classic wisdom such as task-oriented\ncommunication and edge federated learning, we present a versatile framework\nthat efficiently coordinates edge AI models to cater to users' personal demands\nwhile automatically generating code to train new models in a privacy-preserving\nmanner. Experimental results demonstrate the system's remarkable ability to\naccurately comprehend user demands, efficiently execute AI models with minimal\ncost, and effectively create high-performance AI models at edge servers.\n",
                "链接": "https://arxiv.org/abs/2307.02779"
            },
            {
                "文章ID": "81774",
                "标题": "Attention Paper: How Generative AI Reshapes Digital Shadow Industry?",
                "作者": " Qichao Wang,  Huan Ma,  Wentao Wei,  Hangyu Li,  Liang Chen,  Peilin Zhao,  Binwen Zhao,  Bo Hu,  Shu Zhang,  Zibin Zheng,  Bingzhe Wu",
                "发布日期": "2023-05-31",
                "摘要": "  The rapid development of digital economy has led to the emergence of various\nblack and shadow internet industries, which pose potential risks that can be\nidentified and managed through digital risk management (DRM) that uses\ndifferent techniques such as machine learning and deep learning. The evolution\nof DRM architecture has been driven by changes in data forms. However, the\ndevelopment of AI-generated content (AIGC) technology, such as ChatGPT and\nStable Diffusion, has given black and shadow industries powerful tools to\npersonalize data and generate realistic images and conversations for fraudulent\nactivities. This poses a challenge for DRM systems to control risks from the\nsource of data generation and to respond quickly to the fast-changing risk\nenvironment. This paper aims to provide a technical analysis of the challenges\nand opportunities of AIGC from upstream, midstream, and downstream paths of\nblack/shadow industries and suggest future directions for improving existing\nrisk control systems. The paper will explore the new black and shadow\ntechniques triggered by generative AI technology and provide insights for\nbuilding the next-generation DRM system.\n",
                "链接": "https://arxiv.org/abs/2305.18346"
            },
            {
                "文章ID": "116211",
                "标题": "Automatic Generation of Scenarios for System-level Simulation-based\n  Verification of Autonomous Driving Systems",
                "作者": "Fondazione Bruno Kessler and University of Trento  Srajan Goyal, Fondazione Bruno Kessler  Alberto Griggio, Fondazione Bruno\n  Kessler  Jacob Kimblad, Fondazione Bruno Kessler  Stefano Tonetta",
                "发布日期": "2023-11-17",
                "摘要": "  With increasing complexity of Automated Driving Systems (ADS), ensuring their\nsafety and reliability has become a critical challenge. The Verification and\nValidation (V&V) of these systems are particularly demanding when AI components\nare employed to implement perception and/or control functions. In ESA-funded\nproject VIVAS, we developed a generic framework for system-level\nsimulation-based V&V of autonomous systems. The approach is based on a\nsimulation model of the system, an abstract model that describes symbolically\nthe system behavior, and formal methods to generate scenarios and verify the\nsimulation executions. Various coverage criteria can be defined to guide the\nautomated generation of the scenarios.\n  In this paper, we describe the instantiation of the VIVAS framework for an\nADS case study. This is based on the integration of CARLA, a widely-used\ndriving simulator, and its ScenarioRunner tool, which enables the creation of\ndiverse and complex driving scenarios. This is also used in the CARLA\nAutonomous Driving Challenge to validate different ADS agents for perception\nand control based on AI, shared by the CARLA community. We describe the\ndevelopment of an abstract ADS model and the formulation of a coverage\ncriterion that focuses on the behaviors of vehicles relative to the vehicle\nwith ADS under verification. Leveraging the VIVAS framework, we generate and\nexecute various driving scenarios, thus testing the capabilities of the AI\ncomponents. The results show the effectiveness of VIVAS in automatically\ngenerating scenarios for system-level simulation-based V&V of an automated\ndriving system using CARLA and ScenarioRunner. Therefore, they highlight the\npotential of the approach as a powerful tool in the future of ADS V&V\nmethodologies.\n",
                "链接": "https://arxiv.org/abs/2311.09784"
            },
            {
                "文章ID": "74264",
                "标题": "AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking\n  Head",
                "作者": " Rongjie Huang,  Mingze Li,  Dongchao Yang,  Jiatong Shi,  Xuankai Chang,  Zhenhui Ye,  Yuning Wu,  Zhiqing Hong,  Jiawei Huang,  Jinglin Liu,  Yi Ren,  Zhou Zhao,  Shinji Watanabe",
                "发布日期": "2023-04-26",
                "摘要": "  Large language models (LLMs) have exhibited remarkable capabilities across a\nvariety of domains and tasks, challenging our understanding of learning and\ncognition. Despite the recent success, current LLMs are not capable of\nprocessing complex audio information or conducting spoken conversations (like\nSiri or Alexa). In this work, we propose a multi-modal AI system named\nAudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to\nprocess complex audio information and solve numerous understanding and\ngeneration tasks; and 2) the input/output interface (ASR, TTS) to support\nspoken dialogue. With an increasing demand to evaluate multi-modal LLMs of\nhuman intention understanding and cooperation with foundation models, we\noutline the principles and processes and test AudioGPT in terms of consistency,\ncapability, and robustness. Experimental results demonstrate the capabilities\nof AudioGPT in solving AI tasks with speech, music, sound, and talking head\nunderstanding and generation in multi-round dialogues, which empower humans to\ncreate rich and diverse audio content with unprecedented ease. Our system is\npublicly available at \\url{https://github.com/AIGC-Audio/AudioGPT}.\n",
                "链接": "https://arxiv.org/abs/2304.12995"
            },
            {
                "文章ID": "86084",
                "标题": "Are ChatGPT and Other Similar Systems the Modern Lernaean Hydras of AI?",
                "作者": " Dimitrios Ioannidis,  Jeremy Kepner,  Andrew Bowne,  Harriet S. Bryant",
                "发布日期": "2023-12-05",
                "摘要": "  The rise of Generative Artificial Intelligence systems (''AI systems'') has\ncreated unprecedented social engagement. AI code generation systems provide\nresponses (output) to questions or requests by accessing the vast library of\nopen-source code created by developers over the past few decades. However, they\ndo so by allegedly stealing the open-source code stored in virtual libraries,\nknown as repositories. This Article focuses on how this happens and whether\nthere is a solution that protects innovation and avoids years of litigation. We\nalso touch upon the array of issues raised by the relationship between AI and\ncopyright. Looking ahead, we propose the following: (a) immediate changes to\nthe licenses for open-source code created by developers that will limit access\nand/or use of any open-source code to humans only; (b) we suggest revisions to\nthe Massachusetts Institute of Technology (''MIT'') license so that AI systems\nare required to procure appropriate licenses from open-source code developers,\nwhich we believe will harmonize standards and build social consensus for the\nbenefit of all of humanity, rather than promote profit-driven centers of\ninnovation; (c) we call for urgent legislative action to protect the future of\nAI systems while also promoting innovation; and (d) we propose a shift in the\nburden of proof to AI systems in obfuscation cases.\n",
                "链接": "https://arxiv.org/abs/2306.09267"
            },
            {
                "文章ID": "116028",
                "标题": "Generative AI-Based Probabilistic Constellation Shaping With Diffusion\n  Models",
                "作者": " Mehdi Letafati,  Samad Ali,  Matti Latva-aho",
                "发布日期": "2023-11-17",
                "摘要": "  Diffusion models are at the vanguard of generative AI research with renowned\nsolutions such as ImageGen by Google Brain and DALL.E 3 by OpenAI.\nNevertheless, the potential merits of diffusion models for communication\nengineering applications are not fully understood yet. In this paper, we aim to\nunleash the power of generative AI for PHY design of constellation symbols in\ncommunication systems. Although the geometry of constellations is predetermined\naccording to networking standards, e.g., quadrature amplitude modulation (QAM),\nprobabilistic shaping can design the probability of occurrence (generation) of\nconstellation symbols. This can help improve the information rate and decoding\nperformance of communication systems. We exploit the ``denoise-and-generate''\ncharacteristics of denoising diffusion probabilistic models (DDPM) for\nprobabilistic constellation shaping. The key idea is to learn generating\nconstellation symbols out of noise, ``mimicking'' the way the receiver performs\nsymbol reconstruction. This way, we make the constellation symbols sent by the\ntransmitter, and what is inferred (reconstructed) at the receiver become as\nsimilar as possible, resulting in as few mismatches as possible. Our results\nshow that the generative AI-based scheme outperforms deep neural network\n(DNN)-based benchmark and uniform shaping, while providing network resilience\nas well as robust out-of-distribution performance under low-SNR regimes and\nnon-Gaussian assumptions. Numerical evaluations highlight 30% improvement in\nterms of cosine similarity and a threefold improvement in terms of mutual\ninformation compared to DNN-based approach for 64-QAM geometry.\n",
                "链接": "https://arxiv.org/abs/2311.09349"
            },
            {
                "文章ID": "117402",
                "标题": "Building the Future of Responsible AI: A Reference Architecture for\n  Designing Large Language Model based Agents",
                "作者": " Qinghua Lu,  Liming Zhu,  Xiwei Xu,  Zhenchang Xing,  Stefan Harrer,  Jon Whittle",
                "发布日期": "2023-11-29",
                "摘要": "  Large language models (LLMs) have been widely recognised as transformative\nartificial generative intelligence (AGI) technologies due to their capabilities\nto understand and generate content, including plans with reasoning\ncapabilities. Foundation model based agents derive their autonomy from the\ncapabilities of foundation models, which enable them to autonomously break down\na given goal into a set of manageable tasks and orchestrate task execution to\nmeet the goal. Despite the huge efforts put into building foundation model\nbased autonomous agents, the architecture design of the agents has not yet been\nsystematically explored. Also, while there are significant benefits of using\nautonomous agents for planning and execution, there are serious considerations\nregarding responsible AI related software quality attributes, such as security\nand accountability. Therefore, this paper presents a pattern-oriented reference\narchitecture that serves as architecture design guidance and enables\nresponsible-AI-by-design when designing foundation model based autonomous\nagents. We evaluate the completeness and utility of the proposed reference\narchitecture by mapping it to the architecture of two real-world agents.\n",
                "链接": "https://arxiv.org/abs/2311.13148"
            },
            {
                "文章ID": "84136",
                "标题": "Designing explainable artificial intelligence with active inference: A\n  framework for transparent introspection and decision-making",
                "作者": " Mahault Albarracin,  Inês Hipólito,  Safae Essafi Tremblay,  Jason G. Fox,  Gabriel René,  Karl Friston,  Maxwell J. D. Ramstead",
                "发布日期": "2023-06-08",
                "摘要": "  This paper investigates the prospect of developing human-interpretable,\nexplainable artificial intelligence (AI) systems based on active inference and\nthe free energy principle. We first provide a brief overview of active\ninference, and in particular, of how it applies to the modeling of\ndecision-making, introspection, as well as the generation of overt and covert\nactions. We then discuss how active inference can be leveraged to design\nexplainable AI systems, namely, by allowing us to model core features of\n``introspective'' processes and by generating useful, human-interpretable\nmodels of the processes involved in decision-making. We propose an architecture\nfor explainable AI systems using active inference. This architecture\nforegrounds the role of an explicit hierarchical generative model, the\noperation of which enables the AI system to track and explain the factors that\ncontribute to its own decisions, and whose structure is designed to be\ninterpretable and auditable by human users. We outline how this architecture\ncan integrate diverse sources of information to make informed decisions in an\nauditable manner, mimicking or reproducing aspects of human-like consciousness\nand introspection. Finally, we discuss the implications of our findings for\nfuture research in AI, and the potential ethical considerations of developing\nAI systems with (the appearance of) introspective capabilities.\n",
                "链接": "https://arxiv.org/abs/2306.04025"
            }
        ]
    },
    {
        "question": {
            "question": "请搜索近一年发表的有关多模态大模型与产业相结合、与具体应用场景相结合的论文",
            "type": "2"
        },
        "results": [
            {
                "文章ID": "97795",
                "标题": "Federated Learning in Big Model Era: Domain-Specific Multimodal Large\n  Models",
                "作者": " Zengxiang Li,  Zhaoxiang Hou,  Hui Liu,  Ying Wang,  Tongzhi Li,  Longfei Xie,  Chao Shi,  Chengyi Yang,  Weishan Zhang,  Zelei Liu,  Liang Xu",
                "发布日期": "2023-08-25",
                "摘要": "  Multimodal data, which can comprehensively perceive and recognize the\nphysical world, has become an essential path towards general artificial\nintelligence. However, multimodal large models trained on public datasets often\nunderperform in specific industrial domains. This paper proposes a multimodal\nfederated learning framework that enables multiple enterprises to utilize\nprivate domain data to collaboratively train large models for vertical domains,\nachieving intelligent services across scenarios. The authors discuss in-depth\nthe strategic transformation of federated learning in terms of intelligence\nfoundation and objectives in the era of big model, as well as the new\nchallenges faced in heterogeneous data, model aggregation, performance and cost\ntrade-off, data privacy, and incentive mechanism. The paper elaborates a case\nstudy of leading enterprises contributing multimodal data and expert knowledge\nto city safety operation management , including distributed deployment and\nefficient coordination of the federated learning platform, technical\ninnovations on data quality improvement based on large model capabilities and\nefficient joint fine-tuning approaches. Preliminary experiments show that\nenterprises can enhance and accumulate intelligent capabilities through\nmultimodal model federated learning, thereby jointly creating an smart city\nmodel that provides high-quality intelligent services covering energy\ninfrastructure safety, residential community security, and urban operation\nmanagement. The established federated learning cooperation ecosystem is\nexpected to further aggregate industry, academia, and research resources,\nrealize large models in multiple vertical domains, and promote the large-scale\nindustrial application of artificial intelligence and cutting-edge research on\nmultimodal federated learning.\n",
                "链接": "https://arxiv.org/abs/2308.11217"
            },
            {
                "文章ID": "88316",
                "标题": "Stone Needle: A General Multimodal Large-scale Model Framework towards\n  Healthcare",
                "作者": " Weihua Liu,  Yong Zuo",
                "发布日期": "2023-06-29",
                "摘要": "  In healthcare, multimodal data is prevalent and requires to be\ncomprehensively analyzed before diagnostic decisions, including medical images,\nclinical reports, etc. However, current large-scale artificial intelligence\nmodels predominantly focus on single-modal cognitive abilities and neglect the\nintegration of multiple modalities. Therefore, we propose Stone Needle, a\ngeneral multimodal large-scale model framework tailored explicitly for\nhealthcare applications. Stone Needle serves as a comprehensive medical\nmultimodal model foundation, integrating various modalities such as text,\nimages, videos, and audio to surpass the limitations of single-modal systems.\nThrough the framework components of intent analysis, medical foundation models,\nprompt manager, and medical language module, our architecture can perform\nmulti-modal interaction in multiple rounds of dialogue. Our method is a general\nmultimodal large-scale model framework, integrating diverse modalities and\nallowing us to tailor for specific tasks. The experimental results demonstrate\nthe superior performance of our method compared to single-modal systems. The\nfusion of different modalities and the ability to process complex medical\ninformation in Stone Needle benefits accurate diagnosis, treatment\nrecommendations, and patient care.\n",
                "链接": "https://arxiv.org/abs/2306.16034"
            },
            {
                "文章ID": "100082",
                "标题": "Large AI Model Empowered Multimodal Semantic Communications",
                "作者": " Feibo Jiang,  Yubo Peng,  Li Dong,  Kezhi Wang,  Kun Yang,  Cunhua Pan,  Xiaohu You",
                "发布日期": "2023-09-06",
                "摘要": "  Multimodal signals, including text, audio, image and video, can be integrated\ninto Semantic Communication (SC) for providing an immersive experience with low\nlatency and high quality at the semantic level. However, the multimodal SC has\nseveral challenges, including data heterogeneity, semantic ambiguity, and\nsignal fading. Recent advancements in large AI models, particularly in\nMultimodal Language Model (MLM) and Large Language Model (LLM), offer potential\nsolutions for these issues. To this end, we propose a Large AI Model-based\nMultimodal SC (LAM-MSC) framework, in which we first present the MLM-based\nMultimodal Alignment (MMA) that utilizes the MLM to enable the transformation\nbetween multimodal and unimodal data while preserving semantic consistency.\nThen, a personalized LLM-based Knowledge Base (LKB) is proposed, which allows\nusers to perform personalized semantic extraction or recovery through the LLM.\nThis effectively addresses the semantic ambiguity. Finally, we apply the\nConditional Generative adversarial networks-based channel Estimation (CGE) to\nobtain Channel State Information (CSI). This approach effectively mitigates the\nimpact of fading channels in SC. Finally, we conduct simulations that\ndemonstrate the superior performance of the LAM-MSC framework.\n",
                "链接": "https://arxiv.org/abs/2309.01249"
            },
            {
                "文章ID": "64231",
                "标题": "Multimodal Industrial Anomaly Detection via Hybrid Fusion",
                "作者": " Yue Wang,  Jinlong Peng,  Jiangning Zhang,  Ran Yi,  Yabiao Wang,  Chengjie Wang",
                "发布日期": "2023-09-08",
                "摘要": "  2D-based Industrial Anomaly Detection has been widely discussed, however,\nmultimodal industrial anomaly detection based on 3D point clouds and RGB images\nstill has many untouched fields. Existing multimodal industrial anomaly\ndetection methods directly concatenate the multimodal features, which leads to\na strong disturbance between features and harms the detection performance. In\nthis paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly\ndetection method with hybrid fusion scheme: firstly, we design an unsupervised\nfeature fusion with patch-wise contrastive learning to encourage the\ninteraction of different modal features; secondly, we use a decision layer\nfusion with multiple memory banks to avoid loss of information and additional\nnovelty classifiers to make the final decision. We further propose a point\nfeature alignment operation to better align the point cloud and RGB features.\nExtensive experiments show that our multimodal industrial anomaly detection\nmodel outperforms the state-of-the-art (SOTA) methods on both detection and\nsegmentation precision on MVTec-3D AD dataset. Code is available at\nhttps://github.com/nomewang/M3DM.\n",
                "链接": "https://arxiv.org/abs/2303.00601"
            },
            {
                "文章ID": "105595",
                "标题": "Application of frozen large-scale models to multimodal task-oriented\n  dialogue",
                "作者": " Tatsuki Kawamoto,  Takuma Suzuki,  Ko Miyama,  Takumi Meguro,  Tomohiro Takagi",
                "发布日期": "2023-10-03",
                "摘要": "  In this study, we use the existing Large Language Models ENnhanced to See\nFramework (LENS Framework) to test the feasibility of multimodal task-oriented\ndialogues. The LENS Framework has been proposed as a method to solve computer\nvision tasks without additional training and with fixed parameters of\npre-trained models. We used the Multimodal Dialogs (MMD) dataset, a multimodal\ntask-oriented dialogue benchmark dataset from the fashion field, and for the\nevaluation, we used the ChatGPT-based G-EVAL, which only accepts textual\nmodalities, with arrangements to handle multimodal data. Compared to\nTransformer-based models in previous studies, our method demonstrated an\nabsolute lift of 10.8% in fluency, 8.8% in usefulness, and 5.2% in relevance\nand coherence. The results show that using large-scale models with fixed\nparameters rather than using models trained on a dataset from scratch improves\nperformance in multimodal task-oriented dialogues. At the same time, we show\nthat Large Language Models (LLMs) are effective for multimodal task-oriented\ndialogues. This is expected to lead to efficient applications to existing\nsystems.\n",
                "链接": "https://arxiv.org/abs/2310.00845"
            },
            {
                "文章ID": "104172",
                "标题": "MultiModN- Multimodal, Multi-Task, Interpretable Modular Networks",
                "作者": " Vinitra Swamy,  Malika Satayeva,  Jibril Frej,  Thierry Bossy,  Thijs Vogels,  Martin Jaggi,  Tanja Käser,  Mary-Anne Hartley",
                "发布日期": "2023-11-07",
                "摘要": "  Predicting multiple real-world tasks in a single model often requires a\nparticularly diverse feature space. Multimodal (MM) models aim to extract the\nsynergistic predictive potential of multiple data types to create a shared\nfeature space with aligned semantic meaning across inputs of drastically\nvarying sizes (i.e. images, text, sound). Most current MM architectures fuse\nthese representations in parallel, which not only limits their interpretability\nbut also creates a dependency on modality availability. We present MultiModN, a\nmultimodal, modular network that fuses latent representations in a sequence of\nany number, combination, or type of modality while providing granular real-time\npredictive feedback on any number or combination of predictive tasks.\nMultiModN's composable pipeline is interpretable-by-design, as well as innately\nmulti-task and robust to the fundamental issue of biased missingness. We\nperform four experiments on several benchmark MM datasets across 10 real-world\ntasks (predicting medical diagnoses, academic performance, and weather), and\nshow that MultiModN's sequential MM fusion does not compromise performance\ncompared with a baseline of parallel fusion. By simulating the challenging bias\nof missing not-at-random (MNAR), this work shows that, contrary to MultiModN,\nparallel fusion baselines erroneously learn MNAR and suffer catastrophic\nfailure when faced with different patterns of MNAR at inference. To the best of\nour knowledge, this is the first inherently MNAR-resistant approach to MM\nmodeling. In conclusion, MultiModN provides granular insights, robustness, and\nflexibility without compromising performance.\n",
                "链接": "https://arxiv.org/abs/2309.14118"
            },
            {
                "文章ID": "81732",
                "标题": "Contextual Object Detection with Multimodal Large Language Models",
                "作者": " Yuhang Zang,  Wei Li,  Jun Han,  Kaiyang Zhou,  Chen Change Loy",
                "发布日期": "2023-05-30",
                "摘要": "  Recent Multimodal Large Language Models (MLLMs) are remarkable in\nvision-language tasks, such as image captioning and question answering, but\nlack the essential perception ability, i.e., object detection. In this work, we\naddress this limitation by introducing a novel research problem of contextual\nobject detection -- understanding visible objects within different human-AI\ninteractive contexts. Three representative scenarios are investigated,\nincluding the language cloze test, visual captioning, and question answering.\nMoreover, we present ContextDET, a unified multimodal model that is capable of\nend-to-end differentiable modeling of visual-language contexts, so as to\nlocate, identify, and associate visual objects with language inputs for\nhuman-AI interaction. Our ContextDET involves three key submodels: (i) a visual\nencoder for extracting visual representations, (ii) a pre-trained LLM for\nmultimodal context decoding, and (iii) a visual decoder for predicting bounding\nboxes given contextual object words. The new generate-then-detect framework\nenables us to detect object words within human vocabulary. Extensive\nexperiments show the advantages of ContextDET on our proposed CODE benchmark,\nopen-vocabulary detection, and referring image segmentation. Github:\nhttps://github.com/yuhangzang/ContextDET.\n",
                "链接": "https://arxiv.org/abs/2305.18279"
            },
            {
                "文章ID": "116328",
                "标题": "UnifiedVisionGPT: Streamlining Vision-Oriented AI through Generalized\n  Multimodal Framework",
                "作者": " Chris Kelly,  Luhui Hu,  Cindy Yang,  Yu Tian,  Deshun Yang,  Bang Yang,  Zaoshan Huang,  Zihao Li,  Yuexian Zou",
                "发布日期": "2023-11-20",
                "摘要": "  In the current landscape of artificial intelligence, foundation models serve\nas the bedrock for advancements in both language and vision domains. OpenAI\nGPT-4 has emerged as the pinnacle in large language models (LLMs), while the\ncomputer vision (CV) domain boasts a plethora of state-of-the-art (SOTA) models\nsuch as Meta's SAM and DINO, and YOLOS. However, the financial and\ncomputational burdens of training new models from scratch remain a significant\nbarrier to progress. In response to this challenge, we introduce\nUnifiedVisionGPT, a novel framework designed to consolidate and automate the\nintegration of SOTA vision models, thereby facilitating the development of\nvision-oriented AI. UnifiedVisionGPT distinguishes itself through four key\nfeatures: (1) provides a versatile multimodal framework adaptable to a wide\nrange of applications, building upon the strengths of multimodal foundation\nmodels; (2) seamlessly integrates various SOTA vision models to create a\ncomprehensive multimodal platform, capitalizing on the best components of each\nmodel; (3) prioritizes vision-oriented AI, ensuring a more rapid progression in\nthe CV domain compared to the current trajectory of LLMs; and (4) introduces\nautomation in the selection of SOTA vision models, generating optimal results\nbased on diverse multimodal inputs such as text prompts and images. This paper\noutlines the architecture and capabilities of UnifiedVisionGPT, demonstrating\nits potential to revolutionize the field of computer vision through enhanced\nefficiency, versatility, generalization, and performance. Our implementation,\nalong with the unified multimodal framework and comprehensive dataset, is made\npublicly available at https://github.com/LHBuilder/SA-Segment-Anything.\n",
                "链接": "https://arxiv.org/abs/2311.10125"
            },
            {
                "文章ID": "104627",
                "标题": "Jointly Training Large Autoregressive Multimodal Models",
                "作者": " Emanuele Aiello,  Lili Yu,  Yixin Nie,  Armen Aghajanyan,  Barlas Oguz",
                "发布日期": "2023-09-29",
                "摘要": "  In recent years, advances in the large-scale pretraining of language and\ntext-to-image models have revolutionized the field of machine learning. Yet,\nintegrating these two modalities into a single, robust model capable of\ngenerating seamless multimodal outputs remains a significant challenge. To\naddress this gap, we present the Joint Autoregressive Mixture (JAM) framework,\na modular approach that systematically fuses existing text and image generation\nmodels. We also introduce a specialized, data-efficient instruction-tuning\nstrategy, tailored for mixed-modal generation tasks. Our final instruct-tuned\nmodel demonstrates unparalleled performance in generating high-quality\nmultimodal outputs and represents the first model explicitly designed for this\npurpose.\n",
                "链接": "https://arxiv.org/abs/2309.15564"
            },
            {
                "文章ID": "117088",
                "标题": "A Survey on Multimodal Large Language Models for Autonomous Driving",
                "作者": " Can Cui,  Yunsheng Ma,  Xu Cao,  Wenqian Ye,  Yang Zhou,  Kaizhao Liang,  Jintai Chen,  Juanwu Lu,  Zichong Yang,  Kuei-Da Liao,  Tianren Gao,  Erlong Li,  Kun Tang,  Zhipeng Cao,  Tong Zhou,  Ao Liu,  Xinrui Yan,  Shuqi Mei,  Jianguo Cao,  Ziran Wang,  Chao Zheng",
                "发布日期": "2023-11-22",
                "摘要": "  With the emergence of Large Language Models (LLMs) and Vision Foundation\nModels (VFMs), multimodal AI systems benefiting from large models have the\npotential to equally perceive the real world, make decisions, and control tools\nas humans. In recent months, LLMs have shown widespread attention in autonomous\ndriving and map systems. Despite its immense potential, there is still a lack\nof a comprehensive understanding of key challenges, opportunities, and future\nendeavors to apply in LLM driving systems. In this paper, we present a\nsystematic investigation in this field. We first introduce the background of\nMultimodal Large Language Models (MLLMs), the multimodal models development\nusing LLMs, and the history of autonomous driving. Then, we overview existing\nMLLM tools for driving, transportation, and map systems together with existing\ndatasets and benchmarks. Moreover, we summarized the works in The 1st WACV\nWorkshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD),\nwhich is the first workshop of its kind regarding LLMs in autonomous driving.\nTo further promote the development of this field, we also discuss several\nimportant problems regarding using MLLMs in autonomous driving systems that\nneed to be solved by both academia and industry.\n",
                "链接": "https://arxiv.org/abs/2311.12320"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究，特别关注使用自动标注和迁移学习方法的论文，时间跨度覆盖2019年至今。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "107726",
                "标题": "Data efficient deep learning for medical image analysis: A survey",
                "作者": " Suruchi Kumari,  Pravendra Singh",
                "发布日期": "2023-10-11",
                "摘要": "  The rapid evolution of deep learning has significantly advanced the field of\nmedical image analysis. However, despite these achievements, the further\nenhancement of deep learning models for medical image analysis faces a\nsignificant challenge due to the scarcity of large, well-annotated datasets. To\naddress this issue, recent years have witnessed a growing emphasis on the\ndevelopment of data-efficient deep learning methods. This paper conducts a\nthorough review of data-efficient deep learning methods for medical image\nanalysis. To this end, we categorize these methods based on the level of\nsupervision they rely on, encompassing categories such as no supervision,\ninexact supervision, incomplete supervision, inaccurate supervision, and only\nlimited supervision. We further divide these categories into finer\nsubcategories. For example, we categorize inexact supervision into multiple\ninstance learning and learning with weak annotations. Similarly, we categorize\nincomplete supervision into semi-supervised learning, active learning, and\ndomain-adaptive learning and so on. Furthermore, we systematically summarize\ncommonly used datasets for data efficient deep learning in medical image\nanalysis and investigate future research directions to conclude this survey.\n",
                "链接": "https://arxiv.org/abs/2310.06557"
            },
            {
                "文章ID": "110503",
                "标题": "A comprehensive survey on deep active learning and its applications in\n  medical image analysis",
                "作者": " Haoran Wang,  Qiuye Jin,  Shiman Li,  Siyu Liu,  Manning Wang,  Zhijian Song",
                "发布日期": "2023-10-25",
                "摘要": "  Deep learning has achieved widespread success in medical image analysis,\nleading to an increasing demand for large-scale expert-annotated medical image\ndatasets. Yet, the high cost of annotating medical images severely hampers the\ndevelopment of deep learning in this field. To reduce annotation costs, active\nlearning aims to select the most informative samples for annotation and train\nhigh-performance models with as few labeled samples as possible. In this\nsurvey, we review the core methods of active learning, including the evaluation\nof informativeness and sampling strategy. For the first time, we provide a\ndetailed summary of the integration of active learning with other\nlabel-efficient techniques, such as semi-supervised, self-supervised learning,\nand so on. Additionally, we also highlight active learning works that are\nspecifically tailored to medical image analysis. In the end, we offer our\nperspectives on the future trends and challenges of active learning and its\napplications in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2310.14230"
            },
            {
                "文章ID": "69437",
                "标题": "Medical Image Analysis using Deep Relational Learning",
                "作者": " Zhihua Liu",
                "发布日期": "2023-03-29",
                "摘要": "  In the past ten years, with the help of deep learning, especially the rapid\ndevelopment of deep neural networks, medical image analysis has made remarkable\nprogress. However, how to effectively use the relational information between\nvarious tissues or organs in medical images is still a very challenging\nproblem, and it has not been fully studied. In this thesis, we propose two\nnovel solutions to this problem based on deep relational learning. First, we\npropose a context-aware fully convolutional network that effectively models\nimplicit relation information between features to perform medical image\nsegmentation. The network achieves the state-of-the-art segmentation results on\nthe Multi Modal Brain Tumor Segmentation 2017 (BraTS2017) and Multi Modal Brain\nTumor Segmentation 2018 (BraTS2018) data sets. Subsequently, we propose a new\nhierarchical homography estimation network to achieve accurate medical image\nmosaicing by learning the explicit spatial relationship between adjacent\nframes. We use the UCL Fetoscopy Placenta dataset to conduct experiments and\nour hierarchical homography estimation network outperforms the other\nstate-of-the-art mosaicing methods while generating robust and meaningful\nmosaicing result on unseen frames.\n",
                "链接": "https://arxiv.org/abs/2303.16099"
            },
            {
                "文章ID": "68134",
                "标题": "Label-Efficient Deep Learning in Medical Image Analysis: Challenges and\n  Future Directions",
                "作者": " Cheng Jin,  Zhengrui Guo,  Yi Lin,  Luyang Luo,  Hao Chen",
                "发布日期": "2023-12-21",
                "摘要": "  Deep learning has seen rapid growth in recent years and achieved\nstate-of-the-art performance in a wide range of applications. However, training\nmodels typically requires expensive and time-consuming collection of large\nquantities of labeled data. This is particularly true within the scope of\nmedical imaging analysis (MIA), where data are limited and labels are expensive\nto be acquired. Thus, label-efficient deep learning methods are developed to\nmake comprehensive use of the labeled data as well as the abundance of\nunlabeled and weak-labeled data. In this survey, we extensively investigated\nover 300 recent papers to provide a comprehensive overview of recent progress\non label-efficient learning strategies in MIA. We first present the background\nof label-efficient learning and categorize the approaches into different\nschemes. Next, we examine the current state-of-the-art methods in detail\nthrough each scheme. Specifically, we provide an in-depth investigation,\ncovering not only canonical semi-supervised, self-supervised, and\nmulti-instance learning schemes, but also recently emerged active and\nannotation-efficient learning strategies. Moreover, as a comprehensive\ncontribution to the field, this survey not only elucidates the commonalities\nand unique features of the surveyed methods but also presents a detailed\nanalysis of the current challenges in the field and suggests potential avenues\nfor future research.\n",
                "链接": "https://arxiv.org/abs/2303.12484"
            },
            {
                "文章ID": "34051",
                "标题": "PyMIC: A deep learning toolkit for annotation-efficient medical image\n  segmentation",
                "作者": " Guotai Wang,  Xiangde Luo,  Ran Gu,  Shuojue Yang,  Yijie Qu,  Shuwei Zhai,  Qianfei Zhao,  Kang Li,  Shaoting Zhang",
                "发布日期": "2023-02-14",
                "摘要": "  Background and Objective: Open-source deep learning toolkits are one of the\ndriving forces for developing medical image segmentation models. Existing\ntoolkits mainly focus on fully supervised segmentation and require full and\naccurate pixel-level annotations that are time-consuming and difficult to\nacquire for segmentation tasks, which makes learning from imperfect labels\nhighly desired for reducing the annotation cost. We aim to develop a new deep\nlearning toolkit to support annotation-efficient learning for medical image\nsegmentation.\n  Methods: Our proposed toolkit named PyMIC is a modular deep learning library\nfor medical image segmentation tasks. In addition to basic components that\nsupport development of high-performance models for fully supervised\nsegmentation, it contains several advanced components tailored for learning\nfrom imperfect annotations, such as loading annotated and unannounced images,\nloss functions for unannotated, partially or inaccurately annotated images, and\ntraining procedures for co-learning between multiple networks, etc. PyMIC\nsupports development of semi-supervised, weakly supervised and noise-robust\nlearning methods for medical image segmentation.\n  Results: We present several illustrative medical image segmentation tasks\nbased on PyMIC: (1) Achieving competitive performance on fully supervised\nlearning; (2) Semi-supervised cardiac structure segmentation with only 10%\ntraining images annotated; (3) Weakly supervised segmentation using scribble\nannotations; and (4) Learning from noisy labels for chest radiograph\nsegmentation.\n  Conclusions: The PyMIC toolkit is easy to use and facilitates efficient\ndevelopment of medical image segmentation models with imperfect annotations. It\nis modular and flexible, which enables researchers to develop high-performance\nmodels with low annotation cost. The source code is available at:\nhttps://github.com/HiLab-git/PyMIC.\n",
                "链接": "https://arxiv.org/abs/2208.09350"
            },
            {
                "文章ID": "78299",
                "标题": "DeepEdit: Deep Editable Learning for Interactive Segmentation of 3D\n  Medical Images",
                "作者": " Andres Diaz-Pinto,  Pritesh Mehta,  Sachidanand Alle,  Muhammad Asad,  Richard Brown,  Vishwesh Nath,  Alvin Ihsani,  Michela Antonelli,  Daniel Palkovics,  Csaba Pinter,  Ron Alkalay,  Steve Pieper,  Holger R. Roth,  Daguang Xu,  Prerna Dogra,  Tom Vercauteren,  Andrew Feng,  Abood Quraini,  Sebastien Ourselin,  M. Jorge Cardoso",
                "发布日期": "2023-11-22",
                "摘要": "  Automatic segmentation of medical images is a key step for diagnostic and\ninterventional tasks. However, achieving this requires large amounts of\nannotated volumes, which can be tedious and time-consuming task for expert\nannotators. In this paper, we introduce DeepEdit, a deep learning-based method\nfor volumetric medical image annotation, that allows automatic and\nsemi-automatic segmentation, and click-based refinement. DeepEdit combines the\npower of two methods: a non-interactive (i.e. automatic segmentation using\nnnU-Net, UNET or UNETR) and an interactive segmentation method (i.e. DeepGrow),\ninto a single deep learning model. It allows easy integration of\nuncertainty-based ranking strategies (i.e. aleatoric and epistemic uncertainty\ncomputation) and active learning. We propose and implement a method for\ntraining DeepEdit by using standard training combined with user interaction\nsimulation. Once trained, DeepEdit allows clinicians to quickly segment their\ndatasets by using the algorithm in auto segmentation mode or by providing\nclicks via a user interface (i.e. 3D Slicer, OHIF). We show the value of\nDeepEdit through evaluation on the PROSTATEx dataset for prostate/prostatic\nlesions and the Multi-Atlas Labeling Beyond the Cranial Vault (BTCV) dataset\nfor abdominal CT segmentation, using state-of-the-art network architectures as\nbaseline for comparison. DeepEdit could reduce the time and effort annotating\n3D medical images compared to DeepGrow alone. Source code is available at\nhttps://github.com/Project-MONAI/MONAILabel\n",
                "链接": "https://arxiv.org/abs/2305.10655"
            },
            {
                "文章ID": "97598",
                "标题": "Visual Crowd Analysis: Open Research Problems",
                "作者": " Muhammad Asif Khan,  Hamid Menouar,  Ridha Hamila",
                "发布日期": "2023-08-25",
                "摘要": "  Over the last decade, there has been a remarkable surge in interest in\nautomated crowd monitoring within the computer vision community. Modern\ndeep-learning approaches have made it possible to develop fully-automated\nvision-based crowd-monitoring applications. However, despite the magnitude of\nthe issue at hand, the significant technological advancements, and the\nconsistent interest of the research community, there are still numerous\nchallenges that need to be overcome. In this article, we delve into six major\nareas of visual crowd analysis, emphasizing the key developments in each of\nthese areas. We outline the crucial unresolved issues that must be tackled in\nfuture works, in order to ensure that the field of automated crowd monitoring\ncontinues to progress and thrive. Several surveys related to this topic have\nbeen conducted in the past. Nonetheless, this article thoroughly examines and\npresents a more intuitive categorization of works, while also depicting the\nlatest breakthroughs within the field, incorporating more recent studies\ncarried out within the last few years in a concise manner. By carefully\nchoosing prominent works with significant contributions in terms of novelty or\nperformance gains, this paper presents a more comprehensive exposition of\nadvancements in the current state-of-the-art.\n",
                "链接": "https://arxiv.org/abs/2308.10677"
            },
            {
                "文章ID": "52332",
                "标题": "A Trustworthy Framework for Medical Image Analysis with Deep Learning",
                "作者": " Kai Ma,  Siyuan He,  Pengcheng Xi,  Ashkan Ebadi,  Stéphane Tremblay,  Alexander Wong",
                "发布日期": "2022-12-07",
                "摘要": "  Computer vision and machine learning are playing an increasingly important\nrole in computer-assisted diagnosis; however, the application of deep learning\nto medical imaging has challenges in data availability and data imbalance, and\nit is especially important that models for medical imaging are built to be\ntrustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning\nframework for medical image analysis, which adopts a modular design, leverages\nself-supervised pre-training, and utilizes a novel surrogate loss function.\nExperimental evaluations indicate that models generated from the framework are\nboth trustworthy and high-performing. It is anticipated that the framework will\nsupport researchers and clinicians in advancing the use of deep learning for\ndealing with public health crises including COVID-19.\n",
                "链接": "https://arxiv.org/abs/2212.02764"
            },
            {
                "文章ID": "10753",
                "标题": "Learning from Multiple Expert Annotators for Enhancing Anomaly Detection\n  in Medical Image Analysis",
                "作者": " Khiem H. Le,  Tuan V. Tran,  Hieu H. Pham,  Hieu T. Nguyen,  Tung T. Le,  Ha Q. Nguyen",
                "发布日期": "2022-03-22",
                "摘要": "  Building an accurate computer-aided diagnosis system based on data-driven\napproaches requires a large amount of high-quality labeled data. In medical\nimaging analysis, multiple expert annotators often produce subjective estimates\nabout \"ground truth labels\" during the annotation process, depending on their\nexpertise and experience. As a result, the labeled data may contain a variety\nof human biases with a high rate of disagreement among annotators, which\nsignificantly affect the performance of supervised machine learning algorithms.\nTo tackle this challenge, we propose a simple yet effective approach to combine\nannotations from multiple radiology experts for training a deep learning-based\ndetector that aims to detect abnormalities on medical scans. The proposed\nmethod first estimates the ground truth annotations and confidence scores of\ntraining examples. The estimated annotations and their scores are then used to\ntrain a deep learning detector with a re-weighted loss function to localize\nabnormal findings. We conduct an extensive experimental evaluation of the\nproposed approach on both simulated and real-world medical imaging datasets.\nThe experimental results show that our approach significantly outperforms\nbaseline approaches that do not consider the disagreements among annotators,\nincluding methods in which all of the noisy annotations are treated equally as\nground truth and the ensemble of different models trained on different label\nsets provided separately by annotators.\n",
                "链接": "https://arxiv.org/abs/2203.10611"
            },
            {
                "文章ID": "84878",
                "标题": "Federated Learning for Medical Image Analysis: A Survey",
                "作者": " Hao Guan,  Pew-Thian Yap,  Andrea Bozoki,  Mingxia Liu",
                "发布日期": "2023-09-13",
                "摘要": "  Machine learning in medical imaging often faces a fundamental dilemma, namely\nthe small sample size problem. Many recent studies suggest using multi-domain\ndata pooled from different acquisition sites/datasets to improve statistical\npower. However, medical images from different sites cannot be easily shared to\nbuild large datasets for model training due to privacy protection reasons. As a\npromising solution, federated learning, which enables collaborative training of\nmachine learning models based on data from different sites without cross-site\ndata sharing, has attracted considerable attention recently. In this paper, we\nconduct a comprehensive survey of the recent development of federated learning\nmethods in medical image analysis. We first introduce the background and\nmotivation of federated learning for dealing with privacy protection and\ncollaborative learning issues in medical imaging. We then present a\ncomprehensive review of recent advances in federated learning methods for\nmedical image analysis. Specifically, existing methods are categorized based on\nthree critical aspects of a federated learning system, including client end,\nserver end, and communication techniques. In each category, we summarize the\nexisting federated learning methods according to specific research problems in\nmedical image analysis and also provide insights into the motivations of\ndifferent approaches. In addition, we provide a review of existing benchmark\nmedical imaging datasets and software platforms for current federated learning\nresearch. We also conduct an experimental study to empirically evaluate typical\nfederated learning methods for medical image analysis. This survey can help to\nbetter understand the current research status, challenges and potential\nresearch opportunities in this promising research field.\n",
                "链接": "https://arxiv.org/abs/2306.05980"
            }
        ]
    },
    {
        "question": {
            "question": "请找出最近一年内发表的关于自然语言处理领域中，使用Transformer模型并在大规模数据集上进行预训练的论文。特别关注模型结构和性能指标。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "119613",
                "标题": "Nonparametric Variational Regularisation of Pretrained Transformers",
                "作者": " Fabio Fehr,  James Henderson",
                "发布日期": "2023-12-04",
                "摘要": "  The current paradigm of large-scale pre-training and fine-tuning Transformer\nlarge language models has lead to significant improvements across the board in\nnatural language processing. However, such large models are susceptible to\noverfitting to their training data, and as a result the models perform poorly\nwhen the domain changes. Also, due to the model's scale, the cost of\nfine-tuning the model to the new domain is large. Nonparametric Variational\nInformation Bottleneck (NVIB) has been proposed as a regulariser for training\ncross-attention in Transformers, potentially addressing the overfitting\nproblem. We extend the NVIB framework to replace all types of attention\nfunctions in Transformers, and show that existing pretrained Transformers can\nbe reinterpreted as Nonparametric Variational (NV) models using a proposed\nidentity initialisation. We then show that changing the initialisation\nintroduces a novel, information-theoretic post-training regularisation in the\nattention mechanism, which improves out-of-domain generalisation without any\ntraining. This success supports the hypothesis that pretrained Transformers are\nimplicitly NV Bayesian models.\n",
                "链接": "https://arxiv.org/abs/2312.00662"
            },
            {
                "文章ID": "88555",
                "标题": "MIS-FM: 3D Medical Image Segmentation using Foundation Models Pretrained\n  on a Large-Scale Unannotated Dataset",
                "作者": " Guotai Wang,  Jianghao Wu,  Xiangde Luo,  Xinglong Liu,  Kang Li,  Shaoting Zhang",
                "发布日期": "2023-06-30",
                "摘要": "  Pretraining with large-scale 3D volumes has a potential for improving the\nsegmentation performance on a target medical image dataset where the training\nimages and annotations are limited. Due to the high cost of acquiring\npixel-level segmentation annotations on the large-scale pretraining dataset,\npretraining with unannotated images is highly desirable. In this work, we\npropose a novel self-supervised learning strategy named Volume Fusion (VF) for\npretraining 3D segmentation models. It fuses several random patches from a\nforeground sub-volume to a background sub-volume based on a predefined set of\ndiscrete fusion coefficients, and forces the model to predict the fusion\ncoefficient of each voxel, which is formulated as a self-supervised\nsegmentation task without manual annotations. Additionally, we propose a novel\nnetwork architecture based on parallel convolution and transformer blocks that\nis suitable to be transferred to different downstream segmentation tasks with\nvarious scales of organs and lesions. The proposed model was pretrained with\n110k unannotated 3D CT volumes, and experiments with different downstream\nsegmentation targets including head and neck organs, thoracic/abdominal organs\nshowed that our pretrained model largely outperformed training from scratch and\nseveral state-of-the-art self-supervised training methods and segmentation\nmodels. The code and pretrained model are available at\nhttps://github.com/openmedlab/MIS-FM.\n",
                "链接": "https://arxiv.org/abs/2306.16925"
            },
            {
                "文章ID": "89787",
                "标题": "Vision Language Transformers: A Survey",
                "作者": " Clayton Fields,  Casey Kennington",
                "发布日期": "2023-07-10",
                "摘要": "  Vision language tasks, such as answering questions about or generating\ncaptions that describe an image, are difficult tasks for computers to perform.\nA relatively recent body of research has adapted the pretrained transformer\narchitecture introduced in \\citet{vaswani2017attention} to vision language\nmodeling. Transformer models have greatly improved performance and versatility\nover previous vision language models. They do so by pretraining models on a\nlarge generic datasets and transferring their learning to new tasks with minor\nchanges in architecture and parameter values. This type of transfer learning\nhas become the standard modeling practice in both natural language processing\nand computer vision. Vision language transformers offer the promise of\nproducing similar advancements in tasks which require both vision and language.\nIn this paper, we provide a broad synthesis of the currently available research\non vision language transformer models and offer some analysis of their\nstrengths, limitations and some open questions that remain.\n",
                "链接": "https://arxiv.org/abs/2307.03254"
            },
            {
                "文章ID": "72325",
                "标题": "Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene\n  Understanding",
                "作者": " Yu-Qi Yang,  Yu-Xiao Guo,  Jian-Yu Xiong,  Yang Liu,  Hao Pan,  Peng-Shuai Wang,  Xin Tong,  Baining Guo",
                "发布日期": "2023-08-17",
                "摘要": "  The use of pretrained backbones with fine-tuning has been successful for 2D\nvision and natural language processing tasks, showing advantages over\ntask-specific networks. In this work, we introduce a pretrained 3D backbone,\ncalled {\\SST}, for 3D indoor scene understanding. We design a 3D Swin\ntransformer as our backbone network, which enables efficient self-attention on\nsparse voxels with linear memory complexity, making the backbone scalable to\nlarge models and datasets. We also introduce a generalized contextual relative\npositional embedding scheme to capture various irregularities of point signals\nfor improved network performance. We pretrained a large {\\SST} model on a\nsynthetic Structured3D dataset, which is an order of magnitude larger than the\nScanNet dataset. Our model pretrained on the synthetic dataset not only\ngeneralizes well to downstream segmentation and detection on real 3D point\ndatasets, but also outperforms state-of-the-art methods on downstream tasks\nwith +2.3 mIoU and +2.2 mIoU on S3DIS Area5 and 6-fold semantic segmentation,\n+1.8 mIoU on ScanNet segmentation (val), +1.9 mAP@0.5 on ScanNet detection, and\n+8.1 mAP@0.5 on S3DIS detection. A series of extensive ablation studies further\nvalidate the scalability, generality, and superior performance enabled by our\napproach. The code and models are available at\nhttps://github.com/microsoft/Swin3D .\n",
                "链接": "https://arxiv.org/abs/2304.06906"
            },
            {
                "文章ID": "117062",
                "标题": "Equipping Pretrained Unconditional Music Transformers with Instrument\n  and Genre Controls",
                "作者": " Weihan Xu,  Julian McAuley,  Shlomo Dubnov,  Hao-Wen Dong",
                "发布日期": "2023-11-22",
                "摘要": "  The ''pretraining-and-finetuning'' paradigm has become a norm for training\ndomain-specific models in natural language processing and computer vision. In\nthis work, we aim to examine this paradigm for symbolic music generation\nthrough leveraging the largest ever symbolic music dataset sourced from the\nMuseScore forum. We first pretrain a large unconditional transformer model\nusing 1.5 million songs. We then propose a simple technique to equip this\npretrained unconditional music transformer model with instrument and genre\ncontrols by finetuning the model with additional control tokens. Our proposed\nrepresentation offers improved high-level controllability and expressiveness\nagainst two existing representations. The experimental results show that the\nproposed model can successfully generate music with user-specified instruments\nand genre. In a subjective listening test, the proposed model outperforms the\npretrained baseline model in terms of coherence, harmony, arrangement and\noverall quality.\n",
                "链接": "https://arxiv.org/abs/2311.12257"
            },
            {
                "文章ID": "93080",
                "标题": "FinTree: Financial Dataset Pretrain Transformer Encoder for Relation\n  Extraction",
                "作者": " Hyunjong Ok",
                "发布日期": "2023-07-27",
                "摘要": "  We present FinTree, Financial Dataset Pretrain Transformer Encoder for\nRelation Extraction. Utilizing an encoder language model, we further pretrain\nFinTree on the financial dataset, adapting the model in financial domain tasks.\nFinTree stands out with its novel structure that predicts a masked token\ninstead of the conventional [CLS] token, inspired by the Pattern Exploiting\nTraining methodology. This structure allows for more accurate relation\npredictions between two given entities. The model is trained with a unique\ninput pattern to provide contextual and positional information about the\nentities of interest, and a post-processing step ensures accurate predictions\nin line with the entity types. Our experiments demonstrate that FinTree\noutperforms on the REFinD, a large-scale financial relation extraction dataset.\nThe code and pretrained models are available at\nhttps://github.com/HJ-Ok/FinTree.\n",
                "链接": "https://arxiv.org/abs/2307.13900"
            },
            {
                "文章ID": "79344",
                "标题": "RWKV: Reinventing RNNs for the Transformer Era",
                "作者": " Bo Peng,  Eric Alcaide,  Quentin Anthony,  Alon Albalak,  Samuel Arcadinho,  Stella Biderman,  Huanqi Cao,  Xin Cheng,  Michael Chung,  Matteo Grella,  Kranthi Kiran GV,  Xuzheng He,  Haowen Hou,  Jiaju Lin,  Przemyslaw Kazienko,  Jan Kocon,  Jiaming Kong,  Bartlomiej Koptyra,  Hayden Lau,  Krishna Sri Ipsit Mantri,  Ferdinand Mom,  Atsushi Saito,  Guangyu Song,  Xiangru Tang,  Bolun Wang,  Johan S. Wind,  Stanislaw Wozniak,  Ruichong Zhang,  Zhenyuan Zhang,  Qihang Zhao,  Peng Zhou,  Qinghua Zhou,  Jian Zhu,  Rui-Jie Zhu",
                "发布日期": "2023-12-12",
                "摘要": "  Transformers have revolutionized almost all natural language processing (NLP)\ntasks but suffer from memory and computational complexity that scales\nquadratically with sequence length. In contrast, recurrent neural networks\n(RNNs) exhibit linear scaling in memory and computational requirements but\nstruggle to match the same performance as Transformers due to limitations in\nparallelization and scalability. We propose a novel model architecture,\nReceptance Weighted Key Value (RWKV), that combines the efficient\nparallelizable training of transformers with the efficient inference of RNNs.\n  Our approach leverages a linear attention mechanism and allows us to\nformulate the model as either a Transformer or an RNN, thus parallelizing\ncomputations during training and maintains constant computational and memory\ncomplexity during inference. We scale our models as large as 14 billion\nparameters, by far the largest dense RNN ever trained, and find RWKV performs\non par with similarly sized Transformers, suggesting future work can leverage\nthis architecture to create more efficient models. This work presents a\nsignificant step towards reconciling trade-offs between computational\nefficiency and model performance in sequence processing tasks.\n",
                "链接": "https://arxiv.org/abs/2305.13048"
            },
            {
                "文章ID": "106523",
                "标题": "Procedural Text Mining with Large Language Models",
                "作者": " Anisa Rula,  Jennifer D'Souza",
                "发布日期": "2023-10-06",
                "摘要": "  Recent advancements in the field of Natural Language Processing, particularly\nthe development of large-scale language models that are pretrained on vast\namounts of knowledge, are creating novel opportunities within the realm of\nKnowledge Engineering. In this paper, we investigate the usage of large\nlanguage models (LLMs) in both zero-shot and in-context learning settings to\ntackle the problem of extracting procedures from unstructured PDF text in an\nincremental question-answering fashion. In particular, we leverage the current\nstate-of-the-art GPT-4 (Generative Pre-trained Transformer 4) model,\naccompanied by two variations of in-context learning that involve an ontology\nwith definitions of procedures and steps and a limited number of samples of\nfew-shot learning. The findings highlight both the promise of this approach and\nthe value of the in-context learning customisations. These modifications have\nthe potential to significantly address the challenge of obtaining sufficient\ntraining data, a hurdle often encountered in deep learning-based Natural\nLanguage Processing techniques for procedure extraction.\n",
                "链接": "https://arxiv.org/abs/2310.03376"
            },
            {
                "文章ID": "80004",
                "标题": "On Robustness of Finetuned Transformer-based NLP Models",
                "作者": " Pavan Kalyan Reddy Neerudu,  Subba Reddy Oota,  Mounika Marreddy,  Venkateswara Rao Kagita,  Manish Gupta",
                "发布日期": "2023-11-09",
                "摘要": "  Transformer-based pretrained models like BERT, GPT-2 and T5 have been\nfinetuned for a large number of natural language processing (NLP) tasks, and\nhave been shown to be very effective. However, while finetuning, what changes\nacross layers in these models with respect to pretrained checkpoints is\nunder-studied. Further, how robust are these models to perturbations in input\ntext? Does the robustness vary depending on the NLP task for which the models\nhave been finetuned? While there exists some work on studying the robustness of\nBERT finetuned for a few NLP tasks, there is no rigorous study that compares\nthis robustness across encoder only, decoder only and encoder-decoder models.\nIn this paper, we characterize changes between pretrained and finetuned\nlanguage model representations across layers using two metrics: CKA and STIR.\nFurther, we study the robustness of three language models (BERT, GPT-2 and T5)\nwith eight different text perturbations on classification tasks from the\nGeneral Language Understanding Evaluation (GLUE) benchmark, and generation\ntasks like summarization, free-form generation and question generation. GPT-2\nrepresentations are more robust than BERT and T5 across multiple types of input\nperturbation. Although models exhibit good robustness broadly, dropping nouns,\nverbs or changing characters are the most impactful. Overall, this study\nprovides valuable insights into perturbation-specific weaknesses of popular\nTransformer-based models, which should be kept in mind when passing inputs. We\nmake the code and models publicly available\n[https://github.com/PavanNeerudu/Robustness-of-Transformers-models].\n",
                "链接": "https://arxiv.org/abs/2305.14453"
            },
            {
                "文章ID": "91689",
                "标题": "LEST: Large-scale LiDAR Semantic Segmentation with Transformer",
                "作者": " Chuanyu Luo,  Nuo Cheng,  Sikun Ma,  Han Li,  Xiaohan Li,  Shengguang Lei,  Pu Li",
                "发布日期": "2023-07-19",
                "摘要": "  Large-scale LiDAR-based point cloud semantic segmentation is a critical task\nin autonomous driving perception. Almost all of the previous state-of-the-art\nLiDAR semantic segmentation methods are variants of sparse 3D convolution.\nAlthough the Transformer architecture is becoming popular in the field of\nnatural language processing and 2D computer vision, its application to\nlarge-scale point cloud semantic segmentation is still limited. In this paper,\nwe propose a LiDAR sEmantic Segmentation architecture with pure Transformer,\nLEST. LEST comprises two novel components: a Space Filling Curve (SFC) Grouping\nstrategy and a Distance-based Cosine Linear Transformer, DISCO. On the public\nnuScenes semantic segmentation validation set and SemanticKITTI test set, our\nmodel outperforms all the other state-of-the-art methods.\n",
                "链接": "https://arxiv.org/abs/2307.09367"
            }
        ]
    },
    {
        "question": {
            "question": "请查找关于智能体的研究进展的综述或调查论文。重点关注不同领域中智能体的方法和应用，以及相关的挑战和未来方向。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "19909",
                "标题": "Federated learning: Applications, challenges and future directions",
                "作者": " Subrato Bharati,  M. Rubaiyat Hossain Mondal,  Prajoy Podder,  V. B. Surya Prasath",
                "发布日期": "2022-06-27",
                "摘要": "  Federated learning (FL) is a system in which a central aggregator coordinates\nthe efforts of multiple clients to solve machine learning problems. This\nsetting allows training data to be dispersed in order to protect privacy. The\npurpose of this paper is to provide an overview of FL systems with a focus on\nhealthcare. FL is evaluated here based on its frameworks, architectures, and\napplications. It is shown here that FL solves the preceding issues with a\nshared global deep learning (DL) model via a central aggregator server. This\npaper examines recent developments and provides a comprehensive list of\nunresolved issues, inspired by the rapid growth of FL research. In the context\nof FL, several privacy methods are described, including secure multiparty\ncomputation, homomorphic encryption, differential privacy, and stochastic\ngradient descent. Furthermore, a review of various FL classes, such as\nhorizontal and vertical FL and federated transfer learning, is provided. FL has\napplications in wireless communication, service recommendation, intelligent\nmedical diagnosis systems, and healthcare, all of which are discussed in this\npaper. We also present a thorough review of existing FL challenges, such as\nprivacy protection, communication cost, system heterogeneity, and unreliable\nmodel upload, followed by future research directions.\n",
                "链接": "https://arxiv.org/abs/2205.09513"
            },
            {
                "文章ID": "110592",
                "标题": "Intelligent Escape of Robotic Systems: A Survey of Methodologies,\n  Applications, and Challenges",
                "作者": " Junfei Li,  Simon X. Yang",
                "发布日期": "2023-10-24",
                "摘要": "  Intelligent escape is an interdisciplinary field that employs artificial\nintelligence (AI) techniques to enable robots with the capacity to\nintelligently react to potential dangers in dynamic, intricate, and\nunpredictable scenarios. As the emphasis on safety becomes increasingly\nparamount and advancements in robotic technologies continue to advance, a wide\nrange of intelligent escape methodologies has been developed in recent years.\nThis paper presents a comprehensive survey of state-of-the-art research work on\nintelligent escape of robotic systems. Four main methods of intelligent escape\nare reviewed, including planning-based methodologies, partitioning-based\nmethodologies, learning-based methodologies, and bio-inspired methodologies.\nThe strengths and limitations of existing methods are summarized. In addition,\npotential applications of intelligent escape are discussed in various domains,\nsuch as search and rescue, evacuation, military security, and healthcare. In an\neffort to develop new approaches to intelligent escape, this survey identifies\ncurrent research challenges and provides insights into future research trends\nin intelligent escape.\n",
                "链接": "https://arxiv.org/abs/2310.14485"
            },
            {
                "文章ID": "11378",
                "标题": "Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future\n  Directions",
                "作者": " Jing Gu,  Eliana Stefani,  Qi Wu,  Jesse Thomason,  Xin Eric Wang",
                "发布日期": "2022-06-07",
                "摘要": "  A long-term goal of AI research is to build intelligent agents that can\ncommunicate with humans in natural language, perceive the environment, and\nperform real-world tasks. Vision-and-Language Navigation (VLN) is a fundamental\nand interdisciplinary research topic towards this goal, and receives increasing\nattention from natural language processing, computer vision, robotics, and\nmachine learning communities. In this paper, we review contemporary studies in\nthe emerging field of VLN, covering tasks, evaluation metrics, methods, etc.\nThrough structured analysis of current progress and challenges, we highlight\nthe limitations of current VLN and opportunities for future work. This paper\nserves as a thorough reference for the VLN research community.\n",
                "链接": "https://arxiv.org/abs/2203.12667"
            },
            {
                "文章ID": "36627",
                "标题": "Metaverse for Healthcare: A Survey on Potential Applications, Challenges\n  and Future Directions",
                "作者": " Rajeswari Chengoden,  Nancy Victor,  Thien Huynh-The,  Gokul Yenduri,  Rutvij H. Jhaveri,  Mamoun Alazab,  Sweta Bhattacharya,  Pawan Hegde,  Praveen Kumar Reddy Maddikunta,  Thippa Reddy Gadekallu",
                "发布日期": "2022-09-12",
                "摘要": "  The rapid progress in digitalization and automation have led to an\naccelerated growth in healthcare, generating novel models that are creating new\nchannels for rendering treatment with reduced cost. The Metaverse is an\nemerging technology in the digital space which has huge potential in\nhealthcare, enabling realistic experiences to the patients as well as the\nmedical practitioners. The Metaverse is a confluence of multiple enabling\ntechnologies such as artificial intelligence, virtual reality, augmented\nreality, internet of medical devices, robotics, quantum computing, etc. through\nwhich new directions for providing quality healthcare treatment and services\ncan be explored. The amalgamation of these technologies ensures immersive,\nintimate and personalized patient care. It also provides adaptive intelligent\nsolutions that eliminates the barriers between healthcare providers and\nreceivers. This article provides a comprehensive review of the Metaverse for\nhealthcare, emphasizing on the state of the art, the enabling technologies for\nadopting the Metaverse for healthcare, the potential applications and the\nrelated projects. The issues in the adaptation of the Metaverse for healthcare\napplications are also identified and the plausible solutions are highlighted as\npart of future research directions.\n",
                "链接": "https://arxiv.org/abs/2209.04160"
            },
            {
                "文章ID": "86534",
                "标题": "Advancing Biomedicine with Graph Representation Learning: Recent\n  Progress, Challenges, and Future Directions",
                "作者": " Fang Li,  Yi Nian,  Zenan Sun,  Cui Tao",
                "发布日期": "2023-06-22",
                "摘要": "  Graph representation learning (GRL) has emerged as a pivotal field that has\ncontributed significantly to breakthroughs in various fields, including\nbiomedicine. The objective of this survey is to review the latest advancements\nin GRL methods and their applications in the biomedical field. We also\nhighlight key challenges currently faced by GRL and outline potential\ndirections for future research.\n",
                "链接": "https://arxiv.org/abs/2306.10456"
            },
            {
                "文章ID": "16032",
                "标题": "Creative Problem Solving in Artificially Intelligent Agents: A Survey\n  and Framework",
                "作者": " Evana Gizzi,  Lakshmi Nair,  Sonia Chernova,  Jivko Sinapov",
                "发布日期": "2022-12-15",
                "摘要": "  Creative Problem Solving (CPS) is a sub-area within Artificial Intelligence\n(AI) that focuses on methods for solving off-nominal, or anomalous problems in\nautonomous systems. Despite many advancements in planning and learning,\nresolving novel problems or adapting existing knowledge to a new context,\nespecially in cases where the environment may change in unpredictable ways post\ndeployment, remains a limiting factor in the safe and useful integration of\nintelligent systems. The emergence of increasingly autonomous systems dictates\nthe necessity for AI agents to deal with environmental uncertainty through\ncreativity. To stimulate further research in CPS, we present a definition and a\nframework of CPS, which we adopt to categorize existing AI methods in this\nfield. Our framework consists of four main components of a CPS problem, namely,\n1) problem formulation, 2) knowledge representation, 3) method of knowledge\nmanipulation, and 4) method of evaluation. We conclude our survey with open\nresearch questions, and suggested directions for the future.\n",
                "链接": "https://arxiv.org/abs/2204.10358"
            },
            {
                "文章ID": "55278",
                "标题": "A Survey on Table-and-Text HybridQA: Concepts, Methods, Challenges and\n  Future Directions",
                "作者": " Dingzirui Wang,  Longxu Dou,  Wanxiang Che",
                "发布日期": "2023-02-03",
                "摘要": "  Table-and-text hybrid question answering (HybridQA) is a widely used and\nchallenging NLP task commonly applied in the financial and scientific domain.\nThe early research focuses on migrating other QA task methods to HybridQA,\nwhile with further research, more and more HybridQA-specific methods have been\npresent. With the rapid development of HybridQA, the systematic survey is still\nunder-explored to summarize the main techniques and advance further research.\nSo we present this work to summarize the current HybridQA benchmarks and\nmethods, then analyze the challenges and future directions of this task. The\ncontributions of this paper can be summarized in three folds: (1) first survey,\nto our best knowledge, including benchmarks, methods and challenges for\nHybridQA; (2) systematic investigation with the reasonable comparison of the\nexisting systems to articulate their advantages and shortcomings; (3) detailed\nanalysis of challenges in four important dimensions to shed light on future\ndirections.\n",
                "链接": "https://arxiv.org/abs/2212.13465"
            },
            {
                "文章ID": "49513",
                "标题": "Intelligent Computing: The Latest Advances, Challenges and Future",
                "作者": " Shiqiang Zhu,  Ting Yu,  Tao Xu,  Hongyang Chen,  Schahram Dustdar,  Sylvain Gigan,  Deniz Gunduz,  Ekram Hossain,  Yaochu Jin,  Feng Lin,  Bo Liu,  Zhiguo Wan,  Ji Zhang,  Zhifeng Zhao,  Wentao Zhu,  Zuoning Chen,  Tariq Durrani,  Huaimin Wang,  Jiangxing Wu,  Tongyi Zhang,  Yunhe Pan",
                "发布日期": "2022-11-22",
                "摘要": "  Computing is a critical driving force in the development of human\ncivilization. In recent years, we have witnessed the emergence of intelligent\ncomputing, a new computing paradigm that is reshaping traditional computing and\npromoting digital revolution in the era of big data, artificial intelligence\nand internet-of-things with new computing theories, architectures, methods,\nsystems, and applications. Intelligent computing has greatly broadened the\nscope of computing, extending it from traditional computing on data to\nincreasingly diverse computing paradigms such as perceptual intelligence,\ncognitive intelligence, autonomous intelligence, and human-computer fusion\nintelligence. Intelligence and computing have undergone paths of different\nevolution and development for a long time but have become increasingly\nintertwined in recent years: intelligent computing is not only\nintelligence-oriented but also intelligence-driven. Such cross-fertilization\nhas prompted the emergence and rapid advancement of intelligent computing.\nIntelligent computing is still in its infancy and an abundance of innovations\nin the theories, systems, and applications of intelligent computing are\nexpected to occur soon. We present the first comprehensive survey of literature\non intelligent computing, covering its theory fundamentals, the technological\nfusion of intelligence and computing, important applications, challenges, and\nfuture perspectives. We believe that this survey is highly timely and will\nprovide a comprehensive reference and cast valuable insights into intelligent\ncomputing for academic and industrial researchers and practitioners.\n",
                "链接": "https://arxiv.org/abs/2211.11281"
            },
            {
                "文章ID": "123433",
                "标题": "A review of federated learning in renewable energy applications:\n  Potential, challenges, and future directions",
                "作者": " Albin Grataloup,  Stefan Jonas,  Angela Meyer",
                "发布日期": "2023-12-19",
                "摘要": "  Federated learning has recently emerged as a privacy-preserving distributed\nmachine learning approach. Federated learning enables collaborative training of\nmultiple clients and entire fleets without sharing the involved training\ndatasets. By preserving data privacy, federated learning has the potential to\novercome the lack of data sharing in the renewable energy sector which is\ninhibiting innovation, research and development. Our paper provides an overview\nof federated learning in renewable energy applications. We discuss federated\nlearning algorithms and survey their applications and case studies in renewable\nenergy generation and consumption. We also evaluate the potential and the\nchallenges associated with federated learning applied in power and energy\ncontexts. Finally, we outline promising future research directions in federated\nlearning for applications in renewable energy.\n",
                "链接": "https://arxiv.org/abs/2312.11220"
            },
            {
                "文章ID": "68556",
                "标题": "TinyML: Tools, Applications, Challenges, and Future Research Directions",
                "作者": " Rakhee Kallimani,  Krishna Pai,  Prasoon Raghuwanshi,  Sridhar Iyer,  Onel L. A. López",
                "发布日期": "2023-09-08",
                "摘要": "  In recent years, Artificial Intelligence (AI) and Machine learning (ML) have\ngained significant interest from both, industry and academia. Notably,\nconventional ML techniques require enormous amounts of power to meet the\ndesired accuracy, which has limited their use mainly to high-capability devices\nsuch as network nodes. However, with many advancements in technologies such as\nthe Internet of Things (IoT) and edge computing, it is desirable to incorporate\nML techniques into resource-constrained embedded devices for distributed and\nubiquitous intelligence. This has motivated the emergence of the TinyML\nparadigm which is an embedded ML technique that enables ML applications on\nmultiple cheap, resource- and power-constrained devices. However, during this\ntransition towards appropriate implementation of the TinyML technology,\nmultiple challenges such as processing capacity optimization, improved\nreliability, and maintenance of learning models' accuracy require timely\nsolutions. In this article, various avenues available for TinyML implementation\nare reviewed. Firstly, a background of TinyML is provided, followed by detailed\ndiscussions on various tools supporting TinyML. Then, state-of-art applications\nof TinyML using advanced technologies are detailed. Lastly, various research\nchallenges and future directions are identified.\n",
                "链接": "https://arxiv.org/abs/2303.13569"
            }
        ]
    }
]