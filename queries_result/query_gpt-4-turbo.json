[
    {
        "question": {
            "question": "与大模型工具学习相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "104308",
                "标题": "People's Perceptions Toward Bias and Related Concepts in Large Language\n  Models: A Systematic Review",
                "作者": " Lu Wang,  Max Song,  Rezvaneh Rezapour,  Bum Chul Kwon,  Jina Huh-Yoo",
                "发布日期": "2023-09-27",
                "摘要": "  Large language models (LLMs) have brought breakthroughs in tasks including\ntranslation, summarization, information retrieval, and language generation,\ngaining growing interest in the CHI community. Meanwhile, the literature shows\nresearchers' controversial perceptions about the efficacy, ethics, and\nintellectual abilities of LLMs. However, we do not know how lay people perceive\nLLMs that are pervasive in everyday tools, specifically regarding their\nexperience with LLMs around bias, stereotypes, social norms, or safety. In this\nstudy, we conducted a systematic review to understand what empirical insights\npapers have gathered about people's perceptions toward LLMs. From a total of\n231 retrieved papers, we full-text reviewed 15 papers that recruited human\nevaluators to assess their experiences with LLMs. We report different biases\nand related concepts investigated by these studies, four broader LLM\napplication areas, the evaluators' perceptions toward LLMs' performances\nincluding advantages, biases, and conflicting perceptions, factors influencing\nthese perceptions, and concerns about LLM applications.\n",
                "链接": "https://arxiv.org/abs/2309.14504"
            },
            {
                "文章ID": "95587",
                "标题": "NLLG Quarterly arXiv Report 06/23: What are the most influential current\n  AI Papers?",
                "作者": " Steffen Eger,  Christoph Leiter,  Jonas Belouadi,  Ran Zhang,  Aida Kostikova,  Daniil Larionov,  Yanran Chen,  Vivian Fresen",
                "发布日期": "2023-08-15",
                "摘要": "  The rapid growth of information in the field of Generative Artificial\nIntelligence (AI), particularly in the subfields of Natural Language Processing\n(NLP) and Machine Learning (ML), presents a significant challenge for\nresearchers and practitioners to keep pace with the latest developments. To\naddress the problem of information overload, this report by the Natural\nLanguage Learning Group at Bielefeld University focuses on identifying the most\npopular papers on arXiv, with a specific emphasis on NLP and ML. The objective\nis to offer a quick guide to the most relevant and widely discussed research,\naiding both newcomers and established researchers in staying abreast of current\ntrends. In particular, we compile a list of the 40 most popular papers based on\nnormalized citation counts from the first half of 2023. We observe the\ndominance of papers related to Large Language Models (LLMs) and specifically\nChatGPT during the first half of 2023, with the latter showing signs of\ndeclining popularity more recently, however. Further, NLP related papers are\nthe most influential (around 60\\% of top papers) even though there are twice as\nmany ML related papers in our data. Core issues investigated in the most\nheavily cited papers are: LLM efficiency, evaluation techniques, ethical\nconsiderations, embodied agents, and problem-solving with LLMs. Additionally,\nwe examine the characteristics of top papers in comparison to others outside\nthe top-40 list (noticing the top paper's focus on LLM related issues and\nhigher number of co-authors) and analyze the citation distributions in our\ndataset, among others.\n",
                "链接": "https://arxiv.org/abs/2308.04889"
            },
            {
                "文章ID": "65994",
                "标题": "An Interactive UI to Support Sensemaking over Collections of Parallel\n  Texts",
                "作者": " Joyce Zhou,  Elena Glassman,  Daniel S. Weld",
                "发布日期": "2023-03-14",
                "摘要": "  Scientists and science journalists, among others, often need to make sense of\na large number of papers and how they compare with each other in scope, focus,\nfindings, or any other important factors. However, with a large corpus of\npapers, it's cognitively demanding to pairwise compare and contrast them all\nwith each other. Fully automating this review process would be infeasible,\nbecause it often requires domain-specific knowledge, as well as understanding\nwhat the context and motivations for the review are. While there are existing\ntools to help with the process of organizing and annotating papers for\nliterature reviews, at the core they still rely on people to serially read\nthrough papers and manually make sense of relevant information.\n  We present AVTALER, which combines peoples' unique skills, contextual\nawareness, and knowledge, together with the strength of automation. Given a set\nof comparable text excerpts from a paper corpus, it supports users in\nsensemaking and contrasting paper attributes by interactively aligning text\nexcerpts in a table so that comparable details are presented in a shared\ncolumn. AVTALER is based on a core alignment algorithm that makes use of modern\nNLP tools. Furthermore, AVTALER is a mixed-initiative system: users can\ninteractively give the system constraints which are integrated into the\nalignment construction process.\n",
                "链接": "https://arxiv.org/abs/2303.06264"
            },
            {
                "文章ID": "83968",
                "标题": "SciLit: A Platform for Joint Scientific Literature Discovery,\n  Summarization and Citation Generation",
                "作者": " Nianlong Gu,  Richard H. R. Hahnloser",
                "发布日期": "2023-11-07",
                "摘要": "  Scientific writing involves retrieving, summarizing, and citing relevant\npapers, which can be time-consuming processes in large and rapidly evolving\nfields. By making these processes inter-operable, natural language processing\n(NLP) provides opportunities for creating end-to-end assistive writing tools.\nWe propose SciLit, a pipeline that automatically recommends relevant papers,\nextracts highlights, and suggests a reference sentence as a citation of a\npaper, taking into consideration the user-provided context and keywords. SciLit\nefficiently recommends papers from large databases of hundreds of millions of\npapers using a two-stage pre-fetching and re-ranking literature search system\nthat flexibly deals with addition and removal of a paper database. We provide a\nconvenient user interface that displays the recommended papers as extractive\nsummaries and that offers abstractively-generated citing sentences which are\naligned with the provided context and which mention the chosen keyword(s). Our\nassistive tool for literature discovery and scientific writing is available at\nhttps://scilit.vercel.app\n",
                "链接": "https://arxiv.org/abs/2306.03535"
            },
            {
                "文章ID": "7420",
                "标题": "Did AI get more negative recently?",
                "作者": " Dominik Beese,  Begüm Altunbaş,  Görkem Güzeler,  Steffen Eger",
                "发布日期": "2023-06-30",
                "摘要": "  In this paper, we classify scientific articles in the domain of natural\nlanguage processing (NLP) and machine learning (ML), as core subfields of\nartificial intelligence (AI), into whether (i) they extend the current\nstate-of-the-art by the introduction of novel techniques which beat existing\nmodels or whether (ii) they mainly criticize the existing state-of-the-art,\ni.e. that it is deficient with respect to some property (e.g. wrong evaluation,\nwrong datasets, misleading task specification). We refer to contributions under\n(i) as having a 'positive stance' and contributions under (ii) as having a\n'negative stance' (to related work). We annotate over 1.5 k papers from NLP and\nML to train a SciBERT-based model to automatically predict the stance of a\npaper based on its title and abstract. We then analyse large-scale trends on\nover 41 k papers from the last approximately 35 years in NLP and ML, finding\nthat papers have become substantially more positive over time, but negative\npapers also got more negative and we observe considerably more negative papers\nin recent years. Negative papers are also more influential in terms of\ncitations they receive.\n",
                "链接": "https://arxiv.org/abs/2202.13610"
            },
            {
                "文章ID": "26216",
                "标题": "How Does Automation Shape the Process of Narrative Visualization: A\n  Survey of Tools",
                "作者": " Qing Chen,  Shixiong Cao,  Jiazhe Wang,  Nan Cao",
                "发布日期": "2023-03-23",
                "摘要": "  In recent years, narrative visualization has gained much attention.\nResearchers have proposed different design spaces for various narrative\nvisualization genres and scenarios to facilitate the creation process. As\nusers' needs grow and automation technologies advance, increasingly more tools\nhave been designed and developed. In this study, we summarized six genres of\nnarrative visualization (annotated charts, infographics, timelines &\nstorylines, data comics, scrollytelling & slideshow, and data videos) based on\nprevious research and four types of tools (design spaces, authoring tools,\nML/AI-supported tools and ML/AI-generator tools) based on the intelligence and\nautomation level of the tools. We surveyed 105 papers and tools to study how\nautomation can progressively engage in visualization design and narrative\nprocesses to help users easily create narrative visualizations. This research\naims to provide an overview of current research and development in the\nautomation involvement of narrative visualization tools. We discuss key\nresearch problems in each category and suggest new opportunities to encourage\nfurther research in the related domain.\n",
                "链接": "https://arxiv.org/abs/2206.12118"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "42554",
                "标题": "Machine Learning vs. Deep Learning in 5G Networks -- A Comparison of\n  Scientific Impact",
                "作者": " Ilker Turker,  Serhat Orkun Tan",
                "发布日期": "2022-10-17",
                "摘要": "  Introduction of fifth generation (5G) wireless network technology has matched\nthe crucial need for high capacity and speed needs of the new generation mobile\napplications. Recent advances in Artificial Intelligence (AI) also empowered 5G\ncellular networks with two mainstreams as machine learning (ML) and deep\nlearning (DL) techniques. Our study aims to uncover the differences in\nscientific impact for these two techniques by the means of statistical\nbibliometrics. The performed analysis includes citation performance with\nrespect to indexing types, funding availability, journal or conference\npublishing options together with distributions of these metrics along years to\nevaluate the popularity trends in a detailed manner. Web of Science (WoS)\ndatabase host 2245 papers for ML and 1407 papers for DL-related studies. DL\nstudies, starting with 9% rate in 2013, has reached to 45% rate in 2022 among\nall DL and ML-related studies. Results related to scientific impact indicate\nthat DL studies get slightly more average normalized citation (2.256) compared\nto ML studies (2.118) in 5G, while SCI-Expanded indexed papers in both sides\ntend to have similar citation performance (3.165 and 3.162 respectively).\nML-related studies those are indexed in ESCI show twice citation performance\ncompared to DL. Conference papers in DL domain and journal papers in ML domain\nare superior in scientific interest to their counterparts with minor\ndifferences. Highest citation performance for ML studies is achieved for year\n2014, while this peak is observed for 2017 for DL studies. We can conclude that\nboth publication and citation rate for DL-related papers tend to increase and\noutperform ML-based studies in 5G domain by the means of citation metrics.\n",
                "链接": "https://arxiv.org/abs/2210.07327"
            },
            {
                "文章ID": "32433",
                "标题": "Threddy: An Interactive System for Personalized Thread-based Exploration\n  and Organization of Scientific Literature",
                "作者": " Hyeonsu B. Kang,  Joseph Chee Chang,  Yongsung Kim,  Aniket Kittur",
                "发布日期": "2022-08-17",
                "摘要": "  Reviewing the literature to understand relevant threads of past work is a\ncritical part of research and vehicle for learning. However, as the scientific\nliterature grows the challenges for users to find and make sense of the many\ndifferent threads of research grow as well. Previous work has helped scholars\nto find and group papers with citation information or textual similarity using\nstandalone tools or overview visualizations. Instead, in this work we explore a\ntool integrated into users' reading process that helps them with leveraging\nauthors' existing summarization of threads, typically in introduction or\nrelated work sections, in order to situate their own work's contributions. To\nexplore this we developed a prototype that supports efficient extraction and\norganization of threads along with supporting evidence as scientists read\nresearch articles. The system then recommends further relevant articles based\non user-created threads. We evaluate the system in a lab study and find that it\nhelps scientists to follow and curate research threads without breaking out of\ntheir flow of reading, collect relevant papers and clips, and discover\ninteresting new articles to further grow threads.\n",
                "链接": "https://arxiv.org/abs/2208.03455"
            },
            {
                "文章ID": "21348",
                "标题": "Target-aware Abstractive Related Work Generation with Contrastive\n  Learning",
                "作者": " Xiuying Chen,  Hind Alamro,  Mingzhe Li,  Shen Gao,  Rui Yan,  Xin Gao,  Xiangliang Zhang",
                "发布日期": "2022-05-27",
                "摘要": "  The related work section is an important component of a scientific paper,\nwhich highlights the contribution of the target paper in the context of the\nreference papers. Authors can save their time and effort by using the\nautomatically generated related work section as a draft to complete the final\nrelated work. Most of the existing related work section generation methods rely\non extracting off-the-shelf sentences to make a comparative discussion about\nthe target work and the reference papers. However, such sentences need to be\nwritten in advance and are hard to obtain in practice. Hence, in this paper, we\npropose an abstractive target-aware related work generator (TAG), which can\ngenerate related work sections consisting of new sentences. Concretely, we\nfirst propose a target-aware graph encoder, which models the relationships\nbetween reference papers and the target paper with target-centered attention\nmechanisms. In the decoding process, we propose a hierarchical decoder that\nattends to the nodes of different levels in the graph with keyphrases as\nsemantic indicators. Finally, to generate a more informative related work, we\npropose multi-level contrastive optimization objectives, which aim to maximize\nthe mutual information between the generated related work with the references\nand minimize that with non-references. Extensive experiments on two public\nscholar datasets show that the proposed model brings substantial improvements\nover several strong baselines in terms of automatic and tailored human\nevaluations.\n",
                "链接": "https://arxiv.org/abs/2205.13339"
            }
        ]
    },
    {
        "question": {
            "question": "和大模型可解释相关的最新论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "115222",
                "标题": "Assessing the Interpretability of Programmatic Policies with Large\n  Language Models",
                "作者": " Zahra Bashir,  Michael Bowling,  Levi H. S. Lelis",
                "发布日期": "2023-11-14",
                "摘要": "  Although the synthesis of programs encoding policies often carries the\npromise of interpretability, systematic evaluations to assess the\ninterpretability of these policies were never performed, likely because of the\ncomplexity of such an evaluation. In this paper, we introduce a novel metric\nthat uses large-language models (LLM) to assess the interpretability of\nprogrammatic policies. For our metric, an LLM is given both a program and a\ndescription of its associated programming language. The LLM then formulates a\nnatural language explanation of the program. This explanation is subsequently\nfed into a second LLM, which tries to reconstruct the program from the natural\nlanguage explanation. Our metric measures the behavioral similarity between the\nreconstructed program and the original. We validate our approach using\nobfuscated programs that are used to solve classic programming problems. We\nalso assess our metric with programmatic policies synthesized for playing a\nreal-time strategy game, comparing the interpretability scores of programmatic\npolicies synthesized by an existing system to lightly obfuscated versions of\nthe same programs. Our LLM-based interpretability score consistently ranks less\ninterpretable programs lower and more interpretable ones higher. These findings\nsuggest that our metric could serve as a reliable and inexpensive tool for\nevaluating the interpretability of programmatic policies.\n",
                "链接": "https://arxiv.org/abs/2311.06979"
            },
            {
                "文章ID": "116604",
                "标题": "RecExplainer: Aligning Large Language Models for Recommendation Model\n  Interpretability",
                "作者": " Yuxuan Lei,  Jianxun Lian,  Jing Yao,  Xu Huang,  Defu Lian,  Xing Xie",
                "发布日期": "2023-11-21",
                "摘要": "  Recommender systems are widely used in various online services, with\nembedding-based models being particularly popular due to their expressiveness\nin representing complex signals. However, these models often lack\ninterpretability, making them less reliable and transparent for both users and\ndevelopers. With the emergence of large language models (LLMs), we find that\ntheir capabilities in language expression, knowledge-aware reasoning, and\ninstruction following are exceptionally powerful. Based on this, we propose a\nnew model interpretation approach for recommender systems, by using LLMs as\nsurrogate models and learn to mimic and comprehend target recommender models.\nSpecifically, we introduce three alignment methods: behavior alignment,\nintention alignment, and hybrid alignment. Behavior alignment operates in the\nlanguage space, representing user preferences and item information as text to\nlearn the recommendation model's behavior; intention alignment works in the\nlatent space of the recommendation model, using user and item representations\nto understand the model's behavior; hybrid alignment combines both language and\nlatent spaces for alignment training. To demonstrate the effectiveness of our\nmethods, we conduct evaluation from two perspectives: alignment effect, and\nexplanation generation ability on three public datasets. Experimental results\nindicate that our approach effectively enables LLMs to comprehend the patterns\nof recommendation models and generate highly credible recommendation\nexplanations.\n",
                "链接": "https://arxiv.org/abs/2311.10947"
            },
            {
                "文章ID": "120483",
                "标题": "FlexModel: A Framework for Interpretability of Distributed Large\n  Language Models",
                "作者": " Matthew Choi,  Muhammad Adil Asif,  John Willes,  David Emerson",
                "发布日期": "2023-12-07",
                "摘要": "  With the growth of large language models, now incorporating billions of\nparameters, the hardware prerequisites for their training and deployment have\nseen a corresponding increase. Although existing tools facilitate model\nparallelization and distributed training, deeper model interactions, crucial\nfor interpretability and responsible AI techniques, still demand thorough\nknowledge of distributed computing. This often hinders contributions from\nresearchers with machine learning expertise but limited distributed computing\nbackground. Addressing this challenge, we present FlexModel, a software package\nproviding a streamlined interface for engaging with models distributed across\nmulti-GPU and multi-node configurations. The library is compatible with\nexisting model distribution libraries and encapsulates PyTorch models. It\nexposes user-registerable HookFunctions to facilitate straightforward\ninteraction with distributed model internals, bridging the gap between\ndistributed and single-device model paradigms. Primarily, FlexModel enhances\naccessibility by democratizing model interactions and promotes more inclusive\nresearch in the domain of large-scale neural networks. The package is found at\nhttps://github.com/VectorInstitute/flex_model.\n",
                "链接": "https://arxiv.org/abs/2312.03140"
            },
            {
                "文章ID": "90462",
                "标题": "Scale Alone Does not Improve Mechanistic Interpretability in Vision\n  Models",
                "作者": " Roland S. Zimmermann,  Thomas Klein,  Wieland Brendel",
                "发布日期": "2023-07-12",
                "摘要": "  In light of the recent widespread adoption of AI systems, understanding the\ninternal information processing of neural networks has become increasingly\ncritical. Most recently, machine vision has seen remarkable progress by scaling\nneural networks to unprecedented levels in dataset and model size. We here ask\nwhether this extraordinary increase in scale also positively impacts the field\nof mechanistic interpretability. In other words, has our understanding of the\ninner workings of scaled neural networks improved as well? We here use a\npsychophysical paradigm to quantify mechanistic interpretability for a diverse\nsuite of models and find no scaling effect for interpretability - neither for\nmodel nor dataset size. Specifically, none of the nine investigated\nstate-of-the-art models are easier to interpret than the GoogLeNet model from\nalmost a decade ago. Latest-generation vision models appear even less\ninterpretable than older architectures, hinting at a regression rather than\nimprovement, with modern models sacrificing interpretability for accuracy.\nThese results highlight the need for models explicitly designed to be\nmechanistically interpretable and the need for more helpful interpretability\nmethods to increase our understanding of networks at an atomic level. We\nrelease a dataset containing more than 120'000 human responses from our\npsychophysical evaluation of 767 units across nine models. This dataset is\nmeant to facilitate research on automated instead of human-based\ninterpretability evaluations that can ultimately be leveraged to directly\noptimize the mechanistic interpretability of models.\n",
                "链接": "https://arxiv.org/abs/2307.05471"
            },
            {
                "文章ID": "113521",
                "标题": "Proto-lm: A Prototypical Network-Based Framework for Built-in\n  Interpretability in Large Language Models",
                "作者": " Sean Xie,  Soroush Vosoughi,  Saeed Hassanpour",
                "发布日期": "2023-11-14",
                "摘要": "  Large Language Models (LLMs) have significantly advanced the field of Natural\nLanguage Processing (NLP), but their lack of interpretability has been a major\nconcern. Current methods for interpreting LLMs are post hoc, applied after\ninference time, and have limitations such as their focus on low-level features\nand lack of explainability at higher level text units. In this work, we\nintroduce proto-lm, a prototypical network-based white-box framework that\nallows LLMs to learn immediately interpretable embeddings during the\nfine-tuning stage while maintaining competitive performance. Our method's\napplicability and interpretability are demonstrated through experiments on a\nwide range of NLP tasks, and our results indicate a new possibility of creating\ninterpretable models without sacrificing performance. This novel approach to\ninterpretability in LLMs can pave the way for more interpretable models without\nthe need to sacrifice performance.\n",
                "链接": "https://arxiv.org/abs/2311.01732"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            },
            {
                "文章ID": "83206",
                "标题": "XAI Renaissance: Redefining Interpretability in Medical Diagnostic\n  Models",
                "作者": " Sujith K Mandala",
                "发布日期": "2023-06-05",
                "摘要": "  As machine learning models become increasingly prevalent in medical\ndiagnostics, the need for interpretability and transparency becomes paramount.\nThe XAI Renaissance signifies a significant shift in the field, aiming to\nredefine the interpretability of medical diagnostic models. This paper explores\nthe innovative approaches and methodologies within the realm of Explainable AI\n(XAI) that are revolutionizing the interpretability of medical diagnostic\nmodels. By shedding light on the underlying decision-making process, XAI\ntechniques empower healthcare professionals to understand, trust, and\neffectively utilize these models for accurate and reliable medical diagnoses.\nThis review highlights the key advancements in XAI for medical diagnostics and\ntheir potential to transform the healthcare landscape, ultimately improving\npatient outcomes and fostering trust in AI-driven diagnostic systems.\n",
                "链接": "https://arxiv.org/abs/2306.01668"
            },
            {
                "文章ID": "124419",
                "标题": "Don't Believe Everything You Read: Enhancing Summarization\n  Interpretability through Automatic Identification of Hallucinations in Large\n  Language Models",
                "作者": " Priyesh Vakharia,  Devavrat Joshi,  Meenal Chavan,  Dhananjay Sonawane,  Bhrigu Garg,  Parsa Mazaheri,  Ian Lane",
                "发布日期": "2023-12-25",
                "摘要": "  Large Language Models (LLMs) are adept at text manipulation -- tasks such as\nmachine translation and text summarization. However, these models can also be\nprone to hallucination, which can be detrimental to the faithfulness of any\nanswers that the model provides. Recent works in combating hallucinations in\nLLMs deal with identifying hallucinated sentences and categorizing the\ndifferent ways in which models hallucinate. This paper takes a deep dive into\nLLM behavior with respect to hallucinations, defines a token-level approach to\nidentifying different kinds of hallucinations, and further utilizes this\ntoken-level tagging to improve the interpretability and faithfulness of LLMs in\ndialogue summarization tasks. Through this, the paper presents a new, enhanced\ndataset and a new training paradigm.\n",
                "链接": "https://arxiv.org/abs/2312.14346"
            },
            {
                "文章ID": "117394",
                "标题": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
                "作者": " Chengyu Wang,  Junbing Yan,  Wei Zhang,  Jun Huang",
                "发布日期": "2023-11-23",
                "摘要": "  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.13126"
            },
            {
                "文章ID": "57159",
                "标题": "Generalized Neural Closure Models with Interpretability",
                "作者": " Abhinav Gupta,  Pierre F. J. Lermusiaux",
                "发布日期": "2023-05-19",
                "摘要": "  Improving the predictive capability and computational cost of dynamical\nmodels is often at the heart of augmenting computational physics with machine\nlearning (ML). However, most learning results are limited in interpretability\nand generalization over different computational grid resolutions, initial and\nboundary conditions, domain geometries, and physical or problem-specific\nparameters. In the present study, we simultaneously address all these\nchallenges by developing the novel and versatile methodology of unified neural\npartial delay differential equations. We augment existing/low-fidelity\ndynamical models directly in their partial differential equation (PDE) forms\nwith both Markovian and non-Markovian neural network (NN) closure\nparameterizations. The melding of the existing models with NNs in the\ncontinuous spatiotemporal space followed by numerical discretization\nautomatically allows for the desired generalizability. The Markovian term is\ndesigned to enable extraction of its analytical form and thus provides\ninterpretability. The non-Markovian terms allow accounting for inherently\nmissing time delays needed to represent the real world. We obtain adjoint PDEs\nin the continuous form, thus enabling direct implementation across\ndifferentiable and non-differentiable computational physics codes, different ML\nframeworks, and treatment of nonuniformly-spaced spatiotemporal training data.\nWe demonstrate the new generalized neural closure models (gnCMs) framework\nusing four sets of experiments based on advecting nonlinear waves, shocks, and\nocean acidification models. Our learned gnCMs discover missing physics, find\nleading numerical error terms, discriminate among candidate functional forms in\nan interpretable fashion, achieve generalization, and compensate for the lack\nof complexity in simpler models. Finally, we analyze the computational\nadvantages of our new framework.\n",
                "链接": "https://arxiv.org/abs/2301.06198"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于大模型Agent应用的最新发表论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "112858",
                "标题": "Linked Papers With Code: The Latest in Machine Learning as an RDF\n  Knowledge Graph",
                "作者": " Michael Färber,  David Lamprecht",
                "发布日期": "2023-11-01",
                "摘要": "  In this paper, we introduce Linked Papers With Code (LPWC), an RDF knowledge\ngraph that provides comprehensive, current information about almost 400,000\nmachine learning publications. This includes the tasks addressed, the datasets\nutilized, the methods implemented, and the evaluations conducted, along with\ntheir results. Compared to its non-RDF-based counterpart Papers With Code, LPWC\nnot only translates the latest advancements in machine learning into RDF\nformat, but also enables novel ways for scientific impact quantification and\nscholarly key content recommendation. LPWC is openly accessible at\nhttps://linkedpaperswithcode.com and is licensed under CC-BY-SA 4.0. As a\nknowledge graph in the Linked Open Data cloud, we offer LPWC in multiple\nformats, from RDF dump files to a SPARQL endpoint for direct web queries, as\nwell as a data source with resolvable URIs and links to the data sources\nSemOpenAlex, Wikidata, and DBLP. Additionally, we supply knowledge graph\nembeddings, enabling LPWC to be readily applied in machine learning\napplications.\n",
                "链接": "https://arxiv.org/abs/2310.20475"
            },
            {
                "文章ID": "112845",
                "标题": "Analyzing the Impact of Companies on AI Research Based on Publications",
                "作者": " Michael Färber,  Lazaros Tampakis",
                "发布日期": "2023-11-01",
                "摘要": "  Artificial Intelligence (AI) is one of the most momentous technologies of our\ntime. Thus, it is of major importance to know which stakeholders influence AI\nresearch. Besides researchers at universities and colleges, researchers in\ncompanies have hardly been considered in this context. In this article, we\nconsider how the influence of companies on AI research can be made measurable\non the basis of scientific publishing activities. We compare academic- and\ncompany-authored AI publications published in the last decade and use\nscientometric data from multiple scholarly databases to look for differences\nacross these groups and to disclose the top contributing organizations. While\nthe vast majority of publications is still produced by academia, we find that\nthe citation count an individual publication receives is significantly higher\nwhen it is (co-)authored by a company. Furthermore, using a variety of\naltmetric indicators, we notice that publications with company participation\nreceive considerably more attention online. Finally, we place our analysis\nresults in a broader context and present targeted recommendations to safeguard\na harmonious balance between academia and industry in the realm of AI research.\n",
                "链接": "https://arxiv.org/abs/2310.20444"
            },
            {
                "文章ID": "123234",
                "标题": "HyperPIE: Hyperparameter Information Extraction from Scientific\n  Publications",
                "作者": " Tarek Saier,  Mayumi Ohta,  Takuto Asakura,  Michael Färber",
                "发布日期": "2023-12-19",
                "摘要": "  Automatic extraction of information from publications is key to making\nscientific knowledge machine readable at a large scale. The extracted\ninformation can, for example, facilitate academic search, decision making, and\nknowledge graph construction. An important type of information not covered by\nexisting approaches is hyperparameters. In this paper, we formalize and tackle\nhyperparameter information extraction (HyperPIE) as an entity recognition and\nrelation extraction task. We create a labeled data set covering publications\nfrom a variety of computer science disciplines. Using this data set, we train\nand evaluate BERT-based fine-tuned models as well as five large language\nmodels: GPT-3.5, GALACTICA, Falcon, Vicuna, and WizardLM. For fine-tuned\nmodels, we develop a relation extraction approach that achieves an improvement\nof 29% F1 over a state-of-the-art baseline. For large language models, we\ndevelop an approach leveraging YAML output for structured data extraction,\nwhich achieves an average improvement of 5.5% F1 in entity recognition over\nusing JSON. With our best performing model we extract hyperparameter\ninformation from a large number of unannotated papers, and analyze patterns\nacross disciplines. All our data and source code is publicly available at\nhttps://github.com/IllDepence/hyperpie\n",
                "链接": "https://arxiv.org/abs/2312.10638"
            },
            {
                "文章ID": "119760",
                "标题": "Self Generated Wargame AI: Double Layer Agent Task Planning Based on\n  Large Language Model",
                "作者": " Y. Sun,  J. Zhao,  C. Yu,  W. Wang,  X. Zhou",
                "发布日期": "2023-12-19",
                "摘要": "  The large language models represented by ChatGPT have a disruptive impact on\nthe field of artificial intelligence. But it mainly focuses on natural language\nprocessing, speech recognition, machine learning and natural language\nunderstanding. This paper innovatively applies the large language model to the\nfield of intelligent decision-making, places the large language model in the\ndecision-making center, and constructs an agent architecture with the large\nlanguage model as the core. Based on this, it further proposes a two-layer\nagent task planning, issues and executes decision commands through the\ninteraction of natural language, and carries out simulation verification\nthrough the wargame simulation environment. Through the game confrontation\nsimulation experiment, it is found that the intelligent decision-making ability\nof the large language model is significantly stronger than the commonly used\nreinforcement learning AI and rule AI, and the intelligence, understandability\nand generalization are all better. And through experiments, it was found that\nthe intelligence of the large language model is closely related to prompt. This\nwork also extends the large language model from previous human-computer\ninteraction to the field of intelligent decision-making, which has important\nreference value and significance for the development of intelligent\ndecision-making.\n",
                "链接": "https://arxiv.org/abs/2312.01090"
            },
            {
                "文章ID": "99980",
                "标题": "ModelScope-Agent: Building Your Customizable Agent System with\n  Open-source Large Language Models",
                "作者": " Chenliang Li,  Hehong Chen,  Ming Yan,  Weizhou Shen,  Haiyang Xu,  Zhikai Wu,  Zhicheng Zhang,  Wenmeng Zhou,  Yingda Chen,  Chen Cheng,  Hongzhu Shi,  Ji Zhang,  Fei Huang,  Jingren Zhou",
                "发布日期": "2023-09-06",
                "摘要": "  Large language models (LLMs) have recently demonstrated remarkable\ncapabilities to comprehend human intentions, engage in reasoning, and design\nplanning-like behavior. To further unleash the power of LLMs to accomplish\ncomplex tasks, there is a growing trend to build agent framework that equips\nLLMs, such as ChatGPT, with tool-use abilities to connect with massive external\nAPIs. In this work, we introduce ModelScope-Agent, a general and customizable\nagent framework for real-world applications, based on open-source LLMs as\ncontrollers. It provides a user-friendly system library, with customizable\nengine design to support model training on multiple open-source LLMs, while\nalso enabling seamless integration with both model APIs and common APIs in a\nunified way. To equip the LLMs with tool-use abilities, a comprehensive\nframework has been proposed spanning over tool-use data collection, tool\nretrieval, tool registration, memory control, customized model training, and\nevaluation for practical real-world applications. Finally, we showcase\nModelScopeGPT, a real-world intelligent assistant of ModelScope Community based\non the ModelScope-Agent framework, which is able to connect open-source LLMs\nwith more than 1000 public AI models and localized community knowledge in\nModelScope. The ModelScope-Agent\nlibrary\\footnote{https://github.com/modelscope/modelscope-agent} and online\ndemo\\footnote{https://modelscope.cn/studios/damo/ModelScopeGPT/summary} are now\npublicly available.\n",
                "链接": "https://arxiv.org/abs/2309.00986"
            },
            {
                "文章ID": "122182",
                "标题": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications",
                "作者": " Feibo Jiang,  Li Dong,  Yubo Peng,  Kezhi Wang,  Kun Yang,  Cunhua Pan,  Dusit Niyato,  Octavia A. Dobre",
                "发布日期": "2023-12-14",
                "摘要": "  The rapid development of the Large Language Model (LLM) presents huge\nopportunities for 6G communications, e.g., network optimization and management\nby allowing users to input task requirements to LLMs by nature language.\nHowever, directly applying native LLMs in 6G encounters various challenges,\nsuch as a lack of private communication data and knowledge, limited logical\nreasoning, evaluation, and refinement abilities. Integrating LLMs with the\ncapabilities of retrieval, planning, memory, evaluation and reflection in\nagents can greatly enhance the potential of LLMs for 6G communications. To this\nend, we propose a multi-agent system with customized communication knowledge\nand tools for solving communication related tasks using natural language,\ncomprising three components: (1) Multi-agent Data Retrieval (MDR), which\nemploys the condensate and inference agents to refine and summarize\ncommunication knowledge from the knowledge base, expanding the knowledge\nboundaries of LLMs in 6G communications; (2) Multi-agent Collaborative Planning\n(MCP), which utilizes multiple planning agents to generate feasible solutions\nfor the communication related task from different perspectives based on the\nretrieved knowledge; (3) Multi-agent Evaluation and Reflecxion (MER), which\nutilizes the evaluation agent to assess the solutions, and applies the\nreflexion agent and refinement agent to provide improvement suggestions for\ncurrent solutions. Finally, we validate the effectiveness of the proposed\nmulti-agent system by designing a semantic communication system, as a case\nstudy of 6G communications.\n",
                "链接": "https://arxiv.org/abs/2312.07850"
            },
            {
                "文章ID": "13142",
                "标题": "SciNoBo : A Hierarchical Multi-Label Classifier of Scientific\n  Publications",
                "作者": " Nikolaos Gialitsis,  Sotiris Kotitsas,  Haris Papageorgiou",
                "发布日期": "2022-04-05",
                "摘要": "  Classifying scientific publications according to Field-of-Science (FoS)\ntaxonomies is of crucial importance, allowing funders, publishers, scholars,\ncompanies and other stakeholders to organize scientific literature more\neffectively. Most existing works address classification either at venue level\nor solely based on the textual content of a research publication. We present\nSciNoBo, a novel classification system of publications to predefined FoS\ntaxonomies, leveraging the structural properties of a publication and its\ncitations and references organised in a multilayer network. In contrast to\nother works, our system supports assignments of publications to multiple fields\nby considering their multidisciplinarity potential. By unifying publications\nand venues under a common multilayer network structure made up of citing and\npublishing relationships, classifications at the venue-level can be augmented\nwith publication-level classifications. We evaluate SciNoBo on a publications'\ndataset extracted from Microsoft Academic Graph and we perform a comparative\nanalysis against a state-of-the-art neural-network baseline. The results reveal\nthat our proposed system is capable of producing high-quality classifications\nof publications.\n",
                "链接": "https://arxiv.org/abs/2204.00880"
            },
            {
                "文章ID": "69056",
                "标题": "unarXive 2022: All arXiv Publications Pre-Processed for NLP, Including\n  Structured Full-Text and Citation Network",
                "作者": " Tarek Saier,  Johan Krause,  Michael Färber",
                "发布日期": "2023-11-06",
                "摘要": "  Large-scale data sets on scholarly publications are the basis for a variety\nof bibliometric analyses and natural language processing (NLP) applications.\nEspecially data sets derived from publication's full-text have recently gained\nattention. While several such data sets already exist, we see key shortcomings\nin terms of their domain and time coverage, citation network completeness, and\nrepresentation of full-text content. To address these points, we propose a new\nversion of the data set unarXive. We base our data processing pipeline and\noutput format on two existing data sets, and improve on each of them. Our\nresulting data set comprises 1.9 M publications spanning multiple disciplines\nand 32 years. It furthermore has a more complete citation network than its\npredecessors and retains a richer representation of document structure as well\nas non-textual publication content such as mathematical notation. In addition\nto the data set, we provide ready-to-use training/test data for citation\nrecommendation and IMRaD classification. All data and source code is publicly\navailable at https://github.com/IllDepence/unarXive.\n",
                "链接": "https://arxiv.org/abs/2303.14957"
            },
            {
                "文章ID": "83593",
                "标题": "Graph-Aware Language Model Pre-Training on a Large Graph Corpus Can Help\n  Multiple Graph Applications",
                "作者": " Han Xie,  Da Zheng,  Jun Ma,  Houyu Zhang,  Vassilis N. Ioannidis,  Xiang Song,  Qing Ping,  Sheng Wang,  Carl Yang,  Yi Xu,  Belinda Zeng,  Trishul Chilimbi",
                "发布日期": "2023-06-06",
                "摘要": "  Model pre-training on large text corpora has been demonstrated effective for\nvarious downstream applications in the NLP domain. In the graph mining domain,\na similar analogy can be drawn for pre-training graph models on large graphs in\nthe hope of benefiting downstream graph applications, which has also been\nexplored by several recent studies. However, no existing study has ever\ninvestigated the pre-training of text plus graph models on large heterogeneous\ngraphs with abundant textual information (a.k.a. large graph corpora) and then\nfine-tuning the model on different related downstream applications with\ndifferent graph schemas. To address this problem, we propose a framework of\ngraph-aware language model pre-training (GALM) on a large graph corpus, which\nincorporates large language models and graph neural networks, and a variety of\nfine-tuning methods on downstream applications. We conduct extensive\nexperiments on Amazon's real internal datasets and large public datasets.\nComprehensive empirical results and in-depth analysis demonstrate the\neffectiveness of our proposed methods along with lessons learned.\n",
                "链接": "https://arxiv.org/abs/2306.02592"
            },
            {
                "文章ID": "36556",
                "标题": "A Survey on Large-Population Systems and Scalable Multi-Agent\n  Reinforcement Learning",
                "作者": " Kai Cui,  Anam Tahir,  Gizem Ekinci,  Ahmed Elshamanhory,  Yannick Eich,  Mengguang Li,  Heinz Koeppl",
                "发布日期": "2022-09-09",
                "摘要": "  The analysis and control of large-population systems is of great interest to\ndiverse areas of research and engineering, ranging from epidemiology over\nrobotic swarms to economics and finance. An increasingly popular and effective\napproach to realizing sequential decision-making in multi-agent systems is\nthrough multi-agent reinforcement learning, as it allows for an automatic and\nmodel-free analysis of highly complex systems. However, the key issue of\nscalability complicates the design of control and reinforcement learning\nalgorithms particularly in systems with large populations of agents. While\nreinforcement learning has found resounding empirical success in many scenarios\nwith few agents, problems with many agents quickly become intractable and\nnecessitate special consideration. In this survey, we will shed light on\ncurrent approaches to tractably understanding and analyzing large-population\nsystems, both through multi-agent reinforcement learning and through adjacent\nareas of research such as mean-field games, collective intelligence, or complex\nnetwork theory. These classically independent subject areas offer a variety of\napproaches to understanding or modeling large-population systems, which may be\nof great use for the formulation of tractable MARL algorithms in the future.\nFinally, we survey potential areas of application for large-scale control and\nidentify fruitful future applications of learning algorithms in practical\nsystems. We hope that our survey could provide insight and future directions to\njunior and senior researchers in theoretical and applied sciences alike.\n",
                "链接": "https://arxiv.org/abs/2209.03859"
            }
        ]
    },
    {
        "question": {
            "question": "查询近一年模型推理加速相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "94780",
                "标题": "Radiation reaction on an accelerating point charge",
                "作者": " Jerrold Franklin",
                "发布日期": "2023-08-08",
                "摘要": "  A point charge accelerating under the influence of an external force emits\nelectromagnetic radiation that reduces the increase in its mechanical energy.\nThis causes a reduction in the particle's acceleration. We derive the decrease\nin acceleration due to radiation reaction for a particle accelerating parallel\nto its velocity, and show that it has a negligible effect.\n",
                "链接": "https://arxiv.org/abs/2308.02628"
            },
            {
                "文章ID": "114776",
                "标题": "LCM-LoRA: A Universal Stable-Diffusion Acceleration Module",
                "作者": " Simian Luo,  Yiqin Tan,  Suraj Patil,  Daniel Gu,  Patrick von Platen,  Apolinário Passos,  Longbo Huang,  Jian Li,  Hang Zhao",
                "发布日期": "2023-11-10",
                "摘要": "  Latent Consistency Models (LCMs) have achieved impressive performance in\naccelerating text-to-image generative tasks, producing high-quality images with\nminimal inference steps. LCMs are distilled from pre-trained latent diffusion\nmodels (LDMs), requiring only ~32 A100 GPU training hours. This report further\nextends LCMs' potential in two aspects: First, by applying LoRA distillation to\nStable-Diffusion models including SD-V1.5, SSD-1B, and SDXL, we have expanded\nLCM's scope to larger models with significantly less memory consumption,\nachieving superior image generation quality. Second, we identify the LoRA\nparameters obtained through LCM distillation as a universal Stable-Diffusion\nacceleration module, named LCM-LoRA. LCM-LoRA can be directly plugged into\nvarious Stable-Diffusion fine-tuned models or LoRAs without training, thus\nrepresenting a universally applicable accelerator for diverse image generation\ntasks. Compared with previous numerical PF-ODE solvers such as DDIM,\nDPM-Solver, LCM-LoRA can be viewed as a plug-in neural PF-ODE solver that\npossesses strong generalization abilities. Project page:\nhttps://github.com/luosiallen/latent-consistency-model.\n",
                "链接": "https://arxiv.org/abs/2311.05556"
            },
            {
                "文章ID": "108944",
                "标题": "Chameleon: a heterogeneous and disaggregated accelerator system for\n  retrieval-augmented language models",
                "作者": " Wenqi Jiang,  Marco Zeller,  Roger Waleffe,  Torsten Hoefler,  Gustavo Alonso",
                "发布日期": "2023-11-30",
                "摘要": "  A Retrieval-Augmented Language Model (RALM) augments a generative language\nmodel by retrieving context-specific knowledge from an external database. This\nstrategy facilitates impressive text generation quality even with smaller\nmodels, thus reducing orders of magnitude of computational demands. However,\nRALMs introduce unique system design challenges due to (a) the diverse workload\ncharacteristics between LM inference and retrieval and (b) the various system\nrequirements and bottlenecks for different RALM configurations such as model\nsizes, database sizes, and retrieval frequencies. We propose Chameleon, a\nheterogeneous accelerator system that integrates both LM and retrieval\naccelerators in a disaggregated architecture. The heterogeneity ensures\nefficient acceleration of both LM inference and retrieval, while the\naccelerator disaggregation enables the system to independently scale both types\nof accelerators to fulfill diverse RALM requirements. Our Chameleon prototype\nimplements retrieval accelerators on FPGAs and assigns LM inference to GPUs,\nwith a CPU server orchestrating these accelerators over the network. Compared\nto CPU-based and CPU-GPU vector search systems, Chameleon achieves up to 23.72x\nspeedup and 26.2x energy efficiency. Evaluated on various RALMs, Chameleon\nexhibits up to 2.16x reduction in latency and 3.18x speedup in throughput\ncompared to the hybrid CPU-GPU architecture. These promising results pave the\nway for bringing accelerator heterogeneity and disaggregation into future RALM\nsystems.\n",
                "链接": "https://arxiv.org/abs/2310.09949"
            },
            {
                "文章ID": "124055",
                "标题": "Accelerator-driven Data Arrangement to Minimize Transformers Run-time on\n  Multi-core Architectures",
                "作者": " Alireza Amirshahi,  Giovanni Ansaloni,  David Atienza",
                "发布日期": "2023-12-21",
                "摘要": "  The increasing complexity of transformer models in artificial intelligence\nexpands their computational costs, memory usage, and energy consumption.\nHardware acceleration tackles the ensuing challenges by designing processors\nand accelerators tailored for transformer models, supporting their computation\nhotspots with high efficiency. However, memory bandwidth can hinder\nimprovements in hardware accelerators. Against this backdrop, in this paper we\npropose a novel memory arrangement strategy, governed by the hardware\naccelerator's kernel size, which effectively minimizes off-chip data access.\nThis arrangement is particularly beneficial for end-to-end transformer model\ninference, where most of the computation is based on general matrix\nmultiplication (GEMM) operations. Additionally, we address the overhead of\nnon-GEMM operations in transformer models within the scope of this memory data\narrangement. Our study explores the implementation and effectiveness of the\nproposed accelerator-driven data arrangement approach in both single- and\nmulti-core systems. Our evaluation demonstrates that our approach can achieve\nup to a 2.8x speed increase when executing inferences employing\nstate-of-the-art transformers.\n",
                "链接": "https://arxiv.org/abs/2312.13000"
            },
            {
                "文章ID": "102164",
                "标题": "Draft & Verify: Lossless Large Language Model Acceleration via\n  Self-Speculative Decoding",
                "作者": " Jun Zhang,  Jue Wang,  Huan Li,  Lidan Shou,  Ke Chen,  Gang Chen,  Sharad Mehrotra",
                "发布日期": "2023-09-18",
                "摘要": "  We present a novel inference scheme, self-speculative decoding, for\naccelerating Large Language Models (LLMs) without the need for an auxiliary\nmodel. This approach is characterized by a two-stage process: drafting and\nverification. The drafting stage generates draft tokens at a slightly lower\nquality but more quickly, which is achieved by selectively skipping certain\nintermediate layers during drafting Subsequently, the verification stage\nemploys the original LLM to validate those draft output tokens in one forward\npass. This process ensures the final output remains identical to that produced\nby the unaltered LLM, thereby maintaining output quality. The proposed method\nrequires no additional neural network training and no extra memory footprint,\nmaking it a plug-and-play and cost-effective solution for inference\nacceleration. Benchmarks with LLaMA-2 and its fine-tuned models demonstrated a\nspeedup up to 1.73$\\times$.\n",
                "链接": "https://arxiv.org/abs/2309.08168"
            },
            {
                "文章ID": "100868",
                "标题": "Training Acceleration of Low-Rank Decomposed Networks using Sequential\n  Freezing and Rank Quantization",
                "作者": " Habib Hajimolahoseini,  Walid Ahmed,  Yang Liu",
                "发布日期": "2023-09-08",
                "摘要": "  Low Rank Decomposition (LRD) is a model compression technique applied to the\nweight tensors of deep learning models in order to reduce the number of\ntrainable parameters and computational complexity. However, due to high number\nof new layers added to the architecture after applying LRD, it may not lead to\na high training/inference acceleration if the decomposition ranks are not small\nenough. The issue is that using small ranks increases the risk of significant\naccuracy drop after decomposition. In this paper, we propose two techniques for\naccelerating low rank decomposed models without requiring to use small ranks\nfor decomposition. These methods include rank optimization and sequential\nfreezing of decomposed layers. We perform experiments on both convolutional and\ntransformer-based models. Experiments show that these techniques can improve\nthe model throughput up to 60% during training and 37% during inference when\ncombined together while preserving the accuracy close to that of the original\nmodels\n",
                "链接": "https://arxiv.org/abs/2309.03824"
            },
            {
                "文章ID": "124676",
                "标题": "Understanding the Potential of FPGA-Based Spatial Acceleration for Large\n  Language Model Inference",
                "作者": " Hongzheng Chen,  Jiahao Zhang,  Yixiao Du,  Shaojie Xiang,  Zichao Yue,  Niansong Zhang,  Yaohui Cai,  Zhiru Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Recent advancements in large language models (LLMs) boasting billions of\nparameters have generated a significant demand for efficient deployment in\ninference workloads. The majority of existing approaches rely on temporal\narchitectures that reuse hardware units for different network layers and\noperators. However, these methods often encounter challenges in achieving low\nlatency due to considerable memory access overhead. This paper investigates the\nfeasibility and potential of model-specific spatial acceleration for LLM\ninference on FPGAs. Our approach involves the specialization of distinct\nhardware units for specific operators or layers, facilitating direct\ncommunication between them through a dataflow architecture while minimizing\noff-chip memory accesses. We introduce a comprehensive analytical model for\nestimating the performance of a spatial LLM accelerator, taking into account\nthe on-chip compute and memory resources available on an FPGA. Through our\nanalysis, we can determine the scenarios in which FPGA-based spatial\nacceleration can outperform its GPU-based counterpart. To enable more\nproductive implementations of an LLM model on FPGAs, we further provide a\nlibrary of high-level synthesis (HLS) kernels that are composable and reusable.\nThis library will be made available as open-source. To validate the\neffectiveness of both our analytical model and HLS library, we have implemented\nBERT and GPT2 on an AMD Alveo U280 FPGA device. Experimental results\ndemonstrate our approach can achieve up to 16.1x speedup when compared to\nprevious FPGA-based accelerators for the BERT model. For GPT generative\ninference, we attain a 2.2x speedup compared to DFX, an FPGA overlay, in the\nprefill stage, while achieving a 1.9x speedup and a 5.7x improvement in energy\nefficiency compared to the NVIDIA A100 GPU in the decode stage.\n",
                "链接": "https://arxiv.org/abs/2312.15159"
            },
            {
                "文章ID": "116519",
                "标题": "Exponentially Faster Language Modelling",
                "作者": " Peter Belcak,  Roger Wattenhofer",
                "发布日期": "2023-11-22",
                "摘要": "  Language models only really need to use an exponential fraction of their\nneurons for individual inferences. As proof, we present UltraFastBERT, a BERT\nvariant that uses 0.3% of its neurons during inference while performing on par\nwith similar BERT models. UltraFastBERT selectively engages just 12 out of 4095\nneurons for each layer inference. This is achieved by replacing feedforward\nnetworks with fast feedforward networks (FFFs). While no truly efficient\nimplementation currently exists to unlock the full acceleration potential of\nconditional neural execution, we provide high-level CPU code achieving 78x\nspeedup over the optimized baseline feedforward implementation, and a PyTorch\nimplementation delivering 40x speedup over the equivalent batched feedforward\ninference. We publish our training code, benchmarking setup, and model weights.\n",
                "链接": "https://arxiv.org/abs/2311.10770"
            },
            {
                "文章ID": "89860",
                "标题": "ITA: An Energy-Efficient Attention and Softmax Accelerator for Quantized\n  Transformers",
                "作者": " Gamze İslamoğlu,  Moritz Scherer,  Gianna Paulin,  Tim Fischer,  Victor J. B. Jung,  Angelo Garofalo,  Luca Benini",
                "发布日期": "2023-07-11",
                "摘要": "  Transformer networks have emerged as the state-of-the-art approach for\nnatural language processing tasks and are gaining popularity in other domains\nsuch as computer vision and audio processing. However, the efficient hardware\nacceleration of transformer models poses new challenges due to their high\narithmetic intensities, large memory requirements, and complex dataflow\ndependencies. In this work, we propose ITA, a novel accelerator architecture\nfor transformers and related models that targets efficient inference on\nembedded systems by exploiting 8-bit quantization and an innovative softmax\nimplementation that operates exclusively on integer values. By computing\non-the-fly in streaming mode, our softmax implementation minimizes data\nmovement and energy consumption. ITA achieves competitive energy efficiency\nwith respect to state-of-the-art transformer accelerators with 16.9 TOPS/W,\nwhile outperforming them in area efficiency with 5.93 TOPS/mm$^2$ in 22 nm\nfully-depleted silicon-on-insulator technology at 0.8 V.\n",
                "链接": "https://arxiv.org/abs/2307.03493"
            },
            {
                "文章ID": "120589",
                "标题": "F3-Pruning: A Training-Free and Generalized Pruning Strategy towards\n  Faster and Finer Text-to-Video Synthesis",
                "作者": " Sitong Su,  Jianzhi Liu,  Lianli Gao,  Jingkuan Song",
                "发布日期": "2023-12-07",
                "摘要": "  Recently Text-to-Video (T2V) synthesis has undergone a breakthrough by\ntraining transformers or diffusion models on large-scale datasets.\nNevertheless, inferring such large models incurs huge costs.Previous inference\nacceleration works either require costly retraining or are model-specific.To\naddress this issue, instead of retraining we explore the inference process of\ntwo mainstream T2V models using transformers and diffusion models.The\nexploration reveals the redundancy in temporal attention modules of both\nmodels, which are commonly utilized to establish temporal relations among\nframes.Consequently, we propose a training-free and generalized pruning\nstrategy called F3-Pruning to prune redundant temporal attention\nweights.Specifically, when aggregate temporal attention values are ranked below\na certain ratio, corresponding weights will be pruned.Extensive experiments on\nthree datasets using a classic transformer-based model CogVideo and a typical\ndiffusion-based model Tune-A-Video verify the effectiveness of F3-Pruning in\ninference acceleration, quality assurance and broad applicability.\n",
                "链接": "https://arxiv.org/abs/2312.03459"
            }
        ]
    },
    {
        "question": {
            "question": "查找论文中包含指令微调细节描述的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "90044",
                "标题": "SVIT: Scaling up Visual Instruction Tuning",
                "作者": " Bo Zhao,  Boya Wu,  Muyang He,  Tiejun Huang",
                "发布日期": "2023-12-29",
                "摘要": "  Thanks to the emerging of foundation models, the large language and vision\nmodels are integrated to acquire the multimodal ability of visual captioning,\nquestion answering, etc. Although existing multimodal models present impressive\nperformance of visual understanding and reasoning, their limits are still\nlargely under-explored due to the scarcity of high-quality instruction tuning\ndata. To push the limits of multimodal capability, we Scale up Visual\nInstruction Tuning (SVIT) by constructing a dataset of 4.2 million visual\ninstruction tuning data including 1.6M conversation question-answer (QA) pairs,\n1.6M complex reasoning QA pairs, 1.0M referring QA pairs and 106K detailed\nimage descriptions. Besides the volume, the proposed dataset is also featured\nby the high quality and rich diversity, which is generated by prompting GPT-4\nwith the abundant manual annotations of images. We also propose a new data\nrecipe to select subset with better diversity and balance, which evokes model's\nsuperior capabilities. Extensive experiments verify that SVIT-v1.5, trained on\nthe proposed dataset, outperforms state-of-the-art Multimodal Large Language\nModels on popular benchmarks. The data and code are publicly available at\nhttps://github.com/BAAI-DCAI/Visual-Instruction-Tuning.\n",
                "链接": "https://arxiv.org/abs/2307.04087"
            },
            {
                "文章ID": "121379",
                "标题": "PILLOW: Enhancing Efficient Instruction Fine-tuning via Prompt Matching",
                "作者": " Zhenting Qi,  Xiaoyu Tan,  Shaojie Shi,  Chao Qu,  Yinghui Xu,  Yuan Qi",
                "发布日期": "2023-12-12",
                "摘要": "  Instruction fine-tuning has conventionally been employed to adapt Large\nLanguage Models (LLMs) to a variety of tasks. Nonetheless, this technique often\nnecessitates substantial computational resources, making it impractical for\ndeployment by individuals or small-scale entities. Recently, Low-Rank\nAdaptation (LoRA) has become a promising alternative, offering high\ncapabilities on par with full tuning with reduced resource overhead. However,\nattaining satisfactory performance through the fine-tuning of LoRA is a\nnon-trivial challenge. In this paper, we propose PILLOW, which aims to improve\nLoRA's performance by a discrimination-based prompting method, leveraging LLMs'\nIn-Context Learning ability. PILLOW incorporates a matching network that\nselects prompts from a user-defined prompt pool, concatenates the selected\nprompts with the user instruction as input, and performs inference using the\nLoRA-fine-tuned LLMs. Trained with Reinforcement Learning, PILLOW exhibits\ncommensurate performance on various evaluation metrics compared with typical\ninstruction fine-tuning methods, utilizing only consumer-grade GPU resources\nand exhibiting a large reduction in computational costs.\n",
                "链接": "https://arxiv.org/abs/2312.05621"
            },
            {
                "文章ID": "98575",
                "标题": "Position-Enhanced Visual Instruction Tuning for Multimodal Large\n  Language Models",
                "作者": " Chi Chen,  Ruoyu Qin,  Fuwen Luo,  Xiaoyue Mi,  Peng Li,  Maosong Sun,  Yang Liu",
                "发布日期": "2023-09-15",
                "摘要": "  Recently, Multimodal Large Language Models (MLLMs) that enable Large Language\nModels (LLMs) to interpret images through visual instruction tuning have\nachieved significant success. However, existing visual instruction tuning\nmethods only utilize image-language instruction data to align the language and\nimage modalities, lacking a more fine-grained cross-modal alignment. In this\npaper, we propose Position-enhanced Visual Instruction Tuning (PVIT), which\nextends the functionality of MLLMs by integrating an additional region-level\nvision encoder. This integration promotes a more detailed comprehension of\nimages for the MLLM. In addition, to efficiently achieve a fine-grained\nalignment between the vision modules and the LLM, we design multiple data\ngeneration strategies to construct an image-region-language instruction\ndataset. Finally, we present both quantitative experiments and qualitative\nanalysis that demonstrate the superiority of the proposed model. Code and data\nwill be released at https://github.com/PVIT-official/PVIT.\n",
                "链接": "https://arxiv.org/abs/2308.13437"
            },
            {
                "文章ID": "72812",
                "标题": "Visual Instruction Tuning",
                "作者": " Haotian Liu,  Chunyuan Li,  Qingyang Wu,  Yong Jae Lee",
                "发布日期": "2023-12-14",
                "摘要": "  Instruction tuning large language models (LLMs) using machine-generated\ninstruction-following data has improved zero-shot capabilities on new tasks,\nbut the idea is less explored in the multimodal field. In this paper, we\npresent the first attempt to use language-only GPT-4 to generate multimodal\nlanguage-image instruction-following data. By instruction tuning on such\ngenerated data, we introduce LLaVA: Large Language and Vision Assistant, an\nend-to-end trained large multimodal model that connects a vision encoder and\nLLM for general-purpose visual and language understanding.Our early experiments\nshow that LLaVA demonstrates impressive multimodel chat abilities, sometimes\nexhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and\nyields a 85.1% relative score compared with GPT-4 on a synthetic multimodal\ninstruction-following dataset. When fine-tuned on Science QA, the synergy of\nLLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make\nGPT-4 generated visual instruction tuning data, our model and code base\npublicly available.\n",
                "链接": "https://arxiv.org/abs/2304.08485"
            },
            {
                "文章ID": "98124",
                "标题": "InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning MiniGPT-4",
                "作者": " Lai Wei,  Zihao Jiang,  Weiran Huang,  Lichao Sun",
                "发布日期": "2023-10-12",
                "摘要": "  Multimodal large language models are typically trained in two stages: first\npre-training on image-text pairs, and then fine-tuning using supervised\nvision-language instruction data. Recent studies have shown that large language\nmodels can achieve satisfactory results even with a limited amount of\nhigh-quality instruction-following data. In this paper, we introduce\nInstructionGPT-4, which is fine-tuned on a small dataset comprising only 200\nexamples, amounting to approximately 6\\% of the instruction-following data used\nin the alignment dataset for MiniGPT-4. To achieve this, we first propose\nseveral metrics to access the quality of multimodal instruction data. Based on\nthese metrics, we present an effective and trainable data selector to\nautomatically identify and filter low-quality vision-language data. By\nemploying this method, InstructionGPT-4 outperforms the original MiniGPT-4 on\nvarious evaluations. Overall, our findings demonstrate that less but\nhigh-quality instruction tuning data is efficient in enabling multimodal large\nlanguage models to generate better output. Our code is available at\nhttps://github.com/waltonfuture/InstructionGPT-4.\n",
                "链接": "https://arxiv.org/abs/2308.12067"
            },
            {
                "文章ID": "123289",
                "标题": "Understanding the Instruction Mixture for Large Language Model\n  Fine-tuning",
                "作者": " Renxi Wang,  Minghao Wu,  Yuxia Wang,  Xudong Han,  Chiyu Zhang,  Haonan Li",
                "发布日期": "2023-12-20",
                "摘要": "  While instructions fine-tuning of large language models (LLMs) has been\nproven to enhance performance across various applications, the influence of the\ninstruction dataset mixture on LLMs has not been thoroughly explored. In this\nstudy, we classify instructions into three main types: NLP downstream tasks,\ncoding, and general chatting, and investigate their impact on LLMs. Our\nfindings reveal that specific types of instructions are more beneficial for\nparticular uses, while it may cause harms to other aspects, emphasizing the\nimportance of meticulously designing the instruction mixture to maximize model\nperformance. This study sheds light on the instruction mixture and paves the\nway for future research.\n",
                "链接": "https://arxiv.org/abs/2312.10793"
            },
            {
                "文章ID": "69284",
                "标题": "Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning",
                "作者": " Vladislav Lialin,  Vijeta Deshpande,  Anna Rumshisky",
                "发布日期": "2023-03-29",
                "摘要": "  This paper presents a systematic overview and comparison of\nparameter-efficient fine-tuning methods covering over 40 papers published\nbetween February 2019 and February 2023. These methods aim to resolve the\ninfeasibility and impracticality of fine-tuning large language models by only\ntraining a small set of parameters. We provide a taxonomy that covers a broad\nrange of methods and present a detailed method comparison with a specific focus\non real-life efficiency and fine-tuning multibillion-scale language models.\n",
                "链接": "https://arxiv.org/abs/2303.15647"
            },
            {
                "文章ID": "96286",
                "标题": "#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of\n  Large Language Models",
                "作者": " Keming Lu,  Hongyi Yuan,  Zheng Yuan,  Runji Lin,  Junyang Lin,  Chuanqi Tan,  Chang Zhou,  Jingren Zhou",
                "发布日期": "2023-08-16",
                "摘要": "  Foundation language models obtain the instruction-following ability through\nsupervised fine-tuning (SFT). Diversity and complexity are considered critical\nfactors of a successful SFT dataset, while their definitions remain obscure and\nlack quantitative analyses. In this work, we propose InsTag, an open-set\nfine-grained tagger, to tag samples within SFT datasets based on semantics and\nintentions and define instruction diversity and complexity regarding tags. We\nobtain 6.6K tags to describe comprehensive user queries. Then we analyze\npopular open-sourced SFT datasets and find that the model ability grows with\nmore diverse and complex data. Based on this observation, we propose a data\nselector based on InsTag to select 6K diverse and complex samples from\nopen-source datasets and fine-tune models on InsTag-selected data. The\nresulting models, TagLM, outperform open-source models based on considerably\nlarger SFT data evaluated by MT-Bench, echoing the importance of query\ndiversity and complexity. We open-source InsTag in\nhttps://github.com/OFA-Sys/InsTag.\n",
                "链接": "https://arxiv.org/abs/2308.07074"
            },
            {
                "文章ID": "110607",
                "标题": "CITB: A Benchmark for Continual Instruction Tuning",
                "作者": " Zihan Zhang,  Meng Fang,  Ling Chen,  Mohammad-Reza Namazi-Rad",
                "发布日期": "2023-10-24",
                "摘要": "  Continual learning (CL) is a paradigm that aims to replicate the human\nability to learn and accumulate knowledge continually without forgetting\nprevious knowledge and transferring it to new tasks. Recent instruction tuning\n(IT) involves fine-tuning models to make them more adaptable to solving NLP\ntasks in general. However, it is still uncertain how instruction tuning works\nin the context of CL tasks. This challenging yet practical problem is\nformulated as Continual Instruction Tuning (CIT). In this work, we establish a\nCIT benchmark consisting of learning and evaluation protocols. We curate two\nlong dialogue task streams of different types, InstrDialog and InstrDialog++,\nto study various CL methods systematically. Our experiments show that existing\nCL methods do not effectively leverage the rich natural language instructions,\nand fine-tuning an instruction-tuned model sequentially can yield similar or\nbetter results. We further explore different aspects that might affect the\nlearning of CIT. We hope this benchmark will facilitate more research in this\ndirection.\n",
                "链接": "https://arxiv.org/abs/2310.14510"
            },
            {
                "文章ID": "115619",
                "标题": "Vision-Language Instruction Tuning: A Review and Analysis",
                "作者": " Chen Li,  Yixiao Ge,  Dian Li,  Ying Shan",
                "发布日期": "2023-11-28",
                "摘要": "  Instruction tuning is a crucial supervised training phase in Large Language\nModels (LLMs), aiming to enhance the LLM's ability to generalize instruction\nexecution and adapt to user preferences. With the increasing integration of\nmulti-modal data into LLMs, there is growing interest in Vision-Language\nInstruction Tuning (VLIT), which presents more complex characteristics compared\nto pure text instruction tuning. In this paper, we systematically review the\nlatest VLIT settings and corresponding datasets in multi-modal LLMs and provide\ninsights into the intrinsic motivations behind their design. For the first\ntime, we offer a detailed multi-perspective categorization for existing VLIT\ndatasets and identify the characteristics that high-quality VLIT data should\npossess. By incorporating these characteristics as guiding principles into the\nexisting VLIT data construction process, we conduct extensive experiments and\nverify their positive impact on the performance of tuned multi-modal LLMs.\nFurthermore, we discuss the current challenges and future research directions\nof VLIT, providing insights for the continuous development of this field. The\ncode and dataset related to this paper have been open-sourced at\nhttps://github.com/palchenli/VL-Instruction-Tuning.\n",
                "链接": "https://arxiv.org/abs/2311.08172"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本检测最新进展",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "100439",
                "标题": "STEP -- Towards Structured Scene-Text Spotting",
                "作者": " Sergi Garcia-Bordils,  Dimosthenis Karatzas,  Marçal Rusiñol",
                "发布日期": "2023-12-12",
                "摘要": "  We introduce the structured scene-text spotting task, which requires a\nscene-text OCR system to spot text in the wild according to a query regular\nexpression. Contrary to generic scene text OCR, structured scene-text spotting\nseeks to dynamically condition both scene text detection and recognition on\nuser-provided regular expressions. To tackle this task, we propose the\nStructured TExt sPotter (STEP), a model that exploits the provided text\nstructure to guide the OCR process. STEP is able to deal with regular\nexpressions that contain spaces and it is not bound to detection at the\nword-level granularity. Our approach enables accurate zero-shot structured text\nspotting in a wide variety of real-world reading scenarios and is solely\ntrained on publicly available data. To demonstrate the effectiveness of our\napproach, we introduce a new challenging test dataset that contains several\ntypes of out-of-vocabulary structured text, reflecting important reading\napplications of fields such as prices, dates, serial numbers, license plates\netc. We demonstrate that STEP can provide specialised OCR performance on demand\nin all tested scenarios.\n",
                "链接": "https://arxiv.org/abs/2309.02356"
            },
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "90438",
                "标题": "Handwritten Text Recognition Using Convolutional Neural Network",
                "作者": " Atman Mishra,  A. Sharath Ram,  Kavyashree C",
                "发布日期": "2023-07-12",
                "摘要": "  OCR (Optical Character Recognition) is a technology that offers comprehensive\nalphanumeric recognition of handwritten and printed characters at electronic\nspeed by merely scanning the document. Recently, the understanding of visual\ndata has been termed Intelligent Character Recognition (ICR). Intelligent\nCharacter Recognition (ICR) is the OCR module that can convert scans of\nhandwritten or printed characters into ASCII text. ASCII data is the standard\nformat for data encoding in electronic communication. ASCII assigns standard\nnumeric values to letters, numeral, symbols, white-spaces and other characters.\nIn more technical terms, OCR is the process of using an electronic device to\ntransform 2-Dimensional textual information into machine-encoded text. Anything\nthat contains text both machine written or handwritten can be scanned either\nthrough a scanner or just simply a picture of the text is enough for the\nrecognition system to distinguish the text. The goal of this papers is to show\nthe results of a Convolutional Neural Network model which has been trained on\nNational Institute of Science and Technology (NIST) dataset containing over a\n100,000 images. The network learns from the features extracted from the images\nand use it to generate the probability of each class to which the picture\nbelongs to. We have achieved an accuracy of 90.54% with a loss of 2.53%.\n",
                "链接": "https://arxiv.org/abs/2307.05396"
            },
            {
                "文章ID": "90096",
                "标题": "A Novel Pipeline for Improving Optical Character Recognition through\n  Post-processing Using Natural Language Processing",
                "作者": " Aishik Rakshit,  Samyak Mehta,  Anirban Dasgupta",
                "发布日期": "2023-07-11",
                "摘要": "  Optical Character Recognition (OCR) technology finds applications in\ndigitizing books and unstructured documents, along with applications in other\ndomains such as mobility statistics, law enforcement, traffic, security\nsystems, etc. The state-of-the-art methods work well with the OCR with printed\ntext on license plates, shop names, etc. However, applications such as printed\ntextbooks and handwritten texts have limited accuracy with existing techniques.\nThe reason may be attributed to similar-looking characters and variations in\nhandwritten characters. Since these issues are challenging to address with OCR\ntechnologies exclusively, we propose a post-processing approach using Natural\nLanguage Processing (NLP) tools. This work presents an end-to-end pipeline that\nfirst performs OCR on the handwritten or printed text and then improves its\naccuracy using NLP.\n",
                "链接": "https://arxiv.org/abs/2307.04245"
            },
            {
                "文章ID": "12974",
                "标题": "Unitail: Detecting, Reading, and Matching in Retail Scene",
                "作者": " Fangyi Chen,  Han Zhang,  Zaiwang Li,  Jiachen Dou,  Shentong Mo,  Hao Chen,  Yongxin Zhang,  Uzair Ahmed,  Chenchen Zhu,  Marios Savvides",
                "发布日期": "2022-07-21",
                "摘要": "  To make full use of computer vision technology in stores, it is required to\nconsider the actual needs that fit the characteristics of the retail scene.\nPursuing this goal, we introduce the United Retail Datasets (Unitail), a\nlarge-scale benchmark of basic visual tasks on products that challenges\nalgorithms for detecting, reading, and matching. With 1.8M quadrilateral-shaped\ninstances annotated, the Unitail offers a detection dataset to align product\nappearance better. Furthermore, it provides a gallery-style OCR dataset\ncontaining 1454 product categories, 30k text regions, and 21k transcriptions to\nenable robust reading on products and motivate enhanced product matching.\nBesides benchmarking the datasets using various state-of-the-arts, we customize\na new detector for product detection and provide a simple OCR-based matching\nsolution that verifies its effectiveness.\n",
                "链接": "https://arxiv.org/abs/2204.00298"
            },
            {
                "文章ID": "55598",
                "标题": "A Comprehensive Gold Standard and Benchmark for Comics Text Detection\n  and Recognition",
                "作者": " Gürkan Soykan,  Deniz Yuret,  Tevfik Metin Sezgin",
                "发布日期": "2023-01-02",
                "摘要": "  This study focuses on improving the optical character recognition (OCR) data\nfor panels in the COMICS dataset, the largest dataset containing text and\nimages from comic books. To do this, we developed a pipeline for OCR processing\nand labeling of comic books and created the first text detection and\nrecognition datasets for western comics, called \"COMICS Text+: Detection\" and\n\"COMICS Text+: Recognition\". We evaluated the performance of state-of-the-art\ntext detection and recognition models on these datasets and found significant\nimprovement in word accuracy and normalized edit distance compared to the text\nin COMICS. We also created a new dataset called \"COMICS Text+\", which contains\nthe extracted text from the textboxes in the COMICS dataset. Using the improved\ntext data of COMICS Text+ in the comics processing model from resulted in\nstate-of-the-art performance on cloze-style tasks without changing the model\narchitecture. The COMICS Text+ dataset can be a valuable resource for\nresearchers working on tasks including text detection, recognition, and\nhigh-level processing of comics, such as narrative understanding, character\nrelations, and story generation. All the data and inference instructions can be\naccessed in https://github.com/gsoykan/comics_text_plus.\n",
                "链接": "https://arxiv.org/abs/2212.14674"
            },
            {
                "文章ID": "113971",
                "标题": "AnyText: Multilingual Visual Text Generation And Editing",
                "作者": " Yuxiang Tuo,  Wangmeng Xiang,  Jun-Yan He,  Yifeng Geng,  Xuansong Xie",
                "发布日期": "2023-12-18",
                "摘要": "  Diffusion model based Text-to-Image has achieved impressive achievements\nrecently. Although current technology for synthesizing images is highly\nadvanced and capable of generating images with high fidelity, it is still\npossible to give the show away when focusing on the text area in the generated\nimage. To address this issue, we introduce AnyText, a diffusion-based\nmultilingual visual text generation and editing model, that focuses on\nrendering accurate and coherent text in the image. AnyText comprises a\ndiffusion pipeline with two primary elements: an auxiliary latent module and a\ntext embedding module. The former uses inputs like text glyph, position, and\nmasked image to generate latent features for text generation or editing. The\nlatter employs an OCR model for encoding stroke data as embeddings, which blend\nwith image caption embeddings from the tokenizer to generate texts that\nseamlessly integrate with the background. We employed text-control diffusion\nloss and text perceptual loss for training to further enhance writing accuracy.\nAnyText can write characters in multiple languages, to the best of our\nknowledge, this is the first work to address multilingual visual text\ngeneration. It is worth mentioning that AnyText can be plugged into existing\ndiffusion models from the community for rendering or editing text accurately.\nAfter conducting extensive evaluation experiments, our method has outperformed\nall other approaches by a significant margin. Additionally, we contribute the\nfirst large-scale multilingual text images dataset, AnyWord-3M, containing 3\nmillion image-text pairs with OCR annotations in multiple languages. Based on\nAnyWord-3M dataset, we propose AnyText-benchmark for the evaluation of visual\ntext generation accuracy and quality. Our project will be open-sourced on\nhttps://github.com/tyxsspa/AnyText to improve and promote the development of\ntext generation technology.\n",
                "链接": "https://arxiv.org/abs/2311.03054"
            },
            {
                "文章ID": "28385",
                "标题": "Detection of Furigana Text in Images",
                "作者": " Nikolaj Kjøller Bjerregaard,  Veronika Cheplygina,  Stefan Heinrich",
                "发布日期": "2022-07-11",
                "摘要": "  Furigana are pronunciation notes used in Japanese writing. Being able to\ndetect these can help improve optical character recognition (OCR) performance\nor make more accurate digital copies of Japanese written media by correctly\ndisplaying furigana. This project focuses on detecting furigana in Japanese\nbooks and comics. While there has been research into the detection of Japanese\ntext in general, there are currently no proposed methods for detecting\nfurigana.\n  We construct a new dataset containing Japanese written media and annotations\nof furigana. We propose an evaluation metric for such data which is similar to\nthe evaluation protocols used in object detection except that it allows groups\nof objects to be labeled by one annotation. We propose a method for detection\nof furigana that is based on mathematical morphology and connected component\nanalysis. We evaluate the detections of the dataset and compare different\nmethods for text extraction. We also evaluate different types of images such as\nbooks and comics individually and discuss the challenges of each type of image.\n  The proposed method reaches an F1-score of 76\\% on the dataset. The method\nperforms well on regular books, but less so on comics, and books of irregular\nformat. Finally, we show that the proposed method can improve the performance\nof OCR by 5\\% on the manga109 dataset.\n  Source code is available via\n\\texttt{\\url{https://github.com/nikolajkb/FuriganaDetection}}\n",
                "链接": "https://arxiv.org/abs/2207.03960"
            },
            {
                "文章ID": "73951",
                "标题": "ICDAR 2023 Competition on Reading the Seal Title",
                "作者": " Wenwen Yu,  Mingyu Liu,  Mingrui Chen,  Ning Lu,  Yinlong Wen,  Yuliang Liu,  Dimosthenis Karatzas,  Xiang Bai",
                "发布日期": "2023-06-07",
                "摘要": "  Reading seal title text is a challenging task due to the variable shapes of\nseals, curved text, background noise, and overlapped text. However, this\nimportant element is commonly found in official and financial scenarios, and\nhas not received the attention it deserves in the field of OCR technology. To\npromote research in this area, we organized ICDAR 2023 competition on reading\nthe seal title (ReST), which included two tasks: seal title text detection\n(Task 1) and end-to-end seal title recognition (Task 2). We constructed a\ndataset of 10,000 real seal data, covering the most common classes of seals,\nand labeled all seal title texts with text polygons and text contents. The\ncompetition opened on 30th December, 2022 and closed on 20th March, 2023. The\ncompetition attracted 53 participants from academia and industry including 28\nsubmissions for Task 1 and 25 submissions for Task 2, which demonstrated\nsignificant interest in this challenging task. In this report, we present an\noverview of the competition, including the organization, challenges, and\nresults. We describe the dataset and tasks, and summarize the submissions and\nevaluation results. The results show that significant progress has been made in\nthe field of seal title text reading, and we hope that this competition will\ninspire further research and development in this important area of OCR\ntechnology.\n",
                "链接": "https://arxiv.org/abs/2304.11966"
            },
            {
                "文章ID": "98478",
                "标题": "DISGO: Automatic End-to-End Evaluation for Scene Text OCR",
                "作者": " Mei-Yuh Hwang,  Yangyang Shi,  Ankit Ramchandani,  Guan Pang,  Praveen Krishnan,  Lucas Kabela,  Frank Seide,  Samyak Datta,  Jun Liu",
                "发布日期": "2023-08-28",
                "摘要": "  This paper discusses the challenges of optical character recognition (OCR) on\nnatural scenes, which is harder than OCR on documents due to the wild content\nand various image backgrounds. We propose to uniformly use word error rates\n(WER) as a new measurement for evaluating scene-text OCR, both end-to-end (e2e)\nperformance and individual system component performances. Particularly for the\ne2e metric, we name it DISGO WER as it considers Deletion, Insertion,\nSubstitution, and Grouping/Ordering errors. Finally we propose to utilize the\nconcept of super blocks to automatically compute BLEU scores for e2e OCR\nmachine translation. The small SCUT public test set is used to demonstrate WER\nperformance by a modularized OCR system.\n",
                "链接": "https://arxiv.org/abs/2308.13173"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本识别最新进展。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "90438",
                "标题": "Handwritten Text Recognition Using Convolutional Neural Network",
                "作者": " Atman Mishra,  A. Sharath Ram,  Kavyashree C",
                "发布日期": "2023-07-12",
                "摘要": "  OCR (Optical Character Recognition) is a technology that offers comprehensive\nalphanumeric recognition of handwritten and printed characters at electronic\nspeed by merely scanning the document. Recently, the understanding of visual\ndata has been termed Intelligent Character Recognition (ICR). Intelligent\nCharacter Recognition (ICR) is the OCR module that can convert scans of\nhandwritten or printed characters into ASCII text. ASCII data is the standard\nformat for data encoding in electronic communication. ASCII assigns standard\nnumeric values to letters, numeral, symbols, white-spaces and other characters.\nIn more technical terms, OCR is the process of using an electronic device to\ntransform 2-Dimensional textual information into machine-encoded text. Anything\nthat contains text both machine written or handwritten can be scanned either\nthrough a scanner or just simply a picture of the text is enough for the\nrecognition system to distinguish the text. The goal of this papers is to show\nthe results of a Convolutional Neural Network model which has been trained on\nNational Institute of Science and Technology (NIST) dataset containing over a\n100,000 images. The network learns from the features extracted from the images\nand use it to generate the probability of each class to which the picture\nbelongs to. We have achieved an accuracy of 90.54% with a loss of 2.53%.\n",
                "链接": "https://arxiv.org/abs/2307.05396"
            },
            {
                "文章ID": "100439",
                "标题": "STEP -- Towards Structured Scene-Text Spotting",
                "作者": " Sergi Garcia-Bordils,  Dimosthenis Karatzas,  Marçal Rusiñol",
                "发布日期": "2023-12-12",
                "摘要": "  We introduce the structured scene-text spotting task, which requires a\nscene-text OCR system to spot text in the wild according to a query regular\nexpression. Contrary to generic scene text OCR, structured scene-text spotting\nseeks to dynamically condition both scene text detection and recognition on\nuser-provided regular expressions. To tackle this task, we propose the\nStructured TExt sPotter (STEP), a model that exploits the provided text\nstructure to guide the OCR process. STEP is able to deal with regular\nexpressions that contain spaces and it is not bound to detection at the\nword-level granularity. Our approach enables accurate zero-shot structured text\nspotting in a wide variety of real-world reading scenarios and is solely\ntrained on publicly available data. To demonstrate the effectiveness of our\napproach, we introduce a new challenging test dataset that contains several\ntypes of out-of-vocabulary structured text, reflecting important reading\napplications of fields such as prices, dates, serial numbers, license plates\netc. We demonstrate that STEP can provide specialised OCR performance on demand\nin all tested scenarios.\n",
                "链接": "https://arxiv.org/abs/2309.02356"
            },
            {
                "文章ID": "90096",
                "标题": "A Novel Pipeline for Improving Optical Character Recognition through\n  Post-processing Using Natural Language Processing",
                "作者": " Aishik Rakshit,  Samyak Mehta,  Anirban Dasgupta",
                "发布日期": "2023-07-11",
                "摘要": "  Optical Character Recognition (OCR) technology finds applications in\ndigitizing books and unstructured documents, along with applications in other\ndomains such as mobility statistics, law enforcement, traffic, security\nsystems, etc. The state-of-the-art methods work well with the OCR with printed\ntext on license plates, shop names, etc. However, applications such as printed\ntextbooks and handwritten texts have limited accuracy with existing techniques.\nThe reason may be attributed to similar-looking characters and variations in\nhandwritten characters. Since these issues are challenging to address with OCR\ntechnologies exclusively, we propose a post-processing approach using Natural\nLanguage Processing (NLP) tools. This work presents an end-to-end pipeline that\nfirst performs OCR on the handwritten or printed text and then improves its\naccuracy using NLP.\n",
                "链接": "https://arxiv.org/abs/2307.04245"
            },
            {
                "文章ID": "94665",
                "标题": "Universal Defensive Underpainting Patch: Making Your Text Invisible to\n  Optical Character Recognition",
                "作者": " JiaCheng Deng,  Li Dong,  Jiahao Chen,  Diqun Yan,  Rangding Wang,  Dengpan Ye,  Lingchen Zhao,  Jinyu Tian",
                "发布日期": "2023-08-07",
                "摘要": "  Optical Character Recognition (OCR) enables automatic text extraction from\nscanned or digitized text images, but it also makes it easy to pirate valuable\nor sensitive text from these images. Previous methods to prevent OCR piracy by\ndistorting characters in text images are impractical in real-world scenarios,\nas pirates can capture arbitrary portions of the text images, rendering the\ndefenses ineffective. In this work, we propose a novel and effective defense\nmechanism termed the Universal Defensive Underpainting Patch (UDUP) that\nmodifies the underpainting of text images instead of the characters. UDUP is\ncreated through an iterative optimization process to craft a small, fixed-size\ndefensive patch that can generate non-overlapping underpainting for text images\nof any size. Experimental results show that UDUP effectively defends against\nunauthorized OCR under the setting of any screenshot range or complex image\nbackground. It is agnostic to the content, size, colors, and languages of\ncharacters, and is robust to typical image operations such as scaling and\ncompressing. In addition, the transferability of UDUP is demonstrated by\nevading several off-the-shelf OCRs. The code is available at\nhttps://github.com/QRICKDD/UDUP.\n",
                "链接": "https://arxiv.org/abs/2308.02369"
            },
            {
                "文章ID": "123651",
                "标题": "Advancements and Challenges in Arabic Optical Character Recognition: A\n  Comprehensive Survey",
                "作者": " Mahmoud SalahEldin Kasem,  Mohamed Mahmoud,  Hyun-Soo Kang",
                "发布日期": "2023-12-20",
                "摘要": "  Optical character recognition (OCR) is a vital process that involves the\nextraction of handwritten or printed text from scanned or printed images,\nconverting it into a format that can be understood and processed by machines.\nThis enables further data processing activities such as searching and editing.\nThe automatic extraction of text through OCR plays a crucial role in digitizing\ndocuments, enhancing productivity, improving accessibility, and preserving\nhistorical records. This paper seeks to offer an exhaustive review of\ncontemporary applications, methodologies, and challenges associated with Arabic\nOptical Character Recognition (OCR). A thorough analysis is conducted on\nprevailing techniques utilized throughout the OCR process, with a dedicated\neffort to discern the most efficacious approaches that demonstrate enhanced\noutcomes. To ensure a thorough evaluation, a meticulous keyword-search\nmethodology is adopted, encompassing a comprehensive analysis of articles\nrelevant to Arabic OCR, including both backward and forward citation reviews.\nIn addition to presenting cutting-edge techniques and methods, this paper\ncritically identifies research gaps within the realm of Arabic OCR. By\nhighlighting these gaps, we shed light on potential areas for future\nexploration and development, thereby guiding researchers toward promising\navenues in the field of Arabic OCR. The outcomes of this study provide valuable\ninsights for researchers, practitioners, and stakeholders involved in Arabic\nOCR, ultimately fostering advancements in the field and facilitating the\ncreation of more accurate and efficient OCR systems for the Arabic language.\n",
                "链接": "https://arxiv.org/abs/2312.11812"
            },
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "54214",
                "标题": "Transferring General Multimodal Pretrained Models to Text Recognition",
                "作者": " Junyang Lin,  Xuancheng Ren,  Yichang Zhang,  Gao Liu,  Peng Wang,  An Yang,  Chang Zhou",
                "发布日期": "2022-12-20",
                "摘要": "  This paper proposes a new method, OFA-OCR, to transfer multimodal pretrained\nmodels to text recognition. Specifically, we recast text recognition as image\ncaptioning and directly transfer a unified vision-language pretrained model to\nthe end task. Without pretraining on large-scale annotated or synthetic text\nrecognition data, OFA-OCR outperforms the baselines and achieves\nstate-of-the-art performance in the Chinese text recognition benchmark.\nAdditionally, we construct an OCR pipeline with OFA-OCR, and we demonstrate\nthat it can achieve competitive performance with the product-level API. The\ncode (https://github.com/OFA-Sys/OFA) and demo\n(https://modelscope.cn/studios/damo/ofa_ocr_pipeline/summary) are publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2212.09297"
            },
            {
                "文章ID": "19103",
                "标题": "An empirical study of CTC based models for OCR of Indian languages",
                "作者": " Minesh Mathew,  CV Jawahar",
                "发布日期": "2022-05-16",
                "摘要": "  Recognition of text on word or line images, without the need for sub-word\nsegmentation has become the mainstream of research and development of text\nrecognition for Indian languages. Modelling unsegmented sequences using\nConnectionist Temporal Classification (CTC) is the most commonly used approach\nfor segmentation-free OCR. In this work we present a comprehensive empirical\nstudy of various neural network models that uses CTC for transcribing step-wise\npredictions in the neural network output to a Unicode sequence. The study is\nconducted for 13 Indian languages, using an internal dataset that has around\n1000 pages per language. We study the choice of line vs word as the recognition\nunit, and use of synthetic data to train the models. We compare our models with\npopular publicly available OCR tools for end-to-end document image recognition.\nOur end-to-end pipeline that employ our recognition models and existing text\nsegmentation tools outperform these public OCR tools for 8 out of the 13\nlanguages. We also introduce a new public dataset called Mozhi for word and\nline recognition in Indian language. The dataset contains more than 1.2 million\nannotated word images (120 thousand text lines) across 13 Indian languages. Our\ncode, trained models and the Mozhi dataset will be made available at\nhttp://cvit.iiit.ac.in/research/projects/cvit-projects/\n",
                "链接": "https://arxiv.org/abs/2205.06740"
            },
            {
                "文章ID": "115320",
                "标题": "What Large Language Models Bring to Text-rich VQA?",
                "作者": " Xuejing Liu,  Wei Tang,  Xinzhe Ni,  Jinghui Lu,  Rui Zhao,  Zechao Li,  Fei Tan",
                "发布日期": "2023-11-14",
                "摘要": "  Text-rich VQA, namely Visual Question Answering based on text recognition in\nthe images, is a cross-modal task that requires both image comprehension and\ntext recognition. In this work, we focus on investigating the advantages and\nbottlenecks of LLM-based approaches in addressing this problem. To address the\nabove concern, we separate the vision and language modules, where we leverage\nexternal OCR models to recognize texts in the image and Large Language Models\n(LLMs) to answer the question given texts. The whole framework is training-free\nbenefiting from the in-context ability of LLMs. This pipeline achieved superior\nperformance compared to the majority of existing Multimodal Large Language\nModels (MLLM) on four text-rich VQA datasets. Besides, based on the ablation\nstudy, we find that LLM brings stronger comprehension ability and may introduce\nhelpful knowledge for the VQA problem. The bottleneck for LLM to address\ntext-rich VQA problems may primarily lie in visual part. We also combine the\nOCR module with MLLMs and pleasantly find that the combination of OCR module\nwith MLLM also works. It's worth noting that not all MLLMs can comprehend the\nOCR information, which provides insights into how to train an MLLM that\npreserves the abilities of LLM.\n",
                "链接": "https://arxiv.org/abs/2311.07306"
            },
            {
                "文章ID": "55598",
                "标题": "A Comprehensive Gold Standard and Benchmark for Comics Text Detection\n  and Recognition",
                "作者": " Gürkan Soykan,  Deniz Yuret,  Tevfik Metin Sezgin",
                "发布日期": "2023-01-02",
                "摘要": "  This study focuses on improving the optical character recognition (OCR) data\nfor panels in the COMICS dataset, the largest dataset containing text and\nimages from comic books. To do this, we developed a pipeline for OCR processing\nand labeling of comic books and created the first text detection and\nrecognition datasets for western comics, called \"COMICS Text+: Detection\" and\n\"COMICS Text+: Recognition\". We evaluated the performance of state-of-the-art\ntext detection and recognition models on these datasets and found significant\nimprovement in word accuracy and normalized edit distance compared to the text\nin COMICS. We also created a new dataset called \"COMICS Text+\", which contains\nthe extracted text from the textboxes in the COMICS dataset. Using the improved\ntext data of COMICS Text+ in the comics processing model from resulted in\nstate-of-the-art performance on cloze-style tasks without changing the model\narchitecture. The COMICS Text+ dataset can be a valuable resource for\nresearchers working on tasks including text detection, recognition, and\nhigh-level processing of comics, such as narrative understanding, character\nrelations, and story generation. All the data and inference instructions can be\naccessed in https://github.com/gsoykan/comics_text_plus.\n",
                "链接": "https://arxiv.org/abs/2212.14674"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月agent系列决策文章。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找多模态优化训练方式的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "13600",
                "标题": "Training-Free Robust Multimodal Learning via Sample-Wise Jacobian\n  Regularization",
                "作者": " Zhengqi Gao,  Sucheng Ren,  Zihui Xue,  Siting Li,  Hang Zhao",
                "发布日期": "2022-04-07",
                "摘要": "  Multimodal fusion emerges as an appealing technique to improve model\nperformances on many tasks. Nevertheless, the robustness of such fusion methods\nis rarely involved in the present literature. In this paper, we propose a\ntraining-free robust late-fusion method by exploiting conditional independence\nassumption and Jacobian regularization. Our key is to minimize the Frobenius\nnorm of a Jacobian matrix, where the resulting optimization problem is relaxed\nto a tractable Sylvester equation. Furthermore, we provide a theoretical error\nbound of our method and some insights about the function of the extra modality.\nSeveral numerical experiments on AV-MNIST, RAVDESS, and VGGsound demonstrate\nthe efficacy of our method under both adversarial attacks and random\ncorruptions.\n",
                "链接": "https://arxiv.org/abs/2204.02485"
            },
            {
                "文章ID": "54383",
                "标题": "Generalizing Multimodal Variational Methods to Sets",
                "作者": " Jinzhao Zhou,  Yiqun Duan,  Zhihong Chen,  Yu-Cheng Chang,  Chin-Teng Lin",
                "发布日期": "2022-12-21",
                "摘要": "  Making sense of multiple modalities can yield a more comprehensive\ndescription of real-world phenomena. However, learning the co-representation of\ndiverse modalities is still a long-standing endeavor in emerging machine\nlearning applications and research. Previous generative approaches for\nmultimodal input approximate a joint-modality posterior by uni-modality\nposteriors as product-of-experts (PoE) or mixture-of-experts (MoE). We argue\nthat these approximations lead to a defective bound for the optimization\nprocess and loss of semantic connection among modalities. This paper presents a\nnovel variational method on sets called the Set Multimodal VAE (SMVAE) for\nlearning a multimodal latent space while handling the missing modality problem.\nBy modeling the joint-modality posterior distribution directly, the proposed\nSMVAE learns to exchange information between multiple modalities and compensate\nfor the drawbacks caused by factorization. In public datasets of various\ndomains, the experimental results demonstrate that the proposed method is\napplicable to order-agnostic cross-modal generation while achieving outstanding\nperformance compared to the state-of-the-art multimodal methods. The source\ncode for our method is available online\nhttps://anonymous.4open.science/r/SMVAE-9B3C/.\n",
                "链接": "https://arxiv.org/abs/2212.09918"
            },
            {
                "文章ID": "16766",
                "标题": "Talking Head Generation Driven by Speech-Related Facial Action Units and\n  Audio- Based on Multimodal Representation Fusion",
                "作者": " Sen Chen,  Zhilei Liu,  Jiaxing Liu,  Longbiao Wang",
                "发布日期": "2022-04-28",
                "摘要": "  Talking head generation is to synthesize a lip-synchronized talking head\nvideo by inputting an arbitrary face image and corresponding audio clips.\nExisting methods ignore not only the interaction and relationship of\ncross-modal information, but also the local driving information of the mouth\nmuscles. In this study, we propose a novel generative framework that contains a\ndilated non-causal temporal convolutional self-attention network as a\nmultimodal fusion module to promote the relationship learning of cross-modal\nfeatures. In addition, our proposed method uses both audio- and speech-related\nfacial action units (AUs) as driving information. Speech-related AU information\ncan guide mouth movements more accurately. Because speech is highly correlated\nwith speech-related AUs, we propose an audio-to-AU module to predict\nspeech-related AU information. We utilize pre-trained AU classifier to ensure\nthat the generated images contain correct AU information. We verify the\neffectiveness of the proposed model on the GRID and TCD-TIMIT datasets. An\nablation study is also conducted to verify the contribution of each component.\nThe results of quantitative and qualitative experiments demonstrate that our\nmethod outperforms existing methods in terms of both image quality and lip-sync\naccuracy.\n",
                "链接": "https://arxiv.org/abs/2204.12756"
            },
            {
                "文章ID": "61490",
                "标题": "Relatedly: Scaffolding Literature Reviews with Existing Related Work\n  Sections",
                "作者": " Srishti Palani,  Aakanksha Naik,  Doug Downey,  Amy X. Zhang,  Jonathan Bragg,  Joseph Chee Chang",
                "发布日期": "2023-02-15",
                "摘要": "  Scholars who want to research a scientific topic must take time to read,\nextract meaning, and identify connections across many papers. As scientific\nliterature grows, this becomes increasingly challenging. Meanwhile, authors\nsummarize prior research in papers' related work sections, though this is\nscoped to support a single paper. A formative study found that while reading\nmultiple related work paragraphs helps overview a topic, it is hard to navigate\noverlapping and diverging references and research foci. In this work, we design\na system, Relatedly, that scaffolds exploring and reading multiple related work\nparagraphs on a topic, with features including dynamic re-ranking and\nhighlighting to spotlight unexplored dissimilar information, auto-generated\ndescriptive paragraph headings, and low-lighting of redundant information. From\na within-subjects user study (n=15), we found that scholars generate more\ncoherent, insightful, and comprehensive topic outlines using Relatedly compared\nto a baseline paper list.\n",
                "链接": "https://arxiv.org/abs/2302.06754"
            },
            {
                "文章ID": "14551",
                "标题": "CLMLF:A Contrastive Learning and Multi-Layer Fusion Method for\n  Multimodal Sentiment Detection",
                "作者": " Zhen Li,  Bing Xu,  Conghui Zhu,  Tiejun Zhao",
                "发布日期": "2022-06-15",
                "摘要": "  Compared with unimodal data, multimodal data can provide more features to\nhelp the model analyze the sentiment of data. Previous research works rarely\nconsider token-level feature fusion, and few works explore learning the common\nfeatures related to sentiment in multimodal data to help the model fuse\nmultimodal features. In this paper, we propose a Contrastive Learning and\nMulti-Layer Fusion (CLMLF) method for multimodal sentiment detection.\nSpecifically, we first encode text and image to obtain hidden representations,\nand then use a multi-layer fusion module to align and fuse the token-level\nfeatures of text and image. In addition to the sentiment analysis task, we also\ndesigned two contrastive learning tasks, label based contrastive learning and\ndata based contrastive learning tasks, which will help the model learn common\nfeatures related to sentiment in multimodal data. Extensive experiments\nconducted on three publicly available multimodal datasets demonstrate the\neffectiveness of our approach for multimodal sentiment detection compared with\nexisting methods. The codes are available for use at\nhttps://github.com/Link-Li/CLMLF\n",
                "链接": "https://arxiv.org/abs/2204.05515"
            },
            {
                "文章ID": "51588",
                "标题": "Differentially Private Adaptive Optimization with Delayed\n  Preconditioners",
                "作者": " Tian Li,  Manzil Zaheer,  Ken Ziyu Liu,  Sashank J. Reddi,  H. Brendan McMahan,  Virginia Smith",
                "发布日期": "2023-06-09",
                "摘要": "  Privacy noise may negate the benefits of using adaptive optimizers in\ndifferentially private model training. Prior works typically address this issue\nby using auxiliary information (e.g., public data) to boost the effectiveness\nof adaptive optimization. In this work, we explore techniques to estimate and\nefficiently adapt to gradient geometry in private adaptive optimization without\nauxiliary data. Motivated by the observation that adaptive methods can tolerate\nstale preconditioners, we propose differentially private adaptive training with\ndelayed preconditioners (DP^2), a simple method that constructs delayed but\nless noisy preconditioners to better realize the benefits of adaptivity.\nTheoretically, we provide convergence guarantees for our method for both convex\nand non-convex problems, and analyze trade-offs between delay and privacy noise\nreduction. Empirically, we explore DP^2 across several real-world datasets,\ndemonstrating that it can improve convergence speed by as much as 4x relative\nto non-adaptive baselines and match the performance of state-of-the-art\noptimization methods that require auxiliary data.\n",
                "链接": "https://arxiv.org/abs/2212.00309"
            },
            {
                "文章ID": "53134",
                "标题": "Mutimodal Ranking Optimization for Heterogeneous Face Re-identification",
                "作者": " Hui Hu,  Jiawei Zhang,  Zhen Han",
                "发布日期": "2022-12-13",
                "摘要": "  Heterogeneous face re-identification, namely matching heterogeneous faces\nacross disjoint visible light (VIS) and near-infrared (NIR) cameras, has become\nan important problem in video surveillance application. However, the large\ndomain discrepancy between heterogeneous NIR-VIS faces makes the performance of\nface re-identification degraded dramatically. To solve this problem, a\nmultimodal fusion ranking optimization algorithm for heterogeneous face\nre-identification is proposed in this paper. Firstly, we design a heterogeneous\nface translation network to obtain multimodal face pairs, including\nNIR-VIS/NIR-NIR/VIS-VIS face pairs, through mutual transformation between\nNIR-VIS faces. Secondly, we propose linear and non-linear fusion strategies to\naggregate initial ranking lists of multimodal face pairs and acquire the\noptimized re-ranked list based on modal complementarity. The experimental\nresults show that the proposed multimodal fusion ranking optimization algorithm\ncan effectively utilize the complementarity and outperforms some relative\nmethods on the SCface dataset.\n",
                "链接": "https://arxiv.org/abs/2212.05510"
            },
            {
                "文章ID": "95233",
                "标题": "TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal\n  Backdoored Models",
                "作者": " Indranil Sur,  Karan Sikka,  Matthew Walmer,  Kaushik Koneripalli,  Anirban Roy,  Xiao Lin,  Ajay Divakaran,  Susmit Jha",
                "发布日期": "2023-08-09",
                "摘要": "  We present a Multimodal Backdoor Defense technique TIJO (Trigger Inversion\nusing Joint Optimization). Recent work arXiv:2112.07668 has demonstrated\nsuccessful backdoor attacks on multimodal models for the Visual Question\nAnswering task. Their dual-key backdoor trigger is split across two modalities\n(image and text), such that the backdoor is activated if and only if the\ntrigger is present in both modalities. We propose TIJO that defends against\ndual-key attacks through a joint optimization that reverse-engineers the\ntrigger in both the image and text modalities. This joint optimization is\nchallenging in multimodal models due to the disconnected nature of the visual\npipeline which consists of an offline feature extractor, whose output is then\nfused with the text using a fusion module. The key insight enabling the joint\noptimization in TIJO is that the trigger inversion needs to be carried out in\nthe object detection box feature space as opposed to the pixel space. We\ndemonstrate the effectiveness of our method on the TrojVQA benchmark, where\nTIJO improves upon the state-of-the-art unimodal methods from an AUC of 0.6 to\n0.92 on multimodal dual-key backdoors. Furthermore, our method also improves\nupon the unimodal baselines on unimodal backdoors. We present ablation studies\nand qualitative results to provide insights into our algorithm such as the\ncritical importance of overlaying the inverted feature triggers on all visual\nfeatures during trigger inversion. The prototype implementation of TIJO is\navailable at https://github.com/SRI-CSL/TIJO.\n",
                "链接": "https://arxiv.org/abs/2308.03906"
            },
            {
                "文章ID": "40513",
                "标题": "ASIF: Coupled Data Turns Unimodal Models to Multimodal Without Training",
                "作者": " Antonio Norelli,  Marco Fumero,  Valentino Maiorca,  Luca Moschella,  Emanuele Rodolà,  Francesco Locatello",
                "发布日期": "2023-11-13",
                "摘要": "  CLIP proved that aligning visual and language spaces is key to solving many\nvision tasks without explicit training, but required to train image and text\nencoders from scratch on a huge dataset. LiT improved this by only training the\ntext encoder and using a pre-trained vision network. In this paper, we show\nthat a common space can be created without any training at all, using\nsingle-domain encoders (trained with or without supervision) and a much smaller\namount of image-text pairs. Furthermore, our model has unique properties. Most\nnotably, deploying a new version with updated training samples can be done in a\nmatter of seconds. Additionally, the representations in the common space are\neasily interpretable as every dimension corresponds to the similarity of the\ninput to a unique image-text pair in the multimodal dataset. Experiments on\nstandard zero-shot visual benchmarks demonstrate the typical transfer ability\nof image-text models. Overall, our method represents a simple yet surprisingly\nstrong baseline for foundation multimodal models, raising important questions\non their data efficiency and on the role of retrieval in machine learning.\n",
                "链接": "https://arxiv.org/abs/2210.01738"
            },
            {
                "文章ID": "116988",
                "标题": "Multimodal Machine Unlearning",
                "作者": " Jiali Cheng,  Hadi Amiri",
                "发布日期": "2023-11-22",
                "摘要": "  Machine Unlearning is the process of removing specific training data samples\nand their corresponding effects from an already trained model. It has\nsignificant practical benefits, such as purging private, inaccurate, or\noutdated information from trained models without the need for complete\nre-training. Unlearning within a multimodal setting presents unique challenges\ndue to the intrinsic dependencies between different data modalities and the\nexpensive cost of training on large multimodal datasets and architectures.\nCurrent approaches to machine unlearning have not fully addressed these\nchallenges. To bridge this gap, we introduce MMUL, a machine unlearning\napproach specifically designed for multimodal data and models. MMUL formulates\nthe multimodal unlearning task by focusing on three key properties: (a):\nmodality decoupling, which effectively decouples the association between\nindividual unimodal data points within multimodal inputs marked for deletion,\nrendering them as unrelated data points within the model's context, (b):\nunimodal knowledge retention, which retains the unimodal representation\ncapability of the model post-unlearning, and (c): multimodal knowledge\nretention, which retains the multimodal representation capability of the model\npost-unlearning. MMUL is efficient to train and is not constrained by the\nrequirement of using a strongly convex loss. Experiments on two multimodal\nmodels and four multimodal benchmark datasets, including vision-language and\ngraph-language datasets, show that MMUL outperforms existing baselines, gaining\nan average improvement of +17.6 points against the best-performing unimodal\nbaseline in distinguishing between deleted and remaining data. In addition,\nMMUL can largely maintain pre-existing knowledge of the original model post\nunlearning, with a performance gap of only 0.3 points compared to retraining a\nnew model from scratch.\n",
                "链接": "https://arxiv.org/abs/2311.12047"
            }
        ]
    },
    {
        "question": {
            "question": "与大模型安全相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "109885",
                "标题": "Safety-Gymnasium: A Unified Safe Reinforcement Learning Benchmark",
                "作者": " Jiaming Ji,  Borong Zhang,  Jiayi Zhou,  Xuehai Pan,  Weidong Huang,  Ruiyang Sun,  Yiran Geng,  Yifan Zhong,  Juntao Dai,  Yaodong Yang",
                "发布日期": "2023-11-08",
                "摘要": "  Artificial intelligence (AI) systems possess significant potential to drive\nsocietal progress. However, their deployment often faces obstacles due to\nsubstantial safety concerns. Safe reinforcement learning (SafeRL) emerges as a\nsolution to optimize policies while simultaneously adhering to multiple\nconstraints, thereby addressing the challenge of integrating reinforcement\nlearning in safety-critical scenarios. In this paper, we present an environment\nsuite called Safety-Gymnasium, which encompasses safety-critical tasks in both\nsingle and multi-agent scenarios, accepting vector and vision-only input.\nAdditionally, we offer a library of algorithms named Safe Policy Optimization\n(SafePO), comprising 16 state-of-the-art SafeRL algorithms. This comprehensive\nlibrary can serve as a validation tool for the research community. By\nintroducing this benchmark, we aim to facilitate the evaluation and comparison\nof safety performance, thus fostering the development of reinforcement learning\nfor safer, more reliable, and responsible real-world applications. The website\nof this project can be accessed at\nhttps://sites.google.com/view/safety-gymnasium.\n",
                "链接": "https://arxiv.org/abs/2310.12567"
            },
            {
                "文章ID": "4874",
                "标题": "SAFER: Data-Efficient and Safe Reinforcement Learning via Skill\n  Acquisition",
                "作者": " Dylan Slack,  Yinlam Chow,  Bo Dai,  Nevan Wichers",
                "发布日期": "2022-07-04",
                "摘要": "  Methods that extract policy primitives from offline demonstrations using deep\ngenerative models have shown promise at accelerating reinforcement learning(RL)\nfor new tasks. Intuitively, these methods should also help to trainsafeRLagents\nbecause they enforce useful skills. However, we identify these techniques are\nnot well equipped for safe policy learning because they ignore negative\nexperiences(e.g., unsafe or unsuccessful), focusing only on positive\nexperiences, which harms their ability to generalize to new tasks safely.\nRather, we model the latentsafetycontextusing principled contrastive training\non an offline dataset of demonstrations from many tasks, including both\nnegative and positive experiences. Using this late variable, our RL framework,\nSAFEty skill pRiors (SAFER) extracts task-specific safe primitive skills to\nsafely and successfully generalize to new tasks. In the inference stage,\npolicies trained with SAFER learn to compose safe skills into successful\npolicies. We theoretically characterize why SAFER can enforce safe policy\nlearning and demonstrate its effectiveness on several complex safety-critical\nrobotic grasping tasks inspired by the game Operation, in which\nSAFERoutperforms state-of-the-art primitive learning methods in success and\nsafety.\n",
                "链接": "https://arxiv.org/abs/2202.04849"
            },
            {
                "文章ID": "77788",
                "标题": "OmniSafe: An Infrastructure for Accelerating Safe Reinforcement Learning\n  Research",
                "作者": " Jiaming Ji,  Jiayi Zhou,  Borong Zhang,  Juntao Dai,  Xuehai Pan,  Ruiyang Sun,  Weidong Huang,  Yiran Geng,  Mickel Liu,  Yaodong Yang",
                "发布日期": "2023-05-17",
                "摘要": "  AI systems empowered by reinforcement learning (RL) algorithms harbor the\nimmense potential to catalyze societal advancement, yet their deployment is\noften impeded by significant safety concerns. Particularly in safety-critical\napplications, researchers have raised concerns about unintended harms or unsafe\nbehaviors of unaligned RL agents. The philosophy of safe reinforcement learning\n(SafeRL) is to align RL agents with harmless intentions and safe behavioral\npatterns. In SafeRL, agents learn to develop optimal policies by receiving\nfeedback from the environment, while also fulfilling the requirement of\nminimizing the risk of unintended harm or unsafe behavior. However, due to the\nintricate nature of SafeRL algorithm implementation, combining methodologies\nacross various domains presents a formidable challenge. This had led to an\nabsence of a cohesive and efficacious learning framework within the\ncontemporary SafeRL research milieu. In this work, we introduce a foundational\nframework designed to expedite SafeRL research endeavors. Our comprehensive\nframework encompasses an array of algorithms spanning different RL domains and\nplaces heavy emphasis on safety elements. Our efforts are to make the\nSafeRL-related research process more streamlined and efficient, therefore\nfacilitating further research in AI safety. Our project is released at:\nhttps://github.com/PKU-Alignment/omnisafe.\n",
                "链接": "https://arxiv.org/abs/2305.09304"
            },
            {
                "文章ID": "61419",
                "标题": "Towards Agile Text Classifiers for Everyone",
                "作者": " Maximilian Mozes,  Jessica Hoffmann,  Katrin Tomanek,  Muhamed Kouate,  Nithum Thain,  Ann Yuan,  Tolga Bolukbasi,  Lucas Dixon",
                "发布日期": "2023-10-24",
                "摘要": "  Text-based safety classifiers are widely used for content moderation and\nincreasingly to tune generative language model behavior - a topic of growing\nconcern for the safety of digital assistants and chatbots. However, different\npolicies require different classifiers, and safety policies themselves improve\nfrom iteration and adaptation. This paper introduces and evaluates methods for\nagile text classification, whereby classifiers are trained using small,\ntargeted datasets that can be quickly developed for a particular policy.\nExperimenting with 7 datasets from three safety-related domains, comprising 15\nannotation schemes, led to our key finding: prompt-tuning large language\nmodels, like PaLM 62B, with a labeled dataset of as few as 80 examples can\nachieve state-of-the-art performance. We argue that this enables a paradigm\nshift for text classification, especially for models supporting safer online\ndiscourse. Instead of collecting millions of examples to attempt to create\nuniversal safety classifiers over months or years, classifiers could be tuned\nusing small datasets, created by individuals or small organizations, tailored\nfor specific use cases, and iterated on and adapted in the time-span of a day.\n",
                "链接": "https://arxiv.org/abs/2302.06541"
            },
            {
                "文章ID": "53187",
                "标题": "Evaluating Model-free Reinforcement Learning toward Safety-critical\n  Tasks",
                "作者": " Linrui Zhang,  Qin Zhang,  Li Shen,  Bo Yuan,  Xueqian Wang,  Dacheng Tao",
                "发布日期": "2022-12-13",
                "摘要": "  Safety comes first in many real-world applications involving autonomous\nagents. Despite a large number of reinforcement learning (RL) methods focusing\non safety-critical tasks, there is still a lack of high-quality evaluation of\nthose algorithms that adheres to safety constraints at each decision step under\ncomplex and unknown dynamics. In this paper, we revisit prior work in this\nscope from the perspective of state-wise safe RL and categorize them as\nprojection-based, recovery-based, and optimization-based approaches,\nrespectively. Furthermore, we propose Unrolling Safety Layer (USL), a joint\nmethod that combines safety optimization and safety projection. This novel\ntechnique explicitly enforces hard constraints via the deep unrolling\narchitecture and enjoys structural advantages in navigating the trade-off\nbetween reward improvement and constraint satisfaction. To facilitate further\nresearch in this area, we reproduce related algorithms in a unified pipeline\nand incorporate them into SafeRL-Kit, a toolkit that provides off-the-shelf\ninterfaces and evaluation utilities for safety-critical tasks. We then perform\na comparative study of the involved algorithms on six benchmarks ranging from\nrobotic control to autonomous driving. The empirical results provide an insight\ninto their applicability and robustness in learning zero-cost-return policies\nwithout task-dependent handcrafting. The project page is available at\nhttps://sites.google.com/view/saferlkit.\n",
                "链接": "https://arxiv.org/abs/2212.05727"
            },
            {
                "文章ID": "106345",
                "标题": "Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models",
                "作者": " Xianjun Yang,  Xiao Wang,  Qi Zhang,  Linda Petzold,  William Yang Wang,  Xun Zhao,  Dahua Lin",
                "发布日期": "2023-10-05",
                "摘要": "  Warning: This paper contains examples of harmful language, and reader\ndiscretion is recommended. The increasing open release of powerful large\nlanguage models (LLMs) has facilitated the development of downstream\napplications by reducing the essential cost of data annotation and computation.\nTo ensure AI safety, extensive safety-alignment measures have been conducted to\narmor these models against malicious use (primarily hard prompt attack).\nHowever, beneath the seemingly resilient facade of the armor, there might lurk\na shadow. By simply tuning on 100 malicious examples with 1 GPU hour, these\nsafely aligned LLMs can be easily subverted to generate harmful content.\nFormally, we term a new attack as Shadow Alignment: utilizing a tiny amount of\ndata can elicit safely-aligned models to adapt to harmful tasks without\nsacrificing model helpfulness. Remarkably, the subverted models retain their\ncapability to respond appropriately to regular inquiries. Experiments across 8\nmodels released by 5 different organizations (LLaMa-2, Falcon, InternLM,\nBaiChuan2, Vicuna) demonstrate the effectiveness of shadow alignment attack.\nBesides, the single-turn English-only attack successfully transfers to\nmulti-turn dialogue and other languages. This study serves as a clarion call\nfor a collective effort to overhaul and fortify the safety of open-source LLMs\nagainst malicious attackers.\n",
                "链接": "https://arxiv.org/abs/2310.02949"
            },
            {
                "文章ID": "107434",
                "标题": "SC-Safety: A Multi-round Open-ended Question Adversarial Safety\n  Benchmark for Large Language Models in Chinese",
                "作者": " Liang Xu,  Kangkang Zhao,  Lei Zhu,  Hang Xue",
                "发布日期": "2023-10-10",
                "摘要": "  Large language models (LLMs), like ChatGPT and GPT-4, have demonstrated\nremarkable abilities in natural language understanding and generation. However,\nalongside their positive impact on our daily tasks, they can also produce\nharmful content that negatively affects societal perceptions. To systematically\nassess the safety of Chinese LLMs, we introduce SuperCLUE-Safety (SC-Safety) -\na multi-round adversarial benchmark with 4912 open-ended questions covering\nmore than 20 safety sub-dimensions. Adversarial human-model interactions and\nconversations significantly increase the challenges compared to existing\nmethods. Experiments on 13 major LLMs supporting Chinese yield the following\ninsights: 1) Closed-source models outperform open-sourced ones in terms of\nsafety; 2) Models released from China demonstrate comparable safety levels to\nLLMs like GPT-3.5-turbo; 3) Some smaller models with 6B-13B parameters can\ncompete effectively in terms of safety. By introducing SC-Safety, we aim to\npromote collaborative efforts to create safer and more trustworthy LLMs. The\nbenchmark and findings provide guidance on model selection. Our benchmark can\nbe found at https://www.CLUEbenchmarks.com\n",
                "链接": "https://arxiv.org/abs/2310.05818"
            },
            {
                "文章ID": "108817",
                "标题": "ASSERT: Automated Safety Scenario Red Teaming for Evaluating the\n  Robustness of Large Language Models",
                "作者": " Alex Mei,  Sharon Levy,  William Yang Wang",
                "发布日期": "2023-11-14",
                "摘要": "  As large language models are integrated into society, robustness toward a\nsuite of prompts is increasingly important to maintain reliability in a\nhigh-variance environment.Robustness evaluations must comprehensively\nencapsulate the various settings in which a user may invoke an intelligent\nsystem. This paper proposes ASSERT, Automated Safety Scenario Red Teaming,\nconsisting of three methods -- semantically aligned augmentation, target\nbootstrapping, and adversarial knowledge injection. For robust safety\nevaluation, we apply these methods in the critical domain of AI safety to\nalgorithmically generate a test suite of prompts covering diverse robustness\nsettings -- semantic equivalence, related scenarios, and adversarial. We\npartition our prompts into four safety domains for a fine-grained analysis of\nhow the domain affects model performance. Despite dedicated safeguards in\nexisting state-of-the-art models, we find statistically significant performance\ndifferences of up to 11% in absolute classification accuracy among semantically\nrelated scenarios and error rates of up to 19% absolute error in zero-shot\nadversarial settings, raising concerns for users' physical safety.\n",
                "链接": "https://arxiv.org/abs/2310.09624"
            },
            {
                "文章ID": "51582",
                "标题": "Rethinking Safe Control in the Presence of Self-Seeking Humans",
                "作者": " Zixuan Zhang,  Maitham AL-Sunni,  Haoming Jing,  Hirokazu Shirado,  Yorie Nakahira",
                "发布日期": "2023-02-13",
                "摘要": "  Safe control methods are often intended to behave safely even in worst-case\nhuman uncertainties. However, humans may exploit such safety-first systems,\nwhich results in greater risk for everyone. Despite their significance, no\nprior work has investigated and accounted for such factors in safe control. In\nthis paper, we leverage an interaction-based payoff structure from game theory\nto model humans' short-sighted, self-seeking behaviors and how humans change\ntheir strategies toward machines based on prior experience. We integrate such\nstrategic human behaviors into a safe control architecture. As a result, our\napproach achieves better safety and performance trade-offs when compared to\nboth deterministic worst-case safe control techniques and equilibrium-based\nstochastic methods. Our findings suggest an urgent need to fundamentally\nrethink the safe control framework used in human-technology interaction in\npursuit of greater safety for all.\n",
                "链接": "https://arxiv.org/abs/2212.00295"
            },
            {
                "文章ID": "31317",
                "标题": "Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion\n  Transformer",
                "作者": " Hao Shao,  Letian Wang,  RuoBing Chen,  Hongsheng Li,  Yu Liu",
                "发布日期": "2022-12-08",
                "摘要": "  Large-scale deployment of autonomous vehicles has been continually delayed\ndue to safety concerns. On the one hand, comprehensive scene understanding is\nindispensable, a lack of which would result in vulnerability to rare but\ncomplex traffic situations, such as the sudden emergence of unknown objects.\nHowever, reasoning from a global context requires access to sensors of multiple\ntypes and adequate fusion of multi-modal sensor signals, which is difficult to\nachieve. On the other hand, the lack of interpretability in learning models\nalso hampers the safety with unverifiable failure causes. In this paper, we\npropose a safety-enhanced autonomous driving framework, named Interpretable\nSensor Fusion Transformer(InterFuser), to fully process and fuse information\nfrom multi-modal multi-view sensors for achieving comprehensive scene\nunderstanding and adversarial event detection. Besides, intermediate\ninterpretable features are generated from our framework, which provide more\nsemantics and are exploited to better constrain actions to be within the safe\nsets. We conducted extensive experiments on CARLA benchmarks, where our model\noutperforms prior methods, ranking the first on the public CARLA Leaderboard.\nOur code will be made available at https://github.com/opendilab/InterFuser\n",
                "链接": "https://arxiv.org/abs/2207.14024"
            }
        ]
    },
    {
        "question": {
            "question": "查找大模型推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "108690",
                "标题": "User Inference Attacks on Large Language Models",
                "作者": " Nikhil Kandpal,  Krishna Pillutla,  Alina Oprea,  Peter Kairouz,  Christopher A. Choquette-Choo,  Zheng Xu",
                "发布日期": "2023-10-16",
                "摘要": "  Fine-tuning is a common and effective method for tailoring large language\nmodels (LLMs) to specialized tasks and applications. In this paper, we study\nthe privacy implications of fine-tuning LLMs on user data. To this end, we\ndefine a realistic threat model, called user inference, wherein an attacker\ninfers whether or not a user's data was used for fine-tuning. We implement\nattacks for this threat model that require only a small set of samples from a\nuser (possibly different from the samples used for training) and black-box\naccess to the fine-tuned LLM. We find that LLMs are susceptible to user\ninference attacks across a variety of fine-tuning datasets, at times with near\nperfect attack success rates. Further, we investigate which properties make\nusers vulnerable to user inference, finding that outlier users (i.e. those with\ndata distributions sufficiently different from other users) and users who\ncontribute large quantities of data are most susceptible to attack. Finally, we\nexplore several heuristics for mitigating privacy attacks. We find that\ninterventions in the training algorithm, such as batch or per-example gradient\nclipping and early stopping fail to prevent user inference. However, limiting\nthe number of fine-tuning samples from a single user can reduce attack\neffectiveness, albeit at the cost of reducing the total amount of fine-tuning\ndata.\n",
                "链接": "https://arxiv.org/abs/2310.09266"
            },
            {
                "文章ID": "113368",
                "标题": "FlashDecoding++: Faster Large Language Model Inference on GPUs",
                "作者": " Ke Hong,  Guohao Dai,  Jiaming Xu,  Qiuli Mao,  Xiuhong Li,  Jun Liu,  Kangdi Chen,  Yuhan Dong,  Yu Wang",
                "发布日期": "2023-11-13",
                "摘要": "  As the Large Language Model (LLM) becomes increasingly important in various\ndomains. However, the following challenges still remain unsolved in\naccelerating LLM inference: (1) Synchronized partial softmax update. The\nsoftmax operation requires a synchronized update operation among each partial\nsoftmax result, leading to ~20% overheads for the attention computation in\nLLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices\nperforming GEMM in LLM inference is flat, leading to under-utilized computation\nand >50% performance loss after padding zeros in previous designs. (3)\nPerformance loss due to static dataflow. Kernel performance in LLM depends on\nvaried input data features, hardware configurations, etc. A single and static\ndataflow may lead to a 50.25% performance loss for GEMMs of different shapes in\nLLM inference.\n  We present FlashDecoding++, a fast LLM inference engine supporting mainstream\nLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++\ncreatively proposes: (1) Asynchronized softmax with unified max value.\nFlashDecoding++ introduces a unified max value technique for different partial\nsoftmax computations to avoid synchronization. (2) Flat GEMM optimization with\ndouble buffering. FlashDecoding++ points out that flat GEMMs with different\nshapes face varied bottlenecks. Then, techniques like double buffering are\nintroduced. (3) Heuristic dataflow with hardware resource adaptation.\nFlashDecoding++ heuristically optimizes dataflow using different hardware\nresource considering input dynamics. Due to the versatility of optimizations in\nFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on\nboth NVIDIA and AMD GPUs compared to Hugging Face implementations.\nFlashDecoding++ also achieves an average speedup of 1.37x compared to\nstate-of-the-art LLM inference engines on mainstream LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.01282"
            },
            {
                "文章ID": "71550",
                "标题": "Inference with Reference: Lossless Acceleration of Large Language Models",
                "作者": " Nan Yang,  Tao Ge,  Liang Wang,  Binxing Jiao,  Daxin Jiang,  Linjun Yang,  Rangan Majumder,  Furu Wei",
                "发布日期": "2023-04-11",
                "摘要": "  We propose LLMA, an LLM accelerator to losslessly speed up Large Language\nModel (LLM) inference with references. LLMA is motivated by the observation\nthat there are abundant identical text spans between the decoding result by an\nLLM and the reference that is available in many real world scenarios (e.g.,\nretrieved documents). LLMA first selects a text span from the reference and\ncopies its tokens to the decoder and then efficiently checks the tokens'\nappropriateness as the decoding result in parallel within one decoding step.\nThe improved computational parallelism allows LLMA to achieve over 2x speed-up\nfor LLMs with identical generation results as greedy decoding in many practical\ngeneration scenarios where significant overlap between in-context reference and\noutputs exists (e.g., search engines and multi-turn conversations).\n",
                "链接": "https://arxiv.org/abs/2304.04487"
            },
            {
                "文章ID": "83366",
                "标题": "On Optimal Caching and Model Multiplexing for Large Model Inference",
                "作者": " Banghua Zhu,  Ying Sheng,  Lianmin Zheng,  Clark Barrett,  Michael I. Jordan,  Jiantao Jiao",
                "发布日期": "2023-08-30",
                "摘要": "  Large Language Models (LLMs) and other large foundation models have achieved\nnoteworthy success, but their size exacerbates existing resource consumption\nand latency challenges. In particular, the large-scale deployment of these\nmodels is hindered by the significant resource requirements during inference.\nIn this paper, we study two approaches for mitigating these challenges:\nemploying a cache to store previous queries and learning a model multiplexer to\nchoose from an ensemble of models for query processing.\n  Theoretically, we provide an optimal algorithm for jointly optimizing both\napproaches to reduce the inference cost in both offline and online tabular\nsettings. By combining a caching algorithm, namely Greedy Dual Size with\nFrequency (GDSF) or Least Expected Cost (LEC), with a model multiplexer, we\nachieve optimal rates in both offline and online settings. Empirically,\nsimulations show that the combination of our caching and model multiplexing\nalgorithms greatly improves over the baselines, with up to $50\\times$\nimprovement over the baseline when the ratio between the maximum cost and\nminimum cost is $100$. Experiments on real datasets show a $4.3\\times$\nimprovement in FLOPs over the baseline when the ratio for FLOPs is $10$, and a\n$1.8\\times$ improvement in latency when the ratio for average latency is\n$1.85$.\n",
                "链接": "https://arxiv.org/abs/2306.02003"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "18035",
                "标题": "A collection of invited non-archival papers for the Conference on\n  Health, Inference, and Learning (CHIL) 2022",
                "作者": " Gerardo Flores,  George H. Chen,  Tom Pollard,  Joyce C. Ho,  Tristan Naumann",
                "发布日期": "2022-05-06",
                "摘要": "  A collection of invited non-archival papers for the Conference on Health,\nInference, and Learning (CHIL) 2022. This index is incomplete as some authors\nof invited non-archival presentations opted not to include their papers in this\nindex.\n",
                "链接": "https://arxiv.org/abs/2205.02752"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "100993",
                "标题": "LLMCad: Fast and Scalable On-device Large Language Model Inference",
                "作者": " Daliang Xu,  Wangsong Yin,  Xin Jin,  Ying Zhang,  Shiyun Wei,  Mengwei Xu,  Xuanzhe Liu",
                "发布日期": "2023-09-11",
                "摘要": "  Generative tasks, such as text generation and question answering, hold a\ncrucial position in the realm of mobile applications. Due to their sensitivity\nto privacy concerns, there is a growing demand for their execution directly on\nmobile devices. Currently, the execution of these generative tasks heavily\ndepends on Large Language Models (LLMs). Nevertheless, the limited memory\ncapacity of these devices presents a formidable challenge to the scalability of\nsuch models.\n  In our research, we introduce LLMCad, an innovative on-device inference\nengine specifically designed for efficient generative Natural Language\nProcessing (NLP) tasks. The core idea behind LLMCad revolves around model\ncollaboration: a compact LLM, residing in memory, takes charge of generating\nthe most straightforward tokens, while a high-precision LLM steps in to\nvalidate these tokens and rectify any identified errors. LLMCad incorporates\nthree novel techniques: (1) Instead of generating candidate tokens in a\nsequential manner, LLMCad employs the smaller LLM to construct a token tree,\nencompassing a wider range of plausible token pathways. Subsequently, the\nlarger LLM can efficiently validate all of these pathways simultaneously. (2)\nIt employs a self-adjusting fallback strategy, swiftly initiating the\nverification process whenever the smaller LLM generates an erroneous token. (3)\nTo ensure a continuous flow of token generation, LLMCad speculatively generates\ntokens during the verification process by implementing a compute-IO pipeline.\nThrough an extensive series of experiments, LLMCad showcases an impressive\ntoken generation speed, achieving rates up to 9.3x faster than existing\ninference engines.\n",
                "链接": "https://arxiv.org/abs/2309.04255"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月自然语言处理相关的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "85699",
                "标题": "Operationalising Representation in Natural Language Processing",
                "作者": " Jacqueline Harding",
                "发布日期": "2023-11-21",
                "摘要": "  Despite its centrality in the philosophy of cognitive science, there has been\nlittle prior philosophical work engaging with the notion of representation in\ncontemporary NLP practice. This paper attempts to fill that lacuna: drawing on\nideas from cognitive science, I introduce a framework for evaluating the\nrepresentational claims made about components of neural NLP models, proposing\nthree criteria with which to evaluate whether a component of a model represents\na property and operationalising these criteria using probing classifiers, a\npopular analysis technique in NLP (and deep learning more broadly).\n  The project of operationalising a philosophically-informed notion of\nrepresentation should be of interest to both philosophers of science and NLP\npractitioners. It affords philosophers a novel testing-ground for claims about\nthe nature of representation, and helps NLPers organise the large literature on\nprobing experiments, suggesting novel avenues for empirical research.\n",
                "链接": "https://arxiv.org/abs/2306.08193"
            },
            {
                "文章ID": "115729",
                "标题": "Natural Language Processing for Financial Regulation",
                "作者": " Ixandra Achitouv,  Dragos Gorduza,  Antoine Jacquier",
                "发布日期": "2023-11-16",
                "摘要": "  This article provides an understanding of Natural Language Processing\ntechniques in the framework of financial regulation, more specifically in order\nto perform semantic matching search between rules and policy when no dataset is\navailable for supervised learning. We outline how to outperform simple\npre-trained sentences-transformer models using freely available resources and\nexplain the mathematical concepts behind the key building blocks of Natural\nLanguage Processing.\n",
                "链接": "https://arxiv.org/abs/2311.08533"
            },
            {
                "文章ID": "119807",
                "标题": "Enabling Quantum Natural Language Processing for Hindi Language",
                "作者": " Naman Srivastava,  Gaurang Belekar,  Sunil Saumya,  Aswath Babu H",
                "发布日期": "2023-12-05",
                "摘要": "  Quantum Natural Language Processing (QNLP) is taking huge leaps in solving\nthe shortcomings of classical Natural Language Processing (NLP) techniques and\nmoving towards a more \"Explainable\" NLP system. The current literature around\nQNLP focuses primarily on implementing QNLP techniques in sentences in the\nEnglish language. In this paper, we propose to enable the QNLP approach to\nHINDI, which is the third most spoken language in South Asia. We present the\nprocess of building the parameterized quantum circuits required to undertake\nQNLP on Hindi sentences. We use the pregroup representation of Hindi and the\nDisCoCat framework to draw sentence diagrams. Later, we translate these\ndiagrams to Parameterised Quantum Circuits based on Instantaneous Quantum\nPolynomial (IQP) style ansatz. Using these parameterized quantum circuits\nallows one to train grammar and topic-aware sentence classifiers for the Hindi\nLanguage.\n",
                "链接": "https://arxiv.org/abs/2312.01221"
            },
            {
                "文章ID": "112711",
                "标题": "Partial Tensorized Transformers for Natural Language Processing",
                "作者": " Subhadra Vadlamannati,  Ryan Solgi",
                "发布日期": "2023-11-01",
                "摘要": "  The transformer architecture has revolutionized Natural Language Processing\n(NLP) and other machine-learning tasks, due to its unprecedented accuracy.\nHowever, their extensive memory and parameter requirements often hinder their\npractical applications. In this work, we study the effect of tensor-train\ndecomposition to improve the accuracy and compress transformer vision-language\nneural networks, namely BERT and ViT. We focus both on embedding-layer\ncompression and partial tensorization of neural networks (PTNN) through an\nalgorithmic approach. Our novel PTNN approach significantly improves the\naccuracy of existing models by up to 5%, all without the need for post-training\nadjustments, breaking new ground in the field of tensor decomposition.\n",
                "链接": "https://arxiv.org/abs/2310.20077"
            },
            {
                "文章ID": "113818",
                "标题": "mahaNLP: A Marathi Natural Language Processing Library",
                "作者": " Vidula Magdum,  Omkar Dhekane,  Sharayu Hiwarkhedkar,  Saloni Mittal,  Raviraj Joshi",
                "发布日期": "2023-11-07",
                "摘要": "  We present mahaNLP, an open-source natural language processing (NLP) library\nspecifically built for the Marathi language. It aims to enhance the support for\nthe low-resource Indian language Marathi in the field of NLP. It is an\neasy-to-use, extensible, and modular toolkit for Marathi text analysis built on\nstate-of-the-art MahaBERT-based transformer models. Our work holds significant\nimportance as other existing Indic NLP libraries provide basic Marathi\nprocessing support and rely on older models with restricted performance. Our\ntoolkit stands out by offering a comprehensive array of NLP tasks, encompassing\nboth fundamental preprocessing tasks and advanced NLP tasks like sentiment\nanalysis, NER, hate speech detection, and sentence completion. This paper\nfocuses on an overview of the mahaNLP framework, its features, and its usage.\nThis work is a part of the L3Cube MahaNLP initiative, more information about it\ncan be found at https://github.com/l3cube-pune/MarathiNLP .\n",
                "链接": "https://arxiv.org/abs/2311.02579"
            },
            {
                "文章ID": "115279",
                "标题": "calamanCy: A Tagalog Natural Language Processing Toolkit",
                "作者": " Lester James V. Miranda",
                "发布日期": "2023-11-14",
                "摘要": "  We introduce calamanCy, an open-source toolkit for constructing natural\nlanguage processing (NLP) pipelines for Tagalog. It is built on top of spaCy,\nenabling easy experimentation and integration with other frameworks. calamanCy\naddresses the development gap by providing a consistent API for building NLP\napplications and offering general-purpose multitask models with out-of-the-box\nsupport for dependency parsing, parts-of-speech (POS) tagging, and named entity\nrecognition (NER). calamanCy aims to accelerate the progress of Tagalog NLP by\nconsolidating disjointed resources in a unified framework. The calamanCy\ntoolkit is available on GitHub: https://github.com/ljvmiranda921/calamanCy.\n",
                "链接": "https://arxiv.org/abs/2311.07171"
            },
            {
                "文章ID": "121029",
                "标题": "PyThaiNLP: Thai Natural Language Processing in Python",
                "作者": " Wannaphong Phatthiyaphaibun,  Korakot Chaovavanich,  Charin Polpanumas,  Arthit Suriyawongkul,  Lalita Lowphansirikul,  Pattarawat Chormai,  Peerat Limkonchotiwat,  Thanathip Suntorntip,  Can Udomcharoenchaikit",
                "发布日期": "2023-12-11",
                "摘要": "  We present PyThaiNLP, a free and open-source natural language processing\n(NLP) library for Thai language implemented in Python. It provides a wide range\nof software, models, and datasets for Thai language. We first provide a brief\nhistorical context of tools for Thai language prior to the development of\nPyThaiNLP. We then outline the functionalities it provided as well as datasets\nand pre-trained language models. We later summarize its development milestones\nand discuss our experience during its development. We conclude by demonstrating\nhow industrial and research communities utilize PyThaiNLP in their work. The\nlibrary is freely available at https://github.com/pythainlp/pythainlp.\n",
                "链接": "https://arxiv.org/abs/2312.04649"
            },
            {
                "文章ID": "116570",
                "标题": "Formal concept analysis for evaluating intrinsic dimension of a natural\n  language",
                "作者": " Sergei O. Kuznetsov,  Vasilii A. Gromov,  Nikita S. Borodin,  Andrei M. Divavin",
                "发布日期": "2023-11-21",
                "摘要": "  Some results of a computational experiment for determining the intrinsic\ndimension of linguistic varieties for the Bengali and Russian languages are\npresented. At the same time, both sets of words and sets of bigrams in these\nlanguages were considered separately. The method used to solve this problem was\nbased on formal concept analysis algorithms. It was found that the intrinsic\ndimensions of these languages are significantly less than the dimensions used\nin popular neural network models in natural language processing.\n",
                "链接": "https://arxiv.org/abs/2311.10862"
            },
            {
                "文章ID": "53367",
                "标题": "Auto-labelling of Bug Report using Natural Language Processing",
                "作者": " Avinash Patil,  Aryan Jadon",
                "发布日期": "2023-11-15",
                "摘要": "  The exercise of detecting similar bug reports in bug tracking systems is\nknown as duplicate bug report detection. Having prior knowledge of a bug\nreport's existence reduces efforts put into debugging problems and identifying\nthe root cause. Rule and Query-based solutions recommend a long list of\npotential similar bug reports with no clear ranking. In addition, triage\nengineers are less motivated to spend time going through an extensive list.\nConsequently, this deters the use of duplicate bug report retrieval solutions.\nIn this paper, we have proposed a solution using a combination of NLP\ntechniques. Our approach considers unstructured and structured attributes of a\nbug report like summary, description and severity, impacted products,\nplatforms, categories, etc. It uses a custom data transformer, a deep neural\nnetwork, and a non-generalizing machine learning method to retrieve existing\nidentical bug reports. We have performed numerous experiments with significant\ndata sources containing thousands of bug reports and showcased that the\nproposed solution achieves a high retrieval accuracy of 70% for recall@5.\n",
                "链接": "https://arxiv.org/abs/2212.06334"
            },
            {
                "文章ID": "112674",
                "标题": "BioInstruct: Instruction Tuning of Large Language Models for Biomedical\n  Natural Language Processing",
                "作者": " Hieu Tran,  Zhichao Yang,  Zonghai Yao,  Hong Yu",
                "发布日期": "2023-11-07",
                "摘要": "  To enhance the performance of large language models (LLMs) in biomedical\nnatural language processing (BioNLP) by introducing a domain-specific\ninstruction dataset and examining its impact when combined with multi-task\nlearning principles. We created the BioInstruct, comprising 25,005 instructions\nto instruction-tune LLMs(LLaMA 1 & 2, 7B & 13B version). The instructions were\ncreated by prompting the GPT-4 language model with three-seed samples randomly\ndrawn from an 80 human curated instructions. We employed Low-Rank\nAdaptation(LoRA) for parameter-efficient fine-tuning. We then evaluated these\ninstruction-tuned LLMs on several BioNLP tasks, which can be grouped into three\nmajor categories: question answering(QA), information extraction(IE), and text\ngeneration(GEN). We also examined whether categories(e.g., QA, IE, and\ngeneration) of instructions impact model performance. Comparing with LLMs\nwithout instruction-tuned, our instruction-tuned LLMs demonstrated marked\nperformance gains: 17.3% in QA, 5.7% in IE, and 96% in Generation tasks. Our\n7B-parameter instruction-tuned LLaMA 1 model was competitive or even surpassed\nother LLMs in the biomedical domain that were also fine-tuned from LLaMA 1 with\nvast domain-specific data or a variety of tasks. Our results also show that the\nperformance gain is significantly higher when instruction fine-tuning is\nconducted with closely related tasks. Our findings align with the observations\nof multi-task learning, suggesting the synergies between two tasks. The\nBioInstruct dataset serves as a valuable resource and instruction tuned LLMs\nlead to the best performing BioNLP applications.\n",
                "链接": "https://arxiv.org/abs/2310.19975"
            }
        ]
    },
    {
        "question": {
            "question": "查找多语言情感分析的最新论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "82977",
                "标题": "UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of\n  Multilingual BERT for Low-resource Sentiment Analysis",
                "作者": " Dou Hu,  Lingwei Wei,  Yaxin Liu,  Wei Zhou,  Songlin Hu",
                "发布日期": "2023-06-05",
                "摘要": "  This paper describes our system designed for SemEval-2023 Task 12: Sentiment\nanalysis for African languages. The challenge faced by this task is the\nscarcity of labeled data and linguistic resources in low-resource settings. To\nalleviate these, we propose a generalized multilingual system SACL-XLMR for\nsentiment analysis on low-resource languages. Specifically, we design a\nlexicon-based multilingual BERT to facilitate language adaptation and\nsentiment-aware representation learning. Besides, we apply a supervised\nadversarial contrastive learning technique to learn sentiment-spread structured\nrepresentations and enhance model generalization. Our system achieved\ncompetitive results, largely outperforming baselines on both multilingual and\nzero-shot sentiment classification subtasks. Notably, the system obtained the\n1st rank on the zero-shot classification subtask in the official ranking.\nExtensive experiments demonstrate the effectiveness of our system.\n",
                "链接": "https://arxiv.org/abs/2306.01093"
            },
            {
                "文章ID": "85580",
                "标题": "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted\n  Sentiment Classification Benchmark",
                "作者": " Łukasz Augustyniak,  Szymon Woźniak,  Marcin Gruza,  Piotr Gramacki,  Krzysztof Rajda,  Mikołaj Morzy,  Tomasz Kajdanowicz",
                "发布日期": "2023-06-14",
                "摘要": "  Despite impressive advancements in multilingual corpora collection and model\ntraining, developing large-scale deployments of multilingual models still\npresents a significant challenge. This is particularly true for language tasks\nthat are culture-dependent. One such example is the area of multilingual\nsentiment analysis, where affective markers can be subtle and deeply ensconced\nin culture. This work presents the most extensive open massively multilingual\ncorpus of datasets for training sentiment models. The corpus consists of 79\nmanually selected datasets from over 350 datasets reported in the scientific\nliterature based on strict quality criteria. The corpus covers 27 languages\nrepresenting 6 language families. Datasets can be queried using several\nlinguistic and functional features. In addition, we present a multi-faceted\nsentiment classification benchmark summarizing hundreds of experiments\nconducted on different base models, training objectives, dataset collections,\nand fine-tuning strategies.\n",
                "链接": "https://arxiv.org/abs/2306.07902"
            },
            {
                "文章ID": "121053",
                "标题": "Deep Emotions Across Languages: A Novel Approach for Sentiment\n  Propagation in Multilingual WordNets",
                "作者": " Jan Kocoń",
                "发布日期": "2023-12-11",
                "摘要": "  Sentiment analysis involves using WordNets enriched with emotional metadata,\nwhich are valuable resources. However, manual annotation is time-consuming and\nexpensive, resulting in only a few WordNet Lexical Units being annotated. This\npaper introduces two new techniques for automatically propagating sentiment\nannotations from a partially annotated WordNet to its entirety and to a WordNet\nin a different language: Multilingual Structured Synset Embeddings (MSSE) and\nCross-Lingual Deep Neural Sentiment Propagation (CLDNS). We evaluated the\nproposed MSSE+CLDNS method extensively using Princeton WordNet and Polish\nWordNet, which have many inter-lingual relations. Our results show that the\nMSSE+CLDNS method outperforms existing propagation methods, indicating its\neffectiveness in enriching WordNets with emotional metadata across multiple\nlanguages. This work provides a solid foundation for large-scale, multilingual\nsentiment analysis and is valuable for academic research and practical\napplications.\n",
                "链接": "https://arxiv.org/abs/2312.04715"
            },
            {
                "文章ID": "110460",
                "标题": "Sentiment Analysis Across Multiple African Languages: A Current\n  Benchmark",
                "作者": " Saurav K. Aryal,  Howard Prioleau,  Surakshya Aryal",
                "发布日期": "2023-10-24",
                "摘要": "  Sentiment analysis is a fundamental and valuable task in NLP. However, due to\nlimitations in data and technological availability, research into sentiment\nanalysis of African languages has been fragmented and lacking. With the recent\nrelease of the AfriSenti-SemEval Shared Task 12, hosted as a part of The 17th\nInternational Workshop on Semantic Evaluation, an annotated sentiment analysis\nof 14 African languages was made available. We benchmarked and compared current\nstate-of-art transformer models across 12 languages and compared the\nperformance of training one-model-per-language versus\nsingle-model-all-languages. We also evaluated the performance of standard\nmultilingual models and their ability to learn and transfer cross-lingual\nrepresentation from non-African to African languages. Our results show that\ndespite work in low resource modeling, more data still produces better models\non a per-language basis. Models explicitly developed for African languages\noutperform other models on all tasks. Additionally, no one-model-fits-all\nsolution exists for a per-language evaluation of the models evaluated.\nMoreover, for some languages with a smaller sample size, a larger multilingual\nmodel may perform better than a dedicated per-language model for sentiment\nclassification.\n",
                "链接": "https://arxiv.org/abs/2310.14120"
            },
            {
                "文章ID": "102692",
                "标题": "The ParlaSent multilingual training dataset for sentiment identification\n  in parliamentary proceedings",
                "作者": " Michal Mochtak,  Peter Rupnik,  Nikola Ljubešić",
                "发布日期": "2023-09-19",
                "摘要": "  Sentiments inherently drive politics. How we receive and process information\nplays an essential role in political decision-making, shaping our judgment with\nstrategic consequences both on the level of legislators and the masses. If\nsentiment plays such an important role in politics, how can we study and\nmeasure it systematically? The paper presents a new dataset of\nsentiment-annotated sentences, which are used in a series of experiments\nfocused on training a robust sentiment classifier for parliamentary\nproceedings. The paper also introduces the first domain-specific LLM for\npolitical science applications additionally pre-trained on 1.72 billion\ndomain-specific words from proceedings of 27 European parliaments. We present\nexperiments demonstrating how the additional pre-training of LLM on\nparliamentary data can significantly improve the model downstream performance\non the domain-specific tasks, in our case, sentiment detection in parliamentary\nproceedings. We further show that multilingual models perform very well on\nunseen languages and that additional data from other languages significantly\nimproves the target parliament's results. The paper makes an important\ncontribution to multiple domains of social sciences and bridges them with\ncomputer science and computational linguistics. Lastly, it sets up a more\nrobust approach to sentiment analysis of political texts in general, which\nallows scholars to study political sentiment from a comparative perspective\nusing standardized tools and techniques.\n",
                "链接": "https://arxiv.org/abs/2309.09783"
            },
            {
                "文章ID": "87606",
                "标题": "L3Cube-MahaSent-MD: A Multi-domain Marathi Sentiment Analysis Dataset\n  and Transformer Models",
                "作者": " Aabha Pingle,  Aditya Vyawahare,  Isha Joshi,  Rahul Tangsali,  Raviraj Joshi",
                "发布日期": "2023-06-27",
                "摘要": "  The exploration of sentiment analysis in low-resource languages, such as\nMarathi, has been limited due to the availability of suitable datasets. In this\nwork, we present L3Cube-MahaSent-MD, a multi-domain Marathi sentiment analysis\ndataset, with four different domains - movie reviews, general tweets, TV show\nsubtitles, and political tweets. The dataset consists of around 60,000 manually\ntagged samples covering 3 distinct sentiments - positive, negative, and\nneutral. We create a sub-dataset for each domain comprising 15k samples. The\nMahaSent-MD is the first comprehensive multi-domain sentiment analysis dataset\nwithin the Indic sentiment landscape. We fine-tune different monolingual and\nmultilingual BERT models on these datasets and report the best accuracy with\nthe MahaBERT model. We also present an extensive in-domain and cross-domain\nanalysis thus highlighting the need for low-resource multi-domain datasets. The\ndata and models are available at https://github.com/l3cube-pune/MarathiNLP .\n",
                "链接": "https://arxiv.org/abs/2306.13888"
            },
            {
                "文章ID": "123354",
                "标题": "Aspect-Based Sentiment Analysis with Explicit Sentiment Augmentations",
                "作者": " Jihong Ouyang,  Zhiyao Yang,  Silong Liang,  Bing Wang,  Yimeng Wang,  Ximing Li",
                "发布日期": "2023-12-19",
                "摘要": "  Aspect-based sentiment analysis (ABSA), a fine-grained sentiment\nclassification task, has received much attention recently. Many works\ninvestigate sentiment information through opinion words, such as ''good'' and\n''bad''. However, implicit sentiment widely exists in the ABSA dataset, which\nrefers to the sentence containing no distinct opinion words but still expresses\nsentiment to the aspect term. To deal with implicit sentiment, this paper\nproposes an ABSA method that integrates explicit sentiment augmentations. And\nwe propose an ABSA-specific augmentation method to create such augmentations.\nSpecifically, we post-trains T5 by rule-based data. We employ Syntax Distance\nWeighting and Unlikelihood Contrastive Regularization in the training procedure\nto guide the model to generate an explicit sentiment. Meanwhile, we utilize the\nConstrained Beam Search to ensure the augmentation sentence contains the aspect\nterms. We test ABSA-ESA on two of the most popular benchmarks of ABSA. The\nresults show that ABSA-ESA outperforms the SOTA baselines on implicit and\nexplicit sentiment accuracy.\n",
                "链接": "https://arxiv.org/abs/2312.10961"
            },
            {
                "文章ID": "100113",
                "标题": "UniSA: Unified Generative Framework for Sentiment Analysis",
                "作者": " Zaijing Li,  Ting-En Lin,  Yuchuan Wu,  Meng Liu,  Fengxiao Tang,  Ming Zhao,  Yongbin Li",
                "发布日期": "2023-09-06",
                "摘要": "  Sentiment analysis is a crucial task that aims to understand people's\nemotional states and predict emotional categories based on multimodal\ninformation. It consists of several subtasks, such as emotion recognition in\nconversation (ERC), aspect-based sentiment analysis (ABSA), and multimodal\nsentiment analysis (MSA). However, unifying all subtasks in sentiment analysis\npresents numerous challenges, including modality alignment, unified\ninput/output forms, and dataset bias. To address these challenges, we propose a\nTask-Specific Prompt method to jointly model subtasks and introduce a\nmultimodal generative framework called UniSA. Additionally, we organize the\nbenchmark datasets of main subtasks into a new Sentiment Analysis Evaluation\nbenchmark, SAEval. We design novel pre-training tasks and training methods to\nenable the model to learn generic sentiment knowledge among subtasks to improve\nthe model's multimodal sentiment perception ability. Our experimental results\nshow that UniSA performs comparably to the state-of-the-art on all subtasks and\ngeneralizes well to various subtasks in sentiment analysis.\n",
                "链接": "https://arxiv.org/abs/2309.01339"
            },
            {
                "文章ID": "79191",
                "标题": "Cross-lingual Transfer Can Worsen Bias in Sentiment Analysis",
                "作者": " Seraphina Goldfarb-Tarrant,  Björn Ross,  Adam Lopez",
                "发布日期": "2023-05-23",
                "摘要": "  Sentiment analysis (SA) systems are widely deployed in many of the world's\nlanguages, and there is well-documented evidence of demographic bias in these\nsystems. In languages beyond English, scarcer training data is often\nsupplemented with transfer learning using pre-trained models, including\nmultilingual models trained on other languages. In some cases, even supervision\ndata comes from other languages. Does cross-lingual transfer also import new\nbiases? To answer this question, we use counterfactual evaluation to test\nwhether gender or racial biases are imported when using cross-lingual transfer,\ncompared to a monolingual transfer setting. Across five languages, we find that\nsystems using cross-lingual transfer usually become more biased than their\nmonolingual counterparts. We also find racial biases to be much more prevalent\nthan gender biases. To spur further research on this topic, we release the\nsentiment models we used for this study, and the intermediate checkpoints\nthroughout training, yielding 1,525 distinct models; we also release our\nevaluation code.\n",
                "链接": "https://arxiv.org/abs/2305.12709"
            },
            {
                "文章ID": "110508",
                "标题": "RSM-NLP at BLP-2023 Task 2: Bangla Sentiment Analysis using Weighted and\n  Majority Voted Fine-Tuned Transformers",
                "作者": " Pratinav Seth,  Rashi Goel,  Komal Mathur,  Swetha Vemulapalli",
                "发布日期": "2023-10-24",
                "摘要": "  This paper describes our approach to submissions made at Shared Task 2 at BLP\nWorkshop - Sentiment Analysis of Bangla Social Media Posts. Sentiment Analysis\nis an action research area in the digital age. With the rapid and constant\ngrowth of online social media sites and services and the increasing amount of\ntextual data, the application of automatic Sentiment Analysis is on the rise.\nHowever, most of the research in this domain is based on the English language.\nDespite being the world's sixth most widely spoken language, little work has\nbeen done in Bangla. This task aims to promote work on Bangla Sentiment\nAnalysis while identifying the polarity of social media content by determining\nwhether the sentiment expressed in the text is Positive, Negative, or Neutral.\nOur approach consists of experimenting and finetuning various multilingual and\npre-trained BERT-based models on our downstream tasks and using a Majority\nVoting and Weighted ensemble model that outperforms individual baseline model\nscores. Our system scored 0.711 for the multiclass classification task and\nscored 10th place among the participants on the leaderboard for the shared\ntask. Our code is available at https://github.com/ptnv-s/RSM-NLP-BLP-Task2 .\n",
                "链接": "https://arxiv.org/abs/2310.14261"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于NLP领域的持续性学习论文",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "找一下最近关于大模型评测的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "15455",
                "标题": "Research on Domain Information Mining and Theme Evolution of Scientific\n  Papers",
                "作者": " Changwei Zheng,  Zhe Xue,  Meiyu Liang,  Feifei Kou,  Zeli Guan",
                "发布日期": "2022-04-20",
                "摘要": "  In recent years, with the increase of social investment in scientific\nresearch, the number of research results in various fields has increased\nsignificantly. Cross-disciplinary research results have gradually become an\nemerging frontier research direction. There is a certain dependence between a\nlarge number of research results. It is difficult to effectively analyze\ntoday's scientific research results when looking at a single research field in\nisolation. How to effectively use the huge number of scientific papers to help\nresearchers becomes a challenge. This paper introduces the research status at\nhome and abroad in terms of domain information mining and topic evolution law\nof scientific and technological papers from three aspects: the semantic feature\nrepresentation learning of scientific and technological papers, the field\ninformation mining of scientific and technological papers, and the mining and\nprediction of research topic evolution rules of scientific and technological\npapers.\n",
                "链接": "https://arxiv.org/abs/2204.08476"
            },
            {
                "文章ID": "121595",
                "标题": "Recent Advances in Deterministic Human Motion Prediction: A Review",
                "作者": " Tenghao Deng,  Yan Sun",
                "发布日期": "2023-12-12",
                "摘要": "  In recent years, with the continuous advancement of deep learning and the\nemergence of large-scale human motion datasets, human motion prediction\ntechnology has gradually gained prominence in various fields such as\nhuman-computer interaction, autonomous driving, sports analysis, and personnel\ntracking. This article introduces common model architectures in this domain\nalong with their respective advantages and disadvantages. It also\nsystematically summarizes recent research innovations, focusing on in-depth\ndiscussions of relevant papers in these areas, thereby highlighting\nforward-looking insights into the field's development. Furthermore, this paper\nprovides a comprehensive overview of existing methods, commonly used datasets,\nand evaluation metrics in this field. Finally, it discusses some of the current\nlimitations in the field and proposes potential future research directions to\naddress these challenges and promote further advancements in human motion\nprediction.\n",
                "链接": "https://arxiv.org/abs/2312.06184"
            },
            {
                "文章ID": "96569",
                "标题": "Through the Lens of Core Competency: Survey on Evaluation of Large\n  Language Models",
                "作者": " Ziyu Zhuang,  Qiguang Chen,  Longxuan Ma,  Mingda Li,  Yi Han,  Yushan Qian,  Haopeng Bai,  Zixian Feng,  Weinan Zhang,  Ting Liu",
                "发布日期": "2023-08-16",
                "摘要": "  From pre-trained language model (PLM) to large language model (LLM), the\nfield of natural language processing (NLP) has witnessed steep performance\ngains and wide practical uses. The evaluation of a research field guides its\ndirection of improvement. However, LLMs are extremely hard to thoroughly\nevaluate for two reasons. First of all, traditional NLP tasks become inadequate\ndue to the excellent performance of LLM. Secondly, existing evaluation tasks\nare difficult to keep up with the wide range of applications in real-world\nscenarios. To tackle these problems, existing works proposed various benchmarks\nto better evaluate LLMs. To clarify the numerous evaluation tasks in both\nacademia and industry, we investigate multiple papers concerning LLM\nevaluations. We summarize 4 core competencies of LLM, including reasoning,\nknowledge, reliability, and safety. For every competency, we introduce its\ndefinition, corresponding benchmarks, and metrics. Under this competency\narchitecture, similar tasks are combined to reflect corresponding ability,\nwhile new tasks can also be easily added into the system. Finally, we give our\nsuggestions on the future direction of LLM's evaluation.\n",
                "链接": "https://arxiv.org/abs/2308.07902"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "5419",
                "标题": "ArgSciChat: A Dataset for Argumentative Dialogues on Scientific Papers",
                "作者": " Federico Ruggeri,  Mohsen Mesgar,  Iryna Gurevych",
                "发布日期": "2022-10-14",
                "摘要": "  The applications of conversational agents for scientific disciplines (as\nexpert domains) are understudied due to the lack of dialogue data to train such\nagents. While most data collection frameworks, such as Amazon Mechanical Turk,\nfoster data collection for generic domains by connecting crowd workers and task\ndesigners, these frameworks are not much optimized for data collection in\nexpert domains. Scientists are rarely present in these frameworks due to their\nlimited time budget. Therefore, we introduce a novel framework to collect\ndialogues between scientists as domain experts on scientific papers. Our\nframework lets scientists present their scientific papers as groundings for\ndialogues and participate in dialogue they like its paper title. We use our\nframework to collect a novel argumentative dialogue dataset, ArgSciChat. It\nconsists of 498 messages collected from 41 dialogues on 20 scientific papers.\nAlongside extensive analysis on ArgSciChat, we evaluate a recent conversational\nagent on our dataset. Experimental results show that this agent poorly performs\non ArgSciChat, motivating further research on argumentative scientific agents.\nWe release our framework and the dataset.\n",
                "链接": "https://arxiv.org/abs/2202.06690"
            },
            {
                "文章ID": "114514",
                "标题": "Training CLIP models on Data from Scientific Papers",
                "作者": " Calvin Metzger",
                "发布日期": "2023-11-09",
                "摘要": "  Contrastive Language-Image Pretraining (CLIP) models are able to capture the\nsemantic relationship of images and texts and have enabled a wide range of\napplications, from image retrieval to classification. These models are trained\nwith datasets extracted from web crawls, which are of large quantity but\nlimited quality. This paper explores whether limited amounts higher quality\ndata in a specific domain improve the general performance of CLIP models. To\nthis purpose, we extract text-image data from scientific papers hosted in the\narXiv and PubMed Central repositories. Experiments on small-scale CLIP models\n(ViT B/32) show that model performance increases on average, but only\nmoderately. This result indicates that using the data sources considered in the\npaper to train large-scale CLIP models is a worthwile research direction.\n",
                "链接": "https://arxiv.org/abs/2311.04711"
            },
            {
                "文章ID": "85250",
                "标题": "The Devil is in the Details: On the Pitfalls of Event Extraction\n  Evaluation",
                "作者": " Hao Peng,  Xiaozhi Wang,  Feng Yao,  Kaisheng Zeng,  Lei Hou,  Juanzi Li,  Zhiyuan Liu,  Weixing Shen",
                "发布日期": "2023-06-16",
                "摘要": "  Event extraction (EE) is a crucial task aiming at extracting events from\ntexts, which includes two subtasks: event detection (ED) and event argument\nextraction (EAE). In this paper, we check the reliability of EE evaluations and\nidentify three major pitfalls: (1) The data preprocessing discrepancy makes the\nevaluation results on the same dataset not directly comparable, but the data\npreprocessing details are not widely noted and specified in papers. (2) The\noutput space discrepancy of different model paradigms makes different-paradigm\nEE models lack grounds for comparison and also leads to unclear mapping issues\nbetween predictions and annotations. (3) The absence of pipeline evaluation of\nmany EAE-only works makes them hard to be directly compared with EE works and\nmay not well reflect the model performance in real-world pipeline scenarios. We\ndemonstrate the significant influence of these pitfalls through comprehensive\nmeta-analyses of recent papers and empirical experiments. To avoid these\npitfalls, we suggest a series of remedies, including specifying data\npreprocessing, standardizing outputs, and providing pipeline evaluation\nresults. To help implement these remedies, we develop a consistent evaluation\nframework OMNIEVENT, which can be obtained from\nhttps://github.com/THU-KEG/OmniEvent.\n",
                "链接": "https://arxiv.org/abs/2306.06918"
            }
        ]
    },
    {
        "question": {
            "question": "查找近六个月工具学习评测数据集的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "122009",
                "标题": "CholecTrack20: A Dataset for Multi-Class Multiple Tool Tracking in\n  Laparoscopic Surgery",
                "作者": " Chinedu Innocent Nwoye,  Kareem Elgohary,  Anvita Srinivas,  Fauzan Zaid,  Joël L. Lavanchy,  Nicolas Padoy",
                "发布日期": "2023-12-13",
                "摘要": "  Tool tracking in surgical videos is vital in computer-assisted intervention\nfor tasks like surgeon skill assessment, safety zone estimation, and\nhuman-machine collaboration during minimally invasive procedures. The lack of\nlarge-scale datasets hampers Artificial Intelligence implementation in this\ndomain. Current datasets exhibit overly generic tracking formalization, often\nlacking surgical context: a deficiency that becomes evident when tools move out\nof the camera's scope, resulting in rigid trajectories that hinder realistic\nsurgical representation. This paper addresses the need for a more precise and\nadaptable tracking formalization tailored to the intricacies of endoscopic\nprocedures by introducing CholecTrack20, an extensive dataset meticulously\nannotated for multi-class multi-tool tracking across three perspectives\nrepresenting the various ways of considering the temporal duration of a tool\ntrajectory: (1) intraoperative, (2) intracorporeal, and (3) visibility within\nthe camera's scope. The dataset comprises 20 laparoscopic videos with over\n35,000 frames and 65,000 annotated tool instances with details on spatial\nlocation, category, identity, operator, phase, and surgical visual conditions.\nThis detailed dataset caters to the evolving assistive requirements within a\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2312.07352"
            },
            {
                "文章ID": "108993",
                "标题": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
                "作者": " Alon Jacovi,  Avi Caciularu,  Jonathan Herzig,  Roee Aharoni,  Bernd Bohnet,  Mor Geva",
                "发布日期": "2023-12-29",
                "摘要": "  A growing area of research investigates augmenting language models with tools\n(e.g., search engines, calculators) to overcome their shortcomings (e.g.,\nmissing or incorrect knowledge, incorrect logical inferences). Various few-shot\ntool-usage strategies have been proposed. However, there is no systematic and\nfair comparison across different strategies, or between these strategies and\nstrong baselines that do not leverage tools. We conduct an extensive empirical\nanalysis, finding that (1) across various datasets, example difficulty levels,\nand models, strong no-tool baselines are competitive to tool-assisted\nstrategies, implying that effectively using tools with in-context\ndemonstrations is a difficult unsolved problem; (2) for knowledge-retrieval\ntasks, strategies that *refine* incorrect outputs with tools outperform\nstrategies that retrieve relevant information *ahead of* or *during\ngeneration*; (3) tool-assisted strategies are expensive in the number of tokens\nthey require to work -- incurring additional costs by orders of magnitude --\nwhich does not translate into significant improvement in performance. Overall,\nour findings suggest that few-shot tool integration is still an open challenge,\nemphasizing the need for comprehensive evaluations of future strategies to\naccurately assess their *benefits* and *costs*.\n",
                "链接": "https://arxiv.org/abs/2310.10062"
            },
            {
                "文章ID": "98794",
                "标题": "Confucius: Iterative Tool Learning from Introspection Feedback by\n  Easy-to-Difficult Curriculum",
                "作者": " Shen Gao,  Zhengliang Shi,  Minghang Zhu,  Bowen Fang,  Xin Xin,  Pengjie Ren,  Zhumin Chen,  Jun Ma,  Zhaochun Ren",
                "发布日期": "2023-12-22",
                "摘要": "  Augmenting large language models (LLMs) with external tools has emerged as a\npromising approach to extending the capability of LLMs. Although some works\nemploy open-source LLMs for the tool learning task, most of them are trained in\na controlled environment in which LLMs only learn to execute the human-provided\ntools. However, selecting proper tools from the large toolset is also a crucial\nability for the tool learning model to be applied in real-world applications.\nExisting methods usually directly employ self-instruction methods to train the\nmodel, which ignores differences in tool complexity. In this paper, we propose\nthe Confucius, a novel tool learning framework to train LLM to use complicated\ntools in real-world scenarios, which contains two main phases: (1) We first\npropose a multi-stage learning method to teach the LLM to use various tools\nfrom an easy-to-difficult curriculum; (2) thenceforth, we propose the Iterative\nSelf-instruct from Introspective Feedback (ISIF) to dynamically construct the\ndataset to improve the ability to use the complicated tool. Extensive\nexperiments conducted on both controlled and real-world settings demonstrate\nthe superiority of our tool learning framework in the real-world application\nscenarios compared to both tuning-free (e.g. ChatGPT, Claude) and tuning-based\nbaselines (e.g. GPT4Tools).\n",
                "链接": "https://arxiv.org/abs/2308.14034"
            },
            {
                "文章ID": "123110",
                "标题": "ProTIP: Progressive Tool Retrieval Improves Planning",
                "作者": " Raviteja Anantha,  Bortik Bandyopadhyay,  Anirudh Kashi,  Sayantan Mahinder,  Andrew W Hill,  Srinivas Chappidi",
                "发布日期": "2023-12-19",
                "摘要": "  Large language models (LLMs) are increasingly employed for complex multi-step\nplanning tasks, where the tool retrieval (TR) step is crucial for achieving\nsuccessful outcomes. Two prevalent approaches for TR are single-step retrieval,\nwhich utilizes the complete query, and sequential retrieval using task\ndecomposition (TD), where a full query is segmented into discrete atomic\nsubtasks. While single-step retrieval lacks the flexibility to handle\n\"inter-tool dependency,\" the TD approach necessitates maintaining \"subtask-tool\natomicity alignment,\" as the toolbox can evolve dynamically. To address these\nlimitations, we introduce the Progressive Tool retrieval to Improve Planning\n(ProTIP) framework. ProTIP is a lightweight, contrastive learning-based\nframework that implicitly performs TD without the explicit requirement of\nsubtask labels, while simultaneously maintaining subtask-tool atomicity. On the\nToolBench dataset, ProTIP outperforms the ChatGPT task decomposition-based\napproach by a remarkable margin, achieving a 24% improvement in Recall@K=10 for\nTR and a 41% enhancement in tool accuracy for plan generation.\n",
                "链接": "https://arxiv.org/abs/2312.10332"
            },
            {
                "文章ID": "118185",
                "标题": "SVRDA: A Web-based Dataset Annotation Tool for Slice-to-Volume\n  Registration",
                "作者": " Weixun Luo,  Alexandre Triay Bagur,  Paul Aljabar,  George Ralli,  Sir Michael Brady",
                "发布日期": "2023-11-28",
                "摘要": "  Background and Objective: The lack of benchmark datasets has impeded the\ndevelopment of slice-to-volume registration algorithms. Such datasets are\ndifficult to annotate, primarily due to the dimensional difference within data\nand the dearth of task-specific software. We aim to develop a user-friendly\ntool to streamline dataset annotation for slice-to-volume registration.\n  Methods: The proposed tool, named SVRDA, is an installation-free web\napplication for platform-agnostic collaborative dataset annotation. It enables\nefficient transformation manipulation via keyboard shortcuts and smooth case\ntransitions with auto-saving. SVRDA supports configuration-based data loading\nand adheres to the separation of concerns, offering great flexibility and\nextensibility for future research. Various supplementary features have been\nimplemented to facilitate slice-to-volume registration.\n  Results: We validated the effectiveness of SVRDA by indirectly evaluating the\npost-registration segmentation quality on UK Biobank data, observing a dramatic\noverall improvement (24.02% in the Dice Similarity Coefficient and 48.93% in\nthe 95th percentile Hausdorff distance, respectively) supported by highly\nstatistically significant evidence ($p<0.001$).We further showcased the\nclinical usage of SVRDA by integrating it into test-retest T1 quantification on\nin-house magnetic resonance images, leading to more consistent results after\nregistration.\n  Conclusions: SVRDA can facilitate collaborative annotation of benchmark\ndatasets while being potentially applicable to other pipelines incorporating\nslice-to-volume registration. Full source code and documentation are available\nat https://github.com/Roldbach/SVRDA\n",
                "链接": "https://arxiv.org/abs/2311.15536"
            },
            {
                "文章ID": "119263",
                "标题": "Data-driven prediction of tool wear using Bayesian-regularized\n  artificial neural networks",
                "作者": " Tam T. Truong,  Jay Airao,  Panagiotis Karras,  Faramarz Hojati,  Bahman Azarhoushang,  Ramin Aghababaei",
                "发布日期": "2023-12-01",
                "摘要": "  The prediction of tool wear helps minimize costs and enhance product quality\nin manufacturing. While existing data-driven models using machine learning and\ndeep learning have contributed to the accurate prediction of tool wear, they\noften lack generality and require substantial training data for high accuracy.\nIn this paper, we propose a new data-driven model that uses Bayesian\nRegularized Artificial Neural Networks (BRANNs) to precisely predict milling\ntool wear. BRANNs combine the strengths and leverage the benefits of artificial\nneural networks (ANNs) and Bayesian regularization, whereby ANNs learn complex\npatterns and Bayesian regularization handles uncertainty and prevents\noverfitting, resulting in a more generalized model. We treat both process\nparameters and monitoring sensor signals as BRANN input parameters. We\nconducted an extensive experimental study featuring four different experimental\ndata sets, including the NASA Ames milling dataset, the 2010 PHM Data Challenge\ndataset, the NUAA Ideahouse tool wear dataset, and an in-house performed\nend-milling of the Ti6Al4V dataset. We inspect the impact of input features,\ntraining data size, hidden units, training algorithms, and transfer functions\non the performance of the proposed BRANN model and demonstrate that it\noutperforms existing state-of-the-art models in terms of accuracy and\nreliability.\n",
                "链接": "https://arxiv.org/abs/2311.18620"
            },
            {
                "文章ID": "124318",
                "标题": "T-Eval: Evaluating the Tool Utilization Capability Step by Step",
                "作者": " Zehui Chen,  Weihua Du,  Wenwei Zhang,  Kuikun Liu,  Jiangning Liu,  Miao Zheng,  Jingming Zhuo,  Songyang Zhang,  Dahua Lin,  Kai Chen,  Feng Zhao",
                "发布日期": "2023-12-22",
                "摘要": "  Large language models (LLM) have achieved remarkable performance on various\nNLP tasks and are augmented by tools for broader applications. Yet, how to\nevaluate and analyze the tool-utilization capability of LLMs is still\nunder-explored. In contrast to previous works that evaluate models\nholistically, we comprehensively decompose the tool utilization into multiple\nsub-processes, including instruction following, planning, reasoning, retrieval,\nunderstanding, and review. Based on that, we further introduce \\shortname~to\nevaluate the tool utilization capability step by step. \\shortname~disentangles\nthe tool utilization evaluation into several sub-domains along model\ncapabilities, facilitating the inner understanding of both holistic and\nisolated competency of LLMs. We conduct extensive experiments on \\shortname~and\nin-depth analysis of various LLMs. \\shortname~ not only exhibits consistency\nwith the outcome-oriented evaluation but also provides a more fine-grained\nanalysis of the capabilities of LLMs, providing a new perspective in LLM\nevaluation on tool-utilization ability. The benchmark will be available at\n\\href{https://github.com/open-compass/T-Eval}{https://github.com/open-compass/T-Eval}.\n",
                "链接": "https://arxiv.org/abs/2312.14033"
            },
            {
                "文章ID": "124873",
                "标题": "Design and Implementation of a Tool for Extracting Uzbek Syllables",
                "作者": " Ulugbek Salaev,  Elmurod Kuriyozov,  Gayrat Matlatipov",
                "发布日期": "2023-12-27",
                "摘要": "  The accurate syllabification of words plays a vital role in various Natural\nLanguage Processing applications. Syllabification is a versatile linguistic\ntool with applications in linguistic research, language technology, education,\nand various fields where understanding and processing language is essential. In\nthis paper, we present a comprehensive approach to syllabification for the\nUzbek language, including rule-based techniques and machine learning\nalgorithms. Our rule-based approach utilizes advanced methods for dividing\nwords into syllables, generating hyphenations for line breaks and count of\nsyllables. Additionally, we collected a dataset for evaluating and training\nusing machine learning algorithms comprising word-syllable mappings,\nhyphenations, and syllable counts to predict syllable counts as well as for the\nevaluation of the proposed model. Our results demonstrate the effectiveness and\nefficiency of both approaches in achieving accurate syllabification. The\nresults of our experiments show that both approaches achieved a high level of\naccuracy, exceeding 99%. This study provides valuable insights and\nrecommendations for future research on syllabification and related areas in not\nonly the Uzbek language itself, but also in other closely-related Turkic\nlanguages with low-resource factor.\n",
                "链接": "https://arxiv.org/abs/2312.15779"
            },
            {
                "文章ID": "117713",
                "标题": "Brain MRI Screening Tool with Federated Learning",
                "作者": " Roman Stoklasa,  Ioannis Stathopoulos,  Efstratios Karavasilis,  Efstathios Efstathopoulos,  Marek Dostál,  Miloš Keřkovský,  Michal Kozubek,  Luigi Serio",
                "发布日期": "2023-11-27",
                "摘要": "  In clinical practice, we often see significant delays between MRI scans and\nthe diagnosis made by radiologists, even for severe cases. In some cases, this\nmay be caused by the lack of additional information and clues, so even the\nsevere cases need to wait in the queue for diagnosis. This can be avoided if\nthere is an automatic software tool, which would supplement additional\ninformation, alerting radiologists that the particular patient may be a severe\ncase.\n  We are presenting an automatic brain MRI Screening Tool and we are\ndemonstrating its capabilities for detecting tumor-like pathologies. It is the\nfirst version on the path toward a robust multi-pathology screening solution.\nThe tool supports Federated Learning, so multiple institutions may contribute\nto the model without disclosing their private data.\n",
                "链接": "https://arxiv.org/abs/2311.14086"
            },
            {
                "文章ID": "116523",
                "标题": "ToolTalk: Evaluating Tool-Usage in a Conversational Setting",
                "作者": " Nicholas Farn,  Richard Shin",
                "发布日期": "2023-11-21",
                "摘要": "  Large language models (LLMs) have displayed massive improvements in reasoning\nand decision-making skills and can hold natural conversations with users. Many\nrecent works seek to augment LLM-based assistants with external tools so they\ncan access private or up-to-date information and carry out actions on behalf of\nusers. To better measure the performance of these assistants, this paper\nintroduces ToolTalk, a benchmark consisting of complex user intents requiring\nmulti-step tool usage specified through dialogue. ToolTalk contains 28 tools\ngrouped into 7 plugins, and includes a complete simulated implementation of\neach tool, allowing for fully automated evaluation of assistants that rely on\nexecution feedback. ToolTalk also emphasizes tools that externally affect the\nworld rather than only tools for referencing or searching information. We\nevaluate GPT-3.5 and GPT-4 on ToolTalk resulting in success rates of 26% and\n50% respectively. Our analysis of the errors reveals three major categories and\nsuggests some future directions for improvement. We release ToolTalk at\nhttps://github.com/microsoft/ToolTalk.\n",
                "链接": "https://arxiv.org/abs/2311.10775"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下工具评测相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "95678",
                "标题": "A Unified Interactive Model Evaluation for Classification, Object\n  Detection, and Instance Segmentation in Computer Vision",
                "作者": " Changjian Chen,  Yukai Guo,  Fengyuan Tian,  Shilong Liu,  Weikai Yang,  Zhaowei Wang,  Jing Wu,  Hang Su,  Hanspeter Pfister,  Shixia Liu",
                "发布日期": "2023-08-11",
                "摘要": "  Existing model evaluation tools mainly focus on evaluating classification\nmodels, leaving a gap in evaluating more complex models, such as object\ndetection. In this paper, we develop an open-source visual analysis tool,\nUni-Evaluator, to support a unified model evaluation for classification, object\ndetection, and instance segmentation in computer vision. The key idea behind\nour method is to formulate both discrete and continuous predictions in\ndifferent tasks as unified probability distributions. Based on these\ndistributions, we develop 1) a matrix-based visualization to provide an\noverview of model performance; 2) a table visualization to identify the\nproblematic data subsets where the model performs poorly; 3) a grid\nvisualization to display the samples of interest. These visualizations work\ntogether to facilitate the model evaluation from a global overview to\nindividual samples. Two case studies demonstrate the effectiveness of\nUni-Evaluator in evaluating model performance and making informed improvements.\n",
                "链接": "https://arxiv.org/abs/2308.05168"
            },
            {
                "文章ID": "105659",
                "标题": "Tool-Augmented Reward Modeling",
                "作者": " Lei Li,  Yekun Chai,  Shuohuan Wang,  Yu Sun,  Hao Tian,  Ningyu Zhang,  Hua Wu",
                "发布日期": "2023-10-03",
                "摘要": "  Reward modeling (a.k.a., preference modeling) is instrumental for aligning\nlarge language models with human preferences, particularly within the context\nof reinforcement learning from human feedback (RLHF). While conventional reward\nmodels (RMs) have exhibited remarkable scalability, they oft struggle with\nfundamental functionality such as arithmetic computation, code execution, and\nfactual lookup. In this paper, we propose a tool-augmented preference modeling\napproach, named \\name, to address these limitations by empowering RMs with\naccess to external environments, including calculators and search engines. This\napproach not only fosters synergy between tool utilization and reward grading\nbut also enhances interpretive capacity and scoring reliability. Our study\ndelves into the integration of external tools into RMs, enabling them to\ninteract with diverse external sources and construct task-specific tool\nengagement and reasoning traces in an autoregressive manner. We validate our\napproach across a wide range of domains, incorporating seven distinct external\ntools. Our experimental results demonstrate a noteworthy overall improvement of\n17.7% across eight tasks in preference ranking. Furthermore, our approach\noutperforms Gopher 280B by 7.3% on TruthfulQA task in zero-shot evaluation. In\nhuman evaluations, RLHF trained with Themis attains an average win rate of 32%\nwhen compared to baselines across four distinct tasks. Additionally, we provide\na comprehensive collection of tool-related RM datasets, incorporating data from\nseven distinct tool APIs, totaling 15,000 instances. We anticipate that this\npublicly available dataset will facilitate and inspire further research\nadvancements in the field.\n",
                "链接": "https://arxiv.org/abs/2310.01045"
            },
            {
                "文章ID": "43183",
                "标题": "Prioritizing emergency evacuations under compounding levels of\n  uncertainty",
                "作者": " Lisa J. Einstein,  Robert J. Moss,  Mykel J. Kochenderfer",
                "发布日期": "2022-10-18",
                "摘要": "  Well-executed emergency evacuations can save lives and reduce suffering.\nHowever, decision makers struggle to determine optimal evacuation policies\ngiven the chaos, uncertainty, and value judgments inherent in emergency\nevacuations. We propose and analyze a decision support tool for pre-crisis\ntraining exercises for teams preparing for civilian evacuations and explore the\ntool in the case of the 2021 U.S.-led evacuation from Afghanistan. We use\ndifferent classes of Markov decision processes (MDPs) to capture compounding\nlevels of uncertainty in (1) the priority category of who appears next at the\ngate for evacuation, (2) the distribution of priority categories at the\npopulation level, and (3) individuals' claimed priority category. We compare\nthe number of people evacuated by priority status under eight heuristic\npolicies. The optimized MDP policy achieves the best performance compared to\nall heuristic baselines. We also show that accounting for the compounding\nlevels of model uncertainty incurs added complexity without improvement in\npolicy performance. Useful heuristics can be extracted from the optimized\npolicies to inform human decision makers. We open-source all tools to encourage\nrobust dialogue about the trade-offs, limitations, and potential of integrating\nalgorithms into high-stakes humanitarian decision-making.\n",
                "链接": "https://arxiv.org/abs/2210.08975"
            },
            {
                "文章ID": "75809",
                "标题": "SuperNOVA: Design Strategies and Opportunities for Interactive\n  Visualization in Computational Notebooks",
                "作者": " Zijie J. Wang,  David Munechika,  Seongmin Lee,  Duen Horng Chau",
                "发布日期": "2023-05-05",
                "摘要": "  Computational notebooks such as Jupyter Notebook have become data scientists'\nde facto programming environments. Many visualization researchers and\npractitioners have developed interactive visualization tools that support\nnotebooks. However, little is known about the appropriate design of visual\nanalytics (VA) tools in notebooks. To bridge this critical research gap, we\ninvestigate the design strategies in this space by analyzing 159 notebook VA\ntools and their users' feedback. Our analysis encompasses 62 systems from\nacademic papers and 103 systems sourced from a pool of 55k notebooks containing\ninteractive visualizations that we obtain via scraping 8.6 million notebooks on\nGitHub. We also examine findings from 15 user studies and user feedback in 379\nGitHub issues. Through this work, we identify unique design opportunities and\nconsiderations for future notebook VA tools, such as using and manipulating\nmultimodal data in notebooks as well as balancing the degree of\nvisualization-notebook integration. Finally, we develop SuperNOVA, an\nopen-source interactive tool to help researchers explore existing notebook VA\ntools and search for related work.\n",
                "链接": "https://arxiv.org/abs/2305.03039"
            },
            {
                "文章ID": "107889",
                "标题": "Syntax Error-Free and Generalizable Tool Use for LLMs via Finite-State\n  Decoding",
                "作者": " Kexun Zhang,  Hongqiao Chen,  Lei Li,  William Wang",
                "发布日期": "2023-10-12",
                "摘要": "  Large language models (LLMs) have shown promising capabilities in using\nexternal tools to solve complex problems. However, existing approaches either\ninvolve fine-tuning on tool demonstrations, which do not generalize to new\ntools without additional training, or providing tool documentation in context,\nlimiting the number of tools. Both approaches often generate syntactically\ninvalid tool calls. In this paper, we propose ToolDec, a finite-state\nmachine-guided decoding algorithm for tool-augmented LLMs. ToolDec eliminates\ntool-related errors for any tool-augmented LLMs by ensuring valid tool names\nand type-conforming arguments. Furthermore, ToolDec enables LLM to effectively\nselect tools using only the information contained in their names, with no need\nfor fine-tuning or in-context documentation. We evaluated multiple prior\nmethods and their ToolDec-enhanced versions on a variety of tasks involving\ntools like math functions, knowledge graph relations, and complex real-world\nRESTful APIs. Our experiments show that ToolDec reduces syntactic errors to\nzero, consequently achieving significantly better performance and as much as a\n2x speedup. We also show that ToolDec achieves superior generalization\nperformance on unseen tools, performing up to 8x better than the baselines.\n",
                "链接": "https://arxiv.org/abs/2310.07075"
            },
            {
                "文章ID": "115632",
                "标题": "Eval-GCSC: A New Metric for Evaluating ChatGPT's Performance in Chinese\n  Spelling Correction",
                "作者": " Kunting Li,  Yong Hu,  Shaolei Wang,  Hanhan Ma,  Liang He,  Fandong Meng,  Jie Zhou",
                "发布日期": "2023-11-15",
                "摘要": "  ChatGPT has demonstrated impressive performance in various downstream tasks.\nHowever, in the Chinese Spelling Correction (CSC) task, we observe a\ndiscrepancy: while ChatGPT performs well under human evaluation, it scores\npoorly according to traditional metrics. We believe this inconsistency arises\nbecause the traditional metrics are not well-suited for evaluating generative\nmodels. Their overly strict length and phonics constraints may lead to\nunderestimating ChatGPT's correction capabilities. To better evaluate\ngenerative models in the CSC task, this paper proposes a new evaluation metric:\nEval-GCSC. By incorporating word-level and semantic similarity judgments, it\nrelaxes the stringent length and phonics constraints. Experimental results show\nthat Eval-GCSC closely aligns with human evaluations. Under this metric,\nChatGPT's performance is comparable to traditional token-level classification\nmodels (TCM), demonstrating its potential as a CSC tool. The source code and\nscripts can be accessed at https://github.com/ktlKTL/Eval-GCSC.\n",
                "链接": "https://arxiv.org/abs/2311.08219"
            },
            {
                "文章ID": "45762",
                "标题": "Evaluation of Categorical Generative Models -- Bridging the Gap Between\n  Real and Synthetic Data",
                "作者": " Florence Regol,  Anja Kroon,  Mark Coates",
                "发布日期": "2022-11-01",
                "摘要": "  The machine learning community has mainly relied on real data to benchmark\nalgorithms as it provides compelling evidence of model applicability.\nEvaluation on synthetic datasets can be a powerful tool to provide a better\nunderstanding of a model's strengths, weaknesses, and overall capabilities.\nGaining these insights can be particularly important for generative modeling as\nthe target quantity is completely unknown. Multiple issues related to the\nevaluation of generative models have been reported in the literature. We argue\nthose problems can be avoided by an evaluation based on ground truth. General\ncriticisms of synthetic experiments are that they are too simplified and not\nrepresentative of practical scenarios. As such, our experimental setting is\ntailored to a realistic generative task. We focus on categorical data and\nintroduce an appropriately scalable evaluation method. Our method involves\ntasking a generative model to learn a distribution in a high-dimensional\nsetting. We then successively bin the large space to obtain smaller probability\nspaces where meaningful statistical tests can be applied. We consider\nincreasingly large probability spaces, which correspond to increasingly\ndifficult modeling tasks and compare the generative models based on the highest\ntask difficulty they can reach before being detected as being too far from the\nground truth. We validate our evaluation procedure with synthetic experiments\non both synthetic generative models and current state-of-the-art categorical\ngenerative models.\n",
                "链接": "https://arxiv.org/abs/2210.16405"
            },
            {
                "文章ID": "893",
                "标题": "D-Graph: AI-Assisted Design Concept Exploration Graph",
                "作者": " Shin Sano,  Seiji Yamada",
                "发布日期": "2022-01-12",
                "摘要": "  We present an AI-assisted search tool, the \"Design Concept Exploration Graph\"\n(\"D-Graph\"). It assists automotive designers in creating an original\ndesign-concept phrase, that is, a combination of two adjectives that conveys\nproduct aesthetics. D-Graph retrieves adjectives from a ConceptNet knowledge\ngraph as nodes and visualizes them in a dynamically scalable 3D graph as users\nexplore words. The retrieval algorithm helps in finding unique words by ruling\nout overused words on the basis of word frequency from a large text corpus and\nwords that are too similar between the two in a combination using the cosine\nsimilarity from ConceptNet Numberbatch word embeddings. Our experiment with\nparticipants in the automotive design field that used both the proposed D-Graph\nand a baseline tool for design-concept-phrase creation tasks suggested a\npositive difference in participants' self-evaluation on the phrases they\ncreated, though not significant. Experts' evaluations on the phrases did not\nshow significant differences. Negative correlations between the cosine\nsimilarity of the two words in a design-concept phrase and the experts'\nevaluation were significant. Our qualitative analysis suggested the directions\nfor further development of the tool that should help users in adhering to the\nstrategy of creating compound phrases supported by computational linguistic\nprinciples.\n",
                "链接": "https://arxiv.org/abs/2201.03737"
            },
            {
                "文章ID": "87428",
                "标题": "ToolQA: A Dataset for LLM Question Answering with External Tools",
                "作者": " Yuchen Zhuang,  Yue Yu,  Kuan Wang,  Haotian Sun,  Chao Zhang",
                "发布日期": "2023-06-26",
                "摘要": "  Large Language Models (LLMs) have demonstrated impressive performance in\nvarious NLP tasks, but they still suffer from challenges such as hallucination\nand weak numerical reasoning. To overcome these challenges, external tools can\nbe used to enhance LLMs' question-answering abilities. However, current\nevaluation methods do not distinguish between questions that can be answered\nusing LLMs' internal knowledge and those that require external information\nthrough tool use. To address this issue, we introduce a new dataset called\nToolQA, which is designed to faithfully evaluate LLMs' ability to use external\ntools for question answering. Our development of ToolQA involved a scalable,\nautomated process for dataset curation, along with 13 specialized tools\ndesigned for interaction with external knowledge in order to answer questions.\nImportantly, we strive to minimize the overlap between our benchmark data and\nLLMs' pre-training data, enabling a more precise evaluation of LLMs' tool-use\nreasoning abilities. We conducted an in-depth diagnosis of existing tool-use\nLLMs to highlight their strengths, weaknesses, and potential improvements. Our\nfindings set a new benchmark for evaluating LLMs and suggest new directions for\nfuture advancements. Our data and code are freely available to the broader\nscientific community on GitHub.\n",
                "链接": "https://arxiv.org/abs/2306.13304"
            },
            {
                "文章ID": "64026",
                "标题": "Constrained Bayesian Optimization for Automatic Underwater Vehicle Hull\n  Design",
                "作者": " Harsh Vardhan,  Peter Volgyesi,  Will Hedgecock,  Janos Sztipanovits",
                "发布日期": "2023-03-16",
                "摘要": "  Automatic underwater vehicle hull Design optimization is a complex\nengineering process for generating a UUV hull with optimized properties on a\ngiven requirement. First, it involves the integration of involved\ncomputationally complex engineering simulation tools. Second, it needs\nintegration of a sample efficient optimization framework with the integrated\ntoolchain. To this end, we integrated the CAD tool called FreeCAD with CFD tool\nopenFoam for automatic design evaluation. For optimization, we chose Bayesian\noptimization (BO), which is a well-known technique developed for optimizing\ntime-consuming expensive engineering simulations and has proven to be very\nsample efficient in a variety of problems, including hyper-parameter tuning and\nexperimental design. During the optimization process, we can handle infeasible\ndesign as constraints integrated into the optimization process. By integrating\ndomain-specific toolchain with AI-based optimization, we executed the automatic\ndesign optimization of underwater vehicle hull design. For empirical\nevaluation, we took two different use cases of real-world underwater vehicle\ndesign to validate the execution of our tool.\n",
                "链接": "https://arxiv.org/abs/2302.14732"
            }
        ]
    },
    {
        "question": {
            "question": "大模型在游戏方面的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "102747",
                "标题": "MindAgent: Emergent Gaming Interaction",
                "作者": " Ran Gong,  Qiuyuan Huang,  Xiaojian Ma,  Hoi Vo,  Zane Durante,  Yusuke Noda,  Zilong Zheng,  Song-Chun Zhu,  Demetri Terzopoulos,  Li Fei-Fei,  Jianfeng Gao",
                "发布日期": "2023-09-20",
                "摘要": "  Large Language Models (LLMs) have the capacity of performing complex\nscheduling in a multi-agent system and can coordinate these agents into\ncompleting sophisticated tasks that require extensive collaboration. However,\ndespite the introduction of numerous gaming frameworks, the community has\ninsufficient benchmarks towards building general multi-agents collaboration\ninfrastructure that encompass both LLM and human-NPCs collaborations. In this\nwork, we propose a novel infrastructure - MindAgent - to evaluate planning and\ncoordination emergent capabilities for gaming interaction. In particular, our\ninfrastructure leverages existing gaming framework, to i) require understanding\nof the coordinator for a multi-agent system, ii) collaborate with human players\nvia un-finetuned proper instructions, and iii) establish an in-context learning\non few-shot prompt with feedback. Furthermore, we introduce CUISINEWORLD, a new\ngaming scenario and related benchmark that dispatch a multi-agent collaboration\nefficiency and supervise multiple agents playing the game simultaneously. We\nconduct comprehensive evaluations with new auto-metric CoS for calculating the\ncollaboration efficiency. Finally, our infrastructure can be deployed into\nreal-world gaming scenarios in a customized VR version of CUISINEWORLD and\nadapted in existing broader Minecraft gaming domain. We hope our findings on\nLLMs and the new infrastructure for general-purpose scheduling and coordination\ncan help shed light on how such skills can be obtained by learning from large\nlanguage corpora.\n",
                "链接": "https://arxiv.org/abs/2309.09971"
            },
            {
                "文章ID": "12922",
                "标题": "Perceptual Quality Assessment of UGC Gaming Videos",
                "作者": " Xiangxu Yu,  Zhengzhong Tu,  Neil Birkbeck,  Yilin Wang,  Balu Adsumilli,  Alan C. Bovik",
                "发布日期": "2022-04-15",
                "摘要": "  In recent years, with the vigorous development of the video game industry,\nthe proportion of gaming videos on major video websites like YouTube has\ndramatically increased. However, relatively little research has been done on\nthe automatic quality prediction of gaming videos, especially on those that\nfall in the category of \"User-Generated-Content\" (UGC). Since current leading\ngeneral-purpose Video Quality Assessment (VQA) models do not perform well on\nthis type of gaming videos, we have created a new VQA model specifically\ndesigned to succeed on UGC gaming videos, which we call the Gaming Video\nQuality Predictor (GAME-VQP). GAME-VQP successfully predicts the unique\nstatistical characteristics of gaming videos by drawing upon features designed\nunder modified natural scene statistics models, combined with gaming specific\nfeatures learned by a Convolution Neural Network. We study the performance of\nGAME-VQP on a very recent large UGC gaming video database called\nLIVE-YT-Gaming, and find that it both outperforms other mainstream general VQA\nmodels as well as VQA models specifically designed for gaming videos. The new\nmodel will be made public after paper being accepted.\n",
                "链接": "https://arxiv.org/abs/2204.00128"
            },
            {
                "文章ID": "48707",
                "标题": "Reward Gaming in Conditional Text Generation",
                "作者": " Richard Yuanzhe Pang,  Vishakh Padmakumar,  Thibault Sellam,  Ankur P. Parikh,  He He",
                "发布日期": "2023-06-02",
                "摘要": "  To align conditional text generation model outputs with desired behaviors,\nthere has been an increasing focus on training the model using reinforcement\nlearning (RL) with reward functions learned from human annotations. Under this\nframework, we identify three common cases where high rewards are incorrectly\nassigned to undesirable patterns: noise-induced spurious correlation, naturally\noccurring spurious correlation, and covariate shift. We show that even though\nlearned metrics achieve high performance on the distribution of the data used\nto train the reward function, the undesirable patterns may be amplified during\nRL training of the text generation model. While there has been discussion about\nreward gaming in the RL or safety community, in this discussion piece, we would\nlike to highlight reward gaming in the natural language generation (NLG)\ncommunity using concrete conditional text generation examples and discuss\npotential fixes and areas for future work.\n",
                "链接": "https://arxiv.org/abs/2211.08714"
            },
            {
                "文章ID": "11430",
                "标题": "Subjective and Objective Analysis of Streamed Gaming Videos",
                "作者": " Xiangxu Yu,  Zhenqiang Ying,  Neil Birkbeck,  Yilin Wang,  Balu Adsumilli,  Alan C. Bovik",
                "发布日期": "2022-03-25",
                "摘要": "  The rising popularity of online User-Generated-Content (UGC) in the form of\nstreamed and shared videos, has hastened the development of perceptual Video\nQuality Assessment (VQA) models, which can be used to help optimize their\ndelivery. Gaming videos, which are a relatively new type of UGC videos, are\ncreated when skilled gamers post videos of their gameplay. These kinds of\nscreenshots of UGC gameplay videos have become extremely popular on major\nstreaming platforms like YouTube and Twitch. Synthetically-generated gaming\ncontent presents challenges to existing VQA algorithms, including those based\non natural scene/video statistics models. Synthetically generated gaming\ncontent presents different statistical behavior than naturalistic videos. A\nnumber of studies have been directed towards understanding the perceptual\ncharacteristics of professionally generated gaming videos arising in gaming\nvideo streaming, online gaming, and cloud gaming. However, little work has been\ndone on understanding the quality of UGC gaming videos, and how it can be\ncharacterized and predicted. Towards boosting the progress of gaming video VQA\nmodel development, we conducted a comprehensive study of subjective and\nobjective VQA models on UGC gaming videos. To do this, we created a novel UGC\ngaming video resource, called the LIVE-YouTube Gaming video quality\n(LIVE-YT-Gaming) database, comprised of 600 real UGC gaming videos. We\nconducted a subjective human study on this data, yielding 18,600 human quality\nratings recorded by 61 human subjects. We also evaluated a number of\nstate-of-the-art (SOTA) VQA models on the new database, including a new one,\ncalled GAME-VQP, based on both natural video statistics and CNN-learned\nfeatures. To help support work in this field, we are making the new\nLIVE-YT-Gaming Database, publicly available through the link:\nhttps://live.ece.utexas.edu/research/LIVE-YT-Gaming/index.html .\n",
                "链接": "https://arxiv.org/abs/2203.12824"
            },
            {
                "文章ID": "81335",
                "标题": "Study of Subjective and Objective Quality Assessment of Mobile Cloud\n  Gaming Videos",
                "作者": " Avinab Saha,  Yu-Chih Chen,  Chase Davis,  Bo Qiu,  Xiaoming Wang,  Rahul Gowda,  Ioannis Katsavounidis,  Alan C. Bovik",
                "发布日期": "2023-06-28",
                "摘要": "  We present the outcomes of a recent large-scale subjective study of Mobile\nCloud Gaming Video Quality Assessment (MCG-VQA) on a diverse set of gaming\nvideos. Rapid advancements in cloud services, faster video encoding\ntechnologies, and increased access to high-speed, low-latency wireless internet\nhave all contributed to the exponential growth of the Mobile Cloud Gaming\nindustry. Consequently, the development of methods to assess the quality of\nreal-time video feeds to end-users of cloud gaming platforms has become\nincreasingly important. However, due to the lack of a large-scale public Mobile\nCloud Gaming Video dataset containing a diverse set of distorted videos with\ncorresponding subjective scores, there has been limited work on the development\nof MCG-VQA models. Towards accelerating progress towards these goals, we\ncreated a new dataset, named the LIVE-Meta Mobile Cloud Gaming (LIVE-Meta-MCG)\nvideo quality database, composed of 600 landscape and portrait gaming videos,\non which we collected 14,400 subjective quality ratings from an in-lab\nsubjective study. Additionally, to demonstrate the usefulness of the new\nresource, we benchmarked multiple state-of-the-art VQA algorithms on the\ndatabase. The new database will be made publicly available on our website:\n\\url{https://live.ece.utexas.edu/research/LIVE-Meta-Mobile-Cloud-Gaming/index.html}\n",
                "链接": "https://arxiv.org/abs/2305.17260"
            },
            {
                "文章ID": "75621",
                "标题": "GAMIVAL: Video Quality Prediction on Mobile Cloud Gaming Content",
                "作者": " Yu-Chih Chen,  Avinab Saha,  Chase Davis,  Bo Qiu,  Xiaoming Wang,  Rahul Gowda,  Ioannis Katsavounidis,  Alan C. Bovik",
                "发布日期": "2023-08-31",
                "摘要": "  The mobile cloud gaming industry has been rapidly growing over the last\ndecade. When streaming gaming videos are transmitted to customers' client\ndevices from cloud servers, algorithms that can monitor distorted video quality\nwithout having any reference video available are desirable tools. However,\ncreating No-Reference Video Quality Assessment (NR VQA) models that can\naccurately predict the quality of streaming gaming videos rendered by computer\ngraphics engines is a challenging problem, since gaming content generally\ndiffers statistically from naturalistic videos, often lacks detail, and\ncontains many smooth regions. Until recently, the problem has been further\ncomplicated by the lack of adequate subjective quality databases of mobile\ngaming content. We have created a new gaming-specific NR VQA model called the\nGaming Video Quality Evaluator (GAMIVAL), which combines and leverages the\nadvantages of spatial and temporal gaming distorted scene statistics models, a\nneural noise model, and deep semantic features. Using a support vector\nregression (SVR) as a regressor, GAMIVAL achieves superior performance on the\nnew LIVE-Meta Mobile Cloud Gaming (LIVE-Meta MCG) video quality database.\n",
                "链接": "https://arxiv.org/abs/2305.02422"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "122132",
                "标题": "Scaling Culture in Blockchain Gaming: Generative AI and Pseudonymous\n  Engagement",
                "作者": " Henrik Axelsen,  Sebastian Axelsen,  Valdemar Licht,  Jason Potts",
                "发布日期": "2023-12-14",
                "摘要": "  Managing rapidly growing decentralized gaming communities brings unique\nchallenges at the nexus of cultural economics and technology. This paper\nintroduces a streamlined analytical framework that utilizes Large Language\nModels (LLMs), in this instance open-access generative pre-trained transformer\n(GPT) models, offering an efficient solution with deeper insights into\ncommunity dynamics. The framework aids moderators in identifying pseudonymous\nactor intent, moderating toxic behavior, rewarding desired actions to avoid\nunintended consequences of blockchain-based gaming, and gauging community\nsentiment as communities venture into metaverse platforms and plan for\nhypergrowth. This framework strengthens community controls, eases onboarding,\nand promotes a common moral mission across communities while reducing agency\ncosts by 95 pct. Highlighting the transformative role of generative AI, the\npaper emphasizes its potential to redefine the cost of cultural production. It\nshowcases the utility of GPTs in digital community management, expanding their\nimplications in cultural economics and transmedia storytelling.\n",
                "链接": "https://arxiv.org/abs/2312.07693"
            },
            {
                "文章ID": "55440",
                "标题": "Measuring and Estimating Key Quality Indicators in Cloud Gaming services",
                "作者": " Carlos Baena,  O. S. Peñaherrera-Pulla,  Raquel Barco,  Sergio Fortes",
                "发布日期": "2023-05-11",
                "摘要": "  User equipment is one of the main bottlenecks facing the gaming industry\nnowadays. The extremely realistic games which are currently available trigger\nhigh computational requirements of the user devices to run games. As a\nconsequence, the game industry has proposed the concept of Cloud Gaming, a\nparadigm that improves gaming experience in reduced hardware devices. To this\nend, games are hosted on remote servers, relegating users' devices to play only\nthe role of a peripheral for interacting with the game. However, this paradigm\noverloads the communication links connecting the users with the cloud.\nTherefore, service experience becomes highly dependent on network connectivity.\nTo overcome this, Cloud Gaming will be boosted by the promised performance of\n5G and future 6G networks, together with the flexibility provided by mobility\nin multi-RAT scenarios, such as WiFi. In this scope, the present work proposes\na framework for measuring and estimating the main E2E metrics of the Cloud\nGaming service, namely KQIs. In addition, different machine learning techniques\nare assessed for predicting KQIs related to Cloud Gaming user's experience. To\nthis end, the main key quality indicators (KQIs) of the service such as input\nlag, freeze percent or perceived video frame rate are collected in a real\nenvironment. Based on these, results show that machine learning techniques\nprovide a good estimation of these indicators solely from network-based\nmetrics. This is considered a valuable asset to guide the delivery of Cloud\nGaming services through cellular communications networks even without access to\nthe user's device, as it is expected for telecom operators.\n",
                "链接": "https://arxiv.org/abs/2212.14073"
            },
            {
                "文章ID": "104308",
                "标题": "People's Perceptions Toward Bias and Related Concepts in Large Language\n  Models: A Systematic Review",
                "作者": " Lu Wang,  Max Song,  Rezvaneh Rezapour,  Bum Chul Kwon,  Jina Huh-Yoo",
                "发布日期": "2023-09-27",
                "摘要": "  Large language models (LLMs) have brought breakthroughs in tasks including\ntranslation, summarization, information retrieval, and language generation,\ngaining growing interest in the CHI community. Meanwhile, the literature shows\nresearchers' controversial perceptions about the efficacy, ethics, and\nintellectual abilities of LLMs. However, we do not know how lay people perceive\nLLMs that are pervasive in everyday tools, specifically regarding their\nexperience with LLMs around bias, stereotypes, social norms, or safety. In this\nstudy, we conducted a systematic review to understand what empirical insights\npapers have gathered about people's perceptions toward LLMs. From a total of\n231 retrieved papers, we full-text reviewed 15 papers that recruited human\nevaluators to assess their experiences with LLMs. We report different biases\nand related concepts investigated by these studies, four broader LLM\napplication areas, the evaluators' perceptions toward LLMs' performances\nincluding advantages, biases, and conflicting perceptions, factors influencing\nthese perceptions, and concerns about LLM applications.\n",
                "链接": "https://arxiv.org/abs/2309.14504"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "21348",
                "标题": "Target-aware Abstractive Related Work Generation with Contrastive\n  Learning",
                "作者": " Xiuying Chen,  Hind Alamro,  Mingzhe Li,  Shen Gao,  Rui Yan,  Xin Gao,  Xiangliang Zhang",
                "发布日期": "2022-05-27",
                "摘要": "  The related work section is an important component of a scientific paper,\nwhich highlights the contribution of the target paper in the context of the\nreference papers. Authors can save their time and effort by using the\nautomatically generated related work section as a draft to complete the final\nrelated work. Most of the existing related work section generation methods rely\non extracting off-the-shelf sentences to make a comparative discussion about\nthe target work and the reference papers. However, such sentences need to be\nwritten in advance and are hard to obtain in practice. Hence, in this paper, we\npropose an abstractive target-aware related work generator (TAG), which can\ngenerate related work sections consisting of new sentences. Concretely, we\nfirst propose a target-aware graph encoder, which models the relationships\nbetween reference papers and the target paper with target-centered attention\nmechanisms. In the decoding process, we propose a hierarchical decoder that\nattends to the nodes of different levels in the graph with keyphrases as\nsemantic indicators. Finally, to generate a more informative related work, we\npropose multi-level contrastive optimization objectives, which aim to maximize\nthe mutual information between the generated related work with the references\nand minimize that with non-references. Extensive experiments on two public\nscholar datasets show that the proposed model brings substantial improvements\nover several strong baselines in terms of automatic and tailored human\nevaluations.\n",
                "链接": "https://arxiv.org/abs/2205.13339"
            },
            {
                "文章ID": "95351",
                "标题": "Auditory Attention Decoding with Task-Related Multi-View Contrastive\n  Learning",
                "作者": " Xiaoyu Chen,  Changde Du,  Qiongyi Zhou,  Huiguang He",
                "发布日期": "2023-08-09",
                "摘要": "  The human brain can easily focus on one speaker and suppress others in\nscenarios such as a cocktail party. Recently, researchers found that auditory\nattention can be decoded from the electroencephalogram (EEG) data. However,\nmost existing deep learning methods are difficult to use prior knowledge of\ndifferent views (that is attended speech and EEG are task-related views) and\nextract an unsatisfactory representation. Inspired by Broadbent's filter model,\nwe decode auditory attention in a multi-view paradigm and extract the most\nrelevant and important information utilizing the missing view. Specifically, we\npropose an auditory attention decoding (AAD) method based on multi-view VAE\nwith task-related multi-view contrastive (TMC) learning. Employing TMC learning\nin multi-view VAE can utilize the missing view to accumulate prior knowledge of\ndifferent views into the fusion of representation, and extract the approximate\ntask-related representation. We examine our method on two popular AAD datasets,\nand demonstrate the superiority of our method by comparing it to the\nstate-of-the-art method.\n",
                "链接": "https://arxiv.org/abs/2308.04244"
            },
            {
                "文章ID": "50069",
                "标题": "How do Authors' Perceptions of their Papers Compare with Co-authors'\n  Perceptions and Peer-review Decisions?",
                "作者": " Charvi Rastogi,  Ivan Stelmakh,  Alina Beygelzimer,  Yann N. Dauphin,  Percy Liang,  Jennifer Wortman Vaughan,  Zhenyu Xue, III Hal Daumé,  Emma Pierson,  Nihar B. Shah",
                "发布日期": "2022-11-24",
                "摘要": "  How do author perceptions match up to the outcomes of the peer-review process\nand perceptions of others? In a top-tier computer science conference (NeurIPS\n2021) with more than 23,000 submitting authors and 9,000 submitted papers, we\nsurvey the authors on three questions: (i) their predicted probability of\nacceptance for each of their papers, (ii) their perceived ranking of their own\npapers based on scientific contribution, and (iii) the change in their\nperception about their own papers after seeing the reviews. The salient results\nare: (1) Authors have roughly a three-fold overestimate of the acceptance\nprobability of their papers: The median prediction is 70% for an approximately\n25% acceptance rate. (2) Female authors exhibit a marginally higher\n(statistically significant) miscalibration than male authors; predictions of\nauthors invited to serve as meta-reviewers or reviewers are similarly\ncalibrated, but better than authors who were not invited to review. (3)\nAuthors' relative ranking of scientific contribution of two submissions they\nmade generally agree (93%) with their predicted acceptance probabilities, but\nthere is a notable 7% responses where authors think their better paper will\nface a worse outcome. (4) The author-provided rankings disagreed with the\npeer-review decisions about a third of the time; when co-authors ranked their\njointly authored papers, co-authors disagreed at a similar rate -- about a\nthird of the time. (5) At least 30% of respondents of both accepted and\nrejected papers said that their perception of their own paper improved after\nthe review process. The stakeholders in peer review should take these findings\ninto account in setting their expectations from peer review.\n",
                "链接": "https://arxiv.org/abs/2211.12966"
            },
            {
                "文章ID": "1976",
                "标题": "Why Did You Not Compare With That? Identifying Papers for Use as\n  Baselines",
                "作者": " Manjot Bedi,  Tanisha Pandey,  Sumit Bhatia,  Tanmoy Chakraborty",
                "发布日期": "2022-01-21",
                "摘要": "  We propose the task of automatically identifying papers used as baselines in\na scientific article. We frame the problem as a binary classification task\nwhere all the references in a paper are to be classified as either baselines or\nnon-baselines. This is a challenging problem due to the numerous ways in which\na baseline reference can appear in a paper. We develop a dataset of $2,075$\npapers from ACL anthology corpus with all their references manually annotated\nas one of the two classes. We develop a multi-module attention-based neural\nclassifier for the baseline classification task that outperforms four\nstate-of-the-art citation role classification methods when applied to the\nbaseline classification task. We also present an analysis of the errors made by\nthe proposed classifier, eliciting the challenges that make baseline\nidentification a challenging problem.\n",
                "链接": "https://arxiv.org/abs/2201.08089"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "44909",
                "标题": "Information Filter upon Diversity-Improved Decoding for\n  Diversity-Faithfulness Tradeoff in NLG",
                "作者": " Han Meng,  Xiaosong He,  Zexing Chen,  Feng Zhou",
                "发布日期": "2023-02-22",
                "摘要": "  Some Natural Language Generation (NLG) tasks require both faithfulness and\ndiversity. The decoding strategy is intensively related to the quality of the\ngenerated text. Strategies such as beam search, greedy search, etc., perform\nwith low diversity and high repetition. On the other hand, guided decoding, the\nsolution towards diversity, may generate unfaithful expressions. To this end,\nthis paper presents Information Filter upon Diversity-Improved Decoding (IFDID)\nto obtain the tradeoff between diversity and faithfulness. IFDID is a two-stage\ndecoding strategy leveraging the proposed Enhance-Filter framework, which\nachieves the tradeoff by increasing the probabilities of some typical tokens\nbeing selected and subsequently filtering them by their information amount. To\nverify the effectiveness, we compare our method with other baselines on related\nCommonGEN, RocStories and AdGen benchmarks, which cover Chinese and English\ndatasets. Our numerical experimental results and human evaluation outcomes\nverify the effectiveness of the proposed approach, as our approach achieves a\n1.24 higher ROUGE score describing faithfulness as well as higher diversity\nrepresented by 62.5% higher upon Dist-2 than traditional approaches,\ndemonstrating that IFDID is a novel SOTA decoding strategy for the tradeoff\nbetween diversity and faithfulness.\n",
                "链接": "https://arxiv.org/abs/2210.13829"
            },
            {
                "文章ID": "442",
                "标题": "Automatic Related Work Generation: A Meta Study",
                "作者": " Xiangci Li,  Jessica Ouyang",
                "发布日期": "2022-01-07",
                "摘要": "  Academic research is an exploration activity to solve problems that have\nnever been resolved before. By this nature, each academic research work is\nrequired to perform a literature review to distinguish its novelties that have\nnot been addressed by prior works. In natural language processing, this\nliterature review is usually conducted under the \"Related Work\" section. The\ntask of automatic related work generation aims to automatically generate the\n\"Related Work\" section given the rest of the research paper and a list of cited\npapers. Although this task was proposed over 10 years ago, it received little\nattention until very recently, when it was cast as a variant of the scientific\nmulti-document summarization problem. However, even today, the problems of\nautomatic related work and citation text generation are not yet standardized.\nIn this survey, we conduct a meta-study to compare the existing literature on\nrelated work generation from the perspectives of problem formulation, dataset\ncollection, methodological approach, performance evaluation, and future\nprospects to provide the reader insight into the progress of the\nstate-of-the-art studies, as well as and how future studies can be conducted.\nWe also survey relevant fields of study that we suggest future work to consider\nintegrating.\n",
                "链接": "https://arxiv.org/abs/2201.01880"
            },
            {
                "文章ID": "95587",
                "标题": "NLLG Quarterly arXiv Report 06/23: What are the most influential current\n  AI Papers?",
                "作者": " Steffen Eger,  Christoph Leiter,  Jonas Belouadi,  Ran Zhang,  Aida Kostikova,  Daniil Larionov,  Yanran Chen,  Vivian Fresen",
                "发布日期": "2023-08-15",
                "摘要": "  The rapid growth of information in the field of Generative Artificial\nIntelligence (AI), particularly in the subfields of Natural Language Processing\n(NLP) and Machine Learning (ML), presents a significant challenge for\nresearchers and practitioners to keep pace with the latest developments. To\naddress the problem of information overload, this report by the Natural\nLanguage Learning Group at Bielefeld University focuses on identifying the most\npopular papers on arXiv, with a specific emphasis on NLP and ML. The objective\nis to offer a quick guide to the most relevant and widely discussed research,\naiding both newcomers and established researchers in staying abreast of current\ntrends. In particular, we compile a list of the 40 most popular papers based on\nnormalized citation counts from the first half of 2023. We observe the\ndominance of papers related to Large Language Models (LLMs) and specifically\nChatGPT during the first half of 2023, with the latter showing signs of\ndeclining popularity more recently, however. Further, NLP related papers are\nthe most influential (around 60\\% of top papers) even though there are twice as\nmany ML related papers in our data. Core issues investigated in the most\nheavily cited papers are: LLM efficiency, evaluation techniques, ethical\nconsiderations, embodied agents, and problem-solving with LLMs. Additionally,\nwe examine the characteristics of top papers in comparison to others outside\nthe top-40 list (noticing the top paper's focus on LLM related issues and\nhigher number of co-authors) and analyze the citation distributions in our\ndataset, among others.\n",
                "链接": "https://arxiv.org/abs/2308.04889"
            },
            {
                "文章ID": "42172",
                "标题": "Predicting the clinical citation count of biomedical papers using\n  multilayer perceptron neural network",
                "作者": " Xin Li,  Xuli Tang,  Qikai Cheng",
                "发布日期": "2022-10-24",
                "摘要": "  The number of clinical citations received from clinical guidelines or\nclinical trials has been considered as one of the most appropriate indicators\nfor quantifying the clinical impact of biomedical papers. Therefore, the early\nprediction of the clinical citation count of biomedical papers is critical to\nscientific activities in biomedicine, such as research evaluation, resource\nallocation, and clinical translation. In this study, we designed a four-layer\nmultilayer perceptron neural network (MPNN) model to predict the clinical\ncitation count of biomedical papers in the future by using 9,822,620 biomedical\npapers published from 1985 to 2005. We extracted ninety-one paper features from\nthree dimensions as the input of the model, including twenty-one features in\nthe paper dimension, thirty-five in the reference dimension, and thirty-five in\nthe citing paper dimension. In each dimension, the features can be classified\ninto three categories, i.e., the citation-related features, the clinical\ntranslation-related features, and the topic-related features. Besides, in the\npaper dimension, we also considered the features that have previously been\ndemonstrated to be related to the citation counts of research papers. The\nresults showed that the proposed MPNN model outperformed the other five\nbaseline models, and the features in the reference dimension were the most\nimportant.\n",
                "链接": "https://arxiv.org/abs/2210.06346"
            },
            {
                "文章ID": "120092",
                "标题": "TPPoet: Transformer-Based Persian Poem Generation using Minimal Data and\n  Advanced Decoding Techniques",
                "作者": " Amir Panahandeh,  Hanie Asemi,  Esmaeil Nourani",
                "发布日期": "2023-12-07",
                "摘要": "  Recent advances in language models (LMs), have demonstrated significant\nefficacy in tasks related to the arts and humanities. While LMs have exhibited\nexceptional performance across a wide range of natural language processing\ntasks, there are notable challenges associated with their utilization on small\ndatasets and their ability to replicate more creative human capacities. In this\nstudy, we aim to address these challenges by training a Persian classical\npoetry generation model using a transformer architecture on a specialized\ndataset with no pretraining. Additionally, we propose a novel decoding method\nto enhance coherence and meaningfulness in the generated poetry, effectively\nmanaging the tradeoff between diversity and quality. Furthermore, the results\nof our training approach and the proposed decoding method are evaluated through\ncomprehensive set of automatic and human evaluations and showed its superior\ncapability to generate coherent and meaningful poetry in compare to other\ndecoding methods and an existing Persian large language model (LLM).\n",
                "链接": "https://arxiv.org/abs/2312.02125"
            }
        ]
    },
    {
        "question": {
            "question": "请找到缓和噪声标签影响的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "124269",
                "标题": "Universal Noise Annotation: Unveiling the Impact of Noisy annotation on\n  Object Detection",
                "作者": " Kwangrok Ryoo,  Yeonsik Jo,  Seungjun Lee,  Mira Kim,  Ahra Jo,  Seung Hwan Kim,  Seungryong Kim,  Soonyoung Lee",
                "发布日期": "2023-12-22",
                "摘要": "  For object detection task with noisy labels, it is important to consider not\nonly categorization noise, as in image classification, but also localization\nnoise, missing annotations, and bogus bounding boxes. However, previous studies\nhave only addressed certain types of noise (e.g., localization or\ncategorization). In this paper, we propose Universal-Noise Annotation (UNA), a\nmore practical setting that encompasses all types of noise that can occur in\nobject detection, and analyze how UNA affects the performance of the detector.\nWe analyzed the development direction of previous works of detection algorithms\nand examined the factors that impact the robustness of detection model learning\nmethod. We open-source the code for injecting UNA into the dataset and all the\ntraining log and weight are also shared.\n",
                "链接": "https://arxiv.org/abs/2312.13822"
            },
            {
                "文章ID": "81832",
                "标题": "Examining the Role and Limits of Batchnorm Optimization to Mitigate\n  Diverse Hardware-noise in In-memory Computing",
                "作者": " Abhiroop Bhattacharjee,  Abhishek Moitra,  Youngeun Kim,  Yeshwanth Venkatesha,  Priyadarshini Panda",
                "发布日期": "2023-05-31",
                "摘要": "  In-Memory Computing (IMC) platforms such as analog crossbars are gaining\nfocus as they facilitate the acceleration of low-precision Deep Neural Networks\n(DNNs) with high area- & compute-efficiencies. However, the intrinsic\nnon-idealities in crossbars, which are often non-deterministic and non-linear,\ndegrade the performance of the deployed DNNs. In addition to quantization\nerrors, most frequently encountered non-idealities during inference include\ncrossbar circuit-level parasitic resistances and device-level non-idealities\nsuch as stochastic read noise and temporal drift. In this work, our goal is to\nclosely examine the distortions caused by these non-idealities on the\ndot-product operations in analog crossbars and explore the feasibility of a\nnearly training-less solution via crossbar-aware fine-tuning of batchnorm\nparameters in real-time to mitigate the impact of the non-idealities. This\nenables reduction in hardware costs in terms of memory and training energy for\nIMC noise-aware retraining of the DNN weights on crossbars.\n",
                "链接": "https://arxiv.org/abs/2305.18416"
            },
            {
                "文章ID": "3588",
                "标题": "An Assessment of the Impact of OCR Noise on Language Models",
                "作者": " Konstantin Todorov,  Giovanni Colavizza",
                "发布日期": "2022-02-02",
                "摘要": "  Neural language models are the backbone of modern-day natural language\nprocessing applications. Their use on textual heritage collections which have\nundergone Optical Character Recognition (OCR) is therefore also increasing.\nNevertheless, our understanding of the impact OCR noise could have on language\nmodels is still limited. We perform an assessment of the impact OCR noise has\non a variety of language models, using data in Dutch, English, French and\nGerman. We find that OCR noise poses a significant obstacle to language\nmodelling, with language models increasingly diverging from their noiseless\ntargets as OCR quality lowers. In the presence of small corpora, simpler models\nincluding PPMI and Word2Vec consistently outperform transformer-based models in\nthis respect.\n",
                "链接": "https://arxiv.org/abs/2202.00470"
            },
            {
                "文章ID": "48397",
                "标题": "Quantifying the Impact of Label Noise on Federated Learning",
                "作者": " Shuqi Ke,  Chao Huang,  Xin Liu",
                "发布日期": "2023-04-04",
                "摘要": "  Federated Learning (FL) is a distributed machine learning paradigm where\nclients collaboratively train a model using their local (human-generated)\ndatasets. While existing studies focus on FL algorithm development to tackle\ndata heterogeneity across clients, the important issue of data quality (e.g.,\nlabel noise) in FL is overlooked. This paper aims to fill this gap by providing\na quantitative study on the impact of label noise on FL. We derive an upper\nbound for the generalization error that is linear in the clients' label noise\nlevel. Then we conduct experiments on MNIST and CIFAR-10 datasets using various\nFL algorithms. Our empirical results show that the global model accuracy\nlinearly decreases as the noise level increases, which is consistent with our\ntheoretical analysis. We further find that label noise slows down the\nconvergence of FL training, and the global model tends to overfit when the\nnoise level is high.\n",
                "链接": "https://arxiv.org/abs/2211.07816"
            },
            {
                "文章ID": "76850",
                "标题": "Rethinking the Value of Labels for Instance-Dependent Label Noise\n  Learning",
                "作者": " Hanwen Deng,  Weijia Zhang,  Min-Ling Zhang",
                "发布日期": "2023-05-16",
                "摘要": "  Label noise widely exists in large-scale datasets and significantly\ndegenerates the performances of deep learning algorithms. Due to the\nnon-identifiability of the instance-dependent noise transition matrix, most\nexisting algorithms address the problem by assuming the noisy label generation\nprocess to be independent of the instance features. Unfortunately, noisy labels\nin real-world applications often depend on both the true label and the\nfeatures. In this work, we tackle instance-dependent label noise with a novel\ndeep generative model that avoids explicitly modeling the noise transition\nmatrix. Our algorithm leverages casual representation learning and\nsimultaneously identifies the high-level content and style latent factors from\nthe data. By exploiting the supervision information of noisy labels with\nstructural causal models, our empirical evaluations on a wide range of\nsynthetic and real-world instance-dependent label noise datasets demonstrate\nthat the proposed algorithm significantly outperforms the state-of-the-art\ncounterparts.\n",
                "链接": "https://arxiv.org/abs/2305.06247"
            },
            {
                "文章ID": "5243",
                "标题": "Impact of Discretization Noise of the Dependent variable on Machine\n  Learning Classifiers in Software Engineering",
                "作者": " Gopi Krishnan Rajbahadur,  Shaowei Wang,  Yasutaka Kamei,  Ahmed E. Hassan",
                "发布日期": "2022-02-15",
                "摘要": "  Researchers usually discretize a continuous dependent variable into two\ntarget classes by introducing an artificial discretization threshold (e.g.,\nmedian). However, such discretization may introduce noise (i.e., discretization\nnoise) due to ambiguous class loyalty of data points that are close to the\nartificial threshold. Previous studies do not provide a clear directive on the\nimpact of discretization noise on the classifiers and how to handle such noise.\nIn this paper, we propose a framework to help researchers and practitioners\nsystematically estimate the impact of discretization noise on classifiers in\nterms of its impact on various performance measures and the interpretation of\nclassifiers. Through a case study of 7 software engineering datasets, we find\nthat: 1) discretization noise affects the different performance measures of a\nclassifier differently for different datasets; 2) Though the interpretation of\nthe classifiers are impacted by the discretization noise on the whole, the top\n3 most important features are not affected by the discretization noise.\nTherefore, we suggest that practitioners and researchers use our framework to\nunderstand the impact of discretization noise on the performance of their built\nclassifiers and estimate the exact amount of discretization noise to be\ndiscarded from the dataset to avoid the negative impact of such noise.\n",
                "链接": "https://arxiv.org/abs/2202.06146"
            },
            {
                "文章ID": "117699",
                "标题": "Assessing the Impact of Noise on Quantum Neural Networks: An\n  Experimental Analysis",
                "作者": " Erik B. Terres Escudero,  Danel Arias Alamo,  Oier Mentxaka Gómez,  Pablo García Bringas",
                "发布日期": "2023-11-27",
                "摘要": "  In the race towards quantum computing, the potential benefits of quantum\nneural networks (QNNs) have become increasingly apparent. However, Noisy\nIntermediate-Scale Quantum (NISQ) processors are prone to errors, which poses a\nsignificant challenge for the execution of complex algorithms or quantum\nmachine learning. To ensure the quality and security of QNNs, it is crucial to\nexplore the impact of noise on their performance. This paper provides a\ncomprehensive analysis of the impact of noise on QNNs, examining the Mottonen\nstate preparation algorithm under various noise models and studying the\ndegradation of quantum states as they pass through multiple layers of QNNs.\nAdditionally, the paper evaluates the effect of noise on the performance of\npre-trained QNNs and highlights the challenges posed by noise models in quantum\ncomputing. The findings of this study have significant implications for the\ndevelopment of quantum software, emphasizing the importance of prioritizing\nstability and noise-correction measures when developing QNNs to ensure reliable\nand trustworthy results. This paper contributes to the growing body of\nliterature on quantum computing and quantum machine learning, providing new\ninsights into the impact of noise on QNNs and paving the way towards the\ndevelopment of more robust and efficient quantum algorithms.\n",
                "链接": "https://arxiv.org/abs/2311.14057"
            },
            {
                "文章ID": "106205",
                "标题": "Quantifying and mitigating the impact of label errors on model disparity\n  metrics",
                "作者": " Julius Adebayo,  Melissa Hall,  Bowen Yu,  Bobbie Chern",
                "发布日期": "2023-10-05",
                "摘要": "  Errors in labels obtained via human annotation adversely affect a model's\nperformance. Existing approaches propose ways to mitigate the effect of label\nerror on a model's downstream accuracy, yet little is known about its impact on\na model's disparity metrics. Here we study the effect of label error on a\nmodel's disparity metrics. We empirically characterize how varying levels of\nlabel error, in both training and test data, affect these disparity metrics. We\nfind that group calibration and other metrics are sensitive to train-time and\ntest-time label error -- particularly for minority groups. This disparate\neffect persists even for models trained with noise-aware algorithms. To\nmitigate the impact of training-time label error, we present an approach to\nestimate the influence of a training input's label on a model's group disparity\nmetric. We empirically assess the proposed approach on a variety of datasets\nand find significant improvement, compared to alternative approaches, in\nidentifying training inputs that improve a model's disparity metric. We\ncomplement the approach with an automatic relabel-and-finetune scheme that\nproduces updated models with, provably, improved group calibration error.\n",
                "链接": "https://arxiv.org/abs/2310.02533"
            },
            {
                "文章ID": "34617",
                "标题": "A Study on the Impact of Data Augmentation for Training Convolutional\n  Neural Networks in the Presence of Noisy Labels",
                "作者": " Emeson Santana,  Gustavo Carneiro,  Filipe R. Cordeiro",
                "发布日期": "2023-08-08",
                "摘要": "  Label noise is common in large real-world datasets, and its presence harms\nthe training process of deep neural networks. Although several works have\nfocused on the training strategies to address this problem, there are few\nstudies that evaluate the impact of data augmentation as a design choice for\ntraining deep neural networks. In this work, we analyse the model robustness\nwhen using different data augmentations and their improvement on the training\nwith the presence of noisy labels. We evaluate state-of-the-art and classical\ndata augmentation strategies with different levels of synthetic noise for the\ndatasets MNist, CIFAR-10, CIFAR-100, and the real-world dataset Clothing1M. We\nevaluate the methods using the accuracy metric. Results show that the\nappropriate selection of data augmentation can drastically improve the model\nrobustness to label noise, increasing up to 177.84% of relative best test\naccuracy compared to the baseline with no augmentation, and an increase of up\nto 6% in absolute value with the state-of-the-art DivideMix training strategy.\n",
                "链接": "https://arxiv.org/abs/2208.11176"
            },
            {
                "文章ID": "123805",
                "标题": "FedDiv: Collaborative Noise Filtering for Federated Learning with Noisy\n  Labels",
                "作者": " Jichang Li,  Guanbin Li,  Hui Cheng,  Zicheng Liao,  Yizhou Yu",
                "发布日期": "2023-12-21",
                "摘要": "  Federated learning with noisy labels (F-LNL) aims at seeking an optimal\nserver model via collaborative distributed learning by aggregating multiple\nclient models trained with local noisy or clean samples. On the basis of a\nfederated learning framework, recent advances primarily adopt label noise\nfiltering to separate clean samples from noisy ones on each client, thereby\nmitigating the negative impact of label noise. However, these prior methods do\nnot learn noise filters by exploiting knowledge across all clients, leading to\nsub-optimal and inferior noise filtering performance and thus damaging training\nstability. In this paper, we present FedDiv to tackle the challenges of F-LNL.\nSpecifically, we propose a global noise filter called Federated Noise Filter\nfor effectively identifying samples with noisy labels on every client, thereby\nraising stability during local training sessions. Without sacrificing data\nprivacy, this is achieved by modeling the global distribution of label noise\nacross all clients. Then, in an effort to make the global model achieve higher\nperformance, we introduce a Predictive Consistency based Sampler to identify\nmore credible local data for local model training, thus preventing noise\nmemorization and further boosting the training stability. Extensive experiments\non CIFAR-10, CIFAR-100, and Clothing1M demonstrate that \\texttt{FedDiv}\nachieves superior performance over state-of-the-art F-LNL methods under\ndifferent label noise settings for both IID and non-IID data partitions. Source\ncode is publicly available at https://github.com/lijichang/FLNL-FedDiv.\n",
                "链接": "https://arxiv.org/abs/2312.12263"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下文本检索任务上，是否有关于大模型在语义坍缩问题上的研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "87459",
                "标题": "Long-range Language Modeling with Self-retrieval",
                "作者": " Ohad Rubin,  Jonathan Berant",
                "发布日期": "2023-06-26",
                "摘要": "  Retrieval-augmented language models (LMs) have received much attention\nrecently. However, typically the retriever is not trained jointly as a native\ncomponent of the LM, but added to an already-pretrained LM, which limits the\nability of the LM and the retriever to adapt to one another. In this work, we\npropose the Retrieval-Pretrained Transformer (RPT), an architecture and\ntraining procedure for jointly training a retrieval-augmented LM from scratch\nfor the task of modeling long texts. Given a recently generated text chunk in a\nlong document, the LM computes query representations, which are then used to\nretrieve earlier chunks in the document, located potentially tens of thousands\nof tokens before. Information from retrieved chunks is fused into the LM\nrepresentations to predict the next target chunk. We train the retriever\ncomponent with a semantic objective, where the goal is to retrieve chunks that\nincrease the probability of the next chunk, according to a reference LM. We\nevaluate RPT on four long-range language modeling tasks, spanning books, code,\nand mathematical writing, and demonstrate that RPT improves retrieval quality\nand subsequently perplexity across the board compared to strong baselines.\n",
                "链接": "https://arxiv.org/abs/2306.13421"
            },
            {
                "文章ID": "37207",
                "标题": "Learning to Evaluate Performance of Multi-modal Semantic Localization",
                "作者": " Zhiqiang Yuan,  Wenkai Zhang,  Chongyang Li,  Zhaoying Pan,  Yongqiang Mao,  Jialiang Chen,  Shouke Li,  Hongqi Wang,  Xian Sun",
                "发布日期": "2022-09-20",
                "摘要": "  Semantic localization (SeLo) refers to the task of obtaining the most\nrelevant locations in large-scale remote sensing (RS) images using semantic\ninformation such as text. As an emerging task based on cross-modal retrieval,\nSeLo achieves semantic-level retrieval with only caption-level annotation,\nwhich demonstrates its great potential in unifying downstream tasks. Although\nSeLo has been carried out successively, but there is currently no work has\nsystematically explores and analyzes this urgent direction. In this paper, we\nthoroughly study this field and provide a complete benchmark in terms of\nmetrics and testdata to advance the SeLo task. Firstly, based on the\ncharacteristics of this task, we propose multiple discriminative evaluation\nmetrics to quantify the performance of the SeLo task. The devised significant\narea proportion, attention shift distance, and discrete attention distance are\nutilized to evaluate the generated SeLo map from pixel-level and region-level.\nNext, to provide standard evaluation data for the SeLo task, we contribute a\ndiverse, multi-semantic, multi-objective Semantic Localization Testset\n(AIR-SLT). AIR-SLT consists of 22 large-scale RS images and 59 test cases with\ndifferent semantics, which aims to provide a comprehensive evaluations for\nretrieval models. Finally, we analyze the SeLo performance of RS cross-modal\nretrieval models in detail, explore the impact of different variables on this\ntask, and provide a complete benchmark for the SeLo task. We have also\nestablished a new paradigm for RS referring expression comprehension, and\ndemonstrated the great advantage of SeLo in semantics through combining it with\ntasks such as detection and road extraction. The proposed evaluation metrics,\nsemantic localization testsets, and corresponding scripts have been open to\naccess at github.com/xiaoyuan1996/SemanticLocalizationMetrics .\n",
                "链接": "https://arxiv.org/abs/2209.06515"
            },
            {
                "文章ID": "73561",
                "标题": "Rethinking Benchmarks for Cross-modal Image-text Retrieval",
                "作者": " Weijing Chen,  Linli Yao,  Qin Jin",
                "发布日期": "2023-04-24",
                "摘要": "  Image-text retrieval, as a fundamental and important branch of information\nretrieval, has attracted extensive research attentions. The main challenge of\nthis task is cross-modal semantic understanding and matching. Some recent works\nfocus more on fine-grained cross-modal semantic matching. With the prevalence\nof large scale multimodal pretraining models, several state-of-the-art models\n(e.g. X-VLM) have achieved near-perfect performance on widely-used image-text\nretrieval benchmarks, i.e. MSCOCO-Test-5K and Flickr30K-Test-1K. In this paper,\nwe review the two common benchmarks and observe that they are insufficient to\nassess the true capability of models on fine-grained cross-modal semantic\nmatching. The reason is that a large amount of images and texts in the\nbenchmarks are coarse-grained. Based on the observation, we renovate the\ncoarse-grained images and texts in the old benchmarks and establish the\nimproved benchmarks called MSCOCO-FG and Flickr30K-FG. Specifically, on the\nimage side, we enlarge the original image pool by adopting more similar images.\nOn the text side, we propose a novel semi-automatic renovation approach to\nrefine coarse-grained sentences into finer-grained ones with little human\neffort. Furthermore, we evaluate representative image-text retrieval models on\nour new benchmarks to demonstrate the effectiveness of our method. We also\nanalyze the capability of models on fine-grained semantic comprehension through\nextensive experiments. The results show that even the state-of-the-art models\nhave much room for improvement in fine-grained semantic understanding,\nespecially in distinguishing attributes of close objects in images. Our code\nand improved benchmark datasets are publicly available at:\nhttps://github.com/cwj1412/MSCOCO-Flikcr30K_FG, which we hope will inspire\nfurther in-depth research on cross-modal retrieval.\n",
                "链接": "https://arxiv.org/abs/2304.10824"
            },
            {
                "文章ID": "66770",
                "标题": "UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation",
                "作者": " Daixuan Cheng,  Shaohan Huang,  Junyu Bi,  Yuefeng Zhan,  Jianfeng Liu,  Yujing Wang,  Hao Sun,  Furu Wei,  Denvy Deng,  Qi Zhang",
                "发布日期": "2023-12-19",
                "摘要": "  Large Language Models (LLMs) are popular for their impressive abilities, but\nthe need for model-specific fine-tuning or task-specific prompt engineering can\nhinder their generalization. We propose UPRISE (Universal Prompt Retrieval for\nImproving zero-Shot Evaluation), which tunes a lightweight and versatile\nretriever that automatically retrieves prompts for a given zero-shot task\ninput. Specifically, we demonstrate universality in a cross-task and\ncross-model scenario: the retriever is tuned on a diverse set of tasks, but\ntested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for\ntuning the retriever, but test the retriever on different LLMs of much larger\nscales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that\nUPRISE mitigates the hallucination problem in our experiments with ChatGPT,\nsuggesting its potential to improve even the strongest LLMs. Our model and code\nare available at https://github.com/microsoft/LMOps.\n",
                "链接": "https://arxiv.org/abs/2303.08518"
            },
            {
                "文章ID": "82719",
                "标题": "End-to-end Knowledge Retrieval with Multi-modal Queries",
                "作者": " Man Luo,  Zhiyuan Fang,  Tejas Gokhale,  Yezhou Yang,  Chitta Baral",
                "发布日期": "2023-06-02",
                "摘要": "  We investigate knowledge retrieval with multi-modal queries, i.e. queries\ncontaining information split across image and text inputs, a challenging task\nthat differs from previous work on cross-modal retrieval. We curate a new\ndataset called ReMuQ for benchmarking progress on this task. ReMuQ requires a\nsystem to retrieve knowledge from a large corpus by integrating contents from\nboth text and image queries. We introduce a retriever model ``ReViz'' that can\ndirectly process input text and images to retrieve relevant knowledge in an\nend-to-end fashion without being dependent on intermediate modules such as\nobject detectors or caption generators. We introduce a new pretraining task\nthat is effective for learning knowledge retrieval with multimodal queries and\nalso improves performance on downstream tasks. We demonstrate superior\nperformance in retrieval on two datasets (ReMuQ and OK-VQA) under zero-shot\nsettings as well as further improvements when finetuned on these datasets.\n",
                "链接": "https://arxiv.org/abs/2306.00424"
            },
            {
                "文章ID": "75906",
                "标题": "A Large Cross-Modal Video Retrieval Dataset with Reading Comprehension",
                "作者": " Weijia Wu,  Yuzhong Zhao,  Zhuang Li,  Jiahong Li,  Hong Zhou,  Mike Zheng Shou,  Xiang Bai",
                "发布日期": "2023-05-08",
                "摘要": "  Most existing cross-modal language-to-video retrieval (VR) research focuses\non single-modal input from video, i.e., visual representation, while the text\nis omnipresent in human environments and frequently critical to understand\nvideo. To study how to retrieve video with both modal inputs, i.e., visual and\ntext semantic representations, we first introduce a large-scale and cross-modal\nVideo Retrieval dataset with text reading comprehension, TextVR, which contains\n42.2k sentence queries for 10.5k videos of 8 scenario domains, i.e., Street\nView (indoor), Street View (outdoor), Games, Sports, Driving, Activity, TV\nShow, and Cooking. The proposed TextVR requires one unified cross-modal model\nto recognize and comprehend texts, relate them to the visual context, and\ndecide what text semantic information is vital for the video retrieval task.\nBesides, we present a detailed analysis of TextVR compared to the existing\ndatasets and design a novel multimodal video retrieval baseline for the\ntext-based video retrieval task. The dataset analysis and extensive experiments\nshow that our TextVR benchmark provides many new technical challenges and\ninsights from previous datasets for the video-and-language community. The\nproject website and GitHub repo can be found at\nhttps://sites.google.com/view/loveucvpr23/guest-track and\nhttps://github.com/callsys/TextVR, respectively.\n",
                "链接": "https://arxiv.org/abs/2305.03347"
            },
            {
                "文章ID": "76675",
                "标题": "Vision-Language Models in Remote Sensing: Current Progress and Future\n  Trends",
                "作者": " Congcong Wen,  Yuan Hu,  Xiang Li,  Zhenghang Yuan,  Xiao Xiang Zhu",
                "发布日期": "2023-05-11",
                "摘要": "  The remarkable achievements of ChatGPT and GPT-4 have sparked a wave of\ninterest and research in the field of large language models for Artificial\nGeneral Intelligence (AGI). These models provide us with intelligent solutions\nthat are more similar to human thinking, enabling us to use general artificial\nintelligence to solve problems in various applications. However, in the field\nof remote sensing, the scientific literature on the implementation of AGI\nremains relatively scant. Existing AI-related research primarily focuses on\nvisual understanding tasks while neglecting the semantic understanding of the\nobjects and their relationships. This is where vision-language models excel, as\nthey enable reasoning about images and their associated textual descriptions,\nallowing for a deeper understanding of the underlying semantics.\nVision-language models can go beyond recognizing the objects in an image and\ncan infer the relationships between them, as well as generate natural language\ndescriptions of the image. This makes them better suited for tasks that require\nboth visual and textual understanding, such as image captioning, text-based\nimage retrieval, and visual question answering. This paper provides a\ncomprehensive review of the research on vision-language models in remote\nsensing, summarizing the latest progress, highlighting the current challenges,\nand identifying potential research opportunities. Specifically, we review the\napplication of vision-language models in several mainstream remote sensing\ntasks, including image captioning, text-based image generation, text-based\nimage retrieval, visual question answering, scene classification, semantic\nsegmentation, and object detection. For each task, we briefly describe the task\nbackground and review some representative works. Finally, we summarize the\nlimitations of existing work and provide some possible directions for future\ndevelopment.\n",
                "链接": "https://arxiv.org/abs/2305.05726"
            },
            {
                "文章ID": "82866",
                "标题": "UniDiff: Advancing Vision-Language Models with Generative and\n  Discriminative Learning",
                "作者": " Xiao Dong,  Runhui Huang,  Xiaoyong Wei,  Zequn Jie,  Jianxing Yu,  Jian Yin,  Xiaodan Liang",
                "发布日期": "2023-06-02",
                "摘要": "  Recent advances in vision-language pre-training have enabled machines to\nperform better in multimodal object discrimination (e.g., image-text semantic\nalignment) and image synthesis (e.g., text-to-image generation). On the other\nhand, fine-tuning pre-trained models with discriminative or generative\ncapabilities such as CLIP and Stable Diffusion on domain-specific datasets has\nshown to be effective in various tasks by adapting to specific domains.\nHowever, few studies have explored the possibility of learning both\ndiscriminative and generative capabilities and leveraging their synergistic\neffects to create a powerful and personalized multimodal model during\nfine-tuning. This paper presents UniDiff, a unified multi-modal model that\nintegrates image-text contrastive learning (ITC), text-conditioned image\nsynthesis learning (IS), and reciprocal semantic consistency modeling (RSC).\nUniDiff effectively learns aligned semantics and mitigates the issue of\nsemantic collapse during fine-tuning on small datasets by leveraging RSC on\nvisual features from CLIP and diffusion models, without altering the\npre-trained model's basic architecture. UniDiff demonstrates versatility in\nboth multi-modal understanding and generative tasks. Experimental results on\nthree datasets (Fashion-man, Fashion-woman, and E-commercial Product) showcase\nsubstantial enhancements in vision-language retrieval and text-to-image\ngeneration, illustrating the advantages of combining discriminative and\ngenerative fine-tuning. The proposed UniDiff model establishes a robust\npipeline for personalized modeling and serves as a benchmark for future\ncomparisons in the field.\n",
                "链接": "https://arxiv.org/abs/2306.00813"
            },
            {
                "文章ID": "70726",
                "标题": "AToMiC: An Image/Text Retrieval Test Collection to Support Multimedia\n  Content Creation",
                "作者": " Jheng-Hong Yang,  Carlos Lassance,  Rafael Sampaio de Rezende,  Krishna Srinivasan,  Miriam Redi,  Stéphane Clinchant,  Jimmy Lin",
                "发布日期": "2023-04-05",
                "摘要": "  This paper presents the AToMiC (Authoring Tools for Multimedia Content)\ndataset, designed to advance research in image/text cross-modal retrieval.\nWhile vision-language pretrained transformers have led to significant\nimprovements in retrieval effectiveness, existing research has relied on\nimage-caption datasets that feature only simplistic image-text relationships\nand underspecified user models of retrieval tasks. To address the gap between\nthese oversimplified settings and real-world applications for multimedia\ncontent creation, we introduce a new approach for building retrieval test\ncollections. We leverage hierarchical structures and diverse domains of texts,\nstyles, and types of images, as well as large-scale image-document associations\nembedded in Wikipedia. We formulate two tasks based on a realistic user model\nand validate our dataset through retrieval experiments using baseline models.\nAToMiC offers a testbed for scalable, diverse, and reproducible multimedia\nretrieval research. Finally, the dataset provides the basis for a dedicated\ntrack at the 2023 Text Retrieval Conference (TREC), and is publicly available\nat https://github.com/TREC-AToMiC/AToMiC.\n",
                "链接": "https://arxiv.org/abs/2304.01961"
            },
            {
                "文章ID": "88843",
                "标题": "Meta-training with Demonstration Retrieval for Efficient Few-shot\n  Learning",
                "作者": " Aaron Mueller,  Kanika Narang,  Lambert Mathias,  Qifan Wang,  Hamed Firooz",
                "发布日期": "2023-07-04",
                "摘要": "  Large language models show impressive results on few-shot NLP tasks. However,\nthese models are memory and computation-intensive. Meta-training allows one to\nleverage smaller models for few-shot generalization in a domain-general and\ntask-agnostic manner; however, these methods alone results in models that may\nnot have sufficient parameterization or knowledge to adapt quickly to a large\nvariety of tasks. To overcome this issue, we propose meta-training with\ndemonstration retrieval, where we use a dense passage retriever to retrieve\nsemantically similar labeled demonstrations to each example for more varied\nsupervision. By separating external knowledge from model parameters, we can use\nmeta-training to train parameter-efficient models that generalize well on a\nlarger variety of tasks. We construct a meta-training set from UnifiedQA and\nCrossFit, and propose a demonstration bank based on UnifiedQA tasks. To our\nknowledge, our work is the first to combine retrieval with meta-training, to\nuse DPR models to retrieve demonstrations, and to leverage demonstrations from\nmany tasks simultaneously, rather than randomly sampling demonstrations from\nthe training set of the target task. Our approach outperforms a variety of\ntargeted parameter-efficient and retrieval-augmented few-shot methods on QA,\nNLI, and text classification tasks (including SQuAD, QNLI, and TREC). Our\napproach can be meta-trained and fine-tuned quickly on a single GPU.\n",
                "链接": "https://arxiv.org/abs/2307.00119"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找对机器翻译数据集质量进行评估的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "83169",
                "标题": "Evaluating Machine Translation Quality with Conformal Predictive\n  Distributions",
                "作者": " Patrizio Giovannotti",
                "发布日期": "2023-06-05",
                "摘要": "  This paper presents a new approach for assessing uncertainty in machine\ntranslation by simultaneously evaluating translation quality and providing a\nreliable confidence score. Our approach utilizes conformal predictive\ndistributions to produce prediction intervals with guaranteed coverage, meaning\nthat for any given significance level $\\epsilon$, we can expect the true\nquality score of a translation to fall out of the interval at a rate of\n$1-\\epsilon$. In this paper, we demonstrate how our method outperforms a\nsimple, but effective baseline on six different language pairs in terms of\ncoverage and sharpness. Furthermore, we validate that our approach requires the\ndata exchangeability assumption to hold for optimal performance.\n",
                "链接": "https://arxiv.org/abs/2306.01549"
            },
            {
                "文章ID": "17492",
                "标题": "Quality-Aware Decoding for Neural Machine Translation",
                "作者": " Patrick Fernandes,  António Farinhas,  Ricardo Rei,  José G. C. de Souza,  Perez Ogayo,  Graham Neubig,  André F. T. Martins",
                "发布日期": "2022-05-03",
                "摘要": "  Despite the progress in machine translation quality estimation and evaluation\nin the last years, decoding in neural machine translation (NMT) is mostly\noblivious to this and centers around finding the most probable translation\naccording to the model (MAP decoding), approximated with beam search. In this\npaper, we bring together these two lines of research and propose quality-aware\ndecoding for NMT, by leveraging recent breakthroughs in reference-free and\nreference-based MT evaluation through various inference methods like $N$-best\nreranking and minimum Bayes risk decoding. We perform an extensive comparison\nof various possible candidate generation and ranking methods across four\ndatasets and two model classes and find that quality-aware decoding\nconsistently outperforms MAP-based decoding according both to state-of-the-art\nautomatic metrics (COMET and BLEURT) and to human assessments. Our code is\navailable at https://github.com/deep-spin/qaware-decode.\n",
                "链接": "https://arxiv.org/abs/2205.00978"
            },
            {
                "文章ID": "62353",
                "标题": "Exploring the Potential of Machine Translation for Generating Named\n  Entity Datasets: A Case Study between Persian and English",
                "作者": " Amir Sartipi,  Afsaneh Fatemi",
                "发布日期": "2023-06-07",
                "摘要": "  This study focuses on the generation of Persian named entity datasets through\nthe application of machine translation on English datasets. The generated\ndatasets were evaluated by experimenting with one monolingual and one\nmultilingual transformer model. Notably, the CoNLL 2003 dataset has achieved\nthe highest F1 score of 85.11%. In contrast, the WNUT 2017 dataset yielded the\nlowest F1 score of 40.02%. The results of this study highlight the potential of\nmachine translation in creating high-quality named entity recognition datasets\nfor low-resource languages like Persian. The study compares the performance of\nthese generated datasets with English named entity recognition systems and\nprovides insights into the effectiveness of machine translation for this task.\nAdditionally, this approach could be used to augment data in low-resource\nlanguage or create noisy data to make named entity systems more robust and\nimprove them.\n",
                "链接": "https://arxiv.org/abs/2302.09611"
            },
            {
                "文章ID": "77168",
                "标题": "Improving the Quality of Neural Machine Translation Through Proper\n  Translation of Name Entities",
                "作者": " Radhika Sharma,  Pragya Katyayan,  Nisheeth Joshi",
                "发布日期": "2023-05-15",
                "摘要": "  In this paper, we have shown a method of improving the quality of neural\nmachine translation by translating/transliterating name entities as a\npreprocessing step. Through experiments we have shown the performance gain of\nour system. For evaluation we considered three types of name entities viz\nperson names, location names and organization names. The system was able to\ncorrectly translate mostly all the name entities. For person names the accuracy\nwas 99.86%, for location names the accuracy was 99.63% and for organization\nnames the accuracy was 99.05%. Overall, the accuracy of the system was 99.52%\n",
                "链接": "https://arxiv.org/abs/2305.07360"
            },
            {
                "文章ID": "59415",
                "标题": "An Evaluation of Persian-English Machine Translation Datasets with\n  Transformers",
                "作者": " Amir Sartipi,  Meghdad Dehghan,  Afsaneh Fatemi",
                "发布日期": "2023-02-02",
                "摘要": "  Nowadays, many researchers are focusing their attention on the subject of\nmachine translation (MT). However, Persian machine translation has remained\nunexplored despite a vast amount of research being conducted in languages with\nhigh resources, such as English. Moreover, while a substantial amount of\nresearch has been undertaken in statistical machine translation for some\ndatasets in Persian, there is currently no standard baseline for\ntransformer-based text2text models on each corpus. This study collected and\nanalysed the most popular and valuable parallel corpora, which were used for\nPersian-English translation. Furthermore, we fine-tuned and evaluated two\nstate-of-the-art attention-based seq2seq models on each dataset separately (48\nresults). We hope this paper will assist researchers in comparing their Persian\nto English and vice versa machine translation results to a standard baseline.\n",
                "链接": "https://arxiv.org/abs/2302.00321"
            },
            {
                "文章ID": "50351",
                "标题": "Competency-Aware Neural Machine Translation: Can Machine Translation\n  Know its Own Translation Quality?",
                "作者": " Pei Zhang,  Baosong Yang,  Haoran Wei,  Dayiheng Liu,  Kai Fan,  Luo Si,  Jun Xie",
                "发布日期": "2022-11-28",
                "摘要": "  Neural machine translation (NMT) is often criticized for failures that happen\nwithout awareness. The lack of competency awareness makes NMT untrustworthy.\nThis is in sharp contrast to human translators who give feedback or conduct\nfurther investigations whenever they are in doubt about predictions. To fill\nthis gap, we propose a novel competency-aware NMT by extending conventional NMT\nwith a self-estimator, offering abilities to translate a source sentence and\nestimate its competency. The self-estimator encodes the information of the\ndecoding procedure and then examines whether it can reconstruct the original\nsemantics of the source sentence. Experimental results on four translation\ntasks demonstrate that the proposed method not only carries out translation\ntasks intact but also delivers outstanding performance on quality estimation.\nWithout depending on any reference or annotated data typically required by\nstate-of-the-art metric and quality estimation methods, our model yields an\neven higher correlation with human quality judgments than a variety of\naforementioned methods, such as BLEURT, COMET, and BERTScore. Quantitative and\nqualitative analyses show better robustness of competency awareness in our\nmodel.\n",
                "链接": "https://arxiv.org/abs/2211.13865"
            },
            {
                "文章ID": "19807",
                "标题": "PreQuEL: Quality Estimation of Machine Translation Outputs in Advance",
                "作者": " Shachar Don-Yehiya,  Leshem Choshen,  Omri Abend",
                "发布日期": "2022-12-06",
                "摘要": "  We present the task of PreQuEL, Pre-(Quality-Estimation) Learning. A PreQuEL\nsystem predicts how well a given sentence will be translated, without recourse\nto the actual translation, thus eschewing unnecessary resource allocation when\ntranslation quality is bound to be low. PreQuEL can be defined relative to a\ngiven MT system (e.g., some industry service) or generally relative to the\nstate-of-the-art. From a theoretical perspective, PreQuEL places the focus on\nthe source text, tracing properties, possibly linguistic features, that make a\nsentence harder to machine translate.\n  We develop a baseline model for the task and analyze its performance. We also\ndevelop a data augmentation method (from parallel corpora), that improves\nresults substantially. We show that this augmentation method can improve the\nperformance of the Quality-Estimation task as well. We investigate the\nproperties of the input text that our model is sensitive to, by testing it on\nchallenge sets and different languages. We conclude that it is aware of\nsyntactic and semantic distinctions, and correlates and even over-emphasizes\nthe importance of standard NLP features.\n",
                "链接": "https://arxiv.org/abs/2205.09178"
            },
            {
                "文章ID": "87010",
                "标题": "Evaluation of Chinese-English Machine Translation of Emotion-Loaded\n  Microblog Texts: A Human Annotated Dataset for the Quality Assessment of\n  Emotion Translation",
                "作者": " Shenbin Qian,  Constantin Orasan,  Felix do Carmo,  Qiuliang Li,  Diptesh Kanojia",
                "发布日期": "2023-06-22",
                "摘要": "  In this paper, we focus on how current Machine Translation (MT) tools perform\non the translation of emotion-loaded texts by evaluating outputs from Google\nTranslate according to a framework proposed in this paper. We propose this\nevaluation framework based on the Multidimensional Quality Metrics (MQM) and\nperform a detailed error analysis of the MT outputs. From our analysis, we\nobserve that about 50% of the MT outputs fail to preserve the original emotion.\nAfter further analysis of the errors, we find that emotion carrying words and\nlinguistic phenomena such as polysemous words, negation, abbreviation etc., are\ncommon causes for these translation errors.\n",
                "链接": "https://arxiv.org/abs/2306.11900"
            },
            {
                "文章ID": "110184",
                "标题": "Towards General Error Diagnosis via Behavioral Testing in Machine\n  Translation",
                "作者": " Junjie Wu,  Lemao Liu,  Dit-Yan Yeung",
                "发布日期": "2023-10-23",
                "摘要": "  Behavioral testing offers a crucial means of diagnosing linguistic errors and\nassessing capabilities of NLP models. However, applying behavioral testing to\nmachine translation (MT) systems is challenging as it generally requires human\nefforts to craft references for evaluating the translation quality of such\nsystems on newly generated test cases. Existing works in behavioral testing of\nMT systems circumvent this by evaluating translation quality without\nreferences, but this restricts diagnosis to specific types of errors, such as\nincorrect translation of single numeric or currency words. In order to diagnose\ngeneral errors, this paper proposes a new Bilingual Translation Pair Generation\nbased Behavior Testing (BTPGBT) framework for conducting behavioral testing of\nMT systems. The core idea of BTPGBT is to employ a novel bilingual translation\npair generation (BTPG) approach that automates the construction of high-quality\ntest cases and their pseudoreferences. Experimental results on various MT\nsystems demonstrate that BTPGBT could provide comprehensive and accurate\nbehavioral testing results for general error diagnosis, which further leads to\nseveral insightful findings. Our code and data are available at https:\n//github.com/wujunjie1998/BTPGBT.\n",
                "链接": "https://arxiv.org/abs/2310.13362"
            },
            {
                "文章ID": "39818",
                "标题": "QUAK: A Synthetic Quality Estimation Dataset for Korean-English Neural\n  Machine Translation",
                "作者": " Sugyeong Eo,  Chanjun Park,  Hyeonseok Moon,  Jaehyung Seo,  Gyeongmin Kim,  Jungseob Lee,  Heuiseok Lim",
                "发布日期": "2022-11-30",
                "摘要": "  With the recent advance in neural machine translation demonstrating its\nimportance, research on quality estimation (QE) has been steadily progressing.\nQE aims to automatically predict the quality of machine translation (MT) output\nwithout reference sentences. Despite its high utility in the real world, there\nremain several limitations concerning manual QE data creation: inevitably\nincurred non-trivial costs due to the need for translation experts, and issues\nwith data scaling and language expansion. To tackle these limitations, we\npresent QUAK, a Korean-English synthetic QE dataset generated in a fully\nautomatic manner. This consists of three sub-QUAK datasets QUAK-M, QUAK-P, and\nQUAK-H, produced through three strategies that are relatively free from\nlanguage constraints. Since each strategy requires no human effort, which\nfacilitates scalability, we scale our data up to 1.58M for QUAK-P, H and 6.58M\nfor QUAK-M. As an experiment, we quantitatively analyze word-level QE results\nin various ways while performing statistical analysis. Moreover, we show that\ndatasets scaled in an efficient way also contribute to performance improvements\nby observing meaningful performance gains in QUAK-M, P when adding data up to\n1.58M.\n",
                "链接": "https://arxiv.org/abs/2209.15285"
            }
        ]
    },
    {
        "question": {
            "question": "查找大语言模型相关的分析类型的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "70693",
                "标题": "Summary of ChatGPT-Related Research and Perspective Towards the Future\n  of Large Language Models",
                "作者": " Yiheng Liu,  Tianle Han,  Siyuan Ma,  Jiayue Zhang,  Yuanyuan Yang,  Jiaming Tian,  Hao He,  Antong Li,  Mengshen He,  Zhengliang Liu,  Zihao Wu,  Lin Zhao,  Dajiang Zhu,  Xiang Li,  Ning Qiang,  Dingang Shen,  Tianming Liu,  Bao Ge",
                "发布日期": "2023-08-25",
                "摘要": "  This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and\nGPT-4) research, state-of-the-art large language models (LLM) from the GPT\nseries, and their prospective applications across diverse domains. Indeed, key\ninnovations such as large-scale pre-training that captures knowledge across the\nentire world wide web, instruction fine-tuning and Reinforcement Learning from\nHuman Feedback (RLHF) have played significant roles in enhancing LLMs'\nadaptability and performance. We performed an in-depth analysis of 194 relevant\npapers on arXiv, encompassing trend analysis, word cloud representation, and\ndistribution analysis across various application domains. The findings reveal a\nsignificant and increasing interest in ChatGPT-related research, predominantly\ncentered on direct natural language processing applications, while also\ndemonstrating considerable potential in areas ranging from education and\nhistory to mathematics, medicine, and physics. This study endeavors to furnish\ninsights into ChatGPT's capabilities, potential implications, ethical concerns,\nand offer direction for future advancements in this field.\n",
                "链接": "https://arxiv.org/abs/2304.01852"
            },
            {
                "文章ID": "99611",
                "标题": "Using Large Language Models to Automate Category and Trend Analysis of\n  Scientific Articles: An Application in Ophthalmology",
                "作者": " Hina Raja,  Asim Munawar,  Mohammad Delsoz,  Mohammad Elahi,  Yeganeh Madadi,  Amr Hassan,  Hashem Abu Serhan,  Onur Inam,  Luis Hermandez,  Sang Tran,  Wuqas Munir,  Alaa Abd-Alrazaq,  Hao Chen,   SiamakYousefi",
                "发布日期": "2023-09-01",
                "摘要": "  Purpose: In this paper, we present an automated method for article\nclassification, leveraging the power of Large Language Models (LLM). The\nprimary focus is on the field of ophthalmology, but the model is extendable to\nother fields. Methods: We have developed a model based on Natural Language\nProcessing (NLP) techniques, including advanced LLMs, to process and analyze\nthe textual content of scientific papers. Specifically, we have employed\nzero-shot learning (ZSL) LLM models and compared against Bidirectional and\nAuto-Regressive Transformers (BART) and its variants, and Bidirectional Encoder\nRepresentations from Transformers (BERT), and its variant such as distilBERT,\nSciBERT, PubmedBERT, BioBERT. Results: The classification results demonstrate\nthe effectiveness of LLMs in categorizing large number of ophthalmology papers\nwithout human intervention. Results: To evalute the LLMs, we compiled a dataset\n(RenD) of 1000 ocular disease-related articles, which were expertly annotated\nby a panel of six specialists into 15 distinct categories. The model achieved\nmean accuracy of 0.86 and mean F1 of 0.85 based on the RenD dataset.\nConclusion: The proposed framework achieves notable improvements in both\naccuracy and efficiency. Its application in the domain of ophthalmology\nshowcases its potential for knowledge organization and retrieval in other\ndomains too. We performed trend analysis that enables the researchers and\nclinicians to easily categorize and retrieve relevant papers, saving time and\neffort in literature review and information gathering as well as identification\nof emerging scientific trends within different disciplines. Moreover, the\nextendibility of the model to other scientific fields broadens its impact in\nfacilitating research and trend analysis across diverse disciplines.\n",
                "链接": "https://arxiv.org/abs/2308.16688"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "104308",
                "标题": "People's Perceptions Toward Bias and Related Concepts in Large Language\n  Models: A Systematic Review",
                "作者": " Lu Wang,  Max Song,  Rezvaneh Rezapour,  Bum Chul Kwon,  Jina Huh-Yoo",
                "发布日期": "2023-09-27",
                "摘要": "  Large language models (LLMs) have brought breakthroughs in tasks including\ntranslation, summarization, information retrieval, and language generation,\ngaining growing interest in the CHI community. Meanwhile, the literature shows\nresearchers' controversial perceptions about the efficacy, ethics, and\nintellectual abilities of LLMs. However, we do not know how lay people perceive\nLLMs that are pervasive in everyday tools, specifically regarding their\nexperience with LLMs around bias, stereotypes, social norms, or safety. In this\nstudy, we conducted a systematic review to understand what empirical insights\npapers have gathered about people's perceptions toward LLMs. From a total of\n231 retrieved papers, we full-text reviewed 15 papers that recruited human\nevaluators to assess their experiences with LLMs. We report different biases\nand related concepts investigated by these studies, four broader LLM\napplication areas, the evaluators' perceptions toward LLMs' performances\nincluding advantages, biases, and conflicting perceptions, factors influencing\nthese perceptions, and concerns about LLM applications.\n",
                "链接": "https://arxiv.org/abs/2309.14504"
            },
            {
                "文章ID": "71870",
                "标题": "Galactic ChitChat: Using Large Language Models to Converse with\n  Astronomy Literature",
                "作者": " Ioana Ciucă,  Yuan-Sen Ting",
                "发布日期": "2023-09-13",
                "摘要": "  We demonstrate the potential of the state-of-the-art OpenAI GPT-4 large\nlanguage model to engage in meaningful interactions with Astronomy papers using\nin-context prompting. To optimize for efficiency, we employ a distillation\ntechnique that effectively reduces the size of the original input paper by\n50\\%, while maintaining the paragraph structure and overall semantic integrity.\nWe then explore the model's responses using a multi-document context (ten\ndistilled documents). Our findings indicate that GPT-4 excels in the\nmulti-document domain, providing detailed answers contextualized within the\nframework of related research findings. Our results showcase the potential of\nlarge language models for the astronomical community, offering a promising\navenue for further exploration, particularly the possibility of utilizing the\nmodels for hypothesis generation.\n",
                "链接": "https://arxiv.org/abs/2304.05406"
            },
            {
                "文章ID": "39463",
                "标题": "Automatic Analysis of Available Source Code of Top Artificial\n  Intelligence Conference Papers",
                "作者": " Jialiang Lin,  Yingmin Wang,  Yao Yu,  Yu Zhou,  Yidong Chen,  Xiaodong Shi",
                "发布日期": "2022-09-29",
                "摘要": "  Source code is essential for researchers to reproduce the methods and\nreplicate the results of artificial intelligence (AI) papers. Some\norganizations and researchers manually collect AI papers with available source\ncode to contribute to the AI community. However, manual collection is a\nlabor-intensive and time-consuming task. To address this issue, we propose a\nmethod to automatically identify papers with available source code and extract\ntheir source code repository URLs. With this method, we find that 20.5% of\nregular papers of 10 top AI conferences published from 2010 to 2019 are\nidentified as papers with available source code and that 8.1% of these source\ncode repositories are no longer accessible. We also create the XMU NLP Lab\nREADME Dataset, the largest dataset of labeled README files for source code\ndocument research. Through this dataset, we have discovered that quite a few\nREADME files have no installation instructions or usage tutorials provided.\nFurther, a large-scale comprehensive statistical analysis is made for a general\npicture of the source code of AI conference papers. The proposed solution can\nalso go beyond AI conference papers to analyze other scientific papers from\nboth journals and conferences to shed light on more domains.\n",
                "链接": "https://arxiv.org/abs/2209.14155"
            },
            {
                "文章ID": "95587",
                "标题": "NLLG Quarterly arXiv Report 06/23: What are the most influential current\n  AI Papers?",
                "作者": " Steffen Eger,  Christoph Leiter,  Jonas Belouadi,  Ran Zhang,  Aida Kostikova,  Daniil Larionov,  Yanran Chen,  Vivian Fresen",
                "发布日期": "2023-08-15",
                "摘要": "  The rapid growth of information in the field of Generative Artificial\nIntelligence (AI), particularly in the subfields of Natural Language Processing\n(NLP) and Machine Learning (ML), presents a significant challenge for\nresearchers and practitioners to keep pace with the latest developments. To\naddress the problem of information overload, this report by the Natural\nLanguage Learning Group at Bielefeld University focuses on identifying the most\npopular papers on arXiv, with a specific emphasis on NLP and ML. The objective\nis to offer a quick guide to the most relevant and widely discussed research,\naiding both newcomers and established researchers in staying abreast of current\ntrends. In particular, we compile a list of the 40 most popular papers based on\nnormalized citation counts from the first half of 2023. We observe the\ndominance of papers related to Large Language Models (LLMs) and specifically\nChatGPT during the first half of 2023, with the latter showing signs of\ndeclining popularity more recently, however. Further, NLP related papers are\nthe most influential (around 60\\% of top papers) even though there are twice as\nmany ML related papers in our data. Core issues investigated in the most\nheavily cited papers are: LLM efficiency, evaluation techniques, ethical\nconsiderations, embodied agents, and problem-solving with LLMs. Additionally,\nwe examine the characteristics of top papers in comparison to others outside\nthe top-40 list (noticing the top paper's focus on LLM related issues and\nhigher number of co-authors) and analyze the citation distributions in our\ndataset, among others.\n",
                "链接": "https://arxiv.org/abs/2308.04889"
            },
            {
                "文章ID": "106592",
                "标题": "Comparing Time-Series Analysis Approaches Utilized in Research Papers to\n  Forecast COVID-19 Cases in Africa: A Literature Review",
                "作者": " Ali Ebadi,  Ebrahim Sahafizadeh",
                "发布日期": "2023-10-06",
                "摘要": "  This literature review aimed to compare various time-series analysis\napproaches utilized in forecasting COVID-19 cases in Africa. The study involved\na methodical search for English-language research papers published between\nJanuary 2020 and July 2023, focusing specifically on papers that utilized\ntime-series analysis approaches on COVID-19 datasets in Africa. A variety of\ndatabases including PubMed, Google Scholar, Scopus, and Web of Science were\nutilized for this process. The research papers underwent an evaluation process\nto extract relevant information regarding the implementation and performance of\nthe time-series analysis models. The study highlighted the different\nmethodologies employed, evaluating their effectiveness and limitations in\nforecasting the spread of the virus. The result of this review could contribute\ndeeper insights into the field, and future research should consider these\ninsights to improve time series analysis models and explore the integration of\ndifferent approaches for enhanced public health decision-making.\n",
                "链接": "https://arxiv.org/abs/2310.03606"
            },
            {
                "文章ID": "109092",
                "标题": "Legal NLP Meets MiCAR: Advancing the Analysis of Crypto White Papers",
                "作者": " Carolina Camassa",
                "发布日期": "2023-10-26",
                "摘要": "  In the rapidly evolving field of crypto assets, white papers are essential\ndocuments for investor guidance, and are now subject to unprecedented content\nrequirements under the European Union's Markets in Crypto-Assets Regulation\n(MiCAR). Natural Language Processing (NLP) can serve as a powerful tool for\nboth analyzing these documents and assisting in regulatory compliance. This\npaper delivers two contributions to the topic. First, we survey existing\napplications of textual analysis to unregulated crypto asset white papers,\nuncovering a research gap that could be bridged with interdisciplinary\ncollaboration. We then conduct an analysis of the changes introduced by MiCAR,\nhighlighting the opportunities and challenges of integrating NLP within the new\nregulatory framework. The findings set the stage for further research, with the\npotential to benefit regulators, crypto asset issuers, and investors.\n",
                "链接": "https://arxiv.org/abs/2310.10333"
            }
        ]
    },
    {
        "question": {
            "question": "查询2022年以来指令遵循数据集构建相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "23375",
                "标题": "DLT Compliance Reporting",
                "作者": " Henrik Axelsen,  Johannes Rude Jensen,  Omri Ross",
                "发布日期": "2022-06-08",
                "摘要": "  The IS discourse on the potential of distributed ledger technology (DLT) in\nthe financial services has grown at a tremendous pace in recent years. Yet,\nlittle has been said about the related implications for the costly and highly\nregulated process of compliance reporting. Working with a group of\nrepresentatives from industry and regulatory authorities, we employ the design\nscience research methodology (DSR) in the design, development, and evaluation\nof an artefact, enabling the automated collection and enrichment of\ntransactional data. Our findings indicate that DLT may facilitate the\nautomation of key compliance processes through the implementation of a\n\"pull-model\", in which regulators can access compliance data in near real-time\nto stage aggregate exposures at the supranational level. Generalizing our\npreliminary results, we present four propositions on the implications of DLT in\ncompliance. The findings contribute new practical insights on the topic of\ncompliance to the growing IS discourse on DLT.\n",
                "链接": "https://arxiv.org/abs/2206.03270"
            },
            {
                "文章ID": "15105",
                "标题": "Stateless and Rule-Based Verification For Compliance Checking\n  Applications",
                "作者": " Mohammad Reza Besharati,  Mohammad Izadi,  Ehsaneddin Asgari",
                "发布日期": "2022-05-02",
                "摘要": "  Underlying computational model has an important role in any computation. The\nstate and transition (such as in automata) and rule and value (such as in Lisp\nand logic programming) are two comparable and counterpart computational models.\nBoth of deductive and model checking verification techniques are relying on a\nnotion of state and as a result, their underlying computational models are\nstate dependent. Some verification problems (such as compliance checking by\nwhich an under compliance system is verified against some regulations and\nrules) have not a strong notion of state nor transition. Behalf of it, these\nsystems have a strong notion of value symbols and declarative rules defined on\nthem. SARV (Stateless And Rule-Based Verification) is a verification framework\nthat designed to simplify the overall process of verification for stateless and\nrule-based verification problems (e.g. compliance checking). In this paper, a\nformal logic-based framework for creating intelligent compliance checking\nsystems is presented. We define and introduce this framework, report a case\nstudy and present results of an experiment on it. The case study is about\nprotocol compliance checking for smart cities. Using this solution, a Rescue\nScenario use case and its compliance checking are sketched and modeled. An\nautomation engine for and a compliance solution with SARV are introduced. Based\non 300 data experiments, the SARV-based compliance solution outperforms famous\nmachine learning methods on a 3125-records software quality dataset.\n",
                "链接": "https://arxiv.org/abs/2204.07430"
            },
            {
                "文章ID": "6215",
                "标题": "SODA: Site Object Detection dAtaset for Deep Learning in Construction",
                "作者": " Rui Duan,  Hui Deng,  Mao Tian,  Yichuan Deng,  Jiarui Lin",
                "发布日期": "2023-05-18",
                "摘要": "  Computer vision-based deep learning object detection algorithms have been\ndeveloped sufficiently powerful to support the ability to recognize various\nobjects. Although there are currently general datasets for object detection,\nthere is still a lack of large-scale, open-source dataset for the construction\nindustry, which limits the developments of object detection algorithms as they\ntend to be data-hungry. Therefore, this paper develops a new large-scale image\ndataset specifically collected and annotated for the construction site, called\nSite Object Detection dAtaset (SODA), which contains 15 kinds of object classes\ncategorized by workers, materials, machines, and layout. Firstly, more than\n20,000 images were collected from multiple construction sites in different site\nconditions, weather conditions, and construction phases, which covered\ndifferent angles and perspectives. After careful screening and processing,\n19,846 images including 286,201 objects were then obtained and annotated with\nlabels in accordance with predefined categories. Statistical analysis shows\nthat the developed dataset is advantageous in terms of diversity and volume.\nFurther evaluation with two widely-adopted object detection algorithms based on\ndeep learning (YOLO v3/ YOLO v4) also illustrates the feasibility of the\ndataset for typical construction scenarios, achieving a maximum mAP of 81.47%.\nIn this manner, this research contributes a large-scale image dataset for the\ndevelopment of deep learning-based object detection methods in the construction\nindustry and sets up a performance benchmark for further evaluation of\ncorresponding algorithms in this area.\n",
                "链接": "https://arxiv.org/abs/2202.09554"
            },
            {
                "文章ID": "36727",
                "标题": "Code Compliance Assessment as a Learning Problem",
                "作者": " Neela Sawant,  Srinivasan H. Sengamedu",
                "发布日期": "2022-09-13",
                "摘要": "  Manual code reviews and static code analyzers are the traditional mechanisms\nto verify if source code complies with coding policies. However, these\nmechanisms are hard to scale. We formulate code compliance assessment as a\nmachine learning (ML) problem, to take as input a natural language policy and\ncode, and generate a prediction on the code's compliance, non-compliance, or\nirrelevance. This can help scale compliance classification and search for\npolicies not covered by traditional mechanisms. We explore key research\nquestions on ML model formulation, training data, and evaluation setup. The\ncore idea is to obtain a joint code-text embedding space which preserves\ncompliance relationships via the vector distance of code and policy embeddings.\nAs there is no task-specific data, we re-interpret and filter commonly\navailable software datasets with additional pre-training and pre-finetuning\ntasks that reduce the semantic gap. We benchmarked our approach on two listings\nof coding policies (CWE and CBP). This is a zero-shot evaluation as none of the\npolicies occur in the training set. On CWE and CBP respectively, our tool\nPolicy2Code achieves classification accuracies of (59%, 71%) and search MRR of\n(0.05, 0.21) compared to CodeBERT with classification accuracies of (37%, 54%)\nand MRR of (0.02, 0.02). In a user study, 24% Policy2Code detections were\naccepted compared to 7% for CodeBERT.\n",
                "链接": "https://arxiv.org/abs/2209.04602"
            },
            {
                "文章ID": "81611",
                "标题": "VCVW-3D: A Virtual Construction Vehicles and Workers Dataset with 3D\n  Annotations",
                "作者": " Yuexiong Ding,  Xiaowei Luo",
                "发布日期": "2023-05-30",
                "摘要": "  Currently, object detection applications in construction are almost based on\npure 2D data (both image and annotation are 2D-based), resulting in the\ndeveloped artificial intelligence (AI) applications only applicable to some\nscenarios that only require 2D information. However, most advanced applications\nusually require AI agents to perceive 3D spatial information, which limits the\nfurther development of the current computer vision (CV) in construction. The\nlack of 3D annotated datasets for construction object detection worsens the\nsituation. Therefore, this study creates and releases a virtual dataset with 3D\nannotations named VCVW-3D, which covers 15 construction scenes and involves ten\ncategories of construction vehicles and workers. The VCVW-3D dataset is\ncharacterized by multi-scene, multi-category, multi-randomness,\nmulti-viewpoint, multi-annotation, and binocular vision. Several typical 2D and\nmonocular 3D object detection models are then trained and evaluated on the\nVCVW-3D dataset to provide a benchmark for subsequent research. The VCVW-3D is\nexpected to bring considerable economic benefits and practical significance by\nreducing the costs of data construction, prototype development, and exploration\nof space-awareness applications, thus promoting the development of CV in\nconstruction, especially those of 3D applications.\n",
                "链接": "https://arxiv.org/abs/2305.17927"
            },
            {
                "文章ID": "62715",
                "标题": "Directive Explanations for Monitoring the Risk of Diabetes Onset:\n  Introducing Directive Data-Centric Explanations and Combinations to Support\n  What-If Explorations",
                "作者": " Aditya Bhattacharya,  Jeroen Ooge,  Gregor Stiglic,  Katrien Verbert",
                "发布日期": "2023-02-22",
                "摘要": "  Explainable artificial intelligence is increasingly used in machine learning\n(ML) based decision-making systems in healthcare. However, little research has\ncompared the utility of different explanation methods in guiding healthcare\nexperts for patient care. Moreover, it is unclear how useful, understandable,\nactionable and trustworthy these methods are for healthcare experts, as they\noften require technical ML knowledge. This paper presents an explanation\ndashboard that predicts the risk of diabetes onset and explains those\npredictions with data-centric, feature-importance, and example-based\nexplanations. We designed an interactive dashboard to assist healthcare\nexperts, such as nurses and physicians, in monitoring the risk of diabetes\nonset and recommending measures to minimize risk. We conducted a qualitative\nstudy with 11 healthcare experts and a mixed-methods study with 45 healthcare\nexperts and 51 diabetic patients to compare the different explanation methods\nin our dashboard in terms of understandability, usefulness, actionability, and\ntrust. Results indicate that our participants preferred our representation of\ndata-centric explanations that provide local explanations with a global\noverview over other methods. Therefore, this paper highlights the importance of\nvisually directive data-centric explanation method for assisting healthcare\nexperts to gain actionable insights from patient health records. Furthermore,\nwe share our design implications for tailoring the visual representation of\ndifferent explanation methods for healthcare experts.\n",
                "链接": "https://arxiv.org/abs/2302.10671"
            },
            {
                "文章ID": "59931",
                "标题": "A Case Study for Compliance as Code with Graphs and Language Models:\n  Public release of the Regulatory Knowledge Graph",
                "作者": " Vladimir Ershov",
                "发布日期": "2023-02-06",
                "摘要": "  The paper presents a study on using language models to automate the\nconstruction of executable Knowledge Graph (KG) for compliance. The paper\nfocuses on Abu Dhabi Global Market regulations and taxonomy, involves manual\ntagging a portion of the regulations, training BERT-based models, which are\nthen applied to the rest of the corpus. Coreference resolution and syntax\nanalysis were used to parse the relationships between the tagged entities and\nto form KG stored in a Neo4j database. The paper states that the use of machine\nlearning models released by regulators to automate the interpretation of rules\nis a vital step towards compliance automation, demonstrates the concept\nquerying with Cypher, and states that the produced sub-graphs combined with\nGraph Neural Networks (GNN) will achieve expandability in judgment automation\nsystems. The graph is open sourced on GitHub to provide structured data for\nfuture advancements in the field.\n",
                "链接": "https://arxiv.org/abs/2302.01842"
            },
            {
                "文章ID": "125130",
                "标题": "ConstScene: Dataset and Model for Advancing Robust Semantic Segmentation\n  in Construction Environments",
                "作者": " Maghsood Salimi,  Mohammad Loni,  Sara Afshar,  Marjan Sirjani,  Antonio Cicchetti",
                "发布日期": "2023-12-29",
                "摘要": "  The increasing demand for autonomous machines in construction environments\nnecessitates the development of robust object detection algorithms that can\nperform effectively across various weather and environmental conditions. This\npaper introduces a new semantic segmentation dataset specifically tailored for\nconstruction sites, taking into account the diverse challenges posed by adverse\nweather and environmental conditions. The dataset is designed to enhance the\ntraining and evaluation of object detection models, fostering their\nadaptability and reliability in real-world construction applications. Our\ndataset comprises annotated images captured under a wide range of different\nweather conditions, including but not limited to sunny days, rainy periods,\nfoggy atmospheres, and low-light situations. Additionally, environmental\nfactors such as the existence of dirt/mud on the camera lens are integrated\ninto the dataset through actual captures and synthetic generation to simulate\nthe complex conditions prevalent in construction sites. We also generate\nsynthetic images of the annotations including precise semantic segmentation\nmasks for various objects commonly found in construction environments, such as\nwheel loader machines, personnel, cars, and structural elements. To demonstrate\nthe dataset's utility, we evaluate state-of-the-art object detection algorithms\non our proposed benchmark. The results highlight the dataset's success in\nadversarial training models across diverse conditions, showcasing its efficacy\ncompared to existing datasets that lack such environmental variability.\n",
                "链接": "https://arxiv.org/abs/2312.16516"
            },
            {
                "文章ID": "59190",
                "标题": "Compliance Costs of AI Technology Commercialization: A Field Deployment\n  Perspective",
                "作者": " Weiyue Wu,  Shaoshan Liu",
                "发布日期": "2023-02-01",
                "摘要": "  While Artificial Intelligence (AI) technologies are progressing fast,\ncompliance costs have become a huge financial burden for AI startups, which are\nalready constrained on research & development budgets. This situation creates a\ncompliance trap, as many AI startups are not financially prepared to cope with\na broad spectrum of regulatory requirements. Particularly, the complex and\nvarying regulatory processes across the globe subtly give advantages to\nwell-established and resourceful technology firms over resource-constrained AI\nstartups [1]. The continuation of this trend may phase out the majority of AI\nstartups and lead to giant technology firms' monopolies of AI technologies. To\ndemonstrate the reality of the compliance trap, from a field deployment\nperspective, we delve into the details of compliance costs of AI commercial\noperations.\n",
                "链接": "https://arxiv.org/abs/2301.13454"
            },
            {
                "文章ID": "13545",
                "标题": "ZETAR: Modeling and Computational Design of Strategic and Adaptive\n  Compliance Policies",
                "作者": " Linan Huang,  Quanyan Zhu",
                "发布日期": "2023-10-17",
                "摘要": "  Compliance management plays an important role in mitigating insider threats.\nIncentive design is a proactive and non-invasive approach to achieving\ncompliance by aligning an insider's incentive with the defender's security\nobjective, which motivates (rather than commands) an insider to act in the\norganization's interests. Controlling insiders' incentives for population-level\ncompliance is challenging because they are neither precisely known nor directly\ncontrollable. To this end, we develop ZETAR, a zero-trust audit and\nrecommendation framework, to provide a quantitative approach to model insiders'\nincentives and design customized recommendation policies to improve their\ncompliance. We formulate primal and dual convex programs to compute the optimal\nbespoke recommendation policies. We create the theoretical underpinning for\nunderstanding trust, compliance, and satisfaction, which leads to scoring\nmechanisms of how compliant and persuadable an insider is. After classifying\ninsiders as malicious, self-interested, or amenable based on their incentive\nmisalignment levels with the defender, we establish bespoke information\ndisclosure principles for these insiders of different incentive categories. We\nidentify the policy separability principle and the set convexity, which enable\nfinite-step algorithms to efficiently learn the Completely Trustworthy (CT)\npolicy set when insiders' incentives are unknown. Finally, we present a case\nstudy to corroborate the design. Our results show that ZETAR can well adapt to\ninsiders with different risk and compliance attitudes and significantly improve\ncompliance. Moreover, trustworthy recommendations can provably promote cyber\nhygiene and insiders' satisfaction.\n",
                "链接": "https://arxiv.org/abs/2204.02294"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于gpt4自动生成prompt的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "122463",
                "标题": "Heterogeneous Graph Neural Architecture Search with GPT-4",
                "作者": " Haoyuan Dong,  Yang Gao,  Haishuai Wang,  Hong Yang,  Peng Zhang",
                "发布日期": "2023-12-15",
                "摘要": "  Heterogeneous graph neural architecture search (HGNAS) represents a powerful\ntool for automatically designing effective heterogeneous graph neural networks.\nHowever, existing HGNAS algorithms suffer from inefficient searches and\nunstable results. In this paper, we present a new GPT-4 based HGNAS model to\nimprove the search efficiency and search accuracy of HGNAS. Specifically, we\npresent a new GPT-4 enhanced Heterogeneous Graph Neural Architecture Search\n(GHGNAS for short). The basic idea of GHGNAS is to design a set of prompts that\ncan guide GPT-4 toward the task of generating new heterogeneous graph neural\narchitectures. By iteratively asking GPT-4 with the prompts, GHGNAS continually\nvalidates the accuracy of the generated HGNNs and uses the feedback to further\noptimize the prompts. Experimental results show that GHGNAS can design new\nHGNNs by leveraging the powerful generalization capability of GPT-4. Moreover,\nGHGNAS runs more effectively and stably than previous HGNAS models based on\nreinforcement learning and differentiable search algorithms.\n",
                "链接": "https://arxiv.org/abs/2312.08680"
            },
            {
                "文章ID": "124195",
                "标题": "Using GPT-4 Prompts to Determine Whether Articles Contain Functional\n  Evidence Supporting or Refuting Variant Pathogenicity",
                "作者": " Samuel J. Aronson,  Kalotina Machini,  Pranav Sriraman,  Jiyeon Shin,  Emma R. Henricks,  Charlotte Mailly,  Angie J. Nottage,  Michael Oates,  Matthew S. Lebo",
                "发布日期": "2023-12-22",
                "摘要": "  Purpose: To assess Generative Pre-trained Transformer version 4's (GPT-4)\nability to classify articles containing functional evidence relevant to\nassessments of variant pathogenicity.\n  Results: GPT-4 settings and prompts were trained on a set of 45 articles and\ngenetic variants. A final test set of 72 manually classified articles and\ngenetic variants were then processed using two prompts. The prompts asked GPT-4\nto supply all functional evidence present in an article for a variant or\nindicate that no functional evidence is present. For articles with having\nfunctional evidence, a second prompt asked GPT-4 to classify the evidence into\npathogenic, benign, intermediate, and inconclusive categories. The first prompt\nidentified articles with variant-level functional evidence with 87% sensitivity\nand 89% positive predictive value (PPV). Five of 26 articles with no functional\ndata were indicated as having functional evidence by GPT-4. For variants with\nfunctional assays present as determined by both manual review and GPT-4, the\nsensitivity and PPV of GPT-4 prompt concordance was: Pathogenic (92% sensitive\nand 73% PPV), Intermediate or Inconclusive (67% sensitive and 93% PPV), Benign\n(100% sensitive and 73% PPV).\n  Conclusion: The GPT-4 prompts detected the presence or absence of a\nfunctional assay with high sensitivity and PPV, and articles with unambiguous\nevidence supporting a benign or pathogenic classification with high sensitivity\nand reasonable PPV. Our prompts detected papers with intermediate or\ninconclusive evidence with lower sensitivity but high PPV. Our results support\nthat GPT-4 may be useful in variant classification workflows by enabling\nprioritization of articles for review that are likely to have functional\nevidence supporting or refuting pathogenicity, but not that GPT-4 is capable of\nfully automating the genetics literature review component of variant\nclassification.\n",
                "链接": "https://arxiv.org/abs/2312.13521"
            },
            {
                "文章ID": "105803",
                "标题": "Graph Neural Architecture Search with GPT-4",
                "作者": " Haishuai Wang,  Yang Gao,  Xin Zheng,  Peng Zhang,  Hongyang Chen,  Jiajun Bu",
                "发布日期": "2023-10-04",
                "摘要": "  Graph Neural Architecture Search (GNAS) has shown promising results in\nautomatically designing graph neural networks. However, GNAS still requires\nintensive human labor with rich domain knowledge to design the search space and\nsearch strategy. In this paper, we integrate GPT-4 into GNAS and propose a new\nGPT-4 based Graph Neural Architecture Search method (GPT4GNAS for short). The\nbasic idea of our method is to design a new class of prompts for GPT-4 to guide\nGPT-4 toward the generative task of graph neural architectures. The prompts\nconsist of descriptions of the search space, search strategy, and search\nfeedback of GNAS. By iteratively running GPT-4 with the prompts, GPT4GNAS\ngenerates more accurate graph neural networks with fast convergence.\nExperimental results show that embedding GPT-4 into GNAS outperforms the\nstate-of-the-art GNAS methods.\n",
                "链接": "https://arxiv.org/abs/2310.01436"
            },
            {
                "文章ID": "104941",
                "标题": "GPT-Fathom: Benchmarking Large Language Models to Decipher the\n  Evolutionary Path towards GPT-4 and Beyond",
                "作者": " Shen Zheng,  Yuyu Zhang,  Yijie Zhu,  Chenguang Xi,  Pengyang Gao,  Xun Zhou,  Kevin Chen-Chuan Chang",
                "发布日期": "2023-12-20",
                "摘要": "  With the rapid advancement of large language models (LLMs), there is a\npressing need for a comprehensive evaluation suite to assess their capabilities\nand limitations. Existing LLM leaderboards often reference scores reported in\nother papers without consistent settings and prompts, which may inadvertently\nencourage cherry-picking favored settings and prompts for better results. In\nthis work, we introduce GPT-Fathom, an open-source and reproducible LLM\nevaluation suite built on top of OpenAI Evals. We systematically evaluate 10+\nleading LLMs as well as OpenAI's legacy models on 20+ curated benchmarks across\n7 capability categories, all under aligned settings. Our retrospective study on\nOpenAI's earlier models offers valuable insights into the evolutionary path\nfrom GPT-3 to GPT-4. Currently, the community is eager to know how GPT-3\nprogressively improves to GPT-4, including technical details like whether\nadding code data improves LLM's reasoning capability, which aspects of LLM\ncapability can be improved by SFT and RLHF, how much is the alignment tax, etc.\nOur analysis sheds light on many of these questions, aiming to improve the\ntransparency of advanced LLMs.\n",
                "链接": "https://arxiv.org/abs/2309.16583"
            },
            {
                "文章ID": "93958",
                "标题": "Comparative Analysis of Drug-GPT and ChatGPT LLMs for Healthcare\n  Insights: Evaluating Accuracy and Relevance in Patient and HCP Contexts",
                "作者": " Giorgos Lysandrou,  Roma English Owen,  Kirsty Mursec,  Grant Le Brun,  Elizabeth A. L. Fairley",
                "发布日期": "2023-08-01",
                "摘要": "  This study presents a comparative analysis of three Generative Pre-trained\nTransformer (GPT) solutions in a question and answer (Q&A) setting: Drug-GPT 3,\nDrug-GPT 4, and ChatGPT, in the context of healthcare applications. The\nobjective is to determine which model delivers the most accurate and relevant\ninformation in response to prompts related to patient experiences with atopic\ndermatitis (AD) and healthcare professional (HCP) discussions about diabetes.\nThe results demonstrate that while all three models are capable of generating\nrelevant and accurate responses, Drug-GPT 3 and Drug-GPT 4, which are supported\nby curated datasets of patient and HCP social media and message board posts,\nprovide more targeted and in-depth insights. ChatGPT, a more general-purpose\nmodel, generates broader and more general responses, which may be valuable for\nreaders seeking a high-level understanding of the topics but may lack the depth\nand personal insights found in the answers generated by the specialized\nDrug-GPT models. This comparative analysis highlights the importance of\nconsidering the language model's perspective, depth of knowledge, and currency\nwhen evaluating the usefulness of generated information in healthcare\napplications.\n",
                "链接": "https://arxiv.org/abs/2307.16850"
            },
            {
                "文章ID": "109002",
                "标题": "Prompt Packer: Deceiving LLMs through Compositional Instruction with\n  Hidden Attacks",
                "作者": " Shuyu Jiang,  Xingshu Chen,  Rui Tang",
                "发布日期": "2023-10-17",
                "摘要": "  Recently, Large language models (LLMs) with powerful general capabilities\nhave been increasingly integrated into various Web applications, while\nundergoing alignment training to ensure that the generated content aligns with\nuser intent and ethics. Unfortunately, they remain the risk of generating\nharmful content like hate speech and criminal activities in practical\napplications. Current approaches primarily rely on detecting, collecting, and\ntraining against harmful prompts to prevent such risks. However, they typically\nfocused on the \"superficial\" harmful prompts with a solitary intent, ignoring\ncomposite attack instructions with multiple intentions that can easily elicit\nharmful content in real-world scenarios. In this paper, we introduce an\ninnovative technique for obfuscating harmful instructions: Compositional\nInstruction Attacks (CIA), which refers to attacking by combination and\nencapsulation of multiple instructions. CIA hides harmful prompts within\ninstructions of harmless intentions, making it impossible for the model to\nidentify underlying malicious intentions. Furthermore, we implement two\ntransformation methods, known as T-CIA and W-CIA, to automatically disguise\nharmful instructions as talking or writing tasks, making them appear harmless\nto LLMs. We evaluated CIA on GPT-4, ChatGPT, and ChatGLM2 with two safety\nassessment datasets and two harmful prompt datasets. It achieves an attack\nsuccess rate of 95%+ on safety assessment datasets, and 83%+ for GPT-4, 91%+\nfor ChatGPT (gpt-3.5-turbo backed) and ChatGLM2-6B on harmful prompt datasets.\nOur approach reveals the vulnerability of LLMs to such compositional\ninstruction attacks that harbor underlying harmful intentions, contributing\nsignificantly to LLM security development. Warning: this paper may contain\noffensive or upsetting content!\n",
                "链接": "https://arxiv.org/abs/2310.10077"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "109421",
                "标题": "On the Effectiveness of Creating Conversational Agent Personalities\n  Through Prompting",
                "作者": " Heng Gu,  Chadha Degachi,  Uğur Genç,  Senthil Chandrasegaran,  Himanshu Verma",
                "发布日期": "2023-10-18",
                "摘要": "  In this work, we report on the effectiveness of our efforts to tailor the\npersonality and conversational style of a conversational agent based on GPT-3.5\nand GPT-4 through prompts. We use three personality dimensions with two levels\neach to create eight conversational agents archetypes. Ten conversations were\ncollected per chatbot, of ten exchanges each, generating 1600 exchanges across\nGPT-3.5 and GPT-4. Using Linguistic Inquiry and Word Count (LIWC) analysis, we\ncompared the eight agents on language elements including clout, authenticity,\nand emotion. Four language cues were significantly distinguishing in GPT-3.5,\nwhile twelve were distinguishing in GPT-4. With thirteen out of a total\nnineteen cues in LIWC appearing as significantly distinguishing, our results\nsuggest possible novel prompting approaches may be needed to better suit the\ncreation and evaluation of persistent conversational agent personalities or\nlanguage styles.\n",
                "链接": "https://arxiv.org/abs/2310.11182"
            },
            {
                "文章ID": "98588",
                "标题": "Prompting a Large Language Model to Generate Diverse Motivational\n  Messages: A Comparison with Human-Written Messages",
                "作者": " Samuel Rhys Cox,  Ashraf Abdul,  Wei Tsang Ooi",
                "发布日期": "2023-08-28",
                "摘要": "  Large language models (LLMs) are increasingly capable and prevalent, and can\nbe used to produce creative content. The quality of content is influenced by\nthe prompt used, with more specific prompts that incorporate examples generally\nproducing better results. On from this, it could be seen that using\ninstructions written for crowdsourcing tasks (that are specific and include\nexamples to guide workers) could prove effective LLM prompts. To explore this,\nwe used a previous crowdsourcing pipeline that gave examples to people to help\nthem generate a collectively diverse corpus of motivational messages. We then\nused this same pipeline to generate messages using GPT-4, and compared the\ncollective diversity of messages from: (1) crowd-writers, (2) GPT-4 using the\npipeline, and (3 & 4) two baseline GPT-4 prompts. We found that the LLM prompts\nusing the crowdsourcing pipeline caused GPT-4 to produce more diverse messages\nthan the two baseline prompts. We also discuss implications from messages\ngenerated by both human writers and LLMs.\n",
                "链接": "https://arxiv.org/abs/2308.13479"
            },
            {
                "文章ID": "117134",
                "标题": "Extracting Definienda in Mathematical Scholarly Articles with\n  Transformers",
                "作者": "VALDA  Shufan Jiang, DI-ENS, VALDA  Pierre Senellart",
                "发布日期": "2023-11-22",
                "摘要": "  We consider automatically identifying the defined term within a mathematical\ndefinition from the text of an academic article. Inspired by the development of\ntransformer-based natural language processing applications, we pose the problem\nas (a) a token-level classification task using fine-tuned pre-trained\ntransformers; and (b) a question-answering task using a generalist large\nlanguage model (GPT). We also propose a rule-based approach to build a labeled\ndataset from the LATEX source of papers. Experimental results show that it is\npossible to reach high levels of precision and recall using either recent (and\nexpensive) GPT 4 or simpler pre-trained models fine-tuned on our task.\n",
                "链接": "https://arxiv.org/abs/2311.12448"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态agent, 具身智能的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "61287",
                "标题": "Universal Agent Mixtures and the Geometry of Intelligence",
                "作者": " Samuel Allen Alexander,  David Quarel,  Len Du,  Marcus Hutter",
                "发布日期": "2023-02-14",
                "摘要": "  Inspired by recent progress in multi-agent Reinforcement Learning (RL), in\nthis work we examine the collective intelligent behaviour of theoretical\nuniversal agents by introducing a weighted mixture operation. Given a weighted\nset of agents, their weighted mixture is a new agent whose expected total\nreward in any environment is the corresponding weighted average of the original\nagents' expected total rewards in that environment. Thus, if RL agent\nintelligence is quantified in terms of performance across environments, the\nweighted mixture's intelligence is the weighted average of the original agents'\nintelligences. This operation enables various interesting new theorems that\nshed light on the geometry of RL agent intelligence, namely: results about\nsymmetries, convex agent-sets, and local extrema. We also show that any RL\nagent intelligence measure based on average performance across environments,\nsubject to certain weak technical conditions, is identical (up to a constant\nfactor) to performance within a single environment dependent on said\nintelligence measure.\n",
                "链接": "https://arxiv.org/abs/2302.06083"
            },
            {
                "文章ID": "63780",
                "标题": "Multimodal Speech Recognition for Language-Guided Embodied Agents",
                "作者": " Allen Chang,  Xiaoyuan Zhu,  Aarav Monga,  Seoho Ahn,  Tejas Srinivasan,  Jesse Thomason",
                "发布日期": "2023-10-11",
                "摘要": "  Benchmarks for language-guided embodied agents typically assume text-based\ninstructions, but deployed agents will encounter spoken instructions. While\nAutomatic Speech Recognition (ASR) models can bridge the input gap, erroneous\nASR transcripts can hurt the agents' ability to complete tasks. In this work,\nwe propose training a multimodal ASR model to reduce errors in transcribing\nspoken instructions by considering the accompanying visual context. We train\nour model on a dataset of spoken instructions, synthesized from the ALFRED task\ncompletion dataset, where we simulate acoustic noise by systematically masking\nspoken words. We find that utilizing visual observations facilitates masked\nword recovery, with multimodal ASR models recovering up to 30% more masked\nwords than unimodal baselines. We also find that a text-trained embodied agent\nsuccessfully completes tasks more often by following transcribed instructions\nfrom multimodal ASR models. github.com/Cylumn/embodied-multimodal-asr\n",
                "链接": "https://arxiv.org/abs/2302.14030"
            },
            {
                "文章ID": "114225",
                "标题": "Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI",
                "作者": " Song Yaoxian,  Sun Penglei,  Liu Haoyu,  Li Zhixu,  Song Wei,  Xiao Yanghua,  Zhou Xiaofang",
                "发布日期": "2023-11-08",
                "摘要": "  Embodied AI is one of the most popular studies in artificial intelligence and\nrobotics, which can effectively improve the intelligence of real-world agents\n(i.e. robots) serving human beings. Scene knowledge is important for an agent\nto understand the surroundings and make correct decisions in the varied open\nworld. Currently, knowledge base for embodied tasks is missing and most\nexisting work use general knowledge base or pre-trained models to enhance the\nintelligence of an agent. For conventional knowledge base, it is sparse,\ninsufficient in capacity and cost in data collection. For pre-trained models,\nthey face the uncertainty of knowledge and hard maintenance. To overcome the\nchallenges of scene knowledge, we propose a scene-driven multimodal knowledge\ngraph (Scene-MMKG) construction method combining conventional knowledge\nengineering and large language models. A unified scene knowledge injection\nframework is introduced for knowledge representation. To evaluate the\nadvantages of our proposed method, we instantiate Scene-MMKG considering\ntypical indoor robotic functionalities (Manipulation and Mobility), named\nManipMob-MMKG. Comparisons in characteristics indicate our instantiated\nManipMob-MMKG has broad superiority in data-collection efficiency and knowledge\nquality. Experimental results on typical embodied tasks show that\nknowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the\nperformance obviously without re-designing model structures complexly. Our\nproject can be found at https://sites.google.com/view/manipmob-mmkg\n",
                "链接": "https://arxiv.org/abs/2311.03783"
            },
            {
                "文章ID": "89562",
                "标题": "Building Cooperative Embodied Agents Modularly with Large Language\n  Models",
                "作者": " Hongxin Zhang,  Weihua Du,  Jiaming Shan,  Qinhong Zhou,  Yilun Du,  Joshua B. Tenenbaum,  Tianmin Shu,  Chuang Gan",
                "发布日期": "2023-07-06",
                "摘要": "  Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.\n",
                "链接": "https://arxiv.org/abs/2307.02485"
            },
            {
                "文章ID": "123652",
                "标题": "Urban Generative Intelligence (UGI): A Foundational Platform for Agents\n  in Embodied City Environment",
                "作者": " Fengli Xu,  Jun Zhang,  Chen Gao,  Jie Feng,  Yong Li",
                "发布日期": "2023-12-20",
                "摘要": "  Urban environments, characterized by their complex, multi-layered networks\nencompassing physical, social, economic, and environmental dimensions, face\nsignificant challenges in the face of rapid urbanization. These challenges,\nranging from traffic congestion and pollution to social inequality, call for\nadvanced technological interventions. Recent developments in big data,\nartificial intelligence, urban computing, and digital twins have laid the\ngroundwork for sophisticated city modeling and simulation. However, a gap\npersists between these technological capabilities and their practical\nimplementation in addressing urban challenges in an systemic-intelligent way.\nThis paper proposes Urban Generative Intelligence (UGI), a novel foundational\nplatform integrating Large Language Models (LLMs) into urban systems to foster\na new paradigm of urban intelligence. UGI leverages CityGPT, a foundation model\ntrained on city-specific multi-source data, to create embodied agents for\nvarious urban tasks. These agents, operating within a textual urban environment\nemulated by city simulator and urban knowledge graph, interact through a\nnatural language interface, offering an open platform for diverse intelligent\nand embodied agent development. This platform not only addresses specific urban\nissues but also simulates complex urban systems, providing a multidisciplinary\napproach to understand and manage urban complexity. This work signifies a\ntransformative step in city science and urban intelligence, harnessing the\npower of LLMs to unravel and address the intricate dynamics of urban systems.\nThe code repository with demonstrations will soon be released here\nhttps://github.com/tsinghua-fib-lab/UGI.\n",
                "链接": "https://arxiv.org/abs/2312.11813"
            },
            {
                "文章ID": "118026",
                "标题": "Agent as Cerebrum, Controller as Cerebellum: Implementing an Embodied\n  LMM-based Agent on Drones",
                "作者": " Haoran Zhao,  Fengxing Pan,  Huqiuyue Ping,  Yaoming Zhou",
                "发布日期": "2023-11-28",
                "摘要": "  In this study, we present a novel paradigm for industrial robotic embodied\nagents, encapsulating an 'agent as cerebrum, controller as cerebellum'\narchitecture. Our approach harnesses the power of Large Multimodal Models\n(LMMs) within an agent framework known as AeroAgent, tailored for drone\ntechnology in industrial settings. To facilitate seamless integration with\nrobotic systems, we introduce ROSchain, a bespoke linkage framework connecting\nLMM-based agents to the Robot Operating System (ROS). We report findings from\nextensive empirical research, including simulated experiments on the Airgen and\nreal-world case study, particularly in individual search and rescue operations.\nThe results demonstrate AeroAgent's superior performance in comparison to\nexisting Deep Reinforcement Learning (DRL)-based agents, highlighting the\nadvantages of the embodied LMM in complex, real-world scenarios.\n",
                "链接": "https://arxiv.org/abs/2311.15033"
            },
            {
                "文章ID": "42792",
                "标题": "AVLEN: Audio-Visual-Language Embodied Navigation in 3D Environments",
                "作者": " Sudipta Paul,  Amit K. Roy-Chowdhury,  Anoop Cherian",
                "发布日期": "2022-10-17",
                "摘要": "  Recent years have seen embodied visual navigation advance in two distinct\ndirections: (i) in equipping the AI agent to follow natural language\ninstructions, and (ii) in making the navigable world multimodal, e.g.,\naudio-visual navigation. However, the real world is not only multimodal, but\nalso often complex, and thus in spite of these advances, agents still need to\nunderstand the uncertainty in their actions and seek instructions to navigate.\nTo this end, we present AVLEN~ -- an interactive agent for\nAudio-Visual-Language Embodied Navigation. Similar to audio-visual navigation\ntasks, the goal of our embodied agent is to localize an audio event via\nnavigating the 3D visual world; however, the agent may also seek help from a\nhuman (oracle), where the assistance is provided in free-form natural language.\nTo realize these abilities, AVLEN uses a multimodal hierarchical reinforcement\nlearning backbone that learns: (a) high-level policies to choose either\naudio-cues for navigation or to query the oracle, and (b) lower-level policies\nto select navigation actions based on its audio-visual and language inputs. The\npolicies are trained via rewarding for the success on the navigation task while\nminimizing the number of queries to the oracle. To empirically evaluate AVLEN,\nwe present experiments on the SoundSpaces framework for semantic audio-visual\nnavigation tasks. Our results show that equipping the agent to ask for help\nleads to a clear improvement in performance, especially in challenging cases,\ne.g., when the sound is unheard during training or in the presence of\ndistractor sounds.\n",
                "链接": "https://arxiv.org/abs/2210.07940"
            },
            {
                "文章ID": "104544",
                "标题": "The Importance of Multimodal Emotion Conditioning and Affect Consistency\n  for Embodied Conversational Agents",
                "作者": " Che-Jui Chang,  Samuel S. Sohn,  Sen Zhang,  Rajath Jayashankar,  Muhammad Usman,  Mubbasir Kapadia",
                "发布日期": "2023-12-08",
                "摘要": "  Previous studies regarding the perception of emotions for embodied virtual\nagents have shown the effectiveness of using virtual characters in conveying\nemotions through interactions with humans. However, creating an autonomous\nembodied conversational agent with expressive behaviors presents two major\nchallenges. The first challenge is the difficulty of synthesizing the\nconversational behaviors for each modality that are as expressive as real human\nbehaviors. The second challenge is that the affects are modeled independently,\nwhich makes it difficult to generate multimodal responses with consistent\nemotions across all modalities. In this work, we propose a conceptual\nframework, ACTOR (Affect-Consistent mulTimodal behaviOR generation), that aims\nto increase the perception of affects by generating multimodal behaviors\nconditioned on a consistent driving affect. We have conducted a user study with\n199 participants to assess how the average person judges the affects perceived\nfrom multimodal behaviors that are consistent and inconsistent with respect to\na driving affect. The result shows that among all model conditions, our\naffect-consistent framework receives the highest Likert scores for the\nperception of driving affects. Our statistical analysis suggests that making a\nmodality affect-inconsistent significantly decreases the perception of driving\naffects. We also observe that multimodal behaviors conditioned on consistent\naffects are more expressive compared to behaviors with inconsistent affects.\nTherefore, we conclude that multimodal emotion conditioning and affect\nconsistency are vital to enhancing the perception of affects for embodied\nconversational agents.\n",
                "链接": "https://arxiv.org/abs/2309.15311"
            },
            {
                "文章ID": "52754",
                "标题": "Voice Over Body? Older Adults' Reactions to Robot and Voice Assistant\n  Facilitators of Group Conversation",
                "作者": " Katie Seaborn,  Takuya Sekiguchi,  Seiki Tokunaga,  Norihisa P. Miyake,  Mihoko Otake-Matsuura",
                "发布日期": "2022-12-09",
                "摘要": "  Intelligent agents have great potential as facilitators of group conversation\namong older adults. However, little is known about how to design agents for\nthis purpose and user group, especially in terms of agent embodiment. To this\nend, we conducted a mixed methods study of older adults' reactions to voice and\nbody in a group conversation facilitation agent. Two agent forms with the same\nunderlying artificial intelligence (AI) and voice system were compared: a\nhumanoid robot and a voice assistant. One preliminary study (total n=24) and\none experimental study comparing voice and body morphologies (n=36) were\nconducted with older adults and an experienced human facilitator. Findings\nrevealed that the artificiality of the agent, regardless of its form, was\nbeneficial for the socially uncomfortable task of conversation facilitation.\nEven so, talkative personality types had a poorer experience with the \"bodied\"\nrobot version. Design implications and supplementary reactions, especially to\nagent voice, are also discussed.\n",
                "链接": "https://arxiv.org/abs/2212.04213"
            },
            {
                "文章ID": "106036",
                "标题": "Towards End-to-End Embodied Decision Making via Multi-modal Large\n  Language Model: Explorations with GPT4-Vision and Beyond",
                "作者": " Liang Chen,  Yichi Zhang,  Shuhuai Ren,  Haozhe Zhao,  Zefan Cai,  Yuchi Wang,  Peiyi Wang,  Tianyu Liu,  Baobao Chang",
                "发布日期": "2023-11-29",
                "摘要": "  In this study, we explore the potential of Multimodal Large Language Models\n(MLLMs) in improving embodied decision-making processes for agents. While Large\nLanguage Models (LLMs) have been widely used due to their advanced reasoning\nskills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual\nunderstanding and reasoning capabilities. We investigate whether\nstate-of-the-art MLLMs can handle embodied decision-making in an end-to-end\nmanner and whether collaborations between LLMs and MLLMs can enhance\ndecision-making. To address these questions, we introduce a new benchmark\ncalled PCA-EVAL, which evaluates embodied decision-making from the perspectives\nof Perception, Cognition, and Action. Additionally, we propose HOLMES, a\nmulti-agent cooperation framework that allows LLMs to leverage MLLMs and APIs\nto gather multimodal information for informed decision-making. We compare\nend-to-end embodied decision-making and HOLMES on our benchmark and find that\nthe GPT4-Vision model demonstrates strong end-to-end embodied decision-making\nabilities, outperforming GPT4-HOLMES in terms of average decision accuracy\n(+3%). However, this performance is exclusive to the latest GPT4-Vision model,\nsurpassing the open-source state-of-the-art MLLM by 26%. Our results indicate\nthat powerful MLLMs like GPT4-Vision hold promise for decision-making in\nembodied agents, offering new avenues for MLLM research. Code and data are open\nat https://github.com/pkunlp-icler/PCA-EVAL/.\n",
                "链接": "https://arxiv.org/abs/2310.02071"
            }
        ]
    },
    {
        "question": {
            "question": "新的大模型结构相关探索的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "70693",
                "标题": "Summary of ChatGPT-Related Research and Perspective Towards the Future\n  of Large Language Models",
                "作者": " Yiheng Liu,  Tianle Han,  Siyuan Ma,  Jiayue Zhang,  Yuanyuan Yang,  Jiaming Tian,  Hao He,  Antong Li,  Mengshen He,  Zhengliang Liu,  Zihao Wu,  Lin Zhao,  Dajiang Zhu,  Xiang Li,  Ning Qiang,  Dingang Shen,  Tianming Liu,  Bao Ge",
                "发布日期": "2023-08-25",
                "摘要": "  This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and\nGPT-4) research, state-of-the-art large language models (LLM) from the GPT\nseries, and their prospective applications across diverse domains. Indeed, key\ninnovations such as large-scale pre-training that captures knowledge across the\nentire world wide web, instruction fine-tuning and Reinforcement Learning from\nHuman Feedback (RLHF) have played significant roles in enhancing LLMs'\nadaptability and performance. We performed an in-depth analysis of 194 relevant\npapers on arXiv, encompassing trend analysis, word cloud representation, and\ndistribution analysis across various application domains. The findings reveal a\nsignificant and increasing interest in ChatGPT-related research, predominantly\ncentered on direct natural language processing applications, while also\ndemonstrating considerable potential in areas ranging from education and\nhistory to mathematics, medicine, and physics. This study endeavors to furnish\ninsights into ChatGPT's capabilities, potential implications, ethical concerns,\nand offer direction for future advancements in this field.\n",
                "链接": "https://arxiv.org/abs/2304.01852"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "15455",
                "标题": "Research on Domain Information Mining and Theme Evolution of Scientific\n  Papers",
                "作者": " Changwei Zheng,  Zhe Xue,  Meiyu Liang,  Feifei Kou,  Zeli Guan",
                "发布日期": "2022-04-20",
                "摘要": "  In recent years, with the increase of social investment in scientific\nresearch, the number of research results in various fields has increased\nsignificantly. Cross-disciplinary research results have gradually become an\nemerging frontier research direction. There is a certain dependence between a\nlarge number of research results. It is difficult to effectively analyze\ntoday's scientific research results when looking at a single research field in\nisolation. How to effectively use the huge number of scientific papers to help\nresearchers becomes a challenge. This paper introduces the research status at\nhome and abroad in terms of domain information mining and topic evolution law\nof scientific and technological papers from three aspects: the semantic feature\nrepresentation learning of scientific and technological papers, the field\ninformation mining of scientific and technological papers, and the mining and\nprediction of research topic evolution rules of scientific and technological\npapers.\n",
                "链接": "https://arxiv.org/abs/2204.08476"
            },
            {
                "文章ID": "98421",
                "标题": "An approach based on Open Research Knowledge Graph for Knowledge\n  Acquisition from scientific papers",
                "作者": " Azanzi Jiomekong,  Sanju Tiwari",
                "发布日期": "2023-08-28",
                "摘要": "  A scientific paper can be divided into two major constructs which are\nMetadata and Full-body text. Metadata provides a brief overview of the paper\nwhile the Full-body text contains key-insights that can be valuable to fellow\nresearchers. To retrieve metadata and key-insights from scientific papers,\nknowledge acquisition is a central activity. It consists of gathering,\nanalyzing and organizing knowledge embedded in scientific papers in such a way\nthat it can be used and reused whenever needed. Given the wealth of scientific\nliterature, manual knowledge acquisition is a cumbersome task. Thus,\ncomputer-assisted and (semi-)automatic strategies are generally adopted. Our\npurpose in this research was two fold: curate Open Research Knowledge Graph\n(ORKG) with papers related to ontology learning and define an approach using\nORKG as a computer-assisted tool to organize key-insights extracted from\nresearch papers. This approach was used to document the \"epidemiological\nsurveillance systems design and implementation\" research problem and to prepare\nthe related work of this paper. It is currently used to document \"food\ninformation engineering\", \"Tabular data to Knowledge Graph Matching\" and\n\"Question Answering\" research problems and \"Neuro-symbolic AI\" domain.\n",
                "链接": "https://arxiv.org/abs/2308.12981"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "61747",
                "标题": "Generation of Highlights from Research Papers Using Pointer-Generator\n  Networks and SciBERT Embeddings",
                "作者": " Tohida Rehman,  Debarshi Kumar Sanyal,  Samiran Chattopadhyay,  Plaban Kumar Bhowmick,  Partha Pratim Das",
                "发布日期": "2023-09-19",
                "摘要": "  Nowadays many research articles are prefaced with research highlights to\nsummarize the main findings of the paper. Highlights not only help researchers\nprecisely and quickly identify the contributions of a paper, they also enhance\nthe discoverability of the article via search engines. We aim to automatically\nconstruct research highlights given certain segments of a research paper. We\nuse a pointer-generator network with coverage mechanism and a contextual\nembedding layer at the input that encodes the input tokens into SciBERT\nembeddings. We test our model on a benchmark dataset, CSPubSum, and also\npresent MixSub, a new multi-disciplinary corpus of papers for automatic\nresearch highlight generation. For both CSPubSum and MixSub, we have observed\nthat the proposed model achieves the best performance compared to related\nvariants and other models proposed in the literature. On the CSPubSum dataset,\nour model achieves the best performance when the input is only the abstract of\na paper as opposed to other segments of the paper. It produces ROUGE-1, ROUGE-2\nand ROUGE-L F1-scores of 38.26, 14.26 and 35.51, respectively, METEOR score of\n32.62, and BERTScore F1 of 86.65 which outperform all other baselines. On the\nnew MixSub dataset, where only the abstract is the input, our proposed model\n(when trained on the whole training corpus without distinguishing between the\nsubject categories) achieves ROUGE-1, ROUGE-2 and ROUGE-L F1-scores of 31.78,\n9.76 and 29.3, respectively, METEOR score of 24.00, and BERTScore F1 of 85.25.\n",
                "链接": "https://arxiv.org/abs/2302.07729"
            },
            {
                "文章ID": "11999",
                "标题": "Specialized Document Embeddings for Aspect-based Similarity of Research\n  Papers",
                "作者": " Malte Ostendorff,  Till Blume,  Terry Ruas,  Bela Gipp,  Georg Rehm",
                "发布日期": "2022-03-29",
                "摘要": "  Document embeddings and similarity measures underpin content-based\nrecommender systems, whereby a document is commonly represented as a single\ngeneric embedding. However, similarity computed on single vector\nrepresentations provides only one perspective on document similarity that\nignores which aspects make two documents alike. To address this limitation,\naspect-based similarity measures have been developed using document\nsegmentation or pairwise multi-class document classification. While\nsegmentation harms the document coherence, the pairwise classification approach\nscales poorly to large scale corpora. In this paper, we treat aspect-based\nsimilarity as a classical vector similarity problem in aspect-specific\nembedding spaces. We represent a document not as a single generic embedding but\nas multiple specialized embeddings. Our approach avoids document segmentation\nand scales linearly w.r.t.the corpus size. In an empirical study, we use the\nPapers with Code corpus containing 157,606 research papers and consider the\ntask, method, and dataset of the respective research papers as their aspects.\nWe compare and analyze three generic document embeddings, six specialized\ndocument embeddings and a pairwise classification baseline in the context of\nresearch paper recommendations. As generic document embeddings, we consider\nFastText, SciBERT, and SPECTER. To compute the specialized document embeddings,\nwe compare three alternative methods inspired by retrofitting, fine-tuning, and\nSiamese networks. In our experiments, Siamese SciBERT achieved the highest\nscores. Additional analyses indicate an implicit bias of the generic document\nembeddings towards the dataset aspect and against the method aspect of each\nresearch paper. Our approach of aspect-based document embeddings mitigates\npotential risks arising from implicit biases by making them explicit.\n",
                "链接": "https://arxiv.org/abs/2203.14541"
            },
            {
                "文章ID": "42172",
                "标题": "Predicting the clinical citation count of biomedical papers using\n  multilayer perceptron neural network",
                "作者": " Xin Li,  Xuli Tang,  Qikai Cheng",
                "发布日期": "2022-10-24",
                "摘要": "  The number of clinical citations received from clinical guidelines or\nclinical trials has been considered as one of the most appropriate indicators\nfor quantifying the clinical impact of biomedical papers. Therefore, the early\nprediction of the clinical citation count of biomedical papers is critical to\nscientific activities in biomedicine, such as research evaluation, resource\nallocation, and clinical translation. In this study, we designed a four-layer\nmultilayer perceptron neural network (MPNN) model to predict the clinical\ncitation count of biomedical papers in the future by using 9,822,620 biomedical\npapers published from 1985 to 2005. We extracted ninety-one paper features from\nthree dimensions as the input of the model, including twenty-one features in\nthe paper dimension, thirty-five in the reference dimension, and thirty-five in\nthe citing paper dimension. In each dimension, the features can be classified\ninto three categories, i.e., the citation-related features, the clinical\ntranslation-related features, and the topic-related features. Besides, in the\npaper dimension, we also considered the features that have previously been\ndemonstrated to be related to the citation counts of research papers. The\nresults showed that the proposed MPNN model outperformed the other five\nbaseline models, and the features in the reference dimension were the most\nimportant.\n",
                "链接": "https://arxiv.org/abs/2210.06346"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            }
        ]
    },
    {
        "question": {
            "question": "多模态细粒度图片编辑和生成相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "124621",
                "标题": "FineMoGen: Fine-Grained Spatio-Temporal Motion Generation and Editing",
                "作者": " Mingyuan Zhang,  Huirong Li,  Zhongang Cai,  Jiawei Ren,  Lei Yang,  Ziwei Liu",
                "发布日期": "2023-12-27",
                "摘要": "  Text-driven motion generation has achieved substantial progress with the\nemergence of diffusion models. However, existing methods still struggle to\ngenerate complex motion sequences that correspond to fine-grained descriptions,\ndepicting detailed and accurate spatio-temporal actions. This lack of fine\ncontrollability limits the usage of motion generation to a larger audience. To\ntackle these challenges, we present FineMoGen, a diffusion-based motion\ngeneration and editing framework that can synthesize fine-grained motions, with\nspatial-temporal composition to the user instructions. Specifically, FineMoGen\nbuilds upon diffusion model with a novel transformer architecture dubbed\nSpatio-Temporal Mixture Attention (SAMI). SAMI optimizes the generation of the\nglobal attention template from two perspectives: 1) explicitly modeling the\nconstraints of spatio-temporal composition; and 2) utilizing sparsely-activated\nmixture-of-experts to adaptively extract fine-grained features. To facilitate a\nlarge-scale study on this new fine-grained motion generation task, we\ncontribute the HuMMan-MoGen dataset, which consists of 2,968 videos and 102,336\nfine-grained spatio-temporal descriptions. Extensive experiments validate that\nFineMoGen exhibits superior motion generation quality over state-of-the-art\nmethods. Notably, FineMoGen further enables zero-shot motion editing\ncapabilities with the aid of modern large language models (LLM), which\nfaithfully manipulates motion sequences with fine-grained instructions. Project\nPage: https://mingyuan-zhang.github.io/projects/FineMoGen.html\n",
                "链接": "https://arxiv.org/abs/2312.15004"
            },
            {
                "文章ID": "13260",
                "标题": "Flexible Portrait Image Editing with Fine-Grained Control",
                "作者": " Linlin Liu,  Qian Fu,  Fei Hou,  Ying He",
                "发布日期": "2022-04-05",
                "摘要": "  We develop a new method for portrait image editing, which supports\nfine-grained editing of geometries, colors, lights and shadows using a single\nneural network model. We adopt a novel asymmetric conditional GAN architecture:\nthe generators take the transformed conditional inputs, such as edge maps,\ncolor palette, sliders and masks, that can be directly edited by the user; the\ndiscriminators take the conditional inputs in the way that can guide\ncontrollable image generation more effectively. Taking color editing as an\nexample, we feed color palettes (which can be edited easily) into the\ngenerator, and color maps (which contain positional information of colors) into\nthe discriminator. We also design a region-weighted discriminator so that\nhigher weights are assigned to more important regions, like eyes and skin.\nUsing a color palette, the user can directly specify the desired colors of\nhair, skin, eyes, lip and background. Color sliders allow the user to blend\ncolors in an intuitive manner. The user can also edit lights and shadows by\nmodifying the corresponding masks. We demonstrate the effectiveness of our\nmethod by evaluating it on the CelebAMask-HQ dataset with a wide range of\ntasks, including geometry/color/shadow/light editing, hand-drawn sketch to\nimage translation, and color transfer. We also present ablation studies to\njustify our design.\n",
                "链接": "https://arxiv.org/abs/2204.01318"
            },
            {
                "文章ID": "52126",
                "标题": "Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models",
                "作者": " Naoki Matsunaga,  Masato Ishii,  Akio Hayakawa,  Kenji Suzuki,  Takuya Narihira",
                "发布日期": "2023-06-01",
                "摘要": "  Our goal is to develop fine-grained real-image editing methods suitable for\nreal-world applications. In this paper, we first summarize four requirements\nfor these methods and propose a novel diffusion-based image editing framework\nwith pixel-wise guidance that satisfies these requirements. Specifically, we\ntrain pixel-classifiers with a few annotated data and then infer the\nsegmentation map of a target image. Users then manipulate the map to instruct\nhow the image will be edited. We utilize a pre-trained diffusion model to\ngenerate edited images aligned with the user's intention with pixel-wise\nguidance. The effective combination of proposed guidance and other techniques\nenables highly controllable editing with preserving the outside of the edited\narea, which results in meeting our requirements. The experimental results\ndemonstrate that our proposal outperforms the GAN-based method for editing\nquality and speed.\n",
                "链接": "https://arxiv.org/abs/2212.02024"
            },
            {
                "文章ID": "26773",
                "标题": "MACSA: A Multimodal Aspect-Category Sentiment Analysis Dataset with\n  Multimodal Fine-grained Aligned Annotations",
                "作者": " Hao Yang,  Yanyan Zhao,  Jianwei Liu,  Yang Wu,  Bing Qin",
                "发布日期": "2022-06-29",
                "摘要": "  Multimodal fine-grained sentiment analysis has recently attracted increasing\nattention due to its broad applications. However, the existing multimodal\nfine-grained sentiment datasets most focus on annotating the fine-grained\nelements in text but ignore those in images, which leads to the fine-grained\nelements in visual content not receiving the full attention they deserve. In\nthis paper, we propose a new dataset, the Multimodal Aspect-Category Sentiment\nAnalysis (MACSA) dataset, which contains more than 21K text-image pairs. The\ndataset provides fine-grained annotations for both textual and visual content\nand firstly uses the aspect category as the pivot to align the fine-grained\nelements between the two modalities. Based on our dataset, we propose the\nMultimodal ACSA task and a multimodal graph-based aligned model (MGAM), which\nadopts a fine-grained cross-modal fusion method. Experimental results show that\nour method can facilitate the baseline comparison for future research on this\ncorpus. We will make the dataset and code publicly available.\n",
                "链接": "https://arxiv.org/abs/2206.13969"
            },
            {
                "文章ID": "124901",
                "标题": "SERF: Fine-Grained Interactive 3D Segmentation and Editing with Radiance\n  Fields",
                "作者": " Kaichen Zhou,  Lanqing Hong,  Enze Xie,  Yongxin Yang,  Zhenguo Li,  Wei Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Although significant progress has been made in the field of 2D-based\ninteractive editing, fine-grained 3D-based interactive editing remains\nrelatively unexplored. This limitation can be attributed to two main\nchallenges: the lack of an efficient 3D representation robust to different\nmodifications and the absence of an effective 3D interactive segmentation\nmethod. In this paper, we introduce a novel fine-grained interactive 3D\nsegmentation and editing algorithm with radiance fields, which we refer to as\nSERF. Our method entails creating a neural mesh representation by integrating\nmulti-view algorithms with pre-trained 2D models. Building upon this\nrepresentation, we introduce a novel surface rendering technique that preserves\nlocal information and is robust to deformation. Moreover, this representation\nforms the basis for achieving accurate and interactive 3D segmentation without\nrequiring 3D supervision. Harnessing this representation facilitates a range of\ninteractive 3D editing operations, encompassing tasks such as interactive\ngeometry editing and texture painting. Extensive experiments and visualization\nexamples of editing on both real and synthetic data demonstrate the superiority\nof our method on representation quality and editing ability.\n",
                "链接": "https://arxiv.org/abs/2312.15856"
            },
            {
                "文章ID": "41367",
                "标题": "MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language\n  Representation Learning",
                "作者": " Zijia Zhao,  Longteng Guo,  Xingjian He,  Shuai Shao,  Zehuan Yuan,  Jing Liu",
                "发布日期": "2023-06-16",
                "摘要": "  Multimodal representation learning has shown promising improvements on\nvarious vision-language tasks. Most existing methods excel at building\nglobal-level alignment between vision and language while lacking effective\nfine-grained image-text interaction. In this paper, we propose a jointly masked\nmultimodal modeling method to learn fine-grained multimodal representations.\nOur method performs joint masking on image-text input and integrates both\nimplicit and explicit targets for the masked signals to recover. The implicit\ntarget provides a unified and debiased objective for vision and language, where\nthe model predicts latent multimodal representations of the unmasked input. The\nexplicit target further enriches the multimodal representations by recovering\nhigh-level and semantically meaningful information: momentum visual features of\nimage patches and concepts of word tokens. Through such a masked modeling\nprocess, our model not only learns fine-grained multimodal interaction, but\nalso avoids the semantic gap between high-level representations and low- or\nmid-level prediction targets (e.g. image pixels), thus producing semantically\nrich multimodal representations that perform well on both zero-shot and\nfine-tuned settings. Our pre-trained model (named MAMO) achieves\nstate-of-the-art performance on various downstream vision-language tasks,\nincluding image-text retrieval, visual question answering, visual reasoning,\nand weakly-supervised visual grounding.\n",
                "链接": "https://arxiv.org/abs/2210.04183"
            },
            {
                "文章ID": "69760",
                "标题": "Hierarchical Fine-Grained Image Forgery Detection and Localization",
                "作者": " Xiao Guo,  Xiaohong Liu,  Zhiyuan Ren,  Steven Grosz,  Iacopo Masi,  Xiaoming Liu",
                "发布日期": "2023-03-31",
                "摘要": "  Differences in forgery attributes of images generated in CNN-synthesized and\nimage-editing domains are large, and such differences make a unified image\nforgery detection and localization (IFDL) challenging. To this end, we present\na hierarchical fine-grained formulation for IFDL representation learning.\nSpecifically, we first represent forgery attributes of a manipulated image with\nmultiple labels at different levels. Then we perform fine-grained\nclassification at these levels using the hierarchical dependency between them.\nAs a result, the algorithm is encouraged to learn both comprehensive features\nand inherent hierarchical nature of different forgery attributes, thereby\nimproving the IFDL representation. Our proposed IFDL framework contains three\ncomponents: multi-branch feature extractor, localization and classification\nmodules. Each branch of the feature extractor learns to classify forgery\nattributes at one level, while localization and classification modules segment\nthe pixel-level forgery region and detect image-level forgery, respectively.\nLastly, we construct a hierarchical fine-grained dataset to facilitate our\nstudy. We demonstrate the effectiveness of our method on $7$ different\nbenchmarks, for both tasks of IFDL and forgery attribute classification. Our\nsource code and dataset can be found:\n\\href{https://github.com/CHELSEA234/HiFi_IFDL}{github.com/CHELSEA234/HiFi-IFDL}.\n",
                "链接": "https://arxiv.org/abs/2303.17111"
            },
            {
                "文章ID": "73032",
                "标题": "Text-guided Image-and-Shape Editing and Generation: A Short Survey",
                "作者": " Cheng-Kang Ted Chao,  Yotam Gingold",
                "发布日期": "2023-04-20",
                "摘要": "  Image and shape editing are ubiquitous among digital artworks. Graphics\nalgorithms facilitate artists and designers to achieve desired editing intents\nwithout going through manually tedious retouching. In the recent advance of\nmachine learning, artists' editing intents can even be driven by text, using a\nvariety of well-trained neural networks. They have seen to be receiving an\nextensive success on such as generating photorealistic images, artworks and\nhuman poses, stylizing meshes from text, or auto-completion given image and\nshape priors. In this short survey, we provide an overview over 50 papers on\nstate-of-the-art (text-guided) image-and-shape generation techniques. We start\nwith an overview on recent editing algorithms in the introduction. Then, we\nprovide a comprehensive review on text-guided editing techniques for 2D and 3D\nindependently, where each of its sub-section begins with a brief background\nintroduction. We also contextualize editing algorithms under recent implicit\nneural representations. Finally, we conclude the survey with the discussion\nover existing methods and potential research ideas.\n",
                "链接": "https://arxiv.org/abs/2304.09244"
            },
            {
                "文章ID": "80167",
                "标题": "BLIP-Diffusion: Pre-trained Subject Representation for Controllable\n  Text-to-Image Generation and Editing",
                "作者": " Dongxu Li,  Junnan Li,  Steven C. H. Hoi",
                "发布日期": "2023-06-23",
                "摘要": "  Subject-driven text-to-image generation models create novel renditions of an\ninput subject based on text prompts. Existing models suffer from lengthy\nfine-tuning and difficulties preserving the subject fidelity. To overcome these\nlimitations, we introduce BLIP-Diffusion, a new subject-driven image generation\nmodel that supports multimodal control which consumes inputs of subject images\nand text prompts. Unlike other subject-driven generation models, BLIP-Diffusion\nintroduces a new multimodal encoder which is pre-trained to provide subject\nrepresentation. We first pre-train the multimodal encoder following BLIP-2 to\nproduce visual representation aligned with the text. Then we design a subject\nrepresentation learning task which enables a diffusion model to leverage such\nvisual representation and generates new subject renditions. Compared with\nprevious methods such as DreamBooth, our model enables zero-shot subject-driven\ngeneration, and efficient fine-tuning for customized subject with up to 20x\nspeedup. We also demonstrate that BLIP-Diffusion can be flexibly combined with\nexisting techniques such as ControlNet and prompt-to-prompt to enable novel\nsubject-driven generation and editing applications. Code and models will be\nreleased at\nhttps://github.com/salesforce/LAVIS/tree/main/projects/blip-diffusion. Project\npage at https://dxli94.github.io/BLIP-Diffusion-website/.\n",
                "链接": "https://arxiv.org/abs/2305.14720"
            },
            {
                "文章ID": "96626",
                "标题": "DragNUWA: Fine-grained Control in Video Generation by Integrating Text,\n  Image, and Trajectory",
                "作者": " Shengming Yin,  Chenfei Wu,  Jian Liang,  Jie Shi,  Houqiang Li,  Gong Ming,  Nan Duan",
                "发布日期": "2023-08-17",
                "摘要": "  Controllable video generation has gained significant attention in recent\nyears. However, two main limitations persist: Firstly, most existing works\nfocus on either text, image, or trajectory-based control, leading to an\ninability to achieve fine-grained control in videos. Secondly, trajectory\ncontrol research is still in its early stages, with most experiments being\nconducted on simple datasets like Human3.6M. This constraint limits the models'\ncapability to process open-domain images and effectively handle complex curved\ntrajectories. In this paper, we propose DragNUWA, an open-domain\ndiffusion-based video generation model. To tackle the issue of insufficient\ncontrol granularity in existing works, we simultaneously introduce text, image,\nand trajectory information to provide fine-grained control over video content\nfrom semantic, spatial, and temporal perspectives. To resolve the problem of\nlimited open-domain trajectory control in current research, We propose\ntrajectory modeling with three aspects: a Trajectory Sampler (TS) to enable\nopen-domain control of arbitrary trajectories, a Multiscale Fusion (MF) to\ncontrol trajectories in different granularities, and an Adaptive Training (AT)\nstrategy to generate consistent videos following trajectories. Our experiments\nvalidate the effectiveness of DragNUWA, demonstrating its superior performance\nin fine-grained control in video generation. The homepage link is\n\\url{https://www.microsoft.com/en-us/research/project/dragnuwa/}\n",
                "链接": "https://arxiv.org/abs/2308.08089"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找风格化机器翻译相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "92370",
                "标题": "Incorporating Human Translator Style into English-Turkish Literary\n  Machine Translation",
                "作者": " Zeynep Yirmibeşoğlu,  Olgun Dursun,  Harun Dallı,  Mehmet Şahin,  Ena Hodzik,  Sabri Gürses,  Tunga Güngör",
                "发布日期": "2023-07-24",
                "摘要": "  Although machine translation systems are mostly designed to serve in the\ngeneral domain, there is a growing tendency to adapt these systems to other\ndomains like literary translation. In this paper, we focus on English-Turkish\nliterary translation and develop machine translation models that take into\naccount the stylistic features of translators. We fine-tune a pre-trained\nmachine translation model by the manually-aligned works of a particular\ntranslator. We make a detailed analysis of the effects of manual and automatic\nalignments, data augmentation methods, and corpus size on the translations. We\npropose an approach based on stylistic features to evaluate the style of a\ntranslator in the output translations. We show that the human translator style\ncan be highly recreated in the target machine translations by adapting the\nmodels to the style of the translator.\n",
                "链接": "https://arxiv.org/abs/2307.11457"
            },
            {
                "文章ID": "49438",
                "标题": "A Theory of Unsupervised Translation Motivated by Understanding Animal\n  Communication",
                "作者": " Shafi Goldwasser,  David F. Gruber,  Adam Tauman Kalai,  Orr Paradise",
                "发布日期": "2023-11-07",
                "摘要": "  Neural networks are capable of translating between languages -- in some cases\neven between two languages where there is little or no access to parallel\ntranslations, in what is known as Unsupervised Machine Translation (UMT). Given\nthis progress, it is intriguing to ask whether machine learning tools can\nultimately enable understanding animal communication, particularly that of\nhighly intelligent animals. We propose a theoretical framework for analyzing\nUMT when no parallel translations are available and when it cannot be assumed\nthat the source and target corpora address related subject domains or posses\nsimilar linguistic structure. We exemplify this theory with two stylized models\nof language, for which our framework provides bounds on necessary sample\ncomplexity; the bounds are formally proven and experimentally verified on\nsynthetic data. These bounds show that the error rates are inversely related to\nthe language complexity and amount of common ground. This suggests that\nunsupervised translation of animal communication may be feasible if the\ncommunication system is sufficiently complex.\n",
                "链接": "https://arxiv.org/abs/2211.11081"
            },
            {
                "文章ID": "107113",
                "标题": "Synslator: An Interactive Machine Translation Tool with Online Learning",
                "作者": " Jiayi Wang,  Ke Wang,  Fengming Zhou,  Chengyu Wang,  Zhiyong Fu,  Zeyu Feng,  Yu Zhao,  Yuqi Zhang",
                "发布日期": "2023-10-10",
                "摘要": "  Interactive machine translation (IMT) has emerged as a progression of the\ncomputer-aided translation paradigm, where the machine translation system and\nthe human translator collaborate to produce high-quality translations. This\npaper introduces Synslator, a user-friendly computer-aided translation (CAT)\ntool that not only supports IMT, but is adept at online learning with real-time\ntranslation memories. To accommodate various deployment environments for CAT\nservices, Synslator integrates two different neural translation models to\nhandle translation memories for online learning. Additionally, the system\nemploys a language model to enhance the fluency of translations in an\ninteractive mode. In evaluation, we have confirmed the effectiveness of online\nlearning through the translation models, and have observed a 13% increase in\npost-editing efficiency with the interactive functionalities of Synslator. A\ntutorial video is available at:https://youtu.be/K0vRsb2lTt8.\n",
                "链接": "https://arxiv.org/abs/2310.05025"
            },
            {
                "文章ID": "32543",
                "标题": "Automatically constructing Wordnet synsets",
                "作者": " Khang Nhut Lam,  Feras Al Tarouti,  Jugal Kalita",
                "发布日期": "2022-10-14",
                "摘要": "  Manually constructing a Wordnet is a difficult task, needing years of\nexperts' time. As a first step to automatically construct full Wordnets, we\npropose approaches to generate Wordnet synsets for languages both resource-rich\nand resource-poor, using publicly available Wordnets, a machine translator\nand/or a single bilingual dictionary. Our algorithms translate synsets of\nexisting Wordnets to a target language T, then apply a ranking method on the\ntranslation candidates to find best translations in T. Our approaches are\napplicable to any language which has at least one existing bilingual dictionary\ntranslating from English to it.\n",
                "链接": "https://arxiv.org/abs/2208.03870"
            },
            {
                "文章ID": "93520",
                "标题": "Multilingual Tourist Assistance using ChatGPT: Comparing Capabilities in\n  Hindi, Telugu, and Kannada",
                "作者": " Sanjana Kolar,  Rohit Kumar",
                "发布日期": "2023-07-31",
                "摘要": "  This research investigates the effectiveness of ChatGPT, an AI language model\nby OpenAI, in translating English into Hindi, Telugu, and Kannada languages,\naimed at assisting tourists in India's linguistically diverse environment. To\nmeasure the translation quality, a test set of 50 questions from diverse fields\nsuch as general knowledge, food, and travel was used. These were assessed by\nfive volunteers for accuracy and fluency, and the scores were subsequently\nconverted into a BLEU score. The BLEU score evaluates the closeness of a\nmachine-generated translation to a human translation, with a higher score\nindicating better translation quality. The Hindi translations outperformed\nothers, showcasing superior accuracy and fluency, whereas Telugu translations\nlagged behind. Human evaluators rated both the accuracy and fluency of\ntranslations, offering a comprehensive perspective on the language model's\nperformance.\n",
                "链接": "https://arxiv.org/abs/2307.15376"
            },
            {
                "文章ID": "56448",
                "标题": "Applying Automated Machine Translation to Educational Video Courses",
                "作者": " Linden Wang",
                "发布日期": "2023-09-20",
                "摘要": "  We studied the capability of automated machine translation in the online\nvideo education space by automatically translating Khan Academy videos with\nstate-of-the-art translation models and applying text-to-speech synthesis and\naudio/video synchronization to build engaging videos in target languages. We\nalso analyzed and established two reliable translation confidence estimators\nbased on round-trip translations in order to efficiently manage translation\nquality and reduce human translation effort. Finally, we developed a deployable\nsystem to deliver translated videos to end users and collect user corrections\nfor iterative improvement.\n",
                "链接": "https://arxiv.org/abs/2301.03141"
            },
            {
                "文章ID": "81117",
                "标题": "Do GPTs Produce Less Literal Translations?",
                "作者": " Vikas Raunak,  Arul Menezes,  Matt Post,  Hany Hassan Awadalla",
                "发布日期": "2023-06-07",
                "摘要": "  Large Language Models (LLMs) such as GPT-3 have emerged as general-purpose\nlanguage models capable of addressing many natural language generation or\nunderstanding tasks. On the task of Machine Translation (MT), multiple works\nhave investigated few-shot prompting mechanisms to elicit better translations\nfrom LLMs. However, there has been relatively little investigation on how such\ntranslations differ qualitatively from the translations generated by standard\nNeural Machine Translation (NMT) models. In this work, we investigate these\ndifferences in terms of the literalness of translations produced by the two\nsystems. Using literalness measures involving word alignment and monotonicity,\nwe find that translations out of English (E-X) from GPTs tend to be less\nliteral, while exhibiting similar or better scores on MT quality metrics. We\ndemonstrate that this finding is borne out in human evaluations as well. We\nthen show that these differences are especially pronounced when translating\nsentences that contain idiomatic expressions.\n",
                "链接": "https://arxiv.org/abs/2305.16806"
            },
            {
                "文章ID": "73945",
                "标题": "UTSGAN: Unseen Transition Suss GAN for Transition-Aware Image-to-image\n  Translation",
                "作者": " Yaxin Shi,  Xiaowei Zhou,  Ping Liu,  Ivor W. Tsang",
                "发布日期": "2023-04-25",
                "摘要": "  In the field of Image-to-Image (I2I) translation, ensuring consistency\nbetween input images and their translated results is a key requirement for\nproducing high-quality and desirable outputs. Previous I2I methods have relied\non result consistency, which enforces consistency between the translated\nresults and the ground truth output, to achieve this goal. However, result\nconsistency is limited in its ability to handle complex and unseen attribute\nchanges in translation tasks. To address this issue, we introduce a\ntransition-aware approach to I2I translation, where the data translation\nmapping is explicitly parameterized with a transition variable, allowing for\nthe modelling of unobserved translations triggered by unseen transitions.\nFurthermore, we propose the use of transition consistency, defined on the\ntransition variable, to enable regularization of consistency on unobserved\ntranslations, which is omitted in previous works. Based on these insights, we\npresent Unseen Transition Suss GAN (UTSGAN), a generative framework that\nconstructs a manifold for the transition with a stochastic transition encoder\nand coherently regularizes and generalizes result consistency and transition\nconsistency on both training and unobserved translations with tailor-designed\nconstraints. Extensive experiments on four different I2I tasks performed on\nfive different datasets demonstrate the efficacy of our proposed UTSGAN in\nperforming consistent translations.\n",
                "链接": "https://arxiv.org/abs/2304.11955"
            },
            {
                "文章ID": "103710",
                "标题": "Automatically Testing Functional Properties of Code Translation Models",
                "作者": " Hasan Ferit Eniser,  Valentin Wüstholz,  Maria Christakis",
                "发布日期": "2023-09-25",
                "摘要": "  Large language models are becoming increasingly practical for translating\ncode across programming languages, a process known as $transpiling$. Even\nthough automated transpilation significantly boosts developer productivity, a\nkey concern is whether the generated code is correct. Existing work initially\nused manually crafted test suites to test the translations of a small corpus of\nprograms; these test suites were later automated. In contrast, we devise the\nfirst approach for automated, functional, property-based testing of code\ntranslation models. Our general, user-provided specifications about the\ntranspiled code capture a range of properties, from purely syntactic to purely\nsemantic ones. As shown by our experiments, this approach is very effective in\ndetecting property violations in popular code translation models, and\ntherefore, in evaluating model quality with respect to given properties. We\nalso go a step further and explore the usage scenario where a user simply aims\nto obtain a correct translation of some code with respect to certain properties\nwithout necessarily being concerned about the overall quality of the model. To\nthis purpose, we develop the first property-guided search procedure for code\ntranslation models, where a model is repeatedly queried with slightly different\nparameters to produce alternative and potentially more correct translations.\nOur results show that this search procedure helps to obtain significantly\nbetter code translations.\n",
                "链接": "https://arxiv.org/abs/2309.12813"
            },
            {
                "文章ID": "48179",
                "标题": "Easy Guided Decoding in Providing Suggestions for Interactive Machine\n  Translation",
                "作者": " Ke Wang,  Xin Ge,  Jiayi Wang,  Yu Zhao,  Yuqi Zhang",
                "发布日期": "2023-06-05",
                "摘要": "  Machine translation technology has made great progress in recent years, but\nit cannot guarantee error free results. Human translators perform post editing\non machine translations to correct errors in the scene of computer aided\ntranslation. In favor of expediting the post editing process, many works have\ninvestigated machine translation in interactive modes, in which machines can\nautomatically refine the rest of translations constrained by human's edits.\nTranslation Suggestion (TS), as an interactive mode to assist human\ntranslators, requires machines to generate alternatives for specific incorrect\nwords or phrases selected by human translators. In this paper, we utilize the\nparameterized objective function of neural machine translation (NMT) and\npropose a novel constrained decoding algorithm, namely Prefix Suffix Guided\nDecoding (PSGD), to deal with the TS problem without additional training.\nCompared to the state of the art lexically constrained decoding method, PSGD\nimproves translation quality by an average of $10.87$ BLEU and $8.62$ BLEU on\nthe WeTS and the WMT 2022 Translation Suggestion datasets, respectively, and\nreduces decoding time overhead by an average of 63.4% tested on the WMT\ntranslation datasets. Furthermore, on both of the TS benchmark datasets, it is\nsuperior to other supervised learning systems trained with TS annotated data.\n",
                "链接": "https://arxiv.org/abs/2211.07093"
            }
        ]
    },
    {
        "question": {
            "question": "查找中文ner常用的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "6079",
                "标题": "TURNER: The Uncertainty-based Retrieval Framework for Chinese NER",
                "作者": " Zhichao Geng,  Hang Yan,  Zhangyue Yin,  Chenxin An,  Xipeng Qiu",
                "发布日期": "2022-02-21",
                "摘要": "  Chinese NER is a difficult undertaking due to the ambiguity of Chinese\ncharacters and the absence of word boundaries. Previous work on Chinese NER\nfocus on lexicon-based methods to introduce boundary information and reduce\nout-of-vocabulary (OOV) cases during prediction. However, it is expensive to\nobtain and dynamically maintain high-quality lexicons in specific domains,\nwhich motivates us to utilize more general knowledge resources, e.g., search\nengines. In this paper, we propose TURNER: The Uncertainty-based Retrieval\nframework for Chinese NER. The idea behind TURNER is to imitate human behavior:\nwe frequently retrieve auxiliary knowledge as assistance when encountering an\nunknown or uncertain entity. To improve the efficiency and effectiveness of\nretrieval, we first propose two types of uncertainty sampling methods for\nselecting the most ambiguous entity-level uncertain components of the input\ntext. Then, the Knowledge Fusion Model re-predict the uncertain samples by\ncombining retrieved knowledge. Experiments on four benchmark datasets\ndemonstrate TURNER's effectiveness. TURNER outperforms existing lexicon-based\napproaches and achieves the new SOTA.\n",
                "链接": "https://arxiv.org/abs/2202.09022"
            },
            {
                "文章ID": "5948",
                "标题": "AISHELL-NER: Named Entity Recognition from Chinese Speech",
                "作者": " Boli Chen,  Guangwei Xu,  Xiaobin Wang,  Pengjun Xie,  Meishan Zhang,  Fei Huang",
                "发布日期": "2022-02-18",
                "摘要": "  Named Entity Recognition (NER) from speech is among Spoken Language\nUnderstanding (SLU) tasks, aiming to extract semantic information from the\nspeech signal. NER from speech is usually made through a two-step pipeline that\nconsists of (1) processing the audio using an Automatic Speech Recognition\n(ASR) system and (2) applying an NER tagger to the ASR outputs. Recent works\nhave shown the capability of the End-to-End (E2E) approach for NER from English\nand French speech, which is essentially entity-aware ASR. However, due to the\nmany homophones and polyphones that exist in Chinese, NER from Chinese speech\nis effectively a more challenging task. In this paper, we introduce a new\ndataset AISEHLL-NER for NER from Chinese speech. Extensive experiments are\nconducted to explore the performance of several state-of-the-art methods. The\nresults demonstrate that the performance could be improved by combining\nentity-aware ASR and pretrained NER tagger, which can be easily applied to the\nmodern SLU pipeline. The dataset is publicly available at\ngithub.com/Alibaba-NLP/AISHELL-NER.\n",
                "链接": "https://arxiv.org/abs/2202.08533"
            },
            {
                "文章ID": "44485",
                "标题": "Improving Chinese Named Entity Recognition by Search Engine Augmentation",
                "作者": " Qinghua Mao,  Jiatong Li,  Kui Meng",
                "发布日期": "2022-10-25",
                "摘要": "  Compared with English, Chinese suffers from more grammatical ambiguities,\nlike fuzzy word boundaries and polysemous words. In this case, contextual\ninformation is not sufficient to support Chinese named entity recognition\n(NER), especially for rare and emerging named entities. Semantic augmentation\nusing external knowledge is a potential way to alleviate this problem, while\nhow to obtain and leverage external knowledge for the NER task remains a\nchallenge. In this paper, we propose a neural-based approach to perform\nsemantic augmentation using external knowledge from search engine for Chinese\nNER. In particular, a multi-channel semantic fusion model is adopted to\ngenerate the augmented input representations, which aggregates external related\ntexts retrieved from the search engine. Experiments have shown the superiority\nof our model across 4 NER datasets, including formal and social media language\ncontexts, which further prove the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2210.12662"
            },
            {
                "文章ID": "125250",
                "标题": "Unified Lattice Graph Fusion for Chinese Named Entity Recognition",
                "作者": " Dixiang Zhang,  Junyu Lu,  Pingjian Zhang",
                "发布日期": "2023-12-29",
                "摘要": "  Integrating lexicon into character-level sequence has been proven effective\nto leverage word boundary and semantic information in Chinese named entity\nrecognition (NER). However, prior approaches usually utilize feature weighting\nand position coupling to integrate word information, but ignore the semantic\nand contextual correspondence between the fine-grained semantic units in the\ncharacter-word space. To solve this issue, we propose a Unified Lattice Graph\nFusion (ULGF) approach for Chinese NER. ULGF can explicitly capture various\nsemantic and boundary relations across different semantic units with the\nadjacency matrix by converting the lattice structure into a unified graph. We\nstack multiple graph-based intra-source self-attention and inter-source\ncross-gating fusion layers that iteratively carry out semantic interactions to\nlearn node representations. To alleviate the over-reliance on word information,\nwe further propose to leverage lexicon entity classification as an auxiliary\ntask. Experiments on four Chinese NER benchmark datasets demonstrate the\nsuperiority of our ULGF approach.\n",
                "链接": "https://arxiv.org/abs/2312.16917"
            },
            {
                "文章ID": "28049",
                "标题": "Rethinking the Value of Gazetteer in Chinese Named Entity Recognition",
                "作者": " Qianglong Chen,  Xiangji Zeng,  Jiangang Zhu,  Yin Zhang,  Bojia Lin,  Yang Yang,  Daxin Jiang",
                "发布日期": "2022-07-19",
                "摘要": "  Gazetteer is widely used in Chinese named entity recognition (NER) to enhance\nspan boundary detection and type classification. However, to further understand\nthe generalizability and effectiveness of gazetteers, the NLP community still\nlacks a systematic analysis of the gazetteer-enhanced NER model. In this paper,\nwe first re-examine the effectiveness several common practices of the\ngazetteer-enhanced NER models and carry out a series of detailed analysis to\nevaluate the relationship between the model performance and the gazetteer\ncharacteristics, which can guide us to build a more suitable gazetteer. The\nfindings of this paper are as follows: (1) the gazetteer improves most of the\nsituations that the traditional NER model datasets are difficult to learn. (2)\nthe performance of model greatly benefits from the high-quality pre-trained\nlexeme embeddings. (3) a good gazetteer should cover more entities that can be\nmatched in both the training set and testing set.\n",
                "链接": "https://arxiv.org/abs/2207.02802"
            },
            {
                "文章ID": "15120",
                "标题": "Qtrade AI at SemEval-2022 Task 11: An Unified Framework for Multilingual\n  NER Task",
                "作者": " Weichao Gan,  Yuanping Lin,  Guangbo Yu,  Guimin Chen,  Qian Ye",
                "发布日期": "2022-04-18",
                "摘要": "  This paper describes our system, which placed third in the Multilingual Track\n(subtask 11), fourth in the Code-Mixed Track (subtask 12), and seventh in the\nChinese Track (subtask 9) in the SemEval 2022 Task 11: MultiCoNER Multilingual\nComplex Named Entity Recognition. Our system's key contributions are as\nfollows: 1) For multilingual NER tasks, we offer an unified framework with\nwhich one can easily execute single-language or multilingual NER tasks, 2) for\nlow-resource code-mixed NER task, one can easily enhance his or her dataset\nthrough implementing several simple data augmentation methods and 3) for\nChinese tasks, we propose a model that can capture Chinese lexical semantic,\nlexical border, and lexical graph structural information. Finally, our system\nachieves macro-f1 scores of 77.66, 84.35, and 74.00 on subtasks 11, 12, and 9,\nrespectively, during the testing phase.\n",
                "链接": "https://arxiv.org/abs/2204.07459"
            },
            {
                "文章ID": "108977",
                "标题": "Empirical Study of Zero-Shot NER with ChatGPT",
                "作者": " Tingyu Xie,  Qi Li,  Jian Zhang,  Yan Zhang,  Zuozhu Liu,  Hongwei Wang",
                "发布日期": "2023-10-17",
                "摘要": "  Large language models (LLMs) exhibited powerful capability in various natural\nlanguage processing tasks. This work focuses on exploring LLM performance on\nzero-shot information extraction, with a focus on the ChatGPT and named entity\nrecognition (NER) task. Inspired by the remarkable reasoning capability of LLM\non symbolic and arithmetic reasoning, we adapt the prevalent reasoning methods\nto NER and propose reasoning strategies tailored for NER. First, we explore a\ndecomposed question-answering paradigm by breaking down the NER task into\nsimpler subproblems by labels. Second, we propose syntactic augmentation to\nstimulate the model's intermediate thinking in two ways: syntactic prompting,\nwhich encourages the model to analyze the syntactic structure itself, and tool\naugmentation, which provides the model with the syntactic information generated\nby a parsing tool. Besides, we adapt self-consistency to NER by proposing a\ntwo-stage majority voting strategy, which first votes for the most consistent\nmentions, then the most consistent types. The proposed methods achieve\nremarkable improvements for zero-shot NER across seven benchmarks, including\nChinese and English datasets, and on both domain-specific and general-domain\nscenarios. In addition, we present a comprehensive analysis of the error types\nwith suggestions for optimization directions. We also verify the effectiveness\nof the proposed methods on the few-shot setting and other LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.10035"
            },
            {
                "文章ID": "35129",
                "标题": "Domain-Specific NER via Retrieving Correlated Samples",
                "作者": " Xin Zhang,  Yong Jiang,  Xiaobin Wang,  Xuming Hu,  Yueheng Sun,  Pengjun Xie,  Meishan Zhang",
                "发布日期": "2022-09-29",
                "摘要": "  Successful Machine Learning based Named Entity Recognition models could fail\non texts from some special domains, for instance, Chinese addresses and\ne-commerce titles, where requires adequate background knowledge. Such texts are\nalso difficult for human annotators. In fact, we can obtain some potentially\nhelpful information from correlated texts, which have some common entities, to\nhelp the text understanding. Then, one can easily reason out the correct answer\nby referencing correlated samples. In this paper, we suggest enhancing NER\nmodels with correlated samples. We draw correlated samples by the sparse BM25\nretriever from large-scale in-domain unlabeled data. To explicitly simulate the\nhuman reasoning process, we perform a training-free entity type calibrating by\nmajority voting. To capture correlation features in the training stage, we\nsuggest to model correlated samples by the transformer-based multi-instance\ncross-encoder. Empirical results on datasets of the above two domains show the\nefficacy of our methods.\n",
                "链接": "https://arxiv.org/abs/2208.12995"
            },
            {
                "文章ID": "75893",
                "标题": "LLM-RM at SemEval-2023 Task 2: Multilingual Complex NER using\n  XLM-RoBERTa",
                "作者": " Rahul Mehta,  Vasudeva Varma",
                "发布日期": "2023-05-08",
                "摘要": "  Named Entity Recognition(NER) is a task of recognizing entities at a token\nlevel in a sentence. This paper focuses on solving NER tasks in a multilingual\nsetting for complex named entities. Our team, LLM-RM participated in the\nrecently organized SemEval 2023 task, Task 2: MultiCoNER II,Multilingual\nComplex Named Entity Recognition. We approach the problem by leveraging\ncross-lingual representation provided by fine-tuning XLM-Roberta base model on\ndatasets of all of the 12 languages provided -- Bangla, Chinese, English,\nFarsi, French, German, Hindi, Italian, Portuguese, Spanish, Swedish and\nUkrainian\n",
                "链接": "https://arxiv.org/abs/2305.03300"
            },
            {
                "文章ID": "12836",
                "标题": "$k$NN-NER: Named Entity Recognition with Nearest Neighbor Search",
                "作者": " Shuhe Wang,  Xiaoya Li,  Yuxian Meng,  Tianwei Zhang,  Rongbin Ouyang,  Jiwei Li,  Guoyin Wang",
                "发布日期": "2022-04-01",
                "摘要": "  Inspired by recent advances in retrieval augmented methods in\nNLP~\\citep{khandelwal2019generalization,khandelwal2020nearest,meng2021gnn}, in\nthis paper, we introduce a $k$ nearest neighbor NER ($k$NN-NER) framework,\nwhich augments the distribution of entity labels by assigning $k$ nearest\nneighbors retrieved from the training set. This strategy makes the model more\ncapable of handling long-tail cases, along with better few-shot learning\nabilities. $k$NN-NER requires no additional operation during the training\nphase, and by interpolating $k$ nearest neighbors search into the vanilla NER\nmodel, $k$NN-NER consistently outperforms its vanilla counterparts: we achieve\na new state-of-the-art F1-score of 72.03 (+1.25) on the Chinese Weibo dataset\nand improved results on a variety of widely used NER benchmarks. Additionally,\nwe show that $k$NN-NER can achieve comparable results to the vanilla NER model\nwith 40\\% less amount of training data. Code available at\n\\url{https://github.com/ShannonAI/KNN-NER}.\n",
                "链接": "https://arxiv.org/abs/2203.17103"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下最近用反事实做数据增强的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "36857",
                "标题": "Bias Challenges in Counterfactual Data Augmentation",
                "作者": " S Chandra Mouli,  Yangze Zhou,  Bruno Ribeiro",
                "发布日期": "2022-09-15",
                "摘要": "  Deep learning models tend not to be out-of-distribution robust primarily due\nto their reliance on spurious features to solve the task. Counterfactual data\naugmentations provide a general way of (approximately) achieving\nrepresentations that are counterfactual-invariant to spurious features, a\nrequirement for out-of-distribution (OOD) robustness. In this work, we show\nthat counterfactual data augmentations may not achieve the desired\ncounterfactual-invariance if the augmentation is performed by a\ncontext-guessing machine, an abstract machine that guesses the most-likely\ncontext of a given input. We theoretically analyze the invariance imposed by\nsuch counterfactual data augmentations and describe an exemplar NLP task where\ncounterfactual data augmentation by a context-guessing machine does not lead to\nrobust OOD classifiers.\n",
                "链接": "https://arxiv.org/abs/2209.05104"
            },
            {
                "文章ID": "81687",
                "标题": "On Counterfactual Data Augmentation Under Confounding",
                "作者": " Abbavaram Gowtham Reddy,  Saketh Bachu,  Saloni Dash,  Charchit Sharma,  Amit Sharma,  Vineeth N Balasubramanian",
                "发布日期": "2023-11-22",
                "摘要": "  Counterfactual data augmentation has recently emerged as a method to mitigate\nconfounding biases in the training data. These biases, such as spurious\ncorrelations, arise due to various observed and unobserved confounding\nvariables in the data generation process. In this paper, we formally analyze\nhow confounding biases impact downstream classifiers and present a causal\nviewpoint to the solutions based on counterfactual data augmentation. We\nexplore how removing confounding biases serves as a means to learn invariant\nfeatures, ultimately aiding in generalization beyond the observed data\ndistribution. Additionally, we present a straightforward yet powerful algorithm\nfor generating counterfactual images, which effectively mitigates the influence\nof confounding effects on downstream classifiers. Through experiments on MNIST\nvariants and the CelebA datasets, we demonstrate how our simple augmentation\nmethod helps existing state-of-the-art methods achieve good results.\n",
                "链接": "https://arxiv.org/abs/2305.18183"
            },
            {
                "文章ID": "74413",
                "标题": "Implicit Counterfactual Data Augmentation for Deep Neural Networks",
                "作者": " Xiaoling Zhou,  Ou Wu",
                "发布日期": "2023-04-27",
                "摘要": "  Machine-learning models are prone to capturing the spurious correlations\nbetween non-causal attributes and classes, with counterfactual data\naugmentation being a promising direction for breaking these spurious\nassociations. However, explicitly generating counterfactual data is\nchallenging, with the training efficiency declining. Therefore, this study\nproposes an implicit counterfactual data augmentation (ICDA) method to remove\nspurious correlations and make stable predictions. Specifically, first, a novel\nsample-wise augmentation strategy is developed that generates semantically and\ncounterfactually meaningful deep features with distinct augmentation strength\nfor each sample. Second, we derive an easy-to-compute surrogate loss on the\naugmented feature set when the number of augmented samples becomes infinite.\nThird, two concrete schemes are proposed, including direct quantification and\nmeta-learning, to derive the key parameters for the robust loss. In addition,\nICDA is explained from a regularization aspect, with extensive experiments\nindicating that our method consistently improves the generalization performance\nof popular depth networks on multiple typical learning scenarios that require\nout-of-distribution generalization.\n",
                "链接": "https://arxiv.org/abs/2304.13431"
            },
            {
                "文章ID": "114161",
                "标题": "Counterfactual Data Augmentation with Contrastive Learning",
                "作者": " Ahmed Aloui,  Juncheng Dong,  Cat P. Le,  Vahid Tarokh",
                "发布日期": "2023-11-08",
                "摘要": "  Statistical disparity between distinct treatment groups is one of the most\nsignificant challenges for estimating Conditional Average Treatment Effects\n(CATE). To address this, we introduce a model-agnostic data augmentation method\nthat imputes the counterfactual outcomes for a selected subset of individuals.\nSpecifically, we utilize contrastive learning to learn a representation space\nand a similarity measure such that in the learned representation space close\nindividuals identified by the learned similarity measure have similar potential\noutcomes. This property ensures reliable imputation of counterfactual outcomes\nfor the individuals with close neighbors from the alternative treatment group.\nBy augmenting the original dataset with these reliable imputations, we can\neffectively reduce the discrepancy between different treatment groups, while\ninducing minimal imputation error. The augmented dataset is subsequently\nemployed to train CATE estimation models. Theoretical analysis and experimental\nstudies on synthetic and semi-synthetic benchmarks demonstrate that our method\nachieves significant improvements in both performance and robustness to\noverfitting across state-of-the-art models.\n",
                "链接": "https://arxiv.org/abs/2311.03630"
            },
            {
                "文章ID": "45900",
                "标题": "Counterfactual Data Augmentation via Perspective Transition for\n  Open-Domain Dialogues",
                "作者": " Jiao Ou,  Jinchao Zhang,  Yang Feng,  Jie Zhou",
                "发布日期": "2022-11-01",
                "摘要": "  The construction of open-domain dialogue systems requires high-quality\ndialogue datasets. The dialogue data admits a wide variety of responses for a\ngiven dialogue history, especially responses with different semantics. However,\ncollecting high-quality such a dataset in most scenarios is labor-intensive and\ntime-consuming. In this paper, we propose a data augmentation method to\nautomatically augment high-quality responses with different semantics by\ncounterfactual inference. Specifically, given an observed dialogue, our\ncounterfactual generation model first infers semantically different responses\nby replacing the observed reply perspective with substituted ones. Furthermore,\nour data selection method filters out detrimental augmented responses.\nExperimental results show that our data augmentation method can augment\nhigh-quality responses with different semantics for a given dialogue history,\nand can outperform competitive baselines on multiple downstream tasks.\n",
                "链接": "https://arxiv.org/abs/2210.16838"
            },
            {
                "文章ID": "86799",
                "标题": "A Novel Counterfactual Data Augmentation Method for Aspect-Based\n  Sentiment Analysis",
                "作者": " Dongming Wu,  Lulu Wen,  Chao Chen,  Zhaoshu Shi",
                "发布日期": "2023-10-10",
                "摘要": "  Aspect-based-sentiment-analysis (ABSA) is a fine-grained sentiment evaluation\ntask, which analyzes the emotional polarity of the evaluation aspects.\nGenerally, the emotional polarity of an aspect exists in the corresponding\nopinion expression, whose diversity has great impact on model's performance. To\nmitigate this problem, we propose a novel and simple counterfactual data\naugmentation method to generate opinion expressions with reversed sentiment\npolarity. In particular, the integrated gradients are calculated to locate and\nmask the opinion expression. Then, a prompt combined with the reverse\nexpression polarity is added to the original text, and a Pre-trained language\nmodel (PLM), T5, is finally was employed to predict the masks. The experimental\nresults shows the proposed counterfactual data augmentation method performs\nbetter than current augmentation methods on three ABSA datasets, i.e. Laptop,\nRestaurant, and MAMS.\n",
                "链接": "https://arxiv.org/abs/2306.11260"
            },
            {
                "文章ID": "21004",
                "标题": "Counterfactual Data Augmentation improves Factuality of Abstractive\n  Summarization",
                "作者": " Dheeraj Rajagopal,  Siamak Shakeri,  Cicero Nogueira dos Santos,  Eduard Hovy,  Chung-Ching Chang",
                "发布日期": "2022-05-26",
                "摘要": "  Abstractive summarization systems based on pretrained language models often\ngenerate coherent but factually inconsistent sentences. In this paper, we\npresent a counterfactual data augmentation approach where we augment data with\nperturbed summaries that increase the training data diversity. Specifically, we\npresent three augmentation approaches based on replacing (i) entities from\nother and the same category and (ii) nouns with their corresponding WordNet\nhypernyms. We show that augmenting the training data with our approach improves\nthe factual correctness of summaries without significantly affecting the ROUGE\nscore. We show that in two commonly used summarization datasets (CNN/Dailymail\nand XSum), we improve the factual correctness by about 2.5 points on average\n",
                "链接": "https://arxiv.org/abs/2205.12416"
            },
            {
                "文章ID": "43960",
                "标题": "MoCoDA: Model-based Counterfactual Data Augmentation",
                "作者": " Silviu Pitis,  Elliot Creager,  Ajay Mandlekar,  Animesh Garg",
                "发布日期": "2022-10-21",
                "摘要": "  The number of states in a dynamic process is exponential in the number of\nobjects, making reinforcement learning (RL) difficult in complex, multi-object\ndomains. For agents to scale to the real world, they will need to react to and\nreason about unseen combinations of objects. We argue that the ability to\nrecognize and use local factorization in transition dynamics is a key element\nin unlocking the power of multi-object reasoning. To this end, we show that (1)\nknown local structure in the environment transitions is sufficient for an\nexponential reduction in the sample complexity of training a dynamics model,\nand (2) a locally factored dynamics model provably generalizes\nout-of-distribution to unseen states and actions. Knowing the local structure\nalso allows us to predict which unseen states and actions this dynamics model\nwill generalize to. We propose to leverage these observations in a novel\nModel-based Counterfactual Data Augmentation (MoCoDA) framework. MoCoDA applies\na learned locally factored dynamics model to an augmented distribution of\nstates and actions to generate counterfactual transitions for RL. MoCoDA works\nwith a broader set of local structures than prior work and allows for direct\ncontrol over the augmented training distribution. We show that MoCoDA enables\nRL agents to learn policies that generalize to unseen states and actions. We\nuse MoCoDA to train an offline RL agent to solve an out-of-distribution\nrobotics manipulation task on which standard offline RL algorithms fail.\n",
                "链接": "https://arxiv.org/abs/2210.11287"
            },
            {
                "文章ID": "110605",
                "标题": "EXPLAIN, EDIT, GENERATE: Rationale-Sensitive Counterfactual Data\n  Augmentation for Multi-hop Fact Verification",
                "作者": " Yingjie Zhu,  Jiasheng Si,  Yibo Zhao,  Haiyang Zhu,  Deyu Zhou,  Yulan He",
                "发布日期": "2023-10-24",
                "摘要": "  Automatic multi-hop fact verification task has gained significant attention\nin recent years. Despite impressive results, these well-designed models perform\npoorly on out-of-domain data. One possible solution is to augment the training\ndata with counterfactuals, which are generated by minimally altering the causal\nfeatures of the original data. However, current counterfactual data\naugmentation techniques fail to handle multi-hop fact verification due to their\nincapability to preserve the complex logical relationships within multiple\ncorrelated texts. In this paper, we overcome this limitation by developing a\nrationale-sensitive method to generate linguistically diverse and\nlabel-flipping counterfactuals while preserving logical relationships. In\nspecific, the diverse and fluent counterfactuals are generated via an\nExplain-Edit-Generate architecture. Moreover, the checking and filtering\nmodules are proposed to regularize the counterfactual data with logical\nrelations and flipped labels. Experimental results show that the proposed\napproach outperforms the SOTA baselines and can generate linguistically diverse\ncounterfactual data without disrupting their logical relationships.\n",
                "链接": "https://arxiv.org/abs/2310.14508"
            },
            {
                "文章ID": "88864",
                "标题": "Counterfactual Collaborative Reasoning",
                "作者": " Jianchao Ji,  Zelong Li,  Shuyuan Xu,  Max Xiong,  Juntao Tan,  Yingqiang Ge,  Hao Wang,  Yongfeng Zhang",
                "发布日期": "2023-07-06",
                "摘要": "  Causal reasoning and logical reasoning are two important types of reasoning\nabilities for human intelligence. However, their relationship has not been\nextensively explored under machine intelligence context. In this paper, we\nexplore how the two reasoning abilities can be jointly modeled to enhance both\naccuracy and explainability of machine learning models. More specifically, by\nintegrating two important types of reasoning ability -- counterfactual\nreasoning and (neural) logical reasoning -- we propose Counterfactual\nCollaborative Reasoning (CCR), which conducts counterfactual logic reasoning to\nimprove the performance. In particular, we use recommender system as an example\nto show how CCR alleviate data scarcity, improve accuracy and enhance\ntransparency. Technically, we leverage counterfactual reasoning to generate\n\"difficult\" counterfactual training examples for data augmentation, which --\ntogether with the original training examples -- can enhance the model\nperformance. Since the augmented data is model irrelevant, they can be used to\nenhance any model, enabling the wide applicability of the technique. Besides,\nmost of the existing data augmentation methods focus on \"implicit data\naugmentation\" over users' implicit feedback, while our framework conducts\n\"explicit data augmentation\" over users explicit feedback based on\ncounterfactual logic reasoning. Experiments on three real-world datasets show\nthat CCR achieves better performance than non-augmented models and implicitly\naugmented models, and also improves model transparency by generating\ncounterfactual explanations.\n",
                "链接": "https://arxiv.org/abs/2307.00165"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用蒙特卡罗树搜索解决序列决策问题的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "71411",
                "标题": "Improving Performance Insensitivity of Large-scale Multiobjective\n  Optimization via Monte Carlo Tree Search",
                "作者": " Haokai Hong,  Min Jiang,  Gary G. Yen",
                "发布日期": "2023-04-17",
                "摘要": "  The large-scale multiobjective optimization problem (LSMOP) is characterized\nby simultaneously optimizing multiple conflicting objectives and involving\nhundreds of decision variables. Many real-world applications in engineering\nfields can be modeled as LSMOPs; simultaneously, engineering applications\nrequire insensitivity in performance. This requirement usually means that the\nresults from the algorithm runs should not only be good for every run in terms\nof performance but also that the performance of multiple runs should not\nfluctuate too much, i.e., the algorithm shows good insensitivity. Considering\nthat substantial computational resources are requested for each run, it is\nessential to improve upon the performance of the large-scale multiobjective\noptimization algorithm, as well as the insensitivity of the algorithm. However,\nexisting large-scale multiobjective optimization algorithms solely focus on\nimproving the performance of the algorithms, leaving the insensitivity\ncharacteristics unattended. In this work, we propose an evolutionary algorithm\nfor solving LSMOPs based on Monte Carlo tree search, the so-called LMMOCTS,\nwhich aims to improve the performance and insensitivity for large-scale\nmultiobjective optimization problems. The proposed method samples the decision\nvariables to construct new nodes on the Monte Carlo tree for optimization and\nevaluation. It selects nodes with good evaluation for further search to reduce\nthe performance sensitivity caused by large-scale decision variables. We\ncompare the proposed algorithm with several state-of-the-art designs on\ndifferent benchmark functions. We also propose two metrics to measure the\nsensitivity of the algorithm. The experimental results confirm the\neffectiveness and performance insensitivity of the proposed design for solving\nlarge-scale multiobjective optimization problems.\n",
                "链接": "https://arxiv.org/abs/2304.04071"
            },
            {
                "文章ID": "98469",
                "标题": "Diverse, Top-k, and Top-Quality Planning Over Simulators",
                "作者": " Lyndon Benke,  Tim Miller,  Michael Papasimeon,  Nir Lipovetzky",
                "发布日期": "2023-08-28",
                "摘要": "  Diverse, top-k, and top-quality planning are concerned with the generation of\nsets of solutions to sequential decision problems. Previously this area has\nbeen the domain of classical planners that require a symbolic model of the\nproblem instance. This paper proposes a novel alternative approach that uses\nMonte Carlo Tree Search (MCTS), enabling application to problems for which only\na black-box simulation model is available. We present a procedure for\nextracting bounded sets of plans from pre-generated search trees in best-first\norder, and a metric for evaluating the relative quality of paths through a\nsearch tree. We demonstrate this approach on a path-planning problem with\nhidden information, and suggest adaptations to the MCTS algorithm to increase\nthe diversity of generated plans. Our results show that our method can generate\ndiverse and high-quality plan sets in domains where classical planners are not\napplicable.\n",
                "链接": "https://arxiv.org/abs/2308.13147"
            },
            {
                "文章ID": "40416",
                "标题": "Continuous Monte Carlo Graph Search",
                "作者": " Kalle Kujanpää,  Amin Babadi,  Yi Zhao,  Juho Kannala,  Alexander Ilin,  Joni Pajarinen",
                "发布日期": "2023-07-19",
                "摘要": "  In many complex sequential decision-making tasks, online planning is crucial\nfor high performance. For efficient online planning, Monte Carlo Tree Search\n(MCTS) employs a principled mechanism for trading off exploration for\nexploitation. MCTS outperforms comparison methods in many discrete\ndecision-making domains such as Go, Chess, and Shogi. Following, extensions of\nMCTS to continuous domains have been proposed. However, the inherent high\nbranching factor and the resulting explosion of search tree size are limiting\nexisting methods. To address this problem, we propose Continuous Monte Carlo\nGraph Search (CMCGS), a novel extension of MCTS to online planning in\nenvironments with continuous state and action spaces. CMCGS takes advantage of\nthe insight that, during planning, sharing the same action policy between\nseveral states can yield high performance. To implement this idea, at each time\nstep, CMCGS clusters similar states into a limited number of stochastic action\nbandit nodes, which produce a layered directed graph instead of an MCTS search\ntree. Experimental evaluation shows that CMCGS outperforms comparable planning\nmethods in several complex continuous DeepMind Control Suite benchmarks and a\n2D navigation task with limited sample budgets. Furthermore, CMCGS can be\nparallelized to scale up and it outperforms the Cross-Entropy Method (CEM) in\ncontinuous control with learned dynamics models.\n",
                "链接": "https://arxiv.org/abs/2210.01426"
            },
            {
                "文章ID": "108378",
                "标题": "LightZero: A Unified Benchmark for Monte Carlo Tree Search in General\n  Sequential Decision Scenarios",
                "作者": " Yazhe Niu,  Yuan Pu,  Zhenjie Yang,  Xueyan Li,  Tong Zhou,  Jiyuan Ren,  Shuai Hu,  Hongsheng Li,  Yu Liu",
                "发布日期": "2023-10-13",
                "摘要": "  Building agents based on tree-search planning capabilities with learned\nmodels has achieved remarkable success in classic decision-making problems,\nsuch as Go and Atari. However, it has been deemed challenging or even\ninfeasible to extend Monte Carlo Tree Search (MCTS) based algorithms to diverse\nreal-world applications, especially when these environments involve complex\naction spaces and significant simulation costs, or inherent stochasticity. In\nthis work, we introduce LightZero, the first unified benchmark for deploying\nMCTS/MuZero in general sequential decision scenarios. Specificially, we\nsummarize the most critical challenges in designing a general MCTS-style\ndecision-making solver, then decompose the tightly-coupled algorithm and system\ndesign of tree-search RL methods into distinct sub-modules. By incorporating\nmore appropriate exploration and optimization strategies, we can significantly\nenhance these sub-modules and construct powerful LightZero agents to tackle\ntasks across a wide range of domains, such as board games, Atari, MuJoCo,\nMiniGrid and GoBigger. Detailed benchmark results reveal the significant\npotential of such methods in building scalable and efficient decision\nintelligence. The code is available as part of OpenDILab at\nhttps://github.com/opendilab/LightZero.\n",
                "链接": "https://arxiv.org/abs/2310.08348"
            },
            {
                "文章ID": "5515",
                "标题": "A Unified Perspective on Value Backup and Exploration in Monte-Carlo\n  Tree Search",
                "作者": " Tuan Dam,  Carlo D'Eramo,  Jan Peters,  Joni Pajarinen",
                "发布日期": "2022-02-16",
                "摘要": "  Monte-Carlo Tree Search (MCTS) is a class of methods for solving complex\ndecision-making problems through the synergy of Monte-Carlo planning and\nReinforcement Learning (RL). The highly combinatorial nature of the problems\ncommonly addressed by MCTS requires the use of efficient exploration strategies\nfor navigating the planning tree and quickly convergent value backup methods.\nThese crucial problems are particularly evident in recent advances that combine\nMCTS with deep neural networks for function approximation. In this work, we\npropose two methods for improving the convergence rate and exploration based on\na newly introduced backup operator and entropy regularization. We provide\nstrong theoretical guarantees to bound convergence rate, approximation error,\nand regret of our methods. Moreover, we introduce a mathematical framework\nbased on the use of the $\\alpha$-divergence for backup and exploration in MCTS.\nWe show that this theoretical formulation unifies different approaches,\nincluding our newly introduced ones, under the same mathematical framework,\nallowing to obtain different methods by simply changing the value of $\\alpha$.\nIn practice, our unified perspective offers a flexible way to balance between\nexploration and exploitation by tuning the single $\\alpha$ parameter according\nto the problem at hand. We validate our methods through a rigorous empirical\nstudy from basic toy problems to the complex Atari games, and including both\nMDP and POMDP problems.\n",
                "链接": "https://arxiv.org/abs/2202.07071"
            },
            {
                "文章ID": "66610",
                "标题": "Beyond Games: A Systematic Review of Neural Monte Carlo Tree Search\n  Applications",
                "作者": " Marco Kemmerling,  Daniel Lütticke,  Robert H. Schmitt",
                "发布日期": "2023-12-29",
                "摘要": "  The advent of AlphaGo and its successors marked the beginning of a new\nparadigm in playing games using artificial intelligence. This was achieved by\ncombining Monte Carlo tree search, a planning procedure, and deep learning.\nWhile the impact on the domain of games has been undeniable, it is less clear\nhow useful similar approaches are in applications beyond games and how they\nneed to be adapted from the original methodology. We review 129 peer-reviewed\narticles detailing the application of neural Monte Carlo tree search methods in\ndomains other than games. Our goal is to systematically assess how such methods\nare structured in practice and if their success can be extended to other\ndomains. We find applications in a variety of domains, many distinct ways of\nguiding the tree search using learned policy and value functions, and various\ntraining methods. Our review maps the current landscape of algorithms in the\nfamily of neural monte carlo tree search as they are applied to practical\nproblems, which is a first step towards a more principled way of designing such\nalgorithms for specific problems and their requirements.\n",
                "链接": "https://arxiv.org/abs/2303.08060"
            },
            {
                "文章ID": "75072",
                "标题": "Nearly Optimal Steiner Trees using Graph Neural Network Assisted Monte\n  Carlo Tree Search",
                "作者": " Reyan Ahmed,  Mithun Ghosh,  Kwang-Sung Jun,  Stephen Kobourov",
                "发布日期": "2023-05-02",
                "摘要": "  Graph neural networks are useful for learning problems, as well as for\ncombinatorial and graph problems such as the Subgraph Isomorphism Problem and\nthe Traveling Salesman Problem. We describe an approach for computing Steiner\nTrees by combining a graph neural network and Monte Carlo Tree Search. We first\ntrain a graph neural network that takes as input a partial solution and\nproposes a new node to be added as output. This neural network is then used in\na Monte Carlo search to compute a Steiner tree. The proposed method\nconsistently outperforms the standard 2-approximation algorithm on many\ndifferent types of graphs and often finds the optimal solution.\n",
                "链接": "https://arxiv.org/abs/2305.00535"
            },
            {
                "文章ID": "27474",
                "标题": "An AlphaZero-Inspired Approach to Solving Search Problems",
                "作者": " Evgeny Dantsin,  Vladik Kreinovich,  Alexander Wolpert",
                "发布日期": "2022-07-05",
                "摘要": "  AlphaZero and its extension MuZero are computer programs that use\nmachine-learning techniques to play at a superhuman level in chess, go, and a\nfew other games. They achieved this level of play solely with reinforcement\nlearning from self-play, without any domain knowledge except the game rules. It\nis a natural idea to adapt the methods and techniques used in AlphaZero for\nsolving search problems such as the Boolean satisfiability problem (in its\nsearch version). Given a search problem, how to represent it for an\nAlphaZero-inspired solver? What are the \"rules of solving\" for this search\nproblem? We describe possible representations in terms of easy-instance solvers\nand self-reductions, and we give examples of such representations for the\nsatisfiability problem. We also describe a version of Monte Carlo tree search\nadapted for search problems.\n",
                "链接": "https://arxiv.org/abs/2207.00919"
            },
            {
                "文章ID": "49945",
                "标题": "UNSAT Solver Synthesis via Monte Carlo Forest Search",
                "作者": " Chris Cameron,  Jason Hartford,  Taylor Lundy,  Tuan Truong,  Alan Milligan,  Rex Chen,  Kevin Leyton-Brown",
                "发布日期": "2023-05-29",
                "摘要": "  We introduce Monte Carlo Forest Search (MCFS), a class of reinforcement\nlearning (RL) algorithms for learning policies in {tree MDPs}, for which policy\nexecution involves traversing an exponential-sized tree. Examples of such\nproblems include proving unsatisfiability of a SAT formula; counting the number\nof solutions of a satisfiable SAT formula; and finding the optimal solution to\na mixed-integer program. MCFS algorithms can be seen as extensions of Monte\nCarlo Tree Search (MCTS) to cases where, rather than finding a good path\n(solution) within a tree, the problem is to find a small tree within a forest\nof candidate trees. We instantiate and evaluate our ideas in an algorithm that\nwe dub Knuth Synthesis, an MCFS algorithm that learns DPLL branching policies\nfor solving the Boolean satisfiability (SAT) problem, with the objective of\nachieving good average-case performance on a given distribution of\nunsatisfiable problem instances. Knuth Synthesis leverages two key ideas to\navoid the prohibitive costs of policy evaluations in an exponentially-sized\ntree. First, we estimate tree size by randomly sampling paths and measuring\ntheir lengths, drawing on an unbiased approximation due to Knuth (1975).\nSecond, we query a strong solver at a user-defined depth rather than learning a\npolicy across the whole tree, to focus our policy search on early decisions\nthat offer the greatest potential for reducing tree size. We matched or\nimproved performance over a strong baseline on three well-known SAT\ndistributions (R3SAT, sgen, satfc).\n",
                "链接": "https://arxiv.org/abs/2211.12581"
            },
            {
                "文章ID": "106127",
                "标题": "Rollout Heuristics for Online Stochastic Contingent Planning",
                "作者": " Oded Blumenthal,  Guy Shani",
                "发布日期": "2023-10-05",
                "摘要": "  Partially observable Markov decision processes (POMDP) are a useful model for\ndecision-making under partial observability and stochastic actions. Partially\nObservable Monte-Carlo Planning is an online algorithm for deciding on the next\naction to perform, using a Monte-Carlo tree search approach, based on the UCT\n(UCB applied to trees) algorithm for fully observable Markov-decision\nprocesses. POMCP develops an action-observation tree, and at the leaves, uses a\nrollout policy to provide a value estimate for the leaf. As such, POMCP is\nhighly dependent on the rollout policy to compute good estimates, and hence\nidentify good actions. Thus, many practitioners who use POMCP are required to\ncreate strong, domain-specific heuristics.\n  In this paper, we model POMDPs as stochastic contingent planning problems.\nThis allows us to leverage domain-independent heuristics that were developed in\nthe planning community. We suggest two heuristics, the first is based on the\nwell-known h_add heuristic from classical planning, and the second is computed\nin belief space, taking the value of information into account.\n",
                "链接": "https://arxiv.org/abs/2310.02345"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用gpt4做评测指标优缺点的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "116110",
                "标题": "Enhancing Medical Text Evaluation with GPT-4",
                "作者": " Yiqing Xie,  Sheng Zhang,  Hao Cheng,  Zelalem Gero,  Cliff Wong,  Tristan Naumann,  Hoifung Poon",
                "发布日期": "2023-11-17",
                "摘要": "  In the evaluation of medical text generation, it is essential to scrutinize\neach piece of information and ensure the utmost accuracy of the evaluation.\nExisting evaluation metrics either focus on coarse-level evaluation that\nassigns one score for the whole generated output or rely on evaluation models\ntrained on general domain, resulting in inaccuracies when adapted to the\nmedical domain. To address these issues, we propose a set of factuality-centric\nevaluation aspects and design corresponding GPT-4-based metrics for medical\ntext generation. We systematically compare these metrics with existing ones on\nclinical note generation and medical report summarization tasks, revealing low\ninter-metric correlation. A comprehensive human evaluation confirms that the\nproposed GPT-4-based metrics exhibit substantially higher agreement with human\njudgments than existing evaluation metrics. Our study contributes to the\nunderstanding of medical text generation evaluation and offers a more reliable\nalternative to existing metrics.\n",
                "链接": "https://arxiv.org/abs/2311.09581"
            },
            {
                "文章ID": "110350",
                "标题": "Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large\n  Language Models on Sequence to Sequence Tasks",
                "作者": " Andrea Sottana,  Bin Liang,  Kai Zou,  Zheng Yuan",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) evaluation is a patchy and inconsistent\nlandscape, and it is becoming clear that the quality of automatic evaluation\nmetrics is not keeping up with the pace of development of generative models. We\naim to improve the understanding of current models' performance by providing a\npreliminary and hybrid evaluation on a range of open and closed-source\ngenerative LLMs on three NLP benchmarks: text summarisation, text\nsimplification and grammatical error correction (GEC), using both automatic and\nhuman evaluation. We also explore the potential of the recently released GPT-4\nto act as an evaluator. We find that ChatGPT consistently outperforms many\nother popular models according to human reviewers on the majority of metrics,\nwhile scoring much more poorly when using classic automatic evaluation metrics.\nWe also find that human reviewers rate the gold reference as much worse than\nthe best models' outputs, indicating the poor quality of many popular\nbenchmarks. Finally, we find that GPT-4 is capable of ranking models' outputs\nin a way which aligns reasonably closely to human judgement despite\ntask-specific variations, with a lower alignment in the GEC task.\n",
                "链接": "https://arxiv.org/abs/2310.13800"
            },
            {
                "文章ID": "69609",
                "标题": "G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment",
                "作者": " Yang Liu,  Dan Iter,  Yichong Xu,  Shuohang Wang,  Ruochen Xu,  Chenguang Zhu",
                "发布日期": "2023-05-25",
                "摘要": "  The quality of texts generated by natural language generation (NLG) systems\nis hard to measure automatically. Conventional reference-based metrics, such as\nBLEU and ROUGE, have been shown to have relatively low correlation with human\njudgments, especially for tasks that require creativity and diversity. Recent\nstudies suggest using large language models (LLMs) as reference-free metrics\nfor NLG evaluation, which have the benefit of being applicable to new tasks\nthat lack human references. However, these LLM-based evaluators still have\nlower human correspondence than medium-size neural evaluators. In this work, we\npresent G-Eval, a framework of using large language models with\nchain-of-thoughts (CoT) and a form-filling paradigm, to assess the quality of\nNLG outputs. We experiment with two generation tasks, text summarization and\ndialogue generation. We show that G-Eval with GPT-4 as the backbone model\nachieves a Spearman correlation of 0.514 with human on summarization task,\noutperforming all previous methods by a large margin. We also propose\npreliminary analysis on the behavior of LLM-based evaluators, and highlight the\npotential issue of LLM-based evaluators having a bias towards the LLM-generated\ntexts. The code is at https://github.com/nlpyang/geval\n",
                "链接": "https://arxiv.org/abs/2303.16634"
            },
            {
                "文章ID": "71129",
                "标题": "Instruction Tuning with GPT-4",
                "作者": " Baolin Peng,  Chunyuan Li,  Pengcheng He,  Michel Galley,  Jianfeng Gao",
                "发布日期": "2023-04-07",
                "摘要": "  Prior work has shown that finetuning large language models (LLMs) using\nmachine-generated instruction-following data enables such models to achieve\nremarkable zero-shot capabilities on new tasks, and no human-written\ninstructions are needed. In this paper, we present the first attempt to use\nGPT-4 to generate instruction-following data for LLM finetuning. Our early\nexperiments on instruction-tuned LLaMA models show that the 52K English and\nChinese instruction-following data generated by GPT-4 leads to superior\nzero-shot performance on new tasks to the instruction-following data generated\nby previous state-of-the-art models. We also collect feedback and comparison\ndata from GPT-4 to enable a comprehensive evaluation and reward model training.\nWe make our data generated using GPT-4 as well as our codebase publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2304.03277"
            },
            {
                "文章ID": "115172",
                "标题": "Evaluation of GPT-4 for chest X-ray impression generation: A reader\n  study on performance and perception",
                "作者": " Sebastian Ziegelmayer,  Alexander W. Marka,  Nicolas Lenhart,  Nadja Nehls,  Stefan Reischl,  Felix Harder,  Andreas Sauter,  Marcus Makowski,  Markus Graf,  Joshua Gawlitza",
                "发布日期": "2023-12-27",
                "摘要": "  The remarkable generative capabilities of multimodal foundation models are\ncurrently being explored for a variety of applications. Generating radiological\nimpressions is a challenging task that could significantly reduce the workload\nof radiologists. In our study we explored and analyzed the generative abilities\nof GPT-4 for Chest X-ray impression generation. To generate and evaluate\nimpressions of chest X-rays based on different input modalities (image, text,\ntext and image), a blinded radiological report was written for 25-cases of the\npublicly available NIH-dataset. GPT-4 was given image, finding section or both\nsequentially to generate an input dependent impression. In a blind randomized\nreading, 4-radiologists rated the impressions and were asked to classify the\nimpression origin (Human, AI), providing justification for their decision.\nLastly text model evaluation metrics and their correlation with the\nradiological score (summation of the 4 dimensions) was assessed. According to\nthe radiological score, the human-written impression was rated highest,\nalthough not significantly different to text-based impressions. The automated\nevaluation metrics showed moderate to substantial correlations to the\nradiological score for the image impressions, however individual scores were\nhighly divergent among inputs, indicating insufficient representation of\nradiological quality. Detection of AI-generated impressions varied by input and\nwas 61% for text-based impressions. Impressions classified as AI-generated had\nsignificantly worse radiological scores even when written by a radiologist,\nindicating potential bias. Our study revealed significant discrepancies between\na radiological assessment and common automatic evaluation metrics depending on\nthe model input. The detection of AI-generated findings is subject to bias that\nhighly rated impressions are perceived as human-written.\n",
                "链接": "https://arxiv.org/abs/2311.06815"
            },
            {
                "文章ID": "80356",
                "标题": "Is GPT-4 a Good Data Analyst?",
                "作者": " Liying Cheng,  Xingxuan Li,  Lidong Bing",
                "发布日期": "2023-10-24",
                "摘要": "  As large language models (LLMs) have demonstrated their powerful capabilities\nin plenty of domains and tasks, including context understanding, code\ngeneration, language generation, data storytelling, etc., many data analysts\nmay raise concerns if their jobs will be replaced by artificial intelligence\n(AI). This controversial topic has drawn great attention in public. However, we\nare still at a stage of divergent opinions without any definitive conclusion.\nMotivated by this, we raise the research question of \"is GPT-4 a good data\nanalyst?\" in this work and aim to answer it by conducting head-to-head\ncomparative studies. In detail, we regard GPT-4 as a data analyst to perform\nend-to-end data analysis with databases from a wide range of domains. We\npropose a framework to tackle the problems by carefully designing the prompts\nfor GPT-4 to conduct experiments. We also design several task-specific\nevaluation metrics to systematically compare the performance between several\nprofessional human data analysts and GPT-4. Experimental results show that\nGPT-4 can achieve comparable performance to humans. We also provide in-depth\ndiscussions about our results to shed light on further studies before reaching\nthe conclusion that GPT-4 can replace data analysts.\n",
                "链接": "https://arxiv.org/abs/2305.15038"
            },
            {
                "文章ID": "95177",
                "标题": "GPT-4 Can't Reason",
                "作者": " Konstantine Arkoudas",
                "发布日期": "2023-08-11",
                "摘要": "  GPT-4 was released in March 2023 to wide acclaim, marking a very substantial\nimprovement across the board over GPT-3.5 (OpenAI's previously best model,\nwhich had powered the initial release of ChatGPT). However, despite the\ngenuinely impressive improvement, there are good reasons to be highly skeptical\nof GPT-4's ability to reason. This position paper discusses the nature of\nreasoning; criticizes the current formulation of reasoning problems in the NLP\ncommunity, as well as the way in which LLM reasoning performance is currently\nevaluated; introduces a small collection of 21 diverse reasoning problems; and\nperforms a detailed qualitative evaluation of GPT-4's performance on those\nproblems. Based on this analysis, the paper concludes that, despite its\noccasional flashes of analytical brilliance, GPT-4 at present is utterly\nincapable of reasoning.\n",
                "链接": "https://arxiv.org/abs/2308.03762"
            },
            {
                "文章ID": "112047",
                "标题": "Using GPT-4 to Augment Unbalanced Data for Automatic Scoring",
                "作者": " Luyang Fang,  Gyeong-Geon Lee,  Xiaoming Zhai",
                "发布日期": "2023-11-21",
                "摘要": "  Machine learning-based automatic scoring can be challenging if students'\nresponses are unbalanced across scoring categories, as it introduces\nuncertainty in the machine training process. To meet this challenge, we\nintroduce a novel text data augmentation framework using GPT-4, a generative\nlarge language model, specifically tailored for unbalanced datasets in\nautomatic scoring. Our experimental dataset comprised student-written responses\nto two science items. We crafted prompts for GPT-4 to generate responses\nresembling student-written answers, particularly for the minority scoring\nclasses, to augment the data. We then finetuned DistillBERT for automatic\nscoring based on the augmented and original datasets. Model performance was\nassessed using accuracy, precision, recall, and F1 score. We incorporate varied\namounts of augmented data to examine scoring performance, and our findings\nrevealed remarkedly improved model performance. The average maximum increase\nobserved across two items is: 3.5% for accuracy, 30.6% for precision, 21.1% for\nrecall, and 24.2% for F1 score. Notably, using just 5% of the augmented data\nled to substantial improvements: 2.6%, 29.2%, 15.1%, and 19.6%. Interestingly,\nthe extent of improvement varied depending on specific datasets. Moreover, we\nfound that a varying amount of augmented data (5%-40%) was needed to obtain a\nstable improvement. We also compare models trained with GPT-4 augmented data\nand those trained with additional student-written responses. The findings\nindicate that former ones match or even exceed the performance of the latter.\nSpecifically, there is an average difference of 1.7%, 1.9%, 11.0%, and 7.8% for\nfour metrics separately. This research underscores the potential and\neffectiveness of data augmentation techniques utilizing GPT-4 in addressing\nunbalanced datasets within automated assessment.\n",
                "链接": "https://arxiv.org/abs/2310.18365"
            },
            {
                "文章ID": "74335",
                "标题": "AI-assisted coding: Experiments with GPT-4",
                "作者": " Russell A Poldrack,  Thomas Lu,  Gašper Beguš",
                "发布日期": "2023-04-27",
                "摘要": "  Artificial intelligence (AI) tools based on large language models have\nacheived human-level performance on some computer programming tasks. We report\nseveral experiments using GPT-4 to generate computer code. These experiments\ndemonstrate that AI code generation using the current generation of tools,\nwhile powerful, requires substantial human validation to ensure accurate\nperformance. We also demonstrate that GPT-4 refactoring of existing code can\nsignificantly improve that code along several established metrics for code\nquality, and we show that GPT-4 can generate tests with substantial coverage,\nbut that many of the tests fail when applied to the associated code. These\nfindings suggest that while AI coding tools are very powerful, they still\nrequire humans in the loop to ensure validity and accuracy of the results.\n",
                "链接": "https://arxiv.org/abs/2304.13187"
            },
            {
                "文章ID": "57762",
                "标题": "Robot Skill Learning Via Classical Robotics-Based Generated Datasets:\n  Advantages, Disadvantages, and Future Improvement",
                "作者": " Batu Kaan Oezen",
                "发布日期": "2023-01-24",
                "摘要": "  Why do we not profit from our long-existing classical robotics knowledge and\nlook for some alternative way for data collection? The situation ignoring all\nexisting methods might be such a waste. This article argues that a dataset\ncreated using a classical robotics algorithm is a crucial part of future\ndevelopment. This developed classic algorithm has a perfect domain adaptation\nand generalization property, and most importantly, collecting datasets based on\nthem is quite easy. It is well known that current robot skill-learning\napproaches perform exceptionally badly in the unseen domain, and their\nperformance against adversarial attacks is quite limited as long as they do not\nhave a very exclusive big dataset. Our experiment is the initial steps of using\na dataset created by classical robotics codes. Our experiment investigated\npossible trajectory collection based on classical robotics. It addressed some\nadvantages and disadvantages and pointed out other future development ideas.\n",
                "链接": "https://arxiv.org/abs/2301.08794"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用GPT4v完成多模态智能体的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "115991",
                "标题": "Comparing Humans, GPT-4, and GPT-4V On Abstraction and Reasoning Tasks",
                "作者": " Melanie Mitchell,  Alessandro B. Palmarini,  Arseny Moskvichev",
                "发布日期": "2023-12-25",
                "摘要": "  We explore the abstract reasoning abilities of text-only and multimodal\nversions of GPT-4, using the ConceptARC benchmark [10], which is designed to\nevaluate robust understanding and reasoning with core-knowledge concepts. We\nextend the work of Moskvichev et al. [10] by evaluating GPT-4 on more detailed,\none-shot prompting (rather than simple, zero-shot prompts) with text versions\nof ConceptARC tasks, and by evaluating GPT-4V, the multimodal version of GPT-4,\non zero- and one-shot prompts using image versions of the simplest tasks. Our\nexperimental results support the conclusion that neither version of GPT-4 has\ndeveloped robust abstraction abilities at humanlike levels.\n",
                "链接": "https://arxiv.org/abs/2311.09247"
            },
            {
                "文章ID": "66852",
                "标题": "GPT-4 Technical Report",
                "作者": "Rai   OpenAI, Rai   :, Rai  Josh Achiam, Rai  Steven Adler, Rai  Sandhini Agarwal, Rai  Lama Ahmad, Rai  Ilge Akkaya, Rai  Florencia Leoni Aleman, Rai  Diogo Almeida, Rai  Janko Altenschmidt, Rai  Sam Altman, Rai  Shyamal Anadkat, Rai  Red Avila, Rai  Igor Babuschkin, Rai  Suchir Balaji, Rai  Valerie Balcom, Rai  Paul Baltescu, Rai  Haiming Bao, Rai  Mo Bavarian, Rai  Jeff Belgum, Rai  Irwan Bello, Rai  Jake Berdine, Rai  Gabriel Bernadett-Shapiro, Rai  Christopher Berner, Rai  Lenny Bogdonoff, Rai  Oleg Boiko, Rai  Madelaine Boyd, Rai  Anna-Luisa Brakman, Rai  Greg Brockman, Rai  Tim Brooks, Rai  Miles Brundage, Rai  Kevin Button, Rai  Trevor Cai, Rai  Rosie Campbell, Rai  Andrew Cann, Rai  Brittany Carey, Rai  Chelsea Carlson, Rai  Rory Carmichael, Rai  Brooke Chan, Rai  Che Chang, Rai  Fotis Chantzis, Rai  Derek Chen, Rai  Sully Chen, Rai  Ruby Chen, Rai  Jason Chen, Rai  Mark Chen, Rai  Ben Chess, Rai  Chester Cho, Rai  Casey Chu, Rai  Hyung Won Chung, Rai  Dave Cummings, Rai  Jeremiah Currier, Rai  Yunxing Dai, Rai  Cory Decareaux, Rai  Thomas Degry, Rai  Noah Deutsch, Rai  Damien Deville, Rai  Arka Dhar, Rai  David Dohan, Rai  Steve Dowling, Rai  Sheila Dunning, Rai  Adrien Ecoffet, Rai  Atty Eleti, Rai  Tyna Eloundou, Rai  David Farhi, Rai  Liam Fedus, Rai  Niko Felix, Rai  Simón Posada Fishman, Rai  Juston Forte, Rai  Isabella Fulford, Rai  Leo Gao, Rai  Elie Georges, Rai  Christian Gibson, Rai  Vik Goel, Rai  Tarun Gogineni, Rai  Gabriel Goh, Rai  Rapha Gontijo-Lopes, Rai  Jonathan Gordon, Rai  Morgan Grafstein, Rai  Scott Gray, Rai  Ryan Greene, Rai  Joshua Gross, Rai  Shixiang Shane Gu, Rai  Yufei Guo, Rai  Chris Hallacy, Rai  Jesse Han, Rai  Jeff Harris, Rai  Yuchen He, Rai  Mike Heaton, Rai  Johannes Heidecke, Rai  Chris Hesse, Rai  Alan Hickey, Rai  Wade Hickey, Rai  Peter Hoeschele, Rai  Brandon Houghton, Rai  Kenny Hsu, Rai  Shengli Hu, Rai  Xin Hu, Rai  Joost Huizinga, Rai  Shantanu Jain, Rai  Shawn Jain, Rai  Joanne Jang, Rai  Angela Jiang, Rai  Roger Jiang, Rai  Haozhun Jin, Rai  Denny Jin, Rai  Shino Jomoto, Rai  Billie Jonn, Rai  Heewoo Jun, Rai  Tomer Kaftan, Rai  Łukasz Kaiser, Rai  Ali Kamali, Rai  Ingmar Kanitscheider, Rai  Nitish Shirish Keskar, Rai  Tabarak Khan, Rai  Logan Kilpatrick, Rai  Jong Wook Kim, Rai  Christina Kim, Rai  Yongjik Kim, Rai  Hendrik Kirchner, Rai  Jamie Kiros, Rai  Matt Knight, Rai  Daniel Kokotajlo, Rai  Łukasz Kondraciuk, Rai  Andrew Kondrich, Rai  Aris Konstantinidis, Rai  Kyle Kosic, Rai  Gretchen Krueger, Rai  Vishal Kuo, Rai  Michael Lampe, Rai  Ikai Lan, Rai  Teddy Lee, Rai  Jan Leike, Rai  Jade Leung, Rai  Daniel Levy, Rai  Chak Ming Li, Rai  Rachel Lim, Rai  Molly Lin, Rai  Stephanie Lin, Rai  Mateusz Litwin, Rai  Theresa Lopez, Rai  Ryan Lowe, Rai  Patricia Lue, Rai  Anna Makanju, Rai  Kim Malfacini, Rai  Sam Manning, Rai  Todor Markov, Rai  Yaniv Markovski, Rai  Bianca Martin, Rai  Katie Mayer, Rai  Andrew Mayne, Rai  Bob McGrew, Rai  Scott Mayer McKinney, Rai  Christine McLeavey, Rai  Paul McMillan, Rai  Jake McNeil, Rai  David Medina, Rai  Aalok Mehta, Rai  Jacob Menick, Rai  Luke Metz, Rai  Andrey Mishchenko, Rai  Pamela Mishkin, Rai  Vinnie Monaco, Rai  Evan Morikawa, Rai  Daniel Mossing, Rai  Tong Mu, Rai  Mira Murati, Rai  Oleg Murk, Rai  David Mély, Rai  Ashvin Nair, Rai  Reiichiro Nakano, Rai  Rajeev Nayak, Rai  Arvind Neelakantan, Rai  Richard Ngo, Rai  Hyeonwoo Noh, Rai  Long Ouyang, Rai  Cullen O'Keefe, Rai  Jakub Pachocki, Rai  Alex Paino, Rai  Joe Palermo, Rai  Ashley Pantuliano, Rai  Giambattista Parascandolo, Rai  Joel Parish, Rai  Emy Parparita, Rai  Alex Passos, Rai  Mikhail Pavlov, Rai  Andrew Peng, Rai  Adam Perelman, Rai  Filipe de Avila Belbute Peres, Rai  Michael Petrov, Rai  Henrique Ponde de Oliveira Pinto, Rai   Michael,   Pokorny,  Michelle Pokrass,  Vitchyr Pong,  Tolly Powell,  Alethea Power,  Boris Power,  Elizabeth Proehl,  Raul Puri,  Alec Radford,  Jack Rae,  Aditya Ramesh,  Cameron Raymond,  Francis Real,  Kendra Rimbach,  Carl Ross,  Bob Rotsted,  Henri Roussez,  Nick Ryder,  Mario Saltarelli,  Ted Sanders,  Shibani Santurkar,  Girish Sastry,  Heather Schmidt,  David Schnurr,  John Schulman,  Daniel Selsam,  Kyla Sheppard,  Toki Sherbakov,  Jessica Shieh,  Sarah Shoker,  Pranav Shyam,  Szymon Sidor,  Eric Sigler,  Maddie Simens,  Jordan Sitkin,  Katarina Slama,  Ian Sohl,  Benjamin Sokolowsky,  Yang Song,  Natalie Staudacher,  Felipe Petroski Such,  Natalie Summers,  Ilya Sutskever,  Jie Tang,  Nikolas Tezak,  Madeleine Thompson,  Phil Tillet,  Amin Tootoonchian,  Elizabeth Tseng,  Preston Tuggle,  Nick Turley,  Jerry Tworek,  Juan Felipe Cerón Uribe,  Andrea Vallone,  Arun Vijayvergiya,  Chelsea Voss,  Carroll Wainwright,  Justin Jay Wang,  Alvin Wang,  Ben Wang,  Jonathan Ward,  Jason Wei,  CJ Weinmann,  Akila Welihinda,  Peter Welinder,  Jiayi Weng,  Lilian Weng,  Matt Wiethoff,  Dave Willner,  Clemens Winter,  Samuel Wolrich,  Hannah Wong,  Lauren Workman,  Sherwin Wu,  Jeff Wu,  Michael Wu,  Kai Xiao,  Tao Xu,  Sarah Yoo,  Kevin Yu,  Qiming Yuan,  Wojciech Zaremba,  Rowan Zellers,  Chong Zhang,  Marvin Zhang,  Shengjia Zhao,  Tianhao Zheng,  Juntang Zhuang,  William Zhuk,  Barret Zoph",
                "发布日期": "2023-12-20",
                "摘要": "  We report the development of GPT-4, a large-scale, multimodal model which can\naccept image and text inputs and produce text outputs. While less capable than\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance on\nvarious professional and academic benchmarks, including passing a simulated bar\nexam with a score around the top 10% of test takers. GPT-4 is a\nTransformer-based model pre-trained to predict the next token in a document.\nThe post-training alignment process results in improved performance on measures\nof factuality and adherence to desired behavior. A core component of this\nproject was developing infrastructure and optimization methods that behave\npredictably across a wide range of scales. This allowed us to accurately\npredict some aspects of GPT-4's performance based on models trained with no\nmore than 1/1,000th the compute of GPT-4.\n",
                "链接": "https://arxiv.org/abs/2303.08774"
            },
            {
                "文章ID": "95177",
                "标题": "GPT-4 Can't Reason",
                "作者": " Konstantine Arkoudas",
                "发布日期": "2023-08-11",
                "摘要": "  GPT-4 was released in March 2023 to wide acclaim, marking a very substantial\nimprovement across the board over GPT-3.5 (OpenAI's previously best model,\nwhich had powered the initial release of ChatGPT). However, despite the\ngenuinely impressive improvement, there are good reasons to be highly skeptical\nof GPT-4's ability to reason. This position paper discusses the nature of\nreasoning; criticizes the current formulation of reasoning problems in the NLP\ncommunity, as well as the way in which LLM reasoning performance is currently\nevaluated; introduces a small collection of 21 diverse reasoning problems; and\nperforms a detailed qualitative evaluation of GPT-4's performance on those\nproblems. Based on this analysis, the paper concludes that, despite its\noccasional flashes of analytical brilliance, GPT-4 at present is utterly\nincapable of reasoning.\n",
                "链接": "https://arxiv.org/abs/2308.03762"
            },
            {
                "文章ID": "71129",
                "标题": "Instruction Tuning with GPT-4",
                "作者": " Baolin Peng,  Chunyuan Li,  Pengcheng He,  Michel Galley,  Jianfeng Gao",
                "发布日期": "2023-04-07",
                "摘要": "  Prior work has shown that finetuning large language models (LLMs) using\nmachine-generated instruction-following data enables such models to achieve\nremarkable zero-shot capabilities on new tasks, and no human-written\ninstructions are needed. In this paper, we present the first attempt to use\nGPT-4 to generate instruction-following data for LLM finetuning. Our early\nexperiments on instruction-tuned LLaMA models show that the 52K English and\nChinese instruction-following data generated by GPT-4 leads to superior\nzero-shot performance on new tasks to the instruction-following data generated\nby previous state-of-the-art models. We also collect feedback and comparison\ndata from GPT-4 to enable a comprehensive evaluation and reward model training.\nWe make our data generated using GPT-4 as well as our codebase publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2304.03277"
            },
            {
                "文章ID": "68454",
                "标题": "Capabilities of GPT-4 on Medical Challenge Problems",
                "作者": " Harsha Nori,  Nicholas King,  Scott Mayer McKinney,  Dean Carignan,  Eric Horvitz",
                "发布日期": "2023-04-13",
                "摘要": "  Large language models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding and generation across various domains, including\nmedicine. We present a comprehensive evaluation of GPT-4, a state-of-the-art\nLLM, on medical competency examinations and benchmark datasets. GPT-4 is a\ngeneral-purpose model that is not specialized for medical problems through\ntraining or engineered to solve clinical tasks. Our analysis covers two sets of\nofficial practice materials for the USMLE, a three-step examination program\nused to assess clinical competency and grant licensure in the United States. We\nalso evaluate performance on the MultiMedQA suite of benchmark datasets. Beyond\nmeasuring model performance, experiments were conducted to investigate the\ninfluence of test questions containing both text and images on model\nperformance, probe for memorization of content during training, and study\nprobability calibration, which is of critical importance in high-stakes\napplications like medicine. Our results show that GPT-4, without any\nspecialized prompt crafting, exceeds the passing score on USMLE by over 20\npoints and outperforms earlier general-purpose models (GPT-3.5) as well as\nmodels specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned\nversion of Flan-PaLM 540B). In addition, GPT-4 is significantly better\ncalibrated than GPT-3.5, demonstrating a much-improved ability to predict the\nlikelihood that its answers are correct. We also explore the behavior of the\nmodel qualitatively through a case study that shows the ability of GPT-4 to\nexplain medical reasoning, personalize explanations to students, and\ninteractively craft new counterfactual scenarios around a medical case.\nImplications of the findings are discussed for potential uses of GPT-4 in\nmedical education, assessment, and clinical practice, with appropriate\nattention to challenges of accuracy and safety.\n",
                "链接": "https://arxiv.org/abs/2303.13375"
            },
            {
                "文章ID": "69729",
                "标题": "Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission\n  Exams",
                "作者": " Desnes Nunes,  Ricardo Primi,  Ramon Pires,  Roberto Lotufo,  Rodrigo Nogueira",
                "发布日期": "2023-03-31",
                "摘要": "  The present study aims to explore the capabilities of Language Models (LMs)\nin tackling high-stakes multiple-choice tests, represented here by the Exame\nNacional do Ensino M\\'edio (ENEM), a multidisciplinary entrance examination\nwidely adopted by Brazilian universities. This exam poses challenging tasks for\nLMs, since its questions may span into multiple fields of knowledge, requiring\nunderstanding of information from diverse domains. For instance, a question may\nrequire comprehension of both statistics and biology to be solved. This work\nanalyzed responses generated by GPT-3.5 and GPT-4 models for questions\npresented in the 2009-2017 exams, as well as for questions of the 2022 exam,\nwhich were made public after the training of the models was completed.\nFurthermore, different prompt strategies were tested, including the use of\nChain-of-Thought (CoT) prompts to generate explanations for answers. On the\n2022 edition, the best-performing model, GPT-4 with CoT, achieved an accuracy\nof 87%, largely surpassing GPT-3.5 by 11 points. The code and data used on\nexperiments are available at https://github.com/piresramon/gpt-4-enem.\n",
                "链接": "https://arxiv.org/abs/2303.17003"
            },
            {
                "文章ID": "112047",
                "标题": "Using GPT-4 to Augment Unbalanced Data for Automatic Scoring",
                "作者": " Luyang Fang,  Gyeong-Geon Lee,  Xiaoming Zhai",
                "发布日期": "2023-11-21",
                "摘要": "  Machine learning-based automatic scoring can be challenging if students'\nresponses are unbalanced across scoring categories, as it introduces\nuncertainty in the machine training process. To meet this challenge, we\nintroduce a novel text data augmentation framework using GPT-4, a generative\nlarge language model, specifically tailored for unbalanced datasets in\nautomatic scoring. Our experimental dataset comprised student-written responses\nto two science items. We crafted prompts for GPT-4 to generate responses\nresembling student-written answers, particularly for the minority scoring\nclasses, to augment the data. We then finetuned DistillBERT for automatic\nscoring based on the augmented and original datasets. Model performance was\nassessed using accuracy, precision, recall, and F1 score. We incorporate varied\namounts of augmented data to examine scoring performance, and our findings\nrevealed remarkedly improved model performance. The average maximum increase\nobserved across two items is: 3.5% for accuracy, 30.6% for precision, 21.1% for\nrecall, and 24.2% for F1 score. Notably, using just 5% of the augmented data\nled to substantial improvements: 2.6%, 29.2%, 15.1%, and 19.6%. Interestingly,\nthe extent of improvement varied depending on specific datasets. Moreover, we\nfound that a varying amount of augmented data (5%-40%) was needed to obtain a\nstable improvement. We also compare models trained with GPT-4 augmented data\nand those trained with additional student-written responses. The findings\nindicate that former ones match or even exceed the performance of the latter.\nSpecifically, there is an average difference of 1.7%, 1.9%, 11.0%, and 7.8% for\nfour metrics separately. This research underscores the potential and\neffectiveness of data augmentation techniques utilizing GPT-4 in addressing\nunbalanced datasets within automated assessment.\n",
                "链接": "https://arxiv.org/abs/2310.18365"
            },
            {
                "文章ID": "70587",
                "标题": "GPT-4 to GPT-3.5: 'Hold My Scalpel' -- A Look at the Competency of\n  OpenAI's GPT on the Plastic Surgery In-Service Training Exam",
                "作者": " Jonathan D. Freedman,  Ian A. Nappier",
                "发布日期": "2023-04-05",
                "摘要": "  The Plastic Surgery In-Service Training Exam (PSITE) is an important\nindicator of resident proficiency and serves as a useful benchmark for\nevaluating OpenAI's GPT. Unlike many of the simulated tests or practice\nquestions shown in the GPT-4 Technical Paper, the multiple-choice questions\nevaluated here are authentic PSITE questions. These questions offer realistic\nclinical vignettes that a plastic surgeon commonly encounters in practice and\nscores highly correlate with passing the written boards required to become a\nBoard Certified Plastic Surgeon. Our evaluation shows dramatic improvement of\nGPT-4 (without vision) over GPT-3.5 with both the 2022 and 2021 exams\nrespectively increasing the score from 8th to 88th percentile and 3rd to 99th\npercentile. The final results of the 2023 PSITE are set to be released on April\n11, 2023, and this is an exciting moment to continue our research with a fresh\nexam. Our evaluation pipeline is ready for the moment that the exam is released\nso long as we have access via OpenAI to the GPT-4 API. With multimodal input,\nwe may achieve superhuman performance on the 2023.\n",
                "链接": "https://arxiv.org/abs/2304.01503"
            },
            {
                "文章ID": "88221",
                "标题": "Evaluating GPT-3.5 and GPT-4 on Grammatical Error Correction for\n  Brazilian Portuguese",
                "作者": " Maria Carolina Penteado,  Fábio Perez",
                "发布日期": "2023-07-19",
                "摘要": "  We investigate the effectiveness of GPT-3.5 and GPT-4, two large language\nmodels, as Grammatical Error Correction (GEC) tools for Brazilian Portuguese\nand compare their performance against Microsoft Word and Google Docs. We\nintroduce a GEC dataset for Brazilian Portuguese with four categories: Grammar,\nSpelling, Internet, and Fast typing. Our results show that while GPT-4 has\nhigher recall than other methods, LLMs tend to have lower precision, leading to\novercorrection. This study demonstrates the potential of LLMs as practical GEC\ntools for Brazilian Portuguese and encourages further exploration of LLMs for\nnon-English languages and other educational settings.\n",
                "链接": "https://arxiv.org/abs/2306.15788"
            },
            {
                "文章ID": "124407",
                "标题": "Exploiting Novel GPT-4 APIs",
                "作者": " Kellin Pelrine,  Mohammad Taufeeque,  Michał Zając,  Euan McLean,  Adam Gleave",
                "发布日期": "2023-12-25",
                "摘要": "  Language model attacks typically assume one of two extreme threat models:\nfull white-box access to model weights, or black-box access limited to a text\ngeneration API. However, real-world APIs are often more flexible than just text\ngeneration: these APIs expose ``gray-box'' access leading to new threat\nvectors. To explore this, we red-team three new functionalities exposed in the\nGPT-4 APIs: fine-tuning, function calling and knowledge retrieval. We find that\nfine-tuning a model on as few as 15 harmful examples or 100 benign examples can\nremove core safeguards from GPT-4, enabling a range of harmful outputs.\nFurthermore, we find that GPT-4 Assistants readily divulge the function call\nschema and can be made to execute arbitrary function calls. Finally, we find\nthat knowledge retrieval can be hijacked by injecting instructions into\nretrieval documents. These vulnerabilities highlight that any additions to the\nfunctionality exposed by an API can create new vulnerabilities.\n",
                "链接": "https://arxiv.org/abs/2312.14302"
            }
        ]
    },
    {
        "question": {
            "question": "使用LLM进行蛋白质结构/功能/性质预测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "84482",
                "标题": "Multi-level Protein Representation Learning for Blind Mutational Effect\n  Prediction",
                "作者": " Yang Tan,  Bingxin Zhou,  Yuanhong Jiang,  Yu Guang Wang,  Liang Hong",
                "发布日期": "2023-06-09",
                "摘要": "  Directed evolution plays an indispensable role in protein engineering that\nrevises existing protein sequences to attain new or enhanced functions.\nAccurately predicting the effects of protein variants necessitates an in-depth\nunderstanding of protein structure and function. Although large self-supervised\nlanguage models have demonstrated remarkable performance in zero-shot inference\nusing only protein sequences, these models inherently do not interpret the\nspatial characteristics of protein structures, which are crucial for\ncomprehending protein folding stability and internal molecular interactions.\nThis paper introduces a novel pre-training framework that cascades sequential\nand geometric analyzers for protein primary and tertiary structures. It guides\nmutational directions toward desired traits by simulating natural selection on\nwild-type proteins and evaluates the effects of variants based on their fitness\nto perform the function. We assess the proposed approach using a public\ndatabase and two new databases for a variety of variant effect prediction\ntasks, which encompass a diverse set of proteins and assays from different\ntaxa. The prediction results achieve state-of-the-art performance over other\nzero-shot learning methods for both single-site mutations and deep mutations.\n",
                "链接": "https://arxiv.org/abs/2306.04899"
            },
            {
                "文章ID": "106475",
                "标题": "InstructProtein: Aligning Human and Protein Language via Knowledge\n  Instruction",
                "作者": " Zeyuan Wang,  Qiang Zhang,  Keyan Ding,  Ming Qin,  Xiang Zhuang,  Xiaotong Li,  Huajun Chen",
                "发布日期": "2023-10-06",
                "摘要": "  Large Language Models (LLMs) have revolutionized the field of natural\nlanguage processing, but they fall short in comprehending biological sequences\nsuch as proteins. To address this challenge, we propose InstructProtein, an\ninnovative LLM that possesses bidirectional generation capabilities in both\nhuman and protein languages: (i) taking a protein sequence as input to predict\nits textual function description and (ii) using natural language to prompt\nprotein sequence generation. To achieve this, we first pre-train an LLM on both\nprotein and natural language corpora, enabling it to comprehend individual\nlanguages. Then supervised instruction tuning is employed to facilitate the\nalignment of these two distinct languages. Herein, we introduce a knowledge\ngraph-based instruction generation framework to construct a high-quality\ninstruction dataset, addressing annotation imbalance and instruction deficits\nin existing protein-text corpus. In particular, the instructions inherit the\nstructural relations between proteins and function annotations in knowledge\ngraphs, which empowers our model to engage in the causal modeling of protein\nfunctions, akin to the chain-of-thought processes in natural languages.\nExtensive experiments on bidirectional protein-text generation tasks show that\nInstructProtein outperforms state-of-the-art LLMs by large margins. Moreover,\nInstructProtein serves as a pioneering step towards text-based protein function\nprediction and sequence design, effectively bridging the gap between protein\nand human language understanding.\n",
                "链接": "https://arxiv.org/abs/2310.03269"
            },
            {
                "文章ID": "106818",
                "标题": "Functional Geometry Guided Protein Sequence and Backbone Structure\n  Co-Design",
                "作者": " Zhenqiao Song,  Yunlong Zhao,  Wenxian Shi,  Yang Yang,  Lei Li",
                "发布日期": "2023-10-10",
                "摘要": "  Proteins are macromolecules responsible for essential functions in almost all\nliving organisms. Designing reasonable proteins with desired functions is\ncrucial. A protein's sequence and structure are strongly correlated and they\ntogether determine its function. In this paper, we propose NAEPro, a model to\njointly design Protein sequence and structure based on automatically detected\nfunctional sites. NAEPro is powered by an interleaving network of attention and\nequivariant layers, which can capture global correlation in a whole sequence\nand local influence from nearest amino acids in three dimensional (3D) space.\nSuch an architecture facilitates effective yet economic message passing at two\nlevels. We evaluate our model and several strong baselines on two protein\ndatasets, $\\beta$-lactamase and myoglobin. Experimental results show that our\nmodel consistently achieves the highest amino acid recovery rate, TM-score, and\nthe lowest RMSD among all competitors. These findings prove the capability of\nour model to design protein sequences and structures that closely resemble\ntheir natural counterparts. Furthermore, in-depth analysis further confirms our\nmodel's ability to generate highly effective proteins capable of binding to\ntheir target metallocofactors. We provide code, data and models in Github.\n",
                "链接": "https://arxiv.org/abs/2310.04343"
            },
            {
                "文章ID": "29171",
                "标题": "Deep Learning Methods for Protein Family Classification on PDB\n  Sequencing Data",
                "作者": " Aaron Wang",
                "发布日期": "2022-07-15",
                "摘要": "  Composed of amino acid chains that influence how they fold and thus dictating\ntheir function and features, proteins are a class of macromolecules that play a\ncentral role in major biological processes and are required for the structure,\nfunction, and regulation of the body's tissues. Understanding protein functions\nis vital to the development of therapeutics and precision medicine, and hence\nthe ability to classify proteins and their functions based on measurable\nfeatures is crucial; indeed, the automatic inference of a protein's properties\nfrom its sequence of amino acids, known as its primary structure, remains an\nimportant open problem within the field of bioinformatics, especially given the\nrecent advancements in sequencing technologies and the extensive number of\nknown but uncategorized proteins with unknown properties. In this work, we\ndemonstrate and compare the performance of several deep learning frameworks,\nincluding novel bi-directional LSTM and convolutional models, on widely\navailable sequencing data from the Protein Data Bank (PDB) of the Research\nCollaboratory for Structural Bioinformatics (RCSB), as well as benchmark this\nperformance against classical machine learning approaches, including k-nearest\nneighbors and multinomial regression classifiers, trained on experimental data.\nOur results show that our deep learning models deliver superior performance to\nclassical machine learning methods, with the convolutional architecture\nproviding the most impressive inference performance.\n",
                "链接": "https://arxiv.org/abs/2207.06678"
            },
            {
                "文章ID": "93224",
                "标题": "Prot2Text: Multimodal Protein's Function Generation with GNNs and\n  Transformers",
                "作者": " Hadi Abdine,  Michail Chatzianastasis,  Costas Bouyioukos,  Michalis Vazirgiannis",
                "发布日期": "2023-12-22",
                "摘要": "  The complex nature of big biological systems pushed some scientists to\nclassify its understanding under the inconceivable missions. Different leveled\nchallenges complicated this task, one of is the prediction of a protein's\nfunction. In recent years, significant progress has been made in this field\nthrough the development of various machine learning approaches. However, most\nexisting methods formulate the task as a multi-classification problem, i.e\nassigning predefined labels to proteins. In this work, we propose a novel\napproach, \\textbf{Prot2Text}, which predicts a protein function's in a free\ntext style, moving beyond the conventional binary or categorical\nclassifications. By combining Graph Neural Networks(GNNs) and Large Language\nModels(LLMs), in an encoder-decoder framework, our model effectively integrates\ndiverse data types including proteins' sequences, structures, and textual\nannotations. This multimodal approach allows for a holistic representation of\nproteins' functions, enabling the generation of detailed and accurate\ndescriptions. To evaluate our model, we extracted a multimodal protein dataset\nfrom SwissProt, and demonstrate empirically the effectiveness of Prot2Text.\nThese results highlight the transformative impact of multimodal models,\nspecifically the fusion of GNNs and LLMs, empowering researchers with powerful\ntools for more accurate prediction of proteins' functions. The code, the models\nand a demo will be publicly released.\n",
                "链接": "https://arxiv.org/abs/2307.14367"
            },
            {
                "文章ID": "120437",
                "标题": "Protein Language Model-Powered 3D Ligand Binding Site Prediction from\n  Protein Sequence",
                "作者": " Shuo Zhang,  Lei Xie",
                "发布日期": "2023-12-07",
                "摘要": "  Prediction of ligand binding sites of proteins is a fundamental and important\ntask for understanding the function of proteins and screening potential drugs.\nMost existing methods require experimentally determined protein holo-structures\nas input. However, such structures can be unavailable on novel or less-studied\nproteins. To tackle this limitation, we propose LaMPSite, which only takes\nprotein sequences and ligand molecular graphs as input for ligand binding site\npredictions. The protein sequences are used to retrieve residue-level\nembeddings and contact maps from the pre-trained ESM-2 protein language model.\nThe ligand molecular graphs are fed into a graph neural network to compute\natom-level embeddings. Then we compute and update the protein-ligand\ninteraction embedding based on the protein residue-level embeddings and ligand\natom-level embeddings, and the geometric constraints in the inferred protein\ncontact map and ligand distance map. A final pooling on protein-ligand\ninteraction embedding would indicate which residues belong to the binding\nsites. Without any 3D coordinate information of proteins, our proposed model\nachieves competitive performance compared to baseline methods that require 3D\nprotein structures when predicting binding sites. Given that less than 50% of\nproteins have reliable structure information in the current stage, LaMPSite\nwill provide new opportunities for drug discovery.\n",
                "链接": "https://arxiv.org/abs/2312.03016"
            },
            {
                "文章ID": "47032",
                "标题": "Learning the shape of protein micro-environments with a holographic\n  convolutional neural network",
                "作者": " Michael N. Pun,  Andrew Ivanov,  Quinn Bellamy,  Zachary Montague,  Colin LaMont,  Philip Bradley,  Jakub Otwinowski,  Armita Nourmohammad",
                "发布日期": "2022-11-08",
                "摘要": "  Proteins play a central role in biology from immune recognition to brain\nactivity. While major advances in machine learning have improved our ability to\npredict protein structure from sequence, determining protein function from\nstructure remains a major challenge. Here, we introduce Holographic\nConvolutional Neural Network (H-CNN) for proteins, which is a physically\nmotivated machine learning approach to model amino acid preferences in protein\nstructures. H-CNN reflects physical interactions in a protein structure and\nrecapitulates the functional information stored in evolutionary data. H-CNN\naccurately predicts the impact of mutations on protein function, including\nstability and binding of protein complexes. Our interpretable computational\nmodel for protein structure-function maps could guide design of novel proteins\nwith desired function.\n",
                "链接": "https://arxiv.org/abs/2211.02936"
            },
            {
                "文章ID": "58852",
                "标题": "Generating Novel, Designable, and Diverse Protein Structures by\n  Equivariantly Diffusing Oriented Residue Clouds",
                "作者": " Yeqing Lin,  Mohammed AlQuraishi",
                "发布日期": "2023-06-08",
                "摘要": "  Proteins power a vast array of functional processes in living cells. The\ncapability to create new proteins with designed structures and functions would\nthus enable the engineering of cellular behavior and development of\nprotein-based therapeutics and materials. Structure-based protein design aims\nto find structures that are designable (can be realized by a protein sequence),\nnovel (have dissimilar geometry from natural proteins), and diverse (span a\nwide range of geometries). While advances in protein structure prediction have\nmade it possible to predict structures of novel protein sequences, the\ncombinatorially large space of sequences and structures limits the practicality\nof search-based methods. Generative models provide a compelling alternative, by\nimplicitly learning the low-dimensional structure of complex data\ndistributions. Here, we leverage recent advances in denoising diffusion\nprobabilistic models and equivariant neural networks to develop Genie, a\ngenerative model of protein structures that performs discrete-time diffusion\nusing a cloud of oriented reference frames in 3D space. Through in silico\nevaluations, we demonstrate that Genie generates protein backbones that are\nmore designable, novel, and diverse than existing models. This indicates that\nGenie is capturing key aspects of the distribution of protein structure space\nand facilitates protein design with high success rates. Code for generating new\nproteins and training new versions of Genie is available at\nhttps://github.com/aqlaboratory/genie.\n",
                "链接": "https://arxiv.org/abs/2301.12485"
            },
            {
                "文章ID": "21935",
                "标题": "Protein Structure and Sequence Generation with Equivariant Denoising\n  Diffusion Probabilistic Models",
                "作者": " Namrata Anand,  Tudor Achim",
                "发布日期": "2022-05-31",
                "摘要": "  Proteins are macromolecules that mediate a significant fraction of the\ncellular processes that underlie life. An important task in bioengineering is\ndesigning proteins with specific 3D structures and chemical properties which\nenable targeted functions. To this end, we introduce a generative model of both\nprotein structure and sequence that can operate at significantly larger scales\nthan previous molecular generative modeling approaches. The model is learned\nentirely from experimental data and conditions its generation on a compact\nspecification of protein topology to produce a full-atom backbone configuration\nas well as sequence and side-chain predictions. We demonstrate the quality of\nthe model via qualitative and quantitative analysis of its samples. Videos of\nsampling trajectories are available at https://nanand2.github.io/proteins .\n",
                "链接": "https://arxiv.org/abs/2205.15019"
            },
            {
                "文章ID": "65999",
                "标题": "A Systematic Study of Joint Representation Learning on Protein Sequences\n  and Structures",
                "作者": " Zuobai Zhang,  Chuanrui Wang,  Minghao Xu,  Vijil Chenthamarakshan,  Aurélie Lozano,  Payel Das,  Jian Tang",
                "发布日期": "2023-10-19",
                "摘要": "  Learning effective protein representations is critical in a variety of tasks\nin biology such as predicting protein functions. Recent sequence representation\nlearning methods based on Protein Language Models (PLMs) excel in\nsequence-based tasks, but their direct adaptation to tasks involving protein\nstructures remains a challenge. In contrast, structure-based methods leverage\n3D structural information with graph neural networks and geometric pre-training\nmethods show potential in function prediction tasks, but still suffers from the\nlimited number of available structures. To bridge this gap, our study\nundertakes a comprehensive exploration of joint protein representation learning\nby integrating a state-of-the-art PLM (ESM-2) with distinct structure encoders\n(GVP, GearNet, CDConv). We introduce three representation fusion strategies and\nexplore different pre-training techniques. Our method achieves significant\nimprovements over existing sequence- and structure-based methods, setting new\nstate-of-the-art for function annotation. This study underscores several\nimportant design choices for fusing protein sequence and structure information.\nOur implementation is available at\nhttps://github.com/DeepGraphLearning/ESM-GearNet.\n",
                "链接": "https://arxiv.org/abs/2303.06275"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用BERT和RoBERTa进行多语言情感分析的最新论文，要求涵盖2022年以来的研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "82977",
                "标题": "UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of\n  Multilingual BERT for Low-resource Sentiment Analysis",
                "作者": " Dou Hu,  Lingwei Wei,  Yaxin Liu,  Wei Zhou,  Songlin Hu",
                "发布日期": "2023-06-05",
                "摘要": "  This paper describes our system designed for SemEval-2023 Task 12: Sentiment\nanalysis for African languages. The challenge faced by this task is the\nscarcity of labeled data and linguistic resources in low-resource settings. To\nalleviate these, we propose a generalized multilingual system SACL-XLMR for\nsentiment analysis on low-resource languages. Specifically, we design a\nlexicon-based multilingual BERT to facilitate language adaptation and\nsentiment-aware representation learning. Besides, we apply a supervised\nadversarial contrastive learning technique to learn sentiment-spread structured\nrepresentations and enhance model generalization. Our system achieved\ncompetitive results, largely outperforming baselines on both multilingual and\nzero-shot sentiment classification subtasks. Notably, the system obtained the\n1st rank on the zero-shot classification subtask in the official ranking.\nExtensive experiments demonstrate the effectiveness of our system.\n",
                "链接": "https://arxiv.org/abs/2306.01093"
            },
            {
                "文章ID": "52169",
                "标题": "Video Games as a Corpus: Sentiment Analysis using Fallout New Vegas\n  Dialog",
                "作者": " Mika Hämäläinen,  Khalid Alnajjar,  Thierry Poibeau",
                "发布日期": "2022-12-06",
                "摘要": "  We present a method for extracting a multilingual sentiment annotated dialog\ndata set from Fallout New Vegas. The game developers have preannotated every\nline of dialog in the game in one of the 8 different sentiments: \\textit{anger,\ndisgust, fear, happy, neutral, pained, sad } and \\textit{surprised}. The game\nhas been translated into English, Spanish, German, French and Italian. We\nconduct experiments on multilingual, multilabel sentiment analysis on the\nextracted data set using multilingual BERT, XLMRoBERTa and language specific\nBERT models. In our experiments, multilingual BERT outperformed XLMRoBERTa for\nmost of the languages, also language specific models were slightly better than\nmultilingual BERT for most of the languages. The best overall accuracy was 54\\%\nand it was achieved by using multilingual BERT on Spanish data. The extracted\ndata set presents a challenging task for sentiment analysis. We have released\nthe data, including the testing and training splits, openly on Zenodo. The data\nset has been shuffled for copyright reasons.\n",
                "链接": "https://arxiv.org/abs/2212.02168"
            },
            {
                "文章ID": "15513",
                "标题": "Mono vs Multilingual BERT for Hate Speech Detection and Text\n  Classification: A Case Study in Marathi",
                "作者": " Abhishek Velankar,  Hrushikesh Patil,  Raviraj Joshi",
                "发布日期": "2022-11-15",
                "摘要": "  Transformers are the most eminent architectures used for a vast range of\nNatural Language Processing tasks. These models are pre-trained over a large\ntext corpus and are meant to serve state-of-the-art results over tasks like\ntext classification. In this work, we conduct a comparative study between\nmonolingual and multilingual BERT models. We focus on the Marathi language and\nevaluate the models on the datasets for hate speech detection, sentiment\nanalysis and simple text classification in Marathi. We use standard\nmultilingual models such as mBERT, indicBERT and xlm-RoBERTa and compare with\nMahaBERT, MahaALBERT and MahaRoBERTa, the monolingual models for Marathi. We\nfurther show that Marathi monolingual models outperform the multilingual BERT\nvariants on five different downstream fine-tuning experiments. We also evaluate\nsentence embeddings from these models by freezing the BERT encoder layers. We\nshow that monolingual MahaBERT based models provide rich representations as\ncompared to sentence embeddings from multi-lingual counterparts. However, we\nobserve that these embeddings are not generic enough and do not work well on\nout of domain social media datasets. We consider two Marathi hate speech\ndatasets L3Cube-MahaHate, HASOC-2021, a Marathi sentiment classification\ndataset L3Cube-MahaSent, and Marathi Headline, Articles classification\ndatasets.\n",
                "链接": "https://arxiv.org/abs/2204.08669"
            },
            {
                "文章ID": "114320",
                "标题": "Modelling Sentiment Analysis: LLMs and data augmentation techniques",
                "作者": " Guillem Senabre Prades",
                "发布日期": "2023-11-08",
                "摘要": "  This paper provides different approaches for a binary sentiment\nclassification on a small training dataset. LLMs that provided state-of-the-art\nresults in sentiment analysis and similar domains are being used, such as BERT,\nRoBERTa and XLNet.\n",
                "链接": "https://arxiv.org/abs/2311.04139"
            },
            {
                "文章ID": "31048",
                "标题": "Enhancing Collaborative Filtering Recommender with Prompt-Based\n  Sentiment Analysis",
                "作者": " Elliot Dang,  Zheyuan Hu,  Tong Li",
                "发布日期": "2022-07-27",
                "摘要": "  Collaborative Filtering(CF) recommender is a crucial application in the\nonline market and ecommerce. However, CF recommender has been proven to suffer\nfrom persistent problems related to sparsity of the user rating that will\nfurther lead to a cold-start issue. Existing methods address the data sparsity\nissue by applying token-level sentiment analysis that translate text review\ninto sentiment scores as a complement of the user rating. In this paper, we\nattempt to optimize the sentiment analysis with advanced NLP models including\nBERT and RoBERTa, and experiment on whether the CF recommender has been further\nenhanced. We build the recommenders on the Amazon US Reviews dataset, and tune\nthe pretrained BERT and RoBERTa with the traditional fine-tuned paradigm as\nwell as the new prompt-based learning paradigm. Experimental result shows that\nthe recommender enhanced with the sentiment ratings predicted by the fine-tuned\nRoBERTa has the best performance, and achieved 30.7% overall gain by comparing\nMAP, NDCG and precision at K to the baseline recommender. Prompt-based learning\nparadigm, although superior to traditional fine-tune paradigm in pure sentiment\nanalysis, fail to further improve the CF recommender.\n",
                "链接": "https://arxiv.org/abs/2207.12883"
            },
            {
                "文章ID": "824",
                "标题": "BERT for Sentiment Analysis: Pre-trained and Fine-Tuned Alternatives",
                "作者": " Frederico Souza,  João Filho",
                "发布日期": "2022-01-11",
                "摘要": "  BERT has revolutionized the NLP field by enabling transfer learning with\nlarge language models that can capture complex textual patterns, reaching the\nstate-of-the-art for an expressive number of NLP applications. For text\nclassification tasks, BERT has already been extensively explored. However,\naspects like how to better cope with the different embeddings provided by the\nBERT output layer and the usage of language-specific instead of multilingual\nmodels are not well studied in the literature, especially for the Brazilian\nPortuguese language. The purpose of this article is to conduct an extensive\nexperimental study regarding different strategies for aggregating the features\nproduced in the BERT output layer, with a focus on the sentiment analysis task.\nThe experiments include BERT models trained with Brazilian Portuguese corpora\nand the multilingual version, contemplating multiple aggregation strategies and\nopen-source datasets with predefined training, validation, and test partitions\nto facilitate the reproducibility of the results. BERT achieved the highest\nROC-AUC values for the majority of cases as compared to TF-IDF. Nonetheless,\nTF-IDF represents a good trade-off between the predictive performance and\ncomputational cost.\n",
                "链接": "https://arxiv.org/abs/2201.03382"
            },
            {
                "文章ID": "47660",
                "标题": "BERT-Based Combination of Convolutional and Recurrent Neural Network for\n  Indonesian Sentiment Analysis",
                "作者": " Hendri Murfi,   Syamsyuriani,  Theresia Gowandi,  Gianinna Ardaneswari,  Siti Nurrohmah",
                "发布日期": "2022-11-11",
                "摘要": "  Sentiment analysis is the computational study of opinions and emotions\nex-pressed in text. Deep learning is a model that is currently producing\nstate-of-the-art in various application domains, including sentiment analysis.\nMany researchers are using a hybrid approach that combines different deep\nlearning models and has been shown to improve model performance. In sentiment\nanalysis, input in text data is first converted into a numerical\nrepresentation. The standard method used to obtain a text representation is the\nfine-tuned embedding method. However, this method does not pay attention to\neach word's context in the sentence. Therefore, the Bidirectional Encoder\nRepresentation from Transformer (BERT) model is used to obtain text\nrepresentations based on the context and position of words in sentences. This\nresearch extends the previous hybrid deep learning using BERT representation\nfor Indonesian sentiment analysis. Our simulation shows that the BERT\nrepresentation improves the accuracies of all hybrid architectures. The\nBERT-based LSTM-CNN also reaches slightly better accuracies than other\nBERT-based hybrid architectures.\n",
                "链接": "https://arxiv.org/abs/2211.05273"
            },
            {
                "文章ID": "74465",
                "标题": "HausaNLP at SemEval-2023 Task 12: Leveraging African Low Resource\n  TweetData for Sentiment Analysis",
                "作者": " Saheed Abdullahi Salahudeen,  Falalu Ibrahim Lawan,  Ahmad Mustapha Wali,  Amina Abubakar Imam,  Aliyu Rabiu Shuaibu,  Aliyu Yusuf,  Nur Bala Rabiu,  Musa Bello,  Shamsuddeen Umaru Adamu,  Saminu Mohammad Aliyu,  Murja Sani Gadanya,  Sanah Abdullahi Muaz,  Mahmoud Said Ahmad,  Abdulkadir Abdullahi,  Abdulmalik Yusuf Jamoh",
                "发布日期": "2023-04-27",
                "摘要": "  We present the findings of SemEval-2023 Task 12, a shared task on sentiment\nanalysis for low-resource African languages using Twitter dataset. The task\nfeatured three subtasks; subtask A is monolingual sentiment classification with\n12 tracks which are all monolingual languages, subtask B is multilingual\nsentiment classification using the tracks in subtask A and subtask C is a\nzero-shot sentiment classification. We present the results and findings of\nsubtask A, subtask B and subtask C. We also release the code on github. Our\ngoal is to leverage low-resource tweet data using pre-trained Afro-xlmr-large,\nAfriBERTa-Large, Bert-base-arabic-camelbert-da-sentiment (Arabic-camelbert),\nMultilingual-BERT (mBERT) and BERT models for sentiment analysis of 14 African\nlanguages. The datasets for these subtasks consists of a gold standard\nmulti-class labeled Twitter datasets from these languages. Our results\ndemonstrate that Afro-xlmr-large model performed better compared to the other\nmodels in most of the languages datasets. Similarly, Nigerian languages: Hausa,\nIgbo, and Yoruba achieved better performance compared to other languages and\nthis can be attributed to the higher volume of data present in the languages.\n",
                "链接": "https://arxiv.org/abs/2304.13634"
            },
            {
                "文章ID": "110508",
                "标题": "RSM-NLP at BLP-2023 Task 2: Bangla Sentiment Analysis using Weighted and\n  Majority Voted Fine-Tuned Transformers",
                "作者": " Pratinav Seth,  Rashi Goel,  Komal Mathur,  Swetha Vemulapalli",
                "发布日期": "2023-10-24",
                "摘要": "  This paper describes our approach to submissions made at Shared Task 2 at BLP\nWorkshop - Sentiment Analysis of Bangla Social Media Posts. Sentiment Analysis\nis an action research area in the digital age. With the rapid and constant\ngrowth of online social media sites and services and the increasing amount of\ntextual data, the application of automatic Sentiment Analysis is on the rise.\nHowever, most of the research in this domain is based on the English language.\nDespite being the world's sixth most widely spoken language, little work has\nbeen done in Bangla. This task aims to promote work on Bangla Sentiment\nAnalysis while identifying the polarity of social media content by determining\nwhether the sentiment expressed in the text is Positive, Negative, or Neutral.\nOur approach consists of experimenting and finetuning various multilingual and\npre-trained BERT-based models on our downstream tasks and using a Majority\nVoting and Weighted ensemble model that outperforms individual baseline model\nscores. Our system scored 0.711 for the multiclass classification task and\nscored 10th place among the participants on the leaderboard for the shared\ntask. Our code is available at https://github.com/ptnv-s/RSM-NLP-BLP-Task2 .\n",
                "链接": "https://arxiv.org/abs/2310.14261"
            },
            {
                "文章ID": "48994",
                "标题": "BERT-Deep CNN: State-of-the-Art for Sentiment Analysis of COVID-19\n  Tweets",
                "作者": " Javad Hassannataj Joloudari,  Sadiq Hussain,  Mohammad Ali Nematollahi,  Rouhollah Bagheri,  Fatemeh Fazl,  Roohallah Alizadehsani,  Reza Lashgari,  Ashis Talukder",
                "发布日期": "2023-08-16",
                "摘要": "  The free flow of information has been accelerated by the rapid development of\nsocial media technology. There has been a significant social and psychological\nimpact on the population due to the outbreak of Coronavirus disease (COVID-19).\nThe COVID-19 pandemic is one of the current events being discussed on social\nmedia platforms. In order to safeguard societies from this pandemic, studying\npeople's emotions on social media is crucial. As a result of their particular\ncharacteristics, sentiment analysis of texts like tweets remains challenging.\nSentiment analysis is a powerful text analysis tool. It automatically detects\nand analyzes opinions and emotions from unstructured data. Texts from a wide\nrange of sources are examined by a sentiment analysis tool, which extracts\nmeaning from them, including emails, surveys, reviews, social media posts, and\nweb articles. To evaluate sentiments, natural language processing (NLP) and\nmachine learning techniques are used, which assign weights to entities, topics,\nthemes, and categories in sentences or phrases. Machine learning tools learn\nhow to detect sentiment without human intervention by examining examples of\nemotions in text. In a pandemic situation, analyzing social media texts to\nuncover sentimental trends can be very helpful in gaining a better\nunderstanding of society's needs and predicting future trends. We intend to\nstudy society's perception of the COVID-19 pandemic through social media using\nstate-of-the-art BERT and Deep CNN models. The superiority of BERT models over\nother deep models in sentiment analysis is evident and can be concluded from\nthe comparison of the various research studies mentioned in this article.\n",
                "链接": "https://arxiv.org/abs/2211.09733"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找一下2018年以后使用强化学习做机器翻译任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "40957",
                "标题": "Reinforcement Learning with Large Action Spaces for Neural Machine\n  Translation",
                "作者": " Asaf Yehudai,  Leshem Choshen,  Lior Fox,  Omri Abend",
                "发布日期": "2022-10-07",
                "摘要": "  Applying Reinforcement learning (RL) following maximum likelihood estimation\n(MLE) pre-training is a versatile method for enhancing neural machine\ntranslation (NMT) performance. However, recent work has argued that the gains\nproduced by RL for NMT are mostly due to promoting tokens that have already\nreceived a fairly high probability in pre-training. We hypothesize that the\nlarge action space is a main obstacle to RL's effectiveness in MT, and conduct\ntwo sets of experiments that lend support to our hypothesis. First, we find\nthat reducing the size of the vocabulary improves RL's effectiveness. Second,\nwe find that effectively reducing the dimension of the action space without\nchanging the vocabulary also yields notable improvement as evaluated by BLEU,\nsemantic similarity, and human evaluation. Indeed, by initializing the\nnetwork's final fully connected layer (that maps the network's internal\ndimension to the vocabulary dimension), with a layer that generalizes over\nsimilar actions, we obtain a substantial improvement in RL performance: 1.5\nBLEU points on average.\n",
                "链接": "https://arxiv.org/abs/2210.03053"
            },
            {
                "文章ID": "29736",
                "标题": "MAD for Robust Reinforcement Learning in Machine Translation",
                "作者": " Domenic Donato,  Lei Yu,  Wang Ling,  Chris Dyer",
                "发布日期": "2022-07-19",
                "摘要": "  We introduce a new distributed policy gradient algorithm and show that it\noutperforms existing reward-aware training procedures such as REINFORCE,\nminimum risk training (MRT) and proximal policy optimization (PPO) in terms of\ntraining stability and generalization performance when optimizing machine\ntranslation models. Our algorithm, which we call MAD (on account of using the\nmean absolute deviation in the importance weighting calculation), has\ndistributed data generators sampling multiple candidates per source sentence on\nworker nodes, while a central learner updates the policy. MAD depends crucially\non two variance reduction strategies: (1) a conditional reward normalization\nmethod that ensures each source sentence has both positive and negative reward\ntranslation examples and (2) a new robust importance weighting scheme that acts\nas a conditional entropy regularizer. Experiments on a variety of translation\ntasks show that policies learned using the MAD algorithm perform very well when\nusing both greedy decoding and beam search, and that the learned policies are\nsensitive to the specific reward used during training.\n",
                "链接": "https://arxiv.org/abs/2207.08583"
            },
            {
                "文章ID": "55838",
                "标题": "Active Learning for Neural Machine Translation",
                "作者": " Neeraj Vashistha,  Kriti Singh,  Ramakant Shakya",
                "发布日期": "2023-01-03",
                "摘要": "  The machine translation mechanism translates texts automatically between\ndifferent natural languages, and Neural Machine Translation (NMT) has gained\nattention for its rational context analysis and fluent translation accuracy.\nHowever, processing low-resource languages that lack relevant training\nattributes like supervised data is a current challenge for Natural Language\nProcessing (NLP). We incorporated a technique known Active Learning with the\nNMT toolkit Joey NMT to reach sufficient accuracy and robust predictions of\nlow-resource language translation. With active learning, a semi-supervised\nmachine learning strategy, the training algorithm determines which unlabeled\ndata would be the most beneficial for obtaining labels using selected query\ntechniques. We implemented two model-driven acquisition functions for selecting\nthe samples to be validated. This work uses transformer-based NMT systems;\nbaseline model (BM), fully trained model (FTM) , active learning least\nconfidence based model (ALLCM), and active learning margin sampling based model\n(ALMSM) when translating English to Hindi. The Bilingual Evaluation Understudy\n(BLEU) metric has been used to evaluate system results. The BLEU scores of BM,\nFTM, ALLCM and ALMSM systems are 16.26, 22.56 , 24.54, and 24.20, respectively.\nThe findings in this paper demonstrate that active learning techniques helps\nthe model to converge early and improve the overall quality of the translation\nsystem.\n",
                "链接": "https://arxiv.org/abs/2301.00688"
            },
            {
                "文章ID": "10776",
                "标题": "Mitigating Gender Bias in Machine Translation through Adversarial\n  Learning",
                "作者": " Eve Fleisig,  Christiane Fellbaum",
                "发布日期": "2022-03-22",
                "摘要": "  Machine translation and other NLP systems often contain significant biases\nregarding sensitive attributes, such as gender or race, that worsen system\nperformance and perpetuate harmful stereotypes. Recent preliminary research\nsuggests that adversarial learning can be used as part of a model-agnostic bias\nmitigation method that requires no data modifications. However, adapting this\nstrategy for machine translation and other modern NLP domains requires (1)\nrestructuring training objectives in the context of fine-tuning pretrained\nlarge language models and (2) developing measures for gender or other protected\nvariables for tasks in which these attributes must be deduced from the data\nitself.\n  We present an adversarial learning framework that addresses these challenges\nto mitigate gender bias in seq2seq machine translation. Our framework improves\nthe disparity in translation quality for sentences with male vs. female\nentities by 86% for English-German translation and 91% for English-French\ntranslation, with minimal effect on translation quality. The results suggest\nthat adversarial learning is a promising technique for mitigating gender bias\nin machine translation.\n",
                "链接": "https://arxiv.org/abs/2203.10675"
            },
            {
                "文章ID": "107113",
                "标题": "Synslator: An Interactive Machine Translation Tool with Online Learning",
                "作者": " Jiayi Wang,  Ke Wang,  Fengming Zhou,  Chengyu Wang,  Zhiyong Fu,  Zeyu Feng,  Yu Zhao,  Yuqi Zhang",
                "发布日期": "2023-10-10",
                "摘要": "  Interactive machine translation (IMT) has emerged as a progression of the\ncomputer-aided translation paradigm, where the machine translation system and\nthe human translator collaborate to produce high-quality translations. This\npaper introduces Synslator, a user-friendly computer-aided translation (CAT)\ntool that not only supports IMT, but is adept at online learning with real-time\ntranslation memories. To accommodate various deployment environments for CAT\nservices, Synslator integrates two different neural translation models to\nhandle translation memories for online learning. Additionally, the system\nemploys a language model to enhance the fluency of translations in an\ninteractive mode. In evaluation, we have confirmed the effectiveness of online\nlearning through the translation models, and have observed a 13% increase in\npost-editing efficiency with the interactive functionalities of Synslator. A\ntutorial video is available at:https://youtu.be/K0vRsb2lTt8.\n",
                "链接": "https://arxiv.org/abs/2310.05025"
            },
            {
                "文章ID": "79608",
                "标题": "Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine\n  Translation",
                "作者": " Jiayi Wang,  Ke Wang,  Yuqi Zhang,  Yu Zhao,  Pontus Stenetorp",
                "发布日期": "2023-05-24",
                "摘要": "  Non-parametric, k-nearest-neighbor algorithms have recently made inroads to\nassist generative models such as language models and machine translation\ndecoders. We explore whether such non-parametric models can improve machine\ntranslation models at the fine-tuning stage by incorporating statistics from\nthe kNN predictions to inform the gradient updates for a baseline translation\nmodel. There are multiple methods which could be used to incorporate kNN\nstatistics and we investigate gradient scaling by a gating mechanism, the kNN's\nground truth probability, and reinforcement learning. For four standard\nin-domain machine translation datasets, compared with classic fine-tuning, we\nreport consistent improvements of all of the three methods by as much as 1.45\nBLEU and 1.28 BLEU for German-English and English-German translations\nrespectively. Through qualitative analysis, we found particular improvements\nwhen it comes to translating grammatical relations or function words, which\nresults in increased fluency of our model.\n",
                "链接": "https://arxiv.org/abs/2305.13648"
            },
            {
                "文章ID": "110267",
                "标题": "Simultaneous Machine Translation with Tailored Reference",
                "作者": " Shoutao Guo,  Shaolei Zhang,  Yang Feng",
                "发布日期": "2023-10-27",
                "摘要": "  Simultaneous machine translation (SiMT) generates translation while reading\nthe whole source sentence. However, existing SiMT models are typically trained\nusing the same reference disregarding the varying amounts of available source\ninformation at different latency. Training the model with ground-truth at low\nlatency may introduce forced anticipations, whereas utilizing reference\nconsistent with the source word order at high latency results in performance\ndegradation. Consequently, it is crucial to train the SiMT model with\nappropriate reference that avoids forced anticipations during training while\nmaintaining high quality. In this paper, we propose a novel method that\nprovides tailored reference for the SiMT models trained at different latency by\nrephrasing the ground-truth. Specifically, we introduce the tailor, induced by\nreinforcement learning, to modify ground-truth to the tailored reference. The\nSiMT model is trained with the tailored reference and jointly optimized with\nthe tailor to enhance performance. Importantly, our method is applicable to a\nwide range of current SiMT approaches. Experiments on three translation tasks\ndemonstrate that our method achieves state-of-the-art performance in both fixed\nand adaptive policies.\n",
                "链接": "https://arxiv.org/abs/2310.13588"
            },
            {
                "文章ID": "119702",
                "标题": "Quick Back-Translation for Unsupervised Machine Translation",
                "作者": " Benjamin Brimacombe,  Jiawei Zhou",
                "发布日期": "2023-12-05",
                "摘要": "  The field of unsupervised machine translation has seen significant\nadvancement from the marriage of the Transformer and the back-translation\nalgorithm. The Transformer is a powerful generative model, and back-translation\nleverages Transformer's high-quality translations for iterative\nself-improvement. However, the Transformer is encumbered by the run-time of\nautoregressive inference during back-translation, and back-translation is\nlimited by a lack of synthetic data efficiency. We propose a two-for-one\nimprovement to Transformer back-translation: Quick Back-Translation (QBT). QBT\nre-purposes the encoder as a generative model, and uses encoder-generated\nsequences to train the decoder in conjunction with the original autoregressive\nback-translation step, improving data throughput and utilization. Experiments\non various WMT benchmarks demonstrate that a relatively small number of\nrefining steps of QBT improve current unsupervised machine translation models,\nand that QBT dramatically outperforms standard back-translation only method in\nterms of training efficiency for comparable translation qualities.\n",
                "链接": "https://arxiv.org/abs/2312.00912"
            },
            {
                "文章ID": "6641",
                "标题": "An Overview on Machine Translation Evaluation",
                "作者": " Lifeng Han",
                "发布日期": "2022-02-23",
                "摘要": "  Since the 1950s, machine translation (MT) has become one of the important\ntasks of AI and development, and has experienced several different periods and\nstages of development, including rule-based methods, statistical methods, and\nrecently proposed neural network-based learning methods. Accompanying these\nstaged leaps is the evaluation research and development of MT, especially the\nimportant role of evaluation methods in statistical translation and neural\ntranslation research. The evaluation task of MT is not only to evaluate the\nquality of machine translation, but also to give timely feedback to machine\ntranslation researchers on the problems existing in machine translation itself,\nhow to improve and how to optimise. In some practical application fields, such\nas in the absence of reference translations, the quality estimation of machine\ntranslation plays an important role as an indicator to reveal the credibility\nof automatically translated target languages. This report mainly includes the\nfollowing contents: a brief history of machine translation evaluation (MTE),\nthe classification of research methods on MTE, and the the cutting-edge\nprogress, including human evaluation, automatic evaluation, and evaluation of\nevaluation methods (meta-evaluation). Manual evaluation and automatic\nevaluation include reference-translation based and reference-translation\nindependent participation; automatic evaluation methods include traditional\nn-gram string matching, models applying syntax and semantics, and deep learning\nmodels; evaluation of evaluation methods includes estimating the credibility of\nhuman evaluations, the reliability of the automatic evaluation, the reliability\nof the test set, etc. Advances in cutting-edge evaluation methods include\ntask-based evaluation, using pre-trained language models based on big data, and\nlightweight optimisation models using distillation techniques.\n",
                "链接": "https://arxiv.org/abs/2202.11027"
            },
            {
                "文章ID": "67893",
                "标题": "LEAPT: Learning Adaptive Prefix-to-prefix Translation For Simultaneous\n  Machine Translation",
                "作者": " Lei Lin,  Shuangtao Li,  Xiaodong Shi",
                "发布日期": "2023-03-22",
                "摘要": "  Simultaneous machine translation, which aims at a real-time translation, is\nuseful in many live scenarios but very challenging due to the trade-off between\naccuracy and latency. To achieve the balance for both, the model needs to wait\nfor appropriate streaming text (READ policy) and then generates its translation\n(WRITE policy). However, WRITE policies of previous work either are specific to\nthe method itself due to the end-to-end training or suffer from the input\nmismatch between training and decoding for the non-end-to-end training.\nTherefore, it is essential to learn a generic and better WRITE policy for\nsimultaneous machine translation. Inspired by strategies utilized by human\ninterpreters and \"wait\" policies, we propose a novel adaptive prefix-to-prefix\ntraining policy called LEAPT, which allows our machine translation model to\nlearn how to translate source sentence prefixes and make use of the future\ncontext. Experiments show that our proposed methods greatly outperform\ncompetitive baselines and achieve promising results.\n",
                "链接": "https://arxiv.org/abs/2303.11750"
            }
        ]
    },
    {
        "question": {
            "question": "请找出使用Transformer模型并在大规模数据集上进行预训练的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "42528",
                "标题": "How to Train Vision Transformer on Small-scale Datasets?",
                "作者": " Hanan Gani,  Muzammal Naseer,  Mohammad Yaqub",
                "发布日期": "2022-10-14",
                "摘要": "  Vision Transformer (ViT), a radically different architecture than\nconvolutional neural networks offers multiple advantages including design\nsimplicity, robustness and state-of-the-art performance on many vision tasks.\nHowever, in contrast to convolutional neural networks, Vision Transformer lacks\ninherent inductive biases. Therefore, successful training of such models is\nmainly attributed to pre-training on large-scale datasets such as ImageNet with\n1.2M or JFT with 300M images. This hinders the direct adaption of Vision\nTransformer for small-scale datasets. In this work, we show that\nself-supervised inductive biases can be learned directly from small-scale\ndatasets and serve as an effective weight initialization scheme for\nfine-tuning. This allows to train these models without large-scale\npre-training, changes to model architecture or loss functions. We present\nthorough experiments to successfully train monolithic and non-monolithic Vision\nTransformers on five small datasets including CIFAR10/100, CINIC10, SVHN,\nTiny-ImageNet and two fine-grained datasets: Aircraft and Cars. Our approach\nconsistently improves the performance of Vision Transformers while retaining\ntheir properties such as attention to salient regions and higher robustness.\nOur codes and pre-trained models are available at:\nhttps://github.com/hananshafi/vits-for-small-scale-datasets.\n",
                "链接": "https://arxiv.org/abs/2210.07240"
            },
            {
                "文章ID": "11046",
                "标题": "WuDaoMM: A large-scale Multi-Modal Dataset for Pre-training models",
                "作者": " Sha Yuan,  Shuai Zhao,  Jiahong Leng,  Zhao Xue,  Hanyu Zhao,  Peiyu Liu,  Zheng Gong,  Wayne Xin Zhao,  Junyi Li,  Jie Tang",
                "发布日期": "2022-05-03",
                "摘要": "  Compared with the domain-specific model, the vision-language pre-training\nmodels (VLPMs) have shown superior performance on downstream tasks with fast\nfine-tuning process. For example, ERNIE-ViL, Oscar and UNIMO trained VLPMs with\na uniform transformers stack architecture and large amounts of image-text\npaired data, achieving remarkable results on downstream tasks such as\nimage-text reference(IR and TR), vision question answering (VQA) and image\ncaptioning (IC) etc. During the training phase, VLPMs are always fed with a\ncombination of multiple public datasets to meet the demand of large-scare\ntraining data. However, due to the unevenness of data distribution including\nsize, task type and quality, using the mixture of multiple datasets for model\ntraining can be problematic. In this work, we introduce a large-scale\nmulti-modal corpora named WuDaoMM, totally containing more than 650M image-text\npairs. Specifically, about 600 million pairs of data are collected from\nmultiple webpages in which image and caption present weak correlation, and the\nother 50 million strong-related image-text pairs are collected from some\nhigh-quality graphic websites. We also release a base version of WuDaoMM with 5\nmillion strong-correlated image-text pairs, which is sufficient to support the\ncommon cross-modal model pre-training. Besides, we trained both an\nunderstanding and a generation vision-language (VL) model to test the dataset\neffectiveness. The results show that WuDaoMM can be applied as an efficient\ndataset for VLPMs, especially for the model in text-to-image generation task.\nThe data is released at https://data.wudaoai.cn\n",
                "链接": "https://arxiv.org/abs/2203.11480"
            },
            {
                "文章ID": "3168",
                "标题": "ScaLA: Accelerating Adaptation of Pre-Trained Transformer-Based Language\n  Models via Efficient Large-Batch Adversarial Noise",
                "作者": " Minjia Zhang,  Niranjan Uma Naresh,  Yuxiong He",
                "发布日期": "2022-02-01",
                "摘要": "  In recent years, large pre-trained Transformer-based language models have led\nto dramatic improvements in many natural language understanding tasks. To train\nthese models with increasing sizes, many neural network practitioners attempt\nto increase the batch sizes in order to leverage multiple GPUs to improve\ntraining speed. However, increasing the batch size often makes the optimization\nmore difficult, leading to slow convergence or poor generalization that can\nrequire orders of magnitude more training time to achieve the same model\nquality. In this paper, we explore the steepness of the loss landscape of\nlarge-batch optimization for adapting pre-trained Transformer-based language\nmodels to domain-specific tasks and find that it tends to be highly complex and\nirregular, posing challenges to generalization on downstream tasks.\n  To tackle this challenge, we propose ScaLA, a novel and efficient method to\naccelerate the adaptation speed of pre-trained transformer networks. Different\nfrom prior methods, we take a sequential game-theoretic approach by adding\nlightweight adversarial noise into large-batch optimization, which\nsignificantly improves adaptation speed while preserving model generalization.\nExperiment results show that ScaLA attains 2.7--9.8$\\times$ adaptation speedups\nover the baseline for GLUE on BERT-base and RoBERTa-large, while achieving\ncomparable and sometimes higher accuracy than the state-of-the-art large-batch\noptimization methods. Finally, we also address the theoretical aspect of\nlarge-batch optimization with adversarial noise and provide a theoretical\nconvergence rate analysis for ScaLA using techniques for analyzing non-convex\nsaddle-point problems.\n",
                "链接": "https://arxiv.org/abs/2201.12469"
            },
            {
                "文章ID": "62495",
                "标题": "Large-scale Multi-Modal Pre-trained Models: A Comprehensive Survey",
                "作者": " Xiao Wang,  Guangyao Chen,  Guangwu Qian,  Pengcheng Gao,  Xiao-Yong Wei,  Yaowei Wang,  Yonghong Tian,  Wen Gao",
                "发布日期": "2023-11-01",
                "摘要": "  With the urgent demand for generalized deep models, many pre-trained big\nmodels are proposed, such as BERT, ViT, GPT, etc. Inspired by the success of\nthese models in single domains (like computer vision and natural language\nprocessing), the multi-modal pre-trained big models have also drawn more and\nmore attention in recent years. In this work, we give a comprehensive survey of\nthese models and hope this paper could provide new insights and helps fresh\nresearchers to track the most cutting-edge works. Specifically, we firstly\nintroduce the background of multi-modal pre-training by reviewing the\nconventional deep learning, pre-training works in natural language process,\ncomputer vision, and speech. Then, we introduce the task definition, key\nchallenges, and advantages of multi-modal pre-training models (MM-PTMs), and\ndiscuss the MM-PTMs with a focus on data, objectives, network architectures,\nand knowledge enhanced pre-training. After that, we introduce the downstream\ntasks used for the validation of large-scale MM-PTMs, including generative,\nclassification, and regression tasks. We also give visualization and analysis\nof the model parameters and results on representative downstream tasks.\nFinally, we point out possible research directions for this topic that may\nbenefit future works. In addition, we maintain a continuously updated paper\nlist for large-scale pre-trained multi-modal big models:\nhttps://github.com/wangxiao5791509/MultiModal_BigModels_Survey\n",
                "链接": "https://arxiv.org/abs/2302.10035"
            },
            {
                "文章ID": "88500",
                "标题": "Foundation Model for Endoscopy Video Analysis via Large-scale\n  Self-supervised Pre-train",
                "作者": " Zhao Wang,  Chang Liu,  Shaoting Zhang,  Qi Dou",
                "发布日期": "2023-11-30",
                "摘要": "  Foundation models have exhibited remarkable success in various applications,\nsuch as disease diagnosis and text report generation. To date, a foundation\nmodel for endoscopic video analysis is still lacking. In this paper, we propose\nEndo-FM, a foundation model specifically developed using massive endoscopic\nvideo data. First, we build a video transformer, which captures both local and\nglobal long-range dependencies across spatial and temporal dimensions. Second,\nwe pre-train our transformer model using global and local views via a\nself-supervised manner, aiming to make it robust to spatial-temporal variations\nand discriminative across different scenes. To develop the foundation model, we\nconstruct a large-scale endoscopy video dataset by combining 9 publicly\navailable datasets and a privately collected dataset from Baoshan Branch of\nRenji Hospital in Shanghai, China. Our dataset overall consists of over 33K\nvideo clips with up to 5 million frames, encompassing various protocols, target\norgans, and disease types. Our pre-trained Endo-FM can be easily adopted for a\ngiven downstream task via fine-tuning by serving as the backbone. With\nexperiments on 3 different types of downstream tasks, including classification,\nsegmentation, and detection, our Endo-FM surpasses the current state-of-the-art\n(SOTA) self-supervised pre-training and adapter-based transfer learning methods\nby a significant margin, such as VCL (3.1% F1, 4.8% Dice, and 5.5% F1 for\nclassification, segmentation, and detection) and ST-Adapter (5.9% F1, 9.6%\nDice, and 9.9% F1 for classification, segmentation, and detection). Code,\ndatasets, and models are released at https://github.com/med-air/Endo-FM.\n",
                "链接": "https://arxiv.org/abs/2306.16741"
            },
            {
                "文章ID": "115137",
                "标题": "ReactionT5: a large-scale pre-trained model towards application of\n  limited reaction data",
                "作者": " Tatsuya Sagawa,  Ryosuke Kojima",
                "发布日期": "2023-11-14",
                "摘要": "  Transformer-based deep neural networks have revolutionized the field of\nmolecular-related prediction tasks by treating molecules as symbolic sequences.\nThese models have been successfully applied in various organic chemical\napplications by pretraining them with extensive compound libraries and\nsubsequently fine-tuning them with smaller in-house datasets for specific\ntasks. However, many conventional methods primarily focus on single molecules,\nwith limited exploration of pretraining for reactions involving multiple\nmolecules. In this paper, we propose ReactionT5, a novel model that leverages\npretraining on the Open Reaction Database (ORD), a publicly available\nlarge-scale resource. We further fine-tune this model for yield prediction and\nproduct prediction tasks, demonstrating its impressive performance even with\nlimited fine-tuning data compared to traditional models. The pre-trained\nReactionT5 model is publicly accessible on the Hugging Face platform.\n",
                "链接": "https://arxiv.org/abs/2311.06708"
            },
            {
                "文章ID": "125008",
                "标题": "Large-scale Long-tailed Disease Diagnosis on Radiology Images",
                "作者": " Qiaoyu Zheng,  Weike Zhao,  Chaoyi Wu,  Xiaoman Zhang,  Ya Zhang,  Yanfeng Wang,  Weidi Xie",
                "发布日期": "2023-12-29",
                "摘要": "  In this study, we aim to investigate the problem of large-scale,\nlarge-vocabulary disease classification for radiologic images, which can be\nformulated as a multi-modal, multi-anatomy, multi-label, long-tailed\nclassification. Our main contributions are three folds: (i), on dataset\nconstruction, we build up an academically accessible, large-scale diagnostic\ndataset that encompasses 5568 disorders linked with 930 unique ICD-10-CM codes,\ncontaining 39,026 cases (192,675 scans). (ii), on model design, we present a\nnovel architecture that enables to process arbitrary number of input scans,\nfrom various imaging modalities, which is trained with knowledge enhancement to\nleverage the rich domain knowledge; (iii), on evaluation, we initialize a new\nbenchmark for multi-modal multi-anatomy long-tailed diagnosis. Our method shows\nsuperior results on it. Additionally, our final model serves as a pre-trained\nmodel, and can be finetuned to benefit diagnosis on various external datasets.\n",
                "链接": "https://arxiv.org/abs/2312.16151"
            },
            {
                "文章ID": "111054",
                "标题": "Dynamic Convolutional Neural Networks as Efficient Pre-trained Audio\n  Models",
                "作者": " Florian Schmid,  Khaled Koutini,  Gerhard Widmer",
                "发布日期": "2023-10-25",
                "摘要": "  The introduction of large-scale audio datasets, such as AudioSet, paved the\nway for Transformers to conquer the audio domain and replace CNNs as the\nstate-of-the-art neural network architecture for many tasks. Audio Spectrogram\nTransformers are excellent at exploiting large datasets, creating powerful\npre-trained models that surpass CNNs when fine-tuned on downstream tasks.\nHowever, current popular Audio Spectrogram Transformers are demanding in terms\nof computational complexity compared to CNNs. Recently, we have shown that, by\nemploying Transformer-to-CNN Knowledge Distillation, efficient CNNs can catch\nup with and even outperform Transformers on large datasets. In this work, we\nextend this line of research and increase the capacity of efficient CNNs by\nintroducing dynamic CNN blocks, constructed of dynamic non-linearities, dynamic\nconvolutions and attention mechanisms. We show that these dynamic CNNs\noutperform traditional efficient CNNs, in terms of the performance-complexity\ntrade-off and parameter efficiency, at the task of audio tagging on the\nlarge-scale AudioSet. Our experiments further indicate that the introduced\ndynamic CNNs achieve better performance on downstream tasks and scale up well,\nattaining Transformer performance and even outperforming them on AudioSet and\nseveral downstream tasks.\n",
                "链接": "https://arxiv.org/abs/2310.15648"
            },
            {
                "文章ID": "52728",
                "标题": "DialogCC: Large-Scale Multi-Modal Dialogue Dataset",
                "作者": " Young-Jun Lee,  Byungsoo Ko,  Han-Gyu Kim,  Ho-Jin Choi",
                "发布日期": "2022-12-09",
                "摘要": "  As sharing images in an instant message is a crucial factor, there has been\nactive research on learning a image-text multi-modal dialogue model. However,\ntraining a well-generalized multi-modal dialogue model is challenging because\nexisting multi-modal dialogue datasets contain a small number of data, limited\ntopics, and a restricted variety of images per dialogue. In this paper, we\npresent a multi-modal dialogue dataset creation pipeline that involves matching\nlarge-scale images to dialogues based on CLIP similarity. Using this automatic\npipeline, we propose a large-scale multi-modal dialogue dataset, DialogCC,\nwhich covers diverse real-world topics and various images per dialogue. With\nextensive experiments, we demonstrate that training a multi-modal dialogue\nmodel with our dataset can improve generalization performance. Additionally,\nexisting models trained with our dataset achieve state-of-the-art performance\non image and text retrieval tasks. The source code and the dataset will be\nreleased after publication.\n",
                "链接": "https://arxiv.org/abs/2212.04119"
            },
            {
                "文章ID": "52062",
                "标题": "MiLMo:Minority Multilingual Pre-trained Language Model",
                "作者": " Junjie Deng,  Hanru Shi,  Xinhe Yu,  Wugedele Bao,  Yuan Sun,  Xiaobing Zhao",
                "发布日期": "2023-04-11",
                "摘要": "  Pre-trained language models are trained on large-scale unsupervised data, and\nthey can fine-turn the model only on small-scale labeled datasets, and achieve\ngood results. Multilingual pre-trained language models can be trained on\nmultiple languages, and the model can understand multiple languages at the same\ntime. At present, the search on pre-trained models mainly focuses on rich\nresources, while there is relatively little research on low-resource languages\nsuch as minority languages, and the public multilingual pre-trained language\nmodel can not work well for minority languages. Therefore, this paper\nconstructs a multilingual pre-trained model named MiLMo that performs better on\nminority language tasks, including Mongolian, Tibetan, Uyghur, Kazakh and\nKorean. To solve the problem of scarcity of datasets on minority languages and\nverify the effectiveness of the MiLMo model, this paper constructs a minority\nmultilingual text classification dataset named MiTC, and trains a word2vec\nmodel for each language. By comparing the word2vec model and the pre-trained\nmodel in the text classification task, this paper provides an optimal scheme\nfor the downstream task research of minority languages. The final experimental\nresults show that the performance of the pre-trained model is better than that\nof the word2vec model, and it has achieved the best results in minority\nmultilingual text classification. The multilingual pre-trained model MiLMo,\nmultilingual word2vec model and multilingual text classification dataset MiTC\nare published on http://milmo.cmli-nlp.com/.\n",
                "链接": "https://arxiv.org/abs/2212.01779"
            }
        ]
    },
    {
        "question": {
            "question": "找一下使用强化学习做代码生成的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "59289",
                "标题": "Execution-based Code Generation using Deep Reinforcement Learning",
                "作者": " Parshin Shojaee,  Aneesh Jain,  Sindhu Tipirneni,  Chandan K. Reddy",
                "发布日期": "2023-07-21",
                "摘要": "  The utilization of programming language (PL) models, pre-trained on\nlarge-scale code corpora, as a means of automating software engineering\nprocesses has demonstrated considerable potential in streamlining various code\ngeneration tasks such as code completion, code translation, and program\nsynthesis. However, current approaches mainly rely on supervised fine-tuning\nobjectives borrowed from text generation, neglecting unique sequence-level\ncharacteristics of code, including but not limited to compilability as well as\nsyntactic and functional correctness. To address this limitation, we propose\nPPOCoder, a new framework for code generation that synergistically combines\npre-trained PL models with Proximal Policy Optimization (PPO) which is a widely\nused deep reinforcement learning technique. By utilizing non-differentiable\nfeedback from code execution and structure alignment, PPOCoder seamlessly\nintegrates external code-specific knowledge into the model optimization\nprocess. It's important to note that PPOCoder is a task-agnostic and\nmodel-agnostic framework that can be used across different code generation\ntasks and PLs. Extensive experiments on three code generation tasks demonstrate\nthe effectiveness of our proposed approach compared to SOTA methods, achieving\nsignificant improvements in compilation success rates and functional\ncorrectness across different PLs.\n",
                "链接": "https://arxiv.org/abs/2301.13816"
            },
            {
                "文章ID": "42744",
                "标题": "Robust Preference Learning for Storytelling via Contrastive\n  Reinforcement Learning",
                "作者": " Louis Castricato,  Alexander Havrilla,  Shahbuland Matiana,  Michael Pieler,  Anbang Ye,  Ian Yang,  Spencer Frazier,  Mark Riedl",
                "发布日期": "2022-12-16",
                "摘要": "  Controlled automated story generation seeks to generate natural language\nstories satisfying constraints from natural language critiques or preferences.\nExisting methods to control for story preference utilize prompt engineering\nwhich is labor intensive and often inconsistent. They may also use\nlogit-manipulation methods which require annotated datasets to exist for the\ndesired attributes. To address these issues, we first train a contrastive\nbi-encoder model to align stories with corresponding human critiques, named\nCARP, building a general purpose preference model. This is subsequently used as\na reward function to fine-tune a generative language model via reinforcement\nlearning. However, simply fine-tuning a generative language model with a\ncontrastive reward model does not always reliably result in a story generation\nsystem capable of generating stories that meet user preferences. To increase\nstory generation robustness we further fine-tune the contrastive reward model\nusing a prompt-learning technique. A human participant study is then conducted\ncomparing generations from our full system, ablations, and two baselines. We\nshow that the full fine-tuning pipeline results in a story generator preferred\nover a LLM 20x as large as well as logit-based methods. This motivates the use\nof contrastive learning for general purpose human preference modeling.\n",
                "链接": "https://arxiv.org/abs/2210.07792"
            },
            {
                "文章ID": "54777",
                "标题": "A survey on text generation using generative adversarial networks",
                "作者": " Gustavo Henrique de Rosa,  João Paulo Papa",
                "发布日期": "2022-12-22",
                "摘要": "  This work presents a thorough review concerning recent studies and text\ngeneration advancements using Generative Adversarial Networks. The usage of\nadversarial learning for text generation is promising as it provides\nalternatives to generate the so-called \"natural\" language. Nevertheless,\nadversarial text generation is not a simple task as its foremost architecture,\nthe Generative Adversarial Networks, were designed to cope with continuous\ninformation (image) instead of discrete data (text). Thus, most works are based\non three possible options, i.e., Gumbel-Softmax differentiation, Reinforcement\nLearning, and modified training objectives. All alternatives are reviewed in\nthis survey as they present the most recent approaches for generating text\nusing adversarial-based techniques. The selected works were taken from renowned\ndatabases, such as Science Direct, IEEEXplore, Springer, Association for\nComputing Machinery, and arXiv, whereas each selected work has been critically\nanalyzed and assessed to present its objective, methodology, and experimental\nresults.\n",
                "链接": "https://arxiv.org/abs/2212.11119"
            },
            {
                "文章ID": "51256",
                "标题": "Coder Reviewer Reranking for Code Generation",
                "作者": " Tianyi Zhang,  Tao Yu,  Tatsunori B. Hashimoto,  Mike Lewis,  Wen-tau Yih,  Daniel Fried,  Sida I. Wang",
                "发布日期": "2022-11-30",
                "摘要": "  Sampling diverse programs from a code language model and reranking with model\nlikelihood is a popular method for code generation but it is prone to\npreferring degenerate solutions. Inspired by collaborative programming, we\npropose Coder-Reviewer reranking. We augment Coder language models from past\nwork, which generate programs given language instructions, with Reviewer\nmodels, which evaluate the likelihood of the instruction given the generated\nprograms. We perform an extensive study across six datasets with eight models\nfrom three model families. Experimental results show that Coder-Reviewer\nreranking leads to consistent and significant improvement (up to 17% absolute\naccuracy gain) over reranking with the Coder model only. When combined with\nexecutability filtering, Coder-Reviewer reranking can often outperform the\nminimum Bayes risk method. Coder-Reviewer reranking is easy to implement by\nprompting, can generalize to different programming languages, and works well\nwith off-the-shelf hyperparameters.\n",
                "链接": "https://arxiv.org/abs/2211.16490"
            },
            {
                "文章ID": "64969",
                "标题": "MotionVideoGAN: A Novel Video Generator Based on the Motion Space\n  Learned from Image Pairs",
                "作者": " Jingyuan Zhu,  Huimin Ma,  Jiansheng Chen,  Jian Yuan",
                "发布日期": "2023-03-07",
                "摘要": "  Video generation has achieved rapid progress benefiting from high-quality\nrenderings provided by powerful image generators. We regard the video synthesis\ntask as generating a sequence of images sharing the same contents but varying\nin motions. However, most previous video synthesis frameworks based on\npre-trained image generators treat content and motion generation separately,\nleading to unrealistic generated videos. Therefore, we design a novel framework\nto build the motion space, aiming to achieve content consistency and fast\nconvergence for video generation. We present MotionVideoGAN, a novel video\ngenerator synthesizing videos based on the motion space learned by pre-trained\nimage pair generators. Firstly, we propose an image pair generator named\nMotionStyleGAN to generate image pairs sharing the same contents and producing\nvarious motions. Then we manage to acquire motion codes to edit one image in\nthe generated image pairs and keep the other unchanged. The motion codes help\nus edit images within the motion space since the edited image shares the same\ncontents with the other unchanged one in image pairs. Finally, we introduce a\nlatent code generator to produce latent code sequences using motion codes for\nvideo generation. Our approach achieves state-of-the-art performance on the\nmost complex video dataset ever used for unconditional video generation\nevaluation, UCF101.\n",
                "链接": "https://arxiv.org/abs/2303.02906"
            },
            {
                "文章ID": "72223",
                "标题": "\"What It Wants Me To Say\": Bridging the Abstraction Gap Between End-User\n  Programmers and Code-Generating Large Language Models",
                "作者": " Michael Xieyang Liu,  Advait Sarkar,  Carina Negreanu,  Ben Zorn,  Jack Williams,  Neil Toronto,  Andrew D. Gordon",
                "发布日期": "2023-04-14",
                "摘要": "  Code-generating large language models translate natural language into code.\nHowever, only a small portion of the infinite space of naturalistic utterances\nis effective at guiding code generation. For non-expert end-user programmers,\nlearning this is the challenge of abstraction matching. We examine this\nchallenge in the specific context of data analysis in spreadsheets, in a system\nthat maps the users natural language query to Python code using the Codex\ngenerator, executes the code, and shows the result. We propose grounded\nabstraction matching, which bridges the abstraction gap by translating the code\nback into a systematic and predictable naturalistic utterance. In a\nbetween-subjects, think-aloud study (n=24), we compare grounded abstraction\nmatching to an ungrounded alternative based on previously established query\nframing principles. We find that the grounded approach improves end-users'\nunderstanding of the scope and capabilities of the code-generating model, and\nthe kind of language needed to use it effectively.\n",
                "链接": "https://arxiv.org/abs/2304.06597"
            },
            {
                "文章ID": "30296",
                "标题": "CodeT: Code Generation with Generated Tests",
                "作者": " Bei Chen,  Fengji Zhang,  Anh Nguyen,  Daoguang Zan,  Zeqi Lin,  Jian-Guang Lou,  Weizhu Chen",
                "发布日期": "2022-11-24",
                "摘要": "  The task of generating code solutions for a given programming problem can\nbenefit from the use of pre-trained language models such as Codex, which can\nproduce multiple diverse samples. However, a major challenge for this task is\nto select the most appropriate solution from the multiple samples generated by\nthe pre-trained language models. A natural way to evaluate the quality and\ncorrectness of a code solution is to run it against a set of test cases, but\nthe manual creation of such test cases is often costly and time-consuming. In\nthis paper, we propose a novel method, CodeT, that leverages the same\npre-trained language models to automatically generate test cases for the code\nsamples, thus reducing the human effort and increasing the coverage of the test\nscenarios. CodeT then executes the code samples using the generated test cases,\nand performs a dual execution agreement, which considers both the consistency\nof the outputs against the generated test cases and the agreement of the\noutputs with other code samples. We conduct comprehensive experiments on four\nbenchmarks, HumanEval, MBPP, APPS and CodeContests, using five different\npre-trained language models with varying sizes and capabilities. Our results\nshow that CodeT can significantly improve the performance of code solution\nselection over previous methods, achieving remarkable and consistent gains\nacross different models and benchmarks. For instance, CodeT improves the pass@1\nmetric on HumanEval to 65.8%, which represents an absolute improvement of 18.8%\nover the code-davinci-002 model, and an absolute improvement of more than 20%\nover the previous state-of-the-art results.\n",
                "链接": "https://arxiv.org/abs/2207.10397"
            },
            {
                "文章ID": "120674",
                "标题": "Self-conditioned Image Generation via Generating Representations",
                "作者": " Tianhong Li,  Dina Katabi,  Kaiming He",
                "发布日期": "2023-12-11",
                "摘要": "  This paper presents $\\textbf{R}$epresentation-$\\textbf{C}$onditioned image\n$\\textbf{G}$eneration (RCG), a simple yet effective image generation framework\nwhich sets a new benchmark in class-unconditional image generation. RCG does\nnot condition on any human annotations. Instead, it conditions on a\nself-supervised representation distribution which is mapped from the image\ndistribution using a pre-trained encoder. During generation, RCG samples from\nsuch representation distribution using a representation diffusion model (RDM),\nand employs a pixel generator to craft image pixels conditioned on the sampled\nrepresentation. Such a design provides substantial guidance during the\ngenerative process, resulting in high-quality image generation. Tested on\nImageNet 256$\\times$256, RCG achieves a Frechet Inception Distance (FID) of\n3.31 and an Inception Score (IS) of 253.4. These results not only significantly\nimprove the state-of-the-art of class-unconditional image generation but also\nrival the current leading methods in class-conditional image generation,\nbridging the long-standing performance gap between these two tasks. Code is\navailable at https://github.com/LTH14/rcg.\n",
                "链接": "https://arxiv.org/abs/2312.03701"
            },
            {
                "文章ID": "15595",
                "标题": "CodexDB: Generating Code for Processing SQL Queries using GPT-3 Codex",
                "作者": " Immanuel Trummer",
                "发布日期": "2022-04-20",
                "摘要": "  CodexDB is an SQL processing engine whose internals can be customized via\nnatural language instructions. CodexDB is based on OpenAI's GPT-3 Codex model\nwhich translates text into code. It is a framework on top of GPT-3 Codex that\ndecomposes complex SQL queries into a series of simple processing steps,\ndescribed in natural language. Processing steps are enriched with user-provided\ninstructions and descriptions of database properties. Codex translates the\nresulting text into query processing code. An early prototype of CodexDB is\nable to generate correct code for a majority of queries of the WikiSQL\nbenchmark and can be customized in various ways.\n",
                "链接": "https://arxiv.org/abs/2204.08941"
            },
            {
                "文章ID": "3116",
                "标题": "Generative Cooperative Networks for Natural Language Generation",
                "作者": " Sylvain Lamprier,  Thomas Scialom,  Antoine Chaffin,  Vincent Claveau,  Ewa Kijak,  Jacopo Staiano,  Benjamin Piwowarski",
                "发布日期": "2022-01-31",
                "摘要": "  Generative Adversarial Networks (GANs) have known a tremendous success for\nmany continuous generation tasks, especially in the field of image generation.\nHowever, for discrete outputs such as language, optimizing GANs remains an open\nproblem with many instabilities, as no gradient can be properly back-propagated\nfrom the discriminator output to the generator parameters. An alternative is to\nlearn the generator network via reinforcement learning, using the discriminator\nsignal as a reward, but such a technique suffers from moving rewards and\nvanishing gradient problems. Finally, it often falls short compared to direct\nmaximum-likelihood approaches. In this paper, we introduce Generative\nCooperative Networks, in which the discriminator architecture is cooperatively\nused along with the generation policy to output samples of realistic texts for\nthe task at hand. We give theoretical guarantees of convergence for our\napproach, and study various efficient decoding schemes to empirically achieve\nstate-of-the-art results in two main NLG tasks.\n",
                "链接": "https://arxiv.org/abs/2201.12320"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下关于大模型使用工具的安全性的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "109885",
                "标题": "Safety-Gymnasium: A Unified Safe Reinforcement Learning Benchmark",
                "作者": " Jiaming Ji,  Borong Zhang,  Jiayi Zhou,  Xuehai Pan,  Weidong Huang,  Ruiyang Sun,  Yiran Geng,  Yifan Zhong,  Juntao Dai,  Yaodong Yang",
                "发布日期": "2023-11-08",
                "摘要": "  Artificial intelligence (AI) systems possess significant potential to drive\nsocietal progress. However, their deployment often faces obstacles due to\nsubstantial safety concerns. Safe reinforcement learning (SafeRL) emerges as a\nsolution to optimize policies while simultaneously adhering to multiple\nconstraints, thereby addressing the challenge of integrating reinforcement\nlearning in safety-critical scenarios. In this paper, we present an environment\nsuite called Safety-Gymnasium, which encompasses safety-critical tasks in both\nsingle and multi-agent scenarios, accepting vector and vision-only input.\nAdditionally, we offer a library of algorithms named Safe Policy Optimization\n(SafePO), comprising 16 state-of-the-art SafeRL algorithms. This comprehensive\nlibrary can serve as a validation tool for the research community. By\nintroducing this benchmark, we aim to facilitate the evaluation and comparison\nof safety performance, thus fostering the development of reinforcement learning\nfor safer, more reliable, and responsible real-world applications. The website\nof this project can be accessed at\nhttps://sites.google.com/view/safety-gymnasium.\n",
                "链接": "https://arxiv.org/abs/2310.12567"
            },
            {
                "文章ID": "4874",
                "标题": "SAFER: Data-Efficient and Safe Reinforcement Learning via Skill\n  Acquisition",
                "作者": " Dylan Slack,  Yinlam Chow,  Bo Dai,  Nevan Wichers",
                "发布日期": "2022-07-04",
                "摘要": "  Methods that extract policy primitives from offline demonstrations using deep\ngenerative models have shown promise at accelerating reinforcement learning(RL)\nfor new tasks. Intuitively, these methods should also help to trainsafeRLagents\nbecause they enforce useful skills. However, we identify these techniques are\nnot well equipped for safe policy learning because they ignore negative\nexperiences(e.g., unsafe or unsuccessful), focusing only on positive\nexperiences, which harms their ability to generalize to new tasks safely.\nRather, we model the latentsafetycontextusing principled contrastive training\non an offline dataset of demonstrations from many tasks, including both\nnegative and positive experiences. Using this late variable, our RL framework,\nSAFEty skill pRiors (SAFER) extracts task-specific safe primitive skills to\nsafely and successfully generalize to new tasks. In the inference stage,\npolicies trained with SAFER learn to compose safe skills into successful\npolicies. We theoretically characterize why SAFER can enforce safe policy\nlearning and demonstrate its effectiveness on several complex safety-critical\nrobotic grasping tasks inspired by the game Operation, in which\nSAFERoutperforms state-of-the-art primitive learning methods in success and\nsafety.\n",
                "链接": "https://arxiv.org/abs/2202.04849"
            },
            {
                "文章ID": "39802",
                "标题": "On the Impossible Safety of Large AI Models",
                "作者": " El-Mahdi El-Mhamdi,  Sadegh Farhadkhani,  Rachid Guerraoui,  Nirupam Gupta,  Lê-Nguyên Hoang,  Rafael Pinot,  Sébastien Rouault,  John Stephan",
                "发布日期": "2023-05-10",
                "摘要": "  Large AI Models (LAIMs), of which large language models are the most\nprominent recent example, showcase some impressive performance. However they\nhave been empirically found to pose serious security issues. This paper\nsystematizes our knowledge about the fundamental impossibility of building\narbitrarily accurate and secure machine learning models. More precisely, we\nidentify key challenging features of many of today's machine learning settings.\nNamely, high accuracy seems to require memorizing large training datasets,\nwhich are often user-generated and highly heterogeneous, with both sensitive\ninformation and fake users. We then survey statistical lower bounds that, we\nargue, constitute a compelling case against the possibility of designing\nhigh-accuracy LAIMs with strong security guarantees.\n",
                "链接": "https://arxiv.org/abs/2209.15259"
            },
            {
                "文章ID": "104712",
                "标题": "Identifying the Risks of LM Agents with an LM-Emulated Sandbox",
                "作者": " Yangjun Ruan,  Honghua Dong,  Andrew Wang,  Silviu Pitis,  Yongchao Zhou,  Jimmy Ba,  Yann Dubois,  Chris J. Maddison,  Tatsunori Hashimoto",
                "发布日期": "2023-09-28",
                "摘要": "  Recent advances in Language Model (LM) agents and tool use, exemplified by\napplications like ChatGPT Plugins, enable a rich set of capabilities but also\namplify potential risks - such as leaking private data or causing financial\nlosses. Identifying these risks is labor-intensive, necessitating implementing\nthe tools, manually setting up the environment for each test scenario, and\nfinding risky cases. As tools and agents become more complex, the high cost of\ntesting these agents will make it increasingly difficult to find high-stakes,\nlong-tailed risks. To address these challenges, we introduce ToolEmu: a\nframework that uses an LM to emulate tool execution and enables the testing of\nLM agents against a diverse range of tools and scenarios, without manual\ninstantiation. Alongside the emulator, we develop an LM-based automatic safety\nevaluator that examines agent failures and quantifies associated risks. We test\nboth the tool emulator and evaluator through human evaluation and find that\n68.8% of failures identified with ToolEmu would be valid real-world agent\nfailures. Using our curated initial benchmark consisting of 36 high-stakes\ntools and 144 test cases, we provide a quantitative risk analysis of current LM\nagents and identify numerous failures with potentially severe outcomes.\nNotably, even the safest LM agent exhibits such failures 23.9% of the time\naccording to our evaluator, underscoring the need to develop safer LM agents\nfor real-world deployment.\n",
                "链接": "https://arxiv.org/abs/2309.15817"
            },
            {
                "文章ID": "81272",
                "标题": "Large Language Models as Tool Makers",
                "作者": " Tianle Cai,  Xuezhi Wang,  Tengyu Ma,  Xinyun Chen,  Denny Zhou",
                "发布日期": "2023-05-29",
                "摘要": "  Recent research shows the potential of enhancing the problem-solving ability\nof large language models (LLMs) through the use of external tools. However,\nprior work along this line depends on the availability of existing tools. In\nthis work, we take an initial step towards removing this dependency by\nproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),\nwhere LLMs create their own reusable tools for problem-solving. Our approach\nconsists of two key phases: 1) tool making: an LLM acts as the tool maker that\ncrafts tools for given tasks, where a tool is implemented as a Python utility\nfunction. 2) tool using: an LLM acts as the tool user, which applies the tool\nbuilt by the tool maker for problem-solving. The tool user can be either the\nsame or a different LLM from the tool maker. Tool-making enables an LLM to\ncontinually generate tools that can be applied to different requests so that\nfuture requests can call the corresponding APIs when beneficial for solving the\ntasks. Furthermore, the division of labor among LLMs for tool-making and\ntool-using phases introduces the opportunity to achieve cost effectiveness\nwithout degrading the quality of generated tools and problem solutions. For\nexample, recognizing that tool-making demands more sophisticated capabilities\nthan tool-using, we can apply a powerful yet resource-intensive model as the\ntool maker, and a lightweight while cost-effective model as the tool user. We\nvalidate the effectiveness of our approach across a variety of complex\nreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and\nGPT-3.5 as the tool user, LATM can achieve performance that is on par with\nusing GPT-4 for both tool making and tool using, while the inference cost is\nsignificantly reduced.\n",
                "链接": "https://arxiv.org/abs/2305.17126"
            },
            {
                "文章ID": "121990",
                "标题": "Safe Multi-Task Bayesian Optimization",
                "作者": " Jannis O. Lübsen,  Christian Hespe,  Annika Eichler",
                "发布日期": "2023-12-13",
                "摘要": "  Bayesian optimization has become a powerful tool for safe online optimization\nof systems, due to its high sample efficiency and noise robustness. For further\nspeed-up reduced physical models of the system can be incorporated into the\noptimization to accelerate the process, since the models are able to offer an\napproximation of the actual system, and sampling from them is significantly\ncheaper. The similarity between model and reality is represented by additional\nhyperparameters and learned within the optimization process. Safety is an\nimportant criteria for online optimization methods like Bayesian optimization,\nwhich has been addressed by recent literature, which provide safety guarantees\nunder the assumption of known hyperparameters. However, in practice this is not\napplicable. Therefore, we extend the robust Gaussian process uniform error\nbounds to meet the multi-task setting, which involves the calculation of a\nconfidence region from the hyperparameter posterior distribution utilizing\nMarkov chain Monte Carlo methods. Then, using the robust safety bounds,\nBayesian optimization is applied to safely optimize the system while\nincorporating measurements of the models. Simulations show that the\noptimization can be significantly accelerated compared to other\nstate-of-the-art safe Bayesian optimization methods depending on the fidelity\nof the models.\n",
                "链接": "https://arxiv.org/abs/2312.07281"
            },
            {
                "文章ID": "105613",
                "标题": "All Languages Matter: On the Multilingual Safety of Large Language\n  Models",
                "作者": " Wenxuan Wang,  Zhaopeng Tu,  Chang Chen,  Youliang Yuan,  Jen-tse Huang,  Wenxiang Jiao,  Michael R. Lyu",
                "发布日期": "2023-10-03",
                "摘要": "  Safety lies at the core of developing and deploying large language models\n(LLMs). However, previous safety benchmarks only concern the safety in one\nlanguage, e.g. the majority language in the pretraining data such as English.\nIn this work, we build the first multilingual safety benchmark for LLMs,\nXSafety, in response to the global deployment of LLMs in practice. XSafety\ncovers 14 kinds of commonly used safety issues across 10 languages that span\nseveral language families. We utilize XSafety to empirically study the\nmultilingual safety for 4 widely-used LLMs, including both close-API and\nopen-source models. Experimental results show that all LLMs produce\nsignificantly more unsafe responses for non-English queries than English ones,\nindicating the necessity of developing safety alignment for non-English\nlanguages. In addition, we propose several simple and effective prompting\nmethods to improve the multilingual safety of ChatGPT by evoking safety\nknowledge and improving cross-lingual generalization of safety alignment. Our\nprompting method can significantly reduce the ratio of unsafe responses from\n19.1% to 9.7% for non-English queries. We release our data at\nhttps://github.com/Jarviswang94/Multilingual_safety_benchmark.\n",
                "链接": "https://arxiv.org/abs/2310.00905"
            },
            {
                "文章ID": "80992",
                "标题": "On the Tool Manipulation Capability of Open-source Large Language Models",
                "作者": " Qiantong Xu,  Fenglu Hong,  Bo Li,  Changran Hu,  Zhengyu Chen,  Jian Zhang",
                "发布日期": "2023-05-29",
                "摘要": "  Recent studies on software tool manipulation with large language models\n(LLMs) mostly rely on closed model APIs. The industrial adoption of these\nmodels is substantially constrained due to the security and robustness risks in\nexposing information to closed LLM API services. In this paper, we ask can we\nenhance open-source LLMs to be competitive to leading closed LLM APIs in tool\nmanipulation, with practical amount of human supervision. By analyzing common\ntool manipulation failures, we first demonstrate that open-source LLMs may\nrequire training with usage examples, in-context demonstration and generation\nstyle regulation to resolve failures. These insights motivate us to revisit\nclassical methods in LLM literature, and demonstrate that we can adapt them as\nmodel alignment with programmatic data generation, system prompts and\nin-context demonstration retrievers to enhance open-source LLMs for tool\nmanipulation. To evaluate these techniques, we create the ToolBench, a tool\nmanipulation benchmark consisting of diverse software tools for real-world\ntasks. We demonstrate that our techniques can boost leading open-source LLMs by\nup to 90% success rate, showing capabilities competitive to OpenAI GPT-4 in 4\nout of 8 ToolBench tasks. We show that such enhancement typically requires\nabout one developer day to curate data for each tool, rendering a recipe with\npractical amount of human supervision.\n",
                "链接": "https://arxiv.org/abs/2305.16504"
            },
            {
                "文章ID": "107889",
                "标题": "Syntax Error-Free and Generalizable Tool Use for LLMs via Finite-State\n  Decoding",
                "作者": " Kexun Zhang,  Hongqiao Chen,  Lei Li,  William Wang",
                "发布日期": "2023-10-12",
                "摘要": "  Large language models (LLMs) have shown promising capabilities in using\nexternal tools to solve complex problems. However, existing approaches either\ninvolve fine-tuning on tool demonstrations, which do not generalize to new\ntools without additional training, or providing tool documentation in context,\nlimiting the number of tools. Both approaches often generate syntactically\ninvalid tool calls. In this paper, we propose ToolDec, a finite-state\nmachine-guided decoding algorithm for tool-augmented LLMs. ToolDec eliminates\ntool-related errors for any tool-augmented LLMs by ensuring valid tool names\nand type-conforming arguments. Furthermore, ToolDec enables LLM to effectively\nselect tools using only the information contained in their names, with no need\nfor fine-tuning or in-context documentation. We evaluated multiple prior\nmethods and their ToolDec-enhanced versions on a variety of tasks involving\ntools like math functions, knowledge graph relations, and complex real-world\nRESTful APIs. Our experiments show that ToolDec reduces syntactic errors to\nzero, consequently achieving significantly better performance and as much as a\n2x speedup. We also show that ToolDec achieves superior generalization\nperformance on unseen tools, performing up to 8x better than the baselines.\n",
                "链接": "https://arxiv.org/abs/2310.07075"
            },
            {
                "文章ID": "94169",
                "标题": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language\n  Models",
                "作者": " Cheng-Yu Hsieh,  Si-An Chen,  Chun-Liang Li,  Yasuhisa Fujii,  Alexander Ratner,  Chen-Yu Lee,  Ranjay Krishna,  Tomas Pfister",
                "发布日期": "2023-08-02",
                "摘要": "  Today, large language models (LLMs) are taught to use new tools by providing\na few demonstrations of the tool's usage. Unfortunately, demonstrations are\nhard to acquire, and can result in undesirable biased usage if the wrong\ndemonstration is chosen. Even in the rare scenario that demonstrations are\nreadily available, there is no principled selection protocol to determine how\nmany and which ones to provide. As tasks grow more complex, the selection\nsearch grows combinatorially and invariably becomes intractable. Our work\nprovides an alternative to demonstrations: tool documentation. We advocate the\nuse of tool documentation, descriptions for the individual tool usage, over\ndemonstrations. We substantiate our claim through three main empirical findings\non 6 tasks across both vision and language modalities. First, on existing\nbenchmarks, zero-shot prompts with only tool documentation are sufficient for\neliciting proper tool usage, achieving performance on par with few-shot\nprompts. Second, on a newly collected realistic tool-use dataset with hundreds\nof available tool APIs, we show that tool documentation is significantly more\nvaluable than demonstrations, with zero-shot documentation significantly\noutperforming few-shot without documentation. Third, we highlight the benefits\nof tool documentations by tackling image generation and video tracking using\njust-released unseen state-of-the-art models as tools. Finally, we highlight\nthe possibility of using tool documentation to automatically enable new\napplications: by using nothing more than the documentation of GroundingDino,\nStable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the\njust-released Grounded-SAM and Track Anything models.\n",
                "链接": "https://arxiv.org/abs/2308.00675"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下对使用GPT生成数据集的训练步骤进行改进的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "68065",
                "标题": "Generate labeled training data using Prompt Programming and GPT-3. An\n  example of Big Five Personality Classification",
                "作者": " Eason Chen",
                "发布日期": "2023-03-23",
                "摘要": "  We generated 25000 conversations labeled with Big Five Personality traits\nusing prompt programming at GPT-3. Then we train Big Five classification models\nwith these data and evaluate them with 2500 data from generated dialogues and\nreal conversational datasets labeled in Big Five by human annotators. The\nresults indicated that this approach is promising for creating effective\ntraining data. We then compare the performance by different training approaches\nand models. Our results suggest that using Adapter-Transformers and transfer\nlearning from pre-trained RoBERTa sentiment analysis model will perform best\nwith the generated data. Our best model obtained an accuracy of 0.71 in\ngenerated data and 0.65 in real datasets. Finally, we discuss this approach's\npotential limitations and confidence metric.\n",
                "链接": "https://arxiv.org/abs/2303.12279"
            },
            {
                "文章ID": "56440",
                "标题": "Automatic Generation of German Drama Texts Using Fine Tuned GPT-2 Models",
                "作者": " Mariam Bangura,  Kristina Barabashova,  Anna Karnysheva,  Sarah Semczuk,  Yifan Wang",
                "发布日期": "2023-01-11",
                "摘要": "  This study is devoted to the automatic generation of German drama texts. We\nsuggest an approach consisting of two key steps: fine-tuning a GPT-2 model (the\noutline model) to generate outlines of scenes based on keywords and fine-tuning\na second model (the generation model) to generate scenes from the scene\noutline. The input for the neural model comprises two datasets: the German\nDrama Corpus (GerDraCor) and German Text Archive (Deutsches Textarchiv or DTA).\nIn order to estimate the effectiveness of the proposed method, our models are\ncompared with baseline GPT-2 models. Our models perform well according to\nautomatic quantitative evaluation, but, conversely, manual qualitative analysis\nreveals a poor quality of generated texts. This may be due to the quality of\nthe dataset or training inputs.\n",
                "链接": "https://arxiv.org/abs/2301.03119"
            },
            {
                "文章ID": "20498",
                "标题": "Improving Short Text Classification With Augmented Data Using GPT-3",
                "作者": " Salvador Balkus,  Donghui Yan",
                "发布日期": "2023-08-29",
                "摘要": "  GPT-3 is a large-scale natural language model developed by OpenAI that can\nperform many different tasks, including topic classification. Although\nresearchers claim that it requires only a small number of in-context examples\nto learn a task, in practice GPT-3 requires these training examples to be\neither of exceptional quality or a higher quantity than easily created by hand.\nTo address this issue, this study teaches GPT-3 to classify whether a question\nis related to data science by augmenting a small training set with additional\nexamples generated by GPT-3 itself. This study compares two classifiers: the\nGPT-3 Classification Endpoint with augmented examples, and the GPT-3 Completion\nEndpoint with an optimal training set chosen using a genetic algorithm. We find\nthat while the augmented Completion Endpoint achieves upwards of 80 percent\nvalidation accuracy, using the augmented Classification Endpoint yields more\nconsistent accuracy on unseen examples. In this way, giving large-scale machine\nlearning models like GPT-3 the ability to propose their own additional training\nexamples can result in improved classification performance.\n",
                "链接": "https://arxiv.org/abs/2205.10981"
            },
            {
                "文章ID": "112047",
                "标题": "Using GPT-4 to Augment Unbalanced Data for Automatic Scoring",
                "作者": " Luyang Fang,  Gyeong-Geon Lee,  Xiaoming Zhai",
                "发布日期": "2023-11-21",
                "摘要": "  Machine learning-based automatic scoring can be challenging if students'\nresponses are unbalanced across scoring categories, as it introduces\nuncertainty in the machine training process. To meet this challenge, we\nintroduce a novel text data augmentation framework using GPT-4, a generative\nlarge language model, specifically tailored for unbalanced datasets in\nautomatic scoring. Our experimental dataset comprised student-written responses\nto two science items. We crafted prompts for GPT-4 to generate responses\nresembling student-written answers, particularly for the minority scoring\nclasses, to augment the data. We then finetuned DistillBERT for automatic\nscoring based on the augmented and original datasets. Model performance was\nassessed using accuracy, precision, recall, and F1 score. We incorporate varied\namounts of augmented data to examine scoring performance, and our findings\nrevealed remarkedly improved model performance. The average maximum increase\nobserved across two items is: 3.5% for accuracy, 30.6% for precision, 21.1% for\nrecall, and 24.2% for F1 score. Notably, using just 5% of the augmented data\nled to substantial improvements: 2.6%, 29.2%, 15.1%, and 19.6%. Interestingly,\nthe extent of improvement varied depending on specific datasets. Moreover, we\nfound that a varying amount of augmented data (5%-40%) was needed to obtain a\nstable improvement. We also compare models trained with GPT-4 augmented data\nand those trained with additional student-written responses. The findings\nindicate that former ones match or even exceed the performance of the latter.\nSpecifically, there is an average difference of 1.7%, 1.9%, 11.0%, and 7.8% for\nfour metrics separately. This research underscores the potential and\neffectiveness of data augmentation techniques utilizing GPT-4 in addressing\nunbalanced datasets within automated assessment.\n",
                "链接": "https://arxiv.org/abs/2310.18365"
            },
            {
                "文章ID": "121374",
                "标题": "Sim-GPT: Text Similarity via GPT Annotated Data",
                "作者": " Shuhe Wang,  Beiming Cao,  Shengyu Zhang,  Xiaoya Li,  Jiwei Li,  Fei Wu,  Guoyin Wang,  Eduard Hovy",
                "发布日期": "2023-12-13",
                "摘要": "  Due to the lack of a large collection of high-quality labeled sentence pairs\nwith textual similarity scores, existing approaches for Semantic Textual\nSimilarity (STS) mostly rely on unsupervised techniques or training signals\nthat are only partially correlated with textual similarity, e.g., NLI-based\ndatasets. To tackle this issue, in this paper, we propose the strategy of\nmeasuring text similarity via GPT annotated data (Sim-GPT for short). The core\nidea of Sim-GPT is to generate data with STS labels using GPT-4, based on which\nan STS model is trained. Sim-GPT framework utilizes LLMs to provide a\nsubstantial amount of reliable annotated data filling the gap of the lack of\ntraining signals for STS. Sim-GPT is trained on a one-time generated dataset\nusing BERT or RoBERTa as the backbone, which offers long-term savings in cost\nand speed compared to repeatedly invoking LLMs for each sentence pair. Trained\non the examples from GPT-4 (371K), Sim-GPT yields SOTA performances on the\nwidely-used seven STS benchmarks: +0.99 over supervised-SimCSE, and +0.42 over\nthe current SOTA PromCSE model. To encourage further advancements of the field,\nwe release both models and the 371K annotated examples from GPT-4. Code, models\nand annotated data are available at: https://github.com/ShuheWang1998/Sim-GPT.\n",
                "链接": "https://arxiv.org/abs/2312.05603"
            },
            {
                "文章ID": "94735",
                "标题": "Learning to Generate Training Datasets for Robust Semantic Segmentation",
                "作者": " Marwane Hariat,  Olivier Laurent,  Rémi Kazmierczak,  Shihao Zhang,  Andrei Bursuc,  Angela Yao,  Gianni Franchi",
                "发布日期": "2023-08-21",
                "摘要": "  Semantic segmentation techniques have shown significant progress in recent\nyears, but their robustness to real-world perturbations and data samples not\nseen during training remains a challenge, particularly in safety-critical\napplications. In this paper, we propose a novel approach to improve the\nrobustness of semantic segmentation techniques by leveraging the synergy\nbetween label-to-image generators and image-to-label segmentation models.\nSpecifically, we design and train Robusta, a novel robust conditional\ngenerative adversarial network to generate realistic and plausible perturbed or\noutlier images that can be used to train reliable segmentation models. We\nconduct in-depth studies of the proposed generative model, assess the\nperformance and robustness of the downstream segmentation network, and\ndemonstrate that our approach can significantly enhance the robustness of\nsemantic segmentation techniques in the face of real-world perturbations,\ndistribution shifts, and out-of-distribution samples. Our results suggest that\nthis approach could be valuable in safety-critical applications, where the\nreliability of semantic segmentation techniques is of utmost importance and\ncomes with a limited computational budget in inference. We will release our\ncode shortly.\n",
                "链接": "https://arxiv.org/abs/2308.02535"
            },
            {
                "文章ID": "15595",
                "标题": "CodexDB: Generating Code for Processing SQL Queries using GPT-3 Codex",
                "作者": " Immanuel Trummer",
                "发布日期": "2022-04-20",
                "摘要": "  CodexDB is an SQL processing engine whose internals can be customized via\nnatural language instructions. CodexDB is based on OpenAI's GPT-3 Codex model\nwhich translates text into code. It is a framework on top of GPT-3 Codex that\ndecomposes complex SQL queries into a series of simple processing steps,\ndescribed in natural language. Processing steps are enriched with user-provided\ninstructions and descriptions of database properties. Codex translates the\nresulting text into query processing code. An early prototype of CodexDB is\nable to generate correct code for a majority of queries of the WikiSQL\nbenchmark and can be customized in various ways.\n",
                "链接": "https://arxiv.org/abs/2204.08941"
            },
            {
                "文章ID": "45055",
                "标题": "On Robust Incremental Learning over Many Multilingual Steps",
                "作者": " Karan Praharaj,  Irina Matveeva",
                "发布日期": "2022-10-27",
                "摘要": "  Recent work in incremental learning has introduced diverse approaches to\ntackle catastrophic forgetting from data augmentation to optimized training\nregimes. However, most of them focus on very few training steps. We propose a\nmethod for robust incremental learning over dozens of fine-tuning steps using\ndata from a variety of languages. We show that a combination of\ndata-augmentation and an optimized training regime allows us to continue\nimproving the model even for as many as fifty training steps. Crucially, our\naugmentation strategy does not require retaining access to previous training\ndata and is suitable in scenarios with privacy constraints.\n",
                "链接": "https://arxiv.org/abs/2210.14307"
            },
            {
                "文章ID": "35504",
                "标题": "Generating Intermediate Steps for NLI with Next-Step Supervision",
                "作者": " Deepanway Ghosal,  Somak Aditya,  Monojit Choudhury",
                "发布日期": "2022-09-01",
                "摘要": "  The Natural Language Inference (NLI) task often requires reasoning over\nmultiple steps to reach the conclusion. While the necessity of generating such\nintermediate steps (instead of a summary explanation) has gained popular\nsupport, it is unclear how to generate such steps without complete end-to-end\nsupervision and how such generated steps can be further utilized. In this work,\nwe train a sequence-to-sequence model to generate only the next step given an\nNLI premise and hypothesis pair (and previous steps); then enhance it with\nexternal knowledge and symbolic search to generate intermediate steps with only\nnext-step supervision. We show the correctness of such generated steps through\nautomated and human verification. Furthermore, we show that such generated\nsteps can help improve end-to-end NLI task performance using simple data\naugmentation strategies, across multiple public NLI datasets.\n",
                "链接": "https://arxiv.org/abs/2208.14641"
            },
            {
                "文章ID": "79980",
                "标题": "Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with\n  Customized Exercise Generation",
                "作者": " Zhenwen Liang,  Wenhao Yu,  Tanmay Rajpurohit,  Peter Clark,  Xiangliang Zhang,  Ashwin Kaylan",
                "发布日期": "2023-05-25",
                "摘要": "  In this paper, we present a novel approach for distilling math word problem\nsolving capabilities from large language models (LLMs) into smaller, more\nefficient student models. Our approach is designed to consider the student\nmodel's weaknesses and foster a tailored learning experience by generating\ntargeted exercises aligned with educational science principles, such as\nknowledge tracing and personalized learning. Concretely, we let GPT-3 be a math\ntutor and run two steps iteratively: 1) assessing the student model's current\nlearning status on a GPT-generated exercise book, and 2) improving the student\nmodel by training it with tailored exercise samples generated by GPT-3.\nExperimental results reveal that our approach outperforms LLMs (e.g., GPT-3 and\nPaLM) in accuracy across three distinct benchmarks while employing\nsignificantly fewer parameters. Furthermore, we provide a comprehensive\nanalysis of the various components within our methodology to substantiate their\nefficacy.\n",
                "链接": "https://arxiv.org/abs/2305.14386"
            }
        ]
    },
    {
        "question": {
            "question": "请找到利用clip做开放词汇检测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "105778",
                "标题": "CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense\n  Prediction",
                "作者": " Size Wu,  Wenwei Zhang,  Lumin Xu,  Sheng Jin,  Xiangtai Li,  Wentao Liu,  Chen Change Loy",
                "发布日期": "2023-10-03",
                "摘要": "  Open-vocabulary dense prediction tasks including object detection and image\nsegmentation have been advanced by the success of Contrastive Language-Image\nPre-training (CLIP). CLIP models, particularly those incorporating vision\ntransformers (ViTs), have exhibited remarkable generalization ability in\nzero-shot image classification. However, when transferring the vision-language\nalignment of CLIP from global image representation to local region\nrepresentation for the open-vocabulary dense prediction tasks, CLIP ViTs suffer\nfrom the domain shift from full images to local image regions. In this paper,\nwe embark on an in-depth analysis of the region-language alignment in CLIP\nmodels, which is essential for downstream open-vocabulary dense prediction\ntasks. Subsequently, we propose an approach named CLIPSelf, which adapts the\nimage-level recognition ability of CLIP ViT to local image regions without\nneeding any region-text pairs. CLIPSelf empowers ViTs to distill itself by\naligning a region representation extracted from its dense feature map with the\nimage-level representation of the corresponding image crop. With the enhanced\nCLIP ViTs, we achieve new state-of-the-art performance on open-vocabulary\nobject detection, semantic segmentation, and panoptic segmentation across\nvarious benchmarks. Models and code will be available at\nhttps://github.com/wusize/CLIPSelf.\n",
                "链接": "https://arxiv.org/abs/2310.01403"
            },
            {
                "文章ID": "121784",
                "标题": "OpenSD: Unified Open-Vocabulary Segmentation and Detection",
                "作者": " Shuai Li,  Minghan Li,  Pengfei Wang,  Lei Zhang",
                "发布日期": "2023-12-13",
                "摘要": "  Recently, a few open-vocabulary methods have been proposed by employing a\nunified architecture to tackle generic segmentation and detection tasks.\nHowever, their performance still lags behind the task-specific models due to\nthe conflict between different tasks, and their open-vocabulary capability is\nlimited due to the inadequate use of CLIP. To address these challenges, we\npresent a universal transformer-based framework, abbreviated as OpenSD, which\nutilizes the same architecture and network parameters to handle open-vocabulary\nsegmentation and detection tasks. First, we introduce a decoder decoupled\nlearning strategy to alleviate the semantic conflict between thing and staff\ncategories so that each individual task can be learned more effectively under\nthe same framework. Second, to better leverage CLIP for end-to-end segmentation\nand detection, we propose dual classifiers to handle the in-vocabulary domain\nand out-of-vocabulary domain, respectively. The text encoder is further trained\nto be region-aware for both thing and stuff categories through decoupled prompt\nlearning, enabling them to filter out duplicated and low-quality predictions,\nwhich is important to end-to-end segmentation and detection. Extensive\nexperiments are conducted on multiple datasets under various circumstances. The\nresults demonstrate that OpenSD outperforms state-of-the-art open-vocabulary\nsegmentation and detection methods in both closed- and open-vocabulary\nsettings. Code is available at https://github.com/strongwolf/OpenSD\n",
                "链接": "https://arxiv.org/abs/2312.06703"
            },
            {
                "文章ID": "124461",
                "标题": "FM-OV3D: Foundation Model-based Cross-modal Knowledge Blending for\n  Open-Vocabulary 3D Detection",
                "作者": " Dongmei Zhang,  Chang Li,  Ray Zhang,  Shenghao Xie,  Wei Xue,  Xiaodong Xie,  Shanghang Zhang",
                "发布日期": "2023-12-25",
                "摘要": "  The superior performances of pre-trained foundation models in various visual\ntasks underscore their potential to enhance the 2D models' open-vocabulary\nability. Existing methods explore analogous applications in the 3D space.\nHowever, most of them only center around knowledge extraction from singular\nfoundation models, which limits the open-vocabulary ability of 3D models. We\nhypothesize that leveraging complementary pre-trained knowledge from various\nfoundation models can improve knowledge transfer from 2D pre-trained visual\nlanguage models to the 3D space. In this work, we propose FM-OV3D, a method of\nFoundation Model-based Cross-modal Knowledge Blending for Open-Vocabulary 3D\nDetection, which improves the open-vocabulary localization and recognition\nabilities of 3D model by blending knowledge from multiple pre-trained\nfoundation models, achieving true open-vocabulary without facing constraints\nfrom original 3D datasets. Specifically, to learn the open-vocabulary 3D\nlocalization ability, we adopt the open-vocabulary localization knowledge of\nthe Grounded-Segment-Anything model. For open-vocabulary 3D recognition\nability, We leverage the knowledge of generative foundation models, including\nGPT-3 and Stable Diffusion models, and cross-modal discriminative models like\nCLIP. The experimental results on two popular benchmarks for open-vocabulary 3D\nobject detection show that our model efficiently learns knowledge from multiple\nfoundation models to enhance the open-vocabulary ability of the 3D model and\nsuccessfully achieves state-of-the-art performance in open-vocabulary 3D object\ndetection tasks. Code is released at\nhttps://github.com/dmzhang0425/FM-OV3D.git.\n",
                "链接": "https://arxiv.org/abs/2312.14465"
            },
            {
                "文章ID": "68854",
                "标题": "Prompt-Guided Transformers for End-to-End Open-Vocabulary Object\n  Detection",
                "作者": " Hwanjun Song,  Jihwan Bang",
                "发布日期": "2023-03-28",
                "摘要": "  Prompt-OVD is an efficient and effective framework for open-vocabulary object\ndetection that utilizes class embeddings from CLIP as prompts, guiding the\nTransformer decoder to detect objects in both base and novel classes.\nAdditionally, our novel RoI-based masked attention and RoI pruning techniques\nhelp leverage the zero-shot classification ability of the Vision\nTransformer-based CLIP, resulting in improved detection performance at minimal\ncomputational cost. Our experiments on the OV-COCO and OVLVIS datasets\ndemonstrate that Prompt-OVD achieves an impressive 21.2 times faster inference\nspeed than the first end-to-end open-vocabulary detection method (OV-DETR),\nwhile also achieving higher APs than four two-stage-based methods operating\nwithin similar inference time ranges. Code will be made available soon.\n",
                "链接": "https://arxiv.org/abs/2303.14386"
            },
            {
                "文章ID": "94707",
                "标题": "Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen\n  Convolutional CLIP",
                "作者": " Qihang Yu,  Ju He,  Xueqing Deng,  Xiaohui Shen,  Liang-Chieh Chen",
                "发布日期": "2023-11-16",
                "摘要": "  Open-vocabulary segmentation is a challenging task requiring segmenting and\nrecognizing objects from an open set of categories. One way to address this\nchallenge is to leverage multi-modal models, such as CLIP, to provide image and\ntext features in a shared embedding space, which bridges the gap between\nclosed-vocabulary and open-vocabulary recognition. Hence, existing methods\noften adopt a two-stage framework to tackle the problem, where the inputs first\ngo through a mask generator and then through the CLIP model along with the\npredicted masks. This process involves extracting features from images multiple\ntimes, which can be ineffective and inefficient. By contrast, we propose to\nbuild everything into a single-stage framework using a shared Frozen\nConvolutional CLIP backbone, which not only significantly simplifies the\ncurrent two-stage pipeline, but also remarkably yields a better accuracy-cost\ntrade-off. The proposed FC-CLIP, benefits from the following observations: the\nfrozen CLIP backbone maintains the ability of open-vocabulary classification\nand can also serve as a strong mask generator, and the convolutional CLIP\ngeneralizes well to a larger input resolution than the one used during\ncontrastive image-text pretraining. When training on COCO panoptic data only\nand testing in a zero-shot manner, FC-CLIP achieve 26.8 PQ, 16.8 AP, and 34.1\nmIoU on ADE20K, 18.2 PQ, 27.9 mIoU on Mapillary Vistas, 44.0 PQ, 26.8 AP, 56.2\nmIoU on Cityscapes, outperforming the prior art by +4.2 PQ, +2.4 AP, +4.2 mIoU\non ADE20K, +4.0 PQ on Mapillary Vistas and +20.1 PQ on Cityscapes,\nrespectively. Additionally, the training and testing time of FC-CLIP is 7.5x\nand 6.6x significantly faster than the same prior art, while using 5.9x fewer\nparameters. FC-CLIP also sets a new state-of-the-art performance across various\nopen-vocabulary semantic segmentation datasets. Code at\nhttps://github.com/bytedance/fc-clip\n",
                "链接": "https://arxiv.org/abs/2308.02487"
            },
            {
                "文章ID": "28246",
                "标题": "Bridging the Gap between Object and Image-level Representations for\n  Open-Vocabulary Detection",
                "作者": " Hanoona Rasheed,  Muhammad Maaz,  Muhammad Uzair Khattak,  Salman Khan,  Fahad Shahbaz Khan",
                "发布日期": "2022-11-30",
                "摘要": "  Existing open-vocabulary object detectors typically enlarge their vocabulary\nsizes by leveraging different forms of weak supervision. This helps generalize\nto novel objects at inference. Two popular forms of weak-supervision used in\nopen-vocabulary detection (OVD) include pretrained CLIP model and image-level\nsupervision. We note that both these modes of supervision are not optimally\naligned for the detection task: CLIP is trained with image-text pairs and lacks\nprecise localization of objects while the image-level supervision has been used\nwith heuristics that do not accurately specify local object regions. In this\nwork, we propose to address this problem by performing object-centric alignment\nof the language embeddings from the CLIP model. Furthermore, we visually ground\nthe objects with only image-level supervision using a pseudo-labeling process\nthat provides high-quality object proposals and helps expand the vocabulary\nduring training. We establish a bridge between the above two object-alignment\nstrategies via a novel weight transfer function that aggregates their\ncomplimentary strengths. In essence, the proposed model seeks to minimize the\ngap between object and image-centric representations in the OVD setting. On the\nCOCO benchmark, our proposed approach achieves 36.6 AP50 on novel classes, an\nabsolute 8.2 gain over the previous best performance. For LVIS, we surpass the\nstate-of-the-art ViLD model by 5.0 mask AP for rare categories and 3.4 overall.\nCode: https://github.com/hanoonaR/object-centric-ovd.\n",
                "链接": "https://arxiv.org/abs/2207.03482"
            },
            {
                "文章ID": "116861",
                "标题": "CastDet: Toward Open Vocabulary Aerial Object Detection with\n  CLIP-Activated Student-Teacher Learning",
                "作者": " Yan Li,  Weiwei Guo,  Dunyun He,  Jiaqi Zhou,  Yuze Gao,  Wenxian Yu",
                "发布日期": "2023-11-21",
                "摘要": "  Object detection in aerial images is a pivotal task for various earth\nobservation applications, whereas current algorithms learn to detect only a\npre-defined set of object categories demanding sufficient bounding-box\nannotated training samples and fail to detect novel object categories. In this\npaper, we consider open-vocabulary object detection (OVD) in aerial images that\nenables the characterization of new objects beyond training categories on the\nearth surface without annotating training images for these new categories. The\nperformance of OVD depends on the quality of class-agnostic region proposals\nand pseudo-labels that can generalize well to novel object categories. To\nsimultaneously generate high-quality proposals and pseudo-labels, we propose\nCastDet, a CLIP-activated student-teacher open-vocabulary object Detection\nframework. Our end-to-end framework within the student-teacher mechanism\nemploys the CLIP model as an extra omniscient teacher of rich knowledge into\nthe student-teacher self-learning process. By doing so, our approach boosts\nnovel object proposals and classification. Furthermore, we design a dynamic\nlabel queue technique to maintain high-quality pseudo labels during batch\ntraining and mitigate label imbalance. We conduct extensive experiments on\nmultiple existing aerial object detection datasets, which are set up for the\nOVD task. Experimental results demonstrate our CastDet achieving superior\nopen-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean),\nwhich outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD\ndataset.\n",
                "链接": "https://arxiv.org/abs/2311.11646"
            },
            {
                "文章ID": "120843",
                "标题": "Open-Vocabulary Segmentation with Semantic-Assisted Calibration",
                "作者": " Yong Liu,  Sule Bai,  Guanbin Li,  Yitong Wang,  Yansong Tang",
                "发布日期": "2023-12-08",
                "摘要": "  This paper studies open-vocabulary segmentation (OVS) through calibrating\nin-vocabulary and domain-biased embedding space with generalized contextual\nprior of CLIP. As the core of open-vocabulary understanding, alignment of\nvisual content with the semantics of unbounded text has become the bottleneck\nof this field. To address this challenge, recent works propose to utilize CLIP\nas an additional classifier and aggregate model predictions with CLIP\nclassification results. Despite their remarkable progress, performance of OVS\nmethods in relevant scenarios is still unsatisfactory compared with supervised\ncounterparts. We attribute this to the in-vocabulary embedding and\ndomain-biased CLIP prediction. To this end, we present a Semantic-assisted\nCAlibration Network (SCAN). In SCAN, we incorporate generalized semantic prior\nof CLIP into proposal embedding to avoid collapsing on known categories.\nBesides, a contextual shift strategy is applied to mitigate the lack of global\ncontext and unnatural background noise. With above designs, SCAN achieves\nstate-of-the-art performance on all popular open-vocabulary segmentation\nbenchmarks. Furthermore, we also focus on the problem of existing evaluation\nsystem that ignores semantic duplication across categories, and propose a new\nmetric called Semantic-Guided IoU (SG-IoU).\n",
                "链接": "https://arxiv.org/abs/2312.04089"
            },
            {
                "文章ID": "110181",
                "标题": "SILC: Improving Vision Language Pretraining with Self-Distillation",
                "作者": " Muhammad Ferjad Naeem,  Yongqin Xian,  Xiaohua Zhai,  Lukas Hoyer,  Luc Van Gool,  Federico Tombari",
                "发布日期": "2023-12-08",
                "摘要": "  Image-Text pretraining on web-scale image caption datasets has become the\ndefault recipe for open vocabulary classification and retrieval models thanks\nto the success of CLIP and its variants. Several works have also used CLIP\nfeatures for dense prediction tasks and have shown the emergence of open-set\nabilities. However, the contrastive objective used by these models only focuses\non image-text alignment and does not incentivise image feature learning for\ndense prediction tasks. In this work, we introduce SILC, a novel framework for\nvision language pretraining. SILC improves image-text contrastive learning with\nthe simple addition of local-to-global correspondence learning by\nself-distillation. We show that distilling local image features from an\nexponential moving average (EMA) teacher model significantly improves model\nperformance on dense predictions tasks like detection and segmentation, while\nalso providing improvements on image-level tasks such as classification and\nretrieval. SILC models sets a new state of the art for zero-shot\nclassification, few shot classification, image and text retrieval, zero-shot\nsegmentation, and open vocabulary segmentation. We further show that SILC\nfeatures greatly benefit open vocabulary detection, captioning and visual\nquestion answering.\n",
                "链接": "https://arxiv.org/abs/2310.13355"
            },
            {
                "文章ID": "22912",
                "标题": "Delving into the Openness of CLIP",
                "作者": " Shuhuai Ren,  Lei Li,  Xuancheng Ren,  Guangxiang Zhao,  Xu Sun",
                "发布日期": "2023-05-09",
                "摘要": "  Contrastive Language-Image Pre-training (CLIP) formulates image\nclassification as an image-to-text matching task, i.e., matching images to the\ncorresponding natural language descriptions instead of discrete category IDs.\nThis allows for open-vocabulary visual recognition, where the model can\nrecognize images from an open class set (also known as an open vocabulary) in a\nzero-shot manner. However, evaluating the openness of CLIP-like models is\nchallenging, as the models are open to arbitrary vocabulary in theory, but\ntheir accuracy varies in practice. To address this, we resort to an incremental\nperspective to assess the openness through vocabulary expansions, and define\nextensibility to measure a model's ability to handle novel classes. Our\nevaluation shows that CLIP-like models are not truly open, and their\nperformance deteriorates as the vocabulary expands. We further dissect the\nfeature space of CLIP from the perspectives of representation alignment and\nuniformity. Our investigation reveals that the overestimation of openness is\ndue to confusion among competing text features, rather than a failure to\ncapture the similarity between image features and text features of novel\nclasses. We hope that our investigation and analysis will facilitate future\nresearch on the CLIP openness issue.\n",
                "链接": "https://arxiv.org/abs/2206.01986"
            }
        ]
    },
    {
        "question": {
            "question": "请找到使用自蒸馏加强目标检测性能的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "65588",
                "标题": "Smooth and Stepwise Self-Distillation for Object Detection",
                "作者": " Jieren Deng,  Xin Zhou,  Hao Tian,  Zhihong Pan,  Derek Aguiar",
                "发布日期": "2023-03-10",
                "摘要": "  Distilling the structured information captured in feature maps has\ncontributed to improved results for object detection tasks, but requires\ncareful selection of baseline architectures and substantial pre-training.\nSelf-distillation addresses these limitations and has recently achieved\nstate-of-the-art performance for object detection despite making several\nsimplifying architectural assumptions. Building on this work, we propose Smooth\nand Stepwise Self-Distillation (SSSD) for object detection. Our SSSD\narchitecture forms an implicit teacher from object labels and a feature pyramid\nnetwork backbone to distill label-annotated feature maps using Jensen-Shannon\ndistance, which is smoother than distillation losses used in prior work. We\nadditionally add a distillation coefficient that is adaptively configured based\non the learning rate. We extensively benchmark SSSD against a baseline and two\nstate-of-the-art object detector architectures on the COCO dataset by varying\nthe coefficients and backbone and detector networks. We demonstrate that SSSD\nachieves higher average precision in most experimental settings, is robust to a\nwide range of coefficients, and benefits from our stepwise distillation\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2303.05015"
            },
            {
                "文章ID": "92560",
                "标题": "Spatial Self-Distillation for Object Detection with Inaccurate Bounding\n  Boxes",
                "作者": " Di Wu,  Pengfei Chen,  Xuehui Yu,  Guorong Li,  Zhenjun Han,  Jianbin Jiao",
                "发布日期": "2023-08-16",
                "摘要": "  Object detection via inaccurate bounding boxes supervision has boosted a\nbroad interest due to the expensive high-quality annotation data or the\noccasional inevitability of low annotation quality (\\eg tiny objects). The\nprevious works usually utilize multiple instance learning (MIL), which highly\ndepends on category information, to select and refine a low-quality box. Those\nmethods suffer from object drift, group prediction and part domination problems\nwithout exploring spatial information. In this paper, we heuristically propose\na \\textbf{Spatial Self-Distillation based Object Detector (SSD-Det)} to mine\nspatial information to refine the inaccurate box in a self-distillation\nfashion. SSD-Det utilizes a Spatial Position Self-Distillation \\textbf{(SPSD)}\nmodule to exploit spatial information and an interactive structure to combine\nspatial information and category information, thus constructing a high-quality\nproposal bag. To further improve the selection procedure, a Spatial Identity\nSelf-Distillation \\textbf{(SISD)} module is introduced in SSD-Det to obtain\nspatial confidence to help select the best proposals. Experiments on MS-COCO\nand VOC datasets with noisy box annotation verify our method's effectiveness\nand achieve state-of-the-art performance. The code is available at\nhttps://github.com/ucas-vg/PointTinyBenchmark/tree/SSD-Det.\n",
                "链接": "https://arxiv.org/abs/2307.12101"
            },
            {
                "文章ID": "17577",
                "标题": "Cross Domain Object Detection by Target-Perceived Dual Branch\n  Distillation",
                "作者": " Mengzhe He,  Yali Wang,  Jiaxi Wu,  Yiru Wang,  Hanqing Li,  Bo Li,  Weihao Gan,  Wei Wu,  Yu Qiao",
                "发布日期": "2022-05-04",
                "摘要": "  Cross domain object detection is a realistic and challenging task in the\nwild. It suffers from performance degradation due to large shift of data\ndistributions and lack of instance-level annotations in the target domain.\nExisting approaches mainly focus on either of these two difficulties, even\nthough they are closely coupled in cross domain object detection. To solve this\nproblem, we propose a novel Target-perceived Dual-branch Distillation (TDD)\nframework. By integrating detection branches of both source and target domains\nin a unified teacher-student learning scheme, it can reduce domain shift and\ngenerate reliable supervision effectively. In particular, we first introduce a\ndistinct Target Proposal Perceiver between two domains. It can adaptively\nenhance source detector to perceive objects in a target image, by leveraging\ntarget proposal contexts from iterative cross-attention. Afterwards, we design\na concise Dual Branch Self Distillation strategy for model training, which can\nprogressively integrate complementary object knowledge from different domains\nvia self-distillation in two branches. Finally, we conduct extensive\nexperiments on a number of widely-used scenarios in cross domain object\ndetection. The results show that our TDD significantly outperforms the\nstate-of-the-art methods on all the benchmarks. Our code and model will be\navailable at https://github.com/Feobi1999/TDD.\n",
                "链接": "https://arxiv.org/abs/2205.01291"
            },
            {
                "文章ID": "114760",
                "标题": "Object-centric Cross-modal Feature Distillation for Event-based Object\n  Detection",
                "作者": " Lei Li,  Alexander Liniger,  Mario Millhaeusler,  Vagia Tsiminaki,  Yuanyou Li,  Dengxin Dai",
                "发布日期": "2023-11-10",
                "摘要": "  Event cameras are gaining popularity due to their unique properties, such as\ntheir low latency and high dynamic range. One task where these benefits can be\ncrucial is real-time object detection. However, RGB detectors still outperform\nevent-based detectors due to the sparsity of the event data and missing visual\ndetails. In this paper, we develop a novel knowledge distillation approach to\nshrink the performance gap between these two modalities. To this end, we\npropose a cross-modality object detection distillation method that by design\ncan focus on regions where the knowledge distillation works best. We achieve\nthis by using an object-centric slot attention mechanism that can iteratively\ndecouple features maps into object-centric features and corresponding\npixel-features used for distillation. We evaluate our novel distillation\napproach on a synthetic and a real event dataset with aligned grayscale images\nas a teacher modality. We show that object-centric distillation allows to\nsignificantly improve the performance of the event-based student object\ndetector, nearly halving the performance gap with respect to the teacher.\n",
                "链接": "https://arxiv.org/abs/2311.05494"
            },
            {
                "文章ID": "14912",
                "标题": "Spatial Likelihood Voting with Self-Knowledge Distillation for Weakly\n  Supervised Object Detection",
                "作者": " Ze Chen,  Zhihang Fu,  Jianqiang Huang,  Mingyuan Tao,  Rongxin Jiang,  Xiang Tian,  Yaowu Chen,  Xian-sheng Hua",
                "发布日期": "2022-04-15",
                "摘要": "  Weakly supervised object detection (WSOD), which is an effective way to train\nan object detection model using only image-level annotations, has attracted\nconsiderable attention from researchers. However, most of the existing methods,\nwhich are based on multiple instance learning (MIL), tend to localize instances\nto the discriminative parts of salient objects instead of the entire content of\nall objects. In this paper, we propose a WSOD framework called the Spatial\nLikelihood Voting with Self-knowledge Distillation Network (SLV-SD Net). In\nthis framework, we introduce a spatial likelihood voting (SLV) module to\nconverge region proposal localization without bounding box annotations.\nSpecifically, in every iteration during training, all the region proposals in a\ngiven image act as voters voting for the likelihood of each category in the\nspatial dimensions. After dilating the alignment on the area with large\nlikelihood values, the voting results are regularized as bounding boxes, which\nare then used for the final classification and localization. Based on SLV, we\nfurther propose a self-knowledge distillation (SD) module to refine the feature\nrepresentations of the given image. The likelihood maps generated by the SLV\nmodule are used to supervise the feature learning of the backbone network,\nencouraging the network to attend to wider and more diverse areas of the image.\nExtensive experiments on the PASCAL VOC 2007/2012 and MS-COCO datasets\ndemonstrate the excellent performance of SLV-SD Net. In addition, SLV-SD Net\nproduces new state-of-the-art results on these benchmarks.\n",
                "链接": "https://arxiv.org/abs/2204.06899"
            },
            {
                "文章ID": "112170",
                "标题": "Efficient Object Detection in Optical Remote Sensing Imagery via\n  Attention-based Feature Distillation",
                "作者": " Pourya Shamsolmoali,  Jocelyn Chanussot,  Huiyu Zhou,  Yue Lu",
                "发布日期": "2023-10-31",
                "摘要": "  Efficient object detection methods have recently received great attention in\nremote sensing. Although deep convolutional networks often have excellent\ndetection accuracy, their deployment on resource-limited edge devices is\ndifficult. Knowledge distillation (KD) is a strategy for addressing this issue\nsince it makes models lightweight while maintaining accuracy. However, existing\nKD methods for object detection have encountered two constraints. First, they\ndiscard potentially important background information and only distill nearby\nforeground regions. Second, they only rely on the global context, which limits\nthe student detector's ability to acquire local information from the teacher\ndetector. To address the aforementioned challenges, we propose Attention-based\nFeature Distillation (AFD), a new KD approach that distills both local and\nglobal information from the teacher detector. To enhance local distillation, we\nintroduce a multi-instance attention mechanism that effectively distinguishes\nbetween background and foreground elements. This approach prompts the student\ndetector to focus on the pertinent channels and pixels, as identified by the\nteacher detector. Local distillation lacks global information, thus attention\nglobal distillation is proposed to reconstruct the relationship between various\npixels and pass it from teacher to student detector. The performance of AFD is\nevaluated on two public aerial image benchmarks, and the evaluation results\ndemonstrate that AFD in object detection can attain the performance of other\nstate-of-the-art models while being efficient.\n",
                "链接": "https://arxiv.org/abs/2310.18676"
            },
            {
                "文章ID": "33013",
                "标题": "Self-Knowledge Distillation via Dropout",
                "作者": " Hyoje Lee,  Yeachan Park,  Hyun Seo,  Myungjoo Kang",
                "发布日期": "2022-08-12",
                "摘要": "  To boost the performance, deep neural networks require deeper or wider\nnetwork structures that involve massive computational and memory costs. To\nalleviate this issue, the self-knowledge distillation method regularizes the\nmodel by distilling the internal knowledge of the model itself. Conventional\nself-knowledge distillation methods require additional trainable parameters or\nare dependent on the data. In this paper, we propose a simple and effective\nself-knowledge distillation method using a dropout (SD-Dropout). SD-Dropout\ndistills the posterior distributions of multiple models through a dropout\nsampling. Our method does not require any additional trainable modules, does\nnot rely on data, and requires only simple operations. Furthermore, this simple\nmethod can be easily combined with various self-knowledge distillation\napproaches. We provide a theoretical and experimental analysis of the effect of\nforward and reverse KL-divergences in our work. Extensive experiments on\nvarious vision tasks, i.e., image classification, object detection, and\ndistribution shift, demonstrate that the proposed method can effectively\nimprove the generalization of a single network. Further experiments show that\nthe proposed method also improves calibration performance, adversarial\nrobustness, and out-of-distribution detection ability.\n",
                "链接": "https://arxiv.org/abs/2208.05642"
            },
            {
                "文章ID": "65349",
                "标题": "Gradient-Guided Knowledge Distillation for Object Detectors",
                "作者": " Qizhen Lan,  Qing Tian",
                "发布日期": "2023-03-09",
                "摘要": "  Deep learning models have demonstrated remarkable success in object\ndetection, yet their complexity and computational intensity pose a barrier to\ndeploying them in real-world applications (e.g., self-driving perception).\nKnowledge Distillation (KD) is an effective way to derive efficient models.\nHowever, only a small number of KD methods tackle object detection. Also, most\nof them focus on mimicking the plain features of the teacher model but rarely\nconsider how the features contribute to the final detection. In this paper, we\npropose a novel approach for knowledge distillation in object detection, named\nGradient-guided Knowledge Distillation (GKD). Our GKD uses gradient information\nto identify and assign more weights to features that significantly impact the\ndetection loss, allowing the student to learn the most relevant features from\nthe teacher. Furthermore, we present bounding-box-aware multi-grained feature\nimitation (BMFI) to further improve the KD performance. Experiments on the\nKITTI and COCO-Traffic datasets demonstrate our method's efficacy in knowledge\ndistillation for object detection. On one-stage and two-stage detectors, our\nGKD-BMFI leads to an average of 5.1% and 3.8% mAP improvement, respectively,\nbeating various state-of-the-art KD methods.\n",
                "链接": "https://arxiv.org/abs/2303.04240"
            },
            {
                "文章ID": "12802",
                "标题": "Self-distillation Augmented Masked Autoencoders for Histopathological\n  Image Classification",
                "作者": " Yang Luo,  Zhineng Chen,  Shengtian Zhou,  Xieping Gao",
                "发布日期": "2023-05-30",
                "摘要": "  Self-supervised learning (SSL) has drawn increasing attention in\nhistopathological image analysis in recent years. Compared to contrastive\nlearning which is troubled with the false negative problem, i.e., semantically\nsimilar images are selected as negative samples, masked autoencoders (MAE)\nbuilding SSL from a generative paradigm is probably a more appropriate\npre-training. In this paper, we introduce MAE and verify the effect of visible\npatches for histopathological image understanding. Moreover, a novel SD-MAE\nmodel is proposed to enable a self-distillation augmented MAE. Besides the\nreconstruction loss on masked image patches, SD-MAE further imposes the\nself-distillation loss on visible patches to enhance the representational\ncapacity of the encoder located shallow layer. We apply SD-MAE to\nhistopathological image classification, cell segmentation and object detection.\nExperiments demonstrate that SD-MAE shows highly competitive performance when\ncompared with other SSL methods in these tasks.\n",
                "链接": "https://arxiv.org/abs/2203.16983"
            },
            {
                "文章ID": "2760",
                "标题": "Adaptive Instance Distillation for Object Detection in Autonomous\n  Driving",
                "作者": " Qizhen Lan,  Qing Tian",
                "发布日期": "2023-03-23",
                "摘要": "  In recent years, knowledge distillation (KD) has been widely used to derive\nefficient models. Through imitating a large teacher model, a lightweight\nstudent model can achieve comparable performance with more efficiency. However,\nmost existing knowledge distillation methods are focused on classification\ntasks. Only a limited number of studies have applied knowledge distillation to\nobject detection, especially in time-sensitive autonomous driving scenarios. In\nthis paper, we propose Adaptive Instance Distillation (AID) to selectively\nimpart teacher's knowledge to the student to improve the performance of\nknowledge distillation. Unlike previous KD methods that treat all instances\nequally, our AID can attentively adjust the distillation weights of instances\nbased on the teacher model's prediction loss. We verified the effectiveness of\nour AID method through experiments on the KITTI and the COCO traffic datasets.\nThe results show that our method improves the performance of state-of-the-art\nattention-guided and non-local distillation methods and achieves better\ndistillation results on both single-stage and two-stage detectors. Compared to\nthe baseline, our AID led to an average of 2.7% and 2.1% mAP increases for\nsingle-stage and two-stage detectors, respectively. Furthermore, our AID is\nalso shown to be useful for self-distillation to improve the teacher model's\nperformance.\n",
                "链接": "https://arxiv.org/abs/2201.11097"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用2020年以后CONLL 2004数据集进行NER评测的论文",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找一下使用CrossWoz或MultiWoz数据集进行DST评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "7222",
                "标题": "ASSIST: Towards Label Noise-Robust Dialogue State Tracking",
                "作者": " Fanghua Ye,  Yue Feng,  Emine Yilmaz",
                "发布日期": "2022-03-15",
                "摘要": "  The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state\ntracking (DST). However, substantial noise has been discovered in its state\nannotations. Such noise brings about huge challenges for training DST models\nrobustly. Although several refined versions, including MultiWOZ 2.1-2.4, have\nbeen published recently, there are still lots of noisy labels, especially in\nthe training set. Besides, it is costly to rectify all the problematic\nannotations. In this paper, instead of improving the annotation quality\nfurther, we propose a general framework, named ASSIST (lAbel noiSe-robuSt\ndIalogue State Tracking), to train DST models robustly from noisy labels.\nASSIST first generates pseudo labels for each sample in the training set by\nusing an auxiliary model trained on a small clean dataset, then puts the\ngenerated pseudo labels and vanilla noisy labels together to train the primary\nmodel. We show the validity of ASSIST theoretically. Experimental results also\ndemonstrate that ASSIST improves the joint goal accuracy of DST by up to\n$28.16\\%$ on MultiWOZ 2.0 and $8.41\\%$ on MultiWOZ 2.4, compared to using only\nthe vanilla noisy labels.\n",
                "链接": "https://arxiv.org/abs/2202.13024"
            },
            {
                "文章ID": "61900",
                "标题": "Dialogue State Distillation Network with Inter-slot Contrastive Learning\n  for Dialogue State Tracking",
                "作者": " Jing Xu,  Dandan Song,  Chong Liu,  Siu Cheung Hui,  Fei Li,  Qiang Ju,  Xiaonan He,  Jian Xie",
                "发布日期": "2023-03-08",
                "摘要": "  In task-oriented dialogue systems, Dialogue State Tracking (DST) aims to\nextract users' intentions from the dialogue history. Currently, most existing\napproaches suffer from error propagation and are unable to dynamically select\nrelevant information when utilizing previous dialogue states. Moreover, the\nrelations between the updates of different slots provide vital clues for DST.\nHowever, the existing approaches rely only on predefined graphs to indirectly\ncapture the relations. In this paper, we propose a Dialogue State Distillation\nNetwork (DSDN) to utilize relevant information of previous dialogue states and\nmigrate the gap of utilization between training and testing. Thus, it can\ndynamically exploit previous dialogue states and avoid introducing error\npropagation simultaneously. Further, we propose an inter-slot contrastive\nlearning loss to effectively capture the slot co-update relations from dialogue\ncontext. Experiments are conducted on the widely used MultiWOZ 2.0 and MultiWOZ\n2.1 datasets. The experimental results show that our proposed model achieves\nthe state-of-the-art performance for DST.\n",
                "链接": "https://arxiv.org/abs/2302.08220"
            },
            {
                "文章ID": "17975",
                "标题": "LUNA: Learning Slot-Turn Alignment for Dialogue State Tracking",
                "作者": " Yifan Wang,  Jing Zhao,  Junwei Bao,  Chaoqun Duan,  Youzheng Wu,  Xiaodong He",
                "发布日期": "2022-05-06",
                "摘要": "  Dialogue state tracking (DST) aims to predict the current dialogue state\ngiven the dialogue history. Existing methods generally exploit the utterances\nof all dialogue turns to assign value for each slot. This could lead to\nsuboptimal results due to the information introduced from irrelevant utterances\nin the dialogue history, which may be useless and can even cause confusion. To\naddress this problem, we propose LUNA, a sLot-tUrN Alignment enhanced approach.\nIt first explicitly aligns each slot with its most relevant utterance, then\nfurther predicts the corresponding value based on this aligned utterance\ninstead of all dialogue utterances. Furthermore, we design a slot ranking\nauxiliary task to learn the temporal correlation among slots which could\nfacilitate the alignment. Comprehensive experiments are conducted on\nmulti-domain task-oriented dialogue datasets, i.e., MultiWOZ 2.0, MultiWOZ 2.1,\nand MultiWOZ 2.2. The results show that LUNA achieves new state-of-the-art\nresults on these datasets.\n",
                "链接": "https://arxiv.org/abs/2205.02550"
            },
            {
                "文章ID": "37569",
                "标题": "SF-DST: Few-Shot Self-Feeding Reading Comprehension Dialogue State\n  Tracking with Auxiliary Task",
                "作者": " Jihyun Lee,  Gary Geunbae Lee",
                "发布日期": "2022-09-19",
                "摘要": "  Few-shot dialogue state tracking (DST) model tracks user requests in dialogue\nwith reliable accuracy even with a small amount of data. In this paper, we\nintroduce an ontology-free few-shot DST with self-feeding belief state input.\nThe self-feeding belief state input increases the accuracy in multi-turn\ndialogue by summarizing previous dialogue. Also, we newly developed a slot-gate\nauxiliary task. This new auxiliary task helps classify whether a slot is\nmentioned in the dialogue. Our model achieved the best score in a few-shot\nsetting for four domains on multiWOZ 2.0.\n",
                "链接": "https://arxiv.org/abs/2209.07742"
            },
            {
                "文章ID": "40726",
                "标题": "Schema Encoding for Transferable Dialogue State Tracking",
                "作者": " Hyunmin Jeon,  Gary Geunbae Lee",
                "发布日期": "2022-10-06",
                "摘要": "  Dialogue state tracking (DST) is an essential sub-task for task-oriented\ndialogue systems. Recent work has focused on deep neural models for DST.\nHowever, the neural models require a large dataset for training. Furthermore,\napplying them to another domain needs a new dataset because the neural models\nare generally trained to imitate the given dataset. In this paper, we propose\nSchema Encoding for Transferable Dialogue State Tracking (SETDST), which is a\nneural DST method for effective transfer to new domains. Transferable DST could\nassist developments of dialogue systems even with few dataset on target\ndomains. We use a schema encoder not just to imitate the dataset but to\ncomprehend the schema of the dataset. We aim to transfer the model to new\ndomains by encoding new schemas and using them for DST on multi-domain\nsettings. As a result, SET-DST improved the joint accuracy by 1.46 points on\nMultiWOZ 2.1.\n",
                "链接": "https://arxiv.org/abs/2210.02351"
            },
            {
                "文章ID": "109162",
                "标题": "Semantic Parsing by Large Language Models for Intricate Updating\n  Strategies of Zero-Shot Dialogue State Tracking",
                "作者": " Yuxiang Wu,  Guanting Dong,  Weiran Xu",
                "发布日期": "2023-11-28",
                "摘要": "  Zero-shot Dialogue State Tracking (DST) addresses the challenge of acquiring\nand annotating task-oriented dialogues, which can be time-consuming and costly.\nHowever, DST extends beyond simple slot-filling and requires effective updating\nstrategies for tracking dialogue state as conversations progress. In this\npaper, we propose ParsingDST, a new In-Context Learning (ICL) method, to\nintroduce additional intricate updating strategies in zero-shot DST. Our\napproach reformulates the DST task by leveraging powerful Large Language Models\n(LLMs) and translating the original dialogue text to JSON through semantic\nparsing as an intermediate state. We also design a novel framework that\nincludes more modules to ensure the effectiveness of updating strategies in the\ntext-to-JSON process. Experimental results demonstrate that our approach\noutperforms existing zero-shot DST methods on MultiWOZ, exhibiting significant\nimprovements in Joint Goal Accuracy (JGA) and slot accuracy compared to\nexisting ICL methods. Our code has been released.\n",
                "链接": "https://arxiv.org/abs/2310.10520"
            },
            {
                "文章ID": "32158",
                "标题": "Act-Aware Slot-Value Predicting in Multi-Domain Dialogue State Tracking",
                "作者": " Ruolin Su,  Ting-Wei Wu,  Biing-Hwang Juang",
                "发布日期": "2022-08-05",
                "摘要": "  As an essential component in task-oriented dialogue systems, dialogue state\ntracking (DST) aims to track human-machine interactions and generate state\nrepresentations for managing the dialogue. Representations of dialogue states\nare dependent on the domain ontology and the user's goals. In several\ntask-oriented dialogues with a limited scope of objectives, dialogue states can\nbe represented as a set of slot-value pairs. As the capabilities of dialogue\nsystems expand to support increasing naturalness in communication,\nincorporating dialogue act processing into dialogue model design becomes\nessential. The lack of such consideration limits the scalability of dialogue\nstate tracking models for dialogues having specific objectives and ontology. To\naddress this issue, we formulate and incorporate dialogue acts, and leverage\nrecent advances in machine reading comprehension to predict both categorical\nand non-categorical types of slots for multi-domain dialogue state tracking.\nExperimental results show that our models can improve the overall accuracy of\ndialogue state tracking on the MultiWOZ 2.1 dataset, and demonstrate that\nincorporating dialogue acts can guide dialogue state design for future\ntask-oriented dialogue systems.\n",
                "链接": "https://arxiv.org/abs/2208.02462"
            },
            {
                "文章ID": "20132",
                "标题": "Beyond the Granularity: Multi-Perspective Dialogue Collaborative\n  Selection for Dialogue State Tracking",
                "作者": " Jinyu Guo,  Kai Shuang,  Jijie Li,  Zihan Wang,  Yixuan Liu",
                "发布日期": "2022-05-23",
                "摘要": "  In dialogue state tracking, dialogue history is a crucial material, and its\nutilization varies between different models. However, no matter how the\ndialogue history is used, each existing model uses its own consistent dialogue\nhistory during the entire state tracking process, regardless of which slot is\nupdated. Apparently, it requires different dialogue history to update different\nslots in different turns. Therefore, using consistent dialogue contents may\nlead to insufficient or redundant information for different slots, which\naffects the overall performance. To address this problem, we devise DiCoS-DST\nto dynamically select the relevant dialogue contents corresponding to each slot\nfor state updating. Specifically, it first retrieves turn-level utterances of\ndialogue history and evaluates their relevance to the slot from a combination\nof three perspectives: (1) its explicit connection to the slot name; (2) its\nrelevance to the current turn dialogue; (3) Implicit Mention Oriented\nReasoning. Then these perspectives are combined to yield a decision, and only\nthe selected dialogue contents are fed into State Generator, which explicitly\nminimizes the distracting information passed to the downstream state\nprediction. Experimental results show that our approach achieves new\nstate-of-the-art performance on MultiWOZ 2.1 and MultiWOZ 2.2, and achieves\nsuperior performance on multiple mainstream benchmark datasets (including\nSim-M, Sim-R, and DSTC2).\n",
                "链接": "https://arxiv.org/abs/2205.10059"
            },
            {
                "文章ID": "8024",
                "标题": "Dialogue Summaries as Dialogue States (DS2), Template-Guided\n  Summarization for Few-shot Dialogue State Tracking",
                "作者": " Jamin Shin,  Hangyeol Yu,  Hyeongdon Moon,  Andrea Madotto,  Juneyoung Park",
                "发布日期": "2022-03-04",
                "摘要": "  Annotating task-oriented dialogues is notorious for the expensive and\ndifficult data collection process. Few-shot dialogue state tracking (DST) is a\nrealistic solution to this problem. In this paper, we hypothesize that dialogue\nsummaries are essentially unstructured dialogue states; hence, we propose to\nreformulate dialogue state tracking as a dialogue summarization problem. To\nelaborate, we train a text-to-text language model with synthetic template-based\ndialogue summaries, generated by a set of rules from the dialogue states. Then,\nthe dialogue states can be recovered by inversely applying the summary\ngeneration rules. We empirically show that our method DS2 outperforms previous\nworks on few-shot DST in MultiWoZ 2.0 and 2.1, in both cross-domain and\nmulti-domain settings. Our method also exhibits vast speedup during both\ntraining and inference as it can generate all states at once. Finally, based on\nour analysis, we discover that the naturalness of the summary templates plays a\nkey role for successful training.\n",
                "链接": "https://arxiv.org/abs/2203.01552"
            },
            {
                "文章ID": "31009",
                "标题": "Controllable User Dialogue Act Augmentation for Dialogue State Tracking",
                "作者": " Chun-Mao Lai,  Ming-Hao Hsu,  Chao-Wei Huang,  Yun-Nung Chen",
                "发布日期": "2022-07-27",
                "摘要": "  Prior work has demonstrated that data augmentation is useful for improving\ndialogue state tracking. However, there are many types of user utterances,\nwhile the prior method only considered the simplest one for augmentation,\nraising the concern about poor generalization capability. In order to better\ncover diverse dialogue acts and control the generation quality, this paper\nproposes controllable user dialogue act augmentation (CUDA-DST) to augment user\nutterances with diverse behaviors. With the augmented data, different state\ntrackers gain improvement and show better robustness, achieving the\nstate-of-the-art performance on MultiWOZ 2.1\n",
                "链接": "https://arxiv.org/abs/2207.12757"
            }
        ]
    },
    {
        "question": {
            "question": "2023年后利用hotpotqa数据集做问题生成任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "5376",
                "标题": "QA4QG: Using Question Answering to Constrain Multi-Hop Question\n  Generation",
                "作者": " Dan Su,  Peng Xu,  Pascale Fung",
                "发布日期": "2022-02-15",
                "摘要": "  Multi-hop question generation (MQG) aims to generate complex questions which\nrequire reasoning over multiple pieces of information of the input passage.\nMost existing work on MQG has focused on exploring graph-based networks to\nequip the traditional Sequence-to-sequence framework with reasoning ability.\nHowever, these models do not take full advantage of the constraint between\nquestions and answers. Furthermore, studies on multi-hop question answering\n(QA) suggest that Transformers can replace the graph structure for multi-hop\nreasoning. Therefore, in this work, we propose a novel framework, QA4QG, a\nQA-augmented BART-based framework for MQG. It augments the standard BART model\nwith an additional multi-hop QA module to further constrain the generated\nquestion. Our results on the HotpotQA dataset show that QA4QG outperforms all\nstate-of-the-art models, with an increase of 8 BLEU-4 and 8 ROUGE points\ncompared to the best results previously reported. Our work suggests the\nadvantage of introducing pre-trained language models and QA module for the MQG\ntask.\n",
                "链接": "https://arxiv.org/abs/2202.06538"
            },
            {
                "文章ID": "111240",
                "标题": "BLP 2023 Task 2: Sentiment Analysis",
                "作者": " Md. Arid Hasan,  Firoj Alam,  Anika Anjum,  Shudipta Das,  Afiyat Anjum",
                "发布日期": "2023-10-26",
                "摘要": "  We present an overview of the BLP Sentiment Shared Task, organized as part of\nthe inaugural BLP 2023 workshop, co-located with EMNLP 2023. The task is\ndefined as the detection of sentiment in a given piece of social media text.\nThis task attracted interest from 71 participants, among whom 29 and 30 teams\nsubmitted systems during the development and evaluation phases, respectively.\nIn total, participants submitted 597 runs. However, a total of 15 teams\nsubmitted system description papers. The range of approaches in the submitted\nsystems spans from classical machine learning models, fine-tuning pre-trained\nmodels, to leveraging Large Language Model (LLMs) in zero- and few-shot\nsettings. In this paper, we provide a detailed account of the task setup,\nincluding dataset development and evaluation setup. Additionally, we provide a\nbrief overview of the systems submitted by the participants. All datasets and\nevaluation scripts from the shared task have been made publicly available for\nthe research community, to foster further research in this domain\n",
                "链接": "https://arxiv.org/abs/2310.16183"
            },
            {
                "文章ID": "10231",
                "标题": "Ask to Understand: Question Generation for Multi-hop Question Answering",
                "作者": " Jiawei Li,  Mucheng Ren,  Yang Gao,  Yizhe Yang",
                "发布日期": "2022-03-18",
                "摘要": "  Multi-hop Question Answering (QA) requires the machine to answer complex\nquestions by finding scattering clues and reasoning from multiple documents.\nGraph Network (GN) and Question Decomposition (QD) are two common approaches at\npresent. The former uses the \"black-box\" reasoning process to capture the\npotential relationship between entities and sentences, thus achieving good\nperformance. At the same time, the latter provides a clear reasoning logical\nroute by decomposing multi-hop questions into simple single-hop sub-questions.\nIn this paper, we propose a novel method to complete multi-hop QA from the\nperspective of Question Generation (QG). Specifically, we carefully design an\nend-to-end QG module on the basis of a classical QA module, which could help\nthe model understand the context by asking inherently logical sub-questions,\nthus inheriting interpretability from the QD-based method and showing superior\nperformance. Experiments on the HotpotQA dataset demonstrate that the\neffectiveness of our proposed QG module, human evaluation further clarifies its\ninterpretability quantitatively, and thorough analysis shows that the QG module\ncould generate better sub-questions than QD methods in terms of fluency,\nconsistency, and diversity.\n",
                "链接": "https://arxiv.org/abs/2203.09073"
            },
            {
                "文章ID": "58619",
                "标题": "Graph Attention with Hierarchies for Multi-hop Question Answering",
                "作者": " Yunjie He,  Philip John Gorinski,  Ieva Staliunaite,  Pontus Stenetorp",
                "发布日期": "2023-01-30",
                "摘要": "  Multi-hop QA (Question Answering) is the task of finding the answer to a\nquestion across multiple documents. In recent years, a number of Deep\nLearning-based approaches have been proposed to tackle this complex task, as\nwell as a few standard benchmarks to assess models Multi-hop QA capabilities.\nIn this paper, we focus on the well-established HotpotQA benchmark dataset,\nwhich requires models to perform answer span extraction as well as support\nsentence prediction. We present two extensions to the SOTA Graph Neural Network\n(GNN) based model for HotpotQA, Hierarchical Graph Network (HGN): (i) we\ncomplete the original hierarchical structure by introducing new edges between\nthe query and context sentence nodes; (ii) in the graph propagation step, we\npropose a novel extension to Hierarchical Graph Attention Network GATH (Graph\nATtention with Hierarchies) that makes use of the graph hierarchy to update the\nnode representations in a sequential fashion. Experiments on HotpotQA\ndemonstrate the efficiency of the proposed modifications and support our\nassumptions about the effects of model related variables.\n",
                "链接": "https://arxiv.org/abs/2301.11792"
            },
            {
                "文章ID": "113764",
                "标题": "Citance-Contextualized Summarization of Scientific Papers",
                "作者": " Shahbaz Syed,  Ahmad Dawar Hakimi,  Khalid Al-Khatib,  Martin Potthast",
                "发布日期": "2023-11-14",
                "摘要": "  Current approaches to automatic summarization of scientific papers generate\ninformative summaries in the form of abstracts. However, abstracts are not\nintended to show the relationship between a paper and the references cited in\nit. We propose a new contextualized summarization approach that can generate an\ninformative summary conditioned on a given sentence containing the citation of\na reference (a so-called \"citance\"). This summary outlines the content of the\ncited paper relevant to the citation location. Thus, our approach extracts and\nmodels the citances of a paper, retrieves relevant passages from cited papers,\nand generates abstractive summaries tailored to each citance. We evaluate our\napproach using $\\textbf{Webis-Context-SciSumm-2023}$, a new dataset containing\n540K~computer science papers and 4.6M~citances therein.\n",
                "链接": "https://arxiv.org/abs/2311.02408"
            },
            {
                "文章ID": "74474",
                "标题": "Using Implicit Feedback to Improve Question Generation",
                "作者": " Hugo Rodrigues,  Eric Nyberg,  Luisa Coheur",
                "发布日期": "2023-04-27",
                "摘要": "  Question Generation (QG) is a task of Natural Language Processing (NLP) that\naims at automatically generating questions from text. Many applications can\nbenefit from automatically generated questions, but often it is necessary to\ncurate those questions, either by selecting or editing them. This task is\ninformative on its own, but it is typically done post-generation, and, thus,\nthe effort is wasted. In addition, most existing systems cannot incorporate\nthis feedback back into them easily. In this work, we present a system, GEN,\nthat learns from such (implicit) feedback. Following a pattern-based approach,\nit takes as input a small set of sentence/question pairs and creates patterns\nwhich are then applied to new unseen sentences. Each generated question, after\nbeing corrected by the user, is used as a new seed in the next iteration, so\nmore patterns are created each time. We also take advantage of the corrections\nmade by the user to score the patterns and therefore rank the generated\nquestions. Results show that GEN is able to improve by learning from both\nlevels of implicit feedback when compared to the version with no learning,\nconsidering the top 5, 10, and 20 questions. Improvements go up from 10%,\ndepending on the metric and strategy used.\n",
                "链接": "https://arxiv.org/abs/2304.13664"
            },
            {
                "文章ID": "111378",
                "标题": "CUNI Submission to MRL 2023 Shared Task on Multi-lingual Multi-task\n  Information Retrieval",
                "作者": " Jindřich Helcl,  Jindřich Libovický",
                "发布日期": "2023-10-26",
                "摘要": "  We present the Charles University system for the MRL~2023 Shared Task on\nMulti-lingual Multi-task Information Retrieval. The goal of the shared task was\nto develop systems for named entity recognition and question answering in\nseveral under-represented languages. Our solutions to both subtasks rely on the\ntranslate-test approach. We first translate the unlabeled examples into English\nusing a multilingual machine translation model. Then, we run inference on the\ntranslated data using a strong task-specific model. Finally, we project the\nlabeled data back into the original language. To keep the inferred tags on the\ncorrect positions in the original language, we propose a method based on\nscoring the candidate positions using a label-sensitive translation model. In\nboth settings, we experiment with finetuning the classification models on the\ntranslated data. However, due to a domain mismatch between the development data\nand the shared task validation and test sets, the finetuned models could not\noutperform our baselines.\n",
                "链接": "https://arxiv.org/abs/2310.16528"
            },
            {
                "文章ID": "84664",
                "标题": "The ADAIO System at the BEA-2023 Shared Task on Generating AI Teacher\n  Responses in Educational Dialogues",
                "作者": "2 and 3  Adaeze Adigwe, 2 and 3  Zheng Yuan",
                "发布日期": "2023-06-09",
                "摘要": "  This paper presents the ADAIO team's system entry in the Building Educational\nApplications (BEA) 2023 Shared Task on Generating AI Teacher Responses in\nEducational Dialogues. The task aims to assess the performance of\nstate-of-the-art generative models as AI teachers in producing suitable\nresponses within a student-teacher dialogue. Our system comprises evaluating\nvarious baseline models using OpenAI GPT-3 and designing diverse prompts to\nprompt the OpenAI models for teacher response generation. After the challenge,\nour system achieved second place by employing a few-shot prompt-based approach\nwith the OpenAI text-davinci-003 model. The results highlight the few-shot\nlearning capabilities of large-language models, particularly OpenAI's GPT-3, in\nthe role of AI teachers.\n",
                "链接": "https://arxiv.org/abs/2306.05360"
            },
            {
                "文章ID": "5419",
                "标题": "ArgSciChat: A Dataset for Argumentative Dialogues on Scientific Papers",
                "作者": " Federico Ruggeri,  Mohsen Mesgar,  Iryna Gurevych",
                "发布日期": "2022-10-14",
                "摘要": "  The applications of conversational agents for scientific disciplines (as\nexpert domains) are understudied due to the lack of dialogue data to train such\nagents. While most data collection frameworks, such as Amazon Mechanical Turk,\nfoster data collection for generic domains by connecting crowd workers and task\ndesigners, these frameworks are not much optimized for data collection in\nexpert domains. Scientists are rarely present in these frameworks due to their\nlimited time budget. Therefore, we introduce a novel framework to collect\ndialogues between scientists as domain experts on scientific papers. Our\nframework lets scientists present their scientific papers as groundings for\ndialogues and participate in dialogue they like its paper title. We use our\nframework to collect a novel argumentative dialogue dataset, ArgSciChat. It\nconsists of 498 messages collected from 41 dialogues on 20 scientific papers.\nAlongside extensive analysis on ArgSciChat, we evaluate a recent conversational\nagent on our dataset. Experimental results show that this agent poorly performs\non ArgSciChat, motivating further research on argumentative scientific agents.\nWe release our framework and the dataset.\n",
                "链接": "https://arxiv.org/abs/2202.06690"
            },
            {
                "文章ID": "60822",
                "标题": "Generating a Structured Summary of Numerous Academic Papers: Dataset and\n  Method",
                "作者": " Shuaiqi Liu,  Jiannong Cao,  Ruosong Yang,  Zhiyuan Wen",
                "发布日期": "2023-02-10",
                "摘要": "  Writing a survey paper on one research topic usually needs to cover the\nsalient content from numerous related papers, which can be modeled as a\nmulti-document summarization (MDS) task. Existing MDS datasets usually focus on\nproducing the structureless summary covering a few input documents. Meanwhile,\nprevious structured summary generation works focus on summarizing a single\ndocument into a multi-section summary. These existing datasets and methods\ncannot meet the requirements of summarizing numerous academic papers into a\nstructured summary. To deal with the scarcity of available data, we propose\nBigSurvey, the first large-scale dataset for generating comprehensive summaries\nof numerous academic papers on each topic. We collect target summaries from\nmore than seven thousand survey papers and utilize their 430 thousand reference\npapers' abstracts as input documents. To organize the diverse content from\ndozens of input documents and ensure the efficiency of processing long text\nsequences, we propose a summarization method named category-based alignment and\nsparse transformer (CAST). The experimental results show that our CAST method\noutperforms various advanced summarization methods.\n",
                "链接": "https://arxiv.org/abs/2302.04580"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用机器学习方法进行心理健康疾病研究的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "98633",
                "标题": "Discovering Mental Health Research Topics with Topic Modeling",
                "作者": " Xin Gao,  Cem Sazara",
                "发布日期": "2023-08-29",
                "摘要": "  Mental health significantly influences various aspects of our daily lives,\nand its importance has been increasingly recognized by the research community\nand the general public, particularly in the wake of the COVID-19 pandemic. This\nheightened interest is evident in the growing number of publications dedicated\nto mental health in the past decade. In this study, our goal is to identify\ngeneral trends in the field and pinpoint high-impact research topics by\nanalyzing a large dataset of mental health research papers. To accomplish this,\nwe collected abstracts from various databases and trained a customized\nSentence-BERT based embedding model leveraging the BERTopic framework. Our\ndataset comprises 96,676 research papers pertaining to mental health, enabling\nus to examine the relationships between different topics using their abstracts.\nTo evaluate the effectiveness of the model, we compared it against two other\nstate-of-the-art methods: Top2Vec model and LDA-BERT model. The model\ndemonstrated superior performance in metrics that measure topic diversity and\ncoherence. To enhance our analysis, we also generated word clouds to provide a\ncomprehensive overview of the machine learning models applied in mental health\nresearch, shedding light on commonly utilized techniques and emerging trends.\nFurthermore, we provide a GitHub link* to the dataset used in this paper,\nensuring its accessibility for further research endeavors.\n",
                "链接": "https://arxiv.org/abs/2308.13569"
            },
            {
                "文章ID": "79967",
                "标题": "A Survey on the Role of Artificial Intelligence in the Prediction and\n  Diagnosis of Schizophrenia",
                "作者": " Narges Ramesh,  Yasmin Ghodsi,  Hamidreza Bolhasani",
                "发布日期": "2023-05-25",
                "摘要": "  Machine learning is employed in healthcare to draw approximate conclusions\nregarding human diseases and mental health problems. Compared to older\ntraditional methods, it can help to analyze data more efficiently and produce\nbetter and more dependable results. Millions of people are affected by\nschizophrenia, which is a chronic mental disorder that can significantly impact\ntheir lives. Many machine learning algorithms have been developed to predict\nand prevent this disease, and they can potentially be implemented in the\ndiagnosis of individuals who have it. This survey aims to review papers that\nhave focused on the use of deep learning to detect and predict schizophrenia\nusing EEG signals, functional magnetic resonance imaging (fMRI), and diffusion\nmagnetic resonance imaging (dMRI). With our chosen search strategy, we assessed\nten publications from 2019 to 2022. All studies achieved successful predictions\nof more than 80%. This review provides summaries of the studies and compares\ntheir notable aspects. In the field of artificial intelligence (AI) and machine\nlearning (ML) for schizophrenia, significant advances have been made due to the\navailability of ML tools, and we are optimistic that this field will continue\nto grow.\n",
                "链接": "https://arxiv.org/abs/2305.14370"
            },
            {
                "文章ID": "111553",
                "标题": "An Integrative Survey on Mental Health Conversational Agents to Bridge\n  Computer Science and Medical Perspectives",
                "作者": " Young Min Cho,  Sunny Rai,  Lyle Ungar,  João Sedoc,  Sharath Chandra Guntuku",
                "发布日期": "2023-12-01",
                "摘要": "  Mental health conversational agents (a.k.a. chatbots) are widely studied for\ntheir potential to offer accessible support to those experiencing mental health\nchallenges. Previous surveys on the topic primarily consider papers published\nin either computer science or medicine, leading to a divide in understanding\nand hindering the sharing of beneficial knowledge between both domains. To\nbridge this gap, we conduct a comprehensive literature review using the PRISMA\nframework, reviewing 534 papers published in both computer science and\nmedicine. Our systematic review reveals 136 key papers on building mental\nhealth-related conversational agents with diverse characteristics of modeling\nand experimental design techniques. We find that computer science papers focus\non LLM techniques and evaluating response quality using automated metrics with\nlittle attention to the application while medical papers use rule-based\nconversational agents and outcome metrics to measure the health outcomes of\nparticipants. Based on our findings on transparency, ethics, and cultural\nheterogeneity in this review, we provide a few recommendations to help bridge\nthe disciplinary divide and enable the cross-disciplinary development of mental\nhealth conversational agents.\n",
                "链接": "https://arxiv.org/abs/2310.17017"
            },
            {
                "文章ID": "27506",
                "标题": "Mental Illness Classification on Social Media Texts using Deep Learning\n  and Transfer Learning",
                "作者": " Iqra Ameer,  Muhammad Arif,  Grigori Sidorov,  Helena Gòmez-Adorno,  Alexander Gelbukh",
                "发布日期": "2022-07-05",
                "摘要": "  Given the current social distance restrictions across the world, most\nindividuals now use social media as their major medium of communication.\nMillions of people suffering from mental diseases have been isolated due to\nthis, and they are unable to get help in person. They have become more reliant\non online venues to express themselves and seek advice on dealing with their\nmental disorders. According to the World health organization (WHO),\napproximately 450 million people are affected. Mental illnesses, such as\ndepression, anxiety, etc., are immensely common and have affected an\nindividuals' physical health. Recently Artificial Intelligence (AI) methods\nhave been presented to help mental health providers, including psychiatrists\nand psychologists, in decision making based on patients' authentic information\n(e.g., medical records, behavioral data, social media utilization, etc.). AI\ninnovations have demonstrated predominant execution in numerous real-world\napplications broadening from computer vision to healthcare. This study analyzes\nunstructured user data on the Reddit platform and classifies five common mental\nillnesses: depression, anxiety, bipolar disorder, ADHD, and PTSD. We trained\ntraditional machine learning, deep learning, and transfer learning multi-class\nmodels to detect mental disorders of individuals. This effort will benefit the\npublic health system by automating the detection process and informing\nappropriate authorities about people who require emergency assistance.\n",
                "链接": "https://arxiv.org/abs/2207.01012"
            },
            {
                "文章ID": "108695",
                "标题": "A Hybrid Approach for Depression Classification: Random Forest-ANN\n  Ensemble on Motor Activity Signals",
                "作者": " Anket Patil,  Dhairya Shah,  Abhishek Shah,  Mokshit Gala",
                "发布日期": "2023-10-16",
                "摘要": "  Regarding the rising number of people suffering from mental health illnesses\nin today's society, the importance of mental health cannot be overstated.\nWearable sensors, which are increasingly widely available, provide a potential\nway to track and comprehend mental health issues. These gadgets not only\nmonitor everyday activities but also continuously record vital signs like heart\nrate, perhaps providing information on a person's mental state. Recent research\nhas used these sensors in conjunction with machine learning methods to identify\npatterns relating to different mental health conditions, highlighting the\nimmense potential of this data beyond simple activity monitoring. In this\nresearch, we present a novel algorithm called the Hybrid Random forest - Neural\nnetwork that has been tailored to evaluate sensor data from depressed patients.\nOur method has a noteworthy accuracy of 80\\% when evaluated on a special\ndataset that included both unipolar and bipolar depressive patients as well as\nhealthy controls. The findings highlight the algorithm's potential for reliably\ndetermining a person's depression condition using sensor data, making a\nsubstantial contribution to the area of mental health diagnostics.\n",
                "链接": "https://arxiv.org/abs/2310.09277"
            },
            {
                "文章ID": "34711",
                "标题": "Adverse Childhood Experiences Identification from Clinical Notes with\n  Ontologies and NLP",
                "作者": " Jinge Wu,  Rowena Smith,  Honghan Wu",
                "发布日期": "2022-08-25",
                "摘要": "  Adverse Childhood Experiences (ACEs) are defined as a collection of highly\nstressful, and potentially traumatic, events or circumstances that occur\nthroughout childhood and/or adolescence. They have been shown to be associated\nwith increased risks of mental health diseases or other abnormal behaviours in\nlater lives. However, the identification of ACEs from free-text Electronic\nHealth Records (EHRs) with Natural Language Processing (NLP) is challenging\nbecause (a) there is no NLP ready ACE ontologies; (b) there are limited cases\navailable for machine learning, necessitating the data annotation from clinical\nexperts. We are currently developing a tool that would use NLP techniques to\nassist us in surfacing ACEs from clinical notes. This will enable us further\nresearch in identifying evidence of the relationship between ACEs and the\nsubsequent developments of mental illness (e.g., addictions) in large-scale and\nlongitudinal free-text EHRs, which has previously not been possible.\n",
                "链接": "https://arxiv.org/abs/2208.11466"
            },
            {
                "文章ID": "90246",
                "标题": "MentalHealthAI: Utilizing Personal Health Device Data to Optimize\n  Psychiatry Treatment",
                "作者": " Manan Shukla,  Oshani Seneviratne",
                "发布日期": "2023-07-12",
                "摘要": "  Mental health disorders remain a significant challenge in modern healthcare,\nwith diagnosis and treatment often relying on subjective patient descriptions\nand past medical history. To address this issue, we propose a personalized\nmental health tracking and mood prediction system that utilizes patient\nphysiological data collected through personal health devices. Our system\nleverages a decentralized learning mechanism that combines transfer and\nfederated machine learning concepts using smart contracts, allowing data to\nremain on users' devices and enabling effective tracking of mental health\nconditions for psychiatric treatment and management in a privacy-aware and\naccountable manner. We evaluate our model using a popular mental health dataset\nthat demonstrates promising results. By utilizing connected health systems and\nmachine learning models, our approach offers a novel solution to the challenge\nof providing psychiatrists with further insight into their patients' mental\nhealth outside of traditional office visits.\n",
                "链接": "https://arxiv.org/abs/2307.04777"
            },
            {
                "文章ID": "39601",
                "标题": "Reducing Stress and Anxiety in the Metaverse: A Systematic Review of\n  Meditation, Mindfulness and Virtual Reality",
                "作者": " Xian Wang,  Xiaoyu Mo,  Mingming Fan,  Lik-Hang Lee,  Bertram E. Shi,  Pan Hui",
                "发布日期": "2022-09-30",
                "摘要": "  Meditation, or mindfulness, is widely used to improve mental health. With the\nemergence of Virtual Reality technology, many studies have provided evidence\nthat meditation with VR can bring health benefits. However, to our knowledge,\nthere are no guidelines and comprehensive reviews in the literature on how to\nconduct such research in virtual reality. In order to understand the role of VR\ntechnology in meditation and future research opportunities, we conducted a\nsystematic literature review in the IEEE and ACM databases. Our process yielded\n19 eligible papers and we conducted a structured analysis. We understand the\nstate-of-art of meditation type, design consideration and VR and technology\nthrough these papers and conclude research opportunities and challenges for the\nfuture.\n",
                "链接": "https://arxiv.org/abs/2209.14645"
            },
            {
                "文章ID": "104767",
                "标题": "Identifying Risk Factors for Post-COVID-19 Mental Health Disorders: A\n  Machine Learning Perspective",
                "作者": " Maitham G. Yousif,  Fadhil G. Al-Amran,  Hector J. Castro",
                "发布日期": "2023-09-29",
                "摘要": "  In this study, we leveraged machine learning techniques to identify risk\nfactors associated with post-COVID-19 mental health disorders. Our analysis,\nbased on data collected from 669 patients across various provinces in Iraq,\nyielded valuable insights. We found that age, gender, and geographical region\nof residence were significant demographic factors influencing the likelihood of\ndeveloping mental health disorders in post-COVID-19 patients. Additionally,\ncomorbidities and the severity of COVID-19 illness were important clinical\npredictors. Psychosocial factors, such as social support, coping strategies,\nand perceived stress levels, also played a substantial role. Our findings\nemphasize the complex interplay of multiple factors in the development of\nmental health disorders following COVID-19 recovery. Healthcare providers and\npolicymakers should consider these risk factors when designing targeted\ninterventions and support systems for individuals at risk. Machine\nlearning-based approaches can provide a valuable tool for predicting and\npreventing adverse mental health outcomes in post-COVID-19 patients. Further\nresearch and prospective studies are needed to validate these findings and\nenhance our understanding of the long-term psychological impact of the COVID-19\npandemic. This study contributes to the growing body of knowledge regarding the\nmental health consequences of the COVID-19 pandemic and underscores the\nimportance of a multidisciplinary approach to address the diverse needs of\nindividuals on the path to recovery. Keywords: COVID-19, mental health, risk\nfactors, machine learning, Iraq\n",
                "链接": "https://arxiv.org/abs/2309.16055"
            },
            {
                "文章ID": "32474",
                "标题": "Bias Reducing Multitask Learning on Mental Health Prediction",
                "作者": " Khadija Zanna,  Kusha Sridhar,  Han Yu,  Akane Sano",
                "发布日期": "2022-08-09",
                "摘要": "  There has been an increase in research in developing machine learning models\nfor mental health detection or prediction in recent years due to increased\nmental health issues in society. Effective use of mental health prediction or\ndetection models can help mental health practitioners re-define mental\nillnesses more objectively than currently done, and identify illnesses at an\nearlier stage when interventions may be more effective. However, there is still\na lack of standard in evaluating bias in such machine learning models in the\nfield, which leads to challenges in providing reliable predictions and in\naddressing disparities. This lack of standards persists due to factors such as\ntechnical difficulties, complexities of high dimensional clinical health data,\netc., which are especially true for physiological signals. This along with\nprior evidence of relations between some physiological signals with certain\ndemographic identities restates the importance of exploring bias in mental\nhealth prediction models that utilize physiological signals. In this work, we\naim to perform a fairness analysis and implement a multi-task learning based\nbias mitigation method on anxiety prediction models using ECG data. Our method\nis based on the idea of epistemic uncertainty and its relationship with model\nweights and feature space representation. Our analysis showed that our anxiety\nprediction base model introduced some bias with regards to age, income,\nethnicity, and whether a participant is born in the U.S. or not, and our bias\nmitigation method performed better at reducing the bias in the model, when\ncompared to the reweighting mitigation technique. Our analysis on feature\nimportance also helped identify relationships between heart rate variability\nand multiple demographic groupings.\n",
                "链接": "https://arxiv.org/abs/2208.03621"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "52332",
                "标题": "A Trustworthy Framework for Medical Image Analysis with Deep Learning",
                "作者": " Kai Ma,  Siyuan He,  Pengcheng Xi,  Ashkan Ebadi,  Stéphane Tremblay,  Alexander Wong",
                "发布日期": "2022-12-07",
                "摘要": "  Computer vision and machine learning are playing an increasingly important\nrole in computer-assisted diagnosis; however, the application of deep learning\nto medical imaging has challenges in data availability and data imbalance, and\nit is especially important that models for medical imaging are built to be\ntrustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning\nframework for medical image analysis, which adopts a modular design, leverages\nself-supervised pre-training, and utilizes a novel surrogate loss function.\nExperimental evaluations indicate that models generated from the framework are\nboth trustworthy and high-performing. It is anticipated that the framework will\nsupport researchers and clinicians in advancing the use of deep learning for\ndealing with public health crises including COVID-19.\n",
                "链接": "https://arxiv.org/abs/2212.02764"
            },
            {
                "文章ID": "25222",
                "标题": "A Comparative Study of Confidence Calibration in Deep Learning: From\n  Computer Vision to Medical Imaging",
                "作者": " Riqiang Gao,  Thomas Li,  Yucheng Tang,  Zhoubing Xu,  Michael Kammer,  Sanja L. Antic,  Kim Sandler,  Fabien Moldonado,  Thomas A. Lasko,  Bennett Landman",
                "发布日期": "2022-06-20",
                "摘要": "  Although deep learning prediction models have been successful in the\ndiscrimination of different classes, they can often suffer from poor\ncalibration across challenging domains including healthcare. Moreover, the\nlong-tail distribution poses great challenges in deep learning classification\nproblems including clinical disease prediction. There are approaches proposed\nrecently to calibrate deep prediction in computer vision, but there are no\nstudies found to demonstrate how the representative models work in different\nchallenging contexts. In this paper, we bridge the confidence calibration from\ncomputer vision to medical imaging with a comparative study of four high-impact\ncalibration models. Our studies are conducted in different contexts (natural\nimage classification and lung cancer risk estimation) including in balanced vs.\nimbalanced training sets and in computer vision vs. medical imaging. Our\nresults support key findings: (1) We achieve new conclusions which are not\nstudied under different learning contexts, e.g., combining two calibration\nmodels that both mitigate the overconfident prediction can lead to\nunder-confident prediction, and simpler calibration models from the computer\nvision domain tend to be more generalizable to medical imaging. (2) We\nhighlight the gap between general computer vision tasks and medical imaging\nprediction, e.g., calibration methods ideal for general computer vision tasks\nmay in fact damage the calibration of medical imaging prediction. (3) We also\nreinforce previous conclusions in natural image classification settings. We\nbelieve that this study has merits to guide readers to choose calibration\nmodels and understand gaps between general computer vision and medical imaging\ndomains.\n",
                "链接": "https://arxiv.org/abs/2206.08833"
            },
            {
                "文章ID": "43911",
                "标题": "Reproducibility of the Methods in Medical Imaging with Deep Learning",
                "作者": " Attila Simko,  Anders Garpebring,  Joakim Jonsson,  Tufve Nyholm,  Tommy Löfstedt",
                "发布日期": "2022-10-21",
                "摘要": "  Concerns about the reproducibility of deep learning research are more\nprominent than ever, with no clear solution in sight. The relevance of machine\nlearning research can only be improved if we also employ empirical rigor that\nincorporates reproducibility guidelines, especially so in the medical imaging\nfield. The Medical Imaging with Deep Learning (MIDL) conference has made\nadvancements in this direction by advocating open access, and recently also\nrecommending authors to make their code public - both aspects being adopted by\nthe majority of the conference submissions. This helps the reproducibility of\nthe methods, however, there is currently little or no support for further\nevaluation of these supplementary material, making them vulnerable to poor\nquality, which affects the impact of the entire submission. We have evaluated\nall accepted full paper submissions to MIDL between 2018 and 2022 using\nestablished, but slightly adjusted guidelines on reproducibility and the\nquality of the public repositories. The evaluations show that publishing\nrepositories and using public datasets are becoming more popular, which helps\ntraceability, but the quality of the repositories has not improved over the\nyears, leaving room for improvement in every aspect of designing repositories.\nMerely 22% of all submissions contain a repository that were deemed repeatable\nusing our evaluations. From the commonly encountered issues during the\nevaluations, we propose a set of guidelines for machine learning-related\nresearch for medical imaging applications, adjusted specifically for future\nsubmissions to MIDL.\n",
                "链接": "https://arxiv.org/abs/2210.11146"
            },
            {
                "文章ID": "92854",
                "标题": "Deep Learning Approaches for Data Augmentation in Medical Imaging: A\n  Review",
                "作者": " Aghiles Kebaili,  Jérôme Lapuyade-Lahorgue,  Su Ruan",
                "发布日期": "2023-07-26",
                "摘要": "  Deep learning has become a popular tool for medical image analysis, but the\nlimited availability of training data remains a major challenge, particularly\nin the medical field where data acquisition can be costly and subject to\nprivacy regulations. Data augmentation techniques offer a solution by\nartificially increasing the number of training samples, but these techniques\noften produce limited and unconvincing results. To address this issue, a\ngrowing number of studies have proposed the use of deep generative models to\ngenerate more realistic and diverse data that conform to the true distribution\nof the data. In this review, we focus on three types of deep generative models\nfor medical image augmentation: variational autoencoders, generative\nadversarial networks, and diffusion models. We provide an overview of the\ncurrent state of the art in each of these models and discuss their potential\nfor use in different downstream tasks in medical imaging, including\nclassification, segmentation, and cross-modal translation. We also evaluate the\nstrengths and limitations of each model and suggest directions for future\nresearch in this field. Our goal is to provide a comprehensive review about the\nuse of deep generative models for medical image augmentation and to highlight\nthe potential of these models for improving the performance of deep learning\nalgorithms in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2307.13125"
            },
            {
                "文章ID": "94331",
                "标题": "Deep learning for unsupervised domain adaptation in medical imaging:\n  Recent advancements and future perspectives",
                "作者": " Suruchi Kumari,  Pravendra Singh",
                "发布日期": "2023-08-03",
                "摘要": "  Deep learning has demonstrated remarkable performance across various tasks in\nmedical imaging. However, these approaches primarily focus on supervised\nlearning, assuming that the training and testing data are drawn from the same\ndistribution. Unfortunately, this assumption may not always hold true in\npractice. To address these issues, unsupervised domain adaptation (UDA)\ntechniques have been developed to transfer knowledge from a labeled domain to a\nrelated but unlabeled domain. In recent years, significant advancements have\nbeen made in UDA, resulting in a wide range of methodologies, including feature\nalignment, image translation, self-supervision, and disentangled representation\nmethods, among others. In this paper, we provide a comprehensive literature\nreview of recent deep UDA approaches in medical imaging from a technical\nperspective. Specifically, we categorize current UDA research in medical\nimaging into six groups and further divide them into finer subcategories based\non the different tasks they perform. We also discuss the respective datasets\nused in the studies to assess the divergence between the different domains.\nFinally, we discuss emerging areas and provide insights and discussions on\nfuture research directions to conclude this survey.\n",
                "链接": "https://arxiv.org/abs/2308.01265"
            },
            {
                "文章ID": "18618",
                "标题": "Explainable Deep Learning Methods in Medical Image Classification: A\n  Survey",
                "作者": " Cristiano Patrício,  João C. Neves,  Luís F. Teixeira",
                "发布日期": "2023-09-20",
                "摘要": "  The remarkable success of deep learning has prompted interest in its\napplication to medical imaging diagnosis. Even though state-of-the-art deep\nlearning models have achieved human-level accuracy on the classification of\ndifferent types of medical data, these models are hardly adopted in clinical\nworkflows, mainly due to their lack of interpretability. The black-box-ness of\ndeep learning models has raised the need for devising strategies to explain the\ndecision process of these models, leading to the creation of the topic of\neXplainable Artificial Intelligence (XAI). In this context, we provide a\nthorough survey of XAI applied to medical imaging diagnosis, including visual,\ntextual, example-based and concept-based explanation methods. Moreover, this\nwork reviews the existing medical imaging datasets and the existing metrics for\nevaluating the quality of the explanations. In addition, we include a\nperformance comparison among a set of report generation-based methods. Finally,\nthe major challenges in applying XAI to medical imaging and the future research\ndirections on the topic are also discussed.\n",
                "链接": "https://arxiv.org/abs/2205.04766"
            },
            {
                "文章ID": "82624",
                "标题": "Multi-environment lifelong deep reinforcement learning for medical\n  imaging",
                "作者": " Guangyao Zheng,  Shuhao Lai,  Vladimir Braverman,  Michael A. Jacobs,  Vishwa S. Parekh",
                "发布日期": "2023-06-02",
                "摘要": "  Deep reinforcement learning(DRL) is increasingly being explored in medical\nimaging. However, the environments for medical imaging tasks are constantly\nevolving in terms of imaging orientations, imaging sequences, and pathologies.\nTo that end, we developed a Lifelong DRL framework, SERIL to continually learn\nnew tasks in changing imaging environments without catastrophic forgetting.\nSERIL was developed using selective experience replay based lifelong learning\ntechnique for the localization of five anatomical landmarks in brain MRI on a\nsequence of twenty-four different imaging environments. The performance of\nSERIL, when compared to two baseline setups: MERT(multi-environment-best-case)\nand SERT(single-environment-worst-case) demonstrated excellent performance with\nan average distance of $9.90\\pm7.35$ pixels from the desired landmark across\nall 120 tasks, compared to $10.29\\pm9.07$ for MERT and $36.37\\pm22.41$ for\nSERT($p<0.05$), demonstrating the excellent potential for continuously learning\nmultiple tasks across dynamically changing imaging environments.\n",
                "链接": "https://arxiv.org/abs/2306.00188"
            },
            {
                "文章ID": "82718",
                "标题": "Introduction to Medical Imaging Informatics",
                "作者": " Md. Zihad Bin Jahangir,  Ruksat Hossain,  Riadul Islam,  MD Abdullah Al Nasim,  Md. Mahim Anjum Haque,  Md Jahangir Alam,  Sajedul Talukder",
                "发布日期": "2023-06-21",
                "摘要": "  Medical imaging informatics is a rapidly growing field that combines the\nprinciples of medical imaging and informatics to improve the acquisition,\nmanagement, and interpretation of medical images. This chapter introduces the\nbasic concepts of medical imaging informatics, including image processing,\nfeature engineering, and machine learning. It also discusses the recent\nadvancements in computer vision and deep learning technologies and how they are\nused to develop new quantitative image markers and prediction models for\ndisease detection, diagnosis, and prognosis prediction. By covering the basic\nknowledge of medical imaging informatics, this chapter provides a foundation\nfor understanding the role of informatics in medicine and its potential impact\non patient care.\n",
                "链接": "https://arxiv.org/abs/2306.00421"
            },
            {
                "文章ID": "61865",
                "标题": "A Review of Uncertainty Estimation and its Application in Medical\n  Imaging",
                "作者": " Ke Zou,  Zhihao Chen,  Xuedong Yuan,  Xiaojing Shen,  Meng Wang,  Huazhu Fu",
                "发布日期": "2023-05-17",
                "摘要": "  The use of AI systems in healthcare for the early screening of diseases is of\ngreat clinical importance. Deep learning has shown great promise in medical\nimaging, but the reliability and trustworthiness of AI systems limit their\ndeployment in real clinical scenes, where patient safety is at stake.\nUncertainty estimation plays a pivotal role in producing a confidence\nevaluation along with the prediction of the deep model. This is particularly\nimportant in medical imaging, where the uncertainty in the model's predictions\ncan be used to identify areas of concern or to provide additional information\nto the clinician. In this paper, we review the various types of uncertainty in\ndeep learning, including aleatoric uncertainty and epistemic uncertainty. We\nfurther discuss how they can be estimated in medical imaging. More importantly,\nwe review recent advances in deep learning models that incorporate uncertainty\nestimation in medical imaging. Finally, we discuss the challenges and future\ndirections in uncertainty estimation in deep learning for medical imaging. We\nhope this review will ignite further interest in the community and provide\nresearchers with an up-to-date reference regarding applications of uncertainty\nestimation models in medical imaging.\n",
                "链接": "https://arxiv.org/abs/2302.08119"
            },
            {
                "文章ID": "73470",
                "标题": "Invariant Scattering Transform for Medical Imaging",
                "作者": " Md Manjurul Ahsan,  Shivakumar Raman,  Zahed Siddique",
                "发布日期": "2023-06-01",
                "摘要": "  Over the years, the Invariant Scattering Transform (IST) technique has become\npopular for medical image analysis, including using wavelet transform\ncomputation using Convolutional Neural Networks (CNN) to capture patterns'\nscale and orientation in the input signal. IST aims to be invariant to\ntransformations that are common in medical images, such as translation,\nrotation, scaling, and deformation, used to improve the performance in medical\nimaging applications such as segmentation, classification, and registration,\nwhich can be integrated into machine learning algorithms for disease detection,\ndiagnosis, and treatment planning. Additionally, combining IST with deep\nlearning approaches has the potential to leverage their strengths and enhance\nmedical image analysis outcomes. This study provides an overview of IST in\nmedical imaging by considering the types of IST, their application,\nlimitations, and potential scopes for future researchers and practitioners.\n",
                "链接": "https://arxiv.org/abs/2304.10582"
            }
        ]
    },
    {
        "question": {
            "question": "查找基于优化实现模型越狱的文献",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "107661",
                "标题": "Jailbreak and Guard Aligned Language Models with Only Few In-Context\n  Demonstrations",
                "作者": " Zeming Wei,  Yifei Wang,  Yisen Wang",
                "发布日期": "2023-10-11",
                "摘要": "  Large Language Models (LLMs) have shown remarkable success in various tasks,\nbut concerns about their safety and the potential for generating malicious\ncontent have emerged. In this paper, we explore the power of In-Context\nLearning (ICL) in manipulating the alignment ability of LLMs. We find that by\nproviding just few in-context demonstrations without fine-tuning, LLMs can be\nmanipulated to increase or decrease the probability of jailbreaking, i.e.\nanswering malicious prompts. Based on these observations, we propose In-Context\nAttack (ICA) and In-Context Defense (ICD) methods for jailbreaking and guarding\naligned language model purposes. ICA crafts malicious contexts to guide models\nin generating harmful outputs, while ICD enhances model robustness by\ndemonstrations of rejecting to answer harmful prompts. Our experiments show the\neffectiveness of ICA and ICD in increasing or reducing the success rate of\nadversarial jailbreaking attacks. Overall, we shed light on the potential of\nICL to influence LLM behavior and provide a new perspective for enhancing the\nsafety and alignment of LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.06387"
            },
            {
                "文章ID": "115932",
                "标题": "Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts",
                "作者": " Yuanwei Wu,  Xiang Li,  Yixin Liu,  Pan Zhou,  Lichao Sun",
                "发布日期": "2023-11-16",
                "摘要": "  Existing work on jailbreak Multimodal Large Language Models (MLLMs) has\nfocused primarily on adversarial examples in model inputs, with less attention\nto vulnerabilities in model APIs. To fill the research gap, we carry out the\nfollowing work: 1) We discover a system prompt leakage vulnerability in GPT-4V.\nThrough carefully designed dialogue, we successfully steal the internal system\nprompts of GPT-4V. This finding indicates potential exploitable security risks\nin MLLMs; 2)Based on the acquired system prompts, we propose a novel MLLM\njailbreaking attack method termed SASP (Self-Adversarial Attack via System\nPrompt). By employing GPT-4 as a red teaming tool against itself, we aim to\nsearch for potential jailbreak prompts leveraging stolen system prompts.\nFurthermore, in pursuit of better performance, we also add human modification\nbased on GPT-4's analysis, which further improves the attack success rate to\n98.7\\%; 3) We evaluated the effect of modifying system prompts to defend\nagainst jailbreaking attacks. Results show that appropriately designed system\nprompts can significantly reduce jailbreak success rates. Overall, our work\nprovides new insights into enhancing MLLM security, demonstrating the important\nrole of system prompts in jailbreaking, which could be leveraged to greatly\nfacilitate jailbreak success rates while also holding the potential for\ndefending against jailbreaks.\n",
                "链接": "https://arxiv.org/abs/2311.09127"
            },
            {
                "文章ID": "71794",
                "标题": "Multi-step Jailbreaking Privacy Attacks on ChatGPT",
                "作者": " Haoran Li,  Dadi Guo,  Wei Fan,  Mingshi Xu,  Jie Huang,  Fanpu Meng,  Yangqiu Song",
                "发布日期": "2023-11-02",
                "摘要": "  With the rapid progress of large language models (LLMs), many downstream NLP\ntasks can be well solved given appropriate prompts. Though model developers and\nresearchers work hard on dialog safety to avoid generating harmful content from\nLLMs, it is still challenging to steer AI-generated content (AIGC) for the\nhuman good. As powerful LLMs are devouring existing text data from various\ndomains (e.g., GPT-3 is trained on 45TB texts), it is natural to doubt whether\nthe private information is included in the training data and what privacy\nthreats can these LLMs and their downstream applications bring. In this paper,\nwe study the privacy threats from OpenAI's ChatGPT and the New Bing enhanced by\nChatGPT and show that application-integrated LLMs may cause new privacy\nthreats. To this end, we conduct extensive experiments to support our claims\nand discuss LLMs' privacy implications.\n",
                "链接": "https://arxiv.org/abs/2304.05197"
            },
            {
                "文章ID": "115920",
                "标题": "Defending Large Language Models Against Jailbreaking Attacks Through\n  Goal Prioritization",
                "作者": " Zhexin Zhang,  Junxiao Yang,  Pei Ke,  Minlie Huang",
                "发布日期": "2023-11-16",
                "摘要": "  Large Language Models (LLMs) continue to advance in their capabilities, yet\nthis progress is accompanied by a growing array of safety risks. While\nsignificant attention has been dedicated to exploiting weaknesses in LLMs\nthrough jailbreaking attacks, there remains a paucity of exploration into\ndefending against these attacks. We point out a pivotal factor contributing to\nthe success of jailbreaks: the inherent conflict between the goals of being\nhelpful and ensuring safety. To counter jailbreaking attacks, we propose to\nintegrate goal prioritization at both training and inference stages.\nImplementing goal prioritization during inference substantially diminishes the\nAttack Success Rate (ASR) of jailbreaking attacks, reducing it from 66.4% to\n2.0% for ChatGPT and from 68.2% to 19.4% for Vicuna-33B, without compromising\ngeneral performance. Furthermore, integrating the concept of goal\nprioritization into the training phase reduces the ASR from 71.0% to 6.6% for\nLLama2-13B. Remarkably, even in scenarios where no jailbreaking samples are\nincluded during training, our approach slashes the ASR by half, decreasing it\nfrom 71.0% to 34.0%. Additionally, our findings reveal that while stronger LLMs\nface greater safety risks, they also possess a greater capacity to be steered\ntowards defending against such attacks. We hope our work could contribute to\nthe comprehension of jailbreaking attacks and defenses, and shed light on the\nrelationship between LLMs' capability and safety. Our code will be available at\n\\url{https://github.com/thu-coai/JailbreakDefense_GoalPriority}.\n",
                "链接": "https://arxiv.org/abs/2311.09096"
            },
            {
                "文章ID": "80421",
                "标题": "Collaborative Recommendation Model Based on Multi-modal Multi-view\n  Attention Network: Movie and literature cases",
                "作者": " Zheng Hu,  Shi-Min Cai,  Jun Wang,  Tao Zhou",
                "发布日期": "2023-05-25",
                "摘要": "  The existing collaborative recommendation models that use multi-modal\ninformation emphasize the representation of users' preferences but easily\nignore the representation of users' dislikes. Nevertheless, modelling users'\ndislikes facilitates comprehensively characterizing user profiles. Thus, the\nrepresentation of users' dislikes should be integrated into the user modelling\nwhen we construct a collaborative recommendation model. In this paper, we\npropose a novel Collaborative Recommendation Model based on Multi-modal\nmulti-view Attention Network (CRMMAN), in which the users are represented from\nboth preference and dislike views. Specifically, the users' historical\ninteractions are divided into positive and negative interactions, used to model\nthe user's preference and dislike views, respectively. Furthermore, the\nsemantic and structural information extracted from the scene is employed to\nenrich the item representation. We validate CRMMAN by designing contrast\nexperiments based on two benchmark MovieLens-1M and Book-Crossing datasets.\nMovielens-1m has about a million ratings, and Book-Crossing has about 300,000\nratings. Compared with the state-of-the-art knowledge-graph-based and\nmulti-modal recommendation methods, the AUC, NDCG@5 and NDCG@10 are improved by\n2.08%, 2.20% and 2.26% on average of two datasets. We also conduct controlled\nexperiments to explore the effects of multi-modal information and multi-view\nmechanism. The experimental results show that both of them enhance the model's\nperformance.\n",
                "链接": "https://arxiv.org/abs/2305.15159"
            },
            {
                "文章ID": "6524",
                "标题": "On Uncertainty Estimation by Tree-based Surrogate Models in Sequential\n  Model-based Optimization",
                "作者": " Jungtaek Kim,  Seungjin Choi",
                "发布日期": "2022-02-23",
                "摘要": "  Sequential model-based optimization sequentially selects a candidate point by\nconstructing a surrogate model with the history of evaluations, to solve a\nblack-box optimization problem. Gaussian process (GP) regression is a popular\nchoice as a surrogate model, because of its capability of calculating\nprediction uncertainty analytically. On the other hand, an ensemble of\nrandomized trees is another option and has practical merits over GPs due to its\nscalability and easiness of handling continuous/discrete mixed variables. In\nthis paper we revisit various ensembles of randomized trees to investigate\ntheir behavior in the perspective of prediction uncertainty estimation. Then,\nwe propose a new way of constructing an ensemble of randomized trees, referred\nto as BwO forest, where bagging with oversampling is employed to construct\nbootstrapped samples that are used to build randomized trees with random\nsplitting. Experimental results demonstrate the validity and good performance\nof BwO forest over existing tree-based models in various circumstances.\n",
                "链接": "https://arxiv.org/abs/2202.10669"
            },
            {
                "文章ID": "106619",
                "标题": "SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks",
                "作者": " Alexander Robey,  Eric Wong,  Hamed Hassani,  George J. Pappas",
                "发布日期": "2023-11-30",
                "摘要": "  Despite efforts to align large language models (LLMs) with human values,\nwidely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to\njailbreaking attacks, wherein an adversary fools a targeted LLM into generating\nobjectionable content. To address this vulnerability, we propose SmoothLLM, the\nfirst algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our\nfinding that adversarially-generated prompts are brittle to character-level\nchanges, our defense first randomly perturbs multiple copies of a given input\nprompt, and then aggregates the corresponding predictions to detect adversarial\ninputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to\nbelow one percentage point, avoids unnecessary conservatism, and admits\nprovable guarantees on attack mitigation. Moreover, our defense uses\nexponentially fewer queries than existing attacks and is compatible with any\nLLM. Our code is publicly available at the following link:\nhttps://github.com/arobey1/smooth-llm.\n",
                "链接": "https://arxiv.org/abs/2310.03684"
            },
            {
                "文章ID": "27272",
                "标题": "Literature on Hand GESTURE Recognition using Graph based methods",
                "作者": " Neha Baranwal,  Varun Sharma",
                "发布日期": "2022-07-04",
                "摘要": "  Skeleton based recognition systems are gaining popularity and machine\nlearning models focusing on points or joints in a skeleton have proved to be\ncomputationally effective and application in many areas like Robotics. It is\neasy to track points and thereby preserving spatial and temporal information,\nwhich plays an important role in abstracting the required information,\nclassification becomes an easy task. In this paper, we aim to study these\npoints but using a cloud mechanism, where we define a cloud as collection of\npoints. However, when we add temporal information, it may not be possible to\nretrieve the coordinates of a point in each frame and hence instead of focusing\non a single point, we can use k-neighbors to retrieve the state of the point\nunder discussion. Our focus is to gather such information using weight sharing\nbut making sure that when we try to retrieve the information from neighbors, we\ndo not carry noise with it. LSTM which has capability of long-term modelling\nand can carry both temporal and spatial information. In this article we tried\nto summarise graph based gesture recognition method.\n",
                "链接": "https://arxiv.org/abs/2207.00329"
            },
            {
                "文章ID": "86939",
                "标题": "DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT\n  Models",
                "作者": " Boxin Wang,  Weixin Chen,  Hengzhi Pei,  Chulin Xie,  Mintong Kang,  Chenhui Zhang,  Chejian Xu,  Zidi Xiong,  Ritik Dutta,  Rylan Schaeffer,  Sang T. Truong,  Simran Arora,  Mantas Mazeika,  Dan Hendrycks,  Zinan Lin,  Yu Cheng,  Sanmi Koyejo,  Dawn Song,  Bo Li",
                "发布日期": "2023-12-21",
                "摘要": "  Generative Pre-trained Transformer (GPT) models have exhibited exciting\nprogress in their capabilities, capturing the interest of practitioners and the\npublic alike. Yet, while the literature on the trustworthiness of GPT models\nremains limited, practitioners have proposed employing capable GPT models for\nsensitive applications such as healthcare and finance -- where mistakes can be\ncostly. To this end, this work proposes a comprehensive trustworthiness\nevaluation for large language models with a focus on GPT-4 and GPT-3.5,\nconsidering diverse perspectives -- including toxicity, stereotype bias,\nadversarial robustness, out-of-distribution robustness, robustness on\nadversarial demonstrations, privacy, machine ethics, and fairness. Based on our\nevaluations, we discover previously unpublished vulnerabilities to\ntrustworthiness threats. For instance, we find that GPT models can be easily\nmisled to generate toxic and biased outputs and leak private information in\nboth training data and conversation history. We also find that although GPT-4\nis usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more\nvulnerable given jailbreaking system or user prompts, potentially because GPT-4\nfollows (misleading) instructions more precisely. Our work illustrates a\ncomprehensive trustworthiness evaluation of GPT models and sheds light on the\ntrustworthiness gaps. Our benchmark is publicly available at\nhttps://decodingtrust.github.io/; our dataset can be previewed at\nhttps://huggingface.co/datasets/AI-Secure/DecodingTrust; a concise version of\nthis work is at https://openreview.net/pdf?id=kaHpo8OZw2.\n",
                "链接": "https://arxiv.org/abs/2306.11698"
            },
            {
                "文章ID": "104247",
                "标题": "Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM",
                "作者": " Bochuan Cao,  Yuanpu Cao,  Lu Lin,  Jinghui Chen",
                "发布日期": "2023-12-11",
                "摘要": "  Recently, Large Language Models (LLMs) have made significant advancements and\nare now widely used across various domains. Unfortunately, there has been a\nrising concern that LLMs can be misused to generate harmful or malicious\ncontent. Though a line of research has focused on aligning LLMs with human\nvalues and preventing them from producing inappropriate content, such\nalignments are usually vulnerable and can be bypassed by alignment-breaking\nattacks via adversarially optimized or handcrafted jailbreaking prompts. In\nthis work, we introduce a Robustly Aligned LLM (RA-LLM) to defend against\npotential alignment-breaking attacks. RA-LLM can be directly constructed upon\nan existing aligned LLM with a robust alignment checking function, without\nrequiring any expensive retraining or fine-tuning process of the original LLM.\nFurthermore, we also provide a theoretical analysis for RA-LLM to verify its\neffectiveness in defending against alignment-breaking attacks. Through\nreal-world experiments on open-source large language models, we demonstrate\nthat RA-LLM can successfully defend against both state-of-the-art adversarial\nprompts and popular handcrafted jailbreaking prompts by reducing their attack\nsuccess rates from nearly 100% to around 10% or less.\n",
                "链接": "https://arxiv.org/abs/2309.14348"
            }
        ]
    },
    {
        "question": {
            "question": "强化学习在大语言模型领域中应用的相关论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "61474",
                "标题": "Guiding Pretraining in Reinforcement Learning with Large Language Models",
                "作者": " Yuqing Du,  Olivia Watkins,  Zihan Wang,  Cédric Colas,  Trevor Darrell,  Pieter Abbeel,  Abhishek Gupta,  Jacob Andreas",
                "发布日期": "2023-09-18",
                "摘要": "  Reinforcement learning algorithms typically struggle in the absence of a\ndense, well-shaped reward function. Intrinsically motivated exploration methods\naddress this limitation by rewarding agents for visiting novel states or\ntransitions, but these methods offer limited benefits in large environments\nwhere most discovered novelty is irrelevant for downstream tasks. We describe a\nmethod that uses background knowledge from text corpora to shape exploration.\nThis method, called ELLM (Exploring with LLMs) rewards an agent for achieving\ngoals suggested by a language model prompted with a description of the agent's\ncurrent state. By leveraging large-scale language model pretraining, ELLM\nguides agents toward human-meaningful and plausibly useful behaviors without\nrequiring a human in the loop. We evaluate ELLM in the Crafter game environment\nand the Housekeep robotic simulator, showing that ELLM-trained agents have\nbetter coverage of common-sense behaviors during pretraining and usually match\nor improve performance on a range of downstream tasks. Code available at\nhttps://github.com/yuqingd/ellm.\n",
                "链接": "https://arxiv.org/abs/2302.06692"
            },
            {
                "文章ID": "60210",
                "标题": "Grounding Large Language Models in Interactive Environments with Online\n  Reinforcement Learning",
                "作者": " Thomas Carta,  Clément Romac,  Thomas Wolf,  Sylvain Lamprier,  Olivier Sigaud,  Pierre-Yves Oudeyer",
                "发布日期": "2023-09-07",
                "摘要": "  Recent works successfully leveraged Large Language Models' (LLM) abilities to\ncapture abstract knowledge about world's physics to solve decision-making\nproblems. Yet, the alignment between LLMs' knowledge and the environment can be\nwrong and limit functional competence due to lack of grounding. In this paper,\nwe study an approach (named GLAM) to achieve this alignment through functional\ngrounding: we consider an agent using an LLM as a policy that is progressively\nupdated as the agent interacts with the environment, leveraging online\nReinforcement Learning to improve its performance to solve goals. Using an\ninteractive textual environment designed to study higher-level forms of\nfunctional grounding, and a set of spatial and navigation tasks, we study\nseveral scientific questions: 1) Can LLMs boost sample efficiency for online\nlearning of various RL tasks? 2) How can it boost different forms of\ngeneralization? 3) What is the impact of online learning? We study these\nquestions by functionally grounding several variants (size, architecture) of\nFLAN-T5.\n",
                "链接": "https://arxiv.org/abs/2302.02662"
            },
            {
                "文章ID": "121388",
                "标题": "Leveraging Reinforcement Learning and Large Language Models for Code\n  Optimization",
                "作者": " Shukai Duan,  Nikos Kanakaris,  Xiongye Xiao,  Heng Ping,  Chenyu Zhou,  Nesreen K. Ahmed,  Guixiang Ma,  Mihai Capota,  Theodore L. Willke,  Shahin Nazarian,  Paul Bogdan",
                "发布日期": "2023-12-12",
                "摘要": "  Code optimization is a daunting task that requires a significant level of\nexpertise from experienced programmers. This level of expertise is not\nsufficient when compared to the rapid development of new hardware\narchitectures. Towards advancing the whole code optimization process, recent\napproaches rely on machine learning and artificial intelligence techniques.\nThis paper introduces a new framework to decrease the complexity of code\noptimization. The proposed framework builds on large language models (LLMs) and\nreinforcement learning (RL) and enables LLMs to receive feedback from their\nenvironment (i.e., unit tests) during the fine-tuning process. We compare our\nframework with existing state-of-the-art models and show that it is more\nefficient with respect to speed and computational usage, as a result of the\ndecrement in training steps and its applicability to models with fewer\nparameters. Additionally, our framework reduces the possibility of logical and\nsyntactical errors. Toward evaluating our approach, we run several experiments\non the PIE dataset using a CodeT5 language model and RRHF, a new reinforcement\nlearning algorithm. We adopt a variety of evaluation metrics with regards to\noptimization quality, and speedup. The evaluation results demonstrate that the\nproposed framework has similar results in comparison with existing models using\nshorter training times and smaller pre-trained models. In particular, we\naccomplish an increase of 5.6% and 2.2 over the baseline models concerning the\n%OP T and SP metrics.\n",
                "链接": "https://arxiv.org/abs/2312.05657"
            },
            {
                "文章ID": "113753",
                "标题": "Accelerating Reinforcement Learning of Robotic Manipulations via\n  Feedback from Large Language Models",
                "作者": " Kun Chu,  Xufeng Zhao,  Cornelius Weber,  Mengdi Li,  Stefan Wermter",
                "发布日期": "2023-11-07",
                "摘要": "  Reinforcement Learning (RL) plays an important role in the robotic\nmanipulation domain since it allows self-learning from trial-and-error\ninteractions with the environment. Still, sample efficiency and reward\nspecification seriously limit its potential. One possible solution involves\nlearning from expert guidance. However, obtaining a human expert is impractical\ndue to the high cost of supervising an RL agent, and developing an automatic\nsupervisor is a challenging endeavor. Large Language Models (LLMs) demonstrate\nremarkable abilities to provide human-like feedback on user inputs in natural\nlanguage. Nevertheless, they are not designed to directly control low-level\nrobotic motions, as their pretraining is based on vast internet data rather\nthan specific robotics data. In this paper, we introduce the Lafite-RL\n(Language agent feedback interactive Reinforcement Learning) framework, which\nenables RL agents to learn robotic tasks efficiently by taking advantage of\nLLMs' timely feedback. Our experiments conducted on RLBench tasks illustrate\nthat, with simple prompt design in natural language, the Lafite-RL agent\nexhibits improved learning capabilities when guided by an LLM. It outperforms\nthe baseline in terms of both learning efficiency and success rate,\nunderscoring the efficacy of the rewards provided by an LLM.\n",
                "链接": "https://arxiv.org/abs/2311.02379"
            },
            {
                "文章ID": "79284",
                "标题": "Meta-in-context learning in large language models",
                "作者": " Julian Coda-Forno,  Marcel Binz,  Zeynep Akata,  Matthew Botvinick,  Jane X. Wang,  Eric Schulz",
                "发布日期": "2023-05-23",
                "摘要": "  Large language models have shown tremendous performance in a variety of\ntasks. In-context learning -- the ability to improve at a task after being\nprovided with a number of demonstrations -- is seen as one of the main\ncontributors to their success. In the present paper, we demonstrate that the\nin-context learning abilities of large language models can be recursively\nimproved via in-context learning itself. We coin this phenomenon\nmeta-in-context learning. Looking at two idealized domains, a one-dimensional\nregression task and a two-armed bandit task, we show that meta-in-context\nlearning adaptively reshapes a large language model's priors over expected\ntasks. Furthermore, we find that meta-in-context learning modifies the\nin-context learning strategies of such models. Finally, we extend our approach\nto a benchmark of real-world regression problems where we observe competitive\nperformance to traditional learning algorithms. Taken together, our work\nimproves our understanding of in-context learning and paves the way toward\nadapting large language models to the environment they are applied purely\nthrough meta-in-context learning rather than traditional finetuning.\n",
                "链接": "https://arxiv.org/abs/2305.12907"
            },
            {
                "文章ID": "85592",
                "标题": "Large Language Models Are Semi-Parametric Reinforcement Learning Agents",
                "作者": " Danyang Zhang,  Lu Chen,  Situo Zhang,  Hongshen Xu,  Zihan Zhao,  Kai Yu",
                "发布日期": "2023-10-31",
                "摘要": "  Inspired by the insights in cognitive science with respect to human memory\nand reasoning mechanism, a novel evolvable LLM-based (Large Language Model)\nagent framework is proposed as REMEMBERER. By equipping the LLM with a\nlong-term experience memory, REMEMBERER is capable of exploiting the\nexperiences from the past episodes even for different task goals, which excels\nan LLM-based agent with fixed exemplars or equipped with a transient working\nmemory. We further introduce Reinforcement Learning with Experience Memory\n(RLEM) to update the memory. Thus, the whole system can learn from the\nexperiences of both success and failure, and evolve its capability without\nfine-tuning the parameters of the LLM. In this way, the proposed REMEMBERER\nconstitutes a semi-parametric RL agent. Extensive experiments are conducted on\ntwo RL task sets to evaluate the proposed framework. The average results with\ndifferent initialization and training sets exceed the prior SOTA by 4% and 2%\nfor the success rate on two task sets and demonstrate the superiority and\nrobustness of REMEMBERER.\n",
                "链接": "https://arxiv.org/abs/2306.07929"
            },
            {
                "文章ID": "116733",
                "标题": "Rethinking Large Language Models in Mental Health Applications",
                "作者": " Shaoxiong Ji,  Tianlin Zhang,  Kailai Yang,  Sophia Ananiadou,  Erik Cambria",
                "发布日期": "2023-12-19",
                "摘要": "  Large Language Models (LLMs) have become valuable assets in mental health,\nshowing promise in both classification tasks and counseling applications. This\npaper offers a perspective on using LLMs in mental health applications. It\ndiscusses the instability of generative models for prediction and the potential\nfor generating hallucinatory outputs, underscoring the need for ongoing audits\nand evaluations to maintain their reliability and dependability. The paper also\ndistinguishes between the often interchangeable terms ``explainability'' and\n``interpretability'', advocating for developing inherently interpretable\nmethods instead of relying on potentially hallucinated self-explanations\ngenerated by LLMs. Despite the advancements in LLMs, human counselors'\nempathetic understanding, nuanced interpretation, and contextual awareness\nremain irreplaceable in the sensitive and complex realm of mental health\ncounseling. The use of LLMs should be approached with a judicious and\nconsiderate mindset, viewing them as tools that complement human expertise\nrather than seeking to replace it.\n",
                "链接": "https://arxiv.org/abs/2311.11267"
            },
            {
                "文章ID": "117384",
                "标题": "Enhancing Logical Reasoning in Large Language Models to Facilitate Legal\n  Applications",
                "作者": " Ha-Thanh Nguyen,  Wachara Fungwacharakorn,  Ken Satoh",
                "发布日期": "2023-11-23",
                "摘要": "  Language serves as a vehicle for conveying thought, enabling communication\namong individuals. The ability to distinguish between diverse concepts,\nidentify fairness and injustice, and comprehend a range of legal notions\nfundamentally relies on logical reasoning. Large Language Models (LLMs) attempt\nto emulate human language understanding and generation, but their competency in\nlogical reasoning remains limited. This paper seeks to address the\nphilosophical question: How can we effectively teach logical reasoning to LLMs\nwhile maintaining a deep understanding of the intricate relationship between\nlanguage and logic? By focusing on bolstering LLMs' capabilities in logical\nreasoning, we aim to expand their applicability in law and other\nlogic-intensive disciplines. To this end, we propose a Reinforcement Learning\nfrom Logical Feedback (RLLF) approach, which serves as a potential framework\nfor refining LLMs' reasoning capacities. Through RLLF and a revised evaluation\nmethodology, we explore new avenues for research in this domain and contribute\nto the development of LLMs capable of handling complex legal reasoning tasks\nwhile acknowledging the fundamental connection between language and logic.\n",
                "链接": "https://arxiv.org/abs/2311.13095"
            },
            {
                "文章ID": "34816",
                "标题": "Shortcut Learning of Large Language Models in Natural Language\n  Understanding",
                "作者": " Mengnan Du,  Fengxiang He,  Na Zou,  Dacheng Tao,  Xia Hu",
                "发布日期": "2023-05-09",
                "摘要": "  Large language models (LLMs) have achieved state-of-the-art performance on a\nseries of natural language understanding tasks. However, these LLMs might rely\non dataset bias and artifacts as shortcuts for prediction. This has\nsignificantly affected their generalizability and adversarial robustness. In\nthis paper, we provide a review of recent developments that address the\nshortcut learning and robustness challenge of LLMs. We first introduce the\nconcepts of shortcut learning of language models. We then introduce methods to\nidentify shortcut learning behavior in language models, characterize the\nreasons for shortcut learning, as well as introduce mitigation solutions.\nFinally, we discuss key research challenges and potential research directions\nin order to advance the field of LLMs.\n",
                "链接": "https://arxiv.org/abs/2208.11857"
            },
            {
                "文章ID": "93700",
                "标题": "Okapi: Instruction-tuned Large Language Models in Multiple Languages\n  with Reinforcement Learning from Human Feedback",
                "作者": " Viet Dac Lai,  Chien Van Nguyen,  Nghia Trung Ngo,  Thuat Nguyen,  Franck Dernoncourt,  Ryan A. Rossi,  Thien Huu Nguyen",
                "发布日期": "2023-08-03",
                "摘要": "  A key technology for the development of large language models (LLMs) involves\ninstruction tuning that helps align the models' responses with human\nexpectations to realize impressive learning abilities. Two major approaches for\ninstruction tuning characterize supervised fine-tuning (SFT) and reinforcement\nlearning from human feedback (RLHF), which are currently applied to produce the\nbest commercial LLMs (e.g., ChatGPT). To improve the accessibility of LLMs for\nresearch and development efforts, various instruction-tuned open-source LLMs\nhave also been introduced recently, e.g., Alpaca, Vicuna, to name a few.\nHowever, existing open-source LLMs have only been instruction-tuned for English\nand a few popular languages, thus hindering their impacts and accessibility to\nmany other languages in the world. Among a few very recent work to explore\ninstruction tuning for LLMs in multiple languages, SFT has been used as the\nonly approach to instruction-tune LLMs for multiple languages. This has left a\nsignificant gap for fine-tuned LLMs based on RLHF in diverse languages and\nraised important questions on how RLHF can boost the performance of\nmultilingual instruction tuning. To overcome this issue, we present Okapi, the\nfirst system with instruction-tuned LLMs based on RLHF for multiple languages.\nOkapi introduces instruction and response-ranked data in 26 diverse languages\nto facilitate the experiments and development of future multilingual LLM\nresearch. We also present benchmark datasets to enable the evaluation of\ngenerative LLMs in multiple languages. Our experiments demonstrate the\nadvantages of RLHF for multilingual instruction over SFT for different base\nmodels and datasets. Our framework and resources are released at\nhttps://github.com/nlp-uoregon/Okapi.\n",
                "链接": "https://arxiv.org/abs/2307.16039"
            }
        ]
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "89073",
                "标题": "Analysis of Task Transferability in Large Pre-trained Classifiers",
                "作者": " Akshay Mehra,  Yunbei Zhang,  Jihun Hamm",
                "发布日期": "2023-07-04",
                "摘要": "  Transfer learning transfers the knowledge acquired by a model from a source\ntask to multiple downstream target tasks with minimal fine-tuning. The success\nof transfer learning at improving performance, especially with the use of large\npre-trained models has made transfer learning an essential tool in the machine\nlearning toolbox. However, the conditions under which the performance is\ntransferable to downstream tasks are not understood very well. In this work, we\nanalyze the transfer of performance for classification tasks, when only the\nlast linear layer of the source model is fine-tuned on the target task. We\npropose a novel Task Transfer Analysis approach that transforms the source\ndistribution (and classifier) by changing the class prior distribution, label,\nand feature spaces to produce a new source distribution (and classifier) and\nallows us to relate the loss of the downstream task (i.e., transferability) to\nthat of the source task. Concretely, our bound explains transferability in\nterms of the Wasserstein distance between the transformed source and downstream\ntask's distribution, conditional entropy between the label distributions of the\ntwo tasks, and weighted loss of the source classifier on the source task.\nMoreover, we propose an optimization problem for learning the transforms of the\nsource task to minimize the upper bound on transferability. We perform a\nlarge-scale empirical study by using state-of-the-art pre-trained models and\ndemonstrate the effectiveness of our bound and optimization at predicting\ntransferability. The results of our experiments demonstrate how factors such as\ntask relatedness, pretraining method, and model architecture affect\ntransferability.\n",
                "链接": "https://arxiv.org/abs/2307.00823"
            },
            {
                "文章ID": "119143",
                "标题": "Label-efficient Training of Small Task-specific Models by Leveraging\n  Vision Foundation Models",
                "作者": " Raviteja Vemulapalli,  Hadi Pouransari,  Fartash Faghri,  Sachin Mehta,  Mehrdad Farajtabar,  Mohammad Rastegari,  Oncel Tuzel",
                "发布日期": "2023-12-01",
                "摘要": "  Large Vision Foundation Models (VFMs) pretrained on massive datasets exhibit\nimpressive performance on various downstream tasks, especially with limited\nlabeled target data. However, due to their high memory and compute\nrequirements, these models cannot be deployed in resource constrained settings.\nThis raises an important question: How can we utilize the knowledge from a\nlarge VFM to train a small task-specific model for a new target task with\nlimited labeled training data? In this work, we answer this question by\nproposing a simple and highly effective task-oriented knowledge transfer\napproach to leverage pretrained VFMs for effective training of small\ntask-specific models. Our experimental results on four target tasks under\nlimited labeled data settings show that the proposed knowledge transfer\napproach outperforms task-agnostic VFM distillation, web-scale CLIP pretraining\nand supervised ImageNet pretraining by 1-10.5%, 2-22% and 2-14%, respectively.\nWe also show that the dataset used for transferring knowledge has a significant\neffect on the final target task performance, and propose an image\nretrieval-based approach for curating effective transfer sets.\n",
                "链接": "https://arxiv.org/abs/2311.18237"
            },
            {
                "文章ID": "26664",
                "标题": "ST-Adapter: Parameter-Efficient Image-to-Video Transfer Learning",
                "作者": " Junting Pan,  Ziyi Lin,  Xiatian Zhu,  Jing Shao,  Hongsheng Li",
                "发布日期": "2022-10-14",
                "摘要": "  Capitalizing on large pre-trained models for various downstream tasks of\ninterest have recently emerged with promising performance. Due to the\never-growing model size, the standard full fine-tuning based task adaptation\nstrategy becomes prohibitively costly in terms of model training and storage.\nThis has led to a new research direction in parameter-efficient transfer\nlearning. However, existing attempts typically focus on downstream tasks from\nthe same modality (e.g., image understanding) of the pre-trained model. This\ncreates a limit because in some specific modalities, (e.g., video\nunderstanding) such a strong pre-trained model with sufficient knowledge is\nless or not available. In this work, we investigate such a novel cross-modality\ntransfer learning setting, namely parameter-efficient image-to-video transfer\nlearning. To solve this problem, we propose a new Spatio-Temporal Adapter\n(ST-Adapter) for parameter-efficient fine-tuning per video task. With a\nbuilt-in spatio-temporal reasoning capability in a compact design, ST-Adapter\nenables a pre-trained image model without temporal knowledge to reason about\ndynamic video content at a small (~8%) per-task parameter cost, requiring\napproximately 20 times fewer updated parameters compared to previous work.\nExtensive experiments on video action recognition tasks show that our\nST-Adapter can match or even outperform the strong full fine-tuning strategy\nand state-of-the-art video models, whilst enjoying the advantage of parameter\nefficiency. The code and model are available at\nhttps://github.com/linziyi96/st-adapter\n",
                "链接": "https://arxiv.org/abs/2206.13559"
            },
            {
                "文章ID": "106450",
                "标题": "Talking Models: Distill Pre-trained Knowledge to Downstream Models via\n  Interactive Communication",
                "作者": " Zhe Zhao,  Qingyun Liu,  Huan Gui,  Bang An,  Lichan Hong,  Ed H. Chi",
                "发布日期": "2023-10-06",
                "摘要": "  Many recent breakthroughs in machine learning have been enabled by the\npre-trained foundation models. By scaling up model parameters, training data,\nand computation resources, foundation models have significantly advanced the\nstate-of-the-art in many applications. However, it is still an open question of\nhow to use these models to perform downstream tasks efficiently. Knowledge\ndistillation (KD) has been explored to tackle this challenge. KD transfers\nknowledge from a large teacher model to a smaller student model. While KD has\nbeen successful in improving student model performance, recent research has\ndiscovered that a powerful teacher does not necessarily lead to a powerful\nstudent, due to their huge capacity gap. In addition, the potential\ndistribution shifts between the pre-training data and downstream tasks can make\nknowledge transfer in KD sub-optimal for improving downstream task performance.\nIn this paper, we extend KD with an interactive communication process to help\nstudents of downstream tasks learn effectively from pre-trained foundation\nmodels. Our design is inspired by the way humans learn from teachers who can\nexplain knowledge in a way that meets the students' needs. Specifically, we let\neach model (i.e., student and teacher) train two components: (1) an encoder\nencoding the model's hidden states to a message and (2) a decoder decoding any\nmessages to its own hidden states. With encoder and decoder, not only can the\nteacher transfer rich information by encoding its hidden states, but also the\nstudent can send messages with information of downstream tasks to the teacher.\nTherefore, knowledge passing from teacher to student can be tailored to the\nstudent's capacity and downstream tasks' distributions. We conducted\nexperiments on benchmark datasets to show that our communication mechanism\noutperforms state-of-the-art distillation techniques.\n",
                "链接": "https://arxiv.org/abs/2310.03188"
            },
            {
                "文章ID": "80244",
                "标题": "BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual\n  Transfer",
                "作者": " Akari Asai,  Sneha Kudugunta,  Xinyan Velocity Yu,  Terra Blevins,  Hila Gonen,  Machel Reid,  Yulia Tsvetkov,  Sebastian Ruder,  Hannaneh Hajishirzi",
                "发布日期": "2023-05-25",
                "摘要": "  Despite remarkable advancements in few-shot generalization in natural\nlanguage processing, most models are developed and evaluated primarily in\nEnglish. To facilitate research on few-shot cross-lingual transfer, we\nintroduce a new benchmark, called BUFFET, which unifies 15 diverse tasks across\n54 languages in a sequence-to-sequence format and provides a fixed set of\nfew-shot examples and instructions. BUFFET is designed to establish a rigorous\nand equitable evaluation framework for few-shot cross-lingual transfer across a\nbroad range of tasks and languages. Using BUFFET, we perform thorough\nevaluations of state-of-the-art multilingual large language models with\ndifferent transfer methods, namely in-context learning and fine-tuning. Our\nfindings reveal significant room for improvement in few-shot in-context\ncross-lingual transfer. In particular, ChatGPT with in-context learning often\nperforms worse than much smaller mT5-base models fine-tuned on English task\ndata and few-shot in-language examples. Our analysis suggests various avenues\nfor future research in few-shot cross-lingual transfer, such as improved\npretraining, understanding, and future evaluations.\n",
                "链接": "https://arxiv.org/abs/2305.14857"
            },
            {
                "文章ID": "10705",
                "标题": "Hierarchical Inductive Transfer for Continual Dialogue Learning",
                "作者": " Shaoxiong Feng,  Xuancheng Ren,  Kan Li,  Xu Sun",
                "发布日期": "2022-03-22",
                "摘要": "  Pre-trained models have achieved excellent performance on the dialogue task.\nHowever, for the continual increase of online chit-chat scenarios, directly\nfine-tuning these models for each of the new tasks not only explodes the\ncapacity of the dialogue system on the embedded devices but also causes\nknowledge forgetting on pre-trained models and knowledge interference among\ndiverse dialogue tasks. In this work, we propose a hierarchical inductive\ntransfer framework to learn and deploy the dialogue skills continually and\nefficiently. First, we introduce the adapter module into pre-trained models for\nlearning new dialogue tasks. As the only trainable module, it is beneficial for\nthe dialogue system on the embedded devices to acquire new dialogue skills with\nnegligible additional parameters. Then, for alleviating knowledge interference\nbetween tasks yet benefiting the regularization between them, we further design\nhierarchical inductive transfer that enables new tasks to use general knowledge\nin the base adapter without being misled by diverse knowledge in task-specific\nadapters. Empirical evaluation and analysis indicate that our framework obtains\ncomparable performance under deployment-friendly model capacity.\n",
                "链接": "https://arxiv.org/abs/2203.10484"
            },
            {
                "文章ID": "89864",
                "标题": "Derivative Free Weight-space Ensembling",
                "作者": " Dean Ninalga",
                "发布日期": "2023-07-27",
                "摘要": "  Recent work suggests that interpolating between the weights of two\nspecialized language models can transfer knowledge between tasks in a way that\nmulti-task learning cannot. However, very few have explored interpolation\nbetween more than two models, where each has a distinct knowledge base. In this\npaper, we introduce Derivative Free Weight-space Ensembling (DFWE), a new\nfew-sample task transfer approach for open-domain dialogue. Our framework\ncreates a set of diverse expert language models trained using a predefined set\nof source tasks. Next, we finetune each of the expert models on the target\ntask, approaching the target task from several distinct knowledge bases.\nFinally, we linearly interpolate between the model weights using a\ngradient-free-optimization algorithm, to efficiently find a good interpolation\nweighting. We demonstrate the effectiveness of the method on FETA-Friends\noutperforming the standard pretrain-finetune approach.\n",
                "链接": "https://arxiv.org/abs/2307.03506"
            },
            {
                "文章ID": "122482",
                "标题": "VMT-Adapter: Parameter-Efficient Transfer Learning for Multi-Task Dense\n  Scene Understanding",
                "作者": " Yi Xin,  Junlong Du,  Qiang Wang,  Zhiwen Lin,  Ke Yan",
                "发布日期": "2023-12-18",
                "摘要": "  Large-scale pre-trained models have achieved remarkable success in various\ncomputer vision tasks. A standard approach to leverage these models is to\nfine-tune all model parameters for downstream tasks, which poses challenges in\nterms of computational and storage costs. Recently, inspired by Natural\nLanguage Processing (NLP), parameter-efficient transfer learning has been\nsuccessfully applied to vision tasks. However, most existing techniques\nprimarily focus on single-task adaptation, and despite limited research on\nmulti-task adaptation, these methods often exhibit suboptimal training and\ninference efficiency. In this paper, we first propose an once-for-all Vision\nMulti-Task Adapter (VMT-Adapter), which strikes approximately O(1) training and\ninference efficiency w.r.t task number. Concretely, VMT-Adapter shares the\nknowledge from multiple tasks to enhance cross-task interaction while preserves\ntask-specific knowledge via independent knowledge extraction modules. Notably,\nsince task-specific modules require few parameters, VMT-Adapter can handle an\narbitrary number of tasks with a negligible increase of trainable parameters.\nWe also propose VMT-Adapter-Lite, which further reduces the trainable\nparameters by learning shared parameters between down- and up-projections.\nExtensive experiments on four dense scene understanding tasks demonstrate the\nsuperiority of VMT-Adapter(-Lite), achieving a 3.96%(1.34%) relative\nimprovement compared to single-task full fine-tuning, while utilizing merely\n~1% (0.36%) trainable parameters of the pre-trained model.\n",
                "链接": "https://arxiv.org/abs/2312.08733"
            },
            {
                "文章ID": "46363",
                "标题": "Beyond Not-Forgetting: Continual Learning with Backward Knowledge\n  Transfer",
                "作者": " Sen Lin,  Li Yang,  Deliang Fan,  Junshan Zhang",
                "发布日期": "2022-11-03",
                "摘要": "  By learning a sequence of tasks continually, an agent in continual learning\n(CL) can improve the learning performance of both a new task and `old' tasks by\nleveraging the forward knowledge transfer and the backward knowledge transfer,\nrespectively. However, most existing CL methods focus on addressing\ncatastrophic forgetting in neural networks by minimizing the modification of\nthe learnt model for old tasks. This inevitably limits the backward knowledge\ntransfer from the new task to the old tasks, because judicious model updates\ncould possibly improve the learning performance of the old tasks as well. To\ntackle this problem, we first theoretically analyze the conditions under which\nupdating the learnt model of old tasks could be beneficial for CL and also lead\nto backward knowledge transfer, based on the gradient projection onto the input\nsubspaces of old tasks. Building on the theoretical analysis, we next develop a\nContinUal learning method with Backward knowlEdge tRansfer (CUBER), for a fixed\ncapacity neural network without data replay. In particular, CUBER first\ncharacterizes the task correlation to identify the positively correlated old\ntasks in a layer-wise manner, and then selectively modifies the learnt model of\nthe old tasks when learning the new task. Experimental studies show that CUBER\ncan even achieve positive backward knowledge transfer on several existing CL\nbenchmarks for the first time without data replay, where the related baselines\nstill suffer from catastrophic forgetting (negative backward knowledge\ntransfer). The superior performance of CUBER on the backward knowledge transfer\nalso leads to higher accuracy accordingly.\n",
                "链接": "https://arxiv.org/abs/2211.00789"
            },
            {
                "文章ID": "58204",
                "标题": "One Model for All Domains: Collaborative Domain-Prefix Tuning for\n  Cross-Domain NER",
                "作者": " Xiang Chen,  Lei Li,  Shuofei Qiao,  Ningyu Zhang,  Chuanqi Tan,  Yong Jiang,  Fei Huang,  Huajun Chen",
                "发布日期": "2023-09-19",
                "摘要": "  Cross-domain NER is a challenging task to address the low-resource problem in\npractical scenarios. Previous typical solutions mainly obtain a NER model by\npre-trained language models (PLMs) with data from a rich-resource domain and\nadapt it to the target domain. Owing to the mismatch issue among entity types\nin different domains, previous approaches normally tune all parameters of PLMs,\nending up with an entirely new NER model for each domain. Moreover, current\nmodels only focus on leveraging knowledge in one general source domain while\nfailing to successfully transfer knowledge from multiple sources to the target.\nTo address these issues, we introduce Collaborative Domain-Prefix Tuning for\ncross-domain NER (CP-NER) based on text-to-text generative PLMs. Specifically,\nwe present text-to-text generation grounding domain-related instructors to\ntransfer knowledge to new domain NER tasks without structural modifications. We\nutilize frozen PLMs and conduct collaborative domain-prefix tuning to stimulate\nthe potential of PLMs to handle NER tasks across various domains. Experimental\nresults on the Cross-NER benchmark show that the proposed approach has flexible\ntransfer ability and performs better on both one-source and multiple-source\ncross-domain NER tasks. Codes are available in\nhttps://github.com/zjunlp/DeepKE/tree/main/example/ner/cross.\n",
                "链接": "https://arxiv.org/abs/2301.10410"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和人文学科交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "112477",
                "标题": "Artificial intelligence and the limits of the humanities",
                "作者": " Włodzisław Duch",
                "发布日期": "2023-10-31",
                "摘要": "  The complexity of cultures in the modern world is now beyond human\ncomprehension. Cognitive sciences cast doubts on the traditional explanations\nbased on mental models. The core subjects in humanities may lose their\nimportance. Humanities have to adapt to the digital age. New, interdisciplinary\nbranches of humanities emerge. Instant access to information will be replaced\nby instant access to knowledge. Understanding the cognitive limitations of\nhumans and the opportunities opened by the development of artificial\nintelligence and interdisciplinary research necessary to address global\nchallenges is the key to the revitalization of humanities. Artificial\nintelligence will radically change humanities, from art to political sciences\nand philosophy, making these disciplines attractive to students and enabling\nthem to go beyond current limitations.\n",
                "链接": "https://arxiv.org/abs/2310.19425"
            },
            {
                "文章ID": "70754",
                "标题": "A Bibliometric Review of Large Language Models Research from 2017 to\n  2023",
                "作者": " Lizhou Fan,  Lingyao Li,  Zihui Ma,  Sanggyu Lee,  Huizi Yu,  Libby Hemphill",
                "发布日期": "2023-04-06",
                "摘要": "  Large language models (LLMs) are a class of language models that have\ndemonstrated outstanding performance across a range of natural language\nprocessing (NLP) tasks and have become a highly sought-after research area,\nbecause of their ability to generate human-like language and their potential to\nrevolutionize science and technology. In this study, we conduct bibliometric\nand discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000\npublications, this paper serves as a roadmap for researchers, practitioners,\nand policymakers to navigate the current landscape of LLMs research. We present\nthe research trends from 2017 to early 2023, identifying patterns in research\nparadigms and collaborations. We start with analyzing the core algorithm\ndevelopments and NLP tasks that are fundamental in LLMs research. We then\ninvestigate the applications of LLMs in various fields and domains including\nmedicine, engineering, social science, and humanities. Our review also reveals\nthe dynamic, fast-paced evolution of LLMs research. Overall, this paper offers\nvaluable insights into the current state, impact, and potential of LLMs\nresearch and its applications.\n",
                "链接": "https://arxiv.org/abs/2304.02020"
            },
            {
                "文章ID": "93762",
                "标题": "Text Analysis Using Deep Neural Networks in Digital Humanities and\n  Information Science",
                "作者": " Omri Suissa,  Avshalom Elmalech,  Maayan Zhitomirsky-Geffet",
                "发布日期": "2023-08-01",
                "摘要": "  Combining computational technologies and humanities is an ongoing effort\naimed at making resources such as texts, images, audio, video, and other\nartifacts digitally available, searchable, and analyzable. In recent years,\ndeep neural networks (DNN) dominate the field of automatic text analysis and\nnatural language processing (NLP), in some cases presenting a super-human\nperformance. DNNs are the state-of-the-art machine learning algorithms solving\nmany NLP tasks that are relevant for Digital Humanities (DH) research, such as\nspell checking, language detection, entity extraction, author detection,\nquestion answering, and other tasks. These supervised algorithms learn patterns\nfrom a large number of \"right\" and \"wrong\" examples and apply them to new\nexamples. However, using DNNs for analyzing the text resources in DH research\npresents two main challenges: (un)availability of training data and a need for\ndomain adaptation. This paper explores these challenges by analyzing multiple\nuse-cases of DH studies in recent literature and their possible solutions and\nlays out a practical decision model for DH experts for when and how to choose\nthe appropriate deep learning approaches for their research. Moreover, in this\npaper, we aim to raise awareness of the benefits of utilizing deep learning\nmodels in the DH community.\n",
                "链接": "https://arxiv.org/abs/2307.16217"
            },
            {
                "文章ID": "112547",
                "标题": "Transformation vs Tradition: Artificial General Intelligence (AGI) for\n  Arts and Humanities",
                "作者": " Zhengliang Liu,  Yiwei Li,  Qian Cao,  Junwen Chen,  Tianze Yang,  Zihao Wu,  John Hale,  John Gibbs,  Khaled Rasheed,  Ninghao Liu,  Gengchen Mai,  Tianming Liu",
                "发布日期": "2023-10-31",
                "摘要": "  Recent advances in artificial general intelligence (AGI), particularly large\nlanguage models and creative image generation systems have demonstrated\nimpressive capabilities on diverse tasks spanning the arts and humanities.\nHowever, the swift evolution of AGI has also raised critical questions about\nits responsible deployment in these culturally significant domains\ntraditionally seen as profoundly human. This paper provides a comprehensive\nanalysis of the applications and implications of AGI for text, graphics, audio,\nand video pertaining to arts and the humanities. We survey cutting-edge systems\nand their usage in areas ranging from poetry to history, marketing to film, and\ncommunication to classical art. We outline substantial concerns pertaining to\nfactuality, toxicity, biases, and public safety in AGI systems, and propose\nmitigation strategies. The paper argues for multi-stakeholder collaboration to\nensure AGI promotes creativity, knowledge, and cultural values without\nundermining truth or human dignity. Our timely contribution summarizes a\nrapidly developing field, highlighting promising directions while advocating\nfor responsible progress centering on human flourishing. The analysis lays the\ngroundwork for further research on aligning AGI's technological capacities with\nenduring social goods.\n",
                "链接": "https://arxiv.org/abs/2310.19626"
            },
            {
                "文章ID": "109281",
                "标题": "If the Sources Could Talk: Evaluating Large Language Models for Research\n  Assistance in History",
                "作者": " Giselle Gonzalez Garcia,  Christian Weilbach",
                "发布日期": "2023-10-18",
                "摘要": "  The recent advent of powerful Large-Language Models (LLM) provides a new\nconversational form of inquiry into historical memory (or, training data, in\nthis case). We show that by augmenting such LLMs with vector embeddings from\nhighly specialized academic sources, a conversational methodology can be made\naccessible to historians and other researchers in the Humanities. Concretely,\nwe evaluate and demonstrate how LLMs have the ability of assisting researchers\nwhile they examine a customized corpora of different types of documents,\nincluding, but not exclusive to: (1). primary sources, (2). secondary sources\nwritten by experts, and (3). the combination of these two. Compared to\nestablished search interfaces for digital catalogues, such as metadata and\nfull-text search, we evaluate the richer conversational style of LLMs on the\nperformance of two main types of tasks: (1). question-answering, and (2).\nextraction and organization of data. We demonstrate that LLMs semantic\nretrieval and reasoning abilities on problem-specific tasks can be applied to\nlarge textual archives that have not been part of the its training data.\nTherefore, LLMs can be augmented with sources relevant to specific research\nprojects, and can be queried privately by researchers.\n",
                "链接": "https://arxiv.org/abs/2310.10808"
            },
            {
                "文章ID": "72600",
                "标题": "SikuGPT: A Generative Pre-trained Model for Intelligent Information\n  Processing of Ancient Texts from the Perspective of Digital Humanities",
                "作者": " Liu Chang,  Wang Dongbo,  Zhao Zhixiao,  Hu Die,  Wu Mengcheng,  Lin Litao,  Shen Si,  Li Bin,  Liu Jiangfeng,  Zhang Hai,  Zhao Lianzheng",
                "发布日期": "2023-04-18",
                "摘要": "  The rapid advance in artificial intelligence technology has facilitated the\nprosperity of digital humanities research. Against such backdrop, research\nmethods need to be transformed in the intelligent processing of ancient texts,\nwhich is a crucial component of digital humanities research, so as to adapt to\nnew development trends in the wave of AIGC. In this study, we propose a GPT\nmodel called SikuGPT based on the corpus of Siku Quanshu. The model's\nperformance in tasks such as intralingual translation and text classification\nexceeds that of other GPT-type models aimed at processing ancient texts.\nSikuGPT's ability to process traditional Chinese ancient texts can help promote\nthe organization of ancient information and knowledge services, as well as the\ninternational dissemination of Chinese ancient culture.\n",
                "链接": "https://arxiv.org/abs/2304.07778"
            },
            {
                "文章ID": "115369",
                "标题": "MEGAVERSE: Benchmarking Large Language Models Across Languages,\n  Modalities, Models and Tasks",
                "作者": " Sanchit Ahuja,  Divyanshu Aggarwal,  Varun Gumma,  Ishaan Watts,  Ashutosh Sathe,  Millicent Ochieng,  Rishav Hada,  Prachi Jain,  Maxamed Axmed,  Kalika Bali,  Sunayana Sitaram",
                "发布日期": "2023-11-14",
                "摘要": "  Recently, there has been a rapid advancement in research on Large Language\nModels (LLMs), resulting in significant progress in several Natural Language\nProcessing (NLP) tasks. Consequently, there has been a surge in LLM evaluation\nresearch to comprehend the models' capabilities and limitations. However, much\nof this research has been confined to the English language, leaving LLM\nbuilding and evaluation for non-English languages relatively unexplored. There\nhas been an introduction of several new LLMs, necessitating their evaluation on\nnon-English languages. This study aims to expand our MEGA benchmarking suite by\nincluding six new datasets to form the MEGAVERSE benchmark. The benchmark\ncomprises 22 datasets covering 81 languages, including low-resource African\nlanguages. We evaluate several state-of-the-art LLMs like GPT-3.5-Turbo, GPT4,\nPaLM2, and Llama2 on the MEGAVERSE datasets. Additionally, we include two\nmultimodal datasets in the benchmark and assess the performance of the\nLLaVa-v1.5 model. Our experiments suggest that GPT4 and PaLM2 outperform the\nLlama models on various tasks, notably on low-resource languages, with GPT4\noutperforming PaLM2 on more datasets than vice versa. However, issues such as\ndata contamination must be addressed to obtain an accurate assessment of LLM\nperformance on non-English languages.\n",
                "链接": "https://arxiv.org/abs/2311.07463"
            },
            {
                "文章ID": "66370",
                "标题": "Algorithmic Ghost in the Research Shell: Large Language Models and\n  Academic Knowledge Creation in Management Research",
                "作者": " Nigel Williams,  Stanislav Ivanov,  Dimitrios Buhalis",
                "发布日期": "2023-03-14",
                "摘要": "  The paper looks at the role of large language models in academic knowledge\ncreation based on a scoping review (2018 to January 2023) of how researchers\nhave previously used the language model GPT to assist in the performance of\nacademic knowledge creation tasks beyond data analysis. These tasks include\nwriting, editing, reviewing, dataset creation and curation, which have been\ndifficult to perform using earlier ML tools. Based on a synthesis of these\npapers, this study identifies pathways for a future academic research landscape\nthat incorporates wider usage of large language models based on the current\nmodes of adoption in published articles as a Co-Writer, Research Assistant and\nRespondent.\n",
                "链接": "https://arxiv.org/abs/2303.07304"
            },
            {
                "文章ID": "104261",
                "标题": "Machine-assisted mixed methods: augmenting humanities and social\n  sciences with artificial intelligence",
                "作者": " Andres Karjus",
                "发布日期": "2023-09-27",
                "摘要": "  The increasing capacities of large language models (LLMs) present an\nunprecedented opportunity to scale up data analytics in the humanities and\nsocial sciences, augmenting and automating qualitative analytic tasks\npreviously typically allocated to human labor. This contribution proposes a\nsystematic mixed methods framework to harness qualitative analytic expertise,\nmachine scalability, and rigorous quantification, with attention to\ntransparency and replicability. 16 machine-assisted case studies are showcased\nas proof of concept. Tasks include linguistic and discourse analysis, lexical\nsemantic change detection, interview analysis, historical event cause inference\nand text mining, detection of political stance, text and idea reuse, genre\ncomposition in literature and film; social network inference, automated\nlexicography, missing metadata augmentation, and multimodal visual cultural\nanalytics. In contrast to the focus on English in the emerging LLM\napplicability literature, many examples here deal with scenarios involving\nsmaller languages and historical texts prone to digitization distortions. In\nall but the most difficult tasks requiring expert knowledge, generative LLMs\ncan demonstrably serve as viable research instruments. LLM (and human)\nannotations may contain errors and variation, but the agreement rate can and\nshould be accounted for in subsequent statistical modeling; a bootstrapping\napproach is discussed. The replications among the case studies illustrate how\ntasks previously requiring potentially months of team effort and complex\ncomputational pipelines, can now be accomplished by an LLM-assisted scholar in\na fraction of the time. Importantly, this approach is not intended to replace,\nbut to augment researcher knowledge and skills. With these opportunities in\nsight, qualitative expertise and the ability to pose insightful questions have\narguably never been more critical.\n",
                "链接": "https://arxiv.org/abs/2309.14379"
            },
            {
                "文章ID": "100283",
                "标题": "On the Planning, Search, and Memorization Capabilities of Large Language\n  Models",
                "作者": " Yunhao Yang,  Anshul Tomar",
                "发布日期": "2023-09-06",
                "摘要": "  The rapid advancement of large language models, such as the Generative\nPre-trained Transformer (GPT) series, has had significant implications across\nvarious disciplines. In this study, we investigate the potential of the\nstate-of-the-art large language model (GPT-4) for planning tasks. We explore\nits effectiveness in multiple planning subfields, highlighting both its\nstrengths and limitations. Through a comprehensive examination, we identify\nareas where large language models excel in solving planning problems and reveal\nthe constraints that limit their applicability. Our empirical analysis focuses\non GPT-4's performance in planning domain extraction, graph search path\nplanning, and adversarial planning. We then propose a way of fine-tuning a\ndomain-specific large language model to improve its Chain of Thought (CoT)\ncapabilities for the above-mentioned tasks. The results provide valuable\ninsights into the potential applications of large language models in the\nplanning domain and pave the way for future research to overcome their\nlimitations and expand their capabilities.\n",
                "链接": "https://arxiv.org/abs/2309.01868"
            }
        ]
    },
    {
        "question": {
            "question": "2022年后与AI for Science相关的综述论文",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "91376",
                "标题": "Towards eXplainable AI for Mobility Data Science",
                "作者": " Anahid Jalali,  Anita Graser,  Clemens Heistracher",
                "发布日期": "2023-09-08",
                "摘要": "  This paper presents our ongoing work towards XAI for Mobility Data Science\napplications, focusing on explainable models that can learn from dense\ntrajectory data, such as GPS tracks of vehicles and vessels using temporal\ngraph neural networks (GNNs) and counterfactuals. We review the existing GeoXAI\nstudies, argue the need for comprehensible explanations with human-centered\napproaches, and outline a research path toward XAI for Mobility Data Science.\n",
                "链接": "https://arxiv.org/abs/2307.08461"
            },
            {
                "文章ID": "94694",
                "标题": "AI Literature Review Suite",
                "作者": " David A. Tovar",
                "发布日期": "2023-08-07",
                "摘要": "  The process of conducting literature reviews is often time-consuming and\nlabor-intensive. To streamline this process, I present an AI Literature Review\nSuite that integrates several functionalities to provide a comprehensive\nliterature review. This tool leverages the power of open access science, large\nlanguage models (LLMs) and natural language processing to enable the searching,\ndownloading, and organizing of PDF files, as well as extracting content from\narticles. Semantic search queries are used for data retrieval, while text\nembeddings and summarization using LLMs present succinct literature reviews.\nInteraction with PDFs is enhanced through a user-friendly graphical user\ninterface (GUI). The suite also features integrated programs for bibliographic\norganization, interaction and query, and literature review summaries. This tool\npresents a robust solution to automate and optimize the process of literature\nreview in academic and industrial research.\n",
                "链接": "https://arxiv.org/abs/2308.02443"
            },
            {
                "文章ID": "116688",
                "标题": "Best uses of ChatGPT and Generative AI for computer science research",
                "作者": " Eduardo C. Garrido-Merchan",
                "发布日期": "2023-11-21",
                "摘要": "  Generative Artificial Intelligence (AI), particularly tools like OpenAI's\npopular ChatGPT, is reshaping the landscape of computer science research. Used\nwisely, these tools can boost the productivity of a computer research\nscientist. This paper provides an exploration of the diverse applications of\nChatGPT and other generative AI technologies in computer science academic\nresearch, making recommendations about the use of Generative AI to make more\nproductive the role of the computer research scientist, with the focus of\nwriting new research papers. We highlight innovative uses such as brainstorming\nresearch ideas, aiding in the drafting and styling of academic papers and\nassisting in the synthesis of state-of-the-art section. Further, we delve into\nusing these technologies in understanding interdisciplinary approaches, making\ncomplex texts simpler, and recommending suitable academic journals for\npublication. Significant focus is placed on generative AI's contributions to\nsynthetic data creation, research methodology, and mentorship, as well as in\ntask organization and article quality assessment. The paper also addresses the\nutility of AI in article review, adapting texts to length constraints,\nconstructing counterarguments, and survey development. Moreover, we explore the\ncapabilities of these tools in disseminating ideas, generating images and\naudio, text transcription, and engaging with editors. We also describe some\nnon-recommended uses of generative AI for computer science research, mainly\nbecause of the limitations of this technology.\n",
                "链接": "https://arxiv.org/abs/2311.11175"
            },
            {
                "文章ID": "65341",
                "标题": "AI for Science: An Emerging Agenda",
                "作者": " Philipp Berens,  Kyle Cranmer,  Neil D. Lawrence,  Ulrike von Luxburg,  Jessica Montgomery",
                "发布日期": "2023-03-09",
                "摘要": "  This report documents the programme and the outcomes of Dagstuhl Seminar\n22382 \"Machine Learning for Science: Bridging Data-Driven and Mechanistic\nModelling\". Today's scientific challenges are characterised by complexity.\nInterconnected natural, technological, and human systems are influenced by\nforces acting across time- and spatial-scales, resulting in complex\ninteractions and emergent behaviours. Understanding these phenomena -- and\nleveraging scientific advances to deliver innovative solutions to improve\nsociety's health, wealth, and well-being -- requires new ways of analysing\ncomplex systems. The transformative potential of AI stems from its widespread\napplicability across disciplines, and will only be achieved through integration\nacross research domains. AI for science is a rendezvous point. It brings\ntogether expertise from $\\mathrm{AI}$ and application domains; combines\nmodelling knowledge with engineering know-how; and relies on collaboration\nacross disciplines and between humans and machines. Alongside technical\nadvances, the next wave of progress in the field will come from building a\ncommunity of machine learning researchers, domain experts, citizen scientists,\nand engineers working together to design and deploy effective AI tools. This\nreport summarises the discussions from the seminar and provides a roadmap to\nsuggest how different communities can collaborate to deliver a new wave of\nprogress in AI and its application for scientific discovery.\n",
                "链接": "https://arxiv.org/abs/2303.04217"
            },
            {
                "文章ID": "110050",
                "标题": "AI for Mathematics: A Cognitive Science Perspective",
                "作者": " Cedegao E. Zhang,  Katherine M. Collins,  Adrian Weller,  Joshua B. Tenenbaum",
                "发布日期": "2023-10-23",
                "摘要": "  Mathematics is one of the most powerful conceptual systems developed and used\nby the human species. Dreams of automated mathematicians have a storied history\nin artificial intelligence (AI). Rapid progress in AI, particularly propelled\nby advances in large language models (LLMs), has sparked renewed, widespread\ninterest in building such systems. In this work, we reflect on these goals from\na \\textit{cognitive science} perspective. We call attention to several\nclassical and ongoing research directions from cognitive science, which we\nbelieve are valuable for AI practitioners to consider when seeking to build\ntruly human (or superhuman)-level mathematical systems. We close with open\ndiscussions and questions that we believe necessitate a multi-disciplinary\nperspective -- cognitive scientists working in tandem with AI researchers and\nmathematicians -- as we move toward better mathematical AI systems which not\nonly help us push the frontier of the mathematics, but also offer glimpses into\nhow we as humans are even capable of such great cognitive feats.\n",
                "链接": "https://arxiv.org/abs/2310.13021"
            },
            {
                "文章ID": "65767",
                "标题": "Position Paper on Dataset Engineering to Accelerate Science",
                "作者": " Emilio Vital Brazil,  Eduardo Soares,  Lucas Villa Real,  Leonardo Azevedo,  Vinicius Segura,  Luiz Zerkowski,  Renato Cerqueira",
                "发布日期": "2023-03-13",
                "摘要": "  Data is a critical element in any discovery process. In the last decades, we\nobserved exponential growth in the volume of available data and the technology\nto manipulate it. However, data is only practical when one can structure it for\na well-defined task. For instance, we need a corpus of text broken into\nsentences to train a natural language machine-learning model. In this work, we\nwill use the token \\textit{dataset} to designate a structured set of data built\nto perform a well-defined task. Moreover, the dataset will be used in most\ncases as a blueprint of an entity that at any moment can be stored as a table.\nSpecifically, in science, each area has unique forms to organize, gather and\nhandle its datasets. We believe that datasets must be a first-class entity in\nany knowledge-intensive process, and all workflows should have exceptional\nattention to datasets' lifecycle, from their gathering to uses and evolution.\nWe advocate that science and engineering discovery processes are extreme\ninstances of the need for such organization on datasets, claiming for new\napproaches and tooling. Furthermore, these requirements are more evident when\nthe discovery workflow uses artificial intelligence methods to empower the\nsubject-matter expert. In this work, we discuss an approach to bringing\ndatasets as a critical entity in the discovery process in science. We\nillustrate some concepts using material discovery as a use case. We chose this\ndomain because it leverages many significant problems that can be generalized\nto other science fields.\n",
                "链接": "https://arxiv.org/abs/2303.05545"
            },
            {
                "文章ID": "19147",
                "标题": "AI and Citizen Science for Serendipity",
                "作者": " Marisa Ponti,  Anastasia Skarpeti,  Bruno Kestemont",
                "发布日期": "2022-05-17",
                "摘要": "  It has been argued that introducing AI to creative practices destroys\nspontaneity, intuition and serendipity. However, the design of systems that\nleverage complex interactions between citizen scientists (members of the public\nengaged in research tasks) and computational AI methods have the potential to\nfacilitate creative exploration and chance encounters. Drawing from theories\nand literature about serendipity and computation, this article points to three\ninterrelated aspects that support the emergence of serendipity in hybrid\ncitizen science systems: the task environment; the characteristics of citizen\nscientists; and anomalies and errors.\n",
                "链接": "https://arxiv.org/abs/2205.06890"
            },
            {
                "文章ID": "59467",
                "标题": "Serious Games and AI: Challenges and Opportunities for Computational\n  Social Science",
                "作者": " Jaime Pérez,  Mario Castro,  Gregorio López",
                "发布日期": "2023-07-06",
                "摘要": "  The video game industry plays an essential role in the entertainment sphere\nof our society. However, from Monopoly to Flight Simulators, serious games have\nalso been appealing tools for learning a new language, conveying values, or\ntraining skills. Furthermore, the resurgence of Artificial Intelligence (AI)\nand data science in the last decade has created a unique opportunity since the\namount of data collected through a game is immense, as is the amount of data\nneeded to feed such AI algorithms. This paper aims to identify relevant\nresearch lines using Serious Games as a novel research tool, especially in\nComputational Social Sciences. To contextualize, we also conduct a\n(non-systematic) literature review of this field. We conclude that the synergy\nbetween games and data can foster the use of AI for good and open up new\nstrategies to empower humanity and support social research with novel\ncomputational tools. We also discuss the challenges and new opportunities that\narise from aspiring to such lofty goals.\n",
                "链接": "https://arxiv.org/abs/2302.00500"
            },
            {
                "文章ID": "80483",
                "标题": "Science in the Era of ChatGPT, Large Language Models and Generative AI:\n  Challenges for Research Ethics and How to Respond",
                "作者": " Evangelos Pournaras",
                "发布日期": "2023-08-01",
                "摘要": "  Large language models of artificial intelligence (AI), such as ChatGPT, find\nremarkable but controversial applicability in science and research. This paper\nreviews epistemological challenges, ethical and integrity risks in science\nconduct in the advent of generative AI. This is with the aim to lay new timely\nfoundations for a high-quality research ethics review. The role of AI language\nmodels as a research instrument and subject is scrutinized along with ethical\nimplications for scientists, participants and reviewers. New emerging practices\nfor research ethics review are discussed, concluding with ten recommendations\nthat shape a response for a more responsible research conduct in the era of AI.\n",
                "链接": "https://arxiv.org/abs/2305.15299"
            },
            {
                "文章ID": "26706",
                "标题": "Kwame for Science: An AI Teaching Assistant Based on Sentence-BERT for\n  Science Education in West Africa",
                "作者": " George Boateng,  Samuel John,  Andrew Glago,  Samuel Boateng,  Victor Kumbol",
                "发布日期": "2022-07-12",
                "摘要": "  Africa has a high student-to-teacher ratio which limits students' access to\nteachers. Consequently, students struggle to get answers to their questions. In\nthis work, we extended Kwame, our previous AI teaching assistant, adapted it\nfor science education, and deployed it as a web app. Kwame for Science answers\nquestions of students based on the Integrated Science subject of the West\nAfrican Senior Secondary Certificate Examination (WASSCE). Kwame for Science is\na Sentence-BERT-based question-answering web app that displays 3 paragraphs as\nanswers along with a confidence score in response to science questions.\nAdditionally, it displays the top 5 related past exam questions and their\nanswers in addition to the 3 paragraphs. Our preliminary evaluation of the\nKwame for Science with a 2.5-week real-world deployment showed a top 3 accuracy\nof 87.5% (n=56) with 190 users across 11 countries. Kwame for Science will\nenable the delivery of scalable, cost-effective, and quality remote education\nto millions of people across Africa.\n",
                "链接": "https://arxiv.org/abs/2206.13703"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下2023年关于LLM-based Agent的综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "98891",
                "标题": "RecMind: Large Language Model Powered Agent For Recommendation",
                "作者": " Yancheng Wang,  Ziyan Jiang,  Zheng Chen,  Fan Yang,  Yingxue Zhou,  Eunah Cho,  Xing Fan,  Xiaojiang Huang,  Yanbin Lu,  Yingzhen Yang",
                "发布日期": "2023-08-29",
                "摘要": "  Recent advancements in instructing Large Language Models (LLMs) to utilize\nexternal tools and execute multi-step plans have significantly enhanced their\nability to solve intricate tasks, ranging from mathematical problems to\ncreative writing. Yet, there remains a notable gap in studying the capacity of\nLLMs in responding to personalized queries such as a recommendation request. To\nbridge this gap, we have designed an LLM-powered autonomous recommender agent,\nRecMind, which is capable of providing precise personalized recommendations\nthrough careful planning, utilizing tools for obtaining external knowledge, and\nleveraging individual data. We propose a novel algorithm, Self-Inspiring, to\nimprove the planning ability of the LLM agent. At each intermediate planning\nstep, the LLM 'self-inspires' to consider all previously explored states to\nplan for next step. This mechanism greatly improves the model's ability to\ncomprehend and utilize historical planning information for recommendation. We\nevaluate RecMind's performance in various recommendation scenarios, including\nrating prediction, sequential recommendation, direct recommendation,\nexplanation generation, and review summarization. Our experiment shows that\nRecMind outperforms existing zero/few-shot LLM-based recommendation methods in\ndifferent recommendation tasks and achieves competitive performance to a recent\nmodel P5, which requires fully pre-train for the recommendation tasks.\n",
                "链接": "https://arxiv.org/abs/2308.14296"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "97862",
                "标题": "A Survey on Large Language Model based Autonomous Agents",
                "作者": " Lei Wang,  Chen Ma,  Xueyang Feng,  Zeyu Zhang,  Hao Yang,  Jingsen Zhang,  Zhiyuan Chen,  Jiakai Tang,  Xu Chen,  Yankai Lin,  Wayne Xin Zhao,  Zhewei Wei,  Ji-Rong Wen",
                "发布日期": "2023-09-08",
                "摘要": "  Autonomous agents have long been a prominent research focus in both academic\nand industry communities. Previous research in this field often focuses on\ntraining agents with limited knowledge within isolated environments, which\ndiverges significantly from human learning processes, and thus makes the agents\nhard to achieve human-like decisions. Recently, through the acquisition of vast\namounts of web knowledge, large language models (LLMs) have demonstrated\nremarkable potential in achieving human-level intelligence. This has sparked an\nupsurge in studies investigating LLM-based autonomous agents. In this paper, we\npresent a comprehensive survey of these studies, delivering a systematic review\nof the field of LLM-based autonomous agents from a holistic perspective. More\nspecifically, we first discuss the construction of LLM-based autonomous agents,\nfor which we propose a unified framework that encompasses a majority of the\nprevious work. Then, we present a comprehensive overview of the diverse\napplications of LLM-based autonomous agents in the fields of social science,\nnatural science, and engineering. Finally, we delve into the evaluation\nstrategies commonly used for LLM-based autonomous agents. Based on the previous\nstudies, we also present several challenges and future directions in this\nfield. To keep track of this field and continuously update our survey, we\nmaintain a repository of relevant references at\nhttps://github.com/Paitesanshi/LLM-Agent-Survey.\n",
                "链接": "https://arxiv.org/abs/2308.11432"
            },
            {
                "文章ID": "107902",
                "标题": "ClausewitzGPT Framework: A New Frontier in Theoretical Large Language\n  Model Enhanced Information Operations",
                "作者": " Benjamin Kereopa-Yorke",
                "发布日期": "2023-10-12",
                "摘要": "  In a digital epoch where cyberspace is the emerging nexus of geopolitical\ncontention, the melding of information operations and Large Language Models\n(LLMs) heralds a paradigm shift, replete with immense opportunities and\nintricate challenges. As tools like the Mistral 7B LLM (Mistral, 2023)\ndemocratise access to LLM capabilities (Jin et al., 2023), a vast spectrum of\nactors, from sovereign nations to rogue entities (Howard et al., 2023), find\nthemselves equipped with potent narrative-shaping instruments (Goldstein et\nal., 2023). This paper puts forth a framework for navigating this brave new\nworld in the \"ClausewitzGPT\" equation. This novel formulation not only seeks to\nquantify the risks inherent in machine-speed LLM-augmented operations but also\nunderscores the vital role of autonomous AI agents (Wang, Xie, et al., 2023).\nThese agents, embodying ethical considerations (Hendrycks et al., 2021), emerge\nas indispensable components (Wang, Ma, et al., 2023), ensuring that as we race\nforward, we do not lose sight of moral compasses and societal imperatives.\n  Mathematically underpinned and inspired by the timeless tenets of\nClausewitz's military strategy (Clausewitz, 1832), this thesis delves into the\nintricate dynamics of AI-augmented information operations. With references to\nrecent findings and research (Department of State, 2023), it highlights the\nstaggering year-on-year growth of AI information campaigns (Evgeny Pashentsev,\n2023), stressing the urgency of our current juncture. The synthesis of\nEnlightenment thinking, and Clausewitz's principles provides a foundational\nlens, emphasising the imperative of clear strategic vision, ethical\nconsiderations, and holistic understanding in the face of rapid technological\nadvancement.\n",
                "链接": "https://arxiv.org/abs/2310.07099"
            },
            {
                "文章ID": "106067",
                "标题": "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with\n  Agent Team Optimization",
                "作者": " Zijun Liu,  Yanzhe Zhang,  Peng Li,  Yang Liu,  Diyi Yang",
                "发布日期": "2023-10-04",
                "摘要": "  Large language model (LLM) agents have been shown effective on a wide range\nof tasks, and by ensembling multiple LLM agents, their performances could be\nfurther improved. Existing approaches employ a fixed set of agents to interact\nwith each other in a static architecture, which limits their generalizability\nto various tasks and requires strong human prior in designing these agents. In\nthis work, we propose to construct a strategic team of agents communicating in\na dynamic interaction architecture based on the task query. Specifically, we\nbuild a framework named Dynamic LLM-Agent Network ($\\textbf{DyLAN}$) for\nLLM-agent collaboration on complicated tasks like reasoning and code\ngeneration. DyLAN enables agents to interact for multiple rounds in a dynamic\narchitecture with inference-time agent selection and an early-stopping\nmechanism to improve performance and efficiency. We further design an automatic\nagent team optimization algorithm based on an unsupervised metric termed\n$\\textit{Agent Importance Score}$, enabling the selection of best agents based\non the contribution each agent makes. Empirically, we demonstrate that DyLAN\nperforms well in both reasoning and code generation tasks with reasonable\ncomputational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and\nHumanEval, respectively, compared to a single execution on GPT-35-turbo. On\nspecific subjects of MMLU, agent team optimization in DyLAN increases accuracy\nby up to 25.0%.\n",
                "链接": "https://arxiv.org/abs/2310.02170"
            },
            {
                "文章ID": "109250",
                "标题": "Theory of Mind for Multi-Agent Collaboration via Large Language Models",
                "作者": " Huao Li,  Yu Quan Chong,  Simon Stepputtis,  Joseph Campbell,  Dana Hughes,  Michael Lewis,  Katia Sycara",
                "发布日期": "2023-10-24",
                "摘要": "  While Large Language Models (LLMs) have demonstrated impressive\naccomplishments in both reasoning and planning, their abilities in multi-agent\ncollaborations remains largely unexplored. This study evaluates LLM-based\nagents in a multi-agent cooperative text game with Theory of Mind (ToM)\ninference tasks, comparing their performance with Multi-Agent Reinforcement\nLearning (MARL) and planning-based baselines. We observed evidence of emergent\ncollaborative behaviors and high-order Theory of Mind capabilities among\nLLM-based agents. Our results reveal limitations in LLM-based agents' planning\noptimization due to systematic failures in managing long-horizon contexts and\nhallucination about the task state. We explore the use of explicit belief state\nrepresentations to mitigate these issues, finding that it enhances task\nperformance and the accuracy of ToM inferences for LLM-based agents.\n",
                "链接": "https://arxiv.org/abs/2310.10701"
            },
            {
                "文章ID": "111753",
                "标题": "Skill-Mix: a Flexible and Expandable Family of Evaluations for AI models",
                "作者": " Dingli Yu,  Simran Kaur,  Arushi Gupta,  Jonah Brown-Cohen,  Anirudh Goyal,  Sanjeev Arora",
                "发布日期": "2023-10-27",
                "摘要": "  With LLMs shifting their role from statistical modeling of language to\nserving as general-purpose AI agents, how should LLM evaluations change?\nArguably, a key ability of an AI agent is to flexibly combine, as needed, the\nbasic skills it has learned. The capability to combine skills plays an\nimportant role in (human) pedagogy and also in a paper on emergence phenomena\n(Arora & Goyal, 2023).\n  This work introduces Skill-Mix, a new evaluation to measure ability to\ncombine skills. Using a list of $N$ skills the evaluator repeatedly picks\nrandom subsets of $k$ skills and asks the LLM to produce text combining that\nsubset of skills. Since the number of subsets grows like $N^k$, for even modest\n$k$ this evaluation will, with high probability, require the LLM to produce\ntext significantly different from any text in the training set. The paper\ndevelops a methodology for (a) designing and administering such an evaluation,\nand (b) automatic grading (plus spot-checking by humans) of the results using\nGPT-4 as well as the open LLaMA-2 70B model.\n  Administering a version of to popular chatbots gave results that, while\ngenerally in line with prior expectations, contained surprises. Sizeable\ndifferences exist among model capabilities that are not captured by their\nranking on popular LLM leaderboards (\"cramming for the leaderboard\").\nFurthermore, simple probability calculations indicate that GPT-4's reasonable\nperformance on $k=5$ is suggestive of going beyond \"stochastic parrot\" behavior\n(Bender et al., 2021), i.e., it combines skills in ways that it had not seen\nduring training.\n  We sketch how the methodology can lead to a Skill-Mix based eco-system of\nopen evaluations for AI capabilities of future models.\n",
                "链接": "https://arxiv.org/abs/2310.17567"
            },
            {
                "文章ID": "88267",
                "标题": "The 2nd Place Solution for 2023 Waymo Open Sim Agents Challenge",
                "作者": " Cheng Qian,  Di Xiu,  Minghao Tian",
                "发布日期": "2023-06-29",
                "摘要": "  In this technical report, we present the 2nd place solution of 2023 Waymo\nOpen Sim Agents Challenge (WOSAC)[4]. We propose a simple yet effective\nautoregressive method for simulating multi-agent behaviors, which is built upon\na well-known multimodal motion forecasting framework called Motion Transformer\n(MTR)[5] with postprocessing algorithms applied. Our submission named MTR+++\nachieves 0.4697 on the Realism Meta metric in 2023 WOSAC. Besides, a modified\nmodel based on MTR named MTR_E is proposed after the challenge, which has a\nbetter score 0.4911 and is ranked the 3rd on the leaderboard of WOSAC as of\nJune 25, 2023.\n",
                "链接": "https://arxiv.org/abs/2306.15914"
            },
            {
                "文章ID": "107376",
                "标题": "A Closer Look into Automatic Evaluation Using Large Language Models",
                "作者": " Cheng-Han Chiang,  Hung-yi Lee",
                "发布日期": "2023-10-10",
                "摘要": "  Using large language models (LLMs) to evaluate text quality has recently\ngained popularity. Some prior works explore the idea of using LLMs for\nevaluation, while they differ in some details of the evaluation process. In\nthis paper, we analyze LLM evaluation (Chiang and Lee, 2023) and G-Eval (Liu et\nal., 2023), and we discuss how those details in the evaluation process change\nhow well the ratings given by LLMs correlate with human ratings. We find that\nthe auto Chain-of-Thought (CoT) used in G-Eval does not always make G-Eval more\naligned with human ratings. We also show that forcing the LLM to output only a\nnumeric rating, as in G-Eval, is suboptimal. Last, we reveal that asking the\nLLM to explain its own ratings consistently improves the correlation between\nthe ChatGPT and human ratings and pushes state-of-the-art (SoTA) correlations\non two meta-evaluation datasets.\n",
                "链接": "https://arxiv.org/abs/2310.05657"
            },
            {
                "文章ID": "51962",
                "标题": "Event knowledge in large language models: the gap between the impossible\n  and the unlikely",
                "作者": " Carina Kauf,  Anna A. Ivanova,  Giulia Rambelli,  Emmanuele Chersoni,  Jingyuan Selena She,  Zawad Chowdhury,  Evelina Fedorenko,  Alessandro Lenci",
                "发布日期": "2023-10-27",
                "摘要": "  Word co-occurrence patterns in language corpora contain a surprising amount\nof conceptual knowledge. Large language models (LLMs), trained to predict words\nin context, leverage these patterns to achieve impressive performance on\ndiverse semantic tasks requiring world knowledge. An important but understudied\nquestion about LLMs' semantic abilities is whether they acquire generalized\nknowledge of common events. Here, we test whether five pre-trained LLMs (from\n2018's BERT to 2023's MPT) assign higher likelihood to plausible descriptions\nof agent-patient interactions than to minimally different implausible versions\nof the same event. Using three curated sets of minimal sentence pairs (total\nn=1,215), we found that pre-trained LLMs possess substantial event knowledge,\noutperforming other distributional language models. In particular, they almost\nalways assign higher likelihood to possible vs. impossible events (The teacher\nbought the laptop vs. The laptop bought the teacher). However, LLMs show less\nconsistent preferences for likely vs. unlikely events (The nanny tutored the\nboy vs. The boy tutored the nanny). In follow-up analyses, we show that (i) LLM\nscores are driven by both plausibility and surface-level sentence features,\n(ii) LLM scores generalize well across syntactic variants (active vs. passive\nconstructions) but less well across semantic variants (synonymous sentences),\n(iii) some LLM errors mirror human judgment ambiguity, and (iv) sentence\nplausibility serves as an organizing dimension in internal LLM representations.\nOverall, our results show that important aspects of event knowledge naturally\nemerge from distributional linguistic patterns, but also highlight a gap\nbetween representations of possible/impossible and likely/unlikely events.\n",
                "链接": "https://arxiv.org/abs/2212.01488"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "89910",
                "标题": "Comparing Apples to Apples: Generating Aspect-Aware Comparative\n  Sentences from User Reviews",
                "作者": " Jessica Echterhoff,  An Yan,  Julian McAuley",
                "发布日期": "2023-07-25",
                "摘要": "  It is time-consuming to find the best product among many similar\nalternatives. Comparative sentences can help to contrast one item from others\nin a way that highlights important features of an item that stand out. Given\nreviews of one or multiple items and relevant item features, we generate\ncomparative review sentences to aid users to find the best fit. Specifically,\nour model consists of three successive components in a transformer: (i) an item\nencoding module to encode an item for comparison, (ii) a comparison generation\nmodule that generates comparative sentences in an autoregressive manner, (iii)\na novel decoding method for user personalization. We show that our pipeline\ngenerates fluent and diverse comparative sentences. We run experiments on the\nrelevance and fidelity of our generated sentences in a human evaluation study\nand find that our algorithm creates comparative review sentences that are\nrelevant and truthful.\n",
                "链接": "https://arxiv.org/abs/2307.03691"
            },
            {
                "文章ID": "47160",
                "标题": "Decoding Neural Signals with Computational Models: A Systematic Review\n  of Invasive BMI",
                "作者": " Rezwan Firuzi,  Hamed Ahmadyani,  Mohammad Foad Abdi,  Dana Naderi,  Jahan Hassan,  Ayub Bokani",
                "发布日期": "2022-11-08",
                "摘要": "  There are significant milestones in modern human's civilization in which\nmankind stepped into a different level of life with a new spectrum of\npossibilities and comfort. From fire-lighting technology and wheeled wagons to\nwriting, electricity and the Internet, each one changed our lives dramatically.\nIn this paper, we take a deep look into the invasive Brain Machine Interface\n(BMI), an ambitious and cutting-edge technology which has the potential to be\nanother important milestone in human civilization. Not only beneficial for\npatients with severe medical conditions, the invasive BMI technology can\nsignificantly impact different technologies and almost every aspect of human's\nlife. We review the biological and engineering concepts that underpin the\nimplementation of BMI applications. There are various essential techniques that\nare necessary for making invasive BMI applications a reality. We review these\nthrough providing an analysis of (i) possible applications of invasive BMI\ntechnology, (ii) the methods and devices for detecting and decoding brain\nsignals, as well as (iii) possible options for stimulating signals into human's\nbrain. Finally, we discuss the challenges and opportunities of invasive BMI for\nfurther development in the area.\n",
                "链接": "https://arxiv.org/abs/2211.03324"
            },
            {
                "文章ID": "122597",
                "标题": "ComOM at VLSP 2023: A Dual-Stage Framework with BERTology and Unified\n  Multi-Task Instruction Tuning Model for Vietnamese Comparative Opinion Mining",
                "作者": " Dang Van Thin,  Duong Ngoc Hao,  Ngan Luu-Thuy Nguyen",
                "发布日期": "2023-12-15",
                "摘要": "  The ComOM shared task aims to extract comparative opinions from product\nreviews in Vietnamese language. There are two sub-tasks, including (1)\nComparative Sentence Identification (CSI) and (2) Comparative Element\nExtraction (CEE). The first task is to identify whether the input is a\ncomparative review, and the purpose of the second task is to extract the\nquintuplets mentioned in the comparative review. To address this task, our team\nproposes a two-stage system based on fine-tuning a BERTology model for the CSI\ntask and unified multi-task instruction tuning for the CEE task. Besides, we\napply the simple data augmentation technique to increase the size of the\ndataset for training our model in the second stage. Experimental results show\nthat our approach outperforms the other competitors and has achieved the top\nscore on the official private test.\n",
                "链接": "https://arxiv.org/abs/2312.09000"
            },
            {
                "文章ID": "112788",
                "标题": "Extracting Entities of Interest from Comparative Product Reviews",
                "作者": " Jatin Arora,  Sumit Agrawal,  Pawan Goyal,  Sayan Pathak",
                "发布日期": "2023-11-01",
                "摘要": "  This paper presents a deep learning based approach to extract product\ncomparison information out of user reviews on various e-commerce websites. Any\ncomparative product review has three major entities of information: the names\nof the products being compared, the user opinion (predicate) and the feature or\naspect under comparison. All these informing entities are dependent on each\nother and bound by the rules of the language, in the review. We observe that\ntheir inter-dependencies can be captured well using LSTMs. We evaluate our\nsystem on existing manually labeled datasets and observe out-performance over\nthe existing Semantic Role Labeling (SRL) framework popular for this task.\n",
                "链接": "https://arxiv.org/abs/2310.20274"
            },
            {
                "文章ID": "115879",
                "标题": "Speculative Contrastive Decoding",
                "作者": " Hongyi Yuan,  Keming Lu,  Fei Huang,  Zheng Yuan,  Chang Zhou",
                "发布日期": "2023-11-16",
                "摘要": "  Large language models (LLMs) have shown extraordinary performance in various\nlanguage tasks, but high computational requirements hinder their widespread\ndeployment. Speculative decoding, which uses amateur models to predict the\ngeneration of expert models, has been proposed as a way to accelerate LLM\ninference. However, speculative decoding focuses on acceleration instead of\nmaking the best use of the token distribution from amateur models. We proposed\nSpeculative Contrastive Decoding (SCD), an accelerated decoding method\nleveraging the natural contrast between expert and amateur models in\nspeculative decoding. Comprehensive evaluations on four benchmarks show that\nSCD can achieve similar acceleration factors as speculative decoding while\nfurther improving the generation quality as the contrastive decoding. The\nanalysis of token probabilities further demonstrates the compatibility between\nspeculative and contrastive decoding. Overall, SCD provides an effective\napproach to enhance the decoding quality of LLMs while saving computational\nresources.\n",
                "链接": "https://arxiv.org/abs/2311.08981"
            },
            {
                "文章ID": "109426",
                "标题": "EEG motor imagery decoding: A framework for comparative analysis with\n  channel attention mechanisms",
                "作者": " Martin Wimpff,  Leonardo Gizzi,  Jan Zerfowski,  Bin Yang",
                "发布日期": "2023-10-18",
                "摘要": "  The objective of this study is to investigate the application of various\nchannel attention mechanisms within the domain of brain-computer interface\n(BCI) for motor imagery decoding. Channel attention mechanisms can be seen as a\npowerful evolution of spatial filters traditionally used for motor imagery\ndecoding. This study systematically compares such mechanisms by integrating\nthem into a lightweight architecture framework to evaluate their impact. We\ncarefully construct a straightforward and lightweight baseline architecture\ndesigned to seamlessly integrate different channel attention mechanisms. This\napproach is contrary to previous works which only investigate one attention\nmechanism and usually build a very complex, sometimes nested architecture. Our\nframework allows us to evaluate and compare the impact of different attention\nmechanisms under the same circumstances. The easy integration of different\nchannel attention mechanisms as well as the low computational complexity\nenables us to conduct a wide range of experiments on three datasets to\nthoroughly assess the effectiveness of the baseline model and the attention\nmechanisms. Our experiments demonstrate the strength and generalizability of\nour architecture framework as well as how channel attention mechanisms can\nimprove the performance while maintaining the small memory footprint and low\ncomputational complexity of our baseline architecture. Our architecture\nemphasizes simplicity, offering easy integration of channel attention\nmechanisms, while maintaining a high degree of generalizability across\ndatasets, making it a versatile and efficient solution for EEG motor imagery\ndecoding within brain-computer interfaces.\n",
                "链接": "https://arxiv.org/abs/2310.11198"
            },
            {
                "文章ID": "117508",
                "标题": "A Comparative Analysis of Supportive Navigation on Movie Recommenders",
                "作者": " Mohammad Sualeh Ali,  Muhammed Maaz Tariq,  Alina Ahmed,  Abdul Razaque Soomro,  Danysh Syed",
                "发布日期": "2023-11-23",
                "摘要": "  This literature review covers the research and thought process that went into\nmaking a solution for the infinite scrolling problem faced in streaming\nservices such as Netflix. Using the data collected, we have come to the\nconclusion that an alternate layout can somewhat alleviate the problems it\ntakes in navigating a list of movies. We also found out by a comparative\nanalysis that some layouts, the circular one in particular, is advantageous in\ncertain settings making it an ideal candidate for a movie recommender system.\n",
                "链接": "https://arxiv.org/abs/2311.13494"
            },
            {
                "文章ID": "24084",
                "标题": "Comparative Snippet Generation",
                "作者": " Saurabh Jain,  Yisong Miao,  Min-Yen Kan",
                "发布日期": "2022-06-14",
                "摘要": "  We model product reviews to generate comparative responses consisting of\npositive and negative experiences regarding the product. Specifically, we\ngenerate a single-sentence, comparative response from a given positive and a\nnegative opinion. We contribute the first dataset for this task of Comparative\nSnippet Generation from contrasting opinions regarding a product, and a\nperformance analysis of a pre-trained BERT model to generate such snippets.\n",
                "链接": "https://arxiv.org/abs/2206.05473"
            },
            {
                "文章ID": "90598",
                "标题": "Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM\n  Decoding",
                "作者": " Seongjun Yang,  Gibbeum Lee,  Jaewoong Cho,  Dimitris Papailiopoulos,  Kangwook Lee",
                "发布日期": "2023-07-13",
                "摘要": "  This paper presents \"Predictive Pipelined Decoding (PPD),\" an approach that\nspeeds up greedy decoding in Large Language Models (LLMs) while maintaining the\nexact same output as the original decoding. Unlike conventional strategies, PPD\nemploys additional compute resources to parallelize the initiation of\nsubsequent token decoding during the current token decoding. This innovative\nmethod reduces decoding latency and reshapes the understanding of trade-offs in\nLLM decoding strategies. We have developed a theoretical framework that allows\nus to analyze the trade-off between computation and latency. Using this\nframework, we can analytically estimate the potential reduction in latency\nassociated with our proposed method, achieved through the assessment of the\nmatch rate, represented as p_correct. The results demonstrate that the use of\nextra computational resources has the potential to accelerate LLM greedy\ndecoding.\n",
                "链接": "https://arxiv.org/abs/2307.05908"
            },
            {
                "文章ID": "91982",
                "标题": "Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding\n  (Survey)",
                "作者": " Subba Reddy Oota,  Manish Gupta,  Raju S. Bapi,  Gael Jobard,  Frederic Alexandre,  Xavier Hinaut",
                "发布日期": "2023-07-21",
                "摘要": "  How does the brain represent different modes of information? Can we design a\nsystem that automatically understands what the user is thinking? Such questions\ncan be answered by studying brain recordings like functional magnetic resonance\nimaging (fMRI). As a first step, the neuroscience community has contributed\nseveral large cognitive neuroscience datasets related to passive\nreading/listening/viewing of concept words, narratives, pictures and movies.\nEncoding and decoding models using these datasets have also been proposed in\nthe past two decades. These models serve as additional tools for basic research\nin cognitive science and neuroscience. Encoding models aim at generating fMRI\nbrain representations given a stimulus automatically. They have several\npractical applications in evaluating and diagnosing neurological conditions and\nthus also help design therapies for brain damage. Decoding models solve the\ninverse problem of reconstructing the stimuli given the fMRI. They are useful\nfor designing brain-machine or brain-computer interfaces. Inspired by the\neffectiveness of deep learning models for natural language processing, computer\nvision, and speech, recently several neural encoding and decoding models have\nbeen proposed. In this survey, we will first discuss popular representations of\nlanguage, vision and speech stimuli, and present a summary of neuroscience\ndatasets. Further, we will review popular deep learning based encoding and\ndecoding architectures and note their benefits and limitations. Finally, we\nwill conclude with a brief summary and discussion about future trends. Given\nthe large amount of recently published work in the `computational cognitive\nneuroscience' community, we believe that this survey nicely organizes the\nplethora of work and presents it as a coherent story.\n",
                "链接": "https://arxiv.org/abs/2307.10246"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近三个月有关语言模型rlhf的arxiv上的全部文章。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大模型结合树搜索方法进行推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "79447",
                "标题": "Enhance Reasoning Ability of Visual-Language Models via Large Language\n  Models",
                "作者": " Yueting Yang,  Xintong Zhang,  Wenjuan Han",
                "发布日期": "2023-05-23",
                "摘要": "  Pre-trained visual language models (VLM) have shown excellent performance in\nimage caption tasks. However, it sometimes shows insufficient reasoning\nability. In contrast, large language models (LLMs) emerge with powerful\nreasoning capabilities. Therefore, we propose a method called TReE, which\ntransfers the reasoning ability of a large language model to a visual language\nmodel in zero-shot scenarios. TReE contains three stages: observation,\nthinking, and re-thinking. Observation stage indicates that VLM obtains the\noverall information of the relative image. Thinking stage combines the image\ninformation and task description as the prompt of the LLM, inference with the\nrationals. Re-Thinking stage learns from rationale and then inference the final\nresult through VLM.\n",
                "链接": "https://arxiv.org/abs/2305.13267"
            },
            {
                "文章ID": "97885",
                "标题": "Composed Image Retrieval using Contrastive Learning and Task-oriented\n  CLIP-based Features",
                "作者": " Alberto Baldrati,  Marco Bertini,  Tiberio Uricchio,  Alberto del Bimbo",
                "发布日期": "2023-08-23",
                "摘要": "  Given a query composed of a reference image and a relative caption, the\nComposed Image Retrieval goal is to retrieve images visually similar to the\nreference one that integrates the modifications expressed by the caption. Given\nthat recent research has demonstrated the efficacy of large-scale vision and\nlanguage pre-trained (VLP) models in various tasks, we rely on features from\nthe OpenAI CLIP model to tackle the considered task. We initially perform a\ntask-oriented fine-tuning of both CLIP encoders using the element-wise sum of\nvisual and textual features. Then, in the second stage, we train a Combiner\nnetwork that learns to combine the image-text features integrating the bimodal\ninformation and providing combined features used to perform the retrieval. We\nuse contrastive learning in both stages of training. Starting from the bare\nCLIP features as a baseline, experimental results show that the task-oriented\nfine-tuning and the carefully crafted Combiner network are highly effective and\noutperform more complex state-of-the-art approaches on FashionIQ and CIRR, two\npopular and challenging datasets for composed image retrieval. Code and\npre-trained models are available at https://github.com/ABaldrati/CLIP4Cir\n",
                "链接": "https://arxiv.org/abs/2308.11485"
            },
            {
                "文章ID": "6131",
                "标题": "Rethinking Pareto Frontier for Performance Evaluation of Deep Neural\n  Networks",
                "作者": " Vahid Partovi Nia,  Alireza Ghaffari,  Mahdi Zolnouri,  Yvon Savaria",
                "发布日期": "2022-09-23",
                "摘要": "  Performance optimization of deep learning models is conducted either manually\nor through automatic architecture search, or a combination of both. On the\nother hand, their performance strongly depends on the target hardware and how\nsuccessfully the models were trained. We propose to use a multi-dimensional\nPareto frontier to re-define the efficiency measure of candidate deep learning\nmodels, where several variables such as training cost, inference latency, and\naccuracy play a relative role in defining a dominant model. Furthermore, a\nrandom version of the multi-dimensional Pareto frontier is introduced to\nmitigate the uncertainty of accuracy, latency, and throughput of deep learning\nmodels in different experimental setups. These two complementary methods can be\ncombined to perform objective benchmarking of deep learning models. Our\nproposed method is applied to a wide range of deep image classification models\ntrained on ImageNet data. Our method combines competing variables with\nstochastic nature in a single relative efficiency measure. This allows ranking\ndeep learning models that run efficiently on different hardware, and combining\ninference efficiency with training efficiency objectively.\n",
                "链接": "https://arxiv.org/abs/2202.09275"
            },
            {
                "文章ID": "99341",
                "标题": "Efficient and Explainable Graph Neural Architecture Search via\n  Monte-Carlo Tree Search",
                "作者": " Yuya Sasaki",
                "发布日期": "2023-09-04",
                "摘要": "  Graph neural networks (GNNs) are powerful tools for performing data science\ntasks in various domains. Although we use GNNs in wide application scenarios,\nit is a laborious task for researchers and practitioners to design/select\noptimal GNN architectures in diverse graphs. To save human efforts and\ncomputational costs, graph neural architecture search (Graph NAS) has been used\nto search for a sub-optimal GNN architecture that combines existing components.\nHowever, there are no existing Graph NAS methods that satisfy explainability,\nefficiency, and adaptability to various graphs. Therefore, we propose an\nefficient and explainable Graph NAS method, called ExGNAS, which consists of\n(i) a simple search space that can adapt to various graphs and (ii) a search\nalgorithm that makes the decision process explainable. The search space\nincludes only fundamental functions that can handle homophilic and heterophilic\ngraphs. The search algorithm efficiently searches for the best GNN architecture\nvia Monte-Carlo tree search without neural models. The combination of our\nsearch space and algorithm achieves finding accurate GNN models and the\nimportant functions within the search space. We comprehensively evaluate our\nmethod compared with twelve hand-crafted GNN architectures and three Graph NAS\nmethods in four graphs. Our experimental results show that ExGNAS increases AUC\nup to 3.6 and reduces run time up to 78\\% compared with the state-of-the-art\nGraph NAS methods. Furthermore, we show ExGNAS is effective in analyzing the\ndifference between GNN architectures in homophilic and heterophilic graphs.\n",
                "链接": "https://arxiv.org/abs/2308.15734"
            },
            {
                "文章ID": "7261",
                "标题": "Content-Variant Reference Image Quality Assessment via Knowledge\n  Distillation",
                "作者": " Guanghao Yin,  Wei Wang,  Zehuan Yuan,  Chuchu Han,  Wei Ji,  Shouqian Sun,  Changhu Wang",
                "发布日期": "2022-03-01",
                "摘要": "  Generally, humans are more skilled at perceiving differences between\nhigh-quality (HQ) and low-quality (LQ) images than directly judging the quality\nof a single LQ image. This situation also applies to image quality assessment\n(IQA). Although recent no-reference (NR-IQA) methods have made great progress\nto predict image quality free from the reference image, they still have the\npotential to achieve better performance since HQ image information is not fully\nexploited. In contrast, full-reference (FR-IQA) methods tend to provide more\nreliable quality evaluation, but its practicability is affected by the\nrequirement for pixel-level aligned reference images. To address this, we\nfirstly propose the content-variant reference method via knowledge distillation\n(CVRKD-IQA). Specifically, we use non-aligned reference (NAR) images to\nintroduce various prior distributions of high-quality images. The comparisons\nof distribution differences between HQ and LQ images can help our model better\nassess the image quality. Further, the knowledge distillation transfers more\nHQ-LQ distribution difference information from the FR-teacher to the\nNAR-student and stabilizing CVRKD-IQA performance. Moreover, to fully mine the\nlocal-global combined information, while achieving faster inference speed, our\nmodel directly processes multiple image patches from the input with the\nMLP-mixer. Cross-dataset experiments verify that our model can outperform all\nNAR/NR-IQA SOTAs, even reach comparable performance with FR-IQA methods on some\noccasions. Since the content-variant and non-aligned reference HQ images are\neasy to obtain, our model can support more IQA applications with its relative\nrobustness to content variations. Our code and more detailed elaborations of\nsupplements are available: https://github.com/guanghaoyin/CVRKD-IQA.\n",
                "链接": "https://arxiv.org/abs/2202.13123"
            },
            {
                "文章ID": "71064",
                "标题": "PopulAtion Parameter Averaging (PAPA)",
                "作者": " Alexia Jolicoeur-Martineau,  Emy Gervais,  Kilian Fatras,  Yan Zhang,  Simon Lacoste-Julien",
                "发布日期": "2023-05-25",
                "摘要": "  Ensemble methods combine the predictions of multiple models to improve\nperformance, but they require significantly higher computation costs at\ninference time. To avoid these costs, multiple neural networks can be combined\ninto one by averaging their weights. However, this usually performs\nsignificantly worse than ensembling. Weight averaging is only beneficial when\ndifferent enough to benefit from combining them, but similar enough to average\nwell. Based on this idea, we propose PopulAtion Parameter Averaging (PAPA): a\nmethod that combines the generality of ensembling with the efficiency of weight\naveraging. PAPA leverages a population of diverse models (trained on different\ndata orders, augmentations, and regularizations) while slowly pushing the\nweights of the networks toward the population average of the weights. PAPA\nreduces the performance gap between averaging and ensembling, increasing the\naverage accuracy of a population of models by up to 0.8% on CIFAR-10, 1.9% on\nCIFAR-100, and 1.6% on ImageNet when compared to training independent\n(non-averaged) models.\n",
                "链接": "https://arxiv.org/abs/2304.03094"
            },
            {
                "文章ID": "121309",
                "标题": "Consistency Models for Scalable and Fast Simulation-Based Inference",
                "作者": " Marvin Schmitt,  Valentin Pratz,  Ullrich Köthe,  Paul-Christian Bürkner,  Stefan T Radev",
                "发布日期": "2023-12-12",
                "摘要": "  Simulation-based inference (SBI) is constantly in search of more expressive\nalgorithms for accurately inferring the parameters of complex models from noisy\ndata. We present consistency models for neural posterior estimation (CMPE), a\nnew free-form conditional sampler for scalable, fast, and amortized SBI with\ngenerative neural networks. CMPE combines the advantages of normalizing flows\nand flow matching methods into a single generative architecture: It essentially\ndistills a continuous probability flow and enables rapid few-shot inference\nwith an unconstrained architecture that can be tailored to the structure of the\nestimation problem. Our empirical evaluation demonstrates that CMPE not only\noutperforms current state-of-the-art algorithms on three hard low-dimensional\nproblems, but also achieves competitive performance in a high-dimensional\nBayesian denoising experiment and in estimating a computationally demanding\nmulti-scale model of tumor spheroid growth.\n",
                "链接": "https://arxiv.org/abs/2312.05440"
            },
            {
                "文章ID": "104860",
                "标题": "Augmenting transformers with recursively composed multi-grained\n  representations",
                "作者": " Xiang Hu,  Qingyang Zhu,  Kewei Tu,  Wei Wu",
                "发布日期": "2023-09-29",
                "摘要": "  We present ReCAT, a recursive composition augmented Transformer that is able\nto explicitly model hierarchical syntactic structures of raw texts without\nrelying on gold trees during both learning and inference. Existing research\nalong this line restricts data to follow a hierarchical tree structure and thus\nlacks inter-span communications. To overcome the problem, we propose a novel\ncontextual inside-outside (CIO) layer that learns contextualized\nrepresentations of spans through bottom-up and top-down passes, where a\nbottom-up pass forms representations of high-level spans by composing low-level\nspans, while a top-down pass combines information inside and outside a span. By\nstacking several CIO layers between the embedding layer and the attention\nlayers in Transformer, the ReCAT model can perform both deep intra-span and\ndeep inter-span interactions, and thus generate multi-grained representations\nfully contextualized with other spans. Moreover, the CIO layers can be jointly\npre-trained with Transformers, making ReCAT enjoy scaling ability, strong\nperformance, and interpretability at the same time. We conduct experiments on\nvarious sentence-level and span-level tasks. Evaluation results indicate that\nReCAT can significantly outperform vanilla Transformer models on all span-level\ntasks and baselines that combine recursive networks with Transformers on\nnatural language inference tasks. More interestingly, the hierarchical\nstructures induced by ReCAT exhibit strong consistency with human-annotated\nsyntactic trees, indicating good interpretability brought by the CIO layers.\n",
                "链接": "https://arxiv.org/abs/2309.16319"
            },
            {
                "文章ID": "105289",
                "标题": "SocREval: Large Language Models with the Socratic Method for\n  Reference-Free Reasoning Evaluation",
                "作者": " Hangfeng He,  Hongming Zhang,  Dan Roth",
                "发布日期": "2023-10-03",
                "摘要": "  To comprehensively assess the capacity of current models for complex\nreasoning, it is crucial to assess their step-by-step reasoning in a scalable\nmanner. Established reference-based evaluation metrics rely on human-annotated\nreasoning chains to assess the model-derived chains. However, such\n``gold-standard'' human-written reasoning chains may not be unique and their\nacquisition is often labor-intensive. Existing reference-free reasoning metrics\neliminate the need for human-crafted reasoning chains as references, but they\ntypically require fine-tuning on datasets with human-derived reasoning chains,\nwhich complicates the process and raises concerns regarding generalizability\nacross diverse datasets. To address these challenges, we harness GPT-4 to\nautomatically evaluate reasoning chain quality, obviating the need for\nhuman-crafted references. Leveraging the Socratic method, we devise tailored\nprompts to enhance reference-free reasoning evaluation, which we term SocREval\n(Socratic method for Reasoning Evaluation). Empirical results from four human\nannotated datasets reveal that SocREval significantly improves GPT-4's\nperformance, surpassing existing reference-free and reference-based reasoning\nevaluation metrics. Beyond its demonstrated efficacy, our proposed framework,\nlarge language models (LLMs) with the Socratic method, proves to be both\ncost-efficient and robust to prompt writing and example selection, as\nsubstantiated by our in-depth analysis.\n",
                "链接": "https://arxiv.org/abs/2310.00074"
            },
            {
                "文章ID": "105172",
                "标题": "Alphazero-like Tree-Search can Guide Large Language Model Decoding and\n  Training",
                "作者": " Xidong Feng,  Ziyu Wan,  Muning Wen,  Ying Wen,  Weinan Zhang,  Jun Wang",
                "发布日期": "2023-10-02",
                "摘要": "  Large language models (LLMs) typically employ sampling or beam search,\naccompanied by prompts such as Chain-of-Thought (CoT), to boost reasoning and\ndecoding ability. Recent work like Tree-of-Thought (ToT) and Reasoning via\nPlanning (RAP) aim to augment the reasoning capabilities of LLMs by utilizing\ntree-search algorithms to guide multi-step reasoning. These methods mainly\nfocus on LLMs' reasoning ability during inference and heavily rely on\nhuman-designed prompts to activate LLM as a value function, which lacks general\napplicability and scalability. To address these limitations, we present an\nAlphaZero-like tree-search framework for LLMs (termed TS-LLM), systematically\nillustrating how tree-search with a learned value function can guide LLMs'\ndecoding ability. TS-LLM distinguishes itself in two key ways: (1) Leveraging a\nlearned value function, our approach can be generally applied to different\ntasks beyond reasoning (such as RLHF alignment), and LLMs of any size, without\nprompting advanced, large-scale models. (2) It can guide LLM's decoding during\nboth inference and training. Empirical evaluations across reasoning, planning,\nand RLHF alignment tasks validate the effectiveness of TS-LLM, even on trees\nwith a depth of 64.\n",
                "链接": "https://arxiv.org/abs/2309.17179"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于通过prompt经验性研究大语言模型行为的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "63456",
                "标题": "Robot Behavior-Tree-Based Task Generation with Large Language Models",
                "作者": " Yue Cao,  C. S. George Lee",
                "发布日期": "2023-02-28",
                "摘要": "  Nowadays, the behavior tree is gaining popularity as a representation for\nrobot tasks due to its modularity and reusability. Designing behavior-tree\ntasks manually is time-consuming for robot end-users, thus there is a need for\ninvestigating automatic behavior-tree-based task generation. Prior\nbehavior-tree-based task generation approaches focus on fixed primitive tasks\nand lack generalizability to new task domains. To cope with this issue, we\npropose a novel behavior-tree-based task generation approach that utilizes\nstate-of-the-art large language models. We propose a Phase-Step prompt design\nthat enables a hierarchical-structured robot task generation and further\nintegrate it with behavior-tree-embedding-based search to set up the\nappropriate prompt. In this way, we enable an automatic and cross-domain\nbehavior-tree task generation. Our behavior-tree-based task generation approach\ndoes not require a set of pre-defined primitive tasks. End-users only need to\ndescribe an abstract desired task and our proposed approach can swiftly\ngenerate the corresponding behavior tree. A full-process case study is provided\nto demonstrate our proposed approach. An ablation study is conducted to\nevaluate the effectiveness of our Phase-Step prompts. Assessment on Phase-Step\nprompts and the limitation of large language models are presented and\ndiscussed.\n",
                "链接": "https://arxiv.org/abs/2302.12927"
            },
            {
                "文章ID": "111116",
                "标题": "Unnatural language processing: How do language models handle\n  machine-generated prompts?",
                "作者": " Corentin Kervadec,  Francesca Franzon,  Marco Baroni",
                "发布日期": "2023-10-25",
                "摘要": "  Language model prompt optimization research has shown that semantically and\ngrammatically well-formed manually crafted prompts are routinely outperformed\nby automatically generated token sequences with no apparent meaning or\nsyntactic structure, including sequences of vectors from a model's embedding\nspace. We use machine-generated prompts to probe how models respond to input\nthat is not composed of natural language expressions. We study the behavior of\nmodels of different sizes in multiple semantic tasks in response to both\ncontinuous and discrete machine-generated prompts, and compare it to the\nbehavior in response to human-generated natural-language prompts. Even when\nproducing a similar output, machine-generated and human prompts trigger\ndifferent response patterns through the network processing pathways, including\ndifferent perplexities, different attention and output entropy distributions,\nand different unit activation profiles. We provide preliminary insight into the\nnature of the units activated by different prompt types, suggesting that only\nnatural language prompts recruit a genuinely linguistic circuit.\n",
                "链接": "https://arxiv.org/abs/2310.15829"
            },
            {
                "文章ID": "119665",
                "标题": "Large Language Models for Travel Behavior Prediction",
                "作者": " Baichuan Mo,  Hanyong Xu,  Dingyi Zhuang,  Ruoyun Ma,  Xiaotong Guo,  Jinhua Zhao",
                "发布日期": "2023-12-05",
                "摘要": "  Travel behavior prediction is a fundamental task in transportation demand\nmanagement. The conventional methods for travel behavior prediction rely on\nnumerical data to construct mathematical models and calibrate model parameters\nto represent human preferences. Recent advancement in large language models\n(LLMs) has shown great reasoning abilities to solve complex problems. In this\nstudy, we propose to use LLMs to predict travel behavior with prompt\nengineering without data-based parameter learning. Specifically, we carefully\ndesign our prompts that include 1) task description, 2) travel characteristics,\n3) individual attributes, and 4) guides of thinking with domain knowledge, and\nask the LLMs to predict an individual's travel behavior and explain the\nresults. We select the travel mode choice task as a case study. Results show\nthat, though no training samples are provided, LLM-based predictions have\ncompetitive accuracy and F1-score as canonical supervised learning methods such\nas multinomial logit, random forest, and neural networks. LLMs can also output\nreasons that support their prediction. However, though in most of the cases,\nthe output explanations are reasonable, we still observe cases that violate\nlogic or with hallucinations.\n",
                "链接": "https://arxiv.org/abs/2312.00819"
            },
            {
                "文章ID": "115250",
                "标题": "On the Discussion of Large Language Models: Symmetry of Agents and\n  Interplay with Prompts",
                "作者": " Qineng Wang,  Zihao Wang,  Ying Su,  Yangqiu Song",
                "发布日期": "2023-11-14",
                "摘要": "  Two ways has been discussed to unlock the reasoning capability of a large\nlanguage model. The first one is prompt engineering and the second one is to\ncombine the multiple inferences of large language models, or the multi-agent\ndiscussion. Theoretically, this paper justifies the multi-agent discussion\nmechanisms from the symmetry of agents. Empirically, this paper reports the\nempirical results of the interplay of prompts and discussion mechanisms,\nrevealing the empirical state-of-the-art performance of complex multi-agent\nmechanisms can be approached by carefully developed prompt engineering. This\npaper also proposes a scalable discussion mechanism based on conquer and merge,\nproviding a simple multi-agent discussion solution with simple prompts but\nstate-of-the-art performance.\n",
                "链接": "https://arxiv.org/abs/2311.07076"
            },
            {
                "文章ID": "84328",
                "标题": "PromptBench: Towards Evaluating the Robustness of Large Language Models\n  on Adversarial Prompts",
                "作者": " Kaijie Zhu,  Jindong Wang,  Jiaheng Zhou,  Zichen Wang,  Hao Chen,  Yidong Wang,  Linyi Yang,  Wei Ye,  Yue Zhang,  Neil Zhenqiang Gong,  Xing Xie",
                "发布日期": "2023-10-19",
                "摘要": "  The increasing reliance on Large Language Models (LLMs) across academia and\nindustry necessitates a comprehensive understanding of their robustness to\nprompts. In response to this vital need, we introduce PromptBench, a robustness\nbenchmark designed to measure LLMs' resilience to adversarial prompts. This\nstudy uses a plethora of adversarial textual attacks targeting prompts across\nmultiple levels: character, word, sentence, and semantic. The adversarial\nprompts, crafted to mimic plausible user errors like typos or synonyms, aim to\nevaluate how slight deviations can affect LLM outcomes while maintaining\nsemantic integrity. These prompts are then employed in diverse tasks, such as\nsentiment analysis, natural language inference, reading comprehension, machine\ntranslation, and math problem-solving. Our study generates 4788 adversarial\nprompts, meticulously evaluated over 8 tasks and 13 datasets. Our findings\ndemonstrate that contemporary LLMs are not robust to adversarial prompts.\nFurthermore, we present comprehensive analysis to understand the mystery behind\nprompt robustness and its transferability. We then offer insightful robustness\nanalysis and pragmatic recommendations for prompt composition, beneficial to\nboth researchers and everyday users. Code is available at:\nhttps://github.com/microsoft/promptbench.\n",
                "链接": "https://arxiv.org/abs/2306.04528"
            },
            {
                "文章ID": "102889",
                "标题": "Explaining Agent Behavior with Large Language Models",
                "作者": " Xijia Zhang,  Yue Guo,  Simon Stepputtis,  Katia Sycara,  Joseph Campbell",
                "发布日期": "2023-09-20",
                "摘要": "  Intelligent agents such as robots are increasingly deployed in real-world,\nsafety-critical settings. It is vital that these agents are able to explain the\nreasoning behind their decisions to human counterparts, however, their behavior\nis often produced by uninterpretable models such as deep neural networks. We\npropose an approach to generate natural language explanations for an agent's\nbehavior based only on observations of states and actions, agnostic to the\nunderlying model representation. We show how a compact representation of the\nagent's behavior can be learned and used to produce plausible explanations with\nminimal hallucination while affording user interaction with a pre-trained large\nlanguage model. Through user studies and empirical experiments, we show that\nour approach generates explanations as helpful as those generated by a human\ndomain expert while enabling beneficial interactions such as clarification and\ncounterfactual queries.\n",
                "链接": "https://arxiv.org/abs/2309.10346"
            },
            {
                "文章ID": "89162",
                "标题": "Prompt Middleware: Mapping Prompts for Large Language Models to UI\n  Affordances",
                "作者": " Stephen MacNeil,  Andrew Tran,  Joanne Kim,  Ziheng Huang,  Seth Bernstein,  Dan Mogil",
                "发布日期": "2023-07-04",
                "摘要": "  To help users do complex work, researchers have developed techniques to\nintegrate AI and human intelligence into user interfaces (UIs). With the recent\nintroduction of large language models (LLMs), which can generate text in\nresponse to a natural language prompt, there are new opportunities to consider\nhow to integrate LLMs into UIs. We present Prompt Middleware, a framework for\ngenerating prompts for LLMs based on UI affordances. These include prompts that\nare predefined by experts (static prompts), generated from templates with\nfill-in options in the UI (template-based prompts), or created from scratch\n(free-form prompts). We demonstrate this framework with FeedbackBuffet, a\nwriting assistant that automatically generates feedback based on a user's text\ninput. Inspired by prior research showing how templates can help non-experts\nperform more like experts, FeedbackBuffet leverages template-based prompt\nmiddleware to enable feedback seekers to specify the types of feedback they\nwant to receive as options in a UI. These options are composed using a template\nto form a feedback request prompt to GPT-3. We conclude with a discussion about\nhow Prompt Middleware can help developers integrate LLMs into UIs.\n",
                "链接": "https://arxiv.org/abs/2307.01142"
            },
            {
                "文章ID": "117222",
                "标题": "Can Large Language Models Understand Content and Propagation for\n  Misinformation Detection: An Empirical Study",
                "作者": " Mengyang Chen,  Lingwei Wei,  Han Cao,  Wei Zhou,  Songlin Hu",
                "发布日期": "2023-11-22",
                "摘要": "  Large Language Models (LLMs) have garnered significant attention for their\npowerful ability in natural language understanding and reasoning. In this\npaper, we present a comprehensive empirical study to explore the performance of\nLLMs on misinformation detection tasks. This study stands as the pioneering\ninvestigation into the understanding capabilities of multiple LLMs regarding\nboth content and propagation across social media platforms. Our empirical\nstudies on five misinformation detection datasets show that LLMs with diverse\nprompts achieve comparable performance in text-based misinformation detection\nbut exhibit notably constrained capabilities in comprehending propagation\nstructure compared to existing models in propagation-based misinformation\ndetection. Besides, we further design four instruction-tuned strategies to\nenhance LLMs for both content and propagation-based misinformation detection.\nThese strategies boost LLMs to actively learn effective features from multiple\ninstances or hard instances, and eliminate irrelevant propagation structures,\nthereby achieving better detection performance. Extensive experiments further\ndemonstrate LLMs would play a better capacity in content and propagation\nstructure under these proposed strategies and achieve promising detection\nperformance. These findings highlight the potential ability of LLMs to detect\nmisinformation.\n",
                "链接": "https://arxiv.org/abs/2311.12699"
            },
            {
                "文章ID": "102110",
                "标题": "An Empirical Evaluation of Prompting Strategies for Large Language\n  Models in Zero-Shot Clinical Natural Language Processing",
                "作者": " Sonish Sivarajkumar,  Mark Kelley,  Alyssa Samolyk-Mazzanti,  Shyam Visweswaran,  Yanshan Wang",
                "发布日期": "2023-09-18",
                "摘要": "  Large language models (LLMs) have shown remarkable capabilities in Natural\nLanguage Processing (NLP), especially in domains where labeled data is scarce\nor expensive, such as clinical domain. However, to unlock the clinical\nknowledge hidden in these LLMs, we need to design effective prompts that can\nguide them to perform specific clinical NLP tasks without any task-specific\ntraining data. This is known as in-context learning, which is an art and\nscience that requires understanding the strengths and weaknesses of different\nLLMs and prompt engineering approaches. In this paper, we present a\ncomprehensive and systematic experimental study on prompt engineering for five\nclinical NLP tasks: Clinical Sense Disambiguation, Biomedical Evidence\nExtraction, Coreference Resolution, Medication Status Extraction, and\nMedication Attribute Extraction. We assessed the prompts proposed in recent\nliterature, including simple prefix, simple cloze, chain of thought, and\nanticipatory prompts, and introduced two new types of prompts, namely heuristic\nprompting and ensemble prompting. We evaluated the performance of these prompts\non three state-of-the-art LLMs: GPT-3.5, BARD, and LLAMA2. We also contrasted\nzero-shot prompting with few-shot prompting, and provide novel insights and\nguidelines for prompt engineering for LLMs in clinical NLP. To the best of our\nknowledge, this is one of the first works on the empirical evaluation of\ndifferent prompt engineering approaches for clinical NLP in this era of\ngenerative AI, and we hope that it will inspire and inform future research in\nthis area.\n",
                "链接": "https://arxiv.org/abs/2309.08008"
            },
            {
                "文章ID": "58117",
                "标题": "Large Language Models as Fiduciaries: A Case Study Toward Robustly\n  Communicating With Artificial Intelligence Through Legal Standards",
                "作者": " John J. Nay",
                "发布日期": "2023-01-31",
                "摘要": "  Artificial Intelligence (AI) is taking on increasingly autonomous roles,\ne.g., browsing the web as a research assistant and managing money. But\nspecifying goals and restrictions for AI behavior is difficult. Similar to how\nparties to a legal contract cannot foresee every potential \"if-then\"\ncontingency of their future relationship, we cannot specify desired AI behavior\nfor all circumstances. Legal standards facilitate robust communication of\ninherently vague and underspecified goals. Instructions (in the case of\nlanguage models, \"prompts\") that employ legal standards will allow AI agents to\ndevelop shared understandings of the spirit of a directive that generalize\nexpectations regarding acceptable actions to take in unspecified states of the\nworld. Standards have built-in context that is lacking from other goal\nspecification languages, such as plain language and programming languages.\nThrough an empirical study on thousands of evaluation labels we constructed\nfrom U.S. court opinions, we demonstrate that large language models (LLMs) are\nbeginning to exhibit an \"understanding\" of one of the most relevant legal\nstandards for AI agents: fiduciary obligations. Performance comparisons across\nmodels suggest that, as LLMs continue to exhibit improved core capabilities,\ntheir legal standards understanding will also continue to improve. OpenAI's\nlatest LLM has 78% accuracy on our data, their previous release has 73%\naccuracy, and a model from their 2020 GPT-3 paper has 27% accuracy (worse than\nrandom). Our research is an initial step toward a framework for evaluating AI\nunderstanding of legal standards more broadly, and for conducting reinforcement\nlearning with legal feedback (RLLF).\n",
                "链接": "https://arxiv.org/abs/2301.10095"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近两年关于语言模型奖励建模评估的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "21453",
                "标题": "Quark: Controllable Text Generation with Reinforced Unlearning",
                "作者": " Ximing Lu,  Sean Welleck,  Jack Hessel,  Liwei Jiang,  Lianhui Qin,  Peter West,  Prithviraj Ammanabrolu,  Yejin Choi",
                "发布日期": "2022-11-18",
                "摘要": "  Large-scale language models often learn behaviors that are misaligned with\nuser expectations. Generated text may contain offensive or toxic language,\ncontain significant repetition, or be of a different sentiment than desired by\nthe user. We consider the task of unlearning these misalignments by fine-tuning\nthe language model on signals of what not to do. We introduce Quantized Reward\nKonditioning (Quark), an algorithm for optimizing a reward function that\nquantifies an (un)wanted property, while not straying too far from the original\nmodel. Quark alternates between (i) collecting samples with the current\nlanguage model, (ii) sorting them into quantiles based on reward, with each\nquantile identified by a reward token prepended to the language model's input,\nand (iii) using a standard language modeling loss on samples from each quantile\nconditioned on its reward token, while remaining nearby the original language\nmodel via a KL-divergence penalty. By conditioning on a high-reward token at\ngeneration time, the model generates text that exhibits less of the unwanted\nproperty. For unlearning toxicity, negative sentiment, and repetition, our\nexperiments show that Quark outperforms both strong baselines and\nstate-of-the-art reinforcement learning methods like PPO (Schulman et al.\n2017), while relying only on standard language modeling primitives.\n",
                "链接": "https://arxiv.org/abs/2205.13636"
            },
            {
                "文章ID": "114857",
                "标题": "Let's Reinforce Step by Step",
                "作者": " Sarah Pan,  Vladislav Lialin,  Sherin Muckatira,  Anna Rumshisky",
                "发布日期": "2023-11-13",
                "摘要": "  While recent advances have boosted LM proficiency in linguistic benchmarks,\nLMs consistently struggle to reason correctly on complex tasks like\nmathematics. We turn to Reinforcement Learning from Human Feedback (RLHF) as a\nmethod with which to shape model reasoning processes. In particular, we explore\ntwo reward schemes, outcome-supervised reward models (ORMs) and\nprocess-supervised reward models (PRMs), to optimize for logical reasoning. Our\nresults show that the fine-grained reward provided by PRM-based methods\nenhances accuracy on simple mathematical reasoning (GSM8K) while, unexpectedly,\nreducing performance in complex tasks (MATH). Furthermore, we show the critical\nrole reward aggregation functions play in model performance. Providing\npromising avenues for future research, our study underscores the need for\nfurther exploration into fine-grained reward modeling for more reliable\nlanguage models.\n",
                "链接": "https://arxiv.org/abs/2311.05821"
            },
            {
                "文章ID": "106629",
                "标题": "Beyond One-Preference-Fits-All Alignment: Multi-Objective Direct\n  Preference Optimization",
                "作者": " Zhanhui Zhou,  Jie Liu,  Chao Yang,  Jing Shao,  Yu Liu,  Xiangyu Yue,  Wanli Ouyang,  Yu Qiao",
                "发布日期": "2023-12-18",
                "摘要": "  A single language model (LM), despite aligning well with an average labeler\nthrough reinforcement learning from human feedback (RLHF), may not universally\nsuit diverse human preferences. Recent approaches therefore opt for\ncustomization by collecting multi-dimensional feedback and creating distinct\nreward models (RMs) for each dimension (e.g., helpfulness, harmlessness, or\nhonesty). Different LMs can then be optimized for different preferences using\nmulti-objective RLHF (MORLHF) with different reward weightings. Yet, RL\nfine-tuning is unstable and resource-heavy, especially for MORLHF with diverse\nand usually conflicting objectives. In this paper, we present Multi-Objective\nDirect Preference Optimization (MODPO), an RL-free algorithm that extends\nDirect Preference Optimization (DPO) for multiple alignment objectives with\nminimal overheads. Essentially, MODPO folds language modeling directly into\nreward modeling, training LMs as implicit collective reward models (cRMs) that\ncombine all objectives with specific weightings. While theoretically guaranteed\nto produce the same optimal solutions as MORLHF, MODPO is practically more\nstable and computationally efficient. Empirical results from safety alignment\nand long-form question answering confirm that MODPO matches or outperforms\nexisting methods, consistently producing a Pareto front of LMs that cater to\ndiverse preferences with 3 times less computational resources compared to\nMORLHF.\n",
                "链接": "https://arxiv.org/abs/2310.03708"
            },
            {
                "文章ID": "105659",
                "标题": "Tool-Augmented Reward Modeling",
                "作者": " Lei Li,  Yekun Chai,  Shuohuan Wang,  Yu Sun,  Hao Tian,  Ningyu Zhang,  Hua Wu",
                "发布日期": "2023-10-03",
                "摘要": "  Reward modeling (a.k.a., preference modeling) is instrumental for aligning\nlarge language models with human preferences, particularly within the context\nof reinforcement learning from human feedback (RLHF). While conventional reward\nmodels (RMs) have exhibited remarkable scalability, they oft struggle with\nfundamental functionality such as arithmetic computation, code execution, and\nfactual lookup. In this paper, we propose a tool-augmented preference modeling\napproach, named \\name, to address these limitations by empowering RMs with\naccess to external environments, including calculators and search engines. This\napproach not only fosters synergy between tool utilization and reward grading\nbut also enhances interpretive capacity and scoring reliability. Our study\ndelves into the integration of external tools into RMs, enabling them to\ninteract with diverse external sources and construct task-specific tool\nengagement and reasoning traces in an autoregressive manner. We validate our\napproach across a wide range of domains, incorporating seven distinct external\ntools. Our experimental results demonstrate a noteworthy overall improvement of\n17.7% across eight tasks in preference ranking. Furthermore, our approach\noutperforms Gopher 280B by 7.3% on TruthfulQA task in zero-shot evaluation. In\nhuman evaluations, RLHF trained with Themis attains an average win rate of 32%\nwhen compared to baselines across four distinct tasks. Additionally, we provide\na comprehensive collection of tool-related RM datasets, incorporating data from\nseven distinct tool APIs, totaling 15,000 instances. We anticipate that this\npublicly available dataset will facilitate and inspire further research\nadvancements in the field.\n",
                "链接": "https://arxiv.org/abs/2310.01045"
            },
            {
                "文章ID": "107200",
                "标题": "Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning\n  from Human Feedback",
                "作者": " Wei Shen,  Rui Zheng,  Wenyu Zhan,  Jun Zhao,  Shihan Dou,  Tao Gui,  Qi Zhang,  Xuanjing Huang",
                "发布日期": "2023-11-30",
                "摘要": "  Reinforcement learning from human feedback serves as a crucial bridge,\naligning large language models with human and societal values. This alignment\nrequires a vast corpus of human feedback to learn a reward model, which is\nsubsequently used to finetune language models. However, we have identified that\nthe reward model often finds shortcuts to bypass its intended objectives,\nmisleadingly assuming that humans prefer longer responses. The emergence of\nlength bias often induces the model to favor longer outputs, yet it doesn't\nequate to an increase in helpful information within these outputs. In this\npaper, we propose an innovative solution, applying the Product-of-Experts (PoE)\ntechnique to separate reward modeling from the influence of sequence length. In\nour framework, the main expert concentrates on understanding human intents,\nwhile the biased expert targets the identification and capture of length bias.\nTo further enhance the learning of bias, we introduce perturbations into the\nbias-focused expert, disrupting the flow of semantic information. Experimental\nresults validate the effectiveness of our approach, indicating that language\nmodel performance is improved, irrespective of sequence length.\n",
                "链接": "https://arxiv.org/abs/2310.05199"
            },
            {
                "文章ID": "79661",
                "标题": "Aligning Large Language Models through Synthetic Feedback",
                "作者": " Sungdong Kim,  Sanghwan Bae,  Jamin Shin,  Soyoung Kang,  Donghyun Kwak,  Kang Min Yoo,  Minjoon Seo",
                "发布日期": "2023-10-24",
                "摘要": "  Aligning large language models (LLMs) to human values has become increasingly\nimportant as it enables sophisticated steering of LLMs. However, it requires\nsignificant human demonstrations and feedback or distillation from proprietary\nLLMs such as ChatGPT. In this work, we propose a novel alignment learning\nframework with synthetic feedback not dependent on extensive human annotations\nand proprietary LLMs. First, we perform reward modeling (RM) with synthetic\nfeedback by contrasting responses from vanilla LLMs with various sizes and\nprompts. Then, we use the RM to simulate high-quality demonstrations to train a\nsupervised policy and further optimize the model with reinforcement learning.\nOur resulting model, Aligned Language Model with Synthetic Training dataset\n(ALMoST), outperforms recent open-sourced models, which are trained on the\noutputs of InstructGPT or human-annotated demonstrations, in alignment\nbenchmarks. In human evaluation, our model is preferred to Alpaca and Dolly-v2,\n55.0% and 58.5% of the time, respectively. Further analyses demonstrate the\nefficacy and importance of synthetic feedback in our framework. The code is\navailable at https://github.com/naver-ai/almost\n",
                "链接": "https://arxiv.org/abs/2305.13735"
            },
            {
                "文章ID": "42744",
                "标题": "Robust Preference Learning for Storytelling via Contrastive\n  Reinforcement Learning",
                "作者": " Louis Castricato,  Alexander Havrilla,  Shahbuland Matiana,  Michael Pieler,  Anbang Ye,  Ian Yang,  Spencer Frazier,  Mark Riedl",
                "发布日期": "2022-12-16",
                "摘要": "  Controlled automated story generation seeks to generate natural language\nstories satisfying constraints from natural language critiques or preferences.\nExisting methods to control for story preference utilize prompt engineering\nwhich is labor intensive and often inconsistent. They may also use\nlogit-manipulation methods which require annotated datasets to exist for the\ndesired attributes. To address these issues, we first train a contrastive\nbi-encoder model to align stories with corresponding human critiques, named\nCARP, building a general purpose preference model. This is subsequently used as\na reward function to fine-tune a generative language model via reinforcement\nlearning. However, simply fine-tuning a generative language model with a\ncontrastive reward model does not always reliably result in a story generation\nsystem capable of generating stories that meet user preferences. To increase\nstory generation robustness we further fine-tune the contrastive reward model\nusing a prompt-learning technique. A human participant study is then conducted\ncomparing generations from our full system, ablations, and two baselines. We\nshow that the full fine-tuning pipeline results in a story generator preferred\nover a LLM 20x as large as well as logit-based methods. This motivates the use\nof contrastive learning for general purpose human preference modeling.\n",
                "链接": "https://arxiv.org/abs/2210.07792"
            },
            {
                "文章ID": "6241",
                "标题": "Reward Modeling for Mitigating Toxicity in Transformer-based Language\n  Models",
                "作者": " Farshid Faal,  Ketra Schmitt,  Jia Yuan Yu",
                "发布日期": "2022-07-28",
                "摘要": "  Transformer-based language models are able to generate fluent text and be\nefficiently adapted across various natural language generation tasks. However,\nlanguage models that are pretrained on large unlabeled web text corpora have\nbeen shown to suffer from degenerating toxic content and social bias behaviors,\nconsequently hindering their safe deployment. Various detoxification methods\nwere proposed to mitigate the language model's toxicity; however, these methods\nstruggled to detoxify language models when conditioned on prompts that contain\nspecific social identities related to gender, race, or religion. In this study,\nwe propose Reinforce-Detoxify; A reinforcement learning-based method for\nmitigating toxicity in language models. We address the challenge of safety in\nlanguage models and propose a new reward model that is able to detect toxic\ncontent and mitigate unintended bias towards social identities in toxicity\nprediction. The experiments demonstrate that the Reinforce-Detoxify method for\nlanguage model detoxification outperforms existing detoxification approaches in\nautomatic evaluation metrics, indicating the ability of our approach in\nlanguage model detoxification and less prone to unintended bias toward social\nidentities in generated content.\n",
                "链接": "https://arxiv.org/abs/2202.09662"
            },
            {
                "文章ID": "58975",
                "标题": "Direct Preference-based Policy Optimization without Reward Modeling",
                "作者": " Gaon An,  Junhyeok Lee,  Xingdong Zuo,  Norio Kosaka,  Kyung-Min Kim,  Hyun Oh Song",
                "发布日期": "2023-10-30",
                "摘要": "  Preference-based reinforcement learning (PbRL) is an approach that enables RL\nagents to learn from preference, which is particularly useful when formulating\na reward function is challenging. Existing PbRL methods generally involve a\ntwo-step procedure: they first learn a reward model based on given preference\ndata and then employ off-the-shelf reinforcement learning algorithms using the\nlearned reward model. However, obtaining an accurate reward model solely from\npreference information, especially when the preference is from human teachers,\ncan be difficult. Instead, we propose a PbRL algorithm that directly learns\nfrom preference without requiring any reward modeling. To achieve this, we\nadopt a contrastive learning framework to design a novel policy scoring metric\nthat assigns a high score to policies that align with the given preferences. We\napply our algorithm to offline RL tasks with actual human preference labels and\nshow that our algorithm outperforms or is on par with the existing PbRL\nmethods. Notably, on high-dimensional control tasks, our algorithm surpasses\noffline RL methods that learn with ground-truth reward information. Finally, we\nshow that our algorithm can be successfully applied to fine-tune large language\nmodels.\n",
                "链接": "https://arxiv.org/abs/2301.12842"
            },
            {
                "文章ID": "109991",
                "标题": "Generative Marginalization Models",
                "作者": " Sulin Liu,  Peter J. Ramadge,  Ryan P. Adams",
                "发布日期": "2023-10-20",
                "摘要": "  We introduce marginalization models (MaMs), a new family of generative models\nfor high-dimensional discrete data. They offer scalable and flexible generative\nmodeling with tractable likelihoods by explicitly modeling all induced marginal\ndistributions. Marginalization models enable fast evaluation of arbitrary\nmarginal probabilities with a single forward pass of the neural network, which\novercomes a major limitation of methods with exact marginal inference, such as\nautoregressive models (ARMs). We propose scalable methods for learning the\nmarginals, grounded in the concept of \"marginalization self-consistency\".\nUnlike previous methods, MaMs support scalable training of any-order generative\nmodels for high-dimensional problems under the setting of energy-based\ntraining, where the goal is to match the learned distribution to a given\ndesired probability (specified by an unnormalized (log) probability function\nsuch as energy function or reward function). We demonstrate the effectiveness\nof the proposed model on a variety of discrete data distributions, including\nbinary images, language, physical systems, and molecules, for maximum\nlikelihood and energy-based training settings. MaMs achieve orders of magnitude\nspeedup in evaluating the marginal probabilities on both settings. For\nenergy-based training tasks, MaMs enable any-order generative modeling of\nhigh-dimensional problems beyond the capability of previous methods. Code is at\nhttps://github.com/PrincetonLIPS/MaM.\n",
                "链接": "https://arxiv.org/abs/2310.12920"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到从位置编码角度改善模型长序列建模能力的相关论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "6738",
                "标题": "FastRPB: a Scalable Relative Positional Encoding for Long Sequence Tasks",
                "作者": " Maksim Zubkov,  Daniil Gavrilov",
                "发布日期": "2022-02-24",
                "摘要": "  Transformers achieve remarkable performance in various domains, including\nNLP, CV, audio processing, and graph analysis. However, they do not scale well\non long sequence tasks due to their quadratic complexity w.r.t. the inputs\nlength. Linear Transformers were proposed to address this limitation. However,\nthese models have shown weaker performance on the long sequence tasks comparing\nto the original one. In this paper, we explore Linear Transformer models,\nrethinking their two core components. Firstly, we improved Linear Transformer\nwith Shift-Invariant Kernel Function SIKF, which achieve higher accuracy\nwithout loss in speed. Secondly, we introduce FastRPB which stands for Fast\nRelative Positional Bias, which efficiently adds positional information to\nself-attention using Fast Fourier Transformation. FastRPB is independent of the\nself-attention mechanism and can be combined with an original self-attention\nand all its efficient variants. FastRPB has O(N log(N)) computational\ncomplexity, requiring O(N) memory w.r.t. input sequence length N.\n",
                "链接": "https://arxiv.org/abs/2202.11364"
            },
            {
                "文章ID": "91660",
                "标题": "Linearized Relative Positional Encoding",
                "作者": " Zhen Qin,  Weixuan Sun,  Kaiyue Lu,  Hui Deng,  Dongxu Li,  Xiaodong Han,  Yuchao Dai,  Lingpeng Kong,  Yiran Zhong",
                "发布日期": "2023-07-19",
                "摘要": "  Relative positional encoding is widely used in vanilla and linear\ntransformers to represent positional information. However, existing encoding\nmethods of a vanilla transformer are not always directly applicable to a linear\ntransformer, because the latter requires a decomposition of the query and key\nrepresentations into separate kernel functions. Nevertheless, principles for\ndesigning encoding methods suitable for linear transformers remain\nunderstudied. In this work, we put together a variety of existing linear\nrelative positional encoding approaches under a canonical form and further\npropose a family of linear relative positional encoding algorithms via unitary\ntransformation. Our formulation leads to a principled framework that can be\nused to develop new relative positional encoding methods that preserve linear\nspace-time complexity. Equipped with different models, the proposed linearized\nrelative positional encoding (LRPE) family derives effective encoding for\nvarious applications. Experiments show that compared with existing methods,\nLRPE achieves state-of-the-art performance in language modeling, text\nclassification, and image classification. Meanwhile, it emphasizes a general\nparadigm for designing broadly more relative positional encoding methods that\nare applicable to linear transformers. The code is available at\nhttps://github.com/OpenNLPLab/Lrpe.\n",
                "链接": "https://arxiv.org/abs/2307.09270"
            },
            {
                "文章ID": "50484",
                "标题": "PIP: Positional-encoding Image Prior",
                "作者": " Nimrod Shabtay,  Eli Schwartz,  Raja Giryes",
                "发布日期": "2023-04-04",
                "摘要": "  In Deep Image Prior (DIP), a Convolutional Neural Network (CNN) is fitted to\nmap a latent space to a degraded (e.g. noisy) image but in the process learns\nto reconstruct the clean image. This phenomenon is attributed to CNN's internal\nimage-prior. We revisit the DIP framework, examining it from the perspective of\na neural implicit representation. Motivated by this perspective, we replace the\nrandom or learned latent with Fourier-Features (Positional Encoding). We show\nthat thanks to the Fourier features properties, we can replace the convolution\nlayers with simple pixel-level MLPs. We name this scheme ``Positional Encoding\nImage Prior\" (PIP) and exhibit that it performs very similarly to DIP on\nvarious image-reconstruction tasks with much less parameters required.\nAdditionally, we demonstrate that PIP can be easily extended to videos, where\n3D-DIP struggles and suffers from instability. Code and additional examples for\nall tasks, including videos, are available on the project page\nhttps://nimrodshabtay.github.io/PIP/\n",
                "链接": "https://arxiv.org/abs/2211.14298"
            },
            {
                "文章ID": "50009",
                "标题": "Learning Regularized Positional Encoding for Molecular Prediction",
                "作者": " Xiang Gao,  Weihao Gao,  Wenzhi Xiao,  Zhirui Wang,  Chong Wang,  Liang Xiang",
                "发布日期": "2022-11-24",
                "摘要": "  Machine learning has become a promising approach for molecular modeling.\nPositional quantities, such as interatomic distances and bond angles, play a\ncrucial role in molecule physics. The existing works rely on careful manual\ndesign of their representation. To model the complex nonlinearity in predicting\nmolecular properties in an more end-to-end approach, we propose to encode the\npositional quantities with a learnable embedding that is continuous and\ndifferentiable. A regularization technique is employed to encourage embedding\nsmoothness along the physical dimension. We experiment with a variety of\nmolecular property and force field prediction tasks. Improved performance is\nobserved for three different model architectures after plugging in the proposed\npositional encoding method. In addition, the learned positional encoding allows\neasier physics-based interpretation. We observe that tasks of similar physics\nhave the similar learned positional encoding.\n",
                "链接": "https://arxiv.org/abs/2211.12773"
            },
            {
                "文章ID": "61325",
                "标题": "A Unified View of Long-Sequence Models towards Modeling Million-Scale\n  Dependencies",
                "作者": " Hongyu Hè,  Marko Kabic",
                "发布日期": "2023-02-17",
                "摘要": "  Ever since their conception, Transformers have taken over traditional\nsequence models in many tasks, such as NLP, image classification, and\nvideo/audio processing, for their fast training and superior performance. Much\nof the merit is attributable to positional encoding and multi-head attention.\nHowever, Transformers fall short in learning long-range dependencies mainly due\nto the quadratic complexity scaled with context length, in terms of both time\nand space. Consequently, over the past five years, a myriad of methods has been\nproposed to make Transformers more efficient. In this work, we first take a\nstep back, study and compare existing solutions to long-sequence modeling in\nterms of their pure mathematical formulation. Specifically, we summarize them\nusing a unified template, given their shared nature of token mixing. Through\nbenchmarks, we then demonstrate that long context length does yield better\nperformance, albeit application-dependent, and traditional Transformer models\nfall short in taking advantage of long-range dependencies. Next, inspired by\nemerging sparse models of huge capacity, we propose a machine learning system\nfor handling million-scale dependencies. As a proof of concept, we evaluate the\nperformance of one essential component of this system, namely, the distributed\nmulti-head attention. We show that our algorithm can scale up attention\ncomputation by almost $40\\times$ using four GeForce RTX 4090 GPUs, compared to\nvanilla multi-head attention mechanism. We believe this study is an\ninstrumental step towards modeling million-scale dependencies.\n",
                "链接": "https://arxiv.org/abs/2302.06218"
            },
            {
                "文章ID": "9782",
                "标题": "Efficient Long Sequence Encoding via Synchronization",
                "作者": " Xiangyang Mou,  Mo Yu,  Bingsheng Yao,  Lifu Huang",
                "发布日期": "2022-03-16",
                "摘要": "  Pre-trained Transformer models have achieved successes in a wide range of NLP\ntasks, but are inefficient when dealing with long input sequences. Existing\nstudies try to overcome this challenge via segmenting the long sequence\nfollowed by hierarchical encoding or post-hoc aggregation. We propose a\nsynchronization mechanism for hierarchical encoding. Our approach first\nidentifies anchor tokens across segments and groups them by their roles in the\noriginal input sequence. Then inside Transformer layer, anchor embeddings are\nsynchronized within their group via a self-attention module. Our approach is a\ngeneral framework with sufficient flexibility -- when adapted to a new task, it\nis easy to be enhanced with the task-specific anchor definitions. Experiments\non two representative tasks with different types of long input texts,\nNarrativeQA summary setting and wild multi-hop reasoning from HotpotQA,\ndemonstrate that our approach is able to improve the global information\nexchange among segments while maintaining efficiency.\n",
                "链接": "https://arxiv.org/abs/2203.07644"
            },
            {
                "文章ID": "3277",
                "标题": "GRPE: Relative Positional Encoding for Graph Transformer",
                "作者": " Wonpyo Park,  Woonggi Chang,  Donggeon Lee,  Juntae Kim,  Seung-won Hwang",
                "发布日期": "2022-10-17",
                "摘要": "  We propose a novel positional encoding for learning graph on Transformer\narchitecture. Existing approaches either linearize a graph to encode absolute\nposition in the sequence of nodes, or encode relative position with another\nnode using bias terms. The former loses preciseness of relative position from\nlinearization, while the latter loses a tight integration of node-edge and\nnode-topology interaction. To overcome the weakness of the previous approaches,\nour method encodes a graph without linearization and considers both\nnode-topology and node-edge interaction. We name our method Graph Relative\nPositional Encoding dedicated to graph representation learning. Experiments\nconducted on various graph datasets show that the proposed method outperforms\nprevious approaches significantly. Our code is publicly available at\nhttps://github.com/lenscloth/GRPE.\n",
                "链接": "https://arxiv.org/abs/2201.12787"
            },
            {
                "文章ID": "82296",
                "标题": "The Impact of Positional Encoding on Length Generalization in\n  Transformers",
                "作者": " Amirhossein Kazemnejad,  Inkit Padhi,  Karthikeyan Natesan Ramamurthy,  Payel Das,  Siva Reddy",
                "发布日期": "2023-11-08",
                "摘要": "  Length generalization, the ability to generalize from small training context\nsizes to larger ones, is a critical challenge in the development of\nTransformer-based language models. Positional encoding (PE) has been identified\nas a major factor influencing length generalization, but the exact impact of\ndifferent PE schemes on extrapolation in downstream tasks remains unclear. In\nthis paper, we conduct a systematic empirical study comparing the length\ngeneralization performance of decoder-only Transformers with five different\nposition encoding approaches including Absolute Position Embedding (APE), T5's\nRelative PE, ALiBi, and Rotary, in addition to Transformers without positional\nencoding (NoPE). Our evaluation encompasses a battery of reasoning and\nmathematical tasks. Our findings reveal that the most commonly used positional\nencoding methods, such as ALiBi, Rotary, and APE, are not well suited for\nlength generalization in downstream tasks. More importantly, NoPE outperforms\nother explicit positional encoding methods while requiring no additional\ncomputation. We theoretically demonstrate that NoPE can represent both absolute\nand relative PEs, but when trained with SGD, it mostly resembles T5's relative\nPE attention patterns. Finally, we find that scratchpad is not always helpful\nto solve length generalization and its format highly impacts the model's\nperformance. Overall, our work suggests that explicit position embeddings are\nnot essential for decoder-only Transformers to generalize well to longer\nsequences.\n",
                "链接": "https://arxiv.org/abs/2305.19466"
            },
            {
                "文章ID": "112565",
                "标题": "HyPE: Attention with Hyperbolic Biases for Relative Positional Encoding",
                "作者": " Giorgio Angelotti",
                "发布日期": "2023-10-31",
                "摘要": "  In Transformer-based architectures, the attention mechanism is inherently\npermutation-invariant with respect to the input sequence's tokens. To impose\nsequential order, token positions are typically encoded using a scheme with\neither fixed or learnable parameters. We introduce Hyperbolic Positional\nEncoding (HyPE), a novel method that utilizes hyperbolic functions' properties\nto encode tokens' relative positions. This approach biases the attention\nmechanism without the necessity of storing the $O(L^2)$ values of the mask,\nwith $L$ being the length of the input sequence. HyPE leverages preliminary\nconcatenation operations and matrix multiplications, facilitating the encoding\nof relative distances indirectly incorporating biases into the softmax\ncomputation. This design ensures compatibility with FlashAttention-2 and\nsupports the gradient backpropagation for any potential learnable parameters\nwithin the encoding. We analytically demonstrate that, by careful\nhyperparameter selection, HyPE can approximate the attention bias of ALiBi,\nthereby offering promising generalization capabilities for contexts extending\nbeyond the lengths encountered during pretraining. The experimental evaluation\nof HyPE is proposed as a direction for future research.\n",
                "链接": "https://arxiv.org/abs/2310.19676"
            },
            {
                "文章ID": "45624",
                "标题": "Generalized Laplacian Positional Encoding for Graph Representation\n  Learning",
                "作者": " Sohir Maskey,  Ali Parviz,  Maximilian Thiessen,  Hannes Stärk,  Ylli Sadikaj,  Haggai Maron",
                "发布日期": "2022-11-11",
                "摘要": "  Graph neural networks (GNNs) are the primary tool for processing\ngraph-structured data. Unfortunately, the most commonly used GNNs, called\nMessage Passing Neural Networks (MPNNs) suffer from several fundamental\nlimitations. To overcome these limitations, recent works have adapted the idea\nof positional encodings to graph data. This paper draws inspiration from the\nrecent success of Laplacian-based positional encoding and defines a novel\nfamily of positional encoding schemes for graphs. We accomplish this by\ngeneralizing the optimization problem that defines the Laplace embedding to\nmore general dissimilarity functions rather than the 2-norm used in the\noriginal formulation. This family of positional encodings is then instantiated\nby considering p-norms. We discuss a method for calculating these positional\nencoding schemes, implement it in PyTorch and demonstrate how the resulting\npositional encoding captures different properties of the graph. Furthermore, we\ndemonstrate that this novel family of positional encodings can improve the\nexpressive power of MPNNs. Lastly, we present preliminary experimental results.\n",
                "链接": "https://arxiv.org/abs/2210.15956"
            }
        ]
    },
    {
        "question": {
            "question": "利用大模型做数学题生成的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "61811",
                "标题": "Tree-Based Representation and Generation of Natural and Mathematical\n  Language",
                "作者": " Alexander Scarlatos,  Andrew Lan",
                "发布日期": "2023-02-17",
                "摘要": "  Mathematical language in scientific communications and educational scenarios\nis important yet relatively understudied compared to natural languages. Recent\nworks on mathematical language focus either on representing stand-alone\nmathematical expressions, especially in their natural tree format, or\nmathematical reasoning in pre-trained natural language models. Existing works\non jointly modeling and generating natural and mathematical languages simply\ntreat mathematical expressions as text, without accounting for the rigid\nstructural properties of mathematical expressions. In this paper, we propose a\nseries of modifications to existing language models to jointly represent and\ngenerate text and math: representing mathematical expressions as sequences of\nnode tokens in their operator tree format, using math symbol and tree position\nembeddings to preserve the semantic and structural properties of mathematical\nexpressions, and using a constrained decoding method to generate mathematically\nvalid expressions. We ground our modifications in GPT-2, resulting in a model\nMathGPT, and demonstrate that it outperforms baselines on mathematical\nexpression generation tasks.\n",
                "链接": "https://arxiv.org/abs/2302.07974"
            },
            {
                "文章ID": "110277",
                "标题": "Three Questions Concerning the Use of Large Language Models to\n  Facilitate Mathematics Learning",
                "作者": " An-Zi Yen,  Wei-Ling Hsu",
                "发布日期": "2023-10-23",
                "摘要": "  Due to the remarkable language understanding and generation abilities of\nlarge language models (LLMs), their use in educational applications has been\nexplored. However, little work has been done on investigating the pedagogical\nability of LLMs in helping students to learn mathematics. In this position\npaper, we discuss the challenges associated with employing LLMs to enhance\nstudents' mathematical problem-solving skills by providing adaptive feedback.\nApart from generating the wrong reasoning processes, LLMs can misinterpret the\nmeaning of the question, and also exhibit difficulty in understanding the given\nquestions' rationales when attempting to correct students' answers. Three\nresearch questions are formulated.\n",
                "链接": "https://arxiv.org/abs/2310.13615"
            },
            {
                "文章ID": "21205",
                "标题": "NaturalProver: Grounded Mathematical Proof Generation with Language\n  Models",
                "作者": " Sean Welleck,  Jiacheng Liu,  Ximing Lu,  Hannaneh Hajishirzi,  Yejin Choi",
                "发布日期": "2022-11-02",
                "摘要": "  Theorem proving in natural mathematical language - the mixture of symbolic\nand natural language used by humans - plays a central role in mathematical\nadvances and education, and tests aspects of reasoning that are core to\nintelligence. Yet it has remained underexplored with modern generative models.\nWe study large-scale language models on two new generation tasks: suggesting\nthe next step in a mathematical proof, and full proof generation. We develop\nNaturalProver, a language model that generates proofs by conditioning on\nbackground references (e.g. theorems and definitions that are either retrieved\nor human-provided), and optionally enforces their presence with constrained\ndecoding. On theorems from the NaturalProofs benchmark, NaturalProver improves\nthe quality of next-step suggestions and generated proofs over fine-tuned\nGPT-3, according to human evaluations from university-level mathematics\nstudents. NaturalProver is capable of proving some theorems that require short\n(2-6 step) proofs, and providing next-step suggestions that are rated as\ncorrect and useful over 40% of the time, which is to our knowledge the first\ndemonstration of these capabilities using neural language models.\n",
                "链接": "https://arxiv.org/abs/2205.12910"
            },
            {
                "文章ID": "89573",
                "标题": "Math Agents: Computational Infrastructure, Mathematical Embedding, and\n  Genomics",
                "作者": " Melanie Swan,  Takashi Kido,  Eric Roland,  Renato P. dos Santos",
                "发布日期": "2023-07-07",
                "摘要": "  The advancement in generative AI could be boosted with more accessible\nmathematics. Beyond human-AI chat, large language models (LLMs) are emerging in\nprogramming, algorithm discovery, and theorem proving, yet their genomics\napplication is limited. This project introduces Math Agents and mathematical\nembedding as fresh entries to the \"Moore's Law of Mathematics\", using a\nGPT-based workflow to convert equations from literature into LaTeX and Python\nformats. While many digital equation representations exist, there's a lack of\nautomated large-scale evaluation tools. LLMs are pivotal as linguistic user\ninterfaces, providing natural language access for human-AI chat and formal\nlanguages for large-scale AI-assisted computational infrastructure. Given the\ninfinite formal possibility spaces, Math Agents, which interact with math,\ncould potentially shift us from \"big data\" to \"big math\". Math, unlike the more\nflexible natural language, has properties subject to proof, enabling its use\nbeyond traditional applications like high-validation math-certified icons for\nAI alignment aims. This project aims to use Math Agents and mathematical\nembeddings to address the ageing issue in information systems biology by\napplying multiscalar physics mathematics to disease models and genomic data.\nGenerative AI with episodic memory could help analyse causal relations in\nlongitudinal health records, using SIR Precision Health models. Genomic data is\nsuggested for addressing the unsolved Alzheimer's disease problem.\n",
                "链接": "https://arxiv.org/abs/2307.02502"
            },
            {
                "文章ID": "83091",
                "标题": "An Empirical Study on Challenging Math Problem Solving with GPT-4",
                "作者": " Yiran Wu,  Feiran Jia,  Shaokun Zhang,  Hangyu Li,  Erkang Zhu,  Yue Wang,  Yin Tat Lee,  Richard Peng,  Qingyun Wu,  Chi Wang",
                "发布日期": "2023-06-09",
                "摘要": "  Employing Large Language Models (LLMs) to address mathematical problems is an\nintriguing research endeavor, considering the abundance of math problems\nexpressed in natural language across numerous science and engineering fields.\nWhile several prior works have investigated solving elementary mathematics\nusing LLMs, this work explores the frontier of using GPT-4 for solving more\ncomplex and challenging math problems. We evaluate various ways of using GPT-4.\nSome of them are adapted from existing work, and one is MathChat, a\nconversational problem-solving framework newly proposed in this work. We\nperform the evaluation on difficult high school competition problems from the\nMATH dataset, which shows the advantage of the proposed conversational\napproach.\n",
                "链接": "https://arxiv.org/abs/2306.01337"
            },
            {
                "文章ID": "106097",
                "标题": "MathVista: Evaluating Math Reasoning in Visual Contexts with GPT-4V,\n  Bard, and Other Large Multimodal Models",
                "作者": " Pan Lu,  Hritik Bansal,  Tony Xia,  Jiacheng Liu,  Chunyuan Li,  Hannaneh Hajishirzi,  Hao Cheng,  Kai-Wei Chang,  Michel Galley,  Jianfeng Gao",
                "发布日期": "2023-10-27",
                "摘要": "  Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit\nimpressive problem-solving skills in many tasks and domains, but their ability\nin mathematical reasoning in visual contexts has not been systematically\nstudied. To bridge this gap, we present MathVista, a benchmark designed to\ncombine challenges from diverse mathematical and visual tasks. It consists of\n6,141 examples, derived from 28 existing multimodal datasets involving\nmathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and\nPaperQA). Completing these tasks requires fine-grained, deep visual\nunderstanding and compositional reasoning, which all state-of-the-art\nfoundation models find challenging. With MathVista, we have conducted a\ncomprehensive, quantitative evaluation of 12 prominent foundation models. The\nbest-performing GPT-4V model achieves an overall accuracy of 49.9%,\nsubstantially outperforming Bard, the second-best performer, by 15.1%. Our\nin-depth analysis reveals that the superiority of GPT-4V is mainly attributed\nto its enhanced visual perception and mathematical reasoning. However, GPT-4V\nstill falls short of human performance by 10.4%, as it often struggles to\nunderstand complex figures and perform rigorous reasoning. This significant gap\nunderscores the critical role that MathVista will play in the development of\ngeneral-purpose AI agents capable of tackling mathematically intensive and\nvisually rich real-world tasks. We further explore the new ability of\nself-verification, the application of self-consistency, and the interactive\nchatbot capabilities of GPT-4V, highlighting its promising potential for future\nresearch. The project is available at https://mathvista.github.io/.\n",
                "链接": "https://arxiv.org/abs/2310.02255"
            },
            {
                "文章ID": "99865",
                "标题": "Extracting Mathematical Concepts with Large Language Models",
                "作者": " Valeria de Paiva,  Qiyue Gao,  Pavel Kovalev,  Lawrence S. Moss",
                "发布日期": "2023-09-06",
                "摘要": "  We extract mathematical concepts from mathematical text using generative\nlarge language models (LLMs) like ChatGPT, contributing to the field of\nautomatic term extraction (ATE) and mathematical text processing, and also to\nthe study of LLMs themselves. Our work builds on that of others in that we aim\nfor automatic extraction of terms (keywords) in one mathematical field,\ncategory theory, using as a corpus the 755 abstracts from a snapshot of the\nonline journal \"Theory and Applications of Categories\", circa 2020. Where our\nstudy diverges from previous work is in (1) providing a more thorough analysis\nof what makes mathematical term extraction a difficult problem to begin with;\n(2) paying close attention to inter-annotator disagreements; (3) providing a\nset of guidelines which both human and machine annotators could use to\nstandardize the extraction process; (4) introducing a new annotation tool to\nhelp humans with ATE, applicable to any mathematical field and even beyond\nmathematics; (5) using prompts to ChatGPT as part of the extraction process,\nand proposing best practices for such prompts; and (6) raising the question of\nwhether ChatGPT could be used as an annotator on the same level as human\nexperts. Our overall findings are that the matter of mathematical ATE is an\ninteresting field which can benefit from participation by LLMs, but LLMs\nthemselves cannot at this time surpass human performance on it.\n",
                "链接": "https://arxiv.org/abs/2309.00642"
            },
            {
                "文章ID": "98177",
                "标题": "How to Protect Copyright Data in Optimization of Large Language Models?",
                "作者": " Timothy Chu,  Zhao Song,  Chiwun Yang",
                "发布日期": "2023-08-24",
                "摘要": "  Large language models (LLMs) and generative AI have played a transformative\nrole in computer research and applications. Controversy has arisen as to\nwhether these models output copyrighted data, which can occur if the data the\nmodels are trained on is copyrighted. LLMs are built on the transformer neural\nnetwork architecture, which in turn relies on a mathematical computation called\nAttention that uses the softmax function.\n  In this paper, we show that large language model training and optimization\ncan be seen as a softmax regression problem. We then establish a method of\nefficiently performing softmax regression, in a way that prevents the\nregression function from generating copyright data. This establishes a\ntheoretical method of training large language models in a way that avoids\ngenerating copyright data.\n",
                "链接": "https://arxiv.org/abs/2308.12247"
            },
            {
                "文章ID": "91891",
                "标题": "Generating Mathematical Derivations with Large Language Models",
                "作者": " Jordan Meadows,  Marco Valentino,  Andre Freitas",
                "发布日期": "2023-08-09",
                "摘要": "  The derivation of mathematical results in specialised fields, using Large\nLanguage Models (LLMs), is an emerging research direction that can help\nidentify models' limitations, and potentially support mathematical discovery.\nIn this paper, we leverage a symbolic engine to generate derivations of\nequations at scale, and investigate the capabilities of LLMs when deriving goal\nequations from premises. Specifically, we employ in-context learning for GPT\nand fine-tune a range of T5 models to compare the robustness and generalisation\nof pre-training strategies to specialised models. Empirical results show that\nfine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and\nout-of-distribution test sets in conventional scores. However, an in-depth\nanalysis reveals that the fine-tuned models are more sensitive to perturbations\ninvolving unseen symbols and (to a lesser extent) changes to equation\nstructure. In addition, we analyse 1.7K equations, and over 200 derivations, to\nhighlight common reasoning errors such as the inclusion of incorrect,\nirrelevant, and redundant equations. Finally, we explore the suitability of\nexisting metrics for evaluating mathematical derivations and find evidence\nthat, while they can capture general properties such as sensitivity to\nperturbations, they fail to highlight fine-grained reasoning errors and\nessential differences between models. Overall, this work demonstrates that\ntraining models on synthetic data may improve their math capabilities beyond\nmuch larger LLMs, but current metrics are not appropriately assessing the\nquality of generated mathematical text.\n",
                "链接": "https://arxiv.org/abs/2307.09998"
            },
            {
                "文章ID": "111569",
                "标题": "math-PVS: A Large Language Model Framework to Map Scientific\n  Publications to PVS Theories",
                "作者": " Hassen Saidi,  Susmit Jha,  Tuhin Sahai",
                "发布日期": "2023-10-27",
                "摘要": "  As artificial intelligence (AI) gains greater adoption in a wide variety of\napplications, it has immense potential to contribute to mathematical discovery,\nby guiding conjecture generation, constructing counterexamples, assisting in\nformalizing mathematics, and discovering connections between different\nmathematical areas, to name a few.\n  While prior work has leveraged computers for exhaustive mathematical proof\nsearch, recent efforts based on large language models (LLMs) aspire to position\ncomputing platforms as co-contributors in the mathematical research process.\nDespite their current limitations in logic and mathematical tasks, there is\ngrowing interest in melding theorem proving systems with foundation models.\nThis work investigates the applicability of LLMs in formalizing advanced\nmathematical concepts and proposes a framework that can critically review and\ncheck mathematical reasoning in research papers. Given the noted reasoning\nshortcomings of LLMs, our approach synergizes the capabilities of proof\nassistants, specifically PVS, with LLMs, enabling a bridge between textual\ndescriptions in academic papers and formal specifications in PVS. By harnessing\nthe PVS environment, coupled with data ingestion and conversion mechanisms, we\nenvision an automated process, called \\emph{math-PVS}, to extract and formalize\nmathematical theorems from research papers, offering an innovative tool for\nacademic review and discovery.\n",
                "链接": "https://arxiv.org/abs/2310.17064"
            }
        ]
    },
    {
        "question": {
            "question": "查找可以用于验证模型推理能力的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "113190",
                "标题": "VQA-GEN: A Visual Question Answering Benchmark for Domain Generalization",
                "作者": " Suraj Jyothi Unni,  Raha Moraffah,  Huan Liu",
                "发布日期": "2023-11-03",
                "摘要": "  Visual question answering (VQA) models are designed to demonstrate\nvisual-textual reasoning capabilities. However, their real-world applicability\nis hindered by a lack of comprehensive benchmark datasets. Existing domain\ngeneralization datasets for VQA exhibit a unilateral focus on textual shifts\nwhile VQA being a multi-modal task contains shifts across both visual and\ntextual domains. We propose VQA-GEN, the first ever multi-modal benchmark\ndataset for distribution shift generated through a shift induced pipeline.\nExperiments demonstrate VQA-GEN dataset exposes the vulnerability of existing\nmethods to joint multi-modal distribution shifts. validating that comprehensive\nmulti-modal shifts are critical for robust VQA generalization. Models trained\non VQA-GEN exhibit improved cross-domain and in-domain performance, confirming\nthe value of VQA-GEN. Further, we analyze the importance of each shift\ntechnique of our pipeline contributing to the generalization of the model.\n",
                "链接": "https://arxiv.org/abs/2311.00807"
            },
            {
                "文章ID": "111569",
                "标题": "math-PVS: A Large Language Model Framework to Map Scientific\n  Publications to PVS Theories",
                "作者": " Hassen Saidi,  Susmit Jha,  Tuhin Sahai",
                "发布日期": "2023-10-27",
                "摘要": "  As artificial intelligence (AI) gains greater adoption in a wide variety of\napplications, it has immense potential to contribute to mathematical discovery,\nby guiding conjecture generation, constructing counterexamples, assisting in\nformalizing mathematics, and discovering connections between different\nmathematical areas, to name a few.\n  While prior work has leveraged computers for exhaustive mathematical proof\nsearch, recent efforts based on large language models (LLMs) aspire to position\ncomputing platforms as co-contributors in the mathematical research process.\nDespite their current limitations in logic and mathematical tasks, there is\ngrowing interest in melding theorem proving systems with foundation models.\nThis work investigates the applicability of LLMs in formalizing advanced\nmathematical concepts and proposes a framework that can critically review and\ncheck mathematical reasoning in research papers. Given the noted reasoning\nshortcomings of LLMs, our approach synergizes the capabilities of proof\nassistants, specifically PVS, with LLMs, enabling a bridge between textual\ndescriptions in academic papers and formal specifications in PVS. By harnessing\nthe PVS environment, coupled with data ingestion and conversion mechanisms, we\nenvision an automated process, called \\emph{math-PVS}, to extract and formalize\nmathematical theorems from research papers, offering an innovative tool for\nacademic review and discovery.\n",
                "链接": "https://arxiv.org/abs/2310.17064"
            },
            {
                "文章ID": "75161",
                "标题": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
                "作者": " Eddie Guo,  Mehul Gupta,  Jiawen Deng,  Ye-Jean Park,  Mike Paget,  Christopher Naugler",
                "发布日期": "2023-10-09",
                "摘要": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
                "链接": "https://arxiv.org/abs/2305.00844"
            },
            {
                "文章ID": "53943",
                "标题": "Teaching Small Language Models to Reason",
                "作者": " Lucie Charlotte Magister,  Jonathan Mallinson,  Jakub Adamek,  Eric Malmi,  Aliaksei Severyn",
                "发布日期": "2023-06-02",
                "摘要": "  Chain of thought prompting successfully improves the reasoning capabilities\nof large language models, achieving state of the art results on a range of\ndatasets. However, these reasoning capabilities only appear to emerge in models\nwith a size of over 100 billion parameters. In this paper, we explore the\ntransfer of such reasoning capabilities to models with less than 100 billion\nparameters via knowledge distillation. Specifically, we finetune a student\nmodel on the chain of thought outputs generated by a larger teacher model. Our\nexperiments show that the proposed method improves task performance across\narithmetic, commonsense and symbolic reasoning datasets. For example, the\naccuracy of T5 XXL on GSM8K improves from 8.11% to 21.99% when finetuned on\nPaLM-540B generated chains of thought.\n",
                "链接": "https://arxiv.org/abs/2212.08410"
            },
            {
                "文章ID": "120555",
                "标题": "Teaching Specific Scientific Knowledge into Large Language Models\n  through Additional Training",
                "作者": " Kan Hatakeyama-Sato,  Yasuhiko Igarashi,  Shun Katakami,  Yuta Nabae,  Teruaki Hayakawa",
                "发布日期": "2023-12-19",
                "摘要": "  Through additional training, we explore embedding specialized scientific\nknowledge into the Llama 2 Large Language Model (LLM). Key findings reveal that\neffective knowledge integration requires reading texts from multiple\nperspectives, especially in instructional formats. We utilize text augmentation\nto tackle the scarcity of specialized texts, including style conversions and\ntranslations. Hyperparameter optimization proves crucial, with different size\nmodels (7b, 13b, and 70b) reasonably undergoing additional training. Validating\nour methods, we construct a dataset of 65,000 scientific papers. Although we\nhave succeeded in partially embedding knowledge, the study highlights the\ncomplexities and limitations of incorporating specialized information into\nLLMs, suggesting areas for further improvement.\n",
                "链接": "https://arxiv.org/abs/2312.03360"
            },
            {
                "文章ID": "26747",
                "标题": "Explaining Any ML Model? -- On Goals and Capabilities of XAI",
                "作者": " Moritz Renftle,  Holger Trittenbach,  Michael Poznic,  Reinhard Heil",
                "发布日期": "2022-06-29",
                "摘要": "  An increasing ubiquity of machine learning (ML) motivates research on\nalgorithms to explain ML models and their predictions -- so-called eXplainable\nArtificial Intelligence (XAI). Despite many survey papers and discussions, the\ngoals and capabilities of XAI algorithms are far from being well understood. We\nargue that this is because of a problematic reasoning scheme in XAI literature:\nXAI algorithms are said to complement ML models with desired properties, such\nas \"interpretability\", or \"explainability\". These properties are in turn\nassumed to contribute to a goal, like \"trust\" in an ML system. But most\nproperties lack precise definitions and their relationship to such goals is far\nfrom obvious. The result is a reasoning scheme that obfuscates research results\nand leaves an important question unanswered: What can one expect from XAI\nalgorithms? In this article, we clarify the goals and capabilities of XAI\nalgorithms from a concrete perspective: that of their users. Explaining ML\nmodels is only necessary if users have questions about them. We show that users\ncan ask diverse questions, but that only one of them can be answered by current\nXAI algorithms. Answering this core question can be trivial, difficult or even\nimpossible, depending on the ML application. Based on these insights, we\noutline which capabilities policymakers, researchers and society can reasonably\nexpect from XAI algorithms.\n",
                "链接": "https://arxiv.org/abs/2206.13888"
            },
            {
                "文章ID": "61480",
                "标题": "On the Planning Abilities of Large Language Models (A Critical\n  Investigation with a Proposed Benchmark)",
                "作者": " Karthik Valmeekam,  Sarath Sreedharan,  Matthew Marquez,  Alberto Olmo,  Subbarao Kambhampati",
                "发布日期": "2023-02-15",
                "摘要": "  Intrigued by the claims of emergent reasoning capabilities in LLMs trained on\ngeneral web corpora, in this paper, we set out to investigate their planning\ncapabilities. We aim to evaluate (1) how good LLMs are by themselves in\ngenerating and validating simple plans in commonsense planning tasks (of the\ntype that humans are generally quite good at) and (2) how good LLMs are in\nbeing a source of heuristic guidance for other agents--either AI planners or\nhuman planners--in their planning tasks. To investigate these questions in a\nsystematic rather than anecdotal manner, we start by developing a benchmark\nsuite based on the kinds of domains employed in the International Planning\nCompetition. On this benchmark, we evaluate LLMs in three modes: autonomous,\nheuristic and human-in-the-loop. Our results show that LLM's ability to\nautonomously generate executable plans is quite meager, averaging only about 3%\nsuccess rate. The heuristic and human-in-the-loop modes show slightly more\npromise. In addition to these results, we also make our benchmark and\nevaluation tools available to support investigations by research community.\n",
                "链接": "https://arxiv.org/abs/2302.06706"
            },
            {
                "文章ID": "110712",
                "标题": "MCC-KD: Multi-CoT Consistent Knowledge Distillation",
                "作者": " Hongzhan Chen,  Siyue Wu,  Xiaojun Quan,  Rui Wang,  Ming Yan,  Ji Zhang",
                "发布日期": "2023-12-21",
                "摘要": "  Large language models (LLMs) have showcased remarkable capabilities in\ncomplex reasoning through chain of thought (CoT) prompting. Recently, there has\nbeen a growing interest in transferring these reasoning abilities from LLMs to\nsmaller models. However, achieving both the diversity and consistency in\nrationales presents a challenge. In this paper, we focus on enhancing these two\naspects and propose Multi-CoT Consistent Knowledge Distillation (MCC-KD) to\nefficiently distill the reasoning capabilities. In MCC-KD, we generate multiple\nrationales for each question and enforce consistency among the corresponding\npredictions by minimizing the bidirectional KL-divergence between the answer\ndistributions. We investigate the effectiveness of MCC-KD with different model\narchitectures (LLaMA/FlanT5) and various model scales (3B/7B/11B/13B) on both\nmathematical reasoning and commonsense reasoning benchmarks. The empirical\nresults not only confirm MCC-KD's superior performance on in-distribution\ndatasets but also highlight its robust generalization ability on\nout-of-distribution datasets.\n",
                "链接": "https://arxiv.org/abs/2310.14747"
            },
            {
                "文章ID": "116000",
                "标题": "Disentangling the Potential Impacts of Papers into Diffusion,\n  Conformity, and Contribution Values",
                "作者": " Zhikai Xue,  Guoxiu He,  Zhuoren Jiang,  Yangyang Kang,  Star Zhao,  Wei Lu",
                "发布日期": "2023-11-17",
                "摘要": "  The potential impact of an academic paper is determined by various factors,\nincluding its popularity and contribution. Existing models usually estimate\noriginal citation counts based on static graphs and fail to differentiate\nvalues from nuanced perspectives. In this study, we propose a novel graph\nneural network to Disentangle the Potential impacts of Papers into Diffusion,\nConformity, and Contribution values (called DPPDCC). Given a target paper,\nDPPDCC encodes temporal and structural features within the constructed dynamic\nheterogeneous graph. Particularly, to capture the knowledge flow, we emphasize\nthe importance of comparative and co-cited/citing information between papers\nand aggregate snapshots evolutionarily. To unravel popularity, we contrast\naugmented graphs to extract the essence of diffusion and predict the\naccumulated citation binning to model conformity. We further apply orthogonal\nconstraints to encourage distinct modeling of each perspective and preserve the\ninherent value of contribution. To evaluate models' generalization for papers\npublished at various times, we reformulate the problem by partitioning data\nbased on specific time points to mirror real-world conditions. Extensive\nexperimental results on three datasets demonstrate that DPPDCC significantly\noutperforms baselines for previously, freshly, and immediately published\npapers. Further analyses confirm its robust capabilities. We will make our\ndatasets and codes publicly available.\n",
                "链接": "https://arxiv.org/abs/2311.09262"
            },
            {
                "文章ID": "120767",
                "标题": "Efficient Large Language Models: A Survey",
                "作者": " Zhongwei Wan,  Xin Wang,  Che Liu,  Samiul Alam,  Yu Zheng,  Jiachen Liu,  Zhongnan Qu,  Shen Yan,  Yi Zhu,  Quanlu Zhang,  Mosharaf Chowdhury,  Mi Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Large Language Models (LLMs) have demonstrated remarkable capabilities in\nimportant tasks such as natural language understanding, language generation,\nand complex reasoning and have the potential to make a substantial impact on\nour society. Such capabilities, however, come with the considerable resources\nthey demand, highlighting the strong need to develop effective techniques for\naddressing their efficiency challenges. In this survey, we provide a systematic\nand comprehensive review of efficient LLMs research. We organize the literature\nin a taxonomy consisting of three main categories, covering distinct yet\ninterconnected efficient LLMs topics from model-centric, data-centric, and\nframework-centric perspective, respectively. We have also created a GitHub\nrepository where we compile the papers featured in this survey at\nhttps://github.com/AIoT-MLSys-Lab/EfficientLLMs, and will actively maintain\nthis repository and incorporate new research as it emerges. We hope our survey\ncan serve as a valuable resource to help researchers and practitioners gain a\nsystematic understanding of the research developments in efficient LLMs and\ninspire them to contribute to this important and exciting field.\n",
                "链接": "https://arxiv.org/abs/2312.03863"
            }
        ]
    },
    {
        "question": {
            "question": "帮我找一下用大模型进行论文查找的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "75161",
                "标题": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
                "作者": " Eddie Guo,  Mehul Gupta,  Jiawen Deng,  Ye-Jean Park,  Mike Paget,  Christopher Naugler",
                "发布日期": "2023-10-09",
                "摘要": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
                "链接": "https://arxiv.org/abs/2305.00844"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "83805",
                "标题": "Synthesizing Affective Neurophysiological Signals Using Generative\n  Models: A Review Paper",
                "作者": " Alireza F. Nia,  Vanessa Tang,  Gonzalo Maso Talou,  Mark Billinghurst",
                "发布日期": "2023-06-07",
                "摘要": "  The integration of emotional intelligence in machines is an important step in\nadvancing human-computer interaction. This demands the development of reliable\nend-to-end emotion recognition systems. However, the scarcity of public\naffective datasets presents a challenge. In this literature review, we\nemphasize the use of generative models to address this issue in\nneurophysiological signals, particularly Electroencephalogram (EEG) and\nFunctional Near-Infrared Spectroscopy (fNIRS). We provide a comprehensive\nanalysis of different generative models used in the field, examining their\ninput formulation, deployment strategies, and methodologies for evaluating the\nquality of synthesized data. This review serves as a comprehensive overview,\noffering insights into the advantages, challenges, and promising future\ndirections in the application of generative models in emotion recognition\nsystems. Through this review, we aim to facilitate the progression of\nneurophysiological data augmentation, thereby supporting the development of\nmore efficient and reliable emotion recognition systems.\n",
                "链接": "https://arxiv.org/abs/2306.03112"
            },
            {
                "文章ID": "48330",
                "标题": "Pied Piper: Meta Search for Music",
                "作者": " Pulak Malhotra,  Ashwin Rao",
                "发布日期": "2022-12-01",
                "摘要": "  Internet search engines have become an integral part of life, but for pop\nmusic, people still rely on textual search engines like Google. We propose Pied\npiper, a meta search engine for music. It can search for music lyrics, song\nmetadata and song audio or a combination of any of these as the input query and\nefficiently return the relevant results.\n",
                "链接": "https://arxiv.org/abs/2211.07610"
            },
            {
                "文章ID": "101124",
                "标题": "Toward Reproducing Network Research Results Using Large Language Models",
                "作者": " Qiao Xiang,  Yuling Lin,  Mingjun Fang,  Bang Huang,  Siyong Huang,  Ridi Wen,  Franck Le,  Linghe Kong,  Jiwu Shu",
                "发布日期": "2023-09-12",
                "摘要": "  Reproducing research results in the networking community is important for\nboth academia and industry. The current best practice typically resorts to\nthree approaches: (1) looking for publicly available prototypes; (2) contacting\nthe authors to get a private prototype; and (3) manually implementing a\nprototype following the description of the publication. However, most published\nnetwork research does not have public prototypes and private prototypes are\nhard to get. As such, most reproducing efforts are spent on manual\nimplementation based on the publications, which is both time and labor\nconsuming and error-prone. In this paper, we boldly propose reproducing network\nresearch results using the emerging large language models (LLMs). In\nparticular, we first prove its feasibility with a small-scale experiment, in\nwhich four students with essential networking knowledge each reproduces a\ndifferent networking system published in prominent conferences and journals by\nprompt engineering ChatGPT. We report the experiment's observations and lessons\nand discuss future open research questions of this proposal. This work raises\nno ethical issue.\n",
                "链接": "https://arxiv.org/abs/2309.04716"
            },
            {
                "文章ID": "57742",
                "标题": "Neural Architecture Search: Insights from 1000 Papers",
                "作者": " Colin White,  Mahmoud Safari,  Rhea Sukthanker,  Binxin Ru,  Thomas Elsken,  Arber Zela,  Debadeepta Dey,  Frank Hutter",
                "发布日期": "2023-01-26",
                "摘要": "  In the past decade, advances in deep learning have resulted in breakthroughs\nin a variety of areas, including computer vision, natural language\nunderstanding, speech recognition, and reinforcement learning. Specialized,\nhigh-performing neural architectures are crucial to the success of deep\nlearning in these areas. Neural architecture search (NAS), the process of\nautomating the design of neural architectures for a given task, is an\ninevitable next step in automating machine learning and has already outpaced\nthe best human-designed architectures on many tasks. In the past few years,\nresearch in NAS has been progressing rapidly, with over 1000 papers released\nsince 2020 (Deng and Lindauer, 2021). In this survey, we provide an organized\nand comprehensive guide to neural architecture search. We give a taxonomy of\nsearch spaces, algorithms, and speedup techniques, and we discuss resources\nsuch as benchmarks, best practices, other surveys, and open-source libraries.\n",
                "链接": "https://arxiv.org/abs/2301.08727"
            },
            {
                "文章ID": "117394",
                "标题": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
                "作者": " Chengyu Wang,  Junbing Yan,  Wei Zhang,  Jun Huang",
                "发布日期": "2023-11-23",
                "摘要": "  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.13126"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到，最早提出分布式词表示的论文是哪一篇？",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "16842",
                "标题": "Extremal GloVe: Theoretically Accurate Distributed Word Embedding by\n  Tail Inference",
                "作者": " Hao Wang",
                "发布日期": "2022-04-28",
                "摘要": "  Distributed word embeddings such as Word2Vec and GloVe have been widely\nadopted in industrial context settings. Major technical applications of GloVe\ninclude recommender systems and natural language processing. The fundamental\ntheory behind GloVe relies on the selection of a weighting function in the\nweighted least squres formulation that computes the powered ratio of word\noccurrence count and the maximum word count in the corpus. However, the initial\nformulation of GloVe is not theoretically sound in two aspects, namely the\nselection of the weighting function and its power exponent is ad-hoc. In this\npaper, we utilize the theory of extreme value analysis and propose a\ntheoretically accurate version of GloVe. By reformulating the weighted least\nsquares loss function as the expected loss function and accurately choosing the\npower exponent, we create a theoretically accurate version of GloVe. We\ndemonstrate the competitiveness of our algorithm and show that the initial\nformulation of GloVe with the suggested optimal parameter can be viewed as a\nspecial case of our paradigm.\n",
                "链接": "https://arxiv.org/abs/2204.13009"
            },
            {
                "文章ID": "36500",
                "标题": "Tag-Aware Document Representation for Research Paper Recommendation",
                "作者": " Hebatallah A. Mohamed,  Giuseppe Sansonetti,  Alessandro Micarelli",
                "发布日期": "2022-09-09",
                "摘要": "  Finding online research papers relevant to one's interests is very\nchallenging due to the increasing number of publications. Therefore,\npersonalized research paper recommendation has become a significant and timely\nresearch topic. Collaborative filtering is a successful recommendation\napproach, which exploits the ratings given to items by users as a source of\ninformation for learning to make accurate recommendations. However, the ratings\nare often very sparse as in the research paper domain, due to the huge number\nof publications growing every year. Therefore, more attention has been drawn to\nhybrid methods that consider both ratings and content information.\nNevertheless, most of the hybrid recommendation approaches that are based on\ntext embedding have utilized bag-of-words techniques, which ignore word order\nand semantic meaning. In this paper, we propose a hybrid approach that\nleverages deep semantic representation of research papers based on social tags\nassigned by users. The experimental evaluation is performed on CiteULike, a\nreal and publicly available dataset. The obtained findings show that the\nproposed model is effective in recommending research papers even when the\nrating data is very sparse.\n",
                "链接": "https://arxiv.org/abs/2209.03660"
            },
            {
                "文章ID": "116434",
                "标题": "Collaborative Word-based Pre-trained Item Representation for\n  Transferable Recommendation",
                "作者": " Shenghao Yang,  Chenyang Wang,  Yankai Liu,  Kangping Xu,  Weizhi Ma,  Yiqun Liu,  Min Zhang,  Haitao Zeng,  Junlan Feng,  Chao Deng",
                "发布日期": "2023-12-22",
                "摘要": "  Item representation learning (IRL) plays an essential role in recommender\nsystems, especially for sequential recommendation. Traditional sequential\nrecommendation models usually utilize ID embeddings to represent items, which\nare not shared across different domains and lack the transferable ability.\nRecent studies use pre-trained language models (PLM) for item text embeddings\n(text-based IRL) that are universally applicable across domains. However, the\nexisting text-based IRL is unaware of the important collaborative filtering\n(CF) information. In this paper, we propose CoWPiRec, an approach of\nCollaborative Word-based Pre-trained item representation for Recommendation. To\neffectively incorporate CF information into text-based IRL, we convert the\nitem-level interaction data to a word graph containing word-level\ncollaborations. Subsequently, we design a novel pre-training task to align the\nword-level semantic- and CF-related item representation. Extensive experimental\nresults on multiple public datasets demonstrate that compared to\nstate-of-the-art transferable sequential recommenders, CoWPiRec achieves\nsignificantly better performances in both fine-tuning and zero-shot settings\nfor cross-scenario recommendation and effectively alleviates the cold-start\nissue. The code is available at: https://github.com/ysh-1998/CoWPiRec.\n",
                "链接": "https://arxiv.org/abs/2311.10501"
            },
            {
                "文章ID": "3597",
                "标题": "Towards a Theoretical Understanding of Word and Relation Representation",
                "作者": " Carl Allen",
                "发布日期": "2022-02-02",
                "摘要": "  Representing words by vectors, or embeddings, enables computational reasoning\nand is foundational to automating natural language tasks. For example, if word\nembeddings of similar words contain similar values, word similarity can be\nreadily assessed, whereas judging that from their spelling is often impossible\n(e.g. cat /feline) and to predetermine and store similarities between all words\nis prohibitively time-consuming, memory intensive and subjective. We focus on\nword embeddings learned from text corpora and knowledge graphs. Several\nwell-known algorithms learn word embeddings from text on an unsupervised basis\nby learning to predict those words that occur around each word, e.g. word2vec\nand GloVe. Parameters of such word embeddings are known to reflect word\nco-occurrence statistics, but how they capture semantic meaning has been\nunclear. Knowledge graph representation models learn representations both of\nentities (words, people, places, etc.) and relations between them, typically by\ntraining a model to predict known facts in a supervised manner. Despite steady\nimprovements in fact prediction accuracy, little is understood of the latent\nstructure that enables this.\n  The limited understanding of how latent semantic structure is encoded in the\ngeometry of word embeddings and knowledge graph representations makes a\nprincipled means of improving their performance, reliability or\ninterpretability unclear. To address this:\n  1. we theoretically justify the empirical observation that particular\ngeometric relationships between word embeddings learned by algorithms such as\nword2vec and GloVe correspond to semantic relations between words; and\n  2. we extend this correspondence between semantics and geometry to the\nentities and relations of knowledge graphs, providing a model for the latent\nstructure of knowledge graph representation linked to that of word embeddings.\n",
                "链接": "https://arxiv.org/abs/2202.00486"
            },
            {
                "文章ID": "49974",
                "标题": "Word-Level Representation From Bytes For Language Modeling",
                "作者": " Chu-Tak Lee,  Qipeng Guo,  Xipeng Qiu",
                "发布日期": "2022-11-24",
                "摘要": "  Modern language models mostly take sub-words as input, a design that balances\nthe trade-off between vocabulary size, number of parameters, and performance.\nHowever, sub-word tokenization still has disadvantages like not being robust to\nnoise and difficult to generalize to new languages. Also, the current trend of\nscaling up models reveals that larger models require larger embeddings but that\nmakes parallelization hard. Previous work on image classification proves\nsplitting raw input into a sequence of chucks is a strong, model-agnostic\ninductive bias. Based on this observation, we rethink the existing\ncharacter-aware method that takes character-level inputs but makes word-level\nsequence modeling and prediction. We overhaul this method by introducing a\ncross-attention network that builds word-level representation directly from\nbytes, and a sub-word level prediction based on word-level hidden states to\navoid the time and space requirement of word-level prediction. With these two\nimprovements combined, we have a token free model with slim input embeddings\nfor downstream tasks. We name our method Byte2Word and perform evaluations on\nlanguage modeling and text classification. Experiments show that Byte2Word is\non par with the strong sub-word baseline BERT but only takes up 10\\% of\nembedding size. We further test our method on synthetic noise and cross-lingual\ntransfer and find it competitive to baseline methods on both settings.\n",
                "链接": "https://arxiv.org/abs/2211.12677"
            },
            {
                "文章ID": "686",
                "标题": "Coherence-Based Distributed Document Representation Learning for\n  Scientific Documents",
                "作者": " Shicheng Tan,  Shu Zhao,  Yanping Zhang",
                "发布日期": "2022-01-11",
                "摘要": "  Distributed document representation is one of the basic problems in natural\nlanguage processing. Currently distributed document representation methods\nmainly consider the context information of words or sentences. These methods do\nnot take into account the coherence of the document as a whole, e.g., a\nrelation between the paper title and abstract, headline and description, or\nadjacent bodies in the document. The coherence shows whether a document is\nmeaningful, both logically and syntactically, especially in scientific\ndocuments (papers or patents, etc.). In this paper, we propose a coupled text\npair embedding (CTPE) model to learn the representation of scientific\ndocuments, which maintains the coherence of the document with coupled text\npairs formed by segmenting the document. First, we divide the document into two\nparts (e.g., title and abstract, etc) which construct a coupled text pair.\nThen, we adopt negative sampling to construct uncoupled text pairs whose two\nparts are from different documents. Finally, we train the model to judge\nwhether the text pair is coupled or uncoupled and use the obtained embedding of\ncoupled text pairs as the embedding of documents. We perform experiments on\nthree datasets for one information retrieval task and two recommendation tasks.\nThe experimental results verify the effectiveness of the proposed CTPE model.\n",
                "链接": "https://arxiv.org/abs/2201.02846"
            },
            {
                "文章ID": "80919",
                "标题": "A Distributed Automatic Domain-Specific Multi-Word Term Recognition\n  Architecture using Spark Ecosystem",
                "作者": " Ciprian-Octavian Truică,  Neculai-Ovidiu Istrate,  Elena-Simona Apostol",
                "发布日期": "2023-05-29",
                "摘要": "  Automatic Term Recognition is used to extract domain-specific terms that\nbelong to a given domain. In order to be accurate, these corpus and\nlanguage-dependent methods require large volumes of textual data that need to\nbe processed to extract candidate terms that are afterward scored according to\na given metric. To improve text preprocessing and candidate terms extraction\nand scoring, we propose a distributed Spark-based architecture to automatically\nextract domain-specific terms. The main contributions are as follows: (1)\npropose a novel distributed automatic domain-specific multi-word term\nrecognition architecture built on top of the Spark ecosystem; (2) perform an\nin-depth analysis of our architecture in terms of accuracy and scalability; (3)\ndesign an easy-to-integrate Python implementation that enables the use of Big\nData processing in fields such as Computational Linguistics and Natural\nLanguage Processing. We prove empirically the feasibility of our architecture\nby performing experiments on two real-world datasets.\n",
                "链接": "https://arxiv.org/abs/2305.16343"
            },
            {
                "文章ID": "73435",
                "标题": "Distributed Neural Representation for Reactive in situ Visualization",
                "作者": " Qi Wu,  Joseph A. Insley,  Victor A. Mateevitsi,  Silvio Rizzi,  Michael E. Papka,  Kwan-Liu Ma",
                "发布日期": "2023-04-21",
                "摘要": "  In situ visualization and steering of computational modeling can be\neffectively achieved using reactive programming, which leverages temporal\nabstraction and data caching mechanisms to create dynamic workflows. However,\nimplementing a temporal cache for large-scale simulations can be challenging.\nImplicit neural networks have proven effective in compressing large volume\ndata. However, their application to distributed data has yet to be fully\nexplored. In this work, we develop an implicit neural representation for\ndistributed volume data and incorporate it into the DIVA reactive programming\nsystem. This implementation enables us to build an in situ temporal caching\nsystem with a capacity 100 times larger than previously achieved. We integrate\nour implementation into the Ascent infrastructure and evaluate its performance\nusing real-world simulations.\n",
                "链接": "https://arxiv.org/abs/2304.10516"
            },
            {
                "文章ID": "19560",
                "标题": "KGNN: Distributed Framework for Graph Neural Knowledge Representation",
                "作者": " Binbin Hu,  Zhiyang Hu,  Zhiqiang Zhang,  Jun Zhou,  Chuan Shi",
                "发布日期": "2022-05-18",
                "摘要": "  Knowledge representation learning has been commonly adopted to incorporate\nknowledge graph (KG) into various online services. Although existing knowledge\nrepresentation learning methods have achieved considerable performance\nimprovement, they ignore high-order structure and abundant attribute\ninformation, resulting unsatisfactory performance on semantics-rich KGs.\nMoreover, they fail to make prediction in an inductive manner and cannot scale\nto large industrial graphs. To address these issues, we develop a novel\nframework called KGNN to take full advantage of knowledge data for\nrepresentation learning in the distributed learning system. KGNN is equipped\nwith GNN based encoder and knowledge aware decoder, which aim to jointly\nexplore high-order structure and attribute information together in a\nfine-grained fashion and preserve the relation patterns in KGs, respectively.\nExtensive experiments on three datasets for link prediction and triplet\nclassification task demonstrate the effectiveness and scalability of KGNN\nframework.\n",
                "链接": "https://arxiv.org/abs/2205.08285"
            },
            {
                "文章ID": "22285",
                "标题": "Distributed Graph Neural Network Training with Periodic Stale\n  Representation Synchronization",
                "作者": " Zheng Chai,  Guangji Bai,  Liang Zhao,  Yue Cheng",
                "发布日期": "2022-10-04",
                "摘要": "  Despite the recent success of Graph Neural Networks, it remains challenging\nto train a GNN on large graphs with millions of nodes and billions of edges,\nwhich are prevalent in many graph-based applications. Traditional\nsampling-based methods accelerate GNN training by dropping edges and nodes,\nwhich impairs the graph integrity and model performance. Differently,\ndistributed GNN algorithms accelerate GNN training by utilizing multiple\ncomputing devices and can be classified into two types: \"partition-based\"\nmethods enjoy low communication costs but suffer from information loss due to\ndropped edges, while \"propagation-based\" methods avoid information loss but\nsuffer from prohibitive communication overhead caused by the neighbor\nexplosion. To jointly address these problems, this paper proposes DIGEST\n(DIstributed Graph reprEsentation SynchronizaTion), a novel distributed GNN\ntraining framework that synergizes the complementary strength of both\ncategories of existing methods. We propose to allow each device to utilize the\nstale representations of its neighbors in other subgraphs during subgraph\nparallel training. This way, our method preserves global graph information from\nneighbors to avoid information loss and reduce communication costs. Our\nconvergence analysis demonstrates that DIGEST enjoys a state-of-the-art\nconvergence rate. Extensive experimental evaluation on large, real-world graph\ndatasets shows that DIGEST achieves up to 21.82 speedups without compromising\nperformance compared to state-of-the-art distributed GNN training frameworks.\n",
                "链接": "https://arxiv.org/abs/2206.00057"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下nips 2023 paper list",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "84628",
                "标题": "Overview of the Problem List Summarization (ProbSum) 2023 Shared Task on\n  Summarizing Patients' Active Diagnoses and Problems from Electronic Health\n  Record Progress Notes",
                "作者": " Yanjun Gao,  Dmitriy Dligach,  Timothy Miller,  Matthew M. Churpek,  Majid Afshar",
                "发布日期": "2023-06-09",
                "摘要": "  The BioNLP Workshop 2023 initiated the launch of a shared task on Problem\nList Summarization (ProbSum) in January 2023. The aim of this shared task is to\nattract future research efforts in building NLP models for real-world\ndiagnostic decision support applications, where a system generating relevant\nand accurate diagnoses will augment the healthcare providers decision-making\nprocess and improve the quality of care for patients. The goal for participants\nis to develop models that generated a list of diagnoses and problems using\ninput from the daily care notes collected from the hospitalization of\ncritically ill patients. Eight teams submitted their final systems to the\nshared task leaderboard. In this paper, we describe the tasks, datasets,\nevaluation metrics, and baseline systems. Additionally, the techniques and\nresults of the evaluation of the different approaches tried by the\nparticipating teams are summarized.\n",
                "链接": "https://arxiv.org/abs/2306.05270"
            },
            {
                "文章ID": "40312",
                "标题": "SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis",
                "作者": " Jiaxin Pei,  Vítor Silva,  Maarten Bos,  Yozon Liu,  Leonardo Neves,  David Jurgens,  Francesco Barbieri",
                "发布日期": "2023-02-06",
                "摘要": "  We propose MINT, a new Multilingual INTimacy analysis dataset covering 13,372\ntweets in 10 languages including English, French, Spanish, Italian, Portuguese,\nKorean, Dutch, Chinese, Hindi, and Arabic. We benchmarked a list of popular\nmultilingual pre-trained language models. The dataset is released along with\nthe SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis\n(https://sites.google.com/umich.edu/semeval-2023-tweet-intimacy).\n",
                "链接": "https://arxiv.org/abs/2210.01108"
            },
            {
                "文章ID": "47574",
                "标题": "A Characterization of List Learnability",
                "作者": " Moses Charikar,  Chirag Pabbaraju",
                "发布日期": "2023-03-28",
                "摘要": "  A classical result in learning theory shows the equivalence of PAC\nlearnability of binary hypothesis classes and the finiteness of VC dimension.\nExtending this to the multiclass setting was an open problem, which was settled\nin a recent breakthrough result characterizing multiclass PAC learnability via\nthe DS dimension introduced earlier by Daniely and Shalev-Shwartz. In this work\nwe consider list PAC learning where the goal is to output a list of $k$\npredictions. List learning algorithms have been developed in several settings\nbefore and indeed, list learning played an important role in the recent\ncharacterization of multiclass learnability. In this work we ask: when is it\npossible to $k$-list learn a hypothesis class? We completely characterize\n$k$-list learnability in terms of a generalization of DS dimension that we call\nthe $k$-DS dimension. Generalizing the recent characterization of multiclass\nlearnability, we show that a hypothesis class is $k$-list learnable if and only\nif the $k$-DS dimension is finite.\n",
                "链接": "https://arxiv.org/abs/2211.04956"
            },
            {
                "文章ID": "69199",
                "标题": "List Online Classification",
                "作者": " Shay Moran,  Ohad Sharon,  Iska Tsubari,  Sivan Yosebashvili",
                "发布日期": "2023-05-19",
                "摘要": "  We study multiclass online prediction where the learner can predict using a\nlist of multiple labels (as opposed to just one label in the traditional\nsetting). We characterize learnability in this model using the $b$-ary\nLittlestone dimension. This dimension is a variation of the classical\nLittlestone dimension with the difference that binary mistake trees are\nreplaced with $(k+1)$-ary mistake trees, where $k$ is the number of labels in\nthe list. In the agnostic setting, we explore different scenarios depending on\nwhether the comparator class consists of single-labeled or multi-labeled\nfunctions and its tradeoff with the size of the lists the algorithm uses. We\nfind that it is possible to achieve negative regret in some cases and provide a\ncomplete characterization of when this is possible. As part of our work, we\nadapt classical algorithms such as Littlestone's SOA and Rosenblatt's\nPerceptron to predict using lists of labels. We also establish combinatorial\nresults for list-learnable classes, including an list online version of the\nSauer-Shelah-Perles Lemma. We state our results within the framework of pattern\nclasses -- a generalization of hypothesis classes which can represent adaptive\nhypotheses (i.e. functions with memory), and model data-dependent assumptions\nsuch as linear classification with margin.\n",
                "链接": "https://arxiv.org/abs/2303.15383"
            },
            {
                "文章ID": "101771",
                "标题": "OWL Reasoners still useable in 2023",
                "作者": " Konrad Abicht",
                "发布日期": "2023-09-14",
                "摘要": "  In a systematic literature and software review over 100 OWL reasoners/systems\nwere analyzed to see if they would still be usable in 2023. This has never been\ndone in this capacity. OWL reasoners still play an important role in knowledge\norganisation and management, but the last comprehensive surveys/studies are\nmore than 8 years old. The result of this work is a comprehensive list of 95\nstandalone OWL reasoners and systems using an OWL reasoner. For each item,\ninformation on project pages, source code repositories and related\ndocumentation was gathered. The raw research data is provided in a Github\nrepository for anyone to use.\n",
                "链接": "https://arxiv.org/abs/2309.06888"
            },
            {
                "文章ID": "91898",
                "标题": "Rob\\^oCIn Small Size League Extended Team Description Paper for RoboCup\n  2023",
                "作者": " Aline Lima de Oliveira,  Cauê Addae da Silva Gomes,  Cecília Virginia Santos da Silva,  Charles Matheus de Sousa Alves,  Danilo Andrade Martins de Souza,  Driele Pires Ferreira Araújo Xavier,  Edgleyson Pereira da Silva,  Felipe Bezerra Martins,  Lucas Henrique Cavalcanti Santos,  Lucas Dias Maciel,  Matheus Paixão Gumercindo dos Santos,  Matheus Lafayette Vasconcelos,  Matheus Vinícius Teotonio do Nascimento Andrade,  João Guilherme Oliveira Carvalho de Melo,  João Pedro Souza Pereira de Moura,  José Ronald da Silva,  José Victor Silva Cruz,  Pedro Henrique Santana de Morais,  Pedro Paulo Salman de Oliveira,  Riei Joaquim Matos Rodrigues,  Roberto Costa Fernandes,  Ryan Vinicius Santos Morais,  Tamara Mayara Ramos Teobaldo,  Washington Igor dos Santos Silva,  Edna Natividade Silva Barros",
                "发布日期": "2023-07-20",
                "摘要": "  Rob\\^oCIn has participated in RoboCup Small Size League since 2019, won its\nfirst world title in 2022 (Division B), and is currently a three-times\nLatin-American champion. This paper presents our improvements to defend the\nSmall Size League (SSL) division B title in RoboCup 2023 in Bordeaux, France.\nThis paper aims to share some of the academic research that our team developed\nover the past year. Our team has successfully published 2 articles related to\nSSL at two high-impact conferences: the 25th RoboCup International Symposium\nand the 19th IEEE Latin American Robotics Symposium (LARS 2022). Over the last\nyear, we have been continuously migrating from our past codebase to\nUnification. We will describe the new architecture implemented and some points\nof software and AI refactoring. In addition, we discuss the process of\nintegrating machined components into the mechanical system, our development for\nparticipating in the vision blackout challenge last year and what we are\npreparing for this year.\n",
                "链接": "https://arxiv.org/abs/2307.10018"
            },
            {
                "文章ID": "84651",
                "标题": "CUED at ProbSum 2023: Hierarchical Ensemble of Summarization Models",
                "作者": " Potsawee Manakul,  Yassir Fathullah,  Adian Liusie,  Vyas Raina,  Vatsal Raina,  Mark Gales",
                "发布日期": "2023-06-09",
                "摘要": "  In this paper, we consider the challenge of summarizing patients' medical\nprogress notes in a limited data setting. For the Problem List Summarization\n(shared task 1A) at the BioNLP Workshop 2023, we demonstrate that Clinical-T5\nfine-tuned to 765 medical clinic notes outperforms other extractive,\nabstractive and zero-shot baselines, yielding reasonable baseline systems for\nmedical note summarization. Further, we introduce Hierarchical Ensemble of\nSummarization Models (HESM), consisting of token-level ensembles of diverse\nfine-tuned Clinical-T5 models, followed by Minimum Bayes Risk (MBR) decoding.\nOur HESM approach lead to a considerable summarization performance boost, and\nwhen evaluated on held-out challenge data achieved a ROUGE-L of 32.77, which\nwas the best-performing system at the top of the shared task leaderboard.\n",
                "链接": "https://arxiv.org/abs/2306.05317"
            },
            {
                "文章ID": "16951",
                "标题": "List-Mode PET Image Reconstruction Using Deep Image Prior",
                "作者": " Kibo Ote,  Fumio Hashimoto,  Yuya Onishi,  Takashi Isobe,  Yasuomi Ouchi",
                "发布日期": "2023-02-10",
                "摘要": "  List-mode positron emission tomography (PET) image reconstruction is an\nimportant tool for PET scanners with many lines-of-response and additional\ninformation such as time-of-flight and depth-of-interaction. Deep learning is\none possible solution to enhance the quality of PET image reconstruction.\nHowever, the application of deep learning techniques to list-mode PET image\nreconstruction has not been progressed because list data is a sequence of bit\ncodes and unsuitable for processing by convolutional neural networks (CNN). In\nthis study, we propose a novel list-mode PET image reconstruction method using\nan unsupervised CNN called deep image prior (DIP) which is the first trial to\nintegrate list-mode PET image reconstruction and CNN. The proposed list-mode\nDIP reconstruction (LM-DIPRecon) method alternatively iterates the regularized\nlist-mode dynamic row action maximum likelihood algorithm (LM-DRAMA) and\nmagnetic resonance imaging conditioned DIP (MR-DIP) using an alternating\ndirection method of multipliers. We evaluated LM-DIPRecon using both simulation\nand clinical data, and it achieved sharper images and better tradeoff curves\nbetween contrast and noise than the LM-DRAMA, MR-DIP and sinogram-based\nDIPRecon methods. These results indicated that the LM-DIPRecon is useful for\nquantitative PET imaging with limited events while keeping accurate raw data\ninformation. In addition, as list data has finer temporal information than\ndynamic sinograms, list-mode deep image prior reconstruction is expected to be\nuseful for 4D PET imaging and motion correction.\n",
                "链接": "https://arxiv.org/abs/2204.13404"
            },
            {
                "文章ID": "70282",
                "标题": "FANS: Fast Non-Autoregressive Sequence Generation for Item List\n  Continuation",
                "作者": " Qijiong Liu,  Jieming Zhu,  Jiahao Wu,  Tiandeng Wu,  Zhenhua Dong,  Xiao-Ming Wu",
                "发布日期": "2023-04-04",
                "摘要": "  User-curated item lists, such as video-based playlists on Youtube and\nbook-based lists on Goodreads, have become prevalent for content sharing on\nonline platforms. Item list continuation is proposed to model the overall trend\nof a list and predict subsequent items. Recently, Transformer-based models have\nshown promise in comprehending contextual information and capturing item\nrelationships in a list. However, deploying them in real-time industrial\napplications is challenging, mainly because the autoregressive generation\nmechanism used in them is time-consuming. In this paper, we propose a novel\nfast non-autoregressive sequence generation model, namely FANS, to enhance\ninference efficiency and quality for item list continuation. First, we use a\nnon-autoregressive generation mechanism to decode next $K$ items simultaneously\ninstead of one by one in existing models. Then, we design a two-stage\nclassifier to replace the vanilla classifier used in current transformer-based\nmodels to further reduce the decoding time. Moreover, to improve the quality of\nnon-autoregressive generation, we employ a curriculum learning strategy to\noptimize training. Experimental results on four real-world item list\ncontinuation datasets including Zhihu, Spotify, AotM, and Goodreads show that\nour FANS model can significantly improve inference efficiency (up to 8.7x)\nwhile achieving competitive or better generation quality for item list\ncontinuation compared with the state-of-the-art autoregressive models. We also\nvalidate the efficiency of FANS in an industrial setting. Our source code and\ndata will be available at MindSpore/models and Github.\n",
                "链接": "https://arxiv.org/abs/2304.00545"
            },
            {
                "文章ID": "54687",
                "标题": "Learning List-Level Domain-Invariant Representations for Ranking",
                "作者": " Ruicheng Xian,  Honglei Zhuang,  Zhen Qin,  Hamed Zamani,  Jing Lu,  Ji Ma,  Kai Hui,  Han Zhao,  Xuanhui Wang,  Michael Bendersky",
                "发布日期": "2023-11-01",
                "摘要": "  Domain adaptation aims to transfer the knowledge learned on (data-rich)\nsource domains to (low-resource) target domains, and a popular method is\ninvariant representation learning, which matches and aligns the data\ndistributions on the feature space. Although this method is studied extensively\nand applied on classification and regression problems, its adoption on ranking\nproblems is sporadic, and the few existing implementations lack theoretical\njustifications. This paper revisits invariant representation learning for\nranking. Upon reviewing prior work, we found that they implement what we call\nitem-level alignment, which aligns the distributions of the items being ranked\nfrom all lists in aggregate but ignores their list structure. However, the list\nstructure should be leveraged, because it is intrinsic to ranking problems\nwhere the data and the metrics are defined and computed on lists, not the items\nby themselves. To close this discrepancy, we propose list-level alignment --\nlearning domain-invariant representations at the higher level of lists. The\nbenefits are twofold: it leads to the first domain adaptation generalization\nbound for ranking, in turn providing theoretical support for the proposed\nmethod, and it achieves better empirical transfer performance for unsupervised\ndomain adaptation on ranking tasks, including passage reranking.\n",
                "链接": "https://arxiv.org/abs/2212.10764"
            }
        ]
    },
    {
        "question": {
            "question": "请列出近一年来工业界发表的搜广推工作落地实践的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "52041",
                "标题": "Time-Synchronized Full System State Estimation Considering Practical\n  Implementation Challenges",
                "作者": " Antos Cheeramban Varghese,  Hritik Shah,  Behrouz Azimian,  Anamitra Pal,  Evangelos Farantatos",
                "发布日期": "2023-08-17",
                "摘要": "  As phasor measurement units (PMUs) are usually placed on the highest voltage\nbuses, many lower voltage levels of the bulk power system are not observed by\nthem. This lack of visibility makes time-synchronized state estimation of the\nfull system a challenging problem. We propose a Deep Neural network-based State\nEstimator (DeNSE) to overcome this problem. The DeNSE employs a Bayesian\nframework to indirectly combine inferences drawn from slow timescale but\nwidespread supervisory control and data acquisition (SCADA) data with fast\ntimescale but local PMU data to attain sub-second situational awareness of the\nentire system. The practical utility of the proposed approach is demonstrated\nby considering topology changes, non-Gaussian measurement noise, and bad data\ndetection and correction. The results obtained using the IEEE 118-bus system\nshow the superiority of the DeNSE over a purely SCADA state estimator, a\nSCADA-PMU hybrid state estimator, and a PMU-only linear state estimator from a\ntechno-economic viability perspective. Lastly, the scalability of the DeNSE is\nproven by performing state estimation on a large and realistic 2000-bus\nSynthetic Texas system.\n",
                "链接": "https://arxiv.org/abs/2212.01729"
            },
            {
                "文章ID": "72359",
                "标题": "Unsupervised ANN-Based Equalizer and Its Trainable FPGA Implementation",
                "作者": " Jonas Ney,  Vincent Lauinger,  Laurent Schmalen,  Norbert Wehn",
                "发布日期": "2023-07-31",
                "摘要": "  In recent years, communication engineers put strong emphasis on artificial\nneural network (ANN)-based algorithms with the aim of increasing the\nflexibility and autonomy of the system and its components. In this context,\nunsupervised training is of special interest as it enables adaptation without\nthe overhead of transmitting pilot symbols. In this work, we present a novel\nANN-based, unsupervised equalizer and its trainable field programmable gate\narray (FPGA) implementation. We demonstrate that our custom loss function\nallows the ANN to adapt for varying channel conditions, approaching the\nperformance of a supervised baseline. Furthermore, as a first step towards a\npractical communication system, we design an efficient FPGA implementation of\nour proposed algorithm, which achieves a throughput in the order of Gbit/s,\noutperforming a high-performance GPU by a large margin.\n",
                "链接": "https://arxiv.org/abs/2304.06987"
            },
            {
                "文章ID": "86673",
                "标题": "Blockchain-Enabled Federated Learning: A Reference Architecture Design,\n  Implementation, and Verification",
                "作者": " Eunsu Goh,  Dae-Yeol Kim,  Kwangkee Lee,  Suyeong Oh,  Jong-Eui Chae,  Do-Yup Kim",
                "发布日期": "2023-11-27",
                "摘要": "  This paper presents a novel reference architecture for blockchain-enabled\nfederated learning (BCFL), a state-of-the-art approach that amalgamates the\nstrengths of federated learning and blockchain technology.We define smart\ncontract functions, stakeholders and their roles, and the use of interplanetary\nfile system (IPFS) as key components of BCFL and conduct a comprehensive\nanalysis. In traditional centralized federated learning, the selection of local\nnodes and the collection of learning results for each round are merged under\nthe control of a central server. In contrast, in BCFL, all these processes are\nmonitored and managed via smart contracts. Additionally, we propose an\nextension architecture to support both crossdevice and cross-silo federated\nlearning scenarios. Furthermore, we implement and verify the architecture in a\npractical real-world Ethereum development environment. Our BCFL reference\narchitecture provides significant flexibility and extensibility, accommodating\nthe integration of various additional elements, as per specific requirements\nand use cases, thereby rendering it an adaptable solution for a wide range of\nBCFL applications. As a prominent example of extensibility, decentralized\nidentifiers (DIDs) have been employed as an authentication method to introduce\npractical utilization within BCFL. This study not only bridges a crucial gap\nbetween research and practical deployment but also lays a solid foundation for\nfuture explorations in the realm of BCFL. The pivotal contribution of this\nstudy is the successful implementation and verification of a realistic BCFL\nreference architecture. We intend to make the source code publicly accessible\nshortly, fostering further advancements and adaptations within the community.\n",
                "链接": "https://arxiv.org/abs/2306.10841"
            },
            {
                "文章ID": "44609",
                "标题": "Implementation of Trained Factorization Machine Recommendation System on\n  Quantum Annealer",
                "作者": " Chen-Yu Liu,  Hsin-Yu Wang,  Pei-Yen Liao,  Ching-Jui Lai,  Min-Hsiu Hsieh",
                "发布日期": "2023-11-09",
                "摘要": "  Factorization Machine (FM) is the most commonly used model to build a\nrecommendation system since it can incorporate side information to improve\nperformance. However, producing item suggestions for a given user with a\ntrained FM is time-consuming. It requires a run-time of $O((N_m \\log N_m)^2)$,\nwhere $N_m$ is the number of items in the dataset. To address this problem, we\npropose a quadratic unconstrained binary optimization (QUBO) scheme to combine\nwith FM and apply quantum annealing (QA) computation. Compared to classical\nmethods, this hybrid algorithm provides a faster than quadratic speedup in\nfinding good user suggestions. We then demonstrate the aforementioned\ncomputational advantage on current NISQ hardware by experimenting with a real\nexample on a D-Wave annealer.\n",
                "链接": "https://arxiv.org/abs/2210.12953"
            },
            {
                "文章ID": "86810",
                "标题": "Decentralized Quantum Federated Learning for Metaverse: Analysis, Design\n  and Implementation",
                "作者": " Dev Gurung,  Shiva Raj Pokhrel,  Gang Li",
                "发布日期": "2023-06-21",
                "摘要": "  With the emerging developments of the Metaverse, a virtual world where people\ncan interact, socialize, play, and conduct their business, it has become\ncritical to ensure that the underlying systems are transparent, secure, and\ntrustworthy. To this end, we develop a decentralized and trustworthy quantum\nfederated learning (QFL) framework. The proposed QFL leverages the power of\nblockchain to create a secure and transparent system that is robust against\ncyberattacks and fraud. In addition, the decentralized QFL system addresses the\nrisks associated with a centralized server-based approach. With extensive\nexperiments and analysis, we evaluate classical federated learning (CFL) and\nQFL in a distributed setting and demonstrate the practicality and benefits of\nthe proposed design. Our theoretical analysis and discussions develop a\ngenuinely decentralized financial system essential for the Metaverse.\nFurthermore, we present the application of blockchain-based QFL in a hybrid\nmetaverse powered by a metaverse observer and world model. Our implementation\ndetails and code are publicly available 1.\n",
                "链接": "https://arxiv.org/abs/2306.11297"
            },
            {
                "文章ID": "125018",
                "标题": "GreenFlow: A Computation Allocation Framework for Building\n  Environmentally Sound Recommendation System",
                "作者": " Xingyu Lu,  Zhining Liu,  Yanchu Guan,  Hongxuan Zhang,  Chenyi Zhuang,  Wenqi Ma,  Yize Tan,  Jinjie Gu,  Guannan Zhang",
                "发布日期": "2023-12-29",
                "摘要": "  Given the enormous number of users and items, industrial cascade\nrecommendation systems (RS) are continuously expanded in size and complexity to\ndeliver relevant items, such as news, services, and commodities, to the\nappropriate users. In a real-world scenario with hundreds of thousands requests\nper second, significant computation is required to infer personalized results\nfor each request, resulting in a massive energy consumption and carbon emission\nthat raises concern.\n  This paper proposes GreenFlow, a practical computation allocation framework\nfor RS, that considers both accuracy and carbon emission during inference. For\neach stage (e.g., recall, pre-ranking, ranking, etc.) of a cascade RS, when a\nuser triggers a request, we define two actions that determine the computation:\n(1) the trained instances of models with different computational complexity;\nand (2) the number of items to be inferred in the stage. We refer to the\ncombinations of actions in all stages as action chains. A reward score is\nestimated for each action chain, followed by dynamic primal-dual optimization\nconsidering both the reward and computation budget. Extensive experiments\nverify the effectiveness of the framework, reducing computation consumption by\n41% in an industrial mobile application while maintaining commercial revenue.\nMoreover, the proposed framework saves approximately 5000kWh of electricity and\nreduces 3 tons of carbon emissions per day.\n",
                "链接": "https://arxiv.org/abs/2312.16176"
            },
            {
                "文章ID": "85520",
                "标题": "KuaiSAR: A Unified Search And Recommendation Dataset",
                "作者": " Zhongxiang Sun,  Zihua Si,  Xiaoxue Zang,  Dewei Leng,  Yanan Niu,  Yang Song,  Xiao Zhang,  Jun Xu",
                "发布日期": "2023-12-22",
                "摘要": "  The confluence of Search and Recommendation (S&R) services is vital to online\nservices, including e-commerce and video platforms. The integration of S&R\nmodeling is a highly intuitive approach adopted by industry practitioners.\nHowever, there is a noticeable lack of research conducted in this area within\nacademia, primarily due to the absence of publicly available datasets.\nConsequently, a substantial gap has emerged between academia and industry\nregarding research endeavors in joint optimization using user behavior data\nfrom both S&R services. To bridge this gap, we introduce the first large-scale,\nreal-world dataset KuaiSAR of integrated Search And Recommendation behaviors\ncollected from Kuaishou, a leading short-video app in China with over 350\nmillion daily active users. Previous research in this field has predominantly\nemployed publicly available semi-synthetic datasets and simulated, with\nartificially fabricated search behaviors. Distinct from previous datasets,\nKuaiSAR contains genuine user behaviors, including the occurrence of each\ninteraction within either search or recommendation service, and the users'\ntransitions between the two services. This work aids in joint modeling of S&R,\nand utilizing search data for recommender systems (and recommendation data for\nsearch engines). Furthermore, due to the various feedback labels associated\nwith user-video interactions, KuaiSAR also supports a broad range of tasks,\nincluding intent recommendation, multi-task learning, and modeling of long\nsequential multi-behavioral patterns. We believe this dataset will serve as a\ncatalyst for innovative research and bridge the gap between academia and\nindustry in understanding the S&R services in practical, real-world\napplications.\n",
                "链接": "https://arxiv.org/abs/2306.07705"
            },
            {
                "文章ID": "112399",
                "标题": "Stochastic Configuration Machines: FPGA Implementation",
                "作者": " Matthew J. Felicetti,  Dianhui Wang",
                "发布日期": "2023-10-31",
                "摘要": "  Neural networks for industrial applications generally have additional\nconstraints such as response speed, memory size and power usage. Randomized\nlearners can address some of these issues. However, hardware solutions can\nprovide better resource reduction whilst maintaining the model's performance.\nStochastic configuration networks (SCNs) are a prime choice in industrial\napplications due to their merits and feasibility for data modelling. Stochastic\nConfiguration Machines (SCMs) extend this to focus on reducing the memory\nconstraints by limiting the randomized weights to a binary value with a scalar\nfor each node and using a mechanism model to improve the learning performance\nand result interpretability. This paper aims to implement SCM models on a field\nprogrammable gate array (FPGA) and introduce binary-coded inputs to the\nalgorithm. Results are reported for two benchmark and two industrial datasets,\nincluding SCM with single-layer and deep architectures.\n",
                "链接": "https://arxiv.org/abs/2310.19225"
            },
            {
                "文章ID": "121744",
                "标题": "Examining the Effect of Implementation Factors on Deep Learning\n  Reproducibility",
                "作者": " Kevin Coakley,  Christine R. Kirkpatrick,  Odd Erik Gundersen",
                "发布日期": "2023-12-12",
                "摘要": "  Reproducing published deep learning papers to validate their conclusions can\nbe difficult due to sources of irreproducibility. We investigate the impact\nthat implementation factors have on the results and how they affect\nreproducibility of deep learning studies. Three deep learning experiments were\nran five times each on 13 different hardware environments and four different\nsoftware environments. The analysis of the 780 combined results showed that\nthere was a greater than 6% accuracy range on the same deterministic examples\nintroduced from hardware or software environment variations alone. To account\nfor these implementation factors, researchers should run their experiments\nmultiple times in different hardware and software environments to verify their\nconclusions are not affected.\n",
                "链接": "https://arxiv.org/abs/2312.06633"
            },
            {
                "文章ID": "100694",
                "标题": "Retail store customer behavior analysis system: Design and\n  Implementation",
                "作者": " Tuan Dinh Nguyen,  Keisuke Hihara,  Tung Cao Hoang,  Yumeka Utada,  Akihiko Torii,  Naoki Izumi,  Nguyen Thanh Thuy,  Long Quoc Tran",
                "发布日期": "2023-09-08",
                "摘要": "  Understanding customer behavior in retail stores plays a crucial role in\nimproving customer satisfaction by adding personalized value to services.\nBehavior analysis reveals both general and detailed patterns in the interaction\nof customers with a store items and other people, providing store managers with\ninsight into customer preferences. Several solutions aim to utilize this data\nby recognizing specific behaviors through statistical visualization. However,\ncurrent approaches are limited to the analysis of small customer behavior sets,\nutilizing conventional methods to detect behaviors. They do not use deep\nlearning techniques such as deep neural networks, which are powerful methods in\nthe field of computer vision. Furthermore, these methods provide limited\nfigures when visualizing the behavioral data acquired by the system. In this\nstudy, we propose a framework that includes three primary parts: mathematical\nmodeling of customer behaviors, behavior analysis using an efficient deep\nlearning based system, and individual and group behavior visualization. Each\nmodule and the entire system were validated using data from actual situations\nin a retail store.\n",
                "链接": "https://arxiv.org/abs/2309.03232"
            }
        ]
    },
    {
        "question": {
            "question": "闭源大模型用户数据隐私保护研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "106181",
                "标题": "Large Language Models Can Be Good Privacy Protection Learners",
                "作者": " Yijia Xiao,  Yiqiao Jin,  Yushi Bai,  Yue Wu,  Xianjun Yang,  Xiao Luo,  Wenchao Yu,  Xujiang Zhao,  Yanchi Liu,  Haifeng Chen,  Wei Wang,  Wei Cheng",
                "发布日期": "2023-10-10",
                "摘要": "  The proliferation of Large Language Models (LLMs) has driven considerable\ninterest in fine-tuning them with domain-specific data to create specialized\nlanguage models. Nevertheless, such domain-specific fine-tuning data often\ncontains sensitive personally identifiable information (PII). Direct\nfine-tuning LLMs on this data without privacy protection poses a risk of\nleakage. To address this challenge, we introduce Privacy Protection Language\nModels (PPLM), a novel paradigm for fine-tuning LLMs that effectively injects\ndomain-specific knowledge while safeguarding data privacy. Our work offers a\ntheoretical analysis for model design and delves into various techniques such\nas corpus curation, penalty-based unlikelihood in training loss, and\ninstruction-based tuning, etc. Extensive experiments across diverse datasets\nand scenarios demonstrate the effectiveness of our approaches. In particular,\ninstruction tuning with both positive and negative examples, stands out as a\npromising method, effectively protecting private data while enhancing the\nmodel's knowledge. Our work underscores the potential for Large Language Models\nas robust privacy protection learners.\n",
                "链接": "https://arxiv.org/abs/2310.02469"
            },
            {
                "文章ID": "85712",
                "标题": "Protecting User Privacy in Remote Conversational Systems: A\n  Privacy-Preserving framework based on text sanitization",
                "作者": " Zhigang Kan,  Linbo Qiao,  Hao Yu,  Liwen Peng,  Yifu Gao,  Dongsheng Li",
                "发布日期": "2023-06-16",
                "摘要": "  Large Language Models (LLMs) are gaining increasing attention due to their\nexceptional performance across numerous tasks. As a result, the general public\nutilize them as an influential tool for boosting their productivity while\nnatural language processing researchers endeavor to employ them in solving\nexisting or new research problems. Unfortunately, individuals can only access\nsuch powerful AIs through APIs, which ultimately leads to the transmission of\nraw data to the models' providers and increases the possibility of privacy data\nleakage. Current privacy-preserving methods for cloud-deployed language models\naim to protect privacy information in the pre-training dataset or during the\nmodel training phase. However, they do not meet the specific challenges\npresented by the remote access approach of new large-scale language models.\n  This paper introduces a novel task, \"User Privacy Protection for Dialogue\nModels,\" which aims to safeguard sensitive user information from any possible\ndisclosure while conversing with chatbots. We also present an evaluation scheme\nfor this task, which covers evaluation metrics for privacy protection, data\navailability, and resistance to simulation attacks. Moreover, we propose the\nfirst framework for this task, namely privacy protection through text\nsanitization. Before sending the input to remote large models, it filters out\nthe sensitive information, using several rounds of text sanitization based on\nprivacy types that users define. Upon receiving responses from the larger\nmodel, our framework automatically restores privacy to ensure that the\nconversation goes smoothly, without intervention from the privacy filter.\nExperiments based on real-world datasets demonstrate the efficacy of our\nprivacy-preserving approach against eavesdropping from potential attackers.\n",
                "链接": "https://arxiv.org/abs/2306.08223"
            },
            {
                "文章ID": "5282",
                "标题": "Privacy protection based on mask template",
                "作者": " Hao Wang,  Yu Bai,  Guangmin Sun,  Jie Liu",
                "发布日期": "2022-02-15",
                "摘要": "  Powerful recognition algorithms are widely used in the Internet or important\nmedical systems, which poses a serious threat to personal privacy. Although the\nlaw provides for diversity protection, e.g. The General Data Protection\nRegulation (GDPR) in Europe and Articles 1032 to 1039 of the civil code in\nChina. However, as an important privacy disclosure event, biometric data is\noften hidden, which is difficult for the owner to detect and trace to the\nsource. Human biometrics generally exist in images. In order to avoid the\ndisclosure of personal privacy, we should prevent unauthorized recognition\nalgorithms from acquiring the real features of the original image.\n",
                "链接": "https://arxiv.org/abs/2202.06250"
            },
            {
                "文章ID": "98333",
                "标题": "Harnessing the Power of David against Goliath: Exploring Instruction\n  Data Generation without Using Closed-Source Models",
                "作者": " Yue Wang,  Xinrui Wang,  Juntao Li,  Jinxiong Chang,  Qishen Zhang,  Zhongyi Liu,  Guannan Zhang,  Min Zhang",
                "发布日期": "2023-08-25",
                "摘要": "  Instruction tuning is instrumental in enabling Large Language Models~(LLMs)\nto follow user instructions to complete various open-domain tasks. The success\nof instruction tuning depends on the availability of high-quality instruction\ndata. Owing to the exorbitant cost and substandard quality of human annotation,\nrecent works have been deeply engaged in the exploration of the utilization of\npowerful closed-source models to generate instruction data automatically.\nHowever, these methods carry potential risks arising from the usage\nrequirements of powerful closed-source models, which strictly forbid the\nutilization of their outputs to develop machine learning models. To deal with\nthis problem, in this work, we explore alternative approaches to generate\nhigh-quality instruction data that do not rely on closed-source models. Our\nexploration includes an investigation of various existing instruction\ngeneration methods, culminating in the integration of the most efficient\nvariant with two novel strategies to enhance the quality further. Evaluation\nresults from two benchmarks and the GPT-4 model demonstrate the effectiveness\nof our generated instruction data, which can outperform Alpaca, a method\nreliant on closed-source models. We hope that more progress can be achieved in\ngenerating high-quality instruction data without using closed-source models.\n",
                "链接": "https://arxiv.org/abs/2308.12711"
            },
            {
                "文章ID": "46467",
                "标题": "User-Entity Differential Privacy in Learning Natural Language Models",
                "作者": " Phung Lai,  NhatHai Phan,  Tong Sun,  Rajiv Jain,  Franck Dernoncourt,  Jiuxiang Gu,  Nikolaos Barmpalios",
                "发布日期": "2022-11-10",
                "摘要": "  In this paper, we introduce a novel concept of user-entity differential\nprivacy (UeDP) to provide formal privacy protection simultaneously to both\nsensitive entities in textual data and data owners in learning natural language\nmodels (NLMs). To preserve UeDP, we developed a novel algorithm, called\nUeDP-Alg, optimizing the trade-off between privacy loss and model utility with\na tight sensitivity bound derived from seamlessly combining user and sensitive\nentity sampling processes. An extensive theoretical analysis and evaluation\nshow that our UeDP-Alg outperforms baseline approaches in model utility under\nthe same privacy budget consumption on several NLM tasks, using benchmark\ndatasets.\n",
                "链接": "https://arxiv.org/abs/2211.01141"
            },
            {
                "文章ID": "84894",
                "标题": "SoK: Analysis of User-Centered Studies Focusing on Healthcare Privacy &\n  Security",
                "作者": " Faiza Tazi,  Archana Nandakumar,  Josiah Dykstra,  Prashanth Rajivan,  Sanchari Das",
                "发布日期": "2023-06-27",
                "摘要": "  Sensitive information is intrinsically tied to interactions in healthcare,\nand its protection is of paramount importance for achieving high-quality\npatient outcomes. Research in healthcare privacy and security is predominantly\nfocused on understanding the factors that increase the susceptibility of users\nto privacy and security breaches. To understand further, we systematically\nreview 26 research papers in this domain to explore the existing user studies\nin healthcare privacy and security. Following the review, we conducted a\ncard-sorting exercise, allowing us to identify 12 themes integral to this\nsubject such as \"Data Sharing,\" \"Risk Awareness,\" and \"Privacy.\" Further to the\nidentification of these themes, we performed an in-depth analysis of the 26\nresearch papers report on the insights into the discourse within the research\ncommunity about healthcare privacy and security, particularly from the user\nperspective.\n",
                "链接": "https://arxiv.org/abs/2306.06033"
            },
            {
                "文章ID": "18379",
                "标题": "Decentralized Stochastic Optimization with Inherent Privacy Protection",
                "作者": " Yongqiang Wang,  H. Vincent Poor",
                "发布日期": "2022-05-10",
                "摘要": "  Decentralized stochastic optimization is the basic building block of modern\ncollaborative machine learning, distributed estimation and control, and\nlarge-scale sensing. Since involved data usually contain sensitive information\nlike user locations, healthcare records and financial transactions, privacy\nprotection has become an increasingly pressing need in the implementation of\ndecentralized stochastic optimization algorithms. In this paper, we propose a\ndecentralized stochastic gradient descent algorithm which is embedded with\ninherent privacy protection for every participating agent against other\nparticipating agents and external eavesdroppers. This proposed algorithm builds\nin a dynamics based gradient-obfuscation mechanism to enable privacy protection\nwithout compromising optimization accuracy, which is in significant difference\nfrom differential-privacy based privacy solutions for decentralized\noptimization that have to trade optimization accuracy for privacy. The dynamics\nbased privacy approach is encryption-free, and hence avoids incurring heavy\ncommunication or computation overhead, which is a common problem with\nencryption based privacy solutions for decentralized stochastic optimization.\nBesides rigorously characterizing the convergence performance of the proposed\ndecentralized stochastic gradient descent algorithm under both convex objective\nfunctions and non-convex objective functions, we also provide rigorous\ninformation-theoretic analysis of its strength of privacy protection.\nSimulation results for a distributed estimation problem as well as numerical\nexperiments for decentralized learning on a benchmark machine learning dataset\nconfirm the effectiveness of the proposed approach.\n",
                "链接": "https://arxiv.org/abs/2205.03884"
            },
            {
                "文章ID": "76520",
                "标题": "Leveraging Generative AI Models for Synthetic Data Generation in\n  Healthcare: Balancing Research and Privacy",
                "作者": " Aryan Jadon,  Shashank Kumar",
                "发布日期": "2023-11-15",
                "摘要": "  The widespread adoption of electronic health records and digital healthcare\ndata has created a demand for data-driven insights to enhance patient outcomes,\ndiagnostics, and treatments. However, using real patient data presents privacy\nand regulatory challenges, including compliance with HIPAA and GDPR. Synthetic\ndata generation, using generative AI models like GANs and VAEs offers a\npromising solution to balance valuable data access and patient privacy\nprotection. In this paper, we examine generative AI models for creating\nrealistic, anonymized patient data for research and training, explore synthetic\ndata applications in healthcare, and discuss its benefits, challenges, and\nfuture research directions. Synthetic data has the potential to revolutionize\nhealthcare by providing anonymized patient data while preserving privacy and\nenabling versatile applications.\n",
                "链接": "https://arxiv.org/abs/2305.05247"
            },
            {
                "文章ID": "36589",
                "标题": "Privacy of Autonomous Vehicles: Risks, Protection Methods, and Future\n  Directions",
                "作者": " Chulin Xie,  Zhong Cao,  Yunhui Long,  Diange Yang,  Ding Zhao,  Bo Li",
                "发布日期": "2022-09-12",
                "摘要": "  Recent advances in machine learning have enabled its wide application in\ndifferent domains, and one of the most exciting applications is autonomous\nvehicles (AVs), which have encouraged the development of a number of ML\nalgorithms from perception to prediction to planning. However, training AVs\nusually requires a large amount of training data collected from different\ndriving environments (e.g., cities) as well as different types of personal\ninformation (e.g., working hours and routes). Such collected large data,\ntreated as the new oil for ML in the data-centric AI era, usually contains a\nlarge amount of privacy-sensitive information which is hard to remove or even\naudit. Although existing privacy protection approaches have achieved certain\ntheoretical and empirical success, there is still a gap when applying them to\nreal-world applications such as autonomous vehicles. For instance, when\ntraining AVs, not only can individually identifiable information reveal\nprivacy-sensitive information, but also population-level information such as\nroad construction within a city, and proprietary-level commercial secrets of\nAVs. Thus, it is critical to revisit the frontier of privacy risks and\ncorresponding protection approaches in AVs to bridge this gap. Following this\ngoal, in this work, we provide a new taxonomy for privacy risks and protection\nmethods in AVs, and we categorize privacy in AVs into three levels: individual,\npopulation, and proprietary. We explicitly list out recent challenges to\nprotect each of these levels of privacy, summarize existing solutions to these\nchallenges, discuss the lessons and conclusions, and provide potential future\ndirections and opportunities for both researchers and practitioners. We believe\nthis work will help to shape the privacy research in AV and guide the privacy\nprotection technology design.\n",
                "链接": "https://arxiv.org/abs/2209.04022"
            },
            {
                "文章ID": "20866",
                "标题": "OPOM: Customized Invisible Cloak towards Face Privacy Protection",
                "作者": " Yaoyao Zhong,  Weihong Deng",
                "发布日期": "2022-05-25",
                "摘要": "  While convenient in daily life, face recognition technologies also raise\nprivacy concerns for regular users on the social media since they could be used\nto analyze face images and videos, efficiently and surreptitiously without any\nsecurity restrictions. In this paper, we investigate the face privacy\nprotection from a technology standpoint based on a new type of customized\ncloak, which can be applied to all the images of a regular user, to prevent\nmalicious face recognition systems from uncovering their identity.\nSpecifically, we propose a new method, named one person one mask (OPOM), to\ngenerate person-specific (class-wise) universal masks by optimizing each\ntraining sample in the direction away from the feature subspace of the source\nidentity. To make full use of the limited training images, we investigate\nseveral modeling methods, including affine hulls, class centers, and convex\nhulls, to obtain a better description of the feature subspace of source\nidentities. The effectiveness of the proposed method is evaluated on both\ncommon and celebrity datasets against black-box face recognition models with\ndifferent loss functions and network architectures. In addition, we discuss the\nadvantages and potential problems of the proposed method. In particular, we\nconduct an application study on the privacy protection of a video dataset,\nSherlock, to demonstrate the potential practical usage of the proposed method.\nDatasets and code are available at https://github.com/zhongyy/OPOM.\n",
                "链接": "https://arxiv.org/abs/2205.11981"
            }
        ]
    },
    {
        "question": {
            "question": "推荐与AutoGPT相似的10篇文献",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "86417",
                "标题": "AD-AutoGPT: An Autonomous GPT for Alzheimer's Disease Infodemiology",
                "作者": " Haixing Dai,  Yiwei Li,  Zhengliang Liu,  Lin Zhao,  Zihao Wu,  Suhang Song,  Ye Shen,  Dajiang Zhu,  Xiang Li,  Sheng Li,  Xiaobai Yao,  Lu Shi,  Quanzheng Li,  Zhuo Chen,  Donglan Zhang,  Gengchen Mai,  Tianming Liu",
                "发布日期": "2023-06-21",
                "摘要": "  In this pioneering study, inspired by AutoGPT, the state-of-the-art\nopen-source application based on the GPT-4 large language model, we develop a\nnovel tool called AD-AutoGPT which can conduct data collection, processing, and\nanalysis about complex health narratives of Alzheimer's Disease in an\nautonomous manner via users' textual prompts. We collated comprehensive data\nfrom a variety of news sources, including the Alzheimer's Association, BBC,\nMayo Clinic, and the National Institute on Aging since June 2022, leading to\nthe autonomous execution of robust trend analyses, intertopic distance maps\nvisualization, and identification of salient terms pertinent to Alzheimer's\nDisease. This approach has yielded not only a quantifiable metric of relevant\ndiscourse but also valuable insights into public focus on Alzheimer's Disease.\nThis application of AD-AutoGPT in public health signifies the transformative\npotential of AI in facilitating a data-rich understanding of complex health\nnarratives like Alzheimer's Disease in an autonomous manner, setting the\ngroundwork for future AI-driven investigations in global health landscapes.\n",
                "链接": "https://arxiv.org/abs/2306.10095"
            },
            {
                "文章ID": "63484",
                "标题": "AugGPT: Leveraging ChatGPT for Text Data Augmentation",
                "作者": " Haixing Dai,  Zhengliang Liu,  Wenxiong Liao,  Xiaoke Huang,  Yihan Cao,  Zihao Wu,  Lin Zhao,  Shaochen Xu,  Wei Liu,  Ninghao Liu,  Sheng Li,  Dajiang Zhu,  Hongmin Cai,  Lichao Sun,  Quanzheng Li,  Dinggang Shen,  Tianming Liu,  Xiang Li",
                "发布日期": "2023-03-21",
                "摘要": "  Text data augmentation is an effective strategy for overcoming the challenge\nof limited sample sizes in many natural language processing (NLP) tasks. This\nchallenge is especially prominent in the few-shot learning scenario, where the\ndata in the target domain is generally much scarcer and of lowered quality. A\nnatural and widely-used strategy to mitigate such challenges is to perform data\naugmentation to better capture the data invariance and increase the sample\nsize. However, current text data augmentation methods either can't ensure the\ncorrect labeling of the generated data (lacking faithfulness) or can't ensure\nsufficient diversity in the generated data (lacking compactness), or both.\nInspired by the recent success of large language models, especially the\ndevelopment of ChatGPT, which demonstrated improved language comprehension\nabilities, in this work, we propose a text data augmentation approach based on\nChatGPT (named AugGPT). AugGPT rephrases each sentence in the training samples\ninto multiple conceptually similar but semantically different samples. The\naugmented samples can then be used in downstream model training. Experiment\nresults on few-shot learning text classification tasks show the superior\nperformance of the proposed AugGPT approach over state-of-the-art text data\naugmentation methods in terms of testing accuracy and distribution of the\naugmented samples.\n",
                "链接": "https://arxiv.org/abs/2302.13007"
            },
            {
                "文章ID": "96648",
                "标题": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
                "作者": " Qingyun Wu,  Gagan Bansal,  Jieyu Zhang,  Yiran Wu,  Beibin Li,  Erkang Zhu,  Li Jiang,  Xiaoyun Zhang,  Shaokun Zhang,  Jiale Liu,  Ahmed Hassan Awadallah,  Ryen W White,  Doug Burger,  Chi Wang",
                "发布日期": "2023-10-05",
                "摘要": "  AutoGen is an open-source framework that allows developers to build LLM\napplications via multiple agents that can converse with each other to\naccomplish tasks. AutoGen agents are customizable, conversable, and can operate\nin various modes that employ combinations of LLMs, human inputs, and tools.\nUsing AutoGen, developers can also flexibly define agent interaction behaviors.\nBoth natural language and computer code can be used to program flexible\nconversation patterns for different applications. AutoGen serves as a generic\ninfrastructure to build diverse applications of various complexities and LLM\ncapacities. Empirical studies demonstrate the effectiveness of the framework in\nmany example applications, with domains ranging from mathematics, coding,\nquestion answering, operations research, online decision-making, entertainment,\netc.\n",
                "链接": "https://arxiv.org/abs/2308.08155"
            },
            {
                "文章ID": "74264",
                "标题": "AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking\n  Head",
                "作者": " Rongjie Huang,  Mingze Li,  Dongchao Yang,  Jiatong Shi,  Xuankai Chang,  Zhenhui Ye,  Yuning Wu,  Zhiqing Hong,  Jiawei Huang,  Jinglin Liu,  Yi Ren,  Zhou Zhao,  Shinji Watanabe",
                "发布日期": "2023-04-26",
                "摘要": "  Large language models (LLMs) have exhibited remarkable capabilities across a\nvariety of domains and tasks, challenging our understanding of learning and\ncognition. Despite the recent success, current LLMs are not capable of\nprocessing complex audio information or conducting spoken conversations (like\nSiri or Alexa). In this work, we propose a multi-modal AI system named\nAudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to\nprocess complex audio information and solve numerous understanding and\ngeneration tasks; and 2) the input/output interface (ASR, TTS) to support\nspoken dialogue. With an increasing demand to evaluate multi-modal LLMs of\nhuman intention understanding and cooperation with foundation models, we\noutline the principles and processes and test AudioGPT in terms of consistency,\ncapability, and robustness. Experimental results demonstrate the capabilities\nof AudioGPT in solving AI tasks with speech, music, sound, and talking head\nunderstanding and generation in multi-round dialogues, which empower humans to\ncreate rich and diverse audio content with unprecedented ease. Our system is\npublicly available at \\url{https://github.com/AIGC-Audio/AudioGPT}.\n",
                "链接": "https://arxiv.org/abs/2304.12995"
            },
            {
                "文章ID": "13182",
                "标题": "AutoOpt: A General Framework for Automatically Designing Metaheuristic\n  Optimization Algorithms with Diverse Structures",
                "作者": " Qi Zhao,  Bai Yan,  Xianglong Chen,  Taiwei Hu,  Shi Cheng,  Yuhui Shi",
                "发布日期": "2023-05-05",
                "摘要": "  Metaheuristics are widely recognized gradient-free solvers to hard problems\nthat do not meet the rigorous mathematical assumptions of conventional solvers.\nThe automated design of metaheuristic algorithms provides an attractive path to\nrelieve manual design effort and gain enhanced performance beyond human-made\nalgorithms. However, the specific algorithm prototype and linear algorithm\nrepresentation in the current automated design pipeline restrict the design\nwithin a fixed algorithm structure, which hinders discovering novelties and\ndiversity across the metaheuristic family. To address this challenge, this\npaper proposes a general framework, AutoOpt, for automatically designing\nmetaheuristic algorithms with diverse structures. AutoOpt contains three\ninnovations: (i) A general algorithm prototype dedicated to covering the\nmetaheuristic family as widely as possible. It promotes high-quality automated\ndesign on different problems by fully discovering potentials and novelties\nacross the family. (ii) A directed acyclic graph algorithm representation to\nfit the proposed prototype. Its flexibility and evolvability enable discovering\nvarious algorithm structures in a single run of design, thus boosting the\npossibility of finding high-performance algorithms. (iii) A graph\nrepresentation embedding method offering an alternative compact form of the\ngraph to be manipulated, which ensures AutoOpt's generality. Experiments on\nnumeral functions and real applications validate AutoOpt's efficiency and\npracticability.\n",
                "链接": "https://arxiv.org/abs/2204.00998"
            },
            {
                "文章ID": "60937",
                "标题": "AutoNMT: A Framework to Streamline the Research of Seq2Seq Models",
                "作者": " Salvador Carrión,  Francisco Casacuberta",
                "发布日期": "2023-02-13",
                "摘要": "  We present AutoNMT, a framework to streamline the research of seq-to-seq\nmodels by automating the data pipeline (i.e., file management, data\npreprocessing, and exploratory analysis), automating experimentation in a\ntoolkit-agnostic manner, which allows users to use either their own models or\nexisting seq-to-seq toolkits such as Fairseq or OpenNMT, and finally,\nautomating the report generation (plots and summaries). Furthermore, this\nlibrary comes with its own seq-to-seq toolkit so that users can easily\ncustomize it for non-standard tasks.\n",
                "链接": "https://arxiv.org/abs/2302.04981"
            },
            {
                "文章ID": "9495",
                "标题": "AutoGPart: Intermediate Supervision Search for Generalizable 3D Part\n  Segmentation",
                "作者": " Xueyi Liu,  Xiaomeng Xu,  Anyi Rao,  Chuang Gan,  Li Yi",
                "发布日期": "2022-04-18",
                "摘要": "  Training a generalizable 3D part segmentation network is quite challenging\nbut of great importance in real-world applications. To tackle this problem,\nsome works design task-specific solutions by translating human understanding of\nthe task to machine's learning process, which faces the risk of missing the\noptimal strategy since machines do not necessarily understand in the exact\nhuman way. Others try to use conventional task-agnostic approaches designed for\ndomain generalization problems with no task prior knowledge considered. To\nsolve the above issues, we propose AutoGPart, a generic method enabling\ntraining generalizable 3D part segmentation networks with the task prior\nconsidered. AutoGPart builds a supervision space with geometric prior knowledge\nencoded, and lets the machine to search for the optimal supervisions from the\nspace for a specific segmentation task automatically. Extensive experiments on\nthree generalizable 3D part segmentation tasks are conducted to demonstrate the\neffectiveness and versatility of AutoGPart. We demonstrate that the performance\nof segmentation networks using simple backbones can be significantly improved\nwhen trained with supervisions searched by our method.\n",
                "链接": "https://arxiv.org/abs/2203.06558"
            },
            {
                "文章ID": "108389",
                "标题": "AutoVP: An Automated Visual Prompting Framework and Benchmark",
                "作者": " Hsi-Ai Tsao,  Lei Hsiung,  Pin-Yu Chen,  Sijia Liu,  Tsung-Yi Ho",
                "发布日期": "2023-10-13",
                "摘要": "  Visual prompting (VP) is an emerging parameter-efficient fine-tuning approach\nto adapting pre-trained vision models to solve various downstream\nimage-classification tasks. However, there has hitherto been little systematic\nstudy of the design space of VP and no clear benchmark for evaluating its\nperformance. To bridge this gap, we propose AutoVP, an end-to-end expandable\nframework for automating VP design choices, along with 12 downstream\nimage-classification tasks that can serve as a holistic VP-performance\nbenchmark. Our design space covers 1) the joint optimization of the prompts; 2)\nthe selection of pre-trained models, including image classifiers and text-image\nencoders; and 3) model output mapping strategies, including nonparametric and\ntrainable label mapping. Our extensive experimental results show that AutoVP\noutperforms the best-known current VP methods by a substantial margin, having\nup to 6.7% improvement in accuracy; and attains a maximum performance increase\nof 27.5% compared to linear-probing (LP) baseline. AutoVP thus makes a two-fold\ncontribution: serving both as an efficient tool for hyperparameter tuning on VP\ndesign choices, and as a comprehensive benchmark that can reasonably be\nexpected to accelerate VP's development. The source code is available at\nhttps://github.com/IBM/AutoVP.\n",
                "链接": "https://arxiv.org/abs/2310.08381"
            },
            {
                "文章ID": "7009",
                "标题": "AutoIP: A United Framework to Integrate Physics into Gaussian Processes",
                "作者": " Da Long,  Zheng Wang,  Aditi Krishnapriyan,  Robert Kirby,  Shandian Zhe,  Michael Mahoney",
                "发布日期": "2022-07-22",
                "摘要": "  Physical modeling is critical for many modern science and engineering\napplications. From a data science or machine learning perspective, where more\ndomain-agnostic, data-driven models are pervasive, physical knowledge -- often\nexpressed as differential equations -- is valuable in that it is complementary\nto data, and it can potentially help overcome issues such as data sparsity,\nnoise, and inaccuracy. In this work, we propose a simple, yet powerful and\ngeneral framework -- AutoIP, for Automatically Incorporating Physics -- that\ncan integrate all kinds of differential equations into Gaussian Processes (GPs)\nto enhance prediction accuracy and uncertainty quantification. These equations\ncan be linear or nonlinear, spatial, temporal, or spatio-temporal, complete or\nincomplete with unknown source terms, and so on. Based on kernel\ndifferentiation, we construct a GP prior to sample the values of the target\nfunction, equation-related derivatives, and latent source functions, which are\nall jointly from a multivariate Gaussian distribution. The sampled values are\nfed to two likelihoods: one to fit the observations, and the other to conform\nto the equation. We use the whitening method to evade the strong dependency\nbetween the sampled function values and kernel parameters, and we develop a\nstochastic variational learning algorithm. AutoIP shows improvement upon\nvanilla GPs in both simulation and several real-world applications, even using\nrough, incomplete equations.\n",
                "链接": "https://arxiv.org/abs/2202.12316"
            },
            {
                "文章ID": "91419",
                "标题": "BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs",
                "作者": " Yang Zhao,  Zhijie Lin,  Daquan Zhou,  Zilong Huang,  Jiashi Feng,  Bingyi Kang",
                "发布日期": "2023-07-18",
                "摘要": "  LLMs have demonstrated remarkable abilities at interacting with humans\nthrough language, especially with the usage of instruction-following data.\nRecent advancements in LLMs, such as MiniGPT-4, LLaVA, and X-LLM, further\nenlarge their abilities by incorporating multi-modal inputs, including image,\nvideo, and speech. Despite their effectiveness at generating precise and\ndetailed language understanding of the given modality signal, these LLMs give\nup the ability to ground specific parts of inputs, thus only constructing a\ncoarse-grained mapping. However, explicit and informative correspondence\nbetween text and other modalities will not only improve the user experience but\nalso help to expand the application scenario of multi-modal LLMs. Therefore, we\npropose BuboGPT, a multi-modal LLM with visual grounding that can perform\ncross-modal interaction between vision, audio and language, providing\nfine-grained understanding of visual objects and other given modalities. As a\nresult, BuboGPT is able to point out the specific location of an object in the\nimage, when it is generating response or description for that object. Our\ncontributions are two-fold: 1) An off-the-shelf visual grounding module based\non SAM that extracts entities in a sentence and find corresponding masks in the\nimage. 2) A two-stage training scheme and instruction dataset to endow joint\ntext-image-audio understanding. Our experiments show that BuboGPT achieves\nimpressive multi-modality understanding and visual grounding abilities during\nthe interaction with human. It performs consistently well when provided by\narbitrary modality combinations (either aligned or unaligned). Our code, model\nand dataset are available at https://bubo-gpt.github.io .\n",
                "链接": "https://arxiv.org/abs/2307.08581"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究，特别关注使用自动标注和迁移学习方法的论文，时间跨度覆盖2019年至今。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "34051",
                "标题": "PyMIC: A deep learning toolkit for annotation-efficient medical image\n  segmentation",
                "作者": " Guotai Wang,  Xiangde Luo,  Ran Gu,  Shuojue Yang,  Yijie Qu,  Shuwei Zhai,  Qianfei Zhao,  Kang Li,  Shaoting Zhang",
                "发布日期": "2023-02-14",
                "摘要": "  Background and Objective: Open-source deep learning toolkits are one of the\ndriving forces for developing medical image segmentation models. Existing\ntoolkits mainly focus on fully supervised segmentation and require full and\naccurate pixel-level annotations that are time-consuming and difficult to\nacquire for segmentation tasks, which makes learning from imperfect labels\nhighly desired for reducing the annotation cost. We aim to develop a new deep\nlearning toolkit to support annotation-efficient learning for medical image\nsegmentation.\n  Methods: Our proposed toolkit named PyMIC is a modular deep learning library\nfor medical image segmentation tasks. In addition to basic components that\nsupport development of high-performance models for fully supervised\nsegmentation, it contains several advanced components tailored for learning\nfrom imperfect annotations, such as loading annotated and unannounced images,\nloss functions for unannotated, partially or inaccurately annotated images, and\ntraining procedures for co-learning between multiple networks, etc. PyMIC\nsupports development of semi-supervised, weakly supervised and noise-robust\nlearning methods for medical image segmentation.\n  Results: We present several illustrative medical image segmentation tasks\nbased on PyMIC: (1) Achieving competitive performance on fully supervised\nlearning; (2) Semi-supervised cardiac structure segmentation with only 10%\ntraining images annotated; (3) Weakly supervised segmentation using scribble\nannotations; and (4) Learning from noisy labels for chest radiograph\nsegmentation.\n  Conclusions: The PyMIC toolkit is easy to use and facilitates efficient\ndevelopment of medical image segmentation models with imperfect annotations. It\nis modular and flexible, which enables researchers to develop high-performance\nmodels with low annotation cost. The source code is available at:\nhttps://github.com/HiLab-git/PyMIC.\n",
                "链接": "https://arxiv.org/abs/2208.09350"
            },
            {
                "文章ID": "110503",
                "标题": "A comprehensive survey on deep active learning and its applications in\n  medical image analysis",
                "作者": " Haoran Wang,  Qiuye Jin,  Shiman Li,  Siyu Liu,  Manning Wang,  Zhijian Song",
                "发布日期": "2023-10-25",
                "摘要": "  Deep learning has achieved widespread success in medical image analysis,\nleading to an increasing demand for large-scale expert-annotated medical image\ndatasets. Yet, the high cost of annotating medical images severely hampers the\ndevelopment of deep learning in this field. To reduce annotation costs, active\nlearning aims to select the most informative samples for annotation and train\nhigh-performance models with as few labeled samples as possible. In this\nsurvey, we review the core methods of active learning, including the evaluation\nof informativeness and sampling strategy. For the first time, we provide a\ndetailed summary of the integration of active learning with other\nlabel-efficient techniques, such as semi-supervised, self-supervised learning,\nand so on. Additionally, we also highlight active learning works that are\nspecifically tailored to medical image analysis. In the end, we offer our\nperspectives on the future trends and challenges of active learning and its\napplications in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2310.14230"
            },
            {
                "文章ID": "107726",
                "标题": "Data efficient deep learning for medical image analysis: A survey",
                "作者": " Suruchi Kumari,  Pravendra Singh",
                "发布日期": "2023-10-11",
                "摘要": "  The rapid evolution of deep learning has significantly advanced the field of\nmedical image analysis. However, despite these achievements, the further\nenhancement of deep learning models for medical image analysis faces a\nsignificant challenge due to the scarcity of large, well-annotated datasets. To\naddress this issue, recent years have witnessed a growing emphasis on the\ndevelopment of data-efficient deep learning methods. This paper conducts a\nthorough review of data-efficient deep learning methods for medical image\nanalysis. To this end, we categorize these methods based on the level of\nsupervision they rely on, encompassing categories such as no supervision,\ninexact supervision, incomplete supervision, inaccurate supervision, and only\nlimited supervision. We further divide these categories into finer\nsubcategories. For example, we categorize inexact supervision into multiple\ninstance learning and learning with weak annotations. Similarly, we categorize\nincomplete supervision into semi-supervised learning, active learning, and\ndomain-adaptive learning and so on. Furthermore, we systematically summarize\ncommonly used datasets for data efficient deep learning in medical image\nanalysis and investigate future research directions to conclude this survey.\n",
                "链接": "https://arxiv.org/abs/2310.06557"
            },
            {
                "文章ID": "69437",
                "标题": "Medical Image Analysis using Deep Relational Learning",
                "作者": " Zhihua Liu",
                "发布日期": "2023-03-29",
                "摘要": "  In the past ten years, with the help of deep learning, especially the rapid\ndevelopment of deep neural networks, medical image analysis has made remarkable\nprogress. However, how to effectively use the relational information between\nvarious tissues or organs in medical images is still a very challenging\nproblem, and it has not been fully studied. In this thesis, we propose two\nnovel solutions to this problem based on deep relational learning. First, we\npropose a context-aware fully convolutional network that effectively models\nimplicit relation information between features to perform medical image\nsegmentation. The network achieves the state-of-the-art segmentation results on\nthe Multi Modal Brain Tumor Segmentation 2017 (BraTS2017) and Multi Modal Brain\nTumor Segmentation 2018 (BraTS2018) data sets. Subsequently, we propose a new\nhierarchical homography estimation network to achieve accurate medical image\nmosaicing by learning the explicit spatial relationship between adjacent\nframes. We use the UCL Fetoscopy Placenta dataset to conduct experiments and\nour hierarchical homography estimation network outperforms the other\nstate-of-the-art mosaicing methods while generating robust and meaningful\nmosaicing result on unseen frames.\n",
                "链接": "https://arxiv.org/abs/2303.16099"
            },
            {
                "文章ID": "104026",
                "标题": "OneSeg: Self-learning and One-shot Learning based Single-slice\n  Annotation for 3D Medical Image Segmentation",
                "作者": " Yixuan Wu,  Bo Zheng,  Jintai Chen,  Danny Z. Chen,  Jian Wu",
                "发布日期": "2023-09-26",
                "摘要": "  As deep learning methods continue to improve medical image segmentation\nperformance, data annotation is still a big bottleneck due to the\nlabor-intensive and time-consuming burden on medical experts, especially for 3D\nimages. To significantly reduce annotation efforts while attaining competitive\nsegmentation accuracy, we propose a self-learning and one-shot learning based\nframework for 3D medical image segmentation by annotating only one slice of\neach 3D image. Our approach takes two steps: (1) self-learning of a\nreconstruction network to learn semantic correspondence among 2D slices within\n3D images, and (2) representative selection of single slices for one-shot\nmanual annotation and propagating the annotated data with the well-trained\nreconstruction network. Extensive experiments verify that our new framework\nachieves comparable performance with less than 1% annotated data compared with\nfully supervised methods and generalizes well on several out-of-distribution\ntesting sets.\n",
                "链接": "https://arxiv.org/abs/2309.13671"
            },
            {
                "文章ID": "93650",
                "标题": "Cross-dimensional transfer learning in medical image segmentation with\n  deep learning",
                "作者": " Hicham Messaoudi,  Ahror Belaid,  Douraied Ben Salem,  Pierre-Henri Conze",
                "发布日期": "2023-08-01",
                "摘要": "  Over the last decade, convolutional neural networks have emerged and advanced\nthe state-of-the-art in various image analysis and computer vision\napplications. The performance of 2D image classification networks is constantly\nimproving and being trained on databases made of millions of natural images.\nHowever, progress in medical image analysis has been hindered by limited\nannotated data and acquisition constraints. These limitations are even more\npronounced given the volumetry of medical imaging data. In this paper, we\nintroduce an efficient way to transfer the efficiency of a 2D classification\nnetwork trained on natural images to 2D, 3D uni- and multi-modal medical image\nsegmentation applications. In this direction, we designed novel architectures\nbased on two key principles: weight transfer by embedding a 2D pre-trained\nencoder into a higher dimensional U-Net, and dimensional transfer by expanding\na 2D segmentation network into a higher dimension one. The proposed networks\nwere tested on benchmarks comprising different modalities: MR, CT, and\nultrasound images. Our 2D network ranked first on the CAMUS challenge dedicated\nto echo-cardiographic data segmentation and surpassed the state-of-the-art.\nRegarding 2D/3D MR and CT abdominal images from the CHAOS challenge, our\napproach largely outperformed the other 2D-based methods described in the\nchallenge paper on Dice, RAVD, ASSD, and MSSD scores and ranked third on the\nonline evaluation platform. Our 3D network applied to the BraTS 2022\ncompetition also achieved promising results, reaching an average Dice score of\n91.69% (91.22%) for the whole tumor, 83.23% (84.77%) for the tumor core, and\n81.75% (83.88%) for enhanced tumor using the approach based on weight\n(dimensional) transfer. Experimental and qualitative results illustrate the\neffectiveness of our methods for multi-dimensional medical image segmentation.\n",
                "链接": "https://arxiv.org/abs/2307.15872"
            },
            {
                "文章ID": "52332",
                "标题": "A Trustworthy Framework for Medical Image Analysis with Deep Learning",
                "作者": " Kai Ma,  Siyuan He,  Pengcheng Xi,  Ashkan Ebadi,  Stéphane Tremblay,  Alexander Wong",
                "发布日期": "2022-12-07",
                "摘要": "  Computer vision and machine learning are playing an increasingly important\nrole in computer-assisted diagnosis; however, the application of deep learning\nto medical imaging has challenges in data availability and data imbalance, and\nit is especially important that models for medical imaging are built to be\ntrustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning\nframework for medical image analysis, which adopts a modular design, leverages\nself-supervised pre-training, and utilizes a novel surrogate loss function.\nExperimental evaluations indicate that models generated from the framework are\nboth trustworthy and high-performing. It is anticipated that the framework will\nsupport researchers and clinicians in advancing the use of deep learning for\ndealing with public health crises including COVID-19.\n",
                "链接": "https://arxiv.org/abs/2212.02764"
            },
            {
                "文章ID": "110135",
                "标题": "Diagnosis-oriented Medical Image Compression with Efficient Transfer\n  Learning",
                "作者": " Guangqi Xie,  Xin Li,  Xiaohan Pan,  Zhibo Chen",
                "发布日期": "2023-10-23",
                "摘要": "  Remote medical diagnosis has emerged as a critical and indispensable\ntechnique in practical medical systems, where medical data are required to be\nefficiently compressed and transmitted for diagnosis by either professional\ndoctors or intelligent diagnosis devices. In this process, a large amount of\nredundant content irrelevant to the diagnosis is subjected to high-fidelity\ncoding, leading to unnecessary transmission costs. To mitigate this, we propose\ndiagnosis-oriented medical image compression, a special semantic compression\ntask designed for medical scenarios, targeting to reduce the compression cost\nwithout compromising the diagnosis accuracy. However, collecting sufficient\nmedical data to optimize such a compression system is significantly expensive\nand challenging due to privacy issues and the lack of professional annotation.\nIn this study, we propose DMIC, the first efficient transfer learning-based\ncodec, for diagnosis-oriented medical image compression, which can be\neffectively optimized with only few-shot annotated medical examples, by reusing\nthe knowledge in the existing reinforcement learning-based task-driven semantic\ncoding framework, i.e., HRLVSC [1]. Concretely, we focus on tuning only the\npartial parameters of the policy network for bit allocation within HRLVSC,\nwhich enables it to adapt to the medical images. In this work, we validate our\nDMIC with the typical medical task, Coronary Artery Segmentation. Extensive\nexperiments have demonstrated that our DMIC can achieve 47.594%BD-Rate savings\ncompared to the HEVC anchor, by tuning only the A2C module (2.7% parameters) of\nthe policy network with only 1 medical sample.\n",
                "链接": "https://arxiv.org/abs/2310.13250"
            },
            {
                "文章ID": "30540",
                "标题": "Self-Supervised-RCNN for Medical Image Segmentation with Limited Data\n  Annotation",
                "作者": " Banafshe Felfeliyan,  Abhilash Hareendranathan,  Gregor Kuntze,  David Cornell,  Nils D. Forkert,  Jacob L. Jaremko,  Janet L. Ronsky",
                "发布日期": "2022-07-25",
                "摘要": "  Many successful methods developed for medical image analysis that are based\non machine learning use supervised learning approaches, which often require\nlarge datasets annotated by experts to achieve high accuracy. However, medical\ndata annotation is time-consuming and expensive, especially for segmentation\ntasks. To solve the problem of learning with limited labeled medical image\ndata, an alternative deep learning training strategy based on self-supervised\npretraining on unlabeled MRI scans is proposed in this work. Our pretraining\napproach first, randomly applies different distortions to random areas of\nunlabeled images and then predicts the type of distortions and loss of\ninformation. To this aim, an improved version of Mask-RCNN architecture has\nbeen adapted to localize the distortion location and recover the original image\npixels. The effectiveness of the proposed method for segmentation tasks in\ndifferent pre-training and fine-tuning scenarios is evaluated based on the\nOsteoarthritis Initiative dataset. Using this self-supervised pretraining\nmethod improved the Dice score by 20% compared to training from scratch. The\nproposed self-supervised learning is simple, effective, and suitable for\ndifferent ranges of medical image analysis tasks including anomaly detection,\nsegmentation, and classification.\n",
                "链接": "https://arxiv.org/abs/2207.11191"
            },
            {
                "文章ID": "88712",
                "标题": "MedAugment: Universal Automatic Data Augmentation Plug-in for Medical\n  Image Analysis",
                "作者": " Zhaoshan Liu,  Qiujie Lv,  Yifan Li,  Ziduo Yang,  Lei Shen",
                "发布日期": "2023-11-08",
                "摘要": "  Data augmentation (DA) has been widely leveraged in the realm of computer\nvision to alleviate the data shortage, whereas the DA in medical image analysis\n(MIA) faces multiple challenges. The prevalent DA approaches in MIA encompass\nconventional DA, synthetic DA, and automatic DA. However, the utilization of\nthese approaches poses various challenges such as experience-driven design and\nintensive computation cost. Here, we propose an efficient and effective\nautomatic DA method termed MedAugment. We propose the pixel augmentation space\nand spatial augmentation space and exclude the operations that can break the\ndetails and features within medical images. Besides, we propose a novel\nsampling strategy by sampling a limited number of operations from the two\nspaces. Moreover, we present a hyperparameter mapping relationship to produce a\nrational augmentation level and make the MedAugment fully controllable using a\nsingle hyperparameter. These revisions address the differences between natural\nand medical images. Extensive experimental results on four classification and\nthree segmentation datasets demonstrate the superiority of MedAugment. We posit\nthat the plug-and-use and training-free MedAugment holds the potential to make\na valuable contribution to the medical field, particularly benefiting medical\nexperts lacking foundational expertise in deep learning. Code is available at\nhttps://github.com/NUS-Tim/MedAugment.\n",
                "链接": "https://arxiv.org/abs/2306.17466"
            }
        ]
    },
    {
        "question": {
            "question": "请找出最近一年内发表的关于自然语言处理领域中，使用Transformer模型并在大规模数据集上进行预训练的论文。特别关注模型结构和性能指标。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "请查找关于智能体的研究进展的综述或调查论文。重点关注不同领域中智能体的方法和应用，以及相关的挑战和未来方向。",
            "type": "5"
        },
        "results": []
    }
]