[
    {
        "question": {
            "question": "与大模型工具学习相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            },
            {
                "文章ID": "81151",
                "标题": "Playing repeated games with Large Language Models",
                "作者": " Elif Akata,  Lion Schulz,  Julian Coda-Forno,  Seong Joon Oh,  Matthias Bethge,  Eric Schulz",
                "发布日期": "2023-05-29",
                "摘要": "  Large Language Models (LLMs) are transforming society and permeating into\ndiverse applications. As a result, LLMs will frequently interact with us and\nother agents. It is, therefore, of great societal value to understand how LLMs\nbehave in interactive social settings. Here, we propose to use behavioral game\ntheory to study LLM's cooperation and coordination behavior. To do so, we let\ndifferent LLMs (GPT-3, GPT-3.5, and GPT-4) play finitely repeated games with\neach other and with other, human-like strategies. Our results show that LLMs\ngenerally perform well in such tasks and also uncover persistent behavioral\nsignatures. In a large set of two players-two strategies games, we find that\nLLMs are particularly good at games where valuing their own self-interest pays\noff, like the iterated Prisoner's Dilemma family. However, they behave\nsub-optimally in games that require coordination. We, therefore, further focus\non two games from these distinct families. In the canonical iterated Prisoner's\nDilemma, we find that GPT-4 acts particularly unforgivingly, always defecting\nafter another agent has defected only once. In the Battle of the Sexes, we find\nthat GPT-4 cannot match the behavior of the simple convention to alternate\nbetween options. We verify that these behavioral signatures are stable across\nrobustness checks. Finally, we show how GPT-4's behavior can be modified by\nproviding further information about the other player as well as by asking it to\npredict the other player's actions before making a choice. These results enrich\nour understanding of LLM's social behavior and pave the way for a behavioral\ngame theory for machines.\n",
                "链接": "https://arxiv.org/abs/2305.16867"
            },
            {
                "文章ID": "61490",
                "标题": "Relatedly: Scaffolding Literature Reviews with Existing Related Work\n  Sections",
                "作者": " Srishti Palani,  Aakanksha Naik,  Doug Downey,  Amy X. Zhang,  Jonathan Bragg,  Joseph Chee Chang",
                "发布日期": "2023-02-15",
                "摘要": "  Scholars who want to research a scientific topic must take time to read,\nextract meaning, and identify connections across many papers. As scientific\nliterature grows, this becomes increasingly challenging. Meanwhile, authors\nsummarize prior research in papers' related work sections, though this is\nscoped to support a single paper. A formative study found that while reading\nmultiple related work paragraphs helps overview a topic, it is hard to navigate\noverlapping and diverging references and research foci. In this work, we design\na system, Relatedly, that scaffolds exploring and reading multiple related work\nparagraphs on a topic, with features including dynamic re-ranking and\nhighlighting to spotlight unexplored dissimilar information, auto-generated\ndescriptive paragraph headings, and low-lighting of redundant information. From\na within-subjects user study (n=15), we found that scholars generate more\ncoherent, insightful, and comprehensive topic outlines using Relatedly compared\nto a baseline paper list.\n",
                "链接": "https://arxiv.org/abs/2302.06754"
            },
            {
                "文章ID": "91604",
                "标题": "Non-stationary Delayed Combinatorial Semi-Bandit with Causally Related\n  Rewards",
                "作者": " Saeed Ghoorchian,  Setareh Maghsudi",
                "发布日期": "2023-07-19",
                "摘要": "  Sequential decision-making under uncertainty is often associated with long\nfeedback delays. Such delays degrade the performance of the learning agent in\nidentifying a subset of arms with the optimal collective reward in the long\nrun. This problem becomes significantly challenging in a non-stationary\nenvironment with structural dependencies amongst the reward distributions\nassociated with the arms. Therefore, besides adapting to delays and\nenvironmental changes, learning the causal relations alleviates the adverse\neffects of feedback delay on the decision-making process. We formalize the\ndescribed setting as a non-stationary and delayed combinatorial semi-bandit\nproblem with causally related rewards. We model the causal relations by a\ndirected graph in a stationary structural equation model. The agent maximizes\nthe long-term average payoff, defined as a linear function of the base arms'\nrewards. We develop a policy that learns the structural dependencies from\ndelayed feedback and utilizes that to optimize the decision-making while\nadapting to drifts. We prove a regret bound for the performance of the proposed\nalgorithm. Besides, we evaluate our method via numerical analysis using\nsynthetic and real-world datasets to detect the regions that contribute the\nmost to the spread of Covid-19 in Italy.\n",
                "链接": "https://arxiv.org/abs/2307.09093"
            },
            {
                "文章ID": "81272",
                "标题": "Large Language Models as Tool Makers",
                "作者": " Tianle Cai,  Xuezhi Wang,  Tengyu Ma,  Xinyun Chen,  Denny Zhou",
                "发布日期": "2023-05-29",
                "摘要": "  Recent research shows the potential of enhancing the problem-solving ability\nof large language models (LLMs) through the use of external tools. However,\nprior work along this line depends on the availability of existing tools. In\nthis work, we take an initial step towards removing this dependency by\nproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),\nwhere LLMs create their own reusable tools for problem-solving. Our approach\nconsists of two key phases: 1) tool making: an LLM acts as the tool maker that\ncrafts tools for given tasks, where a tool is implemented as a Python utility\nfunction. 2) tool using: an LLM acts as the tool user, which applies the tool\nbuilt by the tool maker for problem-solving. The tool user can be either the\nsame or a different LLM from the tool maker. Tool-making enables an LLM to\ncontinually generate tools that can be applied to different requests so that\nfuture requests can call the corresponding APIs when beneficial for solving the\ntasks. Furthermore, the division of labor among LLMs for tool-making and\ntool-using phases introduces the opportunity to achieve cost effectiveness\nwithout degrading the quality of generated tools and problem solutions. For\nexample, recognizing that tool-making demands more sophisticated capabilities\nthan tool-using, we can apply a powerful yet resource-intensive model as the\ntool maker, and a lightweight while cost-effective model as the tool user. We\nvalidate the effectiveness of our approach across a variety of complex\nreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and\nGPT-3.5 as the tool user, LATM can achieve performance that is on par with\nusing GPT-4 for both tool making and tool using, while the inference cost is\nsignificantly reduced.\n",
                "链接": "https://arxiv.org/abs/2305.17126"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "90826",
                "标题": "Negated Complementary Commonsense using Large Language Models",
                "作者": " Navid Rezaei,  Marek Z. Reformat",
                "发布日期": "2023-07-14",
                "摘要": "  Larger language models, such as GPT-3, have shown to be excellent in many\ntasks. However, we demonstrate that out-of-ordinary questions can throw the\nmodel off guard. This work focuses on finding answers to negated complementary\nquestions in commonsense scenarios. We illustrate how such questions adversely\naffect the model responses. We propose a model-agnostic methodology to improve\nthe performance in negated complementary scenarios. Our method outperforms\nfew-shot generation from GPT-3 (by more than 11 points) and, more importantly,\nhighlights the significance of studying the response of large language models\nin negated complementary questions. The code, data, and experiments are\navailable under: https://github.com/navidre/negated_complementary_commonsense.\n",
                "链接": "https://arxiv.org/abs/2307.06794"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "123543",
                "标题": "Large Language Models are Complex Table Parsers",
                "作者": " Bowen Zhao,  Changkai Ji,  Yuejie Zhang,  Wen He,  Yingwen Wang,  Qing Wang,  Rui Feng,  Xiaobo Zhang",
                "发布日期": "2023-12-20",
                "摘要": "  With the Generative Pre-trained Transformer 3.5 (GPT-3.5) exhibiting\nremarkable reasoning and comprehension abilities in Natural Language Processing\n(NLP), most Question Answering (QA) research has primarily centered around\ngeneral QA tasks based on GPT, neglecting the specific challenges posed by\nComplex Table QA. In this paper, we propose to incorporate GPT-3.5 to address\nsuch challenges, in which complex tables are reconstructed into tuples and\nspecific prompt designs are employed for dialogues. Specifically, we encode\neach cell's hierarchical structure, position information, and content as a\ntuple. By enhancing the prompt template with an explanatory description of the\nmeaning of each tuple and the logical reasoning process of the task, we\neffectively improve the hierarchical structure awareness capability of GPT-3.5\nto better parse the complex tables. Extensive experiments and results on\nComplex Table QA datasets, i.e., the open-domain dataset HiTAB and the aviation\ndomain dataset AIT-QA show that our approach significantly outperforms previous\nwork on both datasets, leading to state-of-the-art (SOTA) performance.\n",
                "链接": "https://arxiv.org/abs/2312.11521"
            }
        ]
    },
    {
        "question": {
            "question": "和大模型可解释相关的最新论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "107503",
                "标题": "An evolutionary model of personality traits related to cooperative\n  behavior using a large language model",
                "作者": " Reiji Suzuki,  Takaya Arita",
                "发布日期": "2023-10-11",
                "摘要": "  This paper aims to shed light on the evolutionary dynamics of diverse and\nsocial populations by introducing the rich expressiveness of generative models\ninto the trait expression of social agent-based evolutionary models.\nSpecifically, we focus on the evolution of personality traits in the context of\na game-theoretic relationship as a situation in which inter-individual\ninterests exert strong selection pressures. We construct an agent model in\nwhich linguistic descriptions of personality traits related to cooperative\nbehavior are used as genes. The deterministic strategies extracted from Large\nLanguage Model (LLM) that make behavioral decisions based on these personality\ntraits are used as behavioral traits. The population is evolved according to\nselection based on average payoff and mutation of genes by asking LLM to\nslightly modify the parent gene toward cooperative or selfish. Through\npreliminary experiments and analyses, we clarify that such a model can indeed\nexhibit the evolution of cooperative behavior based on the diverse and\nhigher-order representation of personality traits. We also observed the\nrepeated intrusion of cooperative and selfish personality traits through\nchanges in the expression of personality traits, and found that the emerging\nwords in the evolved gene well reflected the behavioral tendency of its\npersonality in terms of their semantics.\n",
                "链接": "https://arxiv.org/abs/2310.05976"
            },
            {
                "文章ID": "99995",
                "标题": "Explainability for Large Language Models: A Survey",
                "作者": " Haiyan Zhao,  Hanjie Chen,  Fan Yang,  Ninghao Liu,  Huiqi Deng,  Hengyi Cai,  Shuaiqiang Wang,  Dawei Yin,  Mengnan Du",
                "发布日期": "2023-11-30",
                "摘要": "  Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language processing. However, their internal mechanisms are still\nunclear and this lack of transparency poses unwanted risks for downstream\napplications. Therefore, understanding and explaining these models is crucial\nfor elucidating their behaviors, limitations, and social impacts. In this\npaper, we introduce a taxonomy of explainability techniques and provide a\nstructured overview of methods for explaining Transformer-based language\nmodels. We categorize techniques based on the training paradigms of LLMs:\ntraditional fine-tuning-based paradigm and prompting-based paradigm. For each\nparadigm, we summarize the goals and dominant approaches for generating local\nexplanations of individual predictions and global explanations of overall model\nknowledge. We also discuss metrics for evaluating generated explanations, and\ndiscuss how explanations can be leveraged to debug models and improve\nperformance. Lastly, we examine key challenges and emerging opportunities for\nexplanation techniques in the era of LLMs in comparison to conventional machine\nlearning models.\n",
                "链接": "https://arxiv.org/abs/2309.01029"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "125173",
                "标题": "A Large Language Model-based Computational Approach to Improve\n  Identity-Related Write-Ups",
                "作者": " Alex Doboli",
                "发布日期": "2023-12-29",
                "摘要": "  Creating written products is essential to modern life, including writings\nabout one's identity and personal experiences. However, writing is often a\ndifficult activity that requires extensive effort to frame the central ideas,\nthe pursued approach to communicate the central ideas, e.g., using analogies,\nmetaphors, or other possible means, the needed presentation structure, and the\nactual verbal expression. Large Language Models, a recently emerged approach in\nMachine Learning, can offer a significant help in reducing the effort and\nimproving the quality of written products. This paper proposes a new\ncomputational approach to explore prompts that given as inputs to a Large\nLanguage Models can generate cues to improve the considered written products.\nTwo case studies on improving write-ups, one based on an analogy and one on a\nmetaphor, are also presented in the paper.\n",
                "链接": "https://arxiv.org/abs/2312.16659"
            },
            {
                "文章ID": "70693",
                "标题": "Summary of ChatGPT-Related Research and Perspective Towards the Future\n  of Large Language Models",
                "作者": " Yiheng Liu,  Tianle Han,  Siyuan Ma,  Jiayue Zhang,  Yuanyuan Yang,  Jiaming Tian,  Hao He,  Antong Li,  Mengshen He,  Zhengliang Liu,  Zihao Wu,  Lin Zhao,  Dajiang Zhu,  Xiang Li,  Ning Qiang,  Dingang Shen,  Tianming Liu,  Bao Ge",
                "发布日期": "2023-08-25",
                "摘要": "  This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and\nGPT-4) research, state-of-the-art large language models (LLM) from the GPT\nseries, and their prospective applications across diverse domains. Indeed, key\ninnovations such as large-scale pre-training that captures knowledge across the\nentire world wide web, instruction fine-tuning and Reinforcement Learning from\nHuman Feedback (RLHF) have played significant roles in enhancing LLMs'\nadaptability and performance. We performed an in-depth analysis of 194 relevant\npapers on arXiv, encompassing trend analysis, word cloud representation, and\ndistribution analysis across various application domains. The findings reveal a\nsignificant and increasing interest in ChatGPT-related research, predominantly\ncentered on direct natural language processing applications, while also\ndemonstrating considerable potential in areas ranging from education and\nhistory to mathematics, medicine, and physics. This study endeavors to furnish\ninsights into ChatGPT's capabilities, potential implications, ethical concerns,\nand offer direction for future advancements in this field.\n",
                "链接": "https://arxiv.org/abs/2304.01852"
            },
            {
                "文章ID": "72313",
                "标题": "Evaluation of Social Biases in Recent Large Pre-Trained Models",
                "作者": " Swapnil Sharma,  Nikita Anand,  Kranthi Kiran G. V.,  Alind Jain",
                "发布日期": "2023-04-17",
                "摘要": "  Large pre-trained language models are widely used in the community. These\nmodels are usually trained on unmoderated and unfiltered data from open sources\nlike the Internet. Due to this, biases that we see in platforms online which\nare a reflection of those in society are in turn captured and learned by these\nmodels. These models are deployed in applications that affect millions of\npeople and their inherent biases are harmful to the targeted social groups. In\nthis work, we study the general trend in bias reduction as newer pre-trained\nmodels are released. Three recent models ( ELECTRA, DeBERTa, and DistilBERT)\nare chosen and evaluated against two bias benchmarks, StereoSet and\nCrowS-Pairs. They are compared to the baseline of BERT using the associated\nmetrics. We explore whether as advancements are made and newer, faster, lighter\nmodels are released: are they being developed responsibly such that their\ninherent social biases have been reduced compared to their older counterparts?\nThe results are compiled and we find that all the models under study do exhibit\nbiases but have generally improved as compared to BERT.\n",
                "链接": "https://arxiv.org/abs/2304.06861"
            },
            {
                "文章ID": "79831",
                "标题": "Balancing Explainability-Accuracy of Complex Models",
                "作者": " Poushali Sengupta,  Yan Zhang,  Sabita Maharjan,  Frank Eliassen",
                "发布日期": "2023-05-24",
                "摘要": "  Explainability of AI models is an important topic that can have a significant\nimpact in all domains and applications from autonomous driving to healthcare.\nThe existing approaches to explainable AI (XAI) are mainly limited to simple\nmachine learning algorithms, and the research regarding the\nexplainability-accuracy tradeoff is still in its infancy especially when we are\nconcerned about complex machine learning techniques like neural networks and\ndeep learning (DL). In this work, we introduce a new approach for complex\nmodels based on the co-relation impact which enhances the explainability\nconsiderably while also ensuring the accuracy at a high level. We propose\napproaches for both scenarios of independent features and dependent features.\nIn addition, we study the uncertainty associated with features and output.\nFurthermore, we provide an upper bound of the computation complexity of our\nproposed approach for the dependent features. The complexity bound depends on\nthe order of logarithmic of the number of observations which provides a\nreliable result considering the higher dimension of dependent feature space\nwith a smaller number of observations.\n",
                "链接": "https://arxiv.org/abs/2305.14098"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "57565",
                "标题": "CEnt: An Entropy-based Model-agnostic Explainability Framework to\n  Contrast Classifiers' Decisions",
                "作者": " Julia El Zini,  Mohammad Mansour,  Mariette Awad",
                "发布日期": "2023-01-20",
                "摘要": "  Current interpretability methods focus on explaining a particular model's\ndecision through present input features. Such methods do not inform the user of\nthe sufficient conditions that alter these decisions when they are not\ndesirable. Contrastive explanations circumvent this problem by providing\nexplanations of the form \"If the feature $X>x$, the output $Y$ would be\ndifferent''. While different approaches are developed to find contrasts; these\nmethods do not all deal with mutability and attainability constraints.\n  In this work, we present a novel approach to locally contrast the prediction\nof any classifier. Our Contrastive Entropy-based explanation method, CEnt,\napproximates a model locally by a decision tree to compute entropy information\nof different feature splits. A graph, G, is then built where contrast nodes are\nfound through a one-to-many shortest path search. Contrastive examples are\ngenerated from the shortest path to reflect feature splits that alter model\ndecisions while maintaining lower entropy. We perform local sampling on\nmanifold-like distances computed by variational auto-encoders to reflect data\ndensity. CEnt is the first non-gradient-based contrastive method generating\ndiverse counterfactuals that do not necessarily exist in the training data\nwhile satisfying immutability (ex. race) and semi-immutability (ex. age can\nonly change in an increasing direction). Empirical evaluation on four\nreal-world numerical datasets demonstrates the ability of CEnt in generating\ncounterfactuals that achieve better proximity rates than existing methods\nwithout compromising latency, feasibility, and attainability. We further extend\nCEnt to imagery data to derive visually appealing and useful contrasts between\nclass labels on MNIST and Fashion MNIST datasets. Finally, we show how CEnt can\nserve as a tool to detect vulnerabilities of textual classifiers.\n",
                "链接": "https://arxiv.org/abs/2301.07941"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于大模型Agent应用的最新发表论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "112858",
                "标题": "Linked Papers With Code: The Latest in Machine Learning as an RDF\n  Knowledge Graph",
                "作者": " Michael Färber,  David Lamprecht",
                "发布日期": "2023-11-01",
                "摘要": "  In this paper, we introduce Linked Papers With Code (LPWC), an RDF knowledge\ngraph that provides comprehensive, current information about almost 400,000\nmachine learning publications. This includes the tasks addressed, the datasets\nutilized, the methods implemented, and the evaluations conducted, along with\ntheir results. Compared to its non-RDF-based counterpart Papers With Code, LPWC\nnot only translates the latest advancements in machine learning into RDF\nformat, but also enables novel ways for scientific impact quantification and\nscholarly key content recommendation. LPWC is openly accessible at\nhttps://linkedpaperswithcode.com and is licensed under CC-BY-SA 4.0. As a\nknowledge graph in the Linked Open Data cloud, we offer LPWC in multiple\nformats, from RDF dump files to a SPARQL endpoint for direct web queries, as\nwell as a data source with resolvable URIs and links to the data sources\nSemOpenAlex, Wikidata, and DBLP. Additionally, we supply knowledge graph\nembeddings, enabling LPWC to be readily applied in machine learning\napplications.\n",
                "链接": "https://arxiv.org/abs/2310.20475"
            },
            {
                "文章ID": "92252",
                "标题": "On the Convergence of Bounded Agents",
                "作者": " David Abel,  André Barreto,  Hado van Hasselt,  Benjamin Van Roy,  Doina Precup,  Satinder Singh",
                "发布日期": "2023-07-21",
                "摘要": "  When has an agent converged? Standard models of the reinforcement learning\nproblem give rise to a straightforward definition of convergence: An agent\nconverges when its behavior or performance in each environment state stops\nchanging. However, as we shift the focus of our learning problem from the\nenvironment's state to the agent's state, the concept of an agent's convergence\nbecomes significantly less clear. In this paper, we propose two complementary\naccounts of agent convergence in a framing of the reinforcement learning\nproblem that centers around bounded agents. The first view says that a bounded\nagent has converged when the minimal number of states needed to describe the\nagent's future behavior cannot decrease. The second view says that a bounded\nagent has converged just when the agent's performance only changes if the\nagent's internal state changes. We establish basic properties of these two\ndefinitions, show that they accommodate typical views of convergence in\nstandard settings, and prove several facts about their nature and relationship.\nWe take these perspectives, definitions, and analysis to bring clarity to a\ncentral idea of the field.\n",
                "链接": "https://arxiv.org/abs/2307.11044"
            },
            {
                "文章ID": "102059",
                "标题": "The Rise and Potential of Large Language Model Based Agents: A Survey",
                "作者": " Zhiheng Xi,  Wenxiang Chen,  Xin Guo,  Wei He,  Yiwen Ding,  Boyang Hong,  Ming Zhang,  Junzhe Wang,  Senjie Jin,  Enyu Zhou,  Rui Zheng,  Xiaoran Fan,  Xiao Wang,  Limao Xiong,  Yuhao Zhou,  Weiran Wang,  Changhao Jiang,  Yicheng Zou,  Xiangyang Liu,  Zhangyue Yin,  Shihan Dou,  Rongxiang Weng,  Wensen Cheng,  Qi Zhang,  Wenjuan Qin,  Yongyan Zheng,  Xipeng Qiu,  Xuanjing Huang,  Tao Gui",
                "发布日期": "2023-09-20",
                "摘要": "  For a long time, humanity has pursued artificial intelligence (AI) equivalent\nto or surpassing the human level, with AI agents considered a promising vehicle\nfor this pursuit. AI agents are artificial entities that sense their\nenvironment, make decisions, and take actions. Many efforts have been made to\ndevelop intelligent agents, but they mainly focus on advancement in algorithms\nor training strategies to enhance specific capabilities or performance on\nparticular tasks. Actually, what the community lacks is a general and powerful\nmodel to serve as a starting point for designing AI agents that can adapt to\ndiverse scenarios. Due to the versatile capabilities they demonstrate, large\nlanguage models (LLMs) are regarded as potential sparks for Artificial General\nIntelligence (AGI), offering hope for building general AI agents. Many\nresearchers have leveraged LLMs as the foundation to build AI agents and have\nachieved significant progress. In this paper, we perform a comprehensive survey\non LLM-based agents. We start by tracing the concept of agents from its\nphilosophical origins to its development in AI, and explain why LLMs are\nsuitable foundations for agents. Building upon this, we present a general\nframework for LLM-based agents, comprising three main components: brain,\nperception, and action, and the framework can be tailored for different\napplications. Subsequently, we explore the extensive applications of LLM-based\nagents in three aspects: single-agent scenarios, multi-agent scenarios, and\nhuman-agent cooperation. Following this, we delve into agent societies,\nexploring the behavior and personality of LLM-based agents, the social\nphenomena that emerge from an agent society, and the insights they offer for\nhuman society. Finally, we discuss several key topics and open problems within\nthe field. A repository for the related papers at\nhttps://github.com/WooooDyy/LLM-Agent-Paper-List.\n",
                "链接": "https://arxiv.org/abs/2309.07864"
            },
            {
                "文章ID": "111732",
                "标题": "CompeteAI: Understanding the Competition Behaviors in Large Language\n  Model-based Agents",
                "作者": " Qinlin Zhao,  Jindong Wang,  Yixuan Zhang,  Yiqiao Jin,  Kaijie Zhu,  Hao Chen,  Xing Xie",
                "发布日期": "2023-10-27",
                "摘要": "  Large language models (LLMs) have been widely used as agents to complete\ndifferent tasks, such as personal assistance or event planning. While most work\nhas focused on cooperation and collaboration between agents, little work\nexplores competition, another important mechanism that fosters the development\nof society and economy. In this paper, we seek to examine the competition\nbehaviors in LLM-based agents. We first propose a general framework to study\nthe competition between agents. Then, we implement a practical competitive\nenvironment using GPT-4 to simulate a virtual town with two types of agents,\nincluding restaurant agents and customer agents. Specifically, restaurant\nagents compete with each other to attract more customers, where the competition\nfosters them to transform, such as cultivating new operating strategies. The\nresults of our experiments reveal several interesting findings ranging from\nsocial learning to Matthew Effect, which aligns well with existing sociological\nand economic theories. We believe that competition between agents deserves\nfurther investigation to help us understand society better. The code will be\nreleased soon.\n",
                "链接": "https://arxiv.org/abs/2310.17512"
            },
            {
                "文章ID": "115250",
                "标题": "On the Discussion of Large Language Models: Symmetry of Agents and\n  Interplay with Prompts",
                "作者": " Qineng Wang,  Zihao Wang,  Ying Su,  Yangqiu Song",
                "发布日期": "2023-11-14",
                "摘要": "  Two ways has been discussed to unlock the reasoning capability of a large\nlanguage model. The first one is prompt engineering and the second one is to\ncombine the multiple inferences of large language models, or the multi-agent\ndiscussion. Theoretically, this paper justifies the multi-agent discussion\nmechanisms from the symmetry of agents. Empirically, this paper reports the\nempirical results of the interplay of prompts and discussion mechanisms,\nrevealing the empirical state-of-the-art performance of complex multi-agent\nmechanisms can be approached by carefully developed prompt engineering. This\npaper also proposes a scalable discussion mechanism based on conquer and merge,\nproviding a simple multi-agent discussion solution with simple prompts but\nstate-of-the-art performance.\n",
                "链接": "https://arxiv.org/abs/2311.07076"
            },
            {
                "文章ID": "49513",
                "标题": "Intelligent Computing: The Latest Advances, Challenges and Future",
                "作者": " Shiqiang Zhu,  Ting Yu,  Tao Xu,  Hongyang Chen,  Schahram Dustdar,  Sylvain Gigan,  Deniz Gunduz,  Ekram Hossain,  Yaochu Jin,  Feng Lin,  Bo Liu,  Zhiguo Wan,  Ji Zhang,  Zhifeng Zhao,  Wentao Zhu,  Zuoning Chen,  Tariq Durrani,  Huaimin Wang,  Jiangxing Wu,  Tongyi Zhang,  Yunhe Pan",
                "发布日期": "2022-11-22",
                "摘要": "  Computing is a critical driving force in the development of human\ncivilization. In recent years, we have witnessed the emergence of intelligent\ncomputing, a new computing paradigm that is reshaping traditional computing and\npromoting digital revolution in the era of big data, artificial intelligence\nand internet-of-things with new computing theories, architectures, methods,\nsystems, and applications. Intelligent computing has greatly broadened the\nscope of computing, extending it from traditional computing on data to\nincreasingly diverse computing paradigms such as perceptual intelligence,\ncognitive intelligence, autonomous intelligence, and human-computer fusion\nintelligence. Intelligence and computing have undergone paths of different\nevolution and development for a long time but have become increasingly\nintertwined in recent years: intelligent computing is not only\nintelligence-oriented but also intelligence-driven. Such cross-fertilization\nhas prompted the emergence and rapid advancement of intelligent computing.\nIntelligent computing is still in its infancy and an abundance of innovations\nin the theories, systems, and applications of intelligent computing are\nexpected to occur soon. We present the first comprehensive survey of literature\non intelligent computing, covering its theory fundamentals, the technological\nfusion of intelligence and computing, important applications, challenges, and\nfuture perspectives. We believe that this survey is highly timely and will\nprovide a comprehensive reference and cast valuable insights into intelligent\ncomputing for academic and industrial researchers and practitioners.\n",
                "链接": "https://arxiv.org/abs/2211.11281"
            },
            {
                "文章ID": "50834",
                "标题": "Application of the YOLOv5 Model for the Detection of Microobjects in the\n  Marine Environment",
                "作者": " Aleksandr N. Grekov,  Yurii E. Shishkin,  Sergei S. Peliushenko,  Aleksandr S. Mavrin",
                "发布日期": "2022-11-29",
                "摘要": "  The efficiency of using the YOLOV5 machine learning model for solving the\nproblem of automatic de-tection and recognition of micro-objects in the marine\nenvironment is studied. Samples of microplankton and microplastics were\nprepared, according to which a database of classified images was collected for\ntraining an image recognition neural network. The results of experiments using\na trained network to find micro-objects in photo and video images in real time\nare presented. Experimental studies have shown high efficiency, comparable to\nmanual recognition, of the proposed model in solving problems of detect-ing\nmicro-objects in the marine environment.\n",
                "链接": "https://arxiv.org/abs/2211.15218"
            },
            {
                "文章ID": "85994",
                "标题": "Exploring the Application of Large-scale Pre-trained Models on Adverse\n  Weather Removal",
                "作者": " Zhentao Tan,  Yue Wu,  Qiankun Liu,  Qi Chu,  Le Lu,  Jieping Ye,  Nenghai Yu",
                "发布日期": "2023-06-16",
                "摘要": "  Image restoration under adverse weather conditions (e.g., rain, snow and\nhaze) is a fundamental computer vision problem and has important indications\nfor various downstream applications. Different from early methods that are\nspecially designed for specific type of weather, most recent works tend to\nremove various adverse weather effects simultaneously through either spatial\nfeature representation learning or semantic information embedding. Inspired by\nthe various successful applications of large-scale pre-trained models (e.g,\nCLIP), in this paper, we explore the potential benefits of them for this task\nthrough both spatial feature representation learning and semantic information\nembedding aspects: 1) for spatial feature representation learning, we design a\nSpatially-Adaptive Residual (\\textbf{SAR}) Encoder to extract degraded areas\nadaptively. To facilitate its training, we propose a Soft Residual Distillation\n(\\textbf{CLIP-SRD}) strategy to transfer the spatial knowledge from CLIP\nbetween clean and adverse weather images; 2) for semantic information\nembedding, we propose a CLIP Weather Prior (\\textbf{CWP}) embedding module to\nmake the network handle different weather conditions adaptively. This module\nintegrates the sample specific weather prior extracted by CLIP image encoder\ntogether with the distribution specific information learned by a set of\nparameters, and embeds them through a cross attention mechanism. Extensive\nexperiments demonstrate that our proposed method can achieve state-of-the-art\nperformance under different and challenging adverse weather conditions. Code\nwill be made available.\n",
                "链接": "https://arxiv.org/abs/2306.09008"
            },
            {
                "文章ID": "91355",
                "标题": "On the application of Large Language Models for language teaching and\n  assessment technology",
                "作者": " Andrew Caines,  Luca Benedetto,  Shiva Taslimipoor,  Christopher Davis,  Yuan Gao,  Oeistein Andersen,  Zheng Yuan,  Mark Elliott,  Russell Moore,  Christopher Bryant,  Marek Rei,  Helen Yannakoudakis,  Andrew Mullooly,  Diane Nicholls,  Paula Buttery",
                "发布日期": "2023-07-18",
                "摘要": "  The recent release of very large language models such as PaLM and GPT-4 has\nmade an unprecedented impact in the popular media and public consciousness,\ngiving rise to a mixture of excitement and fear as to their capabilities and\npotential uses, and shining a light on natural language processing research\nwhich had not previously received so much attention. The developments offer\ngreat promise for education technology, and in this paper we look specifically\nat the potential for incorporating large language models in AI-driven language\nteaching and assessment systems. We consider several research areas and also\ndiscuss the risks and ethical considerations surrounding generative AI in\neducation technology for language learners. Overall we find that larger\nlanguage models offer improvements over previous models in text generation,\nopening up routes toward content generation which had not previously been\nplausible. For text generation they must be prompted carefully and their\noutputs may need to be reshaped before they are ready for use. For automated\ngrading and grammatical error correction, tasks whose progress is checked on\nwell-known benchmarks, early investigations indicate that large language models\non their own do not improve on state-of-the-art results according to standard\nevaluation metrics. For grading it appears that linguistic features established\nin the literature should still be used for best performance, and for error\ncorrection it may be that the models can offer alternative feedback styles\nwhich are not measured sensitively with existing methods. In all cases, there\nis work to be done to experiment with the inclusion of large language models in\neducation technology for language learners, in order to properly understand and\nreport on their capacities and limitations, and to ensure that foreseeable\nrisks such as misinformation and harmful bias are mitigated.\n",
                "链接": "https://arxiv.org/abs/2307.08393"
            },
            {
                "文章ID": "97862",
                "标题": "A Survey on Large Language Model based Autonomous Agents",
                "作者": " Lei Wang,  Chen Ma,  Xueyang Feng,  Zeyu Zhang,  Hao Yang,  Jingsen Zhang,  Zhiyuan Chen,  Jiakai Tang,  Xu Chen,  Yankai Lin,  Wayne Xin Zhao,  Zhewei Wei,  Ji-Rong Wen",
                "发布日期": "2023-09-08",
                "摘要": "  Autonomous agents have long been a prominent research focus in both academic\nand industry communities. Previous research in this field often focuses on\ntraining agents with limited knowledge within isolated environments, which\ndiverges significantly from human learning processes, and thus makes the agents\nhard to achieve human-like decisions. Recently, through the acquisition of vast\namounts of web knowledge, large language models (LLMs) have demonstrated\nremarkable potential in achieving human-level intelligence. This has sparked an\nupsurge in studies investigating LLM-based autonomous agents. In this paper, we\npresent a comprehensive survey of these studies, delivering a systematic review\nof the field of LLM-based autonomous agents from a holistic perspective. More\nspecifically, we first discuss the construction of LLM-based autonomous agents,\nfor which we propose a unified framework that encompasses a majority of the\nprevious work. Then, we present a comprehensive overview of the diverse\napplications of LLM-based autonomous agents in the fields of social science,\nnatural science, and engineering. Finally, we delve into the evaluation\nstrategies commonly used for LLM-based autonomous agents. Based on the previous\nstudies, we also present several challenges and future directions in this\nfield. To keep track of this field and continuously update our survey, we\nmaintain a repository of relevant references at\nhttps://github.com/Paitesanshi/LLM-Agent-Survey.\n",
                "链接": "https://arxiv.org/abs/2308.11432"
            }
        ]
    },
    {
        "question": {
            "question": "查询近一年模型推理加速相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "111604",
                "标题": "Hierarchical Semi-Implicit Variational Inference with Application to\n  Diffusion Model Acceleration",
                "作者": " Longlin Yu,  Tianyu Xie,  Yu Zhu,  Tong Yang,  Xiangyu Zhang,  Cheng Zhang",
                "发布日期": "2023-10-27",
                "摘要": "  Semi-implicit variational inference (SIVI) has been introduced to expand the\nanalytical variational families by defining expressive semi-implicit\ndistributions in a hierarchical manner. However, the single-layer architecture\ncommonly used in current SIVI methods can be insufficient when the target\nposterior has complicated structures. In this paper, we propose hierarchical\nsemi-implicit variational inference, called HSIVI, which generalizes SIVI to\nallow more expressive multi-layer construction of semi-implicit distributions.\nBy introducing auxiliary distributions that interpolate between a simple base\ndistribution and the target distribution, the conditional layers can be trained\nby progressively matching these auxiliary distributions one layer after\nanother. Moreover, given pre-trained score networks, HSIVI can be used to\naccelerate the sampling process of diffusion models with the score matching\nobjective. We show that HSIVI significantly enhances the expressiveness of SIVI\non several Bayesian inference problems with complicated target distributions.\nWhen used for diffusion model acceleration, we show that HSIVI can produce high\nquality samples comparable to or better than the existing fast diffusion model\nbased samplers with a small number of function evaluations on various datasets.\n",
                "链接": "https://arxiv.org/abs/2310.17153"
            },
            {
                "文章ID": "123966",
                "标题": "Lookahead: An Inference Acceleration Framework for Large Language Model\n  with Lossless Generation Accuracy",
                "作者": " Yao Zhao,  Zhitian Xie,  Chenyi Zhuang,  Jinjie Gu",
                "发布日期": "2023-12-21",
                "摘要": "  As Large Language Models (LLMs) have made significant advancements across\nvarious tasks, such as question answering, translation, text summarization, and\ndialogue systems, the need for accuracy in information becomes crucial,\nespecially for serious financial products serving billions of users like\nAlipay. To address this, Alipay has developed a Retrieval-Augmented Generation\n(RAG) system that grounds LLMs on the most accurate and up-to-date information.\nHowever, for a real-world product serving millions of users, the inference\nspeed of LLMs becomes a critical factor compared to a mere experimental model.\n  Hence, this paper presents a generic framework for accelerating the inference\nprocess, resulting in a substantial increase in speed and cost reduction for\nour RAG system, with lossless generation accuracy. In the traditional inference\nprocess, each token is generated sequentially by the LLM, leading to a time\nconsumption proportional to the number of generated tokens. To enhance this\nprocess, our framework, named \\textit{lookahead}, introduces a\n\\textit{multi-branch} strategy. Instead of generating a single token at a time,\nwe propose a \\textit{Trie-based Retrieval} (TR) process that enables the\ngeneration of multiple branches simultaneously, each of which is a sequence of\ntokens. Subsequently, for each branch, a \\textit{Verification and Accept} (VA)\nprocess is performed to identify the longest correct sub-sequence as the final\noutput. Our strategy offers two distinct advantages: (1) it guarantees absolute\ncorrectness of the output, avoiding any approximation algorithms, and (2) the\nworst-case performance of our approach is equivalent to the conventional\nprocess. We conduct extensive experiments to demonstrate the significant\nimprovements achieved by applying our inference acceleration framework.\n",
                "链接": "https://arxiv.org/abs/2312.12728"
            },
            {
                "文章ID": "124676",
                "标题": "Understanding the Potential of FPGA-Based Spatial Acceleration for Large\n  Language Model Inference",
                "作者": " Hongzheng Chen,  Jiahao Zhang,  Yixiao Du,  Shaojie Xiang,  Zichao Yue,  Niansong Zhang,  Yaohui Cai,  Zhiru Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Recent advancements in large language models (LLMs) boasting billions of\nparameters have generated a significant demand for efficient deployment in\ninference workloads. The majority of existing approaches rely on temporal\narchitectures that reuse hardware units for different network layers and\noperators. However, these methods often encounter challenges in achieving low\nlatency due to considerable memory access overhead. This paper investigates the\nfeasibility and potential of model-specific spatial acceleration for LLM\ninference on FPGAs. Our approach involves the specialization of distinct\nhardware units for specific operators or layers, facilitating direct\ncommunication between them through a dataflow architecture while minimizing\noff-chip memory accesses. We introduce a comprehensive analytical model for\nestimating the performance of a spatial LLM accelerator, taking into account\nthe on-chip compute and memory resources available on an FPGA. Through our\nanalysis, we can determine the scenarios in which FPGA-based spatial\nacceleration can outperform its GPU-based counterpart. To enable more\nproductive implementations of an LLM model on FPGAs, we further provide a\nlibrary of high-level synthesis (HLS) kernels that are composable and reusable.\nThis library will be made available as open-source. To validate the\neffectiveness of both our analytical model and HLS library, we have implemented\nBERT and GPT2 on an AMD Alveo U280 FPGA device. Experimental results\ndemonstrate our approach can achieve up to 16.1x speedup when compared to\nprevious FPGA-based accelerators for the BERT model. For GPT generative\ninference, we attain a 2.2x speedup compared to DFX, an FPGA overlay, in the\nprefill stage, while achieving a 1.9x speedup and a 5.7x improvement in energy\nefficiency compared to the NVIDIA A100 GPU in the decode stage.\n",
                "链接": "https://arxiv.org/abs/2312.15159"
            },
            {
                "文章ID": "117018",
                "标题": "Explaining Deep Learning Models for Age-related Gait Classification\n  based on time series acceleration",
                "作者": " Xiaoping Zheng,  Bert Otten,  Michiel F Reneman,  Claudine JC Lamoth",
                "发布日期": "2023-11-29",
                "摘要": "  Gait analysis holds significant importance in monitoring daily health,\nparticularly among older adults. Advancements in sensor technology enable the\ncapture of movement in real-life environments and generate big data. Machine\nlearning, notably deep learning (DL), shows promise to use these big data in\ngait analysis. However, the inherent black-box nature of these models poses\nchallenges for their clinical application. This study aims to enhance\ntransparency in DL-based gait classification for aged-related gait patterns\nusing Explainable Artificial Intelligence, such as SHAP.\n  A total of 244 subjects, comprising 129 adults and 115 older adults (age>65),\nwere included. They performed a 3-minute walking task while accelerometers were\naffixed to the lumbar segment L3. DL models, convolutional neural network (CNN)\nand gated recurrent unit (GRU), were trained using 1-stride and 8-stride\naccelerations, respectively, to classify adult and older adult groups. SHAP was\nemployed to explain the models' predictions.\n  CNN achieved a satisfactory performance with an accuracy of 81.4% and an AUC\nof 0.89, and GRU demonstrated promising results with an accuracy of 84.5% and\nan AUC of 0.94. SHAP analysis revealed that both CNN and GRU assigned higher\nSHAP values to the data from vertical and walking directions, particularly\nemphasizing data around heel contact, spanning from the terminal swing to\nloading response phases. Furthermore, SHAP values indicated that GRU did not\ntreat every stride equally.\n  CNN accurately distinguished between adults and older adults based on the\ncharacteristics of a single stride's data. GRU achieved accurate classification\nby considering the relationships and subtle differences between strides. In\nboth models, data around heel contact emerged as most critical, suggesting\ndifferences in acceleration and deceleration patterns during walking between\ndifferent age groups.\n",
                "链接": "https://arxiv.org/abs/2311.12089"
            },
            {
                "文章ID": "107843",
                "标题": "Sparse Fine-tuning for Inference Acceleration of Large Language Models",
                "作者": " Eldar Kurtic,  Denis Kuznedelev,  Elias Frantar,  Michael Goin,  Dan Alistarh",
                "发布日期": "2023-10-16",
                "摘要": "  We consider the problem of accurate sparse fine-tuning of large language\nmodels (LLMs), that is, fine-tuning pretrained LLMs on specialized tasks, while\ninducing sparsity in their weights. On the accuracy side, we observe that\nstandard loss-based fine-tuning may fail to recover accuracy, especially at\nhigh sparsities. To address this, we perform a detailed study of\ndistillation-type losses, determining an L2-based distillation approach we term\nSquareHead which enables accurate recovery even at higher sparsities, across\nall model types. On the practical efficiency side, we show that sparse LLMs can\nbe executed with speedups by taking advantage of sparsity, for both CPU and GPU\nruntimes. While the standard approach is to leverage sparsity for computational\nreduction, we observe that in the case of memory-bound LLMs sparsity can also\nbe leveraged for reducing memory bandwidth. We exhibit end-to-end results\nshowing speedups due to sparsity, while recovering accuracy, on T5 (language\ntranslation), Whisper (speech translation), and open GPT-type (MPT for text\ngeneration). For MPT text generation, we show for the first time that sparse\nfine-tuning can reach 75% sparsity without accuracy drops, provide notable\nend-to-end speedups for both CPU and GPU inference, and highlight that sparsity\nis also compatible with quantization approaches. Models and software for\nreproducing our results are provided in Section 6.\n",
                "链接": "https://arxiv.org/abs/2310.06927"
            },
            {
                "文章ID": "94810",
                "标题": "Exploiting On-chip Heterogeneity of Versal Architecture for GNN\n  Inference Acceleration",
                "作者": " Paul Chen,  Pavan Manjunath,  Sasindu Wijeratne,  Bingyi Zhang,  Viktor Prasanna",
                "发布日期": "2023-08-08",
                "摘要": "  Graph Neural Networks (GNNs) have revolutionized many Machine Learning (ML)\napplications, such as social network analysis, bioinformatics, etc. GNN\ninference can be accelerated by exploiting data sparsity in the input graph,\nvertex features, and intermediate data in GNN computations. For dynamic\nsparsity exploitation, we leverage the heterogeneous computing capabilities of\nAMD Versal ACAP architecture to accelerate GNN inference. We develop a custom\nhardware module that executes the sparse primitives of the computation kernel\non the Programmable Logic (PL) and efficiently computes the dense primitives\nusing the AI Engine (AIE). To exploit data sparsity during inference, we devise\na runtime kernel mapping strategy that dynamically assigns computation tasks to\nthe PL and AIE based on data sparsity. Our implementation on the VCK5000 ACAP\nplatform leads to superior performance compared with the state-of-the-art\nimplementations on CPU, GPU, ACAP, and other custom GNN accelerators. Compared\nwith these implementations, we achieve significant average runtime speedup\nacross various models and datasets of 162.42x, 17.01x, 9.90x, and 27.23x,\nrespectively. Furthermore, for Graph Convolutional Network (GCN) inference, our\napproach leads to a speedup of 3.9-96.7x compared to designs using PL only on\nthe same ACAP device.\n",
                "链接": "https://arxiv.org/abs/2308.02749"
            },
            {
                "文章ID": "87109",
                "标题": "Adaptive DNN Surgery for Selfish Inference Acceleration with On-demand\n  Edge Resource",
                "作者": " Xiang Yang,  Dezhi Chen,  Qi Qi,  Jingyu Wang,  Haifeng Sun,  Jianxin Liao,  Song Guo",
                "发布日期": "2023-06-22",
                "摘要": "  Deep Neural Networks (DNNs) have significantly improved the accuracy of\nintelligent applications on mobile devices. DNN surgery, which partitions DNN\nprocessing between mobile devices and multi-access edge computing (MEC)\nservers, can enable real-time inference despite the computational limitations\nof mobile devices. However, DNN surgery faces a critical challenge: determining\nthe optimal computing resource demand from the server and the corresponding\npartition strategy, while considering both inference latency and MEC server\nusage costs. This problem is compounded by two factors: (1) the finite\ncomputing capacity of the MEC server, which is shared among multiple devices,\nleading to inter-dependent demands, and (2) the shift in modern DNN\narchitecture from chains to directed acyclic graphs (DAGs), which complicates\npotential solutions.\n  In this paper, we introduce a novel Decentralized DNN Surgery (DDS)\nframework. We formulate the partition strategy as a min-cut and propose a\nresource allocation game to adaptively schedule the demands of mobile devices\nin an MEC environment. We prove the existence of a Nash Equilibrium (NE), and\ndevelop an iterative algorithm to efficiently reach the NE for each device. Our\nextensive experiments demonstrate that DDS can effectively handle varying MEC\nscenarios, achieving up to 1.25$\\times$ acceleration compared to the\nstate-of-the-art algorithm.\n",
                "链接": "https://arxiv.org/abs/2306.12185"
            },
            {
                "文章ID": "112504",
                "标题": "SparseByteNN: A Novel Mobile Inference Acceleration Framework Based on\n  Fine-Grained Group Sparsity",
                "作者": " Haitao Xu,  Songwei Liu,  Yuyang Xu,  Shuai Wang,  Jiashi Li,  Chenqian Yan,  Liangqiang Li,  Lean Fu,  Xin Pan,  Fangmin Chen",
                "发布日期": "2023-10-31",
                "摘要": "  To address the challenge of increasing network size, researchers have\ndeveloped sparse models through network pruning. However, maintaining model\naccuracy while achieving significant speedups on general computing devices\nremains an open problem. In this paper, we present a novel mobile inference\nacceleration framework SparseByteNN, which leverages fine-grained kernel\nsparsity to achieve real-time execution as well as high accuracy. Our framework\nconsists of two parts: (a) A fine-grained kernel sparsity schema with a\nsparsity granularity between structured pruning and unstructured pruning. It\ndesigns multiple sparse patterns for different operators. Combined with our\nproposed whole network rearrangement strategy, the schema achieves a high\ncompression rate and high precision at the same time. (b) Inference engine\nco-optimized with the sparse pattern. The conventional wisdom is that this\nreduction in theoretical FLOPs does not translate into real-world efficiency\ngains. We aim to correct this misconception by introducing a family of\nefficient sparse kernels for ARM and WebAssembly. Equipped with our efficient\nimplementation of sparse primitives, we show that sparse versions of\nMobileNet-v1 outperform strong dense baselines on the efficiency-accuracy\ncurve. Experimental results on Qualcomm 855 show that for 30% sparse\nMobileNet-v1, SparseByteNN achieves 1.27x speedup over the dense version and\n1.29x speedup over the state-of-the-art sparse inference engine MNN with a\nslight accuracy drop of 0.224%. The source code of SparseByteNN will be\navailable at https://github.com/lswzjuer/SparseByteNN\n",
                "链接": "https://arxiv.org/abs/2310.19509"
            },
            {
                "文章ID": "108754",
                "标题": "Towards More Accurate Diffusion Model Acceleration with A Timestep\n  Aligner",
                "作者": " Mengfei Xia,  Yujun Shen,  Changsong Lei,  Yu Zhou,  Ran Yi,  Deli Zhao,  Wenping Wang,  Yong-jin Liu",
                "发布日期": "2023-10-17",
                "摘要": "  A diffusion model, which is formulated to produce an image using thousands of\ndenoising steps, usually suffers from a slow inference speed. Existing\nacceleration algorithms simplify the sampling by skipping most steps yet\nexhibit considerable performance degradation. By viewing the generation of\ndiffusion models as a discretized integrating process, we argue that the\nquality drop is partly caused by applying an inaccurate integral direction to a\ntimestep interval. To rectify this issue, we propose a timestep aligner that\nhelps find a more accurate integral direction for a particular interval at the\nminimum cost. Specifically, at each denoising step, we replace the original\nparameterization by conditioning the network on a new timestep, which is\nobtained by aligning the sampling distribution to the real distribution.\nExtensive experiments show that our plug-in design can be trained efficiently\nand boost the inference performance of various state-of-the-art acceleration\nmethods, especially when there are few denoising steps. For example, when using\n10 denoising steps on the popular LSUN Bedroom dataset, we improve the FID of\nDDIM from 9.65 to 6.07, simply by adopting our method for a more appropriate\nset of timesteps. Code will be made publicly available.\n",
                "链接": "https://arxiv.org/abs/2310.09469"
            },
            {
                "文章ID": "102164",
                "标题": "Draft & Verify: Lossless Large Language Model Acceleration via\n  Self-Speculative Decoding",
                "作者": " Jun Zhang,  Jue Wang,  Huan Li,  Lidan Shou,  Ke Chen,  Gang Chen,  Sharad Mehrotra",
                "发布日期": "2023-09-18",
                "摘要": "  We present a novel inference scheme, self-speculative decoding, for\naccelerating Large Language Models (LLMs) without the need for an auxiliary\nmodel. This approach is characterized by a two-stage process: drafting and\nverification. The drafting stage generates draft tokens at a slightly lower\nquality but more quickly, which is achieved by selectively skipping certain\nintermediate layers during drafting Subsequently, the verification stage\nemploys the original LLM to validate those draft output tokens in one forward\npass. This process ensures the final output remains identical to that produced\nby the unaltered LLM, thereby maintaining output quality. The proposed method\nrequires no additional neural network training and no extra memory footprint,\nmaking it a plug-and-play and cost-effective solution for inference\nacceleration. Benchmarks with LLaMA-2 and its fine-tuned models demonstrated a\nspeedup up to 1.73$\\times$.\n",
                "链接": "https://arxiv.org/abs/2309.08168"
            }
        ]
    },
    {
        "question": {
            "question": "查找论文中包含指令微调细节描述的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "100215",
                "标题": "Donkii: Can Annotation Error Detection Methods Find Errors in\n  Instruction-Tuning Datasets?",
                "作者": " Leon Weber-Genzel,  Robert Litschko,  Ekaterina Artemova,  Barbara Plank",
                "发布日期": "2023-09-06",
                "摘要": "  Instruction-tuning has become an integral part of training pipelines for\nLarge Language Models (LLMs) and has been shown to yield strong performance\ngains. In an orthogonal line of research, Annotation Error Detection (AED) has\nemerged as a tool for detecting quality issues of gold-standard labels. But so\nfar, the application of AED methods is limited to discriminative settings. It\nis an open question how well AED methods generalize to generative settings\nwhich are becoming widespread via generative LLMs. In this work, we present a\nfirst and new benchmark for AED on instruction-tuning data: Donkii. It\nencompasses three instruction-tuning datasets enriched with annotations by\nexperts and semi-automatic methods. We find that all three datasets contain\nclear-cut errors that sometimes directly propagate into instruction-tuned LLMs.\nWe propose four AED baselines for the generative setting and evaluate them\ncomprehensively on the newly introduced dataset. Our results demonstrate that\nchoosing the right AED method and model size is indeed crucial, thereby\nderiving practical recommendations. To gain insights, we provide a first\ncase-study to examine how the quality of the instruction-tuning datasets\ninfluences downstream performance.\n",
                "链接": "https://arxiv.org/abs/2309.01669"
            },
            {
                "文章ID": "72812",
                "标题": "Visual Instruction Tuning",
                "作者": " Haotian Liu,  Chunyuan Li,  Qingyang Wu,  Yong Jae Lee",
                "发布日期": "2023-12-14",
                "摘要": "  Instruction tuning large language models (LLMs) using machine-generated\ninstruction-following data has improved zero-shot capabilities on new tasks,\nbut the idea is less explored in the multimodal field. In this paper, we\npresent the first attempt to use language-only GPT-4 to generate multimodal\nlanguage-image instruction-following data. By instruction tuning on such\ngenerated data, we introduce LLaVA: Large Language and Vision Assistant, an\nend-to-end trained large multimodal model that connects a vision encoder and\nLLM for general-purpose visual and language understanding.Our early experiments\nshow that LLaVA demonstrates impressive multimodel chat abilities, sometimes\nexhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and\nyields a 85.1% relative score compared with GPT-4 on a synthetic multimodal\ninstruction-following dataset. When fine-tuned on Science QA, the synergy of\nLLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make\nGPT-4 generated visual instruction tuning data, our model and code base\npublicly available.\n",
                "链接": "https://arxiv.org/abs/2304.08485"
            },
            {
                "文章ID": "71129",
                "标题": "Instruction Tuning with GPT-4",
                "作者": " Baolin Peng,  Chunyuan Li,  Pengcheng He,  Michel Galley,  Jianfeng Gao",
                "发布日期": "2023-04-07",
                "摘要": "  Prior work has shown that finetuning large language models (LLMs) using\nmachine-generated instruction-following data enables such models to achieve\nremarkable zero-shot capabilities on new tasks, and no human-written\ninstructions are needed. In this paper, we present the first attempt to use\nGPT-4 to generate instruction-following data for LLM finetuning. Our early\nexperiments on instruction-tuned LLaMA models show that the 52K English and\nChinese instruction-following data generated by GPT-4 leads to superior\nzero-shot performance on new tasks to the instruction-following data generated\nby previous state-of-the-art models. We also collect feedback and comparison\ndata from GPT-4 to enable a comprehensive evaluation and reward model training.\nWe make our data generated using GPT-4 as well as our codebase publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2304.03277"
            },
            {
                "文章ID": "108778",
                "标题": "Instruction Tuning with Human Curriculum",
                "作者": " Bruce W. Lee,  Hyunsoo Cho,  Kang Min Yoo",
                "发布日期": "2023-10-17",
                "摘要": "  The dominant paradigm for instruction tuning is the random-shuffled training\nof maximally diverse instruction-response pairs. This paper explores the\npotential benefits of applying a structured cognitive learning approach to\ninstruction tuning in contemporary large language models like ChatGPT and\nGPT-4. Unlike the previous conventional randomized instruction dataset, we\npropose a highly structured synthetic dataset that mimics the progressive and\norganized nature of human education. We curate our dataset by aligning it with\neducational frameworks, incorporating meta information including its topic and\ncognitive rigor level for each sample. Our dataset covers comprehensive\nfine-grained topics spanning diverse educational stages (from middle school to\ngraduate school) with various questions for each topic to enhance conceptual\ndepth using Bloom's taxonomy-a classification framework distinguishing various\nlevels of human cognition for each concept. The results demonstrate that this\ncognitive rigorous training approach yields significant performance\nenhancements - +3.06 on the MMLU benchmark and an additional +1.28 on AI2\nReasoning Challenge (hard set) - compared to conventional randomized training,\nall while avoiding additional computational costs. This research highlights the\npotential of leveraging human learning principles to enhance the capabilities\nof language models in comprehending and responding to complex instructions and\ntasks.\n",
                "链接": "https://arxiv.org/abs/2310.09518"
            },
            {
                "文章ID": "109604",
                "标题": "Reflection-Tuning: Data Recycling Improves LLM Instruction-Tuning",
                "作者": " Ming Li,  Lichang Chen,  Jiuhai Chen,  Shwai He,  Heng Huang,  Jiuxiang Gu,  Tianyi Zhou",
                "发布日期": "2023-10-19",
                "摘要": "  Recent advancements in Large Language Models (LLMs) have expanded the\nhorizons of natural language understanding and generation. Notably, the output\ncontrol and alignment with the input of LLMs can be refined through instruction\ntuning. However, as highlighted in several studies, low-quality data in the\ntraining set are usually detrimental to instruction tuning, resulting in\ninconsistent or even misleading LLM outputs. We propose a novel method, termed\n\"reflection-tuning,\" which addresses the problem by self-improvement and\njudging capabilities of LLMs. This approach utilizes an oracle LLM to recycle\nthe original training data by introspecting and enhancing the quality of\ninstructions and responses in the data. Extensive experiments on widely used\nevaluation benchmarks show that LLMs trained with our recycled data outperform\nthose trained with existing datasets in various benchmarks.\n",
                "链接": "https://arxiv.org/abs/2310.11716"
            },
            {
                "文章ID": "100423",
                "标题": "CIEM: Contrastive Instruction Evaluation Method for Better Instruction\n  Tuning",
                "作者": " Hongyu Hu,  Jiyuan Zhang,  Minyi Zhao,  Zhenbang Sun",
                "发布日期": "2023-11-27",
                "摘要": "  Nowadays, the research on Large Vision-Language Models (LVLMs) has been\nsignificantly promoted thanks to the success of Large Language Models (LLM).\nNevertheless, these Vision-Language Models (VLMs) are suffering from the\ndrawback of hallucination -- due to insufficient understanding of vision and\nlanguage modalities, VLMs may generate incorrect perception information when\ndoing downstream applications, for example, captioning a non-existent entity.\nTo address the hallucination phenomenon, on the one hand, we introduce a\nContrastive Instruction Evaluation Method (CIEM), which is an automatic\npipeline that leverages an annotated image-text dataset coupled with an LLM to\ngenerate factual/contrastive question-answer pairs for the evaluation of the\nhallucination of VLMs. On the other hand, based on CIEM, we further propose a\nnew instruction tuning method called CIT (the abbreviation of Contrastive\nInstruction Tuning) to alleviate the hallucination of VLMs by automatically\nproducing high-quality factual/contrastive question-answer pairs and\ncorresponding justifications for model tuning. Through extensive experiments on\nCIEM and CIT, we pinpoint the hallucination issues commonly present in existing\nVLMs, the disability of the current instruction-tuning dataset to handle the\nhallucination phenomenon and the superiority of CIT-tuned VLMs over both CIEM\nand public datasets.\n",
                "链接": "https://arxiv.org/abs/2309.02301"
            },
            {
                "文章ID": "117440",
                "标题": "Automatic Instruction Optimization for Open-source LLM Instruction\n  Tuning",
                "作者": " Yilun Liu,  Shimin Tao,  Xiaofeng Zhao,  Ming Zhu,  Wenbing Ma,  Junhao Zhu,  Chang Su,  Yutai Hou,  Miao Zhang,  Min Zhang,  Hongxia Ma,  Li Zhang,  Hao Yang,  Yanfei Jiang",
                "发布日期": "2023-11-23",
                "摘要": "  Instruction tuning is crucial for enabling Language Learning Models (LLMs) in\nresponding to human instructions. The quality of instruction pairs used for\ntuning greatly affects the performance of LLMs. However, the manual creation of\nhigh-quality instruction datasets is costly, leading to the adoption of\nautomatic generation of instruction pairs by LLMs as a popular alternative in\nthe training of open-source LLMs. To ensure the high quality of LLM-generated\ninstruction datasets, several approaches have been proposed. Nevertheless,\nexisting methods either compromise dataset integrity by filtering a large\nproportion of samples, or are unsuitable for industrial applications. In this\npaper, instead of discarding low-quality samples, we propose CoachLM, a novel\napproach to enhance the quality of instruction datasets through automatic\nrevisions on samples in the dataset. CoachLM is trained from the samples\nrevised by human experts and significantly increases the proportion of\nhigh-quality samples in the dataset from 17.7% to 78.9%. The effectiveness of\nCoachLM is further assessed on various real-world instruction test sets. The\nresults show that CoachLM improves the instruction-following capabilities of\nthe instruction-tuned LLM by an average of 29.9%, which even surpasses larger\nLLMs with nearly twice the number of parameters. Furthermore, CoachLM is\nsuccessfully deployed in a data management system for LLMs at Huawei, resulting\nin an efficiency improvement of up to 20% in the cleaning of 40k real-world\ninstruction pairs. We release the training data and code of CoachLM\n(https://github.com/lunyiliu/CoachLM).\n",
                "链接": "https://arxiv.org/abs/2311.13246"
            },
            {
                "文章ID": "5011",
                "标题": "Describing image focused in cognitive and visual details for visually\n  impaired people: An approach to generating inclusive paragraphs",
                "作者": " Daniel Louzada Fernandes,  Marcos Henrique Fonseca Ribeiro,  Fabio Ribeiro Cerqueira,  Michel Melo Silva",
                "发布日期": "2022-02-17",
                "摘要": "  Several services for people with visual disabilities have emerged recently\ndue to achievements in Assistive Technologies and Artificial Intelligence\nareas. Despite the growth in assistive systems availability, there is a lack of\nservices that support specific tasks, such as understanding the image context\npresented in online content, e.g., webinars. Image captioning techniques and\ntheir variants are limited as Assistive Technologies as they do not match the\nneeds of visually impaired people when generating specific descriptions. We\npropose an approach for generating context of webinar images combining a dense\ncaptioning technique with a set of filters, to fit the captions in our domain,\nand a language model for the abstractive summary task. The results demonstrated\nthat we can produce descriptions with higher interpretability and focused on\nthe relevant information for that group of people by combining image analysis\nmethods and neural language models.\n",
                "链接": "https://arxiv.org/abs/2202.05331"
            },
            {
                "文章ID": "75184",
                "标题": "Poisoning Language Models During Instruction Tuning",
                "作者": " Alexander Wan,  Eric Wallace,  Sheng Shen,  Dan Klein",
                "发布日期": "2023-05-02",
                "摘要": "  Instruction-tuned LMs such as ChatGPT, FLAN, and InstructGPT are finetuned on\ndatasets that contain user-submitted examples, e.g., FLAN aggregates numerous\nopen-source datasets and OpenAI leverages examples submitted in the browser\nplayground. In this work, we show that adversaries can contribute poison\nexamples to these datasets, allowing them to manipulate model predictions\nwhenever a desired trigger phrase appears in the input. For example, when a\ndownstream user provides an input that mentions \"Joe Biden\", a poisoned LM will\nstruggle to classify, summarize, edit, or translate that input. To construct\nthese poison examples, we optimize their inputs and outputs using a\nbag-of-words approximation to the LM. We evaluate our method on open-source\ninstruction-tuned LMs. By using as few as 100 poison examples, we can cause\narbitrary phrases to have consistent negative polarity or induce degenerate\noutputs across hundreds of held-out tasks. Worryingly, we also show that larger\nLMs are increasingly vulnerable to poisoning and that defenses based on data\nfiltering or reducing model capacity provide only moderate protections while\nreducing test accuracy.\n",
                "链接": "https://arxiv.org/abs/2305.00944"
            },
            {
                "文章ID": "88641",
                "标题": "On the Exploitability of Instruction Tuning",
                "作者": " Manli Shu,  Jiongxiao Wang,  Chen Zhu,  Jonas Geiping,  Chaowei Xiao,  Tom Goldstein",
                "发布日期": "2023-10-31",
                "摘要": "  Instruction tuning is an effective technique to align large language models\n(LLMs) with human intents. In this work, we investigate how an adversary can\nexploit instruction tuning by injecting specific instruction-following examples\ninto the training data that intentionally changes the model's behavior. For\nexample, an adversary can achieve content injection by injecting training\nexamples that mention target content and eliciting such behavior from\ndownstream models. To achieve this goal, we propose \\textit{AutoPoison}, an\nautomated data poisoning pipeline. It naturally and coherently incorporates\nversatile attack goals into poisoned data with the help of an oracle LLM. We\nshowcase two example attacks: content injection and over-refusal attacks, each\naiming to induce a specific exploitable behavior. We quantify and benchmark the\nstrength and the stealthiness of our data poisoning scheme. Our results show\nthat AutoPoison allows an adversary to change a model's behavior by poisoning\nonly a small fraction of data while maintaining a high level of stealthiness in\nthe poisoned examples. We hope our work sheds light on how data quality affects\nthe behavior of instruction-tuned models and raises awareness of the importance\nof data quality for responsible deployments of LLMs. Code is available at\n\\url{https://github.com/azshue/AutoPoison}.\n",
                "链接": "https://arxiv.org/abs/2306.17194"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本检测最新进展",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "43946",
                "标题": "OCR-VQGAN: Taming Text-within-Image Generation",
                "作者": " Juan A. Rodriguez,  David Vazquez,  Issam Laradji,  Marco Pedersoli,  Pau Rodriguez",
                "发布日期": "2022-10-26",
                "摘要": "  Synthetic image generation has recently experienced significant improvements\nin domains such as natural image or art generation. However, the problem of\nfigure and diagram generation remains unexplored. A challenging aspect of\ngenerating figures and diagrams is effectively rendering readable texts within\nthe images. To alleviate this problem, we present OCR-VQGAN, an image encoder,\nand decoder that leverages OCR pre-trained features to optimize a text\nperceptual loss, encouraging the architecture to preserve high-fidelity text\nand diagram structure. To explore our approach, we introduce the Paper2Fig100k\ndataset, with over 100k images of figures and texts from research papers. The\nfigures show architecture diagrams and methodologies of articles available at\narXiv.org from fields like artificial intelligence and computer vision. Figures\nusually include text and discrete objects, e.g., boxes in a diagram, with lines\nand arrows that connect them. We demonstrate the effectiveness of OCR-VQGAN by\nconducting several experiments on the task of figure reconstruction.\nAdditionally, we explore the qualitative and quantitative impact of weighting\ndifferent perceptual metrics in the overall loss function. We release code,\nmodels, and dataset at https://github.com/joanrod/ocr-vqgan.\n",
                "链接": "https://arxiv.org/abs/2210.11248"
            },
            {
                "文章ID": "49513",
                "标题": "Intelligent Computing: The Latest Advances, Challenges and Future",
                "作者": " Shiqiang Zhu,  Ting Yu,  Tao Xu,  Hongyang Chen,  Schahram Dustdar,  Sylvain Gigan,  Deniz Gunduz,  Ekram Hossain,  Yaochu Jin,  Feng Lin,  Bo Liu,  Zhiguo Wan,  Ji Zhang,  Zhifeng Zhao,  Wentao Zhu,  Zuoning Chen,  Tariq Durrani,  Huaimin Wang,  Jiangxing Wu,  Tongyi Zhang,  Yunhe Pan",
                "发布日期": "2022-11-22",
                "摘要": "  Computing is a critical driving force in the development of human\ncivilization. In recent years, we have witnessed the emergence of intelligent\ncomputing, a new computing paradigm that is reshaping traditional computing and\npromoting digital revolution in the era of big data, artificial intelligence\nand internet-of-things with new computing theories, architectures, methods,\nsystems, and applications. Intelligent computing has greatly broadened the\nscope of computing, extending it from traditional computing on data to\nincreasingly diverse computing paradigms such as perceptual intelligence,\ncognitive intelligence, autonomous intelligence, and human-computer fusion\nintelligence. Intelligence and computing have undergone paths of different\nevolution and development for a long time but have become increasingly\nintertwined in recent years: intelligent computing is not only\nintelligence-oriented but also intelligence-driven. Such cross-fertilization\nhas prompted the emergence and rapid advancement of intelligent computing.\nIntelligent computing is still in its infancy and an abundance of innovations\nin the theories, systems, and applications of intelligent computing are\nexpected to occur soon. We present the first comprehensive survey of literature\non intelligent computing, covering its theory fundamentals, the technological\nfusion of intelligence and computing, important applications, challenges, and\nfuture perspectives. We believe that this survey is highly timely and will\nprovide a comprehensive reference and cast valuable insights into intelligent\ncomputing for academic and industrial researchers and practitioners.\n",
                "链接": "https://arxiv.org/abs/2211.11281"
            },
            {
                "文章ID": "48455",
                "标题": "A Benchmark and Dataset for Post-OCR text correction in Sanskrit",
                "作者": " Ayush Maheshwari,  Nikhil Singh,  Amrith Krishna,  Ganesh Ramakrishnan",
                "发布日期": "2022-11-16",
                "摘要": "  Sanskrit is a classical language with about 30 million extant manuscripts fit\nfor digitisation, available in written, printed or scannedimage forms. However,\nit is still considered to be a low-resource language when it comes to available\ndigital resources. In this work, we release a post-OCR text correction dataset\ncontaining around 218,000 sentences, with 1.5 million words, from 30 different\nbooks. Texts in Sanskrit are known to be diverse in terms of their linguistic\nand stylistic usage since Sanskrit was the 'lingua franca' for discourse in the\nIndian subcontinent for about 3 millennia. Keeping this in mind, we release a\nmulti-domain dataset, from areas as diverse as astronomy, medicine and\nmathematics, with some of them as old as 18 centuries. Further, we release\nmultiple strong baselines as benchmarks for the task, based on pre-trained\nSeq2Seq language models. We find that our best-performing model, consisting of\nbyte level tokenization in conjunction with phonetic encoding (Byt5+SLP1),\nyields a 23% point increase over the OCR output in terms of word and character\nerror rates. Moreover, we perform extensive experiments in evaluating these\nmodels on their performance and analyse common causes of mispredictions both at\nthe graphemic and lexical levels. Our code and dataset is publicly available at\nhttps://github.com/ayushbits/pe-ocr-sanskrit.\n",
                "链接": "https://arxiv.org/abs/2211.07980"
            },
            {
                "文章ID": "87564",
                "标题": "Resume Information Extraction via Post-OCR Text Processing",
                "作者": " Selahattin Serdar Helli,  Senem Tanberk,  Sena Nur Cavsak",
                "发布日期": "2023-06-27",
                "摘要": "  Information extraction (IE), one of the main tasks of natural language\nprocessing (NLP), has recently increased importance in the use of resumes. In\nstudies on the text to extract information from the CV, sentence classification\nwas generally made using NLP models. In this study, it is aimed to extract\ninformation by classifying all of the text groups after pre-processing such as\nOptical Character Recognition (OCT) and object recognition with the YOLOv8\nmodel of the resumes. The text dataset consists of 286 resumes collected for 5\ndifferent (education, experience, talent, personal and language) job\ndescriptions in the IT industry. The dataset created for object recognition\nconsists of 1198 resumes, which were collected from the open-source internet\nand labeled as sets of text. BERT, BERT-t, DistilBERT, RoBERTa and XLNet were\nused as models. F1 score variances were used to compare the model results. In\naddition, the YOLOv8 model has also been reported comparatively in itself. As a\nresult of the comparison, DistilBERT was showed better results despite having a\nlower number of parameters than other models.\n",
                "链接": "https://arxiv.org/abs/2306.13775"
            },
            {
                "文章ID": "103556",
                "标题": "Education in the age of Generative AI: Context and Recent Developments",
                "作者": " Rafael Ferreira Mello,  Elyda Freitas,  Filipe Dwan Pereira,  Luciano Cabral,  Patricia Tedesco,  Geber Ramalho",
                "发布日期": "2023-09-25",
                "摘要": "  With the emergence of generative artificial intelligence, an increasing\nnumber of individuals and organizations have begun exploring its potential to\nenhance productivity and improve product quality across various sectors. The\nfield of education is no exception. However, it is vital to notice that\nartificial intelligence adoption in education dates back to the 1960s. In light\nof this historical context, this white paper serves as the inaugural piece in a\nfour-part series that elucidates the role of AI in education. The series delves\ninto topics such as its potential, successful applications, limitations,\nethical considerations, and future trends. This initial article provides a\ncomprehensive overview of the field, highlighting the recent developments\nwithin the generative artificial intelligence sphere.\n",
                "链接": "https://arxiv.org/abs/2309.12332"
            },
            {
                "文章ID": "79433",
                "标题": "Deepfake Text Detection in the Wild",
                "作者": " Yafu Li,  Qintong Li,  Leyang Cui,  Wei Bi,  Longyue Wang,  Linyi Yang,  Shuming Shi,  Yue Zhang",
                "发布日期": "2023-05-23",
                "摘要": "  Recent advances in large language models have enabled them to reach a level\nof text generation comparable to that of humans. These models show powerful\ncapabilities across a wide range of content, including news article writing,\nstory generation, and scientific writing. Such capability further narrows the\ngap between human-authored and machine-generated texts, highlighting the\nimportance of deepfake text detection to avoid potential risks such as fake\nnews propagation and plagiarism. However, previous work has been limited in\nthat they testify methods on testbed of specific domains or certain language\nmodels. In practical scenarios, the detector faces texts from various domains\nor LLMs without knowing their sources. To this end, we build a wild testbed by\ngathering texts from various human writings and deepfake texts generated by\ndifferent LLMs. Human annotators are only slightly better than random guessing\nat identifying machine-generated texts. Empirical results on automatic\ndetection methods further showcase the challenges of deepfake text detection in\na wild testbed. In addition, out-of-distribution poses a greater challenge for\na detector to be employed in realistic application scenarios. We release our\nresources at https://github.com/yafuly/DeepfakeTextDetect.\n",
                "链接": "https://arxiv.org/abs/2305.13242"
            },
            {
                "文章ID": "87257",
                "标题": "Recent Developments in Recommender Systems: A Survey",
                "作者": " Yang Li,  Kangbo Liu,  Ranjan Satapathy,  Suhang Wang,  Erik Cambria",
                "发布日期": "2023-07-06",
                "摘要": "  In this technical survey, we comprehensively summarize the latest\nadvancements in the field of recommender systems. The objective of this study\nis to provide an overview of the current state-of-the-art in the field and\nhighlight the latest trends in the development of recommender systems. The\nstudy starts with a comprehensive summary of the main taxonomy of recommender\nsystems, including personalized and group recommender systems, and then delves\ninto the category of knowledge-based recommender systems. In addition, the\nsurvey analyzes the robustness, data bias, and fairness issues in recommender\nsystems, summarizing the evaluation metrics used to assess the performance of\nthese systems. Finally, the study provides insights into the latest trends in\nthe development of recommender systems and highlights the new directions for\nfuture research in the field.\n",
                "链接": "https://arxiv.org/abs/2306.12680"
            },
            {
                "文章ID": "52727",
                "标题": "OCR-RTPS: An OCR-based real-time positioning system for the valet\n  parking",
                "作者": " Zizhang Wu,  Xinyuan Chen,  Jizheng Wang,  Xiaoquan Wang,  Yuanzhu Gan,  Muqing Fang,  Tianhao Xu",
                "发布日期": "2022-12-12",
                "摘要": "  Obtaining the position of ego-vehicle is a crucial prerequisite for automatic\ncontrol and path planning in the field of autonomous driving. Most existing\npositioning systems rely on GPS, RTK, or wireless signals, which are arduous to\nprovide effective localization under weak signal conditions. This paper\nproposes a real-time positioning system based on the detection of the parking\nnumbers as they are unique positioning marks in the parking lot scene. It does\nnot only can help with the positioning with open area, but also run\nindependently under isolation environment. The result tested on both public\ndatasets and self-collected dataset show that the system outperforms others in\nboth performances and applies in practice. In addition, the code and dataset\nwill release later.\n",
                "链接": "https://arxiv.org/abs/2212.04116"
            },
            {
                "文章ID": "85288",
                "标题": "When Vision Fails: Text Attacks Against ViT and OCR",
                "作者": " Nicholas Boucher,  Jenny Blessing,  Ilia Shumailov,  Ross Anderson,  Nicolas Papernot",
                "发布日期": "2023-06-13",
                "摘要": "  While text-based machine learning models that operate on visual inputs of\nrendered text have become robust against a wide range of existing attacks, we\nshow that they are still vulnerable to visual adversarial examples encoded as\ntext. We use the Unicode functionality of combining diacritical marks to\nmanipulate encoded text so that small visual perturbations appear when the text\nis rendered. We show how a genetic algorithm can be used to generate visual\nadversarial examples in a black-box setting, and conduct a user study to\nestablish that the model-fooling adversarial examples do not affect human\ncomprehension. We demonstrate the effectiveness of these attacks in the real\nworld by creating adversarial examples against production models published by\nFacebook, Microsoft, IBM, and Google.\n",
                "链接": "https://arxiv.org/abs/2306.07033"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本识别最新进展。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "42779",
                "标题": "Text Detection Forgot About Document OCR",
                "作者": " Krzysztof Olejniczak,  Milan Šulc",
                "发布日期": "2023-01-24",
                "摘要": "  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n",
                "链接": "https://arxiv.org/abs/2210.07903"
            },
            {
                "文章ID": "43946",
                "标题": "OCR-VQGAN: Taming Text-within-Image Generation",
                "作者": " Juan A. Rodriguez,  David Vazquez,  Issam Laradji,  Marco Pedersoli,  Pau Rodriguez",
                "发布日期": "2022-10-26",
                "摘要": "  Synthetic image generation has recently experienced significant improvements\nin domains such as natural image or art generation. However, the problem of\nfigure and diagram generation remains unexplored. A challenging aspect of\ngenerating figures and diagrams is effectively rendering readable texts within\nthe images. To alleviate this problem, we present OCR-VQGAN, an image encoder,\nand decoder that leverages OCR pre-trained features to optimize a text\nperceptual loss, encouraging the architecture to preserve high-fidelity text\nand diagram structure. To explore our approach, we introduce the Paper2Fig100k\ndataset, with over 100k images of figures and texts from research papers. The\nfigures show architecture diagrams and methodologies of articles available at\narXiv.org from fields like artificial intelligence and computer vision. Figures\nusually include text and discrete objects, e.g., boxes in a diagram, with lines\nand arrows that connect them. We demonstrate the effectiveness of OCR-VQGAN by\nconducting several experiments on the task of figure reconstruction.\nAdditionally, we explore the qualitative and quantitative impact of weighting\ndifferent perceptual metrics in the overall loss function. We release code,\nmodels, and dataset at https://github.com/joanrod/ocr-vqgan.\n",
                "链接": "https://arxiv.org/abs/2210.11248"
            },
            {
                "文章ID": "87564",
                "标题": "Resume Information Extraction via Post-OCR Text Processing",
                "作者": " Selahattin Serdar Helli,  Senem Tanberk,  Sena Nur Cavsak",
                "发布日期": "2023-06-27",
                "摘要": "  Information extraction (IE), one of the main tasks of natural language\nprocessing (NLP), has recently increased importance in the use of resumes. In\nstudies on the text to extract information from the CV, sentence classification\nwas generally made using NLP models. In this study, it is aimed to extract\ninformation by classifying all of the text groups after pre-processing such as\nOptical Character Recognition (OCT) and object recognition with the YOLOv8\nmodel of the resumes. The text dataset consists of 286 resumes collected for 5\ndifferent (education, experience, talent, personal and language) job\ndescriptions in the IT industry. The dataset created for object recognition\nconsists of 1198 resumes, which were collected from the open-source internet\nand labeled as sets of text. BERT, BERT-t, DistilBERT, RoBERTa and XLNet were\nused as models. F1 score variances were used to compare the model results. In\naddition, the YOLOv8 model has also been reported comparatively in itself. As a\nresult of the comparison, DistilBERT was showed better results despite having a\nlower number of parameters than other models.\n",
                "链接": "https://arxiv.org/abs/2306.13775"
            },
            {
                "文章ID": "85288",
                "标题": "When Vision Fails: Text Attacks Against ViT and OCR",
                "作者": " Nicholas Boucher,  Jenny Blessing,  Ilia Shumailov,  Ross Anderson,  Nicolas Papernot",
                "发布日期": "2023-06-13",
                "摘要": "  While text-based machine learning models that operate on visual inputs of\nrendered text have become robust against a wide range of existing attacks, we\nshow that they are still vulnerable to visual adversarial examples encoded as\ntext. We use the Unicode functionality of combining diacritical marks to\nmanipulate encoded text so that small visual perturbations appear when the text\nis rendered. We show how a genetic algorithm can be used to generate visual\nadversarial examples in a black-box setting, and conduct a user study to\nestablish that the model-fooling adversarial examples do not affect human\ncomprehension. We demonstrate the effectiveness of these attacks in the real\nworld by creating adversarial examples against production models published by\nFacebook, Microsoft, IBM, and Google.\n",
                "链接": "https://arxiv.org/abs/2306.07033"
            },
            {
                "文章ID": "36484",
                "标题": "Levenshtein OCR",
                "作者": " Cheng Da,  Peng Wang,  Cong Yao",
                "发布日期": "2022-11-15",
                "摘要": "  A novel scene text recognizer based on Vision-Language Transformer (VLT) is\npresented. Inspired by Levenshtein Transformer in the area of NLP, the proposed\nmethod (named Levenshtein OCR, and LevOCR for short) explores an alternative\nway for automatically transcribing textual content from cropped natural images.\nSpecifically, we cast the problem of scene text recognition as an iterative\nsequence refinement process. The initial prediction sequence produced by a pure\nvision model is encoded and fed into a cross-modal transformer to interact and\nfuse with the visual features, to progressively approximate the ground truth.\nThe refinement process is accomplished via two basic character-level\noperations: deletion and insertion, which are learned with imitation learning\nand allow for parallel decoding, dynamic length change and good\ninterpretability. The quantitative experiments clearly demonstrate that LevOCR\nachieves state-of-the-art performances on standard benchmarks and the\nqualitative analyses verify the effectiveness and advantage of the proposed\nLevOCR algorithm. Code is available at\nhttps://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/LevOCR.\n",
                "链接": "https://arxiv.org/abs/2209.03594"
            },
            {
                "文章ID": "98478",
                "标题": "DISGO: Automatic End-to-End Evaluation for Scene Text OCR",
                "作者": " Mei-Yuh Hwang,  Yangyang Shi,  Ankit Ramchandani,  Guan Pang,  Praveen Krishnan,  Lucas Kabela,  Frank Seide,  Samyak Datta,  Jun Liu",
                "发布日期": "2023-08-28",
                "摘要": "  This paper discusses the challenges of optical character recognition (OCR) on\nnatural scenes, which is harder than OCR on documents due to the wild content\nand various image backgrounds. We propose to uniformly use word error rates\n(WER) as a new measurement for evaluating scene-text OCR, both end-to-end (e2e)\nperformance and individual system component performances. Particularly for the\ne2e metric, we name it DISGO WER as it considers Deletion, Insertion,\nSubstitution, and Grouping/Ordering errors. Finally we propose to utilize the\nconcept of super blocks to automatically compute BLEU scores for e2e OCR\nmachine translation. The small SCUT public test set is used to demonstrate WER\nperformance by a modularized OCR system.\n",
                "链接": "https://arxiv.org/abs/2308.13173"
            },
            {
                "文章ID": "1390",
                "标题": "Recent Progress in the CUHK Dysarthric Speech Recognition System",
                "作者": " Shansong Liu,  Mengzhe Geng,  Shoukang Hu,  Xurong Xie,  Mingyu Cui,  Jianwei Yu,  Xunying Liu,  Helen Meng",
                "发布日期": "2022-03-01",
                "摘要": "  Despite the rapid progress of automatic speech recognition (ASR) technologies\nin the past few decades, recognition of disordered speech remains a highly\nchallenging task to date. Disordered speech presents a wide spectrum of\nchallenges to current data intensive deep neural networks (DNNs) based ASR\ntechnologies that predominantly target normal speech. This paper presents\nrecent research efforts at the Chinese University of Hong Kong (CUHK) to\nimprove the performance of disordered speech recognition systems on the largest\npublicly available UASpeech dysarthric speech corpus. A set of novel modelling\ntechniques including neural architectural search, data augmentation using\nspectra-temporal perturbation, model based speaker adaptation and cross-domain\ngeneration of visual features within an audio-visual speech recognition (AVSR)\nsystem framework were employed to address the above challenges. The combination\nof these techniques produced the lowest published word error rate (WER) of\n25.21% on the UASpeech test set 16 dysarthric speakers, and an overall WER\nreduction of 5.4% absolute (17.6% relative) over the CUHK 2018 dysarthric\nspeech recognition system featuring a 6-way DNN system combination and cross\nadaptation of out-of-domain normal speech data trained systems. Bayesian model\nadaptation further allows rapid adaptation to individual dysarthric speakers to\nbe performed using as little as 3.06 seconds of speech. The efficacy of these\ntechniques were further demonstrated on a CUDYS Cantonese dysarthric speech\nrecognition task.\n",
                "链接": "https://arxiv.org/abs/2201.05845"
            },
            {
                "文章ID": "7207",
                "标题": "OCR-IDL: OCR Annotations for Industry Document Library Dataset",
                "作者": " Ali Furkan Biten,  Rubèn Tito,  Lluis Gomez,  Ernest Valveny,  Dimosthenis Karatzas",
                "发布日期": "2022-03-01",
                "摘要": "  Pretraining has proven successful in Document Intelligence tasks where deluge\nof documents are used to pretrain the models only later to be finetuned on\ndownstream tasks. One of the problems of the pretraining approaches is the\ninconsistent usage of pretraining data with different OCR engines leading to\nincomparable results between models. In other words, it is not obvious whether\nthe performance gain is coming from diverse usage of amount of data and\ndistinct OCR engines or from the proposed models. To remedy the problem, we\nmake public the OCR annotations for IDL documents using commercial OCR engine\ngiven their superior performance over open source OCR models. The contributed\ndataset (OCR-IDL) has an estimated monetary value over 20K US$. It is our hope\nthat OCR-IDL can be a starting point for future works on Document Intelligence.\nAll of our data and its collection process with the annotations can be found in\nhttps://github.com/furkanbiten/idl_data.\n",
                "链接": "https://arxiv.org/abs/2202.12985"
            },
            {
                "文章ID": "48455",
                "标题": "A Benchmark and Dataset for Post-OCR text correction in Sanskrit",
                "作者": " Ayush Maheshwari,  Nikhil Singh,  Amrith Krishna,  Ganesh Ramakrishnan",
                "发布日期": "2022-11-16",
                "摘要": "  Sanskrit is a classical language with about 30 million extant manuscripts fit\nfor digitisation, available in written, printed or scannedimage forms. However,\nit is still considered to be a low-resource language when it comes to available\ndigital resources. In this work, we release a post-OCR text correction dataset\ncontaining around 218,000 sentences, with 1.5 million words, from 30 different\nbooks. Texts in Sanskrit are known to be diverse in terms of their linguistic\nand stylistic usage since Sanskrit was the 'lingua franca' for discourse in the\nIndian subcontinent for about 3 millennia. Keeping this in mind, we release a\nmulti-domain dataset, from areas as diverse as astronomy, medicine and\nmathematics, with some of them as old as 18 centuries. Further, we release\nmultiple strong baselines as benchmarks for the task, based on pre-trained\nSeq2Seq language models. We find that our best-performing model, consisting of\nbyte level tokenization in conjunction with phonetic encoding (Byt5+SLP1),\nyields a 23% point increase over the OCR output in terms of word and character\nerror rates. Moreover, we perform extensive experiments in evaluating these\nmodels on their performance and analyse common causes of mispredictions both at\nthe graphemic and lexical levels. Our code and dataset is publicly available at\nhttps://github.com/ayushbits/pe-ocr-sanskrit.\n",
                "链接": "https://arxiv.org/abs/2211.07980"
            },
            {
                "文章ID": "92859",
                "标题": "Does Progress On Object Recognition Benchmarks Improve Real-World\n  Generalization?",
                "作者": " Megan Richards,  Polina Kirichenko,  Diane Bouchacourt,  Mark Ibrahim",
                "发布日期": "2023-07-26",
                "摘要": "  For more than a decade, researchers have measured progress in object\nrecognition on ImageNet-based generalization benchmarks such as ImageNet-A, -C,\nand -R. Recent advances in foundation models, trained on orders of magnitude\nmore data, have begun to saturate these standard benchmarks, but remain brittle\nin practice. This suggests standard benchmarks, which tend to focus on\npredefined or synthetic changes, may not be sufficient for measuring real world\ngeneralization. Consequently, we propose studying generalization across\ngeography as a more realistic measure of progress using two datasets of objects\nfrom households across the globe. We conduct an extensive empirical evaluation\nof progress across nearly 100 vision models up to most recent foundation\nmodels. We first identify a progress gap between standard benchmarks and\nreal-world, geographical shifts: progress on ImageNet results in up to 2.5x\nmore progress on standard generalization benchmarks than real-world\ndistribution shifts. Second, we study model generalization across geographies\nby measuring the disparities in performance across regions, a more fine-grained\nmeasure of real world generalization. We observe all models have large\ngeographic disparities, even foundation CLIP models, with differences of 7-20%\nin accuracy between regions. Counter to modern intuition, we discover progress\non standard benchmarks fails to improve geographic disparities and often\nexacerbates them: geographic disparities between the least performant models\nand today's best models have more than tripled. Our results suggest scaling\nalone is insufficient for consistent robustness to real-world distribution\nshifts. Finally, we highlight in early experiments how simple last layer\nretraining on more representative, curated data can complement scaling as a\npromising direction of future work, reducing geographic disparity on both\nbenchmarks by over two-thirds.\n",
                "链接": "https://arxiv.org/abs/2307.13136"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月agent系列决策文章。",
            "type": "1"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找多模态优化训练方式的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "67955",
                "标题": "Clustering US Counties to Find Patterns Related to the COVID-19 Pandemic",
                "作者": " Cora Brown,  Sarah Milstein,  Tianyi Sun,  Cooper Zhao",
                "发布日期": "2023-03-22",
                "摘要": "  When COVID-19 first started spreading and quarantine was implemented, the\nSociety for Industrial and Applied Mathematics (SIAM) Student Chapter at the\nUniversity of Minnesota-Twin Cities began a collaboration with Ecolab to use\nour skills as data scientists and mathematicians to extract useful insights\nfrom relevant data relating to the pandemic. This collaboration consisted of\nmultiple groups working on different projects. In this write-up we focus on\nusing clustering techniques to help us find groups of similar counties in the\nUS and use that to help us understand the pandemic. Our team for this project\nconsisted of University of Minnesota students Cora Brown, Sarah Milstein,\nTianyi Sun, and Cooper Zhao, with help from Ecolab Data Scientist Jimmy\nBroomfield and University of Minnesota student Skye Ke. In the sections below\nwe describe all of the work done for this project. In Section 2, we list the\ndata we gathered, as well as the feature engineering we performed. In Section\n3, we describe the metrics we used for evaluating our models. In Section 4, we\nexplain the methods we used for interpreting the results of our various\nclustering approaches. In Section 5, we describe the different clustering\nmethods we implemented. In Section 6, we present the results of our clustering\ntechniques and provide relevant interpretation. Finally, in Section 7, we\nprovide some concluding remarks comparing the different clustering methods.\n",
                "链接": "https://arxiv.org/abs/2303.11936"
            },
            {
                "文章ID": "87122",
                "标题": "Fantastic Weights and How to Find Them: Where to Prune in Dynamic Sparse\n  Training",
                "作者": " Aleksandra I. Nowak,  Bram Grooten,  Decebal Constantin Mocanu,  Jacek Tabor",
                "发布日期": "2023-12-01",
                "摘要": "  Dynamic Sparse Training (DST) is a rapidly evolving area of research that\nseeks to optimize the sparse initialization of a neural network by adapting its\ntopology during training. It has been shown that under specific conditions, DST\nis able to outperform dense models. The key components of this framework are\nthe pruning and growing criteria, which are repeatedly applied during the\ntraining process to adjust the network's sparse connectivity. While the growing\ncriterion's impact on DST performance is relatively well studied, the influence\nof the pruning criterion remains overlooked. To address this issue, we design\nand perform an extensive empirical analysis of various pruning criteria to\nbetter understand their impact on the dynamics of DST solutions. Surprisingly,\nwe find that most of the studied methods yield similar results. The differences\nbecome more significant in the low-density regime, where the best performance\nis predominantly given by the simplest technique: magnitude-based pruning. The\ncode is provided at https://github.com/alooow/fantastic_weights_paper\n",
                "链接": "https://arxiv.org/abs/2306.12230"
            },
            {
                "文章ID": "51062",
                "标题": "Instance-Specific Image Goal Navigation: Training Embodied Agents to\n  Find Object Instances",
                "作者": " Jacob Krantz,  Stefan Lee,  Jitendra Malik,  Dhruv Batra,  Devendra Singh Chaplot",
                "发布日期": "2022-11-30",
                "摘要": "  We consider the problem of embodied visual navigation given an image-goal\n(ImageNav) where an agent is initialized in an unfamiliar environment and\ntasked with navigating to a location 'described' by an image. Unlike related\nnavigation tasks, ImageNav does not have a standardized task definition which\nmakes comparison across methods difficult. Further, existing formulations have\ntwo problematic properties; (1) image-goals are sampled from random locations\nwhich can lead to ambiguity (e.g., looking at walls), and (2) image-goals match\nthe camera specification and embodiment of the agent; this rigidity is limiting\nwhen considering user-driven downstream applications. We present the\nInstance-specific ImageNav task (InstanceImageNav) to address these\nlimitations. Specifically, the goal image is 'focused' on some particular\nobject instance in the scene and is taken with camera parameters independent of\nthe agent. We instantiate InstanceImageNav in the Habitat Simulator using\nscenes from the Habitat-Matterport3D dataset (HM3D) and release a standardized\nbenchmark to measure community progress.\n",
                "链接": "https://arxiv.org/abs/2211.15876"
            },
            {
                "文章ID": "116268",
                "标题": "RED-DOT: Multimodal Fact-checking via Relevant Evidence Detection",
                "作者": " Stefanos-Iordanis Papadopoulos,  Christos Koutlis,  Symeon Papadopoulos,  Panagiotis C. Petrantonakis",
                "发布日期": "2023-11-17",
                "摘要": "  Online misinformation is often multimodal in nature, i.e., it is caused by\nmisleading associations between texts and accompanying images. To support the\nfact-checking process, researchers have been recently developing automatic\nmultimodal methods that gather and analyze external information, evidence,\nrelated to the image-text pairs under examination. However, prior works assumed\nall collected evidence to be relevant. In this study, we introduce a \"Relevant\nEvidence Detection\" (RED) module to discern whether each piece of evidence is\nrelevant, to support or refute the claim. Specifically, we develop the\n\"Relevant Evidence Detection Directed Transformer\" (RED-DOT) and explore\nmultiple architectural variants (e.g., single or dual-stage) and mechanisms\n(e.g., \"guided attention\"). Extensive ablation and comparative experiments\ndemonstrate that RED-DOT achieves significant improvements over the\nstate-of-the-art on the VERITE benchmark by up to 28.5%. Furthermore, our\nevidence re-ranking and element-wise modality fusion led to RED-DOT achieving\ncompetitive and even improved performance on NewsCLIPings+, without the need\nfor numerous evidence or multiple backbone encoders. Finally, our qualitative\nanalysis demonstrates that the proposed \"guided attention\" module has the\npotential to enhance the architecture's interpretability. We release our code\nat: https://github.com/stevejpapad/relevant-evidence-detection\n",
                "链接": "https://arxiv.org/abs/2311.09939"
            },
            {
                "文章ID": "114514",
                "标题": "Training CLIP models on Data from Scientific Papers",
                "作者": " Calvin Metzger",
                "发布日期": "2023-11-09",
                "摘要": "  Contrastive Language-Image Pretraining (CLIP) models are able to capture the\nsemantic relationship of images and texts and have enabled a wide range of\napplications, from image retrieval to classification. These models are trained\nwith datasets extracted from web crawls, which are of large quantity but\nlimited quality. This paper explores whether limited amounts higher quality\ndata in a specific domain improve the general performance of CLIP models. To\nthis purpose, we extract text-image data from scientific papers hosted in the\narXiv and PubMed Central repositories. Experiments on small-scale CLIP models\n(ViT B/32) show that model performance increases on average, but only\nmoderately. This result indicates that using the data sources considered in the\npaper to train large-scale CLIP models is a worthwile research direction.\n",
                "链接": "https://arxiv.org/abs/2311.04711"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "12691",
                "标题": "Data-driven Prediction of Relevant Scenarios for Robust Combinatorial\n  Optimization",
                "作者": " Marc Goerigk,  Jannis Kurtz",
                "发布日期": "2022-12-26",
                "摘要": "  We study iterative methods for (two-stage) robust combinatorial optimization\nproblems with discrete uncertainty. We propose a machine-learning-based\nheuristic to determine starting scenarios that provide strong lower bounds. To\nthis end, we design dimension-independent features and train a Random Forest\nClassifier on small-dimensional instances. Experiments show that our method\nimproves the solution process for larger instances than contained in the\ntraining set and also provides a feature importance-score which gives insights\ninto the role of scenario properties.\n",
                "链接": "https://arxiv.org/abs/2203.16642"
            },
            {
                "文章ID": "79842",
                "标题": "Cost-aware learning of relevant contextual variables within Bayesian\n  optimization",
                "作者": " Julien Martinelli,  Ayush Bharti,  S. T. John,  Armi Tiihonen,  Sabina Sloman,  Louis Filstroff,  Samuel Kaski",
                "发布日期": "2023-05-25",
                "摘要": "  Contextual Bayesian Optimization (CBO) is a powerful framework for optimizing\nblack-box, expensive-to-evaluate functions with respect to design variables,\nwhile simultaneously efficiently integrating relevant contextual information\nregarding the environment, such as experimental conditions. However, in many\npractical scenarios, the relevance of contextual variables is not necessarily\nknown beforehand. Moreover, the contextual variables can sometimes be optimized\nthemselves, a setting that current CBO algorithms do not take into account.\nOptimizing contextual variables may be costly, which raises the question of\ndetermining a minimal relevant subset. In this paper, we frame this problem as\na cost-aware model selection BO task and address it using a novel method,\nSensitivity-Analysis-Driven Contextual BO (SADCBO). We learn the relevance of\ncontext variables by sensitivity analysis of the posterior surrogate model at\nspecific input points, whilst minimizing the cost of optimization by leveraging\nrecent developments on early stopping for BO. We empirically evaluate our\nproposed SADCBO against alternatives on synthetic experiments together with\nextensive ablation studies, and demonstrate a consistent improvement across\nexamples.\n",
                "链接": "https://arxiv.org/abs/2305.14120"
            },
            {
                "文章ID": "97726",
                "标题": "Spurious Correlations and Where to Find Them",
                "作者": " Gautam Sreekumar,  Vishnu Naresh Boddeti",
                "发布日期": "2023-08-23",
                "摘要": "  Spurious correlations occur when a model learns unreliable features from the\ndata and are a well-known drawback of data-driven learning. Although there are\nseveral algorithms proposed to mitigate it, we are yet to jointly derive the\nindicators of spurious correlations. As a result, the solutions built upon\nstandalone hypotheses fail to beat simple ERM baselines. We collect some of the\ncommonly studied hypotheses behind the occurrence of spurious correlations and\ninvestigate their influence on standard ERM baselines using synthetic datasets\ngenerated from causal graphs. Subsequently, we observe patterns connecting\nthese hypotheses and model design choices.\n",
                "链接": "https://arxiv.org/abs/2308.11043"
            },
            {
                "文章ID": "2226",
                "标题": "Good Classification Measures and How to Find Them",
                "作者": " Martijn Gösgens,  Anton Zhiyanov,  Alexey Tikhonov,  Liudmila Prokhorenkova",
                "发布日期": "2022-01-25",
                "摘要": "  Several performance measures can be used for evaluating classification\nresults: accuracy, F-measure, and many others. Can we say that some of them are\nbetter than others, or, ideally, choose one measure that is best in all\nsituations? To answer this question, we conduct a systematic analysis of\nclassification performance measures: we formally define a list of desirable\nproperties and theoretically analyze which measures satisfy which properties.\nWe also prove an impossibility theorem: some desirable properties cannot be\nsimultaneously satisfied. Finally, we propose a new family of measures\nsatisfying all desirable properties except one. This family includes the\nMatthews Correlation Coefficient and a so-called Symmetric Balanced Accuracy\nthat was not previously used in classification literature. We believe that our\nsystematic approach gives an important tool to practitioners for adequately\nevaluating classification results.\n",
                "链接": "https://arxiv.org/abs/2201.09044"
            }
        ]
    },
    {
        "question": {
            "question": "与大模型安全相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            },
            {
                "文章ID": "119662",
                "标题": "Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective",
                "作者": " Yixuan Wang,  Ruochen Jiao,  Chengtian Lang,  Sinong Simon Zhan,  Chao Huang,  Zhaoran Wang,  Zhuoran Yang,  Qi Zhu",
                "发布日期": "2023-12-20",
                "摘要": "  Autonomous Driving (AD) faces crucial hurdles for commercial launch, notably\nin the form of diminished public trust and safety concerns from long-tail\nunforeseen driving scenarios. This predicament is due to the limitation of deep\nneural networks in AD software, which struggle with interpretability and\nexhibit poor generalization capabilities in out-of-distribution and uncertain\nscenarios. To this end, this paper advocates for the integration of Large\nLanguage Models (LLMs) into the AD system, leveraging their robust common-sense\nknowledge, reasoning abilities, and human-interaction capabilities. The\nproposed approach deploys the LLM as an intelligent decision-maker in planning,\nincorporating safety verifiers for contextual safety learning to enhance\noverall AD performance and safety. We present results from two case studies\nthat affirm the efficacy of our approach. We further discuss the potential\nintegration of LLM for other AD software components including perception,\nprediction, and simulation. Despite the observed challenges in the case\nstudies, the integration of LLMs is promising and beneficial for reinforcing\nboth safety and performance in AD.\n",
                "链接": "https://arxiv.org/abs/2312.00812"
            },
            {
                "文章ID": "73408",
                "标题": "Safety Assessment of Chinese Large Language Models",
                "作者": " Hao Sun,  Zhexin Zhang,  Jiawen Deng,  Jiale Cheng,  Minlie Huang",
                "发布日期": "2023-04-21",
                "摘要": "  With the rapid popularity of large language models such as ChatGPT and GPT-4,\na growing amount of attention is paid to their safety concerns. These models\nmay generate insulting and discriminatory content, reflect incorrect social\nvalues, and may be used for malicious purposes such as fraud and dissemination\nof misleading information. Evaluating and enhancing their safety is\nparticularly essential for the wide application of large language models\n(LLMs). To further promote the safe deployment of LLMs, we develop a Chinese\nLLM safety assessment benchmark. Our benchmark explores the comprehensive\nsafety performance of LLMs from two perspectives: 8 kinds of typical safety\nscenarios and 6 types of more challenging instruction attacks. Our benchmark is\nbased on a straightforward process in which it provides the test prompts and\nevaluates the safety of the generated responses from the evaluated model. In\nevaluation, we utilize the LLM's strong evaluation ability and develop it as a\nsafety evaluator by prompting. On top of this benchmark, we conduct safety\nassessments and analyze 15 LLMs including the OpenAI GPT series and other\nwell-known Chinese LLMs, where we observe some interesting findings. For\nexample, we find that instruction attacks are more likely to expose safety\nissues of all LLMs. Moreover, to promote the development and deployment of\nsafe, responsible, and ethical AI, we publicly release SafetyPrompts including\n100k augmented prompts and responses by LLMs.\n",
                "链接": "https://arxiv.org/abs/2304.10436"
            },
            {
                "文章ID": "114317",
                "标题": "Unveiling Safety Vulnerabilities of Large Language Models",
                "作者": " George Kour,  Marcel Zalmanovici,  Naama Zwerdling,  Esther Goldbraich,  Ora Nova Fandina,  Ateret Anaby-Tavor,  Orna Raz,  Eitan Farchi",
                "发布日期": "2023-11-08",
                "摘要": "  As large language models become more prevalent, their possible harmful or\ninappropriate responses are a cause for concern. This paper introduces a unique\ndataset containing adversarial examples in the form of questions, which we call\nAttaQ, designed to provoke such harmful or inappropriate responses. We assess\nthe efficacy of our dataset by analyzing the vulnerabilities of various models\nwhen subjected to it. Additionally, we introduce a novel automatic approach for\nidentifying and naming vulnerable semantic regions - input semantic areas for\nwhich the model is likely to produce harmful outputs. This is achieved through\nthe application of specialized clustering techniques that consider both the\nsemantic similarity of the input attacks and the harmfulness of the model's\nresponses. Automatically identifying vulnerable semantic regions enhances the\nevaluation of model weaknesses, facilitating targeted improvements to its\nsafety mechanisms and overall reliability.\n",
                "链接": "https://arxiv.org/abs/2311.04124"
            },
            {
                "文章ID": "39802",
                "标题": "On the Impossible Safety of Large AI Models",
                "作者": " El-Mahdi El-Mhamdi,  Sadegh Farhadkhani,  Rachid Guerraoui,  Nirupam Gupta,  Lê-Nguyên Hoang,  Rafael Pinot,  Sébastien Rouault,  John Stephan",
                "发布日期": "2023-05-10",
                "摘要": "  Large AI Models (LAIMs), of which large language models are the most\nprominent recent example, showcase some impressive performance. However they\nhave been empirically found to pose serious security issues. This paper\nsystematizes our knowledge about the fundamental impossibility of building\narbitrarily accurate and secure machine learning models. More precisely, we\nidentify key challenging features of many of today's machine learning settings.\nNamely, high accuracy seems to require memorizing large training datasets,\nwhich are often user-generated and highly heterogeneous, with both sensitive\ninformation and fake users. We then survey statistical lower bounds that, we\nargue, constitute a compelling case against the possibility of designing\nhigh-accuracy LAIMs with strong security guarantees.\n",
                "链接": "https://arxiv.org/abs/2209.15259"
            },
            {
                "文章ID": "101815",
                "标题": "SafetyBench: Evaluating the Safety of Large Language Models with\n  Multiple Choice Questions",
                "作者": " Zhexin Zhang,  Leqi Lei,  Lindong Wu,  Rui Sun,  Yongkang Huang,  Chong Long,  Xiao Liu,  Xuanyu Lei,  Jie Tang,  Minlie Huang",
                "发布日期": "2023-09-14",
                "摘要": "  With the rapid development of Large Language Models (LLMs), increasing\nattention has been paid to their safety concerns. Consequently, evaluating the\nsafety of LLMs has become an essential task for facilitating the broad\napplications of LLMs. Nevertheless, the absence of comprehensive safety\nevaluation benchmarks poses a significant impediment to effectively assess and\nenhance the safety of LLMs. In this work, we present SafetyBench, a\ncomprehensive benchmark for evaluating the safety of LLMs, which comprises\n11,435 diverse multiple choice questions spanning across 7 distinct categories\nof safety concerns. Notably, SafetyBench also incorporates both Chinese and\nEnglish data, facilitating the evaluation in both languages. Our extensive\ntests over 25 popular Chinese and English LLMs in both zero-shot and few-shot\nsettings reveal a substantial performance advantage for GPT-4 over its\ncounterparts, and there is still significant room for improving the safety of\ncurrent LLMs. We believe SafetyBench will enable fast and comprehensive\nevaluation of LLMs' safety, and foster the development of safer LLMs. Data and\nevaluation guidelines are available at https://github.com/thu-coai/SafetyBench.\nSubmission entrance and leaderboard are available at\nhttps://llmbench.ai/safety.\n",
                "链接": "https://arxiv.org/abs/2309.07045"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "102063",
                "标题": "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language\n  Models that Follow Instructions",
                "作者": " Federico Bianchi,  Mirac Suzgun,  Giuseppe Attanasio,  Paul Röttger,  Dan Jurafsky,  Tatsunori Hashimoto,  James Zou",
                "发布日期": "2023-09-26",
                "摘要": "  Training large language models to follow instructions makes them perform\nbetter on a wide range of tasks, generally becoming more helpful. However, a\nperfectly helpful model will follow even the most malicious instructions and\nreadily generate harmful content. In this paper, we raise concerns over the\nsafety of models that only emphasize helpfulness, not safety, in their\ninstruction-tuning. We show that several popular instruction-tuned models are\nhighly unsafe. Moreover, we show that adding just 3% safety examples (a few\nhundred demonstrations) in the training set when fine-tuning a model like LLaMA\ncan substantially improve their safety. Our safety-tuning does not make models\nsignificantly less capable or helpful as measured by standard benchmarks.\nHowever, we do find a behavior of exaggerated safety, where too much\nsafety-tuning makes models refuse to respond to reasonable prompts that\nsuperficially resemble unsafe ones. Our study sheds light on trade-offs in\ntraining LLMs to follow instructions and exhibit safe behavior.\n",
                "链接": "https://arxiv.org/abs/2309.07875"
            },
            {
                "文章ID": "112959",
                "标题": "Robust Safety Classifier for Large Language Models: Adversarial Prompt\n  Shield",
                "作者": " Jinhwa Kim,  Ali Derakhshan,  Ian G. Harris",
                "发布日期": "2023-11-02",
                "摘要": "  Large Language Models' safety remains a critical concern due to their\nvulnerability to adversarial attacks, which can prompt these systems to produce\nharmful responses. In the heart of these systems lies a safety classifier, a\ncomputational model trained to discern and mitigate potentially harmful,\noffensive, or unethical outputs. However, contemporary safety classifiers,\ndespite their potential, often fail when exposed to inputs infused with\nadversarial noise. In response, our study introduces the Adversarial Prompt\nShield (APS), a lightweight model that excels in detection accuracy and\ndemonstrates resilience against adversarial prompts. Additionally, we propose\nnovel strategies for autonomously generating adversarial training datasets,\nnamed Bot Adversarial Noisy Dialogue (BAND) datasets. These datasets are\ndesigned to fortify the safety classifier's robustness, and we investigate the\nconsequences of incorporating adversarial examples into the training process.\nThrough evaluations involving Large Language Models, we demonstrate that our\nclassifier has the potential to decrease the attack success rate resulting from\nadversarial attacks by up to 60%. This advancement paves the way for the next\ngeneration of more reliable and resilient conversational agents.\n",
                "链接": "https://arxiv.org/abs/2311.00172"
            }
        ]
    },
    {
        "question": {
            "question": "查找大模型推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "113368",
                "标题": "FlashDecoding++: Faster Large Language Model Inference on GPUs",
                "作者": " Ke Hong,  Guohao Dai,  Jiaming Xu,  Qiuli Mao,  Xiuhong Li,  Jun Liu,  Kangdi Chen,  Yuhan Dong,  Yu Wang",
                "发布日期": "2023-11-13",
                "摘要": "  As the Large Language Model (LLM) becomes increasingly important in various\ndomains. However, the following challenges still remain unsolved in\naccelerating LLM inference: (1) Synchronized partial softmax update. The\nsoftmax operation requires a synchronized update operation among each partial\nsoftmax result, leading to ~20% overheads for the attention computation in\nLLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices\nperforming GEMM in LLM inference is flat, leading to under-utilized computation\nand >50% performance loss after padding zeros in previous designs. (3)\nPerformance loss due to static dataflow. Kernel performance in LLM depends on\nvaried input data features, hardware configurations, etc. A single and static\ndataflow may lead to a 50.25% performance loss for GEMMs of different shapes in\nLLM inference.\n  We present FlashDecoding++, a fast LLM inference engine supporting mainstream\nLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++\ncreatively proposes: (1) Asynchronized softmax with unified max value.\nFlashDecoding++ introduces a unified max value technique for different partial\nsoftmax computations to avoid synchronization. (2) Flat GEMM optimization with\ndouble buffering. FlashDecoding++ points out that flat GEMMs with different\nshapes face varied bottlenecks. Then, techniques like double buffering are\nintroduced. (3) Heuristic dataflow with hardware resource adaptation.\nFlashDecoding++ heuristically optimizes dataflow using different hardware\nresource considering input dynamics. Due to the versatility of optimizations in\nFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on\nboth NVIDIA and AMD GPUs compared to Hugging Face implementations.\nFlashDecoding++ also achieves an average speedup of 1.37x compared to\nstate-of-the-art LLM inference engines on mainstream LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.01282"
            },
            {
                "文章ID": "83366",
                "标题": "On Optimal Caching and Model Multiplexing for Large Model Inference",
                "作者": " Banghua Zhu,  Ying Sheng,  Lianmin Zheng,  Clark Barrett,  Michael I. Jordan,  Jiantao Jiao",
                "发布日期": "2023-08-30",
                "摘要": "  Large Language Models (LLMs) and other large foundation models have achieved\nnoteworthy success, but their size exacerbates existing resource consumption\nand latency challenges. In particular, the large-scale deployment of these\nmodels is hindered by the significant resource requirements during inference.\nIn this paper, we study two approaches for mitigating these challenges:\nemploying a cache to store previous queries and learning a model multiplexer to\nchoose from an ensemble of models for query processing.\n  Theoretically, we provide an optimal algorithm for jointly optimizing both\napproaches to reduce the inference cost in both offline and online tabular\nsettings. By combining a caching algorithm, namely Greedy Dual Size with\nFrequency (GDSF) or Least Expected Cost (LEC), with a model multiplexer, we\nachieve optimal rates in both offline and online settings. Empirically,\nsimulations show that the combination of our caching and model multiplexing\nalgorithms greatly improves over the baselines, with up to $50\\times$\nimprovement over the baseline when the ratio between the maximum cost and\nminimum cost is $100$. Experiments on real datasets show a $4.3\\times$\nimprovement in FLOPs over the baseline when the ratio for FLOPs is $10$, and a\n$1.8\\times$ improvement in latency when the ratio for average latency is\n$1.85$.\n",
                "链接": "https://arxiv.org/abs/2306.02003"
            },
            {
                "文章ID": "100993",
                "标题": "LLMCad: Fast and Scalable On-device Large Language Model Inference",
                "作者": " Daliang Xu,  Wangsong Yin,  Xin Jin,  Ying Zhang,  Shiyun Wei,  Mengwei Xu,  Xuanzhe Liu",
                "发布日期": "2023-09-11",
                "摘要": "  Generative tasks, such as text generation and question answering, hold a\ncrucial position in the realm of mobile applications. Due to their sensitivity\nto privacy concerns, there is a growing demand for their execution directly on\nmobile devices. Currently, the execution of these generative tasks heavily\ndepends on Large Language Models (LLMs). Nevertheless, the limited memory\ncapacity of these devices presents a formidable challenge to the scalability of\nsuch models.\n  In our research, we introduce LLMCad, an innovative on-device inference\nengine specifically designed for efficient generative Natural Language\nProcessing (NLP) tasks. The core idea behind LLMCad revolves around model\ncollaboration: a compact LLM, residing in memory, takes charge of generating\nthe most straightforward tokens, while a high-precision LLM steps in to\nvalidate these tokens and rectify any identified errors. LLMCad incorporates\nthree novel techniques: (1) Instead of generating candidate tokens in a\nsequential manner, LLMCad employs the smaller LLM to construct a token tree,\nencompassing a wider range of plausible token pathways. Subsequently, the\nlarger LLM can efficiently validate all of these pathways simultaneously. (2)\nIt employs a self-adjusting fallback strategy, swiftly initiating the\nverification process whenever the smaller LLM generates an erroneous token. (3)\nTo ensure a continuous flow of token generation, LLMCad speculatively generates\ntokens during the verification process by implementing a compute-IO pipeline.\nThrough an extensive series of experiments, LLMCad showcases an impressive\ntoken generation speed, achieving rates up to 9.3x faster than existing\ninference engines.\n",
                "链接": "https://arxiv.org/abs/2309.04255"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "116170",
                "标题": "Large Language Model Inference with Lexical Shortlisting",
                "作者": " Nikolay Bogoychev,  Pinzhen Chen,  Barry Haddow,  Alexandra Birch",
                "发布日期": "2023-11-17",
                "摘要": "  Large language model (LLM) inference is computation and memory intensive, so\nwe adapt lexical shortlisting to it hoping to improve both. While lexical\nshortlisting is well-explored in tasks like machine translation, it requires\nmodifications before being suitable for LLMs as the intended applications vary\nsignificantly. Our work studies two heuristics to shortlist sub-vocabulary at\nLLM inference time: Unicode-based script filtering and corpus-based selection.\nWe explore different LLM families and sizes, and we find that lexical\nshortlisting can reduce the memory usage of some models by nearly 50\\% and has\nan upper bound of 25\\% improvement in generation speed. In this pilot study, we\nalso identify the drawbacks of such vocabulary selection methods and propose\navenues for future research.\n",
                "链接": "https://arxiv.org/abs/2311.09709"
            },
            {
                "文章ID": "55730",
                "标题": "Rethinking with Retrieval: Faithful Large Language Model Inference",
                "作者": " Hangfeng He,  Hongming Zhang,  Dan Roth",
                "发布日期": "2023-01-03",
                "摘要": "  Despite the success of large language models (LLMs) in various natural\nlanguage processing (NLP) tasks, the stored knowledge in these models may\ninevitably be incomplete, out-of-date, or incorrect. This motivates the need to\nutilize external knowledge to assist LLMs. Unfortunately, current methods for\nincorporating external knowledge often require additional training or\nfine-tuning, which can be costly and may not be feasible for LLMs. To address\nthis issue, we propose a novel post-processing approach, rethinking with\nretrieval (RR), which retrieves relevant external knowledge based on the\ndecomposed reasoning steps obtained from the chain-of-thought (CoT) prompting.\nThis lightweight approach does not require additional training or fine-tuning\nand is not limited by the input length of LLMs. We evaluate the effectiveness\nof RR through extensive experiments with GPT-3 on three complex reasoning\ntasks: commonsense reasoning, temporal reasoning, and tabular reasoning. Our\nresults show that RR can produce more faithful explanations and improve the\nperformance of LLMs.\n",
                "链接": "https://arxiv.org/abs/2301.00303"
            },
            {
                "文章ID": "108690",
                "标题": "User Inference Attacks on Large Language Models",
                "作者": " Nikhil Kandpal,  Krishna Pillutla,  Alina Oprea,  Peter Kairouz,  Christopher A. Choquette-Choo,  Zheng Xu",
                "发布日期": "2023-10-16",
                "摘要": "  Fine-tuning is a common and effective method for tailoring large language\nmodels (LLMs) to specialized tasks and applications. In this paper, we study\nthe privacy implications of fine-tuning LLMs on user data. To this end, we\ndefine a realistic threat model, called user inference, wherein an attacker\ninfers whether or not a user's data was used for fine-tuning. We implement\nattacks for this threat model that require only a small set of samples from a\nuser (possibly different from the samples used for training) and black-box\naccess to the fine-tuned LLM. We find that LLMs are susceptible to user\ninference attacks across a variety of fine-tuning datasets, at times with near\nperfect attack success rates. Further, we investigate which properties make\nusers vulnerable to user inference, finding that outlier users (i.e. those with\ndata distributions sufficiently different from other users) and users who\ncontribute large quantities of data are most susceptible to attack. Finally, we\nexplore several heuristics for mitigating privacy attacks. We find that\ninterventions in the training algorithm, such as batch or per-example gradient\nclipping and early stopping fail to prevent user inference. However, limiting\nthe number of fine-tuning samples from a single user can reduce attack\neffectiveness, albeit at the cost of reducing the total amount of fine-tuning\ndata.\n",
                "链接": "https://arxiv.org/abs/2310.09266"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "18035",
                "标题": "A collection of invited non-archival papers for the Conference on\n  Health, Inference, and Learning (CHIL) 2022",
                "作者": " Gerardo Flores,  George H. Chen,  Tom Pollard,  Joyce C. Ho,  Tristan Naumann",
                "发布日期": "2022-05-06",
                "摘要": "  A collection of invited non-archival papers for the Conference on Health,\nInference, and Learning (CHIL) 2022. This index is incomplete as some authors\nof invited non-archival presentations opted not to include their papers in this\nindex.\n",
                "链接": "https://arxiv.org/abs/2205.02752"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月自然语言处理相关的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "197",
                "标题": "Robust Natural Language Processing: Recent Advances, Challenges, and\n  Future Directions",
                "作者": " Marwan Omar,  Soohyeon Choi,  DaeHun Nyang,  David Mohaisen",
                "发布日期": "2022-10-24",
                "摘要": "  Recent natural language processing (NLP) techniques have accomplished high\nperformance on benchmark datasets, primarily due to the significant improvement\nin the performance of deep learning. The advances in the research community\nhave led to great enhancements in state-of-the-art production systems for NLP\ntasks, such as virtual assistants, speech recognition, and sentiment analysis.\nHowever, such NLP systems still often fail when tested with adversarial\nattacks. The initial lack of robustness exposed troubling gaps in current\nmodels' language understanding capabilities, creating problems when NLP systems\nare deployed in real life. In this paper, we present a structured overview of\nNLP robustness research by summarizing the literature in a systemic way across\nvarious dimensions. We then take a deep-dive into the various dimensions of\nrobustness, across techniques, metrics, embeddings, and benchmarks. Finally, we\nargue that robustness should be multi-dimensional, provide insights into\ncurrent research, identify gaps in the literature to suggest directions worth\npursuing to address these gaps.\n",
                "链接": "https://arxiv.org/abs/2201.00768"
            },
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "44791",
                "标题": "Classification of Misinformation in New Articles using Natural Language\n  Processing and a Recurrent Neural Network",
                "作者": " Brendan Cunha,  Lydia Manikonda",
                "发布日期": "2022-10-26",
                "摘要": "  This paper seeks to address the classification of misinformation in news\narticles using a Long Short Term Memory Recurrent Neural Network. Articles were\ntaken from 2018; a year that was filled with reporters writing about President\nDonald Trump, Special Counsel Robert Mueller, the Fifa World Cup, and Russia.\nThe model presented successfully classifies these articles with an accuracy\nscore of 0.779944. We consider this to be successful because the model was\ntrained on articles that included languages other than English as well as\nincomplete, or fragmented, articles.\n",
                "链接": "https://arxiv.org/abs/2210.13534"
            },
            {
                "文章ID": "85699",
                "标题": "Operationalising Representation in Natural Language Processing",
                "作者": " Jacqueline Harding",
                "发布日期": "2023-11-21",
                "摘要": "  Despite its centrality in the philosophy of cognitive science, there has been\nlittle prior philosophical work engaging with the notion of representation in\ncontemporary NLP practice. This paper attempts to fill that lacuna: drawing on\nideas from cognitive science, I introduce a framework for evaluating the\nrepresentational claims made about components of neural NLP models, proposing\nthree criteria with which to evaluate whether a component of a model represents\na property and operationalising these criteria using probing classifiers, a\npopular analysis technique in NLP (and deep learning more broadly).\n  The project of operationalising a philosophically-informed notion of\nrepresentation should be of interest to both philosophers of science and NLP\npractitioners. It affords philosophers a novel testing-ground for claims about\nthe nature of representation, and helps NLPers organise the large literature on\nprobing experiments, suggesting novel avenues for empirical research.\n",
                "链接": "https://arxiv.org/abs/2306.08193"
            },
            {
                "文章ID": "79436",
                "标题": "Interactive Natural Language Processing",
                "作者": " Zekun Wang,  Ge Zhang,  Kexin Yang,  Ning Shi,  Wangchunshu Zhou,  Shaochun Hao,  Guangzheng Xiong,  Yizhi Li,  Mong Yuan Sim,  Xiuying Chen,  Qingqing Zhu,  Zhenzhu Yang,  Adam Nik,  Qi Liu,  Chenghua Lin,  Shi Wang,  Ruibo Liu,  Wenhu Chen,  Ke Xu,  Dayiheng Liu,  Yike Guo,  Jie Fu",
                "发布日期": "2023-05-23",
                "摘要": "  Interactive Natural Language Processing (iNLP) has emerged as a novel\nparadigm within the field of NLP, aimed at addressing limitations in existing\nframeworks while aligning with the ultimate goals of artificial intelligence.\nThis paradigm considers language models as agents capable of observing, acting,\nand receiving feedback iteratively from external entities. Specifically,\nlanguage models in this context can: (1) interact with humans for better\nunderstanding and addressing user needs, personalizing responses, aligning with\nhuman values, and improving the overall user experience; (2) interact with\nknowledge bases for enriching language representations with factual knowledge,\nenhancing the contextual relevance of responses, and dynamically leveraging\nexternal information to generate more accurate and informed responses; (3)\ninteract with models and tools for effectively decomposing and addressing\ncomplex tasks, leveraging specialized expertise for specific subtasks, and\nfostering the simulation of social behaviors; and (4) interact with\nenvironments for learning grounded representations of language, and effectively\ntackling embodied tasks such as reasoning, planning, and decision-making in\nresponse to environmental observations. This paper offers a comprehensive\nsurvey of iNLP, starting by proposing a unified definition and framework of the\nconcept. We then provide a systematic classification of iNLP, dissecting its\nvarious components, including interactive objects, interaction interfaces, and\ninteraction methods. We proceed to delve into the evaluation methodologies used\nin the field, explore its diverse applications, scrutinize its ethical and\nsafety issues, and discuss prospective research directions. This survey serves\nas an entry point for researchers who are interested in this rapidly evolving\narea and offers a broad view of the current landscape and future trajectory of\niNLP.\n",
                "链接": "https://arxiv.org/abs/2305.13246"
            },
            {
                "文章ID": "34310",
                "标题": "Review of Natural Language Processing in Pharmacology",
                "作者": " Dimitar Trajanov,  Vangel Trajkovski,  Makedonka Dimitrieva,  Jovana Dobreva,  Milos Jovanovik,  Matej Klemen,  Aleš Žagar,  Marko Robnik-Šikonja",
                "发布日期": "2023-01-27",
                "摘要": "  Natural language processing (NLP) is an area of artificial intelligence that\napplies information technologies to process the human language, understand it\nto a certain degree, and use it in various applications. This area has rapidly\ndeveloped in the last few years and now employs modern variants of deep neural\nnetworks to extract relevant patterns from large text corpora. The main\nobjective of this work is to survey the recent use of NLP in the field of\npharmacology. As our work shows, NLP is a highly relevant information\nextraction and processing approach for pharmacology. It has been used\nextensively, from intelligent searches through thousands of medical documents\nto finding traces of adversarial drug interactions in social media. We split\nour coverage into five categories to survey modern NLP methodology, commonly\naddressed tasks, relevant textual data, knowledge bases, and useful programming\nlibraries. We split each of the five categories into appropriate subcategories,\ndescribe their main properties and ideas, and summarize them in a tabular form.\nThe resulting survey presents a comprehensive overview of the area, useful to\npractitioners and interested observers.\n",
                "链接": "https://arxiv.org/abs/2208.10228"
            },
            {
                "文章ID": "56677",
                "标题": "User-Centered Security in Natural Language Processing",
                "作者": " Chris Emmery",
                "发布日期": "2023-01-12",
                "摘要": "  This dissertation proposes a framework of user-centered security in Natural\nLanguage Processing (NLP), and demonstrates how it can improve the\naccessibility of related research. Accordingly, it focuses on two security\ndomains within NLP with great public interest. First, that of author profiling,\nwhich can be employed to compromise online privacy through invasive inferences.\nWithout access and detailed insight into these models' predictions, there is no\nreasonable heuristic by which Internet users might defend themselves from such\ninferences. Secondly, that of cyberbullying detection, which by default\npresupposes a centralized implementation; i.e., content moderation across\nsocial platforms. As access to appropriate data is restricted, and the nature\nof the task rapidly evolves (both through lexical variation, and cultural\nshifts), the effectiveness of its classifiers is greatly diminished and thereby\noften misrepresented.\n  Under the proposed framework, we predominantly investigate the use of\nadversarial attacks on language; i.e., changing a given input (generating\nadversarial samples) such that a given model does not function as intended.\nThese attacks form a common thread between our user-centered security problems;\nthey are highly relevant for privacy-preserving obfuscation methods against\nauthor profiling, and adversarial samples might also prove useful to assess the\ninfluence of lexical variation and augmentation on cyberbullying detection.\n",
                "链接": "https://arxiv.org/abs/2301.04230"
            },
            {
                "文章ID": "63180",
                "标题": "Natural Language Processing in the Legal Domain",
                "作者": " Daniel Martin Katz,  Dirk Hartung,  Lauritz Gerlach,  Abhik Jana, II Michael J. Bommarito",
                "发布日期": "2023-02-24",
                "摘要": "  In this paper, we summarize the current state of the field of NLP & Law with\na specific focus on recent technical and substantive developments. To support\nour analysis, we construct and analyze a nearly complete corpus of more than\nsix hundred NLP & Law related papers published over the past decade. Our\nanalysis highlights several major trends. Namely, we document an increasing\nnumber of papers written, tasks undertaken, and languages covered over the\ncourse of the past decade. We observe an increase in the sophistication of the\nmethods which researchers deployed in this applied context. Slowly but surely,\nLegal NLP is beginning to match not only the methodological sophistication of\ngeneral NLP but also the professional standards of data availability and code\nreproducibility observed within the broader scientific community. We believe\nall of these trends bode well for the future of the field, but many questions\nin both the academic and commercial sphere still remain open.\n",
                "链接": "https://arxiv.org/abs/2302.12039"
            },
            {
                "文章ID": "121029",
                "标题": "PyThaiNLP: Thai Natural Language Processing in Python",
                "作者": " Wannaphong Phatthiyaphaibun,  Korakot Chaovavanich,  Charin Polpanumas,  Arthit Suriyawongkul,  Lalita Lowphansirikul,  Pattarawat Chormai,  Peerat Limkonchotiwat,  Thanathip Suntorntip,  Can Udomcharoenchaikit",
                "发布日期": "2023-12-11",
                "摘要": "  We present PyThaiNLP, a free and open-source natural language processing\n(NLP) library for Thai language implemented in Python. It provides a wide range\nof software, models, and datasets for Thai language. We first provide a brief\nhistorical context of tools for Thai language prior to the development of\nPyThaiNLP. We then outline the functionalities it provided as well as datasets\nand pre-trained language models. We later summarize its development milestones\nand discuss our experience during its development. We conclude by demonstrating\nhow industrial and research communities utilize PyThaiNLP in their work. The\nlibrary is freely available at https://github.com/pythainlp/pythainlp.\n",
                "链接": "https://arxiv.org/abs/2312.04649"
            },
            {
                "文章ID": "60462",
                "标题": "Natural Language Processing for Policymaking",
                "作者": " Zhijing Jin,  Rada Mihalcea",
                "发布日期": "2023-02-08",
                "摘要": "  Language is the medium for many political activities, from campaigns to news\nreports. Natural language processing (NLP) uses computational tools to parse\ntext into key information that is needed for policymaking. In this chapter, we\nintroduce common methods of NLP, including text classification, topic modeling,\nevent extraction, and text scaling. We then overview how these methods can be\nused for policymaking through four major applications including data collection\nfor evidence-based policymaking, interpretation of political decisions, policy\ncommunication, and investigation of policy effects. Finally, we highlight some\npotential limitations and ethical concerns when using NLP for policymaking.\n  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational\nSocial Science for Policy (2023). Open Access on Springer:\nhttps://doi.org/10.1007/978-3-031-16624-2\n",
                "链接": "https://arxiv.org/abs/2302.03490"
            }
        ]
    },
    {
        "question": {
            "question": "查找多语言情感分析的最新论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "112858",
                "标题": "Linked Papers With Code: The Latest in Machine Learning as an RDF\n  Knowledge Graph",
                "作者": " Michael Färber,  David Lamprecht",
                "发布日期": "2023-11-01",
                "摘要": "  In this paper, we introduce Linked Papers With Code (LPWC), an RDF knowledge\ngraph that provides comprehensive, current information about almost 400,000\nmachine learning publications. This includes the tasks addressed, the datasets\nutilized, the methods implemented, and the evaluations conducted, along with\ntheir results. Compared to its non-RDF-based counterpart Papers With Code, LPWC\nnot only translates the latest advancements in machine learning into RDF\nformat, but also enables novel ways for scientific impact quantification and\nscholarly key content recommendation. LPWC is openly accessible at\nhttps://linkedpaperswithcode.com and is licensed under CC-BY-SA 4.0. As a\nknowledge graph in the Linked Open Data cloud, we offer LPWC in multiple\nformats, from RDF dump files to a SPARQL endpoint for direct web queries, as\nwell as a data source with resolvable URIs and links to the data sources\nSemOpenAlex, Wikidata, and DBLP. Additionally, we supply knowledge graph\nembeddings, enabling LPWC to be readily applied in machine learning\napplications.\n",
                "链接": "https://arxiv.org/abs/2310.20475"
            },
            {
                "文章ID": "18354",
                "标题": "Multi-Domain Targeted Sentiment Analysis",
                "作者": " Orith Toledo-Ronen,  Matan Orbach,  Yoav Katz,  Noam Slonim",
                "发布日期": "2022-05-10",
                "摘要": "  Targeted Sentiment Analysis (TSA) is a central task for generating insights\nfrom consumer reviews. Such content is extremely diverse, with sites like\nAmazon or Yelp containing reviews on products and businesses from many\ndifferent domains. A real-world TSA system should gracefully handle that\ndiversity. This can be achieved by a multi-domain model -- one that is robust\nto the domain of the analyzed texts, and performs well on various domains. To\naddress this scenario, we present a multi-domain TSA system based on augmenting\na given training set with diverse weak labels from assorted domains. These are\nobtained through self-training on the Yelp reviews corpus. Extensive\nexperiments with our approach on three evaluation datasets across different\ndomains demonstrate the effectiveness of our solution. We further analyze how\nrestrictions imposed on the available labeled data affect the performance, and\ncompare the proposed method to the costly alternative of manually gathering\ndiverse TSA labeled data. Our results and analysis show that our approach is a\npromising step towards a practical domain-robust TSA system.\n",
                "链接": "https://arxiv.org/abs/2205.03804"
            },
            {
                "文章ID": "109724",
                "标题": "On the use of Vision-Language models for Visual Sentiment Analysis: a\n  study on CLIP",
                "作者": " Cristina Bustos,  Carles Civit,  Brian Du,  Albert Sole-Ribalta,  Agata Lapedriza",
                "发布日期": "2023-10-19",
                "摘要": "  This work presents a study on how to exploit the CLIP embedding space to\nperform Visual Sentiment Analysis. We experiment with two architectures built\non top of the CLIP embedding space, which we denote by CLIP-E. We train the\nCLIP-E models with WEBEmo, the largest publicly available and manually labeled\nbenchmark for Visual Sentiment Analysis, and perform two sets of experiments.\nFirst, we test on WEBEmo and compare the CLIP-E architectures with\nstate-of-the-art (SOTA) models and with CLIP Zero-Shot. Second, we perform\ncross dataset evaluation, and test the CLIP-E architectures trained with WEBEmo\non other Visual Sentiment Analysis benchmarks. Our results show that the CLIP-E\napproaches outperform SOTA models in WEBEmo fine grained categorization, and\nthey also generalize better when tested on datasets that have not been seen\nduring training. Interestingly, we observed that for the FI dataset, CLIP\nZero-Shot produces better accuracies than SOTA models and CLIP-E trained on\nWEBEmo. These results motivate several questions that we discuss in this paper,\nsuch as how we should design new benchmarks and evaluate Visual Sentiment\nAnalysis, and whether we should keep designing tailored Deep Learning models\nfor Visual Sentiment Analysis or focus our efforts on better using the\nknowledge encoded in large vision-language models such as CLIP for this task.\n",
                "链接": "https://arxiv.org/abs/2310.12062"
            },
            {
                "文章ID": "23956",
                "标题": "Sentiment analysis on electricity twitter posts",
                "作者": " Pardeep Kaur,  Maryam Edalati",
                "发布日期": "2022-06-13",
                "摘要": "  In today's world, everyone is expressive in some way, and the focus of this\nproject is on people's opinions about rising electricity prices in United\nKingdom and India using data from Twitter, a micro-blogging platform on which\npeople post messages, known as tweets. Because many people's incomes are not\ngood and they have to pay so many taxes and bills, maintaining a home has\nbecome a disputed issue these days. Despite the fact that Government offered\nsubsidy schemes to compensate people electricity bills but it is not welcomed\nby people. In this project, the aim is to perform sentiment analysis on\npeople's expressions and opinions expressed on Twitter. In order to grasp the\nelectricity prices opinion, it is necessary to carry out sentiment analysis for\nthe government and consumers in energy market. Furthermore, text present on\nthese medias are unstructured in nature, so to process them we firstly need to\npre-process the data. There are so many feature extraction techniques such as\nBag of Words, TF-IDF (Term Frequency-Inverse Document Frequency), word\nembedding, NLP based features like word count. In this project, we analysed the\nimpact of feature TF-IDF word level on electricity bills dataset of sentiment\nanalysis. We found that by using TF-IDF word level performance of sentiment\nanalysis is 3-4 higher than using N-gram features. Analysis is done using four\nclassification algorithms including Naive Bayes, Decision Tree, Random Forest,\nand Logistic Regression and considering F-Score, Accuracy, Precision, and\nRecall performance parameters.\n",
                "链接": "https://arxiv.org/abs/2206.05042"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "42411",
                "标题": "On the Evaluation of the Plausibility and Faithfulness of Sentiment\n  Analysis Explanations",
                "作者": " Julia El Zini,  Mohamad Mansour,  Basel Mousi,  Mariette Awad",
                "发布日期": "2022-10-14",
                "摘要": "  Current Explainable AI (ExAI) methods, especially in the NLP field, are\nconducted on various datasets by employing different metrics to evaluate\nseveral aspects. The lack of a common evaluation framework is hindering the\nprogress tracking of such methods and their wider adoption. In this work,\ninspired by offline information retrieval, we propose different metrics and\ntechniques to evaluate the explainability of SA models from two angles. First,\nwe evaluate the strength of the extracted \"rationales\" in faithfully explaining\nthe predicted outcome. Second, we measure the agreement between ExAI methods\nand human judgment on a homegrown dataset1 to reflect on the rationales\nplausibility. Our conducted experiments comprise four dimensions: (1) the\nunderlying architectures of SA models, (2) the approach followed by the ExAI\nmethod, (3) the reasoning difficulty, and (4) the homogeneity of the\nground-truth rationales. We empirically demonstrate that anchors explanations\nare more aligned with the human judgment and can be more confident in\nextracting supporting rationales. As can be foreseen, the reasoning complexity\nof sentiment is shown to thwart ExAI methods from extracting supporting\nevidence. Moreover, a remarkable discrepancy is discerned between the results\nof different explainability methods on the various architectures suggesting the\nneed for consolidation to observe enhanced performance. Predominantly,\ntransformers are shown to exhibit better explainability than convolutional and\nrecurrent architectures. Our work paves the way towards designing more\ninterpretable NLP models and enabling a common evaluation ground for their\nrelative strengths and robustness.\n",
                "链接": "https://arxiv.org/abs/2210.06916"
            },
            {
                "文章ID": "109794",
                "标题": "The Sentiment Problem: A Critical Survey towards Deconstructing\n  Sentiment Analysis",
                "作者": " Pranav Narayanan Venkit,  Mukund Srinath,  Sanjana Gautam,  Saranya Venkatraman,  Vipul Gupta,  Rebecca J. Passonneau,  Shomir Wilson",
                "发布日期": "2023-10-20",
                "摘要": "  We conduct an inquiry into the sociotechnical aspects of sentiment analysis\n(SA) by critically examining 189 peer-reviewed papers on their applications,\nmodels, and datasets. Our investigation stems from the recognition that SA has\nbecome an integral component of diverse sociotechnical systems, exerting\ninfluence on both social and technical users. By delving into sociological and\ntechnological literature on sentiment, we unveil distinct conceptualizations of\nthis term in domains such as finance, government, and medicine. Our study\nexposes a lack of explicit definitions and frameworks for characterizing\nsentiment, resulting in potential challenges and biases. To tackle this issue,\nwe propose an ethics sheet encompassing critical inquiries to guide\npractitioners in ensuring equitable utilization of SA. Our findings underscore\nthe significance of adopting an interdisciplinary approach to defining\nsentiment in SA and offer a pragmatic solution for its implementation.\n",
                "链接": "https://arxiv.org/abs/2310.12318"
            },
            {
                "文章ID": "118704",
                "标题": "Natural Language Processing Through Transfer Learning: A Case Study on\n  Sentiment Analysis",
                "作者": " Aman Yadav,  Abhishek Vichare",
                "发布日期": "2023-11-29",
                "摘要": "  Artificial intelligence and machine learning have significantly bolstered the\ntechnological world. This paper explores the potential of transfer learning in\nnatural language processing focusing mainly on sentiment analysis. The models\ntrained on the big data can also be used where data are scarce. The claim is\nthat, compared to training models from scratch, transfer learning, using\npre-trained BERT models, can increase sentiment classification accuracy. The\nstudy adopts a sophisticated experimental design that uses the IMDb dataset of\nsentimentally labelled movie reviews. Pre-processing includes tokenization and\nencoding of text data, making it suitable for NLP models. The dataset is used\non a BERT based model, measuring its performance using accuracy. The result\ncomes out to be 100 per cent accurate. Although the complete accuracy could\nappear impressive, it might be the result of overfitting or a lack of\ngeneralization. Further analysis is required to ensure the model's ability to\nhandle diverse and unseen data. The findings underscore the effectiveness of\ntransfer learning in NLP, showcasing its potential to excel in sentiment\nanalysis tasks. However, the research calls for a cautious interpretation of\nperfect accuracy and emphasizes the need for additional measures to validate\nthe model's generalization.\n",
                "链接": "https://arxiv.org/abs/2311.16965"
            },
            {
                "文章ID": "80332",
                "标题": "Sentiment Analysis in the Era of Large Language Models: A Reality Check",
                "作者": " Wenxuan Zhang,  Yue Deng,  Bing Liu,  Sinno Jialin Pan,  Lidong Bing",
                "发布日期": "2023-05-25",
                "摘要": "  Sentiment analysis (SA) has been a long-standing research area in natural\nlanguage processing. It can offer rich insights into human sentiments and\nopinions and has thus seen considerable interest from both academia and\nindustry. With the advent of large language models (LLMs) such as ChatGPT,\nthere is a great potential for their employment on SA problems. However, the\nextent to which existing LLMs can be leveraged for different sentiment analysis\ntasks remains unclear. This paper aims to provide a comprehensive investigation\ninto the capabilities of LLMs in performing various sentiment analysis tasks,\nfrom conventional sentiment classification to aspect-based sentiment analysis\nand multifaceted analysis of subjective texts. We evaluate performance across\n13 tasks on 26 datasets and compare the results against small language models\n(SLMs) trained on domain-specific datasets. Our study reveals that while LLMs\ndemonstrate satisfactory performance in simpler tasks, they lag behind in more\ncomplex tasks requiring deeper understanding or structured sentiment\ninformation. However, LLMs significantly outperform SLMs in few-shot learning\nsettings, suggesting their potential when annotation resources are limited. We\nalso highlight the limitations of current evaluation practices in assessing\nLLMs' SA abilities and propose a novel benchmark, \\textsc{SentiEval}, for a\nmore comprehensive and realistic evaluation. Data and code during our\ninvestigations are available at\n\\url{https://github.com/DAMO-NLP-SG/LLM-Sentiment}.\n",
                "链接": "https://arxiv.org/abs/2305.15005"
            },
            {
                "文章ID": "53574",
                "标题": "Multi-task Learning for Cross-Lingual Sentiment Analysis",
                "作者": " Gaurish Thakkar,  Nives Mikelic Preradovic,  Marko Tadic",
                "发布日期": "2022-12-15",
                "摘要": "  This paper presents a cross-lingual sentiment analysis of news articles using\nzero-shot and few-shot learning. The study aims to classify the Croatian news\narticles with positive, negative, and neutral sentiments using the Slovene\ndataset. The system is based on a trilingual BERT-based model trained in three\nlanguages: English, Slovene, Croatian. The paper analyses different setups\nusing datasets in two languages and proposes a simple multi-task model to\nperform sentiment classification. The evaluation is performed using the\nfew-shot and zero-shot scenarios in single-task and multi-task experiments for\nCroatian and Slovene.\n",
                "链接": "https://arxiv.org/abs/2212.07160"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于NLP领域的持续性学习论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "85699",
                "标题": "Operationalising Representation in Natural Language Processing",
                "作者": " Jacqueline Harding",
                "发布日期": "2023-11-21",
                "摘要": "  Despite its centrality in the philosophy of cognitive science, there has been\nlittle prior philosophical work engaging with the notion of representation in\ncontemporary NLP practice. This paper attempts to fill that lacuna: drawing on\nideas from cognitive science, I introduce a framework for evaluating the\nrepresentational claims made about components of neural NLP models, proposing\nthree criteria with which to evaluate whether a component of a model represents\na property and operationalising these criteria using probing classifiers, a\npopular analysis technique in NLP (and deep learning more broadly).\n  The project of operationalising a philosophically-informed notion of\nrepresentation should be of interest to both philosophers of science and NLP\npractitioners. It affords philosophers a novel testing-ground for claims about\nthe nature of representation, and helps NLPers organise the large literature on\nprobing experiments, suggesting novel avenues for empirical research.\n",
                "链接": "https://arxiv.org/abs/2306.08193"
            },
            {
                "文章ID": "79436",
                "标题": "Interactive Natural Language Processing",
                "作者": " Zekun Wang,  Ge Zhang,  Kexin Yang,  Ning Shi,  Wangchunshu Zhou,  Shaochun Hao,  Guangzheng Xiong,  Yizhi Li,  Mong Yuan Sim,  Xiuying Chen,  Qingqing Zhu,  Zhenzhu Yang,  Adam Nik,  Qi Liu,  Chenghua Lin,  Shi Wang,  Ruibo Liu,  Wenhu Chen,  Ke Xu,  Dayiheng Liu,  Yike Guo,  Jie Fu",
                "发布日期": "2023-05-23",
                "摘要": "  Interactive Natural Language Processing (iNLP) has emerged as a novel\nparadigm within the field of NLP, aimed at addressing limitations in existing\nframeworks while aligning with the ultimate goals of artificial intelligence.\nThis paradigm considers language models as agents capable of observing, acting,\nand receiving feedback iteratively from external entities. Specifically,\nlanguage models in this context can: (1) interact with humans for better\nunderstanding and addressing user needs, personalizing responses, aligning with\nhuman values, and improving the overall user experience; (2) interact with\nknowledge bases for enriching language representations with factual knowledge,\nenhancing the contextual relevance of responses, and dynamically leveraging\nexternal information to generate more accurate and informed responses; (3)\ninteract with models and tools for effectively decomposing and addressing\ncomplex tasks, leveraging specialized expertise for specific subtasks, and\nfostering the simulation of social behaviors; and (4) interact with\nenvironments for learning grounded representations of language, and effectively\ntackling embodied tasks such as reasoning, planning, and decision-making in\nresponse to environmental observations. This paper offers a comprehensive\nsurvey of iNLP, starting by proposing a unified definition and framework of the\nconcept. We then provide a systematic classification of iNLP, dissecting its\nvarious components, including interactive objects, interaction interfaces, and\ninteraction methods. We proceed to delve into the evaluation methodologies used\nin the field, explore its diverse applications, scrutinize its ethical and\nsafety issues, and discuss prospective research directions. This survey serves\nas an entry point for researchers who are interested in this rapidly evolving\narea and offers a broad view of the current landscape and future trajectory of\niNLP.\n",
                "链接": "https://arxiv.org/abs/2305.13246"
            },
            {
                "文章ID": "34310",
                "标题": "Review of Natural Language Processing in Pharmacology",
                "作者": " Dimitar Trajanov,  Vangel Trajkovski,  Makedonka Dimitrieva,  Jovana Dobreva,  Milos Jovanovik,  Matej Klemen,  Aleš Žagar,  Marko Robnik-Šikonja",
                "发布日期": "2023-01-27",
                "摘要": "  Natural language processing (NLP) is an area of artificial intelligence that\napplies information technologies to process the human language, understand it\nto a certain degree, and use it in various applications. This area has rapidly\ndeveloped in the last few years and now employs modern variants of deep neural\nnetworks to extract relevant patterns from large text corpora. The main\nobjective of this work is to survey the recent use of NLP in the field of\npharmacology. As our work shows, NLP is a highly relevant information\nextraction and processing approach for pharmacology. It has been used\nextensively, from intelligent searches through thousands of medical documents\nto finding traces of adversarial drug interactions in social media. We split\nour coverage into five categories to survey modern NLP methodology, commonly\naddressed tasks, relevant textual data, knowledge bases, and useful programming\nlibraries. We split each of the five categories into appropriate subcategories,\ndescribe their main properties and ideas, and summarize them in a tabular form.\nThe resulting survey presents a comprehensive overview of the area, useful to\npractitioners and interested observers.\n",
                "链接": "https://arxiv.org/abs/2208.10228"
            },
            {
                "文章ID": "56677",
                "标题": "User-Centered Security in Natural Language Processing",
                "作者": " Chris Emmery",
                "发布日期": "2023-01-12",
                "摘要": "  This dissertation proposes a framework of user-centered security in Natural\nLanguage Processing (NLP), and demonstrates how it can improve the\naccessibility of related research. Accordingly, it focuses on two security\ndomains within NLP with great public interest. First, that of author profiling,\nwhich can be employed to compromise online privacy through invasive inferences.\nWithout access and detailed insight into these models' predictions, there is no\nreasonable heuristic by which Internet users might defend themselves from such\ninferences. Secondly, that of cyberbullying detection, which by default\npresupposes a centralized implementation; i.e., content moderation across\nsocial platforms. As access to appropriate data is restricted, and the nature\nof the task rapidly evolves (both through lexical variation, and cultural\nshifts), the effectiveness of its classifiers is greatly diminished and thereby\noften misrepresented.\n  Under the proposed framework, we predominantly investigate the use of\nadversarial attacks on language; i.e., changing a given input (generating\nadversarial samples) such that a given model does not function as intended.\nThese attacks form a common thread between our user-centered security problems;\nthey are highly relevant for privacy-preserving obfuscation methods against\nauthor profiling, and adversarial samples might also prove useful to assess the\ninfluence of lexical variation and augmentation on cyberbullying detection.\n",
                "链接": "https://arxiv.org/abs/2301.04230"
            },
            {
                "文章ID": "63180",
                "标题": "Natural Language Processing in the Legal Domain",
                "作者": " Daniel Martin Katz,  Dirk Hartung,  Lauritz Gerlach,  Abhik Jana, II Michael J. Bommarito",
                "发布日期": "2023-02-24",
                "摘要": "  In this paper, we summarize the current state of the field of NLP & Law with\na specific focus on recent technical and substantive developments. To support\nour analysis, we construct and analyze a nearly complete corpus of more than\nsix hundred NLP & Law related papers published over the past decade. Our\nanalysis highlights several major trends. Namely, we document an increasing\nnumber of papers written, tasks undertaken, and languages covered over the\ncourse of the past decade. We observe an increase in the sophistication of the\nmethods which researchers deployed in this applied context. Slowly but surely,\nLegal NLP is beginning to match not only the methodological sophistication of\ngeneral NLP but also the professional standards of data availability and code\nreproducibility observed within the broader scientific community. We believe\nall of these trends bode well for the future of the field, but many questions\nin both the academic and commercial sphere still remain open.\n",
                "链接": "https://arxiv.org/abs/2302.12039"
            },
            {
                "文章ID": "121029",
                "标题": "PyThaiNLP: Thai Natural Language Processing in Python",
                "作者": " Wannaphong Phatthiyaphaibun,  Korakot Chaovavanich,  Charin Polpanumas,  Arthit Suriyawongkul,  Lalita Lowphansirikul,  Pattarawat Chormai,  Peerat Limkonchotiwat,  Thanathip Suntorntip,  Can Udomcharoenchaikit",
                "发布日期": "2023-12-11",
                "摘要": "  We present PyThaiNLP, a free and open-source natural language processing\n(NLP) library for Thai language implemented in Python. It provides a wide range\nof software, models, and datasets for Thai language. We first provide a brief\nhistorical context of tools for Thai language prior to the development of\nPyThaiNLP. We then outline the functionalities it provided as well as datasets\nand pre-trained language models. We later summarize its development milestones\nand discuss our experience during its development. We conclude by demonstrating\nhow industrial and research communities utilize PyThaiNLP in their work. The\nlibrary is freely available at https://github.com/pythainlp/pythainlp.\n",
                "链接": "https://arxiv.org/abs/2312.04649"
            },
            {
                "文章ID": "127",
                "标题": "Learning with Latent Structures in Natural Language Processing: A Survey",
                "作者": " Zhaofeng Wu",
                "发布日期": "2022-01-12",
                "摘要": "  While end-to-end learning with fully differentiable models has enabled\ntremendous success in natural language process (NLP) and machine learning,\nthere have been significant recent interests in learning with latent discrete\nstructures to incorporate better inductive biases for improved end-task\nperformance and better interpretability. This paradigm, however, is not\nstraightforwardly amenable to the mainstream gradient-based optimization\nmethods. This work surveys three main families of methods to learn such models:\nsurrogate gradients, continuous relaxation, and marginal likelihood\nmaximization via sampling. We conclude with a review of applications of these\nmethods and an inspection of the learned latent structure that they induce.\n",
                "链接": "https://arxiv.org/abs/2201.00490"
            },
            {
                "文章ID": "14740",
                "标题": "Experimental Standards for Deep Learning in Natural Language Processing\n  Research",
                "作者": " Dennis Ulmer,  Elisa Bassignana,  Max Müller-Eberstein,  Daniel Varab,  Mike Zhang,  Rob van der Goot,  Christian Hardmeier,  Barbara Plank",
                "发布日期": "2022-10-18",
                "摘要": "  The field of Deep Learning (DL) has undergone explosive growth during the\nlast decade, with a substantial impact on Natural Language Processing (NLP) as\nwell. Yet, compared to more established disciplines, a lack of common\nexperimental standards remains an open challenge to the field at large.\nStarting from fundamental scientific principles, we distill ongoing discussions\non experimental standards in NLP into a single, widely-applicable methodology.\nFollowing these best practices is crucial to strengthen experimental evidence,\nimprove reproducibility and support scientific progress. These standards are\nfurther collected in a public repository to help them transparently adapt to\nfuture needs.\n",
                "链接": "https://arxiv.org/abs/2204.06251"
            },
            {
                "文章ID": "60462",
                "标题": "Natural Language Processing for Policymaking",
                "作者": " Zhijing Jin,  Rada Mihalcea",
                "发布日期": "2023-02-08",
                "摘要": "  Language is the medium for many political activities, from campaigns to news\nreports. Natural language processing (NLP) uses computational tools to parse\ntext into key information that is needed for policymaking. In this chapter, we\nintroduce common methods of NLP, including text classification, topic modeling,\nevent extraction, and text scaling. We then overview how these methods can be\nused for policymaking through four major applications including data collection\nfor evidence-based policymaking, interpretation of political decisions, policy\ncommunication, and investigation of policy effects. Finally, we highlight some\npotential limitations and ethical concerns when using NLP for policymaking.\n  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational\nSocial Science for Policy (2023). Open Access on Springer:\nhttps://doi.org/10.1007/978-3-031-16624-2\n",
                "链接": "https://arxiv.org/abs/2302.03490"
            }
        ]
    },
    {
        "question": {
            "question": "找一下最近关于大模型评测的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "67955",
                "标题": "Clustering US Counties to Find Patterns Related to the COVID-19 Pandemic",
                "作者": " Cora Brown,  Sarah Milstein,  Tianyi Sun,  Cooper Zhao",
                "发布日期": "2023-03-22",
                "摘要": "  When COVID-19 first started spreading and quarantine was implemented, the\nSociety for Industrial and Applied Mathematics (SIAM) Student Chapter at the\nUniversity of Minnesota-Twin Cities began a collaboration with Ecolab to use\nour skills as data scientists and mathematicians to extract useful insights\nfrom relevant data relating to the pandemic. This collaboration consisted of\nmultiple groups working on different projects. In this write-up we focus on\nusing clustering techniques to help us find groups of similar counties in the\nUS and use that to help us understand the pandemic. Our team for this project\nconsisted of University of Minnesota students Cora Brown, Sarah Milstein,\nTianyi Sun, and Cooper Zhao, with help from Ecolab Data Scientist Jimmy\nBroomfield and University of Minnesota student Skye Ke. In the sections below\nwe describe all of the work done for this project. In Section 2, we list the\ndata we gathered, as well as the feature engineering we performed. In Section\n3, we describe the metrics we used for evaluating our models. In Section 4, we\nexplain the methods we used for interpreting the results of our various\nclustering approaches. In Section 5, we describe the different clustering\nmethods we implemented. In Section 6, we present the results of our clustering\ntechniques and provide relevant interpretation. Finally, in Section 7, we\nprovide some concluding remarks comparing the different clustering methods.\n",
                "链接": "https://arxiv.org/abs/2303.11936"
            },
            {
                "文章ID": "72313",
                "标题": "Evaluation of Social Biases in Recent Large Pre-Trained Models",
                "作者": " Swapnil Sharma,  Nikita Anand,  Kranthi Kiran G. V.,  Alind Jain",
                "发布日期": "2023-04-17",
                "摘要": "  Large pre-trained language models are widely used in the community. These\nmodels are usually trained on unmoderated and unfiltered data from open sources\nlike the Internet. Due to this, biases that we see in platforms online which\nare a reflection of those in society are in turn captured and learned by these\nmodels. These models are deployed in applications that affect millions of\npeople and their inherent biases are harmful to the targeted social groups. In\nthis work, we study the general trend in bias reduction as newer pre-trained\nmodels are released. Three recent models ( ELECTRA, DeBERTa, and DistilBERT)\nare chosen and evaluated against two bias benchmarks, StereoSet and\nCrowS-Pairs. They are compared to the baseline of BERT using the associated\nmetrics. We explore whether as advancements are made and newer, faster, lighter\nmodels are released: are they being developed responsibly such that their\ninherent social biases have been reduced compared to their older counterparts?\nThe results are compiled and we find that all the models under study do exhibit\nbiases but have generally improved as compared to BERT.\n",
                "链接": "https://arxiv.org/abs/2304.06861"
            },
            {
                "文章ID": "107503",
                "标题": "An evolutionary model of personality traits related to cooperative\n  behavior using a large language model",
                "作者": " Reiji Suzuki,  Takaya Arita",
                "发布日期": "2023-10-11",
                "摘要": "  This paper aims to shed light on the evolutionary dynamics of diverse and\nsocial populations by introducing the rich expressiveness of generative models\ninto the trait expression of social agent-based evolutionary models.\nSpecifically, we focus on the evolution of personality traits in the context of\na game-theoretic relationship as a situation in which inter-individual\ninterests exert strong selection pressures. We construct an agent model in\nwhich linguistic descriptions of personality traits related to cooperative\nbehavior are used as genes. The deterministic strategies extracted from Large\nLanguage Model (LLM) that make behavioral decisions based on these personality\ntraits are used as behavioral traits. The population is evolved according to\nselection based on average payoff and mutation of genes by asking LLM to\nslightly modify the parent gene toward cooperative or selfish. Through\npreliminary experiments and analyses, we clarify that such a model can indeed\nexhibit the evolution of cooperative behavior based on the diverse and\nhigher-order representation of personality traits. We also observed the\nrepeated intrusion of cooperative and selfish personality traits through\nchanges in the expression of personality traits, and found that the emerging\nwords in the evolved gene well reflected the behavioral tendency of its\npersonality in terms of their semantics.\n",
                "链接": "https://arxiv.org/abs/2310.05976"
            },
            {
                "文章ID": "125173",
                "标题": "A Large Language Model-based Computational Approach to Improve\n  Identity-Related Write-Ups",
                "作者": " Alex Doboli",
                "发布日期": "2023-12-29",
                "摘要": "  Creating written products is essential to modern life, including writings\nabout one's identity and personal experiences. However, writing is often a\ndifficult activity that requires extensive effort to frame the central ideas,\nthe pursued approach to communicate the central ideas, e.g., using analogies,\nmetaphors, or other possible means, the needed presentation structure, and the\nactual verbal expression. Large Language Models, a recently emerged approach in\nMachine Learning, can offer a significant help in reducing the effort and\nimproving the quality of written products. This paper proposes a new\ncomputational approach to explore prompts that given as inputs to a Large\nLanguage Models can generate cues to improve the considered written products.\nTwo case studies on improving write-ups, one based on an analogy and one on a\nmetaphor, are also presented in the paper.\n",
                "链接": "https://arxiv.org/abs/2312.16659"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "43057",
                "标题": "An efficient deep neural network to find small objects in large 3D\n  images",
                "作者": " Jungkyu Park,  Jakub Chłędowski,  Stanisław Jastrzębski,  Jan Witowski,  Yanqi Xu,  Linda Du,  Sushma Gaddam,  Eric Kim,  Alana Lewin,  Ujas Parikh,  Anastasia Plaunova,  Sardius Chen,  Alexandra Millet,  James Park,  Kristine Pysarenko,  Shalin Patel,  Julia Goldberg,  Melanie Wegener,  Linda Moy,  Laura Heacock,  Beatriu Reig,  Krzysztof J. Geras",
                "发布日期": "2023-02-28",
                "摘要": "  3D imaging enables accurate diagnosis by providing spatial information about\norgan anatomy. However, using 3D images to train AI models is computationally\nchallenging because they consist of 10x or 100x more pixels than their 2D\ncounterparts. To be trained with high-resolution 3D images, convolutional\nneural networks resort to downsampling them or projecting them to 2D. We\npropose an effective alternative, a neural network that enables efficient\nclassification of full-resolution 3D medical images. Compared to off-the-shelf\nconvolutional neural networks, our network, 3D Globally-Aware Multiple Instance\nClassifier (3D-GMIC), uses 77.98%-90.05% less GPU memory and 91.23%-96.02% less\ncomputation. While it is trained only with image-level labels, without\nsegmentation labels, it explains its predictions by providing pixel-level\nsaliency maps. On a dataset collected at NYU Langone Health, including 85,526\npatients with full-field 2D mammography (FFDM), synthetic 2D mammography, and\n3D mammography, 3D-GMIC achieves an AUC of 0.831 (95% CI: 0.769-0.887) in\nclassifying breasts with malignant findings using 3D mammography. This is\ncomparable to the performance of GMIC on FFDM (0.816, 95% CI: 0.737-0.878) and\nsynthetic 2D (0.826, 95% CI: 0.754-0.884), which demonstrates that 3D-GMIC\nsuccessfully classified large 3D images despite focusing computation on a\nsmaller percentage of its input compared to GMIC. Therefore, 3D-GMIC identifies\nand utilizes extremely small regions of interest from 3D images consisting of\nhundreds of millions of pixels, dramatically reducing associated computational\nchallenges. 3D-GMIC generalizes well to BCS-DBT, an external dataset from Duke\nUniversity Hospital, achieving an AUC of 0.848 (95% CI: 0.798-0.896).\n",
                "链接": "https://arxiv.org/abs/2210.08645"
            },
            {
                "文章ID": "101956",
                "标题": "Are Large Language Model-based Evaluators the Solution to Scaling Up\n  Multilingual Evaluation?",
                "作者": " Rishav Hada,  Varun Gumma,  Adrian de Wynter,  Harshita Diddee,  Mohamed Ahmed,  Monojit Choudhury,  Kalika Bali,  Sunayana Sitaram",
                "发布日期": "2023-09-15",
                "摘要": "  Large Language Models (LLMs) have demonstrated impressive performance on\nNatural Language Processing (NLP) tasks, such as Question Answering,\nSummarization, and Classification. The use of LLMs as evaluators, that can rank\nor score the output of other models (usually LLMs) has become increasingly\npopular, due to the limitations of current evaluation techniques including the\nlack of appropriate benchmarks, metrics, cost, and access to human annotators.\nWhile LLMs are capable of handling approximately 100 languages, the majority of\nlanguages beyond the top 20 lack systematic evaluation across various tasks,\nmetrics, and benchmarks. This creates an urgent need to scale up multilingual\nevaluation to ensure a precise understanding of LLM performance across diverse\nlanguages. LLM-based evaluators seem like the perfect solution to this problem,\nas they do not require human annotators, human-created references, or\nbenchmarks and can theoretically be used to evaluate any language covered by\nthe LLM. In this paper, we investigate whether LLM-based evaluators can help\nscale up multilingual evaluation. Specifically, we calibrate LLM-based\nevaluation against 20k human judgments of five metrics across three\ntext-generation tasks in eight languages. Our findings indicate that LLM-based\nevaluators may exhibit bias towards higher scores and should be used with\ncaution and should always be calibrated with a dataset of native speaker\njudgments, particularly in low-resource and non-Latin script languages.\n",
                "链接": "https://arxiv.org/abs/2309.07462"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "97463",
                "标题": "Can Large Language Models Find And Fix Vulnerable Software?",
                "作者": " David Noever",
                "发布日期": "2023-08-22",
                "摘要": "  In this study, we evaluated the capability of Large Language Models (LLMs),\nparticularly OpenAI's GPT-4, in detecting software vulnerabilities, comparing\ntheir performance against traditional static code analyzers like Snyk and\nFortify. Our analysis covered numerous repositories, including those from NASA\nand the Department of Defense. GPT-4 identified approximately four times the\nvulnerabilities than its counterparts. Furthermore, it provided viable fixes\nfor each vulnerability, demonstrating a low rate of false positives. Our tests\nencompassed 129 code samples across eight programming languages, revealing the\nhighest vulnerabilities in PHP and JavaScript. GPT-4's code corrections led to\na 90% reduction in vulnerabilities, requiring only an 11% increase in code\nlines. A critical insight was LLMs' ability to self-audit, suggesting fixes for\ntheir identified vulnerabilities and underscoring their precision. Future\nresearch should explore system-level vulnerabilities and integrate multiple\nstatic code analyzers for a holistic perspective on LLMs' potential.\n",
                "链接": "https://arxiv.org/abs/2308.10345"
            },
            {
                "文章ID": "97726",
                "标题": "Spurious Correlations and Where to Find Them",
                "作者": " Gautam Sreekumar,  Vishnu Naresh Boddeti",
                "发布日期": "2023-08-23",
                "摘要": "  Spurious correlations occur when a model learns unreliable features from the\ndata and are a well-known drawback of data-driven learning. Although there are\nseveral algorithms proposed to mitigate it, we are yet to jointly derive the\nindicators of spurious correlations. As a result, the solutions built upon\nstandalone hypotheses fail to beat simple ERM baselines. We collect some of the\ncommonly studied hypotheses behind the occurrence of spurious correlations and\ninvestigate their influence on standard ERM baselines using synthetic datasets\ngenerated from causal graphs. Subsequently, we observe patterns connecting\nthese hypotheses and model design choices.\n",
                "链接": "https://arxiv.org/abs/2308.11043"
            }
        ]
    },
    {
        "question": {
            "question": "近一个月与多模态大模型相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "87495",
                "标题": "A Survey on Multimodal Large Language Models",
                "作者": " Shukang Yin,  Chaoyou Fu,  Sirui Zhao,  Ke Li,  Xing Sun,  Tong Xu,  Enhong Chen",
                "发布日期": "2023-06-26",
                "摘要": "  Multimodal Large Language Model (MLLM) recently has been a new rising\nresearch hotspot, which uses powerful Large Language Models (LLMs) as a brain\nto perform multimodal tasks. The surprising emergent capabilities of MLLM, such\nas writing stories based on images and OCR-free math reasoning, are rare in\ntraditional methods, suggesting a potential path to artificial general\nintelligence. In this paper, we aim to trace and summarize the recent progress\nof MLLM. First of all, we present the formulation of MLLM and delineate its\nrelated concepts. Then, we discuss the key techniques and applications,\nincluding Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning\n(M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning\n(LAVR). Finally, we discuss existing challenges and point out promising\nresearch directions. In light of the fact that the era of MLLM has only just\nbegun, we will keep updating this survey and hope it can inspire more research.\nAn associated GitHub link collecting the latest papers is available at\nhttps://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.\n",
                "链接": "https://arxiv.org/abs/2306.13549"
            },
            {
                "文章ID": "7420",
                "标题": "Did AI get more negative recently?",
                "作者": " Dominik Beese,  Begüm Altunbaş,  Görkem Güzeler,  Steffen Eger",
                "发布日期": "2023-06-30",
                "摘要": "  In this paper, we classify scientific articles in the domain of natural\nlanguage processing (NLP) and machine learning (ML), as core subfields of\nartificial intelligence (AI), into whether (i) they extend the current\nstate-of-the-art by the introduction of novel techniques which beat existing\nmodels or whether (ii) they mainly criticize the existing state-of-the-art,\ni.e. that it is deficient with respect to some property (e.g. wrong evaluation,\nwrong datasets, misleading task specification). We refer to contributions under\n(i) as having a 'positive stance' and contributions under (ii) as having a\n'negative stance' (to related work). We annotate over 1.5 k papers from NLP and\nML to train a SciBERT-based model to automatically predict the stance of a\npaper based on its title and abstract. We then analyse large-scale trends on\nover 41 k papers from the last approximately 35 years in NLP and ML, finding\nthat papers have become substantially more positive over time, but negative\npapers also got more negative and we observe considerably more negative papers\nin recent years. Negative papers are also more influential in terms of\ncitations they receive.\n",
                "链接": "https://arxiv.org/abs/2202.13610"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "95587",
                "标题": "NLLG Quarterly arXiv Report 06/23: What are the most influential current\n  AI Papers?",
                "作者": " Steffen Eger,  Christoph Leiter,  Jonas Belouadi,  Ran Zhang,  Aida Kostikova,  Daniil Larionov,  Yanran Chen,  Vivian Fresen",
                "发布日期": "2023-08-15",
                "摘要": "  The rapid growth of information in the field of Generative Artificial\nIntelligence (AI), particularly in the subfields of Natural Language Processing\n(NLP) and Machine Learning (ML), presents a significant challenge for\nresearchers and practitioners to keep pace with the latest developments. To\naddress the problem of information overload, this report by the Natural\nLanguage Learning Group at Bielefeld University focuses on identifying the most\npopular papers on arXiv, with a specific emphasis on NLP and ML. The objective\nis to offer a quick guide to the most relevant and widely discussed research,\naiding both newcomers and established researchers in staying abreast of current\ntrends. In particular, we compile a list of the 40 most popular papers based on\nnormalized citation counts from the first half of 2023. We observe the\ndominance of papers related to Large Language Models (LLMs) and specifically\nChatGPT during the first half of 2023, with the latter showing signs of\ndeclining popularity more recently, however. Further, NLP related papers are\nthe most influential (around 60\\% of top papers) even though there are twice as\nmany ML related papers in our data. Core issues investigated in the most\nheavily cited papers are: LLM efficiency, evaluation techniques, ethical\nconsiderations, embodied agents, and problem-solving with LLMs. Additionally,\nwe examine the characteristics of top papers in comparison to others outside\nthe top-40 list (noticing the top paper's focus on LLM related issues and\nhigher number of co-authors) and analyze the citation distributions in our\ndataset, among others.\n",
                "链接": "https://arxiv.org/abs/2308.04889"
            },
            {
                "文章ID": "119149",
                "标题": "mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large\n  Language Model",
                "作者": " Anwen Hu,  Yaya Shi,  Haiyang Xu,  Jiabo Ye,  Qinghao Ye,  Ming Yan,  Chenliang Li,  Qi Qian,  Ji Zhang,  Fei Huang",
                "发布日期": "2023-12-01",
                "摘要": "  Recently, the strong text creation ability of Large Language Models(LLMs) has\ngiven rise to many tools for assisting paper reading or even writing. However,\nthe weak diagram analysis abilities of LLMs or Multimodal LLMs greatly limit\ntheir application scenarios, especially for scientific academic paper writing.\nIn this work, towards a more versatile copilot for academic paper writing, we\nmainly focus on strengthening the multi-modal diagram analysis ability of\nMultimodal LLMs. By parsing Latex source files of high-quality papers, we\ncarefully build a multi-modal diagram understanding dataset M-Paper. By\naligning diagrams in the paper with related paragraphs, we construct\nprofessional diagram analysis samples for training and evaluation. M-Paper is\nthe first dataset to support joint comprehension of multiple scientific\ndiagrams, including figures and tables in the format of images or Latex codes.\nBesides, to better align the copilot with the user's intention, we introduce\nthe `outline' as the control signal, which could be directly given by the user\nor revised based on auto-generated ones. Comprehensive experiments with a\nstate-of-the-art Mumtimodal LLM demonstrate that training on our dataset shows\nstronger scientific diagram understanding performance, including diagram\ncaptioning, diagram analysis, and outline recommendation. The dataset, code,\nand model are available at\nhttps://github.com/X-PLUG/mPLUG-DocOwl/tree/main/PaperOwl.\n",
                "链接": "https://arxiv.org/abs/2311.18248"
            },
            {
                "文章ID": "120419",
                "标题": "Literature Review of Mixed Reality Research",
                "作者": " Aizierjiang Aiersilan",
                "发布日期": "2023-12-18",
                "摘要": "  In the global context, while mixed reality has been an emerging concept for\nyears, recent technological and scientific advancements have now made it poised\nto revolutionize industries and daily life by offering enhanced functionalities\nand improved services. Besides reviewing the highly cited papers in the last 20\nyears among over a thousand research papers on mixed reality, this systematic\nreview provides the state-of-the-art applications and utilities of the mixed\nreality by primarily scrutinizing the associated papers in 2022 and 2023.\nFocusing on the potentials that this technology have in providing digitally\nsupported simulations and other utilities in the era of large language models,\nhighlighting the potential and limitations of the innovative solutions and also\nbringing focus to emerging research directions, such as telemedicine, remote\ncontrol and optimization of direct volume rendering. The paper's associated\nrepository is publicly accessible at https://aizierjiang.github.io/mr.\n",
                "链接": "https://arxiv.org/abs/2312.02995"
            },
            {
                "文章ID": "111631",
                "标题": "Emotion Recognition by Video: A review",
                "作者": " Junxiao Xue,  Jie Wang,  Xuecheng Wu,  Liangyu Fu",
                "发布日期": "2023-10-27",
                "摘要": "  Video emotion recognition is an important branch of affective computing, and\nits solutions can be applied in different fields such as human-computer\ninteraction (HCI) and intelligent medical treatment. Although the number of\npapers published in the field of emotion recognition is increasing, there are\nfew comprehensive literature reviews covering related research on video emotion\nrecognition. Therefore, this paper selects articles published from 2015 to 2023\nto systematize the existing trends in video emotion recognition in related\nstudies. In this paper, we first talk about two typical emotion models, then we\ntalk about databases that are frequently utilized for video emotion\nrecognition, including unimodal databases and multimodal databases. Next, we\nlook at and classify the specific structure and performance of modern unimodal\nand multimodal video emotion recognition methods, talk about the benefits and\ndrawbacks of each, and then we compare them in detail in the tables. Further,\nwe sum up the primary difficulties right now looked by video emotion\nrecognition undertakings and point out probably the most encouraging future\nheadings, such as establishing an open benchmark database and better multimodal\nfusion strategys. The essential objective of this paper is to assist scholarly\nand modern scientists with keeping up to date with the most recent advances and\nnew improvements in this speedy, high-influence field of video emotion\nrecognition.\n",
                "链接": "https://arxiv.org/abs/2310.17212"
            },
            {
                "文章ID": "102959",
                "标题": "OpenMSD: Towards Multilingual Scientific Documents Similarity\n  Measurement",
                "作者": " Yang Gao,  Ji Ma,  Ivan Korotkov,  Keith Hall,  Dana Alon,  Don Metzler",
                "发布日期": "2023-09-20",
                "摘要": "  We develop and evaluate multilingual scientific documents similarity\nmeasurement models in this work. Such models can be used to find related works\nin different languages, which can help multilingual researchers find and\nexplore papers more efficiently. We propose the first multilingual scientific\ndocuments dataset, Open-access Multilingual Scientific Documents (OpenMSD),\nwhich has 74M papers in 103 languages and 778M citation pairs. With OpenMSD, we\npretrain science-specialized language models, and explore different strategies\nto derive \"related\" paper pairs to fine-tune the models, including using a\nmixture of citation, co-citation, and bibliographic-coupling pairs. To further\nimprove the models' performance for non-English papers, we explore the use of\ngenerative language models to enrich the non-English papers with English\nsummaries. This allows us to leverage the models' English capabilities to\ncreate better representations for non-English papers. Our best model\nsignificantly outperforms strong baselines by 7-16% (in mean average\nprecision).\n",
                "链接": "https://arxiv.org/abs/2309.10539"
            },
            {
                "文章ID": "124188",
                "标题": "InfoVisDial: An Informative Visual Dialogue Dataset by Bridging Large\n  Multimodal and Language Models",
                "作者": " Bingbing Wen,  Zhengyuan Yang,  Jianfeng Wang,  Zhe Gan,  Bill Howe,  Lijuan Wang",
                "发布日期": "2023-12-22",
                "摘要": "  In this paper, we build a visual dialogue dataset, named InfoVisDial, which\nprovides rich informative answers in each round even with external knowledge\nrelated to the visual content. Different from existing datasets where the\nanswer is compact and short, InfoVisDial contains long free-form answers with\nrich information in each round of dialogue. For effective data collection, the\nkey idea is to bridge the large-scale multimodal model (e.g., GIT) and the\nlanguage models (e.g., GPT-3). GIT can describe the image content even with\nscene text, while GPT-3 can generate informative dialogue based on the image\ndescription and appropriate prompting techniques. With such automatic pipeline,\nwe can readily generate informative visual dialogue data at scale. Then, we ask\nhuman annotators to rate the generated dialogues to filter the low-quality\nconversations.Human analyses show that InfoVisDial covers informative and\ndiverse dialogue topics: $54.4\\%$ of the dialogue rounds are related to image\nscene texts, and $36.7\\%$ require external knowledge. Each round's answer is\nalso long and open-ended: $87.3\\%$ of answers are unique with an average length\nof $8.9$, compared with $27.37\\%$ and $2.9$ in VisDial. Last, we propose a\nstrong baseline by adapting the GIT model for the visual dialogue task and\nfine-tune the model on InfoVisDial. Hopefully, our work can motivate more\neffort on this direction.\n",
                "链接": "https://arxiv.org/abs/2312.13503"
            },
            {
                "文章ID": "111067",
                "标题": "Improving Biomedical Abstractive Summarisation with Knowledge\n  Aggregation from Citation Papers",
                "作者": " Chen Tang,  Shun Wang,  Tomas Goldsack,  Chenghua Lin",
                "发布日期": "2023-10-25",
                "摘要": "  Abstracts derived from biomedical literature possess distinct domain-specific\ncharacteristics, including specialised writing styles and biomedical\nterminologies, which necessitate a deep understanding of the related\nliterature. As a result, existing language models struggle to generate\ntechnical summaries that are on par with those produced by biomedical experts,\ngiven the absence of domain-specific background knowledge. This paper aims to\nenhance the performance of language models in biomedical abstractive\nsummarisation by aggregating knowledge from external papers cited within the\nsource article. We propose a novel attention-based citation aggregation model\nthat integrates domain-specific knowledge from citation papers, allowing neural\nnetworks to generate summaries by leveraging both the paper content and\nrelevant knowledge from citation papers. Furthermore, we construct and release\na large-scale biomedical summarisation dataset that serves as a foundation for\nour research. Extensive experiments demonstrate that our model outperforms\nstate-of-the-art approaches and achieves substantial improvements in\nabstractive biomedical text summarisation.\n",
                "链接": "https://arxiv.org/abs/2310.15684"
            }
        ]
    },
    {
        "question": {
            "question": "查找近六个月工具学习评测数据集的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "86605",
                "标题": "LaDe: The First Comprehensive Last-mile Delivery Dataset from Industry",
                "作者": " Lixia Wu,  Haomin Wen,  Haoyuan Hu,  Xiaowei Mao,  Yutong Xia,  Ergang Shan,  Jianbin Zhen,  Junhong Lou,  Yuxuan Liang,  Liuqing Yang,  Roger Zimmermann,  Youfang Lin,  Huaiyu Wan",
                "发布日期": "2023-06-21",
                "摘要": "  Real-world last-mile delivery datasets are crucial for research in logistics,\nsupply chain management, and spatio-temporal data mining. Despite a plethora of\nalgorithms developed to date, no widely accepted, publicly available last-mile\ndelivery dataset exists to support research in this field. In this paper, we\nintroduce \\texttt{LaDe}, the first publicly available last-mile delivery\ndataset with millions of packages from the industry. LaDe has three unique\ncharacteristics: (1) Large-scale. It involves 10,677k packages of 21k couriers\nover 6 months of real-world operation. (2) Comprehensive information. It offers\noriginal package information, such as its location and time requirements, as\nwell as task-event information, which records when and where the courier is\nwhile events such as task-accept and task-finish events happen. (3) Diversity.\nThe dataset includes data from various scenarios, including package pick-up and\ndelivery, and from multiple cities, each with its unique spatio-temporal\npatterns due to their distinct characteristics such as populations. We verify\nLaDe on three tasks by running several classical baseline models per task. We\nbelieve that the large-scale, comprehensive, diverse feature of LaDe can offer\nunparalleled opportunities to researchers in the supply chain community, data\nmining community, and beyond. The dataset homepage is publicly available at\nhttps://huggingface.co/datasets/Cainiao-AI/LaDe.\n",
                "链接": "https://arxiv.org/abs/2306.10675"
            },
            {
                "文章ID": "62650",
                "标题": "Climate Model Driven Seasonal Forecasting Approach with Deep Learning",
                "作者": " Alper Unal,  Busra Asan,  Ismail Sezen,  Bugra Yesilkaynak,  Yusuf Aydin,  Mehmet Ilicak,  Gozde Unal",
                "发布日期": "2023-02-22",
                "摘要": "  Understanding seasonal climatic conditions is critical for better management\nof resources such as water, energy and agriculture. Recently, there has been a\ngreat interest in utilizing the power of artificial intelligence methods in\nclimate studies. This paper presents a cutting-edge deep learning model\n(UNet++) trained by state-of-the-art global CMIP6 models to forecast global\ntemperatures a month ahead using the ERA5 reanalysis dataset. ERA5 dataset was\nalso used for finetuning as well performance analysis in the validation\ndataset. Three different setups (CMIP6; CMIP6 + elevation; CMIP6 + elevation +\nERA5 finetuning) were used with both UNet and UNet++ algorithms resulting in\nsix different models. For each model 14 different sequential and non-sequential\ntemporal settings were used. The Mean Absolute Error (MAE) analysis revealed\nthat UNet++ with CMIP6 with elevation and ERA5 finetuning model with \"Year 3\nMonth 2\" temporal case provided the best outcome with an MAE of 0.7. Regression\nanalysis over the validation dataset between the ERA5 data values and the\ncorresponding AI model predictions revealed slope and $R^2$ values close to 1\nsuggesting a very good agreement. The AI model predicts significantly better\nthan the mean CMIP6 ensemble between 2016 and 2021. Both models predict the\nsummer months more accurately than the winter months.\n",
                "链接": "https://arxiv.org/abs/2302.10480"
            },
            {
                "文章ID": "77431",
                "标题": "Privacy-Preserving Taxi-Demand Prediction Using Federated Learning",
                "作者": " Yumeki Goto,  Tomoya Matsumoto,  Hamada Rizk,  Naoto Yanai,  Hirozumi Yamaguchi",
                "发布日期": "2023-05-23",
                "摘要": "  Taxi-demand prediction is an important application of machine learning that\nenables taxi-providing facilities to optimize their operations and city\nplanners to improve transportation infrastructure and services. However, the\nuse of sensitive data in these systems raises concerns about privacy and\nsecurity. In this paper, we propose the use of federated learning for\ntaxi-demand prediction that allows multiple parties to train a machine learning\nmodel on their own data while keeping the data private and secure. This can\nenable organizations to build models on data they otherwise would not be able\nto access. Evaluation with real-world data collected from 16 taxi service\nproviders in Japan over a period of six months showed that the proposed system\ncan predict the demand level accurately within 1\\% error compared to a single\nmodel trained with integrated data.\n",
                "链接": "https://arxiv.org/abs/2305.08107"
            },
            {
                "文章ID": "55820",
                "标题": "Design and analysis of tweet-based election models for the 2021 Mexican\n  legislative election",
                "作者": " Alejandro Vigna-Gómez,  Javier Murillo,  Manelik Ramirez,  Alberto Borbolla,  Ian Márquez,  Prasun K. Ray",
                "发布日期": "2023-08-15",
                "摘要": "  Modelling and forecasting real-life human behaviour using online social media\nis an active endeavour of interest in politics, government, academia, and\nindustry. Since its creation in 2006, Twitter has been proposed as a potential\nlaboratory that could be used to gauge and predict social behaviour. During the\nlast decade, the user base of Twitter has been growing and becoming more\nrepresentative of the general population. Here we analyse this user base in the\ncontext of the 2021 Mexican Legislative Election. To do so, we use a dataset of\n15 million election-related tweets in the six months preceding election day. We\nexplore different election models that assign political preference to either\nthe ruling parties or the opposition. We find that models using data with\ngeographical attributes determine the results of the election with better\nprecision and accuracy than conventional polling methods. These results\ndemonstrate that analysis of public online data can outperform conventional\npolling methods, and that political analysis and general forecasting would\nlikely benefit from incorporating such data in the immediate future. Moreover,\nthe same Twitter dataset with geographical attributes is positively correlated\nwith results from official census data on population and internet usage in\nMexico. These findings suggest that we have reached a period in time when\nonline activity, appropriately curated, can provide an accurate representation\nof offline behaviour.\n",
                "链接": "https://arxiv.org/abs/2301.00626"
            },
            {
                "文章ID": "28273",
                "标题": "Robustness Evaluation of Deep Unsupervised Learning Algorithms for\n  Intrusion Detection Systems",
                "作者": " D'Jeff Kanda Nkashama,  Arian Soltani,  Jean-Charles Verdier,  Marc Frappier,  Pierre-Martin Tardif,  Froduald Kabanza",
                "发布日期": "2023-10-31",
                "摘要": "  Recently, advances in deep learning have been observed in various fields,\nincluding computer vision, natural language processing, and cybersecurity.\nMachine learning (ML) has demonstrated its ability as a potential tool for\nanomaly detection-based intrusion detection systems to build secure computer\nnetworks. Increasingly, ML approaches are widely adopted than heuristic\napproaches for cybersecurity because they learn directly from data. Data is\ncritical for the development of ML systems, and becomes potential targets for\nattackers. Basically, data poisoning or contamination is one of the most common\ntechniques used to fool ML models through data. This paper evaluates the\nrobustness of six recent deep learning algorithms for intrusion detection on\ncontaminated data. Our experiments suggest that the state-of-the-art algorithms\nused in this study are sensitive to data contamination and reveal the\nimportance of self-defense against data perturbation when developing novel\nmodels, especially for intrusion detection systems.\n",
                "链接": "https://arxiv.org/abs/2207.03576"
            },
            {
                "文章ID": "63716",
                "标题": "ChatGPT: A Meta-Analysis after 2.5 Months",
                "作者": " Christoph Leiter,  Ran Zhang,  Yanran Chen,  Jonas Belouadi,  Daniil Larionov,  Vivian Fresen,  Steffen Eger",
                "发布日期": "2023-02-28",
                "摘要": "  ChatGPT, a chatbot developed by OpenAI, has gained widespread popularity and\nmedia attention since its release in November 2022. However, little hard\nevidence is available regarding its perception in various sources. In this\npaper, we analyze over 300,000 tweets and more than 150 scientific papers to\ninvestigate how ChatGPT is perceived and discussed. Our findings show that\nChatGPT is generally viewed as of high quality, with positive sentiment and\nemotions of joy dominating in social media. Its perception has slightly\ndecreased since its debut, however, with joy decreasing and (negative) surprise\non the rise, and it is perceived more negatively in languages other than\nEnglish. In recent scientific papers, ChatGPT is characterized as a great\nopportunity across various fields including the medical domain, but also as a\nthreat concerning ethics and receives mixed assessments for education. Our\ncomprehensive meta-analysis of ChatGPT's current perception after 2.5 months\nsince its release can contribute to shaping the public debate and informing its\nfuture development. We make our data available.\n",
                "链接": "https://arxiv.org/abs/2302.13795"
            },
            {
                "文章ID": "121116",
                "标题": "Critical Analysis of 5G Networks Traffic Intrusion using PCA, t-SNE and\n  UMAP Visualization and Classifying Attacks",
                "作者": " Humera Ghani,  Shahram Salekzamankhani,  Bal Virdee",
                "发布日期": "2023-12-11",
                "摘要": "  Networks, threat models, and malicious actors are advancing quickly. With the\nincreased deployment of the 5G networks, the security issues of the attached 5G\nphysical devices have also increased. Therefore, artificial intelligence based\nautonomous end-to-end security design is needed that can deal with incoming\nthreats by detecting network traffic anomalies. To address this requirement, in\nthis research, we used a recently published 5G traffic dataset, 5G-NIDD, to\ndetect network traffic anomalies using machine and deep learning approaches.\nFirst, we analyzed the dataset using three visualization techniques:\nt-Distributed Stochastic Neighbor Embedding (t-SNE), Uniform Manifold\nApproximation and Projection (UMAP), and Principal Component Analysis (PCA).\nSecond, we reduced the data dimensionality using mutual information and PCA\ntechniques. Third, we solve the class imbalance issue by inserting synthetic\nrecords of minority classes. Last, we performed classification using six\ndifferent classifiers and presented the evaluation metrics. We received the\nbest results when K-Nearest Neighbors classifier was used: accuracy (97.2%),\ndetection rate (96.7%), and false positive rate (2.2%).\n",
                "链接": "https://arxiv.org/abs/2312.04864"
            },
            {
                "文章ID": "14709",
                "标题": "On the dynamics of credit history and social interaction features, and\n  their impact on creditworthiness assessment performance",
                "作者": " Ricardo Muñoz-Cancino,  Cristián Bravo,  Sebastián A. Ríos,  Manuel Graña",
                "发布日期": "2022-04-14",
                "摘要": "  For more than a half-century, credit risk management has used credit scoring\nmodels in each of its well-defined stages to manage credit risk. Application\nscoring is used to decide whether to grant a credit or not, while behavioral\nscoring is used mainly for portfolio management and to take preventive actions\nin case of default signals. In both cases, network data has recently been shown\nto be valuable to increase the predictive power of these models, especially\nwhen the borrower's historical data is scarce or not available. This study aims\nto understand the creditworthiness assessment performance dynamics and how it\nis influenced by the credit history, repayment behavior, and social network\nfeatures. To accomplish this, we introduced a machine learning classification\nframework to analyze 97.000 individuals and companies from the moment they\nobtained their first loan to 12 months afterward. Our novel and massive dataset\nallow us to characterize each borrower according to their credit behavior, and\nsocial and economic relationships. Our research shows that borrowers' history\nincreases performance at a decreasing rate during the first six months and then\nstabilizes. The most notable effect on perfomance of social networks features\noccurs at loan application; in personal scoring, this effect prevails a few\nmonths, while in business scoring adds value throughout the study period. These\nfindings are of great value to improve credit risk management and optimize the\nuse of traditional information and alternative data sources.\n",
                "链接": "https://arxiv.org/abs/2204.06122"
            },
            {
                "文章ID": "20115",
                "标题": "Predicting electrode array impedance after one month from cochlear\n  implantation surgery",
                "作者": " Yousef A. Alohali,  Yassin Abdelsamad,  Tamer Mesallam,  Fida Almuhawas,  Abdulrahman Hagr,  Mahmoud S. Fayed",
                "发布日期": "2022-05-23",
                "摘要": "  Sensorineural hearing loss can be treated using Cochlear implantation. After\nthis surgery using the electrode array impedance measurements, we can check the\nstability of the impedance value and the dynamic range. Deterioration of speech\nrecognition scores could happen because of increased impedance values.\nMedicines used to do these measures many times during a year after the surgery.\nPredicting the electrode impedance could help in taking decisions to help the\npatient get better hearing. In this research we used a dataset of 80 patients\nof children who did cochlear implantation using MED-EL FLEX28 electrode array\nof 12 channels. We predicted the electrode impedance on each channel after 1\nmonth from the surgery date. We used different machine learning algorithms like\nneural networks and decision trees. Our results indicates that the electrode\nimpedance can be predicted, and the best algorithm is different based on the\nelectrode channel. Also, the accuracy level varies between 66% and 100% based\non the electrode channel when accepting an error range between 0 and 3 KO.\nFurther research is required to predict the electrode impedance after three\nmonths, six months and one year.\n",
                "链接": "https://arxiv.org/abs/2205.10021"
            },
            {
                "文章ID": "28888",
                "标题": "A machine-learning-based tool for last closed-flux surface\n  reconstruction on tokamaks",
                "作者": " Chenguang Wan,  Zhi Yu,  Alessandro Pau,  Xiaojuan Liu,  Jiangang Li",
                "发布日期": "2023-04-19",
                "摘要": "  Nuclear fusion represents one of the best alternatives for a sustainable\nsource of clean energy. Tokamaks allow to confine fusion plasma with magnetic\nfields and one of the main challenges in the control of the magnetic\nconfiguration is the prediction/reconstruction of the Last Closed-Flux Surface\n(LCFS). The evolution in time of the LCFS is determined by the interaction of\nthe actuator coils and the internal tokamak plasma. This task requires\nreal-time capable tools able to deal with high-dimensional data as well as with\nhigh resolution in time, where the interaction between a wide range of input\nactuator coils with internal plasma state responses add additional layer of\ncomplexity. In this work, we present the application of a novel state of the\nart machine learning model to the LCFS reconstruction in the Experimental\nAdvanced Superconducting Tokamak (EAST) that learns automatically from the\nexperimental data of EAST. This architecture allows not only offline simulation\nand testing of a particular control strategy, but can also be embedded in the\nreal-time control system for online magnetic equilibrium reconstruction and\nprediction. In the real-time modeling test, our approach achieves very high\naccuracies, with over 99% average similarity in LCFS reconstruction of the\nentire discharge process.\n",
                "链接": "https://arxiv.org/abs/2207.05695"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下工具评测相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "86386",
                "标题": "TOBY: A Tool for Exploring Data in Academic Survey Papers",
                "作者": " Tathagata Chakraborti,  Jungkoo Kang,  Christian Muise,  Sarath Sreedharan,  Michael Walker,  Daniel Szafir,  Tom Williams",
                "发布日期": "2023-06-21",
                "摘要": "  This paper describes TOBY, a visualization tool that helps a user explore the\ncontents of an academic survey paper. The visualization consists of four\ncomponents: a hierarchical view of taxonomic data in the survey, a document\nsimilarity view in the space of taxonomic classes, a network view of citations,\nand a new paper recommendation tool. In this paper, we will discuss these\nfeatures in the context of three separate deployments of the tool.\n",
                "链接": "https://arxiv.org/abs/2306.10051"
            },
            {
                "文章ID": "34033",
                "标题": "SimLDA: A tool for topic model evaluation",
                "作者": " Rebecca M. C. Taylor,  Johan A. du Preez",
                "发布日期": "2022-08-22",
                "摘要": "  Variational Bayes (VB) applied to latent Dirichlet allocation (LDA) has\nbecome the most popular algorithm for aspect modeling. While sufficiently\nsuccessful in text topic extraction from large corpora, VB is less successful\nin identifying aspects in the presence of limited data. We present a novel\nvariational message passing algorithm as applied to Latent Dirichlet Allocation\n(LDA) and compare it with the gold standard VB and collapsed Gibbs sampling. In\nsituations where marginalisation leads to non-conjugate messages, we use ideas\nfrom sampling to derive approximate update equations. In cases where conjugacy\nholds, Loopy Belief update (LBU) (also known as Lauritzen-Spiegelhalter) is\nused. Our algorithm, ALBU (approximate LBU), has strong similarities with\nVariational Message Passing (VMP) (which is the message passing variant of VB).\nTo compare the performance of the algorithms in the presence of limited data,\nwe use data sets consisting of tweets and news groups. Using coherence measures\nwe show that ALBU learns latent distributions more accurately than does VB,\nespecially for smaller data sets.\n",
                "链接": "https://arxiv.org/abs/2208.09299"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "25887",
                "标题": "Diagnostic Tool for Out-of-Sample Model Evaluation",
                "作者": " Ludvig Hult,  Dave Zachariah,  Petre Stoica",
                "发布日期": "2023-10-17",
                "摘要": "  Assessment of model fitness is a key part of machine learning. The standard\nparadigm is to learn models by minimizing a chosen loss function averaged over\ntraining data, with the aim of achieving small losses on future data. In this\npaper, we consider the use of a finite calibration data set to characterize the\nfuture, out-of-sample losses of a model. We propose a simple model diagnostic\ntool that provides finite-sample guarantees under weak assumptions. The tool is\nsimple to compute and to interpret. Several numerical experiments are presented\nto show how the proposed method quantifies the impact of distribution shifts,\naids the analysis of regression, and enables model selection as well as\nhyper-parameter tuning.\n",
                "链接": "https://arxiv.org/abs/2206.10982"
            },
            {
                "文章ID": "108993",
                "标题": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
                "作者": " Alon Jacovi,  Avi Caciularu,  Jonathan Herzig,  Roee Aharoni,  Bernd Bohnet,  Mor Geva",
                "发布日期": "2023-12-29",
                "摘要": "  A growing area of research investigates augmenting language models with tools\n(e.g., search engines, calculators) to overcome their shortcomings (e.g.,\nmissing or incorrect knowledge, incorrect logical inferences). Various few-shot\ntool-usage strategies have been proposed. However, there is no systematic and\nfair comparison across different strategies, or between these strategies and\nstrong baselines that do not leverage tools. We conduct an extensive empirical\nanalysis, finding that (1) across various datasets, example difficulty levels,\nand models, strong no-tool baselines are competitive to tool-assisted\nstrategies, implying that effectively using tools with in-context\ndemonstrations is a difficult unsolved problem; (2) for knowledge-retrieval\ntasks, strategies that *refine* incorrect outputs with tools outperform\nstrategies that retrieve relevant information *ahead of* or *during\ngeneration*; (3) tool-assisted strategies are expensive in the number of tokens\nthey require to work -- incurring additional costs by orders of magnitude --\nwhich does not translate into significant improvement in performance. Overall,\nour findings suggest that few-shot tool integration is still an open challenge,\nemphasizing the need for comprehensive evaluations of future strategies to\naccurately assess their *benefits* and *costs*.\n",
                "链接": "https://arxiv.org/abs/2310.10062"
            },
            {
                "文章ID": "18767",
                "标题": "ALIGNMEET: A Comprehensive Tool for Meeting Annotation, Alignment, and\n  Evaluation",
                "作者": " Peter Polák,  Muskaan Singh,  Anna Nedoluzhko,  Ondřej Bojar",
                "发布日期": "2022-05-12",
                "摘要": "  Summarization is a challenging problem, and even more challenging is to\nmanually create, correct, and evaluate the summaries. The severity of the\nproblem grows when the inputs are multi-party dialogues in a meeting setup. To\nfacilitate the research in this area, we present ALIGNMEET, a comprehensive\ntool for meeting annotation, alignment, and evaluation. The tool aims to\nprovide an efficient and clear interface for fast annotation while mitigating\nthe risk of introducing errors. Moreover, we add an evaluation mode that\nenables a comprehensive quality evaluation of meeting minutes. To the best of\nour knowledge, there is no such tool available. We release the tool as open\nsource. It is also directly installable from PyPI.\n",
                "链接": "https://arxiv.org/abs/2205.05433"
            },
            {
                "文章ID": "88457",
                "标题": "CORAE: A Tool for Intuitive and Continuous Retrospective Evaluation of\n  Interactions",
                "作者": " Michael J. Sack,  Maria Teresa Parreira,  Jenny Fu,  Asher Lipman,  Hifza Javed,  Nawid Jamali,  Malte Jung",
                "发布日期": "2023-06-30",
                "摘要": "  This paper introduces CORAE, a novel web-based open-source tool for\nCOntinuous Retrospective Affect Evaluation, designed to capture continuous\naffect data about interpersonal perceptions in dyadic interactions. Grounded in\nbehavioral ecology perspectives of emotion, this approach replaces valence as\nthe relevant rating dimension with approach and withdrawal, reflecting the\ndegree to which behavior is perceived as increasing or decreasing social\ndistance. We conducted a study to experimentally validate the efficacy of our\nplatform with 24 participants. The tool's effectiveness was tested in the\ncontext of dyadic negotiation, revealing insights about how interpersonal\ndynamics evolve over time. We find that the continuous affect rating method is\nconsistent with individuals' perception of the overall interaction. This paper\ncontributes to the growing body of research on affective computing and offers a\nvaluable tool for researchers interested in investigating the temporal dynamics\nof affect and emotion in social interactions.\n",
                "链接": "https://arxiv.org/abs/2306.16629"
            },
            {
                "文章ID": "5122",
                "标题": "Deep soccer captioning with transformer: dataset, semantics-related\n  losses, and multi-level evaluation",
                "作者": " Ahmad Hammoudeh,  Bastien Vanderplaetse,  Stéphane Dupont",
                "发布日期": "2022-12-01",
                "摘要": "  This work aims at generating captions for soccer videos using deep learning.\nIn this context, this paper introduces a dataset, model, and triple-level\nevaluation. The dataset consists of 22k caption-clip pairs and three visual\nfeatures (images, optical flow, inpainting) for ~500 hours of \\emph{SoccerNet}\nvideos. The model is divided into three parts: a transformer learns language,\nConvNets learn vision, and a fusion of linguistic and visual features generates\ncaptions. The paper suggests evaluating generated captions at three levels:\nsyntax (the commonly used evaluation metrics such as BLEU-score and CIDEr),\nmeaning (the quality of descriptions for a domain expert), and corpus (the\ndiversity of generated captions). The paper shows that the diversity of\ngenerated captions has improved (from 0.07 reaching 0.18) with\nsemantics-related losses that prioritize selected words. Semantics-related\nlosses and the utilization of more visual features (optical flow, inpainting)\nimproved the normalized captioning score by 28\\%. The web page of this work:\nhttps://sites.google.com/view/soccercaptioning}{https://sites.google.com/view/soccercaptioning\n",
                "链接": "https://arxiv.org/abs/2202.05728"
            },
            {
                "文章ID": "33437",
                "标题": "ELEVANT: A Fully Automatic Fine-Grained Entity Linking Evaluation and\n  Analysis Tool",
                "作者": " Hannah Bast,  Matthias Hertel,  Natalie Prange",
                "发布日期": "2022-08-16",
                "摘要": "  We present Elevant, a tool for the fully automatic fine-grained evaluation of\na set of entity linkers on a set of benchmarks. Elevant provides an automatic\nbreakdown of the performance by various error categories and by entity type.\nElevant also provides a rich and compact, yet very intuitive and\nself-explanatory visualization of the results of a linker on a benchmark in\ncomparison to the ground truth. A live demo, the link to the complete code base\non GitHub and a link to a demo video are provided under\nhttps://elevant.cs.uni-freiburg.de .\n",
                "链接": "https://arxiv.org/abs/2208.07193"
            },
            {
                "文章ID": "113764",
                "标题": "Citance-Contextualized Summarization of Scientific Papers",
                "作者": " Shahbaz Syed,  Ahmad Dawar Hakimi,  Khalid Al-Khatib,  Martin Potthast",
                "发布日期": "2023-11-14",
                "摘要": "  Current approaches to automatic summarization of scientific papers generate\ninformative summaries in the form of abstracts. However, abstracts are not\nintended to show the relationship between a paper and the references cited in\nit. We propose a new contextualized summarization approach that can generate an\ninformative summary conditioned on a given sentence containing the citation of\na reference (a so-called \"citance\"). This summary outlines the content of the\ncited paper relevant to the citation location. Thus, our approach extracts and\nmodels the citances of a paper, retrieves relevant passages from cited papers,\nand generates abstractive summaries tailored to each citance. We evaluate our\napproach using $\\textbf{Webis-Context-SciSumm-2023}$, a new dataset containing\n540K~computer science papers and 4.6M~citances therein.\n",
                "链接": "https://arxiv.org/abs/2311.02408"
            }
        ]
    },
    {
        "question": {
            "question": "大模型在游戏方面的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "75161",
                "标题": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
                "作者": " Eddie Guo,  Mehul Gupta,  Jiawen Deng,  Ye-Jean Park,  Mike Paget,  Christopher Naugler",
                "发布日期": "2023-10-09",
                "摘要": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
                "链接": "https://arxiv.org/abs/2305.00844"
            },
            {
                "文章ID": "80551",
                "标题": "SPRING: Studying the Paper and Reasoning to Play Games",
                "作者": " Yue Wu,  Shrimai Prabhumoye,  So Yeon Min,  Yonatan Bisk,  Ruslan Salakhutdinov,  Amos Azaria,  Tom Mitchell,  Yuanzhi Li",
                "发布日期": "2023-12-13",
                "摘要": "  Open-world survival games pose significant challenges for AI algorithms due\nto their multi-tasking, deep exploration, and goal prioritization requirements.\nDespite reinforcement learning (RL) being popular for solving games, its high\nsample complexity limits its effectiveness in complex open-world games like\nCrafter or Minecraft. We propose a novel approach, SPRING, to read the game's\noriginal academic paper and use the knowledge learned to reason and play the\ngame through a large language model (LLM). Prompted with the LaTeX source as\ngame context and a description of the agent's current observation, our SPRING\nframework employs a directed acyclic graph (DAG) with game-related questions as\nnodes and dependencies as edges. We identify the optimal action to take in the\nenvironment by traversing the DAG and calculating LLM responses for each node\nin topological order, with the LLM's answer to final node directly translating\nto environment actions. In our experiments, we study the quality of in-context\n\"reasoning\" induced by different forms of prompts under the setting of the\nCrafter open-world environment. Our experiments suggest that LLMs, when\nprompted with consistent chain-of-thought, have great potential in completing\nsophisticated high-level trajectories. Quantitatively, SPRING with GPT-4\noutperforms all state-of-the-art RL baselines, trained for 1M steps, without\nany training. Finally, we show the potential of games as a test bed for LLMs.\n",
                "链接": "https://arxiv.org/abs/2305.15486"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "121257",
                "标题": "GlitchBench: Can large multimodal models detect video game glitches?",
                "作者": " Mohammad Reza Taesiri,  Tianjun Feng,  Cor-Paul Bezemer,  Anh Nguyen",
                "发布日期": "2023-12-12",
                "摘要": "  Large multimodal models (LMMs) have evolved from large language models (LLMs)\nto integrate multiple input modalities, such as visual inputs. This integration\naugments the capacity of LLMs for tasks requiring visual comprehension and\nreasoning. However, the extent and limitations of their enhanced abilities are\nnot fully understood, especially when it comes to real-world tasks. To address\nthis gap, we introduce GlitchBench, a novel benchmark derived from video game\nquality assurance tasks, to test and evaluate the reasoning capabilities of\nLMMs. Our benchmark is curated from a variety of unusual and glitched scenarios\nfrom video games and aims to challenge both the visual and linguistic reasoning\npowers of LMMs in detecting and interpreting out-of-the-ordinary events. We\nevaluate multiple state-of-the-art LMMs, and we show that GlitchBench presents\na new challenge for these models. Code and data are available at:\nhttps://glitchbench.github.io/\n",
                "链接": "https://arxiv.org/abs/2312.05291"
            },
            {
                "文章ID": "117394",
                "标题": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
                "作者": " Chengyu Wang,  Junbing Yan,  Wei Zhang,  Jun Huang",
                "发布日期": "2023-11-23",
                "摘要": "  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.13126"
            },
            {
                "文章ID": "81151",
                "标题": "Playing repeated games with Large Language Models",
                "作者": " Elif Akata,  Lion Schulz,  Julian Coda-Forno,  Seong Joon Oh,  Matthias Bethge,  Eric Schulz",
                "发布日期": "2023-05-29",
                "摘要": "  Large Language Models (LLMs) are transforming society and permeating into\ndiverse applications. As a result, LLMs will frequently interact with us and\nother agents. It is, therefore, of great societal value to understand how LLMs\nbehave in interactive social settings. Here, we propose to use behavioral game\ntheory to study LLM's cooperation and coordination behavior. To do so, we let\ndifferent LLMs (GPT-3, GPT-3.5, and GPT-4) play finitely repeated games with\neach other and with other, human-like strategies. Our results show that LLMs\ngenerally perform well in such tasks and also uncover persistent behavioral\nsignatures. In a large set of two players-two strategies games, we find that\nLLMs are particularly good at games where valuing their own self-interest pays\noff, like the iterated Prisoner's Dilemma family. However, they behave\nsub-optimally in games that require coordination. We, therefore, further focus\non two games from these distinct families. In the canonical iterated Prisoner's\nDilemma, we find that GPT-4 acts particularly unforgivingly, always defecting\nafter another agent has defected only once. In the Battle of the Sexes, we find\nthat GPT-4 cannot match the behavior of the simple convention to alternate\nbetween options. We verify that these behavioral signatures are stable across\nrobustness checks. Finally, we show how GPT-4's behavior can be modified by\nproviding further information about the other player as well as by asking it to\npredict the other player's actions before making a choice. These results enrich\nour understanding of LLM's social behavior and pave the way for a behavioral\ngame theory for machines.\n",
                "链接": "https://arxiv.org/abs/2305.16867"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "101477",
                "标题": "Strategic Behavior of Large Language Models: Game Structure vs.\n  Contextual Framing",
                "作者": " Nunzio Lorè,  Babak Heydari",
                "发布日期": "2023-09-13",
                "摘要": "  This paper investigates the strategic decision-making capabilities of three\nLarge Language Models (LLMs): GPT-3.5, GPT-4, and LLaMa-2, within the framework\nof game theory. Utilizing four canonical two-player games -- Prisoner's\nDilemma, Stag Hunt, Snowdrift, and Prisoner's Delight -- we explore how these\nmodels navigate social dilemmas, situations where players can either cooperate\nfor a collective benefit or defect for individual gain. Crucially, we extend\nour analysis to examine the role of contextual framing, such as diplomatic\nrelations or casual friendships, in shaping the models' decisions. Our findings\nreveal a complex landscape: while GPT-3.5 is highly sensitive to contextual\nframing, it shows limited ability to engage in abstract strategic reasoning.\nBoth GPT-4 and LLaMa-2 adjust their strategies based on game structure and\ncontext, but LLaMa-2 exhibits a more nuanced understanding of the games'\nunderlying mechanics. These results highlight the current limitations and\nvaried proficiencies of LLMs in strategic decision-making, cautioning against\ntheir unqualified use in tasks requiring complex strategic reasoning.\n",
                "链接": "https://arxiv.org/abs/2309.05898"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "1976",
                "标题": "Why Did You Not Compare With That? Identifying Papers for Use as\n  Baselines",
                "作者": " Manjot Bedi,  Tanisha Pandey,  Sumit Bhatia,  Tanmoy Chakraborty",
                "发布日期": "2022-01-21",
                "摘要": "  We propose the task of automatically identifying papers used as baselines in\na scientific article. We frame the problem as a binary classification task\nwhere all the references in a paper are to be classified as either baselines or\nnon-baselines. This is a challenging problem due to the numerous ways in which\na baseline reference can appear in a paper. We develop a dataset of $2,075$\npapers from ACL anthology corpus with all their references manually annotated\nas one of the two classes. We develop a multi-module attention-based neural\nclassifier for the baseline classification task that outperforms four\nstate-of-the-art citation role classification methods when applied to the\nbaseline classification task. We also present an analysis of the errors made by\nthe proposed classifier, eliciting the challenges that make baseline\nidentification a challenging problem.\n",
                "链接": "https://arxiv.org/abs/2201.08089"
            },
            {
                "文章ID": "50069",
                "标题": "How do Authors' Perceptions of their Papers Compare with Co-authors'\n  Perceptions and Peer-review Decisions?",
                "作者": " Charvi Rastogi,  Ivan Stelmakh,  Alina Beygelzimer,  Yann N. Dauphin,  Percy Liang,  Jennifer Wortman Vaughan,  Zhenyu Xue, III Hal Daumé,  Emma Pierson,  Nihar B. Shah",
                "发布日期": "2022-11-24",
                "摘要": "  How do author perceptions match up to the outcomes of the peer-review process\nand perceptions of others? In a top-tier computer science conference (NeurIPS\n2021) with more than 23,000 submitting authors and 9,000 submitted papers, we\nsurvey the authors on three questions: (i) their predicted probability of\nacceptance for each of their papers, (ii) their perceived ranking of their own\npapers based on scientific contribution, and (iii) the change in their\nperception about their own papers after seeing the reviews. The salient results\nare: (1) Authors have roughly a three-fold overestimate of the acceptance\nprobability of their papers: The median prediction is 70% for an approximately\n25% acceptance rate. (2) Female authors exhibit a marginally higher\n(statistically significant) miscalibration than male authors; predictions of\nauthors invited to serve as meta-reviewers or reviewers are similarly\ncalibrated, but better than authors who were not invited to review. (3)\nAuthors' relative ranking of scientific contribution of two submissions they\nmade generally agree (93%) with their predicted acceptance probabilities, but\nthere is a notable 7% responses where authors think their better paper will\nface a worse outcome. (4) The author-provided rankings disagreed with the\npeer-review decisions about a third of the time; when co-authors ranked their\njointly authored papers, co-authors disagreed at a similar rate -- about a\nthird of the time. (5) At least 30% of respondents of both accepted and\nrejected papers said that their perception of their own paper improved after\nthe review process. The stakeholders in peer review should take these findings\ninto account in setting their expectations from peer review.\n",
                "链接": "https://arxiv.org/abs/2211.12966"
            },
            {
                "文章ID": "95351",
                "标题": "Auditory Attention Decoding with Task-Related Multi-View Contrastive\n  Learning",
                "作者": " Xiaoyu Chen,  Changde Du,  Qiongyi Zhou,  Huiguang He",
                "发布日期": "2023-08-09",
                "摘要": "  The human brain can easily focus on one speaker and suppress others in\nscenarios such as a cocktail party. Recently, researchers found that auditory\nattention can be decoded from the electroencephalogram (EEG) data. However,\nmost existing deep learning methods are difficult to use prior knowledge of\ndifferent views (that is attended speech and EEG are task-related views) and\nextract an unsatisfactory representation. Inspired by Broadbent's filter model,\nwe decode auditory attention in a multi-view paradigm and extract the most\nrelevant and important information utilizing the missing view. Specifically, we\npropose an auditory attention decoding (AAD) method based on multi-view VAE\nwith task-related multi-view contrastive (TMC) learning. Employing TMC learning\nin multi-view VAE can utilize the missing view to accumulate prior knowledge of\ndifferent views into the fusion of representation, and extract the approximate\ntask-related representation. We examine our method on two popular AAD datasets,\nand demonstrate the superiority of our method by comparing it to the\nstate-of-the-art method.\n",
                "链接": "https://arxiv.org/abs/2308.04244"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "70884",
                "标题": "Learning to Compare Longitudinal Images",
                "作者": " Heejong Kim,  Mert R. Sabuncu",
                "发布日期": "2023-04-18",
                "摘要": "  Longitudinal studies, where a series of images from the same set of\nindividuals are acquired at different time-points, represent a popular\ntechnique for studying and characterizing temporal dynamics in biomedical\napplications. The classical approach for longitudinal comparison involves\nnormalizing for nuisance variations, such as image orientation or contrast\ndifferences, via pre-processing. Statistical analysis is, in turn, conducted to\ndetect changes of interest, either at the individual or population level. This\nclassical approach can suffer from pre-processing issues and limitations of the\nstatistical modeling. For example, normalizing for nuisance variation might be\nhard in settings where there are a lot of idiosyncratic changes. In this paper,\nwe present a simple machine learning-based approach that can alleviate these\nissues. In our approach, we train a deep learning model (called PaIRNet, for\nPairwise Image Ranking Network) to compare pairs of longitudinal images, with\nor without supervision. In the self-supervised setup, for instance, the model\nis trained to temporally order the images, which requires learning to recognize\ntime-irreversible changes. Our results from four datasets demonstrate that\nPaIRNet can be very effective in localizing and quantifying meaningful\nlongitudinal changes while discounting nuisance variation. Our code is\navailable at\n\\url{https://github.com/heejong-kim/learning-to-compare-longitudinal-images.git}\n",
                "链接": "https://arxiv.org/abs/2304.02531"
            },
            {
                "文章ID": "109422",
                "标题": "Sparse Multi-Object Render-and-Compare",
                "作者": " Florian Langer,  Ignas Budvytis,  Roberto Cipolla",
                "发布日期": "2023-10-18",
                "摘要": "  Reconstructing 3D shape and pose of static objects from a single image is an\nessential task for various industries, including robotics, augmented reality,\nand digital content creation. This can be done by directly predicting 3D shape\nin various representations or by retrieving CAD models from a database and\npredicting their alignments. Directly predicting 3D shapes often produces\nunrealistic, overly smoothed or tessellated shapes. Retrieving CAD models\nensures realistic shapes but requires robust and accurate alignment. Learning\nto directly predict CAD model poses from image features is challenging and\ninaccurate. Works, such as ROCA, compute poses from predicted normalised object\ncoordinates which can be more accurate but are susceptible to systematic\nfailure. SPARC demonstrates that following a ''render-and-compare'' approach\nwhere a network iteratively improves upon its own predictions achieves accurate\nalignments. Nevertheless, it performs individual CAD alignment for every object\ndetected in an image. This approach is slow when applied to many objects as the\ntime complexity increases linearly with the number of objects and can not learn\ninter-object relations. Introducing a new network architecture Multi-SPARC we\nlearn to perform CAD model alignments for multiple detected objects jointly.\nCompared to other single-view methods we achieve state-of-the-art performance\non the challenging real-world dataset ScanNet. By improving the instance\nalignment accuracy from 31.8% to 40.3% we perform similar to state-of-the-art\nmulti-view methods.\n",
                "链接": "https://arxiv.org/abs/2310.11184"
            },
            {
                "文章ID": "53554",
                "标题": "Decoding Multi-class Motor-related Intentions with User-optimized and\n  Robust BCI System Based on Multimodal Dataset",
                "作者": " Jeong-Hyun Cho,  Byoung-Hee Kwon,  Byeong-Hoo Lee",
                "发布日期": "2022-12-15",
                "摘要": "  A brain-computer interface (BCI) based on electroencephalography (EEG) can be\nuseful for rehabilitation and the control of external devices. Five grasping\ntasks were decoded for motor execution (ME) and motor imagery (MI). During this\nexperiment, eight healthy subjects were asked to imagine and grasp five\nobjects. Analysis of EEG signals was performed after detecting muscle signals\non electromyograms (EMG) with a time interval selection technique on data taken\nfrom these ME and MI experiments. By refining only data corresponding to the\nexact time when the users performed the motor intention, the proposed method\ncan train the decoding model using only the EEG data generated by various motor\nintentions with strong correlation with a specific class. There was an accuracy\nof 70.73% for ME and 47.95% for MI for the five offline tasks. This method may\nbe applied to future applications, such as controlling robot hands with BCIs.\n",
                "链接": "https://arxiv.org/abs/2212.07083"
            },
            {
                "文章ID": "6063",
                "标题": "A Summary of the ComParE COVID-19 Challenges",
                "作者": " Harry Coppock,  Alican Akman,  Christian Bergler,  Maurice Gerczuk,  Chloë Brown,  Jagmohan Chauhan,  Andreas Grammenos,  Apinan Hasthanasombat,  Dimitris Spathis,  Tong Xia,  Pietro Cicuta,  Jing Han,  Shahin Amiriparian,  Alice Baird,  Lukas Stappen,  Sandra Ottl,  Panagiotis Tzirakis,  Anton Batliner,  Cecilia Mascolo,  Björn W. Schuller",
                "发布日期": "2022-02-21",
                "摘要": "  The COVID-19 pandemic has caused massive humanitarian and economic damage.\nTeams of scientists from a broad range of disciplines have searched for methods\nto help governments and communities combat the disease. One avenue from the\nmachine learning field which has been explored is the prospect of a digital\nmass test which can detect COVID-19 from infected individuals' respiratory\nsounds. We present a summary of the results from the INTERSPEECH 2021\nComputational Paralinguistics Challenges: COVID-19 Cough, (CCS) and COVID-19\nSpeech, (CSS).\n",
                "链接": "https://arxiv.org/abs/2202.08981"
            },
            {
                "文章ID": "113764",
                "标题": "Citance-Contextualized Summarization of Scientific Papers",
                "作者": " Shahbaz Syed,  Ahmad Dawar Hakimi,  Khalid Al-Khatib,  Martin Potthast",
                "发布日期": "2023-11-14",
                "摘要": "  Current approaches to automatic summarization of scientific papers generate\ninformative summaries in the form of abstracts. However, abstracts are not\nintended to show the relationship between a paper and the references cited in\nit. We propose a new contextualized summarization approach that can generate an\ninformative summary conditioned on a given sentence containing the citation of\na reference (a so-called \"citance\"). This summary outlines the content of the\ncited paper relevant to the citation location. Thus, our approach extracts and\nmodels the citances of a paper, retrieves relevant passages from cited papers,\nand generates abstractive summaries tailored to each citance. We evaluate our\napproach using $\\textbf{Webis-Context-SciSumm-2023}$, a new dataset containing\n540K~computer science papers and 4.6M~citances therein.\n",
                "链接": "https://arxiv.org/abs/2311.02408"
            },
            {
                "文章ID": "11655",
                "标题": "Compare learning: bi-attention network for few-shot learning",
                "作者": " Li Ke,  Meng Pan,  Weigao Wen,  Dong Li",
                "发布日期": "2022-03-28",
                "摘要": "  Learning with few labeled data is a key challenge for visual recognition, as\ndeep neural networks tend to overfit using a few samples only. One of the\nFew-shot learning methods called metric learning addresses this challenge by\nfirst learning a deep distance metric to determine whether a pair of images\nbelong to the same category, then applying the trained metric to instances from\nother test set with limited labels. This method makes the most of the few\nsamples and limits the overfitting effectively. However, extant metric networks\nusually employ Linear classifiers or Convolutional neural networks (CNN) that\nare not precise enough to globally capture the subtle differences between\nvectors. In this paper, we propose a novel approach named Bi-attention network\nto compare the instances, which can measure the similarity between embeddings\nof instances precisely, globally and efficiently. We verify the effectiveness\nof our model on two benchmarks. Experiments show that our approach achieved\nimproved accuracy and convergence speed over baseline models.\n",
                "链接": "https://arxiv.org/abs/2203.13487"
            }
        ]
    },
    {
        "question": {
            "question": "请找到缓和噪声标签影响的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "48397",
                "标题": "Quantifying the Impact of Label Noise on Federated Learning",
                "作者": " Shuqi Ke,  Chao Huang,  Xin Liu",
                "发布日期": "2023-04-04",
                "摘要": "  Federated Learning (FL) is a distributed machine learning paradigm where\nclients collaboratively train a model using their local (human-generated)\ndatasets. While existing studies focus on FL algorithm development to tackle\ndata heterogeneity across clients, the important issue of data quality (e.g.,\nlabel noise) in FL is overlooked. This paper aims to fill this gap by providing\na quantitative study on the impact of label noise on FL. We derive an upper\nbound for the generalization error that is linear in the clients' label noise\nlevel. Then we conduct experiments on MNIST and CIFAR-10 datasets using various\nFL algorithms. Our empirical results show that the global model accuracy\nlinearly decreases as the noise level increases, which is consistent with our\ntheoretical analysis. We further find that label noise slows down the\nconvergence of FL training, and the global model tends to overfit when the\nnoise level is high.\n",
                "链接": "https://arxiv.org/abs/2211.07816"
            },
            {
                "文章ID": "88300",
                "标题": "Systematic analysis of the impact of label noise correction on ML\n  Fairness",
                "作者": " I. Oliveira e Silva,  C. Soares,  I. Sousa,  R. Ghani",
                "发布日期": "2023-06-29",
                "摘要": "  Arbitrary, inconsistent, or faulty decision-making raises serious concerns,\nand preventing unfair models is an increasingly important challenge in Machine\nLearning. Data often reflect past discriminatory behavior, and models trained\non such data may reflect bias on sensitive attributes, such as gender, race, or\nage. One approach to developing fair models is to preprocess the training data\nto remove the underlying biases while preserving the relevant information, for\nexample, by correcting biased labels. While multiple label noise correction\nmethods are available, the information about their behavior in identifying\ndiscrimination is very limited. In this work, we develop an empirical\nmethodology to systematically evaluate the effectiveness of label noise\ncorrection techniques in ensuring the fairness of models trained on biased\ndatasets. Our methodology involves manipulating the amount of label noise and\ncan be used with fairness benchmarks but also with standard ML datasets. We\napply the methodology to analyze six label noise correction methods according\nto several fairness metrics on standard OpenML datasets. Our results suggest\nthat the Hybrid Label Noise Correction method achieves the best trade-off\nbetween predictive performance and fairness. Clustering-Based Correction can\nreduce discrimination the most, however, at the cost of lower predictive\nperformance.\n",
                "链接": "https://arxiv.org/abs/2306.15994"
            },
            {
                "文章ID": "33646",
                "标题": "Investigating the Impact of Model Width and Density on Generalization in\n  Presence of Label Noise",
                "作者": " Yihao Xue,  Kyle Whitecross,  Baharan Mirzasoleiman",
                "发布日期": "2023-06-16",
                "摘要": "  Increasing the size of overparameterized neural networks has been a key in\nachieving state-of-the-art performance. This is captured by the double descent\nphenomenon, where the test loss follows a decreasing-increasing-decreasing\npattern as model width increases. However, the effect of label noise on the\ntest loss curve has not been fully explored. In this work, we uncover an\nintriguing phenomenon where label noise leads to a \\textit{final ascent} in the\noriginally observed double descent curve. Specifically, under a sufficiently\nlarge noise-to-sample-size ratio, optimal generalization is achieved at\nintermediate widths. Through theoretical analysis, we attribute this phenomenon\nto the shape transition of test loss variance induced by label noise.\nFurthermore, we extend the final ascent phenomenon to model density and provide\nthe first theoretical characterization showing that reducing density by\nrandomly dropping trainable parameters improves generalization under label\nnoise. We also thoroughly examine the roles of regularization and sample size.\nSurprisingly, we find that larger $\\ell_2$ regularization and robust learning\nmethods against label noise exacerbate the final ascent. We confirm the\nvalidity of our findings through extensive experiments on ReLu networks trained\non MNIST, ResNets trained on CIFAR-10/100, and InceptionResNet-v2 trained on\nStanford Cars with real-world noisy labels.\n",
                "链接": "https://arxiv.org/abs/2208.08003"
            },
            {
                "文章ID": "8323",
                "标题": "Learning from Label Proportions by Learning with Label Noise",
                "作者": " Jianxin Zhang,  Yutong Wang,  Clayton Scott",
                "发布日期": "2023-09-26",
                "摘要": "  Learning from label proportions (LLP) is a weakly supervised classification\nproblem where data points are grouped into bags, and the label proportions\nwithin each bag are observed instead of the instance-level labels. The task is\nto learn a classifier to predict the individual labels of future individual\ninstances. Prior work on LLP for multi-class data has yet to develop a\ntheoretically grounded algorithm. In this work, we provide a theoretically\ngrounded approach to LLP based on a reduction to learning with label noise,\nusing the forward correction (FC) loss of \\citet{Patrini2017MakingDN}. We\nestablish an excess risk bound and generalization error analysis for our\napproach, while also extending the theory of the FC loss which may be of\nindependent interest. Our approach demonstrates improved empirical performance\nin deep learning scenarios across multiple datasets and architectures, compared\nto the leading existing methods.\n",
                "链接": "https://arxiv.org/abs/2203.02496"
            },
            {
                "文章ID": "83903",
                "标题": "Binary Classification with Instance and Label Dependent Label Noise",
                "作者": " Hyungki Im,  Paul Grigas",
                "发布日期": "2023-06-07",
                "摘要": "  Learning with label dependent label noise has been extensively explored in\nboth theory and practice; however, dealing with instance (i.e., feature) and\nlabel dependent label noise continues to be a challenging task. The difficulty\narises from the fact that the noise rate varies for each instance, making it\nchallenging to estimate accurately. The question of whether it is possible to\nlearn a reliable model using only noisy samples remains unresolved. We answer\nthis question with a theoretical analysis that provides matching upper and\nlower bounds. Surprisingly, our results show that, without any additional\nassumptions, empirical risk minimization achieves the optimal excess risk\nbound. Specifically, we derive a novel excess risk bound proportional to the\nnoise level, which holds in very general settings, by comparing the empirical\nrisk minimizers obtained from clean samples and noisy samples. Second, we show\nthat the minimax lower bound for the 0-1 loss is a constant proportional to the\naverage noise rate. Our findings suggest that learning solely with noisy\nsamples is impossible without access to clean samples or strong assumptions on\nthe distribution of the data.\n",
                "链接": "https://arxiv.org/abs/2306.03402"
            },
            {
                "文章ID": "65748",
                "标题": "Efficient Testable Learning of Halfspaces with Adversarial Label Noise",
                "作者": " Ilias Diakonikolas,  Daniel M. Kane,  Vasilis Kontonis,  Sihan Liu,  Nikos Zarifis",
                "发布日期": "2023-03-10",
                "摘要": "  We give the first polynomial-time algorithm for the testable learning of\nhalfspaces in the presence of adversarial label noise under the Gaussian\ndistribution. In the recently introduced testable learning model, one is\nrequired to produce a tester-learner such that if the data passes the tester,\nthen one can trust the output of the robust learner on the data. Our\ntester-learner runs in time $\\poly(d/\\eps)$ and outputs a halfspace with\nmisclassification error $O(\\opt)+\\eps$, where $\\opt$ is the 0-1 error of the\nbest fitting halfspace. At a technical level, our algorithm employs an\niterative soft localization technique enhanced with appropriate testers to\nensure that the data distribution is sufficiently similar to a Gaussian.\n",
                "链接": "https://arxiv.org/abs/2303.05485"
            },
            {
                "文章ID": "87655",
                "标题": "Weakly Supervised Multi-Label Classification of Full-Text Scientific\n  Papers",
                "作者": " Yu Zhang,  Bowen Jin,  Xiusi Chen,  Yanzhen Shen,  Yunyi Zhang,  Yu Meng,  Jiawei Han",
                "发布日期": "2023-10-24",
                "摘要": "  Instead of relying on human-annotated training samples to build a classifier,\nweakly supervised scientific paper classification aims to classify papers only\nusing category descriptions (e.g., category names, category-indicative\nkeywords). Existing studies on weakly supervised paper classification are less\nconcerned with two challenges: (1) Papers should be classified into not only\ncoarse-grained research topics but also fine-grained themes, and potentially\ninto multiple themes, given a large and fine-grained label space; and (2) full\ntext should be utilized to complement the paper title and abstract for\nclassification. Moreover, instead of viewing the entire paper as a long linear\nsequence, one should exploit the structural information such as citation links\nacross papers and the hierarchy of sections and paragraphs in each paper. To\ntackle these challenges, in this study, we propose FUTEX, a framework that uses\nthe cross-paper network structure and the in-paper hierarchy structure to\nclassify full-text scientific papers under weak supervision. A network-aware\ncontrastive fine-tuning module and a hierarchy-aware aggregation module are\ndesigned to leverage the two types of structural signals, respectively.\nExperiments on two benchmark datasets demonstrate that FUTEX significantly\noutperforms competitive baselines and is on par with fully supervised\nclassifiers that use 1,000 to 60,000 ground-truth training samples.\n",
                "链接": "https://arxiv.org/abs/2306.14003"
            },
            {
                "文章ID": "4031",
                "标题": "Identifiability of Label Noise Transition Matrix",
                "作者": " Yang Liu,  Hao Cheng,  Kun Zhang",
                "发布日期": "2022-07-05",
                "摘要": "  The noise transition matrix plays a central role in the problem of learning\nwith noisy labels. Among many other reasons, a large number of existing\nsolutions rely on access to it. Identifying and estimating the transition\nmatrix without ground truth labels is a critical and challenging task. When\nlabel noise transition depends on each instance, the problem of identifying the\ninstance-dependent noise transition matrix becomes substantially more\nchallenging. Despite recent works proposing solutions for learning from\ninstance-dependent noisy labels, the field lacks a unified understanding of\nwhen such a problem remains identifiable. The goal of this paper is to\ncharacterize the identifiability of the label noise transition matrix. Building\non Kruskal's identifiability results, we are able to show the necessity of\nmultiple noisy labels in identifying the noise transition matrix for the\ngeneric case at the instance level. We further instantiate the results to\nexplain the successes of the state-of-the-art solutions and how additional\nassumptions alleviated the requirement of multiple noisy labels. Our result\nalso reveals that disentangled features are helpful in the above identification\ntask and we provide empirical evidence.\n",
                "链接": "https://arxiv.org/abs/2202.02016"
            },
            {
                "文章ID": "53932",
                "标题": "Instance-specific Label Distribution Regularization for Learning with\n  Label Noise",
                "作者": " Zehui Liao,  Shishuai Hu,  Yutong Xie,  Yong Xia",
                "发布日期": "2022-12-19",
                "摘要": "  Modeling noise transition matrix is a kind of promising method for learning\nwith label noise. Based on the estimated noise transition matrix and the noisy\nposterior probabilities, the clean posterior probabilities, which are jointly\ncalled Label Distribution (LD) in this paper, can be calculated as the\nsupervision. To reliably estimate the noise transition matrix, some methods\nassume that anchor points are available during training. Nonetheless, if anchor\npoints are invalid, the noise transition matrix might be poorly learned,\nresulting in poor performance. Consequently, other methods treat reliable data\npoints, extracted from training data, as pseudo anchor points. However, from a\nstatistical point of view, the noise transition matrix can be inferred from\ndata with noisy labels under the clean-label-domination assumption. Therefore,\nwe aim to estimate the noise transition matrix without (pseudo) anchor points.\nThere is evidence showing that samples are more likely to be mislabeled as\nother similar class labels, which means the mislabeling probability is highly\ncorrelated with the inter-class correlation. Inspired by this observation, we\npropose an instance-specific Label Distribution Regularization (LDR), in which\nthe instance-specific LD is estimated as the supervision, to prevent DCNNs from\nmemorizing noisy labels. Specifically, we estimate the noisy posterior under\nthe supervision of noisy labels, and approximate the batch-level noise\ntransition matrix by estimating the inter-class correlation matrix with neither\nanchor points nor pseudo anchor points. Experimental results on two synthetic\nnoisy datasets and two real-world noisy datasets demonstrate that our LDR\noutperforms existing methods.\n",
                "链接": "https://arxiv.org/abs/2212.08380"
            },
            {
                "文章ID": "111388",
                "标题": "Label Propagation for Graph Label Noise",
                "作者": " Yao Cheng,  Caihua Shan,  Yifei Shen,  Xiang Li,  Siqiang Luo,  Dongsheng Li",
                "发布日期": "2023-10-26",
                "摘要": "  Label noise is a common challenge in large datasets, as it can significantly\ndegrade the generalization ability of deep neural networks. Most existing\nstudies focus on noisy labels in computer vision; however, graph models\nencompass both node features and graph topology as input, and become more\nsusceptible to label noise through message-passing mechanisms. Recently, only a\nfew works have been proposed to tackle the label noise on graphs. One major\nlimitation is that they assume the graph is homophilous and the labels are\nsmoothly distributed. Nevertheless, real-world graphs may contain varying\ndegrees of heterophily or even be heterophily-dominated, leading to the\ninadequacy of current methods. In this paper, we study graph label noise in the\ncontext of arbitrary heterophily, with the aim of rectifying noisy labels and\nassigning labels to previously unlabeled nodes. We begin by conducting two\nempirical analyses to explore the impact of graph homophily on graph label\nnoise. Following observations, we propose a simple yet efficient algorithm,\ndenoted as LP4GLN. Specifically, LP4GLN is an iterative algorithm with three\nsteps: (1) reconstruct the graph to recover the homophily property, (2) utilize\nlabel propagation to rectify the noisy labels, (3) select high-confidence\nlabels to retain for the next iteration. By iterating these steps, we obtain a\nset of correct labels, ultimately achieving high accuracy in the node\nclassification task. The theoretical analysis is also provided to demonstrate\nits remarkable denoising \"effect\". Finally, we conduct experiments on 10\nbenchmark datasets under varying graph heterophily levels and noise types,\ncomparing the performance of LP4GLN with 7 typical baselines. Our results\nillustrate the superior performance of the proposed LP4GLN.\n",
                "链接": "https://arxiv.org/abs/2310.16560"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下文本检索任务上，是否有关于大模型在语义坍缩问题上的研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "46101",
                "标题": "Semantic Novelty Detection and Characterization in Factual Text\n  Involving Named Entities",
                "作者": " Nianzu Ma,  Sahisnu Mazumder,  Alexander Politowicz,  Bing Liu,  Eric Robertson,  Scott Grigsby",
                "发布日期": "2022-11-01",
                "摘要": "  Much of the existing work on text novelty detection has been studied at the\ntopic level, i.e., identifying whether the topic of a document or a sentence is\nnovel or not. Little work has been done at the fine-grained semantic level (or\ncontextual level). For example, given that we know Elon Musk is the CEO of a\ntechnology company, the sentence \"Elon Musk acted in the sitcom The Big Bang\nTheory\" is novel and surprising because normally a CEO would not be an actor.\nExisting topic-based novelty detection methods work poorly on this problem\nbecause they do not perform semantic reasoning involving relations between\nnamed entities in the text and their background knowledge. This paper proposes\nan effective model (called PAT-SND) to solve the problem, which can also\ncharacterize the novelty. An annotated dataset is also created. Evaluation\nshows that PAT-SND outperforms 10 baselines by large margins.\n",
                "链接": "https://arxiv.org/abs/2210.17440"
            },
            {
                "文章ID": "81507",
                "标题": "Reward Collapse in Aligning Large Language Models",
                "作者": " Ziang Song,  Tianle Cai,  Jason D. Lee,  Weijie J. Su",
                "发布日期": "2023-05-30",
                "摘要": "  The extraordinary capabilities of large language models (LLMs) such as\nChatGPT and GPT-4 are in part unleashed by aligning them with reward models\nthat are trained on human preferences, which are often represented as rankings\nof responses to prompts. In this paper, we document the phenomenon of\n\\textit{reward collapse}, an empirical observation where the prevailing\nranking-based approach results in an \\textit{identical} reward distribution\n\\textit{regardless} of the prompts during the terminal phase of training. This\noutcome is undesirable as open-ended prompts like ``write a short story about\nyour best friend'' should yield a continuous range of rewards for their\ncompletions, while specific prompts like ``what is the capital of New Zealand''\nshould generate either high or low rewards. Our theoretical investigation\nreveals that reward collapse is primarily due to the insufficiency of the\nranking-based objective function to incorporate prompt-related information\nduring optimization. This insight allows us to derive closed-form expressions\nfor the reward distribution associated with a set of utility functions in an\nasymptotic regime. To overcome reward collapse, we introduce a prompt-aware\noptimization scheme that provably admits a prompt-dependent reward distribution\nwithin the interpolating regime. Our experimental results suggest that our\nproposed prompt-aware utility functions significantly alleviate reward collapse\nduring the training of reward models.\n",
                "链接": "https://arxiv.org/abs/2305.17608"
            },
            {
                "文章ID": "121795",
                "标题": "Privacy Issues in Large Language Models: A Survey",
                "作者": " Seth Neel,  Peter Chang",
                "发布日期": "2023-12-13",
                "摘要": "  This is the first survey of the active area of AI research that focuses on\nprivacy issues in Large Language Models (LLMs). Specifically, we focus on work\nthat red-teams models to highlight privacy risks, attempts to build privacy\ninto the training or inference process, enables efficient data deletion from\ntrained models to comply with existing privacy regulations, and tries to\nmitigate copyright issues. Our focus is on summarizing technical research that\ndevelops algorithms, proves theorems, and runs empirical evaluations. While\nthere is an extensive body of legal and policy work addressing these challenges\nfrom a different angle, that is not the focus of our survey. Nevertheless,\nthese works, along with recent legal developments do inform how these technical\nproblems are formalized, and so we discuss them briefly in Section 1. While we\nhave made our best effort to include all the relevant work, due to the fast\nmoving nature of this research we may have missed some recent work. If we have\nmissed some of your work please contact us, as we will attempt to keep this\nsurvey relatively up to date. We are maintaining a repository with the list of\npapers covered in this survey and any relevant code that was publicly available\nat https://github.com/safr-ml-lab/survey-llm.\n",
                "链接": "https://arxiv.org/abs/2312.06717"
            },
            {
                "文章ID": "12053",
                "标题": "Image-text Retrieval: A Survey on Recent Research and Development",
                "作者": " Min Cao,  Shiping Li,  Juntao Li,  Liqiang Nie,  Min Zhang",
                "发布日期": "2022-11-21",
                "摘要": "  In the past few years, cross-modal image-text retrieval (ITR) has experienced\nincreased interest in the research community due to its excellent research\nvalue and broad real-world application. It is designed for the scenarios where\nthe queries are from one modality and the retrieval galleries from another\nmodality. This paper presents a comprehensive and up-to-date survey on the ITR\napproaches from four perspectives. By dissecting an ITR system into two\nprocesses: feature extraction and feature alignment, we summarize the recent\nadvance of the ITR approaches from these two perspectives. On top of this, the\nefficiency-focused study on the ITR system is introduced as the third\nperspective. To keep pace with the times, we also provide a pioneering overview\nof the cross-modal pre-training ITR approaches as the fourth perspective.\nFinally, we outline the common benchmark datasets and valuation metric for ITR,\nand conduct the accuracy comparison among the representative ITR approaches.\nSome critical yet less studied issues are discussed at the end of the paper.\n",
                "链接": "https://arxiv.org/abs/2203.14713"
            },
            {
                "文章ID": "99892",
                "标题": "SoK: Safer Digital-Safety Research Involving At-Risk Users",
                "作者": " Rosanna Bellini,  Emily Tseng,  Noel Warford,  Alaa Daffalla,  Tara Matthews,  Sunny Consolvo,  Jill Palzkill Woelfer,  Patrick Gage Kelley,  Michelle L. Mazurek,  Dana Cuomo,  Nicola Dell,  Thomas Ristenpart",
                "发布日期": "2023-09-06",
                "摘要": "  Research involving at-risk users -- that is, users who are more likely to\nexperience a digital attack or to be disproportionately affected when harm from\nsuch an attack occurs -- can pose significant safety challenges to both users\nand researchers. Nevertheless, pursuing research in computer security and\nprivacy is crucial to understanding how to meet the digital-safety needs of\nat-risk users and to design safer technology for all. To standardize and\nbolster safer research involving such users, we offer an analysis of 196\nacademic works to elicit 14 research risks and 36 safety practices used by a\ngrowing community of researchers. We pair this inconsistent set of reported\nsafety practices with oral histories from 12 domain experts to contribute\nscaffolded and consolidated pragmatic guidance that researchers can use to\nplan, execute, and share safer digital-safety research involving at-risk users.\nWe conclude by suggesting areas for future research regarding the reporting,\nstudy, and funding of at-risk user research\n",
                "链接": "https://arxiv.org/abs/2309.00735"
            },
            {
                "文章ID": "106796",
                "标题": "A Comprehensive Evaluation of Large Language Models on Benchmark\n  Biomedical Text Processing Tasks",
                "作者": " Israt Jahan,  Md Tahmid Rahman Laskar,  Chun Peng,  Jimmy Huang",
                "发布日期": "2023-10-11",
                "摘要": "  Recently, Large Language Models (LLM) have demonstrated impressive capability\nto solve a wide range of tasks. However, despite their success across various\ntasks, no prior work has investigated their capability in the biomedical domain\nyet. To this end, this paper aims to evaluate the performance of LLMs on\nbenchmark biomedical tasks. For this purpose, we conduct a comprehensive\nevaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets.\nTo the best of our knowledge, this is the first work that conducts an extensive\nevaluation and comparison of various LLMs in the biomedical domain.\nInterestingly, we find based on our evaluation that in biomedical datasets that\nhave smaller training sets, zero-shot LLMs even outperform the current\nstate-of-the-art fine-tuned biomedical models. This suggests that pretraining\non large text corpora makes LLMs quite specialized even in the biomedical\ndomain. We also find that not a single LLM can outperform other LLMs in all\ntasks, with the performance of different LLMs may vary depending on the task.\nWhile their performance is still quite poor in comparison to the biomedical\nmodels that were fine-tuned on large training sets, our findings demonstrate\nthat LLMs have the potential to be a valuable tool for various biomedical tasks\nthat lack large annotated data.\n",
                "链接": "https://arxiv.org/abs/2310.04270"
            },
            {
                "文章ID": "120739",
                "标题": "Sports Recommender Systems: Overview and Research Issues",
                "作者": " Alexander Felfernig,  Manfred Wundara,  Thi Ngoc Trang Tran,  Viet-Man Le,  Sebastian Lubos,  Seda Polat-Erdeniz",
                "发布日期": "2023-12-08",
                "摘要": "  Sports recommender systems receive an increasing attention due to their\npotential of fostering healthy living, improving personal well-being, and\nincreasing performances in sport. These systems support people in sports, for\nexample, by the recommendation of healthy and performance boosting food items,\nthe recommendation of training practices, talent and team recommendation, and\nthe recommendation of specific tactics in competitions. With applications in\nthe virtual world, for example, the recommendation of maps or opponents in\ne-sports, these systems already transcend conventional sports scenarios where\nphysical presence is needed. On the basis of different working examples, we\npresent an overview of sports recommender systems applications and techniques.\nOverall, we analyze the related state-of-the-art and discuss open research\nissues.\n",
                "链接": "https://arxiv.org/abs/2312.03785"
            },
            {
                "文章ID": "110623",
                "标题": "Evaluating Large Language Models on Controlled Generation Tasks",
                "作者": " Jiao Sun,  Yufei Tian,  Wangchunshu Zhou,  Nan Xu,  Qian Hu,  Rahul Gupta,  John Frederick Wieting,  Nanyun Peng,  Xuezhe Ma",
                "发布日期": "2023-10-24",
                "摘要": "  While recent studies have looked into the abilities of large language models\nin various benchmark tasks, including question generation, reading\ncomprehension, multilingual and etc, there have been few studies looking into\nthe controllability of large language models on generation tasks. We present an\nextensive analysis of various benchmarks including a sentence planning\nbenchmark with different granularities. After comparing large language models\nagainst state-of-the-start finetuned smaller models, we present a spectrum\nshowing large language models falling behind, are comparable, or exceed the\nability of smaller models. We conclude that **large language models struggle at\nmeeting fine-grained hard constraints**.\n",
                "链接": "https://arxiv.org/abs/2310.14542"
            },
            {
                "文章ID": "103626",
                "标题": "Creativity Support in the Age of Large Language Models: An Empirical\n  Study Involving Emerging Writers",
                "作者": " Tuhin Chakrabarty,  Vishakh Padmakumar,  Faeze Brahman,  Smaranda Muresan",
                "发布日期": "2023-09-26",
                "摘要": "  The development of large language models (LLMs) capable of following\ninstructions and engaging in conversational interactions sparked increased\ninterest in their utilization across various support tools. We investigate the\nutility of modern LLMs in assisting professional writers via an empirical user\nstudy (n=30). The design of our collaborative writing interface is grounded in\nthe cognitive process model of writing that views writing as a goal-oriented\nthinking process encompassing non-linear cognitive activities: planning,\ntranslating, and reviewing. Participants are asked to submit a post-completion\nsurvey to provide feedback on the potential and pitfalls of LLMs as writing\ncollaborators. Upon analyzing the writer-LLM interactions, we find that while\nwriters seek LLM's help across all three types of cognitive activities, they\nfind LLMs more helpful in translation and reviewing. Our findings from\nanalyzing both the interactions and the survey responses highlight future\nresearch directions in creative writing assistance using LLMs.\n",
                "链接": "https://arxiv.org/abs/2309.12570"
            },
            {
                "文章ID": "115971",
                "标题": "Assessing Translation capabilities of Large Language Models involving\n  English and Indian Languages",
                "作者": " Vandan Mujadia,  Ashok Urlana,  Yash Bhaskar,  Penumalla Aditya Pavani,  Kukkapalli Shravya,  Parameswari Krishnamurthy,  Dipti Misra Sharma",
                "发布日期": "2023-11-16",
                "摘要": "  Generative Large Language Models (LLMs) have achieved remarkable advancements\nin various NLP tasks. In this work, our aim is to explore the multilingual\ncapabilities of large language models by using machine translation as a task\ninvolving English and 22 Indian languages. We first investigate the translation\ncapabilities of raw large language models, followed by exploring the in-context\nlearning capabilities of the same raw models. We fine-tune these large language\nmodels using parameter efficient fine-tuning methods such as LoRA and\nadditionally with full fine-tuning. Through our study, we have identified the\nbest performing large language model for the translation task involving LLMs,\nwhich is based on LLaMA.\n  Our results demonstrate significant progress, with average BLEU scores of\n13.42, 15.93, 12.13, 12.30, and 12.07, as well as CHRF scores of 43.98, 46.99,\n42.55, 42.42, and 45.39, respectively, using 2-stage fine-tuned LLaMA-13b for\nEnglish to Indian languages on IN22 (conversational), IN22 (general),\nflores200-dev, flores200-devtest, and newstest2019 testsets. Similarly, for\nIndian languages to English, we achieved average BLEU scores of 14.03, 16.65,\n16.17, 15.35 and 12.55 along with chrF scores of 36.71, 40.44, 40.26, 39.51,\nand 36.20, respectively, using fine-tuned LLaMA-13b on IN22 (conversational),\nIN22 (general), flores200-dev, flores200-devtest, and newstest2019 testsets.\nOverall, our findings highlight the potential and strength of large language\nmodels for machine translation capabilities, including for languages that are\ncurrently underrepresented in LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.09216"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找对机器翻译数据集质量进行评估的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "83169",
                "标题": "Evaluating Machine Translation Quality with Conformal Predictive\n  Distributions",
                "作者": " Patrizio Giovannotti",
                "发布日期": "2023-06-05",
                "摘要": "  This paper presents a new approach for assessing uncertainty in machine\ntranslation by simultaneously evaluating translation quality and providing a\nreliable confidence score. Our approach utilizes conformal predictive\ndistributions to produce prediction intervals with guaranteed coverage, meaning\nthat for any given significance level $\\epsilon$, we can expect the true\nquality score of a translation to fall out of the interval at a rate of\n$1-\\epsilon$. In this paper, we demonstrate how our method outperforms a\nsimple, but effective baseline on six different language pairs in terms of\ncoverage and sharpness. Furthermore, we validate that our approach requires the\ndata exchangeability assumption to hold for optimal performance.\n",
                "链接": "https://arxiv.org/abs/2306.01549"
            },
            {
                "文章ID": "84997",
                "标题": "Conformalizing Machine Translation Evaluation",
                "作者": " Chrysoula Zerva,  André F. T. Martins",
                "发布日期": "2023-06-13",
                "摘要": "  Several uncertainty estimation methods have been recently proposed for\nmachine translation evaluation. While these methods can provide a useful\nindication of when not to trust model predictions, we show in this paper that\nthe majority of them tend to underestimate model uncertainty, and as a result\nthey often produce misleading confidence intervals that do not cover the ground\ntruth. We propose as an alternative the use of conformal prediction, a\ndistribution-free method to obtain confidence intervals with a theoretically\nestablished guarantee on coverage. First, we demonstrate that split conformal\nprediction can ``correct'' the confidence intervals of previous methods to\nyield a desired coverage level. Then, we highlight biases in estimated\nconfidence intervals, both in terms of the translation language pairs and the\nquality of translations. We apply conditional conformal prediction techniques\nto obtain calibration subsets for each data subgroup, leading to equalized\ncoverage.\n",
                "链接": "https://arxiv.org/abs/2306.06221"
            },
            {
                "文章ID": "87010",
                "标题": "Evaluation of Chinese-English Machine Translation of Emotion-Loaded\n  Microblog Texts: A Human Annotated Dataset for the Quality Assessment of\n  Emotion Translation",
                "作者": " Shenbin Qian,  Constantin Orasan,  Felix do Carmo,  Qiuliang Li,  Diptesh Kanojia",
                "发布日期": "2023-06-22",
                "摘要": "  In this paper, we focus on how current Machine Translation (MT) tools perform\non the translation of emotion-loaded texts by evaluating outputs from Google\nTranslate according to a framework proposed in this paper. We propose this\nevaluation framework based on the Multidimensional Quality Metrics (MQM) and\nperform a detailed error analysis of the MT outputs. From our analysis, we\nobserve that about 50% of the MT outputs fail to preserve the original emotion.\nAfter further analysis of the errors, we find that emotion carrying words and\nlinguistic phenomena such as polysemous words, negation, abbreviation etc., are\ncommon causes for these translation errors.\n",
                "链接": "https://arxiv.org/abs/2306.11900"
            },
            {
                "文章ID": "59415",
                "标题": "An Evaluation of Persian-English Machine Translation Datasets with\n  Transformers",
                "作者": " Amir Sartipi,  Meghdad Dehghan,  Afsaneh Fatemi",
                "发布日期": "2023-02-02",
                "摘要": "  Nowadays, many researchers are focusing their attention on the subject of\nmachine translation (MT). However, Persian machine translation has remained\nunexplored despite a vast amount of research being conducted in languages with\nhigh resources, such as English. Moreover, while a substantial amount of\nresearch has been undertaken in statistical machine translation for some\ndatasets in Persian, there is currently no standard baseline for\ntransformer-based text2text models on each corpus. This study collected and\nanalysed the most popular and valuable parallel corpora, which were used for\nPersian-English translation. Furthermore, we fine-tuned and evaluated two\nstate-of-the-art attention-based seq2seq models on each dataset separately (48\nresults). We hope this paper will assist researchers in comparing their Persian\nto English and vice versa machine translation results to a standard baseline.\n",
                "链接": "https://arxiv.org/abs/2302.00321"
            },
            {
                "文章ID": "39818",
                "标题": "QUAK: A Synthetic Quality Estimation Dataset for Korean-English Neural\n  Machine Translation",
                "作者": " Sugyeong Eo,  Chanjun Park,  Hyeonseok Moon,  Jaehyung Seo,  Gyeongmin Kim,  Jungseob Lee,  Heuiseok Lim",
                "发布日期": "2022-11-30",
                "摘要": "  With the recent advance in neural machine translation demonstrating its\nimportance, research on quality estimation (QE) has been steadily progressing.\nQE aims to automatically predict the quality of machine translation (MT) output\nwithout reference sentences. Despite its high utility in the real world, there\nremain several limitations concerning manual QE data creation: inevitably\nincurred non-trivial costs due to the need for translation experts, and issues\nwith data scaling and language expansion. To tackle these limitations, we\npresent QUAK, a Korean-English synthetic QE dataset generated in a fully\nautomatic manner. This consists of three sub-QUAK datasets QUAK-M, QUAK-P, and\nQUAK-H, produced through three strategies that are relatively free from\nlanguage constraints. Since each strategy requires no human effort, which\nfacilitates scalability, we scale our data up to 1.58M for QUAK-P, H and 6.58M\nfor QUAK-M. As an experiment, we quantitatively analyze word-level QE results\nin various ways while performing statistical analysis. Moreover, we show that\ndatasets scaled in an efficient way also contribute to performance improvements\nby observing meaningful performance gains in QUAK-M, P when adding data up to\n1.58M.\n",
                "链接": "https://arxiv.org/abs/2209.15285"
            },
            {
                "文章ID": "50351",
                "标题": "Competency-Aware Neural Machine Translation: Can Machine Translation\n  Know its Own Translation Quality?",
                "作者": " Pei Zhang,  Baosong Yang,  Haoran Wei,  Dayiheng Liu,  Kai Fan,  Luo Si,  Jun Xie",
                "发布日期": "2022-11-28",
                "摘要": "  Neural machine translation (NMT) is often criticized for failures that happen\nwithout awareness. The lack of competency awareness makes NMT untrustworthy.\nThis is in sharp contrast to human translators who give feedback or conduct\nfurther investigations whenever they are in doubt about predictions. To fill\nthis gap, we propose a novel competency-aware NMT by extending conventional NMT\nwith a self-estimator, offering abilities to translate a source sentence and\nestimate its competency. The self-estimator encodes the information of the\ndecoding procedure and then examines whether it can reconstruct the original\nsemantics of the source sentence. Experimental results on four translation\ntasks demonstrate that the proposed method not only carries out translation\ntasks intact but also delivers outstanding performance on quality estimation.\nWithout depending on any reference or annotated data typically required by\nstate-of-the-art metric and quality estimation methods, our model yields an\neven higher correlation with human quality judgments than a variety of\naforementioned methods, such as BLEURT, COMET, and BERTScore. Quantitative and\nqualitative analyses show better robustness of competency awareness in our\nmodel.\n",
                "链接": "https://arxiv.org/abs/2211.13865"
            },
            {
                "文章ID": "37434",
                "标题": "Rethinking Round-Trip Translation for Machine Translation Evaluation",
                "作者": " Terry Yue Zhuo,  Qiongkai Xu,  Xuanli He,  Trevor Cohn",
                "发布日期": "2023-05-16",
                "摘要": "  Automatic evaluation on low-resource language translation suffers from a\ndeficiency of parallel corpora. Round-trip translation could be served as a\nclever and straightforward technique to alleviate the requirement of the\nparallel evaluation corpus. However, there was an observation of obscure\ncorrelations between the evaluation scores by forward and round-trip\ntranslations in the era of statistical machine translation (SMT). In this\npaper, we report the surprising finding that round-trip translation can be used\nfor automatic evaluation without the references. Firstly, our revisit on the\nround-trip translation in SMT evaluation unveils that its long-standing\nmisunderstanding is essentially caused by copying mechanism. After removing\ncopying mechanism in SMT, round-trip translation scores can appropriately\nreflect the forward translation performance. Then, we demonstrate the\nrectification is overdue as round-trip translation could benefit multiple\nmachine translation evaluation tasks. To be more specific, round-trip\ntranslation could be used i) to predict corresponding forward translation\nscores; ii) to improve the performance of the recently advanced quality\nestimation model; and iii) to identify adversarial competitors in shared tasks\nvia cross-system verification.\n",
                "链接": "https://arxiv.org/abs/2209.07351"
            },
            {
                "文章ID": "6641",
                "标题": "An Overview on Machine Translation Evaluation",
                "作者": " Lifeng Han",
                "发布日期": "2022-02-23",
                "摘要": "  Since the 1950s, machine translation (MT) has become one of the important\ntasks of AI and development, and has experienced several different periods and\nstages of development, including rule-based methods, statistical methods, and\nrecently proposed neural network-based learning methods. Accompanying these\nstaged leaps is the evaluation research and development of MT, especially the\nimportant role of evaluation methods in statistical translation and neural\ntranslation research. The evaluation task of MT is not only to evaluate the\nquality of machine translation, but also to give timely feedback to machine\ntranslation researchers on the problems existing in machine translation itself,\nhow to improve and how to optimise. In some practical application fields, such\nas in the absence of reference translations, the quality estimation of machine\ntranslation plays an important role as an indicator to reveal the credibility\nof automatically translated target languages. This report mainly includes the\nfollowing contents: a brief history of machine translation evaluation (MTE),\nthe classification of research methods on MTE, and the the cutting-edge\nprogress, including human evaluation, automatic evaluation, and evaluation of\nevaluation methods (meta-evaluation). Manual evaluation and automatic\nevaluation include reference-translation based and reference-translation\nindependent participation; automatic evaluation methods include traditional\nn-gram string matching, models applying syntax and semantics, and deep learning\nmodels; evaluation of evaluation methods includes estimating the credibility of\nhuman evaluations, the reliability of the automatic evaluation, the reliability\nof the test set, etc. Advances in cutting-edge evaluation methods include\ntask-based evaluation, using pre-trained language models based on big data, and\nlightweight optimisation models using distillation techniques.\n",
                "链接": "https://arxiv.org/abs/2202.11027"
            },
            {
                "文章ID": "14818",
                "标题": "Disentangling Uncertainty in Machine Translation Evaluation",
                "作者": " Chrysoula Zerva,  Taisiya Glushkova,  Ricardo Rei,  André F. T. Martins",
                "发布日期": "2022-12-01",
                "摘要": "  Trainable evaluation metrics for machine translation (MT) exhibit strong\ncorrelation with human judgements, but they are often hard to interpret and\nmight produce unreliable scores under noisy or out-of-domain data. Recent work\nhas attempted to mitigate this with simple uncertainty quantification\ntechniques (Monte Carlo dropout and deep ensembles), however these techniques\n(as we show) are limited in several ways -- for example, they are unable to\ndistinguish between different kinds of uncertainty, and they are time and\nmemory consuming. In this paper, we propose more powerful and efficient\nuncertainty predictors for MT evaluation, and we assess their ability to target\ndifferent sources of aleatoric and epistemic uncertainty. To this end, we\ndevelop and compare training objectives for the COMET metric to enhance it with\nan uncertainty prediction output, including heteroscedastic regression,\ndivergence minimization, and direct uncertainty prediction. Our experiments\nshow improved results on uncertainty prediction for the WMT metrics task\ndatasets, with a substantial reduction in computational costs. Moreover, they\ndemonstrate the ability of these predictors to address specific uncertainty\ncauses in MT evaluation, such as low quality references and out-of-domain data.\n",
                "链接": "https://arxiv.org/abs/2204.06546"
            },
            {
                "文章ID": "54518",
                "标题": "Extrinsic Evaluation of Machine Translation Metrics",
                "作者": " Nikita Moghe,  Tom Sherborne,  Mark Steedman,  Alexandra Birch",
                "发布日期": "2023-06-21",
                "摘要": "  Automatic machine translation (MT) metrics are widely used to distinguish the\ntranslation qualities of machine translation systems across relatively large\ntest sets (system-level evaluation). However, it is unclear if automatic\nmetrics are reliable at distinguishing good translations from bad translations\nat the sentence level (segment-level evaluation). In this paper, we investigate\nhow useful MT metrics are at detecting the success of a machine translation\ncomponent when placed in a larger platform with a downstream task. We evaluate\nthe segment-level performance of the most widely used MT metrics (chrF, COMET,\nBERTScore, etc.) on three downstream cross-lingual tasks (dialogue state\ntracking, question answering, and semantic parsing). For each task, we only\nhave access to a monolingual task-specific model. We calculate the correlation\nbetween the metric's ability to predict a good/bad translation with the\nsuccess/failure on the final task for the Translate-Test setup. Our experiments\ndemonstrate that all metrics exhibit negligible correlation with the extrinsic\nevaluation of the downstream outcomes. We also find that the scores provided by\nneural metrics are not interpretable mostly because of undefined ranges. We\nsynthesise our analysis into recommendations for future MT metrics to produce\nlabels rather than scores for more informative interaction between machine\ntranslation and multilingual language understanding.\n",
                "链接": "https://arxiv.org/abs/2212.10297"
            }
        ]
    },
    {
        "question": {
            "question": "查找大语言模型相关的分析类型的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "97463",
                "标题": "Can Large Language Models Find And Fix Vulnerable Software?",
                "作者": " David Noever",
                "发布日期": "2023-08-22",
                "摘要": "  In this study, we evaluated the capability of Large Language Models (LLMs),\nparticularly OpenAI's GPT-4, in detecting software vulnerabilities, comparing\ntheir performance against traditional static code analyzers like Snyk and\nFortify. Our analysis covered numerous repositories, including those from NASA\nand the Department of Defense. GPT-4 identified approximately four times the\nvulnerabilities than its counterparts. Furthermore, it provided viable fixes\nfor each vulnerability, demonstrating a low rate of false positives. Our tests\nencompassed 129 code samples across eight programming languages, revealing the\nhighest vulnerabilities in PHP and JavaScript. GPT-4's code corrections led to\na 90% reduction in vulnerabilities, requiring only an 11% increase in code\nlines. A critical insight was LLMs' ability to self-audit, suggesting fixes for\ntheir identified vulnerabilities and underscoring their precision. Future\nresearch should explore system-level vulnerabilities and integrate multiple\nstatic code analyzers for a holistic perspective on LLMs' potential.\n",
                "链接": "https://arxiv.org/abs/2308.10345"
            },
            {
                "文章ID": "107503",
                "标题": "An evolutionary model of personality traits related to cooperative\n  behavior using a large language model",
                "作者": " Reiji Suzuki,  Takaya Arita",
                "发布日期": "2023-10-11",
                "摘要": "  This paper aims to shed light on the evolutionary dynamics of diverse and\nsocial populations by introducing the rich expressiveness of generative models\ninto the trait expression of social agent-based evolutionary models.\nSpecifically, we focus on the evolution of personality traits in the context of\na game-theoretic relationship as a situation in which inter-individual\ninterests exert strong selection pressures. We construct an agent model in\nwhich linguistic descriptions of personality traits related to cooperative\nbehavior are used as genes. The deterministic strategies extracted from Large\nLanguage Model (LLM) that make behavioral decisions based on these personality\ntraits are used as behavioral traits. The population is evolved according to\nselection based on average payoff and mutation of genes by asking LLM to\nslightly modify the parent gene toward cooperative or selfish. Through\npreliminary experiments and analyses, we clarify that such a model can indeed\nexhibit the evolution of cooperative behavior based on the diverse and\nhigher-order representation of personality traits. We also observed the\nrepeated intrusion of cooperative and selfish personality traits through\nchanges in the expression of personality traits, and found that the emerging\nwords in the evolved gene well reflected the behavioral tendency of its\npersonality in terms of their semantics.\n",
                "链接": "https://arxiv.org/abs/2310.05976"
            },
            {
                "文章ID": "125173",
                "标题": "A Large Language Model-based Computational Approach to Improve\n  Identity-Related Write-Ups",
                "作者": " Alex Doboli",
                "发布日期": "2023-12-29",
                "摘要": "  Creating written products is essential to modern life, including writings\nabout one's identity and personal experiences. However, writing is often a\ndifficult activity that requires extensive effort to frame the central ideas,\nthe pursued approach to communicate the central ideas, e.g., using analogies,\nmetaphors, or other possible means, the needed presentation structure, and the\nactual verbal expression. Large Language Models, a recently emerged approach in\nMachine Learning, can offer a significant help in reducing the effort and\nimproving the quality of written products. This paper proposes a new\ncomputational approach to explore prompts that given as inputs to a Large\nLanguage Models can generate cues to improve the considered written products.\nTwo case studies on improving write-ups, one based on an analogy and one on a\nmetaphor, are also presented in the paper.\n",
                "链接": "https://arxiv.org/abs/2312.16659"
            },
            {
                "文章ID": "70928",
                "标题": "Revolutionizing Single Cell Analysis: The Power of Large Language Models\n  for Cell Type Annotation",
                "作者": " Zehua Zeng,  Hongwu Du",
                "发布日期": "2023-04-07",
                "摘要": "  In recent years, single cell RNA sequencing has become a widely used\ntechnique to study cellular diversity and function. However, accurately\nannotating cell types from single cell data has been a challenging task, as it\nrequires extensive knowledge of cell biology and gene function. The emergence\nof large language models such as ChatGPT and New Bing in 2023 has\nrevolutionized this process by integrating the scientific literature and\nproviding accurate annotations of cell types. This breakthrough enables\nresearchers to conduct literature reviews more efficiently and accurately, and\ncan potentially uncover new insights into cell type annotation. By using\nChatGPT to annotate single cell data, we can relate rare cell type to their\nfunction and reveal specific differentiation trajectories of cell subtypes that\nwere previously overlooked. This can have important applications in\nunderstanding cancer progression, mammalian development, and stem cell\ndifferentiation, and can potentially lead to the discovery of key cells that\ninterrupt the differentiation pathway and solve key problems in the life\nsciences. Overall, the future of cell type annotation in single cell data looks\npromising and the Large Language model will be an important milestone in the\nhistory of single cell analysis.\n",
                "链接": "https://arxiv.org/abs/2304.02697"
            },
            {
                "文章ID": "75161",
                "标题": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
                "作者": " Eddie Guo,  Mehul Gupta,  Jiawen Deng,  Ye-Jean Park,  Mike Paget,  Christopher Naugler",
                "发布日期": "2023-10-09",
                "摘要": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
                "链接": "https://arxiv.org/abs/2305.00844"
            },
            {
                "文章ID": "67955",
                "标题": "Clustering US Counties to Find Patterns Related to the COVID-19 Pandemic",
                "作者": " Cora Brown,  Sarah Milstein,  Tianyi Sun,  Cooper Zhao",
                "发布日期": "2023-03-22",
                "摘要": "  When COVID-19 first started spreading and quarantine was implemented, the\nSociety for Industrial and Applied Mathematics (SIAM) Student Chapter at the\nUniversity of Minnesota-Twin Cities began a collaboration with Ecolab to use\nour skills as data scientists and mathematicians to extract useful insights\nfrom relevant data relating to the pandemic. This collaboration consisted of\nmultiple groups working on different projects. In this write-up we focus on\nusing clustering techniques to help us find groups of similar counties in the\nUS and use that to help us understand the pandemic. Our team for this project\nconsisted of University of Minnesota students Cora Brown, Sarah Milstein,\nTianyi Sun, and Cooper Zhao, with help from Ecolab Data Scientist Jimmy\nBroomfield and University of Minnesota student Skye Ke. In the sections below\nwe describe all of the work done for this project. In Section 2, we list the\ndata we gathered, as well as the feature engineering we performed. In Section\n3, we describe the metrics we used for evaluating our models. In Section 4, we\nexplain the methods we used for interpreting the results of our various\nclustering approaches. In Section 5, we describe the different clustering\nmethods we implemented. In Section 6, we present the results of our clustering\ntechniques and provide relevant interpretation. Finally, in Section 7, we\nprovide some concluding remarks comparing the different clustering methods.\n",
                "链接": "https://arxiv.org/abs/2303.11936"
            },
            {
                "文章ID": "105266",
                "标题": "A Large Language Model Approach to Educational Survey Feedback Analysis",
                "作者": " Michael J. Parker,  Caitlin Anderson,  Claire Stone,  YeaRim Oh",
                "发布日期": "2023-10-02",
                "摘要": "  This paper assesses the potential for the large language models (LLMs) GPT-4\nand GPT-3.5 to aid in deriving insight from education feedback surveys.\nExploration of LLM use cases in education has focused on teaching and learning,\nwith less exploration of capabilities in education feedback analysis. Survey\nanalysis in education involves goals such as finding gaps in curricula or\nevaluating teachers, often requiring time-consuming manual processing of\ntextual responses. LLMs have the potential to provide a flexible means of\nachieving these goals without specialized machine learning models or\nfine-tuning. We demonstrate a versatile approach to such goals by treating them\nas sequences of natural language processing (NLP) tasks including\nclassification (multi-label, multi-class, and binary), extraction, thematic\nanalysis, and sentiment analysis, each performed by LLM. We apply these\nworkflows to a real-world dataset of 2500 end-of-course survey comments from\nbiomedical science courses, and evaluate a zero-shot approach (i.e., requiring\nno examples or labeled training data) across all tasks, reflecting education\nsettings, where labeled data is often scarce. By applying effective prompting\npractices, we achieve human-level performance on multiple tasks with GPT-4,\nenabling workflows necessary to achieve typical goals. We also show the\npotential of inspecting LLMs' chain-of-thought (CoT) reasoning for providing\ninsight that may foster confidence in practice. Moreover, this study features\ndevelopment of a versatile set of classification categories, suitable for\nvarious course types (online, hybrid, or in-person) and amenable to\ncustomization. Our results suggest that LLMs can be used to derive a range of\ninsights from survey text.\n",
                "链接": "https://arxiv.org/abs/2309.17447"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            }
        ]
    },
    {
        "question": {
            "question": "查询2022年以来指令遵循数据集构建相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "47894",
                "标题": "How Much Hate with #china? A Preliminary Analysis on China-related\n  Hateful Tweets Two Years After the Covid Pandemic Began",
                "作者": " Jinghua Xu,  Zarah Weiss",
                "发布日期": "2022-11-21",
                "摘要": "  Following the outbreak of a global pandemic, online content is filled with\nhate speech. Donald Trump's ''Chinese Virus'' tweet shifted the blame for the\nspread of the Covid-19 virus to China and the Chinese people, which triggered a\nnew round of anti-China hate both online and offline. This research intends to\nexamine China-related hate speech on Twitter during the two years following the\nburst of the pandemic (2020 and 2021). Through Twitter's API, in total\n2,172,333 tweets hashtagged #china posted during the time were collected. By\nemploying multiple state-of-the-art pretrained language models for hate speech\ndetection, we identify a wide range of hate of various types, resulting in an\nautomatically labeled anti-China hate speech dataset. We identify a hateful\nrate in #china tweets of 2.5% in 2020 and 1.9% in 2021. This is well above the\naverage rate of online hate speech on Twitter at 0.6% identified in Gao et al.,\n2017. We further analyzed the longitudinal development of #china tweets and\nthose identified as hateful in 2020 and 2021 through visualizing the daily\nnumber and hate rate over the two years. Our keyword analysis of hate speech in\n#china tweets reveals the most frequently mentioned terms in the hateful #china\ntweets, which can be used for further social science studies.\n",
                "链接": "https://arxiv.org/abs/2211.06116"
            },
            {
                "文章ID": "29176",
                "标题": "Visualizing Gender Gap in Film Industry over the Past 100 Years",
                "作者": " Junkai Man,  Ruitian Wu,  Chenglin Zhang,  Xin Tong",
                "发布日期": "2022-07-15",
                "摘要": "  Visualizing big data can provide valuable insights into social science\nresearch. In this project, we focused on visualizing the potential gender gap\nin the global film industry over the past 100 years. We profiled the\ndifferences both for the actors/actresses and male/female movie audiences and\nanalyzed the IMDb data of the most popular 10,000 movies (the composition and\nimportance of casts of different genders, the cooperation network of the\nactors/actresses, the movie genres, the movie descriptions, etc.) and audience\nratings (the differences between male's and female's ratings). Findings suggest\nthat the gender gap has been distinct in many aspects, but a recent trend is\nthat this gap narrows down and women are gaining discursive power in the film\nindustry. Our study presented rich data, vivid illustrations, and novel\nperspectives that can serve as the foundation for further studies on related\ntopics and their social implications.\n",
                "链接": "https://arxiv.org/abs/2207.06692"
            },
            {
                "文章ID": "67955",
                "标题": "Clustering US Counties to Find Patterns Related to the COVID-19 Pandemic",
                "作者": " Cora Brown,  Sarah Milstein,  Tianyi Sun,  Cooper Zhao",
                "发布日期": "2023-03-22",
                "摘要": "  When COVID-19 first started spreading and quarantine was implemented, the\nSociety for Industrial and Applied Mathematics (SIAM) Student Chapter at the\nUniversity of Minnesota-Twin Cities began a collaboration with Ecolab to use\nour skills as data scientists and mathematicians to extract useful insights\nfrom relevant data relating to the pandemic. This collaboration consisted of\nmultiple groups working on different projects. In this write-up we focus on\nusing clustering techniques to help us find groups of similar counties in the\nUS and use that to help us understand the pandemic. Our team for this project\nconsisted of University of Minnesota students Cora Brown, Sarah Milstein,\nTianyi Sun, and Cooper Zhao, with help from Ecolab Data Scientist Jimmy\nBroomfield and University of Minnesota student Skye Ke. In the sections below\nwe describe all of the work done for this project. In Section 2, we list the\ndata we gathered, as well as the feature engineering we performed. In Section\n3, we describe the metrics we used for evaluating our models. In Section 4, we\nexplain the methods we used for interpreting the results of our various\nclustering approaches. In Section 5, we describe the different clustering\nmethods we implemented. In Section 6, we present the results of our clustering\ntechniques and provide relevant interpretation. Finally, in Section 7, we\nprovide some concluding remarks comparing the different clustering methods.\n",
                "链接": "https://arxiv.org/abs/2303.11936"
            },
            {
                "文章ID": "82232",
                "标题": "Visual Exploratory Data Analysis of the Covid-19 Pandemic in Nigeria:\n  Two Years after the Outbreak",
                "作者": " Ugochukwu Orji,  Modesta Ezema,  Elochukwu Ukwandu,  Chikaodili Ugwuishiwu,  Ezugwu Obianuju,  Malachi Egbugha",
                "发布日期": "2023-06-04",
                "摘要": "  The outbreak of the coronavirus disease in Nigeria and all over the world in\n2019/2020 caused havoc on the world's economy and put a strain on global\nhealthcare facilities and personnel. It also threw up many opportunities to\nimprove processes using artificial intelligence techniques like big data\nanalytics and business intelligence. The need to speedily make decisions that\ncould have far-reaching effects is prompting the boom in data analytics which\nis achieved via exploratory data analysis (EDA) to see trends, patterns, and\nrelationships in the data. Today, big data analytics is revolutionizing\nprocesses and helping improve productivity and decision-making capabilities in\nall aspects of life. The large amount of heterogeneous and, in most cases,\nopaque data now available has made it possible for researchers and businesses\nof all sizes to effectively deploy data analytics to gain action-oriented\ninsights into various problems in real time. In this paper, we deployed\nMicrosoft Excel and Python to perform EDA of the covid-19 pandemic data in\nNigeria and presented our results via visualizations and a dashboard using\nTableau. The dataset is from the Nigeria Centre for Disease Control (NCDC)\nrecorded between February 28th, 2020, and July 19th, 2022. This paper aims to\nfollow the data and visually show the trends over the past 2 years and also\nshow the powerful capabilities of these data analytics tools and techniques.\nFurthermore, our findings contribute to the current literature on Covid-19\nresearch by showcasing how the virus has progressed in Nigeria over time and\nthe insights thus far.\n",
                "链接": "https://arxiv.org/abs/2305.19297"
            },
            {
                "文章ID": "23536",
                "标题": "Using Mixed-Effects Models to Learn Bayesian Networks from Related Data\n  Sets",
                "作者": " Marco Scutari,  Christopher Marquis,  Laura Azzimonti",
                "发布日期": "2022-11-16",
                "摘要": "  We commonly assume that data are a homogeneous set of observations when\nlearning the structure of Bayesian networks. However, they often comprise\ndifferent data sets that are related but not homogeneous because they have been\ncollected in different ways or from different populations.\n  In our previous work (Azzimonti, Corani and Scutari, 2021), we proposed a\nclosed-form Bayesian Hierarchical Dirichlet score for discrete data that pools\ninformation across related data sets to learn a single encompassing network\nstructure, while taking into account the differences in their probabilistic\nstructures. In this paper, we provide an analogous solution for learning a\nBayesian network from continuous data using mixed-effects models to pool\ninformation across the related data sets. We study its structural, parametric,\npredictive and classification accuracy and we show that it outperforms both\nconditional Gaussian Bayesian networks (that do not perform any pooling) and\nclassical Gaussian Bayesian networks (that disregard the heterogeneous nature\nof the data). The improvement is marked for low sample sizes and for unbalanced\ndata sets.\n",
                "链接": "https://arxiv.org/abs/2206.03743"
            },
            {
                "文章ID": "5986",
                "标题": "Mining On Alzheimer's Diseases Related Knowledge Graph to Identity\n  Potential AD-related Semantic Triples for Drug Repurposing",
                "作者": " Yi Nian,  Xinyue Hu,  Rui Zhang,  Jingna Feng,  Jingcheng Du,  Fang Li,  Yong Chen,  Cui Tao",
                "发布日期": "2022-11-30",
                "摘要": "  To date, there are no effective treatments for most neurodegenerative\ndiseases. Knowledge graphs can provide comprehensive and semantic\nrepresentation for heterogeneous data, and have been successfully leveraged in\nmany biomedical applications including drug repurposing. Our objective is to\nconstruct a knowledge graph from literature to study relations between\nAlzheimer's disease (AD) and chemicals, drugs and dietary supplements in order\nto identify opportunities to prevent or delay neurodegenerative progression. We\ncollected biomedical annotations and extracted their relations using SemRep via\nSemMedDB. We used both a BERT-based classifier and rule-based methods during\ndata preprocessing to exclude noise while preserving most AD-related semantic\ntriples. The 1,672,110 filtered triples were used to train with knowledge graph\ncompletion algorithms (i.e., TransE, DistMult, and ComplEx) to predict\ncandidates that might be helpful for AD treatment or prevention. Among three\nknowledge graph completion models, TransE outperformed the other two (MR =\n13.45, Hits@1 = 0.306). We leveraged the time-slicing technique to further\nevaluate the prediction results. We found supporting evidence for most highly\nranked candidates predicted by our model which indicates that our approach can\ninform reliable new knowledge. This paper shows that our graph mining model can\npredict reliable new relationships between AD and other entities (i.e., dietary\nsupplements, chemicals, and drugs). The knowledge graph constructed can\nfacilitate data-driven knowledge discoveries and the generation of novel\nhypotheses.\n",
                "链接": "https://arxiv.org/abs/2202.08712"
            },
            {
                "文章ID": "13672",
                "标题": "Beyond Separability: Analyzing the Linear Transferability of Contrastive\n  Representations to Related Subpopulations",
                "作者": " Jeff Z. HaoChen,  Colin Wei,  Ananya Kumar,  Tengyu Ma",
                "发布日期": "2022-05-25",
                "摘要": "  Contrastive learning is a highly effective method for learning\nrepresentations from unlabeled data. Recent works show that contrastive\nrepresentations can transfer across domains, leading to simple state-of-the-art\nalgorithms for unsupervised domain adaptation. In particular, a linear\nclassifier trained to separate the representations on the source domain can\nalso predict classes on the target domain accurately, even though the\nrepresentations of the two domains are far from each other. We refer to this\nphenomenon as linear transferability. This paper analyzes when and why\ncontrastive representations exhibit linear transferability in a general\nunsupervised domain adaptation setting. We prove that linear transferability\ncan occur when data from the same class in different domains (e.g., photo dogs\nand cartoon dogs) are more related with each other than data from different\nclasses in different domains (e.g., photo dogs and cartoon cats) are. Our\nanalyses are in a realistic regime where the source and target domains can have\nunbounded density ratios and be weakly related, and they have distant\nrepresentations across domains.\n",
                "链接": "https://arxiv.org/abs/2204.02683"
            },
            {
                "文章ID": "118106",
                "标题": "Student's Interests Related to Web and Mobile Technologies Study",
                "作者": " Manuela Petrescu,  Adrian Sterca,  Ioan Badarinza",
                "发布日期": "2023-11-28",
                "摘要": "  We explore in this paper the interests and challenges of students regarding\nweb and mobile technologies. Our study is based on a survey among undergraduate\nstudents, students that attend a Web Programming course. In particular, we\nstudy the challenges students have in following a successful career in web or\nmobile development and we have found that the most important one is the large\neffort required for keeping up to date with the fast changing web and mobile\ntechnologies. Overall, the attitude of the surveyed undergraduate students\ntowards web development and mobile development is rather positive, as more than\n60% of them said that they are interested in a career in web or mobile\ndevelopment. We also found out that most of them prefer working on back-end web\ntechnologies. As for the specific web technologies students are interested on,\nthey are highly varied. Overall, our study provides valuable insights into the\ninterests and challenges of students regarding web and mobile technologies,\nwhich can guide the development of effective teaching and learning approaches\nin this area.\n",
                "链接": "https://arxiv.org/abs/2311.15293"
            },
            {
                "文章ID": "59915",
                "标题": "Understanding metric-related pitfalls in image analysis validation",
                "作者": " Annika Reinke,  Minu D. Tizabi,  Michael Baumgartner,  Matthias Eisenmann,  Doreen Heckmann-Nötzel,  A. Emre Kavur,  Tim Rädsch,  Carole H. Sudre,  Laura Acion,  Michela Antonelli,  Tal Arbel,  Spyridon Bakas,  Arriel Benis,  Matthew Blaschko,  Florian Buettner,  M. Jorge Cardoso,  Veronika Cheplygina,  Jianxu Chen,  Evangelia Christodoulou,  Beth A. Cimini,  Gary S. Collins,  Keyvan Farahani,  Luciana Ferrer,  Adrian Galdran,  Bram van Ginneken,  Ben Glocker,  Patrick Godau,  Robert Haase,  Daniel A. Hashimoto,  Michael M. Hoffman,  Merel Huisman,  Fabian Isensee,  Pierre Jannin,  Charles E. Kahn,  Dagmar Kainmueller,  Bernhard Kainz,  Alexandros Karargyris,  Alan Karthikesalingam,  Hannes Kenngott,  Jens Kleesiek,  Florian Kofler,  Thijs Kooi,  Annette Kopp-Schneider,  Michal Kozubek,  Anna Kreshuk,  Tahsin Kurc,  Bennett A. Landman,  Geert Litjens,  Amin Madani,  Klaus Maier-Hein,  Anne L. Martel,  Peter Mattson,  Erik Meijering,  Bjoern Menze,  Karel G. M. Moons,  Henning Müller,  Brennan Nichyporuk,  Felix Nickel,  Jens Petersen,  Susanne M. Rafelski,  Nasir Rajpoot,  Mauricio Reyes,  Michael A. Riegler,  Nicola Rieke,  Julio Saez-Rodriguez,  Clara I. Sánchez,  Shravya Shetty,  Maarten van Smeden,  Ronald M. Summers,  Abdel A. Taha,  Aleksei Tiulpin,  Sotirios A. Tsaftaris,  Ben Van Calster,  Gaël Varoquaux,  Manuel Wiesenfarth,  Ziv R. Yaniv,  Paul F. Jäger,  Lena Maier-Hein",
                "发布日期": "2023-12-08",
                "摘要": "  Validation metrics are key for the reliable tracking of scientific progress\nand for bridging the current chasm between artificial intelligence (AI)\nresearch and its translation into practice. However, increasing evidence shows\nthat particularly in image analysis, metrics are often chosen inadequately in\nrelation to the underlying research problem. This could be attributed to a lack\nof accessibility of metric-related knowledge: While taking into account the\nindividual strengths, weaknesses, and limitations of validation metrics is a\ncritical prerequisite to making educated choices, the relevant knowledge is\ncurrently scattered and poorly accessible to individual researchers. Based on a\nmulti-stage Delphi process conducted by a multidisciplinary expert consortium\nas well as extensive community feedback, the present work provides the first\nreliable and comprehensive common point of access to information on pitfalls\nrelated to validation metrics in image analysis. Focusing on biomedical image\nanalysis but with the potential of transfer to other fields, the addressed\npitfalls generalize across application domains and are categorized according to\na newly created, domain-agnostic taxonomy. To facilitate comprehension,\nillustrations and specific examples accompany each pitfall. As a structured\nbody of information accessible to researchers of all levels of expertise, this\nwork enhances global comprehension of a key topic in image analysis validation.\n",
                "链接": "https://arxiv.org/abs/2302.01790"
            },
            {
                "文章ID": "121615",
                "标题": "Team-related Features in Code Review Prediction Models",
                "作者": " Eduardo Witter,  Ingrid Nunes,  Dietmar Jannach",
                "发布日期": "2023-12-12",
                "摘要": "  Modern Code Review (MCR) is an informal tool-assisted quality assurance\npractice. It relies on the asynchronous communication among the authors of code\nchanges and reviewers, who are developers that provide feedback. However, from\ncandidate developers, some are able to provide better feedback than others\ngiven a particular context. The selection of reviewers is thus an important\ntask, which can benefit from automated support. Many approaches have been\nproposed in this direction, using for example data from code review\nrepositories to recommend reviewers. In this paper, we propose the use of\nteam-related features to improve the performance of predictions that are\nhelpful to build code reviewer recommenders, with our target predictions being\nthe identification of reviewers that would participate in a review and the\nprovided amount of feedback. We evaluate the prediction power of these\nfeatures, which are related to code ownership, workload, and team relationship.\nThis evaluation was done by carefully addressing challenges imposed by the MCR\ndomain, such as temporal aspects of the dataset and unbalanced classes.\nMoreover, given that it is currently unknown how much past data is needed for\nbuilding MCR prediction models with acceptable performance, we explore the\namount of past data used to build prediction models. Our results show that,\nindividually, features related to code ownership have the best prediction\npower. However, based on feature selection, we conclude that all proposed\nfeatures together with lines of code can make the best predictions for both\nreviewer participation and amount of feedback. Regarding the amount of past\ndata, the timeframes of 3, 6, 9, and 12 months of data produce similar results.\nTherefore, models can be trained considering short timeframes, thus reducing\nthe computational costs with negligible impact in the prediction performance\n...\n",
                "链接": "https://arxiv.org/abs/2312.06244"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于gpt4自动生成prompt的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "106864",
                "标题": "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language\n  Models",
                "作者": " Xiaogeng Liu,  Nan Xu,  Muhao Chen,  Chaowei Xiao",
                "发布日期": "2023-10-10",
                "摘要": "  The aligned Large Language Models (LLMs) are powerful language understanding\nand decision-making tools that are created through extensive alignment with\nhuman feedback. However, these large models remain susceptible to jailbreak\nattacks, where adversaries manipulate prompts to elicit malicious outputs that\nshould not be given by aligned LLMs. Investigating jailbreak prompts can lead\nus to delve into the limitations of LLMs and further guide us to secure them.\nUnfortunately, existing jailbreak techniques suffer from either (1) scalability\nissues, where attacks heavily rely on manual crafting of prompts, or (2)\nstealthiness problems, as attacks depend on token-based algorithms to generate\nprompts that are often semantically meaningless, making them susceptible to\ndetection through basic perplexity testing. In light of these challenges, we\nintend to answer this question: Can we develop an approach that can\nautomatically generate stealthy jailbreak prompts? In this paper, we introduce\nAutoDAN, a novel jailbreak attack against aligned LLMs. AutoDAN can\nautomatically generate stealthy jailbreak prompts by the carefully designed\nhierarchical genetic algorithm. Extensive evaluations demonstrate that AutoDAN\nnot only automates the process while preserving semantic meaningfulness, but\nalso demonstrates superior attack strength in cross-model transferability, and\ncross-sample universality compared with the baseline. Moreover, we also compare\nAutoDAN with perplexity-based defense methods and show that AutoDAN can bypass\nthem effectively.\n",
                "链接": "https://arxiv.org/abs/2310.04451"
            },
            {
                "文章ID": "74190",
                "标题": "CitePrompt: Using Prompts to Identify Citation Intent in Scientific\n  Papers",
                "作者": " Avishek Lahiri,  Debarshi Kumar Sanyal,  Imon Mukherjee",
                "发布日期": "2023-05-04",
                "摘要": "  Citations in scientific papers not only help us trace the intellectual\nlineage but also are a useful indicator of the scientific significance of the\nwork. Citation intents prove beneficial as they specify the role of the\ncitation in a given context. In this paper, we present CitePrompt, a framework\nwhich uses the hitherto unexplored approach of prompt-based learning for\ncitation intent classification. We argue that with the proper choice of the\npretrained language model, the prompt template, and the prompt verbalizer, we\ncan not only get results that are better than or comparable to those obtained\nwith the state-of-the-art methods but also do it with much less exterior\ninformation about the scientific document. We report state-of-the-art results\non the ACL-ARC dataset, and also show significant improvement on the SciCite\ndataset over all baseline models except one. As suitably large labelled\ndatasets for citation intent classification can be quite hard to find, in a\nfirst, we propose the conversion of this task to the few-shot and zero-shot\nsettings. For the ACL-ARC dataset, we report a 53.86% F1 score for the\nzero-shot setting, which improves to 63.61% and 66.99% for the 5-shot and\n10-shot settings, respectively.\n",
                "链接": "https://arxiv.org/abs/2304.12730"
            },
            {
                "文章ID": "123546",
                "标题": "Assessing GPT4-V on Structured Reasoning Tasks",
                "作者": " Mukul Singh,  José Cambronero,  Sumit Gulwani,  Vu Le,  Gust Verbruggen",
                "发布日期": "2023-12-20",
                "摘要": "  Multi-modality promises to unlock further uses for large language models.\nRecently, the state-of-the-art language model GPT-4 was enhanced with vision\ncapabilities. We carry out a prompting evaluation of GPT-4V and five other\nbaselines on structured reasoning tasks, such as mathematical reasoning, visual\ndata analysis, and code generation. We show that visual Chain-of-Thought, an\nextension of Chain-of-Thought to multi-modal LLMs, yields significant\nimprovements over the vanilla model. We also present a categorized analysis of\nscenarios where these models perform well and where they struggle, highlighting\nchallenges associated with coherent multimodal reasoning.\n",
                "链接": "https://arxiv.org/abs/2312.11524"
            },
            {
                "文章ID": "38716",
                "标题": "Best Prompts for Text-to-Image Models and How to Find Them",
                "作者": " Nikita Pavlichenko,  Dmitry Ustalov",
                "发布日期": "2023-06-05",
                "摘要": "  Recent progress in generative models, especially in text-guided diffusion\nmodels, has enabled the production of aesthetically-pleasing imagery resembling\nthe works of professional human artists. However, one has to carefully compose\nthe textual description, called the prompt, and augment it with a set of\nclarifying keywords. Since aesthetics are challenging to evaluate\ncomputationally, human feedback is needed to determine the optimal prompt\nformulation and keyword combination. In this paper, we present a\nhuman-in-the-loop approach to learning the most useful combination of prompt\nkeywords using a genetic algorithm. We also show how such an approach can\nimprove the aesthetic appeal of images depicting the same descriptions.\n",
                "链接": "https://arxiv.org/abs/2209.11711"
            },
            {
                "文章ID": "17780",
                "标题": "Go Back in Time: Generating Flashbacks in Stories with Event Temporal\n  Prompts",
                "作者": " Rujun Han,  Hong Chen,  Yufei Tian,  Nanyun Peng",
                "发布日期": "2022-05-05",
                "摘要": "  Stories or narratives are comprised of a sequence of events. To compose\ninteresting stories, professional writers often leverage a creative writing\ntechnique called flashback that inserts past events into current storylines as\nwe commonly observe in novels and plays. However, it is challenging for\nmachines to generate flashback as it requires a solid understanding of event\ntemporal order (e.g. \"feeling hungry\" before \"eat,\" not vice versa), and the\ncreativity to arrange storylines so that earlier events do not always appear\nfirst in narrative order. Two major issues in existing systems that exacerbate\nthe challenges: 1) temporal bias in pertaining and story datasets that leads to\nmonotonic event temporal orders; 2) lack of explicit guidance that helps\nmachines decide where to insert flashbacks. We propose to address these issues\nusing structured storylines to encode events and their pair-wise temporal\nrelations (before, after and vague) as temporal prompts that guide how stories\nshould unfold temporally. We leverage a Plan-and-Write framework enhanced by\nreinforcement learning to generate storylines and stories end-to-end.\nEvaluation results show that the proposed method can generate more interesting\nstories with flashbacks while maintaining textual diversity, fluency, and\ntemporal coherence.\n",
                "链接": "https://arxiv.org/abs/2205.01898"
            },
            {
                "文章ID": "60822",
                "标题": "Generating a Structured Summary of Numerous Academic Papers: Dataset and\n  Method",
                "作者": " Shuaiqi Liu,  Jiannong Cao,  Ruosong Yang,  Zhiyuan Wen",
                "发布日期": "2023-02-10",
                "摘要": "  Writing a survey paper on one research topic usually needs to cover the\nsalient content from numerous related papers, which can be modeled as a\nmulti-document summarization (MDS) task. Existing MDS datasets usually focus on\nproducing the structureless summary covering a few input documents. Meanwhile,\nprevious structured summary generation works focus on summarizing a single\ndocument into a multi-section summary. These existing datasets and methods\ncannot meet the requirements of summarizing numerous academic papers into a\nstructured summary. To deal with the scarcity of available data, we propose\nBigSurvey, the first large-scale dataset for generating comprehensive summaries\nof numerous academic papers on each topic. We collect target summaries from\nmore than seven thousand survey papers and utilize their 430 thousand reference\npapers' abstracts as input documents. To organize the diverse content from\ndozens of input documents and ensure the efficiency of processing long text\nsequences, we propose a summarization method named category-based alignment and\nsparse transformer (CAST). The experimental results show that our CAST method\noutperforms various advanced summarization methods.\n",
                "链接": "https://arxiv.org/abs/2302.04580"
            },
            {
                "文章ID": "109030",
                "标题": "A Search for Prompts: Generating Structured Answers from Contracts",
                "作者": " Adam Roegiest,  Radha Chitta,  Jonathan Donnelly,  Maya Lash,  Alexandra Vtyurina,  François Longtin",
                "发布日期": "2023-10-17",
                "摘要": "  In many legal processes being able to action on the concrete implication of a\nlegal question can be valuable to automating human review or signalling certain\nconditions (e.g., alerts around automatic renewal). To support such tasks, we\npresent a form of legal question answering that seeks to return one (or more)\nfixed answers for a question about a contract clause. After showing that\nunstructured generative question answering can have questionable outcomes for\nsuch a task, we discuss our exploration methodology for legal question\nanswering prompts using OpenAI's \\textit{GPT-3.5-Turbo} and provide a summary\nof insights.\n  Using insights gleaned from our qualitative experiences, we compare our\nproposed template prompts against a common semantic matching approach and find\nthat our prompt templates are far more accurate despite being less reliable in\nthe exact response return. With some additional tweaks to prompts and the use\nof in-context learning, we are able to further improve the performance of our\nproposed strategy while maximizing the reliability of responses as best we can.\n",
                "链接": "https://arxiv.org/abs/2310.10141"
            },
            {
                "文章ID": "103106",
                "标题": "Is GPT4 a Good Trader?",
                "作者": " Bingzhe Wu",
                "发布日期": "2023-09-21",
                "摘要": "  Recently, large language models (LLMs), particularly GPT-4, have demonstrated\nsignificant capabilities in various planning and reasoning tasks\n\\cite{cheng2023gpt4,bubeck2023sparks}. Motivated by these advancements, there\nhas been a surge of interest among researchers to harness the capabilities of\nGPT-4 for the automated design of quantitative factors that do not overlap with\nexisting factor libraries, with an aspiration to achieve alpha returns\n\\cite{webpagequant}. In contrast to these work, this study aims to examine the\nfidelity of GPT-4's comprehension of classic trading theories and its\nproficiency in applying its code interpreter abilities to real-world trading\ndata analysis. Such an exploration is instrumental in discerning whether the\nunderlying logic GPT-4 employs for trading is intrinsically reliable.\nFurthermore, given the acknowledged interpretative latitude inherent in most\ntrading theories, we seek to distill more precise methodologies of deploying\nthese theories from GPT-4's analytical process, potentially offering invaluable\ninsights to human traders.\n  To achieve this objective, we selected daily candlestick (K-line) data from\nspecific periods for certain assets, such as the Shanghai Stock Index. Through\nmeticulous prompt engineering, we guided GPT-4 to analyze the technical\nstructures embedded within this data, based on specific theories like the\nElliott Wave Theory. We then subjected its analytical output to manual\nevaluation, assessing its interpretative depth and accuracy vis-\\`a-vis these\ntrading theories from multiple dimensions. The results and findings from this\nstudy could pave the way for a synergistic amalgamation of human expertise and\nAI-driven insights in the realm of trading.\n",
                "链接": "https://arxiv.org/abs/2309.10982"
            },
            {
                "文章ID": "103691",
                "标题": "OpenAi's GPT4 as coding assistant",
                "作者": " Lefteris Moussiades,  George Zografos",
                "发布日期": "2023-09-25",
                "摘要": "  Lately, Large Language Models have been widely used in code generation. GPT4\nis considered the most potent Large Language Model from Openai. In this paper,\nwe examine GPT3.5 and GPT4 as coding assistants. More specifically, we have\nconstructed appropriate tests to check whether the two systems can a) answer\ntypical questions that can arise during the code development, b) produce\nreliable code, and c) contribute to code debugging. The test results are\nimpressive. The performance of GPT4 is outstanding and signals an increase in\nthe productivity of programmers and the reorganization of software development\nprocedures based on these new tools.\n",
                "链接": "https://arxiv.org/abs/2309.12732"
            },
            {
                "文章ID": "120162",
                "标题": "Generating Action-conditioned Prompts for Open-vocabulary Video Action\n  Recognition",
                "作者": " Chengyou Jia,  Minnan Luo,  Xiaojun Chang,  Zhuohang Dang,  Mingfei Han,  Mengmeng Wang,  Guang Dai,  Sizhe Dang,  Jingdong Wang",
                "发布日期": "2023-12-06",
                "摘要": "  Exploring open-vocabulary video action recognition is a promising venture,\nwhich aims to recognize previously unseen actions within any arbitrary set of\ncategories. Existing methods typically adapt pretrained image-text models to\nthe video domain, capitalizing on their inherent strengths in generalization. A\ncommon thread among such methods is the augmentation of visual embeddings with\ntemporal information to improve the recognition of seen actions. Yet, they\ncompromise with standard less-informative action descriptions, thus faltering\nwhen confronted with novel actions. Drawing inspiration from human cognitive\nprocesses, we argue that augmenting text embeddings with human prior knowledge\nis pivotal for open-vocabulary video action recognition. To realize this, we\ninnovatively blend video models with Large Language Models (LLMs) to devise\nAction-conditioned Prompts. Specifically, we harness the knowledge in LLMs to\nproduce a set of descriptive sentences that contain distinctive features for\nidentifying given actions. Building upon this foundation, we further introduce\na multi-modal action knowledge alignment mechanism to align concepts in video\nand textual knowledge encapsulated within the prompts. Extensive experiments on\nvarious video benchmarks, including zero-shot, few-shot, and base-to-novel\ngeneralization settings, demonstrate that our method not only sets new SOTA\nperformance but also possesses excellent interpretability.\n",
                "链接": "https://arxiv.org/abs/2312.02226"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态agent, 具身智能的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "65134",
                "标题": "Can an Embodied Agent Find Your \"Cat-shaped Mug\"? LLM-Guided Exploration\n  for Zero-Shot Object Navigation",
                "作者": " Vishnu Sashank Dorbala, Jr. James F. Mullen,  Dinesh Manocha",
                "发布日期": "2023-11-07",
                "摘要": "  We present LGX (Language-guided Exploration), a novel algorithm for\nLanguage-Driven Zero-Shot Object Goal Navigation (L-ZSON), where an embodied\nagent navigates to a uniquely described target object in a previously unseen\nenvironment. Our approach makes use of Large Language Models (LLMs) for this\ntask by leveraging the LLM's commonsense reasoning capabilities for making\nsequential navigational decisions. Simultaneously, we perform generalized\ntarget object detection using a pre-trained Vision-Language grounding model. We\nachieve state-of-the-art zero-shot object navigation results on RoboTHOR with a\nsuccess rate (SR) improvement of over 27% over the current baseline of the\nOWL-ViT CLIP on Wheels (OWL CoW). Furthermore, we study the usage of LLMs for\nrobot navigation and present an analysis of various prompting strategies\naffecting the model output. Finally, we showcase the benefits of our approach\nvia \\textit{real-world} experiments that indicate the superior performance of\nLGX in detecting and navigating to visually unique objects.\n",
                "链接": "https://arxiv.org/abs/2303.03480"
            },
            {
                "文章ID": "93106",
                "标题": "Heterogeneous Embodied Multi-Agent Collaboration",
                "作者": " Xinzhu Liu,  Di Guo,  Huaping Liu",
                "发布日期": "2023-07-28",
                "摘要": "  Multi-agent embodied tasks have recently been studied in complex indoor\nvisual environments. Collaboration among multiple agents can improve work\nefficiency and has significant practical value. However, most of the existing\nresearch focuses on homogeneous multi-agent tasks. Compared with homogeneous\nagents, heterogeneous agents can leverage their different capabilities to\nallocate corresponding sub-tasks and cooperate to complete complex tasks.\nHeterogeneous multi-agent tasks are common in real-world scenarios, and the\ncollaboration strategy among heterogeneous agents is a challenging and\nimportant problem to be solved. To study collaboration among heterogeneous\nagents, we propose the heterogeneous multi-agent tidying-up task, in which\nmultiple heterogeneous agents with different capabilities collaborate with each\nother to detect misplaced objects and place them in reasonable locations. This\nis a demanding task since it requires agents to make the best use of their\ndifferent capabilities to conduct reasonable task planning and complete the\nwhole task. To solve this task, we build a heterogeneous multi-agent tidying-up\nbenchmark dataset in a large number of houses with multiple rooms based on\nProcTHOR-10K. We propose the hierarchical decision model based on misplaced\nobject detection, reasonable receptacle prediction, as well as the\nhandshake-based group communication mechanism. Extensive experiments are\nconducted to demonstrate the effectiveness of the proposed model. The project's\nwebsite and videos of experiments can be found at https://hetercol.github.io/.\n",
                "链接": "https://arxiv.org/abs/2307.13957"
            },
            {
                "文章ID": "93062",
                "标题": "MAEA: Multimodal Attribution for Embodied AI",
                "作者": " Vidhi Jain,  Jayant Sravan Tamarapalli,  Sahiti Yerramilli,  Yonatan Bisk",
                "发布日期": "2023-07-27",
                "摘要": "  Understanding multimodal perception for embodied AI is an open question\nbecause such inputs may contain highly complementary as well as redundant\ninformation for the task. A relevant direction for multimodal policies is\nunderstanding the global trends of each modality at the fusion layer. To this\nend, we disentangle the attributions for visual, language, and previous action\ninputs across different policies trained on the ALFRED dataset. Attribution\nanalysis can be utilized to rank and group the failure scenarios, investigate\nmodeling and dataset biases, and critically analyze multimodal EAI policies for\nrobustness and user trust before deployment. We present MAEA, a framework to\ncompute global attributions per modality of any differentiable policy. In\naddition, we show how attributions enable lower-level behavior analysis in EAI\npolicies for language and visual attributions.\n",
                "链接": "https://arxiv.org/abs/2307.13850"
            },
            {
                "文章ID": "51062",
                "标题": "Instance-Specific Image Goal Navigation: Training Embodied Agents to\n  Find Object Instances",
                "作者": " Jacob Krantz,  Stefan Lee,  Jitendra Malik,  Dhruv Batra,  Devendra Singh Chaplot",
                "发布日期": "2022-11-30",
                "摘要": "  We consider the problem of embodied visual navigation given an image-goal\n(ImageNav) where an agent is initialized in an unfamiliar environment and\ntasked with navigating to a location 'described' by an image. Unlike related\nnavigation tasks, ImageNav does not have a standardized task definition which\nmakes comparison across methods difficult. Further, existing formulations have\ntwo problematic properties; (1) image-goals are sampled from random locations\nwhich can lead to ambiguity (e.g., looking at walls), and (2) image-goals match\nthe camera specification and embodiment of the agent; this rigidity is limiting\nwhen considering user-driven downstream applications. We present the\nInstance-specific ImageNav task (InstanceImageNav) to address these\nlimitations. Specifically, the goal image is 'focused' on some particular\nobject instance in the scene and is taken with camera parameters independent of\nthe agent. We instantiate InstanceImageNav in the Habitat Simulator using\nscenes from the Habitat-Matterport3D dataset (HM3D) and release a standardized\nbenchmark to measure community progress.\n",
                "链接": "https://arxiv.org/abs/2211.15876"
            },
            {
                "文章ID": "71754",
                "标题": "If consciousness is dynamically relevant, artificial intelligence isn't\n  conscious",
                "作者": " Johannes Kleiner,  Tim Ludwig",
                "发布日期": "2023-11-13",
                "摘要": "  We demonstrate that if consciousness is relevant for the temporal evolution\nof a system's states--that is, if it is dynamically relevant--then AI systems\ncannot be conscious. That is because AI systems run on CPUs, GPUs, TPUs or\nother processors which have been designed and verified to adhere to\ncomputational dynamics that systematically preclude or suppress deviations. The\ndesign and verification preclude or suppress, in particular, potential\nconsciousness-related dynamical effects, so that if consciousness is\ndynamically relevant, AI systems cannot be conscious.\n",
                "链接": "https://arxiv.org/abs/2304.05077"
            },
            {
                "文章ID": "117303",
                "标题": "An Embodied Generalist Agent in 3D World",
                "作者": " Jiangyong Huang,  Silong Yong,  Xiaojian Ma,  Xiongkun Linghu,  Puhao Li,  Yan Wang,  Qing Li,  Song-Chun Zhu,  Baoxiong Jia,  Siyuan Huang",
                "发布日期": "2023-11-23",
                "摘要": "  Leveraging massive knowledge and learning schemes from large language models\n(LLMs), recent machine learning models show notable successes in building\ngeneralist agents that exhibit the capability of general-purpose task solving\nin diverse domains, including natural language processing, computer vision, and\nrobotics. However, a significant challenge remains as these models exhibit\nlimited ability in understanding and interacting with the 3D world. We argue\nthis limitation significantly hinders the current models from performing\nreal-world tasks and further achieving general intelligence. To this end, we\nintroduce an embodied multi-modal and multi-task generalist agent that excels\nin perceiving, grounding, reasoning, planning, and acting in the 3D world. Our\nproposed agent, referred to as LEO, is trained with shared LLM-based model\narchitectures, objectives, and weights in two stages: (i) 3D vision-language\nalignment and (ii) 3D vision-language-action instruction tuning. To facilitate\nthe training, we meticulously curate and generate an extensive dataset\ncomprising object-level and scene-level multi-modal tasks with exceeding scale\nand complexity, necessitating a deep understanding of and interaction with the\n3D world. Through rigorous experiments, we demonstrate LEO's remarkable\nproficiency across a wide spectrum of tasks, including 3D captioning, question\nanswering, embodied reasoning, embodied navigation, and robotic manipulation.\nOur ablation results further provide valuable insights for the development of\nfuture embodied generalist agents.\n",
                "链接": "https://arxiv.org/abs/2311.12871"
            },
            {
                "文章ID": "2627",
                "标题": "A Method to Predict Semantic Relations on Artificial Intelligence Papers",
                "作者": " Francisco Andrades,  Ricardo Ñanculef",
                "发布日期": "2022-01-26",
                "摘要": "  Predicting the emergence of links in large evolving networks is a difficult\ntask with many practical applications. Recently, the Science4cast competition\nhas illustrated this challenge presenting a network of 64.000 AI concepts and\nasking the participants to predict which topics are going to be researched\ntogether in the future. In this paper, we present a solution to this problem\nbased on a new family of deep learning approaches, namely Graph Neural\nNetworks. The results of the challenge show that our solution is competitive\neven if we had to impose severe restrictions to obtain a computationally\nefficient and parsimonious model: ignoring the intrinsic dynamics of the graph\nand using only a small subset of the nodes surrounding a target link.\nPreliminary experiments presented in this paper suggest the model is learning\ntwo related, but different patterns: the absorption of a node by a sub-graph\nand union of more dense sub-graphs. The model seems to excel at recognizing the\nfirst type of pattern.\n",
                "链接": "https://arxiv.org/abs/2201.10518"
            },
            {
                "文章ID": "44810",
                "标题": "Embodied, Situated, and Grounded Intelligence: Implications for AI",
                "作者": " Tyler Millhouse,  Melanie Moses,  Melanie Mitchell",
                "发布日期": "2022-10-26",
                "摘要": "  In April of 2022, the Santa Fe Institute hosted a workshop on embodied,\nsituated, and grounded intelligence as part of the Institute's Foundations of\nIntelligence project. The workshop brought together computer scientists,\npsychologists, philosophers, social scientists, and others to discuss the\nscience of embodiment and related issues in human intelligence, and its\nimplications for building robust, human-level AI. In this report, we summarize\neach of the talks and the subsequent discussions. We also draw out a number of\nkey themes and identify important frontiers for future research.\n",
                "链接": "https://arxiv.org/abs/2210.13589"
            },
            {
                "文章ID": "65105",
                "标题": "PaLM-E: An Embodied Multimodal Language Model",
                "作者": " Danny Driess,  Fei Xia,  Mehdi S. M. Sajjadi,  Corey Lynch,  Aakanksha Chowdhery,  Brian Ichter,  Ayzaan Wahid,  Jonathan Tompson,  Quan Vuong,  Tianhe Yu,  Wenlong Huang,  Yevgen Chebotar,  Pierre Sermanet,  Daniel Duckworth,  Sergey Levine,  Vincent Vanhoucke,  Karol Hausman,  Marc Toussaint,  Klaus Greff,  Andy Zeng,  Igor Mordatch,  Pete Florence",
                "发布日期": "2023-03-07",
                "摘要": "  Large language models excel at a wide range of complex tasks. However,\nenabling general inference in the real world, e.g., for robotics problems,\nraises the challenge of grounding. We propose embodied language models to\ndirectly incorporate real-world continuous sensor modalities into language\nmodels and thereby establish the link between words and percepts. Input to our\nembodied language model are multi-modal sentences that interleave visual,\ncontinuous state estimation, and textual input encodings. We train these\nencodings end-to-end, in conjunction with a pre-trained large language model,\nfor multiple embodied tasks including sequential robotic manipulation planning,\nvisual question answering, and captioning. Our evaluations show that PaLM-E, a\nsingle large embodied multimodal model, can address a variety of embodied\nreasoning tasks, from a variety of observation modalities, on multiple\nembodiments, and further, exhibits positive transfer: the model benefits from\ndiverse joint training across internet-scale language, vision, and\nvisual-language domains. Our largest model, PaLM-E-562B with 562B parameters,\nin addition to being trained on robotics tasks, is a visual-language generalist\nwith state-of-the-art performance on OK-VQA, and retains generalist language\ncapabilities with increasing scale.\n",
                "链接": "https://arxiv.org/abs/2303.03378"
            },
            {
                "文章ID": "116268",
                "标题": "RED-DOT: Multimodal Fact-checking via Relevant Evidence Detection",
                "作者": " Stefanos-Iordanis Papadopoulos,  Christos Koutlis,  Symeon Papadopoulos,  Panagiotis C. Petrantonakis",
                "发布日期": "2023-11-17",
                "摘要": "  Online misinformation is often multimodal in nature, i.e., it is caused by\nmisleading associations between texts and accompanying images. To support the\nfact-checking process, researchers have been recently developing automatic\nmultimodal methods that gather and analyze external information, evidence,\nrelated to the image-text pairs under examination. However, prior works assumed\nall collected evidence to be relevant. In this study, we introduce a \"Relevant\nEvidence Detection\" (RED) module to discern whether each piece of evidence is\nrelevant, to support or refute the claim. Specifically, we develop the\n\"Relevant Evidence Detection Directed Transformer\" (RED-DOT) and explore\nmultiple architectural variants (e.g., single or dual-stage) and mechanisms\n(e.g., \"guided attention\"). Extensive ablation and comparative experiments\ndemonstrate that RED-DOT achieves significant improvements over the\nstate-of-the-art on the VERITE benchmark by up to 28.5%. Furthermore, our\nevidence re-ranking and element-wise modality fusion led to RED-DOT achieving\ncompetitive and even improved performance on NewsCLIPings+, without the need\nfor numerous evidence or multiple backbone encoders. Finally, our qualitative\nanalysis demonstrates that the proposed \"guided attention\" module has the\npotential to enhance the architecture's interpretability. We release our code\nat: https://github.com/stevejpapad/relevant-evidence-detection\n",
                "链接": "https://arxiv.org/abs/2311.09939"
            }
        ]
    },
    {
        "question": {
            "question": "新的大模型结构相关探索的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "47291",
                "标题": "Exploration of Convolutional Neural Network Architectures for Large\n  Region Map Automation",
                "作者": " R. M. Tsenov,  C. J. Henry,  J. L. Storie,  C. D. Storie,  B. Murray,  M. Sokolov",
                "发布日期": "2023-03-16",
                "摘要": "  Deep learning semantic segmentation algorithms have provided improved\nframeworks for the automated production of Land-Use and Land-Cover (LULC) maps,\nwhich significantly increases the frequency of map generation as well as\nconsistency of production quality. In this research, a total of 28 different\nmodel variations were examined to improve the accuracy of LULC maps. The\nexperiments were carried out using Landsat 5/7 or Landsat 8 satellite images\nwith the North American Land Change Monitoring System labels. The performance\nof various CNNs and extension combinations were assessed, where VGGNet with an\noutput stride of 4, and modified U-Net architecture provided the best results.\nAdditional expanded analysis of the generated LULC maps was also provided.\nUsing a deep neural network, this work achieved 92.4% accuracy for 13 LULC\nclasses within southern Manitoba representing a 15.8% improvement over\npublished results for the NALCMS. Based on the large regions of interest,\nhigher radiometric resolution of Landsat 8 data resulted in better overall\naccuracies (88.04%) compare to Landsat 5/7 (80.66%) for 16 LULC classes. This\nrepresents an 11.44% and 4.06% increase in overall accuracy compared to\npreviously published NALCMS results, including larger land area and higher\nnumber of LULC classes incorporated into the models compared to other published\nLULC map automation methods.\n",
                "链接": "https://arxiv.org/abs/2211.03854"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "71982",
                "标题": "DartsReNet: Exploring new RNN cells in ReNet architectures",
                "作者": " Brian Moser,  Federico Raue,  Jörn Hees,  Andreas Dengel",
                "发布日期": "2023-04-13",
                "摘要": "  We present new Recurrent Neural Network (RNN) cells for image classification\nusing a Neural Architecture Search (NAS) approach called DARTS. We are\ninterested in the ReNet architecture, which is a RNN based approach presented\nas an alternative for convolutional and pooling steps. ReNet can be defined\nusing any standard RNN cells, such as LSTM and GRU. One limitation is that\nstandard RNN cells were designed for one dimensional sequential data and not\nfor two dimensions like it is the case for image classification. We overcome\nthis limitation by using DARTS to find new cell designs. We compare our results\nwith ReNet that uses GRU and LSTM cells. Our found cells outperform the\nstandard RNN cells on CIFAR-10 and SVHN. The improvements on SVHN indicate\ngeneralizability, as we derived the RNN cell designs from CIFAR-10 without\nperforming a new cell search for SVHN.\n",
                "链接": "https://arxiv.org/abs/2304.05838"
            },
            {
                "文章ID": "18762",
                "标题": "Recommending Research Papers to Chemists: A Specialized Interface for\n  Chemical Entity Exploration",
                "作者": " Corinna Breitinger,  Kay Herklotz,  Tim Flegelskamp,  Norman Meuschke",
                "发布日期": "2022-05-12",
                "摘要": "  Researchers and scientists increasingly rely on specialized information\nretrieval (IR) or recommendation systems (RS) to support them in their daily\nresearch tasks. Paper recommender systems are one such tool scientists use to\nstay on top of the ever-increasing number of academic publications in their\nfield. Improving research paper recommender systems is an active research\nfield. However, less research has focused on how the interfaces of research\npaper recommender systems can be tailored to suit the needs of different\nresearch domains. For example, in the field of biomedicine and chemistry,\nresearchers are not only interested in textual relevance but may also want to\ndiscover or compare the contained chemical entity information found in a\npaper's full text. Existing recommender systems for academic literature do not\nsupport the discovery of this non-textual, but semantically valuable, chemical\nentity data. We present the first implementation of a specialized chemistry\npaper recommender system capable of visualizing the contained chemical\nstructures, chemical formulae, and synonyms for chemical compounds within the\ndocument's full text. We review existing tools and related research in this\nfield before describing the implementation of our ChemVis system. With the help\nof chemists, we are expanding the functionality of ChemVis, and will perform an\nevaluation of recommendation performance and usability in future work.\n",
                "链接": "https://arxiv.org/abs/2205.05414"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "105692",
                "标题": "Large Language Model-Powered Smart Contract Vulnerability Detection: New\n  Perspectives",
                "作者": " Sihao Hu,  Tiansheng Huang,  Fatih İlhan,  Selim Furkan Tekin,  Ling Liu",
                "发布日期": "2023-10-18",
                "摘要": "  This paper provides a systematic analysis of the opportunities, challenges,\nand potential solutions of harnessing Large Language Models (LLMs) such as\nGPT-4 to dig out vulnerabilities within smart contracts based on our ongoing\nresearch. For the task of smart contract vulnerability detection, achieving\npractical usability hinges on identifying as many true vulnerabilities as\npossible while minimizing the number of false positives. Nonetheless, our\nempirical study reveals contradictory yet interesting findings: generating more\nanswers with higher randomness largely boosts the likelihood of producing a\ncorrect answer but inevitably leads to a higher number of false positives. To\nmitigate this tension, we propose an adversarial framework dubbed GPTLens that\nbreaks the conventional one-stage detection into two synergistic stages $-$\ngeneration and discrimination, for progressive detection and refinement,\nwherein the LLM plays dual roles, i.e., auditor and critic, respectively. The\ngoal of auditor is to yield a broad spectrum of vulnerabilities with the hope\nof encompassing the correct answer, whereas the goal of critic that evaluates\nthe validity of identified vulnerabilities is to minimize the number of false\npositives. Experimental results and illustrative examples demonstrate that\nauditor and critic work together harmoniously to yield pronounced improvements\nover the conventional one-stage detection. GPTLens is intuitive, strategic, and\nentirely LLM-driven without relying on specialist expertise in smart contracts,\nshowcasing its methodical generality and potential to detect a broad spectrum\nof vulnerabilities. Our code is available at:\nhttps://github.com/git-disl/GPTLens.\n",
                "链接": "https://arxiv.org/abs/2310.01152"
            },
            {
                "文章ID": "69949",
                "标题": "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language\n  Model Society",
                "作者": " Guohao Li,  Hasan Abed Al Kader Hammoud,  Hani Itani,  Dmitrii Khizbullin,  Bernard Ghanem",
                "发布日期": "2023-11-03",
                "摘要": "  The rapid advancement of chat-based language models has led to remarkable\nprogress in complex task-solving. However, their success heavily relies on\nhuman input to guide the conversation, which can be challenging and\ntime-consuming. This paper explores the potential of building scalable\ntechniques to facilitate autonomous cooperation among communicative agents, and\nprovides insight into their \"cognitive\" processes. To address the challenges of\nachieving autonomous cooperation, we propose a novel communicative agent\nframework named role-playing. Our approach involves using inception prompting\nto guide chat agents toward task completion while maintaining consistency with\nhuman intentions. We showcase how role-playing can be used to generate\nconversational data for studying the behaviors and capabilities of a society of\nagents, providing a valuable resource for investigating conversational language\nmodels. In particular, we conduct comprehensive studies on\ninstruction-following cooperation in multi-agent settings. Our contributions\ninclude introducing a novel communicative agent framework, offering a scalable\napproach for studying the cooperative behaviors and capabilities of multi-agent\nsystems, and open-sourcing our library to support research on communicative\nagents and beyond: https://github.com/camel-ai/camel.\n",
                "链接": "https://arxiv.org/abs/2303.17760"
            },
            {
                "文章ID": "78789",
                "标题": "PANNA 2.0: Efficient neural network interatomic potentials and new\n  architectures",
                "作者": " Franco Pellegrini,  Ruggero Lot,  Yusuf Shaidu,  Emine Küçükbenli",
                "发布日期": "2023-05-22",
                "摘要": "  We present the latest release of PANNA 2.0 (Properties from Artificial Neural\nNetwork Architectures), a code for the generation of neural network interatomic\npotentials based on local atomic descriptors and multilayer perceptrons. Built\non a new back end, this new release of PANNA features improved tools for\ncustomizing and monitoring network training, better GPU support including a\nfast descriptor calculator, new plugins for external codes and a new\narchitecture for the inclusion of long-range electrostatic interactions through\na variational charge equilibration scheme. We present an overview of the main\nfeatures of the new code, and several benchmarks comparing the accuracy of\nPANNA models to the state of the art, on commonly used benchmarks as well as\nricher datasets.\n",
                "链接": "https://arxiv.org/abs/2305.11805"
            },
            {
                "文章ID": "103034",
                "标题": "Interactive Distillation of Large Single-Topic Corpora of Scientific\n  Papers",
                "作者": " Nicholas Solovyev,  Ryan Barron,  Manish Bhattarai,  Maksim E. Eren,  Kim O. Rasmussen,  Boian S. Alexandrov",
                "发布日期": "2023-09-20",
                "摘要": "  Highly specific datasets of scientific literature are important for both\nresearch and education. However, it is difficult to build such datasets at\nscale. A common approach is to build these datasets reductively by applying\ntopic modeling on an established corpus and selecting specific topics. A more\nrobust but time-consuming approach is to build the dataset constructively in\nwhich a subject matter expert (SME) handpicks documents. This method does not\nscale and is prone to error as the dataset grows. Here we showcase a new tool,\nbased on machine learning, for constructively generating targeted datasets of\nscientific literature. Given a small initial \"core\" corpus of papers, we build\na citation network of documents. At each step of the citation network, we\ngenerate text embeddings and visualize the embeddings through dimensionality\nreduction. Papers are kept in the dataset if they are \"similar\" to the core or\nare otherwise pruned through human-in-the-loop selection. Additional insight\ninto the papers is gained through sub-topic modeling using SeNMFk. We\ndemonstrate our new tool for literature review by applying it to two different\nfields in machine learning.\n",
                "链接": "https://arxiv.org/abs/2309.10772"
            }
        ]
    },
    {
        "question": {
            "question": "多模态细粒度图片编辑和生成相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "124621",
                "标题": "FineMoGen: Fine-Grained Spatio-Temporal Motion Generation and Editing",
                "作者": " Mingyuan Zhang,  Huirong Li,  Zhongang Cai,  Jiawei Ren,  Lei Yang,  Ziwei Liu",
                "发布日期": "2023-12-27",
                "摘要": "  Text-driven motion generation has achieved substantial progress with the\nemergence of diffusion models. However, existing methods still struggle to\ngenerate complex motion sequences that correspond to fine-grained descriptions,\ndepicting detailed and accurate spatio-temporal actions. This lack of fine\ncontrollability limits the usage of motion generation to a larger audience. To\ntackle these challenges, we present FineMoGen, a diffusion-based motion\ngeneration and editing framework that can synthesize fine-grained motions, with\nspatial-temporal composition to the user instructions. Specifically, FineMoGen\nbuilds upon diffusion model with a novel transformer architecture dubbed\nSpatio-Temporal Mixture Attention (SAMI). SAMI optimizes the generation of the\nglobal attention template from two perspectives: 1) explicitly modeling the\nconstraints of spatio-temporal composition; and 2) utilizing sparsely-activated\nmixture-of-experts to adaptively extract fine-grained features. To facilitate a\nlarge-scale study on this new fine-grained motion generation task, we\ncontribute the HuMMan-MoGen dataset, which consists of 2,968 videos and 102,336\nfine-grained spatio-temporal descriptions. Extensive experiments validate that\nFineMoGen exhibits superior motion generation quality over state-of-the-art\nmethods. Notably, FineMoGen further enables zero-shot motion editing\ncapabilities with the aid of modern large language models (LLM), which\nfaithfully manipulates motion sequences with fine-grained instructions. Project\nPage: https://mingyuan-zhang.github.io/projects/FineMoGen.html\n",
                "链接": "https://arxiv.org/abs/2312.15004"
            },
            {
                "文章ID": "13260",
                "标题": "Flexible Portrait Image Editing with Fine-Grained Control",
                "作者": " Linlin Liu,  Qian Fu,  Fei Hou,  Ying He",
                "发布日期": "2022-04-05",
                "摘要": "  We develop a new method for portrait image editing, which supports\nfine-grained editing of geometries, colors, lights and shadows using a single\nneural network model. We adopt a novel asymmetric conditional GAN architecture:\nthe generators take the transformed conditional inputs, such as edge maps,\ncolor palette, sliders and masks, that can be directly edited by the user; the\ndiscriminators take the conditional inputs in the way that can guide\ncontrollable image generation more effectively. Taking color editing as an\nexample, we feed color palettes (which can be edited easily) into the\ngenerator, and color maps (which contain positional information of colors) into\nthe discriminator. We also design a region-weighted discriminator so that\nhigher weights are assigned to more important regions, like eyes and skin.\nUsing a color palette, the user can directly specify the desired colors of\nhair, skin, eyes, lip and background. Color sliders allow the user to blend\ncolors in an intuitive manner. The user can also edit lights and shadows by\nmodifying the corresponding masks. We demonstrate the effectiveness of our\nmethod by evaluating it on the CelebAMask-HQ dataset with a wide range of\ntasks, including geometry/color/shadow/light editing, hand-drawn sketch to\nimage translation, and color transfer. We also present ablation studies to\njustify our design.\n",
                "链接": "https://arxiv.org/abs/2204.01318"
            },
            {
                "文章ID": "52126",
                "标题": "Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models",
                "作者": " Naoki Matsunaga,  Masato Ishii,  Akio Hayakawa,  Kenji Suzuki,  Takuya Narihira",
                "发布日期": "2023-06-01",
                "摘要": "  Our goal is to develop fine-grained real-image editing methods suitable for\nreal-world applications. In this paper, we first summarize four requirements\nfor these methods and propose a novel diffusion-based image editing framework\nwith pixel-wise guidance that satisfies these requirements. Specifically, we\ntrain pixel-classifiers with a few annotated data and then infer the\nsegmentation map of a target image. Users then manipulate the map to instruct\nhow the image will be edited. We utilize a pre-trained diffusion model to\ngenerate edited images aligned with the user's intention with pixel-wise\nguidance. The effective combination of proposed guidance and other techniques\nenables highly controllable editing with preserving the outside of the edited\narea, which results in meeting our requirements. The experimental results\ndemonstrate that our proposal outperforms the GAN-based method for editing\nquality and speed.\n",
                "链接": "https://arxiv.org/abs/2212.02024"
            },
            {
                "文章ID": "123024",
                "标题": "Focus on Your Instruction: Fine-grained and Multi-instruction Image\n  Editing by Attention Modulation",
                "作者": " Qin Guo,  Tianwei Lin",
                "发布日期": "2023-12-19",
                "摘要": "  Recently, diffusion-based methods, like InstructPix2Pix (IP2P), have achieved\neffective instruction-based image editing, requiring only natural language\ninstructions from the user. However, these methods often inadvertently alter\nunintended areas and struggle with multi-instruction editing, resulting in\ncompromised outcomes. To address these issues, we introduce the Focus on Your\nInstruction (FoI), a method designed to ensure precise and harmonious editing\nacross multiple instructions without extra training or test-time optimization.\nIn the FoI, we primarily emphasize two aspects: (1) precisely extracting\nregions of interest for each instruction and (2) guiding the denoising process\nto concentrate within these regions of interest. For the first objective, we\nidentify the implicit grounding capability of IP2P from the cross-attention\nbetween instruction and image, then develop an effective mask extraction\nmethod. For the second objective, we introduce a cross attention modulation\nmodule for rough isolation of target editing regions and unrelated regions.\nAdditionally, we introduce a mask-guided disentangle sampling strategy to\nfurther ensure clear region isolation. Experimental results demonstrate that\nFoI surpasses existing methods in both quantitative and qualitative\nevaluations, especially excelling in multi-instruction editing task.\n",
                "链接": "https://arxiv.org/abs/2312.10113"
            },
            {
                "文章ID": "124901",
                "标题": "SERF: Fine-Grained Interactive 3D Segmentation and Editing with Radiance\n  Fields",
                "作者": " Kaichen Zhou,  Lanqing Hong,  Enze Xie,  Yongxin Yang,  Zhenguo Li,  Wei Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Although significant progress has been made in the field of 2D-based\ninteractive editing, fine-grained 3D-based interactive editing remains\nrelatively unexplored. This limitation can be attributed to two main\nchallenges: the lack of an efficient 3D representation robust to different\nmodifications and the absence of an effective 3D interactive segmentation\nmethod. In this paper, we introduce a novel fine-grained interactive 3D\nsegmentation and editing algorithm with radiance fields, which we refer to as\nSERF. Our method entails creating a neural mesh representation by integrating\nmulti-view algorithms with pre-trained 2D models. Building upon this\nrepresentation, we introduce a novel surface rendering technique that preserves\nlocal information and is robust to deformation. Moreover, this representation\nforms the basis for achieving accurate and interactive 3D segmentation without\nrequiring 3D supervision. Harnessing this representation facilitates a range of\ninteractive 3D editing operations, encompassing tasks such as interactive\ngeometry editing and texture painting. Extensive experiments and visualization\nexamples of editing on both real and synthetic data demonstrate the superiority\nof our method on representation quality and editing ability.\n",
                "链接": "https://arxiv.org/abs/2312.15856"
            },
            {
                "文章ID": "96626",
                "标题": "DragNUWA: Fine-grained Control in Video Generation by Integrating Text,\n  Image, and Trajectory",
                "作者": " Shengming Yin,  Chenfei Wu,  Jian Liang,  Jie Shi,  Houqiang Li,  Gong Ming,  Nan Duan",
                "发布日期": "2023-08-17",
                "摘要": "  Controllable video generation has gained significant attention in recent\nyears. However, two main limitations persist: Firstly, most existing works\nfocus on either text, image, or trajectory-based control, leading to an\ninability to achieve fine-grained control in videos. Secondly, trajectory\ncontrol research is still in its early stages, with most experiments being\nconducted on simple datasets like Human3.6M. This constraint limits the models'\ncapability to process open-domain images and effectively handle complex curved\ntrajectories. In this paper, we propose DragNUWA, an open-domain\ndiffusion-based video generation model. To tackle the issue of insufficient\ncontrol granularity in existing works, we simultaneously introduce text, image,\nand trajectory information to provide fine-grained control over video content\nfrom semantic, spatial, and temporal perspectives. To resolve the problem of\nlimited open-domain trajectory control in current research, We propose\ntrajectory modeling with three aspects: a Trajectory Sampler (TS) to enable\nopen-domain control of arbitrary trajectories, a Multiscale Fusion (MF) to\ncontrol trajectories in different granularities, and an Adaptive Training (AT)\nstrategy to generate consistent videos following trajectories. Our experiments\nvalidate the effectiveness of DragNUWA, demonstrating its superior performance\nin fine-grained control in video generation. The homepage link is\n\\url{https://www.microsoft.com/en-us/research/project/dragnuwa/}\n",
                "链接": "https://arxiv.org/abs/2308.08089"
            },
            {
                "文章ID": "117252",
                "标题": "A Fine-Grained Image Description Generation Method Based on Joint\n  Objectives",
                "作者": " Yifan Zhang,  Chunzhen Lin,  Donglin Cao,  Dazhen Lin",
                "发布日期": "2023-11-23",
                "摘要": "  The goal of fine-grained image description generation techniques is to learn\ndetailed information from images and simulate human-like descriptions that\nprovide coherent and comprehensive textual details about the image content.\nCurrently, most of these methods face two main challenges: description\nrepetition and omission. Moreover, the existing evaluation metrics cannot\nclearly reflect the performance of models on these two issues. To address these\nchallenges, we propose an innovative Fine-grained Image Description Generation\nmodel based on Joint Objectives. Furthermore, we introduce new object-based\nevaluation metrics to more intuitively assess the model's performance in\nhandling description repetition and omission. This novel approach combines\nvisual features at both the image level and object level to maximize their\nadvantages and incorporates an object penalty mechanism to reduce description\nrepetition. Experimental results demonstrate that our proposed method\nsignificantly improves the CIDEr evaluation metric, indicating its excellent\nperformance in addressing description repetition and omission issues.\n",
                "链接": "https://arxiv.org/abs/2311.12799"
            },
            {
                "文章ID": "122275",
                "标题": "Fine-Grained Image-Text Alignment in Medical Imaging Enables Cyclic\n  Image-Report Generation",
                "作者": " Wenting Chen,  Linlin Shen,  Xiang Li,  Yixuan Yuan",
                "发布日期": "2023-12-29",
                "摘要": "  To address these issues, we propose a novel Adaptive patch-word Matching\n(AdaMatch) model to correlate chest X-ray (CXR) image regions with words in\nmedical reports and apply it to CXR-report generation to provide explainability\nfor the generation process. AdaMatch exploits the fine-grained relation between\nadaptive patches and words to provide explanations of specific image regions\nwith corresponding words. To capture the abnormal regions of varying sizes and\npositions, we introduce the Adaptive Patch extraction (AdaPatch) module to\nacquire the adaptive patches for these regions adaptively. In order to provide\nexplicit explainability for CXR-report generation task, we propose an\nAdaMatch-based bidirectional large language model for Cyclic CXR-report\ngeneration (AdaMatch-Cyclic). It employs the AdaMatch to obtain the keywords\nfor CXR images and `keypatches' for medical reports as hints to guide\nCXR-report generation. Extensive experiments on two publicly available CXR\ndatasets prove the effectiveness of our method and its superior performance to\nexisting methods.\n",
                "链接": "https://arxiv.org/abs/2312.08078"
            },
            {
                "文章ID": "69760",
                "标题": "Hierarchical Fine-Grained Image Forgery Detection and Localization",
                "作者": " Xiao Guo,  Xiaohong Liu,  Zhiyuan Ren,  Steven Grosz,  Iacopo Masi,  Xiaoming Liu",
                "发布日期": "2023-03-31",
                "摘要": "  Differences in forgery attributes of images generated in CNN-synthesized and\nimage-editing domains are large, and such differences make a unified image\nforgery detection and localization (IFDL) challenging. To this end, we present\na hierarchical fine-grained formulation for IFDL representation learning.\nSpecifically, we first represent forgery attributes of a manipulated image with\nmultiple labels at different levels. Then we perform fine-grained\nclassification at these levels using the hierarchical dependency between them.\nAs a result, the algorithm is encouraged to learn both comprehensive features\nand inherent hierarchical nature of different forgery attributes, thereby\nimproving the IFDL representation. Our proposed IFDL framework contains three\ncomponents: multi-branch feature extractor, localization and classification\nmodules. Each branch of the feature extractor learns to classify forgery\nattributes at one level, while localization and classification modules segment\nthe pixel-level forgery region and detect image-level forgery, respectively.\nLastly, we construct a hierarchical fine-grained dataset to facilitate our\nstudy. We demonstrate the effectiveness of our method on $7$ different\nbenchmarks, for both tasks of IFDL and forgery attribute classification. Our\nsource code and dataset can be found:\n\\href{https://github.com/CHELSEA234/HiFi_IFDL}{github.com/CHELSEA234/HiFi-IFDL}.\n",
                "链接": "https://arxiv.org/abs/2303.17111"
            },
            {
                "文章ID": "40110",
                "标题": "Fine-grained Contrastive Learning for Definition Generation",
                "作者": " Hengyuan Zhang,  Dawei Li,  Shiping Yang,  Yanran Li",
                "发布日期": "2022-10-04",
                "摘要": "  Recently, pre-trained transformer-based models have achieved great success in\nthe task of definition generation (DG). However, previous encoder-decoder\nmodels lack effective representation learning to contain full semantic\ncomponents of the given word, which leads to generating under-specific\ndefinitions. To address this problem, we propose a novel contrastive learning\nmethod, encouraging the model to capture more detailed semantic representations\nfrom the definition sequence encoding. According to both automatic and manual\nevaluation, the experimental results on three mainstream benchmarks demonstrate\nthat the proposed method could generate more specific and high-quality\ndefinitions compared with several state-of-the-art models.\n",
                "链接": "https://arxiv.org/abs/2210.00543"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找风格化机器翻译相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "83081",
                "标题": "Text Style Transfer Back-Translation",
                "作者": " Daimeng Wei,  Zhanglin Wu,  Hengchao Shang,  Zongyao Li,  Minghan Wang,  Jiaxin Guo,  Xiaoyu Chen,  Zhengzhe Yu,  Hao Yang",
                "发布日期": "2023-06-05",
                "摘要": "  Back Translation (BT) is widely used in the field of machine translation, as\nit has been proved effective for enhancing translation quality. However, BT\nmainly improves the translation of inputs that share a similar style (to be\nmore specific, translation-like inputs), since the source side of BT data is\nmachine-translated. For natural inputs, BT brings only slight improvements and\nsometimes even adverse effects. To address this issue, we propose Text Style\nTransfer Back Translation (TST BT), which uses a style transfer model to modify\nthe source side of BT data. By making the style of source-side text more\nnatural, we aim to improve the translation of natural inputs. Our experiments\non various language pairs, including both high-resource and low-resource ones,\ndemonstrate that TST BT significantly improves translation performance against\npopular BT benchmarks. In addition, TST BT is proved to be effective in domain\nadaptation so this strategy can be regarded as a general data augmentation\nmethod. Our training code and text style transfer model are open-sourced.\n",
                "链接": "https://arxiv.org/abs/2306.01318"
            },
            {
                "文章ID": "7091",
                "标题": "Screening Gender Transfer in Neural Machine Translation",
                "作者": " Guillaume Wisniewski,  Lichao Zhu,  Nicolas Ballier,  François Yvon",
                "发布日期": "2022-02-28",
                "摘要": "  This paper aims at identifying the information flow in state-of-the-art\nmachine translation systems, taking as example the transfer of gender when\ntranslating from French into English. Using a controlled set of examples, we\nexperiment several ways to investigate how gender information circulates in a\nencoder-decoder architecture considering both probing techniques as well as\ninterventions on the internal representations used in the MT system. Our\nresults show that gender information can be found in all token representations\nbuilt by the encoder and the decoder and lead us to conclude that there are\nmultiple pathways for gender transfer.\n",
                "链接": "https://arxiv.org/abs/2202.12568"
            },
            {
                "文章ID": "101979",
                "标题": "Speech-to-Speech Translation with Discrete-Unit-Based Style Transfer",
                "作者": " Yongqi Wang,  Jionghao Bai,  Rongjie Huang,  Ruiqi Li,  Zhiqing Hong,  Zhou Zhao",
                "发布日期": "2023-09-15",
                "摘要": "  Direct speech-to-speech translation (S2ST) with discrete self-supervised\nrepresentations has achieved remarkable accuracy, but is unable to preserve the\nspeaker timbre of the source speech during translation. Meanwhile, the scarcity\nof high-quality speaker-parallel data poses a challenge for learning style\ntransfer between source and target speech. We propose an S2ST framework with an\nacoustic language model based on discrete units from a self-supervised model\nand a neural codec for style transfer. The acoustic language model leverages\nself-supervised in-context learning, acquiring the ability for style transfer\nwithout relying on any speaker-parallel data, thereby overcoming the issue of\ndata scarcity. By using extensive training data, our model achieves zero-shot\ncross-lingual style transfer on previously unseen source languages. Experiments\nshow that our model generates translated speeches with high fidelity and style\nsimilarity. Audio samples are available at http://stylelm.github.io/ .\n",
                "链接": "https://arxiv.org/abs/2309.07566"
            },
            {
                "文章ID": "521",
                "标题": "Consistent Style Transfer",
                "作者": " Xuan Luo,  Zhen Han,  Lingkang Yang,  Lingling Zhang",
                "发布日期": "2022-01-10",
                "摘要": "  Recently, attentional arbitrary style transfer methods have been proposed to\nachieve fine-grained results, which manipulates the point-wise similarity\nbetween content and style features for stylization. However, the attention\nmechanism based on feature points ignores the feature multi-manifold\ndistribution, where each feature manifold corresponds to a semantic region in\nthe image. Consequently, a uniform content semantic region is rendered by\nhighly different patterns from various style semantic regions, producing\ninconsistent stylization results with visual artifacts. We proposed the\nprogressive attentional manifold alignment (PAMA) to alleviate this problem,\nwhich repeatedly applies attention operations and space-aware interpolations.\nThe attention operation rearranges style features dynamically according to the\nspatial distribution of content features. This makes the content and style\nmanifolds correspond on the feature map. Then the space-aware interpolation\nadaptively interpolates between the corresponding content and style manifolds\nto increase their similarity. By gradually aligning the content manifolds to\nstyle manifolds, the proposed PAMA achieves state-of-the-art performance while\navoiding the inconsistency of semantic regions. Codes are available at\nhttps://github.com/computer-vision2022/PAMA.\n",
                "链接": "https://arxiv.org/abs/2201.02233"
            },
            {
                "文章ID": "78691",
                "标题": "Viewing Knowledge Transfer in Multilingual Machine Translation Through a\n  Representational Lens",
                "作者": " David Stap,  Vlad Niculae,  Christof Monz",
                "发布日期": "2023-12-05",
                "摘要": "  We argue that translation quality alone is not a sufficient metric for\nmeasuring knowledge transfer in multilingual neural machine translation. To\nsupport this claim, we introduce Representational Transfer Potential (RTP),\nwhich measures representational similarities between languages. We show that\nRTP can measure both positive and negative transfer (interference), and find\nthat RTP is strongly correlated with changes in translation quality, indicating\nthat transfer does occur. Furthermore, we investigate data and language\ncharacteristics that are relevant for transfer, and find that multi-parallel\noverlap is an important yet under-explored feature. Based on this, we develop a\nnovel training scheme, which uses an auxiliary similarity loss that encourages\nrepresentations to be more invariant across languages by taking advantage of\nmulti-parallel data. We show that our method yields increased translation\nquality for low- and mid-resource languages across multiple data and model\nsetups.\n",
                "链接": "https://arxiv.org/abs/2305.11550"
            },
            {
                "文章ID": "92370",
                "标题": "Incorporating Human Translator Style into English-Turkish Literary\n  Machine Translation",
                "作者": " Zeynep Yirmibeşoğlu,  Olgun Dursun,  Harun Dallı,  Mehmet Şahin,  Ena Hodzik,  Sabri Gürses,  Tunga Güngör",
                "发布日期": "2023-07-24",
                "摘要": "  Although machine translation systems are mostly designed to serve in the\ngeneral domain, there is a growing tendency to adapt these systems to other\ndomains like literary translation. In this paper, we focus on English-Turkish\nliterary translation and develop machine translation models that take into\naccount the stylistic features of translators. We fine-tune a pre-trained\nmachine translation model by the manually-aligned works of a particular\ntranslator. We make a detailed analysis of the effects of manual and automatic\nalignments, data augmentation methods, and corpus size on the translations. We\npropose an approach based on stylistic features to evaluate the style of a\ntranslator in the output translations. We show that the human translator style\ncan be highly recreated in the target machine translations by adapting the\nmodels to the style of the translator.\n",
                "链接": "https://arxiv.org/abs/2307.11457"
            },
            {
                "文章ID": "79369",
                "标题": "Decomposed Prompting for Machine Translation Between Related Languages\n  using Large Language Models",
                "作者": " Ratish Puduppully,  Anoop Kunchukuttan,  Raj Dabre,  Ai Ti Aw,  Nancy F. Chen",
                "发布日期": "2023-10-24",
                "摘要": "  This study investigates machine translation between related languages i.e.,\nlanguages within the same family that share linguistic characteristics such as\nword order and lexical similarity. Machine translation through few-shot\nprompting leverages a small set of translation pair examples to generate\ntranslations for test sentences. This procedure requires the model to learn how\nto generate translations while simultaneously ensuring that token ordering is\nmaintained to produce a fluent and accurate translation. We propose that for\nrelated languages, the task of machine translation can be simplified by\nleveraging the monotonic alignment characteristic of such languages. We\nintroduce DecoMT, a novel approach of few-shot prompting that decomposes the\ntranslation process into a sequence of word chunk translations. Through\nautomatic and human evaluation conducted on multiple related language pairs\nacross various language families, we demonstrate that our proposed approach of\ndecomposed prompting surpasses multiple established few-shot baseline\napproaches. For example, DecoMT outperforms the strong few-shot prompting BLOOM\nmodel with an average improvement of 8 chrF++ scores across the examined\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2305.13085"
            },
            {
                "文章ID": "11752",
                "标题": "Playing Lottery Tickets in Style Transfer Models",
                "作者": " Meihao Kong,  Jing Huo,  Wenbin Li,  Jing Wu,  Yu-Kun Lai,  Yang Gao",
                "发布日期": "2022-04-12",
                "摘要": "  Style transfer has achieved great success and attracted a wide range of\nattention from both academic and industrial communities due to its flexible\napplication scenarios. However, the dependence on a pretty large VGG-based\nautoencoder leads to existing style transfer models having high parameter\ncomplexities, which limits their applications on resource-constrained devices.\nCompared with many other tasks, the compression of style transfer models has\nbeen less explored. Recently, the lottery ticket hypothesis (LTH) has shown\ngreat potential in finding extremely sparse matching subnetworks which can\nachieve on par or even better performance than the original full networks when\ntrained in isolation. In this work, we for the first time perform an empirical\nstudy to verify whether such trainable matching subnetworks also exist in style\ntransfer models. Specifically, we take two most popular style transfer models,\ni.e., AdaIN and SANet, as the main testbeds, which represent global and local\ntransformation based style transfer methods respectively. We carry out\nextensive experiments and comprehensive analysis, and draw the following\nconclusions. (1) Compared with fixing the VGG encoder, style transfer models\ncan benefit more from training the whole network together. (2) Using iterative\nmagnitude pruning, we find the matching subnetworks at 89.2% sparsity in AdaIN\nand 73.7% sparsity in SANet, which demonstrates that style transfer models can\nplay lottery tickets too. (3) The feature transformation module should also be\npruned to obtain a much sparser model without affecting the existence and\nquality of the matching subnetworks. (4) Besides AdaIN and SANet, other models\nsuch as LST, MANet, AdaAttN and MCCNet can also play lottery tickets, which\nshows that LTH can be generalized to various style transfer models.\n",
                "链接": "https://arxiv.org/abs/2203.13802"
            },
            {
                "文章ID": "52773",
                "标题": "ConsistTL: Modeling Consistency in Transfer Learning for Low-Resource\n  Neural Machine Translation",
                "作者": " Zhaocong Li,  Xuebo Liu,  Derek F. Wong,  Lidia S. Chao,  Min Zhang",
                "发布日期": "2022-12-09",
                "摘要": "  Transfer learning is a simple and powerful method that can be used to boost\nmodel performance of low-resource neural machine translation (NMT). Existing\ntransfer learning methods for NMT are static, which simply transfer knowledge\nfrom a parent model to a child model once via parameter initialization. In this\npaper, we propose a novel transfer learning method for NMT, namely ConsistTL,\nwhich can continuously transfer knowledge from the parent model during the\ntraining of the child model. Specifically, for each training instance of the\nchild model, ConsistTL constructs the semantically-equivalent instance for the\nparent model and encourages prediction consistency between the parent and child\nfor this instance, which is equivalent to the child model learning each\ninstance under the guidance of the parent model. Experimental results on five\nlow-resource NMT tasks demonstrate that ConsistTL results in significant\nimprovements over strong transfer learning baselines, with a gain up to 1.7\nBLEU over the existing back-translation model on the widely-used WMT17\nTurkish-English benchmark. Further analysis reveals that ConsistTL can improve\nthe inference calibration of the child model. Code and scripts are freely\navailable at https://github.com/NLP2CT/ConsistTL.\n",
                "链接": "https://arxiv.org/abs/2212.04262"
            },
            {
                "文章ID": "10215",
                "标题": "Triangular Transfer: Freezing the Pivot for Triangular Machine\n  Translation",
                "作者": " Meng Zhang,  Liangyou Li,  Qun Liu",
                "发布日期": "2022-03-18",
                "摘要": "  Triangular machine translation is a special case of low-resource machine\ntranslation where the language pair of interest has limited parallel data, but\nboth languages have abundant parallel data with a pivot language. Naturally,\nthe key to triangular machine translation is the successful exploitation of\nsuch auxiliary data. In this work, we propose a transfer-learning-based\napproach that utilizes all types of auxiliary data. As we train auxiliary\nsource-pivot and pivot-target translation models, we initialize some parameters\nof the pivot side with a pre-trained language model and freeze them to\nencourage both translation models to work in the same pivot language space, so\nthat they can be smoothly transferred to the source-target translation model.\nExperiments show that our approach can outperform previous ones.\n",
                "链接": "https://arxiv.org/abs/2203.09027"
            }
        ]
    },
    {
        "question": {
            "question": "查找中文ner常用的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "35501",
                "标题": "Application of Data Encryption in Chinese Named Entity Recognition",
                "作者": " Kaifang Long,  Jikun Dong,  Shengyu Fan,  Yanfang Geng,  Yang Cao,  Han Zhao,  Hui Yu,  Weizhi Xu",
                "发布日期": "2022-09-01",
                "摘要": "  Recently, with the continuous development of deep learning, the performance\nof named entity recognition tasks has been dramatically improved. However, the\nprivacy and the confidentiality of data in some specific fields, such as\nbiomedical and military, cause insufficient data to support the training of\ndeep neural networks. In this paper, we propose an encryption learning\nframework to address the problems of data leakage and inconvenient disclosure\nof sensitive data in certain domains. We introduce multiple encryption\nalgorithms to encrypt training data in the named entity recognition task for\nthe first time. In other words, we train the deep neural network using the\nencrypted data. We conduct experiments on six Chinese datasets, three of which\nare constructed by ourselves. The experimental results show that the encryption\nmethod achieves satisfactory results. The performance of some models trained\nwith encrypted data even exceeds the performance of the unencrypted method,\nwhich verifies the effectiveness of the introduced encryption method and solves\nthe problem of data leakage to a certain extent.\n",
                "链接": "https://arxiv.org/abs/2208.14627"
            },
            {
                "文章ID": "5948",
                "标题": "AISHELL-NER: Named Entity Recognition from Chinese Speech",
                "作者": " Boli Chen,  Guangwei Xu,  Xiaobin Wang,  Pengjun Xie,  Meishan Zhang,  Fei Huang",
                "发布日期": "2022-02-18",
                "摘要": "  Named Entity Recognition (NER) from speech is among Spoken Language\nUnderstanding (SLU) tasks, aiming to extract semantic information from the\nspeech signal. NER from speech is usually made through a two-step pipeline that\nconsists of (1) processing the audio using an Automatic Speech Recognition\n(ASR) system and (2) applying an NER tagger to the ASR outputs. Recent works\nhave shown the capability of the End-to-End (E2E) approach for NER from English\nand French speech, which is essentially entity-aware ASR. However, due to the\nmany homophones and polyphones that exist in Chinese, NER from Chinese speech\nis effectively a more challenging task. In this paper, we introduce a new\ndataset AISEHLL-NER for NER from Chinese speech. Extensive experiments are\nconducted to explore the performance of several state-of-the-art methods. The\nresults demonstrate that the performance could be improved by combining\nentity-aware ASR and pretrained NER tagger, which can be easily applied to the\nmodern SLU pipeline. The dataset is publicly available at\ngithub.com/Alibaba-NLP/AISHELL-NER.\n",
                "链接": "https://arxiv.org/abs/2202.08533"
            },
            {
                "文章ID": "125250",
                "标题": "Unified Lattice Graph Fusion for Chinese Named Entity Recognition",
                "作者": " Dixiang Zhang,  Junyu Lu,  Pingjian Zhang",
                "发布日期": "2023-12-29",
                "摘要": "  Integrating lexicon into character-level sequence has been proven effective\nto leverage word boundary and semantic information in Chinese named entity\nrecognition (NER). However, prior approaches usually utilize feature weighting\nand position coupling to integrate word information, but ignore the semantic\nand contextual correspondence between the fine-grained semantic units in the\ncharacter-word space. To solve this issue, we propose a Unified Lattice Graph\nFusion (ULGF) approach for Chinese NER. ULGF can explicitly capture various\nsemantic and boundary relations across different semantic units with the\nadjacency matrix by converting the lattice structure into a unified graph. We\nstack multiple graph-based intra-source self-attention and inter-source\ncross-gating fusion layers that iteratively carry out semantic interactions to\nlearn node representations. To alleviate the over-reliance on word information,\nwe further propose to leverage lexicon entity classification as an auxiliary\ntask. Experiments on four Chinese NER benchmark datasets demonstrate the\nsuperiority of our ULGF approach.\n",
                "链接": "https://arxiv.org/abs/2312.16917"
            },
            {
                "文章ID": "18871",
                "标题": "NFLAT: Non-Flat-Lattice Transformer for Chinese Named Entity Recognition",
                "作者": " Shuang Wu,  Xiaoning Song,  Zhenhua Feng,  Xiao-Jun Wu",
                "发布日期": "2022-11-15",
                "摘要": "  Recently, Flat-LAttice Transformer (FLAT) has achieved great success in\nChinese Named Entity Recognition (NER). FLAT performs lexical enhancement by\nconstructing flat lattices, which mitigates the difficulties posed by blurred\nword boundaries and the lack of word semantics. In FLAT, the positions of\nstarting and ending characters are used to connect a matching word. However,\nthis method is likely to match more words when dealing with long texts,\nresulting in long input sequences. Therefore, it significantly increases the\nmemory and computational costs of the self-attention module. To deal with this\nissue, we advocate a novel lexical enhancement method, InterFormer, that\neffectively reduces the amount of computational and memory costs by\nconstructing non-flat lattices. Furthermore, with InterFormer as the backbone,\nwe implement NFLAT for Chinese NER. NFLAT decouples lexicon fusion and context\nfeature encoding. Compared with FLAT, it reduces unnecessary attention\ncalculations in \"word-character\" and \"word-word\". This reduces the memory usage\nby about 50% and can use more extensive lexicons or higher batches for network\ntraining. The experimental results obtained on several well-known benchmarks\ndemonstrate the superiority of the proposed method over the state-of-the-art\nhybrid (character-word) models.\n",
                "链接": "https://arxiv.org/abs/2205.05832"
            },
            {
                "文章ID": "44485",
                "标题": "Improving Chinese Named Entity Recognition by Search Engine Augmentation",
                "作者": " Qinghua Mao,  Jiatong Li,  Kui Meng",
                "发布日期": "2022-10-25",
                "摘要": "  Compared with English, Chinese suffers from more grammatical ambiguities,\nlike fuzzy word boundaries and polysemous words. In this case, contextual\ninformation is not sufficient to support Chinese named entity recognition\n(NER), especially for rare and emerging named entities. Semantic augmentation\nusing external knowledge is a potential way to alleviate this problem, while\nhow to obtain and leverage external knowledge for the NER task remains a\nchallenge. In this paper, we propose a neural-based approach to perform\nsemantic augmentation using external knowledge from search engine for Chinese\nNER. In particular, a multi-channel semantic fusion model is adopted to\ngenerate the augmented input representations, which aggregates external related\ntexts retrieved from the search engine. Experiments have shown the superiority\nof our model across 4 NER datasets, including formal and social media language\ncontexts, which further prove the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2210.12662"
            },
            {
                "文章ID": "28049",
                "标题": "Rethinking the Value of Gazetteer in Chinese Named Entity Recognition",
                "作者": " Qianglong Chen,  Xiangji Zeng,  Jiangang Zhu,  Yin Zhang,  Bojia Lin,  Yang Yang,  Daxin Jiang",
                "发布日期": "2022-07-19",
                "摘要": "  Gazetteer is widely used in Chinese named entity recognition (NER) to enhance\nspan boundary detection and type classification. However, to further understand\nthe generalizability and effectiveness of gazetteers, the NLP community still\nlacks a systematic analysis of the gazetteer-enhanced NER model. In this paper,\nwe first re-examine the effectiveness several common practices of the\ngazetteer-enhanced NER models and carry out a series of detailed analysis to\nevaluate the relationship between the model performance and the gazetteer\ncharacteristics, which can guide us to build a more suitable gazetteer. The\nfindings of this paper are as follows: (1) the gazetteer improves most of the\nsituations that the traditional NER model datasets are difficult to learn. (2)\nthe performance of model greatly benefits from the high-quality pre-trained\nlexeme embeddings. (3) a good gazetteer should cover more entities that can be\nmatched in both the training set and testing set.\n",
                "链接": "https://arxiv.org/abs/2207.02802"
            },
            {
                "文章ID": "33368",
                "标题": "Syntax-driven Data Augmentation for Named Entity Recognition",
                "作者": " Arie Pratama Sutiono,  Gus Hahn-Powell",
                "发布日期": "2022-10-04",
                "摘要": "  In low resource settings, data augmentation strategies are commonly leveraged\nto improve performance. Numerous approaches have attempted document-level\naugmentation (e.g., text classification), but few studies have explored\ntoken-level augmentation. Performed naively, data augmentation can produce\nsemantically incongruent and ungrammatical examples. In this work, we compare\nsimple masked language model replacement and an augmentation method using\nconstituency tree mutations to improve the performance of named entity\nrecognition in low-resource settings with the aim of preserving linguistic\ncohesion of the augmented sentences.\n",
                "链接": "https://arxiv.org/abs/2208.06957"
            },
            {
                "文章ID": "118177",
                "标题": "A Corpus for Named Entity Recognition in Chinese Novels with\n  Multi-genres",
                "作者": " Hanjie Zhao,  Jinge Xie,  Yuchen Yan,  Yuxiang Jia,  Yawen Ye,  Hongying Zan",
                "发布日期": "2023-11-28",
                "摘要": "  Entities like person, location, organization are important for literary text\nanalysis. The lack of annotated data hinders the progress of named entity\nrecognition (NER) in literary domain. To promote the research of literary NER,\nwe build the largest multi-genre literary NER corpus containing 263,135\nentities in 105,851 sentences from 260 online Chinese novels spanning 13\ndifferent genres. Based on the corpus, we investigate characteristics of\nentities from different genres. We propose several baseline NER models and\nconduct cross-genre and cross-domain experiments. Experimental results show\nthat genre difference significantly impact NER performance though not as much\nas domain difference like literary domain and news domain. Compared with NER in\nnews domain, literary NER still needs much improvement and the\nOut-of-Vocabulary (OOV) problem is more challenging due to the high variety of\nentities in literary works.\n",
                "链接": "https://arxiv.org/abs/2311.15509"
            },
            {
                "文章ID": "12159",
                "标题": "Federated Named Entity Recognition",
                "作者": " Joel Mathew,  Dimitris Stripelis,  José Luis Ambite",
                "发布日期": "2022-03-30",
                "摘要": "  We present an analysis of the performance of Federated Learning in a\nparadigmatic natural-language processing task: Named-Entity Recognition (NER).\nFor our evaluation, we use the language-independent CoNLL-2003 dataset as our\nbenchmark dataset and a Bi-LSTM-CRF model as our benchmark NER model. We show\nthat federated training reaches almost the same performance as the centralized\nmodel, though with some performance degradation as the learning environments\nbecome more heterogeneous. We also show the convergence rate of federated\nmodels for NER. Finally, we discuss existing challenges of Federated Learning\nfor NLP applications that can foster future research directions.\n",
                "链接": "https://arxiv.org/abs/2203.15101"
            },
            {
                "文章ID": "62584",
                "标题": "Dynamic Named Entity Recognition",
                "作者": " Tristan Luiggi,  Laure Soulier,  Vincent Guigue,  Siwar Jendoubi,  Aurélien Baelde",
                "发布日期": "2023-02-22",
                "摘要": "  Named Entity Recognition (NER) is a challenging and widely studied task that\ninvolves detecting and typing entities in text. So far,NER still approaches\nentity typing as a task of classification into universal classes (e.g. date,\nperson, or location). Recent advances innatural language processing focus on\narchitectures of increasing complexity that may lead to overfitting and\nmemorization, and thus, underuse of context. Our work targets situations where\nthe type of entities depends on the context and cannot be solved solely by\nmemorization. We hence introduce a new task: Dynamic Named Entity Recognition\n(DNER), providing a framework to better evaluate the ability of algorithms to\nextract entities by exploiting the context. The DNER benchmark is based on two\ndatasets, DNER-RotoWire and DNER-IMDb. We evaluate baseline models and present\nexperiments reflecting issues and research axes related to this novel task.\n",
                "链接": "https://arxiv.org/abs/2302.10314"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下最近用反事实做数据增强的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "81243",
                "标题": "Towards Visualization Thumbnail Designs that Entice Reading Data-driven\n  Articles",
                "作者": " Hwiyeon Kim,  Joohee Kim,  Yunha Han,  Hwajung Hong,  Oh-Sang Kwon,  Young-Woo Park,  Niklas Elmqvist,  Sungahn Ko,  Bum Chul Kwon",
                "发布日期": "2023-05-29",
                "摘要": "  As online news increasingly include data journalism, there is a corresponding\nincrease in the incorporation of visualization in article thumbnail images.\nHowever, little research exists on the design rationale for visualization\nthumbnails, such as resizing, cropping, simplifying, and embellishing charts\nthat appear within the body of the associated article. Therefore, in this paper\nwe aim to understand these design choices and determine what makes a\nvisualization thumbnail inviting and interpretable. To this end, we first\nsurvey visualization thumbnails collected online and discuss visualization\nthumbnail practices with data journalists and news graphics designers. Based on\nthe survey and discussion results, we then define a design space for\nvisualization thumbnails and conduct a user study with four types of\nvisualization thumbnails derived from the design space. The study results\nindicate that different chart components play different roles in attracting\nreader attention and enhancing reader understandability of the visualization\nthumbnails. We also find various thumbnail design strategies for effectively\ncombining the charts' components, such as a data summary with highlights and\ndata labels, and a visual legend with text labels and Human Recognizable\nObjects (HROs), into thumbnails. Ultimately, we distill our findings into\ndesign implications that allow effective visualization thumbnail designs for\ndata-rich news articles. Our work can thus be seen as a first step toward\nproviding structured guidance on how to design compelling thumbnails for data\nstories.\n",
                "链接": "https://arxiv.org/abs/2305.17051"
            },
            {
                "文章ID": "36857",
                "标题": "Bias Challenges in Counterfactual Data Augmentation",
                "作者": " S Chandra Mouli,  Yangze Zhou,  Bruno Ribeiro",
                "发布日期": "2022-09-15",
                "摘要": "  Deep learning models tend not to be out-of-distribution robust primarily due\nto their reliance on spurious features to solve the task. Counterfactual data\naugmentations provide a general way of (approximately) achieving\nrepresentations that are counterfactual-invariant to spurious features, a\nrequirement for out-of-distribution (OOD) robustness. In this work, we show\nthat counterfactual data augmentations may not achieve the desired\ncounterfactual-invariance if the augmentation is performed by a\ncontext-guessing machine, an abstract machine that guesses the most-likely\ncontext of a given input. We theoretically analyze the invariance imposed by\nsuch counterfactual data augmentations and describe an exemplar NLP task where\ncounterfactual data augmentation by a context-guessing machine does not lead to\nrobust OOD classifiers.\n",
                "链接": "https://arxiv.org/abs/2209.05104"
            },
            {
                "文章ID": "43960",
                "标题": "MoCoDA: Model-based Counterfactual Data Augmentation",
                "作者": " Silviu Pitis,  Elliot Creager,  Ajay Mandlekar,  Animesh Garg",
                "发布日期": "2022-10-21",
                "摘要": "  The number of states in a dynamic process is exponential in the number of\nobjects, making reinforcement learning (RL) difficult in complex, multi-object\ndomains. For agents to scale to the real world, they will need to react to and\nreason about unseen combinations of objects. We argue that the ability to\nrecognize and use local factorization in transition dynamics is a key element\nin unlocking the power of multi-object reasoning. To this end, we show that (1)\nknown local structure in the environment transitions is sufficient for an\nexponential reduction in the sample complexity of training a dynamics model,\nand (2) a locally factored dynamics model provably generalizes\nout-of-distribution to unseen states and actions. Knowing the local structure\nalso allows us to predict which unseen states and actions this dynamics model\nwill generalize to. We propose to leverage these observations in a novel\nModel-based Counterfactual Data Augmentation (MoCoDA) framework. MoCoDA applies\na learned locally factored dynamics model to an augmented distribution of\nstates and actions to generate counterfactual transitions for RL. MoCoDA works\nwith a broader set of local structures than prior work and allows for direct\ncontrol over the augmented training distribution. We show that MoCoDA enables\nRL agents to learn policies that generalize to unseen states and actions. We\nuse MoCoDA to train an offline RL agent to solve an out-of-distribution\nrobotics manipulation task on which standard offline RL algorithms fail.\n",
                "链接": "https://arxiv.org/abs/2210.11287"
            },
            {
                "文章ID": "81687",
                "标题": "On Counterfactual Data Augmentation Under Confounding",
                "作者": " Abbavaram Gowtham Reddy,  Saketh Bachu,  Saloni Dash,  Charchit Sharma,  Amit Sharma,  Vineeth N Balasubramanian",
                "发布日期": "2023-11-22",
                "摘要": "  Counterfactual data augmentation has recently emerged as a method to mitigate\nconfounding biases in the training data. These biases, such as spurious\ncorrelations, arise due to various observed and unobserved confounding\nvariables in the data generation process. In this paper, we formally analyze\nhow confounding biases impact downstream classifiers and present a causal\nviewpoint to the solutions based on counterfactual data augmentation. We\nexplore how removing confounding biases serves as a means to learn invariant\nfeatures, ultimately aiding in generalization beyond the observed data\ndistribution. Additionally, we present a straightforward yet powerful algorithm\nfor generating counterfactual images, which effectively mitigates the influence\nof confounding effects on downstream classifiers. Through experiments on MNIST\nvariants and the CelebA datasets, we demonstrate how our simple augmentation\nmethod helps existing state-of-the-art methods achieve good results.\n",
                "链接": "https://arxiv.org/abs/2305.18183"
            },
            {
                "文章ID": "114161",
                "标题": "Counterfactual Data Augmentation with Contrastive Learning",
                "作者": " Ahmed Aloui,  Juncheng Dong,  Cat P. Le,  Vahid Tarokh",
                "发布日期": "2023-11-08",
                "摘要": "  Statistical disparity between distinct treatment groups is one of the most\nsignificant challenges for estimating Conditional Average Treatment Effects\n(CATE). To address this, we introduce a model-agnostic data augmentation method\nthat imputes the counterfactual outcomes for a selected subset of individuals.\nSpecifically, we utilize contrastive learning to learn a representation space\nand a similarity measure such that in the learned representation space close\nindividuals identified by the learned similarity measure have similar potential\noutcomes. This property ensures reliable imputation of counterfactual outcomes\nfor the individuals with close neighbors from the alternative treatment group.\nBy augmenting the original dataset with these reliable imputations, we can\neffectively reduce the discrepancy between different treatment groups, while\ninducing minimal imputation error. The augmented dataset is subsequently\nemployed to train CATE estimation models. Theoretical analysis and experimental\nstudies on synthetic and semi-synthetic benchmarks demonstrate that our method\nachieves significant improvements in both performance and robustness to\noverfitting across state-of-the-art models.\n",
                "链接": "https://arxiv.org/abs/2311.03630"
            },
            {
                "文章ID": "67038",
                "标题": "Explaining Groups of Instances Counterfactually for XAI: A Use Case,\n  Algorithm and User Study for Group-Counterfactuals",
                "作者": " Greta Warren,  Mark T. Keane,  Christophe Gueret,  Eoin Delaney",
                "发布日期": "2023-03-17",
                "摘要": "  Counterfactual explanations are an increasingly popular form of post hoc\nexplanation due to their (i) applicability across problem domains, (ii)\nproposed legal compliance (e.g., with GDPR), and (iii) reliance on the\ncontrastive nature of human explanation. Although counterfactual explanations\nare normally used to explain individual predictive-instances, we explore a\nnovel use case in which groups of similar instances are explained in a\ncollective fashion using ``group counterfactuals'' (e.g., to highlight a\nrepeating pattern of illness in a group of patients). These group\ncounterfactuals meet a human preference for coherent, broad explanations\ncovering multiple events/instances. A novel, group-counterfactual algorithm is\nproposed to generate high-coverage explanations that are faithful to the\nto-be-explained model. This explanation strategy is also evaluated in a large,\ncontrolled user study (N=207), using objective (i.e., accuracy) and subjective\n(i.e., confidence, explanation satisfaction, and trust) psychological measures.\nThe results show that group counterfactuals elicit modest but definite\nimprovements in people's understanding of an AI system. The implications of\nthese findings for counterfactual methods and for XAI are discussed.\n",
                "链接": "https://arxiv.org/abs/2303.09297"
            },
            {
                "文章ID": "34843",
                "标题": "Data Augmentation for Graph Data: Recent Advancements",
                "作者": " Maria Marrium,  Arif Mahmood",
                "发布日期": "2022-08-26",
                "摘要": "  Graph Neural Network (GNNs) based methods have recently become a popular tool\nto deal with graph data because of their ability to incorporate structural\ninformation. The only hurdle in the performance of GNNs is the lack of labeled\ndata. Data Augmentation techniques for images and text data can not be used for\ngraph data because of the complex and non-euclidean structure of graph data.\nThis gap has forced researchers to shift their focus towards the development of\ndata augmentation techniques for graph data. Most of the proposed Graph Data\nAugmentation (GDA) techniques are task-specific. In this paper, we survey the\nexisting GDA techniques based on different graph tasks. This survey not only\nprovides a reference to the research community of GDA but also provides the\nnecessary information to the researchers of other domains.\n",
                "链接": "https://arxiv.org/abs/2208.11973"
            },
            {
                "文章ID": "21004",
                "标题": "Counterfactual Data Augmentation improves Factuality of Abstractive\n  Summarization",
                "作者": " Dheeraj Rajagopal,  Siamak Shakeri,  Cicero Nogueira dos Santos,  Eduard Hovy,  Chung-Ching Chang",
                "发布日期": "2022-05-26",
                "摘要": "  Abstractive summarization systems based on pretrained language models often\ngenerate coherent but factually inconsistent sentences. In this paper, we\npresent a counterfactual data augmentation approach where we augment data with\nperturbed summaries that increase the training data diversity. Specifically, we\npresent three augmentation approaches based on replacing (i) entities from\nother and the same category and (ii) nouns with their corresponding WordNet\nhypernyms. We show that augmenting the training data with our approach improves\nthe factual correctness of summaries without significantly affecting the ROUGE\nscore. We show that in two commonly used summarization datasets (CNN/Dailymail\nand XSum), we improve the factual correctness by about 2.5 points on average\n",
                "链接": "https://arxiv.org/abs/2205.12416"
            },
            {
                "文章ID": "74413",
                "标题": "Implicit Counterfactual Data Augmentation for Deep Neural Networks",
                "作者": " Xiaoling Zhou,  Ou Wu",
                "发布日期": "2023-04-27",
                "摘要": "  Machine-learning models are prone to capturing the spurious correlations\nbetween non-causal attributes and classes, with counterfactual data\naugmentation being a promising direction for breaking these spurious\nassociations. However, explicitly generating counterfactual data is\nchallenging, with the training efficiency declining. Therefore, this study\nproposes an implicit counterfactual data augmentation (ICDA) method to remove\nspurious correlations and make stable predictions. Specifically, first, a novel\nsample-wise augmentation strategy is developed that generates semantically and\ncounterfactually meaningful deep features with distinct augmentation strength\nfor each sample. Second, we derive an easy-to-compute surrogate loss on the\naugmented feature set when the number of augmented samples becomes infinite.\nThird, two concrete schemes are proposed, including direct quantification and\nmeta-learning, to derive the key parameters for the robust loss. In addition,\nICDA is explained from a regularization aspect, with extensive experiments\nindicating that our method consistently improves the generalization performance\nof popular depth networks on multiple typical learning scenarios that require\nout-of-distribution generalization.\n",
                "链接": "https://arxiv.org/abs/2304.13431"
            },
            {
                "文章ID": "54607",
                "标题": "DISCO: Distilling Counterfactuals with Large Language Models",
                "作者": " Zeming Chen,  Qiyue Gao,  Antoine Bosselut,  Ashish Sabharwal,  Kyle Richardson",
                "发布日期": "2023-06-07",
                "摘要": "  Models trained with counterfactually augmented data learn representations of\nthe causal structure of tasks, enabling robust generalization. However,\nhigh-quality counterfactual data is scarce for most tasks and not easily\ngenerated at scale. When crowdsourced, such data is typically limited in scale\nand diversity; when generated using supervised methods, it is computationally\nexpensive to extend to new counterfactual dimensions. In this work, we\nintroduce DISCO (DIStilled COunterfactual Data), a new method for automatically\ngenerating high quality counterfactual data at scale. DISCO engineers prompts\nto generate phrasal perturbations with a large general language model. Then, a\ntask-specific teacher model filters these generations to distill high-quality\ncounterfactual data. While task-agnostic, we apply our pipeline to the task of\nnatural language inference (NLI) and find that on challenging evaluations such\nas the NLI stress test, comparatively smaller student models trained with DISCO\ngenerated counterfactuals are more robust (6% absolute) and generalize better\nacross distributions (2%) compared to models trained without data augmentation.\nFurthermore, DISCO augmented models are 10% more consistent between\ncounterfactual pairs on three evaluation sets, demonstrating that DISCO\naugmentation enables models to more reliably learn causal representations. Our\nrepository is available at: https://github.com/eric11eca/disco\n",
                "链接": "https://arxiv.org/abs/2212.10534"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用蒙特卡罗树搜索解决序列决策问题的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "108378",
                "标题": "LightZero: A Unified Benchmark for Monte Carlo Tree Search in General\n  Sequential Decision Scenarios",
                "作者": " Yazhe Niu,  Yuan Pu,  Zhenjie Yang,  Xueyan Li,  Tong Zhou,  Jiyuan Ren,  Shuai Hu,  Hongsheng Li,  Yu Liu",
                "发布日期": "2023-10-13",
                "摘要": "  Building agents based on tree-search planning capabilities with learned\nmodels has achieved remarkable success in classic decision-making problems,\nsuch as Go and Atari. However, it has been deemed challenging or even\ninfeasible to extend Monte Carlo Tree Search (MCTS) based algorithms to diverse\nreal-world applications, especially when these environments involve complex\naction spaces and significant simulation costs, or inherent stochasticity. In\nthis work, we introduce LightZero, the first unified benchmark for deploying\nMCTS/MuZero in general sequential decision scenarios. Specificially, we\nsummarize the most critical challenges in designing a general MCTS-style\ndecision-making solver, then decompose the tightly-coupled algorithm and system\ndesign of tree-search RL methods into distinct sub-modules. By incorporating\nmore appropriate exploration and optimization strategies, we can significantly\nenhance these sub-modules and construct powerful LightZero agents to tackle\ntasks across a wide range of domains, such as board games, Atari, MuJoCo,\nMiniGrid and GoBigger. Detailed benchmark results reveal the significant\npotential of such methods in building scalable and efficient decision\nintelligence. The code is available as part of OpenDILab at\nhttps://github.com/opendilab/LightZero.\n",
                "链接": "https://arxiv.org/abs/2310.08348"
            },
            {
                "文章ID": "53055",
                "标题": "Lookahead Pathology in Monte-Carlo Tree Search",
                "作者": " Khoi P. N. Nguyen,  Raghuram Ramanujan",
                "发布日期": "2022-12-13",
                "摘要": "  Monte-Carlo Tree Search (MCTS) is an adversarial search paradigm that first\nfound prominence with its success in the domain of computer Go. Early\ntheoretical work established the game-theoretic soundness and convergence\nbounds for Upper Confidence bounds applied to Trees (UCT), the most popular\ninstantiation of MCTS; however, there remain notable gaps in our understanding\nof how UCT behaves in practice. In this work, we address one such gap by\nconsidering the question of whether UCT can exhibit lookahead pathology -- a\nparadoxical phenomenon first observed in Minimax search where greater search\neffort leads to worse decision-making. We introduce a novel family of synthetic\ngames that offer rich modeling possibilities while remaining amenable to\nmathematical analysis. Our theoretical and experimental results suggest that\nUCT is indeed susceptible to pathological behavior in a range of games drawn\nfrom this family.\n",
                "链接": "https://arxiv.org/abs/2212.05208"
            },
            {
                "文章ID": "54835",
                "标题": "Feature Acquisition using Monte Carlo Tree Search",
                "作者": " Sungsoo Lim,  Diego Klabjan,  Mark Shapiro",
                "发布日期": "2022-12-23",
                "摘要": "  Feature acquisition algorithms address the problem of acquiring informative\nfeatures while balancing the costs of acquisition to improve the learning\nperformances of ML models. Previous approaches have focused on calculating the\nexpected utility values of features to determine the acquisition sequences.\nOther approaches formulated the problem as a Markov Decision Process (MDP) and\napplied reinforcement learning based algorithms. In comparison to previous\napproaches, we focus on 1) formulating the feature acquisition problem as a MDP\nand applying Monte Carlo Tree Search, 2) calculating the intermediary rewards\nfor each acquisition step based on model improvements and acquisition costs and\n3) simultaneously optimizing model improvement and acquisition costs with\nmulti-objective Monte Carlo Tree Search. With Proximal Policy Optimization and\nDeep Q-Network algorithms as benchmark, we show the effectiveness of our\nproposed approach with experimental study.\n",
                "链接": "https://arxiv.org/abs/2212.11360"
            },
            {
                "文章ID": "67092",
                "标题": "Proof Number Based Monte-Carlo Tree Search",
                "作者": " Jakub Kowalski,  Elliot Doe,  Mark H. M. Winands,  Daniel Górski,  Dennis J. N. J. Soemers",
                "发布日期": "2023-12-22",
                "摘要": "  This paper proposes a new game-search algorithm, PN-MCTS, which combines\nMonte-Carlo Tree Search (MCTS) and Proof-Number Search (PNS). These two\nalgorithms have been successfully applied for decision making in a range of\ndomains. We define three areas where the additional knowledge provided by the\nproof and disproof numbers gathered in MCTS trees might be used: final move\nselection, solving subtrees, and the UCB1 selection mechanism. We test all\npossible combinations on different time settings, playing against vanilla UCT\non several games: Lines of Action ($7$$\\times$$7$ and $8$$\\times$$8$ board\nsizes), MiniShogi, Knightthrough, and Awari. Furthermore, we extend this new\nalgorithm to properly address games with draws, like Awari, by adding an\nadditional layer of PNS on top of the MCTS tree. The experiments show that\nPN-MCTS confidently outperforms MCTS in all tested game domains, achieving win\nrates up to 96.2\\% for Lines of Action.\n",
                "链接": "https://arxiv.org/abs/2303.09449"
            },
            {
                "文章ID": "102301",
                "标题": "Maneuver Decision-Making Through Proximal Policy Optimization And Monte\n  Carlo Tree Search",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-09-19",
                "摘要": "  Maneuver decision-making can be regarded as a Markov decision process and can\nbe address by reinforcement learning. However, original reinforcement learning\nalgorithms can hardly solve the maneuvering decision-making problem. One reason\nis that agents use random actions in the early stages of training, which makes\nit difficult to get rewards and learn how to make effective decisions. To\naddress this issue, a method based on proximal policy optimization and Monte\nCarlo tree search is proposed. The method uses proximal policy optimization to\ntrain the agent, and regards the results of air combat as targets to train the\nvalue network. Then, based on the value network and the visit count of each\nnode, Monte Carlo tree search is used to find the actions with more expected\nreturns than random actions, which can improve the training performance. The\nablation studies and simulation experiments indicate that agents trained by the\nproposed method can make different decisions according to different states,\nwhich demonstrates that the method can solve the maneuvering decision problem\nthat the original reinforcement learning algorithm cannot solve.\n",
                "链接": "https://arxiv.org/abs/2309.08611"
            },
            {
                "文章ID": "23592",
                "标题": "Combining Monte-Carlo Tree Search with Proof-Number Search",
                "作者": " Elliot Doe,  Mark H. M. Winands,  Dennis J. N. J. Soemers,  Cameron Browne",
                "发布日期": "2022-06-09",
                "摘要": "  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
                "链接": "https://arxiv.org/abs/2206.03965"
            },
            {
                "文章ID": "107708",
                "标题": "Accelerating Monte Carlo Tree Search with Probability Tree State\n  Abstraction",
                "作者": " Yangqing Fu,  Ming Sun,  Buqing Nie,  Yue Gao",
                "发布日期": "2023-10-11",
                "摘要": "  Monte Carlo Tree Search (MCTS) algorithms such as AlphaGo and MuZero have\nachieved superhuman performance in many challenging tasks. However, the\ncomputational complexity of MCTS-based algorithms is influenced by the size of\nthe search space. To address this issue, we propose a novel probability tree\nstate abstraction (PTSA) algorithm to improve the search efficiency of MCTS. A\ngeneral tree state abstraction with path transitivity is defined. In addition,\nthe probability tree state abstraction is proposed for fewer mistakes during\nthe aggregation step. Furthermore, the theoretical guarantees of the\ntransitivity and aggregation error bound are justified. To evaluate the\neffectiveness of the PTSA algorithm, we integrate it with state-of-the-art\nMCTS-based algorithms, such as Sampled MuZero and Gumbel MuZero. Experimental\nresults on different tasks demonstrate that our method can accelerate the\ntraining process of state-of-the-art algorithms with 10%-45% search space\nreduction.\n",
                "链接": "https://arxiv.org/abs/2310.06513"
            },
            {
                "文章ID": "7216",
                "标题": "Decision Making in Non-Stationary Environments with Policy-Augmented\n  Monte Carlo Tree Search",
                "作者": " Geoffrey Pettet,  Ayan Mukhopadhyay,  Abhishek Dubey",
                "发布日期": "2022-03-01",
                "摘要": "  Decision-making under uncertainty (DMU) is present in many important\nproblems. An open challenge is DMU in non-stationary environments, where the\ndynamics of the environment can change over time. Reinforcement Learning (RL),\na popular approach for DMU problems, learns a policy by interacting with a\nmodel of the environment offline. Unfortunately, if the environment changes the\npolicy can become stale and take sub-optimal actions, and relearning the policy\nfor the updated environment takes time and computational effort. An alternative\nis online planning approaches such as Monte Carlo Tree Search (MCTS), which\nperform their computation at decision time. Given the current environment, MCTS\nplans using high-fidelity models to determine promising action trajectories.\nThese models can be updated as soon as environmental changes are detected to\nimmediately incorporate them into decision making. However, MCTS's convergence\ncan be slow for domains with large state-action spaces. In this paper, we\npresent a novel hybrid decision-making approach that combines the strengths of\nRL and planning while mitigating their weaknesses. Our approach, called Policy\nAugmented MCTS (PA-MCTS), integrates a policy's actin-value estimates into\nMCTS, using the estimates to seed the action trajectories favored by the\nsearch. We hypothesize that PA-MCTS will converge more quickly than standard\nMCTS while making better decisions than the policy can make on its own when\nfaced with nonstationary environments. We test our hypothesis by comparing\nPA-MCTS with pure MCTS and an RL agent applied to the classical CartPole\nenvironment. We find that PC-MCTS can achieve higher cumulative rewards than\nthe policy in isolation under several environmental shifts while converging in\nsignificantly fewer iterations than pure MCTS.\n",
                "链接": "https://arxiv.org/abs/2202.13003"
            },
            {
                "文章ID": "22592",
                "标题": "Policy Gradient Algorithms with Monte-Carlo Tree Search for Non-Markov\n  Decision Processes",
                "作者": " Tetsuro Morimura,  Kazuhiro Ota,  Kenshi Abe,  Peinan Zhang",
                "发布日期": "2022-06-03",
                "摘要": "  Policy gradient (PG) is a reinforcement learning (RL) approach that optimizes\na parameterized policy model for an expected return using gradient ascent.\nGiven a well-parameterized policy model, such as a neural network model, with\nappropriate initial parameters, the PG algorithms work well even when\nenvironment does not have the Markov property. Otherwise, they can be trapped\non a plateau or suffer from peakiness effects. As another successful RL\napproach, algorithms based on Monte-Carlo Tree Search (MCTS), which include\nAlphaZero, have obtained groundbreaking results especially on the board game\nplaying domain. They are also suitable to be applied to non-Markov decision\nprocesses. However, since the standard MCTS does not have the ability to learn\nstate representation, the size of the tree-search space can be too large to\nsearch. In this work, we examine a mixture policy of PG and MCTS to complement\neach other's difficulties and take advantage of them. We derive conditions for\nasymptotic convergence with results of a two-timescale stochastic approximation\nand propose an algorithm that satisfies these conditions. The effectivity of\nthe proposed methods is verified through numerical experiments on non-Markov\ndecision processes.\n",
                "链接": "https://arxiv.org/abs/2206.01011"
            },
            {
                "文章ID": "22082",
                "标题": "Critic Sequential Monte Carlo",
                "作者": " Vasileios Lioutas,  Jonathan Wilder Lavington,  Justice Sefas,  Matthew Niedoba,  Yunpeng Liu,  Berend Zwartsenberg,  Setareh Dabiri,  Frank Wood,  Adam Scibior",
                "发布日期": "2023-01-24",
                "摘要": "  We introduce CriticSMC, a new algorithm for planning as inference built from\na composition of sequential Monte Carlo with learned Soft-Q function heuristic\nfactors. These heuristic factors, obtained from parametric approximations of\nthe marginal likelihood ahead, more effectively guide SMC towards the desired\ntarget distribution, which is particularly helpful for planning in environments\nwith hard constraints placed sparsely in time. Compared with previous work, we\nmodify the placement of such heuristic factors, which allows us to cheaply\npropose and evaluate large numbers of putative action particles, greatly\nincreasing inference and planning efficiency. CriticSMC is compatible with\ninformative priors, whose density function need not be known, and can be used\nas a model-free control algorithm. Our experiments on collision avoidance in a\nhigh-dimensional simulated driving task show that CriticSMC significantly\nreduces collision rates at a low computational cost while maintaining realism\nand diversity of driving behaviors across vehicles and environment scenarios.\n",
                "链接": "https://arxiv.org/abs/2205.15460"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用gpt4做评测指标优缺点的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "123333",
                "标题": "The Pros and Cons of Adversarial Robustness",
                "作者": " Yacine Izza,  Joao Marques-Silva",
                "发布日期": "2023-12-19",
                "摘要": "  Robustness is widely regarded as a fundamental problem in the analysis of\nmachine learning (ML) models. Most often robustness equates with deciding the\nnon-existence of adversarial examples, where adversarial examples denote\nsituations where small changes on some inputs cause a change in the prediction.\nThe perceived importance of ML model robustness explains the continued progress\nobserved for most of the last decade. Whereas robustness is often assessed\nlocally, i.e. given some target point in feature space, robustness can also be\ndefined globally, i.e. where any point in feature space can be considered. The\nimportance of ML model robustness is illustrated for example by the existence\nof competitions evaluating the progress of robustness tools, namely in the case\nof neural networks (NNs) but also by efforts towards robustness certification.\nMore recently, robustness tools have also been used for computing rigorous\nexplanations of ML models. In contrast with the observed successes of\nrobustness, this paper uncovers some limitations with existing definitions of\nrobustness, both global and local, but also with efforts towards robustness\ncertification. The paper also investigates uses of adversarial examples besides\nthose related with robustness.\n",
                "链接": "https://arxiv.org/abs/2312.10911"
            },
            {
                "文章ID": "33038",
                "标题": "On the Pros and Cons of Momentum Encoder in Self-Supervised Visual\n  Representation Learning",
                "作者": " Trung Pham,  Chaoning Zhang,  Axi Niu,  Kang Zhang,  Chang D. Yoo",
                "发布日期": "2022-08-12",
                "摘要": "  Exponential Moving Average (EMA or momentum) is widely used in modern\nself-supervised learning (SSL) approaches, such as MoCo, for enhancing\nperformance. We demonstrate that such momentum can also be plugged into\nmomentum-free SSL frameworks, such as SimCLR, for a performance boost. Despite\nits wide use as a fundamental component in modern SSL frameworks, the benefit\ncaused by momentum is not well understood. We find that its success can be at\nleast partly attributed to the stability effect. In the first attempt, we\nanalyze how EMA affects each part of the encoder and reveal that the portion\nnear the encoder's input plays an insignificant role while the latter parts\nhave much more influence. By monitoring the gradient of the overall loss with\nrespect to the output of each block in the encoder, we observe that the final\nlayers tend to fluctuate much more than other layers during backpropagation,\ni.e. less stability. Interestingly, we show that using EMA to the final part of\nthe SSL encoder, i.e. projector, instead of the whole deep network encoder can\ngive comparable or preferable performance. Our proposed projector-only momentum\nhelps maintain the benefit of EMA but avoids the double forward computation.\n",
                "链接": "https://arxiv.org/abs/2208.05744"
            },
            {
                "文章ID": "115113",
                "标题": "The Pros and Cons of Using Machine Learning and Interpretable Machine\n  Learning Methods in psychiatry detection applications, specifically\n  depression disorder: A Brief Review",
                "作者": " Hossein Simchi,  Samira Tajik",
                "发布日期": "2023-11-14",
                "摘要": "  The COVID-19 pandemic has forced many people to limit their social\nactivities, which has resulted in a rise in mental illnesses, particularly\ndepression. To diagnose these illnesses with accuracy and speed, and prevent\nsevere outcomes such as suicide, the use of machine learning has become\nincreasingly important. Additionally, to provide precise and understandable\ndiagnoses for better treatment, AI scientists and researchers must develop\ninterpretable AI-based solutions. This article provides an overview of relevant\narticles in the field of machine learning and interpretable AI, which helps to\nunderstand the advantages and disadvantages of using AI in psychiatry disorder\ndetection applications.\n",
                "链接": "https://arxiv.org/abs/2311.06633"
            },
            {
                "文章ID": "103691",
                "标题": "OpenAi's GPT4 as coding assistant",
                "作者": " Lefteris Moussiades,  George Zografos",
                "发布日期": "2023-09-25",
                "摘要": "  Lately, Large Language Models have been widely used in code generation. GPT4\nis considered the most potent Large Language Model from Openai. In this paper,\nwe examine GPT3.5 and GPT4 as coding assistants. More specifically, we have\nconstructed appropriate tests to check whether the two systems can a) answer\ntypical questions that can arise during the code development, b) produce\nreliable code, and c) contribute to code debugging. The test results are\nimpressive. The performance of GPT4 is outstanding and signals an increase in\nthe productivity of programmers and the reorganization of software development\nprocedures based on these new tools.\n",
                "链接": "https://arxiv.org/abs/2309.12732"
            },
            {
                "文章ID": "107507",
                "标题": "The Unreasonable Effectiveness of Linear Prediction as a Perceptual\n  Metric",
                "作者": " Daniel Severo,  Lucas Theis,  Johannes Ballé",
                "发布日期": "2023-10-11",
                "摘要": "  We show how perceptual embeddings of the visual system can be constructed at\ninference-time with no training data or deep neural network features. Our\nperceptual embeddings are solutions to a weighted least squares (WLS) problem,\ndefined at the pixel-level, and solved at inference-time, that can capture\nglobal and local image characteristics. The distance in embedding space is used\nto define a perceptual similarity metric which we call LASI: Linear\nAutoregressive Similarity Index. Experiments on full-reference image quality\nassessment datasets show LASI performs competitively with learned deep feature\nbased methods like LPIPS (Zhang et al., 2018) and PIM (Bhardwaj et al., 2020),\nat a similar computational cost to hand-crafted methods such as MS-SSIM (Wang\net al., 2003). We found that increasing the dimensionality of the embedding\nspace consistently reduces the WLS loss while increasing performance on\nperceptual tasks, at the cost of increasing the computational complexity. LASI\nis fully differentiable, scales cubically with the number of embedding\ndimensions, and can be parallelized at the pixel-level. A Maximum\nDifferentiation (MAD) competition (Wang & Simoncelli, 2008) between LASI and\nLPIPS shows that both methods are capable of finding failure points for the\nother, suggesting these metrics can be combined.\n",
                "链接": "https://arxiv.org/abs/2310.05986"
            },
            {
                "文章ID": "39509",
                "标题": "Using Processing Fluency as a Metric of Trust in Scatterplot\n  Visualizations",
                "作者": " Hamza Elhamdadi,  Lace Padilla,  Cindy Xiong",
                "发布日期": "2022-09-30",
                "摘要": "  Establishing trust with readers is an important first step in visual data\ncommunication. But what makes a visualization trustworthy? Psychology and\nbehavioral economics research has found processing fluency (i.e., speed and\naccuracy of perceiving and processing a stimulus) is central to perceived\ntrust. We examine the association between processing fluency and trust in\nvisualizations through two empirical studies. In Experiment 1, we tested the\neffect of camouflaging a visualization on processing fluency. Participants\nestimated the proportion of data values within a specified range for six\ncamouflaged visualizations and one non-camouflaged control; they also reported\ntheir perceived difficulty for each of the visualizations. Camouflaged\nvisualizations produced less accurate estimations compared to the control. In\nExperiment 2, we created a decision task based on trust games adapted from\nbehavioral economics. We asked participants to invest money in two hypothetical\ncompanies and report how much they trust each company. One company communicates\nits strategy with a camouflaged visualization, the other with a controlled\nvisualization. Participants tended to invest less money in the company\npresenting a camouflaged visualization. Hence, we found support for the\nhypothesis that processing fluency is key to the perception of trust in visual\ndata communication.\n",
                "链接": "https://arxiv.org/abs/2209.14340"
            },
            {
                "文章ID": "71832",
                "标题": "The efficacy potential of cyber security advice as presented in news\n  articles",
                "作者": " Mark Quinlan,  Aaron Ceross,  Andrew Simpson",
                "发布日期": "2023-04-12",
                "摘要": "  Cyber security advice is a broad church: it is thematically expansive,\ncomprising expert texts, user-generated data consumed by individual users via\ninformal learning, and much in-between. While there is evidence that cyber\nsecurity news articles play a role in disseminating cyber security advice, the\nnature and extent of that role are not clear. We present a corpus of cyber\nsecurity advice generated from mainstream news articles. The work was driven by\ntwo research objectives. The first objective was to ascertain what kind of\nactionable advice is being disseminated; the second was to explore ways of\ndetermining the efficacy potential of news-mediated security advice. The\nresults show an increase in the generation of cyber security news articles,\ntogether with increases in vocabulary complexity and reading difficulty. We\nargue that these could present challenges for vulnerable users. We believe that\nthis corpus and the accompanying analysis have the potential to inform future\nefforts to quantify and improve the efficacy potential of security advice\ndissemination.\n",
                "链接": "https://arxiv.org/abs/2304.05309"
            },
            {
                "文章ID": "103106",
                "标题": "Is GPT4 a Good Trader?",
                "作者": " Bingzhe Wu",
                "发布日期": "2023-09-21",
                "摘要": "  Recently, large language models (LLMs), particularly GPT-4, have demonstrated\nsignificant capabilities in various planning and reasoning tasks\n\\cite{cheng2023gpt4,bubeck2023sparks}. Motivated by these advancements, there\nhas been a surge of interest among researchers to harness the capabilities of\nGPT-4 for the automated design of quantitative factors that do not overlap with\nexisting factor libraries, with an aspiration to achieve alpha returns\n\\cite{webpagequant}. In contrast to these work, this study aims to examine the\nfidelity of GPT-4's comprehension of classic trading theories and its\nproficiency in applying its code interpreter abilities to real-world trading\ndata analysis. Such an exploration is instrumental in discerning whether the\nunderlying logic GPT-4 employs for trading is intrinsically reliable.\nFurthermore, given the acknowledged interpretative latitude inherent in most\ntrading theories, we seek to distill more precise methodologies of deploying\nthese theories from GPT-4's analytical process, potentially offering invaluable\ninsights to human traders.\n  To achieve this objective, we selected daily candlestick (K-line) data from\nspecific periods for certain assets, such as the Shanghai Stock Index. Through\nmeticulous prompt engineering, we guided GPT-4 to analyze the technical\nstructures embedded within this data, based on specific theories like the\nElliott Wave Theory. We then subjected its analytical output to manual\nevaluation, assessing its interpretative depth and accuracy vis-\\`a-vis these\ntrading theories from multiple dimensions. The results and findings from this\nstudy could pave the way for a synergistic amalgamation of human expertise and\nAI-driven insights in the realm of trading.\n",
                "链接": "https://arxiv.org/abs/2309.10982"
            },
            {
                "文章ID": "4592",
                "标题": "On the Pitfalls of Using the Residual Error as Anomaly Score",
                "作者": " Felix Meissen,  Benedikt Wiestler,  Georgios Kaissis,  Daniel Rueckert",
                "发布日期": "2023-09-26",
                "摘要": "  Many current state-of-the-art methods for anomaly localization in medical\nimages rely on calculating a residual image between a potentially anomalous\ninput image and its \"healthy\" reconstruction. As the reconstruction of the\nunseen anomalous region should be erroneous, this yields large residuals as a\nscore to detect anomalies in medical images. However, this assumption does not\ntake into account residuals resulting from imperfect reconstructions of the\nmachine learning models used. Such errors can easily overshadow residuals of\ninterest and therefore strongly question the use of residual images as scoring\nfunction. Our work explores this fundamental problem of residual images in\ndetail. We theoretically define the problem and thoroughly evaluate the\ninfluence of intensity and texture of anomalies against the effect of imperfect\nreconstructions in a series of experiments. Code and experiments are available\nunder https://github.com/FeliMe/residual-score-pitfalls\n",
                "链接": "https://arxiv.org/abs/2202.03826"
            },
            {
                "文章ID": "111434",
                "标题": "In the user's eyes we find trust: Using gaze data as a predictor or\n  trust in an artifical intelligence",
                "作者": " Martin Johannes Dechant,  Olga Lukashova-Sanz,  Siegfried Wahl",
                "发布日期": "2023-10-26",
                "摘要": "  Trust is essential for our interactions with others but also with artificial\nintelligence (AI) based systems. To understand whether a user trusts an AI,\nresearchers need reliable measurement tools. However, currently discussed\nmarkers mostly rely on expensive and invasive sensors, like\nelectroencephalograms, which may cause discomfort. The analysis of gaze data\nhas been suggested as a convenient tool for trust assessment. However, the\nrelationship between trust and several aspects of the gaze behaviour is not yet\nfully understood. To provide more insights into this relationship, we propose a\nexploration study in virtual reality where participants have to perform a\nsorting task together with a simulated AI in a simulated robotic arm embedded\nin a gaming. We discuss the potential benefits of this approach and outline our\nstudy design in this submission.\n",
                "链接": "https://arxiv.org/abs/2310.16672"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用GPT4v完成多模态智能体的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "86459",
                "标题": "Genes in Intelligent Agents",
                "作者": " Fu Feng,  Jing Wang,  Xu Yang,  Xin Geng",
                "发布日期": "2023-10-30",
                "摘要": "  The genes in nature give the lives on earth the current biological\nintelligence through transmission and accumulation over billions of years.\nInspired by the biological intelligence, artificial intelligence (AI) has\ndevoted to building the machine intelligence. Although it has achieved thriving\nsuccesses, the machine intelligence still lags far behind the biological\nintelligence. The reason may lie in that animals are born with some\nintelligence encoded in their genes, but machines lack such intelligence and\nlearn from scratch. Inspired by the genes of animals, we define the ``genes''\nof machines named as the ``learngenes'' and propose the Genetic Reinforcement\nLearning (GRL). GRL is a computational framework that simulates the evolution\nof organisms in reinforcement learning (RL) and leverages the learngenes to\nlearn and evolve the intelligence agents. Leveraging GRL, we first show that\nthe learngenes take the form of the fragments of the agents' neural networks\nand can be inherited across generations. Second, we validate that the\nlearngenes can transfer ancestral experience to the agents and bring them\ninstincts and strong learning abilities. Third, we justify the Lamarckian\ninheritance of the intelligent agents and the continuous evolution of the\nlearngenes. Overall, the learngenes have taken the machine intelligence one\nmore step toward the biological intelligence.\n",
                "链接": "https://arxiv.org/abs/2306.10225"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "34904",
                "标题": "Towards A Complete Multi-Agent Pathfinding Algorithm For Large Agents",
                "作者": " Stepan Dergachev,  Konstantin Yakovlev",
                "发布日期": "2022-08-26",
                "摘要": "  Multi-agent pathfinding (MAPF) is a challenging problem which is hard to\nsolve optimally even when simplifying assumptions are adopted, e.g. planar\ngraphs (typically -- grids), discretized time, uniform duration of move and\nwait actions etc. On the other hand, MAPF under such restrictive assumptions\n(also known as the Classical MAPF) is equivalent to the so-called pebble motion\nproblem for which non-optimal polynomial time algorithms do exist. Recently, a\nbody of works emerged that investigated MAPF beyond the basic setting and, in\nparticular, considered agents of arbitrary size and shape. Still, to the best\nof our knowledge no complete algorithms for such MAPF variant exists. In this\nwork we attempt to narrow this gap by considering MAPF for large agents and\nsuggesting how this problem can be reduced to pebble motion on (general)\ngraphs. The crux of this reduction is the procedure that moves away the agents\naway from the edge which is needed to perform a move action of the current\nagent. We consider different variants of how this procedure can be implemented\nand present a variant of the pebble motion algorithm which incorporates this\nprocedure. Unfortunately, the algorithm is still incomplete, but empirically we\nshow that it is able to solve much more MAPF instances (under the strict time\nlimit) with large agents on arbitrary non-planar graphs (roadmaps) compared to\nthe state-of-the-art MAPF solver -- Continous Conflict-Based Search (CCBS).\n",
                "链接": "https://arxiv.org/abs/2208.12236"
            },
            {
                "文章ID": "80852",
                "标题": "Incomplete Multimodal Learning for Complex Brain Disorders Prediction",
                "作者": " Reza Shirkavand,  Liang Zhan,  Heng Huang,  Li Shen,  Paul M. Thompson",
                "发布日期": "2023-05-26",
                "摘要": "  Recent advancements in the acquisition of various brain data sources have\ncreated new opportunities for integrating multimodal brain data to assist in\nearly detection of complex brain disorders. However, current data integration\napproaches typically need a complete set of biomedical data modalities, which\nmay not always be feasible, as some modalities are only available in\nlarge-scale research cohorts and are prohibitive to collect in routine clinical\npractice. Especially in studies of brain diseases, research cohorts may include\nboth neuroimaging data and genetic data, but for practical clinical diagnosis,\nwe often need to make disease predictions only based on neuroimages. As a\nresult, it is desired to design machine learning models which can use all\navailable data (different data could provide complementary information) during\ntraining but conduct inference using only the most common data modality. We\npropose a new incomplete multimodal data integration approach that employs\ntransformers and generative adversarial networks to effectively exploit\nauxiliary modalities available during training in order to improve the\nperformance of a unimodal model at inference. We apply our new method to\npredict cognitive degeneration and disease outcomes using the multimodal\nimaging genetic data from Alzheimer's Disease Neuroimaging Initiative (ADNI)\ncohort. Experimental results demonstrate that our approach outperforms the\nrelated machine learning and deep learning methods by a significant margin.\n",
                "链接": "https://arxiv.org/abs/2305.16222"
            },
            {
                "文章ID": "36179",
                "标题": "Data Centred Intelligent Geosciences: Research Agenda and Opportunities,\n  Position Paper",
                "作者": " Aderson Farias do Nascimento,  Martin A. Musicante,  Umberto Souza da Costa,  Bruno M. Carvalho,  Marcus Alexandre Nunes,  Genoveva Vargas-Solar",
                "发布日期": "2022-09-07",
                "摘要": "  This paper describes and discusses our vision to develop and reason about\nbest practices and novel ways of curating data-centric geosciences knowledge\n(data, experiments, models, methods, conclusions, and interpretations). This\nknowledge is produced from applying statistical modelling, Machine Learning,\nand modern data analytics methods on geo-data collections. The problems address\nopen methodological questions in model building, models' assessment,\nprediction, and forecasting workflows.\n",
                "链接": "https://arxiv.org/abs/2209.02384"
            },
            {
                "文章ID": "18559",
                "标题": "Scim: Intelligent Skimming Support for Scientific Papers",
                "作者": " Raymond Fok,  Hita Kambhamettu,  Luca Soldaini,  Jonathan Bragg,  Kyle Lo,  Andrew Head,  Marti A. Hearst,  Daniel S. Weld",
                "发布日期": "2023-09-26",
                "摘要": "  Researchers need to keep up with immense literatures, though it is\ntime-consuming and difficult to do so. In this paper, we investigate the role\nthat intelligent interfaces can play in helping researchers skim papers, that\nis, rapidly reviewing a paper to attain a cursory understanding of its\ncontents. After conducting formative interviews and a design probe, we suggest\nthat skimming aids should aim to thread the needle of highlighting content that\nis simultaneously diverse, evenly-distributed, and important. We introduce\nScim, a novel intelligent skimming interface that reifies this aim, designed to\nsupport the skimming process by highlighting salient paper contents to direct a\nskimmer's focus. Key to the design is that the highlights are faceted by\ncontent type, evenly-distributed across a paper, with a density configurable by\nreaders at both the global and local level. We evaluate Scim with an in-lab\nusability study and deployment study, revealing how skimming aids can support\nreaders throughout the skimming experience and yielding design considerations\nand tensions for the design of future intelligent skimming tools.\n",
                "链接": "https://arxiv.org/abs/2205.04561"
            },
            {
                "文章ID": "83868",
                "标题": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM\n  Agents",
                "作者": " Yashar Talebirad,  Amirhossein Nadiri",
                "发布日期": "2023-06-07",
                "摘要": "  In this paper, we present a novel framework for enhancing the capabilities of\nlarge language models (LLMs) by leveraging the power of multi-agent systems.\nOur framework introduces a collaborative environment where multiple intelligent\nagent components, each with distinctive attributes and roles, work together to\nhandle complex tasks more efficiently and effectively. We demonstrate the\npracticality and versatility of our framework through case studies in\nartificial general intelligence (AGI), specifically focusing on the Auto-GPT\nand BabyAGI models. We also examine the \"Gorilla\" model, which integrates\nexternal APIs into the LLM. Our framework addresses limitations and challenges\nsuch as looping issues, security risks, scalability, system evaluation, and\nethical considerations. By modeling various domains such as courtroom\nsimulations and software development scenarios, we showcase the potential\napplications and benefits of our proposed multi-agent system. Our framework\nprovides an avenue for advancing the capabilities and performance of LLMs\nthrough collaboration and knowledge exchange among intelligent agents.\n",
                "链接": "https://arxiv.org/abs/2306.03314"
            },
            {
                "文章ID": "2627",
                "标题": "A Method to Predict Semantic Relations on Artificial Intelligence Papers",
                "作者": " Francisco Andrades,  Ricardo Ñanculef",
                "发布日期": "2022-01-26",
                "摘要": "  Predicting the emergence of links in large evolving networks is a difficult\ntask with many practical applications. Recently, the Science4cast competition\nhas illustrated this challenge presenting a network of 64.000 AI concepts and\nasking the participants to predict which topics are going to be researched\ntogether in the future. In this paper, we present a solution to this problem\nbased on a new family of deep learning approaches, namely Graph Neural\nNetworks. The results of the challenge show that our solution is competitive\neven if we had to impose severe restrictions to obtain a computationally\nefficient and parsimonious model: ignoring the intrinsic dynamics of the graph\nand using only a small subset of the nodes surrounding a target link.\nPreliminary experiments presented in this paper suggest the model is learning\ntwo related, but different patterns: the absorption of a node by a sub-graph\nand union of more dense sub-graphs. The model seems to excel at recognizing the\nfirst type of pattern.\n",
                "链接": "https://arxiv.org/abs/2201.10518"
            },
            {
                "文章ID": "40702",
                "标题": "From Intelligent Agents to Trustworthy Human-Centred Multiagent Systems",
                "作者": " Mohammad Divband Soorati,  Enrico H. Gerding,  Enrico Marchioni,  Pavel Naumov,  Timothy J. Norman,  Sarvapali D. Ramchurn,  Bahar Rastegari,  Adam Sobey,  Sebastian Stein,  Danesh Tarpore,  Vahid Yazdanpanah,  Jie Zhang",
                "发布日期": "2022-10-06",
                "摘要": "  The Agents, Interaction and Complexity research group at the University of\nSouthampton has a long track record of research in multiagent systems (MAS). We\nhave made substantial scientific contributions across learning in MAS,\ngame-theoretic techniques for coordinating agent systems, and formal methods\nfor representation and reasoning. We highlight key results achieved by the\ngroup and elaborate on recent work and open research challenges in developing\ntrustworthy autonomous systems and deploying human-centred AI systems that aim\nto support societal good.\n",
                "链接": "https://arxiv.org/abs/2210.02260"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            }
        ]
    },
    {
        "question": {
            "question": "使用LLM进行蛋白质结构/功能/性质预测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "87297",
                "标题": "StrainTensorNet: Predicting crystal structure elastic properties using\n  SE(3)-equivariant graph neural networks",
                "作者": " Teerachote Pakornchote,  Annop Ektarawong,  Thiparat Chotibut",
                "发布日期": "2023-11-13",
                "摘要": "  Accurately predicting the elastic properties of crystalline solids is vital\nfor computational materials science. However, traditional atomistic scale ab\ninitio approaches are computationally intensive, especially for studying\ncomplex materials with a large number of atoms in a unit cell. We introduce a\nnovel data-driven approach to efficiently predict the elastic properties of\ncrystal structures using SE(3)-equivariant graph neural networks (GNNs). This\napproach yields important scalar elastic moduli with the accuracy comparable to\nrecent data-driven studies. Importantly, our symmetry-aware GNNs model also\nenables the prediction of the strain energy density (SED) and the associated\nelastic constants, the fundamental tensorial quantities that are significantly\ninfluenced by a material's crystallographic group. The model consistently\ndistinguishes independent elements of SED tensors, in accordance with the\nsymmetry of the crystal structures. Finally, our deep learning model possesses\nmeaningful latent features, offering an interpretable prediction of the elastic\nproperties.\n",
                "链接": "https://arxiv.org/abs/2306.12818"
            },
            {
                "文章ID": "34638",
                "标题": "Secondary Protein Structure Prediction Using Neural Networks",
                "作者": " Sidharth Malhotra,  Robin Walters",
                "发布日期": "2022-08-25",
                "摘要": "  In this paper we experiment with using neural network structures to predict a\nprotein's secondary structure ({\\alpha} helix positions) from only its primary\nstructure (amino acid sequence). We implement a fully connected neural network\n(FCNN) and preform three experiments using that FCNN. Firstly, we do a\ncross-species comparison of models trained and tested on mouse and human\ndatasets. Secondly, we test the impact of varying the length of protein\nsequence we input into the model. Thirdly, we compare custom error functions\ndesigned to focus on the center of the input window. At the end of paper we\npropose a alternative, recurrent neural network model which can be applied to\nthe problem.\n",
                "链接": "https://arxiv.org/abs/2208.11248"
            },
            {
                "文章ID": "109510",
                "标题": "Protein 3D Graph Structure Learning for Robust Structure-based Protein\n  Property Prediction",
                "作者": " Yufei Huang,  Siyuan Li,  Jin Su,  Lirong Wu,  Odin Zhang,  Haitao Lin,  Jingqi Qi,  Zihan Liu,  Zhangyang Gao,  Yuyang Liu,  Jiangbin Zheng,  Stan. ZQ. Li",
                "发布日期": "2023-10-20",
                "摘要": "  Protein structure-based property prediction has emerged as a promising\napproach for various biological tasks, such as protein function prediction and\nsub-cellular location estimation. The existing methods highly rely on\nexperimental protein structure data and fail in scenarios where these data are\nunavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were\nutilized as alternatives. However, we observed that current practices, which\nsimply employ accurately predicted structures during inference, suffer from\nnotable degradation in prediction accuracy. While similar phenomena have been\nextensively studied in general fields (e.g., Computer Vision) as model\nrobustness, their impact on protein property prediction remains unexplored. In\nthis paper, we first investigate the reason behind the performance decrease\nwhen utilizing predicted structures, attributing it to the structure embedding\nbias from the perspective of structure representation learning. To study this\nproblem, we identify a Protein 3D Graph Structure Learning Problem for Robust\nProtein Property Prediction (PGSL-RP3), collect benchmark datasets, and present\na protein Structure embedding Alignment Optimization framework (SAO) to\nmitigate the problem of structure embedding bias between the predicted and\nexperimental protein structures. Extensive experiments have shown that our\nframework is model-agnostic and effective in improving the property prediction\nof both predicted structures and experimental structures. The benchmark\ndatasets and codes will be released to benefit the community.\n",
                "链接": "https://arxiv.org/abs/2310.11466"
            },
            {
                "文章ID": "18972",
                "标题": "Predicting Human Psychometric Properties Using Computational Language\n  Models",
                "作者": "Jr. Antonio Laverghetta,  Animesh Nighojkar,  Jamshidbek Mirzakhalov,  John Licato",
                "发布日期": "2022-05-13",
                "摘要": "  Transformer-based language models (LMs) continue to achieve state-of-the-art\nperformance on natural language processing (NLP) benchmarks, including tasks\ndesigned to mimic human-inspired \"commonsense\" competencies. To better\nunderstand the degree to which LMs can be said to have certain linguistic\nreasoning skills, researchers are beginning to adapt the tools and concepts\nfrom psychometrics. But to what extent can benefits flow in the other\ndirection? In other words, can LMs be of use in predicting the psychometric\nproperties of test items, when those items are given to human participants? If\nso, the benefit for psychometric practitioners is enormous, as it can reduce\nthe need for multiple rounds of empirical testing. We gather responses from\nnumerous human participants and LMs (transformer- and non-transformer-based) on\na broad diagnostic test of linguistic competencies. We then use the human\nresponses to calculate standard psychometric properties of the items in the\ndiagnostic test, using the human responses and the LM responses separately. We\nthen determine how well these two sets of predictions correlate. We find that\ntransformer-based LMs predict the human psychometric data consistently well\nacross most categories, suggesting that they can be used to gather human-like\npsychometric data without the need for extensive human trials.\n",
                "链接": "https://arxiv.org/abs/2205.06203"
            },
            {
                "文章ID": "110430",
                "标题": "LLM-Prop: Predicting Physical And Electronic Properties Of Crystalline\n  Solids From Their Text Descriptions",
                "作者": " Andre Niyongabo Rubungo,  Craig Arnold,  Barry P. Rand,  Adji Bousso Dieng",
                "发布日期": "2023-10-24",
                "摘要": "  The prediction of crystal properties plays a crucial role in the crystal\ndesign process. Current methods for predicting crystal properties focus on\nmodeling crystal structures using graph neural networks (GNNs). Although GNNs\nare powerful, accurately modeling the complex interactions between atoms and\nmolecules within a crystal remains a challenge. Surprisingly, predicting\ncrystal properties from crystal text descriptions is understudied, despite the\nrich information and expressiveness that text data offer. One of the main\nreasons is the lack of publicly available data for this task. In this paper, we\ndevelop and make public a benchmark dataset (called TextEdge) that contains\ntext descriptions of crystal structures with their properties. We then propose\nLLM-Prop, a method that leverages the general-purpose learning capabilities of\nlarge language models (LLMs) to predict the physical and electronic properties\nof crystals from their text descriptions. LLM-Prop outperforms the current\nstate-of-the-art GNN-based crystal property predictor by about 4% in predicting\nband gap, 3% in classifying whether the band gap is direct or indirect, and 66%\nin predicting unit cell volume. LLM-Prop also outperforms a finetuned MatBERT,\na domain-specific pre-trained BERT model, despite having 3 times fewer\nparameters. Our empirical results may highlight the current inability of GNNs\nto capture information pertaining to space group symmetry and Wyckoff sites for\naccurate crystal property prediction.\n",
                "链接": "https://arxiv.org/abs/2310.14029"
            },
            {
                "文章ID": "26245",
                "标题": "PSP: Million-level Protein Sequence Dataset for Protein Structure\n  Prediction",
                "作者": " Sirui Liu,  Jun Zhang,  Haotian Chu,  Min Wang,  Boxin Xue,  Ningxi Ni,  Jialiang Yu,  Yuhao Xie,  Zhenyu Chen,  Mengyun Chen,  Yuan Liu,  Piya Patra,  Fan Xu,  Jie Chen,  Zidong Wang,  Lijiang Yang,  Fan Yu,  Lei Chen,  Yi Qin Gao",
                "发布日期": "2022-06-27",
                "摘要": "  Proteins are essential component of human life and their structures are\nimportant for function and mechanism analysis. Recent work has shown the\npotential of AI-driven methods for protein structure prediction. However, the\ndevelopment of new models is restricted by the lack of dataset and benchmark\ntraining procedure. To the best of our knowledge, the existing open source\ndatasets are far less to satisfy the needs of modern protein sequence-structure\nrelated research. To solve this problem, we present the first million-level\nprotein structure prediction dataset with high coverage and diversity, named as\nPSP. This dataset consists of 570k true structure sequences (10TB) and 745k\ncomplementary distillation sequences (15TB). We provide in addition the\nbenchmark training procedure for SOTA protein structure prediction model on\nthis dataset. We validate the utility of this dataset for training by\nparticipating CAMEO contest in which our model won the first place. We hope our\nPSP dataset together with the training benchmark can enable a broader community\nof AI/biology researchers for AI-driven protein related research.\n",
                "链接": "https://arxiv.org/abs/2206.12240"
            },
            {
                "文章ID": "31301",
                "标题": "HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein\n  Language Model as an Alternative",
                "作者": " Xiaomin Fang,  Fan Wang,  Lihang Liu,  Jingzhou He,  Dayong Lin,  Yingfei Xiang,  Xiaonan Zhang,  Hua Wu,  Hui Li,  Le Song",
                "发布日期": "2023-10-19",
                "摘要": "  AI-based protein structure prediction pipelines, such as AlphaFold2, have\nachieved near-experimental accuracy. These advanced pipelines mainly rely on\nMultiple Sequence Alignments (MSAs) as inputs to learn the co-evolution\ninformation from the homologous sequences. Nonetheless, searching MSAs from\nprotein databases is time-consuming, usually taking dozens of minutes.\nConsequently, we attempt to explore the limits of fast protein structure\nprediction by using only primary sequences of proteins. HelixFold-Single is\nproposed to combine a large-scale protein language model with the superior\ngeometric learning capability of AlphaFold2. Our proposed method,\nHelixFold-Single, first pre-trains a large-scale protein language model (PLM)\nwith thousands of millions of primary sequences utilizing the self-supervised\nlearning paradigm, which will be used as an alternative to MSAs for learning\nthe co-evolution information. Then, by combining the pre-trained PLM and the\nessential components of AlphaFold2, we obtain an end-to-end differentiable\nmodel to predict the 3D coordinates of atoms from only the primary sequence.\nHelixFold-Single is validated in datasets CASP14 and CAMEO, achieving\ncompetitive accuracy with the MSA-based methods on the targets with large\nhomologous families. Furthermore, HelixFold-Single consumes much less time than\nthe mainstream pipelines for protein structure prediction, demonstrating its\npotential in tasks requiring many predictions. The code of HelixFold-Single is\navailable at\nhttps://github.com/PaddlePaddle/PaddleHelix/tree/dev/apps/protein_folding/helixfold-single,\nand we also provide stable web services on\nhttps://paddlehelix.baidu.com/app/drug/protein-single/forecast.\n",
                "链接": "https://arxiv.org/abs/2207.13921"
            },
            {
                "文章ID": "42172",
                "标题": "Predicting the clinical citation count of biomedical papers using\n  multilayer perceptron neural network",
                "作者": " Xin Li,  Xuli Tang,  Qikai Cheng",
                "发布日期": "2022-10-24",
                "摘要": "  The number of clinical citations received from clinical guidelines or\nclinical trials has been considered as one of the most appropriate indicators\nfor quantifying the clinical impact of biomedical papers. Therefore, the early\nprediction of the clinical citation count of biomedical papers is critical to\nscientific activities in biomedicine, such as research evaluation, resource\nallocation, and clinical translation. In this study, we designed a four-layer\nmultilayer perceptron neural network (MPNN) model to predict the clinical\ncitation count of biomedical papers in the future by using 9,822,620 biomedical\npapers published from 1985 to 2005. We extracted ninety-one paper features from\nthree dimensions as the input of the model, including twenty-one features in\nthe paper dimension, thirty-five in the reference dimension, and thirty-five in\nthe citing paper dimension. In each dimension, the features can be classified\ninto three categories, i.e., the citation-related features, the clinical\ntranslation-related features, and the topic-related features. Besides, in the\npaper dimension, we also considered the features that have previously been\ndemonstrated to be related to the citation counts of research papers. The\nresults showed that the proposed MPNN model outperformed the other five\nbaseline models, and the features in the reference dimension were the most\nimportant.\n",
                "链接": "https://arxiv.org/abs/2210.06346"
            },
            {
                "文章ID": "24433",
                "标题": "Exploring evolution-aware & -free protein language models as protein\n  function predictors",
                "作者": " Mingyang Hu,  Fajie Yuan,  Kevin K. Yang,  Fusong Ju,  Jin Su,  Hui Wang,  Fei Yang,  Qiuyang Ding",
                "发布日期": "2022-10-18",
                "摘要": "  Large-scale Protein Language Models (PLMs) have improved performance in\nprotein prediction tasks, ranging from 3D structure prediction to various\nfunction predictions. In particular, AlphaFold, a ground-breaking AI system,\ncould potentially reshape structural biology. However, the utility of the PLM\nmodule in AlphaFold, Evoformer, has not been explored beyond structure\nprediction. In this paper, we investigate the representation ability of three\npopular PLMs: ESM-1b (single sequence), MSA-Transformer (multiple sequence\nalignment) and Evoformer (structural), with a special focus on Evoformer.\nSpecifically, we aim to answer the following key questions: (i) Does the\nEvoformer trained as part of AlphaFold produce representations amenable to\npredicting protein function? (ii) If yes, can Evoformer replace ESM-1b and\nMSA-Transformer? (ii) How much do these PLMs rely on evolution-related protein\ndata? In this regard, are they complementary to each other? We compare these\nmodels by empirical study along with new insights and conclusions. All code and\ndatasets for reproducibility are available at\nhttps://github.com/elttaes/Revisiting-PLMs.\n",
                "链接": "https://arxiv.org/abs/2206.06583"
            },
            {
                "文章ID": "120970",
                "标题": "An LLM Compiler for Parallel Function Calling",
                "作者": " Sehoon Kim,  Suhong Moon,  Ryan Tabrizi,  Nicholas Lee,  Michael W. Mahoney,  Kurt Keutzer,  Amir Gholami",
                "发布日期": "2023-12-08",
                "摘要": "  Large Language Models (LLMs) have shown remarkable results on various complex\nreasoning benchmarks. The reasoning capabilities of LLMs enable them to execute\nfunction calls, using user-provided functions to overcome their inherent\nlimitations, such as knowledge cutoffs, poor arithmetic skills, or lack of\naccess to private data. This development has expanded LLMs' scope to include\nmulti-function calling, where LLMs are equipped with a variety of functions and\nselect the proper functions based on the context. Multi-function calling\nabilities of LLMs have catalyzed LLM-based software development, allowing them\nto tackle more complex problems. However, current methods for multi-function\ncalling often require sequential reasoning and acting for each function which\ncan result in high latency, cost, and sometimes inaccurate behavior. To address\nthis, we introduce LLMCompiler, which executes functions in parallel to\nefficiently orchestrate multi-function calling. Drawing from the principles of\nclassical compilers, LLMCompiler streamlines parallel function calling with\nthree components: (i) an LLM Planner, formulating execution strategies and\ndependencies; (ii) a Task Fetching Unit, dispatching function calling tasks;\nand (iii) an Executor, executing these tasks in parallel. LLMCompiler\nautomatically computes an optimized orchestration for the function calls and\ncan be used with open-source models such as LLaMA-2. We have benchmarked\nLLMCompiler on a range of tasks including cases with non-trivial\ninter-dependency between function calls, as well as cases that require dynamic\nreplanning based on intermediate results. We observe consistent latency speedup\nof up to 3.7x, cost savings of up to 6.7x, and accuracy improvement of up to\n~9% as compared to ReAct. Additionally, LLMCompiler achieves up to 1.35x\nlatency gain over OpenAI's recent parallel function calling, while achieving\nsimilar accuracy.\n",
                "链接": "https://arxiv.org/abs/2312.04511"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用BERT和RoBERTa进行多语言情感分析的最新论文，要求涵盖2022年以来的研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "112858",
                "标题": "Linked Papers With Code: The Latest in Machine Learning as an RDF\n  Knowledge Graph",
                "作者": " Michael Färber,  David Lamprecht",
                "发布日期": "2023-11-01",
                "摘要": "  In this paper, we introduce Linked Papers With Code (LPWC), an RDF knowledge\ngraph that provides comprehensive, current information about almost 400,000\nmachine learning publications. This includes the tasks addressed, the datasets\nutilized, the methods implemented, and the evaluations conducted, along with\ntheir results. Compared to its non-RDF-based counterpart Papers With Code, LPWC\nnot only translates the latest advancements in machine learning into RDF\nformat, but also enables novel ways for scientific impact quantification and\nscholarly key content recommendation. LPWC is openly accessible at\nhttps://linkedpaperswithcode.com and is licensed under CC-BY-SA 4.0. As a\nknowledge graph in the Linked Open Data cloud, we offer LPWC in multiple\nformats, from RDF dump files to a SPARQL endpoint for direct web queries, as\nwell as a data source with resolvable URIs and links to the data sources\nSemOpenAlex, Wikidata, and DBLP. Additionally, we supply knowledge graph\nembeddings, enabling LPWC to be readily applied in machine learning\napplications.\n",
                "链接": "https://arxiv.org/abs/2310.20475"
            },
            {
                "文章ID": "109901",
                "标题": "Predict the Future from the Past? On the Temporal Data Distribution\n  Shift in Financial Sentiment Classifications",
                "作者": " Yue Guo,  Chenxi Hu,  Yi Yang",
                "发布日期": "2023-10-20",
                "摘要": "  Temporal data distribution shift is prevalent in the financial text. How can\na financial sentiment analysis system be trained in a volatile market\nenvironment that can accurately infer sentiment and be robust to temporal data\ndistribution shifts? In this paper, we conduct an empirical study on the\nfinancial sentiment analysis system under temporal data distribution shifts\nusing a real-world financial social media dataset that spans three years. We\nfind that the fine-tuned models suffer from general performance degradation in\nthe presence of temporal distribution shifts. Furthermore, motivated by the\nunique temporal nature of the financial text, we propose a novel method that\ncombines out-of-distribution detection with time series modeling for temporal\nfinancial sentiment analysis. Experimental results show that the proposed\nmethod enhances the model's capability to adapt to evolving temporal shifts in\na volatile financial market.\n",
                "链接": "https://arxiv.org/abs/2310.12620"
            },
            {
                "文章ID": "95613",
                "标题": "Performance Analysis of Transformer Based Models (BERT, ALBERT and\n  RoBERTa) in Fake News Detection",
                "作者": " Shafna Fitria Nur Azizah,  Hasan Dwi Cahyono,  Sari Widya Sihwi,  Wisnu Widiarto",
                "发布日期": "2023-08-10",
                "摘要": "  Fake news is fake material in a news media format but is not processed\nproperly by news agencies. The fake material can provoke or defame significant\nentities or individuals or potentially even for the personal interests of the\ncreators, causing problems for society. Distinguishing fake news and real news\nis challenging due to limited of domain knowledge and time constraints.\nAccording to the survey, the top three areas most exposed to hoaxes and\nmisinformation by residents are in Banten, DKI Jakarta and West Java. The model\nof transformers is referring to an approach in the field of artificial\nintelligence (AI) in natural language processing utilizing the deep learning\narchitectures. Transformers exercise a powerful attention mechanism to process\ntext in parallel and produce rich and contextual word representations. A\nprevious study indicates a superior performance of a transformer model known as\nBERT over and above non transformer approach. However, some studies suggest the\nperformance can be improved with the use of improved BERT models known as\nALBERT and RoBERTa. However, the modified BERT models are not well explored for\ndetecting fake news in Bahasa Indonesia. In this research, we explore those\ntransformer models and found that ALBERT outperformed other models with 87.6%\naccuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch)\nrespectively. Source code available at:\nhttps://github.com/Shafna81/fakenewsdetection.git\n",
                "链接": "https://arxiv.org/abs/2308.04950"
            },
            {
                "文章ID": "752",
                "标题": "Semantic and sentiment analysis of selected Bhagavad Gita translations\n  using BERT-based language framework",
                "作者": " Rohitash Chandra,  Venkatesh Kulkarni",
                "发布日期": "2022-02-16",
                "摘要": "  It is well known that translations of songs and poems not only break rhythm\nand rhyming patterns, but can also result in loss of semantic information. The\nBhagavad Gita is an ancient Hindu philosophical text originally written in\nSanskrit that features a conversation between Lord Krishna and Arjuna prior to\nthe Mahabharata war. The Bhagavad Gita is also one of the key sacred texts in\nHinduism and is known as the forefront of the Vedic corpus of Hinduism. In the\nlast two centuries, there has been a lot of interest in Hindu philosophy from\nwestern scholars; hence, the Bhagavad Gita has been translated in a number of\nlanguages. However, there is not much work that validates the quality of the\nEnglish translations. Recent progress of language models powered by deep\nlearning has enabled not only translations but a better understanding of\nlanguage and texts with semantic and sentiment analysis. Our work is motivated\nby the recent progress of language models powered by deep learning methods. In\nthis paper, we present a framework that compares selected translations (from\nSanskrit to English) of the Bhagavad Gita using semantic and sentiment\nanalyses. We use hand-labelled sentiment dataset for tuning state-of-art deep\nlearning-based language model known as bidirectional encoder representations\nfrom transformers (BERT). We provide sentiment and semantic analysis for\nselected chapters and verses across translations. Our results show that\nalthough the style and vocabulary in the respective translations vary widely,\nthe sentiment analysis and semantic similarity shows that the message conveyed\nare mostly similar.\n",
                "链接": "https://arxiv.org/abs/2201.03115"
            },
            {
                "文章ID": "90924",
                "标题": "Digital Health Discussion Through Articles Published Until the Year\n  2021: A Digital Topic Modeling Approach",
                "作者": " Junhyoun Sung,  Hyungsook Kim",
                "发布日期": "2023-09-20",
                "摘要": "  The digital health industry has grown in popularity since the 2010s, but\nthere has been limited analysis of the topics discussed in the field across\nacademic disciplines. This study aims to analyze the research trends of digital\nhealth-related articles published on the Web of Science until 2021, in order to\nunderstand the concentration, scope, and characteristics of the research.\n15,950 digital health-related papers from the top 10 academic fields were\nanalyzed using the Web of Science. The papers were grouped into three domains:\npublic health, medicine, and electrical engineering and computer science\n(EECS). Two time periods (2012-2016 and 2017-2021) were compared using Latent\nDirichlet Allocation (LDA) for topic modeling. The number of topics was\ndetermined based on coherence score, and topic compositions were compared using\na homogeneity test. The number of optimal topics varied across domains and time\nperiods. For public health, the first and second halves had 13 and 19 topics,\nrespectively. Medicine had 14 and 25 topics, and EECS had 7 and 21 topics. Text\nanalysis revealed shared topics among the domains, but with variations in\ncomposition. The homogeneity test confirmed significant differences between the\ngroups (adjusted p-value<0.05). Six dominant themes emerged, including journal\narticle methodology, information technology, medical issues, population\ndemographics, social phenomena, and healthcare. Digital health research is\nexpanding and evolving, particularly in relation to Covid-19, where topics such\nas depression and mental disorders, education, and physical activity have\ngained prominence. There was no bias in topic composition among the three\ndomains, but other fields like kinesiology or psychology could contribute to\nfuture digital health research. Exploring expanded topics that reflect people's\nneeds for digital health over time will be crucial.\n",
                "链接": "https://arxiv.org/abs/2307.07130"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "68450",
                "标题": "ChatGPT and a New Academic Reality: Artificial Intelligence-Written\n  Research Papers and the Ethics of the Large Language Models in Scholarly\n  Publishing",
                "作者": " Brady Lund,  Ting Wang,  Nishith Reddy Mannuru,  Bing Nie,  Somipam Shimray,  Ziang Wang",
                "发布日期": "2023-04-03",
                "摘要": "  This paper discusses OpenAIs ChatGPT, a generative pre-trained transformer,\nwhich uses natural language processing to fulfill text-based user requests\n(i.e., a chatbot). The history and principles behind ChatGPT and similar models\nare discussed. This technology is then discussed in relation to its potential\nimpact on academia and scholarly research and publishing. ChatGPT is seen as a\npotential model for the automated preparation of essays and other types of\nscholarly manuscripts. Potential ethical issues that could arise with the\nemergence of large language models like GPT-3, the underlying technology behind\nChatGPT, and its usage by academics and researchers, are discussed and situated\nwithin the context of broader advancements in artificial intelligence, machine\nlearning, and natural language processing for research and scholarly\npublishing.\n",
                "链接": "https://arxiv.org/abs/2303.13367"
            },
            {
                "文章ID": "42411",
                "标题": "On the Evaluation of the Plausibility and Faithfulness of Sentiment\n  Analysis Explanations",
                "作者": " Julia El Zini,  Mohamad Mansour,  Basel Mousi,  Mariette Awad",
                "发布日期": "2022-10-14",
                "摘要": "  Current Explainable AI (ExAI) methods, especially in the NLP field, are\nconducted on various datasets by employing different metrics to evaluate\nseveral aspects. The lack of a common evaluation framework is hindering the\nprogress tracking of such methods and their wider adoption. In this work,\ninspired by offline information retrieval, we propose different metrics and\ntechniques to evaluate the explainability of SA models from two angles. First,\nwe evaluate the strength of the extracted \"rationales\" in faithfully explaining\nthe predicted outcome. Second, we measure the agreement between ExAI methods\nand human judgment on a homegrown dataset1 to reflect on the rationales\nplausibility. Our conducted experiments comprise four dimensions: (1) the\nunderlying architectures of SA models, (2) the approach followed by the ExAI\nmethod, (3) the reasoning difficulty, and (4) the homogeneity of the\nground-truth rationales. We empirically demonstrate that anchors explanations\nare more aligned with the human judgment and can be more confident in\nextracting supporting rationales. As can be foreseen, the reasoning complexity\nof sentiment is shown to thwart ExAI methods from extracting supporting\nevidence. Moreover, a remarkable discrepancy is discerned between the results\nof different explainability methods on the various architectures suggesting the\nneed for consolidation to observe enhanced performance. Predominantly,\ntransformers are shown to exhibit better explainability than convolutional and\nrecurrent architectures. Our work paves the way towards designing more\ninterpretable NLP models and enabling a common evaluation ground for their\nrelative strengths and robustness.\n",
                "链接": "https://arxiv.org/abs/2210.06916"
            },
            {
                "文章ID": "73574",
                "标题": "Text2Time: Transformer-based Article Time Period Prediction",
                "作者": " Karthick Prasad Gunasekaran,  B Chase Babrich,  Saurabh Shirodkar,  Hee Hwang",
                "发布日期": "2023-04-26",
                "摘要": "  The task of predicting the publication period of text documents, such as news\narticles, is an important but less studied problem in the field of natural\nlanguage processing. Predicting the year of a news article can be useful in\nvarious contexts, such as historical research, sentiment analysis, and media\nmonitoring. In this work, we investigate the problem of predicting the\npublication period of a text document, specifically a news article, based on\nits textual content. In order to do so, we created our own extensive labeled\ndataset of over 350,000 news articles published by The New York Times over six\ndecades. In our approach, we use a pretrained BERT model fine-tuned for the\ntask of text classification, specifically for time period prediction.This model\nexceeds our expectations and provides some very impressive results in terms of\naccurately classifying news articles into their respective publication decades.\nThe results beat the performance of the baseline model for this relatively\nunexplored task of time prediction from text.\n",
                "链接": "https://arxiv.org/abs/2304.10859"
            },
            {
                "文章ID": "31048",
                "标题": "Enhancing Collaborative Filtering Recommender with Prompt-Based\n  Sentiment Analysis",
                "作者": " Elliot Dang,  Zheyuan Hu,  Tong Li",
                "发布日期": "2022-07-27",
                "摘要": "  Collaborative Filtering(CF) recommender is a crucial application in the\nonline market and ecommerce. However, CF recommender has been proven to suffer\nfrom persistent problems related to sparsity of the user rating that will\nfurther lead to a cold-start issue. Existing methods address the data sparsity\nissue by applying token-level sentiment analysis that translate text review\ninto sentiment scores as a complement of the user rating. In this paper, we\nattempt to optimize the sentiment analysis with advanced NLP models including\nBERT and RoBERTa, and experiment on whether the CF recommender has been further\nenhanced. We build the recommenders on the Amazon US Reviews dataset, and tune\nthe pretrained BERT and RoBERTa with the traditional fine-tuned paradigm as\nwell as the new prompt-based learning paradigm. Experimental result shows that\nthe recommender enhanced with the sentiment ratings predicted by the fine-tuned\nRoBERTa has the best performance, and achieved 30.7% overall gain by comparing\nMAP, NDCG and precision at K to the baseline recommender. Prompt-based learning\nparadigm, although superior to traditional fine-tune paradigm in pure sentiment\nanalysis, fail to further improve the CF recommender.\n",
                "链接": "https://arxiv.org/abs/2207.12883"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找一下2018年以后使用强化学习做机器翻译任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "29736",
                "标题": "MAD for Robust Reinforcement Learning in Machine Translation",
                "作者": " Domenic Donato,  Lei Yu,  Wang Ling,  Chris Dyer",
                "发布日期": "2022-07-19",
                "摘要": "  We introduce a new distributed policy gradient algorithm and show that it\noutperforms existing reward-aware training procedures such as REINFORCE,\nminimum risk training (MRT) and proximal policy optimization (PPO) in terms of\ntraining stability and generalization performance when optimizing machine\ntranslation models. Our algorithm, which we call MAD (on account of using the\nmean absolute deviation in the importance weighting calculation), has\ndistributed data generators sampling multiple candidates per source sentence on\nworker nodes, while a central learner updates the policy. MAD depends crucially\non two variance reduction strategies: (1) a conditional reward normalization\nmethod that ensures each source sentence has both positive and negative reward\ntranslation examples and (2) a new robust importance weighting scheme that acts\nas a conditional entropy regularizer. Experiments on a variety of translation\ntasks show that policies learned using the MAD algorithm perform very well when\nusing both greedy decoding and beam search, and that the learned policies are\nsensitive to the specific reward used during training.\n",
                "链接": "https://arxiv.org/abs/2207.08583"
            },
            {
                "文章ID": "99348",
                "标题": "Task-Based MoE for Multitask Multilingual Machine Translation",
                "作者": " Hai Pham,  Young Jin Kim,  Subhabrata Mukherjee,  David P. Woodruff,  Barnabas Poczos,  Hany Hassan Awadalla",
                "发布日期": "2023-10-26",
                "摘要": "  Mixture-of-experts (MoE) architecture has been proven a powerful method for\ndiverse tasks in training deep models in many applications. However, current\nMoE implementations are task agnostic, treating all tokens from different tasks\nin the same manner. In this work, we instead design a novel method that\nincorporates task information into MoE models at different granular levels with\nshared dynamic task-based adapters. Our experiments and analysis show the\nadvantages of our approaches over the dense and canonical MoE models on\nmulti-task multilingual machine translations. With task-specific adapters, our\nmodels can additionally generalize to new tasks efficiently.\n",
                "链接": "https://arxiv.org/abs/2308.15772"
            },
            {
                "文章ID": "40957",
                "标题": "Reinforcement Learning with Large Action Spaces for Neural Machine\n  Translation",
                "作者": " Asaf Yehudai,  Leshem Choshen,  Lior Fox,  Omri Abend",
                "发布日期": "2022-10-07",
                "摘要": "  Applying Reinforcement learning (RL) following maximum likelihood estimation\n(MLE) pre-training is a versatile method for enhancing neural machine\ntranslation (NMT) performance. However, recent work has argued that the gains\nproduced by RL for NMT are mostly due to promoting tokens that have already\nreceived a fairly high probability in pre-training. We hypothesize that the\nlarge action space is a main obstacle to RL's effectiveness in MT, and conduct\ntwo sets of experiments that lend support to our hypothesis. First, we find\nthat reducing the size of the vocabulary improves RL's effectiveness. Second,\nwe find that effectively reducing the dimension of the action space without\nchanging the vocabulary also yields notable improvement as evaluated by BLEU,\nsemantic similarity, and human evaluation. Indeed, by initializing the\nnetwork's final fully connected layer (that maps the network's internal\ndimension to the vocabulary dimension), with a layer that generalizes over\nsimilar actions, we obtain a substantial improvement in RL performance: 1.5\nBLEU points on average.\n",
                "链接": "https://arxiv.org/abs/2210.03053"
            },
            {
                "文章ID": "50762",
                "标题": "Summer: WeChat Neural Machine Translation Systems for the WMT22\n  Biomedical Translation Task",
                "作者": " Ernan Li,  Fandong Meng,  Jie Zhou",
                "发布日期": "2022-11-29",
                "摘要": "  This paper introduces WeChat's participation in WMT 2022 shared biomedical\ntranslation task on Chinese to English. Our systems are based on the\nTransformer, and use several different Transformer structures to improve the\nquality of translation. In our experiments, we employ data filtering, data\ngeneration, several variants of Transformer, fine-tuning and model ensemble.\nOur Chinese$\\to$English system, named Summer, achieves the highest BLEU score\namong all submissions.\n",
                "链接": "https://arxiv.org/abs/2211.15022"
            },
            {
                "文章ID": "44053",
                "标题": "The VolcTrans System for WMT22 Multilingual Machine Translation Task",
                "作者": " Xian Qian,  Kai Hu,  Jiaqiang Wang,  Yifeng Liu,  Xingyuan Pan,  Jun Cao,  Mingxuan Wang",
                "发布日期": "2022-10-24",
                "摘要": "  This report describes our VolcTrans system for the WMT22 shared task on\nlarge-scale multilingual machine translation. We participated in the\nunconstrained track which allows the use of external resources. Our system is a\ntransformerbased multilingual model trained on data from multiple sources\nincluding the public training set from the data track, NLLB data provided by\nMeta AI, self-collected parallel corpora, and pseudo bitext from\nback-translation. A series of heuristic rules clean both bilingual and\nmonolingual texts. On the official test set, our system achieves 17.3 BLEU,\n21.9 spBLEU, and 41.9 chrF2++ on average over all language pairs. The average\ninference speed is 11.5 sentences per second using a single Nvidia Tesla V100\nGPU. Our code and trained models are available at\nhttps://github.com/xian8/wmt22\n",
                "链接": "https://arxiv.org/abs/2210.11599"
            },
            {
                "文章ID": "48289",
                "标题": "Findings of the Covid-19 MLIA Machine Translation Task",
                "作者": " Francisco Casacuberta,  Alexandru Ceausu,  Khalid Choukri,  Miltos Deligiannis,  Miguel Domingo,  Mercedes García-Martínez,  Manuel Herranz,  Guillaume Jacquet,  Vassilis Papavassiliou,  Stelios Piperidis,  Prokopis Prokopidis,  Dimitris Roussis,  Marwa Hadj Salah",
                "发布日期": "2022-11-15",
                "摘要": "  This work presents the results of the machine translation (MT) task from the\nCovid-19 MLIA @ Eval initiative, a community effort to improve the generation\nof MT systems focused on the current Covid-19 crisis. Nine teams took part in\nthis event, which was divided in two rounds and involved seven different\nlanguage pairs. Two different scenarios were considered: one in which only the\nprovided data was allowed, and a second one in which the use of external\nresources was allowed. Overall, best approaches were based on multilingual\nmodels and transfer learning, with an emphasis on the importance of applying a\ncleaning process to the training data.\n",
                "链接": "https://arxiv.org/abs/2211.07465"
            },
            {
                "文章ID": "62269",
                "标题": "Natural Language-conditioned Reinforcement Learning with Inside-out Task\n  Language Development and Translation",
                "作者": " Jing-Cheng Pang,  Xin-Yu Yang,  Si-Hang Yang,  Yang Yu",
                "发布日期": "2023-02-21",
                "摘要": "  Natural Language-conditioned reinforcement learning (RL) enables the agents\nto follow human instructions. Previous approaches generally implemented\nlanguage-conditioned RL by providing human instructions in natural language\n(NL) and training a following policy. In this outside-in approach, the policy\nneeds to comprehend the NL and manage the task simultaneously. However, the\nunbounded NL examples often bring much extra complexity for solving concrete RL\ntasks, which can distract policy learning from completing the task. To ease the\nlearning burden of the policy, we investigate an inside-out scheme for natural\nlanguage-conditioned RL by developing a task language (TL) that is task-related\nand unique. The TL is used in RL to achieve highly efficient and effective\npolicy training. Besides, a translator is trained to translate NL into TL. We\nimplement this scheme as TALAR (TAsk Language with predicAte Representation)\nthat learns multiple predicates to model object relationships as the TL.\nExperiments indicate that TALAR not only better comprehends NL instructions but\nalso leads to a better instruction-following policy that improves 13.4% success\nrate and adapts to unseen expressions of NL instruction. The TL can also be an\neffective task abstraction, naturally compatible with hierarchical RL.\n",
                "链接": "https://arxiv.org/abs/2302.09368"
            },
            {
                "文章ID": "6229",
                "标题": "CALCS 2021 Shared Task: Machine Translation for Code-Switched Data",
                "作者": " Shuguang Chen,  Gustavo Aguilar,  Anirudh Srinivasan,  Mona Diab,  Thamar Solorio",
                "发布日期": "2022-02-22",
                "摘要": "  To date, efforts in the code-switching literature have focused for the most\npart on language identification, POS, NER, and syntactic parsing. In this\npaper, we address machine translation for code-switched social media data. We\ncreate a community shared task. We provide two modalities for participation:\nsupervised and unsupervised. For the supervised setting, participants are\nchallenged to translate English into Hindi-English (Eng-Hinglish) in a single\ndirection. For the unsupervised setting, we provide the following language\npairs: English and Spanish-English (Eng-Spanglish), and English and Modern\nStandard Arabic-Egyptian Arabic (Eng-MSAEA) in both directions. We share\ninsights and challenges in curating the \"into\" code-switching language\nevaluation data. Further, we provide baselines for all language pairs in the\nshared task. The leaderboard for the shared task comprises 12 individual system\nsubmissions corresponding to 5 different teams. The best performance achieved\nis 12.67% BLEU score for English to Hinglish and 25.72% BLEU score for MSAEA to\nEnglish.\n",
                "链接": "https://arxiv.org/abs/2202.09625"
            },
            {
                "文章ID": "39469",
                "标题": "An Automatic Evaluation of the WMT22 General Machine Translation Task",
                "作者": " Benjamin Marie",
                "发布日期": "2022-11-10",
                "摘要": "  This report presents an automatic evaluation of the general machine\ntranslation task of the Seventh Conference on Machine Translation (WMT22). It\nevaluates a total of 185 systems for 21 translation directions including\nhigh-resource to low-resource language pairs and from closely related to\ndistant languages. This large-scale automatic evaluation highlights some of the\ncurrent limits of state-of-the-art machine translation systems. It also shows\nhow automatic metrics, namely chrF, BLEU, and COMET, can complement themselves\nto mitigate their own limits in terms of interpretability and accuracy.\n",
                "链接": "https://arxiv.org/abs/2209.14172"
            },
            {
                "文章ID": "54369",
                "标题": "Synthetic Pre-Training Tasks for Neural Machine Translation",
                "作者": " Zexue He,  Graeme Blackwood,  Rameswar Panda,  Julian McAuley,  Rogerio Feris",
                "发布日期": "2023-06-01",
                "摘要": "  Pre-training models with large crawled corpora can lead to issues such as\ntoxicity and bias, as well as copyright and privacy concerns. A promising way\nof alleviating such concerns is to conduct pre-training with synthetic tasks\nand data, since no real-world information is ingested by the model. Our goal in\nthis paper is to understand the factors that contribute to the effectiveness of\npre-training models when using synthetic resources, particularly in the context\nof neural machine translation. We propose several novel approaches to\npre-training translation models that involve different levels of lexical and\nstructural knowledge, including: 1) generating obfuscated data from a large\nparallel corpus 2) concatenating phrase pairs extracted from a small\nword-aligned corpus, and 3) generating synthetic parallel data without real\nhuman language corpora. Our experiments on multiple language pairs reveal that\npre-training benefits can be realized even with high levels of obfuscation or\npurely synthetic parallel data. We hope the findings from our comprehensive\nempirical analysis will shed light on understanding what matters for NMT\npre-training, as well as pave the way for the development of more efficient and\nless toxic models.\n",
                "链接": "https://arxiv.org/abs/2212.09864"
            }
        ]
    },
    {
        "question": {
            "question": "请找出使用Transformer模型并在大规模数据集上进行预训练的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "114192",
                "标题": "ClimateSet: A Large-Scale Climate Model Dataset for Machine Learning",
                "作者": " Julia Kaltenborn,  Charlotte E. E. Lange,  Venkatesh Ramesh,  Philippe Brouillard,  Yaniv Gurwicz,  Chandni Nagda,  Jakob Runge,  Peer Nowack,  David Rolnick",
                "发布日期": "2023-11-08",
                "摘要": "  Climate models have been key for assessing the impact of climate change and\nsimulating future climate scenarios. The machine learning (ML) community has\ntaken an increased interest in supporting climate scientists' efforts on\nvarious tasks such as climate model emulation, downscaling, and prediction\ntasks. Many of those tasks have been addressed on datasets created with single\nclimate models. However, both the climate science and ML communities have\nsuggested that to address those tasks at scale, we need large, consistent, and\nML-ready climate model datasets. Here, we introduce ClimateSet, a dataset\ncontaining the inputs and outputs of 36 climate models from the Input4MIPs and\nCMIP6 archives. In addition, we provide a modular dataset pipeline for\nretrieving and preprocessing additional climate models and scenarios. We\nshowcase the potential of our dataset by using it as a benchmark for ML-based\nclimate model emulation. We gain new insights about the performance and\ngeneralization capabilities of the different ML models by analyzing their\nperformance across different climate models. Furthermore, the dataset can be\nused to train an ML emulator on several climate models instead of just one.\nSuch a \"super emulator\" can quickly project new climate change scenarios,\ncomplementing existing scenarios already provided to policymakers. We believe\nClimateSet will create the basis needed for the ML community to tackle\nclimate-related tasks at scale.\n",
                "链接": "https://arxiv.org/abs/2311.03721"
            },
            {
                "文章ID": "113032",
                "标题": "fMRI-PTE: A Large-scale fMRI Pretrained Transformer Encoder for\n  Multi-Subject Brain Activity Decoding",
                "作者": " Xuelin Qian,  Yun Wang,  Jingyang Huo,  Jianfeng Feng,  Yanwei Fu",
                "发布日期": "2023-11-02",
                "摘要": "  The exploration of brain activity and its decoding from fMRI data has been a\nlongstanding pursuit, driven by its potential applications in brain-computer\ninterfaces, medical diagnostics, and virtual reality. Previous approaches have\nprimarily focused on individual subject analysis, highlighting the need for a\nmore universal and adaptable framework, which is the core motivation behind our\nwork. In this work, we propose fMRI-PTE, an innovative auto-encoder approach\nfor fMRI pre-training, with a focus on addressing the challenges of varying\nfMRI data dimensions due to individual brain differences. Our approach involves\ntransforming fMRI signals into unified 2D representations, ensuring consistency\nin dimensions and preserving distinct brain activity patterns. We introduce a\nnovel learning strategy tailored for pre-training 2D fMRI images, enhancing the\nquality of reconstruction. fMRI-PTE's adaptability with image generators\nenables the generation of well-represented fMRI features, facilitating various\ndownstream tasks, including within-subject and cross-subject brain activity\ndecoding. Our contributions encompass introducing fMRI-PTE, innovative data\ntransformation, efficient training, a novel learning strategy, and the\nuniversal applicability of our approach. Extensive experiments validate and\nsupport our claims, offering a promising foundation for further research in\nthis domain.\n",
                "链接": "https://arxiv.org/abs/2311.00342"
            },
            {
                "文章ID": "88555",
                "标题": "MIS-FM: 3D Medical Image Segmentation using Foundation Models Pretrained\n  on a Large-Scale Unannotated Dataset",
                "作者": " Guotai Wang,  Jianghao Wu,  Xiangde Luo,  Xinglong Liu,  Kang Li,  Shaoting Zhang",
                "发布日期": "2023-06-30",
                "摘要": "  Pretraining with large-scale 3D volumes has a potential for improving the\nsegmentation performance on a target medical image dataset where the training\nimages and annotations are limited. Due to the high cost of acquiring\npixel-level segmentation annotations on the large-scale pretraining dataset,\npretraining with unannotated images is highly desirable. In this work, we\npropose a novel self-supervised learning strategy named Volume Fusion (VF) for\npretraining 3D segmentation models. It fuses several random patches from a\nforeground sub-volume to a background sub-volume based on a predefined set of\ndiscrete fusion coefficients, and forces the model to predict the fusion\ncoefficient of each voxel, which is formulated as a self-supervised\nsegmentation task without manual annotations. Additionally, we propose a novel\nnetwork architecture based on parallel convolution and transformer blocks that\nis suitable to be transferred to different downstream segmentation tasks with\nvarious scales of organs and lesions. The proposed model was pretrained with\n110k unannotated 3D CT volumes, and experiments with different downstream\nsegmentation targets including head and neck organs, thoracic/abdominal organs\nshowed that our pretrained model largely outperformed training from scratch and\nseveral state-of-the-art self-supervised training methods and segmentation\nmodels. The code and pretrained model are available at\nhttps://github.com/openmedlab/MIS-FM.\n",
                "链接": "https://arxiv.org/abs/2306.16925"
            },
            {
                "文章ID": "78781",
                "标题": "DMDD: A Large-Scale Dataset for Dataset Mentions Detection",
                "作者": " Huitong Pan,  Qi Zhang,  Eduard Dragut,  Cornelia Caragea,  Longin Jan Latecki",
                "发布日期": "2023-10-06",
                "摘要": "  The recognition of dataset names is a critical task for automatic information\nextraction in scientific literature, enabling researchers to understand and\nidentify research opportunities. However, existing corpora for dataset mention\ndetection are limited in size and naming diversity. In this paper, we introduce\nthe Dataset Mentions Detection Dataset (DMDD), the largest publicly available\ncorpus for this task. DMDD consists of the DMDD main corpus, comprising 31,219\nscientific articles with over 449,000 dataset mentions weakly annotated in the\nformat of in-text spans, and an evaluation set, which comprises of 450\nscientific articles manually annotated for evaluation purposes. We use DMDD to\nestablish baseline performance for dataset mention detection and linking. By\nanalyzing the performance of various models on DMDD, we are able to identify\nopen problems in dataset mention detection. We invite the community to use our\ndataset as a challenge to develop novel dataset mention detection models.\n",
                "链接": "https://arxiv.org/abs/2305.11779"
            },
            {
                "文章ID": "29374",
                "标题": "Plex: Towards Reliability using Pretrained Large Model Extensions",
                "作者": " Dustin Tran,  Jeremiah Liu,  Michael W. Dusenberry,  Du Phan,  Mark Collier,  Jie Ren,  Kehang Han,  Zi Wang,  Zelda Mariet,  Huiyi Hu,  Neil Band,  Tim G. J. Rudner,  Karan Singhal,  Zachary Nado,  Joost van Amersfoort,  Andreas Kirsch,  Rodolphe Jenatton,  Nithum Thain,  Honglin Yuan,  Kelly Buchanan,  Kevin Murphy,  D. Sculley,  Yarin Gal,  Zoubin Ghahramani,  Jasper Snoek,  Balaji Lakshminarayanan",
                "发布日期": "2022-07-18",
                "摘要": "  A recent trend in artificial intelligence is the use of pretrained models for\nlanguage and vision tasks, which have achieved extraordinary performance but\nalso puzzling failures. Probing these models' abilities in diverse ways is\ntherefore critical to the field. In this paper, we explore the reliability of\nmodels, where we define a reliable model as one that not only achieves strong\npredictive performance but also performs well consistently over many\ndecision-making tasks involving uncertainty (e.g., selective prediction, open\nset recognition), robust generalization (e.g., accuracy and proper scoring\nrules such as log-likelihood on in- and out-of-distribution datasets), and\nadaptation (e.g., active learning, few-shot uncertainty). We devise 10 types of\ntasks over 40 datasets in order to evaluate different aspects of reliability on\nboth vision and language domains. To improve reliability, we developed ViT-Plex\nand T5-Plex, pretrained large model extensions for vision and language\nmodalities, respectively. Plex greatly improves the state-of-the-art across\nreliability tasks, and simplifies the traditional protocol as it improves the\nout-of-the-box performance and does not require designing scores or tuning the\nmodel for each task. We demonstrate scaling effects over model sizes up to 1B\nparameters and pretraining dataset sizes up to 4B examples. We also demonstrate\nPlex's capabilities on challenging tasks including zero-shot open set\nrecognition, active learning, and uncertainty in conversational language\nunderstanding.\n",
                "链接": "https://arxiv.org/abs/2207.07411"
            },
            {
                "文章ID": "104233",
                "标题": "Small-scale proxies for large-scale Transformer training instabilities",
                "作者": " Mitchell Wortsman,  Peter J. Liu,  Lechao Xiao,  Katie Everett,  Alex Alemi,  Ben Adlam,  John D. Co-Reyes,  Izzeddin Gur,  Abhishek Kumar,  Roman Novak,  Jeffrey Pennington,  Jascha Sohl-dickstein,  Kelvin Xu,  Jaehoon Lee,  Justin Gilmer,  Simon Kornblith",
                "发布日期": "2023-10-18",
                "摘要": "  Teams that have trained large Transformer-based models have reported training\ninstabilities at large scale that did not appear when training with the same\nhyperparameters at smaller scales. Although the causes of such instabilities\nare of scientific interest, the amount of resources required to reproduce them\nhas made investigation difficult. In this work, we seek ways to reproduce and\nstudy training stability and instability at smaller scales. First, we focus on\ntwo sources of training instability described in previous work: the growth of\nlogits in attention layers (Dehghani et al., 2023) and divergence of the output\nlogits from the log probabilities (Chowdhery et al., 2022). By measuring the\nrelationship between learning rate and loss across scales, we show that these\ninstabilities also appear in small models when training at high learning rates,\nand that mitigations previously employed at large scales are equally effective\nin this regime. This prompts us to investigate the extent to which other known\noptimizer and model interventions influence the sensitivity of the final loss\nto changes in the learning rate. To this end, we study methods such as warm-up,\nweight decay, and the $\\mu$Param (Yang et al., 2022), and combine techniques to\ntrain small models that achieve similar losses across orders of magnitude of\nlearning rate variation. Finally, to conclude our exploration we study two\ncases where instabilities can be predicted before they emerge by examining the\nscaling behavior of model activation and gradient norms.\n",
                "链接": "https://arxiv.org/abs/2309.14322"
            },
            {
                "文章ID": "52728",
                "标题": "DialogCC: Large-Scale Multi-Modal Dialogue Dataset",
                "作者": " Young-Jun Lee,  Byungsoo Ko,  Han-Gyu Kim,  Ho-Jin Choi",
                "发布日期": "2022-12-09",
                "摘要": "  As sharing images in an instant message is a crucial factor, there has been\nactive research on learning a image-text multi-modal dialogue model. However,\ntraining a well-generalized multi-modal dialogue model is challenging because\nexisting multi-modal dialogue datasets contain a small number of data, limited\ntopics, and a restricted variety of images per dialogue. In this paper, we\npresent a multi-modal dialogue dataset creation pipeline that involves matching\nlarge-scale images to dialogues based on CLIP similarity. Using this automatic\npipeline, we propose a large-scale multi-modal dialogue dataset, DialogCC,\nwhich covers diverse real-world topics and various images per dialogue. With\nextensive experiments, we demonstrate that training a multi-modal dialogue\nmodel with our dataset can improve generalization performance. Additionally,\nexisting models trained with our dataset achieve state-of-the-art performance\non image and text retrieval tasks. The source code and the dataset will be\nreleased after publication.\n",
                "链接": "https://arxiv.org/abs/2212.04119"
            },
            {
                "文章ID": "84598",
                "标题": "Large-scale Dataset Pruning with Dynamic Uncertainty",
                "作者": " Muyang He,  Shuo Yang,  Tiejun Huang,  Bo Zhao",
                "发布日期": "2023-06-09",
                "摘要": "  The state of the art of many learning tasks, e.g., image classification, is\nadvanced by collecting larger datasets and then training larger models on them.\nAs the outcome, the increasing computational cost is becoming unaffordable. In\nthis paper, we investigate how to prune the large-scale datasets, and thus\nproduce an informative subset for training sophisticated deep models with\nnegligible performance drop. We propose a simple yet effective dataset pruning\nmethod by exploring both the prediction uncertainty and training dynamics. To\nour knowledge, this is the first work to study dataset pruning on large-scale\ndatasets, i.e., ImageNet-1K and ImageNet-21K, and advanced models, i.e., Swin\nTransformer and ConvNeXt. Extensive experimental results indicate that our\nmethod outperforms the state of the art and achieves 75% lossless compression\nratio on both ImageNet-1K and ImageNet-21K. The code and pruned datasets are\navailable at https://github.com/BAAI-DCAI/Dataset-Pruning.\n",
                "链接": "https://arxiv.org/abs/2306.05175"
            },
            {
                "文章ID": "87484",
                "标题": "DISCO-10M: A Large-Scale Music Dataset",
                "作者": " Luca A. Lanzendörfer,  Florian Grötschla,  Emil Funke,  Roger Wattenhofer",
                "发布日期": "2023-10-06",
                "摘要": "  Music datasets play a crucial role in advancing research in machine learning\nfor music. However, existing music datasets suffer from limited size,\naccessibility, and lack of audio resources. To address these shortcomings, we\npresent DISCO-10M, a novel and extensive music dataset that surpasses the\nlargest previously available music dataset by an order of magnitude. To ensure\nhigh-quality data, we implement a multi-stage filtering process. This process\nincorporates similarities based on textual descriptions and audio embeddings.\nMoreover, we provide precomputed CLAP embeddings alongside DISCO-10M,\nfacilitating direct application on various downstream tasks. These embeddings\nenable efficient exploration of machine learning applications on the provided\ndata. With DISCO-10M, we aim to democratize and facilitate new research to help\nadvance the development of novel machine learning models for music.\n",
                "链接": "https://arxiv.org/abs/2306.13512"
            }
        ]
    },
    {
        "question": {
            "question": "找一下使用强化学习做代码生成的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "64359",
                "标题": "Reinforcement Learning Guided Multi-Objective Exam Paper Generation",
                "作者": " Yuhu Shang,  Xuexiong Luo,  Lihong Wang,  Hao Peng,  Xiankun Zhang,  Yimeng Ren,  Kun Liang",
                "发布日期": "2023-03-03",
                "摘要": "  To reduce the repetitive and complex work of instructors, exam paper\ngeneration (EPG) technique has become a salient topic in the intelligent\neducation field, which targets at generating high-quality exam paper\nautomatically according to instructor-specified assessment criteria. The\ncurrent advances utilize the ability of heuristic algorithms to optimize\nseveral well-known objective constraints, such as difficulty degree, number of\nquestions, etc., for producing optimal solutions. However, in real scenarios,\nconsidering other equally relevant objectives (e.g., distribution of exam\nscores, skill coverage) is extremely important. Besides, how to develop an\nautomatic multi-objective solution that finds an optimal subset of questions\nfrom a huge search space of large-sized question datasets and thus composes a\nhigh-quality exam paper is urgent but non-trivial. To this end, we skillfully\ndesign a reinforcement learning guided Multi-Objective Exam Paper Generation\nframework, termed MOEPG, to simultaneously optimize three exam domain-specific\nobjectives including difficulty degree, distribution of exam scores, and skill\ncoverage. Specifically, to accurately measure the skill proficiency of the\nexaminee group, we first employ deep knowledge tracing to model the interaction\ninformation between examinees and response logs. We then design the flexible\nExam Q-Network, a function approximator, which automatically selects the\nappropriate question to update the exam paper composition process. Later, MOEPG\ndivides the decision space into multiple subspaces to better guide the updated\ndirection of the exam paper. Through extensive experiments on two real-world\ndatasets, we demonstrate that MOEPG is feasible in addressing the multiple\ndilemmas of exam paper generation scenario.\n",
                "链接": "https://arxiv.org/abs/2303.01042"
            },
            {
                "文章ID": "30296",
                "标题": "CodeT: Code Generation with Generated Tests",
                "作者": " Bei Chen,  Fengji Zhang,  Anh Nguyen,  Daoguang Zan,  Zeqi Lin,  Jian-Guang Lou,  Weizhu Chen",
                "发布日期": "2022-11-24",
                "摘要": "  The task of generating code solutions for a given programming problem can\nbenefit from the use of pre-trained language models such as Codex, which can\nproduce multiple diverse samples. However, a major challenge for this task is\nto select the most appropriate solution from the multiple samples generated by\nthe pre-trained language models. A natural way to evaluate the quality and\ncorrectness of a code solution is to run it against a set of test cases, but\nthe manual creation of such test cases is often costly and time-consuming. In\nthis paper, we propose a novel method, CodeT, that leverages the same\npre-trained language models to automatically generate test cases for the code\nsamples, thus reducing the human effort and increasing the coverage of the test\nscenarios. CodeT then executes the code samples using the generated test cases,\nand performs a dual execution agreement, which considers both the consistency\nof the outputs against the generated test cases and the agreement of the\noutputs with other code samples. We conduct comprehensive experiments on four\nbenchmarks, HumanEval, MBPP, APPS and CodeContests, using five different\npre-trained language models with varying sizes and capabilities. Our results\nshow that CodeT can significantly improve the performance of code solution\nselection over previous methods, achieving remarkable and consistent gains\nacross different models and benchmarks. For instance, CodeT improves the pass@1\nmetric on HumanEval to 65.8%, which represents an absolute improvement of 18.8%\nover the code-davinci-002 model, and an absolute improvement of more than 20%\nover the previous state-of-the-art results.\n",
                "链接": "https://arxiv.org/abs/2207.10397"
            },
            {
                "文章ID": "51256",
                "标题": "Coder Reviewer Reranking for Code Generation",
                "作者": " Tianyi Zhang,  Tao Yu,  Tatsunori B. Hashimoto,  Mike Lewis,  Wen-tau Yih,  Daniel Fried,  Sida I. Wang",
                "发布日期": "2022-11-30",
                "摘要": "  Sampling diverse programs from a code language model and reranking with model\nlikelihood is a popular method for code generation but it is prone to\npreferring degenerate solutions. Inspired by collaborative programming, we\npropose Coder-Reviewer reranking. We augment Coder language models from past\nwork, which generate programs given language instructions, with Reviewer\nmodels, which evaluate the likelihood of the instruction given the generated\nprograms. We perform an extensive study across six datasets with eight models\nfrom three model families. Experimental results show that Coder-Reviewer\nreranking leads to consistent and significant improvement (up to 17% absolute\naccuracy gain) over reranking with the Coder model only. When combined with\nexecutability filtering, Coder-Reviewer reranking can often outperform the\nminimum Bayes risk method. Coder-Reviewer reranking is easy to implement by\nprompting, can generalize to different programming languages, and works well\nwith off-the-shelf hyperparameters.\n",
                "链接": "https://arxiv.org/abs/2211.16490"
            },
            {
                "文章ID": "59289",
                "标题": "Execution-based Code Generation using Deep Reinforcement Learning",
                "作者": " Parshin Shojaee,  Aneesh Jain,  Sindhu Tipirneni,  Chandan K. Reddy",
                "发布日期": "2023-07-21",
                "摘要": "  The utilization of programming language (PL) models, pre-trained on\nlarge-scale code corpora, as a means of automating software engineering\nprocesses has demonstrated considerable potential in streamlining various code\ngeneration tasks such as code completion, code translation, and program\nsynthesis. However, current approaches mainly rely on supervised fine-tuning\nobjectives borrowed from text generation, neglecting unique sequence-level\ncharacteristics of code, including but not limited to compilability as well as\nsyntactic and functional correctness. To address this limitation, we propose\nPPOCoder, a new framework for code generation that synergistically combines\npre-trained PL models with Proximal Policy Optimization (PPO) which is a widely\nused deep reinforcement learning technique. By utilizing non-differentiable\nfeedback from code execution and structure alignment, PPOCoder seamlessly\nintegrates external code-specific knowledge into the model optimization\nprocess. It's important to note that PPOCoder is a task-agnostic and\nmodel-agnostic framework that can be used across different code generation\ntasks and PLs. Extensive experiments on three code generation tasks demonstrate\nthe effectiveness of our proposed approach compared to SOTA methods, achieving\nsignificant improvements in compilation success rates and functional\ncorrectness across different PLs.\n",
                "链接": "https://arxiv.org/abs/2301.13816"
            },
            {
                "文章ID": "27761",
                "标题": "CodeRL: Mastering Code Generation through Pretrained Models and Deep\n  Reinforcement Learning",
                "作者": " Hung Le,  Yue Wang,  Akhilesh Deepak Gotmare,  Silvio Savarese,  Steven C. H. Hoi",
                "发布日期": "2022-11-04",
                "摘要": "  Program synthesis or code generation aims to generate a program that\nsatisfies a problem specification. Recent approaches using large-scale\npretrained language models (LMs) have shown promising results, yet they have\nsome critical limitations. In particular, they often follow a standard\nsupervised fine-tuning procedure to train a code generation model only from the\npairs of natural-language problem descriptions and ground-truth programs. Such\nparadigm largely ignores some important but potentially useful signals in the\nproblem specification such as unit tests, which thus often results in poor\nperformance when solving complex unseen coding tasks. To address the\nlimitations, we propose \"CodeRL\", a new framework for program synthesis tasks\nthrough pretrained LMs and deep reinforcement learning (RL). Specifically,\nduring training, we treat the code-generating LM as an actor network, and\nintroduce a critic network that is trained to predict the functional\ncorrectness of generated programs and provide dense feedback signals to the\nactor. During inference, we introduce a new generation procedure with a\ncritical sampling strategy that allows a model to automatically regenerate\nprograms based on feedback from example unit tests and critic scores. For the\nmodel backbones, we extended the encoder-decoder architecture of CodeT5 with\nenhanced learning objectives, larger model sizes, and better pretraining data.\nOur method not only achieves new SOTA results on the challenging APPS\nbenchmark, but also shows strong zero-shot transfer capability with new SOTA\nresults on the simpler MBPP benchmark.\n",
                "链接": "https://arxiv.org/abs/2207.01780"
            },
            {
                "文章ID": "110290",
                "标题": "Automatic Unit Test Data Generation and Actor-Critic Reinforcement\n  Learning for Code Synthesis",
                "作者": " Philip John Gorinski,  Matthieu Zimmer,  Gerasimos Lampouras,  Derrick Goh Xin Deik,  Ignacio Iacobacci",
                "发布日期": "2023-10-23",
                "摘要": "  The advent of large pre-trained language models in the domain of Code\nSynthesis has shown remarkable performance on various benchmarks, treating the\nproblem of Code Generation in a fashion similar to Natural Language Generation,\ntrained with a Language Modelling (LM) objective. In addition, the property of\nprogramming language code being precisely evaluable with respect to its\nsemantics -- through the use of Unit Tests to check its functional correctness\n-- lends itself to using Reinforcement Learning (RL) as a further training\nparadigm. Previous work has shown that RL can be applied as such to improve\nmodels' coding capabilities; however, such RL-based methods rely on a reward\nsignal based on defined Unit Tests, which are much harder to obtain compared to\nthe huge crawled code datasets used in LM objectives. In this work, we present\na novel approach to automatically obtain data consisting of function signatures\nand associated Unit Tests, suitable for RL training of Code Synthesis models.\nWe also introduce a straightforward, simple yet effective Actor-Critic RL\ntraining scheme and show that it, in conjunction with automatically generated\ntraining data, leads to improvement of a pre-trained code language model's\nperformance by up to 9.9% improvement over the original underlying code\nsynthesis LM, and up to 4.3% over RL-based models trained with standard PPO or\nCodeRL.\n",
                "链接": "https://arxiv.org/abs/2310.13669"
            },
            {
                "文章ID": "72734",
                "标题": "Stochastic Code Generation",
                "作者": " Swapnil Sharma,  Nikita Anand, V Kranthi Kiran G.",
                "发布日期": "2023-04-18",
                "摘要": "  Large language models pre-trained for code generation can generate\nhigh-quality short code but often struggle with generating coherent long code\nand understanding higher-level or system-level specifications. This issue is\nalso observed in language modeling for long text generation, and one proposed\nsolution is the use of a latent stochastic process. This approach involves\ngenerating a document plan and then producing text that is consistent with it.\n  In this study, we investigate whether this technique can be applied to code\ngeneration to improve coherence. We base our proposed encoder and decoder on\nthe pre-trained GPT-2 based CodeParrot model and utilize the APPS dataset for\ntraining. We evaluate our results using the HumanEval benchmark and observe\nthat the modified Time Control model performs similarly to CodeParrot on this\nevaluation.\n",
                "链接": "https://arxiv.org/abs/2304.08243"
            },
            {
                "文章ID": "89545",
                "标题": "Exploring Continual Learning for Code Generation Models",
                "作者": " Prateek Yadav,  Qing Sun,  Hantian Ding,  Xiaopeng Li,  Dejiao Zhang,  Ming Tan,  Xiaofei Ma,  Parminder Bhatia,  Ramesh Nallapati,  Murali Krishna Ramanathan,  Mohit Bansal,  Bing Xiang",
                "发布日期": "2023-07-06",
                "摘要": "  Large-scale code generation models such as Codex and CodeT5 have achieved\nimpressive performance. However, libraries are upgraded or deprecated very\nfrequently and re-training large-scale language models is computationally\nexpensive. Therefore, Continual Learning (CL) is an important aspect that\nremains underexplored in the code domain. In this paper, we introduce a\nbenchmark called CodeTask-CL that covers a wide range of tasks, including code\ngeneration, translation, summarization, and refinement, with different input\nand output programming languages. Next, on our CodeTask-CL benchmark, we\ncompare popular CL techniques from NLP and Vision domains. We find that\neffective methods like Prompt Pooling (PP) suffer from catastrophic forgetting\ndue to the unstable training of the prompt selection mechanism caused by stark\ndistribution shifts in coding tasks. We address this issue with our proposed\nmethod, Prompt Pooling with Teacher Forcing (PP-TF), that stabilizes training\nby enforcing constraints on the prompt selection mechanism and leads to a\n21.54% improvement over Prompt Pooling. Along with the benchmark, we establish\na training pipeline that can be used for CL on code models, which we believe\ncan motivate further development of CL methods for code models. Our code is\navailable at https://github.com/amazon-science/codetaskcl-pptf\n",
                "链接": "https://arxiv.org/abs/2307.02435"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "119060",
                "标题": "Self-Infilling Code Generation",
                "作者": " Lin Zheng,  Jianbo Yuan,  Zhi Zhang,  Hongxia Yang,  Lingpeng Kong",
                "发布日期": "2023-12-01",
                "摘要": "  This work introduces a general code generation framework that incorporates\ninfilling operations into auto-regressive decoding. Our approach capitalizes on\nthe observation that recent code language models with infilling capabilities\ncan perform \\emph{self-infilling}: whereas infilling operations aim to fill in\nthe middle based on a predefined prefix and suffix, self-infilling sequentially\ngenerates both such surrounding context and the infilled content. We utilize\nthis feature to develop an infilling-augmented decoding process that\nfacilitates non-monotonic generation. This approach allows for postponing the\ngeneration of uncertain code snippets until a definitive suffix is established,\nleading to improved control over the generation sequence. In addition, it\nfacilitates a looping mechanism, which can iteratively update and synchronize\neach piece of generation in a cyclic manner. Extensive experiments are\nconducted to demonstrate that our proposed decoding process is effective in\nenhancing regularity and quality across several code generation benchmarks.\n",
                "链接": "https://arxiv.org/abs/2311.17972"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下关于大模型使用工具的安全性的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "94169",
                "标题": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language\n  Models",
                "作者": " Cheng-Yu Hsieh,  Si-An Chen,  Chun-Liang Li,  Yasuhisa Fujii,  Alexander Ratner,  Chen-Yu Lee,  Ranjay Krishna,  Tomas Pfister",
                "发布日期": "2023-08-02",
                "摘要": "  Today, large language models (LLMs) are taught to use new tools by providing\na few demonstrations of the tool's usage. Unfortunately, demonstrations are\nhard to acquire, and can result in undesirable biased usage if the wrong\ndemonstration is chosen. Even in the rare scenario that demonstrations are\nreadily available, there is no principled selection protocol to determine how\nmany and which ones to provide. As tasks grow more complex, the selection\nsearch grows combinatorially and invariably becomes intractable. Our work\nprovides an alternative to demonstrations: tool documentation. We advocate the\nuse of tool documentation, descriptions for the individual tool usage, over\ndemonstrations. We substantiate our claim through three main empirical findings\non 6 tasks across both vision and language modalities. First, on existing\nbenchmarks, zero-shot prompts with only tool documentation are sufficient for\neliciting proper tool usage, achieving performance on par with few-shot\nprompts. Second, on a newly collected realistic tool-use dataset with hundreds\nof available tool APIs, we show that tool documentation is significantly more\nvaluable than demonstrations, with zero-shot documentation significantly\noutperforming few-shot without documentation. Third, we highlight the benefits\nof tool documentations by tackling image generation and video tracking using\njust-released unseen state-of-the-art models as tools. Finally, we highlight\nthe possibility of using tool documentation to automatically enable new\napplications: by using nothing more than the documentation of GroundingDino,\nStable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the\njust-released Grounded-SAM and Track Anything models.\n",
                "链接": "https://arxiv.org/abs/2308.00675"
            },
            {
                "文章ID": "95072",
                "标题": "TPTU: Large Language Model-based AI Agents for Task Planning and Tool\n  Usage",
                "作者": " Jingqing Ruan,  Yihong Chen,  Bin Zhang,  Zhiwei Xu,  Tianpeng Bao,  Guoqing Du,  Shiwei Shi,  Hangyu Mao,  Ziyue Li,  Xingyu Zeng,  Rui Zhao",
                "发布日期": "2023-11-08",
                "摘要": "  With recent advancements in natural language processing, Large Language\nModels (LLMs) have emerged as powerful tools for various real-world\napplications. Despite their prowess, the intrinsic generative abilities of LLMs\nmay prove insufficient for handling complex tasks which necessitate a\ncombination of task planning and the usage of external tools. In this paper, we\nfirst propose a structured framework tailored for LLM-based AI Agents and\ndiscuss the crucial capabilities necessary for tackling intricate problems.\nWithin this framework, we design two distinct types of agents (i.e., one-step\nagent and sequential agent) to execute the inference process. Subsequently, we\ninstantiate the framework using various LLMs and evaluate their Task Planning\nand Tool Usage (TPTU) abilities on typical tasks. By highlighting key findings\nand challenges, our goal is to provide a helpful resource for researchers and\npractitioners to leverage the power of LLMs in their AI applications. Our study\nemphasizes the substantial potential of these models, while also identifying\nareas that need more investigation and improvement.\n",
                "链接": "https://arxiv.org/abs/2308.03427"
            },
            {
                "文章ID": "116754",
                "标题": "TPTU-v2: Boosting Task Planning and Tool Usage of Large Language\n  Model-based Agents in Real-world Systems",
                "作者": " Yilun Kong,  Jingqing Ruan,  Yihong Chen,  Bin Zhang,  Tianpeng Bao,  Shiwei Shi,  Guoqing Du,  Xiaoru Hu,  Hangyu Mao,  Ziyue Li,  Xingyu Zeng,  Rui Zhao",
                "发布日期": "2023-11-21",
                "摘要": "  Large Language Models (LLMs) have demonstrated proficiency in addressing\ntasks that necessitate a combination of task planning and the usage of external\ntools that require a blend of task planning and the utilization of external\ntools, such as APIs. However, real-world complex systems present three\nprevalent challenges concerning task planning and tool usage: (1) The real\nsystem usually has a vast array of APIs, so it is impossible to feed the\ndescriptions of all APIs to the prompt of LLMs as the token length is limited;\n(2) the real system is designed for handling complex tasks, and the base LLMs\ncan hardly plan a correct sub-task order and API-calling order for such tasks;\n(3) Similar semantics and functionalities among APIs in real systems create\nchallenges for both LLMs and even humans in distinguishing between them. In\nresponse, this paper introduces a comprehensive framework aimed at enhancing\nthe Task Planning and Tool Usage (TPTU) abilities of LLM-based agents operating\nwithin real-world systems. Our framework comprises three key components\ndesigned to address these challenges: (1) the API Retriever selects the most\npertinent APIs for the user task among the extensive array available; (2) LLM\nFinetuner tunes a base LLM so that the finetuned LLM can be more capable for\ntask planning and API calling; (3) the Demo Selector adaptively retrieves\ndifferent demonstrations related to hard-to-distinguish APIs, which is further\nused for in-context learning to boost the final performance. We validate our\nmethods using a real-world commercial system as well as an open-sourced\nacademic dataset, and the outcomes clearly showcase the efficacy of each\nindividual component as well as the integrated framework.\n",
                "链接": "https://arxiv.org/abs/2311.11315"
            },
            {
                "文章ID": "116523",
                "标题": "ToolTalk: Evaluating Tool-Usage in a Conversational Setting",
                "作者": " Nicholas Farn,  Richard Shin",
                "发布日期": "2023-11-21",
                "摘要": "  Large language models (LLMs) have displayed massive improvements in reasoning\nand decision-making skills and can hold natural conversations with users. Many\nrecent works seek to augment LLM-based assistants with external tools so they\ncan access private or up-to-date information and carry out actions on behalf of\nusers. To better measure the performance of these assistants, this paper\nintroduces ToolTalk, a benchmark consisting of complex user intents requiring\nmulti-step tool usage specified through dialogue. ToolTalk contains 28 tools\ngrouped into 7 plugins, and includes a complete simulated implementation of\neach tool, allowing for fully automated evaluation of assistants that rely on\nexecution feedback. ToolTalk also emphasizes tools that externally affect the\nworld rather than only tools for referencing or searching information. We\nevaluate GPT-3.5 and GPT-4 on ToolTalk resulting in success rates of 26% and\n50% respectively. Our analysis of the errors reveals three major categories and\nsuggests some future directions for improvement. We release ToolTalk at\nhttps://github.com/microsoft/ToolTalk.\n",
                "链接": "https://arxiv.org/abs/2311.10775"
            },
            {
                "文章ID": "123332",
                "标题": "CLOVA: A Closed-Loop Visual Assistant with Tool Usage and Update",
                "作者": " Zhi Gao,  Yuntao Du,  Xintong Zhang,  Xiaojian Ma,  Wenjuan Han,  Song-Chun Zhu,  Qing Li",
                "发布日期": "2023-12-19",
                "摘要": "  Leveraging large language models (LLMs) to integrate off-the-shelf tools\n(e.g., visual models and image processing functions) is a promising research\ndirection to build powerful visual assistants for solving diverse visual tasks.\nHowever, the learning capability is rarely explored in existing methods, as\nthey freeze the used tools after deployment, thereby limiting the\ngeneralization to new environments requiring specific knowledge. In this paper,\nwe propose CLOVA, a Closed-LOop Visual Assistant to address this limitation,\nwhich encompasses inference, reflection, and learning phases in a closed-loop\nframework. During inference, LLMs generate programs and execute corresponding\ntools to accomplish given tasks. The reflection phase introduces a multimodal\nglobal-local reflection scheme to analyze whether and which tool needs to be\nupdated based on environmental feedback. Lastly, the learning phase uses three\nflexible manners to collect training data in real-time and introduces a novel\nprompt tuning scheme to update the tools, enabling CLOVA to efficiently learn\nspecific knowledge for new environments without human involvement. Experiments\nshow that CLOVA outperforms tool-usage methods by 5% in visual question\nanswering and multiple-image reasoning tasks, by 10% in knowledge tagging\ntasks, and by 20% in image editing tasks, highlighting the significance of the\nlearning capability for general visual assistants.\n",
                "链接": "https://arxiv.org/abs/2312.10908"
            },
            {
                "文章ID": "98955",
                "标题": "Using ChatGPT as a Static Application Security Testing Tool",
                "作者": " Atieh Bakhshandeh,  Abdalsamad Keramatfar,  Amir Norouzi,  Mohammad Mahdi Chekidehkhoun",
                "发布日期": "2023-08-29",
                "摘要": "  In recent years, artificial intelligence has had a conspicuous growth in\nalmost every aspect of life. One of the most applicable areas is security code\nreview, in which a lot of AI-based tools and approaches have been proposed.\nRecently, ChatGPT has caught a huge amount of attention with its remarkable\nperformance in following instructions and providing a detailed response.\nRegarding the similarities between natural language and code, in this paper, we\nstudy the feasibility of using ChatGPT for vulnerability detection in Python\nsource code. Toward this goal, we feed an appropriate prompt along with\nvulnerable data to ChatGPT and compare its results on two datasets with the\nresults of three widely used Static Application Security Testing tools (Bandit,\nSemgrep and SonarQube). We implement different kinds of experiments with\nChatGPT and the results indicate that ChatGPT reduces the false positive and\nfalse negative rates and has the potential to be used for Python source code\nvulnerability detection.\n",
                "链接": "https://arxiv.org/abs/2308.14434"
            },
            {
                "文章ID": "81272",
                "标题": "Large Language Models as Tool Makers",
                "作者": " Tianle Cai,  Xuezhi Wang,  Tengyu Ma,  Xinyun Chen,  Denny Zhou",
                "发布日期": "2023-05-29",
                "摘要": "  Recent research shows the potential of enhancing the problem-solving ability\nof large language models (LLMs) through the use of external tools. However,\nprior work along this line depends on the availability of existing tools. In\nthis work, we take an initial step towards removing this dependency by\nproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),\nwhere LLMs create their own reusable tools for problem-solving. Our approach\nconsists of two key phases: 1) tool making: an LLM acts as the tool maker that\ncrafts tools for given tasks, where a tool is implemented as a Python utility\nfunction. 2) tool using: an LLM acts as the tool user, which applies the tool\nbuilt by the tool maker for problem-solving. The tool user can be either the\nsame or a different LLM from the tool maker. Tool-making enables an LLM to\ncontinually generate tools that can be applied to different requests so that\nfuture requests can call the corresponding APIs when beneficial for solving the\ntasks. Furthermore, the division of labor among LLMs for tool-making and\ntool-using phases introduces the opportunity to achieve cost effectiveness\nwithout degrading the quality of generated tools and problem solutions. For\nexample, recognizing that tool-making demands more sophisticated capabilities\nthan tool-using, we can apply a powerful yet resource-intensive model as the\ntool maker, and a lightweight while cost-effective model as the tool user. We\nvalidate the effectiveness of our approach across a variety of complex\nreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and\nGPT-3.5 as the tool user, LATM can achieve performance that is on par with\nusing GPT-4 for both tool making and tool using, while the inference cost is\nsignificantly reduced.\n",
                "链接": "https://arxiv.org/abs/2305.17126"
            },
            {
                "文章ID": "88346",
                "标题": "MLSMM: Machine Learning Security Maturity Model",
                "作者": " Felix Jedrzejewski,  Davide Fucci,  Oleksandr Adamov",
                "发布日期": "2023-06-29",
                "摘要": "  Assessing the maturity of security practices during the development of\nMachine Learning (ML) based software components has not gotten as much\nattention as traditional software development. In this Blue Sky idea paper, we\npropose an initial Machine Learning Security Maturity Model (MLSMM) which\norganizes security practices along the ML-development lifecycle and, for each,\nestablishes three levels of maturity. We envision MLSMM as a step towards\ncloser collaboration between industry and academia.\n",
                "链接": "https://arxiv.org/abs/2306.16127"
            },
            {
                "文章ID": "111559",
                "标题": "netFound: Foundation Model for Network Security",
                "作者": " Satyandra Guthula,  Navya Battula,  Roman Beltiukov,  Wenbo Guo,  Arpit Gupta",
                "发布日期": "2023-11-29",
                "摘要": "  In ML for network security, traditional workflows rely on high-quality\nlabeled data and manual feature engineering, but limited datasets and human\nexpertise hinder feature selection, leading to models struggling to capture\ncrucial relationships and generalize effectively. Inspired by recent\nadvancements in ML application domains like GPT-4 and Vision Transformers, we\nhave developed netFound, a foundational model for network security. This model\nundergoes pre-training using self-supervised algorithms applied to readily\navailable unlabeled network packet traces. netFound's design incorporates\nhierarchical and multi-modal attributes of network traffic, effectively\ncapturing hidden networking contexts, including application logic,\ncommunication protocols, and network conditions.\n  With this pre-trained foundation in place, we can fine-tune netFound for a\nwide array of downstream tasks, even when dealing with low-quality, limited,\nand noisy labeled data. Our experiments demonstrate netFound's superiority over\nexisting state-of-the-art ML-based solutions across three distinct network\ndownstream tasks: traffic classification, network intrusion detection, and APT\ndetection. Furthermore, we emphasize netFound's robustness against noisy and\nmissing labels, as well as its ability to generalize across temporal variations\nand diverse network environments. Finally, through a series of ablation\nstudies, we provide comprehensive insights into how our design choices enable\nnetFound to more effectively capture hidden networking contexts, further\nsolidifying its performance and utility in network security applications.\n",
                "链接": "https://arxiv.org/abs/2310.17025"
            },
            {
                "文章ID": "94691",
                "标题": "A large language model-assisted education tool to provide feedback on\n  open-ended responses",
                "作者": " Jordan K. Matelsky,  Felipe Parodi,  Tony Liu,  Richard D. Lange,  Konrad P. Kording",
                "发布日期": "2023-08-07",
                "摘要": "  Open-ended questions are a favored tool among instructors for assessing\nstudent understanding and encouraging critical exploration of course material.\nProviding feedback for such responses is a time-consuming task that can lead to\noverwhelmed instructors and decreased feedback quality. Many instructors resort\nto simpler question formats, like multiple-choice questions, which provide\nimmediate feedback but at the expense of personalized and insightful comments.\nHere, we present a tool that uses large language models (LLMs), guided by\ninstructor-defined criteria, to automate responses to open-ended questions. Our\ntool delivers rapid personalized feedback, enabling students to quickly test\ntheir knowledge and identify areas for improvement. We provide open-source\nreference implementations both as a web application and as a Jupyter Notebook\nwidget that can be used with instructional coding or math notebooks. With\ninstructor guidance, LLMs hold promise to enhance student learning outcomes and\nelevate instructional methodologies.\n",
                "链接": "https://arxiv.org/abs/2308.02439"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下对使用GPT生成数据集的训练步骤进行改进的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "81391",
                "标题": "DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of\n  GPT-Generated Text",
                "作者": " Xianjun Yang,  Wei Cheng,  Yue Wu,  Linda Petzold,  William Yang Wang,  Haifeng Chen",
                "发布日期": "2023-10-05",
                "摘要": "  Large language models (LLMs) have notably enhanced the fluency and diversity\nof machine-generated text. However, this progress also presents a significant\nchallenge in detecting the origin of a given text, and current research on\ndetection methods lags behind the rapid evolution of LLMs. Conventional\ntraining-based methods have limitations in flexibility, particularly when\nadapting to new domains, and they often lack explanatory power. To address this\ngap, we propose a novel training-free detection strategy called Divergent\nN-Gram Analysis (DNA-GPT). Given a text, we first truncate it in the middle and\nthen use only the preceding portion as input to the LLMs to regenerate the new\nremaining parts. By analyzing the differences between the original and new\nremaining parts through N-gram analysis in black-box or probability divergence\nin white-box, we unveil significant discrepancies between the distribution of\nmachine-generated text and the distribution of human-written text. We conducted\nextensive experiments on the most advanced LLMs from OpenAI, including\ntext-davinci-003, GPT-3.5-turbo, and GPT-4, as well as open-source models such\nas GPT-NeoX-20B and LLaMa-13B. Results show that our zero-shot approach\nexhibits state-of-the-art performance in distinguishing between human and\nGPT-generated text on four English and one German dataset, outperforming\nOpenAI's own classifier, which is trained on millions of text. Additionally,\nour methods provide reasonable explanations and evidence to support our claim,\nwhich is a unique feature of explainable detection. Our method is also robust\nunder the revised text attack and can additionally solve model sourcing. Codes\nare available at https://github.com/Xianjun-Yang/DNA-GPT.\n",
                "链接": "https://arxiv.org/abs/2305.17359"
            },
            {
                "文章ID": "80486",
                "标题": "Training on Thin Air: Improve Image Classification with Generated Data",
                "作者": " Yongchao Zhou,  Hshmat Sahak,  Jimmy Ba",
                "发布日期": "2023-05-25",
                "摘要": "  Acquiring high-quality data for training discriminative models is a crucial\nyet challenging aspect of building effective predictive systems. In this paper,\nwe present Diffusion Inversion, a simple yet effective method that leverages\nthe pre-trained generative model, Stable Diffusion, to generate diverse,\nhigh-quality training data for image classification. Our approach captures the\noriginal data distribution and ensures data coverage by inverting images to the\nlatent space of Stable Diffusion, and generates diverse novel training images\nby conditioning the generative model on noisy versions of these vectors. We\nidentify three key components that allow our generated images to successfully\nsupplant the original dataset, leading to a 2-3x enhancement in sample\ncomplexity and a 6.5x decrease in sampling time. Moreover, our approach\nconsistently outperforms generic prompt-based steering methods and KNN\nretrieval baseline across a wide range of datasets. Additionally, we\ndemonstrate the compatibility of our approach with widely-used data\naugmentation techniques, as well as the reliability of the generated data in\nsupporting various neural architectures and enhancing few-shot learning.\n",
                "链接": "https://arxiv.org/abs/2305.15316"
            },
            {
                "文章ID": "79102",
                "标题": "GPT Paternity Test: GPT Generated Text Detection with GPT Genetic\n  Inheritance",
                "作者": " Xiao Yu,  Yuang Qi,  Kejiang Chen,  Guoqiang Chen,  Xi Yang,  Pengyuan Zhu,  Weiming Zhang,  Nenghai Yu",
                "发布日期": "2023-05-23",
                "摘要": "  Large Language Models (LLMs) can generate texts that carry the risk of\nvarious misuses, including plagiarism, planting fake reviews on e-commerce\nplatforms, or creating fake social media postings that can sway election\nresults. Detecting whether a text is machine-generated has thus become\nincreasingly important. While machine-learning-based detection strategies\nexhibit superior performance, they often lack generalizability, limiting their\npracticality. In this work, we introduce GPT Paternity Test (GPT-Pat), which\nreliably detects machine-generated text across varied datasets. Given a text\nunder scrutiny, we leverage ChatGPT to generate a corresponding question and\nprovide a re-answer to the question. By comparing the similarity between the\noriginal text and the generated re-answered text, it can be determined whether\nthe text is machine-generated. GPT-Pat consists of a Siamese network to compute\nthe similarity between the original text and the generated re-answered text and\na binary classifier. Our method achieved an average accuracy of 94.57% on four\ngeneralization test sets, surpassing the state-of-the-art RoBERTa-based method\nby 12.34%. The accuracy drop of our method is only about half of that of the\nRoBERTa-based method when it is attacked by re-translation and polishing.\n",
                "链接": "https://arxiv.org/abs/2305.12519"
            },
            {
                "文章ID": "79177",
                "标题": "G3Detector: General GPT-Generated Text Detector",
                "作者": " Haolan Zhan,  Xuanli He,  Qiongkai Xu,  Yuxiang Wu,  Pontus Stenetorp",
                "发布日期": "2023-08-07",
                "摘要": "  The burgeoning progress in the field of Large Language Models (LLMs) heralds\nsignificant benefits due to their unparalleled capacities. However, it is\ncritical to acknowledge the potential misuse of these models, which could give\nrise to a spectrum of social and ethical dilemmas. Despite numerous preceding\nefforts centered around distinguishing synthetic text, most existing detection\nsystems fail to identify data synthesized by the latest LLMs, such as ChatGPT\nand GPT-4. In response to this challenge, we introduce an unpretentious yet\npotent detection approach proficient in identifying synthetic text across a\nwide array of fields. Moreover, our detector demonstrates outstanding\nperformance uniformly across various model architectures and decoding\nstrategies. It also possesses the capability to identify text generated\nutilizing a potent detection-evasion technique. Our comprehensive research\nunderlines our commitment to boosting the robustness and efficiency of\nmachine-generated text detection mechanisms, particularly in the context of\nswiftly progressing and increasingly adaptive AI technologies.\n",
                "链接": "https://arxiv.org/abs/2305.12680"
            },
            {
                "文章ID": "68411",
                "标题": "Enriching Neural Network Training Dataset to Improve Worst-Case\n  Performance Guarantees",
                "作者": " Rahul Nellikkath,  Spyros Chatzivasileiadis",
                "发布日期": "2023-03-24",
                "摘要": "  Machine learning algorithms, especially Neural Networks (NNs), are a valuable\ntool used to approximate non-linear relationships, like the AC-Optimal Power\nFlow (AC-OPF), with considerable accuracy -- and achieving a speedup of several\norders of magnitude when deployed for use. Often in power systems literature,\nthe NNs are trained with a fixed dataset generated prior to the training\nprocess. In this paper, we show that adapting the NN training dataset during\ntraining can improve the NN performance and substantially reduce its worst-case\nviolations. This paper proposes an algorithm that identifies and enriches the\ntraining dataset with critical datapoints that reduce the worst-case violations\nand deliver a neural network with improved worst-case performance guarantees.\nWe demonstrate the performance of our algorithm in four test power systems,\nranging from 39-buses to 162-buses.\n",
                "链接": "https://arxiv.org/abs/2303.13228"
            },
            {
                "文章ID": "77375",
                "标题": "GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content",
                "作者": " Yutian Chen,  Hao Kang,  Vivian Zhai,  Liangze Li,  Rita Singh,  Bhiksha Raj",
                "发布日期": "2023-05-19",
                "摘要": "  This paper presents a novel approach for detecting ChatGPT-generated vs.\nhuman-written text using language models. To this end, we first collected and\nreleased a pre-processed dataset named OpenGPTText, which consists of rephrased\ncontent generated using ChatGPT. We then designed, implemented, and trained two\ndifferent models for text classification, using Robustly Optimized BERT\nPretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5),\nrespectively. Our models achieved remarkable results, with an accuracy of over\n97% on the test dataset, as evaluated through various metrics. Furthermore, we\nconducted an interpretability study to showcase our model's ability to extract\nand differentiate key features between human-written and ChatGPT-generated\ntext. Our findings provide important insights into the effective use of\nlanguage models to detect generated text.\n",
                "链接": "https://arxiv.org/abs/2305.07969"
            },
            {
                "文章ID": "19557",
                "标题": "A two-steps approach to improve the performance of Android malware\n  detectors",
                "作者": " Nadia Daoudi,  Kevin Allix,  Tegawendé F. Bissyandé,  Jacques Klein",
                "发布日期": "2022-05-18",
                "摘要": "  The popularity of Android OS has made it an appealing target to malware\ndevelopers. To evade detection, including by ML-based techniques, attackers\ninvest in creating malware that closely resemble legitimate apps. In this\npaper, we propose GUIDED RETRAINING, a supervised representation learning-based\nmethod that boosts the performance of a malware detector. First, the dataset is\nsplit into \"easy\" and \"difficult\" samples, where difficulty is associated to\nthe prediction probabilities yielded by a malware detector: for difficult\nsamples, the probabilities are such that the classifier is not confident on the\npredictions, which have high error rates. Then, we apply our GUIDED RETRAINING\nmethod on the difficult samples to improve their classification. For the subset\nof \"easy\" samples, the base malware detector is used to make the final\npredictions since the error rate on that subset is low by construction. For the\nsubset of \"difficult\" samples, we rely on GUIDED RETRAINING, which leverages\nthe correct predictions and the errors made by the base malware detector to\nguide the retraining process. GUIDED RETRAINING focuses on the difficult\nsamples: it learns new embeddings of these samples using Supervised Contrastive\nLearning and trains an auxiliary classifier for the final predictions. We\nvalidate our method on four state-of-the-art Android malware detection\napproaches using over 265k malware and benign apps, and we demonstrate that\nGUIDED RETRAINING can reduce up to 40.41% prediction errors made by the malware\ndetectors. Our method is generic and designed to enhance the classification\nperformance on a binary classification task. Consequently, it can be applied to\nother classification problems beyond Android malware detection.\n",
                "链接": "https://arxiv.org/abs/2205.08265"
            },
            {
                "文章ID": "4574",
                "标题": "Semantic features of object concepts generated with GPT-3",
                "作者": " Hannes Hansen,  Martin N. Hebart",
                "发布日期": "2022-05-11",
                "摘要": "  Semantic features have been playing a central role in investigating the\nnature of our conceptual representations. Yet the enormous time and effort\nrequired to empirically sample and norm features from human raters has\nrestricted their use to a limited set of manually curated concepts. Given\nrecent promising developments with transformer-based language models, here we\nasked whether it was possible to use such models to automatically generate\nmeaningful lists of properties for arbitrary object concepts and whether these\nmodels would produce features similar to those found in humans. To this end, we\nprobed a GPT-3 model to generate semantic features for 1,854 objects and\ncompared automatically-generated features to existing human feature norms.\nGPT-3 generated many more features than humans, yet showed a similar\ndistribution in the types of generated features. Generated feature norms\nrivaled human norms in predicting similarity, relatedness, and category\nmembership, while variance partitioning demonstrated that these predictions\nwere driven by similar variance in humans and GPT-3. Together, these results\nhighlight the potential of large language models to capture important facets of\nhuman knowledge and yield a new approach for automatically generating\ninterpretable feature sets, thus drastically expanding the potential use of\nsemantic features in psychological and linguistic studies.\n",
                "链接": "https://arxiv.org/abs/2202.03753"
            },
            {
                "文章ID": "81531",
                "标题": "Evaluating GPT-3 Generated Explanations for Hateful Content Moderation",
                "作者": " Han Wang,  Ming Shan Hee,  Md Rabiul Awal,  Kenny Tsu Wei Choo,  Roy Ka-Wei Lee",
                "发布日期": "2023-08-31",
                "摘要": "  Recent research has focused on using large language models (LLMs) to generate\nexplanations for hate speech through fine-tuning or prompting. Despite the\ngrowing interest in this area, these generated explanations' effectiveness and\npotential limitations remain poorly understood. A key concern is that these\nexplanations, generated by LLMs, may lead to erroneous judgments about the\nnature of flagged content by both users and content moderators. For instance,\nan LLM-generated explanation might inaccurately convince a content moderator\nthat a benign piece of content is hateful. In light of this, we propose an\nanalytical framework for examining hate speech explanations and conducted an\nextensive survey on evaluating such explanations. Specifically, we prompted\nGPT-3 to generate explanations for both hateful and non-hateful content, and a\nsurvey was conducted with 2,400 unique respondents to evaluate the generated\nexplanations. Our findings reveal that (1) human evaluators rated the\nGPT-generated explanations as high quality in terms of linguistic fluency,\ninformativeness, persuasiveness, and logical soundness, (2) the persuasive\nnature of these explanations, however, varied depending on the prompting\nstrategy employed, and (3) this persuasiveness may result in incorrect\njudgments about the hatefulness of the content. Our study underscores the need\nfor caution in applying LLM-generated explanations for content moderation. Code\nand results are available at https://github.com/Social-AI-Studio/GPT3-HateEval.\n",
                "链接": "https://arxiv.org/abs/2305.17680"
            },
            {
                "文章ID": "83635",
                "标题": "Efficient GPT Model Pre-training using Tensor Train Matrix\n  Representation",
                "作者": " Viktoriia Chekalina,  Georgii Novikov,  Julia Gusak,  Ivan Oseledets,  Alexander Panchenko",
                "发布日期": "2023-06-06",
                "摘要": "  Large-scale transformer models have shown remarkable performance in language\nmodelling tasks. However, such models feature billions of parameters, leading\nto difficulties in their deployment and prohibitive training costs from\nscratch. To reduce the number of the parameters in the GPT-2 architecture, we\nreplace the matrices of fully-connected layers with the corresponding Tensor\nTrain Matrix~(TTM) structure. Finally, we customize forward and backward\noperations through the TTM-based layer for simplicity and the stableness of\nfurther training. % The resulting GPT-2-based model stores up to 40% fewer\nparameters, showing the perplexity comparable to the original model. On the\ndownstream tasks, including language understanding and text summarization, the\nmodel performs similarly to the original GPT-2 model. The proposed tensorized\nlayers could be used to efficiently pre-training other Transformer models.\n",
                "链接": "https://arxiv.org/abs/2306.02697"
            }
        ]
    },
    {
        "question": {
            "question": "请找到利用clip做开放词汇检测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "104220",
                "标题": "CLIP-DIY: CLIP Dense Inference Yields Open-Vocabulary Semantic\n  Segmentation For-Free",
                "作者": " Monika Wysoczańska,  Michaël Ramamonjisoa,  Tomasz Trzciński,  Oriane Siméoni",
                "发布日期": "2023-11-29",
                "摘要": "  The emergence of CLIP has opened the way for open-world image perception. The\nzero-shot classification capabilities of the model are impressive but are\nharder to use for dense tasks such as image segmentation. Several methods have\nproposed different modifications and learning schemes to produce dense output.\nInstead, we propose in this work an open-vocabulary semantic segmentation\nmethod, dubbed CLIP-DIY, which does not require any additional training or\nannotations, but instead leverages existing unsupervised object localization\napproaches. In particular, CLIP-DIY is a multi-scale approach that directly\nexploits CLIP classification abilities on patches of different sizes and\naggregates the decision in a single map. We further guide the segmentation\nusing foreground/background scores obtained using unsupervised object\nlocalization methods. With our method, we obtain state-of-the-art zero-shot\nsemantic segmentation results on PASCAL VOC and perform on par with the best\nmethods on COCO. The code is available at\nhttp://github.com/wysoczanska/clip-diy\n",
                "链接": "https://arxiv.org/abs/2309.14289"
            },
            {
                "文章ID": "41351",
                "标题": "Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP",
                "作者": " Feng Liang,  Bichen Wu,  Xiaoliang Dai,  Kunpeng Li,  Yinan Zhao,  Hang Zhang,  Peizhao Zhang,  Peter Vajda,  Diana Marculescu",
                "发布日期": "2023-04-04",
                "摘要": "  Open-vocabulary semantic segmentation aims to segment an image into semantic\nregions according to text descriptions, which may not have been seen during\ntraining. Recent two-stage methods first generate class-agnostic mask proposals\nand then leverage pre-trained vision-language models, e.g., CLIP, to classify\nmasked regions. We identify the performance bottleneck of this paradigm to be\nthe pre-trained CLIP model, since it does not perform well on masked images. To\naddress this, we propose to finetune CLIP on a collection of masked image\nregions and their corresponding text descriptions. We collect training data by\nmining an existing image-caption dataset (e.g., COCO Captions), using CLIP to\nmatch masked image regions to nouns in the image captions. Compared with the\nmore precise and manually annotated segmentation labels with fixed classes\n(e.g., COCO-Stuff), we find our noisy but diverse dataset can better retain\nCLIP's generalization ability. Along with finetuning the entire model, we\nutilize the \"blank\" areas in masked images using a method we dub mask prompt\ntuning. Experiments demonstrate mask prompt tuning brings significant\nimprovement without modifying any weights of CLIP, and it can further improve a\nfully finetuned model. In particular, when trained on COCO and evaluated on\nADE20K-150, our best model achieves 29.6% mIoU, which is +8.5% higher than the\nprevious state-of-the-art. For the first time, open-vocabulary generalist\nmodels match the performance of supervised specialist models in 2017 without\ndataset-specific adaptations.\n",
                "链接": "https://arxiv.org/abs/2210.04150"
            },
            {
                "文章ID": "50058",
                "标题": "Open-vocabulary Attribute Detection",
                "作者": " María A. Bravo,  Sudhanshu Mittal,  Simon Ging,  Thomas Brox",
                "发布日期": "2023-03-10",
                "摘要": "  Vision-language modeling has enabled open-vocabulary tasks where predictions\ncan be queried using any text prompt in a zero-shot manner. Existing\nopen-vocabulary tasks focus on object classes, whereas research on object\nattributes is limited due to the lack of a reliable attribute-focused\nevaluation benchmark. This paper introduces the Open-Vocabulary Attribute\nDetection (OVAD) task and the corresponding OVAD benchmark. The objective of\nthe novel task and benchmark is to probe object-level attribute information\nlearned by vision-language models. To this end, we created a clean and densely\nannotated test set covering 117 attribute classes on the 80 object classes of\nMS COCO. It includes positive and negative annotations, which enables\nopen-vocabulary evaluation. Overall, the benchmark consists of 1.4 million\nannotations. For reference, we provide a first baseline method for\nopen-vocabulary attribute detection. Moreover, we demonstrate the benchmark's\nvalue by studying the attribute detection performance of several foundation\nmodels. Project page https://ovad-benchmark.github.io\n",
                "链接": "https://arxiv.org/abs/2211.12914"
            },
            {
                "文章ID": "68353",
                "标题": "CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting\n  and Anchor Pre-Matching",
                "作者": " Xiaoshi Wu,  Feng Zhu,  Rui Zhao,  Hongsheng Li",
                "发布日期": "2023-03-24",
                "摘要": "  Open-vocabulary detection (OVD) is an object detection task aiming at\ndetecting objects from novel categories beyond the base categories on which the\ndetector is trained. Recent OVD methods rely on large-scale visual-language\npre-trained models, such as CLIP, for recognizing novel objects. We identify\nthe two core obstacles that need to be tackled when incorporating these models\ninto detector training: (1) the distribution mismatch that happens when\napplying a VL-model trained on whole images to region recognition tasks; (2)\nthe difficulty of localizing objects of unseen classes. To overcome these\nobstacles, we propose CORA, a DETR-style framework that adapts CLIP for\nOpen-vocabulary detection by Region prompting and Anchor pre-matching. Region\nprompting mitigates the whole-to-region distribution gap by prompting the\nregion features of the CLIP-based region classifier. Anchor pre-matching helps\nlearning generalizable object localization by a class-aware matching mechanism.\nWe evaluate CORA on the COCO OVD benchmark, where we achieve 41.7 AP50 on novel\nclasses, which outperforms the previous SOTA by 2.4 AP50 even without resorting\nto extra training data. When extra training data is available, we train\nCORA$^+$ on both ground-truth base-category annotations and additional pseudo\nbounding box labels computed by CORA. CORA$^+$ achieves 43.1 AP50 on the COCO\nOVD benchmark and 28.1 box APr on the LVIS OVD benchmark.\n",
                "链接": "https://arxiv.org/abs/2303.13076"
            },
            {
                "文章ID": "12649",
                "标题": "PromptDet: Towards Open-vocabulary Detection using Uncurated Images",
                "作者": " Chengjian Feng,  Yujie Zhong,  Zequn Jie,  Xiangxiang Chu,  Haibing Ren,  Xiaolin Wei,  Weidi Xie,  Lin Ma",
                "发布日期": "2022-07-19",
                "摘要": "  The goal of this work is to establish a scalable pipeline for expanding an\nobject detector towards novel/unseen categories, using zero manual annotations.\nTo achieve that, we make the following four contributions: (i) in pursuit of\ngeneralisation, we propose a two-stage open-vocabulary object detector, where\nthe class-agnostic object proposals are classified with a text encoder from\npre-trained visual-language model; (ii) To pair the visual latent space (of RPN\nbox proposals) with that of the pre-trained text encoder, we propose the idea\nof regional prompt learning to align the textual embedding space with regional\nvisual object features; (iii) To scale up the learning procedure towards\ndetecting a wider spectrum of objects, we exploit the available online resource\nvia a novel self-training framework, which allows to train the proposed\ndetector on a large corpus of noisy uncurated web images. Lastly, (iv) to\nevaluate our proposed detector, termed as PromptDet, we conduct extensive\nexperiments on the challenging LVIS and MS-COCO dataset. PromptDet shows\nsuperior performance over existing approaches with fewer additional training\nimages and zero manual annotations whatsoever. Project page with code:\nhttps://fcjian.github.io/promptdet.\n",
                "链接": "https://arxiv.org/abs/2203.16513"
            },
            {
                "文章ID": "68341",
                "标题": "Open-Vocabulary Object Detection using Pseudo Caption Labels",
                "作者": " Han-Cheol Cho,  Won Young Jhoo,  Wooyoung Kang,  Byungseok Roh",
                "发布日期": "2023-03-24",
                "摘要": "  Recent open-vocabulary detection methods aim to detect novel objects by\ndistilling knowledge from vision-language models (VLMs) trained on a vast\namount of image-text pairs. To improve the effectiveness of these methods,\nresearchers have utilized datasets with a large vocabulary that contains a\nlarge number of object classes, under the assumption that such data will enable\nmodels to extract comprehensive knowledge on the relationships between various\nobjects and better generalize to unseen object classes. In this study, we argue\nthat more fine-grained labels are necessary to extract richer knowledge about\nnovel objects, including object attributes and relationships, in addition to\ntheir names. To address this challenge, we propose a simple and effective\nmethod named Pseudo Caption Labeling (PCL), which utilizes an image captioning\nmodel to generate captions that describe object instances from diverse\nperspectives. The resulting pseudo caption labels offer dense samples for\nknowledge distillation. On the LVIS benchmark, our best model trained on the\nde-duplicated VisualGenome dataset achieves an AP of 34.5 and an APr of 30.6,\ncomparable to the state-of-the-art performance. PCL's simplicity and\nflexibility are other notable features, as it is a straightforward\npre-processing technique that can be used with any image captioning model\nwithout imposing any restrictions on model architecture or training process.\n",
                "链接": "https://arxiv.org/abs/2303.13040"
            },
            {
                "文章ID": "116861",
                "标题": "CastDet: Toward Open Vocabulary Aerial Object Detection with\n  CLIP-Activated Student-Teacher Learning",
                "作者": " Yan Li,  Weiwei Guo,  Dunyun He,  Jiaqi Zhou,  Yuze Gao,  Wenxian Yu",
                "发布日期": "2023-11-21",
                "摘要": "  Object detection in aerial images is a pivotal task for various earth\nobservation applications, whereas current algorithms learn to detect only a\npre-defined set of object categories demanding sufficient bounding-box\nannotated training samples and fail to detect novel object categories. In this\npaper, we consider open-vocabulary object detection (OVD) in aerial images that\nenables the characterization of new objects beyond training categories on the\nearth surface without annotating training images for these new categories. The\nperformance of OVD depends on the quality of class-agnostic region proposals\nand pseudo-labels that can generalize well to novel object categories. To\nsimultaneously generate high-quality proposals and pseudo-labels, we propose\nCastDet, a CLIP-activated student-teacher open-vocabulary object Detection\nframework. Our end-to-end framework within the student-teacher mechanism\nemploys the CLIP model as an extra omniscient teacher of rich knowledge into\nthe student-teacher self-learning process. By doing so, our approach boosts\nnovel object proposals and classification. Furthermore, we design a dynamic\nlabel queue technique to maintain high-quality pseudo labels during batch\ntraining and mitigate label imbalance. We conduct extensive experiments on\nmultiple existing aerial object detection datasets, which are set up for the\nOVD task. Experimental results demonstrate our CastDet achieving superior\nopen-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean),\nwhich outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD\ndataset.\n",
                "链接": "https://arxiv.org/abs/2311.11646"
            },
            {
                "文章ID": "71939",
                "标题": "CLIP Surgery for Better Explainability with Enhancement in\n  Open-Vocabulary Tasks",
                "作者": " Yi Li,  Hualiang Wang,  Yiqun Duan,  Xiaomeng Li",
                "发布日期": "2023-04-13",
                "摘要": "  Contrastive Language-Image Pre-training (CLIP) is a powerful multimodal large\nvision model that has demonstrated significant benefits for downstream tasks,\nincluding many zero-shot learning and text-guided vision tasks. However, we\nnotice some severe problems regarding the model's explainability, which\nundermines its credibility and impedes related tasks. Specifically, we find\nCLIP prefers the background regions than the foregrounds according to the\npredicted similarity map, which contradicts human understanding. Besides, there\nare obvious noisy activations on the visualization results at irrelevant\npositions. To address these two issues, we conduct in-depth analyses and reveal\nthe reasons with new findings and evidences. Based on these insights, we\npropose the CLIP Surgery, a method that enables surgery-like modifications for\nthe inference architecture and features, for better explainability and\nenhancement in multiple open-vocabulary tasks. The proposed method has\nsignificantly improved the explainability of CLIP for both convolutional\nnetworks and vision transformers, surpassing existing methods by large margins.\nBesides, our approach also demonstrates remarkable improvements in\nopen-vocabulary segmentation and multi-label recognition tasks. For examples,\nthe mAP improvement on NUS-Wide multi-label recognition is 4.41% without any\nadditional training, and our CLIP Surgery surpasses the state-of-the-art method\nby 8.74% at mIoU on Cityscapes open-vocabulary semantic segmentation.\nFurthermore, our method benefits other tasks including multimodal visualization\nand interactive segmentation like Segment Anything Model (SAM). The code is\navailable at https://github.com/xmed-lab/CLIP_Surgery\n",
                "链接": "https://arxiv.org/abs/2304.05653"
            },
            {
                "文章ID": "86253",
                "标题": "Scaling Open-Vocabulary Object Detection",
                "作者": " Matthias Minderer,  Alexey Gritsenko,  Neil Houlsby",
                "发布日期": "2023-07-21",
                "摘要": "  Open-vocabulary object detection has benefited greatly from pretrained\nvision-language models, but is still limited by the amount of available\ndetection training data. While detection training data can be expanded by using\nWeb image-text pairs as weak supervision, this has not been done at scales\ncomparable to image-level pretraining. Here, we scale up detection data with\nself-training, which uses an existing detector to generate pseudo-box\nannotations on image-text pairs. Major challenges in scaling self-training are\nthe choice of label space, pseudo-annotation filtering, and training\nefficiency. We present the OWLv2 model and OWL-ST self-training recipe, which\naddress these challenges. OWLv2 surpasses the performance of previous\nstate-of-the-art open-vocabulary detectors already at comparable training\nscales (~10M examples). However, with OWL-ST, we can scale to over 1B examples,\nyielding further large improvement: With an L/14 architecture, OWL-ST improves\nAP on LVIS rare classes, for which the model has seen no human box annotations,\nfrom 31.2% to 44.6% (43% relative improvement). OWL-ST unlocks Web-scale\ntraining for open-world localization, similar to what has been seen for image\nclassification and language modelling.\n",
                "链接": "https://arxiv.org/abs/2306.09683"
            },
            {
                "文章ID": "115237",
                "标题": "Open-Vocabulary Video Anomaly Detection",
                "作者": " Peng Wu,  Xuerong Zhou,  Guansong Pang,  Yujia Sun,  Jing Liu,  Peng Wang,  Yanning Zhang",
                "发布日期": "2023-11-16",
                "摘要": "  Video anomaly detection (VAD) with weak supervision has achieved remarkable\nperformance in utilizing video-level labels to discriminate whether a video\nframe is normal or abnormal. However, current approaches are inherently limited\nto a closed-set setting and may struggle in open-world applications where there\ncan be anomaly categories in the test data unseen during training. A few recent\nstudies attempt to tackle a more realistic setting, open-set VAD, which aims to\ndetect unseen anomalies given seen anomalies and normal videos. However, such a\nsetting focuses on predicting frame anomaly scores, having no ability to\nrecognize the specific categories of anomalies, despite the fact that this\nability is essential for building more informed video surveillance systems.\nThis paper takes a step further and explores open-vocabulary video anomaly\ndetection (OVVAD), in which we aim to leverage pre-trained large models to\ndetect and categorize seen and unseen anomalies. To this end, we propose a\nmodel that decouples OVVAD into two mutually complementary tasks --\nclass-agnostic detection and class-specific classification -- and jointly\noptimizes both tasks. Particularly, we devise a semantic knowledge injection\nmodule to introduce semantic knowledge from large language models for the\ndetection task, and design a novel anomaly synthesis module to generate pseudo\nunseen anomaly videos with the help of large vision generation models for the\nclassification task. These semantic knowledge and synthesis anomalies\nsubstantially extend our model's capability in detecting and categorizing a\nvariety of seen and unseen anomalies. Extensive experiments on three\nwidely-used benchmarks demonstrate our model achieves state-of-the-art\nperformance on OVVAD task.\n",
                "链接": "https://arxiv.org/abs/2311.07042"
            }
        ]
    },
    {
        "question": {
            "question": "请找到使用自蒸馏加强目标检测性能的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "66024",
                "标题": "Enhanced K-Radar: Optimal Density Reduction to Improve Detection\n  Performance and Accessibility of 4D Radar Tensor-based Object Detection",
                "作者": " Dong-Hee Paek,  Seung-Hyun Kong,  Kevin Tirta Wijaya",
                "发布日期": "2023-03-14",
                "摘要": "  Recent works have shown the superior robustness of four-dimensional (4D)\nRadar-based three-dimensional (3D) object detection in adverse weather\nconditions. However, processing 4D Radar data remains a challenge due to the\nlarge data size, which require substantial amount of memory for computing and\nstorage. In previous work, an online density reduction is performed on the 4D\nRadar Tensor (4DRT) to reduce the data size, in which the density reduction\nlevel is chosen arbitrarily. However, the impact of density reduction on the\ndetection performance and memory consumption remains largely unknown. In this\npaper, we aim to address this issue by conducting extensive hyperparamter\ntuning on the density reduction level. Experimental results show that\nincreasing the density level from 0.01% to 50% of the original 4DRT density\nlevel proportionally improves the detection performance, at a cost of memory\nconsumption. However, when the density level is increased beyond 5%, only the\nmemory consumption increases, while the detection performance oscillates below\nthe peak point. In addition to the optimized density hyperparameter, we also\nintroduce 4D Sparse Radar Tensor (4DSRT), a new representation for 4D Radar\ndata with offline density reduction, leading to a significantly reduced raw\ndata size. An optimized development kit for training the neural networks is\nalso provided, which along with the utilization of 4DSRT, improves training\nspeed by a factor of 17.1 compared to the state-of-the-art 4DRT-based neural\nnetworks. All codes are available at: https://github.com/kaist-avelab/K-Radar.\n",
                "链接": "https://arxiv.org/abs/2303.06342"
            },
            {
                "文章ID": "58001",
                "标题": "Improving Performance of Object Detection using the Mechanisms of Visual\n  Recognition in Humans",
                "作者": " Amir Ghasemi,  Nasrin Bayat,  Fatemeh Mottaghian,  Akram Bayat",
                "发布日期": "2023-03-15",
                "摘要": "  Object recognition systems are usually trained and evaluated on high\nresolution images. However, in real world applications, it is common that the\nimages have low resolutions or have small sizes. In this study, we first track\nthe performance of the state-of-the-art deep object recognition network,\nFaster- RCNN, as a function of image resolution. The results reveals negative\neffects of low resolution images on recognition performance. They also show\nthat different spatial frequencies convey different information about the\nobjects in recognition process. It means multi-resolution recognition system\ncan provides better insight into optimal selection of features that results in\nbetter recognition of objects. This is similar to the mechanisms of the human\nvisual systems that are able to implement multi-scale representation of a\nvisual scene simultaneously. Then, we propose a multi-resolution object\nrecognition framework rather than a single-resolution network. The proposed\nframework is evaluated on the PASCAL VOC2007 database. The experimental results\nshow the performance of our adapted multi-resolution Faster-RCNN framework\noutperforms the single-resolution Faster-RCNN on input images with various\nresolutions with an increase in the mean Average Precision (mAP) of 9.14%\nacross all resolutions and 1.2% on the full-spectrum images. Furthermore, the\nproposed model yields robustness of the performance over a wide range of\nspatial frequencies.\n",
                "链接": "https://arxiv.org/abs/2301.09667"
            },
            {
                "文章ID": "59657",
                "标题": "On Suppressing Range of Adaptive Stepsizes of Adam to Improve\n  Generalisation Performance",
                "作者": " Guoqiang Zhang",
                "发布日期": "2023-03-01",
                "摘要": "  A number of recent adaptive optimizers improve the generalisation performance\nof Adam by essentially reducing the variance of adaptive stepsizes to get\ncloser to SGD with momentum. Following the above motivation, we suppress the\nrange of the adaptive stepsizes of Adam by exploiting the layerwise gradient\nstatistics. In particular, at each iteration, we propose to perform three\nconsecutive operations on the second momentum v_t before using it to update a\nDNN model: (1): down-scaling, (2): epsilon-embedding, and (3):\ndown-translating. The resulting algorithm is referred to as SET-Adam, where SET\nis a brief notation of the three operations. The down-scaling operation on v_t\nis performed layerwise by making use of the angles between the layerwise\nsubvectors of v_t and the corresponding all-one subvectors. Extensive\nexperimental results show that SET-Adam outperforms eight adaptive optimizers\nwhen training transformers and LSTMs for NLP, and VGG and ResNet for image\nclassification over CIAF10 and CIFAR100 while matching the best performance of\nthe eight adaptive methods when training WGAN-GP models for image generation\ntasks. Furthermore, SET-Adam produces higher validation accuracies than Adam\nand AdaBelief for training ResNet18 over ImageNet.\n",
                "链接": "https://arxiv.org/abs/2302.01029"
            },
            {
                "文章ID": "65588",
                "标题": "Smooth and Stepwise Self-Distillation for Object Detection",
                "作者": " Jieren Deng,  Xin Zhou,  Hao Tian,  Zhihong Pan,  Derek Aguiar",
                "发布日期": "2023-03-10",
                "摘要": "  Distilling the structured information captured in feature maps has\ncontributed to improved results for object detection tasks, but requires\ncareful selection of baseline architectures and substantial pre-training.\nSelf-distillation addresses these limitations and has recently achieved\nstate-of-the-art performance for object detection despite making several\nsimplifying architectural assumptions. Building on this work, we propose Smooth\nand Stepwise Self-Distillation (SSSD) for object detection. Our SSSD\narchitecture forms an implicit teacher from object labels and a feature pyramid\nnetwork backbone to distill label-annotated feature maps using Jensen-Shannon\ndistance, which is smoother than distillation losses used in prior work. We\nadditionally add a distillation coefficient that is adaptively configured based\non the learning rate. We extensively benchmark SSSD against a baseline and two\nstate-of-the-art object detector architectures on the COCO dataset by varying\nthe coefficients and backbone and detector networks. We demonstrate that SSSD\nachieves higher average precision in most experimental settings, is robust to a\nwide range of coefficients, and benefits from our stepwise distillation\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2303.05015"
            },
            {
                "文章ID": "43891",
                "标题": "Frequency of Interest-based Noise Attenuation Method to Improve Anomaly\n  Detection Performance",
                "作者": " YeongHyeon Park,  Myung Jin Kim,  Won Seok Park",
                "发布日期": "2022-12-05",
                "摘要": "  Accurately extracting driving events is the way to maximize computational\nefficiency and anomaly detection performance in the tire frictional nose-based\nanomaly detection task. This study proposes a concise and highly useful method\nfor improving the precision of the event extraction that is hindered by extra\nnoise such as wind noise, which is difficult to characterize clearly due to its\nrandomness. The core of the proposed method is based on the identification of\nthe road friction sound corresponding to the frequency of interest and removing\nthe opposite characteristics with several frequency filters. Our method enables\nprecision maximization of driving event extraction while improving anomaly\ndetection performance by an average of 8.506%. Therefore, we conclude our\nmethod is a practical solution suitable for road surface anomaly detection\npurposes in outdoor edge computing environments.\n",
                "链接": "https://arxiv.org/abs/2210.11068"
            },
            {
                "文章ID": "47808",
                "标题": "Impact of Video Compression on the Performance of Object Detection\n  Systems for Surveillance Applications",
                "作者": " Michael O'Byrne,   Vibhoothi,  Mark Sugrue,  Anil Kokaram",
                "发布日期": "2022-11-14",
                "摘要": "  This study examines the relationship between H.264 video compression and the\nperformance of an object detection network (YOLOv5). We curated a set of 50\nsurveillance videos and annotated targets of interest (people, bikes, and\nvehicles). Videos were encoded at 5 quality levels using Constant Rate Factor\n(CRF) values in the set {22,32,37,42,47}. YOLOv5 was applied to compressed\nvideos and detection performance was analyzed at each CRF level. Test results\nindicate that the detection performance is generally robust to moderate levels\nof compression; using a CRF value of 37 instead of 22 leads to significantly\nreduced bitrates/file sizes without adversely affecting detection performance.\nHowever, detection performance degrades appreciably at higher compression\nlevels, especially in complex scenes with poor lighting and fast-moving\ntargets. Finally, retraining YOLOv5 on compressed imagery gives up to a 1%\nimprovement in F1 score when applied to highly compressed footage.\n",
                "链接": "https://arxiv.org/abs/2211.05805"
            },
            {
                "文章ID": "49409",
                "标题": "Minimizing the Accumulated Trajectory Error to Improve Dataset\n  Distillation",
                "作者": " Jiawei Du,  Yidi Jiang,  Vincent Y. F. Tan,  Joey Tianyi Zhou,  Haizhou Li",
                "发布日期": "2023-03-28",
                "摘要": "  Model-based deep learning has achieved astounding successes due in part to\nthe availability of large-scale real-world data. However, processing such\nmassive amounts of data comes at a considerable cost in terms of computations,\nstorage, training and the search for good neural architectures. Dataset\ndistillation has thus recently come to the fore. This paradigm involves\ndistilling information from large real-world datasets into tiny and compact\nsynthetic datasets such that processing the latter ideally yields similar\nperformances as the former. State-of-the-art methods primarily rely on learning\nthe synthetic dataset by matching the gradients obtained during training\nbetween the real and synthetic data. However, these gradient-matching methods\nsuffer from the so-called accumulated trajectory error caused by the\ndiscrepancy between the distillation and subsequent evaluation. To mitigate the\nadverse impact of this accumulated trajectory error, we propose a novel\napproach that encourages the optimization algorithm to seek a flat trajectory.\nWe show that the weights trained on synthetic data are robust against the\naccumulated errors perturbations with the regularization towards the flat\ntrajectory. Our method, called Flat Trajectory Distillation (FTD), is shown to\nboost the performance of gradient-matching methods by up to 4.7% on a subset of\nimages of the ImageNet dataset with higher resolution images. We also validate\nthe effectiveness and generalizability of our method with datasets of different\nresolutions and demonstrate its applicability to neural architecture search.\nCode is available at https://github.com/AngusDujw/FTD-distillation.\n",
                "链接": "https://arxiv.org/abs/2211.11004"
            },
            {
                "文章ID": "37726",
                "标题": "Understanding the Impact of Image Quality and Distance of Objects to\n  Object Detection Performance",
                "作者": " Yu Hao,  Haoyang Pei,  Yixuan Lyu,  Zhongzheng Yuan,  John-Ross Rizzo,  Yao Wang,  Yi Fang",
                "发布日期": "2022-09-20",
                "摘要": "  Deep learning has made great strides for object detection in images. The\ndetection accuracy and computational cost of object detection depend on the\nspatial resolution of an image, which may be constrained by both the camera and\nstorage considerations. Compression is often achieved by reducing either\nspatial or amplitude resolution or, at times, both, both of which have\nwell-known effects on performance. Detection accuracy also depends on the\ndistance of the object of interest from the camera. Our work examines the\nimpact of spatial and amplitude resolution, as well as object distance, on\nobject detection accuracy and computational cost. We develop a\nresolution-adaptive variant of YOLOv5 (RA-YOLO), which varies the number of\nscales in the feature pyramid and detection head based on the spatial\nresolution of the input image. To train and evaluate this new method, we\ncreated a dataset of images with diverse spatial and amplitude resolutions by\ncombining images from the TJU and Eurocity datasets and generating different\nresolutions by applying spatial resizing and compression. We first show that\nRA-YOLO achieves a good trade-off between detection accuracy and inference time\nover a large range of spatial resolutions. We then evaluate the impact of\nspatial and amplitude resolutions on object detection accuracy using the\nproposed RA-YOLO model. We demonstrate that the optimal spatial resolution that\nleads to the highest detection accuracy depends on the 'tolerated' image size.\nWe further assess the impact of the distance of an object to the camera on the\ndetection accuracy and show that higher spatial resolution enables a greater\ndetection range. These results provide important guidelines for choosing the\nimage spatial resolution and compression settings predicated on available\nbandwidth, storage, desired inference time, and/or desired detection range, in\npractical applications.\n",
                "链接": "https://arxiv.org/abs/2209.08237"
            },
            {
                "文章ID": "91485",
                "标题": "A mixed policy to improve performance of language models on math\n  problems",
                "作者": " Gang Chen",
                "发布日期": "2023-07-19",
                "摘要": "  When to solve math problems, most language models take a sampling strategy to\npredict next word according conditional probabilities. In the math reasoning\nstep, it may generate wrong answer. Considering math problems are\ndeterministic, we propose a mixed policy exploration approach to solve math\nproblems with reinforcement learning. In peculiar, we propose a two level token\nexploration policy: the abstract level explores next token with probability and\nthe second level is deterministic. Specifically, the abstract level policy will\ndecide whether the token is operator or operand with probability sampling,\nwhile the second level is deterministic to select next token with the highest\nscore in a greedy way. We test our method on GSM8K dataset with GPT-2 model,\nand demonstrate more than $2\\%$ performance gain. Our implementation is\navailable at https://github.com/vividitytech/math_lm_rl.\n",
                "链接": "https://arxiv.org/abs/2307.08767"
            },
            {
                "文章ID": "19557",
                "标题": "A two-steps approach to improve the performance of Android malware\n  detectors",
                "作者": " Nadia Daoudi,  Kevin Allix,  Tegawendé F. Bissyandé,  Jacques Klein",
                "发布日期": "2022-05-18",
                "摘要": "  The popularity of Android OS has made it an appealing target to malware\ndevelopers. To evade detection, including by ML-based techniques, attackers\ninvest in creating malware that closely resemble legitimate apps. In this\npaper, we propose GUIDED RETRAINING, a supervised representation learning-based\nmethod that boosts the performance of a malware detector. First, the dataset is\nsplit into \"easy\" and \"difficult\" samples, where difficulty is associated to\nthe prediction probabilities yielded by a malware detector: for difficult\nsamples, the probabilities are such that the classifier is not confident on the\npredictions, which have high error rates. Then, we apply our GUIDED RETRAINING\nmethod on the difficult samples to improve their classification. For the subset\nof \"easy\" samples, the base malware detector is used to make the final\npredictions since the error rate on that subset is low by construction. For the\nsubset of \"difficult\" samples, we rely on GUIDED RETRAINING, which leverages\nthe correct predictions and the errors made by the base malware detector to\nguide the retraining process. GUIDED RETRAINING focuses on the difficult\nsamples: it learns new embeddings of these samples using Supervised Contrastive\nLearning and trains an auxiliary classifier for the final predictions. We\nvalidate our method on four state-of-the-art Android malware detection\napproaches using over 265k malware and benign apps, and we demonstrate that\nGUIDED RETRAINING can reduce up to 40.41% prediction errors made by the malware\ndetectors. Our method is generic and designed to enhance the classification\nperformance on a binary classification task. Consequently, it can be applied to\nother classification problems beyond Android malware detection.\n",
                "链接": "https://arxiv.org/abs/2205.08265"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用2020年以后CONLL 2004数据集进行NER评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "54351",
                "标题": "Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?",
                "作者": " Shuheng Liu,  Alan Ritter",
                "发布日期": "2023-07-13",
                "摘要": "  The CoNLL-2003 English named entity recognition (NER) dataset has been widely\nused to train and evaluate NER models for almost 20 years. However, it is\nunclear how well models that are trained on this 20-year-old data and developed\nover a period of decades using the same test set will perform when applied on\nmodern data. In this paper, we evaluate the generalization of over 20 different\nmodels trained on CoNLL-2003, and show that NER models have very different\ngeneralization. Surprisingly, we find no evidence of performance degradation in\npre-trained Transformers, such as RoBERTa and T5, even when fine-tuned using\ndecades-old data. We investigate why some models generalize well to new data\nwhile others do not, and attempt to disentangle the effects of temporal drift\nand overfitting due to test reuse. Our analysis suggests that most\ndeterioration is due to temporal mismatch between the pre-training corpora and\nthe downstream test sets. We found that four factors are important for good\ngeneralization: model architecture, number of parameters, time period of the\npre-training corpus, in addition to the amount of fine-tuning data. We suggest\ncurrent evaluation methods have, in some sense, underestimated progress on NER\nover the past 20 years, as NER models have not only improved on the original\nCoNLL-2003 test set, but improved even more on modern data. Our datasets can be\nfound at https://github.com/ShuhengL/acl2023_conllpp.\n",
                "链接": "https://arxiv.org/abs/2212.09747"
            },
            {
                "文章ID": "115272",
                "标题": "Developing a Named Entity Recognition Dataset for Tagalog",
                "作者": " Lester James V. Miranda",
                "发布日期": "2023-11-14",
                "摘要": "  We present the development of a Named Entity Recognition (NER) dataset for\nTagalog. This corpus helps fill the resource gap present in Philippine\nlanguages today, where NER resources are scarce. The texts were obtained from a\npretraining corpora containing news reports, and were labeled by native\nspeakers in an iterative fashion. The resulting dataset contains ~7.8k\ndocuments across three entity types: Person, Organization, and Location. The\ninter-annotator agreement, as measured by Cohen's $\\kappa$, is 0.81. We also\nconducted extensive empirical evaluation of state-of-the-art methods across\nsupervised and transfer learning settings. Finally, we released the data and\nprocessing code publicly to inspire future work on Tagalog NLP.\n",
                "链接": "https://arxiv.org/abs/2311.07161"
            },
            {
                "文章ID": "17054",
                "标题": "HiNER: A Large Hindi Named Entity Recognition Dataset",
                "作者": " Rudra Murthy,  Pallab Bhattacharjee,  Rahul Sharnagat,  Jyotsana Khatri,  Diptesh Kanojia,  Pushpak Bhattacharyya",
                "发布日期": "2022-05-02",
                "摘要": "  Named Entity Recognition (NER) is a foundational NLP task that aims to\nprovide class labels like Person, Location, Organisation, Time, and Number to\nwords in free text. Named Entities can also be multi-word expressions where the\nadditional I-O-B annotation information helps label them during the NER\nannotation process. While English and European languages have considerable\nannotated data for the NER task, Indian languages lack on that front -- both in\nterms of quantity and following annotation standards. This paper releases a\nsignificantly sized standard-abiding Hindi NER dataset containing 109,146\nsentences and 2,220,856 tokens, annotated with 11 tags. We discuss the dataset\nstatistics in all their essential detail and provide an in-depth analysis of\nthe NER tag-set used with our data. The statistics of tag-set in our dataset\nshow a healthy per-tag distribution, especially for prominent classes like\nPerson, Location and Organisation. Since the proof of resource-effectiveness is\nin building models with the resource and testing the model on benchmark data\nand against the leader-board entries in shared tasks, we do the same with the\naforesaid data. We use different language models to perform the sequence\nlabelling task for NER and show the efficacy of our data by performing a\ncomparative evaluation with models trained on another dataset available for the\nHindi NER task. Our dataset helps achieve a weighted F1 score of 88.78 with all\nthe tags and 92.22 when we collapse the tag-set, as discussed in the paper. To\nthe best of our knowledge, no available dataset meets the standards of volume\n(amount) and variability (diversity), as far as Hindi NER is concerned. We fill\nthis gap through this work, which we hope will significantly help NLP for\nHindi. We release this dataset with our code and models at\nhttps://github.com/cfiltnlp/HiNER\n",
                "链接": "https://arxiv.org/abs/2204.13743"
            },
            {
                "文章ID": "28227",
                "标题": "AsNER -- Annotated Dataset and Baseline for Assamese Named Entity\n  recognition",
                "作者": " Dhrubajyoti Pathak,  Sukumar Nandi,  Priyankoo Sarmah",
                "发布日期": "2022-12-22",
                "摘要": "  We present the AsNER, a named entity annotation dataset for low resource\nAssamese language with a baseline Assamese NER model. The dataset contains\nabout 99k tokens comprised of text from the speech of the Prime Minister of\nIndia and Assamese play. It also contains person names, location names and\naddresses. The proposed NER dataset is likely to be a significant resource for\ndeep neural based Assamese language processing. We benchmark the dataset by\ntraining NER models and evaluating using state-of-the-art architectures for\nsupervised named entity recognition (NER) such as Fasttext, BERT, XLM-R, FLAIR,\nMuRIL etc. We implement several baseline approaches with state-of-the-art\nsequence tagging Bi-LSTM-CRF architecture. The highest F1-score among all\nbaselines achieves an accuracy of 80.69% when using MuRIL as a word embedding\nmethod. The annotated dataset and the top performing model are made publicly\navailable.\n",
                "链接": "https://arxiv.org/abs/2207.03422"
            },
            {
                "文章ID": "110514",
                "标题": "NERetrieve: Dataset for Next Generation Named Entity Recognition and\n  Retrieval",
                "作者": " Uri Katz,  Matan Vetzler,  Amir DN Cohen,  Yoav Goldberg",
                "发布日期": "2023-10-24",
                "摘要": "  Recognizing entities in texts is a central need in many information-seeking\nscenarios, and indeed, Named Entity Recognition (NER) is arguably one of the\nmost successful examples of a widely adopted NLP task and corresponding NLP\ntechnology. Recent advances in large language models (LLMs) appear to provide\neffective solutions (also) for NER tasks that were traditionally handled with\ndedicated models, often matching or surpassing the abilities of the dedicated\nmodels. Should NER be considered a solved problem? We argue to the contrary:\nthe capabilities provided by LLMs are not the end of NER research, but rather\nan exciting beginning. They allow taking NER to the next level, tackling\nincreasingly more useful, and increasingly more challenging, variants. We\npresent three variants of the NER task, together with a dataset to support\nthem. The first is a move towards more fine-grained -- and intersectional --\nentity types. The second is a move towards zero-shot recognition and extraction\nof these fine-grained types based on entity-type labels. The third, and most\nchallenging, is the move from the recognition setup to a novel retrieval setup,\nwhere the query is a zero-shot entity type, and the expected result is all the\nsentences from a large, pre-indexed corpus that contain entities of these\ntypes, and their corresponding spans. We show that all of these are far from\nbeing solved. We provide a large, silver-annotated corpus of 4 million\nparagraphs covering 500 entity types, to facilitate research towards all of\nthese three goals.\n",
                "链接": "https://arxiv.org/abs/2310.14282"
            },
            {
                "文章ID": "111254",
                "标题": "CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset",
                "作者": " Susanna Rücker,  Alan Akbik",
                "发布日期": "2023-10-26",
                "摘要": "  The CoNLL-03 corpus is arguably the most well-known and utilized benchmark\ndataset for named entity recognition (NER). However, prior works found\nsignificant numbers of annotation errors, incompleteness, and inconsistencies\nin the data. This poses challenges to objectively comparing NER approaches and\nanalyzing their errors, as current state-of-the-art models achieve F1-scores\nthat are comparable to or even exceed the estimated noise level in CoNLL-03. To\naddress this issue, we present a comprehensive relabeling effort assisted by\nautomatic consistency checking that corrects 7.0% of all labels in the English\nCoNLL-03. Our effort adds a layer of entity linking annotation both for better\nexplainability of NER labels and as additional safeguard of annotation quality.\nOur experimental evaluation finds not only that state-of-the-art approaches\nreach significantly higher F1-scores (97.1%) on our data, but crucially that\nthe share of correct predictions falsely counted as errors due to annotation\nnoise drops from 47% to 6%. This indicates that our resource is well suited to\nanalyze the remaining errors made by state-of-the-art models, and that the\ntheoretical upper bound even on high resource, coarse-grained NER is not yet\nreached. To facilitate such analysis, we make CleanCoNLL publicly available to\nthe research community.\n",
                "链接": "https://arxiv.org/abs/2310.16225"
            },
            {
                "文章ID": "12159",
                "标题": "Federated Named Entity Recognition",
                "作者": " Joel Mathew,  Dimitris Stripelis,  José Luis Ambite",
                "发布日期": "2022-03-30",
                "摘要": "  We present an analysis of the performance of Federated Learning in a\nparadigmatic natural-language processing task: Named-Entity Recognition (NER).\nFor our evaluation, we use the language-independent CoNLL-2003 dataset as our\nbenchmark dataset and a Bi-LSTM-CRF model as our benchmark NER model. We show\nthat federated training reaches almost the same performance as the centralized\nmodel, though with some performance degradation as the learning environments\nbecome more heterogeneous. We also show the convergence rate of federated\nmodels for NER. Finally, we discuss existing challenges of Federated Learning\nfor NLP applications that can foster future research directions.\n",
                "链接": "https://arxiv.org/abs/2203.15101"
            },
            {
                "文章ID": "62584",
                "标题": "Dynamic Named Entity Recognition",
                "作者": " Tristan Luiggi,  Laure Soulier,  Vincent Guigue,  Siwar Jendoubi,  Aurélien Baelde",
                "发布日期": "2023-02-22",
                "摘要": "  Named Entity Recognition (NER) is a challenging and widely studied task that\ninvolves detecting and typing entities in text. So far,NER still approaches\nentity typing as a task of classification into universal classes (e.g. date,\nperson, or location). Recent advances innatural language processing focus on\narchitectures of increasing complexity that may lead to overfitting and\nmemorization, and thus, underuse of context. Our work targets situations where\nthe type of entities depends on the context and cannot be solved solely by\nmemorization. We hence introduce a new task: Dynamic Named Entity Recognition\n(DNER), providing a framework to better evaluate the ability of algorithms to\nextract entities by exploiting the context. The DNER benchmark is based on two\ndatasets, DNER-RotoWire and DNER-IMDb. We evaluate baseline models and present\nexperiments reflecting issues and research axes related to this novel task.\n",
                "链接": "https://arxiv.org/abs/2302.10314"
            },
            {
                "文章ID": "71838",
                "标题": "Exploring the Use of Foundation Models for Named Entity Recognition and\n  Lemmatization Tasks in Slavic Languages",
                "作者": " Gabriela Pałka,  Artur Nowakowski",
                "发布日期": "2023-04-12",
                "摘要": "  This paper describes Adam Mickiewicz University's (AMU) solution for the 4th\nShared Task on SlavNER. The task involves the identification, categorization,\nand lemmatization of named entities in Slavic languages. Our approach involved\nexploring the use of foundation models for these tasks. In particular, we used\nmodels based on the popular BERT and T5 model architectures. Additionally, we\nused external datasets to further improve the quality of our models. Our\nsolution obtained promising results, achieving high metrics scores in both\ntasks. We describe our approach and the results of our experiments in detail,\nshowing that the method is effective for NER and lemmatization in Slavic\nlanguages. Additionally, our models for lemmatization will be available at:\nhttps://huggingface.co/amu-cai.\n",
                "链接": "https://arxiv.org/abs/2304.05336"
            },
            {
                "文章ID": "35474",
                "标题": "MultiCoNER: A Large-scale Multilingual dataset for Complex Named Entity\n  Recognition",
                "作者": " Shervin Malmasi,  Anjie Fang,  Besnik Fetahu,  Sudipta Kar,  Oleg Rokhlenko",
                "发布日期": "2022-09-01",
                "摘要": "  We present MultiCoNER, a large multilingual dataset for Named Entity\nRecognition that covers 3 domains (Wiki sentences, questions, and search\nqueries) across 11 languages, as well as multilingual and code-mixing subsets.\nThis dataset is designed to represent contemporary challenges in NER, including\nlow-context scenarios (short and uncased text), syntactically complex entities\nlike movie titles, and long-tail entity distributions. The 26M token dataset is\ncompiled from public resources using techniques such as heuristic-based\nsentence sampling, template extraction and slotting, and machine translation.\nWe applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a\nstate-of-the-art GEMNET model that leverages gazetteers. The baseline achieves\nmoderate performance (macro-F1=54%), highlighting the difficulty of our data.\nGEMNET, which uses gazetteers, improvement significantly (average improvement\nof macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained\nlanguage models, and we believe that it can help further research in building\nrobust NER systems. MultiCoNER is publicly available at\nhttps://registry.opendata.aws/multiconer/ and we hope that this resource will\nhelp advance research in various aspects of NER.\n",
                "链接": "https://arxiv.org/abs/2208.14536"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用CrossWoz或MultiWoz数据集进行DST评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "46848",
                "标题": "MultiWOZ-DF -- A Dataflow implementation of the MultiWOZ dataset",
                "作者": " Joram Meron,  Victor Guimarães",
                "发布日期": "2022-11-07",
                "摘要": "  Semantic Machines (SM) have introduced the use of the dataflow (DF) paradigm\nto dialogue modelling, using computational graphs to hierarchically represent\nuser requests, data, and the dialogue history [Semantic Machines et al. 2020].\nAlthough the main focus of that paper was the SMCalFlow dataset (to date, the\nonly dataset with \"native\" DF annotations), they also reported some results of\nan experiment using a transformed version of the commonly used MultiWOZ dataset\n[Budzianowski et al. 2018] into a DF format. In this paper, we expand the\nexperiments using DF for the MultiWOZ dataset, exploring some additional\nexperimental set-ups. The code and instructions to reproduce the experiments\nreported here have been released. The contributions of this paper are: 1.) A DF\nimplementation capable of executing MultiWOZ dialogues; 2.) Several versions of\nconversion of MultiWOZ into a DF format are presented; 3.) Experimental results\non state match and translation accuracy.\n",
                "链接": "https://arxiv.org/abs/2211.02303"
            },
            {
                "文章ID": "7222",
                "标题": "ASSIST: Towards Label Noise-Robust Dialogue State Tracking",
                "作者": " Fanghua Ye,  Yue Feng,  Emine Yilmaz",
                "发布日期": "2022-03-15",
                "摘要": "  The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state\ntracking (DST). However, substantial noise has been discovered in its state\nannotations. Such noise brings about huge challenges for training DST models\nrobustly. Although several refined versions, including MultiWOZ 2.1-2.4, have\nbeen published recently, there are still lots of noisy labels, especially in\nthe training set. Besides, it is costly to rectify all the problematic\nannotations. In this paper, instead of improving the annotation quality\nfurther, we propose a general framework, named ASSIST (lAbel noiSe-robuSt\ndIalogue State Tracking), to train DST models robustly from noisy labels.\nASSIST first generates pseudo labels for each sample in the training set by\nusing an auxiliary model trained on a small clean dataset, then puts the\ngenerated pseudo labels and vanilla noisy labels together to train the primary\nmodel. We show the validity of ASSIST theoretically. Experimental results also\ndemonstrate that ASSIST improves the joint goal accuracy of DST by up to\n$28.16\\%$ on MultiWOZ 2.0 and $8.41\\%$ on MultiWOZ 2.4, compared to using only\nthe vanilla noisy labels.\n",
                "链接": "https://arxiv.org/abs/2202.13024"
            },
            {
                "文章ID": "45137",
                "标题": "Is MultiWOZ a Solved Task? An Interactive TOD Evaluation Framework with\n  User Simulator",
                "作者": " Qinyuan Cheng,  Linyang Li,  Guofeng Quan,  Feng Gao,  Xiaofeng Mou,  Xipeng Qiu",
                "发布日期": "2022-10-27",
                "摘要": "  Task-Oriented Dialogue (TOD) systems are drawing more and more attention in\nrecent studies. Current methods focus on constructing pre-trained models or\nfine-tuning strategies while the evaluation of TOD is limited by a policy\nmismatch problem. That is, during evaluation, the user utterances are from the\nannotated dataset while these utterances should interact with previous\nresponses which can have many alternatives besides annotated texts. Therefore,\nin this work, we propose an interactive evaluation framework for TOD. We first\nbuild a goal-oriented user simulator based on pre-trained models and then use\nthe user simulator to interact with the dialogue system to generate dialogues.\nBesides, we introduce a sentence-level and a session-level score to measure the\nsentence fluency and session coherence in the interactive evaluation.\nExperimental results show that RL-based TOD systems trained by our proposed\nuser simulator can achieve nearly 98% inform and success rates in the\ninteractive evaluation of MultiWOZ dataset and the proposed scores measure the\nresponse quality besides the inform and success rates. We are hoping that our\nwork will encourage simulator-based interactive evaluations in the TOD task.\n",
                "链接": "https://arxiv.org/abs/2210.14529"
            },
            {
                "文章ID": "5419",
                "标题": "ArgSciChat: A Dataset for Argumentative Dialogues on Scientific Papers",
                "作者": " Federico Ruggeri,  Mohsen Mesgar,  Iryna Gurevych",
                "发布日期": "2022-10-14",
                "摘要": "  The applications of conversational agents for scientific disciplines (as\nexpert domains) are understudied due to the lack of dialogue data to train such\nagents. While most data collection frameworks, such as Amazon Mechanical Turk,\nfoster data collection for generic domains by connecting crowd workers and task\ndesigners, these frameworks are not much optimized for data collection in\nexpert domains. Scientists are rarely present in these frameworks due to their\nlimited time budget. Therefore, we introduce a novel framework to collect\ndialogues between scientists as domain experts on scientific papers. Our\nframework lets scientists present their scientific papers as groundings for\ndialogues and participate in dialogue they like its paper title. We use our\nframework to collect a novel argumentative dialogue dataset, ArgSciChat. It\nconsists of 498 messages collected from 41 dialogues on 20 scientific papers.\nAlongside extensive analysis on ArgSciChat, we evaluate a recent conversational\nagent on our dataset. Experimental results show that this agent poorly performs\non ArgSciChat, motivating further research on argumentative scientific agents.\nWe release our framework and the dataset.\n",
                "链接": "https://arxiv.org/abs/2202.06690"
            },
            {
                "文章ID": "40726",
                "标题": "Schema Encoding for Transferable Dialogue State Tracking",
                "作者": " Hyunmin Jeon,  Gary Geunbae Lee",
                "发布日期": "2022-10-06",
                "摘要": "  Dialogue state tracking (DST) is an essential sub-task for task-oriented\ndialogue systems. Recent work has focused on deep neural models for DST.\nHowever, the neural models require a large dataset for training. Furthermore,\napplying them to another domain needs a new dataset because the neural models\nare generally trained to imitate the given dataset. In this paper, we propose\nSchema Encoding for Transferable Dialogue State Tracking (SETDST), which is a\nneural DST method for effective transfer to new domains. Transferable DST could\nassist developments of dialogue systems even with few dataset on target\ndomains. We use a schema encoder not just to imitate the dataset but to\ncomprehend the schema of the dataset. We aim to transfer the model to new\ndomains by encoding new schemas and using them for DST on multi-domain\nsettings. As a result, SET-DST improved the joint accuracy by 1.46 points on\nMultiWOZ 2.1.\n",
                "链接": "https://arxiv.org/abs/2210.02351"
            },
            {
                "文章ID": "60862",
                "标题": "Find a witness or shatter: the landscape of computable PAC learning",
                "作者": " Valentino Delle Rose,  Alexander Kozachinskiy,  Cristobal Rojas,  Tomasz Steifer",
                "发布日期": "2023-02-24",
                "摘要": "  This paper contributes to the study of CPAC learnability -- a computable\nversion of PAC learning -- by solving three open questions from recent papers.\nFirstly, we prove that every improperly CPAC learnable class is contained in a\nclass which is properly CPAC learnable with polynomial sample complexity. This\nconfirms a conjecture by Agarwal et al (COLT 2021). Secondly, we show that\nthere exists a decidable class of hypothesis which is properly CPAC learnable,\nbut only with uncomputably fast growing sample complexity. This solves a\nquestion from Sterkenburg (COLT 2022). Finally, we construct a decidable class\nof finite Littlestone dimension which is not improperly CPAC learnable,\nstrengthening a recent result of Sterkenburg (2022) and answering a question\nposed by Hasrati and Ben-David (ALT 2023). Together with previous work, our\nresults provide a complete landscape for the learnability problem in the CPAC\nsetting.\n",
                "链接": "https://arxiv.org/abs/2302.04731"
            },
            {
                "文章ID": "48889",
                "标题": "Self-Training with Purpose Preserving Augmentation Improves Few-shot\n  Generative Dialogue State Tracking",
                "作者": " Jihyun Lee,  Chaebin Lee,  Yunsu Kim,  Gary Geunbae Lee",
                "发布日期": "2022-11-18",
                "摘要": "  In dialogue state tracking (DST), labeling the dataset involves considerable\nhuman labor. We propose a new self-training framework for few-shot generative\nDST that utilize unlabeled data. Our self-training method iteratively improves\nthe model by pseudo labeling and employs Purpose Preserving Augmentation\n(PPAug) to prevent overfitting. We increaese the few-shot 10% performance by\napproximately 4% on MultiWOZ 2.1 and enhances the slot-recall 8.34% for unseen\nvalues compared to baseline.\n",
                "链接": "https://arxiv.org/abs/2211.09379"
            },
            {
                "文章ID": "8498",
                "标题": "Mismatch between Multi-turn Dialogue and its Evaluation Metric in\n  Dialogue State Tracking",
                "作者": " Takyoung Kim,  Hoonsang Yoon,  Yukyung Lee,  Pilsung Kang,  Misuk Kim",
                "发布日期": "2022-04-01",
                "摘要": "  Dialogue state tracking (DST) aims to extract essential information from\nmulti-turn dialogue situations and take appropriate actions. A belief state,\none of the core pieces of information, refers to the subject and its specific\ncontent, and appears in the form of domain-slot-value. The trained model\npredicts \"accumulated\" belief states in every turn, and joint goal accuracy and\nslot accuracy are mainly used to evaluate the prediction; however, we specify\nthat the current evaluation metrics have a critical limitation when evaluating\nbelief states accumulated as the dialogue proceeds, especially in the most used\nMultiWOZ dataset. Additionally, we propose relative slot accuracy to complement\nexisting metrics. Relative slot accuracy does not depend on the number of\npredefined slots, and allows intuitive evaluation by assigning relative scores\naccording to the turn of each dialogue. This study also encourages not solely\nthe reporting of joint goal accuracy, but also various complementary metrics in\nDST tasks for the sake of a realistic evaluation.\n",
                "链接": "https://arxiv.org/abs/2203.03123"
            },
            {
                "文章ID": "41702",
                "标题": "CSS: Combining Self-training and Self-supervised Learning for Few-shot\n  Dialogue State Tracking",
                "作者": " Haoning Zhang,  Junwei Bao,  Haipeng Sun,  Huaishao Luo,  Wenye Li,  Shuguang Cui",
                "发布日期": "2022-10-12",
                "摘要": "  Few-shot dialogue state tracking (DST) is a realistic problem that trains the\nDST model with limited labeled data. Existing few-shot methods mainly transfer\nknowledge learned from external labeled dialogue data (e.g., from question\nanswering, dialogue summarization, machine reading comprehension tasks, etc.)\ninto DST, whereas collecting a large amount of external labeled data is\nlaborious, and the external data may not effectively contribute to the\nDST-specific task. In this paper, we propose a few-shot DST framework called\nCSS, which Combines Self-training and Self-supervised learning methods. The\nunlabeled data of the DST task is incorporated into the self-training\niterations, where the pseudo labels are predicted by a DST model trained on\nlimited labeled data in advance. Besides, a contrastive self-supervised method\nis used to learn better representations, where the data is augmented by the\ndropout operation to train the model. Experimental results on the MultiWOZ\ndataset show that our proposed CSS achieves competitive performance in several\nfew-shot scenarios.\n",
                "链接": "https://arxiv.org/abs/2210.05146"
            },
            {
                "文章ID": "111434",
                "标题": "In the user's eyes we find trust: Using gaze data as a predictor or\n  trust in an artifical intelligence",
                "作者": " Martin Johannes Dechant,  Olga Lukashova-Sanz,  Siegfried Wahl",
                "发布日期": "2023-10-26",
                "摘要": "  Trust is essential for our interactions with others but also with artificial\nintelligence (AI) based systems. To understand whether a user trusts an AI,\nresearchers need reliable measurement tools. However, currently discussed\nmarkers mostly rely on expensive and invasive sensors, like\nelectroencephalograms, which may cause discomfort. The analysis of gaze data\nhas been suggested as a convenient tool for trust assessment. However, the\nrelationship between trust and several aspects of the gaze behaviour is not yet\nfully understood. To provide more insights into this relationship, we propose a\nexploration study in virtual reality where participants have to perform a\nsorting task together with a simulated AI in a simulated robotic arm embedded\nin a gaming. We discuss the potential benefits of this approach and outline our\nstudy design in this submission.\n",
                "链接": "https://arxiv.org/abs/2310.16672"
            }
        ]
    },
    {
        "question": {
            "question": "2023年后利用hotpotqa数据集做问题生成任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "106859",
                "标题": "Human Mobility Question Answering (Vision Paper)",
                "作者": " Hao Xue,  Flora D. Salim",
                "发布日期": "2023-10-16",
                "摘要": "  Question answering (QA) systems have attracted much attention from the\nartificial intelligence community as they can learn to answer questions based\non the given knowledge source (e.g., images in visual question answering).\nHowever, the research into question answering systems with human mobility data\nremains unexplored. Mining human mobility data is crucial for various\napplications such as smart city planning, pandemic management, and personalised\nrecommendation system. In this paper, we aim to tackle this gap and introduce a\nnovel task, that is, human mobility question answering (MobQA). The aim of the\ntask is to let the intelligent system learn from mobility data and answer\nrelated questions. This task presents a new paradigm change in mobility\nprediction research and further facilitates the research of human mobility\nrecommendation systems. To better support this novel research topic, this\nvision paper also proposes an initial design of the dataset and a potential\ndeep learning model framework for the introduced MobQA task. We hope that this\npaper will provide novel insights and open new directions in human mobility\nresearch and question answering research.\n",
                "链接": "https://arxiv.org/abs/2310.04443"
            },
            {
                "文章ID": "27917",
                "标题": "A Dataset on Malicious Paper Bidding in Peer Review",
                "作者": " Steven Jecmen,  Minji Yoon,  Vincent Conitzer,  Nihar B. Shah,  Fei Fang",
                "发布日期": "2023-03-14",
                "摘要": "  In conference peer review, reviewers are often asked to provide \"bids\" on\neach submitted paper that express their interest in reviewing that paper. A\npaper assignment algorithm then uses these bids (along with other data) to\ncompute a high-quality assignment of reviewers to papers. However, this process\nhas been exploited by malicious reviewers who strategically bid in order to\nunethically manipulate the paper assignment, crucially undermining the peer\nreview process. For example, these reviewers may aim to get assigned to a\nfriend's paper as part of a quid-pro-quo deal. A critical impediment towards\ncreating and evaluating methods to mitigate this issue is the lack of any\npublicly-available data on malicious paper bidding. In this work, we collect\nand publicly release a novel dataset to fill this gap, collected from a mock\nconference activity where participants were instructed to bid either honestly\nor maliciously. We further provide a descriptive analysis of the bidding\nbehavior, including our categorization of different strategies employed by\nparticipants. Finally, we evaluate the ability of each strategy to manipulate\nthe assignment, and also evaluate the performance of some simple algorithms\nmeant to detect malicious bidding. The performance of these detection\nalgorithms can be taken as a baseline for future research on detecting\nmalicious bidding.\n",
                "链接": "https://arxiv.org/abs/2207.02303"
            },
            {
                "文章ID": "2393",
                "标题": "Question Generation for Evaluating Cross-Dataset Shifts in Multi-modal\n  Grounding",
                "作者": " Arjun R. Akula",
                "发布日期": "2022-01-25",
                "摘要": "  Visual question answering (VQA) is the multi-modal task of answering natural\nlanguage questions about an input image. Through cross-dataset adaptation\nmethods, it is possible to transfer knowledge from a source dataset with larger\ntrain samples to a target dataset where training set is limited. Suppose a VQA\nmodel trained on one dataset train set fails in adapting to another, it is hard\nto identify the underlying cause of domain mismatch as there could exists a\nmultitude of reasons such as image distribution mismatch and question\ndistribution mismatch. At UCLA, we are working on a VQG module that facilitate\nin automatically generating OOD shifts that aid in systematically evaluating\ncross-dataset adaptation capabilities of VQA models.\n",
                "链接": "https://arxiv.org/abs/2201.09639"
            },
            {
                "文章ID": "76178",
                "标题": "OpenViVQA: Task, Dataset, and Multimodal Fusion Models for Visual\n  Question Answering in Vietnamese",
                "作者": " Nghia Hieu Nguyen,  Duong T. D. Vo,  Kiet Van Nguyen,  Ngan Luu-Thuy Nguyen",
                "发布日期": "2023-10-03",
                "摘要": "  In recent years, visual question answering (VQA) has attracted attention from\nthe research community because of its highly potential applications (such as\nvirtual assistance on intelligent cars, assistant devices for blind people, or\ninformation retrieval from document images using natural language as queries)\nand challenge. The VQA task requires methods that have the ability to fuse the\ninformation from questions and images to produce appropriate answers. Neural\nvisual question answering models have achieved tremendous growth on large-scale\ndatasets which are mostly for resource-rich languages such as English. However,\navailable datasets narrow the VQA task as the answers selection task or answer\nclassification task. We argue that this form of VQA is far from human ability\nand eliminates the challenge of the answering aspect in the VQA task by just\nselecting answers rather than generating them. In this paper, we introduce the\nOpenViVQA (Open-domain Vietnamese Visual Question Answering) dataset, the first\nlarge-scale dataset for VQA with open-ended answers in Vietnamese, consists of\n11,000+ images associated with 37,000+ question-answer pairs (QAs). Moreover,\nwe proposed FST, QuMLAG, and MLPAG which fuse information from images and\nanswers, then use these fused features to construct answers as humans\niteratively. Our proposed methods achieve results that are competitive with\nSOTA models such as SAAA, MCAN, LORA, and M4C. The dataset is available to\nencourage the research community to develop more generalized algorithms\nincluding transformers for low-resource languages such as Vietnamese.\n",
                "链接": "https://arxiv.org/abs/2305.04183"
            },
            {
                "文章ID": "59883",
                "标题": "LIQUID: A Framework for List Question Answering Dataset Generation",
                "作者": " Seongyun Lee,  Hyunjae Kim,  Jaewoo Kang",
                "发布日期": "2023-02-07",
                "摘要": "  Question answering (QA) models often rely on large-scale training datasets,\nwhich necessitates the development of a data generation framework to reduce the\ncost of manual annotations. Although several recent studies have aimed to\ngenerate synthetic questions with single-span answers, no study has been\nconducted on the creation of list questions with multiple, non-contiguous spans\nas answers. To address this gap, we propose LIQUID, an automated framework for\ngenerating list QA datasets from unlabeled corpora. We first convert a passage\nfrom Wikipedia or PubMed into a summary and extract named entities from the\nsummarized text as candidate answers. This allows us to select answers that are\nsemantically correlated in context and is, therefore, suitable for constructing\nlist questions. We then create questions using an off-the-shelf question\ngenerator with the extracted entities and original passage. Finally, iterative\nfiltering and answer expansion are performed to ensure the accuracy and\ncompleteness of the answers. Using our synthetic data, we significantly improve\nthe performance of the previous best list QA models by exact-match F1 scores of\n5.0 on MultiSpanQA, 1.9 on Quoref, and 2.8 averaged across three BioASQ\nbenchmarks.\n",
                "链接": "https://arxiv.org/abs/2302.01691"
            },
            {
                "文章ID": "108331",
                "标题": "Visual Question Generation in Bengali",
                "作者": " Mahmud Hasan,  Labiba Islam,  Jannatul Ferdous Ruma,  Tasmiah Tahsin Mayeesha,  Rashedur M. Rahman",
                "发布日期": "2023-10-13",
                "摘要": "  The task of Visual Question Generation (VQG) is to generate human-like\nquestions relevant to the given image. As VQG is an emerging research field,\nexisting works tend to focus only on resource-rich language such as English due\nto the availability of datasets. In this paper, we propose the first Bengali\nVisual Question Generation task and develop a novel transformer-based\nencoder-decoder architecture that generates questions in Bengali when given an\nimage. We propose multiple variants of models - (i) image-only: baseline model\nof generating questions from images without additional information, (ii)\nimage-category and image-answer-category: guided VQG where we condition the\nmodel to generate questions based on the answer and the category of expected\nquestion. These models are trained and evaluated on the translated VQAv2.0\ndataset. Our quantitative and qualitative results establish the first state of\nthe art models for VQG task in Bengali and demonstrate that our models are\ncapable of generating grammatically correct and relevant questions. Our\nquantitative results show that our image-cat model achieves a BLUE-1 score of\n33.12 and BLEU-3 score of 7.56 which is the highest of the other two variants.\nWe also perform a human evaluation to assess the quality of the generation\ntasks. Human evaluation suggests that image-cat model is capable of generating\ngoal-driven and attribute-specific questions and also stays relevant to the\ncorresponding image.\n",
                "链接": "https://arxiv.org/abs/2310.08187"
            },
            {
                "文章ID": "17220",
                "标题": "End-to-end Spoken Conversational Question Answering: Task, Dataset and\n  Model",
                "作者": " Chenyu You,  Nuo Chen,  Fenglin Liu,  Shen Ge,  Xian Wu,  Yuexian Zou",
                "发布日期": "2022-05-02",
                "摘要": "  In spoken question answering, the systems are designed to answer questions\nfrom contiguous text spans within the related speech transcripts. However, the\nmost natural way that human seek or test their knowledge is via human\nconversations. Therefore, we propose a new Spoken Conversational Question\nAnswering task (SCQA), aiming at enabling the systems to model complex dialogue\nflows given the speech documents. In this task, our main objective is to build\nthe system to deal with conversational questions based on the audio recordings,\nand to explore the plausibility of providing more cues from different\nmodalities with systems in information gathering. To this end, instead of\ndirectly adopting automatically generated speech transcripts with highly noisy\ndata, we propose a novel unified data distillation approach, DDNet, which\neffectively ingests cross-modal information to achieve fine-grained\nrepresentations of the speech and language modalities. Moreover, we propose a\nsimple and novel mechanism, termed Dual Attention, by encouraging better\nalignments between audio and text to ease the process of knowledge transfer. To\nevaluate the capacity of SCQA systems in a dialogue-style interaction, we\nassemble a Spoken Conversational Question Answering (Spoken-CoQA) dataset with\nmore than 40k question-answer pairs from 4k conversations. The performance of\nthe existing state-of-the-art methods significantly degrade on our dataset,\nhence demonstrating the necessity of cross-modal information integration. Our\nexperimental results demonstrate that our proposed method achieves superior\nperformance in spoken conversational question answering tasks.\n",
                "链接": "https://arxiv.org/abs/2204.14272"
            },
            {
                "文章ID": "91898",
                "标题": "Rob\\^oCIn Small Size League Extended Team Description Paper for RoboCup\n  2023",
                "作者": " Aline Lima de Oliveira,  Cauê Addae da Silva Gomes,  Cecília Virginia Santos da Silva,  Charles Matheus de Sousa Alves,  Danilo Andrade Martins de Souza,  Driele Pires Ferreira Araújo Xavier,  Edgleyson Pereira da Silva,  Felipe Bezerra Martins,  Lucas Henrique Cavalcanti Santos,  Lucas Dias Maciel,  Matheus Paixão Gumercindo dos Santos,  Matheus Lafayette Vasconcelos,  Matheus Vinícius Teotonio do Nascimento Andrade,  João Guilherme Oliveira Carvalho de Melo,  João Pedro Souza Pereira de Moura,  José Ronald da Silva,  José Victor Silva Cruz,  Pedro Henrique Santana de Morais,  Pedro Paulo Salman de Oliveira,  Riei Joaquim Matos Rodrigues,  Roberto Costa Fernandes,  Ryan Vinicius Santos Morais,  Tamara Mayara Ramos Teobaldo,  Washington Igor dos Santos Silva,  Edna Natividade Silva Barros",
                "发布日期": "2023-07-20",
                "摘要": "  Rob\\^oCIn has participated in RoboCup Small Size League since 2019, won its\nfirst world title in 2022 (Division B), and is currently a three-times\nLatin-American champion. This paper presents our improvements to defend the\nSmall Size League (SSL) division B title in RoboCup 2023 in Bordeaux, France.\nThis paper aims to share some of the academic research that our team developed\nover the past year. Our team has successfully published 2 articles related to\nSSL at two high-impact conferences: the 25th RoboCup International Symposium\nand the 19th IEEE Latin American Robotics Symposium (LARS 2022). Over the last\nyear, we have been continuously migrating from our past codebase to\nUnification. We will describe the new architecture implemented and some points\nof software and AI refactoring. In addition, we discuss the process of\nintegrating machined components into the mechanical system, our development for\nparticipating in the vision blackout challenge last year and what we are\npreparing for this year.\n",
                "链接": "https://arxiv.org/abs/2307.10018"
            },
            {
                "文章ID": "65767",
                "标题": "Position Paper on Dataset Engineering to Accelerate Science",
                "作者": " Emilio Vital Brazil,  Eduardo Soares,  Lucas Villa Real,  Leonardo Azevedo,  Vinicius Segura,  Luiz Zerkowski,  Renato Cerqueira",
                "发布日期": "2023-03-13",
                "摘要": "  Data is a critical element in any discovery process. In the last decades, we\nobserved exponential growth in the volume of available data and the technology\nto manipulate it. However, data is only practical when one can structure it for\na well-defined task. For instance, we need a corpus of text broken into\nsentences to train a natural language machine-learning model. In this work, we\nwill use the token \\textit{dataset} to designate a structured set of data built\nto perform a well-defined task. Moreover, the dataset will be used in most\ncases as a blueprint of an entity that at any moment can be stored as a table.\nSpecifically, in science, each area has unique forms to organize, gather and\nhandle its datasets. We believe that datasets must be a first-class entity in\nany knowledge-intensive process, and all workflows should have exceptional\nattention to datasets' lifecycle, from their gathering to uses and evolution.\nWe advocate that science and engineering discovery processes are extreme\ninstances of the need for such organization on datasets, claiming for new\napproaches and tooling. Furthermore, these requirements are more evident when\nthe discovery workflow uses artificial intelligence methods to empower the\nsubject-matter expert. In this work, we discuss an approach to bringing\ndatasets as a critical entity in the discovery process in science. We\nillustrate some concepts using material discovery as a use case. We chose this\ndomain because it leverages many significant problems that can be generalized\nto other science fields.\n",
                "链接": "https://arxiv.org/abs/2303.05545"
            },
            {
                "文章ID": "111240",
                "标题": "BLP 2023 Task 2: Sentiment Analysis",
                "作者": " Md. Arid Hasan,  Firoj Alam,  Anika Anjum,  Shudipta Das,  Afiyat Anjum",
                "发布日期": "2023-10-26",
                "摘要": "  We present an overview of the BLP Sentiment Shared Task, organized as part of\nthe inaugural BLP 2023 workshop, co-located with EMNLP 2023. The task is\ndefined as the detection of sentiment in a given piece of social media text.\nThis task attracted interest from 71 participants, among whom 29 and 30 teams\nsubmitted systems during the development and evaluation phases, respectively.\nIn total, participants submitted 597 runs. However, a total of 15 teams\nsubmitted system description papers. The range of approaches in the submitted\nsystems spans from classical machine learning models, fine-tuning pre-trained\nmodels, to leveraging Large Language Model (LLMs) in zero- and few-shot\nsettings. In this paper, we provide a detailed account of the task setup,\nincluding dataset development and evaluation setup. Additionally, we provide a\nbrief overview of the systems submitted by the participants. All datasets and\nevaluation scripts from the shared task have been made publicly available for\nthe research community, to foster further research in this domain\n",
                "链接": "https://arxiv.org/abs/2310.16183"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用机器学习方法进行心理健康疾病研究的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "22134",
                "标题": "Individual health-disease phase diagrams for disease prevention based on\n  machine learning",
                "作者": " Kazuki Nakamura,  Eiichiro Uchino,  Noriaki Sato,  Ayano Araki,  Kei Terayama,  Ryosuke Kojima,  Koichi Murashita,  Ken Itoh,  Tatsuya Mikami,  Yoshinori Tamada,  Yasushi Okuno",
                "发布日期": "2022-07-08",
                "摘要": "  Early disease detection and prevention methods based on effective\ninterventions are gaining attention. Machine learning technology has enabled\nprecise disease prediction by capturing individual differences in multivariate\ndata. Progress in precision medicine has revealed that substantial\nheterogeneity exists in health data at the individual level and that complex\nhealth factors are involved in the development of chronic diseases. However, it\nremains a challenge to identify individual physiological state changes in\ncross-disease onset processes because of the complex relationships among\nmultiple biomarkers. Here, we present the health-disease phase diagram (HDPD),\nwhich represents a personal health state by visualizing the boundary values of\nmultiple biomarkers that fluctuate early in the disease progression process. In\nHDPDs, future onset predictions are represented by perturbing multiple\nbiomarker values while accounting for dependencies among variables. We\nconstructed HDPDs for 11 non-communicable diseases (NCDs) from a longitudinal\nhealth checkup cohort of 3,238 individuals, comprising 3,215 measurement items\nand genetic data. Improvement of biomarker values to the non-onset region in\nHDPD significantly prevented future disease onset in 7 out of 11 NCDs. Our\nresults demonstrate that HDPDs can represent individual physiological states in\nthe onset process and be used as intervention goals for disease prevention.\n",
                "链接": "https://arxiv.org/abs/2205.15598"
            },
            {
                "文章ID": "98633",
                "标题": "Discovering Mental Health Research Topics with Topic Modeling",
                "作者": " Xin Gao,  Cem Sazara",
                "发布日期": "2023-08-29",
                "摘要": "  Mental health significantly influences various aspects of our daily lives,\nand its importance has been increasingly recognized by the research community\nand the general public, particularly in the wake of the COVID-19 pandemic. This\nheightened interest is evident in the growing number of publications dedicated\nto mental health in the past decade. In this study, our goal is to identify\ngeneral trends in the field and pinpoint high-impact research topics by\nanalyzing a large dataset of mental health research papers. To accomplish this,\nwe collected abstracts from various databases and trained a customized\nSentence-BERT based embedding model leveraging the BERTopic framework. Our\ndataset comprises 96,676 research papers pertaining to mental health, enabling\nus to examine the relationships between different topics using their abstracts.\nTo evaluate the effectiveness of the model, we compared it against two other\nstate-of-the-art methods: Top2Vec model and LDA-BERT model. The model\ndemonstrated superior performance in metrics that measure topic diversity and\ncoherence. To enhance our analysis, we also generated word clouds to provide a\ncomprehensive overview of the machine learning models applied in mental health\nresearch, shedding light on commonly utilized techniques and emerging trends.\nFurthermore, we provide a GitHub link* to the dataset used in this paper,\nensuring its accessibility for further research endeavors.\n",
                "链接": "https://arxiv.org/abs/2308.13569"
            },
            {
                "文章ID": "113411",
                "标题": "Identifying Alzheimer Disease Dementia Levels Using Machine Learning\n  Methods",
                "作者": " Md Gulzar Hussain,  Ye Shiren",
                "发布日期": "2023-11-06",
                "摘要": "  Dementia, a prevalent neurodegenerative condition, is a major manifestation\nof Alzheimer's disease (AD). As the condition progresses from mild to severe,\nit significantly impairs the individual's ability to perform daily tasks\nindependently, necessitating the need for timely and accurate AD\nclassification. Machine learning or deep learning models have emerged as\neffective tools for this purpose. In this study, we suggested an approach for\nclassifying the four stages of dementia using RF, SVM, and CNN algorithms,\naugmented with watershed segmentation for feature extraction from MRI images.\nOur results reveal that SVM with watershed features achieves an impressive\naccuracy of 96.25%, surpassing other classification methods. The ADNI dataset\nis utilized to evaluate the effectiveness of our method, and we observed that\nthe inclusion of watershed segmentation contributes to the enhanced performance\nof the models.\n",
                "链接": "https://arxiv.org/abs/2311.01428"
            },
            {
                "文章ID": "20900",
                "标题": "Bias Discovery in Machine Learning Models for Mental Health",
                "作者": " Pablo Mosteiro,  Jesse Kuiper,  Judith Masthoff,  Floortje Scheepers,  Marco Spruit",
                "发布日期": "2022-05-25",
                "摘要": "  Fairness and bias are crucial concepts in artificial intelligence, yet they\nare relatively ignored in machine learning applications in clinical psychiatry.\nWe computed fairness metrics and present bias mitigation strategies using a\nmodel trained on clinical mental health data. We collected structured data\nrelated to the admission, diagnosis, and treatment of patients in the\npsychiatry department of the University Medical Center Utrecht. We trained a\nmachine learning model to predict future administrations of benzodiazepines on\nthe basis of past data. We found that gender plays an unexpected role in the\npredictions-this constitutes bias. Using the AI Fairness 360 package, we\nimplemented reweighing and discrimination-aware regularization as bias\nmitigation strategies, and we explored their implications for model\nperformance. This is the first application of bias exploration and mitigation\nin a machine learning model trained on real clinical psychiatry data.\n",
                "链接": "https://arxiv.org/abs/2205.12093"
            },
            {
                "文章ID": "32886",
                "标题": "Research on restaurant recommendation using machine learning",
                "作者": " Junan Pan,  Zhihao Zhao",
                "发布日期": "2022-08-11",
                "摘要": "  A recommender system is a system that helps users filter irrelevant\ninformation and create user interest models based on their historical records.\nWith the continuous development of Internet information, recommendation systems\nhave received widespread attention in the industry. In this era of ubiquitous\ndata and information, how to obtain and analyze these data has become the\nresearch topic of many people. In view of this situation, this paper makes some\nbrief overviews of machine learning-related recommendation systems. By\nanalyzing some technologies and ideas used by machine learning in recommender\nsystems, let more people understand what is Big data and what is machine\nlearning. The most important point is to let everyone understand the profound\nimpact of machine learning on our daily life.\n",
                "链接": "https://arxiv.org/abs/2208.05113"
            },
            {
                "文章ID": "32474",
                "标题": "Bias Reducing Multitask Learning on Mental Health Prediction",
                "作者": " Khadija Zanna,  Kusha Sridhar,  Han Yu,  Akane Sano",
                "发布日期": "2022-08-09",
                "摘要": "  There has been an increase in research in developing machine learning models\nfor mental health detection or prediction in recent years due to increased\nmental health issues in society. Effective use of mental health prediction or\ndetection models can help mental health practitioners re-define mental\nillnesses more objectively than currently done, and identify illnesses at an\nearlier stage when interventions may be more effective. However, there is still\na lack of standard in evaluating bias in such machine learning models in the\nfield, which leads to challenges in providing reliable predictions and in\naddressing disparities. This lack of standards persists due to factors such as\ntechnical difficulties, complexities of high dimensional clinical health data,\netc., which are especially true for physiological signals. This along with\nprior evidence of relations between some physiological signals with certain\ndemographic identities restates the importance of exploring bias in mental\nhealth prediction models that utilize physiological signals. In this work, we\naim to perform a fairness analysis and implement a multi-task learning based\nbias mitigation method on anxiety prediction models using ECG data. Our method\nis based on the idea of epistemic uncertainty and its relationship with model\nweights and feature space representation. Our analysis showed that our anxiety\nprediction base model introduced some bias with regards to age, income,\nethnicity, and whether a participant is born in the U.S. or not, and our bias\nmitigation method performed better at reducing the bias in the model, when\ncompared to the reweighting mitigation technique. Our analysis on feature\nimportance also helped identify relationships between heart rate variability\nand multiple demographic groupings.\n",
                "链接": "https://arxiv.org/abs/2208.03621"
            },
            {
                "文章ID": "57937",
                "标题": "Deep Learning Mental Health Dialogue System",
                "作者": " Lennart Brocki,  George C. Dyer,  Anna Gładka,  Neo Christopher Chung",
                "发布日期": "2023-01-24",
                "摘要": "  Mental health counseling remains a major challenge in modern society due to\ncost, stigma, fear, and unavailability. We posit that generative artificial\nintelligence (AI) models designed for mental health counseling could help\nimprove outcomes by lowering barriers to access. To this end, we have developed\na deep learning (DL) dialogue system called Serena. The system consists of a\ncore generative model and post-processing algorithms. The core generative model\nis a 2.7 billion parameter Seq2Seq Transformer fine-tuned on thousands of\ntranscripts of person-centered-therapy (PCT) sessions. The series of\npost-processing algorithms detects contradictions, improves coherency, and\nremoves repetitive answers. Serena is implemented and deployed on\n\\url{https://serena.chat}, which currently offers limited free services. While\nthe dialogue system is capable of responding in a qualitatively empathetic and\nengaging manner, occasionally it displays hallucination and long-term\nincoherence. Overall, we demonstrate that a deep learning mental health\ndialogue system has the potential to provide a low-cost and effective\ncomplement to traditional human counselors with less barriers to access.\n",
                "链接": "https://arxiv.org/abs/2301.09412"
            },
            {
                "文章ID": "56312",
                "标题": "Causal Categorization of Mental Health Posts using Transformers",
                "作者": " Simranjeet Kaur,  Ritika Bhardwaj,  Aastha Jain,  Muskan Garg,  Chandni Saxena",
                "发布日期": "2023-01-18",
                "摘要": "  With recent developments in digitization of clinical psychology, NLP research\ncommunity has revolutionized the field of mental health detection on social\nmedia. Existing research in mental health analysis revolves around the\ncross-sectional studies to classify users' intent on social media. For in-depth\nanalysis, we investigate existing classifiers to solve the problem of causal\ncategorization which suggests the inefficiency of learning based methods due to\nlimited training samples. To handle this challenge, we use transformer models\nand demonstrate the efficacy of a pre-trained transfer learning on \"CAMS\"\ndataset. The experimental result improves the accuracy and depicts the\nimportance of identifying cause-and-effect relationships in the underlying\ntext.\n",
                "链接": "https://arxiv.org/abs/2301.02589"
            },
            {
                "文章ID": "116611",
                "标题": "Classification Methods Based on Machine Learning for the Analysis of\n  Fetal Health Data",
                "作者": " Binod Regmi,  Chiranjibi Shah",
                "发布日期": "2023-11-21",
                "摘要": "  The persistent battle to decrease childhood mortality serves as a commonly\nemployed benchmark for gauging advancements in the field of medicine. Globally,\nthe under-5 mortality rate stands at approximately 5 million, with a\nsignificant portion of these deaths being avoidable. Given the significance of\nthis problem, Machine learning-based techniques have emerged as a prominent\ntool for assessing fetal health. In this work, we have analyzed the\nclassification performance of various machine learning models for fetal health\nanalysis. Classification performance of various machine learning models, such\nas support vector machine (SVM), random forest(RF), and attentive interpretable\ntabular learning (TabNet) have been assessed on fetal health. Moreover,\ndimensionality reduction techniques, such as Principal component analysis (PCA)\nand Linear discriminant analysis (LDA) have been implemented to obtain better\nclassification performance with less number of features. A TabNet model on a\nfetal health dataset provides a classification accuracy of 94.36%. In general,\nthis technology empowers doctors and healthcare experts to achieve precise\nfetal health classification and identify the most influential features in the\nprocess.\n",
                "链接": "https://arxiv.org/abs/2311.10962"
            },
            {
                "文章ID": "23569",
                "标题": "Counseling Summarization using Mental Health Knowledge Guided Utterance\n  Filtering",
                "作者": "Grin  Aseem Srivastava, Grin  Tharun Suresh, Grin  Sarah Peregrine,   Lord,  Md. Shad Akhtar,  Tanmoy Chakraborty",
                "发布日期": "2022-06-09",
                "摘要": "  The psychotherapy intervention technique is a multifaceted conversation\nbetween a therapist and a patient. Unlike general clinical discussions,\npsychotherapy's core components (viz. symptoms) are hard to distinguish, thus\nbecoming a complex problem to summarize later. A structured counseling\nconversation may contain discussions about symptoms, history of mental health\nissues, or the discovery of the patient's behavior. It may also contain\ndiscussion filler words irrelevant to a clinical summary. We refer to these\nelements of structured psychotherapy as counseling components. In this paper,\nthe aim is mental health counseling summarization to build upon domain\nknowledge and to help clinicians quickly glean meaning. We create a new dataset\nafter annotating 12.9K utterances of counseling components and reference\nsummaries for each dialogue. Further, we propose ConSum, a novel\ncounseling-component guided summarization model. ConSum undergoes three\nindependent modules. First, to assess the presence of depressive symptoms, it\nfilters utterances utilizing the Patient Health Questionnaire (PHQ-9), while\nthe second and third modules aim to classify counseling components. At last, we\npropose a problem-specific Mental Health Information Capture (MHIC) evaluation\nmetric for counseling summaries. Our comparative study shows that we improve on\nperformance and generate cohesive, semantic, and coherent summaries. We\ncomprehensively analyze the generated summaries to investigate the capturing of\npsychotherapy elements. Human and clinical evaluations on the summary show that\nConSum generates quality summary. Further, mental health experts validate the\nclinical acceptability of the ConSum. Lastly, we discuss the uniqueness in\nmental health counseling summarization in the real world and show evidences of\nits deployment on an online application with the support of mpathic.ai\n",
                "链接": "https://arxiv.org/abs/2206.03886"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "65067",
                "标题": "Evaluating the Fairness of Deep Learning Uncertainty Estimates in\n  Medical Image Analysis",
                "作者": " Raghav Mehta,  Changjian Shui,  Tal Arbel",
                "发布日期": "2023-03-07",
                "摘要": "  Although deep learning (DL) models have shown great success in many medical\nimage analysis tasks, deployment of the resulting models into real clinical\ncontexts requires: (1) that they exhibit robustness and fairness across\ndifferent sub-populations, and (2) that the confidence in DL model predictions\nbe accurately expressed in the form of uncertainties. Unfortunately, recent\nstudies have indeed shown significant biases in DL models across demographic\nsubgroups (e.g., race, sex, age) in the context of medical image analysis,\nindicating a lack of fairness in the models. Although several methods have been\nproposed in the ML literature to mitigate a lack of fairness in DL models, they\nfocus entirely on the absolute performance between groups without considering\ntheir effect on uncertainty estimation. In this work, we present the first\nexploration of the effect of popular fairness models on overcoming biases\nacross subgroups in medical image analysis in terms of bottom-line performance,\nand their effects on uncertainty quantification. We perform extensive\nexperiments on three different clinically relevant tasks: (i) skin lesion\nclassification, (ii) brain tumour segmentation, and (iii) Alzheimer's disease\nclinical score regression. Our results indicate that popular ML methods, such\nas data-balancing and distributionally robust optimization, succeed in\nmitigating fairness issues in terms of the model performances for some of the\ntasks. However, this can come at the cost of poor uncertainty estimates\nassociated with the model predictions. This tradeoff must be mitigated if\nfairness models are to be adopted in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2303.03242"
            },
            {
                "文章ID": "69437",
                "标题": "Medical Image Analysis using Deep Relational Learning",
                "作者": " Zhihua Liu",
                "发布日期": "2023-03-29",
                "摘要": "  In the past ten years, with the help of deep learning, especially the rapid\ndevelopment of deep neural networks, medical image analysis has made remarkable\nprogress. However, how to effectively use the relational information between\nvarious tissues or organs in medical images is still a very challenging\nproblem, and it has not been fully studied. In this thesis, we propose two\nnovel solutions to this problem based on deep relational learning. First, we\npropose a context-aware fully convolutional network that effectively models\nimplicit relation information between features to perform medical image\nsegmentation. The network achieves the state-of-the-art segmentation results on\nthe Multi Modal Brain Tumor Segmentation 2017 (BraTS2017) and Multi Modal Brain\nTumor Segmentation 2018 (BraTS2018) data sets. Subsequently, we propose a new\nhierarchical homography estimation network to achieve accurate medical image\nmosaicing by learning the explicit spatial relationship between adjacent\nframes. We use the UCL Fetoscopy Placenta dataset to conduct experiments and\nour hierarchical homography estimation network outperforms the other\nstate-of-the-art mosaicing methods while generating robust and meaningful\nmosaicing result on unseen frames.\n",
                "链接": "https://arxiv.org/abs/2303.16099"
            },
            {
                "文章ID": "3541",
                "标题": "Research on Question Classification Methods in the Medical Field",
                "作者": " Jinzhang Liu",
                "发布日期": "2022-02-02",
                "摘要": "  Question classification is one of the important links in the research of\nquestion and answering system. The existing question classification models are\nmore trained on public data sets. At present, there is a lack of question\nclassification data sets in specific fields, especially in the medical field.\nTo make up for this gap, this paper presents a data set for question\nclassification in the medical field. Moreover, this paper proposes a\nmulti-dimensional extraction of the characteristics of the question by\ncombining multiple neural network models, and proposes a question\nclassification model based on multi-dimensional feature extraction. The\nexperimental results show that the proposed method can effectively improve the\nperformance of question classification.\n",
                "链接": "https://arxiv.org/abs/2202.00298"
            },
            {
                "文章ID": "110503",
                "标题": "A comprehensive survey on deep active learning and its applications in\n  medical image analysis",
                "作者": " Haoran Wang,  Qiuye Jin,  Shiman Li,  Siyu Liu,  Manning Wang,  Zhijian Song",
                "发布日期": "2023-10-25",
                "摘要": "  Deep learning has achieved widespread success in medical image analysis,\nleading to an increasing demand for large-scale expert-annotated medical image\ndatasets. Yet, the high cost of annotating medical images severely hampers the\ndevelopment of deep learning in this field. To reduce annotation costs, active\nlearning aims to select the most informative samples for annotation and train\nhigh-performance models with as few labeled samples as possible. In this\nsurvey, we review the core methods of active learning, including the evaluation\nof informativeness and sampling strategy. For the first time, we provide a\ndetailed summary of the integration of active learning with other\nlabel-efficient techniques, such as semi-supervised, self-supervised learning,\nand so on. Additionally, we also highlight active learning works that are\nspecifically tailored to medical image analysis. In the end, we offer our\nperspectives on the future trends and challenges of active learning and its\napplications in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2310.14230"
            },
            {
                "文章ID": "56274",
                "标题": "Deep-learning models in medical image analysis: Detection of esophagitis\n  from the Kvasir Dataset",
                "作者": " Kyoka Yoshiok,  Kensuke Tanioka,  Satoru Hiwa,  Tomoyuki Hiroyasu",
                "发布日期": "2023-01-09",
                "摘要": "  Early detection of esophagitis is important because this condition can\nprogress to cancer if left untreated. However, the accuracies of different deep\nlearning models in detecting esophagitis have yet to be compared. Thus, this\nstudy aimed to compare the accuracies of convolutional neural network models\n(GoogLeNet, ResNet-50, MobileNet V2, and MobileNet V3) in detecting esophagitis\nfrom the open Kvasir dataset of endoscopic images. Results showed that among\nthe models, GoogLeNet achieved the highest F1-scores. Based on the average of\ntrue positive rate, MobileNet V3 predicted esophagitis more confidently than\nthe other models. The results obtained using the models were also compared with\nthose obtained using SHapley Additive exPlanations and Gradient-weighted Class\nActivation Mapping.\n",
                "链接": "https://arxiv.org/abs/2301.02390"
            },
            {
                "文章ID": "36669",
                "标题": "Bridging the Gap: Differentially Private Equivariant Deep Learning for\n  Medical Image Analysis",
                "作者": " Florian A. Hölzl,  Daniel Rueckert,  Georgios Kaissis",
                "发布日期": "2023-06-21",
                "摘要": "  Machine learning with formal privacy-preserving techniques like Differential\nPrivacy (DP) allows one to derive valuable insights from sensitive medical\nimaging data while promising to protect patient privacy, but it usually comes\nat a sharp privacy-utility trade-off. In this work, we propose to use steerable\nequivariant convolutional networks for medical image analysis with DP. Their\nimproved feature quality and parameter efficiency yield remarkable accuracy\ngains, narrowing the privacy-utility gap.\n",
                "链接": "https://arxiv.org/abs/2209.04338"
            },
            {
                "文章ID": "11766",
                "标题": "Intelligent Masking: Deep Q-Learning for Context Encoding in Medical\n  Image Analysis",
                "作者": " Mojtaba Bahrami,  Mahsa Ghorbani,  Nassir Navab",
                "发布日期": "2022-04-06",
                "摘要": "  The need for a large amount of labeled data in the supervised setting has led\nrecent studies to utilize self-supervised learning to pre-train deep neural\nnetworks using unlabeled data. Many self-supervised training strategies have\nbeen investigated especially for medical datasets to leverage the information\navailable in the much fewer unlabeled data. One of the fundamental strategies\nin image-based self-supervision is context prediction. In this approach, a\nmodel is trained to reconstruct the contents of an arbitrary missing region of\nan image based on its surroundings. However, the existing methods adopt a\nrandom and blind masking approach by focusing uniformly on all regions of the\nimages. This approach results in a lot of unnecessary network updates that\ncause the model to forget the rich extracted features. In this work, we develop\na novel self-supervised approach that occludes targeted regions to improve the\npre-training procedure. To this end, we propose a reinforcement learning-based\nagent which learns to intelligently mask input images through deep Q-learning.\nWe show that training the agent against the prediction model can significantly\nimprove the semantic features extracted for downstream classification tasks. We\nperform our experiments on two public datasets for diagnosing breast cancer in\nthe ultrasound images and detecting lower-grade glioma with MR images. In our\nexperiments, we show that our novel masking strategy advances the learned\nfeatures according to the performance on the classification task in terms of\naccuracy, macro F1, and AUROC.\n",
                "链接": "https://arxiv.org/abs/2203.13865"
            },
            {
                "文章ID": "68134",
                "标题": "Label-Efficient Deep Learning in Medical Image Analysis: Challenges and\n  Future Directions",
                "作者": " Cheng Jin,  Zhengrui Guo,  Yi Lin,  Luyang Luo,  Hao Chen",
                "发布日期": "2023-12-21",
                "摘要": "  Deep learning has seen rapid growth in recent years and achieved\nstate-of-the-art performance in a wide range of applications. However, training\nmodels typically requires expensive and time-consuming collection of large\nquantities of labeled data. This is particularly true within the scope of\nmedical imaging analysis (MIA), where data are limited and labels are expensive\nto be acquired. Thus, label-efficient deep learning methods are developed to\nmake comprehensive use of the labeled data as well as the abundance of\nunlabeled and weak-labeled data. In this survey, we extensively investigated\nover 300 recent papers to provide a comprehensive overview of recent progress\non label-efficient learning strategies in MIA. We first present the background\nof label-efficient learning and categorize the approaches into different\nschemes. Next, we examine the current state-of-the-art methods in detail\nthrough each scheme. Specifically, we provide an in-depth investigation,\ncovering not only canonical semi-supervised, self-supervised, and\nmulti-instance learning schemes, but also recently emerged active and\nannotation-efficient learning strategies. Moreover, as a comprehensive\ncontribution to the field, this survey not only elucidates the commonalities\nand unique features of the surveyed methods but also presents a detailed\nanalysis of the current challenges in the field and suggests potential avenues\nfor future research.\n",
                "链接": "https://arxiv.org/abs/2303.12484"
            },
            {
                "文章ID": "2860",
                "标题": "An Analysis on Ensemble Learning optimized Medical Image Classification\n  with Deep Convolutional Neural Networks",
                "作者": " Dominik Müller,  Iñaki Soto-Rey,  Frank Kramer",
                "发布日期": "2022-04-14",
                "摘要": "  Novel and high-performance medical image classification pipelines are heavily\nutilizing ensemble learning strategies. The idea of ensemble learning is to\nassemble diverse models or multiple predictions and, thus, boost prediction\nperformance. However, it is still an open question to what extent as well as\nwhich ensemble learning strategies are beneficial in deep learning based\nmedical image classification pipelines. In this work, we proposed a\nreproducible medical image classification pipeline for analyzing the\nperformance impact of the following ensemble learning techniques: Augmenting,\nStacking, and Bagging. The pipeline consists of state-of-the-art preprocessing\nand image augmentation methods as well as 9 deep convolution neural network\narchitectures. It was applied on four popular medical imaging datasets with\nvarying complexity. Furthermore, 12 pooling functions for combining multiple\npredictions were analyzed, ranging from simple statistical functions like\nunweighted averaging up to more complex learning-based functions like support\nvector machines. Our results revealed that Stacking achieved the largest\nperformance gain of up to 13% F1-score increase. Augmenting showed consistent\nimprovement capabilities by up to 4% and is also applicable to single model\nbased pipelines. Cross-validation based Bagging demonstrated significant\nperformance gain close to Stacking, which resulted in an F1-score increase up\nto +11%. Furthermore, we demonstrated that simple statistical pooling functions\nare equal or often even better than more complex pooling functions. We\nconcluded that the integration of ensemble learning techniques is a powerful\nmethod for any medical image classification pipeline to improve robustness and\nboost performance.\n",
                "链接": "https://arxiv.org/abs/2201.11440"
            },
            {
                "文章ID": "52332",
                "标题": "A Trustworthy Framework for Medical Image Analysis with Deep Learning",
                "作者": " Kai Ma,  Siyuan He,  Pengcheng Xi,  Ashkan Ebadi,  Stéphane Tremblay,  Alexander Wong",
                "发布日期": "2022-12-07",
                "摘要": "  Computer vision and machine learning are playing an increasingly important\nrole in computer-assisted diagnosis; however, the application of deep learning\nto medical imaging has challenges in data availability and data imbalance, and\nit is especially important that models for medical imaging are built to be\ntrustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning\nframework for medical image analysis, which adopts a modular design, leverages\nself-supervised pre-training, and utilizes a novel surrogate loss function.\nExperimental evaluations indicate that models generated from the framework are\nboth trustworthy and high-performing. It is anticipated that the framework will\nsupport researchers and clinicians in advancing the use of deep learning for\ndealing with public health crises including COVID-19.\n",
                "链接": "https://arxiv.org/abs/2212.02764"
            }
        ]
    },
    {
        "question": {
            "question": "查找基于优化实现模型越狱的文献",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "71794",
                "标题": "Multi-step Jailbreaking Privacy Attacks on ChatGPT",
                "作者": " Haoran Li,  Dadi Guo,  Wei Fan,  Mingshi Xu,  Jie Huang,  Fanpu Meng,  Yangqiu Song",
                "发布日期": "2023-11-02",
                "摘要": "  With the rapid progress of large language models (LLMs), many downstream NLP\ntasks can be well solved given appropriate prompts. Though model developers and\nresearchers work hard on dialog safety to avoid generating harmful content from\nLLMs, it is still challenging to steer AI-generated content (AIGC) for the\nhuman good. As powerful LLMs are devouring existing text data from various\ndomains (e.g., GPT-3 is trained on 45TB texts), it is natural to doubt whether\nthe private information is included in the training data and what privacy\nthreats can these LLMs and their downstream applications bring. In this paper,\nwe study the privacy threats from OpenAI's ChatGPT and the New Bing enhanced by\nChatGPT and show that application-integrated LLMs may cause new privacy\nthreats. To this end, we conduct extensive experiments to support our claims\nand discuss LLMs' privacy implications.\n",
                "链接": "https://arxiv.org/abs/2304.05197"
            },
            {
                "文章ID": "96414",
                "标题": "Symphony: Optimized Model Serving using Centralized Orchestration",
                "作者": " Lequn Chen,  Weixin Deng,  Anirudh Canumalla,  Yu Xin,  Matthai Philipose,  Arvind Krishnamurthy",
                "发布日期": "2023-08-16",
                "摘要": "  The orchestration of deep neural network (DNN) model inference on GPU\nclusters presents two significant challenges: achieving high accelerator\nefficiency given the batching properties of model inference while meeting\nlatency service level objectives (SLOs), and adapting to workload changes both\nin terms of short-term fluctuations and long-term resource allocation. To\naddress these challenges, we propose Symphony, a centralized scheduling system\nthat can scale to millions of requests per second and coordinate tens of\nthousands of GPUs. Our system utilizes a non-work-conserving scheduling\nalgorithm capable of achieving high batch efficiency while also enabling robust\nautoscaling. Additionally, we developed an epoch-scale algorithm that allocates\nmodels to sub-clusters based on the compute and memory needs of the models.\nThrough extensive experiments, we demonstrate that Symphony outperforms prior\nsystems by up to 4.7x higher goodput.\n",
                "链接": "https://arxiv.org/abs/2308.07470"
            },
            {
                "文章ID": "78917",
                "标题": "SneakyPrompt: Jailbreaking Text-to-image Generative Models",
                "作者": " Yuchen Yang,  Bo Hui,  Haolin Yuan,  Neil Gong,  Yinzhi Cao",
                "发布日期": "2023-11-14",
                "摘要": "  Text-to-image generative models such as Stable Diffusion and DALL$\\cdot$E\nraise many ethical concerns due to the generation of harmful images such as\nNot-Safe-for-Work (NSFW) ones. To address these ethical concerns, safety\nfilters are often adopted to prevent the generation of NSFW images. In this\nwork, we propose SneakyPrompt, the first automated attack framework, to\njailbreak text-to-image generative models such that they generate NSFW images\neven if safety filters are adopted. Given a prompt that is blocked by a safety\nfilter, SneakyPrompt repeatedly queries the text-to-image generative model and\nstrategically perturbs tokens in the prompt based on the query results to\nbypass the safety filter. Specifically, SneakyPrompt utilizes reinforcement\nlearning to guide the perturbation of tokens. Our evaluation shows that\nSneakyPrompt successfully jailbreaks DALL$\\cdot$E 2 with closed-box safety\nfilters to generate NSFW images. Moreover, we also deploy several\nstate-of-the-art, open-source safety filters on a Stable Diffusion model. Our\nevaluation shows that SneakyPrompt not only successfully generates NSFW images,\nbut also outperforms existing text adversarial attacks when extended to\njailbreak text-to-image generative models, in terms of both the number of\nqueries and qualities of the generated NSFW images. SneakyPrompt is open-source\nand available at this repository:\n\\url{https://github.com/Yuchen413/text2image_safety}.\n",
                "链接": "https://arxiv.org/abs/2305.12082"
            },
            {
                "文章ID": "44293",
                "标题": "FIND: An Unsupervised Implicit 3D Model of Articulated Human Feet",
                "作者": " Oliver Boyne,  James Charles,  Roberto Cipolla",
                "发布日期": "2022-11-23",
                "摘要": "  In this paper we present a high fidelity and articulated 3D human foot model.\nThe model is parameterised by a disentangled latent code in terms of shape,\ntexture and articulated pose. While high fidelity models are typically created\nwith strong supervision such as 3D keypoint correspondences or\npre-registration, we focus on the difficult case of little to no annotation. To\nthis end, we make the following contributions: (i) we develop a Foot Implicit\nNeural Deformation field model, named FIND, capable of tailoring explicit\nmeshes at any resolution i.e. for low or high powered devices; (ii) an approach\nfor training our model in various modes of weak supervision with progressively\nbetter disentanglement as more labels, such as pose categories, are provided;\n(iii) a novel unsupervised part-based loss for fitting our model to 2D images\nwhich is better than traditional photometric or silhouette losses; (iv)\nfinally, we release a new dataset of high resolution 3D human foot scans,\nFoot3D. On this dataset, we show our model outperforms a strong PCA\nimplementation trained on the same data in terms of shape quality and part\ncorrespondences, and that our novel unsupervised part-based loss improves\ninference on images.\n",
                "链接": "https://arxiv.org/abs/2210.12241"
            },
            {
                "文章ID": "55131",
                "标题": "An optimized fuzzy logic model for proactive maintenance",
                "作者": " Abdelouadoud Kerarmi,  Assia Kamal-idrissi,  Amal El Fallah Seghrouchni",
                "发布日期": "2022-12-27",
                "摘要": "  Fuzzy logic has been proposed in previous studies for machine diagnosis, to\novercome different drawbacks of the traditional diagnostic approaches used.\nAmong these approaches Failure Mode and Effect Critical Analysis method(FMECA)\nattempts to identify potential modes and treat failures before they occur based\non subjective expert judgments. Although several versions of fuzzy logic are\nused to improve FMECA or to replace it, since it is an extremely cost-intensive\napproach in terms of failure modes because it evaluates each one of them\nseparately, these propositions have not explicitly focused on the combinatorial\ncomplexity nor justified the choice of membership functions in Fuzzy logic\nmodeling. Within this context, we develop an optimization-based approach\nreferred to Integrated Truth Table and Fuzzy Logic Model (ITTFLM) that smartly\ngenerates fuzzy logic rules using Truth Tables. The ITTFLM was tested on fan\ndata collected in real-time from a plant machine. In the experiment, three\ntypes of membership functions (Triangular, Trapezoidal, and Gaussian) were\nused. The ITTFLM can generate outputs in 5ms, the results demonstrate that this\nmodel based on the Trapezoidal membership functions identifies the failure\nstates with high accuracy, and its capability of dealing with large numbers of\nrules and thus meets the real-time constraints that usually impact user\nexperience.\n",
                "链接": "https://arxiv.org/abs/2212.12757"
            },
            {
                "文章ID": "60419",
                "标题": "The Effect of Metadata on Scientific Literature Tagging: A Cross-Field\n  Cross-Model Study",
                "作者": " Yu Zhang,  Bowen Jin,  Qi Zhu,  Yu Meng,  Jiawei Han",
                "发布日期": "2023-10-24",
                "摘要": "  Due to the exponential growth of scientific publications on the Web, there is\na pressing need to tag each paper with fine-grained topics so that researchers\ncan track their interested fields of study rather than drowning in the whole\nliterature. Scientific literature tagging is beyond a pure multi-label text\nclassification task because papers on the Web are prevalently accompanied by\nmetadata information such as venues, authors, and references, which may serve\nas additional signals to infer relevant tags. Although there have been studies\nmaking use of metadata in academic paper classification, their focus is often\nrestricted to one or two scientific fields (e.g., computer science and\nbiomedicine) and to one specific model. In this work, we systematically study\nthe effect of metadata on scientific literature tagging across 19 fields. We\nselect three representative multi-label classifiers (i.e., a bag-of-words\nmodel, a sequence-based model, and a pre-trained language model) and explore\ntheir performance change in scientific literature tagging when metadata are fed\nto the classifiers as additional features. We observe some ubiquitous patterns\nof metadata's effects across all fields (e.g., venues are consistently\nbeneficial to paper tagging in almost all cases), as well as some unique\npatterns in fields other than computer science and biomedicine, which are not\nexplored in previous studies.\n",
                "链接": "https://arxiv.org/abs/2302.03341"
            },
            {
                "文章ID": "79722",
                "标题": "Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study",
                "作者": " Yi Liu,  Gelei Deng,  Zhengzi Xu,  Yuekang Li,  Yaowen Zheng,  Ying Zhang,  Lida Zhao,  Tianwei Zhang,  Yang Liu",
                "发布日期": "2023-05-24",
                "摘要": "  Large Language Models (LLMs), like ChatGPT, have demonstrated vast potential\nbut also introduce challenges related to content constraints and potential\nmisuse. Our study investigates three key research questions: (1) the number of\ndifferent prompt types that can jailbreak LLMs, (2) the effectiveness of\njailbreak prompts in circumventing LLM constraints, and (3) the resilience of\nChatGPT against these jailbreak prompts. Initially, we develop a classification\nmodel to analyze the distribution of existing prompts, identifying ten distinct\npatterns and three categories of jailbreak prompts. Subsequently, we assess the\njailbreak capability of prompts with ChatGPT versions 3.5 and 4.0, utilizing a\ndataset of 3,120 jailbreak questions across eight prohibited scenarios.\nFinally, we evaluate the resistance of ChatGPT against jailbreak prompts,\nfinding that the prompts can consistently evade the restrictions in 40 use-case\nscenarios. The study underscores the importance of prompt structures in\njailbreaking LLMs and discusses the challenges of robust jailbreak prompt\ngeneration and prevention.\n",
                "链接": "https://arxiv.org/abs/2305.13860"
            },
            {
                "文章ID": "106619",
                "标题": "SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks",
                "作者": " Alexander Robey,  Eric Wong,  Hamed Hassani,  George J. Pappas",
                "发布日期": "2023-11-30",
                "摘要": "  Despite efforts to align large language models (LLMs) with human values,\nwidely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to\njailbreaking attacks, wherein an adversary fools a targeted LLM into generating\nobjectionable content. To address this vulnerability, we propose SmoothLLM, the\nfirst algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our\nfinding that adversarially-generated prompts are brittle to character-level\nchanges, our defense first randomly perturbs multiple copies of a given input\nprompt, and then aggregates the corresponding predictions to detect adversarial\ninputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to\nbelow one percentage point, avoids unnecessary conservatism, and admits\nprovable guarantees on attack mitigation. Moreover, our defense uses\nexponentially fewer queries than existing attacks and is compatible with any\nLLM. Our code is publicly available at the following link:\nhttps://github.com/arobey1/smooth-llm.\n",
                "链接": "https://arxiv.org/abs/2310.03684"
            },
            {
                "文章ID": "120088",
                "标题": "Tree of Attacks: Jailbreaking Black-Box LLMs Automatically",
                "作者": " Anay Mehrotra,  Manolis Zampetakis,  Paul Kassianik,  Blaine Nelson,  Hyrum Anderson,  Yaron Singer,  Amin Karbasi",
                "发布日期": "2023-12-05",
                "摘要": "  While Large Language Models (LLMs) display versatile functionality, they\ncontinue to generate harmful, biased, and toxic content, as demonstrated by the\nprevalence of human-designed jailbreaks. In this work, we present Tree of\nAttacks with Pruning (TAP), an automated method for generating jailbreaks that\nonly requires black-box access to the target LLM. TAP utilizes an LLM to\niteratively refine candidate (attack) prompts using tree-of-thoughts reasoning\nuntil one of the generated prompts jailbreaks the target. Crucially, before\nsending prompts to the target, TAP assesses them and prunes the ones unlikely\nto result in jailbreaks. Using tree-of-thought reasoning allows TAP to navigate\na large search space of prompts and pruning reduces the total number of queries\nsent to the target. In empirical evaluations, we observe that TAP generates\nprompts that jailbreak state-of-the-art LLMs (including GPT4 and GPT4-Turbo)\nfor more than 80% of the prompts using only a small number of queries. This\nsignificantly improves upon the previous state-of-the-art black-box method for\ngenerating jailbreaks.\n",
                "链接": "https://arxiv.org/abs/2312.02119"
            },
            {
                "文章ID": "57228",
                "标题": "Ankh: Optimized Protein Language Model Unlocks General-Purpose Modelling",
                "作者": " Ahmed Elnaggar,  Hazem Essam,  Wafaa Salah-Eldin,  Walid Moustafa,  Mohamed Elkerdawy,  Charlotte Rochereau,  Burkhard Rost",
                "发布日期": "2023-01-18",
                "摘要": "  As opposed to scaling-up protein language models (PLMs), we seek improving\nperformance via protein-specific optimization. Although the proportionality\nbetween the language model size and the richness of its learned representations\nis validated, we prioritize accessibility and pursue a path of data-efficient,\ncost-reduced, and knowledge-guided optimization. Through over twenty\nexperiments ranging from masking, architecture, and pre-training data, we\nderive insights from protein-specific experimentation into building a model\nthat interprets the language of life, optimally. We present Ankh, the first\ngeneral-purpose PLM trained on Google's TPU-v4 surpassing the state-of-the-art\nperformance with fewer parameters (<10% for pre-training, <7% for inference,\nand <30% for the embedding dimension). We provide a representative range of\nstructure and function benchmarks where Ankh excels. We further provide a\nprotein variant generation analysis on High-N and One-N input data scales where\nAnkh succeeds in learning protein evolutionary conservation-mutation trends and\nintroducing functional diversity while retaining key structural-functional\ncharacteristics. We dedicate our work to promoting accessibility to research\ninnovation via attainable resources.\n",
                "链接": "https://arxiv.org/abs/2301.06568"
            }
        ]
    },
    {
        "question": {
            "question": "强化学习在大语言模型领域中应用的相关论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "116733",
                "标题": "Rethinking Large Language Models in Mental Health Applications",
                "作者": " Shaoxiong Ji,  Tianlin Zhang,  Kailai Yang,  Sophia Ananiadou,  Erik Cambria",
                "发布日期": "2023-12-19",
                "摘要": "  Large Language Models (LLMs) have become valuable assets in mental health,\nshowing promise in both classification tasks and counseling applications. This\npaper offers a perspective on using LLMs in mental health applications. It\ndiscusses the instability of generative models for prediction and the potential\nfor generating hallucinatory outputs, underscoring the need for ongoing audits\nand evaluations to maintain their reliability and dependability. The paper also\ndistinguishes between the often interchangeable terms ``explainability'' and\n``interpretability'', advocating for developing inherently interpretable\nmethods instead of relying on potentially hallucinated self-explanations\ngenerated by LLMs. Despite the advancements in LLMs, human counselors'\nempathetic understanding, nuanced interpretation, and contextual awareness\nremain irreplaceable in the sensitive and complex realm of mental health\ncounseling. The use of LLMs should be approached with a judicious and\nconsiderate mindset, viewing them as tools that complement human expertise\nrather than seeking to replace it.\n",
                "链接": "https://arxiv.org/abs/2311.11267"
            },
            {
                "文章ID": "61474",
                "标题": "Guiding Pretraining in Reinforcement Learning with Large Language Models",
                "作者": " Yuqing Du,  Olivia Watkins,  Zihan Wang,  Cédric Colas,  Trevor Darrell,  Pieter Abbeel,  Abhishek Gupta,  Jacob Andreas",
                "发布日期": "2023-09-18",
                "摘要": "  Reinforcement learning algorithms typically struggle in the absence of a\ndense, well-shaped reward function. Intrinsically motivated exploration methods\naddress this limitation by rewarding agents for visiting novel states or\ntransitions, but these methods offer limited benefits in large environments\nwhere most discovered novelty is irrelevant for downstream tasks. We describe a\nmethod that uses background knowledge from text corpora to shape exploration.\nThis method, called ELLM (Exploring with LLMs) rewards an agent for achieving\ngoals suggested by a language model prompted with a description of the agent's\ncurrent state. By leveraging large-scale language model pretraining, ELLM\nguides agents toward human-meaningful and plausibly useful behaviors without\nrequiring a human in the loop. We evaluate ELLM in the Crafter game environment\nand the Housekeep robotic simulator, showing that ELLM-trained agents have\nbetter coverage of common-sense behaviors during pretraining and usually match\nor improve performance on a range of downstream tasks. Code available at\nhttps://github.com/yuqingd/ellm.\n",
                "链接": "https://arxiv.org/abs/2302.06692"
            },
            {
                "文章ID": "91937",
                "标题": "Challenges and Applications of Large Language Models",
                "作者": " Jean Kaddour,  Joshua Harris,  Maximilian Mozes,  Herbie Bradley,  Roberta Raileanu,  Robert McHardy",
                "发布日期": "2023-07-20",
                "摘要": "  Large Language Models (LLMs) went from non-existent to ubiquitous in the\nmachine learning discourse within a few years. Due to the fast pace of the\nfield, it is difficult to identify the remaining challenges and already\nfruitful application areas. In this paper, we aim to establish a systematic set\nof open problems and application successes so that ML researchers can\ncomprehend the field's current state more quickly and become productive.\n",
                "链接": "https://arxiv.org/abs/2307.10169"
            },
            {
                "文章ID": "93700",
                "标题": "Okapi: Instruction-tuned Large Language Models in Multiple Languages\n  with Reinforcement Learning from Human Feedback",
                "作者": " Viet Dac Lai,  Chien Van Nguyen,  Nghia Trung Ngo,  Thuat Nguyen,  Franck Dernoncourt,  Ryan A. Rossi,  Thien Huu Nguyen",
                "发布日期": "2023-08-03",
                "摘要": "  A key technology for the development of large language models (LLMs) involves\ninstruction tuning that helps align the models' responses with human\nexpectations to realize impressive learning abilities. Two major approaches for\ninstruction tuning characterize supervised fine-tuning (SFT) and reinforcement\nlearning from human feedback (RLHF), which are currently applied to produce the\nbest commercial LLMs (e.g., ChatGPT). To improve the accessibility of LLMs for\nresearch and development efforts, various instruction-tuned open-source LLMs\nhave also been introduced recently, e.g., Alpaca, Vicuna, to name a few.\nHowever, existing open-source LLMs have only been instruction-tuned for English\nand a few popular languages, thus hindering their impacts and accessibility to\nmany other languages in the world. Among a few very recent work to explore\ninstruction tuning for LLMs in multiple languages, SFT has been used as the\nonly approach to instruction-tune LLMs for multiple languages. This has left a\nsignificant gap for fine-tuned LLMs based on RLHF in diverse languages and\nraised important questions on how RLHF can boost the performance of\nmultilingual instruction tuning. To overcome this issue, we present Okapi, the\nfirst system with instruction-tuned LLMs based on RLHF for multiple languages.\nOkapi introduces instruction and response-ranked data in 26 diverse languages\nto facilitate the experiments and development of future multilingual LLM\nresearch. We also present benchmark datasets to enable the evaluation of\ngenerative LLMs in multiple languages. Our experiments demonstrate the\nadvantages of RLHF for multilingual instruction over SFT for different base\nmodels and datasets. Our framework and resources are released at\nhttps://github.com/nlp-uoregon/Okapi.\n",
                "链接": "https://arxiv.org/abs/2307.16039"
            },
            {
                "文章ID": "60210",
                "标题": "Grounding Large Language Models in Interactive Environments with Online\n  Reinforcement Learning",
                "作者": " Thomas Carta,  Clément Romac,  Thomas Wolf,  Sylvain Lamprier,  Olivier Sigaud,  Pierre-Yves Oudeyer",
                "发布日期": "2023-09-07",
                "摘要": "  Recent works successfully leveraged Large Language Models' (LLM) abilities to\ncapture abstract knowledge about world's physics to solve decision-making\nproblems. Yet, the alignment between LLMs' knowledge and the environment can be\nwrong and limit functional competence due to lack of grounding. In this paper,\nwe study an approach (named GLAM) to achieve this alignment through functional\ngrounding: we consider an agent using an LLM as a policy that is progressively\nupdated as the agent interacts with the environment, leveraging online\nReinforcement Learning to improve its performance to solve goals. Using an\ninteractive textual environment designed to study higher-level forms of\nfunctional grounding, and a set of spatial and navigation tasks, we study\nseveral scientific questions: 1) Can LLMs boost sample efficiency for online\nlearning of various RL tasks? 2) How can it boost different forms of\ngeneralization? 3) What is the impact of online learning? We study these\nquestions by functionally grounding several variants (size, architecture) of\nFLAN-T5.\n",
                "链接": "https://arxiv.org/abs/2302.02662"
            },
            {
                "文章ID": "117384",
                "标题": "Enhancing Logical Reasoning in Large Language Models to Facilitate Legal\n  Applications",
                "作者": " Ha-Thanh Nguyen,  Wachara Fungwacharakorn,  Ken Satoh",
                "发布日期": "2023-11-23",
                "摘要": "  Language serves as a vehicle for conveying thought, enabling communication\namong individuals. The ability to distinguish between diverse concepts,\nidentify fairness and injustice, and comprehend a range of legal notions\nfundamentally relies on logical reasoning. Large Language Models (LLMs) attempt\nto emulate human language understanding and generation, but their competency in\nlogical reasoning remains limited. This paper seeks to address the\nphilosophical question: How can we effectively teach logical reasoning to LLMs\nwhile maintaining a deep understanding of the intricate relationship between\nlanguage and logic? By focusing on bolstering LLMs' capabilities in logical\nreasoning, we aim to expand their applicability in law and other\nlogic-intensive disciplines. To this end, we propose a Reinforcement Learning\nfrom Logical Feedback (RLLF) approach, which serves as a potential framework\nfor refining LLMs' reasoning capacities. Through RLLF and a revised evaluation\nmethodology, we explore new avenues for research in this domain and contribute\nto the development of LLMs capable of handling complex legal reasoning tasks\nwhile acknowledging the fundamental connection between language and logic.\n",
                "链接": "https://arxiv.org/abs/2311.13095"
            },
            {
                "文章ID": "85592",
                "标题": "Large Language Models Are Semi-Parametric Reinforcement Learning Agents",
                "作者": " Danyang Zhang,  Lu Chen,  Situo Zhang,  Hongshen Xu,  Zihan Zhao,  Kai Yu",
                "发布日期": "2023-10-31",
                "摘要": "  Inspired by the insights in cognitive science with respect to human memory\nand reasoning mechanism, a novel evolvable LLM-based (Large Language Model)\nagent framework is proposed as REMEMBERER. By equipping the LLM with a\nlong-term experience memory, REMEMBERER is capable of exploiting the\nexperiences from the past episodes even for different task goals, which excels\nan LLM-based agent with fixed exemplars or equipped with a transient working\nmemory. We further introduce Reinforcement Learning with Experience Memory\n(RLEM) to update the memory. Thus, the whole system can learn from the\nexperiences of both success and failure, and evolve its capability without\nfine-tuning the parameters of the LLM. In this way, the proposed REMEMBERER\nconstitutes a semi-parametric RL agent. Extensive experiments are conducted on\ntwo RL task sets to evaluate the proposed framework. The average results with\ndifferent initialization and training sets exceed the prior SOTA by 4% and 2%\nfor the success rate on two task sets and demonstrate the superiority and\nrobustness of REMEMBERER.\n",
                "链接": "https://arxiv.org/abs/2306.07929"
            },
            {
                "文章ID": "110634",
                "标题": "AlpaCare:Instruction-tuned Large Language Models for Medical Application",
                "作者": " Xinlu Zhang,  Chenxin Tian,  Xianjun Yang,  Lichang Chen,  Zekun Li,  Linda Ruth Petzold",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) have demonstrated significant enhancements in\ninstruction-following abilities through instruction tuning, achieving notable\nperformances across various tasks. Previous research has focused on fine-tuning\nmedical domain-specific LLMs using an extensive array of medical-specific data,\nincorporating millions of pieces of biomedical literature to augment their\nmedical capabilities. However, existing medical instruction-tuned LLMs have\nbeen constrained by the limited scope of tasks and instructions available,\nrestricting the efficacy of instruction tuning and adversely affecting\nperformance in the general domain. In this paper, we fine-tune LLaMA-series\nmodels using 52k diverse, machine-generated, medical instruction-following\ndata, MedInstruct-52k, resulting in the model AlpaCare. Comprehensive\nexperimental results on both general and medical-specific domain free-form\ninstruction evaluations showcase AlpaCare's strong medical proficiency and\ngeneralizability compared to previous instruction-tuned models in both medical\nand general domains. We provide public access to our MedInstruct-52k dataset\nand a clinician-crafted free-form instruction test set, MedInstruct-test, along\nwith our codebase, to foster further research and development. Our project page\nis available at https://github.com/XZhang97666/AlpaCare.\n",
                "链接": "https://arxiv.org/abs/2310.14558"
            },
            {
                "文章ID": "114654",
                "标题": "A Survey of Large Language Models in Medicine: Principles, Applications,\n  and Challenges",
                "作者": " Hongjian Zhou,  Fenglin Liu,  Boyang Gu,  Xinyu Zou,  Jinfa Huang,  Jinge Wu,  Yiru Li,  Sam S. Chen,  Peilin Zhou,  Junling Liu,  Yining Hua,  Chengfeng Mao,  Xian Wu,  Yefeng Zheng,  Lei Clifton,  Zheng Li,  Jiebo Luo,  David A. Clifton",
                "发布日期": "2023-12-12",
                "摘要": "  Large language models (LLMs), such as ChatGPT, have received substantial\nattention due to their impressive human language understanding and generation\ncapabilities. Therefore, the application of LLMs in medicine to assist\nphysicians and patient care emerges as a promising research direction in both\nartificial intelligence and clinical medicine. To reflect this trend, this\nsurvey provides a comprehensive overview of the principles, applications, and\nchallenges faced by LLMs in medicine. Specifically, we aim to address the\nfollowing questions: 1) How can medical LLMs be built? 2) What are the\ndownstream performances of medical LLMs? 3) How can medical LLMs be utilized in\nreal-world clinical practice? 4) What challenges arise from the use of medical\nLLMs? and 5) How can we better construct and utilize medical LLMs? As a result,\nthis survey aims to provide insights into the opportunities and challenges of\nLLMs in medicine and serve as a valuable resource for constructing practical\nand effective medical LLMs. A regularly updated list of practical guides on\nmedical LLMs can be found at\nhttps://github.com/AI-in-Health/MedLLMsPracticalGuide.\n",
                "链接": "https://arxiv.org/abs/2311.05112"
            },
            {
                "文章ID": "117311",
                "标题": "Overview of Current Applications of Large Language Models in Various\n  Medical Specialities",
                "作者": " Ummara Mumtaz,  Awais Ahmed,  Summaya Mumtaz",
                "发布日期": "2023-11-23",
                "摘要": "  This paper gives an overview of the latest applications of Large Language\nModels (LLMs) in the healthcare sector, highlighting their transformative role\nin enhancing medical care quality. By processing vast amounts of data from\ndiverse medical domains, LLMs have become pivotal in assisting doctors,\nhealthcare providers, and patients. We explore their utilization in various\nmedical specialties, such as cancer diagnostics, dentistry, nephrology,\ndermatology, etc. The paper includes the LLM methodologies applied in various\nmedical specialties, different data types in the medical domains and the\nrelevant input formatting for LLMs, along with practical use-cases of LLMs in\nthe healthcare domain.\n",
                "链接": "https://arxiv.org/abs/2311.12882"
            }
        ]
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "117493",
                "标题": "Transfer Attacks and Defenses for Large Language Models on Coding Tasks",
                "作者": " Chi Zhang,  Zifan Wang,  Ravi Mangal,  Matt Fredrikson,  Limin Jia,  Corina Pasareanu",
                "发布日期": "2023-11-23",
                "摘要": "  Modern large language models (LLMs), such as ChatGPT, have demonstrated\nimpressive capabilities for coding tasks including writing and reasoning about\ncode. They improve upon previous neural network models of code, such as\ncode2seq or seq2seq, that already demonstrated competitive results when\nperforming tasks such as code summarization and identifying code\nvulnerabilities. However, these previous code models were shown vulnerable to\nadversarial examples, i.e. small syntactic perturbations that do not change the\nprogram's semantics, such as the inclusion of \"dead code\" through false\nconditions or the addition of inconsequential print statements, designed to\n\"fool\" the models. LLMs can also be vulnerable to the same adversarial\nperturbations but a detailed study on this concern has been lacking so far. In\nthis paper we aim to investigate the effect of adversarial perturbations on\ncoding tasks with LLMs. In particular, we study the transferability of\nadversarial examples, generated through white-box attacks on smaller code\nmodels, to LLMs. Furthermore, to make the LLMs more robust against such\nadversaries without incurring the cost of retraining, we propose prompt-based\ndefenses that involve modifying the prompt to include additional information\nsuch as examples of adversarially perturbed code and explicit instructions for\nreversing adversarial perturbations. Our experiments show that adversarial\nexamples obtained with a smaller code model are indeed transferable, weakening\nthe LLMs' performance. The proposed defenses show promise in improving the\nmodel's resilience, paving the way to more robust defensive solutions for LLMs\nin code-related applications.\n",
                "链接": "https://arxiv.org/abs/2311.13445"
            },
            {
                "文章ID": "110744",
                "标题": "ALCUNA: Large Language Models Meet New Knowledge",
                "作者": " Xunjian Yin,  Baizhou Huang,  Xiaojun Wan",
                "发布日期": "2023-10-24",
                "摘要": "  With the rapid development of NLP, large-scale language models (LLMs) excel\nin various tasks across multiple domains now. However, existing benchmarks may\nnot adequately measure these models' capabilities, especially when faced with\nnew knowledge. In this paper, we address the lack of benchmarks to evaluate\nLLMs' ability to handle new knowledge, an important and challenging aspect in\nthe rapidly evolving world. We propose an approach called KnowGen that\ngenerates new knowledge by altering existing entity attributes and\nrelationships, resulting in artificial entities that are distinct from\nreal-world entities. With KnowGen, we introduce a benchmark named ALCUNA to\nassess LLMs' abilities in knowledge understanding, differentiation, and\nassociation. We benchmark several LLMs, reveals that their performance in face\nof new knowledge is not satisfactory, particularly in reasoning between new and\ninternal knowledge. We also explore the impact of entity similarity on the\nmodel's understanding of entity knowledge and the influence of contextual\nentities. We appeal to the need for caution when using LLMs in new scenarios or\nwith new knowledge, and hope that our benchmarks can help drive the development\nof LLMs in face of new knowledge.\n",
                "链接": "https://arxiv.org/abs/2310.14820"
            },
            {
                "文章ID": "41595",
                "标题": "Knowledge Distillation Transfer Sets and their Impact on Downstream NLU\n  Tasks",
                "作者": " Charith Peris,  Lizhen Tan,  Thomas Gueudre,  Turan Gojayev,  Pan Wei,  Gokmen Oz",
                "发布日期": "2022-10-19",
                "摘要": "  Teacher-student knowledge distillation is a popular technique for compressing\ntoday's prevailing large language models into manageable sizes that fit\nlow-latency downstream applications. Both the teacher and the choice of\ntransfer set used for distillation are crucial ingredients in creating a high\nquality student. Yet, the generic corpora used to pretrain the teacher and the\ncorpora associated with the downstream target domain are often significantly\ndifferent, which raises a natural question: should the student be distilled\nover the generic corpora, so as to learn from high-quality teacher predictions,\nor over the downstream task corpora to align with finetuning? Our study\ninvestigates this trade-off using Domain Classification (DC) and Intent\nClassification/Named Entity Recognition (ICNER) as downstream tasks. We distill\nseveral multilingual students from a larger multilingual LM with varying\nproportions of generic and task-specific datasets, and report their performance\nafter finetuning on DC and ICNER. We observe significant improvements across\ntasks and test sets when only task-specific corpora is used. We also report on\nhow the impact of adding task-specific data to the transfer set correlates with\nthe similarity between generic and task-specific data. Our results clearly\nindicate that, while distillation from a generic LM benefits downstream tasks,\nstudents learn better using target domain data even if it comes at the price of\nnoisier teacher predictions. In other words, target domain data still trumps\nteacher knowledge.\n",
                "链接": "https://arxiv.org/abs/2210.04834"
            },
            {
                "文章ID": "111790",
                "标题": "Fantastic Gains and Where to Find Them: On the Existence and Prospect of\n  General Knowledge Transfer between Any Pretrained Model",
                "作者": " Karsten Roth,  Lukas Thede,  Almut Sophia Koepke,  Oriol Vinyals,  Olivier Hénaff,  Zeynep Akata",
                "发布日期": "2023-10-27",
                "摘要": "  Training deep networks requires various design decisions regarding for\ninstance their architecture, data augmentation, or optimization. In this work,\nwe find these training variations to result in networks learning unique feature\nsets from the data. Using public model libraries comprising thousands of models\ntrained on canonical datasets like ImageNet, we observe that for arbitrary\npairings of pretrained models, one model extracts significant data context\nunavailable in the other -- independent of overall performance. Given any\narbitrary pairing of pretrained models and no external rankings (such as\nseparate test sets, e.g. due to data privacy), we investigate if it is possible\nto transfer such \"complementary\" knowledge from one model to another without\nperformance degradation -- a task made particularly difficult as additional\nknowledge can be contained in stronger, equiperformant or weaker models. Yet\nfacilitating robust transfer in scenarios agnostic to pretrained model pairings\nwould unlock auxiliary gains and knowledge fusion from any model repository\nwithout restrictions on model and problem specifics - including from weaker,\nlower-performance models. This work therefore provides an initial, in-depth\nexploration on the viability of such general-purpose knowledge transfer. Across\nlarge-scale experiments, we first reveal the shortcomings of standard knowledge\ndistillation techniques, and then propose a much more general extension through\ndata partitioning for successful transfer between nearly all pretrained models,\nwhich we show can also be done unsupervised. Finally, we assess both the\nscalability and impact of fundamental model properties on successful\nmodel-agnostic knowledge transfer.\n",
                "链接": "https://arxiv.org/abs/2310.17653"
            },
            {
                "文章ID": "77185",
                "标题": "Synergistic Interplay between Search and Large Language Models for\n  Information Retrieval",
                "作者": " Jiazhan Feng,  Chongyang Tao,  Xiubo Geng,  Tao Shen,  Can Xu,  Guodong Long,  Dongyan Zhao,  Daxin Jiang",
                "发布日期": "2023-12-13",
                "摘要": "  Information retrieval (IR) plays a crucial role in locating relevant\nresources from vast amounts of data, and its applications have evolved from\ntraditional knowledge bases to modern retrieval models (RMs). The emergence of\nlarge language models (LLMs) has further revolutionized the IR field by\nenabling users to interact with search systems in natural languages. In this\npaper, we explore the advantages and disadvantages of LLMs and RMs,\nhighlighting their respective strengths in understanding user-issued queries\nand retrieving up-to-date information. To leverage the benefits of both\nparadigms while circumventing their limitations, we propose InteR, a novel\nframework that facilitates information refinement through synergy between RMs\nand LLMs. InteR allows RMs to expand knowledge in queries using LLM-generated\nknowledge collections and enables LLMs to enhance prompt formulation using\nretrieved documents. This iterative refinement process augments the inputs of\nRMs and LLMs, leading to more accurate retrieval. Experiments on large-scale\nretrieval benchmarks involving web search and low-resource retrieval tasks\ndemonstrate that InteR achieves overall superior zero-shot retrieval\nperformance compared to state-of-the-art methods, even those using relevance\njudgment. Source code is available at https://github.com/Cyril-JZ/InteR\n",
                "链接": "https://arxiv.org/abs/2305.07402"
            },
            {
                "文章ID": "32391",
                "标题": "Homomorphisms Between Transfer, Multi-Task, and Meta-Learning Systems",
                "作者": " Tyler Cody",
                "发布日期": "2022-08-09",
                "摘要": "  Transfer learning, multi-task learning, and meta-learning are well-studied\ntopics concerned with the generalization of knowledge across learning tasks and\nare closely related to general intelligence. But, the formal, general systems\ndifferences between them are underexplored in the literature. This lack of\nsystems-level formalism leads to difficulties in coordinating related,\ninter-disciplinary engineering efforts. This manuscript formalizes transfer\nlearning, multi-task learning, and meta-learning as abstract learning systems,\nconsistent with the formal-minimalist abstract systems theory of Mesarovic and\nTakahara. Moreover, it uses the presented formalism to relate the three\nconcepts of learning in terms of composition, hierarchy, and structural\nhomomorphism. Findings are readily depicted in terms of input-output systems,\nhighlighting the ease of delineating formal, general systems differences\nbetween transfer, multi-task, and meta-learning.\n",
                "链接": "https://arxiv.org/abs/2208.03316"
            },
            {
                "文章ID": "74818",
                "标题": "Search-in-the-Chain: Towards Accurate, Credible and Traceable Large\n  Language Models for Knowledge-intensive Tasks",
                "作者": " Shicheng Xu,  Liang Pang,  Huawei Shen,  Xueqi Cheng,  Tat-Seng Chua",
                "发布日期": "2023-09-25",
                "摘要": "  Making the contents generated by Large Language Model (LLM) such as ChatGPT,\naccurate, credible and traceable is crucial, especially in complex\nknowledge-intensive tasks that require multi-step reasoning and each of which\nneeds knowledge to solve. Introducing Information Retrieval (IR) to provide LLM\nwith external knowledge is good potential to solve this problem. However, where\nand how to introduce IR into LLM is a big challenge. Previous work has the\ndisadvantage that the wrong knowledge retrieved by IR misleads the LLM or\nbreaks the reasoning chain of LLM. In this paper, we propose a novel framework\ncalled Search-in-the-Chain (SearChain) for the interaction between LLM and IR\nto solve the challenges. First, LLM generates the global reasoning chain called\nChain-of-Query (CoQ) where each node consists of an IR-oriented query and the\nanswer to the query. Second, IR verifies the answer of each node of CoQ, it\ncorrects the answer that is not consistent with the retrieved information when\nIR gives high confidence, which improves the credibility. Third, LLM can mark\nits missing knowledge in CoQ and IR can provide this knowledge to LLM. These\nthree operations improve the accuracy of LLM for complex knowledge-intensive\ntasks in terms of reasoning ability and knowledge. Finally, SearChain generates\nthe reasoning process and marks references to supporting documents for each\nreasoning step, which improves traceability. SearChain transforms the topology\nof reasoning from chain to tree, which can modify the reasoning direction.\nExperiment shows that SearChain outperforms baselines on complex\nknowledge-intensive tasks including multi-hop question-answering, slot filling,\nfact checking, and long-form question-answering.\n",
                "链接": "https://arxiv.org/abs/2304.14732"
            },
            {
                "文章ID": "97984",
                "标题": "KnowledGPT: Enhancing Large Language Models with Retrieval and Storage\n  Access on Knowledge Bases",
                "作者": " Xintao Wang,  Qianwen Yang,  Yongting Qiu,  Jiaqing Liang,  Qianyu He,  Zhouhong Gu,  Yanghua Xiao,  Wei Wang",
                "发布日期": "2023-08-24",
                "摘要": "  Large language models (LLMs) have demonstrated impressive impact in the field\nof natural language processing, but they still struggle with several issues\nregarding, such as completeness, timeliness, faithfulness and adaptability.\nWhile recent efforts have focuses on connecting LLMs with external knowledge\nsources, the integration of knowledge bases (KBs) remains understudied and\nfaces several challenges. In this paper, we introduce KnowledGPT, a\ncomprehensive framework to bridge LLMs with various knowledge bases,\nfacilitating both the retrieval and storage of knowledge. The retrieval process\nemploys the program of thought prompting, which generates search language for\nKBs in code format with pre-defined functions for KB operations. Besides\nretrieval, KnowledGPT offers the capability to store knowledge in a\npersonalized KB, catering to individual user demands. With extensive\nexperiments, we show that by integrating LLMs with KBs, KnowledGPT properly\nanswers a broader range of questions requiring world knowledge compared with\nvanilla LLMs, utilizing both knowledge existing in widely-known KBs and\nextracted into personalized KBs.\n",
                "链接": "https://arxiv.org/abs/2308.11761"
            },
            {
                "文章ID": "66370",
                "标题": "Algorithmic Ghost in the Research Shell: Large Language Models and\n  Academic Knowledge Creation in Management Research",
                "作者": " Nigel Williams,  Stanislav Ivanov,  Dimitrios Buhalis",
                "发布日期": "2023-03-14",
                "摘要": "  The paper looks at the role of large language models in academic knowledge\ncreation based on a scoping review (2018 to January 2023) of how researchers\nhave previously used the language model GPT to assist in the performance of\nacademic knowledge creation tasks beyond data analysis. These tasks include\nwriting, editing, reviewing, dataset creation and curation, which have been\ndifficult to perform using earlier ML tools. Based on a synthesis of these\npapers, this study identifies pathways for a future academic research landscape\nthat incorporates wider usage of large language models based on the current\nmodes of adoption in published articles as a Co-Writer, Research Assistant and\nRespondent.\n",
                "链接": "https://arxiv.org/abs/2303.07304"
            },
            {
                "文章ID": "9744",
                "标题": "Leveraging Visual Knowledge in Language Tasks: An Empirical Study on\n  Intermediate Pre-training for Cross-modal Knowledge Transfer",
                "作者": " Woojeong Jin,  Dong-Ho Lee,  Chenguang Zhu,  Jay Pujara,  Xiang Ren",
                "发布日期": "2022-03-18",
                "摘要": "  Pre-trained language models are still far from human performance in tasks\nthat need understanding of properties (e.g. appearance, measurable quantity)\nand affordances of everyday objects in the real world since the text lacks such\ninformation due to reporting bias. In this work, we study whether integrating\nvisual knowledge into a language model can fill the gap. We investigate two\ntypes of knowledge transfer: (1) text knowledge transfer using image captions\nthat may contain enriched visual knowledge and (2) cross-modal knowledge\ntransfer using both images and captions with vision-language training\nobjectives. On 5 downstream tasks that may need visual knowledge to solve the\nproblem, we perform extensive empirical comparisons over the presented\nobjectives. Our experiments show that visual knowledge transfer can improve\nperformance in both low-resource and fully supervised settings.\n",
                "链接": "https://arxiv.org/abs/2203.07519"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和人文学科交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "123540",
                "标题": "User Modeling in the Era of Large Language Models: Current Research and\n  Future Directions",
                "作者": " Zhaoxuan Tan,  Meng Jiang",
                "发布日期": "2023-12-27",
                "摘要": "  User modeling (UM) aims to discover patterns or learn representations from\nuser data about the characteristics of a specific user, such as profile,\npreference, and personality. The user models enable personalization and\nsuspiciousness detection in many online applications such as recommendation,\neducation, and healthcare. Two common types of user data are text and graph, as\nthe data usually contain a large amount of user-generated content (UGC) and\nonline interactions. The research of text and graph mining is developing\nrapidly, contributing many notable solutions in the past two decades. Recently,\nlarge language models (LLMs) have shown superior performance on generating,\nunderstanding, and even reasoning over text data. The approaches of user\nmodeling have been equipped with LLMs and soon become outstanding. This article\nsummarizes existing research about how and why LLMs are great tools of modeling\nand understanding UGC. Then it reviews a few categories of large language\nmodels for user modeling (LLM-UM) approaches that integrate the LLMs with text\nand graph-based methods in different ways. Then it introduces specific LLM-UM\ntechniques for a variety of UM applications. Finally, it presents remaining\nchallenges and future directions in the LLM-UM research. We maintain the\nreading list at: https://github.com/TamSiuhin/LLM-UM-Reading\n",
                "链接": "https://arxiv.org/abs/2312.11518"
            },
            {
                "文章ID": "70693",
                "标题": "Summary of ChatGPT-Related Research and Perspective Towards the Future\n  of Large Language Models",
                "作者": " Yiheng Liu,  Tianle Han,  Siyuan Ma,  Jiayue Zhang,  Yuanyuan Yang,  Jiaming Tian,  Hao He,  Antong Li,  Mengshen He,  Zhengliang Liu,  Zihao Wu,  Lin Zhao,  Dajiang Zhu,  Xiang Li,  Ning Qiang,  Dingang Shen,  Tianming Liu,  Bao Ge",
                "发布日期": "2023-08-25",
                "摘要": "  This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and\nGPT-4) research, state-of-the-art large language models (LLM) from the GPT\nseries, and their prospective applications across diverse domains. Indeed, key\ninnovations such as large-scale pre-training that captures knowledge across the\nentire world wide web, instruction fine-tuning and Reinforcement Learning from\nHuman Feedback (RLHF) have played significant roles in enhancing LLMs'\nadaptability and performance. We performed an in-depth analysis of 194 relevant\npapers on arXiv, encompassing trend analysis, word cloud representation, and\ndistribution analysis across various application domains. The findings reveal a\nsignificant and increasing interest in ChatGPT-related research, predominantly\ncentered on direct natural language processing applications, while also\ndemonstrating considerable potential in areas ranging from education and\nhistory to mathematics, medicine, and physics. This study endeavors to furnish\ninsights into ChatGPT's capabilities, potential implications, ethical concerns,\nand offer direction for future advancements in this field.\n",
                "链接": "https://arxiv.org/abs/2304.01852"
            },
            {
                "文章ID": "113893",
                "标题": "On the Intersection of Self-Correction and Trust in Language Models",
                "作者": " Satyapriya Krishna",
                "发布日期": "2023-11-07",
                "摘要": "  Large Language Models (LLMs) have demonstrated remarkable capabilities in\nperforming complex cognitive tasks. However, their complexity and lack of\ntransparency have raised several trustworthiness concerns, including the\npropagation of misinformation and toxicity. Recent research has explored the\nself-correction capabilities of LLMs to enhance their performance. In this\nwork, we investigate whether these self-correction capabilities can be\nharnessed to improve the trustworthiness of LLMs. We conduct experiments\nfocusing on two key aspects of trustworthiness: truthfulness and toxicity. Our\nfindings reveal that self-correction can lead to improvements in toxicity and\ntruthfulness, but the extent of these improvements varies depending on the\nspecific aspect of trustworthiness and the nature of the task. Interestingly,\nour study also uncovers instances of \"self-doubt\" in LLMs during the\nself-correction process, introducing a new set of challenges that need to be\naddressed.\n",
                "链接": "https://arxiv.org/abs/2311.02801"
            },
            {
                "文章ID": "35258",
                "标题": "Labeling of Cultural Heritage Collections on the Intersection of Visual\n  Analytics and Digital Humanities",
                "作者": " Christofer Meinecke",
                "发布日期": "2022-08-30",
                "摘要": "  Engaging in interdisciplinary projects on the intersection between\nvisualization and humanities research can be a challenging endeavor. Challenges\ncan be finding valuable outcomes for both domains, or how to apply\nstate-of-the-art visual analytics methods like supervised machine learning\nalgorithms. We discuss these challenges when working with cultural heritage\ndata. Further, there is a gap in applying these methods to intangible heritage.\nTo give a reflection on some interdisciplinary projects, we present three case\nstudies focusing on the labeling of cultural heritage collections, the problems\nand challenges with the data, the participatory design process, and takeaways\nfor the visualization scholars from these collaborations.\n",
                "链接": "https://arxiv.org/abs/2208.13512"
            },
            {
                "文章ID": "70754",
                "标题": "A Bibliometric Review of Large Language Models Research from 2017 to\n  2023",
                "作者": " Lizhou Fan,  Lingyao Li,  Zihui Ma,  Sanggyu Lee,  Huizi Yu,  Libby Hemphill",
                "发布日期": "2023-04-06",
                "摘要": "  Large language models (LLMs) are a class of language models that have\ndemonstrated outstanding performance across a range of natural language\nprocessing (NLP) tasks and have become a highly sought-after research area,\nbecause of their ability to generate human-like language and their potential to\nrevolutionize science and technology. In this study, we conduct bibliometric\nand discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000\npublications, this paper serves as a roadmap for researchers, practitioners,\nand policymakers to navigate the current landscape of LLMs research. We present\nthe research trends from 2017 to early 2023, identifying patterns in research\nparadigms and collaborations. We start with analyzing the core algorithm\ndevelopments and NLP tasks that are fundamental in LLMs research. We then\ninvestigate the applications of LLMs in various fields and domains including\nmedicine, engineering, social science, and humanities. Our review also reveals\nthe dynamic, fast-paced evolution of LLMs research. Overall, this paper offers\nvaluable insights into the current state, impact, and potential of LLMs\nresearch and its applications.\n",
                "链接": "https://arxiv.org/abs/2304.02020"
            },
            {
                "文章ID": "66370",
                "标题": "Algorithmic Ghost in the Research Shell: Large Language Models and\n  Academic Knowledge Creation in Management Research",
                "作者": " Nigel Williams,  Stanislav Ivanov,  Dimitrios Buhalis",
                "发布日期": "2023-03-14",
                "摘要": "  The paper looks at the role of large language models in academic knowledge\ncreation based on a scoping review (2018 to January 2023) of how researchers\nhave previously used the language model GPT to assist in the performance of\nacademic knowledge creation tasks beyond data analysis. These tasks include\nwriting, editing, reviewing, dataset creation and curation, which have been\ndifficult to perform using earlier ML tools. Based on a synthesis of these\npapers, this study identifies pathways for a future academic research landscape\nthat incorporates wider usage of large language models based on the current\nmodes of adoption in published articles as a Co-Writer, Research Assistant and\nRespondent.\n",
                "链接": "https://arxiv.org/abs/2303.07304"
            },
            {
                "文章ID": "11875",
                "标题": "mdx: A Cloud Platform for Supporting Data Science and Cross-Disciplinary\n  Research Collaborations",
                "作者": " Toyotaro Suzumura,  Akiyoshi Sugiki,  Hiroyuki Takizawa,  Akira Imakura,  Hiroshi Nakamura,  Kenjiro Taura,  Tomohiro Kudoh,  Toshihiro Hanawa,  Yuji Sekiya,  Hiroki Kobayashi,  Shin Matsushima,  Yohei Kuga,  Ryo Nakamura,  Renhe Jiang,  Junya Kawase,  Masatoshi Hanai,  Hiroshi Miyazaki,  Tsutomu Ishizaki,  Daisuke Shimotoku,  Daisuke Miyamoto,  Kento Aida,  Atsuko Takefusa,  Takashi Kurimoto,  Koji Sasayama,  Naoya Kitagawa,  Ikki Fujiwara,  Yusuke Tanimura,  Takayuki Aoki,  Toshio Endo,  Satoshi Ohshima,  Keiichiro Fukazawa,  Susumu Date,  Toshihiro Uchibayashi",
                "发布日期": "2022-03-29",
                "摘要": "  The growing amount of data and advances in data science have created a need\nfor a new kind of cloud platform that provides users with flexibility, strong\nsecurity, and the ability to couple with supercomputers and edge devices\nthrough high-performance networks. We have built such a nation-wide cloud\nplatform, called \"mdx\" to meet this need. The mdx platform's virtualization\nservice, jointly operated by 9 national universities and 2 national research\ninstitutes in Japan, launched in 2021, and more features are in development.\nCurrently mdx is used by researchers in a wide variety of domains, including\nmaterials informatics, geo-spatial information science, life science,\nastronomical science, economics, social science, and computer science. This\npaper provides an the overview of the mdx platform, details the motivation for\nits development, reports its current status, and outlines its future plans.\n",
                "链接": "https://arxiv.org/abs/2203.14188"
            },
            {
                "文章ID": "109408",
                "标题": "The Quo Vadis of the Relationship between Language and Large Language\n  Models",
                "作者": " Evelina Leivada,  Vittoria Dentella,  Elliot Murphy",
                "发布日期": "2023-10-18",
                "摘要": "  In the field of Artificial (General) Intelligence (AI), the several recent\nadvancements in Natural language processing (NLP) activities relying on Large\nLanguage Models (LLMs) have come to encourage the adoption of LLMs as\nscientific models of language. While the terminology employed for the\ncharacterization of LLMs favors their embracing as such, it is not clear that\nthey are in a place to offer insights into the target system they seek to\nrepresent. After identifying the most important theoretical and empirical risks\nbrought about by the adoption of scientific models that lack transparency, we\ndiscuss LLMs relating them to every scientific model's fundamental components:\nthe object, the medium, the meaning and the user. We conclude that, at their\ncurrent stage of development, LLMs hardly offer any explanations for language,\nand then we provide an outlook for more informative future research directions\non this topic.\n",
                "链接": "https://arxiv.org/abs/2310.11146"
            },
            {
                "文章ID": "122703",
                "标题": "Perspectives on the State and Future of Deep Learning - 2023",
                "作者": " Micah Goldblum,  Anima Anandkumar,  Richard Baraniuk,  Tom Goldstein,  Kyunghyun Cho,  Zachary C Lipton,  Melanie Mitchell,  Preetum Nakkiran,  Max Welling,  Andrew Gordon Wilson",
                "发布日期": "2023-12-20",
                "摘要": "  The goal of this series is to chronicle opinions and issues in the field of\nmachine learning as they stand today and as they change over time. The plan is\nto host this survey periodically until the AI singularity\npaperclip-frenzy-driven doomsday, keeping an updated list of topical questions\nand interviewing new community members for each edition. In this issue, we\nprobed people's opinions on interpretable AI, the value of benchmarking in\nmodern NLP, the state of progress towards understanding deep learning, and the\nfuture of academia.\n",
                "链接": "https://arxiv.org/abs/2312.09323"
            },
            {
                "文章ID": "51962",
                "标题": "Event knowledge in large language models: the gap between the impossible\n  and the unlikely",
                "作者": " Carina Kauf,  Anna A. Ivanova,  Giulia Rambelli,  Emmanuele Chersoni,  Jingyuan Selena She,  Zawad Chowdhury,  Evelina Fedorenko,  Alessandro Lenci",
                "发布日期": "2023-10-27",
                "摘要": "  Word co-occurrence patterns in language corpora contain a surprising amount\nof conceptual knowledge. Large language models (LLMs), trained to predict words\nin context, leverage these patterns to achieve impressive performance on\ndiverse semantic tasks requiring world knowledge. An important but understudied\nquestion about LLMs' semantic abilities is whether they acquire generalized\nknowledge of common events. Here, we test whether five pre-trained LLMs (from\n2018's BERT to 2023's MPT) assign higher likelihood to plausible descriptions\nof agent-patient interactions than to minimally different implausible versions\nof the same event. Using three curated sets of minimal sentence pairs (total\nn=1,215), we found that pre-trained LLMs possess substantial event knowledge,\noutperforming other distributional language models. In particular, they almost\nalways assign higher likelihood to possible vs. impossible events (The teacher\nbought the laptop vs. The laptop bought the teacher). However, LLMs show less\nconsistent preferences for likely vs. unlikely events (The nanny tutored the\nboy vs. The boy tutored the nanny). In follow-up analyses, we show that (i) LLM\nscores are driven by both plausibility and surface-level sentence features,\n(ii) LLM scores generalize well across syntactic variants (active vs. passive\nconstructions) but less well across semantic variants (synonymous sentences),\n(iii) some LLM errors mirror human judgment ambiguity, and (iv) sentence\nplausibility serves as an organizing dimension in internal LLM representations.\nOverall, our results show that important aspects of event knowledge naturally\nemerge from distributional linguistic patterns, but also highlight a gap\nbetween representations of possible/impossible and likely/unlikely events.\n",
                "链接": "https://arxiv.org/abs/2212.01488"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和脑科学交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "70754",
                "标题": "A Bibliometric Review of Large Language Models Research from 2017 to\n  2023",
                "作者": " Lizhou Fan,  Lingyao Li,  Zihui Ma,  Sanggyu Lee,  Huizi Yu,  Libby Hemphill",
                "发布日期": "2023-04-06",
                "摘要": "  Large language models (LLMs) are a class of language models that have\ndemonstrated outstanding performance across a range of natural language\nprocessing (NLP) tasks and have become a highly sought-after research area,\nbecause of their ability to generate human-like language and their potential to\nrevolutionize science and technology. In this study, we conduct bibliometric\nand discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000\npublications, this paper serves as a roadmap for researchers, practitioners,\nand policymakers to navigate the current landscape of LLMs research. We present\nthe research trends from 2017 to early 2023, identifying patterns in research\nparadigms and collaborations. We start with analyzing the core algorithm\ndevelopments and NLP tasks that are fundamental in LLMs research. We then\ninvestigate the applications of LLMs in various fields and domains including\nmedicine, engineering, social science, and humanities. Our review also reveals\nthe dynamic, fast-paced evolution of LLMs research. Overall, this paper offers\nvaluable insights into the current state, impact, and potential of LLMs\nresearch and its applications.\n",
                "链接": "https://arxiv.org/abs/2304.02020"
            },
            {
                "文章ID": "114592",
                "标题": "An Interdisciplinary Outlook on Large Language Models for Scientific\n  Research",
                "作者": " James Boyko,  Joseph Cohen,  Nathan Fox,  Maria Han Veiga,  Jennifer I-Hsiu Li,  Jing Liu,  Bernardo Modenesi,  Andreas H. Rauch,  Kenneth N. Reid,  Soumi Tribedi,  Anastasia Visheratina,  Xin Xie",
                "发布日期": "2023-11-10",
                "摘要": "  In this paper, we describe the capabilities and constraints of Large Language\nModels (LLMs) within disparate academic disciplines, aiming to delineate their\nstrengths and limitations with precision. We examine how LLMs augment\nscientific inquiry, offering concrete examples such as accelerating literature\nreview by summarizing vast numbers of publications, enhancing code development\nthrough automated syntax correction, and refining the scientific writing\nprocess. Simultaneously, we articulate the challenges LLMs face, including\ntheir reliance on extensive and sometimes biased datasets, and the potential\nethical dilemmas stemming from their use. Our critical discussion extends to\nthe varying impacts of LLMs across fields, from the natural sciences, where\nthey help model complex biological sequences, to the social sciences, where\nthey can parse large-scale qualitative data. We conclude by offering a nuanced\nperspective on how LLMs can be both a boon and a boundary to scientific\nprogress.\n",
                "链接": "https://arxiv.org/abs/2311.04929"
            },
            {
                "文章ID": "112056",
                "标题": "Large-scale Foundation Models and Generative AI for BigData Neuroscience",
                "作者": " Ran Wang,  Zhe Sage Chen",
                "发布日期": "2023-10-31",
                "摘要": "  Recent advances in machine learning have made revolutionary breakthroughs in\ncomputer games, image and natural language understanding, and scientific\ndiscovery. Foundation models and large-scale language models (LLMs) have\nrecently achieved human-like intelligence thanks to BigData. With the help of\nself-supervised learning (SSL) and transfer learning, these models may\npotentially reshape the landscapes of neuroscience research and make a\nsignificant impact on the future. Here we present a mini-review on recent\nadvances in foundation models and generative AI models as well as their\napplications in neuroscience, including natural language and speech, semantic\nmemory, brain-machine interfaces (BMIs), and data augmentation. We argue that\nthis paradigm-shift framework will open new avenues for many neuroscience\nresearch directions and discuss the accompanying challenges and opportunities.\n",
                "链接": "https://arxiv.org/abs/2310.18377"
            },
            {
                "文章ID": "113893",
                "标题": "On the Intersection of Self-Correction and Trust in Language Models",
                "作者": " Satyapriya Krishna",
                "发布日期": "2023-11-07",
                "摘要": "  Large Language Models (LLMs) have demonstrated remarkable capabilities in\nperforming complex cognitive tasks. However, their complexity and lack of\ntransparency have raised several trustworthiness concerns, including the\npropagation of misinformation and toxicity. Recent research has explored the\nself-correction capabilities of LLMs to enhance their performance. In this\nwork, we investigate whether these self-correction capabilities can be\nharnessed to improve the trustworthiness of LLMs. We conduct experiments\nfocusing on two key aspects of trustworthiness: truthfulness and toxicity. Our\nfindings reveal that self-correction can lead to improvements in toxicity and\ntruthfulness, but the extent of these improvements varies depending on the\nspecific aspect of trustworthiness and the nature of the task. Interestingly,\nour study also uncovers instances of \"self-doubt\" in LLMs during the\nself-correction process, introducing a new set of challenges that need to be\naddressed.\n",
                "链接": "https://arxiv.org/abs/2311.02801"
            },
            {
                "文章ID": "105384",
                "标题": "In-Context Learning in Large Language Models: A Neuroscience-inspired\n  Analysis of Representations",
                "作者": " Safoora Yousefi,  Leo Betthauser,  Hosein Hasanbeig,  Akanksha Saran,  Raphaël Millière,  Ida Momennejad",
                "发布日期": "2023-10-19",
                "摘要": "  Large language models (LLMs) exhibit remarkable performance improvement\nthrough in-context learning (ICL) by leveraging task-specific examples in the\ninput. However, the mechanisms behind this improvement remain elusive. In this\nwork, we investigate embeddings and attention representations in Llama-2 70B\nand Vicuna 13B. Specifically, we study how embeddings and attention change\nafter in-context-learning, and how these changes mediate improvement in\nbehavior. We employ neuroscience-inspired techniques, such as representational\nsimilarity analysis (RSA), and propose novel methods for parameterized probing\nand attention ratio analysis (ARA, measuring the ratio of attention to relevant\nvs. irrelevant information). We designed three tasks with a priori\nrelationships among their conditions: reading comprehension, linear regression,\nand adversarial prompt injection. We formed hypotheses about expected\nsimilarities in task representations to investigate latent changes in\nembeddings and attention. Our analyses revealed a meaningful correlation\nbetween changes in both embeddings and attention representations with\nimprovements in behavioral performance after ICL. This empirical framework\nempowers a nuanced understanding of how latent representations affect LLM\nbehavior with and without ICL, offering valuable tools and insights for future\nresearch and practical applications.\n",
                "链接": "https://arxiv.org/abs/2310.00313"
            },
            {
                "文章ID": "87950",
                "标题": "Large Multimodal Models: Notes on CVPR 2023 Tutorial",
                "作者": " Chunyuan Li",
                "发布日期": "2023-06-27",
                "摘要": "  This tutorial note summarizes the presentation on ``Large Multimodal Models:\nTowards Building and Surpassing Multimodal GPT-4'', a part of CVPR 2023\ntutorial on ``Recent Advances in Vision Foundation Models''. The tutorial\nconsists of three parts. We first introduce the background on recent GPT-like\nlarge models for vision-and-language modeling to motivate the research in\ninstruction-tuned large multimodal models (LMMs). As a pre-requisite, we\ndescribe the basics of instruction-tuning in large language models, which is\nfurther extended to the multimodal space. Lastly, we illustrate how to build\nthe minimum prototype of multimodal GPT-4 like models with the open-source\nresource, and review the recently emerged topics.\n",
                "链接": "https://arxiv.org/abs/2306.14895"
            },
            {
                "文章ID": "80006",
                "标题": "Having Beer after Prayer? Measuring Cultural Bias in Large Language\n  Models",
                "作者": " Tarek Naous,  Michael J. Ryan,  Alan Ritter,  Wei Xu",
                "发布日期": "2023-11-17",
                "摘要": "  It is important that language models appropriately adapt to specific cultural\ncontexts. However, as we show in this paper, multilingual and Arabic\nmonolingual language models default to Western culture even when prompted in\nArabic and contextualized by an Arab cultural setting. To measure this Western\nbias, we introduce CAMeL, a dataset of naturally occurring Arabic prompts\nspanning eight diverse cultural aspects and an extensive list of 20,504\ncultural targets corresponding to Arab or Western culture. Using CAMeL, we show\nthat models favor Western targets and demonstrate cultural unfairness on\ndownstream tasks such as named entity recognition and sentiment analysis. Our\nanalyses of pretraining corpora also reveal that commonly used sources such as\nWikipedia may not be suited to build culturally aware models, underscoring the\nimportance of carefully curating pretraining data in constructing language\nmodels to serve a global population.\n",
                "链接": "https://arxiv.org/abs/2305.14456"
            },
            {
                "文章ID": "96394",
                "标题": "Exploring the Intersection of Large Language Models and Agent-Based\n  Modeling via Prompt Engineering",
                "作者": " Edward Junprung",
                "发布日期": "2023-08-16",
                "摘要": "  The final frontier for simulation is the accurate representation of complex,\nreal-world social systems. While agent-based modeling (ABM) seeks to study the\nbehavior and interactions of agents within a larger system, it is unable to\nfaithfully capture the full complexity of human-driven behavior. Large language\nmodels (LLMs), like ChatGPT, have emerged as a potential solution to this\nbottleneck by enabling researchers to explore human-driven interactions in\npreviously unimaginable ways. Our research investigates simulations of human\ninteractions using LLMs. Through prompt engineering, inspired by Park et al.\n(2023), we present two simulations of believable proxies of human behavior: a\ntwo-agent negotiation and a six-agent murder mystery game.\n",
                "链接": "https://arxiv.org/abs/2308.07411"
            },
            {
                "文章ID": "106494",
                "标题": "Benchmarking Large Language Models As AI Research Agents",
                "作者": " Qian Huang,  Jian Vora,  Percy Liang,  Jure Leskovec",
                "发布日期": "2023-10-06",
                "摘要": "  Scientific experimentation involves an iterative process of creating\nhypotheses, designing experiments, running experiments, and analyzing the\nresults. Can we build AI research agents to perform these long-horizon tasks?\nTo take a step towards building and evaluating research agents on such\nopen-ended decision-making tasks, we focus on the problem of machine learning\nengineering: given a task description and a dataset, build a high-performing\nmodel. In this paper, we propose MLAgentBench, a suite of ML tasks for\nbenchmarking AI research agents. Agents can perform actions like\nreading/writing files, executing code, and inspecting outputs. With these\nactions, agents could run experiments, analyze the results, and modify the code\nof entire machine learning pipelines, such as data processing, architecture,\ntraining processes, etc. The benchmark then automatically evaluates the agent's\nperformance objectively over various metrics related to performance and\nefficiency. We also design an LLM-based research agent to automatically perform\nexperimentation loops in such an environment. Empirically, we find that a\nGPT-4-based research agent can feasibly build compelling ML models over many\ntasks in MLAgentBench, displaying highly interpretable plans and actions.\nHowever, the success rates vary considerably; they span from almost 90\\% on\nwell-established older datasets to as low as 10\\% on recent Kaggle Challenges\n-- unavailable during the LLM model's pretraining -- and even 0\\% on newer\nresearch challenges like BabyLM. Finally, we identify several key challenges\nfor LLM-based research agents such as long-term planning and hallucination. Our\ncode is released at https://github.com/snap-stanford/MLAgentBench.\n",
                "链接": "https://arxiv.org/abs/2310.03302"
            },
            {
                "文章ID": "112605",
                "标题": "The Eval4NLP 2023 Shared Task on Prompting Large Language Models as\n  Explainable Metrics",
                "作者": " Christoph Leiter,  Juri Opitz,  Daniel Deutsch,  Yang Gao,  Rotem Dror,  Steffen Eger",
                "发布日期": "2023-10-31",
                "摘要": "  With an increasing number of parameters and pre-training data, generative\nlarge language models (LLMs) have shown remarkable capabilities to solve tasks\nwith minimal or no task-related examples. Notably, LLMs have been successfully\nemployed as evaluation metrics in text generation tasks. Within this context,\nwe introduce the Eval4NLP 2023 shared task that asks participants to explore\nprompting and score extraction for machine translation (MT) and summarization\nevaluation. Specifically, we propose a novel competition setting in which we\nselect a list of allowed LLMs and disallow fine-tuning to ensure a focus on\nprompting. We present an overview of participants' approaches and evaluate them\non a new reference-free test set spanning three language pairs for MT and a\nsummarization dataset. Notably, despite the task's restrictions, the\nbest-performing systems achieve results on par with or even surpassing recent\nreference-free metrics developed using larger models, including GEMBA and\nComet-Kiwi-XXL. Finally, as a separate track, we perform a small-scale human\nevaluation of the plausibility of explanations given by the LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.19792"
            }
        ]
    },
    {
        "question": {
            "question": "2022年后与AI for Science相关的综述论文",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "47944",
                "标题": "Artificial Intelligence and Life in 2030: The One Hundred Year Study on\n  Artificial Intelligence",
                "作者": " Peter Stone,  Rodney Brooks,  Erik Brynjolfsson,  Ryan Calo,  Oren Etzioni,  Greg Hager,  Julia Hirschberg,  Shivaram Kalyanakrishnan,  Ece Kamar,  Sarit Kraus,  Kevin Leyton-Brown,  David Parkes,  William Press,  AnnaLee Saxenian,  Julie Shah,  Milind Tambe,  Astro Teller",
                "发布日期": "2022-11-14",
                "摘要": "  In September 2016, Stanford's \"One Hundred Year Study on Artificial\nIntelligence\" project (AI100) issued the first report of its planned long-term\nperiodic assessment of artificial intelligence (AI) and its impact on society.\nIt was written by a panel of 17 study authors, each of whom is deeply rooted in\nAI research, chaired by Peter Stone of the University of Texas at Austin. The\nreport, entitled \"Artificial Intelligence and Life in 2030,\" examines eight\ndomains of typical urban settings on which AI is likely to have impact over the\ncoming years: transportation, home and service robots, healthcare, education,\npublic safety and security, low-resource communities, employment and workplace,\nand entertainment. It aims to provide the general public with a scientifically\nand technologically accurate portrayal of the current state of AI and its\npotential and to help guide decisions in industry and governments, as well as\nto inform research and development in the field. The charge for this report was\ngiven to the panel by the AI100 Standing Committee, chaired by Barbara Grosz of\nHarvard University.\n",
                "链接": "https://arxiv.org/abs/2211.06318"
            },
            {
                "文章ID": "64936",
                "标题": "Artificial Intelligence: 70 Years Down the Road",
                "作者": " Lin Zhang",
                "发布日期": "2023-03-07",
                "摘要": "  Artificial intelligence (AI) has a history of nearly a century from its\ninception to the present day. We have summarized the development trends and\ndiscovered universal rules, including both success and failure. We have\nanalyzed the reasons from both technical and philosophical perspectives to help\nunderstand the reasons behind the past failures and current successes of AI,\nand to provide a basis for thinking and exploring future development.\nSpecifically, we have found that the development of AI in different fields,\nincluding computer vision, natural language processing, and machine learning,\nfollows a pattern from rules to statistics to data-driven methods. In the face\nof past failures and current successes, we need to think systematically about\nthe reasons behind them. Given the unity of AI between natural and social\nsciences, it is necessary to incorporate philosophical thinking to understand\nand solve AI problems, and we believe that starting from the dialectical method\nof Marx is a feasible path. We have concluded that the sustainable development\ndirection of AI should be human-machine collaboration and a technology path\ncentered on computing power. Finally, we have summarized the impact of AI on\nsociety from this trend.\n",
                "链接": "https://arxiv.org/abs/2303.02819"
            },
            {
                "文章ID": "91776",
                "标题": "PubMed and Beyond: Biomedical Literature Search in the Age of Artificial\n  Intelligence",
                "作者": " Qiao Jin,  Robert Leaman,  Zhiyong Lu",
                "发布日期": "2023-09-22",
                "摘要": "  Biomedical research yields a wealth of information, much of which is only\naccessible through the literature. Consequently, literature search is an\nessential tool for building on prior knowledge in clinical and biomedical\nresearch. Although recent improvements in artificial intelligence have expanded\nfunctionality beyond keyword-based search, these advances may be unfamiliar to\nclinicians and researchers. In response, we present a survey of literature\nsearch tools tailored to both general and specific information needs in\nbiomedicine, with the objective of helping readers efficiently fulfill their\ninformation needs. We first examine the widely used PubMed search engine,\ndiscussing recent improvements and continued challenges. We then describe\nliterature search tools catering to five specific information needs: 1.\nIdentifying high-quality clinical research for evidence-based medicine. 2.\nRetrieving gene-related information for precision medicine and genomics. 3.\nSearching by meaning, including natural language questions. 4. Locating related\narticles with literature recommendation. 5. Mining literature to discover\nassociations between concepts such as diseases and genetic variants.\nAdditionally, we cover practical considerations and best practices for choosing\nand using these tools. Finally, we provide a perspective on the future of\nliterature search engines, considering recent breakthroughs in large language\nmodels such as ChatGPT. In summary, our survey provides a comprehensive view of\nbiomedical literature search functionalities with 36 publicly available tools.\n",
                "链接": "https://arxiv.org/abs/2307.09683"
            },
            {
                "文章ID": "2627",
                "标题": "A Method to Predict Semantic Relations on Artificial Intelligence Papers",
                "作者": " Francisco Andrades,  Ricardo Ñanculef",
                "发布日期": "2022-01-26",
                "摘要": "  Predicting the emergence of links in large evolving networks is a difficult\ntask with many practical applications. Recently, the Science4cast competition\nhas illustrated this challenge presenting a network of 64.000 AI concepts and\nasking the participants to predict which topics are going to be researched\ntogether in the future. In this paper, we present a solution to this problem\nbased on a new family of deep learning approaches, namely Graph Neural\nNetworks. The results of the challenge show that our solution is competitive\neven if we had to impose severe restrictions to obtain a computationally\nefficient and parsimonious model: ignoring the intrinsic dynamics of the graph\nand using only a small subset of the nodes surrounding a target link.\nPreliminary experiments presented in this paper suggest the model is learning\ntwo related, but different patterns: the absorption of a node by a sub-graph\nand union of more dense sub-graphs. The model seems to excel at recognizing the\nfirst type of pattern.\n",
                "链接": "https://arxiv.org/abs/2201.10518"
            },
            {
                "文章ID": "91365",
                "标题": "Artificial Intelligence for Science in Quantum, Atomistic, and Continuum\n  Systems",
                "作者": " Xuan Zhang,  Limei Wang,  Jacob Helwig,  Youzhi Luo,  Cong Fu,  Yaochen Xie,  Meng Liu,  Yuchao Lin,  Zhao Xu,  Keqiang Yan,  Keir Adams,  Maurice Weiler,  Xiner Li,  Tianfan Fu,  Yucheng Wang,  Haiyang Yu,  YuQing Xie,  Xiang Fu,  Alex Strasser,  Shenglong Xu,  Yi Liu,  Yuanqi Du,  Alexandra Saxton,  Hongyi Ling,  Hannah Lawrence,  Hannes Stärk,  Shurui Gui,  Carl Edwards,  Nicholas Gao,  Adriana Ladera,  Tailin Wu,  Elyssa F. Hofgard,  Aria Mansouri Tehrani,  Rui Wang,  Ameya Daigavane,  Montgomery Bohde,  Jerry Kurtin,  Qian Huang,  Tuong Phung,  Minkai Xu,  Chaitanya K. Joshi,  Simon V. Mathis,  Kamyar Azizzadenesheli,  Ada Fang,  Alán Aspuru-Guzik,  Erik Bekkers,  Michael Bronstein,  Marinka Zitnik,  Anima Anandkumar,  Stefano Ermon,  Pietro Liò,  Rose Yu,  Stephan Günnemann,  Jure Leskovec,  Heng Ji,  Jimeng Sun,  Regina Barzilay,  Tommi Jaakkola,  Connor W. Coley,  Xiaoning Qian,  Xiaofeng Qian,  Tess Smidt,  Shuiwang Ji",
                "发布日期": "2023-11-16",
                "摘要": "  Advances in artificial intelligence (AI) are fueling a new paradigm of\ndiscoveries in natural sciences. Today, AI has started to advance natural\nsciences by improving, accelerating, and enabling our understanding of natural\nphenomena at a wide range of spatial and temporal scales, giving rise to a new\narea of research known as AI for science (AI4Science). Being an emerging\nresearch paradigm, AI4Science is unique in that it is an enormous and highly\ninterdisciplinary area. Thus, a unified and technical treatment of this field\nis needed yet challenging. This work aims to provide a technically thorough\naccount of a subarea of AI4Science; namely, AI for quantum, atomistic, and\ncontinuum systems. These areas aim at understanding the physical world from the\nsubatomic (wavefunctions and electron density), atomic (molecules, proteins,\nmaterials, and interactions), to macro (fluids, climate, and subsurface) scales\nand form an important subarea of AI4Science. A unique advantage of focusing on\nthese areas is that they largely share a common set of challenges, thereby\nallowing a unified and foundational treatment. A key common challenge is how to\ncapture physics first principles, especially symmetries, in natural systems by\ndeep learning methods. We provide an in-depth yet intuitive account of\ntechniques to achieve equivariance to symmetry transformations. We also discuss\nother common technical challenges, including explainability,\nout-of-distribution generalization, knowledge transfer with foundation and\nlarge language models, and uncertainty quantification. To facilitate learning\nand education, we provide categorized lists of resources that we found to be\nuseful. We strive to be thorough and unified and hope this initial effort may\ntrigger more community interests and efforts to further advance AI4Science.\n",
                "链接": "https://arxiv.org/abs/2307.08423"
            },
            {
                "文章ID": "96846",
                "标题": "Consciousness in Artificial Intelligence: Insights from the Science of\n  Consciousness",
                "作者": " Patrick Butlin,  Robert Long,  Eric Elmoznino,  Yoshua Bengio,  Jonathan Birch,  Axel Constant,  George Deane,  Stephen M. Fleming,  Chris Frith,  Xu Ji,  Ryota Kanai,  Colin Klein,  Grace Lindsay,  Matthias Michel,  Liad Mudrik,  Megan A. K. Peters,  Eric Schwitzgebel,  Jonathan Simon,  Rufin VanRullen",
                "发布日期": "2023-08-23",
                "摘要": "  Whether current or near-term AI systems could be conscious is a topic of\nscientific interest and increasing public concern. This report argues for, and\nexemplifies, a rigorous and empirically grounded approach to AI consciousness:\nassessing existing AI systems in detail, in light of our best-supported\nneuroscientific theories of consciousness. We survey several prominent\nscientific theories of consciousness, including recurrent processing theory,\nglobal workspace theory, higher-order theories, predictive processing, and\nattention schema theory. From these theories we derive \"indicator properties\"\nof consciousness, elucidated in computational terms that allow us to assess AI\nsystems for these properties. We use these indicator properties to assess\nseveral recent AI systems, and we discuss how future systems might implement\nthem. Our analysis suggests that no current AI systems are conscious, but also\nsuggests that there are no obvious technical barriers to building AI systems\nwhich satisfy these indicators.\n",
                "链接": "https://arxiv.org/abs/2308.08708"
            },
            {
                "文章ID": "99506",
                "标题": "Science Communications for Explainable Artificial Intelligence",
                "作者": " Simon Hudson,  Matija Franklin",
                "发布日期": "2023-09-01",
                "摘要": "  Artificial Intelligence (AI) has a communication problem. XAI methods have\nbeen used to make AI more understandable and helped resolve some of the\ntransparency issues that inhibit AI's broader usability. However, user\nevaluation studies reveal that the often numerical explanations provided by XAI\nmethods have not always been effective for many types of users of AI systems.\nThis article aims to adapt the major communications models from Science\nCommunications into a framework for practitioners to understand, influence, and\nintegrate the context of audiences both for their communications supporting AI\nliteracy in the public and in designing XAI systems that are more adaptive to\ndifferent users.\n",
                "链接": "https://arxiv.org/abs/2308.16377"
            },
            {
                "文章ID": "15136",
                "标题": "An Introductory Review of Spiking Neural Network and Artificial Neural\n  Network: From Biological Intelligence to Artificial Intelligence",
                "作者": " Shengjie Zheng,  Lang Qian,  Pingsheng Li,  Chenggang He,  Xiaoqin Qin,  Xiaojian Li",
                "发布日期": "2022-04-18",
                "摘要": "  Recently, stemming from the rapid development of artificial intelligence,\nwhich has gained expansive success in pattern recognition, robotics, and\nbioinformatics, neuroscience is also gaining tremendous progress. A kind of\nspiking neural network with biological interpretability is gradually receiving\nwide attention, and this kind of neural network is also regarded as one of the\ndirections toward general artificial intelligence. This review introduces the\nfollowing sections, the biological background of spiking neurons and the\ntheoretical basis, different neuronal models, the connectivity of neural\ncircuits, the mainstream neural network learning mechanisms and network\narchitectures, etc. This review hopes to attract different researchers and\nadvance the development of brain-inspired intelligence and artificial\nintelligence.\n",
                "链接": "https://arxiv.org/abs/2204.07519"
            },
            {
                "文章ID": "47274",
                "标题": "Issues and Challenges in Applications of Artificial Intelligence to\n  Nuclear Medicine -- The Bethesda Report (AI Summit 2022)",
                "作者": " Arman Rahmim,  Tyler J. Bradshaw,  Irène Buvat,  Joyita Dutta,  Abhinav K. Jha,  Paul E. Kinahan,  Quanzheng Li,  Chi Liu,  Melissa D. McCradden,  Babak Saboury,  Eliot Siegel,  John J. Sunderland,  Richard L. Wahl",
                "发布日期": "2022-11-08",
                "摘要": "  The SNMMI Artificial Intelligence (SNMMI-AI) Summit, organized by the SNMMI\nAI Task Force, took place in Bethesda, MD on March 21-22, 2022. It brought\ntogether various community members and stakeholders from academia, healthcare,\nindustry, patient representatives, and government (NIH, FDA), and considered\nvarious key themes to envision and facilitate a bright future for routine,\ntrustworthy use of AI in nuclear medicine. In what follows, essential issues,\nchallenges, controversies and findings emphasized in the meeting are\nsummarized.\n",
                "链接": "https://arxiv.org/abs/2211.03783"
            },
            {
                "文章ID": "43747",
                "标题": "Review of the state of the art in autonomous artificial intelligence",
                "作者": " Petar Radanliev,  David De Roure",
                "发布日期": "2022-10-20",
                "摘要": "  This article presents a new design for autonomous artificial intelligence\n(AI), based on the state-of-the-art algorithms, and describes a new autonomous\nAI system called AutoAI. The methodology is used to assemble the design founded\non self-improved algorithms that use new and emerging sources of data (NEFD).\nThe objective of the article is to conceptualise the design of a novel AutoAI\nalgorithm. The conceptual approach is used to advance into building new and\nimproved algorithms. The article integrates and consolidates the findings from\nexisting literature and advances the AutoAI design into (1) using new and\nemerging sources of data for teaching and training AI algorithms and (2)\nenabling AI algorithms to use automated tools for training new and improved\nalgorithms. This approach is going beyond the state-of-the-art in AI algorithms\nand suggests a design that enables autonomous algorithms to self-optimise and\nself-adapt, and on a higher level, be capable to self-procreate.\n",
                "链接": "https://arxiv.org/abs/2210.10659"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下2023年关于LLM-based Agent的综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "23000",
                "标题": "Machine learning applications for electricity market agent-based models:\n  A systematic literature review",
                "作者": " Alexander J. M. Kell,  Stephen McGough,  Matthew Forshaw",
                "发布日期": "2022-06-07",
                "摘要": "  The electricity market has a vital role to play in the decarbonisation of the\nenergy system. However, the electricity market is made up of many different\nvariables and data inputs. These variables and data inputs behave in sometimes\nunpredictable ways which can not be predicted a-priori. It has therefore been\nsuggested that agent-based simulations are used to better understand the\ndynamics of the electricity market. Agent-based models provide the opportunity\nto integrate machine learning and artificial intelligence to add intelligence,\nmake better forecasts and control the power market in better and more efficient\nways. In this systematic literature review, we review 55 papers published\nbetween 2016 and 2021 which focus on machine learning applied to agent-based\nelectricity market models. We find that research clusters around popular\ntopics, such as bidding strategies. However, there exists a long-tail of\ndifferent research applications that could benefit from the high intensity\nresearch from the more investigated applications.\n",
                "链接": "https://arxiv.org/abs/2206.02196"
            },
            {
                "文章ID": "84465",
                "标题": "A Systematic Literature Review on Client Selection in Federated Learning",
                "作者": " Carl Smestad,  Jingyue Li",
                "发布日期": "2023-06-09",
                "摘要": "  With the arising concerns of privacy within machine learning, federated\nlearning (FL) was invented in 2017, in which the clients, such as mobile\ndevices, train a model and send the update to the centralized server. Choosing\nclients randomly for FL can harm learning performance due to different reasons.\nMany studies have proposed approaches to address the challenges of client\nselection of FL. However, no systematic literature review (SLR) on this topic\nexisted. This SLR investigates the state of the art of client selection in FL\nand answers the challenges, solutions, and metrics to evaluate the solutions.\nWe systematically reviewed 47 primary studies. The main challenges found in\nclient selection are heterogeneity, resource allocation, communication costs,\nand fairness. The client selection schemes aim to improve the original random\nselection algorithm by focusing on one or several of the aforementioned\nchallenges. The most common metric used is testing accuracy versus\ncommunication rounds, as testing accuracy measures the successfulness of the\nlearning and preferably in as few communication rounds as possible, as they are\nvery expensive. Although several possible improvements can be made with the\ncurrent state of client selection, the most beneficial ones are evaluating the\nimpact of unsuccessful clients and gaining a more theoretical understanding of\nthe impact of fairness in FL.\n",
                "链接": "https://arxiv.org/abs/2306.04862"
            },
            {
                "文章ID": "32835",
                "标题": "Literature Review: Graph Kernels in Chemoinformatics",
                "作者": " James Young",
                "发布日期": "2022-08-29",
                "摘要": "  The purpose of this review is to introduce the reader to graph kernels and\nthe corresponding literature, with an emphasis on those with direct application\nto chemoinformatics. Graph kernels are functions that allow for the inference\nof properties of molecules and compounds, which can help with tasks such as\nfinding suitable compounds in drug design. The use of kernel methods is but one\nparticular way two quantify similarity between graphs. We restrict our\ndiscussion to this one method, although popular alternatives have emerged in\nrecent years, most notably graph neural networks.\n",
                "链接": "https://arxiv.org/abs/2208.04929"
            },
            {
                "文章ID": "50902",
                "标题": "Automating Systematic Literature Reviews with Natural Language\n  Processing and Text Mining: a Systematic Literature Review",
                "作者": " Girish Sundaram,  Daniel Berleant",
                "发布日期": "2023-08-01",
                "摘要": "  Objectives: An SLR is presented focusing on text mining based automation of\nSLR creation. The present review identifies the objectives of the automation\nstudies and the aspects of those steps that were automated. In so doing, the\nvarious ML techniques used, challenges, limitations and scope of further\nresearch are explained.\n  Methods: Accessible published literature studies that primarily focus on\nautomation of study selection, study quality assessment, data extraction and\ndata synthesis portions of SLR. Twenty-nine studies were analyzed.\n  Results: This review identifies the objectives of the automation studies,\nsteps within the study selection, study quality assessment, data extraction and\ndata synthesis portions that were automated, the various ML techniques used,\nchallenges, limitations and scope of further research.\n  Discussion: We describe uses of NLP/TM techniques to support increased\nautomation of systematic literature reviews. This area has attracted increase\nattention in the last decade due to significant gaps in the applicability of TM\nto automate steps in the SLR process. There are significant gaps in the\napplication of TM and related automation techniques in the areas of data\nextraction, monitoring, quality assessment and data synthesis. There is thus a\nneed for continued progress in this area, and this is expected to ultimately\nsignificantly facilitate the construction of systematic literature reviews.\n",
                "链接": "https://arxiv.org/abs/2211.15397"
            },
            {
                "文章ID": "79186",
                "标题": "Systematic Literature Review on Application of Machine Learning in\n  Continuous Integration",
                "作者": " Ali Kazemi Arani,  Triet Huynh Minh Le,  Mansooreh Zahedi,  Muhammad Ali Babar",
                "发布日期": "2023-07-18",
                "摘要": "  This research conducted a systematic review of the literature on machine\nlearning (ML)-based methods in the context of Continuous Integration (CI) over\nthe past 22 years. The study aimed to identify and describe the techniques used\nin ML-based solutions for CI and analyzed various aspects such as data\nengineering, feature engineering, hyper-parameter tuning, ML models, evaluation\nmethods, and metrics. In this paper, we have depicted the phases of CI testing,\nthe connection between them, and the employed techniques in training the ML\nmethod phases. We presented nine types of data sources and four taken steps in\nthe selected studies for preparing the data. Also, we identified four feature\ntypes and nine subsets of data features through thematic analysis of the\nselected studies. Besides, five methods for selecting and tuning the\nhyper-parameters are shown. In addition, we summarised the evaluation methods\nused in the literature and identified fifteen different metrics. The most\ncommonly used evaluation methods were found to be precision, recall, and\nF1-score, and we have also identified five methods for evaluating the\nperformance of trained ML models. Finally, we have presented the relationship\nbetween ML model types, performance measurements, and CI phases. The study\nprovides valuable insights for researchers and practitioners interested in\nML-based methods in CI and emphasizes the need for further research in this\narea.\n",
                "链接": "https://arxiv.org/abs/2305.12695"
            },
            {
                "文章ID": "70216",
                "标题": "Reviewer Assignment Problem: A Systematic Review of the Literature",
                "作者": " Meltem Aksoy,  Seda Yanik,  Mehmet Fatih Amasyali",
                "发布日期": "2023-04-05",
                "摘要": "  Appropriate reviewer assignment significantly impacts the quality of proposal\nevaluation, as accurate and fair reviews are contingent on their assignment to\nrelevant reviewers. The crucial task of assigning reviewers to submitted\nproposals is the starting point of the review process and is also known as the\nreviewer assignment problem (RAP). Due to the obvious restrictions of manual\nassignment, journal editors, conference organizers, and grant managers demand\nautomatic reviewer assignment approaches. Many studies have proposed assignment\nsolutions in response to the demand for automated procedures since 1992. The\nprimary objective of this survey paper is to provide scholars and practitioners\nwith a comprehensive overview of available research on the RAP. To achieve this\ngoal, this article presents an in-depth systematic review of 103 publications\nin the field of reviewer assignment published in the past three decades and\navailable in the Web of Science, Scopus, ScienceDirect, Google Scholar, and\nSemantic Scholar databases. This review paper classified and discussed the RAP\napproaches into two broad categories and numerous subcategories based on their\nunderlying techniques. Furthermore, potential future research directions for\neach category are presented. This survey shows that the research on the RAP is\nbecoming more significant and that more effort is required to develop new\napproaches and a framework.\n",
                "链接": "https://arxiv.org/abs/2304.00353"
            },
            {
                "文章ID": "106140",
                "标题": "Conversational Health Agents: A Personalized LLM-Powered Agent Framework",
                "作者": " Mahyar Abbasian,  Iman Azimi,  Amir M. Rahmani,  Ramesh Jain",
                "发布日期": "2023-12-11",
                "摘要": "  Conversational Health Agents (CHAs) are interactive systems that provide\nhealthcare services, such as assistance, self-awareness, and diagnosis. Current\nCHAs, especially those utilizing Large Language Models (LLMs), primarily focus\non conversation aspects. However, they offer limited agent capabilities\nspecifically lacking multi-step problem-solving, empathetic conversations, and\nmultimodal data analysis. Our aim is to overcome these limitations. In this\npaper, we propose an LLM-powered framework to empower CHAs to generate a\npersonalized response for users' healthcare queries. This framework provides\ncritical thinking, knowledge acquisition, and problem-solving abilities by\nintegrating healthcare data sources, enabling multilingual and multimodal\nconversations, and interacting with various user data analysis tools. We\nillustrate the framework's proficiency in handling complex healthcare tasks via\na case study on stress level estimation, showcasing the agent's cognitive and\noperational capabilities. Powered by our framework, the CHA can provide\nappropriate responses, when the user inquires about their stress level. To\nachieve this, it learns to collect photoplethysmogram signals, converts them\ninto heart rate variability, and interprets them as indicators of stress\nlevels.\n",
                "链接": "https://arxiv.org/abs/2310.02374"
            },
            {
                "文章ID": "94694",
                "标题": "AI Literature Review Suite",
                "作者": " David A. Tovar",
                "发布日期": "2023-08-07",
                "摘要": "  The process of conducting literature reviews is often time-consuming and\nlabor-intensive. To streamline this process, I present an AI Literature Review\nSuite that integrates several functionalities to provide a comprehensive\nliterature review. This tool leverages the power of open access science, large\nlanguage models (LLMs) and natural language processing to enable the searching,\ndownloading, and organizing of PDF files, as well as extracting content from\narticles. Semantic search queries are used for data retrieval, while text\nembeddings and summarization using LLMs present succinct literature reviews.\nInteraction with PDFs is enhanced through a user-friendly graphical user\ninterface (GUI). The suite also features integrated programs for bibliographic\norganization, interaction and query, and literature review summaries. This tool\npresents a robust solution to automate and optimize the process of literature\nreview in academic and industrial research.\n",
                "链接": "https://arxiv.org/abs/2308.02443"
            },
            {
                "文章ID": "105192",
                "标题": "LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent\n  Negotiation Games",
                "作者": " Sahar Abdelnabi,  Amr Gomaa,  Sarath Sivaprasad,  Lea Schönherr,  Mario Fritz",
                "发布日期": "2023-10-02",
                "摘要": "  There is a growing interest in using Large Language Models (LLMs) as agents\nto tackle real-world tasks that may require assessing complex situations. Yet,\nwe have a limited understanding of LLMs' reasoning and decision-making\ncapabilities, partly stemming from a lack of dedicated evaluation benchmarks.\nAs negotiating and compromising are key aspects of our everyday communication\nand collaboration, we propose using scorable negotiation games as a new\nevaluation framework for LLMs. We create a testbed of diverse text-based,\nmulti-agent, multi-issue, semantically rich negotiation games, with easily\ntunable difficulty. To solve the challenge, agents need to have strong\narithmetic, inference, exploration, and planning capabilities, while seamlessly\nintegrating them. Via a systematic zero-shot Chain-of-Thought prompting (CoT),\nwe show that agents can negotiate and consistently reach successful deals. We\nquantify the performance with multiple metrics and observe a large gap between\nGPT-4 and earlier models. Importantly, we test the generalization to new games\nand setups. Finally, we show that these games can help evaluate other critical\naspects, such as the interaction dynamics between agents in the presence of\ngreedy and adversarial players.\n",
                "链接": "https://arxiv.org/abs/2309.17234"
            },
            {
                "文章ID": "119996",
                "标题": "A Comprehensive Literature Review on Sweet Orange Leaf Diseases",
                "作者": " Yousuf Rayhan Emon,  Md Golam Rabbani,  Dr. Md. Taimur Ahad,  Faruk Ahmed",
                "发布日期": "2023-12-05",
                "摘要": "  Sweet orange leaf diseases are significant to agricultural productivity. Leaf\ndiseases impact fruit quality in the citrus industry. The apparition of machine\nlearning makes the development of disease finder. Early detection and diagnosis\nare necessary for leaf management. Sweet orange leaf disease-predicting\nautomated systems have already been developed using different image-processing\ntechniques. This comprehensive literature review is systematically based on\nleaf disease and machine learning methodologies applied to the detection of\ndamaged leaves via image classification. The benefits and limitations of\ndifferent machine learning models, including Vision Transformer (ViT), Neural\nNetwork (CNN), CNN with SoftMax and RBF SVM, Hybrid CNN-SVM, HLB-ConvMLP,\nEfficientNet-b0, YOLOv5, YOLOv7, Convolutional, Deep CNN. These machine\nlearning models tested on various datasets and detected the disease. This\ncomprehensive review study related to leaf disease compares the performance of\nthe models; those models' accuracy, precision, recall, etc., were used in the\nsubsisting studies\n",
                "链接": "https://arxiv.org/abs/2312.01756"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "68991",
                "标题": "Joint fMRI Decoding and Encoding with Latent Embedding Alignment",
                "作者": " Xuelin Qian,  Yikai Wang,  Yanwei Fu,  Xinwei Sun,  Xiangyang Xue,  Jianfeng Feng",
                "发布日期": "2023-06-06",
                "摘要": "  The connection between brain activity and corresponding visual stimuli is\ncrucial in comprehending the human brain. While deep generative models have\nexhibited advancement in recovering brain recordings by generating images\nconditioned on fMRI signals, accomplishing high-quality generation with\nconsistent semantics continues to pose challenges. Moreover, the prediction of\nbrain activity from visual stimuli remains a formidable undertaking. In this\npaper, we introduce a unified framework that addresses both fMRI decoding and\nencoding. Commencing with the establishment of two latent spaces capable of\nrepresenting and reconstructing fMRI signals and visual images, respectively,\nwe proceed to align the fMRI signals and visual images within the latent space,\nthereby enabling a bidirectional transformation between the two domains. Our\nLatent Embedding Alignment (LEA) model concurrently recovers visual stimuli\nfrom fMRI signals and predicts brain activity from images within a unified\nframework. The performance of LEA surpasses that of existing methods on\nmultiple benchmark fMRI decoding and encoding datasets. By integrating fMRI\ndecoding and encoding, LEA offers a comprehensive solution for modeling the\nintricate relationship between brain activity and visual stimuli.\n",
                "链接": "https://arxiv.org/abs/2303.14730"
            },
            {
                "文章ID": "15783",
                "标题": "Cross-view Brain Decoding",
                "作者": " Subba Reddy Oota,  Jashn Arora,  Manish Gupta,  Raju S. Bapi",
                "发布日期": "2022-04-21",
                "摘要": "  How the brain captures the meaning of linguistic stimuli across multiple\nviews is still a critical open question in neuroscience. Consider three\ndifferent views of the concept apartment: (1) picture (WP) presented with the\ntarget word label, (2) sentence (S) using the target word, and (3) word cloud\n(WC) containing the target word along with other semantically related words.\nUnlike previous efforts, which focus only on single view analysis, in this\npaper, we study the effectiveness of brain decoding in a zero-shot cross-view\nlearning setup. Further, we propose brain decoding in the novel context of\ncross-view-translation tasks like image captioning (IC), image tagging (IT),\nkeyword extraction (KE), and sentence formation (SF). Using extensive\nexperiments, we demonstrate that cross-view zero-shot brain decoding is\npractical leading to ~0.68 average pairwise accuracy across view pairs. Also,\nthe decoded representations are sufficiently detailed to enable high accuracy\nfor cross-view-translation tasks with following pairwise accuracy: IC (78.0),\nIT (83.0), KE (83.7) and SF (74.5). Analysis of the contribution of different\nbrain networks reveals exciting cognitive insights: (1) A high percentage of\nvisual voxels are involved in image captioning and image tagging tasks, and a\nhigh percentage of language voxels are involved in the sentence formation and\nkeyword extraction tasks. (2) Zero-shot accuracy of the model trained on S view\nand tested on WC view is better than same-view accuracy of the model trained\nand tested on WC view.\n",
                "链接": "https://arxiv.org/abs/2204.09564"
            },
            {
                "文章ID": "43075",
                "标题": "ConReader: Exploring Implicit Relations in Contracts for Contract Clause\n  Extraction",
                "作者": " Weiwen Xu,  Yang Deng,  Wenqiang Lei,  Wenlong Zhao,  Tat-Seng Chua,  Wai Lam",
                "发布日期": "2022-10-18",
                "摘要": "  We study automatic Contract Clause Extraction (CCE) by modeling implicit\nrelations in legal contracts. Existing CCE methods mostly treat contracts as\nplain text, creating a substantial barrier to understanding contracts of high\ncomplexity. In this work, we first comprehensively analyze the complexity\nissues of contracts and distill out three implicit relations commonly found in\ncontracts, namely, 1) Long-range Context Relation that captures the\ncorrelations of distant clauses; 2) Term-Definition Relation that captures the\nrelation between important terms with their corresponding definitions; and 3)\nSimilar Clause Relation that captures the similarities between clauses of the\nsame type. Then we propose a novel framework ConReader to exploit the above\nthree relations for better contract understanding and improving CCE.\nExperimental results show that ConReader makes the prediction more\ninterpretable and achieves new state-of-the-art on two CCE tasks in both\nconventional and zero-shot settings.\n",
                "链接": "https://arxiv.org/abs/2210.08697"
            },
            {
                "文章ID": "77552",
                "标题": "A Hierarchical Encoding-Decoding Scheme for Abstractive Multi-document\n  Summarization",
                "作者": " Chenhui Shen,  Liying Cheng,  Xuan-Phi Nguyen,  Yang You,  Lidong Bing",
                "发布日期": "2023-11-02",
                "摘要": "  Pre-trained language models (PLMs) have achieved outstanding achievements in\nabstractive single-document summarization (SDS). However, such benefits may not\nfully extend to multi-document summarization (MDS), where the handling of\ncross-document information is more complex. Previous works either design new\nMDS architectures or apply PLMs bluntly with concatenated source documents as a\nreformulated SDS task. While the former does not utilize previous pre-training\nefforts and may not generalize well across different domains, the latter may\nnot sufficiently attend to the intricate cross-document relationships unique to\nMDS tasks. Instead, we enforce hierarchy on both the encoder and decoder to\nbetter utilize a PLM to facilitate multi-document interactions for the MDS\ntask. Across 10 MDS benchmarks from various domains, our method outperforms or\nis competitive with the previous best models, including those with additional\nMDS pre-training or with more parameters. It outperforms its corresponding PLM\nbackbone by up to 3 Rouge-L and is favored by humans.\n",
                "链接": "https://arxiv.org/abs/2305.08503"
            },
            {
                "文章ID": "102703",
                "标题": "Efficient Avoidance of Vulnerabilities in Auto-completed Smart Contract\n  Code Using Vulnerability-constrained Decoding",
                "作者": " André Storhaug,  Jingyue Li,  Tianyuan Hu",
                "发布日期": "2023-10-09",
                "摘要": "  Auto-completing code enables developers to speed up coding significantly.\nRecent advances in transformer-based large language model (LLM) technologies\nhave been applied to code synthesis. However, studies show that many of such\nsynthesized codes contain vulnerabilities. We propose a novel\nvulnerability-constrained decoding approach to reduce the amount of vulnerable\ncode generated by such models. Using a small dataset of labeled vulnerable\nlines of code, we fine-tune an LLM to include vulnerability labels when\ngenerating code, acting as an embedded classifier. Then, during decoding, we\ndeny the model to generate these labels to avoid generating vulnerable code. To\nevaluate the method, we chose to automatically complete Ethereum Blockchain\nsmart contracts (SCs) as the case study due to the strict requirements of SC\nsecurity. We first fine-tuned the 6-billion-parameter GPT-J model using 186,397\nEthereum SCs after removing the duplication from 2,217,692 SCs. The fine-tuning\ntook more than one week using ten GPUs. The results showed that our fine-tuned\nmodel could synthesize SCs with an average BLEU (BiLingual Evaluation\nUnderstudy) score of 0.557. However, many codes in the auto-completed SCs were\nvulnerable. Using the code before the vulnerable line of 176 SCs containing\ndifferent types of vulnerabilities to auto-complete the code, we found that\nmore than 70% of the auto-completed codes were insecure. Thus, we further\nfine-tuned the model on other 941 vulnerable SCs containing the same types of\nvulnerabilities and applied vulnerability-constrained decoding. The fine-tuning\ntook only one hour with four GPUs. We then auto-completed the 176 SCs again and\nfound that our approach could identify 62% of the code to be generated as\nvulnerable and avoid generating 67% of them, indicating the approach could\nefficiently and effectively avoid vulnerabilities in the auto-completed code.\n",
                "链接": "https://arxiv.org/abs/2309.09826"
            },
            {
                "文章ID": "91982",
                "标题": "Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding\n  (Survey)",
                "作者": " Subba Reddy Oota,  Manish Gupta,  Raju S. Bapi,  Gael Jobard,  Frederic Alexandre,  Xavier Hinaut",
                "发布日期": "2023-07-21",
                "摘要": "  How does the brain represent different modes of information? Can we design a\nsystem that automatically understands what the user is thinking? Such questions\ncan be answered by studying brain recordings like functional magnetic resonance\nimaging (fMRI). As a first step, the neuroscience community has contributed\nseveral large cognitive neuroscience datasets related to passive\nreading/listening/viewing of concept words, narratives, pictures and movies.\nEncoding and decoding models using these datasets have also been proposed in\nthe past two decades. These models serve as additional tools for basic research\nin cognitive science and neuroscience. Encoding models aim at generating fMRI\nbrain representations given a stimulus automatically. They have several\npractical applications in evaluating and diagnosing neurological conditions and\nthus also help design therapies for brain damage. Decoding models solve the\ninverse problem of reconstructing the stimuli given the fMRI. They are useful\nfor designing brain-machine or brain-computer interfaces. Inspired by the\neffectiveness of deep learning models for natural language processing, computer\nvision, and speech, recently several neural encoding and decoding models have\nbeen proposed. In this survey, we will first discuss popular representations of\nlanguage, vision and speech stimuli, and present a summary of neuroscience\ndatasets. Further, we will review popular deep learning based encoding and\ndecoding architectures and note their benefits and limitations. Finally, we\nwill conclude with a brief summary and discussion about future trends. Given\nthe large amount of recently published work in the `computational cognitive\nneuroscience' community, we believe that this survey nicely organizes the\nplethora of work and presents it as a coherent story.\n",
                "链接": "https://arxiv.org/abs/2307.10246"
            },
            {
                "文章ID": "47160",
                "标题": "Decoding Neural Signals with Computational Models: A Systematic Review\n  of Invasive BMI",
                "作者": " Rezwan Firuzi,  Hamed Ahmadyani,  Mohammad Foad Abdi,  Dana Naderi,  Jahan Hassan,  Ayub Bokani",
                "发布日期": "2022-11-08",
                "摘要": "  There are significant milestones in modern human's civilization in which\nmankind stepped into a different level of life with a new spectrum of\npossibilities and comfort. From fire-lighting technology and wheeled wagons to\nwriting, electricity and the Internet, each one changed our lives dramatically.\nIn this paper, we take a deep look into the invasive Brain Machine Interface\n(BMI), an ambitious and cutting-edge technology which has the potential to be\nanother important milestone in human civilization. Not only beneficial for\npatients with severe medical conditions, the invasive BMI technology can\nsignificantly impact different technologies and almost every aspect of human's\nlife. We review the biological and engineering concepts that underpin the\nimplementation of BMI applications. There are various essential techniques that\nare necessary for making invasive BMI applications a reality. We review these\nthrough providing an analysis of (i) possible applications of invasive BMI\ntechnology, (ii) the methods and devices for detecting and decoding brain\nsignals, as well as (iii) possible options for stimulating signals into human's\nbrain. Finally, we discuss the challenges and opportunities of invasive BMI for\nfurther development in the area.\n",
                "链接": "https://arxiv.org/abs/2211.03324"
            },
            {
                "文章ID": "5326",
                "标题": "Hierarchical Point Cloud Encoding and Decoding with Lightweight\n  Self-Attention based Model",
                "作者": " En Yen Puang,  Hao Zhang,  Hongyuan Zhu,  Wei Jing",
                "发布日期": "2022-03-16",
                "摘要": "  In this paper we present SA-CNN, a hierarchical and lightweight\nself-attention based encoding and decoding architecture for representation\nlearning of point cloud data. The proposed SA-CNN introduces convolution and\ntransposed convolution stacks to capture and generate contextual information\namong unordered 3D points. Following conventional hierarchical pipeline, the\nencoding process extracts feature in local-to-global manner, while the decoding\nprocess generates feature and point cloud in coarse-to-fine, multi-resolution\nstages. We demonstrate that SA-CNN is capable of a wide range of applications,\nnamely classification, part segmentation, reconstruction, shape retrieval, and\nunsupervised classification. While achieving the state-of-the-art or comparable\nperformance in the benchmarks, SA-CNN maintains its model complexity several\norder of magnitude lower than the others. In term of qualitative results, we\nvisualize the multi-stage point cloud reconstructions and latent walks on rigid\nobjects as well as deformable non-rigid human and robot models.\n",
                "链接": "https://arxiv.org/abs/2202.06407"
            },
            {
                "文章ID": "41529",
                "标题": "EmbryosFormer: Deformable Transformer and Collaborative\n  Encoding-Decoding for Embryos Stage Development Classification",
                "作者": " Tien-Phat Nguyen,  Trong-Thang Pham,  Tri Nguyen,  Hieu Le,  Dung Nguyen,  Hau Lam,  Phong Nguyen,  Jennifer Fowler,  Minh-Triet Tran,  Ngan Le",
                "发布日期": "2022-10-11",
                "摘要": "  The timing of cell divisions in early embryos during the In-Vitro\nFertilization (IVF) process is a key predictor of embryo viability. However,\nobserving cell divisions in Time-Lapse Monitoring (TLM) is a time-consuming\nprocess and highly depends on experts. In this paper, we propose EmbryosFormer,\na computational model to automatically detect and classify cell divisions from\noriginal time-lapse images. Our proposed network is designed as an\nencoder-decoder deformable transformer with collaborative heads. The\ntransformer contracting path predicts per-image labels and is optimized by a\nclassification head. The transformer expanding path models the temporal\ncoherency between embryo images to ensure monotonic non-decreasing constraint\nand is optimized by a segmentation head. Both contracting and expanding paths\nare synergetically learned by a collaboration head. We have benchmarked our\nproposed EmbryosFormer on two datasets: a public dataset with mouse embryos\nwith 8-cell stage and an in-house dataset with human embryos with 4-cell stage.\nSource code: https://github.com/UARK-AICV/Embryos.\n",
                "链接": "https://arxiv.org/abs/2210.04615"
            },
            {
                "文章ID": "107624",
                "标题": "Encoding and Decoding Narratives: Datafication and Alternative Access\n  Models for Audiovisual Archives",
                "作者": " Yuchen Yang",
                "发布日期": "2023-10-11",
                "摘要": "  Situated in the intersection of audiovisual archives, computational methods,\nand immersive interactions, this work probes the increasingly important\naccessibility issues from a two-fold approach. Firstly, the work proposes an\nontological data model to handle complex descriptors (metadata, feature\nvectors, etc.) with regard to user interactions. Secondly, this work examines\ntext-to-video retrieval from an implementation perspective by proposing a\nclassifier-enhanced workflow to deal with complex and hybrid queries and a\ntraining data augmentation workflow to improve performance. This work serves as\nthe foundation for experimenting with novel public-facing access models to\nlarge audiovisual archives\n",
                "链接": "https://arxiv.org/abs/2310.06309"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近三个月有关语言模型rlhf的arxiv上的全部文章。",
            "type": "5"
        },
        "results": []
    },
    {
        "question": {
            "question": "查找大模型结合树搜索方法进行推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105172",
                "标题": "Alphazero-like Tree-Search can Guide Large Language Model Decoding and\n  Training",
                "作者": " Xidong Feng,  Ziyu Wan,  Muning Wen,  Ying Wen,  Weinan Zhang,  Jun Wang",
                "发布日期": "2023-10-02",
                "摘要": "  Large language models (LLMs) typically employ sampling or beam search,\naccompanied by prompts such as Chain-of-Thought (CoT), to boost reasoning and\ndecoding ability. Recent work like Tree-of-Thought (ToT) and Reasoning via\nPlanning (RAP) aim to augment the reasoning capabilities of LLMs by utilizing\ntree-search algorithms to guide multi-step reasoning. These methods mainly\nfocus on LLMs' reasoning ability during inference and heavily rely on\nhuman-designed prompts to activate LLM as a value function, which lacks general\napplicability and scalability. To address these limitations, we present an\nAlphaZero-like tree-search framework for LLMs (termed TS-LLM), systematically\nillustrating how tree-search with a learned value function can guide LLMs'\ndecoding ability. TS-LLM distinguishes itself in two key ways: (1) Leveraging a\nlearned value function, our approach can be generally applied to different\ntasks beyond reasoning (such as RLHF alignment), and LLMs of any size, without\nprompting advanced, large-scale models. (2) It can guide LLM's decoding during\nboth inference and training. Empirical evaluations across reasoning, planning,\nand RLHF alignment tasks validate the effectiveness of TS-LLM, even on trees\nwith a depth of 64.\n",
                "链接": "https://arxiv.org/abs/2309.17179"
            },
            {
                "文章ID": "109239",
                "标题": "Autonomous Tree-search Ability of Large Language Models",
                "作者": " Zheyu Zhang,  Zhuorui Ye,  Yikang Shen,  Chuang Gan",
                "发布日期": "2023-10-18",
                "摘要": "  Large Language Models have excelled in remarkable reasoning capabilities with\nadvanced prompting techniques, but they fall short on tasks that require\nexploration, strategic foresight, and sequential decision-making. Recent works\npropose to utilize external programs to define search logic, such that LLMs can\nperform passive tree search to solve more challenging reasoning tasks. Though\nimpressive results have been achieved, there are several fundamental\nlimitations of these approaches. First, passive tree searches are not efficient\nas they usually require multiple rounds of LLM API calls to solve one single\nproblem. Moreover, passive search methods are not flexible since they need\ntask-specific program designs. Then a natural question arises: can we maintain\nthe tree-search capability of LLMs without the aid of external programs, and\ncan still generate responses that clearly demonstrate the process of a\ntree-structure search? To this end, we propose a new concept called autonomous\ntree-search ability of LLM, which can automatically generate a response\ncontaining search trajectories for the correct answer. Concretely, we perform\nsearch trajectories using capable LLM API via a fixed system prompt, allowing\nthem to perform autonomous tree-search (ATS) right out of the box. Experiments\non 4 puzzle games demonstrate our method can achieve huge improvements. The\nATS-BFS method outperforms the Chain of Thought approach by achieving an\naverage accuracy improvement of 33%. Compared to Tree of Thoughts, it requires\n65.6% or 47.7% less GPT-api cost to attain a comparable level of accuracy.\nMoreover, we have collected data using the ATS prompt method and fine-tuned\nLLaMA. This approach yield a greater improvement compared to the ones\nfine-tuned on CoT data. Specifically, it outperforms CoT-tuned LLaMAs by an\naverage of 40.6% and 38.5% for LLaMA2-7B and LLaMA2-13B, respectively.\n",
                "链接": "https://arxiv.org/abs/2310.10686"
            },
            {
                "文章ID": "77937",
                "标题": "SpecInfer: Accelerating Generative Large Language Model Serving with\n  Speculative Inference and Token Tree Verification",
                "作者": " Xupeng Miao,  Gabriele Oliaro,  Zhihao Zhang,  Xinhao Cheng,  Zeyu Wang,  Rae Ying Yee Wong,  Alan Zhu,  Lijie Yang,  Xiaoxiang Shi,  Chunan Shi,  Zhuoming Chen,  Daiyaan Arfeen,  Reyna Abhyankar,  Zhihao Jia",
                "发布日期": "2023-08-17",
                "摘要": "  The high computational and memory requirements of generative large language\nmodels (LLMs) make it challenging to serve them quickly and cheaply. This paper\nintroduces SpecInfer, an LLM serving system that accelerates generative LLM\ninference with speculative inference and token tree verification. A key insight\nbehind Specinfer is to combine various collectively boost-tuned small language\nmodels to jointly predict the LLM's outputs; the predictions are organized as a\ntoken tree, whose nodes each represent a candidate token sequence. The\ncorrectness of all candidate token sequences represented by a token tree is\nverified against the LLM in parallel using a novel tree-based parallel decoding\nmechanism. SpecInfer uses an LLM as a token tree verifier instead of an\nincremental decoder, which significantly reduces the end-to-end latency and\ncomputational requirement for serving generative LLMs while provably preserving\nmodel quality. Our evaluation shows that SpecInfer outperforms existing LLM\nserving systems by 1.3-2.4x for distributed LLM inference and by 2.6-3.5x for\noffloading-based LLM inference, while preserving the same generative\nperformance. SpecInfer is publicly available at\nhttps://github.com/flexflow/FlexFlow/tree/inference.\n",
                "链接": "https://arxiv.org/abs/2305.09781"
            },
            {
                "文章ID": "57742",
                "标题": "Neural Architecture Search: Insights from 1000 Papers",
                "作者": " Colin White,  Mahmoud Safari,  Rhea Sukthanker,  Binxin Ru,  Thomas Elsken,  Arber Zela,  Debadeepta Dey,  Frank Hutter",
                "发布日期": "2023-01-26",
                "摘要": "  In the past decade, advances in deep learning have resulted in breakthroughs\nin a variety of areas, including computer vision, natural language\nunderstanding, speech recognition, and reinforcement learning. Specialized,\nhigh-performing neural architectures are crucial to the success of deep\nlearning in these areas. Neural architecture search (NAS), the process of\nautomating the design of neural architectures for a given task, is an\ninevitable next step in automating machine learning and has already outpaced\nthe best human-designed architectures on many tasks. In the past few years,\nresearch in NAS has been progressing rapidly, with over 1000 papers released\nsince 2020 (Deng and Lindauer, 2021). In this survey, we provide an organized\nand comprehensive guide to neural architecture search. We give a taxonomy of\nsearch spaces, algorithms, and speedup techniques, and we discuss resources\nsuch as benchmarks, best practices, other surveys, and open-source libraries.\n",
                "链接": "https://arxiv.org/abs/2301.08727"
            },
            {
                "文章ID": "75178",
                "标题": "Explanation through Reward Model Reconciliation using POMDP Tree Search",
                "作者": " Benjamin D. Kraske,  Anshu Saksena,  Anna L. Buczak,  Zachary N. Sunberg",
                "发布日期": "2023-05-02",
                "摘要": "  As artificial intelligence (AI) algorithms are increasingly used in\nmission-critical applications, promoting user-trust of these systems will be\nessential to their success. Ensuring users understand the models over which\nalgorithms reason promotes user trust. This work seeks to reconcile differences\nbetween the reward model that an algorithm uses for online partially observable\nMarkov decision (POMDP) planning and the implicit reward model assumed by a\nhuman user. Action discrepancies, differences in decisions made by an algorithm\nand user, are leveraged to estimate a user's objectives as expressed in\nweightings of a reward function.\n",
                "链接": "https://arxiv.org/abs/2305.00931"
            },
            {
                "文章ID": "77485",
                "标题": "Large Language Model Guided Tree-of-Thought",
                "作者": " Jieyi Long",
                "发布日期": "2023-05-16",
                "摘要": "  In this paper, we introduce the Tree-of-Thought (ToT) framework, a novel\napproach aimed at improving the problem-solving capabilities of auto-regressive\nlarge language models (LLMs). The ToT technique is inspired by the human mind's\napproach for solving complex reasoning tasks through trial and error. In this\nprocess, the human mind explores the solution space through a tree-like thought\nprocess, allowing for backtracking when necessary. To implement ToT as a\nsoftware system, we augment an LLM with additional modules including a prompter\nagent, a checker module, a memory module, and a ToT controller. In order to\nsolve a given problem, these modules engage in a multi-round conversation with\nthe LLM. The memory module records the conversation and state history of the\nproblem solving process, which allows the system to backtrack to the previous\nsteps of the thought-process and explore other directions from there. To verify\nthe effectiveness of the proposed technique, we implemented a ToT-based solver\nfor the Sudoku Puzzle. Experimental results show that the ToT framework can\nsignificantly increase the success rate of Sudoku puzzle solving. Our\nimplementation of the ToT-based Sudoku solver is available on GitHub:\n\\url{https://github.com/jieyilong/tree-of-thought-puzzle-solver}.\n",
                "链接": "https://arxiv.org/abs/2305.08291"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "794",
                "标题": "Tree-based Search Graph for Approximate Nearest Neighbor Search",
                "作者": " Xiaobin Fan,  Xiaoping Wang,  Kai Lu,  Lei Xue,  Jinjing Zhao",
                "发布日期": "2022-01-11",
                "摘要": "  Nearest neighbor search supports important applications in many domains, such\nas database, machine learning, computer vision. Since the computational cost\nfor accurate search is too high, the community turned to the research of\napproximate nearest neighbor search (ANNS). Among them, graph-based algorithm\nis one of the most important branches. Research by Fu et al. shows that the\nalgorithms based on Monotonic Search Network (MSNET), such as NSG and NSSG,\nhave achieved the state-of-the-art search performance in efficiency. The MSNET\nis dedicated to achieving monotonic search with minimal out-degree of nodes to\npursue high efficiency. However, the current MSNET designs did not optimize the\nprobability of the monotonic search, and the lower bound of the probability is\nonly 50%. If they fail in monotonic search stage, they have to suffer\ntremendous backtracking cost to achieve the required accuracy. This will cause\nperformance problems in search efficiency. To address this problem, we propose\n(r,p)-MSNET, which achieves guaranteed probability on monotonic search. Due to\nthe high building complexity of a strict (r,p)-MSNET, we propose TBSG, which is\nan approximation with low complexity. Experiment conducted on four\nmillion-scaled datasets show that TBSG outperforms existing state-of-the-art\ngraph-based algorithms in search efficiency. Our code has been released on\nGithub.\n",
                "链接": "https://arxiv.org/abs/2201.03237"
            },
            {
                "文章ID": "23592",
                "标题": "Combining Monte-Carlo Tree Search with Proof-Number Search",
                "作者": " Elliot Doe,  Mark H. M. Winands,  Dennis J. N. J. Soemers,  Cameron Browne",
                "发布日期": "2022-06-09",
                "摘要": "  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
                "链接": "https://arxiv.org/abs/2206.03965"
            },
            {
                "文章ID": "107708",
                "标题": "Accelerating Monte Carlo Tree Search with Probability Tree State\n  Abstraction",
                "作者": " Yangqing Fu,  Ming Sun,  Buqing Nie,  Yue Gao",
                "发布日期": "2023-10-11",
                "摘要": "  Monte Carlo Tree Search (MCTS) algorithms such as AlphaGo and MuZero have\nachieved superhuman performance in many challenging tasks. However, the\ncomputational complexity of MCTS-based algorithms is influenced by the size of\nthe search space. To address this issue, we propose a novel probability tree\nstate abstraction (PTSA) algorithm to improve the search efficiency of MCTS. A\ngeneral tree state abstraction with path transitivity is defined. In addition,\nthe probability tree state abstraction is proposed for fewer mistakes during\nthe aggregation step. Furthermore, the theoretical guarantees of the\ntransitivity and aggregation error bound are justified. To evaluate the\neffectiveness of the PTSA algorithm, we integrate it with state-of-the-art\nMCTS-based algorithms, such as Sampled MuZero and Gumbel MuZero. Experimental\nresults on different tasks demonstrate that our method can accelerate the\ntraining process of state-of-the-art algorithms with 10%-45% search space\nreduction.\n",
                "链接": "https://arxiv.org/abs/2310.06513"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于通过prompt经验性研究大语言模型行为的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "70118",
                "标题": "On the Creativity of Large Language Models",
                "作者": " Giorgio Franceschelli,  Mirco Musolesi",
                "发布日期": "2023-07-11",
                "摘要": "  Large Language Models (LLMs) are revolutionizing several areas of Artificial\nIntelligence. One of the most remarkable applications is creative writing,\ne.g., poetry or storytelling: the generated outputs are often of astonishing\nquality. However, a natural question arises: can LLMs be really considered\ncreative? In this article we firstly analyze the development of LLMs under the\nlens of creativity theories, investigating the key open questions and\nchallenges. In particular, we focus our discussion around the dimensions of\nvalue, novelty and surprise as proposed by Margaret Boden in her work. Then, we\nconsider different classic perspectives, namely product, process, press and\nperson. We discuss a set of ``easy'' and ``hard'' problems in machine\ncreativity, presenting them in relation to LLMs. Finally, we examine the\nsocietal impact of these technologies with a particular focus on the creative\nindustries, analyzing the opportunities offered by them, the challenges arising\nby them and the potential associated risks, from both legal and ethical points\nof view.\n",
                "链接": "https://arxiv.org/abs/2304.00008"
            },
            {
                "文章ID": "112605",
                "标题": "The Eval4NLP 2023 Shared Task on Prompting Large Language Models as\n  Explainable Metrics",
                "作者": " Christoph Leiter,  Juri Opitz,  Daniel Deutsch,  Yang Gao,  Rotem Dror,  Steffen Eger",
                "发布日期": "2023-10-31",
                "摘要": "  With an increasing number of parameters and pre-training data, generative\nlarge language models (LLMs) have shown remarkable capabilities to solve tasks\nwith minimal or no task-related examples. Notably, LLMs have been successfully\nemployed as evaluation metrics in text generation tasks. Within this context,\nwe introduce the Eval4NLP 2023 shared task that asks participants to explore\nprompting and score extraction for machine translation (MT) and summarization\nevaluation. Specifically, we propose a novel competition setting in which we\nselect a list of allowed LLMs and disallow fine-tuning to ensure a focus on\nprompting. We present an overview of participants' approaches and evaluate them\non a new reference-free test set spanning three language pairs for MT and a\nsummarization dataset. Notably, despite the task's restrictions, the\nbest-performing systems achieve results on par with or even surpassing recent\nreference-free metrics developed using larger models, including GEMBA and\nComet-Kiwi-XXL. Finally, as a separate track, we perform a small-scale human\nevaluation of the plausibility of explanations given by the LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.19792"
            },
            {
                "文章ID": "105613",
                "标题": "All Languages Matter: On the Multilingual Safety of Large Language\n  Models",
                "作者": " Wenxuan Wang,  Zhaopeng Tu,  Chang Chen,  Youliang Yuan,  Jen-tse Huang,  Wenxiang Jiao,  Michael R. Lyu",
                "发布日期": "2023-10-03",
                "摘要": "  Safety lies at the core of developing and deploying large language models\n(LLMs). However, previous safety benchmarks only concern the safety in one\nlanguage, e.g. the majority language in the pretraining data such as English.\nIn this work, we build the first multilingual safety benchmark for LLMs,\nXSafety, in response to the global deployment of LLMs in practice. XSafety\ncovers 14 kinds of commonly used safety issues across 10 languages that span\nseveral language families. We utilize XSafety to empirically study the\nmultilingual safety for 4 widely-used LLMs, including both close-API and\nopen-source models. Experimental results show that all LLMs produce\nsignificantly more unsafe responses for non-English queries than English ones,\nindicating the necessity of developing safety alignment for non-English\nlanguages. In addition, we propose several simple and effective prompting\nmethods to improve the multilingual safety of ChatGPT by evoking safety\nknowledge and improving cross-lingual generalization of safety alignment. Our\nprompting method can significantly reduce the ratio of unsafe responses from\n19.1% to 9.7% for non-English queries. We release our data at\nhttps://github.com/Jarviswang94/Multilingual_safety_benchmark.\n",
                "链接": "https://arxiv.org/abs/2310.00905"
            },
            {
                "文章ID": "113446",
                "标题": "The Behavior of Large Language Models When Prompted to Generate Code\n  Explanations",
                "作者": " Priti Oli,  Rabin Banjade,  Jeevan Chapagain,  Vasile Rus",
                "发布日期": "2023-11-13",
                "摘要": "  This paper systematically investigates the generation of code explanations by\nLarge Language Models (LLMs) for code examples commonly encountered in\nintroductory programming courses. Our findings reveal significant variations in\nthe nature of code explanations produced by LLMs, influenced by factors such as\nthe wording of the prompt, the specific code examples under consideration, the\nprogramming language involved, the temperature parameter, and the version of\nthe LLM. However, a consistent pattern emerges for Java and Python, where\nexplanations exhibit a Flesch-Kincaid readability level of approximately 7-8\ngrade and a consistent lexical density, indicating the proportion of meaningful\nwords relative to the total explanation size. Additionally, the generated\nexplanations consistently achieve high scores for correctness, but lower scores\non three other metrics: completeness, conciseness, and specificity.\n",
                "链接": "https://arxiv.org/abs/2311.01490"
            },
            {
                "文章ID": "71061",
                "标题": "ChatGPT for Shaping the Future of Dentistry: The Potential of\n  Multi-Modal Large Language Model",
                "作者": " Hanyao Huang,  Ou Zheng,  Dongdong Wang,  Jiayi Yin,  Zijin Wang,  Shengxuan Ding,  Heng Yin,  Chuan Xu,  Renjie Yang,  Qian Zheng,  Bing Shi",
                "发布日期": "2023-08-01",
                "摘要": "  The ChatGPT, a lite and conversational variant of Generative Pretrained\nTransformer 4 (GPT-4) developed by OpenAI, is one of the milestone Large\nLanguage Models (LLMs) with billions of parameters. LLMs have stirred up much\ninterest among researchers and practitioners in their impressive skills in\nnatural language processing tasks, which profoundly impact various fields. This\npaper mainly discusses the future applications of LLMs in dentistry. We\nintroduce two primary LLM deployment methods in dentistry, including automated\ndental diagnosis and cross-modal dental diagnosis, and examine their potential\napplications. Especially, equipped with a cross-modal encoder, a single LLM can\nmanage multi-source data and conduct advanced natural language reasoning to\nperform complex clinical operations. We also present cases to demonstrate the\npotential of a fully automatic Multi-Modal LLM AI system for dentistry clinical\napplication. While LLMs offer significant potential benefits, the challenges,\nsuch as data privacy, data quality, and model bias, need further study.\nOverall, LLMs have the potential to revolutionize dental diagnosis and\ntreatment, which indicates a promising avenue for clinical application and\nresearch in dentistry.\n",
                "链接": "https://arxiv.org/abs/2304.03086"
            },
            {
                "文章ID": "121390",
                "标题": "Understanding the Effect of Model Compression on Social Bias in Large\n  Language Models",
                "作者": " Gustavo Gonçalves,  Emma Strubell",
                "发布日期": "2023-12-13",
                "摘要": "  Large Language Models (LLMs) trained with self-supervision on vast corpora of\nweb text fit to the social biases of that text. Without intervention, these\nsocial biases persist in the model's predictions in downstream tasks, leading\nto representational harm. Many strategies have been proposed to mitigate the\neffects of inappropriate social biases learned during pretraining.\nSimultaneously, methods for model compression have become increasingly popular\nto reduce the computational burden of LLMs. Despite the popularity and need for\nboth approaches, little work has been done to explore the interplay between\nthese two. We perform a carefully controlled study of the impact of model\ncompression via quantization and knowledge distillation on measures of social\nbias in LLMs. Longer pretraining and larger models led to higher social bias,\nand quantization showed a regularizer effect with its best trade-off around 20%\nof the original pretraining time.\n",
                "链接": "https://arxiv.org/abs/2312.05662"
            },
            {
                "文章ID": "97206",
                "标题": "On the Unexpected Abilities of Large Language Models",
                "作者": " Stefano Nolfi",
                "发布日期": "2023-12-19",
                "摘要": "  Large Language Models (LLMs) are capable of displaying a wide range of\nabilities that are not directly connected with the task for which they are\ntrained: predicting the next words of human-written texts. In this article, I\nreview recent research investigating the cognitive abilities developed by LLMs\nand their relation to human cognition. I discuss the nature of the indirect\nprocess that leads to the acquisition of these cognitive abilities, their\nrelation to other indirect processes, and the implications for the acquisition\nof integrated abilities. Moreover, I propose the factors that enable the\ndevelopment of abilities that are related only very indirectly to the proximal\nobjective of the training task. Finally, I discuss whether the full set of\ncapabilities that LLMs could possibly develop is predictable.\n",
                "链接": "https://arxiv.org/abs/2308.09720"
            },
            {
                "文章ID": "122703",
                "标题": "Perspectives on the State and Future of Deep Learning - 2023",
                "作者": " Micah Goldblum,  Anima Anandkumar,  Richard Baraniuk,  Tom Goldstein,  Kyunghyun Cho,  Zachary C Lipton,  Melanie Mitchell,  Preetum Nakkiran,  Max Welling,  Andrew Gordon Wilson",
                "发布日期": "2023-12-20",
                "摘要": "  The goal of this series is to chronicle opinions and issues in the field of\nmachine learning as they stand today and as they change over time. The plan is\nto host this survey periodically until the AI singularity\npaperclip-frenzy-driven doomsday, keeping an updated list of topical questions\nand interviewing new community members for each edition. In this issue, we\nprobed people's opinions on interpretable AI, the value of benchmarking in\nmodern NLP, the state of progress towards understanding deep learning, and the\nfuture of academia.\n",
                "链接": "https://arxiv.org/abs/2312.09323"
            },
            {
                "文章ID": "105449",
                "标题": "From Language Modeling to Instruction Following: Understanding the\n  Behavior Shift in LLMs after Instruction Tuning",
                "作者": " Xuansheng Wu,  Wenlin Yao,  Jianshu Chen,  Xiaoman Pan,  Xiaoyang Wang,  Ninghao Liu,  Dong Yu",
                "发布日期": "2023-10-03",
                "摘要": "  Large Language Models (LLMs) have achieved remarkable success, demonstrating\npowerful instruction-following capabilities across diverse tasks. Instruction\nfine-tuning is critical in enabling LLMs to align with user intentions and\neffectively follow instructions. In this work, we investigate how instruction\nfine-tuning modifies pre-trained models, focusing on two perspectives:\ninstruction recognition and knowledge evolution. To study the behavior shift of\nLLMs, we employ a suite of local and global explanation methods, including a\ngradient-based approach for input-output attribution and techniques for\ninterpreting patterns and concepts in self-attention and feed-forward layers.\nOur findings reveal three significant impacts of instruction fine-tuning: 1) It\nempowers LLMs to better recognize the instruction parts from user prompts,\nthereby facilitating high-quality response generation and addressing the\n``lost-in-the-middle'' issue observed in pre-trained models; 2) It aligns the\nknowledge stored in feed-forward layers with user-oriented tasks, exhibiting\nminimal shifts across linguistic levels. 3) It facilitates the learning of\nword-word relations with instruction verbs through the self-attention\nmechanism, particularly in the lower and middle layers, indicating enhanced\nrecognition of instruction words. These insights contribute to a deeper\nunderstanding of the behavior shifts in LLMs after instruction fine-tuning and\nlay the groundwork for future research aimed at interpreting and optimizing\nLLMs for various applications. We will release our code and data soon.\n",
                "链接": "https://arxiv.org/abs/2310.00492"
            },
            {
                "文章ID": "111732",
                "标题": "CompeteAI: Understanding the Competition Behaviors in Large Language\n  Model-based Agents",
                "作者": " Qinlin Zhao,  Jindong Wang,  Yixuan Zhang,  Yiqiao Jin,  Kaijie Zhu,  Hao Chen,  Xing Xie",
                "发布日期": "2023-10-27",
                "摘要": "  Large language models (LLMs) have been widely used as agents to complete\ndifferent tasks, such as personal assistance or event planning. While most work\nhas focused on cooperation and collaboration between agents, little work\nexplores competition, another important mechanism that fosters the development\nof society and economy. In this paper, we seek to examine the competition\nbehaviors in LLM-based agents. We first propose a general framework to study\nthe competition between agents. Then, we implement a practical competitive\nenvironment using GPT-4 to simulate a virtual town with two types of agents,\nincluding restaurant agents and customer agents. Specifically, restaurant\nagents compete with each other to attract more customers, where the competition\nfosters them to transform, such as cultivating new operating strategies. The\nresults of our experiments reveal several interesting findings ranging from\nsocial learning to Matthew Effect, which aligns well with existing sociological\nand economic theories. We believe that competition between agents deserves\nfurther investigation to help us understand society better. The code will be\nreleased soon.\n",
                "链接": "https://arxiv.org/abs/2310.17512"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态大模型理解和生成统一建模、端到端训练相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "21046",
                "标题": "End-to-End Multimodal Fact-Checking and Explanation Generation: A\n  Challenging Dataset and Models",
                "作者": "Virginia Tech  Barry Menglong Yao, Virginia Tech  Aditya Shah, Lehigh University  Lichao Sun, Virginia Tech  Jin-Hee Cho, Virginia Tech  Lifu Huang",
                "发布日期": "2023-07-10",
                "摘要": "  We propose end-to-end multimodal fact-checking and explanation generation,\nwhere the input is a claim and a large collection of web sources, including\narticles, images, videos, and tweets, and the goal is to assess the\ntruthfulness of the claim by retrieving relevant evidence and predicting a\ntruthfulness label (e.g., support, refute or not enough information), and to\ngenerate a statement to summarize and explain the reasoning and ruling process.\nTo support this research, we construct Mocheg, a large-scale dataset consisting\nof 15,601 claims where each claim is annotated with a truthfulness label and a\nruling statement, and 33,880 textual paragraphs and 12,112 images in total as\nevidence. To establish baseline performances on Mocheg, we experiment with\nseveral state-of-the-art neural architectures on the three pipelined subtasks:\nmultimodal evidence retrieval, claim verification, and explanation generation,\nand demonstrate that the performance of the state-of-the-art end-to-end\nmultimodal fact-checking does not provide satisfactory outcomes. To the best of\nour knowledge, we are the first to build the benchmark dataset and solutions\nfor end-to-end multimodal fact-checking and explanation generation. The\ndataset, source code and model checkpoints are available at\nhttps://github.com/VT-NLP/Mocheg.\n",
                "链接": "https://arxiv.org/abs/2205.12487"
            },
            {
                "文章ID": "12682",
                "标题": "End-to-end Document Recognition and Understanding with Dessurt",
                "作者": " Brian Davis,  Bryan Morse,  Bryan Price,  Chris Tensmeyer,  Curtis Wigington,  Vlad Morariu",
                "发布日期": "2022-06-17",
                "摘要": "  We introduce Dessurt, a relatively simple document understanding transformer\ncapable of being fine-tuned on a greater variety of document tasks than prior\nmethods. It receives a document image and task string as input and generates\narbitrary text autoregressively as output. Because Dessurt is an end-to-end\narchitecture that performs text recognition in addition to the document\nunderstanding, it does not require an external recognition model as prior\nmethods do. Dessurt is a more flexible model than prior methods and is able to\nhandle a variety of document domains and tasks. We show that this model is\neffective at 9 different dataset-task combinations.\n",
                "链接": "https://arxiv.org/abs/2203.16618"
            },
            {
                "文章ID": "75571",
                "标题": "End-to-end Training and Decoding for Pivot-based Cascaded Translation\n  Model",
                "作者": " Hao Cheng,  Meng Zhang,  Liangyou Li,  Qun Liu,  Zhihua Zhang",
                "发布日期": "2023-05-04",
                "摘要": "  Utilizing pivot language effectively can significantly improve low-resource\nmachine translation. Usually, the two translation models, source-pivot and\npivot-target, are trained individually and do not utilize the limited (source,\ntarget) parallel data. This work proposes an end-to-end training method for the\ncascaded translation model and configures an improved decoding algorithm. The\ninput of the pivot-target model is modified to weighted pivot embedding based\non the probability distribution output by the source-pivot model. This allows\nthe model to be trained end-to-end. In addition, we mitigate the inconsistency\nbetween tokens and probability distributions while using beam search in pivot\ndecoding. Experiments demonstrate that our method enhances the quality of\ntranslation.\n",
                "链接": "https://arxiv.org/abs/2305.02261"
            },
            {
                "文章ID": "62000",
                "标题": "JEIT: Joint End-to-End Model and Internal Language Model Training for\n  Speech Recognition",
                "作者": " Zhong Meng,  Weiran Wang,  Rohit Prabhavalkar,  Tara N. Sainath,  Tongzhou Chen,  Ehsan Variani,  Yu Zhang,  Bo Li,  Andrew Rosenberg,  Bhuvana Ramabhadran",
                "发布日期": "2023-02-20",
                "摘要": "  We propose JEIT, a joint end-to-end (E2E) model and internal language model\n(ILM) training method to inject large-scale unpaired text into ILM during E2E\ntraining which improves rare-word speech recognition. With JEIT, the E2E model\ncomputes an E2E loss on audio-transcript pairs while its ILM estimates a\ncross-entropy loss on unpaired text. The E2E model is trained to minimize a\nweighted sum of E2E and ILM losses. During JEIT, ILM absorbs knowledge from\nunpaired text while the E2E training serves as regularization. Unlike ILM\nadaptation methods, JEIT does not require a separate adaptation step and avoids\nthe need for Kullback-Leibler divergence regularization of ILM. We also show\nthat modular hybrid autoregressive transducer (MHAT) performs better than HAT\nin the JEIT framework, and is much more robust than HAT during ILM adaptation.\nTo push the limit of unpaired text injection, we further propose a combined\nJEIT and JOIST training (CJJT) that benefits from modality matching, encoder\ntext injection and ILM training. Both JEIT and CJJT can foster a more effective\nLM fusion. With 100B unpaired sentences, JEIT/CJJT improves rare-word\nrecognition accuracy by up to 16.4% over a model trained without unpaired text.\n",
                "链接": "https://arxiv.org/abs/2302.08583"
            },
            {
                "文章ID": "94301",
                "标题": "Interpretable End-to-End Driving Model for Implicit Scene Understanding",
                "作者": " Yiyang Sun,  Xiaonian Wang,  Yangyang Zhang,  Jiagui Tang,  Xiaqiang Tang,  Jing Yao",
                "发布日期": "2023-08-03",
                "摘要": "  Driving scene understanding is to obtain comprehensive scene information\nthrough the sensor data and provide a basis for downstream tasks, which is\nindispensable for the safety of self-driving vehicles. Specific perception\ntasks, such as object detection and scene graph generation, are commonly used.\nHowever, the results of these tasks are only equivalent to the characterization\nof sampling from high-dimensional scene features, which are not sufficient to\nrepresent the scenario. In addition, the goal of perception tasks is\ninconsistent with human driving that just focuses on what may affect the\nego-trajectory. Therefore, we propose an end-to-end Interpretable Implicit\nDriving Scene Understanding (II-DSU) model to extract implicit high-dimensional\nscene features as scene understanding results guided by a planning module and\nto validate the plausibility of scene understanding using auxiliary perception\ntasks for visualization. Experimental results on CARLA benchmarks show that our\napproach achieves the new state-of-the-art and is able to obtain scene features\nthat embody richer scene information relevant to driving, enabling superior\nperformance of the downstream planning.\n",
                "链接": "https://arxiv.org/abs/2308.01180"
            },
            {
                "文章ID": "12174",
                "标题": "Towards End-to-End Unified Scene Text Detection and Layout Analysis",
                "作者": " Shangbang Long,  Siyang Qin,  Dmitry Panteleev,  Alessandro Bissacco,  Yasuhisa Fujii,  Michalis Raptis",
                "发布日期": "2022-06-06",
                "摘要": "  Scene text detection and document layout analysis have long been treated as\ntwo separate tasks in different image domains. In this paper, we bring them\ntogether and introduce the task of unified scene text detection and layout\nanalysis. The first hierarchical scene text dataset is introduced to enable\nthis novel research task. We also propose a novel method that is able to\nsimultaneously detect scene text and form text clusters in a unified way.\nComprehensive experiments show that our unified model achieves better\nperformance than multiple well-designed baseline methods. Additionally, this\nmodel achieves state-of-the-art results on multiple scene text detection\ndatasets without the need of complex post-processing. Dataset and code:\nhttps://github.com/google-research-datasets/hiertext and\nhttps://github.com/tensorflow/models/tree/master/official/projects/unified_detector.\n",
                "链接": "https://arxiv.org/abs/2203.15143"
            },
            {
                "文章ID": "122514",
                "标题": "Planning and Rendering: Towards End-to-End Product Poster Generation",
                "作者": " Zhaochen Li,  Fengheng Li,  Wei Feng,  Honghe Zhu,  An Liu,  Yaoyu Li,  Zheng Zhang,  Jingjing Lv,  Xin Zhu,  Junjie Shen,  Zhangang Lin,  Jingping Shao,  Zhenglu Yang",
                "发布日期": "2023-12-15",
                "摘要": "  End-to-end product poster generation significantly optimizes design\nefficiency and reduces production costs. Prevailing methods predominantly rely\non image-inpainting methods to generate clean background images for given\nproducts. Subsequently, poster layout generation methods are employed to\nproduce corresponding layout results. However, the background images may not be\nsuitable for accommodating textual content due to their complexity, and the\nfixed location of products limits the diversity of layout results. To alleviate\nthese issues, we propose a novel product poster generation framework named\nP\\&R. The P\\&R draws inspiration from the workflow of designers in creating\nposters, which consists of two stages: Planning and Rendering. At the planning\nstage, we propose a PlanNet to generate the layout of the product and other\nvisual components considering both the appearance features of the product and\nsemantic features of the text, which improves the diversity and rationality of\nthe layouts. At the rendering stage, we propose a RenderNet to generate the\nbackground for the product while considering the generated layout, where a\nspatial fusion module is introduced to fuse the layout of different visual\ncomponents. To foster the advancement of this field, we propose the first\nend-to-end product poster generation dataset PPG30k, comprising 30k exquisite\nproduct poster images along with comprehensive image and text annotations. Our\nmethod outperforms the state-of-the-art product poster generation methods on\nPPG30k. The PPG30k will be released soon.\n",
                "链接": "https://arxiv.org/abs/2312.08822"
            },
            {
                "文章ID": "92569",
                "标题": "Modality Confidence Aware Training for Robust End-to-End Spoken Language\n  Understanding",
                "作者": " Suyoun Kim,  Akshat Shrivastava,  Duc Le,  Ju Lin,  Ozlem Kalinli,  Michael L. Seltzer",
                "发布日期": "2023-07-25",
                "摘要": "  End-to-end (E2E) spoken language understanding (SLU) systems that generate a\nsemantic parse from speech have become more promising recently. This approach\nuses a single model that utilizes audio and text representations from\npre-trained speech recognition models (ASR), and outperforms traditional\npipeline SLU systems in on-device streaming scenarios. However, E2E SLU systems\nstill show weakness when text representation quality is low due to ASR\ntranscription errors. To overcome this issue, we propose a novel E2E SLU system\nthat enhances robustness to ASR errors by fusing audio and text representations\nbased on the estimated modality confidence of ASR hypotheses. We introduce two\nnovel techniques: 1) an effective method to encode the quality of ASR\nhypotheses and 2) an effective approach to integrate them into E2E SLU models.\nWe show accuracy improvements on STOP dataset and share the analysis to\ndemonstrate the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2307.12134"
            },
            {
                "文章ID": "118545",
                "标题": "GPT4Video: A Unified Multimodal Large Language Model for\n  lnstruction-Followed Understanding and Safety-Aware Generation",
                "作者": " Zhanyu Wang,  Longyue Wang,  Zhen Zhao,  Minghao Wu,  Chenyang Lyu,  Huayang Li,  Deng Cai,  Luping Zhou,  Shuming Shi,  Zhaopeng Tu",
                "发布日期": "2023-11-29",
                "摘要": "  While the recent advances in Multimodal Large Language Models (MLLMs)\nconstitute a significant leap forward in the field, these models are\npredominantly confined to the realm of input-side multimodal comprehension,\nlacking the capacity for multimodal content generation. To fill this gap, we\npresent GPT4Video, a unified multi-model framework that empowers Large Language\nModels (LLMs) with the capability of both video understanding and generation.\nSpecifically, we develop an instruction-following-based approach integrated\nwith the stable diffusion generative model, which has demonstrated to\neffectively and securely handle video generation scenarios. GPT4Video offers\nthe following benefits: 1) It exhibits impressive capabilities in both video\nunderstanding and generation scenarios. For example, GPT4Video outperforms\nValley by 11.8\\% on the Video Question Answering task, and surpasses NExt-GPT\nby 2.3\\% on the Text to Video generation task. 2) it endows the LLM/MLLM with\nvideo generation capabilities without requiring additional training parameters\nand can flexibly interface with a wide range of models to perform video\ngeneration. 3) it maintains a safe and healthy conversation not only in\noutput-side but also the input side in an end-to-end manner. Qualitative and\nqualitative experiments demonstrate that GPT4Video holds the potential to\nfunction as a effective, safe and Humanoid-like video assistant that can handle\nboth video understanding and generation scenarios.\n",
                "链接": "https://arxiv.org/abs/2311.16511"
            },
            {
                "文章ID": "46362",
                "标题": "Unified End-to-End Speech Recognition and Endpointing for Fast and\n  Efficient Speech Systems",
                "作者": " Shaan Bijwadia,  Shuo-yiin Chang,  Bo Li,  Tara Sainath,  Chao Zhang,  Yanzhang He",
                "发布日期": "2023-02-16",
                "摘要": "  Automatic speech recognition (ASR) systems typically rely on an external\nendpointer (EP) model to identify speech boundaries. In this work, we propose a\nmethod to jointly train the ASR and EP tasks in a single end-to-end (E2E)\nmultitask model, improving EP quality by optionally leveraging information from\nthe ASR audio encoder. We introduce a \"switch\" connection, which trains the EP\nto consume either the audio frames directly or low-level latent representations\nfrom the ASR model. This results in a single E2E model that can be used during\ninference to perform frame filtering at low cost, and also make high quality\nend-of-query (EOQ) predictions based on ongoing ASR computation. We present\nresults on a voice search test set showing that, compared to separate\nsingle-task models, this approach reduces median endpoint latency by 120 ms\n(30.8% reduction), and 90th percentile latency by 170 ms (23.0% reduction),\nwithout regressing word error rate. For continuous recognition, WER improves by\n10.6% (relative).\n",
                "链接": "https://arxiv.org/abs/2211.00786"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近两年关于语言模型奖励建模评估的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "29176",
                "标题": "Visualizing Gender Gap in Film Industry over the Past 100 Years",
                "作者": " Junkai Man,  Ruitian Wu,  Chenglin Zhang,  Xin Tong",
                "发布日期": "2022-07-15",
                "摘要": "  Visualizing big data can provide valuable insights into social science\nresearch. In this project, we focused on visualizing the potential gender gap\nin the global film industry over the past 100 years. We profiled the\ndifferences both for the actors/actresses and male/female movie audiences and\nanalyzed the IMDb data of the most popular 10,000 movies (the composition and\nimportance of casts of different genders, the cooperation network of the\nactors/actresses, the movie genres, the movie descriptions, etc.) and audience\nratings (the differences between male's and female's ratings). Findings suggest\nthat the gender gap has been distinct in many aspects, but a recent trend is\nthat this gap narrows down and women are gaining discursive power in the film\nindustry. Our study presented rich data, vivid illustrations, and novel\nperspectives that can serve as the foundation for further studies on related\ntopics and their social implications.\n",
                "链接": "https://arxiv.org/abs/2207.06692"
            },
            {
                "文章ID": "82232",
                "标题": "Visual Exploratory Data Analysis of the Covid-19 Pandemic in Nigeria:\n  Two Years after the Outbreak",
                "作者": " Ugochukwu Orji,  Modesta Ezema,  Elochukwu Ukwandu,  Chikaodili Ugwuishiwu,  Ezugwu Obianuju,  Malachi Egbugha",
                "发布日期": "2023-06-04",
                "摘要": "  The outbreak of the coronavirus disease in Nigeria and all over the world in\n2019/2020 caused havoc on the world's economy and put a strain on global\nhealthcare facilities and personnel. It also threw up many opportunities to\nimprove processes using artificial intelligence techniques like big data\nanalytics and business intelligence. The need to speedily make decisions that\ncould have far-reaching effects is prompting the boom in data analytics which\nis achieved via exploratory data analysis (EDA) to see trends, patterns, and\nrelationships in the data. Today, big data analytics is revolutionizing\nprocesses and helping improve productivity and decision-making capabilities in\nall aspects of life. The large amount of heterogeneous and, in most cases,\nopaque data now available has made it possible for researchers and businesses\nof all sizes to effectively deploy data analytics to gain action-oriented\ninsights into various problems in real time. In this paper, we deployed\nMicrosoft Excel and Python to perform EDA of the covid-19 pandemic data in\nNigeria and presented our results via visualizations and a dashboard using\nTableau. The dataset is from the Nigeria Centre for Disease Control (NCDC)\nrecorded between February 28th, 2020, and July 19th, 2022. This paper aims to\nfollow the data and visually show the trends over the past 2 years and also\nshow the powerful capabilities of these data analytics tools and techniques.\nFurthermore, our findings contribute to the current literature on Covid-19\nresearch by showcasing how the virus has progressed in Nigeria over time and\nthe insights thus far.\n",
                "链接": "https://arxiv.org/abs/2305.19297"
            },
            {
                "文章ID": "6241",
                "标题": "Reward Modeling for Mitigating Toxicity in Transformer-based Language\n  Models",
                "作者": " Farshid Faal,  Ketra Schmitt,  Jia Yuan Yu",
                "发布日期": "2022-07-28",
                "摘要": "  Transformer-based language models are able to generate fluent text and be\nefficiently adapted across various natural language generation tasks. However,\nlanguage models that are pretrained on large unlabeled web text corpora have\nbeen shown to suffer from degenerating toxic content and social bias behaviors,\nconsequently hindering their safe deployment. Various detoxification methods\nwere proposed to mitigate the language model's toxicity; however, these methods\nstruggled to detoxify language models when conditioned on prompts that contain\nspecific social identities related to gender, race, or religion. In this study,\nwe propose Reinforce-Detoxify; A reinforcement learning-based method for\nmitigating toxicity in language models. We address the challenge of safety in\nlanguage models and propose a new reward model that is able to detect toxic\ncontent and mitigate unintended bias towards social identities in toxicity\nprediction. The experiments demonstrate that the Reinforce-Detoxify method for\nlanguage model detoxification outperforms existing detoxification approaches in\nautomatic evaluation metrics, indicating the ability of our approach in\nlanguage model detoxification and less prone to unintended bias toward social\nidentities in generated content.\n",
                "链接": "https://arxiv.org/abs/2202.09662"
            },
            {
                "文章ID": "99245",
                "标题": "Two Hundred Years After Hamilton: The Simple Axiom That Underlies\n  Classical Mechanics",
                "作者": " David J. Tannor",
                "发布日期": "2023-08-30",
                "摘要": "  In 1834-1835, Hamilton published two papers that revolutionized classical\nmechanics. In these papers, he introduced the Hamilton-Jacobi equation,\nHamilton's equations of motion and the principle of least action. These three\nformulations of classical mechanics became the forerunners of quantum\nmechanics, but none of these is what Hamilton was looking for: he was looking\nfor what he called the principal function, $S(q',q'',T)$, from which the entire\ntrajectory history can be obtained just by differentiation. Here we show that\nall of Hamilton's formulations can be derived just by assuming that the\nprincipal function is additive, $S(q',q'',T)=S(q',Q,t_1)+S(Q,q'',t_2)$ with\n$t_1+t_2=T$. This simple additivity axiom can be considered the fundamental\nprinciple of classical mechanics and shows that analytical mechanics is\nessentially just a footnote to the problem of finding the shortest path between\ntwo points. The simplicity of the formulation could provide new perspectives on\nsome of the major themes in classical mechanics including symplectic geometry,\nperiodic orbit theory and Morse theory, as well as giving new perspectives on\nquantum mechanics. Moreover, it could potentially provide a unified description\nof different areas of physics, leading to insight for example, into the\ntransition from deterministic dynamics to statistical mechanics.\n",
                "链接": "https://arxiv.org/abs/2308.15369"
            },
            {
                "文章ID": "64695",
                "标题": "Topic Modeling Based on Two-Step Flow Theory: Application to Tweets\n  about Bitcoin",
                "作者": " Aos Mulahuwaish,  Matthew Loucks,  Basheer Qolomany,  Ala Al-Fuqaha",
                "发布日期": "2023-03-06",
                "摘要": "  Digital cryptocurrencies such as Bitcoin have exploded in recent years in\nboth popularity and value. By their novelty, cryptocurrencies tend to be both\nvolatile and highly speculative. The capricious nature of these coins is helped\nfacilitated by social media networks such as Twitter. However, not everyone's\nopinion matters equally, with most posts garnering little to no attention.\nAdditionally, the majority of tweets are retweeted from popular posts. We must\ndetermine whose opinion matters and the difference between influential and\nnon-influential users. This study separates these two groups and analyzes the\ndifferences between them. It uses Hypertext-induced Topic Selection (HITS)\nalgorithm, which segregates the dataset based on influence. Topic modeling is\nthen employed to uncover differences in each group's speech types and what\ngroup may best represent the entire community. We found differences in language\nand interest between these two groups regarding Bitcoin and that the opinion\nleaders of Twitter are not aligned with the majority of users. There were 2559\nopinion leaders (0.72% of users) who accounted for 80% of the authority and the\nmajority (99.28%) users for the remaining 20% out of a total of 355,139 users.\n",
                "链接": "https://arxiv.org/abs/2303.02032"
            },
            {
                "文章ID": "39421",
                "标题": "Argumentative Reward Learning: Reasoning About Human Preferences",
                "作者": " Francis Rhys Ward,  Francesco Belardinelli,  Francesca Toni",
                "发布日期": "2022-10-05",
                "摘要": "  We define a novel neuro-symbolic framework, argumentative reward learning,\nwhich combines preference-based argumentation with existing approaches to\nreinforcement learning from human feedback. Our method improves prior work by\ngeneralising human preferences, reducing the burden on the user and increasing\nthe robustness of the reward model. We demonstrate this with a number of\nexperiments.\n",
                "链接": "https://arxiv.org/abs/2209.14010"
            },
            {
                "文章ID": "73751",
                "标题": "Transformer-Based Language Model Surprisal Predicts Human Reading Times\n  Best with About Two Billion Training Tokens",
                "作者": " Byung-Doh Oh,  William Schuler",
                "发布日期": "2023-10-24",
                "摘要": "  Recent psycholinguistic studies have drawn conflicting conclusions about the\nrelationship between the quality of a language model and the ability of its\nsurprisal estimates to predict human reading times, which has been speculated\nto be due to the large gap in both the amount of training data and model\ncapacity across studies. The current work aims to consolidate these findings by\nevaluating surprisal estimates from Transformer-based language model variants\nthat vary systematically in the amount of training data and model capacity on\ntheir ability to predict human reading times. The results show that surprisal\nestimates from most variants with contemporary model capacities provide the\nbest fit after seeing about two billion training tokens, after which they begin\nto diverge from humanlike expectations. Additionally, newly-trained smaller\nmodel variants reveal a 'tipping point' at convergence, after which the\ndecrease in language model perplexity begins to result in poorer fits to human\nreading times. These results suggest that the massive amount of training data\nis mainly responsible for the poorer fit achieved by surprisal from larger\npre-trained language models, and that a certain degree of model capacity is\nnecessary for Transformer-based language models to capture humanlike\nexpectations.\n",
                "链接": "https://arxiv.org/abs/2304.11389"
            },
            {
                "文章ID": "42460",
                "标题": "Spontaneous Emerging Preference in Two-tower Language Model",
                "作者": " Zhengqi He,  Taro Toyoizumi",
                "发布日期": "2022-10-14",
                "摘要": "  The ever-growing size of the foundation language model has brought\nsignificant performance gains in various types of downstream tasks. With the\nexistence of side-effects brought about by the large size of the foundation\nlanguage model such as deployment cost, availability issues, and environmental\ncost, there is some interest in exploring other possible directions, such as a\ndivide-and-conquer scheme. In this paper, we are asking a basic question: are\nlanguage processes naturally dividable? We study this problem with a simple\ntwo-tower language model setting, where two language models with identical\nconfigurations are trained side-by-side cooperatively. With this setting, we\ndiscover the spontaneous emerging preference phenomenon, where some of the\ntokens are consistently better predicted by one tower while others by another\ntower. This phenomenon is qualitatively stable, regardless of model\nconfiguration and type, suggesting this as an intrinsic property of natural\nlanguage. This study suggests that interesting properties of natural language\nare still waiting to be discovered, which may aid the future development of\nnatural language processing techniques.\n",
                "链接": "https://arxiv.org/abs/2210.07041"
            },
            {
                "文章ID": "26084",
                "标题": "Backward baselines: Is your model predicting the past?",
                "作者": " Moritz Hardt,  Michael P. Kim",
                "发布日期": "2022-06-24",
                "摘要": "  When does a machine learning model predict the future of individuals and when\ndoes it recite patterns that predate the individuals? In this work, we propose\na distinction between these two pathways of prediction, supported by\ntheoretical, empirical, and normative arguments. At the center of our proposal\nis a family of simple and efficient statistical tests, called backward\nbaselines, that demonstrate if, and to which extent, a model recounts the past.\nOur statistical theory provides guidance for interpreting backward baselines,\nestablishing equivalences between different baselines and familiar statistical\nconcepts. Concretely, we derive a meaningful backward baseline for auditing a\nprediction system as a black box, given only background variables and the\nsystem's predictions. Empirically, we evaluate the framework on different\nprediction tasks derived from longitudinal panel surveys, demonstrating the\nease and effectiveness of incorporating backward baselines into the practice of\nmachine learning.\n",
                "链接": "https://arxiv.org/abs/2206.11673"
            },
            {
                "文章ID": "47794",
                "标题": "Nano: Nested Human-in-the-Loop Reward Learning for Few-shot Language\n  Model Control",
                "作者": " Xiang Fan,  Yiwei Lyu,  Paul Pu Liang,  Ruslan Salakhutdinov,  Louis-Philippe Morency",
                "发布日期": "2023-09-26",
                "摘要": "  Pretrained language models have demonstrated extraordinary capabilities in\nlanguage generation. However, real-world tasks often require controlling the\ndistribution of generated text in order to mitigate bias, promote fairness, and\nachieve personalization. Existing techniques for controlling the distribution\nof generated text only work with quantified distributions, which require\npre-defined categories, proportions of the distribution, or an existing corpus\nfollowing the desired distributions. However, many important distributions,\nsuch as personal preferences, are unquantified. In this work, we tackle the\nproblem of generating text following arbitrary distributions (quantified and\nunquantified) by proposing Nano, a few-shot human-in-the-loop training\nalgorithm that continuously learns from human feedback. Nano achieves\nstate-of-the-art results on single topic/attribute as well as quantified\ndistribution control compared to previous works. We also show that Nano is able\nto learn unquantified distributions, achieves personalization, and captures\ndifferences between different individuals' personal preferences with high\nsample efficiency.\n",
                "链接": "https://arxiv.org/abs/2211.05750"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到从位置编码角度改善模型长序列建模能力的相关论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "9782",
                "标题": "Efficient Long Sequence Encoding via Synchronization",
                "作者": " Xiangyang Mou,  Mo Yu,  Bingsheng Yao,  Lifu Huang",
                "发布日期": "2022-03-16",
                "摘要": "  Pre-trained Transformer models have achieved successes in a wide range of NLP\ntasks, but are inefficient when dealing with long input sequences. Existing\nstudies try to overcome this challenge via segmenting the long sequence\nfollowed by hierarchical encoding or post-hoc aggregation. We propose a\nsynchronization mechanism for hierarchical encoding. Our approach first\nidentifies anchor tokens across segments and groups them by their roles in the\noriginal input sequence. Then inside Transformer layer, anchor embeddings are\nsynchronized within their group via a self-attention module. Our approach is a\ngeneral framework with sufficient flexibility -- when adapted to a new task, it\nis easy to be enhanced with the task-specific anchor definitions. Experiments\non two representative tasks with different types of long input texts,\nNarrativeQA summary setting and wild multi-hop reasoning from HotpotQA,\ndemonstrate that our approach is able to improve the global information\nexchange among segments while maintaining efficiency.\n",
                "链接": "https://arxiv.org/abs/2203.07644"
            },
            {
                "文章ID": "40615",
                "标题": "WavSpA: Wavelet Space Attention for Boosting Transformers' Long Sequence\n  Learning Ability",
                "作者": " Yufan Zhuang,  Zihan Wang,  Fangbo Tao,  Jingbo Shang",
                "发布日期": "2023-05-24",
                "摘要": "  Transformer and its variants are fundamental neural architectures in deep\nlearning. Recent works show that learning attention in the Fourier space can\nimprove the long sequence learning capability of Transformers. We argue that\nwavelet transform shall be a better choice because it captures both position\nand frequency information with linear time complexity. Therefore, in this\npaper, we systematically study the synergy between wavelet transform and\nTransformers. We propose Wavelet Space Attention (WavSpA) that facilitates\nattention learning in a learnable wavelet coefficient space which replaces the\nattention in Transformers by (1) applying forward wavelet transform to project\nthe input sequences to multi-resolution bases, (2) conducting attention\nlearning in the wavelet coefficient space, and (3) reconstructing the\nrepresentation in input space via backward wavelet transform. Extensive\nexperiments on the Long Range Arena demonstrate that learning attention in the\nwavelet space using either fixed or adaptive wavelets can consistently improve\nTransformer's performance and also significantly outperform learning in Fourier\nspace. We further show our method can enhance Transformer's reasoning\nextrapolation capability over distance on the LEGO chain-of-reasoning task.\n",
                "链接": "https://arxiv.org/abs/2210.01989"
            },
            {
                "文章ID": "6738",
                "标题": "FastRPB: a Scalable Relative Positional Encoding for Long Sequence Tasks",
                "作者": " Maksim Zubkov,  Daniil Gavrilov",
                "发布日期": "2022-02-24",
                "摘要": "  Transformers achieve remarkable performance in various domains, including\nNLP, CV, audio processing, and graph analysis. However, they do not scale well\non long sequence tasks due to their quadratic complexity w.r.t. the inputs\nlength. Linear Transformers were proposed to address this limitation. However,\nthese models have shown weaker performance on the long sequence tasks comparing\nto the original one. In this paper, we explore Linear Transformer models,\nrethinking their two core components. Firstly, we improved Linear Transformer\nwith Shift-Invariant Kernel Function SIKF, which achieve higher accuracy\nwithout loss in speed. Secondly, we introduce FastRPB which stands for Fast\nRelative Positional Bias, which efficiently adds positional information to\nself-attention using Fast Fourier Transformation. FastRPB is independent of the\nself-attention mechanism and can be combined with an original self-attention\nand all its efficient variants. FastRPB has O(N log(N)) computational\ncomplexity, requiring O(N) memory w.r.t. input sequence length N.\n",
                "链接": "https://arxiv.org/abs/2202.11364"
            },
            {
                "文章ID": "15348",
                "标题": "Dynamic Position Encoding for Transformers",
                "作者": " Joyce Zheng,  Mehdi Rezagholizadeh,  Peyman Passban",
                "发布日期": "2022-10-25",
                "摘要": "  Recurrent models have been dominating the field of neural machine translation\n(NMT) for the past few years. Transformers \\citep{vaswani2017attention}, have\nradically changed it by proposing a novel architecture that relies on a\nfeed-forward backbone and self-attention mechanism. Although Transformers are\npowerful, they could fail to properly encode sequential/positional information\ndue to their non-recurrent nature. To solve this problem, position embeddings\nare defined exclusively for each time step to enrich word information. However,\nsuch embeddings are fixed after training regardless of the task and the word\nordering system of the source or target language.\n  In this paper, we propose a novel architecture with new position embeddings\ndepending on the input text to address this shortcoming by taking the order of\ntarget words into consideration. Instead of using predefined position\nembeddings, our solution generates new embeddings to refine each word's\nposition information. Since we do not dictate the position of source tokens and\nlearn them in an end-to-end fashion, we refer to our method as dynamic position\nencoding (DPE). We evaluated the impact of our model on multiple datasets to\ntranslate from English into German, French, and Italian and observed meaningful\nimprovements in comparison to the original Transformer.\n",
                "链接": "https://arxiv.org/abs/2204.08142"
            },
            {
                "文章ID": "106867",
                "标题": "Spherical Position Encoding for Transformers",
                "作者": " Eren Unlu",
                "发布日期": "2023-10-10",
                "摘要": "  Position encoding is the primary mechanism which induces notion of sequential\norder for input tokens in transformer architectures. Even though this\nformulation in the original transformer paper has yielded plausible performance\nfor general purpose language understanding and generation, several new\nframeworks such as Rotary Position Embedding (RoPE) are proposed for further\nenhancement. In this paper, we introduce the notion of \"geotokens\" which are\ninput elements for transformer architectures, each representing an information\nrelated to a geological location. Unlike the natural language the sequential\nposition is not important for the model but the geographical coordinates are.\nIn order to induce the concept of relative position for such a setting and\nmaintain the proportion between the physical distance and distance on embedding\nspace, we formulate a position encoding mechanism based on RoPE architecture\nwhich is adjusted for spherical coordinates.\n",
                "链接": "https://arxiv.org/abs/2310.04454"
            },
            {
                "文章ID": "42698",
                "标题": "CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling",
                "作者": " Jun Zhang,  Shuyang Jiang,  Jiangtao Feng,  Lin Zheng,  Lingpeng Kong",
                "发布日期": "2023-07-04",
                "摘要": "  Transformer has achieved remarkable success in language, image, and speech\nprocessing. Recently, various efficient attention architectures have been\nproposed to improve transformer's efficiency while largely preserving its\nefficacy, especially in modeling long sequences. A widely-used benchmark to\ntest these efficient methods' capability on long-range modeling is Long Range\nArena (LRA). However, LRA only focuses on the standard bidirectional (or\nnoncausal) self attention, and completely ignores cross attentions and\nunidirectional (or causal) attentions, which are equally important to\ndownstream applications. In this paper, we propose Comprehensive Attention\nBenchmark (CAB) under a fine-grained attention taxonomy with four\ndistinguishable attention patterns, namely, noncausal self, causal self,\nnoncausal cross, and causal cross attentions. CAB collects seven real-world\ntasks from different research areas to evaluate efficient attentions under the\nfour attention patterns. Among these tasks, CAB validates efficient attentions\nin eight backbone networks to show their generalization across neural\narchitectures. We conduct exhaustive experiments to benchmark the performances\nof nine widely-used efficient attention architectures designed with different\nphilosophies on CAB. Extensive experimental results also shed light on the\nfundamental problems of efficient attentions, such as efficiency length against\nvanilla attention, performance consistency across attention patterns, the\nbenefit of attention mechanisms, and interpolation/extrapolation on\nlong-context language modeling.\n",
                "链接": "https://arxiv.org/abs/2210.07661"
            },
            {
                "文章ID": "61456",
                "标题": "Simple Hardware-Efficient Long Convolutions for Sequence Modeling",
                "作者": " Daniel Y. Fu,  Elliot L. Epstein,  Eric Nguyen,  Armin W. Thomas,  Michael Zhang,  Tri Dao,  Atri Rudra,  Christopher Ré",
                "发布日期": "2023-02-15",
                "摘要": "  State space models (SSMs) have high performance on long sequence modeling but\nrequire sophisticated initialization techniques and specialized implementations\nfor high quality and runtime performance. We study whether a simple alternative\ncan match SSMs in performance and efficiency: directly learning long\nconvolutions over the sequence. We find that a key requirement to achieving\nhigh performance is keeping the convolution kernels smooth. We find that simple\ninterventions--such as squashing the kernel weights--result in smooth kernels\nand recover SSM performance on a range of tasks including the long range arena,\nimage classification, language modeling, and brain data modeling. Next, we\ndevelop FlashButterfly, an IO-aware algorithm to improve the runtime\nperformance of long convolutions. FlashButterfly appeals to classic Butterfly\ndecompositions of the convolution to reduce GPU memory IO and increase FLOP\nutilization. FlashButterfly speeds up convolutions by 2.2$\\times$, and allows\nus to train on Path256, a challenging task with sequence length 64K, where we\nset state-of-the-art by 29.1 points while training 7.2$\\times$ faster than\nprior work. Lastly, we introduce an extension to FlashButterfly that learns the\ncoefficients of the Butterfly decomposition, increasing expressivity without\nincreasing runtime. Using this extension, we outperform a Transformer on\nWikiText103 by 0.2 PPL with 30% fewer parameters.\n",
                "链接": "https://arxiv.org/abs/2302.06646"
            },
            {
                "文章ID": "43292",
                "标题": "What Makes Convolutional Models Great on Long Sequence Modeling?",
                "作者": " Yuhong Li,  Tianle Cai,  Yi Zhang,  Deming Chen,  Debadeepta Dey",
                "发布日期": "2022-10-18",
                "摘要": "  Convolutional models have been widely used in multiple domains. However, most\nexisting models only use local convolution, making the model unable to handle\nlong-range dependency efficiently. Attention overcomes this problem by\naggregating global information but also makes the computational complexity\nquadratic to the sequence length. Recently, Gu et al. [2021] proposed a model\ncalled S4 inspired by the state space model. S4 can be efficiently implemented\nas a global convolutional model whose kernel size equals the input sequence\nlength. S4 can model much longer sequences than Transformers and achieve\nsignificant gains over SoTA on several long-range tasks. Despite its empirical\nsuccess, S4 is involved. It requires sophisticated parameterization and\ninitialization schemes. As a result, S4 is less intuitive and hard to use. Here\nwe aim to demystify S4 and extract basic principles that contribute to the\nsuccess of S4 as a global convolutional model. We focus on the structure of the\nconvolution kernel and identify two critical but intuitive principles enjoyed\nby S4 that are sufficient to make up an effective global convolutional model:\n1) The parameterization of the convolutional kernel needs to be efficient in\nthe sense that the number of parameters should scale sub-linearly with sequence\nlength. 2) The kernel needs to satisfy a decaying structure that the weights\nfor convolving with closer neighbors are larger than the more distant ones.\nBased on the two principles, we propose a simple yet effective convolutional\nmodel called Structured Global Convolution (SGConv). SGConv exhibits strong\nempirical performance over several tasks: 1) With faster speed, SGConv\nsurpasses S4 on Long Range Arena and Speech Command datasets. 2) When plugging\nSGConv into standard language and vision models, it shows the potential to\nimprove both efficiency and performance.\n",
                "链接": "https://arxiv.org/abs/2210.09298"
            },
            {
                "文章ID": "53852",
                "标题": "Efficient Long Sequence Modeling via State Space Augmented Transformer",
                "作者": " Simiao Zuo,  Xiaodong Liu,  Jian Jiao,  Denis Charles,  Eren Manavoglu,  Tuo Zhao,  Jianfeng Gao",
                "发布日期": "2022-12-19",
                "摘要": "  Transformer models have achieved superior performance in various natural\nlanguage processing tasks. However, the quadratic computational cost of the\nattention mechanism limits its practicality for long sequences. There are\nexisting attention variants that improve the computational efficiency, but they\nhave limited ability to effectively compute global information. In parallel to\nTransformer models, state space models (SSMs) are tailored for long sequences,\nbut they are not flexible enough to capture complicated local information. We\npropose SPADE, short for $\\underline{\\textbf{S}}$tate\ns$\\underline{\\textbf{P}}$ace\n$\\underline{\\textbf{A}}$ugmente$\\underline{\\textbf{D}}$\nTransform$\\underline{\\textbf{E}}$r. Specifically, we augment a SSM into the\nbottom layer of SPADE, and we employ efficient local attention methods for the\nother layers. The SSM augments global information, which complements the lack\nof long-range dependency issue in local attention methods. Experimental results\non the Long Range Arena benchmark and language modeling tasks demonstrate the\neffectiveness of the proposed method. To further demonstrate the scalability of\nSPADE, we pre-train large encoder-decoder models and present fine-tuning\nresults on natural language understanding and natural language generation\ntasks.\n",
                "链接": "https://arxiv.org/abs/2212.08136"
            },
            {
                "文章ID": "88225",
                "标题": "HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide\n  Resolution",
                "作者": " Eric Nguyen,  Michael Poli,  Marjan Faizi,  Armin Thomas,  Callum Birch-Sykes,  Michael Wornow,  Aman Patel,  Clayton Rabideau,  Stefano Massaroli,  Yoshua Bengio,  Stefano Ermon,  Stephen A. Baccus,  Chris Ré",
                "发布日期": "2023-11-15",
                "摘要": "  Genomic (DNA) sequences encode an enormous amount of information for gene\nregulation and protein synthesis. Similar to natural language models,\nresearchers have proposed foundation models in genomics to learn generalizable\nfeatures from unlabeled genome data that can then be fine-tuned for downstream\ntasks such as identifying regulatory elements. Due to the quadratic scaling of\nattention, previous Transformer-based genomic models have used 512 to 4k tokens\nas context (<0.001% of the human genome), significantly limiting the modeling\nof long-range interactions in DNA. In addition, these methods rely on\ntokenizers or fixed k-mers to aggregate meaningful DNA units, losing single\nnucleotide resolution where subtle genetic variations can completely alter\nprotein function via single nucleotide polymorphisms (SNPs). Recently, Hyena, a\nlarge language model based on implicit convolutions was shown to match\nattention in quality while allowing longer context lengths and lower time\ncomplexity. Leveraging Hyena's new long-range capabilities, we present\nHyenaDNA, a genomic foundation model pretrained on the human reference genome\nwith context lengths of up to 1 million tokens at the single nucleotide-level -\nan up to 500x increase over previous dense attention-based models. HyenaDNA\nscales sub-quadratically in sequence length (training up to 160x faster than\nTransformer), uses single nucleotide tokens, and has full global context at\neach layer. We explore what longer context enables - including the first use of\nin-context learning in genomics. On fine-tuned benchmarks from the Nucleotide\nTransformer, HyenaDNA reaches state-of-the-art (SotA) on 12 of 18 datasets\nusing a model with orders of magnitude less parameters and pretraining data. On\nthe GenomicBenchmarks, HyenaDNA surpasses SotA on 7 of 8 datasets on average by\n+10 accuracy points. Code at https://github.com/HazyResearch/hyena-dna.\n",
                "链接": "https://arxiv.org/abs/2306.15794"
            }
        ]
    },
    {
        "question": {
            "question": "利用大模型做数学题生成的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "91891",
                "标题": "Generating Mathematical Derivations with Large Language Models",
                "作者": " Jordan Meadows,  Marco Valentino,  Andre Freitas",
                "发布日期": "2023-08-09",
                "摘要": "  The derivation of mathematical results in specialised fields, using Large\nLanguage Models (LLMs), is an emerging research direction that can help\nidentify models' limitations, and potentially support mathematical discovery.\nIn this paper, we leverage a symbolic engine to generate derivations of\nequations at scale, and investigate the capabilities of LLMs when deriving goal\nequations from premises. Specifically, we employ in-context learning for GPT\nand fine-tune a range of T5 models to compare the robustness and generalisation\nof pre-training strategies to specialised models. Empirical results show that\nfine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and\nout-of-distribution test sets in conventional scores. However, an in-depth\nanalysis reveals that the fine-tuned models are more sensitive to perturbations\ninvolving unseen symbols and (to a lesser extent) changes to equation\nstructure. In addition, we analyse 1.7K equations, and over 200 derivations, to\nhighlight common reasoning errors such as the inclusion of incorrect,\nirrelevant, and redundant equations. Finally, we explore the suitability of\nexisting metrics for evaluating mathematical derivations and find evidence\nthat, while they can capture general properties such as sensitivity to\nperturbations, they fail to highlight fine-grained reasoning errors and\nessential differences between models. Overall, this work demonstrates that\ntraining models on synthetic data may improve their math capabilities beyond\nmuch larger LLMs, but current metrics are not appropriately assessing the\nquality of generated mathematical text.\n",
                "链接": "https://arxiv.org/abs/2307.09998"
            },
            {
                "文章ID": "110277",
                "标题": "Three Questions Concerning the Use of Large Language Models to\n  Facilitate Mathematics Learning",
                "作者": " An-Zi Yen,  Wei-Ling Hsu",
                "发布日期": "2023-10-23",
                "摘要": "  Due to the remarkable language understanding and generation abilities of\nlarge language models (LLMs), their use in educational applications has been\nexplored. However, little work has been done on investigating the pedagogical\nability of LLMs in helping students to learn mathematics. In this position\npaper, we discuss the challenges associated with employing LLMs to enhance\nstudents' mathematical problem-solving skills by providing adaptive feedback.\nApart from generating the wrong reasoning processes, LLMs can misinterpret the\nmeaning of the question, and also exhibit difficulty in understanding the given\nquestions' rationales when attempting to correct students' answers. Three\nresearch questions are formulated.\n",
                "链接": "https://arxiv.org/abs/2310.13615"
            },
            {
                "文章ID": "8888",
                "标题": "Regularized Training of Intermediate Layers for Generative Models for\n  Inverse Problems",
                "作者": " Sean Gunn,  Jorio Cocola,  Paul Hand",
                "发布日期": "2022-04-12",
                "摘要": "  Generative Adversarial Networks (GANs) have been shown to be powerful and\nflexible priors when solving inverse problems. One challenge of using them is\novercoming representation error, the fundamental limitation of the network in\nrepresenting any particular signal. Recently, multiple proposed inversion\nalgorithms reduce representation error by optimizing over intermediate layer\nrepresentations. These methods are typically applied to generative models that\nwere trained agnostic of the downstream inversion algorithm. In our work, we\nintroduce a principle that if a generative model is intended for inversion\nusing an algorithm based on optimization of intermediate layers, it should be\ntrained in a way that regularizes those intermediate layers. We instantiate\nthis principle for two notable recent inversion algorithms: Intermediate Layer\nOptimization and the Multi-Code GAN prior. For both of these inversion\nalgorithms, we introduce a new regularized GAN training algorithm and\ndemonstrate that the learned generative model results in lower reconstruction\nerrors across a wide range of under sampling ratios when solving compressed\nsensing, inpainting, and super-resolution problems.\n",
                "链接": "https://arxiv.org/abs/2203.04382"
            },
            {
                "文章ID": "77344",
                "标题": "Dual Use Concerns of Generative AI and Large Language Models",
                "作者": " Alexei Grinbaum,  Laurynas Adomaitis",
                "发布日期": "2023-12-27",
                "摘要": "  We suggest the implementation of the Dual Use Research of Concern (DURC)\nframework, originally designed for life sciences, to the domain of generative\nAI, with a specific focus on Large Language Models (LLMs). With its\ndemonstrated advantages and drawbacks in biological research, we believe the\nDURC criteria can be effectively redefined for LLMs, potentially contributing\nto improved AI governance. Acknowledging the balance that must be struck when\nemploying the DURC framework, we highlight its crucial political role in\nenhancing societal awareness of the impact of generative AI. As a final point,\nwe offer a series of specific recommendations for applying the DURC approach to\nLLM research.\n",
                "链接": "https://arxiv.org/abs/2305.07882"
            },
            {
                "文章ID": "65225",
                "标题": "Hidden Knowledge: Mathematical Methods for the Extraction of the\n  Fingerprint of Medieval Paper from Digital Images",
                "作者": " Tamara G. Grossmann,  Carola-Bibiane Schönlieb,  Orietta Da Rold",
                "发布日期": "2023-03-08",
                "摘要": "  Medieval paper, a handmade product, is made with a mould which leaves an\nindelible imprint on the sheet of paper. This imprint includes chain lines,\nlaid lines and watermarks which are often visible on the sheet. Extracting\nthese features allows the identification of paper stock and gives information\nabout chronology, localisation and movement of books and people. Most\ncomputational work for feature extraction of paper analysis has so far focused\non radiography or transmitted light images. While these imaging methods provide\nclear visualisation for the features of interest, they are expensive and time\nconsuming in their acquisition and not feasible for smaller institutions.\nHowever, reflected light images of medieval paper manuscripts are abundant and\npossibly cheaper in their acquisition. In this paper, we propose algorithms to\ndetect and extract the laid and chain lines from reflected light images. We\ntackle the main drawback of reflected light images, that is, the low contrast\nattenuation of lines and intensity jumps due to noise and degradation, by\nemploying the spectral total variation decomposition and develop methods for\nsubsequent line extraction. Our results clearly demonstrate the feasibility of\nusing reflected light images in paper analysis. This work enables the feature\nextraction for paper manuscripts that have otherwise not been analysed due to a\nlack of appropriate images. We also open the door for paper stock\nidentification at scale.\n",
                "链接": "https://arxiv.org/abs/2303.03794"
            },
            {
                "文章ID": "104046",
                "标题": "Use of Large Language Models for Stance Classification",
                "作者": " Iain J. Cruickshank,  Lynnette Hui Xian Ng",
                "发布日期": "2023-09-26",
                "摘要": "  Stance detection, the task of predicting an author's viewpoint towards a\nsubject of interest, has long been a focal point of research. Current stance\ndetection methods predominantly rely on manual annotation of sentences,\nfollowed by training a supervised machine learning model. This manual\nannotation process, however, imposes limitations on the model's ability to\nfully comprehend the stances in the sentence and hampers its potential to\ngeneralize across different contexts. In this study, we investigate the use of\nLarge Language Models (LLMs) for the task of stance classification, with an\nabsolute minimum use of human labels. We scrutinize four distinct types of\nprompting schemes combined with LLMs, comparing their accuracies with manual\nstance determination. Our study reveals that while LLMs can match or sometimes\neven exceed the benchmark results in each dataset, their overall accuracy is\nnot definitively better than what can be produced by supervised models. This\nsuggests potential areas for improvement in the stance classification for LLMs.\nThe application of LLMs, however, opens up promising avenues for unsupervised\nstance detection, thereby curtailing the need for manual collection and\nannotation of stances. This not only streamlines the process but also paves the\nway for expanding stance detection capabilities across languages. Through this\npaper, we shed light on the stance classification abilities of LLMs, thereby\ncontributing valuable insights that can guide future advancements in this\ndomain.\n",
                "链接": "https://arxiv.org/abs/2309.13734"
            },
            {
                "文章ID": "87854",
                "标题": "Exploring the Robustness of Large Language Models for Solving\n  Programming Problems",
                "作者": " Atsushi Shirafuji,  Yutaka Watanobe,  Takumi Ito,  Makoto Morishita,  Yuki Nakamura,  Yusuke Oda,  Jun Suzuki",
                "发布日期": "2023-06-27",
                "摘要": "  Using large language models (LLMs) for source code has recently gained\nattention. LLMs, such as Transformer-based models like Codex and ChatGPT, have\nbeen shown to be highly capable of solving a wide range of programming\nproblems. However, the extent to which LLMs understand problem descriptions and\ngenerate programs accordingly or just retrieve source code from the most\nrelevant problem in training data based on superficial cues has not been\ndiscovered yet. To explore this research question, we conduct experiments to\nunderstand the robustness of several popular LLMs, CodeGen and GPT-3.5 series\nmodels, capable of tackling code generation tasks in introductory programming\nproblems. Our experimental results show that CodeGen and Codex are sensitive to\nthe superficial modifications of problem descriptions and significantly impact\ncode generation performance. Furthermore, we observe that Codex relies on\nvariable names, as randomized variables decrease the solved rate significantly.\nHowever, the state-of-the-art (SOTA) models, such as InstructGPT and ChatGPT,\nshow higher robustness to superficial modifications and have an outstanding\ncapability for solving programming problems. This highlights the fact that\nslight modifications to the prompts given to the LLMs can greatly affect code\ngeneration performance, and careful formatting of prompts is essential for\nhigh-quality code generation, while the SOTA models are becoming more robust to\nperturbations.\n",
                "链接": "https://arxiv.org/abs/2306.14583"
            },
            {
                "文章ID": "65723",
                "标题": "MathPrompter: Mathematical Reasoning using Large Language Models",
                "作者": " Shima Imani,  Liang Du,  Harsh Shrivastava",
                "发布日期": "2023-03-10",
                "摘要": "  Large Language Models (LLMs) have limited performance when solving arithmetic\nreasoning tasks and often provide incorrect answers. Unlike natural language\nunderstanding, math problems typically have a single correct answer, making the\ntask of generating accurate solutions more challenging for LLMs. To the best of\nour knowledge, we are not aware of any LLMs that indicate their level of\nconfidence in their responses which fuels a trust deficit in these models\nimpeding their adoption. To address this deficiency, we propose `MathPrompter',\na technique that improves performance of LLMs on arithmetic problems along with\nincreased reliance in the predictions. MathPrompter uses the Zero-shot\nchain-of-thought prompting technique to generate multiple Algebraic expressions\nor Python functions to solve the same math problem in different ways and\nthereby raise the confidence level in the output results. This is in contrast\nto other prompt based CoT methods, where there is no check on the validity of\nthe intermediate steps followed. Our technique improves over state-of-the-art\non the MultiArith dataset ($78.7\\%\\rightarrow92.5\\%$) evaluated using 175B\nparameter GPT-based LLM.\n",
                "链接": "https://arxiv.org/abs/2303.05398"
            },
            {
                "文章ID": "99865",
                "标题": "Extracting Mathematical Concepts with Large Language Models",
                "作者": " Valeria de Paiva,  Qiyue Gao,  Pavel Kovalev,  Lawrence S. Moss",
                "发布日期": "2023-09-06",
                "摘要": "  We extract mathematical concepts from mathematical text using generative\nlarge language models (LLMs) like ChatGPT, contributing to the field of\nautomatic term extraction (ATE) and mathematical text processing, and also to\nthe study of LLMs themselves. Our work builds on that of others in that we aim\nfor automatic extraction of terms (keywords) in one mathematical field,\ncategory theory, using as a corpus the 755 abstracts from a snapshot of the\nonline journal \"Theory and Applications of Categories\", circa 2020. Where our\nstudy diverges from previous work is in (1) providing a more thorough analysis\nof what makes mathematical term extraction a difficult problem to begin with;\n(2) paying close attention to inter-annotator disagreements; (3) providing a\nset of guidelines which both human and machine annotators could use to\nstandardize the extraction process; (4) introducing a new annotation tool to\nhelp humans with ATE, applicable to any mathematical field and even beyond\nmathematics; (5) using prompts to ChatGPT as part of the extraction process,\nand proposing best practices for such prompts; and (6) raising the question of\nwhether ChatGPT could be used as an annotator on the same level as human\nexperts. Our overall findings are that the matter of mathematical ATE is an\ninteresting field which can benefit from participation by LLMs, but LLMs\nthemselves cannot at this time surpass human performance on it.\n",
                "链接": "https://arxiv.org/abs/2309.00642"
            },
            {
                "文章ID": "84434",
                "标题": "On the Use of Generative Models in Observational Causal Analysis",
                "作者": " Nimrod Megiddo",
                "发布日期": "2023-06-09",
                "摘要": "  The use of a hypothetical generative model was been suggested for causal\nanalysis of observational data. The very assumption of a particular model is a\ncommitment to a certain set of variables and therefore to a certain set of\npossible causes. Estimating the joint probability distribution of can be useful\nfor predicting values of variables in view of the observed values of others,\nbut it is not sufficient for inferring causal relationships. The model\ndescribes a single observable distribution and cannot a chain of effects of\nintervention that deviate from the observed distribution.\n",
                "链接": "https://arxiv.org/abs/2306.04792"
            }
        ]
    },
    {
        "question": {
            "question": "查找可以用于验证模型推理能力的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "79447",
                "标题": "Enhance Reasoning Ability of Visual-Language Models via Large Language\n  Models",
                "作者": " Yueting Yang,  Xintong Zhang,  Wenjuan Han",
                "发布日期": "2023-05-23",
                "摘要": "  Pre-trained visual language models (VLM) have shown excellent performance in\nimage caption tasks. However, it sometimes shows insufficient reasoning\nability. In contrast, large language models (LLMs) emerge with powerful\nreasoning capabilities. Therefore, we propose a method called TReE, which\ntransfers the reasoning ability of a large language model to a visual language\nmodel in zero-shot scenarios. TReE contains three stages: observation,\nthinking, and re-thinking. Observation stage indicates that VLM obtains the\noverall information of the relative image. Thinking stage combines the image\ninformation and task description as the prompt of the LLM, inference with the\nrationals. Re-Thinking stage learns from rationale and then inference the final\nresult through VLM.\n",
                "链接": "https://arxiv.org/abs/2305.13267"
            },
            {
                "文章ID": "122067",
                "标题": "BaRDa: A Belief and Reasoning Dataset that Separates Factual Accuracy\n  and Reasoning Ability",
                "作者": " Peter Clark,  Bhavana Dalvi Mishra,  Oyvind Tafjord",
                "发布日期": "2023-12-13",
                "摘要": "  While there are numerous benchmarks comparing the performance of modern\nlanguage models (LMs), end-task evaluations often conflate notions of *factual\naccuracy* (\"truth\") and *reasoning ability* (\"rationality\", or \"honesty\" in the\nsense of correctly reporting implications of beliefs). Our goal is a dataset\nthat clearly distinguishes these two notions. Our approach is to leverage and\nextend a collection of human-annotated *entailment trees*, engineered to\nexpress both good and bad chains of reasoning, and using a mixture of true and\nfalse facts, in particular including counterfactual examples, to avoid belief\nbias (also known as the \"content effect\"). The resulting dataset, called BaRDa,\ncontains 3000 entailments (1787 valid, 1213 invalid), using 6681 true and 2319\nfalse statements. Testing on four GPT-series models,\nGPT3(curie)/GPT3(davinici)/3.5/4, we find factual accuracy (truth) scores of\n74.1/80.6/82.6/87.1 and reasoning accuracy scores of 63.1/78.0/71.8/79.2. This\nshows the clear progression of models towards improved factual accuracy and\nentailment reasoning, and the dataset provides a new benchmark that more\ncleanly separates and quantifies these two notions.\n",
                "链接": "https://arxiv.org/abs/2312.07527"
            },
            {
                "文章ID": "107444",
                "标题": "GraphLLM: Boosting Graph Reasoning Ability of Large Language Model",
                "作者": " Ziwei Chai,  Tianjie Zhang,  Liang Wu,  Kaiqiao Han,  Xiaohai Hu,  Xuanwen Huang,  Yang Yang",
                "发布日期": "2023-10-10",
                "摘要": "  The advancement of Large Language Models (LLMs) has remarkably pushed the\nboundaries towards artificial general intelligence (AGI), with their\nexceptional ability on understanding diverse types of information, including\nbut not limited to images and audio. Despite this progress, a critical gap\nremains in empowering LLMs to proficiently understand and reason on graph data.\nRecent studies underscore LLMs' underwhelming performance on fundamental graph\nreasoning tasks. In this paper, we endeavor to unearth the obstacles that\nimpede LLMs in graph reasoning, pinpointing the common practice of converting\ngraphs into natural language descriptions (Graph2Text) as a fundamental\nbottleneck. To overcome this impediment, we introduce GraphLLM, a pioneering\nend-to-end approach that synergistically integrates graph learning models with\nLLMs. This synergy equips LLMs with the ability to proficiently interpret and\nreason on graph data, harnessing the superior expressive power of graph\nlearning models. Our empirical evaluations across four fundamental graph\nreasoning tasks validate the effectiveness of GraphLLM. The results exhibit a\nsubstantial average accuracy enhancement of 54.44%, alongside a noteworthy\ncontext reduction of 96.45% across various graph reasoning tasks.\n",
                "链接": "https://arxiv.org/abs/2310.05845"
            },
            {
                "文章ID": "72179",
                "标题": "Analysing Fairness of Privacy-Utility Mobility Models",
                "作者": " Yuting Zhan,  Hamed Haddadi,  Afra Mashhadi",
                "发布日期": "2023-04-14",
                "摘要": "  Preserving the individuals' privacy in sharing spatial-temporal datasets is\ncritical to prevent re-identification attacks based on unique trajectories.\nExisting privacy techniques tend to propose ideal privacy-utility tradeoffs,\nhowever, largely ignore the fairness implications of mobility models and\nwhether such techniques perform equally for different groups of users. The\nquantification between fairness and privacy-aware models is still unclear and\nthere barely exists any defined sets of metrics for measuring fairness in the\nspatial-temporal context. In this work, we define a set of fairness metrics\ndesigned explicitly for human mobility, based on structural similarity and\nentropy of the trajectories. Under these definitions, we examine the fairness\nof two state-of-the-art privacy-preserving models that rely on GAN and\nrepresentation learning to reduce the re-identification rate of users for data\nsharing. Our results show that while both models guarantee group fairness in\nterms of demographic parity, they violate individual fairness criteria,\nindicating that users with highly similar trajectories receive disparate\nprivacy gain. We conclude that the tension between the re-identification task\nand individual fairness needs to be considered for future spatial-temporal data\nanalysis and modelling to achieve a privacy-preserving fairness-aware setting.\n",
                "链接": "https://arxiv.org/abs/2304.06469"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "106747",
                "标题": "Analysis of the Reasoning with Redundant Information Provided Ability of\n  Large Language Models",
                "作者": " Wenbei Xie",
                "发布日期": "2023-10-09",
                "摘要": "  Recent advancements in Large Language Models (LLMs) have demonstrated\nimpressive capabilities across a range of natural language processing tasks,\nespecially in reasoning, a cornerstone for achieving Artificial General\nIntelligence (AGI). However, commonly used benchmarks may not fully encapsulate\nthe inferential abilities of these models in real-world scenarios. To address\nthis gap, a new form of Question-Answering (QA) task, termed Reasoning with\nRedundant Information Provided (RRIP), is introduced. The study designed a\nmodified version of the grade school math 8K (GSM-8K) dataset which has several\nvariants focusing on different attributes of redundant information. This\ninvestigation evaluates two popular LLMs, LlaMA2-13B-chat and generative\npre-trained transformer 3.5 (GPT-3.5), contrasting their performance on\ntraditional QA tasks against the RRIP tasks. Findings indicate that while these\nmodels achieved moderate success on standard QA benchmarks, their performance\nnotably declines when assessed on RRIP tasks. The study not only highlights the\nlimitations of current LLMs in handling redundant information but also suggests\nthat future training of these models should focus on incorporating redundant\ninformation into the training data to increase the performance on RRIP tasks.\n",
                "链接": "https://arxiv.org/abs/2310.04039"
            },
            {
                "文章ID": "110171",
                "标题": "Democratizing Reasoning Ability: Tailored Learning from Large Language\n  Model",
                "作者": " Zhaoyang Wang,  Shaohan Huang,  Yuxuan Liu,  Jiahai Wang,  Minghui Song,  Zihan Zhang,  Haizhen Huang,  Furu Wei,  Weiwei Deng,  Feng Sun,  Qi Zhang",
                "发布日期": "2023-10-23",
                "摘要": "  Large language models (LLMs) exhibit impressive emergent abilities in natural\nlanguage processing, but their democratization is hindered due to huge\ncomputation requirements and closed-source nature. Recent research on advancing\nopen-source smaller LMs by distilling knowledge from black-box LLMs has\nobtained promising results in the instruction-following ability. However, the\nreasoning ability which is more challenging to foster, is relatively rarely\nexplored. In this paper, we propose a tailored learning approach to distill\nsuch reasoning ability to smaller LMs to facilitate the democratization of the\nexclusive reasoning ability. In contrast to merely employing LLM as a data\nannotator, we exploit the potential of LLM as a reasoning teacher by building\nan interactive multi-round learning paradigm. This paradigm enables the student\nto expose its deficiencies to the black-box teacher who then can provide\ncustomized training data in return. Further, to exploit the reasoning potential\nof the smaller LM, we propose self-reflection learning to motivate the student\nto learn from self-made mistakes. The learning from self-reflection and LLM are\nall tailored to the student's learning status, thanks to the seamless\nintegration with the multi-round learning paradigm. Comprehensive experiments\nand analysis on mathematical and commonsense reasoning tasks demonstrate the\neffectiveness of our method. The code will be available at\nhttps://github.com/Raibows/Learn-to-Reason.\n",
                "链接": "https://arxiv.org/abs/2310.13332"
            },
            {
                "文章ID": "124571",
                "标题": "NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language\n  Models via Complexity Classes",
                "作者": " Lizhou Fan,  Wenyue Hua,  Lingyao Li,  Haoyang Ling,  Yongfeng Zhang,  Libby Hemphill",
                "发布日期": "2023-12-27",
                "摘要": "  Complex reasoning ability is one of the most important features of current\nLLMs, which has also been leveraged to play an integral role in complex\ndecision-making tasks. Therefore, the investigation into the reasoning\ncapabilities of Large Language Models (LLMs) is critical: numerous benchmarks\nhave been established to assess the reasoning abilities of LLMs. However,\ncurrent benchmarks are inadequate in offering a rigorous evaluation of the full\nextent of reasoning abilities that LLMs are capable of achieving. They are also\nprone to the risk of overfitting, as these benchmarks, being publicly\naccessible and static, allow models to potentially tailor their responses to\nspecific benchmark metrics, thereby inflating their performance. Addressing\nthese limitations, our research introduces a new benchmark, named NPHardEval.\nThis benchmark is designed to evaluate the reasoning abilities of LLMs across a\nbroad spectrum of 900 algorithmic questions, extending up to the NP-Hard\ncomplexity class. These questions are meticulously chosen to represent a wide\nrange of complexity class below the NP-hard complexity class, offering a\nrigorous measure of the reasoning ability of LLMs. Through this study, we shed\nlight on the current state of reasoning in LLMs, providing an objective and\nrigorous perspective through the comparison of LLMs' performance across complex\nclasses. Moreover, this benchmark is designed with a dynamic update mechanism,\nwhere the datapoints are refreshed on a monthly basis. Such regular updates\nplay a crucial role in mitigating the risk of LLMs overfitting to the\nbenchmark, promoting a more accurate and reliable assessment of their reasoning\ncapabilities. The benchmark dataset and code of NPHardEval are available at\nhttps://github.com/casmlab/NPHardEval.\n",
                "链接": "https://arxiv.org/abs/2312.14890"
            },
            {
                "文章ID": "103829",
                "标题": "Effective Distillation of Table-based Reasoning Ability from LLMs",
                "作者": " Bohao Yang,  Chen Tang,  Kun Zhao,  Chenghao Xiao,  Chenghua Lin",
                "发布日期": "2023-09-26",
                "摘要": "  Large Language Models (LLMs) have demonstrated remarkable performance across\na wide range of natural language processing tasks. However, their remarkable\nparameter size and their impressive high requirement of computing resources\npose challenges for their practical deployment. Recent research has revealed\nthat specific capabilities of LLMs, such as numerical reasoning, can be\ntransferred to smaller models through distillation. Some studies explore the\npotential of leveraging LLMs to perform table-based reasoning. Nevertheless,\nprior to our work, there has been no investigation into the prospect of\nspecialising table reasoning skills in smaller models specifically tailored for\ntable-to-text generation tasks. In this paper, we propose a novel table-based\nreasoning distillation, with the aim of distilling distilling LLMs into\ntailored, smaller models specifically designed for table-based reasoning task.\nExperimental results have shown that a 0.22 billion parameter model\n(Flan-T5-base) fine-tuned using distilled data, not only achieves a significant\nimprovement compared to traditionally fine-tuned baselines but also surpasses\nspecific LLMs like gpt-3.5-turbo on the scientific table-to-text generation\ndataset (SciGen). The code and data are released in\nhttps://github.com/Bernard-Yang/TableDistill.\n",
                "链接": "https://arxiv.org/abs/2309.13182"
            },
            {
                "文章ID": "18543",
                "标题": "Validation of a motion model for soccer players' sprint by means of\n  tracking data",
                "作者": " Takuma Narizuka,  Kenta Takizawa,  Yoshihiro Yamazaki",
                "发布日期": "2023-01-18",
                "摘要": "  In soccer game analysis, the widespread availability of play-by-play and\ntracking data has made it possible to test mathematical models that have been\ndiscussed mainly theoretically. One of the essential models in soccer game\nanalysis is a motion model that predicts the arrival point of a player in $ t $\ns. Although many space evaluation and pass prediction methods rely on motion\nmodels, the validity of each has not been fully clarified. This study focuses\non the motion model proposed by Fujimura and Sugihara (Fujimura-Sugihara model)\nunder sprint conditions based on the equation of motion. A previous study\nindicated that the Fujimura-Sugihara model is ineffective for soccer games\nbecause it generates a circular arrival region. This study aims to examine the\nvalidity of the Fujimura-Sugihara model using soccer tracking data.\nSpecifically, we quantitatively compare the arrival regions of players between\nthe model and real data. We show that the boundary of the player's arrival\nregion is circular rather than elliptical, which is consistent with the model.\nWe also show that the initial speed dependence of the arrival region satisfies\nthe solution of the model. Furthermore, we propose a method for estimating\nvalid kinetic parameters in the model directly from tracking data and discuss\nthe limitations of the model for soccer games based on the estimated\nparameters.\n",
                "链接": "https://arxiv.org/abs/2205.04511"
            }
        ]
    },
    {
        "question": {
            "question": "帮我找一下用大模型进行论文查找的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "117394",
                "标题": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
                "作者": " Chengyu Wang,  Junbing Yan,  Wei Zhang,  Jun Huang",
                "发布日期": "2023-11-23",
                "摘要": "  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.13126"
            },
            {
                "文章ID": "57742",
                "标题": "Neural Architecture Search: Insights from 1000 Papers",
                "作者": " Colin White,  Mahmoud Safari,  Rhea Sukthanker,  Binxin Ru,  Thomas Elsken,  Arber Zela,  Debadeepta Dey,  Frank Hutter",
                "发布日期": "2023-01-26",
                "摘要": "  In the past decade, advances in deep learning have resulted in breakthroughs\nin a variety of areas, including computer vision, natural language\nunderstanding, speech recognition, and reinforcement learning. Specialized,\nhigh-performing neural architectures are crucial to the success of deep\nlearning in these areas. Neural architecture search (NAS), the process of\nautomating the design of neural architectures for a given task, is an\ninevitable next step in automating machine learning and has already outpaced\nthe best human-designed architectures on many tasks. In the past few years,\nresearch in NAS has been progressing rapidly, with over 1000 papers released\nsince 2020 (Deng and Lindauer, 2021). In this survey, we provide an organized\nand comprehensive guide to neural architecture search. We give a taxonomy of\nsearch spaces, algorithms, and speedup techniques, and we discuss resources\nsuch as benchmarks, best practices, other surveys, and open-source libraries.\n",
                "链接": "https://arxiv.org/abs/2301.08727"
            },
            {
                "文章ID": "58389",
                "标题": "uHelp: intelligent volunteer search for mutual help communities",
                "作者": " Nardine Osman,  Bruno Rosell,  Carles Sierra,  Marco Schorlemmer,  Jordi Sabater-Mir,  Lissette Lemus",
                "发布日期": "2023-01-27",
                "摘要": "  When people need help with their day-to-day activities, they turn to family,\nfriends or neighbours. But despite an increasingly networked world, technology\nfalls short in finding suitable volunteers. In this paper, we propose uHelp, a\nplatform for building a community of helpful people and supporting community\nmembers find the appropriate help within their social network. Lately,\napplications that focus on finding volunteers have started to appear, such as\nHelpin or Facebook's Community Help. However, what distinguishes uHelp from\nexisting applications is its trust-based intelligent search for volunteers.\nAlthough trust is crucial to these innovative social applications, none of them\nhave seriously achieved yet a trust-building solution such as that of uHelp.\nuHelp's intelligent search for volunteers is based on a number of AI\ntechnologies: (1) a novel trust-based flooding algorithm that navigates one's\nsocial network looking for appropriate trustworthy volunteers; (2) a novel\ntrust model that maintains the trustworthiness of peers by learning from their\nsimilar past experiences; and (3) a semantic similarity model that assesses the\nsimilarity of experiences. This article presents the uHelp application,\ndescribes the underlying AI technologies that allow uHelp find trustworthy\nvolunteers efficiently, and illustrates the implementation details. uHelp's\ninitial prototype has been tested with a community of single parents in\nBarcelona, and the app is available online at both Apple Store and Google Play.\n",
                "链接": "https://arxiv.org/abs/2301.11112"
            },
            {
                "文章ID": "75161",
                "标题": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
                "作者": " Eddie Guo,  Mehul Gupta,  Jiawen Deng,  Ye-Jean Park,  Mike Paget,  Christopher Naugler",
                "发布日期": "2023-10-09",
                "摘要": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
                "链接": "https://arxiv.org/abs/2305.00844"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "48330",
                "标题": "Pied Piper: Meta Search for Music",
                "作者": " Pulak Malhotra,  Ashwin Rao",
                "发布日期": "2022-12-01",
                "摘要": "  Internet search engines have become an integral part of life, but for pop\nmusic, people still rely on textual search engines like Google. We propose Pied\npiper, a meta search engine for music. It can search for music lyrics, song\nmetadata and song audio or a combination of any of these as the input query and\nefficiently return the relevant results.\n",
                "链接": "https://arxiv.org/abs/2211.07610"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到，最早提出分布式词表示的论文是哪一篇？",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "16842",
                "标题": "Extremal GloVe: Theoretically Accurate Distributed Word Embedding by\n  Tail Inference",
                "作者": " Hao Wang",
                "发布日期": "2022-04-28",
                "摘要": "  Distributed word embeddings such as Word2Vec and GloVe have been widely\nadopted in industrial context settings. Major technical applications of GloVe\ninclude recommender systems and natural language processing. The fundamental\ntheory behind GloVe relies on the selection of a weighting function in the\nweighted least squres formulation that computes the powered ratio of word\noccurrence count and the maximum word count in the corpus. However, the initial\nformulation of GloVe is not theoretically sound in two aspects, namely the\nselection of the weighting function and its power exponent is ad-hoc. In this\npaper, we utilize the theory of extreme value analysis and propose a\ntheoretically accurate version of GloVe. By reformulating the weighted least\nsquares loss function as the expected loss function and accurately choosing the\npower exponent, we create a theoretically accurate version of GloVe. We\ndemonstrate the competitiveness of our algorithm and show that the initial\nformulation of GloVe with the suggested optimal parameter can be viewed as a\nspecial case of our paradigm.\n",
                "链接": "https://arxiv.org/abs/2204.13009"
            },
            {
                "文章ID": "42603",
                "标题": "Multilingual Word Sense Disambiguation with Unified Sense Representation",
                "作者": " Ying Su,  Hongming Zhang,  Yangqiu Song,  Tong Zhang",
                "发布日期": "2022-10-17",
                "摘要": "  As a key natural language processing (NLP) task, word sense disambiguation\n(WSD) evaluates how well NLP models can understand the lexical semantics of\nwords under specific contexts. Benefited from the large-scale annotation,\ncurrent WSD systems have achieved impressive performances in English by\ncombining supervised learning with lexical knowledge. However, such success is\nhard to be replicated in other languages, where we only have limited\nannotations.In this paper, based on the multilingual lexicon BabelNet\ndescribing the same set of concepts across languages, we propose building\nknowledge and supervised-based Multilingual Word Sense Disambiguation (MWSD)\nsystems. We build unified sense representations for multiple languages and\naddress the annotation scarcity problem for MWSD by transferring annotations\nfrom rich-sourced languages to poorer ones. With the unified sense\nrepresentations, annotations from multiple languages can be jointly trained to\nbenefit the MWSD tasks. Evaluations of SemEval-13 and SemEval-15 datasets\ndemonstrate the effectiveness of our methodology.\n",
                "链接": "https://arxiv.org/abs/2210.07447"
            },
            {
                "文章ID": "49974",
                "标题": "Word-Level Representation From Bytes For Language Modeling",
                "作者": " Chu-Tak Lee,  Qipeng Guo,  Xipeng Qiu",
                "发布日期": "2022-11-24",
                "摘要": "  Modern language models mostly take sub-words as input, a design that balances\nthe trade-off between vocabulary size, number of parameters, and performance.\nHowever, sub-word tokenization still has disadvantages like not being robust to\nnoise and difficult to generalize to new languages. Also, the current trend of\nscaling up models reveals that larger models require larger embeddings but that\nmakes parallelization hard. Previous work on image classification proves\nsplitting raw input into a sequence of chucks is a strong, model-agnostic\ninductive bias. Based on this observation, we rethink the existing\ncharacter-aware method that takes character-level inputs but makes word-level\nsequence modeling and prediction. We overhaul this method by introducing a\ncross-attention network that builds word-level representation directly from\nbytes, and a sub-word level prediction based on word-level hidden states to\navoid the time and space requirement of word-level prediction. With these two\nimprovements combined, we have a token free model with slim input embeddings\nfor downstream tasks. We name our method Byte2Word and perform evaluations on\nlanguage modeling and text classification. Experiments show that Byte2Word is\non par with the strong sub-word baseline BERT but only takes up 10\\% of\nembedding size. We further test our method on synthetic noise and cross-lingual\ntransfer and find it competitive to baseline methods on both settings.\n",
                "链接": "https://arxiv.org/abs/2211.12677"
            },
            {
                "文章ID": "19560",
                "标题": "KGNN: Distributed Framework for Graph Neural Knowledge Representation",
                "作者": " Binbin Hu,  Zhiyang Hu,  Zhiqiang Zhang,  Jun Zhou,  Chuan Shi",
                "发布日期": "2022-05-18",
                "摘要": "  Knowledge representation learning has been commonly adopted to incorporate\nknowledge graph (KG) into various online services. Although existing knowledge\nrepresentation learning methods have achieved considerable performance\nimprovement, they ignore high-order structure and abundant attribute\ninformation, resulting unsatisfactory performance on semantics-rich KGs.\nMoreover, they fail to make prediction in an inductive manner and cannot scale\nto large industrial graphs. To address these issues, we develop a novel\nframework called KGNN to take full advantage of knowledge data for\nrepresentation learning in the distributed learning system. KGNN is equipped\nwith GNN based encoder and knowledge aware decoder, which aim to jointly\nexplore high-order structure and attribute information together in a\nfine-grained fashion and preserve the relation patterns in KGs, respectively.\nExtensive experiments on three datasets for link prediction and triplet\nclassification task demonstrate the effectiveness and scalability of KGNN\nframework.\n",
                "链接": "https://arxiv.org/abs/2205.08285"
            },
            {
                "文章ID": "73435",
                "标题": "Distributed Neural Representation for Reactive in situ Visualization",
                "作者": " Qi Wu,  Joseph A. Insley,  Victor A. Mateevitsi,  Silvio Rizzi,  Michael E. Papka,  Kwan-Liu Ma",
                "发布日期": "2023-04-21",
                "摘要": "  In situ visualization and steering of computational modeling can be\neffectively achieved using reactive programming, which leverages temporal\nabstraction and data caching mechanisms to create dynamic workflows. However,\nimplementing a temporal cache for large-scale simulations can be challenging.\nImplicit neural networks have proven effective in compressing large volume\ndata. However, their application to distributed data has yet to be fully\nexplored. In this work, we develop an implicit neural representation for\ndistributed volume data and incorporate it into the DIVA reactive programming\nsystem. This implementation enables us to build an in situ temporal caching\nsystem with a capacity 100 times larger than previously achieved. We integrate\nour implementation into the Ascent infrastructure and evaluate its performance\nusing real-world simulations.\n",
                "链接": "https://arxiv.org/abs/2304.10516"
            },
            {
                "文章ID": "3597",
                "标题": "Towards a Theoretical Understanding of Word and Relation Representation",
                "作者": " Carl Allen",
                "发布日期": "2022-02-02",
                "摘要": "  Representing words by vectors, or embeddings, enables computational reasoning\nand is foundational to automating natural language tasks. For example, if word\nembeddings of similar words contain similar values, word similarity can be\nreadily assessed, whereas judging that from their spelling is often impossible\n(e.g. cat /feline) and to predetermine and store similarities between all words\nis prohibitively time-consuming, memory intensive and subjective. We focus on\nword embeddings learned from text corpora and knowledge graphs. Several\nwell-known algorithms learn word embeddings from text on an unsupervised basis\nby learning to predict those words that occur around each word, e.g. word2vec\nand GloVe. Parameters of such word embeddings are known to reflect word\nco-occurrence statistics, but how they capture semantic meaning has been\nunclear. Knowledge graph representation models learn representations both of\nentities (words, people, places, etc.) and relations between them, typically by\ntraining a model to predict known facts in a supervised manner. Despite steady\nimprovements in fact prediction accuracy, little is understood of the latent\nstructure that enables this.\n  The limited understanding of how latent semantic structure is encoded in the\ngeometry of word embeddings and knowledge graph representations makes a\nprincipled means of improving their performance, reliability or\ninterpretability unclear. To address this:\n  1. we theoretically justify the empirical observation that particular\ngeometric relationships between word embeddings learned by algorithms such as\nword2vec and GloVe correspond to semantic relations between words; and\n  2. we extend this correspondence between semantics and geometry to the\nentities and relations of knowledge graphs, providing a model for the latent\nstructure of knowledge graph representation linked to that of word embeddings.\n",
                "链接": "https://arxiv.org/abs/2202.00486"
            },
            {
                "文章ID": "80919",
                "标题": "A Distributed Automatic Domain-Specific Multi-Word Term Recognition\n  Architecture using Spark Ecosystem",
                "作者": " Ciprian-Octavian Truică,  Neculai-Ovidiu Istrate,  Elena-Simona Apostol",
                "发布日期": "2023-05-29",
                "摘要": "  Automatic Term Recognition is used to extract domain-specific terms that\nbelong to a given domain. In order to be accurate, these corpus and\nlanguage-dependent methods require large volumes of textual data that need to\nbe processed to extract candidate terms that are afterward scored according to\na given metric. To improve text preprocessing and candidate terms extraction\nand scoring, we propose a distributed Spark-based architecture to automatically\nextract domain-specific terms. The main contributions are as follows: (1)\npropose a novel distributed automatic domain-specific multi-word term\nrecognition architecture built on top of the Spark ecosystem; (2) perform an\nin-depth analysis of our architecture in terms of accuracy and scalability; (3)\ndesign an easy-to-integrate Python implementation that enables the use of Big\nData processing in fields such as Computational Linguistics and Natural\nLanguage Processing. We prove empirically the feasibility of our architecture\nby performing experiments on two real-world datasets.\n",
                "链接": "https://arxiv.org/abs/2305.16343"
            },
            {
                "文章ID": "116434",
                "标题": "Collaborative Word-based Pre-trained Item Representation for\n  Transferable Recommendation",
                "作者": " Shenghao Yang,  Chenyang Wang,  Yankai Liu,  Kangping Xu,  Weizhi Ma,  Yiqun Liu,  Min Zhang,  Haitao Zeng,  Junlan Feng,  Chao Deng",
                "发布日期": "2023-12-22",
                "摘要": "  Item representation learning (IRL) plays an essential role in recommender\nsystems, especially for sequential recommendation. Traditional sequential\nrecommendation models usually utilize ID embeddings to represent items, which\nare not shared across different domains and lack the transferable ability.\nRecent studies use pre-trained language models (PLM) for item text embeddings\n(text-based IRL) that are universally applicable across domains. However, the\nexisting text-based IRL is unaware of the important collaborative filtering\n(CF) information. In this paper, we propose CoWPiRec, an approach of\nCollaborative Word-based Pre-trained item representation for Recommendation. To\neffectively incorporate CF information into text-based IRL, we convert the\nitem-level interaction data to a word graph containing word-level\ncollaborations. Subsequently, we design a novel pre-training task to align the\nword-level semantic- and CF-related item representation. Extensive experimental\nresults on multiple public datasets demonstrate that compared to\nstate-of-the-art transferable sequential recommenders, CoWPiRec achieves\nsignificantly better performances in both fine-tuning and zero-shot settings\nfor cross-scenario recommendation and effectively alleviates the cold-start\nissue. The code is available at: https://github.com/ysh-1998/CoWPiRec.\n",
                "链接": "https://arxiv.org/abs/2311.10501"
            },
            {
                "文章ID": "118082",
                "标题": "Probabilistic Transformer: A Probabilistic Dependency Model for\n  Contextual Word Representation",
                "作者": " Haoyi Wu,  Kewei Tu",
                "发布日期": "2023-11-28",
                "摘要": "  Syntactic structures used to play a vital role in natural language processing\n(NLP), but since the deep learning revolution, NLP has been gradually dominated\nby neural models that do not consider syntactic structures in their design. One\nvastly successful class of neural models is transformers. When used as an\nencoder, a transformer produces contextual representation of words in the input\nsentence. In this work, we propose a new model of contextual word\nrepresentation, not from a neural perspective, but from a purely syntactic and\nprobabilistic perspective. Specifically, we design a conditional random field\nthat models discrete latent representations of all words in a sentence as well\nas dependency arcs between them; and we use mean field variational inference\nfor approximate inference. Strikingly, we find that the computation graph of\nour model resembles transformers, with correspondences between dependencies and\nself-attention and between distributions over latent representations and\ncontextual embeddings of words. Experiments show that our model performs\ncompetitively to transformers on small to medium sized datasets. We hope that\nour work could help bridge the gap between traditional syntactic and\nprobabilistic approaches and cutting-edge neural approaches to NLP, and inspire\nmore linguistically-principled neural approaches in the future.\n",
                "链接": "https://arxiv.org/abs/2311.15211"
            },
            {
                "文章ID": "686",
                "标题": "Coherence-Based Distributed Document Representation Learning for\n  Scientific Documents",
                "作者": " Shicheng Tan,  Shu Zhao,  Yanping Zhang",
                "发布日期": "2022-01-11",
                "摘要": "  Distributed document representation is one of the basic problems in natural\nlanguage processing. Currently distributed document representation methods\nmainly consider the context information of words or sentences. These methods do\nnot take into account the coherence of the document as a whole, e.g., a\nrelation between the paper title and abstract, headline and description, or\nadjacent bodies in the document. The coherence shows whether a document is\nmeaningful, both logically and syntactically, especially in scientific\ndocuments (papers or patents, etc.). In this paper, we propose a coupled text\npair embedding (CTPE) model to learn the representation of scientific\ndocuments, which maintains the coherence of the document with coupled text\npairs formed by segmenting the document. First, we divide the document into two\nparts (e.g., title and abstract, etc) which construct a coupled text pair.\nThen, we adopt negative sampling to construct uncoupled text pairs whose two\nparts are from different documents. Finally, we train the model to judge\nwhether the text pair is coupled or uncoupled and use the obtained embedding of\ncoupled text pairs as the embedding of documents. We perform experiments on\nthree datasets for one information retrieval task and two recommendation tasks.\nThe experimental results verify the effectiveness of the proposed CTPE model.\n",
                "链接": "https://arxiv.org/abs/2201.02846"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下nips 2023 paper list",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "91898",
                "标题": "Rob\\^oCIn Small Size League Extended Team Description Paper for RoboCup\n  2023",
                "作者": " Aline Lima de Oliveira,  Cauê Addae da Silva Gomes,  Cecília Virginia Santos da Silva,  Charles Matheus de Sousa Alves,  Danilo Andrade Martins de Souza,  Driele Pires Ferreira Araújo Xavier,  Edgleyson Pereira da Silva,  Felipe Bezerra Martins,  Lucas Henrique Cavalcanti Santos,  Lucas Dias Maciel,  Matheus Paixão Gumercindo dos Santos,  Matheus Lafayette Vasconcelos,  Matheus Vinícius Teotonio do Nascimento Andrade,  João Guilherme Oliveira Carvalho de Melo,  João Pedro Souza Pereira de Moura,  José Ronald da Silva,  José Victor Silva Cruz,  Pedro Henrique Santana de Morais,  Pedro Paulo Salman de Oliveira,  Riei Joaquim Matos Rodrigues,  Roberto Costa Fernandes,  Ryan Vinicius Santos Morais,  Tamara Mayara Ramos Teobaldo,  Washington Igor dos Santos Silva,  Edna Natividade Silva Barros",
                "发布日期": "2023-07-20",
                "摘要": "  Rob\\^oCIn has participated in RoboCup Small Size League since 2019, won its\nfirst world title in 2022 (Division B), and is currently a three-times\nLatin-American champion. This paper presents our improvements to defend the\nSmall Size League (SSL) division B title in RoboCup 2023 in Bordeaux, France.\nThis paper aims to share some of the academic research that our team developed\nover the past year. Our team has successfully published 2 articles related to\nSSL at two high-impact conferences: the 25th RoboCup International Symposium\nand the 19th IEEE Latin American Robotics Symposium (LARS 2022). Over the last\nyear, we have been continuously migrating from our past codebase to\nUnification. We will describe the new architecture implemented and some points\nof software and AI refactoring. In addition, we discuss the process of\nintegrating machined components into the mechanical system, our development for\nparticipating in the vision blackout challenge last year and what we are\npreparing for this year.\n",
                "链接": "https://arxiv.org/abs/2307.10018"
            },
            {
                "文章ID": "36791",
                "标题": "An Improved Algorithm For Online Min-Sum Set Cover",
                "作者": " Marcin Bienkowski,  Marcin Mucha",
                "发布日期": "2023-03-28",
                "摘要": "  We study a fundamental model of online preference aggregation, where an\nalgorithm maintains an ordered list of $n$ elements. An input is a stream of\npreferred sets $R_1, R_2, \\dots, R_t, \\dots$. Upon seeing $R_t$ and without\nknowledge of any future sets, an algorithm has to rerank elements (change the\nlist ordering), so that at least one element of $R_t$ is found near the list\nfront. The incurred cost is a sum of the list update costs (the number of swaps\nof neighboring list elements) and access costs (position of the first element\nof $R_t$ on the list). This scenario occurs naturally in applications such as\nordering items in an online shop using aggregated preferences of shop\ncustomers. The theoretical underpinning of this problem is known as Min-Sum Set\nCover.\n  Unlike previous work (Fotakis et al., ICALP 2020, NIPS 2020) that mostly\nstudied the performance of an online algorithm ALG against the static optimal\nsolution (a single optimal list ordering), in this paper, we study an arguably\nharder variant where the benchmark is the provably stronger optimal dynamic\nsolution OPT (that may also modify the list ordering). In terms of an online\nshop, this means that the aggregated preferences of its user base evolve with\ntime. We construct a computationally efficient randomized algorithm whose\ncompetitive ratio (ALG-to-OPT cost ratio) is $O(r^2)$ and prove the existence\nof a deterministic $O(r^4)$-competitive algorithm. Here, $r$ is the maximum\ncardinality of sets $R_t$. This is the first algorithm whose ratio does not\ndepend on $n$: the previously best algorithm for this problem was $O(r^{3/2}\n\\cdot \\sqrt{n})$-competitive and $\\Omega(r)$ is a lower bound on the\nperformance of any deterministic online algorithm.\n",
                "链接": "https://arxiv.org/abs/2209.04870"
            },
            {
                "文章ID": "69199",
                "标题": "List Online Classification",
                "作者": " Shay Moran,  Ohad Sharon,  Iska Tsubari,  Sivan Yosebashvili",
                "发布日期": "2023-05-19",
                "摘要": "  We study multiclass online prediction where the learner can predict using a\nlist of multiple labels (as opposed to just one label in the traditional\nsetting). We characterize learnability in this model using the $b$-ary\nLittlestone dimension. This dimension is a variation of the classical\nLittlestone dimension with the difference that binary mistake trees are\nreplaced with $(k+1)$-ary mistake trees, where $k$ is the number of labels in\nthe list. In the agnostic setting, we explore different scenarios depending on\nwhether the comparator class consists of single-labeled or multi-labeled\nfunctions and its tradeoff with the size of the lists the algorithm uses. We\nfind that it is possible to achieve negative regret in some cases and provide a\ncomplete characterization of when this is possible. As part of our work, we\nadapt classical algorithms such as Littlestone's SOA and Rosenblatt's\nPerceptron to predict using lists of labels. We also establish combinatorial\nresults for list-learnable classes, including an list online version of the\nSauer-Shelah-Perles Lemma. We state our results within the framework of pattern\nclasses -- a generalization of hypothesis classes which can represent adaptive\nhypotheses (i.e. functions with memory), and model data-dependent assumptions\nsuch as linear classification with margin.\n",
                "链接": "https://arxiv.org/abs/2303.15383"
            },
            {
                "文章ID": "84628",
                "标题": "Overview of the Problem List Summarization (ProbSum) 2023 Shared Task on\n  Summarizing Patients' Active Diagnoses and Problems from Electronic Health\n  Record Progress Notes",
                "作者": " Yanjun Gao,  Dmitriy Dligach,  Timothy Miller,  Matthew M. Churpek,  Majid Afshar",
                "发布日期": "2023-06-09",
                "摘要": "  The BioNLP Workshop 2023 initiated the launch of a shared task on Problem\nList Summarization (ProbSum) in January 2023. The aim of this shared task is to\nattract future research efforts in building NLP models for real-world\ndiagnostic decision support applications, where a system generating relevant\nand accurate diagnoses will augment the healthcare providers decision-making\nprocess and improve the quality of care for patients. The goal for participants\nis to develop models that generated a list of diagnoses and problems using\ninput from the daily care notes collected from the hospitalization of\ncritically ill patients. Eight teams submitted their final systems to the\nshared task leaderboard. In this paper, we describe the tasks, datasets,\nevaluation metrics, and baseline systems. Additionally, the techniques and\nresults of the evaluation of the different approaches tried by the\nparticipating teams are summarized.\n",
                "链接": "https://arxiv.org/abs/2306.05270"
            },
            {
                "文章ID": "25879",
                "标题": "List-Decodable Covariance Estimation",
                "作者": " Misha Ivkov,  Pravesh K. Kothari",
                "发布日期": "2022-06-23",
                "摘要": "  We give the first polynomial time algorithm for \\emph{list-decodable\ncovariance estimation}. For any $\\alpha > 0$, our algorithm takes input a\nsample $Y \\subseteq \\mathbb{R}^d$ of size $n\\geq d^{\\mathsf{poly}(1/\\alpha)}$\nobtained by adversarially corrupting an $(1-\\alpha)n$ points in an i.i.d.\nsample $X$ of size $n$ from the Gaussian distribution with unknown mean $\\mu_*$\nand covariance $\\Sigma_*$. In $n^{\\mathsf{poly}(1/\\alpha)}$ time, it outputs a\nconstant-size list of $k = k(\\alpha)= (1/\\alpha)^{\\mathsf{poly}(1/\\alpha)}$\ncandidate parameters that, with high probability, contains a\n$(\\hat{\\mu},\\hat{\\Sigma})$ such that the total variation distance\n$TV(\\mathcal{N}(\\mu_*,\\Sigma_*),\\mathcal{N}(\\hat{\\mu},\\hat{\\Sigma}))<1-O_{\\alpha}(1)$.\nThis is the statistically strongest notion of distance and implies\nmultiplicative spectral and relative Frobenius distance approximation for\nparameters with dimension independent error. Our algorithm works more generally\nfor $(1-\\alpha)$-corruptions of any distribution $D$ that possesses low-degree\nsum-of-squares certificates of two natural analytic properties: 1)\nanti-concentration of one-dimensional marginals and 2) hypercontractivity of\ndegree 2 polynomials.\n  Prior to our work, the only known results for estimating covariance in the\nlist-decodable setting were for the special cases of list-decodable linear\nregression and subspace recovery due to Karmarkar, Klivans, and Kothari (2019),\nRaghavendra and Yau (2019 and 2020) and Bakshi and Kothari (2020). These\nresults need superpolynomial time for obtaining any subconstant error in the\nunderlying dimension. Our result implies the first polynomial-time \\emph{exact}\nalgorithm for list-decodable linear regression and subspace recovery that\nallows, in particular, to obtain $2^{-\\mathsf{poly}(d)}$ error in\npolynomial-time. Our result also implies an improved algorithm for clustering\nnon-spherical mixtures.\n",
                "链接": "https://arxiv.org/abs/2206.10942"
            },
            {
                "文章ID": "83545",
                "标题": "Discussion Paper: The Threat of Real Time Deepfakes",
                "作者": " Guy Frankovits,  Yisroel Mirsky",
                "发布日期": "2023-06-06",
                "摘要": "  Generative deep learning models are able to create realistic audio and video.\nThis technology has been used to impersonate the faces and voices of\nindividuals. These ``deepfakes'' are being used to spread misinformation,\nenable scams, perform fraud, and blackmail the innocent. The technology\ncontinues to advance and today attackers have the ability to generate deepfakes\nin real-time. This new capability poses a significant threat to society as\nattackers begin to exploit the technology in advances social engineering\nattacks. In this paper, we discuss the implications of this emerging threat,\nidentify the challenges with preventing these attacks and suggest a better\ndirection for researching stronger defences.\n",
                "链接": "https://arxiv.org/abs/2306.02487"
            },
            {
                "文章ID": "21714",
                "标题": "List-Decodable Sparse Mean Estimation",
                "作者": " Shiwei Zeng,  Jie Shen",
                "发布日期": "2022-12-07",
                "摘要": "  Robust mean estimation is one of the most important problems in statistics:\ngiven a set of samples in $\\mathbb{R}^d$ where an $\\alpha$ fraction are drawn\nfrom some distribution $D$ and the rest are adversarially corrupted, we aim to\nestimate the mean of $D$. A surge of recent research interest has been focusing\non the list-decodable setting where $\\alpha \\in (0, \\frac12]$, and the goal is\nto output a finite number of estimates among which at least one approximates\nthe target mean. In this paper, we consider that the underlying distribution\n$D$ is Gaussian with $k$-sparse mean. Our main contribution is the first\npolynomial-time algorithm that enjoys sample complexity $O\\big(\\mathrm{poly}(k,\n\\log d)\\big)$, i.e. poly-logarithmic in the dimension. One of our core\nalgorithmic ingredients is using low-degree sparse polynomials to filter\noutliers, which may find more applications.\n",
                "链接": "https://arxiv.org/abs/2205.14337"
            },
            {
                "文章ID": "47574",
                "标题": "A Characterization of List Learnability",
                "作者": " Moses Charikar,  Chirag Pabbaraju",
                "发布日期": "2023-03-28",
                "摘要": "  A classical result in learning theory shows the equivalence of PAC\nlearnability of binary hypothesis classes and the finiteness of VC dimension.\nExtending this to the multiclass setting was an open problem, which was settled\nin a recent breakthrough result characterizing multiclass PAC learnability via\nthe DS dimension introduced earlier by Daniely and Shalev-Shwartz. In this work\nwe consider list PAC learning where the goal is to output a list of $k$\npredictions. List learning algorithms have been developed in several settings\nbefore and indeed, list learning played an important role in the recent\ncharacterization of multiclass learnability. In this work we ask: when is it\npossible to $k$-list learn a hypothesis class? We completely characterize\n$k$-list learnability in terms of a generalization of DS dimension that we call\nthe $k$-DS dimension. Generalizing the recent characterization of multiclass\nlearnability, we show that a hypothesis class is $k$-list learnable if and only\nif the $k$-DS dimension is finite.\n",
                "链接": "https://arxiv.org/abs/2211.04956"
            },
            {
                "文章ID": "78248",
                "标题": "Online List Labeling with Predictions",
                "作者": " Samuel McCauley,  Benjamin Moseley,  Aidin Niaparast,  Shikha Singh",
                "发布日期": "2023-06-21",
                "摘要": "  A growing line of work shows how learned predictions can be used to break\nthrough worst-case barriers to improve the running time of an algorithm.\nHowever, incorporating predictions into data structures with strong theoretical\nguarantees remains underdeveloped. This paper takes a step in this direction by\nshowing that predictions can be leveraged in the fundamental online list\nlabeling problem. In the problem, n items arrive over time and must be stored\nin sorted order in an array of size Theta(n). The array slot of an element is\nits label and the goal is to maintain sorted order while minimizing the total\nnumber of elements moved (i.e., relabeled). We design a new list labeling data\nstructure and bound its performance in two models. In the worst-case\nlearning-augmented model, we give guarantees in terms of the error in the\npredictions. Our data structure provides strong guarantees: it is optimal for\nany prediction error and guarantees the best-known worst-case bound even when\nthe predictions are entirely erroneous. We also consider a stochastic error\nmodel and bound the performance in terms of the expectation and variance of the\nerror. Finally, the theoretical results are demonstrated empirically. In\nparticular, we show that our data structure has strong performance on real\ntemporal data sets where predictions are constructed from elements that arrived\nin the past, as is typically done in a practical use case.\n",
                "链接": "https://arxiv.org/abs/2305.10536"
            },
            {
                "文章ID": "40312",
                "标题": "SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis",
                "作者": " Jiaxin Pei,  Vítor Silva,  Maarten Bos,  Yozon Liu,  Leonardo Neves,  David Jurgens,  Francesco Barbieri",
                "发布日期": "2023-02-06",
                "摘要": "  We propose MINT, a new Multilingual INTimacy analysis dataset covering 13,372\ntweets in 10 languages including English, French, Spanish, Italian, Portuguese,\nKorean, Dutch, Chinese, Hindi, and Arabic. We benchmarked a list of popular\nmultilingual pre-trained language models. The dataset is released along with\nthe SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis\n(https://sites.google.com/umich.edu/semeval-2023-tweet-intimacy).\n",
                "链接": "https://arxiv.org/abs/2210.01108"
            }
        ]
    },
    {
        "question": {
            "question": "请列出近一年来工业界发表的搜广推工作落地实践的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "90924",
                "标题": "Digital Health Discussion Through Articles Published Until the Year\n  2021: A Digital Topic Modeling Approach",
                "作者": " Junhyoun Sung,  Hyungsook Kim",
                "发布日期": "2023-09-20",
                "摘要": "  The digital health industry has grown in popularity since the 2010s, but\nthere has been limited analysis of the topics discussed in the field across\nacademic disciplines. This study aims to analyze the research trends of digital\nhealth-related articles published on the Web of Science until 2021, in order to\nunderstand the concentration, scope, and characteristics of the research.\n15,950 digital health-related papers from the top 10 academic fields were\nanalyzed using the Web of Science. The papers were grouped into three domains:\npublic health, medicine, and electrical engineering and computer science\n(EECS). Two time periods (2012-2016 and 2017-2021) were compared using Latent\nDirichlet Allocation (LDA) for topic modeling. The number of topics was\ndetermined based on coherence score, and topic compositions were compared using\na homogeneity test. The number of optimal topics varied across domains and time\nperiods. For public health, the first and second halves had 13 and 19 topics,\nrespectively. Medicine had 14 and 25 topics, and EECS had 7 and 21 topics. Text\nanalysis revealed shared topics among the domains, but with variations in\ncomposition. The homogeneity test confirmed significant differences between the\ngroups (adjusted p-value<0.05). Six dominant themes emerged, including journal\narticle methodology, information technology, medical issues, population\ndemographics, social phenomena, and healthcare. Digital health research is\nexpanding and evolving, particularly in relation to Covid-19, where topics such\nas depression and mental disorders, education, and physical activity have\ngained prominence. There was no bias in topic composition among the three\ndomains, but other fields like kinesiology or psychology could contribute to\nfuture digital health research. Exploring expanded topics that reflect people's\nneeds for digital health over time will be crucial.\n",
                "链接": "https://arxiv.org/abs/2307.07130"
            },
            {
                "文章ID": "110217",
                "标题": "The Past, Present, and Future of Typological Databases in NLP",
                "作者": " Emi Baylor,  Esther Ploeger,  Johannes Bjerva",
                "发布日期": "2023-10-23",
                "摘要": "  Typological information has the potential to be beneficial in the development\nof NLP models, particularly for low-resource languages. Unfortunately, current\nlarge-scale typological databases, notably WALS and Grambank, are inconsistent\nboth with each other and with other sources of typological information, such as\nlinguistic grammars. Some of these inconsistencies stem from coding errors or\nlinguistic variation, but many of the disagreements are due to the discrete\ncategorical nature of these databases. We shed light on this issue by\nsystematically exploring disagreements across typological databases and\nresources, and their uses in NLP, covering the past and present. We next\ninvestigate the future of such work, offering an argument that a continuous\nview of typological features is clearly beneficial, echoing recommendations\nfrom linguistics. We propose that such a view of typology has significant\npotential in the future, including in language modeling in low-resource\nscenarios.\n",
                "链接": "https://arxiv.org/abs/2310.13440"
            },
            {
                "文章ID": "81304",
                "标题": "Inferring the Future by Imagining the Past",
                "作者": " Kartik Chandra,  Tony Chen,  Tzu-Mao Li,  Jonathan Ragan-Kelley,  Josh Tenenbaum",
                "发布日期": "2023-10-31",
                "摘要": "  A single panel of a comic book can say a lot: it can depict not only where\nthe characters currently are, but also their motions, their motivations, their\nemotions, and what they might do next. More generally, humans routinely infer\ncomplex sequences of past and future events from a *static snapshot* of a\n*dynamic scene*, even in situations they have never seen before.\n  In this paper, we model how humans make such rapid and flexible inferences.\nBuilding on a long line of work in cognitive science, we offer a Monte Carlo\nalgorithm whose inferences correlate well with human intuitions in a wide\nvariety of domains, while only using a small, cognitively-plausible number of\nsamples. Our key technical insight is a surprising connection between our\ninference problem and Monte Carlo path tracing, which allows us to apply\ndecades of ideas from the computer graphics community to this\nseemingly-unrelated theory of mind task.\n",
                "链接": "https://arxiv.org/abs/2305.17195"
            },
            {
                "文章ID": "109901",
                "标题": "Predict the Future from the Past? On the Temporal Data Distribution\n  Shift in Financial Sentiment Classifications",
                "作者": " Yue Guo,  Chenxi Hu,  Yi Yang",
                "发布日期": "2023-10-20",
                "摘要": "  Temporal data distribution shift is prevalent in the financial text. How can\na financial sentiment analysis system be trained in a volatile market\nenvironment that can accurately infer sentiment and be robust to temporal data\ndistribution shifts? In this paper, we conduct an empirical study on the\nfinancial sentiment analysis system under temporal data distribution shifts\nusing a real-world financial social media dataset that spans three years. We\nfind that the fine-tuned models suffer from general performance degradation in\nthe presence of temporal distribution shifts. Furthermore, motivated by the\nunique temporal nature of the financial text, we propose a novel method that\ncombines out-of-distribution detection with time series modeling for temporal\nfinancial sentiment analysis. Experimental results show that the proposed\nmethod enhances the model's capability to adapt to evolving temporal shifts in\na volatile financial market.\n",
                "链接": "https://arxiv.org/abs/2310.12620"
            },
            {
                "文章ID": "95785",
                "标题": "Recent Advancements In The Field Of Deepfake Detection",
                "作者": " Natalie Krueger,  Dr. Mounika Vanamala,  Dr. Rushit Dave",
                "发布日期": "2023-08-11",
                "摘要": "  A deepfake is a photo or video of a person whose image has been digitally\naltered or partially replaced with an image of someone else. Deepfakes have the\npotential to cause a variety of problems and are often used maliciously. A\ncommon usage is altering videos of prominent political figures and celebrities.\nThese deepfakes can portray them making offensive, problematic, and/or untrue\nstatements. Current deepfakes can be very realistic, and when used in this way,\ncan spread panic and even influence elections and political opinions. There are\nmany deepfake detection strategies currently in use but finding the most\ncomprehensive and universal method is critical. So, in this survey we will\naddress the problems of malicious deepfake creation and the lack of universal\ndeepfake detection methods. Our objective is to survey and analyze a variety of\ncurrent methods and advances in the field of deepfake detection.\n",
                "链接": "https://arxiv.org/abs/2308.05563"
            },
            {
                "文章ID": "107051",
                "标题": "Commercialized Generative AI: A Critical Study of the Feasibility and\n  Ethics of Generating Native Advertising Using Large Language Models in\n  Conversational Web Search",
                "作者": " Ines Zelch,  Matthias Hagen,  Martin Potthast",
                "发布日期": "2023-10-10",
                "摘要": "  How will generative AI pay for itself? Unless charging users for access,\nselling advertising is the only alternative. Especially in the multi-billion\ndollar web search market with ads as the main source of revenue, the\nintroduction of a subscription model seems unlikely. The recent disruption of\nsearch by generative large language models could thus ultimately be accompanied\nby generated ads. Our concern is that the commercialization of generative AI in\ngeneral and large language models in particular could lead to native\nadvertising in the form of quite subtle brand or product placements. In web\nsearch, the evolution of search engine results pages (SERPs) from traditional\nlists of ``ten blue links'' (lists SERPs) to generated text with web page\nreferences (text SERPs) may further blur the line between advertising-based and\norganic search results, making it difficult for users to distinguish between\nthe two, depending on how advertising is integrated and disclosed. To raise\nawareness of this potential development, we conduct a pilot study analyzing the\ncapabilities of current large language models to blend ads with organic search\nresults. Although the models still struggle to subtly frame ads in an unrelated\ncontext, their potential is evident when integrating ads into related topics\nwhich calls for further investigation.\n",
                "链接": "https://arxiv.org/abs/2310.04892"
            },
            {
                "文章ID": "108276",
                "标题": "The Search-and-Mix Paradigm in Approximate Nash Equilibrium Algorithms",
                "作者": " Xiaotie Deng,  Dongchen Li,  Hanyu Li",
                "发布日期": "2023-10-13",
                "摘要": "  AI in Math deals with mathematics in a constructive manner so that reasoning\nbecomes automated, less laborious, and less error-prone. For algorithms, the\nquestion becomes how to automate analyses for specific problems. For the first\ntime, this work provides an automatic method for approximation analysis on a\nwell-studied problem in theoretical computer science: computing approximate\nNash equilibria in two-player games. We observe that such algorithms can be\nreformulated into a search-and-mix paradigm, which involves a search phase\nfollowed by a mixing phase. By doing so, we are able to fully automate the\nprocedure of designing and analyzing the mixing phase. For example, we\nillustrate how to perform our method with a program to analyze the\napproximation bounds of all the algorithms in the literature. Same\napproximation bounds are computed without any hand-written proof. Our automatic\nmethod heavily relies on the LP-relaxation structure in approximate Nash\nequilibria. Since many approximation algorithms and online algorithms adopt the\nLP relaxation, our approach may be extended to automate the analysis of other\nalgorithms.\n",
                "链接": "https://arxiv.org/abs/2310.08066"
            },
            {
                "文章ID": "83698",
                "标题": "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy\n  Actor-Critic",
                "作者": " Tianying Ji,  Yu Luo,  Fuchun Sun,  Xianyuan Zhan,  Jianwei Zhang,  Huazhe Xu",
                "发布日期": "2023-10-16",
                "摘要": "  Learning high-quality Q-value functions plays a key role in the success of\nmany modern off-policy deep reinforcement learning (RL) algorithms. Previous\nworks focus on addressing the value overestimation issue, an outcome of\nadopting function approximators and off-policy learning. Deviating from the\ncommon viewpoint, we observe that Q-values are indeed underestimated in the\nlatter stage of the RL training process, primarily related to the use of\ninferior actions from the current policy in Bellman updates as compared to the\nmore optimal action samples in the replay buffer. We hypothesize that this\nlong-neglected phenomenon potentially hinders policy learning and reduces\nsample efficiency. Our insight to address this issue is to incorporate\nsufficient exploitation of past successes while maintaining exploration\noptimism. We propose the Blended Exploitation and Exploration (BEE) operator, a\nsimple yet effective approach that updates Q-value using both historical\nbest-performing actions and the current policy. The instantiations of our\nmethod in both model-free and model-based settings outperform state-of-the-art\nmethods in various continuous control tasks and achieve strong performance in\nfailure-prone scenarios and real-world robot tasks.\n",
                "链接": "https://arxiv.org/abs/2306.02865"
            },
            {
                "文章ID": "102770",
                "标题": "Looking through the past: better knowledge retention for generative\n  replay in continual learning",
                "作者": " Valeriya Khan,  Sebastian Cygert,  Kamil Deja,  Tomasz Trzciński,  Bartłomiej Twardowski",
                "发布日期": "2023-09-20",
                "摘要": "  In this work, we improve the generative replay in a continual learning\nsetting to perform well on challenging scenarios. Current generative rehearsal\nmethods are usually benchmarked on small and simple datasets as they are not\npowerful enough to generate more complex data with a greater number of classes.\nWe notice that in VAE-based generative replay, this could be attributed to the\nfact that the generated features are far from the original ones when mapped to\nthe latent space. Therefore, we propose three modifications that allow the\nmodel to learn and generate complex data. More specifically, we incorporate the\ndistillation in latent space between the current and previous models to reduce\nfeature drift. Additionally, a latent matching for the reconstruction and\noriginal data is proposed to improve generated features alignment. Further,\nbased on the observation that the reconstructions are better for preserving\nknowledge, we add the cycling of generations through the previously trained\nmodel to make them closer to the original data. Our method outperforms other\ngenerative replay methods in various scenarios. Code available at\nhttps://github.com/valeriya-khan/looking-through-the-past.\n",
                "链接": "https://arxiv.org/abs/2309.10012"
            },
            {
                "文章ID": "110649",
                "标题": "Large Search Model: Redefining Search Stack in the Era of LLMs",
                "作者": " Liang Wang,  Nan Yang,  Xiaolong Huang,  Linjun Yang,  Rangan Majumder,  Furu Wei",
                "发布日期": "2023-10-24",
                "摘要": "  Modern search engines are built on a stack of different components, including\nquery understanding, retrieval, multi-stage ranking, and question answering,\namong others. These components are often optimized and deployed independently.\nIn this paper, we introduce a novel conceptual framework called large search\nmodel, which redefines the conventional search stack by unifying search tasks\nwith one large language model (LLM). All tasks are formulated as autoregressive\ntext generation problems, allowing for the customization of tasks through the\nuse of natural language prompts. This proposed framework capitalizes on the\nstrong language understanding and reasoning capabilities of LLMs, offering the\npotential to enhance search result quality while simultaneously simplifying the\nexisting cumbersome search stack. To substantiate the feasibility of this\nframework, we present a series of proof-of-concept experiments and discuss the\npotential challenges associated with implementing this approach within\nreal-world search systems.\n",
                "链接": "https://arxiv.org/abs/2310.14587"
            }
        ]
    },
    {
        "question": {
            "question": "闭源大模型用户数据隐私保护研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "106181",
                "标题": "Large Language Models Can Be Good Privacy Protection Learners",
                "作者": " Yijia Xiao,  Yiqiao Jin,  Yushi Bai,  Yue Wu,  Xianjun Yang,  Xiao Luo,  Wenchao Yu,  Xujiang Zhao,  Yanchi Liu,  Haifeng Chen,  Wei Wang,  Wei Cheng",
                "发布日期": "2023-10-10",
                "摘要": "  The proliferation of Large Language Models (LLMs) has driven considerable\ninterest in fine-tuning them with domain-specific data to create specialized\nlanguage models. Nevertheless, such domain-specific fine-tuning data often\ncontains sensitive personally identifiable information (PII). Direct\nfine-tuning LLMs on this data without privacy protection poses a risk of\nleakage. To address this challenge, we introduce Privacy Protection Language\nModels (PPLM), a novel paradigm for fine-tuning LLMs that effectively injects\ndomain-specific knowledge while safeguarding data privacy. Our work offers a\ntheoretical analysis for model design and delves into various techniques such\nas corpus curation, penalty-based unlikelihood in training loss, and\ninstruction-based tuning, etc. Extensive experiments across diverse datasets\nand scenarios demonstrate the effectiveness of our approaches. In particular,\ninstruction tuning with both positive and negative examples, stands out as a\npromising method, effectively protecting private data while enhancing the\nmodel's knowledge. Our work underscores the potential for Large Language Models\nas robust privacy protection learners.\n",
                "链接": "https://arxiv.org/abs/2310.02469"
            },
            {
                "文章ID": "5282",
                "标题": "Privacy protection based on mask template",
                "作者": " Hao Wang,  Yu Bai,  Guangmin Sun,  Jie Liu",
                "发布日期": "2022-02-15",
                "摘要": "  Powerful recognition algorithms are widely used in the Internet or important\nmedical systems, which poses a serious threat to personal privacy. Although the\nlaw provides for diversity protection, e.g. The General Data Protection\nRegulation (GDPR) in Europe and Articles 1032 to 1039 of the civil code in\nChina. However, as an important privacy disclosure event, biometric data is\noften hidden, which is difficult for the owner to detect and trace to the\nsource. Human biometrics generally exist in images. In order to avoid the\ndisclosure of personal privacy, we should prevent unauthorized recognition\nalgorithms from acquiring the real features of the original image.\n",
                "链接": "https://arxiv.org/abs/2202.06250"
            },
            {
                "文章ID": "24967",
                "标题": "Adversarial Privacy Protection on Speech Enhancement",
                "作者": " Mingyu Dong,  Diqun Yan,  Rangding Wang",
                "发布日期": "2022-06-17",
                "摘要": "  Speech is easily leaked imperceptibly, such as being recorded by mobile\nphones in different situations. Private content in speech may be maliciously\nextracted through speech enhancement technology. Speech enhancement technology\nhas developed rapidly along with deep neural networks (DNNs), but adversarial\nexamples can cause DNNs to fail. In this work, we propose an adversarial method\nto degrade speech enhancement systems. Experimental results show that generated\nadversarial examples can erase most content information in original examples or\nreplace it with target speech content through speech enhancement. The word\nerror rate (WER) between an enhanced original example and enhanced adversarial\nexample recognition result can reach 89.0%. WER of target attack between\nenhanced adversarial example and target example is low to 33.75% . Adversarial\nperturbation can bring the rate of change to the original example to more than\n1.4430. This work can prevent the malicious extraction of speech.\n",
                "链接": "https://arxiv.org/abs/2206.08170"
            },
            {
                "文章ID": "111984",
                "标题": "$\\alpha$-Mutual Information: A Tunable Privacy Measure for Privacy\n  Protection in Data Sharing",
                "作者": " MirHamed Jafarzadeh Asl,  Mohammadhadi Shateri,  Fabrice Labeau",
                "发布日期": "2023-10-30",
                "摘要": "  This paper adopts Arimoto's $\\alpha$-Mutual Information as a tunable privacy\nmeasure, in a privacy-preserving data release setting that aims to prevent\ndisclosing private data to adversaries. By fine-tuning the privacy metric, we\ndemonstrate that our approach yields superior models that effectively thwart\nattackers across various performance dimensions. We formulate a general\ndistortion-based mechanism that manipulates the original data to offer privacy\nprotection. The distortion metrics are determined according to the data\nstructure of a specific experiment. We confront the problem expressed in the\nformulation by employing a general adversarial deep learning framework that\nconsists of a releaser and an adversary, trained with opposite goals. This\nstudy conducts empirical experiments on images and time-series data to verify\nthe functionality of $\\alpha$-Mutual Information. We evaluate the\nprivacy-utility trade-off of customized models and compare them to mutual\ninformation as the baseline measure. Finally, we analyze the consequence of an\nattacker's access to side information about private data and witness that\nadapting the privacy measure results in a more refined model than the\nstate-of-the-art in terms of resiliency against side information.\n",
                "链接": "https://arxiv.org/abs/2310.18241"
            },
            {
                "文章ID": "64631",
                "标题": "Developers Need Protection, Too: Perspectives and Research Challenges\n  for Privacy in Social Coding Platforms",
                "作者": " Nicolás E. Díaz Ferreyra,  Abdessamad Imine,  Melina Vidoni,  Riccardo Scandariato",
                "发布日期": "2023-03-06",
                "摘要": "  Social Coding Platforms (SCPs) like GitHub have become central to modern\nsoftware engineering thanks to their collaborative and version-control\nfeatures. Like in mainstream Online Social Networks (OSNs) such as Facebook,\nusers of SCPs are subjected to privacy attacks and threats given the high\namounts of personal and project-related data available in their profiles and\nsoftware repositories. However, unlike in OSNs, the privacy concerns and\npractices of SCP users have not been extensively explored nor documented in the\ncurrent literature. In this work, we present the preliminary results of an\nonline survey (N=105) addressing developers' concerns and perceptions about\nprivacy threats steaming from SCPs. Our results suggest that, although users\nexpress concern about social and organisational privacy threats, they often\nfeel safe sharing personal and project-related information on these platforms.\nMoreover, attacks targeting the inference of sensitive attributes are\nconsidered more likely than those seeking to re-identify source-code\ncontributors. Based on these findings, we propose a set of recommendations for\nfuture investigations addressing privacy and identity management in SCPs.\n",
                "链接": "https://arxiv.org/abs/2303.01822"
            },
            {
                "文章ID": "1657",
                "标题": "Tutela: An Open-Source Tool for Assessing User-Privacy on Ethereum and\n  Tornado Cash",
                "作者": " Mike Wu,  Will McTighe,  Kaili Wang,  Istvan A. Seres,  Nick Bax,  Manuel Puebla,  Mariano Mendez,  Federico Carrone,  Tomás De Mattey,  Herman O. Demaestri,  Mariano Nicolini,  Pedro Fontana",
                "发布日期": "2022-01-19",
                "摘要": "  A common misconception among blockchain users is that pseudonymity guarantees\nprivacy. The reality is almost the opposite. Every transaction one makes is\nrecorded on a public ledger and reveals information about one's identity.\nMixers, such as Tornado Cash, were developed to preserve privacy through\n\"mixing\" transactions with those of others in an anonymity pool, making it\nharder to link deposits and withdrawals from the pool. Unfortunately, it is\nstill possible to reveal information about those in the anonymity pool if users\nare not careful. We introduce Tutela, an application built on expert heuristics\nto report the true anonymity of an Ethereum address. In particular, Tutela has\nthree functionalities: first, it clusters together Ethereum addresses based on\ninteraction history such that for an Ethereum address, we can identify other\naddresses likely owned by the same entity; second, it shows Ethereum users\ntheir potentially compromised transactions; third, Tutela computes the true\nsize of the anonymity pool of each Tornado Cash mixer by excluding potentially\ncompromised transactions. A public implementation of Tutela can be found at\nhttps://github.com/TutelaLabs/tutela-app. To use Tutela, visit\nhttps://www.tutela.xyz.\n",
                "链接": "https://arxiv.org/abs/2201.06811"
            },
            {
                "文章ID": "76951",
                "标题": "ONCE: Boosting Content-based Recommendation with Both Open- and\n  Closed-source Large Language Models",
                "作者": " Qijiong Liu,  Nuo Chen,  Tetsuya Sakai,  Xiao-Ming Wu",
                "发布日期": "2023-09-01",
                "摘要": "  Personalized content-based recommender systems have become indispensable\ntools for users to navigate through the vast amount of content available on\nplatforms like daily news websites and book recommendation services. However,\nexisting recommenders face significant challenges in understanding the content\nof items. Large language models (LLMs), which possess deep semantic\ncomprehension and extensive knowledge from pretraining, have proven to be\neffective in various natural language processing tasks. In this study, we\nexplore the potential of leveraging both open- and closed-source LLMs to\nenhance content-based recommendation. With open-source LLMs, we utilize their\ndeep layers as content encoders, enriching the representation of content at the\nembedding level. For closed-source LLMs, we employ prompting techniques to\nenrich the training data at the token level. Through comprehensive experiments,\nwe demonstrate the high effectiveness of both types of LLMs and show the\nsynergistic relationship between them. Notably, we observed a significant\nrelative improvement of up to 19.32% compared to existing state-of-the-art\nrecommendation models. These findings highlight the immense potential of both\nopen- and closed-source of LLMs in enhancing content-based recommendation\nsystems. We will make our code and LLM-generated data available for other\nresearchers to reproduce our results.\n",
                "链接": "https://arxiv.org/abs/2305.06566"
            },
            {
                "文章ID": "123540",
                "标题": "User Modeling in the Era of Large Language Models: Current Research and\n  Future Directions",
                "作者": " Zhaoxuan Tan,  Meng Jiang",
                "发布日期": "2023-12-27",
                "摘要": "  User modeling (UM) aims to discover patterns or learn representations from\nuser data about the characteristics of a specific user, such as profile,\npreference, and personality. The user models enable personalization and\nsuspiciousness detection in many online applications such as recommendation,\neducation, and healthcare. Two common types of user data are text and graph, as\nthe data usually contain a large amount of user-generated content (UGC) and\nonline interactions. The research of text and graph mining is developing\nrapidly, contributing many notable solutions in the past two decades. Recently,\nlarge language models (LLMs) have shown superior performance on generating,\nunderstanding, and even reasoning over text data. The approaches of user\nmodeling have been equipped with LLMs and soon become outstanding. This article\nsummarizes existing research about how and why LLMs are great tools of modeling\nand understanding UGC. Then it reviews a few categories of large language\nmodels for user modeling (LLM-UM) approaches that integrate the LLMs with text\nand graph-based methods in different ways. Then it introduces specific LLM-UM\ntechniques for a variety of UM applications. Finally, it presents remaining\nchallenges and future directions in the LLM-UM research. We maintain the\nreading list at: https://github.com/TamSiuhin/LLM-UM-Reading\n",
                "链接": "https://arxiv.org/abs/2312.11518"
            },
            {
                "文章ID": "98333",
                "标题": "Harnessing the Power of David against Goliath: Exploring Instruction\n  Data Generation without Using Closed-Source Models",
                "作者": " Yue Wang,  Xinrui Wang,  Juntao Li,  Jinxiong Chang,  Qishen Zhang,  Zhongyi Liu,  Guannan Zhang,  Min Zhang",
                "发布日期": "2023-08-25",
                "摘要": "  Instruction tuning is instrumental in enabling Large Language Models~(LLMs)\nto follow user instructions to complete various open-domain tasks. The success\nof instruction tuning depends on the availability of high-quality instruction\ndata. Owing to the exorbitant cost and substandard quality of human annotation,\nrecent works have been deeply engaged in the exploration of the utilization of\npowerful closed-source models to generate instruction data automatically.\nHowever, these methods carry potential risks arising from the usage\nrequirements of powerful closed-source models, which strictly forbid the\nutilization of their outputs to develop machine learning models. To deal with\nthis problem, in this work, we explore alternative approaches to generate\nhigh-quality instruction data that do not rely on closed-source models. Our\nexploration includes an investigation of various existing instruction\ngeneration methods, culminating in the integration of the most efficient\nvariant with two novel strategies to enhance the quality further. Evaluation\nresults from two benchmarks and the GPT-4 model demonstrate the effectiveness\nof our generated instruction data, which can outperform Alpaca, a method\nreliant on closed-source models. We hope that more progress can be achieved in\ngenerating high-quality instruction data without using closed-source models.\n",
                "链接": "https://arxiv.org/abs/2308.12711"
            },
            {
                "文章ID": "101319",
                "标题": "Diff-Privacy: Diffusion-based Face Privacy Protection",
                "作者": " Xiao He,  Mingrui Zhu,  Dongxin Chen,  Nannan Wang,  Xinbo Gao",
                "发布日期": "2023-09-12",
                "摘要": "  Privacy protection has become a top priority as the proliferation of AI\ntechniques has led to widespread collection and misuse of personal data.\nAnonymization and visual identity information hiding are two important facial\nprivacy protection tasks that aim to remove identification characteristics from\nfacial images at the human perception level. However, they have a significant\ndifference in that the former aims to prevent the machine from recognizing\ncorrectly, while the latter needs to ensure the accuracy of machine\nrecognition. Therefore, it is difficult to train a model to complete these two\ntasks simultaneously. In this paper, we unify the task of anonymization and\nvisual identity information hiding and propose a novel face privacy protection\nmethod based on diffusion models, dubbed Diff-Privacy. Specifically, we train\nour proposed multi-scale image inversion module (MSI) to obtain a set of SDM\nformat conditional embeddings of the original image. Based on the conditional\nembeddings, we design corresponding embedding scheduling strategies and\nconstruct different energy functions during the denoising process to achieve\nanonymization and visual identity information hiding. Extensive experiments\nhave been conducted to validate the effectiveness of our proposed framework in\nprotecting facial privacy.\n",
                "链接": "https://arxiv.org/abs/2309.05330"
            }
        ]
    },
    {
        "question": {
            "question": "推荐与AutoGPT相似的10篇文献",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "86417",
                "标题": "AD-AutoGPT: An Autonomous GPT for Alzheimer's Disease Infodemiology",
                "作者": " Haixing Dai,  Yiwei Li,  Zhengliang Liu,  Lin Zhao,  Zihao Wu,  Suhang Song,  Ye Shen,  Dajiang Zhu,  Xiang Li,  Sheng Li,  Xiaobai Yao,  Lu Shi,  Quanzheng Li,  Zhuo Chen,  Donglan Zhang,  Gengchen Mai,  Tianming Liu",
                "发布日期": "2023-06-21",
                "摘要": "  In this pioneering study, inspired by AutoGPT, the state-of-the-art\nopen-source application based on the GPT-4 large language model, we develop a\nnovel tool called AD-AutoGPT which can conduct data collection, processing, and\nanalysis about complex health narratives of Alzheimer's Disease in an\nautonomous manner via users' textual prompts. We collated comprehensive data\nfrom a variety of news sources, including the Alzheimer's Association, BBC,\nMayo Clinic, and the National Institute on Aging since June 2022, leading to\nthe autonomous execution of robust trend analyses, intertopic distance maps\nvisualization, and identification of salient terms pertinent to Alzheimer's\nDisease. This approach has yielded not only a quantifiable metric of relevant\ndiscourse but also valuable insights into public focus on Alzheimer's Disease.\nThis application of AD-AutoGPT in public health signifies the transformative\npotential of AI in facilitating a data-rich understanding of complex health\nnarratives like Alzheimer's Disease in an autonomous manner, setting the\ngroundwork for future AI-driven investigations in global health landscapes.\n",
                "链接": "https://arxiv.org/abs/2306.10095"
            },
            {
                "文章ID": "31207",
                "标题": "AutoTransition: Learning to Recommend Video Transition Effects",
                "作者": " Yaojie Shen,  Libo Zhang,  Kai Xu,  Xiaojie Jin",
                "发布日期": "2022-07-28",
                "摘要": "  Video transition effects are widely used in video editing to connect shots\nfor creating cohesive and visually appealing videos. However, it is challenging\nfor non-professionals to choose best transitions due to the lack of\ncinematographic knowledge and design skills. In this paper, we present the\npremier work on performing automatic video transitions recommendation (VTR):\ngiven a sequence of raw video shots and companion audio, recommend video\ntransitions for each pair of neighboring shots. To solve this task, we collect\na large-scale video transition dataset using publicly available video templates\non editing softwares. Then we formulate VTR as a multi-modal retrieval problem\nfrom vision/audio to video transitions and propose a novel multi-modal matching\nframework which consists of two parts. First we learn the embedding of video\ntransitions through a video transition classification task. Then we propose a\nmodel to learn the matching correspondence from vision/audio inputs to video\ntransitions. Specifically, the proposed model employs a multi-modal transformer\nto fuse vision and audio information, as well as capture the context cues in\nsequential transition outputs. Through both quantitative and qualitative\nexperiments, we clearly demonstrate the effectiveness of our method. Notably,\nin the comprehensive user study, our method receives comparable scores compared\nwith professional editors while improving the video editing efficiency by\n\\textbf{300\\scalebox{1.25}{$\\times$}}. We hope our work serves to inspire other\nresearchers to work on this new task. The dataset and codes are public at\n\\url{https://github.com/acherstyx/AutoTransition}.\n",
                "链接": "https://arxiv.org/abs/2207.13479"
            },
            {
                "文章ID": "91549",
                "标题": "REX: Rapid Exploration and eXploitation for AI Agents",
                "作者": " Rithesh Murthy,  Shelby Heinecke,  Juan Carlos Niebles,  Zhiwei Liu,  Le Xue,  Weiran Yao,  Yihao Feng,  Zeyuan Chen,  Akash Gokul,  Devansh Arpit,  Ran Xu,  Phil Mui,  Huan Wang,  Caiming Xiong,  Silvio Savarese",
                "发布日期": "2023-07-19",
                "摘要": "  In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.\n",
                "链接": "https://arxiv.org/abs/2307.08962"
            },
            {
                "文章ID": "60093",
                "标题": "Precursor recommendation for inorganic synthesis by machine learning\n  materials similarity from scientific literature",
                "作者": " Tanjin He,  Haoyan Huo,  Christopher J. Bartel,  Zheren Wang,  Kevin Cruse,  Gerbrand Ceder",
                "发布日期": "2023-06-13",
                "摘要": "  Synthesis prediction is a key accelerator for the rapid design of advanced\nmaterials. However, determining synthesis variables such as the choice of\nprecursor materials is challenging for inorganic materials because the sequence\nof reactions during heating is not well understood. In this work, we use a\nknowledge base of 29,900 solid-state synthesis recipes, text-mined from the\nscientific literature, to automatically learn which precursors to recommend for\nthe synthesis of a novel target material. The data-driven approach learns\nchemical similarity of materials and refers the synthesis of a new target to\nprecedent synthesis procedures of similar materials, mimicking human synthesis\ndesign. When proposing five precursor sets for each of 2,654 unseen test target\nmaterials, the recommendation strategy achieves a success rate of at least 82%.\nOur approach captures decades of heuristic synthesis data in a mathematical\nform, making it accessible for use in recommendation engines and autonomous\nlaboratories.\n",
                "链接": "https://arxiv.org/abs/2302.02303"
            },
            {
                "文章ID": "75016",
                "标题": "Leveraging Data Mining Algorithms to Recommend Source Code Changes",
                "作者": " AmirHossein Naghshzan,  Saeed Khalilazar,  Pierre Poilane,  Olga Baysal,  Latifa Guerrouj,  Foutse Khomh",
                "发布日期": "2023-05-02",
                "摘要": "  Context: Recent research has used data mining to develop techniques that can\nguide developers through source code changes. To the best of our knowledge,\nvery few studies have investigated data mining techniques and--or compared\ntheir results with other algorithms or a baseline. Objectives: This paper\nproposes an automatic method for recommending source code changes using four\ndata mining algorithms. We not only use these algorithms to recommend source\ncode changes, but we also conduct an empirical evaluation. Methods: Our\ninvestigation includes seven open-source projects from which we extracted\nsource change history at the file level. We used four widely data mining\nalgorithms \\ie{} Apriori, FP-Growth, Eclat, and Relim to compare the algorithms\nin terms of performance (Precision, Recall and F-measure) and execution time.\nResults: Our findings provide empirical evidence that while some Frequent\nPattern Mining algorithms, such as Apriori may outperform other algorithms in\nsome cases, the results are not consistent throughout all the software\nprojects, which is more likely due to the nature and characteristics of the\nstudied projects, in particular their change history. Conclusion: Apriori seems\nappropriate for large-scale projects, whereas Eclat appears to be suitable for\nsmall-scale projects. Moreover, FP-Growth seems an efficient approach in terms\nof execution time.\n",
                "链接": "https://arxiv.org/abs/2305.00323"
            },
            {
                "文章ID": "123126",
                "标题": "Do Similar Entities have Similar Embeddings?",
                "作者": " Nicolas Hubert,  Heiko Paulheim,  Armelle Brun,  Davy Monticolo",
                "发布日期": "2023-12-19",
                "摘要": "  Knowledge graph embedding models (KGEMs) developed for link prediction learn\nvector representations for graph entities, known as embeddings. A common tacit\nassumption is the KGE entity similarity assumption, which states that these\nKGEMs retain the graph's structure within their embedding space, i.e., position\nsimilar entities close to one another. This desirable property make KGEMs\nwidely used in downstream tasks such as recommender systems or drug\nrepurposing. Yet, the alignment of graph similarity with embedding space\nsimilarity has rarely been formally evaluated. Typically, KGEMs are assessed\nbased on their sole link prediction capabilities, using ranked-based metrics\nsuch as Hits@K or Mean Rank. This paper challenges the prevailing assumption\nthat entity similarity in the graph is inherently mirrored in the embedding\nspace. Therefore, we conduct extensive experiments to measure the capability of\nKGEMs to cluster similar entities together, and investigate the nature of the\nunderlying factors. Moreover, we study if different KGEMs expose a different\nnotion of similarity. Datasets, pre-trained embeddings and code are available\nat: https://github.com/nicolas-hbt/similar-embeddings.\n",
                "链接": "https://arxiv.org/abs/2312.10370"
            },
            {
                "文章ID": "12284",
                "标题": "Learning to act: a Reinforcement Learning approach to recommend the best\n  next activities",
                "作者": " Stefano Branchi,  Chiara Di Francescomarino,  Chiara Ghidini,  David Massimo,  Francesco Ricci,  Massimiliano Ronzani",
                "发布日期": "2022-06-16",
                "摘要": "  The rise of process data availability has recently led to the development of\ndata-driven learning approaches. However, most of these approaches restrict the\nuse of the learned model to predict the future of ongoing process executions.\nThe goal of this paper is moving a step forward and leveraging available data\nto learning to act, by supporting users with recommendations derived from an\noptimal strategy (measure of performance). We take the optimization perspective\nof one process actor and we recommend the best activities to execute next, in\nresponse to what happens in a complex external environment, where there is no\ncontrol on exogenous factors. To this aim, we investigate an approach that\nlearns, by means of Reinforcement Learning, the optimal policy from the\nobservation of past executions and recommends the best activities to carry on\nfor optimizing a Key Performance Indicator of interest. The validity of the\napproach is demonstrated on two scenarios taken from real-life data.\n",
                "链接": "https://arxiv.org/abs/2203.15398"
            },
            {
                "文章ID": "119726",
                "标题": "A Hypergraph-Based Approach to Recommend Online Resources in a Library",
                "作者": " Debashish Roy,  Rajarshi Roy Chowdhury",
                "发布日期": "2023-12-05",
                "摘要": "  When users in a digital library read or browse online resources, it generates\nan immense amount of data. If the underlying system can recommend items, such\nas books and journals, to the users, it will help them to find the related\nitems. This research analyzes a digital library's usage data to recommend items\nto its users, and it uses different clustering algorithms to design the\nrecommender system. We have used content-based clustering, including\nhierarchical, expectation maximization (EM), K-mean, FarthestFirst, and\ndensity-based clustering algorithms, and user access pattern-based clustering,\nwhich uses a hypergraph-based approach to generate the clusters. This research\nshows that the recommender system designed using the hypergraph algorithm\ngenerates the most accurate recommendation model compared to those designed\nusing the content-based clustering approaches.\n",
                "链接": "https://arxiv.org/abs/2312.01007"
            },
            {
                "文章ID": "97565",
                "标题": "Age Recommendation from Texts and Sentences for Children",
                "作者": " Rashedur Rahman,  Gwénolé Lecorvé,  Nicolas Béchet",
                "发布日期": "2023-08-22",
                "摘要": "  Children have less text understanding capability than adults. Moreover, this\ncapability differs among the children of different ages. Hence, automatically\npredicting a recommended age based on texts or sentences would be a great\nbenefit to propose adequate texts to children and to help authors writing in\nthe most appropriate way. This paper presents our recent advances on the age\nrecommendation task. We consider age recommendation as a regression task, and\ndiscuss the need for appropriate evaluation metrics, study the use of\nstate-of-the-art machine learning model, namely Transformers, and compare it to\ndifferent models coming from the literature. Our results are also compared with\nrecommendations made by experts. Further, this paper deals with preliminary\nexplainability of the age prediction model by analyzing various linguistic\nfeatures. We conduct the experiments on a dataset of 3, 673 French texts (132K\nsentences, 2.5M words). To recommend age at the text level and sentence level,\nour best models achieve MAE scores of 0.98 and 1.83 respectively on the test\nset. Also, compared to the recommendations made by experts, our sentence-level\nrecommendation model gets a similar score to the experts, while the text-level\nrecommendation model outperforms the experts by an MAE score of 1.48.\n",
                "链接": "https://arxiv.org/abs/2308.10586"
            },
            {
                "文章ID": "100452",
                "标题": "Doppelgangers: Learning to Disambiguate Images of Similar Structures",
                "作者": " Ruojin Cai,  Joseph Tung,  Qianqian Wang,  Hadar Averbuch-Elor,  Bharath Hariharan,  Noah Snavely",
                "发布日期": "2023-09-06",
                "摘要": "  We consider the visual disambiguation task of determining whether a pair of\nvisually similar images depict the same or distinct 3D surfaces (e.g., the same\nor opposite sides of a symmetric building). Illusory image matches, where two\nimages observe distinct but visually similar 3D surfaces, can be challenging\nfor humans to differentiate, and can also lead 3D reconstruction algorithms to\nproduce erroneous results. We propose a learning-based approach to visual\ndisambiguation, formulating it as a binary classification task on image pairs.\nTo that end, we introduce a new dataset for this problem, Doppelgangers, which\nincludes image pairs of similar structures with ground truth labels. We also\ndesign a network architecture that takes the spatial distribution of local\nkeypoints and matches as input, allowing for better reasoning about both local\nand global cues. Our evaluation shows that our method can distinguish illusory\nmatches in difficult cases, and can be integrated into SfM pipelines to produce\ncorrect, disambiguated 3D reconstructions. See our project page for our code,\ndatasets, and more results: http://doppelgangers-3d.github.io/.\n",
                "链接": "https://arxiv.org/abs/2309.02420"
            }
        ]
    },
    {
        "question": {
            "question": "请搜索近一年发表的有关多模态大模型与产业相结合、与具体应用场景相结合的论文",
            "type": "2"
        },
        "results": [
            {
                "文章ID": "102996",
                "标题": "CFGPT: Chinese Financial Assistant with Large Language Model",
                "作者": " Jiangtong Li,  Yuxuan Bian,  Guoxuan Wang,  Yang Lei,  Dawei Cheng,  Zhijun Ding,  Changjun Jiang",
                "发布日期": "2023-09-25",
                "摘要": "  Large language models (LLMs) have demonstrated great potential in natural\nlanguage processing tasks within the financial domain. In this work, we present\na Chinese Financial Generative Pre-trained Transformer framework, named CFGPT,\nwhich includes a dataset~(CFData) for pre-training and supervised fine-tuning,\na financial LLM~(CFLLM) to adeptly manage financial texts, and a deployment\nframework~(CFAPP) designed to navigate real-world financial applications. The\nCFData comprising both a pre-training dataset and a supervised fine-tuning\ndataset, where the pre-training dataset collates Chinese financial data and\nanalytics, alongside a smaller subset of general-purpose text with 584M\ndocuments and 141B tokens in total, and the supervised fine-tuning dataset is\ntailored for six distinct financial tasks, embodying various facets of\nfinancial analysis and decision-making with 1.5M instruction pairs and 1.5B\ntokens in total. The CFLLM, which is based on InternLM-7B to balance the model\ncapability and size, is trained on CFData in two stage, continued pre-training\nand supervised fine-tuning. The CFAPP is centered on large language models\n(LLMs) and augmented with additional modules to ensure multifaceted\nfunctionality in real-world application. Our codes are released at\nhttps://github.com/TongjiFinLab/CFGPT.\n",
                "链接": "https://arxiv.org/abs/2309.10654"
            },
            {
                "文章ID": "78689",
                "标题": "Empower Large Language Model to Perform Better on Industrial\n  Domain-Specific Question Answering",
                "作者": " Fangkai Yang,  Pu Zhao,  Zezhong Wang,  Lu Wang,  Jue Zhang,  Mohit Garg,  Qingwei Lin,  Saravan Rajmohan,  Dongmei Zhang",
                "发布日期": "2023-10-17",
                "摘要": "  Large Language Model (LLM) has gained popularity and achieved remarkable\nresults in open-domain tasks, but its performance in real industrial\ndomain-specific scenarios is average due to its lack of specific domain\nknowledge. This issue has attracted widespread attention, but there are few\nrelevant benchmarks available. In this paper, we provide a benchmark Question\nAnswering (QA) dataset named MSQA, centered around Microsoft products and IT\ntechnical problems encountered by customers. This dataset contains industry\ncloud-specific QA knowledge, an area not extensively covered in general LLMs,\nmaking it well-suited for evaluating methods aiming to enhance LLMs'\ndomain-specific capabilities. In addition, we propose a new model interaction\nparadigm that can empower LLM to achieve better performance on domain-specific\ntasks where it is not proficient. Extensive experiments demonstrate that the\napproach following our method outperforms the commonly used LLM with retrieval\nmethods. We make our source code and sample data available at:\nhttps://aka.ms/Microsoft_QA.\n",
                "链接": "https://arxiv.org/abs/2305.11541"
            },
            {
                "文章ID": "112345",
                "标题": "Myriad: Large Multimodal Model by Applying Vision Experts for Industrial\n  Anomaly Detection",
                "作者": " Yuanze Li,  Haolin Wang,  Shihao Yuan,  Ming Liu,  Debin Zhao,  Yiwen Guo,  Chen Xu,  Guangming Shi,  Wangmeng Zuo",
                "发布日期": "2023-11-02",
                "摘要": "  Existing industrial anomaly detection (IAD) methods predict anomaly scores\nfor both anomaly detection and localization. However, they struggle to perform\na multi-turn dialog and detailed descriptions for anomaly regions, e.g., color,\nshape, and categories of industrial anomalies. Recently, large multimodal\n(i.e., vision and language) models (LMMs) have shown eminent perception\nabilities on multiple vision tasks such as image captioning, visual\nunderstanding, visual reasoning, etc., making it a competitive potential choice\nfor more comprehensible anomaly detection. However, the knowledge about anomaly\ndetection is absent in existing general LMMs, while training a specific LMM for\nanomaly detection requires a tremendous amount of annotated data and massive\ncomputation resources. In this paper, we propose a novel large multi-modal\nmodel by applying vision experts for industrial anomaly detection (dubbed\nMyriad), which leads to definite anomaly detection and high-quality anomaly\ndescription. Specifically, we adopt MiniGPT-4 as the base LMM and design an\nExpert Perception module to embed the prior knowledge from vision experts as\ntokens which are intelligible to Large Language Models (LLMs). To compensate\nfor the errors and confusions of vision experts, we introduce a domain adapter\nto bridge the visual representation gaps between generic and industrial images.\nFurthermore, we propose a Vision Expert Instructor, which enables the Q-Former\nto generate IAD domain vision-language tokens according to vision expert prior.\nExtensive experiments on MVTec-AD and VisA benchmarks demonstrate that our\nproposed method not only performs favorably against state-of-the-art methods\nunder the 1-class and few-shot settings, but also provide definite anomaly\nprediction along with detailed descriptions in IAD domain.\n",
                "链接": "https://arxiv.org/abs/2310.19070"
            },
            {
                "文章ID": "97795",
                "标题": "Federated Learning in Big Model Era: Domain-Specific Multimodal Large\n  Models",
                "作者": " Zengxiang Li,  Zhaoxiang Hou,  Hui Liu,  Ying Wang,  Tongzhi Li,  Longfei Xie,  Chao Shi,  Chengyi Yang,  Weishan Zhang,  Zelei Liu,  Liang Xu",
                "发布日期": "2023-08-25",
                "摘要": "  Multimodal data, which can comprehensively perceive and recognize the\nphysical world, has become an essential path towards general artificial\nintelligence. However, multimodal large models trained on public datasets often\nunderperform in specific industrial domains. This paper proposes a multimodal\nfederated learning framework that enables multiple enterprises to utilize\nprivate domain data to collaboratively train large models for vertical domains,\nachieving intelligent services across scenarios. The authors discuss in-depth\nthe strategic transformation of federated learning in terms of intelligence\nfoundation and objectives in the era of big model, as well as the new\nchallenges faced in heterogeneous data, model aggregation, performance and cost\ntrade-off, data privacy, and incentive mechanism. The paper elaborates a case\nstudy of leading enterprises contributing multimodal data and expert knowledge\nto city safety operation management , including distributed deployment and\nefficient coordination of the federated learning platform, technical\ninnovations on data quality improvement based on large model capabilities and\nefficient joint fine-tuning approaches. Preliminary experiments show that\nenterprises can enhance and accumulate intelligent capabilities through\nmultimodal model federated learning, thereby jointly creating an smart city\nmodel that provides high-quality intelligent services covering energy\ninfrastructure safety, residential community security, and urban operation\nmanagement. The established federated learning cooperation ecosystem is\nexpected to further aggregate industry, academia, and research resources,\nrealize large models in multiple vertical domains, and promote the large-scale\nindustrial application of artificial intelligence and cutting-edge research on\nmultimodal federated learning.\n",
                "链接": "https://arxiv.org/abs/2308.11217"
            },
            {
                "文章ID": "87099",
                "标题": "Exploiting Multimodal Synthetic Data for Egocentric Human-Object\n  Interaction Detection in an Industrial Scenario",
                "作者": " Rosario Leonardi,  Francesco Ragusa,  Antonino Furnari,  Giovanni Maria Farinella",
                "发布日期": "2023-06-22",
                "摘要": "  In this paper, we tackle the problem of Egocentric Human-Object Interaction\n(EHOI) detection in an industrial setting. To overcome the lack of public\ndatasets in this context, we propose a pipeline and a tool for generating\nsynthetic images of EHOIs paired with several annotations and data signals\n(e.g., depth maps or instance segmentation masks). Using the proposed pipeline,\nwe present EgoISM-HOI a new multimodal dataset composed of synthetic EHOI\nimages in an industrial environment with rich annotations of hands and objects.\nTo demonstrate the utility and effectiveness of synthetic EHOI data produced by\nthe proposed tool, we designed a new method that predicts and combines\ndifferent multimodal signals to detect EHOIs in RGB images. Our study shows\nthat exploiting synthetic data to pre-train the proposed method significantly\nimproves performance when tested on real-world data. Moreover, the proposed\napproach outperforms state-of-the-art class-agnostic methods. To support\nresearch in this field, we publicly release the datasets, source code, and\npre-trained models at https://iplab.dmi.unict.it/egoism-hoi.\n",
                "链接": "https://arxiv.org/abs/2306.12152"
            },
            {
                "文章ID": "124479",
                "标题": "DuaLight: Enhancing Traffic Signal Control by Leveraging\n  Scenario-Specific and Scenario-Shared Knowledge",
                "作者": " Jiaming Lu,  Jingqing Ruan,  Haoyuan Jiang,  Ziyue Li,  Hangyu Mao,  Rui Zhao",
                "发布日期": "2023-12-25",
                "摘要": "  Reinforcement learning has been revolutionizing the traditional traffic\nsignal control task, showing promising power to relieve congestion and improve\nefficiency. However, the existing methods lack effective learning mechanisms\ncapable of absorbing dynamic information inherent to a specific scenario and\nuniversally applicable dynamic information across various scenarios. Moreover,\nwithin each specific scenario, they fail to fully capture the essential\nempirical experiences about how to coordinate between neighboring and target\nintersections, leading to sub-optimal system-wide outcomes.\n  Viewing these issues, we propose DuaLight, which aims to leverage both the\nexperiential information within a single scenario and the generalizable\ninformation across various scenarios for enhanced decision-making.\nSpecifically, DuaLight introduces a scenario-specific experiential weight\nmodule with two learnable parts: Intersection-wise and Feature-wise, guiding\nhow to adaptively utilize neighbors and input features for each scenario, thus\nproviding a more fine-grained understanding of different intersections.\nFurthermore, we implement a scenario-shared Co-Train module to facilitate the\nlearning of generalizable dynamics information across different scenarios.\nEmpirical results on both real-world and synthetic scenarios show DuaLight\nachieves competitive performance across various metrics, offering a promising\nsolution to alleviate traffic congestion, with 3-7\\% improvements. The code is\navailable under: https://github.com/lujiaming-12138/DuaLight.\n",
                "链接": "https://arxiv.org/abs/2312.14532"
            },
            {
                "文章ID": "114068",
                "标题": "GLaMM: Pixel Grounding Large Multimodal Model",
                "作者": " Hanoona Rasheed,  Muhammad Maaz,  Sahal Shaji,  Abdelrahman Shaker,  Salman Khan,  Hisham Cholakkal,  Rao M. Anwer,  Erix Xing,  Ming-Hsuan Yang,  Fahad S. Khan",
                "发布日期": "2023-11-07",
                "摘要": "  Large Multimodal Models (LMMs) extend Large Language Models to the vision\ndomain. Initial efforts towards LMMs used holistic images and text prompts to\ngenerate ungrounded textual responses. Very recently, region-level LMMs have\nbeen used to generate visually grounded responses. However, they are limited to\nonly referring a single object category at a time, require users to specify the\nregions in inputs, or cannot offer dense pixel-wise object grounding. In this\nwork, we present Grounding LMM (GLaMM), the first model that can generate\nnatural language responses seamlessly intertwined with corresponding object\nsegmentation masks. GLaMM not only grounds objects appearing in the\nconversations but is flexible enough to accept both textual and optional visual\nprompts (region of interest) as input. This empowers users to interact with the\nmodel at various levels of granularity, both in textual and visual domains. Due\nto the lack of standard benchmarks for the novel setting of generating visually\ngrounded detailed conversations, we introduce a comprehensive evaluation\nprotocol with our curated grounded conversations. Our proposed Grounded\nConversation Generation (GCG) task requires densely grounded concepts in\nnatural scenes at a large-scale. To this end, we propose a densely annotated\nGrounding-anything Dataset (GranD) using our proposed automated annotation\npipeline that encompasses 7.5M unique concepts grounded in a total of 810M\nregions available with segmentation masks. Besides GCG, GLaMM also performs\neffectively on several downstream tasks e.g., referring expression\nsegmentation, image and region-level captioning and vision-language\nconversations. Project Page: https://mbzuai-oryx.github.io/groundingLMM.\n",
                "链接": "https://arxiv.org/abs/2311.03356"
            },
            {
                "文章ID": "124447",
                "标题": "A Unified Industrial Large Knowledge Model Framework in Smart\n  Manufacturing",
                "作者": " Jay Lee,  Hanqi Su",
                "发布日期": "2023-12-25",
                "摘要": "  The recent emergence of large language models (LLMs) shows the potential for\nartificial general intelligence, revealing new opportunities in industry 4.0\nand smart manufacturing. However, a notable gap exists in applying these LLMs\nin industry, primarily due to their training on general knowledge rather than\ndomain-specific knowledge. Such specialized domain knowledge is vital for\neffectively addressing the complex needs of industrial applications. To bridge\nthis gap, this paper proposes an Industrial Large Knowledge Model (ILKM)\nframework emphasizing their potential to revolutionize the industry in smart\nmanufacturing. In addition, ILKMs and LLMs are compared from eight\nperspectives. Finally, \"6S Principle\" is proposed as the guideline for the\ndevelopment of ILKMs in smart manufacturing.\n",
                "链接": "https://arxiv.org/abs/2312.14428"
            },
            {
                "文章ID": "105595",
                "标题": "Application of frozen large-scale models to multimodal task-oriented\n  dialogue",
                "作者": " Tatsuki Kawamoto,  Takuma Suzuki,  Ko Miyama,  Takumi Meguro,  Tomohiro Takagi",
                "发布日期": "2023-10-03",
                "摘要": "  In this study, we use the existing Large Language Models ENnhanced to See\nFramework (LENS Framework) to test the feasibility of multimodal task-oriented\ndialogues. The LENS Framework has been proposed as a method to solve computer\nvision tasks without additional training and with fixed parameters of\npre-trained models. We used the Multimodal Dialogs (MMD) dataset, a multimodal\ntask-oriented dialogue benchmark dataset from the fashion field, and for the\nevaluation, we used the ChatGPT-based G-EVAL, which only accepts textual\nmodalities, with arrangements to handle multimodal data. Compared to\nTransformer-based models in previous studies, our method demonstrated an\nabsolute lift of 10.8% in fluency, 8.8% in usefulness, and 5.2% in relevance\nand coherence. The results show that using large-scale models with fixed\nparameters rather than using models trained on a dataset from scratch improves\nperformance in multimodal task-oriented dialogues. At the same time, we show\nthat Large Language Models (LLMs) are effective for multimodal task-oriented\ndialogues. This is expected to lead to efficient applications to existing\nsystems.\n",
                "链接": "https://arxiv.org/abs/2310.00845"
            },
            {
                "文章ID": "100082",
                "标题": "Large AI Model Empowered Multimodal Semantic Communications",
                "作者": " Feibo Jiang,  Yubo Peng,  Li Dong,  Kezhi Wang,  Kun Yang,  Cunhua Pan,  Xiaohu You",
                "发布日期": "2023-09-06",
                "摘要": "  Multimodal signals, including text, audio, image and video, can be integrated\ninto Semantic Communication (SC) for providing an immersive experience with low\nlatency and high quality at the semantic level. However, the multimodal SC has\nseveral challenges, including data heterogeneity, semantic ambiguity, and\nsignal fading. Recent advancements in large AI models, particularly in\nMultimodal Language Model (MLM) and Large Language Model (LLM), offer potential\nsolutions for these issues. To this end, we propose a Large AI Model-based\nMultimodal SC (LAM-MSC) framework, in which we first present the MLM-based\nMultimodal Alignment (MMA) that utilizes the MLM to enable the transformation\nbetween multimodal and unimodal data while preserving semantic consistency.\nThen, a personalized LLM-based Knowledge Base (LKB) is proposed, which allows\nusers to perform personalized semantic extraction or recovery through the LLM.\nThis effectively addresses the semantic ambiguity. Finally, we apply the\nConditional Generative adversarial networks-based channel Estimation (CGE) to\nobtain Channel State Information (CSI). This approach effectively mitigates the\nimpact of fading channels in SC. Finally, we conduct simulations that\ndemonstrate the superior performance of the LAM-MSC framework.\n",
                "链接": "https://arxiv.org/abs/2309.01249"
            }
        ]
    },
    {
        "question": {
            "question": "请找出最近一年内发表的关于自然语言处理领域中，使用Transformer模型并在大规模数据集上进行预训练的论文。特别关注模型结构和性能指标。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "109322",
                "标题": "Enhanced Transformer Architecture for Natural Language Processing",
                "作者": " Woohyeon Moon,  Taeyoung Kim,  Bumgeun Park,  Dongsoo Har",
                "发布日期": "2023-10-18",
                "摘要": "  Transformer is a state-of-the-art model in the field of natural language\nprocessing (NLP). Current NLP models primarily increase the number of\ntransformers to improve processing performance. However, this technique\nrequires a lot of training resources such as computing capacity. In this paper,\na novel structure of Transformer is proposed. It is featured by full layer\nnormalization, weighted residual connection, positional encoding exploiting\nreinforcement learning, and zero masked self-attention. The proposed\nTransformer model, which is called Enhanced Transformer, is validated by the\nbilingual evaluation understudy (BLEU) score obtained with the Multi30k\ntranslation dataset. As a result, the Enhanced Transformer achieves 202.96%\nhigher BLEU score as compared to the original transformer with the translation\ndataset.\n",
                "链接": "https://arxiv.org/abs/2310.10930"
            },
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "93014",
                "标题": "Evaluating Large Language Models for Radiology Natural Language\n  Processing",
                "作者": " Zhengliang Liu,  Tianyang Zhong,  Yiwei Li,  Yutong Zhang,  Yi Pan,  Zihao Zhao,  Peixin Dong,  Chao Cao,  Yuxiao Liu,  Peng Shu,  Yaonai Wei,  Zihao Wu,  Chong Ma,  Jiaqi Wang,  Sheng Wang,  Mengyue Zhou,  Zuowei Jiang,  Chunlin Li,  Jason Holmes,  Shaochen Xu,  Lu Zhang,  Haixing Dai,  Kai Zhang,  Lin Zhao,  Yuanhao Chen,  Xu Liu,  Peilong Wang,  Pingkun Yan,  Jun Liu,  Bao Ge,  Lichao Sun,  Dajiang Zhu,  Xiang Li,  Wei Liu,  Xiaoyan Cai,  Xintao Hu,  Xi Jiang,  Shu Zhang,  Xin Zhang,  Tuo Zhang,  Shijie Zhao,  Quanzheng Li,  Hongtu Zhu,  Dinggang Shen,  Tianming Liu",
                "发布日期": "2023-07-28",
                "摘要": "  The rise of large language models (LLMs) has marked a pivotal shift in the\nfield of natural language processing (NLP). LLMs have revolutionized a\nmultitude of domains, and they have made a significant impact in the medical\nfield. Large language models are now more abundant than ever, and many of these\nmodels exhibit bilingual capabilities, proficient in both English and Chinese.\nHowever, a comprehensive evaluation of these models remains to be conducted.\nThis lack of assessment is especially apparent within the context of radiology\nNLP. This study seeks to bridge this gap by critically evaluating thirty two\nLLMs in interpreting radiology reports, a crucial component of radiology NLP.\nSpecifically, the ability to derive impressions from radiologic findings is\nassessed. The outcomes of this evaluation provide key insights into the\nperformance, strengths, and weaknesses of these LLMs, informing their practical\napplications within the medical domain.\n",
                "链接": "https://arxiv.org/abs/2307.13693"
            },
            {
                "文章ID": "115729",
                "标题": "Natural Language Processing for Financial Regulation",
                "作者": " Ixandra Achitouv,  Dragos Gorduza,  Antoine Jacquier",
                "发布日期": "2023-11-16",
                "摘要": "  This article provides an understanding of Natural Language Processing\ntechniques in the framework of financial regulation, more specifically in order\nto perform semantic matching search between rules and policy when no dataset is\navailable for supervised learning. We outline how to outperform simple\npre-trained sentences-transformer models using freely available resources and\nexplain the mathematical concepts behind the key building blocks of Natural\nLanguage Processing.\n",
                "链接": "https://arxiv.org/abs/2311.08533"
            },
            {
                "文章ID": "85699",
                "标题": "Operationalising Representation in Natural Language Processing",
                "作者": " Jacqueline Harding",
                "发布日期": "2023-11-21",
                "摘要": "  Despite its centrality in the philosophy of cognitive science, there has been\nlittle prior philosophical work engaging with the notion of representation in\ncontemporary NLP practice. This paper attempts to fill that lacuna: drawing on\nideas from cognitive science, I introduce a framework for evaluating the\nrepresentational claims made about components of neural NLP models, proposing\nthree criteria with which to evaluate whether a component of a model represents\na property and operationalising these criteria using probing classifiers, a\npopular analysis technique in NLP (and deep learning more broadly).\n  The project of operationalising a philosophically-informed notion of\nrepresentation should be of interest to both philosophers of science and NLP\npractitioners. It affords philosophers a novel testing-ground for claims about\nthe nature of representation, and helps NLPers organise the large literature on\nprobing experiments, suggesting novel avenues for empirical research.\n",
                "链接": "https://arxiv.org/abs/2306.08193"
            },
            {
                "文章ID": "56812",
                "标题": "NarrowBERT: Accelerating Masked Language Model Pretraining and Inference",
                "作者": " Haoxin Li,  Phillip Keung,  Daniel Cheng,  Jungo Kasai,  Noah A. Smith",
                "发布日期": "2023-06-07",
                "摘要": "  Large-scale language model pretraining is a very successful form of\nself-supervised learning in natural language processing, but it is increasingly\nexpensive to perform as the models and pretraining corpora have become larger\nover time. We propose NarrowBERT, a modified transformer encoder that increases\nthe throughput for masked language model pretraining by more than $2\\times$.\nNarrowBERT sparsifies the transformer model such that the self-attention\nqueries and feedforward layers only operate on the masked tokens of each\nsentence during pretraining, rather than all of the tokens as with the usual\ntransformer encoder. We also show that NarrowBERT increases the throughput at\ninference time by as much as $3.5\\times$ with minimal (or no) performance\ndegradation on sentence encoding tasks like MNLI. Finally, we examine the\nperformance of NarrowBERT on the IMDB and Amazon reviews classification and\nCoNLL NER tasks and show that it is also comparable to standard BERT\nperformance.\n",
                "链接": "https://arxiv.org/abs/2301.04761"
            },
            {
                "文章ID": "85203",
                "标题": "AraMUS: Pushing the Limits of Data and Model Scale for Arabic Natural\n  Language Processing",
                "作者": " Asaad Alghamdi,  Xinyu Duan,  Wei Jiang,  Zhenhai Wang,  Yimeng Wu,  Qingrong Xia,  Zhefeng Wang,  Yi Zheng,  Mehdi Rezagholizadeh,  Baoxing Huai,  Peilun Cheng,  Abbas Ghaddar",
                "发布日期": "2023-06-13",
                "摘要": "  Developing monolingual large Pre-trained Language Models (PLMs) is shown to\nbe very successful in handling different tasks in Natural Language Processing\n(NLP). In this work, we present AraMUS, the largest Arabic PLM with 11B\nparameters trained on 529GB of high-quality Arabic textual data. AraMUS\nachieves state-of-the-art performances on a diverse set of Arabic\nclassification and generative tasks. Moreover, AraMUS shows impressive few-shot\nlearning abilities compared with the best existing Arabic PLMs.\n",
                "链接": "https://arxiv.org/abs/2306.06800"
            },
            {
                "文章ID": "80431",
                "标题": "SciReviewGen: A Large-scale Dataset for Automatic Literature Review\n  Generation",
                "作者": " Tetsu Kasanishi,  Masaru Isonuma,  Junichiro Mori,  Ichiro Sakata",
                "发布日期": "2023-05-25",
                "摘要": "  Automatic literature review generation is one of the most challenging tasks\nin natural language processing. Although large language models have tackled\nliterature review generation, the absence of large-scale datasets has been a\nstumbling block to the progress. We release SciReviewGen, consisting of over\n10,000 literature reviews and 690,000 papers cited in the reviews. Based on the\ndataset, we evaluate recent transformer-based summarization models on the\nliterature review generation task, including Fusion-in-Decoder extended for\nliterature review generation. Human evaluation results show that some\nmachine-generated summaries are comparable to human-written reviews, while\nrevealing the challenges of automatic literature review generation such as\nhallucinations and a lack of detailed information. Our dataset and code are\navailable at https://github.com/tetsu9923/SciReviewGen.\n",
                "链接": "https://arxiv.org/abs/2305.15186"
            },
            {
                "文章ID": "112711",
                "标题": "Partial Tensorized Transformers for Natural Language Processing",
                "作者": " Subhadra Vadlamannati,  Ryan Solgi",
                "发布日期": "2023-11-01",
                "摘要": "  The transformer architecture has revolutionized Natural Language Processing\n(NLP) and other machine-learning tasks, due to its unprecedented accuracy.\nHowever, their extensive memory and parameter requirements often hinder their\npractical applications. In this work, we study the effect of tensor-train\ndecomposition to improve the accuracy and compress transformer vision-language\nneural networks, namely BERT and ViT. We focus both on embedding-layer\ncompression and partial tensorization of neural networks (PTNN) through an\nalgorithmic approach. Our novel PTNN approach significantly improves the\naccuracy of existing models by up to 5%, all without the need for post-training\nadjustments, breaking new ground in the field of tensor decomposition.\n",
                "链接": "https://arxiv.org/abs/2310.20077"
            },
            {
                "文章ID": "113818",
                "标题": "mahaNLP: A Marathi Natural Language Processing Library",
                "作者": " Vidula Magdum,  Omkar Dhekane,  Sharayu Hiwarkhedkar,  Saloni Mittal,  Raviraj Joshi",
                "发布日期": "2023-11-07",
                "摘要": "  We present mahaNLP, an open-source natural language processing (NLP) library\nspecifically built for the Marathi language. It aims to enhance the support for\nthe low-resource Indian language Marathi in the field of NLP. It is an\neasy-to-use, extensible, and modular toolkit for Marathi text analysis built on\nstate-of-the-art MahaBERT-based transformer models. Our work holds significant\nimportance as other existing Indic NLP libraries provide basic Marathi\nprocessing support and rely on older models with restricted performance. Our\ntoolkit stands out by offering a comprehensive array of NLP tasks, encompassing\nboth fundamental preprocessing tasks and advanced NLP tasks like sentiment\nanalysis, NER, hate speech detection, and sentence completion. This paper\nfocuses on an overview of the mahaNLP framework, its features, and its usage.\nThis work is a part of the L3Cube MahaNLP initiative, more information about it\ncan be found at https://github.com/l3cube-pune/MarathiNLP .\n",
                "链接": "https://arxiv.org/abs/2311.02579"
            }
        ]
    },
    {
        "question": {
            "question": "请查找关于智能体的研究进展的综述或调查论文。重点关注不同领域中智能体的方法和应用，以及相关的挑战和未来方向。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "68556",
                "标题": "TinyML: Tools, Applications, Challenges, and Future Research Directions",
                "作者": " Rakhee Kallimani,  Krishna Pai,  Prasoon Raghuwanshi,  Sridhar Iyer,  Onel L. A. López",
                "发布日期": "2023-09-08",
                "摘要": "  In recent years, Artificial Intelligence (AI) and Machine learning (ML) have\ngained significant interest from both, industry and academia. Notably,\nconventional ML techniques require enormous amounts of power to meet the\ndesired accuracy, which has limited their use mainly to high-capability devices\nsuch as network nodes. However, with many advancements in technologies such as\nthe Internet of Things (IoT) and edge computing, it is desirable to incorporate\nML techniques into resource-constrained embedded devices for distributed and\nubiquitous intelligence. This has motivated the emergence of the TinyML\nparadigm which is an embedded ML technique that enables ML applications on\nmultiple cheap, resource- and power-constrained devices. However, during this\ntransition towards appropriate implementation of the TinyML technology,\nmultiple challenges such as processing capacity optimization, improved\nreliability, and maintenance of learning models' accuracy require timely\nsolutions. In this article, various avenues available for TinyML implementation\nare reviewed. Firstly, a background of TinyML is provided, followed by detailed\ndiscussions on various tools supporting TinyML. Then, state-of-art applications\nof TinyML using advanced technologies are detailed. Lastly, various research\nchallenges and future directions are identified.\n",
                "链接": "https://arxiv.org/abs/2303.13569"
            },
            {
                "文章ID": "36627",
                "标题": "Metaverse for Healthcare: A Survey on Potential Applications, Challenges\n  and Future Directions",
                "作者": " Rajeswari Chengoden,  Nancy Victor,  Thien Huynh-The,  Gokul Yenduri,  Rutvij H. Jhaveri,  Mamoun Alazab,  Sweta Bhattacharya,  Pawan Hegde,  Praveen Kumar Reddy Maddikunta,  Thippa Reddy Gadekallu",
                "发布日期": "2022-09-12",
                "摘要": "  The rapid progress in digitalization and automation have led to an\naccelerated growth in healthcare, generating novel models that are creating new\nchannels for rendering treatment with reduced cost. The Metaverse is an\nemerging technology in the digital space which has huge potential in\nhealthcare, enabling realistic experiences to the patients as well as the\nmedical practitioners. The Metaverse is a confluence of multiple enabling\ntechnologies such as artificial intelligence, virtual reality, augmented\nreality, internet of medical devices, robotics, quantum computing, etc. through\nwhich new directions for providing quality healthcare treatment and services\ncan be explored. The amalgamation of these technologies ensures immersive,\nintimate and personalized patient care. It also provides adaptive intelligent\nsolutions that eliminates the barriers between healthcare providers and\nreceivers. This article provides a comprehensive review of the Metaverse for\nhealthcare, emphasizing on the state of the art, the enabling technologies for\nadopting the Metaverse for healthcare, the potential applications and the\nrelated projects. The issues in the adaptation of the Metaverse for healthcare\napplications are also identified and the plausible solutions are highlighted as\npart of future research directions.\n",
                "链接": "https://arxiv.org/abs/2209.04160"
            },
            {
                "文章ID": "77270",
                "标题": "A Comprehensive Survey on Affective Computing; Challenges, Trends,\n  Applications, and Future Directions",
                "作者": " Sitara Afzal,  Haseeb Ali Khan,  Imran Ullah Khan,  Md. Jalil Piran,  Jong Weon Lee",
                "发布日期": "2023-05-16",
                "摘要": "  As the name suggests, affective computing aims to recognize human emotions,\nsentiments, and feelings. There is a wide range of fields that study affective\ncomputing, including languages, sociology, psychology, computer science, and\nphysiology. However, no research has ever been done to determine how machine\nlearning (ML) and mixed reality (XR) interact together. This paper discusses\nthe significance of affective computing, as well as its ideas, conceptions,\nmethods, and outcomes. By using approaches of ML and XR, we survey and discuss\nrecent methodologies in affective computing. We survey the state-of-the-art\napproaches along with current affective data resources. Further, we discuss\nvarious applications where affective computing has a significant impact, which\nwill aid future scholars in gaining a better understanding of its significance\nand practical relevance.\n",
                "链接": "https://arxiv.org/abs/2305.07665"
            },
            {
                "文章ID": "55278",
                "标题": "A Survey on Table-and-Text HybridQA: Concepts, Methods, Challenges and\n  Future Directions",
                "作者": " Dingzirui Wang,  Longxu Dou,  Wanxiang Che",
                "发布日期": "2023-02-03",
                "摘要": "  Table-and-text hybrid question answering (HybridQA) is a widely used and\nchallenging NLP task commonly applied in the financial and scientific domain.\nThe early research focuses on migrating other QA task methods to HybridQA,\nwhile with further research, more and more HybridQA-specific methods have been\npresent. With the rapid development of HybridQA, the systematic survey is still\nunder-explored to summarize the main techniques and advance further research.\nSo we present this work to summarize the current HybridQA benchmarks and\nmethods, then analyze the challenges and future directions of this task. The\ncontributions of this paper can be summarized in three folds: (1) first survey,\nto our best knowledge, including benchmarks, methods and challenges for\nHybridQA; (2) systematic investigation with the reasonable comparison of the\nexisting systems to articulate their advantages and shortcomings; (3) detailed\nanalysis of challenges in four important dimensions to shed light on future\ndirections.\n",
                "链接": "https://arxiv.org/abs/2212.13465"
            },
            {
                "文章ID": "84805",
                "标题": "Multimodal Explainable Artificial Intelligence: A Comprehensive Review\n  of Methodological Advances and Future Research Directions",
                "作者": " Nikolaos Rodis,  Christos Sardianos,  Georgios Th. Papadopoulos,  Panagiotis Radoglou-Grammatikis,  Panagiotis Sarigiannidis,  Iraklis Varlamis",
                "发布日期": "2023-06-12",
                "摘要": "  The current study focuses on systematically analyzing the recent advances in\nthe field of Multimodal eXplainable Artificial Intelligence (MXAI). In\nparticular, the relevant primary prediction tasks and publicly available\ndatasets are initially described. Subsequently, a structured presentation of\nthe MXAI methods of the literature is provided, taking into account the\nfollowing criteria: a) The number of the involved modalities, b) The stage at\nwhich explanations are produced, and c) The type of the adopted methodology\n(i.e. mathematical formalism). Then, the metrics used for MXAI evaluation are\ndiscussed. Finally, a comprehensive analysis of current challenges and future\nresearch directions is provided.\n",
                "链接": "https://arxiv.org/abs/2306.05731"
            },
            {
                "文章ID": "17579",
                "标题": "Visual Knowledge Discovery with Artificial Intelligence: Challenges and\n  Future Directions",
                "作者": " Boris Kovalerchuk,  Răzvan Andonie,  Nuno Datia,  Kawa Nazemi,  Ebad Banissi",
                "发布日期": "2022-05-05",
                "摘要": "  This volume is devoted to the emerging field of Integrated Visual Knowledge\nDiscovery that combines advances in Artificial Intelligence/Machine Learning\n(AI/ML) and Visualization/Visual Analytics. Chapters included are extended\nversions of the selected AI and Visual Analytics papers and related symposia at\nthe recent International Information Visualization Conferences (IV2019 and\nIV2020). AI/ML face a long-standing challenge of explaining models to humans.\nModels explanation is fundamentally human activity, not only an algorithmic\none. In this chapter we aim to present challenges and future directions within\nthe field of Visual Analytics, Visual Knowledge Discovery and AI/ML, and to\ndiscuss the role of visualization in visual AI/ML. In addition, we describe\nprogress in emerging Full 2D ML, natural language processing, and AI/ML in\nmultidimensional data aided by visual means.\n",
                "链接": "https://arxiv.org/abs/2205.01296"
            },
            {
                "文章ID": "64747",
                "标题": "Backdoor Attacks and Defenses in Federated Learning: Survey, Challenges\n  and Future Research Directions",
                "作者": " Thuy Dung Nguyen,  Tuan Nguyen,  Phi Le Nguyen,  Hieu H. Pham,  Khoa Doan,  Kok-Seng Wong",
                "发布日期": "2023-03-07",
                "摘要": "  Federated learning (FL) is a machine learning (ML) approach that allows the\nuse of distributed data without compromising personal privacy. However, the\nheterogeneous distribution of data among clients in FL can make it difficult\nfor the orchestration server to validate the integrity of local model updates,\nmaking FL vulnerable to various threats, including backdoor attacks. Backdoor\nattacks involve the insertion of malicious functionality into a targeted model\nthrough poisoned updates from malicious clients. These attacks can cause the\nglobal model to misbehave on specific inputs while appearing normal in other\ncases. Backdoor attacks have received significant attention in the literature\ndue to their potential to impact real-world deep learning applications.\nHowever, they have not been thoroughly studied in the context of FL. In this\nsurvey, we provide a comprehensive survey of current backdoor attack strategies\nand defenses in FL, including a comprehensive analysis of different approaches.\nWe also discuss the challenges and potential future directions for attacks and\ndefenses in the context of FL.\n",
                "链接": "https://arxiv.org/abs/2303.02213"
            },
            {
                "文章ID": "75487",
                "标题": "A Survey on Dataset Distillation: Approaches, Applications and Future\n  Directions",
                "作者": " Jiahui Geng,  Zongxiong Chen,  Yuandou Wang,  Herbert Woisetschlaeger,  Sonja Schimmler,  Ruben Mayer,  Zhiming Zhao,  Chunming Rong",
                "发布日期": "2023-08-25",
                "摘要": "  Dataset distillation is attracting more attention in machine learning as\ntraining sets continue to grow and the cost of training state-of-the-art models\nbecomes increasingly high. By synthesizing datasets with high information\ndensity, dataset distillation offers a range of potential applications,\nincluding support for continual learning, neural architecture search, and\nprivacy protection. Despite recent advances, we lack a holistic understanding\nof the approaches and applications. Our survey aims to bridge this gap by first\nproposing a taxonomy of dataset distillation, characterizing existing\napproaches, and then systematically reviewing the data modalities, and related\napplications. In addition, we summarize the challenges and discuss future\ndirections for this field of research.\n",
                "链接": "https://arxiv.org/abs/2305.01975"
            },
            {
                "文章ID": "115918",
                "标题": "Applications of Computer Vision in Autonomous Vehicles: Methods,\n  Challenges and Future Directions",
                "作者": " Xingshuai Dong,  Massimiliano L. Cappuccio",
                "发布日期": "2023-11-17",
                "摘要": "  Autonomous vehicle refers to a vehicle capable of perceiving its surrounding\nenvironment and driving with little or no human driver input. The perception\nsystem is a fundamental component which enables the autonomous vehicle to\ncollect data and extract relevant information from the environment to drive\nsafely. Benefit from the recent advances in computer vision, the perception\ntask can be achieved by using sensors, such as camera, LiDAR, radar, and\nultrasonic sensor. This paper reviews publications on computer vision and\nautonomous driving that are published during the last ten years. In particular,\nwe first investigate the development of autonomous driving systems and\nsummarize these systems that are developed by the major automotive\nmanufacturers from different countries. Second, we investigate the sensors and\nbenchmark data sets that are commonly utilized for autonomous driving. Then, a\ncomprehensive overview of computer vision applications for autonomous driving\nsuch as depth estimation, object detection, lane detection, and traffic sign\nrecognition are discussed. Additionally, we review public opinions and concerns\non autonomous vehicles. Based on the discussion, we analyze the current\ntechnological challenges that autonomous vehicles meet with. Finally, we\npresent our insights and point out some promising directions for future\nresearch. This paper will help the reader to understand autonomous vehicles\nfrom the perspectives of academia and industry.\n",
                "链接": "https://arxiv.org/abs/2311.09093"
            },
            {
                "文章ID": "70279",
                "标题": "A Survey on Federated Learning for the Healthcare Metaverse: Concepts,\n  Applications, Challenges, and Future Directions",
                "作者": " Ali Kashif Bashir,  Nancy Victor,  Sweta Bhattacharya,  Thien Huynh-The,  Rajeswari Chengoden,  Gokul Yenduri,  Praveen Kumar Reddy Maddikunta,  Quoc-Viet Pham,  Thippa Reddy Gadekallu,  Madhusanka Liyanage",
                "发布日期": "2023-04-06",
                "摘要": "  Recent technological advancements have considerately improved healthcare\nsystems to provide various intelligent healthcare services and improve the\nquality of life. Federated learning (FL), a new branch of artificial\nintelligence (AI), opens opportunities to deal with privacy issues in\nhealthcare systems and exploit data and computing resources available at\ndistributed devices. Additionally, the Metaverse, through integrating emerging\ntechnologies, such as AI, cloud edge computing, Internet of Things (IoT),\nblockchain, and semantic communications, has transformed many vertical domains\nin general and the healthcare sector in particular. Obviously, FL shows many\nbenefits and provides new opportunities for conventional and Metaverse\nhealthcare, motivating us to provide a survey on the usage of FL for Metaverse\nhealthcare systems. First, we present preliminaries to IoT-based healthcare\nsystems, FL in conventional healthcare, and Metaverse healthcare. The benefits\nof FL in Metaverse healthcare are then discussed, from improved privacy and\nscalability, better interoperability, better data management, and extra\nsecurity to automation and low-latency healthcare services. Subsequently, we\ndiscuss several applications pertaining to FL-enabled Metaverse healthcare,\nincluding medical diagnosis, patient monitoring, medical education, infectious\ndisease, and drug discovery. Finally, we highlight significant challenges and\npotential solutions toward the realization of FL in Metaverse healthcare.\n",
                "链接": "https://arxiv.org/abs/2304.00524"
            }
        ]
    }
]