[
    {
        "question": {
            "question": "与大模型工具学习相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "86386",
                "标题": "TOBY: A Tool for Exploring Data in Academic Survey Papers",
                "作者": " Tathagata Chakraborti,  Jungkoo Kang,  Christian Muise,  Sarath Sreedharan,  Michael Walker,  Daniel Szafir,  Tom Williams",
                "发布日期": "2023-06-21",
                "摘要": "  This paper describes TOBY, a visualization tool that helps a user explore the\ncontents of an academic survey paper. The visualization consists of four\ncomponents: a hierarchical view of taxonomic data in the survey, a document\nsimilarity view in the space of taxonomic classes, a network view of citations,\nand a new paper recommendation tool. In this paper, we will discuss these\nfeatures in the context of three separate deployments of the tool.\n",
                "链接": "https://arxiv.org/abs/2306.10051"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "94169",
                "标题": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language\n  Models",
                "作者": " Cheng-Yu Hsieh,  Si-An Chen,  Chun-Liang Li,  Yasuhisa Fujii,  Alexander Ratner,  Chen-Yu Lee,  Ranjay Krishna,  Tomas Pfister",
                "发布日期": "2023-08-02",
                "摘要": "  Today, large language models (LLMs) are taught to use new tools by providing\na few demonstrations of the tool's usage. Unfortunately, demonstrations are\nhard to acquire, and can result in undesirable biased usage if the wrong\ndemonstration is chosen. Even in the rare scenario that demonstrations are\nreadily available, there is no principled selection protocol to determine how\nmany and which ones to provide. As tasks grow more complex, the selection\nsearch grows combinatorially and invariably becomes intractable. Our work\nprovides an alternative to demonstrations: tool documentation. We advocate the\nuse of tool documentation, descriptions for the individual tool usage, over\ndemonstrations. We substantiate our claim through three main empirical findings\non 6 tasks across both vision and language modalities. First, on existing\nbenchmarks, zero-shot prompts with only tool documentation are sufficient for\neliciting proper tool usage, achieving performance on par with few-shot\nprompts. Second, on a newly collected realistic tool-use dataset with hundreds\nof available tool APIs, we show that tool documentation is significantly more\nvaluable than demonstrations, with zero-shot documentation significantly\noutperforming few-shot without documentation. Third, we highlight the benefits\nof tool documentations by tackling image generation and video tracking using\njust-released unseen state-of-the-art models as tools. Finally, we highlight\nthe possibility of using tool documentation to automatically enable new\napplications: by using nothing more than the documentation of GroundingDino,\nStable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the\njust-released Grounded-SAM and Track Anything models.\n",
                "链接": "https://arxiv.org/abs/2308.00675"
            },
            {
                "文章ID": "81272",
                "标题": "Large Language Models as Tool Makers",
                "作者": " Tianle Cai,  Xuezhi Wang,  Tengyu Ma,  Xinyun Chen,  Denny Zhou",
                "发布日期": "2023-05-29",
                "摘要": "  Recent research shows the potential of enhancing the problem-solving ability\nof large language models (LLMs) through the use of external tools. However,\nprior work along this line depends on the availability of existing tools. In\nthis work, we take an initial step towards removing this dependency by\nproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),\nwhere LLMs create their own reusable tools for problem-solving. Our approach\nconsists of two key phases: 1) tool making: an LLM acts as the tool maker that\ncrafts tools for given tasks, where a tool is implemented as a Python utility\nfunction. 2) tool using: an LLM acts as the tool user, which applies the tool\nbuilt by the tool maker for problem-solving. The tool user can be either the\nsame or a different LLM from the tool maker. Tool-making enables an LLM to\ncontinually generate tools that can be applied to different requests so that\nfuture requests can call the corresponding APIs when beneficial for solving the\ntasks. Furthermore, the division of labor among LLMs for tool-making and\ntool-using phases introduces the opportunity to achieve cost effectiveness\nwithout degrading the quality of generated tools and problem solutions. For\nexample, recognizing that tool-making demands more sophisticated capabilities\nthan tool-using, we can apply a powerful yet resource-intensive model as the\ntool maker, and a lightweight while cost-effective model as the tool user. We\nvalidate the effectiveness of our approach across a variety of complex\nreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and\nGPT-3.5 as the tool user, LATM can achieve performance that is on par with\nusing GPT-4 for both tool making and tool using, while the inference cost is\nsignificantly reduced.\n",
                "链接": "https://arxiv.org/abs/2305.17126"
            },
            {
                "文章ID": "95072",
                "标题": "TPTU: Large Language Model-based AI Agents for Task Planning and Tool\n  Usage",
                "作者": " Jingqing Ruan,  Yihong Chen,  Bin Zhang,  Zhiwei Xu,  Tianpeng Bao,  Guoqing Du,  Shiwei Shi,  Hangyu Mao,  Ziyue Li,  Xingyu Zeng,  Rui Zhao",
                "发布日期": "2023-11-08",
                "摘要": "  With recent advancements in natural language processing, Large Language\nModels (LLMs) have emerged as powerful tools for various real-world\napplications. Despite their prowess, the intrinsic generative abilities of LLMs\nmay prove insufficient for handling complex tasks which necessitate a\ncombination of task planning and the usage of external tools. In this paper, we\nfirst propose a structured framework tailored for LLM-based AI Agents and\ndiscuss the crucial capabilities necessary for tackling intricate problems.\nWithin this framework, we design two distinct types of agents (i.e., one-step\nagent and sequential agent) to execute the inference process. Subsequently, we\ninstantiate the framework using various LLMs and evaluate their Task Planning\nand Tool Usage (TPTU) abilities on typical tasks. By highlighting key findings\nand challenges, our goal is to provide a helpful resource for researchers and\npractitioners to leverage the power of LLMs in their AI applications. Our study\nemphasizes the substantial potential of these models, while also identifying\nareas that need more investigation and improvement.\n",
                "链接": "https://arxiv.org/abs/2308.03427"
            },
            {
                "文章ID": "103034",
                "标题": "Interactive Distillation of Large Single-Topic Corpora of Scientific\n  Papers",
                "作者": " Nicholas Solovyev,  Ryan Barron,  Manish Bhattarai,  Maksim E. Eren,  Kim O. Rasmussen,  Boian S. Alexandrov",
                "发布日期": "2023-09-20",
                "摘要": "  Highly specific datasets of scientific literature are important for both\nresearch and education. However, it is difficult to build such datasets at\nscale. A common approach is to build these datasets reductively by applying\ntopic modeling on an established corpus and selecting specific topics. A more\nrobust but time-consuming approach is to build the dataset constructively in\nwhich a subject matter expert (SME) handpicks documents. This method does not\nscale and is prone to error as the dataset grows. Here we showcase a new tool,\nbased on machine learning, for constructively generating targeted datasets of\nscientific literature. Given a small initial \"core\" corpus of papers, we build\na citation network of documents. At each step of the citation network, we\ngenerate text embeddings and visualize the embeddings through dimensionality\nreduction. Papers are kept in the dataset if they are \"similar\" to the core or\nare otherwise pruned through human-in-the-loop selection. Additional insight\ninto the papers is gained through sub-topic modeling using SeNMFk. We\ndemonstrate our new tool for literature review by applying it to two different\nfields in machine learning.\n",
                "链接": "https://arxiv.org/abs/2309.10772"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "94691",
                "标题": "A large language model-assisted education tool to provide feedback on\n  open-ended responses",
                "作者": " Jordan K. Matelsky,  Felipe Parodi,  Tony Liu,  Richard D. Lange,  Konrad P. Kording",
                "发布日期": "2023-08-07",
                "摘要": "  Open-ended questions are a favored tool among instructors for assessing\nstudent understanding and encouraging critical exploration of course material.\nProviding feedback for such responses is a time-consuming task that can lead to\noverwhelmed instructors and decreased feedback quality. Many instructors resort\nto simpler question formats, like multiple-choice questions, which provide\nimmediate feedback but at the expense of personalized and insightful comments.\nHere, we present a tool that uses large language models (LLMs), guided by\ninstructor-defined criteria, to automate responses to open-ended questions. Our\ntool delivers rapid personalized feedback, enabling students to quickly test\ntheir knowledge and identify areas for improvement. We provide open-source\nreference implementations both as a web application and as a Jupyter Notebook\nwidget that can be used with instructional coding or math notebooks. With\ninstructor guidance, LLMs hold promise to enhance student learning outcomes and\nelevate instructional methodologies.\n",
                "链接": "https://arxiv.org/abs/2308.02439"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            }
        ]
    },
    {
        "question": {
            "question": "和大模型可解释相关的最新论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "116604",
                "标题": "RecExplainer: Aligning Large Language Models for Recommendation Model\n  Interpretability",
                "作者": " Yuxuan Lei,  Jianxun Lian,  Jing Yao,  Xu Huang,  Defu Lian,  Xing Xie",
                "发布日期": "2023-11-21",
                "摘要": "  Recommender systems are widely used in various online services, with\nembedding-based models being particularly popular due to their expressiveness\nin representing complex signals. However, these models often lack\ninterpretability, making them less reliable and transparent for both users and\ndevelopers. With the emergence of large language models (LLMs), we find that\ntheir capabilities in language expression, knowledge-aware reasoning, and\ninstruction following are exceptionally powerful. Based on this, we propose a\nnew model interpretation approach for recommender systems, by using LLMs as\nsurrogate models and learn to mimic and comprehend target recommender models.\nSpecifically, we introduce three alignment methods: behavior alignment,\nintention alignment, and hybrid alignment. Behavior alignment operates in the\nlanguage space, representing user preferences and item information as text to\nlearn the recommendation model's behavior; intention alignment works in the\nlatent space of the recommendation model, using user and item representations\nto understand the model's behavior; hybrid alignment combines both language and\nlatent spaces for alignment training. To demonstrate the effectiveness of our\nmethods, we conduct evaluation from two perspectives: alignment effect, and\nexplanation generation ability on three public datasets. Experimental results\nindicate that our approach effectively enables LLMs to comprehend the patterns\nof recommendation models and generate highly credible recommendation\nexplanations.\n",
                "链接": "https://arxiv.org/abs/2311.10947"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "107503",
                "标题": "An evolutionary model of personality traits related to cooperative\n  behavior using a large language model",
                "作者": " Reiji Suzuki,  Takaya Arita",
                "发布日期": "2023-10-11",
                "摘要": "  This paper aims to shed light on the evolutionary dynamics of diverse and\nsocial populations by introducing the rich expressiveness of generative models\ninto the trait expression of social agent-based evolutionary models.\nSpecifically, we focus on the evolution of personality traits in the context of\na game-theoretic relationship as a situation in which inter-individual\ninterests exert strong selection pressures. We construct an agent model in\nwhich linguistic descriptions of personality traits related to cooperative\nbehavior are used as genes. The deterministic strategies extracted from Large\nLanguage Model (LLM) that make behavioral decisions based on these personality\ntraits are used as behavioral traits. The population is evolved according to\nselection based on average payoff and mutation of genes by asking LLM to\nslightly modify the parent gene toward cooperative or selfish. Through\npreliminary experiments and analyses, we clarify that such a model can indeed\nexhibit the evolution of cooperative behavior based on the diverse and\nhigher-order representation of personality traits. We also observed the\nrepeated intrusion of cooperative and selfish personality traits through\nchanges in the expression of personality traits, and found that the emerging\nwords in the evolved gene well reflected the behavioral tendency of its\npersonality in terms of their semantics.\n",
                "链接": "https://arxiv.org/abs/2310.05976"
            },
            {
                "文章ID": "125173",
                "标题": "A Large Language Model-based Computational Approach to Improve\n  Identity-Related Write-Ups",
                "作者": " Alex Doboli",
                "发布日期": "2023-12-29",
                "摘要": "  Creating written products is essential to modern life, including writings\nabout one's identity and personal experiences. However, writing is often a\ndifficult activity that requires extensive effort to frame the central ideas,\nthe pursued approach to communicate the central ideas, e.g., using analogies,\nmetaphors, or other possible means, the needed presentation structure, and the\nactual verbal expression. Large Language Models, a recently emerged approach in\nMachine Learning, can offer a significant help in reducing the effort and\nimproving the quality of written products. This paper proposes a new\ncomputational approach to explore prompts that given as inputs to a Large\nLanguage Models can generate cues to improve the considered written products.\nTwo case studies on improving write-ups, one based on an analogy and one on a\nmetaphor, are also presented in the paper.\n",
                "链接": "https://arxiv.org/abs/2312.16659"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            },
            {
                "文章ID": "81272",
                "标题": "Large Language Models as Tool Makers",
                "作者": " Tianle Cai,  Xuezhi Wang,  Tengyu Ma,  Xinyun Chen,  Denny Zhou",
                "发布日期": "2023-05-29",
                "摘要": "  Recent research shows the potential of enhancing the problem-solving ability\nof large language models (LLMs) through the use of external tools. However,\nprior work along this line depends on the availability of existing tools. In\nthis work, we take an initial step towards removing this dependency by\nproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),\nwhere LLMs create their own reusable tools for problem-solving. Our approach\nconsists of two key phases: 1) tool making: an LLM acts as the tool maker that\ncrafts tools for given tasks, where a tool is implemented as a Python utility\nfunction. 2) tool using: an LLM acts as the tool user, which applies the tool\nbuilt by the tool maker for problem-solving. The tool user can be either the\nsame or a different LLM from the tool maker. Tool-making enables an LLM to\ncontinually generate tools that can be applied to different requests so that\nfuture requests can call the corresponding APIs when beneficial for solving the\ntasks. Furthermore, the division of labor among LLMs for tool-making and\ntool-using phases introduces the opportunity to achieve cost effectiveness\nwithout degrading the quality of generated tools and problem solutions. For\nexample, recognizing that tool-making demands more sophisticated capabilities\nthan tool-using, we can apply a powerful yet resource-intensive model as the\ntool maker, and a lightweight while cost-effective model as the tool user. We\nvalidate the effectiveness of our approach across a variety of complex\nreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and\nGPT-3.5 as the tool user, LATM can achieve performance that is on par with\nusing GPT-4 for both tool making and tool using, while the inference cost is\nsignificantly reduced.\n",
                "链接": "https://arxiv.org/abs/2305.17126"
            },
            {
                "文章ID": "75938",
                "标题": "A technical note on bilinear layers for interpretability",
                "作者": " Lee Sharkey",
                "发布日期": "2023-05-08",
                "摘要": "  The ability of neural networks to represent more features than neurons makes\ninterpreting them challenging. This phenomenon, known as superposition, has\nspurred efforts to find architectures that are more interpretable than standard\nmultilayer perceptrons (MLPs) with elementwise activation functions. In this\nnote, I examine bilinear layers, which are a type of MLP layer that are\nmathematically much easier to analyze while simultaneously performing better\nthan standard MLPs. Although they are nonlinear functions of their input, I\ndemonstrate that bilinear layers can be expressed using only linear operations\nand third order tensors. We can integrate this expression for bilinear layers\ninto a mathematical framework for transformer circuits, which was previously\nlimited to attention-only transformers. These results suggest that bilinear\nlayers are easier to analyze mathematically than current architectures and thus\nmay lend themselves to deeper safety insights by allowing us to talk more\nformally about circuits in neural networks. Additionally, bilinear layers may\noffer an alternative path for mechanistic interpretability through\nunderstanding the mechanisms of feature construction instead of enumerating a\n(potentially exponentially) large number of features in large models.\n",
                "链接": "https://arxiv.org/abs/2305.03452"
            },
            {
                "文章ID": "115222",
                "标题": "Assessing the Interpretability of Programmatic Policies with Large\n  Language Models",
                "作者": " Zahra Bashir,  Michael Bowling,  Levi H. S. Lelis",
                "发布日期": "2023-11-14",
                "摘要": "  Although the synthesis of programs encoding policies often carries the\npromise of interpretability, systematic evaluations to assess the\ninterpretability of these policies were never performed, likely because of the\ncomplexity of such an evaluation. In this paper, we introduce a novel metric\nthat uses large-language models (LLM) to assess the interpretability of\nprogrammatic policies. For our metric, an LLM is given both a program and a\ndescription of its associated programming language. The LLM then formulates a\nnatural language explanation of the program. This explanation is subsequently\nfed into a second LLM, which tries to reconstruct the program from the natural\nlanguage explanation. Our metric measures the behavioral similarity between the\nreconstructed program and the original. We validate our approach using\nobfuscated programs that are used to solve classic programming problems. We\nalso assess our metric with programmatic policies synthesized for playing a\nreal-time strategy game, comparing the interpretability scores of programmatic\npolicies synthesized by an existing system to lightly obfuscated versions of\nthe same programs. Our LLM-based interpretability score consistently ranks less\ninterpretable programs lower and more interpretable ones higher. These findings\nsuggest that our metric could serve as a reliable and inexpensive tool for\nevaluating the interpretability of programmatic policies.\n",
                "链接": "https://arxiv.org/abs/2311.06979"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于大模型Agent应用的最新发表论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "99600",
                "标题": "Autoencoder-based Online Data Quality Monitoring for the CMS\n  Electromagnetic Calorimeter",
                "作者": "on behalf of the CMS Collaboration  Abhirami Harilal, on behalf of the CMS Collaboration  Kyungmin Park, on behalf of the CMS Collaboration  Michael Andrews, on behalf of the CMS Collaboration  Manfred Paulini",
                "发布日期": "2023-09-01",
                "摘要": "  The online Data Quality Monitoring system (DQM) of the CMS electromagnetic\ncalorimeter (ECAL) is a crucial operational tool that allows ECAL experts to\nquickly identify, localize, and diagnose a broad range of detector issues that\nwould otherwise hinder physics-quality data taking. Although the existing ECAL\nDQM system has been continuously updated to respond to new problems, it remains\none step behind newer and unforeseen issues. Using unsupervised deep learning,\na real-time autoencoder-based anomaly detection system is developed that is\nable to detect ECAL anomalies unseen in past data. After accounting for spatial\nvariations in the response of the ECAL and the temporal evolution of anomalies,\nthe new system is able to efficiently detect anomalies while maintaining an\nestimated false discovery rate between $10^{-2}$ to $10^{-4}$, beating existing\nbenchmarks by about two orders of magnitude. The real-world performance of the\nsystem is validated using anomalies found in 2018 and 2022 LHC collision data.\nAdditionally, first results from deploying the autoencoder-based system in the\nCMS online DQM workflow for the ECAL barrel during Run 3 of the LHC are\npresented, showing its promising performance in detecting obscure issues that\ncould have been missed in the existing DQM system.\n",
                "链接": "https://arxiv.org/abs/2308.16659"
            },
            {
                "文章ID": "24392",
                "标题": "A method for comparing multiple imputation techniques: a case study on\n  the U.S. National COVID Cohort Collaborative",
                "作者": "on behalf of the N3C Consortium  Elena Casiraghi, on behalf of the N3C Consortium  Rachel Wong, on behalf of the N3C Consortium  Margaret Hall, on behalf of the N3C Consortium  Ben Coleman, on behalf of the N3C Consortium  Marco Notaro, on behalf of the N3C Consortium  Michael D. Evans, on behalf of the N3C Consortium  Jena S. Tronieri, on behalf of the N3C Consortium  Hannah Blau, on behalf of the N3C Consortium  Bryan Laraway, on behalf of the N3C Consortium  Tiffany J. Callahan, on behalf of the N3C Consortium  Lauren E. Chan, on behalf of the N3C Consortium  Carolyn T. Bramante, on behalf of the N3C Consortium  John B. Buse, on behalf of the N3C Consortium  Richard A. Moffitt, on behalf of the N3C Consortium  Til Sturmer, on behalf of the N3C Consortium  Steven G. Johnson, on behalf of the N3C Consortium  Yu Raymond Shao, on behalf of the N3C Consortium  Justin Reese, on behalf of the N3C Consortium  Peter N. Robinson, on behalf of the N3C Consortium  Alberto Paccanaro, on behalf of the N3C Consortium  Giorgio Valentini, on behalf of the N3C Consortium  Jared D. Huling, on behalf of the N3C Consortium  Kenneth Wilkins,   :,  Tell Bennet,  Christopher Chute,  Peter DeWitt,  Kenneth Gersing,  Andrew Girvin,  Melissa Haendel,  Jeremy Harper,  Janos Hajagos,  Stephanie Hong,  Emily Pfaff,  Jane Reusch,  Corneliu Antoniescu,  Kimberly Robaski",
                "发布日期": "2022-09-27",
                "摘要": "  Healthcare datasets obtained from Electronic Health Records have proven to be\nextremely useful to assess associations between patients' predictors and\noutcomes of interest. However, these datasets often suffer from missing values\nin a high proportion of cases and the simple removal of these cases may\nintroduce severe bias. For these reasons, several multiple imputation\nalgorithms have been proposed to attempt to recover the missing information.\nEach algorithm presents strengths and weaknesses, and there is currently no\nconsensus on which multiple imputation algorithms works best in a given\nscenario. Furthermore, the selection of each algorithm parameters and\ndata-related modelling choices are also both crucial and challenging. In this\npaper, we propose a novel framework to numerically evaluate strategies for\nhandling missing data in the context of statistical analysis, with a particular\nfocus on multiple imputation techniques. We demonstrate the feasibility of our\napproach on a large cohort of type-2 diabetes patients provided by the National\nCOVID Cohort Collaborative (N3C) Enclave, where we explored the influence of\nvarious patient characteristics on outcomes related to COVID-19. Our analysis\nincluded classic multiple imputation techniques as well as simple complete-case\nInverse Probability Weighted models. The experiments presented here show that\nour approach could effectively highlight the most valid and performant\nmissing-data handling strategy for our case study. Moreover, our methodology\nallowed us to gain an understanding of the behavior of the different models and\nof how it changed as we modified their parameters. Our method is general and\ncan be applied to different research fields and on datasets containing\nheterogeneous types.\n",
                "链接": "https://arxiv.org/abs/2206.06444"
            },
            {
                "文章ID": "39427",
                "标题": "Advising Autonomous Cars about the Rules of the Road",
                "作者": "The University of Manchester  Joe Collenette, The\n  University of Manchester  Louise A. Dennis, The University of Manchester  Michael Fisher",
                "发布日期": "2022-09-29",
                "摘要": "  This paper describes (R)ules (o)f (T)he (R)oad (A)dvisor, an agent that\nprovides recommended and possible actions to be generated from a set of\nhuman-level rules. We describe the architecture and design of RoTRA, both\nformally and with an example. Specifically, we use RoTRA to formalise and\nimplement the UK \"Rules of the Road\", and describe how this can be incorporated\ninto autonomous cars such that they can reason internally about obeying the\nrules of the road. In addition, the possible actions generated are annotated to\nindicate whether the rules state that the action must be taken or that they\nonly recommend that the action should be taken, as per the UK Highway Code\n(Rules of The Road). The benefits of utilising this system include being able\nto adapt to different regulations in different jurisdictions; allowing clear\ntraceability from rules to behaviour, and providing an external automated\naccountability mechanism that can check whether the rules were obeyed in some\ngiven situation. A simulation of an autonomous car shows, via a concrete\nexample, how trust can be built by putting the autonomous vehicle through a\nnumber of scenarios which test the car's ability to obey the rules of the road.\nAutonomous cars that incorporate this system are able to ensure that they are\nobeying the rules of the road and external (legal or regulatory) bodies can\nverify that this is the case, without the vehicle or its manufacturer having to\nexpose their source code or make their working transparent, thus allowing\ngreater trust between car companies, jurisdictions, and the general public.\n",
                "链接": "https://arxiv.org/abs/2209.14035"
            },
            {
                "文章ID": "4958",
                "标题": "Radar-based Materials Classification Using Deep Wavelet Scattering\n  Transform: A Comparison of Centimeter vs. Millimeter Wave Units",
                "作者": "The University of Sydney  Rami N. Khushaba, The\n  University of Sydney  Andrew J. Hill",
                "发布日期": "2022-02-11",
                "摘要": "  Radar-based materials detection received significant attention in recent\nyears for its potential inclusion in consumer and industrial applications like\nobject recognition for grasping and manufacturing quality assurance and\ncontrol. Several radar publications were developed for material classification\nunder controlled settings with specific materials' properties and shapes.\nRecent literature has challenged the earlier findings on radars-based materials\nclassification claiming that earlier solutions are not easily scaled to\nindustrial applications due to a variety of real-world issues. Published\nexperiments on the impact of these factors on the robustness of the extracted\nradar-based traditional features have already demonstrated that the application\nof deep neural networks can mitigate, to some extent, the impact to produce a\nviable solution. However, previous studies lacked an investigation of the\nusefulness of lower frequency radar units, specifically <10GHz, against the\nhigher range units around and above 60GHz. This research considers two radar\nunits with different frequency ranges: Walabot-3D (6.3-8 GHz) cm-wave and\nIMAGEVK-74 (62-69 GHz) mm-wave imaging units by Vayyar Imaging. A comparison is\npresented on the applicability of each unit for material classification. This\nwork extends upon previous efforts, by applying deep wavelet scattering\ntransform for the identification of different materials based on the reflected\nsignals. In the wavelet scattering feature extractor, data is propagated\nthrough a series of wavelet transforms, nonlinearities, and averaging to\nproduce low-variance representations of the reflected radar signals. This work\nis unique in comparison of the radar units and algorithms in material\nclassification and includes real-time demonstrations that show strong\nperformance by both units, with increased robustness offered by the cm-wave\nradar unit.\n",
                "链接": "https://arxiv.org/abs/2202.05169"
            },
            {
                "文章ID": "60555",
                "标题": "Reliable Natural Language Understanding with Large Language Models and\n  Answer Set Programming",
                "作者": "The University of Texas at Dallas  Abhiramon Rajasekharan, The University of Texas at Dallas  Yankai Zeng, The University of\n  Texas at Dallas  Parth Padalkar, The University of Texas at Dallas  Gopal Gupta",
                "发布日期": "2023-08-31",
                "摘要": "  Humans understand language by extracting information (meaning) from\nsentences, combining it with existing commonsense knowledge, and then\nperforming reasoning to draw conclusions. While large language models (LLMs)\nsuch as GPT-3 and ChatGPT are able to leverage patterns in the text to solve a\nvariety of NLP tasks, they fall short in problems that require reasoning. They\nalso cannot reliably explain the answers generated for a given question. In\norder to emulate humans better, we propose STAR, a framework that combines LLMs\nwith Answer Set Programming (ASP). We show how LLMs can be used to effectively\nextract knowledge -- represented as predicates -- from language. Goal-directed\nASP is then employed to reliably reason over this knowledge. We apply the STAR\nframework to three different NLU tasks requiring reasoning: qualitative\nreasoning, mathematical reasoning, and goal-directed conversation. Our\nexperiments reveal that STAR is able to bridge the gap of reasoning in NLU\ntasks, leading to significant performance improvements, especially for smaller\nLLMs, i.e., LLMs with a smaller number of parameters. NLU applications\ndeveloped using the STAR framework are also explainable: along with the\npredicates generated, a justification in the form of a proof tree can be\nproduced for a given output.\n",
                "链接": "https://arxiv.org/abs/2302.03780"
            },
            {
                "文章ID": "124998",
                "标题": "On the non-slippery slope: Some observations on a recent paper on\n  rolling bodies published in Nature",
                "作者": " Olaf Müller",
                "发布日期": "2023-12-27",
                "摘要": "  An interesting recent paper in Nature explores a new method to construct\nsolid bodies rolling along given curves on an inclined plane, based on the\nGauss Theorem. The present article complements those examinations with rigorous\nexistence theorems and connections to seemingly unrelated questions like\nmaritime rescue operations.\n",
                "链接": "https://arxiv.org/abs/2312.16128"
            },
            {
                "文章ID": "6201",
                "标题": "PETCI: A Parallel English Translation Dataset of Chinese Idioms",
                "作者": "The University of Chicago  Kenan Tang",
                "发布日期": "2022-02-22",
                "摘要": "  Idioms are an important language phenomenon in Chinese, but idiom translation\nis notoriously hard. Current machine translation models perform poorly on idiom\ntranslation, while idioms are sparse in many translation datasets. We present\nPETCI, a parallel English translation dataset of Chinese idioms, aiming to\nimprove idiom translation by both human and machine. The dataset is built by\nleveraging human and machine effort. Baseline generation models show\nunsatisfactory abilities to improve translation, but structure-aware\nclassification models show good performance on distinguishing good\ntranslations. Furthermore, the size of PETCI can be easily increased without\nexpertise. Overall, PETCI can be helpful to language learners and machine\ntranslation systems.\n",
                "链接": "https://arxiv.org/abs/2202.09509"
            },
            {
                "文章ID": "95589",
                "标题": "Why Data Science Projects Fail",
                "作者": "The University of Auckland  Balaram Panda",
                "发布日期": "2023-08-10",
                "摘要": "  Data Science is a modern Data Intelligence practice, which is the core of\nmany businesses and helps businesses build smart strategies around to deal with\nbusinesses challenges more efficiently. Data Science practice also helps in\nautomating business processes using the algorithm, and it has several other\nbenefits, which also deliver in a non-profitable framework. In regards to data\nscience, three key components primarily influence the effective outcome of a\ndata science project. Those are 1.Availability of Data 2.Algorithm 3.Processing\npower or infrastructure\n",
                "链接": "https://arxiv.org/abs/2308.04896"
            },
            {
                "文章ID": "30074",
                "标题": "Towards Plug'n Play Task-Level Autonomy for Robotics Using POMDPs and\n  Generative Models",
                "作者": "Ben-Gurion University of the Negev  Or Wertheim, Ben-Gurion University of the Negev  Dan R. Suissa, Ben-Gurion University\n  of the Negev  Ronen I. Brafman",
                "发布日期": "2022-07-21",
                "摘要": "  To enable robots to achieve high level objectives, engineers typically write\nscripts that apply existing specialized skills, such as navigation, object\ndetection and manipulation to achieve these goals. Writing good scripts is\nchallenging since they must intelligently balance the inherent stochasticity of\na physical robot's actions and sensors, and the limited information it has. In\nprinciple, AI planning can be used to address this challenge and generate good\nbehavior policies automatically. But this requires passing three hurdles.\nFirst, the AI must understand each skill's impact on the world. Second, we must\nbridge the gap between the more abstract level at which we understand what a\nskill does and the low-level state variables used within its code. Third, much\nintegration effort is required to tie together all components. We describe an\napproach for integrating robot skills into a working autonomous robot\ncontroller that schedules its skills to achieve a specified task and carries\nfour key advantages. 1) Our Generative Skill Documentation Language (GSDL)\nmakes code documentation simpler, compact, and more expressive using ideas from\nprobabilistic programming languages. 2) An expressive abstraction mapping (AM)\nbridges the gap between low-level robot code and the abstract AI planning\nmodel. 3) Any properly documented skill can be used by the controller without\nany additional programming effort, providing a Plug'n Play experience. 4) A\nPOMDP solver schedules skill execution while properly balancing partial\nobservability, stochastic behavior, and noisy sensing.\n",
                "链接": "https://arxiv.org/abs/2207.09713"
            },
            {
                "文章ID": "4481",
                "标题": "Optimizing Warfarin Dosing using Deep Reinforcement Learning",
                "作者": "The University of Iowa Tippie College of Business  Sadjad Anzabi Zadeh, The University of Iowa Tippie College of Business  W. Nick Street, The University of Iowa Tippie College of Business  Barrett W. Thomas",
                "发布日期": "2022-12-26",
                "摘要": "  Warfarin is a widely used anticoagulant, and has a narrow therapeutic range.\nDosing of warfarin should be individualized, since slight overdosing or\nunderdosing can have catastrophic or even fatal consequences. Despite much\nresearch on warfarin dosing, current dosing protocols do not live up to\nexpectations, especially for patients sensitive to warfarin. We propose a deep\nreinforcement learning-based dosing model for warfarin. To overcome the issue\nof relatively small sample sizes in dosing trials, we use a Pharmacokinetic/\nPharmacodynamic (PK/PD) model of warfarin to simulate dose-responses of virtual\npatients. Applying the proposed algorithm on virtual test patients shows that\nthis model outperforms a set of clinically accepted dosing protocols by a wide\nmargin. We tested the robustness of our dosing protocol on a second PK/PD model\nand showed that its performance is comparable to the set of baseline protocols.\n",
                "链接": "https://arxiv.org/abs/2202.03486"
            }
        ]
    },
    {
        "question": {
            "question": "查询近一年模型推理加速相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "78490",
                "标题": "Lightweight Online Learning for Sets of Related Problems in Automated\n  Reasoning",
                "作者": " Haoze Wu,  Christopher Hahn,  Florian Lonsing,  Makai Mann,  Raghuram Ramanujan,  Clark Barrett",
                "发布日期": "2023-08-16",
                "摘要": "  We present Self-Driven Strategy Learning ($\\textit{sdsl}$), a lightweight\nonline learning methodology for automated reasoning tasks that involve solving\na set of related problems. $\\textit{sdsl}$ does not require offline training,\nbut instead automatically constructs a dataset while solving earlier problems.\nIt fits a machine learning model to this data which is then used to adjust the\nsolving strategy for later problems. We formally define the approach as a set\nof abstract transition rules. We describe a concrete instance of the sdsl\ncalculus which uses conditional sampling for generating data and random forests\nas the underlying machine learning model. We implement the approach on top of\nthe Kissat solver and show that the combination of Kissat+$\\textit{sdsl}$\ncertifies larger bounds and finds more counter-examples than other\nstate-of-the-art bounded model checking approaches on benchmarks obtained from\nthe latest Hardware Model Checking Competition.\n",
                "链接": "https://arxiv.org/abs/2305.11087"
            },
            {
                "文章ID": "81304",
                "标题": "Inferring the Future by Imagining the Past",
                "作者": " Kartik Chandra,  Tony Chen,  Tzu-Mao Li,  Jonathan Ragan-Kelley,  Josh Tenenbaum",
                "发布日期": "2023-10-31",
                "摘要": "  A single panel of a comic book can say a lot: it can depict not only where\nthe characters currently are, but also their motions, their motivations, their\nemotions, and what they might do next. More generally, humans routinely infer\ncomplex sequences of past and future events from a *static snapshot* of a\n*dynamic scene*, even in situations they have never seen before.\n  In this paper, we model how humans make such rapid and flexible inferences.\nBuilding on a long line of work in cognitive science, we offer a Monte Carlo\nalgorithm whose inferences correlate well with human intuitions in a wide\nvariety of domains, while only using a small, cognitively-plausible number of\nsamples. Our key technical insight is a surprising connection between our\ninference problem and Monte Carlo path tracing, which allows us to apply\ndecades of ideas from the computer graphics community to this\nseemingly-unrelated theory of mind task.\n",
                "链接": "https://arxiv.org/abs/2305.17195"
            },
            {
                "文章ID": "117018",
                "标题": "Explaining Deep Learning Models for Age-related Gait Classification\n  based on time series acceleration",
                "作者": " Xiaoping Zheng,  Bert Otten,  Michiel F Reneman,  Claudine JC Lamoth",
                "发布日期": "2023-11-29",
                "摘要": "  Gait analysis holds significant importance in monitoring daily health,\nparticularly among older adults. Advancements in sensor technology enable the\ncapture of movement in real-life environments and generate big data. Machine\nlearning, notably deep learning (DL), shows promise to use these big data in\ngait analysis. However, the inherent black-box nature of these models poses\nchallenges for their clinical application. This study aims to enhance\ntransparency in DL-based gait classification for aged-related gait patterns\nusing Explainable Artificial Intelligence, such as SHAP.\n  A total of 244 subjects, comprising 129 adults and 115 older adults (age>65),\nwere included. They performed a 3-minute walking task while accelerometers were\naffixed to the lumbar segment L3. DL models, convolutional neural network (CNN)\nand gated recurrent unit (GRU), were trained using 1-stride and 8-stride\naccelerations, respectively, to classify adult and older adult groups. SHAP was\nemployed to explain the models' predictions.\n  CNN achieved a satisfactory performance with an accuracy of 81.4% and an AUC\nof 0.89, and GRU demonstrated promising results with an accuracy of 84.5% and\nan AUC of 0.94. SHAP analysis revealed that both CNN and GRU assigned higher\nSHAP values to the data from vertical and walking directions, particularly\nemphasizing data around heel contact, spanning from the terminal swing to\nloading response phases. Furthermore, SHAP values indicated that GRU did not\ntreat every stride equally.\n  CNN accurately distinguished between adults and older adults based on the\ncharacteristics of a single stride's data. GRU achieved accurate classification\nby considering the relationships and subtle differences between strides. In\nboth models, data around heel contact emerged as most critical, suggesting\ndifferences in acceleration and deceleration patterns during walking between\ndifferent age groups.\n",
                "链接": "https://arxiv.org/abs/2311.12089"
            },
            {
                "文章ID": "110217",
                "标题": "The Past, Present, and Future of Typological Databases in NLP",
                "作者": " Emi Baylor,  Esther Ploeger,  Johannes Bjerva",
                "发布日期": "2023-10-23",
                "摘要": "  Typological information has the potential to be beneficial in the development\nof NLP models, particularly for low-resource languages. Unfortunately, current\nlarge-scale typological databases, notably WALS and Grambank, are inconsistent\nboth with each other and with other sources of typological information, such as\nlinguistic grammars. Some of these inconsistencies stem from coding errors or\nlinguistic variation, but many of the disagreements are due to the discrete\ncategorical nature of these databases. We shed light on this issue by\nsystematically exploring disagreements across typological databases and\nresources, and their uses in NLP, covering the past and present. We next\ninvestigate the future of such work, offering an argument that a continuous\nview of typological features is clearly beneficial, echoing recommendations\nfrom linguistics. We propose that such a view of typology has significant\npotential in the future, including in language modeling in low-resource\nscenarios.\n",
                "链接": "https://arxiv.org/abs/2310.13440"
            },
            {
                "文章ID": "86581",
                "标题": "Acceleration in Policy Optimization",
                "作者": " Veronica Chelu,  Tom Zahavy,  Arthur Guez,  Doina Precup,  Sebastian Flennerhag",
                "发布日期": "2023-09-07",
                "摘要": "  We work towards a unifying paradigm for accelerating policy optimization\nmethods in reinforcement learning (RL) by integrating foresight in the policy\nimprovement step via optimistic and adaptive updates. Leveraging the connection\nbetween policy iteration and policy gradient methods, we view policy\noptimization algorithms as iteratively solving a sequence of surrogate\nobjectives, local lower bounds on the original objective. We define optimism as\npredictive modelling of the future behavior of a policy, and adaptivity as\ntaking immediate and anticipatory corrective actions to mitigate accumulating\nerrors from overshooting predictions or delayed responses to change. We use\nthis shared lens to jointly express other well-known algorithms, including\nmodel-based policy improvement based on forward search, and optimistic\nmeta-learning algorithms. We analyze properties of this formulation, and show\nconnections to other accelerated optimization algorithms. Then, we design an\noptimistic policy gradient algorithm, adaptive via meta-gradient learning, and\nempirically highlight several design choices pertaining to acceleration, in an\nillustrative task.\n",
                "链接": "https://arxiv.org/abs/2306.10587"
            },
            {
                "文章ID": "92084",
                "标题": "Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in\n  Language Model Prompting",
                "作者": " Rylan Schaeffer,  Kateryna Pistunova,  Samar Khanna,  Sarthak Consul,  Sanmi Koyejo",
                "发布日期": "2023-07-25",
                "摘要": "  Language models can be prompted to reason through problems in a manner that\nsignificantly improves performance. However, \\textit{why} such prompting\nimproves performance is unclear. Recent work showed that using logically\n\\textit{invalid} Chain-of-Thought (CoT) prompting improves performance almost\nas much as logically \\textit{valid} CoT prompting, and that editing CoT prompts\nto replace problem-specific information with abstract information or\nout-of-distribution information typically doesn't harm performance. Critics\nhave responded that these findings are based on too few and too easily solved\ntasks to draw meaningful conclusions. To resolve this dispute, we test whether\nlogically invalid CoT prompts offer the same level of performance gains as\nlogically valid prompts on the hardest tasks in the BIG-Bench benchmark, termed\nBIG-Bench Hard (BBH). We find that the logically \\textit{invalid} reasoning\nprompts do indeed achieve similar performance gains on BBH tasks as logically\nvalid reasoning prompts. We also discover that some CoT prompts used by\nprevious works contain logical errors. This suggests that covariates beyond\nlogically valid reasoning are responsible for performance improvements.\n",
                "链接": "https://arxiv.org/abs/2307.10573"
            },
            {
                "文章ID": "124676",
                "标题": "Understanding the Potential of FPGA-Based Spatial Acceleration for Large\n  Language Model Inference",
                "作者": " Hongzheng Chen,  Jiahao Zhang,  Yixiao Du,  Shaojie Xiang,  Zichao Yue,  Niansong Zhang,  Yaohui Cai,  Zhiru Zhang",
                "发布日期": "2023-12-27",
                "摘要": "  Recent advancements in large language models (LLMs) boasting billions of\nparameters have generated a significant demand for efficient deployment in\ninference workloads. The majority of existing approaches rely on temporal\narchitectures that reuse hardware units for different network layers and\noperators. However, these methods often encounter challenges in achieving low\nlatency due to considerable memory access overhead. This paper investigates the\nfeasibility and potential of model-specific spatial acceleration for LLM\ninference on FPGAs. Our approach involves the specialization of distinct\nhardware units for specific operators or layers, facilitating direct\ncommunication between them through a dataflow architecture while minimizing\noff-chip memory accesses. We introduce a comprehensive analytical model for\nestimating the performance of a spatial LLM accelerator, taking into account\nthe on-chip compute and memory resources available on an FPGA. Through our\nanalysis, we can determine the scenarios in which FPGA-based spatial\nacceleration can outperform its GPU-based counterpart. To enable more\nproductive implementations of an LLM model on FPGAs, we further provide a\nlibrary of high-level synthesis (HLS) kernels that are composable and reusable.\nThis library will be made available as open-source. To validate the\neffectiveness of both our analytical model and HLS library, we have implemented\nBERT and GPT2 on an AMD Alveo U280 FPGA device. Experimental results\ndemonstrate our approach can achieve up to 16.1x speedup when compared to\nprevious FPGA-based accelerators for the BERT model. For GPT generative\ninference, we attain a 2.2x speedup compared to DFX, an FPGA overlay, in the\nprefill stage, while achieving a 1.9x speedup and a 5.7x improvement in energy\nefficiency compared to the NVIDIA A100 GPU in the decode stage.\n",
                "链接": "https://arxiv.org/abs/2312.15159"
            },
            {
                "文章ID": "109901",
                "标题": "Predict the Future from the Past? On the Temporal Data Distribution\n  Shift in Financial Sentiment Classifications",
                "作者": " Yue Guo,  Chenxi Hu,  Yi Yang",
                "发布日期": "2023-10-20",
                "摘要": "  Temporal data distribution shift is prevalent in the financial text. How can\na financial sentiment analysis system be trained in a volatile market\nenvironment that can accurately infer sentiment and be robust to temporal data\ndistribution shifts? In this paper, we conduct an empirical study on the\nfinancial sentiment analysis system under temporal data distribution shifts\nusing a real-world financial social media dataset that spans three years. We\nfind that the fine-tuned models suffer from general performance degradation in\nthe presence of temporal distribution shifts. Furthermore, motivated by the\nunique temporal nature of the financial text, we propose a novel method that\ncombines out-of-distribution detection with time series modeling for temporal\nfinancial sentiment analysis. Experimental results show that the proposed\nmethod enhances the model's capability to adapt to evolving temporal shifts in\na volatile financial market.\n",
                "链接": "https://arxiv.org/abs/2310.12620"
            },
            {
                "文章ID": "96202",
                "标题": "Diagnostic Reasoning Prompts Reveal the Potential for Large Language\n  Model Interpretability in Medicine",
                "作者": " Thomas Savage,  Ashwin Nayak,  Robert Gallo,  Ekanath Rangan,  Jonathan H Chen",
                "发布日期": "2023-08-15",
                "摘要": "  One of the major barriers to using large language models (LLMs) in medicine\nis the perception they use uninterpretable methods to make clinical decisions\nthat are inherently different from the cognitive processes of clinicians. In\nthis manuscript we develop novel diagnostic reasoning prompts to study whether\nLLMs can perform clinical reasoning to accurately form a diagnosis. We find\nthat GPT4 can be prompted to mimic the common clinical reasoning processes of\nclinicians without sacrificing diagnostic accuracy. This is significant because\nan LLM that can use clinical reasoning to provide an interpretable rationale\noffers physicians a means to evaluate whether LLMs can be trusted for patient\ncare. Novel prompting methods have the potential to expose the black box of\nLLMs, bringing them one step closer to safe and effective use in medicine.\n",
                "链接": "https://arxiv.org/abs/2308.06834"
            },
            {
                "文章ID": "92457",
                "标题": "Question Decomposition Improves the Faithfulness of Model-Generated\n  Reasoning",
                "作者": " Ansh Radhakrishnan,  Karina Nguyen,  Anna Chen,  Carol Chen,  Carson Denison,  Danny Hernandez,  Esin Durmus,  Evan Hubinger,  Jackson Kernion,  Kamilė Lukošiūtė,  Newton Cheng,  Nicholas Joseph,  Nicholas Schiefer,  Oliver Rausch,  Sam McCandlish,  Sheer El Showk,  Tamera Lanham,  Tim Maxwell,  Venkatesa Chandrasekaran,  Zac Hatfield-Dodds,  Jared Kaplan,  Jan Brauner,  Samuel R. Bowman,  Ethan Perez",
                "发布日期": "2023-07-26",
                "摘要": "  As large language models (LLMs) perform more difficult tasks, it becomes\nharder to verify the correctness and safety of their behavior. One approach to\nhelp with this issue is to prompt LLMs to externalize their reasoning, e.g., by\nhaving them generate step-by-step reasoning as they answer a question\n(Chain-of-Thought; CoT). The reasoning may enable us to check the process that\nmodels use to perform tasks. However, this approach relies on the stated\nreasoning faithfully reflecting the model's actual reasoning, which is not\nalways the case. To improve over the faithfulness of CoT reasoning, we have\nmodels generate reasoning by decomposing questions into subquestions.\nDecomposition-based methods achieve strong performance on question-answering\ntasks, sometimes approaching that of CoT while improving the faithfulness of\nthe model's stated reasoning on several recently-proposed metrics. By forcing\nthe model to answer simpler subquestions in separate contexts, we greatly\nincrease the faithfulness of model-generated reasoning over CoT, while still\nachieving some of the performance gains of CoT. Our results show it is possible\nto improve the faithfulness of model-generated reasoning; continued\nimprovements may lead to reasoning that enables us to verify the correctness\nand safety of LLM behavior.\n",
                "链接": "https://arxiv.org/abs/2307.11768"
            }
        ]
    },
    {
        "question": {
            "question": "查找论文中包含指令微调细节描述的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "117394",
                "标题": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
                "作者": " Chengyu Wang,  Junbing Yan,  Wei Zhang,  Jun Huang",
                "发布日期": "2023-11-23",
                "摘要": "  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.13126"
            },
            {
                "文章ID": "7583",
                "标题": "Paper Plain: Making Medical Research Papers Approachable to Healthcare\n  Consumers with Natural Language Processing",
                "作者": " Tal August,  Lucy Lu Wang,  Jonathan Bragg,  Marti A. Hearst,  Andrew Head,  Kyle Lo",
                "发布日期": "2022-03-02",
                "摘要": "  When seeking information not covered in patient-friendly documents, like\nmedical pamphlets, healthcare consumers may turn to the research literature.\nReading medical papers, however, can be a challenging experience. To improve\naccess to medical papers, we introduce a novel interactive interface-Paper\nPlain-with four features powered by natural language processing: definitions of\nunfamiliar terms, in-situ plain language section summaries, a collection of key\nquestions that guide readers to answering passages, and plain language\nsummaries of the answering passages. We evaluate Paper Plain, finding that\nparticipants who use Paper Plain have an easier time reading and understanding\nresearch papers without a loss in paper comprehension compared to those who use\na typical PDF reader. Altogether, the study results suggest that guiding\nreaders to relevant passages and providing plain language summaries, or\n\"gists,\" alongside the original paper content can make reading medical papers\neasier and give readers more confidence to approach these papers.\n",
                "链接": "https://arxiv.org/abs/2203.00130"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "27917",
                "标题": "A Dataset on Malicious Paper Bidding in Peer Review",
                "作者": " Steven Jecmen,  Minji Yoon,  Vincent Conitzer,  Nihar B. Shah,  Fei Fang",
                "发布日期": "2023-03-14",
                "摘要": "  In conference peer review, reviewers are often asked to provide \"bids\" on\neach submitted paper that express their interest in reviewing that paper. A\npaper assignment algorithm then uses these bids (along with other data) to\ncompute a high-quality assignment of reviewers to papers. However, this process\nhas been exploited by malicious reviewers who strategically bid in order to\nunethically manipulate the paper assignment, crucially undermining the peer\nreview process. For example, these reviewers may aim to get assigned to a\nfriend's paper as part of a quid-pro-quo deal. A critical impediment towards\ncreating and evaluating methods to mitigate this issue is the lack of any\npublicly-available data on malicious paper bidding. In this work, we collect\nand publicly release a novel dataset to fill this gap, collected from a mock\nconference activity where participants were instructed to bid either honestly\nor maliciously. We further provide a descriptive analysis of the bidding\nbehavior, including our categorization of different strategies employed by\nparticipants. Finally, we evaluate the ability of each strategy to manipulate\nthe assignment, and also evaluate the performance of some simple algorithms\nmeant to detect malicious bidding. The performance of these detection\nalgorithms can be taken as a baseline for future research on detecting\nmalicious bidding.\n",
                "链接": "https://arxiv.org/abs/2207.02303"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            },
            {
                "文章ID": "98124",
                "标题": "InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning MiniGPT-4",
                "作者": " Lai Wei,  Zihao Jiang,  Weiran Huang,  Lichao Sun",
                "发布日期": "2023-10-12",
                "摘要": "  Multimodal large language models are typically trained in two stages: first\npre-training on image-text pairs, and then fine-tuning using supervised\nvision-language instruction data. Recent studies have shown that large language\nmodels can achieve satisfactory results even with a limited amount of\nhigh-quality instruction-following data. In this paper, we introduce\nInstructionGPT-4, which is fine-tuned on a small dataset comprising only 200\nexamples, amounting to approximately 6\\% of the instruction-following data used\nin the alignment dataset for MiniGPT-4. To achieve this, we first propose\nseveral metrics to access the quality of multimodal instruction data. Based on\nthese metrics, we present an effective and trainable data selector to\nautomatically identify and filter low-quality vision-language data. By\nemploying this method, InstructionGPT-4 outperforms the original MiniGPT-4 on\nvarious evaluations. Overall, our findings demonstrate that less but\nhigh-quality instruction tuning data is efficient in enabling multimodal large\nlanguage models to generate better output. Our code is available at\nhttps://github.com/waltonfuture/InstructionGPT-4.\n",
                "链接": "https://arxiv.org/abs/2308.12067"
            },
            {
                "文章ID": "123368",
                "标题": "Position Paper on Materials Design -- A Modern Approach",
                "作者": " Willi Grossmann,  Sebastian Eilermann,  Tim Rensmeyer,  Artur Liebert,  Michael Hohmann,  Christian Wittke,  Oliver Niggemann",
                "发布日期": "2023-12-19",
                "摘要": "  Traditional design cycles for new materials and assemblies have two\nfundamental drawbacks. The underlying physical relationships are often too\ncomplex to be precisely calculated and described. Aside from that, many unknown\nuncertainties, such as exact manufacturing parameters or materials composition,\ndominate the real assembly behavior. Machine learning (ML) methods overcome\nthese fundamental limitations through data-driven learning. In addition, modern\napproaches can specifically increase system knowledge. Representation Learning\nallows the physical, and if necessary, even symbolic interpretation of the\nlearned solution. In this way, the most complex physical relationships can be\nconsidered and quickly described. Furthermore, generative ML approaches can\nsynthesize possible morphologies of the materials based on defined conditions\nto visualize the effects of uncertainties. This modern approach accelerates the\ndesign process for new materials and enables the prediction and interpretation\nof realistic materials behavior.\n",
                "链接": "https://arxiv.org/abs/2312.10996"
            },
            {
                "文章ID": "49528",
                "标题": "Recovering Fine Details for Neural Implicit Surface Reconstruction",
                "作者": " Decai Chen,  Peng Zhang,  Ingo Feldmann,  Oliver Schreer,  Peter Eisert",
                "发布日期": "2022-11-22",
                "摘要": "  Recent works on implicit neural representations have made significant\nstrides. Learning implicit neural surfaces using volume rendering has gained\npopularity in multi-view reconstruction without 3D supervision. However,\naccurately recovering fine details is still challenging, due to the underlying\nambiguity of geometry and appearance representation. In this paper, we present\nD-NeuS, a volume rendering-base neural implicit surface reconstruction method\ncapable to recover fine geometry details, which extends NeuS by two additional\nloss functions targeting enhanced reconstruction quality. First, we encourage\nthe rendered surface points from alpha compositing to have zero signed distance\nvalues, alleviating the geometry bias arising from transforming SDF to density\nfor volume rendering. Second, we impose multi-view feature consistency on the\nsurface points, derived by interpolating SDF zero-crossings from sampled points\nalong rays. Extensive quantitative and qualitative results demonstrate that our\nmethod reconstructs high-accuracy surfaces with details, and outperforms the\nstate of the art.\n",
                "链接": "https://arxiv.org/abs/2211.11320"
            },
            {
                "文章ID": "50760",
                "标题": "Fine-tuning language models to find agreement among humans with diverse\n  preferences",
                "作者": " Michiel A. Bakker,  Martin J. Chadwick,  Hannah R. Sheahan,  Michael Henry Tessler,  Lucy Campbell-Gillingham,  Jan Balaguer,  Nat McAleese,  Amelia Glaese,  John Aslanides,  Matthew M. Botvinick,  Christopher Summerfield",
                "发布日期": "2022-11-29",
                "摘要": "  Recent work in large language modeling (LLMs) has used fine-tuning to align\noutputs with the preferences of a prototypical user. This work assumes that\nhuman preferences are static and homogeneous across individuals, so that\naligning to a a single \"generic\" user will confer more general alignment. Here,\nwe embrace the heterogeneity of human preferences to consider a different\nchallenge: how might a machine help people with diverse views find agreement?\nWe fine-tune a 70 billion parameter LLM to generate statements that maximize\nthe expected approval for a group of people with potentially diverse opinions.\nHuman participants provide written opinions on thousands of questions touching\non moral and political issues (e.g., \"should we raise taxes on the rich?\"), and\nrate the LLM's generated candidate consensus statements for agreement and\nquality. A reward model is then trained to predict individual preferences,\nenabling it to quantify and rank consensus statements in terms of their appeal\nto the overall group, defined according to different aggregation (social\nwelfare) functions. The model produces consensus statements that are preferred\nby human users over those from prompted LLMs (>70%) and significantly\noutperforms a tight fine-tuned baseline that lacks the final ranking step.\nFurther, our best model's consensus statements are preferred over the best\nhuman-generated opinions (>65%). We find that when we silently constructed\nconsensus statements from only a subset of group members, those who were\nexcluded were more likely to dissent, revealing the sensitivity of the\nconsensus to individual contributions. These results highlight the potential to\nuse LLMs to help groups of humans align their values with one another.\n",
                "链接": "https://arxiv.org/abs/2211.15006"
            },
            {
                "文章ID": "121379",
                "标题": "PILLOW: Enhancing Efficient Instruction Fine-tuning via Prompt Matching",
                "作者": " Zhenting Qi,  Xiaoyu Tan,  Shaojie Shi,  Chao Qu,  Yinghui Xu,  Yuan Qi",
                "发布日期": "2023-12-12",
                "摘要": "  Instruction fine-tuning has conventionally been employed to adapt Large\nLanguage Models (LLMs) to a variety of tasks. Nonetheless, this technique often\nnecessitates substantial computational resources, making it impractical for\ndeployment by individuals or small-scale entities. Recently, Low-Rank\nAdaptation (LoRA) has become a promising alternative, offering high\ncapabilities on par with full tuning with reduced resource overhead. However,\nattaining satisfactory performance through the fine-tuning of LoRA is a\nnon-trivial challenge. In this paper, we propose PILLOW, which aims to improve\nLoRA's performance by a discrimination-based prompting method, leveraging LLMs'\nIn-Context Learning ability. PILLOW incorporates a matching network that\nselects prompts from a user-defined prompt pool, concatenates the selected\nprompts with the user instruction as input, and performs inference using the\nLoRA-fine-tuned LLMs. Trained with Reinforcement Learning, PILLOW exhibits\ncommensurate performance on various evaluation metrics compared with typical\ninstruction fine-tuning methods, utilizing only consumer-grade GPU resources\nand exhibiting a large reduction in computational costs.\n",
                "链接": "https://arxiv.org/abs/2312.05621"
            }
        ]
    },
    {
        "question": {
            "question": "查找OCR文本检测最新进展",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "39052",
                "标题": "The role of low-energy electrons in the charging process of LISA test\n  masses",
                "作者": " Simone Taioli,  Maurizio Dapor,  Francesco Dimiccoli,  Michele Fabi,  Valerio Ferroni,  Catia Grimani,  Mattia Villani,  William Joseph Weber",
                "发布日期": "2023-02-22",
                "摘要": "  The space environment encountered by operating spacecraft is populated by a\ncontinuous flux of charged particles that penetrate into electronic devices\ninducing phantom commands and loss of control, eventually leading to satellite\nfailure. Moreover, electron static discharge that results from secondary\nelectron emission of the device materials can also be responsible for satellite\nmalfunction. In this regard, the estimate of the total electron yield is\nfundamental for our understanding of the test-mass charging associated with\ngalactic cosmic rays in the LISA Pathfinder mission and in the forthcoming\ngravitational wave observatory LISA. To unveil the role of low energy electrons\nin this process owing to galactic and solar energetic particle events, in this\nwork we study the interaction of keV and sub-keV electrons with a gold slab\nusing a mixed Monte Carlo and ab-initio framework. We determine the energy\nspectrum of the electrons emerging from such a gold slab hit by a primary\nelectron beam by considering the relevant energy loss mechanisms as well as the\nelastic scattering events. We also show that our results are consistent with\nexperimental data and Monte Carlo simulations carried out with the GEANT4-DNA\ntoolkit.\n",
                "链接": "https://arxiv.org/abs/2209.12791"
            },
            {
                "文章ID": "79433",
                "标题": "Deepfake Text Detection in the Wild",
                "作者": " Yafu Li,  Qintong Li,  Leyang Cui,  Wei Bi,  Longyue Wang,  Linyi Yang,  Shuming Shi,  Yue Zhang",
                "发布日期": "2023-05-23",
                "摘要": "  Recent advances in large language models have enabled them to reach a level\nof text generation comparable to that of humans. These models show powerful\ncapabilities across a wide range of content, including news article writing,\nstory generation, and scientific writing. Such capability further narrows the\ngap between human-authored and machine-generated texts, highlighting the\nimportance of deepfake text detection to avoid potential risks such as fake\nnews propagation and plagiarism. However, previous work has been limited in\nthat they testify methods on testbed of specific domains or certain language\nmodels. In practical scenarios, the detector faces texts from various domains\nor LLMs without knowing their sources. To this end, we build a wild testbed by\ngathering texts from various human writings and deepfake texts generated by\ndifferent LLMs. Human annotators are only slightly better than random guessing\nat identifying machine-generated texts. Empirical results on automatic\ndetection methods further showcase the challenges of deepfake text detection in\na wild testbed. In addition, out-of-distribution poses a greater challenge for\na detector to be employed in realistic application scenarios. We release our\nresources at https://github.com/yafuly/DeepfakeTextDetect.\n",
                "链接": "https://arxiv.org/abs/2305.13242"
            },
            {
                "文章ID": "45022",
                "标题": "Using Deep Learning to Find the Next Unicorn: A Practical Synthesis",
                "作者": " Lele Cao,  Vilhelm von Ehrenheim,  Sebastian Krakowski,  Xiaoxue Li,  Alexandra Lutz",
                "发布日期": "2022-10-26",
                "摘要": "  Startups often represent newly established business models associated with\ndisruptive innovation and high scalability. They are commonly regarded as\npowerful engines for economic and social development. Meanwhile, startups are\nheavily constrained by many factors such as limited financial funding and human\nresources. Therefore the chance for a startup to eventually succeed is as rare\nas ``spotting a unicorn in the wild''. Venture Capital (VC) strives to identify\nand invest in unicorn startups during their early stages, hoping to gain a high\nreturn. To avoid entirely relying on human domain expertise and intuition,\ninvestors usually employ data-driven approaches to forecast the success\nprobability of startups. Over the past two decades, the industry has gone\nthrough a paradigm shift moving from conventional statistical approaches\ntowards becoming machine-learning (ML) based. Notably, the rapid growth of data\nvolume and variety is quickly ushering in deep learning (DL), a subset of ML,\nas a potentially superior approach in terms capacity and expressivity. In this\nwork, we carry out a literature review and synthesis on DL-based approaches,\ncovering the entire DL life cycle. The objective is a) to obtain a thorough and\nin-depth understanding of the methodologies for startup evaluation using DL,\nand b) to distil valuable and actionable learning for practitioners. To the\nbest of our knowledge, our work is the first of this kind.\n",
                "链接": "https://arxiv.org/abs/2210.14195"
            },
            {
                "文章ID": "39057",
                "标题": "FONDUE: an algorithm to find the optimal dimensionality of the latent\n  representations of variational autoencoders",
                "作者": " Lisa Bonheme,  Marek Grzes",
                "发布日期": "2022-09-27",
                "摘要": "  When training a variational autoencoder (VAE) on a given dataset, determining\nthe optimal number of latent variables is mostly done by grid search: a costly\nprocess in terms of computational time and carbon footprint. In this paper, we\nexplore the intrinsic dimension estimation (IDE) of the data and latent\nrepresentations learned by VAEs. We show that the discrepancies between the IDE\nof the mean and sampled representations of a VAE after only a few steps of\ntraining reveal the presence of passive variables in the latent space, which,\nin well-behaved VAEs, indicates a superfluous number of dimensions. Using this\nproperty, we propose FONDUE: an algorithm which quickly finds the number of\nlatent dimensions after which the mean and sampled representations start to\ndiverge (i.e., when passive variables are introduced), providing a principled\nmethod for selecting the number of latent dimensions for VAEs and autoencoders.\n",
                "链接": "https://arxiv.org/abs/2209.12806"
            },
            {
                "文章ID": "82504",
                "标题": "Human or Not? A Gamified Approach to the Turing Test",
                "作者": " Daniel Jannai,  Amos Meron,  Barak Lenz,  Yoav Levine,  Yoav Shoham",
                "发布日期": "2023-06-01",
                "摘要": "  We present \"Human or Not?\", an online game inspired by the Turing test, that\nmeasures the capability of AI chatbots to mimic humans in dialog, and of humans\nto tell bots from other humans. Over the course of a month, the game was played\nby over 1.5 million users who engaged in anonymous two-minute chat sessions\nwith either another human or an AI language model which was prompted to behave\nlike humans. The task of the players was to correctly guess whether they spoke\nto a person or to an AI. This largest scale Turing-style test conducted to date\nrevealed some interesting facts. For example, overall users guessed the\nidentity of their partners correctly in only 68% of the games. In the subset of\nthe games in which users faced an AI bot, users had even lower correct guess\nrates of 60% (that is, not much higher than chance). This white paper details\nthe development, deployment, and results of this unique experiment. While this\nexperiment calls for many extensions and refinements, these findings already\nbegin to shed light on the inevitable near future which will commingle humans\nand AI.\n",
                "链接": "https://arxiv.org/abs/2305.20010"
            },
            {
                "文章ID": "44503",
                "标题": "On the Transformation of Latent Space in Fine-Tuned NLP Models",
                "作者": " Nadir Durrani,  Hassan Sajjad,  Fahim Dalvi,  Firoj Alam",
                "发布日期": "2022-10-25",
                "摘要": "  We study the evolution of latent space in fine-tuned NLP models. Different\nfrom the commonly used probing-framework, we opt for an unsupervised method to\nanalyze representations. More specifically, we discover latent concepts in the\nrepresentational space using hierarchical clustering. We then use an alignment\nfunction to gauge the similarity between the latent space of a pre-trained\nmodel and its fine-tuned version. We use traditional linguistic concepts to\nfacilitate our understanding and also study how the model space transforms\ntowards task-specific information. We perform a thorough analysis, comparing\npre-trained and fine-tuned models across three models and three downstream\ntasks. The notable findings of our work are: i) the latent space of the higher\nlayers evolve towards task-specific concepts, ii) whereas the lower layers\nretain generic concepts acquired in the pre-trained model, iii) we discovered\nthat some concepts in the higher layers acquire polarity towards the output\nclass, and iv) that these concepts can be used for generating adversarial\ntriggers.\n",
                "链接": "https://arxiv.org/abs/2210.12696"
            },
            {
                "文章ID": "111434",
                "标题": "In the user's eyes we find trust: Using gaze data as a predictor or\n  trust in an artifical intelligence",
                "作者": " Martin Johannes Dechant,  Olga Lukashova-Sanz,  Siegfried Wahl",
                "发布日期": "2023-10-26",
                "摘要": "  Trust is essential for our interactions with others but also with artificial\nintelligence (AI) based systems. To understand whether a user trusts an AI,\nresearchers need reliable measurement tools. However, currently discussed\nmarkers mostly rely on expensive and invasive sensors, like\nelectroencephalograms, which may cause discomfort. The analysis of gaze data\nhas been suggested as a convenient tool for trust assessment. However, the\nrelationship between trust and several aspects of the gaze behaviour is not yet\nfully understood. To provide more insights into this relationship, we propose a\nexploration study in virtual reality where participants have to perform a\nsorting task together with a simulated AI in a simulated robotic arm embedded\nin a gaming. We discuss the potential benefits of this approach and outline our\nstudy design in this submission.\n",
                "链接": "https://arxiv.org/abs/2310.16672"
            },
            {
                "文章ID": "34765",
                "标题": "Detecting the unknown in Object Detection",
                "作者": " Dario Fontanel,  Matteo Tarantino,  Fabio Cermelli,  Barbara Caputo",
                "发布日期": "2022-08-25",
                "摘要": "  Object detection methods have witnessed impressive improvements in the last\nyears thanks to the design of novel neural network architectures and the\navailability of large scale datasets. However, current methods have a\nsignificant limitation: they are able to detect only the classes observed\nduring training time, that are only a subset of all the classes that a detector\nmay encounter in the real world. Furthermore, the presence of unknown classes\nis often not considered at training time, resulting in methods not even able to\ndetect that an unknown object is present in the image. In this work, we address\nthe problem of detecting unknown objects, known as open-set object detection.\nWe propose a novel training strategy, called UNKAD, able to predict unknown\nobjects without requiring any annotation of them, exploiting non annotated\nobjects that are already present in the background of training images. In\nparticular, exploiting the four-steps training strategy of Faster R-CNN, UNKAD\nfirst identifies and pseudo-labels unknown objects and then uses the\npseudo-annotations to train an additional unknown class. While UNKAD can\ndirectly detect unknown objects, we further combine it with previous unknown\ndetection techniques, showing that it improves their performance at no costs.\n",
                "链接": "https://arxiv.org/abs/2208.11641"
            },
            {
                "文章ID": "79805",
                "标题": "Process-To-Text: A Framework for the Quantitative Description of\n  Processes in Natural Language",
                "作者": " Yago Fontenla-Seco,  Alberto Bugarín-Diz,  Manuel Lama",
                "发布日期": "2023-05-24",
                "摘要": "  In this paper we present the Process-To-Text (P2T) framework for the\nautomatic generation of textual descriptive explanations of processes. P2T\nintegrates three AI paradigms: process mining for extracting temporal and\nstructural information from a process, fuzzy linguistic protoforms for\nmodelling uncertain terms, and natural language generation for building the\nexplanations. A real use-case in the cardiology domain is presented, showing\nthe potential of P2T for providing natural language explanations addressed to\nspecialists.\n",
                "链接": "https://arxiv.org/abs/2305.14044"
            },
            {
                "文章ID": "58293",
                "标题": "Quantum anomaly detection in the latent space of proton collision events\n  at the LHC",
                "作者": " Kinga Anna Woźniak,  Vasilis Belis,  Ema Puljak,  Panagiotis Barkoutsos,  Günther Dissertori,  Michele Grossi,  Maurizio Pierini,  Florentin Reiter,  Ivano Tavernelli,  Sofia Vallecorsa",
                "发布日期": "2023-03-07",
                "摘要": "  We propose a new strategy for anomaly detection at the LHC based on\nunsupervised quantum machine learning algorithms. To accommodate the\nconstraints on the problem size dictated by the limitations of current quantum\nhardware we develop a classical convolutional autoencoder. The designed quantum\nanomaly detection models, namely an unsupervised kernel machine and two\nclustering algorithms, are trained to find new-physics events in the latent\nrepresentation of LHC data produced by the autoencoder. The performance of the\nquantum algorithms is benchmarked against classical counterparts on different\nnew-physics scenarios and its dependence on the dimensionality of the latent\nspace and the size of the training dataset is studied. For kernel-based anomaly\ndetection, we identify a regime where the quantum model significantly\noutperforms its classical counterpart. An instance of the kernel machine is\nimplemented on a quantum computer to verify its suitability for available\nhardware. We demonstrate that the observed consistent performance advantage is\nrelated to the inherent quantum properties of the circuit used.\n",
                "链接": "https://arxiv.org/abs/2301.10780"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月agent系列决策文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "39027",
                "标题": "Multi-Agent Sequential Decision-Making via Communication",
                "作者": " Ziluo Ding,  Kefan Su,  Weixin Hong,  Liwen Zhu,  Tiejun Huang,  Zongqing Lu",
                "发布日期": "2022-09-27",
                "摘要": "  Communication helps agents to obtain information about others so that better\ncoordinated behavior can be learned. Some existing work communicates predicted\nfuture trajectory with others, hoping to get clues about what others would do\nfor better coordination. However, circular dependencies sometimes can occur\nwhen agents are treated synchronously so it is hard to coordinate\ndecision-making. In this paper, we propose a novel communication scheme,\nSequential Communication (SeqComm). SeqComm treats agents asynchronously (the\nupper-level agents make decisions before the lower-level ones) and has two\ncommunication phases. In negotiation phase, agents determine the priority of\ndecision-making by communicating hidden states of observations and comparing\nthe value of intention, which is obtained by modeling the environment dynamics.\nIn launching phase, the upper-level agents take the lead in making decisions\nand communicate their actions with the lower-level agents. Theoretically, we\nprove the policies learned by SeqComm are guaranteed to improve monotonically\nand converge. Empirically, we show that SeqComm outperforms existing methods in\nvarious multi-agent cooperative tasks.\n",
                "链接": "https://arxiv.org/abs/2209.12713"
            },
            {
                "文章ID": "109649",
                "标题": "Masked Pretraining for Multi-Agent Decision Making",
                "作者": " Jie Liu,  Yinmin Zhang,  Chuming Li,  Chao Yang,  Yaodong Yang,  Yu Liu,  Wanli Ouyang",
                "发布日期": "2023-10-19",
                "摘要": "  Building a single generalist agent with zero-shot capability has recently\nsparked significant advancements in decision-making. However, extending this\ncapability to multi-agent scenarios presents challenges. Most current works\nstruggle with zero-shot capabilities, due to two challenges particular to the\nmulti-agent settings: a mismatch between centralized pretraining and\ndecentralized execution, and varying agent numbers and action spaces, making it\ndifficult to create generalizable representations across diverse downstream\ntasks. To overcome these challenges, we propose a \\textbf{Mask}ed pretraining\nframework for \\textbf{M}ulti-\\textbf{a}gent decision making (MaskMA). This\nmodel, based on transformer architecture, employs a mask-based collaborative\nlearning strategy suited for decentralized execution with partial observation.\nMoreover, MaskMA integrates a generalizable action representation by dividing\nthe action space into actions toward self-information and actions related to\nother entities. This flexibility allows MaskMA to tackle tasks with varying\nagent numbers and thus different action spaces. Extensive experiments in SMAC\nreveal MaskMA, with a single model pretrained on 11 training maps, can achieve\nan impressive 77.8% zero-shot win rate on 60 unseen test maps by decentralized\nexecution, while also performing effectively on other types of downstream tasks\n(\\textit{e.g.,} varied policies collaboration and ad hoc team play).\n",
                "链接": "https://arxiv.org/abs/2310.11846"
            },
            {
                "文章ID": "888",
                "标题": "Pavlovian Signalling with General Value Functions in Agent-Agent\n  Temporal Decision Making",
                "作者": " Andrew Butcher,  Michael Bradley Johanson,  Elnaz Davoodi,  Dylan J. A. Brenneis,  Leslie Acker,  Adam S. R. Parker,  Adam White,  Joseph Modayil,  Patrick M. Pilarski",
                "发布日期": "2022-01-12",
                "摘要": "  In this paper, we contribute a multi-faceted study into Pavlovian signalling\n-- a process by which learned, temporally extended predictions made by one\nagent inform decision-making by another agent. Signalling is intimately\nconnected to time and timing. In service of generating and receiving signals,\nhumans and other animals are known to represent time, determine time since past\nevents, predict the time until a future stimulus, and both recognize and\ngenerate patterns that unfold in time. We investigate how different temporal\nprocesses impact coordination and signalling between learning agents by\nintroducing a partially observable decision-making domain we call the Frost\nHollow. In this domain, a prediction learning agent and a reinforcement\nlearning agent are coupled into a two-part decision-making system that works to\nacquire sparse reward while avoiding time-conditional hazards. We evaluate two\ndomain variations: machine agents interacting in a seven-state linear walk, and\nhuman-machine interaction in a virtual-reality environment. Our results\nshowcase the speed of learning for Pavlovian signalling, the impact that\ndifferent temporal representations do (and do not) have on agent-agent\ncoordination, and how temporal aliasing impacts agent-agent and human-agent\ninteractions differently. As a main contribution, we establish Pavlovian\nsignalling as a natural bridge between fixed signalling paradigms and fully\nadaptive communication learning between two agents. We further show how to\ncomputationally build this adaptive signalling process out of a fixed\nsignalling process, characterized by fast continual prediction learning and\nminimal constraints on the nature of the agent receiving signals. Our results\ntherefore suggest an actionable, constructivist path towards communication\nlearning between reinforcement learning agents.\n",
                "链接": "https://arxiv.org/abs/2201.03709"
            },
            {
                "文章ID": "62777",
                "标题": "Causal Explanations for Sequential Decision-Making in Multi-Agent\n  Systems",
                "作者": " Balint Gyevnar,  Cheng Wang,  Christopher G. Lucas,  Shay B. Cohen,  Stefano V. Albrecht",
                "发布日期": "2023-08-29",
                "摘要": "  We present CEMA: Causal Explanations in Multi-Agent systems; a general\nframework to create causal explanations for an agent's decisions in sequential\nmulti-agent systems. The core of CEMA is a novel causal selection method\ninspired by how humans select causes for explanations. Unlike prior work that\nassumes a specific causal structure, CEMA is applicable whenever a\nprobabilistic model for predicting future states of the environment is\navailable. Given such a model, CEMA samples counterfactual worlds that inform\nus about the salient causes behind the agent's decisions. We evaluate CEMA on\nthe task of motion planning for autonomous driving and test it in diverse\nsimulated scenarios. We show that CEMA correctly and robustly identifies the\ncauses behind decisions, even when a large number of agents is present, and\nshow via a user study that CEMA's explanations have a positive effect on\nparticipant's trust in AVs and are rated at least as good as high-quality human\nexplanations elicited from other participants.\n",
                "链接": "https://arxiv.org/abs/2302.10809"
            },
            {
                "文章ID": "74616",
                "标题": "Preference Inference from Demonstration in Multi-objective Multi-agent\n  Decision Making",
                "作者": " Junlin Lu",
                "发布日期": "2023-04-28",
                "摘要": "  It is challenging to quantify numerical preferences for different objectives\nin a multi-objective decision-making problem. However, the demonstrations of a\nuser are often accessible. We propose an algorithm to infer linear preference\nweights from either optimal or near-optimal demonstrations. The algorithm is\nevaluated in three environments with two baseline methods. Empirical results\ndemonstrate significant improvements compared to the baseline algorithms, in\nterms of both time requirements and accuracy of the inferred preferences. In\nfuture work, we plan to evaluate the algorithm's effectiveness in a multi-agent\nsystem, where one of the agents is enabled to infer the preferences of an\nopponent using our preference inference algorithm.\n",
                "链接": "https://arxiv.org/abs/2304.14126"
            },
            {
                "文章ID": "105753",
                "标题": "ChoiceMates: Supporting Unfamiliar Online Decision-Making with\n  Multi-Agent Conversational Interactions",
                "作者": " Jeongeon Park,  Bryan Min,  Xiaojuan Ma,  Juho Kim",
                "发布日期": "2023-11-15",
                "摘要": "  Unfamiliar decisions -- decisions where people lack adequate domain knowledge\nor expertise -- specifically increase the complexity and uncertainty of the\nprocess of searching for, understanding, and making decisions with online\ninformation. Through our formative study (n=14), we observed users' challenges\nin accessing diverse perspectives, identifying relevant information, and\ndeciding the right moment to make the final decision. We present ChoiceMates, a\nsystem that enables conversations with a dynamic set of LLM-powered agents for\na holistic domain understanding and efficient discovery and management of\ninformation to make decisions. Agents, as opinionated personas, flexibly join\nthe conversation, not only providing responses but also conversing among\nthemselves to elicit each agent's preferences. Our between-subjects study\n(n=36) comparing ChoiceMates to conventional web search and single-agent showed\nthat ChoiceMates was more helpful in discovering, diving deeper, and managing\ninformation compared to Web with higher confidence. We also describe how\nparticipants utilized multi-agent conversations in their decision-making\nprocess.\n",
                "链接": "https://arxiv.org/abs/2310.01331"
            },
            {
                "文章ID": "116642",
                "标题": "Tactics2D: A Multi-agent Reinforcement Learning Environment for Driving\n  Decision-making",
                "作者": " Yueyuan Li,  Songan Zhang,  Mingyang Jiang,  Xingyuan Chen,  Ming Yang",
                "发布日期": "2023-11-21",
                "摘要": "  Tactics2D is an open-source multi-agent reinforcement learning library with a\nPython backend. Its goal is to provide a convenient toolset for researchers to\ndevelop decision-making algorithms for autonomous driving. The library includes\ndiverse traffic scenarios implemented as gym-based environments equipped with\nmulti-sensory capabilities and violation detection for traffic rules.\nAdditionally, it features a reinforcement learning baseline tested with\nreasonable evaluation metrics. Tactics2D is highly modular and customizable.\nThe source code of Tactics2D is available at\nhttps://github.com/WoodOxen/Tactics2D.\n",
                "链接": "https://arxiv.org/abs/2311.11058"
            },
            {
                "文章ID": "84884",
                "标题": "Distributed Consensus Algorithm for Decision-Making in Multi-agent\n  Multi-armed Bandit",
                "作者": " Xiaotong Cheng,  Setareh Maghsudi",
                "发布日期": "2023-06-12",
                "摘要": "  We study a structured multi-agent multi-armed bandit (MAMAB) problem in a\ndynamic environment. A graph reflects the information-sharing structure among\nagents, and the arms' reward distributions are piecewise-stationary with\nseveral unknown change points. The agents face the identical\npiecewise-stationary MAB problem. The goal is to develop a decision-making\npolicy for the agents that minimizes the regret, which is the expected total\nloss of not playing the optimal arm at each time step. Our proposed solution,\nRestarted Bayesian Online Change Point Detection in Cooperative Upper\nConfidence Bound Algorithm (RBO-Coop-UCB), involves an efficient multi-agent\nUCB algorithm as its core enhanced with a Bayesian change point detector. We\nalso develop a simple restart decision cooperation that improves\ndecision-making. Theoretically, we establish that the expected group regret of\nRBO-Coop-UCB is upper bounded by $\\mathcal{O}(KNM\\log T + K\\sqrt{MT\\log T})$,\nwhere K is the number of agents, M is the number of arms, and T is the number\nof time steps. Numerical experiments on synthetic and real-world datasets\ndemonstrate that our proposed method outperforms the state-of-the-art\nalgorithms.\n",
                "链接": "https://arxiv.org/abs/2306.05998"
            },
            {
                "文章ID": "10496",
                "标题": "Decision-Making under Miscalibration",
                "作者": " Guy N. Rothblum,  Gal Yona",
                "发布日期": "2022-03-21",
                "摘要": "  ML-based predictions are used to inform consequential decisions about\nindividuals. How should we use predictions (e.g., risk of heart attack) to\ninform downstream binary classification decisions (e.g., undergoing a medical\nprocedure)? When the risk estimates are perfectly calibrated, the answer is\nwell understood: a classification problem's cost structure induces an optimal\ntreatment threshold $j^{\\star}$. In practice, however, some amount of\nmiscalibration is unavoidable, raising a fundamental question: how should one\nuse potentially miscalibrated predictions to inform binary decisions? We\nformalize a natural (distribution-free) solution concept: given anticipated\nmiscalibration of $\\alpha$, we propose using the threshold $j$ that minimizes\nthe worst-case regret over all $\\alpha$-miscalibrated predictors, where the\nregret is the difference in clinical utility between using the threshold in\nquestion and using the optimal threshold in hindsight. We provide closed form\nexpressions for $j$ when miscalibration is measured using both expected and\nmaximum calibration error, which reveal that it indeed differs from $j^{\\star}$\n(the optimal threshold under perfect calibration). We validate our theoretical\nfindings on real data, demonstrating that there are natural cases in which\nmaking decisions using $j$ improves the clinical utility.\n",
                "链接": "https://arxiv.org/abs/2203.09852"
            },
            {
                "文章ID": "75527",
                "标题": "Asymmetric quantum decision-making",
                "作者": " Honoka Shiratori,  Hiroaki Shinkawa,  André Röhm,  Nicolas Chauvet,  Etsuo Segawa,  Jonathan Laurent,  Guillaume Bachelier,  Tomoki Yamagami,  Ryoichi Horisaki,  Makoto Naruse",
                "发布日期": "2023-05-04",
                "摘要": "  Collective decision-making is crucial to information and communication\nsystems. Decision conflicts among agents hinder the maximization of potential\nutilities of the entire system. Quantum processes can realize conflict-free\njoint decisions among two agents using the entanglement of photons or quantum\ninterference of orbital angular momentum (OAM). However, previous studies have\nalways presented symmetric resultant joint decisions. Although this property\nhelps maintain and preserve equality, it cannot resolve disparities. Global\nchallenges, such as ethics and equity, are recognized in the field of\nresponsible artificial intelligence as responsible research and innovation\nparadigm. Thus, decision-making systems must not only preserve existing\nequality but also tackle disparities. This study theoretically and numerically\ninvestigates asymmetric collective decision-making using quantum interference\nof photons carrying OAM or entangled photons. Although asymmetry is\nsuccessfully realized, a photon loss is inevitable in the proposed models. The\navailable range of asymmetry and method for obtaining the desired degree of\nasymmetry are analytically formulated.\n",
                "链接": "https://arxiv.org/abs/2305.02117"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态优化训练方式的相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "48380",
                "标题": "Detection of fraudulent financial papers by picking a collection of\n  characteristics using optimization algorithms and classification techniques\n  based on squirrels",
                "作者": " Peyman Mohammadzadeh germi,  Mohsen Najarbashi",
                "发布日期": "2022-11-28",
                "摘要": "  To produce important investment decisions, investors require financial\nrecords and economic information. However, most companies manipulate investors\nand financial institutions by inflating their financial statements. Fraudulent\nFinancial Activities exist in any monetary or financial transaction scenario,\nwhether physical or electronic. A challenging problem that arises in this\ndomain is the issue that affects and troubles individuals and institutions.\nThis problem has attracted more attention in the field in part owing to the\nprevalence of financial fraud and the paucity of previous research. For this\npurpose, in this study, the main approach to solve this problem, an anomaly\ndetection-based approach based on a combination of feature selection based on\nsquirrel optimization pattern and classification methods have been used. The\naim is to develop this method to provide a model for detecting anomalies in\nfinancial statements using a combination of selected features with the nearest\nneighbor classifications, neural networks, support vector machine, and\nBayesian. Anomaly samples are then analyzed and compared to recommended\ntechniques using assessment criteria. Squirrel optimization's meta-exploratory\ncapability, along with the approach's ability to identify abnormalities in\nfinancial data, has been shown to be effective in implementing the suggested\nstrategy. They discovered fake financial statements because of their expertise.\n",
                "链接": "https://arxiv.org/abs/2211.07747"
            },
            {
                "文章ID": "67955",
                "标题": "Clustering US Counties to Find Patterns Related to the COVID-19 Pandemic",
                "作者": " Cora Brown,  Sarah Milstein,  Tianyi Sun,  Cooper Zhao",
                "发布日期": "2023-03-22",
                "摘要": "  When COVID-19 first started spreading and quarantine was implemented, the\nSociety for Industrial and Applied Mathematics (SIAM) Student Chapter at the\nUniversity of Minnesota-Twin Cities began a collaboration with Ecolab to use\nour skills as data scientists and mathematicians to extract useful insights\nfrom relevant data relating to the pandemic. This collaboration consisted of\nmultiple groups working on different projects. In this write-up we focus on\nusing clustering techniques to help us find groups of similar counties in the\nUS and use that to help us understand the pandemic. Our team for this project\nconsisted of University of Minnesota students Cora Brown, Sarah Milstein,\nTianyi Sun, and Cooper Zhao, with help from Ecolab Data Scientist Jimmy\nBroomfield and University of Minnesota student Skye Ke. In the sections below\nwe describe all of the work done for this project. In Section 2, we list the\ndata we gathered, as well as the feature engineering we performed. In Section\n3, we describe the metrics we used for evaluating our models. In Section 4, we\nexplain the methods we used for interpreting the results of our various\nclustering approaches. In Section 5, we describe the different clustering\nmethods we implemented. In Section 6, we present the results of our clustering\ntechniques and provide relevant interpretation. Finally, in Section 7, we\nprovide some concluding remarks comparing the different clustering methods.\n",
                "链接": "https://arxiv.org/abs/2303.11936"
            },
            {
                "文章ID": "34482",
                "标题": "Predicting Query-Item Relationship using Adversarial Training and Robust\n  Modeling Techniques",
                "作者": " Min Seok Kim",
                "发布日期": "2022-08-24",
                "摘要": "  We present an effective way to predict search query-item relationship. We\ncombine pre-trained transformer and LSTM models, and increase model robustness\nusing adversarial training, exponential moving average, multi-sampled dropout,\nand diversity based ensemble, to tackle an extremely difficult problem of\npredicting against queries not seen before. All of our strategies focus on\nincreasing robustness of deep learning models and are applicable in any task\nwhere deep learning models are used. Applying our strategies, we achieved 10th\nplace in KDD Cup 2022 Product Substitution Classification task.\n",
                "链接": "https://arxiv.org/abs/2208.10751"
            },
            {
                "文章ID": "45022",
                "标题": "Using Deep Learning to Find the Next Unicorn: A Practical Synthesis",
                "作者": " Lele Cao,  Vilhelm von Ehrenheim,  Sebastian Krakowski,  Xiaoxue Li,  Alexandra Lutz",
                "发布日期": "2022-10-26",
                "摘要": "  Startups often represent newly established business models associated with\ndisruptive innovation and high scalability. They are commonly regarded as\npowerful engines for economic and social development. Meanwhile, startups are\nheavily constrained by many factors such as limited financial funding and human\nresources. Therefore the chance for a startup to eventually succeed is as rare\nas ``spotting a unicorn in the wild''. Venture Capital (VC) strives to identify\nand invest in unicorn startups during their early stages, hoping to gain a high\nreturn. To avoid entirely relying on human domain expertise and intuition,\ninvestors usually employ data-driven approaches to forecast the success\nprobability of startups. Over the past two decades, the industry has gone\nthrough a paradigm shift moving from conventional statistical approaches\ntowards becoming machine-learning (ML) based. Notably, the rapid growth of data\nvolume and variety is quickly ushering in deep learning (DL), a subset of ML,\nas a potentially superior approach in terms capacity and expressivity. In this\nwork, we carry out a literature review and synthesis on DL-based approaches,\ncovering the entire DL life cycle. The objective is a) to obtain a thorough and\nin-depth understanding of the methodologies for startup evaluation using DL,\nand b) to distil valuable and actionable learning for practitioners. To the\nbest of our knowledge, our work is the first of this kind.\n",
                "链接": "https://arxiv.org/abs/2210.14195"
            },
            {
                "文章ID": "114659",
                "标题": "Quranic Conversations: Developing a Semantic Search tool for the Quran\n  using Arabic NLP Techniques",
                "作者": " Yasser Shohoud,  Maged Shoman,  Sarah Abdelazim",
                "发布日期": "2023-11-10",
                "摘要": "  The Holy Book of Quran is believed to be the literal word of God (Allah) as\nrevealed to the Prophet Muhammad (PBUH) over a period of approximately 23\nyears. It is the book where God provides guidance on how to live a righteous\nand just life, emphasizing principles like honesty, compassion, charity and\njustice, as well as providing rules for personal conduct, family matters,\nbusiness ethics and much more. However, due to constraints related to the\nlanguage and the Quran organization, it is challenging for Muslims to get all\nrelevant ayahs (verses) pertaining to a matter or inquiry of interest. Hence,\nwe developed a Quran semantic search tool which finds the verses pertaining to\nthe user inquiry or prompt. To achieve this, we trained several models on a\nlarge dataset of over 30 tafsirs, where typically each tafsir corresponds to\none verse in the Quran and, using cosine similarity, obtained the tafsir tensor\nwhich is most similar to the prompt tensor of interest, which was then used to\nindex for the corresponding ayah in the Quran. Using the SNxLM model, we were\nable to achieve a cosine similarity score as high as 0.97 which corresponds to\nthe abdu tafsir for a verse relating to financial matters.\n",
                "链接": "https://arxiv.org/abs/2311.05120"
            },
            {
                "文章ID": "57742",
                "标题": "Neural Architecture Search: Insights from 1000 Papers",
                "作者": " Colin White,  Mahmoud Safari,  Rhea Sukthanker,  Binxin Ru,  Thomas Elsken,  Arber Zela,  Debadeepta Dey,  Frank Hutter",
                "发布日期": "2023-01-26",
                "摘要": "  In the past decade, advances in deep learning have resulted in breakthroughs\nin a variety of areas, including computer vision, natural language\nunderstanding, speech recognition, and reinforcement learning. Specialized,\nhigh-performing neural architectures are crucial to the success of deep\nlearning in these areas. Neural architecture search (NAS), the process of\nautomating the design of neural architectures for a given task, is an\ninevitable next step in automating machine learning and has already outpaced\nthe best human-designed architectures on many tasks. In the past few years,\nresearch in NAS has been progressing rapidly, with over 1000 papers released\nsince 2020 (Deng and Lindauer, 2021). In this survey, we provide an organized\nand comprehensive guide to neural architecture search. We give a taxonomy of\nsearch spaces, algorithms, and speedup techniques, and we discuss resources\nsuch as benchmarks, best practices, other surveys, and open-source libraries.\n",
                "链接": "https://arxiv.org/abs/2301.08727"
            },
            {
                "文章ID": "21661",
                "标题": "Learning to Find Proofs and Theorems by Learning to Refine Search\n  Strategies: The Case of Loop Invariant Synthesis",
                "作者": " Jonathan Laurent,  André Platzer",
                "发布日期": "2023-09-12",
                "摘要": "  We propose a new approach to automated theorem proving where an\nAlphaZero-style agent is self-training to refine a generic high-level expert\nstrategy expressed as a nondeterministic program. An analogous teacher agent is\nself-training to generate tasks of suitable relevance and difficulty for the\nlearner. This allows leveraging minimal amounts of domain knowledge to tackle\nproblems for which training data is unavailable or hard to synthesize. As a\nspecific illustration, we consider loop invariant synthesis for imperative\nprograms and use neural networks to refine both the teacher and solver\nstrategies.\n",
                "链接": "https://arxiv.org/abs/2205.14229"
            },
            {
                "文章ID": "74606",
                "标题": "DataComp: In search of the next generation of multimodal datasets",
                "作者": " Samir Yitzhak Gadre,  Gabriel Ilharco,  Alex Fang,  Jonathan Hayase,  Georgios Smyrnis,  Thao Nguyen,  Ryan Marten,  Mitchell Wortsman,  Dhruba Ghosh,  Jieyu Zhang,  Eyal Orgad,  Rahim Entezari,  Giannis Daras,  Sarah Pratt,  Vivek Ramanujan,  Yonatan Bitton,  Kalyani Marathe,  Stephen Mussmann,  Richard Vencu,  Mehdi Cherti,  Ranjay Krishna,  Pang Wei Koh,  Olga Saukh,  Alexander Ratner,  Shuran Song,  Hannaneh Hajishirzi,  Ali Farhadi,  Romain Beaumont,  Sewoong Oh,  Alex Dimakis,  Jenia Jitsev,  Yair Carmon,  Vaishaal Shankar,  Ludwig Schmidt",
                "发布日期": "2023-10-23",
                "摘要": "  Multimodal datasets are a critical component in recent breakthroughs such as\nStable Diffusion and GPT-4, yet their design does not receive the same research\nattention as model architectures or training algorithms. To address this\nshortcoming in the ML ecosystem, we introduce DataComp, a testbed for dataset\nexperiments centered around a new candidate pool of 12.8 billion image-text\npairs from Common Crawl. Participants in our benchmark design new filtering\ntechniques or curate new data sources and then evaluate their new dataset by\nrunning our standardized CLIP training code and testing the resulting model on\n38 downstream test sets. Our benchmark consists of multiple compute scales\nspanning four orders of magnitude, which enables the study of scaling trends\nand makes the benchmark accessible to researchers with varying resources. Our\nbaseline experiments show that the DataComp workflow leads to better training\nsets. In particular, our best baseline, DataComp-1B, enables training a CLIP\nViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet, outperforming\nOpenAI's CLIP ViT-L/14 by 3.7 percentage points while using the same training\nprocedure and compute. We release DataComp and all accompanying code at\nwww.datacomp.ai.\n",
                "链接": "https://arxiv.org/abs/2304.14108"
            },
            {
                "文章ID": "42172",
                "标题": "Predicting the clinical citation count of biomedical papers using\n  multilayer perceptron neural network",
                "作者": " Xin Li,  Xuli Tang,  Qikai Cheng",
                "发布日期": "2022-10-24",
                "摘要": "  The number of clinical citations received from clinical guidelines or\nclinical trials has been considered as one of the most appropriate indicators\nfor quantifying the clinical impact of biomedical papers. Therefore, the early\nprediction of the clinical citation count of biomedical papers is critical to\nscientific activities in biomedicine, such as research evaluation, resource\nallocation, and clinical translation. In this study, we designed a four-layer\nmultilayer perceptron neural network (MPNN) model to predict the clinical\ncitation count of biomedical papers in the future by using 9,822,620 biomedical\npapers published from 1985 to 2005. We extracted ninety-one paper features from\nthree dimensions as the input of the model, including twenty-one features in\nthe paper dimension, thirty-five in the reference dimension, and thirty-five in\nthe citing paper dimension. In each dimension, the features can be classified\ninto three categories, i.e., the citation-related features, the clinical\ntranslation-related features, and the topic-related features. Besides, in the\npaper dimension, we also considered the features that have previously been\ndemonstrated to be related to the citation counts of research papers. The\nresults showed that the proposed MPNN model outperformed the other five\nbaseline models, and the features in the reference dimension were the most\nimportant.\n",
                "链接": "https://arxiv.org/abs/2210.06346"
            },
            {
                "文章ID": "73781",
                "标题": "Increasing the Scope as You Learn: Adaptive Bayesian Optimization in\n  Nested Subspaces",
                "作者": " Leonard Papenmeier,  Luigi Nardi,  Matthias Poloczek",
                "发布日期": "2023-04-25",
                "摘要": "  Recent advances have extended the scope of Bayesian optimization (BO) to\nexpensive-to-evaluate black-box functions with dozens of dimensions, aspiring\nto unlock impactful applications, for example, in the life sciences, neural\narchitecture search, and robotics. However, a closer examination reveals that\nthe state-of-the-art methods for high-dimensional Bayesian optimization (HDBO)\nsuffer from degrading performance as the number of dimensions increases or even\nrisk failure if certain unverifiable assumptions are not met. This paper\nproposes BAxUS that leverages a novel family of nested random subspaces to\nadapt the space it optimizes over to the problem. This ensures high performance\nwhile removing the risk of failure, which we assert via theoretical guarantees.\nA comprehensive evaluation demonstrates that BAxUS achieves better results than\nthe state-of-the-art methods for a broad set of applications.\n",
                "链接": "https://arxiv.org/abs/2304.11468"
            }
        ]
    },
    {
        "question": {
            "question": "与大模型安全相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "112490",
                "标题": "Security Challenges for Cloud or Fog Computing-Based AI Applications",
                "作者": " Amir Pakmehr,  Andreas Aßmuth,  Christoph P. Neumann,  Gerald Pirkl",
                "发布日期": "2023-12-22",
                "摘要": "  Security challenges for Cloud or Fog-based machine learning services pose\nseveral concerns. Securing the underlying Cloud or Fog services is essential,\nas successful attacks against these services, on which machine learning\napplications rely, can lead to significant impairments of these applications.\nBecause the requirements for AI applications can also be different, we\ndifferentiate according to whether they are used in the Cloud or in a Fog\nComputing network. This then also results in different threats or attack\npossibilities. For Cloud platforms, the responsibility for security can be\ndivided between different parties. Security deficiencies at a lower level can\nhave a direct impact on the higher level where user data is stored. While\nresponsibilities are simpler for Fog Computing networks, by moving services to\nthe edge of the network, we have to secure them against physical access to the\ndevices. We conclude by outlining specific information security requirements\nfor AI applications.\n",
                "链接": "https://arxiv.org/abs/2310.19459"
            },
            {
                "文章ID": "92148",
                "标题": "LLM Censorship: A Machine Learning Challenge or a Computer Security\n  Problem?",
                "作者": " David Glukhov,  Ilia Shumailov,  Yarin Gal,  Nicolas Papernot,  Vardan Papyan",
                "发布日期": "2023-07-25",
                "摘要": "  Large language models (LLMs) have exhibited impressive capabilities in\ncomprehending complex instructions. However, their blind adherence to provided\ninstructions has led to concerns regarding risks of malicious use. Existing\ndefence mechanisms, such as model fine-tuning or output censorship using LLMs,\nhave proven to be fallible, as LLMs can still generate problematic responses.\nCommonly employed censorship approaches treat the issue as a machine learning\nproblem and rely on another LM to detect undesirable content in LLM outputs. In\nthis paper, we present the theoretical limitations of such semantic censorship\napproaches. Specifically, we demonstrate that semantic censorship can be\nperceived as an undecidable problem, highlighting the inherent challenges in\ncensorship that arise due to LLMs' programmatic and instruction-following\ncapabilities. Furthermore, we argue that the challenges extend beyond semantic\ncensorship, as knowledgeable attackers can reconstruct impermissible outputs\nfrom a collection of permissible ones. As a result, we propose that the problem\nof censorship needs to be reevaluated; it should be treated as a security\nproblem which warrants the adaptation of security-based approaches to mitigate\npotential risks.\n",
                "链接": "https://arxiv.org/abs/2307.10719"
            },
            {
                "文章ID": "115941",
                "标题": "Grounding or Guesswork? Large Language Models are Presumptive Grounders",
                "作者": " Omar Shaikh,  Kristina Gligorić,  Ashna Khetan,  Matthias Gerstgrasser,  Diyi Yang,  Dan Jurafsky",
                "发布日期": "2023-11-16",
                "摘要": "  Effective conversation requires common ground: a shared understanding between\nthe participants. Common ground, however, does not emerge spontaneously in\nconversation. Speakers and listeners work together to both identify and\nconstruct a shared basis while avoiding misunderstanding. To accomplish\ngrounding, humans rely on a range of dialogue acts, like clarification (What do\nyou mean?) and acknowledgment (I understand.). In domains like teaching and\nemotional support, carefully constructing grounding prevents misunderstanding.\nHowever, it is unclear whether large language models (LLMs) leverage these\ndialogue acts in constructing common ground. To this end, we curate a set of\ngrounding acts and propose corresponding metrics that quantify attempted\ngrounding. We study whether LLMs use these grounding acts, simulating them\ntaking turns from several dialogue datasets, and comparing the results to\nhumans. We find that current LLMs are presumptive grounders, biased towards\nassuming common ground without using grounding acts. To understand the roots of\nthis behavior, we examine the role of instruction tuning and reinforcement\nlearning with human feedback (RLHF), finding that RLHF leads to less grounding.\nAltogether, our work highlights the need for more research investigating\ngrounding in human-AI interaction.\n",
                "链接": "https://arxiv.org/abs/2311.09144"
            },
            {
                "文章ID": "107596",
                "标题": "Model Tuning or Prompt Tuning? A Study of Large Language Models for\n  Clinical Concept and Relation Extraction",
                "作者": " Cheng Peng,  Xi Yang,  Kaleb E Smith,  Zehao Yu,  Aokun Chen,  Jiang Bian,  Yonghui Wu",
                "发布日期": "2023-10-11",
                "摘要": "  Objective To develop soft prompt-based learning algorithms for large language\nmodels (LLMs), examine the shape of prompts, prompt-tuning using\nfrozen/unfrozen LLMs, transfer learning, and few-shot learning abilities.\nMethods We developed a soft prompt-based LLM model and compared 4 training\nstrategies including (1) fine-tuning without prompts; (2) hard-prompt with\nunfrozen LLMs; (3) soft-prompt with unfrozen LLMs; and (4) soft-prompt with\nfrozen LLMs. We evaluated 7 pretrained LLMs using the 4 training strategies for\nclinical concept and relation extraction on two benchmark datasets. We\nevaluated the transfer learning ability of the prompt-based learning algorithms\nin a cross-institution setting. We also assessed the few-shot learning ability.\nResults and Conclusion When LLMs are unfrozen, GatorTron-3.9B with soft\nprompting achieves the best strict F1-scores of 0.9118 and 0.8604 for concept\nextraction, outperforming the traditional fine-tuning and hard prompt-based\nmodels by 0.6~3.1% and 1.2~2.9%, respectively; GatorTron-345M with soft\nprompting achieves the best F1-scores of 0.8332 and 0.7488 for end-to-end\nrelation extraction, outperforming the other two models by 0.2~2% and\n0.6~11.7%, respectively. When LLMs are frozen, small (i.e., 345 million\nparameters) LLMs have a big gap to be competitive with unfrozen models; scaling\nLLMs up to billions of parameters makes frozen LLMs competitive with unfrozen\nLLMs. For cross-institute evaluation, soft prompting with a frozen\nGatorTron-8.9B model achieved the best performance. This study demonstrates\nthat (1) machines can learn soft prompts better than humans, (2) frozen LLMs\nhave better few-shot learning ability and transfer learning ability to\nfacilitate muti-institution applications, and (3) frozen LLMs require large\nmodels.\n",
                "链接": "https://arxiv.org/abs/2310.06239"
            },
            {
                "文章ID": "53435",
                "标题": "Artificial intelligence technologies to support research assessment: A\n  review",
                "作者": " Kayvan Kousha,  Mike Thelwall",
                "发布日期": "2022-12-14",
                "摘要": "  This literature review identifies indicators that associate with higher\nimpact or higher quality research from article text (e.g., titles, abstracts,\nlengths, cited references and readability) or metadata (e.g., the number of\nauthors, international or domestic collaborations, journal impact factors and\nauthors' h-index). This includes studies that used machine learning techniques\nto predict citation counts or quality scores for journal articles or conference\npapers. The literature review also includes evidence about the strength of\nassociation between bibliometric indicators and quality score rankings from\nprevious UK Research Assessment Exercises (RAEs) and REFs in different subjects\nand years and similar evidence from other countries (e.g., Australia and\nItaly). In support of this, the document also surveys studies that used public\ndatasets of citations, social media indictors or open review texts (e.g.,\nDimensions, OpenCitations, Altmetric.com and Publons) to help predict the\nscholarly impact of articles. The results of this part of the literature review\nwere used to inform the experiments using machine learning to predict REF\njournal article quality scores, as reported in the AI experiments report for\nthis project. The literature review also covers technology to automate\neditorial processes, to provide quality control for papers and reviewers'\nsuggestions, to match reviewers with articles, and to automatically categorise\njournal articles into fields. Bias and transparency in technology assisted\nassessment are also discussed.\n",
                "链接": "https://arxiv.org/abs/2212.06574"
            },
            {
                "文章ID": "104326",
                "标题": "Art or Artifice? Large Language Models and the False Promise of\n  Creativity",
                "作者": " Tuhin Chakrabarty,  Philippe Laban,  Divyansh Agarwal,  Smaranda Muresan,  Chien-Sheng Wu",
                "发布日期": "2023-09-27",
                "摘要": "  Researchers have argued that large language models (LLMs) exhibit\nhigh-quality writing capabilities from blogs to stories. However, evaluating\nobjectively the creativity of a piece of writing is challenging. Inspired by\nthe Torrance Test of Creative Thinking (TTCT), which measures creativity as a\nprocess, we use the Consensual Assessment Technique [3] and propose the\nTorrance Test of Creative Writing (TTCW) to evaluate creativity as a product.\nTTCW consists of 14 binary tests organized into the original dimensions of\nFluency, Flexibility, Originality, and Elaboration. We recruit 10 creative\nwriters and implement a human assessment of 48 stories written either by\nprofessional authors or LLMs using TTCW. Our analysis shows that LLM-generated\nstories pass 3-10X less TTCW tests than stories written by professionals. In\naddition, we explore the use of LLMs as assessors to automate the TTCW\nevaluation, revealing that none of the LLMs positively correlate with the\nexpert assessments.\n",
                "链接": "https://arxiv.org/abs/2309.14556"
            },
            {
                "文章ID": "56590",
                "标题": "Chatbots in a Honeypot World",
                "作者": " Forrest McKee,  David Noever",
                "发布日期": "2023-01-11",
                "摘要": "  Question-and-answer agents like ChatGPT offer a novel tool for use as a\npotential honeypot interface in cyber security. By imitating Linux, Mac, and\nWindows terminal commands and providing an interface for TeamViewer, nmap, and\nping, it is possible to create a dynamic environment that can adapt to the\nactions of attackers and provide insight into their tactics, techniques, and\nprocedures (TTPs). The paper illustrates ten diverse tasks that a\nconversational agent or large language model might answer appropriately to the\neffects of command-line attacker. The original result features feasibility\nstudies for ten model tasks meant for defensive teams to mimic expected\nhoneypot interfaces with minimal risks. Ultimately, the usefulness outside of\nforensic activities stems from whether the dynamic honeypot can extend the\ntime-to-conquer or otherwise delay attacker timelines short of reaching key\nnetwork assets like databases or confidential information. While ongoing\nmaintenance and monitoring may be required, ChatGPT's ability to detect and\ndeflect malicious activity makes it a valuable option for organizations seeking\nto enhance their cyber security posture. Future work will focus on\ncybersecurity layers, including perimeter security, host virus detection, and\ndata security.\n",
                "链接": "https://arxiv.org/abs/2301.03771"
            },
            {
                "文章ID": "61038",
                "标题": "Large Language Models for Code: Security Hardening and Adversarial\n  Testing",
                "作者": " Jingxuan He,  Martin Vechev",
                "发布日期": "2023-10-02",
                "摘要": "  Large language models (large LMs) are increasingly trained on massive\ncodebases and used to generate code. However, LMs lack awareness of security\nand are found to frequently produce unsafe code. This work studies the security\nof LMs along two important axes: (i) security hardening, which aims to enhance\nLMs' reliability in generating secure code, and (ii) adversarial testing, which\nseeks to evaluate LMs' security at an adversarial standpoint. We address both\nof these by formulating a new security task called controlled code generation.\nThe task is parametric and takes as input a binary property to guide the LM to\ngenerate secure or unsafe code, while preserving the LM's capability of\ngenerating functionally correct code. We propose a novel learning-based\napproach called SVEN to solve this task. SVEN leverages property-specific\ncontinuous vectors to guide program generation towards the given property,\nwithout modifying the LM's weights. Our training procedure optimizes these\ncontinuous vectors by enforcing specialized loss terms on different regions of\ncode, using a high-quality dataset carefully curated by us. Our extensive\nevaluation shows that SVEN is highly effective in achieving strong security\ncontrol. For instance, a state-of-the-art CodeGen LM with 2.7B parameters\ngenerates secure code for 59.1% of the time. When we employ SVEN to perform\nsecurity hardening (or adversarial testing) on this LM, the ratio is\nsignificantly boosted to 92.3% (or degraded to 36.8%). Importantly, SVEN\nclosely matches the original LMs in functional correctness.\n",
                "链接": "https://arxiv.org/abs/2302.05319"
            },
            {
                "文章ID": "32433",
                "标题": "Threddy: An Interactive System for Personalized Thread-based Exploration\n  and Organization of Scientific Literature",
                "作者": " Hyeonsu B. Kang,  Joseph Chee Chang,  Yongsung Kim,  Aniket Kittur",
                "发布日期": "2022-08-17",
                "摘要": "  Reviewing the literature to understand relevant threads of past work is a\ncritical part of research and vehicle for learning. However, as the scientific\nliterature grows the challenges for users to find and make sense of the many\ndifferent threads of research grow as well. Previous work has helped scholars\nto find and group papers with citation information or textual similarity using\nstandalone tools or overview visualizations. Instead, in this work we explore a\ntool integrated into users' reading process that helps them with leveraging\nauthors' existing summarization of threads, typically in introduction or\nrelated work sections, in order to situate their own work's contributions. To\nexplore this we developed a prototype that supports efficient extraction and\norganization of threads along with supporting evidence as scientists read\nresearch articles. The system then recommends further relevant articles based\non user-created threads. We evaluate the system in a lab study and find that it\nhelps scientists to follow and curate research threads without breaking out of\ntheir flow of reading, collect relevant papers and clips, and discover\ninteresting new articles to further grow threads.\n",
                "链接": "https://arxiv.org/abs/2208.03455"
            },
            {
                "文章ID": "102828",
                "标题": "Automated Interviewer or Augmented Survey? Collecting Social Data with\n  Large Language Models",
                "作者": " Alejandro Cuevas Villalba,  Eva M. Brown,  Jennifer V. Scurrell,  Jason Entenmann,  Madeleine I. G. Daepp",
                "发布日期": "2023-10-12",
                "摘要": "  Qualitative methods like interviews produce richer data in comparison with\nquantitative surveys, but are difficult to scale. Switching from web-based\nquestionnaires to interactive chatbots offers a compromise, improving user\nengagement and response quality. Uptake remains limited, however, because of\ndifferences in users' expectations versus the capabilities of natural language\nprocessing methods. In this study, we evaluate the potential of large language\nmodels (LLMs) to support an information elicitation chatbot that narrows this\n\"gulf of expectations\" (Luger & Sellen 2016). We conduct a user study in which\nparticipants (N = 399) were randomly assigned to interact with a rule-based\nchatbot versus one of two LLM-augmented chatbots. We observe limited evidence\nof differences in user engagement or response richness between conditions.\nHowever, the addition of LLM-based dynamic probing skills produces significant\nimprovements in both quantitative and qualitative measures of user experience,\nconsistent with a narrowing of the expectations gulf.\n",
                "链接": "https://arxiv.org/abs/2309.10187"
            }
        ]
    },
    {
        "question": {
            "question": "查找大模型推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "105661",
                "标题": "Reasoning on Graphs: Faithful and Interpretable Large Language Model\n  Reasoning",
                "作者": " Linhao Luo,  Yuan-Fang Li,  Gholamreza Haffari,  Shirui Pan",
                "发布日期": "2023-10-03",
                "摘要": "  Large language models (LLMs) have demonstrated impressive reasoning abilities\nin complex tasks. However, they lack up-to-date knowledge and experience\nhallucinations during reasoning, which can lead to incorrect reasoning\nprocesses and diminish their performance and trustworthiness. Knowledge graphs\n(KGs), which capture vast amounts of facts in a structured format, offer a\nreliable source of knowledge for reasoning. Nevertheless, existing KG-based LLM\nreasoning methods only treat KGs as factual knowledge bases and overlook the\nimportance of their structural information for reasoning. In this paper, we\npropose a novel method called reasoning on graphs (RoG) that synergizes LLMs\nwith KGs to enable faithful and interpretable reasoning. Specifically, we\npresent a planning-retrieval-reasoning framework, where RoG first generates\nrelation paths grounded by KGs as faithful plans. These plans are then used to\nretrieve valid reasoning paths from the KGs for LLMs to conduct faithful\nreasoning. Furthermore, RoG not only distills knowledge from KGs to improve the\nreasoning ability of LLMs through training but also allows seamless integration\nwith any arbitrary LLMs during inference. Extensive experiments on two\nbenchmark KGQA datasets demonstrate that RoG achieves state-of-the-art\nperformance on KG reasoning tasks and generates faithful and interpretable\nreasoning results.\n",
                "链接": "https://arxiv.org/abs/2310.01061"
            },
            {
                "文章ID": "115724",
                "标题": "LLMs cannot find reasoning errors, but can correct them!",
                "作者": " Gladys Tyen,  Hassan Mansoor,  Peter Chen,  Tony Mak,  Victor Cărbune",
                "发布日期": "2023-11-16",
                "摘要": "  While self-correction has shown promise in improving LLM outputs in terms of\nstyle and quality (e.g. Chen et al., 2023; Madaan et al., 2023), recent\nattempts to self-correct logical or reasoning errors often cause correct\nanswers to become incorrect, resulting in worse performances overall (Huang et\nal., 2023). In this paper, we break down the self-correction process into two\ncore components: mistake finding and output correction. For mistake finding, we\nrelease BIG-Bench Mistake, a dataset of logical mistakes in Chain-of-Thought\nreasoning traces. We provide benchmark numbers for several state-of-the-art\nLLMs, and demonstrate that LLMs generally struggle with finding logical\nmistakes. For output correction, we propose a backtracking method which\nprovides large improvements when given information on mistake location. We\nconstrue backtracking as a lightweight alternative to reinforcement learning\nmethods, and show that it remains effective with a reward model at 60-70%\naccuracy.\n",
                "链接": "https://arxiv.org/abs/2311.08516"
            },
            {
                "文章ID": "94177",
                "标题": "LISA: Reasoning Segmentation via Large Language Model",
                "作者": " Xin Lai,  Zhuotao Tian,  Yukang Chen,  Yanwei Li,  Yuhui Yuan,  Shu Liu,  Jiaya Jia",
                "发布日期": "2023-08-04",
                "摘要": "  Although perception systems have made remarkable advancements in recent\nyears, they still rely on explicit human instruction to identify the target\nobjects or categories before executing visual recognition tasks. Such systems\nlack the ability to actively reason and comprehend implicit user intentions. In\nthis work, we propose a new segmentation task -- reasoning segmentation. The\ntask is designed to output a segmentation mask given a complex and implicit\nquery text. Furthermore, we establish a benchmark comprising over one thousand\nimage-instruction pairs, incorporating intricate reasoning and world knowledge\nfor evaluation purposes. Finally, we present LISA: large Language Instructed\nSegmentation Assistant, which inherits the language generation capabilities of\nthe multi-modal Large Language Model (LLM) while also possessing the ability to\nproduce segmentation masks. We expand the original vocabulary with a <SEG>\ntoken and propose the embedding-as-mask paradigm to unlock the segmentation\ncapability. Remarkably, LISA can handle cases involving: 1) complex reasoning;\n2) world knowledge; 3) explanatory answers; 4) multi-turn conversation. Also,\nit demonstrates robust zero-shot capability when trained exclusively on\nreasoning-free datasets. In addition, fine-tuning the model with merely 239\nreasoning segmentation image-instruction pairs results in further performance\nenhancement. Experiments show our method not only unlocks new reasoning\nsegmentation capabilities but also proves effective in both complex reasoning\nsegmentation and standard referring segmentation tasks. Code, models, and demo\nare at https://github.com/dvlab-research/LISA.\n",
                "链接": "https://arxiv.org/abs/2308.00692"
            },
            {
                "文章ID": "120164",
                "标题": "PixelLM: Pixel Reasoning with Large Multimodal Model",
                "作者": " Zhongwei Ren,  Zhicheng Huang,  Yunchao Wei,  Yao Zhao,  Dongmei Fu,  Jiashi Feng,  Xiaojie Jin",
                "发布日期": "2023-12-06",
                "摘要": "  While large multimodal models (LMMs) have achieved remarkable progress,\ngenerating pixel-level masks for image reasoning tasks involving multiple\nopen-world targets remains a challenge. To bridge this gap, we introduce\nPixelLM, an effective and efficient LMM for pixel-level reasoning and\nunderstanding. Central to PixelLM is a novel, lightweight pixel decoder and a\ncomprehensive segmentation codebook. The decoder efficiently produces masks\nfrom the hidden embeddings of the codebook tokens, which encode detailed\ntarget-relevant information. With this design, PixelLM harmonizes with the\nstructure of popular LMMs and avoids the need for additional costly\nsegmentation models. Furthermore, we propose a target refinement loss to\nenhance the model's ability to differentiate between multiple targets, leading\nto substantially improved mask quality. To advance research in this area, we\nconstruct MUSE, a high-quality multi-target reasoning segmentation benchmark.\nPixelLM excels across various pixel-level image reasoning and understanding\ntasks, outperforming well-established methods in multiple benchmarks, including\nMUSE, single- and multi-referring segmentation. Comprehensive ablations confirm\nthe efficacy of each proposed component. All code, models, and datasets will be\npublicly available.\n",
                "链接": "https://arxiv.org/abs/2312.02228"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "79948",
                "标题": "Automatic Model Selection with Large Language Models for Reasoning",
                "作者": " James Xu Zhao,  Yuxi Xie,  Kenji Kawaguchi,  Junxian He,  Michael Qizhe Xie",
                "发布日期": "2023-10-24",
                "摘要": "  Chain-of-Thought (CoT) and Program-Aided Language Models (PAL) represent two\ndistinct reasoning methods, each with its own strengths. CoT employs natural\nlanguage, offering flexibility and interpretability, while PAL utilizes\nprogramming language, yielding more structured and rigorous logic. We introduce\na model selection method to combine the best of both worlds by employing a\nlarge language model (LLM) to dynamically select between them. Our theoretical\nanalysis underscores the feasibility of this method, which is further\ncorroborated by empirical results. Our proposed method demonstrates significant\nperformance improvements across eight reasoning datasets with Codex, ChatGPT,\nand GPT-4. Additionally, our method is complementary to self-consistency; when\nintegrated, it can further enhance performance while significantly reducing\ncomputation costs. Moreover, we achieve new state-of-the-art results on GSM8K\nand SVAMP, with respective accuracies of 96.8% and 93.7%. Our code, data and\nprompts are available at https://github.com/XuZhao0/Model-Selection-Reasoning\n",
                "链接": "https://arxiv.org/abs/2305.14333"
            },
            {
                "文章ID": "97658",
                "标题": "Enhancing Recommender Systems with Large Language Model Reasoning Graphs",
                "作者": " Yan Wang,  Zhixuan Chu,  Xin Ouyang,  Simeng Wang,  Hongyan Hao,  Yue Shen,  Jinjie Gu,  Siqiao Xue,  James Y Zhang,  Qing Cui,  Longfei Li,  Jun Zhou,  Sheng Li",
                "发布日期": "2023-08-22",
                "摘要": "  Recommendation systems aim to provide users with relevant suggestions, but\noften lack interpretability and fail to capture higher-level semantic\nrelationships between user behaviors and profiles. In this paper, we propose a\nnovel approach that leverages large language models (LLMs) to construct\npersonalized reasoning graphs. These graphs link a user's profile and\nbehavioral sequences through causal and logical inferences, representing the\nuser's interests in an interpretable way. Our approach, LLM reasoning graphs\n(LLMRG), has four components: chained graph reasoning, divergent extension,\nself-verification and scoring, and knowledge base self-improvement. The\nresulting reasoning graph is encoded using graph neural networks, which serves\nas additional input to improve conventional recommender systems, without\nrequiring extra user or item information. Our approach demonstrates how LLMs\ncan enable more logical and interpretable recommender systems through\npersonalized reasoning graphs. LLMRG allows recommendations to benefit from\nboth engineered recommendation systems and LLM-derived reasoning graphs. We\ndemonstrate the effectiveness of LLMRG on benchmarks and real-world scenarios\nin enhancing base recommendation models.\n",
                "链接": "https://arxiv.org/abs/2308.10835"
            },
            {
                "文章ID": "107444",
                "标题": "GraphLLM: Boosting Graph Reasoning Ability of Large Language Model",
                "作者": " Ziwei Chai,  Tianjie Zhang,  Liang Wu,  Kaiqiao Han,  Xiaohai Hu,  Xuanwen Huang,  Yang Yang",
                "发布日期": "2023-10-10",
                "摘要": "  The advancement of Large Language Models (LLMs) has remarkably pushed the\nboundaries towards artificial general intelligence (AGI), with their\nexceptional ability on understanding diverse types of information, including\nbut not limited to images and audio. Despite this progress, a critical gap\nremains in empowering LLMs to proficiently understand and reason on graph data.\nRecent studies underscore LLMs' underwhelming performance on fundamental graph\nreasoning tasks. In this paper, we endeavor to unearth the obstacles that\nimpede LLMs in graph reasoning, pinpointing the common practice of converting\ngraphs into natural language descriptions (Graph2Text) as a fundamental\nbottleneck. To overcome this impediment, we introduce GraphLLM, a pioneering\nend-to-end approach that synergistically integrates graph learning models with\nLLMs. This synergy equips LLMs with the ability to proficiently interpret and\nreason on graph data, harnessing the superior expressive power of graph\nlearning models. Our empirical evaluations across four fundamental graph\nreasoning tasks validate the effectiveness of GraphLLM. The results exhibit a\nsubstantial average accuracy enhancement of 54.44%, alongside a noteworthy\ncontext reduction of 96.45% across various graph reasoning tasks.\n",
                "链接": "https://arxiv.org/abs/2310.05845"
            },
            {
                "文章ID": "110171",
                "标题": "Democratizing Reasoning Ability: Tailored Learning from Large Language\n  Model",
                "作者": " Zhaoyang Wang,  Shaohan Huang,  Yuxuan Liu,  Jiahai Wang,  Minghui Song,  Zihan Zhang,  Haizhen Huang,  Furu Wei,  Weiwei Deng,  Feng Sun,  Qi Zhang",
                "发布日期": "2023-10-23",
                "摘要": "  Large language models (LLMs) exhibit impressive emergent abilities in natural\nlanguage processing, but their democratization is hindered due to huge\ncomputation requirements and closed-source nature. Recent research on advancing\nopen-source smaller LMs by distilling knowledge from black-box LLMs has\nobtained promising results in the instruction-following ability. However, the\nreasoning ability which is more challenging to foster, is relatively rarely\nexplored. In this paper, we propose a tailored learning approach to distill\nsuch reasoning ability to smaller LMs to facilitate the democratization of the\nexclusive reasoning ability. In contrast to merely employing LLM as a data\nannotator, we exploit the potential of LLM as a reasoning teacher by building\nan interactive multi-round learning paradigm. This paradigm enables the student\nto expose its deficiencies to the black-box teacher who then can provide\ncustomized training data in return. Further, to exploit the reasoning potential\nof the smaller LM, we propose self-reflection learning to motivate the student\nto learn from self-made mistakes. The learning from self-reflection and LLM are\nall tailored to the student's learning status, thanks to the seamless\nintegration with the multi-round learning paradigm. Comprehensive experiments\nand analysis on mathematical and commonsense reasoning tasks demonstrate the\neffectiveness of our method. The code will be available at\nhttps://github.com/Raibows/Learn-to-Reason.\n",
                "链接": "https://arxiv.org/abs/2310.13332"
            },
            {
                "文章ID": "66434",
                "标题": "HCI Papers Cite HCI Papers, Increasingly So",
                "作者": " Xiang 'Anthony' Chen",
                "发布日期": "2023-03-15",
                "摘要": "  We propose X-index -- the proportion of papers' citations coming from outside\ntheir research field -- and use this metric to analyze citations of CHI, UIST,\nand CSCW papers between 2010 and 2022. We found an overall decreasing X-index\nby several measures, indicating that HCI papers have been more and more likely\nto be cited by HCI papers rather than by non-HCI papers.\n",
                "链接": "https://arxiv.org/abs/2303.07539"
            }
        ]
    },
    {
        "question": {
            "question": "近几个月自然语言处理相关的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "26137",
                "标题": "Urdu News Article Recommendation Model using Natural Language Processing\n  Techniques",
                "作者": " Syed Zain Abbas,  Dr. Arif ur Rahman,  Abdul Basit Mughal,  Syed Mujtaba Haider",
                "发布日期": "2022-06-24",
                "摘要": "  There are several online newspapers in urdu but for the users it is difficult\nto find the content they are looking for because these most of them contain\nirrelevant data and most users did not get what they want to retrieve. Our\nproposed framework will help to predict Urdu news in the interests of users and\nreduce the users searching time for news. For this purpose, NLP techniques are\nused for pre-processing, and then TF-IDF with cosine similarity is used for\ngaining the highest similarity and recommended news on user preferences.\nMoreover, the BERT language model is also used for similarity, and by using the\nBERT model similarity increases as compared to TF-IDF so the approach works\nbetter with the BERT language model and recommends news to the user on their\ninterest. The news is recommended when the similarity of the articles is above\n60 percent.\n",
                "链接": "https://arxiv.org/abs/2206.11862"
            },
            {
                "文章ID": "44791",
                "标题": "Classification of Misinformation in New Articles using Natural Language\n  Processing and a Recurrent Neural Network",
                "作者": " Brendan Cunha,  Lydia Manikonda",
                "发布日期": "2022-10-26",
                "摘要": "  This paper seeks to address the classification of misinformation in news\narticles using a Long Short Term Memory Recurrent Neural Network. Articles were\ntaken from 2018; a year that was filled with reporters writing about President\nDonald Trump, Special Counsel Robert Mueller, the Fifa World Cup, and Russia.\nThe model presented successfully classifies these articles with an accuracy\nscore of 0.779944. We consider this to be successful because the model was\ntrained on articles that included languages other than English as well as\nincomplete, or fragmented, articles.\n",
                "链接": "https://arxiv.org/abs/2210.13534"
            },
            {
                "文章ID": "197",
                "标题": "Robust Natural Language Processing: Recent Advances, Challenges, and\n  Future Directions",
                "作者": " Marwan Omar,  Soohyeon Choi,  DaeHun Nyang,  David Mohaisen",
                "发布日期": "2022-10-24",
                "摘要": "  Recent natural language processing (NLP) techniques have accomplished high\nperformance on benchmark datasets, primarily due to the significant improvement\nin the performance of deep learning. The advances in the research community\nhave led to great enhancements in state-of-the-art production systems for NLP\ntasks, such as virtual assistants, speech recognition, and sentiment analysis.\nHowever, such NLP systems still often fail when tested with adversarial\nattacks. The initial lack of robustness exposed troubling gaps in current\nmodels' language understanding capabilities, creating problems when NLP systems\nare deployed in real life. In this paper, we present a structured overview of\nNLP robustness research by summarizing the literature in a systemic way across\nvarious dimensions. We then take a deep-dive into the various dimensions of\nrobustness, across techniques, metrics, embeddings, and benchmarks. Finally, we\nargue that robustness should be multi-dimensional, provide insights into\ncurrent research, identify gaps in the literature to suggest directions worth\npursuing to address these gaps.\n",
                "链接": "https://arxiv.org/abs/2201.00768"
            },
            {
                "文章ID": "65525",
                "标题": "Comprehensive Event Representations using Event Knowledge Graphs and\n  Natural Language Processing",
                "作者": " Tin Kuculo",
                "发布日期": "2023-03-09",
                "摘要": "  Recent work has utilised knowledge-aware approaches to natural language\nunderstanding, question answering, recommendation systems, and other tasks.\nThese approaches rely on well-constructed and large-scale knowledge graphs that\ncan be useful for many downstream applications and empower knowledge-aware\nmodels with commonsense reasoning. Such knowledge graphs are constructed\nthrough knowledge acquisition tasks such as relation extraction and knowledge\ngraph completion. This work seeks to utilise and build on the growing body of\nwork that uses findings from the field of natural language processing (NLP) to\nextract knowledge from text and build knowledge graphs. The focus of this\nresearch project is on how we can use transformer-based approaches to extract\nand contextualise event information, matching it to existing ontologies, to\nbuild a comprehensive knowledge of graph-based event representations.\nSpecifically, sub-event extraction is used as a way of creating sub-event-aware\nevent representations. These event representations are then further enriched\nthrough fine-grained location extraction and contextualised through the\nalignment of historically relevant quotes.\n",
                "链接": "https://arxiv.org/abs/2303.04794"
            },
            {
                "文章ID": "79436",
                "标题": "Interactive Natural Language Processing",
                "作者": " Zekun Wang,  Ge Zhang,  Kexin Yang,  Ning Shi,  Wangchunshu Zhou,  Shaochun Hao,  Guangzheng Xiong,  Yizhi Li,  Mong Yuan Sim,  Xiuying Chen,  Qingqing Zhu,  Zhenzhu Yang,  Adam Nik,  Qi Liu,  Chenghua Lin,  Shi Wang,  Ruibo Liu,  Wenhu Chen,  Ke Xu,  Dayiheng Liu,  Yike Guo,  Jie Fu",
                "发布日期": "2023-05-23",
                "摘要": "  Interactive Natural Language Processing (iNLP) has emerged as a novel\nparadigm within the field of NLP, aimed at addressing limitations in existing\nframeworks while aligning with the ultimate goals of artificial intelligence.\nThis paradigm considers language models as agents capable of observing, acting,\nand receiving feedback iteratively from external entities. Specifically,\nlanguage models in this context can: (1) interact with humans for better\nunderstanding and addressing user needs, personalizing responses, aligning with\nhuman values, and improving the overall user experience; (2) interact with\nknowledge bases for enriching language representations with factual knowledge,\nenhancing the contextual relevance of responses, and dynamically leveraging\nexternal information to generate more accurate and informed responses; (3)\ninteract with models and tools for effectively decomposing and addressing\ncomplex tasks, leveraging specialized expertise for specific subtasks, and\nfostering the simulation of social behaviors; and (4) interact with\nenvironments for learning grounded representations of language, and effectively\ntackling embodied tasks such as reasoning, planning, and decision-making in\nresponse to environmental observations. This paper offers a comprehensive\nsurvey of iNLP, starting by proposing a unified definition and framework of the\nconcept. We then provide a systematic classification of iNLP, dissecting its\nvarious components, including interactive objects, interaction interfaces, and\ninteraction methods. We proceed to delve into the evaluation methodologies used\nin the field, explore its diverse applications, scrutinize its ethical and\nsafety issues, and discuss prospective research directions. This survey serves\nas an entry point for researchers who are interested in this rapidly evolving\narea and offers a broad view of the current landscape and future trajectory of\niNLP.\n",
                "链接": "https://arxiv.org/abs/2305.13246"
            },
            {
                "文章ID": "68432",
                "标题": "SwissBERT: The Multilingual Language Model for Switzerland",
                "作者": " Jannis Vamvas,  Johannes Graën,  Rico Sennrich",
                "发布日期": "2023-06-13",
                "摘要": "  We present SwissBERT, a masked language model created specifically for\nprocessing Switzerland-related text. SwissBERT is a pre-trained model that we\nadapted to news articles written in the national languages of Switzerland --\nGerman, French, Italian, and Romansh. We evaluate SwissBERT on natural language\nunderstanding tasks related to Switzerland and find that it tends to outperform\nprevious models on these tasks, especially when processing contemporary news\nand/or Romansh Grischun. Since SwissBERT uses language adapters, it may be\nextended to Swiss German dialects in future work. The model and our open-source\ncode are publicly released at https://github.com/ZurichNLP/swissbert.\n",
                "链接": "https://arxiv.org/abs/2303.13310"
            },
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "28218",
                "标题": "Bayesian Modeling of Language-Evoked Event-Related Potentials",
                "作者": " Davide Turco,  Conor Houghton",
                "发布日期": "2022-08-17",
                "摘要": "  Bayesian hierarchical models are well-suited to analyzing the often noisy\ndata from electroencephalography experiments in cognitive neuroscience: these\nmodels provide an intuitive framework to account for structures and\ncorrelations in the data, and they allow a straightforward handling of\nuncertainty. In a typical neurolinguistic experiment, event-related potentials\nshow only very small effect sizes and frequentist approaches to data analysis\nfail to establish the significance of some of these effects. Here, we present a\nBayesian approach to analyzing event-related potentials using as an example\ndata from an experiment which relates word surprisal and neural response. Our\nmodel is able to estimate the effect of word surprisal on most components of\nthe event-related potential and provides a richer description of the data. The\nBayesian framework also allows easier comparison between estimates based on\nsurprisal values calculated using different language models.\n",
                "链接": "https://arxiv.org/abs/2207.03392"
            },
            {
                "文章ID": "60462",
                "标题": "Natural Language Processing for Policymaking",
                "作者": " Zhijing Jin,  Rada Mihalcea",
                "发布日期": "2023-02-08",
                "摘要": "  Language is the medium for many political activities, from campaigns to news\nreports. Natural language processing (NLP) uses computational tools to parse\ntext into key information that is needed for policymaking. In this chapter, we\nintroduce common methods of NLP, including text classification, topic modeling,\nevent extraction, and text scaling. We then overview how these methods can be\nused for policymaking through four major applications including data collection\nfor evidence-based policymaking, interpretation of political decisions, policy\ncommunication, and investigation of policy effects. Finally, we highlight some\npotential limitations and ethical concerns when using NLP for policymaking.\n  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational\nSocial Science for Policy (2023). Open Access on Springer:\nhttps://doi.org/10.1007/978-3-031-16624-2\n",
                "链接": "https://arxiv.org/abs/2302.03490"
            },
            {
                "文章ID": "24559",
                "标题": "Computational linguistics and Natural Language Processing",
                "作者": " Saturnino Luz",
                "发布日期": "2022-06-15",
                "摘要": "  This chapter provides an introduction to computational linguistics methods,\nwith focus on their applications to the practice and study of translation. It\ncovers computational models, methods and tools for collection, storage,\nindexing and analysis of linguistic data in the context of translation, and\ndiscusses the main methodological issues and challenges in this field. While an\nexhaustive review of existing computational linguistics methods and tools is\nbeyond the scope of this chapter, we describe the most representative\napproaches, and illustrate them with descriptions of typical applications.\n",
                "链接": "https://arxiv.org/abs/2206.07026"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于NLP领域的持续性学习论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "49978",
                "标题": "Continual Learning of Natural Language Processing Tasks: A Survey",
                "作者": " Zixuan Ke,  Bing Liu",
                "发布日期": "2023-05-12",
                "摘要": "  Continual learning (CL) is a learning paradigm that emulates the human\ncapability of learning and accumulating knowledge continually without\nforgetting the previously learned knowledge and also transferring the learned\nknowledge to help learn new tasks better. This survey presents a comprehensive\nreview and analysis of the recent progress of CL in NLP, which has significant\ndifferences from CL in computer vision and machine learning. It covers (1) all\nCL settings with a taxonomy of existing techniques; (2) catastrophic forgetting\n(CF) prevention, (3) knowledge transfer (KT), which is particularly important\nfor NLP tasks; and (4) some theory and the hidden challenge of inter-task class\nseparation (ICS). (1), (3) and (4) have not been included in the existing\nsurvey. Finally, a list of future directions is discussed.\n",
                "链接": "https://arxiv.org/abs/2211.12701"
            },
            {
                "文章ID": "42418",
                "标题": "On the Explainability of Natural Language Processing Deep Models",
                "作者": " Julia El Zini,  Mariette Awad",
                "发布日期": "2022-10-14",
                "摘要": "  While there has been a recent explosion of work on ExplainableAI ExAI on deep\nmodels that operate on imagery and tabular data, textual datasets present new\nchallenges to the ExAI community. Such challenges can be attributed to the lack\nof input structure in textual data, the use of word embeddings that add to the\nopacity of the models and the difficulty of the visualization of the inner\nworkings of deep models when they are trained on textual data.\n  Lately, methods have been developed to address the aforementioned challenges\nand present satisfactory explanations on Natural Language Processing (NLP)\nmodels. However, such methods are yet to be studied in a comprehensive\nframework where common challenges are properly stated and rigorous evaluation\npractices and metrics are proposed. Motivated to democratize ExAI methods in\nthe NLP field, we present in this work a survey that studies model-agnostic as\nwell as model-specific explainability methods on NLP models. Such methods can\neither develop inherently interpretable NLP models or operate on pre-trained\nmodels in a post-hoc manner. We make this distinction and we further decompose\nthe methods into three categories according to what they explain: (1) word\nembeddings (input-level), (2) inner workings of NLP models (processing-level)\nand (3) models' decisions (output-level). We also detail the different\nevaluation approaches interpretability methods in the NLP field. Finally, we\npresent a case-study on the well-known neural machine translation in an\nappendix and we propose promising future research directions for ExAI in the\nNLP field.\n",
                "链接": "https://arxiv.org/abs/2210.06929"
            },
            {
                "文章ID": "197",
                "标题": "Robust Natural Language Processing: Recent Advances, Challenges, and\n  Future Directions",
                "作者": " Marwan Omar,  Soohyeon Choi,  DaeHun Nyang,  David Mohaisen",
                "发布日期": "2022-10-24",
                "摘要": "  Recent natural language processing (NLP) techniques have accomplished high\nperformance on benchmark datasets, primarily due to the significant improvement\nin the performance of deep learning. The advances in the research community\nhave led to great enhancements in state-of-the-art production systems for NLP\ntasks, such as virtual assistants, speech recognition, and sentiment analysis.\nHowever, such NLP systems still often fail when tested with adversarial\nattacks. The initial lack of robustness exposed troubling gaps in current\nmodels' language understanding capabilities, creating problems when NLP systems\nare deployed in real life. In this paper, we present a structured overview of\nNLP robustness research by summarizing the literature in a systemic way across\nvarious dimensions. We then take a deep-dive into the various dimensions of\nrobustness, across techniques, metrics, embeddings, and benchmarks. Finally, we\nargue that robustness should be multi-dimensional, provide insights into\ncurrent research, identify gaps in the literature to suggest directions worth\npursuing to address these gaps.\n",
                "链接": "https://arxiv.org/abs/2201.00768"
            },
            {
                "文章ID": "95785",
                "标题": "Recent Advancements In The Field Of Deepfake Detection",
                "作者": " Natalie Krueger,  Dr. Mounika Vanamala,  Dr. Rushit Dave",
                "发布日期": "2023-08-11",
                "摘要": "  A deepfake is a photo or video of a person whose image has been digitally\naltered or partially replaced with an image of someone else. Deepfakes have the\npotential to cause a variety of problems and are often used maliciously. A\ncommon usage is altering videos of prominent political figures and celebrities.\nThese deepfakes can portray them making offensive, problematic, and/or untrue\nstatements. Current deepfakes can be very realistic, and when used in this way,\ncan spread panic and even influence elections and political opinions. There are\nmany deepfake detection strategies currently in use but finding the most\ncomprehensive and universal method is critical. So, in this survey we will\naddress the problems of malicious deepfake creation and the lack of universal\ndeepfake detection methods. Our objective is to survey and analyze a variety of\ncurrent methods and advances in the field of deepfake detection.\n",
                "链接": "https://arxiv.org/abs/2308.05563"
            },
            {
                "文章ID": "33809",
                "标题": "On the evolution of research in hypersonics: application of natural\n  language processing and machine learning",
                "作者": " Ashkan Ebadi,  Alain Auger,  Yvan Gauthier",
                "发布日期": "2022-08-22",
                "摘要": "  Research and development in hypersonics have progressed significantly in\nrecent years, with various military and commercial applications being\ndemonstrated increasingly. Public and private organizations in several\ncountries have been investing in hypersonics, with the aim to overtake their\ncompetitors and secure/improve strategic advantage and deterrence. For these\norganizations, being able to identify emerging technologies in a timely and\nreliable manner is paramount. Recent advances in information technology have\nmade it possible to analyze large amounts of data, extract hidden patterns, and\nprovide decision-makers with new insights. In this study, we focus on\nscientific publications about hypersonics within the period of 2000-2020, and\nemploy natural language processing and machine learning to characterize the\nresearch landscape by identifying 12 key latent research themes and analyzing\ntheir temporal evolution. Our publication similarity analysis revealed patterns\nthat are indicative of cycles during two decades of research. The study offers\na comprehensive analysis of the research field and the fact that the research\nthemes are algorithmically extracted removes subjectivity from the exercise and\nenables consistent comparisons between topics and between time intervals.\n",
                "链接": "https://arxiv.org/abs/2208.08507"
            },
            {
                "文章ID": "37115",
                "标题": "The Role of Explanatory Value in Natural Language Processing",
                "作者": " Kees van Deemter",
                "发布日期": "2022-09-14",
                "摘要": "  A key aim of science is explanation, yet the idea of explaining language\nphenomena has taken a backseat in mainstream Natural Language Processing (NLP)\nand many other areas of Artificial Intelligence. I argue that explanation of\nlinguistic behaviour should be a main goal of NLP, and that this is not the\nsame as making NLP models explainable. To illustrate these ideas, some recent\nmodels of human language production are compared with each other. I conclude by\nasking what it would mean for NLP research and institutional policies if our\ncommunity took explanatory value seriously, while heeding some possible\npitfalls.\n",
                "链接": "https://arxiv.org/abs/2209.06169"
            },
            {
                "文章ID": "42672",
                "标题": "The State of Profanity Obfuscation in Natural Language Processing",
                "作者": " Debora Nozza,  Dirk Hovy",
                "发布日期": "2022-10-17",
                "摘要": "  Work on hate speech has made the consideration of rude and harmful examples\nin scientific publications inevitable. This raises various problems, such as\nwhether or not to obscure profanities. While science must accurately disclose\nwhat it does, the unwarranted spread of hate speech is harmful to readers, and\nincreases its internet frequency. While maintaining publications' professional\nappearance, obfuscating profanities makes it challenging to evaluate the\ncontent, especially for non-native speakers. Surveying 150 ACL papers, we\ndiscovered that obfuscation is usually employed for English but not other\nlanguages, and even so quite uneven. We discuss the problems with obfuscation\nand suggest a multilingual community resource called PrOf that has a Python\nmodule to standardize profanity obfuscation processes. We believe PrOf can help\nscientific publication policies to make hate speech work accessible and\ncomparable, irrespective of language.\n",
                "链接": "https://arxiv.org/abs/2210.07595"
            },
            {
                "文章ID": "63180",
                "标题": "Natural Language Processing in the Legal Domain",
                "作者": " Daniel Martin Katz,  Dirk Hartung,  Lauritz Gerlach,  Abhik Jana, II Michael J. Bommarito",
                "发布日期": "2023-02-24",
                "摘要": "  In this paper, we summarize the current state of the field of NLP & Law with\na specific focus on recent technical and substantive developments. To support\nour analysis, we construct and analyze a nearly complete corpus of more than\nsix hundred NLP & Law related papers published over the past decade. Our\nanalysis highlights several major trends. Namely, we document an increasing\nnumber of papers written, tasks undertaken, and languages covered over the\ncourse of the past decade. We observe an increase in the sophistication of the\nmethods which researchers deployed in this applied context. Slowly but surely,\nLegal NLP is beginning to match not only the methodological sophistication of\ngeneral NLP but also the professional standards of data availability and code\nreproducibility observed within the broader scientific community. We believe\nall of these trends bode well for the future of the field, but many questions\nin both the academic and commercial sphere still remain open.\n",
                "链接": "https://arxiv.org/abs/2302.12039"
            },
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "92306",
                "标题": "An In-Depth Evaluation of Federated Learning on Biomedical Natural\n  Language Processing",
                "作者": " Le Peng,  Gaoxiang Luo,  sicheng zhou,  jiandong chen,  Rui Zhang,  Ziyue Xu,  Ju Sun",
                "发布日期": "2023-11-14",
                "摘要": "  Language models (LMs) such as BERT and GPT have revolutionized natural\nlanguage processing (NLP). However, the medical field faces challenges in\ntraining LMs due to limited data access and privacy constraints imposed by\nregulations like the Health Insurance Portability and Accountability Act\n(HIPPA) and the General Data Protection Regulation (GDPR). Federated learning\n(FL) offers a decentralized solution that enables collaborative learning while\nensuring data privacy. In this study, we evaluated FL on 2 biomedical NLP tasks\nencompassing 8 corpora using 6 LMs. Our results show that: 1) FL models\nconsistently outperformed models trained on individual clients' data and\nsometimes performed comparably with models trained with polled data; 2) with\nthe fixed number of total data, FL models training with more clients produced\ninferior performance but pre-trained transformer-based models exhibited great\nresilience. 3) FL models significantly outperformed large language models using\nzero-/one-shot learning and offered lightning inference speed.\n",
                "链接": "https://arxiv.org/abs/2307.11254"
            }
        ]
    },
    {
        "question": {
            "question": "找一下最近关于大模型评测的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "36772",
                "标题": "Multiple Object Tracking in Recent Times: A Literature Review",
                "作者": " Mk Bashar,  Samia Islam,  Kashifa Kawaakib Hussain,  Md. Bakhtiar Hasan,  A. B. M. Ashikur Rahman,  Md. Hasanul Kabir",
                "发布日期": "2022-09-13",
                "摘要": "  Multiple object tracking gained a lot of interest from researchers in recent\nyears, and it has become one of the trending problems in computer vision,\nespecially with the recent advancement of autonomous driving. MOT is one of the\ncritical vision tasks for different issues like occlusion in crowded scenes,\nsimilar appearance, small object detection difficulty, ID switching, etc. To\ntackle these challenges, as researchers tried to utilize the attention\nmechanism of transformer, interrelation of tracklets with graph convolutional\nneural network, appearance similarity of objects in different frames with the\nsiamese network, they also tried simple IOU matching based CNN network, motion\nprediction with LSTM. To take these scattered techniques under an umbrella, we\nhave studied more than a hundred papers published over the last three years and\nhave tried to extract the techniques that are more focused on by researchers in\nrecent times to solve the problems of MOT. We have enlisted numerous\napplications, possibilities, and how MOT can be related to real life. Our\nreview has tried to show the different perspectives of techniques that\nresearchers used overtimes and give some future direction for the potential\nresearchers. Moreover, we have included popular benchmark datasets and metrics\nin this review.\n",
                "链接": "https://arxiv.org/abs/2209.04796"
            },
            {
                "文章ID": "72313",
                "标题": "Evaluation of Social Biases in Recent Large Pre-Trained Models",
                "作者": " Swapnil Sharma,  Nikita Anand,  Kranthi Kiran G. V.,  Alind Jain",
                "发布日期": "2023-04-17",
                "摘要": "  Large pre-trained language models are widely used in the community. These\nmodels are usually trained on unmoderated and unfiltered data from open sources\nlike the Internet. Due to this, biases that we see in platforms online which\nare a reflection of those in society are in turn captured and learned by these\nmodels. These models are deployed in applications that affect millions of\npeople and their inherent biases are harmful to the targeted social groups. In\nthis work, we study the general trend in bias reduction as newer pre-trained\nmodels are released. Three recent models ( ELECTRA, DeBERTa, and DistilBERT)\nare chosen and evaluated against two bias benchmarks, StereoSet and\nCrowS-Pairs. They are compared to the baseline of BERT using the associated\nmetrics. We explore whether as advancements are made and newer, faster, lighter\nmodels are released: are they being developed responsibly such that their\ninherent social biases have been reduced compared to their older counterparts?\nThe results are compiled and we find that all the models under study do exhibit\nbiases but have generally improved as compared to BERT.\n",
                "链接": "https://arxiv.org/abs/2304.06861"
            },
            {
                "文章ID": "50485",
                "标题": "On the Effect of Anticipation on Reading Times",
                "作者": " Tiago Pimentel,  Clara Meister,  Ethan G. Wilcox,  Roger Levy,  Ryan Cotterell",
                "发布日期": "2023-07-17",
                "摘要": "  Over the past two decades, numerous studies have demonstrated how less\npredictable (i.e., higher surprisal) words take more time to read. In general,\nthese studies have implicitly assumed the reading process is purely responsive:\nReaders observe a new word and allocate time to process it as required. We\nargue that prior results are also compatible with a reading process that is at\nleast partially anticipatory: Readers could make predictions about a future\nword and allocate time to process it based on their expectation. In this work,\nwe operationalize this anticipation as a word's contextual entropy. We assess\nthe effect of anticipation on reading by comparing how well surprisal and\ncontextual entropy predict reading times on four naturalistic reading datasets:\ntwo self-paced and two eye-tracking. Experimentally, across datasets and\nanalyses, we find substantial evidence for effects of contextual entropy over\nsurprisal on a word's reading time (RT): in fact, entropy is sometimes better\nthan surprisal in predicting a word's RT. Spillover effects, however, are\ngenerally not captured by entropy, but only by surprisal. Further, we\nhypothesize four cognitive mechanisms through which contextual entropy could\nimpact RTs -- three of which we are able to design experiments to analyze.\nOverall, our results support a view of reading that is not just responsive, but\nalso anticipatory.\n",
                "链接": "https://arxiv.org/abs/2211.14301"
            },
            {
                "文章ID": "72848",
                "标题": "An Evaluation on Large Language Model Outputs: Discourse and\n  Memorization",
                "作者": " Adrian de Wynter,  Xun Wang,  Alex Sokolov,  Qilong Gu,  Si-Qing Chen",
                "发布日期": "2023-07-06",
                "摘要": "  We present an empirical evaluation of various outputs generated by nine of\nthe most widely-available large language models (LLMs). Our analysis is done\nwith off-the-shelf, readily-available tools. We find a correlation between\npercentage of memorized text, percentage of unique text, and overall output\nquality, when measured with respect to output pathologies such as\ncounterfactual and logically-flawed statements, and general failures like not\nstaying on topic. Overall, 80.0% of the outputs evaluated contained memorized\ndata, but outputs containing the most memorized content were also more likely\nto be considered of high quality. We discuss and evaluate mitigation\nstrategies, showing that, in the models evaluated, the rate of memorized text\nbeing output is reduced. We conclude with a discussion on potential\nimplications around what it means to learn, to memorize, and to evaluate\nquality text.\n",
                "链接": "https://arxiv.org/abs/2304.08637"
            },
            {
                "文章ID": "44667",
                "标题": "Facial Soft Biometrics for Recognition in the Wild: Recent Works,\n  Annotation, and COTS Evaluation",
                "作者": " Ester Gonzalez-Sosa,  Julian Fierrez,  Ruben Vera-Rodriguez,  Fernando Alonso-Fernandez",
                "发布日期": "2022-10-25",
                "摘要": "  The role of soft biometrics to enhance person recognition systems in\nunconstrained scenarios has not been extensively studied. Here, we explore the\nutility of the following modalities: gender, ethnicity, age, glasses, beard,\nand moustache. We consider two assumptions: 1) manual estimation of soft\nbiometrics and 2) automatic estimation from two commercial off-the-shelf\nsystems (COTS). All experiments are reported using the labeled faces in the\nwild (LFW) database. First, we study the discrimination capabilities of soft\nbiometrics standalone. Then, experiments are carried out fusing soft biometrics\nwith two state-of-the-art face recognition systems based on deep learning. We\nobserve that soft biometrics is a valuable complement to the face modality in\nunconstrained scenarios, with relative improvements up to 40%/15% in the\nverification performance when using manual/automatic soft biometrics\nestimation. Results are reproducible as we make public our manual annotations\nand COTS outputs of soft biometrics over LFW, as well as the face recognition\nscores.\n",
                "链接": "https://arxiv.org/abs/2210.13129"
            },
            {
                "文章ID": "86800",
                "标题": "Comparative Evaluation of Recent Universal Adversarial Perturbations in\n  Image Classification",
                "作者": " Juanjuan Weng,  Zhiming Luo,  Dazhen Lin,  Shaozi Li",
                "发布日期": "2023-06-21",
                "摘要": "  The vulnerability of Convolutional Neural Networks (CNNs) to adversarial\nsamples has recently garnered significant attention in the machine learning\ncommunity. Furthermore, recent studies have unveiled the existence of universal\nadversarial perturbations (UAPs) that are image-agnostic and highly\ntransferable across different CNN models. In this survey, our primary focus\nrevolves around the recent advancements in UAPs specifically within the image\nclassification task. We categorize UAPs into two distinct categories, i.e.,\nnoise-based attacks and generator-based attacks, thereby providing a\ncomprehensive overview of representative methods within each category. By\npresenting the computational details of these methods, we summarize various\nloss functions employed for learning UAPs. Furthermore, we conduct a\ncomprehensive evaluation of different loss functions within consistent training\nframeworks, including noise-based and generator-based. The evaluation covers a\nwide range of attack settings, including black-box and white-box attacks,\ntargeted and untargeted attacks, as well as the examination of defense\nmechanisms.\n  Our quantitative evaluation results yield several important findings\npertaining to the effectiveness of different loss functions, the selection of\nsurrogate CNN models, the impact of training data and data size, and the\ntraining frameworks involved in crafting universal attackers. Finally, to\nfurther promote future research on universal adversarial attacks, we provide\nsome visualizations of the perturbations and discuss the potential research\ndirections.\n",
                "链接": "https://arxiv.org/abs/2306.11261"
            },
            {
                "文章ID": "30386",
                "标题": "The trade-offs of model size in large recommendation models : A 10000\n  $\\times$ compressed criteo-tb DLRM model (100 GB parameters to mere 10MB)",
                "作者": " Aditya Desai,  Anshumali Shrivastava",
                "发布日期": "2022-07-25",
                "摘要": "  Embedding tables dominate industrial-scale recommendation model sizes, using\nup to terabytes of memory. A popular and the largest publicly available machine\nlearning MLPerf benchmark on recommendation data is a Deep Learning\nRecommendation Model (DLRM) trained on a terabyte of click-through data. It\ncontains 100GB of embedding memory (25+Billion parameters). DLRMs, due to their\nsheer size and the associated volume of data, face difficulty in training,\ndeploying for inference, and memory bottlenecks due to large embedding tables.\nThis paper analyzes and extensively evaluates a generic parameter sharing setup\n(PSS) for compressing DLRM models. We show theoretical upper bounds on the\nlearnable memory requirements for achieving $(1 \\pm \\epsilon)$ approximations\nto the embedding table. Our bounds indicate exponentially fewer parameters\nsuffice for good accuracy. To this end, we demonstrate a PSS DLRM reaching\n10000$\\times$ compression on criteo-tb without losing quality. Such a\ncompression, however, comes with a caveat. It requires 4.5 $\\times$ more\niterations to reach the same saturation quality. The paper argues that this\ntradeoff needs more investigations as it might be significantly favorable.\nLeveraging the small size of the compressed model, we show a 4.3$\\times$\nimprovement in training latency leading to similar overall training times.\nThus, in the tradeoff between system advantage of a small DLRM model vs. slower\nconvergence, we show that scales are tipped towards having a smaller DLRM\nmodel, leading to faster inference, easier deployment, and similar training\ntimes.\n",
                "链接": "https://arxiv.org/abs/2207.10731"
            },
            {
                "文章ID": "6997",
                "标题": "Matching Papers and Reviewers at Large Conferences",
                "作者": " Kevin Leyton-Brown,   Mausam,  Yatin Nandwani,  Hedayat Zarkoob,  Chris Cameron,  Neil Newman,  Dinesh Raghu",
                "发布日期": "2022-08-08",
                "摘要": "  Peer-reviewed conferences, the main publication venues in CS, rely critically\non matching highly qualified reviewers for each paper. Because of the growing\nscale of these conferences, the tight timelines on which they operate, and a\nrecent surge in explicitly dishonest behavior, there is now no alternative to\nperforming this matching in an automated way. This paper studies a novel\nreviewer-paper matching approach that was recently deployed in the 35th AAAI\nConference on Artificial Intelligence (AAAI 2021), and has since been adopted\n(wholly or partially) by other conferences including ICML 2022, AAAI 2022, and\nIJCAI 2022. This approach has three main elements: (1) collecting and\nprocessing input data to identify problematic matches and generate\nreviewer-paper scores; (2) formulating and solving an optimization problem to\nfind good reviewer-paper matchings; and (3) a two-phase reviewing process that\nshifts reviewing resources away from papers likely to be rejected and towards\npapers closer to the decision boundary. This paper also describes an evaluation\nof these innovations based on an extensive post-hoc analysis on real data --\nincluding a comparison with the matching algorithm used in AAAI's previous\n(2020) iteration -- and supplements this with additional numerical\nexperimentation.\n",
                "链接": "https://arxiv.org/abs/2202.12273"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            }
        ]
    },
    {
        "question": {
            "question": "近一个月与多模态大模型相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "114068",
                "标题": "GLaMM: Pixel Grounding Large Multimodal Model",
                "作者": " Hanoona Rasheed,  Muhammad Maaz,  Sahal Shaji,  Abdelrahman Shaker,  Salman Khan,  Hisham Cholakkal,  Rao M. Anwer,  Erix Xing,  Ming-Hsuan Yang,  Fahad S. Khan",
                "发布日期": "2023-11-07",
                "摘要": "  Large Multimodal Models (LMMs) extend Large Language Models to the vision\ndomain. Initial efforts towards LMMs used holistic images and text prompts to\ngenerate ungrounded textual responses. Very recently, region-level LMMs have\nbeen used to generate visually grounded responses. However, they are limited to\nonly referring a single object category at a time, require users to specify the\nregions in inputs, or cannot offer dense pixel-wise object grounding. In this\nwork, we present Grounding LMM (GLaMM), the first model that can generate\nnatural language responses seamlessly intertwined with corresponding object\nsegmentation masks. GLaMM not only grounds objects appearing in the\nconversations but is flexible enough to accept both textual and optional visual\nprompts (region of interest) as input. This empowers users to interact with the\nmodel at various levels of granularity, both in textual and visual domains. Due\nto the lack of standard benchmarks for the novel setting of generating visually\ngrounded detailed conversations, we introduce a comprehensive evaluation\nprotocol with our curated grounded conversations. Our proposed Grounded\nConversation Generation (GCG) task requires densely grounded concepts in\nnatural scenes at a large-scale. To this end, we propose a densely annotated\nGrounding-anything Dataset (GranD) using our proposed automated annotation\npipeline that encompasses 7.5M unique concepts grounded in a total of 810M\nregions available with segmentation masks. Besides GCG, GLaMM also performs\neffectively on several downstream tasks e.g., referring expression\nsegmentation, image and region-level captioning and vision-language\nconversations. Project Page: https://mbzuai-oryx.github.io/groundingLMM.\n",
                "链接": "https://arxiv.org/abs/2311.03356"
            },
            {
                "文章ID": "97795",
                "标题": "Federated Learning in Big Model Era: Domain-Specific Multimodal Large\n  Models",
                "作者": " Zengxiang Li,  Zhaoxiang Hou,  Hui Liu,  Ying Wang,  Tongzhi Li,  Longfei Xie,  Chao Shi,  Chengyi Yang,  Weishan Zhang,  Zelei Liu,  Liang Xu",
                "发布日期": "2023-08-25",
                "摘要": "  Multimodal data, which can comprehensively perceive and recognize the\nphysical world, has become an essential path towards general artificial\nintelligence. However, multimodal large models trained on public datasets often\nunderperform in specific industrial domains. This paper proposes a multimodal\nfederated learning framework that enables multiple enterprises to utilize\nprivate domain data to collaboratively train large models for vertical domains,\nachieving intelligent services across scenarios. The authors discuss in-depth\nthe strategic transformation of federated learning in terms of intelligence\nfoundation and objectives in the era of big model, as well as the new\nchallenges faced in heterogeneous data, model aggregation, performance and cost\ntrade-off, data privacy, and incentive mechanism. The paper elaborates a case\nstudy of leading enterprises contributing multimodal data and expert knowledge\nto city safety operation management , including distributed deployment and\nefficient coordination of the federated learning platform, technical\ninnovations on data quality improvement based on large model capabilities and\nefficient joint fine-tuning approaches. Preliminary experiments show that\nenterprises can enhance and accumulate intelligent capabilities through\nmultimodal model federated learning, thereby jointly creating an smart city\nmodel that provides high-quality intelligent services covering energy\ninfrastructure safety, residential community security, and urban operation\nmanagement. The established federated learning cooperation ecosystem is\nexpected to further aggregate industry, academia, and research resources,\nrealize large models in multiple vertical domains, and promote the large-scale\nindustrial application of artificial intelligence and cutting-edge research on\nmultimodal federated learning.\n",
                "链接": "https://arxiv.org/abs/2308.11217"
            },
            {
                "文章ID": "100082",
                "标题": "Large AI Model Empowered Multimodal Semantic Communications",
                "作者": " Feibo Jiang,  Yubo Peng,  Li Dong,  Kezhi Wang,  Kun Yang,  Cunhua Pan,  Xiaohu You",
                "发布日期": "2023-09-06",
                "摘要": "  Multimodal signals, including text, audio, image and video, can be integrated\ninto Semantic Communication (SC) for providing an immersive experience with low\nlatency and high quality at the semantic level. However, the multimodal SC has\nseveral challenges, including data heterogeneity, semantic ambiguity, and\nsignal fading. Recent advancements in large AI models, particularly in\nMultimodal Language Model (MLM) and Large Language Model (LLM), offer potential\nsolutions for these issues. To this end, we propose a Large AI Model-based\nMultimodal SC (LAM-MSC) framework, in which we first present the MLM-based\nMultimodal Alignment (MMA) that utilizes the MLM to enable the transformation\nbetween multimodal and unimodal data while preserving semantic consistency.\nThen, a personalized LLM-based Knowledge Base (LKB) is proposed, which allows\nusers to perform personalized semantic extraction or recovery through the LLM.\nThis effectively addresses the semantic ambiguity. Finally, we apply the\nConditional Generative adversarial networks-based channel Estimation (CGE) to\nobtain Channel State Information (CSI). This approach effectively mitigates the\nimpact of fading channels in SC. Finally, we conduct simulations that\ndemonstrate the superior performance of the LAM-MSC framework.\n",
                "链接": "https://arxiv.org/abs/2309.01249"
            },
            {
                "文章ID": "108480",
                "标题": "Multimodal Large Language Model for Visual Navigation",
                "作者": " Yao-Hung Hubert Tsai,  Vansh Dhar,  Jialu Li,  Bowen Zhang,  Jian Zhang",
                "发布日期": "2023-11-07",
                "摘要": "  Recent efforts to enable visual navigation using large language models have\nmainly focused on developing complex prompt systems. These systems incorporate\ninstructions, observations, and history into massive text prompts, which are\nthen combined with pre-trained large language models to facilitate visual\nnavigation. In contrast, our approach aims to fine-tune large language models\nfor visual navigation without extensive prompt engineering. Our design involves\na simple text prompt, current observations, and a history collector model that\ngathers information from previous observations as input. For output, our design\nprovides a probability distribution of possible actions that the agent can take\nduring navigation. We train our model using human demonstrations and collision\nsignals from the Habitat-Matterport 3D Dataset (HM3D). Experimental results\ndemonstrate that our method outperforms state-of-the-art behavior cloning\nmethods and effectively reduces collision rates.\n",
                "链接": "https://arxiv.org/abs/2310.08669"
            },
            {
                "文章ID": "120164",
                "标题": "PixelLM: Pixel Reasoning with Large Multimodal Model",
                "作者": " Zhongwei Ren,  Zhicheng Huang,  Yunchao Wei,  Yao Zhao,  Dongmei Fu,  Jiashi Feng,  Xiaojie Jin",
                "发布日期": "2023-12-06",
                "摘要": "  While large multimodal models (LMMs) have achieved remarkable progress,\ngenerating pixel-level masks for image reasoning tasks involving multiple\nopen-world targets remains a challenge. To bridge this gap, we introduce\nPixelLM, an effective and efficient LMM for pixel-level reasoning and\nunderstanding. Central to PixelLM is a novel, lightweight pixel decoder and a\ncomprehensive segmentation codebook. The decoder efficiently produces masks\nfrom the hidden embeddings of the codebook tokens, which encode detailed\ntarget-relevant information. With this design, PixelLM harmonizes with the\nstructure of popular LMMs and avoids the need for additional costly\nsegmentation models. Furthermore, we propose a target refinement loss to\nenhance the model's ability to differentiate between multiple targets, leading\nto substantially improved mask quality. To advance research in this area, we\nconstruct MUSE, a high-quality multi-target reasoning segmentation benchmark.\nPixelLM excels across various pixel-level image reasoning and understanding\ntasks, outperforming well-established methods in multiple benchmarks, including\nMUSE, single- and multi-referring segmentation. Comprehensive ablations confirm\nthe efficacy of each proposed component. All code, models, and datasets will be\npublicly available.\n",
                "链接": "https://arxiv.org/abs/2312.02228"
            },
            {
                "文章ID": "104627",
                "标题": "Jointly Training Large Autoregressive Multimodal Models",
                "作者": " Emanuele Aiello,  Lili Yu,  Yixin Nie,  Armen Aghajanyan,  Barlas Oguz",
                "发布日期": "2023-09-29",
                "摘要": "  In recent years, advances in the large-scale pretraining of language and\ntext-to-image models have revolutionized the field of machine learning. Yet,\nintegrating these two modalities into a single, robust model capable of\ngenerating seamless multimodal outputs remains a significant challenge. To\naddress this gap, we present the Joint Autoregressive Mixture (JAM) framework,\na modular approach that systematically fuses existing text and image generation\nmodels. We also introduce a specialized, data-efficient instruction-tuning\nstrategy, tailored for mixed-modal generation tasks. Our final instruct-tuned\nmodel demonstrates unparalleled performance in generating high-quality\nmultimodal outputs and represents the first model explicitly designed for this\npurpose.\n",
                "链接": "https://arxiv.org/abs/2309.15564"
            },
            {
                "文章ID": "117408",
                "标题": "Multimodal Large Language Models: A Survey",
                "作者": " Jiayang Wu,  Wensheng Gan,  Zefeng Chen,  Shicheng Wan,  Philip S. Yu",
                "发布日期": "2023-11-23",
                "摘要": "  The exploration of multimodal language models integrates multiple data types,\nsuch as images, text, language, audio, and other heterogeneity. While the\nlatest large language models excel in text-based tasks, they often struggle to\nunderstand and process other data types. Multimodal models address this\nlimitation by combining various modalities, enabling a more comprehensive\nunderstanding of diverse data. This paper begins by defining the concept of\nmultimodal and examining the historical development of multimodal algorithms.\nFurthermore, we introduce a range of multimodal products, focusing on the\nefforts of major technology companies. A practical guide is provided, offering\ninsights into the technical aspects of multimodal models. Moreover, we present\na compilation of the latest algorithms and commonly used datasets, providing\nresearchers with valuable resources for experimentation and evaluation. Lastly,\nwe explore the applications of multimodal models and discuss the challenges\nassociated with their development. By addressing these aspects, this paper aims\nto facilitate a deeper understanding of multimodal models and their potential\nin various domains.\n",
                "链接": "https://arxiv.org/abs/2311.13165"
            },
            {
                "文章ID": "118536",
                "标题": "LLMGA: Multimodal Large Language Model based Generation Assistant",
                "作者": " Bin Xia,  Shiyin Wang,  Yingfan Tao,  Yitong Wang,  Jiaya Jia",
                "发布日期": "2023-12-13",
                "摘要": "  In this paper, we introduce a Multimodal Large Language Model-based\nGeneration Assistant (LLMGA), leveraging the vast reservoir of knowledge and\nproficiency in reasoning, comprehension, and response inherent in Large\nLanguage Models (LLMs) to assist users in image generation and editing.\nDiverging from existing approaches where Multimodal Large Language Models\n(MLLMs) generate fixed-size embeddings to control Stable Diffusion (SD), our\nLLMGA provides a detailed language generation prompt for precise control over\nSD. This not only augments LLM context understanding but also reduces noise in\ngeneration prompts, yields images with more intricate and precise content, and\nelevates the interpretability of the network. To this end, we curate a\ncomprehensive dataset comprising prompt refinement, similar image generation,\ninpainting $\\&$ outpainting, and visual question answering. Moreover, we\npropose a two-stage training scheme. In the first stage, we train the MLLM to\ngrasp the properties of image generation and editing, enabling it to generate\ndetailed prompts. In the second stage, we optimize SD to align with the MLLM's\ngeneration prompts. Additionally, we propose a reference-based restoration\nnetwork to alleviate texture, brightness, and contrast disparities between\ngenerated and preserved regions during image editing. Extensive results show\nthat LLMGA has promising generative capabilities and can enable wider\napplications in an interactive manner.\n",
                "链接": "https://arxiv.org/abs/2311.16500"
            },
            {
                "文章ID": "87495",
                "标题": "A Survey on Multimodal Large Language Models",
                "作者": " Shukang Yin,  Chaoyou Fu,  Sirui Zhao,  Ke Li,  Xing Sun,  Tong Xu,  Enhong Chen",
                "发布日期": "2023-06-26",
                "摘要": "  Multimodal Large Language Model (MLLM) recently has been a new rising\nresearch hotspot, which uses powerful Large Language Models (LLMs) as a brain\nto perform multimodal tasks. The surprising emergent capabilities of MLLM, such\nas writing stories based on images and OCR-free math reasoning, are rare in\ntraditional methods, suggesting a potential path to artificial general\nintelligence. In this paper, we aim to trace and summarize the recent progress\nof MLLM. First of all, we present the formulation of MLLM and delineate its\nrelated concepts. Then, we discuss the key techniques and applications,\nincluding Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning\n(M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning\n(LAVR). Finally, we discuss existing challenges and point out promising\nresearch directions. In light of the fact that the era of MLLM has only just\nbegun, we will keep updating this survey and hope it can inspire more research.\nAn associated GitHub link collecting the latest papers is available at\nhttps://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.\n",
                "链接": "https://arxiv.org/abs/2306.13549"
            },
            {
                "文章ID": "99625",
                "标题": "Socratis: Are large multimodal models emotionally aware?",
                "作者": " Katherine Deng,  Arijit Ray,  Reuben Tan,  Saadia Gabriel,  Bryan A. Plummer,  Kate Saenko",
                "发布日期": "2023-11-03",
                "摘要": "  Existing emotion prediction benchmarks contain coarse emotion labels which do\nnot consider the diversity of emotions that an image and text can elicit in\nhumans due to various reasons. Learning diverse reactions to multimodal content\nis important as intelligent machines take a central role in generating and\ndelivering content to society. To address this gap, we propose Socratis, a\nsocietal reactions benchmark, where each image-caption (IC) pair is annotated\nwith multiple emotions and the reasons for feeling them. Socratis contains 18K\nfree-form reactions for 980 emotions on 2075 image-caption pairs from 5\nwidely-read news and image-caption (IC) datasets. We benchmark the capability\nof state-of-the-art multimodal large language models to generate the reasons\nfor feeling an emotion given an IC pair. Based on a preliminary human study, we\nobserve that humans prefer human-written reasons over 2 times more often than\nmachine-generated ones. This shows our task is harder than standard generation\ntasks because it starkly contrasts recent findings where humans cannot tell\napart machine vs human-written news articles, for instance. We further see that\ncurrent captioning metrics based on large vision-language models also fail to\ncorrelate with human preferences. We hope that these findings and our benchmark\nwill inspire further research on training emotionally aware models.\n",
                "链接": "https://arxiv.org/abs/2308.16741"
            }
        ]
    },
    {
        "question": {
            "question": "查找近六个月工具学习评测数据集的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "34033",
                "标题": "SimLDA: A tool for topic model evaluation",
                "作者": " Rebecca M. C. Taylor,  Johan A. du Preez",
                "发布日期": "2022-08-22",
                "摘要": "  Variational Bayes (VB) applied to latent Dirichlet allocation (LDA) has\nbecome the most popular algorithm for aspect modeling. While sufficiently\nsuccessful in text topic extraction from large corpora, VB is less successful\nin identifying aspects in the presence of limited data. We present a novel\nvariational message passing algorithm as applied to Latent Dirichlet Allocation\n(LDA) and compare it with the gold standard VB and collapsed Gibbs sampling. In\nsituations where marginalisation leads to non-conjugate messages, we use ideas\nfrom sampling to derive approximate update equations. In cases where conjugacy\nholds, Loopy Belief update (LBU) (also known as Lauritzen-Spiegelhalter) is\nused. Our algorithm, ALBU (approximate LBU), has strong similarities with\nVariational Message Passing (VMP) (which is the message passing variant of VB).\nTo compare the performance of the algorithms in the presence of limited data,\nwe use data sets consisting of tweets and news groups. Using coherence measures\nwe show that ALBU learns latent distributions more accurately than does VB,\nespecially for smaller data sets.\n",
                "链接": "https://arxiv.org/abs/2208.09299"
            },
            {
                "文章ID": "98573",
                "标题": "Six Lectures on Linearized Neural Networks",
                "作者": " Theodor Misiakiewicz,  Andrea Montanari",
                "发布日期": "2023-08-28",
                "摘要": "  In these six lectures, we examine what can be learnt about the behavior of\nmulti-layer neural networks from the analysis of linear models. We first recall\nthe correspondence between neural networks and linear models via the so-called\nlazy regime. We then review four models for linearized neural networks: linear\nregression with concentrated features, kernel ridge regression, random feature\nmodel and neural tangent model. Finally, we highlight the limitations of the\nlinear theory and discuss how other approaches can overcome them.\n",
                "链接": "https://arxiv.org/abs/2308.13431"
            },
            {
                "文章ID": "53126",
                "标题": "AliCHI: A Large-scale Multi-modal Dataset and Automated Evaluation Tool\n  for Human-like Dialogue Systems",
                "作者": " Zhiling Luo,  Qiankun Shi,  Sha Zhao,  Wei Zhou,  Haiqing Chen,  Yuankai Ma,  Haitao Leng",
                "发布日期": "2022-12-13",
                "摘要": "  A well-designed interactive human-like dialogue system is expected to take\nactions (e.g. smiling) and respond in a pattern similar to humans. However, due\nto the limitation of single-modality (only speech) or small volume of currently\npublic datasets, most dialogue systems can only respond in speech and cannot\ntake human-like actions. In this work, we build a large-scale multi-modal\ndataset of human-to-human conversation in a face-to-face fashion, with\nfine-grained annotations. The raw data in video format contains 635 dialogue\nsessions, being collected from 200 participants on designed topics and lasting\n52 hours in total. Moreover, we manually annotated the verbal and non-verbal\nbehaviors in each dialogue session on their start/end timestamp. Furthermore,\nwe developed a corresponding evaluation tool for human-like dialogue systems to\nautomatically evaluates the accuracy of two basic tasks, turn-taking\nprediction, and backchannel prediction, on both time and content. We have\nopened the data, the tools will be released at the conference.\n",
                "链接": "https://arxiv.org/abs/2212.05489"
            },
            {
                "文章ID": "25887",
                "标题": "Diagnostic Tool for Out-of-Sample Model Evaluation",
                "作者": " Ludvig Hult,  Dave Zachariah,  Petre Stoica",
                "发布日期": "2023-10-17",
                "摘要": "  Assessment of model fitness is a key part of machine learning. The standard\nparadigm is to learn models by minimizing a chosen loss function averaged over\ntraining data, with the aim of achieving small losses on future data. In this\npaper, we consider the use of a finite calibration data set to characterize the\nfuture, out-of-sample losses of a model. We propose a simple model diagnostic\ntool that provides finite-sample guarantees under weak assumptions. The tool is\nsimple to compute and to interpret. Several numerical experiments are presented\nto show how the proposed method quantifies the impact of distribution shifts,\naids the analysis of regression, and enables model selection as well as\nhyper-parameter tuning.\n",
                "链接": "https://arxiv.org/abs/2206.10982"
            },
            {
                "文章ID": "108993",
                "标题": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
                "作者": " Alon Jacovi,  Avi Caciularu,  Jonathan Herzig,  Roee Aharoni,  Bernd Bohnet,  Mor Geva",
                "发布日期": "2023-12-29",
                "摘要": "  A growing area of research investigates augmenting language models with tools\n(e.g., search engines, calculators) to overcome their shortcomings (e.g.,\nmissing or incorrect knowledge, incorrect logical inferences). Various few-shot\ntool-usage strategies have been proposed. However, there is no systematic and\nfair comparison across different strategies, or between these strategies and\nstrong baselines that do not leverage tools. We conduct an extensive empirical\nanalysis, finding that (1) across various datasets, example difficulty levels,\nand models, strong no-tool baselines are competitive to tool-assisted\nstrategies, implying that effectively using tools with in-context\ndemonstrations is a difficult unsolved problem; (2) for knowledge-retrieval\ntasks, strategies that *refine* incorrect outputs with tools outperform\nstrategies that retrieve relevant information *ahead of* or *during\ngeneration*; (3) tool-assisted strategies are expensive in the number of tokens\nthey require to work -- incurring additional costs by orders of magnitude --\nwhich does not translate into significant improvement in performance. Overall,\nour findings suggest that few-shot tool integration is still an open challenge,\nemphasizing the need for comprehensive evaluations of future strategies to\naccurately assess their *benefits* and *costs*.\n",
                "链接": "https://arxiv.org/abs/2310.10062"
            },
            {
                "文章ID": "33437",
                "标题": "ELEVANT: A Fully Automatic Fine-Grained Entity Linking Evaluation and\n  Analysis Tool",
                "作者": " Hannah Bast,  Matthias Hertel,  Natalie Prange",
                "发布日期": "2022-08-16",
                "摘要": "  We present Elevant, a tool for the fully automatic fine-grained evaluation of\na set of entity linkers on a set of benchmarks. Elevant provides an automatic\nbreakdown of the performance by various error categories and by entity type.\nElevant also provides a rich and compact, yet very intuitive and\nself-explanatory visualization of the results of a linker on a benchmark in\ncomparison to the ground truth. A live demo, the link to the complete code base\non GitHub and a link to a demo video are provided under\nhttps://elevant.cs.uni-freiburg.de .\n",
                "链接": "https://arxiv.org/abs/2208.07193"
            },
            {
                "文章ID": "24566",
                "标题": "RGB-Multispectral Matching: Dataset, Learning Methodology, Evaluation",
                "作者": " Fabio Tosi,  Pierluigi Zama Ramirez,  Matteo Poggi,  Samuele Salti,  Stefano Mattoccia,  Luigi Di Stefano",
                "发布日期": "2022-06-15",
                "摘要": "  We address the problem of registering synchronized color (RGB) and\nmulti-spectral (MS) images featuring very different resolution by solving\nstereo matching correspondences. Purposely, we introduce a novel RGB-MS dataset\nframing 13 different scenes in indoor environments and providing a total of 34\nimage pairs annotated with semi-dense, high-resolution ground-truth labels in\nthe form of disparity maps. To tackle the task, we propose a deep learning\narchitecture trained in a self-supervised manner by exploiting a further RGB\ncamera, required only during training data acquisition. In this setup, we can\nconveniently learn cross-modal matching in the absence of ground-truth labels\nby distilling knowledge from an easier RGB-RGB matching task based on a\ncollection of about 11K unlabeled image triplets. Experiments show that the\nproposed pipeline sets a good performance bar (1.16 pixels average registration\nerror) for future research on this novel, challenging task.\n",
                "链接": "https://arxiv.org/abs/2206.07047"
            },
            {
                "文章ID": "25784",
                "标题": "The Right Tool for the Job: Open-Source Auditing Tools in Machine\n  Learning",
                "作者": " Cherie M Poland",
                "发布日期": "2022-06-23",
                "摘要": "  In recent years, discussions about fairness in machine learning, AI ethics\nand algorithm audits have increased. Many entities have developed framework\nguidance to establish a baseline rubric for fairness and accountability.\nHowever, in spite of increased discussions and multiple frameworks, algorithm\nand data auditing still remain difficult to execute in practice. Many\nopen-source auditing tools are available, but users aren't always aware of the\ntools, what they are useful for, or how to access them. Model auditing and\nevaluation are not frequently emphasized skills in machine learning. There are\nalso legal reasons for the proactive adoption of these tools that extend beyond\nthe desire for greater fairness in machine learning. There are positive social\nissues of public perception and goodwill that matter in our highly connected\nglobal society. Greater awareness of these tools and the reasons for actively\nutilizing them may be helpful to the entire continuum of programmers, data\nscientists, engineers, researchers, users and consumers of AI and machine\nlearning products. It is important for everyone to better understand the input\nand output differentials, how they are occurring, and what can be done to\npromote FATE (fairness, accountability, transparency, and ethics) in machine-\nand deep learning. The ability to freely access open-source auditing tools\nremoves barriers to fairness assessment at the most basic levels of machine\nlearning. This paper aims to reinforce the urgent need to actually use these\ntools and provides motivations for doing so. The exemplary tools highlighted\nherein are open-source with software or code-base repositories available that\ncan be used immediately by anyone worldwide.\n",
                "链接": "https://arxiv.org/abs/2206.10613"
            },
            {
                "文章ID": "102940",
                "标题": "An Evaluation of GPT-4 on the ETHICS Dataset",
                "作者": " Sergey Rodionov,  Zarathustra Amadeus Goertzel,  Ben Goertzel",
                "发布日期": "2023-09-20",
                "摘要": "  This report summarizes a short study of the performance of GPT-4 on the\nETHICS dataset. The ETHICS dataset consists of five sub-datasets covering\ndifferent fields of ethics: Justice, Deontology, Virtue Ethics, Utilitarianism,\nand Commonsense Ethics. The moral judgments were curated so as to have a high\ndegree of agreement with the aim of representing shared human values rather\nthan moral dilemmas. GPT-4's performance is much better than that of previous\nmodels and suggests that learning to work with common human values is not the\nhard problem for AI ethics.\n",
                "链接": "https://arxiv.org/abs/2309.10492"
            },
            {
                "文章ID": "39258",
                "标题": "Critical Evaluation of LOCO dataset with Machine Learning",
                "作者": " Recep Savas,  Johannes Hinckeldeyn",
                "发布日期": "2022-09-28",
                "摘要": "  Purpose: Object detection is rapidly evolving through machine learning\ntechnology in automation systems. Well prepared data is necessary to train the\nalgorithms. Accordingly, the objective of this paper is to describe a\nre-evaluation of the so-called Logistics Objects in Context (LOCO) dataset,\nwhich is the first dataset for object detection in the field of intralogistics.\n  Methodology: We use an experimental research approach with three steps to\nevaluate the LOCO dataset. Firstly, the images on GitHub were analyzed to\nunderstand the dataset better. Secondly, Google Drive Cloud was used for\ntraining purposes to revisit the algorithmic implementation and training.\nLastly, the LOCO dataset was examined, if it is possible to achieve the same\ntraining results in comparison to the original publications.\n  Findings: The mean average precision, a common benchmark in object detection,\nachieved in our study was 64.54%, and shows a significant increase from the\ninitial study of the LOCO authors, achieving 41%. However, improvement\npotential is seen specifically within object types of forklifts and pallet\ntruck.\n  Originality: This paper presents the first critical replication study of the\nLOCO dataset for object detection in intralogistics. It shows that the training\nwith better hyperparameters based on LOCO can even achieve a higher accuracy\nthan presented in the original publication. However, there is also further room\nfor improving the LOCO dataset.\n",
                "链接": "https://arxiv.org/abs/2209.13499"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下工具评测相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "34033",
                "标题": "SimLDA: A tool for topic model evaluation",
                "作者": " Rebecca M. C. Taylor,  Johan A. du Preez",
                "发布日期": "2022-08-22",
                "摘要": "  Variational Bayes (VB) applied to latent Dirichlet allocation (LDA) has\nbecome the most popular algorithm for aspect modeling. While sufficiently\nsuccessful in text topic extraction from large corpora, VB is less successful\nin identifying aspects in the presence of limited data. We present a novel\nvariational message passing algorithm as applied to Latent Dirichlet Allocation\n(LDA) and compare it with the gold standard VB and collapsed Gibbs sampling. In\nsituations where marginalisation leads to non-conjugate messages, we use ideas\nfrom sampling to derive approximate update equations. In cases where conjugacy\nholds, Loopy Belief update (LBU) (also known as Lauritzen-Spiegelhalter) is\nused. Our algorithm, ALBU (approximate LBU), has strong similarities with\nVariational Message Passing (VMP) (which is the message passing variant of VB).\nTo compare the performance of the algorithms in the presence of limited data,\nwe use data sets consisting of tweets and news groups. Using coherence measures\nwe show that ALBU learns latent distributions more accurately than does VB,\nespecially for smaller data sets.\n",
                "链接": "https://arxiv.org/abs/2208.09299"
            },
            {
                "文章ID": "108993",
                "标题": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
                "作者": " Alon Jacovi,  Avi Caciularu,  Jonathan Herzig,  Roee Aharoni,  Bernd Bohnet,  Mor Geva",
                "发布日期": "2023-12-29",
                "摘要": "  A growing area of research investigates augmenting language models with tools\n(e.g., search engines, calculators) to overcome their shortcomings (e.g.,\nmissing or incorrect knowledge, incorrect logical inferences). Various few-shot\ntool-usage strategies have been proposed. However, there is no systematic and\nfair comparison across different strategies, or between these strategies and\nstrong baselines that do not leverage tools. We conduct an extensive empirical\nanalysis, finding that (1) across various datasets, example difficulty levels,\nand models, strong no-tool baselines are competitive to tool-assisted\nstrategies, implying that effectively using tools with in-context\ndemonstrations is a difficult unsolved problem; (2) for knowledge-retrieval\ntasks, strategies that *refine* incorrect outputs with tools outperform\nstrategies that retrieve relevant information *ahead of* or *during\ngeneration*; (3) tool-assisted strategies are expensive in the number of tokens\nthey require to work -- incurring additional costs by orders of magnitude --\nwhich does not translate into significant improvement in performance. Overall,\nour findings suggest that few-shot tool integration is still an open challenge,\nemphasizing the need for comprehensive evaluations of future strategies to\naccurately assess their *benefits* and *costs*.\n",
                "链接": "https://arxiv.org/abs/2310.10062"
            },
            {
                "文章ID": "67955",
                "标题": "Clustering US Counties to Find Patterns Related to the COVID-19 Pandemic",
                "作者": " Cora Brown,  Sarah Milstein,  Tianyi Sun,  Cooper Zhao",
                "发布日期": "2023-03-22",
                "摘要": "  When COVID-19 first started spreading and quarantine was implemented, the\nSociety for Industrial and Applied Mathematics (SIAM) Student Chapter at the\nUniversity of Minnesota-Twin Cities began a collaboration with Ecolab to use\nour skills as data scientists and mathematicians to extract useful insights\nfrom relevant data relating to the pandemic. This collaboration consisted of\nmultiple groups working on different projects. In this write-up we focus on\nusing clustering techniques to help us find groups of similar counties in the\nUS and use that to help us understand the pandemic. Our team for this project\nconsisted of University of Minnesota students Cora Brown, Sarah Milstein,\nTianyi Sun, and Cooper Zhao, with help from Ecolab Data Scientist Jimmy\nBroomfield and University of Minnesota student Skye Ke. In the sections below\nwe describe all of the work done for this project. In Section 2, we list the\ndata we gathered, as well as the feature engineering we performed. In Section\n3, we describe the metrics we used for evaluating our models. In Section 4, we\nexplain the methods we used for interpreting the results of our various\nclustering approaches. In Section 5, we describe the different clustering\nmethods we implemented. In Section 6, we present the results of our clustering\ntechniques and provide relevant interpretation. Finally, in Section 7, we\nprovide some concluding remarks comparing the different clustering methods.\n",
                "链接": "https://arxiv.org/abs/2303.11936"
            },
            {
                "文章ID": "18767",
                "标题": "ALIGNMEET: A Comprehensive Tool for Meeting Annotation, Alignment, and\n  Evaluation",
                "作者": " Peter Polák,  Muskaan Singh,  Anna Nedoluzhko,  Ondřej Bojar",
                "发布日期": "2022-05-12",
                "摘要": "  Summarization is a challenging problem, and even more challenging is to\nmanually create, correct, and evaluate the summaries. The severity of the\nproblem grows when the inputs are multi-party dialogues in a meeting setup. To\nfacilitate the research in this area, we present ALIGNMEET, a comprehensive\ntool for meeting annotation, alignment, and evaluation. The tool aims to\nprovide an efficient and clear interface for fast annotation while mitigating\nthe risk of introducing errors. Moreover, we add an evaluation mode that\nenables a comprehensive quality evaluation of meeting minutes. To the best of\nour knowledge, there is no such tool available. We release the tool as open\nsource. It is also directly installable from PyPI.\n",
                "链接": "https://arxiv.org/abs/2205.05433"
            },
            {
                "文章ID": "46198",
                "标题": "Evaluation Metrics for Symbolic Knowledge Extracted from Machine\n  Learning Black Boxes: A Discussion Paper",
                "作者": " Federico Sabbatini,  Roberta Calegari",
                "发布日期": "2022-11-02",
                "摘要": "  As opaque decision systems are being increasingly adopted in almost any\napplication field, issues about their lack of transparency and human\nreadability are a concrete concern for end-users. Amongst existing proposals to\nassociate human-interpretable knowledge with accurate predictions provided by\nopaque models, there are rule extraction techniques, capable of extracting\nsymbolic knowledge out of an opaque model. However, how to assess the level of\nreadability of the extracted knowledge quantitatively is still an open issue.\nFinding such a metric would be the key, for instance, to enable automatic\ncomparison between a set of different knowledge representations, paving the way\nfor the development of parameter autotuning algorithms for knowledge\nextractors. In this paper we discuss the need for such a metric as well as the\ncriticalities of readability assessment and evaluation, taking into account the\nmost common knowledge representations while highlighting the most puzzling\nissues.\n",
                "链接": "https://arxiv.org/abs/2211.00238"
            },
            {
                "文章ID": "88457",
                "标题": "CORAE: A Tool for Intuitive and Continuous Retrospective Evaluation of\n  Interactions",
                "作者": " Michael J. Sack,  Maria Teresa Parreira,  Jenny Fu,  Asher Lipman,  Hifza Javed,  Nawid Jamali,  Malte Jung",
                "发布日期": "2023-06-30",
                "摘要": "  This paper introduces CORAE, a novel web-based open-source tool for\nCOntinuous Retrospective Affect Evaluation, designed to capture continuous\naffect data about interpersonal perceptions in dyadic interactions. Grounded in\nbehavioral ecology perspectives of emotion, this approach replaces valence as\nthe relevant rating dimension with approach and withdrawal, reflecting the\ndegree to which behavior is perceived as increasing or decreasing social\ndistance. We conducted a study to experimentally validate the efficacy of our\nplatform with 24 participants. The tool's effectiveness was tested in the\ncontext of dyadic negotiation, revealing insights about how interpersonal\ndynamics evolve over time. We find that the continuous affect rating method is\nconsistent with individuals' perception of the overall interaction. This paper\ncontributes to the growing body of research on affective computing and offers a\nvaluable tool for researchers interested in investigating the temporal dynamics\nof affect and emotion in social interactions.\n",
                "链接": "https://arxiv.org/abs/2306.16629"
            },
            {
                "文章ID": "19420",
                "标题": "CurFi: An automated tool to find the best regression analysis model\n  using curve fitting",
                "作者": " Ayon Roy,  Tausif Al Zubayer,  Nafisa Tabassum,  Muhammad Nazrul Islam,  Md. Abdus Sattar",
                "发布日期": "2022-05-17",
                "摘要": "  Regression analysis is a well known quantitative research method that\nprimarily explores the relationship between one or more independent variables\nand a dependent variable. Conducting regression analysis manually on large\ndatasets with multiple independent variables can be tedious. An automated\nsystem for regression analysis will be of great help for researchers as well as\nnon-expert users. Thus, the objective of this research is to design and develop\nan automated curve fitting system. As outcome, a curve fitting system named\n\"CurFi\" was developed that uses linear regression models to fit a curve to a\ndataset and to find out the best fit model. The system facilitates to upload a\ndataset, split the dataset into training set and test set, select relevant\nfeatures and label from the dataset; and the system will return the best fit\nlinear regression model after training is completed. The developed tool would\nbe a great resource for the users having limited technical knowledge who will\nalso be able to find the best fit regression model for a dataset using the\ndeveloped \"CurFi\" system.\n",
                "链接": "https://arxiv.org/abs/2205.07804"
            },
            {
                "文章ID": "65053",
                "标题": "Population-based Evaluation in Repeated Rock-Paper-Scissors as a\n  Benchmark for Multiagent Reinforcement Learning",
                "作者": " Marc Lanctot,  John Schultz,  Neil Burch,  Max Olan Smith,  Daniel Hennes,  Thomas Anthony,  Julien Perolat",
                "发布日期": "2023-11-02",
                "摘要": "  Progress in fields of machine learning and adversarial planning has benefited\nsignificantly from benchmark domains, from checkers and the classic UCI data\nsets to Go and Diplomacy. In sequential decision-making, agent evaluation has\nlargely been restricted to few interactions against experts, with the aim to\nreach some desired level of performance (e.g. beating a human professional\nplayer). We propose a benchmark for multiagent learning based on repeated play\nof the simple game Rock, Paper, Scissors along with a population of forty-three\ntournament entries, some of which are intentionally sub-optimal. We describe\nmetrics to measure the quality of agents based both on average returns and\nexploitability. We then show that several RL, online learning, and language\nmodel approaches can learn good counter-strategies and generalize well, but\nultimately lose to the top-performing bots, creating an opportunity for\nresearch in multiagent learning.\n",
                "链接": "https://arxiv.org/abs/2303.03196"
            },
            {
                "文章ID": "25887",
                "标题": "Diagnostic Tool for Out-of-Sample Model Evaluation",
                "作者": " Ludvig Hult,  Dave Zachariah,  Petre Stoica",
                "发布日期": "2023-10-17",
                "摘要": "  Assessment of model fitness is a key part of machine learning. The standard\nparadigm is to learn models by minimizing a chosen loss function averaged over\ntraining data, with the aim of achieving small losses on future data. In this\npaper, we consider the use of a finite calibration data set to characterize the\nfuture, out-of-sample losses of a model. We propose a simple model diagnostic\ntool that provides finite-sample guarantees under weak assumptions. The tool is\nsimple to compute and to interpret. Several numerical experiments are presented\nto show how the proposed method quantifies the impact of distribution shifts,\naids the analysis of regression, and enables model selection as well as\nhyper-parameter tuning.\n",
                "链接": "https://arxiv.org/abs/2206.10982"
            },
            {
                "文章ID": "122150",
                "标题": "Can LLM find the green circle? Investigation and Human-guided tool\n  manipulation for compositional generalization",
                "作者": " Min Zhang,  Jianfeng He,  Shuo Lei,  Murong Yue,  Linhang Wang,  Chang-Tien Lu",
                "发布日期": "2023-12-14",
                "摘要": "  The meaning of complex phrases in natural language is composed of their\nindividual components. The task of compositional generalization evaluates a\nmodel's ability to understand new combinations of components. Previous studies\ntrained smaller, task-specific models, which exhibited poor generalization.\nWhile large language models (LLMs) exhibit impressive generalization abilities\non many tasks through in-context learning (ICL), their potential for\ncompositional generalization remains unexplored. In this paper, we first\nempirically investigate prevailing ICL methods in compositional generalization.\nWe find that they struggle with complex compositional questions due to\ncumulative errors in long reasoning steps and intricate logic required for\ntool-making. Consequently, we propose a human-guided tool manipulation\nframework (HTM) that generates tools for sub-questions and integrates multiple\ntools. Our method enhances the effectiveness of tool creation and usage with\nminimal human effort. Experiments show that our method achieves\nstate-of-the-art performance on two compositional generalization benchmarks and\noutperforms existing methods on the most challenging test split by 70%.\n",
                "链接": "https://arxiv.org/abs/2312.07763"
            }
        ]
    },
    {
        "question": {
            "question": "大模型在游戏方面的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "75161",
                "标题": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
                "作者": " Eddie Guo,  Mehul Gupta,  Jiawen Deng,  Ye-Jean Park,  Mike Paget,  Christopher Naugler",
                "发布日期": "2023-10-09",
                "摘要": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
                "链接": "https://arxiv.org/abs/2305.00844"
            },
            {
                "文章ID": "106983",
                "标题": "Kawaii Game Vocalics: A Preliminary Model",
                "作者": " Katie Seaborn,  Katja Rogers,  Somang Name,  Miu Kojima",
                "发布日期": "2023-10-10",
                "摘要": "  Kawaii is the Japanese concept of cute++, a global export with local\ncharacteristics. Recent work has explored kawaii as a feature of user\nexperience (UX) with social robots, virtual characters, and voice assistants,\ni.e., kawaii vocalics. Games have a long history of incorporating characters\nthat use voice as a means of expressing kawaii. Nevertheless, no work to date\nhas evaluated kawaii game voices or mapped out a model of kawaii game vocalics.\nIn this work, we explored whether and how a model of kawaii vocalics maps onto\ngame character voices. We conducted an online perceptions study (N=157) using\n18 voices from kawaii characters in Japanese games. We replicated the results\nfor computer voice and discovered nuanced relationships between gender and age,\nespecially youthfulness, agelessness, gender ambiguity, and gender neutrality.\nWe provide our initial model and advocate for future work on character visuals\nand within play contexts.\n",
                "链接": "https://arxiv.org/abs/2310.04731"
            },
            {
                "文章ID": "82791",
                "标题": "ReviewerGPT? An Exploratory Study on Using Large Language Models for\n  Paper Reviewing",
                "作者": " Ryan Liu,  Nihar B. Shah",
                "发布日期": "2023-06-02",
                "摘要": "  Given the rapid ascent of large language models (LLMs), we study the\nquestion: (How) can large language models help in reviewing of scientific\npapers or proposals? We first conduct some pilot studies where we find that (i)\nGPT-4 outperforms other LLMs (Bard, Vicuna, Koala, Alpaca, LLaMa, Dolly,\nOpenAssistant, StableLM), and (ii) prompting with a specific question (e.g., to\nidentify errors) outperforms prompting to simply write a review. With these\ninsights, we study the use of LLMs (specifically, GPT-4) for three tasks:\n  1. Identifying errors: We construct 13 short computer science papers each\nwith a deliberately inserted error, and ask the LLM to check for the\ncorrectness of these papers. We observe that the LLM finds errors in 7 of them,\nspanning both mathematical and conceptual errors.\n  2. Verifying checklists: We task the LLM to verify 16 closed-ended checklist\nquestions in the respective sections of 15 NeurIPS 2022 papers. We find that\nacross 119 {checklist question, paper} pairs, the LLM had an 86.6% accuracy.\n  3. Choosing the \"better\" paper: We generate 10 pairs of abstracts,\ndeliberately designing each pair in such a way that one abstract was clearly\nsuperior than the other. The LLM, however, struggled to discern these\nrelatively straightforward distinctions accurately, committing errors in its\nevaluations for 6 out of the 10 pairs.\n  Based on these experiments, we think that LLMs have a promising use as\nreviewing assistants for specific reviewing tasks, but not (yet) for complete\nevaluations of papers or proposals.\n",
                "链接": "https://arxiv.org/abs/2306.00622"
            },
            {
                "文章ID": "117394",
                "标题": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
                "作者": " Chengyu Wang,  Junbing Yan,  Wei Zhang,  Jun Huang",
                "发布日期": "2023-11-23",
                "摘要": "  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n",
                "链接": "https://arxiv.org/abs/2311.13126"
            },
            {
                "文章ID": "121257",
                "标题": "GlitchBench: Can large multimodal models detect video game glitches?",
                "作者": " Mohammad Reza Taesiri,  Tianjun Feng,  Cor-Paul Bezemer,  Anh Nguyen",
                "发布日期": "2023-12-12",
                "摘要": "  Large multimodal models (LMMs) have evolved from large language models (LLMs)\nto integrate multiple input modalities, such as visual inputs. This integration\naugments the capacity of LLMs for tasks requiring visual comprehension and\nreasoning. However, the extent and limitations of their enhanced abilities are\nnot fully understood, especially when it comes to real-world tasks. To address\nthis gap, we introduce GlitchBench, a novel benchmark derived from video game\nquality assurance tasks, to test and evaluate the reasoning capabilities of\nLMMs. Our benchmark is curated from a variety of unusual and glitched scenarios\nfrom video games and aims to challenge both the visual and linguistic reasoning\npowers of LMMs in detecting and interpreting out-of-the-ordinary events. We\nevaluate multiple state-of-the-art LMMs, and we show that GlitchBench presents\na new challenge for these models. Code and data are available at:\nhttps://glitchbench.github.io/\n",
                "链接": "https://arxiv.org/abs/2312.05291"
            },
            {
                "文章ID": "75237",
                "标题": "Multidimensional Fairness in Paper Recommendation",
                "作者": " Reem Alsaffar,  Susan Gauch,  Hiba Al-Kawaz",
                "发布日期": "2023-05-05",
                "摘要": "  To prevent potential bias in the paper review and selection process for\nconferences and journals, most include double blind review. Despite this,\nstudies show that bias still exists. Recommendation algorithms for paper review\nalso may have implicit bias. We offer three fair methods that specifically take\ninto account author diversity in paper recommendation to address this. Our\nmethods provide fair outcomes across many protected variables concurrently, in\ncontrast to typical fair algorithms that only use one protected variable. Five\ndemographic characteristics-gender, ethnicity, career stage, university rank,\nand geolocation-are included in our multidimensional author profiles. The\nOverall Diversity approach uses a score for overall diversity to rank\npublications. The Round Robin Diversity technique chooses papers from authors\nwho are members of each protected group in turn, whereas the Multifaceted\nDiversity method chooses papers that initially fill the demographic feature\nwith the highest importance. We compare the effectiveness of author diversity\nprofiles based on Boolean and continuous-valued features. By selecting papers\nfrom a pool of SIGCHI 2017, DIS 2017, and IUI 2017 papers, we recommend papers\nfor SIGCHI 2017 and evaluate these algorithms using the user profiles. We\ncontrast the papers that were recommended with those that were selected by the\nconference. We find that utilizing profiles with either Boolean or continuous\nfeature values, all three techniques boost diversity while just slightly\ndecreasing utility or not decreasing. By choosing authors who are 42.50% more\ndiverse and with a 2.45% boost in utility, our best technique, Multifaceted\nDiversity, suggests a set of papers that match demographic parity. The\nselection of grant proposals, conference papers, journal articles, and other\nacademic duties might all use this strategy.\n",
                "链接": "https://arxiv.org/abs/2305.01141"
            },
            {
                "文章ID": "104212",
                "标题": "Prediction Model For Wordle Game Results With High Robustness",
                "作者": " Jiaqi Weng,  Chunlin Feng",
                "发布日期": "2023-09-26",
                "摘要": "  In this study, we delve into the dynamics of Wordle using data analysis and\nmachine learning. Our analysis initially focused on the correlation between the\ndate and the number of submitted results. Due to initial popularity bias, we\nmodeled stable data using an ARIMAX model with coefficient values of 9, 0, 2,\nand weekdays/weekends as the exogenous variable. We found no significant\nrelationship between word attributes and hard mode results.\n  To predict word difficulty, we employed a Backpropagation Neural Network,\novercoming overfitting via feature engineering. We also used K-means\nclustering, optimized at five clusters, to categorize word difficulty\nnumerically. Our findings indicate that on March 1st, 2023, around 12,884\nresults will be submitted and the word \"eerie\" averages 4.8 attempts, falling\ninto the hardest difficulty cluster.\n  We further examined the percentage of loyal players and their propensity to\nundertake daily challenges. Our models underwent rigorous sensitivity analyses,\nincluding ADF, ACF, PACF tests, and cross-validation, confirming their\nrobustness. Overall, our study provides a predictive framework for Wordle\ngameplay based on date or a given five-letter word. Results have been\nsummarized and submitted to the Puzzle Editor of the New York Times.\n",
                "链接": "https://arxiv.org/abs/2309.14250"
            },
            {
                "文章ID": "108644",
                "标题": "The Consensus Game: Language Model Generation via Equilibrium Search",
                "作者": " Athul Paul Jacob,  Yikang Shen,  Gabriele Farina,  Jacob Andreas",
                "发布日期": "2023-10-16",
                "摘要": "  When applied to question answering and other text generation tasks, language\nmodels (LMs) may be queried generatively (by sampling answers from their output\ndistribution) or discriminatively (by using them to score or rank a set of\ncandidate outputs). These procedures sometimes yield very different\npredictions. How do we reconcile mutually incompatible scoring procedures to\nobtain coherent LM predictions? We introduce a new, a training-free,\ngame-theoretic procedure for language model decoding. Our approach casts\nlanguage model decoding as a regularized imperfect-information sequential\nsignaling game - which we term the CONSENSUS GAME - in which a GENERATOR seeks\nto communicate an abstract correctness parameter using natural language\nsentences to a DISCRIMINATOR. We develop computational procedures for finding\napproximate equilibria of this game, resulting in a decoding algorithm we call\nEQUILIBRIUM-RANKING. Applied to a large number of tasks (including reading\ncomprehension, commonsense reasoning, mathematical problem-solving, and\ndialog), EQUILIBRIUM-RANKING consistently, and sometimes substantially,\nimproves performance over existing LM decoding procedures - on multiple\nbenchmarks, we observe that applying EQUILIBRIUM-RANKING to LLaMA-7B\noutperforms the much larger LLaMA-65B and PaLM-540B models. These results\nhighlight the promise of game-theoretic tools for addressing fundamental\nchallenges of truthfulness and consistency in LMs.\n",
                "链接": "https://arxiv.org/abs/2310.09139"
            },
            {
                "文章ID": "101477",
                "标题": "Strategic Behavior of Large Language Models: Game Structure vs.\n  Contextual Framing",
                "作者": " Nunzio Lorè,  Babak Heydari",
                "发布日期": "2023-09-13",
                "摘要": "  This paper investigates the strategic decision-making capabilities of three\nLarge Language Models (LLMs): GPT-3.5, GPT-4, and LLaMa-2, within the framework\nof game theory. Utilizing four canonical two-player games -- Prisoner's\nDilemma, Stag Hunt, Snowdrift, and Prisoner's Delight -- we explore how these\nmodels navigate social dilemmas, situations where players can either cooperate\nfor a collective benefit or defect for individual gain. Crucially, we extend\nour analysis to examine the role of contextual framing, such as diplomatic\nrelations or casual friendships, in shaping the models' decisions. Our findings\nreveal a complex landscape: while GPT-3.5 is highly sensitive to contextual\nframing, it shows limited ability to engage in abstract strategic reasoning.\nBoth GPT-4 and LLaMa-2 adjust their strategies based on game structure and\ncontext, but LLaMa-2 exhibits a more nuanced understanding of the games'\nunderlying mechanics. These results highlight the current limitations and\nvaried proficiencies of LLMs in strategic decision-making, cautioning against\ntheir unqualified use in tasks requiring complex strategic reasoning.\n",
                "链接": "https://arxiv.org/abs/2309.05898"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "88755",
                "标题": "Geometric Autoencoders -- What You See is What You Decode",
                "作者": " Philipp Nazari,  Sebastian Damrich,  Fred A. Hamprecht",
                "发布日期": "2023-07-03",
                "摘要": "  Visualization is a crucial step in exploratory data analysis. One possible\napproach is to train an autoencoder with low-dimensional latent space. Large\nnetwork depth and width can help unfolding the data. However, such expressive\nnetworks can achieve low reconstruction error even when the latent\nrepresentation is distorted. To avoid such misleading visualizations, we\npropose first a differential geometric perspective on the decoder, leading to\ninsightful diagnostics for an embedding's distortion, and second a new\nregularizer mitigating such distortion. Our ``Geometric Autoencoder'' avoids\nstretching the embedding spuriously, so that the visualization captures the\ndata structure more faithfully. It also flags areas where little distortion\ncould not be achieved, thus guarding against misinterpretation.\n",
                "链接": "https://arxiv.org/abs/2306.17638"
            },
            {
                "文章ID": "75237",
                "标题": "Multidimensional Fairness in Paper Recommendation",
                "作者": " Reem Alsaffar,  Susan Gauch,  Hiba Al-Kawaz",
                "发布日期": "2023-05-05",
                "摘要": "  To prevent potential bias in the paper review and selection process for\nconferences and journals, most include double blind review. Despite this,\nstudies show that bias still exists. Recommendation algorithms for paper review\nalso may have implicit bias. We offer three fair methods that specifically take\ninto account author diversity in paper recommendation to address this. Our\nmethods provide fair outcomes across many protected variables concurrently, in\ncontrast to typical fair algorithms that only use one protected variable. Five\ndemographic characteristics-gender, ethnicity, career stage, university rank,\nand geolocation-are included in our multidimensional author profiles. The\nOverall Diversity approach uses a score for overall diversity to rank\npublications. The Round Robin Diversity technique chooses papers from authors\nwho are members of each protected group in turn, whereas the Multifaceted\nDiversity method chooses papers that initially fill the demographic feature\nwith the highest importance. We compare the effectiveness of author diversity\nprofiles based on Boolean and continuous-valued features. By selecting papers\nfrom a pool of SIGCHI 2017, DIS 2017, and IUI 2017 papers, we recommend papers\nfor SIGCHI 2017 and evaluate these algorithms using the user profiles. We\ncontrast the papers that were recommended with those that were selected by the\nconference. We find that utilizing profiles with either Boolean or continuous\nfeature values, all three techniques boost diversity while just slightly\ndecreasing utility or not decreasing. By choosing authors who are 42.50% more\ndiverse and with a 2.45% boost in utility, our best technique, Multifaceted\nDiversity, suggests a set of papers that match demographic parity. The\nselection of grant proposals, conference papers, journal articles, and other\nacademic duties might all use this strategy.\n",
                "链接": "https://arxiv.org/abs/2305.01141"
            },
            {
                "文章ID": "99517",
                "标题": "DECODE: DilatEd COnvolutional neural network for Detecting\n  Extreme-mass-ratio inspirals",
                "作者": " Tianyu Zhao,  Yue Zhou,  Ruijun Shi,  Zhoujian Cao,  Zhixiang Ren",
                "发布日期": "2023-10-17",
                "摘要": "  The detection of Extreme Mass Ratio Inspirals (EMRIs) is intricate due to\ntheir complex waveforms, extended duration, and low signal-to-noise ratio\n(SNR), making them more challenging to be identified compared to compact binary\ncoalescences. While matched filtering-based techniques are known for their\ncomputational demands, existing deep learning-based methods primarily handle\ntime-domain data and are often constrained by data duration and SNR. In\naddition, most existing work ignores time-delay interferometry (TDI) and\napplies the long-wavelength approximation in detector response calculations,\nthus limiting their ability to handle laser frequency noise. In this study, we\nintroduce DECODE, an end-to-end model focusing on EMRI signal detection by\nsequence modeling in the frequency domain. Centered around a dilated causal\nconvolutional neural network, trained on synthetic data considering TDI-1.5\ndetector response, DECODE can efficiently process a year's worth of\nmultichannel TDI data with an SNR of around 50. We evaluate our model on 1-year\ndata with accumulated SNR ranging from 50 to 120 and achieve a true positive\nrate of 96.3% at a false positive rate of 1%, keeping an inference time of less\nthan 0.01 seconds. With the visualization of three showcased EMRI signals for\ninterpretability and generalization, DECODE exhibits strong potential for\nfuture space-based gravitational wave data analyses.\n",
                "链接": "https://arxiv.org/abs/2308.16422"
            },
            {
                "文章ID": "38738",
                "标题": "Toward Smart Doors: A Position Paper",
                "作者": " Luigi Capogrosso,  Geri Skenderi,  Federico Girella,  Franco Fummi,  Marco Cristani",
                "发布日期": "2022-09-27",
                "摘要": "  Conventional automatic doors cannot distinguish between people wishing to\npass through the door and people passing by the door, so they often open\nunnecessarily. This leads to the need to adopt new systems in both commercial\nand non-commercial environments: smart doors. In particular, a smart door\nsystem predicts the intention of people near the door based on the social\ncontext of the surrounding environment and then makes rational decisions about\nwhether or not to open the door. This work proposes the first position paper\nrelated to smart doors, without bells and whistles. We first point out that the\nproblem not only concerns reliability, climate control, safety, and mode of\noperation. Indeed, a system to predict the intention of people near the door\nalso involves a deeper understanding of the social context of the scene through\na complex combined analysis of proxemics and scene reasoning. Furthermore, we\nconduct an exhaustive literature review about automatic doors, providing a\nnovel system formulation. Also, we present an analysis of the possible future\napplication of smart doors, a description of the ethical shortcomings, and\nlegislative issues.\n",
                "链接": "https://arxiv.org/abs/2209.11770"
            },
            {
                "文章ID": "53017",
                "标题": "HoloBeam: Paper-Thin Near-Eye Displays",
                "作者": " Kaan Akşit,  Yuta Itoh",
                "发布日期": "2023-01-27",
                "摘要": "  An emerging alternative to conventional Augmented Reality (AR) glasses\ndesigns, Beaming displays promise slim AR glasses free from challenging design\ntrade-offs, including battery-related limits or computational budget-related\nissues. These beaming displays remove active components such as batteries and\nelectronics from AR glasses and move them to a projector that projects images\nto a user from a distance (1-2 meters), where users wear only passive optical\neyepieces. However, earlier implementations of these displays delivered poor\nresolutions (7 cycles per degree) without any optical focus cues and were\nintroduced with a bulky form-factor eyepiece (50 mm thick). This paper\nintroduces a new milestone for beaming displays, which we call HoloBeam. In\nthis new design, a custom holographic projector populates a micro-volume\nlocated at some distance (1-2 meters) with multiple planes of images. Users\nview magnified copies of these images from this small volume with the help of\nan eyepiece that is either a Holographic Optical Element (HOE) or a set of\nlenses. Our HoloBeam prototypes demonstrate the thinnest AR glasses to date\nwith a submillimeter thickness (e.g., HOE film is only 120 um thick). In\naddition, HoloBeam prototypes demonstrate near retinal resolutions (24 cycles\nper degree) with a 70 degrees-wide field of view.\n",
                "链接": "https://arxiv.org/abs/2212.05057"
            },
            {
                "文章ID": "106859",
                "标题": "Human Mobility Question Answering (Vision Paper)",
                "作者": " Hao Xue,  Flora D. Salim",
                "发布日期": "2023-10-16",
                "摘要": "  Question answering (QA) systems have attracted much attention from the\nartificial intelligence community as they can learn to answer questions based\non the given knowledge source (e.g., images in visual question answering).\nHowever, the research into question answering systems with human mobility data\nremains unexplored. Mining human mobility data is crucial for various\napplications such as smart city planning, pandemic management, and personalised\nrecommendation system. In this paper, we aim to tackle this gap and introduce a\nnovel task, that is, human mobility question answering (MobQA). The aim of the\ntask is to let the intelligent system learn from mobility data and answer\nrelated questions. This task presents a new paradigm change in mobility\nprediction research and further facilitates the research of human mobility\nrecommendation systems. To better support this novel research topic, this\nvision paper also proposes an initial design of the dataset and a potential\ndeep learning model framework for the introduced MobQA task. We hope that this\npaper will provide novel insights and open new directions in human mobility\nresearch and question answering research.\n",
                "链接": "https://arxiv.org/abs/2310.04443"
            },
            {
                "文章ID": "110591",
                "标题": "\"Why Should I Review This Paper?\" Unifying Semantic, Topic, and Citation\n  Factors for Paper-Reviewer Matching",
                "作者": " Yu Zhang,  Yanzhen Shen,  Xiusi Chen,  Bowen Jin,  Jiawei Han",
                "发布日期": "2023-10-24",
                "摘要": "  As many academic conferences are overwhelmed by a rapidly increasing number\nof paper submissions, automatically finding appropriate reviewers for each\nsubmission becomes a more urgent need than ever. Various factors have been\nconsidered by previous attempts on this task to measure the expertise relevance\nbetween a paper and a reviewer, including whether the paper is semantically\nclose to, shares topics with, and cites previous papers of the reviewer.\nHowever, the majority of previous studies take only one of these factors into\naccount, leading to an incomprehensive evaluation of paper-reviewer relevance.\nTo bridge this gap, in this paper, we propose a unified model for\npaper-reviewer matching that jointly captures semantic, topic, and citation\nfactors. In the unified model, a contextualized language model backbone is\nshared by all factors to learn common knowledge, while instruction tuning is\nintroduced to characterize the uniqueness of each factor by producing\nfactor-aware paper embeddings. Experiments on four datasets (one of which is\nnewly contributed by us) across different fields, including machine learning,\ncomputer vision, information retrieval, and data mining, consistently validate\nthe effectiveness of our proposed UniPR model in comparison with\nstate-of-the-art paper-reviewer matching methods and scientific pre-trained\nlanguage models.\n",
                "链接": "https://arxiv.org/abs/2310.14483"
            },
            {
                "文章ID": "23588",
                "标题": "Transfer learning to decode brain states reflecting the relationship\n  between cognitive tasks",
                "作者": " Youzhi Qu,  Xinyao Jian,  Wenxin Che,  Penghui Du,  Kai Fu,  Quanying Liu",
                "发布日期": "2022-08-31",
                "摘要": "  Transfer learning improves the performance of the target task by leveraging\nthe data of a specific source task: the closer the relationship between the\nsource and the target tasks, the greater the performance improvement by\ntransfer learning. In neuroscience, the relationship between cognitive tasks is\nusually represented by similarity of activated brain regions or neural\nrepresentation. However, no study has linked transfer learning and neuroscience\nto reveal the relationship between cognitive tasks. In this study, we propose a\ntransfer learning framework to reflect the relationship between cognitive\ntasks, and compare the task relations reflected by transfer learning and by the\noverlaps of brain regions (e.g., neurosynth). Our results of transfer learning\ncreate cognitive taskonomy to reflect the relationship between cognitive tasks\nwhich is well in line with the task relations derived from neurosynth. Transfer\nlearning performs better in task decoding with fMRI data if the source and\ntarget cognitive tasks activate similar brain regions. Our study uncovers the\nrelationship of multiple cognitive tasks and provides guidance for source task\nselection in transfer learning for neural decoding based on small-sample data.\n",
                "链接": "https://arxiv.org/abs/2206.03950"
            },
            {
                "文章ID": "79427",
                "标题": "Sequential Transfer Learning to Decode Heard and Imagined Timbre from\n  fMRI Data",
                "作者": " Sean Paulsen,  Michael Casey",
                "发布日期": "2023-05-23",
                "摘要": "  We present a sequential transfer learning framework for transformers on\nfunctional Magnetic Resonance Imaging (fMRI) data and demonstrate its\nsignificant benefits for decoding musical timbre. In the first of two phases,\nwe pre-train our stacked-encoder transformer architecture on Next Thought\nPrediction, a self-supervised task of predicting whether or not one sequence of\nfMRI data follows another. This phase imparts a general understanding of the\ntemporal and spatial dynamics of neural activity, and can be applied to any\nfMRI dataset. In the second phase, we fine-tune the pre-trained models and\ntrain additional fresh models on the supervised task of predicting whether or\nnot two sequences of fMRI data were recorded while listening to the same\nmusical timbre. The fine-tuned models achieve significantly higher accuracy\nwith shorter training times than the fresh models, demonstrating the efficacy\nof our framework for facilitating transfer learning on fMRI data. Additionally,\nour fine-tuning task achieves a level of classification granularity beyond\nstandard methods. This work contributes to the growing literature on\ntransformer architectures for sequential transfer learning on fMRI data, and\nprovides evidence that our framework is an improvement over current methods for\ndecoding timbre.\n",
                "链接": "https://arxiv.org/abs/2305.13226"
            },
            {
                "文章ID": "81316",
                "标题": "Contrast, Attend and Diffuse to Decode High-Resolution Images from Brain\n  Activities",
                "作者": " Jingyuan Sun,  Mingxiao Li,  Zijiao Chen,  Yunhao Zhang,  Shaonan Wang,  Marie-Francine Moens",
                "发布日期": "2023-12-29",
                "摘要": "  Decoding visual stimuli from neural responses recorded by functional Magnetic\nResonance Imaging (fMRI) presents an intriguing intersection between cognitive\nneuroscience and machine learning, promising advancements in understanding\nhuman visual perception and building non-invasive brain-machine interfaces.\nHowever, the task is challenging due to the noisy nature of fMRI signals and\nthe intricate pattern of brain visual representations. To mitigate these\nchallenges, we introduce a two-phase fMRI representation learning framework.\nThe first phase pre-trains an fMRI feature learner with a proposed\nDouble-contrastive Mask Auto-encoder to learn denoised representations. The\nsecond phase tunes the feature learner to attend to neural activation patterns\nmost informative for visual reconstruction with guidance from an image\nauto-encoder. The optimized fMRI feature learner then conditions a latent\ndiffusion model to reconstruct image stimuli from brain activities.\nExperimental results demonstrate our model's superiority in generating\nhigh-resolution and semantically accurate images, substantially exceeding\nprevious state-of-the-art methods by 39.34% in the 50-way-top-1 semantic\nclassification accuracy. Our research invites further exploration of the\ndecoding task's potential and contributes to the development of non-invasive\nbrain-machine interfaces.\n",
                "链接": "https://arxiv.org/abs/2305.17214"
            }
        ]
    },
    {
        "question": {
            "question": "请找到缓和噪声标签影响的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "71082",
                "标题": "Evaluating the Robustness of Machine Reading Comprehension Models to Low\n  Resource Entity Renaming",
                "作者": " Clemencia Siro,  Tunde Oluwaseyi Ajayi",
                "发布日期": "2023-04-07",
                "摘要": "  Question answering (QA) models have shown compelling results in the task of\nMachine Reading Comprehension (MRC). Recently these systems have proved to\nperform better than humans on held-out test sets of datasets e.g. SQuAD, but\ntheir robustness is not guaranteed. The QA model's brittleness is exposed when\nevaluated on adversarial generated examples by a performance drop. In this\nstudy, we explore the robustness of MRC models to entity renaming, with\nentities from low-resource regions such as Africa. We propose EntSwap, a method\nfor test-time perturbations, to create a test set whose entities have been\nrenamed. In particular, we rename entities of type: country, person,\nnationality, location, organization, and city, to create AfriSQuAD2. Using the\nperturbed test set, we evaluate the robustness of three popular MRC models. We\nfind that compared to base models, large models perform well comparatively on\nnovel entities. Furthermore, our analysis indicates that entity type person\nhighly challenges the MRC models' performance.\n",
                "链接": "https://arxiv.org/abs/2304.03145"
            },
            {
                "文章ID": "59335",
                "标题": "The Impacts of Unanswerable Questions on the Robustness of Machine\n  Reading Comprehension Models",
                "作者": " Son Quoc Tran,  Phong Nguyen-Thuan Do,  Uyen Le,  Matt Kretchmar",
                "发布日期": "2023-02-02",
                "摘要": "  Pretrained language models have achieved super-human performances on many\nMachine Reading Comprehension (MRC) benchmarks. Nevertheless, their relative\ninability to defend against adversarial attacks has spurred skepticism about\ntheir natural language understanding. In this paper, we ask whether training\nwith unanswerable questions in SQuAD 2.0 can help improve the robustness of MRC\nmodels against adversarial attacks. To explore that question, we fine-tune\nthree state-of-the-art language models on either SQuAD 1.1 or SQuAD 2.0 and\nthen evaluate their robustness under adversarial attacks. Our experiments\nreveal that current models fine-tuned on SQuAD 2.0 do not initially appear to\nbe any more robust than ones fine-tuned on SQuAD 1.1, yet they reveal a measure\nof hidden robustness that can be leveraged to realize actual performance gains.\nFurthermore, we find that the robustness of models fine-tuned on SQuAD 2.0\nextends to additional out-of-domain datasets. Finally, we introduce a new\nadversarial attack to reveal artifacts of SQuAD 2.0 that current MRC models are\nlearning.\n",
                "链接": "https://arxiv.org/abs/2302.00094"
            },
            {
                "文章ID": "6867",
                "标题": "Using calibrator to improve robustness in Machine Reading Comprehension",
                "作者": " Jing Jin,  Houfeng Wang",
                "发布日期": "2022-02-25",
                "摘要": "  Machine Reading Comprehension(MRC) has achieved a remarkable result since\nsome powerful models, such as BERT, are proposed. However, these models are not\nrobust enough and vulnerable to adversarial input perturbation and\ngeneralization examples. Some works tried to improve the performance on\nspecific types of data by adding some related examples into training data while\nit leads to degradation on the original dataset, because the shift of data\ndistribution makes the answer ranking based on the softmax probability of model\nunreliable. In this paper, we propose a method to improve the robustness by\nusing a calibrator as the post-hoc reranker, which is implemented based on\nXGBoost model. The calibrator combines both manual features and representation\nlearning features to rerank candidate results. Experimental results on\nadversarial datasets show that our model can achieve performance improvement by\nmore than 10\\% and also make improvement on the original and generalization\ndatasets.\n",
                "链接": "https://arxiv.org/abs/2202.11865"
            },
            {
                "文章ID": "48397",
                "标题": "Quantifying the Impact of Label Noise on Federated Learning",
                "作者": " Shuqi Ke,  Chao Huang,  Xin Liu",
                "发布日期": "2023-04-04",
                "摘要": "  Federated Learning (FL) is a distributed machine learning paradigm where\nclients collaboratively train a model using their local (human-generated)\ndatasets. While existing studies focus on FL algorithm development to tackle\ndata heterogeneity across clients, the important issue of data quality (e.g.,\nlabel noise) in FL is overlooked. This paper aims to fill this gap by providing\na quantitative study on the impact of label noise on FL. We derive an upper\nbound for the generalization error that is linear in the clients' label noise\nlevel. Then we conduct experiments on MNIST and CIFAR-10 datasets using various\nFL algorithms. Our empirical results show that the global model accuracy\nlinearly decreases as the noise level increases, which is consistent with our\ntheoretical analysis. We further find that label noise slows down the\nconvergence of FL training, and the global model tends to overfit when the\nnoise level is high.\n",
                "链接": "https://arxiv.org/abs/2211.07816"
            },
            {
                "文章ID": "3588",
                "标题": "An Assessment of the Impact of OCR Noise on Language Models",
                "作者": " Konstantin Todorov,  Giovanni Colavizza",
                "发布日期": "2022-02-02",
                "摘要": "  Neural language models are the backbone of modern-day natural language\nprocessing applications. Their use on textual heritage collections which have\nundergone Optical Character Recognition (OCR) is therefore also increasing.\nNevertheless, our understanding of the impact OCR noise could have on language\nmodels is still limited. We perform an assessment of the impact OCR noise has\non a variety of language models, using data in Dutch, English, French and\nGerman. We find that OCR noise poses a significant obstacle to language\nmodelling, with language models increasingly diverging from their noiseless\ntargets as OCR quality lowers. In the presence of small corpora, simpler models\nincluding PPMI and Word2Vec consistently outperform transformer-based models in\nthis respect.\n",
                "链接": "https://arxiv.org/abs/2202.00470"
            },
            {
                "文章ID": "92036",
                "标题": "Integrating a Heterogeneous Graph with Entity-aware Self-attention using\n  Relative Position Labels for Reading Comprehension Model",
                "作者": " Shima Foolad,  Kourosh Kiani",
                "发布日期": "2023-07-25",
                "摘要": "  Despite the significant progress made by transformer models in machine\nreading comprehension tasks, they still fall short in handling complex\nreasoning tasks due to the absence of explicit knowledge in the input sequence.\nTo address this limitation, many recent works have proposed injecting external\nknowledge into the model. However, selecting relevant external knowledge,\nensuring its availability, and requiring additional processing steps remain\nchallenging. In this paper, we introduce a novel attention pattern that\nintegrates reasoning knowledge derived from a heterogeneous graph into the\ntransformer architecture without relying on external knowledge. The proposed\nattention pattern comprises three key elements: global-local attention for word\ntokens, graph attention for entity tokens that exhibit strong attention towards\ntokens connected in the graph as opposed to those unconnected, and the\nconsideration of the type of relationship between each entity token and word\ntoken. This results in optimized attention between the two if a relationship\nexists. The pattern is coupled with special relative position labels, allowing\nit to integrate with LUKE's entity-aware self-attention mechanism. The\nexperimental findings corroborate that our model outperforms both the\ncutting-edge LUKE-Graph and the baseline LUKE model on the ReCoRD dataset that\nfocuses on commonsense reasoning.\n",
                "链接": "https://arxiv.org/abs/2307.10443"
            },
            {
                "文章ID": "88300",
                "标题": "Systematic analysis of the impact of label noise correction on ML\n  Fairness",
                "作者": " I. Oliveira e Silva,  C. Soares,  I. Sousa,  R. Ghani",
                "发布日期": "2023-06-29",
                "摘要": "  Arbitrary, inconsistent, or faulty decision-making raises serious concerns,\nand preventing unfair models is an increasingly important challenge in Machine\nLearning. Data often reflect past discriminatory behavior, and models trained\non such data may reflect bias on sensitive attributes, such as gender, race, or\nage. One approach to developing fair models is to preprocess the training data\nto remove the underlying biases while preserving the relevant information, for\nexample, by correcting biased labels. While multiple label noise correction\nmethods are available, the information about their behavior in identifying\ndiscrimination is very limited. In this work, we develop an empirical\nmethodology to systematically evaluate the effectiveness of label noise\ncorrection techniques in ensuring the fairness of models trained on biased\ndatasets. Our methodology involves manipulating the amount of label noise and\ncan be used with fairness benchmarks but also with standard ML datasets. We\napply the methodology to analyze six label noise correction methods according\nto several fairness metrics on standard OpenML datasets. Our results suggest\nthat the Hybrid Label Noise Correction method achieves the best trade-off\nbetween predictive performance and fairness. Clustering-Based Correction can\nreduce discrimination the most, however, at the cost of lower predictive\nperformance.\n",
                "链接": "https://arxiv.org/abs/2306.15994"
            },
            {
                "文章ID": "119182",
                "标题": "Evaluating the Rationale Understanding of Critical Reasoning in Logical\n  Reading Comprehension",
                "作者": " Akira Kawabata,  Saku Sugawara",
                "发布日期": "2023-12-01",
                "摘要": "  To precisely evaluate a language model's capability for logical reading\ncomprehension, we present a dataset for testing the understanding of the\nrationale behind critical reasoning. For questions taken from an existing\nmultiplechoice logical reading comprehension dataset, we crowdsource rationale\ntexts that explain why we should select or eliminate answer options, resulting\nin 3,003 multiple-choice subquestions that are associated with 943 main\nquestions. Experiments on our dataset show that recent large language models\n(e.g., InstructGPT) struggle to answer the subquestions even if they are able\nto answer the main questions correctly. We find that the models perform\nparticularly poorly in answering subquestions written for the incorrect options\nof the main questions, implying that the models have a limited capability for\nexplaining why incorrect alternatives should be eliminated. These results\nsuggest that our dataset encourages further investigation into the critical\nreasoning ability of language models while focusing on the elimination process\nof relevant alternatives.\n",
                "链接": "https://arxiv.org/abs/2311.18353"
            },
            {
                "文章ID": "19437",
                "标题": "Impact of Learning Rate on Noise Resistant Property of Deep Learning\n  Models",
                "作者": " Omobayode Fagbohungbe,  Lijun Qian",
                "发布日期": "2022-05-18",
                "摘要": "  The interest in analog computation has grown tremendously in recent years due\nto its fast computation speed and excellent energy efficiency, which is very\nimportant for edge and IoT devices in the sub-watt power envelope for deep\nlearning inferencing. However, significant performance degradation suffered by\ndeep learning models due to the inherent noise present in the analog\ncomputation can limit their use in mission-critical applications. Hence, there\nis a need to understand the impact of critical model hyperparameters choice on\nthe resulting model noise-resistant property. This need is critical as the\ninsight obtained can be used to design deep learning models that are robust to\nanalog noise. In this paper, the impact of the learning rate, a critical design\nchoice, on the noise-resistant property is investigated. The study is achieved\nby first training deep learning models using different learning rates.\nThereafter, the models are injected with analog noise and the noise-resistant\nproperty of the resulting models is examined by measuring the performance\ndegradation due to the analog noise. The results showed there exists a sweet\nspot of learning rate values that achieves a good balance between model\nprediction performance and model noise-resistant property. Furthermore, the\ntheoretical justification of the observed phenomenon is provided.\n",
                "链接": "https://arxiv.org/abs/2205.07856"
            },
            {
                "文章ID": "80221",
                "标题": "Machine Reading Comprehension using Case-based Reasoning",
                "作者": " Dung Thai,  Dhruv Agarwal,  Mudit Chaudhary,  Wenlong Zhao,  Rajarshi Das,  Manzil Zaheer,  Jay-Yoon Lee,  Hannaneh Hajishirzi,  Andrew McCallum",
                "发布日期": "2023-12-07",
                "摘要": "  We present an accurate and interpretable method for answer extraction in\nmachine reading comprehension that is reminiscent of case-based reasoning (CBR)\nfrom classical AI. Our method (CBR-MRC) builds upon the hypothesis that\ncontextualized answers to similar questions share semantic similarities with\neach other. Given a test question, CBR-MRC first retrieves a set of similar\ncases from a nonparametric memory and then predicts an answer by selecting the\nspan in the test context that is most similar to the contextualized\nrepresentations of answers in the retrieved cases. The semi-parametric nature\nof our approach allows it to attribute a prediction to the specific set of\nevidence cases, making it a desirable choice for building reliable and\ndebuggable QA systems. We show that CBR-MRC provides high accuracy comparable\nwith large reader models and outperforms baselines by 11.5 and 8.4 EM on\nNaturalQuestions and NewsQA, respectively. Further, we demonstrate the ability\nof CBR-MRC in identifying not just the correct answer tokens but also the span\nwith the most relevant supporting evidence. Lastly, we observe that contexts\nfor certain question types show higher lexical diversity than others and find\nthat CBR-MRC is robust to these variations while performance using\nfully-parametric methods drops.\n",
                "链接": "https://arxiv.org/abs/2305.14815"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下文本检索任务上，是否有关于大模型在语义坍缩问题上的研究",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "110649",
                "标题": "Large Search Model: Redefining Search Stack in the Era of LLMs",
                "作者": " Liang Wang,  Nan Yang,  Xiaolong Huang,  Linjun Yang,  Rangan Majumder,  Furu Wei",
                "发布日期": "2023-10-24",
                "摘要": "  Modern search engines are built on a stack of different components, including\nquery understanding, retrieval, multi-stage ranking, and question answering,\namong others. These components are often optimized and deployed independently.\nIn this paper, we introduce a novel conceptual framework called large search\nmodel, which redefines the conventional search stack by unifying search tasks\nwith one large language model (LLM). All tasks are formulated as autoregressive\ntext generation problems, allowing for the customization of tasks through the\nuse of natural language prompts. This proposed framework capitalizes on the\nstrong language understanding and reasoning capabilities of LLMs, offering the\npotential to enhance search result quality while simultaneously simplifying the\nexisting cumbersome search stack. To substantiate the feasibility of this\nframework, we present a series of proof-of-concept experiments and discuss the\npotential challenges associated with implementing this approach within\nreal-world search systems.\n",
                "链接": "https://arxiv.org/abs/2310.14587"
            },
            {
                "文章ID": "34574",
                "标题": "Query-Response Interactions by Multi-tasks in Semantic Search for\n  Chatbot Candidate Retrieval",
                "作者": " Libin Shi,  Kai Zhang,  Wenge Rong",
                "发布日期": "2022-08-24",
                "摘要": "  Semantic search for candidate retrieval is an important yet neglected problem\nin retrieval-based Chatbots, which aims to select a bunch of candidate\nresponses efficiently from a large pool. The existing bottleneck is to ensure\nthe model architecture having two points: 1) rich interactions between a query\nand a response to produce query-relevant responses; 2) ability of separately\nprojecting the query and the response into latent spaces to apply efficiently\nin semantic search during online inference. To tackle this problem, we propose\na novel approach, called Multitask-based Semantic Search Neural Network (MSSNN)\nfor candidate retrieval, which accomplishes query-response interactions through\nmulti-tasks. The method employs a Seq2Seq modeling task to learn a good query\nencoder, and then performs a word prediction task to build response embeddings,\nfinally conducts a simple matching model to form the dot-product scorer.\nExperimental studies have demonstrated the potential of the proposed approach.\n",
                "链接": "https://arxiv.org/abs/2208.11018"
            },
            {
                "文章ID": "100283",
                "标题": "On the Planning, Search, and Memorization Capabilities of Large Language\n  Models",
                "作者": " Yunhao Yang,  Anshul Tomar",
                "发布日期": "2023-09-06",
                "摘要": "  The rapid advancement of large language models, such as the Generative\nPre-trained Transformer (GPT) series, has had significant implications across\nvarious disciplines. In this study, we investigate the potential of the\nstate-of-the-art large language model (GPT-4) for planning tasks. We explore\nits effectiveness in multiple planning subfields, highlighting both its\nstrengths and limitations. Through a comprehensive examination, we identify\nareas where large language models excel in solving planning problems and reveal\nthe constraints that limit their applicability. Our empirical analysis focuses\non GPT-4's performance in planning domain extraction, graph search path\nplanning, and adversarial planning. We then propose a way of fine-tuning a\ndomain-specific large language model to improve its Chain of Thought (CoT)\ncapabilities for the above-mentioned tasks. The results provide valuable\ninsights into the potential applications of large language models in the\nplanning domain and pave the way for future research to overcome their\nlimitations and expand their capabilities.\n",
                "链接": "https://arxiv.org/abs/2309.01868"
            },
            {
                "文章ID": "98663",
                "标题": "On the Depth between Beam Search and Exhaustive Search for Text\n  Generation",
                "作者": " Yuu Jinnai,  Tetsuro Morimura,  Ukyo Honda",
                "发布日期": "2023-08-29",
                "摘要": "  Beam search and exhaustive search are two extreme ends of text decoding\nalgorithms with respect to the search depth. Beam search is limited in both\nsearch width and depth, whereas exhaustive search is a global search that has\nno such limitations. Surprisingly, beam search is not only computationally\ncheaper but also performs better than exhaustive search despite its higher\nsearch error. Plenty of research has investigated a range of beam widths, from\nsmall to large, and reported that a beam width that is neither too large nor\ntoo small is desirable. However, in terms of search depth, only the two extreme\nends, beam search and exhaustive search are studied intensively. In this paper,\nwe examine a range of search depths between the two extremes to discover the\ndesirable search depth. To this end, we introduce Lookahead Beam Search (LBS),\na multi-step lookahead search that optimizes the objective considering a fixed\nnumber of future steps. Beam search and exhaustive search are special cases of\nLBS where the lookahead depth is set to $0$ and $\\infty$, respectively. We\nempirically evaluate the performance of LBS and find that it outperforms beam\nsearch overall on machine translation tasks. The result suggests there is room\nfor improvement in beam search by searching deeper. Inspired by the analysis,\nwe propose Lookbehind Heuristic Beam Search, a computationally feasible search\nalgorithm that heuristically simulates LBS with 1-step lookahead. The empirical\nresults show that the proposed method outperforms vanilla beam search on\nmachine translation and text summarization tasks.\n",
                "链接": "https://arxiv.org/abs/2308.13696"
            },
            {
                "文章ID": "102871",
                "标题": "Using fine-tuning and min lookahead beam search to improve Whisper",
                "作者": " Andrea Do,  Oscar Brown,  Zhengjie Wang,  Nikhil Mathew,  Zixin Liu,  Jawwad Ahmed,  Cheng Yu",
                "发布日期": "2023-09-20",
                "摘要": "  The performance of Whisper in low-resource languages is still far from\nperfect. In addition to a lack of training data on low-resource languages, we\nidentify some limitations in the beam search algorithm used in Whisper. To\naddress these issues, we fine-tune Whisper on additional data and propose an\nimproved decoding algorithm. On the Vietnamese language, fine-tuning\nWhisper-Tiny with LoRA leads to an improvement of 38.49 in WER over the\nzero-shot Whisper-Tiny setting which is a further reduction of 1.45 compared to\nfull-parameter fine-tuning. Additionally, by using Filter-Ends and Min\nLookahead decoding algorithms, the WER reduces by 2.26 on average over a range\nof languages compared to standard beam search. These results generalise to\nlarger Whisper model sizes. We also prove a theorem that Min Lookahead\noutperforms the standard beam search algorithm used in Whisper.\n",
                "链接": "https://arxiv.org/abs/2309.10299"
            },
            {
                "文章ID": "88162",
                "标题": "Dental CLAIRES: Contrastive LAnguage Image REtrieval Search for Dental\n  Research",
                "作者": " Tanjida Kabir,  Luyao Chen,  Muhammad F Walji,  Luca Giancardo,  Xiaoqian Jiang,  Shayan Shams",
                "发布日期": "2023-06-28",
                "摘要": "  Learning about diagnostic features and related clinical information from\ndental radiographs is important for dental research. However, the lack of\nexpert-annotated data and convenient search tools poses challenges. Our primary\nobjective is to design a search tool that uses a user's query for oral-related\nresearch. The proposed framework, Contrastive LAnguage Image REtrieval Search\nfor dental research, Dental CLAIRES, utilizes periapical radiographs and\nassociated clinical details such as periodontal diagnosis, demographic\ninformation to retrieve the best-matched images based on the text query. We\napplied a contrastive representation learning method to find images described\nby the user's text by maximizing the similarity score of positive pairs (true\npairs) and minimizing the score of negative pairs (random pairs). Our model\nachieved a hit@3 ratio of 96% and a Mean Reciprocal Rank (MRR) of 0.82. We also\ndesigned a graphical user interface that allows researchers to verify the\nmodel's performance with interactions.\n",
                "链接": "https://arxiv.org/abs/2306.15651"
            },
            {
                "文章ID": "114659",
                "标题": "Quranic Conversations: Developing a Semantic Search tool for the Quran\n  using Arabic NLP Techniques",
                "作者": " Yasser Shohoud,  Maged Shoman,  Sarah Abdelazim",
                "发布日期": "2023-11-10",
                "摘要": "  The Holy Book of Quran is believed to be the literal word of God (Allah) as\nrevealed to the Prophet Muhammad (PBUH) over a period of approximately 23\nyears. It is the book where God provides guidance on how to live a righteous\nand just life, emphasizing principles like honesty, compassion, charity and\njustice, as well as providing rules for personal conduct, family matters,\nbusiness ethics and much more. However, due to constraints related to the\nlanguage and the Quran organization, it is challenging for Muslims to get all\nrelevant ayahs (verses) pertaining to a matter or inquiry of interest. Hence,\nwe developed a Quran semantic search tool which finds the verses pertaining to\nthe user inquiry or prompt. To achieve this, we trained several models on a\nlarge dataset of over 30 tafsirs, where typically each tafsir corresponds to\none verse in the Quran and, using cosine similarity, obtained the tafsir tensor\nwhich is most similar to the prompt tensor of interest, which was then used to\nindex for the corresponding ayah in the Quran. Using the SNxLM model, we were\nable to achieve a cosine similarity score as high as 0.97 which corresponds to\nthe abdu tafsir for a verse relating to financial matters.\n",
                "链接": "https://arxiv.org/abs/2311.05120"
            },
            {
                "文章ID": "90102",
                "标题": "Shaping the Emerging Norms of Using Large Language Models in Social\n  Computing Research",
                "作者": " Hong Shen,  Tianshi Li,  Toby Jia-Jun Li,  Joon Sung Park,  Diyi Yang",
                "发布日期": "2023-07-11",
                "摘要": "  The emergence of Large Language Models (LLMs) has brought both excitement and\nconcerns to social computing research. On the one hand, LLMs offer\nunprecedented capabilities in analyzing vast amounts of textual data and\ngenerating human-like responses, enabling researchers to delve into complex\nsocial phenomena. On the other hand, concerns are emerging regarding the\nvalidity, privacy, and ethics of the research when LLMs are involved. This SIG\naims at offering an open space for social computing researchers who are\ninterested in understanding the impacts of LLMs to discuss their current\npractices, perspectives, challenges when engaging with LLMs in their everyday\nwork and collectively shaping the emerging norms of using LLMs in social\ncomputing research.\n",
                "链接": "https://arxiv.org/abs/2307.04280"
            },
            {
                "文章ID": "79167",
                "标题": "ConQueR: Contextualized Query Reduction using Search Logs",
                "作者": " Hye-young Kim,  Minjin Choi,  Sunkyung Lee,  Eunseong Choi,  Young-In Song,  Jongwuk Lee",
                "发布日期": "2023-05-23",
                "摘要": "  Query reformulation is a key mechanism to alleviate the linguistic chasm of\nquery in ad-hoc retrieval. Among various solutions, query reduction effectively\nremoves extraneous terms and specifies concise user intent from long queries.\nHowever, it is challenging to capture hidden and diverse user intent. This\npaper proposes Contextualized Query Reduction (ConQueR) using a pre-trained\nlanguage model (PLM). Specifically, it reduces verbose queries with two\ndifferent views: core term extraction and sub-query selection. One extracts\ncore terms from an original query at the term level, and the other determines\nwhether a sub-query is a suitable reduction for the original query at the\nsequence level. Since they operate at different levels of granularity and\ncomplement each other, they are finally aggregated in an ensemble manner. We\nevaluate the reduction quality of ConQueR on real-world search logs collected\nfrom a commercial web search engine. It achieves up to 8.45% gains in exact\nmatch scores over the best competing model.\n",
                "链接": "https://arxiv.org/abs/2305.12662"
            },
            {
                "文章ID": "4592",
                "标题": "On the Pitfalls of Using the Residual Error as Anomaly Score",
                "作者": " Felix Meissen,  Benedikt Wiestler,  Georgios Kaissis,  Daniel Rueckert",
                "发布日期": "2023-09-26",
                "摘要": "  Many current state-of-the-art methods for anomaly localization in medical\nimages rely on calculating a residual image between a potentially anomalous\ninput image and its \"healthy\" reconstruction. As the reconstruction of the\nunseen anomalous region should be erroneous, this yields large residuals as a\nscore to detect anomalies in medical images. However, this assumption does not\ntake into account residuals resulting from imperfect reconstructions of the\nmachine learning models used. Such errors can easily overshadow residuals of\ninterest and therefore strongly question the use of residual images as scoring\nfunction. Our work explores this fundamental problem of residual images in\ndetail. We theoretically define the problem and thoroughly evaluate the\ninfluence of intensity and texture of anomalies against the effect of imperfect\nreconstructions in a series of experiments. Code and experiments are available\nunder https://github.com/FeliMe/residual-score-pitfalls\n",
                "链接": "https://arxiv.org/abs/2202.03826"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找对机器翻译数据集质量进行评估的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "83169",
                "标题": "Evaluating Machine Translation Quality with Conformal Predictive\n  Distributions",
                "作者": " Patrizio Giovannotti",
                "发布日期": "2023-06-05",
                "摘要": "  This paper presents a new approach for assessing uncertainty in machine\ntranslation by simultaneously evaluating translation quality and providing a\nreliable confidence score. Our approach utilizes conformal predictive\ndistributions to produce prediction intervals with guaranteed coverage, meaning\nthat for any given significance level $\\epsilon$, we can expect the true\nquality score of a translation to fall out of the interval at a rate of\n$1-\\epsilon$. In this paper, we demonstrate how our method outperforms a\nsimple, but effective baseline on six different language pairs in terms of\ncoverage and sharpness. Furthermore, we validate that our approach requires the\ndata exchangeability assumption to hold for optimal performance.\n",
                "链接": "https://arxiv.org/abs/2306.01549"
            },
            {
                "文章ID": "42270",
                "标题": "DATScore: Evaluating Translation with Data Augmented Translations",
                "作者": " Moussa Kamal Eddine,  Guokan Shang,  Michalis Vazirgiannis",
                "发布日期": "2022-10-14",
                "摘要": "  The rapid development of large pretrained language models has revolutionized\nnot only the field of Natural Language Generation (NLG) but also its\nevaluation. Inspired by the recent work of BARTScore: a metric leveraging the\nBART language model to evaluate the quality of generated text from various\naspects, we introduce DATScore. DATScore uses data augmentation techniques to\nimprove the evaluation of machine translation. Our main finding is that\nintroducing data augmented translations of the source and reference texts is\ngreatly helpful in evaluating the quality of the generated translation. We also\npropose two novel score averaging and term weighting strategies to improve the\noriginal score computing process of BARTScore. Experimental results on WMT show\nthat DATScore correlates better with human meta-evaluations than the other\nrecent state-of-the-art metrics, especially for low-resource languages.\nAblation studies demonstrate the value added by our new scoring strategies.\nMoreover, we report in our extended experiments the performance of DATScore on\n3 NLG tasks other than translation.\n",
                "链接": "https://arxiv.org/abs/2210.06576"
            },
            {
                "文章ID": "19633",
                "标题": "Consistent Human Evaluation of Machine Translation across Language Pairs",
                "作者": " Daniel Licht,  Cynthia Gao,  Janice Lam,  Francisco Guzman,  Mona Diab,  Philipp Koehn",
                "发布日期": "2022-05-18",
                "摘要": "  Obtaining meaningful quality scores for machine translation systems through\nhuman evaluation remains a challenge given the high variability between human\nevaluators, partly due to subjective expectations for translation quality for\ndifferent language pairs. We propose a new metric called XSTS that is more\nfocused on semantic equivalence and a cross-lingual calibration method that\nenables more consistent assessment. We demonstrate the effectiveness of these\nnovel contributions in large scale evaluation studies across up to 14 language\npairs, with translation both into and out of English.\n",
                "链接": "https://arxiv.org/abs/2205.08533"
            },
            {
                "文章ID": "84997",
                "标题": "Conformalizing Machine Translation Evaluation",
                "作者": " Chrysoula Zerva,  André F. T. Martins",
                "发布日期": "2023-06-13",
                "摘要": "  Several uncertainty estimation methods have been recently proposed for\nmachine translation evaluation. While these methods can provide a useful\nindication of when not to trust model predictions, we show in this paper that\nthe majority of them tend to underestimate model uncertainty, and as a result\nthey often produce misleading confidence intervals that do not cover the ground\ntruth. We propose as an alternative the use of conformal prediction, a\ndistribution-free method to obtain confidence intervals with a theoretically\nestablished guarantee on coverage. First, we demonstrate that split conformal\nprediction can ``correct'' the confidence intervals of previous methods to\nyield a desired coverage level. Then, we highlight biases in estimated\nconfidence intervals, both in terms of the translation language pairs and the\nquality of translations. We apply conditional conformal prediction techniques\nto obtain calibration subsets for each data subgroup, leading to equalized\ncoverage.\n",
                "链接": "https://arxiv.org/abs/2306.06221"
            },
            {
                "文章ID": "50351",
                "标题": "Competency-Aware Neural Machine Translation: Can Machine Translation\n  Know its Own Translation Quality?",
                "作者": " Pei Zhang,  Baosong Yang,  Haoran Wei,  Dayiheng Liu,  Kai Fan,  Luo Si,  Jun Xie",
                "发布日期": "2022-11-28",
                "摘要": "  Neural machine translation (NMT) is often criticized for failures that happen\nwithout awareness. The lack of competency awareness makes NMT untrustworthy.\nThis is in sharp contrast to human translators who give feedback or conduct\nfurther investigations whenever they are in doubt about predictions. To fill\nthis gap, we propose a novel competency-aware NMT by extending conventional NMT\nwith a self-estimator, offering abilities to translate a source sentence and\nestimate its competency. The self-estimator encodes the information of the\ndecoding procedure and then examines whether it can reconstruct the original\nsemantics of the source sentence. Experimental results on four translation\ntasks demonstrate that the proposed method not only carries out translation\ntasks intact but also delivers outstanding performance on quality estimation.\nWithout depending on any reference or annotated data typically required by\nstate-of-the-art metric and quality estimation methods, our model yields an\neven higher correlation with human quality judgments than a variety of\naforementioned methods, such as BLEURT, COMET, and BERTScore. Quantitative and\nqualitative analyses show better robustness of competency awareness in our\nmodel.\n",
                "链接": "https://arxiv.org/abs/2211.13865"
            },
            {
                "文章ID": "37434",
                "标题": "Rethinking Round-Trip Translation for Machine Translation Evaluation",
                "作者": " Terry Yue Zhuo,  Qiongkai Xu,  Xuanli He,  Trevor Cohn",
                "发布日期": "2023-05-16",
                "摘要": "  Automatic evaluation on low-resource language translation suffers from a\ndeficiency of parallel corpora. Round-trip translation could be served as a\nclever and straightforward technique to alleviate the requirement of the\nparallel evaluation corpus. However, there was an observation of obscure\ncorrelations between the evaluation scores by forward and round-trip\ntranslations in the era of statistical machine translation (SMT). In this\npaper, we report the surprising finding that round-trip translation can be used\nfor automatic evaluation without the references. Firstly, our revisit on the\nround-trip translation in SMT evaluation unveils that its long-standing\nmisunderstanding is essentially caused by copying mechanism. After removing\ncopying mechanism in SMT, round-trip translation scores can appropriately\nreflect the forward translation performance. Then, we demonstrate the\nrectification is overdue as round-trip translation could benefit multiple\nmachine translation evaluation tasks. To be more specific, round-trip\ntranslation could be used i) to predict corresponding forward translation\nscores; ii) to improve the performance of the recently advanced quality\nestimation model; and iii) to identify adversarial competitors in shared tasks\nvia cross-system verification.\n",
                "链接": "https://arxiv.org/abs/2209.07351"
            },
            {
                "文章ID": "12443",
                "标题": "Investigating Data Variance in Evaluations of Automatic Machine\n  Translation Metrics",
                "作者": " Jiannan Xiang,  Huayang Li,  Yahui Liu,  Lemao Liu,  Guoping Huang,  Defu Lian,  Shuming Shi",
                "发布日期": "2022-04-21",
                "摘要": "  Current practices in metric evaluation focus on one single dataset, e.g.,\nNewstest dataset in each year's WMT Metrics Shared Task. However, in this\npaper, we qualitatively and quantitatively show that the performances of\nmetrics are sensitive to data. The ranking of metrics varies when the\nevaluation is conducted on different datasets. Then this paper further\ninvestigates two potential hypotheses, i.e., insignificant data points and the\ndeviation of Independent and Identically Distributed (i.i.d) assumption, which\nmay take responsibility for the issue of data variance. In conclusion, our\nfindings suggest that when evaluating automatic translation metrics,\nresearchers should take data variance into account and be cautious to claim the\nresult on a single dataset, because it may leads to inconsistent results with\nmost of other datasets.\n",
                "链接": "https://arxiv.org/abs/2203.15858"
            },
            {
                "文章ID": "6641",
                "标题": "An Overview on Machine Translation Evaluation",
                "作者": " Lifeng Han",
                "发布日期": "2022-02-23",
                "摘要": "  Since the 1950s, machine translation (MT) has become one of the important\ntasks of AI and development, and has experienced several different periods and\nstages of development, including rule-based methods, statistical methods, and\nrecently proposed neural network-based learning methods. Accompanying these\nstaged leaps is the evaluation research and development of MT, especially the\nimportant role of evaluation methods in statistical translation and neural\ntranslation research. The evaluation task of MT is not only to evaluate the\nquality of machine translation, but also to give timely feedback to machine\ntranslation researchers on the problems existing in machine translation itself,\nhow to improve and how to optimise. In some practical application fields, such\nas in the absence of reference translations, the quality estimation of machine\ntranslation plays an important role as an indicator to reveal the credibility\nof automatically translated target languages. This report mainly includes the\nfollowing contents: a brief history of machine translation evaluation (MTE),\nthe classification of research methods on MTE, and the the cutting-edge\nprogress, including human evaluation, automatic evaluation, and evaluation of\nevaluation methods (meta-evaluation). Manual evaluation and automatic\nevaluation include reference-translation based and reference-translation\nindependent participation; automatic evaluation methods include traditional\nn-gram string matching, models applying syntax and semantics, and deep learning\nmodels; evaluation of evaluation methods includes estimating the credibility of\nhuman evaluations, the reliability of the automatic evaluation, the reliability\nof the test set, etc. Advances in cutting-edge evaluation methods include\ntask-based evaluation, using pre-trained language models based on big data, and\nlightweight optimisation models using distillation techniques.\n",
                "链接": "https://arxiv.org/abs/2202.11027"
            },
            {
                "文章ID": "14818",
                "标题": "Disentangling Uncertainty in Machine Translation Evaluation",
                "作者": " Chrysoula Zerva,  Taisiya Glushkova,  Ricardo Rei,  André F. T. Martins",
                "发布日期": "2022-12-01",
                "摘要": "  Trainable evaluation metrics for machine translation (MT) exhibit strong\ncorrelation with human judgements, but they are often hard to interpret and\nmight produce unreliable scores under noisy or out-of-domain data. Recent work\nhas attempted to mitigate this with simple uncertainty quantification\ntechniques (Monte Carlo dropout and deep ensembles), however these techniques\n(as we show) are limited in several ways -- for example, they are unable to\ndistinguish between different kinds of uncertainty, and they are time and\nmemory consuming. In this paper, we propose more powerful and efficient\nuncertainty predictors for MT evaluation, and we assess their ability to target\ndifferent sources of aleatoric and epistemic uncertainty. To this end, we\ndevelop and compare training objectives for the COMET metric to enhance it with\nan uncertainty prediction output, including heteroscedastic regression,\ndivergence minimization, and direct uncertainty prediction. Our experiments\nshow improved results on uncertainty prediction for the WMT metrics task\ndatasets, with a substantial reduction in computational costs. Moreover, they\ndemonstrate the ability of these predictors to address specific uncertainty\ncauses in MT evaluation, such as low quality references and out-of-domain data.\n",
                "链接": "https://arxiv.org/abs/2204.06546"
            },
            {
                "文章ID": "54518",
                "标题": "Extrinsic Evaluation of Machine Translation Metrics",
                "作者": " Nikita Moghe,  Tom Sherborne,  Mark Steedman,  Alexandra Birch",
                "发布日期": "2023-06-21",
                "摘要": "  Automatic machine translation (MT) metrics are widely used to distinguish the\ntranslation qualities of machine translation systems across relatively large\ntest sets (system-level evaluation). However, it is unclear if automatic\nmetrics are reliable at distinguishing good translations from bad translations\nat the sentence level (segment-level evaluation). In this paper, we investigate\nhow useful MT metrics are at detecting the success of a machine translation\ncomponent when placed in a larger platform with a downstream task. We evaluate\nthe segment-level performance of the most widely used MT metrics (chrF, COMET,\nBERTScore, etc.) on three downstream cross-lingual tasks (dialogue state\ntracking, question answering, and semantic parsing). For each task, we only\nhave access to a monolingual task-specific model. We calculate the correlation\nbetween the metric's ability to predict a good/bad translation with the\nsuccess/failure on the final task for the Translate-Test setup. Our experiments\ndemonstrate that all metrics exhibit negligible correlation with the extrinsic\nevaluation of the downstream outcomes. We also find that the scores provided by\nneural metrics are not interpretable mostly because of undefined ranges. We\nsynthesise our analysis into recommendations for future MT metrics to produce\nlabels rather than scores for more informative interaction between machine\ntranslation and multilingual language understanding.\n",
                "链接": "https://arxiv.org/abs/2212.10297"
            }
        ]
    },
    {
        "question": {
            "question": "查找大语言模型相关的分析类型的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "79369",
                "标题": "Decomposed Prompting for Machine Translation Between Related Languages\n  using Large Language Models",
                "作者": " Ratish Puduppully,  Anoop Kunchukuttan,  Raj Dabre,  Ai Ti Aw,  Nancy F. Chen",
                "发布日期": "2023-10-24",
                "摘要": "  This study investigates machine translation between related languages i.e.,\nlanguages within the same family that share linguistic characteristics such as\nword order and lexical similarity. Machine translation through few-shot\nprompting leverages a small set of translation pair examples to generate\ntranslations for test sentences. This procedure requires the model to learn how\nto generate translations while simultaneously ensuring that token ordering is\nmaintained to produce a fluent and accurate translation. We propose that for\nrelated languages, the task of machine translation can be simplified by\nleveraging the monotonic alignment characteristic of such languages. We\nintroduce DecoMT, a novel approach of few-shot prompting that decomposes the\ntranslation process into a sequence of word chunk translations. Through\nautomatic and human evaluation conducted on multiple related language pairs\nacross various language families, we demonstrate that our proposed approach of\ndecomposed prompting surpasses multiple established few-shot baseline\napproaches. For example, DecoMT outperforms the strong few-shot prompting BLOOM\nmodel with an average improvement of 8 chrF++ scores across the examined\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2305.13085"
            },
            {
                "文章ID": "125173",
                "标题": "A Large Language Model-based Computational Approach to Improve\n  Identity-Related Write-Ups",
                "作者": " Alex Doboli",
                "发布日期": "2023-12-29",
                "摘要": "  Creating written products is essential to modern life, including writings\nabout one's identity and personal experiences. However, writing is often a\ndifficult activity that requires extensive effort to frame the central ideas,\nthe pursued approach to communicate the central ideas, e.g., using analogies,\nmetaphors, or other possible means, the needed presentation structure, and the\nactual verbal expression. Large Language Models, a recently emerged approach in\nMachine Learning, can offer a significant help in reducing the effort and\nimproving the quality of written products. This paper proposes a new\ncomputational approach to explore prompts that given as inputs to a Large\nLanguage Models can generate cues to improve the considered written products.\nTwo case studies on improving write-ups, one based on an analogy and one on a\nmetaphor, are also presented in the paper.\n",
                "链接": "https://arxiv.org/abs/2312.16659"
            },
            {
                "文章ID": "70928",
                "标题": "Revolutionizing Single Cell Analysis: The Power of Large Language Models\n  for Cell Type Annotation",
                "作者": " Zehua Zeng,  Hongwu Du",
                "发布日期": "2023-04-07",
                "摘要": "  In recent years, single cell RNA sequencing has become a widely used\ntechnique to study cellular diversity and function. However, accurately\nannotating cell types from single cell data has been a challenging task, as it\nrequires extensive knowledge of cell biology and gene function. The emergence\nof large language models such as ChatGPT and New Bing in 2023 has\nrevolutionized this process by integrating the scientific literature and\nproviding accurate annotations of cell types. This breakthrough enables\nresearchers to conduct literature reviews more efficiently and accurately, and\ncan potentially uncover new insights into cell type annotation. By using\nChatGPT to annotate single cell data, we can relate rare cell type to their\nfunction and reveal specific differentiation trajectories of cell subtypes that\nwere previously overlooked. This can have important applications in\nunderstanding cancer progression, mammalian development, and stem cell\ndifferentiation, and can potentially lead to the discovery of key cells that\ninterrupt the differentiation pathway and solve key problems in the life\nsciences. Overall, the future of cell type annotation in single cell data looks\npromising and the Large Language model will be an important milestone in the\nhistory of single cell analysis.\n",
                "链接": "https://arxiv.org/abs/2304.02697"
            },
            {
                "文章ID": "107503",
                "标题": "An evolutionary model of personality traits related to cooperative\n  behavior using a large language model",
                "作者": " Reiji Suzuki,  Takaya Arita",
                "发布日期": "2023-10-11",
                "摘要": "  This paper aims to shed light on the evolutionary dynamics of diverse and\nsocial populations by introducing the rich expressiveness of generative models\ninto the trait expression of social agent-based evolutionary models.\nSpecifically, we focus on the evolution of personality traits in the context of\na game-theoretic relationship as a situation in which inter-individual\ninterests exert strong selection pressures. We construct an agent model in\nwhich linguistic descriptions of personality traits related to cooperative\nbehavior are used as genes. The deterministic strategies extracted from Large\nLanguage Model (LLM) that make behavioral decisions based on these personality\ntraits are used as behavioral traits. The population is evolved according to\nselection based on average payoff and mutation of genes by asking LLM to\nslightly modify the parent gene toward cooperative or selfish. Through\npreliminary experiments and analyses, we clarify that such a model can indeed\nexhibit the evolution of cooperative behavior based on the diverse and\nhigher-order representation of personality traits. We also observed the\nrepeated intrusion of cooperative and selfish personality traits through\nchanges in the expression of personality traits, and found that the emerging\nwords in the evolved gene well reflected the behavioral tendency of its\npersonality in terms of their semantics.\n",
                "链接": "https://arxiv.org/abs/2310.05976"
            },
            {
                "文章ID": "87693",
                "标题": "Chinese Fine-Grained Financial Sentiment Analysis with Large Language\n  Models",
                "作者": " Yinyu Lan,  Yanru Wu,  Wang Xu,  Weiqiang Feng,  Youhao Zhang",
                "发布日期": "2023-09-18",
                "摘要": "  Entity-level fine-grained sentiment analysis in the financial domain is a\ncrucial subtask of sentiment analysis and currently faces numerous challenges.\nThe primary challenge stems from the lack of high-quality and large-scale\nannotated corpora specifically designed for financial text sentiment analysis,\nwhich in turn limits the availability of data necessary for developing\neffective text processing techniques. Recent advancements in large language\nmodels (LLMs) have yielded remarkable performance in natural language\nprocessing tasks, primarily centered around language pattern matching. In this\npaper, we propose a novel and extensive Chinese fine-grained financial\nsentiment analysis dataset, FinChina SA, for enterprise early warning. We\nthoroughly evaluate and experiment with well-known existing open-source LLMs\nusing our dataset. We firmly believe that our dataset will serve as a valuable\nresource to advance the exploration of real-world financial sentiment analysis\ntasks, which should be the focus of future research. The FinChina SA dataset is\npublicly available at https://github.com/YerayL/FinChina-SA\n",
                "链接": "https://arxiv.org/abs/2306.14096"
            },
            {
                "文章ID": "105266",
                "标题": "A Large Language Model Approach to Educational Survey Feedback Analysis",
                "作者": " Michael J. Parker,  Caitlin Anderson,  Claire Stone,  YeaRim Oh",
                "发布日期": "2023-10-02",
                "摘要": "  This paper assesses the potential for the large language models (LLMs) GPT-4\nand GPT-3.5 to aid in deriving insight from education feedback surveys.\nExploration of LLM use cases in education has focused on teaching and learning,\nwith less exploration of capabilities in education feedback analysis. Survey\nanalysis in education involves goals such as finding gaps in curricula or\nevaluating teachers, often requiring time-consuming manual processing of\ntextual responses. LLMs have the potential to provide a flexible means of\nachieving these goals without specialized machine learning models or\nfine-tuning. We demonstrate a versatile approach to such goals by treating them\nas sequences of natural language processing (NLP) tasks including\nclassification (multi-label, multi-class, and binary), extraction, thematic\nanalysis, and sentiment analysis, each performed by LLM. We apply these\nworkflows to a real-world dataset of 2500 end-of-course survey comments from\nbiomedical science courses, and evaluate a zero-shot approach (i.e., requiring\nno examples or labeled training data) across all tasks, reflecting education\nsettings, where labeled data is often scarce. By applying effective prompting\npractices, we achieve human-level performance on multiple tasks with GPT-4,\nenabling workflows necessary to achieve typical goals. We also show the\npotential of inspecting LLMs' chain-of-thought (CoT) reasoning for providing\ninsight that may foster confidence in practice. Moreover, this study features\ndevelopment of a versatile set of classification categories, suitable for\nvarious course types (online, hybrid, or in-person) and amenable to\ncustomization. Our results suggest that LLMs can be used to derive a range of\ninsights from survey text.\n",
                "链接": "https://arxiv.org/abs/2309.17447"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            },
            {
                "文章ID": "81151",
                "标题": "Playing repeated games with Large Language Models",
                "作者": " Elif Akata,  Lion Schulz,  Julian Coda-Forno,  Seong Joon Oh,  Matthias Bethge,  Eric Schulz",
                "发布日期": "2023-05-29",
                "摘要": "  Large Language Models (LLMs) are transforming society and permeating into\ndiverse applications. As a result, LLMs will frequently interact with us and\nother agents. It is, therefore, of great societal value to understand how LLMs\nbehave in interactive social settings. Here, we propose to use behavioral game\ntheory to study LLM's cooperation and coordination behavior. To do so, we let\ndifferent LLMs (GPT-3, GPT-3.5, and GPT-4) play finitely repeated games with\neach other and with other, human-like strategies. Our results show that LLMs\ngenerally perform well in such tasks and also uncover persistent behavioral\nsignatures. In a large set of two players-two strategies games, we find that\nLLMs are particularly good at games where valuing their own self-interest pays\noff, like the iterated Prisoner's Dilemma family. However, they behave\nsub-optimally in games that require coordination. We, therefore, further focus\non two games from these distinct families. In the canonical iterated Prisoner's\nDilemma, we find that GPT-4 acts particularly unforgivingly, always defecting\nafter another agent has defected only once. In the Battle of the Sexes, we find\nthat GPT-4 cannot match the behavior of the simple convention to alternate\nbetween options. We verify that these behavioral signatures are stable across\nrobustness checks. Finally, we show how GPT-4's behavior can be modified by\nproviding further information about the other player as well as by asking it to\npredict the other player's actions before making a choice. These results enrich\nour understanding of LLM's social behavior and pave the way for a behavioral\ngame theory for machines.\n",
                "链接": "https://arxiv.org/abs/2305.16867"
            },
            {
                "文章ID": "90826",
                "标题": "Negated Complementary Commonsense using Large Language Models",
                "作者": " Navid Rezaei,  Marek Z. Reformat",
                "发布日期": "2023-07-14",
                "摘要": "  Larger language models, such as GPT-3, have shown to be excellent in many\ntasks. However, we demonstrate that out-of-ordinary questions can throw the\nmodel off guard. This work focuses on finding answers to negated complementary\nquestions in commonsense scenarios. We illustrate how such questions adversely\naffect the model responses. We propose a model-agnostic methodology to improve\nthe performance in negated complementary scenarios. Our method outperforms\nfew-shot generation from GPT-3 (by more than 11 points) and, more importantly,\nhighlights the significance of studying the response of large language models\nin negated complementary questions. The code, data, and experiments are\navailable under: https://github.com/navidre/negated_complementary_commonsense.\n",
                "链接": "https://arxiv.org/abs/2307.06794"
            },
            {
                "文章ID": "50760",
                "标题": "Fine-tuning language models to find agreement among humans with diverse\n  preferences",
                "作者": " Michiel A. Bakker,  Martin J. Chadwick,  Hannah R. Sheahan,  Michael Henry Tessler,  Lucy Campbell-Gillingham,  Jan Balaguer,  Nat McAleese,  Amelia Glaese,  John Aslanides,  Matthew M. Botvinick,  Christopher Summerfield",
                "发布日期": "2022-11-29",
                "摘要": "  Recent work in large language modeling (LLMs) has used fine-tuning to align\noutputs with the preferences of a prototypical user. This work assumes that\nhuman preferences are static and homogeneous across individuals, so that\naligning to a a single \"generic\" user will confer more general alignment. Here,\nwe embrace the heterogeneity of human preferences to consider a different\nchallenge: how might a machine help people with diverse views find agreement?\nWe fine-tune a 70 billion parameter LLM to generate statements that maximize\nthe expected approval for a group of people with potentially diverse opinions.\nHuman participants provide written opinions on thousands of questions touching\non moral and political issues (e.g., \"should we raise taxes on the rich?\"), and\nrate the LLM's generated candidate consensus statements for agreement and\nquality. A reward model is then trained to predict individual preferences,\nenabling it to quantify and rank consensus statements in terms of their appeal\nto the overall group, defined according to different aggregation (social\nwelfare) functions. The model produces consensus statements that are preferred\nby human users over those from prompted LLMs (>70%) and significantly\noutperforms a tight fine-tuned baseline that lacks the final ranking step.\nFurther, our best model's consensus statements are preferred over the best\nhuman-generated opinions (>65%). We find that when we silently constructed\nconsensus statements from only a subset of group members, those who were\nexcluded were more likely to dissent, revealing the sensitivity of the\nconsensus to individual contributions. These results highlight the potential to\nuse LLMs to help groups of humans align their values with one another.\n",
                "链接": "https://arxiv.org/abs/2211.15006"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于gpt4自动生成prompt的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "6028",
                "标题": "SGPT: GPT Sentence Embeddings for Semantic Search",
                "作者": " Niklas Muennighoff",
                "发布日期": "2022-08-08",
                "摘要": "  Decoder transformers have continued increasing in scale reaching hundreds of\nbillions of parameters. Due to their scale the same decoder sets\nstate-of-the-art results on various language tasks via prompting or\nfine-tuning. Yet, these large foundation models remain unusable for the related\nfields of semantic search and sentence embeddings. This prevents possibly new\nstate-of-the-art results and forces organizations to train and maintain\nseparate models. To this end, we propose SGPT to use decoders for sentence\nembeddings and semantic search via prompting or fine-tuning. At 5.8 billion\nparameters SGPT improves on the previously best sentence embeddings by a margin\nof 7% and outperforms a concurrent method with 175 billion parameters as\nmeasured on the BEIR search benchmark. Code, models and result files are freely\navailable at https://github.com/Muennighoff/sgpt.\n",
                "链接": "https://arxiv.org/abs/2202.08904"
            },
            {
                "文章ID": "91271",
                "标题": "The Potential and Pitfalls of using a Large Language Model such as\n  ChatGPT or GPT-4 as a Clinical Assistant",
                "作者": " Jingqing Zhang,  Kai Sun,  Akshay Jagadeesh,  Mahta Ghahfarokhi,  Deepa Gupta,  Ashok Gupta,  Vibhor Gupta,  Yike Guo",
                "发布日期": "2023-07-18",
                "摘要": "  Recent studies have demonstrated promising performance of ChatGPT and GPT-4\non several medical domain tasks. However, none have assessed its performance\nusing a large-scale real-world electronic health record database, nor have\nevaluated its utility in providing clinical diagnostic assistance for patients\nacross a full range of disease presentation. We performed two analyses using\nChatGPT and GPT-4, one to identify patients with specific medical diagnoses\nusing a real-world large electronic health record database and the other, in\nproviding diagnostic assistance to healthcare workers in the prospective\nevaluation of hypothetical patients. Our results show that GPT-4 across disease\nclassification tasks with chain of thought and few-shot prompting can achieve\nperformance as high as 96% F1 scores. For patient assessment, GPT-4 can\naccurately diagnose three out of four times. However, there were mentions of\nfactually incorrect statements, overlooking crucial medical findings,\nrecommendations for unnecessary investigations and overtreatment. These issues\ncoupled with privacy concerns, make these models currently inadequate for real\nworld clinical use. However, limited data and time needed for prompt\nengineering in comparison to configuration of conventional machine learning\nworkflows highlight their potential for scalability across healthcare\napplications.\n",
                "链接": "https://arxiv.org/abs/2307.08152"
            },
            {
                "文章ID": "124195",
                "标题": "Using GPT-4 Prompts to Determine Whether Articles Contain Functional\n  Evidence Supporting or Refuting Variant Pathogenicity",
                "作者": " Samuel J. Aronson,  Kalotina Machini,  Pranav Sriraman,  Jiyeon Shin,  Emma R. Henricks,  Charlotte Mailly,  Angie J. Nottage,  Michael Oates,  Matthew S. Lebo",
                "发布日期": "2023-12-22",
                "摘要": "  Purpose: To assess Generative Pre-trained Transformer version 4's (GPT-4)\nability to classify articles containing functional evidence relevant to\nassessments of variant pathogenicity.\n  Results: GPT-4 settings and prompts were trained on a set of 45 articles and\ngenetic variants. A final test set of 72 manually classified articles and\ngenetic variants were then processed using two prompts. The prompts asked GPT-4\nto supply all functional evidence present in an article for a variant or\nindicate that no functional evidence is present. For articles with having\nfunctional evidence, a second prompt asked GPT-4 to classify the evidence into\npathogenic, benign, intermediate, and inconclusive categories. The first prompt\nidentified articles with variant-level functional evidence with 87% sensitivity\nand 89% positive predictive value (PPV). Five of 26 articles with no functional\ndata were indicated as having functional evidence by GPT-4. For variants with\nfunctional assays present as determined by both manual review and GPT-4, the\nsensitivity and PPV of GPT-4 prompt concordance was: Pathogenic (92% sensitive\nand 73% PPV), Intermediate or Inconclusive (67% sensitive and 93% PPV), Benign\n(100% sensitive and 73% PPV).\n  Conclusion: The GPT-4 prompts detected the presence or absence of a\nfunctional assay with high sensitivity and PPV, and articles with unambiguous\nevidence supporting a benign or pathogenic classification with high sensitivity\nand reasonable PPV. Our prompts detected papers with intermediate or\ninconclusive evidence with lower sensitivity but high PPV. Our results support\nthat GPT-4 may be useful in variant classification workflows by enabling\nprioritization of articles for review that are likely to have functional\nevidence supporting or refuting pathogenicity, but not that GPT-4 is capable of\nfully automating the genetics literature review component of variant\nclassification.\n",
                "链接": "https://arxiv.org/abs/2312.13521"
            },
            {
                "文章ID": "73599",
                "标题": "Can GPT-4 Perform Neural Architecture Search?",
                "作者": " Mingkai Zheng,  Xiu Su,  Shan You,  Fei Wang,  Chen Qian,  Chang Xu,  Samuel Albanie",
                "发布日期": "2023-08-03",
                "摘要": "  We investigate the potential of GPT-4~\\cite{gpt4} to perform Neural\nArchitecture Search (NAS) -- the task of designing effective neural\narchitectures. Our proposed approach, \\textbf{G}PT-4 \\textbf{E}nhanced\n\\textbf{N}eural arch\\textbf{I}tect\\textbf{U}re \\textbf{S}earch (GENIUS),\nleverages the generative capabilities of GPT-4 as a black-box optimiser to\nquickly navigate the architecture search space, pinpoint promising candidates,\nand iteratively refine these candidates to improve performance. We assess\nGENIUS across several benchmarks, comparing it with existing state-of-the-art\nNAS techniques to illustrate its effectiveness. Rather than targeting\nstate-of-the-art performance, our objective is to highlight GPT-4's potential\nto assist research on a challenging technical problem through a simple\nprompting scheme that requires relatively limited domain\nexpertise\\footnote{Code available at\n\\href{https://github.com/mingkai-zheng/GENIUS}{https://github.com/mingkai-zheng/GENIUS}.}.\nMore broadly, we believe our preliminary results point to future research that\nharnesses general purpose language models for diverse optimisation tasks. We\nalso highlight important limitations to our study, and note implications for AI\nsafety.\n",
                "链接": "https://arxiv.org/abs/2304.10970"
            },
            {
                "文章ID": "105803",
                "标题": "Graph Neural Architecture Search with GPT-4",
                "作者": " Haishuai Wang,  Yang Gao,  Xin Zheng,  Peng Zhang,  Hongyang Chen,  Jiajun Bu",
                "发布日期": "2023-10-04",
                "摘要": "  Graph Neural Architecture Search (GNAS) has shown promising results in\nautomatically designing graph neural networks. However, GNAS still requires\nintensive human labor with rich domain knowledge to design the search space and\nsearch strategy. In this paper, we integrate GPT-4 into GNAS and propose a new\nGPT-4 based Graph Neural Architecture Search method (GPT4GNAS for short). The\nbasic idea of our method is to design a new class of prompts for GPT-4 to guide\nGPT-4 toward the generative task of graph neural architectures. The prompts\nconsist of descriptions of the search space, search strategy, and search\nfeedback of GNAS. By iteratively running GPT-4 with the prompts, GPT4GNAS\ngenerates more accurate graph neural networks with fast convergence.\nExperimental results show that embedding GPT-4 into GNAS outperforms the\nstate-of-the-art GNAS methods.\n",
                "链接": "https://arxiv.org/abs/2310.01436"
            },
            {
                "文章ID": "70587",
                "标题": "GPT-4 to GPT-3.5: 'Hold My Scalpel' -- A Look at the Competency of\n  OpenAI's GPT on the Plastic Surgery In-Service Training Exam",
                "作者": " Jonathan D. Freedman,  Ian A. Nappier",
                "发布日期": "2023-04-05",
                "摘要": "  The Plastic Surgery In-Service Training Exam (PSITE) is an important\nindicator of resident proficiency and serves as a useful benchmark for\nevaluating OpenAI's GPT. Unlike many of the simulated tests or practice\nquestions shown in the GPT-4 Technical Paper, the multiple-choice questions\nevaluated here are authentic PSITE questions. These questions offer realistic\nclinical vignettes that a plastic surgeon commonly encounters in practice and\nscores highly correlate with passing the written boards required to become a\nBoard Certified Plastic Surgeon. Our evaluation shows dramatic improvement of\nGPT-4 (without vision) over GPT-3.5 with both the 2022 and 2021 exams\nrespectively increasing the score from 8th to 88th percentile and 3rd to 99th\npercentile. The final results of the 2023 PSITE are set to be released on April\n11, 2023, and this is an exciting moment to continue our research with a fresh\nexam. Our evaluation pipeline is ready for the moment that the exam is released\nso long as we have access via OpenAI to the GPT-4 API. With multimodal input,\nwe may achieve superhuman performance on the 2023.\n",
                "链接": "https://arxiv.org/abs/2304.01503"
            },
            {
                "文章ID": "79086",
                "标题": "GPT-3.5, GPT-4, or BARD? Evaluating LLMs Reasoning Ability in Zero-Shot\n  Setting and Performance Boosting Through Prompts",
                "作者": " Jessica López Espejel,  El Hassane Ettifouri,  Mahaman Sanoussi Yahaya Alassan,  El Mehdi Chouham,  Walid Dahhane",
                "发布日期": "2023-09-21",
                "摘要": "  Large Language Models (LLMs) have exhibited remarkable performance on various\nNatural Language Processing (NLP) tasks. However, there is a current hot debate\nregarding their reasoning capacity. In this paper, we examine the performance\nof GPT-3.5, GPT-4, and BARD models, by performing a thorough technical\nevaluation on different reasoning tasks across eleven distinct datasets. Our\npaper provides empirical evidence showcasing the superior performance of\nChatGPT-4 in comparison to both ChatGPT-3.5 and BARD in zero-shot setting\nthroughout almost all evaluated tasks. While the superiority of GPT-4 compared\nto GPT-3.5 might be explained by its larger size and NLP efficiency, this was\nnot evident for BARD. We also demonstrate that the three models show limited\nproficiency in Inductive, Mathematical, and Multi-hop Reasoning Tasks. To\nbolster our findings, we present a detailed and comprehensive analysis of the\nresults from these three models. Furthermore, we propose a set of engineered\nprompts that enhances the zero-shot setting performance of all three models.\n",
                "链接": "https://arxiv.org/abs/2305.12477"
            },
            {
                "文章ID": "56440",
                "标题": "Automatic Generation of German Drama Texts Using Fine Tuned GPT-2 Models",
                "作者": " Mariam Bangura,  Kristina Barabashova,  Anna Karnysheva,  Sarah Semczuk,  Yifan Wang",
                "发布日期": "2023-01-11",
                "摘要": "  This study is devoted to the automatic generation of German drama texts. We\nsuggest an approach consisting of two key steps: fine-tuning a GPT-2 model (the\noutline model) to generate outlines of scenes based on keywords and fine-tuning\na second model (the generation model) to generate scenes from the scene\noutline. The input for the neural model comprises two datasets: the German\nDrama Corpus (GerDraCor) and German Text Archive (Deutsches Textarchiv or DTA).\nIn order to estimate the effectiveness of the proposed method, our models are\ncompared with baseline GPT-2 models. Our models perform well according to\nautomatic quantitative evaluation, but, conversely, manual qualitative analysis\nreveals a poor quality of generated texts. This may be due to the quality of\nthe dataset or training inputs.\n",
                "链接": "https://arxiv.org/abs/2301.03119"
            },
            {
                "文章ID": "25000",
                "标题": "Towards the Generation of Musical Explanations with GPT-3",
                "作者": " Stephen James Krol,  Maria Teresa Llano,  Jon McCormack",
                "发布日期": "2022-06-17",
                "摘要": "  Open AI's language model, GPT-3, has shown great potential for many NLP\ntasks, with applications in many different domains. In this work we carry out a\nfirst study on GPT-3's capability to communicate musical decisions through\ntextual explanations when prompted with a textual representation of a piece of\nmusic. Enabling a dialogue in human-AI music partnerships is an important step\ntowards more engaging and creative human-AI interactions. Our results show that\nGPT-3 lacks the necessary intelligence to really understand musical decisions.\nA major barrier to reach a better performance is the lack of data that includes\nexplanations of the creative process carried out by artists for musical pieces.\nWe believe such a resource would aid the understanding and collaboration with\nAI music systems.\n",
                "链接": "https://arxiv.org/abs/2206.08264"
            },
            {
                "文章ID": "68829",
                "标题": "Analyzing the Performance of GPT-3.5 and GPT-4 in Grammatical Error\n  Correction",
                "作者": " Steven Coyne,  Keisuke Sakaguchi,  Diana Galvan-Sosa,  Michael Zock,  Kentaro Inui",
                "发布日期": "2023-05-31",
                "摘要": "  GPT-3 and GPT-4 models are powerful, achieving high performance on a variety\nof Natural Language Processing tasks. However, there is a relative lack of\ndetailed published analysis of their performance on the task of grammatical\nerror correction (GEC). To address this, we perform experiments testing the\ncapabilities of a GPT-3.5 model (text-davinci-003) and a GPT-4 model\n(gpt-4-0314) on major GEC benchmarks. We compare the performance of different\nprompts in both zero-shot and few-shot settings, analyzing intriguing or\nproblematic outputs encountered with different prompt formats. We report the\nperformance of our best prompt on the BEA-2019 and JFLEG datasets, finding that\nthe GPT models can perform well in a sentence-level revision setting, with\nGPT-4 achieving a new high score on the JFLEG benchmark. Through human\nevaluation experiments, we compare the GPT models' corrections to source, human\nreference, and baseline GEC system sentences and observe differences in editing\nstrategies and how they are scored by human raters.\n",
                "链接": "https://arxiv.org/abs/2303.14342"
            }
        ]
    },
    {
        "question": {
            "question": "新的大模型结构相关探索的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "83595",
                "标题": "Explore and Exploit the Diverse Knowledge in Model Zoo for Domain\n  Generalization",
                "作者": " Yimeng Chen,  Tianyang Hu,  Fengwei Zhou,  Zhenguo Li,  Zhiming Ma",
                "发布日期": "2023-06-06",
                "摘要": "  The proliferation of pretrained models, as a result of advancements in\npretraining techniques, has led to the emergence of a vast zoo of publicly\navailable models. Effectively utilizing these resources to obtain models with\nrobust out-of-distribution generalization capabilities for downstream tasks has\nbecome a crucial area of research. Previous research has primarily focused on\nidentifying the most powerful models within the model zoo, neglecting to fully\nleverage the diverse inductive biases contained within. This paper argues that\nthe knowledge contained in weaker models is valuable and presents a method for\nleveraging the diversity within the model zoo to improve out-of-distribution\ngeneralization capabilities. Specifically, we investigate the behaviors of\nvarious pretrained models across different domains of downstream tasks by\ncharacterizing the variations in their encoded representations in terms of two\ndimensions: diversity shift and correlation shift. This characterization\nenables us to propose a new algorithm for integrating diverse pretrained\nmodels, not limited to the strongest models, in order to achieve enhanced\nout-of-distribution generalization performance. Our proposed method\ndemonstrates state-of-the-art empirical results on a variety of datasets, thus\nvalidating the benefits of utilizing diverse knowledge.\n",
                "链接": "https://arxiv.org/abs/2306.02595"
            },
            {
                "文章ID": "86166",
                "标题": "Explore, Establish, Exploit: Red Teaming Language Models from Scratch",
                "作者": " Stephen Casper,  Jason Lin,  Joe Kwon,  Gatlen Culp,  Dylan Hadfield-Menell",
                "发布日期": "2023-10-12",
                "摘要": "  Deploying large language models (LMs) can pose hazards from harmful outputs\nsuch as toxic or false text. Prior work has introduced automated tools that\nelicit harmful outputs to identify these risks. While this is a valuable step\ntoward securing models, these approaches rely on a pre-existing way to\nefficiently classify undesirable outputs. Using a pre-existing classifier does\nnot allow for red-teaming to be tailored to the target model. Furthermore, when\nfailures can be easily classified in advance, red-teaming has limited marginal\nvalue because problems can be avoided by simply filtering training data and/or\nmodel outputs. Here, we consider red-teaming \"from scratch,\" in which the\nadversary does not begin with a way to classify failures. Our framework\nconsists of three steps: 1) Exploring the model's range of behaviors in the\ndesired context; 2) Establishing a definition and measurement for undesired\nbehavior (e.g., a classifier trained to reflect human evaluations); and 3)\nExploiting the model's flaws using this measure to develop diverse adversarial\nprompts. We use this approach to red-team GPT-3 to discover classes of inputs\nthat elicit false statements. In doing so, we construct the CommonClaim dataset\nof 20,000 statements labeled by humans as common-knowledge-true, common\nknowledge-false, or neither. We are making code and data available.\n",
                "链接": "https://arxiv.org/abs/2306.09442"
            },
            {
                "文章ID": "89505",
                "标题": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
                "作者": " Ben Norman,  Jeff Clune",
                "发布日期": "2023-07-06",
                "摘要": "  Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.\n",
                "链接": "https://arxiv.org/abs/2307.02276"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "21952",
                "标题": "SEREN: Knowing When to Explore and When to Exploit",
                "作者": " Changmin Yu,  David Mguni,  Dong Li,  Aivar Sootla,  Jun Wang,  Neil Burgess",
                "发布日期": "2022-07-01",
                "摘要": "  Efficient reinforcement learning (RL) involves a trade-off between\n\"exploitative\" actions that maximise expected reward and \"explorative'\" ones\nthat sample unvisited states. To encourage exploration, recent approaches\nproposed adding stochasticity to actions, separating exploration and\nexploitation phases, or equating reduction in uncertainty with reward. However,\nthese techniques do not necessarily offer entirely systematic approaches making\nthis trade-off. Here we introduce SElective Reinforcement Exploration Network\n(SEREN) that poses the exploration-exploitation trade-off as a game between an\nRL agent -- \\exploiter, which purely exploits known rewards, and another RL\nagent -- \\switcher, which chooses at which states to activate a pure\nexploration policy that is trained to minimise system uncertainty and override\nExploiter. Using a form of policies known as impulse control, \\switcher is able\nto determine the best set of states to switch to the exploration policy while\nExploiter is free to execute its actions everywhere else. We prove that SEREN\nconverges quickly and induces a natural schedule towards pure exploitation.\nThrough extensive empirical studies in both discrete (MiniGrid) and continuous\n(MuJoCo) control benchmarks, we show that SEREN can be readily combined with\nexisting RL algorithms to yield significant improvement in performance relative\nto state-of-the-art algorithms.\n",
                "链接": "https://arxiv.org/abs/2205.15064"
            },
            {
                "文章ID": "3141",
                "标题": "DoubleU-Net++: Architecture with Exploit Multiscale Features for\n  Vertebrae Segmentation",
                "作者": " Simindokht Jahangard,  Mahdi Bonyani,  Abbas Khosravi",
                "发布日期": "2022-02-01",
                "摘要": "  Accurate segmentation of the vertebra is an important prerequisite in various\nmedical applications (E.g. tele surgery) to assist surgeons. Following the\nsuccessful development of deep neural networks, recent studies have focused on\nthe essential rule of vertebral segmentation. Prior works contain a large\nnumber of parameters, and their segmentation is restricted to only one view.\nInspired by DoubleU-Net, we propose a novel model named DoubleU-Net++ in which\nDensNet as feature extractor, special attention module from Convolutional Block\nAttention on Module (CBAM) and, Pyramid Squeeze Attention (PSA) module are\nemployed to improve extracted features. We evaluate our proposed model on three\ndifferent views (sagittal, coronal, and axial) of VerSe2020 and xVertSeg\ndatasets. Compared with state-of-the-art studies, our architecture is trained\nfaster and achieves higher precision, recall, and F1-score as evaluation\n(imporoved by 4-6%) and the result of above 94% for sagittal view and above 94%\nfor both coronal view and above 93% axial view were gained for VerSe2020\ndataset, respectively. Also, for xVertSeg dataset, we achieved precision,\nrecall,and F1-score of above 97% for sagittal view, above 93% for coronal view\n,and above 96% for axial view.\n",
                "链接": "https://arxiv.org/abs/2201.12389"
            },
            {
                "文章ID": "57742",
                "标题": "Neural Architecture Search: Insights from 1000 Papers",
                "作者": " Colin White,  Mahmoud Safari,  Rhea Sukthanker,  Binxin Ru,  Thomas Elsken,  Arber Zela,  Debadeepta Dey,  Frank Hutter",
                "发布日期": "2023-01-26",
                "摘要": "  In the past decade, advances in deep learning have resulted in breakthroughs\nin a variety of areas, including computer vision, natural language\nunderstanding, speech recognition, and reinforcement learning. Specialized,\nhigh-performing neural architectures are crucial to the success of deep\nlearning in these areas. Neural architecture search (NAS), the process of\nautomating the design of neural architectures for a given task, is an\ninevitable next step in automating machine learning and has already outpaced\nthe best human-designed architectures on many tasks. In the past few years,\nresearch in NAS has been progressing rapidly, with over 1000 papers released\nsince 2020 (Deng and Lindauer, 2021). In this survey, we provide an organized\nand comprehensive guide to neural architecture search. We give a taxonomy of\nsearch spaces, algorithms, and speedup techniques, and we discuss resources\nsuch as benchmarks, best practices, other surveys, and open-source libraries.\n",
                "链接": "https://arxiv.org/abs/2301.08727"
            },
            {
                "文章ID": "91534",
                "标题": "Federated Large Language Model: A Position Paper",
                "作者": " Chaochao Chen,  Xiaohua Feng,  Jun Zhou,  Jianwei Yin,  Xiaolin Zheng",
                "发布日期": "2023-07-19",
                "摘要": "  Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n",
                "链接": "https://arxiv.org/abs/2307.08925"
            },
            {
                "文章ID": "64096",
                "标题": "Containing a spread through sequential learning: to exploit or to\n  explore?",
                "作者": " Xingran Chen,  Hesam Nikpey,  Jungyeol Kim,  Saswati Sarkar,  Shirin Saeedi-Bidokhti",
                "发布日期": "2023-03-24",
                "摘要": "  The spread of an undesirable contact process, such as an infectious disease\n(e.g. COVID-19), is contained through testing and isolation of infected nodes.\nThe temporal and spatial evolution of the process (along with containment\nthrough isolation) render such detection as fundamentally different from active\nsearch detection strategies. In this work, through an active learning approach,\nwe design testing and isolation strategies to contain the spread and minimize\nthe cumulative infections under a given test budget. We prove that the\nobjective can be optimized, with performance guarantees, by greedily selecting\nthe nodes to test. We further design reward-based methodologies that\neffectively minimize an upper bound on the cumulative infections and are\ncomputationally more tractable in large networks. These policies, however, need\nknowledge about the nodes' infection probabilities which are dynamically\nchanging and have to be learned by sequential testing. We develop a\nmessage-passing framework for this purpose and, building on that, show novel\ntradeoffs between exploitation of knowledge through reward-based heuristics and\nexploration of the unknown through a carefully designed probabilistic testing.\nThe tradeoffs are fundamentally distinct from the classical counterparts under\nactive search or multi-armed bandit problems (MABs). We provably show the\nnecessity of exploration in a stylized network and show through simulations\nthat exploration can outperform exploitation in various synthetic and real-data\nnetworks depending on the parameters of the network and the spread.\n",
                "链接": "https://arxiv.org/abs/2303.00141"
            },
            {
                "文章ID": "108589",
                "标题": "LLaMA Rider: Spurring Large Language Models to Explore the Open World",
                "作者": " Yicheng Feng,  Yuxuan Wang,  Jiazheng Liu,  Sipeng Zheng,  Zongqing Lu",
                "发布日期": "2023-10-16",
                "摘要": "  Recently, various studies have leveraged Large Language Models (LLMs) to help\ndecision-making and planning in environments, and try to align the LLMs'\nknowledge with the world conditions. Nonetheless, the capacity of LLMs to\ncontinuously acquire environmental knowledge and adapt in an open world remains\nuncertain. In this paper, we propose an approach to spur LLMs to explore the\nopen world, gather experiences, and learn to improve their task-solving\ncapabilities. In this approach, a multi-round feedback-revision mechanism is\nutilized to encourage LLMs to actively select appropriate revision actions\nguided by feedback information from the environment. This facilitates\nexploration and enhances the model's performance. Besides, we integrate\nsub-task relabeling to assist LLMs in maintaining consistency in sub-task\nplanning and help the model learn the combinatorial nature between tasks,\nenabling it to complete a wider range of tasks through training based on the\nacquired exploration experiences. By evaluation in Minecraft, an open-ended\nsandbox world, we demonstrate that our approach LLaMA-Rider enhances the\nefficiency of the LLM in exploring the environment, and effectively improves\nthe LLM's ability to accomplish more tasks through fine-tuning with merely 1.3k\ninstances of collected data, showing minimal training costs compared to the\nbaseline using reinforcement learning.\n",
                "链接": "https://arxiv.org/abs/2310.08922"
            }
        ]
    },
    {
        "question": {
            "question": "多模态细粒度图片编辑和生成相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "124621",
                "标题": "FineMoGen: Fine-Grained Spatio-Temporal Motion Generation and Editing",
                "作者": " Mingyuan Zhang,  Huirong Li,  Zhongang Cai,  Jiawei Ren,  Lei Yang,  Ziwei Liu",
                "发布日期": "2023-12-27",
                "摘要": "  Text-driven motion generation has achieved substantial progress with the\nemergence of diffusion models. However, existing methods still struggle to\ngenerate complex motion sequences that correspond to fine-grained descriptions,\ndepicting detailed and accurate spatio-temporal actions. This lack of fine\ncontrollability limits the usage of motion generation to a larger audience. To\ntackle these challenges, we present FineMoGen, a diffusion-based motion\ngeneration and editing framework that can synthesize fine-grained motions, with\nspatial-temporal composition to the user instructions. Specifically, FineMoGen\nbuilds upon diffusion model with a novel transformer architecture dubbed\nSpatio-Temporal Mixture Attention (SAMI). SAMI optimizes the generation of the\nglobal attention template from two perspectives: 1) explicitly modeling the\nconstraints of spatio-temporal composition; and 2) utilizing sparsely-activated\nmixture-of-experts to adaptively extract fine-grained features. To facilitate a\nlarge-scale study on this new fine-grained motion generation task, we\ncontribute the HuMMan-MoGen dataset, which consists of 2,968 videos and 102,336\nfine-grained spatio-temporal descriptions. Extensive experiments validate that\nFineMoGen exhibits superior motion generation quality over state-of-the-art\nmethods. Notably, FineMoGen further enables zero-shot motion editing\ncapabilities with the aid of modern large language models (LLM), which\nfaithfully manipulates motion sequences with fine-grained instructions. Project\nPage: https://mingyuan-zhang.github.io/projects/FineMoGen.html\n",
                "链接": "https://arxiv.org/abs/2312.15004"
            },
            {
                "文章ID": "13260",
                "标题": "Flexible Portrait Image Editing with Fine-Grained Control",
                "作者": " Linlin Liu,  Qian Fu,  Fei Hou,  Ying He",
                "发布日期": "2022-04-05",
                "摘要": "  We develop a new method for portrait image editing, which supports\nfine-grained editing of geometries, colors, lights and shadows using a single\nneural network model. We adopt a novel asymmetric conditional GAN architecture:\nthe generators take the transformed conditional inputs, such as edge maps,\ncolor palette, sliders and masks, that can be directly edited by the user; the\ndiscriminators take the conditional inputs in the way that can guide\ncontrollable image generation more effectively. Taking color editing as an\nexample, we feed color palettes (which can be edited easily) into the\ngenerator, and color maps (which contain positional information of colors) into\nthe discriminator. We also design a region-weighted discriminator so that\nhigher weights are assigned to more important regions, like eyes and skin.\nUsing a color palette, the user can directly specify the desired colors of\nhair, skin, eyes, lip and background. Color sliders allow the user to blend\ncolors in an intuitive manner. The user can also edit lights and shadows by\nmodifying the corresponding masks. We demonstrate the effectiveness of our\nmethod by evaluating it on the CelebAMask-HQ dataset with a wide range of\ntasks, including geometry/color/shadow/light editing, hand-drawn sketch to\nimage translation, and color transfer. We also present ablation studies to\njustify our design.\n",
                "链接": "https://arxiv.org/abs/2204.01318"
            },
            {
                "文章ID": "32492",
                "标题": "Preserving Fine-Grain Feature Information in Classification via Entropic\n  Regularization",
                "作者": " Raphael Baena,  Lucas Drumetz,  Vincent Gripon",
                "发布日期": "2022-08-09",
                "摘要": "  Labeling a classification dataset implies to define classes and associated\ncoarse labels, that may approximate a smoother and more complicated ground\ntruth. For example, natural images may contain multiple objects, only one of\nwhich is labeled in many vision datasets, or classes may result from the\ndiscretization of a regression problem. Using cross-entropy to train\nclassification models on such coarse labels is likely to roughly cut through\nthe feature space, potentially disregarding the most meaningful such features,\nin particular losing information on the underlying fine-grain task. In this\npaper we are interested in the problem of solving fine-grain classification or\nregression, using a model trained on coarse-grain labels only. We show that\nstandard cross-entropy can lead to overfitting to coarse-related features. We\nintroduce an entropy-based regularization to promote more diversity in the\nfeature space of trained models, and empirically demonstrate the efficacy of\nthis methodology to reach better performance on the fine-grain problems. Our\nresults are supported through theoretical developments and empirical\nvalidation.\n",
                "链接": "https://arxiv.org/abs/2208.03684"
            },
            {
                "文章ID": "90600",
                "标题": "Grain and Grain Boundary Segmentation using Machine Learning with Real\n  and Generated Datasets",
                "作者": " Peter Warren,  Nandhini Raju,  Abhilash Prasad,  Shajahan Hossain,  Ramesh Subramanian,  Jayanta Kapat,  Navin Manjooran,  Ranajay Ghosh",
                "发布日期": "2023-07-13",
                "摘要": "  We report significantly improved accuracy of grain boundary segmentation\nusing Convolutional Neural Networks (CNN) trained on a combination of real and\ngenerated data. Manual segmentation is accurate but time-consuming, and\nexisting computational methods are faster but often inaccurate. To combat this\ndilemma, machine learning models can be used to achieve the accuracy of manual\nsegmentation and have the efficiency of a computational method. An extensive\ndataset of from 316L stainless steel samples is additively manufactured,\nprepared, polished, etched, and then microstructure grain images were\nsystematically collected. Grain segmentation via existing computational methods\nand manual (by-hand) were conducted, to create \"real\" training data. A Voronoi\ntessellation pattern combined with random synthetic noise and simulated\ndefects, is developed to create a novel artificial grain image fabrication\nmethod. This provided training data supplementation for data-intensive machine\nlearning methods. The accuracy of the grain measurements from microstructure\nimages segmented via computational methods and machine learning methods\nproposed in this work are calculated and compared to provide much benchmarks in\ngrain segmentation. Over 400 images of the microstructure of stainless steel\nsamples were manually segmented for machine learning training applications.\nThis data and the artificial data is available on Kaggle.\n",
                "链接": "https://arxiv.org/abs/2307.05911"
            },
            {
                "文章ID": "73032",
                "标题": "Text-guided Image-and-Shape Editing and Generation: A Short Survey",
                "作者": " Cheng-Kang Ted Chao,  Yotam Gingold",
                "发布日期": "2023-04-20",
                "摘要": "  Image and shape editing are ubiquitous among digital artworks. Graphics\nalgorithms facilitate artists and designers to achieve desired editing intents\nwithout going through manually tedious retouching. In the recent advance of\nmachine learning, artists' editing intents can even be driven by text, using a\nvariety of well-trained neural networks. They have seen to be receiving an\nextensive success on such as generating photorealistic images, artworks and\nhuman poses, stylizing meshes from text, or auto-completion given image and\nshape priors. In this short survey, we provide an overview over 50 papers on\nstate-of-the-art (text-guided) image-and-shape generation techniques. We start\nwith an overview on recent editing algorithms in the introduction. Then, we\nprovide a comprehensive review on text-guided editing techniques for 2D and 3D\nindependently, where each of its sub-section begins with a brief background\nintroduction. We also contextualize editing algorithms under recent implicit\nneural representations. Finally, we conclude the survey with the discussion\nover existing methods and potential research ideas.\n",
                "链接": "https://arxiv.org/abs/2304.09244"
            },
            {
                "文章ID": "8399",
                "标题": "DrawingInStyles: Portrait Image Generation and Editing with Spatially\n  Conditioned StyleGAN",
                "作者": " Wanchao Su,  Hui Ye,  Shu-Yu Chen,  Lin Gao,  Hongbo Fu",
                "发布日期": "2022-06-01",
                "摘要": "  The research topic of sketch-to-portrait generation has witnessed a boost of\nprogress with deep learning techniques. The recently proposed StyleGAN\narchitectures achieve state-of-the-art generation ability but the original\nStyleGAN is not friendly for sketch-based creation due to its unconditional\ngeneration nature. To address this issue, we propose a direct conditioning\nstrategy to better preserve the spatial information under the StyleGAN\nframework. Specifically, we introduce Spatially Conditioned StyleGAN\n(SC-StyleGAN for short), which explicitly injects spatial constraints to the\noriginal StyleGAN generation process. We explore two input modalities, sketches\nand semantic maps, which together allow users to express desired generation\nresults more precisely and easily. Based on SC-StyleGAN, we present\nDrawingInStyles, a novel drawing interface for non-professional users to easily\nproduce high-quality, photo-realistic face images with precise control, either\nfrom scratch or editing existing ones. Qualitative and quantitative evaluations\nshow the superior generation ability of our method to existing and alternative\nsolutions. The usability and expressiveness of our system are confirmed by a\nuser study.\n",
                "链接": "https://arxiv.org/abs/2203.02762"
            },
            {
                "文章ID": "20765",
                "标题": "M6-Fashion: High-Fidelity Multi-modal Image Generation and Editing",
                "作者": " Zhikang Li,  Huiling Zhou,  Shuai Bai,  Peike Li,  Chang Zhou,  Hongxia Yang",
                "发布日期": "2022-05-25",
                "摘要": "  The fashion industry has diverse applications in multi-modal image generation\nand editing. It aims to create a desired high-fidelity image with the\nmulti-modal conditional signal as guidance. Most existing methods learn\ndifferent condition guidance controls by introducing extra models or ignoring\nthe style prior knowledge, which is difficult to handle multiple signal\ncombinations and faces a low-fidelity problem. In this paper, we adapt both\nstyle prior knowledge and flexibility of multi-modal control into one unified\ntwo-stage framework, M6-Fashion, focusing on the practical AI-aided Fashion\ndesign. It decouples style codes in both spatial and semantic dimensions to\nguarantee high-fidelity image generation in the first stage. M6-Fashion\nutilizes self-correction for the non-autoregressive generation to improve\ninference speed, enhance holistic consistency, and support various signal\ncontrols. Extensive experiments on a large-scale clothing dataset M2C-Fashion\ndemonstrate superior performances on various image generation and editing\ntasks. M6-Fashion model serves as a highly potential AI designer for the\nfashion industry.\n",
                "链接": "https://arxiv.org/abs/2205.11705"
            },
            {
                "文章ID": "116307",
                "标题": "Emu Edit: Precise Image Editing via Recognition and Generation Tasks",
                "作者": " Shelly Sheynin,  Adam Polyak,  Uriel Singer,  Yuval Kirstain,  Amit Zohar,  Oron Ashual,  Devi Parikh,  Yaniv Taigman",
                "发布日期": "2023-11-17",
                "摘要": "  Instruction-based image editing holds immense potential for a variety of\napplications, as it enables users to perform any editing operation using a\nnatural language instruction. However, current models in this domain often\nstruggle with accurately executing user instructions. We present Emu Edit, a\nmulti-task image editing model which sets state-of-the-art results in\ninstruction-based image editing. To develop Emu Edit we train it to multi-task\nacross an unprecedented range of tasks, such as region-based editing, free-form\nediting, and Computer Vision tasks, all of which are formulated as generative\ntasks. Additionally, to enhance Emu Edit's multi-task learning abilities, we\nprovide it with learned task embeddings which guide the generation process\ntowards the correct edit type. Both these elements are essential for Emu Edit's\noutstanding performance. Furthermore, we show that Emu Edit can generalize to\nnew tasks, such as image inpainting, super-resolution, and compositions of\nediting tasks, with just a few labeled examples. This capability offers a\nsignificant advantage in scenarios where high-quality samples are scarce.\nLastly, to facilitate a more rigorous and informed assessment of instructable\nimage editing models, we release a new challenging and versatile benchmark that\nincludes seven different image editing tasks.\n",
                "链接": "https://arxiv.org/abs/2311.10089"
            },
            {
                "文章ID": "36699",
                "标题": "Fine-grain Inference on Out-of-Distribution Data with Hierarchical\n  Classification",
                "作者": " Randolph Linderman,  Jingyang Zhang,  Nathan Inkawhich,  Hai Li,  Yiran Chen",
                "发布日期": "2022-09-13",
                "摘要": "  Machine learning methods must be trusted to make appropriate decisions in\nreal-world environments, even when faced with out-of-distribution (OOD)\nsamples. Many current approaches simply aim to detect OOD examples and alert\nthe user when an unrecognized input is given. However, when the OOD sample\nsignificantly overlaps with the training data, a binary anomaly detection is\nnot interpretable or explainable, and provides little information to the user.\nWe propose a new model for OOD detection that makes predictions at varying\nlevels of granularity as the inputs become more ambiguous, the model\npredictions become coarser and more conservative. Consider an animal classifier\nthat encounters an unknown bird species and a car. Both cases are OOD, but the\nuser gains more information if the classifier recognizes that its uncertainty\nover the particular species is too large and predicts bird instead of detecting\nit as OOD. Furthermore, we diagnose the classifiers performance at each level\nof the hierarchy improving the explainability and interpretability of the\nmodels predictions. We demonstrate the effectiveness of hierarchical\nclassifiers for both fine- and coarse-grained OOD tasks.\n",
                "链接": "https://arxiv.org/abs/2209.04493"
            },
            {
                "文章ID": "123486",
                "标题": "SCEdit: Efficient and Controllable Image Diffusion Generation via Skip\n  Connection Editing",
                "作者": " Zeyinzi Jiang,  Chaojie Mao,  Yulin Pan,  Zhen Han,  Jingfeng Zhang",
                "发布日期": "2023-12-19",
                "摘要": "  Image diffusion models have been utilized in various tasks, such as\ntext-to-image generation and controllable image synthesis. Recent research has\nintroduced tuning methods that make subtle adjustments to the original models,\nyielding promising results in specific adaptations of foundational generative\ndiffusion models. Rather than modifying the main backbone of the diffusion\nmodel, we delve into the role of skip connection in U-Net and reveal that\nhierarchical features aggregating long-distance information across encoder and\ndecoder make a significant impact on the content and quality of image\ngeneration. Based on the observation, we propose an efficient generative tuning\nframework, dubbed SCEdit, which integrates and edits Skip Connection using a\nlightweight tuning module named SC-Tuner. Furthermore, the proposed framework\nallows for straightforward extension to controllable image synthesis by\ninjecting different conditions with Controllable SC-Tuner, simplifying and\nunifying the network design for multi-condition inputs. Our SCEdit\nsubstantially reduces training parameters, memory usage, and computational\nexpense due to its lightweight tuners, with backward propagation only passing\nto the decoder blocks. Extensive experiments conducted on text-to-image\ngeneration and controllable image synthesis tasks demonstrate the superiority\nof our method in terms of efficiency and performance. Project page:\n\\url{https://scedit.github.io/}\n",
                "链接": "https://arxiv.org/abs/2312.11392"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找风格化机器翻译相关的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "40744",
                "标题": "The Influence of Explainable Artificial Intelligence: Nudging Behaviour\n  or Boosting Capability?",
                "作者": " Matija Franklin",
                "发布日期": "2022-10-06",
                "摘要": "  This article aims to provide a theoretical account and corresponding paradigm\nfor analysing how explainable artificial intelligence (XAI) influences people's\nbehaviour and cognition. It uses insights from research on behaviour change.\nTwo notable frameworks for thinking about behaviour change techniques are\nnudges - aimed at influencing behaviour - and boosts - aimed at fostering\ncapability. It proposes that local and concept-based explanations are more\nadjacent to nudges, while global and counterfactual explanations are more\nadjacent to boosts. It outlines a method for measuring XAI influence and argues\nfor the benefits of understanding it for optimal, safe and ethical human-AI\ncollaboration.\n",
                "链接": "https://arxiv.org/abs/2210.02407"
            },
            {
                "文章ID": "84965",
                "标题": "Artificial intelligence and radiation protection. A game changer or an\n  update?",
                "作者": "CEPN  Sylvain Andresz, IRSN/PSN-RES/SNC/LN  A Zéphir, IRSN/PSN-RES/SNC/LN  Jeremy Bez, SPRA  Maxime Karst, SPRA  J. Danieli",
                "发布日期": "2023-06-13",
                "摘要": "  Artificial intelligence (AI) is regarded as one of the most disruptive\ntechnology of the century and with countless applications. What does it mean\nfor radiation protection? This article describes the fundamentals of machine\nlearning (ML) based methods and presents the inaugural applications in\ndifferent fields of radiation protection. It is foreseen that the usage of AI\nwill increase in radiation protection. Consequently, this article explores some\nof the benefits and also the potential barriers and questions, including\nethical ones, that can come out. The article proposes that collaboration\nbetween radiation protection professionals and data scientist experts can\naccelerate and guide the development of the algorithms for effective scientific\nand technological outcomes.\n",
                "链接": "https://arxiv.org/abs/2306.06148"
            },
            {
                "文章ID": "64432",
                "标题": "Combining Generative Artificial Intelligence (AI) and the Internet:\n  Heading towards Evolution or Degradation?",
                "作者": " Gonzalo Martínez,  Lauren Watson,  Pedro Reviriego,  José Alberto Hernández,  Marc Juarez,  Rik Sarkar",
                "发布日期": "2023-03-03",
                "摘要": "  In the span of a few months, generative Artificial Intelligence (AI) tools\nthat can generate realistic images or text have taken the Internet by storm,\nmaking them one of the technologies with fastest adoption ever. Some of these\ngenerative AI tools such as DALL-E, MidJourney, or ChatGPT have gained wide\npublic notoriety. Interestingly, these tools are possible because of the\nmassive amount of data (text and images) available on the Internet. The tools\nare trained on massive data sets that are scraped from Internet sites. And now,\nthese generative AI tools are creating massive amounts of new data that are\nbeing fed into the Internet. Therefore, future versions of generative AI tools\nwill be trained with Internet data that is a mix of original and AI-generated\ndata. As time goes on, a mixture of original data and data generated by\ndifferent versions of AI tools will populate the Internet. This raises a few\nintriguing questions: how will future versions of generative AI tools behave\nwhen trained on a mixture of real and AI generated data? Will they evolve with\nthe new data sets or degenerate? Will evolution introduce biases in subsequent\ngenerations of generative AI tools? In this document, we explore these\nquestions and report some very initial simulation results using a simple\nimage-generation AI tool. These results suggest that the quality of the\ngenerated images degrades as more AI-generated data is used for training thus\nsuggesting that generative AI may degenerate. Although these results are\npreliminary and cannot be generalised without further study, they serve to\nillustrate the potential issues of the interaction between generative AI and\nthe Internet.\n",
                "链接": "https://arxiv.org/abs/2303.01255"
            },
            {
                "文章ID": "11176",
                "标题": "4D-OR: Semantic Scene Graphs for OR Domain Modeling",
                "作者": " Ege Özsoy,  Evin Pınar Örnek,  Ulrich Eck,  Tobias Czempiel,  Federico Tombari,  Nassir Navab",
                "发布日期": "2022-03-23",
                "摘要": "  Surgical procedures are conducted in highly complex operating rooms (OR),\ncomprising different actors, devices, and interactions. To date, only medically\ntrained human experts are capable of understanding all the links and\ninteractions in such a demanding environment. This paper aims to bring the\ncommunity one step closer to automated, holistic and semantic understanding and\nmodeling of OR domain. Towards this goal, for the first time, we propose using\nsemantic scene graphs (SSG) to describe and summarize the surgical scene. The\nnodes of the scene graphs represent different actors and objects in the room,\nsuch as medical staff, patients, and medical equipment, whereas edges are the\nrelationships between them. To validate the possibilities of the proposed\nrepresentation, we create the first publicly available 4D surgical SSG dataset,\n4D-OR, containing ten simulated total knee replacement surgeries recorded with\nsix RGB-D sensors in a realistic OR simulation center. 4D-OR includes 6734\nframes and is richly annotated with SSGs, human and object poses, and clinical\nroles. We propose an end-to-end neural network-based SSG generation pipeline,\nwith a rate of success of 0.75 macro F1, indeed being able to infer semantic\nreasoning in the OR. We further demonstrate the representation power of our\nscene graphs by using it for the problem of clinical role prediction, where we\nachieve 0.85 macro F1. The code and dataset will be made available upon\nacceptance.\n",
                "链接": "https://arxiv.org/abs/2203.11937"
            },
            {
                "文章ID": "84278",
                "标题": "Multilingual Clinical NER: Translation or Cross-lingual Transfer?",
                "作者": " Xavier Fontaine,  Félix Gaschi,  Parisa Rastin,  Yannick Toussaint",
                "发布日期": "2023-06-08",
                "摘要": "  Natural language tasks like Named Entity Recognition (NER) in the clinical\ndomain on non-English texts can be very time-consuming and expensive due to the\nlack of annotated data. Cross-lingual transfer (CLT) is a way to circumvent\nthis issue thanks to the ability of multilingual large language models to be\nfine-tuned on a specific task in one language and to provide high accuracy for\nthe same task in another language. However, other methods leveraging\ntranslation models can be used to perform NER without annotated data in the\ntarget language, by either translating the training set or test set. This paper\ncompares cross-lingual transfer with these two alternative methods, to perform\nclinical NER in French and in German without any training data in those\nlanguages. To this end, we release MedNERF a medical NER test set extracted\nfrom French drug prescriptions and annotated with the same guidelines as an\nEnglish dataset. Through extensive experiments on this dataset and on a German\nmedical dataset (Frei and Kramer, 2021), we show that translation-based methods\ncan achieve similar performance to CLT but require more care in their design.\nAnd while they can take advantage of monolingual clinical language models,\nthose do not guarantee better results than large general-purpose multilingual\nmodels, whether with cross-lingual transfer or translation.\n",
                "链接": "https://arxiv.org/abs/2306.04384"
            },
            {
                "文章ID": "81365",
                "标题": "Moral Machine or Tyranny of the Majority?",
                "作者": " Michael Feffer,  Hoda Heidari,  Zachary C. Lipton",
                "发布日期": "2023-05-30",
                "摘要": "  With Artificial Intelligence systems increasingly applied in consequential\ndomains, researchers have begun to ask how these systems ought to act in\nethically charged situations where even humans lack consensus. In the Moral\nMachine project, researchers crowdsourced answers to \"Trolley Problems\"\nconcerning autonomous vehicles. Subsequently, Noothigattu et al. (2018)\nproposed inferring linear functions that approximate each individual's\npreferences and aggregating these linear models by averaging parameters across\nthe population. In this paper, we examine this averaging mechanism, focusing on\nfairness concerns in the presence of strategic effects. We investigate a simple\nsetting where the population consists of two groups, with the minority\nconstituting an {\\alpha} < 0.5 share of the population. To simplify the\nanalysis, we consider the extreme case in which within-group preferences are\nhomogeneous. Focusing on the fraction of contested cases where the minority\ngroup prevails, we make the following observations: (a) even when all parties\nreport their preferences truthfully, the fraction of disputes where the\nminority prevails is less than proportionate in {\\alpha}; (b) the degree of\nsub-proportionality grows more severe as the level of disagreement between the\ngroups increases; (c) when parties report preferences strategically, pure\nstrategy equilibria do not always exist; and (d) whenever a pure strategy\nequilibrium exists, the majority group prevails 100% of the time. These\nfindings raise concerns about stability and fairness of preference vector\naveraging as a mechanism for aggregating diverging voices. Finally, we discuss\nalternatives, including randomized dictatorship and median-based mechanisms.\n",
                "链接": "https://arxiv.org/abs/2305.17319"
            },
            {
                "文章ID": "64320",
                "标题": "Helpful, Misleading or Confusing: How Humans Perceive Fundamental\n  Building Blocks of Artificial Intelligence Explanations",
                "作者": " Edward Small,  Yueqing Xuan,  Danula Hettiachchi,  Kacper Sokol",
                "发布日期": "2023-04-18",
                "摘要": "  Explainable artificial intelligence techniques are developed at breakneck\nspeed, but suitable evaluation approaches lag behind. With explainers becoming\nincreasingly complex and a lack of consensus on how to assess their utility, it\nis challenging to judge the benefit and effectiveness of different\nexplanations. To address this gap, we take a step back from sophisticated\npredictive algorithms and instead look into explainability of simple\ndecision-making models. In this setting, we aim to assess how people perceive\ncomprehensibility of their different representations such as mathematical\nformulation, graphical representation and textual summarisation (of varying\ncomplexity and scope). This allows us to capture how diverse stakeholders --\nengineers, researchers, consumers, regulators and the like -- judge\nintelligibility of fundamental concepts that more elaborate artificial\nintelligence explanations are built from. This position paper charts our\napproach to establishing appropriate evaluation methodology as well as a\nconceptual and practical framework to facilitate setting up and executing\nrelevant user studies.\n",
                "链接": "https://arxiv.org/abs/2303.00934"
            },
            {
                "文章ID": "17416",
                "标题": "Jam or Cream First? Modeling Ambiguity in Neural Machine Translation\n  with SCONES",
                "作者": " Felix Stahlberg,  Shankar Kumar",
                "发布日期": "2022-05-03",
                "摘要": "  The softmax layer in neural machine translation is designed to model the\ndistribution over mutually exclusive tokens. Machine translation, however, is\nintrinsically uncertain: the same source sentence can have multiple\nsemantically equivalent translations. Therefore, we propose to replace the\nsoftmax activation with a multi-label classification layer that can model\nambiguity more effectively. We call our loss function Single-label Contrastive\nObjective for Non-Exclusive Sequences (SCONES). We show that the multi-label\noutput layer can still be trained on single reference training data using the\nSCONES loss function. SCONES yields consistent BLEU score gains across six\ntranslation directions, particularly for medium-resource language pairs and\nsmall beam sizes. By using smaller beam sizes we can speed up inference by a\nfactor of 3.9x and still match or improve the BLEU score obtained using\nsoftmax. Furthermore, we demonstrate that SCONES can be used to train NMT\nmodels that assign the highest probability to adequate translations, thus\nmitigating the \"beam search curse\". Additional experiments on synthetic\nlanguage pairs with varying levels of uncertainty suggest that the improvements\nfrom SCONES can be attributed to better handling of ambiguity.\n",
                "链接": "https://arxiv.org/abs/2205.00704"
            },
            {
                "文章ID": "85504",
                "标题": "Modality Adaption or Regularization? A Case Study on End-to-End Speech\n  Translation",
                "作者": " Yuchen Han,  Chen Xu,  Tong Xiao,  Jingbo Zhu",
                "发布日期": "2023-06-14",
                "摘要": "  Pre-training and fine-tuning is a paradigm for alleviating the data scarcity\nproblem in end-to-end speech translation (E2E ST). The commonplace \"modality\ngap\" between speech and text data often leads to inconsistent inputs between\npre-training and fine-tuning. However, we observe that this gap occurs in the\nearly stages of fine-tuning, but does not have a major impact on the final\nperformance. On the other hand, we find that there has another gap, which we\ncall the \"capacity gap\": high resource tasks (such as ASR and MT) always\nrequire a large model to fit, when the model is reused for a low resource task\n(E2E ST), it will get a sub-optimal performance due to the over-fitting. In a\ncase study, we find that the regularization plays a more important role than\nthe well-designed modality adaption method, which achieves 29.0 for en-de and\n40.3 for en-fr on the MuST-C dataset. Code and models are available at\nhttps://github.com/hannlp/TAB.\n",
                "链接": "https://arxiv.org/abs/2306.07650"
            },
            {
                "文章ID": "44611",
                "标题": "Composition, Attention, or Both?",
                "作者": " Ryo Yoshida,  Yohei Oseki",
                "发布日期": "2023-05-12",
                "摘要": "  In this paper, we propose a novel architecture called Composition Attention\nGrammars (CAGs) that recursively compose subtrees into a single vector\nrepresentation with a composition function, and selectively attend to previous\nstructural information with a self-attention mechanism. We investigate whether\nthese components -- the composition function and the self-attention mechanism\n-- can both induce human-like syntactic generalization. Specifically, we train\nlanguage models (LMs) with and without these two components with the model\nsizes carefully controlled, and evaluate their syntactic generalization\nperformance against six test circuits on the SyntaxGym benchmark. The results\ndemonstrated that the composition function and the self-attention mechanism\nboth play an important role to make LMs more human-like, and closer inspection\nof linguistic phenomenon implied that the composition function allowed\nsyntactic features, but not semantic features, to percolate into subtree\nrepresentations.\n",
                "链接": "https://arxiv.org/abs/2210.12958"
            }
        ]
    },
    {
        "question": {
            "question": "查找中文ner常用的数据集论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "56677",
                "标题": "User-Centered Security in Natural Language Processing",
                "作者": " Chris Emmery",
                "发布日期": "2023-01-12",
                "摘要": "  This dissertation proposes a framework of user-centered security in Natural\nLanguage Processing (NLP), and demonstrates how it can improve the\naccessibility of related research. Accordingly, it focuses on two security\ndomains within NLP with great public interest. First, that of author profiling,\nwhich can be employed to compromise online privacy through invasive inferences.\nWithout access and detailed insight into these models' predictions, there is no\nreasonable heuristic by which Internet users might defend themselves from such\ninferences. Secondly, that of cyberbullying detection, which by default\npresupposes a centralized implementation; i.e., content moderation across\nsocial platforms. As access to appropriate data is restricted, and the nature\nof the task rapidly evolves (both through lexical variation, and cultural\nshifts), the effectiveness of its classifiers is greatly diminished and thereby\noften misrepresented.\n  Under the proposed framework, we predominantly investigate the use of\nadversarial attacks on language; i.e., changing a given input (generating\nadversarial samples) such that a given model does not function as intended.\nThese attacks form a common thread between our user-centered security problems;\nthey are highly relevant for privacy-preserving obfuscation methods against\nauthor profiling, and adversarial samples might also prove useful to assess the\ninfluence of lexical variation and augmentation on cyberbullying detection.\n",
                "链接": "https://arxiv.org/abs/2301.04230"
            },
            {
                "文章ID": "72764",
                "标题": "Thorny Roses: Investigating the Dual Use Dilemma in Natural Language\n  Processing",
                "作者": " Lucie-Aimée Kaffee,  Arnav Arora,  Zeerak Talat,  Isabelle Augenstein",
                "发布日期": "2023-10-31",
                "摘要": "  Dual use, the intentional, harmful reuse of technology and scientific\nartefacts, is a problem yet to be well-defined within the context of Natural\nLanguage Processing (NLP). However, as NLP technologies continue to advance and\nbecome increasingly widespread in society, their inner workings have become\nincreasingly opaque. Therefore, understanding dual use concerns and potential\nways of limiting them is critical to minimising the potential harms of research\nand development. In this paper, we conduct a survey of NLP researchers and\npractitioners to understand the depth and their perspective of the problem as\nwell as to assess existing available support. Based on the results of our\nsurvey, we offer a definition of dual use that is tailored to the needs of the\nNLP community. The survey revealed that a majority of researchers are concerned\nabout the potential dual use of their research but only take limited action\ntoward it. In light of the survey results, we discuss the current state and\npotential means for mitigating dual use in NLP and propose a checklist that can\nbe integrated into existing conference ethics-frameworks, e.g., the ACL ethics\nchecklist.\n",
                "链接": "https://arxiv.org/abs/2304.08315"
            },
            {
                "文章ID": "63180",
                "标题": "Natural Language Processing in the Legal Domain",
                "作者": " Daniel Martin Katz,  Dirk Hartung,  Lauritz Gerlach,  Abhik Jana, II Michael J. Bommarito",
                "发布日期": "2023-02-24",
                "摘要": "  In this paper, we summarize the current state of the field of NLP & Law with\na specific focus on recent technical and substantive developments. To support\nour analysis, we construct and analyze a nearly complete corpus of more than\nsix hundred NLP & Law related papers published over the past decade. Our\nanalysis highlights several major trends. Namely, we document an increasing\nnumber of papers written, tasks undertaken, and languages covered over the\ncourse of the past decade. We observe an increase in the sophistication of the\nmethods which researchers deployed in this applied context. Slowly but surely,\nLegal NLP is beginning to match not only the methodological sophistication of\ngeneral NLP but also the professional standards of data availability and code\nreproducibility observed within the broader scientific community. We believe\nall of these trends bode well for the future of the field, but many questions\nin both the academic and commercial sphere still remain open.\n",
                "链接": "https://arxiv.org/abs/2302.12039"
            },
            {
                "文章ID": "76320",
                "标题": "Putting Natural in Natural Language Processing",
                "作者": " Grzegorz Chrupała",
                "发布日期": "2023-05-24",
                "摘要": "  Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n",
                "链接": "https://arxiv.org/abs/2305.04572"
            },
            {
                "文章ID": "124014",
                "标题": "CORECODE: A Common Sense Annotated Dialogue Dataset with Benchmark Tasks\n  for Chinese Large Language Models",
                "作者": " Dan Shi,  Chaobin You,  Jiantao Huang,  Taihao Li,  Deyi Xiong",
                "发布日期": "2023-12-21",
                "摘要": "  As an indispensable ingredient of intelligence, commonsense reasoning is\ncrucial for large language models (LLMs) in real-world scenarios. In this\npaper, we propose CORECODE, a dataset that contains abundant commonsense\nknowledge manually annotated on dyadic dialogues, to evaluate the commonsense\nreasoning and commonsense conflict detection capabilities of Chinese LLMs. We\ncategorize commonsense knowledge in everyday conversations into three\ndimensions: entity, event, and social interaction. For easy and consistent\nannotation, we standardize the form of commonsense knowledge annotation in\nopen-domain dialogues as \"domain: slot = value\". A total of 9 domains and 37\nslots are defined to capture diverse commonsense knowledge. With these\npre-defined domains and slots, we collect 76,787 commonsense knowledge\nannotations from 19,700 dialogues through crowdsourcing. To evaluate and\nenhance the commonsense reasoning capability for LLMs on the curated dataset,\nwe establish a series of dialogue-level reasoning and detection tasks,\nincluding commonsense knowledge filling, commonsense knowledge generation,\ncommonsense conflict phrase detection, domain identification, slot\nidentification, and event causal inference. A wide variety of existing\nopen-source Chinese LLMs are evaluated with these tasks on our dataset.\nExperimental results demonstrate that these models are not competent to predict\nCORECODE's plentiful reasoning content, and even ChatGPT could only achieve\n0.275 and 0.084 accuracy on the domain identification and slot identification\ntasks under the zero-shot setting. We release the data and codes of CORECODE at\nhttps://github.com/danshi777/CORECODE to promote commonsense reasoning\nevaluation and study of LLMs in the context of daily conversations.\n",
                "链接": "https://arxiv.org/abs/2312.12853"
            },
            {
                "文章ID": "37115",
                "标题": "The Role of Explanatory Value in Natural Language Processing",
                "作者": " Kees van Deemter",
                "发布日期": "2022-09-14",
                "摘要": "  A key aim of science is explanation, yet the idea of explaining language\nphenomena has taken a backseat in mainstream Natural Language Processing (NLP)\nand many other areas of Artificial Intelligence. I argue that explanation of\nlinguistic behaviour should be a main goal of NLP, and that this is not the\nsame as making NLP models explainable. To illustrate these ideas, some recent\nmodels of human language production are compared with each other. I conclude by\nasking what it would mean for NLP research and institutional policies if our\ncommunity took explanatory value seriously, while heeding some possible\npitfalls.\n",
                "链接": "https://arxiv.org/abs/2209.06169"
            },
            {
                "文章ID": "42672",
                "标题": "The State of Profanity Obfuscation in Natural Language Processing",
                "作者": " Debora Nozza,  Dirk Hovy",
                "发布日期": "2022-10-17",
                "摘要": "  Work on hate speech has made the consideration of rude and harmful examples\nin scientific publications inevitable. This raises various problems, such as\nwhether or not to obscure profanities. While science must accurately disclose\nwhat it does, the unwarranted spread of hate speech is harmful to readers, and\nincreases its internet frequency. While maintaining publications' professional\nappearance, obfuscating profanities makes it challenging to evaluate the\ncontent, especially for non-native speakers. Surveying 150 ACL papers, we\ndiscovered that obfuscation is usually employed for English but not other\nlanguages, and even so quite uneven. We discuss the problems with obfuscation\nand suggest a multilingual community resource called PrOf that has a Python\nmodule to standardize profanity obfuscation processes. We believe PrOf can help\nscientific publication policies to make hate speech work accessible and\ncomparable, irrespective of language.\n",
                "链接": "https://arxiv.org/abs/2210.07595"
            },
            {
                "文章ID": "33704",
                "标题": "Differential Privacy in Natural Language Processing: The Story So Far",
                "作者": " Oleksandra Klymenko,  Stephen Meisenbacher,  Florian Matthes",
                "发布日期": "2022-08-18",
                "摘要": "  As the tide of Big Data continues to influence the landscape of Natural\nLanguage Processing (NLP), the utilization of modern NLP methods has grounded\nitself in this data, in order to tackle a variety of text-based tasks. These\nmethods without a doubt can include private or otherwise personally\nidentifiable information. As such, the question of privacy in NLP has gained\nfervor in recent years, coinciding with the development of new\nPrivacy-Enhancing Technologies (PETs). Among these PETs, Differential Privacy\nboasts several desirable qualities in the conversation surrounding data\nprivacy. Naturally, the question becomes whether Differential Privacy is\napplicable in the largely unstructured realm of NLP. This topic has sparked\nnovel research, which is unified in one basic goal: how can one adapt\nDifferential Privacy to NLP methods? This paper aims to summarize the\nvulnerabilities addressed by Differential Privacy, the current thinking, and\nabove all, the crucial next steps that must be considered.\n",
                "链接": "https://arxiv.org/abs/2208.08140"
            },
            {
                "文章ID": "72771",
                "标题": "Use of social media and Natural Language Processing (NLP) in natural\n  hazard research",
                "作者": " José Augusto Proença Maia Devienne",
                "发布日期": "2023-04-18",
                "摘要": "  Twitter is a microblogging service for sending short, public text messages\n(tweets) that has recently received more attention in scientific comunity. In\nthe works of Sasaki et al. (2010) and Earle et al., (2011) the authors explored\nthe real-time interaction on Twitter for detecting natural hazards (e.g.,\nearthquakes, typhoons) baed on users' tweets. An inherent challenge for such an\napplication is the natural language processing (NLP), which basically consists\nin converting the words in number (vectors and tensors) in order to\n(mathematically/ computationally) make predictions and classifications.\nRecently advanced computational tools have been made available for dealing with\ntext computationally. In this report we implement a NLP machine learning with\nTensorFlow, an end-to-end open source plataform for machine learning\napplications, to process and classify evenct based on files containing only\ntext.\n",
                "链接": "https://arxiv.org/abs/2304.08341"
            },
            {
                "文章ID": "85699",
                "标题": "Operationalising Representation in Natural Language Processing",
                "作者": " Jacqueline Harding",
                "发布日期": "2023-11-21",
                "摘要": "  Despite its centrality in the philosophy of cognitive science, there has been\nlittle prior philosophical work engaging with the notion of representation in\ncontemporary NLP practice. This paper attempts to fill that lacuna: drawing on\nideas from cognitive science, I introduce a framework for evaluating the\nrepresentational claims made about components of neural NLP models, proposing\nthree criteria with which to evaluate whether a component of a model represents\na property and operationalising these criteria using probing classifiers, a\npopular analysis technique in NLP (and deep learning more broadly).\n  The project of operationalising a philosophically-informed notion of\nrepresentation should be of interest to both philosophers of science and NLP\npractitioners. It affords philosophers a novel testing-ground for claims about\nthe nature of representation, and helps NLPers organise the large literature on\nprobing experiments, suggesting novel avenues for empirical research.\n",
                "链接": "https://arxiv.org/abs/2306.08193"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下最近用反事实做数据增强的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "86805",
                "标题": "Towards Characterizing Domain Counterfactuals For Invertible Latent\n  Causal Models",
                "作者": " Zeyu Zhou,  Ruqi Bai,  Sean Kulinski,  Murat Kocaoglu,  David I. Inouye",
                "发布日期": "2023-11-16",
                "摘要": "  Answering counterfactual queries has many important applications such as\nknowledge discovery and explainability, but is challenging when causal\nvariables are unobserved and we only see a projection onto an observation\nspace, for instance, image pixels. One approach is to recover the latent\nStructural Causal Model (SCM), but this typically needs unrealistic\nassumptions, such as linearity of the causal mechanisms. Another approach is to\nuse na\\\"ive ML approximations, such as generative models, to generate\ncounterfactual samples; however, these lack guarantees of accuracy. In this\nwork, we strive to strike a balance between practicality and theoretical\nguarantees by focusing on a specific type of causal query called domain\ncounterfactuals, which hypothesizes what a sample would have looked like if it\nhad been generated in a different domain (or environment). Concretely, by only\nassuming invertibility, sparse domain interventions and access to observational\ndata from different domains, we aim to improve domain counterfactual estimation\nboth theoretically and practically with less restrictive assumptions. We define\ndomain counterfactually equivalent models and prove necessary and sufficient\nproperties for equivalent models that provide a tight characterization of the\ndomain counterfactual equivalence classes. Building upon this result, we prove\nthat every equivalence class contains a model where all intervened variables\nare at the end when topologically sorted by the causal DAG. This surprising\nresult suggests that a model design that only allows intervention in the last\n$k$ latent variables may improve model estimation for counterfactuals. We then\ntest this model design on extensive simulated and image-based experiments which\nshow the sparse canonical model indeed improves counterfactual estimation over\nbaseline non-sparse models.\n",
                "链接": "https://arxiv.org/abs/2306.11281"
            },
            {
                "文章ID": "54607",
                "标题": "DISCO: Distilling Counterfactuals with Large Language Models",
                "作者": " Zeming Chen,  Qiyue Gao,  Antoine Bosselut,  Ashish Sabharwal,  Kyle Richardson",
                "发布日期": "2023-06-07",
                "摘要": "  Models trained with counterfactually augmented data learn representations of\nthe causal structure of tasks, enabling robust generalization. However,\nhigh-quality counterfactual data is scarce for most tasks and not easily\ngenerated at scale. When crowdsourced, such data is typically limited in scale\nand diversity; when generated using supervised methods, it is computationally\nexpensive to extend to new counterfactual dimensions. In this work, we\nintroduce DISCO (DIStilled COunterfactual Data), a new method for automatically\ngenerating high quality counterfactual data at scale. DISCO engineers prompts\nto generate phrasal perturbations with a large general language model. Then, a\ntask-specific teacher model filters these generations to distill high-quality\ncounterfactual data. While task-agnostic, we apply our pipeline to the task of\nnatural language inference (NLI) and find that on challenging evaluations such\nas the NLI stress test, comparatively smaller student models trained with DISCO\ngenerated counterfactuals are more robust (6% absolute) and generalize better\nacross distributions (2%) compared to models trained without data augmentation.\nFurthermore, DISCO augmented models are 10% more consistent between\ncounterfactual pairs on three evaluation sets, demonstrating that DISCO\naugmentation enables models to more reliably learn causal representations. Our\nrepository is available at: https://github.com/eric11eca/disco\n",
                "链接": "https://arxiv.org/abs/2212.10534"
            },
            {
                "文章ID": "102871",
                "标题": "Using fine-tuning and min lookahead beam search to improve Whisper",
                "作者": " Andrea Do,  Oscar Brown,  Zhengjie Wang,  Nikhil Mathew,  Zixin Liu,  Jawwad Ahmed,  Cheng Yu",
                "发布日期": "2023-09-20",
                "摘要": "  The performance of Whisper in low-resource languages is still far from\nperfect. In addition to a lack of training data on low-resource languages, we\nidentify some limitations in the beam search algorithm used in Whisper. To\naddress these issues, we fine-tune Whisper on additional data and propose an\nimproved decoding algorithm. On the Vietnamese language, fine-tuning\nWhisper-Tiny with LoRA leads to an improvement of 38.49 in WER over the\nzero-shot Whisper-Tiny setting which is a further reduction of 1.45 compared to\nfull-parameter fine-tuning. Additionally, by using Filter-Ends and Min\nLookahead decoding algorithms, the WER reduces by 2.26 on average over a range\nof languages compared to standard beam search. These results generalise to\nlarger Whisper model sizes. We also prove a theorem that Min Lookahead\noutperforms the standard beam search algorithm used in Whisper.\n",
                "链接": "https://arxiv.org/abs/2309.10299"
            },
            {
                "文章ID": "93935",
                "标题": "Lexically-Accelerated Dense Retrieval",
                "作者": " Hrishikesh Kulkarni,  Sean MacAvaney,  Nazli Goharian,  Ophir Frieder",
                "发布日期": "2023-08-01",
                "摘要": "  Retrieval approaches that score documents based on learned dense vectors\n(i.e., dense retrieval) rather than lexical signals (i.e., conventional\nretrieval) are increasingly popular. Their ability to identify related\ndocuments that do not necessarily contain the same terms as those appearing in\nthe user's query (thereby improving recall) is one of their key advantages.\nHowever, to actually achieve these gains, dense retrieval approaches typically\nrequire an exhaustive search over the document collection, making them\nconsiderably more expensive at query-time than conventional lexical approaches.\nSeveral techniques aim to reduce this computational overhead by approximating\nthe results of a full dense retriever. Although these approaches reasonably\napproximate the top results, they suffer in terms of recall -- one of the key\nadvantages of dense retrieval. We introduce 'LADR' (Lexically-Accelerated Dense\nRetrieval), a simple-yet-effective approach that improves the efficiency of\nexisting dense retrieval models without compromising on retrieval\neffectiveness. LADR uses lexical retrieval techniques to seed a dense retrieval\nexploration that uses a document proximity graph. We explore two variants of\nLADR: a proactive approach that expands the search space to the neighbors of\nall seed documents, and an adaptive approach that selectively searches the\ndocuments with the highest estimated relevance in an iterative fashion. Through\nextensive experiments across a variety of dense retrieval models, we find that\nLADR establishes a new dense retrieval effectiveness-efficiency Pareto frontier\namong approximate k nearest neighbor techniques. Further, we find that when\ntuned to take around 8ms per query in retrieval latency on our hardware, LADR\nconsistently achieves both precision and recall that are on par with an\nexhaustive search on standard benchmarks.\n",
                "链接": "https://arxiv.org/abs/2307.16779"
            },
            {
                "文章ID": "82122",
                "标题": "Event-Centric Query Expansion in Web Search",
                "作者": " Yanan Zhang,  Weijie Cui,  Yangfan Zhang,  Xiaoling Bai,  Zhe Zhang,  Jin Ma,  Xiang Chen,  Tianhua Zhou",
                "发布日期": "2023-05-31",
                "摘要": "  In search engines, query expansion (QE) is a crucial technique to improve\nsearch experience. Previous studies often rely on long-term search log mining,\nwhich leads to slow updates and is sub-optimal for time-sensitive news\nsearches. In this work, we present Event-Centric Query Expansion (EQE), a novel\nQE system that addresses these issues by mining the best expansion from a\nsignificant amount of potential events rapidly and accurately. This system\nconsists of four stages, i.e., event collection, event reformulation, semantic\nretrieval and online ranking. Specifically, we first collect and filter news\nheadlines from websites. Then we propose a generation model that incorporates\ncontrastive learning and prompt-tuning techniques to reformulate these\nheadlines to concise candidates. Additionally, we fine-tune a dual-tower\nsemantic model to function as an encoder for event retrieval and explore a\ntwo-stage contrastive training approach to enhance the accuracy of event\nretrieval. Finally, we rank the retrieved events and select the optimal one as\nQE, which is then used to improve the retrieval of event-related documents.\nThrough offline analysis and online A/B testing, we observe that the EQE system\nsignificantly improves many metrics compared to the baseline. The system has\nbeen deployed in Tencent QQ Browser Search and served hundreds of millions of\nusers. The dataset and baseline codes are available at\nhttps://open-event-hub.github.io/eqe .\n",
                "链接": "https://arxiv.org/abs/2305.19019"
            },
            {
                "文章ID": "70162",
                "标题": "Improving extreme weather events detection with light-weight neural\n  networks",
                "作者": "Plume Labs Stanford University  Romain Lacombe, Stanford University  Hannah Grossman, Stanford University  Lucas Hendren, Stanford University  David Lüdeke",
                "发布日期": "2023-04-04",
                "摘要": "  To advance automated detection of extreme weather events, which are\nincreasing in frequency and intensity with climate change, we explore\nmodifications to a novel light-weight Context Guided convolutional neural\nnetwork architecture trained for semantic segmentation of tropical cyclones and\natmospheric rivers in climate data. Our primary focus is on tropical cyclones,\nthe most destructive weather events, for which current models show limited\nperformance. We investigate feature engineering, data augmentation, learning\nrate modifications, alternative loss functions, and architectural changes. In\ncontrast to previous approaches optimizing for intersection over union, we\nspecifically seek to improve recall to penalize under-counting and prioritize\nidentification of tropical cyclones. We report success through the use of\nweighted loss functions to counter class imbalance for these rare events. We\nconclude with directions for future research on extreme weather events\ndetection, a crucial task for prediction, mitigation, and equitable adaptation\nto the impacts of climate change.\n",
                "链接": "https://arxiv.org/abs/2304.00176"
            },
            {
                "文章ID": "31015",
                "标题": "Using clarification questions to improve software developers' Web search",
                "作者": " Mia Mohammad Imran,  Kostadin Damevski",
                "发布日期": "2022-07-27",
                "摘要": "  Context: Recent research indicates that Web queries written by software\ndevelopers are not very successful in retrieving relevant results, performing\nmeasurably worse compared to general purpose Web queries. Most approaches up to\nthis point have addressed this problem with software engineering-specific\nautomated query reformulation techniques, which work without developer\ninvolvement but are limited by the content of the original query. In other\nwords, these techniques automatically improve the existing query but can not\ncontribute new, previously unmentioned, concepts.\n  Objective: In this paper, we propose a technique to guide software developers\nin manually improving their own Web search queries. We examine a conversational\napproach that follows unsuccessful queries with a clarification question aimed\nat eliciting additional query terms, thus providing to the developer a clear\ndimension along which the query could be improved.\n  Methods: We describe a set of clarification questions derived from a corpus\nof software developer queries and a neural approach to recommending them for a\nnewly issued query.\n  Results: Our evaluation indicates that the recommendation technique is\naccurate, predicting a valid clarification question 80% of the time and\noutperforms simple baselines, as well as, state-of-the-art Learning To Rank\n(LTR) baselines.\n  Conclusion: As shown in the experimental results, the described approach is\ncapable at recommending appropriate clarification questions to software\ndevelopers and considered useful by a sample of developers ranging from novices\nto experienced professionals.\n",
                "链接": "https://arxiv.org/abs/2207.12768"
            },
            {
                "文章ID": "33822",
                "标题": "Merchandise Recommendation for Retail Events with Word Embedding\n  Weighted Tf-idf and Dynamic Query Expansion",
                "作者": " Ted Tao Yuan,  Zezhong Zhang",
                "发布日期": "2022-08-19",
                "摘要": "  To recommend relevant merchandises for seasonal retail events, we rely on\nitem retrieval from marketplace inventory. With feedback to expand query scope,\nwe discuss keyword expansion candidate selection using word embedding\nsimilarity, and an enhanced tf-idf formula for expanded words in search\nranking.\n",
                "链接": "https://arxiv.org/abs/2208.08581"
            },
            {
                "文章ID": "79167",
                "标题": "ConQueR: Contextualized Query Reduction using Search Logs",
                "作者": " Hye-young Kim,  Minjin Choi,  Sunkyung Lee,  Eunseong Choi,  Young-In Song,  Jongwuk Lee",
                "发布日期": "2023-05-23",
                "摘要": "  Query reformulation is a key mechanism to alleviate the linguistic chasm of\nquery in ad-hoc retrieval. Among various solutions, query reduction effectively\nremoves extraneous terms and specifies concise user intent from long queries.\nHowever, it is challenging to capture hidden and diverse user intent. This\npaper proposes Contextualized Query Reduction (ConQueR) using a pre-trained\nlanguage model (PLM). Specifically, it reduces verbose queries with two\ndifferent views: core term extraction and sub-query selection. One extracts\ncore terms from an original query at the term level, and the other determines\nwhether a sub-query is a suitable reduction for the original query at the\nsequence level. Since they operate at different levels of granularity and\ncomplement each other, they are finally aggregated in an ensemble manner. We\nevaluate the reduction quality of ConQueR on real-world search logs collected\nfrom a commercial web search engine. It achieves up to 8.45% gains in exact\nmatch scores over the best competing model.\n",
                "链接": "https://arxiv.org/abs/2305.12662"
            },
            {
                "文章ID": "86280",
                "标题": "Smart Sentiment Analysis-based Search Engine Classification Intelligence",
                "作者": " Mike Nkongolo",
                "发布日期": "2023-06-19",
                "摘要": "  Search engines are widely used for finding information on the internet.\nHowever, there are limitations in the current search approach, such as\nproviding popular but not necessarily relevant results. This research addresses\nthe issue of polysemy in search results by implementing a search function that\ndetermines the sentimentality of the retrieved information. The study utilizes\na web crawler to collect data from the British Broadcasting Corporation (BBC)\nnews site, and the sentimentality of the news articles is determined using the\nSentistrength program. The results demonstrate that the proposed search\nfunction improves recall value while accurately retrieving nonpolysemous news.\nFurthermore, Sentistrength outperforms deep learning and clustering methods in\nclassifying search results. The methodology presented in this article can be\napplied to analyze the sentimentality and reputation of entities on the\ninternet.\n",
                "链接": "https://arxiv.org/abs/2306.09777"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用蒙特卡罗树搜索解决序列决策问题的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "54835",
                "标题": "Feature Acquisition using Monte Carlo Tree Search",
                "作者": " Sungsoo Lim,  Diego Klabjan,  Mark Shapiro",
                "发布日期": "2022-12-23",
                "摘要": "  Feature acquisition algorithms address the problem of acquiring informative\nfeatures while balancing the costs of acquisition to improve the learning\nperformances of ML models. Previous approaches have focused on calculating the\nexpected utility values of features to determine the acquisition sequences.\nOther approaches formulated the problem as a Markov Decision Process (MDP) and\napplied reinforcement learning based algorithms. In comparison to previous\napproaches, we focus on 1) formulating the feature acquisition problem as a MDP\nand applying Monte Carlo Tree Search, 2) calculating the intermediary rewards\nfor each acquisition step based on model improvements and acquisition costs and\n3) simultaneously optimizing model improvement and acquisition costs with\nmulti-objective Monte Carlo Tree Search. With Proximal Policy Optimization and\nDeep Q-Network algorithms as benchmark, we show the effectiveness of our\nproposed approach with experimental study.\n",
                "链接": "https://arxiv.org/abs/2212.11360"
            },
            {
                "文章ID": "23592",
                "标题": "Combining Monte-Carlo Tree Search with Proof-Number Search",
                "作者": " Elliot Doe,  Mark H. M. Winands,  Dennis J. N. J. Soemers,  Cameron Browne",
                "发布日期": "2022-06-09",
                "摘要": "  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
                "链接": "https://arxiv.org/abs/2206.03965"
            },
            {
                "文章ID": "3914",
                "标题": "On Monte Carlo Tree Search for Weighted Vertex Coloring",
                "作者": " Cyril Grelier,  Olivier Goudet,  Jin-Kao Hao",
                "发布日期": "2022-04-08",
                "摘要": "  This work presents the first study of using the popular Monte Carlo Tree\nSearch (MCTS) method combined with dedicated heuristics for solving the\nWeighted Vertex Coloring Problem. Starting with the basic MCTS algorithm, we\ngradually introduce a number of algorithmic variants where MCTS is extended by\nvarious simulation strategies including greedy and local search heuristics. We\nconduct experiments on well-known benchmark instances to assess the value of\neach studied combination. We also provide empirical evidence to shed light on\nthe advantages and limits of each strategy.\n",
                "链接": "https://arxiv.org/abs/2202.01665"
            },
            {
                "文章ID": "53055",
                "标题": "Lookahead Pathology in Monte-Carlo Tree Search",
                "作者": " Khoi P. N. Nguyen,  Raghuram Ramanujan",
                "发布日期": "2022-12-13",
                "摘要": "  Monte-Carlo Tree Search (MCTS) is an adversarial search paradigm that first\nfound prominence with its success in the domain of computer Go. Early\ntheoretical work established the game-theoretic soundness and convergence\nbounds for Upper Confidence bounds applied to Trees (UCT), the most popular\ninstantiation of MCTS; however, there remain notable gaps in our understanding\nof how UCT behaves in practice. In this work, we address one such gap by\nconsidering the question of whether UCT can exhibit lookahead pathology -- a\nparadoxical phenomenon first observed in Minimax search where greater search\neffort leads to worse decision-making. We introduce a novel family of synthetic\ngames that offer rich modeling possibilities while remaining amenable to\nmathematical analysis. Our theoretical and experimental results suggest that\nUCT is indeed susceptible to pathological behavior in a range of games drawn\nfrom this family.\n",
                "链接": "https://arxiv.org/abs/2212.05208"
            },
            {
                "文章ID": "67092",
                "标题": "Proof Number Based Monte-Carlo Tree Search",
                "作者": " Jakub Kowalski,  Elliot Doe,  Mark H. M. Winands,  Daniel Górski,  Dennis J. N. J. Soemers",
                "发布日期": "2023-12-22",
                "摘要": "  This paper proposes a new game-search algorithm, PN-MCTS, which combines\nMonte-Carlo Tree Search (MCTS) and Proof-Number Search (PNS). These two\nalgorithms have been successfully applied for decision making in a range of\ndomains. We define three areas where the additional knowledge provided by the\nproof and disproof numbers gathered in MCTS trees might be used: final move\nselection, solving subtrees, and the UCB1 selection mechanism. We test all\npossible combinations on different time settings, playing against vanilla UCT\non several games: Lines of Action ($7$$\\times$$7$ and $8$$\\times$$8$ board\nsizes), MiniShogi, Knightthrough, and Awari. Furthermore, we extend this new\nalgorithm to properly address games with draws, like Awari, by adding an\nadditional layer of PNS on top of the MCTS tree. The experiments show that\nPN-MCTS confidently outperforms MCTS in all tested game domains, achieving win\nrates up to 96.2\\% for Lines of Action.\n",
                "链接": "https://arxiv.org/abs/2303.09449"
            },
            {
                "文章ID": "116381",
                "标题": "Graph Sparsifications using Neural Network Assisted Monte Carlo Tree\n  Search",
                "作者": " Alvin Chiu,  Mithun Ghosh,  Reyan Ahmed,  Kwang-Sung Jun,  Stephen Kobourov,  Michael T. Goodrich",
                "发布日期": "2023-11-20",
                "摘要": "  Graph neural networks have been successful for machine learning, as well as\nfor combinatorial and graph problems such as the Subgraph Isomorphism Problem\nand the Traveling Salesman Problem. We describe an approach for computing graph\nsparsifiers by combining a graph neural network and Monte Carlo Tree Search. We\nfirst train a graph neural network that takes as input a partial solution and\nproposes a new node to be added as output. This neural network is then used in\na Monte Carlo search to compute a sparsifier. The proposed method consistently\noutperforms several standard approximation algorithms on different types of\ngraphs and often finds the optimal solution.\n",
                "链接": "https://arxiv.org/abs/2311.10316"
            },
            {
                "文章ID": "102301",
                "标题": "Maneuver Decision-Making Through Proximal Policy Optimization And Monte\n  Carlo Tree Search",
                "作者": " Zhang Hong-Peng",
                "发布日期": "2023-09-19",
                "摘要": "  Maneuver decision-making can be regarded as a Markov decision process and can\nbe address by reinforcement learning. However, original reinforcement learning\nalgorithms can hardly solve the maneuvering decision-making problem. One reason\nis that agents use random actions in the early stages of training, which makes\nit difficult to get rewards and learn how to make effective decisions. To\naddress this issue, a method based on proximal policy optimization and Monte\nCarlo tree search is proposed. The method uses proximal policy optimization to\ntrain the agent, and regards the results of air combat as targets to train the\nvalue network. Then, based on the value network and the visit count of each\nnode, Monte Carlo tree search is used to find the actions with more expected\nreturns than random actions, which can improve the training performance. The\nablation studies and simulation experiments indicate that agents trained by the\nproposed method can make different decisions according to different states,\nwhich demonstrates that the method can solve the maneuvering decision problem\nthat the original reinforcement learning algorithm cannot solve.\n",
                "链接": "https://arxiv.org/abs/2309.08611"
            },
            {
                "文章ID": "107708",
                "标题": "Accelerating Monte Carlo Tree Search with Probability Tree State\n  Abstraction",
                "作者": " Yangqing Fu,  Ming Sun,  Buqing Nie,  Yue Gao",
                "发布日期": "2023-10-11",
                "摘要": "  Monte Carlo Tree Search (MCTS) algorithms such as AlphaGo and MuZero have\nachieved superhuman performance in many challenging tasks. However, the\ncomputational complexity of MCTS-based algorithms is influenced by the size of\nthe search space. To address this issue, we propose a novel probability tree\nstate abstraction (PTSA) algorithm to improve the search efficiency of MCTS. A\ngeneral tree state abstraction with path transitivity is defined. In addition,\nthe probability tree state abstraction is proposed for fewer mistakes during\nthe aggregation step. Furthermore, the theoretical guarantees of the\ntransitivity and aggregation error bound are justified. To evaluate the\neffectiveness of the PTSA algorithm, we integrate it with state-of-the-art\nMCTS-based algorithms, such as Sampled MuZero and Gumbel MuZero. Experimental\nresults on different tasks demonstrate that our method can accelerate the\ntraining process of state-of-the-art algorithms with 10%-45% search space\nreduction.\n",
                "链接": "https://arxiv.org/abs/2310.06513"
            },
            {
                "文章ID": "123470",
                "标题": "Monte Carlo Tree Search in the Presence of Transition Uncertainty",
                "作者": " Farnaz Kohankhaki,  Kiarash Aghakasiri,  Hongming Zhang,  Ting-Han Wei,  Chao Gao,  Martin Müller",
                "发布日期": "2023-12-19",
                "摘要": "  Monte Carlo Tree Search (MCTS) is an immensely popular search-based framework\nused for decision making. It is traditionally applied to domains where a\nperfect simulation model of the environment is available. We study and improve\nMCTS in the context where the environment model is given but imperfect. We show\nthat the discrepancy between the model and the actual environment can lead to\nsignificant performance degradation with standard MCTS. We therefore develop\nUncertainty Adapted MCTS (UA-MCTS), a more robust algorithm within the MCTS\nframework. We estimate the transition uncertainty in the given model, and\ndirect the search towards more certain transitions in the state space. We\nmodify all four MCTS phases to improve the search behavior by considering these\nestimates. We prove, in the corrupted bandit case, that adding uncertainty\ninformation to adapt UCB leads to tighter regret bound than standard UCB.\nEmpirically, we evaluate UA-MCTS and its individual components on the\ndeterministic domains from the MinAtar test suite. Our results demonstrate that\nUA-MCTS strongly improves MCTS in the presence of model transition errors.\n",
                "链接": "https://arxiv.org/abs/2312.11348"
            },
            {
                "文章ID": "73772",
                "标题": "Recomputing Solutions to Perturbed Multi-Commodity Pickup and Delivery\n  Vehicle Routing Problems using Monte Carlo Tree Search",
                "作者": " Mithun Goutham,  Stephanie Stockar",
                "发布日期": "2023-04-25",
                "摘要": "  The Multi-Commodity Pickup and Delivery Vehicle Routing Problem aims to\noptimize the pickup and delivery of multiple unique commodities using a fleet\nof several agents with limited payload capacities. This paper addresses the\nchallenge of quickly recomputing the solution to this NP-hard problem when\nthere are unexpected perturbations to the nominal task definitions, likely to\noccur under real-world operating conditions. The proposed method first\ndecomposes the nominal problem by constructing a search tree using Monte Carlo\nTree Search for task assignment, and uses a rapid heuristic for routing each\nagent. When changes to the problem are revealed, the nominal search tree is\nrapidly updated with new costs under the updated problem parameters, generating\nsolutions quicker and with a reduced optimality gap, as compared to recomputing\nthe solution as an entirely new problem. Computational experiments are\nconducted by varying the locations of the nominal problem and the payload\ncapacity of an agent to demonstrate the effectiveness of utilizing the nominal\nsearch tree to handle perturbations for real-time implementation.\n",
                "链接": "https://arxiv.org/abs/2304.11444"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下利用gpt4做评测指标优缺点的文章",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "91271",
                "标题": "The Potential and Pitfalls of using a Large Language Model such as\n  ChatGPT or GPT-4 as a Clinical Assistant",
                "作者": " Jingqing Zhang,  Kai Sun,  Akshay Jagadeesh,  Mahta Ghahfarokhi,  Deepa Gupta,  Ashok Gupta,  Vibhor Gupta,  Yike Guo",
                "发布日期": "2023-07-18",
                "摘要": "  Recent studies have demonstrated promising performance of ChatGPT and GPT-4\non several medical domain tasks. However, none have assessed its performance\nusing a large-scale real-world electronic health record database, nor have\nevaluated its utility in providing clinical diagnostic assistance for patients\nacross a full range of disease presentation. We performed two analyses using\nChatGPT and GPT-4, one to identify patients with specific medical diagnoses\nusing a real-world large electronic health record database and the other, in\nproviding diagnostic assistance to healthcare workers in the prospective\nevaluation of hypothetical patients. Our results show that GPT-4 across disease\nclassification tasks with chain of thought and few-shot prompting can achieve\nperformance as high as 96% F1 scores. For patient assessment, GPT-4 can\naccurately diagnose three out of four times. However, there were mentions of\nfactually incorrect statements, overlooking crucial medical findings,\nrecommendations for unnecessary investigations and overtreatment. These issues\ncoupled with privacy concerns, make these models currently inadequate for real\nworld clinical use. However, limited data and time needed for prompt\nengineering in comparison to configuration of conventional machine learning\nworkflows highlight their potential for scalability across healthcare\napplications.\n",
                "链接": "https://arxiv.org/abs/2307.08152"
            },
            {
                "文章ID": "123333",
                "标题": "The Pros and Cons of Adversarial Robustness",
                "作者": " Yacine Izza,  Joao Marques-Silva",
                "发布日期": "2023-12-19",
                "摘要": "  Robustness is widely regarded as a fundamental problem in the analysis of\nmachine learning (ML) models. Most often robustness equates with deciding the\nnon-existence of adversarial examples, where adversarial examples denote\nsituations where small changes on some inputs cause a change in the prediction.\nThe perceived importance of ML model robustness explains the continued progress\nobserved for most of the last decade. Whereas robustness is often assessed\nlocally, i.e. given some target point in feature space, robustness can also be\ndefined globally, i.e. where any point in feature space can be considered. The\nimportance of ML model robustness is illustrated for example by the existence\nof competitions evaluating the progress of robustness tools, namely in the case\nof neural networks (NNs) but also by efforts towards robustness certification.\nMore recently, robustness tools have also been used for computing rigorous\nexplanations of ML models. In contrast with the observed successes of\nrobustness, this paper uncovers some limitations with existing definitions of\nrobustness, both global and local, but also with efforts towards robustness\ncertification. The paper also investigates uses of adversarial examples besides\nthose related with robustness.\n",
                "链接": "https://arxiv.org/abs/2312.10911"
            },
            {
                "文章ID": "102940",
                "标题": "An Evaluation of GPT-4 on the ETHICS Dataset",
                "作者": " Sergey Rodionov,  Zarathustra Amadeus Goertzel,  Ben Goertzel",
                "发布日期": "2023-09-20",
                "摘要": "  This report summarizes a short study of the performance of GPT-4 on the\nETHICS dataset. The ETHICS dataset consists of five sub-datasets covering\ndifferent fields of ethics: Justice, Deontology, Virtue Ethics, Utilitarianism,\nand Commonsense Ethics. The moral judgments were curated so as to have a high\ndegree of agreement with the aim of representing shared human values rather\nthan moral dilemmas. GPT-4's performance is much better than that of previous\nmodels and suggests that learning to work with common human values is not the\nhard problem for AI ethics.\n",
                "链接": "https://arxiv.org/abs/2309.10492"
            },
            {
                "文章ID": "33038",
                "标题": "On the Pros and Cons of Momentum Encoder in Self-Supervised Visual\n  Representation Learning",
                "作者": " Trung Pham,  Chaoning Zhang,  Axi Niu,  Kang Zhang,  Chang D. Yoo",
                "发布日期": "2022-08-12",
                "摘要": "  Exponential Moving Average (EMA or momentum) is widely used in modern\nself-supervised learning (SSL) approaches, such as MoCo, for enhancing\nperformance. We demonstrate that such momentum can also be plugged into\nmomentum-free SSL frameworks, such as SimCLR, for a performance boost. Despite\nits wide use as a fundamental component in modern SSL frameworks, the benefit\ncaused by momentum is not well understood. We find that its success can be at\nleast partly attributed to the stability effect. In the first attempt, we\nanalyze how EMA affects each part of the encoder and reveal that the portion\nnear the encoder's input plays an insignificant role while the latter parts\nhave much more influence. By monitoring the gradient of the overall loss with\nrespect to the output of each block in the encoder, we observe that the final\nlayers tend to fluctuate much more than other layers during backpropagation,\ni.e. less stability. Interestingly, we show that using EMA to the final part of\nthe SSL encoder, i.e. projector, instead of the whole deep network encoder can\ngive comparable or preferable performance. Our proposed projector-only momentum\nhelps maintain the benefit of EMA but avoids the double forward computation.\n",
                "链接": "https://arxiv.org/abs/2208.05744"
            },
            {
                "文章ID": "102374",
                "标题": "GPT as a Baseline for Recommendation Explanation Texts",
                "作者": " Joyce Zhou,  Thorsten Joachims",
                "发布日期": "2023-09-19",
                "摘要": "  In this work, we establish a baseline potential for how modern\nmodel-generated text explanations of movie recommendations may help users, and\nexplore what different components of these text explanations that users like or\ndislike, especially in contrast to existing human movie reviews. We found that\nparticipants gave no significantly different rankings between movies, nor did\nthey give significantly different individual quality scores to reviews of\nmovies that they had never seen before. However, participants did mark reviews\nas significantly better when they were movies they had seen before. We also\nexplore specific aspects of movie review texts that participants marked as\nimportant for each quality. Overall, we establish that modern LLMs are a\npromising source of recommendation explanations, and we intend on further\nexploring personalizable text explanations in the future.\n",
                "链接": "https://arxiv.org/abs/2309.08817"
            },
            {
                "文章ID": "110350",
                "标题": "Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large\n  Language Models on Sequence to Sequence Tasks",
                "作者": " Andrea Sottana,  Bin Liang,  Kai Zou,  Zheng Yuan",
                "发布日期": "2023-10-24",
                "摘要": "  Large Language Models (LLMs) evaluation is a patchy and inconsistent\nlandscape, and it is becoming clear that the quality of automatic evaluation\nmetrics is not keeping up with the pace of development of generative models. We\naim to improve the understanding of current models' performance by providing a\npreliminary and hybrid evaluation on a range of open and closed-source\ngenerative LLMs on three NLP benchmarks: text summarisation, text\nsimplification and grammatical error correction (GEC), using both automatic and\nhuman evaluation. We also explore the potential of the recently released GPT-4\nto act as an evaluator. We find that ChatGPT consistently outperforms many\nother popular models according to human reviewers on the majority of metrics,\nwhile scoring much more poorly when using classic automatic evaluation metrics.\nWe also find that human reviewers rate the gold reference as much worse than\nthe best models' outputs, indicating the poor quality of many popular\nbenchmarks. Finally, we find that GPT-4 is capable of ranking models' outputs\nin a way which aligns reasonably closely to human judgement despite\ntask-specific variations, with a lower alignment in the GEC task.\n",
                "链接": "https://arxiv.org/abs/2310.13800"
            },
            {
                "文章ID": "48661",
                "标题": "Toward expanding the scope of radiology report summarization to multiple\n  anatomies and modalities",
                "作者": " Zhihong Chen,  Maya Varma,  Xiang Wan,  Curtis Langlotz,  Jean-Benoit Delbrouck",
                "发布日期": "2023-07-25",
                "摘要": "  Radiology report summarization (RRS) is a growing area of research. Given the\nFindings section of a radiology report, the goal is to generate a summary\n(called an Impression section) that highlights the key observations and\nconclusions of the radiology study. However, RRS currently faces essential\nlimitations.First, many prior studies conduct experiments on private datasets,\npreventing reproduction of results and fair comparisons across different\nsystems and solutions. Second, most prior approaches are evaluated solely on\nchest X-rays. To address these limitations, we propose a dataset (MIMIC-RRS)\ninvolving three new modalities and seven new anatomies based on the MIMIC-III\nand MIMIC-CXR datasets. We then conduct extensive experiments to evaluate the\nperformance of models both within and across modality-anatomy pairs in\nMIMIC-RRS. In addition, we evaluate their clinical efficacy via RadGraph, a\nfactual correctness metric.\n",
                "链接": "https://arxiv.org/abs/2211.08584"
            },
            {
                "文章ID": "124195",
                "标题": "Using GPT-4 Prompts to Determine Whether Articles Contain Functional\n  Evidence Supporting or Refuting Variant Pathogenicity",
                "作者": " Samuel J. Aronson,  Kalotina Machini,  Pranav Sriraman,  Jiyeon Shin,  Emma R. Henricks,  Charlotte Mailly,  Angie J. Nottage,  Michael Oates,  Matthew S. Lebo",
                "发布日期": "2023-12-22",
                "摘要": "  Purpose: To assess Generative Pre-trained Transformer version 4's (GPT-4)\nability to classify articles containing functional evidence relevant to\nassessments of variant pathogenicity.\n  Results: GPT-4 settings and prompts were trained on a set of 45 articles and\ngenetic variants. A final test set of 72 manually classified articles and\ngenetic variants were then processed using two prompts. The prompts asked GPT-4\nto supply all functional evidence present in an article for a variant or\nindicate that no functional evidence is present. For articles with having\nfunctional evidence, a second prompt asked GPT-4 to classify the evidence into\npathogenic, benign, intermediate, and inconclusive categories. The first prompt\nidentified articles with variant-level functional evidence with 87% sensitivity\nand 89% positive predictive value (PPV). Five of 26 articles with no functional\ndata were indicated as having functional evidence by GPT-4. For variants with\nfunctional assays present as determined by both manual review and GPT-4, the\nsensitivity and PPV of GPT-4 prompt concordance was: Pathogenic (92% sensitive\nand 73% PPV), Intermediate or Inconclusive (67% sensitive and 93% PPV), Benign\n(100% sensitive and 73% PPV).\n  Conclusion: The GPT-4 prompts detected the presence or absence of a\nfunctional assay with high sensitivity and PPV, and articles with unambiguous\nevidence supporting a benign or pathogenic classification with high sensitivity\nand reasonable PPV. Our prompts detected papers with intermediate or\ninconclusive evidence with lower sensitivity but high PPV. Our results support\nthat GPT-4 may be useful in variant classification workflows by enabling\nprioritization of articles for review that are likely to have functional\nevidence supporting or refuting pathogenicity, but not that GPT-4 is capable of\nfully automating the genetics literature review component of variant\nclassification.\n",
                "链接": "https://arxiv.org/abs/2312.13521"
            },
            {
                "文章ID": "58197",
                "标题": "Counterfactual Editing for Search Result Explanation",
                "作者": " Zhichao Xu,  Hemank Lamba,  Qingyao Ai,  Joel Tetreault,  Alex Jaimes",
                "发布日期": "2023-01-26",
                "摘要": "  Recently substantial improvements in neural retrieval methods also bring to\nlight the inherent blackbox nature of these methods, especially when viewed\nfrom an explainability perspective. Most of existing works on Search Result\nExplanation (SeRE) are designed to provide factual explanation, i.e. to\nfind/generate supporting evidence about documents' relevance to search queries.\nHowever, research in cognitive sciences have shown that human explanations are\ncontrastive i.e. people explain an observed event using some counterfactual\nevents; such explanations reduce cognitive load, and provide actionable\ninsights. Though already proven effective in machine learning and NLP\ncommunities, the formulation and impact of counterfactual explanations have not\nbeen well studied for search systems. In this work, we aim to investigate the\neffectiveness of this perspective via proposing and evaluating counterfactual\nexplanations for the task of SeRE. Specifically, we first conduct a user study\nwhere we investigate if counterfactual explanations indeed improve search\nsessions' effectiveness. Taking this as a motivation, we discuss the desiderata\nthat an ideal counterfactual explanation method for SeRE should adhere to.\nNext, we propose a method $\\text{CFE}^2$ (\\textbf{C}ounter\\textbf{F}actual\n\\textbf{E}xplanation with \\textbf{E}diting) to provide pairwise explanations to\nsearch engine result page. Finally, we showcase that the proposed method when\nevaluated on four publicly available datasets outperforms baselines on both\nmetrics and human evaluation.\n",
                "链接": "https://arxiv.org/abs/2301.10389"
            },
            {
                "文章ID": "18433",
                "标题": "Approaches to the classification of complex systems: Words, texts, and\n  more",
                "作者": " Andrij Rovenchak",
                "发布日期": "2022-05-10",
                "摘要": "  The Chapter starts with introductory information about quantitative\nlinguistics notions, like rank--frequency dependence, Zipf's law, frequency\nspectra, etc. Similarities in distributions of words in texts with level\noccupation in quantum ensembles hint at a superficial analogy with statistical\nphysics. This enables one to define various parameters for texts based on this\nphysical analogy, including \"temperature\", \"chemical potential\", entropy, and\nsome others. Such parameters provide a set of variables to classify texts\nserving as an example of complex systems. Moreover, texts are perhaps the\neasiest complex systems to collect and analyze.\n  Similar approaches can be developed to study, for instance, genomes due to\nwell-known linguistic analogies. We consider a couple of approaches to define\nnucleotide sequences in mitochondrial DNAs and viral RNAs and demonstrate their\npossible application as an auxiliary tool for comparative analysis of genomes.\n  Finally, we discuss entropy as one of the parameters, which can be easily\ncomputed from rank--frequency dependences. Being a discriminating parameter in\nsome problems of classification of complex systems, entropy can be given a\nproper interpretation only in a limited class of problems. Its overall role and\nsignificance remain an open issue so far.\n",
                "链接": "https://arxiv.org/abs/2205.04060"
            }
        ]
    },
    {
        "question": {
            "question": "查找使用GPT4v完成多模态智能体的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "117667",
                "标题": "MLLM-Bench, Evaluating Multi-modal LLMs using GPT-4V",
                "作者": " Wentao Ge,  Shunian Chen,  Guiming Chen,  Junying Chen,  Zhihong Chen,  Shuo Yan,  Chenghao Zhu,  Ziyue Lin,  Wenya Xie,  Xidong Wang,  Anningzhe Gao,  Zhiyi Zhang,  Jianquan Li,  Xiang Wan,  Benyou Wang",
                "发布日期": "2023-11-27",
                "摘要": "  In the pursuit of Artificial General Intelligence (AGI), the integration of\nvision in language models has marked a significant milestone. The advent of\nvision-language models (MLLMs) like GPT-4V have expanded AI applications,\naligning with the multi-modal capabilities of the human brain. However,\nevaluating the efficacy of MLLMs poses a substantial challenge due to the\nsubjective nature of tasks that lack definitive answers. Existing automatic\nevaluation methodologies on multi-modal large language models rely on objective\nqueries that have standard answers, inadequately addressing the nuances of\ncreative and associative multi-modal tasks. To address this, we introduce\nMLLM-Bench, an innovative benchmark inspired by Vicuna, spanning a diverse\narray of scenarios, including Perception, Understanding, Applying, Analyzing,\nEvaluating, and Creation along with the ethical consideration. MLLM-Bench is\ndesigned to reflect user experience more accurately and provide a more holistic\nassessment of model performance. Comparative evaluations indicate a significant\nperformance gap between existing open-source models and GPT-4V. We posit that\nMLLM-Bench will catalyze progress in the open-source community towards\ndeveloping user-centric vision-language models that meet a broad spectrum of\nreal-world applications. See online leaderboard in\n\\url{https://mllm-bench.llmzoo.com}.\n",
                "链接": "https://arxiv.org/abs/2311.13951"
            },
            {
                "文章ID": "114711",
                "标题": "On the Road with GPT-4V(ision): Early Explorations of Visual-Language\n  Model on Autonomous Driving",
                "作者": " Licheng Wen,  Xuemeng Yang,  Daocheng Fu,  Xiaofeng Wang,  Pinlong Cai,  Xin Li,  Tao Ma,  Yingxuan Li,  Linran Xu,  Dengke Shang,  Zheng Zhu,  Shaoyan Sun,  Yeqi Bai,  Xinyu Cai,  Min Dou,  Shuanglu Hu,  Botian Shi,  Yu Qiao",
                "发布日期": "2023-11-29",
                "摘要": "  The pursuit of autonomous driving technology hinges on the sophisticated\nintegration of perception, decision-making, and control systems. Traditional\napproaches, both data-driven and rule-based, have been hindered by their\ninability to grasp the nuance of complex driving environments and the\nintentions of other road users. This has been a significant bottleneck,\nparticularly in the development of common sense reasoning and nuanced scene\nunderstanding necessary for safe and reliable autonomous driving. The advent of\nVisual Language Models (VLM) represents a novel frontier in realizing fully\nautonomous vehicle driving. This report provides an exhaustive evaluation of\nthe latest state-of-the-art VLM, GPT-4V(ision), and its application in\nautonomous driving scenarios. We explore the model's abilities to understand\nand reason about driving scenes, make decisions, and ultimately act in the\ncapacity of a driver. Our comprehensive tests span from basic scene recognition\nto complex causal reasoning and real-time decision-making under varying\nconditions. Our findings reveal that GPT-4V demonstrates superior performance\nin scene understanding and causal reasoning compared to existing autonomous\nsystems. It showcases the potential to handle out-of-distribution scenarios,\nrecognize intentions, and make informed decisions in real driving contexts.\nHowever, challenges remain, particularly in direction discernment, traffic\nlight recognition, vision grounding, and spatial reasoning tasks. These\nlimitations underscore the need for further research and development. Project\nis now available on GitHub for interested parties to access and utilize:\n\\url{https://github.com/PJLab-ADG/GPT4V-AD-Exploration}\n",
                "链接": "https://arxiv.org/abs/2311.05332"
            },
            {
                "文章ID": "108932",
                "标题": "Can GPT-4V(ision) Serve Medical Applications? Case Studies on GPT-4V for\n  Multimodal Medical Diagnosis",
                "作者": " Chaoyi Wu,  Jiayu Lei,  Qiaoyu Zheng,  Weike Zhao,  Weixiong Lin,  Xiaoman Zhang,  Xiao Zhou,  Ziheng Zhao,  Ya Zhang,  Yanfeng Wang,  Weidi Xie",
                "发布日期": "2023-12-05",
                "摘要": "  Driven by the large foundation models, the development of artificial\nintelligence has witnessed tremendous progress lately, leading to a surge of\ngeneral interest from the public. In this study, we aim to assess the\nperformance of OpenAI's newest model, GPT-4V(ision), specifically in the realm\nof multimodal medical diagnosis. Our evaluation encompasses 17 human body\nsystems, including Central Nervous System, Head and Neck, Cardiac, Chest,\nHematology, Hepatobiliary, Gastrointestinal, Urogenital, Gynecology,\nObstetrics, Breast, Musculoskeletal, Spine, Vascular, Oncology, Trauma,\nPediatrics, with images taken from 8 modalities used in daily clinic routine,\ne.g., X-ray, Computed Tomography (CT), Magnetic Resonance Imaging (MRI),\nPositron Emission Tomography (PET), Digital Subtraction Angiography (DSA),\nMammography, Ultrasound, and Pathology. We probe the GPT-4V's ability on\nmultiple clinical tasks with or without patent history provided, including\nimaging modality and anatomy recognition, disease diagnosis, report generation,\ndisease localisation.\n  Our observation shows that, while GPT-4V demonstrates proficiency in\ndistinguishing between medical image modalities and anatomy, it faces\nsignificant challenges in disease diagnosis and generating comprehensive\nreports. These findings underscore that while large multimodal models have made\nsignificant advancements in computer vision and natural language processing, it\nremains far from being used to effectively support real-world medical\napplications and clinical decision-making.\n  All images used in this report can be found in\nhttps://github.com/chaoyi-wu/GPT-4V_Medical_Evaluation.\n",
                "链接": "https://arxiv.org/abs/2310.09909"
            },
            {
                "文章ID": "115991",
                "标题": "Comparing Humans, GPT-4, and GPT-4V On Abstraction and Reasoning Tasks",
                "作者": " Melanie Mitchell,  Alessandro B. Palmarini,  Arseny Moskvichev",
                "发布日期": "2023-12-25",
                "摘要": "  We explore the abstract reasoning abilities of text-only and multimodal\nversions of GPT-4, using the ConceptARC benchmark [10], which is designed to\nevaluate robust understanding and reasoning with core-knowledge concepts. We\nextend the work of Moskvichev et al. [10] by evaluating GPT-4 on more detailed,\none-shot prompting (rather than simple, zero-shot prompts) with text versions\nof ConceptARC tasks, and by evaluating GPT-4V, the multimodal version of GPT-4,\non zero- and one-shot prompts using image versions of the simplest tasks. Our\nexperimental results support the conclusion that neither version of GPT-4 has\ndeveloped robust abstraction abilities at humanlike levels.\n",
                "链接": "https://arxiv.org/abs/2311.09247"
            },
            {
                "文章ID": "121321",
                "标题": "Image and Data Mining in Reticular Chemistry Using GPT-4V",
                "作者": " Zhiling Zheng,  Zhiguo He,  Omar Khattab,  Nakul Rampal,  Matei A. Zaharia,  Christian Borgs,  Jennifer T. Chayes,  Omar M. Yaghi",
                "发布日期": "2023-12-12",
                "摘要": "  The integration of artificial intelligence into scientific research has\nreached a new pinnacle with GPT-4V, a large language model featuring enhanced\nvision capabilities, accessible through ChatGPT or an API. This study\ndemonstrates the remarkable ability of GPT-4V to navigate and obtain complex\ndata for metal-organic frameworks, especially from graphical sources. Our\napproach involved an automated process of converting 346 scholarly articles\ninto 6240 images, which represents a benchmark dataset in this task, followed\nby deploying GPT-4V to categorize and analyze these images using natural\nlanguage prompts. This methodology enabled GPT-4V to accurately identify and\ninterpret key plots integral to MOF characterization, such as nitrogen\nisotherms, PXRD patterns, and TGA curves, among others, with accuracy and\nrecall above 93%. The model's proficiency in extracting critical information\nfrom these plots not only underscores its capability in data mining but also\nhighlights its potential in aiding the creation of comprehensive digital\ndatabases for reticular chemistry. In addition, the extracted nitrogen isotherm\ndata from the selected literature allowed for a comparison between theoretical\nand experimental porosity values for over 200 compounds, highlighting certain\ndiscrepancies and underscoring the importance of integrating computational and\nexperimental data. This work highlights the potential of AI in accelerating\nscientific discovery and innovation, bridging the gap between computational\ntools and experimental research, and paving the way for more efficient,\ninclusive, and comprehensive scientific inquiry.\n",
                "链接": "https://arxiv.org/abs/2312.05468"
            },
            {
                "文章ID": "113392",
                "标题": "GPT-4V(ision) as a Generalist Evaluator for Vision-Language Tasks",
                "作者": " Xinlu Zhang,  Yujie Lu,  Weizhi Wang,  An Yan,  Jun Yan,  Lianke Qin,  Heng Wang,  Xifeng Yan,  William Yang Wang,  Linda Ruth Petzold",
                "发布日期": "2023-11-03",
                "摘要": "  Automatically evaluating vision-language tasks is challenging, especially\nwhen it comes to reflecting human judgments due to limitations in accounting\nfor fine-grained details. Although GPT-4V has shown promising results in\nvarious multi-modal tasks, leveraging GPT-4V as a generalist evaluator for\nthese tasks has not yet been systematically explored. We comprehensively\nvalidate GPT-4V's capabilities for evaluation purposes, addressing tasks\nranging from foundational image-to-text and text-to-image synthesis to\nhigh-level image-to-image translations and multi-images to text alignment. We\nemploy two evaluation methods, single-answer grading and pairwise comparison,\nusing GPT-4V. Notably, GPT-4V shows promising agreement with humans across\nvarious tasks and evaluation methods, demonstrating immense potential for\nmulti-modal LLMs as evaluators. Despite limitations like restricted visual\nclarity grading and real-world complex reasoning, its ability to provide\nhuman-aligned scores enriched with detailed explanations is promising for\nuniversal automatic evaluator.\n",
                "链接": "https://arxiv.org/abs/2311.01361"
            },
            {
                "文章ID": "111381",
                "标题": "An Early Evaluation of GPT-4V(ision)",
                "作者": " Yang Wu,  Shilong Wang,  Hao Yang,  Tian Zheng,  Hongbo Zhang,  Yanyan Zhao,  Bing Qin",
                "发布日期": "2023-10-26",
                "摘要": "  In this paper, we evaluate different abilities of GPT-4V including visual\nunderstanding, language understanding, visual puzzle solving, and understanding\nof other modalities such as depth, thermal, video, and audio. To estimate\nGPT-4V's performance, we manually construct 656 test instances and carefully\nevaluate the results of GPT-4V. The highlights of our findings are as follows:\n(1) GPT-4V exhibits impressive performance on English visual-centric benchmarks\nbut fails to recognize simple Chinese texts in the images; (2) GPT-4V shows\ninconsistent refusal behavior when answering questions related to sensitive\ntraits such as gender, race, and age; (3) GPT-4V obtains worse results than\nGPT-4 (API) on language understanding tasks including general language\nunderstanding benchmarks and visual commonsense knowledge evaluation\nbenchmarks; (4) Few-shot prompting can improve GPT-4V's performance on both\nvisual understanding and language understanding; (5) GPT-4V struggles to find\nthe nuances between two similar images and solve the easy math picture puzzles;\n(6) GPT-4V shows non-trivial performance on the tasks of similar modalities to\nimage, such as video and thermal. Our experimental results reveal the ability\nand limitations of GPT-4V and we hope our paper can provide some insights into\nthe application and research of GPT-4V.\n",
                "链接": "https://arxiv.org/abs/2310.16534"
            },
            {
                "文章ID": "20518",
                "标题": "META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI",
                "作者": " Liangtai Sun,  Xingyu Chen,  Lu Chen,  Tianle Dai,  Zichen Zhu,  Kai Yu",
                "发布日期": "2023-07-26",
                "摘要": "  Task-oriented dialogue (TOD) systems have been widely used by mobile phone\nintelligent assistants to accomplish tasks such as calendar scheduling or hotel\nreservation. Current TOD systems usually focus on multi-turn text/speech\ninteraction, then they would call back-end APIs designed for TODs to perform\nthe task. However, this API-based architecture greatly limits the\ninformation-searching capability of intelligent assistants and may even lead to\ntask failure if TOD-specific APIs are not available or the task is too\ncomplicated to be executed by the provided APIs. In this paper, we propose a\nnew TOD architecture: GUI-based task-oriented dialogue system (GUI-TOD). A\nGUI-TOD system can directly perform GUI operations on real APPs and execute\ntasks without invoking TOD-specific backend APIs. Furthermore, we release\nMETA-GUI, a dataset for training a Multi-modal convErsaTional Agent on mobile\nGUI. We also propose a multi-model action prediction and response model, which\nshow promising results on META-GUI. The dataset, codes and leaderboard are\npublicly available.\n",
                "链接": "https://arxiv.org/abs/2205.11029"
            },
            {
                "文章ID": "18559",
                "标题": "Scim: Intelligent Skimming Support for Scientific Papers",
                "作者": " Raymond Fok,  Hita Kambhamettu,  Luca Soldaini,  Jonathan Bragg,  Kyle Lo,  Andrew Head,  Marti A. Hearst,  Daniel S. Weld",
                "发布日期": "2023-09-26",
                "摘要": "  Researchers need to keep up with immense literatures, though it is\ntime-consuming and difficult to do so. In this paper, we investigate the role\nthat intelligent interfaces can play in helping researchers skim papers, that\nis, rapidly reviewing a paper to attain a cursory understanding of its\ncontents. After conducting formative interviews and a design probe, we suggest\nthat skimming aids should aim to thread the needle of highlighting content that\nis simultaneously diverse, evenly-distributed, and important. We introduce\nScim, a novel intelligent skimming interface that reifies this aim, designed to\nsupport the skimming process by highlighting salient paper contents to direct a\nskimmer's focus. Key to the design is that the highlights are faceted by\ncontent type, evenly-distributed across a paper, with a density configurable by\nreaders at both the global and local level. We evaluate Scim with an in-lab\nusability study and deployment study, revealing how skimming aids can support\nreaders throughout the skimming experience and yielding design considerations\nand tensions for the design of future intelligent skimming tools.\n",
                "链接": "https://arxiv.org/abs/2205.04561"
            },
            {
                "文章ID": "115396",
                "标题": "A Comprehensive Evaluation of GPT-4V on Knowledge-Intensive Visual\n  Question Answering",
                "作者": " Yunxin Li,  Longyue Wang,  Baotian Hu,  Xinyu Chen,  Wanqi Zhong,  Chenyang Lyu,  Min Zhang",
                "发布日期": "2023-11-14",
                "摘要": "  The emergence of multimodal large models (MLMs) has significantly advanced\nthe field of visual understanding, offering remarkable capabilities in the\nrealm of visual question answering (VQA). Yet, the true challenge lies in the\ndomain of knowledge-intensive VQA tasks, which necessitate not just recognition\nof visual elements, but also a deep comprehension of the visual information in\nconjunction with a vast repository of learned knowledge. To uncover such\ncapabilities of MLMs, particularly the newly introduced GPT-4V, we provide an\nin-depth evaluation from three perspectives: 1) Commonsense Knowledge, which\nassesses how well models can understand visual cues and connect to general\nknowledge; 2) Fine-grained World Knowledge, which tests the model's skill in\nreasoning out specific knowledge from images, showcasing their proficiency\nacross various specialized fields; 3) Comprehensive Knowledge with\nDecision-making Rationales, which examines model's capability to provide\nlogical explanations for its inference, facilitating a deeper analysis from the\ninterpretability perspective. Extensive experiments indicate that GPT-4V\nachieves SOTA performance on above three tasks. Interestingly, we find that: a)\nGPT-4V demonstrates enhanced reasoning and explanation when using composite\nimages as few-shot; b) GPT-4V produces severe hallucinations when dealing with\nworld knowledge, highlighting the future need for advancements in this research\ndirection.\n",
                "链接": "https://arxiv.org/abs/2311.07536"
            }
        ]
    },
    {
        "question": {
            "question": "帮我查找一下2018年以后使用强化学习做机器翻译任务的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "29736",
                "标题": "MAD for Robust Reinforcement Learning in Machine Translation",
                "作者": " Domenic Donato,  Lei Yu,  Wang Ling,  Chris Dyer",
                "发布日期": "2022-07-19",
                "摘要": "  We introduce a new distributed policy gradient algorithm and show that it\noutperforms existing reward-aware training procedures such as REINFORCE,\nminimum risk training (MRT) and proximal policy optimization (PPO) in terms of\ntraining stability and generalization performance when optimizing machine\ntranslation models. Our algorithm, which we call MAD (on account of using the\nmean absolute deviation in the importance weighting calculation), has\ndistributed data generators sampling multiple candidates per source sentence on\nworker nodes, while a central learner updates the policy. MAD depends crucially\non two variance reduction strategies: (1) a conditional reward normalization\nmethod that ensures each source sentence has both positive and negative reward\ntranslation examples and (2) a new robust importance weighting scheme that acts\nas a conditional entropy regularizer. Experiments on a variety of translation\ntasks show that policies learned using the MAD algorithm perform very well when\nusing both greedy decoding and beam search, and that the learned policies are\nsensitive to the specific reward used during training.\n",
                "链接": "https://arxiv.org/abs/2207.08583"
            },
            {
                "文章ID": "40957",
                "标题": "Reinforcement Learning with Large Action Spaces for Neural Machine\n  Translation",
                "作者": " Asaf Yehudai,  Leshem Choshen,  Lior Fox,  Omri Abend",
                "发布日期": "2022-10-07",
                "摘要": "  Applying Reinforcement learning (RL) following maximum likelihood estimation\n(MLE) pre-training is a versatile method for enhancing neural machine\ntranslation (NMT) performance. However, recent work has argued that the gains\nproduced by RL for NMT are mostly due to promoting tokens that have already\nreceived a fairly high probability in pre-training. We hypothesize that the\nlarge action space is a main obstacle to RL's effectiveness in MT, and conduct\ntwo sets of experiments that lend support to our hypothesis. First, we find\nthat reducing the size of the vocabulary improves RL's effectiveness. Second,\nwe find that effectively reducing the dimension of the action space without\nchanging the vocabulary also yields notable improvement as evaluated by BLEU,\nsemantic similarity, and human evaluation. Indeed, by initializing the\nnetwork's final fully connected layer (that maps the network's internal\ndimension to the vocabulary dimension), with a layer that generalizes over\nsimilar actions, we obtain a substantial improvement in RL performance: 1.5\nBLEU points on average.\n",
                "链接": "https://arxiv.org/abs/2210.03053"
            },
            {
                "文章ID": "55838",
                "标题": "Active Learning for Neural Machine Translation",
                "作者": " Neeraj Vashistha,  Kriti Singh,  Ramakant Shakya",
                "发布日期": "2023-01-03",
                "摘要": "  The machine translation mechanism translates texts automatically between\ndifferent natural languages, and Neural Machine Translation (NMT) has gained\nattention for its rational context analysis and fluent translation accuracy.\nHowever, processing low-resource languages that lack relevant training\nattributes like supervised data is a current challenge for Natural Language\nProcessing (NLP). We incorporated a technique known Active Learning with the\nNMT toolkit Joey NMT to reach sufficient accuracy and robust predictions of\nlow-resource language translation. With active learning, a semi-supervised\nmachine learning strategy, the training algorithm determines which unlabeled\ndata would be the most beneficial for obtaining labels using selected query\ntechniques. We implemented two model-driven acquisition functions for selecting\nthe samples to be validated. This work uses transformer-based NMT systems;\nbaseline model (BM), fully trained model (FTM) , active learning least\nconfidence based model (ALLCM), and active learning margin sampling based model\n(ALMSM) when translating English to Hindi. The Bilingual Evaluation Understudy\n(BLEU) metric has been used to evaluate system results. The BLEU scores of BM,\nFTM, ALLCM and ALMSM systems are 16.26, 22.56 , 24.54, and 24.20, respectively.\nThe findings in this paper demonstrate that active learning techniques helps\nthe model to converge early and improve the overall quality of the translation\nsystem.\n",
                "链接": "https://arxiv.org/abs/2301.00688"
            },
            {
                "文章ID": "50351",
                "标题": "Competency-Aware Neural Machine Translation: Can Machine Translation\n  Know its Own Translation Quality?",
                "作者": " Pei Zhang,  Baosong Yang,  Haoran Wei,  Dayiheng Liu,  Kai Fan,  Luo Si,  Jun Xie",
                "发布日期": "2022-11-28",
                "摘要": "  Neural machine translation (NMT) is often criticized for failures that happen\nwithout awareness. The lack of competency awareness makes NMT untrustworthy.\nThis is in sharp contrast to human translators who give feedback or conduct\nfurther investigations whenever they are in doubt about predictions. To fill\nthis gap, we propose a novel competency-aware NMT by extending conventional NMT\nwith a self-estimator, offering abilities to translate a source sentence and\nestimate its competency. The self-estimator encodes the information of the\ndecoding procedure and then examines whether it can reconstruct the original\nsemantics of the source sentence. Experimental results on four translation\ntasks demonstrate that the proposed method not only carries out translation\ntasks intact but also delivers outstanding performance on quality estimation.\nWithout depending on any reference or annotated data typically required by\nstate-of-the-art metric and quality estimation methods, our model yields an\neven higher correlation with human quality judgments than a variety of\naforementioned methods, such as BLEURT, COMET, and BERTScore. Quantitative and\nqualitative analyses show better robustness of competency awareness in our\nmodel.\n",
                "链接": "https://arxiv.org/abs/2211.13865"
            },
            {
                "文章ID": "67893",
                "标题": "LEAPT: Learning Adaptive Prefix-to-prefix Translation For Simultaneous\n  Machine Translation",
                "作者": " Lei Lin,  Shuangtao Li,  Xiaodong Shi",
                "发布日期": "2023-03-22",
                "摘要": "  Simultaneous machine translation, which aims at a real-time translation, is\nuseful in many live scenarios but very challenging due to the trade-off between\naccuracy and latency. To achieve the balance for both, the model needs to wait\nfor appropriate streaming text (READ policy) and then generates its translation\n(WRITE policy). However, WRITE policies of previous work either are specific to\nthe method itself due to the end-to-end training or suffer from the input\nmismatch between training and decoding for the non-end-to-end training.\nTherefore, it is essential to learn a generic and better WRITE policy for\nsimultaneous machine translation. Inspired by strategies utilized by human\ninterpreters and \"wait\" policies, we propose a novel adaptive prefix-to-prefix\ntraining policy called LEAPT, which allows our machine translation model to\nlearn how to translate source sentence prefixes and make use of the future\ncontext. Experiments show that our proposed methods greatly outperform\ncompetitive baselines and achieve promising results.\n",
                "链接": "https://arxiv.org/abs/2303.11750"
            },
            {
                "文章ID": "115731",
                "标题": "Extending Multilingual Machine Translation through Imitation Learning",
                "作者": " Wen Lai,  Viktor Hangya,  Alexander Fraser",
                "发布日期": "2023-11-16",
                "摘要": "  Despite the growing variety of languages supported by existing multilingual\nneural machine translation (MNMT) models, most of the world's languages are\nstill being left behind. We aim to extend large-scale MNMT models to a new\nlanguage, allowing for translation between the newly added and all of the\nalready supported languages in a challenging scenario: using only a parallel\ncorpus between the new language and English. Previous approaches, such as\ncontinued training on parallel data including the new language, suffer from\ncatastrophic forgetting (i.e., performance on other languages is reduced). Our\nnovel approach Imit-MNMT treats the task as an imitation learning process,\nwhich mimicks the behavior of an expert, a technique widely used in the\ncomputer vision area, but not well explored in NLP. More specifically, we\nconstruct a pseudo multi-parallel corpus of the new and the original languages\nby pivoting through English, and imitate the output distribution of the\noriginal MNMT model. Extensive experiments show that our approach significantly\nimproves the translation performance between the new and the original\nlanguages, without severe catastrophic forgetting. We also demonstrate that our\napproach is capable of solving copy and off-target problems, which are two\ncommon issues existence in current large-scale MNMT models.\n",
                "链接": "https://arxiv.org/abs/2311.08538"
            },
            {
                "文章ID": "52440",
                "标题": "Neural Machine Translation with Contrastive Translation Memories",
                "作者": " Xin Cheng,  Shen Gao,  Lemao Liu,  Dongyan Zhao,  Rui Yan",
                "发布日期": "2022-12-07",
                "摘要": "  Retrieval-augmented Neural Machine Translation models have been successful in\nmany translation scenarios. Different from previous works that make use of\nmutually similar but redundant translation memories~(TMs), we propose a new\nretrieval-augmented NMT to model contrastively retrieved translation memories\nthat are holistically similar to the source sentence while individually\ncontrastive to each other providing maximal information gains in three phases.\nFirst, in TM retrieval phase, we adopt a contrastive retrieval algorithm to\navoid redundancy and uninformativeness of similar translation pieces. Second,\nin memory encoding stage, given a set of TMs we propose a novel Hierarchical\nGroup Attention module to gather both local context of each TM and global\ncontext of the whole TM set. Finally, in training phase, a Multi-TM contrastive\nlearning objective is introduced to learn salient feature of each TM with\nrespect to target sentence. Experimental results show that our framework\nobtains improvements over strong baselines on the benchmark datasets.\n",
                "链接": "https://arxiv.org/abs/2212.03140"
            },
            {
                "文章ID": "56953",
                "标题": "Prompting Neural Machine Translation with Translation Memories",
                "作者": " Abudurexiti Reheman,  Tao Zhou,  Yingfeng Luo,  Di Yang,  Tong Xiao,  Jingbo Zhu",
                "发布日期": "2023-02-08",
                "摘要": "  Improving machine translation (MT) systems with translation memories (TMs) is\nof great interest to practitioners in the MT community. However, previous\napproaches require either a significant update of the model architecture and/or\nadditional training efforts to make the models well-behaved when TMs are taken\nas additional input. In this paper, we present a simple but effective method to\nintroduce TMs into neural machine translation (NMT) systems. Specifically, we\ntreat TMs as prompts to the NMT model at test time, but leave the training\nprocess unchanged. The result is a slight update of an existing NMT system,\nwhich can be implemented in a few hours by anyone who is familiar with NMT.\nExperimental results on several datasets demonstrate that our system\nsignificantly outperforms strong baselines.\n",
                "链接": "https://arxiv.org/abs/2301.05380"
            },
            {
                "文章ID": "85262",
                "标题": "Rethinking Translation Memory Augmented Neural Machine Translation",
                "作者": " Hongkun Hao,  Guoping Huang,  Lemao Liu,  Zhirui Zhang,  Shuming Shi,  Rui Wang",
                "发布日期": "2023-06-13",
                "摘要": "  This paper rethinks translation memory augmented neural machine translation\n(TM-augmented NMT) from two perspectives, i.e., a probabilistic view of\nretrieval and the variance-bias decomposition principle. The finding\ndemonstrates that TM-augmented NMT is good at the ability of fitting data\n(i.e., lower bias) but is more sensitive to the fluctuations in the training\ndata (i.e., higher variance), which provides an explanation to a recently\nreported contradictory phenomenon on the same translation task: TM-augmented\nNMT substantially advances vanilla NMT under the high-resource scenario whereas\nit fails under the low-resource scenario. Then we propose a simple yet\neffective TM-augmented NMT model to promote the variance and address the\ncontradictory phenomenon. Extensive experiments show that the proposed\nTM-augmented NMT achieves consistent gains over both conventional NMT and\nexisting TM-augmented NMT under two variance-preferable (low-resource and\nplug-and-play) scenarios as well as the high-resource scenario.\n",
                "链接": "https://arxiv.org/abs/2306.06948"
            },
            {
                "文章ID": "119702",
                "标题": "Quick Back-Translation for Unsupervised Machine Translation",
                "作者": " Benjamin Brimacombe,  Jiawei Zhou",
                "发布日期": "2023-12-05",
                "摘要": "  The field of unsupervised machine translation has seen significant\nadvancement from the marriage of the Transformer and the back-translation\nalgorithm. The Transformer is a powerful generative model, and back-translation\nleverages Transformer's high-quality translations for iterative\nself-improvement. However, the Transformer is encumbered by the run-time of\nautoregressive inference during back-translation, and back-translation is\nlimited by a lack of synthetic data efficiency. We propose a two-for-one\nimprovement to Transformer back-translation: Quick Back-Translation (QBT). QBT\nre-purposes the encoder as a generative model, and uses encoder-generated\nsequences to train the decoder in conjunction with the original autoregressive\nback-translation step, improving data throughput and utilization. Experiments\non various WMT benchmarks demonstrate that a relatively small number of\nrefining steps of QBT improve current unsupervised machine translation models,\nand that QBT dramatically outperforms standard back-translation only method in\nterms of training efficiency for comparable translation qualities.\n",
                "链接": "https://arxiv.org/abs/2312.00912"
            }
        ]
    },
    {
        "question": {
            "question": "请找出使用Transformer模型并在大规模数据集上进行预训练的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "97726",
                "标题": "Spurious Correlations and Where to Find Them",
                "作者": " Gautam Sreekumar,  Vishnu Naresh Boddeti",
                "发布日期": "2023-08-23",
                "摘要": "  Spurious correlations occur when a model learns unreliable features from the\ndata and are a well-known drawback of data-driven learning. Although there are\nseveral algorithms proposed to mitigate it, we are yet to jointly derive the\nindicators of spurious correlations. As a result, the solutions built upon\nstandalone hypotheses fail to beat simple ERM baselines. We collect some of the\ncommonly studied hypotheses behind the occurrence of spurious correlations and\ninvestigate their influence on standard ERM baselines using synthetic datasets\ngenerated from causal graphs. Subsequently, we observe patterns connecting\nthese hypotheses and model design choices.\n",
                "链接": "https://arxiv.org/abs/2308.11043"
            },
            {
                "文章ID": "27970",
                "标题": "Gender Biases and Where to Find Them: Exploring Gender Bias in\n  Pre-Trained Transformer-based Language Models Using Movement Pruning",
                "作者": " Przemyslaw Joniak,  Akiko Aizawa",
                "发布日期": "2022-07-07",
                "摘要": "  Language model debiasing has emerged as an important field of study in the\nNLP community. Numerous debiasing techniques were proposed, but bias ablation\nremains an unaddressed issue. We demonstrate a novel framework for inspecting\nbias in pre-trained transformer-based language models via movement pruning.\nGiven a model and a debiasing objective, our framework finds a subset of the\nmodel containing less bias than the original model. We implement our framework\nby pruning the model while fine-tuning it on the debiasing objective. Optimized\nare only the pruning scores - parameters coupled with the model's weights that\nact as gates. We experiment with pruning attention heads, an important building\nblock of transformers: we prune square blocks, as well as establish a new way\nof pruning the entire heads. Lastly, we demonstrate the usage of our framework\nusing gender bias, and based on our findings, we propose an improvement to an\nexisting debiasing method. Additionally, we re-discover a bias-performance\ntrade-off: the better the model performs, the more bias it contains.\n",
                "链接": "https://arxiv.org/abs/2207.02463"
            },
            {
                "文章ID": "2226",
                "标题": "Good Classification Measures and How to Find Them",
                "作者": " Martijn Gösgens,  Anton Zhiyanov,  Alexey Tikhonov,  Liudmila Prokhorenkova",
                "发布日期": "2022-01-25",
                "摘要": "  Several performance measures can be used for evaluating classification\nresults: accuracy, F-measure, and many others. Can we say that some of them are\nbetter than others, or, ideally, choose one measure that is best in all\nsituations? To answer this question, we conduct a systematic analysis of\nclassification performance measures: we formally define a list of desirable\nproperties and theoretically analyze which measures satisfy which properties.\nWe also prove an impossibility theorem: some desirable properties cannot be\nsimultaneously satisfied. Finally, we propose a new family of measures\nsatisfying all desirable properties except one. This family includes the\nMatthews Correlation Coefficient and a so-called Symmetric Balanced Accuracy\nthat was not previously used in classification literature. We believe that our\nsystematic approach gives an important tool to practitioners for adequately\nevaluating classification results.\n",
                "链接": "https://arxiv.org/abs/2201.09044"
            },
            {
                "文章ID": "111379",
                "标题": "Pretty Good Strategies and Where to Find Them",
                "作者": " Wojciech Jamroga,  Damian Kurpiewski",
                "发布日期": "2023-10-26",
                "摘要": "  Synthesis of bulletproof strategies in imperfect information scenarios is a\nnotoriously hard problem. In this paper, we suggest that it is sometimes a\nviable alternative to aim at \"reasonably good\" strategies instead. This makes\nsense not only when an ideal strategy cannot be found due to the complexity of\nthe problem, but also when no winning strategy exists at all. We propose an\nalgorithm for synthesis of such \"pretty good\" strategies. The idea is to first\ngenerate a surely winning strategy with perfect information, and then\niteratively improve it with respect to two criteria of dominance: one based on\nthe amount of conflicting decisions in the strategy, and the other related to\nthe tightness of its outcome set. We focus on reachability goals and evaluate\nthe algorithm experimentally with very promising results.\n",
                "链接": "https://arxiv.org/abs/2310.16531"
            },
            {
                "文章ID": "38716",
                "标题": "Best Prompts for Text-to-Image Models and How to Find Them",
                "作者": " Nikita Pavlichenko,  Dmitry Ustalov",
                "发布日期": "2023-06-05",
                "摘要": "  Recent progress in generative models, especially in text-guided diffusion\nmodels, has enabled the production of aesthetically-pleasing imagery resembling\nthe works of professional human artists. However, one has to carefully compose\nthe textual description, called the prompt, and augment it with a set of\nclarifying keywords. Since aesthetics are challenging to evaluate\ncomputationally, human feedback is needed to determine the optimal prompt\nformulation and keyword combination. In this paper, we present a\nhuman-in-the-loop approach to learning the most useful combination of prompt\nkeywords using a genetic algorithm. We also show how such an approach can\nimprove the aesthetic appeal of images depicting the same descriptions.\n",
                "链接": "https://arxiv.org/abs/2209.11711"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "37743",
                "标题": "Detecting Generated Scientific Papers using an Ensemble of Transformer\n  Models",
                "作者": " Anna Glazkova,  Maksim Glazkov",
                "发布日期": "2022-10-18",
                "摘要": "  The paper describes neural models developed for the DAGPap22 shared task\nhosted at the Third Workshop on Scholarly Document Processing. This shared task\ntargets the automatic detection of generated scientific papers. Our work\nfocuses on comparing different transformer-based models as well as using\nadditional datasets and techniques to deal with imbalanced classes. As a final\nsubmission, we utilized an ensemble of SciBERT, RoBERTa, and DeBERTa fine-tuned\nusing random oversampling technique. Our model achieved 99.24% in terms of\nF1-score. The official evaluation results have put our system at the third\nplace.\n",
                "链接": "https://arxiv.org/abs/2209.08283"
            },
            {
                "文章ID": "37484",
                "标题": "Random initialisations performing above chance and how to find them",
                "作者": " Frederik Benzing,  Simon Schug,  Robert Meier,  Johannes von Oswald,  Yassir Akram,  Nicolas Zucchet,  Laurence Aitchison,  Angelika Steger",
                "发布日期": "2022-11-08",
                "摘要": "  Neural networks trained with stochastic gradient descent (SGD) starting from\ndifferent random initialisations typically find functionally very similar\nsolutions, raising the question of whether there are meaningful differences\nbetween different SGD solutions. Entezari et al.\\ recently conjectured that\ndespite different initialisations, the solutions found by SGD lie in the same\nloss valley after taking into account the permutation invariance of neural\nnetworks. Concretely, they hypothesise that any two solutions found by SGD can\nbe permuted such that the linear interpolation between their parameters forms a\npath without significant increases in loss. Here, we use a simple but powerful\nalgorithm to find such permutations that allows us to obtain direct empirical\nevidence that the hypothesis is true in fully connected networks. Strikingly,\nwe find that two networks already live in the same loss valley at the time of\ninitialisation and averaging their random, but suitably permuted initialisation\nperforms significantly above chance. In contrast, for convolutional\narchitectures, our evidence suggests that the hypothesis does not hold.\nEspecially in a large learning rate regime, SGD seems to discover diverse\nmodes.\n",
                "链接": "https://arxiv.org/abs/2209.07509"
            },
            {
                "文章ID": "114514",
                "标题": "Training CLIP models on Data from Scientific Papers",
                "作者": " Calvin Metzger",
                "发布日期": "2023-11-09",
                "摘要": "  Contrastive Language-Image Pretraining (CLIP) models are able to capture the\nsemantic relationship of images and texts and have enabled a wide range of\napplications, from image retrieval to classification. These models are trained\nwith datasets extracted from web crawls, which are of large quantity but\nlimited quality. This paper explores whether limited amounts higher quality\ndata in a specific domain improve the general performance of CLIP models. To\nthis purpose, we extract text-image data from scientific papers hosted in the\narXiv and PubMed Central repositories. Experiments on small-scale CLIP models\n(ViT B/32) show that model performance increases on average, but only\nmoderately. This result indicates that using the data sources considered in the\npaper to train large-scale CLIP models is a worthwile research direction.\n",
                "链接": "https://arxiv.org/abs/2311.04711"
            },
            {
                "文章ID": "111790",
                "标题": "Fantastic Gains and Where to Find Them: On the Existence and Prospect of\n  General Knowledge Transfer between Any Pretrained Model",
                "作者": " Karsten Roth,  Lukas Thede,  Almut Sophia Koepke,  Oriol Vinyals,  Olivier Hénaff,  Zeynep Akata",
                "发布日期": "2023-10-27",
                "摘要": "  Training deep networks requires various design decisions regarding for\ninstance their architecture, data augmentation, or optimization. In this work,\nwe find these training variations to result in networks learning unique feature\nsets from the data. Using public model libraries comprising thousands of models\ntrained on canonical datasets like ImageNet, we observe that for arbitrary\npairings of pretrained models, one model extracts significant data context\nunavailable in the other -- independent of overall performance. Given any\narbitrary pairing of pretrained models and no external rankings (such as\nseparate test sets, e.g. due to data privacy), we investigate if it is possible\nto transfer such \"complementary\" knowledge from one model to another without\nperformance degradation -- a task made particularly difficult as additional\nknowledge can be contained in stronger, equiperformant or weaker models. Yet\nfacilitating robust transfer in scenarios agnostic to pretrained model pairings\nwould unlock auxiliary gains and knowledge fusion from any model repository\nwithout restrictions on model and problem specifics - including from weaker,\nlower-performance models. This work therefore provides an initial, in-depth\nexploration on the viability of such general-purpose knowledge transfer. Across\nlarge-scale experiments, we first reveal the shortcomings of standard knowledge\ndistillation techniques, and then propose a much more general extension through\ndata partitioning for successful transfer between nearly all pretrained models,\nwhich we show can also be done unsupervised. Finally, we assess both the\nscalability and impact of fundamental model properties on successful\nmodel-agnostic knowledge transfer.\n",
                "链接": "https://arxiv.org/abs/2310.17653"
            }
        ]
    },
    {
        "question": {
            "question": "找一下使用强化学习做代码生成的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "59289",
                "标题": "Execution-based Code Generation using Deep Reinforcement Learning",
                "作者": " Parshin Shojaee,  Aneesh Jain,  Sindhu Tipirneni,  Chandan K. Reddy",
                "发布日期": "2023-07-21",
                "摘要": "  The utilization of programming language (PL) models, pre-trained on\nlarge-scale code corpora, as a means of automating software engineering\nprocesses has demonstrated considerable potential in streamlining various code\ngeneration tasks such as code completion, code translation, and program\nsynthesis. However, current approaches mainly rely on supervised fine-tuning\nobjectives borrowed from text generation, neglecting unique sequence-level\ncharacteristics of code, including but not limited to compilability as well as\nsyntactic and functional correctness. To address this limitation, we propose\nPPOCoder, a new framework for code generation that synergistically combines\npre-trained PL models with Proximal Policy Optimization (PPO) which is a widely\nused deep reinforcement learning technique. By utilizing non-differentiable\nfeedback from code execution and structure alignment, PPOCoder seamlessly\nintegrates external code-specific knowledge into the model optimization\nprocess. It's important to note that PPOCoder is a task-agnostic and\nmodel-agnostic framework that can be used across different code generation\ntasks and PLs. Extensive experiments on three code generation tasks demonstrate\nthe effectiveness of our proposed approach compared to SOTA methods, achieving\nsignificant improvements in compilation success rates and functional\ncorrectness across different PLs.\n",
                "链接": "https://arxiv.org/abs/2301.13816"
            },
            {
                "文章ID": "27761",
                "标题": "CodeRL: Mastering Code Generation through Pretrained Models and Deep\n  Reinforcement Learning",
                "作者": " Hung Le,  Yue Wang,  Akhilesh Deepak Gotmare,  Silvio Savarese,  Steven C. H. Hoi",
                "发布日期": "2022-11-04",
                "摘要": "  Program synthesis or code generation aims to generate a program that\nsatisfies a problem specification. Recent approaches using large-scale\npretrained language models (LMs) have shown promising results, yet they have\nsome critical limitations. In particular, they often follow a standard\nsupervised fine-tuning procedure to train a code generation model only from the\npairs of natural-language problem descriptions and ground-truth programs. Such\nparadigm largely ignores some important but potentially useful signals in the\nproblem specification such as unit tests, which thus often results in poor\nperformance when solving complex unseen coding tasks. To address the\nlimitations, we propose \"CodeRL\", a new framework for program synthesis tasks\nthrough pretrained LMs and deep reinforcement learning (RL). Specifically,\nduring training, we treat the code-generating LM as an actor network, and\nintroduce a critic network that is trained to predict the functional\ncorrectness of generated programs and provide dense feedback signals to the\nactor. During inference, we introduce a new generation procedure with a\ncritical sampling strategy that allows a model to automatically regenerate\nprograms based on feedback from example unit tests and critic scores. For the\nmodel backbones, we extended the encoder-decoder architecture of CodeT5 with\nenhanced learning objectives, larger model sizes, and better pretraining data.\nOur method not only achieves new SOTA results on the challenging APPS\nbenchmark, but also shows strong zero-shot transfer capability with new SOTA\nresults on the simpler MBPP benchmark.\n",
                "链接": "https://arxiv.org/abs/2207.01780"
            },
            {
                "文章ID": "110290",
                "标题": "Automatic Unit Test Data Generation and Actor-Critic Reinforcement\n  Learning for Code Synthesis",
                "作者": " Philip John Gorinski,  Matthieu Zimmer,  Gerasimos Lampouras,  Derrick Goh Xin Deik,  Ignacio Iacobacci",
                "发布日期": "2023-10-23",
                "摘要": "  The advent of large pre-trained language models in the domain of Code\nSynthesis has shown remarkable performance on various benchmarks, treating the\nproblem of Code Generation in a fashion similar to Natural Language Generation,\ntrained with a Language Modelling (LM) objective. In addition, the property of\nprogramming language code being precisely evaluable with respect to its\nsemantics -- through the use of Unit Tests to check its functional correctness\n-- lends itself to using Reinforcement Learning (RL) as a further training\nparadigm. Previous work has shown that RL can be applied as such to improve\nmodels' coding capabilities; however, such RL-based methods rely on a reward\nsignal based on defined Unit Tests, which are much harder to obtain compared to\nthe huge crawled code datasets used in LM objectives. In this work, we present\na novel approach to automatically obtain data consisting of function signatures\nand associated Unit Tests, suitable for RL training of Code Synthesis models.\nWe also introduce a straightforward, simple yet effective Actor-Critic RL\ntraining scheme and show that it, in conjunction with automatically generated\ntraining data, leads to improvement of a pre-trained code language model's\nperformance by up to 9.9% improvement over the original underlying code\nsynthesis LM, and up to 4.3% over RL-based models trained with standard PPO or\nCodeRL.\n",
                "链接": "https://arxiv.org/abs/2310.13669"
            },
            {
                "文章ID": "72734",
                "标题": "Stochastic Code Generation",
                "作者": " Swapnil Sharma,  Nikita Anand, V Kranthi Kiran G.",
                "发布日期": "2023-04-18",
                "摘要": "  Large language models pre-trained for code generation can generate\nhigh-quality short code but often struggle with generating coherent long code\nand understanding higher-level or system-level specifications. This issue is\nalso observed in language modeling for long text generation, and one proposed\nsolution is the use of a latent stochastic process. This approach involves\ngenerating a document plan and then producing text that is consistent with it.\n  In this study, we investigate whether this technique can be applied to code\ngeneration to improve coherence. We base our proposed encoder and decoder on\nthe pre-trained GPT-2 based CodeParrot model and utilize the APPS dataset for\ntraining. We evaluate our results using the HumanEval benchmark and observe\nthat the modified Time Control model performs similarly to CodeParrot on this\nevaluation.\n",
                "链接": "https://arxiv.org/abs/2304.08243"
            },
            {
                "文章ID": "89545",
                "标题": "Exploring Continual Learning for Code Generation Models",
                "作者": " Prateek Yadav,  Qing Sun,  Hantian Ding,  Xiaopeng Li,  Dejiao Zhang,  Ming Tan,  Xiaofei Ma,  Parminder Bhatia,  Ramesh Nallapati,  Murali Krishna Ramanathan,  Mohit Bansal,  Bing Xiang",
                "发布日期": "2023-07-06",
                "摘要": "  Large-scale code generation models such as Codex and CodeT5 have achieved\nimpressive performance. However, libraries are upgraded or deprecated very\nfrequently and re-training large-scale language models is computationally\nexpensive. Therefore, Continual Learning (CL) is an important aspect that\nremains underexplored in the code domain. In this paper, we introduce a\nbenchmark called CodeTask-CL that covers a wide range of tasks, including code\ngeneration, translation, summarization, and refinement, with different input\nand output programming languages. Next, on our CodeTask-CL benchmark, we\ncompare popular CL techniques from NLP and Vision domains. We find that\neffective methods like Prompt Pooling (PP) suffer from catastrophic forgetting\ndue to the unstable training of the prompt selection mechanism caused by stark\ndistribution shifts in coding tasks. We address this issue with our proposed\nmethod, Prompt Pooling with Teacher Forcing (PP-TF), that stabilizes training\nby enforcing constraints on the prompt selection mechanism and leads to a\n21.54% improvement over Prompt Pooling. Along with the benchmark, we establish\na training pipeline that can be used for CL on code models, which we believe\ncan motivate further development of CL methods for code models. Our code is\navailable at https://github.com/amazon-science/codetaskcl-pptf\n",
                "链接": "https://arxiv.org/abs/2307.02435"
            },
            {
                "文章ID": "119060",
                "标题": "Self-Infilling Code Generation",
                "作者": " Lin Zheng,  Jianbo Yuan,  Zhi Zhang,  Hongxia Yang,  Lingpeng Kong",
                "发布日期": "2023-12-01",
                "摘要": "  This work introduces a general code generation framework that incorporates\ninfilling operations into auto-regressive decoding. Our approach capitalizes on\nthe observation that recent code language models with infilling capabilities\ncan perform \\emph{self-infilling}: whereas infilling operations aim to fill in\nthe middle based on a predefined prefix and suffix, self-infilling sequentially\ngenerates both such surrounding context and the infilled content. We utilize\nthis feature to develop an infilling-augmented decoding process that\nfacilitates non-monotonic generation. This approach allows for postponing the\ngeneration of uncertain code snippets until a definitive suffix is established,\nleading to improved control over the generation sequence. In addition, it\nfacilitates a looping mechanism, which can iteratively update and synchronize\neach piece of generation in a cyclic manner. Extensive experiments are\nconducted to demonstrate that our proposed decoding process is effective in\nenhancing regularity and quality across several code generation benchmarks.\n",
                "链接": "https://arxiv.org/abs/2311.17972"
            },
            {
                "文章ID": "122586",
                "标题": "Entity-Augmented Code Generation",
                "作者": " Anton Shapkin,  Denis Litvinov,  Timofey Bryksin",
                "发布日期": "2023-12-15",
                "摘要": "  The current state-of-the-art large language models (LLMs) are effective in\ngenerating high-quality text and encapsulating a broad spectrum of world\nknowledge. However, these models often hallucinate during generation and are\nnot designed to utilize external information sources. To enable requests to the\nexternal knowledge bases, also called knowledge grounding, retrieval-augmented\nLLMs were introduced. For now, their applications have largely involved Open\nDomain Question Answering, Abstractive Question Answering, and such. In this\npaper, we broaden the scope of retrieval-augmented LLMs by venturing into a new\ntask - code generation using external entities. For this task, we collect and\npublish a new dataset for project-level code generation, where the model should\nreuse functions defined in the project during generation. As we show, existing\nretrieval-augmented LLMs fail to assign relevance scores between similar entity\nnames, and to mitigate it, they expand entity names with description context\nand append it to the input. In practice, due to the limited context size they\ncan not accommodate the indefinitely large context of the whole project. To\nsolve this issue, we propose a novel end-to-end trainable architecture with an\nscalable entity retriever injected directly into the LLM decoder. We\ndemonstrate that our model can outperform common baselines in several\nscenarios, including project-level code generation, as well as Bash and SQL\nscripting.\n",
                "链接": "https://arxiv.org/abs/2312.08976"
            },
            {
                "文章ID": "69960",
                "标题": "AceCoder: Utilizing Existing Code to Enhance Code Generation",
                "作者": " Jia Li,  Yunfei Zhao,  Yongmin Li,  Ge Li,  Zhi Jin",
                "发布日期": "2023-09-08",
                "摘要": "  Large Language Models (LLMs) have shown great success in code generation.\nLLMs take as the input a prompt and output the code. A key question is how to\nmake prompts (i.e., Prompting Techniques). Existing prompting techniques are\ndesigned for natural language generation and have low accuracy in code\ngeneration.\n  In this paper, we propose a new prompting technique named AceCoder. Our\nmotivation is that code generation meets two unique challenges (i.e.,\nrequirement understanding and code implementation). AceCoder contains two novel\nmechanisms (i.e., guided code generation and example retrieval) to solve these\nchallenges. (1) Guided code generation asks LLMs first to analyze requirements\nand output an intermediate preliminary (e.g., test cases). The preliminary is\nused to clarify requirements and tell LLMs \"what to write\". (2) Example\nretrieval selects similar programs as examples in prompts, which provide lots\nof relevant content (e.g., algorithms, APIs) and teach LLMs \"how to write\". We\napply AceCoder to three LLMs (e.g., Codex) and evaluate it on three public\nbenchmarks using the Pass@k. Results show that AceCoder can significantly\nimprove the performance of LLMs on code generation. (1) In terms of Pass@1,\nAceCoder outperforms the state-of-the-art baseline by up to 56.4% in MBPP,\n70.7% in MBJP, and 88.4% in MBJSP. (2) AceCoder is effective in LLMs with\ndifferent sizes (i.e., 6B to 13B) and different languages (i.e., Python, Java,\nand JavaScript). (3) Human evaluation shows human developers prefer programs\nfrom AceCoder.\n",
                "链接": "https://arxiv.org/abs/2303.17780"
            },
            {
                "文章ID": "80370",
                "标题": "Who Wrote this Code? Watermarking for Code Generation",
                "作者": " Taehyun Lee,  Seokhee Hong,  Jaewoo Ahn,  Ilgee Hong,  Hwaran Lee,  Sangdoo Yun,  Jamin Shin,  Gunhee Kim",
                "发布日期": "2023-11-20",
                "摘要": "  With the remarkable generation performance of large language models, ethical\nand legal concerns about using them have been raised, such as plagiarism and\ncopyright issues. For such concerns, several approaches to watermark and detect\nLLM-generated text have been proposed very recently. However, we discover that\nthe previous methods fail to function appropriately with code generation tasks\nbecause of the syntactic and semantic characteristics of code. Based on\n\\citet{Kirchenbauer2023watermark}, we propose a new watermarking method,\nSelective WatErmarking via Entropy Thresholding (SWEET), that promotes \"green\"\ntokens only at the position with high entropy of the token distribution during\ngeneration, thereby preserving the correctness of the generated code. The\nwatermarked code is detected by the statistical test and Z-score based on the\nentropy information. Our experiments on HumanEval and MBPP show that SWEET\nsignificantly improves the Pareto Frontier between the code correctness and\nwatermark detection performance. We also show that notable post-hoc detection\nmethods (e.g. DetectGPT) fail to work well in this task. Finally, we show that\nsetting a reasonable entropy threshold is not much of a challenge. Code is\navailable at https://github.com/hongcheki/sweet-watermark.\n",
                "链接": "https://arxiv.org/abs/2305.15060"
            },
            {
                "文章ID": "61100",
                "标题": "CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code",
                "作者": " Shuyan Zhou,  Uri Alon,  Sumit Agarwal,  Graham Neubig",
                "发布日期": "2023-11-01",
                "摘要": "  Since the rise of neural natural-language-to-code models (NL->Code) that can\ngenerate long expressions and statements rather than a single next-token, one\nof the major problems has been reliably evaluating their generated output. In\nthis paper, we propose CodeBERTScore: an evaluation metric for code generation,\nwhich builds on BERTScore (Zhang et al., 2020). Instead of encoding only the\ngenerated tokens as in BERTScore, CodeBERTScore also encodes the natural\nlanguage input preceding the generated code, thus modeling the consistency\nbetween the generated code and its given natural language context as well. We\nperform an extensive evaluation of CodeBERTScore across four programming\nlanguages. We find that CodeBERTScore achieves a higher correlation with human\npreference and with functional correctness than all existing metrics. That is,\ngenerated code that receives a higher score by CodeBERTScore is more likely to\nbe preferred by humans, as well as to function correctly when executed. We\nrelease five language-specific pretrained models to use with our publicly\navailable code. Our language-specific models have been downloaded more than\n1,000,000 times from the Huggingface Hub. Our code and data are available at\nhttps://github.com/neulab/code-bert-score\n",
                "链接": "https://arxiv.org/abs/2302.05527"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下关于大模型使用工具的安全性的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "105613",
                "标题": "All Languages Matter: On the Multilingual Safety of Large Language\n  Models",
                "作者": " Wenxuan Wang,  Zhaopeng Tu,  Chang Chen,  Youliang Yuan,  Jen-tse Huang,  Wenxiang Jiao,  Michael R. Lyu",
                "发布日期": "2023-10-03",
                "摘要": "  Safety lies at the core of developing and deploying large language models\n(LLMs). However, previous safety benchmarks only concern the safety in one\nlanguage, e.g. the majority language in the pretraining data such as English.\nIn this work, we build the first multilingual safety benchmark for LLMs,\nXSafety, in response to the global deployment of LLMs in practice. XSafety\ncovers 14 kinds of commonly used safety issues across 10 languages that span\nseveral language families. We utilize XSafety to empirically study the\nmultilingual safety for 4 widely-used LLMs, including both close-API and\nopen-source models. Experimental results show that all LLMs produce\nsignificantly more unsafe responses for non-English queries than English ones,\nindicating the necessity of developing safety alignment for non-English\nlanguages. In addition, we propose several simple and effective prompting\nmethods to improve the multilingual safety of ChatGPT by evoking safety\nknowledge and improving cross-lingual generalization of safety alignment. Our\nprompting method can significantly reduce the ratio of unsafe responses from\n19.1% to 9.7% for non-English queries. We release our data at\nhttps://github.com/Jarviswang94/Multilingual_safety_benchmark.\n",
                "链接": "https://arxiv.org/abs/2310.00905"
            },
            {
                "文章ID": "70693",
                "标题": "Summary of ChatGPT-Related Research and Perspective Towards the Future\n  of Large Language Models",
                "作者": " Yiheng Liu,  Tianle Han,  Siyuan Ma,  Jiayue Zhang,  Yuanyuan Yang,  Jiaming Tian,  Hao He,  Antong Li,  Mengshen He,  Zhengliang Liu,  Zihao Wu,  Lin Zhao,  Dajiang Zhu,  Xiang Li,  Ning Qiang,  Dingang Shen,  Tianming Liu,  Bao Ge",
                "发布日期": "2023-08-25",
                "摘要": "  This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and\nGPT-4) research, state-of-the-art large language models (LLM) from the GPT\nseries, and their prospective applications across diverse domains. Indeed, key\ninnovations such as large-scale pre-training that captures knowledge across the\nentire world wide web, instruction fine-tuning and Reinforcement Learning from\nHuman Feedback (RLHF) have played significant roles in enhancing LLMs'\nadaptability and performance. We performed an in-depth analysis of 194 relevant\npapers on arXiv, encompassing trend analysis, word cloud representation, and\ndistribution analysis across various application domains. The findings reveal a\nsignificant and increasing interest in ChatGPT-related research, predominantly\ncentered on direct natural language processing applications, while also\ndemonstrating considerable potential in areas ranging from education and\nhistory to mathematics, medicine, and physics. This study endeavors to furnish\ninsights into ChatGPT's capabilities, potential implications, ethical concerns,\nand offer direction for future advancements in this field.\n",
                "链接": "https://arxiv.org/abs/2304.01852"
            },
            {
                "文章ID": "97463",
                "标题": "Can Large Language Models Find And Fix Vulnerable Software?",
                "作者": " David Noever",
                "发布日期": "2023-08-22",
                "摘要": "  In this study, we evaluated the capability of Large Language Models (LLMs),\nparticularly OpenAI's GPT-4, in detecting software vulnerabilities, comparing\ntheir performance against traditional static code analyzers like Snyk and\nFortify. Our analysis covered numerous repositories, including those from NASA\nand the Department of Defense. GPT-4 identified approximately four times the\nvulnerabilities than its counterparts. Furthermore, it provided viable fixes\nfor each vulnerability, demonstrating a low rate of false positives. Our tests\nencompassed 129 code samples across eight programming languages, revealing the\nhighest vulnerabilities in PHP and JavaScript. GPT-4's code corrections led to\na 90% reduction in vulnerabilities, requiring only an 11% increase in code\nlines. A critical insight was LLMs' ability to self-audit, suggesting fixes for\ntheir identified vulnerabilities and underscoring their precision. Future\nresearch should explore system-level vulnerabilities and integrate multiple\nstatic code analyzers for a holistic perspective on LLMs' potential.\n",
                "链接": "https://arxiv.org/abs/2308.10345"
            },
            {
                "文章ID": "94111",
                "标题": "Structural Embeddings of Tools for Large Language Models",
                "作者": " Eren Unlu",
                "发布日期": "2023-08-02",
                "摘要": "  It is evident that the current state of Large Language Models (LLMs)\nnecessitates the incorporation of external tools. The lack of straightforward\nalgebraic and logical reasoning is well documented and prompted researchers to\ndevelop frameworks which allow LLMs to operate via external tools. The\nontological nature of tool utilization for a specific task can be well\nformulated with a Directed Acyclic Graph (DAG). The central aim of the paper is\nto highlight the importance of graph based approaches to LLM-tool interaction\nin near future. We propose an exemplary framework to guide the orchestration of\nexponentially increasing numbers of external tools with LLMs,where objectives\nand functionalities of tools are graph encoded hierarchically. Assuming that\ntextual segments of a Chain-of-Thought (CoT) can be imagined as a tool as\ndefined here, the graph based framework can pave new avenues in that particular\ndirection as well.\n",
                "链接": "https://arxiv.org/abs/2308.00447"
            },
            {
                "文章ID": "70499",
                "标题": "Safety Analysis in the Era of Large Language Models: A Case Study of\n  STPA using ChatGPT",
                "作者": " Yi Qi,  Xingyu Zhao,  Siddartha Khastgir,  Xiaowei Huang",
                "发布日期": "2023-12-21",
                "摘要": "  Can safety analysis make use of Large Language Models (LLMs)? A case study\nexplores Systems Theoretic Process Analysis (STPA) applied to Automatic\nEmergency Brake (AEB) and Electricity Demand Side Management (DSM) systems\nusing ChatGPT. We investigate how collaboration schemes, input semantic\ncomplexity, and prompt guidelines influence STPA results. Comparative results\nshow that using ChatGPT without human intervention may be inadequate due to\nreliability related issues, but with careful design, it may outperform human\nexperts. No statistically significant differences are found when varying the\ninput semantic complexity or using common prompt guidelines, which suggests the\nnecessity for developing domain-specific prompt engineering. We also highlight\nfuture challenges, including concerns about LLM trustworthiness and the\nnecessity for standardisation and regulation in this domain.\n",
                "链接": "https://arxiv.org/abs/2304.01246"
            },
            {
                "文章ID": "114317",
                "标题": "Unveiling Safety Vulnerabilities of Large Language Models",
                "作者": " George Kour,  Marcel Zalmanovici,  Naama Zwerdling,  Esther Goldbraich,  Ora Nova Fandina,  Ateret Anaby-Tavor,  Orna Raz,  Eitan Farchi",
                "发布日期": "2023-11-08",
                "摘要": "  As large language models become more prevalent, their possible harmful or\ninappropriate responses are a cause for concern. This paper introduces a unique\ndataset containing adversarial examples in the form of questions, which we call\nAttaQ, designed to provoke such harmful or inappropriate responses. We assess\nthe efficacy of our dataset by analyzing the vulnerabilities of various models\nwhen subjected to it. Additionally, we introduce a novel automatic approach for\nidentifying and naming vulnerable semantic regions - input semantic areas for\nwhich the model is likely to produce harmful outputs. This is achieved through\nthe application of specialized clustering techniques that consider both the\nsemantic similarity of the input attacks and the harmfulness of the model's\nresponses. Automatically identifying vulnerable semantic regions enhances the\nevaluation of model weaknesses, facilitating targeted improvements to its\nsafety mechanisms and overall reliability.\n",
                "链接": "https://arxiv.org/abs/2311.04124"
            },
            {
                "文章ID": "102063",
                "标题": "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language\n  Models that Follow Instructions",
                "作者": " Federico Bianchi,  Mirac Suzgun,  Giuseppe Attanasio,  Paul Röttger,  Dan Jurafsky,  Tatsunori Hashimoto,  James Zou",
                "发布日期": "2023-09-26",
                "摘要": "  Training large language models to follow instructions makes them perform\nbetter on a wide range of tasks, generally becoming more helpful. However, a\nperfectly helpful model will follow even the most malicious instructions and\nreadily generate harmful content. In this paper, we raise concerns over the\nsafety of models that only emphasize helpfulness, not safety, in their\ninstruction-tuning. We show that several popular instruction-tuned models are\nhighly unsafe. Moreover, we show that adding just 3% safety examples (a few\nhundred demonstrations) in the training set when fine-tuning a model like LLaMA\ncan substantially improve their safety. Our safety-tuning does not make models\nsignificantly less capable or helpful as measured by standard benchmarks.\nHowever, we do find a behavior of exaggerated safety, where too much\nsafety-tuning makes models refuse to respond to reasonable prompts that\nsuperficially resemble unsafe ones. Our study sheds light on trade-offs in\ntraining LLMs to follow instructions and exhibit safe behavior.\n",
                "链接": "https://arxiv.org/abs/2309.07875"
            },
            {
                "文章ID": "97184",
                "标题": "Red-Teaming Large Language Models using Chain of Utterances for\n  Safety-Alignment",
                "作者": " Rishabh Bhardwaj,  Soujanya Poria",
                "发布日期": "2023-08-31",
                "摘要": "  Larger language models (LLMs) have taken the world by storm with their\nmassive multi-tasking capabilities simply by optimizing over a next-word\nprediction objective. With the emergence of their properties and encoded\nknowledge, the risk of LLMs producing harmful outputs increases, making them\nunfit for scalable deployment for the public. In this work, we propose a new\nsafety evaluation benchmark RED-EVAL that carries out red-teaming. We show that\neven widely deployed models are susceptible to the Chain of Utterances-based\n(CoU) prompting, jailbreaking closed source LLM-based systems such as GPT-4 and\nChatGPT to unethically respond to more than 65% and 73% of harmful queries. We\nalso demonstrate the consistency of the RED-EVAL across 8 open-source LLMs in\ngenerating harmful responses in more than 86% of the red-teaming attempts.\nNext, we propose RED-INSTRUCT--An approach for the safety alignment of LLMs. It\nconstitutes two phases: 1) HARMFULQA data collection: Leveraging CoU prompting,\nwe collect a dataset that consists of 1.9K harmful questions covering a wide\nrange of topics, 9.5K safe and 7.3K harmful conversations from ChatGPT; 2)\nSAFE-ALIGN: We demonstrate how the conversational dataset can be used for the\nsafety alignment of LLMs by minimizing the negative log-likelihood over helpful\nresponses and penalizing over harmful responses by gradient accent over sample\nloss. Our model STARLING, a fine-tuned Vicuna-7B, is observed to be more safely\naligned when evaluated on RED-EVAL and HHH benchmarks while preserving the\nutility of the baseline models (TruthfulQA, MMLU, and BBH).\n",
                "链接": "https://arxiv.org/abs/2308.09662"
            },
            {
                "文章ID": "78612",
                "标题": "A Survey of Safety and Trustworthiness of Large Language Models through\n  the Lens of Verification and Validation",
                "作者": " Xiaowei Huang,  Wenjie Ruan,  Wei Huang,  Gaojie Jin,  Yi Dong,  Changshun Wu,  Saddek Bensalem,  Ronghui Mu,  Yi Qi,  Xingyu Zhao,  Kaiwen Cai,  Yanghao Zhang,  Sihao Wu,  Peipei Xu,  Dengyu Wu,  Andre Freitas,  Mustafa A. Mustafa",
                "发布日期": "2023-08-29",
                "摘要": "  Large Language Models (LLMs) have exploded a new heatwave of AI for their\nability to engage end-users in human-level conversations with detailed and\narticulate answers across many knowledge domains. In response to their fast\nadoption in many industrial applications, this survey concerns their safety and\ntrustworthiness. First, we review known vulnerabilities and limitations of the\nLLMs, categorising them into inherent issues, attacks, and unintended bugs.\nThen, we consider if and how the Verification and Validation (V&V) techniques,\nwhich have been widely developed for traditional software and deep learning\nmodels such as convolutional neural networks as independent processes to check\nthe alignment of their implementations against the specifications, can be\nintegrated and further extended throughout the lifecycle of the LLMs to provide\nrigorous analysis to the safety and trustworthiness of LLMs and their\napplications. Specifically, we consider four complementary techniques:\nfalsification and evaluation, verification, runtime monitoring, and regulations\nand ethical use. In total, 370+ references are considered to support the quick\nunderstanding of the safety and trustworthiness issues from the perspective of\nV&V. While intensive research has been conducted to identify the safety and\ntrustworthiness issues, rigorous yet practical methods are called for to ensure\nthe alignment of LLMs with safety and trustworthiness requirements.\n",
                "链接": "https://arxiv.org/abs/2305.11391"
            },
            {
                "文章ID": "105425",
                "标题": "On the Stability of Iterative Retraining of Generative Models on their\n  own Data",
                "作者": " Quentin Bertrand,  Avishek Joey Bose,  Alexandre Duplessis,  Marco Jiralerspong,  Gauthier Gidel",
                "发布日期": "2023-12-14",
                "摘要": "  Deep generative models have made tremendous progress in modeling complex\ndata, often exhibiting generation quality that surpasses a typical human's\nability to discern the authenticity of samples. Undeniably, a key driver of\nthis success is enabled by the massive amounts of web-scale data consumed by\nthese models. Due to these models' striking performance and ease of\navailability, the web will inevitably be increasingly populated with synthetic\ncontent. Such a fact directly implies that future iterations of generative\nmodels must contend with the reality that their training is curated from both\nclean data and artificially generated data from past models. In this paper, we\ndevelop a framework to rigorously study the impact of training generative\nmodels on mixed datasets (of real and synthetic data) on their stability. We\nfirst prove the stability of iterative training under the condition that the\ninitial generative models approximate the data distribution well enough and the\nproportion of clean training data (w.r.t. synthetic data) is large enough. We\nempirically validate our theory on both synthetic and natural images by\niteratively training normalizing flows and state-of-the-art diffusion models on\nCIFAR10 and FFHQ.\n",
                "链接": "https://arxiv.org/abs/2310.00429"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下对使用GPT生成数据集的训练步骤进行改进的论文。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "12834",
                "标题": "PanGu-Bot: Efficient Generative Dialogue Pre-training from Pre-trained\n  Language Model",
                "作者": " Fei Mi,  Yitong Li,  Yulong Zeng,  Jingyan Zhou,  Yasheng Wang,  Chuanfei Xu,  Lifeng Shang,  Xin Jiang,  Shiqi Zhao,  Qun Liu",
                "发布日期": "2022-07-06",
                "摘要": "  In this paper, we introduce PanGu-Bot, a Chinese pre-trained open-domain\ndialogue generation model based on a large pre-trained language model (PLM)\nPANGU-alpha (Zeng et al.,2021). Different from other pre-trained dialogue\nmodels trained over a massive amount of dialogue data from scratch, we aim to\nbuild a powerful dialogue model with relatively fewer data and computation\ncosts by inheriting valuable language capabilities and knowledge from PLMs. To\nthis end, we train PanGu-Bot from the large PLM PANGU-alpha, which has been\nproven well-performed on a variety of Chinese natural language tasks. We\ninvestigate different aspects of responses generated by PanGu-Bot, including\nresponse quality, knowledge, and safety. We show that PanGu-Bot outperforms\nstate-of-the-art Chinese dialogue systems (CDIALGPT (Wang et al., 2020), EVA\n(Zhou et al., 2021), EVA2.0 (Gu et al., 2022)) w.r.t. the above three aspects.\nWe also demonstrate that PanGu-Bot can be easily deployed to generate emotional\nresponses without further training. Throughout our empirical analysis, we also\npoint out that the PanGu-Bot response quality, knowledge correctness, and\nsafety are still far from perfect, and further explorations are indispensable\nto building reliable and smart dialogue systems. Our model and code will be\navailable at\nhttps://github.com/huawei-noah/Pretrained-Language-Model/tree/master/PanGu-Bot\nsoon.\n",
                "链接": "https://arxiv.org/abs/2203.17090"
            },
            {
                "文章ID": "46060",
                "标题": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained\n  Transformers",
                "作者": " Elias Frantar,  Saleh Ashkboos,  Torsten Hoefler,  Dan Alistarh",
                "发布日期": "2023-03-23",
                "摘要": "  Generative Pre-trained Transformer models, known as GPT or OPT, set\nthemselves apart through breakthrough performance across complex language\nmodelling tasks, but also by their extremely high computational and storage\ncosts. Specifically, due to their massive size, even inference for large,\nhighly-accurate GPT models may require multiple performant GPUs, which limits\nthe usability of such models. While there is emerging work on relieving this\npressure via model compression, the applicability and performance of existing\ncompression techniques is limited by the scale and complexity of GPT models. In\nthis paper, we address this challenge, and propose GPTQ, a new one-shot weight\nquantization method based on approximate second-order information, that is both\nhighly-accurate and highly-efficient. Specifically, GPTQ can quantize GPT\nmodels with 175 billion parameters in approximately four GPU hours, reducing\nthe bitwidth down to 3 or 4 bits per weight, with negligible accuracy\ndegradation relative to the uncompressed baseline. Our method more than doubles\nthe compression gains relative to previously-proposed one-shot quantization\nmethods, preserving accuracy, allowing us for the first time to execute an 175\nbillion-parameter model inside a single GPU for generative inference. Moreover,\nwe also show that our method can still provide reasonable accuracy in the\nextreme quantization regime, in which weights are quantized to 2-bit or even\nternary quantization levels. We show experimentally that these improvements can\nbe leveraged for end-to-end inference speedups over FP16, of around 3.25x when\nusing high-end GPUs (NVIDIA A100) and 4.5x when using more cost-effective ones\n(NVIDIA A6000). The implementation is available at\nhttps://github.com/IST-DASLab/gptq.\n",
                "链接": "https://arxiv.org/abs/2210.17323"
            },
            {
                "文章ID": "55223",
                "标题": "Biologically Inspired Design Concept Generation Using Generative\n  Pre-Trained Transformers",
                "作者": " Qihao Zhu,  Xinyu Zhang,  Jianxi Luo",
                "发布日期": "2022-12-27",
                "摘要": "  Biological systems in nature have evolved for millions of years to adapt and\nsurvive the environment. Many features they developed can be inspirational and\nbeneficial for solving technical problems in modern industries. This leads to a\nspecific form of design-by-analogy called bio-inspired design (BID). Although\nBID as a design method has been proven beneficial, the gap between biology and\nengineering continuously hinders designers from effectively applying the\nmethod. Therefore, we explore the recent advance of artificial intelligence\n(AI) for a data-driven approach to bridge the gap. This paper proposes a\ngenerative design approach based on the generative pre-trained language model\n(PLM) to automatically retrieve and map biological analogy and generate BID in\nthe form of natural language. The latest generative pre-trained transformer,\nnamely GPT-3, is used as the base PLM. Three types of design concept generators\nare identified and fine-tuned from the PLM according to the looseness of the\nproblem space representation. Machine evaluators are also fine-tuned to assess\nthe mapping relevancy between the domains within the generated BID concepts.\nThe approach is evaluated and then employed in a real-world project of\ndesigning light-weighted flying cars during its conceptual design phase The\nresults show our approach can generate BID concepts with good performance.\n",
                "链接": "https://arxiv.org/abs/2212.13196"
            },
            {
                "文章ID": "114649",
                "标题": "GeoFormer: Predicting Human Mobility using Generative Pre-trained\n  Transformer (GPT)",
                "作者": " Aivin V. Solatorio",
                "发布日期": "2023-11-10",
                "摘要": "  Predicting human mobility holds significant practical value, with\napplications ranging from enhancing disaster risk planning to simulating\nepidemic spread. In this paper, we present the GeoFormer, a decoder-only\ntransformer model adapted from the GPT architecture to forecast human mobility.\nOur proposed model is rigorously tested in the context of the HuMob Challenge\n2023 -- a competition designed to evaluate the performance of prediction models\non standardized datasets to predict human mobility. The challenge leverages two\ndatasets encompassing urban-scale data of 25,000 and 100,000 individuals over a\nlongitudinal period of 75 days. GeoFormer stands out as a top performer in the\ncompetition, securing a place in the top-3 ranking. Its success is underscored\nby performing well on both performance metrics chosen for the competition --\nthe GEO-BLEU and the Dynamic Time Warping (DTW) measures. The performance of\nthe GeoFormer on the HuMob Challenge 2023 underscores its potential to make\nsubstantial contributions to the field of human mobility prediction, with\nfar-reaching implications for disaster preparedness, epidemic control, and\nbeyond.\n",
                "链接": "https://arxiv.org/abs/2311.05092"
            },
            {
                "文章ID": "80822",
                "标题": "Training Data Extraction From Pre-trained Language Models: A Survey",
                "作者": " Shotaro Ishihara",
                "发布日期": "2023-05-26",
                "摘要": "  As the deployment of pre-trained language models (PLMs) expands, pressing\nsecurity concerns have arisen regarding the potential for malicious extraction\nof training data, posing a threat to data privacy. This study is the first to\nprovide a comprehensive survey of training data extraction from PLMs. Our\nreview covers more than 100 key papers in fields such as natural language\nprocessing and security. First, preliminary knowledge is recapped and a\ntaxonomy of various definitions of memorization is presented. The approaches\nfor attack and defense are then systemized. Furthermore, the empirical findings\nof several quantitative studies are highlighted. Finally, future research\ndirections based on this review are suggested.\n",
                "链接": "https://arxiv.org/abs/2305.16157"
            },
            {
                "文章ID": "114514",
                "标题": "Training CLIP models on Data from Scientific Papers",
                "作者": " Calvin Metzger",
                "发布日期": "2023-11-09",
                "摘要": "  Contrastive Language-Image Pretraining (CLIP) models are able to capture the\nsemantic relationship of images and texts and have enabled a wide range of\napplications, from image retrieval to classification. These models are trained\nwith datasets extracted from web crawls, which are of large quantity but\nlimited quality. This paper explores whether limited amounts higher quality\ndata in a specific domain improve the general performance of CLIP models. To\nthis purpose, we extract text-image data from scientific papers hosted in the\narXiv and PubMed Central repositories. Experiments on small-scale CLIP models\n(ViT B/32) show that model performance increases on average, but only\nmoderately. This result indicates that using the data sources considered in the\npaper to train large-scale CLIP models is a worthwile research direction.\n",
                "链接": "https://arxiv.org/abs/2311.04711"
            },
            {
                "文章ID": "87912",
                "标题": "Distributive Pre-Training of Generative Modeling Using Matrix-Product\n  States",
                "作者": " Sheng-Hsuan Lin,  Olivier Kuijpers,  Sebastian Peterhansl,  Frank Pollmann",
                "发布日期": "2023-06-27",
                "摘要": "  Tensor networks have recently found applications in machine learning for both\nsupervised learning and unsupervised learning. The most common approaches for\ntraining these models are gradient descent methods. In this work, we consider\nan alternative training scheme utilizing basic tensor network operations, e.g.,\nsummation and compression. The training algorithm is based on compressing the\nsuperposition state constructed from all the training data in product state\nrepresentation. The algorithm could be parallelized easily and only iterates\nthrough the dataset once. Hence, it serves as a pre-training algorithm. We\nbenchmark the algorithm on the MNIST dataset and show reasonable results for\ngenerating new images and classification tasks. Furthermore, we provide an\ninterpretation of the algorithm as a compressed quantum kernel density\nestimation for the probability amplitude of input data.\n",
                "链接": "https://arxiv.org/abs/2306.14787"
            },
            {
                "文章ID": "15831",
                "标题": "Generative Pre-Trained Transformers for Biologically Inspired Design",
                "作者": " Qihao Zhu,  Xinyu Zhang,  Jianxi Luo",
                "发布日期": "2022-04-22",
                "摘要": "  Biological systems in nature have evolved for millions of years to adapt and\nsurvive the environment. Many features they developed can be inspirational and\nbeneficial for solving technical problems in modern industries. This leads to a\nnovel form of design-by-analogy called bio-inspired design (BID). Although BID\nas a design method has been proven beneficial, the gap between biology and\nengineering continuously hinders designers from effectively applying the\nmethod. Therefore, we explore the recent advance of artificial intelligence\n(AI) for a computational approach to bridge the gap. This paper proposes a\ngenerative design approach based on the pre-trained language model (PLM) to\nautomatically retrieve and map biological analogy and generate BID in the form\nof natural language. The latest generative pre-trained transformer, namely\nGPT-3, is used as the base PLM. Three types of design concept generators are\nidentified and fine-tuned from the PLM according to the looseness of the\nproblem space representation. Machine evaluators are also fine-tuned to assess\nthe correlation between the domains within the generated BID concepts. The\napproach is then tested via a case study in which the fine-tuned models are\napplied to generate and evaluate light-weighted flying car concepts inspired by\nnature. The results show our approach can generate BID concepts with good\nperformance.\n",
                "链接": "https://arxiv.org/abs/2204.09714"
            },
            {
                "文章ID": "16789",
                "标题": "Transfer Learning with Pre-trained Conditional Generative Models",
                "作者": " Shin'ya Yamaguchi,  Sekitoshi Kanai,  Atsutoshi Kumagai,  Daiki Chijiwa,  Hisashi Kashima",
                "发布日期": "2022-10-03",
                "摘要": "  Transfer learning is crucial in training deep neural networks on new target\ntasks. Current transfer learning methods always assume at least one of (i)\nsource and target task label spaces overlap, (ii) source datasets are\navailable, and (iii) target network architectures are consistent with source\nones. However, holding these assumptions is difficult in practical settings\nbecause the target task rarely has the same labels as the source task, the\nsource dataset access is restricted due to storage costs and privacy, and the\ntarget architecture is often specialized to each task. To transfer source\nknowledge without these assumptions, we propose a transfer learning method that\nuses deep generative models and is composed of the following two stages: pseudo\npre-training (PP) and pseudo semi-supervised learning (P-SSL). PP trains a\ntarget architecture with an artificial dataset synthesized by using conditional\nsource generative models. P-SSL applies SSL algorithms to labeled target data\nand unlabeled pseudo samples, which are generated by cascading the source\nclassifier and generative models to condition them with target samples. Our\nexperimental results indicate that our method can outperform the baselines of\nscratch training and knowledge distillation.\n",
                "链接": "https://arxiv.org/abs/2204.12833"
            },
            {
                "文章ID": "35384",
                "标题": "Deep Generative Modeling on Limited Data with Regularization by\n  Nontransferable Pre-trained Models",
                "作者": " Yong Zhong,  Hongtao Liu,  Xiaodong Liu,  Fan Bao,  Weiran Shen,  Chongxuan Li",
                "发布日期": "2023-04-11",
                "摘要": "  Deep generative models (DGMs) are data-eager because learning a complex model\non limited data suffers from a large variance and easily overfits. Inspired by\nthe classical perspective of the bias-variance tradeoff, we propose regularized\ndeep generative model (Reg-DGM), which leverages a nontransferable pre-trained\nmodel to reduce the variance of generative modeling with limited data.\nFormally, Reg-DGM optimizes a weighted sum of a certain divergence and the\nexpectation of an energy function, where the divergence is between the data and\nthe model distributions, and the energy function is defined by the pre-trained\nmodel w.r.t. the model distribution. We analyze a simple yet representative\nGaussian-fitting case to demonstrate how the weighting hyperparameter trades\noff the bias and the variance. Theoretically, we characterize the existence and\nthe uniqueness of the global minimum of Reg-DGM in a non-parametric setting and\nprove its convergence with neural networks trained by gradient-based methods.\nEmpirically, with various pre-trained feature extractors and a data-dependent\nenergy function, Reg-DGM consistently improves the generation performance of\nstrong DGMs with limited data and achieves competitive results to the\nstate-of-the-art methods. Our implementation is available at\nhttps://github.com/ML-GSAI/Reg-ADA-APA.\n",
                "链接": "https://arxiv.org/abs/2208.14133"
            }
        ]
    },
    {
        "question": {
            "question": "请找到使用自蒸馏加强目标检测性能的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "65588",
                "标题": "Smooth and Stepwise Self-Distillation for Object Detection",
                "作者": " Jieren Deng,  Xin Zhou,  Hao Tian,  Zhihong Pan,  Derek Aguiar",
                "发布日期": "2023-03-10",
                "摘要": "  Distilling the structured information captured in feature maps has\ncontributed to improved results for object detection tasks, but requires\ncareful selection of baseline architectures and substantial pre-training.\nSelf-distillation addresses these limitations and has recently achieved\nstate-of-the-art performance for object detection despite making several\nsimplifying architectural assumptions. Building on this work, we propose Smooth\nand Stepwise Self-Distillation (SSSD) for object detection. Our SSSD\narchitecture forms an implicit teacher from object labels and a feature pyramid\nnetwork backbone to distill label-annotated feature maps using Jensen-Shannon\ndistance, which is smoother than distillation losses used in prior work. We\nadditionally add a distillation coefficient that is adaptively configured based\non the learning rate. We extensively benchmark SSSD against a baseline and two\nstate-of-the-art object detector architectures on the COCO dataset by varying\nthe coefficients and backbone and detector networks. We demonstrate that SSSD\nachieves higher average precision in most experimental settings, is robust to a\nwide range of coefficients, and benefits from our stepwise distillation\nprocedure.\n",
                "链接": "https://arxiv.org/abs/2303.05015"
            },
            {
                "文章ID": "92560",
                "标题": "Spatial Self-Distillation for Object Detection with Inaccurate Bounding\n  Boxes",
                "作者": " Di Wu,  Pengfei Chen,  Xuehui Yu,  Guorong Li,  Zhenjun Han,  Jianbin Jiao",
                "发布日期": "2023-08-16",
                "摘要": "  Object detection via inaccurate bounding boxes supervision has boosted a\nbroad interest due to the expensive high-quality annotation data or the\noccasional inevitability of low annotation quality (\\eg tiny objects). The\nprevious works usually utilize multiple instance learning (MIL), which highly\ndepends on category information, to select and refine a low-quality box. Those\nmethods suffer from object drift, group prediction and part domination problems\nwithout exploring spatial information. In this paper, we heuristically propose\na \\textbf{Spatial Self-Distillation based Object Detector (SSD-Det)} to mine\nspatial information to refine the inaccurate box in a self-distillation\nfashion. SSD-Det utilizes a Spatial Position Self-Distillation \\textbf{(SPSD)}\nmodule to exploit spatial information and an interactive structure to combine\nspatial information and category information, thus constructing a high-quality\nproposal bag. To further improve the selection procedure, a Spatial Identity\nSelf-Distillation \\textbf{(SISD)} module is introduced in SSD-Det to obtain\nspatial confidence to help select the best proposals. Experiments on MS-COCO\nand VOC datasets with noisy box annotation verify our method's effectiveness\nand achieve state-of-the-art performance. The code is available at\nhttps://github.com/ucas-vg/PointTinyBenchmark/tree/SSD-Det.\n",
                "链接": "https://arxiv.org/abs/2307.12101"
            },
            {
                "文章ID": "14674",
                "标题": "Localization Distillation for Object Detection",
                "作者": " Zhaohui Zheng,  Rongguang Ye,  Qibin Hou,  Dongwei Ren,  Ping Wang,  Wangmeng Zuo,  Ming-Ming Cheng",
                "发布日期": "2022-12-09",
                "摘要": "  Previous knowledge distillation (KD) methods for object detection mostly\nfocus on feature imitation instead of mimicking the prediction logits due to\nits inefficiency in distilling the localization information. In this paper, we\ninvestigate whether logit mimicking always lags behind feature imitation.\nTowards this goal, we first present a novel localization distillation (LD)\nmethod which can efficiently transfer the localization knowledge from the\nteacher to the student. Second, we introduce the concept of valuable\nlocalization region that can aid to selectively distill the classification and\nlocalization knowledge for a certain region. Combining these two new\ncomponents, for the first time, we show that logit mimicking can outperform\nfeature imitation and the absence of localization distillation is a critical\nreason for why logit mimicking underperforms for years. The thorough studies\nexhibit the great potential of logit mimicking that can significantly alleviate\nthe localization ambiguity, learn robust feature representation, and ease the\ntraining difficulty in the early stage. We also provide the theoretical\nconnection between the proposed LD and the classification KD, that they share\nthe equivalent optimization effect. Our distillation scheme is simple as well\nas effective and can be easily applied to both dense horizontal object\ndetectors and rotated object detectors. Extensive experiments on the MS COCO,\nPASCAL VOC, and DOTA benchmarks demonstrate that our method can achieve\nconsiderable AP improvement without any sacrifice on the inference speed. Our\nsource code and pretrained models are publicly available at\nhttps://github.com/HikariTJU/LD.\n",
                "链接": "https://arxiv.org/abs/2204.05957"
            },
            {
                "文章ID": "14912",
                "标题": "Spatial Likelihood Voting with Self-Knowledge Distillation for Weakly\n  Supervised Object Detection",
                "作者": " Ze Chen,  Zhihang Fu,  Jianqiang Huang,  Mingyuan Tao,  Rongxin Jiang,  Xiang Tian,  Yaowu Chen,  Xian-sheng Hua",
                "发布日期": "2022-04-15",
                "摘要": "  Weakly supervised object detection (WSOD), which is an effective way to train\nan object detection model using only image-level annotations, has attracted\nconsiderable attention from researchers. However, most of the existing methods,\nwhich are based on multiple instance learning (MIL), tend to localize instances\nto the discriminative parts of salient objects instead of the entire content of\nall objects. In this paper, we propose a WSOD framework called the Spatial\nLikelihood Voting with Self-knowledge Distillation Network (SLV-SD Net). In\nthis framework, we introduce a spatial likelihood voting (SLV) module to\nconverge region proposal localization without bounding box annotations.\nSpecifically, in every iteration during training, all the region proposals in a\ngiven image act as voters voting for the likelihood of each category in the\nspatial dimensions. After dilating the alignment on the area with large\nlikelihood values, the voting results are regularized as bounding boxes, which\nare then used for the final classification and localization. Based on SLV, we\nfurther propose a self-knowledge distillation (SD) module to refine the feature\nrepresentations of the given image. The likelihood maps generated by the SLV\nmodule are used to supervise the feature learning of the backbone network,\nencouraging the network to attend to wider and more diverse areas of the image.\nExtensive experiments on the PASCAL VOC 2007/2012 and MS-COCO datasets\ndemonstrate the excellent performance of SLV-SD Net. In addition, SLV-SD Net\nproduces new state-of-the-art results on these benchmarks.\n",
                "链接": "https://arxiv.org/abs/2204.06899"
            },
            {
                "文章ID": "8799",
                "标题": "Semantic Distillation Guided Salient Object Detection",
                "作者": " Bo Xu,  Guanze Liu,  Han Huang,  Cheng Lu,  Yandong Guo",
                "发布日期": "2022-03-09",
                "摘要": "  Most existing CNN-based salient object detection methods can identify local\nsegmentation details like hair and animal fur, but often misinterpret the real\nsaliency due to the lack of global contextual information caused by the\nsubjectiveness of the SOD task and the locality of convolution layers.\nMoreover, due to the unrealistically expensive labeling costs, the current\nexisting SOD datasets are insufficient to cover the real data distribution. The\nlimitation and bias of the training data add additional difficulty to fully\nexploring the semantic association between object-to-object and\nobject-to-environment in a given image. In this paper, we propose a semantic\ndistillation guided SOD (SDG-SOD) method that produces accurate results by\nfusing semantically distilled knowledge from generated image captioning into\nthe Vision-Transformer-based SOD framework. SDG-SOD can better uncover\ninter-objects and object-to-environment saliency and cover the gap between the\nsubjective nature of SOD and its expensive labeling. Comprehensive experiments\non five benchmark datasets demonstrate that the SDG-SOD outperforms the\nstate-of-the-art approaches on four evaluation metrics, and largely improves\nthe model performance on DUTS, ECSSD, DUT, HKU-IS, and PASCAL-S datasets.\n",
                "链接": "https://arxiv.org/abs/2203.04076"
            },
            {
                "文章ID": "32300",
                "标题": "Task-Balanced Distillation for Object Detection",
                "作者": " Ruining Tang,  Zhenyu Liu,  Yangguang Li,  Yiguo Song,  Hui Liu,  Qide Wang,  Jing Shao,  Guifang Duan,  Jianrong Tan",
                "发布日期": "2022-08-08",
                "摘要": "  Mainstream object detectors are commonly constituted of two sub-tasks,\nincluding classification and regression tasks, implemented by two parallel\nheads. This classic design paradigm inevitably leads to inconsistent spatial\ndistributions between classification score and localization quality (IOU).\nTherefore, this paper alleviates this misalignment in the view of knowledge\ndistillation. First, we observe that the massive teacher achieves a higher\nproportion of harmonious predictions than the lightweight student. Based on\nthis intriguing observation, a novel Harmony Score (HS) is devised to estimate\nthe alignment of classification and regression qualities. HS models the\nrelationship between two sub-tasks and is seen as prior knowledge to promote\nharmonious predictions for the student. Second, this spatial misalignment will\nresult in inharmonious region selection when distilling features. To alleviate\nthis problem, a novel Task-decoupled Feature Distillation (TFD) is proposed by\nflexibly balancing the contributions of classification and regression tasks.\nEventually, HD and TFD constitute the proposed method, named Task-Balanced\nDistillation (TBD). Extensive experiments demonstrate the considerable\npotential and generalization of the proposed method. Specifically, when\nequipped with TBD, RetinaNet with ResNet-50 achieves 41.0 mAP under the COCO\nbenchmark, outperforming the recent FGD and FRS.\n",
                "链接": "https://arxiv.org/abs/2208.03006"
            },
            {
                "文章ID": "50130",
                "标题": "Structural Knowledge Distillation for Object Detection",
                "作者": " Philip de Rijk,  Lukas Schneider,  Marius Cordts,  Dariu M. Gavrila",
                "发布日期": "2022-11-24",
                "摘要": "  Knowledge Distillation (KD) is a well-known training paradigm in deep neural\nnetworks where knowledge acquired by a large teacher model is transferred to a\nsmall student. KD has proven to be an effective technique to significantly\nimprove the student's performance for various tasks including object detection.\nAs such, KD techniques mostly rely on guidance at the intermediate feature\nlevel, which is typically implemented by minimizing an lp-norm distance between\nteacher and student activations during training. In this paper, we propose a\nreplacement for the pixel-wise independent lp-norm based on the structural\nsimilarity (SSIM). By taking into account additional contrast and structural\ncues, feature importance, correlation and spatial dependence in the feature\nspace are considered in the loss formulation. Extensive experiments on MSCOCO\ndemonstrate the effectiveness of our method across different training schemes\nand architectures. Our method adds only little computational overhead, is\nstraightforward to implement and at the same time it significantly outperforms\nthe standard lp-norms. Moreover, more complex state-of-the-art KD methods using\nattention-based sampling mechanisms are outperformed, including a +3.5 AP gain\nusing a Faster R-CNN R-50 compared to a vanilla model.\n",
                "链接": "https://arxiv.org/abs/2211.13133"
            },
            {
                "文章ID": "65873",
                "标题": "Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection",
                "作者": " Luting Wang,  Yi Liu,  Penghui Du,  Zihan Ding,  Yue Liao,  Qiaosong Qi,  Biaolong Chen,  Si Liu",
                "发布日期": "2023-03-13",
                "摘要": "  Open-vocabulary object detection aims to provide object detectors trained on\na fixed set of object categories with the generalizability to detect objects\ndescribed by arbitrary text queries. Previous methods adopt knowledge\ndistillation to extract knowledge from Pretrained Vision-and-Language Models\n(PVLMs) and transfer it to detectors. However, due to the non-adaptive proposal\ncropping and single-level feature mimicking processes, they suffer from\ninformation destruction during knowledge extraction and inefficient knowledge\ntransfer. To remedy these limitations, we propose an Object-Aware Distillation\nPyramid (OADP) framework, including an Object-Aware Knowledge Extraction (OAKE)\nmodule and a Distillation Pyramid (DP) mechanism. When extracting object\nknowledge from PVLMs, the former adaptively transforms object proposals and\nadopts object-aware mask attention to obtain precise and complete knowledge of\nobjects. The latter introduces global and block distillation for more\ncomprehensive knowledge transfer to compensate for the missing relation\ninformation in object distillation. Extensive experiments show that our method\nachieves significant improvement compared to current methods. Especially on the\nMS-COCO dataset, our OADP framework reaches $35.6$ mAP$^{\\text{N}}_{50}$,\nsurpassing the current state-of-the-art method by $3.3$ mAP$^{\\text{N}}_{50}$.\nCode is released at https://github.com/LutingWang/OADP.\n",
                "链接": "https://arxiv.org/abs/2303.05892"
            },
            {
                "文章ID": "9204",
                "标题": "Prediction-Guided Distillation for Dense Object Detection",
                "作者": " Chenhongyi Yang,  Mateusz Ochal,  Amos Storkey,  Elliot J. Crowley",
                "发布日期": "2022-07-19",
                "摘要": "  Real-world object detection models should be cheap and accurate. Knowledge\ndistillation (KD) can boost the accuracy of a small, cheap detection model by\nleveraging useful information from a larger teacher model. However, a key\nchallenge is identifying the most informative features produced by the teacher\nfor distillation. In this work, we show that only a very small fraction of\nfeatures within a ground-truth bounding box are responsible for a teacher's\nhigh detection performance. Based on this, we propose Prediction-Guided\nDistillation (PGD), which focuses distillation on these key predictive regions\nof the teacher and yields considerable gains in performance over many existing\nKD baselines. In addition, we propose an adaptive weighting scheme over the key\nregions to smooth out their influence and achieve even better performance. Our\nproposed approach outperforms current state-of-the-art KD baselines on a\nvariety of advanced one-stage detection architectures. Specifically, on the\nCOCO dataset, our method achieves between +3.1% and +4.6% AP improvement using\nResNet-101 and ResNet-50 as the teacher and student backbones, respectively. On\nthe CrowdHuman dataset, we achieve +3.2% and +2.0% improvements in MR and AP,\nalso using these backbones. Our code is available at\nhttps://github.com/ChenhongyiYang/PGD.\n",
                "链接": "https://arxiv.org/abs/2203.05469"
            },
            {
                "文章ID": "13284",
                "标题": "Re-examining Distillation For Continual Object Detection",
                "作者": " Eli Verwimp,  Kuo Yang,  Sarah Parisot,  Hong Lanqing,  Steven McDonagh,  Eduardo Pérez-Pellitero,  Matthias De Lange,  Tinne Tuytelaars",
                "发布日期": "2022-10-10",
                "摘要": "  Training models continually to detect and classify objects, from new classes\nand new domains, remains an open problem. In this work, we conduct a thorough\nanalysis of why and how object detection models forget catastrophically. We\nfocus on distillation-based approaches in two-stage networks; the most-common\nstrategy employed in contemporary continual object detection work.Distillation\naims to transfer the knowledge of a model trained on previous tasks -- the\nteacher -- to a new model -- the student -- while it learns the new task. We\nshow that this works well for the region proposal network, but that wrong, yet\noverly confident teacher predictions prevent student models from effective\nlearning of the classification head. Our analysis provides a foundation that\nallows us to propose improvements for existing techniques by detecting\nincorrect teacher predictions, based on current ground-truth labels, and by\nemploying an adaptive Huber loss as opposed to the mean squared error for the\ndistillation loss in the classification heads. We evidence that our strategy\nworks not only in a class incremental setting, but also in domain incremental\nsettings, which constitute a realistic context, likely to be the setting of\nrepresentative real-world problems.\n",
                "链接": "https://arxiv.org/abs/2204.01407"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用CrossWoz或MultiWoz数据集进行DST评测的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "95138",
                "标题": "Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using\n  EmotionBench",
                "作者": " Jen-tse Huang,  Man Ho Lam,  Eric John Li,  Shujie Ren,  Wenxuan Wang,  Wenxiang Jiao,  Zhaopeng Tu,  Michael R. Lyu",
                "发布日期": "2023-11-17",
                "摘要": "  Recently, the community has witnessed the advancement of Large Language\nModels (LLMs), which have shown remarkable performance on various downstream\ntasks. Led by powerful models like ChatGPT and Claude, LLMs are revolutionizing\nhow users engage with software, assuming more than mere tools but intelligent\nassistants. Consequently, evaluating LLMs' anthropomorphic capabilities becomes\nincreasingly important in contemporary discourse. Utilizing the emotion\nappraisal theory from psychology, we propose to evaluate the empathy ability of\nLLMs, i.e., how their feelings change when presented with specific situations.\nAfter a careful and comprehensive survey, we collect a dataset containing over\n400 situations that have proven effective in eliciting the eight emotions\ncentral to our study. Categorizing the situations into 36 factors, we conduct a\nhuman evaluation involving more than 1,200 subjects worldwide. With the human\nevaluation results as references, our evaluation includes five LLMs, covering\nboth commercial and open-source models, including variations in model sizes,\nfeaturing the latest iterations, such as GPT-4 and LLaMA 2. A conclusion can be\ndrawn from the results that, despite several misalignments, LLMs can generally\nrespond appropriately to certain situations. Nevertheless, they fall short in\nalignment with the emotional behaviors of human beings and cannot establish\nconnections between similar situations. Our collected dataset of situations,\nthe human evaluation results, and the code of our testing framework, dubbed\nEmotionBench, is made publicly in https://github.com/CUHK-ARISE/EmotionBench.\nWe aspire to contribute to the advancement of LLMs regarding better alignment\nwith the emotional behaviors of human beings, thereby enhancing their utility\nand applicability as intelligent assistants.\n",
                "链接": "https://arxiv.org/abs/2308.03656"
            },
            {
                "文章ID": "6598",
                "标题": "Policy Evaluation for Temporal and/or Spatial Dependent Experiments",
                "作者": " Shikai Luo,  Ying Yang,  Chengchun Shi,  Fang Yao,  Jieping Ye,  Hongtu Zhu",
                "发布日期": "2023-12-05",
                "摘要": "  The aim of this paper is to establish a causal link between the policies\nimplemented by technology companies and the outcomes they yield within\nintricate temporal and/or spatial dependent experiments. We propose a novel\ntemporal/spatio-temporal Varying Coefficient Decision Process (VCDP) model,\ncapable of effectively capturing the evolving treatment effects in situations\ncharacterized by temporal and/or spatial dependence. Our methodology\nencompasses the decomposition of the Average Treatment Effect (ATE) into the\nDirect Effect (DE) and the Indirect Effect (IE). We subsequently devise\ncomprehensive procedures for estimating and making inferences about both DE and\nIE. Additionally, we provide a rigorous analysis of the statistical properties\nof these procedures, such as asymptotic power. To substantiate the\neffectiveness of our approach, we carry out extensive simulations and real data\nanalyses.\n",
                "链接": "https://arxiv.org/abs/2202.10887"
            },
            {
                "文章ID": "105774",
                "标题": "DST-Det: Simple Dynamic Self-Training for Open-Vocabulary Object\n  Detection",
                "作者": " Shilin Xu,  Xiangtai Li,  Size Wu,  Wenwei Zhang,  Yining Li,  Guangliang Cheng,  Yunhai Tong,  Kai Chen,  Chen Change Loy",
                "发布日期": "2023-12-27",
                "摘要": "  Open-vocabulary object detection (OVOD) aims to detect the objects beyond the\nset of classes observed during training. This work presents a simple yet\neffective strategy that leverages the zero-shot classification ability of\npre-trained vision-language models (VLM), such as CLIP, to directly discover\nproposals of possible novel classes. Unlike previous works that ignore novel\nclasses during training and rely solely on the region proposal network (RPN)\nfor novel object detection, our method selectively filters proposals based on\nspecific design criteria. The resulting sets of identified proposals serve as\npseudo-labels of potential novel classes during the training phase. This\nself-training strategy improves the recall and accuracy of novel classes\nwithout requiring additional annotations or datasets. We further propose a\nsimple offline pseudo-label generation strategy to refine the object detector.\nEmpirical evaluations on three datasets, including LVIS, V3Det, and COCO,\ndemonstrate significant improvements over the baseline performance without\nincurring additional parameters or computational costs during inference. In\nparticular, compared with previous F-VLM, our method achieves a 1.7\\%\nimprovement on the LVIS dataset. We also achieve over 6.5\\% improvement on the\nrecent challenging V3Det dataset. When combined with the recent method\nCLIPSelf, our method also achieves 46.7 novel class AP on COCO without\nintroducing extra data for pertaining.\n",
                "链接": "https://arxiv.org/abs/2310.01393"
            },
            {
                "文章ID": "46848",
                "标题": "MultiWOZ-DF -- A Dataflow implementation of the MultiWOZ dataset",
                "作者": " Joram Meron,  Victor Guimarães",
                "发布日期": "2022-11-07",
                "摘要": "  Semantic Machines (SM) have introduced the use of the dataflow (DF) paradigm\nto dialogue modelling, using computational graphs to hierarchically represent\nuser requests, data, and the dialogue history [Semantic Machines et al. 2020].\nAlthough the main focus of that paper was the SMCalFlow dataset (to date, the\nonly dataset with \"native\" DF annotations), they also reported some results of\nan experiment using a transformed version of the commonly used MultiWOZ dataset\n[Budzianowski et al. 2018] into a DF format. In this paper, we expand the\nexperiments using DF for the MultiWOZ dataset, exploring some additional\nexperimental set-ups. The code and instructions to reproduce the experiments\nreported here have been released. The contributions of this paper are: 1.) A DF\nimplementation capable of executing MultiWOZ dialogues; 2.) Several versions of\nconversion of MultiWOZ into a DF format are presented; 3.) Experimental results\non state match and translation accuracy.\n",
                "链接": "https://arxiv.org/abs/2211.02303"
            },
            {
                "文章ID": "99195",
                "标题": "Papeos: Augmenting Research Papers with Talk Videos",
                "作者": " Tae Soo Kim,  Matt Latzke,  Jonathan Bragg,  Amy X. Zhang,  Joseph Chee Chang",
                "发布日期": "2023-08-30",
                "摘要": "  Research consumption has been traditionally limited to the reading of\nacademic papers-a static, dense, and formally written format. Alternatively,\npre-recorded conference presentation videos, which are more dynamic, concise,\nand colloquial, have recently become more widely available but potentially\nunder-utilized. In this work, we explore the design space and benefits for\ncombining academic papers and talk videos to leverage their complementary\nnature to provide a rich and fluid research consumption experience. Based on\nformative and co-design studies, we present Papeos, a novel reading and\nauthoring interface that allow authors to augment their papers by segmenting\nand localizing talk videos alongside relevant paper passages with automatically\ngenerated suggestions. With Papeos, readers can visually skim a paper through\nclip thumbnails, and fluidly switch between consuming dense text in the paper\nor visual summaries in the video. In a comparative lab study (n=16), Papeos\nreduced mental load, scaffolded navigation, and facilitated more comprehensive\nreading of papers.\n",
                "链接": "https://arxiv.org/abs/2308.15224"
            },
            {
                "文章ID": "114218",
                "标题": "Gender Inflected or Bias Inflicted: On Using Grammatical Gender Cues for\n  Bias Evaluation in Machine Translation",
                "作者": " Pushpdeep Singh",
                "发布日期": "2023-11-08",
                "摘要": "  Neural Machine Translation (NMT) models are state-of-the-art for machine\ntranslation. However, these models are known to have various social biases,\nespecially gender bias. Most of the work on evaluating gender bias in NMT has\nfocused primarily on English as the source language. For source languages\ndifferent from English, most of the studies use gender-neutral sentences to\nevaluate gender bias. However, practically, many sentences that we encounter do\nhave gender information. Therefore, it makes more sense to evaluate for bias\nusing such sentences. This allows us to determine if NMT models can identify\nthe correct gender based on the grammatical gender cues in the source sentence\nrather than relying on biased correlations with, say, occupation terms. To\ndemonstrate our point, in this work, we use Hindi as the source language and\nconstruct two sets of gender-specific sentences: OTSC-Hindi and WinoMT-Hindi\nthat we use to evaluate different Hindi-English (HI-EN) NMT systems\nautomatically for gender bias. Our work highlights the importance of\nconsidering the nature of language when designing such extrinsic bias\nevaluation datasets.\n",
                "链接": "https://arxiv.org/abs/2311.03767"
            },
            {
                "文章ID": "68598",
                "标题": "Decision-aid or Controller? Steering Human Decision Makers with\n  Algorithms",
                "作者": " Ruqing Xu,  Sarah Dean",
                "发布日期": "2023-03-27",
                "摘要": "  Algorithms are used to aid human decision makers by making predictions and\nrecommending decisions. Currently, these algorithms are trained to optimize\nprediction accuracy. What if they were optimized to control final decisions? In\nthis paper, we study a decision-aid algorithm that learns about the human\ndecision maker and provides ''personalized recommendations'' to influence final\ndecisions. We first consider fixed human decision functions which map\nobservable features and the algorithm's recommendations to final decisions. We\ncharacterize the conditions under which perfect control over final decisions is\nattainable. Under fairly general assumptions, the parameters of the human\ndecision function can be identified from past interactions between the\nalgorithm and the human decision maker, even when the algorithm was constrained\nto make truthful recommendations. We then consider a decision maker who is\naware of the algorithm's manipulation and responds strategically. By posing the\nsetting as a variation of the cheap talk game [Crawford and Sobel, 1982], we\nshow that all equilibria are partition equilibria where only coarse information\nis shared: the algorithm recommends an interval containing the ideal decision.\nWe discuss the potential applications of such algorithms and their social\nimplications.\n",
                "链接": "https://arxiv.org/abs/2303.13712"
            },
            {
                "文章ID": "11176",
                "标题": "4D-OR: Semantic Scene Graphs for OR Domain Modeling",
                "作者": " Ege Özsoy,  Evin Pınar Örnek,  Ulrich Eck,  Tobias Czempiel,  Federico Tombari,  Nassir Navab",
                "发布日期": "2022-03-23",
                "摘要": "  Surgical procedures are conducted in highly complex operating rooms (OR),\ncomprising different actors, devices, and interactions. To date, only medically\ntrained human experts are capable of understanding all the links and\ninteractions in such a demanding environment. This paper aims to bring the\ncommunity one step closer to automated, holistic and semantic understanding and\nmodeling of OR domain. Towards this goal, for the first time, we propose using\nsemantic scene graphs (SSG) to describe and summarize the surgical scene. The\nnodes of the scene graphs represent different actors and objects in the room,\nsuch as medical staff, patients, and medical equipment, whereas edges are the\nrelationships between them. To validate the possibilities of the proposed\nrepresentation, we create the first publicly available 4D surgical SSG dataset,\n4D-OR, containing ten simulated total knee replacement surgeries recorded with\nsix RGB-D sensors in a realistic OR simulation center. 4D-OR includes 6734\nframes and is richly annotated with SSGs, human and object poses, and clinical\nroles. We propose an end-to-end neural network-based SSG generation pipeline,\nwith a rate of success of 0.75 macro F1, indeed being able to infer semantic\nreasoning in the OR. We further demonstrate the representation power of our\nscene graphs by using it for the problem of clinical role prediction, where we\nachieve 0.85 macro F1. The code and dataset will be made available upon\nacceptance.\n",
                "链接": "https://arxiv.org/abs/2203.11937"
            },
            {
                "文章ID": "28598",
                "标题": "COO: Comic Onomatopoeia Dataset for Recognizing Arbitrary or Truncated\n  Texts",
                "作者": " Jeonghun Baek,  Yusuke Matsui,  Kiyoharu Aizawa",
                "发布日期": "2022-07-12",
                "摘要": "  Recognizing irregular texts has been a challenging topic in text recognition.\nTo encourage research on this topic, we provide a novel comic onomatopoeia\ndataset (COO), which consists of onomatopoeia texts in Japanese comics. COO has\nmany arbitrary texts, such as extremely curved, partially shrunk texts, or\narbitrarily placed texts. Furthermore, some texts are separated into several\nparts. Each part is a truncated text and is not meaningful by itself. These\nparts should be linked to represent the intended meaning. Thus, we propose a\nnovel task that predicts the link between truncated texts. We conduct three\ntasks to detect the onomatopoeia region and capture its intended meaning: text\ndetection, text recognition, and link prediction. Through extensive\nexperiments, we analyze the characteristics of the COO. Our data and code are\navailable at \\url{https://github.com/ku21fan/COO-Comic-Onomatopoeia}.\n",
                "链接": "https://arxiv.org/abs/2207.04675"
            },
            {
                "文章ID": "82872",
                "标题": "In or Out? Fixing ImageNet Out-of-Distribution Detection Evaluation",
                "作者": " Julian Bitterwolf,  Maximilian Müller,  Matthias Hein",
                "发布日期": "2023-06-02",
                "摘要": "  Out-of-distribution (OOD) detection is the problem of identifying inputs\nwhich are unrelated to the in-distribution task. The OOD detection performance\nwhen the in-distribution (ID) is ImageNet-1K is commonly being tested on a\nsmall range of test OOD datasets. We find that most of the currently used test\nOOD datasets, including datasets from the open set recognition (OSR)\nliterature, have severe issues: In some cases more than 50$\\%$ of the dataset\ncontains objects belonging to one of the ID classes. These erroneous samples\nheavily distort the evaluation of OOD detectors. As a solution, we introduce\nwith NINCO a novel test OOD dataset, each sample checked to be ID free, which\nwith its fine-grained range of OOD classes allows for a detailed analysis of an\nOOD detector's strengths and failure modes, particularly when paired with a\nnumber of synthetic \"OOD unit-tests\". We provide detailed evaluations across a\nlarge set of architectures and OOD detection methods on NINCO and the\nunit-tests, revealing new insights about model weaknesses and the effects of\npretraining on OOD detection performance. We provide code and data at\nhttps://github.com/j-cb/NINCO.\n",
                "链接": "https://arxiv.org/abs/2306.00826"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下使用机器学习方法进行心理健康疾病研究的论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "98633",
                "标题": "Discovering Mental Health Research Topics with Topic Modeling",
                "作者": " Xin Gao,  Cem Sazara",
                "发布日期": "2023-08-29",
                "摘要": "  Mental health significantly influences various aspects of our daily lives,\nand its importance has been increasingly recognized by the research community\nand the general public, particularly in the wake of the COVID-19 pandemic. This\nheightened interest is evident in the growing number of publications dedicated\nto mental health in the past decade. In this study, our goal is to identify\ngeneral trends in the field and pinpoint high-impact research topics by\nanalyzing a large dataset of mental health research papers. To accomplish this,\nwe collected abstracts from various databases and trained a customized\nSentence-BERT based embedding model leveraging the BERTopic framework. Our\ndataset comprises 96,676 research papers pertaining to mental health, enabling\nus to examine the relationships between different topics using their abstracts.\nTo evaluate the effectiveness of the model, we compared it against two other\nstate-of-the-art methods: Top2Vec model and LDA-BERT model. The model\ndemonstrated superior performance in metrics that measure topic diversity and\ncoherence. To enhance our analysis, we also generated word clouds to provide a\ncomprehensive overview of the machine learning models applied in mental health\nresearch, shedding light on commonly utilized techniques and emerging trends.\nFurthermore, we provide a GitHub link* to the dataset used in this paper,\nensuring its accessibility for further research endeavors.\n",
                "链接": "https://arxiv.org/abs/2308.13569"
            },
            {
                "文章ID": "20900",
                "标题": "Bias Discovery in Machine Learning Models for Mental Health",
                "作者": " Pablo Mosteiro,  Jesse Kuiper,  Judith Masthoff,  Floortje Scheepers,  Marco Spruit",
                "发布日期": "2022-05-25",
                "摘要": "  Fairness and bias are crucial concepts in artificial intelligence, yet they\nare relatively ignored in machine learning applications in clinical psychiatry.\nWe computed fairness metrics and present bias mitigation strategies using a\nmodel trained on clinical mental health data. We collected structured data\nrelated to the admission, diagnosis, and treatment of patients in the\npsychiatry department of the University Medical Center Utrecht. We trained a\nmachine learning model to predict future administrations of benzodiazepines on\nthe basis of past data. We found that gender plays an unexpected role in the\npredictions-this constitutes bias. Using the AI Fairness 360 package, we\nimplemented reweighing and discrimination-aware regularization as bias\nmitigation strategies, and we explored their implications for model\nperformance. This is the first application of bias exploration and mitigation\nin a machine learning model trained on real clinical psychiatry data.\n",
                "链接": "https://arxiv.org/abs/2205.12093"
            },
            {
                "文章ID": "32886",
                "标题": "Research on restaurant recommendation using machine learning",
                "作者": " Junan Pan,  Zhihao Zhao",
                "发布日期": "2022-08-11",
                "摘要": "  A recommender system is a system that helps users filter irrelevant\ninformation and create user interest models based on their historical records.\nWith the continuous development of Internet information, recommendation systems\nhave received widespread attention in the industry. In this era of ubiquitous\ndata and information, how to obtain and analyze these data has become the\nresearch topic of many people. In view of this situation, this paper makes some\nbrief overviews of machine learning-related recommendation systems. By\nanalyzing some technologies and ideas used by machine learning in recommender\nsystems, let more people understand what is Big data and what is machine\nlearning. The most important point is to let everyone understand the profound\nimpact of machine learning on our daily life.\n",
                "链接": "https://arxiv.org/abs/2208.05113"
            },
            {
                "文章ID": "32474",
                "标题": "Bias Reducing Multitask Learning on Mental Health Prediction",
                "作者": " Khadija Zanna,  Kusha Sridhar,  Han Yu,  Akane Sano",
                "发布日期": "2022-08-09",
                "摘要": "  There has been an increase in research in developing machine learning models\nfor mental health detection or prediction in recent years due to increased\nmental health issues in society. Effective use of mental health prediction or\ndetection models can help mental health practitioners re-define mental\nillnesses more objectively than currently done, and identify illnesses at an\nearlier stage when interventions may be more effective. However, there is still\na lack of standard in evaluating bias in such machine learning models in the\nfield, which leads to challenges in providing reliable predictions and in\naddressing disparities. This lack of standards persists due to factors such as\ntechnical difficulties, complexities of high dimensional clinical health data,\netc., which are especially true for physiological signals. This along with\nprior evidence of relations between some physiological signals with certain\ndemographic identities restates the importance of exploring bias in mental\nhealth prediction models that utilize physiological signals. In this work, we\naim to perform a fairness analysis and implement a multi-task learning based\nbias mitigation method on anxiety prediction models using ECG data. Our method\nis based on the idea of epistemic uncertainty and its relationship with model\nweights and feature space representation. Our analysis showed that our anxiety\nprediction base model introduced some bias with regards to age, income,\nethnicity, and whether a participant is born in the U.S. or not, and our bias\nmitigation method performed better at reducing the bias in the model, when\ncompared to the reweighting mitigation technique. Our analysis on feature\nimportance also helped identify relationships between heart rate variability\nand multiple demographic groupings.\n",
                "链接": "https://arxiv.org/abs/2208.03621"
            },
            {
                "文章ID": "38457",
                "标题": "Common human diseases prediction using machine learning based on survey\n  data",
                "作者": " Jabir Al Nahian,  Abu Kaisar Mohammad Masum,  Sheikh Abujar,  Md. Jueal Mia",
                "发布日期": "2022-09-23",
                "摘要": "  In this era, the moment has arrived to move away from disease as the primary\nemphasis of medical treatment. Although impressive, the multiple techniques\nthat have been developed to detect the diseases. In this time, there are some\ntypes of diseases COVID-19, normal flue, migraine, lung disease, heart disease,\nkidney disease, diabetics, stomach disease, gastric, bone disease, autism are\nthe very common diseases. In this analysis, we analyze disease symptoms and\nhave done disease predictions based on their symptoms. We studied a range of\nsymptoms and took a survey from people in order to complete the task. Several\nclassification algorithms have been employed to train the model. Furthermore,\nperformance evaluation matrices are used to measure the model's performance.\nFinally, we discovered that the part classifier surpasses the others.\n",
                "链接": "https://arxiv.org/abs/2209.10750"
            },
            {
                "文章ID": "116611",
                "标题": "Classification Methods Based on Machine Learning for the Analysis of\n  Fetal Health Data",
                "作者": " Binod Regmi,  Chiranjibi Shah",
                "发布日期": "2023-11-21",
                "摘要": "  The persistent battle to decrease childhood mortality serves as a commonly\nemployed benchmark for gauging advancements in the field of medicine. Globally,\nthe under-5 mortality rate stands at approximately 5 million, with a\nsignificant portion of these deaths being avoidable. Given the significance of\nthis problem, Machine learning-based techniques have emerged as a prominent\ntool for assessing fetal health. In this work, we have analyzed the\nclassification performance of various machine learning models for fetal health\nanalysis. Classification performance of various machine learning models, such\nas support vector machine (SVM), random forest(RF), and attentive interpretable\ntabular learning (TabNet) have been assessed on fetal health. Moreover,\ndimensionality reduction techniques, such as Principal component analysis (PCA)\nand Linear discriminant analysis (LDA) have been implemented to obtain better\nclassification performance with less number of features. A TabNet model on a\nfetal health dataset provides a classification accuracy of 94.36%. In general,\nthis technology empowers doctors and healthcare experts to achieve precise\nfetal health classification and identify the most influential features in the\nprocess.\n",
                "链接": "https://arxiv.org/abs/2311.10962"
            },
            {
                "文章ID": "57937",
                "标题": "Deep Learning Mental Health Dialogue System",
                "作者": " Lennart Brocki,  George C. Dyer,  Anna Gładka,  Neo Christopher Chung",
                "发布日期": "2023-01-24",
                "摘要": "  Mental health counseling remains a major challenge in modern society due to\ncost, stigma, fear, and unavailability. We posit that generative artificial\nintelligence (AI) models designed for mental health counseling could help\nimprove outcomes by lowering barriers to access. To this end, we have developed\na deep learning (DL) dialogue system called Serena. The system consists of a\ncore generative model and post-processing algorithms. The core generative model\nis a 2.7 billion parameter Seq2Seq Transformer fine-tuned on thousands of\ntranscripts of person-centered-therapy (PCT) sessions. The series of\npost-processing algorithms detects contradictions, improves coherency, and\nremoves repetitive answers. Serena is implemented and deployed on\n\\url{https://serena.chat}, which currently offers limited free services. While\nthe dialogue system is capable of responding in a qualitatively empathetic and\nengaging manner, occasionally it displays hallucination and long-term\nincoherence. Overall, we demonstrate that a deep learning mental health\ndialogue system has the potential to provide a low-cost and effective\ncomplement to traditional human counselors with less barriers to access.\n",
                "链接": "https://arxiv.org/abs/2301.09412"
            },
            {
                "文章ID": "56312",
                "标题": "Causal Categorization of Mental Health Posts using Transformers",
                "作者": " Simranjeet Kaur,  Ritika Bhardwaj,  Aastha Jain,  Muskan Garg,  Chandni Saxena",
                "发布日期": "2023-01-18",
                "摘要": "  With recent developments in digitization of clinical psychology, NLP research\ncommunity has revolutionized the field of mental health detection on social\nmedia. Existing research in mental health analysis revolves around the\ncross-sectional studies to classify users' intent on social media. For in-depth\nanalysis, we investigate existing classifiers to solve the problem of causal\ncategorization which suggests the inefficiency of learning based methods due to\nlimited training samples. To handle this challenge, we use transformer models\nand demonstrate the efficacy of a pre-trained transfer learning on \"CAMS\"\ndataset. The experimental result improves the accuracy and depicts the\nimportance of identifying cause-and-effect relationships in the underlying\ntext.\n",
                "链接": "https://arxiv.org/abs/2301.02589"
            },
            {
                "文章ID": "21978",
                "标题": "Machine Learning Methods for Health-Index Prediction in Coating Chambers",
                "作者": " Clemens Heistracher,  Anahid Jalali,  Jürgen Schneeweiss,  Klaudia Kovacs,  Catherine Laflamme,  Bernhard Haslhofer",
                "发布日期": "2022-05-31",
                "摘要": "  Coating chambers create thin layers that improve the mechanical and optical\nsurface properties in jewelry production using physical vapor deposition. In\nsuch a process, evaporated material condensates on the walls of such chambers\nand, over time, causes mechanical defects and unstable processes. As a result,\nmanufacturers perform extensive maintenance procedures to reduce production\nloss. Current rule-based maintenance strategies neglect the impact of specific\nrecipes and the actual condition of the vacuum chamber. Our overall goal is to\npredict the future condition of the coating chamber to allow cost and quality\noptimized maintenance of the equipment. This paper describes the derivation of\na novel health indicator that serves as a step toward condition-based\nmaintenance for coating chambers. We indirectly use gas emissions of the\nchamber's contamination to evaluate the machine's condition. Our approach\nrelies on process data and does not require additional hardware installation.\nFurther, we evaluated multiple machine learning algorithms for a\ncondition-based forecast of the health indicator that also reflects production\nplanning. Our results show that models based on decision trees are the most\neffective and outperform all three benchmarks, improving at least $0.22$ in the\nmean average error. Our work paves the way for cost and quality optimized\nmaintenance of coating applications.\n",
                "链接": "https://arxiv.org/abs/2205.15145"
            },
            {
                "文章ID": "1267",
                "标题": "Mental Health Assessment for the Chatbots",
                "作者": " Yong Shan,  Jinchao Zhang,  Zekang Li,  Yang Feng,  Jie Zhou",
                "发布日期": "2022-01-17",
                "摘要": "  Previous researches on dialogue system assessment usually focus on the\nquality evaluation (e.g. fluency, relevance, etc) of responses generated by the\nchatbots, which are local and technical metrics. For a chatbot which responds\nto millions of online users including minors, we argue that it should have a\nhealthy mental tendency in order to avoid the negative psychological impact on\nthem. In this paper, we establish several mental health assessment dimensions\nfor chatbots (depression, anxiety, alcohol addiction, empathy) and introduce\nthe questionnaire-based mental health assessment methods. We conduct\nassessments on some well-known open-domain chatbots and find that there are\nsevere mental health issues for all these chatbots. We consider that it is due\nto the neglect of the mental health risks during the dataset building and the\nmodel training procedures. We expect to attract researchers' attention to the\nserious mental health problems of chatbots and improve the chatbots' ability in\npositive emotional interaction.\n",
                "链接": "https://arxiv.org/abs/2201.05382"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "69437",
                "标题": "Medical Image Analysis using Deep Relational Learning",
                "作者": " Zhihua Liu",
                "发布日期": "2023-03-29",
                "摘要": "  In the past ten years, with the help of deep learning, especially the rapid\ndevelopment of deep neural networks, medical image analysis has made remarkable\nprogress. However, how to effectively use the relational information between\nvarious tissues or organs in medical images is still a very challenging\nproblem, and it has not been fully studied. In this thesis, we propose two\nnovel solutions to this problem based on deep relational learning. First, we\npropose a context-aware fully convolutional network that effectively models\nimplicit relation information between features to perform medical image\nsegmentation. The network achieves the state-of-the-art segmentation results on\nthe Multi Modal Brain Tumor Segmentation 2017 (BraTS2017) and Multi Modal Brain\nTumor Segmentation 2018 (BraTS2018) data sets. Subsequently, we propose a new\nhierarchical homography estimation network to achieve accurate medical image\nmosaicing by learning the explicit spatial relationship between adjacent\nframes. We use the UCL Fetoscopy Placenta dataset to conduct experiments and\nour hierarchical homography estimation network outperforms the other\nstate-of-the-art mosaicing methods while generating robust and meaningful\nmosaicing result on unseen frames.\n",
                "链接": "https://arxiv.org/abs/2303.16099"
            },
            {
                "文章ID": "65067",
                "标题": "Evaluating the Fairness of Deep Learning Uncertainty Estimates in\n  Medical Image Analysis",
                "作者": " Raghav Mehta,  Changjian Shui,  Tal Arbel",
                "发布日期": "2023-03-07",
                "摘要": "  Although deep learning (DL) models have shown great success in many medical\nimage analysis tasks, deployment of the resulting models into real clinical\ncontexts requires: (1) that they exhibit robustness and fairness across\ndifferent sub-populations, and (2) that the confidence in DL model predictions\nbe accurately expressed in the form of uncertainties. Unfortunately, recent\nstudies have indeed shown significant biases in DL models across demographic\nsubgroups (e.g., race, sex, age) in the context of medical image analysis,\nindicating a lack of fairness in the models. Although several methods have been\nproposed in the ML literature to mitigate a lack of fairness in DL models, they\nfocus entirely on the absolute performance between groups without considering\ntheir effect on uncertainty estimation. In this work, we present the first\nexploration of the effect of popular fairness models on overcoming biases\nacross subgroups in medical image analysis in terms of bottom-line performance,\nand their effects on uncertainty quantification. We perform extensive\nexperiments on three different clinically relevant tasks: (i) skin lesion\nclassification, (ii) brain tumour segmentation, and (iii) Alzheimer's disease\nclinical score regression. Our results indicate that popular ML methods, such\nas data-balancing and distributionally robust optimization, succeed in\nmitigating fairness issues in terms of the model performances for some of the\ntasks. However, this can come at the cost of poor uncertainty estimates\nassociated with the model predictions. This tradeoff must be mitigated if\nfairness models are to be adopted in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2303.03242"
            },
            {
                "文章ID": "36669",
                "标题": "Bridging the Gap: Differentially Private Equivariant Deep Learning for\n  Medical Image Analysis",
                "作者": " Florian A. Hölzl,  Daniel Rueckert,  Georgios Kaissis",
                "发布日期": "2023-06-21",
                "摘要": "  Machine learning with formal privacy-preserving techniques like Differential\nPrivacy (DP) allows one to derive valuable insights from sensitive medical\nimaging data while promising to protect patient privacy, but it usually comes\nat a sharp privacy-utility trade-off. In this work, we propose to use steerable\nequivariant convolutional networks for medical image analysis with DP. Their\nimproved feature quality and parameter efficiency yield remarkable accuracy\ngains, narrowing the privacy-utility gap.\n",
                "链接": "https://arxiv.org/abs/2209.04338"
            },
            {
                "文章ID": "2124",
                "标题": "The Security of Deep Learning Defences for Medical Imaging",
                "作者": " Moshe Levy,  Guy Amit,  Yuval Elovici,  Yisroel Mirsky",
                "发布日期": "2022-01-24",
                "摘要": "  Deep learning has shown great promise in the domain of medical image\nanalysis. Medical professionals and healthcare providers have been adopting the\ntechnology to speed up and enhance their work. These systems use deep neural\nnetworks (DNN) which are vulnerable to adversarial samples; images with\nimperceivable changes that can alter the model's prediction. Researchers have\nproposed defences which either make a DNN more robust or detect the adversarial\nsamples before they do harm. However, none of these works consider an informed\nattacker which can adapt to the defence mechanism. We show that an informed\nattacker can evade five of the current state of the art defences while\nsuccessfully fooling the victim's deep learning model, rendering these defences\nuseless. We then suggest better alternatives for securing healthcare DNNs from\nsuch attacks: (1) harden the system's security and (2) use digital signatures.\n",
                "链接": "https://arxiv.org/abs/2201.08661"
            },
            {
                "文章ID": "43911",
                "标题": "Reproducibility of the Methods in Medical Imaging with Deep Learning",
                "作者": " Attila Simko,  Anders Garpebring,  Joakim Jonsson,  Tufve Nyholm,  Tommy Löfstedt",
                "发布日期": "2022-10-21",
                "摘要": "  Concerns about the reproducibility of deep learning research are more\nprominent than ever, with no clear solution in sight. The relevance of machine\nlearning research can only be improved if we also employ empirical rigor that\nincorporates reproducibility guidelines, especially so in the medical imaging\nfield. The Medical Imaging with Deep Learning (MIDL) conference has made\nadvancements in this direction by advocating open access, and recently also\nrecommending authors to make their code public - both aspects being adopted by\nthe majority of the conference submissions. This helps the reproducibility of\nthe methods, however, there is currently little or no support for further\nevaluation of these supplementary material, making them vulnerable to poor\nquality, which affects the impact of the entire submission. We have evaluated\nall accepted full paper submissions to MIDL between 2018 and 2022 using\nestablished, but slightly adjusted guidelines on reproducibility and the\nquality of the public repositories. The evaluations show that publishing\nrepositories and using public datasets are becoming more popular, which helps\ntraceability, but the quality of the repositories has not improved over the\nyears, leaving room for improvement in every aspect of designing repositories.\nMerely 22% of all submissions contain a repository that were deemed repeatable\nusing our evaluations. From the commonly encountered issues during the\nevaluations, we propose a set of guidelines for machine learning-related\nresearch for medical imaging applications, adjusted specifically for future\nsubmissions to MIDL.\n",
                "链接": "https://arxiv.org/abs/2210.11146"
            },
            {
                "文章ID": "56274",
                "标题": "Deep-learning models in medical image analysis: Detection of esophagitis\n  from the Kvasir Dataset",
                "作者": " Kyoka Yoshiok,  Kensuke Tanioka,  Satoru Hiwa,  Tomoyuki Hiroyasu",
                "发布日期": "2023-01-09",
                "摘要": "  Early detection of esophagitis is important because this condition can\nprogress to cancer if left untreated. However, the accuracies of different deep\nlearning models in detecting esophagitis have yet to be compared. Thus, this\nstudy aimed to compare the accuracies of convolutional neural network models\n(GoogLeNet, ResNet-50, MobileNet V2, and MobileNet V3) in detecting esophagitis\nfrom the open Kvasir dataset of endoscopic images. Results showed that among\nthe models, GoogLeNet achieved the highest F1-scores. Based on the average of\ntrue positive rate, MobileNet V3 predicted esophagitis more confidently than\nthe other models. The results obtained using the models were also compared with\nthose obtained using SHapley Additive exPlanations and Gradient-weighted Class\nActivation Mapping.\n",
                "链接": "https://arxiv.org/abs/2301.02390"
            },
            {
                "文章ID": "52332",
                "标题": "A Trustworthy Framework for Medical Image Analysis with Deep Learning",
                "作者": " Kai Ma,  Siyuan He,  Pengcheng Xi,  Ashkan Ebadi,  Stéphane Tremblay,  Alexander Wong",
                "发布日期": "2022-12-07",
                "摘要": "  Computer vision and machine learning are playing an increasingly important\nrole in computer-assisted diagnosis; however, the application of deep learning\nto medical imaging has challenges in data availability and data imbalance, and\nit is especially important that models for medical imaging are built to be\ntrustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning\nframework for medical image analysis, which adopts a modular design, leverages\nself-supervised pre-training, and utilizes a novel surrogate loss function.\nExperimental evaluations indicate that models generated from the framework are\nboth trustworthy and high-performing. It is anticipated that the framework will\nsupport researchers and clinicians in advancing the use of deep learning for\ndealing with public health crises including COVID-19.\n",
                "链接": "https://arxiv.org/abs/2212.02764"
            },
            {
                "文章ID": "107726",
                "标题": "Data efficient deep learning for medical image analysis: A survey",
                "作者": " Suruchi Kumari,  Pravendra Singh",
                "发布日期": "2023-10-11",
                "摘要": "  The rapid evolution of deep learning has significantly advanced the field of\nmedical image analysis. However, despite these achievements, the further\nenhancement of deep learning models for medical image analysis faces a\nsignificant challenge due to the scarcity of large, well-annotated datasets. To\naddress this issue, recent years have witnessed a growing emphasis on the\ndevelopment of data-efficient deep learning methods. This paper conducts a\nthorough review of data-efficient deep learning methods for medical image\nanalysis. To this end, we categorize these methods based on the level of\nsupervision they rely on, encompassing categories such as no supervision,\ninexact supervision, incomplete supervision, inaccurate supervision, and only\nlimited supervision. We further divide these categories into finer\nsubcategories. For example, we categorize inexact supervision into multiple\ninstance learning and learning with weak annotations. Similarly, we categorize\nincomplete supervision into semi-supervised learning, active learning, and\ndomain-adaptive learning and so on. Furthermore, we systematically summarize\ncommonly used datasets for data efficient deep learning in medical image\nanalysis and investigate future research directions to conclude this survey.\n",
                "链接": "https://arxiv.org/abs/2310.06557"
            },
            {
                "文章ID": "5953",
                "标题": "An overview of deep learning in medical imaging",
                "作者": " Imran Ul Haq",
                "发布日期": "2022-02-18",
                "摘要": "  Machine learning (ML) has seen enormous consideration during the most recent\ndecade. This success started in 2012 when an ML model accomplished a remarkable\ntriumph in the ImageNet Classification, the world's most famous competition for\ncomputer vision. This model was a kind of convolutional neural system (CNN)\ncalled deep learning (DL). Since then, researchers have started to participate\nefficiently in DL's fastest developing area of research. These days, DL systems\nare cutting-edge ML systems spanning a broad range of disciplines, from human\nlanguage processing to video analysis, and commonly used in the scholarly world\nand enterprise sector. Recent advances can bring tremendous improvement to the\nmedical field. Improved and innovative methods for data processing, image\nanalysis and can significantly improve the diagnostic technologies and\nmedicinal services gradually. A quick review of current developments with\nrelevant problems in the field of DL used for medical imaging has been\nprovided. The primary purposes of the review are four: (i) provide a brief\nprolog to DL by discussing different DL models, (ii) review of the DL usage for\nmedical image analysis (classification, detection, segmentation, and\nregistration), (iii) review seven main application fields of DL in medical\nimaging, (iv) give an initial stage to those keen on adding to the research\narea about DL in clinical imaging by providing links of some useful informative\nassets, such as freely available DL codes, public datasets Table 7, and medical\nimaging competition sources Table 8 and end our survey by outlining distinct\ncontinuous difficulties, lessons learned and future of DL in the field of\nmedical science.\n",
                "链接": "https://arxiv.org/abs/2202.08546"
            },
            {
                "文章ID": "54634",
                "标题": "Analysis of Explainable Artificial Intelligence Methods on Medical Image\n  Classification",
                "作者": " Vinay Jogani,  Joy Purohit,  Ishaan Shivhare,  Seema C Shrawne",
                "发布日期": "2023-04-05",
                "摘要": "  The use of deep learning in computer vision tasks such as image\nclassification has led to a rapid increase in the performance of such systems.\nDue to this substantial increment in the utility of these systems, the use of\nartificial intelligence in many critical tasks has exploded. In the medical\ndomain, medical image classification systems are being adopted due to their\nhigh accuracy and near parity with human physicians in many tasks. However,\nthese artificial intelligence systems are extremely complex and are considered\nblack boxes by scientists, due to the difficulty in interpreting what exactly\nled to the predictions made by these models. When these systems are being used\nto assist high-stakes decision-making, it is extremely important to be able to\nunderstand, verify and justify the conclusions reached by the model. The\nresearch techniques being used to gain insight into the black-box models are in\nthe field of explainable artificial intelligence (XAI). In this paper, we\nevaluated three different XAI methods across two convolutional neural network\nmodels trained to classify lung cancer from histopathological images. We\nvisualized the outputs and analyzed the performance of these methods, in order\nto better understand how to apply explainable artificial intelligence in the\nmedical domain.\n",
                "链接": "https://arxiv.org/abs/2212.10565"
            }
        ]
    },
    {
        "question": {
            "question": "查找基于优化实现模型越狱的文献",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "106864",
                "标题": "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language\n  Models",
                "作者": " Xiaogeng Liu,  Nan Xu,  Muhao Chen,  Chaowei Xiao",
                "发布日期": "2023-10-10",
                "摘要": "  The aligned Large Language Models (LLMs) are powerful language understanding\nand decision-making tools that are created through extensive alignment with\nhuman feedback. However, these large models remain susceptible to jailbreak\nattacks, where adversaries manipulate prompts to elicit malicious outputs that\nshould not be given by aligned LLMs. Investigating jailbreak prompts can lead\nus to delve into the limitations of LLMs and further guide us to secure them.\nUnfortunately, existing jailbreak techniques suffer from either (1) scalability\nissues, where attacks heavily rely on manual crafting of prompts, or (2)\nstealthiness problems, as attacks depend on token-based algorithms to generate\nprompts that are often semantically meaningless, making them susceptible to\ndetection through basic perplexity testing. In light of these challenges, we\nintend to answer this question: Can we develop an approach that can\nautomatically generate stealthy jailbreak prompts? In this paper, we introduce\nAutoDAN, a novel jailbreak attack against aligned LLMs. AutoDAN can\nautomatically generate stealthy jailbreak prompts by the carefully designed\nhierarchical genetic algorithm. Extensive evaluations demonstrate that AutoDAN\nnot only automates the process while preserving semantic meaningfulness, but\nalso demonstrates superior attack strength in cross-model transferability, and\ncross-sample universality compared with the baseline. Moreover, we also compare\nAutoDAN with perplexity-based defense methods and show that AutoDAN can bypass\nthem effectively.\n",
                "链接": "https://arxiv.org/abs/2310.04451"
            },
            {
                "文章ID": "93279",
                "标题": "Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal\n  Language Models",
                "作者": " Erfan Shayegani,  Yue Dong,  Nael Abu-Ghazaleh",
                "发布日期": "2023-10-12",
                "摘要": "  We introduce new jailbreak attacks on vision language models (VLMs), which\nuse aligned LLMs and are resilient to text-only jailbreak attacks.\nSpecifically, we develop cross-modality attacks on alignment where we pair\nadversarial images going through the vision encoder with textual prompts to\nbreak the alignment of the language model. Our attacks employ a novel\ncompositional strategy that combines an image, adversarially targeted towards\ntoxic embeddings, with generic prompts to accomplish the jailbreak. Thus, the\nLLM draws the context to answer the generic prompt from the adversarial image.\nThe generation of benign-appearing adversarial images leverages a novel\nembedding-space-based methodology, operating with no access to the LLM model.\nInstead, the attacks require access only to the vision encoder and utilize one\nof our four embedding space targeting strategies. By not requiring access to\nthe LLM, the attacks lower the entry barrier for attackers, particularly when\nvision encoders such as CLIP are embedded in closed-source LLMs. The attacks\nachieve a high success rate across different VLMs, highlighting the risk of\ncross-modality alignment vulnerabilities, and the need for new alignment\napproaches for multi-modal models.\n",
                "链接": "https://arxiv.org/abs/2307.14539"
            },
            {
                "文章ID": "106172",
                "标题": "Low-Resource Languages Jailbreak GPT-4",
                "作者": " Zheng-Xin Yong,  Cristina Menghini,  Stephen H. Bach",
                "发布日期": "2023-10-05",
                "摘要": "  AI safety training and red-teaming of large language models (LLMs) are\nmeasures to mitigate the generation of unsafe content. Our work exposes the\ninherent cross-lingual vulnerability of these safety mechanisms, resulting from\nthe linguistic inequality of safety training data, by successfully\ncircumventing GPT-4's safeguard through translating unsafe English inputs into\nlow-resource languages. On the AdvBenchmark, GPT-4 engages with the unsafe\ntranslated inputs and provides actionable items that can get the users towards\ntheir harmful goals 79% of the time, which is on par with or even surpassing\nstate-of-the-art jailbreaking attacks. Other high-/mid-resource languages have\nsignificantly lower attack success rate, which suggests that the cross-lingual\nvulnerability mainly applies to low-resource languages. Previously, limited\ntraining on low-resource languages primarily affects speakers of those\nlanguages, causing technological disparities. However, our work highlights a\ncrucial shift: this deficiency now poses a risk to all LLMs users. Publicly\navailable translation APIs enable anyone to exploit LLMs' safety\nvulnerabilities. Therefore, our work calls for a more holistic red-teaming\nefforts to develop robust multilingual safeguards with wide language coverage.\n",
                "链接": "https://arxiv.org/abs/2310.02446"
            },
            {
                "文章ID": "57469",
                "标题": "Optimization Algorithms in Smart Grids: A Systematic Literature Review",
                "作者": " Sidra Aslam,  Ala Altaweel,  Ali Bou Nassif",
                "发布日期": "2023-01-19",
                "摘要": "  Electrical smart grids are units that supply electricity from power plants to\nthe users to yield reduced costs, power failures/loss, and maximized energy\nmanagement. Smart grids (SGs) are well-known devices due to their exceptional\nbenefits such as bi-directional communication, stability, detection of power\nfailures, and inter-connectivity with appliances for monitoring purposes. SGs\nare the outcome of different modern applications that are used for managing\ndata and security, i.e., modeling, monitoring, optimization, and/or Artificial\nIntelligence. Hence, the importance of SGs as a research field is increasing\nwith every passing year. This paper focuses on novel features and applications\nof smart grids in domestic and industrial sectors. Specifically, we focused on\nGenetic algorithm, Particle Swarm Optimization, and Grey Wolf Optimization to\nstudy the efforts made up till date for maximized energy management and cost\nminimization in SGs. Therefore, we collected 145 research works (2011 to 2022)\nin this systematic literature review. This research work aims to figure out\ndifferent features and applications of SGs proposed in the last decade and\ninvestigate the trends in popularity of SGs for different regions of world. Our\nfinding is that the most popular optimization algorithm being used by\nresearchers to bring forward new solutions for energy management and cost\neffectiveness in SGs is Particle Swarm Optimization. We also provide a brief\noverview of objective functions and parameters used in the solutions for energy\nand cost effectiveness as well as discuss different open research challenges\nfor future research works.\n",
                "链接": "https://arxiv.org/abs/2301.07512"
            },
            {
                "文章ID": "44293",
                "标题": "FIND: An Unsupervised Implicit 3D Model of Articulated Human Feet",
                "作者": " Oliver Boyne,  James Charles,  Roberto Cipolla",
                "发布日期": "2022-11-23",
                "摘要": "  In this paper we present a high fidelity and articulated 3D human foot model.\nThe model is parameterised by a disentangled latent code in terms of shape,\ntexture and articulated pose. While high fidelity models are typically created\nwith strong supervision such as 3D keypoint correspondences or\npre-registration, we focus on the difficult case of little to no annotation. To\nthis end, we make the following contributions: (i) we develop a Foot Implicit\nNeural Deformation field model, named FIND, capable of tailoring explicit\nmeshes at any resolution i.e. for low or high powered devices; (ii) an approach\nfor training our model in various modes of weak supervision with progressively\nbetter disentanglement as more labels, such as pose categories, are provided;\n(iii) a novel unsupervised part-based loss for fitting our model to 2D images\nwhich is better than traditional photometric or silhouette losses; (iv)\nfinally, we release a new dataset of high resolution 3D human foot scans,\nFoot3D. On this dataset, we show our model outperforms a strong PCA\nimplementation trained on the same data in terms of shape quality and part\ncorrespondences, and that our novel unsupervised part-based loss improves\ninference on images.\n",
                "链接": "https://arxiv.org/abs/2210.12241"
            },
            {
                "文章ID": "107692",
                "标题": "Multilingual Jailbreak Challenges in Large Language Models",
                "作者": " Yue Deng,  Wenxuan Zhang,  Sinno Jialin Pan,  Lidong Bing",
                "发布日期": "2023-10-11",
                "摘要": "  While large language models (LLMs) exhibit remarkable capabilities across a\nwide range of tasks, they pose potential safety concerns, such as the\n``jailbreak'' problem, wherein malicious instructions can manipulate LLMs to\nexhibit undesirable behavior. Although several preventive measures have been\ndeveloped to mitigate the potential risks associated with LLMs, they have\nprimarily focused on English data. In this study, we reveal the presence of\nmultilingual jailbreak challenges within LLMs and consider two potential risk\nscenarios: unintentional and intentional. The unintentional scenario involves\nusers querying LLMs using non-English prompts and inadvertently bypassing the\nsafety mechanisms, while the intentional scenario concerns malicious users\ncombining malicious instructions with multilingual prompts to deliberately\nattack LLMs. The experimental results reveal that in the unintentional\nscenario, the rate of unsafe content increases as the availability of languages\ndecreases. Specifically, low-resource languages exhibit three times the\nlikelihood of encountering harmful content compared to high-resource languages,\nwith both ChatGPT and GPT-4. In the intentional scenario, multilingual prompts\ncan exacerbate the negative impact of malicious instructions, with\nastonishingly high rates of unsafe output: 80.92\\% for ChatGPT and 40.71\\% for\nGPT-4. To handle such a challenge in the multilingual context, we propose a\nnovel \\textsc{Self-Defense} framework that automatically generates multilingual\ntraining data for safety fine-tuning. Experimental results show that ChatGPT\nfine-tuned with such data can achieve a substantial reduction in unsafe content\ngeneration. Data is available at\nhttps://github.com/DAMO-NLP-SG/multilingual-safety-for-LLMs. Warning: This\npaper contains examples with potentially harmful content.\n",
                "链接": "https://arxiv.org/abs/2310.06474"
            },
            {
                "文章ID": "117817",
                "标题": "Universal Jailbreak Backdoors from Poisoned Human Feedback",
                "作者": " Javier Rando,  Florian Tramèr",
                "发布日期": "2023-11-27",
                "摘要": "  Reinforcement Learning from Human Feedback (RLHF) is used to align large\nlanguage models to produce helpful and harmless responses. Yet, prior work\nshowed these models can be jailbroken by finding adversarial prompts that\nrevert the model to its unaligned behavior. In this paper, we consider a new\nthreat where an attacker poisons the RLHF training data to embed a \"jailbreak\nbackdoor\" into the model. The backdoor embeds a trigger word into the model\nthat acts like a universal \"sudo command\": adding the trigger word to any\nprompt enables harmful responses without the need to search for an adversarial\nprompt. Universal jailbreak backdoors are much more powerful than previously\nstudied backdoors on language models, and we find they are significantly harder\nto plant using common backdoor attack techniques. We investigate the design\ndecisions in RLHF that contribute to its purported robustness, and release a\nbenchmark of poisoned models to stimulate future research on universal\njailbreak backdoors.\n",
                "链接": "https://arxiv.org/abs/2311.14455"
            },
            {
                "文章ID": "60419",
                "标题": "The Effect of Metadata on Scientific Literature Tagging: A Cross-Field\n  Cross-Model Study",
                "作者": " Yu Zhang,  Bowen Jin,  Qi Zhu,  Yu Meng,  Jiawei Han",
                "发布日期": "2023-10-24",
                "摘要": "  Due to the exponential growth of scientific publications on the Web, there is\na pressing need to tag each paper with fine-grained topics so that researchers\ncan track their interested fields of study rather than drowning in the whole\nliterature. Scientific literature tagging is beyond a pure multi-label text\nclassification task because papers on the Web are prevalently accompanied by\nmetadata information such as venues, authors, and references, which may serve\nas additional signals to infer relevant tags. Although there have been studies\nmaking use of metadata in academic paper classification, their focus is often\nrestricted to one or two scientific fields (e.g., computer science and\nbiomedicine) and to one specific model. In this work, we systematically study\nthe effect of metadata on scientific literature tagging across 19 fields. We\nselect three representative multi-label classifiers (i.e., a bag-of-words\nmodel, a sequence-based model, and a pre-trained language model) and explore\ntheir performance change in scientific literature tagging when metadata are fed\nto the classifiers as additional features. We observe some ubiquitous patterns\nof metadata's effects across all fields (e.g., venues are consistently\nbeneficial to paper tagging in almost all cases), as well as some unique\npatterns in fields other than computer science and biomedicine, which are not\nexplored in previous studies.\n",
                "链接": "https://arxiv.org/abs/2302.03341"
            },
            {
                "文章ID": "17493",
                "标题": "Real-Time BDI Agents: a model and its implementation",
                "作者": " Andrea Traldi,  Francesco Bruschetti,  Marco Robol,  Marco Roveri,  Paolo Giorgini",
                "发布日期": "2022-05-03",
                "摘要": "  The BDI model proved to be effective for developing applications requiring\nhigh-levels of autonomy and to deal with the complexity and unpredictability of\nreal-world scenarios. The model, however, has significant limitations in\nreacting and handling contingencies within the given real-time constraints.\nWithout an explicit representation of time, existing real-time BDI\nimplementations overlook the temporal implications during the agent's decision\nprocess that may result in delays or unresponsiveness of the system when it\ngets overloaded. In this paper, we redefine the BDI agent control loop inspired\nby well established algorithms for real-time systems to ensure a proper\nreaction of agents and their effective application in typical real-time\ndomains. Our model proposes an effective real-time management of goals, plans,\nand actions with respect to time constraints and resources availability. We\npropose an implementation of the model for a resource-collection video-game and\nwe validate the approach against a set of significant scenarios.\n",
                "链接": "https://arxiv.org/abs/2205.00979"
            },
            {
                "文章ID": "18874",
                "标题": "Supplementary Material: Implementation and Experiments for GAU-based\n  Model",
                "作者": " Zhenjie Liu",
                "发布日期": "2022-05-19",
                "摘要": "  In February this year Google proposed a new Transformer variant called FLASH,\nwhich has a faster speed, lower VRAM footprint and better performance. This is\nachieved by designing a performant layer named GAU (Gated Attention Unit),\nwhich combines the Attention layer and FFN. In this paper, some implementation\ndetails are re-analyzed both theoretically and practically. We then propose a\nnovel GAU-based model and pre-train it on a Chinese corpus. Results of the CLUE\nbenchmark show that our model achieves a dev average score of 75.02, 1% higher\nthan RoFormerV1 and being 45% faster, which is also competitive with\nRoFormerV2.\n",
                "链接": "https://arxiv.org/abs/2205.05842"
            }
        ]
    },
    {
        "question": {
            "question": "强化学习在大语言模型领域中应用的相关论文",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "91937",
                "标题": "Challenges and Applications of Large Language Models",
                "作者": " Jean Kaddour,  Joshua Harris,  Maximilian Mozes,  Herbie Bradley,  Roberta Raileanu,  Robert McHardy",
                "发布日期": "2023-07-20",
                "摘要": "  Large Language Models (LLMs) went from non-existent to ubiquitous in the\nmachine learning discourse within a few years. Due to the fast pace of the\nfield, it is difficult to identify the remaining challenges and already\nfruitful application areas. In this paper, we aim to establish a systematic set\nof open problems and application successes so that ML researchers can\ncomprehend the field's current state more quickly and become productive.\n",
                "链接": "https://arxiv.org/abs/2307.10169"
            },
            {
                "文章ID": "122505",
                "标题": "Evaluating Large Language Models for Health-related Queries with\n  Presuppositions",
                "作者": " Navreet Kaur,  Monojit Choudhury,  Danish Pruthi",
                "发布日期": "2023-12-15",
                "摘要": "  As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n",
                "链接": "https://arxiv.org/abs/2312.08800"
            },
            {
                "文章ID": "105928",
                "标题": "Can large language models provide useful feedback on research papers? A\n  large-scale empirical analysis",
                "作者": " Weixin Liang,  Yuhui Zhang,  Hancheng Cao,  Binglu Wang,  Daisy Ding,  Xinyu Yang,  Kailas Vodrahalli,  Siyu He,  Daniel Smith,  Yian Yin,  Daniel McFarland,  James Zou",
                "发布日期": "2023-10-04",
                "摘要": "  Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n",
                "链接": "https://arxiv.org/abs/2310.01783"
            },
            {
                "文章ID": "116733",
                "标题": "Rethinking Large Language Models in Mental Health Applications",
                "作者": " Shaoxiong Ji,  Tianlin Zhang,  Kailai Yang,  Sophia Ananiadou,  Erik Cambria",
                "发布日期": "2023-12-19",
                "摘要": "  Large Language Models (LLMs) have become valuable assets in mental health,\nshowing promise in both classification tasks and counseling applications. This\npaper offers a perspective on using LLMs in mental health applications. It\ndiscusses the instability of generative models for prediction and the potential\nfor generating hallucinatory outputs, underscoring the need for ongoing audits\nand evaluations to maintain their reliability and dependability. The paper also\ndistinguishes between the often interchangeable terms ``explainability'' and\n``interpretability'', advocating for developing inherently interpretable\nmethods instead of relying on potentially hallucinated self-explanations\ngenerated by LLMs. Despite the advancements in LLMs, human counselors'\nempathetic understanding, nuanced interpretation, and contextual awareness\nremain irreplaceable in the sensitive and complex realm of mental health\ncounseling. The use of LLMs should be approached with a judicious and\nconsiderate mindset, viewing them as tools that complement human expertise\nrather than seeking to replace it.\n",
                "链接": "https://arxiv.org/abs/2311.11267"
            },
            {
                "文章ID": "61474",
                "标题": "Guiding Pretraining in Reinforcement Learning with Large Language Models",
                "作者": " Yuqing Du,  Olivia Watkins,  Zihan Wang,  Cédric Colas,  Trevor Darrell,  Pieter Abbeel,  Abhishek Gupta,  Jacob Andreas",
                "发布日期": "2023-09-18",
                "摘要": "  Reinforcement learning algorithms typically struggle in the absence of a\ndense, well-shaped reward function. Intrinsically motivated exploration methods\naddress this limitation by rewarding agents for visiting novel states or\ntransitions, but these methods offer limited benefits in large environments\nwhere most discovered novelty is irrelevant for downstream tasks. We describe a\nmethod that uses background knowledge from text corpora to shape exploration.\nThis method, called ELLM (Exploring with LLMs) rewards an agent for achieving\ngoals suggested by a language model prompted with a description of the agent's\ncurrent state. By leveraging large-scale language model pretraining, ELLM\nguides agents toward human-meaningful and plausibly useful behaviors without\nrequiring a human in the loop. We evaluate ELLM in the Crafter game environment\nand the Housekeep robotic simulator, showing that ELLM-trained agents have\nbetter coverage of common-sense behaviors during pretraining and usually match\nor improve performance on a range of downstream tasks. Code available at\nhttps://github.com/yuqingd/ellm.\n",
                "链接": "https://arxiv.org/abs/2302.06692"
            },
            {
                "文章ID": "85592",
                "标题": "Large Language Models Are Semi-Parametric Reinforcement Learning Agents",
                "作者": " Danyang Zhang,  Lu Chen,  Situo Zhang,  Hongshen Xu,  Zihan Zhao,  Kai Yu",
                "发布日期": "2023-10-31",
                "摘要": "  Inspired by the insights in cognitive science with respect to human memory\nand reasoning mechanism, a novel evolvable LLM-based (Large Language Model)\nagent framework is proposed as REMEMBERER. By equipping the LLM with a\nlong-term experience memory, REMEMBERER is capable of exploiting the\nexperiences from the past episodes even for different task goals, which excels\nan LLM-based agent with fixed exemplars or equipped with a transient working\nmemory. We further introduce Reinforcement Learning with Experience Memory\n(RLEM) to update the memory. Thus, the whole system can learn from the\nexperiences of both success and failure, and evolve its capability without\nfine-tuning the parameters of the LLM. In this way, the proposed REMEMBERER\nconstitutes a semi-parametric RL agent. Extensive experiments are conducted on\ntwo RL task sets to evaluate the proposed framework. The average results with\ndifferent initialization and training sets exceed the prior SOTA by 4% and 2%\nfor the success rate on two task sets and demonstrate the superiority and\nrobustness of REMEMBERER.\n",
                "链接": "https://arxiv.org/abs/2306.07929"
            },
            {
                "文章ID": "79369",
                "标题": "Decomposed Prompting for Machine Translation Between Related Languages\n  using Large Language Models",
                "作者": " Ratish Puduppully,  Anoop Kunchukuttan,  Raj Dabre,  Ai Ti Aw,  Nancy F. Chen",
                "发布日期": "2023-10-24",
                "摘要": "  This study investigates machine translation between related languages i.e.,\nlanguages within the same family that share linguistic characteristics such as\nword order and lexical similarity. Machine translation through few-shot\nprompting leverages a small set of translation pair examples to generate\ntranslations for test sentences. This procedure requires the model to learn how\nto generate translations while simultaneously ensuring that token ordering is\nmaintained to produce a fluent and accurate translation. We propose that for\nrelated languages, the task of machine translation can be simplified by\nleveraging the monotonic alignment characteristic of such languages. We\nintroduce DecoMT, a novel approach of few-shot prompting that decomposes the\ntranslation process into a sequence of word chunk translations. Through\nautomatic and human evaluation conducted on multiple related language pairs\nacross various language families, we demonstrate that our proposed approach of\ndecomposed prompting surpasses multiple established few-shot baseline\napproaches. For example, DecoMT outperforms the strong few-shot prompting BLOOM\nmodel with an average improvement of 8 chrF++ scores across the examined\nlanguages.\n",
                "链接": "https://arxiv.org/abs/2305.13085"
            },
            {
                "文章ID": "121388",
                "标题": "Leveraging Reinforcement Learning and Large Language Models for Code\n  Optimization",
                "作者": " Shukai Duan,  Nikos Kanakaris,  Xiongye Xiao,  Heng Ping,  Chenyu Zhou,  Nesreen K. Ahmed,  Guixiang Ma,  Mihai Capota,  Theodore L. Willke,  Shahin Nazarian,  Paul Bogdan",
                "发布日期": "2023-12-12",
                "摘要": "  Code optimization is a daunting task that requires a significant level of\nexpertise from experienced programmers. This level of expertise is not\nsufficient when compared to the rapid development of new hardware\narchitectures. Towards advancing the whole code optimization process, recent\napproaches rely on machine learning and artificial intelligence techniques.\nThis paper introduces a new framework to decrease the complexity of code\noptimization. The proposed framework builds on large language models (LLMs) and\nreinforcement learning (RL) and enables LLMs to receive feedback from their\nenvironment (i.e., unit tests) during the fine-tuning process. We compare our\nframework with existing state-of-the-art models and show that it is more\nefficient with respect to speed and computational usage, as a result of the\ndecrement in training steps and its applicability to models with fewer\nparameters. Additionally, our framework reduces the possibility of logical and\nsyntactical errors. Toward evaluating our approach, we run several experiments\non the PIE dataset using a CodeT5 language model and RRHF, a new reinforcement\nlearning algorithm. We adopt a variety of evaluation metrics with regards to\noptimization quality, and speedup. The evaluation results demonstrate that the\nproposed framework has similar results in comparison with existing models using\nshorter training times and smaller pre-trained models. In particular, we\naccomplish an increase of 5.6% and 2.2 over the baseline models concerning the\n%OP T and SP metrics.\n",
                "链接": "https://arxiv.org/abs/2312.05657"
            },
            {
                "文章ID": "115037",
                "标题": "Distilling Large Language Models using Skill-Occupation Graph Context\n  for HR-Related Tasks",
                "作者": " Pouya Pezeshkpour,  Hayate Iso,  Thom Lake,  Nikita Bhutani,  Estevam Hruschka",
                "发布日期": "2023-11-14",
                "摘要": "  Numerous HR applications are centered around resumes and job descriptions.\nWhile they can benefit from advancements in NLP, particularly large language\nmodels, their real-world adoption faces challenges due to absence of\ncomprehensive benchmarks for various HR tasks, and lack of smaller models with\ncompetitive capabilities. In this paper, we aim to bridge this gap by\nintroducing the Resume-Job Description Benchmark (RJDB). We meticulously craft\nthis benchmark to cater to a wide array of HR tasks, including matching and\nexplaining resumes to job descriptions, extracting skills and experiences from\nresumes, and editing resumes. To create this benchmark, we propose to distill\ndomain-specific knowledge from a large language model (LLM). We rely on a\ncurated skill-occupation graph to ensure diversity and provide context for LLMs\ngeneration. Our benchmark includes over 50 thousand triples of job\ndescriptions, matched resumes and unmatched resumes. Using RJDB, we train\nmultiple smaller student models. Our experiments reveal that the student models\nachieve near/better performance than the teacher model (GPT-4), affirming the\neffectiveness of the benchmark. Additionally, we explore the utility of RJDB on\nout-of-distribution data for skill extraction and resume-job description\nmatching, in zero-shot and weak supervision manner. We release our datasets and\ncode to foster further research and industry applications.\n",
                "链接": "https://arxiv.org/abs/2311.06383"
            },
            {
                "文章ID": "118253",
                "标题": "Justifiable Artificial Intelligence: Engineering Large Language Models\n  for Legal Applications",
                "作者": " Sabine Wehnert",
                "发布日期": "2023-11-28",
                "摘要": "  In this work, I discuss how Large Language Models can be applied in the legal\ndomain, circumventing their current drawbacks. Despite their large success and\nacceptance, their lack of explainability hinders legal experts to trust in\ntheir output, and this happens rightfully so. However, in this paper, I argue\nin favor of a new view, Justifiable Artificial Intelligence, instead of\nfocusing on Explainable Artificial Intelligence. I discuss in this paper how\ngaining evidence for and against a Large Language Model's output may make their\ngenerated texts more trustworthy - or hold them accountable for misinformation.\n",
                "链接": "https://arxiv.org/abs/2311.15716"
            }
        ]
    },
    {
        "question": {
            "question": "有关大模型在新任务上面知识迁移的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "96137",
                "标题": "Smart Knowledge Transfer using Google-like Search",
                "作者": " Srijoni Majumdar,  Partha Pratim Das",
                "发布日期": "2023-08-15",
                "摘要": "  To address the issue of rising software maintenance cost due to program\ncomprehension challenges, we propose SMARTKT (Smart Knowledge Transfer), a\nsearch framework, which extracts and integrates knowledge related to various\naspects of an application in form of a semantic graph. This graph supports\nsyntax and semantic queries and converts the process of program comprehension\ninto a {\\em google-like} search problem.\n",
                "链接": "https://arxiv.org/abs/2308.06653"
            },
            {
                "文章ID": "110649",
                "标题": "Large Search Model: Redefining Search Stack in the Era of LLMs",
                "作者": " Liang Wang,  Nan Yang,  Xiaolong Huang,  Linjun Yang,  Rangan Majumder,  Furu Wei",
                "发布日期": "2023-10-24",
                "摘要": "  Modern search engines are built on a stack of different components, including\nquery understanding, retrieval, multi-stage ranking, and question answering,\namong others. These components are often optimized and deployed independently.\nIn this paper, we introduce a novel conceptual framework called large search\nmodel, which redefines the conventional search stack by unifying search tasks\nwith one large language model (LLM). All tasks are formulated as autoregressive\ntext generation problems, allowing for the customization of tasks through the\nuse of natural language prompts. This proposed framework capitalizes on the\nstrong language understanding and reasoning capabilities of LLMs, offering the\npotential to enhance search result quality while simultaneously simplifying the\nexisting cumbersome search stack. To substantiate the feasibility of this\nframework, we present a series of proof-of-concept experiments and discuss the\npotential challenges associated with implementing this approach within\nreal-world search systems.\n",
                "链接": "https://arxiv.org/abs/2310.14587"
            },
            {
                "文章ID": "74818",
                "标题": "Search-in-the-Chain: Towards Accurate, Credible and Traceable Large\n  Language Models for Knowledge-intensive Tasks",
                "作者": " Shicheng Xu,  Liang Pang,  Huawei Shen,  Xueqi Cheng,  Tat-Seng Chua",
                "发布日期": "2023-09-25",
                "摘要": "  Making the contents generated by Large Language Model (LLM) such as ChatGPT,\naccurate, credible and traceable is crucial, especially in complex\nknowledge-intensive tasks that require multi-step reasoning and each of which\nneeds knowledge to solve. Introducing Information Retrieval (IR) to provide LLM\nwith external knowledge is good potential to solve this problem. However, where\nand how to introduce IR into LLM is a big challenge. Previous work has the\ndisadvantage that the wrong knowledge retrieved by IR misleads the LLM or\nbreaks the reasoning chain of LLM. In this paper, we propose a novel framework\ncalled Search-in-the-Chain (SearChain) for the interaction between LLM and IR\nto solve the challenges. First, LLM generates the global reasoning chain called\nChain-of-Query (CoQ) where each node consists of an IR-oriented query and the\nanswer to the query. Second, IR verifies the answer of each node of CoQ, it\ncorrects the answer that is not consistent with the retrieved information when\nIR gives high confidence, which improves the credibility. Third, LLM can mark\nits missing knowledge in CoQ and IR can provide this knowledge to LLM. These\nthree operations improve the accuracy of LLM for complex knowledge-intensive\ntasks in terms of reasoning ability and knowledge. Finally, SearChain generates\nthe reasoning process and marks references to supporting documents for each\nreasoning step, which improves traceability. SearChain transforms the topology\nof reasoning from chain to tree, which can modify the reasoning direction.\nExperiment shows that SearChain outperforms baselines on complex\nknowledge-intensive tasks including multi-hop question-answering, slot filling,\nfact checking, and long-form question-answering.\n",
                "链接": "https://arxiv.org/abs/2304.14732"
            },
            {
                "文章ID": "66370",
                "标题": "Algorithmic Ghost in the Research Shell: Large Language Models and\n  Academic Knowledge Creation in Management Research",
                "作者": " Nigel Williams,  Stanislav Ivanov,  Dimitrios Buhalis",
                "发布日期": "2023-03-14",
                "摘要": "  The paper looks at the role of large language models in academic knowledge\ncreation based on a scoping review (2018 to January 2023) of how researchers\nhave previously used the language model GPT to assist in the performance of\nacademic knowledge creation tasks beyond data analysis. These tasks include\nwriting, editing, reviewing, dataset creation and curation, which have been\ndifficult to perform using earlier ML tools. Based on a synthesis of these\npapers, this study identifies pathways for a future academic research landscape\nthat incorporates wider usage of large language models based on the current\nmodes of adoption in published articles as a Co-Writer, Research Assistant and\nRespondent.\n",
                "链接": "https://arxiv.org/abs/2303.07304"
            },
            {
                "文章ID": "90102",
                "标题": "Shaping the Emerging Norms of Using Large Language Models in Social\n  Computing Research",
                "作者": " Hong Shen,  Tianshi Li,  Toby Jia-Jun Li,  Joon Sung Park,  Diyi Yang",
                "发布日期": "2023-07-11",
                "摘要": "  The emergence of Large Language Models (LLMs) has brought both excitement and\nconcerns to social computing research. On the one hand, LLMs offer\nunprecedented capabilities in analyzing vast amounts of textual data and\ngenerating human-like responses, enabling researchers to delve into complex\nsocial phenomena. On the other hand, concerns are emerging regarding the\nvalidity, privacy, and ethics of the research when LLMs are involved. This SIG\naims at offering an open space for social computing researchers who are\ninterested in understanding the impacts of LLMs to discuss their current\npractices, perspectives, challenges when engaging with LLMs in their everyday\nwork and collectively shaping the emerging norms of using LLMs in social\ncomputing research.\n",
                "链接": "https://arxiv.org/abs/2307.04280"
            },
            {
                "文章ID": "100283",
                "标题": "On the Planning, Search, and Memorization Capabilities of Large Language\n  Models",
                "作者": " Yunhao Yang,  Anshul Tomar",
                "发布日期": "2023-09-06",
                "摘要": "  The rapid advancement of large language models, such as the Generative\nPre-trained Transformer (GPT) series, has had significant implications across\nvarious disciplines. In this study, we investigate the potential of the\nstate-of-the-art large language model (GPT-4) for planning tasks. We explore\nits effectiveness in multiple planning subfields, highlighting both its\nstrengths and limitations. Through a comprehensive examination, we identify\nareas where large language models excel in solving planning problems and reveal\nthe constraints that limit their applicability. Our empirical analysis focuses\non GPT-4's performance in planning domain extraction, graph search path\nplanning, and adversarial planning. We then propose a way of fine-tuning a\ndomain-specific large language model to improve its Chain of Thought (CoT)\ncapabilities for the above-mentioned tasks. The results provide valuable\ninsights into the potential applications of large language models in the\nplanning domain and pave the way for future research to overcome their\nlimitations and expand their capabilities.\n",
                "链接": "https://arxiv.org/abs/2309.01868"
            },
            {
                "文章ID": "114645",
                "标题": "Characterizing Large Language Models as Rationalizers of\n  Knowledge-intensive Tasks",
                "作者": " Aditi Mishra,  Sajjadur Rahman,  Hannah Kim,  Kushan Mitra,  Estevam Hruschka",
                "发布日期": "2023-11-10",
                "摘要": "  Large language models (LLMs) are proficient at generating fluent text with\nminimal task-specific supervision. Yet, their ability to provide well-grounded\nrationalizations for knowledge-intensive tasks remains under-explored. Such\ntasks, like commonsense multiple-choice questions, require rationales based on\nworld knowledge to support predictions and refute alternate options. We\nconsider the task of generating knowledge-guided rationalization in natural\nlanguage by using expert-written examples in a few-shot manner. Surprisingly,\ncrowd-workers preferred knowledge-grounded rationales over crowdsourced\nrationalizations, citing their factuality, sufficiency, and comprehensive\nrefutations. Although LLMs-generated rationales were preferable, further\nimprovements in conciseness and novelty are required. In another study, we show\nhow rationalization of incorrect model predictions erodes humans' trust in\nLLM-generated rationales. Motivated by these observations, we create a\ntwo-stage pipeline to review task predictions and eliminate potential incorrect\ndecisions before rationalization, enabling trustworthy rationale generation.\n",
                "链接": "https://arxiv.org/abs/2311.05085"
            },
            {
                "文章ID": "3183",
                "标题": "AutoDistil: Few-shot Task-agnostic Neural Architecture Search for\n  Distilling Large Language Models",
                "作者": " Dongkuan Xu,  Subhabrata Mukherjee,  Xiaodong Liu,  Debadeepta Dey,  Wenhui Wang,  Xiang Zhang,  Ahmed Hassan Awadallah,  Jianfeng Gao",
                "发布日期": "2022-02-22",
                "摘要": "  Knowledge distillation (KD) methods compress large models into smaller\nstudents with manually-designed student architectures given pre-specified\ncomputational cost. This requires several trials to find a viable student, and\nfurther repeating the process for each student or computational budget change.\nWe use Neural Architecture Search (NAS) to automatically distill several\ncompressed students with variable cost from a large model. Current works train\na single SuperLM consisting of millions of subnetworks with weight-sharing,\nresulting in interference between subnetworks of different sizes. Our framework\nAutoDistil addresses above challenges with the following steps: (a)\nIncorporates inductive bias and heuristics to partition Transformer search\nspace into K compact sub-spaces (K=3 for typical student sizes of base, small\nand tiny); (b) Trains one SuperLM for each sub-space using task-agnostic\nobjective (e.g., self-attention distillation) with weight-sharing of students;\n(c) Lightweight search for the optimal student without re-training. Fully\ntask-agnostic training and search allow students to be reused for fine-tuning\non any downstream task. Experiments on GLUE benchmark against state-of-the-art\nKD and NAS methods demonstrate AutoDistil to outperform leading compression\ntechniques with upto 2.7x reduction in computational cost and negligible loss\nin task performance.\n",
                "链接": "https://arxiv.org/abs/2201.12507"
            },
            {
                "文章ID": "51102",
                "标题": "Extending the Subwording Model of Multilingual Pretrained Models for New\n  Languages",
                "作者": " Kenji Imamura,  Eiichiro Sumita",
                "发布日期": "2022-11-30",
                "摘要": "  Multilingual pretrained models are effective for machine translation and\ncross-lingual processing because they contain multiple languages in one model.\nHowever, they are pretrained after their tokenizers are fixed; therefore it is\ndifficult to change the vocabulary after pretraining. When we extend the\npretrained models to new languages, we must modify the tokenizers\nsimultaneously. In this paper, we add new subwords to the SentencePiece\ntokenizer to apply a multilingual pretrained model to new languages (Inuktitut\nin this paper). In our experiments, we segmented Inuktitut sentences into\nsubwords without changing the segmentation of already pretrained languages, and\napplied the mBART-50 pretrained model to English-Inuktitut translation.\n",
                "链接": "https://arxiv.org/abs/2211.15965"
            },
            {
                "文章ID": "67149",
                "标题": "Neural Architecture Search for Effective Teacher-Student Knowledge\n  Transfer in Language Models",
                "作者": " Aashka Trivedi,  Takuma Udagawa,  Michele Merler,  Rameswar Panda,  Yousef El-Kurdi,  Bishwaranjan Bhattacharjee",
                "发布日期": "2023-10-17",
                "摘要": "  Large pretrained language models have achieved state-of-the-art results on a\nvariety of downstream tasks. Knowledge Distillation (KD) into a smaller student\nmodel addresses their inefficiency, allowing for deployment in\nresource-constrained environments. However, KD can be ineffective when the\nstudent is manually selected from a set of existing options, since it can be a\nsub-optimal choice within the space of all possible student architectures. We\ndevelop multilingual KD-NAS, the use of Neural Architecture Search (NAS) guided\nby KD to find the optimal student architecture for task agnostic distillation\nfrom a multilingual teacher. In each episode of the search process, a NAS\ncontroller predicts a reward based on the distillation loss and latency of\ninference. The top candidate architectures are then distilled from the teacher\non a small proxy set. Finally the architecture(s) with the highest reward is\nselected, and distilled on the full training corpus. KD-NAS can automatically\ntrade off efficiency and effectiveness, and recommends architectures suitable\nto various latency budgets. Using our multi-layer hidden state distillation\nprocess, our KD-NAS student model achieves a 7x speedup on CPU inference (2x on\nGPU) compared to a XLM-Roberta Base Teacher, while maintaining 90% performance,\nand has been deployed in 3 software offerings requiring large throughput, low\nlatency and deployment on CPU.\n",
                "链接": "https://arxiv.org/abs/2303.09639"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和人文学科交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "35258",
                "标题": "Labeling of Cultural Heritage Collections on the Intersection of Visual\n  Analytics and Digital Humanities",
                "作者": " Christofer Meinecke",
                "发布日期": "2022-08-30",
                "摘要": "  Engaging in interdisciplinary projects on the intersection between\nvisualization and humanities research can be a challenging endeavor. Challenges\ncan be finding valuable outcomes for both domains, or how to apply\nstate-of-the-art visual analytics methods like supervised machine learning\nalgorithms. We discuss these challenges when working with cultural heritage\ndata. Further, there is a gap in applying these methods to intangible heritage.\nTo give a reflection on some interdisciplinary projects, we present three case\nstudies focusing on the labeling of cultural heritage collections, the problems\nand challenges with the data, the participatory design process, and takeaways\nfor the visualization scholars from these collaborations.\n",
                "链接": "https://arxiv.org/abs/2208.13512"
            },
            {
                "文章ID": "113893",
                "标题": "On the Intersection of Self-Correction and Trust in Language Models",
                "作者": " Satyapriya Krishna",
                "发布日期": "2023-11-07",
                "摘要": "  Large Language Models (LLMs) have demonstrated remarkable capabilities in\nperforming complex cognitive tasks. However, their complexity and lack of\ntransparency have raised several trustworthiness concerns, including the\npropagation of misinformation and toxicity. Recent research has explored the\nself-correction capabilities of LLMs to enhance their performance. In this\nwork, we investigate whether these self-correction capabilities can be\nharnessed to improve the trustworthiness of LLMs. We conduct experiments\nfocusing on two key aspects of trustworthiness: truthfulness and toxicity. Our\nfindings reveal that self-correction can lead to improvements in toxicity and\ntruthfulness, but the extent of these improvements varies depending on the\nspecific aspect of trustworthiness and the nature of the task. Interestingly,\nour study also uncovers instances of \"self-doubt\" in LLMs during the\nself-correction process, introducing a new set of challenges that need to be\naddressed.\n",
                "链接": "https://arxiv.org/abs/2311.02801"
            },
            {
                "文章ID": "70754",
                "标题": "A Bibliometric Review of Large Language Models Research from 2017 to\n  2023",
                "作者": " Lizhou Fan,  Lingyao Li,  Zihui Ma,  Sanggyu Lee,  Huizi Yu,  Libby Hemphill",
                "发布日期": "2023-04-06",
                "摘要": "  Large language models (LLMs) are a class of language models that have\ndemonstrated outstanding performance across a range of natural language\nprocessing (NLP) tasks and have become a highly sought-after research area,\nbecause of their ability to generate human-like language and their potential to\nrevolutionize science and technology. In this study, we conduct bibliometric\nand discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000\npublications, this paper serves as a roadmap for researchers, practitioners,\nand policymakers to navigate the current landscape of LLMs research. We present\nthe research trends from 2017 to early 2023, identifying patterns in research\nparadigms and collaborations. We start with analyzing the core algorithm\ndevelopments and NLP tasks that are fundamental in LLMs research. We then\ninvestigate the applications of LLMs in various fields and domains including\nmedicine, engineering, social science, and humanities. Our review also reveals\nthe dynamic, fast-paced evolution of LLMs research. Overall, this paper offers\nvaluable insights into the current state, impact, and potential of LLMs\nresearch and its applications.\n",
                "链接": "https://arxiv.org/abs/2304.02020"
            },
            {
                "文章ID": "96394",
                "标题": "Exploring the Intersection of Large Language Models and Agent-Based\n  Modeling via Prompt Engineering",
                "作者": " Edward Junprung",
                "发布日期": "2023-08-16",
                "摘要": "  The final frontier for simulation is the accurate representation of complex,\nreal-world social systems. While agent-based modeling (ABM) seeks to study the\nbehavior and interactions of agents within a larger system, it is unable to\nfaithfully capture the full complexity of human-driven behavior. Large language\nmodels (LLMs), like ChatGPT, have emerged as a potential solution to this\nbottleneck by enabling researchers to explore human-driven interactions in\npreviously unimaginable ways. Our research investigates simulations of human\ninteractions using LLMs. Through prompt engineering, inspired by Park et al.\n(2023), we present two simulations of believable proxies of human behavior: a\ntwo-agent negotiation and a six-agent murder mystery game.\n",
                "链接": "https://arxiv.org/abs/2308.07411"
            },
            {
                "文章ID": "66370",
                "标题": "Algorithmic Ghost in the Research Shell: Large Language Models and\n  Academic Knowledge Creation in Management Research",
                "作者": " Nigel Williams,  Stanislav Ivanov,  Dimitrios Buhalis",
                "发布日期": "2023-03-14",
                "摘要": "  The paper looks at the role of large language models in academic knowledge\ncreation based on a scoping review (2018 to January 2023) of how researchers\nhave previously used the language model GPT to assist in the performance of\nacademic knowledge creation tasks beyond data analysis. These tasks include\nwriting, editing, reviewing, dataset creation and curation, which have been\ndifficult to perform using earlier ML tools. Based on a synthesis of these\npapers, this study identifies pathways for a future academic research landscape\nthat incorporates wider usage of large language models based on the current\nmodes of adoption in published articles as a Co-Writer, Research Assistant and\nRespondent.\n",
                "链接": "https://arxiv.org/abs/2303.07304"
            },
            {
                "文章ID": "79114",
                "标题": "A PhD Student's Perspective on Research in NLP in the Era of Very Large\n  Language Models",
                "作者": " Oana Ignat,  Zhijing Jin,  Artem Abzaliev,  Laura Biester,  Santiago Castro,  Naihao Deng,  Xinyi Gao,  Aylin Gunal,  Jacky He,  Ashkan Kazemi,  Muhammad Khalifa,  Namho Koh,  Andrew Lee,  Siyang Liu,  Do June Min,  Shinka Mori,  Joan Nwatu,  Veronica Perez-Rosas,  Siqi Shen,  Zekun Wang,  Winston Wu,  Rada Mihalcea",
                "发布日期": "2023-05-23",
                "摘要": "  Recent progress in large language models has enabled the deployment of many\ngenerative NLP applications. At the same time, it has also led to a misleading\npublic discourse that ``it's all been solved.'' Not surprisingly, this has in\nturn made many NLP researchers -- especially those at the beginning of their\ncareer -- wonder about what NLP research area they should focus on. This\ndocument is a compilation of NLP research directions that are rich for\nexploration, reflecting the views of a diverse group of PhD students in an\nacademic research lab. While we identify many research areas, many others\nexist; we do not cover those areas that are currently addressed by LLMs but\nwhere LLMs lag behind in performance, or those focused on LLM development. We\nwelcome suggestions for other research directions to include:\nhttps://bit.ly/nlp-era-llm\n",
                "链接": "https://arxiv.org/abs/2305.12544"
            },
            {
                "文章ID": "123540",
                "标题": "User Modeling in the Era of Large Language Models: Current Research and\n  Future Directions",
                "作者": " Zhaoxuan Tan,  Meng Jiang",
                "发布日期": "2023-12-27",
                "摘要": "  User modeling (UM) aims to discover patterns or learn representations from\nuser data about the characteristics of a specific user, such as profile,\npreference, and personality. The user models enable personalization and\nsuspiciousness detection in many online applications such as recommendation,\neducation, and healthcare. Two common types of user data are text and graph, as\nthe data usually contain a large amount of user-generated content (UGC) and\nonline interactions. The research of text and graph mining is developing\nrapidly, contributing many notable solutions in the past two decades. Recently,\nlarge language models (LLMs) have shown superior performance on generating,\nunderstanding, and even reasoning over text data. The approaches of user\nmodeling have been equipped with LLMs and soon become outstanding. This article\nsummarizes existing research about how and why LLMs are great tools of modeling\nand understanding UGC. Then it reviews a few categories of large language\nmodels for user modeling (LLM-UM) approaches that integrate the LLMs with text\nand graph-based methods in different ways. Then it introduces specific LLM-UM\ntechniques for a variety of UM applications. Finally, it presents remaining\nchallenges and future directions in the LLM-UM research. We maintain the\nreading list at: https://github.com/TamSiuhin/LLM-UM-Reading\n",
                "链接": "https://arxiv.org/abs/2312.11518"
            },
            {
                "文章ID": "81668",
                "标题": "The Utility of Large Language Models and Generative AI for Education\n  Research",
                "作者": " Andrew Katz,  Umair Shakir,  Ben Chambers",
                "发布日期": "2023-05-30",
                "摘要": "  The use of natural language processing (NLP) techniques in engineering\neducation can provide valuable insights into the underlying processes involved\nin generating text. While accessing these insights can be labor-intensive if\ndone manually, recent advances in NLP and large language models have made it a\nrealistic option for individuals. This study explores and evaluates a\ncombination of clustering, summarization, and prompting techniques to analyze\nover 1,000 student essays in which students discussed their career interests.\nThe specific assignment prompted students to define and explain their career\ngoals as engineers. Using text embedding representations of student responses,\nwe clustered the responses together to identify thematically similar statements\nfrom students. The clustered responses were then summarized to quickly identify\ncareer interest themes. We also used a set of a priori codes about career\nsatisfaction and sectors to demonstrate an alternative approach to using these\ngenerative text models to analyze student writing. The results of this study\ndemonstrate the feasibility and usefulness of NLP techniques in engineering\neducation research. By automating the initial analysis of student essays,\nresearchers and educators can more efficiently and accurately identify key\nthemes and patterns in student writing. The methods presented in this paper\nhave broader applications for engineering education and research purposes\nbeyond analyzing student essays. By explaining these methods to the engineering\neducation community, readers can utilize them in their own contexts.\n",
                "链接": "https://arxiv.org/abs/2305.18125"
            },
            {
                "文章ID": "90102",
                "标题": "Shaping the Emerging Norms of Using Large Language Models in Social\n  Computing Research",
                "作者": " Hong Shen,  Tianshi Li,  Toby Jia-Jun Li,  Joon Sung Park,  Diyi Yang",
                "发布日期": "2023-07-11",
                "摘要": "  The emergence of Large Language Models (LLMs) has brought both excitement and\nconcerns to social computing research. On the one hand, LLMs offer\nunprecedented capabilities in analyzing vast amounts of textual data and\ngenerating human-like responses, enabling researchers to delve into complex\nsocial phenomena. On the other hand, concerns are emerging regarding the\nvalidity, privacy, and ethics of the research when LLMs are involved. This SIG\naims at offering an open space for social computing researchers who are\ninterested in understanding the impacts of LLMs to discuss their current\npractices, perspectives, challenges when engaging with LLMs in their everyday\nwork and collectively shaping the emerging norms of using LLMs in social\ncomputing research.\n",
                "链接": "https://arxiv.org/abs/2307.04280"
            },
            {
                "文章ID": "112605",
                "标题": "The Eval4NLP 2023 Shared Task on Prompting Large Language Models as\n  Explainable Metrics",
                "作者": " Christoph Leiter,  Juri Opitz,  Daniel Deutsch,  Yang Gao,  Rotem Dror,  Steffen Eger",
                "发布日期": "2023-10-31",
                "摘要": "  With an increasing number of parameters and pre-training data, generative\nlarge language models (LLMs) have shown remarkable capabilities to solve tasks\nwith minimal or no task-related examples. Notably, LLMs have been successfully\nemployed as evaluation metrics in text generation tasks. Within this context,\nwe introduce the Eval4NLP 2023 shared task that asks participants to explore\nprompting and score extraction for machine translation (MT) and summarization\nevaluation. Specifically, we propose a novel competition setting in which we\nselect a list of allowed LLMs and disallow fine-tuning to ensure a focus on\nprompting. We present an overview of participants' approaches and evaluate them\non a new reference-free test set spanning three language pairs for MT and a\nsummarization dataset. Notably, despite the task's restrictions, the\nbest-performing systems achieve results on par with or even surpassing recent\nreference-free metrics developed using larger models, including GEMBA and\nComet-Kiwi-XXL. Finally, as a separate track, we perform a small-scale human\nevaluation of the plausibility of explanations given by the LLMs.\n",
                "链接": "https://arxiv.org/abs/2310.19792"
            }
        ]
    },
    {
        "question": {
            "question": "2023年以后关于大语言模型和脑科学交叉的研究",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "48817",
                "标题": "Galactica: A Large Language Model for Science",
                "作者": " Ross Taylor,  Marcin Kardas,  Guillem Cucurull,  Thomas Scialom,  Anthony Hartshorn,  Elvis Saravia,  Andrew Poulton,  Viktor Kerkez,  Robert Stojnic",
                "发布日期": "2022-11-17",
                "摘要": "  Information overload is a major obstacle to scientific progress. The\nexplosive growth in scientific literature and data has made it ever harder to\ndiscover useful insights in a large mass of information. Today scientific\nknowledge is accessed through search engines, but they are unable to organize\nscientific knowledge alone. In this paper we introduce Galactica: a large\nlanguage model that can store, combine and reason about scientific knowledge.\nWe train on a large scientific corpus of papers, reference material, knowledge\nbases and many other sources. We outperform existing models on a range of\nscientific tasks. On technical knowledge probes such as LaTeX equations,\nGalactica outperforms the latest GPT-3 by 68.2% versus 49.0%. Galactica also\nperforms well on reasoning, outperforming Chinchilla on mathematical MMLU by\n41.3% to 35.7%, and PaLM 540B on MATH with a score of 20.4% versus 8.8%. It\nalso sets a new state-of-the-art on downstream tasks such as PubMedQA and\nMedMCQA dev of 77.6% and 52.9%. And despite not being trained on a general\ncorpus, Galactica outperforms BLOOM and OPT-175B on BIG-bench. We believe these\nresults demonstrate the potential for language models as a new interface for\nscience. We open source the model for the benefit of the scientific community.\n",
                "链接": "https://arxiv.org/abs/2211.09085"
            },
            {
                "文章ID": "70754",
                "标题": "A Bibliometric Review of Large Language Models Research from 2017 to\n  2023",
                "作者": " Lizhou Fan,  Lingyao Li,  Zihui Ma,  Sanggyu Lee,  Huizi Yu,  Libby Hemphill",
                "发布日期": "2023-04-06",
                "摘要": "  Large language models (LLMs) are a class of language models that have\ndemonstrated outstanding performance across a range of natural language\nprocessing (NLP) tasks and have become a highly sought-after research area,\nbecause of their ability to generate human-like language and their potential to\nrevolutionize science and technology. In this study, we conduct bibliometric\nand discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000\npublications, this paper serves as a roadmap for researchers, practitioners,\nand policymakers to navigate the current landscape of LLMs research. We present\nthe research trends from 2017 to early 2023, identifying patterns in research\nparadigms and collaborations. We start with analyzing the core algorithm\ndevelopments and NLP tasks that are fundamental in LLMs research. We then\ninvestigate the applications of LLMs in various fields and domains including\nmedicine, engineering, social science, and humanities. Our review also reveals\nthe dynamic, fast-paced evolution of LLMs research. Overall, this paper offers\nvaluable insights into the current state, impact, and potential of LLMs\nresearch and its applications.\n",
                "链接": "https://arxiv.org/abs/2304.02020"
            },
            {
                "文章ID": "106021",
                "标题": "OceanGPT: A Large Language Model for Ocean Science Tasks",
                "作者": " Zhen Bi,  Ningyu Zhang,  Yida Xue,  Yixin Ou,  Daxiong Ji,  Guozhou Zheng,  Huajun Chen",
                "发布日期": "2023-10-26",
                "摘要": "  Ocean science, which delves into the oceans that are reservoirs of life and\nbiodiversity, is of great significance given that oceans cover over 70% of our\nplanet's surface. Recently, advances in Large Language Models (LLMs) have\ntransformed the paradigm in science. Despite the success in other domains,\ncurrent LLMs often fall short in catering to the needs of domain experts like\noceanographers, and the potential of LLMs for ocean science is under-explored.\nThe intrinsic reason may be the immense and intricate nature of ocean data as\nwell as the necessity for higher granularity and richness in knowledge. To\nalleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean\ndomain, which is expert in various ocean science tasks. We propose DoInstruct,\na novel framework to automatically obtain a large volume of ocean domain\ninstruction data, which generates instructions based on multi-agent\ncollaboration. Additionally, we construct the first oceanography benchmark,\nOceanBench, to evaluate the capabilities of LLMs in the ocean domain. Though\ncomprehensive experiments, OceanGPT not only shows a higher level of knowledge\nexpertise for oceans science tasks but also gains preliminary embodied\nintelligence capabilities in ocean technology. Codes, data and checkpoints will\nsoon be available at https://github.com/zjunlp/KnowLM.\n",
                "链接": "https://arxiv.org/abs/2310.02031"
            },
            {
                "文章ID": "78623",
                "标题": "Towards Human-AI Collaborative Urban Science Research Enabled by\n  Pre-trained Large Language Models",
                "作者": " Jiayi Fu,  Haoying Han,  Xing Su,  Chao Fan",
                "发布日期": "2023-05-22",
                "摘要": "  Pre-trained large language models (PLMs) have the potential to support urban\nscience research through content creation, information extraction, assisted\nprogramming, text classification, and other technical advances. In this\nresearch, we explored the opportunities, challenges, and prospects of PLMs in\nurban science research. Specifically, we discussed potential applications of\nPLMs to urban institution, urban space, urban information, and citizen\nbehaviors research through seven examples using ChatGPT. We also examined the\nchallenges of PLMs in urban science research from both technical and social\nperspectives. The prospects of the application of PLMs in urban science\nresearch were then proposed. We found that PLMs can effectively aid in\nunderstanding complex concepts in urban science, facilitate urban spatial form\nidentification, assist in disaster monitoring, and sense public sentiment. At\nthe same time, however, the applications of PLMs in urban science research face\nevident threats, such as technical limitations, security, privacy, and social\nbias. The development of fundamental models based on domain knowledge and\nhuman-AI collaboration may help improve PLMs to support urban science research\nin future.\n",
                "链接": "https://arxiv.org/abs/2305.11418"
            },
            {
                "文章ID": "101429",
                "标题": "Large Language Model for Science: A Study on P vs. NP",
                "作者": " Qingxiu Dong,  Li Dong,  Ke Xu,  Guangyan Zhou,  Yaru Hao,  Zhifang Sui,  Furu Wei",
                "发布日期": "2023-09-13",
                "摘要": "  In this work, we use large language models (LLMs) to augment and accelerate\nresearch on the P versus NP problem, one of the most important open problems in\ntheoretical computer science and mathematics. Specifically, we propose Socratic\nreasoning, a general framework that promotes in-depth thinking with LLMs for\ncomplex problem-solving. Socratic reasoning encourages LLMs to recursively\ndiscover, solve, and integrate problems while facilitating self-evaluation and\nrefinement. Our pilot study on the P vs. NP problem shows that GPT-4\nsuccessfully produces a proof schema and engages in rigorous reasoning\nthroughout 97 dialogue turns, concluding \"P $\\neq$ NP\", which is in alignment\nwith (Xu and Zhou, 2023). The investigation uncovers novel insights within the\nextensive solution space of LLMs, shedding light on LLM for Science.\n",
                "链接": "https://arxiv.org/abs/2309.05689"
            },
            {
                "文章ID": "107938",
                "标题": "MatChat: A Large Language Model and Application Service Platform for\n  Materials Science",
                "作者": " Ziyi Chen,  Fankai Xie,  Meng Wan,  Yang Yuan,  Miao Liu,  Zongguo Wang,  Sheng Meng,  Yangang Wang",
                "发布日期": "2023-11-03",
                "摘要": "  The prediction of chemical synthesis pathways plays a pivotal role in\nmaterials science research. Challenges, such as the complexity of synthesis\npathways and the lack of comprehensive datasets, currently hinder our ability\nto predict these chemical processes accurately. However, recent advancements in\ngenerative artificial intelligence (GAI), including automated text generation\nand question-answering systems, coupled with fine-tuning techniques, have\nfacilitated the deployment of large-scale AI models tailored to specific\ndomains. In this study, we harness the power of the LLaMA2-7B model and enhance\nit through a learning process that incorporates 13,878 pieces of structured\nmaterial knowledge data. This specialized AI model, named MatChat, focuses on\npredicting inorganic material synthesis pathways. MatChat exhibits remarkable\nproficiency in generating and reasoning with knowledge in materials science.\nAlthough MatChat requires further refinement to meet the diverse material\ndesign needs, this research undeniably highlights its impressive reasoning\ncapabilities and innovative potential in the field of materials science.\nMatChat is now accessible online and open for use, with both the model and its\napplication framework available as open source. This study establishes a robust\nfoundation for collaborative innovation in the integration of generative AI in\nmaterials science.\n",
                "链接": "https://arxiv.org/abs/2310.07197"
            },
            {
                "文章ID": "79552",
                "标题": "A Study of Generative Large Language Model for Medical Research and\n  Healthcare",
                "作者": " Cheng Peng,  Xi Yang,  Aokun Chen,  Kaleb E Smith,  Nima PourNejatian,  Anthony B Costa,  Cheryl Martin,  Mona G Flores,  Ying Zhang,  Tanja Magoc,  Gloria Lipori,  Duane A Mitchell,  Naykky S Ospina,  Mustafa M Ahmed,  William R Hogan,  Elizabeth A Shenkman,  Yi Guo,  Jiang Bian,  Yonghui Wu",
                "发布日期": "2023-11-20",
                "摘要": "  There is enormous enthusiasm and concerns in using large language models\n(LLMs) in healthcare, yet current assumptions are all based on general-purpose\nLLMs such as ChatGPT. This study develops a clinical generative LLM,\nGatorTronGPT, using 277 billion words of mixed clinical and English text with a\nGPT-3 architecture of 20 billion parameters. GatorTronGPT improves biomedical\nnatural language processing for medical research. Synthetic NLP models trained\nusing GatorTronGPT generated text outperform NLP models trained using\nreal-world clinical text. Physicians Turing test using 1 (worst) to 9 (best)\nscale shows that there is no significant difference in linguistic readability\n(p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical\nrelevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that\nphysicians cannot differentiate them (p < 0.001). This study provides insights\non the opportunities and challenges of LLMs for medical research and\nhealthcare.\n",
                "链接": "https://arxiv.org/abs/2305.13523"
            },
            {
                "文章ID": "98470",
                "标题": "SciEval: A Multi-Level Large Language Model Evaluation Benchmark for\n  Scientific Research",
                "作者": " Liangtai Sun,  Yang Han,  Zihan Zhao,  Da Ma,  Zhennan Shen,  Baocai Chen,  Lu Chen,  Kai Yu",
                "发布日期": "2023-08-28",
                "摘要": "  Recently, there has been growing interest in using Large Language Models\n(LLMs) for scientific research. Numerous benchmarks have been proposed to\nevaluate the ability of LLMs for scientific research. However, current\nbenchmarks are mostly based on pre-collected objective questions. This design\nsuffers from data leakage problem and lacks the evaluation of subjective Q/A\nability. In this paper, we propose SciEval, a comprehensive and\nmulti-disciplinary evaluation benchmark to address these issues. Based on\nBloom's taxonomy, SciEval covers four dimensions to systematically evaluate\nscientific research ability. In particular, we design a \"dynamic\" subset based\non scientific principles to prevent evaluation from potential data leakage.\nBoth objective and subjective questions are included in SciEval. These\ncharacteristics make SciEval a more effective benchmark for scientific research\nability evaluation of LLMs. Comprehensive experiments on most advanced LLMs\nshow that, although GPT-4 achieves SOTA performance compared to other LLMs,\nthere is still substantial room for improvement, especially for dynamic\nquestions. The data and codes are now publicly available.\n",
                "链接": "https://arxiv.org/abs/2308.13149"
            },
            {
                "文章ID": "75961",
                "标题": "Can Large Language Models Transform Computational Social Science?",
                "作者": " Caleb Ziems,  William Held,  Omar Shaikh,  Jiaao Chen,  Zhehao Zhang,  Diyi Yang",
                "发布日期": "2023-12-08",
                "摘要": "  Large Language Models (LLMs) are capable of successfully performing many\nlanguage processing tasks zero-shot (without training data). If zero-shot LLMs\ncan also reliably classify and explain social phenomena like persuasiveness and\npolitical ideology, then LLMs could augment the Computational Social Science\n(CSS) pipeline in important ways. This work provides a road map for using LLMs\nas CSS tools. Towards this end, we contribute a set of prompting best practices\nand an extensive evaluation pipeline to measure the zero-shot performance of 13\nlanguage models on 25 representative English CSS benchmarks. On taxonomic\nlabeling tasks (classification), LLMs fail to outperform the best fine-tuned\nmodels but still achieve fair levels of agreement with humans. On free-form\ncoding tasks (generation), LLMs produce explanations that often exceed the\nquality of crowdworkers' gold references. We conclude that the performance of\ntoday's LLMs can augment the CSS research pipeline in two ways: (1) serving as\nzero-shot data annotators on human annotation teams, and (2) bootstrapping\nchallenging creative generation tasks (e.g., explaining the underlying\nattributes of a text). In summary, LLMs are posed to meaningfully participate\nin} social science analysis in partnership with humans.\n",
                "链接": "https://arxiv.org/abs/2305.03514"
            },
            {
                "文章ID": "36178",
                "标题": "YouTube and Science: Models for Research Impact",
                "作者": " Abdul Rahman Shaikh,  Hamed Alhoori,  Maoyuan Sun",
                "发布日期": "2022-09-07",
                "摘要": "  Video communication has been rapidly increasing over the past decade, with\nYouTube providing a medium where users can post, discover, share, and react to\nvideos. There has also been an increase in the number of videos citing research\narticles, especially since it has become relatively commonplace for academic\nconferences to require video submissions. However, the relationship between\nresearch articles and YouTube videos is not clear, and the purpose of the\npresent paper is to address this issue. We created new datasets using YouTube\nvideos and mentions of research articles on various online platforms. We found\nthat most of the articles cited in the videos are related to medicine and\nbiochemistry. We analyzed these datasets through statistical techniques and\nvisualization, and built machine learning models to predict (1) whether a\nresearch article is cited in videos, (2) whether a research article cited in a\nvideo achieves a level of popularity, and (3) whether a video citing a research\narticle becomes popular. The best models achieved F1 scores between 80% and\n94%. According to our results, research articles mentioned in more tweets and\nnews coverage have a higher chance of receiving video citations. We also found\nthat video views are important for predicting citations and increasing research\narticles' popularity and public engagement with science.\n",
                "链接": "https://arxiv.org/abs/2209.02380"
            }
        ]
    },
    {
        "question": {
            "question": "2022年后与AI for Science相关的综述论文",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "99506",
                "标题": "Science Communications for Explainable Artificial Intelligence",
                "作者": " Simon Hudson,  Matija Franklin",
                "发布日期": "2023-09-01",
                "摘要": "  Artificial Intelligence (AI) has a communication problem. XAI methods have\nbeen used to make AI more understandable and helped resolve some of the\ntransparency issues that inhibit AI's broader usability. However, user\nevaluation studies reveal that the often numerical explanations provided by XAI\nmethods have not always been effective for many types of users of AI systems.\nThis article aims to adapt the major communications models from Science\nCommunications into a framework for practitioners to understand, influence, and\nintegrate the context of audiences both for their communications supporting AI\nliteracy in the public and in designing XAI systems that are more adaptive to\ndifferent users.\n",
                "链接": "https://arxiv.org/abs/2308.16377"
            },
            {
                "文章ID": "83154",
                "标题": "Accelerating science with human-aware artificial intelligence",
                "作者": " Jamshid Sourati,  James Evans",
                "发布日期": "2023-06-05",
                "摘要": "  Artificial intelligence (AI) models trained on published scientific findings\nhave been used to invent valuable materials and targeted therapies, but they\ntypically ignore the human scientists who continually alter the landscape of\ndiscovery. Here we show that incorporating the distribution of human expertise\nby training unsupervised models on simulated inferences cognitively accessible\nto experts dramatically improves (up to 400%) AI prediction of future\ndiscoveries beyond those focused on research content alone, especially when\nrelevant literature is sparse. These models succeed by predicting human\npredictions and the scientists who will make them. By tuning human-aware AI to\navoid the crowd, we can generate scientifically promising \"alien\" hypotheses\nunlikely to be imagined or pursued without intervention until the distant\nfuture, which hold promise to punctuate scientific advance beyond questions\ncurrently pursued. Accelerating human discovery or probing its blind spots,\nhuman-aware AI enables us to move toward and beyond the contemporary scientific\nfrontier.\n",
                "链接": "https://arxiv.org/abs/2306.01495"
            },
            {
                "文章ID": "17308",
                "标题": "Artificial Intelligence and Medicine: A literature review",
                "作者": "Biomedical Robotics Laboratory, Department of\n  Biomedical Engineering, City University of Hong Kong  Chottiwatt Jittprasong",
                "发布日期": "2022-05-09",
                "摘要": "  In practically every industry today, artificial intelligence is one of the\nmost effective ways for machines to assist humans. Since its inception, a large\nnumber of researchers throughout the globe have been pioneering the application\nof artificial intelligence in medicine. Although artificial intelligence may\nseem to be a 21st-century concept, Alan Turing pioneered the first foundation\nconcept in the 1940s. Artificial intelligence in medicine has a huge variety of\napplications that researchers are continually exploring. The tremendous\nincrease in computer and human resources has hastened progress in the 21st\ncentury, and it will continue to do so for many years to come. This review of\nthe literature will highlight the emerging field of artificial intelligence in\nmedicine and its current level of development.\n",
                "链接": "https://arxiv.org/abs/2205.00322"
            },
            {
                "文章ID": "97369",
                "标题": "A Review on Objective-Driven Artificial Intelligence",
                "作者": " Apoorv Singh",
                "发布日期": "2023-08-22",
                "摘要": "  While advancing rapidly, Artificial Intelligence still falls short of human\nintelligence in several key aspects due to inherent limitations in current AI\ntechnologies and our understanding of cognition. Humans have an innate ability\nto understand context, nuances, and subtle cues in communication, which allows\nus to comprehend jokes, sarcasm, and metaphors. Machines struggle to interpret\nsuch contextual information accurately. Humans possess a vast repository of\ncommon-sense knowledge that helps us make logical inferences and predictions\nabout the world. Machines lack this innate understanding and often struggle\nwith making sense of situations that humans find trivial. In this article, we\nreview the prospective Machine Intelligence candidates, a review from Prof.\nYann LeCun, and other work that can help close this gap between human and\nmachine intelligence. Specifically, we talk about what's lacking with the\ncurrent AI techniques such as supervised learning, reinforcement learning,\nself-supervised learning, etc. Then we show how Hierarchical planning-based\napproaches can help us close that gap and deep-dive into energy-based,\nlatent-variable methods and Joint embedding predictive architecture methods.\n",
                "链接": "https://arxiv.org/abs/2308.10135"
            },
            {
                "文章ID": "2627",
                "标题": "A Method to Predict Semantic Relations on Artificial Intelligence Papers",
                "作者": " Francisco Andrades,  Ricardo Ñanculef",
                "发布日期": "2022-01-26",
                "摘要": "  Predicting the emergence of links in large evolving networks is a difficult\ntask with many practical applications. Recently, the Science4cast competition\nhas illustrated this challenge presenting a network of 64.000 AI concepts and\nasking the participants to predict which topics are going to be researched\ntogether in the future. In this paper, we present a solution to this problem\nbased on a new family of deep learning approaches, namely Graph Neural\nNetworks. The results of the challenge show that our solution is competitive\neven if we had to impose severe restrictions to obtain a computationally\nefficient and parsimonious model: ignoring the intrinsic dynamics of the graph\nand using only a small subset of the nodes surrounding a target link.\nPreliminary experiments presented in this paper suggest the model is learning\ntwo related, but different patterns: the absorption of a node by a sub-graph\nand union of more dense sub-graphs. The model seems to excel at recognizing the\nfirst type of pattern.\n",
                "链接": "https://arxiv.org/abs/2201.10518"
            },
            {
                "文章ID": "81277",
                "标题": "Integrating Generative Artificial Intelligence in Intelligent Vehicle\n  Systems",
                "作者": " Lukas Stappen,  Jeremy Dillmann,  Serena Striegel,  Hans-Jörg Vögel,  Nicolas Flores-Herr,  Björn W. Schuller",
                "发布日期": "2023-05-30",
                "摘要": "  This paper aims to serve as a comprehensive guide for researchers and\npractitioners, offering insights into the current state, potential\napplications, and future research directions for generative artificial\nintelligence and foundation models within the context of intelligent vehicles.\nAs the automotive industry progressively integrates AI, generative artificial\nintelligence technologies hold the potential to revolutionize user\ninteractions, delivering more immersive, intuitive, and personalised in-car\nexperiences. We provide an overview of current applications of generative\nartificial intelligence in the automotive domain, emphasizing speech, audio,\nvision, and multimodal interactions. We subsequently outline critical future\nresearch areas, including domain adaptability, alignment, multimodal\nintegration and others, as well as, address the challenges and risks associated\nwith ethics. By fostering collaboration and addressing these research areas,\ngenerative artificial intelligence can unlock its full potential, transforming\nthe driving experience and shaping the future of intelligent vehicles.\n",
                "链接": "https://arxiv.org/abs/2305.17137"
            },
            {
                "文章ID": "37961",
                "标题": "Artificial Intelligence for In Silico Clinical Trials: A Review",
                "作者": " Zifeng Wang,  Chufan Gao,  Lucas M. Glass,  Jimeng Sun",
                "发布日期": "2022-09-20",
                "摘要": "  A clinical trial is an essential step in drug development, which is often\ncostly and time-consuming. In silico trials are clinical trials conducted\ndigitally through simulation and modeling as an alternative to traditional\nclinical trials. AI-enabled in silico trials can increase the case group size\nby creating virtual cohorts as controls. In addition, it also enables\nautomation and optimization of trial design and predicts the trial success\nrate. This article systematically reviews papers under three main topics:\nclinical simulation, individualized predictive modeling, and computer-aided\ntrial design. We focus on how machine learning (ML) may be applied in these\napplications. In particular, we present the machine learning problem\nformulation and available data sources for each task. We end with discussing\nthe challenges and opportunities of AI for in silico trials in real-world\napplications.\n",
                "链接": "https://arxiv.org/abs/2209.09023"
            },
            {
                "文章ID": "53435",
                "标题": "Artificial intelligence technologies to support research assessment: A\n  review",
                "作者": " Kayvan Kousha,  Mike Thelwall",
                "发布日期": "2022-12-14",
                "摘要": "  This literature review identifies indicators that associate with higher\nimpact or higher quality research from article text (e.g., titles, abstracts,\nlengths, cited references and readability) or metadata (e.g., the number of\nauthors, international or domestic collaborations, journal impact factors and\nauthors' h-index). This includes studies that used machine learning techniques\nto predict citation counts or quality scores for journal articles or conference\npapers. The literature review also includes evidence about the strength of\nassociation between bibliometric indicators and quality score rankings from\nprevious UK Research Assessment Exercises (RAEs) and REFs in different subjects\nand years and similar evidence from other countries (e.g., Australia and\nItaly). In support of this, the document also surveys studies that used public\ndatasets of citations, social media indictors or open review texts (e.g.,\nDimensions, OpenCitations, Altmetric.com and Publons) to help predict the\nscholarly impact of articles. The results of this part of the literature review\nwere used to inform the experiments using machine learning to predict REF\njournal article quality scores, as reported in the AI experiments report for\nthis project. The literature review also covers technology to automate\neditorial processes, to provide quality control for papers and reviewers'\nsuggestions, to match reviewers with articles, and to automatically categorise\njournal articles into fields. Bias and transparency in technology assisted\nassessment are also discussed.\n",
                "链接": "https://arxiv.org/abs/2212.06574"
            },
            {
                "文章ID": "64435",
                "标题": "Explainable Artificial Intelligence and Cybersecurity: A Systematic\n  Literature Review",
                "作者": " Carlos Mendes,  Tatiane Nogueira Rios",
                "发布日期": "2023-03-03",
                "摘要": "  Cybersecurity vendors consistently apply AI (Artificial Intelligence) to\ntheir solutions and many cybersecurity domains can benefit from AI technology.\nHowever, black-box AI techniques present some difficulties in comprehension and\nadoption by its operators, given that their decisions are not always humanly\nunderstandable (as is usually the case with deep neural networks, for example).\nSince it aims to make the operation of AI algorithms more interpretable for its\nusers and developers, XAI (eXplainable Artificial Intelligence) can be used to\naddress this issue. Through a systematic literature review, this work seeks to\ninvestigate the current research scenario on XAI applied to cybersecurity,\naiming to discover which XAI techniques have been applied in cybersecurity, and\nwhich areas of cybersecurity have already benefited from this technology.\n",
                "链接": "https://arxiv.org/abs/2303.01259"
            },
            {
                "文章ID": "70041",
                "标题": "Artificial Intelligence in Ovarian Cancer Histopathology: A Systematic\n  Review",
                "作者": " Jack Breen,  Katie Allen,  Kieran Zucker,  Pratik Adusumilli,  Andy Scarsbrook,  Geoff Hall,  Nicolas M. Orsi,  Nishant Ravikumar",
                "发布日期": "2023-06-19",
                "摘要": "  Purpose - To characterise and assess the quality of published research\nevaluating artificial intelligence (AI) methods for ovarian cancer diagnosis or\nprognosis using histopathology data. Methods - A search of PubMed, Scopus, Web\nof Science, CENTRAL, and WHO-ICTRP was conducted up to 19/05/2023. The\ninclusion criteria required that research evaluated AI on histopathology images\nfor diagnostic or prognostic inferences in ovarian cancer. The risk of bias was\nassessed using PROBAST. Information about each model of interest was tabulated\nand summary statistics were reported. PRISMA 2020 reporting guidelines were\nfollowed. Results - 1573 records were identified, of which 45 were eligible for\ninclusion. There were 80 models of interest, including 37 diagnostic models, 22\nprognostic models, and 21 models with other diagnostically relevant outcomes.\nModels were developed using 1-1375 slides from 1-776 ovarian cancer patients.\nModel outcomes included treatment response (11/80), malignancy status (10/80),\nstain quantity (9/80), and histological subtype (7/80). All models were found\nto be at high or unclear risk of bias overall, with most research having a high\nrisk of bias in the analysis and a lack of clarity regarding participants and\npredictors in the study. Research frequently suffered from insufficient\nreporting and limited validation using small sample sizes. Conclusion - Limited\nresearch has been conducted on the application of AI to histopathology images\nfor diagnostic or prognostic purposes in ovarian cancer, and none of the\nassociated models have been demonstrated to be ready for real-world\nimplementation. Key aspects to help ensure clinical translation include more\ntransparent and comprehensive reporting of data provenance and modelling\napproaches, as well as improved quantitative performance evaluation using\ncross-validation and external validations.\n",
                "链接": "https://arxiv.org/abs/2303.18005"
            }
        ]
    },
    {
        "question": {
            "question": "对比解码综述",
            "type": "6"
        },
        "results": [
            {
                "文章ID": "17405",
                "标题": "The Implicit Length Bias of Label Smoothing on Beam Search Decoding",
                "作者": " Bowen Liang,  Pidong Wang,  Yuan Cao",
                "发布日期": "2022-05-03",
                "摘要": "  Label smoothing is ubiquitously applied in Neural Machine Translation (NMT)\ntraining. While label smoothing offers a desired regularization effect during\nmodel training, in this paper we demonstrate that it nevertheless introduces\nlength biases in the beam search decoding procedure. Our analysis shows that\nlabel smoothing implicitly applies a length penalty term to output sequence,\ncausing a bias towards shorter translations. We also show that for a model\nfully optimized with label smoothing, translation length is implicitly upper\nbounded by a fixed constant independent of input. We verify our theory by\napplying a simple rectification function at inference time to restore the\nunbiased distributions from the label-smoothed model predictions. This\nrectification method led to consistent quality improvements on WMT\nEnglish-German, English-French, English-Czech and English-Chinese tasks, up to\n+0.3 BLEU at beam size 4 and +2.8 BLEU at beam size 200.\n",
                "链接": "https://arxiv.org/abs/2205.00659"
            },
            {
                "文章ID": "4592",
                "标题": "On the Pitfalls of Using the Residual Error as Anomaly Score",
                "作者": " Felix Meissen,  Benedikt Wiestler,  Georgios Kaissis,  Daniel Rueckert",
                "发布日期": "2023-09-26",
                "摘要": "  Many current state-of-the-art methods for anomaly localization in medical\nimages rely on calculating a residual image between a potentially anomalous\ninput image and its \"healthy\" reconstruction. As the reconstruction of the\nunseen anomalous region should be erroneous, this yields large residuals as a\nscore to detect anomalies in medical images. However, this assumption does not\ntake into account residuals resulting from imperfect reconstructions of the\nmachine learning models used. Such errors can easily overshadow residuals of\ninterest and therefore strongly question the use of residual images as scoring\nfunction. Our work explores this fundamental problem of residual images in\ndetail. We theoretically define the problem and thoroughly evaluate the\ninfluence of intensity and texture of anomalies against the effect of imperfect\nreconstructions in a series of experiments. Code and experiments are available\nunder https://github.com/FeliMe/residual-score-pitfalls\n",
                "链接": "https://arxiv.org/abs/2202.03826"
            },
            {
                "文章ID": "13340",
                "标题": "Neural Estimation of the Rate-Distortion Function With Applications to\n  Operational Source Coding",
                "作者": " Eric Lei,  Hamed Hassani,  Shirin Saeedi Bidokhti",
                "发布日期": "2023-02-03",
                "摘要": "  A fundamental question in designing lossy data compression schemes is how\nwell one can do in comparison with the rate-distortion function, which\ndescribes the known theoretical limits of lossy compression. Motivated by the\nempirical success of deep neural network (DNN) compressors on large, real-world\ndata, we investigate methods to estimate the rate-distortion function on such\ndata, which would allow comparison of DNN compressors with optimality. While\none could use the empirical distribution of the data and apply the\nBlahut-Arimoto algorithm, this approach presents several computational\nchallenges and inaccuracies when the datasets are large and high-dimensional,\nsuch as the case of modern image datasets. Instead, we re-formulate the\nrate-distortion objective, and solve the resulting functional optimization\nproblem using neural networks. We apply the resulting rate-distortion\nestimator, called NERD, on popular image datasets, and provide evidence that\nNERD can accurately estimate the rate-distortion function. Using our estimate,\nwe show that the rate-distortion achievable by DNN compressors are within\nseveral bits of the rate-distortion function for real-world datasets.\nAdditionally, NERD provides access to the rate-distortion achieving channel, as\nwell as samples from its output marginal. Therefore, using recent results in\nreverse channel coding, we describe how NERD can be used to construct an\noperational one-shot lossy compression scheme with guarantees on the achievable\nrate and distortion. Experimental results demonstrate competitive performance\nwith DNN compressors.\n",
                "链接": "https://arxiv.org/abs/2204.01612"
            },
            {
                "文章ID": "114659",
                "标题": "Quranic Conversations: Developing a Semantic Search tool for the Quran\n  using Arabic NLP Techniques",
                "作者": " Yasser Shohoud,  Maged Shoman,  Sarah Abdelazim",
                "发布日期": "2023-11-10",
                "摘要": "  The Holy Book of Quran is believed to be the literal word of God (Allah) as\nrevealed to the Prophet Muhammad (PBUH) over a period of approximately 23\nyears. It is the book where God provides guidance on how to live a righteous\nand just life, emphasizing principles like honesty, compassion, charity and\njustice, as well as providing rules for personal conduct, family matters,\nbusiness ethics and much more. However, due to constraints related to the\nlanguage and the Quran organization, it is challenging for Muslims to get all\nrelevant ayahs (verses) pertaining to a matter or inquiry of interest. Hence,\nwe developed a Quran semantic search tool which finds the verses pertaining to\nthe user inquiry or prompt. To achieve this, we trained several models on a\nlarge dataset of over 30 tafsirs, where typically each tafsir corresponds to\none verse in the Quran and, using cosine similarity, obtained the tafsir tensor\nwhich is most similar to the prompt tensor of interest, which was then used to\nindex for the corresponding ayah in the Quran. Using the SNxLM model, we were\nable to achieve a cosine similarity score as high as 0.97 which corresponds to\nthe abdu tafsir for a verse relating to financial matters.\n",
                "链接": "https://arxiv.org/abs/2311.05120"
            },
            {
                "文章ID": "104862",
                "标题": "Decoding the Workplace & EOR: An Employee Survey Analysis by Data\n  Science Techniques and Visualization",
                "作者": " Kishankumar Bhimani,  Khushbu Saradva",
                "发布日期": "2023-09-29",
                "摘要": "  This research study explores the new dynamics of employee-organi-zation\nrelationships (EOR) [6] using advanced data science methodologies and presents\nfindings through accessible visualizations. Leveraging a dataset pro-cured from\na comprehensive nationwide big employee survey, this study employs innovative\nstrategy for theoretical researcher by using our state-of-the-art\nvisual-ization. The results present insightful visualizations encapsulating\ndemographic analysis, workforce satisfaction, work environment scrutiny, and\nthe employee's view via word cloud interpretations and burnout predictions.\n  The study underscores the profound implications of data science across\nvarious management sectors, enhancing understanding of workplace dynamics and\npro-moting mutual growth and satisfaction. This multifaceted approach caters to\na diverse array of readers, from researchers in sociology and management to\nfirms seeking detailed understanding of their workforce's satisfaction,\nemphasizing on practicality and interpretability.\n  The research encourages proactive measures to improve workplace\nenviron-ments, boost employee satisfaction, and foster healthier, more\nproductive organ-izations. It serves as a resourceful tool for those committed\nto these objectives, manifesting the transformative potential of data science\nin driving insightful nar-ratives about workplace dynamics and\nemployee-organization relationships. In essence, this research unearths\nvaluable insights to aid management, HR profes-sionals, and companies\n",
                "链接": "https://arxiv.org/abs/2309.16329"
            },
            {
                "文章ID": "66173",
                "标题": "Raising The Limit Of Image Rescaling Using Auxiliary Encoding",
                "作者": " Chenzhong Yin,  Zhihong Pan,  Xin Zhou,  Le Kang,  Paul Bogdan",
                "发布日期": "2023-03-14",
                "摘要": "  Normalizing flow models using invertible neural networks (INN) have been\nwidely investigated for successful generative image super-resolution (SR) by\nlearning the transformation between the normal distribution of latent variable\n$z$ and the conditional distribution of high-resolution (HR) images gave a\nlow-resolution (LR) input. Recently, image rescaling models like IRN utilize\nthe bidirectional nature of INN to push the performance limit of image\nupscaling by optimizing the downscaling and upscaling steps jointly. While the\nrandom sampling of latent variable $z$ is useful in generating diverse\nphoto-realistic images, it is not desirable for image rescaling when accurate\nrestoration of the HR image is more important. Hence, in places of random\nsampling of $z$, we propose auxiliary encoding modules to further push the\nlimit of image rescaling performance. Two options to store the encoded latent\nvariables in downscaled LR images, both readily supported in existing image\nfile format, are proposed. One is saved as the alpha-channel, the other is\nsaved as meta-data in the image header, and the corresponding modules are\ndenoted as suffixes -A and -M respectively. Optimal network architectural\nchanges are investigated for both options to demonstrate their effectiveness in\nraising the rescaling performance limit on different baseline models including\nIRN and DLV-IRN.\n",
                "链接": "https://arxiv.org/abs/2303.06747"
            },
            {
                "文章ID": "79167",
                "标题": "ConQueR: Contextualized Query Reduction using Search Logs",
                "作者": " Hye-young Kim,  Minjin Choi,  Sunkyung Lee,  Eunseong Choi,  Young-In Song,  Jongwuk Lee",
                "发布日期": "2023-05-23",
                "摘要": "  Query reformulation is a key mechanism to alleviate the linguistic chasm of\nquery in ad-hoc retrieval. Among various solutions, query reduction effectively\nremoves extraneous terms and specifies concise user intent from long queries.\nHowever, it is challenging to capture hidden and diverse user intent. This\npaper proposes Contextualized Query Reduction (ConQueR) using a pre-trained\nlanguage model (PLM). Specifically, it reduces verbose queries with two\ndifferent views: core term extraction and sub-query selection. One extracts\ncore terms from an original query at the term level, and the other determines\nwhether a sub-query is a suitable reduction for the original query at the\nsequence level. Since they operate at different levels of granularity and\ncomplement each other, they are finally aggregated in an ensemble manner. We\nevaluate the reduction quality of ConQueR on real-world search logs collected\nfrom a commercial web search engine. It achieves up to 8.45% gains in exact\nmatch scores over the best competing model.\n",
                "链接": "https://arxiv.org/abs/2305.12662"
            },
            {
                "文章ID": "45962",
                "标题": "Blank Collapse: Compressing CTC emission for the faster decoding",
                "作者": " Minkyu Jung,  Ohhyeok Kwon,  Seunghyun Seo,  Soonshin Seo",
                "发布日期": "2023-06-28",
                "摘要": "  Connectionist Temporal Classification (CTC) model is a very efficient method\nfor modeling sequences, especially for speech data. In order to use CTC model\nas an Automatic Speech Recognition (ASR) task, the beam search decoding with an\nexternal language model like n-gram LM is necessary to obtain reasonable\nresults. In this paper we analyze the blank label in CTC beam search deeply and\npropose a very simple method to reduce the amount of calculation resulting in\nfaster beam search decoding speed. With this method, we can get up to 78%\nfaster decoding speed than ordinary beam search decoding with a very small loss\nof accuracy in LibriSpeech datasets. We prove this method is effective not only\npractically by experiments but also theoretically by mathematical reasoning. We\nalso observe that this reduction is more obvious if the accuracy of the model\nis higher.\n",
                "链接": "https://arxiv.org/abs/2210.17017"
            },
            {
                "文章ID": "2112",
                "标题": "Reproducing Personalised Session Search over the AOL Query Log",
                "作者": " Sean MacAvaney,  Craig Macdonald,  Iadh Ounis",
                "发布日期": "2022-01-24",
                "摘要": "  Despite its troubled past, the AOL Query Log continues to be an important\nresource to the research community -- particularly for tasks like search\npersonalisation. When using the query log these ranking experiments, little\nattention is usually paid to the document corpus. Recent work typically uses a\ncorpus containing versions of the documents collected long after the log was\nproduced. Given that web documents are prone to change over time, we study the\ndifferences present between a version of the corpus containing documents as\nthey appeared in 2017 (which has been used by several recent works) and a new\nversion we construct that includes documents close to as they appeared at the\ntime the query log was produced (2006). We demonstrate that this new version of\nthe corpus has a far higher coverage of documents present in the original log\n(93%) than the 2017 version (55%). Among the overlapping documents, the content\noften differs substantially. Given these differences, we re-conduct session\nsearch experiments that originally used the 2017 corpus and find that when\nusing our corpus for training or evaluation, system performance improves. We\nplace the results in context by introducing recent adhoc ranking baselines. We\nalso confirm the navigational nature of the queries in the AOL corpus by\nshowing that including the URL substantially improves performance across a\nvariety of models. Our version of the corpus can be easily reconstructed by\nother researchers and is included in the ir-datasets package.\n",
                "链接": "https://arxiv.org/abs/2201.08622"
            },
            {
                "文章ID": "37099",
                "标题": "Analysing the Predictivity of Features to Characterise the Search Space",
                "作者": " Rafet Durgut,  Mehmet Emin Aydin,  Hisham Ihshaish,  Abdur Rakib",
                "发布日期": "2022-09-14",
                "摘要": "  Exploring search spaces is one of the most unpredictable challenges that has\nattracted the interest of researchers for decades. One way to handle\nunpredictability is to characterise the search spaces and take actions\naccordingly. A well-characterised search space can assist in mapping the\nproblem states to a set of operators for generating new problem states. In this\npaper, a landscape analysis-based set of features has been analysed using the\nmost renown machine learning approaches to determine the optimal feature set.\nHowever, in order to deal with problem complexity and induce commonality for\ntransferring experience across domains, the selection of the most\nrepresentative features remains crucial. The proposed approach analyses the\npredictivity of a set of features in order to determine the best\ncategorization.\n",
                "链接": "https://arxiv.org/abs/2209.06114"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近三个月有关语言模型rlhf的arxiv上的全部文章。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "15836",
                "标题": "Recent Progress in Conversational AI",
                "作者": " Zijun Xue,  Ruirui Li,  Mingda Li",
                "发布日期": "2022-04-22",
                "摘要": "  Conversational artificial intelligence (AI) is becoming an increasingly\npopular topic among industry and academia. With the fast development of neural\nnetwork-based models, a lot of neural-based conversational AI system are\ndeveloped. We will provide a brief review of the recent progress in the\nConversational AI, including the commonly adopted techniques, notable works,\nfamous competitions from academia and industry and widely used datasets.\n",
                "链接": "https://arxiv.org/abs/2204.09719"
            },
            {
                "文章ID": "106830",
                "标题": "Confronting Reward Model Overoptimization with Constrained RLHF",
                "作者": " Ted Moskovitz,  Aaditya K. Singh,  DJ Strouse,  Tuomas Sandholm,  Ruslan Salakhutdinov,  Anca D. Dragan,  Stephen McAleer",
                "发布日期": "2023-10-11",
                "摘要": "  Large language models are typically aligned with human preferences by\noptimizing $\\textit{reward models}$ (RMs) fitted to human feedback. However,\nhuman preferences are multi-faceted, and it is increasingly common to derive\nreward from a composition of simpler reward models which each capture a\ndifferent aspect of language quality. This itself presents a challenge, as it\nis difficult to appropriately weight these component RMs when combining them.\nCompounding this difficulty, because any RM is only a proxy for human\nevaluation, this process is vulnerable to $\\textit{overoptimization}$, wherein\npast a certain point, accumulating higher reward is associated with worse human\nratings. In this paper, we perform, to our knowledge, the first study on\noveroptimization in composite RMs, showing that correlation between component\nRMs has a significant effect on the locations of these points. We then\nintroduce an approach to solve this issue using constrained reinforcement\nlearning as a means of preventing the agent from exceeding each RM's threshold\nof usefulness. Our method addresses the problem of weighting component RMs by\nlearning dynamic weights, naturally expressed by Lagrange multipliers. As a\nresult, each RM stays within the range at which it is an effective proxy,\nimproving evaluation performance. Finally, we introduce an adaptive method\nusing gradient-free optimization to identify and optimize towards these points\nduring a single run.\n",
                "链接": "https://arxiv.org/abs/2310.04373"
            },
            {
                "文章ID": "54674",
                "标题": "Spoken Language Understanding for Conversational AI: Recent Advances and\n  Future Direction",
                "作者": " Soyeon Caren Han,  Siqu Long,  Henry Weld,  Josiah Poon",
                "发布日期": "2022-12-22",
                "摘要": "  When a human communicates with a machine using natural language on the web\nand online, how can it understand the human's intention and semantic context of\ntheir talk? This is an important AI task as it enables the machine to construct\na sensible answer or perform a useful action for the human. Meaning is\nrepresented at the sentence level, identification of which is known as intent\ndetection, and at the word level, a labelling task called slot filling. This\ndual-level joint task requires innovative thinking about natural language and\ndeep learning network design, and as a result, many approaches and models have\nbeen proposed and applied.\n  This tutorial will discuss how the joint task is set up and introduce Spoken\nLanguage Understanding/Natural Language Understanding (SLU/NLU) with Deep\nLearning techniques. We will cover the datasets, experiments and metrics used\nin the field. We will describe how the machine uses the latest NLP and Deep\nLearning techniques to address the joint task, including recurrent and\nattention-based Transformer networks and pre-trained models (e.g. BERT). We\nwill then look in detail at a network that allows the two levels of the task,\nintent classification and slot filling, to interact to boost performance\nexplicitly. We will do a code demonstration of a Python notebook for this model\nand attendees will have an opportunity to watch coding demo tasks on this joint\nNLU to further their understanding.\n",
                "链接": "https://arxiv.org/abs/2212.10728"
            },
            {
                "文章ID": "102832",
                "标题": "Stabilizing RLHF through Advantage Model and Selective Rehearsal",
                "作者": " Baolin Peng,  Linfeng Song,  Ye Tian,  Lifeng Jin,  Haitao Mi,  Dong Yu",
                "发布日期": "2023-09-20",
                "摘要": "  Large Language Models (LLMs) have revolutionized natural language processing,\nyet aligning these models with human values and preferences using RLHF remains\na significant challenge. This challenge is characterized by various\ninstabilities, such as reward hacking and catastrophic forgetting. In this\ntechnical report, we propose two innovations to stabilize RLHF training: 1)\nAdvantage Model, which directly models advantage score i.e., extra reward\ncompared to the expected rewards and regulates score distributions across tasks\nto prevent reward hacking. 2) Selective Rehearsal, which mitigates catastrophic\nforgetting by strategically selecting data for PPO training and knowledge\nrehearsing. Our experimental analysis on public and proprietary datasets\nreveals that the proposed methods not only increase stability in RLHF training\nbut also achieve higher reward scores and win rates.\n",
                "链接": "https://arxiv.org/abs/2309.10202"
            },
            {
                "文章ID": "92138",
                "标题": "Topics, Authors, and Networks in Large Language Model Research: Trends\n  from a Survey of 17K arXiv Papers",
                "作者": " Rajiv Movva,  Sidhika Balachandar,  Kenny Peng,  Gabriel Agostini,  Nikhil Garg,  Emma Pierson",
                "发布日期": "2023-10-24",
                "摘要": "  Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n",
                "链接": "https://arxiv.org/abs/2307.10700"
            },
            {
                "文章ID": "95587",
                "标题": "NLLG Quarterly arXiv Report 06/23: What are the most influential current\n  AI Papers?",
                "作者": " Steffen Eger,  Christoph Leiter,  Jonas Belouadi,  Ran Zhang,  Aida Kostikova,  Daniil Larionov,  Yanran Chen,  Vivian Fresen",
                "发布日期": "2023-08-15",
                "摘要": "  The rapid growth of information in the field of Generative Artificial\nIntelligence (AI), particularly in the subfields of Natural Language Processing\n(NLP) and Machine Learning (ML), presents a significant challenge for\nresearchers and practitioners to keep pace with the latest developments. To\naddress the problem of information overload, this report by the Natural\nLanguage Learning Group at Bielefeld University focuses on identifying the most\npopular papers on arXiv, with a specific emphasis on NLP and ML. The objective\nis to offer a quick guide to the most relevant and widely discussed research,\naiding both newcomers and established researchers in staying abreast of current\ntrends. In particular, we compile a list of the 40 most popular papers based on\nnormalized citation counts from the first half of 2023. We observe the\ndominance of papers related to Large Language Models (LLMs) and specifically\nChatGPT during the first half of 2023, with the latter showing signs of\ndeclining popularity more recently, however. Further, NLP related papers are\nthe most influential (around 60\\% of top papers) even though there are twice as\nmany ML related papers in our data. Core issues investigated in the most\nheavily cited papers are: LLM efficiency, evaluation techniques, ethical\nconsiderations, embodied agents, and problem-solving with LLMs. Additionally,\nwe examine the characteristics of top papers in comparison to others outside\nthe top-40 list (noticing the top paper's focus on LLM related issues and\nhigher number of co-authors) and analyze the citation distributions in our\ndataset, among others.\n",
                "链接": "https://arxiv.org/abs/2308.04889"
            },
            {
                "文章ID": "121399",
                "标题": "NLLG Quarterly arXiv Report 09/23: What are the most influential current\n  AI Papers?",
                "作者": " Ran Zhang,  Aida Kostikova,  Christoph Leiter,  Jonas Belouadi,  Daniil Larionov,  Yanran Chen,  Vivian Fresen,  Steffen Eger",
                "发布日期": "2023-12-12",
                "摘要": "  Artificial Intelligence (AI) has witnessed rapid growth, especially in the\nsubfields Natural Language Processing (NLP), Machine Learning (ML) and Computer\nVision (CV). Keeping pace with this rapid progress poses a considerable\nchallenge for researchers and professionals in the field. In this arXiv report,\nthe second of its kind, which covers the period from January to September 2023,\nwe aim to provide insights and analysis that help navigate these dynamic areas\nof AI. We accomplish this by 1) identifying the top-40 most cited papers from\narXiv in the given period, comparing the current top-40 papers to the previous\nreport, which covered the period January to June; 2) analyzing dataset\ncharacteristics and keyword popularity; 3) examining the global sectoral\ndistribution of institutions to reveal differences in engagement across\ngeographical areas. Our findings highlight the continued dominance of NLP:\nwhile only 16% of all submitted papers have NLP as primary category (more than\n25% have CV and ML as primary category), 50% of the most cited papers have NLP\nas primary category, 90% of which target LLMs. Additionally, we show that i)\nthe US dominates among both top-40 and top-9k papers, followed by China; ii)\nEurope clearly lags behind and is hardly represented in the top-40 most cited\npapers; iii) US industry is largely overrepresented in the top-40 most\ninfluential papers.\n",
                "链接": "https://arxiv.org/abs/2312.05688"
            },
            {
                "文章ID": "28744",
                "标题": "Recent Developments in AI and USPTO Open Data",
                "作者": " Scott Beliveau,  Jerry Ma",
                "发布日期": "2022-07-13",
                "摘要": "  The USPTO disseminates one of the largest publicly accessible repositories of\nscientific, technical, and commercial data worldwide. USPTO data has\nhistorically seen frequent use in fields such as patent analytics, economics,\nand prosecution & litigation tools. This article highlights an emerging class\nof usecases directed to the research, development, and application of\nartificial intelligence technology. Such usecases contemplate both the delivery\nof artificial intelligence capabilities for practical IP applications and the\nenablement of future state-of-the-art artificial intelligence research via\nUSPTO data products. Examples from both within and beyond the USPTO are offered\nas case studies.\n",
                "链接": "https://arxiv.org/abs/2207.05239"
            },
            {
                "文章ID": "71860",
                "标题": "Human-AI Co-Creation Approach to Find Forever Chemicals Replacements",
                "作者": " Juliana Jansen Ferreira,  Vinícius Segura,  Joana G. R. Souza,  Gabriel D. J. Barbosa,  João Gallas,  Renato Cerqueira,  Dmitry Zubarev",
                "发布日期": "2023-04-12",
                "摘要": "  Generative models are a powerful tool in AI for material discovery. We are\ndesigning a software framework that supports a human-AI co-creation process to\naccelerate finding replacements for the ``forever chemicals''-- chemicals that\nenable our modern lives, but are harmful to the environment and the human\nhealth. Our approach combines AI capabilities with the domain-specific tacit\nknowledge of subject matter experts to accelerate the material discovery. Our\nco-creation process starts with the interaction between the subject matter\nexperts and a generative model that can generate new molecule designs. In this\nposition paper, we discuss our hypothesis that these subject matter experts can\nbenefit from a more iterative interaction with the generative model, asking for\nsmaller samples and ``guiding'' the exploration of the discovery space with\ntheir knowledge.\n",
                "链接": "https://arxiv.org/abs/2304.05389"
            },
            {
                "文章ID": "90293",
                "标题": "Secrets of RLHF in Large Language Models Part I: PPO",
                "作者": " Rui Zheng,  Shihan Dou,  Songyang Gao,  Yuan Hua,  Wei Shen,  Binghai Wang,  Yan Liu,  Senjie Jin,  Qin Liu,  Yuhao Zhou,  Limao Xiong,  Lu Chen,  Zhiheng Xi,  Nuo Xu,  Wenbin Lai,  Minghao Zhu,  Cheng Chang,  Zhangyue Yin,  Rongxiang Weng,  Wensen Cheng,  Haoran Huang,  Tianxiang Sun,  Hang Yan,  Tao Gui,  Qi Zhang,  Xipeng Qiu,  Xuanjing Huang",
                "发布日期": "2023-07-19",
                "摘要": "  Large language models (LLMs) have formulated a blueprint for the advancement\nof artificial general intelligence. Its primary objective is to function as a\nhuman-centric (helpful, honest, and harmless) assistant. Alignment with humans\nassumes paramount significance, and reinforcement learning with human feedback\n(RLHF) emerges as the pivotal technological paradigm underpinning this pursuit.\nCurrent technical routes usually include \\textbf{reward models} to measure\nhuman preferences, \\textbf{Proximal Policy Optimization} (PPO) to optimize\npolicy model outputs, and \\textbf{process supervision} to improve step-by-step\nreasoning capabilities. However, due to the challenges of reward design,\nenvironment interaction, and agent training, coupled with huge trial and error\ncost of large language models, there is a significant barrier for AI\nresearchers to motivate the development of technical alignment and safe landing\nof LLMs. The stable training of RLHF has still been a puzzle. In the first\nreport, we dissect the framework of RLHF, re-evaluate the inner workings of\nPPO, and explore how the parts comprising PPO algorithms impact policy agent\ntraining. We identify policy constraints being the key factor for the effective\nimplementation of the PPO algorithm. Therefore, we explore the PPO-max, an\nadvanced version of PPO algorithm, to efficiently improve the training\nstability of the policy model. Based on our main results, we perform a\ncomprehensive analysis of RLHF abilities compared with SFT models and ChatGPT.\nThe absence of open-source implementations has posed significant challenges to\nthe investigation of LLMs alignment. Therefore, we are eager to release\ntechnical reports, reward models and PPO codes, aiming to make modest\ncontributions to the advancement of LLMs.\n",
                "链接": "https://arxiv.org/abs/2307.04964"
            }
        ]
    },
    {
        "question": {
            "question": "查找大模型结合树搜索方法进行推理的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "20418",
                "标题": "How sensitive are translation systems to extra contexts? Mitigating\n  gender bias in Neural Machine Translation models through relevant contexts",
                "作者": " Shanya Sharma,  Manan Dey,  Koustuv Sinha",
                "发布日期": "2022-10-18",
                "摘要": "  Neural Machine Translation systems built on top of Transformer-based\narchitectures are routinely improving the state-of-the-art in translation\nquality according to word-overlap metrics. However, a growing number of studies\nalso highlight the inherent gender bias that these models incorporate during\ntraining, which reflects poorly in their translations. In this work, we\ninvestigate whether these models can be instructed to fix their bias during\ninference using targeted, guided instructions as contexts. By translating\nrelevant contextual sentences during inference along with the input, we observe\nlarge improvements in reducing the gender bias in translations, across three\npopular test suites (WinoMT, BUG, SimpleGen). We further propose a novel metric\nto assess several large pre-trained models (OPUS-MT, M2M-100) on their\nsensitivity towards using contexts during translation to correct their biases.\nOur approach requires no fine-tuning and thus can be used easily in production\nsystems to de-bias translations from stereotypical gender-occupation bias 1. We\nhope our method, along with our metric, can be used to build better, bias-free\ntranslation systems.\n",
                "链接": "https://arxiv.org/abs/2205.10762"
            },
            {
                "文章ID": "103710",
                "标题": "Automatically Testing Functional Properties of Code Translation Models",
                "作者": " Hasan Ferit Eniser,  Valentin Wüstholz,  Maria Christakis",
                "发布日期": "2023-09-25",
                "摘要": "  Large language models are becoming increasingly practical for translating\ncode across programming languages, a process known as $transpiling$. Even\nthough automated transpilation significantly boosts developer productivity, a\nkey concern is whether the generated code is correct. Existing work initially\nused manually crafted test suites to test the translations of a small corpus of\nprograms; these test suites were later automated. In contrast, we devise the\nfirst approach for automated, functional, property-based testing of code\ntranslation models. Our general, user-provided specifications about the\ntranspiled code capture a range of properties, from purely syntactic to purely\nsemantic ones. As shown by our experiments, this approach is very effective in\ndetecting property violations in popular code translation models, and\ntherefore, in evaluating model quality with respect to given properties. We\nalso go a step further and explore the usage scenario where a user simply aims\nto obtain a correct translation of some code with respect to certain properties\nwithout necessarily being concerned about the overall quality of the model. To\nthis purpose, we develop the first property-guided search procedure for code\ntranslation models, where a model is repeatedly queried with slightly different\nparameters to produce alternative and potentially more correct translations.\nOur results show that this search procedure helps to obtain significantly\nbetter code translations.\n",
                "链接": "https://arxiv.org/abs/2309.12813"
            },
            {
                "文章ID": "92370",
                "标题": "Incorporating Human Translator Style into English-Turkish Literary\n  Machine Translation",
                "作者": " Zeynep Yirmibeşoğlu,  Olgun Dursun,  Harun Dallı,  Mehmet Şahin,  Ena Hodzik,  Sabri Gürses,  Tunga Güngör",
                "发布日期": "2023-07-24",
                "摘要": "  Although machine translation systems are mostly designed to serve in the\ngeneral domain, there is a growing tendency to adapt these systems to other\ndomains like literary translation. In this paper, we focus on English-Turkish\nliterary translation and develop machine translation models that take into\naccount the stylistic features of translators. We fine-tune a pre-trained\nmachine translation model by the manually-aligned works of a particular\ntranslator. We make a detailed analysis of the effects of manual and automatic\nalignments, data augmentation methods, and corpus size on the translations. We\npropose an approach based on stylistic features to evaluate the style of a\ntranslator in the output translations. We show that the human translator style\ncan be highly recreated in the target machine translations by adapting the\nmodels to the style of the translator.\n",
                "链接": "https://arxiv.org/abs/2307.11457"
            },
            {
                "文章ID": "79608",
                "标题": "Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine\n  Translation",
                "作者": " Jiayi Wang,  Ke Wang,  Yuqi Zhang,  Yu Zhao,  Pontus Stenetorp",
                "发布日期": "2023-05-24",
                "摘要": "  Non-parametric, k-nearest-neighbor algorithms have recently made inroads to\nassist generative models such as language models and machine translation\ndecoders. We explore whether such non-parametric models can improve machine\ntranslation models at the fine-tuning stage by incorporating statistics from\nthe kNN predictions to inform the gradient updates for a baseline translation\nmodel. There are multiple methods which could be used to incorporate kNN\nstatistics and we investigate gradient scaling by a gating mechanism, the kNN's\nground truth probability, and reinforcement learning. For four standard\nin-domain machine translation datasets, compared with classic fine-tuning, we\nreport consistent improvements of all of the three methods by as much as 1.45\nBLEU and 1.28 BLEU for German-English and English-German translations\nrespectively. Through qualitative analysis, we found particular improvements\nwhen it comes to translating grammatical relations or function words, which\nresults in increased fluency of our model.\n",
                "链接": "https://arxiv.org/abs/2305.13648"
            },
            {
                "文章ID": "84526",
                "标题": "T3L: Translate-and-Test Transfer Learning for Cross-Lingual Text\n  Classification",
                "作者": " Inigo Jauregi Unanue,  Gholamreza Haffari,  Massimo Piccardi",
                "发布日期": "2023-06-09",
                "摘要": "  Cross-lingual text classification leverages text classifiers trained in a\nhigh-resource language to perform text classification in other languages with\nno or minimal fine-tuning (zero/few-shots cross-lingual transfer). Nowadays,\ncross-lingual text classifiers are typically built on large-scale, multilingual\nlanguage models (LMs) pretrained on a variety of languages of interest.\nHowever, the performance of these models vary significantly across languages\nand classification tasks, suggesting that the superposition of the language\nmodelling and classification tasks is not always effective. For this reason, in\nthis paper we propose revisiting the classic \"translate-and-test\" pipeline to\nneatly separate the translation and classification stages. The proposed\napproach couples 1) a neural machine translator translating from the targeted\nlanguage to a high-resource language, with 2) a text classifier trained in the\nhigh-resource language, but the neural machine translator generates \"soft\"\ntranslations to permit end-to-end backpropagation during fine-tuning of the\npipeline. Extensive experiments have been carried out over three cross-lingual\ntext classification datasets (XNLI, MLDoc and MultiEURLEX), with the results\nshowing that the proposed approach has significantly improved performance over\na competitive baseline.\n",
                "链接": "https://arxiv.org/abs/2306.04996"
            },
            {
                "文章ID": "32543",
                "标题": "Automatically constructing Wordnet synsets",
                "作者": " Khang Nhut Lam,  Feras Al Tarouti,  Jugal Kalita",
                "发布日期": "2022-10-14",
                "摘要": "  Manually constructing a Wordnet is a difficult task, needing years of\nexperts' time. As a first step to automatically construct full Wordnets, we\npropose approaches to generate Wordnet synsets for languages both resource-rich\nand resource-poor, using publicly available Wordnets, a machine translator\nand/or a single bilingual dictionary. Our algorithms translate synsets of\nexisting Wordnets to a target language T, then apply a ranking method on the\ntranslation candidates to find best translations in T. Our approaches are\napplicable to any language which has at least one existing bilingual dictionary\ntranslating from English to it.\n",
                "链接": "https://arxiv.org/abs/2208.03870"
            },
            {
                "文章ID": "101832",
                "标题": "Mitigating Hallucinations and Off-target Machine Translation with\n  Source-Contrastive and Language-Contrastive Decoding",
                "作者": " Rico Sennrich,  Jannis Vamvas,  Alireza Mohammadshahi",
                "发布日期": "2023-09-14",
                "摘要": "  Hallucinations and off-target translation remain unsolved problems in machine\ntranslation, especially for low-resource languages and massively multilingual\nmodels. In this paper, we introduce methods to mitigate both failure cases with\na modified decoding objective, without requiring retraining or external models.\nIn source-contrastive decoding, we search for a translation that is probable\ngiven the correct input, but improbable given a random input segment,\nhypothesising that hallucinations will be similarly probable given either. In\nlanguage-contrastive decoding, we search for a translation that is probable,\nbut improbable given the wrong language indicator token. In experiments on\nM2M-100 (418M) and SMaLL-100, we find that these methods effectively suppress\nhallucinations and off-target translations, improving chrF2 by 1.7 and 1.4\npoints on average across 57 tested translation directions. In a proof of\nconcept on English--German, we also show that we can suppress off-target\ntranslations with the Llama 2 chat models, demonstrating the applicability of\nthe method to machine translation with LLMs. We release our source code at\nhttps://github.com/ZurichNLP/ContraDecode.\n",
                "链接": "https://arxiv.org/abs/2309.07098"
            },
            {
                "文章ID": "54376",
                "标题": "Improved Long-Form Spoken Language Translation with Large Language\n  Models",
                "作者": " Arya D. McCarthy,  Hao Zhang,  Shankar Kumar,  Felix Stahlberg,  Axel H. Ng",
                "发布日期": "2022-12-21",
                "摘要": "  A challenge in spoken language translation is that plenty of spoken content\nis long-form, but short units are necessary for obtaining high-quality\ntranslations. To address this mismatch, we fine-tune a general-purpose, large\nlanguage model to split long ASR transcripts into segments that can be\nindependently translated so as to maximize the overall translation quality. We\ncompare to several segmentation strategies and find that our approach improves\nBLEU score on three languages by an average of 2.7 BLEU overall compared to an\nautomatic punctuation baseline. Further, we demonstrate the effectiveness of\ntwo constrained decoding strategies to improve well-formedness of the model\noutput from above 99% to 100%.\n",
                "链接": "https://arxiv.org/abs/2212.09895"
            },
            {
                "文章ID": "107076",
                "标题": "CodeTransOcean: A Comprehensive Multilingual Benchmark for Code\n  Translation",
                "作者": " Weixiang Yan,  Yuchen Tian,  Yunzhe Li,  Qian Chen,  Wen Wang",
                "发布日期": "2023-10-26",
                "摘要": "  Recent code translation techniques exploit neural machine translation models\nto translate source code from one programming language to another to satisfy\nproduction compatibility or to improve efficiency of codebase maintenance. Most\nexisting code translation datasets only focus on a single pair of popular\nprogramming languages. To advance research on code translation and meet diverse\nrequirements of real-world applications, we construct CodeTransOcean, a\nlarge-scale comprehensive benchmark that supports the largest variety of\nprogramming languages for code translation. CodeTransOcean consists of three\nnovel multilingual datasets, namely, MultilingualTrans supporting translations\nbetween multiple popular programming languages, NicheTrans for translating\nbetween niche programming languages and popular ones, and LLMTrans for\nevaluating executability of translated code by large language models (LLMs).\nCodeTransOcean also includes a novel cross-framework dataset, DLTrans, for\ntranslating deep learning code across different frameworks. We develop\nmultilingual modeling approaches for code translation and demonstrate their\ngreat potential in improving the translation quality of both low-resource and\nhigh-resource language pairs and boosting the training efficiency. We also\npropose a novel evaluation metric Debugging Success Rate@K for program-level\ncode translation. Last but not least, we evaluate LLM ChatGPT on our datasets\nand investigate its potential for fuzzy execution predictions. We build\nbaselines for CodeTransOcean and analyze challenges of code translation for\nguiding future research. The CodeTransOcean datasets and code are publicly\navailable at https://github.com/WeixiangYAN/CodeTransOcean.\n",
                "链接": "https://arxiv.org/abs/2310.04951"
            },
            {
                "文章ID": "81117",
                "标题": "Do GPTs Produce Less Literal Translations?",
                "作者": " Vikas Raunak,  Arul Menezes,  Matt Post,  Hany Hassan Awadalla",
                "发布日期": "2023-06-07",
                "摘要": "  Large Language Models (LLMs) such as GPT-3 have emerged as general-purpose\nlanguage models capable of addressing many natural language generation or\nunderstanding tasks. On the task of Machine Translation (MT), multiple works\nhave investigated few-shot prompting mechanisms to elicit better translations\nfrom LLMs. However, there has been relatively little investigation on how such\ntranslations differ qualitatively from the translations generated by standard\nNeural Machine Translation (NMT) models. In this work, we investigate these\ndifferences in terms of the literalness of translations produced by the two\nsystems. Using literalness measures involving word alignment and monotonicity,\nwe find that translations out of English (E-X) from GPTs tend to be less\nliteral, while exhibiting similar or better scores on MT quality metrics. We\ndemonstrate that this finding is borne out in human evaluations as well. We\nthen show that these differences are especially pronounced when translating\nsentences that contain idiomatic expressions.\n",
                "链接": "https://arxiv.org/abs/2305.16806"
            }
        ]
    },
    {
        "question": {
            "question": "查找多模态大模型理解和生成统一建模、端到端训练相关论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "94301",
                "标题": "Interpretable End-to-End Driving Model for Implicit Scene Understanding",
                "作者": " Yiyang Sun,  Xiaonian Wang,  Yangyang Zhang,  Jiagui Tang,  Xiaqiang Tang,  Jing Yao",
                "发布日期": "2023-08-03",
                "摘要": "  Driving scene understanding is to obtain comprehensive scene information\nthrough the sensor data and provide a basis for downstream tasks, which is\nindispensable for the safety of self-driving vehicles. Specific perception\ntasks, such as object detection and scene graph generation, are commonly used.\nHowever, the results of these tasks are only equivalent to the characterization\nof sampling from high-dimensional scene features, which are not sufficient to\nrepresent the scenario. In addition, the goal of perception tasks is\ninconsistent with human driving that just focuses on what may affect the\nego-trajectory. Therefore, we propose an end-to-end Interpretable Implicit\nDriving Scene Understanding (II-DSU) model to extract implicit high-dimensional\nscene features as scene understanding results guided by a planning module and\nto validate the plausibility of scene understanding using auxiliary perception\ntasks for visualization. Experimental results on CARLA benchmarks show that our\napproach achieves the new state-of-the-art and is able to obtain scene features\nthat embody richer scene information relevant to driving, enabling superior\nperformance of the downstream planning.\n",
                "链接": "https://arxiv.org/abs/2308.01180"
            },
            {
                "文章ID": "21046",
                "标题": "End-to-End Multimodal Fact-Checking and Explanation Generation: A\n  Challenging Dataset and Models",
                "作者": "Virginia Tech  Barry Menglong Yao, Virginia Tech  Aditya Shah, Lehigh University  Lichao Sun, Virginia Tech  Jin-Hee Cho, Virginia Tech  Lifu Huang",
                "发布日期": "2023-07-10",
                "摘要": "  We propose end-to-end multimodal fact-checking and explanation generation,\nwhere the input is a claim and a large collection of web sources, including\narticles, images, videos, and tweets, and the goal is to assess the\ntruthfulness of the claim by retrieving relevant evidence and predicting a\ntruthfulness label (e.g., support, refute or not enough information), and to\ngenerate a statement to summarize and explain the reasoning and ruling process.\nTo support this research, we construct Mocheg, a large-scale dataset consisting\nof 15,601 claims where each claim is annotated with a truthfulness label and a\nruling statement, and 33,880 textual paragraphs and 12,112 images in total as\nevidence. To establish baseline performances on Mocheg, we experiment with\nseveral state-of-the-art neural architectures on the three pipelined subtasks:\nmultimodal evidence retrieval, claim verification, and explanation generation,\nand demonstrate that the performance of the state-of-the-art end-to-end\nmultimodal fact-checking does not provide satisfactory outcomes. To the best of\nour knowledge, we are the first to build the benchmark dataset and solutions\nfor end-to-end multimodal fact-checking and explanation generation. The\ndataset, source code and model checkpoints are available at\nhttps://github.com/VT-NLP/Mocheg.\n",
                "链接": "https://arxiv.org/abs/2205.12487"
            },
            {
                "文章ID": "12682",
                "标题": "End-to-end Document Recognition and Understanding with Dessurt",
                "作者": " Brian Davis,  Bryan Morse,  Bryan Price,  Chris Tensmeyer,  Curtis Wigington,  Vlad Morariu",
                "发布日期": "2022-06-17",
                "摘要": "  We introduce Dessurt, a relatively simple document understanding transformer\ncapable of being fine-tuned on a greater variety of document tasks than prior\nmethods. It receives a document image and task string as input and generates\narbitrary text autoregressively as output. Because Dessurt is an end-to-end\narchitecture that performs text recognition in addition to the document\nunderstanding, it does not require an external recognition model as prior\nmethods do. Dessurt is a more flexible model than prior methods and is able to\nhandle a variety of document domains and tasks. We show that this model is\neffective at 9 different dataset-task combinations.\n",
                "链接": "https://arxiv.org/abs/2203.16618"
            },
            {
                "文章ID": "75571",
                "标题": "End-to-end Training and Decoding for Pivot-based Cascaded Translation\n  Model",
                "作者": " Hao Cheng,  Meng Zhang,  Liangyou Li,  Qun Liu,  Zhihua Zhang",
                "发布日期": "2023-05-04",
                "摘要": "  Utilizing pivot language effectively can significantly improve low-resource\nmachine translation. Usually, the two translation models, source-pivot and\npivot-target, are trained individually and do not utilize the limited (source,\ntarget) parallel data. This work proposes an end-to-end training method for the\ncascaded translation model and configures an improved decoding algorithm. The\ninput of the pivot-target model is modified to weighted pivot embedding based\non the probability distribution output by the source-pivot model. This allows\nthe model to be trained end-to-end. In addition, we mitigate the inconsistency\nbetween tokens and probability distributions while using beam search in pivot\ndecoding. Experiments demonstrate that our method enhances the quality of\ntranslation.\n",
                "链接": "https://arxiv.org/abs/2305.02261"
            },
            {
                "文章ID": "92569",
                "标题": "Modality Confidence Aware Training for Robust End-to-End Spoken Language\n  Understanding",
                "作者": " Suyoun Kim,  Akshat Shrivastava,  Duc Le,  Ju Lin,  Ozlem Kalinli,  Michael L. Seltzer",
                "发布日期": "2023-07-25",
                "摘要": "  End-to-end (E2E) spoken language understanding (SLU) systems that generate a\nsemantic parse from speech have become more promising recently. This approach\nuses a single model that utilizes audio and text representations from\npre-trained speech recognition models (ASR), and outperforms traditional\npipeline SLU systems in on-device streaming scenarios. However, E2E SLU systems\nstill show weakness when text representation quality is low due to ASR\ntranscription errors. To overcome this issue, we propose a novel E2E SLU system\nthat enhances robustness to ASR errors by fusing audio and text representations\nbased on the estimated modality confidence of ASR hypotheses. We introduce two\nnovel techniques: 1) an effective method to encode the quality of ASR\nhypotheses and 2) an effective approach to integrate them into E2E SLU models.\nWe show accuracy improvements on STOP dataset and share the analysis to\ndemonstrate the effectiveness of our approach.\n",
                "链接": "https://arxiv.org/abs/2307.12134"
            },
            {
                "文章ID": "62000",
                "标题": "JEIT: Joint End-to-End Model and Internal Language Model Training for\n  Speech Recognition",
                "作者": " Zhong Meng,  Weiran Wang,  Rohit Prabhavalkar,  Tara N. Sainath,  Tongzhou Chen,  Ehsan Variani,  Yu Zhang,  Bo Li,  Andrew Rosenberg,  Bhuvana Ramabhadran",
                "发布日期": "2023-02-20",
                "摘要": "  We propose JEIT, a joint end-to-end (E2E) model and internal language model\n(ILM) training method to inject large-scale unpaired text into ILM during E2E\ntraining which improves rare-word speech recognition. With JEIT, the E2E model\ncomputes an E2E loss on audio-transcript pairs while its ILM estimates a\ncross-entropy loss on unpaired text. The E2E model is trained to minimize a\nweighted sum of E2E and ILM losses. During JEIT, ILM absorbs knowledge from\nunpaired text while the E2E training serves as regularization. Unlike ILM\nadaptation methods, JEIT does not require a separate adaptation step and avoids\nthe need for Kullback-Leibler divergence regularization of ILM. We also show\nthat modular hybrid autoregressive transducer (MHAT) performs better than HAT\nin the JEIT framework, and is much more robust than HAT during ILM adaptation.\nTo push the limit of unpaired text injection, we further propose a combined\nJEIT and JOIST training (CJJT) that benefits from modality matching, encoder\ntext injection and ILM training. Both JEIT and CJJT can foster a more effective\nLM fusion. With 100B unpaired sentences, JEIT/CJJT improves rare-word\nrecognition accuracy by up to 16.4% over a model trained without unpaired text.\n",
                "链接": "https://arxiv.org/abs/2302.08583"
            },
            {
                "文章ID": "106028",
                "标题": "Tuning Large language model for End-to-end Speech Translation",
                "作者": " Hao Zhang,  Nianwen Si,  Yaqi Chen,  Wenlin Zhang,  Xukui Yang,  Dan Qu,  Xiaolin Jiao",
                "发布日期": "2023-10-04",
                "摘要": "  With the emergence of large language models (LLMs), multimodal models based\non LLMs have demonstrated significant potential. Models such as LLaSM, X-LLM,\nand SpeechGPT exhibit an impressive ability to comprehend and generate human\ninstructions. However, their performance often falters when faced with complex\ntasks like end-to-end speech translation (E2E-ST), a cross-language and\ncross-modal translation task. In comparison to single-modal models, multimodal\nmodels lag behind in these scenarios. This paper introduces LST, a Large\nmultimodal model designed to excel at the E2E-ST task. LST consists of a speech\nfrontend, an adapter, and a LLM backend. The training of LST consists of two\nstages: (1) Modality adjustment, where the adapter is tuned to align speech\nrepresentation with text embedding space, and (2) Downstream task fine-tuning,\nwhere both the adapter and LLM model are trained to optimize performance on the\nE2EST task. Experimental results on the MuST-C speech translation benchmark\ndemonstrate that LST-13B achieves BLEU scores of 30.39/41.55/35.33 on\nEn-De/En-Fr/En-Es language pairs, surpassing previous models and establishing a\nnew state-of-the-art. Additionally, we conduct an in-depth analysis of\nsingle-modal model selection and the impact of training strategies, which lays\nthe foundation for future research. We will open up our code and models after\nreview.\n",
                "链接": "https://arxiv.org/abs/2310.02050"
            },
            {
                "文章ID": "104271",
                "标题": "LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language\n  Models",
                "作者": " Ahmad Faiz,  Sotaro Kaneda,  Ruhan Wang,  Rita Osi,  Parteek Sharma,  Fan Chen,  Lei Jiang",
                "发布日期": "2023-09-27",
                "摘要": "  The carbon footprint associated with large language models (LLMs) is a\nsignificant concern, encompassing emissions from their training, inference,\nexperimentation, and storage processes, including operational and embodied\ncarbon emissions. An essential aspect is accurately estimating the carbon\nimpact of emerging LLMs even before their training, which heavily relies on GPU\nusage. Existing studies have reported the carbon footprint of LLM training, but\nonly one tool, mlco2, can predict the carbon footprint of new neural networks\nprior to physical training. However, mlco2 has several serious limitations. It\ncannot extend its estimation to dense or mixture-of-experts (MoE) LLMs,\ndisregards critical architectural parameters, focuses solely on GPUs, and\ncannot model embodied carbon footprints. Addressing these gaps, we introduce\n\\textit{LLMCarbon}, an end-to-end carbon footprint projection model designed\nfor both dense and MoE LLMs. Compared to mlco2, LLMCarbon significantly\nenhances the accuracy of carbon footprint estimations for various LLMs.\n",
                "链接": "https://arxiv.org/abs/2309.14393"
            },
            {
                "文章ID": "100055",
                "标题": "End-to-End Learning on Multimodal Knowledge Graphs",
                "作者": " W. X. Wilcke,  P. Bloem,  V. de Boer,  R. H. van t Veer",
                "发布日期": "2023-09-06",
                "摘要": "  Knowledge graphs enable data scientists to learn end-to-end on heterogeneous\nknowledge. However, most end-to-end models solely learn from the relational\ninformation encoded in graphs' structure: raw values, encoded as literal nodes,\nare either omitted completely or treated as regular nodes without consideration\nfor their values. In either case we lose potentially relevant information which\ncould have otherwise been exploited by our learning methods. We propose a\nmultimodal message passing network which not only learns end-to-end from the\nstructure of graphs, but also from their possibly divers set of multimodal node\nfeatures. Our model uses dedicated (neural) encoders to naturally learn\nembeddings for node features belonging to five different types of modalities,\nincluding numbers, texts, dates, images and geometries, which are projected\ninto a joint representation space together with their relational information.\nWe implement and demonstrate our model on node classification and link\nprediction for artificial and real-worlds datasets, and evaluate the effect\nthat each modality has on the overall performance in an inverse ablation study.\nOur results indicate that end-to-end multimodal learning from any arbitrary\nknowledge graph is indeed possible, and that including multimodal information\ncan significantly affect performance, but that much depends on the\ncharacteristics of the data.\n",
                "链接": "https://arxiv.org/abs/2309.01169"
            },
            {
                "文章ID": "12174",
                "标题": "Towards End-to-End Unified Scene Text Detection and Layout Analysis",
                "作者": " Shangbang Long,  Siyang Qin,  Dmitry Panteleev,  Alessandro Bissacco,  Yasuhisa Fujii,  Michalis Raptis",
                "发布日期": "2022-06-06",
                "摘要": "  Scene text detection and document layout analysis have long been treated as\ntwo separate tasks in different image domains. In this paper, we bring them\ntogether and introduce the task of unified scene text detection and layout\nanalysis. The first hierarchical scene text dataset is introduced to enable\nthis novel research task. We also propose a novel method that is able to\nsimultaneously detect scene text and form text clusters in a unified way.\nComprehensive experiments show that our unified model achieves better\nperformance than multiple well-designed baseline methods. Additionally, this\nmodel achieves state-of-the-art results on multiple scene text detection\ndatasets without the need of complex post-processing. Dataset and code:\nhttps://github.com/google-research-datasets/hiertext and\nhttps://github.com/tensorflow/models/tree/master/official/projects/unified_detector.\n",
                "链接": "https://arxiv.org/abs/2203.15143"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下近两年关于语言模型奖励建模评估的文章。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "6241",
                "标题": "Reward Modeling for Mitigating Toxicity in Transformer-based Language\n  Models",
                "作者": " Farshid Faal,  Ketra Schmitt,  Jia Yuan Yu",
                "发布日期": "2022-07-28",
                "摘要": "  Transformer-based language models are able to generate fluent text and be\nefficiently adapted across various natural language generation tasks. However,\nlanguage models that are pretrained on large unlabeled web text corpora have\nbeen shown to suffer from degenerating toxic content and social bias behaviors,\nconsequently hindering their safe deployment. Various detoxification methods\nwere proposed to mitigate the language model's toxicity; however, these methods\nstruggled to detoxify language models when conditioned on prompts that contain\nspecific social identities related to gender, race, or religion. In this study,\nwe propose Reinforce-Detoxify; A reinforcement learning-based method for\nmitigating toxicity in language models. We address the challenge of safety in\nlanguage models and propose a new reward model that is able to detect toxic\ncontent and mitigate unintended bias towards social identities in toxicity\nprediction. The experiments demonstrate that the Reinforce-Detoxify method for\nlanguage model detoxification outperforms existing detoxification approaches in\nautomatic evaluation metrics, indicating the ability of our approach in\nlanguage model detoxification and less prone to unintended bias toward social\nidentities in generated content.\n",
                "链接": "https://arxiv.org/abs/2202.09662"
            },
            {
                "文章ID": "64063",
                "标题": "Reward Design with Language Models",
                "作者": " Minae Kwon,  Sang Michael Xie,  Kalesha Bullard,  Dorsa Sadigh",
                "发布日期": "2023-03-02",
                "摘要": "  Reward design in reinforcement learning (RL) is challenging since specifying\nhuman notions of desired behavior may be difficult via reward functions or\nrequire many expert demonstrations. Can we instead cheaply design rewards using\na natural language interface? This paper explores how to simplify reward design\nby prompting a large language model (LLM) such as GPT-3 as a proxy reward\nfunction, where the user provides a textual prompt containing a few examples\n(few-shot) or a description (zero-shot) of the desired behavior. Our approach\nleverages this proxy reward function in an RL framework. Specifically, users\nspecify a prompt once at the beginning of training. During training, the LLM\nevaluates an RL agent's behavior against the desired behavior described by the\nprompt and outputs a corresponding reward signal. The RL agent then uses this\nreward to update its behavior. We evaluate whether our approach can train\nagents aligned with user objectives in the Ultimatum Game, matrix games, and\nthe DealOrNoDeal negotiation task. In all three tasks, we show that RL agents\ntrained with our framework are well-aligned with the user's objectives and\noutperform RL agents trained with reward functions learned via supervised\nlearning\n",
                "链接": "https://arxiv.org/abs/2303.00001"
            },
            {
                "文章ID": "105659",
                "标题": "Tool-Augmented Reward Modeling",
                "作者": " Lei Li,  Yekun Chai,  Shuohuan Wang,  Yu Sun,  Hao Tian,  Ningyu Zhang,  Hua Wu",
                "发布日期": "2023-10-03",
                "摘要": "  Reward modeling (a.k.a., preference modeling) is instrumental for aligning\nlarge language models with human preferences, particularly within the context\nof reinforcement learning from human feedback (RLHF). While conventional reward\nmodels (RMs) have exhibited remarkable scalability, they oft struggle with\nfundamental functionality such as arithmetic computation, code execution, and\nfactual lookup. In this paper, we propose a tool-augmented preference modeling\napproach, named \\name, to address these limitations by empowering RMs with\naccess to external environments, including calculators and search engines. This\napproach not only fosters synergy between tool utilization and reward grading\nbut also enhances interpretive capacity and scoring reliability. Our study\ndelves into the integration of external tools into RMs, enabling them to\ninteract with diverse external sources and construct task-specific tool\nengagement and reasoning traces in an autoregressive manner. We validate our\napproach across a wide range of domains, incorporating seven distinct external\ntools. Our experimental results demonstrate a noteworthy overall improvement of\n17.7% across eight tasks in preference ranking. Furthermore, our approach\noutperforms Gopher 280B by 7.3% on TruthfulQA task in zero-shot evaluation. In\nhuman evaluations, RLHF trained with Themis attains an average win rate of 32%\nwhen compared to baselines across four distinct tasks. Additionally, we provide\na comprehensive collection of tool-related RM datasets, incorporating data from\nseven distinct tool APIs, totaling 15,000 instances. We anticipate that this\npublicly available dataset will facilitate and inspire further research\nadvancements in the field.\n",
                "链接": "https://arxiv.org/abs/2310.01045"
            },
            {
                "文章ID": "79143",
                "标题": "PrOnto: Language Model Evaluations for 859 Languages",
                "作者": " Luke Gessler",
                "发布日期": "2023-05-23",
                "摘要": "  Evaluation datasets are critical resources for measuring the quality of\npretrained language models. However, due to the high cost of dataset\nannotation, these resources are scarce for most languages other than English,\nmaking it difficult to assess the quality of language models. In this work, we\npresent a new method for evaluation dataset construction which enables any\nlanguage with a New Testament translation to receive a suite of evaluation\ndatasets suitable for pretrained language model evaluation. The method\ncritically involves aligning verses with those in the New Testament portion of\nEnglish OntoNotes, and then projecting annotations from English to the target\nlanguage, with no manual annotation required. We apply this method to 1051 New\nTestament translations in 859 and make them publicly available. Additionally,\nwe conduct experiments which demonstrate the efficacy of our method for\ncreating evaluation tasks which can assess language model quality.\n",
                "链接": "https://arxiv.org/abs/2305.12612"
            },
            {
                "文章ID": "53814",
                "标题": "Attributed Question Answering: Evaluation and Modeling for Attributed\n  Large Language Models",
                "作者": " Bernd Bohnet,  Vinh Q. Tran,  Pat Verga,  Roee Aharoni,  Daniel Andor,  Livio Baldini Soares,  Massimiliano Ciaramita,  Jacob Eisenstein,  Kuzman Ganchev,  Jonathan Herzig,  Kai Hui,  Tom Kwiatkowski,  Ji Ma,  Jianmo Ni,  Lierni Sestorain Saralegui,  Tal Schuster,  William W. Cohen,  Michael Collins,  Dipanjan Das,  Donald Metzler,  Slav Petrov,  Kellie Webster",
                "发布日期": "2023-02-14",
                "摘要": "  Large language models (LLMs) have shown impressive results while requiring\nlittle or no direct supervision. Further, there is mounting evidence that LLMs\nmay have potential in information-seeking scenarios. We believe the ability of\nan LLM to attribute the text that it generates is likely to be crucial in this\nsetting. We formulate and study Attributed QA as a key first step in the\ndevelopment of attributed LLMs. We propose a reproducible evaluation framework\nfor the task and benchmark a broad set of architectures. We take human\nannotations as a gold standard and show that a correlated automatic metric is\nsuitable for development. Our experimental work gives concrete answers to two\nkey questions (How to measure attribution?, and How well do current\nstate-of-the-art methods perform on attribution?), and give some hints as to\nhow to address a third (How to build LLMs with attribution?).\n",
                "链接": "https://arxiv.org/abs/2212.08037"
            },
            {
                "文章ID": "120776",
                "标题": "FoMo Rewards: Can we cast foundation models as reward functions?",
                "作者": " Ekdeep Singh Lubana,  Johann Brehmer,  Pim de Haan,  Taco Cohen",
                "发布日期": "2023-12-08",
                "摘要": "  We explore the viability of casting foundation models as generic reward\nfunctions for reinforcement learning. To this end, we propose a simple pipeline\nthat interfaces an off-the-shelf vision model with a large language model.\nSpecifically, given a trajectory of observations, we infer the likelihood of an\ninstruction describing the task that the user wants an agent to perform. We\nshow that this generic likelihood function exhibits the characteristics ideally\nexpected from a reward function: it associates high values with the desired\nbehaviour and lower values for several similar, but incorrect policies.\nOverall, our work opens the possibility of designing open-ended agents for\ninteractive tasks via foundation models.\n",
                "链接": "https://arxiv.org/abs/2312.03881"
            },
            {
                "文章ID": "78952",
                "标题": "Revisiting Automated Topic Model Evaluation with Large Language Models",
                "作者": " Dominik Stammbach,  Vilém Zouhar,  Alexander Hoyle,  Mrinmaya Sachan,  Elliott Ash",
                "发布日期": "2023-10-24",
                "摘要": "  Topic models are used to make sense of large text collections. However,\nautomatically evaluating topic model output and determining the optimal number\nof topics both have been longstanding challenges, with no effective automated\nsolutions to date. This paper proposes using large language models to evaluate\nsuch output. We find that large language models appropriately assess the\nresulting topics, correlating more strongly with human judgments than existing\nautomated metrics. We then investigate whether we can use large language models\nto automatically determine the optimal number of topics. We automatically\nassign labels to documents and choosing configurations with the most pure\nlabels returns reasonable values for the optimal number of topics.\n",
                "链接": "https://arxiv.org/abs/2305.12152"
            },
            {
                "文章ID": "81507",
                "标题": "Reward Collapse in Aligning Large Language Models",
                "作者": " Ziang Song,  Tianle Cai,  Jason D. Lee,  Weijie J. Su",
                "发布日期": "2023-05-30",
                "摘要": "  The extraordinary capabilities of large language models (LLMs) such as\nChatGPT and GPT-4 are in part unleashed by aligning them with reward models\nthat are trained on human preferences, which are often represented as rankings\nof responses to prompts. In this paper, we document the phenomenon of\n\\textit{reward collapse}, an empirical observation where the prevailing\nranking-based approach results in an \\textit{identical} reward distribution\n\\textit{regardless} of the prompts during the terminal phase of training. This\noutcome is undesirable as open-ended prompts like ``write a short story about\nyour best friend'' should yield a continuous range of rewards for their\ncompletions, while specific prompts like ``what is the capital of New Zealand''\nshould generate either high or low rewards. Our theoretical investigation\nreveals that reward collapse is primarily due to the insufficiency of the\nranking-based objective function to incorporate prompt-related information\nduring optimization. This insight allows us to derive closed-form expressions\nfor the reward distribution associated with a set of utility functions in an\nasymptotic regime. To overcome reward collapse, we introduce a prompt-aware\noptimization scheme that provably admits a prompt-dependent reward distribution\nwithin the interpolating regime. Our experimental results suggest that our\nproposed prompt-aware utility functions significantly alleviate reward collapse\nduring the training of reward models.\n",
                "链接": "https://arxiv.org/abs/2305.17608"
            },
            {
                "文章ID": "79217",
                "标题": "This Prompt is Measuring <MASK>: Evaluating Bias Evaluation in Language\n  Models",
                "作者": " Seraphina Goldfarb-Tarrant,  Eddie Ungless,  Esma Balkir,  Su Lin Blodgett",
                "发布日期": "2023-05-23",
                "摘要": "  Bias research in NLP seeks to analyse models for social biases, thus helping\nNLP practitioners uncover, measure, and mitigate social harms. We analyse the\nbody of work that uses prompts and templates to assess bias in language models.\nWe draw on a measurement modelling framework to create a taxonomy of attributes\nthat capture what a bias test aims to measure and how that measurement is\ncarried out. By applying this taxonomy to 90 bias tests, we illustrate\nqualitatively and quantitatively that core aspects of bias test\nconceptualisations and operationalisations are frequently unstated or\nambiguous, carry implicit assumptions, or be mismatched. Our analysis\nilluminates the scope of possible bias types the field is able to measure, and\nreveals types that are as yet under-researched. We offer guidance to enable the\ncommunity to explore a wider section of the possible bias space, and to better\nclose the gap between desired outcomes and experimental design, both for bias\nand for evaluating language models more broadly.\n",
                "链接": "https://arxiv.org/abs/2305.12757"
            },
            {
                "文章ID": "77473",
                "标题": "MatSci-NLP: Evaluating Scientific Language Models on Materials Science\n  Language Tasks Using Text-to-Schema Modeling",
                "作者": " Yu Song,  Santiago Miret,  Bang Liu",
                "发布日期": "2023-05-16",
                "摘要": "  We present MatSci-NLP, a natural language benchmark for evaluating the\nperformance of natural language processing (NLP) models on materials science\ntext. We construct the benchmark from publicly available materials science text\ndata to encompass seven different NLP tasks, including conventional NLP tasks\nlike named entity recognition and relation classification, as well as NLP tasks\nspecific to materials science, such as synthesis action retrieval which relates\nto creating synthesis procedures for materials. We study various BERT-based\nmodels pretrained on different scientific text corpora on MatSci-NLP to\nunderstand the impact of pretraining strategies on understanding materials\nscience text. Given the scarcity of high-quality annotated data in the\nmaterials science domain, we perform our fine-tuning experiments with limited\ntraining data to encourage the generalize across MatSci-NLP tasks. Our\nexperiments in this low-resource training setting show that language models\npretrained on scientific text outperform BERT trained on general text. MatBERT,\na model pretrained specifically on materials science journals, generally\nperforms best for most tasks. Moreover, we propose a unified text-to-schema for\nmultitask learning on \\benchmark and compare its performance with traditional\nfine-tuning methods. In our analysis of different training methods, we find\nthat our proposed text-to-schema methods inspired by question-answering\nconsistently outperform single and multitask NLP fine-tuning methods. The code\nand datasets are publicly available at\n\\url{https://github.com/BangLab-UdeM-Mila/NLP4MatSci-ACL23}.\n",
                "链接": "https://arxiv.org/abs/2305.08264"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到从位置编码角度改善模型长序列建模能力的相关论文。",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "9782",
                "标题": "Efficient Long Sequence Encoding via Synchronization",
                "作者": " Xiangyang Mou,  Mo Yu,  Bingsheng Yao,  Lifu Huang",
                "发布日期": "2022-03-16",
                "摘要": "  Pre-trained Transformer models have achieved successes in a wide range of NLP\ntasks, but are inefficient when dealing with long input sequences. Existing\nstudies try to overcome this challenge via segmenting the long sequence\nfollowed by hierarchical encoding or post-hoc aggregation. We propose a\nsynchronization mechanism for hierarchical encoding. Our approach first\nidentifies anchor tokens across segments and groups them by their roles in the\noriginal input sequence. Then inside Transformer layer, anchor embeddings are\nsynchronized within their group via a self-attention module. Our approach is a\ngeneral framework with sufficient flexibility -- when adapted to a new task, it\nis easy to be enhanced with the task-specific anchor definitions. Experiments\non two representative tasks with different types of long input texts,\nNarrativeQA summary setting and wild multi-hop reasoning from HotpotQA,\ndemonstrate that our approach is able to improve the global information\nexchange among segments while maintaining efficiency.\n",
                "链接": "https://arxiv.org/abs/2203.07644"
            },
            {
                "文章ID": "27024",
                "标题": "Masked Part-Of-Speech Model: Does Modeling Long Context Help\n  Unsupervised POS-tagging?",
                "作者": " Xiang Zhou,  Shiyue Zhang,  Mohit Bansal",
                "发布日期": "2022-07-01",
                "摘要": "  Previous Part-Of-Speech (POS) induction models usually assume certain\nindependence assumptions (e.g., Markov, unidirectional, local dependency) that\ndo not hold in real languages. For example, the subject-verb agreement can be\nboth long-term and bidirectional. To facilitate flexible dependency modeling,\nwe propose a Masked Part-of-Speech Model (MPoSM), inspired by the recent\nsuccess of Masked Language Models (MLM). MPoSM can model arbitrary tag\ndependency and perform POS induction through the objective of masked POS\nreconstruction. We achieve competitive results on both the English Penn WSJ\ndataset as well as the universal treebank containing 10 diverse languages.\nThough modeling the long-term dependency should ideally help this task, our\nablation study shows mixed trends in different languages. To better understand\nthis phenomenon, we design a novel synthetic experiment that can specifically\ndiagnose the model's ability to learn tag agreement. Surprisingly, we find that\neven strong baselines fail to solve this problem consistently in a very\nsimplified setting: the agreement between adjacent words. Nonetheless, MPoSM\nachieves overall better performance. Lastly, we conduct a detailed error\nanalysis to shed light on other remaining challenges. Our code is available at\nhttps://github.com/owenzx/MPoSM\n",
                "链接": "https://arxiv.org/abs/2206.14969"
            },
            {
                "文章ID": "40615",
                "标题": "WavSpA: Wavelet Space Attention for Boosting Transformers' Long Sequence\n  Learning Ability",
                "作者": " Yufan Zhuang,  Zihan Wang,  Fangbo Tao,  Jingbo Shang",
                "发布日期": "2023-05-24",
                "摘要": "  Transformer and its variants are fundamental neural architectures in deep\nlearning. Recent works show that learning attention in the Fourier space can\nimprove the long sequence learning capability of Transformers. We argue that\nwavelet transform shall be a better choice because it captures both position\nand frequency information with linear time complexity. Therefore, in this\npaper, we systematically study the synergy between wavelet transform and\nTransformers. We propose Wavelet Space Attention (WavSpA) that facilitates\nattention learning in a learnable wavelet coefficient space which replaces the\nattention in Transformers by (1) applying forward wavelet transform to project\nthe input sequences to multi-resolution bases, (2) conducting attention\nlearning in the wavelet coefficient space, and (3) reconstructing the\nrepresentation in input space via backward wavelet transform. Extensive\nexperiments on the Long Range Arena demonstrate that learning attention in the\nwavelet space using either fixed or adaptive wavelets can consistently improve\nTransformer's performance and also significantly outperform learning in Fourier\nspace. We further show our method can enhance Transformer's reasoning\nextrapolation capability over distance on the LEGO chain-of-reasoning task.\n",
                "链接": "https://arxiv.org/abs/2210.01989"
            },
            {
                "文章ID": "6738",
                "标题": "FastRPB: a Scalable Relative Positional Encoding for Long Sequence Tasks",
                "作者": " Maksim Zubkov,  Daniil Gavrilov",
                "发布日期": "2022-02-24",
                "摘要": "  Transformers achieve remarkable performance in various domains, including\nNLP, CV, audio processing, and graph analysis. However, they do not scale well\non long sequence tasks due to their quadratic complexity w.r.t. the inputs\nlength. Linear Transformers were proposed to address this limitation. However,\nthese models have shown weaker performance on the long sequence tasks comparing\nto the original one. In this paper, we explore Linear Transformer models,\nrethinking their two core components. Firstly, we improved Linear Transformer\nwith Shift-Invariant Kernel Function SIKF, which achieve higher accuracy\nwithout loss in speed. Secondly, we introduce FastRPB which stands for Fast\nRelative Positional Bias, which efficiently adds positional information to\nself-attention using Fast Fourier Transformation. FastRPB is independent of the\nself-attention mechanism and can be combined with an original self-attention\nand all its efficient variants. FastRPB has O(N log(N)) computational\ncomplexity, requiring O(N) memory w.r.t. input sequence length N.\n",
                "链接": "https://arxiv.org/abs/2202.11364"
            },
            {
                "文章ID": "42698",
                "标题": "CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling",
                "作者": " Jun Zhang,  Shuyang Jiang,  Jiangtao Feng,  Lin Zheng,  Lingpeng Kong",
                "发布日期": "2023-07-04",
                "摘要": "  Transformer has achieved remarkable success in language, image, and speech\nprocessing. Recently, various efficient attention architectures have been\nproposed to improve transformer's efficiency while largely preserving its\nefficacy, especially in modeling long sequences. A widely-used benchmark to\ntest these efficient methods' capability on long-range modeling is Long Range\nArena (LRA). However, LRA only focuses on the standard bidirectional (or\nnoncausal) self attention, and completely ignores cross attentions and\nunidirectional (or causal) attentions, which are equally important to\ndownstream applications. In this paper, we propose Comprehensive Attention\nBenchmark (CAB) under a fine-grained attention taxonomy with four\ndistinguishable attention patterns, namely, noncausal self, causal self,\nnoncausal cross, and causal cross attentions. CAB collects seven real-world\ntasks from different research areas to evaluate efficient attentions under the\nfour attention patterns. Among these tasks, CAB validates efficient attentions\nin eight backbone networks to show their generalization across neural\narchitectures. We conduct exhaustive experiments to benchmark the performances\nof nine widely-used efficient attention architectures designed with different\nphilosophies on CAB. Extensive experimental results also shed light on the\nfundamental problems of efficient attentions, such as efficiency length against\nvanilla attention, performance consistency across attention patterns, the\nbenefit of attention mechanisms, and interpolation/extrapolation on\nlong-context language modeling.\n",
                "链接": "https://arxiv.org/abs/2210.07661"
            },
            {
                "文章ID": "61456",
                "标题": "Simple Hardware-Efficient Long Convolutions for Sequence Modeling",
                "作者": " Daniel Y. Fu,  Elliot L. Epstein,  Eric Nguyen,  Armin W. Thomas,  Michael Zhang,  Tri Dao,  Atri Rudra,  Christopher Ré",
                "发布日期": "2023-02-15",
                "摘要": "  State space models (SSMs) have high performance on long sequence modeling but\nrequire sophisticated initialization techniques and specialized implementations\nfor high quality and runtime performance. We study whether a simple alternative\ncan match SSMs in performance and efficiency: directly learning long\nconvolutions over the sequence. We find that a key requirement to achieving\nhigh performance is keeping the convolution kernels smooth. We find that simple\ninterventions--such as squashing the kernel weights--result in smooth kernels\nand recover SSM performance on a range of tasks including the long range arena,\nimage classification, language modeling, and brain data modeling. Next, we\ndevelop FlashButterfly, an IO-aware algorithm to improve the runtime\nperformance of long convolutions. FlashButterfly appeals to classic Butterfly\ndecompositions of the convolution to reduce GPU memory IO and increase FLOP\nutilization. FlashButterfly speeds up convolutions by 2.2$\\times$, and allows\nus to train on Path256, a challenging task with sequence length 64K, where we\nset state-of-the-art by 29.1 points while training 7.2$\\times$ faster than\nprior work. Lastly, we introduce an extension to FlashButterfly that learns the\ncoefficients of the Butterfly decomposition, increasing expressivity without\nincreasing runtime. Using this extension, we outperform a Transformer on\nWikiText103 by 0.2 PPL with 30% fewer parameters.\n",
                "链接": "https://arxiv.org/abs/2302.06646"
            },
            {
                "文章ID": "4941",
                "标题": "Help Me Explore: Minimal Social Interventions for Graph-Based Autotelic\n  Agents",
                "作者": " Ahmed Akakzia,  Olivier Serris,  Olivier Sigaud,  Cédric Colas",
                "发布日期": "2022-02-11",
                "摘要": "  In the quest for autonomous agents learning open-ended repertoires of skills,\nmost works take a Piagetian perspective: learning trajectories are the results\nof interactions between developmental agents and their physical environment.\nThe Vygotskian perspective, on the other hand, emphasizes the centrality of the\nsocio-cultural environment: higher cognitive functions emerge from\ntransmissions of socio-cultural processes internalized by the agent. This paper\nargues that both perspectives could be coupled within the learning of autotelic\nagents to foster their skill acquisition. To this end, we make two\ncontributions: 1) a novel social interaction protocol called Help Me Explore\n(HME), where autotelic agents can benefit from both individual and socially\nguided exploration. In social episodes, a social partner suggests goals at the\nfrontier of the learning agent knowledge. In autotelic episodes, agents can\neither learn to master their own discovered goals or autonomously rehearse\nfailed social goals; 2) GANGSTR, a graph-based autotelic agent for manipulation\ndomains capable of decomposing goals into sequences of intermediate sub-goals.\nWe show that when learning within HME, GANGSTR overcomes its individual\nlearning limits by mastering the most complex configurations (e.g. stacks of 5\nblocks) with only few social interventions.\n",
                "链接": "https://arxiv.org/abs/2202.05129"
            },
            {
                "文章ID": "77364",
                "标题": "FoundWright: A System to Help People Re-find Pages from Their\n  Web-history",
                "作者": " Haekyu Park,  Gonzalo Ramos,  Jina Suh,  Christopher Meek,  Rachel Ng,  Mary Czerwinski",
                "发布日期": "2023-05-16",
                "摘要": "  Re-finding information is an essential activity, however, it can be difficult\nwhen people struggle to express what they are looking for. Through a\nneed-finding survey, we first seek opportunities for improving re-finding\nexperiences, and explore one of these opportunities by implementing the\nFoundWright system. The system leverages recent advances in language\ntransformer models to expand people's ability to express what they are looking\nfor, through the interactive creation and manipulation of concepts contained\nwithin documents. We use FoundWright as a design probe to understand (1) how\npeople create and use concepts, (2) how this expanded ability helps re-finding,\nand (3) how people engage and collaborate with FoundWright's machine learning\nsupport. Our probe reveals that this expanded way of expressing re-finding\ngoals helps people with the task, by complementing traditional searching and\nbrowsing. Finally, we present insights and recommendations for future work\naiming at developing systems to support re-finding.\n",
                "链接": "https://arxiv.org/abs/2305.07930"
            },
            {
                "文章ID": "43292",
                "标题": "What Makes Convolutional Models Great on Long Sequence Modeling?",
                "作者": " Yuhong Li,  Tianle Cai,  Yi Zhang,  Deming Chen,  Debadeepta Dey",
                "发布日期": "2022-10-18",
                "摘要": "  Convolutional models have been widely used in multiple domains. However, most\nexisting models only use local convolution, making the model unable to handle\nlong-range dependency efficiently. Attention overcomes this problem by\naggregating global information but also makes the computational complexity\nquadratic to the sequence length. Recently, Gu et al. [2021] proposed a model\ncalled S4 inspired by the state space model. S4 can be efficiently implemented\nas a global convolutional model whose kernel size equals the input sequence\nlength. S4 can model much longer sequences than Transformers and achieve\nsignificant gains over SoTA on several long-range tasks. Despite its empirical\nsuccess, S4 is involved. It requires sophisticated parameterization and\ninitialization schemes. As a result, S4 is less intuitive and hard to use. Here\nwe aim to demystify S4 and extract basic principles that contribute to the\nsuccess of S4 as a global convolutional model. We focus on the structure of the\nconvolution kernel and identify two critical but intuitive principles enjoyed\nby S4 that are sufficient to make up an effective global convolutional model:\n1) The parameterization of the convolutional kernel needs to be efficient in\nthe sense that the number of parameters should scale sub-linearly with sequence\nlength. 2) The kernel needs to satisfy a decaying structure that the weights\nfor convolving with closer neighbors are larger than the more distant ones.\nBased on the two principles, we propose a simple yet effective convolutional\nmodel called Structured Global Convolution (SGConv). SGConv exhibits strong\nempirical performance over several tasks: 1) With faster speed, SGConv\nsurpasses S4 on Long Range Arena and Speech Command datasets. 2) When plugging\nSGConv into standard language and vision models, it shows the potential to\nimprove both efficiency and performance.\n",
                "链接": "https://arxiv.org/abs/2210.09298"
            },
            {
                "文章ID": "53852",
                "标题": "Efficient Long Sequence Modeling via State Space Augmented Transformer",
                "作者": " Simiao Zuo,  Xiaodong Liu,  Jian Jiao,  Denis Charles,  Eren Manavoglu,  Tuo Zhao,  Jianfeng Gao",
                "发布日期": "2022-12-19",
                "摘要": "  Transformer models have achieved superior performance in various natural\nlanguage processing tasks. However, the quadratic computational cost of the\nattention mechanism limits its practicality for long sequences. There are\nexisting attention variants that improve the computational efficiency, but they\nhave limited ability to effectively compute global information. In parallel to\nTransformer models, state space models (SSMs) are tailored for long sequences,\nbut they are not flexible enough to capture complicated local information. We\npropose SPADE, short for $\\underline{\\textbf{S}}$tate\ns$\\underline{\\textbf{P}}$ace\n$\\underline{\\textbf{A}}$ugmente$\\underline{\\textbf{D}}$\nTransform$\\underline{\\textbf{E}}$r. Specifically, we augment a SSM into the\nbottom layer of SPADE, and we employ efficient local attention methods for the\nother layers. The SSM augments global information, which complements the lack\nof long-range dependency issue in local attention methods. Experimental results\non the Long Range Arena benchmark and language modeling tasks demonstrate the\neffectiveness of the proposed method. To further demonstrate the scalability of\nSPADE, we pre-train large encoder-decoder models and present fine-tuning\nresults on natural language understanding and natural language generation\ntasks.\n",
                "链接": "https://arxiv.org/abs/2212.08136"
            }
        ]
    },
    {
        "question": {
            "question": "利用大模型做数学题生成的论文",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "2917",
                "标题": "Generative Adversarial Exploration for Reinforcement Learning",
                "作者": " Weijun Hong,  Menghui Zhu,  Minghuan Liu,  Weinan Zhang,  Ming Zhou,  Yong Yu,  Peng Sun",
                "发布日期": "2022-01-28",
                "摘要": "  Exploration is crucial for training the optimal reinforcement learning (RL)\npolicy, where the key is to discriminate whether a state visiting is novel.\nMost previous work focuses on designing heuristic rules or distance metrics to\ncheck whether a state is novel without considering such a discrimination\nprocess that can be learned. In this paper, we propose a novel method called\ngenerative adversarial exploration (GAEX) to encourage exploration in RL via\nintroducing an intrinsic reward output from a generative adversarial network,\nwhere the generator provides fake samples of states that help discriminator\nidentify those less frequently visited states. Thus the agent is encouraged to\nvisit those states which the discriminator is less confident to judge as\nvisited. GAEX is easy to implement and of high training efficiency. In our\nexperiments, we apply GAEX into DQN and the DQN-GAEX algorithm achieves\nconvincing performance on challenging exploration problems, including the game\nVenture, Montezuma's Revenge and Super Mario Bros, without further fine-tuning\non complicate learning algorithms. To our knowledge, this is the first work to\nemploy GAN in RL exploration problems.\n",
                "链接": "https://arxiv.org/abs/2201.11685"
            },
            {
                "文章ID": "7747",
                "标题": "Generative Adversarial Networks",
                "作者": " Gilad Cohen,  Raja Giryes",
                "发布日期": "2022-03-02",
                "摘要": "  Generative Adversarial Networks (GANs) are very popular frameworks for\ngenerating high-quality data, and are immensely used in both the academia and\nindustry in many domains. Arguably, their most substantial impact has been in\nthe area of computer vision, where they achieve state-of-the-art image\ngeneration. This chapter gives an introduction to GANs, by discussing their\nprinciple mechanism and presenting some of their inherent problems during\ntraining and evaluation. We focus on these three issues: (1) mode collapse, (2)\nvanishing gradients, and (3) generation of low-quality images. We then list\nsome architecture-variant and loss-variant GANs that remedy the above\nchallenges. Lastly, we present two utilization examples of GANs for real-world\napplications: Data augmentation and face images generation.\n",
                "链接": "https://arxiv.org/abs/2203.00667"
            },
            {
                "文章ID": "97252",
                "标题": "Generative Adversarial Networks Unlearning",
                "作者": " Hui Sun,  Tianqing Zhu,  Wenhan Chang,  Wanlei Zhou",
                "发布日期": "2023-08-22",
                "摘要": "  As machine learning continues to develop, and data misuse scandals become\nmore prevalent, individuals are becoming increasingly concerned about their\npersonal information and are advocating for the right to remove their data.\nMachine unlearning has emerged as a solution to erase training data from\ntrained machine learning models. Despite its success in classifiers, research\non Generative Adversarial Networks (GANs) is limited due to their unique\narchitecture, including a generator and a discriminator. One challenge pertains\nto generator unlearning, as the process could potentially disrupt the\ncontinuity and completeness of the latent space. This disruption might\nconsequently diminish the model's effectiveness after unlearning. Another\nchallenge is how to define a criterion that the discriminator should perform\nfor the unlearning images. In this paper, we introduce a substitution mechanism\nand define a fake label to effectively mitigate these challenges. Based on the\nsubstitution mechanism and fake label, we propose a cascaded unlearning\napproach for both item and class unlearning within GAN models, in which the\nunlearning and learning processes run in a cascaded manner. We conducted a\ncomprehensive evaluation of the cascaded unlearning technique using the MNIST\nand CIFAR-10 datasets. Experimental results demonstrate that this approach\nachieves significantly improved item and class unlearning efficiency, reducing\nthe required time by up to 185x and 284x for the MNIST and CIFAR-10 datasets,\nrespectively, in comparison to retraining from scratch. Notably, although the\nmodel's performance experiences minor degradation after unlearning, this\nreduction is negligible when dealing with a minimal number of images (e.g., 64)\nand has no adverse effects on downstream tasks such as classification.\n",
                "链接": "https://arxiv.org/abs/2308.09881"
            },
            {
                "文章ID": "22740",
                "标题": "Causality Learning With Wasserstein Generative Adversarial Networks",
                "作者": " Hristo Petkov,  Colin Hanley,  Feng Dong",
                "发布日期": "2022-06-06",
                "摘要": "  Conventional methods for causal structure learning from data face significant\nchallenges due to combinatorial search space. Recently, the problem has been\nformulated into a continuous optimization framework with an acyclicity\nconstraint to learn Directed Acyclic Graphs (DAGs). Such a framework allows the\nutilization of deep generative models for causal structure learning to better\ncapture the relations between data sample distributions and DAGs. However, so\nfar no study has experimented with the use of Wasserstein distance in the\ncontext of causal structure learning. Our model named DAG-WGAN combines the\nWasserstein-based adversarial loss with an acyclicity constraint in an\nauto-encoder architecture. It simultaneously learns causal structures while\nimproving its data generation capability. We compare the performance of\nDAG-WGAN with other models that do not involve the Wasserstein metric in order\nto identify its contribution to causal structure learning. Our model performs\nbetter with high cardinality data according to our experiments.\n",
                "链接": "https://arxiv.org/abs/2206.01496"
            },
            {
                "文章ID": "8913",
                "标题": "Machine Learning in NextG Networks via Generative Adversarial Networks",
                "作者": " Ender Ayanoglu,  Kemal Davaslioglu,  Yalin E. Sagduyu",
                "发布日期": "2022-03-10",
                "摘要": "  Generative Adversarial Networks (GANs) are Machine Learning (ML) algorithms\nthat have the ability to address competitive resource allocation problems\ntogether with detection and mitigation of anomalous behavior. In this paper, we\ninvestigate their use in next-generation (NextG) communications within the\ncontext of cognitive networks to address i) spectrum sharing, ii) detecting\nanomalies, and iii) mitigating security attacks. GANs have the following\nadvantages. First, they can learn and synthesize field data, which can be\ncostly, time consuming, and nonrepeatable. Second, they enable pre-training\nclassifiers by using semi-supervised data. Third, they facilitate increased\nresolution. Fourth, they enable the recovery of corrupted bits in the spectrum.\nThe paper provides the basics of GANs, a comparative discussion on different\nkinds of GANs, performance measures for GANs in computer vision and image\nprocessing as well as wireless applications, a number of datasets for wireless\napplications, performance measures for general classifiers, a survey of the\nliterature on GANs for i)-iii) above, and future research directions. As a use\ncase of GAN for NextG communications, we show that a GAN can be effectively\napplied for anomaly detection in signal classification (e.g., user\nauthentication) outperforming another state-of-the-art ML technique such as an\nautoencoder.\n",
                "链接": "https://arxiv.org/abs/2203.04453"
            },
            {
                "文章ID": "28364",
                "标题": "Generative Adversarial Networks and Other Generative Models",
                "作者": " Markus Wenzel",
                "发布日期": "2022-07-11",
                "摘要": "  Generative networks are fundamentally different in their aim and methods\ncompared to CNNs for classification, segmentation, or object detection. They\nhave initially not been meant to be an image analysis tool, but to produce\nnaturally looking images. The adversarial training paradigm has been proposed\nto stabilize generative methods, and has proven to be highly successful --\nthough by no means from the first attempt.\n  This chapter gives a basic introduction into the motivation for Generative\nAdversarial Networks (GANs) and traces the path of their success by abstracting\nthe basic task and working mechanism, and deriving the difficulty of early\npractical approaches. Methods for a more stable training will be shown, and\nalso typical signs for poor convergence and their reasons.\n  Though this chapter focuses on GANs that are meant for image generation and\nimage analysis, the adversarial training paradigm itself is not specific to\nimages, and also generalizes to tasks in image analysis. Examples of\narchitectures for image semantic segmentation and abnormality detection will be\nacclaimed, before contrasting GANs with further generative modeling approaches\nlately entering the scene. This will allow a contextualized view on the limits\nbut also benefits of GANs.\n",
                "链接": "https://arxiv.org/abs/2207.03887"
            },
            {
                "文章ID": "8044",
                "标题": "Curvature Graph Generative Adversarial Networks",
                "作者": " Jianxin Li,  Xingcheng Fu,  Qingyun Sun,  Cheng Ji,  Jiajun Tan,  Jia Wu,  Hao Peng",
                "发布日期": "2022-03-04",
                "摘要": "  Generative adversarial network (GAN) is widely used for generalized and\nrobust learning on graph data. However, for non-Euclidean graph data, the\nexisting GAN-based graph representation methods generate negative samples by\nrandom walk or traverse in discrete space, leading to the information loss of\ntopological properties (e.g. hierarchy and circularity). Moreover, due to the\ntopological heterogeneity (i.e., different densities across the graph\nstructure) of graph data, they suffer from serious topological distortion\nproblems. In this paper, we proposed a novel Curvature Graph Generative\nAdversarial Networks method, named \\textbf{\\modelname}, which is the first\nGAN-based graph representation method in the Riemannian geometric manifold. To\nbetter preserve the topological properties, we approximate the discrete\nstructure as a continuous Riemannian geometric manifold and generate negative\nsamples efficiently from the wrapped normal distribution. To deal with the\ntopological heterogeneity, we leverage the Ricci curvature for local structures\nwith different topological properties, obtaining to low-distortion\nrepresentations. Extensive experiments show that CurvGAN consistently and\nsignificantly outperforms the state-of-the-art methods across multiple tasks\nand shows superior robustness and generalization.\n",
                "链接": "https://arxiv.org/abs/2203.01604"
            },
            {
                "文章ID": "74310",
                "标题": "Directed Chain Generative Adversarial Networks",
                "作者": " Ming Min,  Ruimeng Hu,  Tomoyuki Ichiba",
                "发布日期": "2023-05-08",
                "摘要": "  Real-world data can be multimodal distributed, e.g., data describing the\nopinion divergence in a community, the interspike interval distribution of\nneurons, and the oscillators natural frequencies. Generating multimodal\ndistributed real-world data has become a challenge to existing generative\nadversarial networks (GANs). For example, neural stochastic differential\nequations (Neural SDEs), treated as infinite-dimensional GANs, have\ndemonstrated successful performance mainly in generating unimodal time series\ndata. In this paper, we propose a novel time series generator, named directed\nchain GANs (DC-GANs), which inserts a time series dataset (called a\nneighborhood process of the directed chain or input) into the drift and\ndiffusion coefficients of the directed chain SDEs with distributional\nconstraints. DC-GANs can generate new time series of the same distribution as\nthe neighborhood process, and the neighborhood process will provide the key\nstep in learning and generating multimodal distributed time series. The\nproposed DC-GANs are examined on four datasets, including two stochastic models\nfrom social sciences and computational neuroscience, and two real-world\ndatasets on stock prices and energy consumption. To our best knowledge, DC-GANs\nare the first work that can generate multimodal time series data and\nconsistently outperforms state-of-the-art benchmarks with respect to measures\nof distribution, data similarity, and predictive ability.\n",
                "链接": "https://arxiv.org/abs/2304.13131"
            },
            {
                "文章ID": "67848",
                "标题": "CoopInit: Initializing Generative Adversarial Networks via Cooperative\n  Learning",
                "作者": " Yang Zhao,  Jianwen Xie,  Ping Li",
                "发布日期": "2023-03-22",
                "摘要": "  Numerous research efforts have been made to stabilize the training of the\nGenerative Adversarial Networks (GANs), such as through regularization and\narchitecture design. However, we identify the instability can also arise from\nthe fragile balance at the early stage of adversarial learning. This paper\nproposes the CoopInit, a simple yet effective cooperative learning-based\ninitialization strategy that can quickly learn a good starting point for GANs,\nwith a very small computation overhead during training. The proposed algorithm\nconsists of two learning stages: (i) Cooperative initialization stage: The\ndiscriminator of GAN is treated as an energy-based model (EBM) and is optimized\nvia maximum likelihood estimation (MLE), with the help of the GAN's generator\nto provide synthetic data to approximate the learning gradients. The EBM also\nguides the MLE learning of the generator via MCMC teaching; (ii) Adversarial\nfinalization stage: After a few iterations of initialization, the algorithm\nseamlessly transits to the regular mini-max adversarial training until\nconvergence. The motivation is that the MLE-based initialization stage drives\nthe model towards mode coverage, which is helpful in alleviating the issue of\nmode dropping during the adversarial learning stage. We demonstrate the\neffectiveness of the proposed approach on image generation and one-sided\nunpaired image-to-image translation tasks through extensive experiments.\n",
                "链接": "https://arxiv.org/abs/2303.11649"
            },
            {
                "文章ID": "20574",
                "标题": "Time-series Transformer Generative Adversarial Networks",
                "作者": " Padmanaba Srinivasan,  William J. Knottenbelt",
                "发布日期": "2022-05-24",
                "摘要": "  Many real-world tasks are plagued by limitations on data: in some instances\nvery little data is available and in others, data is protected by privacy\nenforcing regulations (e.g. GDPR). We consider limitations posed specifically\non time-series data and present a model that can generate synthetic time-series\nwhich can be used in place of real data. A model that generates synthetic\ntime-series data has two objectives: 1) to capture the stepwise conditional\ndistribution of real sequences, and 2) to faithfully model the joint\ndistribution of entire real sequences. Autoregressive models trained via\nmaximum likelihood estimation can be used in a system where previous\npredictions are fed back in and used to predict future ones; in such models,\nerrors can accrue over time. Furthermore, a plausible initial value is required\nmaking MLE based models not really generative. Many downstream tasks learn to\nmodel conditional distributions of the time-series, hence, synthetic data drawn\nfrom a generative model must satisfy 1) in addition to performing 2). We\npresent TsT-GAN, a framework that capitalises on the Transformer architecture\nto satisfy the desiderata and compare its performance against five\nstate-of-the-art models on five datasets and show that TsT-GAN achieves higher\npredictive performance on all datasets.\n",
                "链接": "https://arxiv.org/abs/2205.11164"
            }
        ]
    },
    {
        "question": {
            "question": "请帮我找到，最早提出分布式词表示的论文是哪一篇？",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "87597",
                "标题": "IERL: Interpretable Ensemble Representation Learning -- Combining\n  CrowdSourced Knowledge and Distributed Semantic Representations",
                "作者": " Yuxin Zi,  Kaushik Roy,  Vignesh Narayanan,  Manas Gaur,  Amit Sheth",
                "发布日期": "2023-06-27",
                "摘要": "  Large Language Models (LLMs) encode meanings of words in the form of\ndistributed semantics. Distributed semantics capture common statistical\npatterns among language tokens (words, phrases, and sentences) from large\namounts of data. LLMs perform exceedingly well across General Language\nUnderstanding Evaluation (GLUE) tasks designed to test a model's understanding\nof the meanings of the input tokens. However, recent studies have shown that\nLLMs tend to generate unintended, inconsistent, or wrong texts as outputs when\nprocessing inputs that were seen rarely during training, or inputs that are\nassociated with diverse contexts (e.g., well-known hallucination phenomenon in\nlanguage generation tasks). Crowdsourced and expert-curated knowledge graphs\nsuch as ConceptNet are designed to capture the meaning of words from a compact\nset of well-defined contexts. Thus LLMs may benefit from leveraging such\nknowledge contexts to reduce inconsistencies in outputs. We propose a novel\nensemble learning method, Interpretable Ensemble Representation Learning\n(IERL), that systematically combines LLM and crowdsourced knowledge\nrepresentations of input tokens. IERL has the distinct advantage of being\ninterpretable by design (when was the LLM context used vs. when was the\nknowledge context used?) over state-of-the-art (SOTA) methods, allowing\nscrutiny of the inputs in conjunction with the parameters of the model,\nfacilitating the analysis of models' inconsistent or irrelevant outputs.\nAlthough IERL is agnostic to the choice of LLM and crowdsourced knowledge, we\ndemonstrate our approach using BERT and ConceptNet. We report improved or\ncompetitive results with IERL across GLUE tasks over current SOTA methods and\nsignificantly enhanced model interpretability.\n",
                "链接": "https://arxiv.org/abs/2306.13865"
            },
            {
                "文章ID": "19560",
                "标题": "KGNN: Distributed Framework for Graph Neural Knowledge Representation",
                "作者": " Binbin Hu,  Zhiyang Hu,  Zhiqiang Zhang,  Jun Zhou,  Chuan Shi",
                "发布日期": "2022-05-18",
                "摘要": "  Knowledge representation learning has been commonly adopted to incorporate\nknowledge graph (KG) into various online services. Although existing knowledge\nrepresentation learning methods have achieved considerable performance\nimprovement, they ignore high-order structure and abundant attribute\ninformation, resulting unsatisfactory performance on semantics-rich KGs.\nMoreover, they fail to make prediction in an inductive manner and cannot scale\nto large industrial graphs. To address these issues, we develop a novel\nframework called KGNN to take full advantage of knowledge data for\nrepresentation learning in the distributed learning system. KGNN is equipped\nwith GNN based encoder and knowledge aware decoder, which aim to jointly\nexplore high-order structure and attribute information together in a\nfine-grained fashion and preserve the relation patterns in KGs, respectively.\nExtensive experiments on three datasets for link prediction and triplet\nclassification task demonstrate the effectiveness and scalability of KGNN\nframework.\n",
                "链接": "https://arxiv.org/abs/2205.08285"
            },
            {
                "文章ID": "73435",
                "标题": "Distributed Neural Representation for Reactive in situ Visualization",
                "作者": " Qi Wu,  Joseph A. Insley,  Victor A. Mateevitsi,  Silvio Rizzi,  Michael E. Papka,  Kwan-Liu Ma",
                "发布日期": "2023-04-21",
                "摘要": "  In situ visualization and steering of computational modeling can be\neffectively achieved using reactive programming, which leverages temporal\nabstraction and data caching mechanisms to create dynamic workflows. However,\nimplementing a temporal cache for large-scale simulations can be challenging.\nImplicit neural networks have proven effective in compressing large volume\ndata. However, their application to distributed data has yet to be fully\nexplored. In this work, we develop an implicit neural representation for\ndistributed volume data and incorporate it into the DIVA reactive programming\nsystem. This implementation enables us to build an in situ temporal caching\nsystem with a capacity 100 times larger than previously achieved. We integrate\nour implementation into the Ascent infrastructure and evaluate its performance\nusing real-world simulations.\n",
                "链接": "https://arxiv.org/abs/2304.10516"
            },
            {
                "文章ID": "686",
                "标题": "Coherence-Based Distributed Document Representation Learning for\n  Scientific Documents",
                "作者": " Shicheng Tan,  Shu Zhao,  Yanping Zhang",
                "发布日期": "2022-01-11",
                "摘要": "  Distributed document representation is one of the basic problems in natural\nlanguage processing. Currently distributed document representation methods\nmainly consider the context information of words or sentences. These methods do\nnot take into account the coherence of the document as a whole, e.g., a\nrelation between the paper title and abstract, headline and description, or\nadjacent bodies in the document. The coherence shows whether a document is\nmeaningful, both logically and syntactically, especially in scientific\ndocuments (papers or patents, etc.). In this paper, we propose a coupled text\npair embedding (CTPE) model to learn the representation of scientific\ndocuments, which maintains the coherence of the document with coupled text\npairs formed by segmenting the document. First, we divide the document into two\nparts (e.g., title and abstract, etc) which construct a coupled text pair.\nThen, we adopt negative sampling to construct uncoupled text pairs whose two\nparts are from different documents. Finally, we train the model to judge\nwhether the text pair is coupled or uncoupled and use the obtained embedding of\ncoupled text pairs as the embedding of documents. We perform experiments on\nthree datasets for one information retrieval task and two recommendation tasks.\nThe experimental results verify the effectiveness of the proposed CTPE model.\n",
                "链接": "https://arxiv.org/abs/2201.02846"
            },
            {
                "文章ID": "1090",
                "标题": "Local2Global: A distributed approach for scaling representation learning\n  on graphs",
                "作者": " Lucas G. S. Jeub,  Giovanni Colavizza,  Xiaowen Dong,  Marya Bazzi,  Mihai Cucuringu",
                "发布日期": "2022-01-14",
                "摘要": "  We propose a decentralised \"local2global\"' approach to graph representation\nlearning, that one can a-priori use to scale any embedding technique. Our\nlocal2global approach proceeds by first dividing the input graph into\noverlapping subgraphs (or \"patches\") and training local representations for\neach patch independently. In a second step, we combine the local\nrepresentations into a globally consistent representation by estimating the set\nof rigid motions that best align the local representations using information\nfrom the patch overlaps, via group synchronization. A key distinguishing\nfeature of local2global relative to existing work is that patches are trained\nindependently without the need for the often costly parameter synchronization\nduring distributed training. This allows local2global to scale to large-scale\nindustrial applications, where the input graph may not even fit into memory and\nmay be stored in a distributed manner. We apply local2global on data sets of\ndifferent sizes and show that our approach achieves a good trade-off between\nscale and accuracy on edge reconstruction and semi-supervised classification.\nWe also consider the downstream task of anomaly detection and show how one can\nuse local2global to highlight anomalies in cybersecurity networks.\n",
                "链接": "https://arxiv.org/abs/2201.04729"
            },
            {
                "文章ID": "22285",
                "标题": "Distributed Graph Neural Network Training with Periodic Stale\n  Representation Synchronization",
                "作者": " Zheng Chai,  Guangji Bai,  Liang Zhao,  Yue Cheng",
                "发布日期": "2022-10-04",
                "摘要": "  Despite the recent success of Graph Neural Networks, it remains challenging\nto train a GNN on large graphs with millions of nodes and billions of edges,\nwhich are prevalent in many graph-based applications. Traditional\nsampling-based methods accelerate GNN training by dropping edges and nodes,\nwhich impairs the graph integrity and model performance. Differently,\ndistributed GNN algorithms accelerate GNN training by utilizing multiple\ncomputing devices and can be classified into two types: \"partition-based\"\nmethods enjoy low communication costs but suffer from information loss due to\ndropped edges, while \"propagation-based\" methods avoid information loss but\nsuffer from prohibitive communication overhead caused by the neighbor\nexplosion. To jointly address these problems, this paper proposes DIGEST\n(DIstributed Graph reprEsentation SynchronizaTion), a novel distributed GNN\ntraining framework that synergizes the complementary strength of both\ncategories of existing methods. We propose to allow each device to utilize the\nstale representations of its neighbors in other subgraphs during subgraph\nparallel training. This way, our method preserves global graph information from\nneighbors to avoid information loss and reduce communication costs. Our\nconvergence analysis demonstrates that DIGEST enjoys a state-of-the-art\nconvergence rate. Extensive experimental evaluation on large, real-world graph\ndatasets shows that DIGEST achieves up to 21.82 speedups without compromising\nperformance compared to state-of-the-art distributed GNN training frameworks.\n",
                "链接": "https://arxiv.org/abs/2206.00057"
            },
            {
                "文章ID": "86603",
                "标题": "Distributed Marker Representation for Ambiguous Discourse Markers and\n  Entangled Relations",
                "作者": " Dongyu Ru,  Lin Qiu,  Xipeng Qiu,  Yue Zhang,  Zheng Zhang",
                "发布日期": "2023-06-21",
                "摘要": "  Discourse analysis is an important task because it models intrinsic semantic\nstructures between sentences in a document. Discourse markers are natural\nrepresentations of discourse in our daily language. One challenge is that the\nmarkers as well as pre-defined and human-labeled discourse relations can be\nambiguous when describing the semantics between sentences. We believe that a\nbetter approach is to use a contextual-dependent distribution over the markers\nto express discourse information. In this work, we propose to learn a\nDistributed Marker Representation (DMR) by utilizing the (potentially)\nunlimited discourse marker data with a latent discourse sense, thereby bridging\nmarkers with sentence pairs. Such representations can be learned automatically\nfrom data without supervision, and in turn provide insights into the data\nitself. Experiments show the SOTA performance of our DMR on the implicit\ndiscourse relation recognition task and strong interpretability. Our method\nalso offers a valuable tool to understand complex ambiguity and entanglement\namong discourse markers and manually defined discourse relations.\n",
                "链接": "https://arxiv.org/abs/2306.10658"
            },
            {
                "文章ID": "106443",
                "标题": "Test Case Recommendations with Distributed Representation of Code\n  Syntactic Features",
                "作者": " Mosab Rezaei,  Hamed Alhoori,  Mona Rahimi",
                "发布日期": "2023-10-06",
                "摘要": "  Frequent modifications of unit test cases are inevitable due to software's\ncontinuous underlying changes in source code, design, and requirements. Since\nmanually maintaining software test suites is tedious, timely, and costly,\nautomating the process of generation and maintenance of test units will\nsignificantly impact the effectiveness and efficiency of software testing\nprocesses.\n  To this end, we propose an automated approach which exploits both structural\nand semantic properties of source code methods and test cases to recommend the\nmost relevant and useful unit tests to the developers. The proposed approach\ninitially trains a neural network to transform method-level source code, as\nwell as unit tests, into distributed representations (embedded vectors) while\npreserving the importance of the structure in the code. Retrieving the semantic\nand structural properties of a given method, the approach computes cosine\nsimilarity between the method's embedding and the previously-embedded training\ninstances. Further, according to the similarity scores between the embedding\nvectors, the model identifies the closest methods of embedding and the\nassociated unit tests as the most similar recommendations.\n  The results on the Methods2Test dataset showed that, while there is no\nguarantee to have similar relevant test cases for the group of similar methods,\nthe proposed approach extracts the most similar existing test cases for a given\nmethod in the dataset, and evaluations show that recommended test cases\ndecrease the developers' effort to generating expected test cases.\n",
                "链接": "https://arxiv.org/abs/2310.03174"
            },
            {
                "文章ID": "47986",
                "标题": "More Generalized and Personalized Unsupervised Representation Learning\n  In A Distributed System",
                "作者": " Yuewei Yang,  Jingwei Sun,  Ang Li,  Hai Li,  Yiran Chen",
                "发布日期": "2022-11-15",
                "摘要": "  Discriminative unsupervised learning methods such as contrastive learning\nhave demonstrated the ability to learn generalized visual representations on\ncentralized data. It is nonetheless challenging to adapt such methods to a\ndistributed system with unlabeled, private, and heterogeneous client data due\nto user styles and preferences. Federated learning enables multiple clients to\ncollectively learn a global model without provoking any privacy breach between\nlocal clients. On the other hand, another direction of federated learning\nstudies personalized methods to address the local heterogeneity. However, work\non solving both generalization and personalization without labels in a\ndecentralized setting remains unfamiliar. In this work, we propose a novel\nmethod, FedStyle, to learn a more generalized global model by infusing local\nstyle information with local content information for contrastive learning, and\nto learn more personalized local models by inducing local style information for\ndownstream tasks. The style information is extracted by contrasting original\nlocal data with strongly augmented local data (Sobel filtered images). Through\nextensive experiments with linear evaluations in both IID and non-IID settings,\nwe demonstrate that FedStyle outperforms both the generalization baseline\nmethods and personalization baseline methods in a stylized decentralized\nsetting. Through comprehensive ablations, we demonstrate our design of style\ninfusion and stylized personalization improve performance significantly.\n",
                "链接": "https://arxiv.org/abs/2211.06470"
            },
            {
                "文章ID": "16842",
                "标题": "Extremal GloVe: Theoretically Accurate Distributed Word Embedding by\n  Tail Inference",
                "作者": " Hao Wang",
                "发布日期": "2022-04-28",
                "摘要": "  Distributed word embeddings such as Word2Vec and GloVe have been widely\nadopted in industrial context settings. Major technical applications of GloVe\ninclude recommender systems and natural language processing. The fundamental\ntheory behind GloVe relies on the selection of a weighting function in the\nweighted least squres formulation that computes the powered ratio of word\noccurrence count and the maximum word count in the corpus. However, the initial\nformulation of GloVe is not theoretically sound in two aspects, namely the\nselection of the weighting function and its power exponent is ad-hoc. In this\npaper, we utilize the theory of extreme value analysis and propose a\ntheoretically accurate version of GloVe. By reformulating the weighted least\nsquares loss function as the expected loss function and accurately choosing the\npower exponent, we create a theoretically accurate version of GloVe. We\ndemonstrate the competitiveness of our algorithm and show that the initial\nformulation of GloVe with the suggested optimal parameter can be viewed as a\nspecial case of our paradigm.\n",
                "链接": "https://arxiv.org/abs/2204.13009"
            }
        ]
    },
    {
        "question": {
            "question": "查找一下nips 2023 paper list",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "115509",
                "标题": "Overview of the TREC 2023 Product Product Search Track",
                "作者": " Daniel Campos,  Surya Kallumadi,  Corby Rosset,  Cheng Xiang Zhai,  Alessandro Magnani",
                "发布日期": "2023-11-16",
                "摘要": "  This is the first year of the TREC Product search track. The focus this year\nwas the creation of a reusable collection and evaluation of the impact of the\nuse of metadata and multi-modal data on retrieval accuracy. This year we\nleverage the new product search corpus, which includes contextual metadata. Our\nanalysis shows that in the product search domain, traditional retrieval systems\nare highly effective and commonly outperform general-purpose pretrained\nembedding models. Our analysis also evaluates the impact of using simplified\nand metadata-enhanced collections, finding no clear trend in the impact of the\nexpanded collection. We also see some surprising outcomes; despite their\nwidespread adoption and competitive performance on other tasks, we find\nsingle-stage dense retrieval runs can commonly be noncompetitive or generate\nlow-quality results both in the zero-shot and fine-tuned domain.\n",
                "链接": "https://arxiv.org/abs/2311.07861"
            },
            {
                "文章ID": "60862",
                "标题": "Find a witness or shatter: the landscape of computable PAC learning",
                "作者": " Valentino Delle Rose,  Alexander Kozachinskiy,  Cristobal Rojas,  Tomasz Steifer",
                "发布日期": "2023-02-24",
                "摘要": "  This paper contributes to the study of CPAC learnability -- a computable\nversion of PAC learning -- by solving three open questions from recent papers.\nFirstly, we prove that every improperly CPAC learnable class is contained in a\nclass which is properly CPAC learnable with polynomial sample complexity. This\nconfirms a conjecture by Agarwal et al (COLT 2021). Secondly, we show that\nthere exists a decidable class of hypothesis which is properly CPAC learnable,\nbut only with uncomputably fast growing sample complexity. This solves a\nquestion from Sterkenburg (COLT 2022). Finally, we construct a decidable class\nof finite Littlestone dimension which is not improperly CPAC learnable,\nstrengthening a recent result of Sterkenburg (2022) and answering a question\nposed by Hasrati and Ben-David (ALT 2023). Together with previous work, our\nresults provide a complete landscape for the learnability problem in the CPAC\nsetting.\n",
                "链接": "https://arxiv.org/abs/2302.04731"
            },
            {
                "文章ID": "45022",
                "标题": "Using Deep Learning to Find the Next Unicorn: A Practical Synthesis",
                "作者": " Lele Cao,  Vilhelm von Ehrenheim,  Sebastian Krakowski,  Xiaoxue Li,  Alexandra Lutz",
                "发布日期": "2022-10-26",
                "摘要": "  Startups often represent newly established business models associated with\ndisruptive innovation and high scalability. They are commonly regarded as\npowerful engines for economic and social development. Meanwhile, startups are\nheavily constrained by many factors such as limited financial funding and human\nresources. Therefore the chance for a startup to eventually succeed is as rare\nas ``spotting a unicorn in the wild''. Venture Capital (VC) strives to identify\nand invest in unicorn startups during their early stages, hoping to gain a high\nreturn. To avoid entirely relying on human domain expertise and intuition,\ninvestors usually employ data-driven approaches to forecast the success\nprobability of startups. Over the past two decades, the industry has gone\nthrough a paradigm shift moving from conventional statistical approaches\ntowards becoming machine-learning (ML) based. Notably, the rapid growth of data\nvolume and variety is quickly ushering in deep learning (DL), a subset of ML,\nas a potentially superior approach in terms capacity and expressivity. In this\nwork, we carry out a literature review and synthesis on DL-based approaches,\ncovering the entire DL life cycle. The objective is a) to obtain a thorough and\nin-depth understanding of the methodologies for startup evaluation using DL,\nand b) to distil valuable and actionable learning for practitioners. To the\nbest of our knowledge, our work is the first of this kind.\n",
                "链接": "https://arxiv.org/abs/2210.14195"
            },
            {
                "文章ID": "111434",
                "标题": "In the user's eyes we find trust: Using gaze data as a predictor or\n  trust in an artifical intelligence",
                "作者": " Martin Johannes Dechant,  Olga Lukashova-Sanz,  Siegfried Wahl",
                "发布日期": "2023-10-26",
                "摘要": "  Trust is essential for our interactions with others but also with artificial\nintelligence (AI) based systems. To understand whether a user trusts an AI,\nresearchers need reliable measurement tools. However, currently discussed\nmarkers mostly rely on expensive and invasive sensors, like\nelectroencephalograms, which may cause discomfort. The analysis of gaze data\nhas been suggested as a convenient tool for trust assessment. However, the\nrelationship between trust and several aspects of the gaze behaviour is not yet\nfully understood. To provide more insights into this relationship, we propose a\nexploration study in virtual reality where participants have to perform a\nsorting task together with a simulated AI in a simulated robotic arm embedded\nin a gaming. We discuss the potential benefits of this approach and outline our\nstudy design in this submission.\n",
                "链接": "https://arxiv.org/abs/2310.16672"
            },
            {
                "文章ID": "21661",
                "标题": "Learning to Find Proofs and Theorems by Learning to Refine Search\n  Strategies: The Case of Loop Invariant Synthesis",
                "作者": " Jonathan Laurent,  André Platzer",
                "发布日期": "2023-09-12",
                "摘要": "  We propose a new approach to automated theorem proving where an\nAlphaZero-style agent is self-training to refine a generic high-level expert\nstrategy expressed as a nondeterministic program. An analogous teacher agent is\nself-training to generate tasks of suitable relevance and difficulty for the\nlearner. This allows leveraging minimal amounts of domain knowledge to tackle\nproblems for which training data is unavailable or hard to synthesize. As a\nspecific illustration, we consider loop invariant synthesis for imperative\nprograms and use neural networks to refine both the teacher and solver\nstrategies.\n",
                "链接": "https://arxiv.org/abs/2205.14229"
            },
            {
                "文章ID": "121476",
                "标题": "Proceedings of the 2023 XCSP3 Competition",
                "作者": " Gilles Audemard,  Christophe Lecoutre,  Emmanuel Lonca",
                "发布日期": "2023-12-12",
                "摘要": "  This document represents the proceedings of the 2023 XCSP3 Competition. The\nresults of this competition of constraint solvers were presented at CP'23 (the\n29th International Conference on Principles and Practice of Constraint\nProgramming, held in Toronto, Canada from 27th to 31th August, 2023).\n",
                "链接": "https://arxiv.org/abs/2312.05877"
            },
            {
                "文章ID": "39057",
                "标题": "FONDUE: an algorithm to find the optimal dimensionality of the latent\n  representations of variational autoencoders",
                "作者": " Lisa Bonheme,  Marek Grzes",
                "发布日期": "2022-09-27",
                "摘要": "  When training a variational autoencoder (VAE) on a given dataset, determining\nthe optimal number of latent variables is mostly done by grid search: a costly\nprocess in terms of computational time and carbon footprint. In this paper, we\nexplore the intrinsic dimension estimation (IDE) of the data and latent\nrepresentations learned by VAEs. We show that the discrepancies between the IDE\nof the mean and sampled representations of a VAE after only a few steps of\ntraining reveal the presence of passive variables in the latent space, which,\nin well-behaved VAEs, indicates a superfluous number of dimensions. Using this\nproperty, we propose FONDUE: an algorithm which quickly finds the number of\nlatent dimensions after which the mean and sampled representations start to\ndiverge (i.e., when passive variables are introduced), providing a principled\nmethod for selecting the number of latent dimensions for VAEs and autoencoders.\n",
                "链接": "https://arxiv.org/abs/2209.12806"
            },
            {
                "文章ID": "98737",
                "标题": "The DiffuseStyleGesture+ entry to the GENEA Challenge 2023",
                "作者": " Sicheng Yang,  Haiwei Xue,  Zhensong Zhang,  Minglei Li,  Zhiyong Wu,  Xiaofei Wu,  Songcen Xu,  Zonghong Dai",
                "发布日期": "2023-08-29",
                "摘要": "  In this paper, we introduce the DiffuseStyleGesture+, our solution for the\nGeneration and Evaluation of Non-verbal Behavior for Embodied Agents (GENEA)\nChallenge 2023, which aims to foster the development of realistic, automated\nsystems for generating conversational gestures. Participants are provided with\na pre-processed dataset and their systems are evaluated through crowdsourced\nscoring. Our proposed model, DiffuseStyleGesture+, leverages a diffusion model\nto generate gestures automatically. It incorporates a variety of modalities,\nincluding audio, text, speaker ID, and seed gestures. These diverse modalities\nare mapped to a hidden space and processed by a modified diffusion model to\nproduce the corresponding gesture for a given speech input. Upon evaluation,\nthe DiffuseStyleGesture+ demonstrated performance on par with the top-tier\nmodels in the challenge, showing no significant differences with those models\nin human-likeness, appropriateness for the interlocutor, and achieving\ncompetitive performance with the best model on appropriateness for agent\nspeech. This indicates that our model is competitive and effective in\ngenerating realistic and appropriate gestures for given speech. The code,\npre-trained models, and demos are available at\nhttps://github.com/YoungSeng/DiffuseStyleGesture/tree/DiffuseStyleGesturePlus/BEAT-TWH-main.\n",
                "链接": "https://arxiv.org/abs/2308.13879"
            },
            {
                "文章ID": "82537",
                "标题": "Findings of the VarDial Evaluation Campaign 2023",
                "作者": " Noëmi Aepli,  Çağrı Çöltekin,  Rob Van Der Goot,  Tommi Jauhiainen,  Mourhaf Kazzaz,  Nikola Ljubešić,  Kai North,  Barbara Plank,  Yves Scherrer,  Marcos Zampieri",
                "发布日期": "2023-06-01",
                "摘要": "  This report presents the results of the shared tasks organized as part of the\nVarDial Evaluation Campaign 2023. The campaign is part of the tenth workshop on\nNatural Language Processing (NLP) for Similar Languages, Varieties and Dialects\n(VarDial), co-located with EACL 2023. Three separate shared tasks were included\nthis year: Slot and intent detection for low-resource language varieties\n(SID4LR), Discriminating Between Similar Languages -- True Labels (DSL-TL), and\nDiscriminating Between Similar Languages -- Speech (DSL-S). All three tasks\nwere organized for the first time this year.\n",
                "链接": "https://arxiv.org/abs/2305.20080"
            },
            {
                "文章ID": "19420",
                "标题": "CurFi: An automated tool to find the best regression analysis model\n  using curve fitting",
                "作者": " Ayon Roy,  Tausif Al Zubayer,  Nafisa Tabassum,  Muhammad Nazrul Islam,  Md. Abdus Sattar",
                "发布日期": "2022-05-17",
                "摘要": "  Regression analysis is a well known quantitative research method that\nprimarily explores the relationship between one or more independent variables\nand a dependent variable. Conducting regression analysis manually on large\ndatasets with multiple independent variables can be tedious. An automated\nsystem for regression analysis will be of great help for researchers as well as\nnon-expert users. Thus, the objective of this research is to design and develop\nan automated curve fitting system. As outcome, a curve fitting system named\n\"CurFi\" was developed that uses linear regression models to fit a curve to a\ndataset and to find out the best fit model. The system facilitates to upload a\ndataset, split the dataset into training set and test set, select relevant\nfeatures and label from the dataset; and the system will return the best fit\nlinear regression model after training is completed. The developed tool would\nbe a great resource for the users having limited technical knowledge who will\nalso be able to find the best fit regression model for a dataset using the\ndeveloped \"CurFi\" system.\n",
                "链接": "https://arxiv.org/abs/2205.07804"
            }
        ]
    },
    {
        "question": {
            "question": "推荐与AutoGPT相似的10篇文献",
            "type": "1"
        },
        "results": [
            {
                "文章ID": "83448",
                "标题": "Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions",
                "作者": " Hui Yang,  Sifu Yue,  Yunzhong He",
                "发布日期": "2023-06-06",
                "摘要": "  Auto-GPT is an autonomous agent that leverages recent advancements in\nadapting Large Language Models (LLMs) for decision-making tasks. While there\nhas been a growing interest in Auto-GPT stypled agents, questions remain\nregarding the effectiveness and flexibility of Auto-GPT in solving real-world\ndecision-making tasks. Its limited capability for real-world engagement and the\nabsence of benchmarks contribute to these uncertainties. In this paper, we\npresent a comprehensive benchmark study of Auto-GPT styled agents in\ndecision-making tasks that simulate real-world scenarios. Our aim is to gain\ndeeper insights into this problem and understand the adaptability of GPT-based\nagents. We compare the performance of popular LLMs such as GPT-4, GPT-3.5,\nClaude, and Vicuna in Auto-GPT styled decision-making tasks. Furthermore, we\nintroduce the Additional Opinions algorithm, an easy and effective method that\nincorporates supervised/imitation-based learners into the Auto-GPT scheme. This\napproach enables lightweight supervised learning without requiring fine-tuning\nof the foundational LLMs. We demonstrate through careful baseline comparisons\nand ablation studies that the Additional Opinions algorithm significantly\nenhances performance in online decision-making benchmarks, including WebShop\nand ALFWorld.\n",
                "链接": "https://arxiv.org/abs/2306.02224"
            },
            {
                "文章ID": "18882",
                "标题": "AdaVAE: Exploring Adaptive GPT-2s in Variational Auto-Encoders for\n  Language Modeling",
                "作者": " Haoqin Tu,  Zhongliang Yang,  Jinshuai Yang,  Yongfeng Huang",
                "发布日期": "2022-11-22",
                "摘要": "  Variational Auto-Encoder (VAE) has become the de-facto learning paradigm in\nachieving representation learning and generation for natural language at the\nsame time. Nevertheless, existing VAE-based language models either employ\nelementary RNNs, which is not powerful to handle complex works in the\nmulti-task situation, or fine-tunes two pre-trained language models (PLMs) for\nany downstream task, which is a huge drain on resources. In this paper, we\npropose the first VAE framework empowered with adaptive GPT-2s (AdaVAE).\nDifferent from existing systems, we unify both the encoder\\&decoder of the VAE\nmodel using GPT-2s with adaptive parameter-efficient components, and further\nintroduce Latent Attention operation to better construct latent space from\ntransformer models. Experiments from multiple dimensions validate that AdaVAE\nis competent to effectively organize language in three related tasks (language\nmodeling, representation modeling and guided text generation) even with less\nthan $15\\%$ activated parameters in training. Our code is available at\n\\url{https://github.com/ImKeTT/AdaVAE}.\n",
                "链接": "https://arxiv.org/abs/2205.05862"
            },
            {
                "文章ID": "116503",
                "标题": "AI-enhanced Auto-correction of Programming Exercises: How Effective is\n  GPT-3.5?",
                "作者": " Imen Azaiz,  Oliver Deckarm,  Sven Strickroth",
                "发布日期": "2023-12-15",
                "摘要": "  Timely formative feedback is considered as one of the most important drivers\nfor effective learning. Delivering timely and individualized feedback is\nparticularly challenging in large classes in higher education. Recently Large\nLanguage Models such as GPT-3 became available to the public that showed\npromising results on various tasks such as code generation and code\nexplanation. This paper investigates the potential of AI in providing\npersonalized code correction and generating feedback. Based on existing student\nsubmissions of two different real-world assignments, the correctness of the\nAI-aided e-assessment as well as the characteristics such as fault\nlocalization, correctness of hints, and code style suggestions of the generated\nfeedback are investigated. The results show that 73 % of the submissions were\ncorrectly identified as either correct or incorrect. In 59 % of these cases,\nGPT-3.5 also successfully generated effective and high-quality feedback.\nAdditionally, GPT-3.5 exhibited weaknesses in its evaluation, including\nlocalization of errors that were not the actual errors, or even hallucinated\nerrors. Implications and potential new usage scenarios are discussed.\n",
                "链接": "https://arxiv.org/abs/2311.10737"
            },
            {
                "文章ID": "31207",
                "标题": "AutoTransition: Learning to Recommend Video Transition Effects",
                "作者": " Yaojie Shen,  Libo Zhang,  Kai Xu,  Xiaojie Jin",
                "发布日期": "2022-07-28",
                "摘要": "  Video transition effects are widely used in video editing to connect shots\nfor creating cohesive and visually appealing videos. However, it is challenging\nfor non-professionals to choose best transitions due to the lack of\ncinematographic knowledge and design skills. In this paper, we present the\npremier work on performing automatic video transitions recommendation (VTR):\ngiven a sequence of raw video shots and companion audio, recommend video\ntransitions for each pair of neighboring shots. To solve this task, we collect\na large-scale video transition dataset using publicly available video templates\non editing softwares. Then we formulate VTR as a multi-modal retrieval problem\nfrom vision/audio to video transitions and propose a novel multi-modal matching\nframework which consists of two parts. First we learn the embedding of video\ntransitions through a video transition classification task. Then we propose a\nmodel to learn the matching correspondence from vision/audio inputs to video\ntransitions. Specifically, the proposed model employs a multi-modal transformer\nto fuse vision and audio information, as well as capture the context cues in\nsequential transition outputs. Through both quantitative and qualitative\nexperiments, we clearly demonstrate the effectiveness of our method. Notably,\nin the comprehensive user study, our method receives comparable scores compared\nwith professional editors while improving the video editing efficiency by\n\\textbf{300\\scalebox{1.25}{$\\times$}}. We hope our work serves to inspire other\nresearchers to work on this new task. The dataset and codes are public at\n\\url{https://github.com/acherstyx/AutoTransition}.\n",
                "链接": "https://arxiv.org/abs/2207.13479"
            },
            {
                "文章ID": "74528",
                "标题": "Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from\n  Literature with GPT-3",
                "作者": " Nicholas Walker,  John Dagdelen,  Kevin Cruse,  Sanghoon Lee,  Samuel Gleason,  Alexander Dunn,  Gerbrand Ceder,  A. Paul Alivisatos,  Kristin A. Persson,  Anubhav Jain",
                "发布日期": "2023-04-28",
                "摘要": "  Although gold nanorods have been the subject of much research, the pathways\nfor controlling their shape and thereby their optical properties remain largely\nheuristically understood. Although it is apparent that the simultaneous\npresence of and interaction between various reagents during synthesis control\nthese properties, computational and experimental approaches for exploring the\nsynthesis space can be either intractable or too time-consuming in practice.\nThis motivates an alternative approach leveraging the wealth of synthesis\ninformation already embedded in the body of scientific literature by developing\ntools to extract relevant structured data in an automated, high-throughput\nmanner. To that end, we present an approach using the powerful GPT-3 language\nmodel to extract structured multi-step seed-mediated growth procedures and\noutcomes for gold nanorods from unstructured scientific text. GPT-3 prompt\ncompletions are fine-tuned to predict synthesis templates in the form of JSON\ndocuments from unstructured text input with an overall accuracy of $86\\%$. The\nperformance is notable, considering the model is performing simultaneous entity\nrecognition and relation extraction. We present a dataset of 11,644 entities\nextracted from 1,137 papers, resulting in 268 papers with at least one complete\nseed-mediated gold nanorod growth procedure and outcome for a total of 332\ncomplete procedures.\n",
                "链接": "https://arxiv.org/abs/2304.13846"
            },
            {
                "文章ID": "65493",
                "标题": "Form 10-K Itemization",
                "作者": " Yanci Zhang,  Mengjia Xia,  Mingyang Li,  Haitao Mao,  Yutong Lu,  Yupeng Lan,  Jinlin Ye,  Rui Dai",
                "发布日期": "2023-03-09",
                "摘要": "  Form 10-K report is a financial report disclosing the annual financial state\nof a public company. It is an important evidence to conduct financial analysis,\ni.e., asset pricing, corporate finance. Practitioners and researchers are\nconstantly designing algorithms to better conduct analysis on information in\nthe Form 10-K report. The vast majority of previous works focus on quantitative\ndata. With recent advancement on natural language processing (NLP), textual\ndata in financial filing attracts more attention. However, to incorporate\ntextual data for analyzing, Form 10-K Itemization is a necessary pre-process\nstep. It aims to segment the whole document into several Item sections, where\neach Item section focuses on a specific financial aspect of the company. With\nthe segmented Item sections, NLP techniques can directly apply on those Item\nsections related to downstream tasks. In this paper, we develop a Form 10-K\nItemization system which can automatically segment all the Item sections in\n10-K documents. The system is both effective and efficient. It reaches a\nretrieval rate of 93%.\n",
                "链接": "https://arxiv.org/abs/2303.04688"
            },
            {
                "文章ID": "75016",
                "标题": "Leveraging Data Mining Algorithms to Recommend Source Code Changes",
                "作者": " AmirHossein Naghshzan,  Saeed Khalilazar,  Pierre Poilane,  Olga Baysal,  Latifa Guerrouj,  Foutse Khomh",
                "发布日期": "2023-05-02",
                "摘要": "  Context: Recent research has used data mining to develop techniques that can\nguide developers through source code changes. To the best of our knowledge,\nvery few studies have investigated data mining techniques and--or compared\ntheir results with other algorithms or a baseline. Objectives: This paper\nproposes an automatic method for recommending source code changes using four\ndata mining algorithms. We not only use these algorithms to recommend source\ncode changes, but we also conduct an empirical evaluation. Methods: Our\ninvestigation includes seven open-source projects from which we extracted\nsource change history at the file level. We used four widely data mining\nalgorithms \\ie{} Apriori, FP-Growth, Eclat, and Relim to compare the algorithms\nin terms of performance (Precision, Recall and F-measure) and execution time.\nResults: Our findings provide empirical evidence that while some Frequent\nPattern Mining algorithms, such as Apriori may outperform other algorithms in\nsome cases, the results are not consistent throughout all the software\nprojects, which is more likely due to the nature and characteristics of the\nstudied projects, in particular their change history. Conclusion: Apriori seems\nappropriate for large-scale projects, whereas Eclat appears to be suitable for\nsmall-scale projects. Moreover, FP-Growth seems an efficient approach in terms\nof execution time.\n",
                "链接": "https://arxiv.org/abs/2305.00323"
            },
            {
                "文章ID": "116370",
                "标题": "From \"Thumbs Up\" to \"10 out of 10\": Reconsidering Scalar Feedback in\n  Interactive Reinforcement Learning",
                "作者": " Hang Yu,  Reuben M. Aronson,  Katherine H. Allen,  Elaine Schaertl Short",
                "发布日期": "2023-11-20",
                "摘要": "  Learning from human feedback is an effective way to improve robotic learning\nin exploration-heavy tasks. Compared to the wide application of binary human\nfeedback, scalar human feedback has been used less because it is believed to be\nnoisy and unstable. In this paper, we compare scalar and binary feedback, and\ndemonstrate that scalar feedback benefits learning when properly handled. We\ncollected binary or scalar feedback respectively from two groups of\ncrowdworkers on a robot task. We found that when considering how consistently a\nparticipant labeled the same data, scalar feedback led to less consistency than\nbinary feedback; however, the difference vanishes if small mismatches are\nallowed. Additionally, scalar and binary feedback show no significant\ndifferences in their correlations with key Reinforcement Learning targets. We\nthen introduce Stabilizing TEacher Assessment DYnamics (STEADY) to improve\nlearning from scalar feedback. Based on the idea that scalar feedback is\nmuti-distributional, STEADY re-constructs underlying positive and negative\nfeedback distributions and re-scales scalar feedback based on feedback\nstatistics. We show that models trained with \\textit{scalar feedback + STEADY }\noutperform baselines, including binary feedback and raw scalar feedback, in a\nrobot reaching task with non-expert human feedback. Our results show that both\nbinary feedback and scalar feedback are dynamic, and scalar feedback is a\npromising signal for use in interactive Reinforcement Learning.\n",
                "链接": "https://arxiv.org/abs/2311.10284"
            },
            {
                "文章ID": "70011",
                "标题": "JobHam-place with smart recommend job options and candidate filtering\n  options",
                "作者": " Shiyao Wu",
                "发布日期": "2023-04-03",
                "摘要": "  Due to the increasing number of graduates, many applicants experience the\nsituation about finding a job, and employers experience difficulty filtering\njob applicants, which might negatively impact their effectiveness. However,\nmost job-hunting websites lack job recommendation and CV filtering or ranking\nfunctionality, which are not integrated into the system. Thus, a smart job\nhunter combined with the above functionality will be conducted in this project,\nwhich contains job recommendations, CV ranking and even a job dashboard for\nskills and job applicant functionality. Job recommendation and CV ranking\nstarts from the automatic keyword extraction and end with the Job/CV ranking\nalgorithm. Automatic keyword extraction is implemented by Job2Skill and the\nCV2Skill model based on Bert. Job2Skill consists of two components, text\nencoder and Gru-based layers, while CV2Skill is mainly based on Bert and\nfine-tunes the pre-trained model by the Resume- Entity dataset. Besides, to\nmatch skills from CV and job description and rank lists of jobs and candidates,\njob/CV ranking algorithms have been provided to compute the occurrence ratio of\nskill words based on TFIDF score and match ratio of the total skill numbers.\nBesides, some advanced features have been integrated into the website to\nimprove user experiences, such as the calendar and sweetalert2 plugin. And some\nbasic features to go through job application processes, such as job application\ntracking and interview arrangement.\n",
                "链接": "https://arxiv.org/abs/2303.17930"
            },
            {
                "文章ID": "119726",
                "标题": "A Hypergraph-Based Approach to Recommend Online Resources in a Library",
                "作者": " Debashish Roy,  Rajarshi Roy Chowdhury",
                "发布日期": "2023-12-05",
                "摘要": "  When users in a digital library read or browse online resources, it generates\nan immense amount of data. If the underlying system can recommend items, such\nas books and journals, to the users, it will help them to find the related\nitems. This research analyzes a digital library's usage data to recommend items\nto its users, and it uses different clustering algorithms to design the\nrecommender system. We have used content-based clustering, including\nhierarchical, expectation maximization (EM), K-mean, FarthestFirst, and\ndensity-based clustering algorithms, and user access pattern-based clustering,\nwhich uses a hypergraph-based approach to generate the clusters. This research\nshows that the recommender system designed using the hypergraph algorithm\ngenerates the most accurate recommendation model compared to those designed\nusing the content-based clustering approaches.\n",
                "链接": "https://arxiv.org/abs/2312.01007"
            }
        ]
    },
    {
        "question": {
            "question": "请搜索近一年发表的有关多模态大模型与产业相结合、与具体应用场景相结合的论文",
            "type": "2"
        },
        "results": [
            {
                "文章ID": "104627",
                "标题": "Jointly Training Large Autoregressive Multimodal Models",
                "作者": " Emanuele Aiello,  Lili Yu,  Yixin Nie,  Armen Aghajanyan,  Barlas Oguz",
                "发布日期": "2023-09-29",
                "摘要": "  In recent years, advances in the large-scale pretraining of language and\ntext-to-image models have revolutionized the field of machine learning. Yet,\nintegrating these two modalities into a single, robust model capable of\ngenerating seamless multimodal outputs remains a significant challenge. To\naddress this gap, we present the Joint Autoregressive Mixture (JAM) framework,\na modular approach that systematically fuses existing text and image generation\nmodels. We also introduce a specialized, data-efficient instruction-tuning\nstrategy, tailored for mixed-modal generation tasks. Our final instruct-tuned\nmodel demonstrates unparalleled performance in generating high-quality\nmultimodal outputs and represents the first model explicitly designed for this\npurpose.\n",
                "链接": "https://arxiv.org/abs/2309.15564"
            },
            {
                "文章ID": "117408",
                "标题": "Multimodal Large Language Models: A Survey",
                "作者": " Jiayang Wu,  Wensheng Gan,  Zefeng Chen,  Shicheng Wan,  Philip S. Yu",
                "发布日期": "2023-11-23",
                "摘要": "  The exploration of multimodal language models integrates multiple data types,\nsuch as images, text, language, audio, and other heterogeneity. While the\nlatest large language models excel in text-based tasks, they often struggle to\nunderstand and process other data types. Multimodal models address this\nlimitation by combining various modalities, enabling a more comprehensive\nunderstanding of diverse data. This paper begins by defining the concept of\nmultimodal and examining the historical development of multimodal algorithms.\nFurthermore, we introduce a range of multimodal products, focusing on the\nefforts of major technology companies. A practical guide is provided, offering\ninsights into the technical aspects of multimodal models. Moreover, we present\na compilation of the latest algorithms and commonly used datasets, providing\nresearchers with valuable resources for experimentation and evaluation. Lastly,\nwe explore the applications of multimodal models and discuss the challenges\nassociated with their development. By addressing these aspects, this paper aims\nto facilitate a deeper understanding of multimodal models and their potential\nin various domains.\n",
                "链接": "https://arxiv.org/abs/2311.13165"
            },
            {
                "文章ID": "91937",
                "标题": "Challenges and Applications of Large Language Models",
                "作者": " Jean Kaddour,  Joshua Harris,  Maximilian Mozes,  Herbie Bradley,  Roberta Raileanu,  Robert McHardy",
                "发布日期": "2023-07-20",
                "摘要": "  Large Language Models (LLMs) went from non-existent to ubiquitous in the\nmachine learning discourse within a few years. Due to the fast pace of the\nfield, it is difficult to identify the remaining challenges and already\nfruitful application areas. In this paper, we aim to establish a systematic set\nof open problems and application successes so that ML researchers can\ncomprehend the field's current state more quickly and become productive.\n",
                "链接": "https://arxiv.org/abs/2307.10169"
            },
            {
                "文章ID": "87495",
                "标题": "A Survey on Multimodal Large Language Models",
                "作者": " Shukang Yin,  Chaoyou Fu,  Sirui Zhao,  Ke Li,  Xing Sun,  Tong Xu,  Enhong Chen",
                "发布日期": "2023-06-26",
                "摘要": "  Multimodal Large Language Model (MLLM) recently has been a new rising\nresearch hotspot, which uses powerful Large Language Models (LLMs) as a brain\nto perform multimodal tasks. The surprising emergent capabilities of MLLM, such\nas writing stories based on images and OCR-free math reasoning, are rare in\ntraditional methods, suggesting a potential path to artificial general\nintelligence. In this paper, we aim to trace and summarize the recent progress\nof MLLM. First of all, we present the formulation of MLLM and delineate its\nrelated concepts. Then, we discuss the key techniques and applications,\nincluding Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning\n(M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning\n(LAVR). Finally, we discuss existing challenges and point out promising\nresearch directions. In light of the fact that the era of MLLM has only just\nbegun, we will keep updating this survey and hope it can inspire more research.\nAn associated GitHub link collecting the latest papers is available at\nhttps://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.\n",
                "链接": "https://arxiv.org/abs/2306.13549"
            },
            {
                "文章ID": "99625",
                "标题": "Socratis: Are large multimodal models emotionally aware?",
                "作者": " Katherine Deng,  Arijit Ray,  Reuben Tan,  Saadia Gabriel,  Bryan A. Plummer,  Kate Saenko",
                "发布日期": "2023-11-03",
                "摘要": "  Existing emotion prediction benchmarks contain coarse emotion labels which do\nnot consider the diversity of emotions that an image and text can elicit in\nhumans due to various reasons. Learning diverse reactions to multimodal content\nis important as intelligent machines take a central role in generating and\ndelivering content to society. To address this gap, we propose Socratis, a\nsocietal reactions benchmark, where each image-caption (IC) pair is annotated\nwith multiple emotions and the reasons for feeling them. Socratis contains 18K\nfree-form reactions for 980 emotions on 2075 image-caption pairs from 5\nwidely-read news and image-caption (IC) datasets. We benchmark the capability\nof state-of-the-art multimodal large language models to generate the reasons\nfor feeling an emotion given an IC pair. Based on a preliminary human study, we\nobserve that humans prefer human-written reasons over 2 times more often than\nmachine-generated ones. This shows our task is harder than standard generation\ntasks because it starkly contrasts recent findings where humans cannot tell\napart machine vs human-written news articles, for instance. We further see that\ncurrent captioning metrics based on large vision-language models also fail to\ncorrelate with human preferences. We hope that these findings and our benchmark\nwill inspire further research on training emotionally aware models.\n",
                "链接": "https://arxiv.org/abs/2308.16741"
            },
            {
                "文章ID": "108418",
                "标题": "Can We Edit Multimodal Large Language Models?",
                "作者": " Siyuan Cheng,  Bozhong Tian,  Qingbin Liu,  Xi Chen,  Yongheng Wang,  Huajun Chen,  Ningyu Zhang",
                "发布日期": "2023-12-29",
                "摘要": "  In this paper, we focus on editing Multimodal Large Language Models (MLLMs).\nCompared to editing single-modal LLMs, multimodal model editing is more\nchallenging, which demands a higher level of scrutiny and careful consideration\nin the editing process. To facilitate research in this area, we construct a new\nbenchmark, dubbed MMEdit, for editing multimodal LLMs and establishing a suite\nof innovative metrics for evaluation. We conduct comprehensive experiments\ninvolving various model editing baselines and analyze the impact of editing\ndifferent components for multimodal LLMs. Empirically, we notice that previous\nbaselines can implement editing multimodal LLMs to some extent, but the effect\nis still barely satisfactory, indicating the potential difficulty of this task.\nWe hope that our work can provide the NLP community with insights. Code and\ndataset are available in https://github.com/zjunlp/EasyEdit.\n",
                "链接": "https://arxiv.org/abs/2310.08475"
            },
            {
                "文章ID": "118448",
                "标题": "Continual Instruction Tuning for Large Multimodal Models",
                "作者": " Jinghan He,  Haiyun Guo,  Ming Tang,  Jinqiao Wang",
                "发布日期": "2023-11-29",
                "摘要": "  Instruction tuning is now a widely adopted approach to aligning large\nmultimodal models (LMMs) to follow human intent. It unifies the data format of\nvision-language tasks, enabling multi-task joint training. However,\nvision-language tasks are constantly being created in practice. Instead of\nalways re-training LMMs when new tasks arrive, continual learning offers\nflexibility for models to continually and efficiently exploit the evolving\ndata. This work aims to explore the following two questions: 1) Do LMMs still\nsuffer from catastrophic forgetting in continual instruction tuning? 2) Are the\nexisting three classes of continual learning methods still applicable to the\ncontinual instruction tuning of LMMs? An extensive study is conducted to\naddress the above questions. First, we establish the first benchmark in this\nsetting and reveal that catastrophic forgetting is still observed when\ncontinually instruction-tuning LMMs. However, the multi-task joint instruction\ntuning can facilitate the model's continual learning ability and mitigate\nforgetting. Second, we integrate and adapt classic continual learning methods\nto our context, demonstrating the efficacy of data replay and model expansion\nstrategies across diverse scenarios. In contrast, regularization-based methods\nonly perform well on models that have been jointly instruction-tuned on\nmultiple tasks. Third, we delve into the correlation and forgetting dynamics\nbetween vision-language task pairs and propose task-similarity-informed\nregularization and model expansion methods for continual instruction tuning of\nLMMs. Experimental results show that our approach consistently boosts the\nmodel's performance.\n",
                "链接": "https://arxiv.org/abs/2311.16206"
            },
            {
                "文章ID": "116733",
                "标题": "Rethinking Large Language Models in Mental Health Applications",
                "作者": " Shaoxiong Ji,  Tianlin Zhang,  Kailai Yang,  Sophia Ananiadou,  Erik Cambria",
                "发布日期": "2023-12-19",
                "摘要": "  Large Language Models (LLMs) have become valuable assets in mental health,\nshowing promise in both classification tasks and counseling applications. This\npaper offers a perspective on using LLMs in mental health applications. It\ndiscusses the instability of generative models for prediction and the potential\nfor generating hallucinatory outputs, underscoring the need for ongoing audits\nand evaluations to maintain their reliability and dependability. The paper also\ndistinguishes between the often interchangeable terms ``explainability'' and\n``interpretability'', advocating for developing inherently interpretable\nmethods instead of relying on potentially hallucinated self-explanations\ngenerated by LLMs. Despite the advancements in LLMs, human counselors'\nempathetic understanding, nuanced interpretation, and contextual awareness\nremain irreplaceable in the sensitive and complex realm of mental health\ncounseling. The use of LLMs should be approached with a judicious and\nconsiderate mindset, viewing them as tools that complement human expertise\nrather than seeking to replace it.\n",
                "链接": "https://arxiv.org/abs/2311.11267"
            },
            {
                "文章ID": "84334",
                "标题": "Multimodal Learning Without Labeled Multimodal Data: Guarantees and\n  Applications",
                "作者": " Paul Pu Liang,  Chun Kai Ling,  Yun Cheng,  Alex Obolenskiy,  Yudong Liu,  Rohan Pandey,  Alex Wilf,  Louis-Philippe Morency,  Ruslan Salakhutdinov",
                "发布日期": "2023-06-08",
                "摘要": "  In many machine learning systems that jointly learn from multiple modalities,\na core research question is to understand the nature of multimodal\ninteractions: the emergence of new task-relevant information during learning\nfrom both modalities that was not present in either alone. We study this\nchallenge of interaction quantification in a semi-supervised setting with only\nlabeled unimodal data and naturally co-occurring multimodal data (e.g.,\nunlabeled images and captions, video and corresponding audio) but when labeling\nthem is time-consuming. Using a precise information-theoretic definition of\ninteractions, our key contributions are the derivations of lower and upper\nbounds to quantify the amount of multimodal interactions in this\nsemi-supervised setting. We propose two lower bounds based on the amount of\nshared information between modalities and the disagreement between separately\ntrained unimodal classifiers, and derive an upper bound through connections to\napproximate algorithms for min-entropy couplings. We validate these estimated\nbounds and show how they accurately track true interactions. Finally, two\nsemi-supervised multimodal applications are explored based on these theoretical\nresults: (1) analyzing the relationship between multimodal performance and\nestimated interactions, and (2) self-supervised learning that embraces\ndisagreement between modalities beyond agreement as is typically done.\n",
                "链接": "https://arxiv.org/abs/2306.04539"
            },
            {
                "文章ID": "81732",
                "标题": "Contextual Object Detection with Multimodal Large Language Models",
                "作者": " Yuhang Zang,  Wei Li,  Jun Han,  Kaiyang Zhou,  Chen Change Loy",
                "发布日期": "2023-05-30",
                "摘要": "  Recent Multimodal Large Language Models (MLLMs) are remarkable in\nvision-language tasks, such as image captioning and question answering, but\nlack the essential perception ability, i.e., object detection. In this work, we\naddress this limitation by introducing a novel research problem of contextual\nobject detection -- understanding visible objects within different human-AI\ninteractive contexts. Three representative scenarios are investigated,\nincluding the language cloze test, visual captioning, and question answering.\nMoreover, we present ContextDET, a unified multimodal model that is capable of\nend-to-end differentiable modeling of visual-language contexts, so as to\nlocate, identify, and associate visual objects with language inputs for\nhuman-AI interaction. Our ContextDET involves three key submodels: (i) a visual\nencoder for extracting visual representations, (ii) a pre-trained LLM for\nmultimodal context decoding, and (iii) a visual decoder for predicting bounding\nboxes given contextual object words. The new generate-then-detect framework\nenables us to detect object words within human vocabulary. Extensive\nexperiments show the advantages of ContextDET on our proposed CODE benchmark,\nopen-vocabulary detection, and referring image segmentation. Github:\nhttps://github.com/yuhangzang/ContextDET.\n",
                "链接": "https://arxiv.org/abs/2305.18279"
            }
        ]
    },
    {
        "question": {
            "question": "查找关于深度学习在医学影像分析中的最新研究，特别关注使用自动标注和迁移学习方法的论文，时间跨度覆盖2019年至今。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "69437",
                "标题": "Medical Image Analysis using Deep Relational Learning",
                "作者": " Zhihua Liu",
                "发布日期": "2023-03-29",
                "摘要": "  In the past ten years, with the help of deep learning, especially the rapid\ndevelopment of deep neural networks, medical image analysis has made remarkable\nprogress. However, how to effectively use the relational information between\nvarious tissues or organs in medical images is still a very challenging\nproblem, and it has not been fully studied. In this thesis, we propose two\nnovel solutions to this problem based on deep relational learning. First, we\npropose a context-aware fully convolutional network that effectively models\nimplicit relation information between features to perform medical image\nsegmentation. The network achieves the state-of-the-art segmentation results on\nthe Multi Modal Brain Tumor Segmentation 2017 (BraTS2017) and Multi Modal Brain\nTumor Segmentation 2018 (BraTS2018) data sets. Subsequently, we propose a new\nhierarchical homography estimation network to achieve accurate medical image\nmosaicing by learning the explicit spatial relationship between adjacent\nframes. We use the UCL Fetoscopy Placenta dataset to conduct experiments and\nour hierarchical homography estimation network outperforms the other\nstate-of-the-art mosaicing methods while generating robust and meaningful\nmosaicing result on unseen frames.\n",
                "链接": "https://arxiv.org/abs/2303.16099"
            },
            {
                "文章ID": "68134",
                "标题": "Label-Efficient Deep Learning in Medical Image Analysis: Challenges and\n  Future Directions",
                "作者": " Cheng Jin,  Zhengrui Guo,  Yi Lin,  Luyang Luo,  Hao Chen",
                "发布日期": "2023-12-21",
                "摘要": "  Deep learning has seen rapid growth in recent years and achieved\nstate-of-the-art performance in a wide range of applications. However, training\nmodels typically requires expensive and time-consuming collection of large\nquantities of labeled data. This is particularly true within the scope of\nmedical imaging analysis (MIA), where data are limited and labels are expensive\nto be acquired. Thus, label-efficient deep learning methods are developed to\nmake comprehensive use of the labeled data as well as the abundance of\nunlabeled and weak-labeled data. In this survey, we extensively investigated\nover 300 recent papers to provide a comprehensive overview of recent progress\non label-efficient learning strategies in MIA. We first present the background\nof label-efficient learning and categorize the approaches into different\nschemes. Next, we examine the current state-of-the-art methods in detail\nthrough each scheme. Specifically, we provide an in-depth investigation,\ncovering not only canonical semi-supervised, self-supervised, and\nmulti-instance learning schemes, but also recently emerged active and\nannotation-efficient learning strategies. Moreover, as a comprehensive\ncontribution to the field, this survey not only elucidates the commonalities\nand unique features of the surveyed methods but also presents a detailed\nanalysis of the current challenges in the field and suggests potential avenues\nfor future research.\n",
                "链接": "https://arxiv.org/abs/2303.12484"
            },
            {
                "文章ID": "93650",
                "标题": "Cross-dimensional transfer learning in medical image segmentation with\n  deep learning",
                "作者": " Hicham Messaoudi,  Ahror Belaid,  Douraied Ben Salem,  Pierre-Henri Conze",
                "发布日期": "2023-08-01",
                "摘要": "  Over the last decade, convolutional neural networks have emerged and advanced\nthe state-of-the-art in various image analysis and computer vision\napplications. The performance of 2D image classification networks is constantly\nimproving and being trained on databases made of millions of natural images.\nHowever, progress in medical image analysis has been hindered by limited\nannotated data and acquisition constraints. These limitations are even more\npronounced given the volumetry of medical imaging data. In this paper, we\nintroduce an efficient way to transfer the efficiency of a 2D classification\nnetwork trained on natural images to 2D, 3D uni- and multi-modal medical image\nsegmentation applications. In this direction, we designed novel architectures\nbased on two key principles: weight transfer by embedding a 2D pre-trained\nencoder into a higher dimensional U-Net, and dimensional transfer by expanding\na 2D segmentation network into a higher dimension one. The proposed networks\nwere tested on benchmarks comprising different modalities: MR, CT, and\nultrasound images. Our 2D network ranked first on the CAMUS challenge dedicated\nto echo-cardiographic data segmentation and surpassed the state-of-the-art.\nRegarding 2D/3D MR and CT abdominal images from the CHAOS challenge, our\napproach largely outperformed the other 2D-based methods described in the\nchallenge paper on Dice, RAVD, ASSD, and MSSD scores and ranked third on the\nonline evaluation platform. Our 3D network applied to the BraTS 2022\ncompetition also achieved promising results, reaching an average Dice score of\n91.69% (91.22%) for the whole tumor, 83.23% (84.77%) for the tumor core, and\n81.75% (83.88%) for enhanced tumor using the approach based on weight\n(dimensional) transfer. Experimental and qualitative results illustrate the\neffectiveness of our methods for multi-dimensional medical image segmentation.\n",
                "链接": "https://arxiv.org/abs/2307.15872"
            },
            {
                "文章ID": "30281",
                "标题": "Auto Machine Learning for Medical Image Analysis by Unifying the Search\n  on Data Augmentation and Neural Architecture",
                "作者": " Jianwei Zhang,  Dong Li,  Lituan Wang,  Lei Zhang",
                "发布日期": "2022-07-22",
                "摘要": "  Automated data augmentation, which aims at engineering augmentation policy\nautomatically, recently draw a growing research interest. Many previous\nauto-augmentation methods utilized a Density Matching strategy by evaluating\npolicies in terms of the test-time augmentation performance. In this paper, we\ntheoretically and empirically demonstrated the inconsistency between the train\nand validation set of small-scale medical image datasets, referred to as\nin-domain sampling bias. Next, we demonstrated that the in-domain sampling bias\nmight cause the inefficiency of Density Matching. To address the problem, an\nimproved augmentation search strategy, named Augmented Density Matching, was\nproposed by randomly sampling policies from a prior distribution for training.\nMoreover, an efficient automatical machine learning(AutoML) algorithm was\nproposed by unifying the search on data augmentation and neural architecture.\nExperimental results indicated that the proposed methods outperformed\nstate-of-the-art approaches on MedMNIST, a pioneering benchmark designed for\nAutoML in medical image analysis.\n",
                "链接": "https://arxiv.org/abs/2207.10351"
            },
            {
                "文章ID": "33280",
                "标题": "Recent Progress in Transformer-based Medical Image Analysis",
                "作者": " Zhaoshan Liu,  Qiujie Lv,  Ziduo Yang,  Yifan Li,  Chau Hung Lee,  Lei Shen",
                "发布日期": "2023-07-26",
                "摘要": "  The transformer is primarily used in the field of natural language\nprocessing. Recently, it has been adopted and shows promise in the computer\nvision (CV) field. Medical image analysis (MIA), as a critical branch of CV,\nalso greatly benefits from this state-of-the-art technique. In this review, we\nfirst recap the core component of the transformer, the attention mechanism, and\nthe detailed structures of the transformer. After that, we depict the recent\nprogress of the transformer in the field of MIA. We organize the applications\nin a sequence of different tasks, including classification, segmentation,\ncaptioning, registration, detection, enhancement, localization, and synthesis.\nThe mainstream classification and segmentation tasks are further divided into\neleven medical image modalities. A large number of experiments studied in this\nreview illustrate that the transformer-based method outperforms existing\nmethods through comparisons with multiple evaluation metrics. Finally, we\ndiscuss the open challenges and future opportunities in this field. This\ntask-modality review with the latest contents, detailed information, and\ncomprehensive comparison may greatly benefit the broad MIA community.\n",
                "链接": "https://arxiv.org/abs/2208.06643"
            },
            {
                "文章ID": "80236",
                "标题": "Deep Learning-based Bio-Medical Image Segmentation using UNet\n  Architecture and Transfer Learning",
                "作者": " Nima Hassanpour,  Abouzar Ghavami",
                "发布日期": "2023-05-25",
                "摘要": "  Image segmentation is a branch of computer vision that is widely used in real\nworld applications including biomedical image processing. With recent\nadvancement of deep learning, image segmentation has achieved at a very high\nlevel performance. Recently, UNet architecture is found as the core of novel\ndeep learning segmentation methods. In this paper we implement UNet\narchitecture from scratch with using basic blocks in Pytorch and evaluate its\nperformance on multiple biomedical image datasets. We also use transfer\nlearning to apply novel modified UNet segmentation packages on the biomedical\nimage datasets. We fine tune the pre-trained transferred model with each\nspecific dataset. We compare its performance with our fundamental UNet\nimplementation. We show that transferred learning model has better performance\nin image segmentation than UNet model that is implemented from scratch.\n",
                "链接": "https://arxiv.org/abs/2305.14841"
            },
            {
                "文章ID": "52332",
                "标题": "A Trustworthy Framework for Medical Image Analysis with Deep Learning",
                "作者": " Kai Ma,  Siyuan He,  Pengcheng Xi,  Ashkan Ebadi,  Stéphane Tremblay,  Alexander Wong",
                "发布日期": "2022-12-07",
                "摘要": "  Computer vision and machine learning are playing an increasingly important\nrole in computer-assisted diagnosis; however, the application of deep learning\nto medical imaging has challenges in data availability and data imbalance, and\nit is especially important that models for medical imaging are built to be\ntrustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning\nframework for medical image analysis, which adopts a modular design, leverages\nself-supervised pre-training, and utilizes a novel surrogate loss function.\nExperimental evaluations indicate that models generated from the framework are\nboth trustworthy and high-performing. It is anticipated that the framework will\nsupport researchers and clinicians in advancing the use of deep learning for\ndealing with public health crises including COVID-19.\n",
                "链接": "https://arxiv.org/abs/2212.02764"
            },
            {
                "文章ID": "107726",
                "标题": "Data efficient deep learning for medical image analysis: A survey",
                "作者": " Suruchi Kumari,  Pravendra Singh",
                "发布日期": "2023-10-11",
                "摘要": "  The rapid evolution of deep learning has significantly advanced the field of\nmedical image analysis. However, despite these achievements, the further\nenhancement of deep learning models for medical image analysis faces a\nsignificant challenge due to the scarcity of large, well-annotated datasets. To\naddress this issue, recent years have witnessed a growing emphasis on the\ndevelopment of data-efficient deep learning methods. This paper conducts a\nthorough review of data-efficient deep learning methods for medical image\nanalysis. To this end, we categorize these methods based on the level of\nsupervision they rely on, encompassing categories such as no supervision,\ninexact supervision, incomplete supervision, inaccurate supervision, and only\nlimited supervision. We further divide these categories into finer\nsubcategories. For example, we categorize inexact supervision into multiple\ninstance learning and learning with weak annotations. Similarly, we categorize\nincomplete supervision into semi-supervised learning, active learning, and\ndomain-adaptive learning and so on. Furthermore, we systematically summarize\ncommonly used datasets for data efficient deep learning in medical image\nanalysis and investigate future research directions to conclude this survey.\n",
                "链接": "https://arxiv.org/abs/2310.06557"
            },
            {
                "文章ID": "2402",
                "标题": "A Review of Deep Transfer Learning and Recent Advancements",
                "作者": " Mohammadreza Iman,  Khaled Rasheed,  Hamid R. Arabnia",
                "发布日期": "2023-03-15",
                "摘要": "  Deep learning has been the answer to many machine learning problems during\nthe past two decades. However, it comes with two major constraints: dependency\non extensive labeled data and training costs. Transfer learning in deep\nlearning, known as Deep Transfer Learning (DTL), attempts to reduce such\ndependency and costs by reusing an obtained knowledge from a source data/task\nin training on a target data/task. Most applied DTL techniques are\nnetwork/model-based approaches. These methods reduce the dependency of deep\nlearning models on extensive training data and drastically decrease training\ncosts. As a result, researchers detected Covid-19 infection on chest X-Rays\nwith high accuracy at the beginning of the pandemic with minimal data using DTL\ntechniques. Also, the training cost reduction makes DTL viable on edge devices\nwith limited resources. Like any new advancement, DTL methods have their own\nlimitations, and a successful transfer depends on some adjustments for\ndifferent scenarios. In this paper, we review the definition and taxonomy of\ndeep transfer learning and well-known methods. Then we investigate the DTL\napproaches by reviewing recent applied DTL techniques in the past five years.\nFurther, we review some experimental analyses of DTLs to learn the best\npractice for applying DTL in different scenarios. Moreover, the limitations of\nDTLs (catastrophic forgetting dilemma and overly biased pre-trained models) are\ndiscussed, along with possible solutions and research trends.\n",
                "链接": "https://arxiv.org/abs/2201.09679"
            },
            {
                "文章ID": "11766",
                "标题": "Intelligent Masking: Deep Q-Learning for Context Encoding in Medical\n  Image Analysis",
                "作者": " Mojtaba Bahrami,  Mahsa Ghorbani,  Nassir Navab",
                "发布日期": "2022-04-06",
                "摘要": "  The need for a large amount of labeled data in the supervised setting has led\nrecent studies to utilize self-supervised learning to pre-train deep neural\nnetworks using unlabeled data. Many self-supervised training strategies have\nbeen investigated especially for medical datasets to leverage the information\navailable in the much fewer unlabeled data. One of the fundamental strategies\nin image-based self-supervision is context prediction. In this approach, a\nmodel is trained to reconstruct the contents of an arbitrary missing region of\nan image based on its surroundings. However, the existing methods adopt a\nrandom and blind masking approach by focusing uniformly on all regions of the\nimages. This approach results in a lot of unnecessary network updates that\ncause the model to forget the rich extracted features. In this work, we develop\na novel self-supervised approach that occludes targeted regions to improve the\npre-training procedure. To this end, we propose a reinforcement learning-based\nagent which learns to intelligently mask input images through deep Q-learning.\nWe show that training the agent against the prediction model can significantly\nimprove the semantic features extracted for downstream classification tasks. We\nperform our experiments on two public datasets for diagnosing breast cancer in\nthe ultrasound images and detecting lower-grade glioma with MR images. In our\nexperiments, we show that our novel masking strategy advances the learned\nfeatures according to the performance on the classification task in terms of\naccuracy, macro F1, and AUROC.\n",
                "链接": "https://arxiv.org/abs/2203.13865"
            }
        ]
    },
    {
        "question": {
            "question": "请找出最近一年内发表的关于自然语言处理领域中，使用Transformer模型并在大规模数据集上进行预训练的论文。特别关注模型结构和性能指标。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "55981",
                "标题": "Language Models are Drummers: Drum Composition with Natural Language\n  Pre-Training",
                "作者": " Li Zhang,  Chris Callison-Burch",
                "发布日期": "2023-01-04",
                "摘要": "  Automatic music generation with artificial intelligence typically requires a\nlarge amount of data which is hard to obtain for many less common genres and\nmusical instruments. To tackle this issue, we present ongoing work and\npreliminary findings on the possibility for deep models to transfer knowledge\nfrom language to music, by finetuning large language models pre-trained on a\nmassive text corpus on only hundreds of MIDI files of drum performances. We\nshow that by doing so, one of the largest, state-of-the-art models (GPT3) is\ncapable of generating reasonable drum grooves, while models that are not\npre-trained (Transformer) shows no such ability beyond naive repetition.\nEvaluating generated music is a challenging task, more so is evaluating drum\ngrooves with little precedence in literature. Hence, we propose a tailored\nstructural evaluation method and analyze drum grooves produced by GPT3 compared\nto those played by human professionals, exposing the strengths and weaknesses\nof such generation by language-to-music transfer. Our findings suggest that\nlanguage-to-music transfer learning with large language models is viable and\npromising.\n",
                "链接": "https://arxiv.org/abs/2301.01162"
            },
            {
                "文章ID": "63721",
                "标题": "Adapting Pre-trained Language Models for Quantum Natural Language\n  Processing",
                "作者": " Qiuchi Li,  Benyou Wang,  Yudong Zhu,  Christina Lioma,  Qun Liu",
                "发布日期": "2023-02-28",
                "摘要": "  The emerging classical-quantum transfer learning paradigm has brought a\ndecent performance to quantum computational models in many tasks, such as\ncomputer vision, by enabling a combination of quantum models and classical\npre-trained neural networks. However, using quantum computing with pre-trained\nmodels has yet to be explored in natural language processing (NLP). Due to the\nhigh linearity constraints of the underlying quantum computing infrastructures,\nexisting Quantum NLP models are limited in performance on real tasks. We fill\nthis gap by pre-training a sentence state with complex-valued BERT-like\narchitecture, and adapting it to the classical-quantum transfer learning scheme\nfor sentence classification. On quantum simulation experiments, the pre-trained\nrepresentation can bring 50\\% to 60\\% increases to the capacity of end-to-end\nquantum models.\n",
                "链接": "https://arxiv.org/abs/2302.13812"
            },
            {
                "文章ID": "85409",
                "标题": "EriBERTa: A Bilingual Pre-Trained Language Model for Clinical Natural\n  Language Processing",
                "作者": " Iker de la Iglesia,  Aitziber Atutxa,  Koldo Gojenola,  Ander Barrena",
                "发布日期": "2023-06-14",
                "摘要": "  The utilization of clinical reports for various secondary purposes, including\nhealth research and treatment monitoring, is crucial for enhancing patient\ncare. Natural Language Processing (NLP) tools have emerged as valuable assets\nfor extracting and processing relevant information from these reports. However,\nthe availability of specialized language models for the clinical domain in\nSpanish has been limited.\n  In this paper, we introduce EriBERTa, a bilingual domain-specific language\nmodel pre-trained on extensive medical and clinical corpora. We demonstrate\nthat EriBERTa outperforms previous Spanish language models in the clinical\ndomain, showcasing its superior capabilities in understanding medical texts and\nextracting meaningful information. Moreover, EriBERTa exhibits promising\ntransfer learning abilities, allowing for knowledge transfer from one language\nto another. This aspect is particularly beneficial given the scarcity of\nSpanish clinical data.\n",
                "链接": "https://arxiv.org/abs/2306.07373"
            },
            {
                "文章ID": "61996",
                "标题": "Foundation Models for Natural Language Processing -- Pre-trained\n  Language Models Integrating Media",
                "作者": " Gerhard Paaß,  Sven Giesselbach",
                "发布日期": "2023-02-20",
                "摘要": "  This open access book provides a comprehensive overview of the state of the\nart in research and applications of Foundation Models and is intended for\nreaders familiar with basic Natural Language Processing (NLP) concepts. Over\nthe recent years, a revolutionary new paradigm has been developed for training\nmodels for NLP. These models are first pre-trained on large collections of text\ndocuments to acquire general syntactic knowledge and semantic information.\nThen, they are fine-tuned for specific tasks, which they can often solve with\nsuperhuman accuracy. When the models are large enough, they can be instructed\nby prompts to solve new tasks without any fine-tuning. Moreover, they can be\napplied to a wide range of different media and problem domains, ranging from\nimage and video processing to robot control learning. Because they provide a\nblueprint for solving many tasks in artificial intelligence, they have been\ncalled Foundation Models. After a brief introduction to basic NLP models the\nmain pre-trained language models BERT, GPT and sequence-to-sequence transformer\nare described, as well as the concepts of self-attention and context-sensitive\nembedding. Then, different approaches to improving these models are discussed,\nsuch as expanding the pre-training criteria, increasing the length of input\ntexts, or including extra knowledge. An overview of the best-performing models\nfor about twenty application areas is then presented, e.g., question answering,\ntranslation, story generation, dialog systems, generating images from text,\netc. For each application area, the strengths and weaknesses of current models\nare discussed, and an outlook on further developments is given. In addition,\nlinks are provided to freely available program code. A concluding chapter\nsummarizes the economic opportunities, mitigation of risks, and potential\ndevelopments of AI.\n",
                "链接": "https://arxiv.org/abs/2302.08575"
            },
            {
                "文章ID": "93322",
                "标题": "Improving Natural Language Inference in Arabic using Transformer Models\n  and Linguistically Informed Pre-Training",
                "作者": " Mohammad Majd Saad Al Deen,  Maren Pielka,  Jörn Hees,  Bouthaina Soulef Abdou,  Rafet Sifa",
                "发布日期": "2023-07-28",
                "摘要": "  This paper addresses the classification of Arabic text data in the field of\nNatural Language Processing (NLP), with a particular focus on Natural Language\nInference (NLI) and Contradiction Detection (CD). Arabic is considered a\nresource-poor language, meaning that there are few data sets available, which\nleads to limited availability of NLP methods. To overcome this limitation, we\ncreate a dedicated data set from publicly available resources. Subsequently,\ntransformer-based machine learning models are being trained and evaluated. We\nfind that a language-specific model (AraBERT) performs competitively with\nstate-of-the-art multilingual approaches, when we apply linguistically informed\npre-training methods such as Named Entity Recognition (NER). To our knowledge,\nthis is the first large-scale evaluation for this task in Arabic, as well as\nthe first application of multi-task pre-training in this context.\n",
                "链接": "https://arxiv.org/abs/2307.14666"
            },
            {
                "文章ID": "109322",
                "标题": "Enhanced Transformer Architecture for Natural Language Processing",
                "作者": " Woohyeon Moon,  Taeyoung Kim,  Bumgeun Park,  Dongsoo Har",
                "发布日期": "2023-10-18",
                "摘要": "  Transformer is a state-of-the-art model in the field of natural language\nprocessing (NLP). Current NLP models primarily increase the number of\ntransformers to improve processing performance. However, this technique\nrequires a lot of training resources such as computing capacity. In this paper,\na novel structure of Transformer is proposed. It is featured by full layer\nnormalization, weighted residual connection, positional encoding exploiting\nreinforcement learning, and zero masked self-attention. The proposed\nTransformer model, which is called Enhanced Transformer, is validated by the\nbilingual evaluation understudy (BLEU) score obtained with the Multi30k\ntranslation dataset. As a result, the Enhanced Transformer achieves 202.96%\nhigher BLEU score as compared to the original transformer with the translation\ndataset.\n",
                "链接": "https://arxiv.org/abs/2310.10930"
            },
            {
                "文章ID": "112711",
                "标题": "Partial Tensorized Transformers for Natural Language Processing",
                "作者": " Subhadra Vadlamannati,  Ryan Solgi",
                "发布日期": "2023-11-01",
                "摘要": "  The transformer architecture has revolutionized Natural Language Processing\n(NLP) and other machine-learning tasks, due to its unprecedented accuracy.\nHowever, their extensive memory and parameter requirements often hinder their\npractical applications. In this work, we study the effect of tensor-train\ndecomposition to improve the accuracy and compress transformer vision-language\nneural networks, namely BERT and ViT. We focus both on embedding-layer\ncompression and partial tensorization of neural networks (PTNN) through an\nalgorithmic approach. Our novel PTNN approach significantly improves the\naccuracy of existing models by up to 5%, all without the need for post-training\nadjustments, breaking new ground in the field of tensor decomposition.\n",
                "链接": "https://arxiv.org/abs/2310.20077"
            },
            {
                "文章ID": "95268",
                "标题": "Continual Pre-Training of Large Language Models: How to (re)warm your\n  model?",
                "作者": " Kshitij Gupta,  Benjamin Thérien,  Adam Ibrahim,  Mats L. Richter,  Quentin Anthony,  Eugene Belilovsky,  Irina Rish,  Timothée Lesort",
                "发布日期": "2023-09-08",
                "摘要": "  Large language models (LLMs) are routinely pre-trained on billions of tokens,\nonly to restart the process over again once new data becomes available. A much\ncheaper and more efficient solution would be to enable the continual\npre-training of these models, i.e. updating pre-trained models with new data\ninstead of re-training them from scratch. However, the distribution shift\ninduced by novel data typically results in degraded performance on past data.\nTaking a step towards efficient continual pre-training, in this work, we\nexamine the effect of different warm-up strategies. Our hypothesis is that the\nlearning rate must be re-increased to improve compute efficiency when training\non a new dataset. We study the warmup phase of models pre-trained on the Pile\n(upstream data, 300B tokens) as we continue to pre-train on SlimPajama\n(downstream data, 297B tokens), following a linear warmup and cosine decay\nschedule. We conduct all experiments on the Pythia 410M language model\narchitecture and evaluate performance through validation perplexity. We\nexperiment with different pre-training checkpoints, various maximum learning\nrates, and various warmup lengths. Our results show that while rewarming models\nfirst increases the loss on upstream and downstream data, in the longer run it\nimproves the downstream performance, outperforming models trained from\nscratch$\\unicode{x2013}$even for a large downstream dataset.\n",
                "链接": "https://arxiv.org/abs/2308.04014"
            },
            {
                "文章ID": "60859",
                "标题": "Lightweight Transformers for Clinical Natural Language Processing",
                "作者": " Omid Rohanian,  Mohammadmahdi Nouriborji,  Hannah Jauncey,  Samaneh Kouchaki,  ISARIC Clinical Characterisation Group,  Lei Clifton,  Laura Merson,  David A. Clifton",
                "发布日期": "2023-02-10",
                "摘要": "  Specialised pre-trained language models are becoming more frequent in NLP\nsince they can potentially outperform models trained on generic texts. BioBERT\nand BioClinicalBERT are two examples of such models that have shown promise in\nmedical NLP tasks. Many of these models are overparametrised and\nresource-intensive, but thanks to techniques like Knowledge Distillation (KD),\nit is possible to create smaller versions that perform almost as well as their\nlarger counterparts. In this work, we specifically focus on development of\ncompact language models for processing clinical texts (i.e. progress notes,\ndischarge summaries etc). We developed a number of efficient lightweight\nclinical transformers using knowledge distillation and continual learning, with\nthe number of parameters ranging from 15 million to 65 million. These models\nperformed comparably to larger models such as BioBERT and ClinicalBioBERT and\nsignificantly outperformed other compact models trained on general or\nbiomedical data. Our extensive evaluation was done across several standard\ndatasets and covered a wide range of clinical text-mining tasks, including\nNatural Language Inference, Relation Extraction, Named Entity Recognition, and\nSequence Classification. To our knowledge, this is the first comprehensive\nstudy specifically focused on creating efficient and compact transformers for\nclinical NLP tasks. The models and code used in this study can be found on our\nHuggingface profile at https://huggingface.co/nlpie and Github page at\nhttps://github.com/nlpie-research/Lightweight-Clinical-Transformers,\nrespectively, promoting reproducibility of our results.\n",
                "链接": "https://arxiv.org/abs/2302.04725"
            },
            {
                "文章ID": "17180",
                "标题": "Developmental Negation Processing in Transformer Language Models",
                "作者": "Jr. Antonio Laverghetta,  John Licato",
                "发布日期": "2022-05-02",
                "摘要": "  Reasoning using negation is known to be difficult for transformer-based\nlanguage models. While previous studies have used the tools of\npsycholinguistics to probe a transformer's ability to reason over negation,\nnone have focused on the types of negation studied in developmental psychology.\nWe explore how well transformers can process such categories of negation, by\nframing the problem as a natural language inference (NLI) task. We curate a set\nof diagnostic questions for our target categories from popular NLI datasets and\nevaluate how well a suite of models reason over them. We find that models\nperform consistently better only on certain categories, suggesting clear\ndistinctions in how they are processed.\n",
                "链接": "https://arxiv.org/abs/2204.14114"
            }
        ]
    },
    {
        "question": {
            "question": "请查找关于智能体的研究进展的综述或调查论文。重点关注不同领域中智能体的方法和应用，以及相关的挑战和未来方向。",
            "type": "5"
        },
        "results": [
            {
                "文章ID": "110512",
                "标题": "A Survey on Continual Semantic Segmentation: Theory, Challenge, Method\n  and Application",
                "作者": " Bo Yuan,  Danpei Zhao",
                "发布日期": "2023-10-24",
                "摘要": "  Continual learning, also known as incremental learning or life-long learning,\nstands at the forefront of deep learning and AI systems. It breaks through the\nobstacle of one-way training on close sets and enables continuous adaptive\nlearning on open-set conditions. In the recent decade, continual learning has\nbeen explored and applied in multiple fields especially in computer vision\ncovering classification, detection and segmentation tasks. Continual semantic\nsegmentation (CSS), of which the dense prediction peculiarity makes it a\nchallenging, intricate and burgeoning task. In this paper, we present a review\nof CSS, committing to building a comprehensive survey on problem formulations,\nprimary challenges, universal datasets, neoteric theories and multifarious\napplications. Concretely, we begin by elucidating the problem definitions and\nprimary challenges. Based on an in-depth investigation of relevant approaches,\nwe sort out and categorize current CSS models into two main branches including\n\\textit{data-replay} and \\textit{data-free} sets. In each branch, the\ncorresponding approaches are similarity-based clustered and thoroughly\nanalyzed, following qualitative comparison and quantitative reproductions on\nrelevant datasets. Besides, we also introduce four CSS specialities with\ndiverse application scenarios and development tendencies. Furthermore, we\ndevelop a benchmark for CSS encompassing representative references, evaluation\nresults and reproductions, which is available\nat~\\url{https://github.com/YBIO/SurveyCSS}. We hope this survey can serve as a\nreference-worthy and stimulating contribution to the advancement of the\nlife-long learning field, while also providing valuable perspectives for\nrelated fields.\n",
                "链接": "https://arxiv.org/abs/2310.14277"
            },
            {
                "文章ID": "106886",
                "标题": "Auto-survey Challenge",
                "作者": "TAU, LISN  Thanh Gia Hieu Khuong, TAU, LISN  Benedictus Kent Rachmat",
                "发布日期": "2023-10-11",
                "摘要": "  We present a novel platform for evaluating the capability of Large Language\nModels (LLMs) to autonomously compose and critique survey papers spanning a\nvast array of disciplines including sciences, humanities, education, and law.\nWithin this framework, AI systems undertake a simulated peer-review mechanism\nakin to traditional scholarly journals, with human organizers serving in an\neditorial oversight capacity. Within this framework, we organized a competition\nfor the AutoML conference 2023. Entrants are tasked with presenting stand-alone\nmodels adept at authoring articles from designated prompts and subsequently\nappraising them. Assessment criteria include clarity, reference\nappropriateness, accountability, and the substantive value of the content. This\npaper presents the design of the competition, including the implementation\nbaseline submissions and methods of evaluation.\n",
                "链接": "https://arxiv.org/abs/2310.04480"
            },
            {
                "文章ID": "59462",
                "标题": "A Comprehensive Survey of Continual Learning: Theory, Method and\n  Application",
                "作者": " Liyuan Wang,  Xingxing Zhang,  Hang Su,  Jun Zhu",
                "发布日期": "2023-06-13",
                "摘要": "  To cope with real-world dynamics, an intelligent agent needs to incrementally\nacquire, update, accumulate, and exploit knowledge throughout its lifetime.\nThis ability, known as continual learning, provides a foundation for AI systems\nto develop themselves adaptively. In a general sense, continual learning is\nexplicitly limited by catastrophic forgetting, where learning a new task\nusually results in a dramatic performance degradation of the old tasks. Beyond\nthis, increasingly numerous advances have emerged in recent years that largely\nextend the understanding and application of continual learning. The growing and\nwidespread interest in this direction demonstrates its realistic significance\nas well as complexity. In this work, we present a comprehensive survey of\ncontinual learning, seeking to bridge the basic settings, theoretical\nfoundations, representative methods, and practical applications. Based on\nexisting theoretical and empirical results, we summarize the general objectives\nof continual learning as ensuring a proper stability-plasticity trade-off and\nan adequate intra/inter-task generalizability in the context of resource\nefficiency. Then we provide a state-of-the-art and elaborated taxonomy,\nextensively analyzing how representative strategies address continual learning,\nand how they are adapted to particular challenges in various applications.\nThrough an in-depth discussion of promising directions, we believe that such a\nholistic perspective can greatly facilitate subsequent exploration in this\nfield and beyond.\n",
                "链接": "https://arxiv.org/abs/2302.00487"
            },
            {
                "文章ID": "34903",
                "标题": "A survey, review, and future trends of skin lesion segmentation and\n  classification",
                "作者": " Md. Kamrul Hasan,  Md. Asif Ahamad,  Choon Hwai Yap,  Guang Yang",
                "发布日期": "2023-02-03",
                "摘要": "  The Computer-aided Diagnosis or Detection (CAD) approach for skin lesion\nanalysis is an emerging field of research that has the potential to alleviate\nthe burden and cost of skin cancer screening. Researchers have recently\nindicated increasing interest in developing such CAD systems, with the\nintention of providing a user-friendly tool to dermatologists to reduce the\nchallenges encountered or associated with manual inspection. This article aims\nto provide a comprehensive literature survey and review of a total of 594\npublications (356 for skin lesion segmentation and 238 for skin lesion\nclassification) published between 2011 and 2022. These articles are analyzed\nand summarized in a number of different ways to contribute vital information\nregarding the methods for the development of CAD systems. These ways include\nrelevant and essential definitions and theories, input data (dataset\nutilization, preprocessing, augmentations, and fixing imbalance problems),\nmethod configuration (techniques, architectures, module frameworks, and\nlosses), training tactics (hyperparameter settings), and evaluation criteria.\nWe intend to investigate a variety of performance-enhancing approaches,\nincluding ensemble and post-processing. We also discuss these dimensions to\nreveal their current trends based on utilization frequencies. In addition, we\nhighlight the primary difficulties associated with evaluating skin lesion\nsegmentation and classification systems using minimal datasets, as well as the\npotential solutions to these difficulties. Findings, recommendations, and\ntrends are disclosed to inform future research on developing an automated and\nrobust CAD system for skin lesion analysis.\n",
                "链接": "https://arxiv.org/abs/2208.12232"
            },
            {
                "文章ID": "50046",
                "标题": "A Survey of Deep Graph Clustering: Taxonomy, Challenge, Application, and\n  Open Resource",
                "作者": " Yue Liu,  Jun Xia,  Sihang Zhou,  Xihong Yang,  Ke Liang,  Chenchen Fan,  Yan Zhuang,  Stan Z. Li,  Xinwang Liu,  Kunlun He",
                "发布日期": "2023-09-13",
                "摘要": "  Graph clustering, which aims to divide nodes in the graph into several\ndistinct clusters, is a fundamental yet challenging task. Benefiting from the\npowerful representation capability of deep learning, deep graph clustering\nmethods have achieved great success in recent years. However, the corresponding\nsurvey paper is relatively scarce, and it is imminent to make a summary of this\nfield. From this motivation, we conduct a comprehensive survey of deep graph\nclustering. Firstly, we introduce formulaic definition, evaluation, and\ndevelopment in this field. Secondly, the taxonomy of deep graph clustering\nmethods is presented based on four different criteria, including graph type,\nnetwork architecture, learning paradigm, and clustering method. Thirdly, we\ncarefully analyze the existing methods via extensive experiments and summarize\nthe challenges and opportunities from five perspectives, including graph data\nquality, stability, scalability, discriminative capability, and unknown cluster\nnumber. Besides, the applications of deep graph clustering methods in six\ndomains, including computer vision, natural language processing, recommendation\nsystems, social network analyses, bioinformatics, and medical science, are\npresented. Last but not least, this paper provides open resource supports,\nincluding 1) a collection\n(\\url{https://github.com/yueliu1999/Awesome-Deep-Graph-Clustering}) of\nstate-of-the-art deep graph clustering methods (papers, codes, and datasets)\nand 2) a unified framework\n(\\url{https://github.com/Marigoldwu/A-Unified-Framework-for-Deep-Attribute-Graph-Clustering})\nof deep graph clustering. We hope this work can serve as a quick guide and help\nresearchers overcome challenges in this vibrant field.\n",
                "链接": "https://arxiv.org/abs/2211.12875"
            },
            {
                "文章ID": "100343",
                "标题": "Robust Recommender System: A Survey and Future Directions",
                "作者": " Kaike Zhang,  Qi Cao,  Fei Sun,  Yunfan Wu,  Shuchang Tao,  Huawei Shen,  Xueqi Cheng",
                "发布日期": "2023-09-06",
                "摘要": "  With the rapid growth of information, recommender systems have become\nintegral for providing personalized suggestions and overcoming information\noverload. However, their practical deployment often encounters \"dirty\" data,\nwhere noise or malicious information can lead to abnormal recommendations.\nResearch on improving recommender systems' robustness against such dirty data\nhas thus gained significant attention. This survey provides a comprehensive\nreview of recent work on recommender systems' robustness. We first present a\ntaxonomy to organize current techniques for withstanding malicious attacks and\nnatural noise. We then explore state-of-the-art methods in each category,\nincluding fraudster detection, adversarial training, certifiable robust\ntraining against malicious attacks, and regularization, purification,\nself-supervised learning against natural noise. Additionally, we summarize\nevaluation metrics and common datasets used to assess robustness. We discuss\nrobustness across varying recommendation scenarios and its interplay with other\nproperties like accuracy, interpretability, privacy, and fairness. Finally, we\ndelve into open issues and future research directions in this emerging field.\nOur goal is to equip readers with a holistic understanding of robust\nrecommender systems and spotlight pathways for future research and development.\n",
                "链接": "https://arxiv.org/abs/2309.02057"
            },
            {
                "文章ID": "56501",
                "标题": "Image Denoising: The Deep Learning Revolution and Beyond -- A Survey\n  Paper --",
                "作者": " Michael Elad,  Bahjat Kawar,  Gregory Vaksman",
                "发布日期": "2023-01-10",
                "摘要": "  Image denoising (removal of additive white Gaussian noise from an image) is\none of the oldest and most studied problems in image processing. An extensive\nwork over several decades has led to thousands of papers on this subject, and\nto many well-performing algorithms for this task. Indeed, 10 years ago, these\nachievements have led some researchers to suspect that \"Denoising is Dead\", in\nthe sense that all that can be achieved in this domain has already been\nobtained. However, this turned out to be far from the truth, with the\npenetration of deep learning (DL) into image processing. The era of DL brought\na revolution to image denoising, both by taking the lead in today's ability for\nnoise removal in images, and by broadening the scope of denoising problems\nbeing treated. Our paper starts by describing this evolution, highlighting in\nparticular the tension and synergy that exist between classical approaches and\nmodern DL-based alternatives in design of image denoisers.\n  The recent transitions in the field of image denoising go far beyond the\nability to design better denoisers. In the 2nd part of this paper we focus on\nrecently discovered abilities and prospects of image denoisers. We expose the\npossibility of using denoisers to serve other problems, such as regularizing\ngeneral inverse problems and serving as the prime engine in diffusion-based\nimage synthesis. We also unveil the idea that denoising and other inverse\nproblems might not have a unique solution as common algorithms would have us\nbelieve. Instead, we describe constructive ways to produce randomized and\ndiverse high quality results for inverse problems, all fueled by the progress\nthat DL brought to image denoising.\n  This survey paper aims to provide a broad view of the history of image\ndenoising and closely related topics. Our aim is to give a better context to\nrecent discoveries, and to the influence of DL in our domain.\n",
                "链接": "https://arxiv.org/abs/2301.03362"
            },
            {
                "文章ID": "123074",
                "标题": "Multi-agent Reinforcement Learning: A Comprehensive Survey",
                "作者": " Dom Huh,  Prasant Mohapatra",
                "发布日期": "2023-12-19",
                "摘要": "  The prevalence of multi-agent applications pervades various interconnected\nsystems in our everyday lives. Despite their ubiquity, the integration and\ndevelopment of intelligent decision-making agents in a shared environment pose\nchallenges to their effective implementation. This survey delves into the\ndomain of multi-agent systems (MAS), placing a specific emphasis on unraveling\nthe intricacies of learning optimal control within the MAS framework, commonly\nknown as multi-agent reinforcement learning (MARL). The objective of this\nsurvey is to provide comprehensive insights into various dimensions of MAS,\nshedding light on myriad opportunities while highlighting the inherent\nchallenges that accompany multi-agent applications. We hope not only to\ncontribute to a deeper understanding of the MAS landscape but also to provide\nvaluable perspectives for both researchers and practitioners. By doing so, we\naim to facilitate informed exploration and foster development within the\ndynamic realm of MAS, recognizing the need for adaptive strategies and\ncontinuous evolution in addressing emerging complexities in MARL.\n",
                "链接": "https://arxiv.org/abs/2312.10256"
            },
            {
                "文章ID": "73029",
                "标题": "The Metaverse: Survey, Trends, Novel Pipeline Ecosystem & Future\n  Directions",
                "作者": " Hani Sami,  Ahmad Hammoud,  Mouhamad Arafeh,  Mohamad Wazzeh,  Sarhad Arisdakessian,  Mario Chahoud,  Osama Wehbi,  Mohamad Ajaj,  Azzam Mourad,  Hadi Otrok,  Omar Abdel Wahab,  Rabeb Mizouni,  Jamal Bentahar,  Chamseddine Talhi,  Zbigniew Dziong,  Ernesto Damiani,  Mohsen Guizani",
                "发布日期": "2023-04-20",
                "摘要": "  The Metaverse offers a second world beyond reality, where boundaries are\nnon-existent, and possibilities are endless through engagement and immersive\nexperiences using the virtual reality (VR) technology. Many disciplines can\nbenefit from the advancement of the Metaverse when accurately developed,\nincluding the fields of technology, gaming, education, art, and culture.\nNevertheless, developing the Metaverse environment to its full potential is an\nambiguous task that needs proper guidance and directions. Existing surveys on\nthe Metaverse focus only on a specific aspect and discipline of the Metaverse\nand lack a holistic view of the entire process. To this end, a more holistic,\nmulti-disciplinary, in-depth, and academic and industry-oriented review is\nrequired to provide a thorough study of the Metaverse development pipeline. To\naddress these issues, we present in this survey a novel multi-layered pipeline\necosystem composed of (1) the Metaverse computing, networking, communications\nand hardware infrastructure, (2) environment digitization, and (3) user\ninteractions. For every layer, we discuss the components that detail the steps\nof its development. Also, for each of these components, we examine the impact\nof a set of enabling technologies and empowering domains (e.g., Artificial\nIntelligence, Security & Privacy, Blockchain, Business, Ethics, and Social) on\nits advancement. In addition, we explain the importance of these technologies\nto support decentralization, interoperability, user experiences, interactions,\nand monetization. Our presented study highlights the existing challenges for\neach component, followed by research directions and potential solutions. To the\nbest of our knowledge, this survey is the most comprehensive and allows users,\nscholars, and entrepreneurs to get an in-depth understanding of the Metaverse\necosystem to find their opportunities and potentials for contribution.\n",
                "链接": "https://arxiv.org/abs/2304.09240"
            },
            {
                "文章ID": "36860",
                "标题": "A challenge-based survey of e-recruitment recommendation systems",
                "作者": " Yoosof Mashayekhi,  Nan Li,  Bo Kang,  Jefrey Lijffijt,  Tijl De Bie",
                "发布日期": "2023-10-23",
                "摘要": "  E-recruitment recommendation systems recommend jobs to job seekers and job\nseekers to recruiters. The recommendations are generated based on the\nsuitability of the job seekers for the positions as well as the job seekers'\nand the recruiters' preferences. Therefore, e-recruitment recommendation\nsystems could greatly impact job seekers' careers. Moreover, by affecting the\nhiring processes of the companies, e-recruitment recommendation systems play an\nimportant role in shaping the companies' competitive edge in the market. Hence,\nthe domain of e-recruitment recommendation deserves specific attention.\nExisting surveys on this topic tend to discuss past studies from the\nalgorithmic perspective, e.g., by categorizing them into collaborative\nfiltering, content based, and hybrid methods. This survey, instead, takes a\ncomplementary, challenge-based approach, which we believe might be more\npractical to developers facing a concrete e-recruitment design task with a\nspecific set of challenges, as well as to researchers looking for impactful\nresearch projects in this domain. We first identify the main challenges in the\ne-recruitment recommendation research. Next, we discuss how those challenges\nhave been studied in the literature. Finally, we provide future research\ndirections that we consider promising in the e-recruitment recommendation\ndomain.\n",
                "链接": "https://arxiv.org/abs/2209.05112"
            }
        ]
    }
]